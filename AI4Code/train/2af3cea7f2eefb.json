{"cell_type":{"77662565":"code","4f70f460":"code","4f580170":"code","44f7af59":"code","4eb2c74c":"code","69df4d43":"code","2d2ca5c9":"code","30ae9deb":"code","6b475aa1":"code","4c0b192f":"code","af93685c":"code","88a99011":"code","be45f6f9":"code","1e848bc8":"code","99dc9846":"code","1cc79988":"code","933b8b2d":"code","b22ee2cf":"code","c8e7fbeb":"code","d98e308d":"code","af028950":"code","c8bf1655":"code","49b1c4ff":"code","02991ec1":"code","7594b810":"code","3e4aa064":"code","0756fbce":"code","5d00ff94":"code","35fd62dd":"code","4a5d8392":"code","7ce8b0d1":"code","ea1ceeb0":"code","36d203b7":"code","a7a4444e":"code","9e3ead7c":"code","1837913f":"code","51997ce9":"code","b9c9921b":"code","8c1f2a11":"code","5f4bce4c":"code","9ab1e4d8":"code","c1f7a26c":"code","041f1d69":"code","30442736":"code","d9edf2e7":"code","82bfb9e4":"code","2235157a":"code","6d90ebce":"code","978f4771":"code","5b0c89a3":"code","d75faaf6":"code","5e1bfe1e":"code","ea7613e5":"code","98d5c6f2":"code","f309db73":"code","9dd13d44":"markdown","1421d884":"markdown","f40f559d":"markdown","33b19452":"markdown","1cc21a82":"markdown","11f4f975":"markdown","a4d5709e":"markdown","9419acaa":"markdown","bc8424f8":"markdown","05c0e2bf":"markdown","cdc949b3":"markdown","1b42913e":"markdown","23111686":"markdown","6ca1f42d":"markdown","788689ed":"markdown","ccb5a951":"markdown","50d03271":"markdown","959b48e6":"markdown","218dd57d":"markdown","f8149f2e":"markdown","85aebcd1":"markdown","d93c274e":"markdown","59d18f66":"markdown","302ddef5":"markdown","06450783":"markdown"},"source":{"77662565":"import nltk\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk import word_tokenize\nfrom nltk.tokenize import WhitespaceTokenizer \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer   \nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, accuracy_score","4f70f460":"df_sms = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv',delimiter=',',encoding='latin-1')","4f580170":"df_sms.head()","44f7af59":"df_sms.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis=1, inplace=True)","4eb2c74c":"df_sms.columns=['label','message']","69df4d43":"df_sms.head()","2d2ca5c9":"df_sms.describe()","30ae9deb":"df_sms.groupby('label').describe()","6b475aa1":"df_sms['length']=df_sms['message'].apply(lambda x: len(x))","4c0b192f":"df_sms.head()","af93685c":"plt.figure(figsize=(8,6))\nplt.hist(x='length', bins=150, data=df_sms,edgecolor='black')\nplt.title('Distribution of the Length of Messages', fontsize=15)\nplt.xlabel('Message Length', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.show()","88a99011":"df_sms['length'].max()","be45f6f9":"df_sms['length'].describe()","1e848bc8":"df_sms[df_sms['length']==910]['message']","99dc9846":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nplt.hist(x='length', bins=60, data=df_sms[df_sms['label']=='ham'],edgecolor='black', color='m')\nplt.title('Distribution of the Length of Ham Messages', fontsize=15)\nplt.ylabel('Frequency', fontsize=12)\nplt.xlabel('Message Length', fontsize=12)\n\nplt.subplot(1,2,2)\nplt.hist(x='length', bins=60, data=df_sms[df_sms['label']=='spam'],edgecolor='black', color='teal')\nplt.title('Distribution of the Length of Spam Messages', fontsize=15)\nplt.ylabel('')\nplt.yticks([])\nplt.xlabel('Message Length', fontsize=12)\n\nplt.show()","1cc79988":"ps=PorterStemmer()\nwst= WhitespaceTokenizer() \n\n##### 1. Converting text to lower case\ndef lower_func (x):\n    return x.lower()\n\n\n##### 2. Removing Numbers from the text corpus\ndef remove_number_func (x): \n    new=\"\"\n    for a in x:\n        if a.isdigit()==False:\n            new=new+a\n    return new\n\n\n##### 3. Removing punctuation \ndef remove_punc_func(x):\n    new=''\n    for a in x:\n        if a not in string.punctuation:\n            new=new+a\n    return new\n\n##### 4. Removing special characters\ndef remove_spec_char_func(x):\n    new=''\n    for a in x:\n        if (a.isalnum()==True) or (a==' '):\n            new=new+a\n    return(new)\n\n##### 5. Removing english stopwords\ndef remove_stopwords(x):\n    new=[]\n    for a in x.split():\n        if a not in stopwords.words('english'):\n            new.append(a)\n    return \" \".join(new)\n\n##### 6. Stemming words to root words\ndef stem_func(x):\n    wordlist = word_tokenize(x)\n    psstem = [ps.stem(a) for a in wordlist]\n    return ' '.join(psstem)\n\n##### 7. Removing extra whitespaces \ndef remove_whitespace_func(x):\n    return(wst.tokenize(x))\n\ndef compose(f, g):\n    return lambda x: f(g(x))\n\nfinal=compose(compose(compose(compose(compose(compose(remove_whitespace_func,stem_func),remove_stopwords),remove_spec_char_func),remove_punc_func),remove_number_func),lower_func)","933b8b2d":"X=df_sms['message']\ny=df_sms['label']","b22ee2cf":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","c8e7fbeb":"pipeline = Pipeline([\n    ('bow', CountVectorizer()),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', MultinomialNB()), \n])","d98e308d":"pipeline.fit(X_train, y_train)","af028950":"prediction1=pipeline.predict(X_test)","c8bf1655":"print(classification_report(y_test,prediction1))","49b1c4ff":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=final)),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', MultinomialNB()), \n])","02991ec1":"pipeline.fit(X_train, y_train)","7594b810":"prediction2=pipeline.predict(X_test)","3e4aa064":"print(classification_report(y_test,prediction2))","0756fbce":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer='word', stop_words='english')),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', MultinomialNB()), \n])","5d00ff94":"pipeline.fit(X_train, y_train)","35fd62dd":"prediction3=pipeline.predict(X_test)","4a5d8392":"print(classification_report(y_test,prediction3))","7ce8b0d1":"pipeline = Pipeline([\n    ('bow', CountVectorizer()),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', PassiveAggressiveClassifier()), \n])","ea1ceeb0":"pipeline.fit(X_train, y_train)","36d203b7":"prediction4=pipeline.predict(X_test)","a7a4444e":"print(classification_report(y_test,prediction4))","9e3ead7c":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=final)),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', PassiveAggressiveClassifier()), \n])","1837913f":"pipeline.fit(X_train, y_train)","51997ce9":"prediction5=pipeline.predict(X_test)","b9c9921b":"print(classification_report(y_test,prediction5))","8c1f2a11":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer='word', stop_words='english')),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', PassiveAggressiveClassifier()), \n])","5f4bce4c":"pipeline.fit(X_train, y_train)","9ab1e4d8":"prediction6=pipeline.predict(X_test)","c1f7a26c":"print(classification_report(y_test,prediction6))","041f1d69":"pipeline = Pipeline([\n    ('bow', CountVectorizer()),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', RandomForestClassifier()), \n])","30442736":"pipeline.fit(X_train, y_train)","d9edf2e7":"prediction7=pipeline.predict(X_test)","82bfb9e4":"print(classification_report(y_test,prediction7))","2235157a":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=final)),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', RandomForestClassifier()), \n])","6d90ebce":"pipeline.fit(X_train, y_train)","978f4771":"prediction8=pipeline.predict(X_test)","5b0c89a3":"print(classification_report(y_test,prediction8))","d75faaf6":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer='word', stop_words='english')),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', RandomForestClassifier()), \n])","5e1bfe1e":"pipeline.fit(X_train, y_train)","ea7613e5":"prediction9=pipeline.predict(X_test)","98d5c6f2":"print(classification_report(y_test,prediction9))","f309db73":"print('MultinomialNB Classifier without text pre-processing', accuracy_score(y_test,prediction1))\nprint('MultinomialNB Classifier with text pre-processing: ', accuracy_score(y_test,prediction2))\nprint('MultinomialNB Classifier with only removing stop words', accuracy_score(y_test,prediction3))\nprint('\\n')\nprint('Passive Aggressive Classifier without text pre-processing: ', accuracy_score(y_test,prediction4))\nprint('Passive Aggressive Classifier with text pre-processing: ', accuracy_score(y_test,prediction5))\nprint('Passive Aggressive Classifier with only removing stop words: ', accuracy_score(y_test,prediction6))\nprint('\\n')\nprint('Random Forest Classifier without text pre-processing: ', accuracy_score(y_test,prediction7))\nprint('Random Forest Classifier with text pre-processing: ', accuracy_score(y_test,prediction8))\nprint('Random Forest Classifier with only removing stop words: ', accuracy_score(y_test,prediction9))","9dd13d44":"#### Passive Aggressive Classifier with Text Preprocessing","1421d884":"#### Random Forest  Classifier with Only Removing Stop Words","f40f559d":"We define a preprocessing function that performs the following operations:\n\n- Converting text to lower case\n\n- Removing numbers from the text corpus\n\n- Removing punctuation from the text corpus\n\n- Removing special characters such as \u2018<\u2019, \u2018\u2026\u2019 from the text corpus\n\n- Removing english stopwords\n\n- Stemming words to root words\n\n- Removing extra whitespaces from the text corpus","33b19452":"The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam. The files contain one message per row and each row contains the label (ham or spam) and the raw text message.\n\nIn this notebook we will use nltk librarie to predict and classify the label of text messages and correctly predict a given piece of text as Spam or Ham.","1cc21a82":"## Exploratory Data Analysis","11f4f975":"#### MultinomialNB Classifier with Text Preprocessing","a4d5709e":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Introduction<\/a><\/span><\/li><li><span><a href=\"#Importing-Libraries\" data-toc-modified-id=\"Importing-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Importing Libraries<\/a><\/span><\/li><li><span><a href=\"#Loading-Dataset\" data-toc-modified-id=\"Loading-Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Loading Dataset<\/a><\/span><\/li><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Exploratory Data Analysis<\/a><\/span><\/li><li><span><a href=\"#Ham\/Spam-Messages-Prediction\" data-toc-modified-id=\"Ham\/Spam-Messages-Prediction-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Ham\/Spam Messages Prediction<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Text-Preprocessing-Function\" data-toc-modified-id=\"Text-Preprocessing-Function-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Text Preprocessing Function<\/a><\/span><\/li><li><span><a href=\"#Splitting-the-Dataset\" data-toc-modified-id=\"Splitting-the-Dataset-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Splitting the Dataset<\/a><\/span><\/li><li><span><a href=\"#Creating-Data-Pipeline\" data-toc-modified-id=\"Creating-Data-Pipeline-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;<\/span>Creating Data Pipeline<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#MultinomialNB-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"MultinomialNB-Classifier-without-Text-Preprocessing-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;<\/span>MultinomialNB Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#MultinomialNB-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"MultinomialNB-Classifier-with-Text-Preprocessing-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;<\/span>MultinomialNB Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#MultinomialNB-Classifier-with-Only-Removing-Stop-Words\" data-toc-modified-id=\"MultinomialNB-Classifier-with-Only-Removing-Stop-Words-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;<\/span>MultinomialNB Classifier with Only Removing Stop Words<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-without-Text-Preprocessing-5.3.4\"><span class=\"toc-item-num\">5.3.4&nbsp;&nbsp;<\/span>Passive Aggressive Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-with-Text-Preprocessing-5.3.5\"><span class=\"toc-item-num\">5.3.5&nbsp;&nbsp;<\/span>Passive Aggressive Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-with-Only-Removing-Stop-Words\" data-toc-modified-id=\"Passive-Aggressive-Classifier-with-Only-Removing-Stop-Words-5.3.6\"><span class=\"toc-item-num\">5.3.6&nbsp;&nbsp;<\/span>Passive Aggressive Classifier with Only Removing Stop Words<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest-Classifier-without-Text-Preprocessing-5.3.7\"><span class=\"toc-item-num\">5.3.7&nbsp;&nbsp;<\/span>Random Forest Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Random-Forest--Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest--Classifier-with-Text-Preprocessing-5.3.8\"><span class=\"toc-item-num\">5.3.8&nbsp;&nbsp;<\/span>Random Forest  Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Random-Forest--Classifier-with-Only-Removing-Stop-Words\" data-toc-modified-id=\"Random-Forest--Classifier-with-Only-Removing-Stop-Words-5.3.9\"><span class=\"toc-item-num\">5.3.9&nbsp;&nbsp;<\/span>Random Forest  Classifier with Only Removing Stop Words<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Conclusion<\/a><\/span><\/li><\/ul><\/div>","9419acaa":"#### Passive Aggressive Classifier with Only Removing Stop Words","bc8424f8":"## Importing Libraries","05c0e2bf":"#### Random Forest  Classifier with Text Preprocessing","cdc949b3":"## Loading Dataset","1b42913e":"## Conclusion","23111686":"## Ham\/Spam Messages Prediction","6ca1f42d":"### Splitting the Dataset ","788689ed":"# <center> SMS Spam Detection by Natural Language Processing <center>","ccb5a951":"## Introduction","50d03271":"### Creating Data Pipeline","959b48e6":"#### MultinomialNB Classifier without Text Preprocessing ","218dd57d":"In this project, the following tasks were preformed:\n\n- We performed exploratory data analysis on the SMS Spam Collection Dataset. \n\n- We built binary classifiers that classify ham and spam messages. We used three different classifiers including Random Forest Classifier, Naive-Bayes Classifier and passive Agressive Classifier to classify messages into ham\/spam categories and applied them with and without text preprocessing and with only removing the stop words.\n\n- Passive Aggressive was the best model for this analysis of the messages. The highest accuracy was 99.01% and it was obtained for the Passive Aggressive model applied on the messages which only their stop words have been removed.","f8149f2e":"#### Passive Aggressive Classifier without Text Preprocessing","85aebcd1":"### Text Preprocessing Function","d93c274e":"#### MultinomialNB Classifier with Only Removing Stop Words","59d18f66":"# ![1.jpg](attachment:1.jpg)","302ddef5":"We can see that the Passive Agreesive Classifier is more effective in predicting whether sms is ham or spam as compared with MultinomialNB and Random Forest Classifiers. The highest accuracy score was obtained for the Passive Agreesive Classifier with  with only removing stop words.","06450783":"#### Random Forest Classifier without Text Preprocessing"}}