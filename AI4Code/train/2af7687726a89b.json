{"cell_type":{"8d4372bf":"code","a0c34026":"code","d5ae4b5e":"code","2b8e783a":"code","f29f1380":"code","a3176638":"code","b81bddf8":"code","c96d023b":"code","94a0bc8a":"code","9b1c6942":"code","a2381fef":"code","3b945c6a":"code","27957417":"code","e46eb3c5":"code","0d8ebb7a":"code","7bb03313":"code","658c5678":"code","dd8dae6b":"code","01c7f95e":"code","bf189fb7":"code","3240960e":"code","9c25da3a":"code","38d65ea7":"code","6e4fc9c2":"code","43a885ec":"code","4154d51d":"code","bbce9228":"code","d9ff1616":"code","85e9144e":"code","7ff1c48c":"code","174789d2":"code","1d3b70a3":"code","cab8dd65":"code","5177a27f":"code","151b8c2f":"code","3eaaf217":"code","747922f5":"code","bdce16b5":"code","981b03cb":"code","0d827e9a":"code","2befe083":"code","43a66d70":"code","59957671":"code","03ee8ad3":"code","cf446b79":"code","834eb6af":"code","f5474073":"code","6d92de91":"code","aac8c948":"code","f1884895":"code","9967ad14":"code","cb4634f7":"code","0d1537a1":"code","4b54ad31":"code","452fc112":"code","63000e58":"code","b5af0520":"code","a8d7d059":"code","96e0797c":"code","e080cf88":"code","51c0eb8d":"code","80549e8a":"code","17621424":"code","bf085b63":"code","391faa6d":"code","d6c0bd54":"code","6b76ce7f":"markdown","f6603941":"markdown","d92e33fd":"markdown","622abff3":"markdown","2e9c78e9":"markdown","07a04502":"markdown","0f418546":"markdown","41cf7e03":"markdown","c5cb06c6":"markdown","88777ed8":"markdown","7515dba0":"markdown","d670733e":"markdown","f66ccdbc":"markdown","3bc59bff":"markdown","ebb28ef8":"markdown","12f36c98":"markdown","ace0f4a4":"markdown","bb76f65c":"markdown","0e3d9f0b":"markdown","9f1991b4":"markdown","e0efae4a":"markdown"},"source":{"8d4372bf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport datetime, time\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = FutureWarning)","a0c34026":"from lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","d5ae4b5e":"from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import scale","2b8e783a":"from scipy.stats import ranksums","f29f1380":"from bayes_opt import BayesianOptimization","a3176638":"def reduce_mem_usage(df_):\n    start_mem = df_.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n    \n    for c in df_.columns[df_.dtypes != 'object']:\n        col_type = df_[c].dtype\n        \n        c_min = df_[c].min()\n        c_max = df_[c].max()\n        if str(col_type)[:3] == 'int':\n            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                df_[c] = df_[c].astype(np.int8)\n            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                df_[c] = df_[c].astype(np.int16)\n            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                df_[c] = df_[c].astype(np.int32)\n            else:\n                df_[c] = df_[c].astype(np.int64)  \n        else:\n            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                df_[c] = df_[c].astype(np.float16)\n            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                df_[c] = df_[c].astype(np.float32)\n            else:\n                df_[c] = df_[c].astype(np.float64)\n\n    end_mem = df_.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df_","b81bddf8":"# For exploring missing values across train and test sets\ndef get_missing_report(df_, target_name = 'TARGET'):\n    # Divide in training\/validation and test data\n    df_train_ = df_[df_[target_name].notnull()].drop(target_name, axis = 1)\n    df_test_ = df_[df_[target_name].isnull()].drop(target_name, axis = 1)\n    \n    count_missing_train = df_train_.isnull().sum().values\n    ratio_missing_train = count_missing_train \/ df_train_.shape[0]\n    count_missing_test = df_test_.isnull().sum().values\n    ratio_missing_test = count_missing_test \/ df_test_.shape[0]\n    \n    return pd.DataFrame(data = {'count_missing_train': count_missing_train, \n                                'ratio_missing_train': ratio_missing_train,\n                                'count_missing_test': count_missing_test, \n                                'ratio_missing_test': ratio_missing_test}, \n                        index = df_test_.columns.values)","c96d023b":"# For comparing distributions of two features\ndef corr_feature_with_target(feature, target):\n    c0 = feature[target == 0].dropna()\n    c1 = feature[target == 1].dropna()\n        \n    if set(feature.unique()) == set([0, 1]):\n        diff = abs(c0.mean(axis = 0) - c1.mean(axis = 0))\n    else:\n        diff = abs(c0.median(axis = 0) - c1.median(axis = 0))\n        \n    p = ranksums(c0, c1)[1] if ((len(c0) >= 20) & (len(c1) >= 20)) else 2\n        \n    return [diff \/ feature.mean(), p]","94a0bc8a":"# For selecting the best model for train set by simple launching the several classic models\ndef plot_roc_curves(df_train_, target_name, random_state = 0):\n    warnings.simplefilter('ignore')\n    \n    f_imp = pd.DataFrame(index = df_train_.columns.drop(target_name))\n    \n    X_trn, X_tst, y_trn, y_tst = train_test_split(df_train_.drop(target_name, axis = 1), \n                                                  df_train_[target_name], \n                                                  test_size = 0.2, random_state = random_state)\n\n    plt.figure(figsize = (7, 7))\n    plt.plot([0, 1], [0, 1], 'k--')\n\n    estimator = LGBMClassifier(random_state = random_state)\n    estimator.fit(X_trn, y_trn)\n    y_pred_xgb = estimator.predict_proba(X_tst)[:, 1]\n    fpr_xgb, tpr_xgb, _ = roc_curve(y_tst, y_pred_xgb)\n    f_imp['LGBM'] = pd.Series(estimator.feature_importances_, index = X_trn.columns)\n    plt.plot(fpr_xgb, tpr_xgb, label = 'LGBM: ' + str(roc_auc_score(y_tst, y_pred_xgb)))\n    \n    X_trn.fillna(X_trn.mean(axis = 0), inplace = True)\n    X_tst.fillna(X_tst.mean(axis = 0), inplace = True)\n        \n    estimator = RandomForestClassifier(random_state = random_state)\n    estimator.fit(X_trn, y_trn)\n    y_pred_rf = estimator.predict_proba(X_tst)[:, 1]\n    fpr_rf, tpr_rf, _ = roc_curve(y_tst, y_pred_rf)\n    f_imp['RF'] = estimator.feature_importances_\n    plt.plot(fpr_rf, tpr_rf, label = 'RF: ' + str(roc_auc_score(y_tst, y_pred_rf)))\n    \n    estimator = LogisticRegression(random_state = random_state)\n    estimator.fit(X_trn, y_trn)\n    y_pred_lrg = estimator.predict_proba(X_tst)[:, 1]\n    fpr_lrg, tpr_lrg, _ = roc_curve(y_tst, y_pred_lrg)\n    plt.plot(fpr_lrg, tpr_lrg, label = 'LogR: ' + str(roc_auc_score(y_tst, y_pred_lrg)))\n    \n    X_trn = pd.DataFrame(scale(X_trn), index = X_trn.index, columns = X_trn.columns)\n    X_tst = pd.DataFrame(scale(X_tst), index = X_tst.index, columns = X_tst.columns)\n    \n    estimator = KNeighborsClassifier()\n    estimator.fit(X_trn, y_trn)\n    y_pred_knn = estimator.predict_proba(X_tst)[:, 1]\n    fpr_knn, tpr_knn, _ = roc_curve(y_tst, y_pred_knn)\n    plt.plot(fpr_knn, tpr_knn, label = 'KNN: ' + str(roc_auc_score(y_tst, y_pred_knn)))\n    \n    del X_trn, X_tst, y_trn, y_tst\n    gc.collect()\n    \n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(loc = 'best')\n    plt.show()\n    \n    f_imp['mean'] = f_imp.mean(axis = 1)\n    return f_imp","9b1c6942":"# For saving scores and metrics\nscores_index = [\n        'roc_auc_train', 'roc_auc_test', \n        'precision_train_0', 'precision_test_0', \n        'precision_train_1', 'precision_test_1', \n        'recall_train_0', 'recall_test_0', \n        'recall_train_1', 'recall_test_1', \n        'LB'\n]","a2381fef":"# For visual analysis of the metrics\ndef display_scores(df_scores_):\n    _, axes = plt.subplots(3, 2, figsize = (25, 10))\n    df_scores_.T[[scores_index[0]]].plot(ax = axes[0, 0]); # roc-auc train\n    df_scores_.T[[scores_index[1], scores_index[10]]].plot(ax = axes[0, 1]); # roc-auc test & LB\n    df_scores_.T[[scores_index[2], scores_index[3]]].plot(ax = axes[1, 0]);  # precision class 0\n    df_scores_.T[[scores_index[4], scores_index[5]]].plot(ax = axes[1, 1]);  # precision class 1\n    df_scores_.T[[scores_index[6], scores_index[7]]].plot(ax = axes[2, 0]);  # recall class 0\n    df_scores_.T[[scores_index[8], scores_index[9]]].plot(ax = axes[2, 1]);  # recall class 1","3b945c6a":"# For cleaning float LGBM parameters after Bayesian optimization\ndef int_lgbm_params(params):\n    for p in params:\n        if p in ['num_leaves', 'max_depth', 'n_estimators', 'subsample_for_bin', 'min_child_samples', \n                 'subsample_freq', 'random_state']:\n            params[p] = int(np.round(params[p], decimals = 0))\n    return params","27957417":"# For cross-validation with LGBM classifier\ndef cv_lgbm_scores(df_, num_folds, params, \n                   target_name = 'TARGET', index_name = 'SK_ID_CURR',\n                   stratified = False, rs = 1001, verbose = -1):\n    \n    warnings.simplefilter('ignore')\n    \n    # Cleaning and defining parameters for LGBM\n    params = int_lgbm_params(params)\n    clf = LGBMClassifier(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n\n    # Divide in training\/validation and test data\n    df_train_ = df_[df_[target_name].notnull()]\n    df_test_ = df_[df_[target_name].isnull()]\n    print(\"Starting LightGBM cross-validation at {}\".format(time.ctime()))\n    print(\"Train shape: {}, test shape: {}\".format(df_train_.shape, df_test_.shape))\n\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = rs)\n    else:\n        folds = KFold(n_splits = num_folds, shuffle = True, random_state = rs)\n        \n    # Create arrays to store results\n    train_pred = np.zeros(df_train_.shape[0])\n    train_pred_proba = np.zeros(df_train_.shape[0])\n\n    test_pred = np.zeros(df_train_.shape[0])\n    test_pred_proba = np.zeros(df_train_.shape[0])\n    \n    prediction = np.zeros(df_test_.shape[0]) # prediction for test set\n    \n    feats = df_train_.columns.drop([target_name, index_name])\n    \n    df_feat_imp_ = pd.DataFrame(index = feats)\n    \n    # Cross-validation cycle\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df_train_[feats], df_train_[target_name])):\n        print('--- Fold {} started at {}'.format(n_fold, time.ctime()))\n        \n        train_x, train_y = df_train_[feats].iloc[train_idx], df_train_[target_name].iloc[train_idx]\n        valid_x, valid_y = df_train_[feats].iloc[valid_idx], df_train_[target_name].iloc[valid_idx]\n\n        clf.fit(train_x, train_y, \n                eval_set = [(valid_x, valid_y)], eval_metric = 'auc', \n                verbose = verbose, early_stopping_rounds = 100)\n\n        train_pred[train_idx] = clf.predict(train_x, num_iteration = clf.best_iteration_)\n        train_pred_proba[train_idx] = clf.predict_proba(train_x, num_iteration = clf.best_iteration_)[:, 1]\n        test_pred[valid_idx] = clf.predict(valid_x, num_iteration = clf.best_iteration_)\n        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n        \n        prediction += clf.predict_proba(df_test_[feats], \n                                        num_iteration = clf.best_iteration_)[:, 1] \/ folds.n_splits\n\n        df_feat_imp_[n_fold] = pd.Series(clf.feature_importances_, index = feats)\n        \n        del train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    # Computation of metrics\n    roc_auc_train = roc_auc_score(df_train_[target_name], train_pred_proba)\n    precision_train = precision_score(df_train_[target_name], train_pred, average = None)\n    recall_train = recall_score(df_train_[target_name], train_pred, average = None)\n    \n    roc_auc_test = roc_auc_score(df_train_[target_name], test_pred_proba)\n    precision_test = precision_score(df_train_[target_name], test_pred, average = None)\n    recall_test = recall_score(df_train_[target_name], test_pred, average = None)\n\n    print('Full AUC score {:.6f}'.format(roc_auc_test))\n    \n    # Filling the feature_importance table\n    df_feat_imp_.fillna(0, inplace = True)\n    df_feat_imp_['mean'] = df_feat_imp_.mean(axis = 1)\n    \n    # Preparing results of prediction for saving\n    prediction_train = df_train_[[index_name]]\n    prediction_train[target_name] = test_pred_proba\n    prediction_test = df_test_[[index_name]]\n    prediction_test[target_name] = prediction\n    \n    del df_train_, df_test_\n    gc.collect()\n    \n    # Returning the results and metrics in format for scores' table\n    return df_feat_imp_, prediction_train, prediction_test, \\\n           [roc_auc_train, roc_auc_test,\n            precision_train[0], precision_test[0], precision_train[1], precision_test[1],\n            recall_train[0], recall_test[0], recall_train[1], recall_test[1], 0]","e46eb3c5":"# For visual analysis of the fearure importances\ndef display_feature_importances(df_feat_imp_):\n    n_columns = 3\n    n_rows = (df_feat_imp_.shape[1] + 1) \/\/ n_columns\n    _, axes = plt.subplots(n_rows, n_columns, figsize=(8 * n_columns, 8 * n_rows))\n    for i, c in enumerate(df_feat_imp_.columns):\n        sns.barplot(x = c, y = 'index', \n                    data = df_feat_imp_.reset_index().sort_values(c, ascending = False).head(20), \n                    ax = axes[i \/\/ n_columns, i % n_columns] if n_rows > 1 else axes[i % n_columns])\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.show()","0d8ebb7a":"# For selection of parameters for LGBM with Bayesian optimization\ndef get_best_params_for_lgbm(df_train_, seed_cv_, seed_bo_, target_name = 'TARGET', \n                             init_points = 5, n_iter = 5):\n    def lgbm_auc_evaluate(**params):\n        warnings.simplefilter('ignore')\n    \n        params = int_lgbm_params(params)   \n        clf = LGBMClassifier(**params, n_estimators = 10000, nthread = 4, n_jobs = -1)\n\n        folds = KFold(n_splits = 2, shuffle = True, random_state = params['random_state'])\n        \n        test_pred_proba = np.zeros(df_train_.shape[0])\n    \n        feats = df_train_.columns.drop(target_name)\n    \n        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df_train_[feats], df_train_[target_name])):\n            train_x, train_y = df_train_[feats].iloc[train_idx], df_train_[target_name].iloc[train_idx]\n            valid_x, valid_y = df_train_[feats].iloc[valid_idx], df_train_[target_name].iloc[valid_idx]\n\n            clf.fit(train_x, train_y, \n                    eval_set = [(valid_x, valid_y)], eval_metric = 'auc', \n                    verbose = False, early_stopping_rounds = 100)\n\n            test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n        \n            del train_x, train_y, valid_x, valid_y\n            gc.collect()\n        \n        roc_auc_test = roc_auc_score(df_train_[target_name], test_pred_proba)\n        \n        return roc_auc_test\n    \n    params = {'learning_rate': (.001, .02), \n          'colsample_bytree': (0.3, 1),\n          'subsample_for_bin' : (20000, 500000),\n          'subsample': (0.3, 1), \n          'num_leaves': (2, 100), \n          'max_depth': (3, 9), \n          'reg_alpha': (.0, 1.), \n          'reg_lambda': (.0, 1.), \n          'min_split_gain': (.01, 1.),\n          'min_child_weight': (1, 50),\n          'min_child_samples': (10, 1000),\n          'random_state': (seed_cv_, seed_cv_)}\n    bo = BayesianOptimization(lgbm_auc_evaluate, params, random_state = seed_bo_)\n    bo.maximize(init_points = init_points, n_iter = n_iter)\n\n    return bo.res['max']['max_val'], bo.res['max']['max_params']","7bb03313":"# For metadata about predictions\nblending_index = ['date', 'to_blend', 'folder', 'file_name', 'auc_train', 'auc_test', 'auc_LB', 'Comments']\nsuffix_train = '_train.csv'\nsuffix_test = '_test.csv'\nblending_folder = '..\/input\/tmp-preds'\nblending_file_name = 'predictions_for_blending.csv'\n\ndf_blend = pd.DataFrame(index = blending_index)\ndf_blend.index.name = 'index'\n#df_blend.to_csv(blending_folder + '\/' + blending_file_name) # Commented for Kaggle","658c5678":"# For saving prediction into file\ndef save_prediction(df_, file_name, index_col = 'SK_ID_CURR', prediction_col = 'TARGET'):\n    df_.columns = [index_col, prediction_col]\n    df_.to_csv(file_name, index = False) ","dd8dae6b":"# For saving files and metadata about predictions for blending\ndef store_predictions_for_blending(df_train_, df_test_, file_name, scor, comments, \n                                   index_col = 'SK_ID_CURR', prediction_col = 'TARGET', \n                                   folder = blending_folder, b_file_name = blending_file_name):\n    \n    full_file_name = folder + '\/' + file_name\n    save_prediction(df_train_, full_file_name + suffix_train, index_col, prediction_col)\n    save_prediction(df_test_, full_file_name + suffix_test, index_col, prediction_col)\n    \n    df_blending = pd.read_csv(b_file_name, index_col = 'index')\n    df_blending[df_blending.shape[1]] = [\n        datetime.datetime.today(),\n        True,\n        folder, file_name,\n        scor[0], scor[1], scor[-1],\n        comments\n    ]\n    df_blending.to_csv(b_file_name)\n    del df_blending\n    gc.collect()","01c7f95e":"# For loading previous prediction results\ndef load_predictions_for_blending(b_folder = blending_folder, b_file_name = blending_file_name):\n    def load_prediction(file_name):\n        tmp = pd.read_csv(file_name)\n        return tmp.set_index(tmp.columns[0])\n\n    df_blend_ = pd.read_csv(b_folder + '\/' + b_file_name, index_col = 'index')\n    df_train_ = []\n    df_test_ = []\n    for c in df_blend_.columns:\n        #full_file_name = df_blend_.loc['folder', c] + '\/' + df_blend_.loc['file_name', c]\n        full_file_name = '..\/input\/tmp-preds' + '\/' + df_blend_.loc['file_name', c] # Only for Kaggle\n        df_train_.append(load_prediction(full_file_name + suffix_train))\n        df_test_.append(load_prediction(full_file_name + suffix_test))\n        \n    df_train_ = pd.concat(df_train_, axis = 1)\n    df_train_.columns = df_blend_.columns\n    df_test_ = pd.concat(df_test_, axis = 1)\n    df_test_.columns = df_blend_.columns\n\n    return df_train_, df_test_, df_blend_","bf189fb7":"# For blending flagged predictions\ndef get_blended_prediction(df_train_, flag, params_):\n    warnings.simplefilter('ignore')\n    \n    test_pred_proba = pd.Series(np.zeros(df_train_.shape[0]), index = df_train_.index)\n    \n    for f in df_train_.columns[flag.values.astype(bool)]:\n        test_pred_proba += df_train_[f] * params_[f]\n        \n    min_pr = test_pred_proba.min()\n    max_pr = test_pred_proba.max()\n    test_pred_proba = (test_pred_proba - min_pr) \/ (max_pr - min_pr)\n    return test_pred_proba","3240960e":"# For selection of parameters with Bayesian optimization\ndef get_best_params_for_blending(df_train_, flag, target, seed_bo_, init_points = 10, n_iter = 10):\n    def blend_auc_evaluate(**params):\n        return roc_auc_score(target, get_blended_prediction(df_train_, flag, params))    \n    \n    params = {}\n    for c in df_train_.columns[flag.values.astype(bool)]:\n        params[c] = (0, 1)\n\n    bo = BayesianOptimization(blend_auc_evaluate, params, random_state = seed_bo_)\n    bo.maximize(init_points = init_points, n_iter = n_iter)\n\n    return bo.res['max']['max_val'], bo.res['max']['max_params']","9c25da3a":"from sklearn.preprocessing import LabelEncoder","38d65ea7":"df_train = pd.read_csv('..\/input\/home-credit-default-risk\/application_train.csv')\ndf_test = pd.read_csv('..\/input\/home-credit-default-risk\/application_test.csv')\nprint('Train shape: {}, test shape: {}'.format(df_train.shape, df_test.shape))","6e4fc9c2":"df_all = pd.concat([df_train, df_test], axis = 0, ignore_index = True)\nprint('\u0421ombined shape: {}'.format(df_all.shape))","43a885ec":"train_index = df_all[df_all['TARGET'].notnull()].index\ntest_index = df_all[df_all['TARGET'].isnull()].index\nprint('Train shape: {}, test shape: {}'.format(df_all.loc[train_index].shape, df_all.loc[test_index].shape))","4154d51d":"del df_train, df_test\ngc.collect()","bbce9228":"le = LabelEncoder()\ncategorical = df_all.columns[df_all.dtypes == 'object']\nprint('{} categorical features were'.format(len(categorical)))\nfor c in categorical:\n    df_all[c].fillna('NaN', inplace = True)\n    df_all[c] = le.fit_transform(df_all[c])\nprint('{} categorical features left'.format(len(df_all.columns[df_all.dtypes == 'object'])))","d9ff1616":"df_all = reduce_mem_usage(df_all)","85e9144e":"missing_values = get_missing_report(df_all)\nmissing_values.sort_values('ratio_missing_train', ascending = False) \\\n                                    [['ratio_missing_train', 'ratio_missing_test']].plot(figsize = (25, 7));","7ff1c48c":"missing_values[abs(missing_values['ratio_missing_train'] - missing_values['ratio_missing_test']) > .1]","174789d2":"corr_target = pd.DataFrame(index = ['diff', 'p'])\nfor c in df_all.columns.drop('TARGET'):\n    corr_target[c] = corr_feature_with_target(df_all.loc[train_index, c], df_all.loc[train_index, 'TARGET'])\ncorr_target = corr_target.T","1d3b70a3":"bad_features = corr_target[(corr_target['diff'] < 1e-5) & (corr_target['p'] > .05)].index\nprint('There are {} uninformative features'.format(len(bad_features)))","cab8dd65":"bad_features","5177a27f":"df_all.drop(bad_features, axis = 1, inplace = True)\ndf_all.shape","151b8c2f":"target_test = (df_all['TARGET'].notnull()).astype(int)","3eaaf217":"corr_test = pd.DataFrame(index = ['diff', 'p'])\nfor c in df_all.columns.drop('TARGET'):\n    corr_test[c] = corr_feature_with_target(df_all[c], target_test)\ncorr_test = corr_test.T","747922f5":"bad_features = corr_test[(corr_test['diff'] > 1) & (corr_test['p'] < .05)].index\nprint('There are {} features with different distribution on the train and test sets'.format(len(bad_features)))","bdce16b5":"bad_features","981b03cb":"df_all.drop(bad_features, axis = 1, inplace = True)\ndf_all.shape","0d827e9a":"feature_importance = plot_roc_curves(df_all.loc[train_index], 'TARGET', random_state = 0)","2befe083":"feature_importance.head()","43a66d70":"display_feature_importances(feature_importance)","59957671":"step = 'first_prediction'","03ee8ad3":"seed_cv = 0","cf446b79":"score_table = pd.DataFrame(index = scores_index)","834eb6af":"f_importance, pred_train, pred_test, score = cv_lgbm_scores(df_all, \n                                                            num_folds = 5, params = {'random_state': seed_cv}, \n                                                            rs = seed_cv)","f5474073":"display_feature_importances(f_importance)","6d92de91":"#save_prediction(pred_test, 'pred_' + step + suffix_test) # Commented for Kaggle","aac8c948":"score[-1] = .745\nscore_table[step] = score\nscore_table.T","f1884895":"#store_predictions_for_blending(pred_train, pred_test, step, score, # Commented for Kaggle\n#                               comments = 'The first prediction without tuning')","9967ad14":"step = 'bo_seed_0'","cb4634f7":"seed_bo = 0","0d1537a1":"best_score, best_params = get_best_params_for_lgbm(df_all.loc[train_index], seed_cv, seed_bo)","4b54ad31":"print('Best score:', best_score)\nprint('Best params:', best_params)","452fc112":"f_importance, pred_train, pred_test, score = cv_lgbm_scores(df_all, \n                                                            num_folds = 5, params = best_params, \n                                                            rs = seed_cv)","63000e58":"#save_prediction(pred_test, 'pred_' + step + suffix_test) # Commented for Kaggle","b5af0520":"score[-1] = .748\nscore_table[step] = score\nscore_table.T","a8d7d059":"display_scores(score_table)","96e0797c":"#store_predictions_for_blending(pred_train, pred_test, step, score, # Commented for Kaggle\n#                               comments = 'Best params for LGBM (seed_bo = 0)')","e080cf88":"df_train, df_test, df_blending = load_predictions_for_blending()\ndf_blending.T","51c0eb8d":"df_train.head()","80549e8a":"df_test.head()","17621424":"best_score, best_params = get_best_params_for_blending(df_train, df_blending.loc['to_blend'], \n                                                       df_all.loc[train_index, 'TARGET'], seed_bo)","bf085b63":"print('Best score:', best_score)\nprint('Best params:', best_params)","391faa6d":"pred = get_blended_prediction(df_test, df_blending.loc['to_blend'], best_params)\npred.head()","d6c0bd54":"#save_prediction(pred.reset_index(), 'final.csv') # Commented for Kaggle","6b76ce7f":"To drop `EXT_SOURCE_1` feature if it's not usefull in next explorations","f6603941":"The most interesting model is LGBM with the first draft score .757. \n\nThe least interesting one is KNearest.","d92e33fd":"## For blending predictions","622abff3":"### Blending predictions","2e9c78e9":"## For cross-validation","07a04502":"### Exploring correlation of features between the train set and target","0f418546":"You can select the best seed for Bayesian Optimization and for CV. I cannot do it in this example.","41cf7e03":"### Convert categorical features\n\nOnly Label encoding for this example","c5cb06c6":"### Calculating the first metrics without Bayesian Optimization","88777ed8":"### Loading datasets","7515dba0":"# Example of baseline","d670733e":"### Exploring missing values","f66ccdbc":"This is just an example!","3bc59bff":"### Selection the best classic model for this dataset","ebb28ef8":"### Exploring correlation of features between the train and test sets","12f36c98":"# A collection of useful (for me) functions","ace0f4a4":"To submit `pred_test` prediction and manually add real LB score in the next cell.","bb76f65c":"### Calculating the metrics with Bayesian Optimization (initial seeds)","0e3d9f0b":"## For EDA","9f1991b4":"This is a collection of scripts which can be useful for this and next competitions, as I think.\n\nThere is an example of baseline at the end of this notebook.","e0efae4a":"## Service functions"}}