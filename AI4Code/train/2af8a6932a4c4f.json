{"cell_type":{"a696ee9a":"code","9cf31730":"code","e184a001":"code","e8771a29":"code","8a290708":"code","c990d415":"code","a0c1eac7":"code","f5dda9dd":"code","62d622db":"code","069d5bf3":"code","b8f8e735":"code","e6158af4":"code","6a487435":"code","a84ae615":"code","94ffd624":"code","86d96ef8":"code","ce9ffb97":"code","cc4dfbb2":"code","d2e92220":"code","77221c0f":"code","41ce63a4":"code","d8513744":"code","ca578c66":"code","1b960423":"code","3275ded5":"code","5d57cf48":"code","f3661908":"code","d1263330":"code","76ec63ed":"code","81570c6c":"code","3ced391d":"code","fe33b1dd":"code","9c331160":"markdown","b32c5d1d":"markdown"},"source":{"a696ee9a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cf31730":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","e184a001":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e8771a29":"df = pd.read_csv('\/kaggle\/input\/chronic-kidney-disease\/kidney_disease_train.csv')\ndf.head()","8a290708":"df.info()","c990d415":"missing_values = (df.isnull().sum()\/len(df)) * 100                  # Visualization of missing values in the dataset\nmissing_values.sort_values(ascending=False,inplace=True)\nplt.barh(y=missing_values.index,width= missing_values.values)","a0c1eac7":"df['classification'].replace({'ckd':1,'notckd':0},inplace=True) # replace classification with numbers","f5dda9dd":"df.select_dtypes('object').nunique()  # drop object columns  wc,rc,dm,cad many unique values","62d622db":"df.drop(columns=['wc','rc','dm','cad','id'],inplace=True)","069d5bf3":"df.head()","b8f8e735":"dummies = list(df.select_dtypes('object').columns) # create dummies and drop drop_first !\ndummies","e6158af4":"df = pd.get_dummies(df,columns=dummies)\ndf.head()","6a487435":"correlation = abs(df.corr().sort_values(by='classification')['classification']) # check correlation of features with  \"classification2\ncorrelation","a84ae615":"select = list(correlation[correlation > 0.3].index) # select features with correlation higher then 0.3\nselect","94ffd624":"df[select].isnull().sum() # check missing values","86d96ef8":"df.dropna(how='any',inplace=True)  #  drop all rows with nan, keep it easy without any imputation","ce9ffb97":"X = df.drop(columns='classification')    # Split label and datsets\ny = df['classification']","cc4dfbb2":"X","d2e92220":"from sklearn.model_selection import train_test_split    \nfrom sklearn.preprocessing import MinMaxScaler","77221c0f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","41ce63a4":"scaler = MinMaxScaler()","d8513744":"X_train = scaler.fit_transform(X_train)\nX_test  = scaler.transform(X_test)","ca578c66":"import tensorflow as tf\nfrom  tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Dense,Activation,Dropout\nfrom tensorflow.keras.constraints import max_norm","1b960423":"model = Sequential()\n\nmodel.add(Dense(28,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(14,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(6,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(3,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.add(Dropout(0.2))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam')","3275ded5":"from tensorflow.keras.callbacks import EarlyStopping  ","5d57cf48":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)","f3661908":"model.fit(x=X_train, \n          y=y_train,\n          epochs=2000,\n          validation_data=(X_test, y_test), verbose=1,\n          callbacks=[early_stop]\n          )","d1263330":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","76ec63ed":"predictions = model.predict_classes(X_test)","81570c6c":"from sklearn.metrics import classification_report,confusion_matrix","3ced391d":"print(classification_report(y_test,predictions))  # 100 % ist not possible, what is wrong ?","fe33b1dd":"print(confusion_matrix(y_test,predictions))     #  confusion matrix","9c331160":"### Split in train and test, normalization","b32c5d1d":"## model selection"}}