{"cell_type":{"c843fbc7":"code","dc0d5142":"code","50b0beb3":"code","f8a25e73":"code","4be156d9":"code","d6e01d04":"code","daef4463":"code","463dcbee":"code","9c01dcd1":"code","441902d3":"code","fa94c85d":"code","7b825263":"code","b62d76dc":"code","ea193238":"code","48d41659":"code","89b1c0b6":"code","311b409c":"code","715a276e":"code","aa3d93ee":"code","f9dfbb5d":"code","5452ae92":"code","68dfb02b":"code","6cc59ec7":"code","c9511c07":"code","1e8f2f5a":"code","e573f005":"code","4374e237":"code","df7f27ea":"code","5569e2f7":"code","f9084f8c":"code","d7d2bd47":"code","5c60060b":"code","b65c0b3a":"code","655deba5":"code","c5bfdabf":"code","817600c7":"code","f4c5307d":"code","9541b788":"code","659fc88e":"code","7da72a95":"code","5f96025f":"code","99b3075e":"code","27dfab38":"code","8068ac66":"code","6e236ead":"code","3cf8ccff":"code","47b56680":"code","d4b7b21b":"code","1f025900":"code","ee699a8a":"code","08aa586d":"code","26510e57":"markdown","7d8b1f45":"markdown","777dc5b8":"markdown","2cf765d8":"markdown","3d7f162c":"markdown","14c49f90":"markdown","22e8116b":"markdown","8cb43b4f":"markdown","f71018ae":"markdown","1a409ed2":"markdown","0a067aea":"markdown","e420c1bf":"markdown","7e29b5c2":"markdown","cf339703":"markdown"},"source":{"c843fbc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc0d5142":"import seaborn as sns\nimport  matplotlib\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport numpy as np","50b0beb3":"#importing datasets\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ncombine=[train_df,test_df]","f8a25e73":"train_df.head()","4be156d9":"train_df.tail()","d6e01d04":"train_df.info()","daef4463":"test_df.info()","463dcbee":"train_df.isna().sum()","9c01dcd1":"train_df.describe()","441902d3":" sum(train_df.filter(items=['Fare','Ticket']).duplicated())","fa94c85d":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","7b825263":"train_df[['Sex','Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived',ascending=False)","b62d76dc":"train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ea193238":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","48d41659":"#Analyse by visualizing data","89b1c0b6":"g= sns.FacetGrid(train_df,col=\"Survived\")\ng.map(plt.hist, \"Age\",bins=20)","311b409c":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","715a276e":"grid=sns.FacetGrid(train_df, row=\"Embarked\", size=2.2, aspect=1.6)\ngrid.map(sns.pointplot,\"Pclass\",'Survived',\"Sex\",palette='deep')\ngrid.add_legend()","aa3d93ee":"#checking for correlation in the data\nplt.rcParams[\"figure.figsize\"]=(10,8)\ncorrMatrix=train_df.corr()\n\nsns.heatmap(corrMatrix,cmap=\"rocket\",annot=True)","f9dfbb5d":"#Ticket and Cabin has no correlation with survival and they have lots of missing values so we will drop them","5452ae92":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","68dfb02b":"#creating new features extracting from original","6cc59ec7":"for dataset in combine:\n    dataset['Title']=dataset.Name.str.extract(' ([A-Za-z]+)\\.',expand=False)\npd.crosstab(train_df[\"Title\"],train_df[\"Sex\"]  )                                           ","c9511c07":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","1e8f2f5a":"#we will convert the categorical title into ordinal and fill missing values\n\ntitle_mapping={'Mr':1,'Miss':2,'Mrs': 3,'Master': 4,\"Rare\": 5}\n\nfor dataset in combine:\n    dataset['Title']=  dataset['Title'].map(title_mapping)\n    dataset['Title']= dataset['Title'].fillna(0)\n    \ntrain_df.head()","e573f005":"#lets visualize this\ng= sns.FacetGrid(train_df,col=\"Survived\")\ng.map(plt.hist, \"Title\",bins=5)","4374e237":"#we are going to drop 'Name' and 'PassengerId' since they have no correlation with Survived\n\n\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","df7f27ea":"#converting sex to a numerical values with female=1 and male=0\n\nfor dataset in combine:\n    dataset['Sex']=dataset['Sex'].map({\"female\":1,\"male\":0}).astype(int)\ntrain_df.head()    ","5569e2f7":"grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","f9084f8c":"#first we create an empty array to contain guessed age values based on Pclass and gender\n\nguess_ages = np.zeros((2,3))\nguess_ages","d7d2bd47":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","5c60060b":"#Let us create Age bands and determine correlations with Survived.\n\ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","b65c0b3a":"#Let us replace Age with ordinals based on these bands.\n\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","655deba5":"#We can now remove the AgeBand feature.\n\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","c5bfdabf":"#Create new feature combining existing features\n#We can create a new feature for FamilySize which combines Parch and SibSp. This will enable us to drop Parch and SibSp from our datasets.\n\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","817600c7":"#We  create another feature called IsAlone.\n\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","f4c5307d":"\n#we will now drop Parch, SibSp, and FamilySize features in favor of IsAlone.\n\ntrain_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","9541b788":"#We can also create an artificial feature combining Pclass and Age.\n\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","659fc88e":"freq_port= train_df.Embarked.dropna()[0]\nfreq_port","7da72a95":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","5f96025f":"#We have to convert the Embarked features to numerical values\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","99b3075e":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","27dfab38":"train_df['FareBand'] = pd.cut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","8068ac66":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","6e236ead":"test_df.head(10)","3cf8ccff":"#This is a supervised form of machine leaening and it is both classification and regression and for this i will be making use of Rnadom forest since it \n#has the highest confidence score after evaluation with other models","47b56680":"from sklearn.ensemble import RandomForestClassifier","d4b7b21b":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","1f025900":"\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","ee699a8a":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred})","08aa586d":" submission.to_csv('submission.csv', index=False)","26510e57":"\n#1.\tAge, Embarked, Cabin has missing values. 177,2 and 687 Respectively\n#2.\tAge, Fare and Cabin are incomplete in the test set\n#3.\tMost passengers did not travel with parent or  Children\n#4.\tTicket,Cabin feature has no correlation with survival\n#5.\tWomen and children were more likely to survive\n#6.\tThe upper class(Pclass=1) were more likely to have survived\n#7.\tThose who had more siblings or spouse onboard were less likely to have survived.\n#8.\tMost passengers are between 15-35 years\n#9.\tOldest passengers survived.\n#10.3rd class male passengers that embarked from port Q were more likely to have survived.\n","7d8b1f45":"checking for missing Values","777dc5b8":"Now we iterate over Sex (0 or 1) and Pclass (1, 2, 3) to calculate guessed values of Age for the six combinations.","2cf765d8":"we have to complete the missing values in fare feature for the test dataset","3d7f162c":"filling the missing values in Embarked with the mode","14c49f90":"we will now create a fareband","22e8116b":"**ANALYZING BY PIVOTING FEATURES**","8cb43b4f":"****Analysing by describing the data","f71018ae":"**Assumptions\/Observations**","1a409ed2":"\n**Filling missing values in Age feature using correlation with other features**\n\n\n\n","0a067aea":"# **Model and Predict***","e420c1bf":"Importing Necessary Libraries","7e29b5c2":"# Wrangling the data","cf339703":"**We will extract the Title from the Name feature to see their correlation with Survived**"}}