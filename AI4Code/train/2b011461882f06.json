{"cell_type":{"7a332b4d":"code","c3b2aa56":"code","6c691b6c":"code","ddb5c05e":"code","369ce22e":"code","88d7dd31":"code","94ec0c34":"code","e97fe647":"code","7a6c6b6f":"code","226f853f":"code","331d0e16":"code","a3e1728d":"code","78549722":"code","f2b40289":"code","acea8d62":"code","eb0af485":"code","3dee921d":"code","adc55d34":"code","22aca449":"code","ece9862f":"code","371c416a":"code","a3ed896d":"code","de62c41a":"code","8f6c8e0b":"code","694c2779":"code","25e5caa0":"code","d219bccb":"code","2dab6bec":"code","0cfcc167":"code","59cbf350":"code","ea347bcf":"code","c2d84b34":"code","90fa540f":"code","556d5cda":"code","c5e50351":"code","576a8ac8":"code","8f38bbb3":"code","afa912ff":"code","a81d177c":"code","089d0a92":"code","7b2055a8":"code","ecf938f6":"code","d67194d6":"code","cbb2afac":"code","a28c536a":"code","725f146b":"code","b64046ce":"code","a59702ec":"code","319b4d57":"code","9021d438":"code","80939d40":"code","b5bb90b9":"markdown","74ada860":"markdown","c0bb1969":"markdown","76384d7b":"markdown","4c413866":"markdown","796e4677":"markdown","2d8364e9":"markdown","a0675c8a":"markdown","4ed5ed30":"markdown","7fb97b8d":"markdown","68b254e0":"markdown","74d7d6b0":"markdown","92d5c309":"markdown","f8a8ce9a":"markdown","4cea16c0":"markdown","4f3a2dbd":"markdown","1f3b2d79":"markdown","60193aff":"markdown","26c87a7e":"markdown","8e1f5fcf":"markdown","9f68ba9b":"markdown","e48b9fb6":"markdown","302fd4a5":"markdown","eb5c03a7":"markdown","ae386813":"markdown","736734b2":"markdown","5b838d6f":"markdown","c88a5202":"markdown","85fc75c1":"markdown","d2c10419":"markdown","52725a77":"markdown","a8cd1507":"markdown","dc7408c2":"markdown"},"source":{"7a332b4d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set(style='white',context='notebook',palette='muted')\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c3b2aa56":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","6c691b6c":"print(train_data.info())","ddb5c05e":"print(test_data.info())","369ce22e":"full_data =train_data.append(test_data, ignore_index=True)\nfull_data.describe()","88d7dd31":"full_data.info()","94ec0c34":"plt.figure(figsize=(14, 6))\nplt.title(\"Distribution of Survival Result\")\nsns.countplot(x=train_data['Survived'])\nplt.show()\n\ntrain_data['Survived'].value_counts()","e97fe647":"# Pclass\nplt.figure(figsize=(14, 6))\nplt.title(\"Distribution of Passenger Class\")\nsns.countplot(x=train_data['Pclass'])\nplt.show()\n\ntrain_data['Pclass'].value_counts()","7a6c6b6f":"# Sex\nplt.figure(figsize=(14, 6))\nplt.title(\"Distribution of Passengers' Genders\")\nsns.countplot(x=train_data['Sex'])\nplt.show()\n\ntrain_data['Sex'].value_counts()","226f853f":"# Age\nplt.figure(figsize=(14, 6))\nplt.title(\"Distribution of Passengers' Ages\")\nsns.distplot(a=train_data['Age'], kde=False)\nplt.show()\n\ntrain_data['Age'].describe()","331d0e16":"# sibsp\n\nplt.figure(figsize=(14, 6))\nplt.title(\"Distribution of Passengers' number of siblings onboard\")\nsns.countplot(x=train_data['SibSp'])\nplt.show()\n\ntrain_data['SibSp'].value_counts()","a3e1728d":"# parch\nplt.figure(figsize=(14, 6))\nplt.title(\"Distribution of Passengers' number of parents and children onboard\")\nsns.countplot(x=train_data['Parch'])\nplt.show()\n\ntrain_data['Parch'].value_counts()","78549722":"# Embark\nplt.figure(figsize=(14, 6))\nplt.title(\"Distribution of Passengers' Embared location\")\nsns.countplot(x=train_data['Embarked'])\nplt.show()\n\ntrain_data['Embarked'].value_counts()","f2b40289":"# Pclass\n\nplt.figure(figsize=(14, 6))\nplt.title(\"Passenger Class vs. Survival Outcome\")\nsns.barplot(x=train_data['Pclass'], y=train_data['Survived'])\nplt.show()\n\nprint( train_data[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean() )","acea8d62":"# Sex\n\nplt.figure(figsize=(14, 6))\nplt.title(\"Passenger Gender vs. Survival Outcome\")\nsns.barplot(x=train_data['Sex'], y=train_data['Survived'])\nplt.show()\n\nprint( train_data[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean() )","eb0af485":"# Age\n\nageFacet=sns.FacetGrid(train_data,hue='Survived',aspect=3)\n\nageFacet.map(sns.kdeplot,'Age',shade=True)\n\nageFacet.set(xlim=(0,train_data['Age'].max()))\nageFacet.add_legend()","3dee921d":"# Parch\n\nplt.figure(figsize=(14, 6))\nplt.title(\"Number of Parents and Children vs. Survive Outcome\")\nsns.barplot(x=train_data['Parch'], y=train_data['Survived'])\nplt.show()\n\nfor num in train_data['Parch'].dropna().unique():\n    if (num == 4) or (num == 6):\n        print(f\"No info for {num} relatives\")\n    else:\n        print(f\"Survival rate if having {num} relatives: \", train_data['Survived'][train_data['Parch']==num].value_counts(normalize=True)[1])","adc55d34":"# SibSp\n\nplt.figure(figsize=(14, 6))\nplt.title(\"Number of Siblings and Spouses vs. Survive Outcome\")\nsns.barplot(x=train_data['SibSp'], y=train_data['Survived'])\nplt.show()\n\nfor num in train_data['SibSp'].dropna().unique():\n    if (num == 5) or (num == 8):\n        print(f\"No info for {num} siblings and spouses\")\n    else:\n        print(f\"Survival rate if having {num} relatives: \", train_data['Survived'][train_data['SibSp']==num].value_counts(normalize=True)[1])","22aca449":"# Embarked\n\nplt.figure(figsize=(14, 6))\nplt.title(\"Number of Parents and Children vs. Survive Outcome\")\nsns.barplot(x=train_data['Embarked'], y=train_data['Survived'])\nplt.show()\n\nfor location in train_data['Embarked'].dropna().unique():\n    print(f\"Survival rate if embarked from {location}: \", train_data['Survived'][train_data['Embarked']==location].value_counts(normalize=True)[1])","ece9862f":"# Fare\n\nageFacet=sns.FacetGrid(train_data,hue='Survived',aspect=3)\nageFacet.map(sns.kdeplot,'Fare',shade=True)\nageFacet.set(xlim=(0,150))\nageFacet.add_legend()\n\nfarePlot=sns.distplot(full_data['Fare'][full_data['Fare'].notnull()],label='skewness:%.2f'%(full_data['Fare'].skew()))\nfarePlot.legend(loc='best')","371c416a":"full_data['Fare']=full_data['Fare'].map(lambda x: np.log(x) if x>0 else 0)","a3ed896d":"full_data['Cabin'] = full_data['Cabin'].fillna('Unkown')\nfull_data['Cabin'].head()","de62c41a":"full_data[full_data['Embarked'].isnull()]","8f6c8e0b":"full_data['Embarked'].value_counts()","694c2779":"full_data['Embarked']=full_data['Embarked'].fillna('S')","25e5caa0":"full_data[full_data['Fare'].isnull()]","d219bccb":"full_data['Fare'] = full_data['Fare'].fillna(full_data[(full_data['Pclass']==3)&(full_data['Embarked']=='S')&(full_data['Cabin']=='U')]['Fare'].mean()) ","2dab6bec":"full_data['Title']=full_data['Name'].map(lambda x:x.split(',')[1].split('.')[0].strip())\n\nfull_data['Title'].value_counts()","0cfcc167":"# Group similar titles together\n\nTitleDict={}\nTitleDict['Mr']='Mr'\nTitleDict['Mlle']='Miss'\nTitleDict['Miss']='Miss'\nTitleDict['Master']='Master'\nTitleDict['Jonkheer']='Master'\nTitleDict['Mme']='Mrs'\nTitleDict['Ms']='Mrs'\nTitleDict['Mrs']='Mrs'\nTitleDict['Don']='Royalty'\nTitleDict['Sir']='Royalty'\nTitleDict['the Countess']='Royalty'\nTitleDict['Dona']='Royalty'\nTitleDict['Lady']='Royalty'\nTitleDict['Capt']='Officer'\nTitleDict['Col']='Officer'\nTitleDict['Major']='Officer'\nTitleDict['Dr']='Officer'\nTitleDict['Rev']='Officer'\n\nfull_data['Title']=full_data['Title'].map(TitleDict)\nfull_data['Title'].value_counts()","59cbf350":"sns.barplot(data=full_data,x='Title',y='Survived')","ea347bcf":"full_data['Family'] = full_data['SibSp'] + full_data['Parch'] + 1\n\nsns.barplot(data=full_data,x='Family',y='Survived')","c2d84b34":"def familysize(familyNum):\n    if familyNum == 1:\n        return 0\n    elif (familyNum>=2) & (familyNum<=4):\n        return 1\n    else:\n        return 2\n\nfull_data['familySize'] = full_data['Family'].map(familysize)\nsns.barplot(data=full_data,x='familySize',y='Survived')\nfull_data['familySize'].value_counts()","90fa540f":"full_data['Deck'] = full_data['Cabin'].map(lambda x:x[0])\n\nsns.barplot(data=full_data,x='Deck',y='Survived')","556d5cda":"TickCountDict = {}\nTickCountDict = full_data['Ticket'].value_counts()\nTickCountDict.head()","c5e50351":"full_data['TickGroup'] = full_data['Ticket'].map(TickCountDict)\nfull_data['TickGroup'].head()","576a8ac8":"sns.barplot(data=full_data,x='TickGroup',y='Survived')","8f38bbb3":"def TickCountGroup(num):\n    if (num>=2) & (num<=4):\n        return 1\n    elif (num==1)|((num>=5)&(num<=8)):\n        return 0\n    else :\n        return 2\n\nfull_data['TickCate']=full_data['TickGroup'].map(TickCountGroup)\n\nsns.barplot(data=full_data,x='TickCate',y='Survived')","afa912ff":"AgePre = full_data[['Age','Parch','Pclass','SibSp','Title','familySize','TickGroup']]\n\nAgePre = pd.get_dummies(AgePre)\nParAge = pd.get_dummies(AgePre['Parch'],prefix='Parch')\nSibAge = pd.get_dummies(AgePre['SibSp'],prefix='SibSp')\nPclAge = pd.get_dummies(AgePre['Pclass'],prefix='Pclass')\n\nAgeCorrDf = pd.DataFrame()\nAgeCorrDf = AgePre.corr()\nAgeCorrDf['Age'].sort_values()","a81d177c":"AgePre = pd.concat([AgePre,ParAge,SibAge,PclAge],axis=1)\nAgePre.head()","089d0a92":"Age_train = AgePre[AgePre['Age'].notnull()]\nAge_test = AgePre[AgePre['Age'].isnull()]\n\nAgeKnown_X = Age_train.drop(['Age'],axis=1)\nAgeKnown_Y = Age_train['Age']","7b2055a8":"Age_X_test = Age_test.drop(['Age'],axis=1)","ecf938f6":"from sklearn.ensemble import RandomForestRegressor\n\nrfr=RandomForestRegressor(random_state=None,n_estimators=500,n_jobs=-1)\nrfr.fit(AgeKnown_X,AgeKnown_Y)\n\nprint(rfr.score(AgeKnown_X,AgeKnown_Y))","d67194d6":"AgeUnKnown_Y = rfr.predict(Age_X_test)\n\nfull_data.loc[full_data['Age'].isnull(),['Age']] = AgeUnKnown_Y\nfull_data.info()","cbb2afac":"fullSel = full_data.drop(['Cabin','Name','Ticket','PassengerId'],axis=1)\n\ncorrDf = pd.DataFrame()\ncorrDf = fullSel.corr()\ncorrDf['Survived'].sort_values(ascending=True)","a28c536a":"plt.figure(figsize=(8,8))\nsns.heatmap(fullSel[['Survived','Age','Embarked','Fare','Parch','Pclass',\n                    'Sex','SibSp','Title','Family','familySize','Deck',\n                     'TickGroup','TickCate']].corr(),cmap='BrBG',annot=True,\n           linewidths=.5)\nplt.xticks(rotation=45)","725f146b":"fullSel = fullSel.drop(['Family','SibSp','TickGroup','Parch'],axis=1)\n\nfullSel = pd.get_dummies(fullSel)\nPclassDf = pd.get_dummies(full_data['Pclass'],prefix='Pclass')\nTickGroupDf = pd.get_dummies(full_data['TickGroup'],prefix='TickGroup')\nfamilySizeDf = pd.get_dummies(full_data['familySize'],prefix='familySize')\n\nfullSel=pd.concat([fullSel,PclassDf,TickGroupDf,familySizeDf],axis=1)","b64046ce":"from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV,cross_val_score,StratifiedKFold\n\nkfold = StratifiedKFold(n_splits=10)\n\nexperData = fullSel[fullSel['Survived'].notnull()]\npreData = fullSel[fullSel['Survived'].isnull()]\n\nexperData_X = experData.drop('Survived',axis=1)\nexperData_y = experData['Survived']\npreData_X = preData.drop('Survived',axis=1)\n\nmodelLR = LogisticRegression()\nLR_param_grid = {'C' : [1,2,3],\n                'penalty':['l1','l2']}\nmodelgsLR = GridSearchCV(modelLR,param_grid = LR_param_grid, cv=kfold, \n                                     scoring=\"accuracy\", n_jobs= -1, verbose = 1)\nmodelgsLR.fit(experData_X,experData_y)","a59702ec":"print(\"Accuracy: \", modelgsLR.best_score_)","319b4d57":"GBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\nmodelgsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, \n                                     scoring=\"accuracy\", n_jobs= -1, verbose = 1)\nmodelgsGBC.fit(experData_X,experData_y)","9021d438":"print('Accuracy: ', modelgsGBC.best_score_)","80939d40":"GBCpreData_y=modelgsGBC.predict(preData_X)\nGBCpreData_y=GBCpreData_y.astype(int)\n\nGBCpreResultDf=pd.DataFrame()\nGBCpreResultDf['PassengerId']=full_data['PassengerId'][full_data['Survived'].isnull()]\nGBCpreResultDf['Survived']=GBCpreData_y\nGBCpreResultDf\n\nGBCpreResultDf.to_csv('submission.csv',index=False)","b5bb90b9":"The above graph shows that if the passenger has a deck letter of E, D, or B, the chance to survive is higher. On the other hand, if the passenger has a deck letter of U, the chance is pretty low.","74ada860":"3. Age\n\nFor this variable, I made two curves to show the distribution of age of passengers who survived and who did not. The two graphs seem to be pretty similar to each other. One thing I notice that is particularly interesting is that more kids below age of 10 seemed to have survived from titanic, as the brown curve is higher when age is below 10. This is also something we want to keep in mind.","c0bb1969":"# Data Preprocessing\n\nSo we just visualized most of our data. The next step would be to proprocess our data in order to select features to train our model. Data Preprocessing essentially have four components: Data Cleaning, Feature Engineering, Cluster Recognition, and Feature Selection\n","76384d7b":"2.4 Ticket Group:\n\nPassengers with the same ticket number may belong to the same group, so we can also create a new column of TickGroup to classify passengers. ","4c413866":"**2. Univariate Analysis for Other Parameters**\n\nNow we have taked a look at Survived category. Let's visualize other columns in the training data. In the titanic dataset, there are nine other variables besides Survived. They are:\n* pclass: the Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n\n* sex:\t             Sex of the passenger\n\n* Age:\t             Age in years of the passenger (Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5)\n\n* sibsp:\t         # of siblings \/ spouses the passenger had that were also aboard the Titanic (Sibling = brother, sister, stepbrother, stepsister, Spouse = husband, wife)\n\n* parch:             # of parents \/ children the passenger had that were also aboard the Titanic (Parent = mother, father, Child = daughter, son, stepdaughter, stepson, Some children travelled only with a nanny, therefore parch=0 for them.)\n\n* ticket:            Ticket number\t\n\n* fare:              Passenger fare\t\n\n* cabin:             Cabin number\t\n\n* embarked:          Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n\nNow we may want to plot graphs to visualize these variables too. (Since ticket number and cabin number are not suitable for analysis we will not visualize them)","796e4677":"2. Sex\n\nThis graph shows that there is a very strong association between passenger's chance of survival and passenger's gender. In fact, the average chance of survival for female passengers is 74.2% and only 18.9% for male passengers! This may also explain why if we just predict all female passengers survived will give us a not bad prediction score. Anyway, we can conclude that gender is definitely an important feature when predicting whether a passenger will survive. ","2d8364e9":"# Visualization of Data\n\n","a0675c8a":"The above shows that in train data, there are 891 rows of passenger information, and in the test data, there are 418 rows of passenger information. Also comparing to the test data, the train data contains one more column of information, which is whether the passenger survived or not. ","4ed5ed30":"2. Feature Engineering: Create new features based on existing variables to extract useful information from data","7fb97b8d":"2.2 Family Size:\n\nthe family size can be reflected by SibSp + Parch + 1 where the '1' refers to that particular passenger","68b254e0":"# Hello Everyone!\nthis is my first time writing a Kaggle notebook discussing about how I analyze this dataset. \n\nSo first of all, let's load the datasets and take a look at the training data.\n","74d7d6b0":"3. Feature Selection\n\nIn this dataset the dimension of data is too high. We want to select only the features that are highly correlated with the Survived column in order to reduce the dimension of our model. ","92d5c309":"Passengers with the title \"Mr.\" shows a significantly low survival rate","f8a8ce9a":"This shows that when the group size is about average, the chance to survive is higher, which also follows our previous conclusions. We can further applied the stragety for family size and cluster these groups again.","4cea16c0":"So we can see that among all data, there are missing values in **Age**, **Fare**, **Cabin**, and **Embarked** categories. In fact for **Cabin** category, there are only 295 rows containing information out of the 1309 total rows. These should be something we keep in mind while doing our analysis. ","4f3a2dbd":"Embarked: Since most passengers embarked from Southampton, we will just replace the two missing values in Embarked with S.","1f3b2d79":"Because the above graph shows that the distribution for **Fare** category is strongly right-skewed, we apply log transformation on it","60193aff":"We have just visualized most of the columns in training data, and in fact we can now already make some easy observations for each category:\n* Passenger Class: Most of the passengers resided in the third class; only some are in the first two classes\n* Sex:             There are more male passengers than there are female passengers\n* Age:             The distribution seem to be slightly right-skewed and with a median at 28. There are kids who are not even 1 year old and elders who are 80 years old.\n* SibSp:           Most passengers have no siblings with them, and the number of siblings decreases exponentially\n* Parch:           Most passengers have no parents or children with them, and the number of siblings decreases exponentially.\n* Embarked:        Most passengers embarked from Southampton, then Cherbourg; Queenstown has the least number of passengers.","26c87a7e":"**1. Univariate Analysis for Survived Parameter:**\n\nThe category that we are interested in this dataset is 'Survived'. Thus we may want to first visualize what is the distribution of this column. Because \"Survived\" is a categorical variable and is consisted of 0 and 1. I used a seaborn countplot to visualize it. Count plots show the counts of observations in each categorical bin using bars and can be essentially treated as a histogram for a categorical variable. \n\nFrom the graph, it is clearly that there were more people who died than people who survived, which follows our intuition that the titanic disaster caused many people to die. We can further get the exact number of survivals and deaths using .value_counts()","8e1f5fcf":"1. Data Cleaning: Handle missing\/abnormal values\n\nSo in this dataset, there are four columns that contain missing data - Age, Fare, Cabin, and Embarked. Let's first clean the missing values. ","9f68ba9b":"6. Embarked\n\nThis graph shows that passengers who embarked from Cherbourg seem to have a sligherly higher chance to survive. ","e48b9fb6":"4. Parch\n\nFor this variable, this is not really a clear trend. However, it can be argued that when the passenger has an average parent\/children group size (e.g 1, 2, and 3), the survival rate seems to be slighly higher than if the passenger has other group sizes. ","302fd4a5":"Fare: We will replace this one missing value in the test data with the average of other fare values from passengers who were also in the 3rd class, from Southampton, and had an unknown cabin value","eb5c03a7":"The above graph again shows that when the family size is about average (e.g 2 to 4 people), the chance to survive will be higher. So let's just classify each family into one of three categories: below 2 people, 2 to 4 people, and more than 4 people.","ae386813":"# Take a look at out data \n\nBefore we begin selecting features and building our model, we may want to take a look at our data and check if we have any missing values. Also, it is a wise diecision to visualize different parameters, especially getting a sense of their distributions and other characteristics. So let's begin!","736734b2":"2.1 Title Column: \n\nName for each passenger can indirectly reflect their status, which will also influence the likelyhood to survive from the disaster","5b838d6f":"7. Fare\n\nThis graph shows that for passengers whose fare is below 20, the chance to survive is slightly higher. ","c88a5202":"# Correlations Between Parameters\n\nWe have just visualized most columns of our data. Now we may want to find associations between variables to help us understand the data and find useful features to build our model. From univariate graphs we see that there seem to be strong associations between certain variables (for example, Parch and SibSp seems to correlate strongly) So let's examine the correlations between all these parameters. This can be achievd\nthrough two ways: **Bivariate Analysis** and a **heat map about correlations**.\n\nSo let's first begin by drawing some bivariate graphs that compare different variables","85fc75c1":"2.3 Cabin Deck:\n\nThe first letter in Cabin value for each passenger reflects the deck they stay in, and the better the deck is, the more likely the passenger will survive. So we may also want to create a new column for deck. ","d2c10419":"2.5 Fill missing values for Age column:\n\nWe can in fact use a regressor to predict the missing age values from other features. To do this, we will first check the correlations between Age and other parameters","52725a77":"Cabin:\nWe will just replace missing values in the Cabin column with \"Unknown\"","a8cd1507":"1. Pclass\n\nThe first Bivariate graph we will plot is Passenger Class vs. Survived. Since Pclass is a categorical variable, we will use a bar graph to visualize the association between the two variables. From this graph, we can conclude that class level indeed has an impact on passenger's chance to survive. The average chance of survival decreases as the class level decreases. ","dc7408c2":"5. SibSp\n\nAgain, this graph may show that if the passenger has an average sibling\/spouse group size, the survival rate may be slightly higher."}}