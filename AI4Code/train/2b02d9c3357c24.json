{"cell_type":{"8408c8d7":"code","a35aacc2":"code","eaaeee45":"code","8f69e4df":"code","53c34dad":"code","430742f4":"code","301ef11f":"code","766a234d":"code","8f31dc76":"code","014b597d":"code","ff291267":"code","a463da8d":"code","949c6f2e":"code","50825e8e":"code","a2fd408b":"code","c7dc0e56":"code","27cb446f":"code","c9200316":"code","b7d1bde9":"code","46f560a3":"code","b3bf3d69":"code","0700e931":"code","aa004503":"code","92eb7de8":"code","57023d5e":"code","fcc3cbbc":"code","f5426f34":"code","c3487c34":"code","ccdc554f":"code","933175c7":"code","bd5303da":"code","830fd7f7":"code","56883e3f":"code","1079f32f":"code","95601c77":"markdown","642bbde5":"markdown","a772e2b6":"markdown","a6fc7e33":"markdown","61790729":"markdown","80b9274d":"markdown","4ba6c9ff":"markdown","a8f1fce5":"markdown","a5357d64":"markdown","8a4966bd":"markdown","3e150a69":"markdown","05749895":"markdown","6c2a4b7c":"markdown","0e6b97c3":"markdown","16fdaf4b":"markdown","c15802ac":"markdown","6fb2f61c":"markdown","40e3f545":"markdown","5b07a905":"markdown","a37fe3ab":"markdown","ffe35329":"markdown","907594bb":"markdown","7ff64254":"markdown","ecdf73fd":"markdown","897b2dcd":"markdown","196f2ae5":"markdown","6d1d8fef":"markdown"},"source":{"8408c8d7":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","a35aacc2":"!wget https:\/\/raw.githubusercontent.com\/alexeygrigorev\/mlbookcamp-code\/master\/chapter-06-trees\/CreditScoring.csv","eaaeee45":"df = pd.read_csv('CreditScoring.csv')\ndf.columns = df.columns.str.lower()","8f69e4df":"df.head()","53c34dad":"df.describe(\n)","430742f4":"status_values = {\n    1: 'ok',\n    2: 'default',\n    0: 'unk'\n}\n\ndf.status = df.status.map(status_values)\n\n\nhome_values = {\n    1: 'rent',\n    2: 'owner',\n    3: 'private',\n    4: 'ignore',\n    5: 'parents',\n    6: 'other',\n    0: 'unk'\n}\n\ndf.home = df.home.map(home_values)\n\nmarital_values = {\n    1: 'single',\n    2: 'married',\n    3: 'widow',\n    4: 'separated',\n    5: 'divorced',\n    0: 'unk'\n}\n\ndf.marital = df.marital.map(marital_values)\n\nrecords_values = {\n    1: 'no',\n    2: 'yes',\n    0: 'unk'\n}\n\ndf.records = df.records.map(records_values)\n\njob_values = {\n    1: 'fixed',\n    2: 'partime',\n    3: 'freelance',\n    4: 'others',\n    0: 'unk'\n}\n\ndf.job = df.job.map(job_values)","301ef11f":"df.describe()","766a234d":"for c in ['income', 'assets', 'debt']:\n    df[c] = df[c].replace(to_replace=99999999, value=0)","8f31dc76":"df = df[df.status != 'unk'].reset_index(drop=True)","014b597d":"df['default'] = (df.status == 'default').astype(int)\ndel df['status']","ff291267":"from sklearn.model_selection import train_test_split","a463da8d":"df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n#df=4455 - df-train_full=3564 - df_test=891 -df_train=2673\ndf_train, df_val = train_test_split(df_train_full, test_size=0.25 , random_state=1)\ndf_train_full.dtypes","949c6f2e":"categorical = df_train[['home', 'marital', 'records', 'job']]\nnumerical = df_train[['seniority', 'time', 'age', 'expenses', 'income', 'assets', 'debt', 'amount', 'price', 'default']]\n\n#X=pd.get_dummies(data=X, columns=['thal'], drop_first=True) - hot encoding categori jadi numeric","50825e8e":"X_train = numerical.drop('default', axis=1)\ny_train = numerical['default']\n\ndel numerical['default']","a2fd408b":"'''\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, roc_curve, auc\n\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)\n\nPredictProb = classifier.predict_proba(X_train)#X_test\npreds = PredictProb[:,1]\nfpr, tpr, threshold = roc_curve(y_train, preds)#y_test\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10,8))\nplt.title('Whats?')\nplt.plot(fpr, tpr, 'b', label = 'AUC = {}'.format(round(roc_auc, 2)))\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n'''\n'''\nLet's drop those features where the missing\/total coefficient is higher than 15%.\ndropList = list(missing_data[missing_data['Percent'] > 0.15].index)\ndropList\ndf.drop(dropList, axis=1, inplace=True)\n\ndf.head()\ndf.drop(['Date'], axis=1, inplace=True)\ndf.drop(['Location'], axis=1, inplace=True)\n\n\nohe = pd.get_dummies(data=df, columns=['WindGustDir','WindDir9am','WindDir3pm'])\n\nfrom sklearn import preprocessing\nfrom numpy import array\n\nohe['RainToday'] = df['RainToday'].astype(str)\nohe['RainTomorrow'] = df['RainTomorrow'].astype(str)\n\nlb = preprocessing.LabelBinarizer()\n\nohe['RainToday'] = lb.fit_transform(ohe['RainToday'])\nohe['RainTomorrow'] = lb.fit_transform(ohe['RainTomorrow'])\n\nohe = ohe.dropna()\n#ohe.drop('Location', axis=1, inplace=True)\ny = ohe['RainTomorrow']\nX = ohe.drop(['RainTomorrow'], axis=1)\n'''","c7dc0e56":"tree_feature =  pd.Series(classifier.feature_importances_, X_train.columns).sort_values(ascending = True)\nplt.figure(figsize = (8,8))\nplt.barh(X_train.columns, tree_feature)\nplt.xlabel('Mean Impurity Reduction', fontsize = 12)\nplt.ylabel('Features', fontsize = 12)\nplt.yticks(fontsize = 12)\nplt.title('Feature Importances', fontsize = 20)","27cb446f":"X_train = df_train[['seniority', 'income', 'assets', 'records', 'job', 'home']]\nX_val = df_val[['seniority', 'income', 'assets', 'records', 'job', 'home']]\n\ny_train = df_train['default']\ny_val = df_val['default']\n\ndel df_train['default']\ndel df_val['default']\n","c9200316":"from sklearn.feature_extraction import DictVectorizer\n\ntrain_dict = X_train.to_dict(orient='records')\ntrain_dict[0]","b7d1bde9":"dv = DictVectorizer(sparse=False)\ndv.fit(train_dict)\n\nX_train = dv.transform(train_dict)\n\ndv.get_feature_names()","46f560a3":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nmodel = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\nmodel.fit(X_train, y_train)","b3bf3d69":"val_dict = df_val.to_dict(orient='records')\nX_val = dv.transform(val_dict)\nmodel.predict_proba(X_val)\ny_pred = model.predict_proba(X_val)[:, 1]\ny_pred","0700e931":"default = y_pred > 0.5\n(y_val == default).mean()","aa004503":"from sklearn.metrics import classification_report, roc_curve, auc\n\nPredictProb = model.predict_proba(X_val)#X_test\npreds = PredictProb[:,1]\nfpr, tpr, threshold = roc_curve(y_val, preds)#y_test\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10,8))\nplt.title('Whats?')\nplt.plot(fpr, tpr, 'b', label = 'AUC = {}'.format(round(roc_auc, 3)))\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","92eb7de8":"from sklearn.metrics import precision_recall_curve\ny_scores = model.predict_proba(X_val)[:,1]\n#y_scores\n\nprecisions, recalls, thresholds = precision_recall_curve(y_val, y_scores)\n\ndef plot_prc (precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n    plt.xlabel('Thresholds')\n    plt.legend(loc='center left')\n    plt.ylim([0,1])\n\nplot_prc(precisions, recalls, thresholds)","57023d5e":"'''\n#y_pred = clf.predict(X_test)  # default threshold is 0.5\ny_pred1 = (model.predict_proba(X_val)[:,1] >= 0.8).astype(int) # set threshold as 0.3\nprecision_score(y_val, y_pred1)\n'''","fcc3cbbc":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\ny_pred = model.predict(X_val)\n#confusion_matrix(y_test, y_pred)\nroc_auc_score(y_val, y_pred)","f5426f34":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n#recall_score(y_test, y_pred)\n#precision_score(y_test, y_pred)\nf1_score(y_val, y_pred)","c3487c34":"X_train = df_train[['seniority', 'income', 'assets', 'records', 'job', 'home']]\nX_val = df_val[['seniority', 'income', 'assets', 'records', 'job', 'home']]\n\ny_train = df_train['default']\ny_val = df_val['default']\n\ndel df_train['default']\ndel df_val['default']\n","ccdc554f":"df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n#df=4455 - df-train_full=3564 - df_test=891 -df_train=2673\ndf_train, df_val = train_test_split(df_train_full, test_size=0.25 , random_state=1)\n\nX_train = df_train[['seniority', 'income', 'assets', 'records', 'job', 'home']]\nX_val = df_val[['seniority', 'income', 'assets', 'records', 'job', 'home']]\n\ny_train = df_train['default']\ny_val = df_val['default']\n\ndel df_train['default']\ndel df_val['default']\n","933175c7":"val_dict = df_val.to_dict(orient='records')\nX_val = dv.transform(val_dict)","bd5303da":"X_train=pd.DataFrame(X_train)\nX_val=pd.DataFrame(X_val)","830fd7f7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom numpy import mean, std\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=1)\n\npredictions = np.zeros(len(X_val))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n    print(f\"Fold: {fold}\")\n    xtrain, xval = X_train.iloc[trn_idx], X_train.iloc[val_idx]\n    ytrain, yval = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n\n    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n   \n    model.fit(X_train, y_train)\n    pred = model.predict_proba(xval)[:,1]\n    roc = roc_auc_score(yval, pred)\n    print(f\" roc_auc_score: {roc}\", np.std(pred)) #, std{roc}) np.std(y_pred)\n    print(\"-\"*50)\n    \n    predictions += model.predict_proba(X_val)[:,1] \/ folds.n_splits ","56883e3f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom numpy import mean, std\n\n\ndef printing_Kfold_scores(x_train_data,y_train_data):\n    fold = KFold(n_splits=5, shuffle=True) \n\n    # Different C parameters\n    c_param_range = [0.01,0.1,1,10]\n\n    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean score'])\n    results_table['C_parameter'] = c_param_range\n\n    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n    j = 0\n    for c_param in c_param_range:\n        print('-------------------------------------------')\n        print('C parameter: ', c_param)\n        print('-------------------------------------------')\n        print('')\n\n        roc_aucs = []\n        for iteration, indices in enumerate(fold.split(X_train)):\n\n            # Call the logistic regression model with a certain C parameter\n            model = LogisticRegression(solver='liblinear', C=c_param, max_iter=1000)\n\n            # Use the training data to fit the model. In this case, we use the portion of the fold to train the model\n            # with indices[0]. We then predict on the portion assigned as the 'test cross validation' with indices[1]\n            model.fit(X_train, y_train)\n\n            # Predict values using the test indices in the training data\n            ypred = model.predict_proba(xval)[:,1]\n\n            # Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n            roc_auc = roc_auc_score(yval, ypred)\n            roc_aucs.append(roc_auc)\n            print('Iteration ', iteration,': auc score = ', roc_auc)\n\n        # The mean value of those recall scores is the metric we want to save and get hold of.\n        results_table[j,'Mean score'] = np.mean(roc_aucs)\n        j += 1\n        print('')\n        print('Mean score ', np.mean(roc_aucs))\n        print('')\n\n    best_c = results_table.loc[results_table['Mean score']]['C_parameter']\n    \n    # Finally, we can check which C parameter is the best amongst the chosen.\n    print('*********************************************************************************')\n    print('Best model to choose from cross validation is with C parameter = ', best_c)\n    print('*********************************************************************************')\n    \n    return best_c","1079f32f":"best_c = printing_Kfold_scores(X_train,y_train)","95601c77":"At which threshold precision and recall curves intersect?\n\n* 0.2\n* 0.4 x\n* 0.6\n* 0.8","642bbde5":"## Question 3\n\nNow let's compute precision and recall for our model.\n\n* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n* For each threshold, compute precision and recall\n* Plot them","a772e2b6":"## Homework 4\n\nUse this notebook as a starter","a6fc7e33":"##############################","61790729":"## Question 2\n\nWhat's the AUC of this model on the validation dataset? (round to 3 digits)\n\n- 0.512\n- 0.612\n- 0.712\n- 0.812 x","80b9274d":"## Question 4\n\nPrecision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n\nThis is the formula for computing F1:\n\n$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n\nWhere $P$ is precision and $R$ is recall.\n\nLet's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01","4ba6c9ff":"Some of the features are encoded as numbers. Use the following code to de-code them:","a8f1fce5":"## Question 1\n\nROC AUC could also be used to evaluate feature importance of numerical variables. \n\nLet's do that\n\n* For each numerical variable, use it as score and compute AUC with the \"default\" variable\n* Use the training dataset for that\n\n\nIf your AUC is < 0.5, invert this variable by putting \"-\" in front\n\n(e.g. `-df_train['expenses']`)\n\nAUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.","a5357d64":"## Training the model\n\nFrom now on, use these columns only:\n\n```\n['seniority', 'income', 'assets', 'records', 'job', 'home']\n```\n\nApply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n\n```\nLogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n```","8a4966bd":"Remove clients with unknown default status","3e150a69":"What are the categorical variables? What are the numerical? #df_train_full.dtypes\nseniority     int64\nhome         object\ntime          int64\nage           int64\nmarital      object\nrecords      object\njob          object\nexpenses      int64\nincome        int64\nassets        int64\ndebt          int64\namount        int64\nprice         int64\ndefault       int64\ndtype: object","05749895":"#############################","6c2a4b7c":"## Your code","0e6b97c3":"Which numerical variable (among the following 4) has the highest AUC?\n\n- seniority\n- time\n- income\n- debt x","16fdaf4b":"Prepare the numerical variables:","c15802ac":"At which threshold F1 is maximal?\n\n- 0.1\n- 0.3\n- 0.5\n- 0.7","6fb2f61c":"## Question 6\n\nNow let's use 5-Fold cross-validation to find the best parameter C\n\n* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n* Initialize `KFold` with the same parameters as previously\n* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)","40e3f545":"# Split the dataset into 3 parts: train\/validation\/test with 60%\/20%\/20% distribution. Use train_test_split funciton for that with random_state=1","5b07a905":"## Question 5\n\n\nUse the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n\n```\nKFold(n_splits=5, shuffle=True, random_state=1)\n```\n\n* Iterate over different folds of `df_full_train`\n* Split the data into train and validation\n* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n* Use AUC to evaluate the model on validation\n","a37fe3ab":"https:\/\/github.com\/alexeygrigorev\/mlbookcamp-code\/blob\/master\/course-zoomcamp\/04-evaluation\/homework-4-starter.ipynb - https:\/\/www.kaggle.com\/joparga3\/in-depth-skewed-data-classif-93-recall-acc-now","ffe35329":"Data:\n\n- https:\/\/github.com\/gastonstat\/CreditScoring\n- Also available [here](https:\/\/raw.githubusercontent.com\/alexeygrigorev\/mlbookcamp-code\/master\/chapter-06-trees\/CreditScoring.csv)","907594bb":"############################################","7ff64254":"Which C leads to the best mean score?\n\n- 0.01\n- 0.1\n- 1\n- 10 x\n\nIf you have ties, select the score with the lowest std. If you still have ties, select the smallest C","ecdf73fd":"## Submit the results\n\nSubmit your results here: https:\/\/forms.gle\/e497sR5iB36mM9Cs5\n\nIt's possible that your answers won't match exactly. If it's the case, select the closest one.\n\n## Deadline\n\nThe deadline for submitting is 04 October 2021, 17:00 CET. After that, the form will be closed.","897b2dcd":"Create the target variable","196f2ae5":"How large is standard devidation of the scores across different folds?\n\n- 0.001\n- 0.014\n- 0.09\n- 0.14 x","6d1d8fef":"## Preparation \n\nWe'll talk about this dataset in more details in week 6. But for now, use the following code to get started"}}