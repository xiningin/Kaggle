{"cell_type":{"abb42775":"code","e1025c46":"code","e7a79d11":"code","12744b13":"code","65734b15":"code","1a97d48d":"code","a2f65af1":"code","76a40987":"code","112bc92f":"code","ce435c9c":"code","967c3a09":"code","c2edf7bc":"code","59d31ecb":"code","9d3092fa":"code","f804f207":"code","9ba934c5":"code","1a4a367f":"code","a63eae15":"code","8ce2b9b8":"code","2f84687a":"code","0670fb93":"code","f71aafbf":"code","b0f91223":"code","bafb03c8":"code","e7114f70":"code","ad09d2d0":"code","a1a9b986":"code","9707e261":"code","f0a201f8":"markdown","6ae392c3":"markdown","5695e3af":"markdown","5052fedb":"markdown","9bfbdfd5":"markdown","03df9166":"markdown"},"source":{"abb42775":"pip install p_tqdm","e1025c46":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # visualization\nimport re\nfrom p_tqdm import p_map\n\n# image handling\nimport cv2\nimport urllib\nfrom urllib import request\n\n# modeling\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import SGD\n\nimport os","e7a79d11":"# read in the app data from kaggle directors; because this analysis is focusing on images, we only need the name, icon URL, and app genre\ndata = pd.read_csv('\/kaggle\/input\/17k-apple-app-store-strategy-games\/appstore_games.csv',usecols=[2,4,15]) ","12744b13":"# parse the genre data to the most granular level of specificity using regular expressions\ndata['Genre Class'] = data['Genres'].apply(lambda x: re.sub(', Strategy','',re.sub('Strategy, ','',re.sub('Games, ','',x))).split(\",\")[0])","65734b15":"# let's check out the structure of the data\ndata.head(10)","1a97d48d":"# let's check out the different classes...\ndata['Genre Class'].unique()","a2f65af1":"# ... and their distribution\ndata['Genre Class'].value_counts().apply(lambda x: x\/len(data['Genre Class'].values))","76a40987":"# and let's create a class weight dictionary to potentially handle the imbalanced nature in the modeling stage\nclass_distribution = data['Genre Class'].value_counts().apply(lambda x: x\/len(data['Genre Class'].values)).reset_index().drop('index',axis=1).to_dict()['Genre Class']","112bc92f":"# for the initial proof of concept, let's just focus in on the top two classes and see if we can distinguish them with a reasonable degree of accuracy\n# both have counts >2500, so we can filter them out with this information\ndata['Genre Class Count'] = data['Genre Class'].map(pd.DataFrame(data['Genre Class'].value_counts()).to_dict()['Genre Class'])\ndata = pd.DataFrame(data[data['Genre Class Count']>2500])","ce435c9c":"# let's pull the original 512x512 image here\ndef load_image(pngfile):\n    content = request.urlopen(pngfile)\n    im = np.asarray(bytearray(content.read()), dtype=\"uint8\")\n    return cv2.cvtColor(cv2.imdecode(im,cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\/255","967c3a09":"# let's tune which interpolation method we use based on manual inspection\ndef load_resize_image(pngfile,interpolation):\n    content = request.urlopen(pngfile)\n    im = np.asarray(bytearray(content.read()), dtype=\"uint8\")\n    return cv2.resize(cv2.cvtColor(cv2.imdecode(im,cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB), dsize=(64, 64), interpolation=interpolation)\/255","c2edf7bc":"# the leftmost image is the original, and it appears that the rightmost interpolation method retains \n# the most integrity of the original image so let's go with the INTER_AREA method\nf, axarr = plt.subplots(1,5)\nf.set_size_inches(18.5, 10.5, forward=True)\naxarr[0].imshow(load_image(data['Icon URL'].tolist()[0]))\naxarr[1].imshow(load_resize_image(data['Icon URL'].tolist()[0],interpolation=cv2.INTER_CUBIC))\naxarr[2].imshow(load_resize_image(data['Icon URL'].tolist()[0],interpolation=cv2.INTER_NEAREST))\naxarr[3].imshow(load_resize_image(data['Icon URL'].tolist()[0],interpolation=cv2.INTER_LINEAR))\naxarr[4].imshow(load_resize_image(data['Icon URL'].tolist()[0],interpolation=cv2.INTER_AREA))","59d31ecb":"# let's redefine the load_resize_image function using the interpolation method we chose for easier use \n# in the multiprocessing step\ndef load_resize_image(pngfile):\n    content = request.urlopen(pngfile)\n    im = np.asarray(bytearray(content.read()), dtype=\"uint8\")\n    return cv2.resize(cv2.cvtColor(cv2.imdecode(im,cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB), dsize=(64, 64), interpolation=cv2.INTER_AREA)\/255","9d3092fa":"# for the POC, let's load the first 5000 images, speeding up with multiprocessing and progress bar\nimages = np.asarray(p_map(load_resize_image,data['Icon URL'].tolist()[:5000]))","f804f207":"# save and download the images as a .npy file so we don't have to load images again in event of \n# notebook crashing\nnp.save(\"images_poc.npy\",images)\n# np.load(\"y_dev.npy\")","9ba934c5":"# check that the data has been properly normalized; should be between 0 and 1\n[np.min(images[100]),np.max(images[100])]","1a4a367f":"# check the distribution of the data between the two classes\ndata['Genre Class'].iloc[:5000].apply(lambda x: 1 if x=='Puzzle' else 0).value_counts()","a63eae15":"# to help with the imbalanced classes, perform oversampling to match the density of them together\nimages = np.append(images,images[data['Genre Class'].iloc[:5000].apply(lambda x: 1 if x=='Puzzle' else 0).values[:5000]==1][:1176],axis=0)","8ce2b9b8":"np.save(\"images_poc_oversampled.npy\",images)\n# images_oversampled = np.load(\"images_poc_oversampled.npy\")","2f84687a":"# verify that the shape of the images is 6176x64x64x3\nimages.shape","0670fb93":"# perform the train vs validation split\nfrom sklearn.model_selection import train_test_split\ny_values = np.append(data['Genre Class'].apply(lambda x: 1 if x=='Puzzle' else 0).values[:5000],[1]*1176)\nX_train, X_dev, y_train, y_dev = train_test_split(images,y_values, test_size=0.15)","f71aafbf":"# let's take a look at the transformations that keras's image data generator will be performing\nfrom keras.preprocessing.image import ImageDataGenerator\nimgen = ImageDataGenerator(rotation_range=60, width_shift_range=.1,height_shift_range=.1,horizontal_flip=True,zoom_range=0.2)\n\nf, axarr = plt.subplots(2,2)\nf.set_size_inches(8, 8, forward=True)\naxarr[0][0].imshow(X_train[0])\naxarr[1][0].imshow(X_train[1])\naxarr[0][1].imshow(imgen.random_transform(X_train[0]))\naxarr[1][1].imshow(imgen.random_transform(X_train[1]))","b0f91223":"def scheduler(epoch, lr):\n    if epoch < 350:\n        return lr\n    else:\n        return .05\n\nwith tf.device('\/gpu:0'):\n    input_dim = X_train.shape[1:]\n    model = Sequential()\n    \n    model.add(layers.Conv2D(64, kernel_size=(3,3), input_shape=input_dim,kernel_initializer='random_normal'))\n    model.add(layers.Activation('tanh'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(layers.Dropout(.25))\n    \n    model.add(layers.Conv2D(128, kernel_size=(3,3), input_shape=input_dim,kernel_initializer='random_normal'))\n    model.add(layers.Activation('tanh'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(layers.Dropout(.25))\n\n\n    model.add(layers.Flatten())\n\n    model.add(layers.Dense(512, activation='tanh',kernel_initializer='random_normal'))\n    \n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer=SGD(learning_rate=.05),metrics=[\"accuracy\"])\n    \n    model.summary()\n    \n    # the image data generator seemed to introduce too much randomness into the model, preventing it from \n    # learning, so I went ahead with just the original data, no data augmentation performed:\n    \n#     datagen = ImageDataGenerator(rotation_range=60,horizontal_flip=True,zoom_range=0.2)\n\n#     history = model.fit(datagen.flow(X_train,y_train,batch_size=64),steps_per_epoch=len(X_train) \/ 64,\n#                         epochs=1000,\n#                         verbose=True,\n#                         validation_data=(X_dev, y_dev))\n    \n    # I also tried a learning rate scheduler to improve the optimization, but this did not result in \n    # increased accuracy\n    \n#     callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n    \n#     history = model.fit(X_train, y_train,\n#                         epochs=600,\n#                         verbose=True,\n#                         callbacks=[callback],\n#                         validation_data=(X_dev, y_dev),\n#                         batch_size=64) \n    \n    # the original model without data augmentation and without a learning rate scheduler ended up \n    # achieving the highest accuracy; there is still overfitting, to be discussed in results section\n    \n    history = model.fit(X_train, y_train,\n                        epochs=500,\n                        verbose=False,\n                        validation_data=(X_dev, y_dev),\n                        batch_size=64)","bafb03c8":"# let's plot the loss history \nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model error')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e7114f70":"# ... and the accuracy history\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","ad09d2d0":"# rerunning the model with the chosen number of epochs:\nwith tf.device('\/gpu:0'):\n    input_dim = X_train.shape[1:]\n    model = Sequential()\n    \n    model.add(layers.Conv2D(64, kernel_size=(3,3), input_shape=input_dim,kernel_initializer='random_normal'))\n    model.add(layers.Activation('tanh'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(layers.Dropout(.25))\n    \n    model.add(layers.Conv2D(128, kernel_size=(3,3), input_shape=input_dim,kernel_initializer='random_normal'))\n    model.add(layers.Activation('tanh'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(layers.Dropout(.25))\n\n\n    model.add(layers.Flatten())\n\n    model.add(layers.Dense(512, activation='tanh',kernel_initializer='random_normal'))\n    \n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer=SGD(learning_rate=.05),metrics=[\"accuracy\"])\n    \n    model.summary()\n    \n    history = model.fit(X_train, y_train,\n                    epochs=250,\n                    verbose=False,\n                    validation_data=(X_dev, y_dev),\n                    batch_size=64)","a1a9b986":"# let's plot the loss history \nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","9707e261":"# ... and the accuracy history\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f0a201f8":"# 1. Read in Data","6ae392c3":"# 3. Load and Preprocess Images","5695e3af":"# 5. Tuning the number of epochs\nFrom the learning curves above, we can use the elbow method to find an appropriate cutoff for the number of epochs so as to minimize the overfitting","5052fedb":"# 4. Modeling","9bfbdfd5":"# 6. Results and Discussion\nFrom the modeling, we were able to achieve an accuracy of around 73%, which is better than the baseline of ~60% (from always guessing entertainment pre-oversampling .242606\/(.242606+.157641)). However, there are two major problems that preclude a higher accuracy:\n1. Overfitting due to the low volume of images\n2. High intra-class variation due to the subjective nature of the classes (i.e. what constitutes a puzzle game vs an entertainment game?). Because they are not strictly defined, we would expect higher variation present in the individual classes and overlap between them","03df9166":"# 2. Preprocess Metadata"}}