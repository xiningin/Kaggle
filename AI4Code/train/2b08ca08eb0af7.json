{"cell_type":{"da17a60c":"code","8cea8bb0":"code","d90d8c9d":"code","36383746":"code","83480b5f":"code","42c477fb":"code","4623ea0f":"markdown","f84eaac5":"markdown"},"source":{"da17a60c":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB3\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Conv2D\n\nfrom sklearn.model_selection import train_test_split\nfpath = '\/kaggle\/input\/stanford-dogs-dataset\/images\/Images\/'\ncategories = os.listdir(fpath)","8cea8bb0":"imgsize = 300\nX =[]\nY = []\n\n#he kernel would not allow me to run the full 120 class dataset. So I had to compromise with 40\n#I think the accuracy for the full dataset would fall somewhere around the 80% mark\nfor index, folder in enumerate(categories[:40]):\n    path = os.path.join(fpath,folder)\n    for img in tqdm(os.listdir(path)):\n        Ipath = os.path.join(path,img)\n        img = cv2.imread(Ipath,cv2.IMREAD_COLOR)\n        img = cv2.resize(img,(imgsize,imgsize))\n        X.append(np.array(img))\n        Y.append(index)\n\nX = np.array(X)\nY = np.array(Y)\nprint(X.shape)\nprint(Y.shape)","d90d8c9d":"labels = np_utils.to_categorical(Y, 40)\n\ntrainImg, testImg, trainLabel, testLabel = train_test_split(X, labels,  test_size=0.3,random_state=69)\nlabels = None\nX = None","36383746":"augs_gen = ImageDataGenerator(preprocessing_function=preprocess_input,featurewise_center=False,  \n        samplewise_center=False, \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.2,  \n        height_shift_range=0.2, \n        horizontal_flip=True,  \n        vertical_flip=False)\naugs_gen.fit(trainImg)\n\nbase_model = EfficientNetB3(include_top=False,\n                  input_shape = (imgsize,imgsize,3),\n                  weights = 'imagenet')\n\nbase_model.trainable = False\n\nmodel = Sequential([base_model])\n#model.add(Conv2D(10, (3,3) , activation = 'relu'))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(40,activation='softmax'))\nmodel.summary()\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n","83480b5f":"h = model.fit(augs_gen.flow(trainImg,trainLabel), epochs = 20, verbose = 1, batch_size = 250,\n              validation_data  = (preprocess_input(testImg),testLabel))\n\nplt.figure(figsize = (10,5))\nplt.subplot(1,2,1)\nplt.plot(h.history['accuracy'],     label = 'Train')\nplt.plot(h.history['val_accuracy'], label = 'Validation')\nplt.title('Accuracy')\nplt.legend(loc = 'upper left')\n\nplt.subplot(1,2,2)\nplt.plot(h.history['loss']    ,label = 'Train')\nplt.plot(h.history['val_loss'],label = 'Validation')\nplt.title('Loss')\nplt.legend(loc = 'upper left')\nplt.show()\n\nprint(100*np.max(h.history['val_accuracy']))","42c477fb":"model.save('SavedEfficientNetB3.h5')","4623ea0f":"This is my attempt to use transfer learning in order to classify the Dogs datasets.\nI dont know enough about segmenting the dataset so I can only classify the first 40 classes out of 120.\n\nI would love to know more about it if someone can leave a comment.\n\nI use **EfficientNetB3** and then use use one Dense layer as my output layer.","f84eaac5":"This 91% accuracy is a little overstated because we picked only 40 classes but this model definitely stays above 85% accuracy for the full 120 classes."}}