{"cell_type":{"1be0e3f3":"code","dfa8e972":"code","8e457cf3":"code","5374e3e3":"code","eff4563b":"code","2456a2b7":"code","cd307fe5":"code","41ba3be3":"code","027ceca7":"code","fd3c1f27":"code","4a77e959":"code","5ec0a607":"code","fb4610d1":"code","93aa7936":"code","91f66629":"code","97b98dac":"code","bb5c6326":"code","b8d797a7":"code","9ac6d894":"code","c20d503f":"code","a8a7e5f0":"code","3ad86bd6":"code","ebbb4c6f":"code","18279d3b":"code","0ea57e83":"code","59cbc10e":"code","2001bcc3":"code","708fda11":"code","e64f24b7":"code","6ae8d233":"code","630e0984":"code","07cc8a36":"code","9cf21ec0":"code","087a2dea":"code","b586f711":"code","f521b97f":"code","1bb1fe1c":"code","5f7794c5":"code","a39ad651":"code","52e30ebf":"code","8ae06e7c":"code","9be6119d":"code","7e917bd2":"markdown","3fc0e070":"markdown","a2456663":"markdown","6006985e":"markdown","d2783371":"markdown","083ff356":"markdown","53755f12":"markdown","31cc582a":"markdown","46586afb":"markdown","584088cc":"markdown","b80e174e":"markdown","f26595d0":"markdown","53037dc7":"markdown"},"source":{"1be0e3f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dfa8e972":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt","8e457cf3":"stroke = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","5374e3e3":"stroke.head()","eff4563b":"strokes = stroke.drop('id', axis=1)","2456a2b7":"strokes.head()","cd307fe5":"strokes['gender'].unique()","41ba3be3":"strokes['ever_married'].unique()","027ceca7":"strokes['work_type'].unique()","fd3c1f27":"strokes['Residence_type'].unique()","4a77e959":"strokes['smoking_status'].unique()","5ec0a607":"sns.countplot(x = strokes['gender'])","fb4610d1":"sns.countplot(x = strokes['ever_married'])","93aa7936":"sns.countplot(x = strokes['work_type'])","91f66629":"sns.countplot(x = strokes['Residence_type'])","97b98dac":"sns.countplot(x = strokes['smoking_status'])","bb5c6326":"strokes['bmi'].fillna(strokes['bmi'].mean(), inplace = True)","b8d797a7":"strokes.info()","9ac6d894":"x = strokes.iloc[:,:-1]\ny = strokes.iloc[:,-1]","c20d503f":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder","a8a7e5f0":"ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [0,4,5,6,9])], remainder='passthrough')\nx = np.array(ct.fit_transform(x))\nprint(x)","3ad86bd6":"from sklearn.model_selection import train_test_split","ebbb4c6f":"x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=1)","18279d3b":"from sklearn.preprocessing import StandardScaler","0ea57e83":"sc = StandardScaler()","59cbc10e":"x_train_1 = sc.fit_transform(x_train)","2001bcc3":"x_test_1 = sc.fit_transform(x_test)","708fda11":"from sklearn.svm import SVC","e64f24b7":"classifier = SVC(random_state = 0, kernel = 'linear')","6ae8d233":"classifier.fit(x_train_1, y_train)","630e0984":"y_pred = classifier.predict(x_test_1)","07cc8a36":"from sklearn.metrics import confusion_matrix","9cf21ec0":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","087a2dea":"from sklearn.metrics import accuracy_score","b586f711":"acc = accuracy_score(y_test, y_pred)\nacc","f521b97f":"from sklearn.tree import DecisionTreeClassifier","1bb1fe1c":"dc = DecisionTreeClassifier(criterion = 'entropy')","5f7794c5":"dc.fit(x_train_1, y_train)","a39ad651":"pred = dc.predict(x_test_1)","52e30ebf":"cm1 = confusion_matrix(y_test, pred)\nprint(cm1)","8ae06e7c":"acc1 = accuracy_score(y_test, pred)\nacc1","9be6119d":"import sklearn\nfig = plt.figure(figsize = (10,10))\nsklearn.tree.plot_tree(dc, filled = True)","7e917bd2":"# Dropping unrequired column","3fc0e070":"# Plotting Countplots","a2456663":"# Using Decision Tree Classifier","6006985e":"# Filling null values","d2783371":"# Using SVM","083ff356":"# Importing required libraries","53755f12":"# Dividing data into x and y","31cc582a":"# Checking unique values for certain columns","46586afb":"# Using One Hot Encoding","584088cc":"# Importing Dataset","b80e174e":"# Splitting dataset into training and testing data","f26595d0":"# Stroke prediction using two models SVM and DecisionTreeClassifier, to check which model gives better prediction","53037dc7":"# Scaling data"}}