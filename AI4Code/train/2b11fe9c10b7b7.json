{"cell_type":{"33e75a8d":"code","e52c66e7":"code","38b65ec6":"code","e93a5a55":"code","4334beb6":"code","cc49d728":"code","11616a62":"code","bf54502c":"code","aeaba25f":"code","88ea0c30":"code","b8f35ab8":"code","6ea235b1":"code","ee49da35":"code","87d3cc87":"code","b5e84586":"code","b8513eb5":"code","75d562a7":"code","dbce29a7":"code","33342246":"markdown","33892d80":"markdown","a33fbb9a":"markdown","df57623f":"markdown","ece715e8":"markdown","f47115ad":"markdown"},"source":{"33e75a8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.metrics import auc, roc_curve, classification_report, confusion_matrix\nfrom scipy.stats import chi2_contingency\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import Lasso\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e52c66e7":"#Load datasets\n\ntrain_data_file_path = '\/kaggle\/input\/titanic\/train.csv'\ntest_data_file_path = '\/kaggle\/input\/titanic\/test.csv'\n\ntrain_data = pd.read_csv(train_data_file_path)\ntest_data = pd.read_csv(test_data_file_path)\n","38b65ec6":"# Some Exploratory Data Analysis (EDA)\n\ndisplay(\"train_data\", train_data.shape)\ndisplay(train_data.head())\ndisplay(train_data.dtypes)\n","e93a5a55":"# Check NULL values \ndisplay(\"PassengerId\", train_data[\"PassengerId\"].isnull().sum())\ndisplay(\"Survived\", train_data[\"Survived\"].isnull().sum())\ndisplay(\"Pclass\", train_data[\"Pclass\"].isnull().sum())\ndisplay(\"Name\", train_data[\"Name\"].isnull().sum())\ndisplay(\"Sex\", train_data[\"Sex\"].isnull().sum())\ndisplay(\"Age\", train_data[\"Age\"].isnull().sum())\ndisplay(\"SibSp\", train_data[\"SibSp\"].isnull().sum())\ndisplay(\"Parch\", train_data[\"Parch\"].isnull().sum())\ndisplay(\"Ticket\", train_data[\"Ticket\"].isnull().sum())\ndisplay(\"Fare\", train_data[\"Fare\"].isnull().sum())\ndisplay(\"Cabin\", train_data[\"Cabin\"].isnull().sum())\ndisplay(\"Embarked\", train_data[\"Embarked\"].isnull().sum())","4334beb6":"train_data[\"Embarked\"].value_counts()","cc49d728":"train_data[\"Survived\"].value_counts()","11616a62":"# Data cleaning according with identified points\n# These changes should be applied on train and test datasets to make these similars\n\n# Clean embarked field\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(\"S\")\n\n# Clean Age field\ntrain_data[\"Age\"] = train_data['Age'].fillna(train_data.groupby('Sex')['Age'].transform('mean'))\ntest_data[\"Age\"] = test_data[\"Age\"].fillna(test_data.groupby('Sex')['Age'].transform('mean'))\n\n# Convert fields to category \ntrain_data['Sex'] = train_data['Sex'].astype('category')\ntrain_data['Embarked'] = train_data['Embarked'].astype('category')\ntrain_data['Survived'] = train_data['Survived'].astype('category')\ntrain_data['SibSp'] = train_data['SibSp'].astype('category')\ntest_data['Sex'] = test_data['Sex'].astype('category')\n# test_data['Survived'] = test_data['Survived'].astype('category')\ntest_data['Embarked'] = test_data['Embarked'].astype('category')\ntest_data['SibSp'] = test_data['SibSp'].astype('category')\n","bf54502c":"#Let's use Lasso for feature selection \n\n# List of selected features \nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n\nX_train_selected = train_data[features]\ny_train_selected = train_data[['Survived']]\n\n# HotEncode to convert categories to numbers \nX_train_selected = pd.get_dummies(X_train_selected)\n\ncolumn_names = X_train_selected.columns\n\nlasso = Lasso(alpha=0.105)\nlasso_coef = lasso.fit(X_train_selected, y_train_selected).coef_\n\n_ = plt.plot(range(len(column_names)), lasso_coef)\n_ = plt.xticks(range(len(column_names)), column_names, rotation=60)\n_ = plt.ylabel('Coefficients')\nplt.show()\n\n","aeaba25f":"# Prepare data for model \n\n# List of selected features \nselected_features = ['Age', 'Fare', 'Sex_female']\n\nX_train_selected = X_train_selected[selected_features]\n#X_test_selected = test_data[features]\n#y_train_selected = train_data[['Survived']]\n\n# HotEncode to convert categories to numbers \n#X_train_selected = pd.get_dummies(X_train_selected)\n#X_test_selected = pd.get_dummies(X_test_selected)\n\nX_train, X_test, y_train, y_test = train_test_split(X_train_selected, y_train_selected, test_size=0.3, \n                                                    random_state=2, stratify=y_train_selected)","88ea0c30":"# Model training with KNN\n\nknn = KNeighborsClassifier(n_neighbors=11)\n\n#knn.fit(X_train, y_train)\ncv_results = cross_val_score(knn, X_train, y_train, cv=5)\nprint(cv_results)\n#y_pred = knn.predict(X_test)\nnp.mean(cv_results)\n#display(\"Score: \" + str(knn.score(X_test, y_test)))\n#accuracy_score(y_pred,y_test)","b8f35ab8":"# Model training with RandomForest Classifier\n\nrf = RandomForestClassifier(max_depth=8, random_state=42)\n\n#rf.fit(X_train, y_train)\ncv_results = cross_val_score(rf, X_train, y_train, cv=5)\nprint(cv_results)\nnp.mean(cv_results)\n#y_pred = rf.predict(X_test)\n\n#display(\"Score: \" + str(knn.score(X_test, y_test)))\n#accuracy_score(y_pred,y_test)","6ea235b1":"# Define pipeline and use Random Forest in GridSearch\n# use scoring as accuracy \n# use cv as 5 \n\nrf_pipe = Pipeline([('rf', RandomForestClassifier(random_state=0))])\n\nparams = [{\n            'rf__n_estimators': [10, 30, 50, 70, 90, 100],\n            'rf__max_depth': [3, 6, 9, 12, 15, 18, 21],\n           }]\n\ngs_rf = GridSearchCV(rf_pipe,\n                      param_grid=params,\n                      scoring='accuracy',\n                      cv=5)\ngs_rf.fit(X_train, y_train)\ndisplay(gs_rf.best_params_)\ngs_rf.score(X_train, y_train)","ee49da35":"# Validate results with test variables \n\nrf = RandomForestClassifier(n_estimators=30, max_depth=6, random_state=0)\n\nrf.fit(X_train, y_train)\n\ny_pred_test = rf.predict(X_test)\n\nrf.score(X_test, y_test)","87d3cc87":"# Prepare test data to apply the previous model \n\n# List of selected features \n#features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n\nX_test_selected = test_data[features]\n#y_test_selected = test_data[['Survived']]\n\n# HotEncode to convert categories to numbers \nX_test_selected = pd.get_dummies(X_test_selected)\n\n# List of selected features \n# selected_features = ['Pclass', 'SibSp', 'Sex_female', 'Embarked_S']\nX_test_selected = X_train_selected[selected_features]\n\n","b5e84586":"# Train the selected model \n\nrf = RandomForestClassifier(n_estimators=30, max_depth=6, random_state=0)\n\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test_selected)","b8513eb5":"# Print confussion matrix for the results \ndisplay(confusion_matrix(y_test, y_pred))\ndisplay(classification_report(y_test, y_pred))","75d562a7":"# Create dataframe to export based on the predicted data\nSurvived = pd.Series(y_pred)\nresult = pd.DataFrame(test_data[['PassengerId']])\nresult['Survived'] = Survived.astype('int64')\ndisplay(result)","dbce29a7":"# Method to download the submission file \n\n# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\n# create a random sample dataframe\n#df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(result[['PassengerId','Survived']])\n\n# \u2193 \u2193 \u2193  Yay, download link! \u2193 \u2193 \u2193","33342246":"PassengerId is not relevant for the analysis so we can remove it. \nAge is around 20% of missing values, we can fill it using according the average age of the sex. \nEmbarked can be filled up with the most constant value S. \nCabin has a lot of missing values. So we can delete it. \nThe target class is not too imbalanced so, for now, we are not dealing with that \n","33892d80":"From the graphic we can conclude \nAlpha 0.1 = Age, fare, sex_female","a33fbb9a":"As RandomForest had the best performance lets use with GridSearch","df57623f":"Selected Variables - ['Age', 'Fare', 'Sex_female']   \\\nKNN Mean = 0.6767141734934351    \\\nRandom Forest Mean = 0.7949837279766581","ece715e8":"TODO: Check if x_test and y_test are being used for validation. Use also n_estimators","f47115ad":"With selected parameters the result is \\\n{'rf__max_depth': 6, 'rf__n_estimators': 30} \\\n0.8562874251497006"}}