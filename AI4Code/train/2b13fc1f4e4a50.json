{"cell_type":{"35429073":"code","5bda1453":"code","b22a0a9a":"code","a2df15af":"code","57ded982":"code","2ff896f2":"code","b4ae3aaa":"code","2db7ca2a":"code","1199ca70":"code","d7095888":"code","6df539ab":"code","486032b8":"code","b0b4319b":"code","33e1ff90":"code","d270b12d":"code","7758aac7":"code","c49c6314":"code","8ff9f880":"markdown","dcd8b97f":"markdown","6679a703":"markdown","716cfb2e":"markdown","0c884abf":"markdown","6ac511e2":"markdown","4db285be":"markdown"},"source":{"35429073":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5bda1453":"data = pd.read_csv('\/kaggle\/input\/life-expectancy-who\/Life Expectancy Data.csv')\ndata.head()","b22a0a9a":"data.shape","a2df15af":"data.info()","57ded982":"data.isnull().sum()","2ff896f2":"data.columns","b4ae3aaa":"x = data['Life expectancy '].mean()\ndata['Life expectancy '].fillna(x, inplace=True)\n\nx = data['Adult Mortality'].mean()\ndata['Adult Mortality'].fillna(x, inplace=True)\n\nx = data['Alcohol'].mean()\ndata['Alcohol'].fillna(x, inplace=True)\n\nx = data['Hepatitis B'].mean()\ndata['Hepatitis B'].fillna(x, inplace=True)\n\nx = data[' BMI '].mean()\ndata[' BMI '].fillna(x, inplace=True)\n\nx = data['Polio'].mean()\ndata['Polio'].fillna(x, inplace=True)\n\nx = data['Total expenditure'].mean()\ndata['Total expenditure'].fillna(x, inplace=True)\n\nx = data['Diphtheria '].mean()\ndata['Diphtheria '].fillna(x, inplace=True)\n\nx = data['GDP'].mean()\ndata['GDP'].fillna(x, inplace=True)\n\nx = data['Population'].mean()\ndata['Population'].fillna(x, inplace=True)\n\nx = data[' thinness  1-19 years'].mean()\ndata[' thinness  1-19 years'].fillna(x, inplace=True)\n\nx = data[' thinness 5-9 years'].mean()\ndata[' thinness 5-9 years'].fillna(x, inplace=True)\n\nx = data['Income composition of resources'].mean()\ndata['Income composition of resources'].fillna(x, inplace=True)\n\nx = data['Schooling'].mean()\ndata['Schooling'].fillna(x, inplace=True)","2db7ca2a":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndata['Country'] = le.fit_transform(data['Country'])\n\nle = LabelEncoder()\ndata['Status'] = le.fit_transform(data['Status'])","1199ca70":"data.isnull().sum()","d7095888":"data.info()","6df539ab":"# Node Class\nclass Node:\n    \n    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n        self.feature = feature\n        self.threshold = threshold\n        self.left = left\n        self.right = right\n        self.value = value\n    \n    def is_leaf_node(self):\n        return self.value is not None\n\n\n# Decision Tree Regressor Class\nclass RegressionTree:\n    def __init__(self, n_feats = None, max_depth = 100, min_samples_split = 2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None ,\n                 random_state=None ,max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0):\n        \n        self.root = None\n        self.n_feats = n_feats\n        self.max_depth = max_depth\n        self.min_samples_split = min_samples_split\n    \n    def fit(self, X, Y):\n        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n        self.col = list(X.columns)\n        self.root = self.growTree(X, Y)\n\n    def growTree(self, X, Y, depth = 0):\n        \n        df = X.copy()\n        df['y'] = Y\n        \n        ymean = np.mean(Y)\n        \n        self.mse = self.get_mse(Y, ymean)\n        \n        n_sample, n_feature = X.shape\n        \n        # stopping criteria\n        if (depth >= self.max_depth or n_sample <= self.min_samples_split):\n            leaf_value = np.mean(Y)\n            return Node(value=leaf_value)\n\n        feats_idxs = list(X.columns)\n\n        best_feat, best_thresh = self.best_criteria(X, Y, feats_idxs)\n\n        left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy()\n\n        left = self.growTree(left_df.drop('y', axis=1), left_df['y'].values.tolist(), depth+1)\n        right = self.growTree(right_df.drop('y', axis=1), right_df['y'].values.tolist(), depth+1)\n\n        return Node(best_feat, best_thresh, left, right)\n    \n    \n    # find out best criteria\n    def best_criteria(self, X, Y, feats_idxs):\n        \n        df = X.copy()\n        \n        df['y'] = Y\n        \n        mse_base = self.mse\n        \n        best_feature = None\n        best_thresh = None\n        \n        for feat in feats_idxs:\n            \n            xdf = df.sort_values(feat)\n            \n            x_mean = self.moving_average(xdf[feat], 2)\n\n            for value in x_mean:\n                left_y = xdf[xdf[feat] < value]['y'].values\n                right_y = xdf[xdf[feat] >= value]['y'].values\n                \n                left_mean = 0\n                right_mean = 0\n                if len(left_y) > 0:\n                    left_mean = np.mean(left_y)\n                if len(right_y) > 0:\n                    right_mean = np.mean(right_y)\n                \n                res_left = left_y - left_mean\n                res_right = right_y - right_mean\n                \n                r = np.concatenate((res_left, res_right), axis=None)\n                \n                n = len(r)\n\n                r = r ** 2\n                r = np.sum(r)\n                mse_split = r \/ n\n                \n                if mse_split < mse_base:\n                    mse_base = mse_split\n                    best_feature = feat\n                    best_thresh = value\n                    \n        return (best_feature, best_thresh)\n    \n    def get_mse(self, y_true, y_hat):\n        n = len(y_true)\n        \n        r = y_true - y_hat\n        \n        r = r ** 2\n        \n        r = np.sum(r)\n        \n        return r \/ n\n    \n    def moving_average(self, x:np.array, window : int):\n        return np.convolve(x, np.ones(window), 'valid') \/ window \n    \n    def predict(self, X):\n        X = X.to_numpy().tolist()\n        \n        return np.array([self.traverse_tree(x, self.root) for x in X])\n\n    def traverse_tree(self, x, node):\n       \n        if node.value is not None:\n            return node.value\n        \n        fr = node.feature\n        index = self.col.index(fr)\n\n        if x[index] <= node.threshold:\n            return self.traverse_tree(x, node.left)\n        \n        return self.traverse_tree(x, node.right)","486032b8":"if __name__ == '__main__':\n    x = data.drop('Life expectancy ', axis=1)\n    y = data['Life expectancy ']\n    \n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n    DRT = RegressionTree(max_depth = 15,min_samples_split = 20)\n\n    DRT.fit(X_train, y_train)\n    \n    y_pred = DRT.predict(X_test)","b0b4319b":"finalData_1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nfinalData_1.head()","33e1ff90":"n = len(y_test)\nmse = y_test - y_pred\nmse = mse ** 2\nmse = np.sum(mse)\nmse = mse \/ n\nprint('Mean Squared Error :', mse)","d270b12d":"from sklearn.tree import DecisionTreeRegressor\nre = DecisionTreeRegressor(max_depth=15, min_samples_split=20)\nre.fit(X_train, y_train)\nyp = re.predict(X_test)","7758aac7":"finalData_2 = pd.DataFrame({'Actual': y_test, 'Predicted': yp})\nfinalData_2.head()","c49c6314":"n = len(y_test)\nmse = y_test - yp\nmse = mse ** 2\nmse = np.sum(mse)\nmse = mse \/ n\nprint('Mean Squared Error :', mse)","8ff9f880":"# Load Data","dcd8b97f":"## Mean Squared Error","6679a703":"# Decision Tree Regressor of sklearn","716cfb2e":"# Decision Tree Regressor ","0c884abf":"# Main Function ","6ac511e2":"# Data Cleaning","4db285be":"## Mean Squared Error"}}