{"cell_type":{"ff084336":"code","b5df7841":"code","428aef84":"code","b4114159":"code","4ced65ee":"code","a91b5f15":"code","3b23a1d8":"code","daed28a8":"code","56cd6960":"code","b02f6a62":"code","2ada74df":"code","ccaefde5":"code","cf0203f8":"code","7433e494":"code","a069e975":"code","24357428":"code","d09980b1":"code","551024b1":"code","82cb26b8":"code","54aa8e47":"code","a3505cec":"code","9ef01e61":"code","2a03617b":"code","8ab65d96":"code","e143a619":"code","8d25d0f8":"code","0eeb4799":"code","68b6f3b7":"code","2033e12f":"code","bc86ab92":"code","41c7c468":"code","2f6638de":"code","7d63567a":"code","07bd2884":"code","c0f5d0fb":"code","1884d4d6":"code","9ff27385":"code","684d0d79":"code","4109d9dc":"code","ec66b4fd":"code","10f1edd3":"code","31eda73c":"code","ce84f525":"code","14efac9b":"code","e3319ba3":"code","cbc9d2b2":"code","7f0b5e91":"code","cfd98a25":"code","72e32b43":"code","50d209ae":"code","14539091":"code","332691ee":"code","e589989b":"code","22861ac2":"code","71e7ee8c":"code","c67b0138":"code","648dc05f":"code","e5fc6484":"code","1b8cbdd8":"code","8dbba0c7":"markdown","3f66ec8d":"markdown","355c0b84":"markdown","a9abfe19":"markdown","7f46c688":"markdown","3dffbb30":"markdown","621ba945":"markdown","3ca5dd72":"markdown","a93fa722":"markdown","4a59df09":"markdown","6d3b8964":"markdown","6928f675":"markdown","fb5e9e80":"markdown"},"source":{"ff084336":"import numpy as np\nimport pandas as pd\nfrom scipy.stats import spearmanr\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nimport tensorflow as tf\nimport nltk","b5df7841":"def corr_metrics_recom(y_true, y_pred):\n    return spearmanr(y_true, y_pred)[0]","428aef84":"def corr_metrics_rating(y_true, y_pred):\n    y_pred = y_pred.argmax(axis=1) + 1\n    y_true = y_true.argmax(axis=1) + 1\n    return spearmanr(y_true, y_pred)[0]","b4114159":"recom_metrics = make_scorer(corr_metrics_recom)","4ced65ee":"rating_metrics = make_scorer(corr_metrics_rating)","a91b5f15":"submission = pd.read_csv('..\/input\/iba-ml1-final-project\/sample_submission.csv')\nsubmission","3b23a1d8":"df_without_text = pd.read_csv('..\/input\/clean-data\/df_without_text.csv', index_col=0).drop('Pos_Feedback_Cnt', axis=1)\ntest_without_text = pd.read_csv('..\/input\/clean-data\/test_without_text.csv', index_col=0).drop('Pos_Feedback_Cnt', axis=1)\nindex_without_text = test_without_text.index\ndf_without_text","daed28a8":"num_cols_without_text=['Age']\ncat_cols_without_text = ['Division', 'Department', 'Product_Category']\n\nnum_transform_without_text = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\n\ncat_transform_without_text = Pipeline(steps=[\n  ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\ncolumn_transformer_without_text = ColumnTransformer(transformers=[\n    ('num_transformer', num_transform_without_text, num_cols_without_text),\n    ('cat_transformer', cat_transform_without_text, cat_cols_without_text)\n])","56cd6960":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","b02f6a62":"X_without_text_recom  = df_without_text.iloc[:, :-2]\ny_without_text_recom = df_without_text.iloc[:, -1]","2ada74df":"pipe_without_text_recom = Pipeline(steps=[\n        ('preprocessing', column_transformer_without_text),\n        ('model', RandomForestClassifier(n_estimators=85, criterion='entropy'))\n    ])","ccaefde5":"scores_without_text_recom = cross_val_score(pipe_without_text_recom, X_without_text_recom, y_without_text_recom, cv=8, scoring=recom_metrics)\nnp.mean(scores_without_text_recom)","cf0203f8":"pipe_without_text_recom.fit(X_without_text_recom, y_without_text_recom)","7433e494":"submission.loc[index_without_text, 'Recommended'] = pipe_without_text_recom.predict(test_without_text)","a069e975":"X_without_text_rating  = df_without_text.iloc[:, :-2]\ny_without_text_rating = df_without_text.iloc[:, -2]","24357428":"from sklearn.svm import SVC\npipe_without_text_rating = Pipeline(steps=[\n        ('preprocessing', column_transformer_without_text),\n        ('model', SVC(class_weight={1:15, 2:5, 3:4, 4:3, 1:1},kernel='poly', degree=3,decision_function_shape='ovo', C=0.95))\n    ])","d09980b1":"scores_without_text_rating = cross_val_score(pipe_without_text_rating, X_without_text_rating, y_without_text_rating, cv=8, scoring=recom_metrics)","551024b1":"print(np.mean(scores_without_text_rating))\nprint(np.std(scores_without_text_rating))","82cb26b8":"pipe_without_text_rating.fit(X_without_text_rating, y_without_text_rating)","54aa8e47":"submission.loc[index_without_text, 'Rating'] = pipe_without_text_rating.predict(test_without_text)","a3505cec":"df_without_review_title = pd.read_csv('..\/input\/clean-data\/df_without_review_title.csv', index_col=0)\ntest_without_review_title = pd.read_csv('..\/input\/clean-data\/test_without_review_title.csv', index_col=0)\nindex_without_review_title = test_without_review_title.index\ndf_without_review_title","9ef01e61":"X_without_review_title_recom = df_without_review_title.iloc[:, :-2]\ny_without_review_title_recom = df_without_review_title.iloc[:, -1]","2a03617b":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","8ab65d96":"# implementation of custom loss function\nfrom tensorflow.keras import backend as K\ndef focal_loss(y_true, y_pred):\n    gamma = 2.0,\n    alpha = 0.25\n    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))","e143a619":"def prepare_without_review_title(X_train, X_test, tokenizer, max_len):\n    X_train_num, X_train_cat, X_train_text = X_train.loc[:, ['Age', 'Pos_Feedback_Cnt']], X_train.loc[:, ['Division', 'Department', 'Product_Category']], X_train.loc[:, 'Review']\n    X_test_num, X_test_cat, X_test_text = X_test.loc[:, ['Age', 'Pos_Feedback_Cnt']], X_test.loc[:, ['Division', 'Department', 'Product_Category']], X_test.loc[:, 'Review']\n    \n    # num scaler\n    scaler = StandardScaler()\n    X_train_num = scaler.fit_transform(X_train_num)\n    X_test_num = scaler.transform(X_test_num)\n    \n    # cat encoder\n    ohe = OneHotEncoder(handle_unknown='ignore')\n    X_train_cat = ohe.fit_transform(X_train_cat).toarray()\n    X_test_cat = ohe.transform(X_test_cat).toarray()\n    \n    # text\n    X_train_text = tokenizer.texts_to_sequences(X_train_text)\n    X_test_text = tokenizer.texts_to_sequences(X_test_text)\n    X_train_text = pad_sequences(X_train_text, maxlen=max_len, padding='post')\n    X_test_text = pad_sequences(X_test_text, maxlen=max_len, padding='post')\n    \n    \n    #X_train = np.hstack((X_train_num, X_train_cat, X_train_text))\n    #X_test = np.hstack((X_test_num, X_test_cat, X_test_text))\n    return X_train_text, X_test_text","8d25d0f8":"lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\n","0eeb4799":"scores_without_review_title_recom = []\nkfolds = StratifiedKFold(8)\nfor train_idx, test_idx in kfolds.split(X_without_review_title_recom, y_without_review_title_recom):\n    tokenizer = Tokenizer(num_words=5000)\n    tokenizer.fit_on_texts(X_without_review_title_recom['Review'])\n    max_len = max([len(s.split()) for s in X_without_review_title_recom['Review']])\n    vocab_size = len(tokenizer.word_index) + 1\n    \n    X_without_review_title_recom_train, X_without_review_title_recom_test = X_without_review_title_recom.iloc[train_idx], X_without_review_title_recom.iloc[test_idx]\n    y_without_review_title_recom_train, y_without_review_title_recom_test = y_without_review_title_recom.iloc[train_idx], y_without_review_title_recom.iloc[test_idx]\n    \n    \n    X_without_review_title_recom_train, X_without_review_title_recom_test = prepare_without_review_title(X_without_review_title_recom_train, X_without_review_title_recom_test, tokenizer, max_len)\n    \n    model_without_review_title_recom = tf.keras.Sequential()\n    model_without_review_title_recom.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=89, mask_zero=True))\n    model_without_review_title_recom.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(18, dropout=0.2)))\n    model_without_review_title_recom.add(tf.keras.layers.Dense(8, activation=tf.keras.layers.PReLU()))\n    model_without_review_title_recom.add(tf.keras.layers.Dropout(0.2))\n    model_without_review_title_recom.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n    model_without_review_title_recom.compile(loss=['binary_crossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n    \n    model_without_review_title_recom.fit(X_without_review_title_recom_train, y_without_review_title_recom_train, epochs=50, batch_size=130)\n    scores_without_review_title_recom.append(corr_metrics_recom(y_without_review_title_recom_test, model_without_review_title_recom.predict(X_without_review_title_recom_test)))\n    \n","68b6f3b7":"print(np.mean(scores_without_review_title_recom))\nprint(np.std(scores_without_review_title_recom))","2033e12f":"X_without_review_title_recom, test_without_review_title_recom = prepare_without_review_title(X_without_review_title_recom, test_without_review_title, tokenizer, max_len)","bc86ab92":"model_without_review_title_recom = tf.keras.Sequential()\nmodel_without_review_title_recom.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=89, mask_zero=True))\nmodel_without_review_title_recom.add((tf.keras.layers.LSTM(18, dropout=0.2)))\nmodel_without_review_title_recom.add(tf.keras.layers.Dense(8, activation=tf.keras.layers.PReLU()))\nmodel_without_review_title_recom.add(tf.keras.layers.Dropout(0.2))\nmodel_without_review_title_recom.add(tf.keras.layers.Dense(1, activation='sigmoid'))\nmodel_without_review_title_recom.compile(loss=['binary_crossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n    \nmodel_without_review_title_recom.fit(X_without_review_title_recom, y_without_review_title_recom, epochs=50, batch_size=130)","41c7c468":"model_without_review_title_recom.summary()","2f6638de":"tf.keras.utils.plot_model(model_without_review_title_recom)","7d63567a":"submission.loc[index_without_review_title, 'Recommended'] = (model_without_review_title_recom.predict(test_without_review_title_recom).flatten()>=0.5).astype(np.int64)","07bd2884":"X_without_review_title_rating  = df_without_review_title.iloc[:, :-2]\ny_without_review_title_rating_temp = df_without_review_title.iloc[:, -2]\ny_without_review_title_rating = np.zeros((y_without_review_title_rating_temp.shape[0], 5))\ny_without_review_title_rating[np.arange(y_without_review_title_rating_temp.shape[0]), y_without_review_title_rating_temp-1] = 1","c0f5d0fb":"kfold = StratifiedKFold(n_splits=5)\nscores_without_review_title_rating = []\nfor train_idx, test_idx in kfold.split(X_without_review_title_rating, y_without_review_title_rating_temp):\n    tokenizer_witout_review_title_rating = Tokenizer(num_words=5000)\n    tokenizer_witout_review_title_rating.fit_on_texts(X_without_review_title_rating['Review'])\n    max_len = max([len(s.split()) for s in X_without_review_title_rating['Review']])\n    vocab_size = len(tokenizer.word_index) + 1\n    \n    X_without_review_title_rating_train, X_without_review_title_rating_test = X_without_review_title_rating.iloc[train_idx], X_without_review_title_rating.iloc[test_idx]\n    y_without_review_title_rating_train, y_without_review_title_rating_test = y_without_review_title_rating[train_idx], y_without_review_title_rating[test_idx]\n\n    X_without_review_title_rating_train, X_without_review_title_rating_test = prepare_without_review_title(X_without_review_title_rating_train, X_without_review_title_rating_test, tokenizer_witout_review_title_rating, max_len)\n\n    model_without_review_title_rating = tf.keras.Sequential()\n    model_without_review_title_rating.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=132, mask_zero=True))\n    model_without_review_title_rating.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(96, dropout=0.15)))\n    model_without_review_title_rating.add(tf.keras.layers.Dense(29, activation=tf.keras.layers.PReLU()))\n    model_without_review_title_rating.add(tf.keras.layers.Dropout(0.2))\n    model_without_review_title_rating.add(tf.keras.layers.Dense(5, activation='softmax'))\n    model_without_review_title_rating.compile(loss=['CategoricalCrossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n\n    model_without_review_title_rating.fit(X_without_review_title_rating_train, y_without_review_title_rating_train, epochs=55, batch_size=85, callbacks=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3))\n    \n    scores_without_review_title_rating.append(corr_metrics_rating(y_without_review_title_rating_test, model_without_review_title_rating.predict(X_without_review_title_rating_test)))\n","1884d4d6":"print(np.mean(scores_without_review_title_rating))\nprint(np.std(scores_without_review_title_rating))","9ff27385":"X_without_review_title_rating, test_without_review_title_rating = prepare_without_review_title(X_without_review_title_rating, test_without_review_title, tokenizer_witout_review_title_rating, max_len)","684d0d79":"model_without_review_title_rating = tf.keras.Sequential()\nmodel_without_review_title_rating.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=132, mask_zero=True))\nmodel_without_review_title_rating.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(96, dropout=0.15)))\nmodel_without_review_title_rating.add(tf.keras.layers.Dense(29, activation=tf.keras.layers.PReLU()))\nmodel_without_review_title_rating.add(tf.keras.layers.Dropout(0.2))\nmodel_without_review_title_rating.add(tf.keras.layers.Dense(5, activation='softmax'))\nmodel_without_review_title_rating.compile(loss=['CategoricalCrossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n\nmodel_without_review_title_rating.fit(X_without_review_title_rating, y_without_review_title_rating, epochs=55, batch_size=85, callbacks=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3))","4109d9dc":"model_without_review_title_rating.summary()","ec66b4fd":"tf.keras.utils.plot_model(model_without_review_title_rating)","10f1edd3":"submission.loc[index_without_review_title, 'Rating'] = model_without_review_title_rating.predict(test_without_review_title_rating).argmax(axis=1)+1","31eda73c":"df_with_text = pd.read_csv('..\/input\/clean-data\/df_with_text.csv', index_col=0)\ntest_with_text = pd.read_csv('..\/input\/clean-data\/test_with_text.csv', index_col=0)\nindex_with_text = test_with_text.index\ndf_with_text","ce84f525":"def prepare_with_text(X_train, X_test, tokenizer, max_len):\n    X_train_num, X_train_cat, X_train_text = X_train.loc[:, ['Age', 'Pos_Feedback_Cnt']], X_train.loc[:, ['Division', 'Department', 'Product_Category']], X_train.loc[:, 'text']\n    X_test_num, X_test_cat, X_test_text = X_test.loc[:, ['Age', 'Pos_Feedback_Cnt']], X_test.loc[:, ['Division', 'Department', 'Product_Category']], X_test.loc[:, 'text']\n    \n    # num scaler\n    scaler = StandardScaler()\n    X_train_num = scaler.fit_transform(X_train_num)\n    X_test_num = scaler.transform(X_test_num)\n    \n    # cat encoder\n    ohe = OneHotEncoder(handle_unknown='ignore')\n    X_train_cat = ohe.fit_transform(X_train_cat).toarray()\n    X_test_cat = ohe.transform(X_test_cat).toarray()\n    \n    # text\n    X_train_text = tokenizer.texts_to_sequences(X_train_text)\n    X_test_text = tokenizer.texts_to_sequences(X_test_text)\n    X_train_text = pad_sequences(X_train_text, maxlen=max_len, padding='post')\n    X_test_text = pad_sequences(X_test_text, maxlen=max_len, padding='post')\n    \n    \n    #X_train = np.hstack((X_train_num, X_train_cat, X_train_text))\n    #X_test = np.hstack((X_test_num, X_test_cat, X_test_text))\n    return X_train_text, X_test_text\n    return X_train_text, X_test_text","14efac9b":"X_with_text_recom = df_with_text.iloc[:, [0, 1, 2, 3, 4, 7]]\ny_with_text_recom = df_with_text.iloc[:, -2]","e3319ba3":"scores_with_text_recom = []\nkfolds = StratifiedKFold(5)\nfor train_idx, test_idx in kfolds.split(X_with_text_recom, y_with_text_recom):\n    tokenizer = Tokenizer(num_words=5000)\n    tokenizer.fit_on_texts(X_with_text_recom['text'])\n    max_len = max([len(s.split()) for s in X_with_text_recom['text']])\n    vocab_size = len(tokenizer.word_index) + 1\n    \n    X_with_text_recom_train, X_with_text_recom_test = X_with_text_recom.iloc[train_idx], X_with_text_recom.iloc[test_idx]\n    y_with_text_recom_train, y_with_text_recom_test = y_with_text_recom.iloc[train_idx], y_with_text_recom.iloc[test_idx]\n    X_with_text_recom_train, X_with_text_recom_test = prepare_with_text(X_with_text_recom_train, X_with_text_recom_test, tokenizer, max_len)\n   \n    model_with_text_recom = tf.keras.Sequential()\n    model_with_text_recom.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=96, mask_zero=True))\n    model_with_text_recom.add((tf.keras.layers.LSTM(14, dropout=0.2)))\n    model_with_text_recom.add(tf.keras.layers.Dense(8, activation=tf.keras.layers.ReLU()))\n    model_with_text_recom.add(tf.keras.layers.Dropout(0.2))\n    model_with_text_recom.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n    model_with_text_recom.compile(loss=['binary_crossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n\n    \n    history = model_with_text_recom.fit(X_with_text_recom_train, y_with_text_recom_train, epochs=26, batch_size=53)\n\n    scores_with_text_recom.append(corr_metrics_recom(y_with_text_recom_test, model_with_text_recom.predict(X_with_text_recom_test)))\n    ","cbc9d2b2":"print(np.mean(scores_with_text_recom))\nprint(np.std(scores_with_text_recom))","7f0b5e91":"X_with_text_recom, test_with_text_recom = prepare_with_text(X_with_text_recom, test_with_text, tokenizer, max_len)","cfd98a25":"model_with_text_recom = tf.keras.Sequential()\nmodel_with_text_recom.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=96, mask_zero=True))\nmodel_with_text_recom.add((tf.keras.layers.LSTM(14, dropout=0.2)))\nmodel_with_text_recom.add(tf.keras.layers.Dense(8, activation=tf.keras.layers.ReLU()))\nmodel_with_text_recom.add(tf.keras.layers.Dropout(0.2))\nmodel_with_text_recom.add(tf.keras.layers.Dense(1, activation='sigmoid'))\nmodel_with_text_recom.compile(loss=['binary_crossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n\nhistory = model_with_text_recom.fit(X_with_text_recom, y_with_text_recom, epochs=26, batch_size=53)\n","72e32b43":"model_with_text_recom.summary()","50d209ae":"tf.keras.utils.plot_model(model_with_text_recom)","14539091":"submission.loc[index_with_text, 'Recommended'] = (model_with_text_recom.predict(test_with_text_recom) >= 0.5).astype(np.int64).flatten()","332691ee":"X_with_text_rating  = df_with_text.iloc[:, [0, 1, 2, 3, 4, 7]]\ny_with_text_rating_temp = df_with_text.iloc[:, -3]\ny_with_text_rating = np.zeros((y_with_text_rating_temp.shape[0], 5))\ny_with_text_rating[np.arange(y_with_text_rating_temp.shape[0]), y_with_text_rating_temp-1] = 1","e589989b":"kfold = StratifiedKFold(n_splits=5)\nscores_with_text_rating = []\nfor train_idx, test_idx in kfold.split(X_with_text_rating, y_with_text_rating_temp):\n    tokenizer_with_text_rating = Tokenizer(num_words=5000)\n    tokenizer_with_text_rating.fit_on_texts(X_with_text_rating['text'])\n    max_len = max([len(s.split()) for s in X_with_text_rating['text']])\n    vocab_size = len(tokenizer.word_index) + 1\n    \n    X_with_text_rating_train, X_with_text_rating_test = X_with_text_rating.iloc[train_idx], X_with_text_rating.iloc[test_idx]\n    y_with_text_rating_train, y_with_text_rating_test = y_with_text_rating[train_idx], y_with_text_rating[test_idx]\n\n    X_with_text_rating_train, X_with_text_rating_test = prepare_with_text(X_with_text_rating_train, X_with_text_rating_test, tokenizer_with_text_rating, max_len)\n\n    model_with_text_rating = tf.keras.Sequential()\n    model_with_text_rating.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=66, mask_zero=True))\n    model_with_text_rating.add((tf.keras.layers.LSTM(16, dropout=0.2)))\n    model_with_text_rating.add(tf.keras.layers.Dense(8, activation=tf.keras.layers.ReLU()))\n    model_with_text_rating.add(tf.keras.layers.Dropout(0.2))\n    model_with_text_rating.add(tf.keras.layers.Dense(5, activation='softmax'))\n    model_with_text_rating.compile(loss=['CategoricalCrossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n\n    model_with_text_rating.fit(X_with_text_rating_train, y_with_text_rating_train, epochs=25, batch_size=50, callbacks=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3))\n    \n    scores_with_text_rating.append(corr_metrics_rating(y_with_text_rating_test, model_with_text_rating.predict(X_with_text_rating_test)))","22861ac2":"print(np.mean(scores_with_text_rating))\nprint(np.std(scores_with_text_rating))","71e7ee8c":"X_with_text_rating, test_with_text_rating = prepare_with_text(X_with_text_rating, test_with_text, tokenizer, max_len)","c67b0138":"model_with_text_rating = tf.keras.Sequential()\nmodel_with_text_rating.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=66, mask_zero=True))\nmodel_with_text_rating.add((tf.keras.layers.LSTM(16, dropout=0.2)))\nmodel_with_text_rating.add(tf.keras.layers.Dense(8, activation=tf.keras.layers.ReLU()))\nmodel_with_text_rating.add(tf.keras.layers.Dropout(0.2))\nmodel_with_text_rating.add(tf.keras.layers.Dense(5, activation='softmax'))\nmodel_with_text_rating.compile(loss=['CategoricalCrossentropy'], optimizer = tf.keras.optimizers.Adamax(learning_rate=lr_schedule))\n\nmodel_with_text_rating.fit(X_with_text_rating_train, y_with_text_rating_train, epochs=25, batch_size=50, callbacks=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3))","648dc05f":"model_with_text_rating.summary()","e5fc6484":"tf.keras.utils.plot_model(model_with_text_rating)","1b8cbdd8":"submission.loc[index_with_text, 'Rating'] = model_with_text_rating.predict(test_with_text_rating).argmax(axis=1)+1","8dbba0c7":"### Rating Without Text","3f66ec8d":"### Recommendation Without Review Title","355c0b84":"### Rating With Text","a9abfe19":"**Begin**","7f46c688":"### Recommendation With Text","3dffbb30":"**With Text**","621ba945":"Model explanation","3ca5dd72":"### Recommendation Without Text","a93fa722":"**Train Without Text**","4a59df09":"Creating custom Spearman correlation metrics","6d3b8964":"### Rating Without Review Title","6928f675":"**Without Review Title**","fb5e9e80":"Model explanation"}}