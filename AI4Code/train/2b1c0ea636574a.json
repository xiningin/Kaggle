{"cell_type":{"a4196b67":"code","22043acd":"code","c2b6566d":"code","8bc0eea2":"code","08d534b5":"code","1f892bd0":"code","4378cb3e":"code","d3baf041":"code","e499f541":"code","786a560e":"code","ca1d4997":"code","6a71c392":"code","26074655":"code","ca35bdd7":"code","9aa82715":"code","52f317ef":"code","4cac8fec":"code","7b3c6449":"code","755886b9":"code","ebb60c98":"code","0eec3577":"code","b301f118":"code","6c9cb04d":"code","351d76a3":"code","021cd740":"code","e2f8221e":"code","c055dc02":"code","bc4ee5c3":"code","65ac3c75":"markdown","4c49f9dc":"markdown","67b492d8":"markdown","0ebac036":"markdown","904fabde":"markdown","e89979c7":"markdown","29325eec":"markdown","ec4947ea":"markdown","d74f1da1":"markdown","984b6df6":"markdown","9a1a471b":"markdown"},"source":{"a4196b67":"!pip install xgboost","22043acd":"!pip install feature-engine","c2b6566d":"!pip install lazypredict","8bc0eea2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08d534b5":"data = pd.read_csv('..\/input\/forest-cover-type-prediction\/train.csv')\ndata.head(5)","1f892bd0":"from sklearn.base import BaseEstimator, TransformerMixin\nclass DistanceTransformer(BaseEstimator, TransformerMixin):\n    # TODO create a tranformer that do its for any numeric variables in a pandas dataframe\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X['EuclideanDistanceHidroloy'] = np.around(\n            np.sqrt(X['Horizontal_Distance_To_Hydrology'] **2 +\n                    X['Vertical_Distance_To_Hydrology'] **2), \n            4)\n        X['Elevation_Vertical_Hydro_Minus'] = X['Elevation'] - X['Vertical_Distance_To_Hydrology']\n        X['Elevation_Vertical_Hydro_Plus'] = X['Elevation'] + X['Vertical_Distance_To_Hydrology']\n        X['Elevation_Vertical_Hydro_Prod'] = X['Elevation'] * X['Vertical_Distance_To_Hydrology']\n        \n        X['Elevation_Horizontal_Hydro_Minus'] = X['Elevation'] - X['Horizontal_Distance_To_Hydrology']\n        X['Elevation_Horizontal_Hydro_Plus'] = X['Elevation'] + X['Horizontal_Distance_To_Hydrology']\n        X['Elevation_Horizontal_Hydro_Prod'] = X['Elevation'] * X['Horizontal_Distance_To_Hydrology']\n        \n        X['Elevation_Horizontal_Fire_Minus'] = X['Elevation'] - X['Horizontal_Distance_To_Fire_Points']\n        X['Elevation_Horizontal_Fire_Plus'] = X['Elevation'] + X['Horizontal_Distance_To_Fire_Points']\n        X['Elevation_Horizontal_Fire_Prod'] = X['Elevation'] * X['Horizontal_Distance_To_Fire_Points']\n        \n        X['Elevation_Horizontal_Roadways_Minus'] = X['Elevation'] - X['Horizontal_Distance_To_Roadways']\n        X['Elevation_Horizontal_Roadways_Plus'] = X['Elevation'] + X['Horizontal_Distance_To_Roadways']\n        X['Elevation_Horizontal_Roadways_Prod'] = X['Elevation'] * X['Horizontal_Distance_To_Roadways']\n                \n        X['Hidrology_Horizonal_Fire_Minus'] = X['Horizontal_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Horizonal_Fire_Plus'] = X['Horizontal_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Horizonal_Fire_Prod'] = X['Horizontal_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Fire_Points']\n        \n        X['Hidrology_Horizonal_Roadways_Minus'] = X['Horizontal_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Horizonal_Roadways_Plus'] = X['Horizontal_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Horizonal_Roadways_Prod'] = X['Horizontal_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Roadways']\n        \n        X['Hidrology_Horizonal_Vertical_Minus'] = X['Horizontal_Distance_To_Hydrology'] - X['Vertical_Distance_To_Hydrology']\n        X['Hidrology_Horizonal_Vertical_Plus'] = X['Horizontal_Distance_To_Hydrology'] + X['Vertical_Distance_To_Hydrology']\n        X['Hidrology_Horizonal_Vertical_Prod'] = X['Horizontal_Distance_To_Hydrology'] * X['Vertical_Distance_To_Hydrology']\n        \n        X['Hidrology_Vertical_Fire_Minus'] = X['Vertical_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Vertical_Fire_Plus'] = X['Vertical_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Fire_Points']\n        X['Hidrology_Vertical_Fire_Prod'] = X['Vertical_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Fire_Points']\n        \n        X['Hidrology_Vertical_Fire_Minus'] = X['Vertical_Distance_To_Hydrology'] - X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Vertical_Fire_Plus'] = X['Vertical_Distance_To_Hydrology'] + X['Horizontal_Distance_To_Roadways']\n        X['Hidrology_Vertical_Fire_Prod'] = X['Vertical_Distance_To_Hydrology'] * X['Horizontal_Distance_To_Roadways']\n        \n        X.drop(['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points'], axis=1, inplace=True)\n        return X","4378cb3e":"class DropIdentifierFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X.drop('Id', axis=1, inplace=True)\n        return X","d3baf041":"from sklearn.utils.validation import check_is_fitted\n\nclass FromDummiesToCategories(BaseEstimator, TransformerMixin):\n    def __init__(self, cols_to_operate, new_column_name):\n        self.cols_to_operate = cols_to_operate\n        self.new_column_name = new_column_name\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X1 = pd.DataFrame(X[self.cols_to_operate])\n        serie = X1.columns[np.where(X1!=0)[1]]\n        X[self.new_column_name] = serie\n        X.drop(self.cols_to_operate, axis=1, inplace=True)\n        return X","e499f541":"class AspectTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, column, new_name):\n        self.column = column\n        self.new_name = new_name\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X[self.new_name] = X[self.column].copy().apply(self._reclassify_aspect)\n        X.drop(self.column, axis=1, inplace=True)\n        return X\n        \n    def _reclassify_aspect(self, x):\n        if x<0:\n            return 'Flat'\n        if  0 >= x < 45:\n            return 'North'\n        if 45 >= x < 90:\n            return 'North_East'\n        if 90 >= x < 135:\n            return 'East'\n        if 135 >= x < 180:\n            return 'South_East'\n        if 180 >= x < 225:\n            return 'South'\n        if 225 >= x < 270:\n            return 'South_West'\n        if 270 >= x < 315:\n            return 'West'\n        if 315 >= x <360:\n            return 'North_West'\n        if 360 >= x :\n            return 'North_West'","786a560e":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\nX = data.drop('Cover_Type', axis=1).copy()\ny = data['Cover_Type'].copy()\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]","ca1d4997":"soil_columns = [x for x in X.columns if x.startswith('Soil_Type')]\nwilder_columns = [x for x in X.columns if x.startswith('Wilder')]","6a71c392":"from feature_engine.discretisation import EqualWidthDiscretiser, EqualFrequencyDiscretiser\nfrom feature_engine.selection  import DropConstantFeatures, DropDuplicateFeatures, DropCorrelatedFeatures, SelectBySingleFeaturePerformance, RecursiveFeatureElimination, SmartCorrelatedSelection, DropFeatures \nfrom feature_engine.encoding import RareLabelEncoder, OneHotEncoder, OrdinalEncoder\nfrom feature_engine.outliers import Winsorizer\nfrom feature_engine.creation import MathematicalCombination\nfrom sklearn.pipeline import Pipeline","26074655":"pipeline_list_1 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dd', DropDuplicateFeatures()),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness', 'Orientation'])),\n    ('dteq', EqualFrequencyDiscretiser(q=10, variables=['EuclideanDistanceHidroloy',                                                   \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),\n    ('dcf', DropCorrelatedFeatures(variables=None, method='pearson', threshold=0.80)),    \n]   \npipeline_1 = Pipeline(pipeline_list_1)\nX_train_pipe_1 = pipeline_1.fit_transform(X_train)\nX_train_pipe_1.head()","ca35bdd7":"X_test_pipe_1 = pipeline_1.transform(X_test)\nX_test_pipe_1.head()","9aa82715":"pipeline_list_2 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dd', DropDuplicateFeatures()),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness', 'Orientation'])),\n    ('winds', Winsorizer(variables=['EuclideanDistanceHidroloy',  'Elevation',                                                 \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dcf', DropCorrelatedFeatures(variables=None, method='pearson', threshold=0.80)),    \n]   \npipeline_2 = Pipeline(pipeline_list_2)\nX_train_pipe_2 = pipeline_2.fit_transform(X_train)\nX_train_pipe_2.head()","52f317ef":"\npipeline_list_3 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness', 'Orientation'])),\n    ('winds', Winsorizer(variables=['EuclideanDistanceHidroloy',  'Elevation',                                                 \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dd', SmartCorrelatedSelection()),  \n]   \npipeline_3 = Pipeline(pipeline_list_3)\nX_train_pipe_3 = pipeline_3.fit_transform(X_train)\nX_train_pipe_3.head()","4cac8fec":"pipeline_list_4 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('dropwild_soil',DropFeatures(soil_columns + wilder_columns)),\n    ('aspect', AspectTransformer(column='Aspect', new_name='Orientation')),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dt', DistanceTransformer()),\n    ('one_hot',OneHotEncoder(variables=['Orientation'])),\n    ('winds', Winsorizer(variables=[\n        'EuclideanDistanceHidroloy',  'Elevation', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dd', SmartCorrelatedSelection()),  \n]   \npipeline_4 = Pipeline(pipeline_list_4)\nX_train_pipe_4 = pipeline_4.fit_transform(X_train)\nX_train_pipe_4.head()","7b3c6449":"pipeline_list_5 = [\n    ('dropuniquefeatures', DropIdentifierFeatures()),\n    ('soil_columns_dummies', FromDummiesToCategories(cols_to_operate=soil_columns, new_column_name='Soil_Type')),\n    ('wilder_columns_dummies', FromDummiesToCategories(cols_to_operate=wilder_columns, new_column_name='Wilderness')),\n    ('soil_rare', RareLabelEncoder(tol=0.05, variables=['Soil_Type'])),\n    ('dp', DropConstantFeatures(tol=0.99)),\n    ('dt', DistanceTransformer()),\n     ('one_hot',OneHotEncoder(variables=['Soil_Type', 'Wilderness'])),\n    ('winds', Winsorizer(variables=['EuclideanDistanceHidroloy',  'Elevation',                                                 \n                                                       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm'])),    \n    ('dd', SmartCorrelatedSelection()),  \n]   \npipeline_5 = Pipeline(pipeline_list_5)\nX_train_pipe_5 = pipeline_5.fit_transform(X_train)\nX_train_pipe_5.head()","755886b9":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\npipe_list_1_rf = [('rf', RandomForestClassifier(random_state=42))]\npipe_1_rf = Pipeline(pipeline_list_1 + pipe_list_1_rf)\nrfpg1 ={\n    'rf__n_estimators': [100, 150, 200],\n    'rf__max_depth': [60,80, None],\n    'rf__min_samples_split': [2, 3, 4],\n}\ngrid1_pipe_1 = GridSearchCV(pipe_1_rf, param_grid=rfpg1, cv=sss, n_jobs=-1, verbose=3)\ngrid1_pipe_1.fit(X_train, y_train)\nprint(\"Best cross-validation accuracy: {:.2f}\".format(grid1_pipe_1.best_score_)) \nprint(\"Test set score: {:.2f}\".format(grid1_pipe_1.score(X_test, y_test))) \nprint(\"Best parameters: {}\".format(grid1_pipe_1.best_params_))","ebb60c98":"from sklearn import metrics\ny_predict_pipe_1 = grid1_pipe_1.predict(X_test)\npd.DataFrame(metrics.confusion_matrix(y_test, y_predict_pipe_1, labels=y_test.unique().tolist()), columns =y_test.unique().tolist(), index = y_test.unique().tolist() )","0eec3577":"\nprint(metrics.classification_report(y_test, y_predict_pipe_1, digits=3))","b301f118":"pipe_list_2_rf = [('rf', RandomForestClassifier(random_state=42))]\npipe_2_rf = Pipeline(pipeline_list_2 + pipe_list_2_rf)\nrfpg2 ={\n    'rf__n_estimators': [100, 150, 200],\n    'rf__max_depth': [60,80, None],\n    'rf__min_samples_split': [2, 3, 4],\n}\ngrid1_pipe_2 = GridSearchCV(pipe_2_rf, param_grid=rfpg2, cv=sss, n_jobs=-1, verbose=3)\ngrid1_pipe_2.fit(X_train, y_train)\nprint(\"Best cross-validation accuracy: {:.2f}\".format(grid1_pipe_2.best_score_)) \nprint(\"Test set score: {:.2f}\".format(grid1_pipe_2.score(X_test, y_test))) \nprint(\"Best parameters: {}\".format(grid1_pipe_2.best_params_))","6c9cb04d":"y_predict_pipe_2 = grid1_pipe_2.predict(X_test)\npd.DataFrame(metrics.confusion_matrix(y_test, y_predict_pipe_2, labels=y_test.unique().tolist()), columns =y_test.unique().tolist(), index = y_test.unique().tolist() )","351d76a3":"print(metrics.classification_report(y_test, y_predict_pipe_2, digits=3))","021cd740":"test = pd.read_csv('..\/input\/forest-cover-type-prediction\/test.csv')\ntest.head()","e2f8221e":"\ntest['Cover_Type'] = grid1_pipe_1.predict(test)","c055dc02":"\nto_kaggle = test[['Id', 'Cover_Type']].copy()","bc4ee5c3":"\nto_kaggle.to_csv('grid1_pipe_1', index=False)","65ac3c75":"# Pipeline 4\nThis pipeline will drop Soil and wilderness columns","4c49f9dc":"# Pipeline 1","67b492d8":"# Pipeline 5\nThis pipeline will use again the coluns of wilderness and soiltype, but will not make the aspect transformation.","0ebac036":"\n# Pipeline 2\nIn this pipeline I will change some transformers as :\n\n* Outliers in Elevation will be windorized\n* EuclidianDiscanteHidrology will not be Discretized, its outliers willbe windorized.\n* Hillshade_9am will not be Discretized, its outliers will be windorized.\n* Hillshade_Noon will not be Discretized, its outliers will be windorized.\n* Hillshade_3pm will not be Discretized, its outliers will be windorized","904fabde":"# # # # Analysis of classifier\nThis classifier has problems with cover type 2 as it miss classify a large portion of the samples, specially it gets confusse class 2 with class 1","e89979c7":"# Pipeline 3\nThis pipeline is similar to pipeline2 except it uses SmartcorrelatedSelection.","29325eec":"# Evaluation Pipeline 1\n","ec4947ea":"# Custom Transformers","d74f1da1":"# Conclusion\nIm not happy with the results in this one, but im gonna stay with pipeline number 1, if in the future I have a better idea or if in my study I see somthing that is worth to try on Data Analysis I will do it in this dataset as i Really enjoy working on it.","984b6df6":"\ny_predict_pipe_1 = grid1_pipe_1.predict(X_test)","9a1a471b":"# Evaluation pipeline 2\n"}}