{"cell_type":{"9f0b6c50":"code","684e2fea":"code","12f39a86":"code","ca36995c":"code","79794784":"code","6406ee9c":"code","6a33f55e":"code","b8f3775b":"code","6debf777":"code","863a96d2":"code","50fe5dc1":"code","96ff84b8":"code","f448e70f":"code","747ed67b":"markdown","40a420a0":"markdown","db60a0c8":"markdown","a0eeb95f":"markdown","790faa9e":"markdown","e8cea083":"markdown","63a583c2":"markdown","9c420109":"markdown"},"source":{"9f0b6c50":"import numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","684e2fea":"X = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\nY = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')","12f39a86":"X.shape","ca36995c":"Y.shape","79794784":"y = np.argmax(Y, axis=1)\ny.shape","6406ee9c":"def visualize_image(image, label):\n    plt.axis('off')\n    plt.title(label)\n    plt.imshow(image)","6a33f55e":"plt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    visualize_image(X[i * 100], label=\"Label: \" + str(y[i * 100]))","b8f3775b":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)","6debf777":"inputs = tf.keras.Input(shape=(64, 64, 1))\n\nconv1 = tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu')(inputs)\npool1 = tf.keras.layers.AveragePooling2D()(conv1)\n\nconv2 = tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu')(pool1)\npool2 = tf.keras.layers.AveragePooling2D()(conv2)\n\nflatten = tf.keras.layers.Flatten()(pool2)\n\ndense1 = tf.keras.layers.Dense(units=120, activation='relu')(flatten)\ndense2 = tf.keras.layers.Dense(units=84, activation='relu')(dense1)\n\noutputs = tf.keras.layers.Dense(units=10, activation='softmax')(dense2)\n\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nprint(model.summary())","863a96d2":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        )\n    ]\n)","50fe5dc1":"plt.figure(figsize=(16, 10))\n\nepochs_range = range(len(history.history['loss']))\n\nplt.plot(epochs_range, history.history['loss'], label=\"Training Loss\")\nplt.plot(epochs_range, history.history['val_loss'], label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Training and Validation Loss Over Time\")\nplt.show()","96ff84b8":"def evaluate_model(model, X_test, y_test):\n    \n    y_pred = np.argmax(model.predict(X_test), axis=1)\n    \n    cm = confusion_matrix(y_test, y_pred)\n    clr = classification_report(y_test, y_pred)\n    \n    results = model.evaluate(X_test, y_test, verbose=0)\n    print(\"Test Loss: {:.5f}\".format(results[0]))\n    print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n    \n    plt.figure(figsize=(10, 10))\n    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","f448e70f":"evaluate_model(model, X_test, y_test)","747ed67b":"# Getting Started","40a420a0":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/NAMmwgZ9ntE","db60a0c8":"# Training","a0eeb95f":"# Modeling","790faa9e":"# Preprocessing","e8cea083":"# Results","63a583c2":"# Task for Today  \n\n***\n\n## Sign Language Digit Recognition  \n\nGiven *images of digits in sign language*, let's try to recognize which **digit** is present in a given image.\n\nWe will use a TensorFlow\/Keras CNN to make our predictions. ","9c420109":"# Visualizing Images"}}