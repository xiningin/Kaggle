{"cell_type":{"651c411f":"code","12a9e2c4":"code","8d4d4656":"code","de0691b1":"code","209ce4a6":"code","63e2b6af":"code","0f34f328":"code","c9ed5237":"code","4f06b9d2":"code","85ca6fb9":"code","bdfca430":"code","e06c1909":"code","e23fdaf6":"code","c9353cb8":"code","228c58f0":"code","f90d012a":"code","43676e0e":"code","1e8939ec":"code","ef9cfe4e":"code","daf35d55":"code","0fcf5c6c":"code","bf733f3a":"code","f48c9345":"markdown","bc015b42":"markdown","afca5d29":"markdown","c25e3100":"markdown","004eb4ec":"markdown","c33470a3":"markdown","ce99036d":"markdown","e48390ba":"markdown","24dbf452":"markdown"},"source":{"651c411f":"# Importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","12a9e2c4":"# Import data and convert time columns from string to timestamp\ndf = pd.read_csv('..\/input\/startup-investments-crunchbase\/investments_VC.csv', encoding = \"ISO-8859-1\", parse_dates=['founded_month', 'founded_quarter', 'founded_year'])","8d4d4656":"# Strip empty spacing from column headers for easier column calling\ndf.rename(columns=lambda x: x.strip(), inplace=True)","de0691b1":"df.head()","209ce4a6":"df.tail()","63e2b6af":"df.isnull().sum()","0f34f328":"# Shape of data before removing NaN rows\ndf.shape","c9ed5237":"# Remove any row with NaN as ALL column values\n# (Calling the data base affected by this command by a new name just in case there is an error)\ndata = df.dropna(how='all')","4f06b9d2":"# Shape of data after removing NaN rows\ndata.dropna(how='all').shape","85ca6fb9":"54294 - 49438","bdfca430":"data = data.dropna(how='any')","e06c1909":"data.shape","e23fdaf6":"pd.set_option('display.max_columns', 40)\ndata.head()","c9353cb8":"# Some columns are strings, some numeric and some time valued. Timestamp was already done on importing so now to make\n# sure that other columns are correct data types. Numeric columns will be converted into float data types.\ndata.dtypes","228c58f0":"# Remove all commas in funding_total_usd column\ndata['funding_total_usd']= data['funding_total_usd'].str.replace(',', '')\ndata['funding_total_usd']= data['funding_total_usd'].str.replace('-', '0')","f90d012a":"data.head()","43676e0e":"# convert whole column funding_total_usd to float data type\ndata['funding_total_usd'] = data['funding_total_usd'].astype(float)","1e8939ec":"data.head()","ef9cfe4e":"data[['state_code', 'region', 'city']]= data[['state_code', 'region', 'city']].astype(str)","daf35d55":"state_count = data['state_code'].value_counts()","0fcf5c6c":"print(f\"Minimum = {np.min(state_count)}\")\nprint(f\"Maximum = {np.max(state_count)}\")\nprint(f\"Median = {np.median(state_count)}\")\nprint(f\"Mean = {round(np.mean(state_count), 2)}\")\nprint(f\"Standard deviation = {round(np.std(state_count), 2)}\")\nprint(f\"Variance = {round(np.var(state_count), 2)}\")","bf733f3a":"state_count1 = state_count[:29,]\nstate_count2 = state_count[30:,]\n\nplt.figure(figsize=(20, 10))\nplt.subplot(211)\nplt.plot(state_count1, color='tab:blue', marker='o')\nplt.plot(state_count1, color='black')\n\nplt.subplot(212)\nplt.plot(state_count2, color='tab:blue', marker='o')\nplt.plot(state_count2, color='black')\n\nplt.show()","f48c9345":"Commas, dashes and no values removed. Now can convert column to float dtype","bc015b42":"### Correcting data types for columns to maintain consistency throughout data","afca5d29":"#### data.dtypes shows the data types of all columns. If there are a mixed data type in a column it will display 'object'. A previous run showed a ValueError that highlighted commas, dashes, no values as a problem for the funding_total_usd column.","c25e3100":"#### The most reocurring value is shown to be 4856. This gives the impression that there are 4856 rows altogether that have NaN value in all columns. Let's test this out.","004eb4ec":"For the sake of simplicity and easier for analysis. dropna will be used for all records with NaN anywhere.","c33470a3":"### A few small examples of cleaning data with pandas","ce99036d":"#### Seems to be a lot of NaN values towards the end of the data set. The next line sums up all NaN values within each column using the function 'isnull()'. Check it out:","e48390ba":"### Top and Tail of data","24dbf452":"### Calculating the sum of all NaN values within each column."}}