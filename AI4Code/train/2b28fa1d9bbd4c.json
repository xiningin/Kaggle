{"cell_type":{"ab8320d4":"code","7af9bcde":"code","5fb8c9dd":"code","5c16ffc6":"code","e3748c95":"code","704a6755":"code","c0279e81":"code","9eb3bf42":"code","fdb27598":"code","7ff3efbe":"code","588873e5":"code","99420cf0":"code","6997b035":"code","6ac72633":"code","224eef4e":"code","63e5704f":"code","0cb3a46e":"code","0fcaf0d1":"code","03190241":"code","578ec538":"code","2bfe5e6a":"code","9ccd6c9d":"code","457a40e4":"code","6283042d":"markdown","0e0ea0e1":"markdown","0715e9d4":"markdown","612483a3":"markdown","a18510ab":"markdown","74181ab0":"markdown","abc4b638":"markdown","89bc2faf":"markdown"},"source":{"ab8320d4":"import os\nimport numpy as np\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7af9bcde":"import pandas as pd","5fb8c9dd":"def weather_data(data=None):\n    \"\"\"\n    param: data a pandas dataframe \n    \n    return\n    data per month\n    \"\"\"\n    \n    cols=data[1].columns # take all columns of first row of list data\n    \n    month = data[2].iloc[0] # take month\n    m_time = data[2].iloc[1:-1] # take all data from this month\n    \n    # We create series pandas for dayofmonth\n    if month[0] == 'Jan':\n        s=pd.date_range(start='2020-01-01', periods= len(m_time) , freq='D')\n    if month[0] == 'Feb':\n        s=pd.date_range(start='2020-02-01', periods= len(m_time) , freq='D')\n        \n    if month[0] == 'Mar':\n        s=pd.date_range(start='2020-03-01', periods= len(m_time) , freq='D')\n        \n    if month[0] == 'Apr':\n        s=pd.date_range(start='2020-03-01', periods= len(m_time) , freq='D')\n        \n        \n        \n    v = [] # initialize\n    v.append(np.array(s)) # append s\n    \n    # take all data for  'Temperature (\u00c2\u00b0 F)', 'Dew Point (\u00c2\u00b0 F)', 'Humidity (%)',\n    #   'Wind Speed (mph)', 'Pressure (Hg)'\n    for i in range(3, 8):\n        c = np.array(data[i].iloc[1:-1,1]) \n        \n        v.append(c)\n        \n    last_feature = np.array(data[8].iloc[1:-1]) # columns precipitation\n    \n    v.append(last_feature)\n    \n    vdt = pd.DataFrame() # initialize \n    for i in range(len(cols)):\n        vdt[cols[i]] = v[i]\n        \n    return vdt # pandas dataframe go below to see a result","5c16ffc6":"def read_main_folder(pardir=None):\n    \"\"\"\n    param: pardir: the main path folder\n    \n    return \n    list of file in each folder\n    \n    \"\"\"\n\n    folder_file = []\n    for dirname, _, filenames in os.walk(pardir):\n        gv = []\n        for filename in filenames:\n            gv.append(os.path.join(dirname, filename))\n    \n        if gv == []: # to avoid an empty list\n            pass\n        else:\n            folder_file.append(gv)\n    \n    return folder_file # see the result below","e3748c95":"def concatenate_and_save_data(folder=None):\n    \"\"\"\n    param: folder: take a path html file\n    \n    return\n    read each html file after concatenate all data per month and then save to csv file\n    \n    \"\"\"\n    \n    value = []\n    cities = ['cairo-egypt','new-york','tehraniran','tokyo-japan','milan-italy']\n    for f in folder:\n        dc = pd.read_html(f)\n        bc = weather_data(data=dc)\n    \n        value.append(bc)\n        \n    con_data = pd.concat(value)\n    print(f)\n        \n    for item in cities:\n        if item in f:\n            city = item #input('Give a city name correspond to this data \u00a7\u00a7\\n')\n    \n            datasets = 'data_'\n    \n            save = datasets + city + '_weather.csv'\n        \n            con_data.to_csv(save, index=False)\n            print('Saving data is done for {} !\\n'.format(item))\n    \n    #return con_data","704a6755":"# take html file\nhtml_file = '\/kaggle\/input\/tokyo-japan\/Tokyo Japan Weather History _ Weather Underground (2020-04-04 17_37_31).html'\nhtml_1 = '\/kaggle\/input\/tehraniran\/Tehran Iran Weather History _ Weather Underground (2020-04-04 17_34_08).html'\nhtml_2 = '\/kaggle\/input\/new-york\/New York City NY Weather History _ Weather Underground (2020-03-24 11_04_39).html'","c0279e81":"if 'new-york' in html_2:\n    print('yes')\nelse:\n    print('no')","9eb3bf42":"df = pd.read_html(html_file) # extract unstructured data from html file using pandas for Tokyo-Japan\ndu = pd.read_html(html_2) # extract unstructured data from html file using pandas for New York City \nds = pd.read_html(html_1)# extract unstructured data from html file using pandas for Tehran-Iran","fdb27598":"# see the type of our unstructured data\ntype(df)","7ff3efbe":"# size\nlen(df) # ","588873e5":"# eda\ndf[1].head(3) # the first row ","99420cf0":"df[1].columns # columns of first row","6997b035":"df[2].head(3) # the second row that are a month","6ac72633":"#see name of month\ndf[2].iloc[0]","224eef4e":"df[3:] # this is a data for all columns above that contains Max, Avg and Min value. \n#For us, we are taking only Avg value of each columns. To get all this data we need to use weather_data function. \n# Go to create function section above. to explain the function","63e5704f":"# result for Tokyo Japan\nweather_data(data=df).head(3) # this is for weather data function","0cb3a46e":"# result for New York City\nweather_data(data=du).head(3)","0fcaf0d1":"# result for Tehran Iran\nweather_data(data=ds).head(3)","03190241":"# now we have a weather data function. we cannot take data for each html file like that we need to define\n#a function that can read all file to put it in the list. go above. ","578ec538":"dir_parent = '\/kaggle\/input'\ndocs = read_main_folder(pardir=dir_parent)","2bfe5e6a":"docs # see the last function above","9ccd6c9d":"dir_parent = '\/kaggle\/input'\ndocs = read_main_folder(pardir=dir_parent)","457a40e4":"# save data for each subfolders\nfor fk in docs:\n    concatenate_and_save_data(folder=fk)","6283042d":"# Extract weather data\n\nWe create three functions:\n\n>read_main_folder: this function read all html file containing in the main folder\n\n>concatenate_and_save_date: this function take all data of five different cities and save it\n\n> weather_data: this function extract the data from pandas dataframe\n\nwe are do some test to see how all theses function work.","0e0ea0e1":"website: https:\/\/www.wunderground.com\/history\/monthly\/jp\/tokyo\/RJTT\/date\/2020-2","0715e9d4":"**Now, you know how extract and save data from html file after you are downloading in the website **  ","612483a3":"## Upvote,download and share this notebook for your own using.\n## Tank you!","a18510ab":"# All together\n\nNow we put all together and see a result","74181ab0":"## create function\n\n**pass this section. read below after come back.**","abc4b638":"## EDA: Test \n\nBefore using these 3 functions, we need to know how are our data. let's go.","89bc2faf":"# Extract data from html file using pandas\n\nSometime, we need data but data are not in structured form (csv, excel, ... ). Web have several unstructured data that we need to use. Some data have an api keys but other data have not an api keys. To provide these data, we use web scraping method. In this notebook we are not using this method but we will use alternative method that I call it  **extracting data from html file**.\n\nWhen we make web scraping, sometime you cannot get data because server give you an answer **HTTP Error 403: Forbidden**. From this answer, we want to get that data. *How can get it*, the answer is just downloading a html file of this data after extract it.\n\nIn this tutorial, we extract data from weather data html file for five cities of five different country.\n\nwebsite: https:\/\/www.wunderground.com\/ "}}