{"cell_type":{"879492d8":"code","9a3b6905":"code","71a7058f":"code","079d9458":"code","5696dcb4":"code","0effe0de":"code","a3dbfe52":"code","7b766a4b":"code","45cb4696":"code","2b3ee410":"code","e87876cd":"code","30b78da5":"code","4d93bb3f":"code","e38b89b9":"code","5e0a64ea":"code","196874b2":"code","b95d3187":"code","3e460d0c":"code","1fd79e81":"code","1d552278":"code","1ed8fd45":"code","f32cec97":"code","6265f683":"code","671103ec":"code","550a1b3c":"code","49325b12":"code","63ad2772":"code","0513a393":"code","43eb8035":"markdown","942f2c7f":"markdown","27d97250":"markdown","0dde2fa1":"markdown","7d49305d":"markdown","1a30b3a3":"markdown"},"source":{"879492d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9a3b6905":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline","71a7058f":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ReduceLROnPlateau # Reduce learning rate when a metric has stopped improving.\nfrom sklearn.model_selection import train_test_split","079d9458":"# Load the data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","5696dcb4":"train.head() ","0effe0de":"train.info()","a3dbfe52":"test.head()","7b766a4b":"test.info()","45cb4696":"X_train=train.drop('label',axis=1)\ny_train=train['label']","2b3ee410":"sns.countplot(x=y_train)\ny_train.value_counts()","e87876cd":"# checking for null values\nX_train.isnull().any().value_counts()","30b78da5":"test.isnull().any().value_counts()","4d93bb3f":"print('max value in one digit matrix',X_train.iloc[0].max())\nprint('min value in one digit matrix' , X_train.iloc[1].min())","e38b89b9":"#Normalization the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0","5e0a64ea":"X_train.shape","196874b2":"# reshapping image in three dimension\nX_train = X_train.values.reshape(-1,28,28,1) # -1 it is an unknown dimension and we want numpy to figure it out.it is length of array\ntest = test.values.reshape(-1,28,28,1)","b95d3187":"print('shape of full data', X_train.shape)\nprint('shape of one digit', X_train[0].shape)","3e460d0c":"# applying ONE-HOT-ENCODING\ny_train=to_categorical(y_train,num_classes=10)","1fd79e81":"# splitting the data into training and validation data\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)","1d552278":"#initialzing the model\nmodel=Sequential()\n\n# first Convolution layer\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\n\n# Second Convoultion layer\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n\n#polling the layers\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# third Convolution layer\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n# fourth Convoultion layer\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n\n# Second polling layer\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# flattening the output from Convolution and polling layers\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","1ed8fd45":"# Define the optimizer\noptimizer = RMSprop()\n# compling the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# decreases the learning rate during training\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \n                                            factor=0.5, min_lr=0.00001)","f32cec97":"# vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train) #Only required if featurewise_center or featurewise_std_normalization or zca_whitening are set to True.","6265f683":"batch_size=30\nnb_train=len(X_train)\nnb_val=len(X_val)","671103ec":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = 20,verbose = 1, \n                              steps_per_epoch=nb_train \/\/ batch_size, \n                              validation_data = (X_val,y_val),\n                              validation_steps=nb_val\/\/batch_size\n                              ,callbacks=[learning_rate_reduction])\nmodel.save('Digit_recognizer.h5')\nmodel.save_weights('Weight_file_for_Digit_recognizer.h5')","550a1b3c":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","49325b12":"prob_pred= model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(prob_pred,axis = 1)","63ad2772":"for i in range(10):\n    plt.imshow(test[i].reshape(28,28),cmap='gray')\n    plt.title('Predicted {}'.format(results[i]))\n    plt.show()","0513a393":"results = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"my_submission.csv\",index=False)","43eb8035":"## Predicting the result","942f2c7f":"If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a shape of [-1] flattens into 1-D. At most one component of shape can be -1.\n                                                           \n[https:\/\/docs.scipy.org\/doc\/numpy-1.10.4\/reference\/generated\/numpy.reshape.html](http:\/\/)","27d97250":"## DATA AUGMENTATION","0dde2fa1":"## Building the model","7d49305d":"## Defining the optimizer","1a30b3a3":"# Visualizing the result"}}