{"cell_type":{"f668caca":"code","f22aab3f":"code","49c75b95":"code","38b5e253":"code","10f43dd4":"code","5906531f":"code","9b31dd75":"code","ba905218":"code","b3bf7c0a":"code","fb3b5fde":"code","e6b320a8":"code","3257d3ab":"code","3a6ec0a1":"code","170fa125":"code","33251c56":"code","04cdc625":"code","8c4f084f":"code","fb0cda5f":"code","c8d000d9":"code","c62a1ce1":"code","45a93710":"code","5b97fb69":"code","2c0d8152":"code","82aa8702":"code","7c62da2e":"code","4463b38a":"code","34a8e5a4":"code","c61f2b80":"code","d53ed9f7":"code","16d05781":"markdown","f4e41cd4":"markdown","092ac00d":"markdown","2f176df3":"markdown"},"source":{"f668caca":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = [16, 8]\n\nprint('Using Tensorflow version:', tf.__version__)","f22aab3f":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","49c75b95":"# !ls \/kaggle\/input","38b5e253":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('shopee-product-detection-student')\n\n# Configuration\nEPOCHS = 32\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","10f43dd4":"train_df = pd.read_csv('..\/input\/after-cleaned\/image_cleaned.csv')\ntest_df = pd.read_csv('..\/input\/shopee-product-detection-student\/test.csv')\n\ntrain_df.shape, test_df.shape","5906531f":"train_df.head()","9b31dd75":"def show_train_img(category):\n    \n    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(24, 10))\n    \n    train_path = '\/kaggle\/input\/shopee-product-detection-open\/train\/train\/train\/'\n    ten_random_samples = pd.Series(os.listdir(os.path.join(train_path, category))).sample(10).values\n    \n    for idx, image in enumerate(ten_random_samples):\n        final_path = os.path.join(train_path, category, image)\n        img = cv2.imread(final_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axes.ravel()[idx].imshow(img)\n        axes.ravel()[idx].axis('off')\n    plt.tight_layout()","ba905218":"def show_test_img():\n    \n    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(24, 10))\n    \n    test_path = '\/kaggle\/input\/shopee-product-detection-open\/test\/test\/test\/'\n    ten_random_samples = pd.Series(os.listdir(test_path)).sample(10).values\n    \n    for idx, image in enumerate(ten_random_samples):\n        final_path = os.path.join(test_path, image)\n        img = cv2.imread(final_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axes.ravel()[idx].imshow(img)\n        axes.ravel()[idx].axis('off')\n    plt.tight_layout()","b3bf7c0a":"# pick random samples\n\ndataset_path = {}\n\ncategories = np.sort(train_df['category_2'].unique())\n\nfor cat in categories:\n    try:\n        dataset_path[cat] = train_df[train_df['category_2'] == cat]['filename'].sample(2400)\n    except:\n        dataset_path[cat] = train_df[train_df['category_2'] == cat]['filename'].sample(frac=1.)","fb3b5fde":"dataset_path[0]","e6b320a8":"category_list = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09',\n                 '10', '11', '12', '13', '14', '15', '16', '17', '18', '19',\n                 '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n                 '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',\n                 '40', '41']","3257d3ab":"train_paths = []\n\nfor idx, key in enumerate(dataset_path.keys()):\n    if key == idx:\n        for path in dataset_path[idx]:\n            train_paths.append(os.path.join(GCS_DS_PATH, 'train', 'train', 'train', category_list[idx], path))","3a6ec0a1":"len(train_paths)","170fa125":"labels = []\n\nfor label in dataset_path.keys():\n    labels.extend([label] * len(dataset_path[label]))\n    \nlen(labels)","33251c56":"from tensorflow.keras.utils import to_categorical\n\n# convert to numpy array\ntrain_paths = np.array(train_paths)\n\n# convert to one-hot-encoding-labels\ntrain_labels = to_categorical(labels)","04cdc625":"# from sklearn.model_selection import train_test_split\n\n# train_paths, valid_paths, train_labels, valid_labels = train_test_split(train_paths, \n#                                                                         train_labels, \n#                                                                         stratify=train_labels,\n#                                                                         test_size=0.1, \n#                                                                         random_state=2020)\n\n# train_paths.shape, valid_paths.shape, train_labels.shape, valid_labels.shape","8c4f084f":"test_paths = []\n\nfor path in test_df['filename']:\n    test_paths.append(os.path.join(GCS_DS_PATH,  'test', 'test', 'test', path))\n    \ntest_paths = np.array(test_paths)","fb0cda5f":"def decode_image(filename, label=None, image_size=(380, 380)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","c8d000d9":"def data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, max_delta=0.5)\n    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n#     image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n#     image = tf.image.random_hue(image, max_delta=0.2)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","c62a1ce1":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .cache()\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\n# valid_dataset = (\n#     tf.data.Dataset\n#     .from_tensor_slices((valid_paths, valid_labels))\n#     .map(decode_image, num_parallel_calls=AUTO)\n#     .batch(BATCH_SIZE)\n#     .cache()\n#     .prefetch(AUTO)\n# )\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","45a93710":"%%time\n!pip install -q efficientnet","5b97fb69":"from tensorflow.keras.layers import Dense\nfrom efficientnet.tfkeras import EfficientNetB4","2c0d8152":"import keras.backend as K\n\ndef categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.25,ls=0.1, classes=42.0):\n    \"\"\"\n    Implementation of Focal Loss from the paper in multiclass classification\n    Formula:\n        loss = -alpha*((1-p)^gamma)*log(p)\n        y_ls = (1 - \u03b1) * y_hot + \u03b1 \/ classes\n    Parameters:\n        alpha -- the same as wighting factor in balanced cross entropy\n        gamma -- focusing parameter for modulating factor (1-p)\n        ls    -- label smoothing parameter(alpha)\n        classes     -- No. of classes\n    Default value:\n        gamma -- 2.0 as mentioned in the paper\n        alpha -- 0.25 as mentioned in the paper\n        ls    -- 0.1\n        classes     -- 4\n    \"\"\"\n    def focal_loss(y_true, y_pred):\n        # Define epsilon so that the backpropagation will not result in NaN\n        # for 0 divisor case\n        epsilon = K.epsilon()\n        # Add the epsilon to prediction value\n        #y_pred = y_pred + epsilon\n        #label smoothing\n        y_pred_ls = (1 - ls) * y_pred + ls \/ classes\n        # Clip the prediction value\n        y_pred_ls = K.clip(y_pred_ls, epsilon, 1.0-epsilon)\n        # Calculate cross entropy\n        cross_entropy = -y_true*K.log(y_pred_ls)\n        # Calculate weight that consists of  modulating factor and weighting factor\n        weight = alpha * y_true * K.pow((1-y_pred_ls), gamma)\n        # Calculate focal loss\n        loss = weight * cross_entropy\n        # Sum the losses in mini_batch\n        loss = K.sum(loss, axis=1)\n        return loss\n    \n    return focal_loss","82aa8702":"%%time\n\nwith strategy.scope():\n    model = tf.keras.Sequential([\n        EfficientNetB4(weights='imagenet', # noisy-student\n                       include_top=False,\n                       pooling='avg'), # max\n        Dense(42, activation='softmax')\n    ])\n    \n    model.layers[0].trainable = False\n    \n    model.compile(optimizer = 'adam',\n                  loss = categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=42.0), # num classes\n                  metrics=['accuracy'])\n    \n    model.summary()","7c62da2e":"n_steps = train_labels.shape[0] \/\/ BATCH_SIZE  # 86428 \/ 128 = 675\n\nhistory = model.fit(\n    train_dataset, \n    steps_per_epoch=n_steps,\n    # validation_data=valid_dataset,\n    epochs=2,\n)","4463b38a":"# model.save()","34a8e5a4":"# Get training and test loss histories\ntraining_loss = history.history['loss']\n# test_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, test_loss, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","c61f2b80":"test_dataset_tta = (\n        tf.data.Dataset\n        .from_tensor_slices(test_paths)\n        .map(decode_image, num_parallel_calls=AUTO)\n        .cache()\n        .map(data_augment, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n)\n\ntta_times = 5\nprobabilities = []\n\nfor i in range(tta_times+1):\n    print('TTA Number: ', i, '\\n')\n    probabilities.append(model.predict(test_dataset_tta, verbose=1))\n    \ntta_pred = np.mean(probabilities, axis=0)","d53ed9f7":"# change with prediction\ntest_df['category'] = tta_pred.argmax(axis=1)\n\n# then add zero-padding\ntest_df['category'] = test_df['category'].apply(lambda x: str(x).zfill(2))\n\ntest_df.to_csv('sub_with_tta_2.csv', index=False)","16d05781":"# **Predict**","f4e41cd4":"## Use focal loss with label smoothing","092ac00d":"> You also can use gridmask \/ cutmix \/ mixup etc for experiment","2f176df3":"<font size=\"+2\" color=\"chocolate\"><b>Pick random sample, 2400 image for each categories<\/b><\/font><br><a id=\"1\"><\/a>\n\n* I think this is not the right way, because a lot of noisy images for each category (with different resolution too)\n* We need a teamwork + time (a lot) for choose the right images to feed into training\n* Or we can do image augmentation technique for better generalization on test data\n\n> You can use the function below to check"}}