{"cell_type":{"3d4da8ef":"code","6ddb8d0b":"code","2053a106":"code","066da22c":"code","312d5f83":"markdown","3edb6f83":"markdown","4f3aa7d0":"markdown","df5b78f2":"markdown","099ded3e":"markdown","face86c1":"markdown","f4c744e1":"markdown","49a24ef4":"markdown","a2cb7111":"markdown","7f892ecf":"markdown","d91f39de":"markdown","5da169b1":"markdown"},"source":{"3d4da8ef":"import pandas as pd\n\nDict={'John Smith':['Nan',2],\n     'Jane Doe': [16,11],\n      'Mary Johnson':[3,1]\n     }\n\ndata=pd.DataFrame.from_dict(Dict,orient='index',columns=['TreatementA','TreatementB'])\ndata","6ddb8d0b":"data_transposed=data.transpose()\ndata_transposed","2053a106":"#addin new instancesto the dataset\n\nDict['Oliver']=['Nan',4]\nDict['Jack']=[10,6]\nDict['Harry']=[8,0]\nDict['Jacob']=[0,5]\nDict['Thomas']=[6,4]\nDict['George']=[4,3]\nDict['Oliiver']=['Nan',4]\nDict['Jackk']=[10,6]\nDict['Harryy']=[8,0]\nDict['Jacobb']=[0,5]\nDict['Thomass']=[6,4]\nDict['Georgee']=[4,3]\nDict['Oliiverr']=['Nan',4]\nDict['Jaackk']=[10,6]\nDict['Haarryy']=[8,0]\nDict['Jaacobb']=[0,5]\nDict['Thomaass']=[6,4]\nDict['Georrgee']=[4,3]\n\ndata=pd.DataFrame.from_dict(Dict,orient='index',columns=['TreatementA','TreatementB'])\n\ndata\n","066da22c":"data_transposed=data.transpose()\ndata_transposed","312d5f83":"References:\n    Journal of Statistical Software\/Tidy Data\n","3edb6f83":"##### Data Semantics\nA dataset is a collection of **values**, usually either numbers (if quantitative) or strings (if qualitative). Values are organised in two ways. Every value belongs to a **variable** and an observation(previously presented as tuples). \n\nA variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An **observation** contains all values measured on the same unit (like a person, or a day, or a race) across attributes.\n\n\nFor a given dataset, it\u2019s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.               \n\nIf the columns in our dataset were home phone and work phone, we could treat these as two variables, but in a fraud detection environment we might want variables phone number and number type because the use of one phone number for multiple people might suggest fraud.\n\n\nA general rule of thumb is that it is easier to describe functional relationships between variables (e.g., z is a linear combination of x and y, density is the ratio of weight to volume) than between rows, and it is easier to make comparisons between groups of observations (e.g., average of group a vs. average of group b) than between groups of columns.\n\nThe experimental design also determines whether or not missing values can be safely dropped. In this experiment, the missing value represents an observation that should have been made, but wasn\u2019t, so it\u2019s important to keep it. Structural missing values, which represent measurements that can\u2019t be made (e.g., the count of pregnant males) can be safely removed.\n","4f3aa7d0":"Note that data's raw structure is highly dependent on the way data is collected. Both structures are tehcnically valid, chosing one over the other is a matter of convention, for reasons of universality, a standardized structure is prefered. ","df5b78f2":"### **Data structure**","099ded3e":"##### \"Happy families are all alike; every unhappy family is unhappy in its own way\" -Leo Tolstoy.","face86c1":"Remember that collecting data is the process of applying certain metrics to a homogeneous population the result is in the following structure :\n\n**(Population_elements,Mesured_feature): Measurement**\n\nWithout any loss of generalization, you can think of this as a quality control of a certain workpiece. Depending on the production throughput, all or just a sample of the manufacutred workpieces must be checked for size, shape or surface finish.\nthis is made using a given instrument or metric (could be a micrometer for continuous measurement or a feeler gauge for discrete measurement), for each **(Product_i, Mesured_dimension)** we assign the measurement value:   **(Product_1,Micrometer): 22mm**.                                                      \nAll measurments of a given dimension are carried out using the same measurement tool to allow comparision as well as universality of the measurment for all users of the same tool. \n\n\nfrom this perspective, our data can be presented as follows :\n\n**(John Smith,TreatementA): Nan**                                                                         \n**(John Smith,TreatementB): 2**\n\n**(Jane Doe, TreatementA): 16**                                                          \n**(Jane Doe, TreatementB): 11**\n\n**(Mary Johnson, TreatementA): 3**                                                \n**(Mary Johnson, TreatementB): 1**\n\n### Now let's apply some structural transformations to this dataset :\n","f4c744e1":"##### Frequent messy data structures\n\nReal datasets can, and often do, violate the three precepts of tidy data in almost every way imaginable. While occasionally you do get a dataset that you can start analysing immediately, this is the exception, not the rule.\n\nThe following is a list of Frequentlty encoutred messy data structures :\n\n","49a24ef4":"\u2022 Column headers are values, not variable names.                                        \n\u2022 Multiple variables are stored in one column.                                         \n\u2022 Variables are stored in both rows and columns.                                        \n\u2022 Multiple types of observational units are stored in the same table.                                       \n\u2022 A single observational unit is stored in multiple tables.                           \n","a2cb7111":"This new presentation has the same \"quantity of information\" as the previous one.\nIn this example we have only three instances but in the real world datasets have way more instances. we will add a few instances to clarify the effect of transposing. ","7f892ecf":"Starting with this wonderful quote by Tolstoy,in this noetbook we will simply replace **'families'** with **'datasets'** and **'hapiness\/unhappiness'** with **'tidy\/messy'**. Like families, tidy datasets are all alike but every messy dataset is messy in its own way. This approach provides a standardized way to link the structure of the datasets(**its physical layout**) with its semantics (**meaning**).","d91f39de":"##### Tidy data \nTidy data is a standard way of mapping the meaning of a dataset to its structure. A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. In tidy data:\n\n1. Each variable forms a column.\n2. Each observation forms a row.\n3. Each type of observational unit forms a table.\n\nFrom this perspective, messy data is any other other arrangement of the data.\n\nTidy data makes it easy for an analyst or a computer to extract needed variables because it provides a standard way of structuring a dataset, it is also particularly well suited for vectorised programming languages, because the layout ensures that values of different variables from the same observation are always paired.\n\nWhile the order of variables(features) and observations(instances) does not affect analysis, a good ordering makes it easier to scan the raw values.  One way of organising variables is by their role in the analysis: are values fixed by the design of the data collection, or are they measured during the course of the experiment? Fixed variables describe the experimental design and are known in advance.\n\nSuppose you're making an experiment to check the **ideal gas law**           **:**                 ***PV = nRT***\n\nThe equation combines four variables, in order to obtain accurate results we must fix two of them, let the third as a variable and make measurments on the fourth.\n\nAccording to the tidy data structure, fixed variables have the priority over the others and should be placed as the first variables in the dataset. Remember that tidy data is only worthwhile if it makes analysis easier, and in our example, before dealing with measurments we must know the conditions or assumptions of the experiment.  ","5da169b1":"Data can be structured in different ways, different structures don't change data's meaning or hidden information but they can affect the information accessibility for us as humans as well as AI programs. The very raw structure of data is simply a set of tuples, let's make things clear with an example."}}