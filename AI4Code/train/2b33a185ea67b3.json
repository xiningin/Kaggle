{"cell_type":{"034634a2":"code","b11a8749":"code","a728a560":"code","ebdaaa04":"code","c78a808b":"code","b19d9a2f":"code","04fd904b":"code","aaf9eb5c":"code","c39afab7":"code","1f461aa1":"code","f51b76ae":"code","4a22e0c3":"code","81c007eb":"code","d1f9d474":"code","1ba6cc16":"code","df3b855e":"code","022120eb":"code","602ff463":"code","5ac6573b":"code","4813b5ae":"markdown","1ec25801":"markdown","c4e30225":"markdown","c12efa9a":"markdown","00588312":"markdown","56b62e80":"markdown","0949baf6":"markdown","a4421672":"markdown"},"source":{"034634a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b11a8749":"import numpy as np\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nimport torch\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport time\nimport random\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom torchvision import datasets, transforms\nimport itertools\nfrom torchvision.utils import make_grid\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.metrics.pairwise import cosine_distances\n# Set random seed for reproducibility\nmanualSeed = 999\n#manualSeed = random.randint(1, 10000) # use if you want new results\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)\nnp.random.seed(manualSeed)","a728a560":"# Encoder's block\ndef enc_conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.BatchNorm2d(out_channels),\n        nn.LeakyReLU(0.2, inplace=True)\n    )\n\n# Decoder's block\ndef dec_conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n    return nn.Sequential(\n        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(inplace=True)\n    )\n\nclass VAE(nn.Module):\n    def __init__(self, dim_code):\n        super(VAE, self).__init__()\n        self.dim_code = dim_code\n\n        self.encoder = nn.Sequential(# -> bsx3x64x64\n            nn.Conv2d(3, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2, inplace=True), # -> bsx64x32x32\n            enc_conv(64, 128, 4, 2, 1), # -> bsx128x16x16\n            enc_conv(128, 256, 4, 2, 1), # -> bsx256x8x8\n            enc_conv(256, 512, 4, 2, 1), # -> bsx512x4x4\n            enc_conv(512, 512, 4, 2, 1) # -> bsx512x2x2\n        )\n        \n        self.fc_mu = nn.Linear(512*4, dim_code) # -> bsxdim_code\n        self.fc_logsigma = nn.Linear(512*4, dim_code) # -> bsxdim_code\n        self.decoder_input = nn.Linear(dim_code, 512*4) # -> bsx512*4\n        \n        self.decoder = nn.Sequential(# -> bsx512x2x2\n            dec_conv(512, 512, 4, 2, 1), # -> bsx512x4x4\n            dec_conv(512, 256, 4, 2, 1), # -> bsx256x8x8\n            dec_conv(256, 128, 4, 2, 1), # -> bsx128x16x16\n            dec_conv(128, 64, 4, 2, 1), # -> bsx64x32x32\n            nn.ConvTranspose2d(64, 3, 4, 2, 1), # -> bsx3x64x64\n            nn.Tanh()\n        )\n\n    def encode(self, x):\n        out = self.encoder(x)\n        out = torch.flatten(out, start_dim=1)\n        mu = self.fc_mu(out)\n        logsigma = self.fc_logsigma(out)\n        return mu, logsigma\n    \n    def gaussian_sampler(self, mu, logsigma):\n        if self.training:\n            sigma = torch.exp(0.5*logsigma)\n            eps = torch.randn_like(sigma)\n            return eps*sigma + mu\n        else:\n            # output should be determined at inference time\n            return mu\n    \n    def decode(self, z):\n        recons = self.decoder_input(z)\n        recons = recons.view(-1, 512, 2, 2)\n        recons = self.decoder(recons)\n        return recons\n\n    def forward(self, x):\n        mu, logsigma = self.encode(x)\n        z = self.gaussian_sampler(mu, logsigma)\n        recons = self.decode(z)\n        return recons, mu, logsigma","ebdaaa04":"def kl_loss(mu, logsigma):\n    \"\"\"Kullback-Leibler divergence.\n    \"\"\"\n    loss_value = torch.mean(-0.5 * torch.sum(1 + logsigma - torch.square(mu) - torch.exp(logsigma), axis=1), axis=0)\n    return loss_value\n\ndef recons_loss(recons, x, function):\n    \"\"\"Reconstruction loss.\n    \"\"\"\n    loss_value = function(recons, x)\n    return loss_value\n\ndef vae_loss(vae_out, x, function=nn.MSELoss(reduction=\"mean\")):\n    recons, mu, logsigma = vae_out\n    kl_loss_weight = 1\/(x.shape[1]*x.shape[2]*x.shape[3])\n    return recons_loss(recons, x, function=function) + kl_loss_weight*kl_loss(mu, logsigma)","c78a808b":"def weights_init(m):\n    \"\"\"Custom weights initialization.\n    \"\"\"\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","b19d9a2f":"def training_part(model, optimizer, criterion, data_train, scheduler=None, epoch=None,\n                  num_epochs=None, device=torch.device(\"cuda:0\")):\n    \"\"\"Training part of training loop.\n    \"\"\"\n    local_stats = {\"Train_losses\": list(), \"iters\": 0}\n    model.train()\n    for i, x in enumerate(data_train):\n        # Data to device\n        x = x.to(device)\n        # Zero gradients\n        model.zero_grad()\n        # Forward pass\n        model_out = model(x)\n        # Calculate loss\n        loss_value = criterion(model_out, x)\n        # Calculate gradients\n        loss_value.backward()\n        optimizer.step()\n        local_stats[\"Train_losses\"].append(loss_value.item())\n\n        # Output training stats\n        if len(data_train) > 4 and i % (len(data_train)\/\/4) == 0 or i == len(data_train)-1:\n            print(f\"[{epoch}\/{num_epochs}][{i}\/{len(data_train)}]\\tTrain_Loss: \"\n            f\"{local_stats['Train_losses'][-1]:.4f}\")\n        \n        local_stats[\"iters\"] += 1\n    \n    if scheduler is not None:\n        if scheduler.__class__.__name__ == \"ReduceLROnPlateau\":\n            scheduler.step(np.mean(local_stats[\"Train_losses\"]))\n        else:\n            scheduler.step()\n    \n    return local_stats","04fd904b":"def validating_part(model, criterion, data_valid, epoch=None, num_epochs=None,\n                    device=torch.device(\"cuda:0\")):\n    \"\"\"Validating part of training loop.\n    \"\"\"\n    local_stats = {\"Val_losses\": list()}\n    model.eval()\n    with torch.no_grad():\n        for i, x in enumerate(data_valid):\n            # Data to device\n            x = x.to(device)\n            # Forward pass\n            model_out = model(x)\n            # Calculate loss\n            loss_value = criterion(model_out, x)\n            local_stats[\"Val_losses\"].append(loss_value.item())\n\n            # Output validating stats\n            if i % 1 == 0:\n                print(f\"[{epoch}\/{num_epochs}][{i}\/{len(data_valid)}]\\tVal_Loss: \"\n                f\"{local_stats['Val_losses'][-1]:.4f}\")\n    return local_stats","aaf9eb5c":"def visualizing_part(model, x_valid, data_valid, train_stats, device=torch.device(\"cuda:0\"),\n                     titles=(\"Input\", \"Output\")):\n    \"\"\"Visualizing part of training loop.\n    \"\"\"\n    # Plot losses\n    plt.figure(figsize=(16, 6))\n    plt.plot(range(1, train_stats[\"epochs\"]+1), [np.mean(hist) for hist in train_stats[\"Train_losses\"]], label=\"Train_losses\")\n    plt.plot(train_stats[\"val_epochs\"], [np.mean(hist) for hist in train_stats[\"Val_losses\"]], label=\"Val_losses\")\n    plt.grid(True)\n    plt.legend()\n    plt.show();\n\n    # Visualize latent space\n    model.eval()\n    with torch.no_grad():\n        codes_list = list()\n        for x in data_valid:\n            codes = model.encode(x.to(device))[0].cpu().numpy()\n            codes_list.append(codes)\n\n    codes = np.concatenate(codes_list)\n    codes = TSNE(n_components=2).fit_transform(codes)\n    plt.figure(figsize=(16, 6))\n    plt.scatter(codes[:, 0], codes[:, 1], label=\"Encoded image\")\n    plt.grid(True)\n    plt.legend()\n    plt.show();\n    \n    # Show images\n    model.eval()\n    with torch.no_grad():\n        x_valid_recons = model(x_valid.to(device))[0].cpu()\n    \n    plt.figure(figsize=(18, 6))\n    for i, x_valid_i in enumerate(x_valid):\n        plt.subplot(2, 6, i+1)\n        plt.axis(\"off\")\n        plt.title(titles[0])\n        img = np.transpose(x_valid_i*0.5+0.5, (1,2,0))\n        if img.shape[-1] == 1:\n            plt.imshow(img.squeeze(), cmap=\"gray\")\n        else:\n            plt.imshow(img)\n        \n        plt.subplot(2, 6, i+7)\n        plt.axis(\"off\")\n        plt.title(titles[1], color=\"r\")\n        img = np.transpose(x_valid_recons[i]*0.5+0.5, (1,2,0))\n        if img.shape[-1] == 1:\n            plt.imshow(img.squeeze(), cmap=\"gray\")\n        else:\n            plt.imshow(img)\n    plt.show();","c39afab7":"def saving_progress(model, optimizer, train_stats, savepath=\"checkpoint.tar\",\n                    scheduler=None):\n    \"\"\"Saving part of training loop.\n    \"\"\"\n    checkpoint = {\"model_state_dict\": model.state_dict(),\n                  \"optimizer_state_dict\": optimizer.state_dict(),\n                  \"train_stats\": train_stats}\n    if scheduler is not None:\n        checkpoint[\"scheduler_state_dict\"] = scheduler.state_dict()\n    \n    torch.save(checkpoint, savepath)\n\ndef loading_progress(model, optimizer, loadpath, scheduler=None):\n    \"\"\"Loading progress.\n    \"\"\"\n    checkpoint = torch.load(loadpath)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n    train_stats = checkpoint[\"train_stats\"]\n    if scheduler is not None:\n        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n    return model, optimizer, train_stats, scheduler","1f461aa1":"def training_loop(model, optimizer, criterion, data_train, data_valid=None, scheduler=None,\n                  num_epochs=200, train_stats=None, device=torch.device(\"cuda:0\"), titles=(\"Input\", \"Output\"),\n                  savepath=\"checkpoint.tar\"):\n    \"\"\"Training Loop.\n    \"\"\"\n    # Dict to keep track of progress\n    if train_stats is None:\n        train_stats = {\"Train_losses\": list(), \"Val_losses\": list(),\n                       \"epochs\": 0, \"val_epochs\": list(), \"iters\": 0}\n    # Data for show\n    if data_valid is not None:\n        x_valid = next(iter(data_valid))[:6]\n    \n    print(\"Starting training loop\")\n    ts_total = time.time()\n    for epoch in range(train_stats[\"epochs\"], num_epochs):\n        # Training part\n        print(f\"Starting {epoch+1} epoch\")\n        ts = time.time()\n        res = training_part(model, optimizer, criterion, data_train, scheduler,\n                            epoch+1, num_epochs, device)\n        print(f\"{epoch+1} epoch complete in {time.time()-ts:.2f}s\")\n        train_stats[\"Train_losses\"].append(res[\"Train_losses\"])\n        train_stats[\"epochs\"] += 1\n        train_stats[\"iters\"] += res[\"iters\"]\n        print(\"-\"*50 + \"\\n\" +\\\n              f\"Train_loss: {np.mean(train_stats['Train_losses'][-1]):.4f}, \"\n              \"\\n\" + \"-\"*50 + \"\\n\")\n        \n        # Validating part\n        if data_valid is not None and epoch % 5 == 0:\n            print(\"Validating a model\")\n            res = validating_part(model, criterion, data_valid, epoch+1,\n                                  num_epochs, device)\n            train_stats[\"Val_losses\"].append(res[\"Val_losses\"])\n            train_stats[\"val_epochs\"].append(epoch+1)\n            print(\"-\"*50 + \"\\n\" +\\\n              f\"Val_loss: {np.mean(train_stats['Val_losses'][-1]):.4f}, \"\n              \"\\n\" + \"-\"*50 + \"\\n\")\n        \n        # Visualizing part\n        if x is not None and epoch % 5 == 0:\n            print(\"Visualizing training stats\")\n            visualizing_part(model, x_valid, data_valid, train_stats, device, titles)\n        \n        # Savinging part\n        if epoch % 5 == 0 or epoch == num_epochs-1:\n            print(\"Saving training progress\")\n            saving_progress(model, optimizer, train_stats, savepath, scheduler)\n    \n    print(f\"Training loop complete in {time.time()-ts_total:.2f}s\")\n    return train_stats","f51b76ae":"import numpy as np\nfrom functools import partial\nimport torch\nimport os\nimport PIL\nfrom typing import Any, Callable, List, Optional, Union, Tuple\nfrom torchvision.datasets.vision import VisionDataset\nfrom torchvision.datasets.utils import download_file_from_google_drive, check_integrity, verify_str_arg\n\n\nclass Bitmoji(VisionDataset):\n    \"\"\"`Bitmoji Faces Dataset <https:\/\/www.kaggle.com\/romaingraux\/bitmojis>`_ Dataset.\n\n    Args:\n        root (string): Root directory where images are downloaded to.\n        transform (callable, optional): A function\/transform that  takes in an PIL image\n            and returns a transformed version. E.g, ``transforms.ToTensor``\n    \"\"\"\n\n    base_folder = \"bitmojis\"\n\n    def __init__(\n            self,\n            root: str,\n            transform: Optional[Callable] = None\n    ) -> None:\n        import pandas\n        super(Bitmoji, self).__init__(root, transform=transform)\n\n        if not self._check_integrity():\n            raise RuntimeError('Dataset not found or corrupted.\\n'\n            '''Correct directory tree:\n            root\/\n            \u251c\u2500\u2500 bitmojis\/\n                \u251c\u2500\u2500 xxx.png\n                \u251c\u2500\u2500 yyy.png\n                \u2514\u2500\u2500 ...\n            ''')\n        \n        self.filename = os.listdir(os.path.join(self.root, self.base_folder))\n\n    def _check_integrity(self) -> bool:\n        return os.path.isdir(os.path.join(self.root, self.base_folder))\n    \n    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n        X = PIL.Image.open(os.path.join(self.root, self.base_folder, self.filename[index]))\n        if self.transform is not None:\n            X = self.transform(X)\n\n        return X\n\n    def __len__(self) -> int:\n        return len(self.filename)","4a22e0c3":"# Prepare the dataset\ntransform=transforms.Compose([\n    transforms.Resize(64),\n    transforms.CenterCrop(64),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\nbitmoji_set = Bitmoji(\"\/kaggle\/input\/bitmojis\", transform=transform)\n\n# Initializing dataloaders\nbatch_size = 128\nworkers = os.cpu_count()\nbitmoji_train = data_utils.DataLoader(data_utils.Subset(bitmoji_set, range(len(bitmoji_set)-8*batch_size)),\n                                batch_size=batch_size, shuffle=True, num_workers=workers)\nbitmoji_valid = data_utils.DataLoader(data_utils.Subset(bitmoji_set, range(len(bitmoji_set)-8*batch_size, len(bitmoji_set))),\n                                 batch_size=batch_size, shuffle=True, num_workers=workers)","81c007eb":"# Visualize dataset\nx = next(iter(bitmoji_valid))\nplt.figure(figsize=(12, 8))\nplt.axis(\"off\")\nplt.imshow(np.transpose(make_grid(x[:40], 8, 1, normalize=True), (1, 2, 0)))\nplt.show();","d1f9d474":"dim_code = 512\nlr = 0.0001\nbeta1 = 0.5\nbeta2 = 0.999\nnum_epochs = 16\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"DEVICE:\", device)","1ba6cc16":"# Create VAE\nvae = VAE(dim_code).to(device)\nvae.apply(weights_init);\n# Initialize Loss functions\ncriterion = vae_loss\n# Setup Adam optimizer\noptimizer = optim.Adam(vae.parameters(), lr=lr, betas=(beta1, beta2))\n# Setup lr_schedulers\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", factor=0.3, patience=3, min_lr=0.000001)","df3b855e":"# Loading if necessary\n# vae, optimizer, train_stats, scheduler = \\\n# loading_progress(vae, optimizer,\n#                  \"\/kaggle\/VAE_51e_512.tar\",\n#                  scheduler=scheduler)","022120eb":"train_stats = training_loop(vae, optimizer, criterion, bitmoji_train, data_valid=bitmoji_valid, scheduler=scheduler,\n                            num_epochs=num_epochs, train_stats=None, device=device, titles=(\"Input\", \"Output\"),\n                            savepath=\"vae_checkpoint.tar\")","602ff463":"x = next(iter(bitmoji_valid))\ninds = np.random.choice(len(x), 8, False)\nx = x[inds]\nvae.eval()\nwith torch.no_grad():\n    x_recons = vae(x.to(device))[0].cpu()\n\nplt.figure(figsize=(12, 8))\nplt.axis(\"off\")\nplt.title(\"Original(Top) vs Reconstructions(Bottom)\")\nplt.imshow(np.transpose(make_grid(torch.cat([x, x_recons]), 8, 1, normalize=True), (1, 2, 0)))\nplt.show();","5ac6573b":"z = torch.randn((40, 512))\nvae.eval()\nwith torch.no_grad():\n    samples = vae.decode(z.to(device)).cpu()\n\nplt.figure(figsize=(18, 14))\nplt.axis(\"off\")\nplt.title(f\"VAE Generations after {num_epochs} epochs\")\nplt.imshow(np.transpose(make_grid(samples, 8, 1, normalize=True), (1, 2, 0)))\nplt.show();","4813b5ae":"# Training","1ec25801":"# Validating","c4e30225":"# VAE Code","c12efa9a":"# Initializations","00588312":"## Model Initialization","56b62e80":"# Sampling","0949baf6":"## Dataset Preparation","a4421672":"# Training Makers"}}