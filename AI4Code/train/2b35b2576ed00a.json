{"cell_type":{"36fb0779":"code","8682c496":"code","a45d6b02":"code","c7eb3b1c":"code","b597ea03":"code","9504a2d6":"code","8b90f7a7":"code","dce9481f":"code","c84c051c":"code","cc67c6a2":"code","e193be5c":"code","e0fa31a5":"code","aae77860":"code","c3e091a8":"markdown","f8c30656":"markdown","aa89709f":"markdown","01566922":"markdown","6a15f546":"markdown","55975319":"markdown","0053bf39":"markdown"},"source":{"36fb0779":"import numpy as np \nimport pandas as pd \nimport gc\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Dense, Activation,  BatchNormalization, Dropout, Concatenate\nfrom tensorflow.keras.models import Model\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","8682c496":"train = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv').astype('float32')\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\").astype('float32')\ntrain.drop(['Soil_Type7','Soil_Type15'],axis =1, inplace = True)\ntest.drop(['Soil_Type7','Soil_Type15'],axis =1, inplace = True)\ntrain.drop(labels =train[train.Cover_Type==5].index,axis = 0, inplace = True)\ntrain = train.reset_index(drop=True)","a45d6b02":"pred  = pd.read_csv('..\/input\/tps-december\/submission.csv').astype('int')\npseudo_test = test.copy()\npseudo_test['Cover_Type'] = pred['Cover_Type']\npseudo_test.shape","c7eb3b1c":"train = pd.concat([train,pseudo_test],axis=0)\ntrain = train.reset_index(drop = True)\ntrain.shape","b597ea03":"del pseudo_test\ngc.collect()","9504a2d6":"target = train['Cover_Type']\ny = pd.get_dummies(train['Cover_Type'])\ntrain.drop(['Cover_Type','Id'], axis = 1, inplace = True)\ntest.drop('Id', axis = 1, inplace = True)\ntrain.shape, test.shape","8b90f7a7":"cat_col = [col for col in train.columns if train[col].nunique() < 4]\nnum_col = [col for col in train.columns if col not in cat_col]","dce9481f":"train[\"mean\"] = train[num_col].mean(axis=1)\ntrain[\"std\"] = train[num_col].std(axis=1)\ntrain[\"min\"] = train[num_col].min(axis=1)\ntrain[\"max\"] = train[num_col].max(axis=1)\ntrain[\"skew\"] = train[num_col].skew(axis=1)\n\ntest[\"mean\"] = test[num_col].mean(axis=1)\ntest[\"std\"] = test[num_col].std(axis=1)\ntest[\"min\"] = test[num_col].min(axis=1)\ntest[\"max\"] = test[num_col].max(axis=1)\ntest[\"skew\"] =test[num_col].skew(axis=1)","c84c051c":"num_col = [col for col in train.columns if col not in cat_col]\n\ntrain_num = train[num_col]\ntrain_cat = train[cat_col]\ntest_num = test[num_col]\ntest_cat = test[cat_col]","cc67c6a2":"ss = StandardScaler()\ntrain_num = pd.DataFrame(ss.fit_transform(train_num))\ntest_num = pd.DataFrame(ss.transform(test_num))","e193be5c":"#del train\ngc.collect()","e0fa31a5":"run = 1 # number of training\nnumber = 8 # number for files submission's name\n\nBATCH_SIZE = 1024*5\nEPOCH = 100\n\nfor j in range(run):\n    \n    # Init Values :\n    pred_final = np.zeros((test_num.shape[0],6))\n    N_split = [13,20] # for several runs, we can change the split, the seed,the drop...\n    SEED = [1,1]\n    DROP = [0.05,0.05]\n    UNIT = [200,200]\n    ACT = 'relu'\n    KERNEL = tf.keras.initializers.GlorotNormal()\n    number +=1\n    train_run = np.zeros((y.shape[0],6))\n\n    skf = StratifiedKFold(n_splits = N_split[j], random_state = SEED[j], shuffle = True)\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_num, target)):\n        \n        # numerical split\n        xtrain_num = train_num.iloc[train_idx,:]\n        xtrain_cat = train_cat.iloc[train_idx,:]\n        ytrain = y.loc[train_idx]\n        \n        # categorical split\n        xval_num = train_num.iloc[val_idx,:]\n        xval_cat = train_cat.iloc[val_idx,:]\n        yval = y.loc[val_idx]\n\n        # Inputs for NN model :\n\n        input_cat= Input(\n                shape = (train_cat.shape[1]),\n                name = \"Categorical features\"\n                )\n        \n        input_num = Input(\n                shape = (train_num.shape[1]),\n                name = \"Numerical features\"\n                )\n\n        # Numerical features encoding\n        Y = Dense(UNIT[j]\/2,\n                kernel_initializer=KERNEL, \n                activation=ACT)(input_num)\n\n        # Inputs Concatenation\n        W = Concatenate()([Y,input_cat])\n        W = Dense(UNIT[j],\n                kernel_initializer=KERNEL, \n                activation=ACT)(W)\n        W = Dropout(DROP[j])(W)\n        W = BatchNormalization()(W)\n\n        # Skip connection\n        Z = Concatenate()([W,Y,input_cat])\n        Z = Dense(UNIT[j]\/2, \n                kernel_initializer=KERNEL, \n                activation=ACT)(Z)\n\n        Z = Dropout(DROP[j])(Z)\n        Z = BatchNormalization()(Z)\n\n        Z= Dense(UNIT[j]\/4, \n                kernel_initializer=KERNEL, \n                activation=ACT)(Z)\n        output1 = Dense(6, \n                kernel_initializer=KERNEL,\n                activation='softmax')(Z)\n\n        model = Model(inputs = [input_num, input_cat],\n                      outputs = output1,name = 'model')\n\n        # Training control :\n        es = tf.keras.callbacks.EarlyStopping(\n                monitor = 'val_acc', \n                min_delta = 1e-06, \n                patience = 6, \n                verbose = 0,\n                mode = 'max', \n                baseline = None,\n                restore_best_weights = True)\n\n        plateau = tf.keras.callbacks.ReduceLROnPlateau(\n                monitor='val_acc',\n                factor = 0.5,\n                patience = 3,\n                verbose = 0,\n                mode = 'max')\n\n        # Training :\n\n        METRICS = ['acc']\n        OPTIMIZER = keras.optimizers.Adam(learning_rate = 0.01)\n\n        model.compile(\n                loss = 'categorical_crossentropy',\n                optimizer = OPTIMIZER,\n                metrics = METRICS) \n\n        model.fit(\n                [xtrain_num,xtrain_cat],\n                ytrain,\n                epochs = EPOCH,\n                batch_size = BATCH_SIZE,\n                validation_data = ([xval_num,\n                                    xval_cat],\n                                   yval),\n                verbose = 0,\n                callbacks=[es,plateau]\n                )\n\n        # NN prediction :\n        pred = model.predict([xval_num,\n                              xval_cat])\n        train_run[val_idx,:] = pred\n\n        y_val = np.argmax(np.array(yval), axis=1) + 1\n        y_val = np.where(y_val < 5, y_val, y_val+1)\n        pred1 = np.argmax(pred, axis=1) +1\n        pred1 = np.where(pred1 < 5, pred1, pred1+1)\n\n        print('FOLD = ',\n              fold+1,\n              \"SCORE NN =\",\n              accuracy_score(y_val, pred1))\n\n        pred_test = model.predict([test_num,test_cat])\n        pred_final += pred_test\/N_split[j]\n\n    pred_train_final = np.argmax(train_run, axis = 1) +1\n    pred_train_final = np.where(pred_train_final < 5, pred_train_final, pred_train_final + 1) \n    \n    print('\\n')\n    print(65*'*')\n    print('number =',\n          number,\n          \"FOLD =\",\n          N_split[j],\n          \"Seed =\",\n          SEED[j],\n          \" SCORE =\",\n          accuracy_score(target, pred_train_final)) \n    print(65*'*')   \n\n    pred = np.argmax(pred_final, axis = 1) +1\n    pred = np.where(pred < 5, pred, pred + 1)\n\n    sub = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')\n    sub['Cover_Type'] = pred\n    sub.to_csv('sub_{}folds_num_{}.csv'.format(fold + 1,number),index = False)","aae77860":"y_true = target\ny_pred = pred_train_final\ncm =confusion_matrix(y_true, y_pred)\nx_axis_labels = [1,2,3,4,6,7] \ny_axis_labels = [1,2,3,4,6,7]\nplt.figure(figsize=(10,10))\nsns.heatmap(cm\/np.sum(cm), \n            annot=True, \n            fmt='.2%', \n            cmap='Blues', \n            xticklabels=x_axis_labels, \n            yticklabels=y_axis_labels)","c3e091a8":"<h1> 2 inputs : Numerical  and Categorical encoded separately","f8c30656":"Upvote is free of charge :-))","aa89709f":"<h2> Numerical and Categorical data split","01566922":"<h2> Simple additional features","6a15f546":"<h2> Confusion Matrix","55975319":"<h2> Pseudo labelling","0053bf39":"![image.png](attachment:d7a828f7-e105-46ae-94e1-8fd6cedd34d6.png)"}}