{"cell_type":{"fca4863d":"code","b1133732":"code","dbc24ab9":"code","f4931431":"code","11231034":"code","1edb58b7":"code","e6a35160":"code","e3f87a8c":"code","25922bc4":"code","9bb9a098":"code","4f6e6a85":"code","537e614a":"code","e76c56bf":"code","35177bfe":"code","fbd36929":"code","83b6195d":"code","1402b001":"code","c2e85016":"code","87687b79":"code","3a7e3bb2":"code","b4931091":"code","47966462":"code","0d4a4c89":"code","e5f226c9":"code","f8fa9ef6":"code","f73adf45":"code","451f2457":"code","8cb76ab7":"code","c19aed9c":"code","4560b30e":"code","488292fb":"code","171ccb00":"code","92ca3b0f":"code","fa01400a":"code","3088c99d":"code","0c2a26b5":"code","9d843939":"code","f2a333f1":"code","aad4936a":"code","7cdfdc38":"code","8d6b30db":"code","fdb420a8":"code","eb37b6f5":"code","45e2d64d":"code","c87e7c02":"code","626b6764":"markdown"},"source":{"fca4863d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b1133732":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport folium\nimport geopandas as gpd\nplt.style.use(\"dark_background\")\n","dbc24ab9":"df = pd.read_csv(\"\/kaggle\/input\/indian-food-101\/indian_food.csv\")\ndf.head()","f4931431":"df.isnull().sum()","11231034":"df.info()","1edb58b7":"df = df.dropna()","e6a35160":"df.describe()","e3f87a8c":"df['course'].unique()","25922bc4":"def plotmapfor(item):\n    itemdata = df[df['course']==item]\n    itemdf =itemdata.state.value_counts().reset_index()\n    itemdf.columns = ['state','count']\n\n    fp = \"..\/input\/india-states\/Igismap\/Indian_States.shp\"\n    map_df = gpd.read_file(fp)\n\n    merged = map_df.set_index('st_nm').join(itemdf.set_index('state'))\n\n    fig, ax = plt.subplots(1, figsize=(20, 12))\n    ax.axis('off')\n    ax.set_title(f'State Wise Distribution of indian {item}', fontdict={'fontsize': '16', 'fontweight' : '3'})\n    merged.plot(column='count', cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)\n","9bb9a098":"plotmapfor(\"snack\")","4f6e6a85":"plotmapfor(\"main course\")","537e614a":"plotmapfor(\"starter\")","e76c56bf":"plotmapfor(\"dessert\")","35177bfe":"df['flavor_profile'].value_counts()","fbd36929":"def plotmapfor(item):\n    itemdata = df[df['flavor_profile']==item]\n    itemdf =itemdata.state.value_counts().reset_index()\n    itemdf.columns = ['state','count']\n\n    fp = \"..\/input\/india-states\/Igismap\/Indian_States.shp\"\n    map_df = gpd.read_file(fp)\n\n    merged = map_df.set_index('st_nm').join(itemdf.set_index('state'))\n\n    fig, ax = plt.subplots(1, figsize=(20, 12))\n    ax.axis('off')\n    ax.set_title(f'State Wise Distribution of flavour profile = {item}', fontdict={'fontsize': '16', 'fontweight' : '3'})\n    merged.plot(column='count', cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)","83b6195d":"plotmapfor(\"spicy\")","1402b001":"plotmapfor(\"sweet\")","c2e85016":"df.head()","87687b79":"df['diet'].unique()","3a7e3bb2":"ax = df['diet'].value_counts().plot(kind='bar',\n                                      figsize=(10, 6),\n                                     color=[\"skyblue\", \"pink\"])\n\nax.set_xticklabels(['vegetarian', 'non vegetarian'],rotation=0,fontsize=12)\nax.set_ylabel('count', fontsize = 12)\nax.set_title(\"Distribution of data based on diet\",fontsize=18)\nplt.show()","b4931091":"ax = df['course'].value_counts().plot(kind='bar',\n                                      figsize=(10, 6),\n                                     color=[\"royalblue\",\"orange\",\"seagreen\",\"maroon\"])\n\nax.set_xticklabels(['dessert', 'main course', 'starter', 'snack'],rotation=0,fontsize=12)\nax.set_ylabel('count', fontsize = 12)\nax.set_title(\"Distribution of data based on diet\",fontsize=18)\nplt.show()","47966462":"df['flavor_profile'].unique()","0d4a4c89":"ax = df['flavor_profile'].value_counts().plot(kind='bar',\n                                      figsize=(10, 6),\n                                     color=[\"royalblue\",\"orange\",\"seagreen\",\"maroon\",\"pink\"])\n\nax.set_xticklabels(['sweet', 'spicy', 'bitter', 'NA', 'sour'],rotation=0,fontsize=12)\nax.set_ylabel('count', fontsize = 12)\nax.set_title(\"Distribution of data based on flavour profile\",fontsize=18)\nplt.show()","e5f226c9":"plt.figure(figsize=(14,8))\nsns.distplot(df['prep_time'],color='red')\nplt.title(\"Histogram for prep time\",fontsize=24)\nplt.show()","f8fa9ef6":"plt.figure(figsize=(14,8))\nsns.boxplot(df['prep_time'],color='red',orient='v')\nplt.title(\"boxplot for prep time\",fontsize=24)\nplt.show()","f73adf45":"plt.figure(figsize=(14,8))\nsns.distplot(df['cook_time'],color='seagreen')\nplt.title(\"Histogram for cook time\",fontsize=24)\nplt.show()","451f2457":"plt.figure(figsize=(14,8))\nsns.boxplot(df['cook_time'],color='seagreen',orient='v')\nplt.title(\"boxplot for cook time\",fontsize=24)\nplt.show()","8cb76ab7":"df['prep_time'].describe()","c19aed9c":"# as our data is skewed so we will compute the Interquantile range to calculate the boundaries \nIQR=df['cook_time'].quantile(0.75)-df['cook_time'].quantile(0.25)\nlower_bridge=df['cook_time'].quantile(0.25)-(IQR*1.5)\nupper_bridge=df['cook_time'].quantile(0.75)+(IQR*1.5)\nprint(lower_bridge), print(upper_bridge)","4560b30e":"#### Extreme outliers\nlower_bridge=df['cook_time'].quantile(0.25)-(IQR*3)\nupper_bridge=df['cook_time'].quantile(0.75)+(IQR*3)\nprint(lower_bridge), print(upper_bridge)","488292fb":"data = df.copy()\ndata.loc[data['cook_time']>=100,'cook_time']=100","171ccb00":"plt.figure(figsize=(14,8))\nsns.distplot(data['cook_time'],color='red')\nplt.title(\"Histogram for cook time after handling outliers\",fontsize=24)\nplt.show()","92ca3b0f":"# Handling outliers for prep_time \n\n# as our data is skewed so we will compute the Interquantile range to calculate the boundaries \nIQR=df['prep_time'].quantile(0.75)-df['prep_time'].quantile(0.25)\nlower_bridge=df['prep_time'].quantile(0.25)-(IQR*1.5)\nupper_bridge=df['prep_time'].quantile(0.75)+(IQR*1.5)\nprint(lower_bridge), print(upper_bridge)\n\n#### Extreme outliers\nlower_bridge=df['prep_time'].quantile(0.25)-(IQR*3)\nupper_bridge=df['prep_time'].quantile(0.75)+(IQR*3)\nprint(lower_bridge), print(upper_bridge)\n\n","fa01400a":"data.loc[data['prep_time']>=50,'prep_time']=50","3088c99d":"plt.figure(figsize=(14,8))\nsns.distplot(data['prep_time'],color='seagreen')\nplt.title(\"Histogram for prep time after handling outliers\",fontsize=24)\nplt.show()","0c2a26b5":"data['totaltime'] = data['prep_time']+data['cook_time']\ndata.head()","9d843939":"from wordcloud import WordCloud, STOPWORDS\n\ncomment_words = '' \nstopwords = set(STOPWORDS)\nfor val in data.name: \n    val = str(val) \n    tokens = val.split() \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower()       \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n                        \nplt.figure(figsize = (10,10), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title(\"Wordcloud for Dishes\",fontsize=24)  \nplt.show()","f2a333f1":"from wordcloud import WordCloud, STOPWORDS\n\ncomment_words = '' \nstopwords = set(STOPWORDS)\nfor val in data.ingredients: \n    val = str(val) \n    tokens = val.split() \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower()       \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n                        \nplt.figure(figsize = (10,10), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title(\"Wordcloud for Ingredients\",fontsize=24) \nplt.show()","aad4936a":"data.head()","7cdfdc38":"group = data.groupby(['course'])[['prep_time']].mean().reset_index()\nfig = px.pie(group,values='prep_time',names='course',title=\"average preparation time taken for items belonging to each course\")\nfig.update_traces(rotation=90, pull=0.02, textinfo=\"percent+label\")\nfig.show()","8d6b30db":"group = data.groupby(['course'])[['cook_time']].mean().reset_index()\nfig = px.pie(group,values='cook_time',names='course',title=\"average cooking time taken for items belonging to each course\")\nfig.update_traces(rotation=90, pull=0.02, textinfo=\"percent+label\")\nfig.show()","fdb420a8":"df = px.data.tips()\nfig = px.sunburst(data, path=['region','course','flavor_profile'], values='totaltime',color='region')\nfig.show()","eb37b6f5":"df = px.data.tips()\nfig = px.sunburst(data, path=['region','course','diet'], values='totaltime',color='region')\nfig.show()","45e2d64d":"def groupbyplot(feature):\n    group = data.groupby(\"name\")[feature].mean().sort_values(ascending=False).reset_index().head(10)\n    fig = plt.figure(figsize=(16,8))\n    fig = px.bar(group, x='name',y=feature,color=feature,title=f\"Top 10 dishes based on {feature} taken\")\n    fig.show()","c87e7c02":"groupbyplot(\"totaltime\")","626b6764":"# we can see some outliers in cook time and prep time columns let's see those"}}