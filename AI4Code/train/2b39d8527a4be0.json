{"cell_type":{"58b09f2a":"code","09e24a9d":"code","e4f65e92":"code","77ddabe5":"code","d3fa9c1b":"code","7f43245e":"code","4e9855e7":"code","f40966b3":"code","89f25bfb":"code","76118147":"code","4d3d58ad":"code","512dd205":"code","aa716326":"code","2ecc1b65":"markdown","a14aaea5":"markdown"},"source":{"58b09f2a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected = True)\nimport plotly.graph_objs as go\n\nprint(plt.style.available) # look at available plot styles\nplt.style.use('ggplot')\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","09e24a9d":"data = pd.read_csv(\"..\/input\/column_2C_weka.csv\")\ndata.head(10)","e4f65e92":"data.info()","77ddabe5":"# check for NaN values\ndata.isna().sum()\n\ndata.describe()","d3fa9c1b":"fig = {\n    \"data\" : [\n        {\n            \"x\" : data[\"class\"],\n            \"name\" : \"class\",\n            \"marker\" : {\"color\" : [\"blue\", \"red\"]},\n            \"type\" : \"histogram\"\n        }\n    ],\n    \n    \"layout\" : {\n        \"title\" : \"Class Count\",\n        \"titlefont\" : {\"color\" : \"black\",\n                       \"size\" : 20},\n        \"xaxis\" : {\"title\" : \"Class\",\n                   \"color\" : \"black\"},\n        \"yaxis\" : {\"title\" : \"Count\",\n                   \"color\" : \"black\"}\n    }\n}\n\niplot(fig)","7f43245e":"class_count = data[\"class\"].value_counts()\nfig = {\n    \"data\" : [\n        {\n            \"labels\" : class_count.index,\n            \"values\" : class_count.values,\n            \"name\" : \"Class\",\n            \"hoverinfo\" : \"label+value+name\",\n            \"textinfo\" : \"percent\",\n            \"marker\" : {\"line\" : {\"width\" : 1.1, \"color\" : \"black\"}},\n            \"hole\" : .3,\n            \"type\" : \"pie\"\n            \n        },\n    ],\n    \n    \"layout\" : {\n        \"title\" : \"Class Count\",\n        \"titlefont\" : {\"size\" : 20}\n    }\n}\n\niplot(fig)\nplt.savefig('graph.png')","4e9855e7":"# for KNN we need to change class names to the integer \n# Abnormal => 1  \/   Normal => 0\ndata[\"class\"] = [1 if each == \"Abnormal\" else 0 for each in data[\"class\"]]","f40966b3":"# preparing the data for classification\ny = data[\"class\"]\nx_data = data.drop([\"class\"], axis=1)","89f25bfb":"# now we need to do normalization\nx = (x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data))","76118147":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .3, random_state = 42)","4d3d58ad":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import r2_score\nknn = KNeighborsClassifier(n_neighbors = 3)\n\nknn.fit(x_train, y_train)\ny_head = knn.predict(x_test)\n\nprint(knn.score(x_test, y_test))","512dd205":"train_accuracy = []\ntest_accuracy = []\n\nfor k, i in enumerate(np.arange(1, 25),1):\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(x_train, y_train)\n    \n    train_accuracy.append(knn.score(x_train, y_train))\n    test_accuracy.append(knn.score(x_test, y_test))\nprint(\"With KNN (K=3) accuracy is: \",knn.score(x_test,y_test))\n    \n\n#plt.subplots(figsize=(18,10))\n#plt.plot(np.arange(1, 25), train_accuracy, label = \"Train\")\n#plt.plot(np.arange(1, 25), test_accuracy, label = \"Test\")\n#plt.xlabel(\"Number of Neighbors (K)\")\n#plt.ylabel(\"Accuracy\")\n#plt.title(\"K vs Accuracy\")\n#plt.legend()\n#plt.show()\n","aa716326":"fig = {\n    \"data\" : [\n        {\n            \"x\" : np.arange(1, 25),\n            \"y\" : train_accuracy,\n            \"name\" : \"Train\",\n            \"text\" : \"train\",\n            \"marker\" : {\"color\" : \"red\"},\n            \"type\" : \"scatter\",\n            \"mode\" : \"lines+markers\"\n        },\n        {\n            \"x\" : np.arange(1, 25),\n            \"y\" : test_accuracy,\n            \"name\" : \"Test\",\n            \"text\" : \"test\",\n            \"marker\" : {\"color\" : \"green\"},\n            \"type\" : \"scatter\",\n            \"mode\" : \"lines+markers\"\n        }\n    ],\n    \n    \"layout\" : {\n        \"title\" : \"K Value vs Accuracy\",\n        \"titlefont\" : {\"color\" : \"black\",\n                       \"size\" : 20},\n        \"xaxis\" : {\"title\" : \"Number of Neighbors (K)\",\n                   \"titlefont\" : {\"size\" : 13,\n                                  \"color\" : \"blue\"}},\n        \"yaxis\" : {\"title\" : \"Accuracy\",\n                   \"titlefont\" : {\"size\" : 13,\n                                  \"color\" : \"blue\"}},\n        \"showlegend\" : True\n    }\n}\n\niplot(fig)\n\n","2ecc1b65":"## Train-Test-Split","a14aaea5":"## Normalization"}}