{"cell_type":{"04e35d3c":"code","ce9f0c3e":"code","5fa48768":"code","362ed70e":"code","fa3e64bb":"code","f5194bb9":"code","46032d63":"code","e2af8aa2":"code","b176028d":"code","a27e9ed8":"code","b8c4ed8b":"code","439dac20":"code","95bc5711":"code","d8cf524c":"code","a622fa2e":"code","a82612eb":"code","06b7a1c8":"code","76f09096":"code","1482d79d":"code","72b189a7":"code","efa6afd9":"code","4df348b5":"code","9daba6f4":"code","5b828122":"code","798d639e":"code","619624c3":"code","6148ec55":"code","0dc44a1c":"code","9282329a":"code","318d6fb2":"code","3be2a39b":"code","c8acdc89":"code","ba4d11eb":"markdown","dbbdf314":"markdown","aeb63a0c":"markdown","88f214fe":"markdown","b738c2fd":"markdown","623f1d33":"markdown","cfc10c7f":"markdown","0b81b146":"markdown","98843c92":"markdown","50074edd":"markdown","8417fc0b":"markdown","7cb98ad2":"markdown","30c21b23":"markdown","7c27166b":"markdown","e0cad75b":"markdown","beb7a443":"markdown","c81750bb":"markdown","5bf46982":"markdown","1630bc1b":"markdown","43f975b2":"markdown","d6b4305a":"markdown","6384d762":"markdown","fb883730":"markdown","c25f6f41":"markdown"},"source":{"04e35d3c":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import TomekLinks\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report\n\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)","ce9f0c3e":"train = pd.read_csv('\/kaggle\/input\/new-trainnew-test\/new_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/new-trainnew-test\/new_test.csv')\ntrain.shape","5fa48768":"fig, ax = plt.subplots(1, 5, figsize=(12, 4))\nax = ax.reshape(1, 5)[0]\nfig.suptitle('Boxplot para Visualiza\u00e7\u00e3o de Outliers', fontsize=16)\n\ncols_float = []\nfor col in train.columns:\n    if train[col].dtype == float and not col.startswith('SQB'):\n        cols_float.append(col)\n\nfor i, col in enumerate(cols_float):\n    ax[i].boxplot(train[col])\n    ax[i].set_title(col, fontsize=16)\n\nplt.tight_layout()","362ed70e":"clf = IsolationForest(max_samples=300, random_state=42)\nclf.fit(train[cols_float])\ntrain['outliers'] = clf.predict(train[cols_float])\nprint('Outliers:', len(train.query('outliers < 0')))","fa3e64bb":"train = train.query('outliers > 0') # Filtrando somente dados que n\u00e3o s\u00e3o outliers\ntrain.drop(columns=['outliers'], inplace=True)","f5194bb9":"def change_dependency_yes(row):\n    if row.dependency == 'yes':\n        return (row.hogar_nin + row.hogar_mayor) \/ row.hogar_adul\n    return row.dependency","46032d63":"train['edjefe'] = train['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntrain['edjefa'] = train['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntrain['dependency'] = train.apply(change_dependency_yes, axis=1)\ntrain['dependency'] = train['dependency'].replace({'no': '0'}).astype(float)","e2af8aa2":"test['edjefe'] = test['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntest['edjefa'] = test['edjefe'].replace({'yes': '1', 'no': '0'}).astype(int)\ntest['dependency'] = test.apply(change_dependency_yes, axis=1)\ntest['dependency'] = test['dependency'].replace({'no': '0'}).astype(float)","b176028d":"X_train_all = train.drop(columns=['Target', 'Id', 'idhogar'])\ny_train_all = train['Target']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_all, y_train_all, test_size=0.15, random_state=42)","a27e9ed8":"X_train_all.shape, y_train_all.shape","b8c4ed8b":"# Oversampling\nsm = SMOTE()\nX_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\ny_train_sm.value_counts()","439dac20":"X_train_sm.shape","95bc5711":"# Undesampling\ntl = TomekLinks()\nX_train_tl, y_train_tl = tl.fit_resample(X_train_sm, y_train_sm)\nX_train_tl.shape, y_train_tl.shape","d8cf524c":"y_train_tl.value_counts()","a622fa2e":"param_grid = {\n    'n_estimators': [200, 400],\n    'oob_score': [True],\n    'min_samples_leaf': [1, 2],\n    'random_state': [42]\n}\nrfg = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=10, n_jobs=-1, return_train_score=True, scoring='accuracy')\nrfg.fit(X_train_tl, y_train_tl)","a82612eb":"grid_df = pd.DataFrame(rfg.cv_results_)\nrank = grid_df[['mean_train_score','mean_test_score','rank_test_score']].sort_values('rank_test_score').head(3)\nBEST_PARAMS = grid_df.sort_values('rank_test_score').params.to_list()[0]\nrank","06b7a1c8":"plt.plot(grid_df['mean_train_score'],label='train')\nplt.plot(grid_df['mean_test_score'],label='test')\nplt.legend()\nplt.show()","76f09096":"y_valid.value_counts()","1482d79d":"plot_confusion_matrix(\n   rfg, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, rfg.predict(X_valid)))","72b189a7":"gbm = GradientBoostingClassifier(n_estimators=400)\ngbm.fit(X_train_tl, y_train_tl)","efa6afd9":"plot_confusion_matrix(\n   gbm, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, gbm.predict(X_valid)))","4df348b5":"ada = AdaBoostClassifier(n_estimators=400)\nada.fit(X_train_tl, y_train_tl)","9daba6f4":"plot_confusion_matrix(\n   ada, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, ada.predict(X_valid)))","5b828122":"xgb = XGBClassifier(n_estimators=400, eval_metric='mlogloss')\nxgb.fit(X_train_tl, y_train_tl)","798d639e":"plot_confusion_matrix(\n   xgb, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, xgb.predict(X_valid)))","619624c3":"cbc = CatBoostClassifier(random_state=42, n_estimators=400, verbose=False)\ncbc.fit(X_train_tl, y_train_tl)","6148ec55":"plot_confusion_matrix(\n   cbc, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, cbc.predict(X_valid)))","0dc44a1c":"lgbm = LGBMClassifier(random_state=42, n_estimators=400)\nlgbm.fit(X_train_tl, y_train_tl)","9282329a":"plot_confusion_matrix(\n   lgbm, X_valid, y_valid, cmap=plt.cm.Blues,values_format='.4g'\n)\nplt.show()\nprint(classification_report(y_valid, lgbm.predict(X_valid)))","318d6fb2":"tl = TomekLinks()\nsm = SMOTE()\n\nX_train_sm_all, y_train_sm_all = sm.fit_resample(X_train_all, y_train_all) # Oversampling\nX_train_tl_all, y_train_tl_all = tl.fit_resample(X_train_sm_all, y_train_sm_all) # Undersampling","3be2a39b":"model = RandomForestClassifier(**BEST_PARAMS)\nmodel.fit(X_train_tl_all, y_train_tl_all)","c8acdc89":"submission = test[['Id']].copy()\ny_pred = model.predict(test.drop(columns=['Id', 'idhogar']))\nsubmission['Target'] = y_pred\n\nsubmission.to_csv('submission.csv', index=False)","ba4d11eb":"Analisando gr\u00e1fico acima e a matriz de confus\u00e3o podemos notar que o modelo de LightGBM obteve uma acur\u00e1cia de 90%.\n- Para a classe 4 foi obtido uma precis\u00e3o de 92%.\n- O recall da classe 4 foi igual a 98%.\n- O f1-score para classe 4 foi igual a 95%.","dbbdf314":"Analisando gr\u00e1fico acima e a matriz de confus\u00e3o podemos notar que o modelo de XGBoost obteve uma acur\u00e1cia de 90%.\n- Para a classe 4 foi obtido uma precis\u00e3o de 92%.\n- O recall da classe 4 foi igual a 97%.\n- O f1-score para classe 4 foi igual a 95%.","aeb63a0c":"Analisando gr\u00e1fico acima e a matriz de confus\u00e3o podemos notar que o modelo de GradientBoost obteve uma acur\u00e1cia geral de 80%.\n- Para a classe 4 foi obtido uma precis\u00e3o de 84%.\n- J\u00e1 o recall da classe 4 foi igual a 94%.\n- O f1-score para classe 4 foi igual 89%.","88f214fe":"### GBM\n\n- Observa\u00e7\u00e3o: Devido ao tempo de execu\u00e7\u00e3o, n\u00e3o ser\u00e1 utilizado o GridSearch para os modelos de boost.","b738c2fd":"### XGBoost","623f1d33":"### AdaBoost","cfc10c7f":"- Ap\u00f3s o oversampling com o m\u00e9todo SMOTE foi utilizado o m\u00e9todo TomekLinks para que seja removido as observa\u00e7\u00f5es semelhantes (Undersampling). Um dos motivos de utilizar o TomekLinks ap\u00f3s o uso do SMOTE \u00e9 para refinar as observa\u00e7\u00f5es, retirando os registros semelhantes que possam \"enviesar\" o modelo.","0b81b146":"## Lendo os Dados","98843c92":"# Modelagem","50074edd":"### Resumo\n- Dentre os Modelos Treinados o melhor modelo foi o RandomForest. Os fatores de escolha foram: Acur\u00e1rcia, Precision e F1-Score (em especial da classe 4).\n        Acc, Prec (classe 4), F1 (Classe 4)\n- **RF**: 92%, 94%, 96%\n- **Light**: 90%, 92%, 95%\n- **XGB**: 90%, 92%, 95%\n- **CAT**: 86%, 89%, 92%\n- **GBM**: 79%, 84%, 89%\n- **ADA**: 66%, 78%, 82%\n\n\n\n- A Explica\u00e7\u00e3o sobre **Precision**, **Recall** e **F1-Score** est\u00e3o na c\u00e9lula de explica\u00e7\u00e3o do RandomForest.\n\n\n- Existe a possibilidade do LightGBM ou XGBoost performarem ainda melhor caso sejam utilizados sob o GridSearch com diferentes configura\u00e7\u00f5es de par\u00e2metros, por\u00e9m, o GridSearch n\u00e3o foi utilizado devido a demora no tempo e treinamento.\n\n\n## Aplicando O RandomForest Melhorado na Base de Teste\n\n\n### Ajustando os Dados Finais","8417fc0b":"- Fazendo a remo\u00e7\u00e3o de outliers com IsolationForest.\n\n- O modelo IsolatioForest funciona da seguinte maneira: S\u00e3o definidos grupos de dados aleatoriamente dentro do conjunto de dados utilizado no treinamento. Cada conjunto de dados ser\u00e1 representado por uma \u00e1rvore isolada (IsolationTree ou iTree). Cada iTree pontua os dados com uma pontua\u00e7\u00e3o de anomalia, e ao final \u00e9 tirado a m\u00e9dia destas pontua\u00e7\u00f5es de anomalia. O valor da m\u00e9dia da pontua\u00e7\u00e3o de anomalia \u00e9 utilizado pelo modelo para encontar os pontos mais distantes da base de dados, esses pontos distantes s\u00e3o os outliers.","7cb98ad2":"- Analisando gr\u00e1fico acima e a matriz de confus\u00e3o podemos notar que o modelo de RandomForest obteve uma acur\u00e1cia de 92%. Outro ponto importante a ser observado \u00e9 o *precision* e *recall*:\n- Para a classe 4 foi obtido uma precis\u00e3o de 94%.\n- J\u00e1 o recall da classe 4 foi igual a 98%.\n- O f1-score para classe 4 = 96%.\n\n\n- Foram citados as medidas da classe 4 pelo fato desta classe possuir a maior ocorr\u00eancia na base de dados.\n\n\n- **Precision**: De todos os valores previstos pelo modelo como classe X , quantos valores o modelo preveu como classe X?\n- **Recall**: De todos os valores que realmente s\u00e3o da classe X quantos valores o modelo preveu sendo da classe X?\n- **f1-Score**: M\u00e9dia Harm\u00f4nica - Medida \u00fanica para repersentar o recall e precision juntos.","30c21b23":"## Removendo Outliers","7c27166b":"### CatBoost","e0cad75b":"## Tratando Classes Desbalanceadas","beb7a443":"### LightGBM","c81750bb":"- O gr\u00e1fico acima apresenta o comportamento do desemepenho de treino e teste realizado no CrossValidation do GridSearch. Podemos notar um alto desempenho no treino e um desempenho inferior nos testes, devido a diferen\u00e7a de valores n\u00e3o ser t\u00e3o distante (1,00 - treino e 0,935 - teste), este gr\u00e1fico mostra que o modelo n\u00e3o est\u00e1 \"overfittado\".","5bf46982":"- Fazendo oversampling com m\u00e9todo SMOTE. Este m\u00e9todo criar\u00e1 novas observa\u00e7\u00f5es baseado no padr\u00e3o de comportamento dos dados. Ao final ser\u00e3o criados novos registros at\u00e9 que todas as classes estejam balanceadas.","1630bc1b":"## Treinando e Avalidando os Modelos\n\n### Random Forest","43f975b2":"## Preparando os Dados","d6b4305a":"### Treinando o Melhor Modelo","6384d762":"### Predi\u00e7\u00f5es","fb883730":"Analisando gr\u00e1fico acima e a matriz de confus\u00e3o podemos notar que o modelo de AdaBoost obteve uma acur\u00e1cia de 66%.\n- Para a classe 4 foi obtido uma precis\u00e3o de 78%.\n- O recall da classe 4 foi igual a 86%.\n- O f1-score para classe 4 igual a 82%.","c25f6f41":"Analisando gr\u00e1fico acima e a matriz de confus\u00e3o podemos notar que o modelo de CatBoost obteve uma acur\u00e1cia de 86%.\n- Para a classe 4 foi obtido uma precis\u00e3o de 89%.\n- O recall da classe 4 foi igual a 97%.\n- O f1-score para classe 4 foi igual a 92%."}}