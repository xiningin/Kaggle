{"cell_type":{"6de4c582":"code","e86c9c70":"code","f6411bd5":"code","f801324d":"code","4d5fffd1":"code","2ac75a95":"code","f19d7ba4":"code","df9f124c":"code","620bf481":"code","3089f4b4":"code","e8399d8a":"code","dcf4a971":"code","575c3a2f":"code","e5c41425":"code","58a52289":"code","cdede732":"code","48776908":"code","f00f0561":"code","f7b7c533":"code","0263d804":"code","ffbd4e4f":"code","778fd75f":"code","cea506b3":"code","901296b1":"code","05cde895":"code","651bd5e8":"code","c0008642":"code","d0076de8":"code","0bef3140":"code","662ebed0":"code","904e6506":"code","34c47172":"code","6d7a0419":"code","69fa927e":"code","8de93874":"code","7fb5ef41":"code","cafd8175":"code","c2edf930":"code","f74e5c1f":"code","6760a3fe":"code","f9982755":"code","fa8d98df":"code","270dd1d7":"code","09fbee40":"code","c6ce5acd":"code","cac082a8":"code","cd980d94":"code","96b29e4a":"code","63d5a756":"code","745444cb":"code","914c3f0a":"code","7c9c6feb":"code","553488f7":"code","c6ec71b5":"code","ce8b9f0a":"code","5d139e42":"code","b881c772":"code","dc2b3161":"code","14351ec0":"code","10373667":"code","fc1ea19f":"code","9f79dd23":"markdown","2acb9ac3":"markdown","0d77adae":"markdown","227da583":"markdown","23459e57":"markdown","477ea08e":"markdown","ed9c9253":"markdown","634e3494":"markdown","29d53832":"markdown","1c06262a":"markdown","b5a609ba":"markdown","5fe5ddde":"markdown","a8df2ac5":"markdown","888aa8f2":"markdown","1e158bb2":"markdown","cacd872e":"markdown","b0ccba1c":"markdown","a3024f65":"markdown","f5c59d8f":"markdown","c2f1896a":"markdown","51731608":"markdown","c85c94ec":"markdown","510561bc":"markdown","44e92d26":"markdown","8e553f45":"markdown","be3f4194":"markdown","4aded5d2":"markdown","c550603d":"markdown","7c66a5a1":"markdown","315c6365":"markdown","ecc090d0":"markdown","3d4a326e":"markdown","a0640347":"markdown","33a7df85":"markdown","d4ca5b4d":"markdown","81b3e1a8":"markdown","4b958ed6":"markdown","d2cb6c4c":"markdown","a0be2886":"markdown","a532a066":"markdown","d78f24c3":"markdown","6c2ece0a":"markdown","f2a4eeae":"markdown","1daf4571":"markdown","5e826b79":"markdown","fbb9efd0":"markdown","cbdad5e1":"markdown","71fd424d":"markdown"},"source":{"6de4c582":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e86c9c70":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\npd.pandas.set_option('display.max_columns',None)","f6411bd5":"df=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","f801324d":"df.head()","4d5fffd1":"df.shape","2ac75a95":"features_with_missing = [features for features in df.columns if df[features].isnull().sum()>1]\n\nfor feature in features_with_missing:\n    print(\"The number of missing values in {} is {}\".format(feature, df[feature].isnull().sum()))","f19d7ba4":"missing_values = df.isnull().sum()\nmissing_values = missing_values[missing_values > 0]\nmissing_values.sort_values(inplace=True)\nmissing_values\n\n\n\n","df9f124c":"missing_values = missing_values.to_frame()\nmissing_values.columns = ['count']\nmissing_values.index.names = ['Name']\nmissing_values['Name'] = missing_values.index\n#missing_values","620bf481":"plt.figure(figsize = (15, 10))\nsns.barplot(x=missing_values['Name'], y=missing_values['count'], data=missing_values)\nplt.xticks(rotation = 90)\nplt.show()\n","3089f4b4":"for feature in features_with_missing:\n    dfcopy=df.copy()\n    # we create a variable that shows 1 whenever the data is missing and 0 otherwise\n    dfcopy[feature] = np.where(dfcopy[feature].isnull(),1,0)\n    \n    # we now calculate the mean SalePrice depening on whether the information is missing or present\n    dfcopy.groupby(feature)['SalePrice'].mean().plot(kind='bar')\n    plt.ylabel('Sales Price')\n    plt.title(feature)\n    plt.show()","e8399d8a":" #we classify features as numerical if their data type is not object\nnum_feat = [features for features in df.columns if df[features].dtypes !='O']\nlen(num_feat)\n\n# hence there are 38 numerical features in which Id class is one of them which doesnt play any role in the \n# house pricing\n","dcf4a971":"df[num_feat].head()","575c3a2f":"year_feat = [features for features in num_feat if 'Yr' in features or 'Year' in features]\nyear_feat","e5c41425":"for feature in year_feat:\n    print(feature, df[feature].unique())\n    ","58a52289":"df.groupby('YrSold')['SalePrice'].mean().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Mean House Price')\nplt.title(\"House Price vs YearSold\")","cdede732":"df.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","48776908":"for feature in year_feat:\n    if feature!='YrSold':\n        dfcopy=df.copy()\n        dfcopy[feature] = dfcopy['YrSold']-dfcopy[feature]\n        \n        plt.scatter(dfcopy[feature],dfcopy['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()\n","f00f0561":"con_feat=[feature for feature in num_feat if len(df[feature].unique())>25 and feature not in year_feat+['Id']]\nprint(\"Continuous feature Count {}\".format(len(con_feat)))","f7b7c533":"\nfor feature in con_feat:\n    dfcopy=df.copy()\n    dfcopy[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","0263d804":"\nfor feature in con_feat:\n    dfcopy=df.copy()\n    if 0 in dfcopy[feature].unique():\n        pass\n    else:\n        dfcopy[feature]=np.log(dfcopy[feature])\n        dfcopy['SalePrice']=np.log(dfcopy['SalePrice'])\n        plt.scatter(dfcopy[feature],dfcopy['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalesPrice')\n        plt.title(feature)\n        plt.show()\n        ","ffbd4e4f":"for feature in con_feat:\n    dfcopy=df.copy()\n    if 0 in dfcopy[feature].unique():\n        pass\n    else:\n        dfcopy[feature]=np.log(dfcopy[feature])\n        sns.boxplot(data=dfcopy, x=(dfcopy[feature]))\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()\n    ","778fd75f":"cat_feat = [features for features in df.columns if df[features].dtypes =='O']\nlen(cat_feat)\n\n\n","cea506b3":"df[cat_feat].head()","901296b1":"for feature in cat_feat:\n    print(\"The distinct number of classes in {} is\/ are: {} \".format(feature, len(df[feature].unique())))","05cde895":"for feature in cat_feat:\n    dfcopy=df.copy()\n    dfcopy.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.ylabel('Median Sale price')\n    plt.xlabel(feature)\n    plt.title(feature)\n    plt.show()","651bd5e8":"#X_train.shape, X_test.shape","c0008642":"drop_cat_feat=[]\n\nfor feature in cat_feat:\n    if df[feature].isnull().sum()\/(len(df[feature]))>0.5:\n       # print(\"The percentage of missing values in {} is {}\".format(feature, df[feature].isnull().sum()\/(len(df[feature]))))\n        drop_cat_feat.append(feature)\nprint(drop_cat_feat)","d0076de8":"drop_num_feat=[]\n\nfor feature in num_feat:\n    if df[feature].isnull().sum()\/(len(df[feature]))>0.5:\n       # print(\"The percentage of missing values in {} is {}\".format(feature, df[feature].isnull().sum()\/(len(df[feature]))))\n        drop_num_feat.append(feature)\nprint(drop_num_feat)","0bef3140":"drop_con_feat=[]\n\nfor feature in con_feat:\n    if df[feature].isnull().sum()\/(len(df[feature]))>0.5:\n       # print(\"The percentage of missing values in {} is {}\".format(feature, df[feature].isnull().sum()\/(len(df[feature]))))\n        drop_con_feat.append(feature)\nprint(drop_con_feat)","662ebed0":"\n\nfeatures_cat_nan=[feature for feature in df.columns if df[feature].isnull().sum()>1 and df[feature].dtypes=='O']\n\nfor feature in features_cat_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(df[feature].isnull().mean(),4)))","904e6506":"def replace_cat_feature(dataset,features_cat_nan):\n    dfcopy=df.copy()\n    dfcopy[features_cat_nan]=dfcopy[features_cat_nan].fillna('Missing')\n    return dfcopy\n\ndf=replace_cat_feature(df,features_cat_nan)\n\ndf[features_cat_nan].isnull().sum()","34c47172":"df.head(10)","6d7a0419":"\nnum_with_nan=[feature for feature in df.columns if df[feature].isnull().sum()>1 and df[feature].dtypes!='O']\n\n## We will print the numerical nan variables and percentage of missing values\n\nfor feature in num_with_nan:\n    print(\"{}: {}% missing value\".format(feature,np.around(df[feature].isnull().mean(),4)))","69fa927e":"for feature in num_with_nan:\n    ## We will replace by using median since there are outliers\n    median_value=df[feature].median()\n    \n    df[feature].fillna(median_value,inplace=True)\n\ndf[num_with_nan].isnull().sum()\n    ","8de93874":"\nfor feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    df[feature]=df['YrSold']-df[feature]","7fb5ef41":"df.head()","cafd8175":"df[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()\n","c2edf930":"import numpy as np\nnum_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n\nfor feature in num_features:\n    df[feature]=np.log(df[feature])\n","f74e5c1f":"df[['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']].head()","6760a3fe":"for feature in cat_feat:\n    temp=df.groupby(feature)['SalePrice'].count()\/len(df)\n    temp_df=temp[temp>0.01].index\n    #print(temp_df)\n    df[feature]=np.where(df[feature].isin(temp_df),df[feature],'Rare_var')\n","f9982755":"df.head(25)","fa8d98df":"#df=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","270dd1d7":"for feature in cat_feat:\n    labels_ordered=df.groupby([feature])['SalePrice'].mean().sort_values().index#to sort the groups of a features\n    # depending on mean SalesPrice and then taking their index\/subclasses\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)} # to start from 0\n    print(labels_ordered)\n    df[feature]=df[feature].map(labels_ordered) # to map various features to numerical order\n    \n    # \n\n","09fbee40":"df.head(10)\n","c6ce5acd":"len(df.columns)","cac082a8":"scaling_feature=[feature for feature in df.columns if feature not in ['Id','SalePrice'] ]\nlen(scaling_feature)","cd980d94":"\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit_transform(df[scaling_feature])\n\n## we always fit_tranform only the training set !\n## never fit_transform the test data set, we only tranform the data set so that the\n## test data set doesnt gather any info on its own\n","96b29e4a":"#scaler.transform(df[scaling_feature])\n\n","63d5a756":"data = pd.concat([df[['Id', 'SalePrice']].reset_index(drop=True),\n                    pd.DataFrame(scaler.transform(df[scaling_feature]), columns=scaling_feature)],\n                    axis=1)\ndata.head()\n\n#log values of sale price along with other values scaled from min-max scaler\n","745444cb":"data.to_csv('X_train.csv',index=False)\n# X_train is the file we will be working with !","914c3f0a":"from sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel","7c9c6feb":"dataset=pd.read_csv('X_train.csv')","553488f7":"y_train=dataset[['SalePrice']]\nX_train=dataset.drop(['Id','SalePrice'],axis=1)\n","c6ec71b5":"feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) \n# remember to set the seed, the random state in this function, otherwise each time we get different set\nfeature_sel_model.fit(X_train, y_train)","ce8b9f0a":"selected_feat = X_train.columns[(feature_sel_model.get_support())]\n#lasso : from the name it signifies that it takes the non-important features to zero\n# out of the 79 columns only 21 remain now","5d139e42":"print('total features: {}'.format((X_train.shape[1])))\nprint('selected features: {}'.format(len(selected_feat)))","b881c772":"selected_feat\n","dc2b3161":"X_train=X_train[selected_feat]\nX_train.head(10)\n","14351ec0":"X_train.shape","10373667":"plt.figure(figsize=(50, 50))\nsns.heatmap(X_train.corr(), annot=True)\nplt.show()","fc1ea19f":"#scaling_feature_test=[feature for feature in Ttdata.columns if feature not in ['Id'] ]\n#len(scaling_feature_test)","9f79dd23":"clearly many of the varibales are not normally distributed. most of them are either right or left skewed.\n\nwe try to  convert them to **Normal distribution** by making of **Log transformation**. We can also use power tranformer using Box-Cox or Yeo-Johnson","2acb9ac3":"for feature in ['YearBuilt', 'YearRemodAdd','GarageYrBlt']:\n    Ttdata[feature] = Ttdata['YrSold']-Ttdata[feature]","0d77adae":"num_features_test = ['LotFrontage', 'LotArea','1stFlrSF','GrLivArea']\nfor feature in num_features_test:\n    Ttdata[feature]=np.log(Ttdata[feature])","227da583":"## We don't predict the output prices as the aim is to learn to select important features from the data set (this data set is containing more than 80 variables) and converting categorical variable into labels in order to convert them to numerical data for predictions\n","23459e57":"this is quite abnormal because with the years increasing the median is decreasing and the mean is following abormal trend.\nSo we now try to plot the sales price vs the year sold - each of the feature to see depending on no. of years how the sales prices plot is behaving\n","477ea08e":"from the above plot once can see that the sales price mean is somtimes less or sometimes more or equal also. therefore each of the feature plays a good role whether or not there are missing values. So we will replace the missing values with something meaningful","ed9c9253":"Ttdata.head()","634e3494":"Now we work on various numerical variables:\nthere are two types of numerical variables: continuous or discrete\n\nwe will consider the feature to be discrete if there are less than 25 unique values present","29d53832":"one would wish to drop these features having very high missing values using the commans : df=df.drop(columns = ['MiscFeature','Fence','PoolQC','Alley'])\n\n\nbut we will leave this to lasso regression , which we see later in the code, the aim of lasso is to make the coeff of non-important features to zero!","1c06262a":"features such as PoolQC, fence, MiscFeature,Alley have lot of missing values. So we can drop these columns\/","b5a609ba":"# Missing Values","5fe5ddde":"# Feature Engineering:\n- We try to fix the missing \/ Nan values.\n- We remove the categories which are present in very less amount and replace by a new feature\n- We try to handle the outliers\n- Other necessary standardization \/ scaling to bring the values to same range\n","a8df2ac5":"# Feature Selection:","888aa8f2":"- Index(['C (all)'], dtype='object', name='MSZoning')\n- Index(['Grvl'], dtype='object', name='Street')\n- Index([], dtype='object', name='Alley')\n- Index(['IR3'], dtype='object', name='LotShape')\n- Index([], dtype='object', name='LandContour')\nIndex(['NoSeWa'], dtype='object', name='Utilities')\nIndex(['FR3'], dtype='object', name='LotConfig')\nIndex(['Sev'], dtype='object', name='LandSlope')\nIndex(['Blueste', 'NPkVill', 'Veenker'], dtype='object', name='Neighborhood')\nIndex(['PosA', 'RRAe', 'RRNe', 'RRNn'], dtype='object', name='Condition1')\nIndex(['Artery', 'Feedr', 'PosA', 'PosN', 'RRAe', 'RRAn', 'RRNn'], dtype='object', name='Condition2')\nIndex([], dtype='object', name='BldgType')\nIndex(['1.5Unf', '2.5Fin', '2.5Unf'], dtype='object', name='HouseStyle')\nIndex(['Flat', 'Gambrel', 'Mansard', 'Shed'], dtype='object', name='RoofStyle')\nIndex(['ClyTile', 'Membran', 'Metal', 'Roll', 'Tar&Grv', 'WdShake', 'WdShngl'], dtype='object', name='RoofMatl')\nIndex(['AsphShn', 'BrkComm', 'CBlock', 'ImStucc', 'Stone'], dtype='object', name='Exterior1st')\nIndex(['AsphShn', 'Brk Cmn', 'CBlock', 'ImStucc', 'Other', 'Stone'], dtype='object', name='Exterior2nd')\nIndex([], dtype='object', name='MasVnrType')\nIndex(['Fa'], dtype='object', name='ExterQual')\nIndex(['Ex', 'Po'], dtype='object', name='ExterCond')\nIndex(['Stone', 'Wood'], dtype='object', name='Foundation')\nIndex([], dtype='object', name='BsmtQual')\nIndex(['Po'], dtype='object', name='BsmtCond')\nIndex([], dtype='object', name='BsmtExposure')\nIndex([], dtype='object', name='BsmtFinType1')\nIndex(['GLQ'], dtype='object', name='BsmtFinType2')\nIndex(['Floor', 'Grav', 'OthW', 'Wall'], dtype='object', name='Heating')\nIndex(['Po'], dtype='object', name='HeatingQC')\nIndex([], dtype='object', name='CentralAir')\nIndex(['FuseP', 'Mix'], dtype='object', name='Electrical')\nIndex([], dtype='object', name='KitchenQual')\nIndex(['Maj1', 'Maj2', 'Sev'], dtype='object', name='Functional')\nIndex([], dtype='object', name='FireplaceQu')\nIndex(['2Types', 'CarPort'], dtype='object', name='GarageType')\nIndex([], dtype='object', name='GarageFinish')\nIndex(['Ex', 'Gd', 'Po'], dtype='object', name='GarageQual')\nIndex(['Ex', 'Gd', 'Po'], dtype='object', name='GarageCond')\nIndex([], dtype='object', name='PavedDrive')\nIndex(['Ex', 'Fa', 'Gd'], dtype='object', name='PoolQC')\nIndex(['MnWw'], dtype='object', name='Fence')\nIndex(['Gar2', 'Othr', 'TenC'], dtype='object', name='MiscFeature')\nIndex(['CWD', 'Con', 'ConLD', 'ConLI', 'ConLw', 'Oth'], dtype='object', name='SaleType')\nIndex(['AdjLand', 'Alloca'], dtype='object', name='SaleCondition')","1e158bb2":"let us see how the cont. numerical features are distributed by making use of histogram","cacd872e":"- Index(['C (all)'], dtype='object', name='MSZoning')\n- Index(['Grvl'], dtype='object', name='Street')\n- Index([], dtype='object', name='Alley')\n- Index(['IR3'], dtype='object', name='LotShape')\n- Index([], dtype='object', name='LandContour')\n- Index(['NoSeWa'], dtype='object', name='Utilities')\n- Index(['FR3'], dtype='object', name='LotConfig')\n- Index(['Sev'], dtype='object', name='LandSlope')\n- Index(['Blueste', 'NPkVill', 'Veenker'], dtype='object', name='Neighborhood')\nIndex(['PosA', 'RRAe', 'RRNe', 'RRNn'], dtype='object', name='Condition1')\nIndex(['Artery', 'Feedr', 'PosA', 'PosN', 'RRAe', 'RRAn', 'RRNn'], dtype='object', name='Condition2')\nIndex([], dtype='object', name='BldgType')\nIndex(['1.5Unf', '2.5Fin', '2.5Unf'], dtype='object', name='HouseStyle')\nIndex(['Flat', 'Gambrel', 'Mansard', 'Shed'], dtype='object', name='RoofStyle')\nIndex(['ClyTile', 'Membran', 'Metal', 'Roll', 'Tar&Grv', 'WdShake', 'WdShngl'], dtype='object', name='RoofMatl')\nIndex(['AsphShn', 'BrkComm', 'CBlock', 'ImStucc', 'Stone'], dtype='object', name='Exterior1st')\nIndex(['AsphShn', 'Brk Cmn', 'CBlock', 'ImStucc', 'Other', 'Stone'], dtype='object', name='Exterior2nd')\nIndex([], dtype='object', name='MasVnrType')\nIndex(['Fa'], dtype='object', name='ExterQual')\nIndex(['Ex', 'Po'], dtype='object', name='ExterCond')\nIndex(['Stone', 'Wood'], dtype='object', name='Foundation')\nIndex([], dtype='object', name='BsmtQual')\nIndex(['Po'], dtype='object', name='BsmtCond')\nIndex([], dtype='object', name='BsmtExposure')\nIndex([], dtype='object', name='BsmtFinType1')\nIndex(['GLQ'], dtype='object', name='BsmtFinType2')\nIndex(['Floor', 'Grav', 'OthW', 'Wall'], dtype='object', name='Heating')\nIndex(['Po'], dtype='object', name='HeatingQC')\nIndex([], dtype='object', name='CentralAir')\nIndex(['FuseP', 'Mix'], dtype='object', name='Electrical')\nIndex([], dtype='object', name='KitchenQual')\nIndex(['Maj1', 'Maj2', 'Sev'], dtype='object', name='Functional')\nIndex([], dtype='object', name='FireplaceQu')\nIndex(['2Types', 'CarPort'], dtype='object', name='GarageType')\nIndex([], dtype='object', name='GarageFinish')\nIndex(['Ex', 'Gd', 'Po'], dtype='object', name='GarageQual')\nIndex(['Ex', 'Gd', 'Po'], dtype='object', name='GarageCond')\nIndex([], dtype='object', name='PavedDrive')\nIndex(['Ex', 'Fa', 'Gd'], dtype='object', name='PoolQC')\nIndex(['MnWw'], dtype='object', name='Fence')\nIndex(['Gar2', 'Othr', 'TenC'], dtype='object', name='MiscFeature')\nIndex(['CWD', 'Con', 'ConLD', 'ConLI', 'ConLw', 'Oth'], dtype='object', name='SaleType')\nIndex(['AdjLand', 'Alloca'], dtype='object', name='SaleCondition')","b0ccba1c":"now we work on numerical features that are continuous\nwe always want data to be normally distributed!\n","a3024f65":"cat_feat_test = [features for features in Ttdata.columns if Ttdata[features].dtypes =='O']\nlen(cat_feat_test)","f5c59d8f":"We now creat two columns (\"Name\" and \"count\") in pandas dataframe. Finally, create a bar plot to represent missing values:","c2f1896a":"# THANK YOU FOR STAYING WITH ME TILL HERE \n# ~ nitishkumar@iiserb.ac.in\n","51731608":"note that in numerical feature we have also taken in account the **TEMPORAL VARIABLES**. Let us first separate them and try to see how the price distribution follows on the basis of that!","c85c94ec":"As we can we see now, none of the columns (categorical) which had high nan values is present now. LASSO did the job for us to select important features from model!","510561bc":"for feature in num_with_nan_test:\n    ## We will replace by using median since there are outliers\n    median_value=Ttdata[feature].median()\n    \n    Ttdata[feature].fillna(median_value,inplace=True)\n\nTtdata[num_with_nan_test].isnull().sum()\n","44e92d26":"clearly lot of outliers present, we will have to work on outliers also!\n","8e553f45":"### Categorical Variables","be3f4194":"#features_cat_nan_test=[feature for feature in Ttdata.columns if Ttdata[feature].isnull().sum()>1 and Ttdata[feature].dtypes=='O']\n\n#for feature in features_cat_nan_test:\n    print(\"{}: {}% missing values\".format(feature,np.round(Ttdata[feature].isnull().mean(),4)))\n","4aded5d2":"num_with_nan_test=[feature for feature in Ttdata.columns if Ttdata[feature].isnull().sum()>1 and Ttdata[feature].dtypes!='O']\n\nWe will print the numerical nan variables and percentage of missing values\n\nfor feature in num_with_nan_test:\n    print(\"{}: {}% missing value\".format(feature,np.around(Ttdata[feature].isnull().mean(),4)))\n","c550603d":"nitishkumar@iiserb.ac.inlabels_ordered","7c66a5a1":"## Hence we have performed the various EDA techinques, performed feature engineering by filling categorical nan values by missing variable and by replacing missing numerical variables by replacing them with median. Median because the data set contains a large number of outliers!\n","315c6365":"We will first split the train data in training and testing data set","ecc090d0":"## In the following notebook we only try to perform the EDA, feature engineering and feature selection on the training data set only","3d4a326e":"Ttdata[['LotFrontage', 'LotArea','1stFlrSF','GrLivArea']].head()","a0640347":"we will check whether the con numerical variables dataset have outliers present or not using **boxplot**.","33a7df85":"Let us try to findout the relationship between each of these categories and the median sales price","d4ca5b4d":"We will now scale the other variables using minmaxscaler (except the ID and Salesprice columns)\n","81b3e1a8":"Since the numerical variables are skewed we will perform log normal distribution\n","4b958ed6":" We will check whether there is a relation between year the house is sold and the sales price","d2cb6c4c":"## After working till I realised that the way I have worked with my data set will make the task difficult in test data set, as we need to predict salesprice but in testdataset we have worked and grouped items depending on the Salesprice. Also it will be very difficult to impute the data by Rar_Var ( as test data set may have different ratio compared to train data set) or to  label the other subclasses of features by the encoding\/labelling we used above!\n\n## So, i will label this code as performing EDA+FE+FS and will try to work on this by deleting the variables having missing values and performing ONEHOTENCODING(OHE) on categorical variables. \n","a0be2886":"which returns a list whose items are the same and in the same order as iterable\u2018s items).\n\n>>> choices = ['pizza', 'pasta', 'salad', 'nachos']\n\n\nlist(enumerate(choices))\n\n\n[(0, 'pizza'), (1, 'pasta'), (2, 'salad'), (3, 'nachos')]","a532a066":"### Numerical variables\n    \n    ","d78f24c3":"since we saw that we had issues in temporal variables we will replace them also!\n","6c2ece0a":"## the important features that we received from select from model are:\n## ['MSSubClass', 'MSZoning', 'Neighborhood', 'OverallQual', 'YearRemodAdd', 'RoofStyle', 'BsmtQual', 'BsmtExposure', 'HeatingQC', 'CentralAir','1stFlrSF', 'GrLivArea', 'BsmtFullBath', 'KitchenQual', 'Fireplaces','FireplaceQu', 'GarageType', 'GarageFinish', 'GarageCars', 'PavedDrive','SaleCondition'], dtype='object')","f2a4eeae":"let us plot bar plot to see the same","1daf4571":"since there are many missing values, we try to see if the missing value and sales price play any role or not\n","5e826b79":"therefore there are 16 features in the data set which are continuous","fbb9efd0":"Ttdata[['YearBuilt']].head()","cbdad5e1":"## Now after normalizing, scaling etc since we have got the SelectfromModel info we can apply various ML algorithm to work and give predictions on the test data set!\n","71fd424d":"def replace_cat_feature(dataset,features_cat_nan_test):\n    Ttdatacopy=Ttdata.copy()\n    Ttdatacopy[features_cat_nan_test]=Ttdata[features_cat_nan_test].fillna('Missing')\n    return Ttdatacopy\n\nTtdata=replace_cat_feature(Ttdata,features_cat_nan_test)\n\nTtdata[features_cat_nan_test].isnull().sum()"}}