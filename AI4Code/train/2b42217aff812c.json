{"cell_type":{"bb7bf74f":"code","e74b5205":"code","bea7af4f":"code","fad43469":"code","74397c21":"code","73afdf88":"code","414d1d5f":"code","7cf0480a":"code","72d0692d":"code","c3a09a57":"code","95d9a49b":"code","b1bf0871":"code","a0a525ad":"code","962f15d8":"code","06cf0adc":"code","98a774b2":"code","bedc5da6":"code","2fd565ec":"code","57f9ef9b":"code","2f5f2af4":"code","9197a8dc":"code","077a4143":"code","e0f8b4c6":"code","0e2f196a":"code","30689661":"code","85cc7720":"code","e27893ef":"code","931ba196":"code","a3b86389":"code","901d59ce":"code","805b7603":"code","8682b42b":"code","ed395115":"code","f9e6208d":"code","7275d589":"code","1bde064f":"code","2f46f65a":"code","6e4494dc":"code","573f00f5":"code","953af1c1":"code","5ef6e71b":"code","77020f8d":"code","9a9aa081":"code","eaee0313":"code","fbec5ae3":"code","321eef8e":"code","76159e22":"code","927d5380":"code","ca672ce9":"code","a13ef4ba":"code","f06f0ae8":"code","a2f7d26a":"code","c69b960b":"code","26eadf6f":"code","2df75b51":"markdown","11091f46":"markdown","61c57ce5":"markdown","e5cac2d4":"markdown","bacfe020":"markdown","7bdc241b":"markdown","b1e136a3":"markdown","3202cd6e":"markdown","e1e65f1f":"markdown","39ac9aa4":"markdown","d277bed3":"markdown","1c263679":"markdown","f58994ee":"markdown","7e515ea7":"markdown"},"source":{"bb7bf74f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\n# warnings.filterwarnings('ignore')","e74b5205":"# Importing all requirements\nimport pandas as pd\nimport pandas_datareader.data as web\nimport numpy as np\nimport seaborn as sns\nimport datetime\nimport plotly.graph_objs as go\nimport statsmodels.tsa.api as smt\nimport statsmodels.tsa.stattools as stt\nimport os\nimport shutil\nimport sklearn\nfrom sklearn import preprocessing\nimport logging\nimport itertools","bea7af4f":"import tensorflow as tf\n# Disable tf logger\ntf.logging.set_verbosity(tf.logging.WARN)                                                                                     \n\n# Pyplot\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n  ","fad43469":"import matplotlib.pyplot as plt\n%matplotlib inline \nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n","74397c21":"\n\nlogger = logging.getLogger('bitcoin')\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler()\nformatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s', datefmt='%m-%d %H:%M')\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)","73afdf88":"from google.cloud import bigquery\n\n# create a helper object for this dataset\nclient = bigquery.Client()\n\nquery = \"\"\" WITH time AS \n            (\n                SELECT TIMESTAMP_MILLIS(timestamp) AS trans_time,\n                    transaction_id\n                FROM `bigquery-public-data.bitcoin_blockchain.transactions`\n            )\n            SELECT COUNT(transaction_id) AS transactions,\n                EXTRACT(MONTH FROM trans_time) AS month,\n                EXTRACT(YEAR FROM trans_time) AS year\n            FROM time\n            GROUP BY year, month \n            ORDER BY year, month\n        \"\"\"\n\n# query = '''\n# #standardSQL\n# SELECT\n#   *\n# FROM (\n#   SELECT\n#     transaction_id,\n#     COUNT(transaction_id) AS dup_transaction_count\n#   FROM\n#     `bigquery-public-data.bitcoin_blockchain.transactions`\n#   GROUP BY\n#     transaction_id)\n# WHERE\n#   dup_transaction_count > 1'''\n\nquery_job = client.query(query)\n\niterator = query_job.result(timeout=30)\nrows = list(iterator)\n\n# Transform the rows into a nice pandas dataframe\ntransactions = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n\n# Look at the first 10 headlines\ntransactions.head(10)\n# active_project=\"bigquery-public-data\",\n#                                               dataset_name=\"bitcoin_blockchain\")","414d1d5f":"transactions.plot(), transactions.hist()","7cf0480a":"transactions.shape","72d0692d":"! pip install --upgrade google-cloud-bigquery","c3a09a57":"# query = \"\"\" WITH time AS \n#             (\n#                 SELECT TIMESTAMP_MILLIS(timestamp) AS trans_time,\n#                     transaction_id\n#                 FROM `bigquery-public-data.bitcoin_blockchain.transactions`\n#             )\n#             SELECT COUNT(transaction_id) AS transactions,\n#                 EXTRACT(MONTH FROM trans_time) AS month,\n#                 EXTRACT(YEAR FROM trans_time) AS year\n#             FROM time\n#             GROUP BY year, month \n#             ORDER BY year, month\n#         \"\"\"\n\n# # note that max_gb_scanned is set to 21, rather than 1\n# transactions_per_month = bt_data.query_to_pandas_safe(query, max_gb_scanned=21)","95d9a49b":"transactions.tail()","b1bf0871":"from sklearn.model_selection import train_test_split\n\ntrain,test = train_test_split(transactions,train_size = 0.5,random_state = 42 )","a0a525ad":"test_orig = test.copy()\ntrain_orig = train.copy()","962f15d8":"train.columns, test.columns","06cf0adc":"test.dtypes, train.dtypes","98a774b2":"#  Shapes \ntrain.shape, test.shape\n","bedc5da6":"df = train.drop('year', 1)\n\nts = df['transactions']\n\nplt.figure(figsize = (8,3))\n\nplt.plot(ts, label = 'Transactions')\nplt.title('Time Series')\nplt.xlabel(\"Time[year]\")\nplt.ylabel(\"transactions\")\n\nplt.legend(loc = 'best')","2fd565ec":"transactions.groupby('year')['transactions'].mean().plot.bar()","57f9ef9b":"# KNN Implementations\n# importing required libraries\nimport pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n# # read the train and test dataset\n# train_da\n# test_data = pd.read_csv('test-data.csv')\n\n# # shape of the dataset\n# print('Shape of training data :',train_data.shape)\n# print('Shape of testing data :',test_data.shape)\n\n# Now, we need to predict the missing target variable in the test data\n# target variable - Survived\n\n# seperate the independent and target variable on training data\ntrain_x = train.drop(columns=['transactions'],axis=1)\ntrain_y = train['transactions']\n\n# seperate the independent and target variable on testing data\ntest_x = test.drop(columns=['transactions'],axis=1)\ntest_y = test['transactions']\n\n'''\nCreate the object of the K-Nearest Neighbor model\nYou can also add other parameters and test your code here\nSome parameters are : n_neighbors, leaf_size\nDocumentation of sklearn K-Neighbors Classifier: \n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html\n\n '''\nmodel = KNeighborsClassifier()  \n\n# fit the model with the training data\nmodel.fit(train_x,train_y)\n\n# Number of Neighbors used to predict the target\nprint('\\nThe number of neighbors used to predict the target : ',model.n_neighbors)\n\n# predict the target on the train dataset\npredict_train = model.predict(train_x)\nprint('\\nTarget on train data',predict_train) \n\n# Accuray Score on train dataset\naccuracy_train = accuracy_score(train_y,predict_train)\nprint('accuracy_score on train dataset : ', accuracy_train)\n\n# predict the target on the test dataset\npredict_test = model.predict(test_x)\nprint('Target on test data',predict_test) \n\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(test_y,predict_test)\nprint('accuracy_score on test dataset : ', accuracy_test)","2f5f2af4":"from google.cloud import bigquery\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport matplotlib.patheffects as PathEffects\nimport matplotlib.pylab as pylab\nimport numpy as np\nimport pandas as pd\nimport itertools\nfrom sklearn.metrics import  confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport time\nimport seaborn as sns\nfrom keras import utils, optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.losses import binary_crossentropy","9197a8dc":"miner_limit = 5000\nnon_miner_limit = 5000","077a4143":"query1 ='''\nWITH \noutput_ages AS (\n  SELECT\n    ARRAY_TO_STRING(outputs.addresses,',') AS output_ages_address,\n    MIN(block_timestamp_month) AS output_month_min,\n    MAX(block_timestamp_month) AS output_month_max\n  FROM `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(outputs) AS outputs\n  GROUP BY output_ages_address\n)\n,input_ages AS (\n  SELECT\n    ARRAY_TO_STRING(inputs.addresses,',') AS input_ages_address,\n    MIN(block_timestamp_month) AS input_month_min,\n    MAX(block_timestamp_month) AS input_month_max\n  FROM `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(inputs) AS inputs\n  GROUP BY input_ages_address\n)\n,output_monthly_stats AS (\n  SELECT\n    ARRAY_TO_STRING(outputs.addresses,',') AS output_monthly_stats_address, \n    COUNT(DISTINCT block_timestamp_month) AS output_active_months,\n    COUNT(outputs) AS total_tx_output_count,\n    SUM(value) AS total_tx_output_value,\n    AVG(value) AS mean_tx_output_value,\n    STDDEV(value) AS stddev_tx_output_value,\n    COUNT(DISTINCT(`hash`)) AS total_output_tx,\n    SUM(value)\/COUNT(block_timestamp_month) AS mean_monthly_output_value,\n    COUNT(outputs.addresses)\/COUNT(block_timestamp_month) AS mean_monthly_output_count\n  FROM `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(outputs) AS outputs\n  GROUP BY output_monthly_stats_address\n)\n,input_monthly_stats AS (\n  SELECT\n    ARRAY_TO_STRING(inputs.addresses,',') AS input_monthly_stats_address, \n    COUNT(DISTINCT block_timestamp_month) AS input_active_months,\n    COUNT(inputs) AS total_tx_input_count,\n    SUM(value) AS total_tx_input_value,\n    AVG(value) AS mean_tx_input_value,\n    STDDEV(value) AS stddev_tx_input_value,\n    COUNT(DISTINCT(`hash`)) AS total_input_tx,\n    SUM(value)\/COUNT(block_timestamp_month) AS mean_monthly_input_value,\n    COUNT(inputs.addresses)\/COUNT(block_timestamp_month) AS mean_monthly_input_count\n  FROM `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(inputs) AS inputs\n  GROUP BY input_monthly_stats_address\n)\n,output_idle_times AS (\n  SELECT\n    address AS idle_time_address,\n    AVG(idle_time) AS mean_output_idle_time,\n    STDDEV(idle_time) AS stddev_output_idle_time\n  FROM\n  (\n    SELECT \n      event.address,\n      IF(prev_block_time IS NULL, NULL, UNIX_SECONDS(block_time) - UNIX_SECONDS(prev_block_time)) AS idle_time\n    FROM (\n      SELECT\n        ARRAY_TO_STRING(outputs.addresses,',') AS address, \n        block_timestamp AS block_time,\n        LAG(block_timestamp) OVER (PARTITION BY ARRAY_TO_STRING(outputs.addresses,',') ORDER BY block_timestamp) AS prev_block_time\n      FROM `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(outputs) AS outputs\n    ) AS event\n    WHERE block_time != prev_block_time\n  )\n  GROUP BY address\n)\n,input_idle_times AS (\n  SELECT\n    address AS idle_time_address,\n    AVG(idle_time) AS mean_input_idle_time,\n    STDDEV(idle_time) AS stddev_input_idle_time\n  FROM\n  (\n    SELECT \n      event.address,\n      IF(prev_block_time IS NULL, NULL, UNIX_SECONDS(block_time) - UNIX_SECONDS(prev_block_time)) AS idle_time\n    FROM (\n      SELECT\n        ARRAY_TO_STRING(inputs.addresses,',') AS address, \n        block_timestamp AS block_time,\n        LAG(block_timestamp) OVER (PARTITION BY ARRAY_TO_STRING(inputs.addresses,',') ORDER BY block_timestamp) AS prev_block_time\n      FROM `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(inputs) AS inputs\n    ) AS event\n    WHERE block_time != prev_block_time\n  )\n  GROUP BY address\n)\n--,miners AS (\n--)\n\n(SELECT\n  TRUE AS is_miner,\n  output_ages_address AS address,\n  UNIX_SECONDS(CAST(output_ages.output_month_min AS TIMESTAMP)) AS output_month_min,\n  UNIX_SECONDS(CAST(output_ages.output_month_max AS TIMESTAMP)) AS output_month_max,\n  UNIX_SECONDS(CAST(input_ages.input_month_min AS TIMESTAMP)) AS input_month_min,\n  UNIX_SECONDS(CAST(input_ages.input_month_max AS TIMESTAMP)) AS input_month_max,\n  UNIX_SECONDS(CAST(output_ages.output_month_max AS TIMESTAMP)) - UNIX_SECONDS(CAST(output_ages.output_month_min AS TIMESTAMP)) AS output_active_time,\n  UNIX_SECONDS(CAST(input_ages.input_month_max AS TIMESTAMP)) - UNIX_SECONDS(CAST(input_ages.input_month_min AS TIMESTAMP)) AS input_active_time,\n  UNIX_SECONDS(CAST(output_ages.output_month_max AS TIMESTAMP)) - UNIX_SECONDS(CAST(input_ages.input_month_max AS TIMESTAMP)) AS io_max_lag,\n  UNIX_SECONDS(CAST(output_ages.output_month_min AS TIMESTAMP)) - UNIX_SECONDS(CAST(input_ages.input_month_min AS TIMESTAMP)) AS io_min_lag,\n  output_monthly_stats.output_active_months,\n  output_monthly_stats.total_tx_output_count,\n  output_monthly_stats.total_tx_output_value,\n  output_monthly_stats.mean_tx_output_value,\n  output_monthly_stats.stddev_tx_output_value,\n  output_monthly_stats.total_output_tx,\n  output_monthly_stats.mean_monthly_output_value,\n  output_monthly_stats.mean_monthly_output_count,\n  input_monthly_stats.input_active_months,\n  input_monthly_stats.total_tx_input_count,\n  input_monthly_stats.total_tx_input_value,\n  input_monthly_stats.mean_tx_input_value,\n  input_monthly_stats.stddev_tx_input_value,\n  input_monthly_stats.total_input_tx,\n  input_monthly_stats.mean_monthly_input_value,\n  input_monthly_stats.mean_monthly_input_count,\n  output_idle_times.mean_output_idle_time,\n  output_idle_times.stddev_output_idle_time,\n  input_idle_times.mean_input_idle_time,\n  input_idle_times.stddev_input_idle_time\nFROM\n  output_ages, output_monthly_stats, output_idle_times,\n  input_ages,  input_monthly_stats, input_idle_times\nWHERE TRUE\n  AND output_ages.output_ages_address = output_monthly_stats.output_monthly_stats_address\n  AND output_ages.output_ages_address = output_idle_times.idle_time_address\n  AND output_ages.output_ages_address = input_monthly_stats.input_monthly_stats_address\n  AND output_ages.output_ages_address = input_ages.input_ages_address\n  AND output_ages.output_ages_address = input_idle_times.idle_time_address\n  AND output_ages.output_ages_address IN\n(\n  SELECT \n    ARRAY_TO_STRING(outputs.addresses,',') AS miner\n  FROM \n  `bigquery-public-data.crypto_bitcoin.blocks` AS blocks,\n  `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(outputs) AS outputs\n  WHERE blocks.hash = transactions.block_hash \n    AND is_coinbase IS TRUE\n    AND ( FALSE\n      --\n      -- miner signatures from https:\/\/en.bitcoin.it\/wiki\/Comparison_of_mining_pools\n      --\n      OR coinbase_param LIKE '%4d696e656420627920416e74506f6f6c%' --AntPool\n      OR coinbase_param LIKE '%2f42434d6f6e737465722f%' --BCMonster\n      --BitcoinAffiliateNetwork\n      OR coinbase_param LIKE '%4269744d696e746572%' --BitMinter\n      --BTC.com\n      --BTCC Pool\n      --BTCDig\n      OR coinbase_param LIKE '%2f7374726174756d2f%' --Btcmp\n      --btcZPool.com\n      --BW Mining\n      OR coinbase_param LIKE '%456c6967697573%' --Eligius\n      --F2Pool\n      --GHash.IO\n      --Give Me COINS\n      --Golden Nonce Pool\n      OR coinbase_param LIKE '%2f627261766f2d6d696e696e672f%' --Bravo Mining\n      OR coinbase_param LIKE '%4b616e6f%' --KanoPool\n      --kmdPool.org\n      OR coinbase_param LIKE '%2f6d6d706f6f6c%' --Merge Mining Pool\n      --MergeMining\n      --Multipool\n      --P2Pool\n      OR coinbase_param LIKE '%2f736c7573682f%' --Slush Pool\n      --ZenPool.org\n    )\n  GROUP BY miner\n  HAVING COUNT(1) >= 20 \n)\nLIMIT {})\nUNION ALL\n(SELECT\n  FALSE AS is_miner,\n  output_ages_address AS address,\n  UNIX_SECONDS(CAST(output_ages.output_month_min AS TIMESTAMP)) AS output_month_min,\n  UNIX_SECONDS(CAST(output_ages.output_month_max AS TIMESTAMP)) AS output_month_max,\n  UNIX_SECONDS(CAST(input_ages.input_month_min AS TIMESTAMP)) AS input_month_min,\n  UNIX_SECONDS(CAST(input_ages.input_month_max AS TIMESTAMP)) AS input_month_max,\n  UNIX_SECONDS(CAST(output_ages.output_month_max AS TIMESTAMP)) - UNIX_SECONDS(CAST(output_ages.output_month_min AS TIMESTAMP)) AS output_active_time,\n  UNIX_SECONDS(CAST(input_ages.input_month_max AS TIMESTAMP)) - UNIX_SECONDS(CAST(input_ages.input_month_min AS TIMESTAMP)) AS input_active_time,\n  UNIX_SECONDS(CAST(output_ages.output_month_max AS TIMESTAMP)) - UNIX_SECONDS(CAST(input_ages.input_month_max AS TIMESTAMP)) AS io_max_lag,\n  UNIX_SECONDS(CAST(output_ages.output_month_min AS TIMESTAMP)) - UNIX_SECONDS(CAST(input_ages.input_month_min AS TIMESTAMP)) AS io_min_lag,\n  output_monthly_stats.output_active_months,\n  output_monthly_stats.total_tx_output_count,\n  output_monthly_stats.total_tx_output_value,\n  output_monthly_stats.mean_tx_output_value,\n  output_monthly_stats.stddev_tx_output_value,\n  output_monthly_stats.total_output_tx,\n  output_monthly_stats.mean_monthly_output_value,\n  output_monthly_stats.mean_monthly_output_count,\n  input_monthly_stats.input_active_months,\n  input_monthly_stats.total_tx_input_count,\n  input_monthly_stats.total_tx_input_value,\n  input_monthly_stats.mean_tx_input_value,\n  input_monthly_stats.stddev_tx_input_value,\n  input_monthly_stats.total_input_tx,\n  input_monthly_stats.mean_monthly_input_value,\n  input_monthly_stats.mean_monthly_input_count,\n  output_idle_times.mean_output_idle_time,\n  output_idle_times.stddev_output_idle_time,\n  input_idle_times.mean_input_idle_time,\n  input_idle_times.stddev_input_idle_time\nFROM\n  output_ages, output_monthly_stats, output_idle_times,\n  input_ages,  input_monthly_stats, input_idle_times\nWHERE TRUE\n  AND output_ages.output_ages_address = output_monthly_stats.output_monthly_stats_address\n  AND output_ages.output_ages_address = output_idle_times.idle_time_address\n  AND output_ages.output_ages_address = input_monthly_stats.input_monthly_stats_address\n  AND output_ages.output_ages_address = input_ages.input_ages_address\n  AND output_ages.output_ages_address = input_idle_times.idle_time_address\n  AND output_ages.output_ages_address NOT IN\n(\n  SELECT \n    ARRAY_TO_STRING(outputs.addresses,',') AS miner\n  FROM \n  `bigquery-public-data.crypto_bitcoin.blocks` AS blocks,\n  `bigquery-public-data.crypto_bitcoin.transactions` AS transactions JOIN UNNEST(outputs) AS outputs\n  WHERE blocks.hash = transactions.block_hash \n    AND is_coinbase IS TRUE\n    AND ( FALSE\n      --\n      -- miner signatures from https:\/\/en.bitcoin.it\/wiki\/Comparison_of_mining_pools\n      --\n      OR coinbase_param LIKE '%4d696e656420627920416e74506f6f6c%' --AntPool\n      OR coinbase_param LIKE '%2f42434d6f6e737465722f%' --BCMonster\n      --BitcoinAffiliateNetwork\n      OR coinbase_param LIKE '%4269744d696e746572%' --BitMinter\n      --BTC.com\n      --BTCC Pool\n      --BTCDig\n      OR coinbase_param LIKE '%2f7374726174756d2f%' --Btcmp\n      --btcZPool.com\n      --BW Mining\n      OR coinbase_param LIKE '%456c6967697573%' --Eligius\n      --F2Pool\n      --GHash.IO\n      --Give Me COINS\n      --Golden Nonce Pool\n      OR coinbase_param LIKE '%2f627261766f2d6d696e696e672f%' --Bravo Mining\n      OR coinbase_param LIKE '%4b616e6f%' --KanoPool\n      --kmdPool.org\n      OR coinbase_param LIKE '%2f6d6d706f6f6c%' --Merge Mining Pool\n      --MergeMining\n      --Multipool\n      --P2Pool\n      OR coinbase_param LIKE '%2f736c7573682f%' --Slush Pool\n      --ZenPool.org\n    )\n  GROUP BY miner\n  HAVING COUNT(1) >= 20 \n)\nLIMIT {})\n'''.format(miner_limit, non_miner_limit)","e0f8b4c6":"bt_data = client.query(query1).to_dataframe()","0e2f196a":"bt_data.head()","30689661":"bt_data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False).head(7)\n\n","85cc7720":"print(\"Shape of data: \",bt_data.shape)","e27893ef":"bt_data.describe()","931ba196":"bt_features = bt_data.drop(labels = ['is_miner', 'address'], axis =1)\ntarget_attr = bt_data['is_miner'].values\nindices = range(len(bt_features))","a3b86389":"X = bt_data.iloc[:, 0:4].values\ny = bt_data.iloc[:, 4].values","901d59ce":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(bt_features, target_attr, indices,  test_size = 0.4)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)","805b7603":"# Shape of splited data\nprint(\"X_train shape: \", X_train.shape)\nprint(\"X_test shape: \", X_test.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"y_test shape: \", y_test.shape)","8682b42b":"X_test.head()","ed395115":"def Data_Clean():\n  print(\"Processing...\")\n# Train\n  X_train.isnull().sum()\n  X_train.info()\n\n\n# Test\n  X_test.isnull().sum()\n  X_test.info()\n  \n\nData_Clean()\nprint(\"Cleaning over..\")","f9e6208d":"bt_data[bt_data==np.inf]=np.nan\nbt_data.fillna(bt_data.mean(), inplace=True)\n\n","7275d589":"\nnumber_features = ['stddev_output_idle_time','stddev_input_idle_time']\n\nX_train = X_train.drop(number_features, axis=1)","1bde064f":"X_test = X_test.drop(number_features, axis=1)\n# y_test = y_test.drop(number_features, axis=1)\n# y_train = y_train.drop(number_features, axis=1)","2f46f65a":"X_test.head()","6e4494dc":"# Feature Scaling\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","573f00f5":"from sklearn.ensemble import RandomForestClassifier\n\nres = RandomForestClassifier(n_estimators=100, class_weight = 'balanced')\nres.fit(X_train, y_train)\ny_pred = res.predict(X_test)\nprobs = res.predict_proba(X_test)[:, 1]","953af1c1":"params = {'legend.fontsize': 'small',\n         'axes.labelsize': 'x-small',\n         'axes.titlesize':'small',\n         'xtick.labelsize':'x-small',\n         'ytick.labelsize':'x-small'}\npylab.rcParams.update(params)","5ef6e71b":" def plot_confusion_matrix(cm, classes, normalize = False, title = 'Visualized Confusion matrix', cmap = plt.cm.Blues):\n   \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis = 1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    dummy = np.array([[0, 0], [0, 0]])\n    plt.figure(figsize = (6, 6))\n    plt.imshow(dummy, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment = \"center\",\n                 color = \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nclass_names = ['not mining pool', 'mining pool']\nnp.set_printoptions(precision = 2)\n\n# Plot confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes = class_names, normalize = False, title = 'Bitcoin Miner Predicted plot')\n\nplt.show()","77020f8d":"accuracy_rate = (cnf_matrix[0][0] + cnf_matrix[1][1]) \/ (cnf_matrix[0][0] + cnf_matrix[1][1] + cnf_matrix[0][1] + cnf_matrix[1][0])\n","9a9aa081":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nprint(\"___________Random-Forest-Classifier_____________\")\n# print(\"\\nReport: \", classification_report(X_test,y_pred.round()))\nprint(\"\\n\\t\\tAccuracy:  {}%\".format(accuracy_rate*100))","eaee0313":"# KNN Implementations\n\nimport pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nmodel = KNeighborsClassifier()  \nmodel.n_neighbors = 3\n# fit the model with the training data\nmodel.fit(X_train,y_train)\n\n# Number of Neighbors used to predict the target\nprint('\\nThe number of neighbors used to predict the target : ',model.n_neighbors)\n\n# predict the target on the train dataset\npredict_train = model.predict(X_train)\nprint('\\nTarget on train data',predict_train) \n\n# Accuray Score on train dataset\naccuracy_train = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : {} %'.format(accuracy_train*100))\n\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data',predict_test) \n\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(y_test,predict_test)\nprint('accuracy_score on test dataset : {}%'.format(accuracy_test*100))","fbec5ae3":"from sklearn.metrics import classification_report\nprint(\"\\n\\t\\t\\t______Report_____\\n\\n\",classification_report(y_test, y_pred))\nprint(\"\\n_____Confusion Matrix______\\n\\n\",confusion_matrix(y_test, y_pred) )\n\n","321eef8e":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport io\n%matplotlib inline","76159e22":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout","927d5380":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))","ca672ce9":"\nlr = 0.001\nregressor = Sequential()\n\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.55))\n\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.5))\n\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.5))\n\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.5))\n\nregressor.add(Dense(units = 1))\nrmsprop = optimizers.RMSprop(lr)\n\n# regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n    \nregressor.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['binary_accuracy'])\nhistory = regressor.fit(X_train, y_train, epochs = 200, batch_size = 800)\n\n","a13ef4ba":"regressor.summary()\n","f06f0ae8":"print(\"\\n.....Confusion-Matrix of LSTM....\\n\\n\", confusion_matrix(y_test, y_pred))","a2f7d26a":"# Testing Accuracy\nscores = regressor.evaluate(X_test, y_test, verbose = 0)\nprint(\"Accuracy: {}%\" .format(scores[1]*100))","c69b960b":"# # summarize history for accuracy\n\n# ['acc', 'val_acc','loss','val_loss']\n# plt.plot(history.history['acc'])\n# plt.plot(history.history['val_acc'])\n# plt.title('model accuracy')\n# plt.ylabel('accuracy')\n# plt.xlabel('epoch')\n# plt.legend(['X_train', 'X_test'], loc='upper left')\n# plt.show()\n# # summarize history for loss\n# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('model loss')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\n# plt.show()","26eadf6f":"import plotly.graph_objects as go\n\nfig = go.Figure(data=[go.Table(header=dict(values=['LSTM Model', 'KNN-Classification','Random Forest Classification']),\n                 cells=dict(values=[\"Accuracy: {}%\" .format(scores[1]*100), 'Accuracy: {}%'.format(accuracy_test*100),\"Accuracy:  {}%\".format(accuracy_rate*100)]))\n                     ])\n\nfig.update_layout(width=1000, height=300)\nfig.update_layout(\n    title=go.layout.Title(\n        text=\"Fig: Accuracy Comparision between different Machine Learning algorithms\",\n        xref=\"paper\",\n        x=0))\nfig.show()","2df75b51":"* Logger establishment\/Customization","11091f46":"___\n\n* ## Prediction using LSTM","61c57ce5":"* #### Splitting into Training and Testing dataset for training","e5cac2d4":"### Data Pre-Processing and Cleaning...","bacfe020":"> Building the Confusion Matrix","7bdc241b":"> Imports Required","b1e136a3":"_________________________________________________________________________________________________________________________________________\n## Data Importing\n","3202cd6e":"### Feature Scalling... extracting features and balanced the dataset","e1e65f1f":" > Importing Required Modules","39ac9aa4":"___\n\n* ## Predict Miner using KNN Classification Algorithm...","d277bed3":"### Analysis of Bitcoin Transactions","1c263679":"* ### Visualization","f58994ee":"> Assigning  LSTM model ","7e515ea7":"* ### Random Forest using Classification Method"}}