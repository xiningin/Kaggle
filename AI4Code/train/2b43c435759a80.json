{"cell_type":{"89d4d243":"code","329dbecd":"code","3744e3a2":"code","495fabae":"code","acd95d09":"code","c4de0ef7":"code","99b13c50":"code","2432992b":"code","6ffc726c":"code","c633e2d3":"code","e4d246e0":"code","a31e143b":"code","df908406":"code","a46ed72d":"code","aa729c0a":"code","08e45232":"code","dfb2bbbb":"code","d883d3bf":"markdown","031af045":"markdown","bebcaed2":"markdown","09c454fc":"markdown"},"source":{"89d4d243":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","329dbecd":"\n\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.inception_v3 import InceptionV3\n","3744e3a2":"\ntrain_dir = '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/train'\ntest_dir = '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test'\n\ntrain_Pnuemonia_dir = '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/train\/PNEUMONIA'\ntrain_Normal_dir = '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/train\/NORMAL'\n\n\ntest_Pnuemonia_dir = '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\/PNEUMONIA'\ntest_Normal_dir = '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\/NORMAL'\n\ndir_list = [train_Pnuemonia_dir,train_Normal_dir,test_Pnuemonia_dir,test_Normal_dir]\n\nfor d in dir_list:\n    print(d, len(os.listdir(d)))","495fabae":"\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255.0,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                   target_size=(150,150),\n                                                   batch_size=64,\n                                                   class_mode='categorical')\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\nvalidation_generator = validation_datagen.flow_from_directory(test_dir,\n                                                             target_size=(150,150),\n                                                             batch_size=62,\n                                                             class_mode='categorical')","acd95d09":"# callback function\n\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=5,\n                                                 restore_best_weights=True)","c4de0ef7":"from keras.applications import VGG16\n\n# VGG16 was designed to work on 224 x 224 pixel input images sizes\nimg_rows = 150\nimg_cols = 150\n\n\n#Loads the VGG16 model \nvgg16 = VGG16(weights = 'imagenet', \n                 include_top = False, \n                 input_shape = (img_rows, img_cols, 3))","99b13c50":"# Here we freeze the last 4 layers \n# Layers are set to trainable as True by default\nfor layer in vgg16.layers:\n    layer.trainable = False\n    \n\n\n# Let's print our layers \nfor (i,layer) in enumerate(vgg16.layers):\n    \n    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)","2432992b":"def addTopModel(bottom_model, num_classes, D=256):\n    \"\"\"creates the top or head of the model that will be \n    placed ontop of the bottom layers\"\"\"\n    top_model = bottom_model.output\n    top_model = Flatten(name = \"flatten\")(top_model)\n    top_model = Dense(D, activation = \"relu\")(top_model)\n    top_model = Dropout(0.3)(top_model)\n    top_model = Dense(num_classes, activation = \"sigmoid\")(top_model)\n    return top_model","6ffc726c":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\n\nnum_classes = 2\n\nFC_Head = addTopModel(vgg16, num_classes)\n\nmodel = Model(inputs=vgg16.input, outputs=FC_Head)\n\nprint(model.summary())","c633e2d3":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='categorical_crossentropy',\n              metrics = ['categorical_accuracy'])\n\nmodel.summary()","e4d246e0":"history = model.fit(train_generator,\n                   epochs=10,\n                   verbose=1,\n                   validation_data=validation_generator,\n                   callbacks=early_stopping_cb)","a31e143b":"# plot accuracy and loss\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# accuracy\n\nplt.plot(epochs, acc, 'b', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b--', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\n# loss\n\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'r--', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","df908406":"validation_generator.class_indices","a46ed72d":" validation_steps = 200\n\nval = model.evaluate(validation_generator, steps = validation_steps)\n\nprint(\"loss: {:.2f}\".format(val[0]))\nprint(\"accuracy: {:.2f}\".format(val[1]))","aa729c0a":"class_dict = {0:'Normal',\n              1:'Pneumonia'}","08e45232":"import cv2","dfb2bbbb":"file_path =  '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\/PNEUMONIA\/SARS-10.1148rg.242035193-g04mr34g07b-Fig7b-day12.jpeg'\ntest_image = cv2.imread(file_path)\ntest_image = cv2.resize(test_image, (150,150),interpolation=cv2.INTER_CUBIC)\nplt.imshow(test_image)\ntest_image = np.expand_dims(test_image,axis=0)\nprobs = model.predict(test_image)\npred_class = np.argmax(probs)\n\npred_class = class_dict[pred_class]\n\nprint('prediction class: ',pred_class)\n\n","d883d3bf":"**Fit The Train and Test to The Image Data Generator**","031af045":"**Defining The Model Architecture **","bebcaed2":"**Load the Train and Test Directories**","09c454fc":"**Import the Necessary Dependencies**"}}