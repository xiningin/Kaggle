{"cell_type":{"9018839f":"code","f8faa60c":"code","703343ce":"code","3fcc882c":"code","0d589937":"code","ebbbabe8":"markdown"},"source":{"9018839f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#load data\ndftrain=pd.read_csv('\/kaggle\/input\/learn-together\/train.csv')\ndftest=pd.read_csv('\/kaggle\/input\/learn-together\/test.csv')\n\n####### DATA PREPARATION #####","f8faa60c":"#https:\/\/www.kaggle.com\/arateris\/2-layer-k-fold-learning-forest-cover \n#Fixing Hillshade_3pm\n#replacing the zeros for better guess, mainly to avoid zeros in the feature engineering and fake outliers. \nnum_train = len(dftrain)\ntmp = dftrain.drop('Cover_Type', axis = 1)\nall_data = tmp.append(dftest)\n\ncols_for_HS = ['Aspect','Slope', 'Hillshade_9am','Hillshade_Noon']\nHS_zero = all_data[all_data.Hillshade_3pm==0]\nHS_train = all_data[all_data.Hillshade_3pm!=0]\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf_hs = RandomForestRegressor(n_estimators=100).fit(HS_train[cols_for_HS], HS_train.Hillshade_3pm)\nout = rf_hs.predict(HS_zero[cols_for_HS]).astype(int)\n\n#I couldn't make this line work, feature not used\n#all_data.loc[HS_zero.index,'Hillshade_3pm'] = out\n#dftrain['Hillshade_3pm']= all_data.loc[:num_train,'Hillshade_3pm']\n#dftest['Hillshade_3pm']= all_data.loc[num_train:,'Hillshade_3pm']\n\n# Add PCA features\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=0.99).fit(all_data)\ntrans = pca.transform(all_data)\n\nfor i in range(trans.shape[1]):\n    col_name= 'pca'+str(i+1)\n    dftrain[col_name] = trans[:num_train, i]\n    dftest[col_name] = trans[num_train:, i]\n\n#https:\/\/www.kaggle.com\/evimarp\/top-6-roosevelt-national-forest-competition\ndef euclidean(df):\n    df['Euclidean_distance_to_hydro'] = (df.Vertical_Distance_To_Hydrology**2 \n                                         + df.Horizontal_Distance_To_Hydrology**2)**.5\n    return df\n\ndftrain = euclidean(dftrain)\ndftest = euclidean(dftest)\n\nfrom itertools import combinations\ndef distances(df):\n    cols = [\n        'Horizontal_Distance_To_Roadways',\n        'Horizontal_Distance_To_Fire_Points',\n        'Horizontal_Distance_To_Hydrology',\n    ]\n    df['distance_mean'] = df[cols].mean(axis=1)\n    df['distance_sum'] = df[cols].sum(axis=1)\n    df['distance_road_fire'] = df[cols[:2]].mean(axis=1)\n    df['distance_hydro_fire'] = df[cols[1:]].mean(axis=1)\n    df['distance_road_hydro'] = df[[cols[0], cols[2]]].mean(axis=1)\n    \n    df['distance_sum_road_fire'] = df[cols[:2]].sum(axis=1)\n    df['distance_sum_hydro_fire'] = df[cols[1:]].sum(axis=1)\n    df['distance_sum_road_hydro'] = df[[cols[0], cols[2]]].sum(axis=1)\n    \n    df['distance_dif_road_fire'] = df[cols[0]] - df[cols[1]]\n    df['distance_dif_hydro_road'] = df[cols[2]] - df[cols[0]]\n    df['distance_dif_hydro_fire'] = df[cols[2]] - df[cols[1]]\n    \n    # Vertical distances measures\n    colv = ['Elevation', 'Vertical_Distance_To_Hydrology']\n    df['Vertical_dif'] = df[colv[0]] - df[colv[1]]\n    df['Vertical_sum'] = df[colv].sum(axis=1)\n    \n    return df\n  \ndftrain = distances(dftrain)\ndftest = distances(dftest)\n    \ndef shade(df):\n    SHADES = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n    \n    df['shade_noon_diff'] = df['Hillshade_9am'] - df['Hillshade_Noon']\n    df['shade_3pm_diff'] = df['Hillshade_Noon'] - df['Hillshade_3pm']\n    df['shade_all_diff'] = df['Hillshade_9am'] - df['Hillshade_3pm']\n    df['shade_sum'] = df[SHADES].sum(axis=1)\n    df['shade_mean'] = df[SHADES].mean(axis=1)\n    \n    return df\n\ndftrain = shade(dftrain)\ndftest = shade(dftest)\n\ndef elevation(df):\n    df['ElevationHydro'] = df['Elevation'] - 0.25 * df['Euclidean_distance_to_hydro']\n    return df\n\ndftrain = elevation(dftrain)\ndftest = elevation(dftest)\n\ndef elevationV(df):\n    df['ElevationV'] = df['Elevation'] - df['Vertical_Distance_To_Hydrology']\n    return df\n\ndftrain = elevationV(dftrain)\ndftest = elevationV(dftest)\n\ndef elevationH(df):\n    df['ElevationH'] = df['Elevation'] - 0.19 * df['Horizontal_Distance_To_Hydrology']\n    return df\n\ndftrain = elevationH(dftrain)\ndftest = elevationH(dftest)\n\ndef kernel_features(df):\n    df['Elevation2'] = df['Elevation']**2\n    df['ElevationLog'] = np.log1p(df['Elevation'])\n    return df\n\ndftrain = kernel_features(dftrain)\ndftest = kernel_features(dftest)\n\ndef degree(df):\n    df['Aspect_cos'] = np.cos(np.radians(df.Aspect))\n    df['Aspect_sin'] = np.sin(np.radians(df.Aspect))\n    #df['Slope_sin'] = np.sin(np.radians(df.Slope))\n    df['Aspectcos_Slope'] = df.Slope * df.Aspect_cos\n    #df['Aspectsin_Slope'] = df.Slope * df.Aspect_sin\n    \n    return df\n\ndftrain = degree(dftrain)\ndftest = degree(dftest)\n\nfrom bisect import bisect\ncardinals = [i for i in range(45, 361, 90)]\npoints = ['N', 'E', 'S', 'W']\n\ndef cardinal(df):\n    df['Cardinal'] = df.Aspect.apply(lambda x: points[bisect(cardinals, x) % 4])\n    return df\n\ndftrain = cardinal(dftrain)\ndftest = cardinal(dftest)\n\ndef cardinal_num(df):\n    d = {'N': 0, 'E': 1, 'S': 0, 'W':-1}\n    df['Cardinal'] = df.Cardinal.apply(lambda x: d[x])\n    return df\n\ndftrain = cardinal_num(dftrain)\ndftest = cardinal_num(dftest)\n\n#adding features based on https:\/\/douglas-fraser.com\/forest_cover_management.pdf pages 21,22\n#note: not all climatic and geologic codes have a soil type\n\ndef Climatic2(row): \n    if (row['Soil_Type1'] == 1) or (row['Soil_Type2'] == 1) or (row['Soil_Type3'] == 1) or (row['Soil_Type4'] == 1) \\\n        or (row['Soil_Type5'] == 1) or (row['Soil_Type6'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Climatic2'] = dftrain.apply (lambda row: Climatic2(row), axis=1)\ndftest['Climatic2'] = dftest.apply (lambda row: Climatic2(row), axis=1)\n\ndef Climatic3(row): \n    if (row['Soil_Type7'] == 1) or (row['Soil_Type8'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Climatic3'] = dftrain.apply (lambda row: Climatic3(row), axis=1)\ndftest['Climatic3'] = dftest.apply (lambda row: Climatic3(row), axis=1)\n\ndef Climatic4(row): \n    if (row['Soil_Type9'] == 1) or (row['Soil_Type10'] == 1) or (row['Soil_Type11'] == 1) or (row['Soil_Type12'] == 1) \\\n        or (row['Soil_Type13'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Climatic4'] = dftrain.apply (lambda row: Climatic4(row), axis=1)\ndftest['Climatic4'] = dftest.apply (lambda row: Climatic4(row), axis=1)\n\ndef Climatic5(row): \n    if (row['Soil_Type14'] == 1) or (row['Soil_Type15'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Climatic5'] = dftrain.apply (lambda row: Climatic5(row), axis=1)\ndftest['Climatic5'] = dftest.apply (lambda row: Climatic5(row), axis=1)\n\ndef Climatic6(row): \n    if (row['Soil_Type16'] == 1) or (row['Soil_Type17'] == 1) or (row['Soil_Type18'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Climatic6'] = dftrain.apply (lambda row: Climatic6(row), axis=1)\ndftest['Climatic6'] = dftest.apply (lambda row: Climatic6(row), axis=1)\n\ndef Climatic7(row): \n    if (row['Soil_Type19'] == 1) or (row['Soil_Type20'] == 1) or (row['Soil_Type21'] == 1) or (row['Soil_Type22'] == 1) \\\n        or (row['Soil_Type23'] == 1) or (row['Soil_Type24'] == 1) or (row['Soil_Type25'] == 1) or (row['Soil_Type26'] == 1) \\\n        or (row['Soil_Type27'] == 1) or (row['Soil_Type28'] == 1) or (row['Soil_Type29'] == 1) or (row['Soil_Type30'] == 1) \\\n        or (row['Soil_Type31'] == 1) or (row['Soil_Type32'] == 1) or (row['Soil_Type33'] == 1) or (row['Soil_Type34'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Climatic7'] = dftrain.apply (lambda row: Climatic7(row), axis=1)\ndftest['Climatic7'] = dftest.apply (lambda row: Climatic7(row), axis=1)\n\ndef Climatic8(row): \n    if (row['Soil_Type35'] == 1) or (row['Soil_Type36'] == 1) or (row['Soil_Type37'] == 1) or (row['Soil_Type38'] == 1) \\\n        or (row['Soil_Type39'] == 1) or (row['Soil_Type40'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Climatic8'] = dftrain.apply (lambda row: Climatic8(row), axis=1)\ndftest['Climatic8'] = dftest.apply (lambda row: Climatic8(row), axis=1)\n\ndef Geologic1(row): \n    if (row['Soil_Type14'] == 1) or (row['Soil_Type15'] == 1) or (row['Soil_Type16'] == 1) or (row['Soil_Type17'] == 1) \\\n        or (row['Soil_Type19'] == 1) or (row['Soil_Type20'] == 1) or (row['Soil_Type21'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Geologic1'] = dftrain.apply (lambda row: Geologic1(row), axis=1)\ndftest['Geologic1'] = dftest.apply (lambda row: Geologic1(row), axis=1)\n\ndef Geologic2(row): \n    if (row['Soil_Type9'] == 1) or (row['Soil_Type22'] == 1) or (row['Soil_Type23'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Geologic2'] = dftrain.apply (lambda row: Geologic2(row), axis=1)\ndftest['Geologic2'] = dftest.apply (lambda row: Geologic2(row), axis=1)\n\ndef Geologic5(row): \n    if (row['Soil_Type7'] == 1) or (row['Soil_Type8'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Geologic5'] = dftrain.apply (lambda row: Geologic5(row), axis=1)\ndftest['Geologic5'] = dftest.apply (lambda row: Geologic5(row), axis=1)\n\ndef Geologic7(row): \n    if (row['Soil_Type1'] == 1) or (row['Soil_Type2'] == 1) or (row['Soil_Type3'] == 1) or (row['Soil_Type4'] == 1) \\\n        or (row['Soil_Type5'] == 1) or (row['Soil_Type6'] == 1) or (row['Soil_Type10'] == 1) \\\n        or (row['Soil_Type11'] == 1) or (row['Soil_Type12'] == 1) or (row['Soil_Type13'] == 1) or (row['Soil_Type18'] == 1) \\\n        or (row['Soil_Type24'] == 1) or (row['Soil_Type25'] == 1) or (row['Soil_Type26'] == 1) or (row['Soil_Type27'] == 1) \\\n        or (row['Soil_Type28'] == 1) or (row['Soil_Type29'] == 1) or (row['Soil_Type30'] == 1) or (row['Soil_Type31'] == 1) \\\n        or (row['Soil_Type32'] == 1) or (row['Soil_Type33'] == 1) or (row['Soil_Type34'] == 1) or (row['Soil_Type35'] == 1) \\\n        or (row['Soil_Type36'] == 1) or (row['Soil_Type37'] == 1) or (row['Soil_Type38'] == 1) or (row['Soil_Type39'] == 1) \\\n        or (row['Soil_Type40'] == 1) :\n        return 1 \n    return 0\n\ndftrain['Geologic7'] = dftrain.apply (lambda row: Geologic7(row), axis=1)\ndftest['Geologic7'] = dftest.apply (lambda row: Geologic7(row), axis=1)\n\n#Reversing One-Hot-Encoding to Categorical attributes, several articles recommend it for decision tree algorithms\n#Doing it for Soil_Type, Wilderness_Area, Geologic and Climatic\n#we are also replacing the categorical values by random numbers to difficult to the algorythm to find relationships between the values\ndftrain['Tmp']=np.where(dftrain.loc[:, 'Soil_Type1':'Soil_Type40'])[1] +1\ndftest['Tmp']=np.where(dftest.loc[:, 'Soil_Type1':'Soil_Type40'])[1] +1\n\ncols = [c for c in dftrain.columns if c[:9] != 'Soil_Type']\ndftrain=dftrain[cols]\ncols = [c for c in dftest.columns if c[:9] != 'Soil_Type']\ndftest=dftest[cols]\n\ndftrain=dftrain.rename(columns = {'Tmp':'Soil_Type'})\ndftest=dftest.rename(columns = {'Tmp':'Soil_Type'})\n\nmin=dftrain['Soil_Type'].min()\nmin2=dftest['Soil_Type'].min()\nif (min2 < min):\n    min=min2\n\nmax=dftrain['Soil_Type'].max()\nmax2=dftest['Soil_Type'].max()\nif (max2 > max):\n    max=max2\n\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\n\nfor i in range (min,max+1):\n    dftrain['Soil_Type'].replace(to_replace=i, value=s[i-min], inplace=True)\n    dftest['Soil_Type'].replace(to_replace=i, value=s[i-min], inplace=True)\n\ndftrain['Tmp']=np.where(dftrain.loc[:, 'Wilderness_Area1':'Wilderness_Area4'])[1] +1\ndftest['Tmp']=np.where(dftest.loc[:, 'Wilderness_Area1':'Wilderness_Area4'])[1] +1\n\ncols = [c for c in dftrain.columns if c[:15] != 'Wilderness_Area']\ndftrain=dftrain[cols]\ncols = [c for c in dftest.columns if c[:15] != 'Wilderness_Area']\ndftest=dftest[cols]\n\ndftrain=dftrain.rename(columns = {'Tmp':'Wilderness_Area'})\ndftest=dftest.rename(columns = {'Tmp':'Wilderness_Area'})\n\nmin=dftrain['Wilderness_Area'].min()\nmin2=dftest['Wilderness_Area'].min()\nif (min2 < min):\n    min=min2\n\nmax=dftrain['Wilderness_Area'].max()\nmax2=dftest['Wilderness_Area'].max()\nif (max2 > max):\n    max=max2\n\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\n\nfor i in range (min,max+1):\n    dftrain['Wilderness_Area'].replace(to_replace=i, value=s[i-min], inplace=True)\n    dftest['Wilderness_Area'].replace(to_replace=i, value=s[i-min], inplace=True)\n\ndftrain['Tmp']=np.where(dftrain.loc[:, 'Climatic2':'Climatic8'])[1] +1\ndftest['Tmp']=np.where(dftest.loc[:, 'Climatic2':'Climatic8'])[1] +1\n\ncols = [c for c in dftrain.columns if c[:8] != 'Climatic']\ndftrain=dftrain[cols]\ncols = [c for c in dftest.columns if c[:8] != 'Climatic']\ndftest=dftest[cols]\n\ndftrain=dftrain.rename(columns = {'Tmp':'Climatic'})\ndftest=dftest.rename(columns = {'Tmp':'Climatic'})\n\nmin=dftrain['Climatic'].min()\nmin2=dftest['Climatic'].min()\nif (min2 < min):\n    min=min2\n\nmax=dftrain['Climatic'].max()\nmax2=dftest['Climatic'].max()\nif (max2 > max):\n    max=max2\n\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\n\nfor i in range (min,max+1):\n    dftrain['Climatic'].replace(to_replace=i, value=s[i-min], inplace=True)\n    dftest['Climatic'].replace(to_replace=i, value=s[i-min], inplace=True)\n\ndftrain['Tmp']=np.where(dftrain.loc[:, 'Geologic1':'Geologic7'])[1] +1\ndftest['Tmp']=np.where(dftest.loc[:, 'Geologic1':'Geologic7'])[1] +1\n\ncols = [c for c in dftrain.columns if c[:8] != 'Geologic']\ndftrain=dftrain[cols]\ncols = [c for c in dftest.columns if c[:8] != 'Geologic']\ndftest=dftest[cols]\n\ndftrain=dftrain.rename(columns = {'Tmp':'Geologic'})\ndftest=dftest.rename(columns = {'Tmp':'Geologic'})\n\nmin=dftrain['Geologic'].min()\nmin2=dftest['Geologic'].min()\nif (min2 < min):\n    min=min2\n\nmax=dftrain['Geologic'].max()\nmax2=dftest['Geologic'].max()\nif (max2 > max):\n    max=max2\n\ns=np.random.randint(low=1, high=np.iinfo(np.int64).max, size=(max-min+1), dtype='int64')\n\nfor i in range (min,max+1):\n    dftrain['Geologic'].replace(to_replace=i, value=s[i-min], inplace=True)\n    dftest['Geologic'].replace(to_replace=i, value=s[i-min], inplace=True)","703343ce":"#split train data in features and labels\ny = dftrain.Cover_Type\nx = dftrain.drop(['Id','Cover_Type'], axis=1)\n\n# split test data in features and Ids\nIds = dftest.Id\nx_predict = dftest.drop('Id', axis=1)\n\n#split in train (80%) and test (20%) sets \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2)","3fcc882c":"##### XGBOOST #####\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\n#train the model\nmodel = XGBClassifier()\nmodel.fit(x_train, y_train)\n\n# make predictions for test data\ny_predict = model.predict(x_test)\npredictions = [round(value) for value in y_predict]\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\n# Predict!!\ny_predict = model.predict(x_predict)","0d589937":"# Save predictions to a file for submission\noutput = pd.DataFrame({'Id': Ids,\n                       'Cover_Type': y_predict})\noutput.to_csv('submission.csv', index=False)\n\n#create a link to download the file    \nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","ebbbabe8":"I started this competition investigating neural networks with this kernel https:\/\/www.kaggle.com\/mulargui\/keras-nn\nNow switching to using forests in this new kernel.\nYou can find all my notes and versions at https:\/\/github.com\/mulargui\/kaggle-Classify-forest-types"}}