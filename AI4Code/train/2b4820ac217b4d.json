{"cell_type":{"fad98284":"code","5db6cc17":"code","9a738b5a":"code","aaa1b373":"code","fa76ec50":"code","e229f2da":"code","ebeac987":"code","fc2c3cac":"code","b4cc52bf":"code","7d34b30b":"code","57f76f8d":"markdown","87d560bf":"markdown","85343e65":"markdown","80d06256":"markdown","e16136ab":"markdown","a9fa5040":"markdown","0ee06118":"markdown","46d608e2":"markdown","5bfff4e5":"markdown","053ca44f":"markdown"},"source":{"fad98284":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https:\/\/pypi.org\/simple\/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'","5db6cc17":"from kaggle_environments import evaluate, make, utils\n\nenv = make(\"connectx\", debug=True)\nenv.render()","9a738b5a":"# This agent random chooses a non-empty column.\ndef my_agent(observation, configuration):\n    \n    import numpy as np \n    np_board = np.array(observation.board).reshape((configuration.rows, configuration.columns))\n    \n    possible_moves = [c for c in range(configuration.columns) if observation.board[c] == 0]\n    \n    symbol = observation.mark\n    \n    move_values = []\n    \n    for move in possible_moves:\n        \n        new_row = 0\n        while new_row < configuration.rows and np_board[new_row, move] == 0 :\n            new_row += 1\n        new_row -= 1\n        \n        np_board[new_row, move] = symbol\n        \n        value = 0\n        \n        inarow = configuration.inarow\n        \n        for i in range(max(0, move - inarow), min(configuration.columns, move + inarow)):\n            count = 0\n            same_symbol_count = 0\n            same_or_free_count = 0\n\n            while i + count < configuration.columns and count < inarow:\n                if np_board[new_row, i + count] == symbol:\n                    same_symbol_count += 1\n                    \n                if np_board[new_row, i + count] == symbol or np_board[new_row, i + count] == 0:\n                    same_or_free_count += 1\n                count += 1\n            \n            if same_symbol_count == inarow:\n                value = max(value, 100.0)\n            elif same_or_free_count == inarow:\n                value += same_symbol_count \/ inarow\n         \n        for i in range(max(0, new_row - inarow), min(configuration.rows, new_row + inarow)):\n            count = 0\n            same_symbol_count = 0\n            same_or_free_count = 0\n            \n            while i + count < configuration.rows and count < inarow:\n                if np_board[i + count, move] == symbol:\n                    same_symbol_count += 1\n                \n                if np_board[i + count, move] == symbol or np_board[i + count, move] == 0:\n                    same_or_free_count += 1\n                count += 1\n            \n            if same_symbol_count == inarow:\n                value = max(value, 100.0)\n                \n            elif same_or_free_count == inarow:\n                value += same_symbol_count \/ inarow\n        \n        np_board[new_row, move] = 0\n        \n        move_values.append((move, value))\n    \n    best_move = max(move_values, key = lambda x: x[1])[0]\n    \n    return best_move","aaa1b373":"env.configuration","fa76ec50":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([my_agent, \"random\"])\nenv.render(mode=\"ipython\", width=500, height=450)","e229f2da":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","ebeac987":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) \/ float(len(rewards))\n\n# Run multiple episodes to estimate its performance.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=100)))\nprint(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))","fc2c3cac":"# \"None\" represents which agent you'll manually play as (first or second player).\n# env.play([None, \"negamax\"], width=500, height=450)","b4cc52bf":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","7d34b30b":"# Note: Stdout replacement is a temporary workaround.\n# import sys\n# out = sys.stdout\n# submission = utils.read_file(\"\/kaggle\/working\/submission.py\")\n# agent = utils.get_last_callable(submission)\n# sys.stdout = out\n\n# env = make(\"connectx\", debug=True)\n# env.run([agent, agent])\n# print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","57f76f8d":"# Install kaggle-environments","87d560bf":"# Play your Agent\nClick on any column to place a checker there (\"manually select action\").","85343e65":"# Create ConnectX Environment","80d06256":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n","e16136ab":"# Write Submission File\n\n","a9fa5040":"# Evaluate your Agent","0ee06118":"# Validate Submission\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely.","46d608e2":"# Test your Agent","5bfff4e5":"# Debug\/Train your Agent","053ca44f":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https:\/\/kaggle.com\/c\/connectx\/submissions) to view your score and episodes being played."}}