{"cell_type":{"71bd4d36":"code","15fd97e8":"code","701f8fb0":"code","81c610a1":"code","71087a47":"code","8c79e018":"code","920accc8":"code","95b91d7d":"code","93564947":"code","ae6f403c":"code","bafba623":"code","372f7146":"code","8d209189":"code","9257cdc4":"code","edf46edc":"code","c322972d":"code","ea8d0052":"code","0f752ddd":"code","d09e2fc5":"code","cb99c478":"code","a75b72d0":"code","6f698643":"code","7cd90d55":"code","a3c95497":"code","36f860c3":"code","fcfc0832":"code","6baaf3ff":"code","29ede2b6":"code","558f2e7e":"code","5977fefa":"code","3690a45c":"code","9c41f3a6":"code","37e2bcfa":"code","0e1d76a7":"code","5a2007bc":"code","0a83acfb":"code","2af5cf0c":"code","7e3a338d":"code","0e32debe":"code","304933b7":"markdown","6e86b693":"markdown","3eacc27b":"markdown","1ce8eb7a":"markdown","abfbeace":"markdown","b3aeefcb":"markdown","94dfebd2":"markdown","01aecc2a":"markdown","36c5e0ca":"markdown","8e67d6c5":"markdown"},"source":{"71bd4d36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15fd97e8":"# Import Libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","701f8fb0":"# Read the csv file\ndata = pd.read_csv('\/kaggle\/input\/bank-note-authentication-uci-data\/BankNote_Authentication.csv')","81c610a1":"data.head()","71087a47":"print(\"Shape of Data before preprocessing: {}\".format(data.shape))","8c79e018":"data.info()","920accc8":"# Stastical analysis of the data\ndata.describe()","95b91d7d":"# Checking the duplicate value\ndata.duplicated().sum()","93564947":"# Dropping all the duplicate values\ndata.drop_duplicates(subset=None, keep='first', inplace=True)","ae6f403c":"data.isnull().sum()","bafba623":"# Checking the null values\nsns.heatmap(data.isnull(),yticklabels = False,cbar = False,cmap = 'viridis')","372f7146":"# Detecting the ouliers\ndef detect_outlier(data):\n    outlier = []\n    threshold = 3\n    mean = np.mean(data)\n    std = np.std(data)\n    for i in data:\n        z_score = (i - mean)\/std\n        if np.abs(z_score)>threshold:\n            outlier.append(i)\n    return outlier","8d209189":"var_list = data['variance'].tolist()\nskew_list = data['skewness'].tolist()\ncurt_list = data['curtosis'].tolist()\nentr_list = data['entropy'].tolist()","9257cdc4":"var_outlier = detect_outlier(var_list)\nvar_outlier","edf46edc":"skew_outlier = detect_outlier(skew_list)\nskew_outlier","c322972d":"curt_outlier = detect_outlier(curt_list)\ncurt_outlier","ea8d0052":"entr_outlier = detect_outlier(entr_list)\nentr_outlier","0f752ddd":"# Shape of Data before removing the outliers\nprint(\"Shape of Data before removing outliers: {}\".format(data.shape))","d09e2fc5":"# Removing the outliers\ndata.drop(data[data['curtosis'] >= 14.8881].index, inplace = True)\ndata.drop(data[data['entropy'] <= -7.5034].index, inplace = True)","cb99c478":"#Shape of Data after removing the outliers\nprint(\"Shape of Data before after outliers: {}\".format(data.shape))","a75b72d0":"plt.figure(figsize =(6,4))\nsns.set_style('darkgrid')\nsns.countplot(x = 'class', data = data)\nplt.title('class (Forged VS Genuine)')\ndata['class'].value_counts(normalize = True)","6f698643":"plt.pie(data['class'].value_counts(), labels = ['Forged Note', 'Original Note'], shadow = True, autopct = '%1.2f%%');","7cd90d55":"sns.pairplot(data, hue='class') ","a3c95497":"corrmat = data.corr()\nplt.figure(figsize=(10,8))\n#plot heat map\nsns.heatmap(corrmat, annot=True, cmap=\"RdYlGn\")","36f860c3":"data.head()","fcfc0832":"# Split the Dataset\nX = data.drop(['class'], axis = 1)\ny = data['class']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","6baaf3ff":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","29ede2b6":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)","558f2e7e":"y_pred = dtc.predict(X_train)\nprint(accuracy_score(y_pred, y_train))","5977fefa":"y_pred_dtc = dtc.predict(X_test)\nprint(classification_report(y_test, y_pred_dtc))\nprint(confusion_matrix(y_test, y_pred_dtc))\nprint(accuracy_score(y_pred_dtc, y_test))","3690a45c":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","9c41f3a6":"y_pred_1 = rfc.predict(X_train)\nprint(accuracy_score(y_pred_1, y_train))","37e2bcfa":"y_pred_rfc = rfc.predict(X_test)\nprint(classification_report(y_test, y_pred_rfc))\nprint(confusion_matrix(y_test, y_pred_rfc))\nprint(accuracy_score(y_pred_rfc, y_test))","0e1d76a7":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)","5a2007bc":"y_pred_2 = knn.predict(X_train)\nprint(accuracy_score(y_pred_2, y_train))","0a83acfb":"y_pred_knn = knn.predict(X_test)\nprint(classification_report(y_test, y_pred_knn))\nprint(confusion_matrix(y_test, y_pred_knn))\nprint(accuracy_score(y_pred_knn, y_test))","2af5cf0c":"# prepare the cross-validation procedure\nfrom sklearn.model_selection import KFold\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\nrandom_grid = {'max_features': max_features,\n              'n_estimators': n_estimators}\ncv = KFold(n_splits=10, random_state=1, shuffle=True)\n# RandomizedSearchCV, using 10 fold cross validation\nrf_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid,scoring='accuracy', \n                               cv = cv, verbose=2, random_state=42, n_jobs = 1)","7e3a338d":"rf_random.fit(X_train,y_train)","0e32debe":"predictions=rf_random.predict(X_test)\nprint(classification_report(y_test, predictions))\nprint(confusion_matrix(y_test, predictions))\nprint(accuracy_score(predictions, y_test))","304933b7":"Out of above 3 algorithms RandomForestClassifier and KNeighborsClassifier performs well for this dataset. I will choose RandomForestClassifier","6e86b693":"There is no missing values in the dataset.","3eacc27b":"After applying KFold cross validation the accuracy score remains same.","1ce8eb7a":"## Data Modelling\n\n### Decision Tree Classifier","abfbeace":"## Exploratory Data Analysis","b3aeefcb":"In a dataset, Forged Note and Genuine Note are around 56% and 44% respectively.<br>\nThe datset looks like a balanced dataset.","94dfebd2":"### Random Forest Classifier","01aecc2a":"## Exploring the Dataset","36c5e0ca":"### KNeighborsClassifier","8e67d6c5":"# Bank Note Authentication\n\nData were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\nDataset can be used for Binary classification problems."}}