{"cell_type":{"c96e0f46":"code","4a7c2c66":"code","9c0eaa90":"code","cfb0ae82":"code","c2c2785e":"code","a2674aca":"code","bbf78b18":"code","1cd7531e":"code","424ce591":"code","41c28236":"code","bab8a810":"code","74e0610d":"code","2d835b85":"code","09d2ede8":"code","ce850c05":"code","f378056f":"code","6844b4fe":"markdown","3e2daa64":"markdown","93b4492c":"markdown","26653a76":"markdown","2ffaee3e":"markdown","8d69dbc5":"markdown","ce53a19a":"markdown","e7a3fae5":"markdown","256262be":"markdown"},"source":{"c96e0f46":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport torch.nn.functional as F\nimport numpy as np","4a7c2c66":"torch.__version__","9c0eaa90":"class LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n\n        # input channel = 1, output channel = 6, kernel_size = 5\n        # input size = (32, 32), output size = (28, 28)\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        # input channel = 6, output channel = 16, kernel_size = 5\n        # input size = (14, 14), output size = (10, 10)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # input dim = 16*5*5, output dim = 120\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        # input dim = 120, output dim = 84\n        self.fc2 = nn.Linear(120, 84)\n        # input dim = 84, output dim = 10\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # pool size = 2\n        # input size = (28, 28), output size = (14, 14), output channel = 6\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        # pool size = 2\n        # input size = (10, 10), output size = (5, 5), output channel = 16\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        # flatten as one dimension\n        x = x.view(x.size()[0], -1)\n        # input dim = 16*5*5, output dim = 120\n        x = F.relu(self.fc1(x))\n        # input dim = 120, output dim = 84\n        x = F.relu(self.fc2(x))\n        # input dim = 84, output dim = 10\n        x = self.fc3(x)\n        return x","cfb0ae82":"def load_data(train_batch_size, test_batch_size):\n    # Fetch training data: total 60000 samples\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST('data', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Resize((32, 32)),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,))\n                       ])),\n        batch_size=train_batch_size, shuffle=True)\n\n    # Fetch test data: total 10000 samples\n    test_loader = torch.utils.data.DataLoader(\n        datasets.MNIST('data', train=False, transform=transforms.Compose([\n            transforms.Resize((32, 32)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ])),\n        batch_size=test_batch_size, shuffle=True)\n\n    return (train_loader, test_loader)","c2c2785e":"def train(model, optimizer, epoch, train_loader, log_interval):\n    # State that you are training the model\n    model.train()\n\n    # define loss function\n    loss_fn = torch.nn.CrossEntropyLoss()\n\n    # Iterate over batches of data\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # Wrap the input and target output in the `Variable` wrapper\n        data, target = Variable(data), Variable(target)\n\n        # Clear the gradients, since PyTorch accumulates them\n        optimizer.zero_grad()\n\n        # Forward propagation\n        output = model(data)\n\n        loss = loss_fn(output, target)\n\n        # Backward propagation\n        loss.backward()\n\n        # Update the parameters(weight,bias)\n        optimizer.step()\n\n        # print log\n        if batch_idx % log_interval == 0:\n            print('Train set, Epoch {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                       100. * batch_idx \/ len(train_loader),\n                loss.data[0]))","a2674aca":"def test(model, epoch, test_loader):\n    # State that you are testing the model; this prevents layers e.g. Dropout to take effect\n    model.eval()\n\n    # Init loss & correct prediction accumulators\n    test_loss = 0\n    correct = 0\n\n    # define loss function\n    loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n\n    # Iterate over data\n    for data, target in test_loader:\n        data, target = Variable(data), Variable(target)\n        \n        # Forward propagation\n        output = model(data)\n\n        # Calculate & accumulate loss\n        test_loss += loss_fn(output, target).data[0]\n\n        # Get the index of the max log-probability (the predicted output label)\n        pred = np.argmax(output.data, axis=1)\n\n        # If correct, increment correct prediction accumulator\n        correct = correct + np.equal(pred, target.data).sum()\n\n    # Print log\n    test_loss \/= len(test_loader.dataset)\n    print('\\nTest set, Epoch {} , Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(epoch,\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct \/ len(test_loader.dataset)))","bbf78b18":"# Provide seed for the pseudorandom number generator s.t. the same results can be reproduced\ntorch.manual_seed(123)\n\nmodel = LeNet()\n\nlr = 0.01\nmomentum=0.5\noptimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n\ntrain_batch_size = 64\ntest_batch_size = 1000\ntrain_loader, test_loader = load_data(train_batch_size, test_batch_size)\n\nepochs = 10\nlog_interval = 100\nfor epoch in range(1, epochs + 1):\n    train(model, optimizer, epoch, train_loader, log_interval=log_interval)\n    test(model, epoch, test_loader)","1cd7531e":"# Show image\nImage.open('..\/input\/test_2.png')","424ce591":"# Load & transform image\nori_img = Image.open('..\/input\/test_2.png').convert('L')\nt = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\nimg = torch.autograd.Variable(t(ori_img).unsqueeze(0))\nori_img.close()","41c28236":"# Predict\nmodel.eval()\noutput = model(img)\npred = output.data.max(1, keepdim=True)[1][0][0]\nprint('Prediction: {}'.format(pred))","bab8a810":"# Show image\nImage.open('..\/input\/test_4.png')","74e0610d":"# Load & transform image\nori_img = Image.open('..\/input\/test_4.png').convert('L')\nt = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\nimg = torch.autograd.Variable(t(ori_img).unsqueeze(0))\nori_img.close()","2d835b85":"# Predict\nmodel.eval()\noutput = model(img)\npred = output.data.max(1, keepdim=True)[1][0][0]\nprint('Prediction: {}'.format(pred))","09d2ede8":"# Show image\nImage.open('..\/input\/test_6.png')","ce850c05":"# Load & transform image\nori_img = Image.open('..\/input\/test_6.png').convert('L')\nt = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\nimg = torch.autograd.Variable(t(ori_img).unsqueeze(0))\nori_img.close()","f378056f":"# Predict\nmodel.eval()\noutput = model(img)\npred = output.data.max(1, keepdim=True)[1][0][0]\nprint('Prediction: {}'.format(pred))","6844b4fe":"## Define a function to train model","3e2daa64":"## Train and evaluate model","93b4492c":"## Define LeNet","26653a76":"## Predict by model","2ffaee3e":"### First prediction: digit 4","8d69dbc5":"### First prediction: digit 6","ce53a19a":"## Define a function to load MNIST","e7a3fae5":"## Define a function to evaluate model","256262be":"### First prediction: digit 2"}}