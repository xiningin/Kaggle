{"cell_type":{"cca7b9e2":"code","3a01dd00":"code","38d8c909":"code","b6189407":"code","c9ef04ce":"code","c5bc022f":"code","4f0da008":"code","87ec2877":"code","280c95e0":"code","36fb369e":"code","9cfdc5fe":"code","b68b18c7":"code","228506c0":"code","da660b5b":"code","5d88bb6e":"code","552c5bba":"code","5d9e6640":"markdown"},"source":{"cca7b9e2":"#import\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","3a01dd00":"# loading dataset\n\nX= np.load(\"..\/input\/sign-language-digits-dataset\/X.npy\")\nY= np.load(\"..\/input\/sign-language-digits-dataset\/Y.npy\")\n\nprint(\"samples shape\", X.shape)\nprint(\"labels shape\", Y.shape)","38d8c909":"# Sample from dataset\n\nplt.imshow(X[1900].reshape(64, 64))\nplt.axis(\"off\")\nplt.colorbar()\nplt.show()","b6189407":"#overwiev datasets, labels\n\nY_df= pd.DataFrame(Y)\n\nlabel=[]\nfor i in range(0,2062):\n    if Y_df.loc[i,0]==1:\n        label.append(9)\n    elif Y_df.loc[i,1]==1:\n        label.append(0)\n    elif Y_df.loc[i,2]==1:\n        label.append(7)\n    elif Y_df.loc[i,3]==1:\n        label.append(6)\n    elif Y_df.loc[i,4]==1:\n        label.append(1)\n    elif Y_df.loc[i,5]==1:\n        label.append(8)\n    elif Y_df.loc[i,6]==1:\n        label.append(4)\n    elif Y_df.loc[i,7]==1:\n        label.append(3)\n    elif Y_df.loc[i,8]==1:\n        label.append(2)\n    elif Y_df.loc[i,9]==1:\n        label.append(5)\n        \nY_labels= pd.Series(label)\n\n# graphic\n\nplt.figure(figsize=(15,7))\n\nsns.countplot(Y_labels)\nplt.title(\"Number of sign language classes\")\nplt.xlabel(\"classes\")\nplt.ylabel(\"Number of samples\")\nprint(Y_labels.value_counts())\nplt.show()","c9ef04ce":"# Train-test-split\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.20, random_state=100)\n\nx_train= X_train.reshape(-1,64,64,1)\nx_test= X_test.reshape(-1,64,64,1)\n\nprint(\"x_train\", x_train.shape)\nprint(\"x_test\", x_test.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"y_test\", y_test.shape)","c5bc022f":"#model creating\n\nmodel= Sequential()\n\n# Convolutional layer 1\n\nmodel.add(Conv2D(filters=8, kernel_size=(5,5), padding =\"Same\", activation= \"relu\", input_shape=(64,64,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Convolutional Layer 2\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding =\"Same\", activation= \"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2), strides= (2,2)))\nmodel.add(Dropout(0.25))\n\n# Convolutional Layer 3\n\nmodel.add(Conv2D(filters=16, kernel_size=(3,3), padding =\"Same\", activation= \"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2), strides= (2,2)))\nmodel.add(Dropout(0.25))\n\n# Convolutional Layer 4\n\nmodel.add(Conv2D(filters=16, kernel_size=(3,3), padding =\"Same\", activation= \"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2), strides= (2,2)))\nmodel.add(Dropout(0.25))\n\n# Fully Connected Layers\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation= \"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation= \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation= \"softmax\"))","4f0da008":"#optimizer\noptimizer = Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999)","87ec2877":"# Compile the model\nmodel.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","280c95e0":"# Data Augmentation\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=10,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.2, # Randomly zoom image 20%\n        width_shift_range=0.1,  # randomly shift images horizontally 10%\n        height_shift_range=0.1,  # randomly shift images vertically 10%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(x_train)","36fb369e":"#Epoch and Batchsize\n\nepochs=100\nbatch_size=100","9cfdc5fe":"#Fit to model\n\nhistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_test,y_test), steps_per_epoch=x_train.shape[0] \/\/ batch_size)","b68b18c7":"Val_acc=history.history['val_accuracy'][-1]\nacc=history.history['accuracy'][-1]\nloss= history.history['loss'][-1]\nval_loss=history.history['val_loss'][-1]","228506c0":"#Results\nprint('Train accuracy of the model: ',acc)\nprint('Train loss of the model: ',loss)\nprint('Validation accuracy of the model: ',Val_acc)\nprint('Validation loss of the model: ',val_loss)","da660b5b":"#Save\nmodel.save('.\/my_model.h5')","5d88bb6e":"#Evaluate- Loss  (smooth)\n\nfrom scipy.interpolate import make_interp_spline, BSpline \n\nx_list = np.arange(0, 100) # epochs number\n\nxnew = np.linspace(x_list.min(), x_list.max(), 20)\n\nspl_val_loss = make_interp_spline(x_list, history.history[\"val_loss\"], k=3)\nspl_loss = make_interp_spline(x_list, history.history[\"loss\"], k=3)\n\ny_smooth_val_loss = spl_val_loss(xnew)\ny_smooth_loss= spl_loss(xnew)\n\nplt.figure(figsize=(12,8))\nplt.subplot(2,2,1)\nplt.plot(xnew, y_smooth_val_loss, label=\"validation_loss\", c=\"r\")\nplt.plot(xnew, y_smooth_loss, label=\"training_loss\", c=\"y\")\nplt.title(\"Training-Validation loss (smooth)\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\n\n# evaluate- loss (normal)\nplt.subplot(2,2,2)\nplt.plot(history.history[\"val_loss\"], label=\"validation_loss\", c=\"r\" )\nplt.plot(history.history[\"loss\"], label=\"training_loss\", c=\"y\" )\nplt.title(\"Training-Validation loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)","552c5bba":"\nspl_val_acc = make_interp_spline(x_list, history.history[\"val_accuracy\"], k=3)\nspl_acc = make_interp_spline(x_list, history.history[\"accuracy\"], k=3)\n\ny_smooth_val_acc = spl_val_acc(xnew)\ny_smooth_acc= spl_acc(xnew)\n\nplt.figure(figsize=(12,8))\nplt.subplot(2,2,1)\nplt.plot(xnew, y_smooth_val_acc, label=\"validation_acc\", c=\"r\")\nplt.plot(xnew, y_smooth_acc, label=\"training_acc\", c=\"y\")\nplt.title(\"Training-Validation Accuracy (smooth)\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.show()\n#Evaluate- Accuracy\n\n\nplt.figure(figsize=(12,8))\nplt.subplot(2,2,2)\nplt.plot(history.history[\"val_accuracy\"], label=\"validation_accuracy\", c=\"r\")\nplt.plot(history.history[\"accuracy\"], label=\"training_accuracy\", c=\"y\")\nplt.title(\"Training-Validation Accuracy\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.show()","5d9e6640":"The CNN model was trained using the sign language dataset. The limited number of data affects the success of the model. With the data augmentation method, the prediction accuracy was tried to be increased. Model performance values are shown below. I am waiting for your suggestions to improve model performance.\n\nTrain accuracy of the model:  0.90\nTrain loss of the model:  0.31\nValidation accuracy of the model:  0.98\nValidation loss of the model:  0.11"}}