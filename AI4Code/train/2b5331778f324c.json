{"cell_type":{"308260dd":"code","2a471676":"code","038105e7":"code","85343254":"code","27b7e0b6":"code","a5adeb79":"code","ca766b9a":"code","203d4865":"code","cc6ffda0":"code","9c654870":"code","2e15c833":"code","b3feb695":"code","ddb576ae":"code","b860a78b":"code","46368467":"code","f6c2627f":"code","8f329c27":"code","2041a7a7":"code","bbe08035":"markdown","af7a9cab":"markdown","999b4d51":"markdown"},"source":{"308260dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport fuzzywuzzy\nfrom fuzzywuzzy import process\nimport chardet\n\nfrom subprocess import check_output\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2a471676":"# this cell is zeeshan's script for intial cleaning\n# Read data\nNA2 = pd.read_csv(\"..\/input\/National Assembly 2002 - Updated.csv\", encoding = \"ISO-8859-1\")\nNA8 = pd.read_csv(\"..\/input\/National Assembly 2008.csv\", encoding = \"ISO-8859-1\")\nNA13 = pd.read_csv(\"..\/input\/National Assembly 2013.csv\", encoding = \"ISO-8859-1\")\n\n# rename coloumns\nNA8.rename(columns={'Unnamed: 0':'District'}, inplace=True)\nNA13.rename(columns={'Unnamed: 0':'District'}, inplace=True)\n\n#Get districts separated out of seats\nNA8.District = NA8.Seat.str.split(\"-\", expand=True)[0]\nNA13.District = NA13.Seat.str.split(\"-\", expand=True)[0]\n\n#Change Data type of turnout\nNA8['Turnout'] = NA8['Turnout'].str.rstrip('%').str.rstrip(' ')\nNA13['Turnout'] = NA13['Turnout'].str.rstrip('%').str.rstrip(' ')\nNA8['Turnout'] = pd.to_numeric(NA8['Turnout'], errors='coerce')\nNA13['Turnout'] = pd.to_numeric(NA13['Turnout'], errors='coerce')\n\n#Add Year Column\nNA2['Year'] = \"2002\"\nNA8['Year'] = \"2008\"\nNA13['Year'] = \"2013\"\n\n#Rename coloumns in NA2\nNA2.rename(columns={'Constituency_title':'ConstituencyTitle', 'Candidate_Name':'CandidateName', 'Total_Valid_Votes':'TotalValidVotes',\n                    'Total_Rejected_Votes':'TotalRejectedVotes', 'Total_Votes':'TotalVotes', 'Total_Registered_Voters':'TotalRegisteredVoters', }, inplace=True)\n\n#Concat all results\ndf = pd.concat([NA2, NA8, NA13])\n\ndf['District'] = df['District'].str.lower()\n# remove trailing white spaces\ndf['District'] = df['District'].str.strip()\n","038105e7":"#convert textual content to lower case\ndf['CandidateName'] = df['CandidateName'].str.lower()\ndf['Party'] = df['Party'].str.lower()\n# remove trailing white spaces\ndf['CandidateName'] = df['CandidateName'].str.strip()\ndf['Party'] = df['Party'].str.strip()","85343254":"# Let's write a function to filter parties which fuzzy wuzzy thinks are same but actually they are not\n# Parties like Pakistan Muslim League(n),Pakistan Muslim League(qa),Pakistan Muslim League(q) and Pakistan Muslim League will have high similarity scores \ndef filter_similarity_exceptions(party_to_match,party_list):\n    #find sub party name\n    sub_party = party_to_match[party_to_match.find(\"(\")+1:party_to_match.find(\")\")].strip()\n    \n    # if party_to_match has no sub party, filter out parties with sub party from party_list\n    if(len(party_to_match.split('(')) < 2):\n        party_list = [x for x in party_list if len(x.split('(')) < 2]\n    \n    #make sure sub party names upto length 2 are same, because they can fall in specified similarity score threshold \n    if(len(sub_party) <= 2):\n        party_list = [x for x in party_list if x[x.find(\"(\")+1:x.find(\")\")].strip() == sub_party]\n    \n    return party_list","27b7e0b6":"# modification of function written by zeeshan to filter similarity exceptions\ndef replace_matches_in_party(df,string_to_match, min_ratio = 90, column='Party'):\n    # get a list of unique strings\n    strings = df[column].unique()\n    \n    # get the top 10 closest matches to our input string\n    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n    # only get matches with a ratio > 90\n    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n    \n    #filter similarity exceptions\n    close_matches = filter_similarity_exceptions(string_to_match,close_matches)\n    \n    # get the rows of all the close matches in our dataframe\n    rows_with_matches = df[column].isin(close_matches)\n\n    # replace all rows with close matches with the input matches \n    df.loc[rows_with_matches, column] = string_to_match","a5adeb79":"# iterate unique parties and replace the same parties which are spelled differntly\nfor party in df['Party'].unique():\n    replace_matches_in_party(df,party, min_ratio = 93, column='Party')","ca766b9a":"# have a look at the results after sorting\ncandidates = df.sort_values('Party')['Party'].unique()\nprint(candidates)","203d4865":"# Ah it's look like, if we decrease the threshold(min_score) further it may cause problems\n# I know these parties have addition of words like Pakitan and Party but are similar, let's replace them\ndf['Party'].replace(['muttahida qaumi movement pakistan'], 'muttahida qaumi movement', inplace = True)\ndf['Party'].replace(['indeindependentdente','independent (retired)','indepndent'], 'independent',inplace = True)\ndf['Party'].replace(['indeindependentdente','independent (retired)','indepndent'], 'independent',inplace = True)\ndf['Party'].replace(['muttahidda majlis-e-amal pakistan','mutthida\\xa0majlis-e-amal\\xa0pakistan'\n                     ,'mutthida\u00ef\u00bf\u00bdmajlis-e-amal\u00ef\u00bf\u00bdpakistan'] \n                     ,'muttahidda majlis-e-amal' ,inplace = True)\ndf['Party'].replace(['nazim-e-mistafa'], 'nizam-e-mustafa party' ,inplace = True)","cc6ffda0":"# we are all set to meet winners\n#reset the index \ndf.reset_index(inplace = True)\n#find candidates with max votes in a constituency and year, aka the winners\nwinning_candidates = df.loc[df.groupby(['Year','ConstituencyTitle'])['Votes'].idxmax()].sort_values('ConstituencyTitle')\nwinning_candidates.head()","9c654870":"# let's find year wise number of seats won by each party \nyear_wise_party_results = winning_candidates.groupby(['Party','Year']).size().to_frame('count').sort_values('count')\nyear_wise_party_results.head()","2e15c833":"# find number of times a candidate won from the same constituency\nconstituency_wise_candidate_wins = winning_candidates.groupby(['ConstituencyTitle','CandidateName']).size().to_frame('wins')\nconstituency_wise_candidate_wins.head()","b3feb695":"# find candidates who won atleast twice from the same constituency\nstrong_candidates = constituency_wise_candidate_wins[constituency_wise_candidate_wins['wins'] >=2 ].sort_values('wins', ascending = False)\nstrong_candidates.head()","ddb576ae":"# find  of number of times a party won from the same constituency\nconstituency_wise_party_wins = winning_candidates.groupby(['ConstituencyTitle','Party']).size().to_frame('wins')\n#find constittuencies where same party won in all three elections\nconfirmed_constituencies_by_party = constituency_wise_party_wins[constituency_wise_party_wins['wins'] == 3].sort_values('wins', ascending = False)\nconfirmed_constituencies_by_party.head()","b860a78b":"#Swing constituencies are those where maximum wins by the same party are 1 i.e. where no party won twice\n#First we will find constituency wise maximum number of wins by a party \nconstituency_wise_max_party_wins = constituency_wise_party_wins.groupby(['ConstituencyTitle'])['wins'].max().to_frame('max_wins_by_any_party')\n#filter out those constituencies where max wins by any party is 1\nswing_constituencies = constituency_wise_max_party_wins[constituency_wise_max_party_wins['max_wins_by_any_party'] == 1]\nswing_constituencies.head()","46368467":"# Time to find Lotas, Ah ha (candidates who changed their parties while competing from the same constituency)\nnum_parties_by_candidate = df[['CandidateName','ConstituencyTitle','Party']].groupby(['CandidateName','ConstituencyTitle'])['Party'].nunique()\\\n.to_frame('count').sort_values('count', ascending = False)\n#find candidates with party count greater than 1\nlotas = num_parties_by_candidate[num_parties_by_candidate['count'] > 1]\n#some lotas for you\nlotas.head()","f6c2627f":"# first value in a constituency may have a null value, let's fill it with next value from same constituency and year\ndf['Turnout'] = df.groupby(['ConstituencyTitle','Year'])['Turnout'].fillna(method = 'bfill')","8f329c27":"# find min, max , average turnout and valid votes constituency wise\naggregations_by_constituency = df.groupby('ConstituencyTitle').agg({'TotalValidVotes' : [np.max, np.min, np.average ],'Turnout' : [np.max, np.min, np.average]})\naggregations_by_constituency.head()","2041a7a7":"# now we will find total number of votes casted to all parties(year wise) and sort them to see popular vote winners\npopular_vote_winners = df.groupby(['Party', 'Year'])['Votes'].sum().to_frame('total_votes').sort_values('total_votes', ascending = False)\npopular_vote_winners.head()","bbe08035":"## That's all for today, building visualizations on top of these insights might be an interesting idea for you","af7a9cab":"# Lets Use the Initial Cleaning script written by Zeeshan and move on to interesting analysis and Insights  ","999b4d51":"## Let's clean textual columns before moving to the fun part"}}