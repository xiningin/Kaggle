{"cell_type":{"a3edd8cb":"code","e54f8473":"code","9e1a19c4":"code","a867efff":"code","f7fd1a0b":"code","5a0abcc1":"code","019328ef":"code","360ad0a9":"code","d2a8ff64":"code","ff0ff517":"code","2e1882af":"code","b527fa7c":"code","a71e707b":"code","582d4b68":"code","421e8f73":"code","81a29a8b":"code","8df1e158":"code","f85a243c":"code","4ea24536":"code","728c143d":"markdown","792b61de":"markdown","c0b33393":"markdown","256ff9aa":"markdown","d868124e":"markdown"},"source":{"a3edd8cb":"import os\nimport wave\nimport IPython\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom tensorflow.keras import layers\nfrom IPython.display import Image, display\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.python.client import device_lib","e54f8473":"device_lib.list_local_devices()","9e1a19c4":"audio_data_directory = \"..\/input\/free-spoken-digits\/free-spoken-digit-dataset-master\/recordings\/\"","a867efff":"audio_file_name  = \"5_yweweler_11.wav\"\naudio_file = wave.open(audio_data_directory + audio_file_name, mode=\"r\")\nsampling_frequency = audio_file.getframerate()\naudio_signal = np.frombuffer(audio_file.readframes(audio_file.getframerate()), dtype=np.int16)\naudio_file.close()","f7fd1a0b":"IPython.display.Audio(audio_data_directory + audio_file_name)","5a0abcc1":"plt.figure(figsize=(14,3))\n\nplt_sig = plt.subplot(1,2,1)\nplt_sig.plot(audio_signal, color=\"c\")\nplt.title(\"Signal audio\")\nplt.xlabel(\"Echantillons\")\nplt.ylabel(\"Amplitude\")\n\nplt_spect = plt.subplot(1,2,2)\nplt.specgram(audio_signal,Fs=sampling_frequency, cmap = \"plasma\")\nplt.xlabel('Temps en S')\nplt.ylabel('Frequence')\nsampling_frequency","019328ef":"def plot_four_audio_files_data(wav_file_names_list):\n    plt.figure(figsize=(15,5))\n    for i, audio_file_name in enumerate(wav_file_names_list):\n        audio_file = wave.open(audio_data_directory + audio_file_name, mode =\"r\")\n        audio_signal = np.frombuffer(audio_file.readframes(audio_file.getframerate()), dtype=np.int16)\n        audio_file.close()\n        signal_plot = plt.subplot(2, 4, 1 + i)\n        signal_plot.plot(audio_signal, color=\"c\")\n        spect_plot = plt.subplot(2, 4, 1 + i + 4)\n        spect_plot.specgram(audio_signal,Fs=sampling_frequency,cmap = \"plasma\")\n        IPython.display.display(IPython.display.Audio(audio_data_directory + audio_file_name))","360ad0a9":"examples_of_wav_files = [\"1_yweweler_44.wav\",\"1_theo_15.wav\", \"1_jackson_5.wav\", \"1_nicolas_4.wav\"]\nplot_four_audio_files_data(examples_of_wav_files)","d2a8ff64":"examples_of_wav_files = [\"8_yweweler_44.wav\",\"8_theo_15.wav\", \"8_jackson_5.wav\", \"8_nicolas_4.wav\"]\nplot_four_audio_files_data(examples_of_wav_files)","ff0ff517":"def create_and_save_spec_image_from_audio_file_name(audio_file_name) :\n    audio_file_name_without_extension = audio_file_name[:-4]\n    digit_directory = \"digit_\" + audio_file_name[0]\n    audio_file = wave.open(audio_data_directory + audio_file_name, mode=\"r\")\n    sampling_frequency = audio_file.getframerate()\n    audio_signal = np.frombuffer(audio_file.readframes(sampling_frequency), dtype=np.int16)\n    plt.specgram(audio_signal, Fs=sampling_frequency, cmap = \"plasma\")\n    plt.savefig(spectrogram_directory + digit_directory + \"\/\" + audio_file_name_without_extension + \".png\")\n    plt.close()","2e1882af":"spectrogram_directory = \"\/kaggle\/temp\/spectrograms\/\"\n# Creating the digits directories\nfor i in range(0,10):\n    Path(spectrogram_directory + \"digit_\" + str(i)).mkdir(parents=True, exist_ok=True)","b527fa7c":"for audio_file_name in tqdm(os.listdir(audio_data_directory)):\n    create_and_save_spec_image_from_audio_file_name(audio_file_name)","a71e707b":"X_train = tf.keras.preprocessing.image_dataset_from_directory(spectrogram_directory,validation_split = 0.225,\n                                                              subset = \"training\", seed=7)\nX_test = tf.keras.preprocessing.image_dataset_from_directory(spectrogram_directory,validation_split = 0.225,\n                                                             subset=\"validation\", seed=7)","582d4b68":"model = Sequential([\n    \n    layers.experimental.preprocessing.Rescaling(1.\/255,  input_shape=(256, 256, 3)),\n    \n    layers.Conv2D(32, 7, strides = 4, padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n    \n    layers.MaxPooling2D((4,4)),\n    \n    layers.Conv2D(128, 3, padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n\n    layers.Flatten(),\n    \n    layers.Dense(256),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n    \n    layers.Dense(10, activation='softmax')\n])","421e8f73":"model.summary()","81a29a8b":"model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","8df1e158":"model_history = model.fit(X_train, validation_data=X_test, epochs=30)","f85a243c":"plt.figure(figsize=(15,5))\n\nplt_loss = plt.subplot(121)\nplt_loss.plot(model_history.history[\"loss\"])\nplt_loss.plot(model_history.history[\"val_loss\"])\n# plt.title(\"\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training\", \"Validation\"], loc=\"upper right\")\n\nplt_accuracy = plt.subplot(122)\nplt_accuracy.plot(model_history.history[\"accuracy\"])\nplt_accuracy.plot(model_history.history[\"val_accuracy\"])\n# plt.title(\"\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training\", \"Validation\"], loc=\"lower right\")","4ea24536":"img = tf.keras.preprocessing.image.load_img(\"\/kaggle\/temp\/spectrograms\/digit_9\/9_nicolas_11.png\", target_size=(256, 256))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nprint(img_array.shape)\nimg_array = tf.expand_dims(img_array, 0)\nprint(img_array.shape)\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\nprint( \"Digit : \"+ str(np.argmax(score)) +\" ; Probability = \"+ str(np.max(score)))\nscore","728c143d":"# Loading the Dataset","792b61de":"# Creating and training the model","c0b33393":"# Loading and displaying some audio files","256ff9aa":"# Creating and saving spectrograms in png files","d868124e":"#  Prediction"}}