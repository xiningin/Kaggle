{"cell_type":{"6e82a331":"code","55c46cd7":"code","1ac75c6b":"code","c0dfe2eb":"code","10b4b18a":"code","740bbd5a":"code","3d293520":"code","13f07ba4":"code","158b741a":"code","d191e800":"code","665bc662":"code","cbe7e07a":"code","b6585acf":"code","31672cbb":"code","317d90bf":"code","d88b6af9":"code","cb170084":"code","62822c42":"code","98f682ad":"code","787d8978":"code","4aa66130":"code","378aed93":"code","dc43d419":"code","20f3df4a":"code","55f2f508":"code","b6d9f1d7":"code","e9f56215":"code","6ba18e41":"code","8155d00b":"code","2f3b04db":"code","e834f3b6":"code","89584efe":"code","e7f1e34f":"code","80fcc260":"code","bd831347":"code","9e92e819":"code","89d7be23":"code","4465d4e1":"code","a366fdb4":"code","89350353":"code","c3104fcf":"code","b9b21474":"code","fbe3e0f6":"markdown","ef338a6a":"markdown","6f4fe15a":"markdown","5675d463":"markdown","a8dc337c":"markdown","c26e9ce4":"markdown","2b0e3aa9":"markdown","28af1237":"markdown","b5409e88":"markdown","b13466c4":"markdown","cfb1b9c1":"markdown","f9571fbb":"markdown","b84869e6":"markdown","84182de9":"markdown","048c9431":"markdown","2a4d7fba":"markdown","4fd4fa5c":"markdown","b2a088af":"markdown","619a2213":"markdown","10c9b0ee":"markdown","8f3e02b8":"markdown","bc340dd6":"markdown","4c88c1ae":"markdown","c7c1390f":"markdown","dc5d3294":"markdown","6e1d389e":"markdown","77b4aa27":"markdown"},"source":{"6e82a331":"# necessary libraries\nimport pandas as pd\nimport numpy as np\n\n# visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom pylab import *\nimport plotly\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n# scikit learn libraries\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost\nimport lightgbm as lgb\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom imblearn.combine import SMOTETomek\n\n# dask libraries\n# from dask_ml.model_selection import train_test_split\n# from cuml.dask.ensemble import RandomForestClassifier\n# import dask_ml.model_selection as dcv\n\nimport warnings\nwarnings.filterwarnings('ignore')","55c46cd7":"# !pip install dask-cuda\n# from dask_cuda import LocalCUDACluster\n# from dask.distributed import Client","1ac75c6b":"# from dask.distributed import Client \n# client = Client() \n# client","c0dfe2eb":"training_data= pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\ntesting_data= pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\n\ndata_dict= pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/DataDictionaryWiDS2021.csv\")\nsolution_temp= pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/SolutionTemplateWiDS2021.csv\")\nsample_submission= pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/SampleSubmissionWiDS2021.csv\")","10b4b18a":"train= training_data.copy()\n\nprint(\"shape of dataset :\", train.shape)\npd.set_option(\"max_columns\", 181)\ntrain.head()","740bbd5a":"# Dropping `Unnamed: 0` column\ntrain= train.drop(columns=[\"Unnamed: 0\"], axis=1)","3d293520":"print(\"percentage of diabetic and non-diabetic cases\\n\", train[\"diabetes_mellitus\"].value_counts()\/ len(train)*100)\n\nplt.figure(figsize=(9,5))\nsns.countplot(train[\"diabetes_mellitus\"],palette=\"Set3\")","13f07ba4":"test= testing_data.copy()\n\nprint(\"shape of dataset :\", test.shape)\npd.set_option(\"max_columns\", 180)\ntest.head()","158b741a":"# Dropping `Unnamed: 0` column\ntest= test.drop(columns=[\"Unnamed: 0\"], axis=1)","d191e800":"train.dtypes.value_counts()","665bc662":"plt.figure(figsize=(17,5))\nsns.heatmap(train.isnull(), cbar=False, cmap= \"viridis\", yticklabels=False)","cbe7e07a":"# creating dataframe of the columns containing missing values\nnull_values= train.isnull().sum()\npercent_null_values= train.isnull().sum()\/ len(train)*100\ntable_null_values= pd.concat([null_values, percent_null_values], axis=1)\ntable_null_values= table_null_values.rename(columns={0: \"Missing Values\", 1: \"Percentage of missing values\"})\ntable_null_values= table_null_values.sort_values(\"Percentage of missing values\", ascending=False)\ntable_null_values= table_null_values[table_null_values[\"Missing Values\"] > 0]\n\nprint(\"160 out of 180 columns have missing values\")\ntable_null_values[:20].style.background_gradient(cmap='Purples')","b6585acf":"f_diabetes= train.loc[(train[\"gender\"] == \"F\") & (train[\"diabetes_mellitus\"] == 1)][[\"gender\", \"diabetes_mellitus\"]]\nf_no_diabetes= train.loc[(train[\"gender\"] == \"F\") & (train[\"diabetes_mellitus\"] == 0)][[\"gender\", \"diabetes_mellitus\"]]\n\nm_diabetes= train.loc[(train[\"gender\"] == \"M\") & (train[\"diabetes_mellitus\"] == 1)][[\"gender\", \"diabetes_mellitus\"]]\nm_no_diabetes= train.loc[(train[\"gender\"] == \"M\") & (train[\"diabetes_mellitus\"] == 0)][[\"gender\", \"diabetes_mellitus\"]]\n\n# plotting\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(go.Pie(labels=[\"diabetes\", \"no_diabetes\"], values=[f_diabetes[\"gender\"].count(), f_no_diabetes[\"gender\"].count()]),1, 1)\n\nfig.add_trace(go.Pie(labels=[\"diabetes\", \"no_diabetes\"],values=[m_diabetes[\"gender\"].count(), m_no_diabetes[\"gender\"].count()]),1, 2)\n\nfig.update_traces(hole=.6, hoverinfo=\"label+percent\", textinfo='percent' ,marker=dict(colors=['#949cdf', '#ff9b93'], line=dict(color='gray', width=2)))\n\nfig.update_layout(title_text= \"Number Of Diabetes Cases as per Gender\",font_size=15,         \n                  annotations=[dict(text='Female', x=0.24, y=0.4, font_size=28, font_color=\"#cc0e74\"),\n                               dict(text='Male', x=0.78, y=0.4, font_size=28, font_color=\"#cc0e74\")])\nfig.show()","31672cbb":"diabetes=train[train[\"diabetes_mellitus\"] == 1].groupby(\"ethnicity\")[\"diabetes_mellitus\"].value_counts()\ndiabetes=diabetes.to_frame().rename(columns={\"diabetes_mellitus\": \"diabetes\"}).reset_index()\ndiabetes=diabetes.drop(columns=[\"diabetes_mellitus\"], axis=1)\n\nno_diabetes=train[train[\"diabetes_mellitus\"] == 0].groupby(\"ethnicity\")[\"diabetes_mellitus\"].value_counts()\nno_diabetes=no_diabetes.to_frame().rename(columns={\"diabetes_mellitus\": \"no_diabetes\"}).reset_index()\nno_diabetes=no_diabetes.drop(columns=[\"diabetes_mellitus\"], axis=1)\n\ndf= diabetes.merge(no_diabetes, on=\"ethnicity\")\ndf=df.sort_values(\"no_diabetes\", ascending=False)\n\n# plot\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x=df[\"ethnicity\"], y=df[\"no_diabetes\"], name='no_diabetes', marker_color='#654062'))\nfig.add_trace(go.Bar(x=df[\"ethnicity\"], y=df[\"diabetes\"],    name='diabetes',    marker_color='#65d6ce'))\n\nfig.update_layout(barmode='group',title='Number Of Diabetes Cases as per Ethnicity', xaxis_tickangle=-45)\nfig.show()","317d90bf":"plot = sns.catplot(data=train, x=\"diabetes_mellitus\", col=\"elective_surgery\",kind=\"count\", height=6,aspect=.8, palette=\"PuRd_r\")\nplot.fig.suptitle(\"Elective surgery and Diabetes Mellitus\", size = 20, y=1.05)","d88b6af9":"# creating column which classifies the weight according to bmi\ntrain[\"weight_type\"] = \"\"\n\ndef impute_weight(cols):\n    weight_type = cols[0]\n    bmi = cols[1]\n    \n    \n    if (bmi<=18.5):\n        return 'Under Weight'\n    \n    elif (bmi>18.5 and bmi< 25):\n        return \"Normal Weight\"\n    \n    elif (bmi>25 and bmi< 30):\n        return \"Over Weight\"\n    \n    else:\n        return \"Obese\"\n    \n\ntrain['weight_type'] = train[['weight_type','bmi']].apply(impute_weight,axis = 1)","cb170084":"diabetes=train[train[\"diabetes_mellitus\"] == 1].groupby(\"weight_type\")[\"diabetes_mellitus\"].value_counts()\ndiabetes=diabetes.to_frame().rename(columns={\"diabetes_mellitus\": \"diabetes\"}).reset_index()\ndiabetes=diabetes.drop(columns=[\"diabetes_mellitus\"], axis=1)\n\nno_diabetes=train[train[\"diabetes_mellitus\"] == 0].groupby(\"weight_type\")[\"diabetes_mellitus\"].value_counts()\nno_diabetes=no_diabetes.to_frame().rename(columns={\"diabetes_mellitus\": \"no_diabetes\"}).reset_index()\nno_diabetes=no_diabetes.drop(columns=[\"diabetes_mellitus\"], axis=1)\n\ndf= diabetes.merge(no_diabetes, on=\"weight_type\")\ndf=df.sort_values(\"no_diabetes\", ascending=False)\n\n# plot\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x=df[\"weight_type\"], y=df[\"no_diabetes\"], name='no_diabetes', marker_color='#bfdcae'))\nfig.add_trace(go.Bar(x=df[\"weight_type\"], y=df[\"diabetes\"],    name='diabetes',    marker_color='#6e6d6d'))\n\nfig.update_layout(barmode='group',title='Number Of Diabetes Cases as per Weight Type')\nfig.show()","62822c42":"a= (len(train[(train[\"aids\"] == 1) & (train[\"diabetes_mellitus\"] == 1)]))\na1=(len(train[(train[\"aids\"] == 1) & (train[\"diabetes_mellitus\"] == 0)]))\n\nb=(len(train[(train[\"cirrhosis\"] == 1) & (train[\"diabetes_mellitus\"] == 1)]))\nb1=(len(train[(train[\"cirrhosis\"] == 1) & (train[\"diabetes_mellitus\"] == 0)]))\n\nc=(len(train[(train[\"hepatic_failure\"] == 1) & (train[\"diabetes_mellitus\"] == 1)]))\nc1=(len(train[(train[\"hepatic_failure\"] == 1) & (train[\"diabetes_mellitus\"] == 0)]))\n\nd=(len(train[(train[\"immunosuppression\"] == 1) & (train[\"diabetes_mellitus\"] == 1)]))\nd1=(len(train[(train[\"immunosuppression\"] == 1) & (train[\"diabetes_mellitus\"] == 0)]))\n\ne=(len(train[(train[\"leukemia\"] == 1) & (train[\"diabetes_mellitus\"] == 1)]))\ne1=(len(train[(train[\"leukemia\"] == 1) & (train[\"diabetes_mellitus\"] == 0)]))\n\nf=(len(train[(train[\"lymphoma\"] == 1) & (train[\"diabetes_mellitus\"] == 1)]))\nf1=(len(train[(train[\"lymphoma\"] == 1) & (train[\"diabetes_mellitus\"] == 0)]))\n\ng=(len(train[(train[\"solid_tumor_with_metastasis\"] == 1) & (train[\"diabetes_mellitus\"] == 1)]))\ng1=(len(train[(train[\"solid_tumor_with_metastasis\"] == 1) & (train[\"diabetes_mellitus\"] == 0)]))","98f682ad":"fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(go.Pie(labels=list(train.iloc[:, -9:-2].columns), values=[a,b,c,d,e,f,g], pull=[0.1, 0, 0, 0, 0.1,0.1,0]),1, 1)\n\nfig.add_trace(go.Pie(labels=list(train.iloc[:, -9:-2].columns),values=[a1,b1,c1,d1,e1,f1,g1], pull=[0.1, 0, 0, 0, 0.1,0.1,0]),1, 2)\n\nfig.update_traces( hoverinfo=\"label+percent\", textinfo='percent' ,\n                  marker=dict(colors=['#fa9579','#654062',\"#65d6ce\",\"#ffe9d6\",\"#a9294f\",\"#c9cbff\",\"#11698e\"]))\n\nfig.update_layout(title_text= \"Patients having other symptoms\",font_size=15,         \n                  annotations=[dict(text='Diabetic Case', x=0.24, y=0.94, font_size=17, font_color=\"#583d72\"),\n                               dict(text='Non Diabetic Case', x=0.78, y=0.94, font_size=17, font_color=\"#583d72\")])\nfig.show()","787d8978":"# creating additional column in both training and testing data to identify each of them\ntrain[\"train\/test\"]= 0\ntest[\"train\/test\"]= 1\n\n# combine\ncombined_data= pd.concat([train, test], axis=0)\n\nprint(combined_data.shape)\ncombined_data.head()","4aa66130":"combined_data= combined_data.drop(columns=[\"encounter_id\", \"hospital_id\", \"icu_id\"], axis=1)","378aed93":"combined_data= combined_data.drop(columns=[\"hospital_admit_source\", \"icu_admit_source\", \"icu_stay_type\", \"icu_type\", \"weight_type\"], axis=1)","dc43d419":"# columns with missing values more than 60%\nto_drop= table_null_values[table_null_values[\"Percentage of missing values\"] >= 60.0].index\n\n# dropping those columns from combined_data\ncombined_data= combined_data.drop(columns=to_drop, axis=1)\n\nprint(\"shape of dataset:\", combined_data.shape)","20f3df4a":"# function to impute random sample\ncolumns= [\"age\", \"height\", \"weight\"]\n\ndef impute_random(df, variable):\n    df[variable] = df[variable]\n    random_sample= df[variable].dropna().sample(df[variable].isnull().sum(), random_state=10)\n    random_sample.index= df[df[variable].isnull()].index\n    df.loc[df[variable].isnull(), variable]= random_sample\n\n# imputing random samples to above numerical columns\nfor column in columns:\n    impute_random(combined_data, column)","55f2f508":"# combined_data with missing values\ncombined_data_original= pd.concat([train, test], axis=0)\n\ncombined_data[\"age_with_null\"]= combined_data_original[\"age\"]\ncombined_data[\"height_with_null\"]= combined_data_original[\"height\"]\ncombined_data[\"weight_with_null\"]= combined_data_original[\"weight\"]\n\nsns.set(rc={\"figure.figsize\": (16, 10)}); np.random.seed(0)\n\nsubplot(3,1,1)\nax = sns.kdeplot(combined_data[\"age\"], shade=True, color=\"#ec4646\")\nax = sns.kdeplot(combined_data[\"age_with_null\"], shade=True, color=\"#1a508b\")\n\nsubplot(3,1,2)\nax = sns.kdeplot(combined_data[\"height\"], shade=True, color=\"#f8dc81\")\nax = sns.kdeplot(combined_data[\"height_with_null\"], shade=True, color=\"#af0069\")\n\nsubplot(3,1,3)\nax = sns.kdeplot(combined_data[\"weight\"], shade=True, color=\"#e27802\")\nax = sns.kdeplot(combined_data[\"weight_with_null\"], shade=True, color=\"#007965\")\n\nplt.show()","b6d9f1d7":"# remaining numerical columns\nnum_cols= combined_data.select_dtypes(include=np.number).drop(columns=[\"age\", \"height\", \"weight\",\"age_with_null\",\"height_with_null\", \"weight_with_null\"])\n\n# numerical columns with missing values\nnum_cols= num_cols.columns[num_cols.isnull().any()]","e9f56215":"# function to impute mean value\ndef impute_mean(df, variable):\n    df[variable]= df[variable].fillna(df[variable].mean())\n    \n# imputing mean values \nfor column in num_cols:\n    impute_mean(combined_data, column)","6ba18e41":"# categorical columns with missing values\ncat_cols= combined_data.select_dtypes(include= [\"object\"]).columns[combined_data.select_dtypes(include= [\"object\"]).isnull().any()]\nprint(\"categorical columns with missing values :\",cat_cols)\n\n# let's first check the percentage of missing values in gender and ethnicity\nprint(\"\\n\",table_null_values.loc[\"gender\"])\nprint(table_null_values.loc[\"ethnicity\"])","8155d00b":"# function to impute mode\ndef impute_mode(df, column):\n    df[column]= df[column].fillna(df[column].mode()[0])\n    \n# imputing mode to the categorical columns\nfor column in cat_cols:\n    impute_mode(combined_data, column)","2f3b04db":"combined_data[\"ethnicity\"].unique()","e834f3b6":"# initialising label encoder\nle= LabelEncoder()\n\n# iterating through each categorical feature and label encoding them\nfor feature in cat_cols:\n    combined_data[feature]= le.fit_transform(combined_data[feature])","89584efe":"# label encoded data\ncombined_data.head(3)","e7f1e34f":"# training data\ntraining= combined_data[combined_data[\"train\/test\"] == 0]\ntraining= training.iloc[:, :-4]\n\n# testing data\ntesting= combined_data[combined_data[\"train\/test\"] == 1]\ntesting= testing.iloc[:, :-5]","80fcc260":"# separating training data into features and target\ntraining_features = training.iloc[:, :-1]\ntraining_target= training.iloc[:, -1]\n\n# initialising oversampling\nsmote= SMOTETomek()\n\n# #implementing oversampling to training data\nx_sm, y_sm= smote.fit_sample(training_features, training_target)\n\n# x_sm and y_sm are the resampled data\n\n# target class count of resampled dataset\nprint(y_sm.value_counts())","bd831347":"x_train, x_val, y_train, y_val= train_test_split(x_sm, y_sm, test_size=0.2, random_state=10)","9e92e819":"# x_train.to_parquet(\"x_train_\", index=False)\n# y_train= pd.DataFrame(y_train)\n# y_train.to_parquet(\"y_train_\", index=False)","89d7be23":"# import dask.dataframe as dd\n# x_train_dask= dd.read_parquet(\".\/x_train_\")\n# y_train_dask= dd.read_parquet(\".\/y_train_\")","4465d4e1":"# import lightgbm as lgb\n\nlgb = lgb.LGBMClassifier(objective='binary',\n                         boosting='gbdt',\n                         learning_rate = 0.01,\n                         max_depth = -1,\n                         num_leaves = 200,\n                         colsample_bytree =0.3,\n                         subsample_freq = 6,\n                         bagging_seed= 100,                     \n                         n_estimators = 30000,\n                         min_data_per_group= 5,\n                         bagging_fraction = 0.6,\n                         feature_fraction = 0.6,\n                         reg_alpha = 1.2,\n                         reg_lambda = 0.2, n_jobs=-1)\n\n# model fitting\nlgb.fit(x_train, y_train)","a366fdb4":"# checking model performance through training data\nxg_pred= lgb.predict(x_train)\n\ncm= confusion_matrix(y_train, xg_pred)\n# plot_confusion_matrix(cm, figsize=(5,5)) \nprint(accuracy_score(y_train, xg_pred))\nprint(classification_report(y_train, xg_pred))","89350353":"# checking model performance through validation data\nxg_pred= lgb.predict(x_val)\n\ncm= confusion_matrix(y_val, xg_pred)\nplot_confusion_matrix(cm, figsize=(5,5))\nprint(accuracy_score(y_val, xg_pred))\nprint(classification_report(y_val, xg_pred))","c3104fcf":"# Making prediction on test data\npredictions= lgb.predict_proba(testing)\npredictions= predictions[:, 1]","b9b21474":"# Making submission\nsubmit= testing_data[[\"encounter_id\"]]\nsubmit[\"diabetes_mellitus\"]= predictions\n\nsubmit.to_csv('lgbm_8.csv',index=False)  \nsubmit.head() ","fbe3e0f6":"### Test Data","ef338a6a":"### Handling missing values in numerical column","6f4fe15a":"### *Comparing distribution plot for `age`, `height`, `weight` after imputing with random samples*","5675d463":"### For rest of the numerical columns","a8dc337c":"## **Upload Data**","c26e9ce4":"*The yellow part in the above heatmap represents the number of missing values in the columns*","2b0e3aa9":"## Checking missing values in Train Data","28af1237":"# Exploratory Data Analysis","b5409e88":"## **Importing libraries**","b13466c4":"### Handling missing values in categorical variable ","cfb1b9c1":"*The class distribution in the target variable is ~78:22 indicating an imbalanced dataset.*","f9571fbb":"## Separating training and test data from combined_data\nSince the testing data does not have a target variable, let's also create a validation set to test the accuracy of our model.","b84869e6":"*Since `gender` and `ethnicity` has very less number of missing values, imputing with MODE will not distort the relation between the most frequent label and the target variable*","84182de9":"## Encoding Categorical Features\n*Since machine learning models are mathematical models that need numbers to work with. Hence we will convert text data into numbers helping our predictive models to understand better.*","048c9431":"### Data Types ","2a4d7fba":"# Data Preprocessing\n*Combining training and testing data to do preprocessing simultaneously*","4fd4fa5c":"***If we have any specific column where null values are over 60% to 65% we can drop that column all together because it will not going to add any predictive power to our model.***","b2a088af":"***`ethnicity` column has 6 categories, we will Label Encode them as One Hot Encoding would create 6 additional columns***","619a2213":"*Since features like **Age**, **Height**, **Weight** follows normal distribution, imputing missing values with their Mean or Median would distort their probability density distribution. Hence for these features imputing missing values with the random sample would do  a better job.*","10c9b0ee":"## Creating validation set from training data\n*But before creating validation set, we need to handle imbalanced target variable in the training data*","8f3e02b8":"# Model Building","bc340dd6":"## LGBM","4c88c1ae":"### Target column of training data","c7c1390f":"### Dropping Unnecessary Columns","dc5d3294":"## Handling Missing Values","6e1d389e":"### Training Data","77b4aa27":"*`encounter_id`, `hospital_id`, `icu_id` are unique identifiers in the dataset so we will drop them.*"}}