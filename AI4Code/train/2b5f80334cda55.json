{"cell_type":{"b6c708b4":"code","d48c9d67":"code","0d2ba412":"code","072ef0fe":"code","1fa2462b":"code","c7d44f57":"code","0c1857c5":"code","5c26990d":"code","36cb3251":"code","30693626":"code","b2ff952d":"code","79cf5d5f":"code","f7c08ab9":"code","2824f227":"code","3316312e":"code","ea4df092":"code","ed495339":"code","4ea9a099":"code","012622ea":"code","fa4a3351":"code","7d26e232":"code","749089f3":"code","088cb4fc":"code","09705e2a":"code","e93472fe":"code","a456c64e":"code","f1195ab5":"code","4df78085":"code","363d39d7":"markdown","899508b7":"markdown","947a937a":"markdown","f8d37f2b":"markdown","8e00e684":"markdown","fbd7a23c":"markdown","44f316eb":"markdown","ef2a4c93":"markdown","2a361161":"markdown","815249bb":"markdown","3e2f150a":"markdown","43e2c98a":"markdown","2c14e8e6":"markdown","d2048f56":"markdown","1e3fa82a":"markdown","20fea6dc":"markdown","5f7e969e":"markdown","01f1ebdb":"markdown","5602cc1c":"markdown","b808149e":"markdown","aa185bae":"markdown"},"source":{"b6c708b4":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os, datetime","d48c9d67":"import pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\n        \ndef get_versions():\n    imports = list(set(get_imports()))\n\n    requirements = []\n    for m in pkg_resources.working_set:\n        if m.project_name in imports and m.project_name!=\"pip\":\n            requirements.append((m.project_name, m.version))\n\n    for r in requirements:\n        print(\"{}== {}\".format(*r))\n\nget_versions()","0d2ba412":"# List all files under the input directory\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# List of physical devices\ntf.config.experimental.list_physical_devices()        ","072ef0fe":"fashion_mnist = tf.keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n# Creating class label array\nclass_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","1fa2462b":"# Shape of training nad test data\nprint(f'Shape of train_images: {train_images.shape}')\nprint(f'Shape of train_labels: {train_labels.shape}')\nprint(f'Shape of test_images: {test_images.shape}')\nprint(f'Shape of test_labels: {test_labels.shape}')","c7d44f57":"# There are 10 labels starting from 0 to 9\nprint(f'Unique train labels: {np.unique(train_labels)}')\nprint(f'Unique test labels: {np.unique(test_labels)}')","0c1857c5":"# The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255\ntrain_images","5c26990d":"\nplt.figure()\nplt.imshow(train_images[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","36cb3251":"# Images labels(classes) possible values from 0 to 9\ntrain_labels","30693626":"# Display the first 25 images from the training set and display the class name below each image.\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()","b2ff952d":"train_images = train_images \/ 255.0\ntest_images = test_images \/ 255.0","79cf5d5f":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28,28)),\n    tf.keras.layers.Dense(128, activation= 'relu'),\n    tf.keras.layers.Dense(10) # linear activation function\n])","f7c08ab9":"# The from_logits=True attribute inform the loss function that the output values generated by the model are not normalized, a.k.a. logits.\n# Since softmax layer is not being added at the last layer, hence we need to have the from_logits=True to indicate the probabilities are not normalized.\n\nmodel.compile(optimizer= 'adam', \n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics = ['accuracy'])","2824f227":"%%timeit -n1 -r1 # time required toexecute this cell once\n\n# To view in TensorBoard\nlogdir = os.path.join(\"logs\/adam\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n\nmodel.fit(train_images, train_labels, epochs= 10, callbacks = [tensorboard_callback])","3316312e":"test_loss, test_acc = model.evaluate(test_images, test_labels, verbose= 2)\nprint(f'\\nTest accuracy: {test_acc}')","ea4df092":"probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\npredictions = probability_model.predict(test_images)","ed495339":"# 'predictions' will contain the prediction for each image in the training set. Lets check the first prediction\npredictions[0]","4ea9a099":"np.argmax(predictions[0])","012622ea":"test_labels[0]","fa4a3351":"def plot_image(i, predictions_array, true_label, img):\n    \"\"\"\n    This method will plot the true image and also compare the prediction with true values if matcing write the caption in green color else in red color.\n    Format is : predicted class %confidence score (true class)\n    \n    Input:\n        i: Index of the prediction to test\n        predictions_array: Every prediction contain array of 10 number\n        true_label: Correct image labels. In case of test data they are test_labels\n        img: Test images. In case of test data they are test_images.\n    \"\"\"\n    true_label, img = true_label[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img, cmap=plt.cm.binary) # For grayscale colormap\n\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        color = 'green'\n    else:\n        color = 'red'\n\n    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n    \nplot_image(0, predictions[0], test_labels, test_images)","7d26e232":"def plot_value_array(i, predictions_array, true_label):\n    \"\"\"\n    This method will plot the percentage confidence score of each class prediction.\n    \n    Input:\n        i: Index of the prediction to test\n        predictions_array: Every prediction contain array of 10 number\n        true_label: Correct image labels. In case of test data they are test_labels\n    \"\"\"\n    true_label = true_label[i]\n    plt.grid(False)\n    plt.xticks(range(10))\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1])\n    predicted_label = np.argmax(predictions_array)\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('green')\n\ni = 0\nplot_value_array(i, predictions[i],  test_labels)","749089f3":"i = 12\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplot_image(i, predictions[i], test_labels, test_images)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions[i],  test_labels)\n_ = plt.xticks(range(10), class_names, rotation=45)\nplt.show()","088cb4fc":"\ntest_list= [16, 17, 22, 23, 24, 25, 39, 40, 41, 42, 48, 49, 50, 51,66]\ntest_list[1]","09705e2a":"# Plot the test images from 'test_list', their predicted labels, and the true labels.\n# Color correct predictions in green and incorrect predictions in red.\n\ntest_list= [16, 17, 22, 23, 24, 25, 39, 40, 41, 42, 48, 49, 50, 51,66]\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows * num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(test_list[i], predictions[test_list[i]], test_labels, test_images)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(test_list[i], predictions[test_list[i]], test_labels)\nplt.tight_layout()\nplt.show()","e93472fe":"# Grab an image from the test dataset.\nimg = test_images[49]\n\nprint(img.shape)","a456c64e":"# Add the image to a batch where it's the only member.\nimg = (np.expand_dims(img, 0))\nprint(img.shape)","f1195ab5":"predictions_single = probability_model.predict(img)\n# Remember that if we do \"predictions = probability_model.predict(test_images)\" then we get predictions for all test data\"\nprint(f'Probabilty for all classes: {predictions_single}, \\nBest confidence score for class: {np.argmax(predictions_single)}')","4df78085":"i = 49\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplot_image(i, predictions_single[0], test_labels, test_images)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions_single[0],  test_labels)\n_ = plt.xticks(range(10), class_names, rotation=45)\nplt.show()","363d39d7":"## Versions of Imported Libraries <a id =\"3\"><\/a>","899508b7":"Now lets plot prediction and value array plot for above iamge.","947a937a":"Similarly to verify our predictions for other images, lets write functions that can return prediction, true label along with image.","f8d37f2b":"# Load Data <a id =\"5\"><\/a>\n* We are using Fashion MNIST dataset which contains 70,000 grayscale images in 10 categories. \n* We will use 60,000 images for training and 10,000 images for testing the model.\n* You can load the data directly from TensorFlow using ```fashion_mnist.load_data()```\n* The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the class of clothing the image represents:\n\n| Label\t| Class |\n|:------|:------|\n|0|\tT-shirt\/top|\n|1|\tTrouser|\n|2|\tPullover|\n|3|\tDress|\n|4|\tCoat|\n|5|\tSandal|\n|6|\tShirt|\n|7|\tSneaker|\n|8|\tBag|\n|9|\tAnkle boot|\n\n* The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n\n![](https:\/\/tensorflow.org\/images\/fashion-mnist-sprite.png)\n","8e00e684":"## Model Accuracy <a id =\"15\"><\/a>\nIn this step we compare the model's performance against test data","fbd7a23c":"# List of Files & Devices <a id =\"4\"><\/a>","44f316eb":"Lets write a function that can plot a bar graph for each class prediction.","ef2a4c93":"## Compile the Model <a id =\"12\"><\/a>\n* In this step we add all the required settings for the model training.\n* **Loss Function**: To measure models accuracy during training.\n* **Optimizer**: To update the model weights based on the input data and loss function output.\n* **Metrics**: Used to monitor the training the and testing steps","2a361161":"## Data Visualization <a id =\"7\"><\/a>","815249bb":"# Exploratory Data Analysis <a id =\"6\"><\/a>","3e2f150a":"## Train the Model <a id =\"13\"><\/a>\nSteps involved in model training are as below\n* Feeding the training images and associated labels to the model.\n* Model learn the mapping of images and labels.\n* Then we ask model to perform predictions using test_images.\n* Verify the model predictions using test_labels.\n\n### Feed the Model <a id =\"14\"><\/a>\n* To start training, call the ```model.fit``` Its called **fit** because it \"fits\" the model to the training data.\n* As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.91 (or 91%) on the training data.","43e2c98a":"# Model Building <a id =\"10\"><\/a>\nBuilding the neural network model requires configuring the input, hidden and output layers.\n\n## Set up the Layers <a id =\"11\"><\/a>\n* The basic building block of the neural network is the layer. Layers extract representation from the data fed into them.\n* Most times we have to chain multiple layers together to solve the problem.\n* The first layer in this network, ```tf.keras.layers.Flatten```, transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels).\n* The input layer do not help in any kind of learning, it only reformats the data.\n* Once we have flattened input data, we can add dense hidden layers to the network. Here we are using two dense layers. \n* The first Dense layer has 128 nodes (or neurons) and using 'relu' activation function.\n* The second (and last) layer returns a logits array with length of 10. Each node contains a score that indicates the current image belongs to one of the 10 classes. Note that here we are not using any activation function, so by default it will be linear activation function.","2c14e8e6":"As you can notice accuracy on the test dataset is less than the training dataset. This gap between accuracy represent **overfitting**.\nFor more detail please refer.\n* [Underfitting Overfitting](https:\/\/satishgunjal.com\/underfitting_overfitting\/)\n* [Demonstrate overfitting](https:\/\/www.tensorflow.org\/tutorials\/keras\/overfit_and_underfit#demonstrate_overfitting)\n* [Strategies to prevent overfitting](https:\/\/www.tensorflow.org\/tutorials\/keras\/overfit_and_underfit#strategies_to_prevent_overfitting)\n\n## Make Predictions <a id =\"16\"><\/a>\n* We can test the model's accuracy on few images from test dataset.\n* But since our model is using the default 'linear activation function' we have to attach a softmax layer to convert the logits to probabilities, which are easier to interpret.","d2048f56":"Lets try with some random samaple and plot the results for verification.","1e3fa82a":"Now predict the correct label for above image (with shape 1, 28, 28)","20fea6dc":"# Using the Trained Model <a id =\"17\"><\/a>\n* By default our model is optimized to make predictions on a batch, or collection of example at once.\n* We can also use model to make prediction on single image","5f7e969e":"So the model predict that prediction image represent the 9th index class. ```class_names[9]-> ankle boot``` Let's cross-check with true value from test_labels","01f1ebdb":"Since we have 10 nodes in the last layer(one for each lass of image) we get 10 predictions for each image. Each number represents the confidence score for each class of image. We can choose the highest confidence score as final prediction of the model.","5602cc1c":"![Deep_Learning_Header_ANN_Image_Classification](https:\/\/raw.githubusercontent.com\/satishgunjal\/images\/master\/Deep_Learning_Header_ANN_Image_Classification.png)\n\n# Index\n\n# Index\n* [Introduction](#1)\n* [Import Libraries](#2)\n* [List of Files & Devices](#4)\n* [Load Data](#5)\n* [Exploratory Data Analysis](#6)\n* [Preprocessing the Data](#8)\n* [Model Building](#10)\n  - [Set up the Layers](#11)\n  - [Compile the Model](#12)  \n  - [Train the Model](#13)\n    - [Feed the Model](#14)\n    - [Model Accuracy](#15)\n  - [Make Predictions](#16)\n* [Using the Trained Model](#17)\n\n# Introduction <a id =\"1\"><\/a>\n\nIn this guide we are going to create and train the neural network model to classify the clothing images. This is based on [Basic classification](https:\/\/www.tensorflow.org\/tutorials\/keras\/classification) tutorial from TensorFlow. We will use TensorFlow deep learning framework along with Keras high level API to build and train the model.\n\n# Import Libraries <a id =\"2\"><\/a>","b808149e":"# Preprocessing the Data <a id =\"8\"><\/a>\n## Scaling <a id =\"9\"><\/a>\n* Pixel values for each image, fall in the range of 0 to 255.\n* Typically zero is taken to be black, and 255 is taken to be white. Values in between make up the different shades of gray.\n* In order to scale the input we are going to divide every value by 255 so that final values will be in the range of 0 to 1.\n* It's important that the training set and the testing set be preprocessed in the same way.","aa185bae":"As you can see from above result that our prediction for test example 12 is Sandal with confidence score of 83%. But the true label for this prediction is Sneaker. Remember that our models test accuracy is 88% means for 12% predictions will go wrong. In this case since Sandal and Sneaker looks a lot alike, this prediction went wrong. Note that the model can be wrong even when the prediction confidence score is very high!!\n\nNow lets plot few more images and their predictions. We will use the below list for testing. ```test_list= [16, 17, 22, 23, 24, 25, 39, 40, 41, 42, 48, 49, 50, 51,66]```"}}