{"cell_type":{"7ae95406":"code","9c5a1ed4":"code","321ab938":"code","d6c1cd54":"code","3778466e":"code","57f76f5d":"code","4e1c6f4a":"code","dd1df833":"code","b8d714d2":"code","4dcb38c1":"code","38c8af16":"code","92924a3a":"code","867d74d1":"code","341e85c8":"code","73cc9dd2":"code","7f9212e0":"code","98b0e11d":"code","c6335788":"code","66a7577a":"code","243375e5":"code","947cfcf6":"code","39731324":"code","c0a1cd74":"code","dbc6c814":"code","8512f0c4":"code","4673a180":"code","ad3a54c2":"code","1d2a4e02":"code","dd7adef1":"code","43d6ce3e":"code","d6a37bf9":"code","59ae582a":"code","c41b2bf3":"code","5eab8565":"code","fd0f296d":"code","6f2c3d02":"code","ea1cfae0":"code","2b49257d":"code","cfb38526":"code","8449861a":"code","2587f864":"code","cd5486ee":"code","5aa7e928":"code","890ed2f0":"code","f2237ac8":"code","36fee616":"code","867d46b4":"code","d6a6b918":"code","c4f3827e":"code","3a3a3143":"code","2ea651db":"code","7fc1bd32":"code","a859ac57":"code","1375f37d":"code","1610daab":"code","859f2d03":"code","fe668793":"code","e3fddffd":"code","2e979aa9":"code","be5f5d87":"code","54705aca":"markdown","e592e06a":"markdown","1f266449":"markdown","2a7138d6":"markdown","fd4a995c":"markdown","bfa17b63":"markdown","36c3b506":"markdown","f0d140f3":"markdown","e63ea4db":"markdown","94592294":"markdown","7a5bf8f9":"markdown","6a537175":"markdown"},"source":{"7ae95406":"!pip install imbalanced-learn","9c5a1ed4":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nfrom tqdm import tqdm\nimport pandas as pd\nimport cv2\nimport numpy as np\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.utils.data_utils import Sequence\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.keras import balanced_batch_generator\nfrom keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline","321ab938":"train = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntrain.head()","d6c1cd54":"test = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\ntest.head()","3778466e":"# malignant = test[test['benign_malignant']=='malignant']\n# malignant_vals = malignant['image_name'].values\n# type(malignant_vals)\n# len(malignant_vals)","57f76f5d":"malignant = train[train['benign_malignant']=='malignant']\nmalignant_vals = malignant['image_name'].values\ntype(malignant_vals)\nlen(malignant_vals)","4e1c6f4a":"malignant_labels = malignant['target'].values\nmalignant_labels_rand = [np.random.choice(malignant_labels) for i in range(584)]","dd1df833":"malignant_list = list(malignant_vals)\ntype(malignant_list)\nlen(malignant_list)\n# malignant_list\n#malignant_rand = [np.random.choice(malignant_vals + '.jpg') for i in range(584)]","b8d714d2":"# DIR = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train'\n# benign_images = []\n\n# for i in malignant_rand:\n#     image1 = plt.imread(os.path.join(DIR,i))\n#     image1 = cv2.resize(image1,(224,224))\n#     benign_images.append(image1)\n# #     np.append(k_be,image1)\n","4dcb38c1":"benign = train[train['benign_malignant']=='benign']\nbenign_vals = benign['image_name'].values\ntype(benign_vals)\nlen(benign_vals)","38c8af16":"benign_labels = benign['target'].values\nbenign_labels_rand = [np.random.choice(benign_labels) for i in range(584)]","92924a3a":"benign_list = list(benign_vals)\ntype(benign_list)\n# benign_rand = [np.random.choice(benign_vals + '.jpg') for i in range(584)]","867d74d1":"benign_list_1 = benign_list[0:584]\nlen(benign_list_1)","341e85c8":"mal_bin_cmbo_img_name_list = malignant_list + benign_list_1\nmal_bin_cmbo_label_list = malignant_labels_rand + benign_labels_rand\nprint(len(mal_bin_cmbo_label_list))\nprint(len(mal_bin_cmbo_img_name_list))","73cc9dd2":"# SEED = 42\n# from sklearn.model_selection import train_test_split\n# x_train,x_val,y_train,y_val = train_test_split(mal_bin_cmbo_img_name_list,mal_bin_cmbo_label_list,test_size = 0.2,random_state = SEED)","7f9212e0":"import gc\ngc.collect()","98b0e11d":"DIR = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train'\nimg_data = []\njpeg = '.jpg'\nimg_size = 224\n\nfor i in tqdm(mal_bin_cmbo_img_name_list):\n    img = plt.imread(os.path.join(DIR,i)+jpeg)\n    img = cv2.resize(img,(img_size,img_size))\n    img_data.append(img)","c6335788":"train_imgs = np.asarray(img_data)\nprint(train_imgs.shape)\ntrain_labels =  np.asarray(mal_bin_cmbo_label_list)\n# test_imgs = np.asarray(test_imgs)\n# test_labels =  np.asarray(test_labels)","66a7577a":"BATCH_SIZE = 64\nSEED = 42\nEPOCHS = 100\nx, y, z = 224, 224, 3\ninputShape = (x, y, z)\nNUM_CLASSES = 1","243375e5":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(\n    train_imgs, \n    train_labels,\n    test_size = 0.3, \n    random_state = SEED\n)","947cfcf6":"type(X_val)","39731324":"train_datagen = ImageDataGenerator( rescale = 1.\/255,\n                                    rotation_range=90,\n                                    width_shift_range=0.15,\n                                    height_shift_range=0.15,\n                                    horizontal_flip = True,\n                                    vertical_flip = True,\n                                    zoom_range=(0.9,1),\n                                    fill_mode= 'nearest',\n                                    brightness_range=(0.8, 1.2),\n                                  )\n\ntrain_generator = train_datagen.flow(X_train, Y_train, batch_size = BATCH_SIZE)\nval_generator = train_datagen.flow(X_val, Y_val, batch_size = BATCH_SIZE, shuffle = True)","c0a1cd74":"import matplotlib.pyplot as plt\nfrom glob import glob\nfrom skimage.io import imread\nfrom skimage.color import rgb2gray\nfrom sklearn.model_selection import train_test_split\nimport keras\nimport numpy as np\n\nfrom keras.models import Sequential\nfrom keras.layers import (  Dense,\n                            Flatten,\n                            LeakyReLU\n                         )\nfrom keras.applications import  VGG19 \nfrom keras.optimizers import Adam\nfrom keras.utils.np_utils import to_categorical\nfrom skimage.transform import resize\nfrom tqdm import tqdm\nfrom keras.preprocessing.image import ImageDataGenerator","dbc6c814":"from keras.callbacks import ModelCheckpoint\nfilepath = \"..\/working\/saved_models-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath,monitor = 'val_acc',verbose = 1,save_best_only = True,mode = 'max')\ncallbacks_list = [checkpoint]","8512f0c4":"model = Sequential()\nmodel.add(VGG19(include_top=False, weights='imagenet', input_shape= inputShape))\nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(LeakyReLU(0.001))\nmodel.add(Dense(16))\nmodel.add(LeakyReLU(0.001))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.layers[0].trainable = False\n\nmodel.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['acc'])\n\nHistory = model.fit_generator(train_generator,\n    steps_per_epoch = len(X_train) \/\/ BATCH_SIZE,\n    epochs = EPOCHS, \n    validation_data = val_generator,\n    validation_steps = len(X_val) \/\/ BATCH_SIZE,\n    callbacks = callbacks_list\n)\n\n\nmodel.save('melanoma-classification-model.h5')","4673a180":"# model.save('melanoma-classification-model.h5')","ad3a54c2":"def hist(History):\n    fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n\n    ax[0].plot(History.history['loss'])\n    ax[0].plot(History.history['val_loss'])\n    ax[0].legend(['Training loss', 'Validation Loss'],fontsize=18)\n    ax[0].set_xlabel('Epochs ',fontsize=16)\n    ax[0].set_ylabel('Loss',fontsize=16)\n    ax[0].set_title('Training loss x Validation Loss',fontsize=16)\n\n\n    ax[1].plot(History.history['acc'])\n    ax[1].plot(History.history['val_acc'])\n    ax[1].legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n    ax[1].set_xlabel('Epochs ',fontsize=16)\n    ax[1].set_ylabel('Accuracy',fontsize=16)\n    ax[1].set_title('Training Accuracy x Validation Accuracy',fontsize=16)","1d2a4e02":"def plot_any(arr, title = ''):\n    plt.figure(figsize = (15, 25))\n    for i in range(len(arr)):\n        plt.subplot(1,len(arr),i + 1)\n        plt.title(title)\n        plt.imshow(arr[i], cmap = 'gray');","dd7adef1":"loss, accu = model.evaluate(X_val, Y_val)\nprint(\"%s: %.2f%%\" % ('Accuracy...', accu))\nprint(\"%s: %.2f\" % ('loss.......', loss))","43d6ce3e":"hist(History)","d6a37bf9":"from keras.models import load_model\nprevious_model = load_model('..\/working\/melanoma-classification-model.h5')","59ae582a":"testimg_dir = test['image_name'].values\ntestimg_dir = list(testimg_dir)\n# testimg_dir","c41b2bf3":"submission=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\nsubmission.head()","5eab8565":"DIR1 = '..\/input\/siim-isic-melanoma-classification\/jpeg\/test'\ntarget=[]\nfor i in tqdm(testimg_dir):\n    img=cv2.imread(os.path.join(DIR1,i)+jpeg)\n    img = cv2.resize(img, (224,224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    img=np.reshape(img,(1,224,224,3))\n    prediction=previous_model.predict(img)\n    target.append(prediction[0][0])\n\nsubmission['target']=target","fd0f296d":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","6f2c3d02":"# !pip install Keras","ea1cfae0":"# from keras.layers import Input,Dense,Flatten\n# from keras.models import Model\n# from keras.applications.vgg16 import VGG16\n# from keras.applications.vgg16 import preprocess_input\n# from keras.preprocessing import image\n# from keras.preprocessing.image import ImageDataGenerator\n# from keras.models import Sequential\n# from glob import glob","2b49257d":"# vgg = VGG16(input_shape = inputShape,weights = 'imagenet',include_top = False)","cfb38526":"# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n#                                                include_top=False,\n#                                                weights='imagenet')","8449861a":"# from skimage.io import imread\n# from skimage.color import rgb2gray\n# from skimage.transform import resize\n\n# train_imgs = []\n# train_labels = []\n# test_imgs  = []\n# test_labels = []\n\n# x, y, z = 224, 224, 3\n\n# #train\n\n# for i in malignant_rand:\n#     img_resize = imread(os.path.join(DIR,i))\n#     img_resize = resize(img_resize, (x, y, z))\n\n#     train_imgs.append(img_resize)\n# #     train_labels.append(klass)\n        \n# #test\n# # for klass, folder in enumerate(tqdm(test_path)):\n# #     for img in glob(folder + '\/*'):\n        \n# #         img_resize = imread(img)\n# #         img_resize = resize(img_resize, (x, y, z))\n\n# #         test_imgs.append(img_resize)\n# #         test_labels.append(klass)","2587f864":"# train_imgs[0].shape","cd5486ee":"# train_imgs = np.asarray(train_imgs)","5aa7e928":"# train_imgs.shape","890ed2f0":"#I can take two list of benign_rand and malignent_rand and concat them then do the for loop for reading the images and store into a new list\n#then convert that list into a nparray\n# then follow 'https:\/\/www.kaggle.com\/xwalker\/simple-cnn-vgg19-keras'\n# NUM_CLASSES = 1\n# EPOCHS = 15\n# BATCH_SIZE = 64\n# inputShape = (x, y, z)\n# X_train, X_test, y_train, y_test = train_test_split(\n#     train_imgs, \n#     train_labels,\n#     test_size = 0.3, \n# )\n# train_datagen = ImageDataGenerator( rescale = 1.\/255,\n#                                     rotation_range=90,\n#                                     width_shift_range=0.15,\n#                                     height_shift_range=0.15,\n#                                     horizontal_flip = True,\n#                                     vertical_flip = True,\n#                                     zoom_range=(0.9,1),\n#                                     fill_mode= 'nearest',\n#                                     brightness_range=(0.8, 1.2),\n#                                   )\n\n# train_generator = train_datagen.flow(X_train, y_train, batch_size = BATCH_SIZE)\n# val_generator = train_datagen.flow(X_test, y_test, batch_size = BATCH_SIZE, shuffle = True)","f2237ac8":"# concated_be_mal = benign_rand + malignant_rand\n# concated_be_mal_1 = [np.random.choice(concated_be_mal)]\n","36fee616":"# plt.imshow(benign_images[9])","867d46b4":"# for i in benign_images:\n#     benign_images_1 = np.asarray(i)\n    ","d6a6b918":"# plt.imshow(benign_images_1[9])","c4f3827e":"# benign_images1[0]","3a3a3143":"# from keras.preprocessing.image import image to array","2ea651db":"# from tqdm import tqdm\n\n# DIR = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train'\n# jpeg = '.jpg'\n# labels = []\n# images = []\n\n\n# directory = []\n# for i in train['image_name']:\n#     directory.append(os.path.join(DIR,i)+jpeg)\n\n# for i in range(train.shape[0]):\n#     labels.append(train['target'])\n    \n# for i in tqdm(range(0,train.shape[0],32)):\n#     imag = plt.imread(directory[i])\n#     imag = imag\/255.0\n#     imag = cv2.resize(imag,(256,256))\n#     images.append(imag)","7fc1bd32":"# img_data = np.reshape(images,(images.shape[0],img_size,img_size,3))\n# label_data = np.array(labels)","a859ac57":"# plt.imshow(images[64])","1375f37d":"# 1036*32\n","1610daab":"# directory[9]","859f2d03":"# im = cv2.imread(directory[9])\n# im = cv2.resize(im,(256,256))\n# im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n# plt.imshow(im)\n# print(im.shape)","fe668793":"# import gc\n# gc.collect()","e3fddffd":"# class BalancedDataGenerator(Sequence):\n#     \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n#     def __init__(self, x, y, datagen, batch_size=32):\n#         self.datagen = datagen\n#         self.batch_size = batch_size\n#         self._shape = x.shape        \n#         datagen.fit(x)\n#         self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), batch_size=self.batch_size, keep_sparse=True)\n\n#     def __len__(self):\n#         return self._shape[0] \/\/ self.batch_size\n\n#     def __getitem__(self, idx):\n#         x_batch, y_batch = self.gen.__next__()\n#         x_batch = x_batch.reshape(-1, *self._shape[1:])\n#         return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()","2e979aa9":"# from keras.preprocessing.Image import ImageDataGenerator\n# datagen = ImageDataGenerator() # define your data augmentation\n# bgen = BalancedDataGenerator(x, y, datagen, batch_size=32)\n# steps_per_epoch = balanced_gen.steps_per_epoch","be5f5d87":"# import gc\n# gc.collect()","54705aca":"## READING THE COMBINED IMAGES AND STORING INTO A LIST","e592e06a":"## COMBINING MAL & BNIN `IMAGE_NAME` LISTS:","1f266449":"# Test Images:","2a7138d6":"## Malignent :","fd4a995c":"## Benign :","bfa17b63":"## Malignent:","36c3b506":"## Making Submission:","f0d140f3":"<center><img src=\"https:\/\/i.imgur.com\/gE3PMKU.jpg\" width=\"500px\"><\/center>\n","e63ea4db":"As you can see, in this note book I have taken 584 images from each class(because the both the classes are highly imbalanced), then applied image augmentation on the fly. If we do the image augmentation without doing that image will increase for sure, but it will not resolve the problem of imbalance class.","94592294":"## TRAIN & VALIDATION SPLIT","7a5bf8f9":"## Ploting the results of the training:","6a537175":"## Model Building:"}}