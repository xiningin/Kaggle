{"cell_type":{"77438a7f":"code","de2aad6f":"code","c3082c64":"code","09041122":"code","e73aacb9":"code","4034fbb6":"code","3645a378":"code","aa239173":"code","ff99e131":"code","29a524d5":"code","72e568ea":"code","13944592":"code","f8c2fcb2":"code","3bb62a08":"code","a06dd93f":"code","7f516962":"code","891ae2ac":"code","b9291365":"code","46c68dbc":"code","ba8733da":"code","d484d45c":"code","cc2856dd":"code","d80f4152":"code","167701f8":"code","d6229838":"code","d08b6715":"code","923fe388":"code","98fb8df3":"code","55296e7b":"code","d5265cfa":"code","a0a5d300":"code","34b5c11f":"code","6aa8ae03":"code","8d68cf84":"code","3ec17687":"code","d2e93591":"code","d46f0d9b":"code","223ed241":"code","f3893de8":"code","9d58a979":"code","396abab2":"code","df6ad4a7":"code","bfb80f9d":"code","37cfda2b":"code","c5efd962":"code","bc955456":"code","8ea19c5c":"code","e364afeb":"code","888f1332":"code","2f7e95a1":"code","a38d512c":"code","5478c9d0":"code","76c266a0":"code","0ba0d119":"code","24df9340":"code","f933af4f":"code","80765009":"code","a688029a":"code","3f66ab61":"code","756b1a76":"code","d9cbb2ea":"code","10d87105":"code","1303584a":"code","d2050a75":"code","9355372d":"code","7a3bdb8d":"code","1b6bdb61":"code","bc35bab6":"code","1d82684c":"code","a863914e":"code","e3ff5a8c":"code","49d851f4":"code","2336ed9b":"code","c724b937":"code","24c60dd1":"code","9c80aa89":"code","8dbb7f05":"code","996bb608":"code","762fd33e":"code","2d00fdbe":"code","0a7ba4ba":"code","b990ee60":"markdown","d6f3dac4":"markdown","2f4c8a55":"markdown","d96fe8cd":"markdown","9908d7ae":"markdown","3f990005":"markdown","05728276":"markdown","1676d7a1":"markdown","887655c4":"markdown","2340ce0a":"markdown","695f112d":"markdown","4d98b62a":"markdown","916fff21":"markdown","6723aecc":"markdown","7fc31d29":"markdown","c2b64cec":"markdown","91cd74fc":"markdown","c614f643":"markdown","d1639fbe":"markdown","e37974f6":"markdown","40f05428":"markdown","610b715d":"markdown","07a407cb":"markdown","93b26cfa":"markdown","e13ecacc":"markdown","53dc1dad":"markdown","464cf083":"markdown","36d1d66e":"markdown","e9ce5296":"markdown","73006c74":"markdown","0b2bdd9d":"markdown","e1bd3a38":"markdown","2dd9ad16":"markdown","f9f18daa":"markdown","2f39bba2":"markdown","1ce1c0e6":"markdown","eab004ff":"markdown","debf530c":"markdown","21387743":"markdown","c1de8077":"markdown","5598f435":"markdown","9d39c39f":"markdown","aca065c3":"markdown","3f78aa05":"markdown","5bee1ce8":"markdown","5ac7c5b8":"markdown","606ccc89":"markdown","c6fb2af2":"markdown","20335212":"markdown","6e7b62be":"markdown","89de4ce1":"markdown","03f483e7":"markdown","281d37b6":"markdown"},"source":{"77438a7f":"# Import libraries\nimport pandas as pd # linear algebra\nimport pandas_profiling as pp\nimport numpy as np # Data processsing\nimport os # os functions\nimport matplotlib.pyplot as plt # Plotting library\nimport seaborn as sns # Data visualization \nfrom sklearn.model_selection import train_test_split,KFold,GridSearchCV,RandomizedSearchCV\n\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBClassifier, plot_importance\nimport xgboost as xgb\nimport re\nimport sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.experimental import enable_hist_gradient_boosting\n# Going to use these  base models for the stacking\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, \n                              ExtraTreesClassifier,  HistGradientBoostingClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import make_scorer, accuracy_score,classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n\nsns.set() #Set aesthetic parameters in one step.\npd.options.display.max_columns=100 # display setting","de2aad6f":"# Load training and test data \nforest_classification_train =pd.read_csv('\/kaggle\/input\/learn-together\/train.csv',index_col = 'Id')\nforest_classification_test = pd.read_csv('\/kaggle\/input\/learn-together\/test.csv',index_col = 'Id')","c3082c64":"forest_classification_train.shape","09041122":"forest_classification_test.shape","e73aacb9":"forest_classification_train.head()","4034fbb6":"forest_classification_test.head()","3645a378":"forest_classification_train.describe().T","aa239173":"# Missing values in the training data\nprint(f\"Missing Values in train: {forest_classification_train.isna().any().any()}\")\n\n# Missing values in the test data\nprint(f\"Missing Values in test: {forest_classification_test.isna().any().any()}\")","ff99e131":"# Lets check the column Types\nprint(f\"Train Column Types: {set(forest_classification_train.dtypes)}\")\nprint(f\"Test Column Types: {set(forest_classification_test.dtypes)}\")","29a524d5":"# Next lets check the number of unique values by column.\nfor column in forest_classification_train.columns:\n    print(column, forest_classification_train[column].nunique())","72e568ea":"print(\"Soil_Type7: \", forest_classification_test[\"Soil_Type7\"].nunique())\nprint(\"Soil_Type15: \", forest_classification_test[\"Soil_Type15\"].nunique())","13944592":"print(\"- - - Test - - -\")\nprint(forest_classification_test[\"Soil_Type7\"].value_counts())\nprint(forest_classification_test[\"Soil_Type15\"].value_counts())","f8c2fcb2":"# drop soil type 7 and 15.\n\nforest_classification_train = forest_classification_train.drop([\"Soil_Type7\", \"Soil_Type15\"], axis = 1)\nforest_classification_test = forest_classification_test.drop([\"Soil_Type7\", \"Soil_Type15\"], axis = 1)","3bb62a08":"forest_classification_train.columns","a06dd93f":"# Histogram for the variable elevation\nforest_classification_train[\"Elevation\"].plot(kind=\"hist\",bins=30)","7f516962":"# Cover type vs Elevation\nforest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Elevation\")","891ae2ac":"forest_classification_train[\"Aspect\"].plot(kind=\"hist\", bins = 30)","b9291365":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Aspect\")\n","46c68dbc":"forest_classification_train[\"Slope\"].plot(kind=\"hist\", bins = 30)","ba8733da":"sns.scatterplot(x=forest_classification_train[\"Slope\"], y=forest_classification_train[\"Cover_Type\"])","d484d45c":"forest_classification_train[\"Horizontal_Distance_To_Hydrology\"].plot(kind=\"hist\", bins = 30)","cc2856dd":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Horizontal_Distance_To_Hydrology\")","d80f4152":"forest_classification_train[\"Vertical_Distance_To_Hydrology\"].plot(kind='hist', bins = 30)","167701f8":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Vertical_Distance_To_Hydrology\")","d6229838":"forest_classification_train[\"Horizontal_Distance_To_Roadways\"].plot(kind='hist', bins = 30)\n","d08b6715":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Horizontal_Distance_To_Roadways\")","923fe388":"forest_classification_train[\"Hillshade_9am\"].plot(kind=\"hist\", bins = 30)\n","98fb8df3":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Hillshade_9am\")","55296e7b":"forest_classification_train[\"Hillshade_Noon\"].plot(kind=\"hist\", bins = 30)\n","d5265cfa":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Hillshade_Noon\")","a0a5d300":"forest_classification_train[\"Hillshade_3pm\"].plot(kind=\"hist\", bins = 30)","34b5c11f":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Hillshade_3pm\")","6aa8ae03":"forest_classification_train[\"Horizontal_Distance_To_Fire_Points\"].plot(kind=\"hist\", bins = 30)\n","8d68cf84":"forest_classification_train.plot(kind=\"scatter\", x=\"Cover_Type\", y=\"Horizontal_Distance_To_Fire_Points\")\n","3ec17687":"sns.countplot(x=\"Wilderness_Area1\", data=forest_classification_train)\n","d2e93591":"sns.countplot(x=\"Wilderness_Area2\", data=forest_classification_train)","d46f0d9b":"sns.countplot(x=\"Wilderness_Area3\", data=forest_classification_train)","223ed241":"sns.countplot(x=\"Wilderness_Area4\", data=forest_classification_train)","f3893de8":"res_soil_dict = {}\nfor col in forest_classification_train.columns[14:-1]:\n    res_soil_dict[col] = forest_classification_train[col].value_counts().loc[1] \n","9d58a979":"sorted_d = sorted(res_soil_dict.items(), key=lambda kv: kv[1])","396abab2":"sorted_d","df6ad4a7":"forest_classification_train[\"Cover_Type\"].plot(kind=\"hist\", bins = 30)","bfb80f9d":"forest_classification_train[\"Cover_Type\"].shape","37cfda2b":"#Change the variable with just two values into categorical variables.\nforest_classification_train.iloc[:,10:-1] = forest_classification_train.iloc[:,10:-1].astype(\"category\")\nforest_classification_test.iloc[:,10:] = forest_classification_test.iloc[:,10:].astype(\"category\")\n\n# Create the correlation plot\nf,ax = plt.subplots(figsize=(8,6))\nsns.heatmap(forest_classification_train.corr(),annot=True, linewidths=.5, fmt='.1f', ax=ax)\nplt.show()\n\ntrain = forest_classification_train\ntest = forest_classification_test\ntrain.iloc[:,10:-1] = train.iloc[:,10:-1].astype(\"category\")\ntest.iloc[:,10:] = test.iloc[:,10:].astype(\"category\")","c5efd962":"# some of the feature engineering steps based on \"Pruthvi H.R, Nisha K.K, Chandana T.L, Navami K and Biju R M (2015) \u2018Feature engineering on forest cover type data with ensemble of decision trees\u2019, 2015 IEEE International Advance Computing Conference (IACC). Banglore, India: IEEE, pp. 1093\u20131098. Available at: 10.1109\/IADCC.2015.7154873 (Accessed: 2 September 2019).\"\n\ntrain['EV_DTH'] = (train.Elevation - train.Vertical_Distance_To_Hydrology)\ntest['EV_DTH'] = (test.Elevation - test.Vertical_Distance_To_Hydrology)\n\ntrain['EH_DTH'] = (train.Elevation -  (train.Horizontal_Distance_To_Hydrology *0.2))\ntest['EH_DTH'] = (test.Elevation -  (test.Horizontal_Distance_To_Hydrology *0.2))\n\ntrain['Dis_To_Hy'] = (((train.Horizontal_Distance_To_Hydrology **2) + (train.Vertical_Distance_To_Hydrology **2))**0.5)\ntest['Dis_To_Hy'] = (((test.Horizontal_Distance_To_Hydrology **2) + (test.Vertical_Distance_To_Hydrology **2))**0.5)\n\ntrain['HyF_1'] = (train.Horizontal_Distance_To_Hydrology + train.Horizontal_Distance_To_Fire_Points)\ntest['HyF_1'] = (test.Horizontal_Distance_To_Hydrology + test.Horizontal_Distance_To_Fire_Points)\n\ntrain['HyF_2'] = (train.Horizontal_Distance_To_Hydrology - train.Horizontal_Distance_To_Fire_Points)\ntest['HyF_2'] = (test.Horizontal_Distance_To_Hydrology - test.Horizontal_Distance_To_Fire_Points)\n\ntrain['HyR_1'] = (train.Horizontal_Distance_To_Hydrology + train.Horizontal_Distance_To_Roadways)\ntest['HyR_1'] = (test.Horizontal_Distance_To_Hydrology + test.Horizontal_Distance_To_Roadways)\n\ntrain['HyR_2'] = (train.Horizontal_Distance_To_Hydrology - train.Horizontal_Distance_To_Roadways)\ntest['HyR_2'] = (test.Horizontal_Distance_To_Hydrology - test.Horizontal_Distance_To_Roadways)\n\n\ntrain['FiR_1'] = (train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Roadways)\ntest['FiR_1'] = (test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Roadways)\n\ntrain['FiR_1'] = (train.Horizontal_Distance_To_Fire_Points - train.Horizontal_Distance_To_Roadways)\ntest['FiR_1'] = (test.Horizontal_Distance_To_Fire_Points - test.Horizontal_Distance_To_Roadways)\n\ntrain['Avg_shade'] = ((train.Hillshade_9am + train.Hillshade_Noon + train.Hillshade_3pm) \/3)\ntest['Avg_shade'] = ((test.Hillshade_9am + test.Hillshade_Noon + test.Hillshade_3pm) \/3)\n\ntrain['Morn_noon_int'] = ((train.Hillshade_9am + train.Hillshade_Noon) \/ 2)\ntest['Morn_noon_int'] = ((test.Hillshade_9am + test.Hillshade_Noon) \/ 2)\n\ntrain['noon_eve_int'] = ((train.Hillshade_3pm + train.Hillshade_Noon) \/ 2)\ntest['noon_eve_int'] = ((test.Hillshade_3pm + test.Hillshade_Noon) \/ 2)\n\ntrain['Slope2'] = np.sqrt(train.Horizontal_Distance_To_Hydrology**2 + train.Vertical_Distance_To_Hydrology**2)\ntest['Slope2'] = np.sqrt(test.Horizontal_Distance_To_Hydrology**2 + test.Vertical_Distance_To_Hydrology**2)","bc955456":"train.isna().any().any()","8ea19c5c":"train.columns","e364afeb":"cols=list(train.columns)\nnumeric_columns=[]\nfor i in range(10):\n    numeric_columns.append(cols[i])\n    \nfor i in range(12):\n    numeric_columns.append(cols[-(i+1)])\nprint(numeric_columns)","888f1332":"train_minmax=train[numeric_columns]\ntest_minmax=test[numeric_columns]\nmm_scaler = MinMaxScaler()\n# my_train_minmax = mm_scaler.fit_transform(train_df[other_columns])\nmm_scaler.fit(train_minmax)\ntrain_trans=mm_scaler.transform(train_minmax)\ntest_trans=mm_scaler.transform(test_minmax)\n\ntemp_train=pd.DataFrame(train_trans)\ntemp_test=pd.DataFrame(test_trans)\n","2f7e95a1":"train.isna().any().any()","a38d512c":"for i in range(22):\n    temp_train.rename(columns={i:numeric_columns[i]},inplace=True)\n    temp_test.rename(columns={i:numeric_columns[i]},inplace=True)\ntemp_train.head()","5478c9d0":"temp_train.index +=1\ntemp_test.index +=1","76c266a0":"train[numeric_columns]=temp_train[numeric_columns]\ntest[numeric_columns]=temp_test[numeric_columns]\ntrain.head()","0ba0d119":"temp_train","24df9340":"train","f933af4f":"# train and validation data split\n\nX_train, X_val, y_train, y_val = train_test_split(forest_classification_train.drop(['Cover_Type'], axis=1), forest_classification_train['Cover_Type'], test_size=0.2,shuffle = True, random_state = 2)","80765009":"X_train.shape","a688029a":"X_val.shape","3f66ab61":"y_train.shape","756b1a76":"y_val.shape","d9cbb2ea":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 8)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","10d87105":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\n# rf_model = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\n# rf_random = RandomizedSearchCV(estimator = rf_model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\n# rf_random.fit(X_train, y_train)","1303584a":"# rf_random.best_params_\n","d2050a75":"train.isna()\n#test.isna().any().any()","9355372d":"# model = RandomForestClassifier(n_estimators=100,random_state = 42)\nRF_random=RandomForestClassifier(n_estimators=885,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=110,bootstrap=False)\n# Train the model on training data\nRF_random.fit(train.drop(['Cover_Type'], axis=1), train['Cover_Type'])\n","7a3bdb8d":"rf = RandomForestClassifier()\nmodel = Pipeline(steps=[('model',rf),])","1b6bdb61":"n_features=test.shape[1]\nint(np.sqrt(n_features))","bc35bab6":"#param_grid = {'model__n_estimators': np.logspace(2,3.5,8).astype(int),\n#              'model__max_features': [0.1,0.3,0.5,0.7,0.9],\n#              'model__max_depth': np.logspace(0,3,10).astype(int),\n#              'model__min_samples_split': [2, 5, 10],\n#              'model__min_samples_leaf': [1, 2, 4],\n#              'model__bootstrap':[True, False]}\n              \n\nparam_grid = {'model__n_estimators': [100,  1000],\n              'model__max_features': [int(np.sqrt(n_features))]}\n\ngrid = RandomizedSearchCV(estimator=model, \n                          param_distributions=param_grid, \n                          n_iter=1, # This was set to 100 in my offline version\n                          cv=3, \n                          verbose=3, \n                          n_jobs=1,\n                          scoring = {'NLL':'neg_log_loss', 'Accuracy':'accuracy'}, \n                          refit='NLL')\n\n#grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=0)\ngrid.fit(train.drop(['Cover_Type'], axis=1), train['Cover_Type'])","1d82684c":"grid.best_params_","a863914e":"grid_pred = grid.predict(X_val)","e3ff5a8c":"accuracy_score(y_val, grid_pred)","49d851f4":"xgb= XGBClassifier( n_estimators=1000,  #todo : search for good parameters\n                    learning_rate= 0.5,  #todo : search for good parameters\n                    objective= 'binary:logistic', #this outputs probability,not one\/zero. should we use binary:hinge? is it better for the learning phase?\n                    random_state= 1,\n                    n_jobs=-1)","2336ed9b":"X_train.iloc[:,10:] = X_train.iloc[:,10:].astype(\"int64\")\nX_val.iloc[:,10:] = X_val.iloc[:,10:].astype(\"int64\")\n\n","c724b937":"param = {'n_estimators': [100, 500, 1000, 2000],\n         'learning_rate': [0.001, 0.01, 0.1, 0.5, 1, 2, 5]}\ngrider = GridSearchCV(xgb, param, n_jobs=-1, cv=3, scoring='accuracy', verbose=True)\n#grider.fit(X_train, y_train)","24c60dd1":"\nxgb.fit(X_train, y_train)\nxgb_val = xgb.predict(X_val)\naccuracy_score(y_val, xgb_val)","9c80aa89":"gbc= GradientBoostingClassifier( n_estimators = 2000, max_depth = 35, max_features = 20, random_state = 1,\n                    learning_rate= 0.1)","8dbb7f05":"gbc.fit(X_train, y_train)\ngbc_val = gbc.predict(X_val)\naccuracy_score(y_val, gbc_val)","996bb608":"forest_classification_train.iloc[:,10:] = forest_classification_train.iloc[:,10:].astype(\"int64\")\nforest_classification_test.iloc[:,10:] = forest_classification_test.iloc[:,10:].astype(\"int64\")\n# Final model.\nclf = XGBClassifier(n_estimators=500,colsample_bytree=0.9,max_depth=9,random_state=1,eta=0.2)\nclf.fit(forest_classification_train.drop(['Cover_Type'], axis=1),forest_classification_train['Cover_Type'])","762fd33e":"test_pred = clf.predict(forest_classification_train.drop(['Cover_Type'], axis=1),forest_classification_train.drop['Cover_Type'])","2d00fdbe":"# temp\nRF_random_pred = RF_random.predict(test)","0a7ba4ba":"# Save test predictions to file\noutput = pd.DataFrame({'ID': forest_classification_test.index.values,\n                       'Cover_Type': RF_random_pred})\noutput.to_csv('submission.csv', index=False)","b990ee60":"looks like the variables are biased towards one value. we can probably drop from both training and testing.","d6f3dac4":"### XGB Classifier ","2f4c8a55":"Lets see if there are correlation between numeric variables.","d96fe8cd":"Looks like all of them are integer 64.","9908d7ae":"### Hillshade_9am \u2013 Hillshade index at 9am, summer solstice.","3f990005":"![](http:\/\/)We dont see any much [](http:\/\/)correlation here as well.","05728276":"Looks like there are about 15120 rows in the training dat set and we have 55 columns.","1676d7a1":"Don't see much difference across the cover type.","887655c4":"Lets explore variable by variable : elevation - level above the sea level\n\n### Elevation - Elevation in meters\n","2340ce0a":"# Data Preparation","695f112d":"looks like most of them are below the water level. Now, lets compare it with target variable.\n","4d98b62a":"**GradientBoostingClassifier**","916fff21":"This shows clear distinction by cover type.","6723aecc":"### Content :\n1. Library import and Data loading.\n2. EDA\n3. Data cleanining and Feature engineering.\n4. Model building.\n5. Predictions.\n","7fc31d29":"There are about 565892 rows in the test dat and 54 columns.","c2b64cec":"hillshade 3pm vs 9am having greater than 0.8 correlation. and Vertical distance to hydrology and horizontal distance having good 0.7 correlation.","91cd74fc":"most of the trees are closer to water sources. Now, lets compare it with target variable.","c614f643":"Hillshade_Noon \u2013 Hillshade index at noon, summer solstice.","d1639fbe":"Though we have across the cover type for hill shade greater than 125, type 3 starts as early as 50, where as 4&5 does not start before 125.","e37974f6":"### RF with RandomSearchCV","40f05428":"There is no correlation with the target variable.","610b715d":"# Data Loading","07a407cb":"Elevation and distnace variables are bigger numbers.","93b26cfa":"### Random Forest with Grid Search","e13ecacc":"Next lets check if there are missing values in the data.","53dc1dad":"0 being black, 255 \u2013 white.\n\n","464cf083":"Lets see how Aspect vs cover type plots.","36d1d66e":"Hillshade_3pm \u2013 Hillshade index at 3pm, summer solstice.","e9ce5296":"we dont see any missing values in training and test data.","73006c74":"We see a trend for every 500. Lets plot the cover type by elevation.","0b2bdd9d":"looks like type 7 and 15 are binary values. Lets explore the split in the test data :","e1bd3a38":"its all over the place, lets see how it relates to the target.","2dd9ad16":"Lets check the columns after dropping the soil type 7 &15.","f9f18daa":"Except soil type 7 and 15 rest of them having two unique values. Lets check the test data.","2f39bba2":"### Target Variable","1ce1c0e6":"Lets check the Pandas profiling report as well.","eab004ff":"Trees seem to have much light in the morning.","debf530c":"Horizontal_Distance_To_Fire_Points \u2013 Horz Dist to nearest wildfire ignition points.","21387743":"# Predictions","c1de8077":"Lets explore variable slope -   **slope in degrees.**\n\nForest land slope in degrees.","5598f435":"We could see some difference between cover tpes 3,4 and 6 vs 1,2,5 and 7.","9d39c39f":"Soil_Type{n}\n","aca065c3":"Vertical_Distance_To_Hydrology \u2013 Vertical Distance to nearest surface water features","3f78aa05":"## EDA","5bee1ce8":"Lets check the data summary.","5ac7c5b8":"Now lets check few rows from training and test data.","606ccc89":"### Aspect - Aspect in degrees azimuth","c6fb2af2":"looks like cover types 3,4,5 are not growing away from the road.","20335212":"Horizontal_Distance_To_Hydrology \u2013 Horz Dist to nearest surface water features.\n\n","6e7b62be":"Wilderness_Area{n}","89de4ce1":"Horizontal_Distance_To_Roadways \u2013 Horz Dist to nearest roadway","03f483e7":"Lets see how it relates to the target variable.","281d37b6":"# [](http:\/\/)Library import"}}