{"cell_type":{"52b87ffc":"code","f41cc655":"code","d5b11b3b":"code","0149da6c":"code","74f30d02":"code","b8dd4467":"code","fbf6c3bc":"code","41e7f5f4":"code","224aa605":"code","2cfd9b55":"code","a53feb1a":"code","479f4cc1":"code","00421dea":"code","42a7e5b1":"code","6ca96959":"code","dfef5eb9":"code","e519d6cb":"code","26dc80e5":"code","bf9d4860":"code","4a370140":"code","b85ee8c9":"code","fe912a56":"code","3fa7c254":"code","eee25779":"code","3200c2ed":"code","0753b07b":"code","f9528221":"code","813c75e4":"code","5e63be8e":"code","8ec5e902":"code","6137161b":"code","d0b1979c":"code","2b6ebc90":"code","9b181a1c":"code","23ec1827":"markdown","a4b99f7f":"markdown","a1a6e1b5":"markdown","908c66c2":"markdown","66c8805a":"markdown","16b1db42":"markdown","0649518c":"markdown","5dcfdcaf":"markdown","dfe7d3ff":"markdown","ec5c950f":"markdown","c5eae93f":"markdown","a570c96e":"markdown","61fe1ade":"markdown","abe9279f":"markdown","e30f9ef8":"markdown"},"source":{"52b87ffc":"import pandas as pd \nimport numpy as np\nfrom nltk.corpus import stopwords\nimport re #regex\nfrom textblob import TextBlob #sentimate analysis\nfrom nltk.probability import FreqDist\n\n#graphs\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport plotly.graph_objects as go","f41cc655":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d5b11b3b":"#data importation\ntdf= pd.read_csv('\/kaggle\/input\/us-election-2020-tweets\/hashtag_donaldtrump.csv', lineterminator='\\n')#trump df\nbdf=pd.read_csv('\/kaggle\/input\/us-election-2020-tweets\/hashtag_joebiden.csv', lineterminator='\\n')#biden df","0149da6c":"tdf.tail()","74f30d02":"bdf.describe()","b8dd4467":"tdf.isnull().sum()","fbf6c3bc":"bdf.isnull().sum()","41e7f5f4":"#drop useles columns\nbdf=bdf.drop(columns=['tweet_id','collected_at','user_description','collected_at'])\ntdf=tdf.drop(columns=['tweet_id','collected_at','user_description','collected_at'])","224aa605":"#adding a collumn\nbdf.loc[:,'condidat'] = 'Biden'\ntdf.loc[:,'condidat'] = 'trump'","2cfd9b55":"tdf.head()","a53feb1a":"#concat both datasets\ndata = pd.concat([bdf,tdf])","479f4cc1":"data.sort_values(by='created_at').info()","00421dea":"data","42a7e5b1":"# wee look for the rows of specific condidat then we remove the rows that has nan in country \n#then we group by avec country then we get the count then we sort  from big to low\n\n#for biden\ny = data.query('(condidat == \"Biden\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx = data.query('(condidat == \"Biden\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n#for trump\ny2 = data.query('(condidat == \"trump\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx2 = data.query('(condidat == \"trump\")').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n\nfig = go.Figure([go.Bar(x=x, y=y, name='joe Biden'),\n                 go.Bar(x=x2, y=y2, name='donald Trump')])\n\n\nfig.update_layout(title_text='tweets count for each countries')\nfig.update_xaxes(title='countries')\nfig.update_yaxes(title='tweet count')\nfig.show()\n","6ca96959":"# wee look for the rows of specific condidat then we remove the rows that has nan in country \n#then we group by avec country then we get the count then we sort  from big to low\n\n#for biden\ny = data.query('(condidat == \"Biden\")& (country != \"United States\")& (country != \"United States of America\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx = data.query('(condidat == \"Biden\")& (country != \"United States\")& (country != \"United States of America\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n#for trump\ny2 = data.query('(condidat == \"trump\")& (country != \"United States\")& (country != \"United States of America\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx2 = data.query('(condidat == \"trump\")& (country != \"United States\")& (country != \"United States of America\")').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n\nfig = go.Figure([go.Bar(x=x, y=y, name='joe Biden'),\n                 go.Bar(x=x2, y=y2, name='donald Trump')])\n\n\nfig.update_layout(title_text='tweets count for each country usa not included')\nfig.update_xaxes(title='countries')\nfig.update_yaxes(title='tweet count')\nfig.show()","dfef5eb9":"# wee look for the rows of specific condidat then we remove the rows that has nan in country \n#then we group by avec country then #AmineAbouothmane we get the count then we sort  from big to low\n\n#for biden\ny = data.query('(condidat == \"Biden\")& (country == \"United States of America\") ').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False)\nx = data.query('(condidat == \"Biden\")& (country == \"United States of America\") ').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False).index\n#for trump\ny2 = data.query('(condidat == \"trump\")& (country == \"United States of America\") ').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False)\nx2 = data.query('(condidat == \"trump\")& (country == \"United States of America\")').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False).index\n\nfig = go.Figure([go.Bar(x=x, y=y, name='joe Biden'),\n                 go.Bar(x=x2, y=y2, name='donald Trump')])\n\n\nfig.update_layout(title_text='tweets count for each state')\nfig.update_xaxes(title='states')\nfig.update_yaxes(title='tweet count')\nfig.show()\n","e519d6cb":"y = data.groupby('condidat').likes.count()\ny.plot(x='condidate',y=\"likes\",kind='bar',title='tweet likes')\n\n","26dc80e5":"y = data.query('(condidat == \"Biden\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5]\nx = data.query('(condidat == \"Biden\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5].index\ny2 = data.query('(condidat == \"trump\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5]\nx2 = data.query('(condidat == \"trump\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5].index\nfig = go.Figure([go.Bar(x=x, y=y, name='Biden'),go.Bar(x=x2, y=y2, name='trump')])\n\n# Customize aspect\nfig.update_layout(title_text='top 5 sources')\nfig.update_xaxes(title='sources')\nfig.update_yaxes(title='tweets count')\nfig.show()","bf9d4860":"country=\"Morocco\"\na=data[data.country==country].groupby('condidat').tweet.count()\na.plot(x='condidate',y=\"tweet\",kind='bar',title=\"tweet count in country 'morocco'\")\n\n","4a370140":"a.plot(x='condidate',y=\"tweet\",kind='pie',title=\"tweet count in country 'morocco'\")","b85ee8c9":"from nltk.tokenize import word_tokenize\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('punkt')","fe912a56":"\n\nexample_sent = \"This is a sample words sentence, showing off the stop words filtration sentence.\"\n\n\nstop_words = set(stopwords.words('english'))\n\nword_tokens = word_tokenize(example_sent)\n\nfiltered_sentence = [w for w in word_tokens if not w in stop_words]\n\nfiltered_sentence = []\n\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)\n#AmineAbouothmane\nprint(word_tokens)\nprint(filtered_sentence)","3fa7c254":"from nltk.probability import FreqDist\nfdist=FreqDist()\nfor word in filtered_sentence:\n    fdist[word.lower()]+=1\nfdist","eee25779":"def Tokenization(text):\n    stop_words = set(stopwords.words('english'))\n\n    word_tokens = word_tokenize(text)\n\n    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n\n    filtered_sentence = []\n\n    for w in word_tokens:\n        if w not in stop_words:\n            filtered_sentence.append(w)\n    fdist=FreqDist()\n    for word in filtered_sentence:\n        fdist[word.lower()]+=1\n    return fdist","3200c2ed":"#regular expression\nimport re\n\nt='@fazf hello !! https:\/\/pythonprogramming.net\/ ohmygod ??, '\ndef cleanText(text):\n    try:\n        # remove @name and links and retweet and hashtags and symbols in the tweet\n        text=re.sub(r'@[A-Za-z0-9]+','',text)\n        text=re.sub(r'#','',text)\n        text=re.sub(r'RT[\\s]+','',text)\n        text=re.sub(r'https?:\\\/\\\/\\S+','',text)\n        text=re.sub(r'[^\\w]', ' ', text)\n    except:\n        pass\n    return text\nprint(cleanText(t))","0753b07b":"#get the tweets from depends on condidat and number of tweets \n#we choose the United States of America to make sure that the langauge is english for the sentiment analysis to work\n\ndef getTweet(condidat,nb):#condidat[trump,Biden]  nb nomver of tweets we want\n    tweets = data.query('condidat == \"'+condidat+'\"').sort_values('user_followers_count',ascending=False).drop_duplicates(['user_name'])[['tweet','country']]\n    #return nb tweets and removing nan \n    tweets = tweets.dropna().loc[tweets.country=='United States of America'][:nb]\n    return tweets\n\n#get the tweets \nnb=1000\ndd=getTweet('trump',nb)\n\n#reset the index\ndd.reset_index(inplace=True, drop=True)\n#apply the function on tweets and stor results to a new column\ndd['ClearTweet']=dd['tweet'].apply(cleanText)\n#AmineAbouothmane\ndd","f9528221":"#create fuction to get the subjectivity and polarity\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\ndef getAnalysis(score):\n    if score<0:\n        return 'negative'\n    elif score==0:\n        return 'neutral'\n    else:\n        return 'positive'","813c75e4":"#adding columns and applying the functionss \ndd['subjectivity']=dd['ClearTweet'].apply(getSubjectivity)\ndd['polarity']=dd['ClearTweet'].apply(getPolarity)\ndd['analysis']=dd['polarity'].apply(getAnalysis)\ndd.head()","5e63be8e":"#plot the word cloud\nallwords=' '.join( [twts for twts in dd['ClearTweet']] )\nwordcloud=WordCloud(width=500,height=300,random_state=21,max_font_size=119).generate(allwords)\n\nplt.imshow(wordcloud,interpolation='bilinear')\nplt.axis('off')\nplt.show()","8ec5e902":"#plot the polarity and subjectivity\n\nplt.figure(figsize=(8,6))\nfor i in range(0,nb):\n    p=dd['polarity'][i]\n    if p<0:\n        plt.scatter(dd['polarity'][i],dd['subjectivity'][i],color='red', marker = '*')\n    elif p==0:\n        plt.scatter(dd['polarity'][i],dd['subjectivity'][i],color='green', marker = 'o')\n    else:\n        plt.scatter(dd['polarity'][i],dd['subjectivity'][i],color='blue', marker = '+')\nplt.xlabel('polarity')\nplt.ylabel('subjectivity')\nplt.title('sentimat analysis')\nplt.show()","6137161b":"o=dd.groupby('analysis').analysis.count()\nneu=dd[dd['analysis']=='neutral'].ClearTweet.count()\npo=dd[dd['analysis']=='positive'].ClearTweet.count()\nneg=dd[dd['analysis']=='negative'].ClearTweet.count()\n\nfig = go.Figure(data=[go.Pie(labels=[\"positivity\",\"negativity\",\"neutrality\"], values=[po,neg,neu])])\nfig.update_layout(title_text='sentimat analysis of tweets (#trump)')\nfig.show()\no.plot(x='analysis',kind='bar',ylabel=\"counts\",title=\"sentimat analysis of tweets (#trump)\")\n","d0b1979c":"ddb=getTweet('Biden',1000)\n#reset the index\nddb.reset_index(inplace=True, drop=True)\n#apply the function on tweets and stor results to a new column\nddb['ClearTweet']=ddb['tweet'].apply(cleanText)\n#adding columns and applying the functionss \nddb['subjectivity']=ddb['ClearTweet'].apply(getSubjectivity)\nddb['polarity']=ddb['ClearTweet'].apply(getPolarity)\nddb['analysis']=ddb['polarity'].apply(getAnalysis)\nddb.tail()","2b6ebc90":"#plot the word cloud\nallwords=' '.join( [twts for twts in ddb['ClearTweet']] )\nwordcloud=WordCloud(width=500,height=300,random_state=21,max_font_size=119).generate(allwords)\n\nplt.imshow(wordcloud,interpolation='bilinear')\nplt.axis('off')\nplt.show()","9b181a1c":"o=ddb.groupby('analysis').analysis.count()\nneu=ddb[ddb['analysis']=='neutral'].ClearTweet.count()\npo=ddb[ddb['analysis']=='positive'].ClearTweet.count()\nneg=ddb[ddb['analysis']=='negative'].ClearTweet.count()\n\nfig = go.Figure(data=[go.Pie(labels=[\"positivity\",\"negativity\",\"neutrality\"], values=[po,neg,neu])])\nfig.update_layout(title_text='sentimat analysis of tweets (#Biden)')\nfig.show()\no.plot(x='analysis',kind='bar',ylabel=\"counts\",title=\"sentimat analysis of tweets (#Biden)\")","23ec1827":"<h1>data analysis<\/h1>","a4b99f7f":"<h1>tweet count for each state<\/h1>","a1a6e1b5":"<h2>example of word tokenz<\/h2>","908c66c2":"created_at: Date and time of tweet creation\ntweet_id: Unique ID of the tweet\ntweet: Full tweet text\nlikes: Number of likes\nretweet_count: Number of retweets\nsource: Utility used to post tweet\nuser_id: User ID of tweet creator\nuser_name: Username of tweet creator\nuser_screen_name: Screen name of tweet creator\nuser_description: Description of self by tweet creator\nuser_join_date: Join date of tweet creator\nuser_followers_count: Followers count on tweet creator\nuser_location: Location given on tweet creator's profile\nlat: Latitude parsed from user_location\nlong: Longitude parsed from user_location\ncity: City parsed from user_location\ncountry: Country parsed from user_location\nstate: State parsed from user_location\nstate_code: State code parsed from user_location\ncollected_at: Date and time tweet data was mined from twitter*","66c8805a":"<h1>tweet count in country \"morocco\" <\/h1>","16b1db42":"<h1>sentimal analysis #Biden tweets<\/h1>","0649518c":"<h1>word cloud<\/h1>","5dcfdcaf":"<h3>The sentiment function of textblob returns two properties, polarity, and subjectivity. ... Subjective sentences generally refer to personal opinion, emotion or judgment<\/h3><br>\n<h3>The key aspect of sentiment analysis is to analyze a body of text for understanding the opinion expressed by it. Typically, we quantify this sentiment with a positive or negative value, called polarity<\/h3>","dfe7d3ff":"<h1>tweet count for each country<\/h1>","ec5c950f":"<h1> Sentiment Analysis<\/h1>","c5eae93f":"<h1>visualisation<\/h1>","a570c96e":"<h1>tweet likes <\/h1>","61fe1ade":"<h1>top 5 sources<\/h1>","abe9279f":"<h1>tweet count for each country usa not included<\/h1>","e30f9ef8":"<h1>data cleaning<\/h1>"}}