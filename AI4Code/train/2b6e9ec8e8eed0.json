{"cell_type":{"d4536865":"code","9d1032b2":"code","32a989b6":"code","dff93399":"code","63920cef":"code","1af878d2":"code","8723d7a0":"code","ebcd21e4":"code","0bba7734":"code","794a7e51":"code","ebcf4235":"code","902345fa":"code","918e324f":"code","b7604952":"code","7496d7d5":"code","9c86cf74":"code","a1e69ea6":"code","0b0f3de3":"markdown","ec8a1086":"markdown","ac44fa84":"markdown","dc92587a":"markdown","2bdd7a18":"markdown","f7958275":"markdown"},"source":{"d4536865":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d1032b2":"from sklearn.impute import SimpleImputer","32a989b6":"# \u7528\u5747\u503c\u586b\u5145NaN\ndef mean_replace(df, columnName):\n    df_mean = df.copy()\n    impute_mean = SimpleImputer()\n    raw_data = df_mean[columnName].values.reshape(-1, 1)\n    new_data = impute_mean.fit_transform(raw_data)\n    df_mean[columnName] = new_data\n    return df_mean\n\n# \u75280\u586b\u5145NaN\ndef zero_replace(df, columnName):\n    # \u75280\u586b\u5145\u5e74\u9f84\u7684\u7f3a\u5931\u503c\n    df0 = df.copy() # \u590d\u5236\u539f\u6570\u636e\uff0c\u907f\u514d\u539f\u6570\u636e\u88ab\u8986\u76d6\n\n    # \u5b9e\u4f8b\u5316\n    impute_0 = SimpleImputer(strategy='constant', fill_value=0)\n\n    # \u53bb\u9664Age\u5c5e\u6027\u7684\u539f\u59cb\u6570\u636e\uff0c\u5e76\u901a\u8fc7values\u8f6c\u5316\u4e3a\u4e00\u7ef4\u6570\u7ec4\uff0c\u5728\u901a\u8fc7reshape\u53d8\u4e3a\u4e8c\u7ef4\u6570\u7ec4\n    # \u56e0\u4e3asklearn\u4e2d\u4f20\u5230\u6570\u636e\u5fc5\u987b\u662f\u4e8c\u7ef4\u7684\n    raw_data = df0[columnName].values.reshape(-1, 1)\n\n    # fit_transform()\u4e00\u6b65\u5230\u4f4d\uff0c\u8fd4\u56de\u586b\u5145\u540e\u7684\u6570\u636e\n    new_data = impute_0.fit_transform(raw_data)\n\n    # \u7528\u65b0\u6570\u636e\u66ff\u6362\u539f\u6570\u636e\n    df0[columnName] = new_data\n    \n    return df0\n\n# \u75280\u586b\u5145val == target\ndef zero_replace_sp(df, columnName, target):\n    # \u75280\u586b\u5145\u5e74\u9f84\u7684\u7f3a\u5931\u503c\n    df0 = df.copy() # \u590d\u5236\u539f\u6570\u636e\uff0c\u907f\u514d\u539f\u6570\u636e\u88ab\u8986\u76d6\n    df0.loc[df0[columnName] == target, columnName] = 0\n    return df0\n\n# \u7528\u4e2d\u4f4d\u6570\u5904\u7406NaN\ndef median_replace(df, columnName):\n    df_median = df.copy()\n    impute_median = SimpleImputer(strategy='median')\n    raw_data = df_median[columnName].values.reshape(-1, 1)\n    new_data = impute_median.fit_transform(raw_data)\n    df_median[columnName] = new_data\n    return df_median\n\ndef standardlize(df, columnName):\n    data = df[columnName]\n    return (data-data.mean())\/(data.std()) \n\ndef manip_data(df):\n    df = df[~df[\"age\"].isin([0])]\n\n    # \u7528\u4e2d\u4f4d\u6570\u586b\u5145\u6708\u6536\u5165\n    df = median_replace(df, \"MonthlyIncome\")\n    # \u75280\u586b\u5145\u5bb6\u4eba\n    df = zero_replace(df, \"NumberOfDependents\")\n    \n    # \u75280\u586b\u5145\u6b20\u6b3e\u903e\u671f\u6b21\u6570\n    #  df = df[~df[\"NumberOfTimes90DaysLate\"].isin([96, 98])]\n    for col in (\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\"):\n        df = zero_replace_sp(df, col, 96)\n        df = zero_replace_sp(df, col, 98)\n    \n    #     df.drop(df[np.isnan(df['MonthlyIncome'])].index, inplace=True)\n    df[\"MonthlyIncome\"] = df[\"MonthlyIncome\"].apply(np.log1p)\n    \n    # log of RevolvingUtilizationOfUnsecuredLines\n    df[\"RevolvingUtilizationOfUnsecuredLines\"] = df[\"RevolvingUtilizationOfUnsecuredLines\"].apply(np.log1p)\n    \n    # \u5168\u90e8\u5f52\u4e00\u5316\n    for columnName in df.columns.tolist():\n        if columnName in (\"id\", \"SeriousDlqin2yrs\"):\n            continue\n        df[columnName] = standardlize(df, columnName)\n        \n    # \u589e\u52a0YoungAge\u4e0eOldAge\u4e24\u4e2a\u7279\u5f81\n    df['YoungAge'] = [1 if x < 21 else 0 for x in df['age']]\n    df['OldAge'] = [1 if x > 65 else 0 for x in df['age']]\n        \n    \n    return df","dff93399":"train_data = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/cs-training.csv\")\ntrain_data.columns = [\"id\"] + train_data.columns.tolist()[1:]\ntrain_data = manip_data(train_data)\n# train_data.fillna(0, inplace=True) # \u628a\u90e8\u5206\u5217\uff0c\u6bd4\u5982MonthlyIncome\u5217\u7684NaN\u6362\u4e3a0\ntrain_data.head(10)","63920cef":"selectedColumns = [\"RevolvingUtilizationOfUnsecuredLines\", \"age\", \"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\", \"NumberOfOpenCreditLinesAndLoans\", \"MonthlyIncome\", \"NumberRealEstateLoansOrLines\"]","1af878d2":"train_x = np.array(train_data[selectedColumns])\ntrain_y = np.array(train_data.SeriousDlqin2yrs)\ntrain_y=train_y.ravel()\ntrain_x","8723d7a0":"test_data = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/cs-test.csv\")\ntest_data.columns = [\"id\"] + test_data.columns.tolist()[1:]\ntest_data = manip_data(test_data)\ntest_data.fillna(0, inplace=True) # \u628aSeriousDlqin2yrs\u5217\u7684NaN\u66ff\u6362\u4e3a0\ntest_data.head(10)","ebcd21e4":"test_x = np.array(test_data[selectedColumns])\ntest_ans=pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/sampleEntry.csv\")\ntest_ans.head()","0bba7734":"test_y=np.array(test_ans.Probability)\ntest_y=test_y.ravel()","794a7e51":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.autograd import Variable\nimport torch.nn.functional as f\nimport matplotlib.pylab as plt\nimport torchvision.transforms as transforms\nuse_gpu = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_gpu else \"cpu\")","ebcf4235":"train_x=torch.from_numpy(train_x)\ntrain_y=torch.from_numpy(train_y)\ntest_x=torch.from_numpy(test_x)\ntest_y=torch.from_numpy(test_y)\nprint(train_x.shape)\nprint(train_y.shape)\nprint(test_x.shape)\nprint(test_y.shape)","902345fa":"if use_gpu:\n    train_x,train_y = Variable(train_x.cuda()).double(), Variable(train_y.cuda()).double()\n    test_x,teat_y = Variable(test_x.cuda()).double(),Variable(test_y.cuda()).double()\nelse:\n    train_x,train_y = Variable(train_x.cuda()).double(), Variable(train_y.cuda()).double()\n    test_x = Variable(test_x.cuda()).double()","918e324f":"class Net(torch.nn.Module):\n    def __init__(self, n_in, n_h1, n_h2, n_out):\n        super(Net, self).__init__()\n        self.fc = torch.nn.Sequential(\n            nn.Linear(n_in, n_h1),\n            nn.Tanh(),\n            nn.Linear(n_h1, n_h2),\n            nn.ReLU(),\n            nn.Linear(n_h2, n_out),\n        )\n    def forward(self, x):\n        return self.fc(x)\n    \n# net = Net(len(selectedColumns), 800, 400, 1)\nnet = Net(len(selectedColumns), 800, 50, 1)\nif use_gpu: \n    net = net.cuda()\nnet = net.double()","b7604952":"optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss_func = nn.MSELoss()\n\nnet.to(device)\ntrain_x,train_y = train_x.to(device),train_y.to(device)\ntest_x,test_y= test_x.to(device),test_y.to(device)","7496d7d5":"for epoch in range(10000):\n    train_prediction = net(train_x)\n    train_prediction = train_prediction.squeeze()\n    train_loss = loss_func(train_prediction, train_y)\n    optimizer.zero_grad()\n    train_loss.backward()\n    optimizer.step()\n    \n    if epoch%10==0:\n        test_prediction=net(test_x)\n        test_prediction = test_prediction.squeeze()\n        test_loss=loss_func(test_prediction,test_y)\n        print('[INFO] train_loss is %.4f'%train_loss.cpu().data.numpy())\n        print('[INFO] test_loss is %.4f'%test_loss.cpu().data.numpy())","9c86cf74":"# \u5b58\u50a8\u7ed3\u679c\ntest_prediction = net(test_x)\ntest_prediction = torch.clamp(test_prediction, min=0.0, max=1.0)","a1e69ea6":"if use_gpu:\n    output = pd.DataFrame({'Id': [int(x) for x in test_data.values[:,0].tolist()], 'Probability': test_prediction.cuda().data.cpu().numpy().ravel()})\nelse:\n    output = pd.DataFrame({'Id': [int(x) for x in test_data.values[:,0].tolist()], 'Probability': test_prediction})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0b0f3de3":"# Training with PyTorch","ec8a1086":"ANN\u7f51\u7edc","ac44fa84":"\u8fd0\u884c\u524d\u5148\u53bb\u53f3\u8fb9\u7684 `Settings` \u91cc\u9762\u5c06 `Accelerator` \u9009\u62e9\u4e3a `GPU`\uff01\n\n\u5426\u5219\u4f1a\u8fd0\u884c\u5f97\u6bd4\u8f83\u6162\u5e76\u4e14\u62a5\u9519\n\n\u4e0d\u8fd0\u884c\u7684\u65f6\u5019\u53ef\u4ee5\u5173\u4e86GPU\u8282\u7701\u514d\u8d39\u65f6\u95f4\uff08","dc92587a":"# \u6570\u636e\u6e05\u6d17\u4e0e\u4fee\u6539\n\n\u8be6\u60c5\u89c1GitHub\u4e0aipynbs\/visualization.ipynb\n\n\u5176\u4e2d\u6709\u8be6\u7ec6\u7684\u89e3\u91ca\u3002","2bdd7a18":"\u4e4b\u540e\u5c31\u662f\u63d0\u4ea4\u4e86\uff0c\u4e0d\u77e5\u9053\u600e\u4e48\u63d0\u4ea4\u7684\u8bdd\u8fd8\u662f\u95ee\u4e00\u4e0b\u5427\n\n\u4e0d\u592a\u597d\u63cf\u8ff0","f7958275":"# \u6570\u636e\u8bfb\u5165\n\n\u6211\u4eec\u5728\u8fd9\u91cc\u8fd8\u9700\u8981\u4f5c\u6570\u636e\u6e05\u6d17\u4e0e\u6570\u636e\u4fee\u6539"}}