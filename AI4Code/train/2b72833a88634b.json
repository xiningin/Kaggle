{"cell_type":{"2d9227d5":"code","2da1e5be":"code","882fa1b9":"code","413432e3":"code","f8493ece":"code","0c64b7b8":"code","b3d9d3aa":"code","53b20e38":"code","1754f6c7":"code","942482be":"code","f8374a91":"code","1cdbc7f7":"code","fc9e8c41":"code","4510b018":"code","88fb654b":"code","2430ca48":"code","0e4814fe":"code","f66731e5":"markdown"},"source":{"2d9227d5":"# Import required libraries\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2da1e5be":"# Loading training data\nraw_train_df = pd.read_csv('\/kaggle\/input\/fi-2020-q2-kaggle-competition\/train.csv')\n\n# Loading data for prediction\nraw_predict_df = pd.read_csv('\/kaggle\/input\/fi-2020-q2-kaggle-competition\/test.csv')\n","882fa1b9":"# Taking a copy of the imported data\ncleaned_train_df = raw_train_df.copy()\n\n# Adding 0.01 to amounts to avoid zeo values and taking log\ncleaned_train_df['Amount'] = np.log(cleaned_train_df['Amount'] + 0.01)\n\n# Same proecdure on data for prediction\ncleaned_test_df = raw_predict_df.copy()\ncleaned_test_df['Amount'] = np.log(cleaned_test_df['Amount'] + 0.01)","413432e3":"# Splitting data for training, validation and testing\ntrain_df, test_df = train_test_split(cleaned_train_df, test_size=0.2)\ntrain_df, validation_df = train_test_split(train_df, test_size=0.2)","f8493ece":"# Creating array of labels\ntrain_labels = np.array(train_df['Class'])\n\n# A logical array of training labels\ntrain_labels_bool = train_labels != 0\n\n# Labels for validation\nvalidation_labels = np.array(validation_df['Class'])\n\n# Labels for test\ntest_labels = np.array(test_df['Class'])","0c64b7b8":"# Extracting features\ntrain_features = np.array(train_df[train_df.columns[1:-1]])\nvalidation_features = np.array(validation_df[validation_df.columns[1:-1]])\ntest_features = np.array(test_df[test_df.columns[1:-1]])\n\n# Data structure for prediction data is different\npredict_features = np.array(cleaned_test_df[cleaned_test_df.columns[2:]])","b3d9d3aa":"# Standardizing numeric features\nscaler_obj = StandardScaler()\ntrain_features = scaler_obj.fit_transform(train_features)\nvalidation_features = scaler_obj.fit_transform(validation_features)\ntest_features = scaler_obj.fit_transform(test_features)\npredict_features = scaler_obj.fit_transform(predict_features)\n\n# Checking range of training data\nmax([max(train_features[i]) for i in range(train_features.shape[1])])\nmin([min(train_features[i]) for i in range(train_features.shape[1])])","53b20e38":"# Limiting the range of features to [-5, 5]\ntrain_features = np.clip(train_features, -5, 5)\nvalidation_features = np.clip(validation_features, -5, 5)\ntest_features = np.clip(test_features, -5, 5)\npredict_features = np.clip(predict_features, -5, 5)","1754f6c7":"# Helper function that generate model\ndef model_gen(dense_nodes=16, output_bias=None):\n    METRICS = [\n        keras.metrics.TruePositives(name='tp'),\n        keras.metrics.TrueNegatives(name='tn'),\n        keras.metrics.FalsePositives(name='fp'),\n        keras.metrics.FalseNegatives(name='fn'),\n        keras.metrics.BinaryAccuracy(name='accuracy'),\n        keras.metrics.Precision(name='precision'),\n        keras.metrics.Recall(name='recall'),\n        keras.metrics.AUC(name='auc')\n    ]\n\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n\n    model = keras.Sequential([\n        keras.layers.Dense(\n            dense_nodes,\n            activation='relu',\n            input_shape=(train_features.shape[-1],)\n        ),\n        keras.layers.Dropout(0.5),\n        keras.layers.Dense(\n            1,\n            activation='sigmoid',\n            bias_initializer=output_bias\n        ),\n    ])\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(lr=1e-3),\n        loss=keras.losses.BinaryCrossentropy(),\n        metrics=METRICS\n    )\n\n    return model","942482be":"# Helper for graphing model performance\ndef graph_model(model):\n    metrics = ['loss', 'auc', 'recall']\n    for i, metric in enumerate(metrics):\n        name = metric.replace(\"_\", \" \").capitalize()\n        plt.subplot(2,2, i+1)\n        plt.plot(\n            model.epoch,\n            model.history[metric],\n            label='Train'\n        )\n\n        plt.plot(\n            model.epoch,\n            model.history['val_'+metric],\n            linestyle=\"--\",\n            label='Val'\n        )\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        plt.legend()","f8374a91":"# Plot Confusion Matrix\ndef plot_cm(labels, predictions, p=0.5):\n    cm = confusion_matrix(labels, predictions > p)\n    plt.figure(figsize=(5, 5))\n    sns.heatmap(cm, annot=True, fmt='d')\n    plt.title(f\"Confusion Matrix @ %{p*100}\")\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"Actual Label\")\n\n    print(\n        f\"True Negatives: {cm[0][0]}\\n\"\n        f\"False Negatives: {cm[1][0]}\\n\"\n        f\"True Positives: {cm[1][1]}\\n\"\n        f\"False Positives: {cm[0][1]}\"\n    )\n\n    plt.show()","1cdbc7f7":"# Plot ROC curve\ndef plot_roc(name, labels, predictions):\n    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n\n    plt.plot(100*fp, 100*tp, label=name, linewidth=2)\n    plt.xlabel(\"False Positives (%)\")\n    plt.ylabel(\"True Positives (%)\")\n    plt.xlim([-0.5, 20])\n    plt.ylim([80, 100.5])\n    plt.grid(True)\n    ax = plt.gca()\n    ax.set_aspect('equal')","fc9e8c41":"# Helper function that return tf dataset\ndef make_ds(features, labels, buffer_size=100000):\n    ds = tf.data.Dataset.from_tensor_slices((features, labels))\n    ds = ds.shuffle(buffer_size).repeat()\n    return ds\n","4510b018":"# Helper function to over sample positive values, we do 50\/50 on positive\/negative records\ndef resample_ds():\n    pos_features = train_features[train_labels_bool]\n    neg_features = train_features[~train_labels_bool]\n\n    pos_labels = train_labels[train_labels_bool]\n    neg_labels = train_labels[~train_labels_bool]\n\n    pos_ds = make_ds(pos_features, pos_labels)\n    neg_ds = make_ds(neg_features, neg_labels)\n\n    resampled_ds = tf.data.experimental.sample_from_datasets(\n        [pos_ds, neg_ds],\n        weights=[0.5, 0.5]\n    )\n    resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(1)\n    steps = np.ceil(len(neg_labels)\/BATCH_SIZE)\n    return resampled_ds, steps","88fb654b":"# Early stopper to avoid overfitting\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_auc',\n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True\n)\n\n# Setting parameters\nBATCH_SIZE = 2048\nEPOCH = 100\nNODES = 24","2430ca48":"# Using helper function to resample training data\nresambled_ds, steps = resample_ds()\n\n# Creating the model\nresample_model = model_gen()\n\n# Creating datasets for validation\nval_ds = tf.data.Dataset.from_tensor_slices((validation_features, validation_labels)).cache()\nval_ds = val_ds.batch(BATCH_SIZE).prefetch(1)\n\n# Training the model\nresample_history = resample_model.fit(\n    resambled_ds,\n    epochs=EPOCH,\n    steps_per_epoch=steps,\n    callbacks=[early_stopping],\n    validation_data=val_ds\n)\n\n# Generating predictions on train\/test data\ntrain_predict = resample_model.predict(train_features, batch_size=BATCH_SIZE)\ntest_predict = resample_model.predict(test_features, batch_size=BATCH_SIZE)\n\n\n# Plotting ROC and CM\nplot_roc(\"Train\", train_labels, train_predict)\nplot_roc(\"Test\", test_labels, test_predict)\nplt.show()\nplot_cm(train_labels, train_predict, p=0.6)","0e4814fe":"# Generating predictions\noutput_prediction = resample_model.predict(predict_features, batch_size=BATCH_SIZE)\n\n# Setting threshold to categorize records\nTHRESHOLD = 0.8\n\npredicted = [1 if x[0] > THRESHOLD else 0 for x in output_prediction.tolist()]\noutput = pd.DataFrame({\n    'id': cleaned_test_df['Id'],\n    'Predicted': predicted\n})\n\noutput.to_csv('submission.csv', index=False)\n","f66731e5":"I followed the [training](https:\/\/www.tensorflow.org\/tutorials\/structured_data\/imbalanced_data) offered by TensorFlow on uing NN on unbalanced data for this work."}}