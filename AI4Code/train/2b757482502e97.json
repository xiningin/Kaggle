{"cell_type":{"64342216":"code","77e770f3":"code","62fee83f":"code","9ddf9619":"code","e62a8ebc":"code","8552a56b":"code","fa4aded7":"code","add0118c":"code","078e4e0c":"code","070719dc":"code","60c624f0":"code","91268b82":"code","5c98c254":"code","0d3d24cc":"code","11397f60":"code","24638e75":"code","df0c54e2":"code","7aa4c90e":"code","1854677e":"code","037ec92c":"code","af274168":"code","009157c8":"code","972b1087":"code","cc7037d4":"code","7ebb9b5f":"code","f52eab26":"code","6c0ba8da":"code","33a4eb4b":"code","9202b263":"code","dff803a1":"code","7b9cecd7":"code","b0795bb9":"code","056a1aab":"code","89f8161e":"code","8ada882c":"code","9cee019f":"code","37587c0b":"code","261782b4":"code","481753fe":"code","b6db7344":"code","55bf7733":"code","70429ed3":"code","7d7595b9":"code","f1d92aaa":"code","d4f51c32":"code","1b1ce1c2":"code","0f75d2e9":"code","3ee35e84":"code","e02b3045":"code","d54318e8":"code","d13f7fa8":"code","f64ff3e4":"code","262452f7":"code","8d760697":"code","940c371a":"code","233c3b06":"code","302b5d7e":"code","52957f03":"code","b38b263e":"code","c6b8a718":"code","574c1713":"code","84746339":"code","19373a36":"code","9155fbc0":"code","9d4d6236":"code","fba92a02":"code","f353909c":"code","77584033":"code","b828dbc0":"code","19107da0":"code","0b4bf7e9":"code","40052cd7":"code","80c542fa":"code","8a2366e9":"code","d7db3f38":"code","4e7985b3":"code","022173c3":"code","e1261547":"code","57310e7c":"code","82feef63":"code","fc07ce40":"code","dbf4cf11":"code","d6e3ccdb":"code","13735ea1":"code","e4f923a8":"code","0bcb6dc0":"code","d6abe0ea":"code","18f034b4":"code","8df89dbe":"markdown","50eeec24":"markdown","3d078032":"markdown","6368a4e6":"markdown","4b80034f":"markdown","bbb2da8d":"markdown","d68bbf61":"markdown","5bf1ac3b":"markdown","9b21e2fb":"markdown","91ced049":"markdown","918b2c6b":"markdown","9767bc6c":"markdown","077d52b1":"markdown","1b8bd66a":"markdown","0fd82ea2":"markdown","719f7b7a":"markdown","7e31a11c":"markdown","c6031faf":"markdown","2f5ddd2d":"markdown","804a4056":"markdown","4a60969e":"markdown","3bddac21":"markdown","90224604":"markdown","10165638":"markdown","da1e3f9d":"markdown","2a8e2967":"markdown","fe1549c2":"markdown","90623f2d":"markdown","b9b04035":"markdown","cf808c24":"markdown","66203380":"markdown","85ab1d0d":"markdown","1d5b51a0":"markdown","0a121410":"markdown","c9f1043e":"markdown","4f2913b4":"markdown","07ae19c6":"markdown","718a0db3":"markdown","73d72256":"markdown","d350f2ab":"markdown","4ecf0837":"markdown","c9bbee3c":"markdown","ef81c9ec":"markdown","2eb3a5a3":"markdown","ac359872":"markdown","aaa5bf6d":"markdown","30af6e4a":"markdown","0694d1e7":"markdown","1dcb81ce":"markdown","c5ae6efb":"markdown","e8260109":"markdown"},"source":{"64342216":"from configparser import ConfigParser, ExtendedInterpolation\nfrom collections import defaultdict\nfrom itertools import combinations, product\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport gensim\nfrom gensim import corpora, models, similarities\nfrom gensim.corpora import Dictionary\nfrom gensim.matutils import kullback_leibler, hellinger\nfrom gensim.models import ldamodel\nfrom gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity, Similarity\nfrom gensim.summarization.bm25 import get_bm25_weights\nfrom gensim.utils import simple_preprocess\nfrom IPython.core.display import display, HTML\nfrom IPython.display import Image\nfrom IPython.lib.display import YouTubeVideo\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom spacy.matcher import Matcher\nfrom sklearn.metrics.pairwise import pairwise_distances\nfrom sklearn.neighbors import NearestNeighbors\nimport spacy\n\n# increase display of columns in pandas\npd.set_option('display.max_colwidth', 200)","77e770f3":"CLEANED_TEXT_PATH ='..\/input\/data-input\/data_immunity.csv'\nSIMILARITY_INDEX = 'pubmed.index'","62fee83f":"# configuration for data, acronyms, and gensim paths\nconfig = ConfigParser(interpolation=ExtendedInterpolation())\nconfig.read('..\/..\/config.ini')\n\nGENSIM_DICTIONARY_PATH = config['NLP']['GENSIM_DICTIONARY_PATH']\nGENSIM_CORPUS_PATH = config['NLP']['GENSIM_CORPUS_PATH']\nCLEANED_TEXT_PATH = config['NLP']['CLEANED_TEXT_PATH']\nSIMILARITY_INDEX = config['NLP']['SIMILARITY_INDEX']\nSAVED_EMBEDDINGS_PATH = config['EMBEDDINGS']['SAVED_EMBEDDINGS_PATH']\nREPORTER_ZIP_PATH = config['EMBEDDINGS']['REPORTER_ZIP_PATH']","9ddf9619":"cleaned_text_df = pd.read_csv(CLEANED_TEXT_PATH, sep='\\t',header=None,names=['text'])\ncleaned_text = cleaned_text_df.text.values\ncleaned_text_df.head()","e62a8ebc":"# # text similarity approaches\n# # SOURCE: https:\/\/pdfs.semanticscholar.org\/5b5c\/a878c534aee3882a038ef9e82f46e102131b.pdf\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/text_similarity_approaches.png\", width=350)","8552a56b":"seq1 = 'medicine'\nseq2 = 'medical'\n\n# create a matrix\nsize_x = len(seq1) + 1\nsize_y = len(seq2) + 1\nmatrix = np.zeros ((size_x, size_y))\nmatrix","fa4aded7":"# set col numbers (0, n-1)\nfor x in range(size_x):\n    matrix [x, 0] = x\n\n# set row numbers (0, n-1)\nfor y in range(size_y):\n    matrix [0, y] = y\n\nmatrix","add0118c":"import numpy as np\n\ndef levenshtein(seq1, seq2):\n    # create a matrix\n    size_x = len(seq1) + 1\n    size_y = len(seq2) + 1\n    matrix = np.zeros ((size_x, size_y))\n    \n    # set col numbers (0, n-1)\n    for x in range(size_x):\n        matrix [x, 0] = x\n    \n    # set row numbers (0, n-1)\n    for y in range(size_y):\n        matrix [0, y] = y\n\n    # calculate distance\n    for x in range(1, size_x):\n        for y in range(1, size_y):\n            # if characters match do not increase distance\n            if seq1[x-1] == seq2[y-1]:\n                matrix [x,y] = matrix[x-1, y-1]\n            # if characters don't match increase min distance by 1\n            else:\n                matrix [x,y] = min(\n                    matrix[x-1,y] + 1,\n                    matrix[x-1,y-1] + 1,\n                    matrix[x,y-1] + 1\n                )\n\n    # print the distance calulation matrix\n    # list(seq1) converts string into a list of the characters\n    print(pd.DataFrame(matrix[1:,1:], index=list(seq1), columns=list(seq2)))\n    \n    return (matrix[size_x - 1, size_y - 1])\n\nlevenshtein('medicine','medical')","078e4e0c":"from IPython.lib.display import YouTubeVideo\nYouTubeVideo('We3YDTzNXEk')","070719dc":"# create a document-term matrix for the first 10 documents\nvect = CountVectorizer(max_features=10)\ntransform_vect = vect.fit_transform(cleaned_text_df['text'][0:10])\n\n# rename the indices as doc_#\nindex = ['doc_{}'.format(i) for i in range(10)]\n\n# create a dataframe\ndist_df = pd.DataFrame(\n      transform_vect.todense()\n    , columns=vect.get_feature_names()\n    , index=index\n)\n\n# view two docs\ndist_df.loc[['doc_1','doc_7'],:]","60c624f0":"# # Similarity via the Jaccard Index\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/jaccard_index.png\", width=450)","91268b82":"# calculate the distance among different vectors\n#\n# NOTE: if both counts are zero, then the term in not counted in the denominator\n#       as the term is outside of the union of both term sets\n\nfrom sklearn.metrics.pairwise import pairwise_distances\n\n# calculate jaccard distance on all documents\njaccard = pairwise_distances(dist_df.values, metric='jaccard')","5c98c254":"sns.heatmap(pairwise_distances(dist_df.values, Y=None, metric='jaccard'));","0d3d24cc":"for doc_ind in range(0,5):\n    print('jaccard distance {}'.format(jaccard[0][doc_ind])) # focus on the first doc (index 0)\n    print(dist_df.iloc[[0, doc_ind], :], '\\n\\n')  # print the first doc and the comparison document","11397f60":"# the geometric equation of the dot product\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/euclidean_distance.jpg\", width=300)","24638e75":"def euclidean_distance(x, y):   \n    return np.sqrt(np.sum((x - y) ** 2))","df0c54e2":"# 3-4-5 triangle\np1 = np.array([0,0])\np2 = np.array([3,4])\neuclidean_distance(x=p1, y=p2)","7aa4c90e":"# 0-3, 0-4\np1 - p2","1854677e":"# -3^2, -4^2\n(p1 - p2) ** 2","037ec92c":"# 9 + 16\nnp.sum((p1 - p2) ** 2)","af274168":"# sqrt(25)\nnp.sqrt(np.sum((p1 - p2) ** 2))","009157c8":"# example from above diagram\np1 = np.array([5,11])\np2 = np.array([12,14])\neuclidean_distance(x=p1, y=p2)","972b1087":"# euclidean distance scales beyond 2-D\np1 = np.array([0,0,0])\np2 = np.array([3,3,3])\neuclidean_distance(x=p1, y=p2)","cc7037d4":"# the distance between a vect and itself is 0\neuclid_df = dist_df \neuclidean_distance(euclid_df.iloc[0], euclid_df.iloc[0])","7ebb9b5f":"# calculate the distance among different vectors\nfor doc_ind in range(1,8):\n    print(euclidean_distance(euclid_df.iloc[0], euclid_df.iloc[doc_ind]))","f52eab26":"print(pairwise_distances(euclid_df, Y=None, metric='euclidean')[0])\nsns.heatmap(pairwise_distances(euclid_df, Y=None, metric='euclidean'));","6c0ba8da":"# example dot product calculation\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/dot_product_calculation.png\", width=200)","33a4eb4b":"# dot product equation\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/dot_product.png\", width=500)","9202b263":"# the geometric equation of the dot product\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/normalization.png\", width=800)","dff803a1":"# the geometric equation of the dot product\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/normalization_example.png\", width=800)","7b9cecd7":"norm_url = 'https:\/\/rorasa.wordpress.com\/2012\/05\/13\/l0-norm-l1-norm-l2-norm-l-infinity-norm\/'\niframe = '<iframe src={} width=1100 height=300><\/iframe>'.format(norm_url)\nHTML(iframe)","b0795bb9":"# the geometric equation of the dot product\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/geometric_dot_product.png\", width=200)","056a1aab":"# cosine similarity equation\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/cosine_similarity.png\", width=200)","89f8161e":"# cosine similarity angles\n# 1 = perfect match\n# 0 = dissimilar documents\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/cosine_similarity_angles.png\", width=1200)","8ada882c":"cosine_url = 'http:\/\/blog.christianperone.com\/2013\/09\/machine-learning-cosine-similarity-for-vector-space-models-part-iii\/'\niframe = '<iframe src={} width=950 height=300><\/iframe>'.format(cosine_url)\nHTML(iframe)","9cee019f":"# view the tfidf scores\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# create tfidf matrix\ndf = pd.DataFrame(cleaned_text[0:5], columns=['text'])\nvect = TfidfVectorizer(max_features=15)\ntransform_vect = vect.fit_transform(df['text'])\npd.DataFrame(transform_vect.toarray(), columns=vect.get_feature_names())","37587c0b":"# reduce the dimensions using SVD\nfrom sklearn.decomposition import TruncatedSVD\n\n# reduce dimensions of tfidf matrix\nsvd = TruncatedSVD(n_components=2)\nsvd_tranform = svd.fit_transform(transform_vect)\nprint(svd_tranform)","261782b4":"from sklearn.neighbors import NearestNeighbors","481753fe":"# EXAMPLE\n\n# sample data\nX = [[1,1], [1,2], [1,3], [1,4], [1,5]]\n\n# calculate cosine distance\nnn = NearestNeighbors(metric='cosine')\nnn.fit(X)\n\n# build a graph of the nearest neighbors using cosine distance\nnn_graph = nn.kneighbors_graph(n_neighbors=4, mode='distance').toarray()\npd.DataFrame(nn_graph)","b6db7344":"# calculate cosine distance\ncosine_neighbors = NearestNeighbors(metric='cosine')\ncosine_neighbors.fit(svd_tranform)","55bf7733":"# build a graph of the nearest neighbors using cosine distance\nind = ['doc{}'.format(i) for i in range(1,6)]\ngraph = cosine_neighbors.kneighbors_graph(n_neighbors=2, mode='distance').toarray()\npd.DataFrame(graph, columns=ind, index=ind)","70429ed3":"# weighted cosine similarity\n# Image(\"https:\/\/s3.amazonaws.com\/nlp.practicum\/weighted_cosine_similarity.png\", width=400)","7d7595b9":"cleaned_text","f1d92aaa":"# convert sentences into list of tokens to format data for gensim\ntexts = [text.split() for text in cleaned_text]\nprint(texts[0])","d4f51c32":"# turn our tokenized documents into a id <-> term dictionary\ndictionary = corpora.Dictionary(texts)\n\n# filter the dictionary to remove infrequent (no_below) and too frequent (no_above) terminology\ndictionary.filter_extremes(no_below=.01, no_above=0.99)\n\nprint(dictionary)","1b1ce1c2":"# create bag of words (e.g. countvectorizer)\nbow_corpus = [dictionary.doc2bow(sent) for sent in texts]\n\n# create tfidf model (e.g. tfidf.fit )\ntfidf = models.TfidfModel(bow_corpus)\n\n# convert bow to tfidf (e.g. tfidf.transform)\ntfidf_corpus = tfidf[bow_corpus] \n\n# view the first transformed sentence\nprint(tfidf_corpus[0])","0f75d2e9":"# create an lsi model (e.g. truncatedsvd.fit)\n# corpus = data to fit model\n# id2word = corpus stores words with numeric ids, this dict maps ids back to the original terms\nlsi = models.LsiModel(corpus=tfidf_corpus, id2word=dictionary, num_topics=20)\nprint(lsi)","3ee35e84":"# convert the tfidf corpus to lsi (e.g. truncatedsvd.transform)\nlsi_corpus = lsi[tfidf_corpus]\nprint(lsi_corpus[0])","e02b3045":"from gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity, Similarity\n\n# transform corpus to LSI space and index it\n# output_prefix - local file to write index (required to enable later additions to the index)\n# corpus - data to fit model\n# num_features - often the num_terms in the corpus\n\nindex = Similarity(\n      output_prefix='lsi.mm'\n    , corpus=lsi_corpus\n    , num_features=lsi.num_terms\n    , shardsize=32768\n)","d54318e8":"index.save(SIMILARITY_INDEX)\n!ls","d13f7fa8":"index = Similarity.load(SIMILARITY_INDEX)\nprint(index)","f64ff3e4":"# tokenize a query string\nquery = \"stimulator of beta_adrenergic structure in treatment_of_ischemic heart_disease\".split()\nprint(query, '\\n')\n\n# convert to bag of words\nvec_bow = dictionary.doc2bow(query)\n\n# convert bow to tfidf\ntfidf_bow = tfidf[vec_bow] \n\n# convert tfidf to LSI space to prepare for similarity query\nvec_lsi = lsi[tfidf_bow]\n\nprint(vec_lsi)","262452f7":"# set the number of matches to return (sorted by most relevant)\nindex.num_best = 10\n\n# perform a similarity query against the index (similarity index of training docs)\nsims = index[vec_lsi]\n\nprint('num docs: {}'.format(len(sims)))\nsims","8d760697":"# NOTE: we add the same documents to the index twice, so the returned sims number may be out of range \n# for the original texts (if so just divide the index by two before slicing texts)\nprint(texts[(2291)])","940c371a":"# add documents to a existing Similarity index (e.g. useful for big data and streaming)\n\nprint(index)  # before\nindex.add_documents(lsi_corpus)\nprint(index)  # after","233c3b06":"from gensim.summarization.bm25 import get_bm25_weights","302b5d7e":"%%time\n\nscores = get_bm25_weights(bow_corpus[0:10])\nprint(scores[0])","52957f03":"bm25_df = pd.DataFrame(scores).T\nbm25_df['text'] = cleaned_text[0:10]\nbm25_df.head()","b38b263e":"!python -m spacy download en_core_web_lg","c6b8a718":"import en_core_web_lg\nnlp = en_core_web_lg.load()","574c1713":"from itertools import combinations\n\ndoc1 = nlp(u\"Paris is the largest city in France.\")\ndoc2 = nlp(u\"Vilnius is the capital of Lithuania.\")\ndoc3 = nlp(u\"An emu is a large bird.\")\ndoc4 = nlp(u\"seagulls flying by the beach\")\n\ndoc_combos = list(combinations([doc1, doc2, doc3, doc4], r=2))\ndoc_combos","84746339":"for doc, other_doc in doc_combos:\n    print(doc)\n    print(other_doc)\n    print(doc.similarity(other_doc), '\\n')","19373a36":"# Cartesian product of input iterables.  Equivalent to nested for-loops.\nfrom itertools import product","9155fbc0":"list(product([['sentence1'],['sentence2'],['sentence3']], repeat=2))","9d4d6236":"def create_similarity_matrix(texts, size, labels=None, viz=True):\n    \"\"\" build a heatmap of similarity scores \"\"\"\n\n    # create a heatmap of similarities by iterating through each term \n    # and calculating its similarity to every other term\n    # similarity is determined by comparing word vectors or \"word embeddings\"\n    matrix = [t1.similarity(t2) for t1, t2 in product(texts, repeat=2)]\n    \n    # remove bottom half of matrix (i.e. duplicate data)\n    matrix = np.array(matrix).reshape(size,size)    \n    matrix = np.triu(matrix)\n    \n    # transform similarity scores into a dataframe\n    if labels is None:\n        labels = [term for term in texts]\n    df = pd.DataFrame(matrix, columns=labels, index=labels)\n    \n    # create a heat map of the similarity scores\n    if viz:\n        sns.set(rc={'figure.figsize':(10,8)})\n        sns.heatmap(df.values)\n    \n    return df","fba92a02":"#sns.set(rc={'figure.figsize':(12,10)})\ncreate_similarity_matrix(\n      nlp(cleaned_text[0])\n    , size=len(cleaned_text[0].split())\n)","f353909c":"from itertools import combinations","77584033":"list(combinations([['sentence1'],['sentence2'],['sentence3']], r=2))","b828dbc0":"%%time\n\n# use set to avoid looking at the similarity of dupliate sentences\ndocs = [nlp(sentence) for sentence in set(cleaned_text[0:1000])]","19107da0":"%%time\n\n# compare the similarity of all sentences against each other\nsimilarity_scores = []\nfor doc1, doc2 in combinations(docs, r=2):\n    sentences_are_different = doc1.text != doc2.text\n    if sentences_are_different:\n        similarity_scores.append([doc1.text, doc2.text, doc1.similarity(doc2)])\n\n# view the top most similar sentences\n# drop sentences with greater than .99 similarity as these are often duplicates\ndf = pd.DataFrame(similarity_scores, columns=['doc1','doc2','similarity'])\ndf[df.similarity < .97].sort_values('similarity', ascending=False).head(10)","0b4bf7e9":"import gensim.downloader as api\nword_vectors = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data","40052cd7":"# Word Mover's Distance\n\n# example sentences\nsentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\nsentence_president = 'The president greets the press in Chicago'.lower().split()\n\n# Compute WMD.\ndistance = word_vectors.wv.wmdistance(document1=sentence_obama, document2=sentence_president)\ndistance","80c542fa":"doc1.text","8a2366e9":"%%time\n\n# compare the similarity of all sentences against each other\nsimilarity_scores = []\nfor doc1, doc2 in combinations(docs, r=2):\n    sentences_are_different = doc1.text != doc2.text\n    if sentences_are_different:\n        wmd = word_vectors.wv.wmdistance(\n            document1=simple_preprocess(doc1.text)\n          , document2=simple_preprocess(doc2.text)\n        )\n        similarity_scores.append([doc1.text, doc2.text, wmd])","d7db3f38":"df = pd.DataFrame(similarity_scores, columns=['doc1','doc2','word_movers_distance'])\ndf = df[df.word_movers_distance != np.inf]\ndf.sort_values('word_movers_distance', ascending=True).head(10)","4e7985b3":"from gensim.utils import simple_preprocess\nfrom gensim.matutils import kullback_leibler, hellinger","022173c3":"# view the first document\ncleaned_text_df['text'][1]","e1261547":"# use gensim to preprocess the document\nprint(simple_preprocess(cleaned_text_df['text'][1]))","57310e7c":"# preprocess all documents\nclean_text = [simple_preprocess(text) for text in cleaned_text_df['text']]\n\n# build bag of words\ndictionary = Dictionary(clean_text)\ncorpus = [dictionary.doc2bow(text) for text in clean_text]\n\n# create LDA model\nmodel = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=3)","82feef63":"# create a bag of words for select documents\ndoc1 = model.id2word.doc2bow(simple_preprocess('abdominal pain persisted throughout treatment'))\ndoc2 = model.id2word.doc2bow(simple_preprocess('the patient had stomach discomfort'))\ndoc3 = model.id2word.doc2bow(simple_preprocess('the president greets the press in chicago'))\n\n# we can now get the LDA topic distributions for these documents\ndoc1_dist = model[doc1] \ndoc2_dist = model[doc2] \ndoc3_dist = model[doc3] \n\n# view results\nprint('doc1_dist: {}'.format(doc1_dist))\nprint('doc2_dist: {}'.format(doc2_dist))\nprint('doc3_dist: {}'.format(doc3_dist))","fc07ce40":"kullback_leibler(doc1_dist, doc2_dist)","dbf4cf11":"kullback_leibler(doc1_dist, doc3_dist)","d6e3ccdb":"hellinger(doc1_dist, doc2_dist)","13735ea1":"hellinger(doc1_dist, doc3_dist)","e4f923a8":"# file names for lesson\nNIH_EXPORTER_CSV = r'https:\/\/exporter.nih.gov\/CSVs\/final\/RePORTER_PRJ_C_FY2019_042.zip'\ncols = ['PROJECT_TITLE']\nreporter = pd.read_csv(NIH_EXPORTER_CSV, encoding='latin-1', usecols=cols)\n\n# remove duplicates\nreporter = reporter[~reporter.PROJECT_TITLE.duplicated()]\n\nreporter.shape","0bcb6dc0":"# vectorize the text\nvect = TfidfVectorizer(min_df=.01, max_df=.95, norm='l2', stop_words='english', max_features=1000, ngram_range=(1,2))\ntitles_vect = vect.fit_transform(reporter['PROJECT_TITLE'])","d6abe0ea":"%%time\n\n# cluster the document using KMeans\n\n# step 1 - import the model\nfrom sklearn.cluster import KMeans\n\n# step 2 - instantiate the model\nkm = KMeans(n_clusters=100, random_state=42)\n\n# step 3 - fit the model with data\n# clustering is unsupervised so we do not have labels to add during .fit()\nkm.fit(titles_vect)\n\n# step 4 - predict the cluster of each section_title\nreporter['clusters'] = km.predict(titles_vect)","18f034b4":"def review_clusters(df, n_clusters):\n    for cl_num in range(n_clusters):\n        print(cl_num)\n        print(reporter[df.clusters == cl_num]['PROJECT_TITLE'].values[0:10])\n        print()\n\nreview_clusters(reporter, n_clusters=100)","8df89dbe":"### Text Similarity Approaches","50eeec24":"The CountVectorizer output of the two documents show the word count, where the vectors do not overlap for any words. Thus the dot product is zero.","3d078032":"### BM25 (Best Match)\n\n- [bm25 gensim source code](https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/summarization\/bm25.py)","6368a4e6":"### Euclidean Distance","4b80034f":"##### Sentence Similarity using the full dataset","bbb2da8d":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/cosine_similarity_angles.png)","d68bbf61":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/normalization.png)","5bf1ac3b":"##### Document Similarity","9b21e2fb":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/text_similarity_approaches.png)","91ced049":"### Word Movers Distance\n\nINSTALLATION: conda install -c conda-forge pyemd \n\nFrom Word Embeddings To Document Distances Abstract: http:\/\/proceedings.mlr.press\/v37\/kusnerb15.pdf","918b2c6b":"##  Similarity with gensim (generate similarity)","9767bc6c":"<a href=\"https:\/\/colab.research.google.com\/github\/Alexjmsherman\/nlp_practicum_cohort3_instructor\/blob\/master\/lessons\/lesson_8_text_similarity\/text_similarity_solution.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","077d52b1":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/euclidean_distance.jpg)","1b8bd66a":"##### Hellinger distance\n\nThe Hellinger distance metric gives an output in the range [0,1] for two probability distributions, with values closer to 0 meaning they are more similar.\n\nSOURCE: https:\/\/en.wikipedia.org\/wiki\/Hellinger_distance","0fd82ea2":"### Similarity Query","719f7b7a":"### Similarity\n\nspaCy is able to compare two objects, and make a prediction of how similar they are. Predicting similarity is useful for building recommendation systems or flagging duplicates. For example, you can suggest a user content that's similar to what they're currently looking at, or label a support ticket as a duplicate if it's very similar to an already existing one.","7e31a11c":"### Cosine Similarity","c6031faf":"### Jaccard Index\n\n\"The Jaccard Index is a statistic to compare and measure how similar two different sets to each other. It is a ratio of intersection of two sets over union of them.\n\nIf you have representative finite number of elements for a particular observation and you want to compare this observation with another observation, you could count the number of items that are common to both of these two sets. It is a natural fit for comparing posts if you know the representative tags for the posts to measure how similar two articles are in terms of tags.\"\n\nSOURCE: http:\/\/bugra.github.io\/work\/notes\/2017-02-07\/similarity-via-jaccard-index\/","2f5ddd2d":"##### Great Explanation of Entropy, Cross-Entropy, and KL-Divergence\n\n[A Short Introduction to Entropy, Cross-Entropy and KL-Divergence](https:\/\/www.youtube.com\/watch?v=ErfnhcEV1O8)","804a4056":"##### Kullback Leibler Divergence\n\nKullback-Leibler returns a value in range [0, +\u221e) where values closer to 0 mean less distance (higher similarity).\n\nThe KL divergence is a measure of how much \u201cpredictive power\u201d or \u201cevidence\u201d each sample will on average bring when you\u2019re trying to distinguish p(x) from q(x), if you\u2019re sampling from p(x). If p(x) and q(x) are very similar then each individual sample will bring little \u201cevidence\u201d to the table. On the other hand, if p(x) and q(x) are very different then each sample will bring a lot of evidence showcasing that q(x) is not a good representation of p(x).\n\nIn practice you\u2019re often in situations where you want to build a model that\u2019s as close as possible to the \u201ctrue\u201d model. In that case, you would like it to be as difficult as possible to distinguish the model you built from the real one, especially for samples that have been sampled from the real model.\n\nSOURCE: https:\/\/medium.com\/@cotra.marko\/making-sense-of-the-kullback-leibler-kl-divergence-b0d57ee10e0a","4a60969e":"## Similarity with SpaCy","3bddac21":"### Problems with Cosine Distance\nCosine Distance does not require exact matches. Unfortunately, the bag-of-words approach implies a word order independence that can overstate document similarity. The sentences ***\u201cI am not a crook\u201d** versus **\u201cAm I not a crook?\u201d** would receive a perfect cosine similarity score of 1, despite their intentions being entirely different\n\n### Additional Material - Weighted Cosine Similarity\n\nWeighted cosine similarity measure: iteratively computes the cosine distance between two documents, but at each iteration the vocabulary is defined by n-grams of different lengths. \n\nThe weighted similarity measure gives a single similarity score, but is built from the cosine similarity between two documents taken at several levels of coarseness. Put simply, we tokenize the two documents with unigrams, compute the cosine similarity between them, and then retokenize the documents with bigrams and again compute the similarity. We repeat this process until we reach our user-defined maximum n-gram length. The resulting set of scores is then combined as a weighted average, where heavier weights are given to the similarity scores between word frequency vectors from the higher n-gram lengths. \n\nLike the basic cosine similarity score, the weighted version varies from 0 to 1. the weighted cosine approach can capture pairs of documents where one copies but edits another. Since this is often the case in copied legislation, judicial decisions or regulations, we expect the weighted cosine similarity score to potentially better represent the similarity between technical documents\n\n\nSOURCE:\n- [Comparing and Evaluating Cosine Similarity Scores,\nWeighted Cosine Similarity Scores, & Substring\nMatching](http:\/\/hansen.web.unc.edu\/files\/2014\/12\/AHJS_Weighted_Cosine.pdf)","90224604":"##### Build a recommendation engine with cosine similarity","10165638":"##### The Levenshtein Distance\n\n\"This method was invented in 1965 by the Russian Mathematician Vladimir Levenshtein (1935-2017). The distance value describes the minimal number of deletions, insertions, or substitutions that are required to transform one string (the source) into another (the target). Unlike the Hamming distance, the Levenshtein distance works on strings with an unequal length.\"\n\nSOURCE: [Levenshtein Distance and Text Similarity in Python](http:\/\/stackabuse.com\/levenshtein-distance-and-text-similarity-in-python\/)","da1e3f9d":"### Agenda:\n\n- Levenshtein distance\n- Jaccard distance\n- Euclidean distance\n- Cosine similarity\n- Similarity with [sklearn, gensim, spacy]\n- Similarity with word embeddings (Word2vec similarity, Word movers distance)\n- Similarity of Probability Distributions (Cross entropy, KL Divergence, Hellinger distance)\n- Nearest-neighbors search\n- Clustering","2a8e2967":"# Similarity of Probability Distributions","fe1549c2":"# Similarity with sklearn\n\n### tfidf -> lsi -> cosine similarity (sklearn)","90623f2d":"The similarity in vector space models is determined by using associative coefficients based on the inner product of the document vector and query vector, where word overlap indicates similarity. The inner product is usually normalized. The most popular similarity measure is the cosine coefficient, which measures the angle between a document vector and the query vector.\n\nThink about it this way. In the numerator of cosine similarity, only terms that exist in both documents contribute to the dot product. If both of the term have high tfidf values, then they add a lot to the numerator. If a term does not exist in either documents, then it adds nothing to the numerator. On the other hand, the deonominator normalizes the documents, so that a document with many terms is punished with a larger denominator. \n\n\nSOURCE: http:\/\/cogsys.imm.dtu.dk\/thor\/projects\/multimedia\/textmining\/node5.html","b9b04035":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/normalization_example.png)","cf808c24":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/cosine_similarity.png)","66203380":"## Term Based Text Similarity","85ab1d0d":"### Word2Vec Similarity Examples:\n\nSOURCE: https:\/\/quomodocumque.wordpress.com\/2016\/01\/15\/messing-around-with-word2vec\/","1d5b51a0":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/weighted_cosine_similarity.png)","0a121410":"### The Norm","c9f1043e":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/dot_product_calculation.png)","4f2913b4":"### Similarities in context\n\nAside from spaCy's built-in word vectors, which were trained on a lot of text with a wide vocabulary, the parsing, tagging and NER models also rely on vector representations of the meanings of words in context. As the processing pipeline is applied spaCy encodes a document's internal meaning representations as an array of floats, also called a tensor. This allows spaCy to make a reasonable guess at a word's meaning, based on its surrounding words. Even if a word hasn't been seen before, spaCy will know something about it. Because spaCy uses a 4-layer convolutional network, the tensors are sensitive to up to four words on either side of a word.","07ae19c6":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/jaccard_index.png)","718a0db3":"## Character Based Text Similarity\n\n\"As an example, this technology is used by information retrieval systems, search engines, automatic indexing systems, text summarizers, categorization systems, plagiarism checkers, speech recognition, rating systems, DNA analysis, and profiling algorithms (IR\/AI programs to automatically link data between people and what they do).\"","73d72256":"##### bow -> tfidf -> lsi in gensim ","d350f2ab":"##### cosine similarity\nThe cosine similarity between two vectors (or two documents on the Vector Space) is a measure that calculates the cosine of the angle between them. This metric is a measurement of orientation and not magnitude, it can be seen as a comparison between documents on a normalized space because we\u2019re not only taking into the consideration the magnitude of each word count (tf-idf) of each document, but also the angle between the documents. What we have to do to build the cosine similarity equation is to solve the equation of the dot product for cosine:\n\n\nThat is the cosine similarity formula. Cosine Similarity will generate a metric that says how related are two documents by looking at the angle instead of the magnitude.","4ecf0837":"### Review Cleaned Text","c9bbee3c":"# Sentence Clustering","ef81c9ec":"\"we often want to determine **similarity between pairs of documents**, or the **similarity between a specific document** and a set of other documents (such as a user query vs. indexed documents).\n\n\n### Use cases:\nBroad:\n- information retrieval\n- document clustering\n- word-sense disambiguation\n- automatic essay scoring\n- short answer grading\n- machine translation\n- Recommendation Engines\n- Search Engines (Query - Result matching)\n\nSpecific:\n- Grant similarity\n- Complaint similarity\n- Duplicate questions\n- Question Answering (e.g. give the same style of question to a customer support agent)","2eb3a5a3":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/dot_product.png)","ac359872":"# Text Similarity\n\n##### Author: Alex Sherman | alsherman@deloitte.com, Vaibhav Srivastav (vasrivastav@deloitte.com) | Revannth (revedala@deloitte.com)","aaa5bf6d":"\"The dot product for two vectors of a and b where a_n and b_n are the components of the vector (features of the document or TF-IDF values for each word of the document in our example)\"\n\nImagine two documents:\n- a = 'medicine medicine medicine'\n- b = 'biomedical biomedical biomedical biomedical'","30af6e4a":"### Index Documents for similarity recommendations (gensim)\n\n**Compute the cosine similarity of a dynamic query against a static corpus of documents**\n\n- gensim.similarities.**MatrixSimilarity**: for an efficient, memory-mapped index -- dense NumPy implementation\n\n\n- gensim.similarities.**SparseMatrixSimilarity**: for an efficient, memory-mapped index -- sparse SciPy implementation\n\n\n- gensim.similarities.**Similarity**: for an efficient out-of-core sharded index (auto-selects MatrixSimilarity or SparseMatrixSimilarity for each shard internally, based on the shard density); this is the most flexible class and should be your first choice.","0694d1e7":"![](https:\/\/s3.amazonaws.com\/nlp.practicum\/geometric_dot_product.png)","1dcb81ce":"##### NOTE: These queries only consider semantic similarity, and ignore important behavior driven features","c5ae6efb":"##### Dot Product","e8260109":"### Annoy\n\n##### Why use Annoy?\n\nThe current implementation for finding k nearest neighbors in a vector space in gensim has linear complexity via brute force in the number of indexed documents, although with extremely low constant factors. The retrieved results are exact, which is an overkill in many applications: approximate results retrieved in sub-linear time may be enough. Annoy can find approximate nearest neighbors much faster.\n\nSOURCE: https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/docs\/notebooks\/annoytutorial.ipynb"}}