{"cell_type":{"cd63e6a9":"code","27304fe7":"code","c4353f41":"markdown","1ecd8355":"markdown"},"source":{"cd63e6a9":"%%writefile submission.py\n\nimport os\nimport secrets\n\nNUM_SCHEMES = 6\nNUM_SCHEMES_FOLLOWUP = 6 \nNUM_SCHEMES_FINAL = 4\n\nmy_last_action = None\ntoken_list = []\ntally = 0\nlog = ''\nact_highest = -1\nact_total = -1\nact_highest_record = []\nact_total_record = []\nbeats = [1, 2, 0]\nframe = 0\nrecords = []\nwins = []\nlast_guesses = []\n\ndef randomPlay():\n    return secrets.randbelow(3)\n\n#####\n# Counts values in a series with a rolling window of some length, returning a \n# distribution of value-counts from that period\n#####\nclass RollingCounter:\n    def __init__(self, length):\n        self.length = length\n        self.items = []\n        self.totals = [0, 0, 0]\n        self.currIndex = 0\n        self.cutoffIndex = self.length * -1\n\n    def count(self, val):\n        self.items.append(val)\n        self.totals[val] += 1\n        if self.cutoffIndex > 0:\n            self.totals[self.items[self.cutoffIndex]] -= 1\n        self.cutoffIndex += 1\n\n    def getDist(self):\n        return self.totals\n\n#####\n# Counts values in a series with several rolling windows, returning a weighted \n# sum of these distributions\n#####\nclass GangCounter:\n    def __init__(self, lengthList):\n        self.lengthList = lengthList\n        self.lengthDict = {}\n        self.counters = []\n        for i, length in enumerate(lengthList):\n            counter = RollingCounter(length)\n            self.counters.append(counter)\n            self.lengthDict[length] = counter\n\n    def setWeightList(self, weights):\n        self.weightList = weights\n\n    def count(self, val):\n        for counter in self.counters:\n            counter.count(val)\n\n    def getDist(self, length):\n        counter = self.counters[self.lengthList.index(length)]\n        return counter.getDist()\n\n    def getDists(self):\n        allDists = []\n        for length in self.lengthList:\n            dist = self.getDist(length)\n            allDists.append(dist)\n        return allDists\n\n    def getWeightedVal(self):\n        outputVal = 0.0\n        totalWeight = 0\n        for i, length in enumerate(self.lengthList):\n            dist = self.getDist(length)\n            if not dist[0] + dist[1] == 0:\n                outputVal += (dist[1] \/ (dist[0] + dist[1])) * self.weightList[i]\n                totalWeight += self.weightList[i]\n        if totalWeight == 0:\n            return 0\n        return outputVal \/ totalWeight\n\n#####\n# Holds a collection of GangCounters that each return a weighted distribution \n# of value-counts from a series.\n#####\nclass CompoundGangCounter:\n    def __init__(self):\n        self.counters = []\n\n    def addWeights(self, lengthList, weightList):\n        counter = GangCounter(lengthList)\n        counter.setWeightList(weightList)\n        self.counters.append(counter)\n\n        \n    ####\n    # GangCounter weights used for evaluating the records of strategies\n    ####\n    def setDefaultWeights(self):\n        self.addWeights([10, 7],[1, 1])\n        self.addWeights([125],[1])\n        self.addWeights([225],[1])\n        self.addWeights([300, 50],[1, 1])\n        self.addWeights([50, 20],[1, 1])\n        self.addWeights([5,4,3,2,1],[10,11,12,13,14])\n\n\n    ####\n    # Weights for evaluating the next layer after strategy records are fed\n    # through a FollowupTree class\n    ####\n    def setDefaultWeightsFollowup(self):\n        self.addWeights([20, 10],[1,1])\n        self.addWeights([125],[1])\n        self.addWeights([7,3],[1, 1])\n        self.addWeights([500, 50],[1, 1])\n        self.addWeights([50, 5],[1, 1])\n        self.addWeights([5,2,1],[1,1,1])\n\n\n    ####\n    # Weights for evaluating the final layer, which compares weighted results\n    # from strategy records and the results of running those records though\n    # FollowupTrees\n    ####\n    def setFinalWeights(self):\n        self.addWeights([900],[1])\n        self.addWeights([10, 7],[1, 1])\n        self.addWeights([500,50],[1,1])\n        self.addWeights([5,4,3, 2, 1], [1,1,1,1,1])\n\n\n    def count(self, val):\n        for counter in self.counters:\n            counter.count(val)\n\n    def getWeightedVals(self):\n        vals = []\n        for weightListIndex in range(len(self.counters)):\n            vals.append(self.counters[weightListIndex].getWeightedVal())\n        return vals\n\n#####\n# An ngram tree that lets us access a list and distribution of next plays \n# for each player after some n-gram of tokens, where a token is a unique \n# combination of this agent's play and the opponent agent's play.\n#####\nclass PatternTree:\n    def __init__(self):\n        self.val = None\n        self.root = True\n        self.count = 0\n        self.indexList = []\n        self.myNextPlays = []\n        self.oppNextPlays = []\n        self.myNextPlaysDist = [0,0,0]\n        self.oppNextPlaysDist = [0,0,0]\n        self.children = {}\n\n    def addNextPlays(self, myNext, oppNext):\n        if not myNext == 'X':\n            self.myNextPlays.append(myNext)\n            self.myNextPlaysDist[int(myNext)] += 1\n        if not oppNext == 'X':\n            self.oppNextPlays.append(oppNext)\n            self.oppNextPlaysDist[int(oppNext)] += 1\n\n    def setVal(self, val, index):\n        self.val = val\n        self.count += 1\n        self.indexList.append(index)\n\n    def addIndex(self, ind):\n        self.count += 1\n        self.indexList.append(ind)\n\n    def addSequence(self, sequence, maxAddLen):\n        for i in range(maxAddLen):\n            self.countPattern(sequence[len(sequence)-i:len(sequence)], 0)\n\n    def countPattern(self, pattern):\n        return self.countPattern(pattern, 0)\n\n    def countPattern(self, pattern, index):\n        if len(pattern) > 0:\n            first = pattern[0]\n            nextToken = 'XX'\n            if len(pattern) > 1:\n                nextToken = pattern[1]\n            oppNext = nextToken[0]\n            myNext = nextToken[1]\n            rest = pattern[1:len(pattern)]\n            child = self.children.get(first, None)\n            if child is None:\n                self.children[first] = PatternTree()\n                self.children[first].setVal(first, index)\n            else:\n                self.children[first].addIndex(index)\n            self.children[first].addNextPlays(myNext, oppNext)\n            self.children[first].countPattern(rest, index + 1)\n\n    def findPatternEndPoint(self, pattern):\n        if len(pattern) > 0:\n            first = pattern[0]\n            rest = pattern[1:len(pattern)]\n            child = self.children.get(first, None)\n            if child is not None:\n                return self.children[first].findPatternEndPoint(rest)\n            else:\n                return None\n        else:\n            return self\n\n#####\n# A PatternTree variant designed to count zeros and ones and that counts \n# results with a CompoundGangCounter.  The records of our strategies are run \n# through FollowupTrees to help detect complex patterns in how our opponent \n# chooses their next action.\n#####\nclass FollowupTree:\n    def __init__(self):\n        self.val = None\n        self.count = 0\n        self.nextCountZeros = 0\n        self.nextCountOnes = 0\n        self.nextCount = CompoundGangCounter()\n        self.nextCount.setDefaultWeightsFollowup()\n        self.children = [None, None, None]\n\n    def getWinProb(self):\n        if float(self.nextCountOnes) + float(self.nextCountZeros) < 2:\n            return 0\n        else:\n            return float(self.nextCountOnes) \/ (float(self.nextCountOnes) + float(self.nextCountZeros))\n\n    def addNext(self, nextElement):\n        if nextElement == 0:\n            self.nextCountZeros += 1\n            self.nextCount.count(0)\n\n        elif nextElement == 1:\n            self.nextCountOnes += 1\n            self.nextCount.count(1)\n\n    def getWeightedVals(self):\n        return self.nextCount.getWeightedVals()\n\n    def setVal(self, val):\n        self.val = val\n        self.count += 1\n\n    def addSequence(self, sequence, maxAddLen):\n        for i in range(maxAddLen):\n            self.countPattern(sequence[len(sequence)-i:len(sequence)])\n\n    def countPattern(self, pattern):\n        if len(pattern) > 0:\n            self.count += 1\n            first = pattern[0]\n            nextToken = 2\n            if len(pattern) > 1:\n                nextToken = pattern[1]\n\n            rest = pattern[1:len(pattern)]\n            child = self.children[first]\n            if child is None:\n                self.children[first] = FollowupTree()\n                self.children[first].setVal(first)\n            self.children[first].addNext(nextToken)\n            self.children[first].countPattern(rest)\n\n    def findPatternEndPoint(self, pattern):\n        if len(pattern) > 0:\n            first = pattern[0]\n            rest = pattern[1:len(pattern)]\n            child = self.children[first]\n            if child is not None:\n                return self.children[first].findPatternEndPoint(rest)\n            else:\n                return None\n        else:\n            return self\n\n#####\n# Update our pattern tree each frame\n#####\npatternTree = PatternTree()\ndef update_ngram_tree(tokenList):\n    global patternTree\n    patternTree.addSequence(tokenList, 15)\n    return patternTree\n\ndef get_ngram(ngramLength, tokenList):\n    return tokenList[len(tokenList) - ngramLength:len(tokenList)]\n\n###############\n# NGRAM STRATEGIES\n#\n# These are strategies that are analyzed each step for each of various ngram lengths. \n# We are matching patterns of multiple lengths from earlier in the match.  Each of these \n# strategies will be analyzed with two rotational \"counter-strategies\"\n###############\n\n#####\n# Strategy based on what we played last after this ngram\n#####\ndef strategy_changeup(tree, ngramLength, tokenList):\n    ngram = get_ngram(ngramLength, tokenList)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None or len(treeNode.myNextPlays) == 0:\n        return randomPlay()\n    myLastPlay = treeNode.myNextPlays[len(treeNode.myNextPlays) - 1]\n    return beats[int(myLastPlay)]\n\n#####\n# Strategy based on what the opponent played last after this ngram\n#####\ndef strategy_opp_repeat(tree, ngramLength, tokenList):\n    ngram = get_ngram(ngramLength, tokenList)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None or len(treeNode.myNextPlays) == 0:\n        return randomPlay()\n    oppLastPlay = treeNode.oppNextPlays[len(treeNode.oppNextPlays) - 1]\n    return int(oppLastPlay)\n\n#####\n# Strategy that alternates what we play based on what we played last\n#####\ndef strategy_alternate_based_on_my_last(tree, ngramLength, tokenList):\n    global frame\n    ngram = get_ngram(ngramLength, tokenList)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None or len(treeNode.myNextPlays) == 0:\n        return randomPlay()\n    myLastPlay = treeNode.myNextPlays[len(treeNode.myNextPlays) - 1]\n    if frame % 2 == 0:\n        return beats[int(myLastPlay)]\n    else:\n        return beats[beats[int(myLastPlay)]]\n\n#####\n# Strategy that alternates what we play based on what the opponent played last\n#####\ndef strategy_alternate_based_on_opp_last(tree, ngramLength, tokenList):\n    global frame\n    ngram = get_ngram(ngramLength, tokenList)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None or len(treeNode.myNextPlays) == 0:\n        return randomPlay()\n    oppLastPlay = treeNode.oppNextPlays[len(treeNode.oppNextPlays) - 1]\n    if frame % 2 == 0:\n        return beats[int(oppLastPlay)]\n    else:\n        return beats[beats[int(oppLastPlay)]]\n\n#####\n# Strategy that expects the opponent to play after this ngram what they \n# typically play after this ngram\n#####\ndef strategy_predict_by_frequency(tree, ngramLength, tokenList):\n    ngram = get_ngram(ngramLength, tokenList)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None:\n        return randomPlay()\n    dist = treeNode.oppNextPlaysDist\n    for i in [0, 1, 2]:\n        if dist[i] > dist[(i + 1) % 3] and dist[i] > dist[(i + 2) % 3]:\n            return beats[i]\n    return randomPlay()\n\n#####\n# Strategy to play whatever we play least after this ngram\n#####\ndef strategy_my_lowest_freq(tree, ngramLength, tokenlist):\n    ngram = get_ngram(ngramLength, token_list)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None:\n        return randomPlay()\n    dist = treeNode.myNextPlaysDist\n    for i in [0, 1, 2]:\n        if dist[i] < dist[(i + 1) % 3] and dist[i] < dist[(i + 2) % 3]:\n            return beats[i]\n    return randomPlay()\n\n#####\n# Strategy to counter an agent that expects our most frequent action\n#####\ndef strategy_my_highest_freq(tree, ngramLength, tokenList):\n    ngram = get_ngram(ngramLength, token_list)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None:\n        return randomPlay()\n    dist = treeNode.myNextPlaysDist\n    return beats[beats[dist.index(max(dist))]]\n\n#####\n# Strategy to counter an agent that always plays its own least frequent action\n#####\ndef strategy_opp_lowest_freq(tree, ngramLength, tokenList):\n    ngram = get_ngram(ngramLength, token_list)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None:\n        return randomPlay()\n    dist = treeNode.oppNextPlaysDist\n    return beats[dist.index(min(dist))]\n\ndef make_distribution(list):\n    dist = [0.0, 0.0, 0.0]\n    for li in list:\n        dist[int(li)] += 1\n\n    return dist\n\n#####\n# Strategy that predicts the opponent will play what they played frequently in \n# the last 4 steps\n#####\ndef strategy_predict_by_frequency_last_four(tree, ngramLength, tokenList):\n    n = 4\n    ngram = get_ngram(ngramLength, tokenList)\n    treeNode = tree.findPatternEndPoint(ngram)\n    if treeNode is None:\n        return randomPlay()\n    dist = make_distribution(treeNode.oppNextPlays[len(treeNode.oppNextPlays) - n:len(treeNode.oppNextPlays)])\n    for i in [0, 1, 2]:\n        if dist[i] > dist[(i + 1) % 3] and dist[i] > dist[(i + 2) % 3]:\n            return beats[i]\n    return randomPlay()\n \n\n#####\n# Evaluates a strategy and its historical record and returns the strategy's \n# recommendation and the record of that strategy as measured by a CompoundGangCounter,\n# also uses Followup Trees to analyze this strategy's record.\n#####\ndef evaluate_strategy(strategyList, strategyIndex, records, wins, last_guesses, tree, tokenList, ngramLength, counter):\n    global followup_trees\n    global NUM_SCHEMES\n    strategy = strategyList[strategyIndex]\n    suggestion = strategy(tree, ngramLength, tokenList)\n    if counter >= 1:\n        suggestion = beats[suggestion]\n    if counter >= 2:\n        suggestion = beats[suggestion]\n    opponentLastPlay = int(tokenList[len(tokenList) - 1][0])\n    if last_guesses[counter][strategyIndex][ngramLength][0] == beats[opponentLastPlay]:\n        wins[counter][strategyIndex][ngramLength].count(1)\n        records[counter][strategyIndex][ngramLength][0].append(1)\n    else:\n        wins[counter][strategyIndex][ngramLength].count(0)\n        records[counter][strategyIndex][ngramLength][0].append(0)\n\n    last_guesses[counter][strategyIndex][ngramLength][0] = suggestion\n    if len(records[counter][strategyIndex][ngramLength][0]) > 3:\n        scores = wins[counter][strategyIndex][ngramLength].getWeightedVals()\n    else:\n        scores = []\n        for i in range(NUM_SCHEMES):\n            scores.append(0)\n\n    followupScores = search_followup_tree(records[counter][strategyIndex][ngramLength][0], followup_trees[counter][strategyIndex][ngramLength])\n    return suggestion, scores, followupScores\n\n#####\n# Uses FollowupTree class to search for ngram patterns in a strategy's record itself\n#####\ndef search_followup_tree(records, tree):\n    global NUM_SCHEMES\n    maxLength = 5\n    lenAdd = 6\n    for i in range(max(len(records) - lenAdd, 0)):\n        tree.countPattern(records[(len(records) - lenAdd) + i:len(records)])\n\n    highestWeightedVals = []\n    for i in range(NUM_SCHEMES):\n        highestWeightedVals.append(0)\n    for ngramLen in range(maxLength):\n        ngram = get_ngram(ngramLen, records)\n        treeNode = tree.findPatternEndPoint(ngram)\n        if treeNode is not None:\n            if ngramLen > 0:\n                weightedVals = treeNode.getWeightedVals()\n                for i, weightedVal in enumerate(weightedVals):\n                    highestWeightedVals[i] = max(weightedVal, highestWeightedVals[i])\n    return highestWeightedVals\n\nfollowup_trees = []\nmy_last_actions = []\nmy_last_actions_followup = []\nscore_records = []\nscore_records_followup = []\nfor i in range(NUM_SCHEMES):\n    my_last_actions.append(0)\n    my_last_actions_followup.append(0)\n    score_records.append(CompoundGangCounter())\n    score_records[len(score_records) - 1].setFinalWeights()\n    score_records_followup.append(CompoundGangCounter())\n    score_records_followup[len(score_records_followup) - 1].setFinalWeights()\n    \nfinal_records = []\nfinal_records_followup = []\nfinal_actions = []\nfinal_actions_followup = []\nfinal_records_counter = []\nfinal_records_counter_followup = []\n    \nfor j in range(NUM_SCHEMES_FINAL):\n    final_records.append(0)\n    final_records_counter.append(GangCounter([225]))\n    final_records_counter[j].setWeightList([1])\n    final_records_counter_followup.append(GangCounter([225]))\n    final_records_counter_followup[j].setWeightList([1])\n    final_actions.append(0)\n    final_actions_followup.append(0)\n    final_records_followup.append(0)\n    \n    \n#####\n# The driver of this agent, gets a matrix of scores from the compound gang counters \n# attached to the record of each ngram strategy, and a second matrix of scores from \n# the followup trees attached to each record, then evaluates the record of each \n# GangCounter's max-strategy record for each matrix and treats the output as a new \n# collection of records.\n#\n# Finally, we evaluate these last records using the \"final\" GangCounter weight \n# scheme: [225]\n#####\ndef evaluate_records(observation, configuration, includeNew):\n    global NUM_SCHEMES\n    strategyList = [\n        strategy_predict_by_frequency,\n        strategy_changeup,\n        strategy_my_lowest_freq,\n        strategy_predict_by_frequency_last_four,\n        strategy_alternate_based_on_my_last,\n        strategy_alternate_based_on_opp_last,\n        strategy_opp_repeat,\n        strategy_opp_lowest_freq,\n        strategy_my_highest_freq\n    ]\n    global followup_trees\n    global records, wins, last_guesses, token_list, log, frame\n    global my_last_actions, my_last_actions_followup, final_actions, final_actions_followup, score_records\n    global final_records_counter, final_records_counter_followup, final_records_followup\n    global match_records\n    ngramSizes = 9\n    \n    if len(records) == 0 or records is None:\n        records = []\n        wins = []\n        last_guesses = []\n        followup_trees = []\n        for counter_num in [0, 1, 2]:\n            records.append([])\n            wins.append([])\n            last_guesses.append([])\n            followup_trees.append([])\n            for strategy_num in range(len(strategyList)):\n                records[counter_num].append([])\n                wins[counter_num].append([])\n                last_guesses[counter_num].append([])\n                followup_trees[counter_num].append([])\n                for ngram_size in range(ngramSizes):\n                    records[counter_num][strategy_num].append([])\n                    wins[counter_num][strategy_num].append(CompoundGangCounter())\n                    wins[counter_num][strategy_num][ngram_size].setDefaultWeights()\n                    last_guesses[counter_num][strategy_num].append([])\n                    followup_trees[counter_num][strategy_num].append(FollowupTree())\n                    for a in [0,2,3]:\n                        records[counter_num][strategy_num][ngram_size].append([])\n                        last_guesses[counter_num][strategy_num][ngram_size].append(0)\n\n    global my_last_action\n    token_list.append(str(observation.lastOpponentAction) + str(my_last_action))\n    tree = update_ngram_tree(token_list)\n\n    highestScores = []\n    highestScorePlays = []\n    highestScoresFollowup = []\n    highestScorePlaysFollowup = []\n    for i in range(NUM_SCHEMES):\n        highestScoresFollowup.append(0)\n        highestScorePlaysFollowup.append(-1)\n        highestScores.append(0)\n        highestScorePlays.append(-1)\n\n    totalScores = [0.0,0.0,0.0]\n    totalFollowupScores = [0.0,0.0,0.0]\n    for ngramLength in range(ngramSizes):\n        for i in range(len(strategyList)):\n            for counter in [0, 1, 2]:\n                suggestion, scores, followupScores = evaluate_strategy(strategyList, i, records, wins, last_guesses, tree,\n                                                                               token_list, ngramLength, counter)\n\n                for scoreIndex in range(NUM_SCHEMES):\n                    score = scores[scoreIndex]\n                    followupScore = followupScores[scoreIndex]\n                    totalScores[int(suggestion)] += score\n                    totalFollowupScores[int(suggestion)] += followupScores[scoreIndex]\n                    if score > highestScores[scoreIndex]:\n                        highestScores[scoreIndex] = score\n                        highestScorePlays[scoreIndex] = suggestion\n                    if followupScore > highestScoresFollowup[scoreIndex]:\n                        highestScoresFollowup[scoreIndex] = followupScore\n                        highestScorePlaysFollowup[scoreIndex] = suggestion\n\n    for i in range(NUM_SCHEMES):\n        if my_last_actions[i] == beats[observation.lastOpponentAction]:\n            score_records[i].count(1)\n        else:\n            score_records[i].count(0)\n        if my_last_actions_followup[i] == beats[observation.lastOpponentAction]:\n            score_records_followup[i].count(1)\n        else:\n            score_records_followup[i].count(0)\n\n    for i in range(NUM_SCHEMES_FINAL):\n        if final_actions[i] == beats[observation.lastOpponentAction]:\n            final_records[i] += 1\n            final_records_counter[i].count(1)\n        else:\n            final_records_counter[i].count(0)\n\n    for i in range(NUM_SCHEMES_FINAL):\n        if final_actions_followup[i] == beats[observation.lastOpponentAction]:\n            final_records_followup[i] += 1\n            final_records_counter_followup[i].count(1)\n        else:\n            final_records_counter_followup[i].count(0)\n        print('c' + str(i) + ': ' + str(final_records[i]) + ' --- ' + 'f' + str(i) + ': ' + str(final_records_followup[i]))\n\n    finalRecordsTotal = []\n    finalRecordsTotalFollowup = []\n    for i in range(NUM_SCHEMES_FINAL):\n        finalRecordsTotal.append(final_records_counter[i].getWeightedVal())\n        finalRecordsTotalFollowup.append(final_records_counter_followup[i].getWeightedVal())\n\n    finalScoreIndex = finalRecordsTotal.index(max(finalRecordsTotal))\n    finalScoreIndexFollowup = finalRecordsTotalFollowup.index(max(finalRecordsTotalFollowup))\n\n\n    for scoreIndex in range(NUM_SCHEMES):\n        if highestScores[scoreIndex] > 0:\n            my_last_actions[scoreIndex] = highestScorePlays[scoreIndex]\n        else:\n            my_last_actions[scoreIndex] = randomPlay()\n        if highestScoresFollowup[scoreIndex] > 0:\n            my_last_actions_followup[scoreIndex] = highestScorePlaysFollowup[scoreIndex]\n        else:\n            my_last_actions_followup[scoreIndex] = randomPlay()\n\n    finalScores = []\n    finalScoresFollowup = []\n    bestPlays = []\n    bestScores = []\n    bestPlaysFollowup = []\n    bestScoresFollowup = []\n    for j in range(NUM_SCHEMES_FINAL):\n        bestPlays.append(-1)\n        bestScores.append(0)\n        bestPlaysFollowup.append(-1)\n        bestScoresFollowup.append(0)\n    for i in range(NUM_SCHEMES):\n        finalScores.append(score_records[i].getWeightedVals())\n        finalScoresFollowup.append(score_records_followup[i].getWeightedVals())\n        for j in range(NUM_SCHEMES_FINAL):\n            if finalScores[i][j] > bestScores[j]:\n                bestScores[j] = finalScores[i][j]\n                bestPlays[j] = my_last_actions[i]\n            if finalScoresFollowup[i][j] > bestScoresFollowup[j]:\n                bestScoresFollowup[j] = finalScoresFollowup[i][j]\n                bestPlaysFollowup[j] = my_last_actions_followup[i]\n    for scoreIndex in range(NUM_SCHEMES_FINAL):\n        final_actions[scoreIndex] = bestPlays[scoreIndex]\n        final_actions_followup[scoreIndex] = bestPlaysFollowup[scoreIndex]\n\n    print('max normal: ' + str(max(finalRecordsTotal)) + ', max followup: ' + str(max(finalRecordsTotalFollowup)))\n    if max(finalRecordsTotal) > max(finalRecordsTotalFollowup):\n        my_last_action = final_actions[finalScoreIndex]\n        print('Using RECORD index ' + str(finalScoreIndex))\n    else:\n        my_last_action = final_actions_followup[finalScoreIndexFollowup]\n        print('Using FOLLOWUP index ' + str(finalScoreIndexFollowup))\n\n    if max(max(finalRecordsTotal), max(finalRecordsTotalFollowup)) < 0.38:\n        my_last_action = randomPlay()\n    if my_last_action == -1:\n        my_last_action = randomPlay()\n    return my_last_action\n\n\ndef counting_agent(observation, configuration):\n    global my_last_action, tally, frame\n    if frame > 1 and observation.lastOpponentAction == beats[my_last_action]:\n        tally -= 1\n    elif frame > 1 and my_last_action == beats[observation.lastOpponentAction]:\n        tally += 1\n    if observation.step < 10:\n        my_last_action = randomPlay()\n    else:\n        my_last_action = evaluate_records(observation, configuration, False)\n    frame += 1\n    print('tally: ', tally)\n    return my_last_action","27304fe7":"from datetime import datetime\nimport kaggle_environments\n\ndef get_result(team):\n    start = datetime.now()\n    outcomes = kaggle_environments.evaluate(\n        'rps', ['submission.py', team], num_episodes=5)\n    won, lost, tie, avg_score = 0, 0, 0, 0.\n    for outcome in outcomes:\n        score = outcome[0]\n        if score > 0: won += 1\n        elif score < 0: lost += 1\n        else: tie += 1\n        avg_score += score\n    elapsed = datetime.now() - start\n    return won, lost, tie, elapsed, float(avg_score) \/ 5.0\n    \nwon, lost, tie, elapsed, score = get_result('..\/input\/rps-dojo\/black_belt\/iocane_powder.py')\nprint('Counting Agent vs. Iocaine: ' + str(won) + ' \/ ' + str(lost) + ' \/ ' + str(tie) + ' \/\/ ' + str(score))\n","c4353f41":"# Layered counting windows\n\nMy first approach to this competition used a collection of strategies and kept a count of how frequently each would win, selecting the strategy with the maximum win count.  The first problem anyone using this approach encounters is that once a strategy accumulates a high win count, the opponent might start to target that strategy, and it will take some time before the win count declines enough to reorient the agent properly.\n\nOne approach (not my strongest approach, but a strong one) was to use multiple rolling windows for counting.  In the code, I refer to \"weight schemes,\" which are collections of rolling windows that use a weighted average to return a score.  Since we can think of a \"strategy\" as an action-selection and a record of hits and misses, we can use weight schemes to convert a collection of strategies into a new collection of strategies (the diagram below is intended to show how).\n\nWhen we layer this technique upon itself, the agent seems to be better equipped to evade detection, and to dynamically target different unique opponent strategies. But it is also prone to more random fluctuation, which  can lead to sporadically losing matches. \n\nToday, near the end of this competition, the strongest variation of this strategy sits at 1016, or about 14th place (silver).\n\n(Write-up and public notebook for my strongest agent are coming soon.  Since this is quite different from my strongest, I figured I'd make it public as well.)\n\n![diagram](https:\/\/i.imgur.com\/MMLu3zN.png)","1ecd8355":"Credit goes to @chankhavu's [RPS Dojo](https:\/\/www.kaggle.com\/chankhavu\/rps-dojo) for this code."}}