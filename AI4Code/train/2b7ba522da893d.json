{"cell_type":{"fe9d41ce":"code","9feeaa51":"code","3e48d865":"code","7854b849":"code","4fd80045":"code","f6882f8b":"code","116d33fa":"code","89ed26f2":"code","509894b0":"code","c5540167":"code","57218ecd":"code","e88d8c50":"code","63655100":"code","ef0845ae":"code","848d8ef4":"code","27e7df33":"code","a205ef63":"code","0e5bc213":"code","39198ee1":"code","4c51d0ae":"code","6fa3e779":"markdown","95d25eed":"markdown","8c0ba07f":"markdown","15b0b2a2":"markdown","877742a6":"markdown","e5691318":"markdown","ff0d1dc5":"markdown","e420cf42":"markdown"},"source":{"fe9d41ce":"import pandas as pd\nimport numpy as np\n","9feeaa51":"test = pd.read_csv(\"test.csv\")","3e48d865":"train.head()","7854b849":"test.head()","4fd80045":"data = pd.read_csv(\"train.csv\")","f6882f8b":"data[\"keyword\"].fillna(\"1234\", inplace=True)\ndata[\"location\"].fillna(\"unknown\", inplace=True)","116d33fa":"data","89ed26f2":"data = pd.read_csv(\"test.csv\")","509894b0":"data[\"keyword\"].fillna(\"9876\", inplace = True)\ndata[\"location\"].fillna(\"unknown\", inplace=True)","c5540167":"data","57218ecd":"pd.options.display.max_rows = 9999\n\ndf = pd.read_csv('train.csv')\n\nprint(df) ","e88d8c50":"pd.options.display.max_rows = 9999\n\ndf = pd.read_csv('test.csv')\n\nprint(df) ","63655100":"import matplotlib.pyplot as plt\nimport seaborn as sns","ef0845ae":"print('There are {} rows and {} columns in train'.format(train.shape[0],train.shape[1]))\nprint('There are {} rows and {} columns in train'.format(test.shape[0],test.shape[1]))","848d8ef4":"x=train.target.value_counts()\nsns.barplot(x.index,x)\nplt.gca().set_ylabel('samples')","27e7df33":"#Number of characters in trains\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntrain_len=train[train['target']==1]['text'].str.len()\nax1.hist(train_len,color='red')\nax1.set_title('disaster trains')\ntraint_len=train[train['target']==0]['text'].str.len()\nax2.hist(train_len,color='green')\nax2.set_title('Not disaster trains')\nfig.suptitle('Characters in trains')\nplt.show()","a205ef63":"#Number of words in a train\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntrain_len=train[train['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(train_len,color='red')\nax1.set_title('disaster trains')\ntrain_len=train[train['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(train_len,color='green')\nax2.set_title('Not disaster trains')\nfig.suptitle('Words in a train')\nplt.show()","0e5bc213":"#Average word length in a train\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword=train[train['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\nax1.set_title('disaster')\nword=train[train['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\nax2.set_title('Not disaster')\nfig.suptitle('Average word length in each train')","39198ee1":"plt.figure(figsize=(10,5))\ncorpus=create_corpus(1)\n\ndic=defaultdict(int)\nimport string\nspecial = string.punctuation\nfor i in (corpus):\n    if i in special:\n        dic[i]+=1\n        \nx,y=zip(*dic.items())\nplt.bar(x,y)","4c51d0ae":"df=pd.concat([train,test])\ndf.shape","6fa3e779":"### Data Cleaning","95d25eed":"### Read the dataset","8c0ba07f":"### Loading the data and getting basic idea","15b0b2a2":"### Exploratory Data Analysis of trains","877742a6":"### Filling null values in CSV File","e5691318":"### Analyzing punctuations","ff0d1dc5":"### Class distribution","e420cf42":"### Max_Rows"}}