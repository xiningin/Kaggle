{"cell_type":{"18844520":"code","1dc5effd":"code","e2122505":"code","57c077ff":"code","9c6f5339":"code","8698d6d8":"code","891ea9ea":"code","68878770":"code","9b2fbee3":"code","1c49595b":"code","1a1f3c71":"code","a99e7140":"code","4c9a4aed":"code","273278ae":"code","29951fa5":"code","1a7a6134":"code","63b09420":"code","95f4b631":"code","9f070bb6":"code","fe360c8c":"code","63d90c12":"code","08772c7a":"code","ea191218":"code","abaa50f0":"code","7eb77122":"code","bfb9984e":"code","cfc7a5b1":"code","4c88462d":"code","57a4726e":"code","77412f3c":"code","02c9a68f":"code","d0ba449b":"markdown","33fecceb":"markdown","bff0dbbd":"markdown","4193e9cc":"markdown","a0545e04":"markdown","25971ad3":"markdown","efb8855a":"markdown","915533cd":"markdown","f760edab":"markdown","72672e71":"markdown","55f8d9d4":"markdown","975292c2":"markdown","e4bf902f":"markdown","4393b7de":"markdown","95fe9246":"markdown","2fa8d4d5":"markdown"},"source":{"18844520":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1dc5effd":"df=pd.read_csv('\/kaggle\/input\/voicegender\/voice.csv')","e2122505":"df.head()","57c077ff":"df.shape","9c6f5339":"df.describe()","8698d6d8":"df.info()","891ea9ea":"df['label'].value_counts()","68878770":"df.columns","9b2fbee3":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","1c49595b":"def calc_limits(feature):\n    q1,q3=df[feature].quantile([0.25,0.75])\n    iqr=q3-q1\n    rang=1.5*iqr\n    return(q1-rang,q3+rang)","1a1f3c71":"def plot(feature):\n    fig,axes=plt.subplots(1,2)\n    sns.boxplot(data=df,x=feature,ax=axes[0])\n    sns.distplot(a=df[feature],ax=axes[1],color='#ff4125')\n    fig.set_size_inches(15,5)\n    \n    lower,upper = calc_limits(feature)\n    l=[df[feature] for i in df[feature] if i>lower and i<upper] \n    print(\"Number of data points remaining if outliers removed : \",len(l))","a99e7140":"plot('meanfreq')","4c9a4aed":"plot('sd')","273278ae":"plot('median')","29951fa5":"plot('Q25')","1a7a6134":"plot('IQR')","63b09420":"plot('skew')","95f4b631":"plot('kurt')","9f070bb6":"temp=[]\nfor i in df['label']:\n    if i=='male':\n        temp.append(1)\n    else:\n        temp.append(0)\ndf['label']=temp","fe360c8c":"cor_mat=df[:].corr()\nplt.figure(figsize=(20,20))\nsns.heatmap(data=cor_mat,annot=True)","63d90c12":"df.drop('centroid',axis=1,inplace=True)","08772c7a":"g = sns.PairGrid(df[['meanfreq','sd','median','Q25','IQR','sp.ent','sfm','meanfun','label']], hue = \"label\")\ng = g.map(plt.scatter).add_legend()","ea191218":"for col in df.columns:\n    lower,upper=calc_limits(col)\n    df = df[(df[col] >lower) & (df[col]<upper)]","abaa50f0":"temp_df=df.copy()\n\ntemp_df.drop(['skew','kurt','mindom','maxdom'],axis=1,inplace=True) # only one of maxdom and dfrange.","7eb77122":"temp_df['meanfreq']=temp_df['meanfreq'].apply(lambda x:x*2)\ntemp_df['median']=temp_df['meanfreq']+temp_df['mode']\ntemp_df['median']=temp_df['median'].apply(lambda x:x\/3)","bfb9984e":"temp_df['pear_skew']=temp_df['meanfreq']-temp_df['mode']\ntemp_df['pear_skew']=temp_df['pear_skew']\/temp_df['sd']\ntemp_df.head(10)","cfc7a5b1":"from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\nscaled_df=scaler.fit_transform(temp_df.drop('label',axis=1))\nX=scaled_df\nY=df['label'].as_matrix()","4c88462d":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n","57a4726e":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import History\nfrom keras.utils import plot_model\nfrom keras.optimizers import SGD\n","77412f3c":"classifier=Sequential()\nhistory = History()\n\n#number of input variables =20\n#first layer \n#input_dim is only for the first layer\nclassifier.add(Dense(output_dim=11,init='uniform',activation='relu',input_dim=16))\n#first Hidden layer\nclassifier.add(Dense(output_dim=11,init='uniform',activation='relu'))\n#Second Hidden\nclassifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n#output layer\nclassifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))\n#Running the artificial neural network\nclassifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n#fitting\nclassifier.fit(X_train,y_train,batch_size=10,epochs=50,validation_split=0.1,callbacks=[history],shuffle=2)","02c9a68f":"import sklearn.metrics as metrics\ny_pred=classifier.predict(X_test)\ny_pred = np.round(y_pred)\n\nprint('Accuracy we are able to achieve with our ANN is',metrics.accuracy_score(y_pred,y_test)*100,'%')\n\nplt.plot(history.history['loss'], color = 'red',label='Variaton Loss over the epochs',)\nplt.plot(history.history['accuracy'],color='cyan',label='Variation in Profit over the epochs')\n\nplt.xlabel('Epochs')\nplt.title('Loss\/Accuracy VS Epoch')\nplt.ylabel('Loss\/Accuracy')\nplt.legend(loc='best')\nplt.show()","d0ba449b":"removing outliers","33fecceb":"we will be dropping centroid because very high corrleation with other variables","bff0dbbd":"calculating outlier by interquetile formula","4193e9cc":"**perfectly balance data......BRAVO**","a0545e04":"# feature enginerring","25971ad3":"to breifly undersatnd data with other variables we will be plotting scatterplot","efb8855a":"visulaing the data:-\n    as mostly are continous varriables plotting histogrm and boxplot will serve our purposes","915533cd":"**our neural net . i have found hidden layers by performing grid serach cv you can also use randomized serah to find best params and neural net**","f760edab":"noramlizing the faetures","72672e71":"# making our ANN model","55f8d9d4":"dropping useless variables","975292c2":"**PERFORMING BIVARIATE ANALYSIS AND CHECKING CORELEATION BETWEEN VARIABLES**","e4bf902f":"outlier present in meanfreq and negatively skewed we have to normalize it\n","4393b7de":"The second new feature that I have added is a new feature to mesure the 'skewness'.\n\nFor this I have used the 'Karl Pearson Coefficent' which is calculated as shown below->\n..........................................................Coefficent = (Mean - Mode )\/StandardDeviation......................................................","95fe9246":"**IF YOU LIKE MY WORK PLAESE UPVOTE IT.**","2fa8d4d5":"3median=2mean+mode"}}