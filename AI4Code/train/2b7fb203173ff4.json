{"cell_type":{"34e3aec6":"code","b5d415a1":"code","8db4442d":"code","c6c83732":"code","7fb538a5":"code","0e3710b7":"code","c5e5c5e7":"code","8218097c":"code","e6dd7e6f":"code","84e6bb15":"code","030e2ed9":"code","528cc9c5":"code","2f0f81a4":"code","49a7def1":"code","a8623bfe":"code","d7e23917":"code","f3c4b087":"code","ad19bf3e":"code","71fa9326":"code","106935d2":"code","aa4881cb":"code","e001bf4a":"code","57b446b9":"code","66b75ae2":"code","68db2dcf":"code","4908656e":"code","66a9bd20":"code","83116c22":"code","b70246ef":"markdown","c48f836e":"markdown","76079ab9":"markdown","56c78395":"markdown","43b61fa2":"markdown","8e9ea084":"markdown","88d677cf":"markdown","41dd8a7f":"markdown"},"source":{"34e3aec6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('..\/input\/petfinder-pawpularity-score'))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5d415a1":"rootDir = \"..\/input\/petfinder-pawpularity-score\/\"\n","8db4442d":"import tensorflow as tf\nfrom tensorflow import keras\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt \nfrom os.path import basename\n%matplotlib inline\n","c6c83732":"trainf = pd.read_csv(rootDir + \"train.csv\")\ntestf = pd.read_csv(rootDir + \"test.csv\")\n","7fb538a5":"trainf['imagename'] = trainf['Id'].apply(lambda x : str(x) + \".jpg\")\ntestf['imagename'] = testf['Id'].apply(lambda x : str(x) + \".jpg\")","0e3710b7":"i = 10\nimgpath = rootDir + \"train\/\" + os.listdir(rootDir + \"train\/\")[i]\nimgname = basename(imgpath)\nprint(f\"image name is {imgname}\")\npscore = trainf[trainf['imagename']== imgname]['Pawpularity'].unique()[0]\nprint(f\"popularity score is {pscore}\")\nimg = Image.open(imgpath)\nimg","c5e5c5e7":"trainf[trainf['imagename']== imgname]","8218097c":"from tensorflow.keras.preprocessing import image \nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,BatchNormalization,GlobalAveragePooling2D,Flatten,Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications import VGG16,ResNet152\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\nfrom sklearn.model_selection import train_test_split","e6dd7e6f":"train_df,valid_df = train_test_split(trainf,test_size = 0.2,random_state  = 1)\ntrain_df = train_df.reset_index(drop = True)\nvalid_df = valid_df.reset_index(drop = True)\nprint(train_df.shape,valid_df.shape)\n","84e6bb15":"train_df.head()","030e2ed9":"train_df.columns","528cc9c5":"# def transferlearn_model():\n#     imgsize = 224 ## using vgg \n#     vgg_model_wtl = VGG16(weights = \"imagenet\",input_shape = (imgsize,imgsize,3), include_top = False ) \n#     layername = \"block3_conv3\"\n#     mymodel = Model(inputs = vgg_model_wtl.input,outputs = vgg_model_wtl.get_layer(layername).output)\n#     newmodel1 = Sequential()\n#     newmodel1.add(mymodel)\n\n#     newmodel1.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n#     newmodel1.add(MaxPooling2D((2,2),padding='same'))\n\n#     newmodel1.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n#     newmodel1.add(MaxPooling2D((2,2),padding='same'))\n\n\n#     newmodel1.add(Conv2D(256,(3,3),activation='relu',padding='same'))\n#     newmodel1.add(MaxPooling2D((2,2),padding='same'))\n\n#     newmodel1.add(GlobalAveragePooling2D())\n#     newmodel1.add(Dense(64,activation='relu'))\n#     newmodel1.add(BatchNormalization())\n\n#     newmodel1.add(Dense(1,activation='linear'))\n\n#     newmodel1.layers[0].trainable=False\n    \n#     newmodel1.compile(loss='mean_squared_error', optimizer='adam',\n#                   metrics=['mse'])\n#     return newmodel1\n    \n# model2train = transferlearn_model()\n\n# ### train and valid\n# train_datagen = ImageDataGenerator(\n#         rescale=1.\/255,\n#         shear_range=0.2,\n#         zoom_range=0.2,\n#         horizontal_flip=True)\n\n# train_generator = train_datagen.flow_from_dataframe(\n#         dataframe=train_df,\n#         directory=rootDir + \"train\/\",\n#         x_col=\"imagename\",\n#         y_col='Pawpularity', ## need not one hot encode \n#         target_size=(224, 224),\n#         batch_size=32,\n#         class_mode='raw')\n\n# valid_datagen = ImageDataGenerator(rescale=1.\/255)\n\n\n# validation_generator = valid_datagen.flow_from_dataframe(\n#         dataframe=valid_df,\n#         directory=rootDir + \"train\/\",\n#         x_col=\"imagename\",\n#         y_col='Pawpularity',\n#         target_size=(224, 224),\n#         batch_size=32,\n#         class_mode='raw')\n\n\n# ES_PATIENCE = 10\n# RLROP_PATIENCE = 3\n# DECAY_DROP = 0.4\n\n# es = EarlyStopping(monitor='val_loss', mode='min', \n#                    patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n# rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', \n#                           patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n\n# callback_list = [es,rlrop]\n\n# RunRes = model2train.fit_generator(generator=train_generator,\n#                     validation_data=validation_generator,epochs = 5,callbacks=callback_list)\n\n# RunRes.history.keys()\n# fig,axes = plt.subplots(2,2,figsize = (8,8))\n# axes[0,0].plot(RunRes.history['loss'])\n# axes[0,1].plot(RunRes.history['val_loss'])\n# axes[1,0].plot(RunRes.history['mse'])\n# axes[1,1].plot(RunRes.history['val_mse'])\n# plt.show()","2f0f81a4":"class customImageGen(tf.keras.utils.Sequence):\n    def __init__(self,imgdir,_dataF,X_col,otherfeats,target,batch_size = 32,dim = (256,256,3),shuffle = True,n_channels = 1,n_classes = 1,flag = \"train\"):\n        self.imgdir  = imgdir \n        self._dataF = _dataF \n        self.target = target\n        self.dim = dim \n        self.shuffle = shuffle \n        self.X_col = X_col\n        self.otherfeats = otherfeats\n        self.n_channels = n_channels\n        self.batch_size = batch_size \n        self.indexes = self._dataF.index\n        self.n_classes = n_classes\n        self.flag = flag\n        \n        \n    def augmen(self,samples):\n        if self.flag == \"train\":\n            datagentrain = ImageDataGenerator(rescale=1. \/ 255.0,\n                                  horizontal_flip = True,\n                                  vertical_flip = False, \n                                  height_shift_range= 0.1, \n                                  width_shift_range=0.1, \n                                  rotation_range=20, \n                                  shear_range = 0.1,\n                                  zoom_range=0.1)\n\n            it = datagentrain.flow(samples, batch_size=1)\n        elif self.flag == \"val\":\n            datagenval = ImageDataGenerator(rescale=1. \/ 255.0)\n\n            it = datagenval.flow(samples, batch_size=1)\n        return it.next() \n    \n    def __len__(self):\n        'Denotes number of batches per epoch'\n        return int(np.floor(len(self.indexes)\/ self.batch_size))\n    def __getitem__(self,index):\n        \"Generate one batch of data\"\n        indexes = self.indexes[index*self.batch_size:(index + 1)*self.batch_size]\n        \n        ## find List of ids \n        list_IDs_temp = [self.indexes[k] for k in indexes]\n        x,otherfeats,y = self.__data__generation(list_IDs_temp)\n        \n        return [x,otherfeats],y\n    \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.indexes))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data__generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim))\n        y = np.empty((self.batch_size,self.n_classes), dtype=int)\n        otherfeats = np.empty((self.batch_size,len(self.otherfeats)), dtype=int)\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            #img=cv2.imread(train_data_dir + ID)\n            img_initial = image.load_img(self.imgdir + self._dataF.loc[ID][self.X_col])\n            img = img_initial.resize((self.dim[:-1]))\n            img_array = image.img_to_array(img)\n            \n            samples = np.expand_dims(img_array, 0)\n            \n            aug_samples = self.augmen(samples)\n\n            \n            X[i,] = aug_samples\n\n            # Store class\n            y[i] = self._dataF.loc[ID][self.target] #self.labels[ID]  #y[i]\n            \n            otherfeats[i] = self._dataF[self.otherfeats].iloc[ID].values\n            \n            \n            \n#         print(f\"X shape is {X.shape} and otherf shape is {otherfeats.shape}\")\n\n        return X,otherfeats,y\n    ","49a7def1":"### Additional features\notherfeats = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']","a8623bfe":"imgg = customImageGen(rootDir + \"train\/\",train_df,'imagename',otherfeats,\"Pawpularity\",batch_size = 1,dim = (256,256,3),shuffle = True,n_channels = 3,flag = 'train')","d7e23917":"imgg.__getitem__(0)[0][0].shape","f3c4b087":"plt.imshow(imgg.__getitem__(0)[0][0][0])\n\nprint(imgg.__getitem__(0)[0][1],imgg.__getitem__(0)[1])","ad19bf3e":"batch_size = 32","71fa9326":"trainGen = customImageGen(rootDir + \"train\/\",train_df,'imagename',otherfeats,\"Pawpularity\",batch_size = batch_size,dim = \\\n                          (256,256,3),shuffle = True,n_channels = 3,flag = 'train')\nvalGen = customImageGen(rootDir + \"train\/\",valid_df,'imagename',otherfeats,\"Pawpularity\",batch_size = batch_size,dim = \\\n                        (256,256,3),shuffle = True,n_channels = 3,flag = 'val')","106935d2":"valGen.indexes.shape +trainGen.indexes.shape\n","aa4881cb":"# valGen.__getitem__(1)[0][0].shape,valGen.__getitem__(1)[0][1].shape\n\nfrom numpy.random import seed\nseed(1)","e001bf4a":"input_feat_tensor = tf.keras.Input(shape=len(otherfeats),name='feat_input')\n# imgsize = 224\nimport tensorflow.keras.backend as K\n\ndef root_mean_squared_error(y_true, y_pred):\n    y_true = float(y_true)\n    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n### CNN model for images\nimgsize = 128\ndef cnnmod():\n    # Create base model\n    #base_model =VGG16(weights = \"imagenet\",input_shape = (imgsize,imgsize,3), include_top = False ) \n    base_model = ResNet152(weights='..\/input\/tf-keras-pretrained-model-weights\/No Top\/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False,input_tensor=keras.Input(shape=(imgsize,imgsize,3)))\n    # Freeze base model\n    base_model.trainable = False\n    # Create new model on top.\n    inputs = keras.Input(shape=(imgsize, imgsize, 3))\n    x = base_model(inputs, training=False)\n#     x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n#     x = MaxPooling2D((2,2),padding='same')(x)\n#     x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n#     x = MaxPooling2D((2,2),padding='same')(x)\n#     x = Conv2D(256,(3,3),activation='relu',padding='same')(x)\n#     x = MaxPooling2D((2,2),padding='same')(x)\n#     x = GlobalAveragePooling2D()(x)\n#     x = Dense(64,activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = keras.layers.GlobalAveragePooling2D()(x)\n    x = Dense(2048,activation = 'relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1000, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    #x = Dense(600, activation='relu')(x)\n    #x = Dropout(0.5)(x)\n    x = Dense(300, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    \n    x = GlobalAveragePooling2D()(x)\n#     x = MaxPooling2D()(x)\n#     x = Flatten()(x)\n    x = Dense(500,activation='relu', name='final_outputcnn')(x)\n#     final_output = Dense(50, activation='relu', name='final_output')(x)\n#     outputs = Dense(8,activation='relu',name= \"lastcnnlayer\")(x)\n    model = tf.keras.Model(inputs, x)\n    return model\ncreatecnn = cnnmod()\n\n######## MLP model for tabular featues\ndef annmodel():\n    input_feat_tensor = tf.keras.Input(shape=len(otherfeats),name='feat_input')\n    x = Dense(8,activation = 'relu',kernel_initializer=tf.keras.initializers.HeNormal())(input_feat_tensor)\n    x = Dropout(0.5)(x)\n    #x = Dense(6,activation = 'relu',kernel_initializer=tf.keras.initializers.HeNormal())(input_feat_tensor)\n    #x = Dropout(0.5)(x)\n    model = tf.keras.Model(input_feat_tensor,x)\n    return model\ncreateann = annmodel()\n# conlayer = tf.keras.layers.Concatenate(axis=1)([createcnn.output,otherfeatsar ])\n# conlayer = tf.keras.layers.concatenate([createcnn.output, input_feat_tensor])\nconlayer = tf.keras.layers.concatenate([createcnn.output, createann.output])\nconlayer = BatchNormalization(name = \"conclayernorm\")(conlayer)\nconlayer = Dense(200,name = \"nonlinint\",activation = 'relu')(conlayer)\nconlayer = Dropout(0.5)(conlayer)\nconlayer = Dense(100,name = \"nonlinint2\",activation = 'relu')(conlayer)\nconlayer = Dropout(0.5)(conlayer)\nz  = Dense(1,activation='linear', name='final_output')(conlayer)\n# finalmod = Model(inputs = [createcnn.input,keras.layers.Input(shape=(12,))],outputs = z )\n# finalmod = Model(inputs = [createcnn.input,input_feat_tensor],outputs = z )\nfinalmod = Model(inputs = [createcnn.input,createann.input],outputs = z )\nfinalmod.compile(loss=[root_mean_squared_error], optimizer='adam',metrics=['mse']) ## custom rmse loss\n    \n    \n    \n","57b446b9":"finalmod.summary()","66b75ae2":"createcnn.output,createann.output,createcnn.input,createann.input","68db2dcf":"import datetime ,re\ndef cleaner(x):\n    x = re.sub(\"[^0-9]\",\"_\",x)\n    return x\n","4908656e":"dt2attch = cleaner(str(datetime.datetime.now()))\nfilepath=\".\/pawweights.best_{epoch:02d}-{val_loss:.2f}\" + \"_\" + dt2attch +\".hdf5\"\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', \n                             verbose=1, save_best_only=True, mode='auto')\n\nES_PATIENCE = 10\nRLROP_PATIENCE = 5\nDECAY_DROP = 0.3\nes = EarlyStopping(monitor='val_loss', mode='min', \n                   patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\nrlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', \n                          patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n\ncallback_list = [checkpoint,es,rlrop]","66a9bd20":"valGen.indexes.shape[0],trainGen.indexes.shape[0],valGen.indexes.shape[0]\/\/batch_size,trainGen.indexes.shape[0]\/\/batch_size\n","83116c22":"RunRes = finalmod.fit_generator(trainGen,steps_per_epoch=trainGen.indexes.shape[0]\/\/batch_size,validation_data=valGen,\n                                validation_steps=valGen.indexes.shape[0]\/\/batch_size,\n                                epochs = 50,callbacks=callback_list,verbose=1)\nprint(RunRes.history.keys())\nfig,axes = plt.subplots(2,2,figsize = (8,8))\naxes[0,0].plot(RunRes.history['loss'])\naxes[0,1].plot(RunRes.history['val_loss'])\naxes[1,0].plot(RunRes.history['mse'])\naxes[1,1].plot(RunRes.history['val_mse'])\nplt.show()\n","b70246ef":"### training model and saving weights. I am using few callbacks \n* Early stopping : To stop training if there is no decrease in validation loss after 8 epochs \n* Reduce learning rate on plateau : To decrease LR as training curve hits a plateau\n* Model checkpoint : To save model weights","c48f836e":"### Make sure you have keras trained weights downloaded in input directory using https:\/\/www.kaggle.com\/antoreepjana\/tf-keras-pretrained-model-weights .This will be useful as we are not supposed to use internet while running inference ","76079ab9":"Train and validation generator","56c78395":"## Base CNN model","43b61fa2":"Let's check if it is working fine","8e9ea084":"## Custom class to add Image features","88d677cf":"### Below written code can be used to utilize default keras Imagegenerator class but we can't add tabular features in it hence we would be writing a custome class. Also the following model is a vgg16 based transfer learning model","41dd8a7f":"### custom model to utlize both CNN and ANN"}}