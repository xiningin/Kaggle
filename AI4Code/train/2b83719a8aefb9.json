{"cell_type":{"877f5175":"code","62b0028c":"code","7d538d32":"code","979bb511":"code","e7740534":"code","2b4d2aa9":"code","3c00a883":"code","e8c54bac":"code","f5252ec6":"code","31b2b0f4":"code","d7873b14":"code","d6fbaab0":"code","5492476e":"code","c0ce1dfa":"code","a1c6534b":"code","9f15b64b":"code","e96eec4c":"code","2750936a":"code","a8b0cc62":"code","0f45a936":"code","18de8297":"code","5b098b09":"code","1479edf4":"code","b8d8770f":"code","b35f80b1":"code","ddc04a4c":"code","5655aef6":"markdown","08e4b048":"markdown","c794997f":"markdown","363d0df3":"markdown","bf738f50":"markdown","23e9d685":"markdown","adbb8555":"markdown"},"source":{"877f5175":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport json\nimport os\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","62b0028c":"biorxiv_dir = '\/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/pdf_json'\nfilenames = os.listdir(biorxiv_dir)\nprint(\"Number of articles retrieved from biorxiv:\", len(filenames))","7d538d32":"def load_files(dirname):\n    filenames = os.listdir(dirname)\n    raw_files = []\n\n    for filename in tqdm(filenames):\n        filename = dirname + filename\n        file = json.load(open(filename, 'rb'))\n        raw_files.append(file)\n    \n    return raw_files\n\ndef generate_clean_df(all_files):\n    cleaned_files = []\n    \n    for file in tqdm(all_files):\n        features = [\n            file['paper_id'],\n            file['metadata']['title'],\n            format_authors(file['metadata']['authors']),\n            format_authors(file['metadata']['authors'], \n                           with_affiliation=True),\n            format_body(file['abstract']),\n            format_body(file['body_text']),\n            format_bib(file['bib_entries']),\n            file['metadata']['authors'],\n            file['bib_entries']\n        ]\n\n        cleaned_files.append(features)\n\n    col_names = ['paper_id', 'title', 'authors',\n                 'affiliations', 'abstract', 'text', \n                 'bibliography','raw_authors','raw_bibliography']\n\n    clean_df = pd.DataFrame(cleaned_files, columns=col_names)\n    clean_df.head()\n    \n    return clean_df","979bb511":"def format_name(author):\n    middle_name = \" \".join(author['middle'])\n    \n    if author['middle']:\n        return \" \".join([author['first'], middle_name, author['last']])\n    else:\n        return \" \".join([author['first'], author['last']])\n\n\ndef format_affiliation(affiliation):\n    text = []\n    location = affiliation.get('location')\n    if location:\n        text.extend(list(affiliation['location'].values()))\n    \n    institution = affiliation.get('institution')\n    if institution:\n        text = [institution] + text\n    return \", \".join(text)\n\ndef format_authors(authors, with_affiliation=False):\n    name_ls = []\n    \n    for author in authors:\n        name = format_name(author)\n        if with_affiliation:\n            affiliation = format_affiliation(author['affiliation'])\n            if affiliation:\n                name_ls.append(f\"{name} ({affiliation})\")\n            else:\n                name_ls.append(name)\n        else:\n            name_ls.append(name)\n    \n    return \", \".join(name_ls)\n\ndef format_body(body_text):\n    texts = [(di['section'], di['text']) for di in body_text]\n    texts_di = {di['section']: \"\" for di in body_text}\n    \n    for section, text in texts:\n        texts_di[section] += text\n\n    body = \"\"\n\n    for section, text in texts_di.items():\n        body += section\n        body += \"\\n\\n\"\n        body += text\n        body += \"\\n\\n\"\n    \n    return body\n\ndef format_bib(bibs):\n    if type(bibs) == dict:\n        bibs = list(bibs.values())\n    bibs = deepcopy(bibs)\n    formatted = []\n    \n    for bib in bibs:\n        bib['authors'] = format_authors(\n            bib['authors'], \n            with_affiliation=False\n        )\n        formatted_ls = [str(bib[k]) for k in ['title', 'authors', 'venue', 'year']]\n        formatted.append(\", \".join(formatted_ls))\n\n    return \"; \".join(formatted)","e7740534":"all_files = []\n\nfor filename in filenames:\n    filename = biorxiv_dir +\"\/\"+ filename\n    file =json.load(open(filename, 'rb'))\n    all_files.append(file)\n\n    \n\n","2b4d2aa9":"def format_name(author):\n    middle_name = \" \".join(author['middle'])\n    \n    if author['middle']:\n        return \" \".join([author['first'], middle_name, author['last']])\n    else:\n        return \" \".join([author['first'], author['last']])\n\n\ndef format_affiliation(affiliation):\n    text = []\n    location = affiliation.get('location')\n    if location:\n        text.extend(list(affiliation['location'].values()))\n    \n    institution = affiliation.get('institution')\n    if institution:\n        text = [institution] + text\n    return \", \".join(text)\n\ndef format_authors(authors, with_affiliation=False):\n    name_ls = []\n    \n    for author in authors:\n        name = format_name(author)\n        if with_affiliation:\n            affiliation = format_affiliation(author['affiliation'])\n            if affiliation:\n                name_ls.append(f\"{name} ({affiliation})\")\n            else:\n                name_ls.append(name)\n        else:\n            name_ls.append(name)\n    \n    return \", \".join(name_ls)\n\ndef format_body(body_text):\n    texts = [(di['section'], di['text']) for di in body_text]\n    texts_di = {di['section']: \"\" for di in body_text}\n    \n    for section, text in texts:\n        texts_di[section] += text\n\n    body = \"\"\n\n    for section, text in texts_di.items():\n        body += section\n        body += \"\\n\\n\"\n        body += text\n        body += \"\\n\\n\"\n    \n    return body\n","3c00a883":"from tqdm.notebook import tqdm\n\ncleaned_files = []\n    \nfor file in tqdm(all_files):\n    features = [\n        file['paper_id'],\n        file['metadata']['title'],\n        format_authors(file['metadata']['authors']),\n        format_authors(file['metadata']['authors'], \n                       with_affiliation=True),\n        format_body(file['abstract']),\n        format_body(file['body_text']),\n\n    ]\n\n    cleaned_files.append(features)\n\ncol_names = ['paper_id', 'title', 'authors',\n             'affiliations', 'abstract', 'text',]\n\ndf = pd.DataFrame(cleaned_files, columns=col_names)\ndf.head()","e8c54bac":"df['abstract_word_count'] = df['abstract'].apply(lambda x: len(x.strip().split()))\ndf['body_word_count'] = df['text'].apply(lambda x: len(x.strip().split()))\ndf.head()","f5252ec6":"df.drop_duplicates(['abstract', 'text'], inplace=True)","31b2b0f4":"df.head(5)","d7873b14":"df.drop_duplicates(['title','abstract'], inplace=True)\ndf.shape","d6fbaab0":"#df = df.head(10000)","5492476e":"import re\n\ndf['text'] = df['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\ndf['abstract'] = df['abstract'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\ndf['text'] = df['text'].apply(lambda x: re.sub('\\n\\n',' ',x))\ndf['abstract'] = df['abstract'].apply(lambda x: re.sub('\\n\\n',' ',x))\ndf['text'] = df['text'].apply(lambda x: re.sub('\\d+', '',x))\ndf['abstract'] = df['abstract'].apply(lambda x: re.sub('\\d+', '',x))\n","c0ce1dfa":"\ndf['text'] = df['text'].apply(lambda x: x.lower())\ndf['abstract'] = df['abstract'].apply(lambda x: x.lower())\ndf.head(5)","a1c6534b":"text = df.drop([\"paper_id\", \"abstract\", \"abstract_word_count\", \"body_word_count\", \"authors\", \"title\", \"affiliations\"], axis=1)","9f15b64b":"text.head(5)","e96eec4c":"docs = []\nfor x in range(0,len(text)):\n    docs.append(str(text.iloc[x]['text']))","2750936a":"print(docs[5])","a8b0cc62":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n\nwith open('..\/input\/stopwords\/englishStopwords.txt', 'r') as f:\n    myLists = [line.strip() for line in f]\n\n               \nvectorizer = TfidfVectorizer(stop_words=myLists)\nX = vectorizer.fit_transform(docs)","0f45a936":"from sklearn.model_selection import train_test_split\n\n# test set size of 20% of the data and the random seed 42 <3\nX_train, X_test = train_test_split(X.toarray(), test_size=0.2, random_state=42)\n\nprint(\"X_train size:\", len(X_train))\nprint(\"X_test size:\", len(X_test), \"\\n\")","18de8297":"from sklearn.cluster import KMeans\n\nk = 10\nkmeans = KMeans(n_clusters=k, n_jobs=4, verbose=10)\ny_pred = kmeans.fit_predict(X_train)","5b098b09":"y_train = y_pred","1479edf4":"y_test = kmeans.predict(X_test)","b8d8770f":"outerlist = []\nwhile len(outerlist) < k:\n    outerlist.append([])","b35f80b1":"for x in docs:\n    Y = vectorizer.transform([x])\n    prediction = kmeans.predict(Y)\n    outerlist[int(prediction)].append(x)\n\norder_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\nterms = vectorizer.get_feature_names()\n\n\nindex = 0\n\n\nfor iter in outerlist:\n    print(\"DOCUMENTS GROUP %d\" % index)\n    print(iter[:1], sep=', ')\n    print(\" \")\n    \n    print(\"-----------------\")\n\n\n    print(\"GROUP DESCRIPTIVE KEYWORDS\" )\n    for ind in order_centroids[index, :10]:\n        print(' %s' % terms[ind]),\n    index = index + 1\n    print(\"-----------------\")\n\n","ddc04a4c":"from sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n    \nprint(model_name, \":\\n\")\nprint(\"Accuracy Score: \", '{:,.3f}'.format(float(accuracy_score(y_test, y_pred)) * 100), \"%\")\nprint(\"F1 score: \", '{:,.3f}'.format(float(f1_score(test, pred, average='micro')) * 100), \"%\")","5655aef6":"***Load Dataset***","08e4b048":"***Preprocessing***\n","c794997f":"***Drop dublicates data from text and abstract data***","363d0df3":"***Helper Functions***","bf738f50":"***Remove Stopwords***","23e9d685":"***Helper Functions***","adbb8555":"***Import Packages***"}}