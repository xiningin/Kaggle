{"cell_type":{"1424e9df":"code","43c7433d":"code","069457ee":"code","63ec89d9":"code","a84752f0":"code","90094e6c":"code","950ac4b9":"code","9e225bdc":"code","26f0ac6b":"markdown","5108cfa3":"markdown"},"source":{"1424e9df":"import numpy as np\nimport pandas as pd\nimport os\nimport multiprocessing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom scipy.special import erfc\nimport scipy\nwarnings.simplefilter('ignore')\nplt.style.use('seaborn')\nfor package in [pd, np, scipy, sns]:\n    print(package.__name__, 'version:', package.__version__)\nprint(os.listdir(\"..\/input\"))","43c7433d":"def load_dataframe(dataset):\n    return pd.read_csv(dataset)\n\nwith multiprocessing.Pool() as pool:\n    train, test = pool.map(load_dataframe, ['..\/input\/train.csv', '..\/input\/test.csv'])","069457ee":"def chauvenet(array):\n    mean = array.mean()           # Mean of incoming array\n    stdv = array.std()            # Standard deviation\n    N = len(array)                # Lenght of incoming array\n    criterion = 1.0\/(2*N)         # Chauvenet's criterion\n    d = abs(array-mean)\/stdv      # Distance of a value to mean in stdv's\n    prob = erfc(d)                # Area normal dist.    \n    return prob < criterion       # Use boolean array outside this function","63ec89d9":"train_outliers = dict()\nfor col in [col for col in train.columns if 'var_' in col]:\n    train_outliers[col] = train[chauvenet(train[col].values)].shape[0]\ntrain_outliers = pd.Series(train_outliers)\n\ntrain_outliers.sort_values().plot(figsize=(14, 40), kind='barh').set_xlabel('Number of outliers');","a84752f0":"print('Total number of outliers in training set: {} ({:.2f}%)'.format(sum(train_outliers.values), (sum(train_outliers.values) \/ train.shape[0]) * 100))","90094e6c":"test_outliers = dict()\nfor col in [col for col in test.columns if 'var_' in col]:\n    test_outliers[col] = test[chauvenet(test[col].values)].shape[0]\ntest_outliers = pd.Series(test_outliers)\n\ntest_outliers.sort_values().plot(figsize=(14, 40), kind='barh').set_xlabel('Number of outliers');","950ac4b9":"print('Total number of outliers in testing set: {} ({:.2f}%)'.format(sum(test_outliers.values), (sum(test_outliers.values) \/ test.shape[0]) * 100))","9e225bdc":"rows = train_outliers.sort_values(ascending=False).head().index.shape[0]\nfig, axes = plt.subplots(nrows=rows, ncols=2, figsize=(14, rows * 6))\nfor i, col in enumerate(train_outliers.sort_values(ascending=False).head().index):\n    sns.distplot(train[(train['target'] == 1)][col].values, ax=axes[i, 0], axlabel='Before', color='orange', label='1');\n    sns.distplot(train[(train['target'] == 0)][col].values, ax=axes[i, 0], label='0');\n    sns.distplot(train[(~chauvenet(train[col].values)) & (train['target'] == 1)][col].values, ax=axes[i, 1], axlabel='After', color='orange', label='1');\n    sns.distplot(train[(~chauvenet(train[col].values)) & (train['target'] == 0)][col].values, ax=axes[i, 1], label='0');\n    axes[i, 0].set_title(col, fontsize=16)\n    axes[i, 0].legend()\n    axes[i, 1].legend()","26f0ac6b":"I have decided to see if there are any outliers in the dataset according to [Chauvenet's criterion](https:\/\/en.wikipedia.org\/wiki\/Chauvenet%27s_criterion)\n\nAn observation $P_i$ is an outlier if the following equation is true:\n$$erfc\\Bigg(\\frac{|P_i - \\bar{P}|}{S_p}\\Bigg) < \\frac{1}{2n}$$\n\n$$erfc(x) = \\frac{2}{\\sqrt{\\pi}} \\int_x^\\infty \\mathrm{e}^{-t^2}\\;\\mathrm{d}t$$","5108cfa3":"Plots with a distribution for 5 top features before removing an outliers and after removing them."}}