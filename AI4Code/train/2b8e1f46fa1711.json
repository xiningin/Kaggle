{"cell_type":{"f7a6f214":"code","ac053ed0":"code","e839a1c3":"code","599b896a":"code","8d582394":"code","ad421a0f":"code","da43db21":"code","dc7d326e":"code","133602ad":"code","6e61582e":"code","aa6dc800":"code","ac456742":"code","7f660fcf":"code","0f9cfe81":"code","1bacdb2b":"code","f442e75d":"code","cb27a53b":"code","b4ca7267":"code","f0927adf":"code","7616a5b1":"code","240f2411":"code","9020403d":"code","2836d94c":"code","9e5ffd89":"code","c59d2e1c":"code","7b67a670":"code","70726aee":"code","d7f2280b":"code","1bec39ee":"code","f8ee3071":"code","9725cbc1":"code","0a1ca50f":"code","ee449b34":"code","06bbc5e3":"code","76988451":"code","be38874d":"code","8dc9bc0c":"code","616c1ddc":"code","ccc47e25":"code","f22c860f":"code","66b82c06":"code","156693c8":"code","a4791168":"code","41a32a68":"code","6c22f545":"code","fdb15159":"markdown","0f38e1a7":"markdown","71f5c674":"markdown","5be7aad8":"markdown","de1942e1":"markdown","885f5290":"markdown","2ff6c875":"markdown","4c2d790b":"markdown","1bf22e82":"markdown","0897f1c0":"markdown","710e9d08":"markdown","8c2a3373":"markdown","ffd55449":"markdown","92de534e":"markdown","39ac0e66":"markdown"},"source":{"f7a6f214":"import tensorflow as tf\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tqdm import tqdm\n\nimport tensorflow.keras.backend as K\nfrom mpl_toolkits.axes_grid1 import ImageGrid","ac053ed0":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nbatch_size=16\nimg_size=256","e839a1c3":"pth='..\/input\/imagenet\/imagenet'\npth_mask='..\/input\/inpainting-mask-generator\/mask'\n\n#train\ntrain_folder=sorted(os.listdir(f'{pth}\/train'))\ntrain_mask_folder=sorted(os.listdir(f'{pth_mask}\/train'))\ndf_train=pd.DataFrame(np.vstack([train_folder,train_mask_folder]).T,columns=['pth','pth_mask'])\ndf_train['pth']=df_train['pth'].apply(lambda x: os.path.join(f'{pth}\/train\/{x}'))\ndf_train['pth_mask']=df_train['pth_mask'].apply(lambda x: os.path.join(f'{pth_mask}\/train\/{x}'))\n\n\n#val\nval_folder=sorted(os.listdir(f'{pth}\/val'))\nval_mask_folder=sorted(os.listdir(f'{pth_mask}\/val'))\ndf_val=pd.DataFrame(np.vstack([val_folder,val_mask_folder]).T,columns=['pth','pth_mask'])\ndf_val['pth']=df_val['pth'].apply(lambda x: os.path.join(f'{pth}\/val\/{x}'))\ndf_val['pth_mask']=df_val['pth_mask'].apply(lambda x: os.path.join(f'{pth_mask}\/val\/{x}'))","599b896a":"def get_image(path,path_mask):\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image=tf.cast(tf.image.resize(image,(img_size,img_size)),'float32')\n    image=image\/255.\n    \n    mask = tf.image.decode_jpeg(tf.io.read_file(path_mask), channels=3)\n    mask=tf.cast(tf.image.resize(mask,(img_size,img_size)),'float32')\n    mask=mask\/255.\n    return image,mask","8d582394":"ds_train=tf.data.Dataset.from_tensor_slices((df_train['pth'],df_train['pth_mask'])).map(get_image,num_parallel_calls=AUTOTUNE).\\\n                        batch(batch_size,drop_remainder=True)\n\nds_val=tf.data.Dataset.from_tensor_slices((df_val['pth'],df_val['pth_mask'])).map(get_image,num_parallel_calls=AUTOTUNE).\\\n                        batch(batch_size,drop_remainder=True)","ad421a0f":"im,m=next(iter(ds_train))","da43db21":"fig,ax=plt.subplots(ncols=3,figsize=(12,12))\nimm=im*m+(1-m)\nax[0].imshow(im[-1])\nax[1].imshow(imm[-1])\nax[2].imshow(m[-1])\nplt.show()","dc7d326e":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ndef VGG():\n    #pool1, pool2 and pool3 for both perceptual loss & style loss\n    vgg16=VGG16(include_top=False,weights=None)\n    vgg16.load_weights('..\/input\/vgg16-weights\/pytorch_to_keras_vgg16.h5',by_name=True)\n    vgg16.trainable=False\n    \n    #layer_names=['block1_pool','block2_pool','block3_pool']\n    layer_names=['block1_conv2','block2_conv2','block3_conv3']\n    outputs = [vgg16.get_layer(name).output for name in layer_names]\n    \n    return tf.keras.Model([vgg16.input], outputs)\n\nvgg=VGG()","133602ad":"def l1(y_true, y_pred):\n    if K.ndim(y_true) == 4:\n        return K.mean(K.abs(y_pred - y_true), axis=[1,2,3])\n    elif K.ndim(y_true) == 3:\n        return K.mean(K.abs(y_pred - y_true), axis=[1,2])\n\n\ndef gram_matrix(x):\n    # Permute channels and get resulting shape\n    x = tf.transpose(x, perm=(0, 3, 1, 2))\n    shape = tf.shape(x)\n    B, C, H, W = shape[0], shape[1], shape[2], shape[3]\n        \n    # Reshape x and do batch dot product\n    features = tf.reshape(x, tf.stack([B, C, H*W]))\n    gram = tf.keras.backend.batch_dot(features, features, axes=2)\n        \n    # Normalize with channels, height and width\n    gram = gram \/  tf.cast(C * H * W, x.dtype)\n        \n    return gram","6e61582e":"#@tf.function\ndef Update(vgg_style,C,optimizer,layer,useall):\n\n    with tf.GradientTape() as tape:\n        vgg_C=vgg((C-mean)\/std)\n        if useall:\n            cost=0\n            for o, g in zip(vgg_C, vgg_style):\n                cost += l1(gram_matrix(o), gram_matrix(g))\n        else:\n            cost=l1(gram_matrix(vgg_style[layer]),gram_matrix(vgg_C[layer]))\n    grad=tape.gradient(cost,[C])\n    optimizer.apply_gradients(zip(grad,[C]))\n    return cost\n\n\ndef style_reconstruction(pth,style,vgg,layer,iters=20,useall=False):\n    '''\n    layer:0~2 \n    style:(1,imsize,imsize,3)\n    '''\n    C=tf.Variable(tf.random.uniform(style.shape),trainable=True)  #initialize by random uniform noise\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2)\n    vgg_style=vgg((style-mean)\/std)\n    #try:\n        #os.makedirs(pth)\n    #except:\n        #pass\n    loop=tqdm(range(iters))\n    for i in loop:\n        cost=Update(vgg_style,C,optimizer,layer,useall)\n        #tf.keras.utils.save_img(f'{pth}\/{i}.jpg',C[0])\n        loop.set_postfix(style_cost=cost)\n    return C","aa6dc800":"C=tf.random.uniform((img_size,img_size,3))","ac456742":"plt.figure(figsize=(8,8))\nplt.imshow(C)\nplt.show()","7f660fcf":"imidx=-7 #choose image\niters=1500","0f9cfe81":"pth='.\/block1_conv2'\nC1=style_reconstruction(pth,tf.expand_dims(im[imidx],axis=0),vgg,0,iters)","1bacdb2b":"fig,ax=plt.subplots(ncols=2,figsize=(16,16))\nax[0].imshow(C1[0],vmax=1,vmin=0)\nax[1].imshow(im[imidx],vmax=1,vmin=0)\nplt.show()","f442e75d":"pth='.\/block2_conv2'\nC2=style_reconstruction(pth,tf.expand_dims(im[imidx],axis=0),vgg,1,iters)","cb27a53b":"fig,ax=plt.subplots(ncols=2,figsize=(16,16))\nax[0].imshow(C2[0],vmax=1,vmin=0)\nax[1].imshow(im[imidx],vmax=1,vmin=0)\nplt.show()","b4ca7267":"pth='.\/block3_conv3'\nC3=style_reconstruction(pth,tf.expand_dims(im[imidx],axis=0),vgg,2,iters)","f0927adf":"fig,ax=plt.subplots(ncols=2,figsize=(16,16))\nax[0].imshow(C3[0],vmax=1,vmin=0)\nax[1].imshow(im[imidx],vmax=1,vmin=0)\nplt.show()","7616a5b1":"pth='.\/mixing'\nC4=style_reconstruction(pth,tf.expand_dims(im[imidx],axis=0),vgg,2,1000,iters)","240f2411":"fig,ax=plt.subplots(ncols=2,figsize=(16,16))\nax[0].imshow(C4[0],vmax=1,vmin=0)\nax[1].imshow(im[imidx],vmax=1,vmin=0)\nplt.show()","9020403d":"Fmap=vgg((im-mean)\/std)","2836d94c":"plt.figure(figsize=(8,8))\nplt.imshow(im[imidx])\nplt.show()","9e5ffd89":"img=Fmap[0][imidx]\nims=[img[...,i] for i in range(Fmap[0].shape[-1])]\nfig = plt.figure(figsize=(16., 16))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(8, 8),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n\nfor ax,x in zip(grid,ims):\n    ax.axis('off')\n    ax.imshow(x,cmap='gray')\nplt.show()","c59d2e1c":"model_bn=tf.keras.models.load_model('..\/input\/inpainting-models\/model_bn_fine\/model_bn_fine')","7b67a670":"imidx=2","70726aee":"layer_names=[\n    'inputs_img',  \n    'up_sampling2d_14',\n    'p_conv2d_15', #pconv(concat[inputs_img,upsampling14])\n    'leaky_re_lu_7',\n    'outputs_img'\n]","d7f2280b":"def get_feature_maps(model,layer_names):\n    outputs = [model.get_layer(name).output for name in layer_names]\n    return tf.keras.Model(inputs=model.inputs,outputs=outputs)","1bec39ee":"mapper_bn=get_feature_maps(model_bn,layer_names)","f8ee3071":"im_masked=im*m+(1-m)\nFmap=mapper_bn([im_masked,m])","9725cbc1":"fig,ax=plt.subplots(ncols=4,figsize=(16,16))\nax[0].imshow(im[imidx])\nax[0].set_title('origin')\nax[0].axis('off')\n\n\nax[1].imshow(m[imidx])\nax[1].set_title('mask')\nax[1].axis('off')\n\n\nax[2].imshow(im_masked[imidx])\nax[2].set_title('masked image')\nax[2].axis('off')\n\nax[3].imshow(Fmap[-1][imidx])\nax[3].set_title('prediction')\nax[3].axis('off')\nplt.show()","0a1ca50f":"def showmap(Fmap,mask=False):\n    img=Fmap\n    ims=[img[...,i] for i in range(Fmap.shape[-1])]\n    fig = plt.figure(figsize=(16., 16))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(8, 8),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n    for ax,x in zip(grid,ims):\n        ax.axis('off')\n        if mask:\n            ax.imshow(x,cmap='gray',vmin=0.,vmax=1.)\n        else:\n            ax.imshow(x,cmap='gray')\n    plt.show()","ee449b34":"print(Fmap[0][imidx].shape)\nshowmap(Fmap[0][imidx])","06bbc5e3":"print(Fmap[1][imidx].shape)\nshowmap(Fmap[1][imidx])","76988451":"#pconv kernel 15\nprint('kernel:',model_bn.trainable_variables[-4].shape) \nprint('bias:',model_bn.trainable_variables[-3].shape) ","be38874d":"print(Fmap[2][1][imidx].shape)\nshowmap(Fmap[2][1][imidx])","8dc9bc0c":"print(Fmap[2][0][imidx].shape)\nshowmap(Fmap[2][0][imidx])","616c1ddc":"print(Fmap[3][imidx].shape) \nshowmap(Fmap[3][imidx])","ccc47e25":"#last kernel \nprint('kernel:',model_bn.trainable_variables[-2]) #padding 1 (1,1,3,3) --> 3x3 filters with 1x1 kernel size  3\u7d443\u500b1x1\u7684kernel\nprint('bias:',model_bn.trainable_variables[-1]) \n\n#tf.keras.layers.Conv2D(filters=3,kernel_size=1,padding='same',strides=1)","f22c860f":"print(Fmap[4][imidx].shape) \nshowmap(Fmap[4][imidx])","66b82c06":"texture=Fmap[-1][imidx]*(1-m)\n\nplt.imshow(texture[imidx])","156693c8":"pconv_names=[layer.name  for layer in model_bn.layers if 'p_conv' in layer.name]","a4791168":"pconv_mapper=get_feature_maps(model_bn,pconv_names)","41a32a68":"im_masked=im*m+(1-m)\nPconvmap=pconv_mapper([im_masked,m])","6c22f545":"for name,pconv in zip(pconv_names,Pconvmap):\n    print(name)\n    showmap(pconv[0][imidx])\n    showmap(pconv[1][imidx],True)","fdb15159":"### Third Block Layer","0f38e1a7":"# Model Architecture Exploring","71f5c674":"## Unet (BatchNormalization)","5be7aad8":"### Second Block Layer","de1942e1":"## Dataset","885f5290":"## Show Featuemap & Mask","2ff6c875":"### Initial random noise","4c2d790b":"### First Block Layer","1bf22e82":"## Inception Score","0897f1c0":"# Perceptual feature","710e9d08":"# Vgg16 & Gram Matrix & Texture Generation","8c2a3373":"We are going to solve optimization problem : \n  * Find a signal C which has minimum gram matrix distance to the style image \n  \n  \n$$min_C ||G^l_{style}-G^l_{C}||$$","ffd55449":"### Combine ","92de534e":"#### 256x256x64 feature in VGG16","39ac0e66":"## Generate Textures From Different Level Feature Maps In VGG16"}}