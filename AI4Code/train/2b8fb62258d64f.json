{"cell_type":{"153d1abb":"code","19cdeb4a":"code","e2ed4203":"code","5305d01c":"code","ade190f9":"code","52af847c":"code","0c4b294d":"code","2e74b1fe":"code","a4fee8a7":"code","5ceaee9f":"code","85576b25":"code","a3fba198":"code","f3d32653":"code","672919bf":"code","a848acb8":"code","7f1306ac":"code","de7b7dc2":"code","f4a04bb9":"code","cc1a27bd":"code","a656f342":"markdown","46a61472":"markdown","e3f1981b":"markdown","19eeec6e":"markdown","27e8f06f":"markdown","65b04675":"markdown","dac07b32":"markdown","871ff3fc":"markdown","65fb6f5d":"markdown","51e90b62":"markdown","f826bf54":"markdown"},"source":{"153d1abb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, SubsetRandomSampler, Subset, WeightedRandomSampler\nimport torchvision\nfrom torch.autograd import Variable\nfrom torchvision.datasets import ImageFolder, DatasetFolder\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport os\nimport seaborn as sns\n\nimport PIL\nfrom PIL import Image\nimport warnings\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","19cdeb4a":"image_transforms = transforms.Compose(\n                   [transforms.Resize((32,32)),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])","e2ed4203":"MAIN = '..\/input\/face-mask-dataset\/data'","5305d01c":"dataset = ImageFolder(\n                      root = MAIN,\n                      transform = image_transforms\n                       )\ndataset","ade190f9":"dataset.class_to_idx\n\ndataset.class_to_idx = {'with_mask':1, 'without_mask':0}\ndataset.class_to_idx","52af847c":"idx2class = {v: k for k, v in dataset.class_to_idx.items()}\nidx2class","0c4b294d":"def get_class_distribution(dataset_obj):\n    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n    \n    for element in dataset_obj:\n        y_lbl = element[1]\n        y_lbl = idx2class[y_lbl]\n        count_dict[y_lbl] += 1\n            \n    return count_dict\nprint(\"Distribution of classes: \\n\", get_class_distribution(dataset))","2e74b1fe":"plt.figure(figsize=(15,8))\nsns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(dataset)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\").set_title('Face Mask Class Distribution')\nplt.show()","a4fee8a7":"train_dataset, val_dataset = random_split(dataset, (6000, 1553))","5ceaee9f":"train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=4, num_workers=2)\nval_loader = DataLoader(dataset=val_dataset, shuffle=False, batch_size=4, num_workers=2)\nprint(\"Length of the train_loader:\", len(train_loader))\nprint(\"Length of the val_loader:\", len(val_loader))","85576b25":"def imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nclasses = ('with_mask', 'without_mask')\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","a3fba198":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()","f3d32653":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","672919bf":"def images_to_probs(net, images):\n    output = net(images)\n    # convert output probabilities to predicted class\n    _, preds_tensor = torch.max(output, 1)\n    preds = np.squeeze(preds_tensor.numpy())\n    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n\ndef evaluate(net, dataloader):\n    correct, total = 0, 0\n    with torch.no_grad():\n        net.eval()\n        for images, labels in dataloader:\n            images, labels = images, labels.numpy()\n\n            preds, probs = images_to_probs(net, images)\n\n            total += len(labels)\n            correct += (preds == labels).sum()\n    return correct\/total * 100\n\nfrom tqdm.notebook import tqdm\n\ndef train(net, loss_fn, opt, dataloader, epochs):\n    num_steps = 0\n    min_loss = 1e+10\n\n    for epoch in tqdm(range(1, epochs+1), total=epochs, desc='Training'):\n        running_loss = []\n        net.train() # Setting the network to TRAIN mode\n        for images, labels in dataloader:\n            images, labels = images, labels\n            num_steps += 1\n\n            # FP\n            outs = net(images)\n            loss = loss_fn(outs, labels)\n\n            # Logging the loss value\n            running_loss.append(loss.item())\n\n            # BP\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n\n            # Clearing the RAM\n            #del images, labels, outs\n            #torch.device('cpu').empty_cache()\n        \n        epoch_loss = sum(running_loss) \/ len(running_loss)\n        acc = evaluate(net, dataloader)\n        print(\"Accuracy: \",acc)\n        print(\"loss: \",epoch_loss)\n        # Model Checkpointing\n        if epoch_loss < min_loss:\n            min_loss = epoch_loss\n            bestmodel = net.state_dict()\n    #torch.save(bestmodel,'{0}_{1:0.4f}.pth'.format('classifier',min_loss))\n    return None\n\n    print('Training finished!!!')","a848acb8":"train(net, criterion, optimizer, train_loader, 2)","7f1306ac":"testimg, testlab = next(iter(val_loader))\ntestimg, testlab = testimg, testlab\n\npred = net(testimg)\npredlab = torch.argmax(pred,axis=1)","de7b7dc2":"print(\"Predicted\",[i for i in predlab])\nprint(\"Actual\",[i for i in testlab])\nfor i in predlab:\n  if i == 0:\n    print(\"without_mask\")\n  else:\n    print(\"with_mask\")\nprint(\"______________________________________________________________________________________________________________\")\nfor i in testlab:\n  if i == 0:\n    print(\"without_mask\")\n  else:\n    print(\"with_mask\")","f4a04bb9":"predlab = predlab.to(torch.device('cpu'))\ntestlab = testlab.to(torch.device('cpu'))\npred = predlab.numpy()\ntest = testlab.numpy()\nmatrix = confusion_matrix(test,pred)\nprint(matrix)","cc1a27bd":"report = classification_report(test, pred, target_names=['with_mask','without_mask'])\nprint(report)  ","a656f342":"# Defining Neural Network","46a61472":"# Training Neural Network","e3f1981b":"## Face Mask Detection\n\nWith face masks becoming the new normal now. The abundance of detecting face masks have also seen a big surge in popularity as well and this is something I tried as I started learning PyTorch.\n\n**NOTE:** I'm still a big noob in PyTorch so I am open to any kind of feedback :)","19eeec6e":"## Confusion Matrix","27e8f06f":"## Random few images","65b04675":"# Testing Neural Network","dac07b32":"# Splitting into Train and Validation Set","871ff3fc":"Currently learning how to do it for the whole validation set. Since batch_size = 4, we get this output.","65fb6f5d":"# Reordering Classes","51e90b62":"# Final Metrics","f826bf54":"# Classification Report"}}