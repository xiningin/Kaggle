{"cell_type":{"074ea0f2":"code","c8f20878":"code","f5d0641a":"code","568d83fa":"code","47b58ec2":"code","fcf74590":"code","bce35aa2":"code","780478bd":"code","42d929df":"code","bb526e96":"code","420b95a1":"code","bd9f2c78":"code","44db12f3":"code","4084d3b2":"code","03045936":"code","9617be29":"code","d92f1562":"code","26d2ddf4":"code","5eb4a90a":"code","685d4923":"code","da515159":"code","b7c2f902":"markdown","d1604480":"markdown","29fdc70e":"markdown","2a140901":"markdown","bfb5cb74":"markdown","97fd969d":"markdown","eb7cb021":"markdown","7aa1f92b":"markdown","1301547e":"markdown","c6ccec38":"markdown","418983bf":"markdown","7ef8b39c":"markdown","959f353a":"markdown","112bcbd5":"markdown","74613a68":"markdown","3e14676a":"markdown","3aaf0a7b":"markdown","294d2333":"markdown","902bee45":"markdown","08808b44":"markdown","89ce0cd7":"markdown","17006537":"markdown","d2f8ac58":"markdown","aabfe14c":"markdown","16690ea5":"markdown","cfd84c34":"markdown","1198b08b":"markdown","de287f13":"markdown","44515420":"markdown","5bde4805":"markdown","b5fad74e":"markdown","6ce724d4":"markdown","09f9bbd5":"markdown","37591511":"markdown","6738647d":"markdown","fddc437f":"markdown","1353b45d":"markdown","e97a3616":"markdown","a673ba0d":"markdown","c113097b":"markdown","97deaaa9":"markdown","219d5241":"markdown"},"source":{"074ea0f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8f20878":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import KFold\nimport itertools\nimport os\nimport shutil\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","f5d0641a":"train_path = '\/kaggle\/input\/cat-and-dog\/training_set\/training_set'\n# valid_path = 'data\/dogs-vs-cats\/valid'\ntest_path = '..\/input\/cat-and-dog\/test_set\/test_set'","568d83fa":"train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['cats', 'dogs'], batch_size=10)\ntest_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['cats', 'dogs'], batch_size=10, shuffle=False)","47b58ec2":"imgs, labels = next(train_batches)","fcf74590":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","bce35aa2":"plotImages(imgs)\nprint(labels)","780478bd":"model = Sequential([\n    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(224,224,3)),\n    MaxPool2D(pool_size=(2, 2), strides=2),\n    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n    MaxPool2D(pool_size=(2, 2), strides=2),\n    Flatten(),\n    Dense(units=2, activation='softmax')\n])","42d929df":"model.summary()","bb526e96":"model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","420b95a1":"model.fit(x=train_batches, epochs=5, verbose=2)","bd9f2c78":"test_imgs, test_labels = next(test_batches)","44db12f3":"plotImages(test_imgs)\nprint(test_labels)","4084d3b2":"predictions = model.predict(x=test_batches, verbose=0)","03045936":"np.round(predictions)","9617be29":"cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))","d92f1562":"cm","26d2ddf4":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","5eb4a90a":"test_batches.class_indices","685d4923":"cm_plot_labels = ['cat','dog']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","da515159":"no_classes = 100\nno_epochs = 5\n# optimizer = Adam()\nverbosity = 1\nnum_folds = 5\n# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor train, test in kfold.split(imgs, labels):\n\n  # Define the model architecture\n    model = Sequential([\n    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(224,224,3)),\n    MaxPool2D(pool_size=(2, 2), strides=2),\n    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n    MaxPool2D(pool_size=(2, 2), strides=2),\n    Flatten(),\n    Dense(units=2, activation='softmax')])\n\n  # Compile the model\n    model.compile(optimizer=Adam(learning_rate=0.0001),\n                  loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n  # Fit data to model\n    history = model.fit(x=train_batches, epochs=5, verbose=2)\n\n  # Generate generalization metrics\n    scores = model.evaluate(imgs[test], labels[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n\n  # Increase fold number\n    fold_no = fold_no + 1\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n","b7c2f902":"Libraries","d1604480":"We can then inspect the `class_indices` for the labels so that we know in which order to pass them to our confusion matrix.","29fdc70e":"We now use the plot_confusion_matrix() function that is copied directly from scikit-learn","2a140901":"these all tutorials are inspired from this [channel](https:\/\/www.youtube.com\/watch?v=LhEMXbjGV_4&list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL&index=11)","bfb5cb74":"We create the confusion matrix using `scikit-learn`","97fd969d":"# optional - how to do cross validation?","eb7cb021":"We\u2019re specifying `5` as the number of `epochs` we\u2019d like to run, and setting the `verbose` parameter to `2`, which just specifies the verbosity of the log output printed to the console during training.","7aa1f92b":"Now that the model is built, we `compile` the model using the `Adam optimizer` with a learning rate of `0.0001`, a loss of `categorical_cross_entropy`, and we\u2019ll look at `accuracy` as our performance metric. ","1301547e":"Now we\u2019ll use our previously built model and call model.predict() to have the model predict on the test set.","c6ccec38":"After running the predictions, we can print our the rounded predictions see what they look like.","418983bf":"This is what the first processed random batch from the training set looks like. Notice that the color appears to be distorted. This has to do with the VGG16 processing we applied to the data sets, which we'll talk about in few minutes. Don't worry about it for now, just know that the RGB pixel data has been processed in such a way that the image data now looks like this before being passed to the network.","7ef8b39c":"# Visualize the data\n\nWe now call `next(train_batches)` to generate a batch of images and labels from the training set. Note that the size of this batch is determined by the `batch_size` we set when we created `train_batches`.","959f353a":"We transform the one-hot encoded predicted labels to be in the same format as the true labels by only selecting the element with the highest value for each prediction using `np.argmax(predictions, axis=-1)`.","112bcbd5":"Note that when we have only two classes, we could instead configure our output layer to have only one output, rather than two, and use `binary_crossentropy` as our loss, rather than `categorical_crossentropy`. Both options work equally well and achieve the exact same result.\n\nWith `binary_crossentropy`, however, the last layer would need to use <font color='orange'>sigmoid<\/font>, rather than <font color='dark pink'>softmax<\/font>, as its activation function.","74613a68":"We\u2019ll now run `next(test_batches)` to extract a batch of images and their corresponding labels from the test set.","3e14676a":"Now that we have a general understanding for how to build and work with a CNN using Keras, we'll now move on to working with a pre-trained model on this data set, which we will see will generalize much better!","3aaf0a7b":"Note, we can access the unshuffled true labels for the test set by calling `test_batches.classes`.","294d2333":"### <font color = 'green'>Preparing the Train Data<\/font>","902bee45":"We can see that the model correctly predicted that an image was a cat `620` times when it actually was a cat, and it incorrectly predicted that an image was a cat `391` times when it was not a cat. It correctly predicted that an image was a dog `768` times, and incorrectly predicted that an image was a dog `244` times.","08808b44":"From this output, we can see the performance of this simple model on the training set is great, with accuracy reaching almost 100% and loss nearing almost 0,we can see that our model is vastly overfitting the training data.\n\nAt this point, we could continue to work on this model to combat overfitting, or we could try another approach of using a pre-trained model on this data. We'll explore the latter in the upcoming cells.","89ce0cd7":"To get a better visualization of these results, we\u2019ll plot them in a confusion matrix.","17006537":"Just as we saw before, cats are labeled with a one-hot encoding of `[1,0]`, and dogs are labeled as `[0,1]`.\n\nNote, because we chose to not shuffle our test set when we originally created it, the first half of the test data is all cats, and the second half is all dogs. Also, recall that the color data appears skewed due to the VGG16 preprocessing we specified when we created the data sets.","d2f8ac58":"![](https:\/\/keras.io\/img\/logo.png)","aabfe14c":"1. <font color='red'>ImageDataGenerator.flow_from_directory()<\/font> creates a DirectoryIterator, which generates batches of normalized tensor image data from the respective data directories.\n2. Notice, to ImageDataGenerator for each of the data sets, we specify <font color='red'>preprocessing_function=tf.keras.applications.vgg16.preprocess_input<\/font>. For now, just understand this does an additional processing step on the images. We'll cover what exactly this processing is when we work with the pre-trained VGG16 CNN in a future episode.\n3. To <font color = 'red'>flow_from_directory()<\/font>, we first specify the path for the data. We then specify the target_size of the images, which will resize all images to the specified size. The size we specify here is determined by the input size that the neural network expects.\n4. The <font color = 'red'>classes<\/font> parameter expects a list that contains the underlying class names, and lastly, we specify the batch_size.\n5. We also specify <font color = 'red'>shuffle=False<\/font> only for <font color = 'red'>test_batches<\/font>. That's because, later when we plot the evaluation results from the model to a <font color = 'red'>confusion matrix<\/font>,we'll need to able to access the unshuffled labels for the test set. By default, the data sets are shuffled\n6. <font color = 'blue'>Note, in the case where you do not know the labels for the test data, you will need to modify the `test_batches` variable. Specifically, the change will be to set the parameters `classes = None` and `class_mode = None` in `flow_from_directory()`.<\/font>","16690ea5":"### <font color = 'green'>Preparing the Test Data<\/font>","cfd84c34":"# Make Predictions With A Keras CNN Image Classifier","1198b08b":"#### Finally, we plot the confusion matrix.","de287f13":"To build the CNN, we\u2019ll use a Keras Sequential model. Recall, we first introduced a Sequential model in an earlier [tutorial](https:\/\/www.kaggle.com\/bavalpreet26\/keras-nb1)","44515420":"Using the `plotImages()` function we previously introduced, we can see what this batch of test data looks like","5bde4805":"To the confusion matrix, we pass the true labels of the test set, along with the predicted labels for the test set from the model.","b5fad74e":"Note that dogs are represented with the `one-hot encoding` of `[0,1]`, and cats are represented by `[1,0]`","6ce724d4":"Now it\u2019s time to train the model.\n\nWe've already introduced the `model.fit()` function to train a model in above cells. We'll be using it in the same fashion here, except for now, we'll be passing in our newly introduced `DirectoryIterators` `train_batches`to train the model.","09f9bbd5":"# Predicting On The Test Data","37591511":"# Train A Simple CNN","6738647d":"We\u2019re now all set up to work with this data!, we\u2019ll now use this data to train a convolutional neural network.","fddc437f":"We then use this plotting function obtained from `TensorFlow's documentation` to plot the processed images within our Jupyter notebook.","1353b45d":"# Build A Simple CNN","e97a3616":"These are the labels that the model is predicting for our images.","a673ba0d":"This is part 2 for keras series click here for [part1](https:\/\/www.kaggle.com\/bavalpreet26\/keras-nb1)","c113097b":"We pass in the test set, `test_batches`, and set `verbose=0` to see no output during the evaluation process.","97deaaa9":"# Plotting Predictions With A Confusion Matrix","219d5241":"The first layer in the model is a 2-dimensional convolutional layer. This layer will have `32` output filters each with a kernel size of `3x3`, and we\u2019ll use the `relu` activation function.\n\nNote that the choice for the number of output filters specified is arbitrary, and the chosen kernel size of `3x3` is generally a very common size to use. You can experiment by choosing different values for these parameters.\n\nWe enable zero-padding by specifying `padding = 'same'`.\n\nOn the first layer only, we also specify the `input_shape`, which is the shape of our data. Our images are `224` pixels high and `224` pixels wide and have `3` color channels: RGB. This gives us an `input_shape` of `(224,224,3)`.\n\nWe then add a `max pooling` layer to pool and reduce the dimensionality of the data.\n\nWe follow this by adding another convolutional layer with the exact specs as the earlier one, except for this second `Conv2D` layer has `64` filters. The choice of 64 here is again arbitrary, but the general choice of having more filters in later layers than in earlier ones is common. This layer is again followed by the same type of `MaxPool2D` layer\n\nWe then `Flatten` the output from the convolutional layer and pass it to a `Dense` layer. This `Dense` layer is the output layer of the network, and so it has `2` nodes, one for cat and one for dog. We\u2019ll use the `softmax` activation function on our output so that the output for each sample is a probability distribution over the outputs of cat and dog.\n\nWe can check out a summary of the model by calling `model.summary()`."}}