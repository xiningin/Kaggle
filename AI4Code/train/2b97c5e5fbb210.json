{"cell_type":{"6f3aa2ba":"code","fe66907d":"code","4061795c":"code","17bf1f64":"code","b2d6af14":"code","b44ce06a":"code","d064389d":"code","b98e8b85":"code","800558d9":"code","7c986bee":"code","32acd529":"code","9dcea7e6":"code","656e3abf":"code","c3db754d":"code","2ae23122":"markdown","9daaf10e":"markdown","e21f7383":"markdown","8c8beb90":"markdown","f7dfebd6":"markdown","d986269f":"markdown","2c532367":"markdown","b4cf332c":"markdown"},"source":{"6f3aa2ba":"! pip install pyts","fe66907d":"import csv\nimport os\nimport re\nimport numpy as np\nimport pickle\nfrom pyts.approximation import PAA\nfrom pyts.image import GADF, MTF, RecurrencePlots\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook\nfrom time import time\nfrom matplotlib import pyplot as plt\nfrom matplotlib import image as mpimg\n%matplotlib inline","4061795c":"input_csv_path = '..\/input\/train.csv'\nsample_size = 150_000\nn_rows = 629145480\nn_samples = n_rows \/\/ sample_size\nIMG_SIZE = 512  # bigger images won't get inside of 5.2GB of Disk allocated by Kaggle kernel","17bf1f64":"def create_folder(folder):\n    if not os.path.exists(folder):\n        os.mkdir(folder)\n        \ndef _make_log10(num):\n    if num == 0:\n        return 0.\n    new_num = np.log10(abs(num)) + 0.05\n    if num < 0:\n        new_num = -new_num\n    return new_num\n\nmake_log10 = np.vectorize(_make_log10)\n\ndef create_image(array, name=None, folder=None, func=None):\n    if func:\n        array = func(array)\n    uvts = PAA(output_size=IMG_SIZE).fit_transform([array])\n    encoder1 = RecurrencePlots()\n    encoder2 = MTF(IMG_SIZE, n_bins=IMG_SIZE\/\/20, quantiles='gaussian')\n    encoder3 = GADF(IMG_SIZE)\n        \n    r = np.squeeze(encoder1.fit_transform(uvts)) \n    g = np.squeeze(encoder2.fit_transform(uvts))\n    b = np.squeeze(encoder3.fit_transform([array]))\n    \n    scaler = MinMaxScaler(feature_range=(0, 1))\n    shape = r.shape\n    r = scaler.fit_transform(r.reshape(-1, 1)).reshape(shape)\n    g = scaler.fit_transform(g.reshape(-1, 1)).reshape(shape)\n    b = scaler.fit_transform(b.reshape(-1, 1)).reshape(shape)\n    rgbArray = np.zeros((IMG_SIZE, IMG_SIZE, 3), 'uint8')\n    rgbArray[..., 0] = r * 256\n    rgbArray[..., 1] = g * 256\n    rgbArray[..., 2] = b * 256\n    \n    if not (name and folder):\n        plt.imshow(rgbArray)\n    else:\n        filename = name + \".png\"\n        plt.imsave(os.path.join(folder, filename),\n                   rgbArray)\n\ndef create_dataset(path, n_samples, sample_size, folder):\n    create_folder(folder)\n    with open(path, \"r\") as read_f:\n        reader = csv.reader(read_f)\n        counter = 0\n        pbar = tqdm_notebook(total=n_samples)\n        row = np.zeros(sample_size)\n        y = np.zeros(n_samples)\n        next(reader)\n        for val, ttf in reader:\n            n = counter \/\/ sample_size\n            m = counter % sample_size\n            row[m] = int(val)\n            if m == sample_size - 1:\n                create_image(row.copy(), str(n), folder,\n                             make_log10)\n                y[n] = float(ttf)\n                row = np.zeros(sample_size)\n                pbar.update(1)\n            counter += 1\n        return y\n\ndef print_rand_images(folder, y=None):\n    fig=plt.figure(figsize=(10, 12))\n    columns, rows = 3, 3\n    ax = []\n    for i in range(columns*rows):\n        img_name = np.random.choice(os.listdir(folder))\n        path = os.path.join(folder, img_name)\n        img = mpimg.imread(path)\n        ax.append(fig.add_subplot(rows, columns, i+1))\n        if y is not None:\n            img_id = int(os.path.splitext(img_name)[0])\n            img_name = f\"ttf: {y[img_id]:.5f}\"\n        ax[-1].set_title(img_name)\n        plt.imshow(img)\n    plt.show()","b2d6af14":"start = time()\ny = create_dataset(input_csv_path, n_samples, sample_size, \"train\")\nprint(\"Completed in {} seconds\".format(int(time()-start)))","b44ce06a":"print_rand_images(\"train\", y)","d064389d":"with open(\"y_train.pkl\", \"wb\") as f:\n    f.write(pickle.dumps(y))","b98e8b85":"! tar -zcvf train.tar.gz train","800558d9":"! rm -rf train","7c986bee":"test_folder = \"test\"\ncreate_folder(test_folder)\ntest_input_dir = \"..\/input\/test\/\"\ntest_files = [os.path.join(test_input_dir, x) for x in os.listdir(test_input_dir)]","32acd529":"start = time()\nfor file in tqdm_notebook(test_files):\n    array = np.loadtxt(file, skiprows=1)\n    name = os.path.splitext(os.path.basename(file))[0]\n    create_image(array, name, test_folder, make_log10)\nprint(\"Completed in {} seconds\".format(int(time()-start)))","9dcea7e6":"print_rand_images(test_folder)","656e3abf":"! tar -zcvf test.tar.gz test","c3db754d":"! rm -rf test","2ae23122":" ### Example of the resulting images:","9daaf10e":" ### Example of the resulting images:","e21f7383":"# Create images for training set","8c8beb90":"# Signal -> images","f7dfebd6":"In this notebook I will create images from signal data.  \nAn output of the notebook may be used to create a model based on CNN.\n\nThe approach is taken from the following gist:\n    - https:\/\/gist.github.com\/oguiza\/26020067f499d48dc52e5bcb8f5f1c57\n \nMore info on  Gramian Angular Fields, Markov Transition Fields and  Recurrence Plots may be found here:\n    - https:\/\/medium.com\/analytics-vidhya\/encoding-time-series-as-images-b043becbdbf3 (GAF)\n    - http:\/\/coral-lab.umbc.edu\/wp-content\/uploads\/2015\/05\/10179-43348-1-SM1.pdf (MTF)\n    - https:\/\/en.wikipedia.org\/wiki\/Recurrence_plot (RP)","d986269f":"### Saving results","2c532367":"# Create images for test set","b4cf332c":"### Saving results"}}