{"cell_type":{"8a12a12a":"code","4e2a997c":"code","949fe836":"code","32c9d45f":"code","defe4cad":"code","66816ee8":"code","201f1750":"code","a94d2491":"code","0fa88b3a":"code","f456d6df":"code","96c7fa28":"code","fb0f3a2a":"code","5bf403a2":"code","07f75819":"code","6b899e58":"code","89f13a7d":"code","8d847bb6":"code","2887a5e5":"code","1d3e86f9":"code","95da435a":"code","fb8520df":"code","7ba30312":"code","35a4bfe3":"code","e63f6a78":"code","b958c49f":"code","2e35949b":"code","ee22aeac":"code","71b4f0ea":"markdown","f3f6744e":"markdown","46c0b25a":"markdown","a6382848":"markdown","296b6865":"markdown","989916d1":"markdown","ae131a4e":"markdown","ba651237":"markdown","b9fde156":"markdown","947da47a":"markdown","6f570fb1":"markdown","dd4bc202":"markdown"},"source":{"8a12a12a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4e2a997c":"#Lets import modules\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib inline\ndf = pd.read_csv(\"..\/input\/kc_house_data.csv\")\ndf.head()","949fe836":"\ndf.info()","32c9d45f":"df.describe()\n","defe4cad":"#for suppressing scientific notation\npd.set_option('display.float_format', lambda x: '%.3f' % x)","66816ee8":"df.describe()","201f1750":"# to check null values in data\nsns.heatmap(df.isnull(), yticklabels= False, cbar=False, cmap= 'viridis')","a94d2491":"df['bedrooms'].value_counts()\n","0fa88b3a":"df['waterfront'].value_counts()","f456d6df":"df['view'].value_counts()","96c7fa28":"df['grade'].value_counts()\n","fb0f3a2a":"\nsns.countplot(df.bedrooms, order = df['bedrooms'].value_counts().index)\n                                    ","5bf403a2":"fig,axes = plt.subplots(nrows=1,ncols=1, figsize=(15,10))\nplt.title('House prices by sqft_living')\nplt.xlabel('sqft_living')\nplt.ylabel('House Prices')\nplt.legend()\nsns.barplot(x='sqft_living', y='price', data = df)\n","07f75819":"fig,axes = plt.subplots(nrows=1,ncols=1, figsize=(15,10))\nplt.title('House prices by sqft_living')\nplt.xlabel('sqft_above')\nplt.ylabel('House Prices')\nplt.legend()\nsns.barplot(x='sqft_above', y='price', data = df)\n","6b899e58":"plt.hist('sqft_living', data = df, bins = 5)","89f13a7d":"fig,axes = plt.subplots(nrows=1,ncols=1, figsize=(15,10))\nsns.distplot(df['sqft_living'], hist=True, kde=True, rug=False, label='sqft_living', norm_hist=True)","8d847bb6":"fig,axes = plt.subplots(nrows=1,ncols=1, figsize=(15,10))\nsns.distplot(df['sqft_living'], hist=True, kde=True, rug=False, label='sqft_living', norm_hist=True)","2887a5e5":"#Finding out mean, median & mode\nprint('Mean', round(df['sqft_living'].mean(), 2))\nprint('Median', df['sqft_living'].median())\nprint('Mode', df['sqft_living'].mode()[0])\n\n","1d3e86f9":"len(df[df['sqft_living']==1300])","95da435a":"def correlation_heatmap(df1):\n    _, ax = plt.subplots(figsize = (15, 10))\n    colormap= sns.diverging_palette(220, 10, as_cmap = True)\n    sns.heatmap(df.corr(), annot=True, cmap = colormap)\n\ncorrelation_heatmap(df)","fb8520df":"train_data, test_data = train_test_split(df, train_size =0.8, random_state = 3)\nreg = linear_model.LinearRegression()\nx_train = np.array(train_data['sqft_living']).reshape(-1,1)\ny_train = np.array(train_data['price']).reshape(-1, 1)\nreg.fit(x_train, y_train)\n#evaluate simple model\nx_test = np.array(test_data['sqft_living']).reshape(-1, 1)\ny_test = np.array(test_data['price']).reshape(-1, 1)\npred = reg.predict(x_test)\nprint('Simple Model')\nmean_squared_error = metrics.mean_squared_error(y_test, pred)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(reg.score(x_train, y_train), 3))\nprint('R-squared (testing) ', round(reg.score(x_test, y_test), 3))\nprint('Intercept: ', reg.intercept_)\nprint('Coefficient:', reg.coef_)\n","7ba30312":"_, ax = plt.subplots(figsize= (10, 12))\nplt.scatter(x_test, y_test, color= 'darkgreen', label = 'data')\nplt.plot(x_test, reg.predict(x_test), color='red', label= ' Predicted Regression line')\nplt.xlabel('Living Space (sqft)')\nplt.ylabel('price')\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n","35a4bfe3":"_ , axes = plt.subplots(2, 1, figsize=(15,10))\nsns.boxplot(x= train_data['grade'], y=train_data['price'],ax = axes[0])\nsns.boxplot(x=train_data['bedrooms'], y=train_data['price'], ax=axes[1])\n\n_ , axes = plt.subplots(1, 1, figsize=(15,10))\nsns.boxplot(x=train_data['bathrooms'], y=train_data['price'])\n\n\n","e63f6a78":"features1 = ['bathrooms','sqft_living','grade', 'sqft_above']\nreg= linear_model.LinearRegression()\nreg.fit(train_data[features1],train_data['price'])\npred = reg.predict(test_data[features1])\nprint('Complex Model_1')\nmean_squared_error = metrics.mean_squared_error(y_test, pred)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(reg.score(train_data[features1], train_data['price']), 3))\nprint('R-squared (testing) ', round(reg.score(test_data[features1], test_data['price']), 3))\nprint('Intercept: ', reg.intercept_)\nprint('Coefficient:', reg.coef_)\n\n\n","b958c49f":"features1 = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view','grade','sqft_above','sqft_basement','lat','sqft_living15']\nreg= linear_model.LinearRegression()\nreg.fit(train_data[features1],train_data['price'])\npred = reg.predict(test_data[features1])\nprint('Complex Model_2')\nmean_squared_error = metrics.mean_squared_error(y_test, pred)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(reg.score(train_data[features1], train_data['price']), 3))\nprint('R-squared (testing) ', round(reg.score(test_data[features1], test_data['price']), 3))\nprint('Intercept: ', reg.intercept_)\nprint('Coefficient:', reg.coef_)\n","2e35949b":"polyfeat = PolynomialFeatures(degree =2)\nxtrain_poly=polyfeat.fit_transform(train_data[features1])\nxtest_poly=polyfeat.fit_transform(test_data[features1])\n\npoly = linear_model.LinearRegression()\npoly.fit(xtrain_poly,train_data['price'])\npredp= poly.predict(xtest_poly)\n\nprint('Complex Model_3')\nmean_squared_error = metrics.mean_squared_error(test_data['price'], predp)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))\nprint('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))\n\n","ee22aeac":"polyfeat = PolynomialFeatures(degree =3)\nxtrain_poly=polyfeat.fit_transform(train_data[features1])\nxtest_poly=polyfeat.fit_transform(test_data[features1])\n\npoly = linear_model.LinearRegression()\npoly.fit(xtrain_poly,train_data['price'])\npredp= poly.predict(xtest_poly)\n\nprint('Complex Model_4')\nmean_squared_error = metrics.mean_squared_error(test_data['price'], predp)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))\nprint('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))\n\n","71b4f0ea":"163 houses which has a view to a waterfront","f3f6744e":"19489 flats have not been viewed at all whereas 319 flats have been viewed already 4 times","46c0b25a":"Overview\n\nWelcome to my Kernel! In this kernel I use various regression methods and try to predict the house prices by using them. As you can guess, there are various methods to suceed this and each method has pros and cons. I think regression is one of the most important methods because it gives us more insight about the data. When we ask why, it is easier to interpret the relation between the response and explanatory variables.\nHere, I start with a very simple model and continue with more complex ones. I try to find the most useful model and during this I also use visuals to be able to understand the data better.\n\nIf you have a question or feedback, do not hesitate to write and if you like this kernel, please do not forget to UPVOTE \ud83d\ude42 \n\nWelcome to my Kernel! In this kernel I use various regression methods and try to predict the house prices by using them. As you can guess, there are various methods to suceed this and each method has pros and cons. I think regression is one of the most important methods because it gives us more insight about the data. When we ask why, it is easier to interpret the relation between the response and explanatory variables.\nHere, I start with a very simple model and continue with more complex ones. I try to find the most useful model and during this I also use visuals to be able to understand the data better.\n\nIf you like this kernel, please do not forget to UPVOTE \ud83d\ude42 ","a6382848":"138 Houses having sqft_living area of 1300 Sqft\nThe distribution is positively skewed with mean value greater than median and median being greater than mode\n","296b6865":"Complex Model_3 gives us R-squared (testing)  score of 0.744.\nFrom above reports, we can conclude that Polynomial regression is best solution.","989916d1":"Most of the houses are having living area of 3000 Sqft. To be precise 75% houses have area of 2550 Sqft (from above describe function)","ae131a4e":"**Polynomial Regression**","ba651237":"In the previous section I used a simple linear regression and found a poor fit. In order to improve this model I am planing to add more features but we should be careful about the overfit which can be seen by the difference between the training and test evaluation metrics. When we have more than one feature in a linear regression, it is defined as multiple regression. Then, it is time to check the correlation matrix before fitting a mutiple regression.","b9fde156":"From description we can infer that\n1. Avg price of house sold in King County, USA is $540088.\n2. Max price of house sold in King County, USA is $7700000.\n3. Avg no. of bedrooms in houses sold in KC is 3\/House with 2 bathrooms \/bedroom with one house is having 33 Bedrooms \n4. Avg area of house is 2079 Sqft with one house having 13540 Sqft. area\n\n","947da47a":"Complex model 1\n","6f570fb1":"When we examine the **correlation matrix**, we may observe that **price** has the highest correlation coefficient with **living area (sqft) ** (0.7)\nWe will use living area (sqft) as feature while creating regression\nWhen we model a linear relationship between a response and just one explanatory variable, this is called simple linear regression.","dd4bc202":"Above representation shows that our data does not have any null values"}}