{"cell_type":{"398ba5d9":"code","76310690":"code","a22aa2f2":"code","9fcedaca":"code","669946de":"code","c306e2fe":"code","6494bfe1":"code","067788af":"code","30f490ee":"code","aaa32c84":"code","f2e5cb73":"code","dd387187":"code","5b9d6a37":"code","56b7ea13":"code","19455518":"code","c746d1f9":"markdown","7972fe39":"markdown","12beefa2":"markdown","361afbca":"markdown","a13ded10":"markdown","b256c114":"markdown","7ec77b79":"markdown","b989713e":"markdown"},"source":{"398ba5d9":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nfrom keras.models import Sequential\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten\nfrom tensorflow.keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","76310690":"training_file = '..\/input\/fashionmnist\/fashion-mnist_train.csv'\ntesting_file = '..\/input\/fashionmnist\/fashion-mnist_test.csv'\ntrain_data = pd.read_csv(training_file)\ntest_data = pd.read_csv(testing_file)","a22aa2f2":"train_data.head()","9fcedaca":"test_data.head()","669946de":"train_data = np.array(train_data, dtype = 'float32')\ntest_data = np.array(test_data, dtype='float32')","c306e2fe":"x_train = train_data[:,1:]\/255\n\ny_train = train_data[:,0]\n\nx_test= test_data[:,1:]\/255\n\ny_test=test_data[:,0]","6494bfe1":"x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 12345)","067788af":"plt.figure(figsize=(20, 10))\nfor i in range(27):\n    plt.subplot(3, 9, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i].reshape((28,28)))\n    plt.title(y_train[i])\nplt.show()","30f490ee":"classification_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nplt.figure(figsize=(20, 10))\nfor i in range(27):\n    plt.subplot(3, 9, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i].reshape((28,28)))\n    label_index = int(y_train[i])\n    plt.title(classification_names[label_index])\nplt.show()","aaa32c84":"x_train = x_train.reshape(x_train.shape[0],*(28,28,1))\nx_test = x_test.reshape(x_test.shape[0],*(28,28,1))\nx_validate = x_validate.reshape(x_validate.shape[0],*(28,28,1))","f2e5cb73":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10,activation = 'softmax') \n])","dd387187":"model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001),metrics =['accuracy'])","5b9d6a37":"history = model.fit(\n    x_train,\n    y_train,\n    batch_size=1000,\n    epochs=30,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","56b7ea13":"plt.figure(figsize=(20, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'],color='blue', label='Loss')\nplt.plot(history.history['val_loss'],color='orange', label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function \/ Cross Entropy Loss')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'],color='blue', label='Accuracy')\nplt.plot(history.history['val_accuracy'],color='orange', label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy \/ Classification Accuracy')\nplt.show()","19455518":"score = model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(score[1]))","c746d1f9":"## Define Model\n\nNext, we need to define a baseline convolutional neural network model for the problem.\n\nThe model has two main aspects: the feature extraction front end comprised of convolutional and pooling layers, and the classifier backend that will make a prediction.\n\nFor the convolutional front-end, we can start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.","7972fe39":"Now let us visualise the some samples after the resize of the data which needs to be ready for train the network .","12beefa2":"Labels Each training and test example is assigned to one of the following labels as shown below:\n\n- 0 T-shirt\/top\n- 1 Trouser\n- 2 Pullover\n- 3 Dress\n- 4 Coat\n- 5 Sandal\n- 6 Shirt\n- 7 Sneaker\n- 8 Bag\n- 9 Ankle boot","361afbca":"## Normalize the data\n\nA good starting point is to normalize the pixel values of grayscale images, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value.","a13ded10":"## Evaluate Model","b256c114":"#### Let us plot the Training Accuracy vs Loss to get a better understanding of the model training.","7ec77b79":"## Load Dataset\n\nThe images are all pre-segmented, that the images all have the same square size of 28\u00d728 pixels, and that the images are grayscale. Therefore, we can load the images and reshape the data arrays to have a single color channel.","b989713e":"# The **Fashion-MNIST** clothing classification problem is a new standard dataset used in computer vision and deep learning.\n\nIt is a dataset comprised of 60,000 small square 28\u00d728 pixel grayscale images of items of 10 types of clothing, such as shoes, t-shirts, dresses, and more. The mapping of all 0-9 integers to class labels is listed below.\n\n![](https:\/\/image.itmedia.co.jp\/ait\/articles\/2005\/28\/cover_news016.png)\n\nIt is a more challenging classification problem than MNIST and top results are achieved by deep learning convolutional neural networks with a classification accuracy of about 90% to 95% on the hold out test dataset."}}