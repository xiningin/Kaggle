{"cell_type":{"052ba62f":"code","d95c2d2e":"code","8ce4e6c2":"code","15a0a373":"code","35bfbca7":"code","42a72ab7":"code","27fdc74f":"code","63bc3b93":"code","7897c2e0":"code","8cb83044":"code","2e96767a":"code","832cc268":"code","09b73ba0":"code","5ecf74ab":"code","9ee2a277":"code","6ea6c30f":"code","c648438a":"markdown","4d0b69e6":"markdown","203705bb":"markdown","e87fad1d":"markdown"},"source":{"052ba62f":"import math\nimport numpy as np\nimport pandas as pd\n\nimport dateutil.easter as easter\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pathlib import Path\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_periodogram, seasonal_plot\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom statsmodels.tsa.deterministic import DeterministicProcess","d95c2d2e":"original_train_df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\noriginal_test_df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\ngdp_df = pd.read_csv('..\/input\/gdp-20152019-finland-norway-and-sweden\/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n\ngdp_df.set_index('year', inplace=True)\n\n# The dates are read as strings and must be converted\nfor df in [original_train_df, original_test_df]:\n    df['date'] = pd.to_datetime(df.date)\noriginal_train_df.head(2)","8ce4e6c2":"# keeping a function ready to compute SMAPE\ndef smape_loss(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return np.abs(y_true - y_pred) \/ (y_true + np.abs(y_pred)) * 200","15a0a373":"# Feature engineering\ndef engineer(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp_df.loc[row.date.year, country]\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 3):\n        new_df[f'sin{k}'] = np.sin(dayofyear \/ 365 * 2 * math.pi * k)\n        new_df[f'cos{k}'] = np.cos(dayofyear \/ 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Hat']\n\n    return new_df\n\ntrain_df = engineer(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer(original_test_df)\n\nfeatures = test_df.columns\n\nfor df in [train_df, test_df]:\n    df[features] = df[features].astype(np.float32)\nprint(list(features))","35bfbca7":"# Feature engineering for holidays\ndef engineer_more(df):\n    \"\"\"Return a new dataframe with more engineered features\"\"\"\n    new_df = engineer(df)\n\n    # End of year\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 14)}),\n                        pd.DataFrame({f\"jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)})],\n                       axis=1)\n    \n    # May\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}), #  + list(range(17, 25))\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(19, 26))})],\n                       axis=1)\n    \n    # June and July\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 14))}),\n                        #pd.DataFrame({f\"june{d}\":\n                        #              (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Norway')\n                        #              for d in list(range(22, 31))}),\n                        #pd.DataFrame({f\"july{d}\":\n                        #              (df.date.dt.month == 7) & (df.date.dt.day == d) & (df.country == 'Norway')\n                        #              for d in list(range(1, 3))})],\n                       ],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 6))})],\n                       axis=1)\n    \n    # First Sunday of November\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 14))})],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})],\n                       axis=1)\n    \n    return new_df.astype(np.float32)\n\ntrain_df = engineer_more(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer_more(original_test_df)\n\nfeatures = list(test_df.columns)\nprint(list(features))","42a72ab7":"from catboost import CatBoostRegressor\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","27fdc74f":"train_df.drop('date', axis=1, inplace=True)","63bc3b93":"X_train, X_val, y_train, y_val = train_test_split(train_df.drop('num_sold',axis=1),train_df['num_sold'], test_size=0.2)\nct = CatBoostRegressor(verbose=False, eval_metric='SMAPE')\nct.fit(X_train, y_train, eval_set=(X_val,y_val))\nct","7897c2e0":"pred = ct.predict(test_df)\npred = [int(i) for i in pred] \n# new_test_df = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/test.csv\")\n# new_test_df['num_sold'] = pred\n# new_test_df = new_test_df[['row_id','num_sold']]\n# new_test_df.to_csv('submission.csv',index=False)","8cb83044":"original_train_df[\"store\"].value_counts()","2e96767a":"train_mart = original_train_df[original_train_df[\"store\"]=='KaggleMart']\ntrain_rama = original_train_df[original_train_df[\"store\"]=='KaggleRama']\ntest_mart = original_test_df[original_test_df[\"store\"]=='KaggleMart']\ntest_rama = original_test_df[original_test_df[\"store\"]=='KaggleRama']","832cc268":"original_train_df.head()","09b73ba0":"test_mart","5ecf74ab":"#mart data prep\ntrain_df_mart = engineer_more(train_mart)\ntrain_df_mart['date'] = train_mart.date\ntrain_df_mart['num_sold'] = train_mart.num_sold.astype(np.float32)\ntest_df_mart = engineer_more(test_mart)\n\nfeatures_mart = list(test_df_mart.columns)\n\n#rama data prep\ntrain_df_rama = engineer_more(train_rama)\ntrain_df_rama['date'] = train_rama.date\ntrain_df_rama['num_sold'] = train_rama.num_sold.astype(np.float32)\ntest_df_rama = engineer_more(test_rama)\n\nfeatures_rama = list(test_df_rama.columns)","9ee2a277":"# mart model and predictions\nX_train_mart, X_val_mart, y_train_mart, y_val_mart = train_test_split(train_df_mart.drop('num_sold',axis=1),train_df_mart['num_sold'], test_size=0.1)\nct_mart = CatBoostRegressor(verbose=False, eval_metric='SMAPE')\nct_mart.fit(X_train_mart, y_train_mart, eval_set=(X_val_mart,y_val_mart))\n\npred_mart = ct.predict(test_df_mart)\npred_mart = [int(i) for i in pred_mart] \ntest_mart['num_sold'] = pred_mart\ntest_mart = test_mart[['row_id','num_sold']]\n\n# rama model and predictions\nX_train_rama, X_val_rama, y_train_rama, y_val_rama = train_test_split(train_df_rama.drop('num_sold',axis=1),train_df_rama['num_sold'], test_size=0.1)\nct_rama = CatBoostRegressor(verbose=False, eval_metric='SMAPE')\nct_rama.fit(X_train_rama, y_train_rama, eval_set=(X_val_rama,y_val_rama))\n\npred_rama = ct.predict(test_df_rama)\npred_rama = [int(i) for i in pred_rama] \ntest_rama['num_sold'] = pred_rama\ntest_rama = test_rama[['row_id','num_sold']]\n\n#submission\nsubmission = pd.concat([test_mart,test_rama])\nsubmission.sort_index(inplace=True)\nsubmission.to_csv('submission.csv',index=False)","6ea6c30f":"submission","c648438a":"* I had used pycaret to know which model suits best for our prepared data set, however did not include this in the the notebook as this would significantly increase processing time.\n* Will be posting new results after I tune the hyper parameters.\n* have used GDP datset and passed it as inputs to the model, additionally have calculated holidays.","4d0b69e6":"### Let us try creating different models for different stores","203705bb":"We will be importing GDP data as well to generate more insights from the data, we will use GDP datasets of ","e87fad1d":"### This notebook will be updated further."}}