{"cell_type":{"ad2027a0":"code","ca12e93e":"code","e6bd16b9":"code","e7c57d58":"code","e3ff6db3":"code","24c569d3":"code","e38cf5e7":"code","d048784b":"code","ab55908e":"code","95c10cb9":"code","a4705748":"code","f8e754d6":"code","db815837":"code","e23d631c":"markdown","baae7fad":"markdown","29278b6e":"markdown","eb5c0b9f":"markdown","fa2d3798":"markdown"},"source":{"ad2027a0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","ca12e93e":"# The intitial files are referred to as dandelion and other, \n# so those are the same names I used.\ndandelion = '..\/input\/dandelionimages\/Images\/dandelion\/IMG_1149.jpg'\nother = '..\/input\/dandelionimages\/Images\/other\/IMG_5490.jpg'\n\n# The PIL module will allow me to view the photos\nimport PIL\nfrom PIL import Image\nImage.open(other)","e6bd16b9":"# loading the image\nimg = PIL.Image.open(dandelion)\n  \n# fetching the dimensions\nwid, hgt = img.size\n  \n# displaying the dimensions\nprint(str(wid) + \"x\" + str(hgt))","e7c57d58":"# Getting the names of the different classes\n\nbase_directory = '..\/input\/dandelionimages\/Images'\nclasses = [x for x in os.listdir(base_directory) if '.' not in x]\nclasses","e3ff6db3":"# Making the empty list we'll populate with the image paths\nimage_paths = []\n\n# Populating the image's paths and classes\nfor picture in classes:\n    image_paths.extend([os.path.join(base_directory, picture, x) for x in os.listdir(\n        os.path.join(base_directory, picture))])\n\nimage_classes = np.array([[picture]*(int(len(image_paths)\/2)) for picture in classes]).reshape(-1)\n\n# Just checking that these are equal\nprint(len(image_classes))    \nprint(len(image_paths))","24c569d3":"# Creating a pandas dataframe\n\ndata = pd.DataFrame({'path': image_paths, 'class': image_classes})\n\nprint(data.head())\nprint(data.shape)","e38cf5e7":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# I'm going to split the data three ways:\n# testing the data, validating it while testing, and the final test.\n\ndef get_generators(data):\n    data_full, test_data = train_test_split(data, stratify=data['class'], test_size=0.1)\n    training_data, validation_data = train_test_split(data_full, test_size=0.2)\n    \n    train_datagen = ImageDataGenerator(rescale=1.0\/512, validation_split=.5)\n    test_datagen = ImageDataGenerator(rescale=1.0\/512)\n\n    train_generator = train_datagen.flow_from_dataframe(training_data, \n                                                        x_col='path', \n                                                        y_col='class',\n                                                        target_size=(512,512), \n                                                        color_mode='rgb', \n                                                        class_mode='categorical',\n                                                        rotation_range=30, \n                                                        horizontal_flip=True,\n                                                        vertical_flip=True,\n                                                        brightness_range=[0.4,1.5],\n                                                        batch_size=32, \n                                                        subset='validation')\n    \n    val_generator = train_datagen.flow_from_dataframe(validation_data, \n                                                      x_col='path', \n                                                      y_col='class',\n                                                      target_size=(512,512),  \n                                                      color_mode='rgb', \n                                                      class_mode='categorical',\n                                                      rotation_range=30,\n                                                      horizontal_flip=True,\n                                                      vertical_flip=True,\n                                                      brightness_range=[0.4,1.5],\n                                                      batch_size=32, \n                                                      subset='validation')\n    \n    test_generator = test_datagen.flow_from_dataframe(test_data,\n                                                      x_col = 'path',\n                                                      y_col = 'class', \n                                                      target_size=(512,512), \n                                                      color_mode = 'rgb',\n                                                      class_mode = 'categorical')\n    \n    return train_generator, val_generator, test_generator","d048784b":"img_shape = (512, 512, 3)\n\ntrain_gen, val_gen, test_gen = get_generators(data)\nprint(len(train_gen))","ab55908e":"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Layer, BatchNormalization, GlobalAveragePooling2D \nfrom tensorflow.keras.models import Sequential\nimport cv2\n\nmodel = Sequential([\n    Conv2D(128, (2,2), strides=3, input_shape=img_shape),\n    MaxPooling2D(),\n    Conv2D(256, (2,2), strides=2), \n    MaxPooling2D(),\n    Conv2D(512, (2,2)),\n    MaxPooling2D(),\n    Flatten(),\n    Dropout(0.5),\n    Dense(1024, activation='relu'),\n    Dropout(0.5),\n    Dense(2, activation='softmax')\n])\n\nmodel.summary()","95c10cb9":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nearlystop = EarlyStopping(patience=10, \n                          restore_best_weights=True)\n\nschedule = ExponentialDecay(initial_learning_rate = 0.002, \n                            decay_steps=1000, \n                            decay_rate=0.7)\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=Adam(learning_rate=schedule), \n              metrics=['accuracy'])\n\nhistory = model.fit(train_gen, \n                    validation_data = val_gen, \n                    epochs=100, \n                    callbacks= [earlystop])","a4705748":"model.evaluate(test_gen)","f8e754d6":"from sklearn.metrics import classification_report\n\nY_pred = model.predict(test_gen)\ny_pred = np.argmax(Y_pred, axis=1)\n\nprint('Classification Report')\ntarget_names = ['Dandelion', 'Other']\nprint(classification_report(test_gen.classes, y_pred, target_names=target_names))","db815837":"import matplotlib.pyplot as plt\n\ndef plot_history(history):\n    \n    # Get list of results on training and test data\n    \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(len(acc))\n    \n    plt.plot(epochs, acc, 'r', label='Training Accuracy')\n    plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    \n    plt.plot(epochs, loss, 'y', label='Training Loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    \nplot_history(history)","e23d631c":"After some initial investigation, the photos are of varying sizes.","baae7fad":"I looked through a few of the photos to get an idea of the quality of picture and the various pictures we'll be categorizing. For the dandelion images, some of them are large while others are relatively small; however, I was able to see the dandelions in the few photos I looked at. The other photos are exactly what you wouldd expect -- pictures of grass that doesn't have a dandelion in it.\n\nNow I'll check the sizes for a few of the photos and see if they are all the same -- I don't think they are based on my initial investigation of the photos, but I want to be sure.","29278b6e":"Hey everyone, thank you for looking at this notebook! I'm still learning a lot about machine learning, and this is one of the first image classification projects I've done. If you see anything you would change or improve, please feel free to comment below.","eb5c0b9f":"Below I've created a neural network to process the different images.\n\nThe network will take in the iamge shape, process it, flatten the image, and then make a final decision about the flattened version.","fa2d3798":"For the portion below, I'm going to use the ImageDataGenerator package from keras. There isn't a ton of data to work with here, and for the most part, increasing the quantity of data is good for image processing. There's a lot of options when working with this thing, and I've decided to use some of the more normal features and then also include rotations, flips, and varying brightness."}}