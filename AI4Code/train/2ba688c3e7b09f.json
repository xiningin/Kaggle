{"cell_type":{"33e081a9":"code","c53a8cb9":"code","d0bc3ac6":"code","9832251d":"code","99667a26":"code","e11d43b5":"code","6a36a70f":"code","3bf5b4fc":"code","f8353394":"code","13afff1d":"code","352f36c4":"code","d7ff67a9":"code","8583d734":"code","50d490aa":"code","f43a21e7":"code","37d92273":"code","991eaa7c":"code","b306e5f2":"code","d8f1239c":"code","dca6fe21":"code","523718fd":"code","d2732174":"markdown","91830ad2":"markdown","7f6d553b":"markdown","0052bc9c":"markdown","005a1887":"markdown","9d19acb6":"markdown","d907fd84":"markdown","a48faa1f":"markdown"},"source":{"33e081a9":"import regex as re\nimport string\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.naive_bayes import BernoulliNB","c53a8cb9":"import nltk\nnltk.download('stopwords')","d0bc3ac6":"train_df = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntrain_df.head()","9832251d":"train_df.info()","99667a26":"train_df['target'].value_counts(normalize=True)","e11d43b5":"train_df[~train_df['keyword'].isnull()][['keyword', 'text']]","6a36a70f":"len(train_df['location'].unique())","3bf5b4fc":"train_df.drop(columns=['keyword', 'location'], inplace=True)","f8353394":"tokenizer = TweetTokenizer()\nstemmer = SnowballStemmer(language='english')","13afff1d":"def preprocess_text(text):\n  cleaned_text = text.lower()\n  \n  #remove words like hashtags, web addresses\n  cleaned_text = re.sub(r'#\\S+|@\\S+|<.*?>|http\\S+', '', cleaned_text)\n\n  cleaned_text = tokenizer.tokenize(cleaned_text)\n  cleaned_text = ' '.join([stemmer.stem(word) for word in cleaned_text if word not in string.punctuation and word not in stopwords.words('english')])\n\n  return cleaned_text","352f36c4":"train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)","d7ff67a9":"train_df['cleaned_text'][0:5]","8583d734":"#Generate BOW with CountVectorizer\nvectorizer = CountVectorizer(max_features=5000)\nX = vectorizer.fit_transform(train_df['cleaned_text']).toarray()\ny = train_df['target']","50d490aa":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y,random_state=100)","f43a21e7":"print (\"train: \", X_train.shape)\nprint (\"test: \", X_val.shape)","37d92273":"bnb = BernoulliNB(alpha=1.0, fit_prior=True)\nbnb.fit(X_train, y_train)\n\ny_train_pred = bnb.predict(X_train)\ny_val_pred = bnb.predict(X_val)\n\nprint (\"train score: \", f1_score(y_train, y_train_pred))\nprint (\"test score: \", f1_score(y_val, y_val_pred))","991eaa7c":"test_df = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\nprint (test_df.head())\nprint (test_df.shape)","b306e5f2":"test_df.drop(columns=['keyword', 'location'], inplace=True)","d8f1239c":"test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)\ntest_X = vectorizer.transform(test_df['cleaned_text'])\ntest_y = bnb.predict(test_X)","dca6fe21":"submission = pd.DataFrame({'id':test_df.id, 'target':test_y})\nsubmission.head()","523718fd":"submission.to_csv('.\/submission.csv', index=False)","d2732174":"**Prediction on test set to be evaluated**","91830ad2":"**Modelling**","7f6d553b":"**Checking- if features keyword and location are useful and should be retained**","0052bc9c":"**Classes seems to be balanced**","005a1887":"**Dropping the features: keyword and location**","9d19acb6":"**Data Reading and Understanding**","d907fd84":"**Approach - <br>\na) Bag of words model using CountVectorizer<br>\nb) Naive Bayes classification**","a48faa1f":"**Data Cleaning and Preprocessing**"}}