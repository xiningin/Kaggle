{"cell_type":{"6bb791dc":"code","c8725bf4":"code","71635e89":"code","fa0c7511":"code","007518b0":"code","1998a356":"code","eb2a0306":"code","22988bdb":"code","9fdab118":"code","de3cc3c5":"code","1637a511":"code","c9e59968":"code","f904a399":"code","3061409e":"code","29efa933":"code","b5717dd9":"code","4755b116":"code","e0804376":"code","874e4446":"code","5aa52d13":"code","5c882f7c":"code","30e5a609":"code","9c3e55e1":"code","0560e7db":"code","5aa0d8bb":"code","0c9c01d6":"code","31be9aa7":"code","8a8c7fa1":"code","0a4cb0a7":"code","590de0ec":"code","54dbef1b":"code","630e2749":"markdown","03795d9a":"markdown","29d2042d":"markdown","e9a1abae":"markdown","cc6d785c":"markdown","1877219e":"markdown","ff60a0da":"markdown","563c9ce6":"markdown","09e20dac":"markdown","e6d48a2b":"markdown","1a0e21b4":"markdown","600a9929":"markdown","d75bdefa":"markdown","c24403f9":"markdown","151e9e5f":"markdown","d2d4cebf":"markdown","a4d3409f":"markdown"},"source":{"6bb791dc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8725bf4":"import glob\nimport os.path as osp\nimport copy\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pickle\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torchvision import datasets, models\nfrom torchvision.utils import make_grid\n\nimport os\nimport time\nfrom PIL import Image\nfrom IPython.display import display\n\nimport warnings\nwarnings.filterwarnings('ignore')","71635e89":"class Config:\n    num_classes = 12\n    img_size = 224\n    batch_size = 64\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    min_lr = 10**-12\n    max_lr = 10\n    pretrained = False\n    criterion = nn.CrossEntropyLoss()\n    epochs = 20","fa0c7511":"train_image_path = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\ntest_image_path = '..\/input\/plant-pathology-2021-fgvc8\/test_images'\ntrain_df_path = '..\/input\/plant-pathology-2021-fgvc8\/train.csv'\ntest_df_path = '..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv'","007518b0":"df_train = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2021-fgvc8\/train.csv\")\ndf_sub = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv\")","1998a356":"#The number of labels\nlen(df_train.labels.unique())","eb2a0306":"#The no.values per label\ndf_train.labels.value_counts()","22988bdb":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndef encode_label(df):\n    df['encoded_label'] = le.fit_transform(df.labels.values)\n    return df\n\nencode_label(df_train)\n    \n# L\u01b0u t\u1eeb \u0111i\u1ec3n m\u00e3 h\u00f3a\ndf_labels_idx = df_train.loc[df_train.duplicated([\"labels\", \"encoded_label\"])==False]\\\n                [[\"encoded_label\", \"labels\"]].set_index(\"encoded_label\").sort_index()\ndisplay(df_labels_idx)","9fdab118":"from sklearn.model_selection import train_test_split","de3cc3c5":"def make_datapath_list(phase='train', val_size=0.25):\n    if phase in [\"train\", \"val\"]:\n        phase_path = \"train_images\"\n    elif phase in [\"test\"]:\n        phase_path = \"test_images\"\n    else:\n        print(f\"{phase} not in path\")    \n        \n    \"\"\"\n    Use resized training dataset for betting training speed\n    Resized datase from: https:\/\/www.kaggle.com\/ankursingh12\/resized-plant2021\n    \"\"\"\n    if phase == 'train' or phase == 'val': \n        rootpath = \"\/kaggle\/input\/resized-plant2021\/img_sz_256\/\"\n    else:\n        rootpath = \"\/kaggle\/input\/plant-pathology-2021-fgvc8\/test_images\/\"\n    \n    target_path = osp.join(rootpath+\"\/*.jpg\")\n    path_list = []\n    \n    for path in glob.glob(target_path):\n        path_list.append(path)\n        \n    if phase in [\"train\", \"val\"]:\n        train, val = train_test_split(path_list, test_size=val_size, random_state=0, shuffle=True)\n        if phase == \"train\":\n            path_list = train\n        else:\n            path_list = val\n    \n    return path_list","1637a511":"train_list = make_datapath_list(phase='train')\nprint(f'The length of training set: {len(train_list)}')\nval_list = make_datapath_list(phase='val')\nprint(f'The length of valuation set: {len(val_list)}')\ntest_list = make_datapath_list(phase='test')\nprint(f'The length of testing set: {len(test_list)}')","c9e59968":"import albumentations as A\nfrom albumentations import Compose\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\ntransform = {\n    'train': Compose([\n        A.Rotate(p=0.1, limit=(-85, 80)),\n        A.RandomShadow(\n            num_shadows_lower=2, \n            num_shadows_upper=3, \n            shadow_dimension=3, \n            shadow_roi=(0, 0.7, 0.4, 0.8), \n            p=0.4\n        ),\n        A.ShiftScaleRotate(\n            shift_limit=0.055, \n            scale_limit=0.065, \n            rotate_limit=35, \n            p=0.6\n        ),\n        A.RandomFog(\n            fog_coef_lower=0.2, \n            fog_coef_upper=0.2, \n            alpha_coef=0.2, \n            p=0.3\n        ),\n        A.RGBShift(\n            r_shift_limit=25, \n            g_shift_limit=15, \n            b_shift_limit=15, \n            p=0.3\n        ),\n        A.RandomBrightnessContrast(p=0.3),\n        A.GaussNoise(\n            var_limit=(50, 70),  \n            always_apply=False, \n            p=0.3\n        ),\n        A.Resize(height=Config.img_size, width=Config.img_size),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ]),\n    'val': Compose([\n        A.Resize(Config.img_size, Config.img_size),\n        A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),            \n        ToTensorV2()\n    ]),\n    'test': Compose([\n        A.Resize(Config.img_size, Config.img_size),\n        A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n}","f904a399":"class PlantDataset(Dataset):\n    \"\"\"\n    Class to create a Dataset\n    \n    Attributes\n    ----------\n    df_train : DataFrame\n        DataFrame containing the image labels.\n    file_list : list\n        A list containing the paths to the images\n    transform : object\n        Instance of the preprocessing class (ImageTransform)\n    phase : 'train' or 'val' or 'test'\n        Specify whether to use train, validation, or test\n    \"\"\"\n    def __init__(self, df_train, file_list, transform=None, phase='train'):\n        self.df_train = df_train\n        self.df_labels_idx = df_labels_idx\n        self.file_list = file_list\n        self.transform = transform[phase]\n        self.phase = phase\n        \n    def __len__(self):\n        \"\"\"\n        Returns the number of images.\n        \"\"\"\n        return len(self.file_list)\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Get data in Tensor format and labels of preprocessed images.\n        \"\"\"\n        \n        # Load the index number image.\n        img_path = self.file_list[index]\n        img = Image.open(img_path)\n        \n        # Preprocessing images\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img_transformed = self.transform(image=img)\n        \n        # image name\n        image_name = img_path[-20:]\n        \n        # Extract the labels\n        if self.phase in [\"train\", \"val\"]:\n            label = df_train.loc[df_train[\"image\"]==image_name][\"encoded_label\"].values[0]\n        elif self.phase in [\"test\"]:\n            label = -1\n        \n        return img_transformed, label, image_name","3061409e":"train_dataset = PlantDataset(df_train, train_list, transform=transform, phase='train')\nval_dataset = PlantDataset(df_train, val_list, transform=transform, phase='val')\ntest_dataset = PlantDataset(df_train, test_list, transform=transform, phase='test')\n\nindex = 0\n\nprint(\"\u3010train dataset\u3011\")\nprint(f\"img num : {train_dataset.__len__()}\")\n# print(f\"img : {train_dataset.__getitem__(index)[0].size()}\")\nprint(f\"label : {train_dataset.__getitem__(index)[1]}\")\nprint(f\"image name : {train_dataset.__getitem__(index)[2]}\")\n\nprint(\"\\n\u3010validation dataset\u3011\")\nprint(f\"img num : {val_dataset.__len__()}\")\n# print(f\"img : {val_dataset.__getitem__(index)[0].size()}\")\nprint(f\"label : {val_dataset.__getitem__(index)[1]}\")\nprint(f\"image name : {val_dataset.__getitem__(index)[2]}\")\n\nprint(\"\\n\u3010test dataset\u3011\")\nprint(f\"img num : {test_dataset.__len__()}\")\n# print(f\"img : {test_dataset.__getitem__(index)[0].size()}\")\nprint(f\"label : {test_dataset.__getitem__(index)[1]}\")\nprint(f\"image name : {test_dataset.__getitem__(index)[2]}\")","29efa933":"train_dataloader = DataLoader(train_dataset, batch_size=Config.batch_size,shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False)\n\n# to Dictionary\ndataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader, \"test\": test_dataloader}","b5717dd9":"from sklearn.metrics import f1_score, accuracy_score","4755b116":"model_config = {\n    \"name\": \"2 FCs, 0.0001 Lr, 30 Epochs\",\n    \"classifier\": torch.nn.Sequential(\n                  torch.nn.Linear(1024, 512),\n                  torch.nn.Linear(512, 12)),\n    \"lr\": 0.0001,\n    \"epoch\": 30\n}","e0804376":"use_pretrained = True\npretrained_model = models.densenet121(pretrained=True)","874e4446":"pretrained_model","5aa52d13":"name, classifier, lr, epoch = model_config.values()\n\npretrained_model.classifier = classifier\n\nprint(f'Model name: {name}')\nprint(pretrained_model)","5c882f7c":"def lr_finder(model, min_lr, max_lr, dataset_lenght=train_dataset.__len__(), \\\n              batch_size=Config.batch_size, criterion=Config.criterion):\n    iter_lrs = [min_lr]\n    iter_losses = []\n    \n    factor = np.exp(np.log(max_lr \/ min_lr) \/ (dataset_lenght \/ batch_size))\n    \n    # Train model with 1 epoch\n    model.to(Config.device)\n    for i, data in tqdm(enumerate(dataloaders_dict['train']), total=len(dataloaders_dict['train'])):\n        \n        optimizer = Adam(model.parameters(), lr=min_lr)\n        \n        # set inputs, labels based on dataloader's batch data\n        inputs = data[0]['image']\n        labels = data[1]\n        inputs = inputs.to(Config.device)\n        labels = labels.to(Config.device)\n\n        #zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        \n        # backward + optimize only if in training phase\n        loss.backward()\n        optimizer.step()\n                \n        # Update and append next iteration learning rate\n        iter_lrs.append(min_lr)\n        min_lr = min_lr * factor\n        \n        # Append this iteration loss\n        iter_losses.append(np.log(loss.cpu().data.numpy().tolist()))\n        \n    iter_lrs.pop()\n    \n    # Plot loss vs log-scaled learning rate\n    plt.figure(figsize=(10, 7))\n    plot = sns.lineplot(iter_lrs, iter_losses)\n    plot.set(xscale=\"log\", \n             xlabel=\"Learning Rate (log-scale)\", \n             ylabel=\"Training Loss\",\n             title=\"Optimal learning rate is slightly below minimum\")","30e5a609":"test_model = copy.deepcopy(pretrained_model)\nlr_finder(test_model, Config.min_lr, Config.max_lr)","9c3e55e1":"Config.lr = 10**-3\noptimizer = Adam(pretrained_model.parameters(), lr=Config.lr)","0560e7db":"def plot_result(train_losses, train_accuracy, train_f1, val_losses, val_accuracy, val_f1):\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 7))\n    ax1.plot(train_losses, label='Train')\n    ax1.plot(val_losses, label='Validation')\n    ax1.set_title('Loss')\n    ax1.legend()\n\n    ax2.plot(train_accuracy, label='Train')\n    ax2.plot(val_accuracy, label='Validation')\n    ax2.set_title('Accuracy')\n    ax2.legend()\n\n    ax3.plot(train_f1, label='Train')\n    ax3.plot(val_f1, label='Validation')\n    ax3.set_title('F1 Score')\n    ax3.legend()","5aa0d8bb":"def append_list(list, appended):\n    for el in appended:\n        list.append(el)\n    return list","0c9c01d6":"def train_model(model, criterion, optimizer, num_epochs=Config.epochs):\n    \n    train_losses = []\n    train_accuracy = []\n    train_f1 = []\n\n    val_losses = []\n    val_accuracy = []\n    val_f1 = []\n    \n    print(f\"Devices to be used : {Config.device}\")\n    model.to(Config.device)\n    torch.backends.cudnn.benchmark = True\n    \n    start_time = time.time()\n        \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n            \n            epoch_targets = []\n            epoch_predictions = []\n\n            # Iterate over data.\n            for i, data in tqdm(enumerate(dataloaders_dict[phase]), total=len(dataloaders_dict[phase])):\n#                 inputs = np.transpose(data[0]['image'], (0, 3, 1, 2))\n                inputs = data[0]['image']\n                labels = data[1]\n                inputs = inputs.to(Config.device)\n                labels = labels.to(Config.device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics                \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n                np_preds = preds.cpu().data.numpy()\n                np_labels = labels.cpu().data.numpy()\n                append_list(epoch_predictions, np_preds)\n                append_list(epoch_targets, np_labels)\n                \n                batch_f1 = f1_score(preds.cpu().data.numpy(), labels.cpu().data.numpy(), average='weighted')\n                \n#                 if i % 50 == 0 and i != 0:\n#                 print(f'Batch: {i}  |  Loss: {loss.item():.4f}   |   F1-score: {batch_f1:.4f}%')         \n\n            epoch_loss = running_loss \/ len(dataloaders_dict[phase].dataset)\n            epoch_acc = running_corrects.double() \/ len(dataloaders_dict[phase].dataset)\n            \n            epoch_f1 = f1_score(epoch_predictions, epoch_targets, average='weighted')\n            \n            if phase == 'train':\n                train_losses.append(epoch_loss)\n                train_accuracy.append(epoch_acc)\n                train_f1.append(epoch_f1)\n            else:\n                val_losses.append(epoch_loss)\n                val_accuracy.append(epoch_acc)\n                val_f1.append(epoch_f1)\n    \n            print('{} Loss: {:.4f} Acc: {:.4f} F1_score: {:.4f}'.format('----> ' + phase.capitalize(), epoch_loss, epoch_acc, epoch_f1))\n            \n    print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed\n    \n    plot_result(train_losses, train_accuracy, train_f1, val_losses, val_accuracy, val_f1)\n    \n    return model","31be9aa7":"trained_model = train_model(pretrained_model, Config.criterion, optimizer)","8a8c7fa1":"def save_model(model, filename):\n    Pkl_Filename = name + \".pkl\"\n\n    with open(Pkl_Filename, 'wb') as file:\n        pickle.dump(model, file)\n        \nsave_model(trained_model, name)","0a4cb0a7":"class PlantPredictor():\n    \"\"\"\n    Class for predicting labels from output results\n    \n    Attributes\n    ----------\n    df_labels_idx: DataFrame\n        DataFrame that associates INDEX with a label name\n    \"\"\"\n    \n    def __init__(self, model, df_labels_idx, dataloaders_dict):\n        self.model = model\n        self.df_labels_idx = df_labels_idx\n        self.dataloaders_dict = dataloaders_dict\n        self.df_submit = pd.DataFrame()\n        \n    \n    def __predict_max(self, out):\n        \"\"\"\n        Get the label name with the highest probability.\n        \n        Parameters\n        ----------\n        predicted_label_name: str\n            Name of the label with the highest prediction probability\n        \"\"\"\n        maxid = np.argmax(out.detach().numpy(), axis=1)\n        df_predicted_label_name = self.df_labels_idx.iloc[maxid]\n        \n        return df_predicted_label_name\n    \n    def inference(self):\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        df_pred_list = []\n        for i, data in enumerate(self.dataloaders_dict['test']):\n            image_name = data[2]\n            self.model.to(device)\n            inputs = data[0]['image']\n            inputs = inputs.to(device)\n            out = self.model(inputs)\n            device = torch.device(\"cpu\")\n            out = out.to(device)\n            df_pred = self.__predict_max(out).reset_index(drop=True)\n            df_pred[\"image\"] = image_name\n            df_pred_list.append(df_pred)\n            \n        self.df_submit = pd.concat(df_pred_list, axis=0)\n        self.df_submit = self.df_submit[[\"image\", \"labels\"]].reset_index(drop=True)","590de0ec":"predictor = PlantPredictor(trained_model, df_labels_idx, dataloaders_dict)\npredictor.inference()\ndf_submit = predictor.df_submit.copy()","54dbef1b":"df_submit.to_csv('submission.csv', index=False)\ndf_submit","630e2749":"# 4. Hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 model","03795d9a":"### 4.2 Save model","29d2042d":"### 5.3 Make submission","e9a1abae":"## 2.4 Create custom Dataset","cc6d785c":"### 4.2 Train model","1877219e":"# 3. Define model","ff60a0da":"## Learning rate finder\nhttps:\/\/towardsdatascience.com\/the-learning-rate-finder-6618dfcb2025","563c9ce6":"## 2.5 Create Dataloader","09e20dac":"### 4.1 C\u00e1c bi\u1ec3u \u0111\u1ed3 c\u1ee7a m\u00f4 h\u00ecnh\n> 1. Loss\n> 2. Accuracy\n> 3. F1","e6d48a2b":"## 2.3 Augumentation\nNh\u1eadn th\u1ea5y ch\u00fang ta c\u00f3 kh\u00e1 \u00edt d\u1eef li\u1ec7u, ...","1a0e21b4":"## 2.2 T\u1ea1o \u0111\u01b0\u1eddng d\u1eabn cho \u1ea3nh v\u00e0 ph\u00e2n chia t\u1eadp hu\u1ea5n luy\u1ec7n, t\u1eadp th\u1ea9m \u0111\u1ecbnh","600a9929":"# 1.  Thi\u1ebft l\u1eadp gi\u00e1 tr\u1ecb c\u1ee7a c\u00e1c tham s\u1ed1 c\u1ed1 \u0111\u1ecbnh\nThi\u1ebft l\u1eadp gi\u00e1 tr\u1ecb c\u1ee7a c\u00e1c tham s\u1ed1 c\u1ed1 \u0111\u1ecbnh c\u00f3 trong b\u00e0i:\n1. *num_classes*: t\u1ed5ng s\u1ed1 l\u01b0\u1ee3ng nh\u00e3n.\n2. *img_size*: k\u00edch th\u01b0\u1edbc c\u1ee7a \u1ea3nh sau qu\u00e1 tr\u00ecnh resized b\u1edfi DataLoader.\n3. *batch_size*: k\u00edch th\u01b0\u1edbc m\u1ed7i batch.\n4. *device*: accelerator \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng.\n5. *criterion*: h\u00e0m m\u1ea5t m\u00e1t (loss function) \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng.","d75bdefa":"## 5.2 Create pridictor ","c24403f9":"# 2. Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u","151e9e5f":"# 5. Make prediction","d2d4cebf":"D\u1ef1a v\u00e0o bi\u1ec3u \u0111\u1ed3, ch\u00fang ta c\u00f3 th\u1ec3 ch\u1ecdn learning rate c\u1ee7a Adam = 10^-3. ","a4d3409f":"There are 12 different labels."}}