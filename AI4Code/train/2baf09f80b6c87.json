{"cell_type":{"0081eb15":"code","9a9dce14":"code","9b4daec0":"code","fd9002de":"code","05e92375":"code","41f66542":"code","9b4162f9":"code","3ab81f5d":"code","8df8e18b":"code","736c2063":"code","fc5aed28":"code","6cabb564":"code","e158fc31":"code","60212f90":"code","cb9fab7f":"code","70149fec":"code","f08ec07f":"code","90823260":"code","d3bf0888":"code","1859b425":"code","d1f4396b":"code","4775e31e":"code","b5fd014a":"code","890d89d5":"code","d9ad0fa0":"code","858b84bc":"code","84e0f416":"code","9a66835d":"code","8cac530c":"code","1a4ee0b2":"code","57b76eb3":"code","28b4fa00":"code","bf1bdc8e":"code","27dbbe64":"code","e7b66291":"code","cf3e4d1d":"code","76529de6":"code","b3b72d5a":"code","f4de5251":"code","d5faaabe":"code","b2f811d2":"code","8848e167":"code","2c557980":"code","621ba530":"code","2730e56e":"code","2f740686":"code","699ba6ec":"code","17a18133":"code","220d429c":"code","ebb0e144":"code","95c3a348":"code","08c6dab6":"code","3610bf94":"code","d4722b19":"code","9632a2d8":"code","41b287b4":"code","3922f2e6":"code","5ebadc0d":"code","d068c365":"code","8111cca0":"code","20a95e8a":"code","b73121da":"code","12fc5bb3":"code","ec5152ea":"code","b8e605e0":"code","a9bf56d0":"code","1e1176c1":"markdown","5da8bff0":"markdown","6b509b70":"markdown","d2c4dbdb":"markdown","d890fb25":"markdown","f37c5be8":"markdown","b636c03c":"markdown","d976047c":"markdown","aca6fb80":"markdown","6ce12810":"markdown","dab9fd74":"markdown","da32ea9e":"markdown","17f5f1df":"markdown","92f1e558":"markdown","710620fb":"markdown","5ca4665b":"markdown","7872ef77":"markdown","de5acb8a":"markdown","ed42124a":"markdown","6889288b":"markdown","67e327c9":"markdown","a6d616a3":"markdown","34319ace":"markdown","380447b2":"markdown","0c051e68":"markdown","d1d0bc80":"markdown","5df71947":"markdown","681b58a5":"markdown","7f23221f":"markdown","36b690ff":"markdown","51836590":"markdown","1de560d1":"markdown","c380f37f":"markdown","517f41e2":"markdown","a203752d":"markdown","42982242":"markdown","d0dba922":"markdown","31d434f3":"markdown","970d626c":"markdown","134890e7":"markdown","9a5020dd":"markdown","d50e88ee":"markdown","aeef534b":"markdown","c13c3971":"markdown","08227b4a":"markdown","630c4522":"markdown","a118faa2":"markdown","5bcde76d":"markdown","a1d5ea5f":"markdown","8249c37f":"markdown","c3e293b6":"markdown","a7e7aadb":"markdown","e7288507":"markdown","66e130d7":"markdown","145250d7":"markdown","419d49a8":"markdown","ee4aee6d":"markdown"},"source":{"0081eb15":"# ignore warnings\nimport sys\nimport warnings\nif not sys.warnoptions:\n       warnings.simplefilter(\"ignore\")","9a9dce14":"# !pip install plotly -Uq\n# import plotly.express as px\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas import Timestamp\nfrom functools import reduce\nfrom scipy import stats as st\nfrom IPython.display import display\nimport numpy as np\n\nimport re\nimport math as mth","9b4daec0":"# metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\n\n# preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix\n\n# modelling\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.utils import shuffle\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cluster import KMeans\n\nfrom xgboost import XGBClassifier\n\n%matplotlib inline","fd9002de":"\ntry:\n    df = pd.read_csv('archive\/WA_Fn-UseC_-Telco-Customer-Churn.csv', index_col=['customerID'])\nexcept:\n    df = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv', index_col=['customerID'])\n\ndisplay(df.sample(10))","05e92375":"def explore(header, df):\n    \"\"\"Prints info, description and percent of missing values for the given table.\n\n    Keyword arguments:\n    header -- the table name\n    df -- the data frame\n    \"\"\"\n    print(F'*****{header} info*****:')\n    print('')\n    df.info();\n    print()   \n    print('\\nGeneral description:')\n    display(df.describe())\n    print('\\nLooking for empty values:')\n    try:\n        print(df.stb.missing(style=True))\n    except:\n        print(df.isna().sum())\n    print('')","41f66542":"explore('conract details',df)","9b4162f9":"df['TotalCharges'].value_counts()","3ab81f5d":"df.loc[df['TotalCharges']==' ','TotalCharges'] = np.nan\ndf = df.dropna()","8df8e18b":"df.isnull().sum()","736c2063":"df['TotalCharges'] = df['TotalCharges'].astype('float')","fc5aed28":"try:\n    print(df.stb.missing(style=True))\nexcept:\n    print(df.isna().sum())","6cabb564":"for col in ('Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup',\n            'DeviceProtection', 'TechSupport', 'StreamingTV',\n            'StreamingMovies', 'MultipleLines', 'PaperlessBilling','PhoneService','Churn'):\n    df[col]= (df[col]=='No').astype(int)","e158fc31":"df.info()","60212f90":"# We will do OHE before Train\/Test\/Validation split for simplicity\n\nohe_encoding = ['Contract','PaymentMethod','InternetService','gender']\ndf_ohe = pd.get_dummies(df[ohe_encoding], drop_first=True)\ndf_ohe.head(5)","cb9fab7f":"# We join back the OHE columns and drop the original ones\ndf = df.join(df_ohe).drop(ohe_encoding, axis=1)","70149fec":"df.hist(edgecolor='black', linewidth=1.2, figsize=(20,15));","f08ec07f":"plt.figure(figsize=(20,20))\nax = sns.heatmap(df.corr(), annot=True, cmap='cividis')\n\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5);\nplt.yticks(rotation=0);","90823260":"# Cohort analysis... didn't work out","d3bf0888":"# df.loc[df['EndDate']=='No', 'EndDate'] = pd.to_datetime('2020-02-01 00:00:00')","1859b425":"# df_retention = df.copy()\n# df_retention = df_retention.query('BeginDate>=\"2019-01-01 00:00:00\"')\n# df_retention['cohort'] = df_retention['BeginDate'].astype('datetime64[M]')\n# df_retention['age'] = ((pd.to_datetime(df_retention['EndDate']) - pd.to_datetime(df_retention['BeginDate'])) \/ np.timedelta64(1,'M')).round().astype('int')\n# display(df_retention.head())","d1f4396b":"# df_retention['uid'] = df_retention.index","4775e31e":"# cohorts = df_retention.pivot_table(index='cohort',\n#                   columns='age',\n#                   values='uid',\n#                   aggfunc='nunique').fillna(0)\n# cohorts","b5fd014a":"df.info()","890d89d5":"df['MonthlyCharges'] = df['MonthlyCharges'].astype(int)\ndf['TotalCharges'] = df['TotalCharges'].astype(int)","d9ad0fa0":"df['PhoneService']","858b84bc":"for column in df:\n    plt.figure()\n    df.boxplot([column])","84e0f416":"df.corr()['Churn'].sort_values().plot(kind='bar', figsize=(12,5));","9a66835d":"# split the data set to 2 sets: training and test. Each set is seperated to features and target-loyal.\nfeatures = df.drop('Churn',axis=1)\ntarget = df['Churn']\nfeatures_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.15, random_state=12345)\n","8cac530c":"print('features_train:',features_train.shape), print('target_train: ',target_train.shape)\n# print('features_valid: ',features_valid.shape), print('target_valid: ',target_valid.shape)\nprint('features_test: ',features_test.shape), print('target_test: ',target_test.shape)","1a4ee0b2":"df_clusters = df.drop('Churn',axis=1)\ndistortion = []\nK = range(1, 8)\nfor k in K:\n    model = KMeans(n_clusters=k, random_state=12345)\n    model.fit(df_clusters)\n    distortion.append(model.inertia_)","57b76eb3":"plt.figure(figsize=(12, 8))\nplt.plot(K, distortion, 'bx-')\nplt.xlabel('Number of clusters')\nplt.ylabel('Objective function value')\nplt.show()","28b4fa00":"# # Training a model for 4 clusters\n# df_clusters = df_clusters[['PaperlessBilling', 'MonthlyCharges', 'TotalCharges',\n#        'MultipleLines','has_internet', 'SeniorCitizen', 'Lifetime',\n#        'Type_One year', 'Type_Two year',\n#        'PaymentMethod_Credit card (automatic)',\n#        'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check',\n#        'InternetService_DSL', 'InternetService_Fiber optic']]\n\n# model = KMeans(n_clusters=4, random_state=12345)\n# model.fit(df_clusters)\n# centroids = pd.DataFrame(model.cluster_centers_, columns=df_clusters.columns)\n# df_clusters['label'] = model.labels_.astype(str)\n# centroids['label'] = ['0 centroid', '1 centroid', '2 centroid', '3 centroid']\n# data_all = pd.concat([df_clusters, centroids], ignore_index=True)\n\n# # Plot the graph\n# sns.pairplot(data_all, hue='label', diag_kind='hist')\n","bf1bdc8e":"# Training a model for 2 clusters\ndf_clusters = df_clusters[['PaperlessBilling', 'MonthlyCharges', 'TotalCharges',\n       'MultipleLines', 'SeniorCitizen', 'tenure',\n       'PaymentMethod_Credit card (automatic)',\n       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check', 'InternetService_Fiber optic']]\nscaler = MinMaxScaler()\n\nscaler.fit_transform(df_clusters)\n\n\nmodel = KMeans(n_clusters=2, random_state=12345)\nmodel.fit(df_clusters)\ncentroids = pd.DataFrame(model.cluster_centers_, columns=df_clusters.columns)\ndf_clusters['label'] = model.labels_.astype(str)\ncentroids['label'] = ['0 centroid', '1 centroid']\ndata_all = pd.concat([df_clusters, centroids], ignore_index=True)\n\n# Plot the graph\nsns.pairplot(data_all, hue='label', diag_kind='hist')\n","27dbbe64":"import sklearn.metrics as metrics\n\ndef evaluate_model(model, train_features, train_target, test_features, test_target):\n    '''\n     Calculate and prints the following metrics for train set and test set:\n     Accuracy, F1 , APS and ROC AUC\n     Prints 3 graphs:\n     F1 Score, ROC curve and PRC \n    '''\n    \n    eval_stats = {}\n    \n    fig, axs = plt.subplots(1, 3, figsize=(20, 6)) \n    \n    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):\n        \n        eval_stats[type] = {}\n    \n        pred_target = model.predict(features)\n        pred_proba = model.predict_proba(features)[:, 1]\n        \n        # F1\n        f1_thresholds = np.arange(0, 1.01, 0.05)\n        f1_scores = [metrics.f1_score(target, pred_proba>=threshold) for threshold in f1_thresholds]\n        \n        # ROC\n        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)\n        roc_auc = metrics.roc_auc_score(target, pred_proba)    \n        eval_stats[type]['ROC AUC'] = roc_auc\n\n        # PRC\n        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)\n        aps = metrics.average_precision_score(target, pred_proba)\n        eval_stats[type]['APS'] = aps\n        \n        if type == 'train':\n            color = 'blue'\n        else:\n            color = 'green'\n\n        # F1 Score\n        ax = axs[0]\n        max_f1_score_idx = np.argmax(f1_scores)\n        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')\n        # setting crosses for some thresholds\n        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n            closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))\n            marker_color = 'orange' if threshold != 0.5 else 'red'\n            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)\n        ax.set_xlim([-0.02, 1.02])    \n        ax.set_ylim([-0.02, 1.02])\n        ax.set_xlabel('threshold')\n        ax.set_ylabel('F1')\n        ax.legend(loc='lower center')\n        ax.set_title(f'F1 Score') \n\n        # ROC\n        ax = axs[1]    \n        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')\n        # setting crosses for some thresholds\n        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n            closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))\n            marker_color = 'orange' if threshold != 0.5 else 'red'            \n            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)\n        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n        ax.set_xlim([-0.02, 1.02])    \n        ax.set_ylim([-0.02, 1.02])\n        ax.set_xlabel('FPR')\n        ax.set_ylabel('TPR')\n        ax.legend(loc='lower center')        \n        ax.set_title(f'ROC Curve')\n        \n        # PRC\n        ax = axs[2]\n        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')\n        # setting crosses for some thresholds\n        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n            closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))\n            marker_color = 'orange' if threshold != 0.5 else 'red'\n            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)\n        ax.set_xlim([-0.02, 1.02])    \n        ax.set_ylim([-0.02, 1.02])\n        ax.set_xlabel('recall')\n        ax.set_ylabel('precision')\n        ax.legend(loc='lower center')\n        ax.set_title(f'PRC')        \n\n        eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)\n        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)\n    \n    df_eval_stats = pd.DataFrame(eval_stats)\n    df_eval_stats = df_eval_stats.round(2)\n    df_eval_stats = df_eval_stats.reindex(index=('Accuracy', 'F1', 'APS', 'ROC AUC'))\n    \n    print(df_eval_stats)\n    \n    return","e7b66291":"\ndef model_eval(model_name, param_grid, model_headline, features_train, target_train, features_test, target_test):\n    '''\n    Creates a pipeline with standard scaling and the given model.\n    Runs a grid search with cross validation on the train set with the given hyperparameters.\n    Prints the best esrimator models and hyperparameters.\n    Predicts on the test set. (use predict proba on possibe models).\n    Prints the model's confusion matrix.\n    Returns a DF row of the model headline, evaluation metrics and best estimator.\n    '''\n    # creating a pipeline\n    pipeline = Pipeline([('scale', StandardScaler()), ('model', model_name)])\n    # gridsearchcv model\n    model = GridSearchCV(pipeline, param_grid=param_grid , cv=5, scoring= 'roc_auc')\n    model.fit(features_train, target_train)\n    print(model.best_estimator_)\n#     print(model.best_score_.round(3))\n    if hasattr(model.best_estimator_._final_estimator, 'predict_proba'):\n        test_predict_p = model.predict_proba(features_test)[:,1] \n        roc_auc = roc_auc_score(target_test, test_predict_p)\n    else:\n        test_predict = model.predict(features_test)\n        roc_auc = roc_auc_score(target_test, test_predict)\n    test_predict = model.predict(features_test)\n    \n    try:\n        # get importance\n        importance = model.best_estimator_._final_estimator.feature_importances_\n        # summarize feature importance\n        feature_importances=pd.DataFrame({'features':features_test.columns,'importance':importance})\n        print(\"Top 12 important features\")\n#         print(\"Features importance\")\n        display(feature_importances.sort_values('importance',ascending=False),head[12])\n    except:\n        try:\n            feature_importances=pd.DataFrame({'feature':list(features_test.columns),'importance':[abs(i) for i in grid.best_estimator_._final_estimator.coef_[0]]})\n            # summarize feature importance\n            print(\"Top 12 important features\")\n            display(feature_importances.sort_values('importance',ascending=False).head[12])\n        except:\n            print('There is no feature_importances_ attribute for this model')\n            \n    cm = confusion_matrix(target_test, test_predict)\n    # visualize confusion matrix with seaborn heatmap\n\n    cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n    sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n#     print(test_predict)\n    f1 = f1_score(target_test, test_predict)\n    acc = accuracy_score(target_test, test_predict)\n    evaluate_model(model, features_train, target_train, features_test, target_test)\n\n\n    return(pd.DataFrame([[ model.best_score_.round(3),  \n                          acc , f1, roc_auc, model.best_estimator_]], \n                        columns=['Train AUC ROC',\n                                 'Test Accuracy', 'Test F1','Test AUC ROC','Model Params'],\n                       index=[model_headline]))","cf3e4d1d":"%%time\n# train predict model with the matrics of f1 which is better for imbalanced classes and evaluate it with roc_auc\nparams  = {'model__min_samples_leaf':[5, 10, 20], 'model__min_samples_split':[30, 60, 90], 'model__max_depth': [5, 10, 20, 30]}\nmodel   = DecisionTreeClassifier(random_state=12345, class_weight=\"balanced\")\nname    ='Decision Tree'\nresults = model_eval(model, params, name, features_train, target_train, features_test, target_test)","76529de6":"params = {'model__solver':['liblinear','saga'], \n              'model__penalty': [ 'l1', 'l2'],\n              'model__C':[100, 10, 1.0, 0.1, 0.01]}\nmodel   = LogisticRegression(random_state=12345)\nname    ='Logistic Regression'\nresult_row = model_eval(model, params, name, features_train, target_train, features_test, target_test)\nresults = results.append(result_row)\n","b3b72d5a":"params = {'model__n_estimators' : [10, 30,60,100], 'model__learning_rate' : [0.4, 0.1, 0.01], 'model__max_depth' : [2,3,4,6,10]}\nmodel   = XGBClassifier(random_state=12345, verbosity = 0)\nname    ='XGBoost'\nresult_row = model_eval(model, params, name, features_train, target_train, features_test, target_test)\n\nresults = results.append(result_row)","f4de5251":"params = {'model__n_estimators': [130, 135, 140],\n              'model__max_depth':  [7, 8, 9, 10, 11, 12]}\nmodel   = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\nname    ='Random Forest Classifier'\nresult_row = model_eval(model, params, name, features_train, target_train, features_test, target_test)\n\nresults = results.append(result_row)","d5faaabe":"params = {'model__n_estimators': [175, 230], 'model__learning_rate': [0.2,0.35, 0.4],\n                 'model__max_depth': [3, 4, 5, 7], 'model__random_state': [42], }\nmodel   = GradientBoostingClassifier()\nname    ='Gradient Boosting Classifier'\nresult_row = model_eval(model, params, name, features_train, target_train, features_test, target_test)\n\nresults = results.append(result_row)","b2f811d2":"# features_GB = ['Lifetime', 'TechSupport', 'TotalCharges', 'InternetService_Fiber optic', 'MonthlyCharges', 'PaymentMethod_Electronic check', 'OnlineSecurity', 'Type_Two year', 'Type_One year', 'PaperlessBilling', 'MultipleLines', 'OnlineBackup', 'DeviceProtection']#, 'gender_Male', 'SeniorCitizen' ]\n","8848e167":"# params = {'model__n_estimators': [175, 230], 'model__learning_rate': [0.2,0.35, 0.4],\n#                  'model__max_depth': [3, 4, 5, 7], 'model__random_state': [42], }\n# model   = GradientBoostingClassifier()\n# name    ='Gradient Boosting Classifier with features selection'\n# result_row = model_eval(model, params, name, features_train[features_GB], target_train, features_test[features_GB], target_test)\n\n# results = results.append(result_row)\n# # with pd.option_context('display.max_colwidth', 1000):\n# #     display(results)\n","2c557980":"params = {'model__n_estimators': [175, 230], 'model__learning_rate': [0.35, 0.4],\n                 'model__max_depth': [3, 4, 5, 7], 'model__random_state': [42], }\nmodel   = GradientBoostingClassifier()\nname    ='Gradient Boosting Classifier with label'\nresult_row = model_eval(model, params, name, features_train.join(df_clusters['label']), target_train, features_test.join(df_clusters['label']), target_test)\n\nresults = results.append(result_row)\n\n","621ba530":"scaler = MinMaxScaler()\n\nfeatures_train_scaled = features_train.copy()\nfeatures_test_scaled = features_test.copy()\n\nscaler.fit_transform(features_train_scaled)\nscaler.transform(features_test_scaled)","2730e56e":"target_train.value_counts(normalize=True)","2f740686":"0.26594\/0.73406","699ba6ec":"def upsample(features, target, repeat):\n    '''\n    Returns upsampeled balanced tuple of 2 data sets: features and target\n    Keyword arguments:\n        features - features data set\n        target - loyal labels data set\n        repeat - integer, the ratio to multiply the minority lable\n    '''\n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n\n    features_upsampled = pd.concat([features_ones] + [features_zeros] * repeat)\n    target_upsampled = pd.concat([target_ones] + [target_zeros] * repeat)\n\n    features_upsampled, target_upsampled = shuffle(\n        features_upsampled, target_upsampled, random_state=12345\n    )\n\n    return features_upsampled, target_upsampled\n\n\nfeatures_upsampled, target_upsampled = upsample(\n    features_train_scaled, target_train, 3\n)","17a18133":"def downsample(features, target, fraction):\n    '''\n    Returns downsampeled balanced tuple of 2 data sets: features and target\n    Keyword arguments:\n        features - features data set\n        target - loyal labels data set\n        fraction - float, the ratio to multiply the majoority lable\n    '''\n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n\n    features_downsampled = pd.concat(\n        [features_ones.sample(frac=fraction, random_state=12345)]\n        + [features_zeros]\n    )\n    target_downsampled = pd.concat(\n        [target_ones.sample(frac=fraction, random_state=12345)]\n        + [target_zeros]\n    )\n\n    features_downsampled, target_downsampled = shuffle(\n        features_downsampled, target_downsampled, random_state=12345\n    )\n\n    return features_downsampled, target_downsampled\n\n\nfeatures_downsampled, target_downsampled = downsample(\n    features_train, target_train, 0.36\n)","220d429c":"import tensorflow as tf\n# Set the random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_1 = tf.keras.Sequential([\n  tf.keras.layers.Dense(8, activation=\"relu\",input_dim=(features_train.shape[1])),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\n# Compile the model with the ideal learning rate\nmodel_1.compile(loss=\"binary_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(lr=0.01), \n                metrics=['AUC'])\n\n# Fit the model for 20 epochs (5 less than before)\nhistory = model_1.fit(features_train_scaled, target_train, epochs=20, batch_size = 32)\n","ebb0e144":"# Evaluate model on the test dataset\nroc_auc = model_1.evaluate(features_test_scaled, target_test)","95c3a348":"test_predict = model_1.predict(features_test_scaled)","08c6dab6":"f1 = f1_score(target_test, test_predict.round())\nacc = accuracy_score(target_test, test_predict.round())","3610bf94":"result_row = pd.DataFrame([[ 0.824,  \n                          acc , f1, roc_auc[1], model_1]], \n                        columns=['Train AUC ROC',\n                                 'Test Accuracy', 'Test F1','Test AUC ROC','Model Params'],\n                       index=['Neural Network'])\nresults = results.append(result_row)","d4722b19":"import tensorflow as tf\n# Set the random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_2 = tf.keras.Sequential([\n  tf.keras.layers.Dense(8, activation=\"relu\",input_dim=(features_train.shape[1])),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\n# Compile the model with the ideal learning rate\nmodel_2.compile(loss=\"binary_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(lr=0.01), # to adjust the learning rate, you need to use tf.keras.optimizers.Adam (not \"adam\")\n                metrics=[tf.keras.metrics.AUC()])\n\n# Fit the model for 20 epochs (5 less than before)\nhistory = model_2.fit(features_upsampled, target_upsampled, epochs=20)","9632a2d8":"# Evaluate model on the test dataset\nmodel_2.evaluate(features_test_scaled, target_test)","41b287b4":"# Evaluate model on the test dataset\nroc_auc = model_2.evaluate(features_test_scaled, target_test)","3922f2e6":"test_predict = model_2.predict(features_test_scaled)","5ebadc0d":"f1 = f1_score(target_test, test_predict.round())\nacc = accuracy_score(target_test, test_predict.round())","d068c365":"result_row = pd.DataFrame([[ 0.7831,  \n                          acc , f1, roc_auc[1], model_2]], \n                        columns=['Train AUC ROC',\n                                 'Test Accuracy', 'Test F1','Test AUC ROC','Model Params'],\n                       index=['Neural Network with upsampling'])\nresults = results.append(result_row)","8111cca0":"# Set the random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_3 = tf.keras.Sequential([\n  tf.keras.layers.Dense(8, activation=\"relu\",input_dim=(features_train.shape[1])),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\n# Compile the model with the ideal learning rate\nmodel_3.compile(loss=\"binary_crossentropy\",\n                optimizer=tf.keras.optimizers.Adam(lr=0.01), # to adjust the learning rate, you need to use tf.keras.optimizers.Adam (not \"adam\")\n                metrics=[tf.keras.metrics.AUC()])\n\n# Fit the model for 20 epochs (5 less than before)\nhistory = model_3.fit(features_downsampled, target_downsampled, epochs=20)","20a95e8a":"# Evaluate model on the test dataset\nmodel_3.evaluate(features_test, target_test)","b73121da":"# Evaluate model on the test dataset\nroc_auc = model_3.evaluate(features_test_scaled, target_test)","12fc5bb3":"test_predict = model_3.predict(features_test_scaled)","ec5152ea":"f1 = f1_score(target_test, test_predict.round())\nacc = accuracy_score(target_test, test_predict.round())","b8e605e0":"result_row = pd.DataFrame([[ 0.7875,  \n                          acc , f1, roc_auc[1], model_3]], \n                        columns=['Train AUC ROC',\n                                 'Test Accuracy', 'Test F1','Test AUC ROC','Model Params'],\n                       index=['Neural Network with downsampling'])\nresults = results.append(result_row)","a9bf56d0":"with pd.option_context('display.max_colwidth', 1000):\n    display(results.sort_values(by=['Test AUC ROC'],ascending=False))","1e1176c1":"#### Observations:\n* contract:\n    - Type, PaperlessBilling, PaymentMethod should be encoded (maybe OHE)\n    - TotalCharges should be numerical\n* internet:\n    - all columns are objectr and have 2 unique values each, so they should be encoded to numerical (0 and 1)\n* personal:\n    - all columns except for SeniorCitizen should be encoded to numerical\n* phone:\n    - only one column MultipleLines which is numerical with 2 unique values. will be binary( 1 and 0)\n* Since the customer ID is the index it's unique so no duplicated rows.\n* No empty values.","5da8bff0":"### Decision Tree - Baseline model","6b509b70":"### Features and Target distribution\nLet's look at the distributions for each numeric variable in the dataset including the target `Churn`:","d2c4dbdb":"### Split the data to train and test sets\nSince we're working with cross validation it's enough to split to train set and test set (without validation set). The gridsearchCV will split the train set to different subsets of train and validation in each set.","d890fb25":"### XGBoost","f37c5be8":"### Gradient Boosting Classifier with label (KMeans)","b636c03c":"### Encoding - OHE","d976047c":"### Feature engineering - KMeans clustering\nIn order to get additional information from our given features let's try and create a new feature using unsupervised learning model for clustering - The KMeans model. The model will try and create segmentation of the bank's customers that will be called `label`. Later on we will use this feature in addition to the other features and see the effect on the model's scores. But first let's find out what is the most suitable amount of clusters we need.","aca6fb80":"## Preprocessing ","6ce12810":"#### Observations:\n* It seems that most of the variables have week correlations between them. It means that they're not redundant and we cannot remove anyone of them. The only features that have a strong correlation (but not too high) are `InternetService_Fiber optic`  that have strong correlation with `MonthlyCharges`. It means that the internet service and especially the fiber optic service contribute enormausely to the price. It will be inteesting to check the effect on the churn. Also `TotalCharges` is strongly correlated with `tenure` since the longer period we sum the higher the charge.\n\n* All the features have a week correlation to the `Churn` target. (At least there is no indication of data leakage here :) )","dab9fd74":"## Scaling\nFor the neural network model we won't use gridsearchCV hence we will preproccess and scale it beforehand","da32ea9e":"#### Observatiopns:\nIn this model we tried to improve the Gradient Boosting by adding additional feature called `label` we created earlier using KMeans clustering to 2 clusters. As we can see the score is a little lower than before and the overfitting is bigger. This try was fertile as well.","17f5f1df":"### Upsampling","92f1e558":"### Features and Target correlation\n**Let's check how our features correlate with each other:**","710620fb":"### Logistic Regression","5ca4665b":"#### Creating 2 clusters variable","7872ef77":"#### Observations:\nThe XGBoost model performs better than the pbaseline model. ROC AUC score of 0.85 on the test set. We used the following hyperparameters that the grid search found to be best\n\nlearning_rate=0.1, max_depth=2, n_estimators=100,\nThe accuracy is 0.8 - better than the baseline. This model is not so sensitive to the imbalance.The precision is very high. We can see that the train roc curve and the test are very close to each other. It implies that there is no overfitting in this model.","de5acb8a":"#### Observations:\nWe tried both 2 clusters and 4 clusters and in both cases we can see that the pairplot looks bizarre. There aren't any clear patterns of clusters apparently since most of our features are binary. It maybe a good idea to try more advanced models like DBScan ( in other project :) ).","ed42124a":"#### Selecting amount of clusters","6889288b":"## Testing the models","67e327c9":"#### Observations:\nThe strongest correlation to the target is 0.35 which is not so high. It means that we will need more features in order to predict the target well enough. \n`tenure` and `Contract_Two year` have the strongest positive correlation. It make sense because the longer period the customer exists the more satisfied he is and less willing to churn. And I guess that customers that pay by a dual year basis are there for longer and not planning to leave the company.\n\nOn the other side `onlineSecurity` and `TechSupport` have the strongest negative correlation to the target. I guess people that have these services are not satisfied and would more probably leave the company. It's worth to check the quality of those services any maybe improve them.\n\n`PhoneService` and `gender` have the lowest correlation - almost 0. It probably doesn't affect the possibility to churn.","a6d616a3":"#### Observations:\nThe Random Forest Classifier performs pretty much the same as all the previous models. ROC AUC score of 0.85 on the test set. We used the following hyperparameters:\n\nclass_weight='balanced', max_depth=8, n_estimators=140 \n\nThe accuracy is 0.76 - better than the baseline. Since we dealt with imbalance here we can look on the accuracy which is not so good. Here also the negative values are predicted better than the positive ones. The precision is much better than the recall. The Train ROC curve is hogher than the test curve which implies there is overfitiing in this model.","34319ace":"## Overview of the general information \n<a class=\"anchor\" id='section1'><\/a>","380447b2":"### Features correlation with the target column","0c051e68":"### Changing data types","d1d0bc80":"#### Observations:\nThis time we used only the 10 most important features in the model to try and improve the overfitting and raise the score. Unfortunately the score of the test set dropped a little bit to 0.92 and the train set got higher- it means that the overfitting only grew.","5df71947":"Lets see how many users were active from certain cohorts on a certain time after registration:","681b58a5":"#### Observation:\nFound an empty string in `TotalCharges` so will remove them.","7f23221f":"## Balancing the target data\nCalculate the ratio of positive and negative labels in order to try several techniques to balance the data.","36b690ff":"#### Observations:\nThe downsampling performed even worse than the upsampling...","51836590":"## Description of the Project\n\nThe telecom operator Interconnect would like to be able to forecast their churn of clients. If it's discovered that a user is planning to leave, they will be offered promotional codes and special plan options. Interconnect's marketing team has collected some of their clientele's personal data, including information about their plans and contracts.","1de560d1":"### Models comparison summary","c380f37f":"#### Observations:\n* We examined the balance of the classes for the target column `Churn` and found out it is unbalanced. Only ~25% of the data is negative (0 or not churned). We should either choose models that are not sensitive to this or use upsampling\/downsampling and class_weight='balanced'.\n* Many clients have a very low monthly charges and the rest distribute normally. It will be interesting to check who are those customers and whether they left or stayed.","517f41e2":"### Final Conclusion:\nThe winner model is XGboost with no special preprocessing except for scaling.\n\nWe Decide to use <b>ROC AUC<\/b> as the evaluation for our models since it's very suitable to classification problems and is <b>robust to imbalance<\/b> of the target classes compared to accuracy for example. \nWhen looking at the ROC curve we would like to choose a model that has high TPR (True Positive Rate) and low FPR (False Positive Rate). Since TPR is on the vertical axis and FPR is on the horizontal axis of the ROC curve we would prefer a model that each treshold appears as up and left as possible. It means that the area under the curve and above the linear line describing the random model should be as big as possible- This is the ROC AUC score. \n\nWe kept our eyes on the <b>confusion matrix<\/b> as well to make sure we avoid as much as we can both <b>type I error and type II error.<\/b>\n\n<b>The best ROC AUC score is 0.85 <\/b> which was pretty similiaar to all the models. The test set has a little better results than the train set but to far, meaning that <\/b>there is no overfitting<\/b> here which is good :)\n\nThe best hyperparameters are:\nlearning_rate=0.1, max_depth=2, n_estimators=100\nAccuracy = 0.8\nF1 = 0.87 :)\n\nThe most <b>important features<\/b> that helped this models are \n<b>tenure which had the biggest effect and then TechSupport and TotalCharges<\/b>\n\n<b>Some of the actions weren't so fruitful.<\/b>\n\nFor example- <b>adding clustering feature using the KMeans<\/b> model, using different techniques of scaling (MinMax normalization and standard scaling) and using the <b>downsample and upsample techniques<\/b> for treating imbalance. \nAlso <b>reducing the amount of features based on they're importance<\/b>  didn't change the score much.\nUnfortunately the <b>Neural networks<\/b>  didn't perform well here even after many tweakings to the models architecture and hyperparameters - even worse than the baseline. Although I do believe we can squeeze it more to get better results but since our time is short and there are great, simpler models at hand we decided to leave it as is.\n\nIn general it seems that the most efficient type of models were the gradient boosting based models.\n","a203752d":"#### Observations:\nWe tried to improve our model using upsamle technique to deal with the data imbalance. Unfortunately it didn't help and even reduced it a bit. Let's try a different approach - downsampling.","42982242":"### Import Libraries","d0dba922":"### Looking for weird values","31d434f3":"#### Observations:\n\n* Customer ID is the unique identifier (PK) of all the tables hence I made him the index. It will also make it easier later to join the tables together.\n* Many fields are object type so we will need to transform them to binary or encode them.\n","970d626c":"### Evaluate model helper functions","134890e7":"### Fully connected network model\nTried tuning with different architectures using:\n* different amount of layers (2-4)\n* different amount of neurons in each layer (4-10)\n* different activation function (sigmoid and ReLu)\n* different optimizer (SGD and Adam)\n* different learning rate (0.001-0.5)\n* Different training time - (epochs 15-30)\n* with scaled and unscaled data (MinMaxScaler)\n* Unbalanced via upsampeled and downsampeled\nShowing here only the best evaluation model structure.","9a5020dd":"#### Observations:\nThe Logistic Regression performs only a little bit better and almost the same as the baseline. ROC AUC score of 0.85 on the test set. We used the the following hyperparameters penalty='l1', random_state=12345,\n                                    solver='saga'. The accuracy is 0.81 - better than the baseline. Since we haven't dealt with imbalance here the accuracy is not a good evaluator. Here also the negative values are predicted better that the positive ones. The precision is much better than the recall.","d50e88ee":"### Fully Connected Neural Network with Downsampling","aeef534b":"#### Observations:\nThere aren't any significant outliers so we will leave it as is.","c13c3971":"### Fully connected Neural Network with upsampling","08227b4a":"#### Observations:\nThe Gradient Boosting Classifier has a ROC AUC score of 0.84 on the test set. We used the the following hyperparameters:\nlearning_rate=0.2, n_estimators=175\n\nThe accuracy is 0.8 - better than the baseline. Since we haven't dealt with imbalance here the accuracy is not a good evaluator. The precision is much better than the recall. The F1 score drops to 0 when the threshold is 1. We can see that the train roc curve is much better (and higher) than the test. It implies that there might be overfitting in this model.\nLet's try to select only the features with the highest importance to try and improve it further.","630c4522":"### Gradient Boosting Classifier","a118faa2":"### Downsampling","5bcde76d":"### Random Forest Classifier","a1d5ea5f":"### Remove empty strings","8249c37f":"#### Observations:\nThe Decision tree is our baseline model with ROC AUC score of 0.84 on the test set. We used the class weight = balanced technique to cope with the target imbalance. The accuracy is 0.76 - not great. We can see that the negative values are predicted pretty good while the positive ones are almost good as guessing. The precision is much better than the recall.","c3e293b6":"### Read files","a7e7aadb":"### Gradient Boosting Classifier with features selection","e7288507":"##  Exploring the data","66e130d7":"#### Observations:\nWe tried to implement a DNN model to predict binary calssification label. The results are not shiny. The ROC AUC score is 0.78 which is worse than our baseline model.","145250d7":"The sum of errors gets lower as th number of classes rises. We can see the elbow breaks between 2-5 clusters. Let's try 2 clusters and 4 clusters and see the influence on the models performances.","419d49a8":"# Supervised Machine Learning Research on Interconnect telecom operator","ee4aee6d":"## Description of the data\n\n* The features:\n    * `customerID` \u2014 unique user identifier \n    * `Contract`  \n    * `PaperlessBilling` \n    * `PaymentMethod` \n    * `MonthlyCharges` \n    * `TotalCharges` \n    * `gender` \n    * `SeniorCitizen`\n    * `Partner` \n    * `Dependents`\n    * `InternetService`\n    * `OnlineSecurity` \n    * `OnlineBackup`\n    * `DeviceProtection`\n    * `TechSupport`\n    * `StreamingTV`\n    * `StreamingMovies`\n    * `MultipleLines` \n    * `PhoneService`\n    *`tenure`\n* The target:\n    * `Churn`\n \n\n## Description of the services\nInterconnect mainly provides two types of services:\n\n1. Landline communication. The telephone can be connected to several lines simultaneously.\n2. Internet. The network can be set up via a telephone line (DSL, *digital subscriber line*) or through a fiber optic cable.\n\nSome other services the company provides include:\n\n- Internet security: antivirus software (*DeviceProtection*) and a malicious website blocker (*OnlineSecurity*)\n- A dedicated technical support line (*TechSupport*)\n- Cloud file storage and data backup (*OnlineBackup*)\n- TV streaming (*StreamingTV*) and a movie directory (*StreamingMovies*)\n\nThe clients can choose either a monthly payment or sign a 1- or 2-year contract. They can use various payment methods and receive an electronic invoice after a transaction."}}