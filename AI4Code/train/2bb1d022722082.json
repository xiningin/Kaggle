{"cell_type":{"b0244dc4":"code","b72f8c15":"code","9ecd7707":"code","04c95061":"code","a94fad6d":"code","18840602":"code","19ccd3a2":"code","3c60523b":"code","764a3c4d":"code","3422fda6":"code","1ca74bdc":"code","a67a8dad":"code","4ef15052":"code","b31af3a9":"code","c1cf107a":"markdown","62797a10":"markdown","303b12e5":"markdown","70b7bc1d":"markdown","f9b5e0f6":"markdown","08186fb5":"markdown","2a17b396":"markdown","63738007":"markdown"},"source":{"b0244dc4":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport torch.optim as optim","b72f8c15":"print(\"Tensor = [[1, 2], [3, 4]]\")\nprint(\"Dimension 0: \")\nprint(\"{}\\n\".format(F.softmax(torch.Tensor([[1,2],[3,4]]), dim=0)))\nprint(\"Dimension 1: \")\nprint(\"{}\".format(F.softmax(torch.Tensor([[1,2],[3,4]]), dim=1)))","9ecd7707":"# File paths\n\ntrain_path = r\"..\/input\/fashionmnist\/fashion-mnist_train.csv\"\ntest_path = r\"..\/input\/fashionmnist\/fashion-mnist_test.csv\"\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)","04c95061":"# Training data dataframe to numpy\ny_data = train_data['label'].values\nX_data = train_data.drop(['label'], axis=1).values\n\n# Testing data dataframe to numpy\ny_test_data = test_data['label'].values\nX_test_data = test_data.drop(['label'], axis=1).values","a94fad6d":"# Load training data and convert it to tensors\n\nX_train = torch.tensor(X_data, dtype=torch.float32)\nX_train = X_train\/255\ny_train = torch.tensor(y_data, dtype=torch.int64)\n\n#Loading testing data\ny_test = torch.tensor(y_test_data, dtype=torch.int64)\nX_test = torch.tensor(X_test_data, dtype=torch.float32)","18840602":"# Build the neural network class\n\nclass Net(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(28*28, 64)\n        self.fc2 = nn.Linear(64, 80)\n        self.fc3 = nn.Linear(80, 120)\n        self.fc4 = nn.Linear(120, 10)\n\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return F.log_softmax(x, dim=1)","19ccd3a2":"if torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\n    print(\"Running on a GPU\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"Running on a CPU\")","3c60523b":"model = Net().to(device)\noptimizer = optim.Adam(model.parameters(), lr = 0.001)","764a3c4d":"EPOCHS = 15\nBATCH_SIZE = 20\n\nfor epoch in range(EPOCHS):\n    for i in tqdm(range(0, len(X_train), BATCH_SIZE)):\n        batch_X = X_train[i:i+BATCH_SIZE].view(-1, 28*28)\n        batch_y = y_train[i:i+BATCH_SIZE]\n        \n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n        \n        model.zero_grad()\n        output = model(batch_X)\n        loss = F.nll_loss(output, batch_y)\n        loss.backward() # Backpropagate the loss with respect to weights and biases\n        optimizer.step() # Update weights and biases base on the loss\n        \n    print(\"Epoch {}: Loss: {} - Accuracy: {}\".format(epoch+1, loss, 1.0-loss))","3422fda6":"correct = 0\ntotal = 0\nTEST_BATCH = 20\n\n\nwith torch.no_grad():\n    for i in tqdm(range(0, len(X_test), TEST_BATCH)):\n        batch_X = X_test[i:i+TEST_BATCH].view(-1,28*28).to(device)\n        batch_y = y_test[i:i+TEST_BATCH]\n        preds = model(batch_X)\n        \n        out_maxes = [torch.argmax(i) for i in preds]\n        \n        for idx, j in enumerate(out_maxes):\n            if j == batch_y[idx]:\n                correct+=1\n            total+=1\n        \n    print(\"val accuracy-{}\".format(correct\/total))","1ca74bdc":"import matplotlib.pyplot as plt","a67a8dad":"with torch.no_grad():\n    predictions = model(X_test[0:5].view(-1,28*28).to(device))\n    pred_class = [torch.argmax(i).tolist() for i in predictions]","4ef15052":"class_label = {0: 'T-shirt\/top',\n            1:  'Trouser',\n            2: 'Pullover',\n            3:  'Dress',\n            4: 'Coat',\n            5: 'Sandal',\n            6: 'Shirt',\n            7: 'Sneaker',\n            8: 'Bag',\n            9: 'Ankle boot'}\n","b31af3a9":"fig, axes = plt.subplots(1,5, figsize=(20,5))\naxes[0].imshow(X_test[0].view(28,28))\naxes[0].set_title(class_label[pred_class[0]])\n\naxes[1].imshow(X_test[1].view(28,28))\naxes[1].set_title(class_label[pred_class[1]])\n\naxes[2].imshow(X_test[2].view(28,28))\naxes[2].set_title(class_label[pred_class[2]])\n\naxes[3].imshow(X_test[3].view(28,28))\naxes[3].set_title(class_label[pred_class[3]])\n\naxes[4].imshow(X_test[4].view(28,28))\naxes[4].set_title(class_label[pred_class[4]])","c1cf107a":"> Creating our training loop","62797a10":">How does dimesionality works?","303b12e5":"# **INTRODUCTION**\n* > Fashion-MNIST is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples\n* > Each example is a 28x28 grayscale image, associated with a label from 10 classes\n* > Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.\n* > Each row in the dataset corresponds to 1 image\n* > Column 1 in the dataset contains the label for each image\n\n\n**Labels**\n* 0 T-shirt\/top\n* 1 Trouser\n* 2 Pullover\n* 3 Dress\n* 4 Coat\n* 5 Sandal\n* 6 Shirt\n* 7 Sneaker\n* 8 Bag\n* 9 Ankle boot","70b7bc1d":"> Visualizing test data and its predicted class","f9b5e0f6":"> Creating the validation loop","08186fb5":"**References**\n* [https:\/\/www.oreilly.com\/library\/view\/tensorflow-for-deep\/9781491980446\/ch04.html](http:\/\/)\n* [https:\/\/towardsdatascience.com\/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464](http:\/\/)\n* [https:\/\/towardsdatascience.com\/diy-ai-an-old-school-matrix-nn-401a00021a55](http:\/\/)","2a17b396":"**Note**\n\nHi, this was my first try on neural network using Pytorch. \nI'm still learning and have a long way to go. \n\n\n**Feedbacks are always welcome**","63738007":"**Feed Forward Neural Network**\n* A fully connected neural network consists of a series of fully connected layers\n* Each output dimension depends on each input dimension\n* The nodes in fully connected networks are commonly referred to as \u201cneurons.\u201d Consequently, elsewhere in the literature, fully connected networks will commonly be referred to as \u201cneural networks.\u201d This nomenclature is largely a historical accident.\n\n![image.png](attachment:image.png)"}}