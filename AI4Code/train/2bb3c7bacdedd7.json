{"cell_type":{"3aeb4c9f":"code","1d98adfc":"code","a3893bab":"code","2e21d989":"code","e6c47cb7":"code","39db101d":"code","17d08498":"code","ae8e3ea6":"code","694d4aec":"code","6617ec79":"markdown","b8933ec8":"markdown"},"source":{"3aeb4c9f":"import pandas as pd \nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.decomposition import PCA as sklearnPCA\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.utils.multiclass import unique_labels\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Model selection and optimization was done outside of this kernel!","1d98adfc":"data = pd.read_csv(\"..\/input\/data.csv\")","a3893bab":"data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\ndata.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)\nY = data.diagnosis.values\nx_data = data.drop(['diagnosis'], axis=1)\nscaler = StandardScaler()\nX = scaler.fit_transform(x_data)\ndata.head()","2e21d989":"train_X, test_X, train_y, test_y = train_test_split(X, Y, random_state=1)","e6c47cb7":"# Instansiate models\ntree = DecisionTreeClassifier(random_state=1)\nsvm = SVC(probability=True, kernel='linear', C=1, gamma = 0.001)\nlog = LogisticRegression(random_state=0, solver='liblinear', \n                         multi_class='ovr')","39db101d":"eclf = VotingClassifier(estimators=[\n     ('tree', tree), ('svm', svm), ('log', log)\n], voting='soft')","17d08498":"eclf.fit(train_X, train_y)\npred_y = eclf.predict(test_X)\naccuracy_score(test_y, pred_y)","ae8e3ea6":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = ['Malignant', 'Benign']\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\nnp.set_printoptions(precision=2)","694d4aec":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(test_y, pred_y, classes=['Malignant', 'Benign'],\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(test_y, pred_y, classes=['Malignant', 'Benign'], normalize=True,\n                      title='Normalized confusion matrix')","6617ec79":"Results of the voting classifier model are **97.9%**. \n\nFor a more complete view of model performance, I have included both the regular and normalized matrices below. ","b8933ec8":"**Introduction**\n\nReally simple introduction into Voting Classifiers. The final model achieves a 98% accuracy. "}}