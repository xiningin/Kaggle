{"cell_type":{"54f41804":"code","401400e2":"code","90df4569":"code","a73f6c9a":"code","46d338e7":"code","3bc70369":"code","440c8f0c":"code","712d806e":"code","7cdcdd60":"code","de8ef150":"code","a5f7efa1":"code","59a9b986":"code","cff8fd9f":"code","c00d145e":"code","1a585921":"code","88ab484c":"markdown","7f76e50e":"markdown","0894fc61":"markdown","5d37972a":"markdown","6c56dfaf":"markdown","167bd6cd":"markdown","68e8d72a":"markdown"},"source":{"54f41804":"from part1_cleaning import *\ndf1, df2, df3 = get_clean_data()","401400e2":"!pip install vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyzer = SentimentIntensityAnalyzer()\n\nhl_compounds = [] # headline compounds\nds_compounds = [] # description\/preview compounds\n\nfor value in df1[\"Headlines\"].values:\n    hl_compounds.append(analyzer.polarity_scores(value)['compound'])\nfor value in df1[\"Description\"].values:\n    ds_compounds.append(analyzer.polarity_scores(value)['compound'])\n    \nprint(hl_compounds[0:10])\nprint(ds_compounds[0:10])","90df4569":"df1['vs_hl_compounds'] = hl_compounds\ndf1['vs_ds_compounds'] = ds_compounds\ndf1","a73f6c9a":"import matplotlib.pyplot as plt\nplt.scatter(df1['vs_hl_compounds'].values, df1['vs_ds_compounds'].values)\nplt.show()","46d338e7":"# storing data\nvader_df1 = df1\n%store vader_df1","3bc70369":"# loading data\n%store -r df2","440c8f0c":"analyzer = SentimentIntensityAnalyzer()\n\nhl_compounds = [] # headline compounds\nds_compounds = [] # description\/preview compounds\n\nfor value in df2[\"Headlines\"].values:\n    hl_compounds.append(analyzer.polarity_scores(value)['compound'])\nfor value in df2[\"Description\"].values:\n    ds_compounds.append(analyzer.polarity_scores(value)['compound'])\n    \nprint(hl_compounds[0:10])\nprint(ds_compounds[0:10])","712d806e":"df2['vs_hl_compounds'] = hl_compounds\ndf2['vs_ds_compounds'] = ds_compounds\ndf2","7cdcdd60":"plt.scatter(df2['vs_hl_compounds'].values, df2['vs_ds_compounds'].values)\nplt.show()","de8ef150":"# storing data\nvader_df2 = df2\n%store vader_df2","a5f7efa1":"# loading data\n%store -r df3","59a9b986":"analyzer = SentimentIntensityAnalyzer()\n\n# since guardian dataset does not include description\/preview\nhl_compounds = [] # headline compounds\n\nfor value in df3[\"Headlines\"].values:\n    hl_compounds.append(analyzer.polarity_scores(value)['compound'])\n    \nprint(hl_compounds[0:10])","cff8fd9f":"df3['vs_hl_compounds'] = hl_compounds\ndf3","c00d145e":"plt.hist(df3['vs_hl_compounds'], bins = 50)\nplt.show()","1a585921":"# storing data\nvader_df3 = df3\n%store vader_df3","88ab484c":"## Reuters data","7f76e50e":"## CNBC data","0894fc61":"Similar to analysis in TextBlob, I decided to run clustering algorithms on vaderSentiment data as well.","5d37972a":"# Polarity Analysis with vaderSentiment - Financial News Sentiment","6c56dfaf":"## Import data","167bd6cd":"Similar to TextBlob, vaderSentiment also returns the polarity scores of each article's headline and preview. However, vaderSentiment introduce compound score, which taken into account all 3 polarity scores generated (negativity, neutrality, positivity).","68e8d72a":"## The Guardian data"}}