{"cell_type":{"ce9c2f28":"code","57592db6":"code","e3e7445d":"code","7b425fed":"code","f65bd3cb":"code","4029f8ea":"code","f2a3d381":"code","183053bd":"code","23763c2c":"code","1985e168":"code","fa6fd582":"code","983a2241":"code","9bb31798":"code","144d165b":"code","37603240":"code","1ac6bd50":"code","8d956ec2":"code","be2147f9":"code","7a8e0103":"code","fa82ec04":"code","81c40bb1":"code","2e63b972":"code","4e89db5b":"code","1d623a25":"markdown","d01b27ef":"markdown","c81d6e70":"markdown"},"source":{"ce9c2f28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","57592db6":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nTest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","e3e7445d":"full_data =[train,test] ","7b425fed":"train.head()","f65bd3cb":"test.head()","4029f8ea":"train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    \nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n# Create new feature IsAlone from FamilySize\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1","f2a3d381":"for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)","183053bd":"for dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)","23763c2c":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"","1985e168":"for dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n# Group all non-common titles into one single grouping \"Rare\"\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nfor dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;","fa6fd582":"# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)","983a2241":"test.head()","9bb31798":"train.head()","144d165b":"features = ['Pclass','Sex','Age','Parch','Fare','Embarked','Has_Cabin','Name_length','FamilySize','IsAlone','Title']","37603240":"import matplotlib.pyplot as plt\nimport xgboost as xgb\nimport seaborn as sns","1ac6bd50":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","8d956ec2":"y=train.iloc[:,0].values\nx=train.iloc[:,1:].values","be2147f9":"X=test.iloc[:,:].values","7a8e0103":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx = sc.fit_transform(x)\nX = sc.fit_transform(X)","fa82ec04":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=400, max_features='log2')\nrf.fit(x, y)","81c40bb1":"Y=rf.predict(X)","2e63b972":"output = pd.DataFrame({ 'PassengerId': Test['PassengerId'] , 'Survived': Y})","4e89db5b":"output.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","1d623a25":"## Preparing Dataset\nTo make our dataset much cleaner than before, with only numerical values and potentially meaningful features. ","d01b27ef":"## Fitting Model","c81d6e70":"### Titanic Solution with Random Forest Classifier"}}