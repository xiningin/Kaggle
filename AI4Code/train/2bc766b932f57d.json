{"cell_type":{"a7a06902":"code","de6370ef":"code","9d30c457":"code","8067dae0":"code","72769418":"code","edf67bea":"code","3ab3af72":"code","72df3867":"code","fb49738d":"code","2dd446e7":"code","5d73a963":"code","7e60b0e1":"code","6b11b191":"code","b7dd6170":"code","b6fa7b09":"code","bb25f52a":"code","382a159d":"code","7b04e53f":"code","84f14635":"code","b20cd132":"code","8b9db4bc":"code","ba555624":"markdown","cc78d9a2":"markdown","d0666174":"markdown","9fc5b81d":"markdown","3a2711b3":"markdown","f91b960a":"markdown","ae93ff55":"markdown"},"source":{"a7a06902":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","de6370ef":"import gc\nimport hyperopt\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\nfrom hyperopt import space_eval\nimport time\nimport math\nfrom hyperopt.pyll.base import scope\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook as tqdm\nimport lightgbm as lgb\nimport pprint\npp = pprint.PrettyPrinter(indent=4)\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom sklearn.model_selection import KFold","9d30c457":"data_dir= \"\/kaggle\/input\/creditcardfraud\"","8067dae0":"df = pd.read_csv(data_dir + \"\/\" + \"creditcard.csv\")","72769418":"df.head()","edf67bea":"input_cols = [\"V\" + str(x) for x in range(1,29)] + [\"Amount\"]","3ab3af72":"X = df[input_cols]","72df3867":"y = df[\"Class\"]","fb49738d":"y.value_counts()","2dd446e7":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=7)","5d73a963":"# Balance dataset with SMOTE\nsm = SMOTE(random_state=7)\nX_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\nX_train_bal = pd.DataFrame(X_train_bal, columns=input_cols)\ny_train_bal = pd.Series(y_train_bal)","7e60b0e1":"number_of_evals = 300\ndef find_best_params_for_lgb(X, y):\n    evaluated_point_scores = {}\n    \n    def objective(params):\n        garbage=gc.collect()\n        if (str(params) in evaluated_point_scores):\n            return evaluated_point_scores[str(params)]\n        else:          \n            kf = KFold(n_splits=2, random_state=7)\n            scores = []\n            for train_index, test_index in kf.split(X.values):                \n                X_train, X_val = X.values[train_index], X.values[test_index]\n                y_train, y_val = y.values.ravel()[train_index], y.values.ravel()[test_index]\n            \n                train_data = lgb.Dataset(X_train, \n                                label=y_train,\n                                feature_name=list(X.columns),\n                                )\n                \n                validation_data = lgb.Dataset(X_val, \n                                label=y_val,\n                                feature_name=list(X.columns),\n                                )\n                \n                evals_result = {}\n                bst = lgb.train(params, train_data, \n                                valid_sets=[train_data, validation_data], \n                                valid_names=['train', 'val'], \n                                evals_result=evals_result, \n                                num_boost_round=10000,\n                                early_stopping_rounds=100,\n                                verbose_eval=None,\n                               )\n\n                y_val_preds = np.where(bst.predict(X_val) > 0.5, 1, 0)\n                score = f1_score(y_val, y_val_preds)\n                scores.append(score)\n                \n#             print(\"Evaluating params:\")\n#             pp.pprint(params)\n            socre=np.mean(scores).item(0)\n#             print(\"f1: \" + str(score))\n            evaluated_point_scores[str(params)] = -score\n            return -score\n    param_space = {\n            'objective': hp.choice(\"objective\", [\"binary\"]),        \n            \"max_depth\": scope.int(hp.quniform(\"max_depth\", 50, 60, 1)),\n            \"learning_rate\": hp.choice(\"learning_rate\", [0.2]),\n            \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 32, 1024, 10)),   \n            \"max_bin\": scope.int(hp.quniform(\"max_bin\", 50, 250, 10)),\n            \"bagging_fraction\": hp.quniform('bagging_fraction', 0.70, 1.0, 0.05),\n            \"feature_fraction\": hp.uniform(\"feature_fraction\", 0.90, 1.0),\n            \"bagging_freq\": hp.choice(\"bagging_freq\", [1]),\n            \"lambda_l1\": hp.quniform('lambda_l1', 1, 10, 1),        \n            \"lambda_l2\": hp.quniform('lambda_l2', 1, 100, 5),\n            \"loss_function\": hp.choice(\"loss_function\", [\"binary_error\"]), \n            \"eval_metric\": hp.choice(\"eval_metric\", [\"binary_error\"]),\n            \"metric\": hp.choice(\"metric\", [\"binary_error\"]),\n            \"random_state\": hp.choice(\"random_state\", [7]),\n            \"verbose\": hp.choice(\"verbose\", [None])\n        }\n\n    best_params = space_eval(\n        param_space, \n        fmin(objective, \n             param_space, \n             algo=hyperopt.tpe.suggest,\n             max_evals=number_of_evals))    \n    \n    \n    # Finding best number of iterations with learning rate 0.1\n    best_params[\"learning_rate\"] = 0.1\n\n    kf = KFold(n_splits=5)\n\n    num_iterations_array = []\n    for train_index, test_index in kf.split(X.values):                \n        X_train, X_val = X.values[train_index], X.values[test_index]\n        y_train, y_val = y.values.ravel()[train_index], y.values.ravel()[test_index]\n\n        train_data = lgb.Dataset(X_train, \n                        label=y_train,\n                        feature_name=list(X.columns),\n                        )\n\n        validation_data = lgb.Dataset(X_val, \n                        label=y_val,\n                        feature_name=list(X.columns),\n                        )\n\n        evals_result = {}\n        bst = lgb.train(best_params, train_data, \n                        valid_sets=[train_data, validation_data], \n                        valid_names=['train', 'val'], \n                        evals_result=evals_result, \n                        num_boost_round=10000,\n                        early_stopping_rounds=100,\n                        verbose_eval=None,\n                       )\n\n        num_iterations_array.append(bst.best_iteration)        \n\n    best_params[\"num_iterations\"] = int(np.mean(num_iterations_array).item(0))        \n    print (\"Best Hyperparameters found:\")\n    pp.pprint(best_params)\n    return best_params","6b11b191":"best_params = find_best_params_for_lgb(X=X_train_bal, y=y_train_bal)","b7dd6170":"train_data = lgb.Dataset(X_train_bal.values, \n                            label=y_train_bal.values.ravel(),\n                            feature_name=list(X_train_bal.columns),\n                        )","b6fa7b09":"bst = lgb.train(best_params, train_data)","bb25f52a":"y_probs = bst.predict(X_test)","382a159d":"test_score = roc_auc_score(y_test, y_probs)","7b04e53f":"test_score","84f14635":"y_preds = np.where(y_probs > 0.5, 1, 0)","b20cd132":"f1 = f1_score(y_test, y_preds)","8b9db4bc":"f1","ba555624":"The performance of the model can be further improved by exploring the Hyperparameter space at more granuarlity level. This can be achieved by evaluating more combinations of hyperparameter values. This will take more execution time to explore the hyperparameter space to find the optimal parameters.\n\nBayesian Optimization technique can also be used to narrow down search space of Hyperparams.","cc78d9a2":"Calculating F1-Score with sample representing a fraudulant transaction considered as positive sample","d0666174":"Calculating AUC ROC score","9fc5b81d":"This dataset is available in the cleaned format with PCA applied on some unspecified underlying original varilables hidden from public due to its sensitive nature. ","3a2711b3":"Next let's find out the best hyperparameters for LightGBM classifier model. I am using Hyperopt library where objective function calculates the negative f1 score as value to be minimized while searching for the optimal values of hyperparameters using Tree-structured Parzen Estimator (TPE) algorithm to explore hyperparameter space. Finally it will find out the best number of iterations with reduced learning rate for gradient boosting algorithm to be used for training on entire training dataset, before evaluating its performance against test dataset.","f91b960a":"As we can see that the dataset is heavily imbalanced as there are very samples with target class value 1 than 0.","ae93ff55":"We will balance dataset with SMOTE, which will oversample the samples that have minority class as output value by introducing new synthetic samples that have slightly different values of input variables from each other."}}