{"cell_type":{"ce41d717":"code","073137ff":"code","f9c8fb2a":"code","11857f9e":"code","d6a0a667":"code","aa5b6b56":"code","48c972fa":"code","212418e0":"code","19edf339":"code","57f60d31":"code","bd016f18":"code","d5ec75ec":"code","1d7355b8":"code","7186004d":"code","a5e9733f":"code","b37e005a":"code","2dbb05c2":"code","aeeea2c1":"markdown","05f976d0":"markdown"},"source":{"ce41d717":"import os\nimport shutil\nimport zipfile\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\n\nfrom distutils.dir_util import copy_tree\n\nfrom torchvision import transforms, models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler","073137ff":"with zipfile.ZipFile('..\/input\/platesv2\/plates.zip', 'r') as zip_obj:\n   # Extract all the contents of zip file in current directory\n   zip_obj.extractall('\/kaggle\/working\/')","f9c8fb2a":"data_root = '\/kaggle\/working\/plates\/'\ntrain_dir = 'train'\ntest_dir = 'test'\nclass_names = ['cleaned', 'dirty']","11857f9e":"os.makedirs(os.path.join(train_dir), exist_ok=True)\nos.makedirs(os.path.join(train_dir, class_names[0]), exist_ok=True)\nos.makedirs(os.path.join(train_dir, class_names[1]), exist_ok=True)\ncopy_tree(os.path.join(f\"{data_root}\/{train_dir}\"), os.path.join(f\"{train_dir}\"))","d6a0a667":"os.makedirs(os.path.join(test_dir), exist_ok=True)\nfor folder, folders, names in os.walk(f\"{data_root}\/{test_dir}\"):\n    for name in names:\n        ind, ttype = name.split('.')\n        if ttype != 'jpg':\n            continue\n        os.makedirs(os.path.join(test_dir, ind))\n        shutil.copy(os.path.join(data_root, test_dir, name), os.path.join(test_dir, ind, name))","aa5b6b56":"means = [0.485, 0.456, 0.406]\nstds = [0.229, 0.224, 0.225]\nbatch_size = 8\n\ntrain_transforms = transforms.Compose([\n    transforms.CenterCrop(224),\n    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(30),\n    transforms.ToTensor(),\n    transforms.Normalize(means, stds)\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(means, stds)\n])\n\ntrain_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\ntest_dataset = torchvision.datasets.ImageFolder(test_dir, test_transforms)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","48c972fa":"class Identity(torch.nn.Module):\n    \"\"\"layer which just returns input\"\"\"\n    \n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return x\n\nmodel = models.resnet50(pretrained=True)\nmodel.fc = Identity()","212418e0":"def get_outputs(model, data_loader, num_epochs=1):\n    \"\"\"gets features of objects and labels for them (object path for test)\"\"\"\n    \n    X, y = [], []\n    \n    for param in model.parameters():\n        param.requires_grad = False\n    \n    model.eval()\n    \n    for i in range(num_epochs):\n        print(f\"Epoch {i}\")\n        \n        for inputs, labels in data_loader:\n            with torch.set_grad_enabled(False):\n                preds = model(inputs)\n            X.extend(preds.tolist())\n            y.extend(labels.tolist())\n       \n    return np.array(X), np.array(y)","19edf339":"X_train, y_train = get_outputs(model, train_dataloader, 50)","57f60d31":"X_test, test_paths = get_outputs(model, test_dataloader)","bd016f18":"scaler = StandardScaler()\nscaler.fit(np.concatenate([X_train, X_test], axis=0))\nX_train_transformed = scaler.transform(X_train)\nX_test_transformed = scaler.transform(X_test)","d5ec75ec":"def partial_learning(model, output_model, scaler,\n                     X_train, y_train, X_test, test_paths,\n                     test_path, train_path, train_transforms, epochs_num=3):\n    # folder to store new labeled images\n    os.makedirs(os.path.join('additional'), exist_ok=True)\n\n    batch_size = 8\n    first_threshold = 0.95  # when model is 'sure' that plate is dirty\n    second_threshold = 0.05  # when model is 'sure' that plate is clear\n    epochs = 50  # number of times each new picture should be augmented\n    \n    os.makedirs(os.path.join('additional', '0'), exist_ok=True)\n    os.makedirs(os.path.join('additional', '1'), exist_ok=True)\n\n    model.fit(X_train, y_train)\n    pred = model.predict_proba(X_test)[:, 1]\n\n    add_1 = pred > first_threshold\n    add_0 = pred < second_threshold\n\n    print(add_1.sum(), add_0.sum())\n\n    for i in test_paths[add_1]:\n        folder = '0' * (4 - len(str(i))) + str(i)\n        path = f\"{test_path}\/{folder}\/{folder}.jpg\"\n        dest_path = f\"additional\/1\/{i}.jpg\"\n        shutil.copy(os.path.join(path), os.path.join(dest_path))\n    for i in test_paths[add_0]:\n        folder = '0' * (4 - len(str(i))) + str(i)\n        path = f\"{test_path}\/{folder}\/{folder}.jpg\"\n        dest_path = f\"additional\/0\/{i}.jpg\"\n        shutil.copy(os.path.join(path), os.path.join(dest_path))\n\n    add_dataset = torchvision.datasets.ImageFolder(f\"additional\", train_transforms)\n\n    add_dataloader = torch.utils.data.DataLoader(\n        add_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n\n    X_add, y_add = get_outputs(output_model, add_dataloader, 50)\n    X_add = scaler.transform(X_add)\n    X_train = np.concatenate([X_train, X_add], axis=0)\n    y_train = np.hstack([y_train, y_add])\n\n    model.fit(X_train, y_train)\n    return X_train, y_train\n","1d7355b8":"lr = LogisticRegression(C=0.001, max_iter=1000)\nnew_X, new_y = partial_learning(lr, model, scaler, X_train_transformed, y_train, X_test_transformed, test_paths,\\\n                 'test', 'train', train_transforms)","7186004d":"!rm -r additional","a5e9733f":"new_y.shape[0] - y_train.shape[0]","b37e005a":"pred = lr.predict_proba(X_test_transformed)[:, 1]","2dbb05c2":"submission = pd.DataFrame.from_dict({'id': test_paths, 'label': pred})\nsubmission['label'] = submission['label'].map(lambda x: 'dirty' if x > 0.1 else 'cleaned')\nsubmission.set_index('id', inplace=True)\nsubmission.to_csv('submission.csv')","aeeea2c1":"<h4> We got 70(3500 with augmentation) additional dirty plates and 70(3500) cleaned plates<h4>","05f976d0":"<h2>Pipeline description:<\/h2>\n<h3>\n   1) Get features of images from train using pretrained resnet50 (with augmentation)<br><br>\n   2) Train simple logistic regression<br><br>\n   3) Use semi-supervised learning: add to train data those objects from test where probability is very high or very small (also with augmentation)<br><br>\n   4) Retrain logistic regression with new data\n<\/h3>"}}