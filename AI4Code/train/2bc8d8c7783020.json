{"cell_type":{"dc748fef":"code","3afee70f":"code","6bd6587d":"code","a8608d80":"code","5a509dc1":"code","93ae7360":"code","77b4e593":"code","8607d3f2":"code","24e891d7":"code","c8a3db0a":"code","a38dded0":"code","9629c713":"code","fd6149d1":"code","d8ec1e13":"code","dacd594d":"code","fe46a134":"markdown","454c026b":"markdown","f2e04960":"markdown","a7e195b8":"markdown"},"source":{"dc748fef":"import sys\nsys.path.append('\/kaggle\/input\/efficientnet-keras-dataset\/efficientnet_kaggle')","3afee70f":"import numpy as np\nimport pandas as pd \nimport math, re, os\nimport random\nimport gc\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\nprint(\"Tensorflow version \" + tf.__version__)\nfrom sklearn.metrics import accuracy_score\nimport efficientnet.tfkeras as efn\nfrom collections import Counter\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","6bd6587d":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    DEVICE = \"TPU\"\nexcept:\n    DEVICE = \"notTPU\"\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","a8608d80":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\nREPLICAS =  strategy.num_replicas_in_sync\nFILENAMES = tf.io.gfile.glob(\"..\/input\/cassava-leaf-disease-classification\" + '\/test_tfrecords\/ld_test*.tfrec')\nBATCH_SIZE = 128 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [512, 512]\nclasses = ['0', '1', '2', '3', '4']  \n\nos.environ['PYTHONHASHSEED']=str(34)\nos.environ['TF_CUDNN_DETERMINISTIC'] = '1'\nrandom.seed(34)\nnp.random.seed(34)\ntf.random.set_seed(34)","5a509dc1":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['target'], tf.int32)\n    \n    return image, label\n\ndef read_unlabeled_tfrecord(example, return_image_name):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # [] means single entry\n    }\n    \n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum if return_image_name else 0\n\ndef get_val_dataset(files, one_hot = False,\n                    shuffle = False, repeat = False, \n                    labeled = True, return_image_names = True,\n                    batch_size = BATCH_SIZE, dim = IMAGE_SIZE[0]):\n   \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTOTUNE)\n\n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(2048)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTOTUNE)\n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n                    num_parallel_calls=AUTOTUNE) \n\n    if one_hot:\n        ds = ds.map(onehot, num_parallel_calls = AUTOTUNE)\n\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\ndef onehot(image,label):\n    CLASSES = len(classes)\n    return image,tf.one_hot(label,CLASSES)","93ae7360":"VALIDATE = False","77b4e593":"from kaggle_datasets import KaggleDatasets\n\nFOLDS=5\nSEED=34\n\nif VALIDATE: \n    GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-tfrecords-512x512')\n    TRAINING_FILENAMES =  tf.io.gfile.glob(GCS_PATH + '\/*.tfrec')\n    AUG_TYPE = 'CUTMIXUP'","8607d3f2":"from sklearn.model_selection import KFold\n\nif VALIDATE:\n    histories = []\n    oof_pred = []; oof_labels = []\n    kfold = KFold(FOLDS, shuffle = True, random_state = SEED)\n\n    for f, (train_index, val_index) in enumerate(kfold.split(TRAINING_FILENAMES)):\n\n        print('#'*25); print('FOLD',f+1); print('#'*25); print('')\n        print('Getting datasets...'); print('')  \n\n        val_ds = get_val_dataset(list(pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES}).loc[val_index]['TRAINING_FILENAMES']),\n                             one_hot=True,labeled=True, return_image_names=False, repeat=False, shuffle=False)\n\n        #and go!\n        print('Getting model...'); print(''); print('Training model...'); print('')\n\n        model = tf.keras.models.load_model(f'..\/input\/cassava-tensorflow-starter-training\/EFFNET_{f}_34_CUTMIXUP_512_full.h5')\n\n        #get OOF predictions\n        oof_labels.append([target.numpy() for img, target in iter(val_ds.unbatch())])\n        x_oof = val_ds.map(lambda image, image_name: image)\n        oof_pred.append(np.argmax(model.predict(x_oof), axis=-1))\n\n        del model; z = gc.collect()","24e891d7":"if VALIDATE:\n    y_true = np.concatenate(oof_labels)\n    y_preds = np.concatenate(oof_pred)\n\n    print(classification_report(np.argmax(y_true, axis=1) if AUG_TYPE is 'CUTMIXUP' else y_true, y_preds))\n    print(f\"OOF accuracy score: {accuracy_score(np.argmax(y_true, axis=1) if AUG_TYPE is 'CUTMIXUP' else y_true, y_preds)}\")","c8a3db0a":"JPEG_PATH = \"..\/input\/cassava-leaf-disease-classification\/test_images\"\nJPEG_PATH_TR = \"..\/input\/cassava-leaf-disease-classification\/train_images\"\n\nimport cv2\nfrom tqdm.notebook import tqdm\n\ndef load_image(jpeg_path, image_id):\n    img = cv2.imread(os.path.join(jpeg_path, image_id))\/255.0\n    img = cv2.resize(img, (512, 512))[:, :, ::-1]\n\n    return img\ndef generator(filepath, paths, batch_size=32):\n    i=0\n    print(len(paths))\n    while i <= len(paths):\n        batch = []\n        for cpt in range(batch_size):\n            if i + cpt >= len(paths):\n                i += batch_size\n                break\n            batch.append(load_image(filepath, paths[i+cpt]))\n            \n        i += batch_size\n        yield np.stack(batch)","a38dded0":"submission = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\ntr = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')","9629c713":"preds_all = []\n\npreds_model = []\nfor fold in range(FOLDS):\n    print(f\"## FOLD: {fold}\")\n\n    ds_test = generator(JPEG_PATH,submission.image_id.values)\n\n    K.clear_session()\n\n    print('Loading and inferring...')\n    model = tf.keras.models.load_model(f'..\/input\/cassava-tensorflow-starter-training\/EFFNET_{fold}_34_CUTMIXUP_512_full.h5')\n\n    preds = model.predict(ds_test, verbose=True)\n    preds_model.append(preds)                 \n\npreds_model = np.stack(preds_model).mean(0)\npreds_all.append(preds_model)\n\npreds_all = np.stack(preds_all)","fd6149d1":"print(preds_all.shape)\npreds_all","d8ec1e13":"submission[\"label\"] = preds_all.mean(0).argmax(1)\nsubmission.to_csv(\"submission.csv\", index=False)","dacd594d":"submission","fe46a134":"# Validation","454c026b":"# Inference","f2e04960":"# Cassava Starter (Inference)\n\n**This is the inference kernel for [this notebook](https:\/\/www.kaggle.com\/tuckerarrants\/cassava-tensorflow-starter-training). I also included the ability to validate the pre-trained model, but this requires TPU connection and hence will not work for submission. You must validate first with internet on and then turn internet off for submission.**","a7e195b8":"# Helper Functions"}}