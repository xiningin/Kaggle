{"cell_type":{"86d8931b":"code","f99f745e":"code","4583240c":"code","758a7b56":"code","8093e607":"code","d03e9d24":"code","f7f9c003":"code","c10dca5d":"code","144d6634":"code","cb380d87":"code","57bb3ec5":"code","a80629cf":"code","d58000b6":"code","1e7aa346":"code","a9d39137":"code","7650ad01":"code","4690e6b4":"code","48fe78c4":"code","e7600d4b":"markdown"},"source":{"86d8931b":"# !pip install datasets\n# !pip uninstall fsspec -y\n# !pip install fsspec==2021.5.0\n\n!pip install \\\n    \/kaggle\/input\/huggingfaces\/datasets\/datasets* \\\n    \/kaggle\/input\/huggingfaces\/datasets\/huggingface_hub* \\\n    \/kaggle\/input\/huggingfaces\/datasets\/tqdm* \\\n    \/kaggle\/input\/huggingfaces\/datasets\/xxhash*\n!pip uninstall fsspec -y\n!pip install \/kaggle\/input\/huggingfaces\/datasets\/fsspec*","f99f745e":"%env WANDB_DISABLED=true","4583240c":"import os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nfrom datasets import load_dataset\nimport torch\nfrom torch import nn\n\nsns.set()\n%matplotlib inline","758a7b56":"data_dir = '\/kaggle\/input\/commonlitreadabilityprize'\ntrain_data_path = os.path.join(data_dir, 'train.csv')\ntest_data_path = os.path.join(data_dir, 'test.csv')\n\ntrain_df = pd.read_csv(train_data_path)\ntest_df = pd.read_csv(test_data_path)\n\nprint(len(train_df))\nprint(len(test_df))","8093e607":"huggingface_dir = '\/kaggle\/input\/huggingface-bert'\nmodel_dir = os.path.join(huggingface_dir, 'bert-base-cased')\n\ntokenizer = BertTokenizer.from_pretrained(model_dir)\nmodel = BertForSequenceClassification.from_pretrained(model_dir)","d03e9d24":"model.classifier = nn.Linear(768, 1)\nmodel.num_labels = 1","f7f9c003":"inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\nlabels = torch.tensor([0]).unsqueeze(0)  # Batch size 1\ninputs['labels'] = labels\noutputs = model(**inputs)\nloss = outputs.loss\nlogits = outputs.logits\n\nprint(outputs)\nprint(loss)\nprint(logits)","c10dca5d":"train_datasets = load_dataset('csv', data_files=[train_data_path])\ntest_datasets = load_dataset('csv', data_files=[test_data_path])","144d6634":"def tokenize_function(examples):\n    return tokenizer(examples['excerpt'], padding='max_length', truncation=True, max_length=512)\n\nf_train_datasets = train_datasets.map(tokenize_function, batched=True)\nf_train_datasets = f_train_datasets.remove_columns(['id', 'url_legal', 'license', 'excerpt', 'standard_error'])\nf_train_datasets = f_train_datasets.rename_column('target', 'labels')\nf_train_datasets = f_train_datasets.shuffle(seed=42)\n\nf_test_datasets = test_datasets.map(tokenize_function, batched=True)\nf_test_datasets = f_test_datasets.remove_columns(['url_legal', 'license', 'excerpt'])","cb380d87":"n_samples = len(f_train_datasets['train'])\nn_train = int(0.9 * n_samples)\n\nf_train_dataset = f_train_datasets['train'].select(range(n_train))\nf_eval_dataset = f_train_datasets['train'].select(range(n_train, n_samples))\n\nf_test_dataset = f_test_datasets['train']","57bb3ec5":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    logits, labels = logits.squeeze(), labels.squeeze()\n    rmse = np.sqrt(np.mean((labels - logits) ** 2))\n    return {'RMSE': rmse}","a80629cf":"# os.environ['WANDB_API_KEY'] = '19baf7fe1571ebd98eff8449df8e8cbc3d30c634'","d58000b6":"training_args = TrainingArguments(\n    'training_args',\n    num_train_epochs = 5,\n    logging_steps = 200,\n    learning_rate = 1e-4,\n    per_device_train_batch_size = 8,\n    per_device_eval_batch_size = 8,\n    evaluation_strategy = 'steps'\n)\n\ntrainer = Trainer(\n    model = model,\n    train_dataset = f_train_dataset,\n    eval_dataset = f_eval_dataset,\n    compute_metrics = compute_metrics,\n    args = training_args\n)","1e7aa346":"# for x in f_train_dataset:\n#     a = len(x['input_ids'])\n#     print(a)\n\n# # [len(v) for v in f_train_dataset[0].values()]","a9d39137":"trainer.train()","7650ad01":"trainer.evaluate()","4690e6b4":"# model.save_pretrained('model_v1')","48fe78c4":"pred_output = trainer.predict(f_test_dataset)\npred_targets = pred_output.predictions.squeeze()\npred_ids = f_test_dataset['id']\n\nsubmission = pd.DataFrame({\n    'id': pred_ids,\n    'target': pred_targets\n})\n\nsubmission.to_csv('submission.csv', index=False)","e7600d4b":"## Video Tutorial\n\nThis EDA comes along with a video tutorial, check it out [here](https:\/\/www.youtube.com\/watch?v=iiwEW-sg9KE&list=PL_49VD9KwQ_OJCqZOeOlSUQKcr1MyifOc&index=2)."}}