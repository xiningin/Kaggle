{"cell_type":{"cf7a9202":"code","0c75b40c":"code","55d8c9da":"code","67ac0d47":"code","410153d2":"code","da2f8162":"code","8e5b9d2e":"code","7c9cd8dd":"code","b2f97f1f":"code","030b9845":"code","a35b5517":"code","4a67086f":"code","76dae284":"code","acfa8bdd":"code","e3a5e5cb":"code","e900a564":"markdown","7bd97e7b":"markdown","77f1357e":"markdown","b40f3d96":"markdown","3e04de98":"markdown","a5cabedd":"markdown","4f1ac6c5":"markdown","9800a811":"markdown"},"source":{"cf7a9202":"import os\nimport cv2\nimport numpy as np\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\nfrom keras.layers.merge import concatenate\nfrom keras.models import Model, load_model\nfrom keras.callbacks import LearningRateScheduler\nfrom keras import backend as K\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","0c75b40c":"image_path = sorted(os.listdir(\"..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTrain\"))\nlabel_path = sorted(os.listdir(\"..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/yTrain\"))","55d8c9da":"def load_images(inputdir, inputpath, imagesize):\n    imglist = []\n    \n    for i in range(len(inputpath)):\n        img = cv2.imread(inputdir+inputpath[i], cv2.IMREAD_COLOR) \n        img = cv2.resize(img, (imagesize, imagesize), interpolation = cv2.INTER_AREA)\n        img = img[::-1] \n        imglist.append(img)\n        \n    return imglist","67ac0d47":"def segment(label, img_size):\n    labels = []\n    \n    for i in range(len(label)):\n        tmp = label[i].flatten()\n        for j in range(len(tmp)):\n            if tmp[j] > 10:\n                tmp[j] = 200\n                \n        labels.append(tmp.reshape(img_size,img_size,3))\n        \n    return labels","410153d2":"IMAGE_SIZE = 128\n\nimage = load_images(\"..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTrain\/\", image_path, IMAGE_SIZE)\nbefore_label = load_images(\"..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/yTrain\/\", label_path, IMAGE_SIZE)\n\nafter_label = segment(before_label, IMAGE_SIZE)\n\nimage \/= np.max(image)\nafter_label \/= np.max(after_label)","da2f8162":"num = 50\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 2, 1)\nplt.imshow(np.squeeze(image[num]))\n\nax = plt.subplot(1, 2, 2)\nplt.imshow(np.squeeze(after_label[num]))","8e5b9d2e":"def Unet():\n    input_img = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n\n    enc1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(input_img)\n    enc1 = BatchNormalization()(enc1)\n    enc1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc1)\n    enc1 = BatchNormalization()(enc1)\n    down1 = MaxPooling2D(pool_size=2, strides=2)(enc1)\n    \n    enc2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down1)\n    enc2 = BatchNormalization()(enc2)\n    enc2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc2)\n    enc2 = BatchNormalization()(enc2)\n    down2 = MaxPooling2D(pool_size=2, strides=2)(enc2)\n\n    enc3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down2)\n    enc3 = BatchNormalization()(enc3)\n    enc3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc3)\n    enc3 = BatchNormalization()(enc3)\n    down3 = MaxPooling2D(pool_size=2, strides=2)(enc3)\n    \n    enc4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down3)\n    enc4 = BatchNormalization()(enc4)\n    enc4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc4)\n    enc4 = BatchNormalization()(enc4)\n    down4 = MaxPooling2D(pool_size=2, strides=2)(enc4)\n    \n    enc5 = Conv2D(2048, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(down4)\n    enc5 = BatchNormalization()(enc5)\n    enc5 = Conv2D(2048, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(enc5)\n    enc5 = BatchNormalization()(enc5)\n\n    up4 = UpSampling2D(size=2)(enc5)\n    dec4 = concatenate([up4, enc4], axis=-1)\n    dec4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec4)\n    dec4 = BatchNormalization()(dec4)\n    dec4 = Conv2D(1024, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec4)\n    dec4 = BatchNormalization()(dec4)\n    \n    up3 = UpSampling2D(size=2)(dec4)\n    dec3 = concatenate([up3, enc3], axis=-1)\n    dec3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec3)\n    dec3 = BatchNormalization()(dec3)\n    dec3 = Conv2D(512, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec3)\n    dec3 = BatchNormalization()(dec3)\n\n    up2 = UpSampling2D(size=2)(dec3)\n    dec2 = concatenate([up2, enc2], axis=-1)\n    dec2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec2)\n    dec2 = BatchNormalization()(dec2)\n    dec2 = Conv2D(256, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec2)\n    dec2 = BatchNormalization()(dec2)\n    \n    up1 = UpSampling2D(size=2)(dec2)\n    dec1 = concatenate([up1, enc1], axis=-1)\n    dec1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec1)\n    dec1 = BatchNormalization()(dec1)\n    dec1 = Conv2D(128, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(dec1)\n    dec1 = BatchNormalization()(dec1)\n    \n    dec1 = Conv2D(3, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"same\")(dec1)\n    \n    model = Model(input=input_img, output=dec1)\n    \n    return model","7c9cd8dd":"model = Unet()\nmodel.summary()","b2f97f1f":"def castF(x):\n    return K.cast(x, K.floatx())\n\ndef castB(x):\n    return K.cast(x, bool)\n\ndef iou_loss_core(true,pred):  #this can be used as a loss if you make it negative\n    intersection = true * pred\n    notTrue = 1 - true\n    union = true + (notTrue * pred)\n\n    return (K.sum(intersection, axis=-1) + K.epsilon()) \/ (K.sum(union, axis=-1) + K.epsilon())\n\ndef competitionMetric2(true, pred): #any shape can go - can't be a loss function\n\n    tresholds = [0.5 + (i*.05)  for i in range(10)]\n\n    #flattened images (batch, pixels)\n    true = K.batch_flatten(true)\n    pred = K.batch_flatten(pred)\n    pred = castF(K.greater(pred, 0.5))\n\n    #total white pixels - (batch,)\n    trueSum = K.sum(true, axis=-1)\n    predSum = K.sum(pred, axis=-1)\n\n    #has mask or not per image - (batch,)\n    true1 = castF(K.greater(trueSum, 1))    \n    pred1 = castF(K.greater(predSum, 1))\n\n    #to get images that have mask in both true and pred\n    truePositiveMask = castB(true1 * pred1)\n\n    #separating only the possible true positives to check iou\n    testTrue = tf.boolean_mask(true, truePositiveMask)\n    testPred = tf.boolean_mask(pred, truePositiveMask)\n\n    #getting iou and threshold comparisons\n    iou = iou_loss_core(testTrue,testPred) \n    truePositives = [castF(K.greater(iou, tres)) for tres in tresholds]\n\n    #mean of thressholds for true positives and total sum\n    truePositives = K.mean(K.stack(truePositives, axis=-1), axis=-1)\n    truePositives = K.sum(truePositives)\n\n    #to get images that don't have mask in both true and pred\n    trueNegatives = (1-true1) * (1 - pred1) # = 1 -true1 - pred1 + true1*pred1\n    trueNegatives = K.sum(trueNegatives) \n\n    return (truePositives + trueNegatives) \/ castF(K.shape(true)[0])","030b9845":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","a35b5517":"X_train, X_val, T_train, T_val = train_test_split(image, after_label, test_size=0.2)\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[dice_coef])\n\ninitial_learningrate=2e-3\n\ndef lr_decay(epoch):\n    if epoch < 10:\n        return initial_learningrate\n    else:\n        return initial_learningrate * 0.99 ** epoch\n    \ntraining = model.fit(X_train, T_train,epochs=30, batch_size=12, shuffle=True, validation_data=(X_val, T_val), verbose=1,callbacks=[LearningRateScheduler(lr_decay,verbose=1)])","4a67086f":"model.save(\"best_model.h5\")","76dae284":"test_path = os.listdir(\"..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTest\")\ntest_image = load_images(\"..\/input\/tray-food-segmentation\/TrayDataset\/TrayDataset\/XTest\/\", test_path, IMAGE_SIZE)\n\ntest_image \/= np.max(test_image)","acfa8bdd":"results = model.predict(test_image,verbose=1)","e3a5e5cb":"n = 7\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 2, 1)\nplt.imshow(np.squeeze(test_image[n]))\n\nax = plt.subplot(1, 2, 2)\nplt.imshow(np.squeeze(results[n]))","e900a564":"# Create model Unet","7bd97e7b":"Enhance the shading of the original segmentation image","77f1357e":"# Training","b40f3d96":"# Metrics Dice","3e04de98":"# Metrics Iou","a5cabedd":"# Visualize train images","4f1ac6c5":"# Predict","9800a811":"# Visualize Results"}}