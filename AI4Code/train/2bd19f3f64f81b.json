{"cell_type":{"793c65d4":"code","4b697ca2":"code","164552dc":"code","e761edf3":"code","e9ef54b3":"code","e60f3467":"code","47f24934":"code","603492c2":"code","5a17a258":"code","ac56cc07":"code","59211ea3":"markdown","c1438533":"markdown","78551bb7":"markdown","544c6983":"markdown","09a8c555":"markdown","b871e2f9":"markdown","0660ef51":"markdown","354d97b0":"markdown","a7346ff3":"markdown","b11bab03":"markdown"},"source":{"793c65d4":"import os\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Input\nfrom sklearn.model_selection import train_test_split","4b697ca2":"df = pd.read_csv('..\/input\/eergy-efficiency-dataset\/ENB2012_data.csv')","164552dc":"df.describe()\n","e761edf3":"def format_output(data):\n    y1 = data.pop('Y1')\n    y1 = np.array(y1)\n    y2 = data.pop('Y2')\n    y2 = np.array(y2)\n    return y1, y2\n\n\ndef norm(x):\n    return (x - train_stats['mean']) \/ train_stats['std']\n\n\ndef plot_diff(y_true, y_pred, title=''):\n    plt.scatter(y_true, y_pred)\n    plt.title(title)\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.axis('equal')\n    plt.axis('square')\n    plt.xlim(plt.xlim())\n    plt.ylim(plt.ylim())\n    plt.plot([-100, 100], [-100, 100])\n    plt.show()\n\n\ndef plot_metrics(metric_name, title, ylim=5):\n    plt.title(title)\n    plt.ylim(0, ylim)\n    plt.plot(history.history[metric_name], color='blue', label=metric_name)\n    plt.plot(history.history['val_' + metric_name], color='green', label='val_' + metric_name)\n    plt.show()","e9ef54b3":"df = df.sample(frac=1).reset_index(drop=True)\n\n# Split the data into train and test with 80 train \/ 20 test\ntrain, test = train_test_split(df, test_size=0.2)\ntrain_stats = train.describe()\n\n# Get Y1 and Y2 as the 2 outputs and format them as np arrays\ntrain_stats.pop('Y1')\ntrain_stats.pop('Y2')\ntrain_stats = train_stats.transpose()\ntrain_Y = format_output(train)\ntest_Y = format_output(test)\n\n# Normalize the training and test data\nnorm_train_X = norm(train)\nnorm_test_X = norm(test)\n","e60f3467":"# Define model layers.\ninput_layer = Input(shape=(len(train .columns),))\nfirst_dense = Dense(units='128', activation='relu')(input_layer)\nsecond_dense = Dense(units='128', activation='relu')(first_dense)\n\n# Y1 output will be fed directly from the second dense\ny1_output = Dense(units='1', name='y1_output')(second_dense)\nthird_dense = Dense(units='64', activation='relu')(second_dense)\n\n# Y2 output will come via the third dense\ny2_output = Dense(units='1', name='y2_output')(third_dense)\n\n# Define the model with the input layer and a list of output layers\nmodel = Model(inputs=input_layer, outputs=[y1_output, y2_output])\n\nprint(model.summary())","47f24934":"# Specify the optimizer, and compile the model with loss functions for both outputs\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\nmodel.compile(optimizer=optimizer,\n              loss={'y1_output': 'mse', 'y2_output': 'mse'},\n              metrics={'y1_output': tf.keras.metrics.RootMeanSquaredError(),\n                       'y2_output': tf.keras.metrics.RootMeanSquaredError()})","603492c2":"# Train the model for 500 epochs\nhistory = model.fit(norm_train_X, train_Y,\n                    epochs=500, batch_size=10, validation_data=(norm_test_X, test_Y))","5a17a258":"# Test the model and print loss and mse for both outputs\nloss, Y1_loss, Y2_loss, Y1_rmse, Y2_rmse = model.evaluate(x=norm_test_X, y=test_Y)\nprint(\"Loss = {}, Y1_loss = {}, Y1_mse = {}, Y2_loss = {}, Y2_mse = {}\".format(loss, Y1_loss, Y1_rmse, Y2_loss, Y2_rmse))","ac56cc07":"# Plot the loss and mse\nY_pred = model.predict(norm_test_X)\nplot_diff(test_Y[0], Y_pred[0], title='Y1')\nplot_diff(test_Y[1], Y_pred[1], title='Y2')\nplot_metrics(metric_name='y1_output_root_mean_squared_error', title='Y1 RMSE', ylim=6)\nplot_metrics(metric_name='y2_output_root_mean_squared_error', title='Y2 RMSE', ylim=7)","59211ea3":"# **Train the Model**","c1438533":"# **Import the Dependencies**","78551bb7":"# **Utilities**\n\n> We Define a few utilities for data conversion and visualization to make our code more neat","544c6983":"**Information about the Dataset**\n\n\nWe perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.\n\nAttribute Information:\n\nThe dataset contains eight attributes (or features, denoted by X1\u2026X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.\n\nSpecifically:\n\n X1 Relative Compactness |\n  X2 Surface Area |\n  X3 Wall Area |\n  X4 Roof Area |\n  X5 Overall Height |\n  X6 Orientation |\n  X7 Glazing Area |\n  X8 Glazing Area Distribution |\n  y1 Heating Load |\n  y2 Cooling Load ","09a8c555":"# **Configure parameters**\n\n> We specify the optimizer as well as the loss and metrics for each output","b871e2f9":"# **Evaluate the model and Plot Metrics**","0660ef51":" # **Prepare the Data**\n\n> We are using the Dataset from Kaggle and importing with Pandas","354d97b0":"# In This Notebook, We are going to see Energy Efficiency Using Neural Networks","a7346ff3":"# **Build the Model**\n\n> Here is how we'll build the model using the functional syntax. Notice that we can specify a list of outputs (i.e. [y1_output, y2_output]) when we instantiate the Model() class.","b11bab03":"# **Splittng the data**"}}