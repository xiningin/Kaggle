{"cell_type":{"1e01773b":"code","70a67915":"code","5c2de919":"code","48e3609d":"code","46db278e":"code","90a10eaa":"markdown","b2ce3335":"markdown","c67c361f":"markdown","7c0391b5":"markdown","73fd1f37":"markdown"},"source":{"1e01773b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pandas.api.types import is_string_dtype\nimport plotly.express as px\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.corpus import stopwords\nimport string\n\n\nprint(\"Dataset analysis fake news\")\nprint(\"Link - https:\/\/www.kaggle.com\/clmentbisaillon\/fake-and-real-news-dataset\")\nprint(\"Sentiment Analysis of fake news dataset for target Donald Trump\")","70a67915":"df_fake_news = pd.read_csv(r\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")\ntokenizer = TweetTokenizer()\n\n\n#tokenize, remove stopwords, non-alphabetic words, lowercase\ndef preprocess(textstring):\n    stops = set(stopwords.words('english'))\n    punctuations = list(string.punctuation)\n    tokens = tokenizer.tokenize(textstring)\n    return [token.lower() for token in tokens if token.isalpha()\n            and token not in stops and token not in punctuations]\n\n\ndf_trump = df_fake_news[df_fake_news['text'].str.contains(\"trump\")]\ndf_trump['pre_process_text'] = df_trump['text'].apply(preprocess)","5c2de919":"from nltk.sentiment.vader import  SentimentIntensityAnalyzer\nsentiment = SentimentIntensityAnalyzer()\n\ntrump_list = df_trump[\"pre_process_text\"].apply(lambda x : \" \".join(x))\n##create text corpus only of tweets mentioning trump\n\ntrump_txt = \" \".join(trump_list)\nsentiments_score = sentiment.polarity_scores(trump_txt)\nprint(sentiments_score)","48e3609d":"def net_sent_score(x) :\n    score = sentiment.polarity_scores(x)\n    if score.get('neg') > score.get('pos'):\n        return  score.get('neg')* -1\n    else:\n        return  score.get('pos')\n\n\ndf_trump['sent_tokens'] = df_trump[\"pre_process_text\"].apply(lambda x : \" \".join(x))\ndf_trump['sent_score'] = df_trump['sent_tokens'].apply(lambda x : net_sent_score(x))\ndf_trump['date'] = pd.to_datetime(df_trump['date'],errors='coerce')\ndf_trump = df_trump.dropna(subset=['date'])\ndf_trump = df_trump.set_index(['date'])\n# df_trump.index = pd.to_datetime(df_trump.index)","46db278e":"df = df_trump.groupby(pd.Grouper(freq='Y'))['sent_score'].mean()\ndf_trump.plot(y='sent_score')","90a10eaa":"This notebook is extends notebook for fake news dataset analysis\nhttps:\/\/www.kaggle.com\/pulkit21aug\/target-victim-of-fake-news\nIn the above notebook it was identified that Donald Trump is target of fake news dataset\n\nManagement decision problem - Take corrective action in  order to curtail the impact of fake news.\nAnalytics Research Problem - Identify the sentiment expressed for Fake news target - Donal Trump\nResearch Objective\n  1. Pre-process data.  2. Sentiment Analysis.  3. Visualise\n  2. Null Hypothesis - Positive sentiments towards Donald Trump","b2ce3335":"Plot the sentiments over time","c67c361f":"Sentiment Score -\n{'neg': 0.186, 'neu': 0.637, 'pos': 0.177, 'compound': -1.0}\nAs we see the compound score we  reject the null hypothesis that the tweets about Donald trump are positive.","7c0391b5":"Research Objective  - Sentiment over time","73fd1f37":"Sentiment analysis for all the tweets as summary"}}