{"cell_type":{"8481232a":"code","fcf37470":"code","691aee42":"code","cb74fbd9":"code","13934bf9":"code","cfe87164":"code","c8a2141e":"code","723fc528":"code","0ea78b77":"code","bd9b034f":"code","d43e1d07":"code","9d227d28":"code","744d4e13":"code","3d057785":"code","8f31043b":"code","3c5a44b7":"code","e11b068a":"code","19bb6bba":"code","431a2abf":"code","c4b72e30":"code","cd2083e6":"code","93f15a41":"code","aac8ce66":"code","8b46f926":"code","0b40849a":"code","9d9f2a52":"code","f10b93d0":"code","bfc5aa33":"code","bba0a54b":"code","4cd437cc":"code","1a8f4e4b":"code","3a3cadaf":"code","15db7221":"code","71d8ed46":"code","29c79af3":"code","647b14a7":"code","c4958ad8":"code","3496bc82":"code","eeebab00":"code","0bf18189":"code","467cdc0c":"code","3c7605a1":"code","b75360e3":"code","cd919611":"code","7acead37":"code","4f62a181":"code","3467d4aa":"code","0e580300":"code","871ef121":"code","0eaeff3f":"code","16025e58":"code","a4774408":"code","a255fea8":"code","879badd8":"code","9ba84995":"code","eadb6509":"code","f397e705":"code","1360c5a7":"code","ff61aeea":"code","bceb7009":"code","3d90ef0b":"code","37f9d7c9":"code","94e246a0":"code","35b36851":"code","db3161c5":"code","2e3c5c07":"code","e839fbe3":"code","318812ea":"code","f95c40e6":"code","40bbb658":"code","df635651":"code","ba8b2761":"markdown","4cacf991":"markdown","07705609":"markdown","e6822288":"markdown","2199f563":"markdown","5df4350c":"markdown","359e27ac":"markdown","82829078":"markdown","81158e3e":"markdown","f835afe4":"markdown","2b3d0ffa":"markdown","5f2bafdd":"markdown","be0d6cc5":"markdown","34fb526e":"markdown","17ab91ee":"markdown","35ae76c2":"markdown","7836524a":"markdown","b295e81b":"markdown","3ad6795a":"markdown","18561333":"markdown","3334d030":"markdown","6118e9b2":"markdown","90afb9cd":"markdown","fdfbcf14":"markdown","40f0f0a6":"markdown","a0608025":"markdown","fd7fe8bd":"markdown","c84b10dc":"markdown","3bada6c2":"markdown","70b29a3b":"markdown","3ede38d0":"markdown","338c6299":"markdown","df5851f6":"markdown","789cf346":"markdown","47a6042b":"markdown","d3e5403a":"markdown","d6d98cef":"markdown","cdb7070a":"markdown","dbe2e2a1":"markdown","e219b2d1":"markdown","2eea6da4":"markdown","c0e69d56":"markdown","b9323a77":"markdown","8e07c0de":"markdown","f06a0bab":"markdown"},"source":{"8481232a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","fcf37470":"df = pd.read_csv(\"..\/input\/Admission_Predict.csv\",sep = \",\")\ndf=df.rename(columns = {'Chance of Admit ':'Chance of Admit'})","691aee42":"df.head()","cb74fbd9":"df.info()","13934bf9":"df.describe()","cfe87164":"sns.pairplot(df)","c8a2141e":"plt.figure(figsize=(15,8))\nsns.heatmap(df.corr(), annot=True)","723fc528":"plt.figure(figsize=(15,12))\nplt.subplot(2,2,1)\nsns.distplot(df['GRE Score'], color='Orange')\nplt.grid(alpha=0.5)\n\nplt.subplot(2,2,2)\nsns.distplot(df['TOEFL Score'], color='Orange')\nplt.grid(alpha=0.5)\n\nplt.subplot(2,2,3)\nsns.distplot(df['University Rating'], color='Orange')\nplt.grid(alpha=0.5)\n\nplt.subplot(2,2,4)\nsns.distplot(df['CGPA'], color='Orange')\nplt.grid(alpha=0.5)","0ea78b77":"plt.figure(figsize=(10,6))\nsns.countplot(y=df['Research'])\nplt.grid(alpha=0.5)\nplt.xlabel('Students')\nplt.show()","bd9b034f":"print(\"Total number of students with Research : \",(df['Research']==1).sum())\nprint(\"Total number of students with-out Research : \",len(df)-(df['Research']==1).sum())\nprint(\"Percentage of students with Research : \",round(((df['Research']==1).sum()\/len(df))*100,2),'%')","d43e1d07":"plt.figure(figsize=(10,6))\nsns.countplot(y=df['University Rating'])\nplt.grid(alpha=0.5)\nplt.xlabel('Students Count')\nplt.show()","9d227d28":"plt.figure(figsize=(10,6))\nuni_influence = df[df[\"Chance of Admit\"] >= 0.75][\"University Rating\"].value_counts()\nuni_influence.plot(kind='barh')\nplt.grid(alpha=0.5)\nplt.xlabel('Student Count')\nplt.ylabel('University Rating')\nplt.show()","744d4e13":"print('From given University Rating each university has a Student count of:')\nprint('University Rating 1 : ',(df['University Rating']==1).sum())\nprint('University Rating 2 : ',(df['University Rating']==2).sum())\nprint('University Rating 3 : ',(df['University Rating']==3).sum())\nprint('University Rating 4 : ',(df['University Rating']==4).sum())\nprint('University Rating 5 : ',(df['University Rating']==5).sum())","3d057785":"print('From given University Rating and Student count in each university, number of Students having chance >75% of Admit:')\nprint('University Rating 1 : ',uni_influence.iloc[4])\nprint('University Rating 2 : ',uni_influence.iloc[3])\nprint('University Rating 3 : ',uni_influence.iloc[2])\nprint('University Rating 4 : ',uni_influence.iloc[0])\nprint('University Rating 5 : ',uni_influence.iloc[1])","8f31043b":"gre_avg = df['GRE Score'].mean()\ngre_std = df['GRE Score'].std()\nprint(\"Maximum GRE Score : 340\")\nprint(\"Average GRE Score : \",gre_avg)\nprint(\"Standard Deaviation : \",gre_std)\n\ndiff = df['GRE Score']-gre_avg\ndf['SD_GRE'] = diff\/gre_std","3c5a44b7":"toefl_avg = df['TOEFL Score'].mean()\ntoefl_std = df['TOEFL Score'].std()\nprint(\"Maximum TOEFL Score : 120\")\nprint(\"Average TOEFL Score : \",toefl_avg)\nprint(\"Standard Deaviation : \",toefl_std)\n\ndiff = df['TOEFL Score']-toefl_avg\ndf['SD_TOEFL'] = diff\/toefl_std","e11b068a":"cgpa_avg = df['CGPA'].mean()\ncgpa_std = df['CGPA'].std()\nprint(\"Maximum CGPA Score : 10\")\nprint(\"Average CGPA Score : \",cgpa_avg)\nprint(\"Standard Deaviation : \",cgpa_std)\n\ndiff = df['CGPA']-cgpa_avg\ndf['SD_CGPA'] = diff\/cgpa_std","19bb6bba":"df.head()","431a2abf":"sns.pairplot(df, x_vars=['GRE Score','TOEFL Score','CGPA','SD_GRE','SD_TOEFL','SD_CGPA'], y_vars='Chance of Admit')","c4b72e30":"plt.figure(figsize=(16,8))\nsns.heatmap(df.corr(), annot=True)","cd2083e6":"x = df.drop(['Chance of Admit'], axis=1)\ny = df['Chance of Admit']","93f15a41":"x.info()","aac8ce66":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 42)","8b46f926":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()","0b40849a":"lr.fit(x_train, y_train)","9d9f2a52":"coef = pd.DataFrame(lr.coef_, x_test.columns, columns = ['Co-efficient'])","f10b93d0":"coef","bfc5aa33":"y_pred_mlr = lr.predict(x_test)","bba0a54b":"len(x_test)","4cd437cc":"fig = plt.figure()\nc = [i for i in range(1,101,1)]\nplt.plot(c,y_test, color = 'green', linewidth = 2.5, label='Test')\nplt.plot(c,y_pred_mlr, color = 'orange', linewidth = 2.5, label='Predicted')\nplt.grid(alpha = 0.3)\nplt.legend()\nfig.suptitle('Actual vs Predicted')","1a8f4e4b":"from sklearn.metrics import mean_squared_error, r2_score\nmse = mean_squared_error(y_test, y_pred_mlr)\nr_square_score = r2_score(y_test, y_pred_mlr)","3a3cadaf":"print('Mean Square Error = ',mse)\nprint('R_Square Score = ',r_square_score)","15db7221":"fig = plt.figure()\nplt.plot(c,y_test-y_pred_mlr, color = 'orange', linewidth = 2.5)\nplt.grid(alpha = 0.3)\nfig.suptitle('Error Terms')","71d8ed46":"import statsmodels.api as sm","29c79af3":"x_train_sm = x_train\nx_train_sm = sm.add_constant(x_train_sm)\nlml = sm.OLS(y_train, x_train_sm).fit()\nlml.params","647b14a7":"print(lml.summary())","c4958ad8":"x_new = df.drop(['Serial No.','University Rating','SOP','Chance of Admit'], axis=1)\ny_new = df['Chance of Admit']","3496bc82":"x_train_new, x_test_new, y_train_new, y_test_new = train_test_split(x_new,y_new, train_size = 0.7, random_state = 100)","eeebab00":"lr.fit(x_train_new, y_train_new)","0bf18189":"y_pred_new = lr.predict(x_test_new)","467cdc0c":"len(x_test_new)","3c7605a1":"# Actual vs Predicted after removing GRE\nfig = plt.figure()\nc = [i for i in range(1,121,1)]\nplt.plot(c,y_test_new, color = 'green', linewidth = 2.5, label='Test')\nplt.plot(c,y_pred_new, color = 'orange', linewidth = 2.5, label='Predicted')\nplt.grid(alpha = 0.3)\nplt.legend()\nfig.suptitle('Actual vs Predicted')","b75360e3":"mse_new = mean_squared_error(y_test_new, y_pred_new)\nr_square_score_new = r2_score(y_test_new, y_pred_new)\nprint('Mean Square Error = ',mse_new)\nprint('R_Square Score = ',r_square_score_new)","cd919611":"fig = plt.figure()\nplt.plot(c,y_test_new-y_pred_new, color = 'orange', linewidth = 2.5)\nplt.grid(alpha = 0.3)\nfig.suptitle('Error Terms')","7acead37":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()","4f62a181":"y_train_label = [1 if each > 0.8 else 0 for each in y_train]\ny_test_label  = [1 if each > 0.8 else 0 for each in y_test]","3467d4aa":"logmodel.fit(x_train, y_train_label)","0e580300":"y_pred_log = logmodel.predict(x_test)","871ef121":"from sklearn.metrics import classification_report\nprint(classification_report(y_test_label, y_pred_log))","0eaeff3f":"from sklearn.metrics import confusion_matrix\ncm_log = confusion_matrix(y_test_label, y_pred_log)","16025e58":"sns.heatmap(cm_log, annot=True)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","a4774408":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint(\"Accuracy Score = \",accuracy_score(y_test_label, y_pred_log))\nprint(\"precision_score: \", precision_score(y_test_label,logmodel.predict(x_test)))\nprint(\"recall_score: \", recall_score(y_test_label,logmodel.predict(x_test)))\nprint(\"f1_score: \",f1_score(y_test_label,logmodel.predict(x_test)))","a255fea8":"from sklearn.svm import SVC\nsvmmodel = SVC()","879badd8":"svmmodel.fit(x_train,y_train_label)","9ba84995":"y_pred_svm = svmmodel.predict(x_test)","eadb6509":"from sklearn.metrics import confusion_matrix\ncm_svm = confusion_matrix(y_test_label, svmmodel.predict(x_test))","f397e705":"sns.heatmap(cm_svm, annot=True)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","1360c5a7":"from sklearn.metrics import precision_score, recall_score, f1_score\nprint(\"Accuracy Score = \",accuracy_score(y_test_label, y_pred_svm))\nprint(\"precision_score: \", precision_score(y_test_label,svmmodel.predict(x_test)))\nprint(\"recall_score: \", recall_score(y_test_label,svmmodel.predict(x_test)))\nprint(\"f1_score: \",f1_score(y_test_label,svmmodel.predict(x_test)))","ff61aeea":"from sklearn.tree import DecisionTreeRegressor\ndt_model = DecisionTreeRegressor()\ndt_model.fit(x_train,y_train)","bceb7009":"y_pred_dt = dt_model.predict(x_test)","3d90ef0b":"from sklearn.metrics import r2_score\nprint('R_Squared Score = ',r2_score(y_test, y_pred_dt))","37f9d7c9":"from sklearn.preprocessing import StandardScaler \nfrom sklearn.neighbors import KNeighborsClassifier","94e246a0":"import math\nmath.sqrt(len(y_test_label))","35b36851":"knnc = KNeighborsClassifier(n_neighbors = 11, p=2, metric = 'euclidean')","db3161c5":"knnc.fit(x_train, y_train_label)","2e3c5c07":"y_pred_knn = knnc.predict(x_test)","e839fbe3":"y_pred_knn","318812ea":"cm = confusion_matrix(y_test_label, y_pred_knn)\nsns.heatmap(cm, annot=True)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","f95c40e6":"from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\nprint(\"Accuracy Score = \",accuracy_score(y_test_label, y_pred_knn))\nprint(\"precision_score: \", precision_score(y_test_label,knnc.predict(x_test)))\nprint(\"recall_score: \", recall_score(y_test_label,knnc.predict(x_test)))\nprint(\"f1_score: \",f1_score(y_test_label,knnc.predict(x_test)))","40bbb658":"x = [\"Linear_Reg\",\"Decision_Tree_Reg\"]\ny = np.array([r2_score(y_test,y_pred_mlr),r2_score(y_test,y_pred_dt)])\nplt.barh(x,y, color='#225b46')\nplt.xlabel(\"R_Squared_Score\")\nplt.ylabel(\"Regression Models\")\nplt.title(\"Best R_Squared Score\")\nplt.grid(alpha=0.5)\nplt.show()","df635651":"x = [\"KNN\",\"SVM\",\"Logistic_Reg\"]\ny = np.array([accuracy_score(y_test_label, y_pred_knn),accuracy_score(y_test_label, y_pred_svm),accuracy_score(y_test_label, y_pred_log)])\nplt.barh(x,y, color='#225b46')\nplt.xlabel(\"Accuracy Score\")\nplt.ylabel(\"Classification Models\")\nplt.title(\"Best Accuracy Score\")\nplt.grid(alpha=0.5)\nplt.show()","ba8b2761":"# Applying Logistic Regression Model:","4cacf991":"<b>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","07705609":"# Applying Decision Tree Regressor Model:","e6822288":"# Applying Support Vector Machine Model: ","2199f563":"<b>Algorithms Considered:<\/b>\n*      Linear Regression\n*      Logistic Regression\n*      Support Vector Machine\n*      K Nearest Neighbours\n*      Decision Tree Regressor","5df4350c":"<b>Analysis on University Ranking:<\/b> ","359e27ac":"# Comparision Between Models:","82829078":"<b>Goal:<\/b>\n*      The main aim of this kernel is to predict the 'Chance of Admit' with high accuracy by applying various ML Algorithms \n        and then comparing their scores..\n*      Compare different models to check for best model depending on r_squared score and accuracy score","81158e3e":"# Conclusion:","f835afe4":"<b>----------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","2b3d0ffa":"# Applying KNN Model:","5f2bafdd":"<b>By analyzing the data and by applying ML model:<\/b>\n    - In Classification\n        - Logistic Regression was better with accuracy score of 97.0%\n        - K Nearest Neighbour was better with accuracy score of 84.0%\n        - Support Vector Machine was better with accuracy score of 70.0%\n        \n    - In Regression\n        - Linear Regression was better with r_squared score of 82.14%\n        - Decision Tree Regressor was better with r_squared score of 65.81%","be0d6cc5":"<b>------------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","34fb526e":"<b>----------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","17ab91ee":"# Statistical Information using Statsmodels:","35ae76c2":"<b>Constructing Pairplot for new parameters against 'Chance of Admit':<\/b> ","7836524a":"<b>Re-Valuating the Data:<\/b>","b295e81b":"<b>Plotting Actual vs Predicted Values:<\/b>","3ad6795a":"<b>------------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","18561333":"<b>----------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","3334d030":"<b>------------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","6118e9b2":"Since Logistic Regression is a Classification model, 'Continuous Data' will not help to classify the output. Hence we need\nto categorize the data into:\n    - Label 1 for Chance of Admit greater or equal to 80%\n    - Label 0 for Chance of Admit lesser than 80%","90afb9cd":"<b>Problem Statement:<\/b>\n    \n    The main goal of this problem is to predict the 'Chance of Admit' of a \n    student in a perticular university given various parameters such  as:\n    \n*         GRE Scores(out of 340)\n*         TOEFL Scores(out of 120)\n*         University Rating(out of 5)\n*         Statement of Purpose and Letter of Recommendation Strength(out of 5)\n*         Undergraduate GPA(out of 10)\n*         Research Experience(either 0 or 1)\n    ","fdfbcf14":"<b>------------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","40f0f0a6":"<b>Checking for any Linear Relationship between the given Parameters:<\/b>\n*      By constructing Pairplot\n*      By constructing Correlation heatmap ","a0608025":"<b>Comparing Classification Models:<\/b>","fd7fe8bd":"<b>Comparing Regression Models:<\/b>","c84b10dc":"<b>Making basic Insights about given data:<\/b>","3bada6c2":"<b>Constructing Heatmap of Corelation for new parameters against 'Chance of Admit':<\/b> ","70b29a3b":"<b>Calculating Error Terms:<\/b>","3ede38d0":"<b>--------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","338c6299":"<b>Analysis on Research Column:<\/b>","df5851f6":"<b>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","789cf346":"<b>Reading Data as CSV File:<\/b>","47a6042b":"If 'p > 0.05' for a 95% level of confidence:\n- Ho : Value is not significant\n- H1 : Value is significant\nSince in GRE p(0.065) > 0.05 so 'we fail to reject Ho' ","d3e5403a":"<b>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","d6d98cef":"<b>Importing Python Packages:<\/b>\n*      Pandas\n*      Numpy\n*      Matplotlib\n*      Seaborn\n","cdb7070a":"<b>From above we can infer that :<\/b>\n- If GRE Score increases by 1 then Chance of Admit will be affected by 0.002092\n- If TOEFL increases by 1 then Chance of Admit will be affected by 0.003529\n- If University Rating increases by 1 then Chance of Admit will be affected by 0.008793\n  <br>and so on...<\/br>","dbe2e2a1":"# Splitting Data For Training & Testing","e219b2d1":"<b>Mean and Standard Deviation of 'GRE Score', 'TOEFL Score', 'CGPA' has been accounted to compare students easily as the \nstudents with positive standard deviation tend to perform well as compared to majority of people i.e scores better than\nthat of mean value<\/b>","2eea6da4":"<b>-------------------------------------------------------------------------------------------------------------------------------------------------------------------<\/b>","c0e69d56":"<b>From above the Parameters with High Corelation against 'Chance of Admit' are:<\/b>\n*      GRE Score\n*      TOEFL Score\n*      CGPA","b9323a77":"# Applying Linear Regression Model:","8e07c0de":"<b>The Co-efficients for the following parameters are:<\/b>","f06a0bab":"<b>Distribution of Parameters:<\/b>"}}