{"cell_type":{"261f5a5b":"code","78c16d78":"code","47e2330b":"code","7819d3a6":"code","2a57c470":"code","653f6ede":"code","928c6f1c":"code","b04f5f62":"code","69e4f43d":"code","4a97b235":"code","edc3500b":"code","a8a4a828":"code","7a8aca02":"code","9e7ad1ec":"markdown","046230d1":"markdown","04439932":"markdown","67af00be":"markdown","a1f0572f":"markdown","1219340c":"markdown"},"source":{"261f5a5b":"%cd \/kaggle\n!mkdir YOLO\n!unzip -o input\/github-yolov5\/yolov5.zip -d YOLO\/","78c16d78":"%ls YOLO\/yolov5","47e2330b":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","7819d3a6":"import numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut","2a57c470":"# reference: https:\/\/www.kaggle.com\/xhlulu\/siim-covid-19-convert-to-jpg-256px\/notebook?scriptVersionId=63196459\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","653f6ede":"TEST_PATH = '\/kaggle\/tmp\/test_data\/'\nos.makedirs(TEST_PATH, exist_ok=True)\ndims_mapping = dict()\n\nfor dirname, _, filenames in tqdm(os.walk(f'\/kaggle\/input\/siim-covid19-detection\/test')):\n    for file in filenames:\n        # set keep_ratio=True to have original aspect ratio\n        xray = read_xray(os.path.join(dirname, file))\n        im = resize(xray, size=256)\n        im.save(os.path.join(TEST_PATH, file.replace('dcm', 'jpg')))\n        dims_mapping[file.replace('.dcm', '')] = xray.shape","928c6f1c":"MODEL_PATH = '\/kaggle\/input\/yolov5s-20epochs\/best.pt'\nIMG_SIZE = 256","b04f5f62":"%cd \/kaggle\/YOLO\/yolov5\n!python detect.py --weights {MODEL_PATH} \\\n                  --source {TEST_PATH} \\\n                  --img {IMG_SIZE} \\\n                  --conf 0.281 \\\n                  --iou-thres 0.5 \\\n                  --max-det 3 \\\n                  --save-txt \\\n                  --save-conf","69e4f43d":"PRED_PATH = 'runs\/detect\/exp\/labels'\nprediction_files = os.listdir(PRED_PATH)\nprint('Number of test images predicted as opacity: ', len(prediction_files))","4a97b235":"# The submisison requires xmin, ymin, xmax, ymax format. \n# YOLOv5 returns x_center, y_center, width, height\ndef correct_bbox_format(bboxes, id_name):\n    correct_bboxes = []\n    H, W = dims_mapping[id_name]\n    for b in bboxes:\n        xc, yc = int(np.round(b[0] * W)), int(np.round(b[1] * H))\n        w, h = int(np.round(b[2] * W)), int(np.round(b[3] * H))\n\n        xmin = xc - int(np.round(w\/2))\n        xmax = xc + int(np.round(w\/2))\n        ymin = yc - int(np.round(h\/2))\n        ymax = yc + int(np.round(h\/2))\n        \n        correct_bboxes.append([xmin, ymin, xmax, ymax])\n        \n    return correct_bboxes\n\n# Read the txt file generated by YOLOv5 during inference and extract \n# confidence and bounding box coordinates.\ndef get_conf_bboxes(file_path):\n    confidence = []\n    bboxes = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            preds = line.strip('\\n').split(' ')\n            preds = list(map(float, preds))\n            confidence.append(preds[-1])\n            bboxes.append(preds[1:-1])\n    return confidence, bboxes","edc3500b":"sub_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df.tail()","a8a4a828":"# Prediction loop for submission\npredictions = []\n\nfor i in tqdm(range(len(sub_df))):\n    row = sub_df.loc[i]\n    id_name = row.id.split('_')[0]\n    id_level = row.id.split('_')[-1]\n    \n    if id_level == 'study':\n        # do study-level classification\n        predictions.append(\"negative 1 0 0 1 1\") # dummy prediction\n        \n    elif id_level == 'image':\n        # we can do image-level classification here.\n        # also we can rely on the object detector's classification head.\n        # for this example submisison we will use YOLO's classification head. \n        # since we already ran the inference we know which test images belong to opacity.\n        if f'{id_name}.txt' in prediction_files:\n            # opacity label\n            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}\/{id_name}.txt')\n            bboxes = correct_bbox_format(bboxes, id_name)\n            pred_string = ''\n            for j, conf in enumerate(confidence):\n                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n            predictions.append(pred_string[:-1]) \n        else:\n            predictions.append(\"none 1 0 0 1 1\")","7a8aca02":"sub_df['PredictionString'] = predictions\nsub_df.to_csv('\/kaggle\/working\/submission.csv', index=False)\nsub_df.tail()","9e7ad1ec":"## \ud83d\udcbe Submit","046230d1":"## \ud83e\udd84 Acknowledgement\n- Title...................: [Train] COVID-19 Detection using YOLOv5\n- Link....................: https:\/\/www.kaggle.com\/ayuraj\/train-covid-19-detection-using-yolov5#%E2%98%80%EF%B8%8F-Imports-and-Setup\n- Author..............: Ayush Thakur (https:\/\/www.kaggle.com\/ayuraj)\n- Version.............: 10","04439932":"## \ud83d\udcf7 Transform test data","67af00be":"This is the inferring version of above [notebook](https:\/\/www.kaggle.com\/ayuraj\/train-covid-19-detection-using-yolov5#%E2%98%80%EF%B8%8F-Imports-and-Setup). Since our inferring code needs to be run with hidden dataset in a disconnected state, so we need to process test data from scratch in this code, at the same time introduce the pre-trained model and yolov5 repository. \n\n**Notice:**\n- This code is only for image level samples, and keep the \"PredictionString\" of study level samples same as submission.csv.\n- This notebook use yolov5s which trained 20 epochs as pretrained model, you could train your own yolov5 model with [this notebook](https:\/\/www.kaggle.com\/ayuraj\/train-covid-19-detection-using-yolov5#%E2%98%80%EF%B8%8F-Imports-and-Setup). If you want to improve your accuracy, consider using 5x instead of 5s. But please notice that it would take more time in training and prediction.\n\n![img](https:\/\/user-images.githubusercontent.com\/26833433\/114313216-f0a5e100-9af5-11eb-8445-c682b60da2e3.png)","a1f0572f":"## \u2328\ufe0f Unzip YOLOv5","1219340c":"## \ud83c\udfa8 Predict"}}