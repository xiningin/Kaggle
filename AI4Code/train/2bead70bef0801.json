{"cell_type":{"c6b4d34d":"code","e8b606ca":"code","0762339a":"code","2cdc0e00":"code","3c1bd070":"code","b72d8b83":"code","cff4e48e":"code","03273ccf":"code","eca7f97d":"code","c875a6df":"code","be36b4be":"code","09e7f1fa":"code","0e8e26fb":"code","20ff9b73":"code","d35e9b54":"code","32e3713c":"code","fdda5b08":"code","3226d8eb":"code","78bd15b3":"code","1555ab0f":"code","7a6ca9a5":"code","7bca041c":"code","2fa6bdf0":"code","cf81c671":"code","d66428c1":"code","a77c693d":"code","59ae9f69":"code","323a67fa":"code","68137407":"code","353889de":"code","14e2c9d1":"markdown","20a38e2b":"markdown","9e4eed83":"markdown","107526cd":"markdown","135061f7":"markdown","e988dd01":"markdown","39186ddd":"markdown"},"source":{"c6b4d34d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom scipy.stats import norm, boxcox\nfrom scipy import stats\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8b606ca":"dataset=pd.read_csv(\"\/kaggle\/input\/insurance\/insurance.csv\",header=0)\ndataset.describe()","0762339a":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","2cdc0e00":"#checking do age and charges have any linear relation\nimport matplotlib.pyplot as plt\nplt.scatter(X[:,0:1], y, color = 'red')\nplt.xlabel('age')\nplt.ylabel('Charges')\nplt.show()","3c1bd070":"dataset[[\"sex\",\"charges\"]].groupby([\"sex\"], as_index = False).mean().sort_values(by = \"charges\",ascending = False).style.background_gradient(\"Greens\")","b72d8b83":"dataset[[\"children\",\"charges\"]].groupby([\"children\"], as_index = False).mean().sort_values(by = \"charges\",ascending = False).style.background_gradient(\"Greens\")","cff4e48e":"dataset[[\"smoker\",\"charges\"]].groupby([\"smoker\"], as_index = False).mean().sort_values(by = \"charges\",ascending = False).style.background_gradient(\"Greens\")","03273ccf":"dataset[[\"region\",\"charges\"]].groupby([\"region\"], as_index = False).mean().sort_values(by = \"charges\",ascending = False).style.background_gradient(\"Greens\")","eca7f97d":"region = dataset.groupby(\"region\", as_index=False)[\"age\",\"bmi\",\"children\",\"charges\"].mean().sort_values(\"age\",ascending=False).style.background_gradient(\"Blues\")\nprint(\"Average value of other properties by region \\n\")\nregion","c875a6df":"sns.distplot(dataset[\"age\"], fit=norm)\nplt.title(\"Age Distplot\", color = \"darkred\")","be36b4be":"sns.distplot(dataset[\"charges\"], fit=norm)\nplt.title(\"charges Distplot\", color = \"darkred\")","09e7f1fa":"#Any missing values\ndataset.isnull().sum()","0e8e26fb":"# Encoding categorical data\n# Encoding the Independent Variable\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n#print(X[0:4,:])\nct = ColumnTransformer(transformers=[('encodersex', OneHotEncoder(), [1]),\n                                     ('encoderchildren', OneHotEncoder(), [3]),\n                                     ('encodersmoker', OneHotEncoder(), [4]),\n                                     ('encoderregion', OneHotEncoder(), [5])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n#print(X[0:4,:])","20ff9b73":"#To handle skweness of charges:\ny = np.log1p(y)","d35e9b54":"#checking top 5 values\nprint(X[0:5])\nprint(y[0:5])","32e3713c":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)","fdda5b08":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","3226d8eb":"# Training the Multiple Linear Regression model on the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\ny_pred=regressor.predict(X_test)\nfrom sklearn import metrics\nscore_rf=metrics.r2_score(y_test, y_pred)\nprint(score_rf)","78bd15b3":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\nrf_param_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nrf = RandomForestRegressor()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = rf_param_grid, n_iter = 100, cv = 3, \n                               verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(X_train, y_train)\ny_pred = rf_random.predict(X_test)","1555ab0f":"print(rf_random.best_params_)\nscore_rf=metrics.r2_score(y_test, y_pred)","7a6ca9a5":"print(\"r_square score --> \",score_rf)\nprint('Mean Absolute Error -->', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error -->', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error -->', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","7bca041c":"from yellowbrick.regressor import PredictionError\nvisualizer = PredictionError(rf_random)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();","2fa6bdf0":"# Predicting the Test set results\n#np.set_printoptions(precision=2)\n#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","cf81c671":"# Training the SVR model on the Training set\nfrom sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)\n\n# Evaluating the Model Performance\nmetrics.r2_score(y_test, y_pred)","d66428c1":"from yellowbrick.regressor import PredictionError\nvisualizer = PredictionError(regressor)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();","a77c693d":"from sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors=5)\nneigh.fit(X_train, y_train)\ny_pred = neigh.predict(X_test)\n\n# Evaluating the Model Performance\nmetrics.r2_score(y_test, y_pred)","59ae9f69":"from yellowbrick.regressor import PredictionError\nvisualizer = PredictionError(neigh)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();","323a67fa":"from sklearn.ensemble import GradientBoostingRegressor\nreg = GradientBoostingRegressor(max_depth=3,random_state=20)\nreg.fit(X_train, y_train)\ny_pred=reg.predict(X_test)\nmetrics.r2_score(y_test, y_pred)","68137407":"from yellowbrick.regressor import PredictionError\nvisualizer = PredictionError(reg)\nvisualizer.fit(X_train, y_train)  \nvisualizer.score(X_test, y_test)        \nvisualizer.show();","353889de":"import xgboost as xgb\n\nmodel = xgb.XGBRegressor(importance_type='gain', learning_rate=0.1)\nmodel.fit(X_train, y_train,verbose=True)\n \nscore = model.score(X_train, y_train)   \nprint(\"Training score: \", score) \nscore = model.score(X_test, y_test)   \nprint(\"test score: \", score)\ny_pred=model.predict(X_test)\nscore = metrics.r2_score(y_test, y_pred)\nprint(\"r2_score : \", score)","14e2c9d1":"skewness can be seen here. so we need to normalize this.","20a38e2b":"***GradientBoostingRegressor***","9e4eed83":"***Multiple Linear Regression model***","107526cd":"***KNeighborsRegressor***","135061f7":"***SVM Regressor***","e988dd01":"***Random Forest Regression model***","39186ddd":"We see that men pay more than women."}}