{"cell_type":{"f61b3f05":"code","8533b7dc":"code","d7a95eca":"code","cc823897":"code","d116e1fa":"code","e412dfb1":"code","30e5c8b2":"code","dc9e2fb2":"code","3d7025f5":"code","3cb9aa96":"code","3a54eab9":"code","84a679e8":"code","9be04ce5":"code","bf33eca2":"code","a1981287":"code","9459ea71":"code","029b63f8":"code","04582fba":"code","14463d53":"code","d9c4821c":"code","d1e3dd17":"markdown","dc11cba1":"markdown","e51b9c6e":"markdown","691dc745":"markdown"},"source":{"f61b3f05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport string\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8533b7dc":"from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, ElasticNet\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nimport sklearn.model_selection\nimport math","d7a95eca":"train_df = pd.read_csv('..\/input\/hse-aml-2020\/books_train.csv')\ntest_df = pd.read_csv('..\/input\/hse-aml-2020\/books_test.csv')\nsample_df = pd.read_csv('..\/input\/hse-aml-2020\/books_sample_submission.csv')","cc823897":"train_df.head(1)","d116e1fa":"def preprocess(line):\n    line = line.strip().lower()\n    line = line.translate(str.maketrans('', '', string.punctuation))\n    return line","e412dfb1":"train_df['publisher'] = train_df['publisher'].apply(preprocess)\ntest_df['publisher'] = test_df['publisher'].apply(preprocess)\n\nvectorizer = HashingVectorizer(n_features=50000)\nX = vectorizer.fit_transform(train_df['publisher'])\ny = train_df['average_rating']\n\nX_test = vectorizer.transform(test_df['publisher'])\n\ntraining, valid, ytraining, yvalid = train_test_split(X, y, test_size = 0.5)\n\nmodel1 = GradientBoostingRegressor()\nmodel1.fit(training, ytraining)\npreds1 = model1.predict(valid)\ntest_preds1 = model1.predict(X_test)","30e5c8b2":"train_df['title'] = train_df['title'].apply(preprocess)\ntest_df['title'] = test_df['title'].apply(preprocess)\n\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(train_df['title'])\ny = train_df['average_rating']\n\nX_test = vectorizer.transform(test_df['title'])\n\ntraining, valid, ytraining, yvalid = train_test_split(X, y, test_size = 0.5)\n\nmodel3 = ElasticNet()\nmodel3.fit(training, ytraining)\npreds3 = model3.predict(valid)\ntest_preds3 = model3.predict(X_test)","dc9e2fb2":"train_df['publication_year'] = train_df['publication_date'].map(lambda x: x.split('\/')[2])\ntrain_df['publication_month'] = train_df['publication_date'].map(lambda x: x.split('\/')[1])\ntrain_df['publication_day'] = train_df['publication_date'].map(lambda x: x.split('\/')[0])\n\ntest_df['publication_year'] = test_df['publication_date'].map(lambda x: x.split('\/')[2])\ntest_df['publication_month'] = test_df['publication_date'].map(lambda x: x.split('\/')[1])\ntest_df['publication_day'] = test_df['publication_date'].map(lambda x: x.split('\/')[0])\n\ntrain_df['populatity'] = train_df['ratings_count'] \/ ( train_df['text_reviews_count'] + 0.1 )\ntest_df['populatity'] = test_df['ratings_count'] \/ ( test_df['text_reviews_count'] + 0.1 )\n\nX = train_df.drop(['average_rating', 'title','authors', 'isbn', 'isbn13', 'publication_date', 'language_code', 'publisher'], axis = 1)\nX_test = test_df.drop(['title','authors', 'isbn', 'isbn13', 'publication_date', 'language_code', 'publisher'], axis = 1)\n\nscaler = StandardScaler()\nscaler.fit(X)\n\nX = scaler.transform(X)\nX_test = scaler.transform(X_test)\ny = train_df['average_rating']\n\ntraining, valid, ytraining, yvalid = train_test_split(X, y, test_size = 0.5)\n\n\nmodel2 = CatBoostRegressor(iterations=2,\n                          learning_rate=1,\n                          depth=2)\nmodel2.fit(training, ytraining)\npreds2 = model2.predict(valid)\ntest_preds2 = model2.predict(X_test)","3d7025f5":"stacking_predictions = np.column_stack((preds1, preds2, preds3))\nstacked_test_predictions = np.column_stack((test_preds1, test_preds2, test_preds3))\n\nmeta_model = GradientBoostingRegressor()\nmeta_model.fit(stacking_predictions, yvalid)\n\nfinal_predictions = meta_model.predict(stacked_test_predictions)","3cb9aa96":"sample_df['average_rating'] = final_predictions","3a54eab9":"sample_df.to_csv('last1.csv', index=False)","84a679e8":"train_df.head()","9be04ce5":"train_df['populatity'] =  train_df['ratings_count'] \/ train_df['text_reviews_count']\ntest_df['populatity'] =  test_df['ratings_count'] \/ test_df['text_reviews_count']","bf33eca2":"# 155\nfor i in range (0, 1000):\n    train_df['hundreds'] = train_df['  num_pages'] \/\/ i\n    print(i, train_df['hundreds'].corr(train_df['  num_pages']), train_df['average_rating'].corr(train_df['hundreds']))","a1981287":"train_df['155pages'] = (train_df['  num_pages'] > 1000).apply(int)","9459ea71":"train_df.corr()","029b63f8":"train_df['average_rating'].corr(train_df['hundreds'])","04582fba":"n = 700\n\nprint(train_df[train_df['  num_pages'] > n].average_rating.mean())\nprint(train_df[train_df['  num_pages'] > n].average_rating.count())\n\nprint(train_df[train_df['  num_pages'] < n].average_rating.mean())\nprint(train_df[train_df['  num_pages'] < n].average_rating.count())","14463d53":"train_df.gtou","d9c4821c":"from catboost import CatBoostRegressor\n# Initialize data\n\n# Initialize CatBoostRegressor\nmodel = CatBoostRegressor(iterations=2,\n                          learning_rate=1,\n                          depth=2)\n# Fit model\nmodel.fit(train_data, train_labels)\n# Get predictions\npreds = model.predict(eval_data)","d1e3dd17":"# Authors Model","dc11cba1":"# STACKING","e51b9c6e":"# Base model","691dc745":"# Publisher Model"}}