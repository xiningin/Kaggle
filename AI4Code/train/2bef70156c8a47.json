{"cell_type":{"f8c10634":"code","b3e1fc71":"code","3a4e452f":"code","3c170927":"code","cbffcd5f":"code","e54a7905":"code","dc468c11":"code","8bc04843":"code","14ffc235":"code","12afe0ae":"code","4dd3bd2c":"code","69ea05f0":"code","479f7638":"code","8801418b":"markdown","8db299c5":"markdown","04db2b5a":"markdown","570e0193":"markdown","ee6899b6":"markdown","6ece7199":"markdown","dc5f4287":"markdown","5b881ad3":"markdown","61c03371":"markdown","83eafd2d":"markdown","9b4f855e":"markdown","6fa214cb":"markdown","36c588d6":"markdown","d4e7efd8":"markdown","42b90626":"markdown","958214e2":"markdown","bd7432b4":"markdown","6fb3a57c":"markdown","954fb64c":"markdown"},"source":{"f8c10634":"# Loading necessary libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","b3e1fc71":"# Load the relevant datasets\n\nmcr = pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\") # responses\nques = pd.read_csv(\"..\/input\/kaggle-survey-2019\/questions_only.csv\") # questions\ntxtr = pd.read_csv(\"..\/input\/kaggle-survey-2019\/other_text_responses.csv\") # text responses\nss = pd.read_csv(\"..\/input\/kaggle-survey-2019\/survey_schema.csv\")","3a4e452f":"# Inspect mcr using head()\n\nmcr.head()","3c170927":"# Function to print the contents of all cells in a given row of a dataframe in their entire length\n\ndef print_all(df, r_num):\n    \"\"\"\n    Task:\n    To print all the content of the cells in a given row without truncation\n    \n    Input :\n    df <- Dataframe\n    r_num <- Row number (starts at 0)\n    \n    Output :\n    Prints out all values for the input row across all attributes with corresponding headers\n    \"\"\"\n    row = df.iloc[r_num]\n    pd.set_option('display.max_rows', len(row))\n    pd.set_option('display.max_colwidth', -1)\n    print(row)\n    pd.reset_option('display.max_rows')","cbffcd5f":"# Inspecting Multiple Choice Responses (We need Questions, so that's why we are passing 0 as the row number)\nprint_all(mcr,0)","e54a7905":"# Function to remove columns from a dataset based on an expression in the column name\n\ndef col_rem_by_exp(df, exp):\n    \"\"\"\n    Task:\n    To remove columns from a dataset based on an expression in the column name\n    \n    Input :\n    df <- Dataframe\n    exp <- The string expression that is common to all columns that need to be removed\n    \n    Output :\n    Returns a dataframe with the removed columns\n    \"\"\"\n    removable_cols = []\n    for i in df.columns:\n        if (exp in i):\n            removable_cols.append(i)\n    return (df.drop(removable_cols, axis=1))","dc468c11":"# Removing \"OTHER_TEXT\" columns\n\nmcr = col_rem_by_exp(mcr, \"_OTHER_TEXT\")\nprint_all(mcr,0)","8bc04843":"# Function to segregate all the questions that have the \"Select all that apply\" option\ndef select_features(df, exp):\n    \"\"\"\n    Task:\n    To group columns from a dataset based on an expression in the column name\n    \n    Input :\n    df <- Dataframe\n    exp <- The string expression that is common to all columns that need to be aggregated\n    \n    Output :\n    Returns the list of all features with the common expression\n    \"\"\"\n    feature_list = []\n    for i in mcr.columns:\n        if (\"_Part_\" in i):\n            q = i\n            pos_ = q.index('_')\n            q_no = int(q[:pos_][1:])\n            if(q_no not in feature_list):\n                feature_list.append(q_no)\n    return feature_list\n","14ffc235":"select_all_ques = select_features(mcr, \"_Part_\")\nprint('\"Select all that apply\" questions :')\nprint(select_all_ques)","12afe0ae":"def response_combine(df, q_num):\n    \"\"\"\n    Task:\n    To combine responses of \"Select all that apply\" questions\n    \n    Input :\n    df <- Multiple choice response survey\n    q_num <- Question number whose responses need to be combined\n    \n    Output :\n    > List of lists...each list corresponds to a row and all the options selected by that respondent are grouped together in it\n    > Leave out the first list (it just groups the headers) once you get the output\n    \"\"\"\n    # Identify the PARTS of the given question number\n    resp_cols = []\n    for i in df.columns:\n        if (('Q'+str(q_num)) in i):\n            resp_cols.append(i)\n            \n    # Aggregate all the responses of a given respondent\n    responses = []\n    for i in range(df.shape[0]):\n        l = list(df[resp_cols].iloc[i])\n        cleaned_responses = [choice for choice in l if str(choice) != 'nan']\n        responses.append(cleaned_responses)\n    \n    # Create a dataframe of these aggregated responses, merge them with the original dataframe and delete the PARTS\n    header = (\"Q\"+str(q_num))\n    temp_df = pd.DataFrame(dict({header:responses}))\n    df = df.drop(resp_cols, axis=1)\n    final_df = pd.concat([df, temp_df], axis=1, sort=False)\n    \n    return (final_df)","4dd3bd2c":"# Cleaning the complete dataframe\nclean_mcr = response_combine(mcr,select_all_ques[0])\nfor q in select_all_ques[1:]:\n    clean_mcr = response_combine(clean_mcr,q)\n    \nprint(\"The shape of the cleaned dataframe is :\",clean_mcr.shape)","69ea05f0":"\"\"\"Fixing the Column Headers\"\"\"\n\n# list of all questions whose positions have changed after response_combine()\npos_changed_ques = [(\"Q\"+str(x)) for x in select_all_ques]\n\n# dropping the position-changed-questions from the main dataframe\nquestions = list(ques.loc[0,pos_changed_ques])\nnew_ques = ques.drop(pos_changed_ques, axis=1)\n\n# using the concept of dataframes concatenation to create \"new_ques\" from \"ques\"\n## new_ques is a modified version of ques that orders questions like how they have been modified in clean_mcr\ntemp_dict = {}\nfor i in range(len(pos_changed_ques)):\n    temp_dict[pos_changed_ques[i]] = questions[i]\ntemp_ques = pd.DataFrame(temp_dict, index=[0])\nnew_ques = pd.concat([new_ques,temp_ques], axis=1)\n\n# new_ques\nnew_ques","479f7638":"\"\"\" Final Clean Up \"\"\"\n\n# Rename columns\nclean_mcr.columns = list(new_ques.iloc[0,:])\n\n# Drop the first row\nclean_mcr = clean_mcr.drop([0])\n\n# Drop the first column (it's not needed)\n# clean_mcr = clean_mcr.drop(clean_mcr.columns[[0]], axis=1)\n\n# Save clean_mcr as an output dataset\nclean_mcr.to_csv(\"clean_multiple_choice_responses.csv\")\n","8801418b":"### RESULT\n**clean_mcr** is our final, cleaned survey dataframe.<br>\nYou can download it from the \"Output\" feature.","8db299c5":"## Key Considerations while dealing with \"Messy Data\"\n\n### The \"Aim\" of your Analysis\n- The kind of data cleaning performed and the extent of data cleaning performed is dependent on the kind of analysis you want to perform\n- Data Cleaning is always going to be **\"specific\"** to the questions you want to answer\n\n### Understanding \"Important\" Data\n- While data cleaning involves removing messy values and modifying them, it is important to identify which of these values are \"un-important\" and can be removed\n- Just because a particular feature has about 30% missing values, it is not possible to make a mechanical call as to whether the feature must be kept or removed; we will need to identify the importance of that feature to the data we have\n- Many a time, we can convert **messy-looking** values to better formats by writing a bit of code. Eg : \"500 Dollars\" might seem like a bad value if we want to perform a calculation with it. So, it's better to convert it to \"500\" for correct computation. (Make sure it's integer)\n\n### Identifying the \"Causes\" of Messy Data\n- Identifying the cause will help shape a better solution to data cleaning\n- At times, human error or bias can be a cause of bad data and other times, faulty apparatus can engender poor data entry\n- If we know the cause, we can definitely figure out the cure!","04db2b5a":"### The \"*response_combine*\" function\n\n- **Motivation :** The \"Select all that apply\" type questions allows for each respondent to choose more than one option for a given question. In the survey data, each of these options are encoded as separate features. (*That explains the huge 240+ features in the dataframe*)\n- **Aim :** To combine responses of \"Select all that apply\" questions\n- **Modules needed :** pandas\n- **Application :** Here, we use it to combine all the options chosen by a respondent for a given question into a single feature\n\n> **CAVEAT :** This function when applied to the dataframe takes a long time to run (over 10 minutes). That's a drawback of this function and I will try to see if I can improve it in the future.","570e0193":"There were only 34 questions in the survey in total. But, the responses dataframe (mcr) has a whopping 246 columns. Why did this happen?\n<br>\n> It's because several questions have their answers split over multiple columns. Example : \"Select all that apply\" and \"Other Text\" questions. We can notice two important patterns from mcr.head():\n* **Select all that apply** questions are in columns encoded as Qi_Part_k (i = question number, k = choice number)\n* **Other Text** responses are under the columns titled Qi_OTHER_TEXT (i = question number)","ee6899b6":"### The \"*select_features*\" function\n\n- **Motivation :** Certain columns in a dataset might share a common \"string expression\" in their titles. So, we can group them all together based on this expression.\n- **Aim :** To make a list of all the columns in a dataframe based on a shared expression\n- **Modules needed :** pandas\n- **Application :** Here, we use it to make a list of all columns with \"_Part_\" in their column titles (Because that's the pattern of questions with a \"Select all that apply\" option","6ece7199":"Withour further ado, I shall step right into the data cleaning process!","dc5f4287":"### The \"*print_all*\" function\n\n- **Motivation :** Since each question in the survey is very long, printing them would cause the truncation of these long values and the truncated portion would be replaced with **...**. This is will not help us observe all the values clearly.\n- **Aim :** To print out the contents of all cells in a given row without truncation\n- **Modules needed :** pandas\n- **Application :** Here, we use it to print all the questions (in row 0 of mcr) in their full length","5b881ad3":"## The Aim of this Notebook\n\n- Outline a \"Step-by-Step\" procedure to **Data Cleaning** on the [2019 Kaggle ML and DS Survey](https:\/\/www.kaggle.com\/c\/kaggle-survey-2019) data\n- Generate a **clean version** of \"multiple_choice_responses.csv\" (Can be found in the **Output** section)\n- This clean version has only 35 columns (34 question-responses and 1 for the timestamp; contrary to the 246 columns in the original *multiple_choice_responses.csv* (There is **no loss** of important data during this conversion)\n- Provide **re-usable code samples** so that anybody could use similar functions for their own projects (or maybe just improve my functions and help me learn in the process)","61c03371":"**NOTE:**\n- I shall be using the terms \"column\" and \"feature\" interchangeably in the course of this notebook","83eafd2d":"### Which are the \"Select all that apply\" questions ?\n\nHere, we shall segregate all the questions that have a \"Select all that apply\" option and store them for later","9b4f855e":"**NOTE :** Text Responses have been encoded to maintain anonymity of respondents (as on the survey data description). So, removing the OTHER_TEXT columns from mcr makes better sense.","6fa214cb":"## Data Cleaning Begins here!","36c588d6":"The new dataset only has 35 columns (1 for the time taken and 34 for questions). This is much cleaner and compact.","d4e7efd8":"### FUTURE WORK\n- Use this cleaned dataset for my project\n- Try and automate the data cleaning process above and apply it to the previous year's Kaggle DS and ML surveys\n\n### CONCLUSION\n\nAnd that's it! My data cleaning for the task I needed is done (as of now). Hopefully, I was able to perform my task correctly, but if there is anything that I have not done well enough, I would love to know about it so that I can improve this notebook :)","42b90626":"All columns with \"OTHER_TEXT\" responses have been removed now, as seen from the output generated.","958214e2":"### It's not over! Yet...\nOkay, so with the **clean_mcr** generated, it looks as though we have cleaned our data well. But, there is an issue that we have introduced in the course of our analysis.\n\n- The response_combine() function removes the questions with \"Select all that apply\" from their original positions in the dataframe, combines all the responses for a given question and appends these new clean features at the end of the new dataframe.\n- This means that we need to make sure that the \"Questions\" that we provide to each of these new features are also ordered correctly. Else, there will be a mixup of column headers and values. And, **THAT IS GOING TO BE BAD!**\n\nTo avoid such a problem, I have written a few lines of code in the cell beneath that takes care of this issue.","bd7432b4":"## What is Data Cleaning?\n- According to **Wikipedia**, *\"Data cleansing or data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.\"*\n- Basically put, **\"Data Cleaning can be thought of as a fundamental step in data science that helps convert available data into a form more suitable for the analysis task at hand.\"**\n\nTaking that *easier-to-comprehend* definition to heart, I have tried cleaning up the [2019 Kaggle ML and DS Survey](https:\/\/www.kaggle.com\/c\/kaggle-survey-2019) data for a pet-project I am trying to work on. ","6fb3a57c":"# Cleaning Up the Kaggle DS and ML Survey 2019\n##### A step-by-step approach to dealing with messy data and structuring it to your needs","954fb64c":"### The \"*col_rem_by_exp*\" function\n\n- **Motivation :** Certain columns in a dataset are of a similar type and this type might not be be useful for analysis. And often, columns of the similar type share a common \"string expression\" in their titles. So, we can remove them all together based on this expression.\n- **Aim :** To remove all the columns in a dataframe based on a shared expression\n- **Modules needed :** pandas\n- **Application :** Here, we use it to remove all the \"OTHER_TEXT\" columns from mcr"}}