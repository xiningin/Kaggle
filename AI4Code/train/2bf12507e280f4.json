{"cell_type":{"edf2fef0":"code","668d8316":"code","691e3020":"code","2fc2d2c2":"code","ecab2086":"code","b8bedd13":"code","02720d4d":"code","f1a8a0ea":"code","adffcfb1":"code","739ed863":"code","5e78a933":"code","7490c925":"code","e59ed136":"code","8ad999cb":"code","6fc23278":"code","e7aa8c49":"code","3107671c":"code","1b0cd874":"code","389e5c4f":"code","2fcefc07":"code","ed02a650":"code","aa0b383f":"code","6981e4ec":"code","d6514f5d":"code","c60bebd7":"markdown","daefd347":"markdown","b47a5c9c":"markdown","c8cdbee3":"markdown","27497c13":"markdown","cfc0e12d":"markdown","d42f939f":"markdown","a465bc3b":"markdown","21327571":"markdown","7652f2ad":"markdown"},"source":{"edf2fef0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport datetime, os\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","668d8316":"#loading dataframes\ntrain_df = pd.read_csv('\/kaggle\/input\/rsna-bone-age\/boneage-training-dataset.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/rsna-bone-age\/boneage-test-dataset.csv')\n\n#appending file extension to id column for both training and testing dataframes\ntrain_df['id'] = train_df['id'].apply(lambda x: str(x)+'.png')\ntest_df['Case ID'] = test_df['Case ID'].apply(lambda x: str(x)+'.png') \n\ntrain_df.head()","691e3020":"#finding out the number of male and female children in the dataset\n#creating a new column called gender to keep the gender of the child as a string\ntrain_df['gender'] = train_df['male'].apply(lambda x: 'male' if x else 'female')\nprint(train_df['gender'].value_counts())\nsns.countplot(x = train_df['gender'])","2fc2d2c2":"#oldest child in the dataset\nprint('MAX age: ' + str(train_df['boneage'].max()) + ' months')\n\n#youngest child in the dataset\nprint('MIN age: ' + str(train_df['boneage'].min()) + ' months')\n\n#mean age is\nmean_bone_age = train_df['boneage'].mean()\nprint('mean: ' + str(mean_bone_age))\n\n#median bone age\nprint('median: ' +str(train_df['boneage'].median()))\n\n#standard deviation of boneage\nstd_bone_age = train_df['boneage'].std()\n\n#models perform better when features are normalised to have zero mean and unity standard deviation\n#using z score for the training\ntrain_df['bone_age_z'] = (train_df['boneage'] - mean_bone_age)\/(std_bone_age)\n\nprint(train_df.head())","ecab2086":"#plotting a histogram for bone ages\ntrain_df['boneage'].hist(color = 'green')\nplt.xlabel('Age in months')\nplt.ylabel('Number of children')\nplt.title('Number of children in each age group')","b8bedd13":"train_df['bone_age_z'].hist(color = 'violet')\nplt.xlabel('bone age z score')\nplt.ylabel('Number of children')\nplt.title('Relationship between number of children and bone age z score')","02720d4d":"#Relationship between age and gender with a categorical scatter plot (swarmplot)\nsns.swarmplot(x = train_df['gender'], y = train_df['boneage'])","f1a8a0ea":"#distribution of age within each gender \nmale = train_df[train_df['gender'] == 'male']\nfemale = train_df[train_df['gender'] == 'female']\nfig, ax = plt.subplots(2,1)\nax[0].hist(male['boneage'], color = 'blue')\nax[0].set_ylabel('Number of boys')\nax[1].hist(female['boneage'], color = 'red')\nax[1].set_xlabel('Age in months')\nax[1].set_ylabel('Number of girls')\nfig.set_size_inches((10,7))","adffcfb1":"#splitting train dataframe into traininng and validation dataframes\ntrain_df['boneage_category'] = pd.cut(train_df['boneage'], 10)\ndf_train, df_valid = train_test_split(train_df, test_size = 0.2, random_state = 0)","739ed863":"# df_train = df_train1.groupby(['boneage_category', 'male']).apply(lambda x: x.sample(500, replace = True)\n#                                                       ).reset_index(drop = True)\n# print('New Data Size:', df_train.shape[0], 'Old Size:', df_train1.shape[0])\n# train_df[['boneage', 'gender']].hist(figsize = (10, 5))","5e78a933":"import matplotlib.image as mpimg\nfor filename, boneage, gender in train_df[['id','boneage','gender']].sample(4).values:\n    img = mpimg.imread('\/kaggle\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset\/'+ filename)\n    plt.imshow(img)\n    plt.title('Image name:{}  Bone age: {} years  Gender: {}'.format(filename, boneage\/12, gender))\n    plt.axis('off')\n    plt.show()","7490c925":"#library required for image preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom  keras.applications.xception import preprocess_input \n\n#reducing down the size of the image \nimg_size = 299\ndata_augmenation = dict(rotation_range=0.2, zoom_range=0.1, horizontal_flip=True,\n                                width_shift_range=0.05,\n                                height_shift_range=0.05,\n                                shear_range=0.05, fill_mode='nearest')\ntrain_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input,  **data_augmenation)\nval_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input)\n\n#train data generator\ntrain_generator = train_data_generator.flow_from_dataframe(\n    dataframe = df_train,\n    directory = '\/kaggle\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset',\n    x_col= 'id',\n    y_col= 'bone_age_z',\n    batch_size = 32,\n    seed = 42,\n    shuffle = True,\n    class_mode= 'other',\n    flip_vertical = True,\n    color_mode = 'rgb',\n    target_size = (img_size, img_size))\n\n#validation data generator\nval_generator = val_data_generator.flow_from_dataframe(\n    dataframe = df_valid,\n    directory = '\/kaggle\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset',\n    x_col = 'id',\n    y_col = 'bone_age_z',\n    batch_size = 32,\n    seed = 42,\n    shuffle = True,\n    class_mode = 'other',\n    flip_vertical = True,\n    color_mode = 'rgb',\n    target_size = (img_size, img_size))\n\n#test data generator\ntest_data_generator = ImageDataGenerator(preprocessing_function = preprocess_input)\n\ntest_generator = test_data_generator.flow_from_directory(\n    directory = '\/kaggle\/input\/rsna-bone-age\/boneage-test-dataset',\n    shuffle = True,\n    class_mode = None,\n    color_mode = 'rgb',\n    target_size = (img_size,img_size))","e59ed136":"test_X, test_Y = next(val_data_generator.flow_from_dataframe( \n                            df_valid, \n                            directory = '\/kaggle\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset',\n                            x_col = 'id',\n                            y_col = 'bone_age_z', \n                            target_size = (img_size, img_size),\n                            batch_size = 2523,\n                            class_mode = 'other'\n                            )) ","8ad999cb":"def plot_it(history):\n    '''function to plot training and validation error'''\n    fig, ax = plt.subplots( figsize=(20,10))\n    ax.plot(history.history['mae_in_months'])\n    ax.plot(history.history['val_mae_in_months'])\n    plt.title('Model Error')\n    plt.ylabel('error')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='upper right')\n    ax.grid(color='black')\n    plt.show()","6fc23278":"from keras.metrics import mean_absolute_error\ndef mae_in_months(x_p, y_p):\n    '''function to return mae in months'''\n    return mean_absolute_error((std_bone_age*x_p + mean_bone_age), (std_bone_age*y_p + mean_bone_age)) ","e7aa8c49":"from tensorflow.keras.layers import GlobalMaxPooling2D, Dense,Flatten, Dropout\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras import Sequential\nimport tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\n# model_1 = ResNet50(input_shape = (img_size, img_size, 3),\n#                                            include_top = False,\n#                                            weights = 'imagenet')\n# model_1 = tf.keras.applications.xception.Xception(input_shape = (img_size, img_size, 3),\n#                                            include_top = False,\n#                                            weights = 'imagenet')\n# model_1 = tf.keras.applications.InceptionResNetV2(input_shape = (img_size, img_size, 3),\n#                                            include_top = False,\n#                                            weights = 'imagenet')\n##******************************\n# model_1 = tf.keras.applications.ResNet152V2(input_shape = (img_size, img_size, 3),\n#                                            include_top = False,\n#                                            weights = 'imagenet')\n# for i, layer in enumerate(model_1.layers[:]):\n#     if i < 70:\n#         layer.trainable = False\n#     else:\n#         layer.trainable = True\n#     print(i, layer)\n## ****************************************\nmodel_1 = tf.keras.applications.DenseNet201(input_shape = (img_size, img_size, 3),\n                                           include_top = False,\n                                           weights = 'imagenet')\nmodel_1.trainable = True\nmodel_2 = Sequential()\nmodel_2.add(model_1)\nmodel_2.add(GlobalMaxPooling2D())\nmodel_2.add(Flatten())\nmodel_2.add(Dense(64, activation = 'relu'))\n# model_2.add(Dropout(0.5))\nmodel_2.add(Dense(32, activation = 'relu'))\nmodel_2.add(Dense(1, activation = 'linear'))\n\nSgd = tf.keras.optimizers.SGD(\n    learning_rate=0.001, momentum=0.0, nesterov=False)\nNaDam = tf.keras.optimizers.Nadam(\n    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\nAdaMax = tf.keras.optimizers.Adamax(\n    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n#compile model\nmodel_2.compile(loss ='mse', optimizer= AdaMax, metrics = [mae_in_months] )\n# model_2.compile(loss ='mse', optimizer= 'adam', metrics = [mae_in_months] )\n\n#model summary\nmodel_2.summary()","3107671c":"# Load the TensorBoard notebook extension\n%load_ext tensorboard\nlogs_dir = '.\\logs'\n%tensorboard --logdir {logs_dir}","1b0cd874":"#early stopping\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience= 12,\n                              verbose=0, mode='auto')\n\n#model checkpoint\nmc = ModelCheckpoint('resnet50_best_imsize299_model.h5', monitor='val_loss', mode='min', save_best_only=True,save_weights_only = False)\n# mc = ModelCheckpoint('xception_best_imsize299_model2.h5', monitor='val_loss', mode='min', save_best_only=True,save_weights_only = False)\n\n#tensorboard callback\nlogdir = os.path.join(logs_dir,datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\ntensorboard_callback =  TensorBoard(logdir, histogram_freq = 1)\n\n#reduce lr on plateau\nred_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n\n# callbacks = [tensorboard_callback,early_stopping,mc, red_lr_plat]\ncallbacks = [early_stopping,mc, red_lr_plat]\n\n\n#fit model\nhistory = model_2.fit_generator(train_generator,\n                            steps_per_epoch = 315,\n                            validation_data = val_generator,\n                            validation_steps = 1,\n                            epochs = 60,\n                            callbacks= callbacks)\nhistory\n%tensorboard --logdir logs\nplot_it(history)\n","389e5c4f":"# for i, layer in enumerate(model_1.layers[:]):\n#     if i < 300:\n#         layer.trainable = False\n#     print(i, layer)\n# \t# Check the trainable status of the individual layers\n# for layer in model_1.layers:\n#     print(layer, layer.trainable)","2fcefc07":"# from tensorflow import keras\n# model_2 =  keras.models.load_model('resnet50_best_imsize299_model.h5')\nmodel_2.load_weights('resnet50_best_imsize299_model.h5')\npred = mean_bone_age + std_bone_age*(model_2.predict(test_X, batch_size = 32, verbose = True))\ntest_months = mean_bone_age + std_bone_age*(test_Y)\n\nord_ind = np.argsort(test_Y)\nord_ind = ord_ind[np.linspace(0, len(ord_ind)-1, 12).astype(int)] # take 8 evenly spaced ones\nfig, axs = plt.subplots(6, 2, figsize = (15, 30))\nfor (ind, ax) in zip(ord_ind, axs.flatten()):\n    ax.imshow(test_X[ind, :,:,0], cmap = 'bone')\n    ax.set_title('Age: %fY\\nPredicted Age: %fY' % (test_months[ind]\/12.0, \n                                                           pred[ind]\/12.0))\n    ax.axis('off')\nfig.savefig('trained_image_predictions.png', dpi = 300)\n\npred_reshape = np.reshape(pred,pred.shape[0])\nprint(\"mean of absolute difference for: \", test_months.shape[0], \" cases in test set: \", np.mean(abs(pred_reshape-test_months)))","ed02a650":"from sklearn.metrics import mean_absolute_error\nmean_absolute_error(pred_reshape, test_months)","aa0b383f":"fig, ax = plt.subplots(figsize = (7,7))\nax.plot(test_months, pred, 'r.', label = 'predictions')\nax.plot(test_months, test_months, 'b-', label = 'actual')\nax.legend(loc = 'upper right')\nax.set_xlabel('Actual Age (Months)')\nax.set_ylabel('Predicted Age (Months)')","6981e4ec":"test_generator.reset()\ny_pred = model_2.predict_generator(test_generator)\npredicted = y_pred.flatten()\npredicted_months = mean_bone_age + std_bone_age*(predicted)\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\": predicted_months})\nresults.to_csv(\"xception_best_imsize299-results.csv\",index=False)","d6514f5d":"test_df","c60bebd7":"**The plot deviates from the line at very old and very young ages probably because we have less examples for those cases in the dataset**","daefd347":"**Setting up Image Data Generators!**<br>\nWe use image data generators for both training, testing and preprocessing of images. Validation set is already broken off from training set. ","b47a5c9c":"## Normalize the data in train set","c8cdbee3":"**Some EDA and feature engineering follow**","27497c13":"This notebook is an attempt to predict bone age using Xception(pre trained model)<br>","cfc0e12d":"Looking into the dataset...","d42f939f":"Evaluating the best saved model on the validation data and visualising results!!","a465bc3b":" The function to plot training and validation error as a function of epochs","21327571":"**Some Setup**<br>\nThe cell below creates the pandas dataframes for training and testing.","7652f2ad":"Predicting on test data, we obtain:"}}