{"cell_type":{"59b6005b":"code","18aab379":"code","bbf805b1":"code","9f00e3b3":"code","cd4c8f9e":"code","eb477df8":"code","e7af65ae":"code","5c82a8a6":"code","058dcdd0":"code","54a71e69":"code","c6deee87":"code","82880aa8":"code","85d54dd5":"code","f39c8935":"code","6b0ee070":"code","684e5bb8":"markdown"},"source":{"59b6005b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","18aab379":"\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbf805b1":"#importing the data\ncomp_test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ncomp_train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","9f00e3b3":"comp_train_data.head(1)","cd4c8f9e":"comp_test_data.head(1)","eb477df8":"#finding the number of nan in each columns\ncomp_train_data.isna().sum()","e7af65ae":"#preproceesing the train data\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\ndrop_cols = ['Age','Cabin','Name','Ticket']\ndrop_train_data = comp_train_data.drop(drop_cols,axis=1)\ndrop_train_data = drop_train_data[True ^ drop_train_data['Embarked'].isna()]\n\nprocc_y_train = drop_train_data['Survived']\ndrop_X_train = drop_train_data.drop('Survived',axis=1)\n\ncate_col = ['Sex','Embarked']\n#implementing onehotencoder on the data\nEmbark_coder = OneHotEncoder(sparse=False)\n#since the output will be in the form of numpy array should convert it into the form of dataframe\ncate_X_train =pd.DataFrame(Embark_coder.fit_transform(drop_X_train[cate_col]))\ncate_X_train.index = drop_X_train.index\nnum_X_train = drop_X_train.drop(cate_col,axis=1)\nprocc_X_train = pd.concat([cate_X_train,num_X_train],axis=1)\n\n#preproccessing the test data\nmissing_values = SimpleImputer()\ndrop_X_test = comp_test_data.drop(drop_cols,axis=1)\ncate_X_test = pd.DataFrame(Embark_coder.transform(drop_X_test[cate_col]))\ncate_X_test.index = drop_X_test.index\nmiss_col = list(drop_X_test.columns[drop_X_test.isna().sum() != 0])\nnum_X_test = drop_X_test.drop(cate_col+miss_col,axis=1)\nmiss_X_test = pd.DataFrame(missing_values.fit_transform(drop_X_test[miss_col]),columns=miss_col)\nprocc_X_test = pd.concat([cate_X_test,num_X_test,miss_X_test],axis=1)\nprint(\"the categories used for one hot encoding are : \")\nprint(Embark_coder.categories_)","5c82a8a6":"miss_X_test = pd.DataFrame(missing_values.fit_transform(drop_X_test[miss_col]),columns=miss_col)\nmiss_X_test","058dcdd0":"#splitting the data for training and validation\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(procc_X_train, procc_y_train)","54a71e69":"set(X_train.columns)","c6deee87":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n#ignore cols\nignore_cols = ['PassengerId']\nreq_cols = set(X_train.columns)-set(ignore_cols)\n#creation of the model\nlogistic_model = LogisticRegression(random_state=3,max_iter=5e3)\n\n#training of the model\nlogistic_model.fit(X_train[req_cols],y_train)\n\n#prediciting the model\ny_pred = logistic_model.predict(X_val[req_cols])\nacc = accuracy_score(y_pred,y_val)\nprint(\"accuracy of the logistic regression model is {}\".format(acc))","82880aa8":"drop_X_train","85d54dd5":"print(\"The parameters for logistic regression model are\")\nprint(logistic_model.coef_)","f39c8935":"#predicitons for test data\ny_pred_test = logistic_model.predict(procc_X_test[req_cols])\noutput = pd.DataFrame({\"PassengerId\":procc_X_test[\"PassengerId\"],'Survived':y_pred_test})\noutput.to_csv('my_submission.csv',index=False)","6b0ee070":"len(y_pred_test)","684e5bb8":"Since lot of data about Cabin is nan I will remove that column and I will remove the two rows in which embarked is nan\n\nI am kind of confused about Age column so I will do two ways in which in one I will remove the age wont remove it another\n\nI am going with my inital assumption that PassengerId, Name, Ticket will not contribute towards the survival rate of the person\n\nAlso I would have to change Embarked into numerical data and \n\nI cannot delete PassengerId because it is requires for the identification of the person in the output"}}