{"cell_type":{"297838b0":"code","479bc7ac":"code","b4036422":"code","5beb705b":"code","633e6cc7":"code","b02c3025":"code","b6104190":"code","25ef0565":"code","3c744d00":"code","3d78a7de":"code","a752826b":"code","46cf2c1f":"code","ca1022c4":"code","fbc9f98a":"code","a00e15be":"code","bc9e7ab5":"code","28d9d536":"code","a18a6c14":"code","114fab38":"code","b79d7cbb":"code","816bd4b8":"code","7e1b5ae9":"code","7bb49719":"code","7ec94915":"code","47e1b899":"markdown","1acf8cfd":"markdown","27a4e776":"markdown","34542642":"markdown","8caaeb5c":"markdown","bb9de634":"markdown","5aca4be8":"markdown","4090302e":"markdown","730b1f16":"markdown","92125f9e":"markdown","a8a3f7a5":"markdown","d93a65de":"markdown","e87191d4":"markdown","43272adc":"markdown","5313a285":"markdown","7e037a2f":"markdown","9d9215a1":"markdown","6d2fc14f":"markdown","10bc251f":"markdown","1197aca6":"markdown","ba152233":"markdown","388abd8f":"markdown","430a3914":"markdown","c7774e48":"markdown"},"source":{"297838b0":"URL = r\"..\/input\/responses.csv\"\n\n# Import utilities\nfrom pandas import read_table\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import classifiers\nfrom sklearn.svm import LinearSVC, NuSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import GridSearchCV","479bc7ac":"# For Plotting\n# __________________________________________\n\ndef plot_avg_p_r_curves(precision, recall, average_precision):\n    plt.figure()\n    plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,\n             where='post')\n    plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2,\n                     color='b')\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    plt.title('Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n                .format(average_precision[\"micro\"]))\n\ndef plot_per_class_p_r_curves(precision, recall, average_precision, classes):\n    from itertools import cycle\n    # setup plot details\n    colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n\n    plt.figure(figsize=(7, 8))\n    lines = []\n    labels = []\n    l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n    lines.append(l)\n    labels.append('micro-average Precision-recall (area = {0:0.2f})'\n                  ''.format(average_precision[\"micro\"]))\n\n    for i, color in zip(range(len(classes)), colors):\n        l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n        lines.append(l)\n        labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                      ''.format(classes[i], average_precision[i]))\n\n    fig = plt.gcf()\n    fig.subplots_adjust(bottom=0.25)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Extension of Precision-Recall curve to multi-class')\n    plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n    plt.show()\n\ndef pca_visualization(X_train, y, n_classes, start_label=0):\n    from sklearn.decomposition import PCA\n    pca = PCA(n_components=2) #2-dimensional PCA\n    transformed = pd.DataFrame(pca.fit_transform(X_train))\n\n    colors = ['red','blue','lightgreen','brown','cyan']\n\n    # Modify indices accordingly if classes don't start from 0\n    for i in range(start_label, n_classes+start_label*1):\n        plt.scatter(transformed[y==i][0], transformed[y==i][1], label='Class {}'.format(i), c=colors[i-start_label])\n    #plt.scatter(transformed[y==2][0], transformed[y==2][1], label='Class 2', c='blue')\n    #plt.scatter(transformed[y==3][0], transformed[y==3][1], label='Class 3', c='lightgreen')\n    #plt.scatter(transformed[y==4][0], transformed[y==4][1], label='Class 4', c='brown')\n    #plt.scatter(transformed[y==5][0], transformed[y==5][1], label='Class 5', c='cyan')\n\n    plt.legend()\n    plt.show()\n\n# ________________________________________________\n# For Preprocessing\n# ________________________________________________\n\ndef transform_categorical_to_numerical(frame):\n    '''\n    Transforms categorical columns to numerical.\n    '''\n    cat_columns = frame.select_dtypes(['O']).columns\n    frame[cat_columns] = frame[cat_columns].apply(lambda x: x.astype('category'))   # change type\n    frame[cat_columns] = frame[cat_columns].apply(lambda x: x.cat.codes)    # change to numerical\n    return frame\n\ndef get_features_and_labels(frame, lbl_col, classes=None, binarize=False):\n    '''\n    Transforms and scales the input data and returns numpy arrays for\n    training and testing inputs and targets.\n    'classes' required if binarize=True.\n    '''\n    frame = transform_categorical_to_numerical(frame)\n\n    # Convert values to floats\n    arr = np.array(frame, dtype=np.float)\n\n    # Use the lbl_col as the target value\n    X, y = np.delete(arr, lbl_col, 1), arr[:, [lbl_col]]\n\n    # Transform labels to binomial dist. (PS: This is a bespoke step to say 'yes' or 1, if y score is >=3)\n    #y = np.array([0 if x<3 else 1 for x in y])\n    #y_ = []\n    #for e in y:\n    #    if e < 3:\n    #        y_.append(1)\n    #    elif e==3 or e != e:    # account for nan\n    #        y_.append(2)\n    #    else:\n    #        y_.append(3)\n\n    #y = np.array(y_)\n\n    # Use 80% of the data for training; test against the rest\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n    # Replace missing values in labels with 0.0. Use\n    # scikit-learn to calculate missing values (below)\n    #frame[frame.isnull()] = 0.0\n\n    # Impute missing values from the training data\n    from sklearn.preprocessing import Imputer\n    imputer = Imputer(strategy='mean')\n    imputer.fit(X_train)\n    X_train = imputer.transform(X_train)\n    X_test = imputer.transform(X_test)\n    imputer = Imputer(strategy='most_frequent')\n    imputer.fit(y_train)\n    y_train = imputer.transform(y_train)\n    y_test = imputer.transform(y_test)\n    \n    # Binarize labels for multiclass PR support\n    if binarize==True:\n        from sklearn.preprocessing import label_binarize\n        y_train = label_binarize(y_train, classes)\n        y_test = label_binarize(y_test, classes)\n    \n    # Normalize the attribute values to mean=0 and variance=1\n    #from sklearn.preprocessing import StandardScaler\n    #scaler = StandardScaler()\n    # To scale to a specified range, we can use MinMaxScaler\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    \n    # Fit the scaler based on the training data, then apply the same\n    # scaling to both training and test sets.\n    scaler.fit(X_train)\n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    # Return the training and test sets\n    return X_train, X_test, y_train, y_test\n\n# =====================================================================","b4036422":"frame = read_table(\n        URL,\n        # Specify the file encoding\n        # Latin-1 is common for data from US sources\n        encoding='latin-1',\n        #encoding='utf-8',  # UTF-8 is also common\n\n        # Specify the separator in the data\n        sep=',',            # comma separated values\n\n        # Ignore spaces after the separator\n        skipinitialspace=True,\n\n        # Generate row labels from each row number\n        index_col=None,\n\n        # Generate column headers row from each column number\n        header=0,          # use the first line as headers\n    )","5beb705b":"f = list(frame) # Extract headers\nprint(f)","633e6cc7":"D = np.array(frame)\nfor element in [e for e in D]:\n    [print(i,x) for (i,x) in enumerate(element) if x != x]","b02c3025":"# Transforms categorical columns to numerical.\ncat_columns = frame.select_dtypes(['O']).columns\nframe[cat_columns] = frame[cat_columns].apply(lambda x: x.astype('category'))   # change type\nframe[cat_columns] = frame[cat_columns].apply(lambda x: x.cat.codes)    # change to numerical\n\n# Convert values to floats\narr = np.array(frame, dtype=np.float)\n\nlbl_col = 139  # Our label is 'Spending on healthy eating' (1-5)\nprint(\"Our label is: \" + f[lbl_col])\nclasses = [1,2,3,4,5]  # For use with label binarizer\n\n# Use the lbl_col as the target value\nX, y = np.delete(arr, lbl_col, 1), arr[:, [lbl_col]]\n\n# Use 80% of the data for training; test against the rest\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Replace missing values in labels with 0.0. Use\n# scikit-learn to calculate missing values (below)\n#frame[frame.isnull()] = 0.0\n\ndef impute_and_normalize(X_train, X_test, y_train, y_test, impute_y=True):\n    # Impute missing values from the training data\n    from sklearn.preprocessing import Imputer\n    imputer = Imputer(strategy='mean')\n    imputer.fit(X_train)\n    X_train = imputer.transform(X_train)\n    X_test = imputer.transform(X_test)\n    \n    if impute_y == True:\n        imputer = Imputer(strategy='most_frequent')\n        imputer.fit(y_train)\n        y_train = imputer.transform(y_train)\n        y_test = imputer.transform(y_test)\n\n    # Perform data normalization\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler(feature_range=(0, 1))\n\n    # Fit the scaler based on the training data, then apply the same\n    # scaling to both training and test sets.\n    scaler.fit(X_train)\n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = impute_and_normalize(X_train, X_test, y_train, y_test)","b6104190":"pca_visualization(X_train, y_train, 5, 1)","25ef0565":"# Binarize labels for multiclass PR support\nfrom sklearn.preprocessing import label_binarize\ny_train = label_binarize(y_train, classes)\ny_test = label_binarize(y_test, classes)","3c744d00":"# Define an execution function with Precision-Recall helper\nfrom sklearn.metrics import precision_recall_curve, f1_score, accuracy_score\ndef execute(clf, clf_name, X_train, X_test, y_train, y_test, skip_pr):\n    clf.fit(X_train, y_train)\n    pred = clf.predict(X_test)\n    score = f1_score(y_test, pred, average='micro')\n    acc = accuracy_score(y_test, pred)\n\n    # For generating the P-R curve\n    try:\n        y_prob = clf.decision_function(X_test)\n    except AttributeError:\n        # Handle BernoilliNB\n        y_prob = clf.predict_proba(X_test)\n\n    # PS: OVR wrapper must be used for multiclass, with label binarizer.\n    precision, recall, avg = get_per_class_pr_re_and_avg(y_test, y_prob) if skip_pr==False else ({},{},{})\n\n    # Include the score in the title\n    print('\\n{} (F1 score={:.3f}, Accuracy={:.4f})'.format(clf_name, score, acc))\n    \n    if skip_pr==False:\n        print('Average precision score, micro-averaged over all classsses: {0:0.2f}'.format(avg[\"micro\"]))\n        \n    return precision, recall, avg\n\ndef get_per_class_pr_re_and_avg(Y_test, y_score):\n    from sklearn.metrics import precision_recall_curve\n    from sklearn.metrics import average_precision_score\n\n    # For each class\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n\n    for i in range(Y_test.shape[1]):\n        precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i], y_score[:, i])\n        average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n\n    # A \"micro-average\": quantifying score on all classes jointly\n    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(), y_score.ravel())\n    average_precision[\"micro\"] = average_precision_score(Y_test, y_score, average=\"micro\")\n    return precision, recall, average_precision","3d78a7de":"def runClassifiers(X_train, X_test, y_train, y_test, skip_pr=False):\n    '''\n     Skip_pr when not using OVR wrapper with multiclass label binarizer.\n     This is due to compatibility reasons with PR curve functions.\n    '''\n    # Evaluate multiple classifiers on the data\n    print(\"Evaluating classifiers\")\n    classifiers = []\n    classifiers.append([LinearSVC(C=1.0), \"LinearSVC\"])\n    classifiers.append([MultinomialNB(), \"MultiNB\"])\n    classifiers.append([KNeighborsClassifier(n_neighbors=10), \"kNN\"])\n    classifiers.append([AdaBoostClassifier(n_estimators=50, learning_rate=1.0, algorithm='SAMME.R'), \"AdaBoost\"])\n    classifiers.append([RandomForestClassifier(n_estimators=100), \"Random forest\"])\n    classifiers.append([SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovo'), \"Baseline ovo rbf SVM\"])\n\n    results = []\n\n    for clf in classifiers:\n        results.append(execute(OneVsRestClassifier(clf[0]), clf[1], X_train, X_test, y_train, y_test, skip_pr))\n    return results\n\nresults = runClassifiers(X_train, X_test, y_train, y_test)","a752826b":"plot_per_class_p_r_curves(results[3][0], results[3][1], results[3][2], classes)","46cf2c1f":"def get_k_best_features(X_train, X_test, y_train, top_k=20):\n    # Select top 20 features that explain the classes\n    from sklearn.feature_selection import SelectKBest, chi2\n\n    ch2 = SelectKBest(chi2, k=top_k)\n    X_train = ch2.fit_transform(X_train, y_train)\n    X_test = ch2.transform(X_test)\n\n    # Print selected feature names\n    top_features = [f[i] for i in ch2.get_support(indices=True)]\n    print(\"Top {} features = {}\".format(top_k, top_features))\n    return X_train, X_test\n\nX_train, X_test = get_k_best_features(X_train, X_test, y_train)","ca1022c4":"results = runClassifiers(X_train, X_test, y_train, y_test)","fbc9f98a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nX_train, X_test, y_train, y_test = impute_and_normalize(X_train, X_test, y_train, y_test)","a00e15be":"results = runClassifiers(X_train, X_test, y_train, y_test, True)","bc9e7ab5":"X_train, X_test = get_k_best_features(X_train, X_test, y_train)\nresults = runClassifiers(X_train, X_test, y_train, y_test, True)","28d9d536":"classifiers2 = []\n\nparam_grid = {'C': np.logspace(-2, 1, 10),\n                  'gamma': [0.0005, 0.001, 0.005, 0.01, 0.1, 1.0],     # Use for testing rbf, poly\n                 'degree': [1,2,3] }\nclf_rbf_ovo = GridSearchCV(SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovo'), param_grid, cv=5)\nclf_rbf_ovr = GridSearchCV(SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovr'), param_grid, cv=5)\nclf_linear_ovo = GridSearchCV(SVC(kernel='linear', class_weight='balanced', decision_function_shape='ovo'), param_grid, cv=5)\nclf_poly_ovo = GridSearchCV(SVC(kernel='poly', class_weight='balanced', decision_function_shape='ovo'), param_grid, cv=5)\nclassifiers2.append([clf_rbf_ovo, \"clf_rbf_ovo\"])\nclassifiers2.append([clf_rbf_ovr, \"clf_rbf_ovr\"])\nclassifiers2.append([clf_linear_ovo, \"clf_linear_ovo\"])\nclassifiers2.append([clf_poly_ovo, \"clf_poly_ovo\"])\n\nfor clf in classifiers2:\n    execute(clf[0], clf[1], X_train, X_test, y_train.ravel(), y_test.ravel(), True)\n    print(clf[0].best_estimator_)\n    print()","a18a6c14":"y_ = []\nfor e in y:\n    if e < 3:\n        y_.append(1)\n    elif e==3 or e != e:    # account for nan, append neutral.\n        y_.append(2)\n    else:\n        y_.append(3)\n\ny_ = np.array(y_)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_, test_size=0.2)\nX_train, X_test, y_train, y_test = impute_and_normalize(X_train, X_test, y_train, y_test, impute_y=False)\n\nX_train, X_test = get_k_best_features(X_train, X_test, y_train)\nresults = runClassifiers(X_train, X_test, y_train.ravel(), y_test.ravel(), True)","114fab38":"pca_visualization(X_train, y_train, 3, 1)","b79d7cbb":"# Performing GridSearchCV on RBF SVM on 3 classes\nparam_grid = {'C': np.logspace(-2, 1, 10),\n                  'gamma': [0.0005, 0.001, 0.005, 0.01, 0.1, 1.0],     # Use for testing rbf, poly\n                 'degree': [1,2,3] }\nclf_rbf_ovo = GridSearchCV(SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovo'), param_grid, cv=5)\nexecute(clf_rbf_ovo, \"RBF SVM OVO\", X_train, X_test, y_train.ravel(), y_test.ravel(), True)\nprint(clf_rbf_ovo.best_estimator_)","816bd4b8":"y_ = np.array([0 if x<=3 else 1 for x in y])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_, test_size=0.2)\nX_train, X_test, y_train, y_test = impute_and_normalize(X_train, X_test, y_train, y_test, impute_y=False)\n\nX_train, X_test = get_k_best_features(X_train, X_test, y_train)\nresults = runClassifiers(X_train, X_test, y_train.ravel(), y_test.ravel(), True)","7e1b5ae9":"pca_visualization(X_train, y_train, 2)","7bb49719":"# Performing GridSearchCV on RBF SVM on 2 classes\nparam_grid = {'C': np.logspace(-2, 1, 10),\n                  'gamma': [0.0005, 0.001, 0.005, 0.01, 0.1, 1.0],     # Use for testing rbf, poly\n                 'degree': [1,2,3] }\nclf_rbf_ovo = GridSearchCV(SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovo'), param_grid, cv=5)\nexecute(clf_rbf_ovo, \"RBF SVM OVO\", X_train, X_test, y_train.ravel(), y_test.ravel(), True)\nprint(clf_rbf_ovo.best_estimator_)\n\nclf_linear_ovo = GridSearchCV(SVC(kernel='linear', class_weight='balanced', decision_function_shape='ovo'), param_grid, cv=5)\nexecute(clf_linear_ovo, \"Linear SVM OVO\", X_train, X_test, y_train.ravel(), y_test.ravel(), True)\nprint(clf_linear_ovo.best_estimator_)","7ec94915":"def execute_regression(clf, clf_name, X_train, X_test, y_train, y_test):\n    clf.fit(X_train, y_train)\n    pred = clf.predict(X_test)\n    score = r2_score(y_test, pred)\n    acc = mean_squared_error(y_test, pred)\n\n    # Include the score in the title\n    print('\\n{} (R2 score={:.3f}, MSE={:.4f})'.format(clf_name, score, acc))\n    \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nregressors = []\nregressors.append([LinearRegression(), \"Linear Regression\"])\nregressors.append([SVR(), \"SVR\"])\n\nfor clf in regressors:\n    execute_regression(clf[0], clf[1], X_train, X_test, y_train.ravel(), y_test.ravel())","47e1b899":"Seems like we have quite a lot of missing values in our dataset.\n\nWe will impute these shortly. Let us first find categorical features and convert to numerical so it is easy to work with the ML algorithms. We will perform a bit of preprocessing to make the data ready to fetch to our baseline ML classifiers.","1acf8cfd":"2-PCA Visualization","27a4e776":"Highest Accuracy (RandomForest) = 56.4%\n\nLet's visualize 2-PCA","34542642":"Let's check the frame headers","8caaeb5c":"Including helper functions","bb9de634":"And now, let's just visualize the training data using 2-component PCA reduction.","5aca4be8":"### Getting the data\nLet us load the data using Pandas\n\nData was already downloaded locally from: https:\/\/www.kaggle.com\/miroslavsabo\/young-people-survey\/data","4090302e":"Seems no substantial improvement.\n\nLet's perform GridSearch and 5-fold cross validation on SVM, using OVO\/OVR strategy, with different kernels.","730b1f16":"Let us setup the baseline classifiers and execute. ","92125f9e":"### Reducing classes to Binomial Distribution\n\n        <= 3 is NO, else YES","a8a3f7a5":"Import required libraries and support files.","d93a65de":"Not much of an improvement unfortunately.\n\nLet's use non-binarized labels without k-best feature selection.","e87191d4":"Seems this data is going to be hard to classify.\n\nLet us binarize classes to deal with multi-class classification.","43272adc":"### GridSearchCV (5-Fold) on RBF SVM ovo","5313a285":"### Preprocessing\n- Transform categorical features to numerical\n- Extract label column\n- Perform 80-20, train-test split (random)\n- Impute missing feature values (mean strategy)\n- Impute missing labels (mode strategy)\n- Binarize labels for multiclass classification using OVR\n        Also necessary for multiclass Precision-Recall.\n- Feature scaling: Normalize features (mean=0 and variance=1)\n        This is important because some features may have varying scores\/answers, eg. Yes\/No, 1-2, 1-5, etc.\n","7e037a2f":"# Machine Learning \n## Spending on healthy food (Young People dataset - Kaggle)\n\nUnderstanding how likely a person is to \"pay more money for good, quality\nor healthy food\" (on a scale from 1 to 5) using the Young People Survey dataset.\n\nThis script performs the basic process for applying a machine learning\nalgorithm to a dataset using Python libraries.\n(Check ProgressReport.docx and Description.pdf for details.)\n\nThe four main steps are:\n   1. Download a dataset (using pandas)\n   2. Process the numeric data (using numpy)\n   3. Feature selection\n   4. Imputation\n   5. Train and evaluate learners (using scikit-learn)\n   6. Plot and compare results (using matplotlib)","9d9215a1":"#### Substantial improvement\nUsing non-binarized labels seems to improve the accuracy. Best close to 36%, using MultinomialNB, and RandomForest.\n\nLet us extract k-best features, and test again.","6d2fc14f":"With the basic preprocessing in place, let us test some baseline classifiers.\n\nBut first let's define some helpers.","10bc251f":"Let's reduce classes to 3 and test again.\n        \n        1=-ve, 2=neutral, 3=+ve","1197aca6":"There we have it. Best accuracy of merely 21.8% using AdaBoost (DTL).\n\nLet us visualize the PR curve for this.","ba152233":"Let's check if there is missing data","388abd8f":"## Regression\nAs the labels can be seen to continuous as well, let us perform some regressions. \n\nI will use LinearRegression and SVR for this task.\n\n### Evaluation\nEvaluation will be done using the R2 score (1.0 best) and MSE (0.0 best).\n","430a3914":"## Improving accuracy\n\n### Some strategies towards improving the accuracy.\n- Use SelectKBest to weed out best features, using chi-squared scoring function.\n- Change binarized labels back to numeric for comparison.\n- Perform K-Fold Cross Validation sampling.\n- Test kernelized SVM with GridSearch for automatic parameter tuning.\n- Reduce classes to Binomial and Trinomial for comparison.","c7774e48":"Well, intuitively, the feature selection looks reasonable. \n\nLet us run our baseline classifiers again and compare the improvements, if any."}}