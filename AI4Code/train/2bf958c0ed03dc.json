{"cell_type":{"2019d5f2":"code","c2e8a45b":"code","84f0cac7":"code","9ba2bdb1":"code","c5817592":"code","9769184b":"code","f2e4937b":"code","42236c7c":"code","5194d475":"code","d7816767":"code","8f3e03e3":"code","ea2b07b1":"code","8a27cd28":"code","bb5846bb":"code","00e89069":"code","dc30af1c":"code","caa04eea":"code","a22606bf":"code","2056a7b9":"code","a5c4e5e5":"code","fd7f4977":"code","0792e0c2":"code","e432f0c8":"code","674c18cb":"code","d2cd3c61":"code","1263aae2":"code","af58c4e4":"code","193a5d07":"code","84272993":"code","03604831":"code","455247f1":"code","4143e7d1":"code","5993d371":"code","a38a20b3":"code","88daed5f":"code","cae4ca96":"code","8c94d2db":"code","47eb2536":"code","ed843aff":"code","5907f684":"markdown","4b52b8da":"markdown","39d6941f":"markdown","fe9003dd":"markdown","9d4ffb56":"markdown","b3fab570":"markdown","4deb8b52":"markdown","e2cfcb1d":"markdown","11a78998":"markdown","371463c4":"markdown","40a06a99":"markdown","b988e39d":"markdown","afc5f7ed":"markdown","64e2ea9a":"markdown","ba008548":"markdown","d120d8c3":"markdown","b8f213c9":"markdown","78a92cc2":"markdown","0b457556":"markdown"},"source":{"2019d5f2":"pip install chart_studio","c2e8a45b":"import json\nimport math\nimport os\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport plotly.graph_objs as go\nfrom chart_studio.plotly import plot, iplot\nfrom keras import layers\nfrom keras.layers import BatchNormalization\nfrom keras.applications import InceptionV3,VGG16,ResNet50,DenseNet201,MobileNetV2,VGG19,DenseNet169\nfrom keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard,EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation,concatenate\nfrom tensorflow.keras.models import Sequential\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom keras import backend as K\nimport gc\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json\nimport itertools","84f0cac7":"def Dataset_loader(DIR, RESIZE, sigmaX=10):\n    IMG = []\n    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n        PATH = os.path.join(DIR,IMAGE_NAME)\n        _, ftype = os.path.splitext(PATH)\n        if ftype == \".jpg\":\n            img = read(PATH)\n           \n            img = cv2.resize(img, (RESIZE,RESIZE))\n            #img=cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n           \n            IMG.append(np.array(img))\n    return IMG\n\nbenign_train = np.array(Dataset_loader('..\/input\/oral-cancer\/dataset\/train\/Normal',96))\nmalign_train = np.array(Dataset_loader('..\/input\/oral-cancer\/dataset\/train\/OSCC',96))\nbenign_test = np.array(Dataset_loader('..\/input\/oral-cancer\/dataset\/test\/Normal',96))\nmalign_test = np.array(Dataset_loader('..\/input\/oral-cancer\/dataset\/test\/OSCC',96))\nbenign_val = np.array(Dataset_loader('..\/input\/oral-cancer\/dataset\/val\/Normal',96))\nmalign_val = np.array(Dataset_loader('..\/input\/oral-cancer\/dataset\/val\/OSCC',96))","9ba2bdb1":"benign_train=np.load('benign_train.npy')\nmalign_train=np.load('malign_train.npy')\n\nbenign_test=np.load('benign_test.npy')\nmalign_test=np.load('malign_test.npy')\n\nbenign_val=np.load('benign_val.npy')\nmalign_val=np.load('malign_val.npy')\n# benign_train2=np.load('benign_train2.npy')\n# malign_train2=np.load('malign_train2.npy')\n\n# benign_test2=np.load('benign_test2.npy')\n# malign_test2=np.load('malign_test2.npy')\n\n# benign_val2=np.load('benign_val2.npy')\n# malign_val2=np.load('malign_val2.npy')","c5817592":"np.save('benign_train.npy', benign_train) \nnp.save('malign_train.npy', malign_train) \n\nnp.save('benign_test.npy', benign_test) \nnp.save('malign_test.npy', malign_test) \n\nnp.save('benign_val.npy', benign_val) \nnp.save('malign_val.npy', malign_val) ","9769184b":"# Skin Cancer: Malignant vs. Benign\n# Create labels\nbenign_train_label = np.zeros(len(benign_train))\nmalign_train_label = np.ones(len(malign_train))\nbenign_test_label = np.zeros(len(benign_test))\nmalign_test_label = np.ones(len(malign_test))\n\nbenign_val_label = np.zeros(len(benign_val))\nmalign_val_label = np.ones(len(malign_val))\n\n# Merge data \nX_train = np.concatenate((benign_train, malign_train), axis = 0)\nY_train = np.concatenate((benign_train_label, malign_train_label), axis = 0)\nX_test = np.concatenate((benign_test, malign_test), axis = 0)\nY_test = np.concatenate((benign_test_label, malign_test_label), axis = 0)\n\nX_val = np.concatenate((benign_val, malign_val), axis = 0)\nY_val = np.concatenate((benign_val_label, malign_val_label), axis = 0)\n\n","f2e4937b":"# To categorical\nY_train = to_categorical(Y_train, num_classes= 2)\nY_test = to_categorical(Y_test, num_classes= 2)\nY_val = to_categorical(Y_val, num_classes= 2)","42236c7c":"x_train=X_train\nx_val=X_val\ny_train=Y_train\ny_val=Y_val","5194d475":"from plotly.offline import iplot\ny = dict()\ny[0] = []\ny[1] = []\nfor set_name in (y_train, y_val, Y_test):\n    y[0].append(np.sum(set_name == 0))\n    y[1].append(np.sum(set_name == 1))\n\ntrace0 = go.Bar(\n    x=['Train Set', 'Validation Set', 'Test Set'],\n    y=y[0],\n    name='No',\n    marker=dict(color='#33cc33'),\n    opacity=0.7\n)\ntrace1 = go.Bar(\n    x=['Train Set', 'Validation Set', 'Test Set'],\n    y=y[1],\n    name='Yes',\n    marker=dict(color='#ff3300'),\n    opacity=0.7\n)\ndata = [trace0, trace1]\nlayout = go.Layout(\n    title='Count of classes in each set',\n    xaxis={'title': 'Set'},\n    yaxis={'title': 'Count'}\n)\nfig = go.Figure(data, layout)\niplot(fig)","d7816767":"# With data augmentation to prevent overfitting \nx_train = x_train\/255.\nx_val = x_val\/255.\nX_test=X_test\/255.","8f3e03e3":"# x_train, x_val, y_train, y_val = train_test_split(\n#     X_train, Y_train, \n#     test_size=0.2, \n#     random_state=11\n\n\nw=60\nh=40\nfig=plt.figure(figsize=(15, 15))\ncolumns = 4\nrows = 3\n\nfor i in range(1, columns*rows +1):\n    ax = fig.add_subplot(rows, columns, i)\n    if np.argmax(Y_train[i]) == 0:\n        ax.title.set_text('Normal')\n    else:\n        ax.title.set_text('Malignant')\n    plt.imshow(x_train[i], interpolation='nearest')\nplt.show()","ea2b07b1":"\n\nBATCH_SIZE = 32\n\ntrain_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\nval_generator = train_datagen.flow(x_val, y_val, batch_size=BATCH_SIZE, shuffle= False)\ntest_generator = train_datagen.flow(X_test, Y_test, batch_size=BATCH_SIZE, shuffle= False)\n\n\n\n\n\n","8a27cd28":"\ndef build_model1(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    return model\n\n# VGG model without the last classifier layers (include_top = False)\nvgg19_model = VGG19(include_top = False,\n                    input_shape = (96,96,3),\n                    weights='imagenet')\n\n\nmodel = build_model1(vgg19_model ,lr = 1e-4)\nmodel.summary()\n","bb5846bb":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.00001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nvgg19H=history\nvgg19M=model\n# saving the model in tensorflow format\nvgg19M.save('.\/vgg19M',save_format='tf')\n\n\n# loading the saved model\n# vgg19M = tf.keras.models.load_model('.\/vgg19')\n\n#vgg16M = tf.keras.models.load_model('.\/vgg16')\n# saving history\nnp.save('vgg19H.npy',history.history)\n# loading the saved history\n# history=np.load('my_history.npy',allow_pickle='TRUE').item()\n","00e89069":"\ndef build_model1(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    return model\n\n# VGG model without the last classifier layers (include_top = False)\nvgg16_model = VGG16(include_top = False,\n                    input_shape = (96,96,3),\n                    weights='imagenet')\n\nmodel = build_model1(vgg16_model ,lr = 1e-4)\nmodel.summary()\n","dc30af1c":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.00001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nvgg16H=history\nvgg16M=model\n# saving the model in tensorflow format\nvgg16M.save('.\/vgg16',save_format='tf')\n\n\n# loading the saved model\nvgg16M = tf.keras.models.load_model('.\/vgg16')\n# saving history\nnp.save('vgg16H.npy',history.history)\n# loading the saved history\n# history=np.load('my_history.npy',allow_pickle='TRUE').item()","caa04eea":"\ndef build_model2(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    return model\n\n# VGG model without the last classifier layers (include_top = False)\nResNet50_model = ResNet50(include_top = False,\n                    input_shape = (96,96,3),\n                    weights='imagenet')\n\nmodel = build_model2(ResNet50_model ,lr = 1e-4)\nmodel.summary()\n","a22606bf":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nResNet50H=history\nResNet50M=model\nnp.save('ResNet50H.npy',history.history)\n# loading the saved history\n# history=np.load('ResNet50H.npy',allow_pickle='TRUE').item()\n# saving the model in tensorflow format\nmodel.save('.\/ResNet50',save_format='tf')\n\n\n# loading the saved model\nResNet50M = tf.keras.models.load_model('.\/ResNet50')","2056a7b9":"def build_model(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    return model\n\nInceptionV3_model = InceptionV3(\nweights='imagenet',\ninclude_top=False,\ninput_shape=(96,96,3))\n\nmodel = build_model(InceptionV3_model ,lr = 1e-4)\nmodel.summary()","a5c4e5e5":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.00001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nInceptionV3H=history\nInceptionV3M=model\nnp.save('InceptionV3H.npy',history.history)\n# loading the saved history\n# history=np.load('InceptionV3H.npy',allow_pickle='TRUE').item()\n# saving the model in tensorflow format\nmodel.save('.\/InceptionV3M',save_format='tf')\n\n\n# loading the saved model\n# InceptionV3M = tf.keras.models.load_model('.\/InceptionV3M')\n","fd7f4977":"def build_model22(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    return model\n\nDenseNet201_model = DenseNet201(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(96,96,3)\n)\n\nmodel = build_model22(DenseNet201_model ,lr = 1e-4)\nmodel.summary()","0792e0c2":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.00001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nDensNet201H=history\nDensNet201M=model\nnp.save('DensNet201H.npy',history.history)\n# loading the saved history\n# history=np.load('ResNet50H.npy',allow_pickle='TRUE').item()\n# saving the model in tensorflow format\nmodel.save('.\/DensNet201M',save_format='tf')\n\n\n# loading the saved model\n#ResNet50M = tf.keras.models.load_model('.\/ResNet50')\n\n\n","e432f0c8":"def build_model22(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    return model\n\nDenseNet169_model = DenseNet169(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(96,96,3)\n)\n\nmodel = build_model22(DenseNet169_model ,lr = 1e-4)\nmodel.summary()","674c18cb":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.00001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nDenseNet169H=history\nDenseNet169M=model\n# np.save('ResNet50H.npy',history.history)\n# loading the saved history\n# history=np.load('DenseNet169H.npy',allow_pickle='TRUE').item()\n# saving the model in tensorflow format\nmodel.save('.\/DenseNet169M',save_format='tf')\n\n\n# loading the saved model\nDenseNet169M = tf.keras.models.load_model('.\/DenseNet169M')\n","d2cd3c61":"\ndef build_model26(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    return model\n\nMobileNetV2_model = MobileNetV2(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(96,96,3)\n)\n\nmodel = build_model26(MobileNetV2_model ,lr = 1e-4)\nmodel.summary()","1263aae2":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.00001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nMobileNetV2H=history\nMobileNetV2M =model\nnp.save('MobileNetV2H.npy',history.history)\n# loading the saved history\n# history=np.load('MobileNetV2H.npy',allow_pickle='TRUE').item()\n# saving the model in tensorflow format\nmodel.save('.\/MobileNetV2M',save_format='tf')\n\n\n# loading the saved model\n# MobileNetV2M = tf.keras.models.load_model('.\/MobileNetV2M')\n","af58c4e4":"MobileNetV2M = tf.keras.models.load_model('.\/MobileNetV2M')\nDenseNet169M = tf.keras.models.load_model('.\/DenseNet169M')\nvgg16M = tf.keras.models.load_model('.\/vgg16')\nResNet50M = tf.keras.models.load_model('.\/ResNet50')\n\n# vgg16M.trainable = False\n# ResNet50M.trainable = False\n# DenseNet169M.trainable = False\n# MobileNetV2M.trainable = False\n\n\n   ","193a5d07":"concat = concatenate([vgg16M, ResNet50M,DenseNet169M,MobileNetV2M], axis=-1)\nconcat.trainable = False","84272993":"kernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(concat)\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (224, 224, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()","03604831":"es = EarlyStopping(monitor='val_acc',mode='max',patience=6)\nfilepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,verbose=1, mode='max', min_lr=0.00001)\ncallbacks_list = [es,checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_generator,steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n                    validation_data=(x_val, y_val),\n                    validation_steps=x_val.shape[0] \/ BATCH_SIZE,\n                    epochs=30, verbose=1,\n                   callbacks=callbacks_list)\nprint(\"early stop :\",es)\n\nMobileNetV2H=history\nMobileNetV2M=model\nnp.save('MobileNetV2H.npy',history.history)\n# loading the saved history\n# history=np.load('MobileNetV2H.npy',allow_pickle='TRUE').item()\n# saving the model in tensorflow format\nmodel.save('.\/MobileNetV2M',save_format='tf')\n\n\n# loading the saved model\nMobileNetV2M = tf.keras.models.load_model('.\/MobileNetV2M')\n","455247f1":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['accuracy', 'val_accuracy']].plot()","4143e7d1":"Y_pred = MobileNetV2M.predict_generator(test_generator, steps=np.ceil(X_test.shape[0]\/BATCH_SIZE))\nacc=accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))\nprint(\"test accuracy score:\",acc)\n","5993d371":"score = MobileNetV2M.evaluate(X_test, Y_test, verbose=0)\nprint(\"accuracy :\",score)","a38a20b3":"tta_steps = 3\npredictions = []\n\nfor i in tqdm(range(tta_steps)):\n    test_generator = train_datagen.flow(X_test, Y_test, batch_size=BATCH_SIZE, shuffle= False)\n    preds = MobileNetV2M.predict_generator(test_generator, steps=np.ceil(X_test.shape[0]\/BATCH_SIZE))\n    predictions.append(preds)\n\n    del test_generator\n    gc.collect()\nY_pred_tta = np.mean(predictions, axis=0)","88daed5f":"i=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(Y_test)):\n    if(np.argmax(Y_test[i])==np.argmax(Y_pred_tta[i])):\n        prop_class.append(i)\n    if(len(prop_class)==8):\n        break\n\ni=0\nfor i in range(len(Y_test)):\n    if(not np.argmax(Y_test[i])==np.argmax(Y_pred_tta[i])):\n        mis_class.append(i)\n    if(len(mis_class)==8):\n        break\n\n# # Display first 8 images of benign\nw=60\nh=40\nfig=plt.figure(figsize=(15, 10))\ncolumns = 4\nrows = 3\n\ndef Transfername(namecode):\n    if namecode==0:\n        return \"Benign\"\n    else:\n        return \"Malignant\"\n    \nfor i in range(len(prop_class)):\n    ax = fig.add_subplot(rows, columns, i+1)\n    ax.set_title(\"Predicted result:\"+ Transfername(np.argmax(Y_pred_tta[prop_class[i]]))\n                       +\"\\n\"+\"Actual result: \"+ Transfername(np.argmax(Y_test[prop_class[i]])))\n    plt.imshow(X_test[prop_class[i]], interpolation='nearest')\nplt.show()","cae4ca96":"\n\n from sklearn.metrics import classification_report\nclassification_report( np.argmax(Y_test, axis=1), np.argmax(Y_pred_tta, axis=1))\n\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar() \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=55)\n    plt.yticks(tick_marks, classes)\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\ncm = confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))\n\ncm_plot_label =['benign', 'malignant']\nplot_confusion_matrix(cm, cm_plot_label, title ='Confusion Metrix for oral Cancer')","8c94d2db":"from sklearn.metrics import roc_auc_score, auc\nfrom sklearn.metrics import roc_curve\nroc_log = roc_auc_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred_tta, axis=1))\nfalse_positive_rate, true_positive_rate, threshold = roc_curve(np.argmax(Y_test, axis=1), np.argmax(Y_pred_tta, axis=1))\narea_under_curve = auc(false_positive_rate, true_positive_rate)\n\nplt.plot([0, 1], [0, 1], 'r--')\nplt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()\n#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')\nplt.close()","47eb2536":"from sklearn.metrics import classification_report\nprint(classification_report( np.argmax(Y_test, axis=1), np.argmax(Y_pred_tta, axis=1)))","ed843aff":"\n\n# save model\n# serialize model to JSON\nmodel_json = model.to_json()\n\nwith open(\"efficientnetb0.json\", \"w\") as json_file:\n    json_file.write(model_json)\n    \n# serialize weights to HDF5\nmodel.save_weights(\"efficientnet.h5\")\nprint(\"Saved model to disk\")\n\n","5907f684":"# **Classification Report**","4b52b8da":"# **EfficientNetB7**","39d6941f":"# **ROC Curves**","fe9003dd":"confussion matrix without normalization","9d4ffb56":"# **Step 3: Categorical Labels**","b3fab570":"# **Step 1 : importing Essential Libraries**","4deb8b52":"# ** Step 2 : Loading pictures and making Dictionary of images and labels**","e2cfcb1d":"# **Step 4 : Normalization**","11a78998":"\n# **Step 5: Model Building**","371463c4":"# **Confusion Matrix**","40a06a99":"# **vgg19**","b988e39d":"# **Step 6: Cross-Validating Model**","afc5f7ed":"# **Densnet201**","64e2ea9a":"# **vgg16**","ba008548":"# **InceptionV3**","d120d8c3":"Prediction","b8f213c9":"# **Densnet169**","78a92cc2":"# **ResNet50**","0b457556":"# **MobileNetV2**"}}