{"cell_type":{"e138c363":"code","532bd68c":"code","b76e3025":"code","f4a82f21":"code","bb115d80":"code","ca7b0b29":"code","23c0d817":"code","16dafca4":"code","30bc37d7":"code","6422f70f":"code","ebb57a30":"markdown","6cc93d00":"markdown","52b850d8":"markdown","52d13af4":"markdown"},"source":{"e138c363":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nfrom joblib import Parallel, delayed\nimport xgboost as xgb\nimport copy\nfrom xgboost.sklearn import XGBRegressor\nimport os\nfrom sklearn.linear_model import LinearRegression\nimport warnings\nimport joblib\nfrom sklearn.model_selection import train_test_split, KFold\nimport lightgbm as lgb\nimport datatable as dt\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler\nwarnings.filterwarnings(action='ignore', category=UserWarning)","532bd68c":"def my_metrics(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true)))\ndef rmspe(y_true, y_pred):  # f(y_true: array, y_pred: array) -> name: string, eval_result: float, is_higher_better: bool\n    output = my_metrics(y_true, y_pred)\n    return 'rmspe', output, False\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef get_stock_stat(stock_id : int, dataType = 'train'):   \n    book_train_subset = pd.read_parquet(f'..\/input\/optiver-realized-volatility-prediction\/book_{dataType}.parquet\/stock_id={stock_id}\/')\n    book_train_subset.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    book_train_subset['bas'] = (book_train_subset[['ask_price1', 'ask_price2']].min(axis = 1)\n                                \/ book_train_subset[['bid_price1', 'bid_price2']].max(axis = 1)\n                                - 1)                               \n    book_train_subset['wap'] = (book_train_subset['bid_price1'] * book_train_subset['ask_size1'] +\n                            book_train_subset['ask_price1'] * book_train_subset['bid_size1']) \/ (\n                            book_train_subset['bid_size1']+ book_train_subset['ask_size1'])\n    book_train_subset['log_return'] = (book_train_subset.groupby(by = ['time_id'])['wap'].\n                                       apply(log_return).\n                                       reset_index(drop = True).\n                                       fillna(0)\n                                      )\n    stock_stat = pd.merge(\n        book_train_subset.groupby(by = ['time_id'])['log_return'].agg(realized_volatility).reset_index(),\n        book_train_subset.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    stock_stat['stock_id'] = stock_id\n    return stock_stat\ndef get_dataSet(stock_ids : list, dataType = 'train'):\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )\n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n    return stock_stat_df","b76e3025":"keep_stock_id = 1\n# keep_stock_id = 0\n","f4a82f21":"# train -------------------------\nif keep_stock_id:\n    td = dt.fread('..\/input\/mytrain\/X_131_features.csv')\n    X = td.to_pandas()\n    del td\nelse: \n    X = pd.read_csv(\"..\/input\/mytrain\/X.csv\")\ny = pd.read_csv(\"..\/input\/mytrain\/y.csv\")\n# to_test ----------------------------------------------------\ntest = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\ntest_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\ntest_dataSet = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\ntest_dataSet = test_dataSet\nfinal_pred1 = test_dataSet[['row_id']]\nto_test = test_dataSet.drop(['row_id'], axis = 1).fillna(0)\nif keep_stock_id:\n    train = pd.read_csv(\"..\/input\/optiver-realized-volatility-prediction\/train.csv\")\n    cols = [f'stock_id_{c}' for c in list(set(train.stock_id))]\n    to_test[cols] = pd.DataFrame(np.stack([(to_test.stock_id == c).astype('int') for c in list(set(train.stock_id))]).T, columns = cols)\nelse:\n    to_test = to_test.drop(\"stock_id\", axis = 1)\n    X = X.drop(\"stock_id\", axis = 1)","bb115d80":"config = {'input_path': \"..\/input\/optiver-realized-volatility-prediction\/trade_\",\n          'train_path': '..\/input\/optiver-realized-volatility-prediction\/train.csv',\n          'test_path' : '..\/input\/optiver-realized-volatility-prediction\/test.csv'}\ntest_df = pd.read_csv(config['test_path'])\ndef read_data(stock_id, data_type):\n    file = glob.glob(config['input_path']+f'{data_type}.parquet\/stock_id={stock_id}\/*')[0]\n    df = pd.read_parquet(file)\n    return df\ndef get_final_df(df, data_type):\n    final_df = pd.DataFrame()\n    unique_id = df['stock_id'].unique().tolist()\n    for stock_id in tqdm(unique_id):\n        temp_stock_df = read_data(stock_id=stock_id, data_type=data_type)\n        temp_stock_df['stock_id'] = stock_id\n        final_df = pd.concat([final_df, temp_stock_df])\n    final_df.reset_index(drop=True)\n    return final_df\ndef get_agg_info(df):\n    agg_df = df.groupby(['stock_id', 'time_id']).agg(mean_sec_in_bucket = ('seconds_in_bucket', 'mean'), \n                                                     mean_price = ('price', 'mean'),\n                                                     mean_size = ('size', 'mean'),\n                                                     mean_order = ('order_count', 'mean'),\n                                                     max_sec_in_bucket = ('seconds_in_bucket', 'max'), \n                                                     max_price = ('price', 'max'),\n                                                     max_size = ('size', 'max'),\n                                                     max_order = ('order_count', 'max'),\n                                                     min_sec_in_bucket = ('seconds_in_bucket', 'min'), \n                                                     min_price = ('price', 'min'),\n                                                     min_size = ('size', 'min'),\n                                                     min_order = ('order_count', 'min'),\n                                                     median_sec_in_bucket = ('seconds_in_bucket', 'median'), \n                                                     median_price = ('price', 'median'),\n                                                     median_size = ('size', 'median'),\n                                                     median_order = ('order_count', 'median')\n                                                    ).reset_index()\n    \n    return agg_df\ntest_final_df = get_final_df(df=test_df, data_type='test')\ntest_agg = get_agg_info(df=test_final_df)\ntest_final_df = pd.merge(test_df, test_agg, on=['stock_id', 'time_id'], how='left')\ntest_final_df.fillna(-999, inplace=True)\ntest_final_df = test_final_df.drop(\"row_id\", axis = 1)\nto_test = to_test.merge(test_final_df, on=['stock_id', 'time_id'], how='left')\nto_test.fillna(-999, inplace=True)\nto_test = to_test.drop(\"stock_id\", axis = 1)","ca7b0b29":"output = []\nif keep_stock_id:\n    for filepath in glob.iglob('..\/input\/629-rvp-131-features-model\/*.pkl'):\n        model = joblib.load(filepath)\n        y_pred = model.predict(to_test, num_iteration = model.best_iteration_)\n        output.append(y_pred)\n        del model\n        del y_pred\nelse:\n    for filepath in glob.iglob('..\/input\/629rvpstock-id-as-continous\/*.pkl'):\n        model = joblib.load(filepath)\n        y_pred = model.predict(to_test, num_iteration = model.best_iteration_)\n        output.append(y_pred)\n        del model\n        del y_pred\ny_pred = sum(output) \/ len(output)","23c0d817":"final_pred1 = final_pred1.assign(target = y_pred)\nfinal_pred1","16dafca4":"def realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    a = (df_book_data['bid_price1'] * df_book_data['ask_size1'] +\n                                df_book_data['ask_price1'] * df_book_data['bid_size1']) \/ (\n                                       df_book_data['bid_size1']+ df_book_data['ask_size1'])\n\n    b = (df_book_data['bid_price2'] * df_book_data['ask_size2'] +\n                                df_book_data['ask_price2'] * df_book_data['bid_size2']) \/ (\n                                       df_book_data['bid_size2']+ df_book_data['ask_size2'])\n    df_book_data['wap'] = (a+b)\/2\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]\ndef past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized","30bc37d7":"list_order_book_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\nfinal_pred2 = past_realized_volatility_per_stock(list_file=list_order_book_file_test,\n                                                           prediction_column_name='target')\nfinal_pred2","6422f70f":"output = final_pred1.merge(final_pred2, on = \"row_id\", how = \"outer\").fillna(0)\n# x: my pred, y: naive\nmy_pred_weight = 0.5\noutput[\"target\"] = output.target_x * my_pred_weight + output.target_y * (1 - my_pred_weight)\noutput = output[[\"row_id\", \"target\"]]\noutput.to_csv('submission.csv',index = False)\nprint(output)","ebb57a30":"# Best Naive baseline 0.29082\n# Reference: https:\/\/www.kaggle.com\/pratibha9\/a-quick-model","6cc93d00":"# References: \n* https:\/\/www.kaggle.com\/mayunnan\/realized-volatility-prediction-code-template by Ma Yunnan\n* https:\/\/www.kaggle.com\/thanish\/randomforest-starter-submission by Thanish Batcha","52b850d8":"# Train: https:\/\/www.kaggle.com\/yus002\/realized-volatility-prediction-lgbm-train","52d13af4":"# Load in models"}}