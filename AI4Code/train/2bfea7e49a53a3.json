{"cell_type":{"5af524fb":"code","4d038322":"code","ba948d30":"code","44f6e5dc":"code","20a15a70":"code","e5c3f1ba":"code","1f617a6d":"code","7f1d9918":"code","314241f2":"code","6e4ffc76":"markdown","247f52fe":"markdown","c02c8825":"markdown","ca7f7c65":"markdown"},"source":{"5af524fb":"!pip install timm\nfrom timm import create_model\n! pip install fastai --upgrade #restart kernel\nfrom fastai.vision.all import *\ndataset_path = Path('..\/input\/petfinder-pawpularity-score')","4d038322":"#creating train df for using st\n\nset_seed(999, reproducible=True)\nBATCH_SIZE = 8                       \n\ntrain_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n\ntrain_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['norm_score']\n\nseed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n# num_bins\n\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\ntrain_df['fold'] = -1\nN_FOLDS = 10        #was10\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\ntrain_df.fold.value_counts().plot.bar()\n\ndef petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ndef get_data(fold):\n    train_df_f = train_df.copy()  # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    dls = ImageDataLoaders.from_df(\n                    train_df_f, #pass in train DataFrame\n                   valid_col='is_valid', #\n                   seed=999, #seed\n                   fn_col='path', #filename\/path is in the second column of the DataFrame\n                   label_col='norm_score', #label is in the first column of the DataFrame\n                   y_block=RegressionBlock, #The type of target\n                   bs=BATCH_SIZE, #pass in batch size\n                   num_workers=8,\n                   item_tfms=Resize(384), #pass in item_tfms\n                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()]) #pass in batch_tfms\n                            ) \n    \n    return dls\n\ndef get_learner(fold_num):\n    data = get_data(fold_num)\n    model = create_model('swin_large_patch4_window12_384', pretrained=True, num_classes=data.c)\n    rmse = AccumMetric(petfinder_rmse)\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=[rmse]).to_fp16()\n    return learn","ba948d30":"import gc\nfor i in range(1): #1 for demonstration substitute N_FOLDS for all oof files\n\n    print(f'Fold {i} results')\n    learn = get_learner(fold_num=i)\n    if i<5: learn.path=Path('..\/input\/sturges-bins-10fold-p1')   # download models 0-4 to {dir_name}\/models\n    else: learn.path=Path('..\/input\/sturges-bins-10fold-p2')     # download models 5-9 to {dir_name}\/models from colab\/kernels or local machine\n\n    #learn.model_dir=Path('models')\n    learn = learn.load(f\"model_fold_{i}\")\n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                            seed=999, #seed\n                            fn_col='path', #filename\/path is in the second column of the DataFrame\n                            label_col='norm_score', #label is in the first column of the DataFrame\n                            y_block=RegressionBlock, #The type of target\n                            bs=BATCH_SIZE, #pass in batch size\n                            num_workers=8,\n                            item_tfms=Resize(384), #pass in item_tfms\n                            batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()])) \n\n    valid = train_df[train_df.fold == i].reset_index(drop=True) # VALID, OOF Preds \n    train_predictions,_ = learn.tta(dl=dls.test_dl(valid), n=7, beta=0)\n    \n    valid['Pawpularity'] = np.stack(train_predictions)*100\n    valid.to_csv(f'oof_preds_sturges_fold_{i}.csv')\n    \n    del learn; torch.cuda.empty_cache(); gc.collect()\n","44f6e5dc":"#creating train df for using sturges bins\n\nset_seed(365, reproducible=True)\nBATCH_SIZE = 8                       \n\ntrain_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n\ntrain_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['norm_score']\n\nseed=365\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n\nimport math\n\n#Rice rule\n\nnum_bins = int(np.ceil(2*((len(train_df))**(1.\/3))))\nnum_bins\n\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\n\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\ntrain_df['fold'] = -1\nN_FOLDS = 10        #was10\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\ntrain_df.fold.value_counts().plot.bar()\n\ndef petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ndef get_data(fold):\n    train_df_f = train_df.copy()  # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    dls = ImageDataLoaders.from_df(\n                    train_df_f, #pass in train DataFrame\n                   valid_col='is_valid', #\n                   seed=365, #seed\n                   fn_col='path', #filename\/path is in the second column of the DataFrame\n                   label_col='norm_score', #label is in the first column of the DataFrame\n                   y_block=RegressionBlock, #The type of target\n                   bs=BATCH_SIZE, #pass in batch size\n                   num_workers=8,\n                   item_tfms=Resize(384), #pass in item_tfms\n                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()]) #pass in batch_tfms\n                            ) \n    \n    return dls\n\n\ndef get_learner(fold_num):\n    data = get_data(fold_num)\n    model = create_model('swin_large_patch4_window12_384', pretrained=True, num_classes=data.c)\n    rmse = AccumMetric(petfinder_rmse)\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=[rmse]).to_fp16()\n    return learn","20a15a70":"import gc\nfor i in range(1):\n\n    print(f'Fold {i} results')\n    learn = get_learner(fold_num=i)\n    if i<5: learn.path=Path('..\/input\/rice-bins-10fold-p1')   # download models 0-4 to {dir_name}\/models, for me I used gdown to download models to a kernel and saved\n    else: learn.path=Path('..\/input\/rice-bins-10fold-p2')     # download models 5-9 to {dir_name}\/models from colab\/kernels or local machine\n\n    #learn.model_dir=Path('models')\n    learn = learn.load(f\"model_fold_{i}\")\n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                            seed=365, #seed\n                            fn_col='path', #filename\/path is in the second column of the DataFrame\n                            label_col='norm_score', #label is in the first column of the DataFrame\n                            y_block=RegressionBlock, #The type of target\n                            bs=BATCH_SIZE, #pass in batch size\n                            num_workers=8,\n                            item_tfms=Resize(384), #pass in item_tfms\n                            batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(), Flip()])) \n\n    valid = train_df[train_df.fold == i].reset_index(drop=True) # VALID, OOF Preds \n    train_predictions,_ = learn.tta(dl=dls.test_dl(valid), n=7, beta=0)\n    \n    valid['Pawpularity'] = np.stack(train_predictions)*100\n    valid.to_csv(f'oof_preds_rice_fold_{i}.csv')\n    \n    del learn; torch.cuda.empty_cache(); gc.collect()\n","e5c3f1ba":"print(\"strurges bins individual CV Scores\")\nfor i in range(10):\n    train=pd.read_csv(f'..\/input\/sturgesoof\/oof_preds_fold_{i}.csv')\n    oof = np.hstack(train['Pawpularity']\/100)\n    true = np.hstack(train.norm_score.values)\n    rmse = np.sqrt( np.mean( (oof - true)**2.0 ))\n    print(f'fold{i} rmse = ', rmse)\n    \nprint(\"rice bins individual CV Scores\")\nfor i in range(10):\n    train=pd.read_csv(f'..\/input\/rice-oof\/oof_preds_fold_{i}.csv')\n    oof = np.hstack(train['Pawpularity']\/100)\n    true = np.hstack(train.norm_score.values)\n    rmse = np.sqrt( np.mean( (oof - true)**2.0 ))\n    print(f'fold{i} rmse = ', rmse)","1f617a6d":"print(\"strurges bins\")\noof_preds = []\noof_true = []\nfor i in range(10):\n    train=pd.read_csv(f'..\/input\/sturgesoof\/oof_preds_fold_{i}.csv')\n    oof_preds.append(train['Pawpularity']\/100); oof_true.append(train.norm_score.values) \n\ntrue = np.hstack(oof_true); oof = np.hstack(oof_preds)   \nrmse = 100*np.sqrt( np.mean( (oof - true)**2.0 ))\nprint(\"overall CV\", rmse)\n\nprint(\"rice bins\")\noof_preds = []\noof_true = []\nfor i in range(10):\n    train=pd.read_csv(f'..\/input\/rice-oof\/oof_preds_fold_{i}.csv')\n    oof_preds.append(train['Pawpularity']\/100); oof_true.append(train.norm_score.values) \n\ntrue = np.hstack(oof_true); oof = np.hstack(oof_preds)   \nrmse = 100*np.sqrt( np.mean( (oof - true)**2.0 ))\nprint(\"overall CV\", rmse)\n","7f1d9918":"oof_preds = []; oof_true = []\ntrain=pd.read_csv(f'.\/oof_preds_sturges_fold_0.csv')\noof_preds.append(train['Pawpularity']\/100); oof_true.append(train.norm_score.values) \ntrue = np.hstack(oof_true); oof = np.hstack(oof_preds)   \nrmse = 100*np.sqrt( np.mean( (oof - true)**2.0 ))","314241f2":"rmse","6e4ffc76":"# Sturges Bins OOF Inference","247f52fe":"# CV Scores using CSV OOF Preds files","c02c8825":"# Rice Bins OOF Inference","ca7f7c65":"**A lot of people in discussions seem to be having trouble in calculating accruate CV scores. So here I demnstrate how to do the same using inference on your saved models adapted from cdeotte's rapids svr pipeline.**"}}