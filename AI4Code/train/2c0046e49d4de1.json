{"cell_type":{"51edde74":"code","413a3b1b":"code","c29c2592":"code","76e5dcb1":"code","028aa1ed":"code","7e1f164e":"code","b8186c51":"code","25469f6a":"code","d01a5cec":"code","de133905":"code","9d9fc43b":"code","3f28a1b0":"code","a3725244":"code","ea3bf799":"code","7186bfe6":"code","64618bf3":"code","2423ced0":"code","63e9c843":"code","ccc11f84":"code","aafae125":"code","ce05936c":"code","3e7afdbe":"code","786780c6":"markdown"},"source":{"51edde74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","413a3b1b":"df = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")\ndf.head()","c29c2592":"df.shape","76e5dcb1":"\ndf.info()","028aa1ed":"plt.figure(figsize=(10,12))\nsns.heatmap(df.corr())","7e1f164e":"z=df['Class'].value_counts(sort=True).sort_index()\nz.plot(kind='bar')","b8186c51":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nz=scaler.fit_transform(df['Amount'].values.reshape(1,-1))\ndf['normAmount']=z.reshape(-1,1)","25469f6a":"Y=df['Class']\ndf=df.drop(['Amount'],axis=1)\nX_TEST=df.drop(['Class'],axis=1)\nY_TEST=df[\"Class\"]","d01a5cec":"df.head()","de133905":"df['Class'].value_counts()","9d9fc43b":"Y=df['Class']\nfraud_indices=np.array(Y[Y==1].index)\nnormal_indices=np.array(Y[Y==0].index)\nnumber_fraud=Y[Y==1].count()","3f28a1b0":"random_normal_indices=np.random.choice(normal_indices,number_fraud,replace=True)\nprint((random_normal_indices).reshape(1,-1))\nunder_sample_indices=np.concatenate([random_normal_indices,fraud_indices])\nimport random\nrandom.shuffle(under_sample_indices)","a3725244":"print(under_sample_indices)","ea3bf799":"df.head()","7186bfe6":"X_under_sample=df.iloc[under_sample_indices]\nX_under_sample=X_under_sample.drop([\"Class\"],axis=1)\nY_under_sample=df['Class'].iloc[under_sample_indices]\nprint(Y_under_sample[:15])\n#print(X_under_sample.shape,Y_under_sample.shape)","64618bf3":"Y_under_sample.value_counts()","2423ced0":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X_under_sample,Y_under_sample,test_size=0.33)\nprint(len(x_test)\/(len(x_test)+len(x_train)))","63e9c843":"from sklearn.model_selection import cross_val_score\ndef kfold():\n    c_param_range = [0.001,0.01,0.1,1,10,100,1000]\n    values=[]    \n    for var in c_param_range:\n        model=LogisticRegression(C=var,penalty=\"l1\")\n        scores=cross_val_score(model,\n                               X_under_sample,Y_under_sample,cv=5,scoring='recall')\n        print(\"C=\",var)\n        print(\"scores\",scores)\n        values.append(scores.mean())\n        print(\"Mean is \",scores.mean())\n    return c_param_range[values.index(max(values))]","ccc11f84":"best_c=kfold()\nprint(\"best_c\",best_c)","aafae125":"model=LogisticRegression(C=best_c,penalty='l1')\nmodel.fit(x_train,y_train)\ny_pred_undersample = model.predict(x_test)\nfrom sklearn.metrics import confusion_matrix\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test,y_pred_undersample)\nnp.set_printoptions(precision=2)\n\nprint(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]\/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n","ce05936c":"model=LogisticRegression(C=best_c,penalty='l1')\nmodel.fit(x_train,y_train)\n\ny_pred_undersample = model.predict(X_TEST)\nfrom sklearn.metrics import confusion_matrix\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(Y_TEST,y_pred_undersample)\nnp.set_printoptions(precision=2)\n\nprint(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]\/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n","3e7afdbe":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report \nlr = LogisticRegression(C = best_c, penalty = 'l1')\ny_pred_undersample_score = lr.fit(x_train,y_train).decision_function(x_test)\n\nfpr, tpr, thresholds = roc_curve(y_test,y_pred_undersample_score)\nroc_auc = auc(fpr,tpr)\n\n# Plot ROC\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.0])\nplt.ylim([-0.1,1.01])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","786780c6":"NOW WE HAVE DONE UNDERSAMPLING \nThe instaces of both classes are same"}}