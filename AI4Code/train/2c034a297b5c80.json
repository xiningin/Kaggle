{"cell_type":{"1907450c":"code","f655c56c":"code","3e9504da":"code","4e02ae0b":"code","49e5b613":"code","af57ec72":"code","378d1167":"code","ed283084":"code","685ac23e":"code","ef6d0894":"code","16461f27":"code","b023b220":"code","6728f26e":"code","bc751ca1":"code","21672213":"code","e598092c":"code","11e21b9a":"code","6f9bbc44":"code","5e142f90":"code","4f6dc5c0":"code","a913b880":"code","36ea6dc0":"code","9bc390b2":"code","8746341d":"code","e01cc5fb":"markdown","945349df":"markdown","8c40e51c":"markdown","8e00b31a":"markdown","57326f71":"markdown","93463c46":"markdown"},"source":{"1907450c":"#Importing libraries\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport imageio\nimport torch \nfrom torch.utils import data\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","f655c56c":"class TGSSaltDataset(data.Dataset):\n    #init with the location of the dataset, and the list of file \n    def __init__(self, root_path, file_list):\n        self.root_path = root_path\n        self.file_list = file_list\n    #get method - how long is the list\n    def __len__(self):\n        return len(self.file_list)\n    #get method - return the seismic image + label for a given index\n    def __getitem__(self, index):\n        #if the index is out of bounds, get a random image\n        if index not in range(0, len(self.file_list)):\n            return self.__getitem__(np.random.randint(0, self.__len__()))\n        #define a file ID using the index parameter\n        file_id = self.file_list[index]\n        #image folder + path\n        image_folder = os.path.join(self.root_path, \"images\")\n        image_path = os.path.join(image_folder, file_id + \".png\")\n        #label folder + path\n        mask_folder = os.path.join(self.root_path, \"masks\")\n        mask_path = os.path.join(mask_folder, file_id + \".png\")\n        #read it, store it in memory as a byte array\n        image = np.array(imageio.imread(image_path), dtype=np.uint8)\n        mask = np.array(imageio.imread(mask_path), dtype=np.uint8)\n        #return image + label\n        return image, mask\n\n","3e9504da":"#train image + mask data\ntrain_mask = pd.read_csv('..\/input\/train.csv')\n#depth data\ndepth = pd.read_csv('..\/input\/depths.csv')\n#training path\ntrain_path = \"..\/input\/train\/\"\n\n#list of files\nfile_list = list(train_mask['id'].values)\n#define our dataset using our class\ndataset = TGSSaltDataset(train_path, file_list)","4e02ae0b":"#function to visualize these images\ndef plot2x2Array(image, mask):\n    #invoke matplotlib!\n    f, axarr = plt.subplots(1,2)\n    axarr[0].imshow(image)\n    axarr[1].imshow(mask)\n    axarr[0].grid()\n    axarr[1].grid()\n    axarr[0].set_title('Image')\n    axarr[1].set_title('Mask')","49e5b613":"for i in range(5):\n    image, mask = dataset[np.random.randint(0, len(dataset))]\n    plot2x2Array(image, mask)","af57ec72":"plt.figure(figsize = (6, 6))\nplt.hist(depth['z'], bins = 50)\nplt.title('Depth distribution')","378d1167":"#convert to image\ndef rleToMask(rleString,height,width):\n    #width heigh\n    rows,cols = height,width\n    try:\n        #get numbers\n        rleNumbers = [int(numstring) for numstring in rleString.split(' ')]\n        #get pairs\n        rlePairs = np.array(rleNumbers).reshape(-1,2)\n        #create an image\n        img = np.zeros(rows*cols,dtype=np.uint8)\n        #for each pair\n        for index,length in rlePairs:\n            #get the pixel value \n            index -= 1\n            img[index:index+length] = 255\n        \n        \n        #reshape\n        img = img.reshape(cols,rows)\n        img = img.T\n    \n    #else return empty image\n    except:\n        img = np.zeros((cols,rows))\n    \n    return img","ed283084":"#for measuring how salty an image is\ndef salt_proportion(imgArray):\n    try: \n        unique, counts = np.unique(imgArray, return_counts=True)\n        ## The total number of pixels is 101*101 = 10,201\n        return counts[1]\/10201.\n    \n    except: \n        return 0.0","685ac23e":"merged = train_mask.merge(depth, how = 'left')\nmerged.head()","ef6d0894":"im_width = 128\nim_height = 128\nborder = 5\nim_chan = 2 # Number of channels: first is original and second cumsum(axis=0)\nn_features = 1 # Number of extra features, like depth\npath_train = '..\/input\/train\/'\npath_test = '..\/input\/test\/'","16461f27":"ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\nplt.figure(figsize=(30,15))\nfor j, img_name in enumerate(ids):\n    q = j+1\n    img = load_img('..\/input\/train\/images\/' + img_name + '.png', grayscale=True)\n    img_mask = load_img('..\/input\/train\/masks\/' + img_name + '.png', grayscale=True)\n    \n    img = np.array(img)\n    img_cumsum = (np.float32(img)-img.mean()).cumsum(axis=0)\n    img_mask = np.array(img_mask)\n    \n    plt.subplot(1,3*(1+len(ids)),q*3-2)\n    plt.imshow(img, cmap='seismic')\n    plt.subplot(1,3*(1+len(ids)),q*3-1)\n    plt.imshow(img_cumsum, cmap='seismic')\n    plt.subplot(1,3*(1+len(ids)),q*3)\n    plt.imshow(img_mask)\nplt.show()\n\n","b023b220":"train_ids = next(os.walk(path_train+\"images\"))[2]\ntest_ids = next(os.walk(path_test+\"images\"))[2]","6728f26e":"import sys \n# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n    img = load_img(path + '\/images\/' + id_)\n    x = img_to_array(img)[:,:,1]\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_train[n] = x\n    mask = img_to_array(load_img(path + '\/masks\/' + id_))[:,:,1]\n    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\nprint('Done!')","bc751ca1":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","21672213":"# Build U-Net model\ninputs = Input((im_height, im_width, im_chan))\ns = Lambda(lambda x: x \/ 255) (inputs)\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()","e598092c":"callback = EarlyStopping(patience=10, verbose=2)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=10, epochs=30, \n                    callbacks=[callback, checkpointer])","11e21b9a":"# Get and resize test images\nX_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    img = load_img(path + '\/images\/' + id_)\n    x = img_to_array(img)[:,:,1]\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\n\nprint('Done!')\n\n","6f9bbc44":"# Predict on train, val and test\nmodel = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=2)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=2)\npreds_test = model.predict(X_test, verbose=2)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","5e142f90":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))\n    \n\npreds_test_upsampled[0].shape","4f6dc5c0":"import random \ndef plot_sample(X, y, preds):\n    ix = random.randint(0, len(X))\n\n    has_mask = y[ix].max() > 0\n\n    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Seismic')\n\n    ax[1].imshow(X[ix, ..., 1], cmap='seismic')\n    if has_mask:\n        ax[1].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[1].set_title('Seismic cumsum')\n\n    ax[2].imshow(y[ix].squeeze())\n    ax[2].set_title('Salt')\n\n    ax[3].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[3].set_title('Salt Pred');\n    \n    \n\n# Check if training data looks all right\nplot_sample(X_train, Y_train, preds_train)\n","a913b880":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","36ea6dc0":"#thres = np.linspace(0.25, 0.75, 20)\n#thres_ioc = [iou_metric_batch(y_valid, np.int32(preds_val > t)) for t in tqdm_notebook(thres)]\n\n#best_thres = thres[np.argmax(thres_ioc)]\n#best_thres, max(thres_ioc)","9bc390b2":"def RLenc(img, order='F', format=True):\n    \n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}","8746341d":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')\nprint ('Submitted to output')","e01cc5fb":"**Model training **","945349df":"Several areas of Earth with large accumulations of oil and gas also have huge deposits of salt below the surface.\n\nBut unfortunately, knowing where large salt deposits are precisely is very difficult. Professional seismic imaging still requires expert human interpretation of salt bodies. This leads to very subjective, highly variable renderings. More alarmingly, it leads to potentially dangerous situations for oil and gas company drillers.","8c40e51c":"**Building U-Net (CNN) Model**","8e00b31a":"**About me: **\nWell I'm not old in the field, just trying to learn new things about ML and data science stuff. So, ignore the errors if any. But your valuable suggestions and corrections are warmly welcome. ","57326f71":" Here we will try to build a best algorithm that automatically and accurately identifies if a subsurface target is salt or not.\n ","93463c46":"**Preparing submission**"}}