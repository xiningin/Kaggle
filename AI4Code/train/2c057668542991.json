{"cell_type":{"8b4f2a96":"code","b0808d3b":"code","2a8b5925":"code","b46a8af7":"code","eec3b623":"code","9bc07845":"code","a4366219":"code","ff7205f3":"code","a3d2cf3e":"code","97a8751d":"code","2fed9909":"code","e285f7d9":"code","56ec4474":"code","f0595b59":"code","47c94db1":"code","12295042":"code","ef741322":"code","aa6c18db":"code","4d4cc091":"code","c5c33279":"code","2ef44ba4":"code","8ccdc17c":"code","727a1ac8":"code","6dca9728":"code","88cf204d":"code","c0c642ee":"code","414d7575":"code","9b6cf174":"code","c210c5a7":"code","b448f480":"code","6346cf6c":"code","d6e0f7ed":"code","dd19596d":"code","fb2a5054":"code","1b0e1e22":"code","72a14232":"code","317c233e":"code","bfc43377":"code","74818c4b":"code","05ea6c41":"code","0ae6a2fa":"code","3585eb1a":"code","1f8e835e":"code","66a8dd8e":"code","793387ce":"code","13987287":"code","1258d4a5":"code","fc7883e9":"code","da2d3048":"code","1332bb28":"code","c5c8b5ae":"code","2de78b4d":"code","9bc8e89a":"code","b12f161c":"code","45fc54d6":"code","a1b88362":"code","f396fa13":"code","8c55b605":"code","037166b9":"code","7bac614f":"code","4a88aea5":"code","b19ecd80":"code","52927136":"code","c05b645b":"code","d5836ac0":"code","3180b591":"code","9895e84a":"code","fdc13386":"code","f0bd8793":"code","c9a14be1":"code","d79b4667":"code","62c25c0c":"code","d795af1e":"code","bc18e36f":"code","3aa4fd9d":"code","621aa489":"code","6e4f903f":"code","1699fc9c":"code","ede1c284":"code","84e89dfd":"code","7edbe454":"code","a915eba8":"code","640bd0b7":"code","348e8212":"code","d893211e":"code","6f905400":"code","dde75b36":"code","0f4e33cc":"code","0c8ab43b":"code","4079482a":"code","3f4eb0e5":"code","2d14cf39":"code","6b38c08b":"code","5893304a":"code","908780cd":"code","810ae4ec":"code","680997c2":"code","5c8d5760":"code","8ac8384e":"code","9f6e13e6":"code","c240b618":"markdown","1b4714ab":"markdown","97b3b6c3":"markdown","c5e381d2":"markdown","1cc47361":"markdown","a2cb3914":"markdown","35dbdcee":"markdown","23a65d2f":"markdown","17bb494c":"markdown","83084028":"markdown","171336b9":"markdown","d8e4d80d":"markdown","5cc71c3a":"markdown"},"source":{"8b4f2a96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.metrics import silhouette_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b0808d3b":"train_data=pd.read_csv('\/kaggle\/input\/sa-customer-segmentation\/flight_train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/sa-customer-segmentation\/flight_test.csv')\nsample_data=pd.read_csv('\/kaggle\/input\/sa-customer-segmentation\/sample.csv')","2a8b5925":"train_data.head()","b46a8af7":"train_data.info()","eec3b623":"train_data.isnull().sum()","9bc07845":"plt.subplots(figsize=(12,12))\nsns.heatmap(train_data.corr(),annot=True)","a4366219":"train_data=train_data.append(test_data)","ff7205f3":"train_data.head()","a3d2cf3e":"train_data.info()","97a8751d":"from sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nlr=LinearRegression()\nimputer=SimpleImputer(missing_values=np.nan,strategy='median')\ntrain_data=train_data[train_data['WORK_CITY'].notnull() & train_data['WORK_PROVINCE']]\nage=imputer.fit(train_data[['AGE']])\ntrain_data['AGE']=imputer.transform(train_data[['AGE']])\ntest_data['AGE']=imputer.transform(test_data[['AGE']])","2fed9909":"train_data.isnull().sum()","e285f7d9":"mis_columns=['SUM_YR_1','SUM_YR_2']\ndef linear_regression_imputer(df,column):\n    from sklearn.preprocessing import StandardScaler\n    scalar=StandardScaler()\n    df['BP_SUM']=scalar.fit_transform(df[['BP_SUM']])\n    parameter='BP_SUM'\n    lr.fit(df[df[column].notnull()][[parameter]],df[df[column].notnull()][[column]])\n    return(lr.predict(df[df[column].isnull()][[parameter]]))\n        ","56ec4474":"df=train_data.copy()\nfor column in mis_columns:\n    lr1=(linear_regression_imputer(df,column))\n    l=len(lr1)\n    train_data.loc[train_data[column].isnull(),column]=lr1.reshape((l,1))\n    ","f0595b59":"train_data.isnull().sum()","47c94db1":"train_data.nunique().sort_values(ascending=False )","12295042":"train_data['GENDER'].unique()","ef741322":"print(train_data['GENDER'].value_counts())\nf,ax=plt.subplots(1,1)\nf.set_size_inches(5,3)\nsns.countplot(train_data[\"GENDER\"], ax=ax)","aa6c18db":"train_data[\"GENDER\"].fillna(\"Male\",inplace=True)","4d4cc091":"train_data.info()","c5c33279":"train_data['WORK_COUNTRY'].unique()","2ef44ba4":"customer_countrytrain=train_data[['WORK_COUNTRY','MEMBER_NO']]","8ccdc17c":"customer_countrytrain.groupby(['WORK_COUNTRY']).agg('count').reset_index().sort_values('MEMBER_NO', ascending=False)","727a1ac8":"\ntrain_data.info()","6dca9728":"train_data.WORK_PROVINCE.nunique()","88cf204d":"def unique_counts(train_data):\n    for i in train_data.columns:\n        count = train_data[i].nunique()\n        print(i, \": \", count)\nunique_counts(train_data)","c0c642ee":"train_data.info()","414d7575":"train_data.describe()","9b6cf174":"age0_30=train_data.AGE[(train_data.AGE>=0) & (train_data.AGE<30)]\nage30_50=train_data.AGE[(train_data.AGE>=30) & (train_data.AGE<50)]\nage50_70=train_data.AGE[(train_data.AGE>=50) & (train_data.AGE<70)]\nage70_100=train_data.AGE[(train_data.AGE>=70) & (train_data.AGE<100)]\n\ny=[len(age0_30.values),len(age30_50.values),len(age50_70.values),len(age70_100.values)]\nx=['0-30','30-50','50-70','70-100']\nsns.barplot(x=x,y=y)\nplt.xlabel('AGE BAND')\nplt.ylabel('count')","c210c5a7":"train_data['FIRST_FLIGHT_DATE']=pd.to_datetime(train_data['FIRST_FLIGHT_DATE'],errors='coerce')\ntrain_data['LAST_FLIGHT_DATE']=pd.to_datetime(train_data['LAST_FLIGHT_DATE'],errors='coerce')\ntrain_data['LOAD_TIME']=pd.to_datetime(train_data['LOAD_TIME'],errors='coerce')\ntrain_data['FFP_DATE']=pd.to_datetime(train_data['FFP_DATE'],errors='coerce')\n\ntrain_data=train_data.loc[train_data['LAST_FLIGHT_DATE'].notnull()]","b448f480":"train_data['Recurency']=(train_data['LOAD_TIME']-train_data['FIRST_FLIGHT_DATE']).dt.days\ntrain_data['Days_old']=(train_data['LOAD_TIME']-train_data['LAST_FLIGHT_DATE']).dt.days\ntrain_data['FFP_days']=(train_data['LOAD_TIME']-train_data['FFP_DATE']).dt.days","6346cf6c":"train_data.info()\ntrain_data.isnull().sum()\ntrain_data.count()","d6e0f7ed":"train_data.drop(columns=['FFP_DATE','WORK_COUNTRY','FIRST_FLIGHT_DATE','WORK_CITY','LOAD_TIME','LAST_FLIGHT_DATE'],inplace=True)\n","dd19596d":"train_data['GENDER'].replace(['Male','Female'],[1,0],inplace=True)\n","fb2a5054":"train_data.head()","1b0e1e22":"\ntrain_data=train_data.reset_index(drop=True)\n","72a14232":"train_data.tail()","317c233e":"train_data=pd.get_dummies(train_data,columns=['FFP_TIER'])\ntrain_data.head()\n","bfc43377":"train_data=pd.get_dummies(train_data,columns=['WORK_PROVINCE'])\n\ntrain_data.head()","74818c4b":"train_id=train_data['MEMBER_NO'].copy()\ntrain_data.drop(['MEMBER_NO'],axis=1,inplace=True)\ntrain_data.head()","05ea6c41":"train_id","0ae6a2fa":"def normalization(df):\n    from sklearn.preprocessing import StandardScaler\n    columns_name=df.columns\n    scaler=StandardScaler()\n    X=scaler.fit_transform(df)\n    df=pd.DataFrame(X)\n    df.columns=columns_name\n    return df\n","3585eb1a":"def pca_decomposition(df,num):\n    pca_data=df.copy()\n    from sklearn.decomposition import PCA\n    decompose=PCA(n_components=num,copy=True, \n          whiten=False, \n          svd_solver='auto', \n          tol=0.0, \n          iterated_power='auto', \n          random_state=0)\n    decompose.fit(pca_data)\n    trans_pca = decompose.transform(pca_data)\n    df_pca = pd.DataFrame(trans_pca)\n    variance_ratio = decompose.explained_variance_ratio_\n    print('pca_components ',num,'   describe ',sum(variance_ratio))\n    return df_pca,sum(variance_ratio)","1f8e835e":"\ndef train_kmeans(x, k):\n    KMModel = KMeans(n_clusters=k, \n                     init='k-means++', \n                     n_init=10, \n                     max_iter=600, \n                     tol=0.0001, \n                     precompute_distances='auto', \n                     verbose=0, \n                     random_state=1, \n                     copy_x=True, \n                     n_jobs=1, \n                     algorithm='auto')\n    KMModel.fit(x) \n    print(\"kmeans,\", k, \"clusters:   \", \"silhouette_score\", silhouette_score(x, KMModel.labels_),'\\n' )\n    return KMModel","66a8dd8e":"from sklearn.cluster import KMeans\n","793387ce":"train_normalize=normalization(train_data)\n\n","13987287":"from sklearn.decomposition import PCA","1258d4a5":"\nalist=[]\ndim=[]\nvari=[]\nfor l in range(150,600,10):\n    pca_result,var=pca_decomposition(train_normalize,l)\n    alist.append(pca_result)\n    vari.append(var)\n    dim.append(l)\n    \n    ","fc7883e9":"plt.figure(figsize=(20,8))\nplt.plot(dim,vari,marker='o',linestyle='--')\nplt.xlabel(\"Number of Components\")\nplt.ylabel(\"Cumulative explained variance\")","da2d3048":"from sklearn.metrics import silhouette_score","1332bb28":"from sklearn.metrics import silhouette_score\ndf=train_normalize.copy()\nfor pca in [300,450,500,400]:\n    df=train_normalize.copy()\n    pca_df,vari=pca_decomposition(df,pca)\n    for cluster in [2,3,4,5,6,7]:\n        train_kmeans(pca_df,cluster)","c5c8b5ae":"wcss=[]\npca_df,vari=pca_decomposition(df,400)\nfor i in [2,3,4,5,6,7]:\n    kmeans=train_kmeans(pca_df, i)\n    wcss.append(kmeans.inertia_)\n","2de78b4d":"plt.plot([2,3,4,5,6,7], wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","9bc8e89a":"k_means_data=pca_df","b12f161c":"list1=[]\n\nkmeans=KMeans(n_clusters=2,init='k-means++',random_state=42)\nlabels=kmeans.fit_predict(k_means_data.iloc[:,:])\n\n","45fc54d6":"from sklearn.metrics import silhouette_score","a1b88362":"print(silhouette_score(k_means_data,labels))","f396fa13":"pca_final,vari=pca_decomposition(pca_df,3)","8c55b605":"pca_final.head()","037166b9":"pca_final.info()","7bac614f":"pca_final['first_pca']=pca_final[0]\npca_final['second_pca']=pca_final[1]\npca_final['third_pca']=pca_final[2]\n","4a88aea5":"pca_final=pca_final.drop(columns=[0,1,2])","b19ecd80":"pca_final.head()","52927136":"pca_final['clusters']=labels","c05b645b":"pca_final.head()","d5836ac0":"pca_final.tail()","3180b591":"pca_final.info()","9895e84a":"from mpl_toolkits.mplot3d import Axes3D","fdc13386":"fig = plt.figure(figsize = (10, 7))\nax = plt.axes(projection =\"3d\")\nx=pca_final['first_pca']\ny=pca_final['second_pca']\nz=pca_final['third_pca']\nlabels=pca_final['clusters']\nprint(\"DONE\")\nax.scatter3D(x, y, z,c=labels,marker='o')\nplt.show()\nax.set_xlabel('first')\nax.set_ylabel('second')\nax.set_zlabel('third')\n ","f0bd8793":"import seaborn as sns\nsns.scatterplot(x=x,y=y,hue=labels,palette=['green','orange'])","c9a14be1":"sns.scatterplot(x=y,y=z,hue=labels,palette=['green','orange'])","d79b4667":"sns.scatterplot(x=x,y=z,hue=labels,palette=['green','orange'])","62c25c0c":"train_data['cluster']=labels","d795af1e":"train_data.info()","bc18e36f":"train_data.info()","3aa4fd9d":"sns.scatterplot(x=train_data['AGE'],y=train_data['FLIGHT_COUNT'],hue=labels,palette=['green','orange'])","621aa489":"sns.scatterplot(x=train_data['AGE'],y=train_data['BP_SUM'],hue=labels,palette=['green','orange'])","6e4f903f":"sns.scatterplot(x=train_data['FLIGHT_COUNT'],y=train_data['BP_SUM'],hue=labels,palette=['green','orange'])","1699fc9c":"train_data.info()","ede1c284":"tidy_train=pd.concat([train_data,train_id],axis=1)","84e89dfd":"tidy_train.info()","7edbe454":"tidy_train.to_csv(\"Tidy_Train.csv\",index=False)","a915eba8":"Train_tidy=pd.read_csv(\"Tidy_Train.csv\")","640bd0b7":"Train_tidy.info()","348e8212":"train_data[\"MEMBER_NO\"]=train_id","d893211e":"train_data.info()","6f905400":"Test_tidy=train_data.loc[49818:]","dde75b36":"Test_tidy.info()","0f4e33cc":"Test_tidy.head()","0c8ab43b":"Test_tidy.info()","4079482a":"result=Test_tidy[[\"MEMBER_NO\",\"cluster\"]]","3f4eb0e5":"result.head()","2d14cf39":"result.info()","6b38c08b":"result['cluster'].unique()","5893304a":"result.to_csv(\"Final_result.csv\",index=False)","908780cd":"test_check=pd.read_csv(\"Final_result.csv\")","810ae4ec":"test_check.info()","680997c2":"Test_tidy.head()","5c8d5760":"sns.scatterplot(x=Test_tidy['AGE'],y=Test_tidy['FLIGHT_COUNT'],hue=labels,palette=['green','orange'])\n","8ac8384e":"sns.scatterplot(x=Test_tidy['AGE'],y=Test_tidy['BP_SUM'],hue=labels,palette=['green','orange'])\n","9f6e13e6":"sns.scatterplot(x=Test_tidy['FLIGHT_COUNT'],y=Test_tidy['BP_SUM'],hue=labels,palette=['green','orange'])","c240b618":"Now we go for data visualization part.","1b4714ab":"k means algorithm","97b3b6c3":"lets start some ML now \nsince we are using unsupervised learning \nwe would be usinng\n1. k means and \n2. k means mini batch \n\n\nscoring we would be using is \n*  Silhouette score\n\nHigher the score means more well defined is the cluster","c5e381d2":"Here, observing the above chart, we can find that distribution of Male is way higher than that of female. So, we replace the missing gender null values with male in the test data.However,train data has no null values for gender.","1cc47361":"so bringing out the features like the age of the customer in the company, Recency of the customer etc. from the given date features.","a2cb3914":"From the above table, we can find that more than 94% of the customers in the data are from China.There is also some research that customer clusters vary by geography, so here we drop the column country and work on province feature for geography.","35dbdcee":"Now we visualize our test data which was clustered.","23a65d2f":"Here, we find that majority of the customers are from the age group 30-50","17bb494c":"PCA decomposition ","83084028":"Now, we check unique values for each column","171336b9":"From the above analysis, we can choose num_components=400 and k=2","d8e4d80d":"One hot encoding the data ","5cc71c3a":"normalization of the data"}}