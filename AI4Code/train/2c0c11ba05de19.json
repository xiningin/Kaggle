{"cell_type":{"dc97fb52":"code","9835d7e4":"code","3795e61a":"code","d25cf075":"code","fd58e08d":"code","5f7d9d6c":"code","ca951415":"code","9bc3f6f7":"code","b5b4c955":"code","198d018e":"code","1e1edc8f":"code","81cfcda0":"code","71ee0faa":"code","ff2389e5":"code","22cae4ae":"code","36176ea9":"code","f34b13ca":"code","5a0058db":"code","3a106213":"code","ba9a1fd8":"code","c8b54e3a":"code","be41ad81":"code","c175fca2":"code","e73d9eeb":"code","1ad70ce5":"code","dcf84e56":"code","c458c19d":"code","0da74d0b":"code","62015dea":"code","e9a36c28":"code","6104fa6f":"code","ad90c074":"code","a57d0c5c":"code","6af1d6da":"code","23c696f6":"code","75a9982e":"code","3c948d73":"code","d8dcede2":"code","5d3b5232":"code","2a008b56":"code","bdb33474":"code","5310f7a4":"code","f5ff4eb4":"code","eb8bb86a":"code","dd116cde":"code","4066a1f7":"code","e9d9d7c5":"code","a2046b1d":"code","c3c1083e":"code","4b2c1cc6":"code","8ebfb1ee":"code","432cecfc":"code","369acf37":"code","a1e5b444":"code","9f4772a6":"code","a2795d3b":"code","b8b574b5":"markdown","c737d554":"markdown","a7fb9abb":"markdown","a5413ace":"markdown","8183e261":"markdown","33d81bad":"markdown","76e369f3":"markdown","564d12af":"markdown","f6e64917":"markdown","7fdb9caa":"markdown","7c777f80":"markdown","348cf8fd":"markdown","dc84dd20":"markdown","edfda99d":"markdown","c099748b":"markdown","b21d4584":"markdown","a9107009":"markdown","02061406":"markdown","9ba2d9ce":"markdown","80d08638":"markdown","1e937627":"markdown","7db550bf":"markdown","0bd35c7d":"markdown","89b1df41":"markdown","f3abbbbc":"markdown","97fa0798":"markdown","114acd65":"markdown","7c293b7d":"markdown","8a979f28":"markdown","f6fcc096":"markdown","d2b8652b":"markdown","640b3729":"markdown","6d110c3b":"markdown","00d2a34e":"markdown","8bb624bf":"markdown","b5efc0c4":"markdown","99b7f6a3":"markdown","5dbb53c6":"markdown","1849f5b6":"markdown","f3cf3057":"markdown","56776cf8":"markdown","7eb679d2":"markdown"},"source":{"dc97fb52":"import plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly import subplots\nimport plotly.figure_factory as ff\nimport matplotlib.pyplot as plt\n\nfrom pandas_profiling import ProfileReport\nimport seaborn as sns\nfrom sklearn import metrics\nfrom scipy import stats","9835d7e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3795e61a":"# Load train and test Datasets\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\ntrain.head()","d25cf075":"report = ProfileReport(train)","fd58e08d":"report","5f7d9d6c":"fig = px.histogram(train, x='Pclass', color='Pclass')\nfig.update_xaxes(type='category')\nfig.show()","ca951415":"fig = px.histogram(train, x='Pclass', color='Sex')\nfig.update_xaxes(type='category')\nfig.show()","9bc3f6f7":"# Explore Pclass vs Survived\ng = sns.catplot(x=\"Pclass\",y=\"Survived\",data=train, kind=\"bar\", height=6 , palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","b5b4c955":"fig = px.histogram(train, x='Sex', color='Sex')\nfig.update_xaxes(type='category')\nfig.show()","198d018e":"# Explore Pclass vs Survived by Sex\ng = sns.catplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train, height=6, kind=\"bar\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","1e1edc8f":"fig = px.histogram(train[~train['Embarked'].isna()], x='Embarked', color='Embarked')\nfig.update_xaxes(type='category')\nfig.show()","81cfcda0":"# Explore Embarked vs Survived \ng = sns.catplot(x=\"Embarked\", y=\"Survived\", data=train, height=6, kind=\"bar\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","71ee0faa":"fig = px.histogram(train, x='SibSp', color='SibSp')\nfig.update_xaxes(type='category')\nfig.show()","ff2389e5":"# Explore SibSp feature vs Survived\ng = sns.catplot(x=\"SibSp\",y=\"Survived\", data=train, kind=\"bar\", height=6)\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","22cae4ae":"fig = px.histogram(train[~train['Age'].isna()], x='Age')\nfig.show()","36176ea9":"# Explore Age distibution \ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 0) & (train[\"Age\"].notnull())], color=\"Red\", shade=True)\ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 1) & (train[\"Age\"].notnull())], ax=g, color=\"Blue\", shade=True)\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])","f34b13ca":"# Explore Fare distribution \ng = sns.distplot(train[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(train[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","5a0058db":"## Join train and test datasets in order to obtain the same number of features during categorical conversion\ntrain_indexs = train.index\ntest_indexs = test.index\n\ndf =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\ndf = df.drop('PassengerId', axis=1)\n\nlen(train_indexs), len(test_indexs)","3a106213":"df.isna().sum()","ba9a1fd8":"# Fill Fare missing values with the median value\ndf[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\n\n# Fill Embarked nan values of dataset with the mode\ndf[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])","c8b54e3a":"df['Fare'].isna().sum(), df['Embarked'].isna().sum()","be41ad81":"# Fill Age with the median age of similar rows according to Pclass and SibSp\n# If no similar crew memeber are found, we will use the full crew age's median\nnan_age_ids = list(df[\"Age\"][df[\"Age\"].isnull()].index)\n\nfor i in nan_age_ids :\n    age_med = df[\"Age\"].median()\n    age_pred = df[\"Age\"][((df['SibSp'] == df.iloc[i][\"SibSp\"]) & (df['Pclass'] == df.iloc[i][\"Pclass\"]))].median()\n    \n    if not np.isnan(age_pred) :\n        df['Age'].iloc[i] = age_pred\n    else :\n        df['Age'].iloc[i] = age_med","c175fca2":"df['Age'].isna().sum()","e73d9eeb":"df[\"Cabin\"][df[\"Cabin\"].notnull()].head()","1ad70ce5":"# Replace the Cabin number by the type of cabin. 'Z' if missing\ndf[\"Cabin\"] = df['Cabin'].apply(lambda x: 'Z' if pd.isnull(x) else x[0])\n\ndf['Cabin'].isna().sum()","dcf84e56":"g = sns.catplot(y=\"Survived\",x=\"Cabin\", data=df, kind=\"bar\", order=['A','B','C','D','E','F','G','T','Z'])\ng = g.set_ylabels(\"Survival Probability\")","c458c19d":"corr = df.corr()\n\nfig, ax = plt.subplots(figsize=(10, 8))\n# mask\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# plot heatmap\nsns.heatmap(corr, mask=mask, annot=False, fmt=\".2f\", cmap='Blues',\n           vmin=-1, vmax=1, cbar_kws={\"shrink\": .8})\n# yticks\nplt.yticks(rotation=0)\nplt.show()","0da74d0b":"df['Ticket'].head()","62015dea":"df['Ticket'] = df['Ticket'].apply(lambda x: 'Z' if x.isdigit() else x.replace('.',' ').replace('\/','').strip().split(' ')[0])\ndf['Ticket'].head()","e9a36c28":"df['Title'] = df['Name'].apply(lambda x: x.split('.')[0].split(' ')[-1])\ndf['Title'].value_counts()","6104fa6f":"# Now we can drop Name column\ndf = df.drop('Name', axis=1)","ad90c074":"df[\"Title\"] = df[\"Title\"].replace(\n    ['Lady','Countess','Capt', 'Mme', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Mlle', 'Ms'], \n    'Rare'\n)\ndf[\"Title\"] = df[\"Title\"].replace(\n    'Miss', \n    'Mrs'\n)\ndf['Title'].value_counts()","a57d0c5c":"g = sns.catplot(x=\"Title\", y=\"Survived\", data=df, kind=\"bar\")\ng = g.set_ylabels(\"survival probability\")","6af1d6da":"# Explore Fare distribution \ng = sns.distplot(df[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(df[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","23c696f6":"df[\"Fare\"] = np.log1p(df[\"Fare\"])\n\n# lets see the distribution now\ng = sns.distplot(df[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(df[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","75a9982e":"# Create a family size descriptor from SibSp and Parch for himself\ndf[\"Fsize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1","3c948d73":"# Create new feature of family size\ndf['Single'] = df['Fsize'].map(lambda s: 1 if s == 1 else 0)\ndf['SmallF'] = df['Fsize'].map(lambda s: 1 if  2 <= s <= 3  else 0)\ndf['LargeF'] = df['Fsize'].map(lambda s: 1 if s >= 4 else 0)","d8dcede2":"# Finding all the categorical columns from the data\ncategorical_columns = df.select_dtypes(exclude=['int64','float64']).columns\nnumerical_columns = df.drop('Survived', axis=1).select_dtypes(include=['int64','float64']).columns\ncategorical_columns","5d3b5232":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndf['Sex'] = le.fit_transform(df['Sex'])","2a008b56":"categorical_columns = df.select_dtypes(exclude=['int64','float64']).columns\ncategorical_columns","bdb33474":"# One hot encoding independent variable x\ndef encode_and_bind(original_dataframe, feature_to_encode):\n    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n    res = pd.concat([original_dataframe, dummies], axis=1)\n    res = res.drop([feature_to_encode], axis=1)\n    return(res) ","5310f7a4":"for feature in categorical_columns:\n    df = encode_and_bind(df, feature)\n\ndf.head()","f5ff4eb4":"## Separate train dataset and test dataset\n\ntrain = df.loc[train_indexs]\ntest = df[len(train_indexs):]\ntest = test.drop(labels=[\"Survived\"], axis=1)","eb8bb86a":"import h2o\nfrom h2o.automl import H2OAutoML\n\nh2o.init()","dd116cde":"hf = h2o.H2OFrame(train)\ntest_hf = h2o.H2OFrame(test)\nhf.head()","4066a1f7":"# Select the predictor variables and the target\nhf['Survived'] = hf['Survived'].asfactor()\npredictors = hf.drop('Survived').columns\nresponse = 'Survived'","e9d9d7c5":"# Split into train and test\ntrain_hf, valid_hf = hf.split_frame(ratios=[.8], seed=1234)","a2046b1d":"# Add a Stopping Creterias: max number of models and max time\n# We are going to exclude DeepLearning algorithms because they are too slow\naml = H2OAutoML(\n    max_models=20,\n    max_runtime_secs=300,\n    seed=1234,\n    # exclude_algos = [\"DeepLearning\"]\n)","c3c1083e":"# Train the model\naml.train(x=predictors,\n        y=response,\n        training_frame=hf,\n)","4b2c1cc6":"# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head(rows=5)  # Print the first 5 rows","8ebfb1ee":"valid_pred = aml.leader.predict(valid_hf)","432cecfc":"metrics.accuracy_score(valid_pred.as_data_frame()['predict'], valid_hf.as_data_frame()['Survived'])","369acf37":"test_ids = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')['PassengerId']","a1e5b444":"test_pred = aml.predict(test_hf)","9f4772a6":"submission = pd.concat([test_ids, test_pred.as_data_frame()['predict']], axis=1)\nsubmission.columns = ['PassengerId', 'Survived']\nsubmission.head()","a2795d3b":"submission.to_csv(\"submission_h2o_automl.csv\",index=False)","b8b574b5":"As we can see, women have more chance to be saved.","c737d554":"## 2.3 Transform variables","a7fb9abb":"### Age","a5413ace":"### Fill Age missings\n\nAs Age has too manu missing, i will take care of this variable separately.","8183e261":"<a id='3'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">3. Feature selection<\/p>\n\nAs this is a short problem (with low number of variables) and loew number of rows, its not necessary for now to reduce the dimensionality of the problem!","33d81bad":"As we can see, it seems that the first letter represent the area in the boat were the passenger was traveling.\n\nWe are going to rebuild the variable with the first letter and we are going to assing a random letter to nans.","76e369f3":"### Name analysis\n\nAs we can see, each name has a particle which informs about the social status.\n\nWe are goint to take it and create a new variable (as name doesnt seem to be a good opciones).","564d12af":"![one-hot-encoding.png](attachment:one-hot-encoding.png)","f6e64917":"## 2.2 Fill missings","7fdb9caa":"![skewness.png](attachment:skewness.png)","7c777f80":"![h2o-automl-logo2.jpg](attachment:h2o-automl-logo2.jpg)","348cf8fd":"## 2.4 Fix numerical variables","dc84dd20":"### Variable Notes\n\n**pclass**: A proxy for socio-economic status (SES)\n* 1st = Upper\n* 2nd = Middle\n* 3rd = Lower\n\n**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\n**sibsp**: The dataset defines family relations in this way...\n**Sibling** = brother, sister, stepbrother, stepsister\n**Spouse** = husband, wife (mistresses and fianc\u00e9s were ignored)\n\n**parch**: The dataset defines family relations in this way...\n* Parent = mother, father\n* Child = daughter, son, stepdaughter, stepson\n\nSome children travelled only with a nanny, therefore parch=0 for them.","edfda99d":"### Pclass","c099748b":"### Fill Cabin missings\n\nAs Cabin has too manu missing, i will take care of this variable separately.","b21d4584":"Conclusiones: \n* As we can see, the most part of the crew was in from the **3\u00ba class**.\n* Its curious that the second mayority class is **1\u00ba class**. It could be explanided because it was an important ship and many rich people wanted to join the trip.\n* We can also conclude that the **1\u00ba class have more chances to sirvive**.","a9107009":"This variable is high skewed so we will have to take care about it.","02061406":"<a id='4'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">4. Modelling<\/p>\n\n\n\nFirstly we are going to split the dataframe","9ba2d9ce":"The peak between 0 and 10 years corresponds to those children that were prioriced in the saving order (not you DiCaprio).","80d08638":"Survived missing values corresponds to the test parts so we should take care of it.","1e937627":"## 2.1 Join train and test\n\nFirstly join both dataset so we can handle data cleaning and feature creation in both dfs at the same time!","7db550bf":"### Fare","0bd35c7d":"In this case, we are going to try the same idea that we used in 'Cabin' variable.\n\nWe are going to applay to each vale:\n* Replace dot (.) with space\n* Remove bars (\/)\n\nNow we camn get the first item.","89b1df41":"![titanic.jpeg](attachment:titanic.jpeg)","f3abbbbc":"Now we have to replace the Rare Titles.","97fa0798":"<a id='1'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">1. Data visualization<\/p>\n\nFirst of all, lets check the variables","114acd65":"It is obvious that Male have less chance to survive than Female.","7c293b7d":"### Tickets analysis","8a979f28":"<a id='5'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">5. Submission<\/p>","f6fcc096":"It seems that people embarked from Cherbourg (C) have more chance to survive.","d2b8652b":"### Sex","640b3729":"<a id='2'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">2. Feature Engineering<\/p>","6d110c3b":"### Embarked","00d2a34e":"<a id='title'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\">Titanic \ud83d\udea2 | DiCaprio's Safety Guide<\/p>","8bb624bf":"Single passengers (0 SibSP) or with two other persons (SibSP 1 or 2) have more chance to survive","b5efc0c4":"## 2.6 Variable Encoding","99b7f6a3":"## 2.5 Create new variables","5dbb53c6":"### Lets check correlation","1849f5b6":"### One-Hot Encoding","f3cf3057":"Nice! we have fixed it up!","56776cf8":"### SibSP","7eb679d2":"As we saw, Fare is a skewed variable so we can transform it with log function to adapt the values"}}