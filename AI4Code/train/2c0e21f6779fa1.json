{"cell_type":{"6d88fe65":"code","f63ad453":"code","ec0c00ca":"code","c42fcc8e":"code","7d0a17b5":"code","1f86086a":"code","67833265":"code","3760c870":"code","fbb2b5ca":"code","3f313999":"code","1634b3f2":"code","b5e62d4c":"code","0311af87":"code","13c2e39a":"markdown","1274c9cd":"markdown","c7964e9e":"markdown","6de20e18":"markdown","2fd224f1":"markdown","2608e402":"markdown","f4915cbc":"markdown","1799e47b":"markdown","b14fdabb":"markdown","1ddf99c4":"markdown","53751ab1":"markdown","53bf1f7d":"markdown"},"source":{"6d88fe65":"import time, math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","f63ad453":"df_train = pd.read_csv(\"..\/input\/da517-2021-the4\/train.csv\")\ndf_train.head()","ec0c00ca":"user_ids = df_train.userID.unique()\nmovie_ids = df_train.movieID.unique()\n\ndf_train_reindexed = df_train.copy()\n\n# need to re-make user ids and movie ids since they are not sequential\nnew_user_id_map = {}\ni = 0\nfor old in user_ids:\n    new_user_id_map[old] = i\n    i += 1\n\nnew_movie_id_map = {}\nj = 0\nfor old in movie_ids:\n    new_movie_id_map[old] = j\n    j += 1\n    \n# Setting new ids\ndf_train_reindexed.loc[:, 'userID'] = df_train_reindexed.apply(\n    lambda row: new_user_id_map[row.userID], axis=1)\ndf_train_reindexed.loc[:, 'movieID'] = df_train_reindexed.apply(\n    lambda row: new_movie_id_map[row.movieID], axis=1)\n\ndf_train_reindexed.head()","c42fcc8e":"# a dictionary to tell us which users have rated which movies\nuser2movie = df_train_reindexed.groupby('userID').movieID.agg(list).to_dict()\n\n# a dictionary to tell us which movies have been rated by which users\nmovie2user = df_train_reindexed.groupby('movieID').userID.agg(list).to_dict()\n\n# a dictionary to look up ratings (TRAIN)\nuser_movie_keys = zip(df_train_reindexed.userID, df_train_reindexed.movieID)\nusermovie2rating = pd.Series(\n    df_train_reindexed.rating.values, index=user_movie_keys).to_dict()","7d0a17b5":"N = np.max(list(user2movie.keys())) + 1\nM = np.max(list(movie2user.keys())) + 1\nprint(\"N:\", N, \"M:\", M)","1f86086a":"# initialize variables\nK = 10 # latent dimensionality\nW = np.random.randn(N, K)\nb = np.zeros(N)\nU = np.random.randn(M, K)\nc = np.zeros(M)\nmu = np.mean(list(usermovie2rating.values()))","67833265":"def get_loss(d):\n    # d: (user_id, movie_id) -> rating\n    N = float(len(d))\n    mse = 0\n    for k, r in d.items():\n        i, j = k\n        # p: prediction[i, j] = W[i].dot(U[j]) + b[i] + c.T[j] + mu\n        p = W[i].dot(U[j]) + b[i] + c[j] + mu\n        mse += np.square(p - r)\n    # return Root Mean Square Error\n    return math.sqrt(mse \/ N)","3760c870":"# train the parameters\nepochs = 25\nreg =10. # regularization penalty\ntrain_losses = []\nt1 = time.time()\nfor epoch in range(epochs):\n    print(f\"Running Epoch: {epoch}\")\n    \n    # loop through each user to update W and b\n    for i in range(N):\n        # for W\n        matrix = np.eye(K) * reg\n        vector = np.zeros(K)\n\n        # for b\n        bi = 0\n        for j in user2movie[i]:\n            r = usermovie2rating[(i,j)]\n            matrix += np.outer(U[j], U[j])\n            vector += (r - b[i] - c[j] - mu)*U[j]\n            bi += (r - W[i].dot(U[j]) - c[j] - mu)\n\n        # set the updates\n        W[i] = np.linalg.solve(matrix, vector)\n        b[i] = bi \/ (len(user2movie[i]) + reg)\n\n    # loop through each movie to update U and c\n    for j in range(M):\n        # for U\n        matrix = np.eye(K) * reg\n        vector = np.zeros(K)\n\n        # for c\n        cj = 0\n        try:\n            for i in movie2user[j]:\n                r = usermovie2rating[(i,j)]\n                matrix += np.outer(W[i], W[i])\n                vector += (r - b[i] - c[j] - mu)*W[i]\n                cj += (r - W[i].dot(U[j]) - b[i] - mu)\n\n            # set the updates\n            U[j] = np.linalg.solve(matrix, vector)\n            c[j] = cj \/ (len(movie2user[j]) + reg)\n\n        except KeyError:\n            # possible not to have any ratings for a movie\n            pass\n\n    # store train loss\n    train_losses.append(get_loss(usermovie2rating))\n\n    print(f\"train loss for epoch {epoch}: {train_losses[-1]}\")\n\nt2 = time.time()\nprint(f\"It took {str(t2 - t1)} to run the epochs\")","fbb2b5ca":"# plot losses\nplt.plot(train_losses, label=\"train loss\")\nplt.legend()\nplt.show()","3f313999":"def predict(i, j):\n    prediction = W[i].dot(U[j]) + b[i] + c.T[j] + mu\n    prediction = min(5, prediction) # limit max rating to 5\n    prediction = max(1, prediction) # limit min rating to 1\n    return prediction","1634b3f2":"# here refering the original indexes is very important!\nscore = predict(new_user_id_map[629], new_movie_id_map[2683])\nprint(\"score (u,i) is\",score)","b5e62d4c":"data_test = pd.read_csv(\"..\/input\/da517-2021-the4\/test_without_labels.csv\")\ndata_test['rating'] = data_test['IDs'].apply(\n    lambda x: predict(\n        new_user_id_map[int(x.split(\"_\")[0])], \n        new_movie_id_map[int(x.split(\"_\")[1])]))\ndata_test.head()","0311af87":"# Save result for submission\ndata_test.to_csv('submission_result.csv', index=False)","13c2e39a":"#### Conclusion:\n\n- Kaggle Score: 0.83648","1274c9cd":"### Predict Test Data File","c7964e9e":"### Data Loading","6de20e18":"### Preprocess Data","2fd224f1":"### Strategy\n\n- Simply apply the equations as is, iteratively\n- Solution for W depends on U, Solution for U depends on W. By the way the order does not matter.\n- Solving for W is just Ax=b, which we know how to solve np.linalg.solve(A, b)","2608e402":"### Import Libraries","f4915cbc":"### Build The Model","1799e47b":"### Build Dictionaries for the frequently asked 3 questions","b14fdabb":"### Test on an individual sample","1ddf99c4":"### Future Improvements for the notebook\n\n- Split train, test to apply Gridsearch CV to find best regularization penalty, latent combination\n- I used regularization penalty fixed as 10 by infering from my multiple Kaggle scores","53751ab1":"#### The Objective\n\n\\begin{array}{c}\nJ=\\sum_{i, j \\in \\Omega}\\left(r_{i j}-\\hat{r}_{i j}\\right)^{2} \\\\\n\\hat{r}_{i j}=w_{i}^{T} u_{j}+b_{i}+c_{j}+\\mu \\\\\n\\end{array}\n\n#### Solving for W\n- Differentiate $w_{i}$\n\n\\begin{array}{l}\n\\frac{\\partial J}{\\partial w_{i}}=2 \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-w_{i}^{T} u_{j}-b_{i}-c_{j}-\\mu\\right)\\left(-u_{j}\\right)=0\n\\end{array}\n\n- Move other terms to right hand side\n\\begin{array}{l}\n\\sum_{j \\in \\Psi_{i}}\\left(w_{i}^{T} u_{j}\\right) u_{j}=\\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-b_{i}-c_{j}-\\mu\\right) u_{j}\n\\end{array}\n\n- Use the trick\n\\begin{array}{l}\nw_{i}=\\left(\\sum_{j \\in \\Psi_{i}} u_{i} u_{i}^{T}\\right)^{-1} \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-b_{i}-c_{j}-\\mu\\right) u_{i}\n\\end{array}\n\n#### Solving for U\n- Since the equations $w_{i}$ and $u_{j}$ are symmetric, use the symmetry argument\n\n\\begin{array}{l}\nu_{j}=\\left(\\sum_{i \\in \\Omega_{j}} w_{i} w_{i}^{T}\\right)^{-1} \\sum_{i \\in \\Omega_{j}}\\left(r_{i j}-b_{i}-c_{j}-\\mu\\right) w_{i}\n\\end{array}\n\n#### Solving for b\n- $b_{i}$ is the average deviation between target and modeling prediction, if the prediction did not involve $b_{i}$\n\n- $b_{i}$ is exactly how much you need to add to the model prediction without $b_{i}$ !\n\n\\begin{array}{c}\n\\frac{\\partial J}{\\partial b_{i}}=2 \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-w_{i}^{T} u_{j}-b_{i}-c_{j}-\\mu\\right)(-1)=0 \\\\\nb_{i}=\\frac{1}{|\\Psi_{i}|} \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-w_{i}^{T} u_{j}-c_{j}-\\mu\\right)\n\\end{array}\n\n#### Solving for c\n- We can similarly derive the update for $c_{j}$ by taking the exact same steps\n\n- Deriavative is nearly identical because the derivative of $c_{j}$ by itself is just one. The only difference here is what we sum over which is now all the users who rated movie j\n\n\\begin{array}{c}\n\\frac{\\partial J}{\\partial c_{j}}=2 \\sum_{i \\in \\Omega_{j}}\\left(r_{i j}-w_{i}^{T} u_{j}-b_{i}-c_{j}-\\mu\\right)(-1)=0 \\\\\nc_{j}=\\frac{1}{|\\Omega_{j}|} \\sum_{i \\in \\Omega_{j}}\\left(r_{i j}-w_{i}^{T} u_{j}-b_{i}-\\mu\\right)\n\\end{array}\n\n#### SUMMARY\n- Don't need to update global average (just calculate it directly from train data)\n\n\\begin{array}{c}\nw_{i}=\\left(\\sum_{j \\in \\Psi_{i}} u_{i} u_{i}^{T}\\right)^{-1} \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-b_{i}-c_{j}-\\mu\\right) u_{i} \\\\\nu_{j}=\\left(\\sum_{i \\in \\Omega_{j}} w_{i} w_{i}^{T}\\right)^{-1} \\sum_{i \\in \\Omega_{j}}\\left(r_{i j}-b_{i}-c_{j}-\\mu\\right) w_{i} \\\\\nb_{i}=\\frac{1}{|\\Psi_{i}|} \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-w_{i}^{T} u_{j}-c_{j}-\\mu\\right) \\\\\nc_{j}=\\frac{1}{|\\Omega_{j}|} \\sum_{i \\in \\Omega_{j}}\\left(r_{i j}-w_{i}^{T} u_{j}-b_{i}-\\mu\\right)\n\\end{array}\n\n#### REGULARIZATION\nA technique to prevent overfitting and help generalization in Linear Regression:\n\n$\\|*\\|_{f}$ is called the **Frobenius norm**\n\n- Model: $\\hat{y}=w^{T} x$\n\n- Objective: $J=\\sum_{i=1}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\lambda\\|w\\|_{2}^{2}$\n\n- Solution: $w=\\left(\\lambda I+X^{T} X\\right)^{-1} X^{T} y$\n\nApplied in our case:\n\n\\begin{equation}\n\\begin{array}{l}\nw_{i}=\\left(\\sum_{j \\in \\Psi_{i}} u_{j} u_{j}^{T}+\\lambda I\\right)^{-1} \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-b_{i}-c_{j}-\\mu\\right) u_{j} \\\\\nu_{j}=\\left(\\sum_{i \\in \\Omega_{j}} w_{i} w_{i}^{T}+\\lambda I\\right)^{-1} \\sum_{i \\in \\Omega_{j}}\\left(r_{i j}-b_{i}-c_{j}-\\mu\\right) w_{i} \\\\\nb_{i}=\\frac{1}{\\left|\\Psi_{i}\\right|+\\lambda} \\sum_{j \\in \\Psi_{i}}\\left(r_{i j}-w_{i}^{T} u_{j}-c_{j}-\\mu\\right) \\\\\nc_{j}=\\frac{1}{\\left|\\Omega_{j}\\right|+\\lambda} \\sum_{i \\in \\Omega_{j}}\\left(r_{i j}-w_{i}^{T} u_{j}-b_{i}-\\mu\\right)\n\\end{array}\n\\end{equation}\n\n","53bf1f7d":"##  LSA (Latent Semantic Analysis) method by Matrix Factorization"}}