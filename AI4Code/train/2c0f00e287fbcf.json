{"cell_type":{"8c95f000":"code","fe019d02":"code","d87eb4cd":"code","b5b0c609":"code","287ba0ad":"code","c456ad7c":"code","f1e7507f":"code","f6ff75e7":"code","3a5a2264":"markdown","d77b73f2":"markdown","a7394ca5":"markdown","aa06aab5":"markdown","51ba6ecb":"markdown","9be675b3":"markdown","36f92e03":"markdown"},"source":{"8c95f000":"import scipy\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression","fe019d02":"D0 = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat-ii\/train.csv\", index_col=\"id\")\nD_test = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat-ii\/test.csv\", index_col=\"id\")\n\ny_train = D0[\"target\"]\nD = D0.drop(columns=\"target\")\ntest_ids = D_test.index\n\nD_all = pd.concat([D, D_test])\nnum_train = len(D)\n\nprint(f\"D_all.shape = {D_all.shape}\")        ","d87eb4cd":"for col in D.columns.difference([\"id\"]):\n    train_vals = set(D[col].dropna().unique())\n    test_vals = set(D_test[col].dropna().unique())\n\n    xor_cat_vals = train_vals ^ test_vals\n    if xor_cat_vals:\n        print(f\"Replacing {len(xor_cat_vals)} values in {col}, {xor_cat_vals}\")\n        D_all.loc[D_all[col].isin(xor_cat_vals), col] = \"xor\"","b5b0c609":"ord_maps = {\n    \"ord_0\": {val: i for i, val in enumerate([1, 2, 3])},\n    \"ord_1\": {\n        val: i\n        for i, val in enumerate(\n            [\"Novice\", \"Contributor\", \"Expert\", \"Master\", \"Grandmaster\"]\n        )\n    },\n    \"ord_2\": {\n        val: i\n        for i, val in enumerate(\n            [\"Freezing\", \"Cold\", \"Warm\", \"Hot\", \"Boiling Hot\", \"Lava Hot\"]\n        )\n    },\n    **{col: {val: i for i, val in enumerate(sorted(D_all[col].dropna().unique()))} for col in [\"ord_3\", \"ord_4\", \"ord_5\", \"day\", \"month\"]},\n}","287ba0ad":"oh_cols = D_all.columns.difference(ord_maps.keys() - {\"day\", \"month\"})\n\nprint(f\"OneHot encoding {len(oh_cols)} columns\")\n\none_hot = pd.get_dummies(\n    D_all[oh_cols],\n    columns=oh_cols,\n    drop_first=True,\n    dummy_na=True,\n    sparse=True,\n    dtype=\"int8\",\n).sparse.to_coo()","c456ad7c":"ord_cols = pd.concat([D_all[col].map(ord_map).fillna(max(ord_map.values())\/\/2).astype(\"float32\") for col, ord_map in ord_maps.items()], axis=1)\nord_cols \/= ord_cols.max()  # for convergence\n\nord_cols_sqr = 4*(ord_cols - 0.5)**2","f1e7507f":"X = scipy.sparse.hstack([one_hot, ord_cols, ord_cols_sqr]).tocsr()\nprint(f\"X.shape = {X.shape}\")\n\nX_train = X[:num_train]\nX_test = X[num_train:]","f6ff75e7":"clf=LogisticRegression(C=0.05, solver=\"lbfgs\", max_iter=5000)\n\nclf.fit(X_train, y_train)\n\npred = clf.predict_proba(X_test)[:, 1]\n\npd.DataFrame({\"id\": test_ids, \"target\": pred}).to_csv(\"submission.csv\", index=False)","3a5a2264":"# Ordinal encoding","d77b73f2":"# Info for ordinal encoding","a7394ca5":"# OneHot encoding","aa06aab5":"# Combine data","51ba6ecb":"# Map value in train xor test","9be675b3":"# Load data","36f92e03":"# Make submission"}}