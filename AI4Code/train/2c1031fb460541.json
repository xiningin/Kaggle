{"cell_type":{"8f6d9c4a":"code","d825ea2d":"code","7cd00ce7":"code","2b0460e3":"code","0509cef9":"code","6579c991":"code","3ef2d5dc":"code","6b9cbf14":"code","dac1c839":"code","8720b432":"code","e14fc180":"code","d1e25ae0":"code","0b6204fd":"code","9f1c607c":"code","609bb3f6":"code","3a68e322":"code","94d0d9fe":"code","8f8c4d39":"code","8f374268":"code","5c828031":"code","34bb246e":"code","b9701f9e":"code","c73b0106":"code","a0890759":"code","26216b23":"code","ab82acb5":"code","939f1b88":"markdown","30224fcf":"markdown","179c9818":"markdown","f1ece9d2":"markdown","5d5e6caf":"markdown"},"source":{"8f6d9c4a":"# Importing all necessary Python Libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","d825ea2d":"# Uploading the training and testing datasets from Kaggle.\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","7cd00ce7":"train_data.info()","2b0460e3":"# Checking for missing values.\ntrain_data.isnull().sum()","0509cef9":"# Removing the Cabin feature due to its extensive missing values.\ntrain_data.drop('Cabin', axis=1, inplace=True)","6579c991":"# Replacing the missing embarked values with the value that appears the most frequently.\ntrain_data[\"Embarked\"].fillna(train_data['Embarked'].value_counts().idxmax(), inplace=True)","3ef2d5dc":"# Replacing the missing age values with the median age value.\ntrain_data[\"Age\"].fillna(train_data[\"Age\"].median(skipna=True), inplace=True)","6b9cbf14":"train_data.isnull().sum()","dac1c839":"train_data.head()","8720b432":"# Encoding the sex values.\ntrain_data['Sex'].replace(\"female\", 0,inplace=True)\ntrain_data['Sex'].replace(\"male\", 1,inplace=True)","e14fc180":"# Encoding the embarked values.\ntrain_data['Embarked'].replace(\"S\", 0,inplace=True)\ntrain_data['Embarked'].replace(\"C\", 1,inplace=True)\ntrain_data['Embarked'].replace(\"Q\", 2,inplace=True)","d1e25ae0":"train_data.dtypes","0b6204fd":"test_data.isnull().sum()","9f1c607c":"test_data[\"Age\"].fillna(test_data[\"Age\"].median(skipna=True), inplace=True)\ntest_data[\"Fare\"].fillna(test_data[\"Fare\"].median(skipna=True), inplace=True)\ntest_data.drop('Cabin', axis=1, inplace=True)","609bb3f6":"test_data['Sex'].replace(\"female\", 0,inplace=True)\ntest_data['Sex'].replace(\"male\", 1,inplace=True)","3a68e322":"test_data['Embarked'].replace(\"S\", 0,inplace=True)\ntest_data['Embarked'].replace(\"C\", 1,inplace=True)\ntest_data['Embarked'].replace(\"Q\", 2,inplace=True)","94d0d9fe":"test_data.dtypes","8f8c4d39":"train_data.shape","8f374268":"test_data.shape","5c828031":"train_data.head()","34bb246e":"outcome_data = train_data[\"Survived\"]\ntrain_data.drop([\"Survived\", \"Ticket\", \"Name\", \"PassengerId\"], axis=1, inplace=True)\ntest_data.drop([\"Name\",\"PassengerId\",\"Ticket\"], axis=1, inplace=True)","b9701f9e":"from sklearn.model_selection import train_test_split\n\n# Selecting the features and the outcome.\nX = train_data.values\ny = outcome_data.values\n\n# Splitting the data into training and test sets.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)","c73b0106":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report","a0890759":"# Initializing a RandomForestClassifier.\nrf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=4, max_features='auto',\n                       max_leaf_nodes=5, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=15,\n                       min_weight_fraction_leaf=0.0, n_estimators=350,\n                       n_jobs=None, oob_score=False, random_state=1\n                            , verbose=0,\n                       warm_start=False)\n\nrf.fit(X_train, y_train)\n\n# Predicting from the test set.\ny_pred = rf.predict(X_test)\n\n# Predicting from the train set.\ny_pred_train = rf.predict(X_train)\n\n# Printing the accuracy with accuracy_score function.\nprint(\"Accuracy Train: \", accuracy_score(y_train, y_pred_train))\n\n# Printing the accuracy with accuracy_score function.\nprint(\"Accuracy Test: \", accuracy_score(y_test, y_pred))\n\n# Printing the confusion matrix.\nprint(\"\\nConfusion Matrix\\n\")\nprint(confusion_matrix(y_test, y_pred))","26216b23":"last_clf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=4, max_features='auto',\n                       max_leaf_nodes=5, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=15,\n                       min_weight_fraction_leaf=0.0, n_estimators=350,\n                       n_jobs=None, oob_score=True, random_state=1, verbose=0,\n                       warm_start=False)\n\nlast_clf.fit(train_data, outcome_data)\nprint(\"%.4f\" % last_clf.oob_score_)","ab82acb5":"ids = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")[[\"PassengerId\"]].values\n\n# Making predictions.\npredictions = last_clf.predict(test_data.values)\n\n# Printing the predictions.\nprint(predictions)\n\n# Creating a dictionary with passenger ids and predictions.\ndf = {'PassengerId': ids.ravel(), 'Survived':predictions}\n\n# Creating a DataFrame named submission.\nsubmission = pd.DataFrame(df)\n\n# Displaying the first five rows of submission.\ndisplay(submission.head())\n\n# Saving the file.\nsubmission.to_csv(\"submission.csv\", index=False)","939f1b88":"# Data","30224fcf":"# Random Forest Classification Predictions","179c9818":"# Random Forest Classification","f1ece9d2":"In this notebook I utilize a simple random forest classification algorithm to predict the passengers that survived the titatnic's crash and those who didn't.","5d5e6caf":"# Importing Libraries"}}