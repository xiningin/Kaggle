{"cell_type":{"0fa356c3":"code","853ae542":"code","e00d420f":"code","c189bf01":"code","53d61950":"code","01170c33":"code","7aee6e63":"code","cc4bbd7b":"code","b17892c7":"code","1f7c5436":"code","b85c49c9":"code","c1ed0541":"code","aa79df83":"code","31d037d2":"code","2d016b54":"code","43b719d5":"code","eb31e1c3":"markdown","345762c3":"markdown","8d592a6a":"markdown","48225efe":"markdown","ce6bd074":"markdown","d50af729":"markdown"},"source":{"0fa356c3":"import pickle\nimport string\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom nltk.util import ngrams","853ae542":"PATH_TO_DATA = Path('..\/input\/title-generation\/')","e00d420f":"train_df = pd.read_csv(PATH_TO_DATA \/ 'train.csv')","c189bf01":"test_df = pd.read_csv(PATH_TO_DATA \/ 'test.csv')","53d61950":"len(train_df), len(test_df)","01170c33":"train_df.drop_duplicates(inplace=True)\nlen(train_df)","7aee6e63":"train_df.head(2)","cc4bbd7b":"test_df.head(2)","b17892c7":"train_abstracts = train_df['abstract'].str.lower()\ntest_abstracts = test_df['abstract'].str.lower()","1f7c5436":"duplicate_ids = {}\n\nfor i, abstract in tqdm(enumerate(test_abstracts)):\n    \n    # a bit clumpsy, but pd.Series.str.contrains is not working for me\n    inclusion_series = (abstract == train_abstracts)\n    if inclusion_series.sum():\n        test_id = i\n        train_id = inclusion_series.idxmax()\n        duplicate_ids[test_id] =  train_id\n        \nlen(duplicate_ids)","b85c49c9":"train_df['title'].apply(lambda s: len(s.split())).describe()","c1ed0541":"def extract_first_sentence(text, max_words=40):\n    return \" \".join(text.strip().split('.')[0].split()[:max_words])","aa79df83":"predicted_titles = test_df['abstract'].apply(extract_first_sentence)","31d037d2":"for test_id, train_id in duplicate_ids.items():\n    predicted_titles.loc[test_id] = train_df.loc[train_id, 'title']","2d016b54":"submission_df = pd.DataFrame({'abstract': test_df['abstract'].values, \n                              'title': predicted_titles.values})\nsubmission_df.to_csv('predicted_titles.csv', index=False)","43b719d5":"def generate_csv(input_file='predicted_titles.csv',\n                 output_file='submission.csv',\n                 voc_file='..\/input\/title-generation\/vocs.pkl'):\n    '''\n    Generates file in format required for submitting result to Kaggle\n    \n    Parameters:\n        input_file (str) : path to csv file with your predicted titles.\n                           Should have two fields: abstract and title\n        output_file (str) : path to output submission file\n        voc_file (str) : path to voc.pkl file\n    '''\n    data = pd.read_csv(input_file)\n    with open(voc_file, 'rb') as voc_file:\n        vocs = pickle.load(voc_file)\n\n    with open(output_file, 'w') as res_file:\n        res_file.write('Id,Predict\\n')\n        \n    output_idx = 0\n    for row_idx, row in data.iterrows():\n        trg = row['title']\n        trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n        trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n        \n        VOCAB_stoi = vocs[row_idx]\n        trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n        trg_vec = np.zeros(len(VOCAB_stoi))    \n\n        for word in trg_intersection:\n            trg_vec[VOCAB_stoi[word]] = 1\n\n        with open(output_file, 'a') as res_file:\n            for is_word in trg_vec:\n                res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n                output_idx += 1\n\n\ngenerate_csv()","eb31e1c3":"**Replace some titles with titles for duplicate papers**","345762c3":"Finding duplicates","8d592a6a":"There's a subtle fault in the arrangement of this competition - 431 papers from the test set are also found in the training set. \n\nSo a dumb baseline looks like this:\n - a title of a duplicate paper form the training set if a duplicate is found\n - first sentence from the abstract otherwise (but no more than 40 words)","48225efe":"Let's pick up the first sentence from the abstract as a hypothesis for a title. But no more than 40 words.","ce6bd074":"Removing duplicates in the training set.","d50af729":"## Submission\n\nReusing code form the published [LSTM baseline](https:\/\/www.kaggle.com\/anastasiayanina\/lstm-baseline)."}}