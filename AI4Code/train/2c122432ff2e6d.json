{"cell_type":{"ba1437dd":"code","50875e98":"code","807a4bea":"code","1582effb":"code","b06fc857":"code","bb8c2032":"code","2eb2e026":"code","1bfc184f":"code","587ff7dc":"code","545b9940":"code","f8a98502":"code","7db594c9":"code","e8666280":"code","e6428594":"code","d3293098":"code","9c2fe69b":"code","d66bb2cb":"code","236a9cc6":"code","918d05a4":"code","4d1c4901":"code","fed355e0":"code","2aafbfca":"code","a26ab686":"code","23fbebc4":"code","39925de0":"code","4955b48d":"code","cbe433e0":"code","de956d2c":"code","40d72168":"code","74c596b2":"code","53044965":"code","ef1cbb62":"code","25628c11":"code","05e52aef":"code","018d5fe2":"code","9ccc1bfe":"code","886916b6":"markdown","a095cc3f":"markdown","2a970bfe":"markdown","e88b16ae":"markdown","d69be1e1":"markdown","00522035":"markdown","ec2221dc":"markdown","e34912d6":"markdown","f5c5c06b":"markdown","8fded75c":"markdown","d016deca":"markdown","7adfd710":"markdown","f04048a7":"markdown","aea75f09":"markdown","e94097b9":"markdown","c3040f29":"markdown"},"source":{"ba1437dd":"# Import required libraries\nimport pandas as pd \nimport numpy as np\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression","50875e98":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')","807a4bea":"test_df.head()","1582effb":"train_df.head()","b06fc857":"print(train_df.columns.values)","bb8c2032":"train_df.info()","2eb2e026":"train_df.describe()","1bfc184f":"train_df.shape","587ff7dc":"# All numeric (float and int) variables in the dataset\ntrain_df_numeric = train_df.select_dtypes(include=['float64', 'int64'])\ntrain_df_numeric.head()","545b9940":"# Correlation matrix\ncor = train_df_numeric.corr()\ncor","f8a98502":"# Figure size\nplt.figure(figsize=(16,8))\n\n# Heatmap\nsns.heatmap(cor, cmap=\"YlGnBu\", annot=True)\nplt.show()","7db594c9":"print(train_df.info())","e8666280":"full_dataset = [train_df, test_df]","e6428594":"# Sex is a binary value column.\n# Hence making female as 0 and male as 1\nsex_dict = {\"female\":0, \"male\":1}\nfor data_df in full_dataset:\n    data_df['Sex'] = data_df['Sex'].apply(lambda x:sex_dict[x])","d3293098":"for data_df in full_dataset:\n    data_df['Title']  = data_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    data_df['Title'] = data_df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Royalty')\n\n    data_df['Title'] = data_df['Title'].replace('Mlle', 'Miss')\n    data_df['Title'] = data_df['Title'].replace('Ms', 'Miss')\n    data_df['Title'] = data_df['Title'].replace('Mme', 'Mrs')\n\n    \ntitle_dict = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\": 5}\nfor data_df in full_dataset: \n    data_df['Title'] = data_df['Title'].apply(lambda x: title_dict[x])\n    data_df['Title'] = data_df['Title'].fillna(0)","9c2fe69b":"def AgeGroup(age):\n    if(age <= 16):\n        return 0 \n    elif age > 16 and age <= 32:\n        return 1\n    elif age>32 and age <=48:\n        return 2 \n    elif age>48 and age <= 64:\n        return 3\n    else:\n        return 4\n    \nfor data_df in full_dataset:\n    age_avg = data_df['Age'].mean()\n    age_std = data_df['Age'].std()\n    age_null_count = data_df['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    data_df['Age'][np.isnan(data_df['Age'])] = age_null_random_list\n    data_df['Age'] = data_df['Age'].astype(int)\n    data_df['AgeGoup'] = data_df['Age'].apply(AgeGroup)","d66bb2cb":"def Alone(familysize):\n    if familysize ==1:\n        return 1 \n    else:\n        return 0\n\nfor data_df in full_dataset:\n    data_df['Family_size'] = data_df['SibSp'] + data_df['Parch'] + 1\n    data_df['IsAlone'] = data_df['Family_size'].apply(Alone)","236a9cc6":"embarked= {'S': 0, 'C': 1, 'Q': 2}\nfor data_df in full_dataset:\n    data_df['Embarked'] = data_df['Embarked'].fillna('S')\n    data_df['Embarked'] = data_df['Embarked'].apply(lambda x: embarked[x])","918d05a4":"def Cabin(cabin):\n    if type(cabin) == str:\n        return 1\n    else:\n        return 0\n    \nfor data_df in full_dataset:\n    data_df['HasCabin'] = data_df['Cabin'].apply(Cabin)","4d1c4901":"def FareGroup(fare):\n    if fare <= 7.91:\n        return 0;\n    elif fare >7.91 and fare <=14.454:\n        return 1\n    elif fare >14.454 and fare <=31:\n        return 2\n    else:\n        return 3\n\nfor data_df in full_dataset:\n    data_df['Fare'] = data_df['Fare'].fillna(data_df['Fare'].median())\n    data_df['FareGroup'] = data_df['Fare'].apply(FareGroup)","fed355e0":"train_df.head()","2aafbfca":"for data_df in full_dataset:\n    data_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'],axis=1, inplace = True)","a26ab686":"full_dataset","23fbebc4":"train_df.head()","39925de0":"# For training and testing purposes, split train dataset into two df\n# Importing test_train_split from sklearn library\nfrom sklearn.model_selection import train_test_split","4955b48d":"# Putting feature variable to X\nX = train_df.drop('Survived',axis=1)\n\n# Putting response variable to y\ny = train_df['Survived']\n\n# Splitting the data into train and test\nx_train_training, x_train_testing, y_train_training, y_train_testing = train_test_split(X, y, test_size=0.30, random_state=101)","cbe433e0":"#x_train = train_df.drop(\"Survived\", axis=1)\n#y_train = train_df[\"Survived\"]","de956d2c":"logreg = LogisticRegression()\nlogreg.fit(x_train_training, y_train_training)\ny_pred = logreg.predict(test_df)\nacc_log = round(logreg.score(x_train_training, y_train_training) * 100, 2)\nacc_log","40d72168":"# Importing random forest classifier from sklearn library\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Running the random forest with default parameters.\nrfc = RandomForestClassifier()","74c596b2":"# fit\nrfc.fit(x_train_training,y_train_training)","53044965":"# Making predictions\nacc_log = round(rfc.score(x_train_training, y_train_training) * 100, 2)\nacc_log","ef1cbb62":"# Making predictions\npredictions = rfc.predict(x_train_training)\nprint( np.mean(predictions == y_train_training))","25628c11":"# Making predictions\npredictions = rfc.predict(x_train_testing)\nprint( np.mean(predictions == y_train_testing))","05e52aef":"y_pred = rfc.predict(test_df)","018d5fe2":"#test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n#submission = pd.DataFrame({\n#        \"PassengerId\": test_data[\"PassengerId\"],\n#        \"Survived\": y_pred\n#    })\n#submission.to_csv('my_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","9ccc1bfe":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nsubmission.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","886916b6":"### **Step 4 : Model Building **","a095cc3f":"### **Import required libraries**","2a970bfe":"### ** Step 3 : Data Cleaning **","e88b16ae":"### **Step 5 : Predictions **","d69be1e1":"### **Age**\n\nThis column has multiple null values.\n\nFilling the null values and classifying the age based on the group.","00522035":"The operations needs to be performed on both training and testing data sets. Hence merging both data set to get a new dataset.","ec2221dc":"There are some null values in the dataset those needs to be treated before building the model.","e34912d6":"### **Step 1 : Acquiring Data**","f5c5c06b":"We have treated the null values and simultaneously converted the categorical columns.\n","8fded75c":"Now dropping the columns for which dummy variables are created.","d016deca":"### **Embarked**\n\nFilling the embarked column with mostly occuring values (S)","7adfd710":"### **Step 2 : EDA on the Data**","f04048a7":"**Logistic Regression**","aea75f09":"#### **Name**\n\nName column contains titles.\nSeparating the titles from name and then converting them.","e94097b9":"### **SibSp and Parch**\n\nWith these features we can create a new feature called Family Size which will be helpful in checking survival ratings.","c3040f29":"**Random Forest**"}}