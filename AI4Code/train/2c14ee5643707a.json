{"cell_type":{"4f5020fe":"code","90cf00f4":"code","090c2ade":"code","4a5d9f07":"code","560512db":"code","3c7e04cb":"code","57070fe0":"code","1bc1e7cc":"code","161eed4d":"code","61903f68":"code","c72605ba":"code","ce19baeb":"code","f7031d1c":"code","9ce9f474":"code","02f561f3":"code","c5a6b890":"markdown","6f44325e":"markdown","9904f0fd":"markdown","3b94b188":"markdown","e98647eb":"markdown","8483eb63":"markdown","d8a4f7c6":"markdown","2dd4ae9a":"markdown","957cb3e1":"markdown"},"source":{"4f5020fe":"!pip install alibi","90cf00f4":"import numpy as np\nimport os\nimport tensorflow as tf\ntf.get_logger().setLevel(40) # suppress deprecation messages\ntf.compat.v1.disable_v2_behavior()\nfrom tensorflow.keras.layers import Activation, Conv2D, Dense, Dropout\nfrom tensorflow.keras.layers import Flatten, Input, Reshape, MaxPooling2D\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import to_categorical\nfrom alibi.explainers import IntegratedGradients\nimport matplotlib.pyplot as plt\nprint('TF version: ', tf.__version__)\nprint('Eager execution enabled: ', tf.executing_eagerly()) # True\nfrom alibi.explainers import CEM","090c2ade":"train, test = tf.keras.datasets.fashion_mnist.load_data()\nX_train, y_train = train\nX_test, y_test = test\ntest_labels = y_test.copy()\ntrain_labels = y_train.copy()\n\nX_train = X_train.reshape(-1, 28, 28, 1).astype('float64') \/ 255\nX_test = X_test.reshape(-1, 28, 28, 1).astype('float64') \/ 255\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","4a5d9f07":"load_fashion_mnist_model = False\nsave_model = True","560512db":"filepath = '.\/model_mnist\/'  # change to directory where model is saved\nif load_fashion_mnist_model:\n    model = tf.keras.models.load_model(os.path.join(filepath, 'model.h5'))\nelse:\n    # define model\n    inputs = Input(shape=(X_train.shape[1:]), dtype=tf.float32)\n    x = Conv2D(64, 2, padding='same', activation='relu')(inputs)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(.3)(x)\n\n    x = Conv2D(32, 2, padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(.3)(x)\n\n    x = Flatten()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(.5)(x)\n    logits = Dense(10, name='logits')(x)\n    outputs = Activation('softmax', name='softmax')(logits)\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    # train model\n    model.fit(X_train,\n              y_train,\n              epochs=6,\n              batch_size=256,\n              verbose=1,\n              validation_data=(X_test, y_test)\n              )\n    if save_model:\n        if not os.path.exists(filepath):\n            os.makedirs(filepath)\n        model.save(os.path.join(filepath, 'model.h5'))","3c7e04cb":"model = load_model('.\/model_mnist\/model.h5')\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test accuracy: ', score[1])","57070fe0":"idx = 11\nX = X_test[idx].reshape((1,) + X_test[idx].shape)\nprint('Prediction on instance to be explained: {}'.format([np.argmax(model.predict(X))]))\nprint('Prediction probabilities for each class on the instance: {}'.format(model.predict(X)))","1bc1e7cc":"mode = 'PN' \nshape = (1,) + X_train.shape[1:]  \nkappa = .2 \n            \n            \nbeta = .1  \nc_init = 10. \nc_steps = 10\nmax_iterations = 1000  \nfeature_range = (X_train.min(axis=0).reshape(shape)-.1,  \n                 X_train.max(axis=0).reshape(shape)+.1)  \nclip = (-1000.,1000.)  \nlr_init = 1e-2  ","161eed4d":"lr = load_model('.\/model_mnist\/model.h5')\n\n# initialize CEM explainer and explain instance\ncem = CEM(lr, mode, shape, kappa=kappa, beta=beta, feature_range=feature_range,\n          max_iterations=max_iterations, c_init=c_init, c_steps=c_steps,\n          learning_rate_init=lr_init, clip=clip)\ncem.fit(X_train, no_info_type='median')  \nexplanation = cem.explain(X, verbose=False)","61903f68":"print('Predicted class: {}'.format([explanation.X_pred]))\nplt.imshow(explanation.X.reshape(28, 28));","c72605ba":"print('Pertinent negative prediction: {}'.format(explanation.PN_pred))\nplt.imshow(explanation.PN.reshape(28, 28));","ce19baeb":"mode = 'PP'","f7031d1c":"# define model\nlr = load_model('.\/model_mnist\/model.h5')\n\n# initialize CEM explainer and explain instance\ncem = CEM(lr, mode, shape, kappa=kappa, beta=beta, feature_range=feature_range,\n          max_iterations=max_iterations, c_init=c_init, c_steps=c_steps,\n          learning_rate_init=lr_init, clip=clip)\ncem.fit(X_train, no_info_type='median')\nexplanation = cem.explain(X, verbose=False)","9ce9f474":"print('Predicted class: {}'.format([explanation.X_pred]))\nplt.imshow(explanation.X.reshape(28, 28));","02f561f3":"print('Pertinent positive prediction: {}'.format(explanation.PP_pred))\nplt.imshow(explanation.PP.reshape(28, 28));","c5a6b890":"The above result clearly shows that the pertinent negative method pushes the prediction to get a prediction different from the original prediction which is 5 (sandal) to 7 (sneaker) in this case.\n\nIt shows the perturbations created to the original instance in order to change the prediction from sandal to sneaker. These are the minimal changes that should be absent to prevent the result from changing.","6f44325e":"The original prediction class is 5 that represtns sandal, since it has a greater prediction probability.","9904f0fd":"Consider the twelfth instance of testing data.","3b94b188":"## CEM","e98647eb":"Here, \n\n*   mode : 'PN' (Pertinent Negative) or 'PP' (Pertinent Positive)\n*   shape : Shape of the current instance. As CEM is applicable for single explanations, we take 1.\n*   kappa, beta, gamma, c_init, c_steps are all mathematical terms for calculating loss\n*   max_iterations : the total no. of loss optimization steps for each value of c\n*   feature_range : global or feature wise minimum and maximum values for the changed instance\n*   clip : minimum and maximum gradient values\n*   lr_init : initial learning rate \n\n","8483eb63":"Generating contrastive explaination for pertinent negative:","d8a4f7c6":"The above result shows that the predicted class remains same on applying PP. The image generated using PP gives a faint idea of the shape which is suffusuent to give the original result which is sandal. The above pixels shown should be compulsorily and minimally present in order to get the same original class 5 as predicted class.","2dd4ae9a":"Contrastive Explanation Method, abbreviated as CEM, is a XAI Method which can give local explanations for a black box model. This method is applicable for classification datasets. CEM gives two kinds of explanations: \n\nPertinent Positives (PP): For a PP, the method finds the features that should be minimally and sufficiently present (e.g. important pixels in an image) to predict the same class as on the original instance.  PP works similarly to Anchors.\n\n\nPertinent Negatives (PN): PN\u2019s on the other hand identify what features should be minimally and necessarily absent from the instance to be explained in order to maintain the original prediction class. The aim of PN\u2019s is not to provide a full set of characteristics that should be absent in the explained instance, but to identify a minimal set of features that is enough to differentiate it from the nearest different class. PN works similarly to Counterfactuals.\n\n\n\n\n","957cb3e1":"Training the model:"}}