{"cell_type":{"0f76ea31":"code","b51b2faa":"code","0afcb376":"code","4af12d9e":"code","1c661cc1":"code","0a54f173":"code","66267b0d":"code","826342be":"code","efaef0e1":"code","bdb69cdb":"code","246f9724":"code","d7498732":"code","0f0225c3":"code","73fae6d2":"code","f8f753e7":"code","aaa9c71f":"code","5c4ad3f4":"code","ca48668e":"code","7f11b2f7":"code","ce862396":"code","72637c85":"code","79567c5d":"code","c36ca056":"code","d3963d09":"code","4c9a87a6":"code","5e0a17a0":"code","0c7a61a8":"code","7a87c996":"code","67042763":"code","5fc92ef3":"code","98d54a5c":"code","b673ba83":"code","64d2ae5e":"code","5dc68caf":"code","e4fcf4bf":"code","6ff4fe16":"code","6ba42cfc":"code","bf9ae7a5":"markdown","06d478c2":"markdown","b4f4ae39":"markdown","0215c491":"markdown","2301ec33":"markdown"},"source":{"0f76ea31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b51b2faa":"train = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/sample_submission.csv')","0afcb376":"train.head()","4af12d9e":"test.head()","1c661cc1":"train.open_channels.unique()","0a54f173":"import matplotlib.pyplot as plt\nimport seaborn as sns","66267b0d":"size=16\nparams = {'legend.fontsize': 'large',\n          'figure.figsize': (16,4),\n          'axes.labelsize': size*1.1,\n          'axes.titlesize': size*1.3,\n          'xtick.labelsize': size*0.9,\n          'ytick.labelsize': size*0.9,\n          'axes.titlepad': 25}\nplt.rcParams.update(params)","826342be":"signal_batch_size = 500_000\ntrain['signal_batch'] = np.arange(len(train)) \/\/ signal_batch_size","efaef0e1":"fig, ax = plt.subplots(1,1,figsize=(12,6))\n\ntrain\\\n    .groupby('signal_batch')['open_channels']\\\n    .apply(lambda x: len(set(x)))\\\n    .value_counts()\\\n    .sort_index()\\\n    .plot(kind='bar', ax=ax, width=0.8)\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height()}', \n                (p.get_x()+p.get_width()\/2., p.get_height()), \n                ha='center', va='bottom', \n                color='black', fontsize=14, \n                #fontweight='heavy',\n                xytext=(0,5), \n                textcoords='offset points')\n\nax.set_yticks([0,1,2,3,4])\nax.set_yticklabels([0,1,2,3,4])\nax.set_xticklabels(ax.get_xticklabels(), rotation=0)\nax.set_xlabel('No. of Labels per Signal Batch')\nax.set_ylabel('No. of Signal Batch')\nax.set_title('Distribution of No. of Labels Per Signal Batch '+'$(n = 10)$')\n\nfor loc in ['right','top']:\n    ax.spines[loc].set_visible(False)","bdb69cdb":"def plot_signal_and_label(segment_size=200):\n    fig, ax = plt.subplots(1,1, figsize=(14,6))\n\n    sample = np.random.randint(0,9)\n    segment = np.random.randint(0,500_000 - segment_size)\n    \n    df_segment = train.query('signal_batch == @sample')\n    \n    df_segment['signal'].iloc[segment:segment+segment_size]\\\n        .plot(ax=ax, label='Signal', alpha=0.8, linewidth=2)\n    \n    ax_2nd = ax.twinx()\n    df_segment['open_channels'].iloc[segment:segment+segment_size]\\\n        .plot(ax=ax_2nd, label='Open Channels (Ground Truth)', color='C1', linewidth=2)\n\n    time_start = df_segment['time'].iloc[segment]\n    time_end = df_segment['time'].iloc[segment + segment_size-1]\n    \n    xticklabels = [val for i, val in enumerate(df_segment['time'].iloc[segment:segment + segment_size + 1]) if i%(segment_size\/\/10) == 0]\n    xtickloc = [val for i, val in enumerate(df_segment.iloc[segment:segment + segment_size + 1].index) if i%(segment_size\/\/10) == 0]\n    \n    ax.set_xticks(xtickloc)\n    ax.set_xticklabels(xticklabels)\n    ax.set_xlabel('Timestamp')\n    \n    ax.set_ylabel('Signal')\n    ax_2nd.set_ylabel('Open Channels')\n    \n    ax.set_title(f'Signal Batch #{sample} \\n('\n                 r'$t_{start} = $' + f'${time_start} s, $'\n                 r'$t_{end} = $' + f'${time_end} s$' + ')')\n    fig.legend(bbox_to_anchor=(1.03,0.5), loc='center left')\n    \n    ax.spines['top'].set_visible(False)\n    ax_2nd.spines['top'].set_visible(False)\n    ax.grid(which='major',axis='x', linestyle='--')\n\n    plt.tight_layout()\n    plt.show()\n    ","246f9724":"for i in range(10):\n    plot_signal_and_label(segment_size=200)","d7498732":"train_time = train['time'].values","0f0225c3":"train_time_0 = train_time[:50000]","73fae6d2":"for i in range(1,100):\n    train_time_0 = np.hstack([train_time_0, train_time[i*50000:(i+1)*50000]])","f8f753e7":"train['time'] = train_time_0","aaa9c71f":"train_time_0 = train_time[:50000]\nfor i in range(1,40):\n    train_time_0 = np.hstack([train_time_0, train_time[i*50000:(i+1)*50000]])\ntest['time'] = train_time_0","5c4ad3f4":"X = train[['time', 'signal']].values\ny = train['open_channels'].values","ca48668e":"train.open_channels.nunique()","7f11b2f7":"sns.countplot(x='open_channels',data=train)","ce862396":"sns.heatmap(train.corr())","72637c85":"train.corr()['open_channels'].sort_values().plot(kind='bar')","79567c5d":"train.corr()['signal'][:-1].sort_values().plot(kind='bar')","c36ca056":"from sklearn.preprocessing import MinMaxScaler","d3963d09":"scaler = MinMaxScaler()","4c9a87a6":"scaler.fit(X)","5e0a17a0":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout","0c7a61a8":"model = Sequential()\n\nmodel.add(Dense(units=100,activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units=50,activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units=25,activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units=15,activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units=11,activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')","7a87c996":"from tensorflow.keras.callbacks import EarlyStopping","67042763":"help(EarlyStopping)","5fc92ef3":"early_stop = EarlyStopping(monitor='train_loss', mode='min', verbose=1, patience=25)","98d54a5c":"model.fit(x=X, \n          y=y, \n          epochs=10,\n          verbose=1,\n          validation_data=(X, y), \n          batch_size = 128,\n          callbacks=[early_stop]\n          )","b673ba83":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","64d2ae5e":"from sklearn.linear_model import LogisticRegressionCV","5dc68caf":"clf = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)","e4fcf4bf":"train_preds = clf.predict(X)\ntrain_preds = np.clip(train_preds, 0, 10)\ntrain_preds = train_preds.astype(int)\nX_test = test[['time', 'signal']].values","6ff4fe16":"test_preds = clf.predict(X_test)\ntest_preds = np.clip(test_preds, 0, 10)\ntest_preds = test_preds.astype(int)\nsubmission['open_channels'] = test_preds\nsubmission.head(20)","6ba42cfc":"np.set_printoptions(precision=4)\nsubmission['time'] = [format(submission.time.values[x], '.4f') for x in range(2000000)]\nsubmission.to_csv('submission.csv', index=False)","bf9ae7a5":"## Lets try LogisticRegressionCV","06d478c2":"## This is absolutely horrible","b4f4ae39":"## The visualizations are inspired by ChewZy's [kernel](https:\/\/www.kaggle.com\/chewzy\/eda-ion-switching-signal-vs-open-channels) ","0215c491":"## Creating a Deep Learning Model","2301ec33":"### Modeling"}}