{"cell_type":{"4b06e5f6":"code","95aac7f8":"code","b54632ef":"code","b373ca8a":"code","efae4aed":"code","0bd8c3d5":"code","d2722423":"code","cf9b4d14":"code","9cfb32e2":"code","da64a56f":"code","4d3e5531":"code","958ec190":"code","53d0ebd5":"code","342e0124":"code","0de7df78":"code","95293cbe":"code","dc296d7d":"code","82f24016":"code","875c92c1":"code","d3f79c42":"code","be8255d6":"code","ffa0cd9d":"code","8691b076":"code","83557113":"code","312af9a1":"code","0b94fd6e":"code","7cb44702":"code","9d75d5d2":"code","b3a20ebf":"code","c06910ce":"code","5311f9d2":"code","53be9b90":"code","fdf56dc9":"code","bbcf4dd2":"code","61bc74b4":"code","9a1871ff":"code","74755987":"code","3c4b494a":"code","fbe5d56f":"code","4c083e5f":"code","673d5712":"code","64cf9707":"code","8e3dc960":"code","07e9dc4e":"markdown"},"source":{"4b06e5f6":"import pandas as pd\nimport numpy as np\n\ndf=pd.read_csv(r\"..\/input\/iba-ml1-final-project\/train.csv\")","95aac7f8":"test= pd.read_csv(r\"..\/input\/iba-ml1-final-project\/test.csv\")","b54632ef":"test.head()","b373ca8a":"test.isnull().sum()","efae4aed":"test['Final_review']= test['Review_Title']+\" \"+test['Review']","0bd8c3d5":"test.fillna(\"Gorgeous\", inplace=True) #Gorgeous","d2722423":"df.head()","cf9b4d14":"df['Final_review']= df['Review_Title']+\" \"+df['Review']","9cfb32e2":"main_col='Final_review'","da64a56f":"df.dropna(subset=[main_col],inplace=True)","4d3e5531":"df.isnull().sum()","958ec190":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df, df.Recommended,test_size = 0.05)","53d0ebd5":"X_train['Rating'].value_counts()","342e0124":"xtr = np.array(X_train[main_col])\nxte = np.array(X_test[main_col])\nytr = np.array(y_train)\nyte = np.array(y_test)\n\nytee = np.array(test[main_col])\n\nytr_r = np.array(X_train['Rating'])\nyte_r = np.array(X_test['Rating'])\n\nprint(xtr.shape)\nprint(xte.shape)\nprint(ytee.shape)\nprint(ytr_r.shape)\nprint(yte_r.shape)","0de7df78":"import tensorflow as tf\n\ntok = tf.keras.preprocessing.text.Tokenizer(\n    num_words=500, filters='!\"#$%&()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n    split=' ', char_level=False, oov_token = 'unknown')","95293cbe":"tok.fit_on_texts(xtr)","dc296d7d":"xtr1 = tok.texts_to_sequences(xtr)","82f24016":"xte1 = tok.texts_to_sequences(xte)","875c92c1":"xtee1 = tok.texts_to_sequences(ytee)","d3f79c42":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nxtr2 = pad_sequences(xtr1, 1000, padding='pre', truncating='post',)\nxte2 = pad_sequences(xte1, 1000, padding='pre', truncating='post')\n","be8255d6":"xtee2 = pad_sequences(xtee1, 1000, padding='pre', truncating='post')","ffa0cd9d":"from tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.metrics import *","8691b076":"ytr1 = to_categorical(ytr,2)\nyte1 = to_categorical(yte,2)\n\nytr1_r = to_categorical(ytr_r,6)\nyte1_r = to_categorical(yte_r,6)","83557113":"embedding_vecor_length = 200\nmax_review_length = 1000\nNUM_WORDS = 10000\n\nmodel = Sequential()\nmodel.add(Embedding(NUM_WORDS, embedding_vecor_length, input_length=max_review_length))\nmodel.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling1D())\nmodel.add(GRU(100, return_sequences=True))\nmodel.add(GRU(50))\n#model.add(Dropout(0.5))\nmodel.add(Dense(200,activation='relu'))\nmodel.add(Dense(2, activation='softmax'))","312af9a1":"model.summary()","0b94fd6e":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","7cb44702":"model.fit(xtr2, ytr1, epochs=5, batch_size=10, validation_data=(xte2, yte1))","9d75d5d2":"pred= np.argmax(model.predict(xte2), axis=-1)","b3a20ebf":"pred1= np.argmax(model.predict(xtee2), axis=-1)","c06910ce":"test['Recommended']=pred1","5311f9d2":"test.Recommended.value_counts()","53be9b90":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(yte, pred)","fdf56dc9":"# calculate the spearman's correlation between two variables\nfrom numpy.random import rand\nfrom numpy.random import seed\nfrom scipy.stats import spearmanr\n# calculate spearman's correlation\ncoef, p = spearmanr(yte, pred)\nprint('Spearmans correlation coefficient: %.3f' % coef)\n","bbcf4dd2":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(yte, pred)","61bc74b4":"embedding_vecor_length = 200\nmax_review_length = 1000\nNUM_WORDS = 10000\n\nmodel2 = Sequential()\nmodel2.add(Embedding(NUM_WORDS, embedding_vecor_length, input_length=max_review_length))\nmodel2.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\nmodel2.add(MaxPooling1D())\nmodel2.add(GRU(400, return_sequences=True))\nmodel2.add(GRU(200))\nmodel2.add(Dense(600,activation='relu'))\nmodel2.add(Dense(6, activation='softmax'))","9a1871ff":"model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","74755987":"model2.fit(xtr2, ytr1_r, epochs=5, batch_size=15, validation_data=(xte2, yte1_r))","3c4b494a":"pred2= np.argmax(model2.predict(xte2), axis=-1)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(yte_r, pred2)","fbe5d56f":"# calculate the spearman's correlation between two variables\nfrom numpy.random import rand\nfrom numpy.random import seed\nfrom scipy.stats import spearmanr\n# calculate spearman's correlation\ncoef, p = spearmanr(yte_r, pred2)\nprint('Spearmans correlation coefficient: %.3f' % coef)\n","4c083e5f":"pred11= np.argmax(model2.predict(xtee2), axis=-1)","673d5712":"test['Rating']=pred11","64cf9707":"test.head()","8e3dc960":"test[['Id','Rating','Recommended']].to_csv(\"submission_11.csv\", index=False)","07e9dc4e":"# Train a model to classify the polarity of comments"}}