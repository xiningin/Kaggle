{"cell_type":{"100d4b4a":"code","c7a09f73":"code","8b6d5499":"code","056d4c10":"code","e36b99b0":"code","9f4a7a3b":"code","34a4356f":"code","b79b1a20":"code","5c9b59c4":"code","6afb7c89":"code","9753fe83":"code","7769c205":"markdown","fb072fe8":"markdown","4f893402":"markdown","94461948":"markdown","74b459ed":"markdown","cabc169b":"markdown","5675830b":"markdown","d132e291":"markdown"},"source":{"100d4b4a":"# Import packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\n# Deep Learning\nimport tensorflow as tf","c7a09f73":"# load in data\ndata = pd.read_csv(\"..\/input\/liverpool-ion-switching\/train.csv\")\ntest = pd.read_csv(\"..\/input\/liverpool-ion-switching\/test.csv\")\nsample_sub = pd.read_csv(\"..\/input\/liverpool-ion-switching\/sample_submission.csv\" ,dtype={'time': 'str'})","8b6d5499":"plt.figure(figsize = (16,8))\nplt.plot(data[data['open_channels']==0]['signal'], color = 'c')\nplt.plot(data[data['open_channels']==1]['signal'], color = 'b')\nplt.plot(data[data['open_channels']==2]['signal'], color = 'r')\nplt.plot(data[data['open_channels']==3]['signal'], color = 'k')\nplt.plot(data[data['open_channels']==4]['signal'], color = 'g')\nplt.plot(data[data['open_channels']==5]['signal'], color = 'y')\nplt.plot(data[data['open_channels']==6]['signal'], color = 'c')\nplt.plot(data[data['open_channels']==7]['signal'], color = 'm')\nplt.plot(data[data['open_channels']==8]['signal'], color = 'b')\nplt.plot(data[data['open_channels']==9]['signal'], color = 'r')\nplt.plot(data[data['open_channels']==10]['signal'], color = 'g')","056d4c10":"combined = pd.concat([data,test])\ncombined = combined.reset_index()\nmodified = []\nfor i in range(70):\n    a = i*10 \n    b = i*10 + 10\n    temp = combined[(combined['time']>a)&(combined['time']<=b)]\n    par = np.polyfit(temp['time'],temp['signal'],2)\n    modified += (temp['signal'] - (par[0]*temp['time']**2 + par[1]*temp['time']**1 + par[2])).tolist()\ncombined['modi'] = modified","e36b99b0":"plt.figure(figsize = (16,8))\nplt.plot(combined[combined['open_channels']==0]['modi'], color = 'c')\nplt.plot(combined[combined['open_channels']==1]['modi'], color = 'b')\nplt.plot(combined[combined['open_channels']==2]['modi'], color = 'r')\nplt.plot(combined[combined['open_channels']==3]['modi'], color = 'k')\nplt.plot(combined[combined['open_channels']==4]['modi'], color = 'g')\nplt.plot(combined[combined['open_channels']==5]['modi'], color = 'y')\nplt.plot(combined[combined['open_channels']==6]['modi'], color = 'c')\nplt.plot(combined[combined['open_channels']==7]['modi'], color = 'm')\nplt.plot(combined[combined['open_channels']==8]['modi'], color = 'b')\nplt.plot(combined[combined['open_channels']==9]['modi'], color = 'r')\nplt.plot(combined[combined['open_channels']==10]['modi'], color = 'g')","9f4a7a3b":"plt.figure(figsize = (16,8))\nplt.plot(combined['modi'], color = 'c')","34a4356f":"#split\nsplit1 = [combined[(combined['time']>0)&(combined['time']<=100)], \n          pd.concat([combined[(combined['time']>500)&(combined['time']<=510)],\n                     combined[(combined['time']>530)&(combined['time']<=540)],\n                     combined[(combined['time']>580)&(combined['time']<=590)],\n                     combined[(combined['time']>600)&(combined['time']<=700)]])]\n\nsplit2 = [pd.concat([combined[(combined['time']>100)&(combined['time']<=150)],\n                     combined[(combined['time']>300)&(combined['time']<=350)]]),\n          combined[(combined['time']>540)&(combined['time']<=550)]]\n    \nsplit3 = [combined[(combined['time']>150)&(combined['time']<=200)],\n          pd.concat([combined[(combined['time']>510)&(combined['time']<=520)],\n                     combined[(combined['time']>590)&(combined['time']<=600)]])]\n\nsplit4 = [pd.concat([combined[(combined['time']>200)&(combined['time']<=250)],\n                     combined[(combined['time']>450)&(combined['time']<=500)]]),\n          pd.concat([combined[(combined['time']>550)&(combined['time']<=560)],\n                     combined[(combined['time']>570)&(combined['time']<=580)]])]  \n                     \nsplit5 = [pd.concat([combined[(combined['time']>250)&(combined['time']<=300)],\n                     combined[(combined['time']>400)&(combined['time']<=450)]]),\n          pd.concat([combined[(combined['time']>520)&(combined['time']<=530)],\n                     combined[(combined['time']>560)&(combined['time']<=570)]])]        ","b79b1a20":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if (logs.get('accuracy')>0.999):\n            print('\\n yuhu, accuracy already reach 99.9%')\n            self.model.stop_training = True ","5c9b59c4":"def get_model(n):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(20, input_shape = [1,], activation='relu'))\n    model.add(tf.keras.layers.Dense(20, activation='relu'))\n    model.add(tf.keras.layers.Dense(20, activation='relu'))\n    model.add(tf.keras.layers.Dense(n,activation='softmax'))\n\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","6afb7c89":"for i in [split1,split2,split3,split4,split5]:\n    split = i\n    skf = StratifiedKFold(n_splits=4)\n    callback = myCallback()\n    record = []\n    for train_index, test_index in skf.split(split[0]['modi'], split[0]['open_channels']):\n        print('\\n Cross validation Segment \\n')\n        X_train, X_test = split[0]['modi'].values[train_index], split[0]['modi'].values[test_index]\n        y_train, y_test = pd.get_dummies(split[0]['open_channels']).values[train_index], pd.get_dummies(split[0]['open_channels']).values[test_index]\n        model = get_model(y_train.shape[1])\n        scaler = StandardScaler()\n        scaler.fit(X_train.reshape(-1, 1))\n        nn_history = model.fit(scaler.transform(X_train.reshape(-1, 1)), y_train, epochs = 10, \n                               validation_data = (scaler.transform(X_test.reshape(-1, 1)),y_test),callbacks = [callback],batch_size = 4000)\n        record.append(nn_history.history['val_accuracy'][-1])\n    print('\\n mean validation accuracy is {}'.format(np.array(record).mean()))\n    \n    #predict\n    split[1].loc[split[1].index,'open_channels'] = np.argmax(model.predict(scaler.transform(np.array(split[1]['modi']).reshape(-1, 1))), axis=-1)\n    \noutput = pd.concat([split1[1],split2[1],split3[1],split4[1],split5[1]])","9753fe83":"output = output.sort_values('time')\nreal_output = output[['time','open_channels']].reset_index()\nreal_output = real_output.drop('index', axis = 1)\nreal_output['time'] =  sample_sub['time']\nreal_output.to_csv('ion.csv', index = False)","7769c205":"Will tidy the notebook up later. Just want to share :). CHeer","fb072fe8":"in this notebook, I will try to show the pattern of the data, then we will train it partially. If you have tried to solve this problem. You must have realized that there is a pattern on the training data. **if an interval has high variances then there will be more categorical output for that interval**. therefore, I will train a model on an interval, then use it to predict the interval in the test dataset that have the similar characteristic.","4f893402":"The interval with high variances has more color. noted. To make it simple to be seen, we can transform each interval to be \"bar\" not curvy by using **polyfit to interpolate then substract them**. I use 10 seconds interval. ","94461948":"# Training by Segmenting","74b459ed":"Lets look at the plot, I differ each categoric by color.","cabc169b":"Now everything is ready to be trained on model.","5675830b":"In summary :\n1. Split the train and test by using the same variances of the data\n2. Train using simple MLP (3 hidden layers)","d132e291":"from the plot above, we can split the train and test by it's variances. Because a particular variances have a number amount of unique output. Here is the split I have done"}}