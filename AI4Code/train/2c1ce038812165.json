{"cell_type":{"aad0175f":"code","a9b3babc":"code","b6230a5e":"code","af5146ce":"code","4d54a339":"code","b9005caa":"code","c2199997":"code","b57324ea":"code","a56147ad":"code","24bd5e8b":"code","8d4c052c":"code","537c9241":"code","8c577a41":"code","2b3a9965":"code","71635d00":"code","033b9a11":"code","91a6468d":"code","8a3cc2c0":"code","2b5f22ae":"code","2752ff61":"code","7d5ba73b":"markdown","79a3b06a":"markdown","800a4403":"markdown","255e6bb9":"markdown","b870ced1":"markdown","e004a5bf":"markdown"},"source":{"aad0175f":"#Importing Requierd Libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\n\n# for Interactive Shells\nfrom IPython.display import display\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\n#removing warnings\nimport sys\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")","a9b3babc":"# reading the csv file\ndf = pd.read_csv('..\/input\/avocado-prices\/avocado.csv')\ndf.head()","b6230a5e":"# we have an extra index column. As it will not be required so we will remove it\ndf.drop([\"Unnamed: 0\"],axis=1,inplace=True)\ndf","af5146ce":"df.info()","4d54a339":"# checking for null values\ndf.isnull().sum()","b9005caa":"#duplicates\nduplicates = df.duplicated().sum()\nif duplicates > 0:\n    print('There are no duplicated entries.')\nelse:\n    print(f'There are {duplicates} duplicates.')","c2199997":"# as few column data types are wrong, so lets fix that\nfor i in df.columns:\n    if i == 'date':\n        df[i] = df[i].astype('datetime64[ns]')\n    elif df[i].dtype == 'object':\n        df[i] = df[i].astype('category')\n\nnumeric_columns = ['AveragePrice', 'Total Volume',\n                   '4046', '4225', '4770',\n                   'Total Bags', 'Small Bags',\n                   'Large Bags', 'XLarge Bags']\ncategorical_columns = ['region', 'type']\ndata_columns = ['Data', 'year']\ndisplay(df.info())","b57324ea":"#  Getting known with the kind of distrubutions\ndef dist_custom(dataset, columns_list, rows, cols, suptitle):\n    fig, axs = plt.subplots(rows, cols,figsize=(16,16))\n    fig.suptitle(suptitle,y=0.92, size=16)\n    axs = axs.flatten()\n    for i, data in enumerate(columns_list):\n        sns.distplot(dataset[data], ax=axs[i])\n        axs[i].set_title(data + ', skewness is '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))\n        \ndist_custom(dataset=df, columns_list=numeric_columns, rows=3, cols=3, suptitle='Distibution for each variable')","a56147ad":"# outliers\ndef boxplots_custom(dataset, columns_list, rows, cols, suptitle):\n    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(16,12))\n    fig.suptitle(suptitle,y=0.93, size=16)\n    axs = axs.flatten()\n    for i, data in enumerate(columns_list):\n        if i % 3 == 0:\n            axs[i].set_ylabel('The number of entries')\n        sns.boxplot( data=dataset[data], orient='h', ax=axs[i])\n        axs[i].set_title(data)\n        \nboxplots_custom(dataset=df, columns_list=numeric_columns, rows=3, cols=3, suptitle='Boxplots before deleting outliers')","24bd5e8b":"# deleting outliers\nQ1 = df[numeric_columns].quantile(0.25)\nQ3 = df[numeric_columns].quantile(0.75)\nIQR = Q3 - Q1\nprint('Here we will get IQR for each column\\n',IQR)\n\ndf_filtered = df[~((df[numeric_columns] < (Q1 - 1.5 * IQR)) |(df[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\ndisplay(df_filtered.shape)","8d4c052c":"boxplots_custom(dataset=df_filtered, \n                columns_list=numeric_columns, \n                rows=3, cols=3, suptitle='Boxplots after deleting outliers')","537c9241":"# We already have information about day and year of price scanning so lets add week and month columns\ndf_filtered['month'] = df_filtered['Date'].astype('datetime64[M]')\ndf_filtered['week'] = df_filtered['Date'].astype('datetime64[W]')\nbins = [0.48, 1.52, 1.78, 1.9, 2.49]\nlabels = [\"low\",\"mean\",\"high\",'expensive']\ndf_filtered['price_types'] = pd.cut(df['AveragePrice'], bins=bins, labels=labels)\ndf_filtered.head()","8c577a41":"# Initialize figure with subplots\nfig = make_subplots(\n    rows=2, cols=2, subplot_titles=(\"Daily average prices\", \"Weekly average prices\",\n                                    \"Monthly average prices\", \"Average prices per years\")\n                                        )\n\ndatasets = []\nfor i in ['Date','week','month','year']:\n    datasets.append(round(df_filtered.groupby(i)['AveragePrice'].mean().reset_index(),3))\nr, c = 1,1 #rows, cols\n    \nfor i, d in enumerate(datasets):\n    # Add traces\n    fig.add_trace(go.Scatter(x=d.iloc[:,0], y=d['AveragePrice']), row=r, col=c)\n    fig.update_xaxes(title_text='Per ' + d.iloc[:,0].name,row=r, col=c)\n    fig.update_yaxes(title_text=\"The sum of avarage price\", row=r, col=c)\n    if i == 1:\n        r, c = 2, 1\n    else:\n        c += 1\n    \n# Update title and height\nfig.update_layout(showlegend=False, title_text=\"Customizing Subplot Axes\", height=700)\n\nfig.show()","2b3a9965":"# Initialize figure with subplots\nfig = make_subplots(\n    rows=1, cols=2, subplot_titles=(\"Daily average prices\", \n                                    \"Monthly average prices\"))\n\ndatasets = []\nfor i in ['Date','month']:\n    for j in ['conventional', 'organic']:\n        datasets.append(round(df_filtered.query('type == @j').groupby(i)['AveragePrice'].mean().reset_index(),3))\nr, c = 1,1\nlegend_ = ['conventional', 'organic']\nfor i, d in enumerate(datasets):\n    # Add traces\n    fig.add_trace(go.Scatter(x=d.iloc[:,0], y=d['AveragePrice'], name=legend_[i%2]+' per ' + d.iloc[:,0].name), row=r, col=c)\n    fig.update_xaxes(title_text='Per ' + d.iloc[:,0].name,row=r, col=c)\n    fig.update_yaxes(title_text=\"The sum of avarage price\", row=r, col=c)\n    if i == 1:\n        c += 1\n    \n# Update title and height\nfig.update_layout(showlegend=True, title_text=\"Daily and monthly avarage prices for conventional and organic types\", height=700)\n\nfig.show()","71635d00":"# histograms\nparam_graphs = df_filtered.hist(numeric_columns, figsize=(16, 10), bins=20)\nplt.suptitle(\"Hists after removing outliers\", y=0.96, size=16)\nfor axis in param_graphs.flatten():\n    axis.set_ylabel('frequency')\nplt.show()\n","033b9a11":"# Distributions and scatter plot for each variable according to type variable\n\ncolumns_for_research = ['AveragePrice', 'Total Volume', '4046','4225','4770', 'type']\ng = sns.pairplot(data=df_filtered[columns_for_research], hue=\"type\")\ng.fig.suptitle(\"Distributions and scatter plots for each variable depending on type\", y=1.01, size=16)\nfor ax in g.axes.flat: \n    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.show()","91a6468d":"# bar plots\nten_largest_volume_regions = df_filtered.groupby(['region'])['Total Volume'].sum().sort_values(ascending=False).reset_index().head(10)\nfig = px.bar(ten_largest_volume_regions,x='region', y='Total Volume', title='Top ten regions with the greatest total volume over the time')\nfig.show()","8a3cc2c0":"df_count_type = df_filtered.groupby(['price_types', 'type'])['Date'].count().reset_index()\n\nplt.figure(figsize=(10, 5))\nsns.countplot(x='price_types', alpha=0.7, hue='type', \n                  data=df_filtered)\nplt.legend( bbox_to_anchor=(1.1, 1.1), loc='upper left')\nplt.xlabel('Price types'), plt.ylabel('Amount')\nplt.title('Relation between type and average price', size=16, y=1.01);","2b5f22ae":"# calculating the correlation matrix\ncorr = df_filtered.corr()\nmatrix = np.triu(corr)\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr, vmax=1.0, vmin=-1.0, \n            fmt='.1g', annot=True, mask = matrix)\n\nplt.title('Correlation matrix', size=16)\nplt.show()","2752ff61":"df_filtered.to_csv(\"Filtered_dataset.csv\")","7d5ba73b":"**Observations about all the above:**\n- At the daily and monthly average price we see a decline in price in January 2016-2017. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops;\n- At the average price per year chart we see a steady decline from 2015 to 2016.\n- After that there is an increase, the peak is in 2017 year.","79a3b06a":"**Observations** :\nFrom the lineplots above:\n- At the daily and monthly average price we see a decline in price in January 2016-2017. We can conclude that in winter avocados are not in demand, or there were a too much avocados in shops;\n- At the average price per year chart we see a steady decline from 2015 to 2016.\n- After that there is an increase, the peak is in 2017 year.","800a4403":"> Looks much better now! But nevertheless we see some outliers even in filtered data. It will be great to scale the features at the step of building model. We'll use filtered data further","255e6bb9":"> Let's create new dataset with avarage avocado price per day, month and year. After that we'll create lineplots with the use of plotly.express and analyze it","b870ced1":"> all features are skewed to the left, there is no Normal Distribution. Let's examine outliers with the use of boxplots.","e004a5bf":"> For Skewed distributions we'll use Inter-Quartile Range (IQR) proximity rule."}}