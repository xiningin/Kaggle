{"cell_type":{"a64ee0a9":"code","7d23df78":"code","c3b23129":"code","a7e85129":"code","5d23776d":"code","a479de16":"code","601e1689":"code","98e7cef1":"code","a9ac2579":"code","d52fa746":"code","4f22830f":"code","c55e75b9":"code","428cc970":"code","c1c3881b":"code","d4544faf":"code","44a5293c":"code","07c3c8a3":"code","552ac953":"code","9aaad882":"code","39571a3e":"code","78b0a60b":"code","65fad0ad":"code","d537a585":"code","53426eab":"markdown","92b6d54e":"markdown","07a9597a":"markdown","88ebd89e":"markdown","a7123a0b":"markdown","2f3f47bb":"markdown","fba46980":"markdown","633ed917":"markdown","c5259979":"markdown","f6135056":"markdown","80e55206":"markdown","94a48c29":"markdown","c98e506f":"markdown","d26d623b":"markdown"},"source":{"a64ee0a9":"import pandas as pd\nimport numpy as np\nimport keras\nfrom keras.models import Model,Sequential\nfrom keras.layers import Input,Dense,Conv2D,MaxPool2D,BatchNormalization,Flatten,Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.datasets import fashion_mnist\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7d23df78":"train = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")","c3b23129":"train.head()","a7e85129":"y_train = train[\"label\"]\nx_train = train.drop(labels = [\"label\"], axis = 1)","5d23776d":"x_train.head()","a479de16":"test.head()","601e1689":"y_test = test[\"label\"]\nx_test = test.drop(labels = [\"label\"], axis = 1)","98e7cef1":"x_train = x_train \/ 255.0\nx_test = x_test \/ 255.0","a9ac2579":"x_train = x_train.values.reshape(-1,28,28,1)\nx_test = x_test.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \", x_train.shape)\nprint(\"test shape: \", x_test.shape)","d52fa746":"y_train = to_categorical(y_train,num_classes = 10)\ny_test = to_categorical(y_test,num_classes = 10)","4f22830f":"print(\"x_train shape: \",x_train.shape)\nprint(\"x_test shape :\",x_test.shape)","c55e75b9":"plt.imshow(x_train[4000])\nplt.axis(\"off\")\nplt.show()\n\nplt.figure()\n\nplt.imshow(x_train[50000])\nplt.axis(\"off\")\nplt.show()","428cc970":"x_train = x_train.reshape(-1,28,28,1)\nx_test = x_test.reshape(-1,28,28,1)\n","c1c3881b":"print(\"x train shape: \",x_train.shape)\nprint(\"x test shape: \",x_test.shape)\nprint(\"y train shape: \",y_train.shape)\nprint(\"y test shape: \",y_test.shape)","d4544faf":"x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.1,random_state = 2)\nprint(\"x_train shape :\",x_train.shape)\nprint(\"x_val shape :\",x_val.shape)\nprint(\"y_train shape :\",y_train.shape)\nprint(\"y_val shape :\",y_val.shape)","44a5293c":"model = Sequential()\nmodel.add(Conv2D(filters = 64,kernel_size = (5,5),activation = \"relu\",padding = \"Same\",input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 32,kernel_size = (5,5),activation = \"relu\",padding = \"Same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(units = 256,activation = \"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(units = 10,activation = \"softmax\"))","07c3c8a3":"model.compile(optimizer = \"RMSprop\",\n              loss = \"categorical_crossentropy\", \n              metrics = [\"accuracy\"])","552ac953":"epochs = 20\nbatch_size = 256","9aaad882":"datagen = ImageDataGenerator(rotation_range = 0.5,\n                   zoom_range = 0.5,\n                   width_shift_range = 0.5,\n                   height_shift_range = 0.5,\n                   horizontal_flip = True)\n\ndatagen.fit(x_train)","39571a3e":"model.summary()","78b0a60b":"hist = model.fit(datagen.flow(x_train, y_train, batch_size = batch_size),\n                      epochs = epochs,\n                      validation_data = (x_val, y_val),\n                      steps_per_epoch = x_train.shape[0] \/\/ batch_size)","65fad0ad":"plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\nplt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\nplt.legend()\nplt.show()\n\nplt.figure()\n\n\nplt.plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nplt.plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nplt.legend()\nplt.show()","d537a585":"\ny_predict=model.predict(x_val)\ny_predict_classes=np.argmax(y_predict,axis=1)\ny_true=np.argmax(y_val,axis=1)\nconfusion_mtx=confusion_matrix(y_true,y_predict_classes)\nf,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(confusion_mtx,annot=True,linewidths=0.01,cmap=\"Oranges\",linecolor=\"white\",fmt=\".1f\",ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","53426eab":"## Loading Data & Data Preparation","92b6d54e":"## Evaluate the Model","07a9597a":"## Convolutional Neural Network","88ebd89e":"## Train-Test Split","a7123a0b":"### Reshaping","2f3f47bb":"## Model Fitting","fba46980":"# Fashion MNIST ","633ed917":"### Data Augmentation","c5259979":"### Compiling Network","f6135056":"### Label Encoding","80e55206":"### Visualizing","94a48c29":"### Confusion Matrix","c98e506f":" # Normalizaton","d26d623b":"## Import Libraries"}}