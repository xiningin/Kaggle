{"cell_type":{"ff4faa03":"code","9926d0b8":"code","f464a8cf":"code","6bb15843":"code","5ad45304":"code","5b84c15c":"code","2da6d704":"code","0a93a89b":"code","aeb7d4f2":"code","413f5ee7":"code","66affeb6":"code","f4171663":"code","993cf346":"code","2de59dd1":"code","7f9b2158":"code","27386f5d":"code","34b4989e":"code","fba9f5b1":"code","21e1870e":"code","45f000a2":"code","5fbd5585":"code","a4f7190d":"code","8555d9c6":"code","5ef6251f":"code","7b249392":"code","d0549263":"code","baba3c9b":"code","b955d0fd":"code","62111fb5":"code","5ce840e9":"code","6210bda8":"code","a75a6e89":"code","8e7481ff":"code","e9295c73":"code","74c24916":"code","f36ed3f5":"code","5f88971a":"code","1b3b9cac":"code","f6ca2492":"code","ef9ce0e7":"code","cec09e62":"code","8292c8da":"code","de0130d2":"code","b8564588":"code","c5dc5bac":"code","ef8298a4":"code","bd99b5f8":"code","db82e797":"code","e9e3bbfe":"code","386cfd85":"code","f68a1710":"code","e1f6170e":"code","c3ae53f6":"code","0f5ffed8":"code","15bf0332":"markdown","8e4cbe7d":"markdown"},"source":{"ff4faa03":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nfrom tqdm.notebook import tqdm\n%matplotlib inline","9926d0b8":"DATA_DIR = '..\/input\/10-monkey-species'\n\nTRAIN_DIR = DATA_DIR + '\/training\/training'                           # Contains training images  \nVAL_DIR = DATA_DIR + '\/validation\/validation'\nTEST_DIR='..\/input\/testing-dataset-for-10-species-of-monkey\/testing'","f464a8cf":"labels_name= ['mantled_howler',\n              'patas_monkey',\n            'bald_uakari',\n            'japanese_macaque',\n            'pygmy_marmoset',\n            'white_headed_capuchin',\n            'silvery_marmoset',\n            'common_squirrel_monkey',\n            'black_headed_night_monkey',\n            'nilgiri_langur']","6bb15843":"labels_name['n0']","5ad45304":"transform = transforms.Compose ([ transforms.Resize(size=(256,256) , interpolation=2),transforms.ToTensor(),])","5b84c15c":"train_dataset = ImageFolder ( TRAIN_DIR , transform=transform )\nval_dataset = ImageFolder ( VAL_DIR , transform=transform ) \ntest_dataset= ImageFolder ( TEST_DIR , transform=transform ) ","2da6d704":"len(train_dataset)","0a93a89b":"len(test_dataset)","aeb7d4f2":"len(val_dataset)","413f5ee7":"print(train_dataset.classes)","66affeb6":"train_dataset[576]","f4171663":"def show_example(img, label):\n    print('Label: ', train_dataset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))","993cf346":"show_example(*train_dataset[0])","2de59dd1":"show_example(*test_dataset[0])","7f9b2158":"random_seed = 10\ntorch.manual_seed(random_seed);","27386f5d":"batch_size=32","34b4989e":"train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size, num_workers=4, pin_memory=True)","fba9f5b1":"for images,labels in train_loader:\n    print('images.shape:', images.shape)\n    fig, ax = plt.subplots(figsize=(32, 16))\n    plt.axis('on')\n    ax.set_xticks([]); ax.set_yticks([])\n    plt.imshow(make_grid(images, nrow=8).permute((1, 2, 0)))\n    break","21e1870e":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass MonkeyClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","45f000a2":"class MonkeyCnnModel(MonkeyClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n             nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # output: 32 x 128 x 128\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n             nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 64 x 64\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n             nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # output: 64 x 32 x 32\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),   # output: 128 x 16 x 16\n\n            nn.Flatten(), \n            nn.Linear(128*16*16, 2048),\n            nn.ReLU(),\n            nn.Linear(2048, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 10))\n        \n    def forward(self, xb):\n        return self.network(xb)","5fbd5585":"class MonkeyCnnModel2(MonkeyCnnModel):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 10)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))","a4f7190d":"model = MonkeyCnnModel2()\nmodel","8555d9c6":"for images, labels in train_loader:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","5ef6251f":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","7b249392":"device = get_default_device()\ndevice","d0549263":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\nto_device(model, device);","baba3c9b":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","b955d0fd":"model = to_device(MonkeyCnnModel2(), device)","62111fb5":"evaluate(model, val_loader)","5ce840e9":"num_epochs = 2\nopt_func = torch.optim.Adam\nlr = 0.001","6210bda8":"history = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)","a75a6e89":"history += fit(3, lr, model, train_loader, val_loader, opt_func)","8e7481ff":"history += fit(3, 0.0001, model, train_loader, val_loader, opt_func)","e9295c73":"history += fit(2, 0.00001, model, train_loader, val_loader, opt_func)","74c24916":"!pip install jovian --upgrade -q","f36ed3f5":"import jovian","5f88971a":"jovian.commit(project='Classification_of_Monkeys_Project_Zero_to_Gans')","1b3b9cac":"jovian.log_metrics(train_loss=history[-1]['train_loss'], \n                   val_loss=history[-1]['val_loss'], \n                   val_acc=history[-1]['val_acc'])","f6ca2492":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","ef9ce0e7":"plot_accuracies(history)","cec09e62":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","8292c8da":"plot_losses(history)","de0130d2":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return labels_name[preds[0].item()]","b8564588":"img, label = test_dataset[50]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', labels_name[label], ', Predicted:', predict_image(img, model))","c5dc5bac":"img, label = test_dataset[0]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', labels_name[label], ', Predicted:', predict_image(img, model))","ef8298a4":"img, label = test_dataset[99]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', labels_name[label], ', Predicted:', predict_image(img, model))","bd99b5f8":"img, label = test_dataset[11]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', labels_name[label], ', Predicted:', predict_image(img, model))","db82e797":"test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\nresult = evaluate(model, test_loader)\nresult","e9e3bbfe":"jovian.log_metrics(test_loss=result['val_loss'], test_acc=result['val_acc'])","386cfd85":"torch.save(model.state_dict(), 'monkeycnn.pth')","f68a1710":"model2 = to_device(MonkeyCnnModel2(), device)","e1f6170e":"model2.load_state_dict(torch.load('monkeycnn.pth'))","c3ae53f6":"evaluate(model2, val_loader)","0f5ffed8":"jovian.commit(project='Classification_of_Monkeys_Project_Zero_to_Gans')","15bf0332":"test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\nresult = evaluate(model, test_loader)\nresult","8e4cbe7d":"# **10 Monkey Species Classification using Convolutional Neural Networks in PyTorch** #"}}