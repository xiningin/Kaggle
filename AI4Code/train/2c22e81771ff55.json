{"cell_type":{"e42be351":"code","6b4589f6":"code","45137566":"code","60040b46":"code","bc41ccab":"code","0c04e7fb":"code","4f75d0fa":"code","1f70f181":"code","373926fa":"code","32d7544c":"code","e3bcb246":"code","9a7cee67":"code","96174714":"code","7c3c3ff4":"code","016d94d1":"code","b594cf60":"code","4ce25f8d":"code","dab4a7da":"code","94ec882c":"code","0614de72":"code","ec578b5e":"code","410b8b2d":"code","c3c30f5d":"markdown","45b27412":"markdown","c6ae827f":"markdown","99c58588":"markdown","60dd26c8":"markdown","cf6e6e4c":"markdown","92ae8208":"markdown","cc8d67c7":"markdown","ea698457":"markdown","20f70631":"markdown","4fb74666":"markdown","f9f8f254":"markdown"},"source":{"e42be351":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6b4589f6":"train_identity = pd.read_csv('\/kaggle\/input\/train_identity.csv')\ntrain_transaction = pd.read_csv('\/kaggle\/input\/train_transaction.csv')","45137566":"print(train_identity.shape)\nprint(train_transaction.shape)","60040b46":"original_memory_usage = train_transaction.memory_usage()\noriginal_memory_usage","bc41ccab":"total_original_memory_usage = original_memory_usage.sum()","0c04e7fb":"a = (train_identity.dtypes == 'object')\nid_cat_cols = list(a[a].index)\na = (train_transaction.dtypes == 'object')\ntrans_cat_cols = list(a[a].index)\nid_num_cols = list(set(train_identity.columns) - set(id_cat_cols))\ntrans_num_cols = list(set(train_transaction.columns) - set(trans_cat_cols))","4f75d0fa":"print(len(id_cat_cols))\nprint(len(id_num_cols))\nprint(len(trans_cat_cols))\nprint(len(trans_num_cols))","1f70f181":"train_transaction.dtypes","373926fa":"train_transaction[trans_num_cols].isnull().sum().sort_values(ascending=False)","32d7544c":"trans_integer_cols = []\nfor c in trans_num_cols:\n    try:\n        if train_transaction[c].fillna(-1.0).apply(float.is_integer).all():\n            trans_integer_cols += [c]\n    except Exception as e:\n        print(\"error: \", c, e)\n","e3bcb246":"len(trans_integer_cols)","9a7cee67":"stats = train_transaction[trans_integer_cols].describe().transpose()\nstats","96174714":"int8columns = stats[stats['max'] < 256].index\nprint(int8columns.shape)\nprint(int8columns)","7c3c3ff4":"int16columns = stats[(stats['max'] >= 256) & (stats['max'] <= 32767)].index\nprint(int16columns.shape)\nprint(int16columns)","016d94d1":"int8columns.shape[0] + int16columns.shape[0]","b594cf60":"for c in int8columns:\n    train_transaction[f'{c}_isna'] = train_transaction[c].isnull()\n    train_transaction[c].fillna(-1.0, inplace=True)\n    train_transaction[c] = train_transaction[c].astype('int8')","4ce25f8d":"for c in int16columns:\n    train_transaction[f'{c}_isna'] = train_transaction[c].isnull()\n    train_transaction[c].fillna(-1.0, inplace=True)\n    train_transaction[c] = train_transaction[c].astype('int16')","dab4a7da":"new_memory_usage = train_transaction.memory_usage()\nnew_memory_usage","94ec882c":"total_new_memory_usage = new_memory_usage.sum()\ntotal_new_memory_usage","0614de72":"total_original_memory_usage","ec578b5e":"total_original_memory_usage - total_new_memory_usage","410b8b2d":"train_transaction.to_feather('train_transaction_reduced_memory')","c3c30f5d":"Let's start by reading in the data and doing some minor analysis.","45b27412":"What about int16?","c6ae827f":"The max precision for all our integer columns is 16bits, where 233 columns only need 8 bits and 64 columns need 16 bits. Looks like we can reduce the memory usage by quite a bit!\n\nSo let's do that right now. We'll replace NaN values with `-1.0` as we previously did, and cast the columns to the corresponding integer type. Note that in practice you may want to do something different, e.g. use the median.\n\nIt might also helpful to mark which rows were previously null, which you could in theory derive from looking at whether it's `-1.0` or not, but if you're using something like the median you would lose track of them. The fact that the value is missing or NaN might be meaningful in your context, so it's a good idea to mark them, using a separate column.","99c58588":"So, we shaved about a gigabyte of RAM from this. You can now save your processed file to a feather format, for further processing.","60dd26c8":"# Beginner memory reduction analysis on IEEE-CIS Fraud Detection\n\nThis is a very simple beginner example on how to reduce memory usage for this dataset. The goal is just to get a reasonable starting point to start from.","cf6e6e4c":"A lot of these columns look like they are integers. I suspect most of them are cast to float64 by default because they contain NaN values. Let's find out:","92ae8208":"Let's look at what can be cast as int8","cc8d67c7":"Yes, looks like a significant portion of these columns contain NaN values. \n\nLet's see if we can replace the NaNs with a known round number, e.g. -1.0 and get all the columns that are really integers.","ea698457":"That took up 2gigs of RAM (you should be able to see it in the right sidebar of your kernel). \n\nLet's look at the data to see if we can use some other datatypes for some of the columns.","20f70631":"As you can see above, these are really small integers. They don't all need to be float64!","4fb74666":"We got a couple of errors from passing in numeric columns that are already integer columns, so we can safely ignore them.\n\nBut wow, 297 columns! But just because they're integers it doesn't mean we can reduce memory for all of them. They might be very large integers that we need 64 bits to represent.\n\nSo let's look at the statistics of these columns using `describe()`","f9f8f254":"That's 233 columns!"}}