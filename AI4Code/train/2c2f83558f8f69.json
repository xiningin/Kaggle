{"cell_type":{"2311e833":"code","3f69c796":"code","997d8425":"code","8e35b609":"code","69ca1bda":"code","a8618648":"code","c6232abb":"code","6b2e98f8":"code","b15ea39d":"code","ae4cc806":"code","f49f10ad":"code","2ebdb7eb":"code","7790d0f8":"code","d7360226":"code","cc1a5a1c":"code","3813dad9":"code","503de6fe":"code","a7761a4a":"code","bf5f9bb3":"code","bcad3a56":"code","0fbd474b":"code","0fe7e49d":"code","781b66a9":"code","6e6b77df":"code","5f40a9e7":"code","baaaf8dc":"code","1146e21e":"code","c59bc470":"code","47c045df":"code","9aa2103e":"code","1f7f5541":"code","11e38d1c":"code","f7a3dfa9":"code","56a56cb0":"code","d9ab8787":"code","b13a6011":"code","5be006d5":"code","ce3c25a8":"code","149aa304":"code","60bdf58b":"code","cf2985cb":"code","ed6b8fb2":"code","b4cb9e24":"code","d40b5f66":"code","07ba58e4":"code","3f8763b9":"code","013e50e1":"code","31ea743b":"code","a981706b":"code","de2db8f6":"code","a62941e7":"code","364a2cf6":"code","ab344c3c":"code","640001f9":"code","4557f056":"code","10e7bc69":"code","002ce352":"code","f721121d":"code","420cd599":"code","a88f0335":"code","4d7bd921":"code","1f6b8ba2":"code","e55a2438":"code","3a4b8b1c":"code","a438af6a":"code","9904d7a7":"code","1d4960a0":"markdown","ad4c6a92":"markdown","c5860c1f":"markdown","831d412d":"markdown","ab7fa728":"markdown","ee60e724":"markdown","6e00d624":"markdown","f767fdfa":"markdown","e5179cd6":"markdown","3693c588":"markdown","1727cdc5":"markdown","e8c861c4":"markdown","55321866":"markdown","06c4db5d":"markdown","5fa0bc73":"markdown","a7a4b04d":"markdown","0cd74556":"markdown","ec2fa191":"markdown","d8aaf3bb":"markdown","0aa98f09":"markdown","9e5cd761":"markdown","dd93e1f6":"markdown","1c753a3a":"markdown","768eb688":"markdown","f48d0ef5":"markdown","04a80e18":"markdown","fc82e32a":"markdown","fc41ee75":"markdown","c9d5da2a":"markdown","96a4302e":"markdown","00d68c62":"markdown","b5bb10bf":"markdown","bceec89f":"markdown","653f5e4b":"markdown","81e32915":"markdown","a6e4ba6a":"markdown","616bd5c0":"markdown","09188b57":"markdown","1855134f":"markdown","4a78dea4":"markdown","0dd5a1e8":"markdown","a1b44397":"markdown","8e7b8905":"markdown","76d853ae":"markdown","c9e25385":"markdown","2cdc990f":"markdown","c9465bad":"markdown","1d8c0c7e":"markdown","e5511847":"markdown","0c3ceb2f":"markdown","2dc91ca9":"markdown","9b63737c":"markdown","ba1f44fa":"markdown","77285302":"markdown","a907a17a":"markdown","edd8ada4":"markdown","d4618294":"markdown"},"source":{"2311e833":"# General-purpose Libraries\nimport numpy as np\nimport pandas as pd\nimport scipy\nimport sklearn\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom collections import Counter\nimport spacy\nfrom time import time\n%matplotlib inline\n\n# Tools for processing data\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.decomposition import TruncatedSVD, PCA\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, recall_score, classification_report, confusion_matrix, make_scorer, adjusted_rand_score, silhouette_score, homogeneity_score, normalized_mutual_info_score\n# Classifiers, supervised and unsupervised\nfrom sklearn import ensemble\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.cluster import AffinityPropagation\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","3f69c796":"# Read data into a DataFrame\ndata = pd.read_csv('..\/input\/articles1.csv')","997d8425":"# Preview the data\ndata.head(3)","8e35b609":"data.info()","69ca1bda":"lengths = pd.Series([len(x) for x in data.content])\nprint('Statistical Summary of Article Lengths')\nprint(lengths.describe())\n\nsns.distplot(lengths,kde=False)\nplt.title('Distribution of Article Lengths (All)')\nplt.show()\nsns.distplot(lengths[lengths<10000],kde=False)\nplt.title('Distribution of Articles Lengths < 10,000 Characters')\nplt.show()","a8618648":"# First ten authors with more than X articles\nprint(data.author.value_counts()[data.author.value_counts()>100][-10:])","c6232abb":"# Make a DataFrame with articles by our chosen authors\n# Include author names and article titles.\n\n# Make a list of the 10 chosen author names\nnames = data.author.value_counts()[data.author.value_counts()>100][-10:].index.tolist()\n\n# DataFrame for articles of all chosen authors\nauthors_data = pd.DataFrame()\nfor name in names:\n    # Select each author's data\n    articles = data[data.author==name][:100][['title','content','author']]\n    # Append it to the DataFrame\n    authors_data = authors_data.append(articles)\n\nauthors_data = authors_data.reset_index().drop('index',1)\n    \nauthors_data.head()","6b2e98f8":"# Look for duplicates\nprint('Number of articles:',authors_data.shape[0])\nprint('Unique articles:',len(np.unique(authors_data.index)))\n\n# Number of authors\nprint('Unique authors:',len(np.unique(authors_data.author)))\nprint('')\nprint('Articles by author:\\n')\n\n# Articles counts by author\nprint(authors_data.author.value_counts())","b15ea39d":"lengths = pd.Series([len(x) for x in authors_data.content])\nprint('Statistical Summary of Article Lengths')\nprint(lengths.describe())\n\nsns.distplot(lengths,kde=False)\nplt.title('Distribution of Article Lengths (All)')\nplt.show()\nsns.distplot(lengths[lengths<10000],kde=False)\nplt.title('Distribution of Articles Lengths < 10,000 Characters')\nplt.show()","ae4cc806":"t0 = time()\n\n# Load spacy NLP object\nnlp = spacy.load('en')\n\n# A list to store common words by all authors\ncommon_words = []\n\n# A dictionary to store the spacy_doc object of each author\nauthors_docs = {}\n\nfor name in names:\n    # Corpus is all the text written by that author\n    corpus = \"\"\n    # Grab all rows of current author, along the 'content' column\n    author_content = authors_data.loc[authors_data.author==name,'content']\n    \n    # Merge all articles in to the author's corpus\n    for article in author_content:\n        corpus = corpus + article\n    # Let Spacy parse the author's body of text\n    doc = nlp(corpus)\n    \n    # Store the doc in the dictionary\n    authors_docs[name] = doc\n        \n    # Filter out punctuation and stop words.\n    lemmas = [token.lemma_ for token in doc\n                if not token.is_punct and not token.is_stop]\n        \n    # Return the most common words of that author's corpus.\n    bow = [item[0] for item in Counter(lemmas).most_common(1000)]\n    \n    # Add them to the list of words by all authors.\n    for word in bow:\n        common_words.append(word)\n\n# Eliminate duplicates\ncommon_words = set(common_words)\n    \nprint('Total number of common words:',len(common_words))\nprint(\"done in %0.3fs\" % (time() - t0))","f49f10ad":"# Let's see our 10 authors in the dictionary\nlengths = []\nfor k,v in authors_docs.items():\n    print(k,'corpus contains',len(v),' words.')\n    lengths.append(len(v))","2ebdb7eb":"sns.barplot(x=lengths,y=names,orient='h')\nplt.title('Word Count per Author in Chosen Data')\nplt.show()","7790d0f8":"# check for lower case words\ncommon_words = pd.Series(pd.DataFrame(columns=common_words).columns)\nprint('Count of all common_words:',len(common_words))\nprint('Count of lowercase common_words:',np.sum([word.islower() for word in common_words]))\n\n# Turn all common_words into lower case\ncommon_words = [word.lower() for word in common_words]\nprint('Count of lowercase common_words (After Conversion):',np.sum([word.islower() for word in common_words]))","d7360226":"# We must remove these in to avoid conflicts with existing features.\nif 'author' in common_words:\n    common_words.remove('author')\nif 'title' in common_words:\n    common_words.remove('title')\nif 'content' in common_words:\n    common_words.remove('content')","cc1a5a1c":"# Count the number of times a common_word appears in each article\n# (about 3Hrs processing)\n\nbow_counts = pd.DataFrame()\nfor name in names:\n    # Select X articles of that author\n    articles = authors_data.loc[authors_data.author==name,:][:50]\n    bow_counts = bow_counts.append(articles)\nbow_counts = bow_counts.reset_index().drop('index',1)\n\n# Use common_words as the columns of a temporary DataFrame\ndf = pd.DataFrame(columns=common_words)\n\n# Join BOW features with the author's content\nbow_counts = bow_counts.join(df)\n\n# Initialize rows with zeroes\nbow_counts.loc[:,common_words] = 0\n\n# Fill the DataFrame with counts of each feature in each article\nt0 = time()\nfor i, article in enumerate(bow_counts.content):\n    doc = nlp(article)\n    for token in doc:\n        if token.lemma_.lower() in common_words:\n            bow_counts.loc[i,token.lemma_.lower()] += 1\n    # Print a message every X articles\n    if i % 50 == 0:\n        if time()-t0 < 3600: # if less than an hour in seconds\n            print(\"Article \",i,\" done after \",(time()-t0)\/60,' minutes.')\n        else:\n            print(\"Article \",i,\" done after \",(time()-t0)\/60\/60,' hours.')","3813dad9":"bow_counts.head(3)","503de6fe":"# This saves the long-awaited data into a pickle file for easy recovery\n#bow_counts.to_pickle('bow_counts')\n\n# Read it back in with the following\n#bow_counts = pd.read_pickle('bow_counts')","a7761a4a":"# Make sure we have 50 articles per author\nbow_counts.author.value_counts()","bf5f9bb3":"# Establish outcome and predictors\ny = bow_counts['author']\nX = bow_counts.drop(['content','author','title'], 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.24,\n                                                    random_state=0,\n                                                    stratify=y)","bcad3a56":"# Make sure classes are balanced after train-test-split\ny_test.value_counts()","0fbd474b":"# Store our results in a DataFrame\nmetrics = ['Algorithm','n_train','Features','ARI','Homogeneity',\n           'Silhouette','Mutual_Info','Cross_Val','Train_Accuracy',\n           'Test_Accuracy']\nperformance = pd.DataFrame(columns=metrics)","0fe7e49d":"# Function to quickly evaluate clustering solutions\ndef evaluate_clust(clust,params,features,i):\n    t0 = time()\n    print('\\n','-'*40,'\\n',clust.__class__.__name__,'\\n','-'*40)\n    \n    # Find best parameters based on scoring of choice\n    score = make_scorer(normalized_mutual_info_score)\n    search = GridSearchCV(clust,params,scoring=score,cv=3).fit(X,y)\n    print(\"Best parameters:\",search.best_params_)\n    y_pred = search.best_estimator_.fit_predict(X)\n\n    ari = adjusted_rand_score(y, y_pred)\n    performance.loc[i,'ARI'] = ari \n    print(\"Adjusted Rand-Index: %.3f\" % ari)\n    \n    hom = homogeneity_score(y,y_pred)\n    performance.loc[i,'Homogeneity'] = hom\n    print(\"Homogeneity Score: %.3f\" % hom)\n    \n    sil = silhouette_score(X,y_pred)\n    performance.loc[i,'Silhouette'] = sil\n    print(\"Silhouette Score: %.3f\" % sil)\n    \n    nmi = normalized_mutual_info_score(y,y_pred)\n    performance.loc[i,'Mutual_Info'] = nmi\n    print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n    \n    performance.loc[i,'n_train'] = len(X)\n    performance.loc[i,'Features'] = features\n    performance.loc[i,'Algorithm'] = clust.__class__.__name__\n    \n    # Print contingency matrix\n    crosstab = pd.crosstab(y, y_pred)\n    plt.figure(figsize=(8,5))\n    sns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\n    plt.show()\n    print(time()-t0,\"seconds.\")","781b66a9":"clust=KMeans()\nparams={\n    'n_clusters': np.arange(10,30,5),\n    'init': ['k-means++','random'],\n    'n_init':[10,20],\n    'precompute_distances':[True,False]\n}\nevaluate_clust(clust,params,features='BOW',i=0)","6e6b77df":"#Declare and fit the model\nclust = MeanShift()\n\nparams={}\nevaluate_clust(clust,params,features='BOW',i=1)","5f40a9e7":"#Declare and fit the model.\nclust = AffinityPropagation()\n\nparams = {\n    'damping':[.5,.7,.9],\n    'max_iter':[200,500]\n}\nevaluate_clust(clust,params,features='BOW',i=2)","baaaf8dc":"clust= SpectralClustering()\n\nparams = {\n    'n_clusters':np.arange(10,26,5),\n    #'eigen_solver':['arpack','lobpcg',None],\n    'n_init':[15,25],\n    'assign_labels':['kmeans','discretize']\n}\n\nfeatures='BOW'\n\ni=3\n\nt0=time()\n\ny_pred = clust.fit_predict(X)\n\nari = adjusted_rand_score(y, y_pred)\nperformance.loc[i,'ARI'] = ari \nprint(\"Adjusted Rand-Index: %.3f\" % ari)\n\nhom = homogeneity_score(y,y_pred)\nperformance.loc[i,'Homogeneity'] = hom\nprint(\"Homogeneity Score: %.3f\" % hom)\n\nsil = silhouette_score(X,y_pred)\nperformance.loc[i,'Silhouette'] = sil\nprint(\"Silhouette Score: %.3f\" % sil)\n\nnmi = normalized_mutual_info_score(y,y_pred)\nperformance.loc[i,'Mutual_Info'] = nmi\nprint(\"Normed Mutual-Info Score: %.3f\" % nmi)\n\nperformance.loc[i,'n_train'] = len(X)\nperformance.loc[i,'Features'] = features\nperformance.loc[i,'Algorithm'] = clust.__class__.__name__\n\n# Print contingency matrix\ncrosstab = pd.crosstab(y, y_pred)\nplt.figure(figsize=(8,5))\nsns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\nplt.show()\nprint(time()-t0,\"seconds.\")","1146e21e":"performance.iloc[:,:7]","c59bc470":"def score_optimization(clf,params,features,i):\n    t0 = time()\n    # Heading\n    print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n    \n    # Find best parameters based on scoring of choice\n    score = make_scorer(normalized_mutual_info_score)\n    search = GridSearchCV(clf,params,\n                          scoring=score,cv=3).fit(X,y)\n    # Extract best estimator\n    best = search.best_estimator_\n    print(\"Best parameters:\",search.best_params_)\n\n    # Cross-validate on all the data\n    cv = cross_val_score(X=X,y=y,estimator=best,cv=5)\n    print(\"\\nCross-val scores(All Data):\",cv)\n    print(\"Mean cv score:\",cv.mean())\n    performance.loc[i,'Cross_Val'] = cv.mean() \n    \n    # Get train accuracy\n    best = best.fit(X_train,y_train)\n    train = best.score(X=X_train,y=y_train)\n    performance.loc[i,'Train_Accuracy'] = train \n    print(\"\\nTrain Accuracy Score:\",train)\n\n    # Get test accuracy\n    test = best.score(X=X_test,y=y_test)\n    performance.loc[i,'Test_Accuracy'] = test \n    print(\"\\nTest Accuracy Score:\",test)\n    \n    y_pred = best.predict(X_test)\n    \n    ari = adjusted_rand_score(y_test, y_pred)\n    performance.loc[i,'ARI'] = ari \n    print(\"\\nAdjusted Rand-Index: %.3f\" % ari)\n    \n    hom = homogeneity_score(y_test,y_pred)\n    performance.loc[i,'Homogeneity'] = hom\n    print(\"Homogeneity Score: %.3f\" % hom)\n    \n    sil = silhouette_score(X_test,y_pred)\n    performance.loc[i,'Silhouette'] = sil\n    print(\"Silhouette Score: %.3f\" % sil)\n    \n    nmi = normalized_mutual_info_score(y_test,y_pred)\n    performance.loc[i,'Mutual_Info'] = nmi\n    print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n\n    #print(classification_report(y_test, y_pred))\n\n    conf_matrix = pd.crosstab(y_test,y_pred)\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n    plt.show()\n    \n    performance.loc[i,'n_train'] = len(X_train)\n    performance.loc[i,'Features'] = features\n    performance.loc[i,'Algorithm'] = clf.__class__.__name__\n    print(time()-t0,'seconds.')","47c045df":"# Parameters to optimize\nparams = [{\n    'solver': ['newton-cg', 'lbfgs', 'sag'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l2']\n    },{\n    'solver': ['liblinear','saga'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l1','l2']\n}]\n\nclf = LogisticRegression(\n    n_jobs=-1 # Use all CPU\n)\n\nscore_optimization(clf=clf,params=params,features='BOW',i=4)","9aa2103e":"# Parameters to compare\nparams = {\n    'criterion':['entropy','gini'],\n}\n\n# Implement the classifier\nclf = ensemble.RandomForestClassifier(\n    n_estimators=100,\n    max_features=None,\n    n_jobs=-1,\n)\n\nscore_optimization(clf=clf,params=params,features='BOW',i=5)","1f7f5541":"# Parameters to compare\nparams = {\n    'learning_rate':[0.3,0.5,0.7,1]\n}\n\n# Implement the classifier\nclf = ensemble.GradientBoostingClassifier(\n    max_features=None\n)\n\nscore_optimization(clf=clf,params=params,features='BOW',i=6)","11e38d1c":"performance.iloc[:7].sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']]","f7a3dfa9":"vectorizer = TfidfVectorizer(max_df=0.3, # drop words that occur in more than X percent of documents\n                             min_df=8, # only use words that appear at least X times\n                             stop_words='english', \n                             lowercase=True, #convert everything to lower case \n                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n                            )\n\n#Pass pandas series to our vectorizer model\ncounts_tfidf = vectorizer.fit_transform(bow_counts.content)\n\n","56a56cb0":"counts_tfidf","d9ab8787":"svd = TruncatedSVD(460)\nsvd.fit(counts_tfidf)\nsvd.explained_variance_ratio_.sum()","b13a6011":"lsa = make_pipeline(svd, Normalizer(copy=False))\nlsa_data = lsa.fit_transform(counts_tfidf)\nlsa_data.shape","5be006d5":"lsa_data = pd.DataFrame(lsa_data)\nlsa_data.head()","ce3c25a8":"#First, establish X and Y\ny = bow_counts['author']\nX = lsa_data\n\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y,\n                                                    test_size=0.24,\n                                                    random_state=0,\n                                                   stratify=y)","149aa304":"y_test.value_counts()","60bdf58b":"clust=KMeans()\nparams={\n    'n_clusters': np.arange(10,30,5),\n    'init': ['k-means++','random'],\n    'n_init':[10,20],\n    'precompute_distances':[True,False]\n}\nevaluate_clust(clust,params,features='LSA',i=7)","cf2985cb":"#Declare and fit the model\nclust = MeanShift()\n\nparams={\n    'bandwidth':[0.5,0.7,0.9]\n}\nevaluate_clust(clust,params,features='LSA',i=8)","ed6b8fb2":"#Declare and fit the model.\nclust = AffinityPropagation()\n\nparams = {\n    'damping':[.5,.7,.9],\n    'max_iter':[200,500]\n}\nevaluate_clust(clust,params,features='LSA',i=9)","b4cb9e24":"clust= SpectralClustering()\n\nparams = {\n    'n_clusters':np.arange(10,26,5),\n    #'eigen_solver':['arpack','lobpcg',None],\n    'n_init':[15,25],\n    'assign_labels':['kmeans','discretize']\n}\n\nfeatures='LSA'\n\ni=10\n\nt0=time()\n\ny_pred = clust.fit_predict(X)\n\nari = adjusted_rand_score(y, y_pred)\nperformance.loc[i,'ARI'] = ari \nprint(\"Adjusted Rand-Index: %.3f\" % ari)\n\nhom = homogeneity_score(y,y_pred)\nperformance.loc[i,'Homogeneity'] = hom\nprint(\"Homogeneity Score: %.3f\" % hom)\n\nsil = silhouette_score(X,y_pred)\nperformance.loc[i,'Silhouette'] = sil\nprint(\"Silhouette Score: %.3f\" % sil)\n\nnmi = normalized_mutual_info_score(y,y_pred)\nperformance.loc[i,'Mutual_Info'] = nmi\nprint(\"Normed Mutual-Info Score: %.3f\" % nmi)\n\nperformance.loc[i,'n_train'] = len(X)\nperformance.loc[i,'Features'] = features\nperformance.loc[i,'Algorithm'] = clust.__class__.__name__\n\n# Print contingency matrix\ncrosstab = pd.crosstab(y, y_pred)\nplt.figure(figsize=(8,5))\nsns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\nplt.show()\nprint(time()-t0,\"seconds.\")","d40b5f66":"performance.iloc[:11].sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']]","07ba58e4":"# Parameters to optimize\nparams = [{\n    'solver': ['newton-cg', 'lbfgs', 'sag'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l2']\n    },{\n    'solver': ['liblinear','saga'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l1','l2']\n}]\n\nclf = LogisticRegression(\n    n_jobs=-1 # Use all CPU\n)\n\nscore_optimization(clf=clf,params=params,features='LSA',i=11)","3f8763b9":"# Parameters to compare\nparams = {\n    'criterion':['entropy','gini'],\n}\n\n# Implement the classifier\nclf = ensemble.RandomForestClassifier(\n    n_estimators=100,\n    max_features=None,\n    n_jobs=-1,\n)\n\nscore_optimization(clf=clf,params=params,features='LSA',i=12)","013e50e1":"# Parameters to compare\nparams = {\n    'learning_rate':[0.3,0.5,0.7,1]\n}\n\n# Implement the classifier\nclf = ensemble.GradientBoostingClassifier(\n    max_features=None\n)\n\nscore_optimization(clf=clf,params=params,features='LSA',i=13)","31ea743b":"performance.iloc[:14].sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']].iloc[:9]","a981706b":"vectorizer = TfidfVectorizer(max_df=0.3, # drop words that occur in more than X percent of documents\n                             min_df=8, # only use words that appear at least X times\n                             stop_words='english', \n                             lowercase=True, #convert everything to lower case \n                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n                            )\n\n#Pass pandas series to our vectorizer model\ncounts_tfidf = vectorizer.fit_transform(authors_data.content)\n\n","de2db8f6":"counts_tfidf","a62941e7":"svd = TruncatedSVD(900)\nsvd.fit(counts_tfidf)\nsvd.explained_variance_ratio_.sum()","364a2cf6":"lsa = make_pipeline(svd, Normalizer(copy=False))\nlsa_data = lsa.fit_transform(counts_tfidf)\nlsa_data.shape","ab344c3c":"lsa_data = pd.DataFrame(lsa_data)\nlsa_data.head()","640001f9":"#First, establish X and Y\ny = authors_data['author']\nX = lsa_data\n\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y,\n                                                    test_size=0.24,\n                                                    random_state=0,\n                                                   stratify=y)","4557f056":"y_test.value_counts()","10e7bc69":"clust=KMeans()\nparams={\n    'n_clusters': np.arange(10,30,5),\n    'init': ['k-means++','random'],\n    'n_init':[10,20],\n    'precompute_distances':[True,False]\n}\nevaluate_clust(clust,params,features='LSA',i=14)","002ce352":"#Declare and fit the model\nclust = MeanShift()\n\nparams={\n    'bandwidth':[0.5,0.7,0.9]\n}\nevaluate_clust(clust,params,features='LSA',i=15)","f721121d":"#Declare and fit the model.\nclust = AffinityPropagation()\n\nparams = {\n    'damping':[.5,.7,.9],\n    'max_iter':[200,500]\n}\nevaluate_clust(clust,params,features='LSA',i=16)","420cd599":"clust= SpectralClustering()\n\nparams = {\n    'n_clusters':np.arange(10,26,5),\n    #'eigen_solver':['arpack','lobpcg',None],\n    'n_init':[15,25],\n    'assign_labels':['kmeans','discretize']\n}\n\nfeatures='LSA'\n\ni=17\n\nt0=time()\n\ny_pred = clust.fit_predict(X)\n\nari = adjusted_rand_score(y, y_pred)\nperformance.loc[i,'ARI'] = ari \nprint(\"Adjusted Rand-Index: %.3f\" % ari)\n\nhom = homogeneity_score(y,y_pred)\nperformance.loc[i,'Homogeneity'] = hom\nprint(\"Homogeneity Score: %.3f\" % hom)\n\nsil = silhouette_score(X,y_pred)\nperformance.loc[i,'Silhouette'] = sil\nprint(\"Silhouette Score: %.3f\" % sil)\n\nnmi = normalized_mutual_info_score(y,y_pred)\nperformance.loc[i,'Mutual_Info'] = nmi\nprint(\"Normed Mutual-Info Score: %.3f\" % nmi)\n\nperformance.loc[i,'n_train'] = len(X)\nperformance.loc[i,'Features'] = features\nperformance.loc[i,'Algorithm'] = clust.__class__.__name__\n\n# Print contingency matrix\ncrosstab = pd.crosstab(y, y_pred)\nplt.figure(figsize=(8,5))\nsns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\nplt.show()\nprint(time()-t0,\"seconds.\")","a88f0335":"# Parameters to optimize\nparams = [{\n    'solver': ['newton-cg', 'lbfgs', 'sag'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l2']\n    },{\n    'solver': ['liblinear','saga'],\n    'C': [0.3, 0.5, 0.7, 1],\n    'penalty': ['l1','l2']\n}]\n\nclf = LogisticRegression(\n    n_jobs=-1 # Use all CPU\n)\n\nscore_optimization(clf=clf,params=params,features='LSA',i=18)","4d7bd921":"# Parameters to compare\nparams = {\n    'criterion':['entropy','gini'],\n}\n\n# Implement the classifier\nclf = ensemble.RandomForestClassifier(\n    n_estimators=100,\n    max_features=None,\n    n_jobs=-1,\n)\n\nscore_optimization(clf=clf,params=params,features='LSA',i=19)","1f6b8ba2":"# Parameters to compare\nparams = {\n    'learning_rate':[0.3,0.5,0.7,1]\n}\n\n# Implement the classifier\nclf = ensemble.GradientBoostingClassifier(\n    max_features=None\n)\n\nscore_optimization(clf=clf,params=params,features='LSA',i=20)","e55a2438":"performance.sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']].iloc[:10]","3a4b8b1c":"performance.sort_values('Mutual_Info',ascending=False)[['Mutual_Info','ARI','Homogeneity','Cross_Val','Train_Accuracy','Test_Accuracy']].iloc[:10]","a438af6a":"performance.sort_values('Test_Accuracy',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']].iloc[:10]","9904d7a7":"plot_data = performance.sort_values('Test_Accuracy',ascending=False)[['Algorithm','Features','n_train','Test_Accuracy']].iloc[:9]\n\nplot_data.n_train = plot_data.n_train.apply(lambda x: str(x))\nplot_data['method'] = plot_data.Features+'_'+plot_data.n_train\n%matplotlib inline\n\nsns.catplot(col='Algorithm',x='method',y='Test_Accuracy',\n            data=plot_data,kind='bar')\nplt.show()","1d4960a0":"- This time we need 900 features to retain 98% of the variance.","ad4c6a92":"### 6.3.2. Random Forest LSA\n\n[Back to Outline](#Outline)","c5860c1f":"### 6.2.5. Spectral Clustering LSA\n\n[Back to Outline](#Outline)\n\nSpectralClustering can't be used with GridSearchCV because it lacks a .fit method. Therefore I won't use the function here.","831d412d":"### 5.4.2. Logistic Regression CBOW\n\n[Back to Outline](#Outline)","ab7fa728":"**Optional:**\n\n- Store contents of `bow_counts`","ee60e724":"### 6.3.1. Logistic Regression LSA","6e00d624":"# 6. Unsupervised Feature Generation\n\n[Back to Outline](#Outline)\n\n\n## 6.1. Latent Semantic Analysis\n\n- Different from Bag-of-Words, Latent Semantic Analysis doesn't identify the most common words present in each article. Instead it identifies thematic components present in the text. Each cell doesn't contain a count, but rather a measure of how well a given feature is exemplified by the current document.","f767fdfa":"- From a theorical total of 10,000 common-words, (1,000 from 10 authors) 3,405 were unique. So roughly a third of all words used by each author is actually part of their unique style.","e5179cd6":"**Comparing Results:**\n\nThe results of more data are mixed with other methods. The LogisticRegression LSA with 760 samples is above GradientBoosting with 380, but below LogisticRegression with 380.\n- **n_train**. Overal the 380 train size which is the 75% train split from the 500 BOW set generated higher scores than larger sizes.\n- **Features**. Overall BOW features produced higher scores than most LSA features.\n- **Supervised VS Unsupervised**. Classification produced indisputably  higher scores than clustering regardless of size or feature-generation .","3693c588":"### 6.4.4. Spectral Clustering LSA (All Content)\n\n[Back to Outline](#Outline)\n\nSpectralClustering can't be used with GridSearchCV because it lacks a .fit method. Therefore I won't use the function here.","1727cdc5":"**Checking for Missing Data**\n\n- The content feature is complete. That's the most important thing. Some author names are missing. We'll make sure to choose 10 properly labeled.","e8c861c4":"- The above is a really bad solution. 30 clusters were created but most of our articles were assigned to the first cluster.\n\n### 5.3.4. Affinity Propagation CBOW\n\n[Back to Outline](#Outline)","55321866":"### 5.4.1. Supervised Parameter Search Function\n\n- The following function will print cross-validation, train and test accuracy scores in addition to the clustering scores we've been utilizing previously.\n- The `GridSearchCV` will also find the parameters that produce the highest `Normalized Mutual Information` score.\n- There is a very clear correlation between the `Mutual_Info` score and the `Test_Accuracy` from our classifiers.\n- Notice that here the `n_train` will be smaller than in the previous section because here we are actually doing a train\/test split, whereas in the previous section we used `fit_predict(X)` on the clustering algorithms.","06c4db5d":"## 6.4. Clustering on LSA (All Content)\n\n[Back to Outline](#Outline)\n\n- Since LSA allows for very quick feature-generation, it's worth making a comparison between past results VS the utilization of all available data. After all, the LSA classifiers aren't far behind the BOW classifiers on 380 samples. With twice the number of articles LSA could very well outperform BOW. ","5fa0bc73":"### 6.4.2. Mean Shift LSA (All Content)\n\n[Back to Outline](#Outline)","a7a4b04d":"- The above solution generated too many clusters to be properly visualized. However, the `Mutual_Info` score is quite decent because datapoints may be falling onto pockets that resemble the true labels.\n\n### 5.3.5. Spectral Clustering CBOW\n\n[Back to Outline](#Outline)\n\n- SpectralClustering can't be used with GridSearchCV because it lacks a .fit method. Therefore I won't use the function here.","0cd74556":"# 4. Limit Data to Scope\n[Back to Outline](#Outline)\n\nHere I'll pick the 10 authors whose names I'll predict based on their content. This selection will remain the same for all the methods I'll compare.\n\nSince we only need 10 authors, I'll get the first 10 authors whose article-count is greater than X. 100 articles per author is a good number because more would take terribly long when fit to classifiers after `TF-IDF`. At the same time, `Bag-of-Words` is the slowest. However, for that I'll limit to 50 of these articles per author.","ec2fa191":"### 6.2.3. Mean Shift LSA\n\n[Back to Outline](#Outline)","d8aaf3bb":"### 6.5.1. Logistic Regression LSA (All Content)","0aa98f09":"### 6.2.4. Affinity Propagation LSA\n\n[Back to Outline](#Outline)","9e5cd761":"- The test data reflects the change in size.","dd93e1f6":"# 7. Choosing Model\n\n[Back to Outline](#Outline)\n\n## 7.1. Comparing Scores\n\n- Since we tracked several scores throughout our testing, let's first compare our scores. The table below is sorted by `Mutual_Info` score.\n-  The first three scores `Mutual_Info, ARI, Homogeneity` are most commonly used for clustering. `Cross_Val, Train_Accuracy, Test_Accuracy` are limited to classification. Therefore the `NaN` missing values are the clustering algorithms.\n- Notice that `Mutal_Info` scores and `Test_Accuracy` are very closely related to one another. \n    - `Homogeneity` is close as well, but it gives 0.99 for index 15, which is a clustering algorithm with several dozens of clusters. Homogeneity will reward clustering solutions with numerous `n_clusters` because it penalizes clusters containing mixed true_labels. But so many clusters are practically useless.","1c753a3a":"### 5.4.4. Gradient Boosting CBOW\n\n[Back to Outline](#Outline)","768eb688":"# 5. Supervised Feature Generation\n[Back to Outline](#Outline)\n\nBag of words is a list of the most common words of a given source of text. To identify each author, I'll create a bag of words containing the most-common words of all authors combined. This set later becomes the basis for feature engineering.\n\n## 5.1 Common Bag of Words\n- Here I'll extract the most-common 1000 words from each author's corpus, store them in a list, and then eliminate duplicates.","f48d0ef5":"### 6.5.3. Gradient Boosting LSA\n\n[Back to Outline](#Outline)","04a80e18":"# 3. Exploratory Data Analysis\n\nLet's get a quick overview of the data available.","fc82e32a":"- This is the data that we can use to train clusters and classifiers. Each entry is an article, each column is a common word, and each cell is a count of the current common word in the current article.","fc41ee75":"**Approach to Clustering**\n\nIn cluster analysis, there usually is no training or test data split. Because you do cluster analysis when you do not have labels, so you cannot \"train\".Training is a concept from machine learning, and train-test splitting is used to avoid overfitting. But if you are not learning labels, you cannot overfit. Properly used cluster analysis is a knowledge discovery method. You want to discover some new structure in your data, not rediscover something that is already labeled.","c9d5da2a":"- Notice that the content fed into the vectorizer is the same amount of data we used for BOW Counts. (500 articles in total, 50 by each author). We could use all of the 1000 articles, but first let's compare the LSA performance against BOW using the same data.\n- The vectorizer returns a CSR Matrix which can then be reduced as in PCA.","96a4302e":"## 7.2. Sorting by Test_Accuracy\n\n[Back to Outline](#Outline)\n\nAlthough we established that `Mutual_Info` and `Test_Accuracy` are very closely aligned, if we sort by `Test_Accuracy` there is a slight difference in top performers.\n- First of all, since clustering solutions have missing values they are all at the bottom.\n- All the BOW solutions are still at the top.\n- LogisticRegression 760 LSA is now above itself at 380 samples. For RandomForest however, less samples produced a higher test accuracy. Same goes for GradientBoosting underneath.","00d68c62":"# 1. Establishing Goals\n\nIn this project I'll attempt to build models to correctly predict the author of a given article. The scope will be limited to 10 authors. The techniques I'll compare will include `Bag-of-Words` VS `Latent Semantic Analysis` for feature-generation, and `Clustering` VS `Supervised Learning` for classification. I'll also experiment with different sample sizes, as feature-generation can be very sensitive to high dimensionality.\n\n# 2. Introduction to DataSet\n\n**From:** https:\/\/www.kaggle.com\/snapcrack\/all-the-news\n\nThis dataset contains news articles scraped from various publications, labeled by publication and author name, as well as date and title.\n\nThe original source on `kaggle.com` contains three `.csv` files. Accross the three, there are over 140,000 articles from a total of 15 publications. \n\nThe dataset used here is only the first of those three files, which contains about a third of all the data at roughly `280MB`. This is more than enough data for the goals of this project.","b5bb10bf":"### 5.3.2. KMeans CBOW\n\n[Back to Outline](#Outline)","bceec89f":"### 5.3.3. Mean Shift CBOW\n\n[Back to Outline](#Outline)","653f5e4b":"# Outline\n\n[1. Establishing Goals](#1.-Establishing-Goals)\n\n[2. Introduction to Dataset](#2.-Introduction-to-Dataset)\n\n[3. Exploratory Data Analysis](#3.-Exploratory-Data-Analysis)\n\n[4. Limit Data to Scope](#4.-Limit-Data-to-Scope)\n\n[5. Supervised Feature Generation](#5.-Supervised-Feature-Generation)\n    \n- [5.1 Common Bag of Words](#5.1-Common-Bag-of-Words)\n- [5.2 Turn Common Words into Features](#5.2-Turn-Common-Words-into-Features)\n- [5.3 Clustering on BOW](#5.3.-Clustering-on-BOW)\n- [5.4 Classification on BOW](#5.4.-Classification-on-BOW)\n\n[6. Unsupervised Feature Generation](#6.-Unsupervised-Feature-Generation)\n\n- [6.1 Latent Semantic Analysis](#6.1.-Latent-Semantic-Analysis)\n- [6.2 Clustering on LSA (BOW Content)](#6.2.-Clustering-on-LSA-(BOW-Content))\n- [6.3 Classification on LSA (BOW Content)](#6.3.-Classification-on-LSA-(BOW-Content))\n- [6.4 Clustering on LSA (All Content)](#6.4.-Clustering-on-LSA-(All-Content))\n- [6.5 Classification on LSA (All Content)](#6.5.-Classification-on-LSA-(All-Content))\n\n[7. Choosing Model](#7.-Choosing-Model)\n\n- [7.1 Comparing Scores](#7.1.-Comparing-Scores)\n- [7.2 Sorting by Test Accuracy](#7.2.-Sorting-by-Test_Accuracy)\n- [7.3 Winner](#7.3.-Winner)","81e32915":"## 6.5. Classification on LSA (All Content)\n\n[Back to Outline](#Outline)\n\n- We've done clustering on LSA using all 1000 articles. Now let's classify.","a6e4ba6a":"- Based on `Mutual_Info`, our highest score came from `AffinityPropagation`. However, the large number of clusters dividing our articles makes the solution a bit impractical.\n- Fortunately we can perform supervised classification on this dataset because we actually do know who wrote these articles.\n\n## 5.4. Classification on BOW\n\n[Back to Outline](#Outline)","616bd5c0":"- Notice that after converting to lowercase the total number of lowercase words still isn't the same as the total. This means there are around 100 non alphabetic words inside our bag. This is probably made up of numbers and words with punctuations within.\n\n","09188b57":"**Length of Articles**\n- In terms of number of characters, the average article has less than 4,000 letters.","1855134f":"**Results**\n\n- Once again, classification trumps clustering regardless of the feature-generation method. \n- BOW features have performed consistently better than LSA on all classifiers.","4a78dea4":"### 6.2.2. KMeans LSA\n\n[Back to Outline](#Outline)","0dd5a1e8":"### 6.4.3. Affinity Propagation LSA (All Content)\n\n[Back to Outline](#Outline)","a1b44397":"### 6.5.2. Random Forest LSA\n\n[Back to Outline](#Outline)","8e7b8905":"### 5.3.1. Unsupervised Parameter Search Function\n\n[Back to Outline](#Outline)\n\n- This function will find the parameters that produce the highest `Normalized Mutual Infomation` score from our clusters. This score is a good baseline from which to compare clustering VS classification because it correlates with good clutering as well as higher accuracy scores.\n- It'll print the relevant statistics as well as a contingency matrix of the result and lastly store our results in an external DataFrame.","76d853ae":"**Look at the Size of Articles Chosen**","c9e25385":"## 5.3. Clustering on BOW\n\n[Back to Outline](#Outline)\n\n- Before classifying, I'll start with clustering. Here I'll create clusters out of the BOW data and see if those clusters resemble the actual author's content. Clusters have no labels, but similar content tends to fall into the same clusters. Therefore in an ideal clustering solution, each author's articles would all fall into a single cluster.","2cdc990f":"## 6.2. Clustering on LSA (BOW Content)\n\n- We'll repeat the clustering and classification, now using the LSA features from the same 500 articles we used in BOW Counts.\n\n[Back to Outline](#Outline)","c9465bad":"- Notice that this time we fed all the articles into the vectorizer. See the size of the CSR Matrix underneath. The 1000 rows are 100 articles for each 10 authors.","1d8c0c7e":"- Although the clustering results didn't have a train\/test or cross-validation score, here we have a `Mutual_Info` score around twice the highest of our clusters. Above, `Mutual_Info` was very close to `Accuracy`, just two percentage points away. As we get more solutions we'll see the consistency between `Mutual_Info` and `Accuracy` among other classifiers. This will allow us to assess classification and clustering solutions by a fair mutual metric.\n\n### 5.4.3. Random Forest CBOW\n\n[Back to Outline](#Outline)","e5511847":"### 6.3.3. Gradient Boosting LSA\n\n[Back to Outline](#Outline)","0c3ceb2f":"- Reducing to 460 features will retain 98% of the explained variance.","2dc91ca9":"**DataFrame to Store our Results**\n\nThis `DataFrame` will hold results from all algorithms implemented ahead. For clustering algorithms, the train\/test and cross_val columns will be left blank because clustering requires no train\/test split. On the other hand, classifiers will inded store their own `ARI, Homogeneity, Silhouette, and Mutual_Info` scores. `Features` will represent the method for feature-engineering, whether BOW or LSA. And the `n_train` column will represent the number of samples in the train size.","9b63737c":"## 7.3. Winner\n\n[Back to Outline](#Outline)\n\n**Algorithm** \n\nClearly LogisticRegression has done a better job at predicting the author name regardless of other factors. Across varying train size and feature-generation, 3 out of the 5 top solutions are from LogisticRegression.\n\n**Feature-Generation**\n\nFor the purposes of predicting author's names, classification on BOW features has outperformed LSA. However LSA could be more appropriate for other tasks. Perhaps an author's uniqueness is more palbable from his vocabulary than from the semantics of his writing. This may explain why BOW was superior in this project.\n\n**Train_Size**\n\nTrain size produced dubious variations in LSA. More data helped LogisticRegression but made others less accurate. It would be nice to see the effects of Train size in BOW, but that takes a long time.\n\n**Score**\n\nNormalized Mutual Information is definitely the best score with which to compare clustering and classification algorithms. Other scores also also have a close resemblance, therefore I'd recommend to always compare several clustering scores.","ba1f44fa":"**Results**\n\n- Clearly classifiers obtain higher scores than clustering, this is despite being trained with less data.\n- So far `Accuracy` correlates perfectly with `Mutual_Info`.","77285302":"### 6.4.1. KMeans LSA (All Content)\n\n[Back to Outline](#Outline)","a907a17a":"## 6.3. Classification on LSA (BOW Content)\n\n[Back to Outline](#Outline)\n\n- Now we'll do supervised classification on the LSA features.","edd8ada4":"**Results (See below)**\n\n- Based on `Mutual_Info` score, classification outperforms clustering regardless of the method used for feature-generation.\n- Within the clustering solutions however, LSA produced higher scores than BOW except for SpectralClustering.","d4618294":"## 5.2 Turn Common Words into Features\n\n**Approach**\n\nDue to the curse of dimensionality, doing this step with all our 1,000 articles would take prohibitively long. (10 authors * 100 articles\/ea = 1,000 articles)  At 30 seconds per article, my personal machine would need 8.5 hours of processing. Therefore I'll limit this part to 50 articles per author. This should still convey enough information for a decent predictive model.\n\n**About 'Common Bag of Words'**\n\nThis technique consists of creating a feature out of each common word and then counting the number of times each common word appears in each article. Each cell will represent the number of times the lemma of the given column appears in the article of the current row. We have over 3,000 common words, and will be using 500 articles total. (50 per author) Plus each article may have a varying number of words in it. That's a lot of text to compare and count."}}