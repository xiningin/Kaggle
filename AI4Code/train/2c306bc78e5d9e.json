{"cell_type":{"250b56b5":"code","05f0a885":"code","3f92ef99":"code","11726200":"code","e7806c4c":"code","7c4877b6":"code","d04b89d6":"code","07694cf7":"code","3a0d05e6":"code","e0adda5f":"code","f3b51d4a":"code","70a55fa7":"code","9aa616c5":"code","f2addd53":"code","4c17cb56":"code","5ba54f79":"code","80dea43f":"code","fb0d5605":"code","558acde7":"code","0b55fa5f":"code","3e010a10":"markdown","2b986a8b":"markdown","50882417":"markdown","c566018f":"markdown","1f76d686":"markdown","d961085d":"markdown","ba1b9a94":"markdown","2d4f5474":"markdown"},"source":{"250b56b5":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.metrics import accuracy_score","05f0a885":"data = pd.read_csv('..\/input\/did-it-rain-in-seattle-19482017\/seattleWeather_1948-2017.csv')","3f92ef99":"data","11726200":"data.info()","e7806c4c":"data.isna().sum()","7c4877b6":"data","d04b89d6":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop missing rows\n    df = df.dropna(axis=0).reset_index(drop=True)\n    \n    # Convert RAIN column to numeric\n    df['RAIN'] = df['RAIN'].astype(np.int)\n    \n    # Extract date features\n    df['DATE'] = pd.to_datetime(df['DATE'])\n    \n    df['YEAR'] = df['DATE'].apply(lambda x: x.year)\n    df['MONTH'] = df['DATE'].apply(lambda x: x.month)\n    df['DAY'] = df['DATE'].apply(lambda x: x.day)\n    \n    df = df.drop('DATE', axis=1)\n    \n    # Split df into X and y\n    y = df['PRCP']\n    X = df.drop('PRCP', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","07694cf7":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","3a0d05e6":"X_train","e0adda5f":"y_train","f3b51d4a":"models = {\n    \"                     Linear Regression\": LinearRegression(),\n    \"      L2 Regularized Linear Regression\": Ridge(),\n    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n    \"                         Decision Tree\": DecisionTreeRegressor(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n    \"                        Neural Network\": MLPRegressor(),\n    \"                         Random Forest\": RandomForestRegressor(),\n    \"                     Gradient Boosting\": GradientBoostingRegressor(),\n    \"                               XGBoost\": XGBRegressor(),\n    \"                              LightGBM\": LGBMRegressor(),\n    \"                              CatBoost\": CatBoostRegressor(verbose=0)\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","70a55fa7":"for name, model in models.items():\n    print(name + \" R^2: {:.5f}\".format(model.score(X_test, y_test)))","9aa616c5":"corr = pd.concat([X_train, y_train], axis=1).corr()\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(corr, annot=True, vmin=-1.0, cmap='mako')\nplt.show()","f2addd53":"def preprocess_inputs_clf(df):\n    df = df.copy()\n    \n    # Drop missing rows\n    df = df.dropna(axis=0).reset_index(drop=True)\n    \n    # Convert RAIN column to numeric\n    df['RAIN'] = df['RAIN'].astype(np.int)\n    \n    # Drop all features except PRCP\n    df = df.drop(['DATE', 'TMAX', 'TMIN'], axis=1)\n    \n    # Split df into X and y\n    y = df['RAIN']\n    X = df.drop('RAIN', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    return X_train, X_test, y_train, y_test","4c17cb56":"X_train, X_test, y_train, y_test = preprocess_inputs_clf(data)","5ba54f79":"X_train","80dea43f":"y_train","fb0d5605":"clf = SVC()\nclf.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {:.2f}%\".format(clf.score(X_test, y_test) * 100))","558acde7":"X_test","0b55fa5f":"y_pred = X_test > 0\ny_pred = np.squeeze(np.array(y_pred, dtype=np.int))\n\nprint(\"Test Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))","3e010a10":"# Examining Correlations","2b986a8b":"# Preprocessing","50882417":"# Classifying using a simple function","c566018f":"# Task for Today  \n\n***\n\n## Seattle Rain Prediction  \n\nGiven *data about weather in Seattle*, let's try to predict how much it will **rain** on a given day.  \n  \nWe will use a variety of regression models to make our predictions.","1f76d686":"# Predicting the PRCP column","d961085d":"# Getting Started","ba1b9a94":"# Predicting the RAIN column","2d4f5474":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/H1i7d3XMzrY"}}