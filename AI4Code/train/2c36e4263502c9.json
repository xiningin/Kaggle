{"cell_type":{"e793fd32":"code","1a731cb6":"code","cc23a794":"code","cfa08af6":"code","dc564cd3":"code","b7899dfd":"code","7c0b3227":"code","c1b5c6cb":"code","1ad6c174":"code","e2c9611e":"code","bd1923da":"code","9137c0cc":"code","cae1bf74":"code","5a7fc039":"code","dbe0e078":"code","0566a90b":"code","1b46c47a":"code","b022570e":"code","d2ead35d":"code","cff9291b":"code","d3978134":"code","a28c7cb2":"code","6508325e":"code","e882aa19":"code","8be899fa":"code","eed0b607":"code","e166a8eb":"code","b0bf147f":"code","ebc4a6c0":"code","74ce8e49":"code","6bb47c30":"code","68c2cbf8":"code","a3dd2ae1":"code","b516a2a0":"code","eccad14d":"code","dbccc738":"code","3aea4567":"code","df29f3a7":"code","447d8695":"code","15eaa206":"code","669705a6":"code","783edd91":"code","d1a80edf":"code","d046471b":"code","864db679":"markdown","9cad86c7":"markdown","bbcf510b":"markdown","a0af6f99":"markdown","750b9bd7":"markdown","01484b7c":"markdown","63184b4c":"markdown","63322dea":"markdown","8e40044e":"markdown","aaf6611f":"markdown","7f856622":"markdown","a5a98d70":"markdown","483caf2a":"markdown"},"source":{"e793fd32":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nsns.set(rc={'figure.figsize':(18,16)})\n\nimport matplotlib.pyplot as plt","1a731cb6":"include_seasons = False\nUse_orig_data = True","cc23a794":"df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv\", index_col=  'date_time' , parse_dates=True)\ndf.head()","cfa08af6":"mdf = pd.read_csv('..\/input\/air-quality-tps-july-data\/AirQualityUCI_with_missing_data.csv')\n#mdf.info()\n#mdf\n\nnew_df = pd.DataFrame(columns = df.columns)\n\n#Date \tTime \t\nnew_df['target_carbon_monoxide'] = mdf['CO(GT)']\t \t\n#NMHC(GT) \t\nnew_df['target_benzene'] = mdf['C6H6(GT)'] \nnew_df['target_nitrogen_oxides'] = mdf['NOx(GT)'] \t \t\n#NO2(GT) \t\n\nnew_df['sensor_1'] = mdf['PT08.S1(CO)']      #Carbon monoxide\nnew_df['sensor_2'] = mdf['PT08.S2(NMHC)']    #Benzene\nnew_df['sensor_3'] = mdf['PT08.S3(NOx)'] \nnew_df['sensor_4'] = mdf['PT08.S4(NO2)']  \t\nnew_df['sensor_5'] = mdf['PT08.S5(O3)'] \nnew_df['deg_C'] = mdf['T'].astype(\"float\")\nnew_df['relative_humidity'] = mdf['RH']  \t\nnew_df['absolute_humidity'] = mdf['AH'] \n\n\nnew_df.head()","dc564cd3":"my_colors = ['#DC143C', '#FF1493', '#FF7F50', '#FFD700', '#32CD32', \n             '#4ddbff', '#1E90FF', '#663399', '#708090']\n\ndf = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv\", parse_dates=True)\ndf = df[df.columns[1:]]\ndf\n\ndf.describe().T.style.background_gradient(subset = ['count'], cmap = 'viridis') \\\n    .bar(subset = ['mean', '50%'], color = my_colors[6]) \\\n    .bar(subset = ['std'], color = my_colors[0])","b7899dfd":"new_df.describe().T.style.background_gradient(subset = ['count'], cmap = 'viridis') \\\n    .bar(subset = ['mean', '50%'], color = my_colors[6]) \\\n    .bar(subset = ['std'], color = my_colors[0])","7c0b3227":"fig = plt.figure(figsize = (20, 15))\nfig.suptitle('TPS July 2021 - Provided data', size = 25, weight = 'bold')\nfor idx, i in enumerate(df.columns):\n    fig.add_subplot(np.ceil(len(df.columns)\/4), 4, idx+1)\n    df.iloc[:, idx].hist(bins = 20)\n    plt.title(i)\nplt.show()","c1b5c6cb":"fig = plt.figure(figsize = (20, 15))\nfig.suptitle('Air quality dataset - Original data', size = 25, weight = 'bold')\nfor idx, i in enumerate(new_df.columns):\n    fig.add_subplot(np.ceil(len(new_df.columns)\/4), 4, idx+1)\n    new_df.iloc[:, idx].hist(bins = 20)\n    plt.title(i)\nplt.show()","1ad6c174":"sns.heatmap(df.corr() , annot = True )","e2c9611e":"sns.heatmap(new_df.corr() , annot = True)","bd1923da":"sns.set_theme(style=\"dark\")","9137c0cc":"df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv\", index_col=  'date_time' , parse_dates=True)\n\ndf['dayoftheweek'] = df.index.dayofweek #Weekly Seasonality\ndf['hourofday'] = df.index.hour #Daily Seasonality\n#df['time'] = df.index.astype(np.int64) #Yearly Trend|\ndf['time'] = df.index.date - df.index.date.min()\ndf['time'] = df['time'].apply(lambda x : x.days)\n\n\n#Features that are useless but needed to find other features\ndf['month'] = df.index.month.astype(\"int\")\n\ndf[\"is_weekend\"] = (df.index.dayofweek >= 5).astype(\"int\")\n\nif include_seasons == True:    \n    df[\"is_winter\"] = df[\"month\"].isin([1, 2, 12])\n    df[\"is_sprint\"] = df[\"month\"].isin([3, 4, 5])\n    df[\"is_summer\"] = df[\"month\"].isin([6, 7, 8])\n    df[\"is_autumn\"] = df[\"month\"].isin([9, 10, 11])\n\n\ndf[\"working_hours\"] =  df[\"hourofday\"].isin(np.arange(8, 21, 1)).astype(\"int\")\n\ndf[\"morning_peak_hour\"] =  df[\"hourofday\"].isin(np.arange(7, 10, 1)).astype(\"int\")\ndf[\"evening_peak_hour\"] =  df[\"hourofday\"].isin(np.arange(17, 21, 1)).astype(\"int\")\n\ndf['SMC'] = (df['absolute_humidity'] * 100) \/ df['relative_humidity']\ndf['Dew_Point'] = 243.12*(np.log(df['relative_humidity'] * 0.01) + \n                          (17.62 * df['deg_C'])\/(243.12+df['deg_C']))\/(17.62-(np.log(df['relative_humidity'] * 0.01)+17.62*df['deg_C']\/(243.12+df['deg_C'])))\n\ndf.to_csv('modefied_train.csv')\n\ndf.tail()","cae1bf74":"#New features\n\nnew_df['date_time'] = mdf['Date'] +' ' +  mdf['Time']\nnew_df['date_time'] = pd.to_datetime(new_df['date_time'])\n\nnew_df['dayoftheweek'] =  new_df['date_time'].dt.dayofweek #Weekly Seasonality\nnew_df['hourofday'] =  new_df['date_time'].dt.hour #Daily Seasonality\n#new_df['time'] =  new_df['date_time'].astype(np.int64) #Yearly Trend|\nnew_df['time'] = new_df['date_time'].dt.date - new_df['date_time'].dt.date.min()\nnew_df['time'] = new_df['time'].apply(lambda x : x.days)\n\n\n#Features that are useless but needed to find other features\nnew_df['month'] =  new_df['date_time'].dt.month.astype(\"int\")\n\nnew_df[\"is_weekend\"] = ( new_df['date_time'].dt.dayofweek >= 5).astype(\"int\")\nif include_seasons == True:\n    new_df[\"is_winter\"] = new_df[\"month\"].isin([1, 2, 12])\n    new_df[\"is_sprint\"] = new_df[\"month\"].isin([3, 4, 5])\n    new_df[\"is_summer\"] = new_df[\"month\"].isin([6, 7, 8])\n    new_df[\"is_autumn\"] = new_df[\"month\"].isin([9, 10, 11])\n\n\nnew_df[\"morning_peak_hour\"] =  new_df[\"hourofday\"].isin(np.arange(7, 10, 1)).astype(\"int\")\nnew_df[\"evening_peak_hour\"] =  new_df[\"hourofday\"].isin(np.arange(17, 21, 1)).astype(\"int\")\n\nnew_df['SMC'] = (new_df['absolute_humidity'] * 100) \/ new_df['relative_humidity']\n\nnew_df[\"working_hours\"] =  new_df[\"hourofday\"].isin(np.arange(8, 21, 1)) #.astype(\"int\")\n\nnew_df['Dew_Point'] = 243.12*(np.log(new_df['relative_humidity'] * 0.01) + \n                          (17.62 * new_df['deg_C'])\/(243.12+new_df['deg_C']))\/(17.62-(np.log(new_df['relative_humidity'] * 0.01)+17.62*new_df['deg_C']\/(243.12+new_df['deg_C'])))\n\nnew_df.to_csv('Orignal_data_new_features_added.csv')\nnew_df.head()","5a7fc039":"def Plot_diff_log_versions( y_data , hue_data):\n    total_plots = 5\n    \n    sensor_data = ['sensor_1' , 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\n    \n    for x_col in sensor_data:\n        \n        plt.figure(figsize = (20,4))\n        x = df[x_col]\n        \n        plt.subplot(1,total_plots,1)\n        y = y_data\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target Normal')\n\n        plt.subplot(1,total_plots,2)\n        y = np.log(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + '  Target Log')\n\n        plt.subplot(1,total_plots,3)\n        y = np.log1p(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target Log1p')\n\n        plt.subplot(1,total_plots,4)\n        y = np.sqrt(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target sqrt')\n\n        plt.subplot(1,total_plots,5)\n        y = np.sqrt(y_data)\n        y = np.log(y)\n        sns.scatterplot(x = x , y = y, hue = hue_data )\n        plt.title(x_col + ' Target sqrt + Log')\n    ","dbe0e078":"y_data = df['target_benzene']\nPlot_diff_log_versions( y_data )","0566a90b":"def Plot_diff_versions_and_sub_versions( y_data1 , y_data2 , hue_data):\n    total_plots = 10\n    \n    sensor_data = ['sensor_1' , 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\n    \n    for x_col in sensor_data:\n        \n        plt.figure(figsize = (40,4))\n        x = df[x_col]\n        \n        \n        y_data = y_data1\n        \n        plt.subplot(1,total_plots,1)\n        y = y_data\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target Normal')\n\n        plt.subplot(1,total_plots,2)\n        y = np.log(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + '  Target Log')\n\n        plt.subplot(1,total_plots,3)\n        y = np.log1p(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target Log1p')\n\n        plt.subplot(1,total_plots,4)\n        y = np.sqrt(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target sqrt')\n\n        plt.subplot(1,total_plots,5)\n        y = np.sqrt(y_data)\n        y = np.log(y)\n        sns.scatterplot(x = x , y = y, hue = hue_data )\n        plt.title(x_col + ' Target sqrt + Log')\n        \n        \n        y_data = y_data2\n        \n        plt.subplot(1,total_plots,6)\n        y = y_data\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target Normal')\n\n        plt.subplot(1,total_plots,7)\n        y = np.log(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + '  Target Log')\n\n        plt.subplot(1,total_plots,8)\n        y = np.log1p(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target Log1p')\n\n        plt.subplot(1,total_plots,9)\n        y = np.sqrt(y_data)\n        sns.scatterplot(x = x , y = y , hue = hue_data)\n        plt.title(x_col + ' Target sqrt')\n\n        plt.subplot(1,total_plots,10)\n        y = np.sqrt(y_data)\n        y = np.log(y)\n        sns.scatterplot(x = x , y = y, hue = hue_data )\n        plt.title(x_col + ' Target sqrt + Log')\n    ","1b46c47a":"y_data1 = df['target_benzene'].loc[df['working_hours'] == 0]\ny_data2 = df['target_benzene'].loc[df['working_hours'] == 1]\nhue_data = df['working_hours']\n\nPlot_diff_versions_and_sub_versions( y_data1 , y_data2 , hue_data)","b022570e":"y_data = df['target_carbon_monoxide']\nPlot_diff_log_versions( y_data )","d2ead35d":"df.columns","cff9291b":"df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv\", index_col=  'date_time' , parse_dates=True)\n\ndf['dayoftheweek'] = df.index.dayofweek #Weekly Seasonality\ndf['hourofday'] = df.index.hour #Daily Seasonality\n#df['time'] = df.index.date - df.index.date.min()\n#df['time'] = df['time'].apply(lambda x : x.days)\n\n\n#Features that are useless but needed to find other features\n#df['month'] = df.index.month.astype(\"int\")\n\ndf[\"is_weekend\"] = (df.index.dayofweek >= 5).astype(\"int\")\n\nif include_seasons == True:    \n    df[\"is_winter\"] = df[\"month\"].isin([1, 2, 12])\n    df[\"is_sprint\"] = df[\"month\"].isin([3, 4, 5])\n    df[\"is_summer\"] = df[\"month\"].isin([6, 7, 8])\n    df[\"is_autumn\"] = df[\"month\"].isin([9, 10, 11])\n\n\ndf[\"working_hours\"] =  df[\"hourofday\"].isin(np.arange(8, 21, 1)).astype(\"int\")\n\n#df[\"morning_peak_hour\"] =  df[\"hourofday\"].isin(np.arange(7, 10, 1)).astype(\"int\")\n#df[\"evening_peak_hour\"] =  df[\"hourofday\"].isin(np.arange(17, 21, 1)).astype(\"int\")\n\n#df['SMC'] = (df['absolute_humidity'] * 100) \/ df['relative_humidity']\n#df['Dew_Point'] = 243.12*(np.log(df['relative_humidity'] * 0.01) + \n#                          (17.62 * df['deg_C'])\/(243.12+df['deg_C']))\/(17.62-(np.log(df['relative_humidity'] * 0.01)+17.62*df['deg_C']\/(243.12+df['deg_C'])))\n\ndf.head()\n","d3978134":"sns.pairplot(df ,  y_vars = target , hue='hourofday')","a28c7cb2":"\nsns.pairplot(df ,  y_vars = target , hue='working_hours')","6508325e":"sns.pairplot(df ,  y_vars = target , hue='is_weekend')","e882aa19":"target = ['target_carbon_monoxide','target_benzene', 'target_nitrogen_oxides']\n\n\n'''train_features = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1',\n       'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n#       'target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides',\n#       'date_time',\n            'dayoftheweek', 'hourofday', \n#                  'time', 'month', \n                  'is_weekend',\n       'working_hours', 'SMC', 'Dew_Point']'''\n\ntrain_features = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1',\n       'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n#       'target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides',\n       'dayoftheweek', 'hourofday', 'time', 'month', 'is_weekend',\n       'working_hours', 'morning_peak_hour', 'evening_peak_hour' , 'SMC', 'Dew_Point']\n\nnew_df = new_df[train_features + target]\nnew_df","8be899fa":"if Use_orig_data == True:\n    df = pd.concat([df , new_df])\n    df\n\ntarget = ['target_carbon_monoxide','target_benzene', 'target_nitrogen_oxides']\n\ndef log_scaling(col):\n  col = np.log(col)\n  return col\n\ndef log_scaling_1p(col):\n  col = np.log1p(col)\n  return col\n\ndf[target[0]] = log_scaling(df[target[0]])\ndf[target[1]] = log_scaling(df[target[1]])\ndf[target[2]] = log_scaling(df[target[2]])\ndf[target].describe()","eed0b607":"test = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv', index_col='date_time', parse_dates=True)\ntest['dayoftheweek'] = test.index.dayofweek\ntest['hourofday'] = test.index.hour\n#test['time'] = test.index.astype(np.int64)\ntest['month'] = test.index.month.astype(\"int\")\n\n#new_df['time'] =  new_df['date_time'].astype(np.int64) #Yearly Trend|\ntest['time'] = test.index.date - test.index.date.min()\ntest['time'] = test['time'].apply(lambda x : x.days)\n\n\ntest[\"morning_peak_hour\"] =  test[\"hourofday\"].isin(np.arange(7, 10, 1)).astype(\"int\")\ntest[\"evening_peak_hour\"] =  test[\"hourofday\"].isin(np.arange(17, 21, 1)).astype(\"int\")\n\n\n\ntest[\"is_weekend\"] = (test.index.dayofweek >= 5).astype(\"int\")\nif include_seasons == True:\n    test[\"is_winter\"] = test[\"month\"].isin([1, 2, 12])\n    test[\"is_sprint\"] = test[\"month\"].isin([3, 4, 5])\n    test[\"is_summer\"] = test[\"month\"].isin([6, 7, 8])\n    test[\"is_autumn\"] = test[\"month\"].isin([9, 10, 11])\n\ntest[\"working_hours\"] =  test[\"hourofday\"].isin(np.arange(8, 21, 1)).astype(\"int\")\ntest['SMC'] = (test['absolute_humidity'] * 100) \/ test['relative_humidity']\ntest['Dew_Point'] = 243.12*(np.log(test['relative_humidity'] * 0.01) + \n                          (17.62 * test['deg_C'])\/(243.12+test['deg_C']))\/(17.62-(np.log(test['relative_humidity'] * 0.01)+17.62*test['deg_C']\/(243.12+test['deg_C'])))\n\n#t = TabularDataset(test)\n#t.head()","e166a8eb":"train_df = df\ntest_df = test","b0bf147f":"train_df","ebc4a6c0":"!pip -q install \"mxnet<2.0.0\"\n!pip -q install autogluon","74ce8e49":"from autogluon.tabular import TabularDataset , TabularPredictor","6bb47c30":"train_df.columns","68c2cbf8":"tr","a3dd2ae1":"TIME_LIMIT = 300\n\nfeature = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1',\n       'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n#       'target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides',\n       'dayoftheweek', 'hourofday', 'time', 'month', 'is_weekend',\n       'working_hours', 'morning_peak_hour','evening_peak_hour', 'SMC', 'Dew_Point']\nprint(len(feature))","b516a2a0":"feature = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1',\n       'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n#       'target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides',\n       'dayoftheweek', 'hourofday', 'time', 'month', 'is_weekend',\n       'working_hours', 'morning_peak_hour','evening_peak_hour', 'SMC', 'Dew_Point']\n\nlabel = target[0]\ntrain_data = train_df[feature + [label]]\n\nprint('Starting training for' , label)\nsave_path = '.\/predictor0\/'\npredictor0 = TabularPredictor(label = label , path = save_path , verbosity=2).fit(train_data ,presets='best_quality', \n                                                num_stack_levels = 3,  num_bag_folds = 5, num_bag_sets = 3,time_limit=TIME_LIMIT)\n\nprint()\n\n\n\n","eccad14d":"feature = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1',\n       'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n#       'target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides',\n       'dayoftheweek', 'hourofday', 'time', 'month', 'is_weekend',\n       'working_hours', 'morning_peak_hour','evening_peak_hour', 'SMC', 'Dew_Point']\n\nlabel = target[1]\ntrain_data = train_df[feature + [label]]\nsave_path = '.\/predictor1\/'\nprint('Starting training for' , label)\npredictor1 = TabularPredictor(label = label , path = save_path , verbosity=2).fit(train_data ,presets='best_quality', \n                              num_stack_levels = 3,  num_bag_folds = 5, num_bag_sets = 3,time_limit=TIME_LIMIT)\nprint()\n\n\n\n","dbccc738":"feature = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1',\n       'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n#       'target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides',\n       'dayoftheweek', 'hourofday', 'time', 'month', 'is_weekend',\n       'working_hours', 'morning_peak_hour','evening_peak_hour', 'SMC', 'Dew_Point']\n\nlabel = target[2]\ntrain_data = train_df[feature + [target[2]]]\nsave_path = '.\/predictor2\/'\nprint('Starting training for' ,  label)\n\npredictor2 = TabularPredictor(label = label , path = save_path , verbosity=2).fit(train_data ,presets='best_quality', \n                              num_stack_levels = 3,  num_bag_folds = 5, num_bag_sets = 3,time_limit=TIME_LIMIT)\nprint()","3aea4567":"predictions0 = predictor0.predict(test_df)\npredictions0 = np.exp(predictions0)\n\npredictions1 = predictor1.predict(test_df)\npredictions1 = np.exp(predictions1)\n\npredictions2 = predictor2.predict(test_df)\npredictions2 = np.exp(predictions2)\n\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\n\nsubmission[target[0]] = np.vstack( [predictions0] ).T\nsubmission[target[1]] = np.vstack( [predictions1] ).T\nsubmission[target[2]] = np.vstack( [predictions2] ).T\nsubmission.to_csv('.\/1_submission.csv', index=False)\nsubmission","df29f3a7":"predictor0.delete_models(models_to_keep='best', dry_run=False)\npredictor1.delete_models(models_to_keep='best', dry_run=False)\npredictor2.delete_models(models_to_keep='best', dry_run=False)\n\npredictor0.save_space()\npredictor1.save_space()\npredictor2.save_space()\n","447d8695":"predictor0.leaderboard()\npredictor1.leaderboard()\npredictor2.leaderboard()","15eaa206":"label = target[2]\ntrain_data = train_df[feature + [target[2]]]\ntrain_data","669705a6":"label = target[0]\ntrain_data = train_df[feature + target]\ntrain_sample = train_data.sample(500)","783edd91":"predictor0.feature_importance(train_sample)","d1a80edf":"predictor1.feature_importance(train_sample)","d046471b":"predictor2.feature_importance(train_sample)","864db679":"# The Original dataset - Air Quality  -  [Link to dataset](https:\/\/www.kaggle.com\/amritpal333\/tps-july-2021-original-data)","9cad86c7":"### As we can see, both of them have similar featutes!","bbcf510b":"# Model Training - AutoGluon\n\nWe can now begin the AutoML process.\nNote that in this kaggle notebook I severely reduced the time limit on the autoML process, so please increase it if you intend to follow it","a0af6f99":"# Lets delete some files to save space for Kaggle ","750b9bd7":"# Log scaling data","01484b7c":"\n\nThe dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. \n\n**Missing values are tagged with -200 value**\nThis dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\n\n### Attribute Information:\n\n- 0 Date (DD\/MM\/YYYY)\n- 1 Time (HH.MM.SS)\n- 2 True hourly averaged concentration CO in mg\/m^3 (reference analyzer)\n- 3 PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)\n- 4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg\/m^3 (reference analyzer)\n- 5 True hourly averaged Benzene concentration in microg\/m^3 (reference analyzer)\n- 6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\n- 7 True hourly averaged NOx concentration in ppb (reference analyzer)\n- 8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted)\n- 9 True hourly averaged NO2 concentration in microg\/m^3 (reference analyzer)\n- 10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\n- 11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)\n- 12 Temperature in \u00c2\u00b0C\n- 13 Relative Humidity (%)\n- 14 AH Absolute Humidity ","63184b4c":"# Feature engineering","63322dea":"# Loading test files","8e40044e":"##  Lets first load the dataset provided to us in the TPS july 2021 competition ","aaf6611f":"# Distribution of both the data","7f856622":"### Yet again we find that both the datasets have exactly the same distribution.","a5a98d70":"# Histogram plots","483caf2a":"# Heatmaps"}}