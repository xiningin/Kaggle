{"cell_type":{"3017b78c":"code","2ecf2d6f":"code","ef88d9db":"code","b7dde4cc":"code","ae3b99e4":"code","ed9bd1ad":"code","a30c781f":"code","4bf4c705":"code","c63f8da9":"code","e7b56c89":"code","e1b5ae5c":"code","0c9a5624":"code","e919b933":"code","5e55f5d6":"code","ea0b5141":"code","c4926e92":"code","c5cce7cc":"code","6840be90":"code","7c36dfd3":"code","536a3a9b":"code","bdab90b5":"code","123d8d3b":"code","d6a2e4e2":"code","e3f71afa":"code","d7d0864f":"code","36116bd8":"markdown","c5318aee":"markdown","66e81d02":"markdown","7f2171d3":"markdown","6bacb7e0":"markdown","3be7780e":"markdown","1fc939db":"markdown","8dc07388":"markdown","53f78b71":"markdown","f31d6d93":"markdown","fcc7624e":"markdown","1d53e67f":"markdown","38b07d63":"markdown","8e080045":"markdown","51b5003e":"markdown","65334902":"markdown","79d59a55":"markdown"},"source":{"3017b78c":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set()\n\nfrom sklearn.model_selection import GroupKFold, KFold\nfrom sklearn.metrics import log_loss\nimport lightgbm as lgb","2ecf2d6f":"DATA_DIR = '..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/'\n\nSTAGE_1 = False # This needs to be False when it's stage 2 ","ef88d9db":"MRSCResults = pd.read_csv(DATA_DIR + '\/MRegularSeasonCompactResults.csv')\n\nA_w = MRSCResults[MRSCResults.WLoc == 'A']\\\n    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n    .rename(columns={\"WTeamID\": \"win_A\"})\nN_w = MRSCResults[MRSCResults.WLoc == 'N']\\\n    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n    .rename(columns={\"WTeamID\": \"win_N\"})\nH_w = MRSCResults[MRSCResults.WLoc == 'H']\\\n    .groupby(['Season','WTeamID'])['WTeamID'].count().to_frame()\\\n    .rename(columns={\"WTeamID\": \"win_H\"})\nwin = A_w.join(N_w, how='outer').join(H_w, how='outer').fillna(0)\n\nH_l = MRSCResults[MRSCResults.WLoc == 'A']\\\n    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n    .rename(columns={\"LTeamID\": \"lost_H\"})\nN_l = MRSCResults[MRSCResults.WLoc == 'N']\\\n    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n    .rename(columns={\"LTeamID\": \"lost_N\"})\nA_l = MRSCResults[MRSCResults.WLoc == 'H']\\\n    .groupby(['Season','LTeamID'])['LTeamID'].count().to_frame()\\\n    .rename(columns={\"LTeamID\": \"lost_A\"})\nlost = A_l.join(N_l, how='outer').join(H_l, how='outer').fillna(0)\n\nwin.index = win.index.rename(['Season', 'TeamID'])\nlost.index = lost.index.rename(['Season', 'TeamID'])\nwl = win.join(lost, how='outer').reset_index()\nwl['win_pct_A'] = wl['win_A'] \/ (wl['win_A'] + wl['lost_A'])\nwl['win_pct_N'] = wl['win_N'] \/ (wl['win_N'] + wl['lost_N'])\nwl['win_pct_H'] = wl['win_H'] \/ (wl['win_H'] + wl['lost_H'])\nwl['win_pct_All'] = (wl['win_A'] + wl['win_N'] + wl['win_H']) \/ \\\n    (wl['win_A'] + wl['win_N'] + wl['win_H'] + wl['lost_A']\\\n     + wl['lost_N'] + wl['lost_H'])\n\ndel A_w, N_w, H_w, H_l, N_l, A_l, win, lost","b7dde4cc":"MRSCResults['relScore'] = MRSCResults.WScore - MRSCResults.LScore\n\nw_scr = MRSCResults.loc[:, ['Season', 'WTeamID', 'WScore', 'WLoc','relScore']]\nw_scr.columns = ['Season', 'TeamID','Score','Loc','relScore']\nl_scr = MRSCResults.loc[:, ['Season', 'LTeamID', 'LScore', 'WLoc','relScore']]\nl_scr['WLoc'] = l_scr.WLoc.apply(lambda x: 'H' if x == 'A' else 'A' \\\n                                 if x == 'H' else 'N')\nl_scr['relScore'] = -1 * l_scr.relScore \nl_scr.columns = ['Season', 'TeamID','Score','Loc','relScore']\nwl_scr = pd.concat([w_scr,l_scr])\n\nA_scr = wl_scr[wl_scr.Loc == 'A'].groupby(['Season','TeamID'])\\\n        ['Score','relScore'].mean()\\\n        .rename(columns={\"Score\": \"Score_A\", \"relScore\": \"relScore_A\"})\nN_scr = wl_scr[wl_scr.Loc == 'N'].groupby(['Season','TeamID'])\\\n        ['Score','relScore'].mean()\\\n        .rename(columns={\"Score\": \"Score_N\", \"relScore\": \"relScore_N\"})\nH_scr = wl_scr[wl_scr.Loc == 'H'].groupby(['Season','TeamID'])\\\n        ['Score','relScore'].mean()\\\n        .rename(columns={\"Score\": \"Score_H\", \"relScore\": \"relScore_H\"})\nAll_scr = wl_scr.groupby(['Season','TeamID'])['Score','relScore']\\\n    .mean().rename(columns={\"Score\": \"Score_All\", \"relScore\": \"relScore_All\"})\nscr = A_scr.join(N_scr, how='outer').join(H_scr, how='outer')\\\n    .join(All_scr, how='outer').fillna(0).reset_index()\n\ndel w_scr, l_scr, wl_scr, A_scr, H_scr, N_scr, All_scr","ae3b99e4":"MRSDetailedResults = pd.read_csv(DATA_DIR + '\/MRegularSeasonDetailedResults.csv')\n\nw = MRSDetailedResults.loc[:, ['Season', 'WTeamID', 'WFGM','WFGA','WFGM3'\n                               ,'WFGA3','WFTM','WFTA','WOR','WDR','WAst',\n                               'WTO','WStl','WBlk','WPF']]\nw.columns = ['Season', 'TeamID', 'FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR',\n             'Ast','TO','Stl','Blk','PF']\nl = MRSDetailedResults.loc[:, ['Season', 'LTeamID', 'LFGM','LFGA','LFGM3',\n                               'LFGA3','LFTM','LFTA','LOR','LDR','LAst',\n                               'LTO','LStl','LBlk','LPF']]\nl.columns = ['Season', 'TeamID', 'FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR',\n             'Ast','TO','Stl','Blk','PF']\n\ndetail = pd.concat([w,l])\ndetail['goal_rate'] = detail.FGM \/ detail.FGA \ndetail['3p_goal_rate'] = detail.FGM3 \/ detail.FGA3  \ndetail['ft_goal_rate'] = detail.FTM  \/ detail.FTA  \n\ndt = detail.groupby(['Season','TeamID'])['FGM','FGA','FGM3','FGA3','FTM','FTA',\n                                         'OR','DR','Ast','TO','Stl','Blk','PF',\n                                          'goal_rate', '3p_goal_rate',\n                                         'ft_goal_rate']\\\n                                        .mean().fillna(0).reset_index()\n\ndel w, l, detail","ed9bd1ad":"MMOrdinals = pd.read_csv(DATA_DIR + '\/MMasseyOrdinals.csv')\n\nMOR_127_128 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n                ((MMOrdinals.RankingDayNum == 127) \\\n                 | (MMOrdinals.RankingDayNum == 128))]\\\n                [['Season','TeamID','OrdinalRank']]\nMOR_50_51 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n                ((MMOrdinals.RankingDayNum == 50) \\\n                 | (MMOrdinals.RankingDayNum == 51))]\\\n                [['Season','TeamID','OrdinalRank']]\nMOR_15_16 = MMOrdinals[(MMOrdinals.SystemName == 'MOR') & \\\n                ((MMOrdinals.RankingDayNum == 15) \\\n                 | (MMOrdinals.RankingDayNum == 16))]\\\n                [['Season','TeamID','OrdinalRank']]\n\nMOR_127_128 = MOR_127_128.rename(columns={'OrdinalRank':'OrdinalRank_127_128'})\nMOR_50_51 = MOR_50_51.rename(columns={'OrdinalRank':'OrdinalRank_50_51'})\nMOR_15_16 = MOR_15_16.rename(columns={'OrdinalRank':'OrdinalRank_15_16'})\n\nMOR = MOR_127_128.merge(MOR_50_51, how='left', on=['Season','TeamID'])\\\n        .merge(MOR_15_16, how='left', on=['Season','TeamID'])\n\n## normalizing Rank values by its season maxium as it varies by seasons\nMOR_max = MOR.groupby('Season')['OrdinalRank_127_128','OrdinalRank_50_51',\n                                'OrdinalRank_15_16'].max().reset_index()\nMOR_max.columns = ['Season', 'maxRank_127_128', 'maxRank_50_51', 'maxRank_15_16']\n\nMOR_tmp = MMOrdinals[(MMOrdinals.SystemName == 'MOR') \\\n                     & (MMOrdinals.RankingDayNum < 133)]\nMOR_stats = MOR_tmp.groupby(['Season','TeamID'])['OrdinalRank']\\\n            .agg(['max','min','std','mean']).reset_index()\nMOR_stats.columns = ['Season','TeamID','RankMax','RankMin','RankStd','RankMean']\n\nMOR = MOR.merge(MOR_max, how='left', on='Season')\\\n        .merge(MOR_stats, how='left', on=['Season','TeamID'])\nMOR['OrdinalRank_127_128'] = MOR['OrdinalRank_127_128'] \/ MOR['maxRank_127_128']\nMOR['OrdinalRank_50_51'] = MOR['OrdinalRank_50_51'] \/ MOR['maxRank_50_51']\nMOR['OrdinalRank_15_16'] = MOR['OrdinalRank_15_16'] \/ MOR['maxRank_15_16']\nMOR['RankTrans_50_51_to_127_128'] = MOR['OrdinalRank_127_128'] \\\n                                    - MOR['OrdinalRank_50_51']\nMOR['RankTrans_15_16_to_127_128'] = MOR['OrdinalRank_127_128'] \\\n                                    - MOR['OrdinalRank_15_16']\n\n# MOR['RankMax'] = MOR['RankMax'] \/ MOR['maxRank_127_128']\n# MOR['RankMin'] = MOR['RankMin'] \/ MOR['maxRank_127_128']\n# MOR['RankStd'] = MOR['RankStd'] \/ MOR['maxRank_127_128']\n# MOR['RankMean'] = MOR['RankMean'] \/ MOR['maxRank_127_128']\n\nMOR.drop(['OrdinalRank_50_51','OrdinalRank_15_16', 'maxRank_50_51'\n          ,'maxRank_15_16'],axis=1, inplace=True)\n\ndel MOR_127_128, MOR_50_51, MOR_15_16, MOR_max, MOR_tmp, MOR_stats","a30c781f":"# Checking availability on RankingDayNum by SystemName \n\n# pd.options.display.max_columns=100\n# tmp = MMasseyOrdinals[(MMasseyOrdinals.SystemName == 'MOR')]\n# pd.crosstab(tmp.Season, tmp.RankingDayNum)","4bf4c705":"# MNCAATourneySeeds = pd.read_csv(DATA_DIR + '\/MDataFiles_Stage1\/MNCAATourneySeeds.csv')\n# MNCAATourneySeeds['seed_num'] =  MNCAATourneySeeds.Seed.apply(lambda x: int(x[1:3]))\n# MNCAATourneySeeds.drop('Seed', axis=1, inplace=True)","c63f8da9":"wl_1 = wl.loc[:,['Season','TeamID','win_pct_A','win_pct_N',\n                 'win_pct_H','win_pct_All']]\nwl_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n                else str(col) for col in wl_1.columns ]\n\nwl_2 = wl.loc[:,['Season','TeamID','win_pct_A','win_pct_N',\n                 'win_pct_H','win_pct_All']]\nwl_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n                else str(col) for col in wl_2.columns ]\n\nscr_1 = scr.copy()\nscr_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n                 else str(col) for col in scr_1.columns ]\n\nscr_2 = scr.copy()\nscr_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n                 else str(col) for col in scr_2.columns ]\n\ndt_1 = dt.copy()\ndt_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n                else str(col) for col in dt_1.columns ]\n\ndt_2 = dt.copy()\ndt_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n                else str(col) for col in dt_2.columns ]\n\nMOR_1 = MOR.copy()\nMOR_1.columns = [str(col) + '_1' if col not in ['Season','TeamID'] \\\n                 else str(col) for col in MOR_1.columns ]\n\nMOR_2 = MOR.copy()\nMOR_2.columns = [str(col) + '_2' if col not in ['Season','TeamID'] \\\n                 else str(col) for col in MOR_2.columns ]","e7b56c89":"TCResults = pd.read_csv(DATA_DIR + '\/MNCAATourneyCompactResults.csv')\n\ntourney1 = TCResults.loc[:, ['Season','WTeamID','LTeamID']]\ntourney1.columns = ['Season','TeamID1','TeamID2']\ntourney1['result'] = 1\n\ntourney2 = TCResults.loc[:, ['Season','LTeamID','WTeamID']]\ntourney2.columns = ['Season','TeamID1','TeamID2']\ntourney2['result'] = 0\n\ntourney = pd.concat([tourney1, tourney2])\ndel tourney1, tourney2","e1b5ae5c":"def merge_data(df):\n\n    df = df.merge(wl_1, how='left', left_on=['Season','TeamID1'],\n                  right_on=['Season','TeamID'])\n    df = df.merge(wl_2, how='left', left_on=['Season','TeamID2'],\n                  right_on=['Season','TeamID'])\n    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n\n\n    df = df.merge(scr_1, how='left', left_on=['Season','TeamID1'],\n                  right_on=['Season','TeamID'])\n    df = df.merge(scr_2, how='left', left_on=['Season','TeamID2'],\n                  right_on=['Season','TeamID'])\n    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n\n    # df['win_pct_A_diff'] = df['win_pct_A_1'] - df['win_pct_A_2']\n    # df['win_pct_N_diff'] = df['win_pct_N_1'] - df['win_pct_N_2']\n    # df['win_pct_H_diff'] = df['win_pct_H_1'] - df['win_pct_H_2']\n#     df['win_pct_All_diff'] = df['win_pct_All_1'] - df['win_pct_All_2']\n\n    # df['Score_A_diff'] = df['Score_A_1'] - df['Score_A_2']\n    # df['Score_N_diff'] = df['Score_N_1'] - df['Score_N_2']\n    # df['Score_H_diff'] = df['Score_H_1'] - df['Score_H_2']\n    # df['Score_All_diff'] = df['Score_All_1'] - df['Score_All_2']\n\n    # df['relScore_A_diff'] = df['relScore_A_1'] - df['relScore_A_2']\n    # df['relScore_N_diff'] = df['relScore_N_1'] - df['relScore_N_2']\n    # df['relScore_H_diff'] = df['relScore_H_1'] - df['relScore_H_2']\n#     df['relScore_All_diff'] = df['relScore_All_1'] - df['relScore_All_2']\n\n    df = df.merge(dt_1, how='left', left_on=['Season','TeamID1'],\n                  right_on=['Season','TeamID'])\n    df = df.merge(dt_2, how='left', left_on=['Season','TeamID2'],\n                  right_on=['Season','TeamID'])\n    \n    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n\n    df = df.merge(MOR_1, how='left', left_on=['Season','TeamID1'],\n                  right_on=['Season','TeamID'])\n    df = df.merge(MOR_2, how='left', left_on=['Season','TeamID2'],\n                  right_on=['Season','TeamID'])\n    df = df.drop(['TeamID_x','TeamID_y'], axis=1)\n\n    df['OrdinalRank_127_128_diff'] = df['OrdinalRank_127_128_1'] \\\n        - df['OrdinalRank_127_128_2']\n    \n    df['magic1'] = df['OrdinalRank_127_128_diff'] - df['RankMean_1']\n    df['magic2'] = df['RankMean_1'] - df['RankMean_2']\n    df['magic3'] = df['OrdinalRank_127_128_diff'] - df['RankMean_2']\n    \n    df['magic11'] = df['OrdinalRank_127_128_diff'] * df['RankMean_1']\n    df['magic21'] = df['RankMean_1'] * df['RankMean_2']\n    df['magic31'] = df['OrdinalRank_127_128_diff'] * df['RankMean_2']\n    \n    df['magic12'] = df['OrdinalRank_127_128_diff'] \/ df['RankMean_1']\n    df['magic22'] = df['RankMean_1'] \/ df['RankMean_2']\n    df['magic32'] = df['OrdinalRank_127_128_diff'] \/ df['RankMean_2']\n\n    df = df.fillna(-1)\n    \n    for col in df.columns:\n        if (df[col] == np.inf).any() or (df[col] == -np.inf).any():\n            df[col][(df[col] == np.inf) | (df[col] == -np.inf)] = -1\n    \n    return df\n\ntourney = merge_data(tourney)\ntourney = tourney.loc[tourney.Season >= 2003,:].reset_index(drop=True)\n\nif STAGE_1:\n    tourney = tourney.loc[tourney.Season < 2015, :]","0c9a5624":"if STAGE_1:\n    MSampleSubmission = pd.read_csv(DATA_DIR + '\/MSampleSubmissionStage1.csv')\nelse:\n    MSampleSubmission = pd.read_csv(DATA_DIR + '\/MSampleSubmissionStage2.csv') # put stage 2 submission file link here\n\ntest1 = MSampleSubmission.copy()\ntest1['Season'] = test1.ID.apply(lambda x: int(x[0:4]))\ntest1['TeamID1'] = test1.ID.apply(lambda x: int(x[5:9]))\ntest1['TeamID2'] = test1.ID.apply(lambda x: int(x[10:14]))\n\ntest2 = MSampleSubmission.copy()\ntest2['Season'] = test2.ID.apply(lambda x: int(x[0:4]))\ntest2['TeamID1'] = test2.ID.apply(lambda x: int(x[10:14]))\ntest2['TeamID2'] = test2.ID.apply(lambda x: int(x[5:9]))\n\ntest = pd.concat([test1,test2]).drop(['Pred'], axis=1)\ntest = merge_data(test)","e919b933":"X = tourney.drop(['Season','TeamID1','TeamID2','result'], axis=1)\ny = tourney[\"result\"]\ns = tourney[\"Season\"]\n\nX_test = test.drop(['ID', 'Season','TeamID1','TeamID2'], axis=1)","5e55f5d6":"s.value_counts()","ea0b5141":"def model_training(X, y, cv, groups, params, metric, early_stopping=10, \\\n    plt_iter=True, X_test=[], cat_features=[]):\n\n    feature_importance = pd.DataFrame()\n    val_scores=[]\n    train_evals=[]\n    valid_evals=[]\n\n    if len(X_test) > 0:\n        test_pred=np.zeros(len(X_test))\n\n    for idx, (train_index, val_index) in enumerate(cv.split(X, y, groups)):\n\n        print(\"###### fold %d ######\" % (idx+1))\n        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n\n        model = lgb.LGBMClassifier(**params)\n\n        model.fit(X_train, y_train,\n                  eval_set=[(X_train, y_train), (X_val, y_val)],\n                  early_stopping_rounds=early_stopping,\n                  verbose=20\n                  #categorical_feature=list(cate_ft_lst),\n                  )\n\n        val_scores.append(model.best_score_['valid_1'][metric])\n        train_evals.append(model.evals_result_['training'][metric])\n        valid_evals.append(model.evals_result_['valid_1'][metric])\n\n        if len(X_test) > 0:\n            test_pred = test_pred + model.predict_proba(X_test, num_iteration=model.best_iteration_)[:,1]\n\n        fold_importance = pd.DataFrame()\n        fold_importance[\"feature\"] = X_train.columns\n        fold_importance[\"importance\"] = model.feature_importances_\n        fold_importance[\"fold\"] = idx+1\n        feature_importance = pd.concat([feature_importance, fold_importance]\n                                       , axis=0)\n\n    if plt_iter:\n        \n        fig, axs = plt.subplots(2, 2, figsize=(9,6))\n        \n        for i, ax in enumerate(axs.flatten()):\n            ax.plot(train_evals[i], label='training')\n            ax.plot(valid_evals[i], label='validation')\n            ax.set(xlabel='interations', ylabel=f'{metric}')\n            ax.set_title(f'fold {i+1}', fontsize=12)\n            ax.legend(loc='upper right', prop={'size': 9})\n        fig.tight_layout()\n        plt.show()\n    \n    print('### CV scores by fold ###')\n    for i in range(cv.get_n_splits(X)):\n        print(f'fold {i+1}: {val_scores[i]:.4f}')\n    print('CV mean score: {0:.4f}, std: {1:.4f}.'\\\n          .format(np.mean(val_scores), np.std(val_scores)))\n    \n    feature_importance = feature_importance[[\"feature\", \"importance\"]]\\\n                         .groupby(\"feature\").mean().sort_values(\n                         by=\"importance\", ascending=False)\n    feature_importance.reset_index(inplace=True)\n\n    if len(X_test) > 0:\n        test_pred = test_pred \/ cv.get_n_splits(X)\n        return feature_importance, test_pred\n    else:\n        return feature_importance","c4926e92":"lgb_params = {'objective': 'binary',\n              'metric': 'binary_logloss',\n              'boosting': 'gbdt',\n              'num_leaves': 31,\n              'feature_fraction': 0.8,\n              'bagging_fraction': 0.8,\n              'bagging_freq': 5,\n              'learning_rate': 0.1,\n              'n_estimators': 1000,\n}","c5cce7cc":"N_FOLDS = 10","6840be90":"%%time\ngroup_kfold = GroupKFold(n_splits=N_FOLDS)\n\nfeature_importance, test_pred = \\\n    model_training(X, y, group_kfold, s, lgb_params, \n    'binary_logloss', plt_iter=True, X_test=X_test)","7c36dfd3":"plt.figure(figsize=(10, 10));\nsns.barplot(x=\"importance\", y=\"feature\", data=feature_importance[:30])\nplt.title('Feature Importnace')","536a3a9b":"# # https:\/\/www.kaggle.com\/joseleiva\/massey-s-ordinal-s-ordinals\n\n# import numpy as np\n# import pandas as pd\n\n# inp = '..\/input\/ncaam-march-mania-2021\/'\n# season_df = pd.read_csv(inp+'MRegularSeasonCompactResults.csv')\n# tourney_df = pd.read_csv(inp+'MNCAATourneyCompactResults.csv')\n# ordinals_df = pd.read_csv(inp+'MMasseyOrdinals.csv').rename(columns={'RankingDayNum':'DayNum'})\n\n# # Get the last available data from each system previous to the tournament\n# ordinals_df = ordinals_df.groupby(['SystemName','Season','TeamID']).last().reset_index()\n\n# # Add winner's ordinals\n# games_df = tourney_df.merge(ordinals_df,left_on=['Season','WTeamID'],\n#                           right_on=['Season','TeamID'])\n# games_df.head()\n# # Then add losser's ordinals\n# games_df = games_df.merge(ordinals_df,left_on=['Season','LTeamID','SystemName'],\n#                           right_on=['Season','TeamID','SystemName'],\n#                           suffixes = ['W','L'])\n\n# ## Add column with 1 if result is correct\n# games_df = games_df.drop(labels=['TeamIDW','TeamIDL'],axis=1)\n# games_df['prediction'] = (games_df.OrdinalRankW<games_df.OrdinalRankL).astype(int)\n# results_by_system = games_df.groupby('SystemName').agg({'prediction':('mean','count')})\n\n# games_df['Wrating'] = 100-4*np.log(games_df['OrdinalRankW']+1)-games_df['OrdinalRankW']\/22\n# games_df['Lrating'] = 100-4*np.log(games_df['OrdinalRankL']+1)-games_df['OrdinalRankL']\/22\n# games_df['prob'] = 1\/(1+10**((games_df['Lrating']-games_df['Wrating'])\/15))\n# loss_results = games_df[games_df.Season>=2015].groupby('SystemName')['prob'].agg([('loss',lambda p: -np.mean(np.log(p))),('count','count')])\n\n# ref_system = 'POM'\n# ordinals_df['Rating']= 100-4*np.log(ordinals_df['OrdinalRank']+1)-ordinals_df['OrdinalRank']\/22\n# ordinals_df = ordinals_df[ordinals_df.SystemName==ref_system]\n\n# # Get submission file\n# sub_df = pd.read_csv(inp+'MSampleSubmissionStage1.csv')\n# sub_df['Season'] = sub_df['ID'].map(lambda x: int(x.split('_')[0]))\n# sub_df['Team1'] = sub_df['ID'].map(lambda x: int(x.split('_')[1]))\n# sub_df['Team2'] = sub_df['ID'].map(lambda x: int(x.split('_')[2]))\n# sub_df = sub_df.merge(ordinals_df[['Season','TeamID','Rating']], how='left', left_on = ['Season','Team1'], right_on = ['Season','TeamID'])\n# sub_df = sub_df.merge(ordinals_df[['Season','TeamID','Rating']], how='left', left_on = ['Season','Team2'], right_on = ['Season','TeamID'], suffixes=['W','L'])","bdab90b5":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm\nimport glob\nimport os\nimport gc\nimport xgboost as xgb\n\ntrain = tourney\ntest = test\n\nxgb_params= {\n        \"objective\": \"binary:logistic\",\n        \"max_depth\": 2,\n        \"learning_rate\": 0.1,\n        \"colsample_bytree\": 0.8,\n        \"subsample\": 0.8,\n        #\"reg_alpha\" : 0,\n        \"min_child_weight\": 30,\n        \"n_jobs\": 2,\n        \"seed\": 2021,\n        'tree_method': \"gpu_hist\",\n        \"gpu_id\": 0,\n        'predictor': 'gpu_predictor'\n    }\n\ny = train[\"result\"]\ns = train[\"Season\"]\nX = train.drop(['Season','TeamID1','TeamID2','result'], axis=1)\n\nX_test = test.drop(['ID', 'Season','TeamID1','TeamID2'], axis=1)\n\ntrain_oof = np.zeros((X.shape[0],))\ntest_preds = 0\ntrain_oof.shape\n\nNUM_FOLDS = 5\nkf = GroupKFold(n_splits=NUM_FOLDS)\nmax_iter = 550\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(X, y, s))):\n        #print(f'Fold {f}')\n        train_df, val_df = X.iloc[train_ind], X.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        train_df_xgb = xgb.DMatrix(train_df, label=train_target)\n        val_df_xgb = xgb.DMatrix(val_df, label=val_target)\n        \n        model = HistGradientBoostingClassifier(max_iter=max_iter, validation_fraction=None, learning_rate=0.01, max_depth=2, min_samples_leaf=32)\n        model1 = RandomForestClassifier()\n        model2 = LogisticRegression(C=1)\n#         model3 = SVC(probability=True)\n        model4 = xgb.train(xgb_params, train_df_xgb, 1000)\n\n        model =  model.fit(train_df, train_target)\n        model1 =  model1.fit(train_df, train_target)\n        model2 =  model2.fit(train_df, train_target)\n#         model3 =  model3.fit(train_df, train_target)\n          \n#         temp_oof = model2.predict_proba(val_df)[:,1]\n#         temp_test = model2.predict_proba(X_test)[:,1]\n        \n        temp_oof = (model.predict_proba(val_df)[:,1] + \\\n                    model1.predict_proba(val_df)[:,1] + \\\n                    model2.predict_proba(val_df)[:,1] + \\\n#                     model3.predict_proba(val_df)[:,1] + \\\n                    model4.predict(val_df_xgb)) \/ 4\n        temp_test = (model.predict_proba(X_test)[:,1] \\\n                     + model1.predict_proba(X_test)[:,1] \\\n                     + model2.predict_proba(X_test)[:,1] \\\n#                      + model3.predict_proba(X_test)[:,1] \\\n                     + model4.predict(xgb.DMatrix(X_test))) \/ 4\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test\/NUM_FOLDS\n        \n        print(log_loss(val_target, temp_oof))\n        \nprint('CV', log_loss(y, train_oof))        \nnp.save('train_oof', train_oof)\nnp.save('test_preds', test_preds)\n\ntest = test\nMSampleSubmission = pd.read_csv('..\/input\/ncaam-march-mania-2021\/MDataFiles_Stage2\/MSampleSubmissionStage2.csv')\n\nidx = test_preds.shape[0] \/\/2\ntest_preds[idx:] = 1 - test_preds[idx:]\n\npred = pd.concat([test.ID, pd.Series(test_preds)], axis=1).groupby('ID')[0]\\\n        .mean().reset_index().rename(columns={0:'Pred'})\nsub3 = MSampleSubmission.drop(['Pred'],axis=1).merge(pred, on='ID')\npred_3 = sub3['Pred']","123d8d3b":"0.5539459504635523","d6a2e4e2":"idx = test_pred.shape[0] \/\/2\ntest_pred[idx:] = 1 - test_pred[idx:]\n\npred = pd.concat([test.ID, pd.Series(test_pred)], axis=1).groupby('ID')[0]\\\n        .mean().reset_index().rename(columns={0:'Pred'})\nsub = MSampleSubmission.drop(['Pred'],axis=1).merge(pred, on='ID')\nsub['Pred'] = sub['Pred'] * 0.3 + sub3['Pred'] * 0.7\nsub.to_csv('submission.csv', index=False)\nsub.head()","e3f71afa":"if STAGE_1:\n    rslt = pd.DataFrame()\n    TCResults_s = TCResults.loc[TCResults.Season >= 2015,:]\n    rslt['season'] = TCResults_s.Season\n    rslt['team1'] = TCResults_s.apply(lambda x: x.WTeamID \\\n                                      if x.WTeamID < x.LTeamID else x.LTeamID\n                                      , axis=1)\n    rslt['team2'] = TCResults_s.apply(lambda x: x.WTeamID \\\n                                      if x.WTeamID > x.LTeamID else x.LTeamID\n                                      , axis=1)\n    rslt['wl'] = TCResults_s.apply(lambda x: 1 if x.WTeamID < x.LTeamID else 0\n                                   , axis=1)\n    rslt['ID'] = rslt.apply(lambda x: str(x.season) + '_' + str(x.team1) \\\n                            + '_' + str(x.team2), axis=1)\n    sub2 = sub.merge(rslt.loc[:,['ID','wl']], how='inner', on='ID')\n\n    preds = []\n    for i in sub2.Pred:\n        preds.append([1-i, i])\n\n    print('Test logloss is {:.5f}'.format(log_loss(sub2.wl.values, preds)))","d7d0864f":"0.51971","36116bd8":"For Stage 1, 2003 <= Season < 2015 will be used for the model training\/validation and test preditions are calculated by that trained model. For Stage 2, Season >= 2003 will be used for  training.","c5318aee":"### Merging engineered features to Tourney dataset","66e81d02":"## Model Training","7f2171d3":"Duplicating each data with changing column names to be matched to 'WTeamID' and 'LTeamID' in Tourney dataset","6bacb7e0":"# 2nd model","3be7780e":"### Creating Score Features","1fc939db":"## FE on RegularSeasonCompactResults\n\n### Calculating Win %","8dc07388":"## Loading Submission Dataset\nDuplicating each ID with swapping TeamIDs. Predictions will be averaged by ID to get better performance.","53f78b71":"Using GroupKFold by Season","f31d6d93":"# NCAAM 2021 - LGB w\/ FE on three Datasets\n\nThis notebook is copied from my notebook from NCAAM 2020. It shows LGB model training with feature engineering on three different datasets:\n- MRegularSeasonCompactResults\n- MRegularSeasonDetailedResults\n- MMasseyOrdinals\n\nThe engineered features are appended to MNCAATourneyCompactResults and then LGB will be trained on it.\n\nOnly Season < 2015 is used for Stage1 training, so there is no leak on the test prediction.","fcc7624e":"## FE on MNCAATourneySeeds\n\nSeed didn't improve the score, so it's not used.","1d53e67f":"## Loading MNCAATourneyCompactResults\n\nThis dataset will be the base dataset for the model training","38b07d63":"## FE on MRegularSeasonDetailedResults","8e080045":"## FE on MMasseyOrdinals\n\nUsing only MOR for now.","51b5003e":"## Creating Submission File\n\nThe second half of the test prediction need to be (1 - pred) as the team order was swapped. The predictions are averaged by ID after that.","65334902":"## Calculating Test Score Locally","79d59a55":"# 3rd model"}}