{"cell_type":{"df46f1b1":"code","0d67fd53":"code","67210c95":"code","b311b8c7":"code","e7b7566c":"code","0c485706":"code","65389790":"code","67971c6a":"code","85107fad":"code","12b183cb":"code","14526b0a":"code","c9d93d30":"code","c1acdcb9":"code","d6be10f2":"code","2cedacc5":"code","0cc89d1e":"code","a2ad396a":"code","5ee95dc7":"code","16f9c67e":"code","3943f04c":"code","ccfd751e":"code","f4494df3":"code","3a5d837a":"code","31e573aa":"code","95849b18":"code","ef72069e":"code","a7f9a3c5":"code","2ed4a30f":"code","ce8ec7a3":"code","19b047bf":"code","00b54c38":"code","ce5b2f33":"code","74f9301d":"code","e8a3f14b":"code","ad3e634f":"code","a3512211":"code","451afb95":"code","2aeceeec":"code","a4c7f5e1":"markdown","95693b57":"markdown","a737b60c":"markdown","7d2861b6":"markdown","28c39659":"markdown","a35d3312":"markdown","bc8b6c3b":"markdown","9e862e60":"markdown","1de103df":"markdown","8ac11da2":"markdown","09a8da43":"markdown","ddb2df50":"markdown","2836bec8":"markdown","baef59b0":"markdown","9ecccbbe":"markdown","12466aab":"markdown","df3e82c8":"markdown","7ba5bb3a":"markdown","95280958":"markdown","cb58625e":"markdown","395f76fb":"markdown","8b9809b5":"markdown","7130e8d9":"markdown","1c44e1b0":"markdown","8e1abe77":"markdown","7c1b0696":"markdown"},"source":{"df46f1b1":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn import tree\n\nimport graphviz \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.impute import KNNImputer\nfrom sklearn.ensemble import RandomForestClassifier\n\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","0d67fd53":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_data.head(20)","67210c95":"train_data.describe()","b311b8c7":"train_data.info()","e7b7566c":"features = []\nfor i in train_data.columns:\n    if i !='Survived':\n        features.append(i)\n\nfeatures","0c485706":"train_data.isnull().sum()","65389790":"for i in features:\n    print(\"\\n\\n\"+i)\n    print (train_data[[i, \"Survived\"]].groupby([i], as_index=False).mean())","67971c6a":"train_data.drop(['PassengerId','Ticket'],axis=1,inplace=True)","85107fad":"\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\n\ntrain_data['Title'] = train_data['Name'].apply(get_title)\ntrain_data.drop('Name',axis=1,inplace=True)\ntrain_data['Title'].unique()","12b183cb":"train_data.groupby(['Title']).size()","14526b0a":"train_data['Title'] = train_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Others')\n\ntrain_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\n","c9d93d30":"train_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","c1acdcb9":"def cabin_group(cabin):\n    if type(cabin) == str:\n        return cabin[0]\n    else:\n        return '-1'\ntrain_data['Cabin_Group'] = train_data['Cabin'].apply(cabin_group)\ntrain_data.drop('Cabin',axis=1,inplace=True)","d6be10f2":"train_data[['Cabin_Group', 'Survived']].groupby(['Cabin_Group'], as_index=False).mean()","2cedacc5":"bucket = pd.qcut(train_data['Fare'], 5)\nbucket.unique()","0cc89d1e":"def FareGroup(fare):\n    if float(fare):\n        if fare > 0.0 and fare <= 7.854:\n            return 1\n        elif fare > 7.854 and fare <= 10.5:\n            return 2\n        elif fare > 10.5 and fare <= 21.679:\n            return 3\n        elif fare > 21.679 and fare <= 39.688:\n            return 4\n        elif fare > 39.688 and fare <= 512.329:\n            return 5\n        else:\n            return -1\n    else:\n        return -1\n    \n    \ntrain_data['FareRange'] = train_data['Fare'].apply(FareGroup)\ntrain_data.drop('Fare',axis=1,inplace=True)\nprint(train_data.groupby(['FareRange']).size())","a2ad396a":"print (train_data[['FareRange', 'Survived']].groupby(['FareRange'], as_index=False).mean())","5ee95dc7":"bucket = pd.qcut(train_data['Age'], 5).unique()\nbucket","16f9c67e":"def AgeGroup(age):\n    if float(age):\n        if age > 19.0 and age <= 25.0:\n            return 1\n        elif age > 25.0 and age <= 31.8:\n            return 2\n        elif age > 31.8 and age <= 41.0:\n            return 3\n        elif age > 41.0 and age <= 80.0:\n            return 4\n        elif age < 19.0:\n            return 0\n        else:\n            return -1\n    else:\n        return -1\n    \n    \ntrain_data['AgeGroup'] = train_data['Age'].apply(AgeGroup)\ntrain_data.drop('Age',axis=1,inplace=True)\nprint (train_data[['AgeGroup', 'Survived']].groupby(['AgeGroup'], as_index=False).mean())","3943f04c":"features = []\nfor i in train_data.columns:\n    if i !='Survived':\n        features.append(i)\n\nfeatures","ccfd751e":"sns.heatmap(train_data.isnull(),yticklabels=True,cbar=True,cmap='viridis')","f4494df3":"sns.set_style('whitegrid')\nfor i in features:\n    sns.countplot(x=i,data=train_data)\n    plt.show()","3a5d837a":"for i in features:\n    sns.histplot(data=train_data.dropna(),x=i,bins=30,color='blue',alpha=0.3)\n    plt.show()\n    \n","31e573aa":"for i in features:\n    if i != 'Survived':\n        sns.scatterplot(data=train_data.dropna(),x=i,y='Survived',color='red')\n        plt.show()\n","95849b18":"for i in features:    \n    sns.countplot(i,hue='Survived',data=train_data)    \n    plt.show()","ef72069e":"for i in features:\n    sns.factorplot(i,'Survived',hue=\"Sex\",data=train_data)\n    plt.show()","a7f9a3c5":"for i in features:\n    sns.violinplot(i,'Survived',hue=\"Sex\",data=train_data)\n    plt.show()","2ed4a30f":"sns.heatmap(train_data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","ce8ec7a3":"train_data.dropna(subset=['Embarked'],inplace=True)\ntrain_data.groupby(['Embarked']).size()","19b047bf":"train_data['AgeGroup'] = train_data['AgeGroup'].apply(lambda x: np.nan if x == -1 else x)\ntrain_data['FareRange'] = train_data['FareRange'].apply(lambda x: np.nan if x == -1 else x)\n\n\nimputer = KNNImputer(n_neighbors= 5)\nAgeGroupImputed = imputer.fit_transform([train_data['AgeGroup']])\nFareRangeImputed = imputer.fit_transform([train_data['FareRange']])\nFareRangeImputed = pd.Series(FareRangeImputed[0])\nAgeGroupImputed = pd.Series(AgeGroupImputed[0])\ntrain_data['FareRange'] = FareRangeImputed\ntrain_data['AgeGroup'] = AgeGroupImputed\n\ntrain_data.head(20)","00b54c38":"sex = pd.get_dummies(train_data['Sex'],drop_first=True)\nembark = pd.get_dummies(train_data['Embarked'],drop_first=True)\ntitle = pd.get_dummies(train_data['Title'],drop_first=True)\nfare = pd.get_dummies(train_data['FareRange'],drop_first=True)\ncabin = pd.get_dummies(train_data['Cabin_Group'],drop_first=True)\nage = pd.get_dummies(train_data['AgeGroup'],drop_first=True)\n\ntrain_data.drop(['AgeGroup','Sex',\"Embarked\",'Title','Cabin_Group','FareRange'],axis=1,inplace=True)\n\ntrain_data = pd.concat([train_data,sex,embark,title,cabin,fare,age],axis=1)\ntrain_data.head(20)","ce5b2f33":"X_train, X_test, y_train, y_test = train_test_split(train_data.drop('Survived',axis=1), \n                                                    train_data['Survived'], test_size=0.30, \n                                                    random_state=101)","74f9301d":"LogisticRegressionModel = LogisticRegression()\nLogisticRegressionModel.fit(X_train,y_train)\n\naccuracy=accuracy_score(y_test,LogisticRegressionModel.predict(X_test))\n\nclassificationRep=classification_report(y_test,LogisticRegressionModel.predict(X_test))\nprint(\"Classification Report: \\n\"+classificationRep)\nprint(\"Accuracy: \"+str(accuracy))","e8a3f14b":"DecisionTreeModel = tree.DecisionTreeClassifier()\nDecisionTreeModel = DecisionTreeModel.fit(X_train, y_train)\naccuracy=accuracy_score(y_test,DecisionTreeModel.predict(X_test))\nclassificationRep=classification_report(y_test,DecisionTreeModel.predict(X_test))\nprint(\"Classification Report: \\n\"+classificationRep)\nprint(\"Accuracy: \"+str(accuracy))","ad3e634f":"data = tree.export_graphviz(DecisionTreeModel, out_file=None) \ngraph = graphviz.Source(data) \ngraph.render(\"Titanic\") \ngraph","a3512211":"KNeighborsClassifierModel = KNeighborsClassifier(n_neighbors=5)\nKNeighborsClassifierModel.fit(X_train, y_train)\naccuracy=accuracy_score(y_test,KNeighborsClassifierModel.predict(X_test))\nclassificationRep=classification_report(y_test,KNeighborsClassifierModel.predict(X_test))\nprint(\"Classification Report: \\n\"+classificationRep)\nprint(\"Accuracy: \"+str(accuracy))","451afb95":"GaussianNBModel = GaussianNB()\nGaussianNBModel.fit(X_train, y_train)\naccuracy=accuracy_score(y_test,GaussianNBModel.predict(X_test))\nclassificationRep=classification_report(y_test,GaussianNBModel.predict(X_test))\nprint(\"Classification Report: \\n\"+classificationRep)\nprint(\"Accuracy: \"+str(accuracy))","2aeceeec":"RandomForestClassifierModel = RandomForestClassifier(max_depth=5, random_state=0)\nRandomForestClassifierModel.fit(X_train,y_train)\naccuracy=accuracy_score(y_test,RandomForestClassifierModel.predict(X_test))\nclassificationRep=classification_report(y_test,RandomForestClassifierModel.predict(X_test))\nprint(\"Classification Report: \\n\"+classificationRep)\nprint(\"Accuracy: \"+str(accuracy))","a4c7f5e1":"Let's check the number of records for each of these titles.","95693b57":"# Importing Libraries","a737b60c":"Let's have an array containing all the column names. We'll use them to create the different plots to check the count of values in each feature.","7d2861b6":"We can replace some of the titles (such as Ms -> Miss) and the group the ones which appear lesser compared to others in a new group. We'll then check the mean number of records of each title's relation to the output.","28c39659":"> **Getting the information of the number of records per columns with null\/NaN value**","a35d3312":"If you like it, please upvote. Also let me know in the comments, if my strategy is incorrect somewhere or you have a better solution for any part or any suggestions on how I should improve the accuracy of my models.","bc8b6c3b":"**Age and Fare**\n\nHere, I'd be using KNN to predict te missing values (which I've classified as -1 in previous function). For this task, I'd be using KNNImputer.","9e862e60":" **HeatMap**\n\n[Heatmap](https:\/\/seaborn.pydata.org\/generated\/seaborn.heatmap.html) contains values having similar shades for same color for each value to be plotted. Darker values denote dense population than lighter colors.","1de103df":"ViolinPlot wrt sex on Survived","8ac11da2":"> **Checking the impact of each feature on target variable**","09a8da43":"**NAME**\n\nLet's look at Name feature. My idea is to get the salutation from each name and store it as a new column 'Title' in the dataframe.","ddb2df50":"I'll update my features array with these new features and dropping the old ones.","2836bec8":"Checking the relation between this new feature with target.","baef59b0":"This notebook is dedicated to EDA of the titanic dataset, to understand the relation between the different features with the target and to use Feature Engineering to handle irregularities in data, and finally I've used a number of classification algorithms to find out the best accuracy.","9ecccbbe":"I'll replace the new columns with the one hot encoded values and append them to my dataframe.","12466aab":"# Handling Null Values\n\nWe have null values in Age, Cabin and Embarked features. I'll try different methods o handling null values for these features.","df3e82c8":"FactorPlot wrt sex on Survived","7ba5bb3a":"**Embarked**\n\nSince we have only 2 null records for Embarked feature, I'm going to save some time and just drop them.","95280958":"**Age**\n\nCreating a similar range for age as well, like Fare and assigning -1 to Null values to be handled later.","cb58625e":"> **Get information about the data like count, mean, standard deviation etc.**","395f76fb":"**FARE**\n\nI'm dividing the fare to 5 buckets or ranges, which I'd be using later for my model.","8b9809b5":"# Reading Dataset","7130e8d9":"**CABIN**\n\nNext, I'm starting with the Cabin feature. For this, I'll assign -1 to NaN\/null vales (and deal with them later) and group the others using the first letter of the values and create a new column 'Cabin_Group'.","1c44e1b0":"> **Creating an array using the columns which would be used for the various graphs for EDA**","8e1abe77":"I will plot a countplot using x as my feature from the list against 'Survived' feature, as to check to which extent the target feature is influenced by individual features.","7c1b0696":"# FEATURE ENGINEERING\nWe see from the above table that some columns have a large amount of similar data or contain NaN values which would be difficult to be used in a model if no changes are made to them. For example, \n\n**PassengerID**: The ID has no impact on survival, so we might ignore the column altogether.\n\n**Cabin**: The Cabin can be grouped according to the classes, and we can try to derive a pattern from it.\n\n**Fare**: There are 200+ different fares that the passengers have paid. Instead of analysing them individually for a prediction, we can use them as a range.\n\n**Ticket**: The Ticket has no impact on survival, so we might ignore the column altogether.\n\n**Age**: Again, like Fare, we need to treat them as age group instead of considering individual ages \n\n**Name**: The names are not important, but the salutation is. We can use that in addition to the Sex and Age feature for prediction."}}