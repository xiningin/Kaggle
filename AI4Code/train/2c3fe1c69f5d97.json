{"cell_type":{"d625d6a8":"code","55f4df37":"code","04238ea3":"code","0719e5f6":"code","89430722":"code","0cfc9ed1":"code","3aaa7e77":"code","974da291":"code","f9a1ab6c":"code","fd97dec1":"code","18d4cd0e":"code","e67dc834":"code","4810589a":"code","220b9bfa":"code","d2c6d50a":"code","0ede4af8":"code","d30caeb6":"code","a2e5c6f9":"code","060abdbc":"code","b034964a":"code","a2f67b51":"code","d9393bde":"code","16780c17":"code","6503b1f2":"code","77e412e9":"code","1d8ccbc4":"code","4a720cda":"code","931d2ba5":"code","7e2f5ea2":"code","b324e3c1":"code","afb044b3":"markdown","c4260e44":"markdown","2c7c5846":"markdown","b0392f05":"markdown","2170b87a":"markdown","59cf5c67":"markdown","a851f437":"markdown","0018d3e6":"markdown","77052d4e":"markdown","a714ed6d":"markdown","961f3f53":"markdown","17c5c920":"markdown","57a5eee5":"markdown","3d2555b0":"markdown"},"source":{"d625d6a8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport re\n\n# file path for train and test data\ntrain_path = \"..\/input\/titanic\/train.csv\"\ntest_path = \"..\/input\/titanic\/test.csv\"\n\n\n# read the files into variables\ntrain_data = pd.read_csv(train_path, index_col=False)\ntest_data = pd.read_csv(test_path, index_col=False)\n\n\n# delete tickets from columns\ncols = list(train_data.columns)\ntrain_data = train_data[cols[1:8] +cols[9:]]\ncols = list(test_data.columns)\ntest_data = test_data[cols[1:7] +cols[8:]]","55f4df37":"# fill null values in Age, Fare, Embarked \ntrain_data = train_data.astype({'Age':'float'}) \ntest_data = test_data.astype({'Age':'float'}) \ntrain_data['Age'].fillna(train_data['Age'].median(), inplace = True)\ntrain_data['Fare'].fillna(train_data['Fare'].median(), inplace = True)\ntrain_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace = True)\ntest_data['Age'].fillna(test_data['Age'].median(), inplace = True)\ntest_data['Fare'].fillna(test_data['Fare'].median(), inplace = True)\ntest_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace = True)","04238ea3":"# add Has_Cabin as a new column, will be in use later when we train a model\ntrain_data['Has_Cabin'] = train_data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest_data['Has_Cabin'] = test_data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)","0719e5f6":"# function to get Mr. Miss etc. from Name\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    if title_search:\n        return title_search.group(1)\n    return \"\"","89430722":"# call the above function\ntrain_data['Title'] = train_data['Name'].apply(get_title)\ntest_data['Title'] = test_data['Name'].apply(get_title)","0cfc9ed1":"# replace repetetive titles which have the same meaning (ex. Mlle and Miss)\ntrain_data['Title'] = train_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntrain_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\n\ntest_data['Title'] = test_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')","3aaa7e77":"# add no_of_fam column to be number of member in family -> which we can retrieve the number from SibSp and Parch\ntrain_data['no_of_fam'] = train_data['SibSp'] + train_data['Parch']\ntest_data['no_of_fam'] = test_data['SibSp'] + test_data['Parch']\ndrop_column = ['SibSp','Parch','Name','Cabin']\ntrain_data.drop(drop_column, axis=1, inplace = True)\ntest_data.drop(drop_column, axis=1, inplace = True)","974da291":"# add Age_Band column to classify age into 4 groups\ntrain_data.loc[ train_data['Age'] <= 16, 'Age_Band'] = 0\ntrain_data.loc[(train_data['Age'] > 16) & (train_data['Age'] <= 32), 'Age_Band'] = 1\ntrain_data.loc[(train_data['Age'] > 32) & (train_data['Age'] <= 48), 'Age_Band'] = 2\ntrain_data.loc[(train_data['Age'] > 48) & (train_data['Age'] <= 64), 'Age_Band'] = 3\ntrain_data.loc[ train_data['Age'] > 64, 'Age_Band'] = 4 \n\ntest_data.loc[ test_data['Age'] <= 16, 'Age_Band'] = 0\ntest_data.loc[(test_data['Age'] > 16) & (test_data['Age'] <= 32), 'Age_Band'] = 1\ntest_data.loc[(test_data['Age'] > 32) & (test_data['Age'] <= 48), 'Age_Band'] = 2\ntest_data.loc[(test_data['Age'] > 48) & (test_data['Age'] <= 64), 'Age_Band'] = 3\ntest_data.loc[ test_data['Age'] > 64, 'Age_Band'] = 4 ","f9a1ab6c":"g = sns.distplot(train_data[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(train_data[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")\n\n# apply log to Fare\ntrain_data['Fare'] = train_data['Fare'].map(lambda i : np.log(i) if i>0 else 0)","fd97dec1":"g = sns.distplot(train_data[\"Fare\"], color=\"b\", label=\"Skewness : %.2f\"%(train_data[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","18d4cd0e":"g = sns.distplot(test_data[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(test_data[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")\n\n# apply log to Fare\ntest_data['Fare'] = test_data['Fare'].map(lambda i : np.log(i) if i>0 else 0)","e67dc834":"g = sns.distplot(test_data[\"Fare\"], color=\"b\", label=\"Skewness : %.2f\"%(test_data[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","4810589a":"total_survived_passengers = train_data['Survived'].loc[(train_data['Survived']==1)].count()\ntotal_survived_female_passengers =train_data['Survived'].loc[(train_data['Sex']==\"female\") & (train_data['Survived']==1)].count()\ntotal_survived_male_passengers =train_data['Survived'].loc[(train_data['Sex']==\"male\") & (train_data['Survived']==1)].count()\n\n# Bar chart \nsns.set_palette(\"RdBu\", n_colors=2)\nsns.barplot(x=['male','female'], y=[total_survived_male_passengers\/total_survived_passengers, total_survived_female_passengers\/total_survived_passengers])\n\n# Add label for vertical axis\nplt.ylabel(\"Survival Rate by Gender\")\nplt.xlabel(\"Gender\")","220b9bfa":"print(\"by all survivors, being female \", total_survived_female_passengers\/total_survived_passengers)\nprint(\"by all survivors, being male \", total_survived_male_passengers\/total_survived_passengers)","d2c6d50a":"# Bar chart \nsns.set_palette(\"RdBu\", n_colors=2)\nsns.barplot(x='Sex', y='Survived', data=train_data);\n\n# Add label for vertical axis\nplt.ylabel(\"Survival Rate in Male and Female\")\nplt.xlabel(\"Gender\")","0ede4af8":"total_female_passengers = train_data['Survived'].loc[(train_data['Sex']==\"female\")].count()\ntotal_survived_female_passengers =train_data['Survived'].loc[(train_data['Sex']==\"female\") & (train_data['Survived']==1)].count()\nprint(\"by all female passengers, being survived\", total_survived_female_passengers\/total_female_passengers)\ntotal_male_passengers = train_data['Survived'].loc[(train_data['Sex']==\"male\")].count()\ntotal_survived_male_passengers =train_data['Survived'].loc[(train_data['Sex']==\"male\") & (train_data['Survived']==1)].count()\nprint(\"by all male passengers, being survived\", total_survived_male_passengers\/total_male_passengers)\n\n","d30caeb6":"#cross tab \npd.crosstab(train_data['Title'], train_data['Survived']).apply(lambda r: r\/r.sum(), axis=1)","a2e5c6f9":"#cross tab \npd.crosstab(train_data['Age_Band'], train_data['Survived']).apply(lambda r: r\/r.sum(), axis=1)","060abdbc":"pd.crosstab(train_data['no_of_fam'], train_data['Survived']).apply(lambda r: r\/r.sum(), axis=1)","b034964a":"pd.crosstab(train_data['Has_Cabin'], train_data['Survived']).apply(lambda r: r\/r.sum(), axis=1)","a2f67b51":"pd.crosstab(train_data['Sex'], train_data['Survived']).apply(lambda r: r\/r.sum(), axis=1)","d9393bde":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\n\n\ncols = list(train_data.columns)\nX = train_data[['Sex','Age_Band',]].values\ny = train_data[['Survived']].values.ravel()\n\n# label Sex and Age_Range to be int!\nLe = LabelEncoder()\nX[:,0] = Le.fit_transform (X[:,0])\nX[:,1] = Le.fit_transform (X[:,1])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n\nmodel = svm.SVC()\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\nacc = accuracy_score(y_test, predictions)\n\nprint(\"predictions:\", predictions)\nprint(\"actual: \", y_test)\nprint(\"accuracy: \", acc)","16780c17":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\n\ntrain_data['Sex'] = train_data['Sex'].astype('category')\ntrain_data['Pclass'] = train_data['Pclass'].astype('category')\ntrain_data['Embarked'] = train_data['Embarked'].astype('category')\ntrain_data['Title'] = train_data['Title'].astype('category')\n\n# label Sex and Age_Range to be int!\ntrain_data['Sex'] = train_data['Sex'].cat.codes\ntrain_data['Pclass'] = train_data['Pclass'].cat.codes\ntrain_data['Embarked'] = train_data['Embarked'].cat.codes\ntrain_data['Title'] = train_data['Title'].cat.codes\n\n\ntrain_data = pd.get_dummies(train_data, columns=['Sex'], prefix = ['Sex'])\ntrain_data = pd.get_dummies(train_data, columns=['Pclass'], prefix = ['Pclass'])\ntrain_data = pd.get_dummies(train_data, columns=['Embarked'], prefix = ['Embarked'])\ntrain_data = pd.get_dummies(train_data, columns=['Title'], prefix = ['Title'])\n\ntest_data['Sex'] = test_data['Sex'].astype('category')\ntest_data['Pclass'] = test_data['Pclass'].astype('category')\ntest_data['Embarked'] = test_data['Embarked'].astype('category')\ntest_data['Title'] = test_data['Title'].astype('category')\n\n# label Sex and Age_Range to be int!\ntest_data['Sex'] = test_data['Sex'].cat.codes\ntest_data['Pclass'] = test_data['Pclass'].cat.codes\ntest_data['Embarked'] = test_data['Embarked'].cat.codes\ntest_data['Title'] = test_data['Title'].cat.codes\n\n\ntest_data = pd.get_dummies(test_data, columns=['Sex'], prefix = ['Sex'])\ntest_data = pd.get_dummies(test_data, columns=['Pclass'], prefix = ['Pclass'])\ntest_data = pd.get_dummies(test_data, columns=['Embarked'], prefix = ['Embarked'])\ntest_data = pd.get_dummies(test_data, columns=['Title'], prefix = ['Title'])\n\nX = train_data[['Fare', 'Has_Cabin', 'no_of_fam', 'Age_Band',\n       'Sex_0', 'Sex_1', 'Pclass_0', 'Pclass_1', 'Pclass_2', 'Embarked_0',\n       'Embarked_1', 'Embarked_2', 'Title_0', 'Title_1', 'Title_2', 'Title_3',\n       'Title_4']].values\ny = train_data[['Survived']].values.ravel()\n\n# X_test = test_data[['Fare', 'Has_Cabin', 'no_of_fam', 'Age_Band',\n#        'Sex_0', 'Sex_1', 'Pclass_0', 'Pclass_1', 'Pclass_2', 'Embarked_0',\n#        'Embarked_1', 'Embarked_2', 'Title_0', 'Title_1', 'Title_2', 'Title_3',\n#        'Title_4']].values\n\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_X = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(scaled_X,y, test_size=0.3)\n\nmodel = svm.SVC()\nmodel.fit(X_train, y_train)\n\n\npredictions = model.predict(X_test)\nacc = accuracy_score(y_test, predictions)\n\nprint(\"predictions:\", predictions)\nprint(\"actual: \", y_test)\nprint(\"accuracy: \", acc)","6503b1f2":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential #what is sequential? most simplist type good for one tensor input and output\nfrom tensorflow.keras.layers import Activation, Dense\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.metrics import categorical_crossentropy\n\nX_train = X_train.astype('float') \ny_train = y_train.astype('float')\n\nmodel = Sequential([\n    Dense(units=16, input_shape=(17,), activation='sigmoid'),\n    Dense(units=2, activation='sigmoid')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.02), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(x=X_train, y= y_train,validation_split=0.2, batch_size=15, epochs=60, shuffle=True, verbose=0)\n\npredictions = model.predict(x=X_test\n    , batch_size=15\n    , verbose=0)\n\nrounded_predictions = np.argmax(predictions, axis=-1)\n\nacc = accuracy_score(y_test, rounded_predictions)\n\nprint(\"predictions:\", rounded_predictions)\nprint(\"actual: \", y_test)\nprint(\"accuracy: \", acc)","77e412e9":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","1d8ccbc4":"%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(y_true=y_test, y_pred=rounded_predictions)\ncm_plot_labels = ['Not Survived','Survived']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","4a720cda":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nneigh_clf = KNeighborsClassifier(n_neighbors=4)\nlog_clf = LogisticRegression()\nsvm_clf = SVC()\nvoting_clf = VotingClassifier(\nestimators=[('lr', log_clf), ('svc', svm_clf),('knn', neigh_clf)],\nvoting='hard'\n)\nvoting_clf.fit(X_train, y_train)\n\nfor clf in (log_clf, svm_clf,neigh_clf, voting_clf):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))","931d2ba5":"#SVM \n\nmodel = svm.SVC()\nmodel.fit(scaled_X, y)\n\nX_test = test_data[['Fare', 'Has_Cabin', 'no_of_fam', 'Age_Band',\n       'Sex_0', 'Sex_1', 'Pclass_0', 'Pclass_1', 'Pclass_2', 'Embarked_0',\n       'Embarked_1', 'Embarked_2', 'Title_0', 'Title_1', 'Title_2', 'Title_3',\n       'Title_4']].values\n\nscaled_X_test = scaler.fit_transform(X_test)\n\npredictions = model.predict(scaled_X_test)\n\nprint(\"predictions:\", predictions)","7e2f5ea2":"\nmodel = Sequential([\n    Dense(units=16, input_shape=(17,), activation='sigmoid'),\n    Dense(units=2, activation='sigmoid')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.02), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(x=scaled_X, y= y,validation_split=0.2, batch_size=15, epochs=60, shuffle=True, verbose=0)\n\npredictions = model.predict(x=scaled_X_test\n    , batch_size=15\n    , verbose=0)\nrounded_predictions = np.argmax(predictions, axis=-1)\n\nprint(\"predictions:\", rounded_predictions)","b324e3c1":"neigh_clf = KNeighborsClassifier(n_neighbors=4)\nlog_clf = LogisticRegression()\nsvm_clf = SVC()\nvoting_clf = VotingClassifier(\nestimators=[('lr', log_clf), ('svc', svm_clf),('knn', neigh_clf)],\nvoting='hard'\n)\nvoting_clf.fit(scaled_X, y)\n    \npredictions = voting_clf.predict(scaled_X_test)\nprint(\"predictions:\", predictions)","afb044b3":"# Train and Test data in Train dataset","c4260e44":"In this data visualization, you can play with it freely! which including filters and parameters. Specifically, the paremeter called \"column selected\", which you can change the showing column or feature in a graph and table. Also, please try click on pie chart anywhere in it, it will filter survived and not survived for the whole dashboard! (Except female and male icons)","2c7c5846":"# train data by SVM","b0392f05":"# train data by Simple Neural Network","2170b87a":"<div class='tableauPlaceholder' id='viz1598402811142' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ti&#47;TitanicDataVisualization_15983899037880&#47;TitanicDashboardKaggleDataset&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='TitanicDataVisualization_15983899037880&#47;TitanicDashboardKaggleDataset' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ti&#47;TitanicDataVisualization_15983899037880&#47;TitanicDashboardKaggleDataset&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1598402811142');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1024px';vizElement.style.height='795px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1024px';vizElement.style.height='795px';} else { vizElement.style.width='100%';vizElement.style.height='2527px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","59cf5c67":"# Train and Test data for competition","a851f437":"In this step, we are going to\n* clean the data\n* add new columns by conditioning existing columns\n","0018d3e6":"# Data Organization","77052d4e":"Data Skewness","a714ed6d":"# train data by Voting Classifier","961f3f53":"Reference:\n\n* Titanic Data Science Solutions by Manav Sehgal https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n\n* Introduction to Ensembling\/Stacking in Python https:\/\/www.kaggle.com\/arthurtok\/introduction-to-ensembling-stacking-in-python\n\n* A Data Science Framework: To Achieve 99% Accuracy https:\/\/www.kaggle.com\/ldfreeman3\/a-data-science-framework-to-achieve-99-accuracy","17c5c920":"We migth have heard and seen a movie about **the *Titanic*** before. We might have heard that most of adult male passengers died on that night. Why? It was a sacrifice, so that, female and youngers could survive with lifeboats. It was a mistake that all of lifeboats could not handle 2K of people. It was a tragic and lesson for humanity. However, today I am going to show that what we have heard is around **70%** true. Let's see!","57a5eee5":"# Data Visualization via seaborn","3d2555b0":"# Data Visualization via Tableau"}}