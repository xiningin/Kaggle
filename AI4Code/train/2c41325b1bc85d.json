{"cell_type":{"78130dba":"code","a8926596":"code","cab4658d":"code","d62eca23":"code","d6bd20f4":"code","3ca35f5b":"code","7f442124":"code","523ff690":"code","4606c264":"code","1c0d8564":"code","fb427b69":"code","6905c432":"code","51970b10":"code","f45605ac":"code","76b110a4":"code","27659f5a":"code","ab967f8b":"code","783095a6":"code","45127a9c":"code","ec5580fc":"code","5711eb22":"code","f4c11f7c":"code","215469d1":"code","9799a1b5":"code","ddeb1f2c":"code","57f904ac":"code","7bcaba53":"code","31fca93a":"code","b1687980":"code","2d7f2312":"code","4c9f5301":"code","28e3fd00":"code","74daab5e":"code","38a06c2d":"code","88111977":"code","e2538005":"code","80262170":"code","865eb799":"code","9d7a0666":"code","8a674da9":"code","e9b2eea0":"code","c3894e67":"code","eb9d939b":"code","178b038b":"code","1870bdc8":"code","10eadf28":"code","42ae358f":"code","0051bc06":"code","6f56bbd6":"code","610c3d4f":"code","68c3384a":"code","b2d24ac9":"code","6bf30734":"code","d573e9b9":"code","060b71b5":"code","005c7b16":"code","3eaa413f":"markdown","014e39d9":"markdown","de7e4079":"markdown","08d3fdcd":"markdown","7be8944a":"markdown","49562427":"markdown","5a3ce690":"markdown","f88ba81a":"markdown","4db09147":"markdown","557c8a9a":"markdown","a6e9c26b":"markdown","20730b8d":"markdown","859aaa89":"markdown","61535860":"markdown","591111e6":"markdown","41149e85":"markdown","5863769f":"markdown","c5eb32c0":"markdown","744fbda8":"markdown","2e46d53a":"markdown","3b1e96e0":"markdown","726190e6":"markdown","dc05f42e":"markdown","3e9f6de9":"markdown","14599034":"markdown","53d5b306":"markdown","3f4897fd":"markdown"},"source":{"78130dba":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a8926596":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport time\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n# missing value compensation\nfrom sklearn.impute import SimpleImputer\n\n# Feature Decompression\nfrom sklearn.feature_selection import RFE\n\n# Train Algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\n\n # select model\nfrom ipywidgets import interact,interactive,fixed,interact_manual\nfrom IPython.display import display\nimport ipywidgets as widgets","cab4658d":"# setting display option\npd.options.display.max_columns = 50","d62eca23":"# setting of path to dataset \ntrain_file = '\/kaggle\/input\/titanic\/train.csv'\ntest_file = '\/kaggle\/input\/titanic\/test.csv'\n\n# setting of submission file\nos.makedirs('\/kaggle\/working\/submit\/', exist_ok=True)\nsubmit_file_dir = '\/kaggle\/working\/'\nsubmit_file_name = 'submission.csv'","d6bd20f4":"# ID column in submission file\nID_column = 'PassengerId'\n\n# target data column of submission file\ntarget_value = 'Survived'","3ca35f5b":"# one-hot-encoding columns (categorical data)\nohe_columns = ['Pclass', 'Sex', 'SibSp','Parch', 'Embarked', 'Title_Group']\n\n# create dic to set data type for each column\nmy_dtype = {k: object  for k in ohe_columns}\nprint(my_dtype)","7f442124":"# Reject column list\nscore_reject_items =[ID_column,'Ticket', 'Cabin']\ntrain_reject_items = score_reject_items + [target_value]","523ff690":"# Read csv file\ndataset = pd.read_csv(train_file,\n                     header=0,    # CSV\u30c7\u30fc\u30bf\u306e1\u884c\u76ee\u304c\u898b\u51fa\u3057(header)\u3067\u6709\u308b\u3053\u3068\u3092\u6307\u5b9a\u3002\u30c7\u30fc\u30bf\u306f1\u884c\u76ee\u304c[0]\n                     dtype=my_dtype)\n\n# 1\u5217\u76ee\u306eID\u60c5\u5831\u3001\u63a8\u8ad6\u5bfe\u8c61\u306f\u7279\u5fb4\u91cf\u304b\u3089\u524a\u9664\n# pandas.core.frame.DataFrame\nX = pd.DataFrame(dataset).drop(columns=train_reject_items, axis=1)\n\n# pandas.core.series.Series\ny = pd.Series(dataset[target_value])\n\n# check the shape\nprint('----------------------------------------------------------------')\nprint('X shape: (%i,%i)' %X.shape)\nprint('----------------------------------------------------------------')\nprint('y shape: (%i,)' %y.shape)\nprint('----------------------------------------------------------------')\nprint(y.value_counts())\nprint('Survived\uff081\uff1ayes\u30010\uff1ano\uff09')\nprint('----------------------------------------------------------------')\nprint()\nprint('dataset:raw data')\ndisplay(dataset.head())\nprint('X:train dataset')\nX.join(y).head()","4606c264":"# csv\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u306e\u8aad\u307f\u51fa\u3057\ndataset_s = pd.read_csv(test_file,\n                          header=0,    # CSV\u30c7\u30fc\u30bf\u306e1\u884c\u76ee\u304c\u898b\u51fa\u3057(header)\u3067\u6709\u308b\u3053\u3068\u3092\u6307\u5b9a\u3002\u30c7\u30fc\u30bf\u306f1\u884c\u76ee\u304c[0]\n                          dtype=my_dtype)\n\n# 1\u5217\u76ee\u306eID\u60c5\u5831\u3001\u63a8\u8ad6\u5bfe\u8c61\u306f\u7279\u5fb4\u91cf\u304b\u3089\u524a\u9664\nID_s = dataset_s.iloc[:,[0]]    # \u7b2c\uff10\u5217\u306fPassengerID\u306a\u306e\u3067\u3001ID\u3068\u3057\u3066\u30bb\u30c3\u30c8\nX_s = dataset_s.drop(score_reject_items, axis=1)    # 1\u5217\u76ee\u306fID\u60c5\u5831\u306e\u305f\u3081\u7279\u5fb4\u91cf\u304b\u3089\u524a\u9664\n\n# \u5f62\u72b6\u306e\u78ba\u8a8d\nprint('-----------------------------------')\nprint('Raw Shape: (%i, %i)' %dataset_s.shape)\nprint('X_s Shape: (%i, %i)' %X_s.shape)\nprint('-----------------------------------')\nprint(X_s.dtypes)\nID_s.join(X_s).head()","1c0d8564":"# Missing values in each columns\ndataset.isnull().sum()","fb427b69":"# data type in each column\ndataset.dtypes","6905c432":"# To extract title from name\nX['Title'] = X.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand = False)\nprint(X.Title.unique())","51970b10":"# Binning Title into 'Title Group'\nMr = ['Mr']\nCrew1 = ['Don', 'Rev', 'Capt']\nCrew2 = ['Major', 'Col', 'Dr']\nWomen_Masters = ['Mrs', 'Miss', 'Master']\nAffluence = ['Mme', 'Ms', 'Lady', 'Sir', 'Mile', 'the Countess', 'Jonkheer']\n\nX['Title_Group'] = np.where(X['Title'] == Mr[0], 'Mr', 'Affluence')\nX['Title_Group'] = np.where(X['Title'].isin(Crew1),  \"Crew1\", X['Title_Group'])\nX['Title_Group'] = np.where(X['Title'].isin(Crew2),  \"Crew2\", X['Title_Group'])\nX['Title_Group'] = np.where(X['Title'].isin(Women_Masters),  \"Women_Masters\", X['Title_Group'])\nX['Title_Group'] = np.where(X['Title'].isin(Affluence),  \"Affluence\", X['Title_Group'])\nX = X.drop(columns=['Name', 'Title'])","f45605ac":"# Average for each Title Group\nTitleplot = X.join(y)['Survived'].groupby(X['Title_Group']).mean()\nTitleplot","76b110a4":"# column list for age prediction\ncols_age_prediction = ['Age', 'Pclass', 'Sex', 'Parch', 'SibSp']\n\n# One-Hot-Encoding\nage_X_df = X[cols_age_prediction]\nage_X_df = pd.get_dummies(age_X_df)\n\n# Diveide into 2 groups , train data and test data for age prediction\nknown_age_df = age_X_df[age_X_df.Age.notnull()]\nunknown_age_df = age_X_df[age_X_df.Age.isnull()]","27659f5a":"Age_X, Age_y = known_age_df.drop(columns=['Age'],axis=1) , known_age_df['Age']\n# Holdout(Split data)\nAge_X_train, Age_X_test, Age_y_train, Age_y_test=train_test_split(Age_X,\n                                               Age_y,\n                                               test_size=0.3,\n                                               random_state=1)\n# Training\nAge_lgb = lgb.LGBMRegressor()\nAge_lgb.fit(Age_X_train, Age_y_train)\n\n# Prediction\nAge_y_pred = Age_lgb.predict(unknown_age_df.drop(columns = ['Age'], axis=1))\n\n# Compensate missing value with predicted value\nX.loc[(X.Age.isnull()), 'Age'] = Age_y_pred","ab967f8b":"# Comfirmation of missing value\nX.isnull().sum()","783095a6":"def one_hot_encoding(data, ohe_columns):\n    X_ohe = pd.get_dummies(data,\n                       dummy_na=True,    # \u6b20\u640d\u5024\u3082\u30c0\u30df\u30fc\u5316\n                       columns=ohe_columns)\n    print('X_ohe shape:(%i,%i)' % X_ohe.shape)\n    display(X_ohe.head())\n    return X_ohe\n    \nX_ohe = one_hot_encoding(X, ohe_columns)","45127a9c":"X_ohe_columns = X_ohe.columns.values\nX_ohe_columns","ec5580fc":"def imputing_nan(X_ohe_for_training, X_ohe_apply_to):\n    \n    imp = SimpleImputer()    # default\u8a2d\u5b9a\u3067\u5e73\u5747\u5024\n    imp.fit(X_ohe_for_training)             # imp\u306b\u3066\u8a08\u7b97\u3059\u308b\u30c7\u30fc\u30bf\n    \n    X_ohe_columns =  X_ohe_for_training.columns.values\n    X_ohe = pd.DataFrame(imp.transform(X_ohe_apply_to), columns=X_ohe_columns)\n    display(X_ohe.head())\n    return X_ohe,  X_ohe_columns, imp\n\nX_ohe, X_ohe_columns, imp = imputing_nan(X_ohe, X_ohe)","5711eb22":"X_ohe.shape","f4c11f7c":"def dimension_compression(X_ohe, y):\n    start = time.time()\n    selector = RFE(RandomForestClassifier(n_estimators=100, random_state=1),\n               n_features_to_select=35, # \u5727\u7e2e\u5f8c\u306e\u6b21\u5143\u6570\n               step=.05)\n    selector.fit(X_ohe,y)\n    X_ohe_columns =  X_ohe.columns.values\n    \n    # selector.support_ list of True or False\n    X_fin = X_ohe.loc[:, X_ohe_columns[selector.support_]]\n    \n    # Duration time\n    duration = time.time() - start\n    print(duration,'s')\n    \n    print('Duration Time:', 'X_fin shape:(%i,%i)' % X_fin.shape)\n    display(X_fin.head())\n    return X_fin, selector\n    \nX_fin, selector = dimension_compression(X_ohe, y)","215469d1":"print('-----------------------------------')\nprint('X_fin shape: (%i,%i)' %X_fin.shape)\nprint('-----------------------------------')\nprint(y.value_counts())\nprint('--------------------------------------------------')\nprint('Survived\uff081\uff1ayes\u30010\uff1ano\uff09:')\nprint('--------------------------------------------------')\nprint('y shape: (%i,)' %y.shape)\nprint('--------------------------------------------------')","9799a1b5":"# set pipelines for different algorithms\n# \u30c7\u30a3\u30af\u30b7\u30e7\u30ca\u30ea\u30fc\u578b\u306epipelines\u306b\u3001\u30e2\u30c7\u30eb\u540d\u3092key\u3001\u5024\u306bpipeline\u306e\u30ea\u30b9\u30c8\u3092\u767b\u9332\npipelines = {\n    'knn':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',KNeighborsClassifier())]),\n    'logistic':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',LogisticRegression(random_state=1))]),\n    'rsvc':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',SVC(C=1.0, kernel='rbf', class_weight='balanced', random_state=1))]),\n    'lsvc':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',LinearSVC(C=1.0, class_weight='balanced',random_state=1))]),\n    'tree':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',DecisionTreeClassifier(random_state=1))]),\n    'rf':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',RandomForestClassifier(random_state=1))]),\n    'gb':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',GradientBoostingClassifier(random_state=1))]),\n    'mlp':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',MLPClassifier(hidden_layer_sizes=(3,3), max_iter=1000, random_state=1))]),\n    'xgb':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',xgb.XGBClassifier(verbosity = 0))]),\n    'lgbm':\n        Pipeline([('scl',StandardScaler()),\n                    ('est',lgb.LGBMClassifier())]),\n}","ddeb1f2c":"params = {\n    'knn' : {'est__n_neighbors':[5,7,10], 'est__weights':['uniform','distance'],},\n    \n    'logistic': {'est__C':[1, 100],},\n    \n    'rsvc': {'est__C':[1, 100],},\n    \n    'lsvc': {'est__C':[1, 100],},\n    \n    'tree': {'est__max_depth': list(range(10, 20)),\n             'est__criterion': ['gini', 'entropy'],},\n    \n    'rf': {'est__n_estimators':[320, 340],\n            'est__max_depth': [8, 10,16],\n            'est__random_state': [0],},\n    \n    'gb': {'est__loss':['deviance'],\n            'est__learning_rate': [0.01, 0.1],\n            'est__min_samples_split': np.linspace(0.1, 0.5, 2),\n            'est__min_samples_leaf': np.linspace(0.1, 0.5, 2),\n            'est__max_depth':[3,5],\n            'est__max_features':['log2','sqrt'],\n            'est__criterion': ['friedman_mse',  'mae'],\n            'est__subsample':[0.5, 1.0],\n            'est__n_estimators':[10],},\n    \n    'mlp': {'est__solver': ['lbfgs'],\n            'est__max_iter': [10000],\n            'est__alpha': 10.0 ** -np.arange(1, 3),\n            'est__hidden_layer_sizes':np.arange(10, 12),},\n    \n    'xgb': {'est__n_estimators':[100,500,],\n            'est__max_depth':[6, 8,10,],\n            'est__learning_rate':[0.001, 0.01, 0.1, 1,],\n            'est__min_child_weight': [1,6],},\n    \n    'lgbm': {'est__max_depth':[20, 50, 60,100],\n            'est__learning_rate':[0.001, 0.01, 0.1,1],\n            'est__num_leaves':[15, 31,64, 128],\n            'est__n_estimators':[100, 500, 700],},\n}","57f904ac":"# Holdout\nX_train, X_test, y_train, y_test=train_test_split(X_fin,\n                                               y,\n                                               test_size=0.3,\n                                               random_state=1)","7bcaba53":"import warnings\nwarnings.simplefilter('ignore')\n\n#  Metrics\nevaluation_scoring = 'f1'\n\n# Dict instance Initialization\nscores = {}\nbest_params ={}\nbest_scores ={}\n\n# algorithm pipeline and gridsearch\nfor pipe_name, pipeline in pipelines.items():\n    print(pipe_name)\n    print(params[pipe_name])\n    start = time.time()\n    gs = GridSearchCV(estimator=pipeline,\n                     param_grid = params[pipe_name],\n                     scoring=evaluation_scoring,\n                     cv=5,\n                     return_train_score=False)\n    # training\n    gs.fit(X_train, y_train)\n    \n    print('time', time.time()-start)\n    scores[(pipe_name,'train')] = accuracy_score(y_train, gs.predict(X_train))\n    scores[(pipe_name,'test')] = accuracy_score(y_test, gs.predict(X_test))\n    best_params[pipe_name] = gs.best_params_\n    best_scores[pipe_name] = gs.best_score_\n    \n    # Create directories to save each model data\n    os.makedirs('\/kaggle\/working\/models\/pipeline_models', exist_ok=True)\n    # Save model\n    file_name = '\/kaggle\/working\/models\/pipeline_models\/'+pipe_name+str(time.time())+'.pkl'\n    pickle.dump(pipeline, open(file_name, 'wb'))\n\nprint('---accuracy---')\npd.Series(scores).unstack()","31fca93a":"print(scores)\nprint()\nprint(best_scores)\nprint()\nprint(best_params)","b1687980":"def get_answer(x):\n    return x","2d7f2312":"model_selection = get_answer(widgets.RadioButtons(options=pipelines.keys()))\ndisplay(model_selection)","4c9f5301":"selected_model_name = model_selection.value\nprint(selected_model_name)","28e3fd00":"best_params[selected_model_name]","74daab5e":"# best_params[seleced_model_name]\u306evalue\u3092\u30ea\u30b9\u30c8\u5316\u3059\u308b\ndef params_parser(best_params, selected_model_name):\n    return {k:[v] for k,v in best_params[selected_model_name].items()}","38a06c2d":"best_param_parsed = params_parser(best_params, selected_model_name)\nprint(best_param_parsed)","88111977":"def train_on_selected_model(pipe_name, pipelines, params, evaluation_scoring, tag):\n    start = time.time()\n    gs = GridSearchCV(estimator=pipelines[pipe_name],\n                     param_grid = params,\n                     scoring=evaluation_scoring,\n                     cv=5,\n                     return_train_score=False)\n    # fit\n    model = gs.fit(X_fin, y)\n    \n    print('time', time.time()-start)\n    scores[(pipe_name,'train')] = accuracy_score(y_train, gs.predict(X_train))\n    scores[(pipe_name,'test')] = accuracy_score(y_test, gs.predict(X_test))\n    \n    # Create directories\n    os.makedirs('\/kaggle\/working\/models\/', exist_ok=True)\n     # To save model\n    file_name = '\/kaggle\/working\/models\/' + pipe_name + '_' + tag + str(time.time())+'.pkl'\n    pickle.dump(model, open(file_name, 'wb'))\n    \n    return model","e2538005":"selected_model = train_on_selected_model(selected_model_name, pipelines, best_param_parsed, evaluation_scoring, 'selected')","80262170":"from sklearn import metrics\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ny_pred_m = selected_model.predict(X_fin)\n\n# FPR, TPR(\nfpr, tpr, thresholds = metrics.roc_curve(y, y_pred_m)\n\n# AUC\nauc = metrics.auc(fpr, tpr)\n\n# Plot ROC curve\nplt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","865eb799":"from sklearn.metrics import f1_score\nprint(f1_score(y, y_pred_m))","9d7a0666":"X_s.isnull().sum()","8a674da9":"# Name\u304b\u3089\u656c\u79f0(Title)\u306e\u62bd\u51fa\nX_s['Title'] = X_s.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand = False)\n\nX_s['Title_Group'] = np.where(X_s['Title'] == Mr[0], 'Mr', 'Affluence')\nX_s['Title_Group'] = np.where(X_s['Title'].isin(Crew1),  \"Crew1\", X_s['Title_Group'])\nX_s['Title_Group'] = np.where(X_s['Title'].isin(Crew2),  \"Crew2\", X_s['Title_Group'])\nX_s['Title_Group'] = np.where(X_s['Title'].isin(Women_Masters),  \"Women_Masters\", X_s['Title_Group'])\nX_s['Title_Group'] = np.where(X_s['Title'].isin(Affluence),  \"Affluence\", X_s['Title_Group'])\nX_s = X_s.drop(columns=['Name', 'Title'])","e9b2eea0":"X_s.head()","c3894e67":"# One-Hot-Encoding\nage_df_s = X_s[cols_age_prediction]\nage_df_s = pd.get_dummies(age_df_s)\n\n\n# Select data by Age value condition\nunknown_age_s = age_df_s[age_df_s.Age.isnull()].values\nunknown_age_s_df = age_df_s[age_df_s.Age.isnull()]\n\ncols_train_Age= set(unknown_age_df.columns.values)\ncols_test_Age = set(unknown_age_s_df.columns.values)\n\ndiff1 = cols_train_Age - cols_test_Age\nprint('Columns of existing in training data: %s' %diff1)\n\ndiff2 = cols_test_Age - cols_train_Age\nprint('Columns of existing in test data for submission: %s' %diff2)\n\n# Predict age for test data \nAge_s_y_pred = Age_lgb.predict(unknown_age_s_df.drop(columns = ['Age']+list(diff2), axis=1))\nX_s.loc[(X_s.Age.isnull()), 'Age'] = Age_s_y_pred","eb9d939b":"X_s.isnull().sum()","178b038b":"X_ohe_s = pd.get_dummies(X_s,\n                         dummy_na=True,\n                         columns=ohe_columns)\nprint('X_ohe_s shape:(%i,%i)' % X_ohe_s.shape)\nX_ohe_s.head(3)","1870bdc8":"cols_model= set(X_ohe.columns.values)\ncols_score = set(X_ohe_s.columns.values)\n\ndiff1 = cols_model - cols_score\nprint('Columns of existing in training data:: %s' %diff1)\n\ndiff2 = cols_score - cols_model\nprint('Columns of existing in test data for submission: %s' %diff2)","10eadf28":"dataset_cols_m = pd.DataFrame(None,\n                         columns=X_ohe_columns,\n                         dtype=float)\ndisplay(dataset_cols_m)","42ae358f":"X_ohe_s = pd.concat([dataset_cols_m, X_ohe_s])\nprint(X_ohe_s.shape)\ndisplay(X_ohe_s.head(3))","0051bc06":"set_Xm = set(X_ohe.columns.values)\nset_Xs = set(X_ohe_s.columns.values)\nprint(set_Xs-set_Xm)\nX_ohe_s = X_ohe_s.drop(list(set_Xs-set_Xm),axis=1)\n\nprint(X_ohe_s.shape)\ndisplay(X_ohe_s.head(3))","6f56bbd6":"print(set_Xm-set_Xs)\nX_ohe_s.loc[:,list(set_Xm-set_Xs)] = X_ohe_s.loc[:,list(set_Xm-set_Xs)].fillna(0,axis=1)\nX_ohe_s.head(3)","610c3d4f":"X_ohe_s = X_ohe_s.reindex(X_ohe_columns, axis=1)\nX_ohe_s.head(3)\nprint(X_ohe_s.shape)","68c3384a":"X_ohe_s.isnull().sum()","b2d24ac9":"print('\u6b20\u640d\u500b\u6570\uff08\u6570\u5024\u5909\u6570\u306e\u6b20\u640d\u88dc\u5b8c\u524d\uff09',X_ohe_s.isnull().sum().sum())    # row\u3092sum()\u3057\u3066\u3001column\u3092sum()\u3059\u308b\n\n# (\u91cd\u8981)\u30e2\u30c7\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u3067\u4f5c\u3063\u305fimp\u3092\u4f7f\u3063\u3066transform\u3059\u308b\n# \u3082\u3057\u3053\u3053\u3067\u6539\u3081\u3066imp\u3057\u305f\u3089\u3001\u6539\u3081\u3066\u8a08\u7b97\u3055\u308c\u3066\u3057\u307e\u3046\u3002\u305d\u306e\u305f\u3081\u30e2\u30c7\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u3067\u4f7f\u3063\u305f\u5e73\u5747\u5024\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066transform\u3059\u308b\nX_ohe_s = pd.DataFrame(imp.transform(X_ohe_s),columns=X_ohe_columns)\n\nprint('\u6b20\u640d\u500b\u6570\uff08\u6570\u5024\u5909\u6570\u306e\u6b20\u640d\u88dc\u5b8c\u5f8c\uff09',X_ohe_s.isnull().sum().sum())","6bf30734":"X_fin_s = X_ohe_s.loc[:, X_ohe_columns[selector.support_]]\nprint(X_fin_s.shape)\nX_fin_s.head(3)\nX_fin_s = X_ohe_s","d573e9b9":"print('-----------------------------------')\nprint('X_fin_s shape: (%i,%i)' %X_fin_s.shape)\nprint('-----------------------------------')","060b71b5":"y_pred = selected_model.predict(X_fin_s)\nprint(len(y_pred))","005c7b16":"result_for_submit = pd.DataFrame({ID_column:dataset_s[ID_column], target_value:y_pred})\n\nos.makedirs(submit_file_dir, exist_ok=True)\nresult_for_submit.to_csv(submit_file_dir+ selected_model_name + '_' + submit_file_name , index=False)","3eaa413f":"## 4. \u30c7\u30fc\u30bf\u524d\u51e6\u7406\n### 4-1. \u656c\u79f0\u306e\u62bd\u51fa","014e39d9":"## 9. \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\n### 9-1. \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u6b20\u640d\u5024\u306e\u78ba\u8a8d","de7e4079":"### 4-4. Simple Imputer\u3092\u7528\u3044\u305f\u6b20\u640d\u5024\u88dc\u5b8c","08d3fdcd":"# \u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u305f\u3081\u306e\u7c21\u6613Auto ML\n\n\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u306e\u30c6\u30fc\u30d6\u30eb\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u3001\u8907\u6570\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306b\u4e26\u3079\u3001\u540c\u6642\u306bGridSearch\u3092\u884c\u3046\u4e00\u9023\u306e\u6d41\u308c\u3092\u6574\u7406\u3057\u307e\u3057\u305f\u3002  \n\u7c21\u6613\u7684\u306b\u8907\u6570\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u7528\u3057\u3001\u6700\u9069\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u3092GridSearch\u306b\u3066\u63a2\u7d22\u3057\u307e\u3059\u3002  \n\n1. \u6e96\u5099\uff08\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\uff09\n2. \u30c7\u30fc\u30bf\u306e\u6e96\u5099\u3001\u8a2d\u5b9a\n3. \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8aad\u307f\u8fbc\u307f\n4. \u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7406  \n  4-1. \u656c\u79f0\u306e\u62bd\u51fa  \n  4-2. \u6b20\u640d\u5024\u306e\u88dc\u5b8c(\u5e74\u9f62\u30c7\u30fc\u30bf\u3092\u4e88\u6e2c\u3059\u308b\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u3001\u4e88\u6e2c\u7d50\u679c\u306b\u3066\u6b20\u640d\u5024\u3092\u88dc\u5b8c\u3059\u308b)  \n  4-3. One Hot \u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0  \n  4-4. Simple Imputer\u3092\u7528\u3044\u305f\u6b20\u640d\u5024\u88dc\u5b8c  \n  4-5. RFE\u3092\u7528\u3044\u305f\u6b21\u5143\u5727\u7e2e  \n5. pipeline\u306e\u8a2d\u5b9a  \n  5-1. \u4f7f\u7528\u3059\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092Pipeline\u3068\u3057\u3066\u4e26\u3079\u308b  \n  5-2. GridSearch\u306b\u4f7f\u7528\u3059\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8a2d\u5b9a  \n6. pipeline\u306b\u3066\u5b9a\u7fa9\u3057\u305f\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092Grid Search\u3068\u3068\u3082\u306b\u5b9f\u884c\u3059\u308b  \n7. \u6700\u7d42\u7684\u306b\u4f7f\u7528\u3059\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u9078\u629e  \n8. \u5168\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u305f\u5b66\u7fd2  \n9. \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c  \n  9-1. \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u6b20\u640d\u5024\u306e\u78ba\u8a8d  \n  9-2. \u656c\u79f0\u306e\u62bd\u51fa  \n  9-3. \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3068\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u6bd4\u8f03  \n  9-4. One Hot \u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0  \n  9-5. \u30ab\u30e9\u30e0\u306e\u9078\u629e  \n  9-6. \u30ab\u30e9\u30e0\u306e\u4e26\u3073\u9806\u5e8f\u306e\u62c5\u4fdd\n  9-7. \u6b20\u640d\u5024\u88dc\u5b8c  \n  9-8. \u6b21\u5143\u5727\u7e2e(selector\u3092\u4f7f\u3063\u3066\u4f7f\u7528\u3059\u308b\u30ab\u30e9\u30e0\u3092\u9078\u629e\u3059\u308b)  \n10. \u4e88\u6e2c\n11. \u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210","7be8944a":"### 9-5. \u30ab\u30e9\u30e0\u306e\u9078\u629e","49562427":"## 7. \u6700\u7d42\u7684\u306b\u4f7f\u7528\u3059\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u9078\u629e","5a3ce690":"## 5. Pipeline\u306e\u5b9a\u7fa9\n### 5-1. Pipeline  \n\u4f7f\u7528\u3059\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092Pipeline\u3068\u3057\u3066\u4e26\u3079\u308b","f88ba81a":"### 4-4. RFE\u3092\u7528\u3044\u305f\u6b21\u5143\u5727\u7e2e","4db09147":"### 4-3. One Hot \u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\nohe_columns\u306b\u3066\u5b9a\u7fa9\u3057\u305fColumn\u306b\u5bfe\u3057\u3066One Hot\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3092\u5b9f\u65bd\u3059\u308b","557c8a9a":"### 3-2. test data","a6e9c26b":"### 5-2. GridSearch\u306b\u4f7f\u7528\u3059\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8a2d\u5b9a","20730b8d":"## 11. \u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210","859aaa89":"## 2. \u30c7\u30fc\u30bf\u306e\u8a2d\u5b9a","61535860":"### 4-2. \u6b20\u640d\u5024\u306e\u88dc\u5b8c(\u5e74\u9f62\u30c7\u30fc\u30bf\u3092\u4e88\u6e2c\u3059\u308b\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u3001\u4e88\u6e2c\u7d50\u679c\u306b\u3066\u6b20\u640d\u5024\u3092\u88dc\u5b8c\u3059\u308b)","591111e6":"### 8. \u5168\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u305f\u5b66\u7fd2","41149e85":"### 9-4. One-hot-encoding Process","5863769f":"### 9-6. \u30ab\u30e9\u30e0\u306e\u4e26\u3073\u9806\u5e8f\u306e\u62c5\u4fdd  ","c5eb32c0":"Select alogorithm with radio button","744fbda8":"Data cleaning after one-hot-encoding","2e46d53a":"### 9-3. \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3068\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u6bd4\u8f03","3b1e96e0":"## 3. \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8aad\u307f\u51fa\u3057\n### 3-1. train data","726190e6":"## 1. \u6e96\u5099","dc05f42e":"### 9-2. \u656c\u79f0\u306e\u62bd\u51fa","3e9f6de9":"## 10. \u4e88\u6e2c","14599034":"### 9-8. \u6b21\u5143\u5727\u7e2e(selector\u3092\u4f7f\u3063\u3066\u4f7f\u7528\u3059\u308b\u30ab\u30e9\u30e0\u3092\u9078\u629e\u3059\u308b)","53d5b306":"### 9-7. \u6b20\u640d\u5024\u88dc\u5b8c  \n\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u751f\u6210\u3057\u305fimp\u3092\u7528\u3044\u3066\u6b20\u640d\u5024\u3092\u88dc\u5b8c\u3059\u308b\u3002\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u8a08\u7b97\u3059\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u3002","3f4897fd":"## 6. pipeline\u306b\u3066\u5b9a\u7fa9\u3057\u305f\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092Grid Search\u3068\u3068\u3082\u306b\u5b9f\u884c\u3059\u308b"}}