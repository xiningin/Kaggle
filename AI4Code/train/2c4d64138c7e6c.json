{"cell_type":{"17334b80":"code","636377f6":"code","eb6784d2":"code","1911110e":"code","5666519c":"code","1918f7d0":"code","b1f7d29b":"code","8c5adb18":"markdown","711e05fd":"markdown","5b144077":"markdown","0277bfd5":"markdown","a3841283":"markdown"},"source":{"17334b80":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom xgboost import XGBRegressor\n\ndata = pd.read_csv('..\/input\/train.csv')\ndata.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = data.SalePrice\nX = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\ntrain_X, test_X, train_y, test_y = train_test_split(X.values, y.values, test_size=0.25)\n\nmy_imputer = SimpleImputer()\ntrain_X = my_imputer.fit_transform(train_X)\ntest_X = my_imputer.transform(test_X)\n\nmy_model = XGBRegressor(n_estimators=1000, \n                        max_depth=5, \n                        learning_rate=0.1, \n                        subsample=0.7, \n                        colsample_bytree=0.8, \n                        colsample_bylevel=0.8, \n                        base_score=train_y.mean(), \n                        random_state=42, seed=42)\nhist = my_model.fit(train_X, train_y, \n                    early_stopping_rounds=5, \n                    eval_set=[(test_X, test_y)], eval_metric='rmse', \n                    verbose=100)","636377f6":"test_pred = my_model.predict(test_X)\nerrors = test_pred - test_y\nsorted_errors = np.argsort(abs(errors))\nworse_5 = sorted_errors[-5:]\nbest_5 = sorted_errors[:5]\n\nprint(pd.DataFrame({'worse':errors[worse_5]}))\nprint()\nprint(pd.DataFrame({'best':errors[best_5]}))","eb6784d2":"import lime\nimport lime.lime_tabular\nexplainer = lime.lime_tabular.LimeTabularExplainer(train_X, feature_names=X.columns, class_names=['SalePrice'], verbose=True, mode='regression')","1911110e":"i = worse_5[0]\nprint('Error =', errors[i])\nexp = explainer.explain_instance(test_X[i], my_model.predict, num_features=10)\nexp.show_in_notebook(show_table=True)","5666519c":"i = worse_5[1]\nprint('Error =', errors[i])\nexp = explainer.explain_instance(test_X[i], my_model.predict, num_features=10)\nexp.show_in_notebook(show_table=True)","1918f7d0":"i = best_5[0]\nprint('Error =', errors[i])\nexp = explainer.explain_instance(test_X[i], my_model.predict, num_features=10)\nexp.show_in_notebook(show_table=True)","b1f7d29b":"i = best_5[1]\nprint('Error =', errors[i])\nexp = explainer.explain_instance(test_X[i], my_model.predict, num_features=10)\nexp.show_in_notebook(show_table=True)","8c5adb18":"Explaining a few worse predictions:","711e05fd":"### LIME (Local Interpretable Model-Agnostic Explanations)","5b144077":"Explaining a few best predictions:","0277bfd5":"## Loading Data and XGB-Model","a3841283":"## Best and Worse Predictions"}}