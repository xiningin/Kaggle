{"cell_type":{"edb2ffff":"code","a730cf36":"code","6d090556":"code","f895293e":"code","32b9389a":"code","e12d6923":"code","78fef636":"code","db8c904e":"code","ae77d7fa":"code","2674dd07":"code","629e00b8":"code","488d217f":"code","79b9edc7":"code","60f025ee":"code","129ed413":"code","3d9d60fd":"code","65778346":"code","da7f3a7e":"code","d06018f6":"code","5d2d0796":"code","fbb4297b":"code","38457450":"code","45c8457c":"code","4f0034c4":"code","2ee1daef":"code","14331641":"code","47c1952f":"code","4989c67e":"code","c27b929e":"code","92f28a91":"code","e4df33fb":"code","89745efe":"code","7fb84462":"code","3d026842":"code","04df5f8a":"code","bcb40490":"code","ffeb360a":"code","ff5dc842":"code","27e7cdb3":"code","0135efdd":"code","1637c2dd":"code","7a2fae4e":"code","f3e638ba":"code","e0bb379b":"code","5e84172f":"code","2ea836fc":"code","0f66c4c4":"code","774a6a4b":"code","ae829280":"code","14dddf2a":"code","cc666870":"code","d12e9bff":"code","b52af06e":"code","46fa81bb":"code","9b6a7d7a":"code","b394e019":"code","120bbc1f":"code","f21d5c51":"code","87cb3ce9":"code","808e20c7":"code","d20a67b1":"markdown","652fed5a":"markdown"},"source":{"edb2ffff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a730cf36":"#bir data 3 e bolunmus. \ndata_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")    \ndata_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndata_gender = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","6d090556":"data_train.head()","f895293e":"data_test.head()","32b9389a":"data_gender.head()","e12d6923":"# daginik olan test verisini birlestirelim\ndata_test2 = pd.merge(data_test, data_gender, on = 'PassengerId') \ndata_test2.head()","78fef636":"len(data_test2.columns)","db8c904e":"len(data_train.columns)","ae77d7fa":"data_test2.columns==data_train.columns","2674dd07":"data_train.columns","629e00b8":"data_test2.columns","488d217f":"#kolonlari yer degistirdik. train i test ile ayni sirada yaptik.\n\ndata_train2 = data_train[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Survived']]\ndata_train2.tail()","79b9edc7":"data_test2.columns == data_train2.columns","60f025ee":"data_test2.head()","129ed413":"data_train2.head()","3d9d60fd":"#esitledigimiz datalari alt alta concat ettik\ndata = pd.concat([data_train2,data_test2], ignore_index=True)\ndata.head(3)","65778346":"data_train.PassengerId.count()\n","da7f3a7e":"data_test.PassengerId.count()","d06018f6":"data_train.PassengerId.count() + data_test.PassengerId.count()","5d2d0796":"data.PassengerId.count()","fbb4297b":"data","38457450":"data.info()","45c8457c":"data.describe().T #sadece int ve float alir","4f0034c4":"#korelasyon\n\ndata.corr()","2ee1daef":"#cabin de kac cesit unique deger var.    \ndata.Cabin.unique()","14331641":"data.Name.unique().size    #ile toplam sayiya bakabilirsiniz.","47c1952f":"# Name sutununda tekrar eden degerleri sorgular\ndata[\"Name\"].value_counts()","4989c67e":"data[data[\"Name\"]==\"Kelly, Mr. James\"]","c27b929e":"data[data[\"Name\"]==\"Connolly, Miss. Kate\"]","92f28a91":"# Ticket sutununda tekrar eden degerleri sorgular\n\ndata[\"Ticket\"].value_counts()","e4df33fb":"data[data[\"Ticket\"]==\"CA. 2343\"]\n\n#not bu 11 kisiye bakip yorum yapmaya calisin.","89745efe":"# sutunlardaki bos\/NaN degerleri toplar.\ndata.isna().sum()","7fb84462":"#kolon isimlerini turkcelestirelim.\n\ndata.rename(columns={\"PassengerId\": \"YolcuID\", \n                     \"Pclass\": \"Sinif\",\n                     \"Name\": \"Ad_Soyad\",\n                     \"Sex\": \"Cinsiyet\",\n                     \"Age\" : \"Yas\",\n                     \"SibSp\":\"Aile_1\",\n                     \"Parch\" : \"Aile_2\",\n                     \"Ticket\" : \"BiletID\",\n                     \"Fare\" : \"Fiyati\",\n                     \"Cabin\" : \"KoltukNO\",\n                     \"Embarked\" : \"Liman\",\n                     \"Survived\" : \"Yasam\"\n                    }, inplace=True)   ","3d026842":"data.columns","04df5f8a":"data.head()","bcb40490":"#icerikleri replace edelim.\n\ndata[\"Yasam\"].replace(0,\"oldu\", inplace=True)\ndata[\"Yasam\"].replace(1,\"yasiyor\", inplace=True)\ndata[\"Liman\"].replace(\"S\",\"Southampton\", inplace=True)\ndata[\"Liman\"].replace(\"C\",\"Cherbourg\", inplace=True)\ndata[\"Liman\"].replace(\"Q\",\"Queenstown\", inplace=True)\ndata[\"Cinsiyet\"].replace(\"male\",\"Erkek\", inplace=True)\ndata[\"Cinsiyet\"].replace(\"female\",\"Kadin\", inplace=True)\n\ndata.head(10)","ffeb360a":"# NaN Degerleri dolduralim.   > fillna\n\ndata[\"KoltukNO\"].fillna(\"Belirsiz\", inplace=True)\ndata.head()","ff5dc842":"#cinsiyete gore gruplayip, sayalim\n\ndata.Cinsiyet.groupby(data.Cinsiyet).count()","27e7cdb3":"# Yasam durumuna gore gruplayip, sayalim\n\ndata.Yasam.groupby(data.Yasam).count()","0135efdd":"#sinifi ==1 ve cinsiyeti == kadin olan degerler. coklu suzme\n\ndata[(data['Sinif'] == 1) & (data['Cinsiyet'] == 'Kadin')]","1637c2dd":"#bazi sutunlari drop edelim\n\ndata.drop([\"Aile_1\",\"Aile_2\"],axis=1, inplace=True)","7a2fae4e":"data.head()","f3e638ba":"#kadin ve erkekleri ayri ayri tutalim.\nerkekler = data[data[\"Cinsiyet\"]==\"Erkek\"]\nkadinlar = data[data[\"Cinsiyet\"]==\"Kadin\"]\ncocuklar = data[data[\"Yas\"]<=18]\n\nkadinlar.head()","e0bb379b":"kadinlar.Yas.mean()","5e84172f":"erkekler.Yas.mean()","2ea836fc":"# kac cocuk var? \ncocuklar.YolcuID.count()","0f66c4c4":"cocuklar.Yas.mean()","774a6a4b":"sinif_1 = data[data[\"Sinif\"] == 1]\nsinif_2 = data[data[\"Sinif\"] == 2]\nsinif_3 = data[data[\"Sinif\"] == 3]","ae829280":"# verideki siniflarin yas ve fiyat ortalamalarini alacak.\ndata.groupby(\"Sinif\")[\"Yas\",\"Fiyati\"].mean()","14dddf2a":"#farkli islemler yapalim. Onun icin hazir veriyi copy edelim\nveri = data.copy()\nveri.head()","cc666870":"#verideki NaN degerleri ve o satiri atacak\nveri.dropna(inplace=True)","d12e9bff":"veri.count()","b52af06e":"#yasi integer yaptik ve tekrar yas sutunu ile degisim yaptik.\nveri[\"Fiyati\"] = veri.Fiyati.astype('int64')","46fa81bb":"veri.head()","9b6a7d7a":"#her kolondaki en yuksek veriyi getirir.\nveri.apply(np.max)","b394e019":"# Yasi 80 olan kisi\nveri[veri[\"Yas\"] >= 80]","120bbc1f":"veri[\"Yas\"]","f21d5c51":"a = veri.iloc[:,[2,3]]","87cb3ce9":"a.T","808e20c7":"# pivot almak, satirlari sutun yapmak\n\nveri.pivot(index ='Ad_Soyad', columns ='YolcuID')\n","d20a67b1":"**Istatiksel islemler icin veride bazi degisiklikler yapalim. **\n\nData uzerinde bilerek yapmadik. Cunku; Amacimiz ML degil, veri uzerinde pandas metodlari uygulamaktir","652fed5a":"demekki zenginler daha yasli :) "}}