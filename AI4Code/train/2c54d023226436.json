{"cell_type":{"37470761":"code","6a7572ad":"code","b1bd4573":"code","7ac966db":"code","ef933cc6":"code","97befbaf":"code","4907c5fd":"code","76ecc07a":"code","c4535779":"code","c70fd0d0":"code","be5c4287":"code","28bd18c1":"code","4b70247d":"code","63e9eb6c":"code","760a8edd":"code","3183dad6":"code","c47682cf":"markdown"},"source":{"37470761":"import os\nprint(len(os.listdir('\/kaggle\/input\/dl-and-ai-with-sadiq\/Train\/Train')))","6a7572ad":"classes = 10\nimg_rows, img_cols = 512, 512\nbatch_size = 512","b1bd4573":"import cv2\nimport matplotlib.pyplot as plt\nimg = cv2.imread('\/kaggle\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Angrybirds\/Ang (100).jpeg')\nplt.imshow(img)","7ac966db":"from keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = '\/kaggle\/input\/dl-and-ai-with-sadiq\/Train\/Train'\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                            rotation_range = 45,\n                            zoom_range = 0.2,\n                            width_shift_range = 0.3,\n                            height_shift_range = 0.3,\n                            shear_range = 0.2,\n                            horizontal_flip = True,\n                            vertical_flip = True,\n                            fill_mode = 'nearest',\n                            validation_split = 0.3)\n\ntrain_generator= train_datagen.flow_from_directory(TRAIN_DIR,\n                                             subset='training',\n                                             target_size=(img_rows, img_cols),\n                                             batch_size=batch_size,\n                                             class_mode='categorical')\n\nvalidation_datagen = ImageDataGenerator(validation_split = 0.3)\n\nvalidation_datagen=validation_datagen.flow_from_directory(TRAIN_DIR,\n                                                          subset='validation',\n                                                          target_size=(img_rows, img_cols),\n                                                          batch_size=batch_size,\n                                                          class_mode='categorical')","ef933cc6":"nb_train_samples = 1485  \nnb_validation_samples = 630 \n\nepochs = 50","97befbaf":"from keras.applications import VGG19from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.models import Model\n\n\n# Re-loads the MobileNet model without the top or FC layers\nvgg16 = VGG16(weights = 'imagenet',include_top = False,input_shape = (img_rows, img_cols, 3))\n\nfor layer in vgg16.layers:\n    layer.trainable = False\n    \n\ndef addTopModelvgg16(bottom_model, num_classes):\n    \"\"\"creates the top or head of the model that will be \n    placed ontop of the bottom layers\"\"\"\n\n    top_model = bottom_model.output\n    top_model = GlobalAveragePooling2D()(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(512,activation='relu')(top_model)\n    top_model = Dense(num_classes,activation='softmax')(top_model)\n    return top_model\n\n\nnum_classes = classes\n\nFC_Head = addTopModelvgg16(vgg16, num_classes)\n\nmodel = Model(inputs = vgg16.input, outputs = FC_Head)","4907c5fd":"from keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n                   \ncheckpoint = ModelCheckpoint(\"vgg16_1.h5\",\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 15,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.01,\n                              patience = 2,\n                              verbose = 1)\n\n# we put our call backs into a callback list\ncallbacks = [checkpoint, reduce_lr, reduce_lr]\n\n# Note we use a very small learning rate \nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = RMSprop(lr = 0.0001),\n              metrics = ['accuracy'])\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples \/\/ batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_datagen,\n    validation_steps = nb_validation_samples \/\/ batch_size)","76ecc07a":"result = pd.DataFrame(history.history)\nresult.head(5)","c4535779":"result.plot(figsize=(10,8))","c70fd0d0":"print(\"Max Training Accurracy: \",result['accuracy'].max())\nprint(\"Min Training Loss: \",result['loss'].min())\nprint(\"Max Validation Accurracy: \",result['val_accuracy'].max())\nprint(\"Min Validation Loss: \",result['val_loss'].min())","be5c4287":"result.plot(figsize=(10,8))","28bd18c1":"result = pd.DataFrame(history.history)\nprint(\"Max Training Accurracy: \",result['accuracy'].max())\nprint(\"Min Training Loss: \",result['loss'].min())\nprint(\"Max Validation Accurracy: \",result['val_accuracy'].max())\nprint(\"Min Validation Loss: \",result['val_loss'].min())","4b70247d":"result.plot(figsize=(10,8))","63e9eb6c":"from keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n                   \n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 15,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.1,\n                              patience = 1,\n                              verbose = 1,\n                              min_lr= 0.000000001)\n# we put our call backs into a callback list\ncallbacks = [checkpoint, reduce_lr, reduce_lr]\n\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples \/\/ batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_datagen,\n    validation_steps = nb_validation_samples \/\/ batch_size)","760a8edd":"result = pd.DataFrame(history.history)\nresult.plot(figsize=(10,8))","3183dad6":"print(\"Max Training Accurracy: \",result['accuracy'].max())\nprint(\"Min Training Loss: \",result['loss'].min())\nprint(\"Max Validation Accurracy: \",result['val_accuracy'].max())\nprint(\"Min Validation Loss: \",result['val_loss'].min())","c47682cf":"# Didn't improved anyhow. I guess this is the limit"}}