{"cell_type":{"d1ccc5ff":"code","03ae5c8f":"code","981d804e":"code","ca93147f":"code","ece39f20":"code","450629df":"code","df7a94b1":"code","c9f7803b":"code","2ca00d4e":"code","124c6d60":"code","e0d3e77b":"code","17f9ca7b":"code","be0237cc":"code","1cbdbca6":"code","3fa3190a":"code","7d079cdb":"code","7d0960a0":"code","fc13a1b6":"code","f7697419":"code","f5a201a5":"markdown","b2d6bb2d":"markdown","822c0508":"markdown","dc26a70b":"markdown","631e7049":"markdown","9551c25e":"markdown","8bf03628":"markdown","4ccf9033":"markdown","f82461e7":"markdown","b32d19b3":"markdown"},"source":{"d1ccc5ff":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.models import load_model\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","03ae5c8f":"EPOCHS = 50\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\ndirectory_root = '..\/input\/leaf-disease'\nwidth=256\nheight=256\ndepth=3","981d804e":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","ca93147f":"image_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}\/{plant_folder}\")\n        \n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}\/{plant_folder}\/{plant_disease_folder}\/\")\n                \n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n\n            for image in plant_disease_image_list[:30]:\n                image_directory = f\"{directory_root}\/{plant_folder}\/{plant_disease_folder}\/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convert_image_to_array(image_directory))\n                    label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")","ece39f20":"image_size = len(image_list)","450629df":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)","df7a94b1":"print(label_binarizer.classes_)","c9f7803b":"np_image_list = np.array(image_list, dtype=np.float16) \/ 225.0","2ca00d4e":"print(\"[INFO] Spliting data to train, test\")\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) ","124c6d60":"aug = ImageDataGenerator(\n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")","e0d3e77b":"model = Sequential()\ninputShape = (height, width, depth)\nchanDim = -1\nif K.image_data_format() == \"channels_first\":\n    inputShape = (depth, height, width)\n    chanDim = 1\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes))\nmodel.add(Activation(\"softmax\"))","17f9ca7b":"model.summary()","be0237cc":"opt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\n# distribution\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n# train the network\nprint(\"[INFO] training network...\")","1cbdbca6":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) \/\/ BS,\n    epochs=EPOCHS, verbose=1\n    )","3fa3190a":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","7d079cdb":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","7d0960a0":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('cnn_model.pkl', 'wb'))\nmodel.save('cnn_modell.h5')","fc13a1b6":"model_file = pickle.load(open('cnn_model.pkl', 'rb'))\nmodel_f = load_model('cnn_modell.h5')","f7697419":"pic = cv2.imread('\/kaggle\/input\/normal-leaf\/normal_leaf.jpg')\npic = cv2.resize(pic,(256,256))\npic = np.reshape(pic,[1,256,256,3])\ny_prob = model_f.predict(pic) \ny_classes = y_prob.argmax(axis=-1)\nprint(y_classes)","f5a201a5":"Get Size of Processed Image","b2d6bb2d":"Plot the train and val curve","822c0508":"Fetch images from directory","dc26a70b":"Transform Image Labels uisng [Scikit Learn](http:\/\/scikit-learn.org\/)'s LabelBinarizer","631e7049":"Save model using Pickle","9551c25e":"Model Accuracy","8bf03628":"Function to convert images to array","4ccf9033":"Print the classes","f82461e7":"Model Summary","b32d19b3":"Import neccessary packages"}}