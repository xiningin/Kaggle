{"cell_type":{"783d9672":"code","e335a464":"code","da16aab8":"code","79093330":"code","2c78f04b":"code","5d6a51a2":"code","b6be82b9":"code","01de71b1":"code","06a4c093":"code","7e3e6add":"code","1ad4374f":"code","ecde227c":"code","d63fb7a5":"code","f61f79a2":"code","c7f4983c":"code","aeb74245":"code","e3e4018b":"code","8ab0694c":"code","cd22e7d3":"code","77d1482c":"code","9e080647":"markdown","8d6210fe":"markdown","975bf6bc":"markdown","2284c6df":"markdown","5dfb4da2":"markdown"},"source":{"783d9672":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.graph_objects as go\nimport matplotlib.style as style\nimport plotly.express as px\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e335a464":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/cusersmarildownloadswinecsv\/wine.csv', delimiter=';', encoding = \"utf8\", nrows = nRowsRead)\ndf.dataframeName = 'wine.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","da16aab8":"from pandas.plotting import scatter_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model, decomposition\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","79093330":"df.plot(subplots=True, sharex=True ,figsize=(20,50))\nplt.show()","2c78f04b":"df.drop('quality', axis=1).corrwith(df.quality).plot(kind='bar', grid=True, figsize=(12, 8), color=['salmon'],\n                                                   title=\"Correlation with Quality\")","5d6a51a2":"dataset = pd.get_dummies(df, columns=['alcohol'], drop_first=True)","b6be82b9":"sc = StandardScaler()\nscale_var = ['citric_acid', 'pH', 'sulphates', 'free_sulfur_dioxide', 'residual_sugar']\ndataset[scale_var] = sc.fit_transform(dataset[scale_var])","01de71b1":"X = dataset.drop('quality', axis=1)\ny = dataset.quality\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","06a4c093":"allAlgo = [('lr', LogisticRegression()),('knn', KNeighborsClassifier()),('dclf', DecisionTreeClassifier()),\n          ('svm', SVC()),('nb', GaussianNB())]","7e3e6add":"res = []\nnames = []\nfor name, algo in allAlgo:\n    kfold = KFold(n_splits=10, random_state=None)\n    cv_results = cross_val_score(algo, X_train, y_train, cv=kfold, scoring='accuracy')\n    res.append(cv_results)\n    names.append(name)\n    print(name, cv_results.mean(), cv_results.std())","1ad4374f":"def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"Train Result:\\n**********************************************\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n************************************************\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","ecde227c":"lr = LogisticRegression(solver='saga',penalty='elasticnet',l1_ratio=0.6,max_iter=1000)\nlr.fit(X_train, y_train)\n\nprint_score(lr, X_train, y_train, X_test, y_test, train=True)\nprint_score(lr, X_train, y_train, X_test, y_test, train=False)","d63fb7a5":"#Applying PCA on Logistic Regression\n\npca = PCA(n_components=10) \nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\nexpained_variance = pca.explained_variance_ratio_\nclassifier = LogisticRegression(random_state = 1)\nclassifier.fit(X_train_pca, y_train)\nprint_score(classifier, X_train_pca, y_train, X_test_pca, y_test, train=True)\nprint_score(classifier, X_train_pca, y_train, X_test_pca, y_test, train=False)","f61f79a2":"sv = SVC(kernel='rbf',C=1)\nsv.fit(X_train, y_train)\nprint_score(sv, X_train, y_train, X_test, y_test, train=True)\nprint_score(sv, X_train, y_train, X_test, y_test, train=False)","c7f4983c":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\nprint_score(knn, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn, X_train, y_train, X_test, y_test, train=False)","aeb74245":"gn = GaussianNB()\ngn.fit(X_train, y_train)\nprint_score(gn, X_train, y_train, X_test, y_test, train=True)\nprint_score(gn, X_train, y_train, X_test, y_test, train=False)","e3e4018b":"#DecisionTreeClassifier\n\ndc = DecisionTreeClassifier()\ndc.fit(X_train, y_train)\nprint_score(dc, X_train, y_train, X_test, y_test, train=True)\nprint_score(dc, X_train, y_train, X_test, y_test, train=False)","8ab0694c":"from sklearn.model_selection import cross_val_score\ncross_validation = cross_val_score(estimator = lr, X = X_train, y = y_train, cv = 10)\nprint(\"Cross validation of LR model = \",cross_validation)\nprint(\"Cross validation of LR model (in mean) = \",cross_validation.mean())","cd22e7d3":"from sklearn.model_selection import cross_val_score\ncross_validation = cross_val_score(estimator = sv, X = X_train, y = y_train, cv = 10)\nprint(\"Cross validation of SVC model = \",cross_validation)\nprint(\"Cross validation of SVC model (in mean) = \",cross_validation.mean())","77d1482c":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thanks Rishabh Raj Shukla for the script' )","9e080647":"![](https:\/\/www.italianowine.com\/copia\/wp-content\/uploads\/2018\/09\/Classificazione-italia-europa-EN.jpg)italienowine.com","8d6210fe":"#The coef_ did not converge\", ConvergenceWarning)","975bf6bc":"#Codes by  Rishabh Raj Shukla   https:\/\/www.kaggle.com\/rajshukla1102\/beginnernotebook\/notebook","2284c6df":"#Applying PCA on Logistic Regression","5dfb4da2":"#Support Vector Machine"}}