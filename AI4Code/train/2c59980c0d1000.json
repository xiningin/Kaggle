{"cell_type":{"be926f5d":"code","066d669c":"code","29fe7483":"code","95233922":"code","fab116b0":"code","9a8734e1":"code","91dfcffb":"code","8e4b24f8":"code","5b8b40e8":"code","c70d437d":"code","316ceae9":"code","f5532c2b":"code","d2870c56":"code","b9f56caf":"code","7e796608":"code","e0844a9b":"code","7d84504f":"code","f549a333":"code","318bf08e":"code","cb4e25c3":"code","8b520a01":"code","48fb3911":"code","1d5fb35d":"code","6d6cddd4":"markdown","c84f9ceb":"markdown","f344993b":"markdown","438b4048":"markdown"},"source":{"be926f5d":"import pandas as pd\nimport numpy as np\nfrom sklearn import svm\ncc =  pd.read_csv(\"..\/input\/creditcard.csv\")","066d669c":"#from pydataset import data\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\ncc= pd.read_csv(\"..\/input\/melanoma\/melanoma.csv\")","29fe7483":"# Data check. \ncc.head()","95233922":"#cc=cc[cc['status']!=3]\n","fab116b0":"#I observed an conflict in the name 'class'. Therefore, I have changed the name from class to category\n\ncc= cc.rename(columns={'status': 'Category'})\ncc.Category[cc.Category == 2] = 0","9a8734e1":"cc.Category.value_counts()","91dfcffb":"# For convinience, divide the dataframe cc based on two labels. \n\nnor_obs = cc.loc[cc.Category==0]    #Data frame with normal observation\nano_obs = cc.loc[cc.Category==1]    #Data frame with anomalous observation","8e4b24f8":"# The given dataframe 'cc' is divided into three sets \n# Training set: train_features\n# Test observations\/features: X_test\n# Test labels: Y_test","5b8b40e8":"# Once class SVM is trained with the observations of only one class. In this case, the algorithm is trained with \n# first 200,000 observation of normal transactions. The remaining observation is merged with the anomalous observation \n# to create a test set. \n\ntrain_feature = nor_obs.loc[0:120, :]\ntrain_feature = train_feature.drop('Category', 1)\nY_1 = nor_obs.loc[120:, 'Category']\nY_2 = ano_obs['Category']","c70d437d":"# Creatng test observations\/features\n\nX_test_1 = nor_obs.loc[120:, :].drop('Category',1)\nX_test_2 = ano_obs.drop('Category',1)\nX_test = X_test_1.append(X_test_2)","316ceae9":"# Setting the hyperparameters for Once Class SVM\nfrom sklearn import svm\noneclass = svm.OneClassSVM(kernel='linear', gamma=0.001, nu=0.95)\n\n# I have used various combination of hyperparameters like linear, rbf, poly, gamma- 0.001, 0.0001, nu- 0.25, 0.5, 0.75, 0.95\n# This combination gave me the most satisfactory results.# The remain data set is (after 200,000 observations) are appended with anomalous observations\n\nY_1 = nor_obs.loc[120:, 'Category']\nY_2 = ano_obs['Category']\n\nY_test= Y_1.append(Y_2)\n\n#Y_test is used to evaluste the model","f5532c2b":"#train_feature","d2870c56":"from sklearn import svm\n# Training the algorithm with the features. \n# This stage is very time consuming processes. In my laptop it took more than an hour to train for 200,000 observations. \n# For rbf, the time taken is even more.\n\noneclass.fit(train_feature)","b9f56caf":"# Test the algorithm on the test set\n\nfraud_pred = oneclass.predict(X_test)","7e796608":"# Check the number of outliers predicted by the algorithm\n\nunique, counts = np.unique(fraud_pred, return_counts=True)\nprint (np.asarray((unique, counts)).T)","e0844a9b":"#Convert Y-test and fraud_pred to dataframe for ease of operation\n\nY_test= Y_test.to_frame()\nY_test=Y_test.reset_index()\nfraud_pred = pd.DataFrame(fraud_pred)\nfraud_pred= fraud_pred.rename(columns={0: 'prediction'})","7d84504f":"fraud_pred[fraud_pred['prediction']==1]=0\nfraud_pred[fraud_pred['prediction']==-1]=1","f549a333":"print(fraud_pred['prediction'].value_counts())\nprint(sum(fraud_pred['prediction'])\/fraud_pred['prediction'].shape[0])","318bf08e":"print(Y_test['Category'].value_counts())\nsum(Y_test['Category'])\/Y_test['Category'].shape[0]","cb4e25c3":"#let's built a ROC curve to validate the result\nfrom sklearn.metrics import roc_curve, auc\n\nfalse_positive_rate, true_positive_rate,  thresholds = roc_curve(Y_test['Category'],fraud_pred['prediction'])\nroc_auc=auc(true_positive_rate,false_positive_rate)\nprint(\"true_positive_rate- \", true_positive_rate)\nprint(\"false_positive_rate- \", false_positive_rate)\nprint(\"roc_auc- \", roc_auc)","8b520a01":"plt.title(\"Receiver Operating Curve\")\nplt.plot(false_positive_rate,true_positive_rate,'b',label=roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","48fb3911":"##Performance check of the model\n\nTP = FN = FP = TN = 0\nfor j in range(len(Y_test)):\n    if Y_test['Category'][j]== 0 and fraud_pred['prediction'][j] == 1:\n        TP = TP+1\n    elif Y_test['Category'][j]== 0 and fraud_pred['prediction'][j] == -1:\n        FN = FN+1\n    elif Y_test['Category'][j]== 1 and fraud_pred['prediction'][j] == 1:\n        FP = FP+1\n    else:\n        TN = TN +1\nprint (TP,  FN,  FP,  TN)\n","1d5fb35d":"# Performance Matrix\n\naccuracy = (TP+TN)\/(TP+FN+FP+TN)\nprint (accuracy)\nsensitivity = TP\/(TP+FN)\nprint (sensitivity)\nspecificity = TN\/(TN+FP)\nprint (specificity)","6d6cddd4":"**Application of Once Class SVM to detect anomaly** ","c84f9ceb":"Following results were obtained \n\naccuracy= 99.9%\n\nsensitivity = 100%\n\nspecificity = 75%\n\nOnce class SVM has shown a very promising performance for this dataset with near 90% detection of anomaly and very few false alarm. This can be a starting point for fine tuning the algorthm to improve the specificity, keeping other things constant. Tuning the hyperparameters are very time consuming process and the Kaggle kernal stops after some time. Therefore, O couldnt run the code. I have just shown my codes in the cell. I am sure this code will run because i have ran it in my Jupyter note book. I have also isolation forest in my previous kernal. Once class SVM seems to outperform isolation forest in this case. ","f344993b":"Once class SVM is trained with the observations of only one class. In this case, the algorithm is trained with first 200,000 observation of normal transactions. The remaining observations are merged with the anomalous observation to create a test set. \n\n","438b4048":"The given dataframe 'cc' is divided into three sets \n\nTraining set: train_features\n\nTest observations\/features: X_test\n\nTest labels: Y_test"}}