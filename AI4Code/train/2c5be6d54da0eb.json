{"cell_type":{"ac0b6231":"code","2bb758e8":"code","b042f760":"code","90ad5f93":"code","ecec84e0":"code","f5171fe1":"code","22bb737a":"code","cc2e039b":"code","3a542d34":"code","1387bcad":"code","57b46b66":"code","630aef6e":"code","a1b89a95":"code","e2459085":"code","f821dc7a":"markdown","db735989":"markdown","8f4f9b6b":"markdown","035dbbb5":"markdown","e2dd9d2c":"markdown","6bd88de6":"markdown"},"source":{"ac0b6231":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2bb758e8":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","b042f760":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","90ad5f93":"women = train_data.loc[train_data.Sex == 'female']['Survived']\nrate_women = sum(women)\/len(women)\n\nprint('rate of survival number',  rate_women)","ecec84e0":"men = train_data.loc[train_data.Sex == 'male']['Survived']\nrate_men = sum(men)\/len(men)\n\nprint('rate pf survival number', rate_men)","f5171fe1":"from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport math\n\ny = train_data['Survived'].to_numpy()\ny_1 = y\nfeatures = ['Pclass', 'Sex', 'SibSp', 'Parch']\nx_train = pd.get_dummies(train_data[features]).to_numpy()\nx_train_1 = x_train\nx_test = pd.get_dummies(test_data[features]).to_numpy()\nratio = math.trunc(len(x_train)*0.8)\nx_train = x_train[:ratio]\nx_valid = x_train_1[ratio:]\ny_train = y[:ratio]\ny_valid = y_1[ratio:]\n\nmodel = Sequential([\n    Dense(512, input_shape = (5,), activation = 'relu'),\n    Dropout(0.4),\n    BatchNormalization(),\n    Dense(256, activation = 'relu'),\n    Dropout(0.3),\n    BatchNormalization(),\n    Dense(128, activation = 'relu'),\n    Dropout(0.4),\n    BatchNormalization(),\n    Dense(64, activation = 'relu'),\n    Dropout(0.3),\n    BatchNormalization(),\n    Dense(32, activation = 'relu'),\n    Dropout(0.2),\n    Dense(16, activation = 'relu'),\n    Dense(1, activation = 'sigmoid')\n])\n\nmodel.summary()","22bb737a":"adam = tf.keras.optimizers.Adam(0.001)\nstocastic_avg_adam = tfa.optimizers.SWA(adam)","cc2e039b":"model.compile(optimizer = stocastic_avg_adam, loss='binary_crossentropy', metrics = ['acc'])\nc_path = 'check.ckpt'\ncheckpoint = ModelCheckpoint(filepath = c_path,\n                             save_weights_only=True,\n                             verbose=20,\n                             save_best_only = True,\n                             monitor = 'val_loss'\n                            )","3a542d34":"history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=100, verbose = 20,\n          callbacks=[checkpoint])","1387bcad":"import matplotlib.pyplot as plt","57b46b66":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loss', 'val_loss'])","630aef6e":"model.load_weights(c_path)\npredictions = model.predict(x_test)","a1b89a95":"pre_label = []\nfor i in range(len(predictions)):\n    if predictions[i][0] >= 0.45:\n        pre_label.append(1)\n    elif predictions[i][0] < 0.45:\n        pre_label.append(0)\noutput = pd.DataFrame({'PassengerId' : test_data.PassengerId,\n                      'Survived' : pre_label})\nprint(output)","e2459085":"output.to_csv('my_submission_2.csv', index=False)","f821dc7a":"## **SWA Optimizing Shows That Validation Loss Is Less Than Train Loss!!**\n### **If you wanna avoid OVERFITTING, Use this Opt!!**","db735989":"### I got values of 'predictions' from 0 to 1.\n#### I need to convert these values to Survived value by own basis (prediction which is larger than 0.5 \u2192 save Survived value to 1)","8f4f9b6b":"# **Simple Titanic Model Using Tensorflow**\n## **Used Library**\n* **Tensorflow**\n* **numpy**\n* **pandas**\n\n## **Using SWA Optimizer**\n[Click Here To Check Out SWA Optimizer!!](https:\/\/www.tensorflow.org\/addons\/api_docs\/python\/tfa\/optimizers\/SWA)\n#### Reference\n* Titanic Tutorial\n* Youtube\n","035dbbb5":"## **Simple Preprocessing By Course**","e2dd9d2c":"## **Simple Sequential Model**","6bd88de6":"## **Loading Data**"}}