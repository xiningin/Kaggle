{"cell_type":{"f9bb5bfe":"code","eeb0587e":"code","c46f2d87":"code","71a2df25":"code","045fc122":"code","5114cff3":"code","e3c036e6":"code","b3359f10":"code","b28c9870":"code","446ec12b":"code","96312adf":"code","c3306d1b":"code","95837e68":"markdown","eeae2038":"markdown","ca2836db":"markdown","f2c21fb5":"markdown","b663d2c3":"markdown","089e49d6":"markdown","69e1c20c":"markdown","2c3ca1ad":"markdown","613dad6f":"markdown","56ce2091":"markdown"},"source":{"f9bb5bfe":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport optuna\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor, Pool, CatBoost\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.optimizer import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import (CosineAnnealingWarmRestarts, CosineAnnealingLR, \n                                      ReduceLROnPlateau)\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup)\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL\nclass color:\n    BOLD = '\\033[1m' + '\\033[93m'\n    END = '\\033[0m'","eeb0587e":"train = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/train.csv\")\ntest = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/test.csv\")\n\nprint(color.BOLD + \"Train Shape:\" + color.END, train.shape, \"\\n\" +\n      color.BOLD + \"Test Shape:\" + color.END, test.shape)\n\ntrain.isna().sum()","c46f2d87":"train.describe()","71a2df25":"\nfrom matplotlib import pyplot\npyplot.hist(train['target'], bins=50,  label='target_bins')\npyplot.hist(train['standard_error'], bins=100, label='error_bins')\npyplot.legend(loc='upper right')\npyplot.show()","045fc122":"pd.set_option('display.max_colwidth', 10000)\ntrain.sort_values('target', ascending=False).head(3)[['excerpt','standard_error','target']]","5114cff3":"pd.set_option('display.max_colwidth', 10000)\ntrain.sort_values('target', ascending=True).head(3)[['excerpt','standard_error','target']]","e3c036e6":"train[(train['target']<=-0.94)&\n      (train['target']>=-0.95)].head(3)[['excerpt','standard_error','target']]","b3359f10":"## Lets find the correlation between target and standard error\nfrom scipy.stats import pearsonr\ncorr, _=pearsonr(train[\"target\"], train[\"standard_error\"])\nprint(corr)\n","b28c9870":"sns.scatterplot(x=train[\"target\"], y=train[\"standard_error\"], \n                size=train[\"standard_error\"], sizes=(20, 100))","446ec12b":"train_licence=train[~(train.license.isnull())]\nprint(train_licence.shape)","96312adf":"corr, _=pearsonr(train_licence[\"target\"], train_licence[\"standard_error\"])\nprint(corr)","c3306d1b":"sns.scatterplot(x=train_licence[\"target\"], y=train_licence[\"standard_error\"], \n                size=train[\"standard_error\"], sizes=(20, 100))\n","95837e68":"### Baseline Model code to follow","eeae2038":"#### EDA\n##### Lets plot the distribution of target and standard error ","ca2836db":"#### Get the data\nWe are going to read the train data here . The columns listed as in the data description of the competition are \n* id - unique ID for excerpt\n* url_legal - URL of source - this is blank in the test set.\n* license - license of source material - this is blank in the test set.\n* excerpt - text to predict reading ease of\n* target - reading ease\n* standard_error - measure of spread of scores among multiple raters for each excerpt. Not included for test data.","f2c21fb5":" ### Introduction What is the project goal? <b> <\/br>\n Goal: To build algorithms to rate the complexity of reading passages for grade 3-12 classroom use.","b663d2c3":"There is no impact in correlation even if the excerpt has a licence and url_legal","089e49d6":"As seen from the graph the standard error reduces towards the middle, but increases towards both ends. This means regardless of the excerpt being complex or simple people rating vary widely and thus standard error rises at both ends","69e1c20c":"Although technically a negative correlation, the relationship between our variables is only weak (nb. the nearer the value is to zero, the weaker the relationship.<b> There is no correlation between standard error and target.","2c3ca1ad":"As shown above we dont have any missing any values in the columns of our concern which is excerpt and target","613dad6f":"Lets understand how the standard error,target and excerpt are related. We are going to look at few examples where target is high meaning excerpt is difficult.","56ce2091":"Lets have a look at whats the impact of having licence and url_legal for an excerpt on that score"}}