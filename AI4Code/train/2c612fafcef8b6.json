{"cell_type":{"fe275c7a":"code","7452f318":"code","63121b0c":"code","f8218fda":"code","254d2281":"code","0f8a600b":"code","e3cc27f3":"code","1ad56e8f":"code","fdf114ab":"code","38168138":"code","c51dfd69":"markdown","7e9e1036":"markdown","c8c3ff51":"markdown","c97f3ad8":"markdown","019003d2":"markdown","e4846dba":"markdown","a47c1f9f":"markdown"},"source":{"fe275c7a":"import numpy as np # linear algebra\nnp.random.seed(0)\nfrom sklearn.feature_selection import SelectPercentile, chi2\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom matplotlib import pyplot as plt\nfrom sklearn import tree\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nlist_fn = ['\/kaggle\/input\/end-als\/end-als\/transcriptomics-data\/DESeq2\/bulbar_vs_limb.csv', \n'\/kaggle\/input\/end-als\/end-als\/transcriptomics-data\/DESeq2\/median_low_vs_high.csv',\n'\/kaggle\/input\/end-als\/end-als\/transcriptomics-data\/DESeq2\/ctrl_vs_case.csv',\n'\/kaggle\/input\/end-als\/end-als\/genomics-data\/geno_bin.csv']\n\nrename_lambda = lambda x: x[5:]\n\nctrl_vs_case = pd.read_csv(list_fn[2])\nx_cols = ctrl_vs_case.columns[2:]\ny_cols = ctrl_vs_case.columns[1:2]\ndata   = ctrl_vs_case[x_cols].to_numpy()\nlabels = ctrl_vs_case[y_cols].to_numpy().ravel()\n\ndata = data[:, data.any(axis=0)]\ndata = normalize(data, axis=1)\nsp = SelectPercentile(chi2, percentile=5).fit(data, labels)\n\nprint(labels.shape, data.shape)\nif np.any(np.isnan(data)) or np.any(np.isinf(data)):\n    print('error')\n\ntrain_size = 0.8\n    \nindices = np.random.permutation(labels.size)\ntrain = indices[:int(labels.size * train_size)]\nvalid = indices[int(labels.size * train_size):]\n\nX = data[train]\nY = labels[train]\nTx = data[valid]\nTy = labels[valid]\n\ndatasets = [pd.read_csv(path) for path in list_fn[:-1]]\ndf = datasets[1]\ndatasets = [datasets[0], datasets[2]]\nfor dataset in datasets:\n    df = pd.merge(df, dataset[[dataset.columns[0], dataset.columns[1]]], on=dataset.columns[0], how='left')\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, roc_curve, auc, precision_recall_curve\n\n# TODO: sensitivity & specificity of model similar scores for both\n\ndef class_one_acc(labels):\n    return sum(labels)\/len(labels)\n\ndef acc(true, preds):\n    return accuracy_score(true, preds)\n\ndef roc_auc(true, conf_scores, verbose=False):\n    fpr, tpr, _ = roc_curve(true, conf_scores)\n    return auc(fpr, tpr) if not verbose else (fpr, tpr, auc(fpr, tpr))\n\ndef prc_auc(true, conf_scores, verbose=False):\n    precision, recall, _ = precision_recall_curve(true, conf_scores)\n    return auc(recall, precision) if not verbose else (recall, precision, auc(recall, precision))\n\ndef plot_auc(true, conf_scores, mode='roc', lw=2):\n    if mode == 'roc':   \n        metric = roc_auc\n        xlabel = 'False Positive Rate'\n        ylabel = 'True Positive Rate'\n        title = 'ROC AUC'\n        p1 = [0, 1]\n        p2 = [0, 1]\n    elif mode == 'prc': \n        metric = prc_auc\n        xlabel = 'Recall'\n        ylabel = 'Precision'\n        title = 'PRC AUC'\n        p1 = [0, 1]\n        p2 = [class_one_acc(true), class_one_acc(true)]\n    else: return;\n    \n    scores = metric(true, conf_scores, verbose=True)\n\n    plt.figure()\n    plt.plot(scores[0], scores[1], color='red', lw=lw, label='ROC curve (area = %0.4f)' % scores[2])\n    plt.plot(p1, p2, color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.legend(loc=\"lower right\")\n    plt.show()","7452f318":"!pip install autokeras","63121b0c":"print('model created')\n_X = sp.transform(X)\n_Y = Y.copy()\n\nnegs = _Y == 0\nratio = int(negs.size \/ negs.sum()) - 1\nif ratio > 0:\n    x_neg = np.concatenate([_X[negs]] * ratio)\n    y_neg = np.concatenate([_Y[negs]] * ratio)\n    _X = np.concatenate([_X, x_neg])\n    _Y = np.concatenate([_Y, y_neg])\n\nprint(np.max(_X), np.min(_X))\n\n\nimport autokeras as ak\nimport tensorflow.keras as K\nprint('model created')\n_Tx = sp.transform(Tx)\n_Ty = Ty.copy()\n\nclf = ak.StructuredDataClassifier(overwrite=True, max_trials=50)\nclf.fit(_X, _Y, epochs=50)\nmodel = clf.export_model()\nprint(model.summary())\nmodel.trainable = False\n# output_model = model.layers[:-1]\n\noutput_model = K.Model(inputs=model.inputs, outputs=model.layers[-3].output)\nprint(output_model.summary())\n\n_Tx = sp.transform(Tx)\n_Tx = output_model.predict(_Tx)\n_X = sp.transform(X)\n_X = output_model.predict(_X)\n\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(_X, Y)\ntree.plot_tree(clf, rounded=True)\n\nprint(clf.score(_Tx, Ty))\nconf_score = clf.predict(_Tx)\nplot_auc(Ty, conf_score, mode='roc')","f8218fda":"from matplotlib import pyplot as plt\nfrom sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X, Y)\ntree.plot_tree(clf, rounded=True)\nprint(clf.score(Tx, Ty))","254d2281":"_Tx = sp.transform(Tx)\n_Tx = output_model.predict(_Tx)\n_X = sp.transform(X)\n_X = output_model.predict(_X)\n\nclf2 = tree.DecisionTreeClassifier()\nclf2 = clf2.fit(_X, Y)\ntree.plot_tree(clf2, rounded=True)\n\n\n\nprint(clf2.score(_Tx, Ty))\n","0f8a600b":"_Tx = sp.transform(Tx)\n_X = sp.transform(X)\n\nclf3 = tree.DecisionTreeClassifier()\nclf3 = clf3.fit(_X, Y)\ntree.plot_tree(clf3, rounded=True)\n\nprint(clf3.score(_Tx, Ty))","e3cc27f3":"_Tx = sp.transform(Tx)\n_Tx = output_model.predict(_Tx)\n_X = sp.transform(X)\n_X = output_model.predict(_X)\nprint(_X.shape)\nfrom sklearn import cluster\nclus1 = cluster.KMeans(5)\n_X = clus1.fit_transform(_X)\n_Tx = clus1.transform(_Tx)\nclf6 = tree.DecisionTreeClassifier()\nprint(_X.shape)\nclf6 = clf6.fit(_X, Y)\ntree.plot_tree(clf6, rounded=True)\n\nprint(clf6.score(_Tx, Ty))","1ad56e8f":"print(clf6.score(_X, Y))","fdf114ab":"_Tx = sp.transform(Tx)\n_X = sp.transform(X)\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(_X, Y)\ntree.plot_tree(clf, rounded=True)\nconf_score = clf.predict(_Tx)\nprint(clf.score(_Tx, Ty))\nplot_auc(Ty, conf_score, mode='roc')","38168138":"from sklearn.ensemble import RandomForestClassifier\n_Tx = sp.transform(Tx)\n_X = sp.transform(X)\nrf = RandomForestClassifier(n_estimators=2)\nrf.fit(_X, Y)\ntree.plot_tree(rf.estimators_[0], rounded=True)\nprint(rf.score(_Tx, Ty))\nconf_score = rf.predict(_Tx)\nplot_auc(Ty, conf_score, mode='roc')","c51dfd69":"## Without embedding and With dim reduction 1","7e9e1036":"## with embedding and with dim reduction","c8c3ff51":"## Without embedding or dim reduction","c97f3ad8":"# With Kmeans","019003d2":"## With embedding and dim reduction","e4846dba":"# Working Model","a47c1f9f":"# Embedding Model (unsupervised)"}}