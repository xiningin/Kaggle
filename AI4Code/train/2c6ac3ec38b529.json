{"cell_type":{"f52b3ad6":"code","a2980706":"code","ead0b105":"code","b697a165":"code","55ecb6a0":"code","326174f8":"code","d64ca9c3":"code","68867bfe":"code","bf927fd9":"code","40c95145":"code","3007a80d":"code","449d0e2e":"code","1d16f195":"code","e5d058ad":"code","4c5ef9d8":"code","58ab3291":"code","15842405":"code","269c8004":"code","73fc70d4":"code","453fb81c":"code","c2ae7ffd":"code","2fffebec":"code","a5768c69":"code","33e561e9":"code","6dc449a6":"code","61765d25":"code","52c3b1bf":"code","84c94507":"code","1c7df8e3":"code","bf89a9ef":"code","43ed25c3":"code","2b8f89d4":"code","09200f0c":"code","f22f98e5":"code","92ecc3b3":"markdown","f3ebc64c":"markdown","17fcdc67":"markdown","d8cf57c5":"markdown","dab6eac0":"markdown","72675521":"markdown","649e5661":"markdown","6af80278":"markdown","46f6b59b":"markdown","4ee04dd4":"markdown","edaa6a31":"markdown","7afb930d":"markdown","8ed140ff":"markdown","bdec27cd":"markdown","0a19381a":"markdown","1c7224d9":"markdown"},"source":{"f52b3ad6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a2980706":"train = pd.read_csv('..\/input\/train.csv', index_col=0)\ntrain.head(10)","ead0b105":"test = pd.read_csv('..\/input\/test.csv', index_col=0)\ntest.head(10)","b697a165":"## this is just the sample submission\nsample_sub = pd.read_csv('..\/input\/gender_submission.csv')\n# gs.head(10)","55ecb6a0":"train.info()","326174f8":"train.Embarked.value_counts()","d64ca9c3":"train.Sex.value_counts()","68867bfe":"# train.Cabin.value_counts()","bf927fd9":"print(train.drop(['Survived'],axis=1).describe())\nprint('\\n========================================')\nprint(test.describe())","40c95145":"print(\"The test set is approximately {:.3f} % if theyre counted as a whole together\".format( 100*len(test) \/ (len(train)+len(test)) ))","3007a80d":"train.isnull().sum()\/len(train)","449d0e2e":"test.isnull().sum()\/len(test)","1d16f195":"target = train.Survived\ntarget.value_counts()","e5d058ad":"print(\"The survival ratio is about {:.3f}%\".format(target.value_counts()[1]\/len(target) *100))","4c5ef9d8":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","58ab3291":"fig, ax=plt.subplots(1,1,figsize=(12,10))\nsns.swarmplot(x=\"Age\", y=\"Sex\", hue=\"Survived\", data=train, ax=ax)\nplt.title(\"Age v Sex on Survival\");","15842405":"train_nc = train.copy()\ntrain_nc['Sex'] = pd.factorize(train.Sex)[0]\ndummies = pd.get_dummies(train.Embarked)\nprint(dummies.head(3))\ntrain_nc = train_nc.join(dummies)\nprint(train_nc.head(3))\ntrain_nc.drop('Embarked',axis=1,inplace=True)","269c8004":"fig, ax=plt.subplots(1,1,figsize=(12,12))\nsns.heatmap(train_nc.corr(),annot=True,cmap='coolwarm');","73fc70d4":"fig, ax=plt.subplots(1,1,figsize=(12,10))\nsns.swarmplot(x=\"Age\", y=\"Sex\", hue=\"Survived\", data=train, ax=ax)\nplt.title(\"Age v Sex on Survival\");\n","453fb81c":"fig, ax=plt.subplots(1,1,figsize=(12,10))\nsns.swarmplot(x=\"Fare\", y=\"Sex\", hue=\"Survived\", data=train, ax=ax)\nplt.title(\"Fare v Sex on Survived\");","c2ae7ffd":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, f1_score\nfrom sklearn.preprocessing import StandardScaler\nimport re\nimport string\nfrom tqdm import tqdm","2fffebec":"TOKENIZER = re.compile(f'([{string.punctuation}\u201c\u201d\u00a8\u00ab\u00bb\u00ae\u00b4\u00b7\u00ba\u00bd\u00be\u00bf\u00a1\u00a7\u00a3\u20a4\u2018\u2019])')\ndef tokenize(s):\n    return TOKENIZER.sub(r' \\1 ', s).split()","a5768c69":"tfidf = TfidfVectorizer(ngram_range=(1,3), tokenizer=tokenize, \n                        max_features = 100,\n                        strip_accents='unicode', use_idf=True,\n                        smooth_idf=True, sublinear_tf=True)","33e561e9":"train['Cabin'] = train.Cabin.fillna('None')\ntest['Cabin'] = test.Cabin.fillna('None')","6dc449a6":"train_name = tfidf.fit_transform(train['Name'])\ntrain_ticket = tfidf.fit_transform(train['Ticket'])\ntrain_cabin = tfidf.fit_transform(train['Cabin'])\n\ntrain_tf = np.concatenate((train_name.todense(), train_ticket.todense(), train_cabin.todense()), axis=1)\n\ntrain_full = train_nc.join(pd.DataFrame(train_tf, index=train.index))\ntrain_full.shape","61765d25":"test_nc = test.copy()\ntest_nc['Sex'] = pd.factorize(test.Sex)[0]\ndummies = pd.get_dummies(test.Embarked)\nprint(dummies.head(3))\ntest_nc = test_nc.join(dummies)\nprint(test_nc.head(3))\ntest_nc.drop('Embarked',axis=1,inplace=True)","52c3b1bf":"test_name = tfidf.fit_transform(test['Name'])\ntest_ticket = tfidf.fit_transform(test['Ticket'])\ntest_cabin = tfidf.fit_transform(test['Cabin'])\n\ntest_tf = np.concatenate((test_name.todense(), test_ticket.todense(), test_cabin.todense()), axis=1)\n\ntest_full = test_nc.join(pd.DataFrame(test_tf, index=test.index))\ntest_full.shape","84c94507":"print(\"DROPPING THE CAT VARS...\")\ntrain_full.drop(['Name','Ticket','Cabin','Survived'],axis=1, inplace=True)\ntest_full.drop(['Name','Ticket','Cabin'],axis=1, inplace=True)","1c7df8e3":"train_full = train_full.fillna(0)\ntest_full = test_full.fillna(0)\n\n# ss = StandardScaler(with_mean=True, with_std=True)\n## does better without the scaler\n\ntrain_fss = train_full #ss.fit_transform(train_full)\ntest_fss = test_full #ss.fit_transform(test_full)","bf89a9ef":"rf = RandomForestClassifier(n_estimators=1000, max_depth=10, min_samples_split=2, random_state=42)","43ed25c3":"def threshold_search(y_true, y_proba):\n    best_threshold = 0\n    best_score = 0\n    for threshold in tqdm([i * 0.01 for i in range(100)]):\n        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n        if score > best_score:\n            best_threshold = threshold\n            best_score = score\n    search_result = {'threshold': best_threshold, 'f1': best_score}\n    return search_result","2b8f89d4":"kfolds = 3\npreds = 0\nths = []\nprint(\" ====================================== \")\nfor k in range(kfolds):\n    xt, xv, yt, yv = train_test_split(train_full, target, test_size=0.15, random_state=(k+1)*42)\n    print(xt.shape, xv.shape, yt.shape, yv.shape)\n    rf.fit(xt, yt)\n    val_preds = rf.predict_proba(xv)\n    print(classification_report(yv, np.round(val_preds[:,1],0).astype(int)))\n    th_sr = threshold_search(yv, np.round(val_preds[:,1],0).astype(int))\n    ths.append(th_sr)\n    print(\"Threshold Search F1 Result :\")\n    print(th_sr)\n    print(\" ========================================== \")\n    preds += rf.predict(test_fss)\n\npreds = preds\/kfolds\nprint(preds.shape)","09200f0c":"sample_sub['Survived'] = np.round(preds,0).astype(int)\nsample_sub.to_csv('submission.csv', index=False)\nprint(sample_sub.Survived.value_counts())\nprint(sample_sub.head(10))","f22f98e5":"print(target.value_counts())","92ecc3b3":"## Survival","f3ebc64c":"Lets go ahead and factorize and dummy the categorical variables.","17fcdc67":"Filled None for NA in Cabin and now doing the Training and Test Feature Creation.","d8cf57c5":"It looks like the ticket class and the fare are highly negatively correlated.","dab6eac0":"## Feature Creation\n\nWe alread dummied and factorized so lets see what we can do with the other text.","72675521":"It appears that mostly women and children survived which is what one might expect.","649e5661":"The general statistics of each of the dataframes are similar.","6af80278":"Lets first take a look at the items we are working with.","46f6b59b":"Test is on par with train.","4ee04dd4":"There are three options inthe embarked category, so we can dummy it.","edaa6a31":"With only 2 catgories we could factorize this.","7afb930d":"Unless you had the most expensive ticket, there doesnt appear to be a visual confirmation you had a better chance to survive.","8ed140ff":"We have passengerid which ought to be indexed, a Binary classification for whether or not they sruvived and 10 features.","bdec27cd":"The Sex and Embarked features are categorical so we could factorize \/ dummy these.\n\nCabin, ticket, and Name are strings with unique values.","0a19381a":"## Random Forest","1c7224d9":"About 20% of __AGE__ and 77% of __CABIN__ are null in the train set."}}