{"cell_type":{"42228e14":"code","2b7e0638":"code","06414b45":"code","d71c9de2":"code","32868ad4":"code","b321e5e0":"code","2d317cfc":"code","7b9f8b4b":"code","22d8f0fd":"code","7f394bbf":"code","57a64157":"code","bac31741":"code","4a1e9e34":"code","7d8eab1a":"code","5225c9f3":"code","804489e8":"code","3eb8caa4":"code","ab9434eb":"code","06f4ab79":"code","863bab35":"code","5cb0e6e1":"code","acd2b2ee":"code","622b0ee3":"markdown","61841cdd":"markdown","80196c58":"markdown","ea0f9bf0":"markdown","f8eaa1d3":"markdown","ff01b1b5":"markdown","1c36ac1e":"markdown","113fb5dc":"markdown","75cecdad":"markdown","92302bf3":"markdown","b6b5da8f":"markdown","93ea7a75":"markdown","c7079695":"markdown","63e1fdd9":"markdown","0972f5b4":"markdown"},"source":{"42228e14":"ls -la ..\/input","2b7e0638":"import datetime\nnow = datetime.datetime.now()\nprint(now)","06414b45":"%matplotlib inline\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot","d71c9de2":"import datetime\nimport os.path\nimport itertools\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn import cluster, datasets, mixture\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\n\nimport tensorflow as tf\n\nfrom keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Lambda, \\\n    Conv1D, Conv2D, Conv3D, \\\n    Conv2DTranspose, \\\n    AveragePooling1D, AveragePooling2D, \\\n    MaxPooling1D, MaxPooling2D, MaxPooling3D, \\\n    GlobalAveragePooling1D, GlobalAveragePooling2D, \\\n    GlobalMaxPooling1D, GlobalMaxPooling2D, GlobalMaxPooling3D, \\\n    LocallyConnected1D, LocallyConnected2D, \\\n    concatenate, Flatten, Average, Activation, \\\n    RepeatVector, Permute, Reshape, Dot, \\\n    multiply, dot, add, \\\n    PReLU, \\\n    Bidirectional, TimeDistributed, \\\n    SpatialDropout1D, \\\n    BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras import losses\nfrom keras.callbacks import BaseLogger, ProgbarLogger, Callback, History\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import regularizers\nfrom keras import initializers\nfrom keras.metrics import categorical_accuracy\nfrom keras.constraints import maxnorm, non_neg\nfrom keras.optimizers import RMSprop\nfrom keras.utils import to_categorical, plot_model\nfrom keras import backend as K\nimport keras","32868ad4":"from PIL import Image\nfrom zipfile import ZipFile\nimport h5py\nimport cv2\nfrom tqdm import tqdm\nimport datetime","b321e5e0":"# Load the data\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","2d317cfc":"train.head()","7b9f8b4b":"test.head()","22d8f0fd":"y_train = train['label'].values\nprint(y_train.shape)\n\ny_cat = to_categorical(y_train)\ny_cat.shape","7f394bbf":"x_train = train.iloc[:,1:].values \/ 255.0\nprint((x_train.min(), x_train.max()))\nx_train.shape","57a64157":"x_train_fl = x_train.reshape((x_train.shape[0], -1))\nx_train_fl.shape","bac31741":"plt.imshow(x_train[0].reshape((28,28)))","4a1e9e34":"x_test = test.iloc[:,:].values \/ 255.0\nprint((x_test.min(), x_test.max()))\nx_test.shape","7d8eab1a":"x_test_fl = x_test.reshape((x_test.shape[0], -1))\nx_test_fl.shape","5225c9f3":"plt.imshow(x_test[0].reshape((28,28)))","804489e8":"sample_submit = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nprint(sample_submit.shape)\nsample_submit.head()","3eb8caa4":"def get_pred(src, rs=10001, show=False):\n    print(src, rs)\n    y_pred0 = pd.read_csv(os.path.join(src, 'proba_s{}.csv'.format(rs)))\n    if show:\n        print(y_pred0.shape)\n        print(y_pred0.head())\n    y_pred0_test = pd.read_csv(os.path.join(src, 'proba_test_s{}.csv'.format(rs)))\n    if show:\n        print(y_pred0_test.shape)\n        print(y_pred0_test.head())\n    \n    return y_pred0.get_values(), y_pred0_test.get_values()","ab9434eb":"y_pred_list = []\ny_pred_test_list = []\n\n\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s101zz'\nrs_init = 10101\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s102zz'\nrs_init = 10201\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s103zz'\nrs_init = 10301\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s104zz'\nrs_init = 10401\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s105zz'\nrs_init = 10501\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s106zz'\nrs_init = 10601\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s107zz'\nrs_init = 10701\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s108zz'\nrs_init = 10801\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n\nsrc = '..\/input\/digit28-2-features-gkernel-bn-da-gkgk-s109zz'\nrs_init = 10901\nfor ii in range(10):\n    rs = rs_init + ii\n    y_pred_0, y_pred_test_0 = get_pred(src, rs)\n    y_pred_list.append(y_pred_0)\n    y_pred_test_list.append(y_pred_test_0)\n","06f4ab79":"len(y_pred_list)","863bab35":"y_pred = np.stack(y_pred_list)\nprint(y_pred.shape)\n\npred = y_pred.mean(axis=0)\nprint(pred.shape)\nprint(pred[0])","5cb0e6e1":"print(f1_score(y_train, np.argmax(pred, axis=1), average='macro'))\nprint(classification_report(y_train, np.argmax(pred, axis=1)))\nconfusion_matrix(y_train, np.argmax(pred, axis=1))","acd2b2ee":"y_pred_test = np.stack(y_pred_test_list)\nprint(y_pred_test.shape)\npred_test = y_pred_test.mean(axis=0)\nprint(pred_test.shape)\nprint(pred_test[0])\n\nsubmit_csv = sample_submit.copy()\nsubmit_csv.Label = np.argmax(pred_test, axis=1)\nsubmit_csv.head()\nsubmit_csv.to_csv('submit.csv', index=False)","622b0ee3":"## Independence of multiple learner\n|state|image|state|image|\n|:-|:-:|:-|:-:|\n|[10001](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10001)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00106_s10001.png)|[10002](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10002)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00106_s10002.png)|\n|[10003](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10003)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00106_s10003.png)|[10004](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10004)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00106_s10004.png)|\n|[10005](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10005)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00106_s10005.png)|[10006](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10006)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00106_s10006.png)|\nstate :: random state","61841cdd":"# Independence of multiple learner\nLet's see the output of the RBF kernel in several learner using different landmarks. The output of this layer is two-dimensional since using two landmarks.\n\n|state|image|state|image|\n|:-|:-:|:-|:-:|\n|[10001](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10001)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00105_s10001.png)|[10002](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10002)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00105_s10002.png)|\n|[10003](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10003)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00105_s10003.png)|[10004](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10004)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00105_s10004.png)|\n|[10005](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10005)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00105_s10005.png)|[10006](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10006)|![](http:\/\/yunopon.sakura.ne.jp\/sblo_files\/wordroid\/image\/ttt00105_s10006.png)|\nstate :: random state","80196c58":"## Whole model\n|...|MODEL|INPUT|OUTPUT|DESC|\n|-------------|:-------------|-----:|-----:|:-----|\n|1| image converter | 28x28x1 | 128 |   |\n|2| classifier | 128 | 10 | quasi SVM(RBF) |","ea0f9bf0":"## -###-","f8eaa1d3":"The results of ensemble by soft voting of these results are as follows.  \n\n|state|training data<br\/>(f1 macro avg)|test data<br\/>kaggle LB score|\n|:--|--:|--:|\n|[ensemble007](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-2-ensemble007) (6 learners above)|0.99795|0.99228|\n|[ensemble018](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-ensemble018) (90 learners)|0.99905|0.99514|","ff01b1b5":"# Another network\nWe changed the classifier in the network as follows.\n\n|...|LAYER|INPUT|OUTPUT|DESC|\n|:-:|:-------------|---:|---:|:-----|\n|1| GaussianKernel(RBF) | 128 | 2 |using TWO fixed Landmarks|\n|2| <span style=\"color:blue\">GaussianKernel(RBF)<\/span> | 2 | 10 | |","1c36ac1e":"The score of this kernel is the result of ensemble of 90 learners.\n\n|state|training data<br\/>(f1 macro avg)|test data<br\/>kaggle LB score|\n|:--|--:|--:|\n|this kernel|0.99801|0.99657|","113fb5dc":"## 1 : image converter\nThis model outputs feature values of images\n```\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 784)          0                                            \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 28, 28, 1)    0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 28, 28, 32)   832         reshape_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 28, 28, 32)   25632       conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 32)   0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 14, 14, 64)   18496       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nglobal_max_pooling2d_1 (GlobalM (None, 64)           0           conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 64)           0           conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 128)          0           global_max_pooling2d_1[0][0]     \n                                                                 global_average_pooling2d_1[0][0] \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 128)          512         concatenate_1[0][0]              \n==================================================================================================\nTotal params: 82,400\nTrainable params: 82,144\nNon-trainable params: 256\n__________________________________________________________________________________________________\n```","75cecdad":"# Result of the ensemble\nThe following is f1_score in the training data of each learner and Kaggle LB score in test data.  \n\n|state|training data<br\/>(f1 macro avg)|test data<br\/>kaggle LB score|\n|:--|--:|--:|\n|[10001](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10001)|0.72|0.77528|\n|[10002](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10002)|0.89|0.86085|\n|[10003](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10003)|0.81|0.83028|\n|[10004](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10004)|0.84|0.82985|\n|[10005](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10005)|0.87|0.85571|\n|[10006](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10006)|0.89|0.87328|","92302bf3":"## 2 : classifier\nWe construct quasi SVM using RBF kernel (Gaussian kernel) and Dense layer (see [Dense vs. GaussianKernel in moon data](https:\/\/github.com\/darecophoenixx\/wordroid.sblo.jp\/wiki\/%5BGaussianKernel-layer%5D-Dense-vs.-GaussianKernel-in-moon-data)). Two fixed landmarks are used for the RBF kernel (Gaussian kernel). By using different values for this fixed landmark, independence of each learner is guaranteed. This is empirical, not mathematically proven.\n\n|...|LAYER|INPUT|OUTPUT|DESC|\n|:-:|:-------------|---:|---:|:-----|\n|1| GaussianKernel(RBF) | 128 | 2 |using TWO fixed Landmarks|\n|2| Dense | 2 | 10 | |","b6b5da8f":"## Result\n|...|kaggle LB score|\n|:--|--:|\n|[10001](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10001)|0.77528|\n|[10002](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10002)|0.86085|\n|[10003](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10003)|0.83028|\n|[10004](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10004)|0.82985|\n|[10005](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10005)|0.85571|\n|[10006](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-5-s10006)|0.87328|\n|||\n|[ensemble007](https:\/\/www.kaggle.com\/wordroid\/digit28-only-2-features-gkernel-bn-2-ensemble007) (6 learners above)|**<span style=\"color:blue\">0.99228<\/span>**|\n|[ensemble018](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-ensemble018) (90 learners)|**<span style=\"color:blue\">0.99514<\/span>**|","93ea7a75":"# Overview\n* Network in Handwritten Digit Recognizer\n* Independence of multiple learner\n* Result of the ensemble\n* Another network","c7079695":"## result\n|state|training data<br\/>(f1 macro avg)|test data<br\/>kaggle LB score|\n|:--|--:|--:|\n|[10001](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10001)|0.98|0.95700|\n|[10002](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10002)|1.00|0.97128|\n|[10003](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10003)|1.00|0.97714|\n|[10004](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10004)|0.99|0.97014|\n|[10005](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10005)|0.99|0.96742|\n|[10006](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-s10006)|0.98|0.95242|\n|[ensemble008](https:\/\/www.kaggle.com\/wordroid\/digit28-2-features-gkernel-bn-gkgk-ensemble008) (6 learners above)|0.99902|0.99200|","63e1fdd9":"# Does RBF kernel (GaussianKernel) with two fixed Landmarks work well in ensemble?\nIn the ensemble method, it is necessary that the correlation between multiple learner is low (or the independence of multiple learner is high). In order to obtain various classifiers with high independence, it is necessary to use a significantly different algorithm. Can we obtain a highly independent learner in a neural network with the same structure?  \n\nIn order to confront this issue, we challenged to obtain a highly independent learner by using RBF kernel with fixed landmarks in classifier just before output of the network.  \n\nIn this article we used keras. We used the [GaussianKernel layer](https:\/\/github.com\/darecophoenixx\/wordroid.sblo.jp\/tree\/master\/lib\/keras_ex\/gkernel) to implement the RBF kernel.  ","0972f5b4":"# Network in Handwritten Digit Recognizer"}}