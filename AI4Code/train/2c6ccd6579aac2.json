{"cell_type":{"728d2a4c":"code","22bc3cf4":"code","f1d37faa":"code","43754685":"code","8211752d":"code","0c3bac3d":"code","b4966f9a":"code","fd381ac7":"code","b084c31b":"code","14279ca3":"code","cdd81afd":"code","7112072a":"code","503c76e3":"code","42d44a8d":"code","05b2f83f":"code","6985dd90":"code","9bb723f9":"code","c7cdfdb3":"code","82398e53":"code","03720194":"code","93ea4b37":"code","343b12af":"code","a0e060db":"code","01d591bf":"code","e0646da6":"code","c1200f6a":"code","55a4c166":"code","02af9a85":"code","543f7d84":"code","964ac2ed":"code","e06f0a60":"code","36a44869":"code","e4426455":"code","92192443":"code","f9f3fff2":"code","5cd512ff":"code","fca9f1a4":"code","d4bd97ff":"code","30b9500f":"code","da42ca42":"markdown","1b4b4827":"markdown","9cc230db":"markdown","8f546739":"markdown","9f0624bf":"markdown","79111d6d":"markdown","0a61e302":"markdown","c01d8b9b":"markdown","885cebfd":"markdown","3c9ae265":"markdown","e48c02e1":"markdown","d2c0a01a":"markdown","8f719e95":"markdown","62932520":"markdown","3e71c099":"markdown","2fac4738":"markdown","0aa34476":"markdown","629434b8":"markdown","fc526647":"markdown","e9fbb8b5":"markdown","d6713807":"markdown","c22bac13":"markdown","f825c440":"markdown","9e296299":"markdown","a1770e25":"markdown","6ad53aad":"markdown","8b1ce4e8":"markdown","f4f7f365":"markdown","75fe9f69":"markdown","c748f5bf":"markdown","9f817e1e":"markdown","c4b6bf81":"markdown","7a0f5ac9":"markdown","c2b1a3b8":"markdown","ed4d52b5":"markdown","73b435c7":"markdown","daaa5d21":"markdown","0ec825b8":"markdown","a86e450c":"markdown","2dbcbb94":"markdown","cc3ba3f2":"markdown","233d9a50":"markdown","f5f02946":"markdown","b12ade78":"markdown","50c417ed":"markdown","5a121203":"markdown","0beaaf8c":"markdown","43230e13":"markdown","c5168651":"markdown","88073026":"markdown","a17911a0":"markdown","e0c172a7":"markdown","5be4adee":"markdown","ff708a02":"markdown","5a018d3a":"markdown","65a1b410":"markdown","96957302":"markdown","882b3f8c":"markdown","573b5299":"markdown"},"source":{"728d2a4c":"import numpy as np\nimport geopandas as gpd\nfrom geopandas.tools import sjoin\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nfrom shapely.geometry import Point\nimport os\nimport seaborn as sns\nimport folium\nfrom folium import plugins\nimport geopandas as gpd\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nfrom shapely.geometry import Point\n\n\n# Any results you write to the current directory are saved as output.","22bc3cf4":"os.listdir(\"..\/input\/data-science-for-good\/cpe-data\")","f1d37faa":"force_df = pd.read_csv('..\/input\/data-science-for-good\/cpe-data\/\/Dept_37-00027'+\n                         '\/37-00027_UOF-P_2014-2016_prepped.csv')\nforce_clean_df = force_df.loc[1:].reset_index(drop=True)\nforce_clean_df ['LOCATION_LONGITUDE']= pd.to_numeric(force_clean_df['LOCATION_LONGITUDE'], downcast='float') \nforce_clean_df ['LOCATION_LATITUDE']= pd.to_numeric(force_clean_df['LOCATION_LATITUDE'], downcast='float') \nforce_clean_df = force_clean_df[np.isfinite(force_clean_df['LOCATION_LONGITUDE'])]\nforce_clean_df=force_clean_df[force_clean_df['LOCATION_LONGITUDE']!=0].reset_index(drop=True)\nfoo=lambda x: Point(x['LOCATION_LONGITUDE'],x['LOCATION_LATITUDE'])\nforce_clean_df['geometry'] = (force_clean_df.apply(foo, axis=1))\nforce_clean_df = gpd.GeoDataFrame(force_clean_df, geometry='geometry')\nforce_clean_df.crs = {'init' :'epsg:4326'}\npolice_df_Austin = gpd.read_file('..\/input\/data-science-for-good\/cpe-data\/'\n                                 +'Dept_37-00027\/37-00027_Shapefiles\/APD_DIST.shp')\npolice_df_Austin.crs = {'init' :'esri:102739'}\npolice_df_Austin = police_df_Austin.to_crs(epsg='4326')\nforce_clean_df.head()","43754685":"locations_df = pd.DataFrame()\nlocationlist=[]\nlocations_df['LOCATION_LONGITUDE']=force_clean_df['LOCATION_LONGITUDE'].astype(float)\nlocations_df['LOCATION_LATITUDE'] =force_clean_df['LOCATION_LATITUDE'].astype(float)\nfor i, r in locations_df.iterrows():\n    locationlist.append([r['LOCATION_LONGITUDE'],r['LOCATION_LATITUDE']])","8211752d":"fig1,ax = plt.subplots(1,2,figsize=(20,10))\npolice_df_Austin.plot(ax=ax[0],column='SECTOR',alpha=0.5,legend=True)\ns=force_clean_df['INCIDENT_REASON']\ns.value_counts().plot(kind='bar',ax=ax[1],rot=10)\nforce_clean_df.plot(marker='.',ax=ax[0])","0c3bac3d":"\nforce_clean_df.SUBJECT_RACE.value_counts()\nprint(force_clean_df.SUBJECT_RACE.value_counts())\nfig1, ax1 = plt.subplots()\nax1.pie(force_clean_df.SUBJECT_RACE.value_counts(),labels=force_clean_df.SUBJECT_RACE.value_counts().keys(),autopct='%1.1f%%',startangle=90,  shadow=True)\nax1.axis('equal')\nplt.show()\n","b4966f9a":"census_poverty_df = pd.read_csv('..\/input\/data-science-for-good\/cpe-data\/'+\n                                'Dept_37-00027\/37-00027_ACS_data\/37-00027_ACS_poverty\/'+\n                                'ACS_15_5YR_S1701_with_ann.csv')\ncensus_poverty_df = census_poverty_df.iloc[1:].reset_index(drop=True)\ncensus_poverty_df = census_poverty_df.rename(columns={'GEO.id2':'GEOID'})\ncensus_tracts_gdf = gpd.read_file(\"..\/input\/texgeo\/cb_2017_48_tract_500k \/cb_2017_48_tract_500k\/\/cb_2017_48_tract_500k.shp\")\ncensus_merged_gdf = census_tracts_gdf.merge(census_poverty_df, on = 'GEOID')\ncensus_merged_gdf = census_merged_gdf.to_crs(epsg='4326')\ncensus_merged_gdf.head()","fd381ac7":"mapa = folium.Map([30.3, -97.7],zoom_start=10, height=500)\nlocations_df = force_clean_df[[\"LOCATION_LATITUDE\", \"LOCATION_LONGITUDE\"]].copy()\nlocations_df = locations_df.iloc[locations_df[['LOCATION_LATITUDE','LOCATION_LONGITUDE']].dropna().index].reset_index(drop=True)\nlocations_df[\"LOCATION_LATITUDE\"] = locations_df[\"LOCATION_LATITUDE\"].astype('float')\nlocations_df[\"LOCATION_LONGITUDE\"] = locations_df[\"LOCATION_LONGITUDE\"].astype('float')\nlocationlist = locations_df.values.tolist()[-2000:]\nfor point in range(0, len(locationlist)):\n    folium.CircleMarker(locationlist[point], radius=0.1, color='red').add_to(mapa)\n\nmapa","b084c31b":"DB_district_list=[k for k in force_clean_df['LOCATION_DISTRICT'].value_counts().keys()]\nDB_district_list","14279ca3":"final_aus_arrest=pd.read_csv('..\/input\/aus-final\/Dept_37-00027_arrest_GEo.csv')\nfinal_aus_arrest.head()","cdd81afd":"force_df = pd.read_csv(\"..\/input\/data-science-for-good\/cpe-data\/Dept_24-00013\/24-00013_UOF_2008-2017_prepped.csv\")\nforce_clean_df = force_df.loc[1:].reset_index(drop=True)\nforce_clean_df ['LOCATION_LONGITUDE']= pd.to_numeric(force_clean_df['LOCATION_LONGITUDE'], downcast='float') \nforce_clean_df ['LOCATION_LATITUDE']= pd.to_numeric(force_clean_df['LOCATION_LATITUDE'], downcast='float') \nforce_clean_df = force_clean_df[np.isfinite(force_clean_df['LOCATION_LONGITUDE'])]\nforce_clean_df=force_clean_df[force_clean_df['LOCATION_LONGITUDE']!=0].reset_index(drop=True)\nfoo=lambda x: Point(x['LOCATION_LONGITUDE'],x['LOCATION_LATITUDE'])\nforce_clean_df['geometry'] = (force_clean_df.apply(foo, axis=1))\nforce_clean_df = gpd.GeoDataFrame(force_clean_df, geometry='geometry')\nforce_clean_df.crs = {'init' :'epsg:4326'}\nforce_clean_df.head()","7112072a":"police_df = gpd.read_file( '..\/input\/data-science-for-good\/cpe-data\/\/Dept_24-00013\/'+\n                '24-00013_Shapefiles\/Minneapolis_Police_Precincts.shp')\npolice_df.head()","503c76e3":"fig1,ax = plt.subplots(1,2,figsize=(20,10))\npolice_df.plot(ax=ax[0],alpha=0.5,legend=True)\ns=force_clean_df['REASON_FOR_FORCE']\ns.value_counts().plot(kind='bar',ax=ax[1])\nforce_clean_df.plot(marker='.',ax=ax[0],column='LOCATION_DISTRICT',legend=True)","42d44a8d":"force_clean_df.SUBJECT_RACE.value_counts()\nprint(force_clean_df.SUBJECT_RACE.value_counts())\nfig1, ax1 = plt.subplots()\nax1.pie(force_clean_df.SUBJECT_RACE.value_counts(),labels=force_clean_df.SUBJECT_RACE.value_counts().keys(),autopct='%1.1f%%',startangle=90,  shadow=True)\nax1.axis('equal')\nplt.show()","05b2f83f":"census_tract_df=gpd.read_file(\"..\/input\/minneapolis\/cb_2017_27_tract_500k \/cb_2017_27_tract_500k.shp\")\ncensus_tract_df.head()","6985dd90":"mapa = folium.Map([45, -93.3], height=500, zoom_start=11)\n\nfolium.GeoJson(police_df).add_to(mapa)\nlocations_df = force_clean_df[[\"LOCATION_LATITUDE\", \"LOCATION_LONGITUDE\"]].copy()\nnotna = locations_df[['LOCATION_LATITUDE','LOCATION_LONGITUDE']].dropna().index\nlocations_df = locations_df.iloc[notna].reset_index(drop=True)\nlocations_df[\"LOCATION_LATITUDE\"] = locations_df[\"LOCATION_LATITUDE\"].astype('float')\nlocations_df[\"LOCATION_LONGITUDE\"] = locations_df[\"LOCATION_LONGITUDE\"].astype('float')\nlocationlist = locations_df.values.tolist()[-2000:]\nfor point in range(0, len(locationlist)):\n    folium.CircleMarker(locationlist[point], radius=0.1, color='red').add_to(mapa)\n\nmapa ","9bb723f9":"overlap_police=gpd.GeoDataFrame(columns=census_tract_df.columns)\nitem_set=[]\nfor index1,x in police_df.iterrows():\n    lst_geoid=[]\n    for index2, y in census_tract_df.iterrows():\n        if x['geometry'].contains(y['geometry']) or y['geometry'].intersects(x['geometry']) or y['geometry'].contains(x['geometry']):\n            if y['GEOID'] not in item_set:\n                lst_geoid.append(y['GEOID'])\n                item_set.append(y['GEOID'])\n                police_df.at[index1,'GEOid']=lst_geoid\n                overlap_police.loc[-1]=y\n                overlap_police.index = overlap_police.index + 1","c7cdfdb3":"fig2,ax2 = plt.subplots()\nforce_clean_df.plot(ax=ax2,marker='.',column='LOCATION_DISTRICT',legend=True,markersize=20)\noverlap_police.plot(ax=ax2,color='0.7',alpha=.5,edgecolor='white')\n\nfig2.set_size_inches(10,10)","82398e53":"final_aus_arrest=pd.read_csv('..\/input\/min-fin\/Dept_2400013_arrest_GEo.csv')\nfinal_aus_arrest.head()","03720194":"force_df = pd.read_csv(\"..\/input\/data-science-for-good\/cpe-data\/Dept_24-00098\/24-00098_Vehicle-Stops-data.csv\")\nforce_clean_df = force_df.loc[1:].reset_index(drop=True)\nforce_clean_df ['LOCATION_LONGITUDE']= pd.to_numeric(force_clean_df['LOCATION_LONGITUDE'], downcast='float') \nforce_clean_df ['LOCATION_LATITUDE']= pd.to_numeric(force_clean_df['LOCATION_LATITUDE'], downcast='float') \nforce_clean_df = force_clean_df[np.isfinite(force_clean_df['LOCATION_LONGITUDE'])]\nforce_clean_df=force_clean_df[force_clean_df['LOCATION_LONGITUDE']!=0].reset_index(drop=True)\nfoo=lambda x: Point(x['LOCATION_LONGITUDE'],x['LOCATION_LATITUDE'])\nforce_clean_df['geometry'] = (force_clean_df.apply(foo, axis=1))\nforce_clean_df = gpd.GeoDataFrame(force_clean_df, geometry='geometry')\nforce_clean_df.crs = {'init' :'epsg:4326'}\nforce_clean_df.head()","93ea4b37":"police_df = gpd.read_file('..\/input\/data-science-for-good\/cpe-data\/Dept_24-00098\/24-00098_Shapefiles\/StPaul_geo_export_6646246d-0f26-48c5-a924-f5a99bb51c47.shp')\npolice_df.head()","343b12af":"\nfig2,ax2 = plt.subplots()\nforce_clean_df.plot(ax=ax2)\npolice_df.plot(ax=ax2,color='0.7',alpha=.5,edgecolor='white')\n\nfig2.set_size_inches(10,10)","a0e060db":"force_clean_df.SUBJECT_RACE.value_counts()\nprint(force_clean_df.SUBJECT_RACE.value_counts())\nfig1, ax1 = plt.subplots()\nax1.pie(force_clean_df.SUBJECT_RACE.value_counts(),labels=force_clean_df.SUBJECT_RACE.value_counts().keys(),autopct='%1.1f%%',startangle=90,  shadow=True)\nax1.axis('equal')\nplt.show()","01d591bf":"census_tract_df=gpd.read_file(\"..\/input\/stpaul\/cb_2015_27_tract_500k\/cb_2015_27_tract_500k.shp\")\ncensus_tract_df.plot()","e0646da6":"final_arrest=pd.read_csv('..\/input\/stpa-final\/Dept_2400098_arrest_GEo.csv')\nfinal_arrest.head()","c1200f6a":"force_df = pd.read_csv(\"..\/input\/data-science-for-good\/cpe-data\/Dept_37-00049\/37-00049_UOF-P_2016_prepped.csv\")\nforce_clean_df = force_df.loc[1:].reset_index(drop=True)\nforce_clean_df ['LOCATION_LONGITUDE']= pd.to_numeric(force_clean_df['LOCATION_LONGITUDE'], downcast='float') \nforce_clean_df ['LOCATION_LATITUDE']= pd.to_numeric(force_clean_df['LOCATION_LATITUDE'], downcast='float') \nforce_clean_df = force_clean_df[np.isfinite(force_clean_df['LOCATION_LONGITUDE'])]\nforce_clean_df=force_clean_df[force_clean_df['LOCATION_LONGITUDE']!=0].reset_index(drop=True)\nfoo=lambda x: Point(x['LOCATION_LONGITUDE'],x['LOCATION_LATITUDE'])\nforce_clean_df['geometry'] = (force_clean_df.apply(foo, axis=1))\nforce_clean_df = gpd.GeoDataFrame(force_clean_df, geometry='geometry')\nforce_clean_df.crs = {'init' :'epsg:4326'}\nforce_clean_df.head()\n","55a4c166":"police_df = gpd.read_file('..\/input\/data-science-for-good\/cpe-data\/Dept_37-00049\/37-00049_Shapefiles\/EPIC.shp')\npolice_df=police_df.to_crs(epsg='4236')\npolice_df.head()","02af9a85":"fig2,ax2 = plt.subplots()\nforce_clean_df.plot(ax=ax2)\npolice_df.plot(ax=ax2,color='0.7',alpha=.5,edgecolor='white')\n\nfig2.set_size_inches(10,10)","543f7d84":"force_clean_df.SUBJECT_RACE.value_counts()\nprint(force_clean_df.SUBJECT_RACE.value_counts())\nfig1, ax1 = plt.subplots()\nax1.pie(force_clean_df.SUBJECT_RACE.value_counts(),labels=force_clean_df.SUBJECT_RACE.value_counts().keys(),autopct='%1.1f%%',startangle=90,  shadow=True)\nax1.axis('equal')\nplt.show()","964ac2ed":"mapa = folium.Map([32.78, -96.79],zoom_start=10, height=500)\nlocations_df = force_clean_df[[\"LOCATION_LATITUDE\", \"LOCATION_LONGITUDE\"]].copy()\nlocations_df = locations_df.iloc[locations_df[['LOCATION_LATITUDE','LOCATION_LONGITUDE']].dropna().index].reset_index(drop=True)\nlocations_df[\"LOCATION_LATITUDE\"] = locations_df[\"LOCATION_LATITUDE\"].astype('float')\nlocations_df[\"LOCATION_LONGITUDE\"] = locations_df[\"LOCATION_LONGITUDE\"].astype('float')\nlocationlist = locations_df.values.tolist()[-2000:]\nfor point in range(0, len(locationlist)):\n    folium.CircleMarker(locationlist[point], radius=0.1, color='red').add_to(mapa)\n\nmapa","e06f0a60":"census_tract_df=gpd.read_file(\"..\/input\/dallas\/cb_2017_48_tract_500k \/cb_2017_48_tract_500k\/cb_2017_48_tract_500k.shp\")\ncensus_tract_df.plot()","36a44869":"final_arrest=pd.read_csv('..\/input\/dala-fin\/Dept_3700049_arrest_GEo.csv')\nfinal_arrest.head()","e4426455":"force_df = pd.read_csv(\"..\/input\/data-science-for-good\/cpe-data\/Dept_35-00016\/35-00016_UOF-OIS-P.csv\")\nforce_clean_df = force_df.loc[1:].reset_index(drop=True)\nforce_clean_df ['LOCATION_LONGITUDE']= pd.to_numeric(force_clean_df['LOCATION_LONGITUDE'], downcast='float') \nforce_clean_df ['LOCATION_LATITUDE']= pd.to_numeric(force_clean_df['LOCATION_LATITUDE'], downcast='float') \nforce_clean_df = force_clean_df[np.isfinite(force_clean_df['LOCATION_LONGITUDE'])]\nforce_clean_df=force_clean_df[force_clean_df['LOCATION_LONGITUDE']!=0].reset_index(drop=True)\nfoo=lambda x: Point(x['LOCATION_LONGITUDE'],x['LOCATION_LATITUDE'])\nforce_clean_df['geometry'] = (force_clean_df.apply(foo, axis=1))\nforce_clean_df = gpd.GeoDataFrame(force_clean_df, geometry='geometry')\nforce_clean_df.crs = {'init' :'epsg:4326'}\nforce_clean_df.head()\n","92192443":"police_df = gpd.read_file('..\/input\/data-science-for-good\/cpe-data\/Dept_35-00016\/35-00016_Shapefiles\/OrlandoPoliceSectors.shp')\npolice_df=police_df.to_crs(epsg='4236')\npolice_df.head()","f9f3fff2":"fig2,ax2 = plt.subplots()\nforce_clean_df.plot(ax=ax2)\npolice_df.plot(ax=ax2,color='0.7',alpha=.5,edgecolor='white')\n\nfig2.set_size_inches(10,10)","5cd512ff":"force_clean_df.SUBJECT_RACE.value_counts()\nprint(force_clean_df.SUBJECT_RACE.value_counts())\nfig1, ax1 = plt.subplots()\nax1.pie(force_clean_df.SUBJECT_RACE.value_counts(),labels=force_clean_df.SUBJECT_RACE.value_counts().keys(),autopct='%1.1f%%',startangle=90,  shadow=True)\nax1.axis('equal')\nplt.show()","fca9f1a4":"mapa = folium.Map([28.53, -81.39],zoom_start=10, height=500)\nlocations_df = force_clean_df[[\"LOCATION_LATITUDE\", \"LOCATION_LONGITUDE\"]].copy()\nlocations_df = locations_df.iloc[locations_df[['LOCATION_LATITUDE','LOCATION_LONGITUDE']].dropna().index].reset_index(drop=True)\nlocations_df[\"LOCATION_LATITUDE\"] = locations_df[\"LOCATION_LATITUDE\"].astype('float')\nlocations_df[\"LOCATION_LONGITUDE\"] = locations_df[\"LOCATION_LONGITUDE\"].astype('float')\nlocationlist = locations_df.values.tolist()[-2000:]\nfor point in range(0, len(locationlist)):\n    folium.CircleMarker(locationlist[point], radius=0.1, color='red').add_to(mapa)\n\nmapa","d4bd97ff":"census_tract_df=gpd.read_file(\"..\/input\/orlando\/cb_2016_12_tract_500k\/cb_2016_12_tract_500k.shp\")\ncensus_tract_df.plot()","30b9500f":"final_arrest=pd.read_csv('..\/input\/orlan-final\/Dept_35-00016_arrest_GEo.csv')\nfinal_arrest.head()","da42ca42":"Minneapolis police department file","1b4b4827":"# Minneapolis","9cc230db":"The dataset of Data Science for Good contains both the police records and the geometry information files among 12 cities. To make good use of our data, the first thing to do is to map our arrest record with our police department data and geometry data. When first having a glance at the arrest record dataset most of them recorded the longitude and latitude of the crime happened location, which can be mapped with the and shapefiles by checking if the polygon contains the arrested record points. By doing so, we can exclude the arrest point (also can be reagred as outliers ) which are not laied in under given police sectors. \n\nThe ACS dataset constains the census information of each [Census Tract](https:\/\/en.wikipedia.org\/wiki\/Census_tract). To combine the ACS information with the arrest record, we introduce the knowledge of Racism Index which measures the Segregation, Education, Economics, Employment and provides a better and comprehensible measurement of racial disparity according to Segregation, Education, Economics, and Employment factors. The index calculation will be detailed explaned in the other kernal. By checking the geometry relationship of each census tract and our arrest record data, we can update the GEOid to each arrest record and in this way, the census data and arrest record are mapped with each other.","8f546739":"Merged census data with the arrest record:","9f0624bf":"Contriburion:\nThe work is contribute by Shuaidong Pan, Faner Lin and Weijian Li","79111d6d":"we can merge the census tract data set with arrest reocrd and update the GEOid to each record like we have down for the previous two dataset","0a61e302":"The St Paul dataset contains much more arrest records than other data set and we can also see this by plot the overlapping plot of ploce department and arrest record","c01d8b9b":"The final data set for index calculation and mining:","885cebfd":"# Data Set","3c9ae265":"First, let us have a look at the arrest file. For future mapping, we need to convert the longitude and latitude to the shaply geometry point.","e48c02e1":"The data folder of our main data: ","d2c0a01a":"After check for overlap and updated the GEOid for each arrest record we now have the final data:","8f719e95":"police department shape file","62932520":"Map the arrest record and police dpartment file on the plot","3e71c099":"The pie chart shows that the major races are white and black in this area\n","2fac4738":"Cobining plot of police department sectors and arrest records","0aa34476":"Mapped our arrest data with the ACS data, we can update the arrest ratio on each tract, and by mapping with the  police sectors data, we then can get the arrest ratio of each race under different police sectors. After getting the combined dataset, we decide to use frequent pattern mining to see if there exist any strong association rules and also by doing so can eliminate unrelated variables.","629434b8":"The final file for index calculation:","fc526647":"Arrest record with shapely points","e9fbb8b5":"Arrest data in the real map","d6713807":"Arrest record on the map","c22bac13":"The problem provided by The Center for Policing Equity(CPE) aims to find a way of measuring justice and solve the problem of racism in policing. In order to find clear and significant information to determine which factor or what kinds of areas are likely to cause or have racial disparity and to extract the essential information from these data, the first thing we need to do is to have a clear understanding of our dataset.","f825c440":"# Dallas","9e296299":"Police department sectors file:","a1770e25":"Arrest repord with shapely point","6ad53aad":"Census data plot","8b1ce4e8":"Subject race among all the arrest record","f4f7f365":"From the pie chart we can also point out that the major races are White and Black","75fe9f69":"Arrest record data set:","c748f5bf":"By the previous step, the data which laied out of the department range are excluded and also by analysing the subject race of each department, we will only include Black and White tow major races to calculate the arrest ratio and index ratio factors in the future.\nAfter preprocessing the data, the next step is to calculate the Racism Index and do the frequent pattern mining","9f817e1e":"Subject Race pie Chart:","c4b6bf81":"Austin arrest file","7a0f5ac9":"Next step [ACS Racism index and policy department information](https:\/\/www.kaggle.com\/linfaner2\/acs-racism-index-and-policy-department-information)","c2b1a3b8":"Subject race pie chart","ed4d52b5":"Subject race pie chart","73b435c7":"Census data  file","daaa5d21":"From these 12 department, we choose to use only 5 of them:\nDept-2400013 Minnesota\nDept-2400098 St Paul\nDept-3700027 Austin\nDept-3500016 Orlando\nDept-3700049 Dallas","0ec825b8":"The final file for index calculation after update the GEOid for each arrest record:","a86e450c":"# Saint Paul","2dbcbb94":"District list:","cc3ba3f2":"From the arrest plot we can see that for sector APT it only has one record. Due to the number of arrest  record in this sector, it most likely will bring bias to our result, so we will exclude this department.\nThen let have a look at the race ratio among all the arrest record\nsubject race pie chart","233d9a50":"The pie chart indicate the major races are Black and White among arrest records","f5f02946":"# Austin","b12ade78":"Arrest and police shape plot","50c417ed":"**For the check of loverlap and geometry relationship process, I did not include those functions and codes in the kernal due to the runtime of each department check","5a121203":"The pie chart indicate the major races are black,white, and Hispanic","0beaaf8c":"Subject Race Pie Chart:","43230e13":"# Overview","c5168651":"# Orlando","88073026":"After the data set merged, then we can assign each GEOid to the arrest record by check if the arrest happened location is in that census tract","a17911a0":"Minneapolis arrest file","e0c172a7":"# Methodology of Mining","5be4adee":"Inorder to have a more clear view of the arrest data we plot the data on the map","ff708a02":"The pie chart shows that Hispanic, White, and Black construct most of the area, so if other departments also has a large population of this three races, then we could only include the arrest ratio of these there major races in our frequent pattern mining procedure.\n\n\nTexas Census file:","5a018d3a":"Update the arrest file GeoID by check if it is contianed by the cunsus track file. ","65a1b410":"Census tract data plot:","96957302":"Police department geometry data file","882b3f8c":"After check for overlap and updated the GEOid for each arrest record we now have the final data:","573b5299":"Census geometry data plot : "}}