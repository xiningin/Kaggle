{"cell_type":{"e28df199":"code","b942015a":"code","84a280ec":"code","06860e47":"code","844e94de":"code","ed104b07":"code","1715d5bb":"code","53f25b3b":"code","434c977a":"code","1a9471ee":"code","682a6c4b":"code","cf1a452e":"code","3e33e29f":"code","e8c80039":"code","7f42e6b7":"code","90afd447":"code","5c5d16b1":"code","15ec2185":"code","7fd49a82":"code","963612fd":"code","fb8ce8aa":"code","5ce8dd58":"code","5be073dd":"markdown","d829bcb5":"markdown","0d7d384b":"markdown","a7907eb3":"markdown","9126d112":"markdown","ba2f566f":"markdown","2579ba0c":"markdown","5529a185":"markdown","17709aa5":"markdown","eb76bd35":"markdown","b6ac3690":"markdown","5f2f1b70":"markdown","97ed56ac":"markdown","8b822831":"markdown","632547d4":"markdown","376c3b2d":"markdown","2ec94010":"markdown","2aac878d":"markdown","0e04790e":"markdown","fb52b7c7":"markdown","a27101de":"markdown","31a4d6cb":"markdown","23a306cf":"markdown","d8e4c7fe":"markdown","5a496ec5":"markdown","2ac014c9":"markdown","85769220":"markdown","1ed78e90":"markdown","76b8e9a7":"markdown","9839bfa7":"markdown","3a76da5e":"markdown","eae96e7f":"markdown","f0e4907e":"markdown","5a45e96f":"markdown","25cf5b45":"markdown","1255b32b":"markdown","e3d9929f":"markdown","315f34a1":"markdown","1d9341e5":"markdown","e145ad21":"markdown","4feddeab":"markdown"},"source":{"e28df199":"import numpy as np\nimport pandas as pd\n\nimport os\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage\n\n\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\n# Map 1 library\nimport plotly.express as px\n\n# Map 2 libraries\nimport descartes\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\nimport cv2\nfrom wordcloud import WordCloud, STOPWORDS\n\n#Text Color\nfrom termcolor import colored\n\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\n\n#Data Preprocessing\nimport sklearn\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n\n#NLP\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#WordCloud\nfrom wordcloud import WordCloud, STOPWORDS\n\n#Text Processing\nimport re\nimport nltk\nnltk.download('popular')\n\n#Language Detection\n!pip install langdetect\nimport langdetect\n\n#Sentiment\nfrom textblob import TextBlob\n\n#ner\nimport spacy\n\n#Vectorizer\nfrom sklearn import feature_extraction, manifold\n\n#Word Embedding\nimport gensim.downloader as gensim_api\n\n#Topic Modeling\nimport gensim\n\n# HTML\nfrom IPython.core.display import HTML\n\nimport warnings\nwarnings.filterwarnings('ignore')","b942015a":"train = pd.read_csv(\"..\/input\/birdclef-2021\/train_metadata.csv\")\ntrain_labels = pd.read_csv(\"..\/input\/birdclef-2021\/train_soundscape_labels.csv\")\n\ntest = pd.read_csv('..\/input\/birdclef-2021\/test.csv')","84a280ec":"train.head()","06860e47":"train.info()","844e94de":"train_labels.head()","ed104b07":"train_labels.info()","1715d5bb":"test.head()","53f25b3b":"test.info()","434c977a":"print(f\"Training Dataset Shape: {colored(train.shape, 'yellow')}\")\nprint(f\"Training Dataset Labels Shape: {colored(train_labels.shape, 'yellow')}\")","1a9471ee":"print(\"Data: train\")\nprint(\"-----------\")\nfor col in train.columns:\n    print(col + \":\" + colored(str(len(train[col].unique())), 'yellow'))\n\nprint(\"\\nData: train_labels\")\nprint(\"-----------\")\nfor col in train_labels.columns:\n    print(col + \":\" + colored(str(len(train_labels[col].unique())), 'yellow'))","682a6c4b":"def plot_distribution(x, title):\n    \n    \"\"\"\n    Function to obtain the distribution plot of given data.\n    \n    params: x(string)     : Name of the Column for the Plot.\n            title(string) : Title of the Plot\n    \"\"\"\n    sns.displot(x)\n\n    plt.title(title, fontsize = 15)\n    plt.show()","cf1a452e":"label_list = [(train.primary_label.value_counts().values, \"Primary Label: Count Distribution\")]","3e33e29f":"for count, title in label_list:\n    plot_distribution(count, title)","e8c80039":"name_list = [(train.scientific_name.value_counts().values, \"Scientific Names: Count Distribution\"),\n            (train.common_name.value_counts().values, \"Common Name: Count Distribution\"),\n            ]","7f42e6b7":"for count, title in name_list:\n    plot_distribution(count, title)","90afd447":"print(f\"The Ratings of songs are in range {colored(train.rating.min(), 'yellow')} upto {colored(train.rating.max(), 'yellow')}\")","5c5d16b1":"plt.figure(figsize=(16, 6))\nax = sns.countplot(train['rating'], palette=\"hls\", order = train['rating'].value_counts().index)\n\nplt.title(\"Rating of Song\", fontsize = 16)\nplt.xticks(fontsize = 13)\nplt.yticks(fontsize = 13)\nplt.ylabel(\"Frequency\", fontsize = 14)\nplt.xlabel(\"Rating\", fontsize = 14)\nplt.show()","15ec2185":"train.type[0]","7fd49a82":"adjusted_type = train['type'].apply(lambda x: x.replace('[', ''))\nadjusted_type = adjusted_type.apply(lambda x: x.replace(']', ''))","963612fd":"adjusted_type = adjusted_type.apply(lambda x: x.split(',')).reset_index().explode(\"type\")","fb8ce8aa":"# Strip of white spaces and convert to lower chars\nadjusted_type = adjusted_type['type'].apply(lambda x: x.strip().lower()).reset_index()\nadjusted_type['type'] = adjusted_type['type'].replace('calls', 'call')","5ce8dd58":"# Create Top 8 list with song types\ntop_8 = list(adjusted_type['type'].value_counts().head(8).reset_index()['index'])\ndata = adjusted_type[adjusted_type['type'].isin(top_8)]\n\nplt.figure(figsize=(16, 6))\nax = sns.countplot(data['type'], palette=\"hls\", order = data['type'].value_counts().index)\n\nplt.title(\"Top 8 Song Types\", fontsize=16)\nplt.ylabel(\"Frequency\", fontsize = 14)\nplt.yticks(fontsize = 13) \nplt.xticks(rotation = 45, fontsize = 13) \nplt.xlabel(\"Type\", fontsize = 14);","5be073dd":"Now, we want to plot the types individually and guess what Python has got us covered! The function `explode` will help us with our goal.","d829bcb5":"## Type\n\n<img src = \"https:\/\/media.istockphoto.com\/vectors\/colorful-singing-birds-cartoon-vector-id180632417?b=1&k=6&m=180632417&s=612x612&w=0&h=Gsct3JG3AtLJxbSZWmMY6bH8_cL5LoSivNHIumMzK6Q=\" width = 400 height = 150\/>","0d7d384b":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Contents<\/center><\/h2>","a7907eb3":"### Value Counts and DIstribution Plot","9126d112":"### Description\nRecent advances in **machine listening** have improved acoustic data collection. However, it remains a challenge to generate analysis outputs with high precision and recall. The majority of data is unexamined due to a lack of effective tools for efficient and reliable extraction of the signals of interests (e.g., bird calls).\n\nThe **Cornell Lab of Ornithology** is dedicated to advancing the understanding and protection of birds and the natural world. The Lab joins with people from all walks of life to make new scientific discoveries, share insights, and galvanize conservation action. For this competition, they're collaborating with **Google Research, LifeCLEF, and Xeno-canto**.\n\nIn this competition, you\u2019ll **automate** the **acoustic identification of birds** in soundscape recordings. You'll examine an acoustic dataset to build detectors and classifiers to extract the signals of interest (bird calls). Innovative solutions will be able to do so efficiently and reliably.","ba2f566f":"Aha! There are no NULL values, so we are good to go.","2579ba0c":"### Data Description\nYour challenge in this competition is to identify which birds are calling in long recordings, given training data generated in meaningfully different contexts. This is the exact problem facing scientists trying to automate the remote monitoring of bird populations. This competition builds on the previous one by adding soundscapes from new locations, more bird species, richer metadata about the test set recordings, and soundscapes to the train set.\n\n### Files\n**train_short_audio** - The bulk of the training data consists of short recordings of individual bird calls generously uploaded by users of xenocanto.org. These files have been downsampled to 32 kHz where applicable to match the test set audio and converted to the ogg format. The training data should have nearly all relevant files; we expect there is no benefit to looking for more on [xenocanto.org](https:\/\/www.xeno-canto.org\/).\n\n**train_soundscapes** - Audio files that are quite comparable to the test set. They are all roughly ten minutes long and in the ogg format. The test set also has soundscapes from the two recording locations represented here.\n\n**test_soundscapes** - When you submit a notebook, the **test_soundscapes** directory will be populated with approximately 80 recordings to be used for scoring. These will be roughly 10 minutes long and in ogg audio format. The file names include the date the recording was taken, which can be especially useful for identifying migratory birds.\n\nThis folder also contains text files with the name and approximate coordinates of the recording location plus a csv with the set of dates the test set soundscapes were recorded.\n\n**test.csv** - Only the first three rows are available for download; the full test.csv is in the hidden test set.\n\n- `row_id`: ID code for the row.\n\n- `site`: Site ID.\n\n- `seconds`: the second ending the time window\n\n- `audio_id`: ID code for the audio file.\n\n**train_metadata.csv** - A wide range of metadata is provided for the training data. The most directly relevant fields are:\n\n- `ebird_code`: a code for the bird species. You can review detailed information about the bird codes by appending the code to `https:\/\/ebird.org\/species\/`, such as `https:\/\/ebird.org\/species\/amecro` for the American Crow.\n\n- `recodist`: the user who provided the recording.\n\n- `site`: where the recording was taken. Some bird species may have local call 'dialects,' so you may want to seek geographic diversity in your training data.\n\n- `date`: while some bird calls can be made year round, such as an alarm call, some are restricted to a specific season. You may want to seek temporal diversity in your training data.\n\n- `filename`: the name of the associated audio file.\n\n**train_soundscape_labels.csv** -\n\n- `row_id`: ID code for the row.\n\n- `site`: Site ID.\n\n- `seconds`: the second ending the time window\n\n- `audio_id`: ID code for the audio file.\n\n- `birds`: space delimited list of any bird songs present in the 5 second window. The label nocall means that no call occurred.\n\n**sample_submission.csv** - A properly formed sample submission file. Only the first three rows are public, the remainder will be provided to your notebook as part of the hidden test set.\n\n- `row_id`\n\n- `birds`: space delimited list of any bird songs present in the 5 second window. If there are no bird calls, use the label nocall.","5529a185":"1. [Competition Overview](#competition-overview)\n2. [Preliminaries](#preliminaries)\n3. [Load Datasets](#load-datasets)\n4. [Tabular Exploration](#tabular-exploration)\n5. [Label Exploration](#label-exploration)\n6. [Name Exploration](#name-exploration)\n7. [Rating and Type Exploration](#rating-and-type-exploration)\n8. [References](#references)","17709aa5":"### Value Counts and Distribution Plot","eb76bd35":"### Dataset Size","b6ac3690":"<a id=\"references\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>References<\/center><\/h2>","5f2f1b70":"### Code Requirements\n\n<img src = \"https:\/\/i.imgur.com\/S32GCaA.png\" width = \"600\" height = \"250\"\/>  \n\nSubmissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n\n- **CPU Notebook** <= 9 hours run-time\n- **GPU Notebook** <= 3 hours run-time\n- **Internet** access disabled\n- Freely & publicly available **external data** is allowed, including pre-trained models\n- **Submission file** must be named submission.csv","97ed56ac":"Now that we have the range, let's see if we have some great bird singers with us!","8b822831":"<h1><center>CLEF: InDepth EDA for Competition<\/center><\/h1>\n\n<center><img src = \"https:\/\/pentagram-production.imgix.net\/wp\/5936349e79c55\/mb-cornell-lab-of-ornithology-05.jpg?rect=%2C%2C%2C&w=640&fm=jpg&q=70&auto=format\" width = \"1000\" height = \"250\"\/><\/center>             \n\n                                                                                   ","632547d4":"<img src = \"https:\/\/data-flair.training\/blogs\/wp-content\/uploads\/sites\/2\/2018\/02\/Python-Libraries-011-1200x900.jpg\" width = 600 height = 250\/>","376c3b2d":"## Rating\n\n<img src = \"https:\/\/images.theconversation.com\/files\/150763\/original\/image-20161219-24307-2d95hz.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=926&fit=clip\" width = 600 height = 250\/>","2ec94010":"The [Cornell Lab of Ornithology](https:\/\/www.birds.cornell.edu\/home) brings together the agility and impact of an on-the-ground nonprofit organization with world-class science and teaching as part of Cornell University\u2019s College of Agriculture and Life Sciences. Their work spans disciplines from science to art, engineering to education. Their global community includes supporters, participants, and partners from all walks of life, united by a love of birds and nature and a commitment to help protect our planet.","2aac878d":"Here we find 2 problems, first is the **Square Brackets** i.e., **[]**, and second is multiple types placed together. We will deal with both these problems individually.","0e04790e":"<img src = \"https:\/\/imdiversity.com\/wp-content\/uploads\/references.jpg\" width = 400 height = 150\/>","fb52b7c7":"<a id=\"load-datasets\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Load Datasets<\/center><\/h2>","a27101de":"#### If you would have any doubts or need guidance in Data Science you can reach out to me on [LinkedIn](https:\/\/www.linkedin.com\/in\/ishandutta0098)","31a4d6cb":"<a id=\"competition-overview\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Competition Overview<\/center><\/h2>","23a306cf":"<a id=\"rating-and-type-exploration\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Rating and Type Exploration<\/center><\/h2>","d8e4c7fe":"- [Birdcall Recognition: EDA and Audio FE](https:\/\/www.kaggle.com\/andradaolteanu\/birdcall-recognition-eda-and-audio-fe)","5a496ec5":"### If you would have any doubts or need guidance in Data Science you can reach out to me on [LinkedIn](https:\/\/www.linkedin.com\/in\/ishandutta0098)","2ac014c9":"### Column-wise Unique Values","85769220":"<a id=\"name-exploration\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Name Exploration<\/center><\/h2>","1ed78e90":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:maroon; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>This is just the beginning! <\/center>                                                   \n<center>More exciting Plots and Analysis on the way!<\/center><\/h2>","76b8e9a7":"We begin with loading the dataset to work upon.","9839bfa7":"### Evaluation\nSubmissions will be evaluated based on their row-wise micro averaged [F1 score](https:\/\/en.wikipedia.org\/wiki\/F1_score).\n\nFor each row_id\/time window, you need to provide a space delimited list of the set of unique birds that made a call beginning or ending in that time window. If there are no bird calls in a time window, use the code `nocall`.","3a76da5e":"<a id=\"label-exploration\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Label Exploration<\/center><\/h2>","eae96e7f":"A good way to understand the distribution of data in a column is by plotting a distribution plot. We write a function `plot_distribution` which will save us a lot of time.","f0e4907e":"### Dataset Head and Info","5a45e96f":"Woww! So we have pretty decent bird singers I guess :-)","25cf5b45":"<a id=\"preliminaries\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Preliminaries<\/center><\/h2>","1255b32b":"We can't directly plot the `type` column as multiple types are mixed together. One of the examples is shown below.","e3d9929f":"<a id=\"tabular-exploration\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Tabular Exploration<\/center><\/h2>","315f34a1":"Let us quickly have a brief look upon the dataset. Hope to not encounter any NULL values!","1d9341e5":"<img src = \"https:\/\/image.freepik.com\/free-vector\/stay-tuned-neon-signs-text-vector_118419-96.jpg\" width = 600 height = 400 \/>","e145ad21":"Firstly, to remove the square brackets, we simply use the python `replace` function which replaces a given input with desired input. So here we are removing the brackets one by one and replacing it wo no spaces (literally nothing!!).","4feddeab":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:maroon; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>If you find this notebook useful, do give me an upvote, it helps to keep up my motivation. <\/center>                                                   <center>This notebook will be updated frequently so keep checking for furthur developments.<\/center><\/h2>"}}