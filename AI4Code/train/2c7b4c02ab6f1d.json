{"cell_type":{"e2298570":"code","9bb69394":"code","42243435":"code","19ebdffd":"code","69ae1a1d":"code","bcaae996":"code","ecbe99b9":"code","6d782894":"code","521cbb0a":"code","cc2f7ccb":"code","9bf41054":"code","a1a7c1b4":"code","b333e076":"code","0282bdf5":"code","f8323dbb":"code","a7aee59d":"code","edd7b4b9":"code","75b67565":"code","9e661c52":"code","05d35db6":"code","4a5d7ae3":"code","2f8e8a8e":"code","b5d9cfb7":"code","d69da805":"code","8ef6d503":"code","db80d2db":"markdown","ac4461bf":"markdown","1c77a3e5":"markdown","8fca93eb":"markdown","7e69c0fa":"markdown","1a27ef7f":"markdown","d8a8008c":"markdown","a0bb55e1":"markdown","c1b182db":"markdown","3a9016db":"markdown"},"source":{"e2298570":"import re\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.pipeline import Pipeline\nimport seaborn as sns\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, learning_curve\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom skmultilearn.problem_transform import ClassifierChain, LabelPowerset\nfrom sklearn.metrics import f1_score\n\nfrom matplotlib.pyplot import figure, show\nplt.style.use('ggplot')\nfrom seaborn import countplot, kdeplot\n\npd.set_option('display.max_rows', 150)","9bb69394":"# got this code from here https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_learning_curve.html\ndef plot_learning_curve(estimator, \n                        title, \n                        X, \n                        y,\n                        ylim=None, \n                        cv=None,\n                        n_jobs=None, \n                        train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(estimator,\n                                                            X,\n                                                            y,\n                                                            cv=cv,\n                                                            scoring=\"f1_macro\",\n                                                            n_jobs=n_jobs,\n                                                            train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","42243435":"df = pd.read_csv(\"\/kaggle\/input\/mpst-movie-plot-synopses-with-tags\/mpst_full_data.csv\")","19ebdffd":"df.head()","69ae1a1d":"df.shape","bcaae996":"df[\"tags\"].str.split(\",\").head()","ecbe99b9":"mlb = MultiLabelBinarizer()\ntags = mlb.fit_transform(df[\"tags\"].str.split(\", \"))\ncategories = mlb.classes_","6d782894":"df = pd.concat([df, pd.DataFrame(tags, columns=mlb.classes_)], axis=1)","521cbb0a":"df.shape","cc2f7ccb":"df.head()","9bf41054":"counts = []\ncategories = mlb.classes_\nfor i in categories:\n    counts.append((i, df[i].sum()))\ndf_stats = pd.DataFrame(counts, columns=['category', 'number_of_synopsis'])","a1a7c1b4":"df_stats.sort_values('number_of_synopsis', ascending=False).plot(x='category', y='number_of_synopsis', kind='bar', legend=False, grid=True, figsize=(24, 6))\nplt.title(\"Total de sinopses por categoria\")\nplt.ylabel('Quantidade', fontsize=12)\nplt.xlabel('categoria', fontsize=12)","b333e076":"rowsums = df.iloc[:,6:].sum(axis=1)\nx = rowsums.value_counts()\n\nplt.figure(figsize=(12,6))\nax = sns.barplot(x.index, x.values)\nplt.title(\"Tags por sinopse\")\nplt.ylabel('Quantidade', fontsize=12)\nplt.xlabel('Total de categorias', fontsize=12)","0282bdf5":"figure(figsize=(12,6))\nkdeplot(df[\"plot_synopsis\"].str.len())\nshow()","f8323dbb":"print('Numero de dados faltantes nas sinopses:')\nsum(df['plot_synopsis'].isna())","a7aee59d":"print(len(df.columns))\ncategories = df_stats.loc[df_stats[\"number_of_synopsis\"] > 400, \"category\"].tolist()\ndf.drop(df_stats.loc[df_stats[\"number_of_synopsis\"] < 400, \"category\"].tolist(), axis=1, inplace=True)\nlen(df.columns)\n","edd7b4b9":"df = df[df.sum(axis=1) != 0]","75b67565":"train = df[(df[\"split\"] == \"train\") | (df[\"split\"] == \"val\")]\ntest = df[df[\"split\"] == \"test\"]","9e661c52":"X_train = train.plot_synopsis\nX_test = test.plot_synopsis\nprint(X_train.shape)\nprint(X_test.shape)","05d35db6":"pipe= Pipeline(steps=[(\"preprocessing\", TfidfVectorizer(stop_words=stop_words, min_df=10, max_features=15000, max_df=.8)),\n                      (\"classifier\", ClassifierChain())])\n\n\nsearch_space = [{\"classifier__classifier\": [(LinearSVC(max_iter=3000))],\n                 \"classifier__classifier__C\": [0.1, 1, 10, 100]}]\n\ngridsearch = GridSearchCV(pipe, \n                          search_space, \n                          cv=5, \n                          n_jobs=-1, \n                          scoring = 'f1_macro') \n\ngridsearch.fit(X_train, train[categories])\n\nmodel = gridsearch.best_estimator_\n\n\n\nprint(gridsearch.best_estimator_)\nprint(gridsearch.best_score_)","4a5d7ae3":"title = \"Learning Curves SVM\"\n\nlc_svm = plot_learning_curve(model, title, X_train, train[categories], ylim=(0.0,1.0), cv=5, n_jobs=-1)\nlc_svm.show()","2f8e8a8e":"predictions = model.predict(X_test)","b5d9cfb7":"f1_score(test[categories], predictions, average=\"macro\")","d69da805":"def predict_synopsis(series_synopsis, model, categories):\n    tags = pd.DataFrame(gridsearch.predict(series_synopsis).todense(), columns=categories) \n    return tags.loc[:,(tags == 1.0).values.tolist()[0]].columns.tolist()\n    ","8ef6d503":"tags = predict_synopsis(pd.Series(test.iloc[96][\"plot_synopsis\"]), model, categories)\n\ntags","db80d2db":"### N\u00famero de sinopses por categoria","ac4461bf":"N\u00e3o existe dados faltantes nas sinopses.","1c77a3e5":"As sinopses apresentam textos extensos com muitas palavras.","8fca93eb":"# Teste Final","7e69c0fa":"### Quantidade de tags por sinopse","1a27ef7f":"\n# Feature Selection\n\nO intuito desta etapa \u00e9 remover as categorias que n\u00e3o tem n\u00famero suficiente para se criar modelo preditivo. O corte aconteceu em tags com menos de 400 ocorr\u00eancias ","d8a8008c":"# Modelagem\n\nPara lidar com o problema multi-label foi escolhido o ClassifierChain e para classifica\u00e7\u00e3o textual foi utilizado o SVM com kernel linear. J\u00e1 a vetoriza\u00e7\u00e3o foi realizada com a t\u00e9cnica BOW(Bag-of-Words) com TF-IDF.","a0bb55e1":"### Distribui\u00e7\u00e3o do tamanho do texto","c1b182db":"# An\u00e1lise Explorat\u00f3ria","3a9016db":"# Resultados"}}