{"cell_type":{"028adea7":"code","5646f892":"code","5355f3a7":"code","329e450d":"code","58f876c0":"code","ff362674":"code","870f1406":"code","bec35139":"code","ed3c8bce":"code","87eb3215":"code","c2bdde9e":"code","36d4eba0":"code","c1545a88":"code","7f756217":"code","19a55631":"code","2aa77af9":"code","cdf64a0a":"code","e93daa2d":"code","80fc090e":"code","1f71813b":"code","0f632d3d":"code","8ea813d0":"code","65d9aa41":"code","068bcdef":"code","858b8ae9":"code","c5aef724":"code","44624679":"markdown","845f191d":"markdown","4d2c917d":"markdown","8c8ba4b4":"markdown","cd972747":"markdown","51b809af":"markdown","074fc576":"markdown","51af439d":"markdown","5b79c680":"markdown","fff521f5":"markdown","fa3d5c89":"markdown","c7ef96ee":"markdown","18850049":"markdown","0be113b7":"markdown","0b9de176":"markdown","40648cc7":"markdown","6a6c3ea7":"markdown","5545306d":"markdown","eaea60cb":"markdown","a47ebad7":"markdown","d8d10312":"markdown","60db7c63":"markdown"},"source":{"028adea7":"import pandas as pd\nimport numpy as np\nimport cv2    \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\n\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras import optimizers\nfrom keras.models import Sequential, Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD\n\nfrom IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n\nplt.style.use('ggplot')\n\n%matplotlib inline","5646f892":"import tensorflow as tf\nprint(tf.__version__)","5355f3a7":"# set variables \nmain_folder = '..\/input\/celeba-dataset\/'\nimages_folder = main_folder + 'img_align_celeba\/img_align_celeba\/'\n\nEXAMPLE_PIC = images_folder + '000506.jpg'\n\nTRAINING_SAMPLES = 10000\nVALIDATION_SAMPLES = 2000\nTEST_SAMPLES = 2000\nIMG_WIDTH = 178\nIMG_HEIGHT = 218\nBATCH_SIZE = 16\nNUM_EPOCHS = 3","329e450d":"# import the data set that include the attribute for each picture\ndf_attr = pd.read_csv(main_folder + 'list_attr_celeba.csv')\ndf_attr.set_index('image_id', inplace=True)\ndf_attr.replace(to_replace=-1, value=0, inplace=True) #replace -1 by 0\ndf_attr.shape","58f876c0":"# List of available attributes\n#for i, j in enumerate(df_attr.columns):\n#    print(i, j)","ff362674":"# plot picture and attributes\nimg = load_img(EXAMPLE_PIC)\nplt.grid(False)\nplt.imshow(img)\ndf_attr.loc[EXAMPLE_PIC.split('\/')[-1]][['Smiling','Male','Young']] #some attributes","870f1406":"# Female or Male?\nplt.title('Female or Male')\nsns.countplot(y='Male', data=df_attr, color=\"c\")\nplt.show()","bec35139":"# Recomended partition\ndf_partition = pd.read_csv(main_folder + 'list_eval_partition.csv')\ndf_partition.head()","ed3c8bce":"# display counter by partition\n# 0 -> TRAINING\n# 1 -> VALIDATION\n# 2 -> TEST\ndf_partition['partition'].value_counts().sort_index()","87eb3215":"# join the partition with the attributes\ndf_partition.set_index('image_id', inplace=True)\ndf_par_attr = df_partition.join(df_attr['Male'], how='inner')\ndf_par_attr.head()","c2bdde9e":"def load_reshape_img(fname):\n    img = load_img(fname)\n    x = img_to_array(img)\/255.\n    x = x.reshape((1,) + x.shape)\n\n    return x\n\n\ndef generate_df(partition, attr, num_samples):\n    '''\n    partition\n        0 -> train\n        1 -> validation\n        2 -> test\n    \n    '''\n    \n    df_ = df_par_attr[(df_par_attr['partition'] == partition) \n                           & (df_par_attr[attr] == 0)].sample(int(num_samples\/2))\n    df_ = pd.concat([df_,\n                      df_par_attr[(df_par_attr['partition'] == partition) \n                                  & (df_par_attr[attr] == 1)].sample(int(num_samples\/2))])\n\n    # for Train and Validation\n    if partition != 2:\n        x_ = np.array([load_reshape_img(images_folder + fname) for fname in df_.index])\n        x_ = x_.reshape(x_.shape[0], 218, 178, 3)\n        y_ = np_utils.to_categorical(df_[attr],2)\n    # for Test\n    else:\n        x_ = []\n        y_ = []\n\n        for index, target in df_.iterrows():\n            im = cv2.imread(images_folder + index)\n            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) \/ 255.0\n            im = np.expand_dims(im, axis =0)\n            x_.append(im)\n            y_.append(target[attr])\n\n    return x_, y_","36d4eba0":"# Generate image generator for data augmentation\ndatagen =  ImageDataGenerator(\n  #preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True\n)\n\n# load one image and reshape\nimg = load_img(EXAMPLE_PIC)\nx = img_to_array(img)\/255.\nx = x.reshape((1,) + x.shape)\n\n# plot 10 augmented images of the loaded iamge\nplt.figure(figsize=(20,10))\nplt.suptitle('Data Augmentation', fontsize=28)\n\ni = 0\nfor batch in datagen.flow(x, batch_size=1):\n    plt.subplot(3, 5, i+1)\n    plt.grid(False)\n    plt.imshow( batch.reshape(218, 178, 3))\n    \n    if i == 9:\n        break\n    i += 1\n    \nplt.show()","c1545a88":"# Train data\nx_train, y_train = generate_df(0, 'Male', TRAINING_SAMPLES)\n\n# Train - Data Preparation - Data Augmentation with generators\ntrain_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n)\n\ntrain_datagen.fit(x_train)\n\ntrain_generator = train_datagen.flow(\nx_train, y_train,\nbatch_size=BATCH_SIZE,\n)","7f756217":"# Validation Data\nx_valid, y_valid = generate_df(1, 'Male', VALIDATION_SAMPLES)\n\n","19a55631":"# Import InceptionV3 Model\ninc_model = InceptionV3(weights='..\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                        include_top=False,\n                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\nprint(\"number of layers:\", len(inc_model.layers))\n#inc_model.summary()","2aa77af9":"#Adding custom Layers\nx = inc_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation=\"relu\")(x)\npredictions = Dense(2, activation=\"softmax\")(x)","cdf64a0a":"# creating the final model \nmodel_ = Model(inputs=inc_model.input, outputs=predictions)\n\n# Lock initial layers to do not be trained\nfor layer in model_.layers[:52]:\n    layer.trainable = False\n\n# compile the model\nmodel_.compile(optimizer=SGD(lr=0.0001, momentum=0.9)\n                    , loss='categorical_crossentropy'\n                    , metrics=['accuracy'])","e93daa2d":"#https:\/\/keras.io\/models\/sequential\/ fit generator\ncheckpointer = ModelCheckpoint(filepath='weights.best.inc.male.hdf5', \n                               verbose=1, save_best_only=True)","80fc090e":"hist = model_.fit_generator(train_generator\n                     , validation_data = (x_valid, y_valid)\n                      , steps_per_epoch= TRAINING_SAMPLES\/BATCH_SIZE\n                      , epochs= NUM_EPOCHS\n                      , callbacks=[checkpointer]\n                      , verbose=1\n                    )","1f71813b":"# Plot loss function value through epochs\nplt.figure(figsize=(18, 4))\nplt.plot(hist.history['loss'], label = 'train')\nplt.plot(hist.history['val_loss'], label = 'valid')\nplt.legend()\nplt.title('Loss Function')\nplt.show()","0f632d3d":"# Plot accuracy through epochs\nplt.figure(figsize=(18, 4))\nplt.plot(hist.history['accuracy'], label = 'train')\nplt.plot(hist.history['val_accuracy'], label = 'valid')\nplt.legend()\nplt.title('Accuracy')\nplt.show()","8ea813d0":"#load the best model\nmodel_.load_weights('weights.best.inc.male.hdf5')","65d9aa41":"# Test Data\nx_test, y_test = generate_df(2, 'Male', TEST_SAMPLES)\n\n# generate prediction\nmodel_predictions = [np.argmax(model_.predict(feature)) for feature in x_test ]\n\n# report test accuracy\ntest_accuracy = 100 * np.sum(np.array(model_predictions)==y_test) \/ len(model_predictions)\nprint('Model Evaluation')\nprint('Test accuracy: %.4f%%' % test_accuracy)\nprint('f1_score:', f1_score(y_test, model_predictions))","068bcdef":"#dictionary to name the prediction\ngender_target = {0: 'Female'\n                , 1: 'Male'}\n\ndef img_to_display(filename):\n   \n    \n    i = Image.open(filename)\n    i.thumbnail((200, 200), Image.LANCZOS)\n    \n    with BytesIO() as buffer:\n        i.save(buffer, 'jpeg')\n        return base64.b64encode(buffer.getvalue()).decode()\n    \n\ndef display_result(filename, prediction, target):\n    '''\n    Display the results in HTML\n    \n    '''\n\n    gender = 'Male'\n    gender_icon = \"https:\/\/i.imgur.com\/nxWan2u.png\"\n        \n    if prediction[1] <= 0.5:\n        gender_icon = \"https:\/\/i.imgur.com\/oAAb8rd.png\"\n        gender = 'Female'\n            \n    display_html = '''\n    <div style=\"overflow: auto;  border: 2px solid #D8D8D8;\n        padding: 5px; width: 420px;\" >\n        <img src=\"data:image\/jpeg;base64,{}\" style=\"float: left;\" width=\"200\" height=\"200\">\n        <div style=\"padding: 10px 0px 0px 20px; overflow: auto;\">\n            <img src=\"{}\" style=\"float: left;\" width=\"40\" height=\"40\">\n            <h3 style=\"margin-left: 50px; margin-top: 2px;\">{}<\/h3>\n            <p style=\"margin-left: 50px; margin-top: -6px; font-size: 12px\">{} prob.<\/p>\n            \n        <\/div>\n    <\/div>\n    '''.format(img_to_display(filename)\n               , gender_icon\n               , gender\n               , \"{0:.2f}%\".format(round(max(prediction)*100,2))\n               , gender_target[target]\n               , filename.split('\/')[-1]\n               )\n\n    display(HTML(display_html))","858b8ae9":"def gender_prediction(filename):\n    '''\n    predict the gender\n    \n    input:\n        filename: str of the file name\n        \n    return:\n        array of the prob of the targets.\n    \n    '''\n    \n    im = cv2.imread(filename)\n    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) \/ 255.0\n    im = np.expand_dims(im, axis =0)\n    \n    # prediction\n    result = model_.predict(im)\n    prediction = np.argmax(result)\n    \n    return result\n    ","c5aef724":"#select random images of the test partition\ndf_to_test = df_par_attr[(df_par_attr['partition'] == 2)].sample(2)\n\nfor index, target in df_to_test.iterrows():\n    result = gender_prediction(images_folder + index)\n    \n    #display result\n    display_result(images_folder + index, result[0], target['Male'])","44624679":"<h2>Inception-V3 model structure<\/h2>\nThis is the structure of the Inception-V3 model, developed over the imagenet dataset.\n\n\n<img src=\"https:\/\/i.imgur.com\/kdXUzu1.png\" width=\"1000px\"\/>\n\n\n","845f191d":"The result is a new set of images with modifications from the original one, that allows to the model to learn from these variations in order to take this kind of images during the learning process and predict better never seen images.","4d2c917d":"## Step 2: Split Dataset into Training, Validation and Test\n\nThe recommended partitioning of images into training, validation, testing of the data set is: \n* 1-162770 are training\n* 162771-182637 are validation\n* 182638-202599 are testing\n\nThe partition is in file <b>list_eval_partition.csv<\/b>\n\nDue time execution, by now we will be using a reduced number of images:\n\n* Training 20000 images\n* Validation 5000 images\n* Test 5000 Images\n","8c8ba4b4":"#### Join the partition and the attributes in the same data frame","cd972747":"With the data generator created and data for validation, we are ready to start modeling.","51b809af":"### Import libraries","074fc576":"## Step 4: Build the Model - Gender Recognition","51af439d":"### Distribution of the Attribute\n\nAs specified before, this Notebook is an imagine recognition project of the Gender. There are more Female gender than Male gender in the data set. This give us some insight about the need to balance the data in next steps.","5b79c680":"#### The best model after NUM_epech got an accuracy over the validation data of 95.75%.","fff521f5":"### List of the available attribute in the CelebA dataset\n\n40 Attributes","fa3d5c89":"<h2>New Top layers<\/h2>\nLayers to be trained with the new model.\n<img src=\"https:\/\/i.imgur.com\/rWF7bRY.png\" width=\"800px\"\/>","c7ef96ee":"### 4.2. Train Model","18850049":"## Step 3: Pre-processing Images: Data Augmentation\n\nGenerates Data Augmentation for iamges.\n\nData Augmentation allows to generate images with modifications to the original ones. The model will learn from these variations (changing angle, size and position), being able to predict better never seen images that could have the same variations in position, size and position.","0be113b7":"### 2.1: Generate Partitions (Train, Validation, Test)\n\nNumber of images need to be balanced in order to get a good performance for the model, each model will have its own folder of training, validation and test balanced data.\n","0b9de176":"### Example of a picture in CelebA dataset\n178 x 218 px","40648cc7":"I hope you enjoyed this Notebook :) Please feel free to ask me question you may have or make improvements to the Notebook. Cheers!","6a6c3ea7":"## Step 1: Data Exploration\n\nWe will be using the CelebA Dataset, which includes images of 178 x 218 px. Below is an example of how the pictures looks like.","5545306d":"### Load the attributes of every picture\nFile: list_attr_celeba.csv","eaea60cb":"### 4.3. Model Evaluation","a47ebad7":"### 3.1. Data Augmentation\n\nThis is how an image will look like after data augmentation (based in the giving parameters below).","d8d10312":"### 4.1. Set the Model","60db7c63":"### 3.2. Build Data Generators"}}