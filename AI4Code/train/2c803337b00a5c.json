{"cell_type":{"a2e32da2":"code","fdcf76e9":"code","967b4f9b":"code","81dce89d":"code","2b6b57db":"code","50b903bb":"code","41db9515":"code","cc9b549e":"code","4297e264":"code","c359b6f8":"code","7a1e1cb9":"code","d2a53e12":"code","9799510e":"code","81c4a507":"code","c4b30191":"code","0d553108":"code","26fa7b0a":"code","aff4d397":"code","ab2fb7ef":"code","b49f63e2":"code","bb680860":"code","3f5acb82":"code","318529f1":"code","7d73edba":"code","e90dbea9":"code","85d0d368":"code","80f175e6":"code","bd3cde9b":"code","8fbc8374":"code","04c291ba":"code","17e1d096":"code","5ef9613f":"code","b1a63a5b":"code","3d197860":"code","7707e41d":"code","32d84ff5":"code","6db0bbb7":"code","f1e8f2c6":"code","7757a8d7":"code","6bc6e882":"code","558449f7":"code","a4467874":"code","df9918c6":"code","7cb6e73f":"code","0e63a074":"code","06d85b61":"code","76c780d1":"code","43b51c03":"code","59d0f974":"code","904e3e11":"code","c237e536":"code","607207c2":"code","10388f79":"code","6bc6303b":"code","ef1bcca2":"code","71a273bd":"code","0b8bc969":"code","2c020ecb":"code","b21defe7":"code","2c072d71":"code","62f1b7e9":"code","65c58875":"code","587eb0b0":"code","ab1b001f":"markdown","5fba6072":"markdown","d9d9c235":"markdown","4869bc8e":"markdown","75732273":"markdown","29f6598b":"markdown","c3eb7c35":"markdown"},"source":{"a2e32da2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fdcf76e9":"df = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","967b4f9b":"df.head()","81dce89d":"df.info()","2b6b57db":"df.isnull().sum()","50b903bb":"df.columns","41db9515":"df['diagnosis'] = np.where(df.diagnosis == 'M',1,0)","cc9b549e":"#df.head()","4297e264":"df.diagnosis.value_counts()","c359b6f8":"df.corr()['diagnosis'].sort_values(ascending=False)","7a1e1cb9":"df = df.drop(columns=['id','Unnamed: 32'],axis=1)","d2a53e12":"df.describe()","9799510e":"df.corr()","81c4a507":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px","c4b30191":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(),annot=True,cmap='YlGnBu',center=0.4)","0d553108":"columns = ['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n\nsns.pairplot(df[columns], hue=\"diagnosis\", palette='mako')","26fa7b0a":"plt.figure(figsize=(10,8))\nsns.countplot(x='diagnosis',data=df)","aff4d397":"fig = px.scatter_matrix(df, dimensions=['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean'], color=\"diagnosis\")\nfig.show()","ab2fb7ef":"fig = px.scatter(df, x='smoothness_mean', y='compactness_mean', color=\"diagnosis\",\n            log_x=True, size_max=60)\nfig.show()","b49f63e2":"fig = px.area(df, x=\"radius_worst\", y=\"texture_worst\", color=\"diagnosis\")\nfig.show()","bb680860":"fig = px.histogram(df, x=\"perimeter_se\", y=\"area_se\", color=\"diagnosis\", marginal=\"rug\", hover_data=df.columns)\nfig.show()","3f5acb82":"fig = px.density_contour(df, x=\"concave points_worst\", y=\"perimeter_worst\",color=\"diagnosis\", marginal_x=\"rug\", marginal_y=\"histogram\")\nfig.show()","318529f1":"df.columns","7d73edba":"X =df.drop('diagnosis',axis=1)\n\n\ny = df.diagnosis","e90dbea9":"## using pearson correlation \nplt.figure(figsize=(20,20))\ncor = X.corr()\nsns.heatmap(cor,annot=True,cmap = plt.cm.CMRmap_r)","85d0d368":"## with the following function we can select highly correlated features\n\ndef correlation(dataset,threshold):\n    col_corr = set() # set of names of all the columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i,j]) > threshold:# we r intrested in coeff value\n                col_name = corr_matrix.columns[i] # getting the name of column\n                col_corr.add(col_name)\n    return col_corr\n                ","80f175e6":"corr_features = correlation(X,0.9)\nlen(set(corr_features))","bd3cde9b":"corr_features","8fbc8374":"X = X.drop(corr_features,axis=1)","04c291ba":"X.head()","17e1d096":"from sklearn.model_selection import train_test_split","5ef9613f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","b1a63a5b":"from sklearn.feature_selection import mutual_info_classif\n\nfrom sklearn.feature_selection import SelectKBest","3d197860":"mutual_info = mutual_info_classif(X_train,y_train)\nmutual_info","7707e41d":"mutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","32d84ff5":"mutual_info.sort_values(ascending=False).plot.bar(figsize=(20,13))","6db0bbb7":"select_15_best = SelectKBest(mutual_info_classif,k=15)\nselect_15_best.fit(X_train,y_train)\ncols = X_train.columns[select_15_best.get_support()]\n","f1e8f2c6":"X_train = X_train[cols] \nX_test = X_test[cols]","7757a8d7":"from sklearn.preprocessing import StandardScaler \nscaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.fit_transform(X_test)","6bc6e882":"from sklearn.linear_model import SGDClassifier\nsgd_cal = SGDClassifier()","558449f7":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(sgd_cal,X_train,y_train,cv=10)","a4467874":"from sklearn.metrics import accuracy_score","df9918c6":"score","7cb6e73f":"score.mean()","0e63a074":"X_train.shape,y_train.shape","06d85b61":"from sklearn.model_selection import StratifiedKFold","76c780d1":"accuracy = []\nskfl = StratifiedKFold(n_splits=10,random_state=None)\nskfl.get_n_splits(X_train,y_train)\nfor train_index,test_index in skfl.split(X_train,y_train):\n    print('train:',train_index,'validation:',test_index)\n    X1_train , X1_test = X_train[train_index] , X_train[test_index]\n    y1_train , y1_test = y_train.iloc[train_index] , y_train.iloc[test_index]\n    \n    sgd_cal.fit(X1_train,y1_train)\n    prediction = sgd_cal.predict(X1_test)\n    score = accuracy_score(prediction,y1_test)\n    accuracy.append(score)","43b51c03":"np.array(accuracy).mean()","59d0f974":"from sklearn.linear_model import LogisticRegression","904e3e11":"lr = LogisticRegression()","c237e536":"lr.fit(X_train,y_train)","607207c2":"prediction = lr.predict(X_test)","10388f79":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score","6bc6303b":"print(classification_report(y_test,prediction))","ef1bcca2":"sns.heatmap(confusion_matrix(y_test,prediction),annot=True)","71a273bd":"print(accuracy_score(y_test,prediction))","0b8bc969":"from sklearn.linear_model import SGDClassifier","2c020ecb":"sgd_cal = SGDClassifier()","b21defe7":"sgd_cal.fit(X_train,y_train)","2c072d71":"predictions = sgd_cal.predict(X_test)","62f1b7e9":"print(classification_report(y_test,predictions))","65c58875":"sns.heatmap(confusion_matrix(y_test,predictions),annot=True,cmap='YlGnBu')","587eb0b0":"print(accuracy_score(y_test,predictions))","ab1b001f":" #  1. USING STRATIFIED K_FOLD","5fba6072":"# **DATA VISUALIZATION**","d9d9c235":" # **TRAINING AND PREDICTIONS** ","4869bc8e":"# **FEATURE SELECTION**","75732273":"# 2. USING LOGISTIC REGRESSION","29f6598b":"# **FEATURE SCALING**","c3eb7c35":"# 3. USING SGD CLASSIFIER"}}