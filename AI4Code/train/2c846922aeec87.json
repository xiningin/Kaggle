{"cell_type":{"93465892":"code","583c4421":"code","5c489dd4":"code","f9ff7831":"code","e54b949e":"code","362c4460":"code","e7fd8e6b":"code","ba565a2a":"code","d4ece622":"code","5bb49339":"code","cc969481":"code","bbdbe0d1":"code","89933ac9":"code","581c61f5":"code","5185430c":"code","223f8295":"code","6abeb078":"code","7e08a8a3":"code","c8604049":"code","cdfb98b1":"code","ed6a9dbc":"code","31b6666d":"code","3b651421":"code","79cae2db":"code","1dd80a97":"code","9aae3ee2":"code","2a223536":"code","52ec2103":"code","340c788e":"code","937c1b2e":"code","7cae8b61":"code","d7e4b4a5":"code","64b5debe":"code","d39b7687":"code","9b06ef79":"code","c3120ed2":"code","63b69095":"markdown","d7bf9fa6":"markdown","f2b2e0b8":"markdown","23e19ef2":"markdown","e36e4dbe":"markdown","ba2ac0bd":"markdown","960b1408":"markdown","ef7b9c2b":"markdown","86f345f5":"markdown","84ec868e":"markdown","b3e9c9e5":"markdown","159e04ef":"markdown","0ffeac39":"markdown","dbb0a3cd":"markdown","90629ff1":"markdown","af5ed2f6":"markdown","9e622f1a":"markdown","2263c56b":"markdown","209e04c6":"markdown","a7ebffdf":"markdown"},"source":{"93465892":"import warnings\nwarnings.filterwarnings(\"ignore\")","583c4421":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.options.display.max_columns = 50\nsns.set_style('darkgrid')","5c489dd4":"nifty_50 = pd.read_csv('..\/input\/nifty-indices-dataset\/NIFTY 50.csv',parse_dates=[\"Date\"], index_col=\"Date\")\nnifty_50.head()","f9ff7831":"nifty_50.isnull().sum()","e54b949e":"nifty_50.interpolate(method='time', inplace=True)","362c4460":"ax = nifty_50[['High', 'Low']].plot(figsize=(20, 6))\nax.set_title('High v\/s Low', fontsize=24);","e7fd8e6b":"ax = nifty_50[['Close']].plot(figsize=(20, 6))\nax.set_title('Closing Prices', fontsize=24);","ba565a2a":"ax = nifty_50[['P\/E', 'P\/B']].plot(figsize=(20, 6))\nax.set_title('P\/E v\/s P\/B', fontsize=24);","d4ece622":"ax = nifty_50[['Close']]['2019':].plot(figsize=(20, 6))\nax.set_title('Closing Prices', fontsize=24);","5bb49339":"nifty_auto = pd.read_csv('..\/input\/nifty-indices-dataset\/NIFTY AUTO.csv',parse_dates=[\"Date\"], index_col=\"Date\")\nnifty_bank = pd.read_csv('..\/input\/nifty-indices-dataset\/NIFTY BANK.csv',parse_dates=[\"Date\"], index_col=\"Date\")\nnifty_fmcg = pd.read_csv('..\/input\/nifty-indices-dataset\/NIFTY FMCG.csv',parse_dates=[\"Date\"], index_col=\"Date\")\nnifty_IT = pd.read_csv('..\/input\/nifty-indices-dataset\/NIFTY IT.csv',parse_dates=[\"Date\"], index_col=\"Date\")\nnifty_metal = pd.read_csv('..\/input\/nifty-indices-dataset\/NIFTY METAL.csv',parse_dates=[\"Date\"], index_col=\"Date\")\nnifty_pharma = pd.read_csv('..\/input\/nifty-indices-dataset\/NIFTY PHARMA.csv',parse_dates=[\"Date\"], index_col=\"Date\")\n\n\nnifty_auto.interpolate(method='time', inplace=True)\nnifty_bank.interpolate(method='time', inplace=True)\nnifty_fmcg.interpolate(method='time', inplace=True)\nnifty_IT.interpolate(method='time', inplace=True)\nnifty_metal.interpolate(method='time', inplace=True)\nnifty_pharma.interpolate(method='time', inplace=True)\n\ndf = pd.DataFrame({\n    'NIFTY Auto index': nifty_auto['Close']['2020':].values, \n    'NIFTY Bank index': nifty_bank['Close']['2020':].values,\n    'NIFTY FMCG index': nifty_fmcg['Close']['2020':].values,\n    'NIFTY IT index': nifty_IT['Close']['2020':].values,\n    'NIFTY Metal index': nifty_metal['Close']['2020':].values,\n    'NIFTY Pharma index': nifty_pharma['Close']['2020':].values,\n})","cc969481":"ax = df.plot.box(figsize=(20, 6))","bbdbe0d1":"ax = df.plot(subplots=True, figsize=(20, 12))","89933ac9":"data = pd.read_csv(\"\/kaggle\/input\/nifty50-stock-market-data\/RELIANCE.csv\", parse_dates=['Date'], index_col='Date', usecols=['Date', 'Open','High','Low','Close','Volume','VWAP'])\nprint(data.shape)\ndata.head()","581c61f5":"data.tail()","5185430c":"ax = data['VWAP'].plot(figsize=(20,6))\nax.set_title('RELIANCE Stock Prices')\nax.axvspan('2014-06-01','2020-10-30', color='green', alpha=0.2) # Modi Govt\nax.axvspan('2020-03-01','2020-10-30', color='red', alpha=0.3) # Covid Pandemic\nax.set_ylabel('VWAP');","223f8295":"fig, ax = plt.subplots(figsize=(20, 6))\nsns.kdeplot(data['VWAP'],shade=True, ax=ax);","6abeb078":"data = data.resample('D').mean()\ndata.isnull().sum()","7e08a8a3":"data.interpolate(method='time', inplace=True)","c8604049":"from statsmodels.tsa.seasonal import seasonal_decompose\nfrom dateutil.parser import parse\n\nplt.rcParams.update({'figure.figsize': (20,10)})\ny = data['VWAP'].to_frame()\n\n\n# Multiplicative Decomposition \nseasonal_decompose(y, model='multiplicative',period = 52).plot().suptitle('Multiplicative Decompose', fontsize=22)\n\n# Additive Decomposition\nseasonal_decompose(y, model='additive',period = 52).plot().suptitle('Additive Decompose', fontsize=22);","cdfb98b1":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string(), '\\n')          # .to_string() removes the line \"dtype: float64\"\n    \n    if result[1] <= 0.05:\n        print(\"Strong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"Weak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")\n        \n    return out\n\nadf_test(data['VWAP'],title='Reliance Stock Data');","ed6a9dbc":"ax = data['VWAP'].resample('M').mean().plot.line(figsize=(20, 6))\nax.axvspan('2014-06','2020-10', color='green', alpha=0.2) # Modi Govt\nax.axvspan('2020-03','2020-10', color='red', alpha=0.3) # Covid Pandemic\nax.set_title('Monthly Mean VWAP for Reliance');","31b6666d":"ax = data['VWAP'].resample('A').mean().plot.bar(figsize=(20, 6))\nax.set_title('Yearly Mean VWAP for Reliance');","3b651421":"import statsmodels.api as sm","79cae2db":"plt.rcParams.update({'figure.figsize': (20,6)})\n\nsm.graphics.tsa.plot_acf(data['VWAP'], lags=30,title='auto correlation of VWAP',zero=False);\nsm.graphics.tsa.plot_pacf(data['VWAP'], lags=30,title='partial auto correlation of VWAP',zero=False);","1dd80a97":"data = data.reset_index()\nlag_features = [\"Open\", \"High\", \"Low\", \"Close\", \"VWAP\", \"Volume\"]\nwindow1 = 3\nwindow2 = 7\nwindow3 = 30\n\ndf_rolled_3d = data[lag_features].rolling(window=window1, min_periods=0)\ndf_rolled_7d = data[lag_features].rolling(window=window2, min_periods=0)\ndf_rolled_30d = data[lag_features].rolling(window=window3, min_periods=0)\n\ndf_mean_3d = df_rolled_3d.mean().shift(1).reset_index().astype(np.float32)\ndf_mean_7d = df_rolled_7d.mean().shift(1).reset_index().astype(np.float32)\ndf_mean_30d = df_rolled_30d.mean().shift(1).reset_index().astype(np.float32)\n\ndf_std_3d = df_rolled_3d.std().shift(1).reset_index().astype(np.float32)\ndf_std_7d = df_rolled_7d.std().shift(1).reset_index().astype(np.float32)\ndf_std_30d = df_rolled_30d.std().shift(1).reset_index().astype(np.float32)\n\nfor feature in lag_features:\n    data[f\"{feature}_mean_lag{window1}\"] = df_mean_3d[feature]\n    data[f\"{feature}_mean_lag{window2}\"] = df_mean_7d[feature]\n    data[f\"{feature}_mean_lag{window3}\"] = df_mean_30d[feature]\n    \n    data[f\"{feature}_std_lag{window1}\"] = df_std_3d[feature]\n    data[f\"{feature}_std_lag{window2}\"] = df_std_7d[feature]\n    data[f\"{feature}_std_lag{window3}\"] = df_std_30d[feature]\n\ndata.set_index(\"Date\", drop=False, inplace=True)\ndata.interpolate('pad',inplace=True)\ndata.fillna(data.mean(), inplace=True)\ndata.head()","9aae3ee2":"data.Date = pd.to_datetime(data.Date, format=\"%Y-%m-%d\")\ndata[\"month\"] = data.Date.dt.month\ndata[\"week\"] = data.Date.dt.week\ndata[\"day\"] = data.Date.dt.day\ndata[\"day_of_week\"] = data.Date.dt.dayofweek\ndata.head()","2a223536":"exogenous_features = data.columns[7:]","52ec2103":"df_train = data.loc[:\"2018\"]\ndf_valid = data.loc[\"2019\"]","340c788e":"from sklearn.metrics import mean_squared_error, mean_absolute_error","937c1b2e":"from sklearn.dummy import DummyRegressor\n\nmodel = DummyRegressor().fit(df_train[exogenous_features], df_train['VWAP'])\ndf_valid['Dummy_preds'] = model.predict(df_valid[exogenous_features])\nprint('RMSE:', np.sqrt(mean_squared_error(df_valid['VWAP'], df_valid['Dummy_preds'])))\nprint('MAE:', mean_absolute_error(df_valid['VWAP'], df_valid['Dummy_preds']))\ndf_valid[['VWAP', 'Dummy_preds']].plot();","7cae8b61":"from lightgbm import LGBMRegressor\n\nmodel = LGBMRegressor().fit(df_train[exogenous_features], df_train['VWAP'])\ndf_valid['LGBM_preds'] = model.predict(df_valid[exogenous_features])\nprint('RMSE:', np.sqrt(mean_squared_error(df_valid['VWAP'], df_valid['LGBM_preds'])))\nprint('MAE:', mean_absolute_error(df_valid['VWAP'], df_valid['LGBM_preds']))\ndf_valid[['VWAP', 'LGBM_preds']].plot();","d7e4b4a5":"!pip install pmdarima\nfrom pmdarima import auto_arima","64b5debe":"%%time\n\nmodel = auto_arima(\n    df_train.VWAP, exogenous=df_train[exogenous_features], \n    trace=True, error_action=\"ignore\", suppress_warnings=True\n).fit(df_train.VWAP, exogenous=df_train[exogenous_features])\n\ndf_valid[\"ARIMAX_preds\"] = model.predict(n_periods=len(df_valid), exogenous=df_valid[exogenous_features])\n\nprint('RMSE:', np.sqrt(mean_squared_error(df_valid['VWAP'], df_valid['ARIMAX_preds'])))\nprint('MAE:', mean_absolute_error(df_valid['VWAP'], df_valid['ARIMAX_preds']))\ndf_valid[['VWAP', 'ARIMAX_preds']].plot();","d39b7687":"model.summary()","9b06ef79":"df_valid['ARIMAX_error'] = df_valid['VWAP'] - df_valid['ARIMAX_preds']\ndf_valid['LGBM_error'] = df_valid['VWAP'] - df_valid['LGBM_preds']\nax = df_valid[['LGBM_error', 'ARIMAX_error']].plot()\nax.set_title('Errors', fontsize=18);","c3120ed2":"fig, ax = plt.subplots()\nax.plot(df_valid['VWAP'].values, df_valid['LGBM_error'].values, '.', label='LGBM_error')\nax.plot(df_valid['VWAP'].values, df_valid['ARIMAX_error'].values, '.', label='ARIMAX_error')\nax.set_title('Residual Plots', fontsize=18)\nax.legend();","63b69095":"## Stationarity\n\nIn the most intuitive sense, stationarity means that the statistical properties of a process generating a time series do not change over time. It does not mean that the series does not change over time, just that the way it changes does not itself change over time. The algebraic equivalent is thus a linear function, perhaps, and not a constant one; the value of a linear function changes as \ud835\udc99 grows, but the way it changes remains constant \u2014 it has a constant slope; one value that captures that rate of change.","d7bf9fa6":"## P\/E v\/s P\/B Ratio : Which one to use?\n\n[P\/E ratio is a popular measure](https:\/\/towardsdatascience.com\/visualizing-the-stock-market-with-tableau-c0a7288e7b4d) of how expensive a company\u2019s stock is. It is simply the company\u2019s market capitalization divided by its net income \u2014 in other words, how much does it cost us to buy $1 of a particular company\u2019s earnings. The higher the P\/E ratio, all other things equal, the more expensive a stock is perceived to be.the P\/E ratio shows what the market is willing to pay today for a stock based on its past or future earnings. A high P\/E could mean that a stock's price is high relative to earnings and possibly overvalued. Conversely, a low P\/E might indicate that the current stock price is low relative to earnings. \n\n![](https:\/\/imgur.com\/mNCjWPD.png)\n\nThe **P\/B ratio** on the other hand measures the market's valuation of a company relative to its book value.P\/B ratio is used by value investors to identify potential investments and P\/B ratios under 1 are typically considered solid investments.\n\n![](https:\/\/imgur.com\/uFGqIRV.png)","f2b2e0b8":"# Time Series Analysis\n\n## What is Time Series Data\nTime series data is a sequence of data points in chronological order that is used by businesses to analyze past data and make future predictions. These data points are a set of observations at specified times and equal intervals, typically with a datetime index and corresponding value. Common examples of time series data in our day-to-day lives include:     \n\n* Measuring weather temperatures \n* Measuring the number of taxi rides per month\n* Predicting a company\u2019s stock prices for the next day\n\n\n## Components of Time\u00a0Series\n\nTime series data consist of four components:\n\n1. Trend Component: This is a variation that moves up or down in a reasonably predictable pattern over a long period.\n\n2. Seasonality Component: is the variation that is regular and periodic and repeats itself over a specific period such as a day, week, month, season, etc.,\n\n3. Cyclical Component: is the variation that corresponds with business or economic 'boom-bust' cycles or follows their own peculiar cycles, and\n\n4. Random Component: is the variation that is erratic or residual and does not fall under any of the above three classifications.\n\n<img src='https:\/\/kite.com\/wp-content\/uploads\/2019\/08\/variations-of-time-series.jpg'>\n\n## Dataset\nIn this notebook, we\u2019ll use it to analyze stock prices of RELIANCE \n\n* The **Open and Close columns** indicate the opening and closing price of the stocks on a particular day.\n* The **High and Low columns** provide the highest and the lowest price for the stock on a particular day, respectively.\n* The **Volume column** tells us the total volume of stocks traded on a particular day.\n* The **volume weighted average price (VWAP)** is a trading benchmark used by traders that gives the average price a security has traded at throughout the day, based on both volume and price. It is important because it provides traders with insight into both the trend and value of a security","23e19ef2":"**References**\n\n* [Nifty Data EDA](https:\/\/www.kaggle.com\/parulpandey\/nifty-data-eda)\n* [Getting started with Time Series using Pandas](https:\/\/www.kaggle.com\/parulpandey\/getting-started-with-time-series-using-pandas)\n* [A modern Time Series tutorial](https:\/\/www.kaggle.com\/rohanrao\/a-modern-time-series-tutorial)\n* [Time Series Analysis and Forecasting - Reliance](https:\/\/www.kaggle.com\/yashvi\/time-series-analysis-and-forecasting-reliance)","e36e4dbe":"# Plotting ACF and PACF\n\n**Autocorrelation** and **partial autocorrelation** plots are heavily used in time series analysis and forecasting.\n\nThese are plots that graphically summarize the strength of a relationship with an observation in a time series with observations at prior time steps.\n\n**Statistical correlation** summarizes the strength of the relationship between two variables.\n\nWe can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a **serial correlation, or an autocorrelation.**\n\nA plot of the autocorrelation of a time series by lag is called the AutoCorrelation Function, or the acronym ACF. This plot is sometimes called a **correlogram or an autocorrelation plot**.\n\nA **partial autocorrelation** is a summary of the relationship between an observation in a time series with observations at prior time steps with the relationships of intervening observations removed.\n\nThe autocorrelation for an observation and an observation at a prior time step is comprised of both the direct correlation and indirect correlations. These indirect correlations are a linear function of the correlation of the observation, with observations at intervening time steps.\n\nIt is these indirect correlations that the partial autocorrelation function seeks to remove. Without going into the math, this is the intuition for the partial autocorrelation.\n\nA **partial autocorrelation** is a summary of the relationship between an observation in a time series with observations at prior time steps with the relationships of intervening observations removed.\n\nThe autocorrelation for an observation and an observation at a prior time step is comprised of both the direct correlation and indirect correlations. These indirect correlations are a linear function of the correlation of the observation, with observations at intervening time steps.\n\nIt is these indirect correlations that the partial autocorrelation function seeks to remove. Without going into the math, this is the intuition for the partial autocorrelation.","ba2ac0bd":"## Performance of other Nifty Sectoral Indices in 2020\n\nLet us now see the performance of NIFTY's sectoral indices which have been provided in the data. It'll be interesting to see how they have fared in these times of turmoil.\n\nLet's quickly understand what each of them represent:\n\n* **NIFTy Auto Index**: The Nifty Auto Index is designed to reflect the behavior and performance of the Automobiles sector which includes manufacturers of cars & motorcycles, heavy vehicles, auto ancillaries, tyres, etc. \n\n* **NIFTY Bank Index**: Nifty Bank Index is an index comprised of the most liquid and large capitalised Indian Banking stocks. It provides investors and market intermediaries with a benchmark that captures the capital market performance of Indian Banks\n\n* **NIFTY FMCG Index**: The Nifty FMCG Index comprises of maximum of 15 companies who manufacture such FMGC(Fast Moving Consumer Goods) products\n\n* **NIFTY IT Index**: Companies in this index are those that have more than 50% of their turnover from IT related activities like IT Infrastructure , IT Education and Software Training , Telecommunication Services and Networking Infrastructure, Software Development, Hardware Manufacturer\u2019s, Vending, Support and Maintenance.\n\n* **NIFTY Metal Index**: The Nifty Metal Index is designed to reflect the behavior and performance of the Metals sector including mining. The Nifty Metal Index comprises of maximum of 15 stocks that are listed on the National Stock Exchange.\n\n* **NIFTY Pharma Index**: Nifty Pharma Index to capture the performance of the Pharmaceuticals companies in this sector.","960b1408":"The residuals are randomly distributed, which indicates that the models are performing very well","ef7b9c2b":"## Error Analysis","86f345f5":"## Market Performance 2019 Onwards","84ec868e":"## About the Stock Data\n\nNow that our data has been converted into the desired format, let\u2019s take a look at its various columns for further analysis.\n\n* **The Open and Close columns** indicate the opening and closing price of the stocks on a particular day.\n* **The High and Low columns** provide the highest and the lowest price for the stock on a particular day, respectively.\n* **The Volume column** tells us the total volume of stocks traded on a particular day.\n* **The Turnover column** refers to the total value of stocks traded during a specific period of time. The time period may be annually, quarterly, monthly or daily\n* **P\/E** also called as the price-earnings ratio relates a company's share price to its earnings per share.\n* **P\/B** also called as Price-To-Book ratio measures the market's valuation of a company relative to its book value.\n* **Div Yield** or the dividend yield is the amount of money a company pays shareholders (over the course of a year) for owning a share of its stock divided by its current stock price\u2014displayed as a percentage.  ","b3e9c9e5":"# Feature Engineering\nAlmost every time series problem will have some external features or some internal feature engineering to help the model.\n\nLet's add some basic features like lag values of available numeric features that are widely used for time series problems. Since we need to predict the price of the stock for a day, we cannot use the feature values of the same day since they will be unavailable at actual inference time. We need to use statistics like mean, standard deviation of their lagged values.\n\nWe will use three sets of lagged values, one previous day, one looking back 7 days and another looking back 30 days as a proxy for last week and last month metrics.","159e04ef":"## Resampling and Missing Treatment","0ffeac39":"# LightGBM","dbb0a3cd":"## Seasonal decomposition\n\nWe can decompose a time series into trend, seasonal amd remainder components. The series can be decomposed as an additive or multiplicative combination of the base level, trend, seasonal index and the residual.\n\nThe seasonal_decompose in statsmodels is used to implements the decomposition.","90629ff1":"For boosting models, it is very useful to add datetime features like hour, day, month, as applicable to provide the model information about the time component in the data. For time series models it is not explicitly required to pass this information","af5ed2f6":"# What is NIFTY 50\n\n![](https:\/\/imgur.com\/fEgI9b6.png)\n\n\nThe NIFTY 50 index is [National Stock Exchange of India's](https:\/\/en.wikipedia.org\/wiki\/National_Stock_Exchange_of_India) benchmark broad based stock market index for the Indian equity market. NIFTY 50 stands for National Index Fifty, and represents the weighted average of 50 Indian company stocks in 17 sectors. It is one of the two main stock indices used in India, the other being the BSE Sensex\n\n\n![](https:\/\/i2.wp.com\/stableinvestor.com\/wp-content\/uploads\/2019\/09\/Nifty-Indexes-Broad-Markets.png?w=630&ssl=1)\n\nThe dataset consists of 13 files.Let's quickly understand what those are:\n\n## INDIAVIX \n\nIndia VIX is a volatility index based on the NIFTY Index Option prices.Volatility Index is a measure of market\u2019s expectation of volatility over the near term. Volatility is often described as the \u201crate and magnitude of changes in prices\" and in finance often referred to as risk. Volatility Index is a measure, of the amount by which an underlying Index is expected to fluctuate, in the near term,\n\n## NIFTY 50, NIFTY 100 and NIFTY 500 \n  * NIFTY 500 - It represents the top 500 companies based on full market capitalisation from the eligible universe\n  * NIFTY 100 - This represents the top 100 companies (i.e. from 1 to 100) from within the NIFTY 500. This index basically tries to track the performance of companies having large market caps.\n  * NIFTY 50 - This represents the first 50 companies from the NIFTY 100.\n\n## NIFTY SMALL CAP & MID CAP\n* NIFTY SMALLCAP - This index measures the performance of small-cap companies.\n* NIFTY MIDCAP - This index tries to measure the performance of mid-cap companies.\n\n## NIFTY NEXT 50\nThis includes the remaining 50 companies from NIFTY 100 after excluding the NIFTY 50 companies. These are also called as NIFTY Junior.\n\n## NIFTY SECTORAL INDICES\nThis includes NIFTY AUTO,NIFTY BANK, NIFTY FMCG, NIFTY IT,NIFTY METAL, NIFTY PHARMA\nThese Indices are designed to reflect the behavior and performance of the segment that they reflect i.e automobiles, bank, pharma etc.\n\n","9e622f1a":"**Missing Values**","2263c56b":"# ARIMAX","209e04c6":"# Dummy Model","a7ebffdf":"# Analysing the NIFTY 50 data"}}