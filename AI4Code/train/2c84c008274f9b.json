{"cell_type":{"eaf81d68":"code","20df14ec":"code","e3024508":"code","4282bcff":"code","09b5b525":"code","7ef59b25":"code","c88a67bc":"code","932174fc":"code","73d3fa2b":"code","1650caae":"code","1ca7d46f":"code","96027149":"code","374e0570":"code","d5813762":"code","474b2d47":"markdown","a09124ff":"markdown","7cacb452":"markdown","945df08a":"markdown","45efcec5":"markdown","ec7e22fd":"markdown"},"source":{"eaf81d68":"!pip install torchsummary","20df14ec":"import sys\nimport os\nimport h5py\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import classification_report\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom torchsummary import summary\n","e3024508":"home = \"..\/input\/3d-mnist\/\"\nos.listdir(home)","4282bcff":"with h5py.File(home+\"full_dataset_vectors.h5\", \"r\") as f:\n    x_train = f[\"X_train\"][:]\n    y_train = f[\"y_train\"][:]\n    x_test = f[\"X_test\"][:]\n    y_test = f[\"y_test\"][:]\n\n    \n# Binarize images.\nthreshold, upper, lower = 0.2, 1, 0\nx_train = np.where(x_train>threshold, upper, lower)\nx_test = np.where(x_test>threshold, upper, lower)\n\n# Convert images to channels, x_len, y_len, z_len shape.\n# Channels first as using pytorch.\nx_train = x_train.reshape(x_train.shape[0], 1, 16,16,16)\nx_test = x_test.reshape(x_test.shape[0], 1, 16,16,16)\n\nonehot_encoder = OneHotEncoder(sparse=False)\ny_train_onehot = onehot_encoder.fit_transform(y_train.reshape(len(y_train), 1))\ny_test_onehot = onehot_encoder.transform(y_test.reshape(len(y_test), 1))\n\nprint(\"x_train\", x_train.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"y_train_onehot\", y_train_onehot.shape)\n\nprint(\"x_test\", x_test.shape)\nprint(\"y_test\", y_test.shape)\nprint(\"y_test_onehot\", y_test_onehot.shape)\n","09b5b525":"plot_idx = np.random.permutation(range(len(x_train)))[0]\nplot_img_3d = np.squeeze(x_train[plot_idx])\nplot_label = y_train[plot_idx]\n\nplot_data = []\nfor x in range(0,16):\n    for y in range(0,16):\n        for z in range(0,16):\n            val = plot_img_3d[x,y,z]\n            plot_data.append([x,y,z,val])\n\nplot_df = pd.DataFrame(plot_data, columns=[\"x\", \"y\", \"z\", \"val\"])\nplot_df = plot_df.loc[plot_df[\"val\"]==1]\n\nfig = px.scatter_3d(plot_df, x='x', y='y', z='z', size=np.ones(len(plot_df)))\nfig.update_layout(title=\"label-{}\".format(plot_label))\nfig.show()","7ef59b25":"class MNISTClassification(nn.Module):\n    def __init__(self, input_channel=1):\n        super(MNISTClassification, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv3d(input_channel, 4, stride=2, kernel_size=3),\n            nn.BatchNorm3d(4),\n            nn.ReLU(),\n            \n            nn.Conv3d(4, 8, stride=2, kernel_size=3),\n            nn.BatchNorm3d(8),\n            nn.ReLU(),\n            \n            nn.Flatten(),\n            \n            nn.Linear(216, 10)\n        )\n    \n    def forward(self, x):\n        out = self.model(x)\n        return out\n\n\n    \ntest_in = np.random.normal(size=(3,1,16,16,16)) #.astype(np.float32)\ntest_in = torch.tensor(test_in, dtype=torch.float32)\nprint(test_in.shape)\nobj = MNISTClassification() #.to(\"cpu\")\nobj = obj.float()\n\nobj(test_in.float())","c88a67bc":"class MNISTDataset(Dataset):\n    def __init__(self, images_3d, labels_onehot, transform=None, target_transform=None):\n        self.images_3d = images_3d\n        self.labels_onehot = labels_onehot\n        self.transform = transform\n        self.target_transform = target_transform\n    \n    def __len__(self):\n        return len(self.images_3d)\n    \n    def __getitem__(self, idx):\n        img = self.images_3d[idx]\n        label_onehot = self.labels_onehot[idx]\n        if self.transform:\n            img = self.transform(img)\n        if self.target_transform:\n            label_onehot = self.target_transform(label_onehot)\n        return img, label_onehot","932174fc":"def train(model, dataloader, loss_fn, optimizer):\n    \"\"\"\n    Trains model for one epoch.\n    \"\"\"\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    loss = 0\n    for n_batch, (x,y) in tqdm(enumerate(dataloader)):\n        x,y = x.to(device).float(), y.to(device).float()\n        \n        y_pred = model(x).float()\n        # print(y.shape, y_pred.shape)\n        loss_val = loss_fn(y_pred, y.long())\n        \n        optimizer.zero_grad()\n        loss_val.backward()\n        optimizer.step()\n        loss += loss_val.item()\n        \n    avg_loss = loss \/ num_batches\n    return avg_loss","73d3fa2b":"def test(model, dataloader, loss_fn):\n    num_batches = len(dataloader)\n    loss = 0\n    y_list, y_pred_list = [], []\n    model.eval()\n    with torch.no_grad():\n        for n_batch, (x,y) in tqdm(enumerate(dataloader)):\n            x,y = x.to(device).float(), y.to(device).float()\n            \n            y_pred = model(x)\n            loss += loss_fn(y_pred, y.long()).item()\n            \n            y_list = y_list + list(np.squeeze(y.numpy()))\n            y_pred_list = y_pred_list + list(np.squeeze(np.argmax(y_pred.numpy(), axis=1)))\n    avg_loss = loss \/ num_batches\n    cls_report = classification_report(y_list, y_pred_list)\n    return avg_loss, cls_report\n#     print(\"Average test loss:\", avg_loss, sep=\"\\n\")\n#     print(\"Test classification report:\", cls_report, sep=\"\\n\")","1650caae":"# list(np.array([1,2,3]))","1ca7d46f":"device = \"cpu\"\nbatch_size = 8\nepochs = 20\nmodel = MNISTClassification().float().to(device)\nsummary(model, input_size=(1,16,16,16))\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\n\n\ntrain_dataset = MNISTDataset(x_train, y_train)\ntest_dataset = MNISTDataset(x_test, y_test)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n","96027149":"train_loss_list, test_loss_list = [], []\nfor epoch in range(epochs):\n    train_loss = train(model, train_dataloader, loss_fn, optimizer)\n    test_loss, test_cls_report = test(model, test_dataloader, loss_fn)\n    print(\"Train Loss:{}\\tTest Loss:{}\".format(train_loss, test_loss))\n    train_loss_list.append(train_loss)\n    test_loss_list.append(test_loss)\n\n","374e0570":"fig = go.Figure()\nfig.add_trace(go.Scatter(y=train_loss_list, name=\"train_loss_list\"))\nfig.add_trace(go.Scatter(y=test_loss_list, name=\"test_loss_list\"))\nfig.show()","d5813762":"# x,y = next(iter(train_dataloader))\n# x.shape, y.shape","474b2d47":"# 3. Classification Model\n\nFor classification we use CNN model using `pytorch` library. One point to note is that in current scenario all the layers that depend on dimensions are with their 3D versions. Whereas in case of images we use 2D versions of layers.","a09124ff":"In 2D images each visible point is known as `pixel`. A pixel is defined by (x,y) coordinates. In 3D we call visible points to be `voxel`. A voxel is defined by (x,y,z) coordinates.\n\nIn cell below we read file `full_dataset_vectors.h5`. In this file each 3D image is represented as a flat vector. After reading these image vectors we need to reshape them to 3D structure. Remember in 2D space MNIST images have shape 16x16. Similarly in 3D space MNIST images have shape 16x16x16. As you will see in cells below we reshape each image vector to 16x16x16.\n\nEach 3D image for 3D MNIST dataset could be considered as 3D matrix or tensor. All values of these tensors are in range of [0,1]. As we need binary images, so we use a `threshold` such that all values of image tensor above `threshold` are considered 1 and values below `threshold` are considered 0. This helps binarize the 3D representation of image.","7cacb452":"Create `Dataset` for training and testing images.","945df08a":"# 1. Read Data","45efcec5":"# 2. Visualize Data\n\nTo get an understanding of how binarized 3D images actually look we perform following steps:\n1. Select a random image and corresponding label.\n2. For ploting 3D image we will use 3D scatter plot from `plotly` library.\n3. Plotly 3D scatter plot accepts a dataframe as input. This dataframe is expected to have at least 3 columns representing x,y and z coordinates of each voxel.\n4. Note that for each x,y,z value in dataframe a point will be created on 3D scatter plot. Since we need to create points on plot only for voxels having value 1 so we filter the dataframe where voxel value is 1.\n5. Plot the results.","ec7e22fd":"In this notebook we will go through the process of creating a classifier for 3D MNIST digits."}}