{"cell_type":{"32657ce2":"code","ff269579":"code","a8bfcedb":"code","33292769":"code","57173ca3":"code","8e695041":"code","43a0210a":"code","00fadae6":"code","6dbdeb35":"code","8d91e1f8":"code","733677d6":"code","55760219":"code","95dd8184":"code","106eed0e":"code","7f08649b":"code","027af301":"code","7ab06e78":"code","58069a7e":"code","e5da4a63":"code","3ba1aadf":"code","2590329f":"code","d4fc9131":"code","bba96cd1":"code","e3199e16":"code","283799f9":"code","a4d609c0":"code","97d6ef02":"code","acfc9072":"code","275f41eb":"code","b741181e":"code","eced10b9":"code","f6a66e21":"code","bf148736":"code","19e4a251":"code","9d7e3962":"code","07b76ec0":"code","36791cb8":"code","c5158756":"code","eff6fe87":"code","74247145":"code","797c3ffd":"code","eedcd728":"code","8540b3fa":"code","27f355a5":"code","de6f5d0c":"code","53060fc6":"code","47f665a7":"code","3bc7a240":"code","14ea3acb":"code","27d386e8":"code","6fa1c3e6":"code","b425381a":"code","034238c8":"code","52fed1a1":"code","1ba6c567":"markdown","405ec200":"markdown","95a5d8b7":"markdown","0f756d02":"markdown","4923a697":"markdown","0b3296b5":"markdown","9e0d3f06":"markdown","11e1e03c":"markdown","6bbd7b01":"markdown","28c11205":"markdown","a215c4bb":"markdown","40e08a22":"markdown","242f2157":"markdown","a83e2d71":"markdown","a62809ef":"markdown","e710d647":"markdown","a8fab27e":"markdown","8f2c46bf":"markdown","05360a6b":"markdown","2197171e":"markdown","2f08aa5f":"markdown"},"source":{"32657ce2":"# import packages\nimport gc\nimport os\nimport subprocess\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport featuretools as ft\nimport lightgbm as lgb\nfrom lightgbm import plot_tree\nfrom graphviz import Digraph\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold,GroupKFold\nfrom sklearn.metrics import roc_auc_score,mean_squared_error\nimport time\nimport pickle\n\n%matplotlib inline","ff269579":"def check_fline(fpath):\n    \"\"\"check total number of lines of file for large files\n    \n    Args:\n    fpath: string. file path\n    \n    Returns:\n    None\n    \n    \"\"\"\n    lines = subprocess.run(['wc', '-l', fpath], stdout=subprocess.PIPE).stdout.decode('utf-8')\n    print(lines, end='', flush=True)","a8bfcedb":"fs=['..\/input\/ashrae-energy-prediction\/train.csv', \n    '..\/input\/ashrae-energy-prediction\/test.csv', \n    '..\/input\/ashrae-energy-prediction\/weather_test.csv',\n    '..\/input\/ashrae-energy-prediction\/weather_train.csv',\n    '..\/input\/ashrae-energy-prediction\/building_metadata.csv']\n[check_fline(s) for s in fs]","33292769":"# Load sample training data\ndf_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv')\ndf_train_weather = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_train.csv')\ndf_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/test.csv')\ndf_test_weather = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_test.csv')\ndf_building = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')","57173ca3":"# Show data shape\n[print(item.shape) for item in [df_train,df_train_weather,df_test,df_test_weather,df_building]]","8e695041":"df_train.head()","43a0210a":"df_test.head()","00fadae6":"df_train_weather.head()","6dbdeb35":"df_building.head()","8d91e1f8":"df_train_total = pd.merge(df_train,df_building,how='left',on='building_id')\ndf_train_total = pd.merge(df_train_total,df_train_weather,how='left',on=[\"site_id\", \"timestamp\"])","733677d6":"df_train_total.head()","55760219":"df_test_total = pd.merge(df_test,df_building,how='left',on='building_id')\ndf_test_total = pd.merge(df_test_total,df_test_weather,how='left',on=[\"site_id\", \"timestamp\"])","95dd8184":"df_test_total.head()","106eed0e":"def feat_value_count(df,colname):\n    \"\"\"value count of each feature\n    \n    Args\n    df: data frame.\n    colname: string. Name of to be valued column\n    \n    Returns\n    df_count: data frame.\n    \"\"\"\n    df_count = df[colname].value_counts().to_frame().reset_index()\n    df_count = df_count.rename(columns={'index':colname+'_values',colname:'counts'})\n    return df_count","7f08649b":"feat_value_count(df_train,'building_id')","027af301":"feat_value_count(df_test,'building_id')","7ab06e78":"len(set(df_train.building_id) & set(df_test.building_id))","58069a7e":"feat_value_count(df_train,'meter')","e5da4a63":"feat_value_count(df_train_weather,'site_id')","3ba1aadf":"feat_value_count(df_building,'primary_use')","2590329f":"feat_value_count(df_building,'site_id')","d4fc9131":"df_train_total.dtypes","bba96cd1":"df_train_total[\"timestamp\"] = pd.to_datetime(df_train_total[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')","e3199e16":"df_test_total[\"timestamp\"] = pd.to_datetime(df_test_total[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')","283799f9":"def check_missing(df,cols=None,axis=0):\n    \"\"\"check data frame column missing situation\n    Args\n    df: data frame.\n    cols: list. List of column names\n    axis: int. 0 means column and 1 means row\n    \n    Returns\n    missing_info: data frame. \n    \"\"\"\n    if cols != None:\n        df = df[cols]\n    missing_num = df.isnull().sum(axis).to_frame().rename(columns={0:'missing_num'})\n    missing_num['missing_percent'] = df.isnull().mean(axis)*100\n    return missing_num.sort_values(by='missing_percent',ascending = False) ","a4d609c0":"df_colmissing = check_missing(df_train_total,cols=None,axis=0)\ndf_colmissing","97d6ef02":"del df_colmissing\ngc.collect()","acfc9072":"print(max(df_train_total.timestamp),min(df_train_total.timestamp))","275f41eb":"print(max(df_test_total.timestamp),min(df_test_total.timestamp))","b741181e":"df_one_building = df_train_total[df_train_total.building_id == 1258]","eced10b9":"df_one_building.head()","f6a66e21":"# electricity\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 0])","bf148736":"del df_one_building\ngc.collect()","19e4a251":"# chilledwater\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 1])","9d7e3962":"# steam\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 2])","07b76ec0":"# hotwater\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 3])","36791cb8":"df_lots_building = df_train_total[df_train_total['building_id'].isin([1258,1298,1249])]","c5158756":"for i in range(0,4):\n    f, ax = plt.subplots(figsize=(15, 6))\n    sns.lineplot(x='timestamp',y='meter_reading', hue = 'building_id',legend=False,\n             data=df_lots_building[df_lots_building.meter == i])","eff6fe87":"del df_lots_building\ngc.collect()","74247145":"for i in range(0,4):\n    corr = df_train_total[df_train_total.meter == i][['timestamp','meter_reading','square_feet','year_built','floor_count',\n             'air_temperature','cloud_coverage','dew_temperature','precip_depth_1_hr',\n             'sea_level_pressure','wind_direction','wind_speed']].corr()\n    f, ax = plt.subplots(figsize=(15, 6))\n    sns.heatmap(corr, vmin=-1, vmax=1, annot=True)","797c3ffd":"del corr\ngc.collect()","eedcd728":"del df_train\ndel df_train_weather\ndel df_test\ndel df_test_weather\ndel df_building\ngc.collect()","8540b3fa":"def label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    # if categorical_colunms are not given than treat object as categorical features\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns","27f355a5":"df_train_total,colname = label_encoder(df_train_total, categorical_columns=['primary_use'])\ndf_test_total,colname = label_encoder(df_test_total, categorical_columns=['primary_use'])","de6f5d0c":"params = {'objective':'regression',\n          'boosting_type':'gbdt',\n          'metric':'rmse',\n          'learning_rate':0.1,\n          'num_leaves': 2**8,\n          'max_depth':-1,\n          'colsample_bytree':0.5,# feature_fraction 0.7\n          'subsample_freq':1,\n          'subsample':0.7,\n          'verbose':-1,\n          #'num_threads':8,\n          'seed': 47,#42\n                } ","53060fc6":"category_cols = ['building_id', 'site_id', 'primary_use']","47f665a7":"def fold_train_model(splits_num,features_train,labels_train,features_test,categorical):\n    splits = splits_num\n    folds = KFold(n_splits = splits,random_state=50)\n    predictions = np.zeros(len(features_test))\n    ave_score = 0\n    \n    for fold_num, (trn_idx, val_idx) in enumerate(folds.split(features_train.values, labels_train.values)):\n        print(\"Fold {}\".format(fold_num))\n        train_df, y_train_df = features_train.iloc[trn_idx], labels_train.iloc[trn_idx]\n        valid_df, y_valid_df = features_train.iloc[val_idx], labels_train.iloc[val_idx]\n\n        trn_data = lgb.Dataset(train_df, label=y_train_df,categorical_feature=categorical)\n        val_data = lgb.Dataset(valid_df, label=y_valid_df,categorical_feature=categorical)\n\n        valid_results = {}\n        clf = lgb.train(params,\n                        trn_data,\n                        10000,\n                        valid_sets = [trn_data, val_data],\n                        verbose_eval=500,\n                        early_stopping_rounds=500,\n                        evals_result=valid_results)\n\n        pred = clf.predict(valid_df)\n        score = np.sqrt(mean_squared_error(y_valid_df, pred))\n        ave_score += score \/ splits\n        predictions += clf.predict(features_test) \/ splits\n    return ave_score,predictions","3bc7a240":"def train_meter_type(meter_type,df_train_total,df_test_total,category_cols):\n    # prepare data\n    df_type_train = df_train_total[df_train_total.meter == meter_type]\n    # transfer label with log\n    df_type_label = np.log1p(df_type_train['meter_reading'])\n    df_type_train.drop(columns = ['meter','meter_reading'],inplace=True)\n    df_type_train['timestamp'] = df_type_train['timestamp'].astype('int64') \/\/ 10**9\n\n    df_type_test = df_test_total[df_test_total.meter == meter_type]\n    df_type_row_id = df_type_test['row_id']\n    df_type_test.drop(columns = ['row_id','meter'],inplace=True)\n    df_type_test['timestamp'] = df_type_test['timestamp'].astype('int64') \/\/ 10**9\n    \n    # train model\n    print('train model')\n    ave_score,predictions_type = fold_train_model(3,df_type_train,df_type_label,df_type_test,category_cols)\n    print('ave socre is %s'%(ave_score))\n    \n    # get prediction\n    print('get prediction')\n    sub_type = pd.DataFrame({'row_id': df_type_row_id, 'meter_reading': np.expm1(predictions_type)})\n    return sub_type,ave_score","14ea3acb":"#sub_ele_f,ave_score = train_meter_type(0,df_train_total,df_test_total,category_cols)","27d386e8":"#sub_cw_f,ave_score_cw = train_meter_type(1,df_train_total,df_test_total,category_cols)","6fa1c3e6":"#sub_stm_f,ave_score_stm = train_meter_type(2,df_train_total,df_test_total,category_cols)","b425381a":"#sub_hw_f,ave_score_hw = train_meter_type(3,df_train_total,df_test_total,category_cols)","034238c8":"#sub_all = pd.concat([sub_ele_f,sub_cw_f,sub_stm_f,sub_hw_f])\n#sub_all.sort_values(by='row_id')","52fed1a1":"sub_all.to_csv(['..\/output\/baseline_log.csv', index = False)","1ba6c567":"# Explore Unique Values","405ec200":"## multiple building","95a5d8b7":"## single building","0f756d02":"# Load Data","4923a697":"We need to predict meter reading given building id, meter, and timestamp.\n\nbuilding_meta.csv --> train.csv by 'building_id'.\n\nweather.csv --> building_meta.csv by 'site_id' --> train.csv by 'timestamp'","0b3296b5":"## set parameter","9e0d3f06":"### Data Findings\n\n1) The energy consumption level of each building is very different. \n2) The data clearly have some 'errors', like loss of data or unusual spikes. \n3) And from the visuals below, it's obvious that each meter type behave very differently. ","11e1e03c":"# Introduction","6bbd7b01":"A total of 1449 buildings are in train data. Building 1298 has the most records and building 403 has the least records.","28c11205":"Looks like there are some outliers.","a215c4bb":"# Target Explore","40e08a22":"It looks that we need to predict all 1449 building meter readings. All buildings that need to be predicted appear in train data.","242f2157":"## feature correlation with target","a83e2d71":"Looks like meter 0: electricity has the most record.","a62809ef":"## helper function","e710d647":"So we have train data span the whole 2016 and we need to predict from day one of 2017 to the end of 2018.","a8fab27e":"## Train Model","8f2c46bf":"# Check Missing Values","05360a6b":"# Basic Data Structure","2197171e":"# Baseline Model","2f08aa5f":"# Check Data Types"}}