{"cell_type":{"93e815ce":"code","748f6fb5":"code","eb943e14":"code","46877db2":"code","1d379028":"code","7fa08d5c":"code","1a61b643":"code","bfc01d6a":"code","a20a8e00":"markdown","7ba4fb36":"markdown","741ddb04":"markdown","5490e77a":"markdown","02a4d257":"markdown","52d24941":"markdown"},"source":{"93e815ce":"import numpy as np \nimport cv2                                         # working with, mainly resizing, images\nimport os,random                                          # dealing with directories\nfrom keras.models import Sequential,Model                # creating sequential model of CNN\nfrom keras.layers import Conv2D,BatchNormalization             # creating convolution layer\nfrom keras.layers import MaxPooling2D              # creating maxpool layer\nfrom keras.layers import Flatten,Activation                   # creating input vector for dense layer\nfrom keras.layers import Dense,GlobalAveragePooling2D                     # create dense layer or fully connected layer\nfrom keras.layers import Dropout                   # use to avoid overfitting by droping some parameters\nimport matplotlib.pyplot as plt   \nfrom sklearn.model_selection import train_test_split   \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,Adadelta","748f6fb5":"IMG_WIDTH,IMG_HEIGTH=150,150\nBatch_Size=8\nEpoch=30\n\ndef onehotlabel(resim):\n    if resim==\"BOLT_LEFT\":\n        return 0\n    elif resim==\"BOLT_RIGHT\":\n        return 1 \n    elif resim==\"FASTENING_MODEL_LEFT\":\n        return 2\n    elif resim==\"FASTENING_MODEL_RIGHT\":\n        return 3 \n    else: return -1\n","eb943e14":"def generate_data(DATADIR):\n    path = os.path.join(DATADIR)\n    dataset = []\n    for imge in os.listdir(DATADIR):        \n        for img in os.listdir(os.path.join(DATADIR,imge)): \n            if img.endswith(\"jpg\"):\n                lbl=onehotlabel(imge)\n                if (lbl!=-1):\n                    im = cv2.imread(os.path.join(path,imge,img),cv2.IMREAD_GRAYSCALE)\n                    im = cv2.resize(im, (IMG_WIDTH, IMG_HEIGTH))\n                    dataset.append([im,onehotlabel(imge)]) \n    \n    random.shuffle(dataset)\n    data = []\n    labels = []\n    for features, label in dataset:        \n        data.append(features.astype('float32') \/ 255)\n        labels.append(label)\n    data = np.array(data)\n#    data.reshape(data.shape[0], IMG_WIDTH ,IMG_HEIGTH,  1)\n    train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size=0.2)\n    return train_data,test_data,train_labels,test_labels\n","46877db2":"path=\"..\/input\/raildataset\/RailDataSet\"\n\ntrain_data,test_data,train_labels,test_labels= generate_data(path)","1d379028":"train_data=train_data.reshape(-1,IMG_WIDTH ,IMG_HEIGTH,1)\ntrain_data=train_data\/255\ntest_data=test_data.reshape(-1,IMG_WIDTH ,IMG_HEIGTH,1)\ntest_data=test_data\/255\n\n\ndatagen_train=ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ndatagen_train.fit(train_data)","7fa08d5c":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(IMG_WIDTH ,IMG_HEIGTH, 1)))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization()) #Y\u0131\u011f\u0131n normalle\u015ftirme derin sinir a\u011flar\u0131ndaki herhangi bir katmana 0\u2019a ortalanm\u0131\u015f ve 1 ile 0 aras\u0131nda de\u011ferlere sahip veriler vermemizi sa\u011flar.\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\n\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation(\"softmax\"))\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nmodel.summary()","1a61b643":"history = model.fit_generator(\n    datagen_train.flow(train_data, train_labels, batch_size=Batch_Size),\n    steps_per_epoch=len(train_data),\n    validation_steps = len(test_data),\n    epochs=Epoch,\n    verbose = 1,\n    validation_data=(test_data,test_labels)\n    )","bfc01d6a":"y_pred = model.predict_classes(test_data)\nacc = np.sum(y_pred == test_labels) \/ np.size(y_pred)\nprint(\"Test accuracy = {}\".format(acc))\n\n\nfinal_loss, final_acc = model.evaluate(test_data, test_labels, verbose=1)\nprint(\"validation loss: {0:.6f}, validation accuracy: {1:.6f}\".format(final_loss, final_acc))\n\naccuracy = history.history['accuracy']\nloss = history.history['loss']\nval_accuracy = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nprint(f'Training Accuracy: {np.max(accuracy)}')\nprint(f'Training Loss: {np.min(loss)}')\nprint(f'Validation Accuracy: {np.max(val_accuracy)}')\nprint(f'Validation Loss: {np.min(val_loss)}')\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')","a20a8e00":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code.","7ba4fb36":"## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)","741ddb04":"## Introduction\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.","5490e77a":"Oh, no! There are no automatic insights available for the file types used in this dataset. As your Kaggle kerneler bot, I'll keep working to fine-tune my hyper-parameters. In the meantime, please feel free to try a different dataset.","02a4d257":"## Conclusion\nClassification success rate is %13. This is very low. What do I need to do to increase it?","52d24941":"There is 0 csv file in the current version of the dataset:\n"}}