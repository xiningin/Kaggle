{"cell_type":{"c450bba5":"code","63350b46":"code","cf517df9":"code","4d635e04":"code","702b72db":"code","ea52f9a8":"code","ebb3c5f1":"code","b0bf959c":"code","ad71768b":"code","54d76769":"code","a54af458":"code","852eba18":"code","3124f9ab":"code","c1a28ebd":"code","25bcecbf":"code","b1a98b01":"code","f1e18066":"code","51e83bc0":"code","6b518fdf":"code","bbbf701d":"code","9b36c394":"code","f507878f":"code","b13f8636":"code","c4cc84d0":"code","03e05d12":"code","20745038":"code","434b5704":"code","a7e78845":"code","ac242e85":"code","f093fb2e":"code","30786e10":"code","168c400a":"code","a6e40831":"code","947ad2fd":"code","07968995":"code","90d3eac3":"code","0a8def59":"code","cf47dd21":"code","61f89770":"code","88ff7047":"code","19580af4":"code","ac8831fe":"code","ec646b57":"code","f8edf7b6":"code","dad4de45":"code","2e0e5fdf":"code","64686254":"code","0cd35b07":"code","0f62f978":"code","a85f644f":"code","464e713b":"code","ad589281":"code","5a7f6a45":"code","43a513f0":"code","f4a113d6":"code","8fa29066":"code","4a3970c1":"markdown","e8fdfd51":"markdown","2b493204":"markdown","f79526f9":"markdown"},"source":{"c450bba5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","63350b46":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","cf517df9":"df = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","4d635e04":"df.head()","702b72db":"sns.heatmap(df.isnull(),cmap='viridis',cbar=False)","ea52f9a8":"df.shape","ebb3c5f1":"df.info()","b0bf959c":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),annot=True)","ad71768b":"discrete_feature = [feature for feature in df.columns if len(df[feature].unique()) < 25]","54d76769":"print(discrete_feature)\nprint('Total Discrete feature :',len(discrete_feature))","a54af458":"for feature in discrete_feature:\n    data = df.copy()\n    \n    data.groupby(feature)['DEATH_EVENT'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('DEATH_EVENT')\n    plt.title(feature)\n    plt.show()","852eba18":"sns.countplot(x='anaemia',hue='DEATH_EVENT',data=df)","3124f9ab":"sns.countplot(x='diabetes',hue='DEATH_EVENT',data=df)","c1a28ebd":"sns.catplot(x='ejection_fraction',hue='DEATH_EVENT',data=df,kind='count');","25bcecbf":"sns.catplot(x='high_blood_pressure',hue='DEATH_EVENT',data=df,kind='count');","b1a98b01":"sns.countplot(x='sex',hue='DEATH_EVENT',data=df)","f1e18066":"sns.countplot(x='smoking',data=df,hue='DEATH_EVENT')","51e83bc0":"contineous_feature = [feature for feature in df.columns if feature not in discrete_feature]","6b518fdf":"print(contineous_feature)\nprint('Total contineous feature count is  : ',len(contineous_feature))","bbbf701d":"df.head()","9b36c394":"for feature in contineous_feature:\n    data = df.copy()\n    #data.groupby(feature)['DEATH_EVENT'].median().plot.bar()\n    plt.scatter(data[feature],data['DEATH_EVENT'])\n    plt.xlabel(feature)\n    plt.ylabel('DEATH_EVENT')\n    plt.title(feature)\n    plt.show()","f507878f":"X_scale  = df.drop('DEATH_EVENT',axis=1)\ny_scale = df['DEATH_EVENT']","b13f8636":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","c4cc84d0":"sc = StandardScaler()","03e05d12":"X_train, X_test, y_train, y_test = train_test_split(X_scale, y_scale, test_size=0.3, random_state=0)","20745038":"X_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","434b5704":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import Lasso","a7e78845":"feature_for_model = SelectFromModel(Lasso(alpha=0.05,random_state=0))\nfeature_for_model.fit(X_train_scaled,y_train)","ac242e85":"feature_for_model.get_support()","f093fb2e":"X.columns","30786e10":"#mask = feature_for_model.get_support()\n#X_train = X_train.columns[mask]","168c400a":"X = X[['age','ejection_fraction','serum_creatinine','serum_sodium','time']]\ny = df['DEATH_EVENT']","a6e40831":"X_train, X_test, y_train, y_test = train_test_split(X_scale, y_scale, test_size=0.3, random_state=0)","947ad2fd":"X_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","07968995":"from sklearn.linear_model import LogisticRegression","90d3eac3":"model = LogisticRegression()","0a8def59":"model.fit(X_train,y_train)","cf47dd21":"y_pred = model.predict(X_test)","61f89770":"from sklearn.metrics import classification_report,confusion_matrix","88ff7047":"print(classification_report(y_test,y_pred))","19580af4":"print(confusion_matrix(y_test,y_pred))","ac8831fe":" #Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]\n# Method of selecting samples for training each tree\n# bootstrap = [True, False]\n","ec646b57":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","f8edf7b6":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nrf = RandomForestClassifier()","dad4de45":"# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 1)","2e0e5fdf":"rf_random.fit(X_train,y_train)","64686254":"rf_random.best_params_","0cd35b07":"y_pred = rf_random.predict(X_test)","0f62f978":"print(confusion_matrix(y_pred,y_test))","a85f644f":"print(classification_report(y_pred,y_test))","464e713b":"rf_random.best_params_","ad589281":"from xgboost import XGBClassifier","5a7f6a45":"model = XGBClassifier()","43a513f0":"model.fit(X_train,y_train)","f4a113d6":"y_pred = model.predict(X_test)","8fa29066":"print(classification_report(y_test,y_pred))","4a3970c1":"### Check Data for Null values","e8fdfd51":"### Since all our feature is numeric. Lets check how many of them are discrete and how many are contineous features","2b493204":"### People with low anaemia are more prone to death event","f79526f9":"### No Null values in our Data Frame"}}