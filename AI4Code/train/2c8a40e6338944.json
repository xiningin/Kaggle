{"cell_type":{"dbc96c50":"code","e410210e":"code","71840c11":"code","9d41c4b4":"code","cc8957a9":"code","34e7fcbe":"code","95d1324e":"code","bdec1799":"code","f647026b":"code","f536b54c":"code","9ef7956d":"code","dc4ae1d8":"code","857e513b":"code","73c49e2f":"code","94501160":"code","377c4f7c":"code","3f91aca2":"code","bd1e0be7":"code","e3b0b0f8":"code","70ab3982":"code","26caa252":"code","170c4c98":"code","a2a302d3":"code","91d6e384":"code","fa990584":"code","c97aad17":"code","347152cc":"code","22c1dfba":"code","c4c8c014":"code","5e7ab8c0":"code","8f77ab18":"code","cb026a4d":"code","37146a63":"code","9c590158":"code","764d4f62":"code","7a1f754b":"code","d12d3988":"code","53bd5273":"code","47c40334":"code","e83b7707":"code","e62151e8":"code","767ac234":"code","e763bbb9":"code","723bbfc5":"code","812d9854":"code","a4506e65":"code","29104b9c":"code","bc029f40":"code","4f468343":"code","613c1dec":"code","48fe03a4":"code","3ffe5340":"code","9b853872":"code","f103e616":"code","36a1fba2":"code","e2e0fa3d":"code","b9c51069":"code","cde94152":"code","2aa90502":"code","43b88e1b":"markdown","e2e5fe57":"markdown","e5e93813":"markdown","a85c9afb":"markdown","bf1e36fe":"markdown","bd4f84e0":"markdown","4d6b0b83":"markdown","313b4518":"markdown","266fc38a":"markdown","19bbc415":"markdown","fd4f53bd":"markdown","fc0763a7":"markdown","3a9be3cd":"markdown","78574cfd":"markdown","4d7d5911":"markdown","027f0089":"markdown","cbc0a359":"markdown","5b93b80a":"markdown","686dc48b":"markdown","67431e3f":"markdown","34bc9c04":"markdown","b274d9be":"markdown","5fb676a4":"markdown","59f09a04":"markdown","76938090":"markdown","987fb4b9":"markdown","356b4cae":"markdown","8996aef3":"markdown","281a8a5d":"markdown","32c8865c":"markdown","4a8a0e6b":"markdown","39bc8178":"markdown","998ef80c":"markdown","74dd99e4":"markdown","640bcdae":"markdown","b31d5364":"markdown","84c101e9":"markdown"},"source":{"dbc96c50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e410210e":"import numpy as np\nimport pandas as pd\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\n\nimport seaborn as sns\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\nfrom prettytable import PrettyTable","71840c11":"#Loading the data\ndf = pd.read_csv('\/kaggle\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv')","9d41c4b4":"df.head()","cc8957a9":"df.shape","34e7fcbe":"df.columns","95d1324e":"df.describe()","bdec1799":"df.describe().T","f647026b":"df.isnull().sum()","f536b54c":"df.groupby(\"area_type\")[\"area_type\"].count()","9ef7956d":"# df.area_type.value_counts().plot(kind='bar')\nplt.hist(df['area_type'], rwidth = 0.8)","dc4ae1d8":"sns.set_theme(style=\"darkgrid\")\nplt.figure(figsize = (20,8))\nax=sns.countplot(df['balcony'], )\nplt.xticks(rotation = 90)\nfor p in ax.patches:\n    ax.annotate(int(p.get_height()), (p.get_x()+0.25, p.get_height()+1), va = 'bottom', color = 'black')","857e513b":"df.bath.value_counts().plot(kind='bar')\n# df.hist(column=['bath'])","73c49e2f":"(df[\"area_type\"].value_counts()).plot.pie(autopct=\"%.2f%%\", shadow=False, wedgeprops={'linewidth': 6}, rotatelabels=True,radius=1.5)\nplt.show()","94501160":"df1 = df.drop(['area_type','availability','society','balcony'],axis= 1)\ndf1.shape","377c4f7c":"# getting details of nan values\ndf1.isnull().sum()","3f91aca2":"df2 = df1.dropna()\ndf2.isnull().sum()","bd1e0be7":"df2['size'].unique()","e3b0b0f8":"# creating new feature BHK (numerical) \ndf2['BHK'] = df2['size'].apply(lambda x: int(x.split(' ')[0]))\ndf2.BHK.unique()","70ab3982":"plt.figure(figsize = (20,8))\nsns.boxplot(x = 'BHK', y = 'price', data = df2)\nplt.show()","26caa252":"plt.figure(figsize = (20,8))\nax=sns.countplot(df2['BHK'])\nplt.xticks(rotation = 90)\nfor p in ax.patches:\n    ax.annotate(int(p.get_height()), (p.get_x()+0.25, p.get_height()+1), va = 'bottom', color = 'black')","170c4c98":"# Exploring total sqaure feature\ndf2['total_sqft'].unique()\n","a2a302d3":"#categorizing data \ndef is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True\n\n\n# data having single value\n# single_value = df2[df2['total_sqft'].apply(is_float)].head(10)\n# single_value\n","91d6e384":"#data having range or different unit.\n# non_uniform = df2[~df2['total_sqft'].apply(is_float)].head(10)\n# non_uniform","fa990584":"df2.isnull().sum()","c97aad17":"def convert_totalsqft_to_num(x):\n    splits = x.split('-')\n    if len(splits) == 2:\n        return (float(splits[0])+float(splits[1]))\/2\n    try:\n        return float(x)\n    except:\n        return None\n\n\n","347152cc":"df2['total_sqft'] = df2['total_sqft'].apply(convert_totalsqft_to_num)\ndf2 = df2[df2['total_sqft'].notnull()]\ndf2.isnull().sum()","22c1dfba":"# making the price_sqft column\ndf3 = df2.copy()\ndf3[\"price_per_sqft\"] = df3[\"price\"]*100000\/df3[\"total_sqft\"]\ndf3.head()","c4c8c014":"df3.location = df3.location.apply(lambda x: x.strip())\nlocation_stats = df3['location'].value_counts(ascending=False)\nlocation_stats","5e7ab8c0":"location_stats_less_than_10 = location_stats[location_stats<=10]\nlocation_stats_less_than_10","8f77ab18":"df3.location = df3.location.apply(lambda x: 'Other' if x in location_stats_less_than_10 else x)\nlen(df3.location.unique())","cb026a4d":"df4 = df3.copy()\noutliers = df3[df3.total_sqft\/df3.BHK<300]\noutliers","37146a63":"df4.isnull().sum()","9c590158":"df5 = df4[~(df4.total_sqft\/df4.BHK<300)]\ndf5.isnull().sum()","764d4f62":"df5['price_per_sqft'].describe()","7a1f754b":"def outlier_removal(df):\n    df_out = pd.DataFrame()\n    for index, location_df in df.groupby('location'):\n        m = np.mean(location_df['price_per_sqft'])\n        s = np.std(location_df['price_per_sqft'])\n        without_outlier = location_df[(location_df['price_per_sqft']>(m-s)) & (location_df['price_per_sqft']<(m+s))]\n        df_out = pd.concat([df_out,without_outlier], ignore_index=True)\n    return df_out","d12d3988":"df6 = outlier_removal(df5)\ndf6.shape","53bd5273":"def plot_scatter(df,location):\n    bhk2 = df[(df.location==location) & (df.BHK==2)]\n    bhk3 = df[(df.location==location) & (df.BHK==3)]\n    matplotlib.rcParams['figure.figsize'] = (8,6)\n    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter(df6,\"Rajaji Nagar\")","47c40334":"plot_scatter(df6,\"Hebbal\")","e83b7707":"#now we can remove those 2 BHK apartments whose price_per_sqft is less than mean price_per_sqft of 1 BHK apartment\n\ndef remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('BHK'):\n            bhk_stats[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('BHK'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n    return df.drop(exclude_indices,axis='index')\ndf7 = remove_bhk_outliers(df6)\n# df8 = df7.copy()\ndf7.shape","e62151e8":"plot_scatter(df7,\"Rajaji Nagar\")","767ac234":"plot_scatter(df7,\"Hebbal\")","e763bbb9":"#plotting price per sqft\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df7.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")","723bbfc5":"plt.hist(df7.bath,rwidth=0.8)\nplt.xlabel(\"Number of bathrooms\")\nplt.ylabel(\"Count\")","812d9854":"df7[df7.bath>df7.BHK+2]","a4506e65":"df8 = df7[df7.bath<df7.BHK+2]\ndf8.shape","29104b9c":"df9 = df8.drop(['size','price_per_sqft'],axis='columns')\ndf9.head(3)","bc029f40":"dummies = pd.get_dummies(df9.location)\ndummies.head(3)","4f468343":"df10 = pd.concat([df9,dummies.drop(['Other'],axis='columns')],axis='columns')\ndf10.head()","613c1dec":"df11 = df10.drop('location', axis =1)\ndf11.shape","48fe03a4":"X = df11.drop(['price'],axis='columns')\nX.head(3)","3ffe5340":"y = df11.price\ny.head(3)","9b853872":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)\n","f103e616":"from sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train,y_train)\nlr_clf.score(X_test,y_test)","36a1fba2":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\n# shuffle Split used for shuffling train_data and test_data\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n\ncross_val_score(LinearRegression(), X, y, cv=cv)","e2e0fa3d":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'linear_regression' : {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n            }\n        },\n        'lasso': {\n            'model': Lasso(),\n            'params': {\n                'alpha': [1,2],\n                'selection': ['random', 'cyclic']\n            }\n        },\n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter': ['best','random']\n            }\n        }\n    }\n    scores = []\n    grid_cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs =  GridSearchCV(config['model'], config['params'], cv=grid_cv, return_train_score=False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n\nfind_best_model_using_gridsearchcv(X,y)","b9c51069":"def predict_price(location,sqft,bath,bhk):    \n    loc_index = np.where(X.columns==location)[0][0]\n\n    x = np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = bhk\n    if loc_index >= 0:\n        x[loc_index] = 1\n\n    return lr_clf.predict([x])[0]","cde94152":"predict_price('1st Phase JP Nagar',1000, 2, 2)","2aa90502":"import pickle\nwith open('banglore_home_prices_model.pickle','wb') as f:\n    pickle.dump(lr_clf,f)","43b88e1b":"Based on above charts we can see that data points highlighted in red below are outliers and they are being removed due to remove_bhk_outliers function,","e2e5fe57":"# Model bulding","e5e93813":"**Dropping some feature as they might have not strong impact on model performance, just to keep model simple.**","a85c9afb":"**Plotting the scatter plot for conditional outlier detection**","bf1e36fe":"# testing the model for few properties\n**defining a function because we don't know index of perticular location.**","bd4f84e0":"dropping all nan values.","4d6b0b83":"# One Hot Encoding for dummies","313b4518":"Performing Group by operation ","266fc38a":"# Outlier removing using bathroom feature","19bbc415":"**Examine locations which is a categorical variable. We need to apply dimensionality reduction technique here to reduce number of locations**","fd4f53bd":"# Export the tested model to a pickle file","fc0763a7":"# Feature Engineering and dimensionality reduction","3a9be3cd":"**Order of input**\n**location, sqft,bath,BHK**","78574cfd":"**OUR OBJECTIVE**\n1. The cost of a mis-classification can be high.\n2. From this project we will able to understand how house prices depend on other factors","4d7d5911":"> Buying a home, especially in a city like Bengaluru, is a tricky choice. While the major factors are usually the same for all metros, there are others to be considered for the Silicon Valley of India. With its help millennial crowd, vibrant culture, great climate and a slew of job opportunities, it is difficult to ascertain the price of a house in Bengaluru.","027f0089":"#here we can see non uniform data. some data are in range and others are in different units.\n\nchecking the total sqaure ft column:","cbc0a359":"# Find best model using GridSearchCV\n**(lasso regression, linear regression, DecisiontreeRegressor)**","5b93b80a":"1.Dealing with Missing Values\n\n2.Dealing With Inconsistancy \n\n3.Data cleaning\n\n4.Outlier removing\n\n5.making prediction\n\n6.model results comparison and hyperparameter tuning.","686dc48b":"**here our linear regression model is 86.97% accurate.**","67431e3f":"# Data Visualization","34bc9c04":"**Problem Statement**\nBy analyzing these Bangalore house data we will determine the approximate price for the houses.","b274d9be":"Plotting**** same scatter chart again to visualize price_per_sqft for 2 BHK and 3 BHK properties","5fb676a4":"# outlier detection ","59f09a04":"# Explainatory Data Analysis","76938090":"Here we can see that 2bhk price is more than 3bhk price for same location and total sqft.\nThis is not good for model.\nso we would compare 3bhk price with mean of 2bhk price.\nIf true, we discard those values.","987fb4b9":"From the above we can clearly see that One is BHK and the other one is Bedroom. \nSo we are making a new column called BHK and discarding all the units i.e. making it numerical.","356b4cae":"**Normally 2 bhk apartment is minimum 600 sqft. Here we will discard some data.  All the data having sqft\/bhk less then 300 will be treated as outlier.**","8996aef3":"**Based on above results we can say that LinearRegression gives the best score. Hence we will use that.**","281a8a5d":"**Here we find that min price per sqft is 267 rs\/sqft whereas max is 176470, this shows a wide variation. \nThese outliers would be removed by std method.\nBut we have to do it by location wise because every location have different mean and std.","32c8865c":"**It is unusual to have 2 more bathrooms than number of bedrooms in a home.\nAgain the business manager has a conversation with you (i.e. a data scientist) that if you have 4 bedroom home and even if you have bathroom in all 4 rooms plus one guest bathroom, you will have total bath = total bed + 1 max. Anything above that is an outlier or a data error and can be removed**","4a8a0e6b":"checking if there are some nan values","39bc8178":"Boxplot shows percentile and outliers.","998ef80c":"**From the above we can see that total_sqft is also a range (say, 3090-5002). For such cases we would just take average of the range. There are other cases such as 4125Perch which we can convert to square ft using unit conversion. \nBut here we are going to just keep things simple and droping them.**","74dd99e4":"Discription of dataset\n","640bcdae":"# Use K Fold cross validation to measure accuracy of our LinearRegression model","b31d5364":"# Important libraries","84c101e9":"**We can see that in 5 iterations we get a score above 80% all the time. This is pretty good but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV for this purpose**"}}