{"cell_type":{"5bf9c2c9":"code","bd30e748":"code","78b12de8":"code","f0d2157f":"code","5df9fba7":"code","6847aca5":"code","4cebc63e":"code","c5409ebd":"code","cce4ad9f":"code","10c43bb7":"code","ee6df86f":"code","7dea4081":"code","5d4165db":"code","8d30419d":"code","6600da37":"code","0defb406":"code","35e6b4c4":"code","58c58a3c":"code","776be397":"code","ce9f8b9f":"code","ac938e1c":"code","1b57d635":"code","dd94792f":"code","df2e1972":"code","d47cae04":"code","2a25c801":"code","8b8f2cae":"code","41aec1b5":"code","648efe75":"code","e238238f":"code","33a32fe1":"code","03f4178c":"markdown","b78ef9e5":"markdown","9b963df6":"markdown","c8b52ba6":"markdown","7eaf217f":"markdown","966d7bb9":"markdown","d5f9414f":"markdown","3352e7b6":"markdown","af411dca":"markdown","41d6c399":"markdown","29241196":"markdown","48744d09":"markdown","5b62ca56":"markdown","f78d2c54":"markdown","25896f9a":"markdown","9b608f68":"markdown","df84be1f":"markdown"},"source":{"5bf9c2c9":"import os\nimport sys\nimport glob\nimport random\nimport datetime\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport skimage.io                           #Used for imshow function\nimport skimage.transform                    #Used for resize function\nfrom skimage.morphology import label        #Used for Run-Length-Encoding RLE to create final submission\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport keras\nfrom keras.layers import Input, Conv2D, Lambda, MaxPooling2D, Conv2DTranspose, concatenate, Dropout, BatchNormalization\nfrom keras.models import Model, load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\n\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Skimage      :', skimage.__version__)\nprint('Keras        :', keras.__version__)\nprint('Tensorflow   :', tf.__version__)","bd30e748":"# \u0437\u0430\u0444\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u0432\u0435\u0440\u0441\u0438\u044e \u043f\u0430\u043a\u0435\u0442\u043e\u0432, \u0447\u0442\u043e\u0431\u044b \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u0431\u044b\u043b\u0438 \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u044b:\n!pip freeze > requirements.txt","78b12de8":"# seed values\nSEED = 42\nrandom.seed = SEED\nnp.random.seed(seed=SEED)","f0d2157f":"# SETUP\nTRAIN_PATH = 'train\/'\nTEST_PATH = 'test\/'\n\nIMG_WIDTH       = 256\nIMG_HEIGHT      = 256\nIMG_CHANNELS    = 3\n\nBATCH_SIZE      = 32\nNUM_EPOCHS      = 50\n# STEPS_PER_EPOCH = 600\nLR              = 0.001\nvalidation_split= 0.1","5df9fba7":"# \u0440\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435\nimport zipfile\nfor name_data in ['test', 'train']:\n    tmp_zip = zipfile.ZipFile('..\/input\/'+name_data+'.zip')\n    tmp_zip.extractall(name_data)\n    tmp_zip.close()","6847aca5":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv')\nsample_submission.sample(5)","4cebc63e":"len(sample_submission)","c5409ebd":"train_labels = pd.read_csv('..\/input\/train_labels.csv')\ntrain_labels.sample(10)","cce4ad9f":"len(train_labels)","10c43bb7":"len(train_labels) - train_labels.ImageId.duplicated().sum()","ee6df86f":"# Get train and test IDs\ntrain_ids = next(os.walk(TRAIN_PATH))\ntest_ids = next(os.walk(TEST_PATH))\n\nmask_count = 0\nfor train_id in train_ids[1]:\n    masks = next(os.walk(TRAIN_PATH + train_id + '\/masks\/'))[2]\n    mask_count += len(masks)\n\nprint('There are {} images.'.format(len(train_ids[1])))\nprint('There are {} masks.'.format(mask_count))\nprint('Approximately {} masks per image.'.format(mask_count \/\/ len(train_ids[1])))","7dea4081":"# \u0434\u043b\u044f \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0443\u0434\u043e\u0431\u043d\u0443\u044e \u043b\u0438\u0431\u0443 skimage\ndef get_X_data(path, output_shape=(None, None)):\n    '''\n    Loads images from path\/{id}\/images\/{id}.png into a numpy array\n    '''\n    img_paths = ['{0}\/{1}\/images\/{1}.png'.format(path, id) for id in os.listdir(path)]\n    X_data = np.array([skimage.transform.resize(skimage.io.imread(path)[:,:,:3], \n                                                output_shape=output_shape, \n                                                mode='constant', \n                                                preserve_range=True) for path in img_paths], dtype=np.uint8)  #take only 3 channels\/bands\n    \n    return X_data","5d4165db":"%%time\n# Get training data\nX_train = get_X_data(TRAIN_PATH, output_shape=(IMG_HEIGHT,IMG_WIDTH))\nprint(X_train.shape, X_train.dtype)","8d30419d":"def get_Y_data(path, output_shape=(None, None)):\n    '''\n    Loads and concatenates images from path\/{id}\/masks\/{id}.png into a numpy array\n    '''\n    img_paths = [glob.glob('{0}\/{1}\/masks\/*.png'.format(path, id)) for id in os.listdir(path)]\n    \n    Y_data = []\n    for i, img_masks in enumerate(img_paths):  #loop through each individual nuclei for an image and combine them together\n        masks = skimage.io.imread_collection(img_masks).concatenate()  #masks.shape = (num_masks, img_height, img_width)\n        mask = np.max(masks, axis=0)                                   #mask.shape = (img_height, img_width)\n        mask = skimage.transform.resize(mask, output_shape=output_shape+(1,), mode='constant', preserve_range=True)  #need to add an extra dimension so mask.shape = (img_height, img_width, 1)\n        Y_data.append(mask)\n    Y_data = np.array(Y_data, dtype=np.bool)\n    \n    return Y_data","6600da37":"%%time\n# Get training data labels\nY_train = get_Y_data(TRAIN_PATH, output_shape=(IMG_HEIGHT,IMG_WIDTH))\nprint(Y_train.shape, Y_train.dtype)","0defb406":"# Check training data\nf, axarr = plt.subplots(2,4)\nf.set_size_inches(20,10)\nix = random.randint(0, len(train_ids[1]))\naxarr[0,0].imshow(X_train[ix])\naxarr[0,1].imshow(np.squeeze(Y_train[ix]))\n\naxarr[0,2].imshow(X_train[ix])\naxarr[0,3].imshow(np.squeeze(Y_train[ix]))\n\naxarr[1,0].imshow(X_train[ix])\naxarr[1,1].imshow(np.squeeze(Y_train[ix]))\n\naxarr[1,2].imshow(X_train[ix])\naxarr[1,3].imshow(np.squeeze(Y_train[ix]))\n\nplt.show()","35e6b4c4":"# Build U-Net model\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = Lambda(lambda x: x \/ 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n#c5 = BatchNormalization() (c5)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\noptimizer = Adam(lr=LR,)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy',)\nmodel.summary()","58c58a3c":"# Fit model\nhistory = model.fit(X_train, Y_train, \n                    validation_split=validation_split, \n                    batch_size=BATCH_SIZE, \n                    epochs=NUM_EPOCHS, \n                    verbose=2,)","776be397":"model.save('keras_unet.h5')","ce9f8b9f":"def plot_loss_history(history):\n    # validation losses\n    val_loss = history.history['val_loss']\n    loss = history.history['loss']\n\n    plt.title('Loss')\n    plt.plot(val_loss, 'r', loss, 'b')\n    plt.show()\n    \nplot_loss_history(history)","ac938e1c":"# Use model to predict train labels\nmodel = load_model('keras_unet.h5',)\nY_predict = model.predict(X_train, verbose=1)\nY_predict.shape","1b57d635":"# Check predict data\nf, axarr = plt.subplots(2,3)\nf.set_size_inches(20,10)\nix = random.randint(0, len(train_ids[1]))\naxarr[0,0].imshow(X_train[ix])\naxarr[0,0].set_title('Microscope')\naxarr[0,1].imshow(np.squeeze(Y_predict[ix]))\naxarr[0,1].set_title('\"Predicted\" Masks')\naxarr[0,2].imshow(np.squeeze(Y_train[ix]))\naxarr[0,2].set_title('\"GroundTruth\" Masks')\n\naxarr[1,0].imshow(X_train[ix])\naxarr[1,0].set_title('Microscope')\naxarr[1,1].imshow(np.squeeze(Y_predict[ix]))\naxarr[1,1].set_title('\"Predicted\" Masks')\naxarr[1,2].imshow(np.squeeze(Y_train[ix]))\naxarr[1,2].set_title('\"GroundTruth\" Masks')\n\nplt.show()","dd94792f":"# Get test data\nX_test = get_X_data(TEST_PATH, output_shape=(IMG_HEIGHT,IMG_WIDTH))\n\n# Use model to predict test labels\nY_hat = model.predict(X_test, verbose=1)\nY_hat.shape","df2e1972":"idx = random.randint(0, len(test_ids[1]))\nprint(X_test[idx].shape)\nskimage.io.imshow(X_test[idx])\nplt.show()\nskimage.io.imshow(Y_hat[idx][:,:,0])\nplt.show()","d47cae04":"# Run-length encoding stolen from https:\/\/www.kaggle.com\/rakhlin\/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = label(x > cutoff)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)","2a25c801":"# Upsample Y_hat back to the original X_test size (height and width)\nY_hat_upsampled = []\nfor i, test_id in enumerate(os.listdir(TEST_PATH)):  #loop through test_ids in the test_path\n    img = skimage.io.imread('{0}\/{1}\/images\/{1}.png'.format(TEST_PATH, test_id))  #read original test image directly from path\n    img_upscaled = skimage.transform.resize(Y_hat[i], (img.shape[0], img.shape[1]), mode='constant', preserve_range=True)  #upscale Y_hat image according to original test image\n    Y_hat_upsampled.append(img_upscaled)   #append upscaled image to Y_hat_upsampled\nlen(Y_hat_upsampled)","8b8f2cae":"# Apply Run-Length Encoding on our Y_hat_upscaled\nnew_test_ids = []\nrles = []\nfor n, id_ in enumerate(os.listdir(TEST_PATH)):\n    rle = list(prob_to_rles(Y_hat_upsampled[n]))\n    rles.extend(rle)\n    new_test_ids.extend([id_] * len(rle))\nlen(new_test_ids)  #note that for each test_image, we can have multiple entries of encoded pixels","41aec1b5":"# Create submission DataFrame\nsub = pd.DataFrame()\nsub['ImageId'] = new_test_ids\nsub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\nsub.to_csv('submission.csv', index=False)","648efe75":"sub.head()","e238238f":"len(sub)","33a32fe1":"# Clean Folder\nimport shutil\nshutil.rmtree('train')\nshutil.rmtree('test')","03f4178c":"# 4. Encode and Submit","b78ef9e5":"\u0421\u0432\u0435\u0440\u044f\u0435\u043c \u043f\u043e \u043f\u0430\u043f\u043a\u0430\u043c","9b963df6":"\u0421\u043c\u043e\u0442\u0440\u0438\u0442\u044c\u0441\u044f \u0445\u043e\u0440\u043e\u0448\u043e","c8b52ba6":"\u0412\u043e\u0442 \u0432\u0441\u0435 \u0438 \u0432\u0441\u0442\u0430\u043b\u043e \u043d\u0430 \u0441\u0432\u043e\u0438 \u043c\u0435\u0441\u0442\u0430, \u0418\u0442\u043e\u0433\u043e 65 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043d\u0430 \u0442\u0435\u0441\u0442\u0435 \u0438 670 \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435.  \n\u0414\u0430\u0432\u0430\u0439 \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043c \u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u044d\u0442\u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438","7eaf217f":"# 3. Make predictions","966d7bb9":"\u041e\u0441\u0442\u0430\u043b\u043e\u0441\u044c \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043d\u0430\u0448\u0443 \u043c\u0430\u0441\u043a\u0443","d5f9414f":"# 2. Build model","3352e7b6":"\u0432 \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0438 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043e \u0447\u0442\u043e \"\u041a\u0430\u0436\u0434\u0430\u044f \u043c\u0430\u0441\u043a\u0430 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u043e\u0434\u043d\u043e \u044f\u0434\u0440\u043e.\"  \n\u0410 \u0438\u0437 \u0432\u0441\u0435\u0445 29\u043a \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432, \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0443 \u043d\u0430\u0441 \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 \u043d\u0430 \u0441\u0430\u043c\u043e\u043c \u0434\u0435\u043b\u0435?","af411dca":"\u0413\u043e\u0442\u043e\u0432\u043e!\n\n## \u0427\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c, \u0447\u0442\u043e\u0431 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442:\n* \u041f\u043e\u0434\u043e\u0431\u0440\u0430\u0442\u044c LR, optimizer, loss\n* \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0441\u0432\u043e\u044e \u043c\u0435\u0442\u0440\u0438\u043a\u0443 (\u0434\u043b\u044f \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 loss \u043d\u0435 \u043b\u0443\u0447\u0448\u0430\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0430) \u0438 callbacks \u043f\u043e \u043d\u0435\u0439\n* \u041f\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u0438 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u0442\u044c Threshold \u0434\u043b\u044f predictions\n* \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e\n* \u041f\u043e\u0438\u0433\u0440\u0430\u0442\u044c\u0441\u044f \u0441 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u043e\u0439\n* \u041f\u043e\u0434\u043e\u0431\u0440\u0430\u0442\u044c \u0434\u0440\u0443\u0433\u0438\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 (\u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438, \u0431\u0430\u0442\u0447 \u0438 \u0442\u043f)\n* \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u043f\u043e\u043b\u0438\u0442\u0438\u043a\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\n* \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c TTA\n* \u041d\u0430\u0439\u0442\u0438 \u0438 \u043e\u0431\u0443\u0447\u0438\u0442\u044c\u0441\u044f \u043d\u0430 \u0434\u0440\u0443\u0433\u0438\u0445 \u0432\u043d\u0435\u0448\u043d\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n* \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u044c \u0438\u0437 \u0440\u0430\u0437\u043d\u044b\u0445 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\n\n\u0423\u0434\u0430\u0447\u0438 \u0432 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438!","41d6c399":"# 0. Intro\n### \u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f: \u0414\u0435\u043b\u0430\u0435\u043c \u0440\u0435\u0448\u0435\u043d\u0438\u0435 \u043d\u0430 \u0431\u0430\u0437\u0435 U-Net","29241196":"\u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0433\u043b\u044f\u043d\u0435\u043c csv","48744d09":"# SETUP","5b62ca56":"![](https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/dsb-2018\/dsb.jpg)","f78d2c54":"\u043c\u044b \u0440\u0435\u0441\u0430\u0439\u0437\u0438\u043b\u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0443 \u0434\u043e 256\u0445256, \u043d\u043e \u0447\u0442\u043e\u0431 \u0432\u0435\u0440\u043d\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043c\u0430\u0441\u043a\u0443 \u043f\u043e\u0434 \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0439 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438","25896f9a":"> \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c U-Net model, \u043f\u043e \u043c\u043e\u0442\u0438\u0432\u0430\u043c [U-Net: Convolutional Networks for Biomedical Image Segmentation](https:\/\/arxiv.org\/pdf\/1505.04597.pdf) \u0438 \u0431\u043b\u0438\u0437\u043a\u043e \u043a \u044d\u0442\u043e\u043c\u0443 [\u0440\u0435\u043f\u043e\u0437\u0438\u0442\u043e\u0440\u0438\u044e](https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation) \u0438\u0437 Kaggle Ultrasound Nerve Segmentation competition.\n\n![](https:\/\/lmb.informatik.uni-freiburg.de\/people\/ronneber\/u-net\/u-net-architecture.png)","9b608f68":"\u041d\u0435 \u043a\u0430\u0436\u0435\u0442\u044c\u0441\u044f \u0441\u0442\u0440\u0430\u043d\u043d\u044b\u043c, \u0447\u0442\u043e \u043d\u0430\u043c \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u044e\u0442 \u043d\u0430 \u0442\u0435\u0441\u0442 \u0442\u043e\u043b\u044c\u043a\u043e 65 \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a? )  \n\u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0447\u0442\u043e \u0432 \u0442\u0440\u0435\u0439\u043d\u0435...","df84be1f":"# 1. Load Data\n\u0440\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435"}}