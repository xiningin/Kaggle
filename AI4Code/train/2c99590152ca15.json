{"cell_type":{"bba6a9d2":"code","ef3e6a15":"code","c60504ec":"code","b5941e56":"code","406c0de8":"code","7688710d":"code","b35f8322":"code","36c5b686":"code","6d6e1a78":"code","beef1068":"code","183b3140":"code","d4ed7905":"code","7f6d99ce":"code","dfa61a29":"code","eafc09f0":"code","0b117e2d":"code","44fee56b":"code","16f18125":"code","77ac01de":"code","5fce0f42":"code","e3c1aabd":"code","c6a95321":"code","2d673581":"code","2e89c6db":"code","6965cf7c":"code","b8e95c54":"code","50dac0e3":"code","f33dab26":"code","59c3458a":"code","8e7bfcaa":"code","c7d1ec10":"code","234050fa":"code","99aec4f8":"code","c2ed7ea1":"code","17e9c96a":"code","b7b3d10a":"code","2c2e9291":"code","aafdf567":"code","a780c034":"code","78efb280":"code","85635612":"code","a3b38f8c":"code","6ba59fb8":"code","13ef71e6":"code","591d0498":"code","cc678230":"code","c5a013df":"code","e12fdd49":"code","2d13e863":"code","1efa7317":"code","9cb8d7d2":"code","13287f9e":"code","73788237":"code","e6902452":"code","8d847b3f":"code","0d91cdb6":"code","7563a37f":"code","d0b36a7d":"code","cd19c26c":"code","6ca89f3b":"code","499f5dc5":"code","f7fc433c":"code","ba61de31":"code","b233bf68":"code","a4e97c7d":"code","a44cfd32":"code","a86c33c2":"code","e6d43991":"code","a49ddc41":"code","5d96ea04":"code","da50cc4c":"code","3ee4ee46":"code","1c7176d3":"code","f7eb88f8":"code","5ff5e763":"code","5496ba48":"code","75a852e7":"code","e842a1bc":"code","66f4a360":"code","f97acb1c":"code","77440c64":"code","49c52fb3":"code","8c05f42e":"code","42e17f02":"code","542b4e5c":"code","eb8db40d":"code","5359c8f3":"code","7d469a25":"code","4fc0c531":"code","32c86b60":"code","4cc9c856":"code","6112cc68":"code","6c6be57b":"code","0269f7ae":"code","0861b0dd":"code","3ec7e04d":"markdown","b0a04a42":"markdown","580a75d4":"markdown","cec333eb":"markdown","3ee94956":"markdown","4eb6b693":"markdown","8accc114":"markdown","9cc1abfe":"markdown","ab8d9ae3":"markdown","df234d4a":"markdown","b40d8329":"markdown","9c12336a":"markdown","996ac4eb":"markdown","ebe6450d":"markdown","6171fa91":"markdown","0ace2c09":"markdown","35a1ccb7":"markdown","85130b7c":"markdown","3fb7b7b1":"markdown","2e49ae8e":"markdown","d3b7d6b2":"markdown","a6747e8d":"markdown","a383c221":"markdown","e0f8ea19":"markdown","8ebd2372":"markdown","bdc7cb66":"markdown","2e862867":"markdown","9c0dc880":"markdown","2b68f9a5":"markdown","9406531d":"markdown","4e34f8ab":"markdown","bbdd2328":"markdown","af58221e":"markdown","8f18be1c":"markdown","f4831e1d":"markdown","e809c37e":"markdown","86b2a5ea":"markdown","cbcd9e82":"markdown","afa9ba18":"markdown","72db00f0":"markdown","aaec2c2f":"markdown","105c027b":"markdown","4e482ddb":"markdown","90eda5e2":"markdown","8d9a9760":"markdown","f11d02a5":"markdown","59307c87":"markdown","6bdaac07":"markdown","eddffd92":"markdown","69e19944":"markdown","c54c9585":"markdown","589b5cbf":"markdown","d1942441":"markdown","22c662bf":"markdown","3e388620":"markdown"},"source":{"bba6a9d2":"import sys\nassert sys.version_info >= (3, 5)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport math \nimport itertools\nimport matplotlib.pyplot as plt\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\nimport os\nnp.random.seed(42)\n\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"classification\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\nos.makedirs(IMAGES_PATH, exist_ok=True)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)\n    import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, LinearRegression,Ridge,Lasso,RidgeCV, ElasticNet\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC, SVR\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier, RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\nfrom sklearn.neural_network import MLPRegressor\n\n#from sklearn.preprocessing import Imputer , Normalizer , scale , MinMaxScaler , StandardScaler, Imputer, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV , KFold , cross_val_score\nfrom sklearn.metrics import confusion_matrix, classification_report, mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error, accuracy_score,precision_score,recall_score,f1_score\nfrom sklearn.feature_selection import RFECV\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n#from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n#from keras.utils import to_categorical\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport missingno as msno\n\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)","ef3e6a15":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","c60504ec":"train = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\ndf = train.copy()\ndf_test = test.copy()","b5941e56":"train.info()","406c0de8":"test.info","7688710d":"train.head(5)","b35f8322":"test.head(5)","36c5b686":"train.tail()","6d6e1a78":"test.tail()","beef1068":"train.shape","183b3140":"test.shape","d4ed7905":"train.describe().T","7f6d99ce":"test.describe().T","dfa61a29":"train.isna().sum()","eafc09f0":"test.isna().sum()","0b117e2d":"train.corr()","44fee56b":"test.corr()","16f18125":"X_train = train.drop([\"label\"], axis=1).values\ny_train = train.label.values\nX_test = test.drop([\"label\"], axis=1).values\ny_test = test.label.values","77ac01de":"print(\"X_train shape --> \",X_train.shape)\nprint(\"y_train shape --> \",y_train.shape)\nprint(\"X_test shape --> \",X_test.shape)\nprint(\"y_test shape --> \",y_test.shape)","5fce0f42":"%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = X_train[3]\nsome_digit_image = some_digit.reshape(28, 28)\nplt.imshow(some_digit_image, cmap=mpl.cm.binary)\nplt.axis(\"off\")\n\nsave_fig(\"some_digit_plot\")\nplt.show()","e3c1aabd":"y_train[3]","c6a95321":"y_train = y_train.astype(np.uint8)","2d673581":"def plot_digit(data):\n    image = data.reshape(28, 28)\n    plt.imshow(image, cmap = mpl.cm.binary,\n               interpolation=\"nearest\")\n    plt.axis(\"off\")\n    \ndef plot_digits(instances, images_per_row=10, **options):\n    size = 28\n    images_per_row = min(len(instances), images_per_row)\n    images = [instance.reshape(size,size) for instance in instances]\n    n_rows = (len(instances) - 1) \/\/ images_per_row + 1\n    row_images = []\n    n_empty = n_rows * images_per_row - len(instances)\n    images.append(np.zeros((size, size * n_empty)))\n    for row in range(n_rows):\n        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n        row_images.append(np.concatenate(rimages, axis=1))\n    image = np.concatenate(row_images, axis=0)\n    plt.imshow(image, cmap = mpl.cm.binary, **options)\n    plt.axis(\"off\")\n    plt.figure(figsize=(40,40))\nexample_images = X_train[:100]\nplot_digits(example_images, images_per_row=10)\nsave_fig(\"more_digits_plot\")\nplt.show()","2e89c6db":"y_train_0 = (y_train == 0) \ny_test_0 = (y_test == 0 )","6965cf7c":"from sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\nsgd_clf.fit(X_train, y_train_0)","b8e95c54":"sgd_clf.predict([some_digit])","50dac0e3":"from sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, X_train, y_train_0, cv=3, scoring=\"accuracy\")","f33dab26":"from sklearn.base import BaseEstimator\nclass Never0Classifier(BaseEstimator):\n    def fit(self, X, y=None):\n        pass\n    def predict(self, X):\n        return np.zeros((len(X), 1), dtype=bool)","59c3458a":"never_0_clf = Never0Classifier()\ncross_val_score(never_0_clf, X_train, y_train_0, cv=3, scoring=\"accuracy\")","8e7bfcaa":"from sklearn.model_selection import cross_val_predict\n\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_0, cv=3)","c7d1ec10":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_train_0, y_train_pred)","234050fa":"y_train_perfect_predictions = y_train_0  \nconfusion_matrix(y_train_0, y_train_perfect_predictions)","99aec4f8":"from sklearn.metrics import precision_score, recall_score\n\nprecision_score(y_train_0, y_train_pred)","c2ed7ea1":"recall_score(y_train_0, y_train_pred)","17e9c96a":"from sklearn.metrics import f1_score\n\nf1_score(y_train_0, y_train_pred)","b7b3d10a":"y_scores = sgd_clf.decision_function([some_digit])\ny_scores","2c2e9291":"threshold = 0\ny_some_digit_pred = (y_scores > threshold)\ny_some_digit_pred","aafdf567":"threshold = 8000\ny_some_digit_pred = (y_scores > threshold)\ny_some_digit_pred","a780c034":"y_scores = cross_val_predict(sgd_clf, X_train, y_train_0, cv=3,\n                             method=\"decision_function\")","78efb280":"from sklearn.metrics import precision_recall_curve\n\nprecisions, recalls, thresholds = precision_recall_curve(y_train_0, y_scores)","85635612":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n    plt.legend(loc=\"center right\", fontsize=16) \n    plt.xlabel(\"Threshold\", fontsize=16)        \n    plt.grid(True)                              \n    plt.axis([-50000, 50000, 0, 1])             \n\n\n\nrecall_90_precision = recalls[np.argmax(precisions >= 0.90)]\nthreshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n\n\nplt.figure(figsize=(8, 4))                                                                 \nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \nplt.plot([-50000, threshold_90_precision], [0.9, 0.9], \"r:\")                                \nplt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\nplt.plot([threshold_90_precision], [0.9], \"ro\")                                            \nplt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                             \nsave_fig(\"precision_recall_vs_threshold_plot\")                                              \nplt.show()","a3b38f8c":"def plot_precision_vs_recall(precisions, recalls):\n    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n    plt.xlabel(\"Recall\", fontsize=16)\n    plt.ylabel(\"Precision\", fontsize=16)\n    plt.axis([0, 1, 0, 1])\n    plt.grid(True)\n\nplt.figure(figsize=(8, 6))\nplot_precision_vs_recall(precisions, recalls)\n\nplt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\nplt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\nplt.plot([recall_90_precision], [0.9], \"ro\")\nsave_fig(\"precision_vs_recall_plot\")\nplt.show()","6ba59fb8":"threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\nthreshold_90_precision","13ef71e6":"y_train_pred_90 = (y_scores >= threshold_90_precision)","591d0498":"precision_score(y_train_0, y_train_pred_90)","cc678230":"recall_score(y_train_0, y_train_pred_90)","c5a013df":"from sklearn.metrics import roc_curve   #\u00e7e\u015fitli e\u015fik de\u011ferleri i\u00e7in TPR ve FPR'yi hesaplamak roc_curve() komutunu kullan\u0131yoruz\n\nfpr, tpr, thresholds = roc_curve(y_train_0, y_scores)","e12fdd49":"def plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') \n    plt.axis([0, 1, 0, 1])                                    \n    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    \n    plt.grid(True)                                            \n\nplt.figure(figsize=(8, 6))                                    \nplot_roc_curve(fpr, tpr)\nfpr_90 = fpr[np.argmax(tpr >= recall_90_precision)]           \nplt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")   \nplt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")  \nplt.plot([fpr_90], [recall_90_precision], \"ro\")               \nsave_fig(\"roc_curve_plot\")                                    \nplt.show()","2d13e863":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_train_0, y_scores)","1efa7317":"from sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\ny_probas_forest = cross_val_predict(forest_clf, X_train, y_train_0, cv=3,\n                                    method=\"predict_proba\")","9cb8d7d2":"y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_0,y_scores_forest)","13287f9e":"recall_for_forest = tpr_forest[np.argmax(fpr_forest >= fpr_90)]\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD\")\nplot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\nplt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\nplt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\nplt.plot([fpr_90], [recall_90_precision], \"ro\")\nplt.plot([fpr_90, fpr_90], [0., recall_for_forest], \"r:\")\nplt.plot([fpr_90], [recall_for_forest], \"ro\")\nplt.grid(True)\nplt.legend(loc=\"lower right\", fontsize=16)\nsave_fig(\"roc_curve_comparison_plot\")\nplt.show()","73788237":"roc_auc_score(y_train_0, y_scores_forest)","e6902452":"y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_0, cv=3)\nprecision_score(y_train_0, y_train_pred_forest)","8d847b3f":"recall_score(y_train_0, y_train_pred_forest)","0d91cdb6":"from sklearn.svm import SVC\n\nsvm_clf = SVC(gamma=\"auto\", random_state=42)\nsvm_clf.fit(X_train[:1000], y_train[:1000]) # y_train, not y_train_5\nsvm_clf.predict([some_digit])","7563a37f":"some_digit_scores = svm_clf.decision_function([some_digit])\nsome_digit_scores","d0b36a7d":"np.argmax(some_digit_scores)","cd19c26c":"svm_clf.classes_","6ca89f3b":"svm_clf.classes_[0]","499f5dc5":"from sklearn.multiclass import OneVsRestClassifier\novr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\novr_clf.fit(X_train[:1000], y_train[:1000])\novr_clf.predict([some_digit])","f7fc433c":"len(ovr_clf.estimators_)","ba61de31":"sgd_clf.fit(X_train, y_train)\nsgd_clf.predict([some_digit])","b233bf68":"sgd_clf.decision_function([some_digit])","a4e97c7d":"cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")","a44cfd32":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\ncross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")","a86c33c2":"y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\nconf_mx = confusion_matrix(y_train, y_train_pred)\nconf_mx","e6d43991":"plt.matshow(conf_mx, cmap=plt.cm.gray)\nsave_fig(\"confusion_matrix_plot\", tight_layout=False)\nplt.show()","a49ddc41":"row_sums = conf_mx.sum(axis=1, keepdims=True)\nnorm_conf_mx = conf_mx \/ row_sums","5d96ea04":"np.fill_diagonal(norm_conf_mx, 0)  #Yaln\u0131zca hatalar\u0131 tutmak i\u00e7in k\u00f6\u015fegeni s\u0131f\u0131rlarla dolduruyoruz\nplt.matshow(norm_conf_mx, cmap=plt.cm.gray)\nsave_fig(\"confusion_matrix_errors_plot\", tight_layout=False)\nplt.show()","da50cc4c":"cl_a, cl_b = 4, 6\nX_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\nX_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\nX_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\nX_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n\nplt.figure(figsize=(8,8))\nplt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\nplt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\nplt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\nplt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\nsave_fig(\"error_analysis_digits_plot\")\nplt.show()","3ee4ee46":"from sklearn.neighbors import KNeighborsClassifier\n\ny_train_large = (y_train >= 7)\ny_train_odd = (y_train % 2 == 1)\ny_multilabel = np.c_[y_train_large, y_train_odd]\n\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(X_train, y_multilabel)","1c7176d3":"knn_clf.predict([some_digit])","f7eb88f8":"y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\nf1_score(y_multilabel, y_train_knn_pred, average=\"macro\")","5ff5e763":"noise = np.random.randint(0, 100, (len(X_train), 784))\nX_train_mod = X_train + noise\nnoise = np.random.randint(0, 100, (len(X_test), 784))\nX_test_mod = X_test + noise\ny_train_mod = X_train\ny_test_mod = X_test","5496ba48":"some_index = 0\nplt.subplot(121); plot_digit(X_test_mod[some_index])\nplt.subplot(122); plot_digit(y_test_mod[some_index])\nsave_fig(\"noisy_digit_example_plot\")\nplt.show()","75a852e7":"knn_clf.fit(X_train_mod, y_train_mod)\nclean_digit = knn_clf.predict([X_test_mod[some_index]])\nplot_digit(clean_digit)\nsave_fig(\"cleaned_digit_example_plot\")","e842a1bc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import confusion_matrix","66f4a360":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","f97acb1c":"train_csv = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest_csv = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")","77440c64":"class FashionDataset(Dataset):\n    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n    \n    def __init__(self, data, transform = None):\n        \"\"\"Method to initilaize variables.\"\"\" \n        self.fashion_MNIST = list(data.values)\n        self.transform = transform\n        \n        label = []\n        image = []\n        \n        for i in self.fashion_MNIST:        \n            label.append(i[0])\n            image.append(i[1:])\n        self.labels = np.asarray(label)\n        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n\n    def __getitem__(self, index):\n        label = self.labels[index]\n        image = self.images[index]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.images)","49c52fb3":"train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\ntest_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n\ntrain_loader = DataLoader(train_set, batch_size=100)\ntest_loader = DataLoader(train_set, batch_size=100)","8c05f42e":"\"\"\"\ntrain_set = torchvision.datasets.FashionMNIST(\".\/data\", download=True, transform=\n                                                transforms.Compose([transforms.ToTensor()]))\ntest_set = torchvision.datasets.FashionMNIST(\".\/data\", download=True, train=False, transform=\n                                               transforms.Compose([transforms.ToTensor()]))  \n\"\"\" ","42e17f02":"\"\"\"\ntrain_loader = torch.utils.data.DataLoader(train_set, \n                                           batch_size=100)\ntest_loader = torch.utils.data.DataLoader(test_set,\n                                          batch_size=100)\n\"\"\"      ","542b4e5c":"def output_label(label):\n    output_mapping = {\n                 0: \"T-shirt\/Top\",\n                 1: \"Trouser\",\n                 2: \"Pullover\",\n                 3: \"Dress\",\n                 4: \"Coat\", \n                 5: \"Sandal\", \n                 6: \"Shirt\",\n                 7: \"Sneaker\",\n                 8: \"Bag\",\n                 9: \"Ankle Boot\"\n                 }\n    input = (label.item() if type(label) == torch.Tensor else label)\n    return output_mapping[input]","eb8db40d":"a = next(iter(train_loader))\na[0].size()","5359c8f3":"len(train_set)","7d469a25":"image, label = next(iter(train_set))\nplt.imshow(image.squeeze(), cmap=\"gray\")\nprint(label)","4fc0c531":"demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n\nbatch = next(iter(demo_loader))\nimages, labels = batch\nprint(type(images), type(labels))\nprint(images.shape, labels.shape)","32c86b60":"grid = torchvision.utils.make_grid(images, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)))\nprint(\"labels: \", end=\" \")\nfor i, label in enumerate(labels):\n    print(output_label(label), end=\", \")","4cc9c856":"class FashionCNN(nn.Module):\n    \n    def __init__(self):\n        super(FashionCNN, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n        self.drop = nn.Dropout2d(0.25)\n        self.fc2 = nn.Linear(in_features=600, out_features=120)\n        self.fc3 = nn.Linear(in_features=120, out_features=10)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        \n        return out","6112cc68":"model = FashionCNN()\nmodel.to(device)\n\nerror = nn.CrossEntropyLoss()\n\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(model)","6c6be57b":"num_epochs = 5\ncount = 0\n \nloss_list = []\niteration_list = []\naccuracy_list = []\n\npredictions_list = []\nlabels_list = []\n\nfor epoch in range(num_epochs):\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n    \n        train = Variable(images.view(100, 1, 28, 28))\n        labels = Variable(labels)     \n        outputs = model(train)\n        loss = error(outputs, labels)\n            \n        optimizer.zero_grad()     \n        loss.backward()        \n        optimizer.step()\n        count += 1\n    \n    \n    \n        if not (count % 50): \n            total = 0\n            correct = 0\n        \n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n                labels_list.append(labels)\n            \n                test = Variable(images.view(100, 1, 28, 28))\n            \n                outputs = model(test)\n            \n                predictions = torch.max(outputs, 1)[1].to(device)\n                predictions_list.append(predictions)\n                correct += (predictions == labels).sum()\n            \n                total += len(labels)\n            \n            accuracy = correct * 100 \/ total\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        \n        if not (count % 500):\n            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))","0269f7ae":"plt.plot(iteration_list, loss_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Iterations vs Loss\")\nplt.show()","0861b0dd":"plt.plot(iteration_list, accuracy_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Iterations vs Accuracy\")\nplt.show()","3ec7e04d":"S\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n yapt\u0131\u011f\u0131 hata t\u00fcrlerini a\u00e7\u0131k\u00e7a g\u00f6rebiliriz. Sat\u0131rlar ger\u00e7ek s\u0131n\u0131flar\u0131, s\u00fctunlar ise tahmin edilen s\u0131n\u0131flar\u0131 temsil eder. 6. s\u0131n\u0131f s\u00fctunu olduk\u00e7a parlak, bu da size bir\u00e7ok g\u00f6r\u00fcnt\u00fcn\u00fcn yanl\u0131\u015f 6'lar olarak s\u0131n\u0131fland\u0131r\u0131ld\u0131\u011f\u0131n\u0131 s\u00f6yl\u00fcyor. Ayr\u0131ca en \u00e7ok kar\u0131\u015ft\u0131r\u0131lanlar\u0131n 4 ve 6 oldu\u011funu s\u00f6ylebiliriz","b0a04a42":"En y\u00fcksek puan\u0131n ger\u00e7ekten de 0. s\u0131n\u0131fa kar\u015f\u0131l\u0131k gelen puan oldu\u011funu g\u00f6r\u00fcyoruz:","580a75d4":"### <span style=\"color:green\"> Precision ve Recall (Kesinlik ve Hassasiyet) <span>","cec333eb":"## Accuracy\nBir s\u0131n\u0131fland\u0131rma modelinin do\u011fru oldu\u011fu tahminlerinin oran\u0131. \u00c7ok s\u0131n\u0131fl\u0131 s\u0131n\u0131fland\u0131rmada do\u011fruluk(accuracy) \u015fu \u015fekilde tan\u0131mlan\u0131r:\nVeri bilimi projelerinde en do\u011fru modelin hangisi olmas\u0131 gerekti\u011fine karar vermek i\u00e7in i\u015f birimlerinden gelen talepleri iyi de\u011ferlendirmemiz gereklidir. Proje \u00e7\u0131kt\u0131lar\u0131m\u0131zda sadece Do\u011fruluk (Accuracy) \u00fczerinden model se\u00e7imi yaparsak , yaln\u0131zca bu metri\u011fe bakmamam\u0131z gerekti\u011fini i\u015f sonu\u00e7lar\u0131nda ac\u0131 tecr\u00fcbelerle g\u00f6rebiliriz.\n\nAccuracy = Do\u011fru tahminler \/ Toplam \u00f6rnek say\u0131s\u0131\n\n\u0130kili s\u0131n\u0131fland\u0131rmada do\u011fruluk a\u015fa\u011f\u0131daki tan\u0131ma sahiptir:\n\nAccuracy = Do\u011fru pozitifler + Do\u011fru negatifler \/ Toplam \u00f6rnek say\u0131s\u0131","3ee94956":"\u015eimdi bir RandomForestClassifier e\u011fitelim ve ROC e\u011frisini ve ROC AUC puan\u0131n\u0131 SGDClassifier'\u0131nkilerle kar\u015f\u0131la\u015ft\u0131ral\u0131m. \u0130lk olarak, e\u011fitim setindeki her bir \u00f6rnek i\u00e7in puan alman\u0131z gerekir. predict_proba() y\u00f6ntemi, \u00f6rnek ba\u015f\u0131na bir sat\u0131r ve s\u0131n\u0131f ba\u015f\u0131na bir s\u00fctun i\u00e7eren ve her biri verilen \u00f6rne\u011fin belirli bir s\u0131n\u0131fa ait olma olas\u0131l\u0131\u011f\u0131n\u0131 i\u00e7eren bir dizi d\u00f6nd\u00fcr\u00fcr (\u00f6rne\u011fin, g\u00f6r\u00fcnt\u00fcn\u00fcn bir ti\u015f\u00f6rt\u00fc temsil etme olas\u0131l\u0131\u011f\u0131 %70 gibi)","4eb6b693":"Bu sefer Scikit-Learn'in OvR veya OvO'yu \u00e7al\u0131\u015ft\u0131rmas\u0131 gerekmedi \u00e7\u00fcnk\u00fc SGD s\u0131n\u0131fland\u0131r\u0131c\u0131lar\u0131 \u00f6rnekleri do\u011frudan birden \u00e7ok s\u0131n\u0131fa s\u0131n\u0131fland\u0131rabilir. decision_function() y\u00f6ntemi art\u0131k s\u0131n\u0131f ba\u015f\u0131na bir de\u011fer d\u00f6nd\u00fcr\u00fcr. SGD s\u0131n\u0131fland\u0131r\u0131c\u0131s\u0131n\u0131n her s\u0131n\u0131fa atad\u0131\u011f\u0131 puana bakal\u0131m:","8accc114":"Son olarak, kesinli\u011fi \u00e7izmek ve e\u015fik de\u011ferinin i\u015flevleri olarak hassasiyet i\u00e7in Matplotlib'i kullanal\u0131m:","9cc1abfe":"Hedefe yak\u0131n diyebiliriz.","ab8d9ae3":"Skor olarak pozitif s\u0131n\u0131f\u0131n olas\u0131l\u0131\u011f\u0131n\u0131 kullanal\u0131m:","df234d4a":"Bu, e\u015fi\u011fi y\u00fckseltmenin hassasiyeti azaltt\u0131\u011f\u0131n\u0131 do\u011frular. G\u00f6r\u00fcnt\u00fc asl\u0131nda bir ti\u015f\u00f6rt\u00fc temsil eder ve s\u0131n\u0131fland\u0131r\u0131c\u0131, e\u015fik 0 oldu\u011funda bunu alg\u0131lar, ancak e\u015fik 8.000'e y\u00fckseltildi\u011finde onu ka\u00e7\u0131r\u0131r.\n\nPeki hangi e\u015fi\u011fi kullanaca\u011f\u0131m\u0131za nas\u0131l karar verece\u011fiz? \u0130lk olarak, e\u011fitim k\u00fcmesindeki t\u00fcm \u00f6rneklerin puanlar\u0131n\u0131 almak i\u00e7in cross_val_predict() i\u015flevini kullanal\u0131m, ancak bu sefer tahminler yerine karar puanlar\u0131n\u0131 d\u00f6nd\u00fcrmek istedi\u011fimizi belirtelim:\n\nBu puanlarla, kesinli\u011fi hesaplamak ve olas\u0131 t\u00fcm e\u015fiklerdeki hassasiyet i\u00e7in exact_recall_curve() i\u015flevini kullanal\u0131m:","b40d8329":"Bu kar\u0131\u015f\u0131kl\u0131k matrisi olduk\u00e7a iyi g\u00f6r\u00fcn\u00fcyor, \u00e7\u00fcnk\u00fc \u00e7o\u011fu g\u00f6r\u00fcnt\u00fc ana k\u00f6\u015fegende, yani do\u011fru s\u0131n\u0131fland\u0131r\u0131lm\u0131\u015flar.\n\nKar\u0131\u015f\u0131kl\u0131k matrisindeki her bir de\u011feri, ilgili s\u0131n\u0131ftaki g\u00f6r\u00fcnt\u00fc say\u0131s\u0131na b\u00f6lelim, b\u00f6ylece mutlak hata say\u0131lar\u0131 yerine hata oranlar\u0131n\u0131 kar\u015f\u0131la\u015ft\u0131rabiliriz:","9c12336a":"# <span style=\"color:red\"> \u00c7ok Etiketli S\u0131n\u0131fland\u0131rma (Multilabel Classification) <span>\n\u015eimdiye kadar her bir \u00f6rnek her zaman sadece bir s\u0131n\u0131fa atanm\u0131\u015ft\u0131r. Baz\u0131 durumlarda, s\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131z\u0131n her bir \u00f6rnek i\u00e7in birden \u00e7ok s\u0131n\u0131f \u00e7\u0131kt\u0131s\u0131n\u0131 almas\u0131n\u0131 isteyebilirsiniz. B\u00f6yle durumlarda \u00e7ok etiketli s\u0131n\u0131fland\u0131rma kullan\u0131l\u0131r(\u00f6rne\u011fin y\u00fcz tan\u0131ma).","996ac4eb":"## <span style=\"color:blue\"> Etiketler(Labels) <span>\n\nHer e\u011fitim ve test \u00f6rne\u011fi, a\u015fa\u011f\u0131daki etiketlerden birine atan\u0131r:\n\n- 0 T-shirt\/top(Ti\u015f\u00f6rt\/\u00fcst)\n- 1 Trouser (Pantolon)\n- 2 Pullover (kazak)\n- 3 Dress (Elbise)\n- 4 Coat (Ceket)\n- 5 Sandal (sandalet)\n- 6 Shirt (g\u00f6mlek)\n- 7 Sneaker (Spor Ayakkab\u0131)\n- 8 Bag (\u00c7anta)\n- 9 Ankle boot (Ayak bile\u011fi botu)","ebe6450d":"Her g\u00f6r\u00fcnt\u00fc 28 piksel y\u00fcksekli\u011finde ve 28 piksel geni\u015fli\u011finde olup, toplamda 784 pikseldir. Her pikselin kendisiyle ili\u015fkilendirilmi\u015f, o pikselin a\u00e7\u0131kl\u0131\u011f\u0131n\u0131 veya koyulu\u011funu g\u00f6steren tek bir piksel de\u011feri vard\u0131r ve daha y\u00fcksek say\u0131lar daha koyu anlam\u0131na gelir. Bu piksel de\u011feri, 0 ile 255 aras\u0131nda bir tamsay\u0131d\u0131r. E\u011fitim ve test veri setlerinde 785 s\u00fctun bulunur. \u0130lk s\u00fctun s\u0131n\u0131f etiketlerinden olu\u015fur ve giyim e\u015fyas\u0131n\u0131 temsil eder. S\u00fctunlar\u0131n geri kalan\u0131, ili\u015fkili g\u00f6r\u00fcnt\u00fcn\u00fcn piksel de\u011ferlerini i\u00e7erir.","6171fa91":"T\u00fcm \u00e7apraz do\u011frulama k\u0131vr\u0131mlar\u0131nda %94'\u00fcn \u00fczerinde do\u011fruluk tahmin oran\u0131 \u00e7ok iyi bir sonu\u00e7. Heyecanlanmadan \u00f6nce \"not-0\" s\u0131n\u0131f\u0131ndaki her bir g\u00f6r\u00fcnt\u00fcy\u00fc s\u0131n\u0131fland\u0131ran bir s\u0131n\u0131fland\u0131r\u0131c\u0131ya bakal\u0131m:","0ace2c09":"G\u00f6r\u00fcnt\u00fcde bir ti\u015f\u00f6rt g\u00f6r\u00fcn\u00fcyor ve etiketine bakt\u0131\u011f\u0131m\u0131zda do\u011fru olarak e\u015fle\u015ftirildi\u011fini g\u00f6r\u00fcyoruz.Labelin bir string oldu\u011funu unutmayal\u0131m. \u00c7o\u011fu ML algoritmas\u0131 say\u0131 bekler, bu y\u00fczden y'yi tam say\u0131ya \u00e7evirelim:","35a1ccb7":"RandomForestClassifier'\u0131n ROC e\u011frisi, SGDClassifier'\u0131nkinden \u00e7ok daha iyi g\u00f6r\u00fcn\u00fcyor: sol \u00fcst k\u00f6\u015feye \u00e7ok daha yak\u0131n geliyor. Sonu\u00e7 olarak, ROC AUC puan\u0131 da \u00f6nemli \u00f6l\u00e7\u00fcde daha iyi:","85130b7c":"Do\u011fru \u00e7al\u0131\u015ft\u0131. 0 rakam\u0131 7 den b\u00fcy\u00fck ve tek say\u0131 de\u011fil.\n\n\u00c7ok etiketli bir s\u0131n\u0131fland\u0131r\u0131c\u0131y\u0131 de\u011ferlendirmenin ve do\u011fru metri\u011fi se\u00e7mek i\u00e7in, her bir etiket (veya daha \u00f6nce tart\u0131\u015f\u0131lan herhangi bir ikili s\u0131n\u0131fland\u0131r\u0131c\u0131 metri\u011fi) i\u00e7in F1 puan\u0131n\u0131 \u00f6l\u00e7\u00fcp, ard\u0131ndan ortalama puan\u0131 hesaplayabiliriz. A\u015fa\u011f\u0131daki kod, t\u00fcm etiketlerdeki ortalama F1 puan\u0131n\u0131 hesaplar:","3fb7b7b1":"## <span style=\"color:blue\"> ROC E\u011frisi <span>\nROC e\u011frisi, ikili s\u0131n\u0131fland\u0131r\u0131c\u0131larla birlikte kullan\u0131lan yayg\u0131n bir ara\u00e7t\u0131r. Kesinlik\/hassasiyet e\u011frisine \u00e7ok benzer, ancak kesinli\u011fe kar\u015f\u0131 hassasiyeti \u00e7izmek yerine, ROC e\u011frisi yanl\u0131\u015f pozitif oran (FPR) kar\u015f\u0131s\u0131nda ger\u00e7ek pozitif oran\u0131 \u00e7izer.","2e49ae8e":"Kesinlik ve hassasiyet puanlar\u0131na bakt\u0131\u011f\u0131m\u0131zda %86,8 kesinlik ve %78,1 hassasiyet de\u011ferine sahip oldu\u011funu g\u00f6r\u00fcyoruz. Fena de\u011fil diyebiliriz.\n\nArt\u0131k ikili s\u0131n\u0131fland\u0131r\u0131c\u0131lar\u0131 nas\u0131l e\u011fitece\u011fimizi, \u00e7apraz do\u011frulama kullanarak s\u0131n\u0131fland\u0131r\u0131c\u0131lar\u0131m\u0131z\u0131 nas\u0131l de\u011ferlendirece\u011fimizi, ihtiya\u00e7lar\u0131m\u0131za uyan kesinlik\/hassasiyet de\u011fi\u015f toku\u015funu nas\u0131l se\u00e7ece\u011fimizi ve \u00e7e\u015fitli modelleri kar\u015f\u0131la\u015ft\u0131rmak i\u00e7in ROC e\u011frilerini ve ROC AUC puanlar\u0131n\u0131 nas\u0131l kullanaca\u011f\u0131m\u0131z\u0131 biliyoruz. \u015eimdi ti\u015f\u00f6rtlerden daha fazlas\u0131n\u0131 tespit etmeye \u00e7al\u0131\u015fal\u0131m.","d3b7d6b2":"SGDClassifier, 0'a e\u015fit bir e\u015fik kullan\u0131r, bu nedenle \u00f6nceki kod, predict() y\u00f6ntemiyle ayn\u0131 sonucu d\u00f6nd\u00fcr\u00fcr (yani, True). E\u015fi\u011fi y\u00fckseltelim:","a6747e8d":"S\u0131n\u0131fland\u0131r\u0131c\u0131, bu g\u00f6r\u00fcnt\u00fcn\u00fcn bir ti\u015f\u00f6rt\u00fc do\u011fru (True) temsil etti\u011fini tahmin eder. Bu bizim durumumuzda da do\u011fru tahmin edilmi\u015f gibi g\u00f6r\u00fcn\u00fcyor.\u015eimdi bu modelin performans\u0131n\u0131 de\u011ferlendirelim.","a383c221":"E\u011fitim setinde 60000 g\u00f6rsel var ve her g\u00f6rselde 784 \u00f6zellik var.Bunun nedeni, her g\u00f6r\u00fcnt\u00fcn\u00fcn 28 \u00d7 28 piksel olmas\u0131 ve her \u00f6zelli\u011fin 0 (beyaz) ile 255 (siyah) aras\u0131nda bir pikselin yo\u011funlu\u011funu temsil etmesidir. Veri setinden bir g\u00f6r\u00fcnt\u00fcye bir g\u00f6z atal\u0131m. Tek yapmam\u0131z gereken bir \u00f6rne\u011fin \u00f6zellik vekt\u00f6r\u00fcn\u00fc almak, onu 28 \u00d7 28 diziye yeniden \u015fekillendirmek ve Matplotlib'in imshow() i\u015flevini kullanarak g\u00f6r\u00fcnt\u00fclemek:","e0f8ea19":"%90 kesinlik (pozitif tahmin de\u011feri) oran\u0131na sahip bir s\u0131n\u0131fland\u0131r\u0131c\u0131m\u0131z var. Bu iyi bir sonu\u00e7. Ama y\u00fcksek kesinlikli bir s\u0131n\u0131fland\u0131r\u0131c\u0131, geri \u00e7a\u011fr\u0131lmas\u0131 \u00e7ok d\u00fc\u015f\u00fckse \u00e7ok kullan\u0131\u015fl\u0131 de\u011fildir!","8ebd2372":"Verimizdeki birka\u00e7 g\u00f6r\u00fcnt\u00fcye g\u00f6z atal\u0131m:","bdc7cb66":"SGDClassifier, e\u011fitim s\u0131ras\u0131nda rastgeleli\u011fe dayan\u0131r. Tekrarlanabilir sonu\u00e7lar istiyorsan\u0131z, random_state parametresini ayarlamal\u0131s\u0131n\u0131z. \u015eimdi onu ti\u015f\u00f6rt g\u00f6r\u00fcnt\u00fclerini tespit etmek i\u00e7in kullanabiliriz:","2e862867":"Elde etti\u011fimiz tahmin oran\u0131, yakla\u015f\u0131k %90 do\u011frulu\u011fa sahip. Bunun nedeni, g\u00f6r\u00fcnt\u00fclerin yaln\u0131zca %10'unun 0 yani ti\u015f\u00f6rt olmas\u0131d\u0131r, bu nedenle her zaman bir g\u00f6r\u00fcnt\u00fcn\u00fcn ti\u015f\u00f6rt olmad\u0131\u011f\u0131n\u0131 tahmin edebiliriz, ve bu tahminlerin yakla\u015f\u0131k %90'\u0131nda hakl\u0131 oluruz.","9c0dc880":"Solda g\u00fcr\u00fclt\u00fcl\u00fc giri\u015f g\u00f6r\u00fcnt\u00fcs\u00fc ve sa\u011fda temiz hedef g\u00f6r\u00fcnt\u00fc. \u015eimdi s\u0131n\u0131fland\u0131r\u0131c\u0131y\u0131 e\u011fitelim ve bu resmi temizleyelim:","2b68f9a5":"Kesinlik e\u011frisinin (precision) hassasiyet (recall) e\u011frisinden daha engebeli olmas\u0131n\u0131n nedeni, e\u015fi\u011fi y\u00fckseltti\u011finizde hassasiyetin bazen d\u00fc\u015febilmesidir (genel olarak y\u00fckselecek olsa da).\u00d6te yandan,hassasiyet yaln\u0131zca e\u015fik artt\u0131\u011f\u0131nda d\u00fc\u015febilir, bu da e\u011frisinin neden d\u00fczg\u00fcn g\u00f6r\u00fcnd\u00fc\u011f\u00fcn\u00fc a\u00e7\u0131klar.\n\n\u0130yi bir kesinlik\/hassasiyet de\u011fi\u015f toku\u015fu se\u00e7menin ba\u015fka bir yolu, a\u015fa\u011f\u0131da g\u00f6sterildi\u011fi gibi (\u00f6nceki ile ayn\u0131 e\u015fik vurgulanm\u0131\u015ft\u0131r) kesinli\u011fi do\u011frudan hassasiyete kar\u015f\u0131 \u00e7izmektir.","9406531d":"Bu kod, her basamak g\u00f6r\u00fcnt\u00fcs\u00fc i\u00e7in iki hedef etiket i\u00e7eren bir y_multilabel dizisi olu\u015fturur: ilki, basama\u011f\u0131n b\u00fcy\u00fck (7, 8 veya 9) olup olmad\u0131\u011f\u0131n\u0131, ikincisi ise tek olup olmad\u0131\u011f\u0131n\u0131 belirtir. Sonraki sat\u0131rlar bir KNeighborsClassifier \u00f6rne\u011fi olu\u015fturur ve bunu birden \u00e7ok hedef dizisini kullanarak e\u011fitiriz. Art\u0131k bir tahmin yapabilir ve bunun iki etiket verdi\u011fini fark edebilirsiniz:","4e34f8ab":"## Loss fonksiyonu (cost fonksiyonu, objective function)\nLoss fonksiyonu tasarlanan modelin hata oran\u0131n\u0131 ayn\u0131 zamanda ba\u015far\u0131m\u0131n\u0131 \u00f6l\u00e7en fonksiyondur. Derin a\u011flar\u0131n son katman\u0131 loss fonksiyonun tan\u0131mland\u0131\u011f\u0131 katmand\u0131r. Loss fonksiyonu, hata hesaplama i\u015fini problemi bir optimizasyon problemine d\u00f6n\u00fc\u015ft\u00fcrerek yapt\u0131\u011f\u0131 i\u00e7in optimizasyon terminolojinde kullan\u0131lan objective function, cost function isimleriyle de tan\u0131mlanmaktad\u0131r. Loss fonksiyonu temelde modelin yapt\u0131\u011f\u0131 tahminin, ger\u00e7ek de\u011ferden (ground truth) ne kadar farkl\u0131 oldu\u011funu hesaplamaktad\u0131r. Bu nedenle iyi tahmin eden bir model olu\u015fturmam\u0131\u015fsak, ger\u00e7ek de\u011fer (ground turth) ile tahmin edilen de\u011fer aras\u0131ndaki fark y\u00fcksek olacak dolay\u0131s\u0131yla loss de\u011feri y\u00fcksek olacak, iyi modele sahipsek loss de\u011feri az olacakt\u0131r. Birebir ayn\u0131 oldu\u011fu durumda loss 0 olacakt\u0131r. \u0130yi bir modelden beklentimiz 0'a yak\u0131n loss de\u011ferine sahip olmas\u0131d\u0131r. Neden 0 de\u011fil? K\u0131sa cevab\u0131 regularization.","bbdd2328":"Bu kod, 0'a kar\u015f\u0131 kalan hedef s\u0131n\u0131flar (y_train_0) yerine 0'dan 9'a (y_train) orijinal hedef s\u0131n\u0131flar\u0131 kullanarak e\u011fitim k\u00fcmesindeki SVC'yi e\u011fitir. Sonra bir tahminde bulunur. Burada, Scikit-Learn asl\u0131nda OvO stratejisini kulland\u0131.\n\ndecision_function() komutunu kullan\u0131rsak, \u00f6rnek ba\u015f\u0131na 10 puan d\u00f6nd\u00fcrd\u00fc\u011f\u00fcn\u00fc g\u00f6r\u00fcr\u00fcz. Bu, s\u0131n\u0131f ba\u015f\u0131na bir puand\u0131r:","af58221e":"Tahmin yapmak i\u00e7in (\u015fimdilik e\u011fitim setinde), s\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n predict() y\u00f6ntemini \u00e7a\u011f\u0131rmak yerine \u015fu kodu \u00e7al\u0131\u015ft\u0131rabilirsiniz:\nBu tahminlerin kesinli\u011fini ve hassasiyetini kontrol edelim:","8f18be1c":"#  <span style=\"color:red\"> Veri Y\u00fckleme <span>\nFashion-MNIST, 60.000 \u00f6rneklik bir e\u011fitim seti ve 10.000 \u00f6rneklik bir test setinden olu\u015fan, Zalando'nun makale g\u00f6r\u00fcnt\u00fclerinin bir veri setidir. Her \u00f6rnek, 10 s\u0131n\u0131ftan bir etiketle ili\u015fkilendirilmi\u015f 28x28 gri tonlamal\u0131 bir g\u00f6r\u00fcnt\u00fcd\u00fcr.","f4831e1d":"S\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n tahmininden olduk\u00e7a emin oldu\u011funu g\u00f6rebiliriz: neredeyse t\u00fcm puanlar b\u00fcy\u00fck \u00f6l\u00e7\u00fcde olumsuz, 0. s\u0131n\u0131f ise 12180.29578626 puana sahip. SGDClassifier'\u0131n do\u011frulu\u011funu de\u011ferlendirmek i\u00e7in cross_val_score() i\u015flevini kullan\u0131n:","e809c37e":"Bir SGDClassifier (veya bir RandomForestClassifier) e\u011fitmek de ayn\u0131 derecede kolayd\u0131r:","86b2a5ea":"# <span style=\"color:red\"> \u00c7ok S\u0131n\u0131fl\u0131 S\u0131n\u0131fland\u0131rma (Multiclass Classification) <span>\nK\u0131yafet g\u00f6r\u00fcnt\u00fclerini 10 s\u0131n\u0131fa (0'dan 9'a kadar) s\u0131n\u0131fland\u0131rabilen bir sistem olu\u015fturman\u0131n bir yolu, her k\u0131yafet i\u00e7in bir tane olmak \u00fczere 10 ikili s\u0131n\u0131fland\u0131r\u0131c\u0131 e\u011fitmektir (0-dedekt\u00f6r, 1-dedekt\u00f6r, 2-detekt\u00f6r vb.). Scikit-Learn, \u00e7ok s\u0131n\u0131fl\u0131 bir s\u0131n\u0131fland\u0131rma g\u00f6revi i\u00e7in ikili s\u0131n\u0131fland\u0131rma algoritmas\u0131 kullanmaya \u00e7al\u0131\u015ft\u0131\u011f\u0131n\u0131z\u0131 alg\u0131lar ve algoritmaya ba\u011fl\u0131 olarak otomatik olarak OvR veya OvO'yu \u00e7al\u0131\u015ft\u0131r\u0131r. Bunu sklearn.svm.SVC s\u0131n\u0131f\u0131n\u0131 kullanarak bir Destek Vekt\u00f6r Makinesi s\u0131n\u0131fland\u0131r\u0131c\u0131s\u0131yla deneyelim:","cbcd9e82":"Kesinli\u011fin %80 hassasiyet civar\u0131nda keskin bir \u015fekilde d\u00fc\u015fmeye ba\u015flad\u0131\u011f\u0131n\u0131 g\u00f6r\u00fcyoruz.Muhtemelen bu d\u00fc\u015f\u00fc\u015ften hemen \u00f6nce bir kesinlik\/hassasiyet de\u011fi\u015f toku\u015fu se\u00e7mek isteyece\u011fiz.Tabi bu se\u00e7im yapm\u0131\u015f oldu\u011fumuz projeye ba\u011fl\u0131d\u0131r. \u00d6rne\u011fin bize en az %90 hassasiyet sa\u011flayan en d\u00fc\u015f\u00fck e\u015fi\u011fi arayabiliriz.np.argmax() bize maksimum de\u011ferin ilk indeksini verir.","afa9ba18":"# <span style=\"color:red\"> \u00c7ok \u00c7\u0131k\u0131\u015fl\u0131 S\u0131n\u0131fland\u0131rma (Multioutput classification) <span>\n\u00c7ok \u00c7\u0131k\u0131\u015fl\u0131 S\u0131n\u0131fland\u0131rma, her etiketin \u00e7ok s\u0131n\u0131fl\u0131 olabilece\u011fi (yani ikiden fazla olas\u0131 de\u011fere sahip olabilece\u011fi) \u00e7ok etiketli s\u0131n\u0131fland\u0131rman\u0131n basit bir genellemesidir.Bunu g\u00f6stermek i\u00e7in, g\u00f6r\u00fcnt\u00fclerdeki g\u00fcr\u00fclt\u00fcy\u00fc ortadan kald\u0131ran bir sistem olu\u015fturmam\u0131z gerekiyor.\n\nMNIST g\u00f6r\u00fcnt\u00fclerini alarak ve NumPy'nin randint() i\u015fleviyle piksel yo\u011funluklar\u0131na g\u00fcr\u00fclt\u00fc ekleyerek e\u011fitim ve test setlerini olu\u015fturarak ba\u015flayal\u0131m. Hedef g\u00f6r\u00fcnt\u00fcler orijinal g\u00f6r\u00fcnt\u00fcler olacakt\u0131r:","72db00f0":"Scikit-Learn'i bire kar\u015f\u0131 bir veya bire kar\u015f\u0131 di\u011ferlerini kullanmaya zorlamak istiyorsan\u0131z, OneVsOneClassifier veya OneVsRestClassifier s\u0131n\u0131flar\u0131n\u0131 kullanabiliriz. \u00d6rne\u011fin, bu kod, bir SVC'ye dayal\u0131 olarak OvR stratejisini kullanarak \u00e7ok s\u0131n\u0131fl\u0131 bir s\u0131n\u0131fland\u0131r\u0131c\u0131 olu\u015fturur:","aaec2c2f":"## <span style=\"color:blue\"> Performans \u00f6l\u00e7\u00fcleri <span>\n\n### <span style=\"color:green\"> \u00c7apraz Do\u011frulama Kullanarak Do\u011frulu\u011fu \u00d6l\u00e7me <span\n                                                                                 \n                                                                                 ","105c027b":"Art\u0131k ROC e\u011frisini \u00e7izmeye haz\u0131r\u0131z.","4e482ddb":"# <span style=\"color:red\"> Binary(\u0130kili) S\u0131n\u0131fland\u0131r\u0131c\u0131 <span>\n \u015eimdilik problemi basitle\u015ftirelim ve sadece bir k\u0131yafeti, \u00f6rne\u011fin ti\u015f\u00f6rt\u00fc tan\u0131mlamaya \u00e7al\u0131\u015fal\u0131m. Bu \u201cti\u015f\u00f6rt-dedekt\u00f6r\u201d, sadece   ti\u015f\u00f6rt ve ti\u015f\u00f6rt olmayan iki s\u0131n\u0131f\u0131 ay\u0131rt edebilen bir ikili s\u0131n\u0131fland\u0131r\u0131c\u0131 \u00f6rne\u011fi olacak. ti\u015f\u00f6rt etiketini target olarak       kar\u015f\u0131l\u0131\u011f\u0131 0 oldu\u011fu i\u00e7in 0'a e\u015fit olanlar\u0131 alaca\u011f\u0131z. Bu s\u0131n\u0131fland\u0131rma g\u00f6revi i\u00e7in hedef vekt\u00f6rleri olu\u015ftural\u0131m:","90eda5e2":"T\u00fcm test k\u0131vr\u0131mlar\u0131nda %74'\u00fcn \u00fczerine \u00e7\u0131k\u0131yor. Rastgele bir s\u0131n\u0131fland\u0131r\u0131c\u0131 kullan\u0131rsak, %10 do\u011fruluk elde ederiz, yani bu o kadar da k\u00f6t\u00fc bir puan de\u011fil, ancak yine de \u00e7ok daha iyisini yapabiliriz. Girdileri basit\u00e7e \u00f6l\u00e7eklendirmek do\u011frulu\u011fu %74'\u00fcn \u00fczerine \u00e7\u0131kar\u0131r:","8d9a9760":"Veri setini test ve e\u011fitim olarak ay\u0131rmam\u0131za gerek yok \u00e7\u00fcnk\u00fc zaten ayr\u0131lm\u0131\u015f haldeydi. \u015eimdi s\u0131n\u0131fland\u0131rma metotlar\u0131na ge\u00e7ebiliriz:","f11d02a5":"Test setinden bir g\u00f6r\u00fcnt\u00fcye g\u00f6z atal\u0131m ","59307c87":"Bu modelin do\u011frulu\u011funa bakal\u0131m:","6bdaac07":"Matplotlib'in matshow() i\u015flevini kullanarak, kar\u0131\u015f\u0131kl\u0131k matrisinin bir g\u00f6r\u00fcnt\u00fc temsiline bakal\u0131m:","eddffd92":"## <span style=\"color:blue\"> Hata Analizi <span>\nHata analizi i\u00e7in ilk olarak kar\u0131\u015f\u0131kl\u0131k matrisine bak\u0131p cross_val_predict() i\u015flevini kullanarak tahminler yapmam\u0131z, ard\u0131ndan daha \u00f6nce yapt\u0131\u011f\u0131m\u0131z gibi convert_matrix() i\u015flevini \u00e7a\u011f\u0131rmam\u0131z gerekiyor.","69e19944":"Veri setimizi dizilere ay\u0131ral\u0131m:","c54c9585":"### <span style=\"color:green\"> Confusion (Kar\u0131\u015f\u0131kl\u0131k) Matrisi <span>\nBir s\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n performans\u0131n\u0131 de\u011ferlendirmenin \u00e7ok daha iyi bir yolu, kar\u0131\u015f\u0131kl\u0131k matrisine bakmakt\u0131r.Kar\u0131\u015f\u0131kl\u0131k matrisini hesaplamak i\u00e7in, ger\u00e7ek hedeflerle kar\u015f\u0131la\u015ft\u0131r\u0131labilmeleri i\u00e7in \u00f6ncelikle bir dizi tahmine sahip olmam\u0131z gerekiyor. Test seti \u00fczerinde tahminlerde bulunabiliriz, ancak \u015fimdilik buna dokunmayal\u0131m (test setini yaln\u0131zca projemizin en sonunda, ba\u015flatmaya haz\u0131r oldu\u011fumuz bir s\u0131n\u0131fland\u0131r\u0131c\u0131m\u0131z oldu\u011funda kullanmak istiyoruz). Bunun yerine cross_val_predict() i\u015flevini kullanabiliriz:","589b5cbf":"Art\u0131k, confusion_matrix() i\u015flevini kullanarak kar\u0131\u015f\u0131kl\u0131k matrisini elde etmeye haz\u0131r\u0131z.\n\nKar\u0131\u015f\u0131kl\u0131k matrisindeki her sat\u0131r ger\u00e7ek bir s\u0131n\u0131f\u0131 temsil ederken, her s\u00fctun tahmin edilen bir s\u0131n\u0131f\u0131 temsil eder. Bu matrisin ilk sat\u0131r\u0131, 0(ti\u015f\u00f6rt) olmayan g\u00f6r\u00fcnt\u00fcleri (negatif s\u0131n\u0131f) dikkate al\u0131r: bunlardan 52.472'si do\u011fru bir \u015fekilde 0 olmayanlar (ger\u00e7ek negatifler olarak adland\u0131r\u0131l\u0131rlar) olarak s\u0131n\u0131fland\u0131r\u0131l\u0131rken, kalan 1.528'si yanl\u0131\u015fl\u0131kla 0'ler (yanl\u0131\u015f pozitifler) olarak s\u0131n\u0131fland\u0131r\u0131lm\u0131\u015ft\u0131r. \u0130kinci sat\u0131r, 0'larin (pozitif s\u0131n\u0131f) g\u00f6r\u00fcnt\u00fclerini dikkate al\u0131r: 1.388'i yanl\u0131\u015f bir \u015fekilde 0'lar (yanl\u0131\u015f negatifler) olarak s\u0131n\u0131fland\u0131r\u0131l\u0131rken, kalan 4.612'si do\u011fru bir \u015fekilde 0'lar (ger\u00e7ek pozitifler) olarak s\u0131n\u0131fland\u0131r\u0131lm\u0131\u015ft\u0131r.\n\nM\u00fckemmel bir s\u0131n\u0131fland\u0131r\u0131c\u0131 yaln\u0131zca ger\u00e7ek pozitiflere ve ger\u00e7ek negatiflere sahip olacakt\u0131r, bu nedenle kar\u0131\u015f\u0131kl\u0131k matrisi yaln\u0131zca ana k\u00f6\u015fegeninde (sol \u00fcstten sa\u011f alta) s\u0131f\u0131r olmayan de\u011ferlere sahip olacakt\u0131r:","d1942441":"Art\u0131k ti\u015f\u00f6rt dedekt\u00f6r\u00fcm\u00fcz\u00fcn do\u011frulu\u011funa bakt\u0131\u011f\u0131m\u0131zda oldu\u011fu kadar parlak g\u00f6r\u00fcnm\u00fcyor. Bir g\u00f6r\u00fcnt\u00fcn\u00fcn ti\u015f\u00f6rt\u00fc temsil etti\u011fini iddia etti\u011fimizde,bunun yaln\u0131zca %75.1'i do\u011frudur. Ayr\u0131ca, ti\u015f\u00f6rtlerin yaln\u0131zca %76,8'ini alg\u0131layabilir.\n\n\u00d6zellikle iki s\u0131n\u0131fland\u0131r\u0131c\u0131y\u0131 kar\u015f\u0131la\u015ft\u0131rman\u0131n basit bir yoluna ihtiyac\u0131n\u0131z varsa, kesinli\u011fi ve hassasiyeti F1 puan\u0131 ad\u0131 verilen tek bir metrikte birle\u015ftirmek genellikle uygundur. F1 puan\u0131, kesinlik ve hassasiyetin harmonik ortalamas\u0131d\u0131r. Normal ortalama t\u00fcm de\u011ferleri e\u015fit olarak ele al\u0131rken, harmonik ortalama d\u00fc\u015f\u00fck de\u011ferlere \u00e7ok daha fazla a\u011f\u0131rl\u0131k verir. Sonu\u00e7 olarak, s\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n hem hassasiyeti hem de kesinli\u011fi y\u00fcksekse y\u00fcksek bir F1 puan\u0131 alacakt\u0131r.","22c662bf":"TPR ne kadar y\u00fcksekse, s\u0131n\u0131fland\u0131r\u0131c\u0131 o kadar fazla yanl\u0131\u015f pozitif (FPR) \u00fcretir. Noktal\u0131 \u00e7izgi, tamamen rastgele bir s\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n ROC e\u011frisini temsil eder; iyi bir s\u0131n\u0131fland\u0131r\u0131c\u0131 bu \u00e7izgiden m\u00fcmk\u00fcn oldu\u011funca uzak durur (sol \u00fcst k\u00f6\u015feye do\u011fru). Bu ROC e\u011frisi, t\u00fcm olas\u0131 e\u015fikler i\u00e7in ger\u00e7ek pozitif orana kar\u015f\u0131 yanl\u0131\u015f pozitif oran\u0131 \u00e7izer; k\u0131rm\u0131z\u0131 daire se\u00e7ilen oran\u0131 vurgular (%43.68 hassasiyette). S\u0131n\u0131fland\u0131r\u0131c\u0131lar\u0131 kar\u015f\u0131la\u015ft\u0131rman\u0131n di\u011fer bir yolu, e\u011frinin alt\u0131ndaki alan\u0131 (AUC) \u00f6l\u00e7mektir. M\u00fckemmel bir s\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n ROC AUC'si 1'e e\u015fit olurken, tamamen rastgele bir s\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n ROC AUC'si 0,5'e e\u015fit olacakt\u0131r. Scikit-Learn, ROC AUC'yi hesaplamak i\u00e7in bir i\u015flev sa\u011flar:","3e388620":"### <span style=\"color:green\"> Precision ve Recall Trade-off  (Kesinlik ve Hassasiyet Dengesi) <span>\nArtan kesinlik, hassasiyeti azalt\u0131r ve bunun tersi de ge\u00e7erlidir. Buna kesinlik\/hassasiyet \u00f6d\u00fcnle\u015fimi denir.Bu \u00f6d\u00fcnle\u015fimi anlamak i\u00e7in SGDClassifier'\u0131n s\u0131n\u0131fland\u0131rma kararlar\u0131n\u0131 nas\u0131l verdi\u011fine bakal\u0131m. Her \u00f6rnek i\u00e7in, bir karar fonksiyonuna dayal\u0131 olarak bir puan hesaplar. Bu puan bir e\u015fikten b\u00fcy\u00fckse, \u00f6rne\u011fi pozitif s\u0131n\u0131fa atar; aksi halde onu negatif s\u0131n\u0131fa atar. Scikit-Learn, e\u015fi\u011fi do\u011frudan belirlemenize izin vermez, ancak tahmin yapmak i\u00e7in kulland\u0131\u011f\u0131 karar puanlar\u0131na eri\u015fmenizi sa\u011flar.S\u0131n\u0131fland\u0131r\u0131c\u0131n\u0131n predict() y\u00f6ntemini \u00e7a\u011f\u0131rmak yerine, her \u00f6rnek i\u00e7in bir puan d\u00f6nd\u00fcren decision_function() y\u00f6ntemini \u00e7a\u011f\u0131rabilir ve ard\u0131ndan bu puanlara dayal\u0131 olarak tahminler yapmak istedi\u011finiz herhangi bir e\u015fi\u011fi kullanabilirsiniz:"}}