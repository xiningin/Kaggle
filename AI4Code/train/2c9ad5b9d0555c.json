{"cell_type":{"3c7dec97":"code","31e6447a":"code","1205006e":"code","e3da20f0":"code","b01a3e37":"code","25a4fff6":"code","2babd512":"code","a0ce5649":"code","d762c3b3":"code","6fee748e":"code","52335941":"code","1fac53f4":"code","d4e4c253":"code","168f5f7e":"code","2ab5b5d8":"code","cce689d0":"code","0eb3a366":"markdown","578a9d8b":"markdown","4c5340ec":"markdown","1f5aa303":"markdown","fea1fbc9":"markdown","c28e86ca":"markdown","681bc8a8":"markdown","0078b0db":"markdown","0adf34d9":"markdown"},"source":{"3c7dec97":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","31e6447a":"#Load the dataset\ndf = pd.read_csv('..\/input\/diabetes.csv')\n\n#Print the first 5 rows of the dataframe.\ndf.head()","1205006e":"#Let's observe the shape of the dataframe.\ndf.shape","e3da20f0":"#Let's create numpy arrays for features and target\nX = df.drop('Outcome',axis=1).values\ny = df['Outcome'].values","b01a3e37":"X[:5]","25a4fff6":"y[:5]","2babd512":"#importing train_test_split\nfrom sklearn.model_selection import train_test_split","a0ce5649":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42, stratify=y)","d762c3b3":"#import KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Setup arrays to store training and test accuracies\nneighbors = np.arange(1,10)\ntrain_accuracy =np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n\nfor i,k in enumerate(neighbors):\n    #Setup a knn classifier with k neighbors\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    #Fit the model\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = knn.score(X_train, y_train)\n    \n    #Compute accuracy on the test set\n    test_accuracy[i] = knn.score(X_test, y_test) ","6fee748e":"#Generate plot\nplt.title('k-NN Varying number of neighbors')\nplt.plot(neighbors, test_accuracy, label='Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label='Training accuracy')\nplt.legend()\nplt.xlabel('Number of neighbors')\nplt.ylabel('Accuracy')\nplt.show()","52335941":"#Setup a knn classifier with k neighbors\nknn = KNeighborsClassifier(n_neighbors=7)","1fac53f4":"#Fit the model\nknn.fit(X_train,y_train)","d4e4c253":"#Get accuracy. Note: In case of classification algorithms score method represents accuracy.\nknn.score(X_test,y_test)","168f5f7e":"#import confusion_matrix\nfrom sklearn.metrics import confusion_matrix","2ab5b5d8":"#let us get the predictions using the classifier we had fit above\ny_pred = knn.predict(X_test)","cce689d0":"confusion_matrix(y_test,y_pred)","0eb3a366":"As observed above we have 768 rows and 9 columns. The first 8 columns represent the features and the last column represent the target\/label. ","578a9d8b":"### Credits\nMost of the code is taken from [KNN for Classification using Scikit-learn](https:\/\/www.kaggle.com\/amolbhivarkar\/knn-for-classification-using-scikit-learn) by [Amol Bhivarkar](https:\/\/www.kaggle.com\/amolbhivarkar)","4c5340ec":"It is a best practice to perform our split in such a way that out split reflects the labels in the data. In other words, we want labels to be split in train and test set as they are in the original dataset. So we use the stratify argument.\n\nAlso we create a test set of size of about 40% of the dataset.","1f5aa303":"Let's split the data randomly into training and test set. \n\nWe will fit\/train a classifier on the training set and make predictions on the test set. Then we will compare the predictions with the known labels.\n\nScikit-learn provides facility to split data into train and test set using train_test_split method.","fea1fbc9":"Let's create a classifier using k-Nearest Neighbors algorithm.\n\nFirst let us first observe the accuracies for different values of k.","c28e86ca":"### K-Nearest Neighbors classification algorithm to predict whether the patients in the \"Pima Indians Diabetes Dataset\" have diabetes or not.","681bc8a8":"We can observe above that we get maximum testing accuracy for k=7. So lets create a KNeighborsClassifier with number of neighbors as 7.","0078b0db":"**Confusion Matrix**\n\nA confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. Scikit-learn provides facility to calculate confusion matrix using the confusion_matrix method.","0adf34d9":"Considering confusion matrix above:\n\nTrue negative = 165\n\nFalse positive = 36\n\nTrue postive = 60\n\nFasle negative = 47"}}