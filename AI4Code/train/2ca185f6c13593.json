{"cell_type":{"ecdcf06a":"code","8354276f":"code","e4eda8be":"code","84640e1f":"code","396eec79":"code","3e2a5a7e":"code","e2f347ee":"code","3577f63f":"code","feffa127":"code","f1e63f58":"code","4672df83":"code","0f1c0545":"code","20601c6d":"code","de489889":"code","9f1e5156":"code","59bdc6a6":"code","169995ad":"code","6dfcf6d4":"code","09adf2d4":"code","cacd0820":"code","e643f491":"code","70ec641e":"code","ce7771ca":"code","c6864c8b":"code","f3e53ebd":"code","0ba3bce1":"code","0e4256b6":"code","bcd00e63":"code","19f94db6":"code","07622541":"code","3a5e6240":"code","3622a677":"code","ab3026cd":"code","907a2f2f":"code","779ef37d":"code","eca2e412":"code","a0f9ef4f":"code","6e41e30a":"code","8c06d17c":"markdown","ce4c81fc":"markdown","a089d0c5":"markdown","a333a08f":"markdown","f6fa1fb4":"markdown","d9cf3a39":"markdown","851ee0b3":"markdown","f166d0c7":"markdown","0e969204":"markdown"},"source":{"ecdcf06a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","8354276f":"train = pd.read_csv(r'..\/input\/bigmart-sales-data\/Train.csv')\ntest = pd.read_csv(r'..\/input\/bigmart-sales-data\/Test.csv')","e4eda8be":"train.head()","84640e1f":"test.head()","396eec79":"# checking Missing values in train data\ntrain.isnull().sum()\/len(train)*100","3e2a5a7e":"# checking Missing values in test data\ntest.isnull().sum()\/len(test)*100","e2f347ee":"train['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0], inplace=True)\ntrain['Item_Weight'].fillna(train['Item_Weight'].mean(), inplace=True)\ntest['Outlet_Size'].fillna(test['Outlet_Size'].mode()[0], inplace=True)\ntest['Item_Weight'].fillna(test['Item_Weight'].mean(), inplace=True)","3577f63f":"# checking the missing values\ntrain.isnull().sum()","feffa127":"test.isnull().sum()","f1e63f58":"train = pd.get_dummies(train, columns = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'],prefix = '',prefix_sep = '')\ntest = pd.get_dummies(test, columns = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'],prefix = '',prefix_sep = '')","4672df83":"train = pd.get_dummies(train, columns = ['Outlet_Identifier'],prefix = '',prefix_sep = '')\ntest = pd.get_dummies(test, columns = ['Outlet_Identifier'],prefix = '',prefix_sep = '')","0f1c0545":"train.head()","20601c6d":"for i in train.columns[1:]:\n    train[i] = (train[i] - train[i].min()) \/ (train[i].max() - train[i].min())","de489889":"for i in test.columns[1:]:\n    test[i] = (test[i] - test[i].min()) \/ (test[i].max() - test[i].min())","9f1e5156":"train = train.drop('Item_Identifier', axis=1)\ntest = test.drop('Item_Identifier', axis=1)","59bdc6a6":"# separating the independent and dependent variables\n\n# storing all the independent variables as X\nX = train.drop('Item_Outlet_Sales', axis=1)\n\n# storing the dependent variable as y\ny = train['Item_Outlet_Sales']","169995ad":"X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=10,test_size=0.2)","6dfcf6d4":"# shape of training and validation set\n(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)","09adf2d4":"# checking the version of keras\nimport keras\nprint(keras.__version__)","cacd0820":"# checking the version of tensorflow\nimport tensorflow as tf\nprint(tf.__version__)","e643f491":"# importing the sequential model\nfrom keras.models import Sequential","70ec641e":"# importing different layers from keras\nfrom keras.layers import InputLayer, Dense,Flatten,Dropout","ce7771ca":"# number of input neurons\nX_train.shape","c6864c8b":"# number of features in the data\nX_train.shape[1]","f3e53ebd":"model = Sequential()","0ba3bce1":"#Input Layer\nmodel.add(Dense(128,kernel_initializer='normal',input_shape=(X_train.shape[1],),activation='relu'))","0e4256b6":"#Hidden Layers\nmodel.add(Dense(256,kernel_initializer='normal',activation='relu'))\nmodel.add(Dense(256,kernel_initializer='normal',activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256,kernel_initializer='normal',activation='relu'))","bcd00e63":"#Output Layer\nmodel.add(Dense(1,kernel_initializer='normal',activation='linear'))","19f94db6":"# Model Summary\nmodel.summary()","07622541":"model.compile(optimizer='adam',loss='mean_absolute_error',metrics=['mean_absolute_error'])","3a5e6240":"model_history = model.fit(X_train,y_train,epochs=300,batch_size=60,validation_split=0.2)","3622a677":"# getting predictions for the validation set\nprediction = model.predict(X_test)","ab3026cd":"prediction","907a2f2f":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score,accuracy_score\nr2_score(y_test,prediction)","779ef37d":"# getting predictions for the test set\nprediction1 = model.predict(test)","eca2e412":"prediction1","a0f9ef4f":"# summarize history for loss\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","6e41e30a":"# summarize history for accuracy\nplt.plot(model_history.history['mean_absolute_error'])\nplt.plot(model_history.history['val_mean_absolute_error'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","8c06d17c":"# Compiling the model (defining loss function, optimizer)\u00b6\n","ce4c81fc":"# Create train and validation\u00b6\n","a089d0c5":"# Defining different layers\u00b6\n","a333a08f":"# Data Scaling\u00b6\n","f6fa1fb4":"# Create Dummy variables of categorical data","d9cf3a39":"# Training the Model\u00b6\n","851ee0b3":"# Filling the Missing Values","f166d0c7":"# Neural Network\u00b6\n# Defining the architecture of the model","0e969204":"# Create Model\u00b6\n"}}