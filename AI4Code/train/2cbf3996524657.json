{"cell_type":{"6f5b84f0":"code","7162798c":"code","aa325b18":"code","b70f401f":"code","089145ea":"code","c9376b26":"code","50bcf76c":"code","d164a3c9":"code","1fc83972":"code","a7e05619":"code","358a4d4d":"code","45ef46ba":"code","af2797b8":"code","6de4f7a3":"code","a9f416be":"code","920ef69c":"code","b5c75122":"markdown","19f28952":"markdown","7247060a":"markdown","2cded4c4":"markdown","48db28c4":"markdown","d88724a0":"markdown","f3326d31":"markdown"},"source":{"6f5b84f0":"!pip install pyspark","7162798c":"!python -m pip install findspark","aa325b18":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\nsc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\nspark = SparkSession.builder.getOrCreate()","b70f401f":"df = spark.read.csv('..\/input\/credit-card-customers\/BankChurners.csv', inferSchema=True, header=True)\ndf.show(5)","089145ea":"df.columns","c9376b26":"df.printSchema()","50bcf76c":"df.describe('Attrition_Flag').show(10)","d164a3c9":"df.select('Attrition_Flag','Customer_Age').show(10)","1fc83972":"df.groupby('Customer_Age').agg({'Total_Revolving_Bal': 'mean'}).show()","a7e05619":"df.groupby('Customer_Age').count().show()","358a4d4d":"from pyspark.mllib.stat import Statistics\n\n# select variables to check correlation\ndf_features = df.select(\"Customer_Age\",\"Total_Trans_Amt\",\"Total_Trans_Ct\",\"Total_Revolving_Bal\") \n\n# create RDD table for correlation calculation\nrdd_table = df_features.rdd.map(lambda row: row[0:])\n\n# get the correlation matrix\ncorr_mat=Statistics.corr(rdd_table, method=\"pearson\")\ncorr_mat","45ef46ba":"plt.imshow(corr_mat,cmap='GnBu')","af2797b8":"print('Data frame describe (string and numeric columns only):')\ndf.describe().toPandas()\n\nprint(f'There are total {df.count()} row, Let print first 2 data rows:')\ndf.limit(2).toPandas()","6de4f7a3":"Months_on_book = df.groupBy('Months_on_book').count()\n\nTotal_Revolving_Bal = df.groupBy('Total_Revolving_Bal').count()","a9f416be":"Months = pd.DataFrame(Months_on_book.rdd.map(lambda line: line.asDict()).collect()).head(20)\nRevolving_Bal = pd.DataFrame(Total_Revolving_Bal.rdd.map(lambda line: line.asDict()).collect()).head(20)","920ef69c":"Months.head(10)\nRevolving_Bal.head(10)","b5c75122":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#ff8000;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\nCreate Spark Context\n<\/h1>\n<\/div>\n","19f28952":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#ff8000;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\nPyspark\n<\/h1>\n<\/div>\n","7247060a":"# 1. Schema","2cded4c4":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#ff8000;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\nBasic Spark Operations\n<\/h1>\n<\/div>\n","48db28c4":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#ff8000;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\n\n\n\nString and Numeric Columns\n<\/h1>\n<\/div>\n","d88724a0":"# How to find the mean of each age group in data?","f3326d31":"![](https:\/\/databricks.com\/wp-content\/uploads\/2018\/12\/PySpark-1024x164.png)"}}