{"cell_type":{"35e31c74":"code","f2674b3d":"code","22d32c8d":"code","34a3fdf0":"code","7125b6be":"code","44ea720a":"code","eb7b706c":"code","76a437ba":"code","de5b009a":"code","4f7d1127":"code","16bcb957":"code","fff26727":"code","49eabe6b":"code","92687c35":"code","9ec11d38":"code","48379f75":"code","213507f1":"code","723b417d":"code","eec99733":"code","368dcc00":"code","6c89b31b":"code","ecb90ca0":"code","d4b43239":"code","c6bd6f03":"code","5f85902d":"code","b43d2348":"code","c7d7e7ef":"code","84e24327":"code","86f423bc":"code","485db2d8":"code","81ee7ac0":"code","d818b99b":"code","2d8c2638":"code","a41f9010":"code","abd2d7ac":"code","016b6f41":"markdown","55d3fead":"markdown","6ec8ef77":"markdown","8f67e5e6":"markdown","bd2ae7c0":"markdown","297f72e4":"markdown","0ff56609":"markdown","9261e62c":"markdown","f5ae1889":"markdown","04ed6132":"markdown","756ec68f":"markdown","9abdba84":"markdown","761d4bab":"markdown","7cb4c9ed":"markdown","ea3c99bc":"markdown","e12ff134":"markdown","67e4e3ae":"markdown","535b804e":"markdown","29b70269":"markdown","8b84098f":"markdown","09f8fc6e":"markdown","80101a55":"markdown","f72f4b26":"markdown","389e0096":"markdown","15fa9f4a":"markdown","89419b76":"markdown","3b410eef":"markdown","86b02b76":"markdown","c4fe69ef":"markdown","2119b9c4":"markdown","8fe224bd":"markdown","1d6b2102":"markdown","9b761379":"markdown","c84944f1":"markdown","ebc34aa2":"markdown","2cd2166d":"markdown","34d3eedf":"markdown","a0030540":"markdown"},"source":{"35e31c74":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nfrom glob import glob\nimport matplotlib.pyplot as plt","f2674b3d":"IMAGE_SIZE = [224, 224]\n\ntrain_path = '..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/*'  # train\nvalid_path = '..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/*'   # test\n","22d32c8d":"vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","34a3fdf0":"vgg.summary()","7125b6be":"# don't train existing weights\nfor layer in vgg.layers:\n    layer.trainable = False","44ea720a":"# useful for getting number of output classes\nfolders = glob('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/*')\nfolders","eb7b706c":"# output layer - you can add more if you want\nx = Flatten()(vgg.output)","76a437ba":"prediction = Dense(len(folders), activation='softmax')(x)","de5b009a":"# create a model object\nmodel = Model(inputs = vgg.input, outputs = prediction)","4f7d1127":"# view the structure of the model\nmodel.summary()","16bcb957":"# tell the model what cost and optimization method to use\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","fff26727":"# Use the Image Data Generator to import the images from the dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","49eabe6b":"# Make sure you provide the same target size as initialied for the image size that is (224,224).\ntraining_set = train_datagen.flow_from_directory('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train', target_size = (224, 224),\n                                                 batch_size = 32, class_mode = 'categorical')","92687c35":"test_set = test_datagen.flow_from_directory('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid', target_size = (224, 224),\n                                            batch_size = 32, class_mode = 'categorical')","9ec11d38":"# fit the model\n# Run the cell. It will take some time to execute\nvgg_model = model.fit_generator(training_set, validation_data = test_set, epochs = 10, steps_per_epoch = len(training_set),\n  validation_steps = len(test_set))","48379f75":"vgg_model.history","213507f1":"# plot the loss\nplt.plot(vgg_model.history['loss'], label='train loss')\nplt.plot(vgg_model.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# plot the accuracy\nplt.plot(vgg_model.history['accuracy'], label='train acc')\nplt.plot(vgg_model.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","723b417d":"# save the model  as a h5 file\nfrom tensorflow.keras.models import load_model\nmodel.save('vgg_model.h5')","eec99733":"# prediction of test data\ny_pred = model.predict(test_set)\ny_pred","368dcc00":"import numpy as np\ny_pred = np.argmax(y_pred, axis=1)\ny_pred","6c89b31b":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Bacterial_spot\/014b58ae-091b-408a-ab4a-5a780cd1c3f3___GCREC_Bact.Sp 2971.JPG\"))\nplt.title('Tomato___Bacterial_spot')","ecb90ca0":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Early_blight\/01f87f04-ff38-4aba-b7d1-587aa06e5282___RS_Erly.B 7851.JPG\"))\nplt.title('Tomato___Early_blight')","d4b43239":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Late_blight\/005a2c1f-4e15-49e4-9e5c-61dc3ecf9708___RS_Late.B 5096_flipLR.JPG\"))\nplt.title('Tomato___Late_blight')","c6bd6f03":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Leaf_Mold\/0160c3b5-d89e-40e5-a313-49ae1524040a___Crnl_L.Mold 6823.JPG\"))\nplt.title('Tomato___Leaf_Mold')","5f85902d":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Septoria_leaf_spot\/03b3e88f-63ad-49e1-88c2-b8bfffd6aaf6___Matt.S_CG 1226_flipTB.JPG\"))\nplt.title('Tomato___Septoria_leaf_spot')","b43d2348":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Spider_mites Two-spotted_spider_mite\/01854aac-d409-4136-b885-3df6943cc349___Com.G_SpM_FL 1374.JPG\"))\nplt.title('Tomato___Spider_mites Two-spotted_spider_mite')","c7d7e7ef":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Target_Spot\/003a5321-0430-42dd-a38d-30ac4563f4ba___Com.G_TgS_FL 8121_newPixel25.JPG\"))\nplt.title('Tomato___Target_Spot')","84e24327":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Tomato_Yellow_Leaf_Curl_Virus\/0383249b-008c-4e0b-b8ee-7eae08be99d3___YLCV_GCREC 2722.JPG\"))\nplt.title('Tomato_Yellow_Leaf_Curl_Virus')","86f423bc":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Tomato_mosaic_virus\/000ec6ea-9063-4c33-8abe-d58ca8a88878___PSU_CG 2169_270deg.JPG\"))\nplt.title('Tomato___mosaic_virus')","485db2d8":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___healthy\/014b5e19-7917-4d76-b632-b5dd31d999ec___RS_HL 9640.JPG\"))\nplt.title('Tomato___healthy')","81ee7ac0":"# load the model\nvgg_load = load_model('vgg_model.h5')","d818b99b":"def prepare(filepath):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR) # Reading the file\n    img_array = img_array \/ 255\n    new_array = cv2.resize(img_array, (224, 224)) # resizing the img_array to (224,224)\n    return new_array.reshape(-1, 224, 224, 3) # reshaping the new data\n\nmodel = tf.keras.models.load_model(\"vgg_model.h5\")","2d8c2638":"prediction = model.predict([prepare(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Tomato_Yellow_Leaf_Curl_Virus\/057552a8-8c38-443f-b523-5ee2b428e622___UF.GRC_YLCV_Lab 09477.JPG\")])\nnp.argmax(prediction)","a41f9010":"class_dict = training_set.class_indices\nclass_dict","abd2d7ac":"if np.argmax(prediction) == 0:\n    print(\"Tomato___Bacterial_spot\")\nelif np.argmax(prediction) == 1:\n    print(\"Tomato___Early_Blight\")\nelif np.argmax(prediction) == 2:\n    print(\"Tomato___Late Blight\")\nelif np.argmax(prediction) == 3:\n    print(\"Tomato___Leaf Mold\")\nelif np.argmax(prediction) == 4:\n    print(\"Tomato___Septoria Leaf Spot\")\nelif np.argmax(prediction) == 5:\n    print(\"Tomato___Spider mites\")\nelif np.argmax(prediction) == 6:\n    print(\"Tomato___Target Spot\")\nelif np.argmax(prediction) == 7:\n    print(\"Tomato___Yellow Leaf Curl Virus\")\nelif np.argmax(prediction) == 8:\n    print(\"Tomato___Mosaic Virus\")\nelse:\n    print(\"Tomato___Healthy\")","016b6f41":"#### Here we have used glob, it indicates the how many number of folder we had means the length of the folder indicates the number of category we have in our neural network.\n#### As we can see above, it showing the number of folders are 10, so here our output layer had 10 cateogries.","55d3fead":"#### As we can see above plot the lines i.e the training accuracy and validation accuracy is going in same direction.","6ec8ef77":"#### Above we are resizing the image size and taking the path of train and test set","8f67e5e6":"## Fitting the Model","bd2ae7c0":"#### As we can see above we have our own input in first layer we are giving our own images and in the last layer we have to add a output layer based on the output category we have.","297f72e4":"#### As shown above we used argmax, it says that for each record which ever having  highest value take that particular index of that value. Here we will take the index of highest value as our output category.","0ff56609":"#### Here we are using ImageGenerator for data augmentation, In data augmentation it creates more variation of images or new images by using the existing one.\n#### Here ImageGenerator read the images from the folder and apply the data augmentation technique like scaling, zooming, vertical flipping, horizonatal flipping.\n#### The model should determine each side of object thats why we use technique like  data augmentation.\n\n#### Above we are rescaling the pixel of an image as we know each pixel ranges between 0 to 255, to convert the pixel between 0 to 1 we are rescaling the pixel.\n\n### Note : We never apply Data Augmentation technique to the test data, because we have to use that original data for predicting our model output.","9261e62c":"#### Our model predicted the amazing training accuracy that is 93 % and validation accuracy is 92 %","f5ae1889":"#### As we can see in summary of model we had used dense layer which is our output layer with 3 categories.","04ed6132":"#### Here we are reading all the images from the folder. \n#### Target size is (224,224) because we had initiliaze this size in our model, so this should be match.\n#### class_ mode is categorical because here we have more then two categories, if we have 2 categoies, we will be using classmode as binary.","756ec68f":"### Prediction","9abdba84":"#### Here we are using VGG16,  we will be using imagenet as a weights and here 3 indicates channel that is RGB, to make it RGB channel we use 3 index\n#### we used include_top=False because in VGG16 the output layer has 1000 category, In our case we have only 10 categories.\n","761d4bab":"#### Here we are compiling our model, our loss function is basically 'categorical_crossentropy' because here our output layer has categories, type of classification problem.","7cb4c9ed":"#### Here we are creating a model with input layer as vgg.input and output is prediction that is our dense layer with 10 cateories and activation function is softmax.","ea3c99bc":"## Data Augmentation","e12ff134":"#### As we can see above, how loss, val_loss is decreasing and accuracy, val_acc is inreasing. So all these values are saved in dictionary.","67e4e3ae":"## Prediction of test data","535b804e":"## Different Category of Images ","29b70269":"## Compiling the Model","8b84098f":"## Summary of model","09f8fc6e":"## Glob function","80101a55":"**If you like my Kernel Please Upvote !  Happy Learning :)**","f72f4b26":"## Adding Dense Layer as a output ","389e0096":"## Check the Prediction for new data","15fa9f4a":"# Tomato Leaf Detection using Transfer Learning VGG16","89419b76":"#### Here we are using existing weights of VGG16 which are initialize, not to retrain them, we will only retrain the last layer, because the last layer have output category that we will use further.","3b410eef":"## VGG16 (Transfer Learning)","86b02b76":"#### Here we are using len(folders), it indicates that we have 'len(folders)' categories means we have 10 categories because the length of folders is 10. \n#### Activation function we have used is softmax beacause the type of problem is classification.","c4fe69ef":"#### Here we are adding flatten() method to flattening the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer. \n#### It convert the 2 dimension into 1 dimension","2119b9c4":"#### As we can see above the model has predict correct new data which is Tomato___Yellow Leaf Curl Virus","8fe224bd":"## Flattening the Output","1d6b2102":"## Import Libraries","9b761379":"## Model Creation","c84944f1":"## To Check the loss and accuracy of model","ebc34aa2":"## Save the Model","2cd2166d":"## Resize the Image","34d3eedf":"## Summary of Model","a0030540":"## Plot loss and accuracy of model"}}