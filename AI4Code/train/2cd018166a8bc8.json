{"cell_type":{"3b4b91c1":"code","2c3a5eb6":"code","81e68d8c":"code","f5fa8628":"code","88e710e9":"code","25d2eae7":"code","aa296efb":"code","e2d6c248":"code","4d6d5c87":"code","9fef371a":"code","dfd046c9":"code","cec764fe":"code","ac8ca8a4":"code","809dca74":"code","8ed28ecc":"code","3faaa77a":"code","109d4ac7":"code","d745c586":"code","88c5dc0d":"code","b96c5b5d":"code","6d0a563b":"code","bcdc5534":"code","c2359db3":"code","c9ac8c49":"code","c3a4cc72":"code","7defee43":"code","a89e7fad":"code","3976f316":"code","e629119e":"markdown","648a2ec3":"markdown","7f3f83e7":"markdown","9ede7bc8":"markdown","1b2603b0":"markdown","f2e3a761":"markdown","52abe2d2":"markdown","6d308cde":"markdown","e8692089":"markdown"},"source":{"3b4b91c1":"# pip install tensorflow\nimport tensorflow as tf\nprint(tf.version)","2c3a5eb6":"string_tensor = tf.Variable(\"this is a string\", tf.string) \nnumber_tensor = tf.Variable(324, tf.int16)\nfloating_tensor = tf.Variable(3.567, tf.float64)\n\nrank1_tensor = tf.Variable([\"one\", \"two\", \"three\", \"four\"], tf.string) \nrank2_tensor = tf.Variable([[\"one\", \"two\"], [\"one\", \"two\"], [\"one\", \"two\"]], tf.string)\n\nprint(\"Tensor 1 Rank: \" + str( tf.rank(rank1_tensor) ))\nprint(\"Tensor 1 Shape: \" + str( rank1_tensor.shape ))\nprint(\"Tensor 2 Rank: \" + str( tf.rank(rank2_tensor) ))\nprint(\"Tensor 2 Shape: \" + str( rank2_tensor.shape ))","81e68d8c":"tensor1 = tf.ones([1,2,3])              # tf.ones() creates a tensor full of ones\ntensor2 = tf.reshape(tensor1, [2,3,1])\ntensor3 = tf.reshape(tensor2, [3, -1])  # -1 tells the tensor to automatically calculate the size of the dimension\n\nprint(tensor1)\nprint(tensor2)\nprint(tensor3)","f5fa8628":"matrix = [[1,2,3,4,5],\n          [6,7,8,9,10],\n          [11,12,13,14,15],\n          [16,17,18,19,20]]\n\ntensor = tf.Variable(matrix, dtype=tf.int32) \nprint(tf.rank(tensor))\nprint(tensor.shape)\n\nthree = tensor[0,2]  # Row 0, column 2\nprint(three)  # -> 3\n\nrow1 = tensor[0]  # Row 0, column all\nprint(row1)\n\ncolumn1 = tensor[:, 0]  # Row all, column 0\nprint(column1)\n\ncolumn_1_in_row_2_and_3 = tensor[1:3, 0] # Row 1 -> 2, column 0\nprint(column_1_in_row_2_and_3)\n\nrow_2_and_4 = tensor[1::2]  # selects second and fourth row\nprint(row_2_and_4)","88e710e9":"from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom six.moves import urllib\n\nimport tensorflow.compat.v2.feature_column as fc\n\nimport tensorflow as tf","25d2eae7":"# Load dataset.\ndftrain = pd.read_csv('https:\/\/storage.googleapis.com\/tf-datasets\/titanic\/train.csv') # training data\ndfeval = pd.read_csv('https:\/\/storage.googleapis.com\/tf-datasets\/titanic\/eval.csv') # testing data\n\ny_train = dftrain.pop('survived')\ny_eval = dfeval.pop('survived')","aa296efb":"dftrain.head()","e2d6c248":"dftrain.describe()","4d6d5c87":"dftrain.shape","9fef371a":"dftrain['age'].hist(bins = 20)","dfd046c9":"dftrain['sex'].value_counts().plot(kind='barh')","cec764fe":"pd.concat([dftrain, y_train], axis=1).groupby('sex')['survived'].mean().plot(kind='barh').set_xlabel('% survive')","ac8ca8a4":"dftrain['sex'].unique()","809dca74":"CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n                       'embark_town', 'alone']\nNUMERIC_COLUMNS = ['age', 'fare']\n\nfeature_columns = []\nfor feature_name in CATEGORICAL_COLUMNS:\n  vocabulary = dftrain[feature_name].unique()\n  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n\nfor feature_name in NUMERIC_COLUMNS:\n  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n\nprint(feature_columns)","8ed28ecc":"def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n  def input_function():  # inner function, this will be returned\n    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n    if shuffle:\n      ds = ds.shuffle(1000)  # randomize order of data\n    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n    return ds  # return a batch of the dataset\n  return input_function  # return a function object for use\n\ntrain_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\neval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n","3faaa77a":"linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n# We create a linear estimtor by passing the feature columns we created earlier","109d4ac7":"linear_est.train(train_input_fn)  # train\nresult = linear_est.evaluate(eval_input_fn)  # get model metrics\/stats by testing on tetsing data\n\nclear_output()\nprint(result['accuracy'])  # the result variable is simply a dict of stats about our model\nprint(result)","d745c586":"pred_dicts = list(linear_est.predict(eval_input_fn))\n\nclear_output()\n\nres_count = 0;\ntimes_try = 20;\n\nfor i in range(0,times_try):\n    pred = pred_dicts[i]['probabilities'][1] # 1 means survival, check this carefully\n    real = y_eval.loc[i]\n    if (abs(pred - real) <= 0.5):\n        res = \"True\"\n        res_count += 1\n    else:\n        res = \"False\"\n    print(\"Predict: \" + str(pred) + \"\\tReal: \" + str(real) + \"\\t >> \" + res)\n\nprint(\"Accuracy: \" + str(res_count\/times_try))","88c5dc0d":"probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n\nclear_output()\nprobs.plot(kind='hist', bins=20, title='predicted probabilities')","b96c5b5d":"train_path = tf.keras.utils.get_file(\n    \"iris_training.csv\", \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/data\/iris_training.csv\")\ntest_path = tf.keras.utils.get_file(\n    \"iris_test.csv\", \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/data\/iris_test.csv\")\n# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe\n\nCSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\nSPECIES = ['Setosa', 'Versicolor', 'Virginica']\n\ntrain = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\ntest = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n\ntrain.head()","6d0a563b":"train_y = train.pop('Species')\ntest_y = test.pop('Species')\ntrain.head() # the species column is now gone","bcdc5534":"train.shape  # we have 120 entires with 4 features","c2359db3":"def input_fn(features, labels, training=True, batch_size=256):\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle and repeat if you are in training mode.\n    if training:\n        dataset = dataset.shuffle(1000).repeat()\n    \n    return dataset.batch(batch_size)","c9ac8c49":"# Feature columns describe how to use the input.\nmy_feature_columns = []\nfor key in train.keys():\n    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\nprint(my_feature_columns)","c3a4cc72":"# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    # Two hidden layers of 30 and 10 nodes respectively.\n    hidden_units=[30, 10],\n    # The model must choose between 3 classes.\n    n_classes=3)","7defee43":"classifier.train(\n    input_fn=lambda: input_fn(train, train_y, training=True),\n    steps=5000)\n# We include a lambda to avoid creating an inner function previously","a89e7fad":"eval_result = classifier.evaluate(\n    input_fn=lambda: input_fn(test, test_y, training=False))\n\nprint('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))","3976f316":"def input_fn(features, batch_size=256):\n    # Convert the inputs to a Dataset without labels.\n    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n\nfeatures = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\npredict = {}\n\nprint(\"Please type numeric values as prompted.\")\nfor feature in features:\n  valid = True\n  while valid: \n    val = input(feature + \": \")\n    if not val.isdigit(): valid = False\n\n  predict[feature] = [float(val)]\n\npredictions = classifier.predict(input_fn=lambda: input_fn(predict))\nfor pred_dict in predictions:\n    class_id = pred_dict['class_ids'][0]\n    probability = pred_dict['probabilities'][class_id]\n\n    print('Prediction is \"{}\" ({:.1f}%)'.format(\n        SPECIES[class_id], 100 * probability))\n","e629119e":"### Handle data","648a2ec3":"### Create the model","7f3f83e7":"### Train the model","9ede7bc8":"### Train the model","1b2603b0":"# Linear Regression","f2e3a761":"### Input data","52abe2d2":"# Classification","6d308cde":"### Simple prediction","e8692089":"### Build the model"}}