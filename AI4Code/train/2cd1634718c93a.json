{"cell_type":{"54af4215":"code","e3d67de0":"code","4d4d01ab":"code","7b9d9ebc":"code","a2a69152":"code","295d18f9":"code","7f687b60":"code","44855b23":"code","75362dc1":"code","60eb17b0":"code","efa059c2":"code","e1dadfc0":"code","b6e6c739":"code","f12afdf2":"code","1a5b99ba":"code","31c75595":"code","29cc3cfd":"code","3d78e4f6":"code","9bae9f56":"code","9a92c940":"markdown","61c45c73":"markdown","a610cd6b":"markdown","29944305":"markdown","ac545e90":"markdown","1190a9f8":"markdown","7163dd54":"markdown","af681ee2":"markdown","926ac0d5":"markdown","747a778d":"markdown","b75c4007":"markdown","419e467e":"markdown","87f1284a":"markdown","61dfc458":"markdown","65f315fb":"markdown","4f94be7c":"markdown","ee506bf9":"markdown","637cb2ad":"markdown","7385f498":"markdown"},"source":{"54af4215":"IS_LONG = True\nIS_TUNING = False\nIS_AUGMENTING = False","e3d67de0":"import os\nimport shutil\n\n# TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom kerastuner import RandomSearch\nfrom kerastuner.engine.hyperparameters import HyperParameters\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras import backend as K\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport imageio\nimport random\n\nsns.set()","4d4d01ab":"train_dir = '\/kaggle\/input\/insa-ml-deep-project\/start_deep_png_short\/train_images\/' if not IS_LONG else '\/kaggle\/input\/insa-ml-deep-project\/start_deep_png_long\/train_images\/'\ntest_dir = '\/kaggle\/input\/insa-ml-deep-project\/start_deep_png_short\/test_images\/' if not IS_LONG else '\/kaggle\/input\/insa-ml-deep-project\/start_deep_png_long\/test_images\/'\nworking_dir = '\/kaggle\/working'\n\nimg_height = 36\nimg_width = 36\nbatch_size = 32","7b9d9ebc":"# Load the dataset\ndef load_data():\n    train_datagen = ImageDataGenerator(\n        rescale=1.\/255, \n        validation_split=0.3,\n        shear_range=0.2,\n        zoom_range=0.2,\n    )\n    test_datagen = ImageDataGenerator(\n        rescale=1.\/255\n    )\n    \n    print (\"Training image data : \")\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='binary',\n        subset='training',\n        color_mode='grayscale')\n    \n    print (\"Validation image data : \")\n    validation_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='binary',\n        subset='validation',\n        color_mode='grayscale')\n    \n    print (\"Test image data : \")\n    test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='binary',\n        shuffle=False,\n        color_mode='grayscale')\n\n    \n    return train_generator, validation_generator, test_generator\n\ntrain_generator, validation_generator, test_generator = load_data()","a2a69152":"(unique, counts) = np.unique(train_generator.labels, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\nprint (frequencies)\nsns.barplot(x=unique, y=counts)\nplt.ylabel('Samples')\nplt.xlabel('Class')\nplt.title('Number of non-face images (0) and face images (1) in train data')","295d18f9":"(unique, counts) = np.unique(test_generator.labels, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\nprint (frequencies)\nsns.barplot(x=unique, y=counts)\nplt.title('Number of non-face images (0) and face images (1) in test data')\nplt.ylabel('Samples')\nplt.xlabel('Class')","7f687b60":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))\n\ndef build_model(hp):\n    model = keras.models.Sequential()\n    \n    if IS_TUNING:\n        model.add(keras.layers.Conv2D(\n            activation='relu', input_shape=(36, 36, 1),\n            filters=hp.Int('conv_1_filter', min_value=8, max_value=64, step=8),\n            kernel_size=hp.Choice('conv_1_kernel', values = [3,5])),\n        )\n        model.add(keras.layers.MaxPooling2D((2, 2)))\n        model.add(keras.layers.Conv2D(\n            activation='relu',\n            filters=hp.Int('conv_2_filter', min_value=8, max_value=128, step=8),\n            kernel_size=hp.Choice('conv_2_kernel', values = [3,5])),\n        )\n        model.add(keras.layers.MaxPooling2D((2, 2)))\n        model.add(keras.layers.Flatten())\n        model.add(keras.layers.Dense(\n            units=hp.Int('dense_1_units', min_value=8, max_value=128, step=8),\n            activation='relu'\n        )),\n        model.add(keras.layers.Dense(2, activation='softmax'))\n        model.compile(optimizer='adam',\n                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  metrics=['accuracy'])\n    else:\n        model.add(keras.layers.Conv2D(36, (3, 3), activation='relu', input_shape=(36, 36, 1)))\n        model.add(keras.layers.MaxPooling2D((2, 2)))\n        model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n        model.add(keras.layers.MaxPooling2D((2, 2)))\n        model.add(keras.layers.Flatten())\n        model.add(keras.layers.Dense(40, activation='relu'))\n        model.add(keras.layers.Dense(2, activation='softmax'))\n        model.compile(\n                #optimizer=keras.optimizers.SGD(),\n                optimizer='adam',\n                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=['accuracy'])\n    return model","44855b23":"if IS_TUNING: \n    tuner_search = RandomSearch(build_model,objective='val_accuracy',max_trials=15,directory=working_dir,project_name=\"DEEP\")","75362dc1":"if IS_TUNING:\n    start = time.time()\n    tuner_search.search(train_generator,epochs=4,validation_data=validation_generator)\n    end = time.time()\n    print(\"Time to tune model : \", end-start)","60eb17b0":"model = tuner_search.get_best_models(num_models=1)[0] if IS_TUNING else build_model(None)\nmodel.summary()","efa059c2":"epochs = 10","e1dadfc0":"callbacks = [\n    keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n        min_delta=1e-3,\n        patience=3,\n        verbose=1,\n    )\n]\nstart = time.time()\n#history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, class_weight = {0:2.4, 1:1}, callbacks=callbacks)\nhistory = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, verbose=2, class_weight = {0:1, 1:1.2})\nend = time.time()\nprint(\"Time to train model : \", end-start)","b6e6c739":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['loss'], label = 'loss')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Indicators')\nplt.ylim([0, 1])\nplt.title('Evolution of indicators against train and validation sets')\nplt.legend(loc='lower right')","f12afdf2":"Y_pred = model.predict(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(test_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['Non-face', 'Face']\nprint(classification_report(test_generator.classes, y_pred))","1a5b99ba":"faces_classified_as_nonfaces = []\nnonfaces_classified_as_faces = []\nfaces_classified_as_faces = []\n\nfor i in range(len(y_pred)):\n    if (test_generator.classes[i]==1):\n        if (y_pred[i]==0):\n            faces_classified_as_nonfaces.append(test_generator._filepaths[i])\n        else:\n            faces_classified_as_faces.append(test_generator._filepaths[i])\n    else:\n        if (y_pred[i]==1):\n            nonfaces_classified_as_faces.append(test_generator._filepaths[i])\n\nprint(\"Number of faces classified as nonfaces :\", len(faces_classified_as_nonfaces))\nprint(\"Number of nonfaces classified as faces :\", len(nonfaces_classified_as_faces))\nprint(\"Number of faces classified as faces :\", len(faces_classified_as_faces))","31c75595":"def plot_results(file_paths):\n    length = 20 if len(file_paths)>19 else len(file_paths)\n    randomList = random.sample(range(0, len(file_paths)), length)\n    num_rows = 4\n    num_cols = 5\n    num_images = length\n    plt.figure(figsize=(2*num_cols, 2*num_rows))\n    for i in range(num_images):\n        plt.subplot(num_rows, num_cols, i+1)\n        image = imageio.imread(file_paths[randomList[i]])\n        plt.imshow(image, cmap='gist_gray')\n    plt.tight_layout()\n    plt.grid(False)\n    plt.show()","29cc3cfd":"plot_results(faces_classified_as_faces)","3d78e4f6":"plot_results(faces_classified_as_nonfaces)","9bae9f56":"plot_results(nonfaces_classified_as_faces)","9a92c940":"## Get best model","61c45c73":"2. Faces classified as non-faces","a610cd6b":"# Study the results\n\n## Getting samples to study","29944305":"## Data visualization","ac545e90":"On test data","1190a9f8":"## Visualizing results","7163dd54":"## Address class imbalance","af681ee2":"## Load the data","926ac0d5":"#### Confusion Matrix and Classification Report","747a778d":"1. Correctly classified faces","b75c4007":"## Create and compile model","419e467e":"# Evaluate model","87f1284a":"3. Non-faces classified as faces","61dfc458":"## Setup Hyperparameter Tuner","65f315fb":"## Dependencies","4f94be7c":"## Execute Tuner","ee506bf9":"### Evolution of accuracy","637cb2ad":"### Testing class balance\n\nOn training and validation data","7385f498":"## Train model"}}