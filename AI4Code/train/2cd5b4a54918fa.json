{"cell_type":{"19a8f400":"code","447f29da":"code","6d11ad1a":"code","e3a87e17":"code","b1a75a2d":"code","534e9bb5":"code","61adb954":"code","a192c981":"code","21ab8b02":"code","9100765b":"code","e4ebc04e":"code","504a1d5a":"code","c70bf091":"code","755fa50c":"code","92c336ec":"code","3ee17c2f":"code","d28fa6a1":"code","c822878b":"code","e530c4ee":"code","22badd06":"code","c5f34122":"code","1e47e90b":"code","2897b414":"markdown","2bac1154":"markdown","47fa4fa9":"markdown","3757da3a":"markdown","8bf61c61":"markdown","e59c620a":"markdown","d239c8de":"markdown","f2e7dc17":"markdown","9290054e":"markdown","f17e0f54":"markdown","acd30567":"markdown","c014cd1c":"markdown","e46f5434":"markdown","b76d86ea":"markdown","25dce16e":"markdown","3bf1fe92":"markdown","cfa15434":"markdown","8b57b656":"markdown","02483048":"markdown","a50556c2":"markdown","f6b8ce63":"markdown","5b118afd":"markdown"},"source":{"19a8f400":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # Seaborn visualization library\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import RobustScaler\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","447f29da":"heart_df = pd.read_csv(\"\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")","6d11ad1a":"heart_df.shape","e3a87e17":"heart_df.sample(6)","b1a75a2d":"heart_df.isnull().sum().sort_values(ascending=False)[:]","534e9bb5":"heart_df.isna().any()","61adb954":"heart_df.nunique()","a192c981":"heart_df.describe()","21ab8b02":"heart_df.dtypes","9100765b":"# Compute the correlation matrix\ncorr = heart_df.corr(method ='pearson')\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","e4ebc04e":"heart_df.corr(method ='pearson')","504a1d5a":"# Plot counts vs. cat features\nsig_cat_feats = [\"cp\", \"exng\", \"caa\"]\nfor i in sig_cat_feats:\n    sns.set_theme(style=\"darkgrid\")\n    ax = sns.countplot(data=heart_df, x=i)\n    plt.show()","c70bf091":"sns.set_theme(style=\"darkgrid\")\nax = sns.countplot(data=heart_df, x=\"output\")\nplt.show()","755fa50c":"# Breakdown the data frame into attributes and label\nX = heart_df.drop('output', axis=1)\ny = heart_df['output']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","92c336ec":"numeric_transformer = Pipeline(steps=[\n    ('scaler', RobustScaler())])","3ee17c2f":"categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])","d28fa6a1":"heart_df.head()","c822878b":"numerical_feats = [\"age\", \"trtbps\", \"chol\", \"thalachh\", \"oldpeak\"]\ncategorical_feats = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exng\", \"slp\", \"caa\", \"thall\"]","e530c4ee":"# Data cleaning and transforming\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numerical_feats),\n        ('cat', categorical_transformer, categorical_feats)])","22badd06":"# Run multiple models and compare\nclassifiers = [\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    KNeighborsClassifier(),\n    LogisticRegression(),\n    ]","c5f34122":"print(\"** Following results reflect classifier models **\")\nclassif_list = []\nacc_list = []\nfor classifier in classifiers:\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', classifier)])\n    pipe.fit(X_train, y_train)   \n    \n    # Predict the test labels\n    preds = pipe.predict(X_test)\n    \n    # Calculate the accuracy and cofussion matrix\n    acc_score = accuracy_score(y_test, preds)\n    conf_matrix = confusion_matrix(y_test, preds)\n    \n    # Calculate how many preidctions were right and wrong\n    n_labels_right = accuracy_score(y_test, preds, normalize=False)\n    n_labels_total = y_test.size\n      \n    # Print details of classifiers, accuracy and cofussion matrix\n    print(\"-------------------------------------------\")\n    print(classifier)\n    print(\"Accuracy: \", acc_score*100)\n    print(\"Predictions correct = \", n_labels_right)\n    print(\"Predictions wrong   = \", n_labels_total - n_labels_right)\n    print(\"Confussion matrix = \\n\", conf_matrix)\n    \n    # Put classifier and accuracy in list to extract the best at the end\n    classif_list.append(classifier)\n    acc_list.append(acc_score*100)","1e47e90b":"# Output the best model by accuracy\nprint(\"-------------------------------------------\")\nprint(\"** The Best Model Goes to ... **\")\nbest_acc = max(acc_list)\nindex = acc_list.index(max(acc_list))\nbest_classif = classif_list[index]\nprint(\"The best accuracy model = \", best_classif)\nprint(\"With an accuracy = \", best_acc)\nprint(\"Complete.\")","2897b414":"**Lets split up the data:\ntrain = 75%  |  test = 25%**","2bac1154":"# Hi there, to get started lets import and visualize the data","47fa4fa9":"**Couple features that I want to label as categories since some are disretized (sex, cp, fbs, restecg, exng, slp, caa, thall)**","3757da3a":"**List the classifiers as a list (will be easy to go back and add classifiers)**","8bf61c61":"**Lets look at the features**","e59c620a":"**Any values missing?**","d239c8de":"**Lets see how much data we workin with**","f2e7dc17":"**Small dataset but nothing to worry about**","9290054e":"**Some features are displaying some correlation - gives us hope we may have good data to train the model on**","f17e0f54":"# Okay enough data drooling, lets split the data and preprocess","acd30567":"**Lets check out how balanced the labels are (labels = prone to a heart attack or not)**","c014cd1c":"**Combine the category and numerical transformers as a preprocessor**","e46f5434":"**Breakdown heart dataframe into categories and numeric sections - this will prep the data for the pipeline**","b76d86ea":"**Pretty balanced, way better than the stroke dataset I worked on previously**","25dce16e":"**See which model predicted the best**","3bf1fe92":"**Loop through the classifiers and run Pipeline and fit functions on the trainig set then predict test set based on the model**","cfa15434":"**Correlation time**","8b57b656":"**Set up pipelines:\nScale the integer features,\nCategorize the discrete features with OneHot** ","02483048":"# Model and Run","a50556c2":"**Import the data**","f6b8ce63":"**Specifically features cp, thalachh, excng, old peak and caa may have signifigance. Plotting the categories will diplay if the counts are balanced**","5b118afd":"**Hm complete dataset, right on**"}}