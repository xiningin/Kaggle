{"cell_type":{"bb83c5d7":"code","844b8434":"code","7bb16d09":"code","42d6d53a":"code","bed181f2":"code","aea32f88":"code","4a940490":"code","8afb9a3e":"code","bdd1d715":"code","2cf216fe":"code","dddbb728":"code","dad1410e":"code","cab2d52a":"code","540b9bcc":"code","d35724b4":"code","36bd772c":"code","2310c6bb":"code","a99cd9ab":"code","6b204e71":"code","93e37067":"code","2dbc6df5":"code","c5dc7402":"code","895deea5":"code","0e040bc6":"code","06e00980":"code","6df4cd03":"code","a937dce2":"code","0b7c5f9f":"markdown","5ac3ecc6":"markdown","892b796a":"markdown","bf921ac2":"markdown","9206fc66":"markdown","6e7058ed":"markdown","9be734e5":"markdown","7722d3a9":"markdown","aea2c1fa":"markdown","a085c885":"markdown","f4bae0d4":"markdown","16eeab00":"markdown","081e6579":"markdown","a68b190c":"markdown","6352d999":"markdown","a59c6ade":"markdown","9eb4843b":"markdown","53f97724":"markdown","7d5ad87d":"markdown","502fdb38":"markdown","42ee8a49":"markdown","542b4668":"markdown","c6f3d277":"markdown","d4f510ea":"markdown","bece0a03":"markdown","18e2f186":"markdown","88642a6d":"markdown","eb029105":"markdown","029803f9":"markdown","48d66519":"markdown","ad44f567":"markdown","caf49f9b":"markdown","21a5d516":"markdown","68d43399":"markdown","df0c5d8c":"markdown","69163d7a":"markdown","ef0d239b":"markdown","46415d1f":"markdown","a22f5f5b":"markdown"},"source":{"bb83c5d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","844b8434":"#import librares\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","7bb16d09":"#import dataset and pre-visualize it.\ndata = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx', sheet_name='All')\ndata.head()","42d6d53a":"# percentage of negative and postive\ncount1 = data.loc[data[data.columns[2]]== 'negative'][data.columns[2]].shape[0]\ncount2 = data.loc[data[data.columns[2]]== 'positive'][data.columns[2]].shape[0]\nprint('negative values is :', round(count1*100\/(count1+count2), 1), '% in dataset')\nprint('positive values is :', round(count2*100\/(count1+count2), 1), '% in dataset')","bed181f2":"#copy dataset for df dataframe\ndf = data.copy()\n\n#define a dictionary to storage original columns names\ncol_names ={}\n\n#define first 3 column manually\ncolumns =['patient', 'f1', 'result' ]\n\n#save first 3 column original names in dictionary\ncol_names = {'patient': data.columns[0], 'f1': data.columns[1], 'result': data.columns[2]}\n\n#define new columns names as f2, f3,...and save original name in dictionary\nfor i in range(3, 111):\n    new_name = 'f' + str(i-1)\n    columns.append(new_name)\n    col_names.update( {new_name : data.columns[i]})\n\n#change columns names\ndf.columns = columns\n\n#remove patient column from df dataframe\ndf = df.drop('patient', axis = 1)\n\n#result\ndf.head()","aea32f88":"#change value of result columns as negative to 0, and positive to 1\ndf['result'] = [0 if a == 'negative' else 1 for a in df['result'].values]\ndf.head()","4a940490":"#modify some NAN value to -99 and change string value to numbers\n\n#to make some change possible I changed null value to -99\ndf = df.replace(np.nan, -99)\n\ndf = df.replace('not_detected', 0)\ndf = df.replace('detected', 1)\ndf = df.replace('negative', 0)\ndf = df.replace('absent', 0)\ndf = df.replace('normal', 0)\ndf = df.replace('Ausentes', 0)\ndf = df.replace('clear', 0)\ndf = df.replace('positive', 1)\ndf = df.replace('present', 1)\ndf = df.replace('not_done', -99) #it's look like null value\n\ndf.iloc[:,87] = df.iloc[:,87].replace('light_yellow', 0)\ndf.iloc[:,87] = df.iloc[:,87].replace('yellow', 1)\ndf.iloc[:,87] = df.iloc[:,87].replace('light_yellow', 2)\ndf.iloc[:,87] = df.iloc[:,87].replace('citrus_yellow', 3)\ndf.iloc[:,87] = df.iloc[:,87].replace('orange', 4)\n\ndf.iloc[:, 81] = df.iloc[:, 81].replace('<1000', '1000')\ndf.iloc[:, 81] = df.iloc[:, 81].replace('', '1000')\ndf.iloc[:, 81] = df.iloc[:, 81].astype('int32')\n\ndf.iloc[:, 71] = df.iloc[:, 71].replace('cloudy', 0)\ndf.iloc[:, 71] = df.iloc[:, 71].replace('lightly_cloudy', 1)\ndf.iloc[:, 71] = df.iloc[:, 71].replace('lightly', 2)\ndf.iloc[:, 71] = df.iloc[:, 71].replace('altered_coloring', 3)\n\ndf.iloc[:, 82] = df.iloc[:, 82].replace('Urato Amorfo --+', 0)\ndf.iloc[:, 82] = df.iloc[:, 82].replace('Urato Amorfo +++', 1)\ndf.iloc[:, 82] = df.iloc[:, 82].replace('Oxalato de C\u00e1lcio -++', 2)\ndf.iloc[:, 82] = df.iloc[:, 82].replace('Oxalato de C\u00e1lcio +++', 3)\n\ndf.iloc[:, 72] = df.iloc[:, 72].replace('N\u00e3o Realizado', 0)\ndf.iloc[:, 72] = df.iloc[:, 72].astype('float')\n\n#change back -99 to null value\ndf = df.replace(-99, np.nan)","8afb9a3e":"#The result\ndf.head()","bdd1d715":"#remove f2, f3, f4, leave just result and lab\ndf = df.drop(['f2', 'f3', 'f4'], axis = 1)\ndf.head()","2cf216fe":"#change NULL to -99\ndf = df.replace(np.nan, -99)\n\n#create a list for storage feature filtered.\nfeatures_filtered = list()\nfeatures_filtered.append('result')\n\n#get columns of the dataset\ncols = list(df.columns)\n\n#remove feature result of the cols list.\ncols.remove('result')\n\n#starting to filtering feature by feature\nfor name in cols:\n    #get count1 - number of valid values of actural feature for positive samples \n    result1 = df.loc[(df[name] != -99) & (df['result'] == 1)]\n    count1 = len(result1.loc[:,[name, 'result']])\n    \n    #get count2 - count2 = number of valid values of actural feature for negative samples\n    result2 = df.loc[(df[name] != -99) & (df['result'] == 0)]\n    count2 = len(result2.loc[:,[name, 'result']])\n    \n    if (count1 + count2) > 0:                       #first filter\n        if (count1*100\/(count1 + count2) >= 9):    #second filter\n            if (count2 >= 500):                     #third filter\n                features_filtered.append(name)      #storage name of feature\n                \n\n#after correlation analyzis I decided to remove  f9 because it is correlatated with f5\nfeatures_filtered.remove('f9')\n\n#change -99 to NULL values\ndf = df.replace(-99, np.nan)\nprint(features_filtered)","dddbb728":"#change -99 values to null value to remove it\ndf = df.replace(-99,np.nan)\n\n#create new Dataframe with selected features\ndf_filtered = df[features_filtered]\n\n#remove null values - whole line\ndf_filtered = df_filtered.dropna()\n\n#results\ndf_filtered.head(), df_filtered.shape","dad1410e":"df_filtered.head()","cab2d52a":"# percentage of negative and postive\ncount1 = df_filtered.loc[df_filtered['result']== 0]['result'].shape[0]\ncount2 = df_filtered.loc[df_filtered['result']== 1]['result'].shape[0]\nprint('negative values is :', round(count1*100\/(count1+count2), 1), '% in dataset')\nprint('positive values is :', round(count2*100\/(count1+count2), 1), '% in dataset')","540b9bcc":"#import library\nfrom sklearn.model_selection import train_test_split\n\n#copy dataframe to X and y\nX = df_filtered.copy()\nX = X.drop('result', axis = 1)\ny = df_filtered.loc[:,'result']\n\n#split dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state = 0)\n\n#reset index\nX_train.reset_index(drop = True, inplace = True)\nX_test.reset_index(drop = True, inplace = True)\ny_train.reset_index(drop = True, inplace = True)\ny_test.reset_index(drop = True, inplace = True)\n\n#train data set with results\ntrain_dataset = X_train.copy()\ntrain_dataset['result'] = y_train","d35724b4":"import matplotlib.pyplot as plt\nimport numpy as np\ntrain_dataset.hist(bins=10, figsize= (20,15))\nplt.show()","36bd772c":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\n#normalize basend on train data (X_train)\nX_t = scaler.fit_transform(X_train)\nX_t = pd.DataFrame(X_t)\nX_t.columns = X_train.columns\nX_train = X_t.copy()\n\n#normalize test data basend on train data (X_train)\nX_t = scaler.transform(X_test)\nX_t = pd.DataFrame(X_t)\nX_t.columns = X_test.columns\nX_test = X_t.copy()\n\n#show histogram for all features\nX_train.hist(bins=10, figsize= (20,15))\nplt.show()","2310c6bb":"#create a new dataframe with just train data include result one it. It for correlation.\ntrain_dataset = X_train.copy()\ntrain_dataset['result'] = y_train\n\n#correlation graphic\ncorr = train_dataset.corr('pearson', 2)\nf, ax = plt.subplots(figsize=(24, 18))\nsns.heatmap(corr, vmax=.8, square=True, cmap='RdYlBu')\n","a99cd9ab":"corr.head(50)","6b204e71":"import seaborn as sns\n\nn=len(train_dataset.columns)\nfig,ax = plt.subplots(n,1, figsize=(6,n*2), sharex=True)\nfor i in range(n):\n    plt.sca(ax[i])\n    col = train_dataset.columns[i]\n    sns.violinplot(x='result', y=col, data=train_dataset, split=False)\n","93e37067":"#Features combinations (Thanks Marcio filho for this code)\nfrom itertools import combinations\ncombos_ = []\nfor f1,f2 in combinations(X_train.columns, 2):\n    f1_ = X_train[f1].corr(y_train)\n    f2_ = X_train[f2].corr(y_train)\n    f1_f2 = ((X_train[f2] - X_train[f1])).corr(y_train)\n    best_single = max(abs(f1_), abs(f2_))\n    combo_score = abs(f1_f2)\n    \n    res = dict()\n    res['f1'] = f1\n    res['f2'] = f2\n    res['f1_'] = f1_\n    res['f2_'] = f2_\n    res['f1_f2_'] = f1_f2 \n    res['f1_f2'] = combo_score - best_single\n    combos_.append(res)\ndf_combos = pd.DataFrame(combos_).sort_values(\"f1_f2\", ascending=False)\ndf_combos = df_combos[df_combos['f1_f2'] > 0.01]\nprint(df_combos.shape)\ndf_combos.head(5)","2dbc6df5":"#create new feature in train data\nX_train['f15_f17'] = X_train['f17'] - X_train['f15']\nX_train['f14_f16'] = X_train['f16'] - X_train['f14']\n\n#create new feature in test data\nX_test['f15_f17'] = X_test['f17'] - X_test['f15']\nX_test['f14_f16'] = X_test['f16'] - X_test['f14']\n\n#updata dictionary of original names features\nnew_name = 'f15_f17'\ncol_names.update( {new_name : col_names['f15'] + ' and ' + col_names['f17']})\n\nnew_name = 'f14_f16'\ncol_names.update( {new_name : col_names['f14'] + ' and ' + col_names['f16']})","c5dc7402":"from lightgbm import LGBMClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom skopt import gp_minimize\n\ndef my_kappa (model, X, y):\n    y_pred = model.predict(X)\n    from sklearn.metrics import cohen_kappa_score\n    kappa = cohen_kappa_score(y, y_pred)\n    return kappa\n\ndef train_model(params):\n    \n    model = LGBMClassifier(learning_rate= params[0], num_leaves= params[1], min_child_samples=params[2],\n                           subsample=params[3], colsample_bytree=params[4], n_estimators=params[5], random_state=0,\n                           subsample_freq=1)\n\n    scores = cross_val_score(estimator = model, X = X_train, y = y_train, scoring= my_kappa, cv = 5, verbose = 0)\n\n    mean_score = np.mean(scores)\n\n    return -mean_score\n\nparams =     [(1e-3, 1e-1, 'log-uniform'), # learning rate\n              (2, 128),                    # num_leaves\n              (1, 100),                    # min_child_samples\n              (0.05, 1.0),                 # subsample\n              (0.1, 1.0),                  # colsample bytree\n              (100, 1000)]                 # number of tree\n\n#search for better params\nopt = gp_minimize(train_model, params, random_state=0, verbose=1, n_calls=50, n_random_starts=10)\n\nprint (\"best kappa\", opt.fun)\nprint(\"best params\", opt.x)\n","895deea5":"\nmodel = LGBMClassifier(learning_rate= opt.x[0], num_leaves= opt.x[1], min_child_samples=opt.x[2],\n                           subsample=opt.x[3], colsample_bytree=opt.x[4], n_estimators=opt.x[5], random_state=0,\n                           subsample_freq=1)\n\nscores = cross_val_score(estimator = model, X = X_train, y = y_train, scoring= my_kappa, cv = 5, verbose = 1)\n\nmodel.fit(X_train, y_train)\n\nmean_score = np.mean(scores)\n\nprint(\"k-folds kappa \", scores)\nprint(\"mean kappa CV\", mean_score)","0e040bc6":"#confusion matrix with Train data\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n\n\ny_pred = model.predict(X_test)\n\nprint('summary report')\nprint(classification_report(y_test, y_pred))\nprint('confusion matrix')\nmc_test = confusion_matrix(y_test, y_pred)\nprint(mc_test)\nprint('kappa coeficient')\nkappa = cohen_kappa_score(y_test, y_pred)\nprint(kappa)\nprint('ROC_AUC score')\nroc_auc = roc_auc_score(y_test, y_pred)\nprint(roc_auc)\n","06e00980":"#confusion matrix with Train data\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n\n\ny_proba = model.predict_proba(X_test)\ny_pred = np.where(y_proba[:,0]> 0.999999, 0,1)\n\nprint('summary report')\nprint(classification_report(y_test, y_pred))\nprint('confusion matrix')\nmc_test = confusion_matrix(y_test, y_pred)\nprint(mc_test)\nprint('kappa coeficient')\nkappa = cohen_kappa_score(y_test, y_pred)\nprint(kappa)\nprint('ROC_AUC score')\nroc_auc = roc_auc_score(y_test, y_pred)\nprint(roc_auc)","6df4cd03":"cols = list(X_test.columns)\noriginal_names = list()\nfor name in cols:\n    original_names.append(col_names[name])\nX_test.columns = original_names\nX_test.head()","a937dce2":"import shap\nshap.initjs()\n# use Kernel SHAP to explain test set predictions\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\nshap.summary_plot(shap_values, X_test)","0b7c5f9f":"## 2.5 Create a filtered dataframe and remove null values","5ac3ecc6":"## 5.1 Change threshold of the probabily predict","892b796a":"This dataset has a lot of **negative values** for some features (is this numbers make sense?) and a lot of NaN values.\nnegative values is 90.1 % in dataset\npositive values is 9.9 % in dataset\n","bf921ac2":"# Goal: Predict confirmed COVID-19 cases among suspected cases","9206fc66":"## 2.4 Feature filtering","6e7058ed":"## 2.6 Split new dataset to train and test","9be734e5":"I used bayesian to optimize hiperparams of the Lightgbm algo. Cross-validation with 5 k-folds was used. The metrics was kappa coeficient.","7722d3a9":"# 1. Import some python librares","aea2c1fa":"## 3.2 Final LightGBM model - Cross-validation results","a085c885":"## 2.7 Histogram","f4bae0d4":"Add first three combination as new features in the train (X_train) and test data (X_test)","16eeab00":"## 2.1 Redefine features names","081e6579":"## 3.3 Results in test data","a68b190c":"After verified the correlation I dicided to remove f3, f4, f5, f9, f10 and f14 (topic 2.5 features filtering). I considered to remove low correlation with target and hight correlation between others features.\n","6352d999":"# Prepare the environment","a59c6ade":"# 3. Modeling using LightGBM","9eb4843b":"## 2.3 Change string columns to number","53f97724":"The result showed we can used some combination in the model. I will used first three in ranking","7d5ad87d":"# 6. interpretation","502fdb38":"Changed threshold to 99.9999% the recall change to 91% in test data. In this case Kappa was 13%, ROC_AUC was 67%, better then random classification. In this case we have 1 False Negative and the model classified correctaly 71 peaple with NO COVID-19. In another hand, the model incorrect classified with CoVid-19 (87 patient), so it is a suspect case with Covid-19. The model remove 71 cases of suspect case (45% recall for negative case). I believe this result could be improve much more using others features.","42ee8a49":"## Goal 1. Good general model highest Kappa coeficient as possible\n\n## Goal 2. Reduce false negative as possible by using ","542b4668":"I verified that the dataset has a lot of string. So I change each column carefully","c6f3d277":"## 2.8 Normalize all features","d4f510ea":"## 2.10 Features combinations","bece0a03":"General model showed in **TEST DATA** accuracy of 89%, ROC_AUC 65%, and Kappa 37% that means the model was better than random classification (in dataset we have 86.5% of negative result and 13.5% of positive result). The precision for positive result was 64% (false positive was 4). The recall was low, 32%, we got 15 false negative (FN), you can see this result in confusion matrix. We should increase the metrics **recall** because in this situation is better have false positive (FP) than false negative (FN). So, next step is to improve recall.\n","18e2f186":"Features original names","88642a6d":"## 2.9 Correlation","eb029105":"## 2.10 Visualization of features","029803f9":"## 3.1 Hiperparams Optimization ","48d66519":"False negative could be a problem. So I tried to reduce fase negative changing the thresholds. Threshold need to be 99% in probabily prediction to have recall 91%. So I used the threshold of 99.9999% to decid if patient is probabily have Covid-19.","ad44f567":"## 2.2 Change column result to number","caf49f9b":"## 5.2 Conclusion","21a5d516":"### Final dataset\n\n- 598 samples \n\n- 13 features\n\n- negative values is : 86.5 % in dataset\n\n- positive values is : 13.5 % in dataset","68d43399":"# 5. Reduce false negative","df0c5d8c":"## 3.4 Conclusion","69163d7a":"Violin graphics bellow we can see it not gonna be easy job. So, I will try some features combination in the next step.","ef0d239b":"Bellow we can seen feature importance in the model. As you can see new features (combinations features) got good ranking","46415d1f":"# 2. Import datasetageneral visualization","a22f5f5b":"After carefully verified the dataset, I concluded it has a lot of null values and a lot of features with low samples of negative and positive results of covid-19. So I filted the features. around 90.1% of data is negative, around 9.9% os positive. So, we have a lot of features with no representative in positive as in negative and vice-versa. So I made the filter in the dataset to remove this features.\n\ncount1 = number of valid values of current feature for positive samples\ncount2 = number of valid values of current feature for negative samples\n\na) First rule of filter: count1 + count2 > 0, for calculate the percentagem of postive count1\/(count1 + count2).\n\nb) Second rule of filter: feature should have at least 9% of positive: count1\/(count1 + count2) >= 0.09\n\nc) Third rule of filter. After verified the second rule, I dicide that 500 of count2 is good number of samples for features selected in second rule: count2 > = 500.\n\nd) Remove some feature that was not good in cross-validation (with low correlation with result and some feature correlated with others). So I removed f3, f4, f14, f10, f5, f9.\n\nPS: I choose this parameters of the filter after a lot of verifications in the dataset\n"}}