{"cell_type":{"324be2c1":"code","c970950f":"code","00f233bb":"code","42a4c497":"code","72e10d48":"code","965a7f08":"code","0a514c60":"code","9c7134a9":"code","2c30dda1":"code","84e6bead":"code","56086396":"code","9c3e0e2b":"code","22146132":"code","b81aa20a":"code","aafd38b0":"code","49f7eb72":"code","7dd110c5":"code","8599289a":"code","492a1dcf":"code","94ea0929":"code","d789ced0":"code","8b8d584b":"code","3ebfe4d4":"code","f63947db":"code","a92601df":"code","7beea8a3":"code","8425ac77":"code","68efa1b7":"code","5912f784":"code","b7db1ec8":"code","ec4e9882":"code","71e55a66":"code","9fe42a99":"code","0df10dcf":"code","27a30631":"code","0bed1161":"code","1738ebe6":"code","2ac39b7e":"code","9934d1e4":"code","c22dc13f":"code","03fb1c7e":"code","716d2be0":"code","cabaaf92":"code","ebd1d60c":"code","dcf6461e":"code","00a99ad6":"code","fdf4d84a":"code","3ee7eacd":"code","55b32677":"code","5cb718f7":"markdown","1093d187":"markdown","ce5bb201":"markdown","74e18ea0":"markdown","a3336e8b":"markdown","a9d4ea0e":"markdown","a70e1da1":"markdown","d48af540":"markdown","33e2d12c":"markdown","41017279":"markdown","7d495f44":"markdown","45f7eadb":"markdown","75728dfa":"markdown","0eaa2e9f":"markdown","c53e7b62":"markdown","84c486b9":"markdown","d9cc9a1a":"markdown","dd6aa618":"markdown","715af32e":"markdown","a6e5dc7c":"markdown","eb17c33b":"markdown"},"source":{"324be2c1":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error,r2_score\nfrom sklearn.model_selection import GridSearchCV\ndata=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata.head()\n","c970950f":"data.info()","00f233bb":"dropping_columns=[i for i in data.columns if (data[i].isnull().sum()\/len(data))*100>30]\n# dropping_columns.append('Id')\ndef drop_missing_columns(data):\n    data.drop(dropping_columns,axis=1,inplace=True)\ndrop_missing_columns(data)","42a4c497":"data.describe()","72e10d48":"data.describe(include='object')","965a7f08":"missing_data_object_column=[i for i in data.columns if data[i].isnull().sum()>0 and data[i].dtype=='O']\nmissing_data_numeric_column=[i for i in data.columns if data[i].isnull().sum()>0 and data[i].dtype!='O' and data[i].nunique()>20]\nmissing_categorical=[i for i in data.columns if data[i].isnull().sum()>0 and data[i].dtype!='O' and data[i].nunique()<20]\nmissing_categorical_data=missing_categorical+missing_data_object_column\ndef removing_missing_value(data):\n    for col in missing_categorical_data:\n        data[col].fillna(method='ffill',inplace=True)\n    for cols in missing_data_numeric_column:\n        data[cols].fillna(value=np.mean(data[cols]),inplace=True)\nremoving_missing_value(data)","0a514c60":"data.skew()","9c7134a9":"numeric_skew_data_name=[i for i in data.columns if data[i].dtype!='O' and data[i].skew()>2.5]","2c30dda1":"#Removing normalizing skew data\ndef remove_skewness(data):\n    for cols in numeric_skew_data_name:\n        data[cols]=data[cols].apply(lambda x: np.log(x+1))\n    return data\ndata=remove_skewness(data)","84e6bead":"data.describe()","56086396":"#categorical data\ncategories=[k for k in data.columns if data[k].dtype=='O']\nencode=[]\ndummy=[]\nfor col in categories:\n    if data[col].nunique()<=5:\n        dummy.append(col)\n    else:\n        encode.append(col)\n\nlbl1=LabelEncoder()\nlbl2=LabelEncoder()\nlbl3=LabelEncoder()\nlbl4=LabelEncoder()\nlbl5=LabelEncoder()\nlbl6=LabelEncoder()\nlbl7=LabelEncoder()\nlbl8=LabelEncoder()\nlbl9=LabelEncoder()\nlbl10=LabelEncoder()\nlbl11=LabelEncoder()\nlbl12=LabelEncoder()\nlbl13=LabelEncoder()\nlbl14=LabelEncoder()\nlbl15=LabelEncoder()\nlbl16=LabelEncoder()\ndef encodings(data):\n    for dummi in dummy:\n        variables=[]\n        variables=pd.get_dummies(data[dummi],drop_first=True)\n        data=pd.concat([data,variables],axis=1)\n        data.drop([dummi],inplace=True,axis=1)\n    data[encode[0]]=lbl1.fit_transform(data[encode[0]])\n    data[encode[1]]=lbl2.fit_transform(data[encode[1]])\n    data[encode[2]]=lbl3.fit_transform(data[encode[2]])\n    data[encode[3]]=lbl4.fit_transform(data[encode[3]])\n    data[encode[4]]=lbl5.fit_transform(data[encode[4]])\n    data[encode[5]]=lbl6.fit_transform(data[encode[5]])\n    data[encode[6]]=lbl7.fit_transform(data[encode[6]])\n    data[encode[7]]=lbl8.fit_transform(data[encode[7]])\n    data[encode[8]]=lbl9.fit_transform(data[encode[8]])\n    data[encode[9]]=lbl10.fit_transform(data[encode[9]])\n    data[encode[10]]=lbl11.fit_transform(data[encode[10]])\n    data[encode[11]]=lbl12.fit_transform(data[encode[11]])\n    data[encode[12]]=lbl13.fit_transform(data[encode[12]])\n    data[encode[13]]=lbl14.fit_transform(data[encode[13]])\n    data[encode[14]]=lbl15.fit_transform(data[encode[14]])\n    data[encode[15]]=lbl16.fit_transform(data[encode[15]])\n    return data\ndata=encodings(data)  ","9c3e0e2b":"duplicate_columns = data.columns[data.columns.duplicated()]\ndef delete_duplicate_columns(data):\n    data.drop(duplicate_columns,inplace=True,axis=1)\n    \n    return data\ndata=delete_duplicate_columns(data)","22146132":"data.drop(['NoSeWa','Mix'],axis=1,inplace=True)","b81aa20a":"correlation=data.corr()","aafd38b0":"for i,cols in enumerate(data.columns):\n    plt.figure(figsize=(10,8))\n    corr1=pd.DataFrame(data=correlation[[cols]].sort_values(by=cols,ascending=False)).iloc[:,:10]\n    sns.heatmap(corr1,vmin=-1)\n    plt.show()\n    if i>70:\n        break","49f7eb72":"output=data['SalePrice']\ndata.drop(['SalePrice'],axis=1,inplace=True)","7dd110c5":"train_data,test_data,train_price,test_price=train_test_split(data.iloc[:,1:],output,test_size=.25,random_state=42)","8599289a":"model1=DecisionTreeRegressor(random_state=42)\ngrid1=GridSearchCV(model1,param_grid={'max_depth':range(8,13)})\ngrid1.fit(train_data,train_price)","492a1dcf":"grid1.best_params_","94ea0929":"regressor1=DecisionTreeRegressor(random_state=42,max_depth=9)\nregressor1.fit(train_data,train_price)","d789ced0":"print(\"mean_squared_log Train Error is \",np.sqrt(mean_squared_log_error(train_price,regressor1.predict(train_data))))\nprint(\"mean_squared_log Test Error is \",np.sqrt(mean_squared_log_error(test_price,regressor1.predict(test_data))))\nprint('r2_score of train data is:-',r2_score(train_price,regressor1.predict(train_data)))\nprint('r2_score of test data is:-',r2_score(test_price,regressor1.predict(test_data)))","8b8d584b":"model2=RandomForestRegressor(random_state=42,max_depth=10)\ngrid2=GridSearchCV(model2,param_grid={'n_estimators':[50,100,150]})\ngrid2.fit(train_data,train_price)","3ebfe4d4":"grid2.best_params_","f63947db":"regressor2=RandomForestRegressor(random_state=42,n_estimators=50)\nregressor2.fit(train_data,train_price)","a92601df":"print(\"mean_squared_log Train Error is \",np.sqrt(mean_squared_log_error(train_price,regressor2.predict(train_data))))\nprint(\"mean_squared_log Test Error is \",np.sqrt(mean_squared_log_error(test_price,regressor2.predict(test_data))))\nprint('r2_score of train data is:-',r2_score(train_price,regressor2.predict(train_data)))\nprint('r2_score of test data is:-',r2_score(test_price,regressor2.predict(test_data)))","7beea8a3":"regressor3=LinearRegression()\nregressor3.fit(train_data,train_price)","8425ac77":"\nprint('r2_score of train data is:-',r2_score(train_price,regressor3.predict(train_data)))\nprint('r2_score of test data is:-',r2_score(test_price,regressor3.predict(test_data)))","68efa1b7":"model4=GradientBoostingRegressor(random_state=42)\ngrid4=GridSearchCV(model4,param_grid={'max_depth':[3,5,7],'tol':[.001,.01,.0001],'learning_rate':[.1,.2,.3]})\ngrid4.fit(train_data,train_price)","5912f784":"grid4.best_params_","b7db1ec8":"regressor4=GradientBoostingRegressor(random_state=42,learning_rate=.2,max_depth=7,tol=.001)\nregressor4.fit(train_data,train_price)","ec4e9882":"print(\"mean_squared_log Train Error is \",np.sqrt(mean_squared_log_error(train_price,regressor4.predict(train_data))))\nprint(\"mean_squared_log Test Error is \",np.sqrt(mean_squared_log_error(test_price,regressor4.predict(test_data))))\nprint('r2_score of train data is:-',r2_score(train_price,regressor4.predict(train_data)))\nprint('r2_score of test data is:-',r2_score(test_price,regressor4.predict(test_data)))","71e55a66":"model5=AdaBoostRegressor(random_state=42)\ngrid5=GridSearchCV(model5,param_grid={'learning_rate':[.1,.5,1,1.5],'n_estimators':[50,100]})\ngrid5.fit(train_data,train_price)","9fe42a99":"grid5.best_params_","0df10dcf":"regressor5=AdaBoostRegressor(random_state=42,n_estimators=100,learning_rate=1)\nregressor5.fit(train_data,train_price)","27a30631":"print(\"mean_squared_log Train Error is \",np.sqrt(mean_squared_log_error(train_price,regressor5.predict(train_data))))\nprint(\"mean_squared_log Test Error is \",np.sqrt(mean_squared_log_error(test_price,regressor5.predict(test_data))))\nprint('r2_score of train data is:-',r2_score(train_price,regressor5.predict(train_data)))\nprint('r2_score of test data is:-',r2_score(test_price,regressor5.predict(test_data)))","0bed1161":"model6=XGBRegressor(random_state=42)\ngrid6=GridSearchCV(model6,param_grid={'n_estimators':[50,100,150],'gamma':[0,.5,1]})\ngrid6.fit(train_data,train_price)","1738ebe6":"grid6.best_params_","2ac39b7e":"regressor6=XGBRegressor(random_state=42,n_estimators=50)\nregressor6.fit(train_data,train_price)","9934d1e4":"print(\"mean_squared_log Train Error is \",np.sqrt(mean_squared_log_error(train_price,regressor6.predict(train_data))))\nprint(\"mean_squared_log Test Error is \",np.sqrt(mean_squared_log_error(test_price,regressor6.predict(test_data))))\nprint('r2_score of train data is:-',r2_score(train_price,regressor6.predict(train_data)))\nprint('r2_score of test data is:-',r2_score(test_price,regressor6.predict(test_data)))","c22dc13f":"test=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest.head()","03fb1c7e":"test.info()","716d2be0":"drop_missing_columns(test)\nremoving_missing_value(test)\ntest.fillna(method='ffill',inplace=True)","cabaaf92":"test.info()","ebd1d60c":"test=encodings(test)\ntest=remove_skewness(test)","dcf6461e":"test.describe()","00a99ad6":"test=delete_duplicate_columns(test)","fdf4d84a":"test_id=test.iloc[:,0]\npredicted_price=regressor2.predict(test.iloc[:,1:])","3ee7eacd":"submission=pd.DataFrame({'Id':test_id,'SalePrice':predicted_price})\nsubmission.head()","55b32677":"submission.to_csv('my_submission_r.csv',index=False)","5cb718f7":"<a id=\"12\"><\/a>\n## LinearRegression","1093d187":"<a id=\"5\"><\/a>\n## Solving skewness of data","ce5bb201":"<a id=\"9\"><\/a>\n# Model selection and evaluation","74e18ea0":"<a id=\"2\"><\/a> \n# Feature Engineering","a3336e8b":"<a id=8><\/a>\n## Spliting Data","a9d4ea0e":"<a id=\"7\"><\/a>\n## Correlations of each column","a70e1da1":"<a id=\"13\"><\/a>\n## GradientBoostingRegressor","d48af540":"<a id=\"3\"><\/a> \n### Removing the columns whose more than 30% data are missing","33e2d12c":"<a id=\"1\"><\/a> \n## Importing modules and Loading datasets","41017279":"<a id=\"6\"><\/a>\n## Encoding the categorical data","7d495f44":"<a id=\"15\"><\/a>\n## XGBRegressor","45f7eadb":"<a id=\"11\"><\/a>\n## RandomForestRegressor","75728dfa":"**Thanks for watching my notebook if you have any query or suggestion feel free to suggest me in comment section.**","0eaa2e9f":"<a id=\"4\"><\/a> \n## Filling Missing Data","c53e7b62":"<a id=\"16\"><\/a>\n## conclusion","84c486b9":"### From the above scores it is evident that RandomForestRegressor and GradientBoostingRegressor are some suitable algorithms that can be used in prediction of sale price of housing data.","d9cc9a1a":"<html><head>\n\n\n<!-- Load require.js. Delete this if your page already loads require.js -->\n<script src=\"https:\/\/cdnjs.cloudflare.com\/ajax\/libs\/require.js\/2.3.4\/require.min.js\" integrity=\"sha256-Ae2Vz\/4ePdIu6ZyI\/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=\" crossorigin=\"anonymous\"><\/script>\n<script src=\"https:\/\/unpkg.com\/@jupyter-widgets\/html-manager@*\/dist\/embed-amd.js\" crossorigin=\"anonymous\"><\/script>\n<script type=\"application\/vnd.jupyter.widget-state+json\">\n{\n    \"version_major\": 2,\n    \"version_minor\": 0,\n    \"state\": {}\n}\n<\/script>\n<\/head>\n<body>\n\n\n<\/body>\n<\/html>\n","dd6aa618":"<a id=\"10\"><\/a>\n## DecisionTreeRegressor","715af32e":"<a id=\"17\"><\/a>\n## Prediction on test dataset","a6e5dc7c":"# Content:\n\n1. [Importing modules and Loading datasets](#1)\n1. [Feature Engineering](#2)\n   1. [Removing the columns whose more than 30% data are missing](#3)\n   1. [Filling Missing Data](#4)\n   1. [Solving skewness of data](#5)\n   1. [Encoding the categorical data](#6)\n   1. [Correlations of each column](#7)\n1. [Spliting Data](#8)\n1. [Model selection and evaluation](#9)\n    1. [DecisionTreeRegressor](#10)\n    1. [ RandomForestRegressor](#11)\n    1. [LinearRegression](#12)\n    1. [GradientBoostingRegressor](#13)\n    1. [ AdaBoostRegressor](#14)\n    1. [XGBRegressor](#15)\n1. [Conclusion](#16)   \n1. [Prediction on test dataset](#17)","eb17c33b":"<a id=\"14\"><\/a>\n## AdaBoostRegressor"}}