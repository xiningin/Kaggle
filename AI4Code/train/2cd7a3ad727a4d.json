{"cell_type":{"814fdad5":"code","408b021a":"code","ffaa5ae7":"code","bc8464b1":"code","590e0e59":"code","860545ed":"code","97123e7e":"code","37b488f4":"code","9e13a621":"code","67f4a769":"code","d615671b":"code","2cb56ab7":"code","1f2506f3":"code","c5ca66b1":"code","39901de1":"code","39d92b8d":"markdown","22c36109":"markdown","a70b2979":"markdown","b05a73d7":"markdown"},"source":{"814fdad5":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport gc\nimport os\nimport sklearn\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import *\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom category_encoders.ordinal import OrdinalEncoder\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve\nfrom sklearn.metrics import recall_score, classification_report, auc, roc_curve\nfrom sklearn.metrics import precision_recall_fscore_support, f1_score, roc_auc_score\n%matplotlib inline\n\nDATA_PATH = '..\/input\/israeli-polling-anomaly\/'\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))        ","408b021a":"# \u05d0\u05d7\u05d5\u05d6 \u05d4\u05d7\u05e1\u05d9\u05de\u05d4\nblock_percent = 0.015","ffaa5ae7":"df = pd.read_csv(DATA_PATH + 'votes_2019.csv', encoding='iso_8859_8')\ndf.head()","bc8464b1":"df = df.dropna(axis=0, how='any')\nprint(\"\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd:\", df['\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd'].sum())\nprint(\"\u05e4\u05e1\u05d5\u05dc\u05d9\u05dd:\", df['\u05e4\u05e1\u05d5\u05dc\u05d9\u05dd'].sum())\noverall_votes_per_party = df.iloc[:,7:].sum()","590e0e59":"percantage_vote_per_pary = overall_votes_per_party\/df['\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd'].sum()\npercantage_vote_per_pary.sort_values(ascending=False).plot.bar(alpha=0.7,figsize=(16,6))","860545ed":"percantage_vote_per_pary = overall_votes_per_party\/df['\u05de\u05e6\u05d1\u05d9\u05e2\u05d9\u05dd'].sum()\npercantage_vote_per_pary = percantage_vote_per_pary[percantage_vote_per_pary.values>block_percent]\npercantage_vote_per_pary.sort_values(ascending=False).plot.bar(alpha=0.7,figsize=(16,6))","97123e7e":"list(df.columns)","37b488f4":"df.head()","9e13a621":"## get one hot encodings of settlements - could also consdier dropping them due to sparsity...\ndf = pd.concat([df.drop([\"\u05e9\u05dd \u05d9\u05e9\u05d5\u05d1\",\"\u05e1\u05de\u05dc \u05d9\u05e9\u05d5\u05d1\"],axis=1),pd.get_dummies(df[\"\u05e9\u05dd \u05d9\u05e9\u05d5\u05d1\"])],axis=1)\nprint(df.shape)\ndf.tail()","67f4a769":"## try standard scaler - normalize, scale\nscl = StandardScaler()\ndf = scl.fit_transform(df)","d615671b":"# batch size 64  , Epoch 20\/20 - loss: 3.5530 - acc: 0.9974 - rounded_accuracy: 0.9115 - val_loss: 3.1404 - val_acc: 0.9977 - val_rounded_accuracy: 0.8568\n# batch size 16 :  Epoch 20\/20 - loss: 0.7925 - acc: 0.9977 - rounded_accuracy: 0.9502 - val_loss: 1.0724 - val_acc: 0.9972 - val_rounded_accuracy: 0.9817\n\ndef rounded_accuracy(y_true, y_pred):\n    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))\n\nK = keras.backend\ndef kl_divergence(p, q):\n    return p * K.log(p \/ q) + (1 - p) * K.log((1 - p) \/ (1 - q))\n\nclass KLDivergenceRegularizer(keras.regularizers.Regularizer):\n    def __init__(self, weight, target=0.1):\n        self.weight = weight\n        self.target = target        \n        \n    def __call__(self, inputs):\n        mean_activities = K.mean(inputs)\n        return self.weight * (\n            kl_divergence(self.target, mean_activities) +\n            kl_divergence(1. - self.target, 1. - mean_activities))\n    \n    def get_config(self):\n        return {\"weight\": self.weight, 'target': self.target}\n    \n    \ndef sparse_autoencoder(n_input):   \n    tf.random.set_random_seed(42)\n    np.random.seed(42)\n    kld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\n    sparse_kl_encoder = keras.models.Sequential([ keras.layers.Dense(64, activation=\"selu\", input_shape=(n_input,), kernel_initializer='lecun_normal'), keras.layers.Dense(300, activation=\"sigmoid\", activity_regularizer=kld_reg) ])\n    sparse_kl_decoder = keras.models.Sequential([keras.layers.Dense(64, activation=\"selu\", input_shape=[300], kernel_initializer='lecun_normal'), keras.layers.Dense(n_input, activation=None), ])\n    sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])\n    sparse_kl_ae.compile(loss=\"mean_squared_error\", optimizer='nadam', metrics=['acc', rounded_accuracy])\n\n    return sparse_kl_ae\n\n# train = df.values\ntrain = df\n\nX_train, X_val = train_test_split(train, test_size=0.2, shuffle=True)\n\nmodel = sparse_autoencoder(train.shape[1])\nlre = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',  patience=3,  verbose=1,  factor=0.5,  min_lr=0.00003)\nes = keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=6)\n\nmodel.fit(X_train, X_train, callbacks=[lre, es], validation_data=[X_val, X_val], batch_size=32, epochs=50, verbose=2)","2cb56ab7":"train_pred = model.predict(train)\n# preds = np.mean(np.power(train - train_pred, 2), axis=1) # ORIG\npreds = np.mean(train_pred, axis=1) # changed\nprint(preds.shape)","1f2506f3":"preds[0:3]","c5ca66b1":"train_pred[0:7]","39901de1":"sub = pd.read_csv(DATA_PATH + 'sample_sub.csv')\n# sub['poll'] = (preds == -1).astype(int) # ORIG\nsub['poll'] = preds # NEW - get probabilities\nsub.to_csv('submission.csv', index=False)","39d92b8d":"### Preprocessing","22c36109":"### Votes Distribution","a70b2979":"### Votes Distribution above block percent","b05a73d7":"### Anomaly Detection"}}