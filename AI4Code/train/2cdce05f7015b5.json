{"cell_type":{"a7ebf130":"code","9bd3b949":"code","1c02dee4":"code","297a8529":"code","fa71cf5f":"code","b76816f2":"code","e7e04b7b":"code","16f87806":"code","785dd1ce":"code","7fbf993f":"code","7eebc933":"code","8c9ecf28":"code","0cb9768b":"code","c19e29d5":"code","aa25ab72":"code","b691f2e2":"code","1a61bae3":"code","4b2e2a69":"code","5b2a241f":"code","00b2402c":"code","2ce3aa6b":"code","f121d8a6":"code","0b32a852":"code","3ba4eef0":"markdown","957cdb8b":"markdown","e991a293":"markdown","3dd6fc0e":"markdown","e50500a2":"markdown","6c0f00db":"markdown","8501bb54":"markdown","1ab6bff1":"markdown","30ebc72b":"markdown","0c88d8e5":"markdown","590269d8":"markdown"},"source":{"a7ebf130":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline","9bd3b949":"df = pd.read_csv(\"..\/input\/classifieddata\/Classified Data\",index_col=0)","1c02dee4":"df.head()","297a8529":"df.info()","fa71cf5f":"df.describe()","b76816f2":"from sklearn.preprocessing import StandardScaler","e7e04b7b":"scaler = StandardScaler()","16f87806":"scaler.fit(df.drop('TARGET CLASS',axis=1))","785dd1ce":"scaled_features = scaler.transform(df.drop('TARGET CLASS',axis=1))","7fbf993f":"df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\ndf_feat.head()","7eebc933":"from sklearn.model_selection import train_test_split","8c9ecf28":"X_train, X_test, y_train, y_test = train_test_split(scaled_features,df['TARGET CLASS'],\n                                                    test_size=0.30)","0cb9768b":"from sklearn.neighbors import KNeighborsClassifier","c19e29d5":"knn = KNeighborsClassifier(n_neighbors=1)","aa25ab72":"knn.fit(X_train,y_train)","b691f2e2":"pred = knn.predict(X_test)","1a61bae3":"from sklearn.metrics import classification_report,confusion_matrix","4b2e2a69":"print(confusion_matrix(y_test,pred))","5b2a241f":"print(classification_report(y_test,pred))","00b2402c":"error_rate = []\n\n# Will take some time\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","2ce3aa6b":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","f121d8a6":"# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\nknn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=1')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","0b32a852":"# NOW WITH K=23\nknn = KNeighborsClassifier(n_neighbors=23)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=23')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","3ba4eef0":"# Choosing a K Value\n\nLet's go ahead and use the elbow method to pick a good K Value:","957cdb8b":"# Get the Data\n\nSet index_col=0 to use the first column as the index.","e991a293":"You've been given a classified data set from a company! They've hidden the feature column names but have given you the data and the target classes. \n\nWe'll try to use KNN to create a model that directly predicts a class for a new data point based off of the features.\n\nLet's grab it and use it!","3dd6fc0e":"# Using KNN\n\nRemember that we are trying to come up with a model to predict whether someone will TARGET CLASS or not. We'll start with k=1.","e50500a2":"# Train Test Split","6c0f00db":"# Import Libraries","8501bb54":"Here we can see that that after around K>23 the error rate just tends to hover around 0.06-0.05 Let's retrain the model with that and check the classification report!","1ab6bff1":"Model Done !!!","30ebc72b":"# Standardize the Variables\n\nBecause the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations, and hence on the KNN classifier, than variables that are on a small scale.","0c88d8e5":"# Predictions and Evaluations\n\nLet's evaluate our KNN model!","590269d8":"# Classified Data-K Nearest Neighbors"}}