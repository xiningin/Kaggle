{"cell_type":{"b001b12c":"code","f8d93f4e":"code","6d728250":"code","2f00ca33":"code","eafb9346":"code","372c8679":"code","7e168704":"code","c5aafa75":"code","8fcb23a6":"code","fc2a6ce0":"code","ddada899":"code","893450b1":"code","7bf667f0":"code","0f5d75ba":"code","1e4ab218":"code","4f2b3437":"code","23174fca":"code","da6058a4":"code","f79d1c50":"markdown","d796d077":"markdown","5a2fecdb":"markdown","04a0c88e":"markdown","fa77737a":"markdown"},"source":{"b001b12c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","f8d93f4e":"df=pd.read_csv('..\/input\/email-spam-classification-dataset-csv\/emails.csv')","6d728250":"df.head()","2f00ca33":"df.info()","eafb9346":"df.isnull().sum()","372c8679":"from sklearn.model_selection import train_test_split","7e168704":"X = df.iloc[:, 1:-1].values\ny = df.iloc[:, -1].values","c5aafa75":"X.shape","8fcb23a6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","fc2a6ce0":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","ddada899":"mnb_model=MultinomialNB()\nmnb_model.fit(X_train,y_train)","893450b1":"lr_model = LogisticRegression(solver='liblinear')\nlr_model.fit(X_train,y_train)","7bf667f0":"rfc_model=RandomForestClassifier()\nrfc_model.fit(X_train,y_train)","0f5d75ba":"from sklearn.metrics import plot_confusion_matrix,classification_report,plot_precision_recall_curve,plot_roc_curve","1e4ab218":"def report(model):\n    preds = model.predict(X_test)\n    print(classification_report(preds,y_test))\n    plot_confusion_matrix(model,X_test,y_test)\n    plot_precision_recall_curve(model,X_test,y_test)\n    plot_roc_curve(model,X_test,y_test)","4f2b3437":"print(\"LOGISTIC REGRESSION MODEL\")\nreport(lr_model)","23174fca":"print(\"NAIVE BAYES MODEL\")\nreport(mnb_model)","da6058a4":"print(\"RANDOM FOREST MODEL\")\nreport(rfc_model)","f79d1c50":"We will consider Logistic Regression, Random Forest Classifier and Naive Bayes Model for the classification task and see which one performs better with its default paramter values. The selected model can then be used after hyperparamter tuning for better results.","d796d077":"###### About:\nThere are 3002 columns. The first column indicates Email name. The name has been set with numbers and not recipients' name to protect privacy. The last column has the labels for prediction : 1 for spam, 0 for not spam. The remaining 3000 columns are the 3000 most common words in all the emails, after excluding the non-alphabetical characters\/words. For each row, the count of each word(column) in that email(row) is stored in the respective cells. Thus, information regarding all 5172 emails are stored in a compact dataframe rather than as separate text files.","5a2fecdb":"###### Modelling","04a0c88e":"From the above, we can see that Random Forest Classifier performed better amongst the three models considered and can be used for the classification task. ","fa77737a":"###### Conclusion"}}