{"cell_type":{"24d4fd20":"code","846c9ded":"code","ebb4e942":"code","13cf878c":"code","f35804c6":"code","d9bbd717":"code","9164ad52":"code","ea0c24bb":"code","4858ac69":"code","73d6d57e":"code","95ab54ae":"code","863dc8ff":"code","c44908e2":"code","bc3d5838":"code","d196129e":"code","d9c0c5a6":"code","04bb69e2":"code","02ecdc81":"code","0ec23dee":"code","46adcbce":"code","639726fd":"code","76bcad7c":"code","79f60776":"code","7919bb60":"code","a248a364":"code","7b9aba31":"code","72675acf":"code","b3df61ec":"code","d3dba439":"code","701411d0":"code","e746971c":"code","2c4aa3c3":"code","861cea17":"code","66831dea":"code","e6ff7939":"code","25e4d243":"code","bdaf9e67":"code","0ec4a79b":"code","e1964e17":"code","a4a23a06":"code","b63884de":"code","4b90eec9":"code","c74316be":"code","99381d0e":"code","ba86963f":"code","933870e7":"code","0ede232a":"code","d84b0201":"code","a0b9b74a":"code","8a24f831":"code","fdbe2e1d":"code","4cd314d3":"code","7318f235":"code","938db94e":"code","e9caa61f":"code","d924ce74":"code","b03524dd":"code","efa0ec36":"code","3a1e65c6":"code","59150b13":"code","2097a20e":"code","2d6b69e0":"code","533f66f1":"code","e18b4d00":"code","eeaceab9":"code","55dd6047":"code","d1fd5208":"code","9be26485":"code","38e18c0a":"code","c2975fb2":"code","e627f33b":"code","05ce4c21":"code","a873a58f":"code","80bd3414":"code","be6c28c0":"code","c18ea917":"code","ce3b455f":"code","b72a322e":"code","aac85972":"code","e63f478c":"code","000ac6c2":"code","f43fffa5":"code","c97a54d3":"code","eb41c0d7":"code","587c19a4":"code","225a2703":"code","ec4813c9":"code","af14725e":"code","087d1047":"code","c3e224a3":"code","89a538c1":"code","c13f0b3b":"markdown","e54b713d":"markdown","6812b0b3":"markdown","18749f41":"markdown","96a6f837":"markdown"},"source":{"24d4fd20":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","846c9ded":"train = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics\/Train\/Train.csv')\ntest = pd.read_csv(\"\/kaggle\/input\/janatahack-healthcare-analytics\/Test.csv\")\nsubmit = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics\/sample_submmission.csv')\nprint(train.shape, test.shape)","ebb4e942":"patient = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics\/Train\/Patient_Profile.csv')\ncamp = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics\/Train\/Health_Camp_Detail.csv')\nhc1 = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics\/Train\/First_Health_Camp_Attended.csv')\nhc2 = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics\/Train\/Second_Health_Camp_Attended.csv')\nhc3 = pd.read_csv('\/kaggle\/input\/janatahack-healthcare-analytics\/Train\/Third_Health_Camp_Attended.csv')","13cf878c":"train.head(2)","f35804c6":"train.isnull().sum()","d9bbd717":"train['pat_camp'] = (train['Patient_ID'].astype(str) + '_' + train['Health_Camp_ID'].astype(str)).astype(str)\ntrain.head(2)\ntest['pat_camp'] = (test['Patient_ID'].astype(str) + '_' + test['Health_Camp_ID'].astype(str)).astype(str)\ntest.head(2)","9164ad52":"print(f'Shape of train: {train.shape}')\nfor col in list(train.columns):\n    print(f'Distinct entries in {col}: {train[col].nunique()}')","ea0c24bb":"train.info()","4858ac69":"train[train['Registration_Date'].isnull()].head()","73d6d57e":"print('Missing registration date info:')\nprint(f'Missing rows: {train[\"Registration_Date\"].isnull().sum()}')\nprint(f'Unique patients related to missing info: {train[train[\"Registration_Date\"].isnull()][\"Patient_ID\"].nunique()}')\nprint(f'Unique health camps related to missing info: {train[train[\"Registration_Date\"].isnull()][\"Health_Camp_ID\"].nunique()}')","95ab54ae":"train['Registration_Date'] = pd.to_datetime(train['Registration_Date'])\ntest['Registration_Date'] = pd.to_datetime(test['Registration_Date'])","863dc8ff":"print(np.min(train['Registration_Date']), np.max(train['Registration_Date']))\nprint(np.min(test['Registration_Date']), np.max(test['Registration_Date']))","c44908e2":"patient.head(2)","bc3d5838":"patient.isnull().sum()","d196129e":"patient.info()","d9c0c5a6":"print(f'Shape of patient: {patient.shape}')\nfor col in list(patient.columns):\n    print(f'Distinct entries in {col}: {patient[col].nunique()}')","04bb69e2":"print(f'Distinct entries in City_Type: {patient.City_Type.unique()}')\nprint(f'Distinct entries in Employer_Category: {patient.Employer_Category.unique()}')","02ecdc81":"patient.City_Type = patient.City_Type.fillna('None')\npatient.Employer_Category = patient.Employer_Category.fillna('None')","0ec23dee":"patients = patient.Patient_ID.nunique()\nassert patients == patient.shape[0]\n\nfor col in list(patient.columns):\n    print(f'None type entries %age in {col}: {100*(patient[patient[col]==\"None\"][col].count()\/patients)}')","46adcbce":"patient[patient['Income'] != \"None\"]['Income'].astype(int).hist()","639726fd":"patient[patient['Age'] != \"None\"]['Age'].astype(float).hist()","76bcad7c":"patient[patient['Education_Score'] != \"None\"]['Education_Score'].astype(float).hist()","79f60776":"patient['First_Interaction'] = pd.to_datetime(patient['First_Interaction'])\npatient.head(2)","7919bb60":"patient['Income'] = [ np.nan if y == \"None\" else y for y in patient['Income']]\npatient['Age'] = [ np.nan if y == \"None\" else y for y in patient['Age']]\npatient['Education_Score'] = [ np.nan if y == \"None\" else y for y in patient['Education_Score']]\n\npatient['Income'] = (patient['Income'].astype(float)).fillna(patient['Income'].mode())\npatient['Age'] = patient['Age'].astype(float)\npatient['Age'] = patient['Age'].fillna(np.mean(patient['Age']))\npatient['Education_Score'] = patient['Education_Score'].astype(float)\npatient['Education_Score'] = patient['Education_Score'].fillna(np.mean(patient['Age']))","a248a364":"hc1['pat_camp'] = (hc1['Patient_ID'].astype(str) + '_' + hc1['Health_Camp_ID'].astype(str)).astype(str)\nhc2['pat_camp'] = (hc2['Patient_ID'].astype(str) + '_' + hc2['Health_Camp_ID'].astype(str)).astype(str)\nhc3['pat_camp'] = (hc3['Patient_ID'].astype(str) + '_' + hc3['Health_Camp_ID'].astype(str)).astype(str)\nhc1.head(2)","7b9aba31":"hc3.Number_of_stall_visited.value_counts()","72675acf":"print(len(np.intersect1d(hc1.Patient_ID, hc2.Patient_ID)))\nprint(len(np.intersect1d(hc1.Patient_ID, hc3.Patient_ID)))\nprint(len(np.intersect1d(hc2.Patient_ID, hc3.Patient_ID)))\nprint(len(np.intersect1d(np.intersect1d(hc1.Patient_ID, hc2.Patient_ID), hc3.Patient_ID)))","b3df61ec":"print(len(np.intersect1d(hc1.Health_Camp_ID, hc2.Health_Camp_ID)))\nprint(len(np.intersect1d(hc1.Health_Camp_ID, hc3.Health_Camp_ID)))\nprint(len(np.intersect1d(hc2.Health_Camp_ID, hc3.Health_Camp_ID)))","d3dba439":"hc1 = hc1[['Patient_ID', 'Health_Camp_ID', 'Donation', 'Health_Score', 'pat_camp']]\nhc1.head(2)","701411d0":"temp = ['Health_Score' if col == 'Health Score' else col for col in hc2.columns]\nhc2.columns = temp\ndel temp\nhc2['Donation'] = 0\nhc2 = hc2[hc1.columns]\nhc2.head(2)","e746971c":"hc3.head(2)","2c4aa3c3":"print(train.shape[0], hc1.shape[0] + hc2.shape[0] + hc3.shape[0])\nprint(len(np.intersect1d(train.pat_camp, hc1.pat_camp)))\nprint(len(np.intersect1d(train.pat_camp, hc2.pat_camp)))\nprint(len(np.intersect1d(train.pat_camp, hc3.pat_camp)))","861cea17":"camp.head(5)","66831dea":"camp['Camp_Start_Date'] = pd.to_datetime(camp['Camp_Start_Date'])\ncamp['Camp_End_Date'] = pd.to_datetime(camp['Camp_End_Date'])\ncamp.head()","e6ff7939":"print(f'Distinct entries in Category1: {camp.Category1.unique()}')\nprint(f'Distinct entries in Category2: {camp.Category2.unique()}')\nprint(f'Distinct entries in Category3: {camp.Category3.unique()}')","25e4d243":"camp['duration'] = [divmod((camp['Camp_End_Date'].iloc[x]-camp['Camp_Start_Date'].iloc[x]).total_seconds(), 86400)[0]+1 for x in camp.index]\ncamp.head(2)","bdaf9e67":"np.log(camp['duration']).hist()","0ec4a79b":"camp['duration'] = np.log(camp['duration'])","e1964e17":"train = pd.merge(train, camp, on = 'Health_Camp_ID', how = 'left')\ntrain.head(2)","a4a23a06":"test = pd.merge(test, camp, on = 'Health_Camp_ID', how = 'left')\ntest.head(2)","b63884de":"train =pd.merge(train, patient, on = 'Patient_ID', how = 'left')\ntrain.head(2) \ntest = pd.merge(test, patient, on = 'Patient_ID', how = 'left')\ntest.head(2)","4b90eec9":"pat = list(hc1['pat_camp']) + list(hc2['pat_camp']) + list(hc3[hc3['Number_of_stall_visited']>0]['pat_camp'])\nout = pd.DataFrame(pat, columns = ['pat_camp'])\nout['outcome'] = 1\nprint(out.shape)","c74316be":"assert len(np.intersect1d(out.pat_camp, train.pat_camp)) == out.shape[0]\nout.head(2)","99381d0e":"train = pd.merge(train, out, on = 'pat_camp', how = 'left')\ntrain['outcome'] = train.outcome.fillna(0)\ntrain.head()","ba86963f":"train['enrol_days'] = [divmod((train['Registration_Date'].iloc[x]-train['First_Interaction'].iloc[x]).total_seconds(), 86400)[0] +1 for x in train.index]\ntest['enrol_days'] = [divmod((test['Registration_Date'].iloc[x]-test['First_Interaction'].iloc[x]).total_seconds(), 86400)[0] +1 for x in test.index]","933870e7":"train['enrol_days'] = train['enrol_days'].fillna(train['enrol_days'].mode())\ntest['enrol_days'] = test['enrol_days'].fillna(test['enrol_days'].mode())","0ede232a":"train.enrol_days.hist()","d84b0201":"train.enrol_days = np.log(train.enrol_days)\ntest.enrol_days = np.log(test.enrol_days)","a0b9b74a":"train['days_since_camp_start'] = [divmod((train['Registration_Date'].iloc[x]-train['Camp_Start_Date'].iloc[x]).total_seconds(), 86400)[0] +1 for x in train.index]\ntest['days_since_camp_start'] = [divmod((test['Registration_Date'].iloc[x]-test['Camp_Start_Date'].iloc[x]).total_seconds(), 86400)[0] +1 for x in test.index]","8a24f831":"train['days_duration_ratio'] = train['days_since_camp_start']\/train['duration']\ntest['days_duration_ratio'] = test['days_since_camp_start']\/test['duration']","fdbe2e1d":"'''\ntrain['days_since_camp_start'] = np.log(train['days_since_camp_start'])\ntest['days_since_camp_start'] = np.log(test['days_since_camp_start'])\n\ntrain['days_duration_ratio'] = np.log(train['days_duration_ratio'])\ntrain['days_duration_ratio'] = np.log(train['days_duration_ratio'])\n'''","4cd314d3":"train['days_for_camp_end'] = [divmod((train['Camp_End_Date'].iloc[x]-train['Registration_Date'].iloc[x]).total_seconds(), 86400)[0] +1 for x in train.index]\ntest['days_for_camp_end'] = [divmod((test['Camp_End_Date'].iloc[x]-test['Registration_Date'].iloc[x]).total_seconds(), 86400)[0] +1 for x in test.index]\n\ntrain['enddays_duration_ratio'] = train['days_for_camp_end']\/train['duration']\ntest['enddays_duration_ratio'] = test['days_for_camp_end']\/test['duration']\n\n'''\ntrain['days_for_camp_end'] = np.log(train['days_for_camp_end'])\ntest['days_for_camp_end'] = np.log(test['days_for_camp_end'])\n\ntrain['enddays_duration_ratio'] = np.log(train['enddays_duration_ratio'])\ntest['enddays_duration_ratio'] = np.log(test['enddays_duration_ratio'])\n'''","7318f235":"test['outcome'] = -1\ndata = train.append(test)","938db94e":"new_df = pd.DataFrame() \nnew_df['total_visits'] = np.log(data.groupby('Patient_ID')['Health_Camp_ID'].count())\n\nnew_df['total_first'] = data[data['Category1'] == 'First'].groupby('Patient_ID')['Health_Camp_ID'].count() \nnew_df['total_second'] = data[data['Category1'] == 'Second'].groupby('Patient_ID')['Health_Camp_ID'].count() \nnew_df['total_third'] = data[data['Category1'] == 'Third'].groupby('Patient_ID')['Health_Camp_ID'].count()\n\nnew_df['total_first'] = new_df['total_first'].fillna(0) \nnew_df['total_second'] = new_df['total_second'].fillna(0) \nnew_df['total_third'] = new_df['total_third'].fillna(0)\n\nnew_df = new_df.reset_index() \nprint(new_df.head())\n\ndata = pd.merge(data, new_df, on = 'Patient_ID', how = 'left')","e9caa61f":"new_df = pd.DataFrame()\nnew_df['total_patients'] = np.log(data.groupby('Health_Camp_ID')['Patient_ID'].count())\ndata = pd.merge(data, new_df, on = 'Health_Camp_ID', how = 'left')","d924ce74":"data.info()","b03524dd":"min_reg = np.min(data['Registration_Date'])\ndata['Registration_Date'] = [divmod((x-min_reg).total_seconds(), 86400)[0] +1 for x in data['Registration_Date']]\n\nmin_start = np.min(data['Camp_Start_Date'])\ndata['Camp_Start_Date'] = [divmod((x-min_start).total_seconds(), 86400)[0] +1 for x in data['Camp_Start_Date']]\nmin_end = np.min(data['Camp_End_Date'])\ndata['Camp_End_Date'] = [divmod((x-min_end).total_seconds(), 86400)[0] +1 for x in data['Camp_End_Date']]\n\nmin_inter = np.min(data['First_Interaction'])\ndata['First_Interaction'] = [divmod((x-min_inter).total_seconds(), 86400)[0] +1 for x in data['First_Interaction']]","efa0ec36":"hc3.head()","3a1e65c6":"new_df = data[['Patient_ID', 'Registration_Date', 'outcome']].sort_values(['Patient_ID', 'Registration_Date']).reset_index(drop=True)\n\npat_list = []\nlast_outcome = []\nfor i, pat_id in enumerate(list(new_df.Patient_ID.unique())):\n    if(i%10000 ==0):\n        print(i)\n    temp = new_df[new_df['Patient_ID'] == pat_id].reset_index(drop=True)\n    temp2 = temp['outcome'][temp.shape[0]-1]\n    pat_list.append(pat_id)\n    last_outcome.append(temp2)","59150b13":"new_df = pd.DataFrame.from_dict({'Patient_ID': pat_list, 'last_outcome': last_outcome})\nnew_df.head()\n","2097a20e":"\"\"\"\nnew_df = pd.DataFrame()\n\ntemp = hc1[['Health_Score', 'Patient_ID']].append(hc2[['Health_Score', 'Patient_ID']])\ntemp.columns = ['Health_Score', 'Patient_ID']\nnew_df['mean_score'] = temp.groupby('Patient_ID')['Health_Score'].mean()\n\ntemp = hc1[['Donation', 'Patient_ID']]\ntemp.columns = ['Donation', 'Patient_ID']\nnew_df['sum_donation'] = temp.groupby('Patient_ID')['Donation'].sum()\nnew_df['count_donation'] = temp.groupby('Patient_ID')['Donation'].count()\n\nnew_df['sum_donation'] = new_df['sum_donation'].fillna(0)\nnew_df['count_donation'] = new_df['count_donation'].fillna(0)\n\ntemp = hc3[['Number_of_stall_visited', 'Patient_ID']]\ntemp.columns = ['Number_of_stall_visited', 'Patient_ID']\nnew_df['total_stalls_visited'] = temp.groupby('Patient_ID')['Number_of_stall_visited'].sum()\nnew_df['mean_stalls_visited'] = temp.groupby('Patient_ID')['Number_of_stall_visited'].mean()\nnew_df['total_stalls_visited'] = new_df['total_stalls_visited'].fillna(0)\nnew_df['mean_stalls_visited'] = new_df['mean_stalls_visited'].fillna(0)\n\nnew_df = new_df.reset_index()\nnew_df.head()\n\"\"\"","2d6b69e0":"data = pd.merge(data, new_df, on = 'Patient_ID', how = 'left')\ndata[new_df.columns] = data[new_df.columns].fillna(0)\ndata.head()","533f66f1":"assert len(list(train.columns)) == len(list(test.columns)) ","e18b4d00":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, classification_report","eeaceab9":"from category_encoders import TargetEncoder, MEstimateEncoder\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()","55dd6047":"cat_cols = ['Category1', 'Category2', 'Category3','City_Type','Employer_Category']\n\nfor col in cat_cols:\n    print(col)\n    encoder.fit(data[col])\n    data[col] = encoder.transform(data[col]).astype('float')","d1fd5208":"train2 = data[data['outcome'] != -1]\ntest2 = data[data['outcome'] == -1]","9be26485":"X = train2.drop(columns = ['Patient_ID',\n                          'Health_Camp_ID'\n                          , 'pat_camp'\n                          ,'Online_Follower', 'LinkedIn_Shared'\n                          , 'Twitter_Shared', 'Facebook_Shared'\n                           , 'Var4', 'Var2', 'Var3'\n                           #'Registration_Date', 'Camp_Start_Date', 'Camp_End_Date'\n                          , 'Income','Education_Score', 'Age'\n                          #, 'First_Interaction'\n                           , 'outcome', 'last_outcome'\n                         ])\ny = train2['outcome']\nprint(X.shape, y.shape)","38e18c0a":"Xtest = test2.drop(columns = ['Patient_ID',\n                            'Health_Camp_ID'\n                          , 'pat_camp'\n                          ,'Online_Follower', 'LinkedIn_Shared'\n                          , 'Twitter_Shared', 'Facebook_Shared'\n                          , 'Var4', 'Var2', 'Var3'\n                          #'Registration_Date', 'Camp_Start_Date', 'Camp_End_Date'\n                          , 'Income','Education_Score', 'Age'\n                          #, 'First_Interaction'\n                           , 'outcome', 'last_outcome'\n                         ])","c2975fb2":"print(X.shape, Xtest.shape)","e627f33b":"X.head()","05ce4c21":"import lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RepeatedKFold, cross_val_score, KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, f1_score, make_scorer","a873a58f":"params = {}\nparams['boosting_type']= 'dart' #dropout aided regressive trees (DART) # improves accuracy\nparams['learning_rate']= 0.05\nparams['verbose']: 0\n    \n#params[\"objective\"] = \"binary:logistic\"\nparams['metric'] = 'auc'\nparams[\"min_data_in_leaf\"] = 8 \nparams[\"bagging_fraction\"] = 0.7\nparams[\"feature_fraction\"] = 0.7\nparams[\"bagging_seed\"] = 50\n\nmodel = LGBMClassifier(objective = 'binary', boosting_type= 'dart', learning_rate = 0.05, metric = 'auc', num_estimators = 600\n                       , random_state = 22, min_data_in_leaf = 8, bagging_fraction = 0.7, feature_fraction = 0.7)\ncv = RepeatedKFold(n_splits = 5, n_repeats = 1, random_state = 22)\nn_scores = cross_val_score(model, X, y, scoring = make_scorer(roc_auc_score), cv = cv )\nprint(np.mean(n_scores), n_scores)\n\nmodel = XGBClassifier(objective = 'binary:logistic',boosting_type= 'dart', learning_rate = 0.05, metric = 'auc', num_estimators = 600\n                       , random_state = 22, min_data_in_leaf = 8, bagging_fraction = 0.7, feature_fraction = 0.7)\ncv = RepeatedKFold(n_splits = 5, n_repeats = 1, random_state = 22)\nn_scores = cross_val_score(model, X, y, scoring = make_scorer(roc_auc_score), cv = cv )\n\n#print(roc_auc_score(model.predict(Xtrain), yval))\nprint(np.mean(n_scores))","80bd3414":"def runLGB2(Xtrain, ytrain, Xval, yval, cat_cols, Xtest = None):\n    params = {\n    'boosting_type': 'dart', #dropout aided regressive trees (DART) # improves accuracy\n    #'max_depth': 10, \n    'learning_rate': 0.05\n    ,'verbose': 1\n    }\n    \n    #regularising for overfitting with inf depth\n    params[\"objective\"] = \"binary\"\n    params['metric'] = 'auc'\n    params[\"min_data_in_leaf\"] = 8 \n    params[\"bagging_fraction\"] = 0.7\n    params[\"feature_fraction\"] = 0.7\n    params[\"bagging_freq\"] = 3\n    params[\"bagging_seed\"] = 50\n\n    n_estimators = 1000\n    early_stopping_rounds = 10\n\n    d_train = lgb.Dataset(Xtrain.copy(), label=ytrain.copy(), categorical_feature=cat_cols)\n    d_valid = lgb.Dataset(Xval.copy(), label=yval.copy(), categorical_feature=cat_cols)\n    watchlist = [d_train, d_valid]\n\n    model = lgb.train(params, d_train, n_estimators\n                      , watchlist\n                      , verbose_eval=80\n                      , early_stopping_rounds=early_stopping_rounds)\n\n    preds = model.predict(Xval, num_iteration=model.best_iteration)\n    err = roc_auc_score(yval, preds)\n    \n    preds_test = model.predict(Xtest, num_iteration=model.best_iteration)\n    return  preds, err, preds_test, model","be6c28c0":"def runXGB(train_X, train_y, test_X, test_y=None,  extra_X=None, num_rounds=200):\n\tparams = {}\n\tparams[\"objective\"] = \"binary:logistic\"\n\tparams['eval_metric'] = 'auc'\n\tparams[\"eta\"] = 0.02 \n\tparams[\"subsample\"] = 0.8\n\tparams[\"min_child_weight\"] = 5\n\tparams[\"colsample_bytree\"] = 0.7\n\tparams[\"max_depth\"] = 6\n\tparams[\"silent\"] = 1\n\tparams[\"seed\"] = 0\n\n\tplst = list(params.items())\n\txgtrain = xgb.DMatrix(train_X, label=train_y)\n\n\tif test_y is not None:\n\t\txgtest = xgb.DMatrix(test_X, label=test_y)\n\t\twatchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n\t\tmodel = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=300)\n\telse:\n\t\txgtest = xgb.DMatrix(test_X)\n\t\tmodel = xgb.train(plst, xgtrain, num_rounds)\n\n\tpred_test_y = model.predict(xgtest)\n\tloss = 0\n    \n\tif extra_X is not None:\n\t\txgtest = xgb.DMatrix(extra_X)\n\t\tpred_extra_y = model.predict(xgtest)\n\t\treturn pred_test_y, pred_extra_y, loss, model \n\n\tif test_y is not None:\n\t\tloss = roc_auc_score(test_y, pred_test_y)\n\t\tprint (loss)\n\t\treturn pred_test_y, loss, model\n\telse:\n\t    return pred_test_y,loss, model","c18ea917":"y = pd.DataFrame(y)\ny['Category1'] = X['Category1'].copy()\ny.head()","ce3b455f":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport time\ncat_cols2 = cat_cols# + ['last_outcome']\n\ndf =pd.DataFrame()\nfor camp_format in X.Category1.unique():\n    preds_buff = 0\n    err_buff = []\n\n    n_splits = 5\n    kf = StratifiedKFold(n_splits=n_splits, shuffle= True, random_state=22)\n   \n    for dev_index, val_index in kf.split(X[X['Category1'] == camp_format], y[y['Category1'] == camp_format]['outcome'].astype(int)):\n        start = time.time()\n        Xtrain, Xval = X[X['Category1'] == camp_format].iloc[dev_index], X[X['Category1'] == camp_format].iloc[val_index]\n        ytrain, yval = y[y['Category1'] == camp_format]['outcome'].astype(int).iloc[dev_index], y[y['Category1'] == camp_format]['outcome'].astype(int).iloc[val_index]    \n        \n        print(Xtrain.shape, Xval.shape, ytrain.shape, yval.shape)\n        \n        pred_val, roc, preds_test, model = runLGB2(Xtrain, ytrain, Xval, yval, cat_cols2, Xtest[Xtest['Category1'] == camp_format])\n        preds_buff += preds_test\n        err_buff.append(roc)\n        print(f'Mean Error: {np.mean(err_buff)}; Split error: {roc}')\n        print(f'Total time in seconds for this fold: {time.time()-start}')\n        print('\\n')\n    '''\n\n    Xtrain, Xval, ytrain, yval = train_test_split(X[X['Category1'] == camp_format], y[y['Category1'] == camp_format]['outcome'].astype(int), test_size = 0.2, random_state = 22, stratify = y[y['Category1'] == camp_format]['outcome'])\n    print(Xtrain.shape, Xval.shape, ytrain.shape, yval.shape)\n    pred_val, roc, preds_test, model = runLGB2(Xtrain, ytrain, Xval, yval, cat_cols2, Xtest[Xtest['Category1'] == camp_format])\n    print(roc)\n    '''\n    \n    temp_df = test2[test2['Category1'] == camp_format][['Patient_ID', 'Health_Camp_ID']].copy()\n    temp_df['Outcome'] = preds_buff\/n_splits\n    df = df.append(temp_df)","b72a322e":"df.head()","aac85972":"df.to_csv('lgb_v2.csv', index = False)","e63f478c":"Xtrain, Xval, ytrain, yval = train_test_split(X, y['outcome'], test_size = 0.2, random_state = 22, stratify = y)\npred_val, roc, preds_test, model = runLGB2(Xtrain, ytrain, Xval, yval, cat_cols2, Xtest)\nroc","000ac6c2":"#submit['Outcome'] = model.predict(Xtest, num_iteration=model.best_iteration)\n#submit[['Patient_ID', 'Health_Camp_ID','Outcome']].to_csv('lgb_v7.csv', index = False)","f43fffa5":"submit['Outcome'] = preds_test\nsubmit.to_csv('gb_1000_v1.csv', index = False)","c97a54d3":"submit.head()","eb41c0d7":"a =model.feature_importance(importance_type='split')\nfeature = pd.DataFrame(model.feature_name())\nfeature['impo'] = a\nfeature = feature.sort_values(by = ['impo'], ascending = False)\nfeature.head(30)","587c19a4":"X.isnull().sum()","225a2703":"import time\n\npreds_buff = 0\nerr_buff = []\n\nn_splits = 5\nkf = StratifiedKFold(n_splits=n_splits, shuffle= True, random_state=22)\n\nfor dev_index, val_index in kf.split(X, y['outcome']):\n    start = time.time()\n    Xtrain, Xval = X.iloc[dev_index], X.iloc[val_index]\n    ytrain, yval = np.array(y['outcome'].iloc[dev_index]), np.array(y['outcome'].iloc[val_index])\n    \n    pred_val, roc, preds_test, model = runLGB2(Xtrain, ytrain, Xval, yval, cat_cols, Xtest)\n    preds_buff += preds_test\n    err_buff.append(roc)\n    print(f'Mean Error: {np.mean(err_buff)}; Split error: {roc}')\n    print(f'Total time in seconds for this fold: {time.time()-start}')\n    print('\\n')\n\npreds_buff \/= n_splits","ec4813c9":"print(err_buff, np.mean(err_buff))","af14725e":"submit['Outcome'] = preds_buff\nsubmit.to_csv('gb_gbdt_new_v4.csv', index = False)","087d1047":"print(len(np.intersect1d(test.pat_camp, hc1.pat_camp)))\nprint(len(np.intersect1d(test.pat_camp, hc2.pat_camp)))\nprint(len(np.intersect1d(test.pat_camp, hc3.pat_camp)))","c3e224a3":"print(len(np.intersect1d(train[train['outcome'] == 1].Patient_ID.unique(), test.Patient_ID)))\nprint(len(np.intersect1d(train[train['outcome'] == 1].Health_Camp_ID.unique(), test.Health_Camp_ID)))","89a538c1":"test['Patient_ID'].nunique()","c13f0b3b":"Income is categorical while Education_Score and Age are floats. ","e54b713d":"A few patients have missing records for multiple health camps. ","6812b0b3":"There are 3 highly sparse features in Patient Info, namely, `Income`, `Education_score` and `Age`.","18749f41":"# Preparing Training and test","96a6f837":"# Baseline Classifier"}}