{"cell_type":{"13712a97":"code","8b66f363":"code","4e8459b9":"code","f87d7501":"code","0d37a3a5":"code","6a646085":"code","c077095c":"code","948b2286":"code","2bbda893":"code","e61c1169":"code","8029dc70":"code","8a856fd8":"code","bd722d46":"code","e06d955d":"code","140ddfdf":"code","b444047b":"code","38d178eb":"code","993ebb72":"code","b44013b3":"code","26b66b76":"code","cc5729e1":"code","cec31d68":"code","f62371b8":"code","40bea401":"code","08bbbf93":"code","d366b765":"code","f2f390ce":"code","0a9e453d":"code","57e12edb":"code","ad2b9798":"code","c02173e4":"code","d186e602":"code","7e8d4789":"code","f7a4905a":"code","3e8ccbc6":"code","f0020935":"code","b14f2abb":"code","edff5865":"code","12c8469a":"code","cad1c18a":"code","edf0dd64":"code","c4b10d91":"code","64802f50":"code","667475e9":"code","375ffcbe":"code","9f3b7337":"code","9f563711":"code","aa163ad6":"code","b8db199a":"code","29f2c8cf":"code","1a64ee11":"code","12e208c9":"code","b59a115a":"code","fa8b0a7e":"code","4b772bef":"code","d5137517":"code","9d93aa70":"markdown","bc366187":"markdown","f7c7320c":"markdown","458eb34b":"markdown","1c5e3740":"markdown","721ca16d":"markdown","8d03e7ea":"markdown","a8e44c01":"markdown","c688939d":"markdown","ad034404":"markdown","5b79347f":"markdown","503dc04d":"markdown","7fb3b760":"markdown","2817c2ef":"markdown","0a1f2341":"markdown","b0ef295b":"markdown","17048caa":"markdown","947b490c":"markdown","549ec455":"markdown","063c8d52":"markdown","9ab43082":"markdown","2e7428e4":"markdown","2a1f8acc":"markdown","7095ec13":"markdown","f212091f":"markdown","92a36031":"markdown","b4c57531":"markdown","690a70b9":"markdown","899853a6":"markdown","c7d2e3d4":"markdown","ddf12c84":"markdown","107f48f0":"markdown","7f8047e0":"markdown","ba09dc06":"markdown","eb04be7d":"markdown","e641f8af":"markdown","f2507610":"markdown","e1d8d6c1":"markdown","cb8e76d4":"markdown","d8700ff8":"markdown","f7abf0bb":"markdown","738ed1d6":"markdown","b6432ba4":"markdown","5650f4c3":"markdown","8d7afeae":"markdown","318cd555":"markdown","eac650d1":"markdown","19b20277":"markdown"},"source":{"13712a97":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","8b66f363":"pip install openpyxl","4e8459b9":"# loading the training data\ndata_train = pd.read_excel(\"..\/input\/flight-fare-prediction-mh\/Data_Train.xlsx\")","f87d7501":"data_train.head()","0d37a3a5":"data_train.tail()","6a646085":"data_train.sample()","c077095c":"def basic_eda(data):\n    print(\"------BASIC EDA OF THE DATA------\")\n    print(\"\\nShape of the data: \")\n    print(data.shape)\n    print(\"\\n-------------------\")\n    print(\"\\nSize of the data: \")\n    print(data.size)\n    print(\"\\n-------------------\")\n    print(\"\\nDatatypes of the object: \")\n    print(data.dtypes)\n    print(\"\\n-------------------\")\n    print(\"\\nColumns of the data: \")\n    print(data.columns)\n    print(\"\\n-------------------\")\n    print(\"\\nInformation of the data: \")\n    print(data.info())\n    \n\n# eda on training data\nbasic_eda(data_train)","948b2286":"data_train.isnull().sum()","2bbda893":"data_train.dropna(inplace=True)","e61c1169":"data_train.isnull().sum()","8029dc70":"data_train[\"Journey_day\"] = pd.to_datetime(data_train.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day","8a856fd8":"data_train[\"Journey_month\"] = pd.to_datetime(data_train[\"Date_of_Journey\"], format = \"%d\/%m\/%Y\").dt.month","bd722d46":"# We have converted Date_of_Journey column into integers. Droping that column\ndata_train.drop([\"Date_of_Journey\"], axis=1, inplace=True)","e06d955d":"data_train.head()","140ddfdf":"data_train[\"Dep_hour\"] = pd.to_datetime(data_train[\"Dep_Time\"]).dt.hour\ndata_train[\"Dep_min\"] = pd.to_datetime(data_train[\"Dep_Time\"]).dt.minute\n\n# We can drop Dep_time \ndata_train.drop([\"Dep_Time\"], axis=1, inplace=True)","b444047b":"data_train.head()","38d178eb":"data_train[\"Arrival_hour\"] = pd.to_datetime(data_train.Arrival_Time).dt.hour\ndata_train[\"Arrival_min\"] = pd.to_datetime(data_train.Arrival_Time).dt.minute\n\n# We can drop Arrival Time\ndata_train.drop([\"Arrival_Time\"], axis=1, inplace=True)\n\ndata_train.head()","993ebb72":"# Time taken by plane to reach the destination is called Duration\n# It is the difference between Departute Time and Arrival time\n\n# Assigning and converting Duration column into list\nduration = list(data_train[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1])) ","b44013b3":"# Adding duration_hours and duration_mins list to data_train dataframe\n\ndata_train[\"Duration_Hours\"] = duration_hours\ndata_train[\"Duration_Mins\"] = duration_mins\n\n# Droping the \"Duration\" Colum\ndata_train.drop([\"Duration\"], axis=1, inplace=True)\n\ndata_train.head()","26b66b76":"data_train['Airline'].value_counts()","cc5729e1":"data_train['Source'].value_counts()","cec31d68":"data_train['Destination'].value_counts()","f62371b8":"data_train['Route'].value_counts()","40bea401":"data_train.columns","08bbbf93":"data_train[\"Journey_day\"].value_counts()","d366b765":"data_train[\"Journey_month\"].value_counts()","f2f390ce":"sns.catplot(y = \"Price\", x = \"Airline\", data = data_train.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 4, aspect = 3)\nplt.title('Airlines vs Price')\nplt.figure(figsize=(30,25))\nplt.show()","0a9e453d":"Airline = data_train[[\"Airline\"]]\nAirline = pd.get_dummies(Airline, drop_first=True)\nAirline.head()","57e12edb":"sns.catplot(y = \"Price\", x = \"Source\", data = data_train.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 4, aspect = 3)\nplt.title('Source vs Price')\nplt.figure(figsize=(30,25))\nplt.show()","ad2b9798":"# It is a Nominal Data\nSource = data_train[\"Source\"]\n\nSource = pd.get_dummies(Source, drop_first = True)\n\nSource.head()","c02173e4":"data_train[\"Destination\"].value_counts()","d186e602":"# It is Nominal data\nDestination = data_train[[\"Destination\"]]\n\nDestination = pd.get_dummies(Destination, drop_first=True)\n\nDestination.head()","7e8d4789":"data_train.head()","f7a4905a":"data_train['Additional_Info'].value_counts()","3e8ccbc6":"data_train['Route'].value_counts()","f0020935":"data_train.drop([\"Route\",\"Additional_Info\"], axis=1, inplace=True)\n\ndata_train.head()","b14f2abb":"data_train['Total_Stops'].value_counts()","edff5865":"data_train.replace({\"non-stop\": 0, \"1 stop\":1, \"2 stops\":2, \"3 stops\":3, \"4 stops\":4}, inplace=True)\n\ndata_train.head()","12c8469a":"data_train = pd.concat([data_train, Airline, Source, Destination], axis=1)\ndata_train.head()\n","cad1c18a":"# Dropping columns coz they are now in encoded version\n\ndata_train.drop([\"Airline\",\"Source\", \"Destination\"], axis=1, inplace=True)","edf0dd64":"# Saving this dataset\n\ndata_train.to_csv('processed_trainData.csv')","c4b10d91":"data_test = pd.read_excel('..\/input\/flight-fare-prediction-mh\/Test_set.xlsx')","64802f50":"data_test.head()","667475e9":"# already created the fucntion\nbasic_eda(data_test)","375ffcbe":"print(\"Null values: \")\nprint(data_test.isnull().sum())\nprint(\"\\nAfter droping the test data: \")\nprint(data_test.isnull().sum())","9f3b7337":"# Date_of_Journey\ndata_test[\"Journey_day\"] = pd.to_datetime(data_test.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day\ndata_test[\"Journey_month\"] = pd.to_datetime(data_test[\"Date_of_Journey\"], format = \"%d\/%m\/%Y\").dt.month\ndata_test.drop([\"Date_of_Journey\"], axis=1, inplace=True)","9f563711":"# Dep_time\ndata_test[\"Dep_hour\"] = pd.to_datetime(data_test[\"Dep_Time\"]).dt.hour\ndata_test[\"Dep_min\"] = pd.to_datetime(data_test[\"Dep_Time\"]).dt.minute\ndata_test.drop([\"Dep_Time\"], axis = 1, inplace = True)","aa163ad6":"data_test[\"Arrival_hour\"] = pd.to_datetime(data_test.Arrival_Time).dt.hour\ndata_test[\"Arrival_min\"] = pd.to_datetime(data_test.Arrival_Time).dt.minute\ndata_test.drop([\"Arrival_Time\"], axis = 1, inplace = True)","b8db199a":"# Duration\n\nduration = list(data_test[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n\n# Adding Duration column to test set\ndata_test[\"Duration_hours\"] = duration_hours\ndata_test[\"Duration_mins\"] = duration_mins\ndata_test.drop([\"Duration\"], axis = 1, inplace = True)","29f2c8cf":"# Categorical\n\nprint(\"Airline\")\nprint(\"-\"*75)\nprint(data_test[\"Airline\"].value_counts())\nAirline = pd.get_dummies(data_test[\"Airline\"], drop_first= True)\n\nprint()\n\nprint(\"Source\")\nprint(\"-\"*75)\nprint(data_test[\"Source\"].value_counts())\nSource = pd.get_dummies(data_test[\"Source\"], drop_first= True)\n\nprint()\n\nprint(\"Destination\")\nprint(\"-\"*75)\nprint(data_test[\"Destination\"].value_counts())\nDestination = pd.get_dummies(data_test[\"Destination\"], drop_first = True)","1a64ee11":"# Additional_Info contains almost 80% no_info\n# Route and Total_Stops are related to each other\ndata_test.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n","12e208c9":"data_test.head()","b59a115a":"# Replacing the Total_Stops\ndata_test.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)","fa8b0a7e":"# Concatenate dataframe --> test_data + Airline + Source + Destination\ndata_test = pd.concat([data_test, Airline, Source, Destination], axis = 1)\n\ndata_test.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n\nprint()\nprint()\n\ndata_test.head()","4b772bef":"print(\"Shape of the training data: \")\nprint(data_train.shape)\nprint(\"Shape of the testing data: \")\nprint(data_test.shape)","d5137517":"# Saving the processed_test data\n\ndata_test.to_csv(\"processed_testData.csv\")","9d93aa70":"### Analyzing the data column wise","bc366187":"## Data Preprocessing and Visualization","f7c7320c":"From description we can see that **Date_of_Journey** is a object data type,\\ Therefore, we have to convert this datatype into timestamp so as to use this column properly for prediction","458eb34b":"**Banglore** is the costly source to travel also from above graph we can clearly see that **Delhi** and **Kolkata** has samiliar median price.","1c5e3740":"### Handling Categorical Data\n\nOne can find many ways to handle categorical data. Some of them categorical data are,\n\n**Nominal data** --> data are not in any order --> **OneHotEncoder** is used in this case\n**Ordinal data** --> data are in order --> **LabelEncoder** is used in this case","721ca16d":"Let's check first 5, last 5 and random 5 samples from the training dataset","8d03e7ea":"### Destination","a8e44c01":"## Visualizing and encoding **Airlines** column","c688939d":"Prices of each Airlines","ad034404":"## Converting data types","5b79347f":"### Concatenate dataframe --> train_data + Airline + Source + Destination","503dc04d":"## Soruce Column","7fb3b760":"Source of the most flights are from **Delhi**, **Kolkata** and **Banglore** ","2817c2ef":"### Encoding the Airline column","0a1f2341":"### Sources","b0ef295b":"## Importing Dataset\n\n- As the data is in the form of excel, so here we can use read_excel() from pandas \n- After loading the data, next steps will be based on analysis of the data\n     - Exploratory Data Analysis (finding hidden information and finding some basic analysis.\n     - Findind null values from the dataset and will fill the missing data with mean, median and mode.\n- Statistical Analysis of the data","17048caa":"Lets check the importance of **Additional_info**","947b490c":"### Null values","549ec455":"It is **Nominal** categorical data as we will perform OneHotEncoding","063c8d52":"### Route","9ab43082":"# Test Data","2e7428e4":"There is no point to point to look factors like Date, stop, arrival_times.","2a1f8acc":"### Encoding the Source","7095ec13":"### Basic exploratory data analysis from above function\n\nThis function will help us to find basic eda of test data","f212091f":"**Total Stops** are the only column that haven't seen yet","92a36031":"Similar to Date_of_Journey we can extract values from Dep_Time","b4c57531":"Even **Route** is not that important for us, sp lets drop these columns.","690a70b9":"#### Encoding of Destination is same but no need to caluclate the price","899853a6":"Arrival time is when plane pulls up to the gate\n\nWe can extract values from Arrival Time\n","c7d2e3d4":"##### For preprocessing the data for Machine Learning Model we need to drop some unecceassary data","ddf12c84":"Some Airlines are long in lenght but our intension here to just check the price range of all Airlines. From above image we can clearly see that\n\n**Jet Airways Business** having very high price (Is it business class plane?May be yes!), Runner up is again **Jet Airways** but other airlines expcept **Jet Airways Business** having nearly same range especially medin range of prices are same.","107f48f0":"### Finding missing values from the data","7f8047e0":"# Flight Fare Prediction - End to End deployment","ba09dc06":"### Airline Column","eb04be7d":"### Shape of training and testing dataset\n","e641f8af":"Let's check the prices from different sources","f2507610":"### Most of the the route followed by the flights are \n1. DEL \u2192 BOM \u2192 COK\n2. BLR \u2192 DEL\n3. CCU \u2192 BOM \u2192 BLR","e1d8d6c1":"**Route** and **Total Stops** has single missing value each. So data doesn't have more null values. So let's drop the null values","cb8e76d4":"Destined flights are **Cochin**, **Banglore** and **Delhi**","d8700ff8":"In above case of **Ordinal** Categorical type we perform LabelEncoder\n\nWe can assign values with corresponding keys","f7abf0bb":"Above numbers are describing the top commonn **Day** and **Months** of the journeys. So, in dates 9, 6 and 27 that are common in most of the journeys but dates are not much importnat where **Months** are too important factors for journeys.\n\nSo, Months are 5-6-3-4 that means May(5)-June(6)-March(3)-April(4). Indian Airlines and journeys are busy in these months because of in India this months are very ideal for travellers because of **Summer Holidays** of students and other factors may be **Business Purpose, IPL(Cricket League in India, commonly held between April-June) and etc.**\n\n**May**, **June** and **March** are the top most journey months","738ed1d6":"## Importing Essential Libraries","b6432ba4":"### Top running airlines \n1. Jet Airways\n2. IndiGo\n3. Air India","5650f4c3":"**Additional_Info** column is not providing us important information","8d7afeae":"## EDA and Encoding of Categorical data","318cd555":"## Preprocessing on the test data","eac650d1":"Most Common Journey Dateand Month","19b20277":"### Duration, Time and Month"}}