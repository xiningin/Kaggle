{"cell_type":{"c702e69b":"code","ac8f1ccc":"code","bcc9bd21":"code","41c6ba89":"code","4d03fa29":"code","a41083e5":"code","7f1ccaa5":"code","4d46387f":"code","47f7e631":"code","f6c0a1df":"code","426b21ed":"code","c58a8450":"code","cd1a57bb":"code","91ea97b8":"code","c6a9dc05":"code","55b0b555":"code","2bc6fc1c":"code","baa6181d":"code","b4542496":"code","fd191bc8":"code","aac81946":"code","61c30956":"code","5684e297":"code","3f26691c":"code","d847ef49":"code","f64acef7":"code","3977e13e":"code","5a9012f6":"code","716c0cd6":"code","4f13b82c":"code","2139fff3":"code","8459e66f":"code","16b3f47d":"code","7aeb9ae4":"code","272f602e":"code","20adcdb1":"code","3b7707a1":"code","9f72c3a1":"code","566a95c0":"code","60289209":"code","2b99d86e":"code","3db87f99":"code","0099242f":"code","49aa49bf":"code","c32129a4":"code","64fea2ae":"code","2de1b5c6":"code","58ba9d82":"code","fab7341b":"code","d6202027":"code","a6e1f54f":"code","1edef3e8":"markdown","97ebb4ed":"markdown","a084bac8":"markdown","f4ea9548":"markdown","7968fd9a":"markdown","1c7b4f66":"markdown","a0903863":"markdown","2b7ab599":"markdown","76f9688d":"markdown","16c01def":"markdown","85613873":"markdown","3dfd5b23":"markdown","76d75912":"markdown","e82c5004":"markdown","cb272dfe":"markdown","b95ab4cf":"markdown","c45215a8":"markdown","cda203d8":"markdown","78d51d1d":"markdown","8153f9aa":"markdown","60081101":"markdown","5fb1bb01":"markdown","2ef55278":"markdown","b930f669":"markdown","e69a82eb":"markdown","c97a3fce":"markdown","f3b1808f":"markdown","57f0fe42":"markdown","0df0f374":"markdown","23727d17":"markdown"},"source":{"c702e69b":"# i build this model  on google colab so i will comment command which i use on it\n# dawnload dataset\n#if you want to download\n#!wget https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00228\/smsspamcollection.zip","ac8f1ccc":"#!unzip smsspamcollection.zip","bcc9bd21":"import os\nprint(os.listdir(\"..\/input\/smsspamcollection\"))","41c6ba89":"# Import libraries necessary for this project\nimport numpy as np\nimport pandas as pd\nfrom time import time\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n# Suppress matplotlib user warnings\n# Necessary for newer version of matplotlib\nimport warnings\nwarnings.filterwarnings(\"ignore\", category = UserWarning, module = \"matplotlib\")\n#\n# Display inline matplotlib plots with IPython\nfrom IPython import get_ipython\nget_ipython().run_line_magic('matplotlib', 'inline')\n###########################################\n\nimport matplotlib.pyplot as pl\nimport matplotlib.patches as mpatches\nfrom wordcloud import WordCloud\nimport numpy as np\nimport pandas as pd\nfrom time import time\nfrom sklearn.metrics import f1_score, accuracy_score\n\n# Pretty display for notebooks\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\n","4d03fa29":"#Load dataset\npd.set_option('display.max_colwidth', 100)\n\ndata = pd.read_csv(\"..\/input\/smsspamcollection\/SMSSpamCollection\", sep='\\t',skipinitialspace=True, header=None)\ndata.columns = ['label', 'body_text']\n\ndisplay(data.head())","a41083e5":"display(data.info())\n","7f1ccaa5":"# Total number of records\nn_records = data.shape[0]\n\n\n# Number of records where SMS  are ham\nn_ham = data[data.label==\"ham\"].label.count()\n\n# Number of records where SMS are ham\nn_spam =data[data.label==\"spam\"].label.count()\n\n# Percentage of SMS which are ham\nspam_percent = (n_spam \/ n_records) * 100\n\n# Print the results\nprint(\"Total number of records: {}\".format(n_records))\nprint(\"SMS which are ham: {}\".format(n_ham))\nprint(\"SMS which are spam: {}\".format(n_spam))\nprint(\"Percentage of SMS which are spam : {:.3f}%\".format(spam_percent))","4d46387f":"# Remove punctuation\nimport string\n\ndef remove_punct(text):\n  text_nopunct = \"\".join([char for char in text if char not in string.punctuation]) \n  return text_nopunct.lower()\n","47f7e631":"data['body_text_clean'] = data['body_text'].apply(lambda x: remove_punct(x))\ndisplay(data.head())","f6c0a1df":"\ndef wc_message(df, type):\n    \"\"\"\n     Visualization repeated words in the messages (spam or ham)!\n\n     inputs:\n      - data fram\n      - label: type of messages (spam or ham) \n    \"\"\"\n    wc = WordCloud(width = 512, height = 512)\n    try:\n        if type == 'spam':\n            spam_words = ''.join(list(data[data['label'] == 'spam']['body_text_clean'] ))\n            spam_wc = wc.generate(spam_words)\n            pl.figure(figsize= (10,8), facecolor= 'k')\n            pl.imshow(spam_wc)\n\n        elif type == 'ham':\n            ham_words = ''.join(list(data[data['label'] == 'ham']['body_text_clean'] ))\n            ham_wc = wc.generate(ham_words)\n            pl.figure(figsize= (10,8), facecolor= 'k')\n            pl.imshow(ham_wc)\n        else:\n          print(\"please input right parmeters type wc_message.__doc__ and follow the inputs\")\n\n\n\n        pl.axis('off')\n        pl.tight_layout(pad = 0)\n        pl.show()\n    except Exception as e:\n        print(e)\n","426b21ed":"wc_message(data, 'spam')","c58a8450":"wc_message(data, 'ham')","cd1a57bb":"#!pip install -U spacy\nimport spacy\n","91ea97b8":"!python -m spacy info en ","c6a9dc05":"#!python3 -m spacy download en","55b0b555":"nlp = spacy.load('en', tagger=False, parser=False, matcher=False)\ndef toknize(text):\n  tokens = nlp(text)    \n  return tokens.text.split(\" \")\n  \n","2bc6fc1c":"data['tokens'] = data['body_text_clean'].apply(lambda x: toknize(x))\ndisplay(data.head())","baa6181d":"# Remove English stop words \nfrom spacy.lang.en.stop_words import STOP_WORDS\n\nprint(STOP_WORDS) \n# you can add new stop words with this command \n#STOP_WORDS.add(\"your_additional_stop_word_here\")","b4542496":"def remove_stopwords(tokenized_list):\n  text = [word for word in tokenized_list if word not in STOP_WORDS]\n  return text","fd191bc8":"data['text_nostop'] = data['tokens'].apply(lambda x: remove_stopwords(x))\n\nprint(data.head())","aac81946":"from spacy import displacy\n\ndoc = nlp(data.body_text_clean[0])\ndisplacy.render(doc, style='dep', jupyter=True)\n","61c30956":"def lemmatizing(tokenized_text):\n    doc = str(tokenized_text).replace('[','').replace(']','')\n    doc = nlp(doc)\n    text = [token.lemma_ for token in doc]\n    text = [w for w in text if w.isalpha() or w.isdigit()]\n\n    return text","5684e297":"data['text_lemmatized'] = data['text_nostop'].apply(lambda x: lemmatizing(x))\n\nprint(data.head())","3f26691c":"def count_punct(text):\n    count = sum([1 for char in text if char in string.punctuation])\n    return round(count\/(len(text) - text.count(\" \")), 3)*100\n\ndata['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\ndata['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\nprint(data.head())","d847ef49":"bins = np.linspace(0, 200, 40)\n\npl.hist(data['body_len'], bins)\npl.title(\"Body Length Distribution\")\npl.show()","f64acef7":"bins = np.linspace(0, 50, 40)\n\npl.hist(data['punct%'], bins)\npl.title(\"Punctuation % Distribution\")\npl.show()","3977e13e":"display(data.head(2))","5a9012f6":"# preprocessing.StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Initialize a scaler, then apply it to the features\nscaler = MinMaxScaler() # default=(0, 1)\nnumerical = ['body_len', 'punct%']\n\ndata[numerical] = scaler.fit_transform(data[numerical])\n\n# Show an example of a record with scaling applied\ndisplay(data.head(n = 5))","716c0cd6":"# save data after normlize it in pkl file to use it latter\nfrom sklearn.externals import joblib\n\njoblib.dump(scaler, 'scalr.pkl')\n","4f13b82c":"# convert label to number before aplly ML algorithms\nlabel_map = {'spam': 1, 'ham': 0}\ndata['label'] = data['label'].map(label_map)","2139fff3":"display(data.head(3))","8459e66f":"features_final = data[['text_lemmatized', 'body_len', 'punct%']]\nlabel = data['label']","16b3f47d":"# Split the 'features' and 'income' data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features_final, \n                                                    label, \n                                                    test_size = 0.2, \n                                                    random_state = 0)\n\n# Show the results of the split\nprint(\"Training set has {} samples.\".format(X_train.shape[0]))\nprint(\"Testing set has {} samples.\".format(X_test.shape[0]))","7aeb9ae4":"# conver 'text_lemmatized' col from list to string to apply TfidfVectorizer on it\ndef tostring(text):\n  doc = str(text).replace('[','').replace(']','')\n  return doc\n\n  ","272f602e":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n\ntfidf_vect = TfidfVectorizer(analyzer = tostring)\ntfidf_vect_fit = tfidf_vect.fit(X_train['text_lemmatized'])\n\ntfidf_train = tfidf_vect_fit.transform(X_train['text_lemmatized'])\ntfidf_test = tfidf_vect_fit.transform(X_test['text_lemmatized'])\n\nX_train_vect = pd.concat([X_train[['body_len', 'punct%']].reset_index(drop=True), \n           pd.DataFrame(tfidf_train.toarray())], axis=1)\nX_test_vect = pd.concat([X_test[['body_len', 'punct%']].reset_index(drop=True), \n           pd.DataFrame(tfidf_test.toarray())], axis=1)\n\ndisplay(X_train_vect.head())","20adcdb1":"from sklearn.externals import joblib\n\njoblib.dump(tfidf_vect, 'vectroizer.pkl')","3b7707a1":"'''\nTP = np.sum(label) # Counting the ones as this is the naive case. \nFP = label.count() - TP # Specific to the naive case\n\nTN = 0 # No predicted negatives in the naive case\nFN = 0 # No predicted negatives in the naive case\n'''\n\n# Calculate ones in income (True postive) and zeroes \nTP = np.sum(label)\nFP = label.count() - TP \nTN = 0\nFN = 0\n\n# TODO: Calculate accuracy, precision and recall\naccuracy = TP \/(TP + FP)\nrecall = TP \/ (TP + FN)\nprecision = TP \/ (TP + FP)\n\n# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\nbeta = 0.5\nfscore = (1 + beta**2)*((precision * recall) \/ ((beta**2 * precision) + recall))\n\n# Print the results \nprint(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))","9f72c3a1":"# Import two metrics from sklearn - fbeta_score and accuracy_score\nfrom sklearn.metrics import fbeta_score , accuracy_score\n\ndef train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n    '''\n    inputs:\n       - learner: the learning algorithm to be trained and predicted on\n       - sample_size: the size of samples (number) to be drawn from training set\n       - X_train: features training set\n       - y_train: label training set\n       - X_test: features testing set\n       - y_test: label testing set\n    '''\n    \n    results = {}\n    \n    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n    start = time() # Get start time\n    learner = learner.fit(X_train[: sample_size], y_train[: sample_size])\n    end = time() # Get end time\n    \n    # Calculate the training time\n    results['train_time'] = end - start\n        \n    # Get the predictions on the test set(X_test),\n    # then get predictions on the first 300 training samples(X_train) using .predict()\n    start = time() # Get start time\n    predictions_test = learner.predict(X_test)\n    predictions_train = learner.predict(X_train[:300])\n    end = time() # Get end time\n    \n    # Calculate the total prediction time\n    results['pred_time'] = end - start\n            \n    # Compute accuracy on the first 300 training samples which is y_train[:300]\n    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n        \n    # Compute accuracy on test set using accuracy_score()\n    results['acc_test'] = accuracy_score(y_test, predictions_test)\n    \n    # Compute F-score on the the first 300 training samples using fbeta_score()\n    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta = 0.5)\n        \n    # Compute F-score on the test set which is y_test\n    results['f_test'] = fbeta_score(y_test, predictions_test, beta = 0.5)\n       \n    # Success\n    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n        \n    # Return the results\n    return results","566a95c0":"#visualization\n\ndef evaluate(results, accuracy, f1):\n    \"\"\"\n    Visualization code to display results of various learners.\n    \n    inputs:\n      - learners: a list of supervised learners\n      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n      - accuracy: The score for the naive predictor\n      - f1: The score for the naive predictor\n    \"\"\"\n  \n    # Create figure\n    fig, ax = pl.subplots(2, 4, figsize = (11,7))\n\n    # Constants\n    bar_width = 0.3\n    colors = ['#A00000','#00A0A0','#00A000']\n    \n    # Super loop to plot four panels of data\n    for k, learner in enumerate(results.keys()):\n        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n            for i in np.arange(3):\n                \n                # Creative plot code\n                ax[j\/\/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n                ax[j\/\/3, j%3].set_xticks([0.45, 1.45, 2.45])\n                ax[j\/\/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n                ax[j\/\/3, j%3].set_xlabel(\"Training Set Size\")\n                ax[j\/\/3, j%3].set_xlim((-0.1, 3.0))\n    \n    # Add unique y-labels\n    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n    ax[0, 1].set_ylabel(\"Accuracy Score\")\n    ax[0, 2].set_ylabel(\"F-score\")\n    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n    ax[1, 1].set_ylabel(\"Accuracy Score\")\n    ax[1, 2].set_ylabel(\"F-score\")\n    \n    # Add titles\n    ax[0, 0].set_title(\"Model Training\")\n    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n    ax[0, 2].set_title(\"F-score on Training Subset\")\n    ax[1, 0].set_title(\"Model Predicting\")\n    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n    ax[1, 2].set_title(\"F-score on Testing Set\")\n    \n    # Add horizontal lines for naive predictors\n    ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n    ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n    ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n    ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n    \n    # Set y-limits for score panels\n    ax[0, 1].set_ylim((0, 1))\n    ax[0, 2].set_ylim((0, 1))\n    ax[1, 1].set_ylim((0, 1))\n    ax[1, 2].set_ylim((0, 1))\n\n    # Set additional plots invisibles\n    ax[0, 3].set_visible(False)\n    ax[1, 3].axis('off')\n\n    # Create legend\n    for i, learner in enumerate(results.keys()):\n        pl.bar(0, 0, color=colors[i], label=learner)\n    pl.legend()\n    \n    # Aesthetics\n    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n    pl.tight_layout()\n    pl.show()","60289209":"# Import the  supervised learning models from sklearn\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\nfrom time import time\nimport matplotlib.pyplot as pl\n\n# Initialize the three models\nclf_A = GaussianNB()\nclf_B = AdaBoostClassifier(random_state = 1)\nclf_C = SVC(random_state = 1)\n\n# Calculate the number of samples for 1%, 10%, and 100% of the training data\nsamples_100 = len(y_train)\nsamples_10 = len(y_train)\/\/10\nsamples_1 = len(y_train)\/\/100\n\n# Collect results on the learners\nresults = {}\nfor clf in [clf_A, clf_B, clf_C]:\n    clf_name = clf.__class__.__name__\n    results[clf_name] = {}\n    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n        results[clf_name][i] = \\\n        train_predict(clf, samples, X_train_vect, y_train, X_test_vect, y_test)\n\n# Run metrics visualization for the three supervised learning models chosen\nevaluate(results, accuracy, fscore)","2b99d86e":"# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import fbeta_score, make_scorer\n\n# Initialize the classifier\nclf = AdaBoostClassifier(random_state=1)\n\nparameters = {'n_estimators' : [50, 100, 150, 250, 500], 'learning_rate': [0.01, 0.1, 1, 1.5, 2]}\n\n# Make an fbeta_score scoring object using make_scorer()\nscorer =make_scorer(fbeta_score, beta= 0.5)\n\n# Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\ngrid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n\n# Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train_vect, y_train)\n\n# Get the estimator\nbest_clf = grid_fit.best_estimator_\n\n# Make predictions using the unoptimized and model\npredictions = (clf.fit(X_train_vect, y_train)).predict(X_test_vect)\nbest_predictions = best_clf.predict(X_test_vect)\n\n# Report the before-and-afterscores\nprint(\"Unoptimized model\\n------\")\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\nprint(\"\\nOptimized Model\\n------\")\nprint(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))","3db87f99":"display(grid_fit.best_estimator_)","0099242f":"#Train the model on the training set using .fit(X_train_vect, y_train)\nmodel = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n          learning_rate=0.1, n_estimators=100, random_state=1)\nstart = time()\nmodel.fit(X_train_vect, y_train)\nend = time()\nfit_time = (end - start)\nstart = time()\ny_pred = model.predict(X_test_vect)\nend = time()\npred_time = (end - start)\n\nrecision, recall, fscore, train_support = score(y_test, y_pred)\nprint('Fit time: {} \/ Predict time: {} ---- Precision: {} \/ Recall: {} \/ Accuracy: {}'.format(\n    np.round(fit_time, 3), np.round(pred_time, 3), np.round(precision, 3), np.round(recall, 3), np.round((y_pred==y_test).sum()\/len(y_pred), 3)))\n","49aa49bf":"# Save to file in the current working directory\njoblib_file = \"joblib_model.pkl\"  \njoblib.dump(model, joblib_file)\n","c32129a4":"joblib_file = \"joblib_model.pkl\"  \n\njoblib_model = joblib.load(joblib_file)\n\n# Calculate the accuracy and predictions\nscore = joblib_model.score(X_test_vect, y_test)  \nprint(\"Test score: {0:.2f} %\".format(100 * score))  \nYpredict = joblib_model.predict(X_test_vect)  \n","64fea2ae":"def prep_text(mesg):\n  text = remove_punct(mesg)\n  data = pd.DataFrame({'body_text' : text}, index=[0])\n  data['tokens'] = data['body_text'].apply(lambda x: toknize(x))\n  data['text_nostop'] = data['tokens'].apply(lambda x: remove_stopwords(x))\n  data['text_lemmatized'] = data['text_nostop'].apply(lambda x: lemmatizing(x))\n  data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n  data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n  return data\n  \n  \n  ","2de1b5c6":"# ham msg\nmsg = \"\"\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\"\"","58ba9d82":"data_prep = prep_text(msg)\ndisplay(data_prep)","fab7341b":"file = 'scalr.pkl'\nscaler = joblib.load(file) \nnumerical = ['body_len',  'punct%']\ndata_prep[numerical] = scaler.transform(data_prep[numerical])\n\ndisplay(data_prep)","d6202027":"vectorizer = joblib.load('vectroizer.pkl')\ntfidf_msg_pred = vectorizer.transform(data_prep['text_lemmatized'])\nX_pred_vect = pd.concat([data_prep[['body_len', 'punct%']].reset_index(drop=True), \n           pd.DataFrame(tfidf_msg_pred.toarray())], axis=1)\n\ndisplay(X_pred_vect.head())\n","a6e1f54f":"try:\n    Ypredict = joblib_model.predict(X_pred_vect)\n    if Ypredict[0] == 0:\n       print(\"msg is ham\")\n    elif Ypredict[0] == 1:\n        print(\"msg is spam\")\nexcept Exception as e:\n  print(e)\n","1edef3e8":"# Choosing the Best Model\n- The most appropriate solution to this problem would be achieved using AdaBoostClassifier .\n - In terms of the F-score, Adaboost slightly outperforms SVC at all training set sizes and significately outperforms GaussianNB.\n - In terms of the time Both the Adaboost and the GaussianNB algorithms are capable of both training on the entire data set and quickly performing predictions.\n - In terms of the accuracies at all training and testing set sizes Adaboost are significantly higher than those obtained when using the GuassianNB algorithm and as high as those ahieved by the more complex SVC model.\n- For this reasons we can say that Adaboost is best suited for this problem. We will be able to fully utilize the entire dataset to maximize the performance in the unseen data without compromising on training and testing the speeds.and will give us accurate result for spam message","97ebb4ed":"#Embedded this model in flask app\n\n- i will embedded this model in flask app in few days and i'll put code in my [github](https:\/\/github.com\/megz2020\/Spam-Classification)","a084bac8":"# Cleaning data","f4ea9548":"# Supervised Learning Models\n","7968fd9a":"# Implementation\n","1c7b4f66":"# Now we will test new data","a0903863":"# Save model","2b7ab599":"# Implementation: Model Tuning\n","76f9688d":"I will investigate  different algorithms, and determine which is best at modeling the data.","16c01def":"# save my vectorize text in pkl file to use it later without make previous step","85613873":"# Implementation: Data Exploration\n\nA cursory investigation of the dataset will determine how many sms fit into either group, and will tell us about the percentage of these sms which are spam. \n","3dfd5b23":"### Lemmatize *text*","76d75912":"# Implementation: Initial Model Evaluation\n\nIn the code cell, i will  implement the following:\n\n* Import the three supervised learning models i've discussed in the previous section.\n* Initialize the three models and store them in 'clf_A', 'clf_B', and 'clf_C'.\n* Use a 'random_state' for each model i use.\n* Calculate the number of records equal to 1%, 10%, and 100% of the training data.\n* Store those values in 'samples_1', 'samples_10', and 'samples_100' respectively.\n","e82c5004":"# Normalizing Numerical Features\n","cb272dfe":"# Evaluating Model Performance\n","b95ab4cf":"**AdaBoost:**\n* A classic use case where AdaBoost algorithms is in the problem of Face Detection.\n\n* Strengths:\n\n * AdaBoost very simple to implement we can achieve similar classification results with much less tweaking of parameters or settings The user only needs to choose:\n\n   1. which weak classifier might work best to solve their given classification problem.\n   2. the number of boosting rounds that should be used during the training phase.\n   \n * Feature selection on very large sets of features.\n\n* Weaknesses\n\n * AdaBoost can be sensitive to noisy data and outliers. In some problems, however, it can be less susceptible to the overfitting problem than most learning algorithms. AdaBoost algorithm does not currently support null rejection, although this will be added at some point in the near future.\n * This particular model could be a good approach to solving the problem as we have a large data set so we can we can perform multiple quick trainining iterations to maximize our overall accuracy.\n\n* References:\n * [analyticsvidhya](https:\/\/www.analyticsvidhya.com\/blog\/2015\/05\/boosting-algorithms-simplified\/)\n * [nickgillian](http:\/\/www.nickgillian.com\/wiki\/pmwiki.php\/GRT\/AdaBoost)\n * [slideshare - Machine learning with ADA Boost](https:\/\/www.slideshare.net\/aman3001\/machine-learning-with-ada-boost)","c45215a8":"# Shuffle and Split Data\n\nNow all categorical variables have been converted into numerical features, and all numerical features have been normalized. As always, we will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing.\n\n\n","cda203d8":"# Project: Spam Classification\n\n## Getting Started\nIn this project, you will employ several Machine learning algorithms  to accurately model classify messages as spam or not spam using a collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site.\n\n The dataset for this project originates from the [UCI Machine Learning Repository](https:\/\/archive.ics.uci.edu\/ml\/datasets\/sms+spam+collection#)\n The datset was donated by  Min-Yen Kan and his team ","78d51d1d":"**The following are some of the supervised learning models that are currently available in scikit-learn that i will use:**\n\n","8153f9aa":"# Test model","60081101":"# conclusion\nAs we see we have messy data so we try to make it tidy as possible to make it suitable for ML algorithms\n- i use spacy which an open-source software library for advanced Natural Language Processing to split text in to words .\n- then convert this words to numbers\n- i try some algorithms and choose the best one\n- AdaBoost is short for Adaptive Boosting. It is basically a machine learning algorithm that is used as a classifier. Whenever you have a large amount of data and you want divide it into different categories, we need a good classification algorithm to do it. Problems in machine learning tend to suffer from the curse of dimensionality. What it means is that a single feature point ends up having a huge dimensionality. As in, the feature vector used to describe a particular thing can be very huge. So if each sample consists of a huge number of potential features, the overall system becomes very slow. This is the reason we cannot use a powerful model with a full feature set because it cannot run in real time. We can only afford to have simple machine learning algorithms. But if the algorithms are too simple, they tend to be less accurate. They are called \u2018weak learners\u2019\n\n- Boosting algorithms typically work by solving subsections of the problem, by peeling them away so future boosting iterations can solve the remaining sections.\n\n- imagine we have some questions in different fields(math, physics , chemistry)i ask my friend who proficient in math to answer this questions after he answer i'm sure he answer math questions very well but i'm not sure about other questions so we go to another friend who proficient in physics and ask him to answer the questions like before i'm sure he answer physics questions very well but i'm not sure about other questions but now i have one can give me right answer for math questions and one who can give me right answer for physics questions this is better than before. now i want one who is proficient in chemistryfor our luck my friend's brother is thr right guy so i ask him to answer the questions so now each group of my questions is completely solved.\n- The takeaway is that weak learners are best combined in a way that allows each one to solve a limited section of the problem. Any machine learning routine can be used as a weak learner. Neural nets, support vector machines or any other would work, but the most commonly used weak learner is the decision tree.\n- so in our model it combines the outputs from weak learner and creates a strong learner which eventually improves the prediction power of the model. Boosting pays higher focus on examples which are mis-classi\ufb01ed or have higher errors by preceding weak rules.\n\n\n\n","5fb1bb01":"**Gaussian Naive Bayes**\n\n* A classical use case is document classification: Determining whether a given (text) document corresponds to one or more categories and for classifying and filtering spam emails based on the likelihood of certain words appearing on an spam email as compared to a non-spam email\n\n* Strengths:\n\n * Easy to implement , Simple to run\n * If the NB conditional independence assumption holds, then it will converge quicker than discriminative models like logistic regression\n * Even if the NB assumption doesn\u2019t hold, it works great in practice.\n * Less training data than others\n * Can be used for both binary and mult-iclass classification problems.\n * Performs pretty well\n* Weaknesses:\n\n * It can\u2019t learn interactions between features (e.g., it can\u2019t learn that although you love movies with Brad Pitt and Tom Cruise, you hate movies where they\u2019re together).\n * Data scarcity For any possible value of a feature, you need to estimate a likelihood value by a frequentist approach. This can result in probabilities going towards 0 or 1, which in turn leads to numerical instabilities and worse results. In this case, you need to smooth in some way your probabilities (e.g. as in sklearn), or to impose some prior on your data, however you may argue that the resulting classifier is not naive anymore.\n* This particular model could be a good approach to solving the problem as we have a large data set with few features.\n\n* References:\n * [wikipedia](https:\/\/en.wikipedia.org\/wiki\/Naive_Bayes_spam_filtering)\n * [quora - real world applications for Naive Bayes classifier](https:\/\/www.quora.com\/In-what-real-world-applications-is-Naive-Bayes-classifier-used)\n * [youtube- udacity - Naive Bayes Strengths and Weaknesses](https:\/\/www.youtube.com\/watch?v=nfbKTrufPOs)\n * [quora - the advantages of using a naive Bayes for classification](https:\/\/www.quora.com\/What-are-the-advantages-of-using-a-naive-Bayes-for-classification)\n * [quora - disadvantages of using a naive bayes for classification](https:\/\/www.quora.com\/What-are-the-disadvantages-of-using-a-naive-bayes-for-classification#ypRbo)\n\n\n\n","2ef55278":"### Vectorize text","b930f669":"# Exploring the Data\n\n","e69a82eb":"**Support Vector Machines (SVC)**\n\n* SVMs can be used to solve various real world problems:\n\n * SVMs are helpful in text and hypertext categorization as their application can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.\n * Face Detection.\n   * It classifies the parts of the image as face and non-face. It contains training data of n x n pixels with a two-class face (+1) and non-face (-1). Then it extracts features from each pixel as face or non-face. Creates a square boundary around faces on the basis of pixel brightness and classifies each image by using the same process.\n * Classification of images.\n   * Experimental results show that SVMs achieve significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback.\n * Hand-written characters can be recognized\n Bioinformatics.\n\n* Strengths:\n\n * High accuracy\n * Nice theoretical guarantees regarding overfitting\n * With an appropriate kernel they can work well even if you\u2019re data isn\u2019t linearly separable in the base feature space.\n* Weaknesses:\n\n * Don't perform so well in very large data set because the training time happens to be cubic in size of data set.\n * Don't work very well in lots and lots of noise do when class are very overlapping you have to count independent evidence that's where the naive bayes classifier would be better.\n * The theory only really covers the determination of the parameters for a given value of the regularisation and kernel parameters and choice of kernel. In a way the SVM moves the problem of over-fitting from optimising the parameters to model selection. Sadly kernel models can be quite sensitive to over-fitting the model selection criterion.\n * The model could be still be a good candidate as there seems to be some features in the data that can more clearly define the income level boundary and dataset not very large so it won't take so long training time\n\n* References:\n * [wikipedia](https:\/\/en.wikipedia.org\/wiki\/Support_vector_machine#Applications)\n * [data-flair - Real-Life Applications of SVM](https:\/\/data-flair.training\/blogs\/applications-of-svm\/)\n * [blog.echen.me](http:\/\/blog.echen.me\/2011\/04\/27\/choosing-a-machine-learning-classifier\/)\n * [youtube - udacity - SVM Strengths and Weaknesses](https:\/\/www.youtube.com\/watch?v=U9-ZsbaaGAs)\n * [stackexchange - Advantages and disadvantages of SVM](https:\/\/stats.stackexchange.com\/questions\/24437\/advantages-and-disadvantages-of-svm)","c97a3fce":"## Metrics and the Naive Predictor\n\n\n\n","f3b1808f":"# Create the two new features","57f0fe42":"# Implementation - Creating a Training and Predicting Pipeline\nTo properly evaluate the performance of each model you've chosen, it's important to create a training and predicting pipeline that allows us to quickly and effectively train models using various sizes of training data and perform predictions on the testing data.  In the code block below, i will  implement the following:\n\n* Import fbeta_score and accuracy_score from sklearn.metrics.\n* Fit the learner to the sampled training data and record the training time.\n* Perform predictions on the test data X_test, and also on the first 300    training points X_train[:300].\n* Record the total prediction time.\n* Calculate the accuracy score for both the training subset and testing set.\n* Calculate the F-score for both the training subset and testing set.\n","0df0f374":" Because of we  are  particularly interested in predicting which sms spam  accurately. It would seem that using accuracy as a metric for evaluating a particular model's performace would be appropriate. Therefore, a model's ability to precisely predict those which are spam as is more important than the model's ability to recall those not related. We can use F-beta score as a metric that considers both precision and recall:\n\n\n$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\nIn particular, when $\\beta = 0.5$, more emphasis is placed on precision. This is called the <strong>F$_{0.5}$ score (or F-score for simplicity).\n\nIt is always important to consider the naive prediction for your data, to help establish a benchmark for whether a model is performing well. using that prediction would be pointless","23727d17":"## install spacy to use it in extract features from text \n* i didnot find english model so i will install it"}}