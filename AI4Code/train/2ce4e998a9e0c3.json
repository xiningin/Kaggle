{"cell_type":{"9f17eae2":"code","097756c4":"code","c0198a77":"code","b6662636":"code","34abc26e":"code","7052ad63":"code","486329d9":"code","f4f3b605":"code","3cbdae47":"code","e96e762b":"code","23ac903e":"code","b033ec8e":"code","91b7137a":"code","90a31ee4":"code","bd384090":"code","2dce4c04":"code","025f8f5a":"code","03052db9":"markdown","4a3bf840":"markdown","2470b536":"markdown","9febcb9a":"markdown","e95039f4":"markdown","37d04592":"markdown","56f71935":"markdown"},"source":{"9f17eae2":"import tensorflow as tf\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport glob\nimport pickle","097756c4":"import random \nfrom tensorflow.keras.layers import Conv2D,Dense,MaxPooling2D,Dropout,Flatten,Activation,MaxPool2D,BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.utils import plot_model","c0198a77":"CATAGORIES=['Bishop','King','Knight','Pawn','Queen','Rook'] ## define the list of number of classes we are going to use.\nDATADIR='..\/input\/chessman-image-dataset\/Chessman-image-dataset\/Chess' # dataset path \nIMG_SIZE=300  ## mention size of image you wanted","b6662636":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                    validation_split=0.3,\n                                    rotation_range=20,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                   shear_range=3, \n                                    zoom_range=50,\n                                    horizontal_flip=True,\n                                   vertical_flip=True)","34abc26e":"batch_size=32\nIMG_HEIGHT=300\ntrain_dir='\/kaggle\/input\/chessman-image-dataset\/Chessman-image-dataset\/Chess'\nos.listdir(train_dir)","7052ad63":"X_train_datagen=train_datagen.flow_from_directory(batch_size=batch_size,\n                                                   directory=train_dir,\n                                                   shuffle=True,\n                                                   target_size=(IMG_HEIGHT, IMG_HEIGHT),\n                                                   subset='training',\n                                                   class_mode='categorical',\n                                                   color_mode='grayscale',\n                                                   seed=42)\n                                                  \n                                                  \nvalidation_generator = train_datagen.flow_from_directory(\n                                                        directory=train_dir,\n                                                        target_size=(IMG_HEIGHT, IMG_HEIGHT),\n                                                        color_mode='grayscale',\n                                                        batch_size=batch_size,\n                                                        class_mode='categorical',\n                                                        subset='validation',\n                                                        shuffle=True,\n                                                        seed=42)","486329d9":"input_shape=(32, 300, 300, 1) ### here full size for model input  (batch_size,img_Size,img_size,1)","f4f3b605":"model = Sequential([\n    Conv2D(16, (3,3), input_shape=input_shape[1:], padding='same', activation='relu'),\n    MaxPooling2D(pool_size=(2,2)),\n    Conv2D(32, (3,3), padding='same', activation='relu'),\n    MaxPooling2D(pool_size=(2,2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(6, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])","3cbdae47":"model.summary()","e96e762b":"Early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)#to prevent overffiting of dataset","23ac903e":"from keras.callbacks import ReduceLROnPlateau ##### To control learning rate\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0005) \ncallback = [Early,learning_rate_reduction]","b033ec8e":"#image,label=next(X_train_datagen)\n#input_shape=image.shape (32, 300, 300, 1)","91b7137a":"history = model.fit_generator(X_train_datagen,\n                              validation_data=validation_generator,\n                              callbacks = callback, \n                              epochs=10,\n                              verbose=0\n                             )### fit dataset for just 10 epoch \n###we can fit for more epoch but our purpose just learning since we prefer 10 epoch may be you train for 50-200 epoch","90a31ee4":"#history=model.fit(trainX, trainY, batch_size=32, epochs=20, verbose=1, validation_data=(testX, testY),callbacks=[callback])","bd384090":"plt.figure(1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model_Accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['train', 'validation'], loc='upper left')","2dce4c04":"##### just and image plotting function\ndef img_plot(x):\n    ndarray=prepare(x)\n    plt.plot(ndarray)\n    plt.show()","025f8f5a":"\n\ndef prepare(file):\n    img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    new_array = cv2.resize(img_array, (IMG_HEIGHT, IMG_HEIGHT))\n    plt.imshow(new_array)\n    return new_array.reshape(-1, IMG_HEIGHT, IMG_HEIGHT, 1)\n#image = testX[1]#your image path\nimage='..\/input\/chessman-image-dataset\/Chessman-image-dataset\/Chess\/Rook\/00000010.jpg'\nprediction = model.predict([prepare(image)])\n#img_plot(image)\nprediction = list(prediction[0])\n#print(CATAGORIES[prediction.index(max(prediction))])\ntemp=CATAGORIES[prediction.index(max(prediction))]\nplt.title(temp)\nplt.show()","03052db9":"**You can use this notebook for referal alsoand feel free to upvote and folk**","4a3bf840":"### Define simple two layer CNN followed by dense two dense unit","2470b536":"### testing how our model works ","9febcb9a":"### Hello guys its just and introductory notebook for CNN and how to train them ","e95039f4":"# **Conclusion:**\n1. as you all are seeing whatever steps i perform on this dataset its very basic one and simplest.\n1. we can further use any transfer learning technique to so that good results can be achieved.\n1. i think there is some issu with the dataset beacuse of that we are getting the expected accuracy.\n1. anyways just use this steps for reference \n1. last tip in classification we cannot judge any model with only accuracy, we need something more i.e. confusion matrix, f1-Score, AUC curve, TRP\/TNR,etc.","37d04592":"## **Hey guys if you read upto this point please give one upvote....your every upvote make me feel motivated**","56f71935":"## visuallize the train acc "}}