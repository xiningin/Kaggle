{"cell_type":{"3f0ff4f0":"code","52f884af":"code","488756e0":"code","56b114ef":"code","9d0eddfe":"code","0e270e98":"code","f2eacc13":"code","0b4f1e6f":"code","c3c8a5fa":"code","f6ce511a":"code","d39ea76f":"code","d754403c":"code","41eb4457":"code","8dda30bb":"code","55813d42":"code","b82d58cd":"code","75379bec":"code","ba3b446a":"code","5ea39183":"code","997cd7ab":"code","0c5250b9":"code","bca5809c":"code","fe94adae":"code","84fe3c47":"code","9c64e68b":"code","40d00a9f":"code","42c3e68b":"code","fe88ba50":"code","16d33aa1":"code","04ef65f3":"code","52df4e48":"code","cbe0bf21":"code","6bbc5cce":"code","5eabe3d6":"code","bb661486":"code","74e581e4":"code","9c15ec96":"code","2aaba3c7":"code","dc727075":"code","2d0e24ee":"code","44e6fd5a":"code","984b66aa":"code","ae75fac2":"code","3b59d9ea":"code","39f7f76d":"code","9a624c43":"code","439601c8":"code","a4db6eef":"code","50437dfe":"code","8f6ccf73":"code","5d774181":"code","0d5a2b95":"code","d6825043":"code","786063b4":"code","adeef2e5":"code","14030a02":"code","85fad17d":"code","7603b84c":"code","631ce962":"code","ffa2809d":"code","40db19eb":"code","d8e34f69":"code","748867bb":"code","e7297323":"code","42c19114":"code","e574a3dd":"code","63d687bf":"code","828319f1":"code","467bcb13":"code","36504534":"code","dfc6dfce":"code","275504bc":"code","f7ca893b":"code","1fa008cd":"code","6eb6b066":"code","86682a4d":"code","885622c3":"code","ce89113c":"code","1895503c":"markdown","0813d6b0":"markdown","e9497589":"markdown","08a005da":"markdown"},"source":{"3f0ff4f0":"%config Completer.use_jedi = False","52f884af":"# part of 2nd place solution: lightgbm model with private score 0.29124 and public lb score 0.28555\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport lightgbm as lgbm\nfrom scipy import sparse as ssp\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder","488756e0":"def Gini(y_true, y_pred):\n    # check and get number of samples\n    assert y_true.shape == y_pred.shape\n    n_samples = y_true.shape[0]\n\n    # sort rows on prediction column\n    # (from largest to smallest)\n    arr = np.array([y_true, y_pred]).transpose()\n    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n\n    # get Lorenz curves\n    L_true = np.cumsum(true_order) * 1. \/ np.sum(true_order)\n    L_pred = np.cumsum(pred_order) * 1. \/ np.sum(pred_order)\n    L_ones = np.linspace(1 \/ n_samples, 1, n_samples)\n\n    # get Gini coefficients (area between curves)\n    G_true = np.sum(L_ones - L_true)\n    G_pred = np.sum(L_ones - L_pred)\n\n    # normalize to true Gini coefficient\n    return G_pred * 1. \/ G_true","56b114ef":"NROWS = 5000\ncv_only = True\nsave_cv = True\nfull_train = False","9d0eddfe":"# Customized Function\uc0dd\uc131\uc2dc \uc778\uc790\ub294 Prediction, dTrain\ndef evalerror(preds, dtrain): \n    labels = dtrain.get_label()\n    return 'gini', Gini(labels, preds), True","0e270e98":"path = \"..\/input\/porto-seguro-safe-driver-prediction\/\"","f2eacc13":"%%time\ntrain = pd.read_csv(path+'train.csv', nrows=NROWS)\ntrain_label = train['target']\ntrain_id = train['id']\ntest = pd.read_csv(path+'test.csv', nrows=NROWS)\ntest_id = test['id']","0b4f1e6f":"NFOLDS = 5","c3c8a5fa":"kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)","f6ce511a":"y = train['target'].values\ndrop_feature = [\n    'id',\n    'target'\n]","d39ea76f":"X = train.drop(drop_feature, axis=1)","d754403c":"X.columns.tolist()","41eb4457":"feature_names = X.columns.tolist()","8dda30bb":"cat_features = [c for c in feature_names if ('cat' in c and 'count' not in c)]\nnum_features = [c for c in feature_names if ('cat' not in c and 'calc' not in c)] # calc\uac00 \uc758\ubbf8\uac00 \uc5c6\ub2e4\ub294 \uc758\uacac\ub4e4\uc774 \uc788\uc5b4 calc\uac00 \ud3ec\ud568\ub41c \uceec\ub7fc \uc81c\uc678","55813d42":"# \uac01 \ud53c\ucc98\uac00 \uac00\uc9c0\uace0 \uc788\ub294 Null,Missing Value \uad00\ub828 \ud53c\ucc98 \uc0dd\uc131\ntrain == -1","b82d58cd":"(train==-1).sum(axis=1).value_counts()","75379bec":"train['missing'] = (train==-1).sum(axis=1).astype(float)\ntest['missing'] = (test==-1).sum(axis=1).astype(float)\nnum_features.append('missing')","ba3b446a":"num_features","5ea39183":"# Category \ub370\uc774\ud130 Label Encoding\nfor c in cat_features:\n    le = LabelEncoder()\n    le.fit(train[c])\n    train[c] = le.transform(train[c])\n    test[c] = le.transform(test[c])","997cd7ab":"train","0c5250b9":"enc = OneHotEncoder()\nenc.fit(train[cat_features])","bca5809c":"X_cat = enc.transform(train[cat_features])\nX_t_cat = enc.transform(test[cat_features])","fe94adae":"ind_features = [c for c in feature_names if 'ind' in c]","84fe3c47":"count = 0\nfor c in ind_features:\n    if count == 0:\n        train['new_ind'] = train[c].astype(str) + '_'\n        test['new_ind'] = test[c].astype(str) + '_'\n        count+=1\n    else:\n        train['new_ind'] += train[c].astype(str)+'_'\n        test['new_ind'] += test[c].astype(str)+'_'","9c64e68b":"train['new_ind'].value_counts().shape[0]","40d00a9f":"# ind feature\ub4e4\uc744 \ud558\ub098\ub85c \ubb36\uc5b4\uc11c \uc0c8\ub85c\uc6b4\uce74\ud14c\uace0\ub9ac\ub97c \ub9cc\ub4e4\uc5b4 \ub0b4\ub294 \uc791\uc5c5.\n# discussion\uc5d0 ind \ud53c\uccd0\uac00 \uc5ee\uc5ec\uc788\uc9c0 \uc54a\uc558\ub098.. \uadf8\ub798\uc11c \ub2e4 \ud569\ucce4\ub2e4. \n# Frequency Encoding....\ncat_count_features = []\nfor c in cat_features+['new_ind']:\n    break;","42c3e68b":"c","fe88ba50":"train[c],test[c]","16d33aa1":"pd.concat([train[c],test[c]]).value_counts().to_dict() # 7000\uc5ec\uac1c\ub098 \ub418\ub294 High Cardinality\ub97c \uc774\ub118\uc73c\ub85c \ub300\uccb4","04ef65f3":"d = pd.concat([train[c],test[c]]).value_counts().to_dict() # 7000\uc5ec\uac1c\ub098 \ub418\ub294 High Cardinality\ub97c \uc774\ub118\uc73c\ub85c \ub300\uccb4","52df4e48":"train[c].apply(lambda x:d.get(x,0))","cbe0bf21":"train[c]","6bbc5cce":"for c in cat_features+['new_ind']:\n    d = pd.concat([train[c],test[c]]).value_counts().to_dict()\n    train['%s_count'%c] = train[c].apply(lambda x:d.get(x,0))\n    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n    cat_count_features.append('%s_count'%c)","5eabe3d6":"cat_count_features","bb661486":"X_cat[0][0][0]","74e581e4":"# Categorical -> Frequence Encoding + One Hot Encoding\uc73c\ub85c \ud45c\ud604.\ntrain_list = [train[num_features+cat_count_features].values,X_cat]\ntest_list = [test[num_features+cat_count_features].values,X_t_cat]","9c15ec96":"train_list # one hot encoding\ud558\uba74 0\uc774 \ub108\ubb34 \ub9ce\uc544\uc11c Compressed Sparse Row \uc801\uc6a9\ub428.","2aaba3c7":"len(train_list)","dc727075":"ssp.hstack(train_list)","2d0e24ee":"ssp.hstack(train_list).tocsr() # CSR: Compressed Sparse Row ","44e6fd5a":"X = ssp.hstack(train_list).tocsr() # Sparse Matrix\ub85c \ud47c\ub2e4.","984b66aa":"X[0][0]","ae75fac2":"X_test = ssp.hstack(test_list).tocsr()","3b59d9ea":"learning_rate = 0.1\nnum_leaves = 15 \nmin_data_in_leaf = 2000 # \ud559\uc2b5\ud560 \ub54c \ub9c8\uc9c0\ub9c9 \ub0a8\uae30\ub294 \ub370\uc774\ud130\nfeature_fraction = 0.6 # feature \ubf51\uc744 \uac2f\uc218\nnum_boost_round = 10000","39f7f76d":"# \ud30c\ub77c\ubbf8\ud130\uc5d0 \ub300\ud55c \uc758\ubbf8\ub97c \uc54c\uace0 \uc788\uc5b4\uc57c \ud55c\ub2e4.\n# \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\uc740 \ub098\uc911\uc5d0.. \uc950\uc5b4\uc9dc\ub0bc\ub54c \ud55c\ub2e4...\nparams = {\"objective\": \"binary\",\n          \"boosting_type\": \"gbdt\", # Gradient Boosting\n          \"learning_rate\": learning_rate,\n          \"num_leaves\": num_leaves,\n          \"max_bin\": 256,\n          \"feature_fraction\": feature_fraction,\n          \"verbosity\": -1, # \ucd9c\ub825 \ubcf4\uc5ec\uc904\uc9c0 \uc5ec\ubd80\n          \"drop_rate\": 0.1, # Drop Out \uac19\uc740\uac70... GBDT\ub294 Drop Rate\uc801\uc6a9\uc548\ub428.\n          \"is_unbalance\": False,\n          \"max_drop\": 50, # GBDT\uc5d0\ub294 \uc0ac\uc6a9 \uc548\ub428.\n          \"min_child_samples\": 10,\n          \"min_child_weight\": 150,\n          \"min_split_gain\": 0,\n          \"subsample\": 0.9\n          }","9a624c43":"x_score = []\nfinal_cv_train = np.zeros(len(train_label)) # Stacking...\nfinal_cv_pred = np.zeros(len(test_id))","439601c8":"final_cv_train","a4db6eef":"for s in np.arange(16): # s: random number\n    break","50437dfe":"s","8f6ccf73":"cv_train = np.zeros(len(train_label))\ncv_pred = np.zeros(len(test_id))","5d774181":"params['seed'] = s # \uc911\uc694\n# \uc559\uc0c1\ube14\uc740 \ub2e4\uc591\uc131\uc774 \uc788\uc5b4\uc11c \uc559\uc0c1\ube14\uc774\ub2e4.\n# \ub2e4\uc591\uc131\uc744 \ud45c\ud604\ud558\ub294 \ubc29\ubc95: \n# \ud53c\uccd0\ub97c \ub2e4\uc591\ud558\uac8c... \n# Random #\ub97c \ubc14\uafd4\ub3c4 \ub2e4\uc591\uc131 \ud655\ubcf4 \uac00\ub2a5..","0d5a2b95":"kf = kfold.split(X, train_label)","d6825043":"best_trees = []\nfold_scores = []","786063b4":"for i, (train_fold, validate) in enumerate(kf):\n    break","adeef2e5":"train_fold","14030a02":"validate","85fad17d":"X_train, X_validate = X[train_fold, :], X[validate, :]\nlabel_train, label_validate = train_label[train_fold], train_label[validate]","7603b84c":"X_train","631ce962":"label_train","ffa2809d":"# XGBoot\uc640 \ub3d9\uc77c\ud558\uac8c DMatrix\ub97c \ub9cc\ub4e4\uace0 \uc9c4\ud589\ud574\uc57c\ud55c\ub2e4.\ndtrain = lgbm.Dataset(X_train, label_train)\ndvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)","40db19eb":"bst = lgbm.train(params, \n           dtrain,\n           num_boost_round, \n           valid_sets=dvalid, \n           feval=evalerror, \n           verbose_eval=100,\n           early_stopping_rounds=100)","d8e34f69":"bst.best_iteration","748867bb":"best_trees.append(bst.best_iteration)","e7297323":"best_trees","42c19114":"cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n# fold\ubcc4\ub85c \ud559\uc2b5\ud558\uace0 \ucb49 \ub354\ud55c\ub2e4.","e574a3dd":"cv_pred","63d687bf":"cv_train[validate] += bst.predict(X_validate)\n# fold\ub97c \ub2e4 \ud6d1\uc73c\uba74 validation fold\ub97c \ub2e4 \ud569\uce58\uba74 \uc804\uccb4 Train Set\uc774 \ub2e4 \ub098\uc628\ub2e4??\n# OF\ub97c \ub9cc\ub4e4\ub54c\ub294 Validate\uc5d0 \ub300\ud574 \uc608\uce21\ud558\uba74 \ub41c\ub2e4??","828319f1":"score = Gini(label_validate, cv_train[validate])","467bcb13":"score","36504534":"fold_scores.append(score)","dfc6dfce":"fold_scores","275504bc":"best_trees = []\nfold_scores = []\n\nfor i, (train_fold, validate) in enumerate(kf):\n    print('#'*30, '{} of {}'.format(i+1, 5))\n    X_train, X_validate, label_train, label_validate = \\\n        X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n    dtrain = lgbm.Dataset(X_train, label_train)\n    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n                    early_stopping_rounds=100)\n    best_trees.append(bst.best_iteration)\n    cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n    cv_train[validate] += bst.predict(X_validate)\n\n    score = Gini(label_validate, cv_train[validate])\n    print(score)\n    fold_scores.append(score)\n\ncv_pred \/= NFOLDS","f7ca893b":"fold_scores","1fa008cd":"final_cv_train += cv_train\nfinal_cv_pred += cv_pred","6eb6b066":"print(\"cv score:\") # Random # \ud558\ub098 \uc120\ud0dd\ud574\uc11c CV Score \uad6c\ud558\uace0\nprint(Gini(train_label, cv_train))","86682a4d":"print(\"current score:\", Gini(train_label, final_cv_train \/ (s + 1.)), s+1) # final_cv_train size \ub9cc\ud07c \ub098\ub214. \/ s+1.\nprint(fold_scores)\nprint(best_trees, np.mean(best_trees))\n\n# Random 16 * KFOLD 5 --> \ucd1d80\ubc88 \ub3cc\ub9bc~","885622c3":"#\uc804\uccb4 \ucf54\ub4dc\nx_score = []\nfinal_cv_train = np.zeros(len(train_label))\nfinal_cv_pred = np.zeros(len(test_id))\n\nfor s in np.arange(16):\n    print('#'*30, 'random number outer iteration: {}'.format(s))\n    cv_train = np.zeros(len(train_label))\n    cv_pred = np.zeros(len(test_id))\n\n    params['seed'] = s\n\n    if cv_only:\n        kf = kfold.split(X, train_label)\n\n        best_trees = []\n        fold_scores = []\n\n        for i, (train_fold, validate) in enumerate(kf):\n            print('#'*10, 'inner cross validation system: {}'.format(i))\n            X_train, X_validate, label_train, label_validate = \\\n                X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n            dtrain = lgbm.Dataset(X_train, label_train)\n            dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n            bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n                            early_stopping_rounds=100)\n            best_trees.append(bst.best_iteration)\n            cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n            cv_train[validate] += bst.predict(X_validate)\n\n            score = Gini(label_validate, cv_train[validate])\n            print(score)\n            fold_scores.append(score)\n\n        cv_pred \/= NFOLDS\n        final_cv_train += cv_train\n        final_cv_pred += cv_pred\n\n        print(\"cv score:\")\n        print(Gini(train_label, cv_train))\n        print(\"current score:\", Gini(train_label, final_cv_train \/ (s + 1.)), s+1)\n        print(fold_scores)\n        print(best_trees, np.mean(best_trees))\n\n        x_score.append(Gini(train_label, cv_train))\n\nprint(x_score)","ce89113c":"pd.DataFrame({'id': test_id, 'target': final_cv_pred \/ 16.}).to_csv('.\/lgbm3_pred_avg.csv', index=False)\npd.DataFrame({'id': train_id, 'target': final_cv_train \/ 16.}).to_csv('.\/lgbm3_cv_avg.csv', index=False)","1895503c":"# Model development","0813d6b0":"\ucd9c\ucc98 - https:\/\/www.kaggle.com\/xiaozhouwang\/2nd-place-lightgbm-solution","e9497589":"# Feature engineering","08a005da":"CV, LB\ub97c \ubb3c\uc5b4\ubcf4\ub294 \uc774\uc720\nCV\ub791 LB\uac00 \uc120\ud615\uc801\uc73c\ub85c \ub530\ub77c\uac00\ub294 \uac8c \uc88b\uc740\ub370..\n1. \uc774 Competition\uc774 Shake up\uc774 \uc0dd\uae38\uac74\uc9c0 \uac04\uc744 \ubcf8\ub2e4. CV, LB\ucc28\uc774\uac00 \ud06c\uace0 Unstable\ud558\uba74 Shake up\uc77c \ubc1c\uc0dd\ud560 \uc5ec\uc9c0\uac00 \uc788\ub2e4\n2. \uace0\uc218\ub4e4\uc758 CV, LB\uac12\uc744 \ubcf4\uace0 \ubcf8\uc778 PC\uc5d0\uc11c \uadf8 \uc815\ub3c4 \uc810\uc218\ub97c \uc62c\ub9b0\ub2e4.\n"}}