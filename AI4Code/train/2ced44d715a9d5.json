{"cell_type":{"8bd05b03":"code","ccce9715":"code","3627d3b4":"code","8b81a4d6":"code","1306170c":"code","651d981c":"code","477b84c6":"code","d8473dae":"code","c5ddeebc":"code","6cb31644":"code","5593d22e":"code","f34c409f":"code","fee1ec4c":"code","9dee29de":"code","052e2b5b":"code","8c492dd3":"code","3b466cb0":"code","6576279f":"code","8e6cee8b":"code","24de9c19":"code","3c2e4d48":"code","73eff04f":"code","d1478866":"code","73e9e204":"code","e3d698b5":"code","a9a2db1f":"code","bc964c3d":"code","a89c8d51":"code","dcc91ea6":"code","f1fb0d14":"code","e666304d":"code","60c29d39":"code","77beebc6":"code","710d8bac":"code","7308867e":"code","0636c189":"code","e9a982fc":"code","e5bae4ef":"code","a29b0fae":"code","cad01994":"code","79c1a678":"code","7c81a0a3":"code","4da57569":"code","5574b709":"code","c26e8b29":"code","62c19b11":"code","57628072":"code","376ea343":"code","1f125544":"code","a509ae19":"code","9affa175":"code","8df83052":"code","10a6eda5":"code","8d6d0197":"code","64880c59":"code","89b18e73":"code","bbf337d0":"code","a9e2b1fa":"code","21edb2a7":"code","97656ed0":"code","43158d52":"markdown","87162323":"markdown","19f2eda0":"markdown","ead83785":"markdown","7817fa6b":"markdown","325c4c4b":"markdown","f2c0834d":"markdown","9a83d2a8":"markdown","22751791":"markdown","5420ad66":"markdown","b90b38e6":"markdown","0a1744c6":"markdown","8d08ddbf":"markdown","9c409119":"markdown","6ed37429":"markdown","0c46e707":"markdown","1d02def5":"markdown","ea7abd67":"markdown","aaa38c4a":"markdown","075e2a62":"markdown","6fcc266a":"markdown","94f53757":"markdown","2a22bc3b":"markdown","d8891a1b":"markdown","d205b435":"markdown","8da64b51":"markdown","dd3ce00b":"markdown","6759b5ca":"markdown","3fa0dae8":"markdown","5e27943f":"markdown"},"source":{"8bd05b03":"## importing libraries:\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ccce9715":"## importing data from my github where I have uploaded this same dataset:\n\n## importing data with name \"diabetes.csv\"\nfrom urllib.request import urlretrieve\nurlretrieve(\"https:\/\/raw.githubusercontent.com\/yadavdeven\/Regression_and_Classification_projects\/main\/datasets_for_projects\/diabetes.csv\",\"diabetes.csv\")\n\n## importing data\ndf = pd.read_csv(\"diabetes.csv\")","3627d3b4":"df.head()","8b81a4d6":"df.shape,df.columns","1306170c":"df.info()","651d981c":"df.Outcome.value_counts()","477b84c6":"df.isnull().sum()","d8473dae":"## Creating a dataframe which shows how many zero values are present in each column:\n\ncolumn_name = []\nzero_value_counts = []\n\nfor column in df.columns:\n    num_zero_values = len(df[df[column] == 0])\n    column_name.append(column)\n    zero_value_counts.append(num_zero_values)\n    df_zero_values = pd.DataFrame(list(zip(column_name,zero_value_counts)),columns = [\"column\",\"num of zero values\"])","c5ddeebc":"df_zero_values","6cb31644":"## looking at df_zero_values, let's fill columns with small numbers of missing values. \n\n## filling missing values for Glucose column:\n\ndf[\"Glucose\"].mean(),df.Glucose.median()          ## mean = 121 and median = 117\ndf.Glucose = df.Glucose.replace(to_replace=0,value=120)   ## putting 120 for all 0 values","5593d22e":"## filling missing values for BloodPressure column:\n\ndf.BloodPressure.mean(),df.BloodPressure.median()    ## mean = 69 and median = 72\ndf.BloodPressure = df.BloodPressure.replace(to_replace=0,value=72)","f34c409f":"## filling missing values for BMI:\n\ndf[\"BMI\"].mean(),df[\"BMI\"].median()           ## both mean and median = 32\ndf[\"BMI\"] = df[\"BMI\"].replace(to_replace=0,value=32)","fee1ec4c":"## Plotting Correlation matrix with Non-null Values:\n\ndf_non_null = df[(df[\"Insulin\"] != 0) & (df[\"SkinThickness\"] != 0)]     ## filtering rows with 0 values \n\n## plotting correlation matrix:\n\ncorr_matrix_non_null = df_non_null.corr()\nplt.figure(figsize=(16,7),dpi=130)\nsns.heatmap(corr_matrix_non_null,\n           annot=True, annot_kws={'size': 15},\n           linewidths = 0.5,\n           fmt=\".2f\", cmap = \"Blues\")\nplt.xticks(rotation = 45);","9dee29de":"## removing warnings:\nimport warnings\nwarnings.filterwarnings('ignore')","052e2b5b":"sns.scatterplot(data=df_non_null, x = \"SkinThickness\", y = \"BMI\");","8c492dd3":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()","3b466cb0":"## filling missing values for SkinThickness based on BMI values:\n\n## defining x and y and converting them in numpy arrays:\nx = np.array(df_non_null[\"BMI\"])\ny = np.array(df_non_null[\"SkinThickness\"])\n\n## such reshaping is compulsory before fitting when we have only 1 feature:\nx = x.reshape(-1,1)\ny = y.reshape(-1,1)\n\nlr = LinearRegression()\nlr.fit(x,y)","6576279f":"## This will fill all missing(0 values) for SkinThickness. \n## uncomment print statement to see outputs:\n\nfor index,bmi_value in enumerate(df[\"BMI\"]):\n    if df[\"SkinThickness\"][index] == 0:\n        bmi_value = np.array(bmi_value)\n        bmi_value = bmi_value.reshape(-1,1)\n        st_pred = lr.predict(bmi_value)\n        st_pred = st_pred.reshape(-1)\n        st_pred = st_pred.item()\n        ##print(bmi_value,st_pred,type(st_pred),df[\"SkinThickness\"][index])\n        \n        df.at[index,\"SkinThickness\"] = st_pred    ","8e6cee8b":"sns.scatterplot(df_non_null.Insulin,df_non_null.Glucose);","24de9c19":"## Repeating same thing for Glucose and Insulin:\n\ndf_insulin = df_non_null[df_non_null[\"Insulin\"] < 400]  ## filtered high values of Insulin to get better fit line\n\nX = np.array(df_insulin.Glucose)\nY = np.array(df_insulin.Insulin)\n\nX = X.reshape(-1,1)\nY = Y.reshape(-1,1)\n\nlr.fit(X,Y)","3c2e4d48":"for index,glucose_value in enumerate(df[\"Glucose\"]):\n    if df[\"Insulin\"][index] == 0:\n        glucose_value = np.array(glucose_value)\n        glucose_value = glucose_value.reshape(-1,1)\n        Insu_pred = lr.predict(glucose_value)\n        Insu_pred = Insu_pred.reshape(-1)\n        Insu_pred = Insu_pred.item()\n        ##print(bmi_value,st_pred,type(st_pred),df[\"SkinThickness\"][index])\n        \n        df.at[index,\"Insulin\"] = st_pred    ","73eff04f":"## Checking for 0 values:\n\ncolumn_name = []\nzero_value_counts = []\n\nfor column in df.columns:\n    num_zero_values = len(df[df[column] == 0])\n    column_name.append(column)\n    zero_value_counts.append(num_zero_values)\n    df_zero_values_2 = pd.DataFrame(list(zip(column_name,zero_value_counts)),columns = [\"column\",\"num of zero values\"])","d1478866":"## All fine:\n\ndf_zero_values_2","73e9e204":"## Correlation matrix for entire data with filled values:\n\ncorr_matrix = df.corr()\nplt.figure(figsize=(16,7),dpi=130)\nsns.heatmap(corr_matrix,\n           annot=True, annot_kws={'size': 15},\n           linewidths = 0.5,\n           fmt=\".2f\", cmap = \"Blues\")\nplt.xticks(rotation = 45);","e3d698b5":"## removing warnings:\nimport warnings\nwarnings.filterwarnings('ignore')","a9a2db1f":"## Visualizing effects of Glucose concentration on Outcome:\n\nfig, axes = plt.subplots(1,2,figsize = (16,6), gridspec_kw={\n                           'width_ratios': [5, 3],'wspace': 0.15},dpi = 120)\n\n## code for distplot: \n\nsns.distplot(df['Glucose'][df.Outcome == 1],ax = axes[0],color = \"red\")\nsns.distplot(df['Glucose'][df.Outcome == 0],ax = axes[0],color = \"#aae9f0\")\naxes[0].legend([\"Diabetes\",\"No Diabetes\"])\n\n## code for boxplot:\n\nsns.boxplot(x = \"Outcome\", y = \"Glucose\",data = df,ax = axes[1])\naxes[1].legend([\"0: No Diabetes\",\"1: Diabetes\"])\n\n## I have used hexadecimal color values from color picker by googling it \n       ## You can access each figure within a plot by using artist[number]\n\n\nmybox1 = axes[1].artists[0]      ## (selected 1st figure from plot 2 that is boxplot)\nmybox1.set_facecolor('#aae9f0')\n\nmybox2 = axes[1].artists[1]     ## (selected 2nd figure from plot 2 that is boxplot)\nmybox2.set_facecolor('red')\n##plt.tight_layout(pad = 2)\nplt.suptitle(\"Impact of Plasma Glucose Level on Outcome\",fontsize = 22);","bc964c3d":"## importing this library for drawing figures on a plot:\n\nimport matplotlib.patches as mpatches","a89c8d51":"## Plotting effects of Glucose and insulin on Outcome:\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14,8))\nax = sns.scatterplot(data=df, x = \"Glucose\", y = \"Insulin\", hue = \"Outcome\",palette = \"Set2\")\n\n## Setting custom labels:\nhandles, labels  =  ax.get_legend_handles_labels()\nax.legend(handles, ['No Diabetes', 'Diabetes'], loc='upper right')\n\nplt.title(\"Impact of Glucose level and Insulin on Diabetes\",{\"fontsize\":20},pad = 20)\n\n## plotting a rectangle to highlight an area of interest:\nrect=mpatches.Rectangle((150,-50),50,450, \n                        fill=False,\n                        color=\"purple\",\n                       linewidth=2)\n                       #facecolor=\"red\")\nplt.gca().add_patch(rect);","dcc91ea6":"## plotting impact of pregnancies on Outcome:\n\nplt.figure(figsize=(12,6))\nsns.set_style(\"white\")\nplt.title(\"Imapct of Pregnacy on Outcome\",fontsize = 16,pad = 20)\nsns.distplot(df['Pregnancies'][df.Outcome == 1], color =\"red\")\nsns.distplot(df['Pregnancies'][df.Outcome == 0], color =\"#aae9f0\")\nplt.legend(['Diabetes', 'No Diabetes']);","f1fb0d14":"## Visualizing effects of Glucose concentration on Outcome:\n\nfig, axes = plt.subplots(1,2,figsize = (14,5),dpi = 120)\n\n## code for 1st plot:\n\naxes[0].set_title(\"Effect of BMI on Outcome\",fontsize = 14,pad = 15)\nsns.boxplot(x = \"Outcome\", y = \"BMI\",data = df,ax = axes[0])\naxes[0].legend([\"0: No Diabetes\",\"Diabetes\"])\n\n## code for 2nd plot:\n\naxes[1].set_title(\"Effect of AGE on Outcome\",fontsize = 14,pad = 15)\nsns.boxplot(x = \"Outcome\", y = \"Age\",data = df,ax = axes[1])\naxes[1].legend([\"0: No Diabetes\",\"1: Diabetes\"])\n\n\nmybox0_0 = axes[0].artists[0]       ## selecting 1st figure from 1st plot and setting color as before\nmybox0_0.set_facecolor('#c7fcd7')   ## and so on ...\n\nmybox0_1 = axes[0].artists[1]  \nmybox0_1.set_facecolor('red')\n##plt.tight_layout(pad = 2)\n\nmybox1_0 = axes[1].artists[0]\nmybox1_0.set_facecolor('#aae9f0')\n\nmybox1_1 = axes[1].artists[1]\nmybox1_1.set_facecolor('red')\n##plt.tight_layout(pad = 2);","e666304d":"## imports for above processes:\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","60c29d39":"## splitting features and target:\nx = df.drop(\"Outcome\",axis = 1)\ny = df.Outcome","77beebc6":"## splitting train and test data:\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\nx_train.shape,x_test.shape,y_train.shape,y_test.shape","710d8bac":"## performing feature scaling:\n\nscaler = StandardScaler()\n\nscaled_x_train = scaler.fit_transform(x_train)\nscaled_x_test = scaler.transform(x_test)","7308867e":"## importing models:\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","0636c189":"## putting models in a dictionary:\n\nmodels = {\"log_regression\": LogisticRegression(),\n          \"random_forest\": RandomForestClassifier(),\n          \"svc\": SVC(kernel = \"rbf\")}\n\n## creating function for fitting and scoring:\n\ndef fit_score(model,x_train,x_test,y_train,y_test):\n    \n    np.random.seed(0)             ## for reproducibility\n    model_scores = {}\n    \n    for model_name, model in models.items():   ## ll take name and model from models dictionary 1 by1\n        \n        model.fit(x_train,y_train)    ## fit model 1 by 1 on training data\n        model_scores[model_name] = model.score(x_test,y_test) ## append score in model_score dictionary\n        \n    return model_scores","e9a982fc":"## importing score metrics before fitting:\n\nfrom sklearn.metrics import confusion_matrix,classification_report,plot_roc_curve,plot_confusion_matrix\nfrom sklearn.metrics import precision_score,recall_score,f1_score","e5bae4ef":"## fitting our base model:\n\nmodel_scores = fit_score(model = models,\n                         x_train = scaled_x_train, x_test = scaled_x_test,\n                         y_train = y_train, y_test = y_test)","a29b0fae":"## let's see the results:\n\nmodel_scores","cad01994":"df_model_scores = pd.DataFrame(model_scores,index = [\"Accuracy\"])\nplt.figure(figsize = (8,6))\nsns.barplot(x = df_model_scores.columns, y = df_model_scores.loc[\"Accuracy\"])\nplt.title(\"Model Scores Comparison\",fontsize=20,pad = 25)\nplt.xticks(fontsize = 16),plt.yticks(fontsize = 16),plt.ylabel(\"Accuracy\",fontsize=16)\n\n## code for plotting percentages on top of every bar\n\nfor index,data in enumerate(df_model_scores.loc[\"Accuracy\"]):\n  plt.text(x=index - 0.25,y=data+0.01,s=f\"{data*100:.2f}%\",fontsize = 14);","79c1a678":"## classification report:\n\ndef get_classification_report(model,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test):\n    np.random.seed(0)\n    model.fit(x_train,y_train)\n    y_pred = model.predict(x_test)\n    print(classification_report(y_test,y_pred))","7c81a0a3":"for model_name, model in models.items():\n    print(f'Classification Report for {model_name}')\n    get_classification_report(model=model)","4da57569":"def get_roc_curve(model,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test):\n    np.random.seed(0)\n    model.fit(x_train,y_train)\n    y_pred = model.predict(x_test)\n    plot_roc_curve(model,x_test,y_test)","5574b709":"for model_name, model in models.items():\n    get_roc_curve(model)\n    plt.title(f'ROC_curve for {model_name}');","c26e8b29":"def get_confusion_matrix(model,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test):\n    np.random.seed(0)\n    model.fit(x_train,y_train)\n    y_pred = model.predict(x_test)\n    print(confusion_matrix(y_test,y_pred))\n    return confusion_matrix","62c19b11":"for model_name, model in models.items():\n    print(f\"Confusion Matrix for {model_name}:\")\n    get_confusion_matrix(model);","57628072":"## Heatmap for Logistic Regression Model:\n\nlr = LogisticRegression()\nlr.fit(scaled_x_train,y_train)\ny_pred = lr.predict(scaled_x_test)\ncf_matrix = confusion_matrix(y_pred,y_test)\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap=\"Greens\",annot_kws={'size':16})\nplt.xlabel(\"Predicted Label\",fontsize = 18)\nplt.ylabel(\"True Label\",fontsize = 18);","376ea343":"## Heatmap for Random Forest Classifier Model:\n\nrf = RandomForestClassifier()\nrf.fit(scaled_x_train,y_train)\ny_pred = rf.predict(scaled_x_test)\ncf_matrix = confusion_matrix(y_pred,y_test)\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='YlGnBu',annot_kws={'size':16})\nplt.xlabel(\"Predicted Label\",fontsize = 18)\nplt.ylabel(\"True Label\",fontsize = 18);","1f125544":"## Heatmap for SVC Model:\n\nsvc = SVC(kernel = \"rbf\")\nsvc.fit(scaled_x_train,y_train)\ny_pred = svc.predict(scaled_x_test)\ncf_matrix = confusion_matrix(y_pred,y_test)\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='BuPu',annot_kws={'size':16})\nplt.xlabel(\"Predicted Label\",fontsize = 18)\nplt.ylabel(\"True Label\",fontsize = 18);","a509ae19":"from sklearn.model_selection import GridSearchCV","9affa175":"## param grid for tuning logistic regression model: \n\nparam_grid = [    \n    {'penalty' : ['l1', 'l2', 'elasticnet'],\n    'C' : np.logspace(0,10, 20),'l1_ratio': np.linspace(0,1,20),\n    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n    'max_iter' : [5000]\n    }\n]","8df83052":"## injecting paramgrid into the model: \n\nclassifier = GridSearchCV(LogisticRegression(),param_grid=param_grid,verbose=True,n_jobs=-1,cv=3)","10a6eda5":"tuned_log_regression = classifier.fit(scaled_x_train,y_train)","8d6d0197":"## our BEST params:\ntuned_log_regression.best_estimator_","64880c59":"from sklearn.metrics import accuracy_score","89b18e73":"y_pred = tuned_log_regression.predict(scaled_x_test)\nscore = accuracy_score(y_pred,y_test)\nscore","bbf337d0":"## rbf kernel is best suited for this type of data also c = 0.1 works best in most cases\n## Hence, tuning for gamma values\n\ngammas = [0.1, 1, 10, 100]\nsvc_scores = []\nfor gamma in gammas:\n   svc = SVC(kernel=\"rbf\", gamma=gamma,C=0.1).fit(scaled_x_train, y_train)\n   svc_scores.append(svc.score(scaled_x_test,y_test))\n   ","a9e2b1fa":"max(svc_scores)","21edb2a7":"## PART 2: Predicting using Deep Learning\n\n## will be updating soon ....","97656ed0":"## PART 3: Model Deployment using Streamlit\n\n## will be updating soon....","43158d52":"### Both the figures gives a clear picture that people having high level of Plasma Glucose Concentration are very likely to have a Diabetes.","87162323":"### Confusion Matrix:","19f2eda0":"### <span style = \"color: purple;\">Approache to be used for Filling Remaing Missing values:<\/span> \n* #### we will fit a regression line between BMI and SkinThickness.\n* #### we will than fill missing values of SkinThickness based on BMI values.\n* #### Because median and mean approach doesn't make good sense with so many values missing.","ead83785":"### So, we got an improvement of (79.87 - 77.27) = <span style = \"color:green;\">2.6 %<\/span>","7817fa6b":"#### Though the above value_counts shows that the there isn't any missing values but that is not the case.\n#### There many missing values in this small dataset, let's see HOW ???","325c4c4b":"   ## <span style = \"color:#9176e8;\">Part 1.6: Model Tuning:<\/span>","f2c0834d":"   ## <span style = \"color:#9176e8;\">Part 1.2: Filling Missing values (0 values for this dataset)<\/span>","9a83d2a8":"#### We won't be filling Pregnancies values because that can be zero and info of sex is not given.\n#### So, we are left with complex columns of Insulin and SkinThickness which have huge missing values. ","22751791":"   ## <span style = \"color:#9176e8;\">BEAUTIFUL, Our Models are producing great results with l_r being the Best:<\/span>\n* ### Seeing ml models train and produce results in one of the Best feelings.\n* ### let's visualize this results for more awesomeness.","5420ad66":"   ### Creating a function for Model fit and score:","b90b38e6":"   ## <span style = \"color:#9176e8;\">Part 1.3: IN DEPTH Data Visualisation with conclusions<\/span>","0a1744c6":"### ROC curve:","8d08ddbf":"### Classification Report:","9c409119":"## <span style = \"color:red;\">Objective:<\/span>\n###      * To predict a person as Diabetic or NOT based on given feature set. \n           ","6ed37429":"* ## <span style=\"color: #9176e8;\">Please upvote, if you found this helpful<\/span>\n* ## <span style=\"color: #9176e8;\">For any doubts do comment will try my best to solve it<\/span>\n## <span style=\"color: #9176e8;\">THANKS...<\/span>","0c46e707":"* #### Values such as BloodPressure, BMI etc can never be zero.\n* #### This suggest us that missing values are being represented by zero in this dataset.","1d02def5":"   ### <span style = \"color:#9176e8;\">Though the above value_counts shows that the there isn't any missing values but that is not the case.<\/span>\n   ### <span style = \"color:#9176e8;\">There many missing values in this small dataset, let's see HOW ???<\/span>","ea7abd67":"### Tuning Logistic model produced no improvement, let's do it for SVC...","aaa38c4a":"### Confusion Matrix is rather confusing us.\n### So, Let's Plot this results using Heatmap and add Percentage to it for Better Understanding.","075e2a62":"## <span style=\"color: red;\">Part 1: Using Scikit-Learn<\/span>","6fcc266a":"### <span style = \"color: purple;\">Inference from above correlation:<\/span> \n#### * There is a strong correlation between SkinThickness and BMI (0.66).\n#### * There is a strong relation between Glucose and Insulin as well (0.58)\n#### * The outcome is very much dependent on Glucose.\n#### * Our further Filling  will be based on this inference.","94f53757":"![image.png](attachment:977f110f-4235-442b-8598-d37fb08ec083.png)","2a22bc3b":"   ### <span style = \"color:#9176e8;\">Part 1.1: Importing data and doing basic evaluation<\/span>","d8891a1b":"   ## <span style = \"color:#9176e8;\">Part 1.5: Model Evaluation:<\/span>","d205b435":"### <span style = \"color: purple;\">Inference from above correlation:<\/span> \n#### * There is a strong correlation between Outcome and BMI which suggest obesity as some role to play.\n#### * There is also good correlation between Outcome and Pregnancies.\n#### * The outcome is very much dependent on Glucose since it show very high correlation.\n#### * If we focus inside of the matrix than Glucose and insulin shows strong relation as well.\n#### * Our further plotting will be based on this inference.","8da64b51":"## <span style = \"color:red;\">Highlights of the project:<\/span>\n### * we will implement the project using multiple algorithms present in scikit-learn library.\n### <span style = \"color:blue;\">* we will fill missing data using various approach, do check them out.<\/span>\n### * we will be using Deep Learning later.\n### * we will perform tuning operation, so as to try and improve our score.\n### * we will perform basic model evaluation since the data is itself not that big and complicated.\n### * I ll also implement this project using streamlit app and the link for the same ll be given.\n### * Everything ll be in parts.","dd3ce00b":"   ## <span style = \"color:#9176e8;\">Part 1.3: Feature Scaling and Splitting of Data:<\/span>","6759b5ca":"## <span style = \"color:red;\">Info about the dataset:<\/span>\n#### **Pregnancies:** Number of times pregnant\n#### **Glucose:** Plasma Glucose Concentration (mg\/dl)\n#### **Blood Pressure:** Diastolic Blood Pressure(mmHg)\n#### **Skin Thickness:** A value used to estimate body fat.\n#### **Insulin:** 2-Hour Serum Insulin (mu U\/ml)\n#### **BMI:** Body Mass Index (weight in kg\/ height in m2)\n#### **Diabetes Pedigree Function:** It provides information about diabetes history in relatives and    genetics. \n#### **Age:** Age (years)\n#### **Outcome:** 0 = Diabetic, 1 = Not Diabetic.","3fa0dae8":"### This Scatter plot shows the impact of insulin along with plasma glucose concentration.\n### The Rectangle box shows that people with high glucose plasma level and low insulin are almost certain to be Diabetic.","5e27943f":"   ## <span style = \"color:#9176e8;\">Part 1.4: Model Building:<\/span>"}}