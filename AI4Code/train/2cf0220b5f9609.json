{"cell_type":{"c1d46bcc":"code","0900676b":"code","80cc476e":"code","24fc4303":"code","beb811b9":"code","7c955eff":"code","f6b9f4a8":"code","799e9122":"code","e346baa4":"code","f71e5054":"code","43cdde90":"code","fd6569d0":"code","d8345565":"code","01d33e1d":"code","49d08881":"code","af91e62b":"code","3f1c0447":"code","cfb81de6":"code","93098ee1":"code","23faa890":"code","95a40bdb":"code","87d8a397":"code","7fe2eae5":"markdown","11519d90":"markdown","68dc8bb7":"markdown","8b0c4634":"markdown","1ffb434f":"markdown","612b7210":"markdown","75e69365":"markdown","5859b334":"markdown","b1a535f1":"markdown","f2d1c620":"markdown","a0bf183d":"markdown"},"source":{"c1d46bcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0900676b":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","80cc476e":"# csv url of cell samples\ncsv = '\/kaggle\/input\/cell_samples.csv'\n# create dataframe using pandas\nData = pd.read_csv(csv)\nData.head()","24fc4303":"# view data types, rows, columns etc\nData.info()","beb811b9":"Data['BareNuc'].value_counts().sort_values()","7c955eff":"# a question mark is evdident in the feature, first replace it with 'np.nan' then replace it with the mean of the feature\nData['BareNuc'].replace('?', np.nan, inplace = True)\n\n# mean of 'BareNuc'\navg_bare = Data['BareNuc'].astype('float').mean()\n# replacing np.nan values the mean\nData['BareNuc'].replace(np.nan, avg_bare, inplace = True)\n\n# convert 'BareNuc' to an 'int' type\nData['BareNuc'] = Data['BareNuc'].astype('int')\nData['BareNuc'].dtype","f6b9f4a8":"Data['Class'].value_counts().plot(kind='bar')\nplt.xlabel('Class of tumor')\nplt.ylabel('Counts')\nplt.title('Benign(2) vs Malignant(4)')\nplt.show()","799e9122":"# visualize distribution of the classes (malignant and benign) based on Clump thickness and Uniformity\nmalignant = Data['Class'] == 4\nbenign = Data['Class'] == 2\n\nax1 = Data[malignant][0:50].plot(kind='scatter',\n                                  x='Clump', y='UnifSize', \n                                  color='r', label='Malignant');\nData[benign][0:50].plot(kind='scatter', \n                         x='Clump', y='UnifSize', \n                         color='blue', label='Benign', ax=ax1);\nplt.show()","e346baa4":"sns.pairplot(Data, hue='Class')","f71e5054":"# distrubution plots to test whether features should be scaled\nax1 = sns.distplot(Data['Clump'], hist=False, label='clump')\nsns.distplot(Data['UnifSize'], hist=False, label='unifsize',ax=ax1)\nsns.distplot(Data['BlandChrom'], hist=False, label='BlandChrom', ax=ax1)","43cdde90":"# features\nX = Data.drop(columns=['Class', 'ID']).values\nprint(X[:5])\n\n# target\nY = Data['Class'].values\nprint(Y[:5])","fd6569d0":"# create training and testing sets\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","d8345565":"from sklearn.preprocessing import StandardScaler\n\n# scale object\nscale = StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.transform(x_test)\n\nprint(x_train[:1])\nprint(x_test[:1])","01d33e1d":"# import libraries to analyze svm\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n\n# kernels to be used in the svm model\nmodels = ['linear', 'poly', 'rbf', 'sigmoid']\n# scoring of the models\nacc_score = []\nprecision = []\nrecall = []\nf1 = []\njacc = []\n\nfor m in models:\n    \n    # svm object fitted with training sets\n    mach = svm.SVC(C=0.5, kernel=m)\n    mach.fit(x_train, y_train)\n    yhat = mach.predict(x_test)\n    \n    acc_score.append(accuracy_score(y_test, yhat))\n    precision.append(precision_score(y_test, yhat, average='weighted'))\n    recall.append(recall_score(y_test, yhat, average='weighted'))\n    f1.append(f1_score(y_test, yhat, average='weighted'))\n    jacc.append(jaccard_score(y_test, yhat, average='weighted'))\n","49d08881":"# position of the best score in the array\nbest_acc = np.array(acc_score).argmax()  # best accuracy score\nbest_prec = np.array(precision).argmax()  # best precision score\nbest_rec = np.array(recall).argmax()   # best recall score\nbest_f1 = np.array(f1).argmax()   # best f1 score\nbest_jacc = np.array(jacc).argmax()  # best jaccard score","af91e62b":"print('Models with the best metrics:\\n')\nprint('Best Accuracy: ', models[best_acc])\nprint('Best Precision: ', models[best_prec])\nprint('Best Recall: ', models[best_rec])\nprint('Best F1: ', models[best_f1])\nprint('Best Jaccard Score: ', models[best_jacc])","3f1c0447":"# svm object fitted with training data\nlr = svm.SVC(C=0.5, kernel='linear', probability=True)\nlr.fit(x_train, y_train)\n\n# estimates\nyhat = lr.predict(x_test)","cfb81de6":"# import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# confusion matrix\nmatrix = confusion_matrix(y_test, yhat)\nsns.heatmap(pd.DataFrame(matrix), annot=True, cmap='YlGnBu', fmt='.2g')\nplt.xticks((0.5,1.5), ['benign(2)', 'malignant(4)'], rotation=45)\nplt.yticks((0.5,1.5), ['benign(2)', 'malignant(4)'], rotation=45)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","93098ee1":"# true positives and negative. False positive and negatives\nTN = matrix[0][0]\nFN = matrix[1][0]\nTP = matrix[1][1]\nFP = matrix[0][1]\n\nsens = TP \/ (TP + FN)\nprec = TP\/ (TP + FP)\nf1 = 2 * ((sens * prec) \/ (sens + prec))\nprint('Sensitivity (Recall): ', sens)\nprint('Positive Prediction Value (Precision): ', prec)\nprint('F1 score: ', f1)\nprint('Specificity: ', TN \/ (TN+FP))\nprint('Negative Prediction Value: ', TN\/ (TN+FN))","23faa890":"# metrics\nacc = accuracy_score(y_test, yhat)\nprec = precision_score(y_test, yhat, average='weighted')\nrec = recall_score(y_test, yhat, average='weighted')\njacc = jaccard_score(y_test, yhat, average='weighted')\n\nprint(acc, prec, rec, f1, jacc)","95a40bdb":"# classification report\nreport = classification_report(y_test, yhat)\nprint(report)","87d8a397":"print(\n    'The model has a Jaccard Index of 95.802% which is ', \n    'exceptionally high and gives us an indication that the ', \n    'testing set and estimate set are extremely similar.\\n')\nprint(\n    'The model also has an accuracy of 97.857% which is exceptional!\\n')\nprint(\n    'The model has an f1 score of 97.08% which shows the weighted average ', \n    'of precision and recall scores. It takes into account false positive and ',\n    'false negatives into account and is a better metric to use when there is ', \n    'an unneven class distribution')\nprint(\n    'The model has a an exceptional precision of 98.03% which shows ', \n    'the ratio of correctly predicted positive observations to the ', \n    'total predicted positive observations.\\n')\nprint(\n    'The model has a recall score of 96.15% which shows the ratio ', \n    'of correctly predicted positive observations to the all ', \n    'observations in actual class - benign(2).\\n')","7fe2eae5":"*Feature 'BareNuc' contains some values that are not numeric and must be converted to an int*","11519d90":"*Training and Testing Sets*","68dc8bb7":"## From the above analysis, the linear kernel performance best for this dataset!  \n\n### Build model again and performance evaluations","8b0c4634":"*Build SVM object*","1ffb434f":"### Analyze each models performance","612b7210":"### Building the model  \n\n1) Create features and target variables  \n2) Create testing and training sets  \n3) Use StandardScaler to fit training set of features, then transform testing set of features  \n4) Create SVM object and compare results of 'polynomial', 'rbf', 'linear', 'sigmoid'  ","75e69365":"# Final Observations","5859b334":"*Create Features and Target variables*","b1a535f1":"## Data Preprocessing","f2d1c620":"## Data Exploration","a0bf183d":"*Use StandardScaler for features*"}}