{"cell_type":{"799f9379":"code","6ffea010":"code","c832349f":"code","7bef2fc2":"code","d6d7824c":"code","487db846":"code","49ab465d":"code","ce253db6":"code","23d1935d":"code","8d147d10":"code","fe3fcef1":"code","ef9a365b":"markdown","8ac32c4d":"markdown","1dbf54d5":"markdown","8b944e7b":"markdown","1ea49743":"markdown","735ade3e":"markdown","bbc855d0":"markdown","d06e7cdb":"markdown","ae59f721":"markdown","5f140ae8":"markdown"},"source":{"799f9379":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets","6ffea010":"if torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\nprint('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n# DEVICE = torch.device('cpu')","c832349f":"BATCH_SIZE = 32\nEPOCHS = 10","7bef2fc2":"train_dataset = datasets.hymenoptera_data(\n    root='..\/input\/hymenoptera-data\/hymenoptera_data', train=True, download=True, transform=transforms.ToTensor())\n\ntest_dataset = datasets.hymenoptera_data(\n    root='..\/input\/hymenoptera-data\/hymenoptera_data', train=False, transform=transforms.ToTensor())\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,batch_size=BATCH_SIZE,shuffle=False)\n\n\n\n\n\n# data_transforms = {\n#     'train': transforms.Compose([\n#         transforms.RandomResizedCrop(224),\n#         transforms.RandomHorizontalFlip(),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n#     ]),\n#     'val': transforms.Compose([\n#         transforms.CenterCrop(224),\n#         transforms.Resize(256),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n#     ]),\n# }\n\n# image_datasets = {x: datasets.ImageFolder(\"..\/data\/hymenoptera_data\", data_transforms[x]) for x in ['train', 'val']}\n# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size = BATCH_SIZE, num_workers = 0, shuffle = True) for x in ['train', 'val']}","d6d7824c":"for (X_train, y_train) in dataloaders['train']:\n    print('X_train:', X_train.size(), 'type:', X_train.type())\n    print('y_train:', y_train.size(), 'type:', y_train.type())\n    break","487db846":"pltsize = 1\nplt.figure(figsize=(10 * pltsize, pltsize))\n\nfor i in range(10):\n    plt.subplot(1, 10, i + 1)\n    plt.axis('off')\n    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n    plt.title('Class: ' + str(y_train[i].item()))","49ab465d":"import torchvision.models as models\nmodel=models.resnet18(pretrained=False)\nnum_ftrs=model.fc.in_features\nmodel.fc=nn.Linear(num_ftrs,2)\nmodel=model.to(DEVICE)\n","ce253db6":"#model = ResNet().to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\ncriterion = nn.CrossEntropyLoss()\n\nprint(model)","23d1935d":"def train(model, train_loader, optimizer, log_interval):\n    model.train()\n    for batch_idx, (image, label) in enumerate(train_loader):\n        image = image.to(DEVICE)\n        label = label.to(DEVICE)\n        optimizer.zero_grad()\n        output = model(image)\n        loss = criterion(output, label)\n        loss.backward()\n        optimizer.step()\n\n        if batch_idx % log_interval == 0:\n            print(\"Train Epoch: {} [{}\/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n                epoch, batch_idx * len(image), \n                len(train_loader.dataset), 100. * batch_idx \/ len(train_loader), \n                loss.item()))","8d147d10":"def evaluate(model, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for image, label in test_loader:\n            image = image.to(DEVICE)\n            label = label.to(DEVICE)\n            output = model(image)\n            test_loss += criterion(output, label).item()\n            prediction = output.max(1, keepdim = True)[1]\n            correct += prediction.eq(label.view_as(prediction)).sum().item()\n    \n    test_loss \/= (len(test_loader.dataset) \/ BATCH_SIZE)\n    test_accuracy = 100. * correct \/ len(test_loader.dataset)\n    return test_loss, test_accuracy","fe3fcef1":"for epoch in range(1, EPOCHS + 1):\n    train(model, dataloaders[\"train\"], optimizer, log_interval = 5)\n    test_loss, test_accuracy = evaluate(model, dataloaders[\"val\"])\n    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n        epoch, test_loss, test_accuracy))","ef9a365b":"### 9. \uac80\uc99d\ub370\uc774\ud130 \ubaa8\ub378 \uc131\ub2a5 \ud3c9\uac00","8ac32c4d":"### 3. \uac1c\ubbf8\uc640 \ubc8c\uc744 \ubd84\ub958\ud558\uae30 \uc704\ud574 \uac1c\ubbf8 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc640 \ubc8c \uc774\ubbf8\uc9c0 \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30","1dbf54d5":"### 7. Optimizer, Objective Function \uc124\uc815\ud558\uae30","8b944e7b":"### 4. \ub370\uc774\ud130 \ud655\uc778\ud558\uae30(1)","1ea49743":"### 2. \ub525\ub7ec\ub2dd \ubaa8\ub378\uc744 \uc124\uacc4\ud560 \ub54c \ud65c\uc6a9\ud558\ub294 \uc7a5\ube44 \ud655\uc778","735ade3e":"### 6. ResNet \ubaa8\ub378 \uc124\uacc4\ud558\uae30","bbc855d0":"### 8. \ud559\uc2b5\ub370\uc774\ud130 \ubaa8\ub378 \uc131\ub2a5 \ud3c9\uac00","d06e7cdb":"### 5. \ub370\uc774\ud130 \ud655\uc778\ud558\uae30(2)","ae59f721":"### 10. Loss, Accuracy \ud655\uc778","5f140ae8":"### 1. Module Import"}}