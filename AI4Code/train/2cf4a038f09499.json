{"cell_type":{"15a70a8f":"code","1ca20575":"code","3cad3914":"code","73de6151":"code","fe39c81d":"code","2f25e35a":"code","58ddc937":"code","7785ea8c":"code","63914fd7":"code","2bc798f8":"code","ca504a0f":"code","b0721e63":"code","90986b2d":"code","472cf3b3":"code","9a608a32":"code","a7d0eca3":"code","edc4b37e":"code","e76c95ab":"code","c53388f7":"code","ad28b70d":"code","f774ba3f":"code","1f79f80f":"code","7168ebcd":"code","31700376":"code","aff77aec":"code","c82476d0":"code","4427cf2e":"code","9ebdf957":"code","0feab78b":"code","71482eaa":"code","89912ce2":"code","9ad7d476":"code","65b66c95":"code","08878da3":"code","b94e07ca":"code","2b4804d5":"code","2560bec0":"code","ca86d703":"code","8b8b4500":"code","652d2999":"code","4aa23161":"code","d1176d76":"code","202dbd78":"code","3d4f250a":"code","65087f9b":"code","9f495096":"code","19befbaf":"code","d98b17a9":"code","cabd4209":"code","7f6b14da":"code","a658b3d8":"code","221c3e6c":"code","1500c78f":"code","88a2d5f8":"code","5a89f5c1":"code","d411ce5d":"code","bbe93b71":"code","7b8927d3":"code","879b9c3a":"code","fdd56bf9":"code","046b29ea":"code","81b2cc3b":"code","22cd737d":"code","33023584":"code","81ae3dcd":"code","4743f65b":"code","a6062950":"code","7088edeb":"code","32475f5d":"code","88bbba1b":"code","3ade0b45":"code","344f6350":"code","0dcfa703":"code","20cbd2c7":"code","590fec75":"code","092911f9":"code","5390cb55":"code","9e9d76dc":"code","f5c27c79":"code","d6ef7b1e":"code","65e7eaec":"markdown","c823c822":"markdown","1cb158f4":"markdown"},"source":{"15a70a8f":"import numpy as np # linear algebra\nnp.random.seed(1337) #reproducibility\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","1ca20575":"import os\nimport pandas as pd\nimport soundfile as sf\nimport scipy.signal as signal\nimport matplotlib.pyplot as plt\nimport gc\nimport IPython.display as ipd ","3cad3914":"train_path = '..\/input\/spoken-language-identification\/train\/train\/'\ntest_path = '..\/input\/spoken-language-identification\/test\/test\/'","73de6151":"filename = 'de_f_0809fd0642232f8c85b0b3d545dc2b5a.fragment1.flac'","fe39c81d":"data, samplerate = sf.read(train_path+filename)","2f25e35a":"import os\nprint(os.listdir('..\/input'))\nimport pandas as pd","58ddc937":"import gc\ngc.collect()","7785ea8c":"data.shape","63914fd7":"#el flac cargado\ndata[:10]","2bc798f8":"samplerate","ca504a0f":"ipd.Audio(train_path+filename)","b0721e63":"#freq, time, Sxx = signal.spectrogram(data, samplerate, scaling='spectrum')\n#plt.pcolormesh(time, freq, Sxx)\n\n## add axis labels\n# plt.ylabel('Frequency [Hz]')\n# plt.xlabel('Time [sec]')","90986b2d":"Pxx, freqs, bins, im = plt.specgram(data, Fs=samplerate)\n\n# add axis labels\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')","472cf3b3":"plt.plot(data)\n\n# add axis labels\nplt.ylabel('Amplitude')\nplt.xlabel('Time in samples')","9a608a32":"filename[:2]","a7d0eca3":"#para train path\nlabel = []\nfor filename in os.listdir(train_path):\n    label.append(filename[:2]) #es [:2] porque el idioma esta en los dos primeros elementos","edc4b37e":"#para test path\nlabel_t = []\nfor filename in os.listdir(test_path):\n    label_t.append(filename[:2])","e76c95ab":"print(len(label))\nprint(len(label_t))","c53388f7":"# gender = []\n# for filename in os.listdir(train_path):\n#     gender.append('male' if filename[3:4]=='m' else 'female')","ad28b70d":"# gender_t = []\n# for filename in os.listdir(test_path):\n#     gender_t.append('male' if filename[3:4]=='m' else 'female')","f774ba3f":"file = []\nfor filename in os.listdir(train_path):\n    file.append(filename)","1f79f80f":"file_t = []\nfor filename in os.listdir(test_path):\n    file_t.append(filename)","7168ebcd":"Label = pd.DataFrame(label,columns=['Language'])","31700376":"Label['Language'].value_counts()","aff77aec":"data = {'filename':file,\n       'languange':label}","c82476d0":"data_t = {'filename':file_t,\n       'languange':label_t}","4427cf2e":"#df es el dataframe de train\ndf = pd.DataFrame(data)","9ebdf957":"#df_t es el dataframe de test\ndf_t = pd.DataFrame(data_t)","0feab78b":"df['filename'][0]","71482eaa":"#extraida de https:\/\/github.com\/tomasz-oponowicz\/spoken_language_identification\ndef generate_fb_and_mfcc(signal, sample_rate):\n\n    # Pre-Emphasis\n    pre_emphasis = 0.97\n    emphasized_signal = np.append(\n        signal[0],\n        signal[1:] - pre_emphasis * signal[:-1])\n\n    # Framing\n    frame_size = 0.025\n    frame_stride = 0.01\n\n    # Convert from seconds to samples\n    frame_length, frame_step = (\n        frame_size * sample_rate,\n        frame_stride * sample_rate)\n    signal_length = len(emphasized_signal)\n    frame_length = int(round(frame_length))\n    frame_step = int(round(frame_step))\n\n    # Make sure that we have at least 1 frame\n    num_frames = int(\n        np.ceil(float(np.abs(signal_length - frame_length)) \/ frame_step))\n\n    pad_signal_length = num_frames * frame_step + frame_length\n    z = np.zeros((pad_signal_length - signal_length))\n\n    # Pad Signal to make sure that all frames have equal\n    # number of samples without truncating any samples\n    # from the original signal\n    pad_signal = np.append(emphasized_signal, z)\n\n    indices = (\n        np.tile(np.arange(0, frame_length), (num_frames, 1)) +\n        np.tile(\n            np.arange(0, num_frames * frame_step, frame_step),\n            (frame_length, 1)\n        ).T\n    )\n    frames = pad_signal[indices.astype(np.int32, copy=False)]\n\n    # Window\n    frames *= np.hamming(frame_length)\n\n    # Fourier-Transform and Power Spectrum\n    NFFT = 512\n\n    # Magnitude of the FFT\n    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))\n\n    # Power Spectrum\n    pow_frames = ((1.0 \/ NFFT) * ((mag_frames) ** 2))\n\n    # Filter Banks\n    nfilt = 40\n\n    low_freq_mel = 0\n\n    # Convert Hz to Mel\n    high_freq_mel = (2595 * np.log10(1 + (sample_rate \/ 2) \/ 700))\n\n    # Equally spaced in Mel scale\n    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)\n\n    # Convert Mel to Hz\n    hz_points = (700 * (10**(mel_points \/ 2595) - 1))\n    bin = np.floor((NFFT + 1) * hz_points \/ sample_rate)\n\n    fbank = np.zeros((nfilt, int(np.floor(NFFT \/ 2 + 1))))\n    for m in range(1, nfilt + 1):\n        f_m_minus = int(bin[m - 1])   # left\n        f_m = int(bin[m])             # center\n        f_m_plus = int(bin[m + 1])    # right\n\n        for k in range(f_m_minus, f_m):\n            fbank[m - 1, k] = (k - bin[m - 1]) \/ (bin[m] - bin[m - 1])\n        for k in range(f_m, f_m_plus):\n            fbank[m - 1, k] = (bin[m + 1] - k) \/ (bin[m + 1] - bin[m])\n    filter_banks = np.dot(pow_frames, fbank.T)\n\n    # Numerical Stability\n    filter_banks = np.where(\n        filter_banks == 0,\n        np.finfo(float).eps,\n        filter_banks)\n\n    # dB\n    filter_banks = 20 * np.log10(filter_banks)\n\n    # MFCCs\n    # num_ceps = 12\n    # cep_lifter = 22\n\n    # ### Keep 2-13\n    # mfcc = dct(\n    #     filter_banks,\n    #     type=2,\n    #     axis=1,\n    #     norm='ortho'\n    # )[:, 1 : (num_ceps + 1)]\n\n    # (nframes, ncoeff) = mfcc.shape\n    # n = np.arange(ncoeff)\n    # lift = 1 + (cep_lifter \/ 2) * np.sin(np.pi * n \/ cep_lifter)\n    # mfcc *= lift\n    #filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)\n    return filter_banks","89912ce2":"from sklearn.model_selection import train_test_split","9ad7d476":"### Splitting 73000 audio files to get enough files for training and for RAM","65b66c95":"X_train,X_test,y_train,y_test = train_test_split(df,df['languange'],stratify = df['languange'],test_size = 0.5,random_state = 0)\nprint(X_train['languange'].value_counts())\nprint(X_test['languange'].value_counts())","08878da3":"X_train,X_test,y_train,y_test = train_test_split(X_train,X_train['languange'],stratify = X_train['languange'],test_size = 0.5,random_state = 0)\nprint(X_train['languange'].value_counts())\nprint(X_test['languange'].value_counts())","b94e07ca":"X_train,X_test,y_train,y_test = train_test_split(X_train,X_train['languange'],stratify = X_train['languange'],test_size = 0.5,random_state = 0)\nprint(X_train['languange'].value_counts())\nprint(X_test['languange'].value_counts())","2b4804d5":"X_train,X_test,y_train,y_test = train_test_split(X_train,X_train['languange'],stratify = X_train['languange'],test_size = 0.6,random_state = 0)\nprint(X_train['languange'].value_counts())\nprint(X_test['languange'].value_counts())","2560bec0":"X_train['filename'].values[:2]","ca86d703":"X_train.head()","8b8b4500":"#reseteamos los indices\nX_train = X_train.reset_index(drop = True)\nX_train.head()","652d2999":"gc.collect()","4aa23161":"series = []\nlength = []\nfor filename in X_train['filename'].values:\n    flac, samplerate = sf.read(train_path+filename)\n    series.append(flac)\n    length.append(samplerate)","d1176d76":"X_train['Series'] = series\nX_train['Length'] = length\nX_train.head(20)","202dbd78":"len(X_train)","3d4f250a":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","65087f9b":"##### Clearing the memory and reusing the notebook\ngc.collect()","9f495096":"#genero filter banks y mfccs para train\nMFCC_array = []\nfor i in range(0,len(X_train)):\n    MFCC = generate_fb_and_mfcc(X_train['Series'][i], X_train['Length'][i])\n    MFCC_sc = sc.fit_transform(MFCC)\n    MFCC_array.append(MFCC_sc)\nMFCC_array = np.array(MFCC_array)  ","19befbaf":"np.save('..\/working\/MFCC_data',MFCC_array)","d98b17a9":"#repito todo para test\nseries_t = []\nlength_t = []\nfor filename in df_t['filename'].values:\n    flac, samplerate = sf.read(test_path+filename)\n    series_t.append(flac)\n    length_t.append(samplerate)","cabd4209":"df_t['Series'] = series_t\ndf_t['Length'] = length_t\ndf_t.head()","7f6b14da":"##genero filter banks y mfccs para test, el que tiene 540 items\nMFCC_array_t = []\nfor i in range(0,len(df_t)):\n    MFCC = generate_fb_and_mfcc(df_t['Series'][i], df_t['Length'][i])\n    MFCC_sc = sc.fit_transform(MFCC)\n    MFCC_array_t.append(MFCC_sc)\nMFCC_array_t = np.array(MFCC_array_t)   ","a658b3d8":"np.save('..\/working\/MFCC_data_t',MFCC_array_t)","221c3e6c":"#language dummies tiene los one hot encoding para X_train\n#language dummies_t tiene los one hot encoding para df_t; i.e. [0, 1, 0], etc\nlanguage_dummies = pd.get_dummies(X_train['languange'])\nlanguage_dummies_t = pd.get_dummies(df_t['languange'])\nnp.save('..\/working\/language_dummy',language_dummies.values)\nnp.save('..\/working\/language_dummy_t',language_dummies_t.values)","1500c78f":"import librosa\nimport librosa.display","88a2d5f8":"#Sample audio feature engineering ","5a89f5c1":"MFCC_array = np.load('..\/working\/MFCC_data.npy')\n","d411ce5d":"language_dummies = np.load('..\/working\/language_dummy.npy')\nlanguage_dummies_t = np.load('..\/working\/language_dummy_t.npy')","bbe93b71":"language_dummies_t[:5]","7b8927d3":"X_train_MFCC,X_test_MFCC,y_train_MFCC,y_test_MFCC = train_test_split(MFCC_array,language_dummies,stratify = language_dummies,test_size = 0.10,random_state = 0)","879b9c3a":"X_train_MFCC.shape","fdd56bf9":"X_train_MFCC = X_train_MFCC.reshape(-1,1000,40,1)","046b29ea":"X_test_MFCC = X_test_MFCC.reshape(-1,1000,40,1)","81b2cc3b":"y_train_MFCC \ny_test_MFCC\nlen(X_train_MFCC)","22cd737d":"from sklearn import preprocessing\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nfrom keras.models import Model, load_model, Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten\nfrom keras.layers import Dropout, Input, Activation\nfrom keras.optimizers import Nadam, SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import regularizers\n","33023584":"input_shape = (1000,40,1)\nmodel = Sequential()\n# model.add(Conv2D(32,(3, 3),strides=(1, 1),padding='same',kernel_regularizer=regularizers.l2(0.0007),\n#         input_shape=input_shape,data_format = 'channels_last'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n# model.add(Conv2D(64,(3, 3),strides=(1, 1),padding='same',kernel_regularizer=regularizers.l2(0.0007)))\n#         #kernel_regularizer=regularizers.l2(0.001)))\n# model.add(Activation('relu'))\n# #model.add(Dropout(0.4))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n# model.add(AveragePooling2D(pool_size=(3, 3),strides=(2, 2),padding='same'))\n# model.add(Flatten())\n# model.add(Dense(128,activation='relu',kernel_regularizer=regularizers.l2(0.0007)))       # kernel_regularizer=regularizers.l2(0.001)))\n# model.add(Dropout(0.40))\n# model.add(BatchNormalization())\n# model.add(Dense(3))\n# model.add(Activation('softmax'))\n\n#---------------------------- NEW MODEL\n\nmodel.add(Conv2D(32,(7, 7), activation='relu', padding='valid', input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\nmodel.add(Conv2D(64,(5,5), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\nmodel.add(Conv2D(128,(3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\nmodel.add(Conv2D(256,(3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\nmodel.add(Conv2D(512,(3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\n\n#sgd = SGD(lr=0.01, decay=1, momentum=0.0, nesterov=False)\n#sgd = sgd(lr=0.01, decay=1e-6, momentum=0.0, nesterov=False)\n#adam = Adam(lr=0.01, decay=1e-6)\nimport math\nfrom keras.callbacks import LearningRateScheduler\nadam = Adam()\ndef step_decay(epoch):\n    # 00158 = 90.4%\n\tinitial_lrate = 0.00158\n\tdrop = 0.9\n\tepochs_drop = 1\n\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)\/epochs_drop))\n\treturn lrate\n\n\nmodel.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])\n\n\n\ncheckpoint = ModelCheckpoint(\n                'model.h5',\n                monitor='val_acc',\n                verbose=0,\n                save_best_only=True,\n                mode='max'\n                )\n\nlrate = LearningRateScheduler(step_decay)\n#es = EarlyStopping(monitor='val_loss',mode = 'max')\nmodel.fit(\n                X_train_MFCC,\n                y_train_MFCC,\n                epochs=60,\n                callbacks=[checkpoint, lrate],\n                verbose=1,\n                validation_data=(X_test_MFCC, y_test_MFCC),\n                batch_size=32)","81ae3dcd":"model = load_model('model.h5')","4743f65b":"model.evaluate(X_test_MFCC,y_test_MFCC)","a6062950":"y_pred = model.predict(X_test_MFCC)","7088edeb":"y_test1 = []\nfor i in range(0,len(y_test_MFCC)):\n    argmax = np.argmax(y_test_MFCC[i,:])\n    y_test1.append(argmax)","32475f5d":"y_pred1 = []\nfor i in range(0,len(y_test_MFCC)):\n    argmax = np.argmax(y_pred[i,:])\n    y_pred1.append(argmax)","88bbba1b":"confusion_matrix(y_test1,y_pred1)","3ade0b45":"print(classification_report(y_test1,y_pred1))","344f6350":"MFCC_array_t = np.load('..\/working\/MFCC_data_t.npy')","0dcfa703":"MFCC_array_t.shape","20cbd2c7":"MFCC_array_t = MFCC_array_t.reshape(-1,1000,40,1)","590fec75":"predictions = model.predict(MFCC_array_t)","092911f9":"predictions","5390cb55":"y_pred1 = []\nfor i in range(0,len(predictions)):\n    argmax = np.argmax(predictions[i,:])\n    y_pred1.append(argmax)","9e9d76dc":"y_test1 = []\nfor i in range(0,len(language_dummies_t)):\n    argmax = np.argmax(language_dummies_t[i,:])\n    y_test1.append(argmax)","f5c27c79":"#confusion_matrix(y_test1,y_pred1)\ncm = confusion_matrix(y_test1,y_pred1)\nprint(np.around(cm\/cm.sum(axis=1, keepdims=True)*100,1))","d6ef7b1e":"print(classification_report(y_test1,y_pred1))","65e7eaec":"no es el peso, no son las capas, no es la reg l1 ni l2","c823c822":"Est\u00e1 balanceado el dataset:","1cb158f4":"cargamos las labels de idiomas en label y label_t"}}