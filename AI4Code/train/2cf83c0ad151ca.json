{"cell_type":{"ac8f55e3":"code","7eb3625b":"code","d61a378c":"code","2132483c":"code","11c14d52":"code","d13e68ba":"code","908b29bc":"code","880e9006":"code","42b70d69":"code","1fa5281b":"code","12559f68":"code","d152579d":"code","11f4d233":"code","52495c4e":"code","c45d7c67":"code","78928333":"code","dd73995a":"code","6a8d08a1":"code","5a565a52":"code","fb75bf86":"code","23d7540f":"code","0adf42d7":"code","bf530eea":"code","a08380c0":"markdown","442eab83":"markdown","498d858e":"markdown","51fd1fe2":"markdown","e643342e":"markdown","f5544eb4":"markdown","0ee6c8df":"markdown","a239e047":"markdown","44a4124e":"markdown","b5b611a3":"markdown","ff244300":"markdown","42742920":"markdown","d4adf481":"markdown","6938f344":"markdown","e7a5d851":"markdown","c73180eb":"markdown","bc22c779":"markdown","797823ed":"markdown","20300df1":"markdown","8605428f":"markdown"},"source":{"ac8f55e3":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7eb3625b":"path = '\/kaggle\/input\/tabular-playground-series-feb-2021\/'\nos.listdir(path)","d61a378c":"train_data = pd.read_csv(path+'train.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","2132483c":"print('Number train samples:', len(train_data.index))\nprint('Number test samples:', len(test_data.index))\nprint('Number features:', len(train_data.columns))","11c14d52":"print('Missing values on the train data:', train_data.isnull().sum().sum())\nprint('Missing values on the test data:', test_data.isnull().sum().sum())","d13e68ba":"features_cat = ['cat'+str(i) for i in range(10)]\nfeatures_num = ['cont'+str(i) for i in range(1, 14)]\nno_features = ['id', 'target']","908b29bc":"print('number of categorical features:', len(features_cat))\nprint('number of numerical features:', len(features_num))","880e9006":"features_cat = ['cat'+str(i) for i in range(10)]\nle = LabelEncoder()\nfor col in features_cat:\n    le.fit(train_data[col])\n    train_data[col] = le.transform(train_data[col])\n    test_data[col] = le.transform(test_data[col])","42b70d69":"train_data['mean'] = train_data[features_num].mean(axis=1)\ntrain_data['std'] = train_data[features_num].std(axis=1)\ntrain_data['max'] = train_data[features_num].max(axis=1)\ntrain_data['min'] = train_data[features_num].min(axis=1)\ntrain_data['sum'] = train_data[features_num].sum(axis=1)\n\ntest_data['mean'] = test_data[features_num].mean(axis=1)\ntest_data['std'] = test_data[features_num].std(axis=1)\ntest_data['max'] = test_data[features_num].max(axis=1)\ntest_data['min'] = test_data[features_num].min(axis=1)\ntest_data['sum'] = test_data[features_num].sum(axis=1)","1fa5281b":"train_data.boxplot(column=features_num, figsize=(10,4))\nplt.show()","12559f68":"train_data.boxplot(column=features_cat, figsize=(10,4))\nplt.show()","d152579d":"temp = train_data\ncorr = temp.corr()\ncorr.style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)","11f4d233":"X_train = train_data[train_data.columns.difference(no_features)]\ny_train = train_data['target']\nX_test = test_data[test_data.columns.difference(no_features)]","52495c4e":"mean = X_train.mean()\nX_train = X_train-mean\nstd = X_train.std()\nX_train = X_train\/std\nX_test = (X_test-mean)\/std","c45d7c67":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2021)","78928333":"print('Train shape:', X_train.shape)\nprint('Val shape:', X_val.shape)\nprint('Test shape:', X_test.shape)","dd73995a":"model = XGBRegressor(objective='reg:squarederror',\n                     booster = \"gbtree\",\n                     eval_metric = \"rmse\",\n                     tree_method = \"gpu_hist\",\n                     n_estimators = 1000,\n                     learning_rate = 0.02,\n                     random_state = 2021)","6a8d08a1":"model.fit(X_train, y_train)\ny_val_pred = model.predict(X_val)\nprint('Score validation data:', np.sqrt(mean_squared_error(y_val, y_val_pred)))","5a565a52":"importance = model.feature_importances_\nfig = plt.figure(figsize=(10, 6))\nx = list(train_data[train_data.columns.difference(no_features)])\nplt.barh(x, 100*importance, color='orange')\nplt.title('Feature Importance', loc='left')\nplt.xlabel('Percentage')\nplt.grid()\nplt.show()","fb75bf86":"y_train_pred = model.predict(X_train)\ny_val_pred = model.predict(X_val)\n\nfig, axs = plt.subplots(1, 2, figsize=(22, 6))\nfig.subplots_adjust(hspace = .5, wspace=.5)\naxs = axs.ravel()\naxs[0].plot(y_train, y_train_pred, 'ro')\naxs[0].plot(y_train, y_train, 'blue')\naxs[1].plot(y_val, y_val_pred, 'ro')\naxs[1].plot(y_val, y_val, 'blue')\nfor i in range(2):\n    axs[i].grid()\n    axs[i].set_xlabel('true')\n    axs[i].set_ylabel('pred')\naxs[0].set_title('train')\naxs[1].set_title('val')\nplt.show()","23d7540f":"y_test = model.predict(X_test)","0adf42d7":"output = samp_subm.copy()\noutput['target'] = y_test","bf530eea":"output.to_csv('submission.csv', index=False)","a08380c0":"Encoding of categorical features:","442eab83":"Distribution of the categorcial data:","498d858e":"# Path","51fd1fe2":"# Libraries","e643342e":"We create statistical features like mean, max and min for every sample on the train and test data.","f5544eb4":"# Analyse Training","0ee6c8df":"Distribution of the numerical values:","a239e047":"# Train, Validation And Test Data","44a4124e":"# Write Output","b5b611a3":"# Overview","ff244300":"Scale Date:","42742920":"Correlation matrix:","d4adf481":"# Feature Engineering","6938f344":"# Load Data","e7a5d851":"# EDA","c73180eb":"Visualization of the error:","bc22c779":"# Model","797823ed":"# Intro\nWelcome to the monthly Kaggle experiment in 2021. This is [february](https:\/\/www.kaggle.com\/c\/tabular-playground-series-feb-2021\/overview). \n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/25225\/logos\/header.png)\n\nThis notebook is a simple tutorial of the second experimental competition. For feature encoding techniques we recommend [this notebook](https:\/\/www.kaggle.com\/drcapa\/categorical-feature-engineering-2-xgb).\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span>","20300df1":"Feature Importance:","8605428f":"# Predict Test Data"}}