{"cell_type":{"66a8dcbb":"code","2bf93847":"code","b8abb753":"code","bc24c0c3":"code","4db3faec":"code","b4c2e3e7":"code","01c06a36":"code","7be3238f":"code","0a20c5e1":"code","b7fc1eef":"code","81a6f360":"code","9d97e390":"code","73ffbfd8":"code","cd3ced04":"code","4347fae3":"code","908a3bfc":"code","c18a342e":"code","fa49880d":"code","a4bc7405":"code","e15ef0b5":"code","2c53614f":"code","dd2a8f7c":"code","8e641d09":"code","7d636bea":"code","7a87f86e":"code","e9a2b7e5":"code","9c942da9":"code","10f54fe1":"code","bee1f521":"code","99f55d77":"markdown","1d3bf12b":"markdown","c2a45e2f":"markdown","092b7e40":"markdown","625f2aad":"markdown","c3ef41b3":"markdown","d2de4a4e":"markdown","d695ea5c":"markdown","24686439":"markdown","d52c8e43":"markdown","553d4314":"markdown","0faebf3b":"markdown","a407d221":"markdown","36e15430":"markdown","2f2abe3d":"markdown"},"source":{"66a8dcbb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nplt.style.use('ggplot')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) \n# that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2bf93847":"file_path = '\/kaggle\/input\/game-analytics\/level_progress.csv'\n\ndf = pd.read_csv(file_path, parse_dates = ['event_datetime'])\ndf.shape, df.columns","b8abb753":"df.head()","bc24c0c3":"df.apply(lambda x : len(x.unique()))","4db3faec":"avg_session_per_player = df.groupby('player_id')['session_id'].nunique().mean()\navg_levels_per_session = df.groupby('session_id')['level_number'].nunique().mean()\nprint('Average sessions by a player:', avg_session_per_player)\nprint('Average (different) levels in a session:', avg_levels_per_session)","b4c2e3e7":"df['status'].value_counts().plot(kind = 'bar', color=plt.cm.Paired(np.arange(3)))","01c06a36":"plt.figure(figsize = (14,7))\ngrouped = df.groupby(['level_number', 'status'])['player_id'].count().reset_index()\ngrouped.set_index('level_number', inplace = True)\ngrouped.groupby('status')['player_id'].plot(legend = True)","7be3238f":"outcome_df = df.loc[df.status != 'start'].copy()\noutcome_df.shape","0a20c5e1":"ct = pd.crosstab(outcome_df['level_number'], outcome_df['status'])\nprint(ct.head())\nprint('\\n')\nprint(ct.tail())","b7fc1eef":"ct_norm = pd.crosstab(outcome_df['level_number'],outcome_df['status'],normalize = 'index').reset_index()\nct_norm['total_samples'] = ct['complete'] + ct['fail']\nct_norm.sort_values('complete').head()","81a6f360":"def get_significance(p_val):\n    \"\"\"Receives the p-value and returns string.\"\"\"\n    if not pd.notnull(p_val):\n        p_text = 'ns' \n    elif p_val > 0.05:\n        p_text = \"ns\"  # above threshold => not significant\n    else:\n        p_text = 'significant'\n    \n    return p_text","9d97e390":"levels_to_consider = ct_norm[ct_norm['total_samples'] > 5]['level_number'].tolist()","73ffbfd8":"ct_chi = ct[ct.index.isin(levels_to_consider)].copy()","cd3ced04":"\nchi2, p, dof, exp = stats.chi2_contingency(ct, correction=False)\nprint('p-value for chi-sqaure test:', p)","4347fae3":"# # - To reconfirm, use proportions_chisquare from the statsmodels pacakge.\n# from statsmodels.stats.proportion import proportions_chisquare\n# r = proportions_chisquare(ct_chi['complete'], ct_chi['total_samples'])\n# print('p-value:', r[1])","908a3bfc":"ct_chi['total_samples'] = ct_chi['complete'] + ct_chi['fail']","c18a342e":"from statsmodels.stats.proportion import proportions_chisquare_allpairs\nr = proportions_chisquare_allpairs(ct_chi['complete'], ct_chi['total_samples'], \n                                   multitest_method = 'simes-hochberg')\n\ng = [eval(t) for t in r.all_pairs_names]\ng1, g2 = zip(*g)\nrows = list(zip(g1, g2, r.pvals_raw, r.pval_corrected()))\nrdf = pd.DataFrame(rows, columns = ['level_1', 'level_2', 'raw_pvalue', 'correct_pvalue'])\nrdf.shape","fa49880d":"rdf['result'] = rdf['correct_pvalue'].apply(lambda x:get_significance(x))","a4bc7405":"sd = dict(zip(ct_norm['level_number'], ct_norm['complete']))","e15ef0b5":"sig_df = rdf[rdf['result'] == 'significant'].copy()\nsig_df['level1_success_ratio'] = sig_df['level_1'].replace(sd)\nsig_df['level2_success_ratio'] = sig_df['level_2'].replace(sd)\nsig_df['diff'] = (sig_df['level1_success_ratio'] - sig_df['level2_success_ratio'])","2c53614f":"sig_df.sort_values('correct_pvalue')","dd2a8f7c":"sig_df[sig_df['diff'] < 0]","8e641d09":"from itertools import combinations\nimport scipy.stats as stats\n\n\nall_combinations = list(combinations(ct.index, 2))\n\npairs = []\np_vals = []\nodds_ratios = []\nfor comb in all_combinations:\n    # subset df into a dataframe containing only the pair \"comb\"\n    sdf = ct[(ct.index == comb[0]) | (ct.index == comb[1])]\n    oddsratio, pvalue = stats.fisher_exact(sdf)\n    pairs.append((comb[0], comb[1]))\n    p_vals.append(pvalue)\n    odds_ratios.append(oddsratio)\n    \nlen(pairs), len(p_vals)","7d636bea":"from statsmodels.sandbox.stats.multicomp import multipletests #fdr_bh\nreject_list, corrected_p_vals = multipletests(p_vals, method='simes-hochberg')[:2]","7a87f86e":"g1, g2 = zip(*pairs)\nrows = list(zip(g1, g2, p_vals, corrected_p_vals))\nrdf = pd.DataFrame(rows, columns = ['level_1', 'level_2', 'raw_pvalue', 'correct_pvalue'])\nrdf['odds_ratio'] = odds_ratios\nrdf.shape","e9a2b7e5":"rdf['result'] = rdf['correct_pvalue'].apply(lambda x:get_significance(x))","9c942da9":"sig_df = rdf[rdf['result'] == 'significant'].copy()\nsig_df['level1_success_rate'] = sig_df['level_1'].replace(sd)\nsig_df['level2_success_rate'] = sig_df['level_2'].replace(sd)\nsig_df['diff'] = (sig_df['level1_success_rate'] - sig_df['level2_success_rate'])","10f54fe1":"sig_df.sort_values('correct_pvalue').head(10)","bee1f521":"sig_df[sig_df['diff'] < 0]","99f55d77":"### Fischer's Excat Test\n\n#### why ?\n\n- It relaxes the some assumptions made by the chisquare test & also is works better with lower sample sizes as this a excat test.","1d3bf12b":"- Session: from the point a user open the game to exit's it. So, in a single session, user can play multiple levels.\n- From the given data, It seems like user can start any level he wants, bcz there are events of next level without completing the current level with in same session.","c2a45e2f":"### ChiSquare test for proportions.\n\n#### To check if there is significant association between level_number & status (success\/fail).\n\n- H0 (Null hypotheses) : The two categorical variables are independent (no association between the two variables) ( H0: Oi = Ei ).\n- H1 (Alternative hypotheses) = The two categorical variables are dependent (there is an association between the two variables) ( Ha: Oi \u2260 Ei ).\n\n\n#### Assumptions:\n\n- The two variables are categorical (nominal) and data is randomly sampled.\n- The levels of variables are mutually exclusive.\n- The expected frequency count for at least 80% of the cell in a contingency table is at least 5.\n- The expected frequency count should not be less than 1.\n- Observations should be independent of each other.\n- Observation data should be frequency counts and not percentages or transformed data.","092b7e40":"- If we go by simple success\/failure ratio, we can say level 44\/42 are having high failure rates, but how significant & consistent ? bcz they have very less samples (< 5). It was the case will all most all levels greather than 10.\n\n- So we need to measure statistically & only take the comparisons that are satistically significant at certain level. (alpha = 0.05)","625f2aad":"\n### Fisher Excat Test: What are the levels, users most likely to fail ?\n\n- The results are inline with the observations from the chisquare test","c3ef41b3":"- consider only the levels with atleast 10 samples. As chisqaure wont handle samller samples & will result in errors","d2de4a4e":"### why does this statistical analysis even matter ?\n\n- As a game publisher,we need to have as more active users as possible which inturn to boost\/maintain revenue.\n- Some levels which are significantly having lesser success rate indicate that user are finding difficult to get past them & they eventually leave\/uninstall the game. It could also mean that users are loosing interest in the game or could be due to affect of other factors.\n\n- So It is important to identify a lower level which is significantly diffcult than higher levels, as higher ones come later in the game.\n\n\n### What to do ? If a level with significant low success ratio is identified ?\n\n- Offering some booster\/extra lifes for the levels which are having significantly lower success rates will help.\n- Reassessing the difficulty of level from user prespective & reordering them will also help.\n- Any other steps neccessarily to motivate the user & retain them.","d695ea5c":"- For a particular level, there can be following possibilities\n    1. start, complete.\n    2. start, fail.\n    3. only start. (might left in midway)\n    \n\n- Around level 3, 4, 5, 6 there is significant spikes in the number of starts & fails. From there on, the numbers have reduced logarthmic fashion.\n\n- I guess one or more of the above levels are significantly difficult than user anticipated.\n ","24686439":"### Filtering data\n\nWhy start events are not needed ?\n\n- They are not needed for our objective to determine the levels those users are most likely to fail.\n- Start by itself wont represent complete event, it must either complete\/fail events succeding it to record whether the attempt is success\/failure.","d52c8e43":"### Chisquare Test: What are the levels, users most likely to fail ?\n\n\n- After sorting the results by p_value, the pair (0,3) is the most significant one rejecting the null hypothesis with highest probability. So we can users are more likely to fail at level 3 than level 0.\n\n- Also, If we look at pairs with negative effect (diff): we can say success ratio of level 3 is significantly less than level 4, 9 & 10. The pattern here is not expected or normal,indicating that players are more likely to fail at level 3.","553d4314":"### Set the Significance level\n\n- alpha = 0.05","0faebf3b":"- Not even single person completed level 49. (only started once)\n- The frequencies\/observations are very low & negligible for all levels > 30. ","a407d221":"### Chisquare test - Post Hoc Analysis (Pairwise tests)\n\n- Post-Hoc Analysis to identify the different level pairs with siginificant difference in ratio of success.","36e15430":"[Refer this R notebook](https:\/\/www.kaggle.com\/asrsaiteja\/proportions-statistical-testing?scriptVersionId=51067164)\n\n- Same test in the R is also giving the p-value of 0.00\n- In addition to chisqaure test, I also performed fisher excat test on the same contigency table using R. The p-value reported is 0.0004998.  (scipy's fischer exact test is limited to 2x2, so I have to use R to perform this)\n\n- As p-values are less than (<) 0.05, safely reject the null hypothesis.\n\n\n#### There is significant dependence b\/w the level_number & status. Now we need to find which level_number(s) are contributing to this","2f2abe3d":"- It is clear that start events are more than sum of complete + fail events, so there are cases where the level has started but resulted in neither success nor fail. So user might have left the game ?\n\n- Start events only represents the start of the level, not outcome so these are not need to be accounted to calculate the rate of success\/failure.\n\n- If a user left(s) a game\/level in middle, can he resume from where he left off ? I dont think so."}}