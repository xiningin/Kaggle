{"cell_type":{"0daf587b":"code","4ba71e64":"code","8c074bc7":"code","6ef9edce":"code","621899f1":"code","ae85fcb0":"code","329fb566":"code","5d7a2128":"code","c8cac048":"code","61ac7dc3":"code","9007f29c":"code","193a08ab":"code","230bb93a":"code","111396ba":"code","65d5b337":"code","77b2ba70":"code","d0125fac":"code","4746bcf5":"markdown","ae6d36c9":"markdown","46450270":"markdown","d8a452bb":"markdown","ca7b97cb":"markdown"},"source":{"0daf587b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","4ba71e64":"# full dataset not taking load\ndf = pd.read_csv(\"\/kaggle\/input\/en-fr-translation-dataset\/en-fr.csv\", nrows=8000000)","8c074bc7":"# import packages\nfrom __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\n# device type \"cuda\" or \"cpu\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","6ef9edce":"SOS_token = 0\nEOS_token = 1\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {} # word \u2192 index (word2index)\n        self.word2count = {} # index \u2192 word (index2word)\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2 # count SOS and EOS\n    \n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n            \n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1\n\ndef unicodeToAscii(s):\n    '''\n    For each character, there are two normal forms: \n    normal form C and normal form D. \n    Normal form D (NFD) is also known as canonical decomposition, and translates each character into its decomposed form. \n    Normal form C (NFC) first applies a canonical decomposition, then composes pre-combined characters again.\n    '''\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s","621899f1":"MAX_LENGTH = 30 # max 10 words including ending punctuation\nhidden_size = 256","ae85fcb0":"def readLang(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n    # split into two lines\n    lines = df.values.tolist()\n    # select everyline into pairs and normalize\n    pairs = [\n        [normalizeString(str(s)) for s in l] for l in lines\n    ]\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n    return input_lang, output_lang, pairs\n\n# filtering to sentences that translate to the form \u201cI am\u201d or \u201cHe is\u201d etc.\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","329fb566":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLang(lang1, lang2, reverse)\n    print(f\"Read sentence pairs: {len(pairs)}\")\n    pairs = filterPairs(pairs)\n    print(f\"Trimmed to sentence pairs: {len(pairs)}\")\n    print(f\"COUNTING WORDS...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted Words...\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\ninput_lang, output_lang, pairs = prepareData(df.columns.tolist()[0], df.columns.tolist()[1], True)\nprint(random.choice(pairs)) # random choice of pairs","5d7a2128":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedding = self.embedding(input).view(1, 1, -1)\n        output = embedding\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)\n\n\nclass DecoderRNN(nn.Module):\n    \"\"\"docstring for DecoderRNN\"\"\"\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","c8cac048":"def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\ndef tensorFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","61ac7dc3":"# Training\n# Preparing Training Data\n# To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). \n# While creating these vectors we will append the EOS token to both sequences.\n\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\ndef tensorFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","9007f29c":"teacher_forcing_ratio = 0.5\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden\n        )\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden\n            )\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di] # Teacher forcing\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden\n            )\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach() # detach from history as input\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n    loss.backward()\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    return loss.item() \/ target_length","193a08ab":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(s))","230bb93a":"def showplot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)\n    plt.show()","111396ba":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\n\ndef trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0 # Reset every print_every\n    plot_loss_total = 0 # Reset every plot_every\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n\n    training_pairs = [tensorFromPair(random.choice(pairs)) for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(\n            input_tensor, target_tensor, \n            encoder, decoder, \n            encoder_optimizer, decoder_optimizer, \n            criterion\n        )\n\n        print_loss_total += loss  \n        plot_loss_total += loss  \n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total \/ print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter \/ n_iters),\n                                         iter, iter \/ n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total \/ plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n    showplot(plot_losses)","65d5b337":"def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n\n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden)\n            topv, topi = decoder_output.data.topk(1)\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words\n\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrainIters(encoder1, decoder1, 75000, print_every=5000)","77b2ba70":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')\nevaluateRandomly(encoder1, decoder1)","d0125fac":"# Test\ndef translateText(input_text):\n    output_words = evaluate(\n        encoder1, decoder1, normalizeString(input_text)\n    )\n    output_sentence = ' '.join(output_words)\n    return f\"Output Sentence: {output_sentence}\"\n\ntranslateText(input_text=input(\"Type sentence: \"))","4746bcf5":"# Seq2Seq Model\n\n## A Sequence to Sequence network, or seq2seq network, or Encoder Decoder network, is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence.","ae6d36c9":"## Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder\u2019s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there.","46450270":"**The full process for preparing the data is:**\n\n* Read text file and split into lines, split lines into pairs\n* Normalize text, filter by length and content\n* Make word lists from sentences in pairs","d8a452bb":"## The whole training process looks like this:\n\n* Start a timer\n* Initialize optimizers and criterion\n* Create set of training pairs\n* Start empty losses array for plotting","ca7b97cb":"# The Encoder\n## The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n![](https:\/\/pytorch.org\/tutorials\/_images\/encoder-network.png)\n\n# The Decoder\n## In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n## At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string SOS token, and the first hidden state is the context vector (the encoder\u2019s last hidden state).\n![](https:\/\/pytorch.org\/tutorials\/_images\/decoder-network.png)"}}