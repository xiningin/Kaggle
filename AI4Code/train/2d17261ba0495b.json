{"cell_type":{"3f3df2e1":"code","e4e4b1d2":"code","036f4464":"code","1910adc9":"code","04b7271f":"code","ba034d4c":"code","5be906f6":"code","c59932f5":"code","5ece8e44":"code","2eb6dad6":"code","5d05b72a":"code","5a63c0b7":"code","dd7c2829":"code","14707b29":"code","57aa0134":"markdown","f027c2f8":"markdown","a522d01a":"markdown","6f2b6e27":"markdown","e02cf650":"markdown","4a79f3fd":"markdown","b0b50c6b":"markdown","ebf8c361":"markdown","c087aa69":"markdown"},"source":{"3f3df2e1":"import numpy as np \nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold, KFold\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, mean_squared_error\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e4e4b1d2":"def read_data():\n    print('Reading training, testing and submission data...')\n    train = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/train.csv')\n    test = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/test.csv')\n    submission = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/sample_submission.csv', dtype={'time':str})\n    print('Train set has {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n    print('Test set has {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n    return train, test, submission\n\ntrain, test, submission = read_data()","036f4464":"# Let's check the data\nbatch = 50 # batches of 50 seconds long\nprint('In the training data we {} batches'.format(train['time'].max() \/ batch))\nprint('In the testing data we {} batches'.format((test['time'].max() \/ batch - (train['time'].max() \/ batch))))\ntotal_batches = (test['time'].max() \/ batch + (train['time'].max() \/ batch))\npd.concat([train.head(), train.tail()])","1910adc9":"# concatenate data\ntrain['set'] = 'train'\ntest['set'] = 'test'\ndata = pd.concat([train, test])\nfor i in range(int(total_batches)):\n    data.loc[(data['time'] > i * batch) & (data['time'] <= (i + 1) * batch), 'batch'] = i + 1\ntrain = data[data['set'] == 'train']\ntest = data[data['set'] == 'test']\ndel data","04b7271f":"plt.figure(figsize = (12, 8))\nsns.countplot(train['open_channels'])\nplt.xlabel('Open Channels', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)\nplt.tick_params(axis='x', labelsize=13)\nplt.tick_params(axis='y', labelsize=13)","ba034d4c":"batch1 = train[train[\"batch\"] == 1]\nbatch2 = train[train[\"batch\"] == 2]\nbatch3 = train[train[\"batch\"] == 3]\nbatch4 = train[train[\"batch\"] == 4]\nbatch5 = train[train[\"batch\"] == 5]\nbatch6 = train[train[\"batch\"] == 6]\nbatch7 = train[train[\"batch\"] == 7]\nbatch8 = train[train[\"batch\"] == 8]\nbatch9 = train[train[\"batch\"] == 9]\nbatch10 = train[train[\"batch\"] == 10]\nfig, axes = plt.subplots(5, 2, figsize = (14, 12))\nsns.countplot(batch1['open_channels'], color = 'red', ax = axes[0][0])\nsns.countplot(batch2['open_channels'], color = 'green', ax = axes[0][1])\nsns.countplot(batch3['open_channels'], color = 'blue', ax = axes[1][0])\nsns.countplot(batch4['open_channels'], color = 'yellow', ax = axes[1][1])\nsns.countplot(batch5['open_channels'], color = 'brown', ax = axes[2][0])\nsns.countplot(batch6['open_channels'], color = 'pink', ax = axes[2][1])\nsns.countplot(batch7['open_channels'], color = 'orange', ax = axes[3][0])\nsns.countplot(batch8['open_channels'], color = 'purple', ax = axes[3][1])\nsns.countplot(batch9['open_channels'], color = 'gold', ax = axes[4][0])\nsns.countplot(batch10['open_channels'], color = 'silver', ax = axes[4][1])\n\nfor i in range(5):\n    for j in range(2):\n        axes[i][j].set_xlabel('')\n        axes[i][j].tick_params(axis='x', labelsize=12)\n        axes[i][j].tick_params(axis='y', labelsize=12)\n        axes[i][j].legend()\n        \naxes[0][0].set_title('Batch 1 Target Distribution', fontsize=13)\naxes[0][1].set_title('Batch 2 Target Distribution', fontsize=13)\naxes[1][0].set_title('Batch 3 Target Distribution', fontsize=13)\naxes[1][1].set_title('Batch 4 Target Distribution', fontsize=13)\naxes[2][0].set_title('Batch 5 Target Distribution', fontsize=13)\naxes[2][1].set_title('Batch 6 Target Distribution', fontsize=13)\naxes[3][0].set_title('Batch 7 Target Distribution', fontsize=13)\naxes[3][1].set_title('Batch 8 Target Distribution', fontsize=13)\naxes[4][0].set_title('Batch 9 Target Distribution', fontsize=13)\naxes[4][1].set_title('Batch 10 Target Distribution', fontsize=13)\nplt.tight_layout()\nplt.show()","5be906f6":"batch11 = test[test[\"batch\"] == 11]\nbatch12 = test[test[\"batch\"] == 12]\nbatch13 = test[test[\"batch\"] == 13]\nbatch14 = test[test[\"batch\"] == 14]\n\nfig, axes = plt.subplots(7, 2, figsize = (16, 14))\nsns.lineplot(batch1['time'], batch1['signal'], color = 'red', ax = axes[0][0])\nsns.lineplot(batch2['time'], batch2['signal'], color = 'green', ax = axes[0][1])\nsns.lineplot(batch3['time'], batch3['signal'], color = 'blue', ax = axes[1][0])\nsns.lineplot(batch4['time'], batch4['signal'], color = 'yellow', ax = axes[1][1])\nsns.lineplot(batch5['time'], batch5['signal'], color = 'brown', ax = axes[2][0])\nsns.lineplot(batch6['time'], batch6['signal'], color = 'pink', ax = axes[2][1])\nsns.lineplot(batch7['time'], batch7['signal'], color = 'orange', ax = axes[3][0])\nsns.lineplot(batch8['time'], batch8['signal'], color = 'purple', ax = axes[3][1])\nsns.lineplot(batch9['time'], batch9['signal'], color = 'gold', ax = axes[4][0])\nsns.lineplot(batch10['time'], batch10['signal'], color = 'silver', ax = axes[4][1])\nsns.lineplot(batch11['time'], batch11['signal'], color = 'skyblue', ax = axes[5][0])\nsns.lineplot(batch12['time'], batch12['signal'], color = 'darkviolet', ax = axes[5][1])\nsns.lineplot(batch13['time'], batch13['signal'], color = 'deeppink', ax = axes[6][0])\nsns.lineplot(batch14['time'], batch14['signal'], color = 'crimson', ax = axes[6][1])\n\nfor i in range(7):\n    for j in range(2):\n        axes[i][j].set_xlabel('')\n        axes[i][j].tick_params(axis='x', labelsize=12)\n        axes[i][j].tick_params(axis='y', labelsize=12)\n        axes[i][j].legend()\n        \naxes[0][0].set_title('Batch 1 Signal', fontsize=13)\naxes[0][1].set_title('Batch 2 Signal', fontsize=13)\naxes[1][0].set_title('Batch 3 Signal', fontsize=13)\naxes[1][1].set_title('Batch 4 Signal', fontsize=13)\naxes[2][0].set_title('Batch 5 Signal', fontsize=13)\naxes[2][1].set_title('Batch 6 Signal', fontsize=13)\naxes[3][0].set_title('Batch 7 Signal', fontsize=13)\naxes[3][1].set_title('Batch 8 Signal', fontsize=13)\naxes[4][0].set_title('Batch 9 Signal', fontsize=13)\naxes[4][1].set_title('Batch 10 Signal', fontsize=13)\naxes[5][0].set_title('Batch 11 Signal', fontsize=13)\naxes[5][1].set_title('Batch 12 Signal', fontsize=13)\naxes[6][0].set_title('Batch 13 Signal', fontsize=13)\naxes[6][1].set_title('Batch 14 Signal', fontsize=13)\nplt.tight_layout()\nplt.show()","c59932f5":"channel0 = train[train[\"open_channels\"] == 0]\nchannel1 = train[train[\"open_channels\"] == 1]\nchannel2 = train[train[\"open_channels\"] == 2]\nchannel3 = train[train[\"open_channels\"] == 3]\nchannel4 = train[train[\"open_channels\"] == 4]\nchannel5 = train[train[\"open_channels\"] == 5]\nchannel6 = train[train[\"open_channels\"] == 6]\nchannel7 = train[train[\"open_channels\"] == 7]\nchannel8 = train[train[\"open_channels\"] == 8]\nchannel9 = train[train[\"open_channels\"] == 9]\nchannel10 = train[train[\"open_channels\"] == 10]\nfig, axes = plt.subplots(6, 2, figsize = (15, 13))\nsns.distplot(channel0['signal'], color = 'red', ax = axes[0][0])\nsns.distplot(channel1['signal'], color = 'green', ax = axes[0][1])\nsns.distplot(channel2['signal'], color = 'blue', ax = axes[1][0])\nsns.distplot(channel3['signal'], color = 'yellow', ax = axes[1][1])\nsns.distplot(channel4['signal'], color = 'brown', ax = axes[2][0])\nsns.distplot(channel5['signal'], color = 'pink', ax = axes[2][1])\nsns.distplot(channel6['signal'], color = 'orange', ax = axes[3][0])\nsns.distplot(channel7['signal'], color = 'purple', ax = axes[3][1])\nsns.distplot(channel8['signal'], color = 'gold', ax = axes[4][0])\nsns.distplot(channel9['signal'], color = 'silver', ax = axes[4][1])\nsns.distplot(channel10['signal'], color = 'black', ax = axes[5][0])\n\nfor i in range(5):\n    for j in range(2):\n        axes[i][j].set_xlabel('')\n        axes[i][j].tick_params(axis='x', labelsize=12)\n        axes[i][j].tick_params(axis='y', labelsize=12)\n        axes[i][j].legend()\n        \naxes[0][0].set_title('Open Channel 0 Target Distribution', fontsize=13)\naxes[0][1].set_title('Open Channel 1 Target Distribution', fontsize=13)\naxes[1][0].set_title('Open Channel 2 Target Distribution', fontsize=13)\naxes[1][1].set_title('Open Channel 3 Target Distribution', fontsize=13)\naxes[2][0].set_title('Open Channel 4 Target Distribution', fontsize=13)\naxes[2][1].set_title('Open Channel 5 Target Distribution', fontsize=13)\naxes[3][0].set_title('Open Channel 6 Target Distribution', fontsize=13)\naxes[3][1].set_title('Open Channel 7 Target Distribution', fontsize=13)\naxes[4][0].set_title('Open Channel 8 Target Distribution', fontsize=13)\naxes[4][1].set_title('Open Channel 9 Target Distribution', fontsize=13)\naxes[5][0].set_title('Open Channel 10 Target Distribution', fontsize=13)\nplt.tight_layout()\nplt.show()","5ece8e44":"# lazy way to get weighted cohen kappa score 0f 0.96 (PL 30% test data)\n# n_groups = 40\n# test[\"group\"] = 0\n# for i in range(n_groups):\n#     ids = np.arange(i*50000, (i+1)*50000)\n#     test.loc[ids,\"group\"] = i\n    \n# for i in range(n_groups):\n#     sub = test[test.group == i]\n#     signals = sub.signal.values\n#     imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n#     signals = (signals - np.min(signals))\/(np.max(signals) - np.min(signals))\n#     signals = signals*(imax-imin)\n#     test.loc[sub.index,\"open_channels\"] = np.array(signals,np.int)\n    \n# submission.open_channels = np.array(test.open_channels, np.int)\n# submission.to_csv(\"submission.csv\",index=False)","2eb6dad6":"# create group (5 seconds each group)\ndef get_signal_tf(train, test):\n    \n    train_groups = 100\n    train['group'] = 0\n    for i in range(train_groups):\n        ids = np.arange(i * 50000, (i + 1) * 50000)\n        train.loc[ids, 'group'] = i\n        \n    test_groups = 40\n    test['group'] = 0\n    for i in range(test_groups):\n        ids = np.arange(i * 50000, (i + 1) * 50000)\n        test.loc[ids, 'group'] = i\n            \n    for i in range(train_groups):\n        sub = train[train.group == i]\n        signals = sub.signal.values\n        imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n        signals = (signals - np.min(signals)) \/ (np.max(signals) - np.min(signals))\n        signals = signals * (imax - imin)\n        train.loc[sub.index, \"signal_tr\"] = np.array(signals, np.int)\n        \n    for i in range(test_groups):\n        sub = test[test.group == i]\n        signals = sub.signal.values\n        imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n        signals = (signals - np.min(signals)) \/ (np.max(signals) - np.min(signals))\n        signals = signals * (imax - imin)\n        test.loc[sub.index, \"signal_tr\"] = np.array(signals, np.int)\n        \n    return train, test\n        \ntrain, test = get_signal_tf(train, test)","5d05b72a":"print('Our weighted cohen cappa score is: {}'.format(cohen_kappa_score(train['open_channels'], train['signal_tr'], weights = 'quadratic')))\nprint('Our cohen cappa score is: {}'.format(cohen_kappa_score(train['open_channels'], train['signal_tr'])))\nprint('Our accuracy score is: {}'.format(accuracy_score(train['open_channels'], train['signal_tr'])))","5a63c0b7":"def preprocess(train, test):\n    \n    pre_train = train.copy()\n    pre_test = test.copy()\n    \n    batch1 = pre_train[pre_train[\"batch\"] == 1]\n    batch2 = pre_train[pre_train[\"batch\"] == 2]\n    batch3 = pre_train[pre_train[\"batch\"] == 3]\n    batch4 = pre_train[pre_train[\"batch\"] == 4]\n    batch5 = pre_train[pre_train[\"batch\"] == 5]\n    batch6 = pre_train[pre_train[\"batch\"] == 6]\n    batch7 = pre_train[pre_train[\"batch\"] == 7]\n    batch8 = pre_train[pre_train[\"batch\"] == 8]\n    batch9 = pre_train[pre_train[\"batch\"] == 9]\n    batch10 = pre_train[pre_train[\"batch\"] == 10]\n    batch11 = pre_test[pre_test['batch'] == 11]\n    batch12 = pre_test[pre_test['batch'] == 12]\n    batch13 = pre_test[pre_test['batch'] == 13]\n    batch14 = pre_test[pre_test['batch'] == 14]\n    batches = [batch1, batch2, batch3, batch4, batch5, batch6, batch7, batch8, batch9, batch10, batch11, batch12, batch13, batch14]\n    for batch in batches:\n        for feature in ['signal_tr']:\n            # lag feature for 1-10 (just trying some random lags)\n            for lag in [1, 2, 3, 4, 5]:\n                batch[feature + '_t' + str(lag)] = batch[feature].shift(lag)\n            # some random rolling features\n            for window in [5, 25, 50, 100, 1000, 5000, 10000, 25000]:\n                batch[feature + 'mean_t' + str(window)] = batch[feature].shift(1).rolling(window).mean()\n                batch[feature + 'std_t' + str(window)] = batch[feature].shift(1).rolling(window).std()\n                batch[feature + 'min_t' + str(window)] = batch[feature].shift(1).rolling(window).min()\n                batch[feature + 'max_t' + str(window)] = batch[feature].shift(1).rolling(window).max()\n                batch[feature + 'var_t' + str(window)] = batch[feature].shift(1).rolling(window).var()\n                \n    pre_train = pd.concat([batch1, batch2, batch3, batch4, batch5, batch6, batch7, batch8, batch9, batch10])\n    pre_test = pd.concat([batch11, batch12, batch13, batch14])\n    \n    return pre_train, pre_test\n\npre_train, pre_test = preprocess(train, test)","dd7c2829":"def run_lgb(pre_trian, pre_test, usefull_features, params):\n    \n    kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n    target = 'open_channels'\n    oof_pred = np.zeros(len(pre_train))\n    y_pred = np.zeros(len(pre_test))\n    feature_importance = pd.DataFrame()\n    \n    # train a baseline model and record the weighted cohen kappa score \n    for fold, (tr_ind, val_ind) in enumerate(kf.split(pre_train)):\n        print('Fold {}'.format(fold + 1))\n        x_train, x_val = pre_train[usefull_features].iloc[tr_ind], pre_train[usefull_features].iloc[val_ind]\n        y_train, y_val = pre_train[target][tr_ind], pre_train[target][val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(params, train_set, num_boost_round = 3000, early_stopping_rounds = 50, \n                         valid_sets = [train_set, val_set], verbose_eval = 100)\n        \n        oof_pred[val_ind] = model.predict(x_val)\n        \n        y_pred += model.predict(pre_test[usefull_features]) \/ kf.n_splits\n        \n        # get fold importance df\n        fold_importance = pd.DataFrame({'features': usefull_features})\n        fold_importance['fold'] = fold + 1\n        fold_importance['importance'] = model.feature_importance()\n        feature_importance = pd.concat([feature_importance, fold_importance])\n        \n    # round predictions\n    rmse_score = np.sqrt(mean_squared_error(pre_trian[target], oof_pred))\n    print('Our oof rmse score is: ', rmse_score)\n    oof_pred = np.clip(oof_pred, 0, 10).astype(int)\n    y_pred = np.clip(y_pred, 0, 10).astype(int)\n    cohen_score = cohen_kappa_score(pre_train[target], oof_pred, weights = 'quadratic')\n    print('Our oof cohen kappa score is: ', cohen_score)\n    \n    # plot feature importance\n    fi_mean = feature_importance.groupby(['features'])['importance'].mean().reset_index()\n    plt.figure(figsize = (12, 14))\n    sns.barplot(x = fi_mean['importance'], y = fi_mean['features'])\n    plt.xlabel('Importance', fontsize = 13)\n    plt.ylabel('Feature', fontsize = 13)\n    plt.tick_params(axis = 'x', labelsize = 11)\n    plt.tick_params(axis = 'y', labelsize = 11)\n    plt.title('Light Gradient Boosting Feature Importance (5 KFold)')\n    plt.show()\n    \n    \n    return oof_pred, y_pred, feature_importance\n\n\n# define hyperparammeter (some random hyperparammeters)\nparams = {'learning_rate': 0.1, \n          'feature_fraction': 0.75, \n          'bagging_fraction': 0.75,\n          'bagging_freq': 1,\n          'n_jobs': -1, \n          'seed': 50,\n          'metric': 'rmse'\n        }\n\n# define the features for training\nfeatures = [col for col in pre_train.columns if col not in ['open_channels', 'set', 'time', 'batch', 'group']]\n\noof_pred, y_pred, feature_importance = run_lgb(pre_train, pre_test, features, params)","14707b29":"submission.open_channels = y_pred\nsubmission.to_csv(\"submission.csv\",index=False)","57aa0134":"# Target Variable Distribution","f027c2f8":"* Channel 0, 1, 2 and 3 have a similar distribution (shape). If you check the x axis you will see an increment for the signal value from 0 to 3\n* Channel 4 and 5 have a similar distribution (shape). If you check the x axis you will see an increment for the signal value from 4 to 5\n* Channel 6, 7, 8, 9 and 10 have a similar distribution (shape). If you check the x axis you will see an increment for the signal value from 6 to 10\n\n* Channels have different signal distributions!!","a522d01a":"* A lot of the batches don't have all of the classes. \n* Batch 1, 2, 3, 7 have only class 0 and 1\n* Batch 4 and 8 have only class 0, 1, 2, 3\n* Batch 6 and 9 have only class 0, 1, 2, 3, 4, 5\n* Batch 5 and 10 have only class 0, 3, 4, 5, 6, 7, 8, 9, 10\n\nIt's look like this batches are married :). \n\n* Batch 1 and 2\n* Batch 3 and 7\n* Batch 4 and 8\n* Batch 5 and 10\n* Batch 6 and 9","6f2b6e27":"# Description of the Problem\n\n* In this competition, you will be predicting the number of open_channels present, based on electrophysiological signal data. Electrophysiological involves measurements of voltage changes or electric current or manipulations on a wide variety of scales from single ion channel proteins to whole organs like the heart\n\nWhat are ion channels:\n\n* Ion channels are pore-forming membrane proteins that allow ions to pass through the channel pore. Their functions include establishing a resting membrane potential, shaping action potentials and other electrical signals by gating the flow of ions across the cell membrane, controlling the flow of ions across secretory and epithelial cells, and regulating cell volume. Ion channels are present in the membranes of all excitable cells. Ion channels are one of the two classes of ionophoric proteins, the other being ion transporters (https:\/\/en.wikipedia.org\/wiki\/Ion_channel)\n\n* In non scientific words their are a kind of protein that are on the outside of the cell and control the access of ions (there are a lot of proteins in a cell, this is just one type)\n    \n\n![image.png](attachment:image.png)\n\nSchematic diagram of an ion channel:\n* 1 - channel domains (typically four per channel), \n* 2 - outer vestibule, \n* 3 - selectivity filter, \n* 4 - diameter of selectivity filter, \n* 5 - phosphorylation site, \n* 6 - cell membrane.\n\nTheir are 11 channels (from 0 to 10) and the metric for evaluating our model is weighted cohen kappa.\n\nAnother important factor of the data is the following:\n\nIMPORTANT: While the time series appears continuous, the data is from discrete batches of 50 seconds long 10 kHz samples (500,000 rows per batch). In other words, the data from 0.0001 - 50.0000 is a different batch than 50.0001 - 100.0000, and thus discontinuous between 50.0000 and 50.0001.\n\nWe have different batches of information were each second contains 10000 examples. \n\nSimple math is 50 seconds * 10000 = 500000 rows\n\nWe have discontinuos data!!","e02cf650":"# Baseline\n\nBaseline was taken from this script\nhttps:\/\/www.kaggle.com\/suicaokhoailang\/an-embarrassingly-simple-baseline-0-960-lb","4a79f3fd":"# Signal Channel Distribution","b0b50c6b":"* Channels 0, 1 and 3 are the most common\n* Channel 10 has only 0.0071 of the participation\n* The four most common channels represent 69% of the observations","ebf8c361":"We have 10 batches of training data and 4 batches of testing data. Let's make a new column to identify each batch","c087aa69":"* Batch 2 has a strange behaviour in the first 10 seconds\n* Batch 8 has some rare peaks\n* Batches that have a similar distribution of the target variable have different signal distribution.\n* Batch 11 and 12 has a wired behaviour (test set)"}}