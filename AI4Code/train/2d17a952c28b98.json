{"cell_type":{"9af029c9":"code","f2fbb5c1":"code","7276cce3":"code","fbf13fea":"code","dafb7393":"code","26c5714a":"code","51491a75":"code","5a57dd4a":"code","1b12b6e9":"code","4000cafb":"code","4509c243":"code","3d9bc260":"code","dc73e09c":"code","1c4b34ca":"code","e623e3a7":"code","f6240eda":"code","f1eed646":"code","2517ddea":"code","ee2b4e20":"code","407e1697":"code","2fafd44e":"code","18127395":"code","f9d1669b":"code","0084146b":"code","4572ff5d":"code","c778396b":"code","eaf315ec":"code","62d13b54":"markdown","9163ca4c":"markdown","f9b809b4":"markdown","c87daf9e":"markdown","4ba31813":"markdown","bbeab4f3":"markdown","2093f0c2":"markdown","6c03dd1c":"markdown","639e9433":"markdown","5bccc954":"markdown","e074ed53":"markdown","eb646f22":"markdown","4b3db195":"markdown","7e1b499b":"markdown","dc5f22c8":"markdown","9525333e":"markdown","4ed115f7":"markdown","3742ac82":"markdown","f9257bdd":"markdown","9940d5fa":"markdown","ddf6ae19":"markdown","0ef9dddb":"markdown","c24dd4b2":"markdown","ac05916c":"markdown","2995b866":"markdown","0278c0fb":"markdown","78ce4f78":"markdown","200ce272":"markdown","867719e9":"markdown","e7556fa7":"markdown","6da532f1":"markdown","fef98d38":"markdown"},"source":{"9af029c9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn-whitegrid')\n\nadult = pd.read_csv('\/kaggle\/input\/adult-pmr3508\/train_data.csv',index_col='Id', na_values=\"?\")","f2fbb5c1":"adult.shape","7276cce3":"adult.sample(5)","fbf13fea":"adult.info()","dafb7393":"adult.describe()","26c5714a":"adult['workclass'].value_counts().plot(kind = 'barh', title = 'Workclass', color='rebeccapurple')","51491a75":"adult.loc[adult['workclass'].isnull()]","5a57dd4a":"adult_null = adult.loc[adult['workclass']=='Private'].count()\n","1b12b6e9":"print(\"workclass == 'private':\", (22696\/32560)*100, \"%\")","4000cafb":"adult['workclass'] = adult['workclass'].fillna(adult['workclass'].mode()[0])","4509c243":"adult['occupation'].value_counts().plot(kind = 'barh', title = 'Occupation', color='rebeccapurple')","3d9bc260":"adult['occupation'] = adult['occupation'].dropna()","dc73e09c":"adult['native.country'].value_counts().plot(kind = 'barh', title = 'Native Country', color='rebeccapurple', figsize=(6,8))\n","1c4b34ca":"adult['native.country'] = adult['native.country'].fillna(adult['native.country'].mode()[0])","e623e3a7":"plt.figure(figsize=(11,9), dpi= 70)\nsns.heatmap(adult.corr(), xticklabels=adult.corr().columns, yticklabels=adult.corr().columns, cmap='magma', center=0, annot=True)\nplt.title('Correlograma das vari\u00e1veis num\u00e9ricas', fontsize=15)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","f6240eda":"titulos = {'workclass':'WorkClass', 'education':'Education', 'marital.status':'Marital Status', 'occupation':'Occupation', 'relationship':'Relationship', 'race':'Race'}\nfor variavel in ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race']: \n    adult[variavel].value_counts().plot(kind = 'barh', title = titulos[variavel], color='rebeccapurple')\n    plt.show()\nadult['native.country'].value_counts().plot(kind = 'barh', title = 'Native Country', color='rebeccapurple', figsize=(6,8))\nplt.show()","f1eed646":"piramideEtaria = adult[['sex', 'age']]\nhomens = piramideEtaria[piramideEtaria.sex == 'Male'].groupby('age').count().reset_index()\nmulheres = piramideEtaria[piramideEtaria.sex == 'Female'].groupby('age').count().reset_index()\nhomens.sex = (-1)*homens.sex \n\nplt.figure (figsize = (10,10))\nplt.barh(homens.age, homens.sex, label = 'Homens', color='royalblue')\nplt.barh(mulheres.age, mulheres.sex, label = 'Mulheres', color='mediumorchid')\nplt.title('Pir\u00e2mide Et\u00e1ria')\nplt.xlabel('N\u00famero de pessoas')\nplt.ylabel('Idade')\nplt.legend()\nplt.show()","2517ddea":"categoricas = ['sex', 'race', 'marital.status', 'occupation', 'relationship']\n\nfor atribute in categoricas:\n    adult[atribute] = adult[atribute].astype('category')\n    string_num = atribute + '_num'\n    adult[string_num] = adult[atribute].cat.codes\n\nadult.sample(5)","ee2b4e20":"Xtrain = adult[['age', 'education.num', 'hours.per.week', 'sex_num', 'race_num', 'marital.status_num', 'capital.gain', 'capital.loss', 'relationship_num']]\nYtrain = adult.income","407e1697":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparameters = {'n_estimators': [x for x in range(50,500,100)],\n              'max_depth': [y for y in range(1,10)]}\n\nRF = RandomForestClassifier(random_state = 42)\nRF_clf = RandomizedSearchCV(RF, parameters, scoring = 'accuracy', cv = 5)\nRF_clf.fit(Xtrain, Ytrain)\n\nprint(f'Melhor pontua\u00e7\u00e3o: {RF_clf.best_score_}')","2fafd44e":"from sklearn.naive_bayes     import GaussianNB\nfrom sklearn.model_selection import cross_val_score\n\nnb = GaussianNB()\nnb.fit(Xtrain, Ytrain)\n\nscoreNB = cross_val_score(nb, Xtrain, Ytrain, cv=5)\nprint(f\"Melhor pontua\u00e7\u00e3o: {str(scoreNB.mean())}\")","18127395":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nparameters = {'solver': ['newton-cg', 'lbfgs', 'saga'],\n              'C': [0.01,0.1,1,10]}\n\nLR = LogisticRegression(random_state = 42,max_iter = 10000)\n\nLR_clf = RandomizedSearchCV(LR, parameters, scoring = 'accuracy', cv = 5)\n\nLR_clf.fit(Xtrain,Ytrain)\n\nprint(f'Melhor pontua\u00e7\u00e3o: {LR_clf.best_score_}')","f9d1669b":"from xgboost import XGBClassifier\n\nparameters = {'n_estimators': [x for x in range(10,100,10)],\n              'max_depth': [y for y in range(0,10)]}\n\nXGB =  XGBClassifier(eval_metric='mlogloss')\nXGB_clf = RandomizedSearchCV(XGB, parameters, scoring='accuracy', cv = 5)\nXGB_clf.fit(Xtrain, Ytrain)\n\nprint(f'Melhor pontua\u00e7\u00e3o: {XGB_clf.best_score_}')","0084146b":"test = pd.read_csv('\/kaggle\/input\/adult-pmr3508\/test_data.csv', index_col = 'Id', na_values = '?')\n","4572ff5d":"test['workclass'] = test['workclass'].fillna(test['workclass'].mode()[0])\ntest['native.country'] = test['native.country'].fillna(test['native.country'].mode()[0])\n\ncategoricas = ['sex', 'race', 'marital.status', 'occupation', 'relationship']\n\nfor atribute in categoricas:\n    test[atribute] = test[atribute].astype('category')\n    string_num = atribute + '_num'\n    test[string_num] = test[atribute].cat.codes\n    ","c778396b":"test.income = np.nan\n\nXtest = test[['age', 'education.num', 'hours.per.week', 'sex_num', 'race_num', 'marital.status_num', 'capital.gain', 'capital.loss', 'relationship_num']]\nYtest = test.income\n\nYtest_pred = XGB_clf.predict(Xtest) #Melhor classificador\n\nprediction = pd.DataFrame(index = test.index)\nprediction['income'] = Ytest_pred\nprediction = prediction.reset_index()\nprediction.head()","eaf315ec":"prediction.to_csv('submittion.csv', index = False)","62d13b54":"Com os dados acima, podemos inferir inicialmente que teremos duas tarefas importantes:\n1. Tratar dados faltantes;\n2. Transformar vari\u00e1veis categ\u00f3ricas em num\u00e9ricas para construir o classificador.","9163ca4c":"### 1.1.4 An\u00e1lises elementares","f9b809b4":"### 1.1.2 Amostra da Database","c87daf9e":"## 4.4 XGBoost","4ba31813":"\u00c9 poss\u00edvel observar que o n\u00famero de homens na amostra \u00e9 muito maior que o n\u00famero de mulheres, revelando uma base cuja amostra \u00e9 possivelmente enviesada.","bbeab4f3":"\u00c9 poss\u00edvel observar que a maioria da popula\u00e7\u00e3o trabalha no setor privado, possui grau de educa\u00e7\u00e3o a partir de Ensino M\u00e9dio completo, s\u00e3o casados ou nunca casaram, branca e original dos Estados Unidos. As ocupa\u00e7\u00f5es profissionais s\u00e3o diversas.\n\n\u00c9 importante ressaltar que os dados podem estar enviesados pela amostra coletada.","2093f0c2":"Agora, faremos a predi\u00e7\u00e3o de fato:","6c03dd1c":"### 1.2.1 Workclass","639e9433":"## 2.3 Pir\u00e2mide Et\u00e1ria","5bccc954":"# 5. Predi\u00e7\u00e3o","e074ed53":"## 4.1 Random forest","eb646f22":"## 4.2 Naive Bayes","4b3db195":"Nesse caso, como n\u00e3o h\u00e1 um dado que se sobressai muito sobre os demais, apenas descartaremos os valores nulos.","7e1b499b":"Ser\u00e3o feitos os mesmos tratamentos feitos na base de treino.","dc5f22c8":"# 1. Tratamento de dados\nAntes de realizarmos as an\u00e1lises, os dados devem ser tratados para que n\u00e3o hajam inconsist\u00eancias nos resultados causados, por exemplo, por dados faltantes.","9525333e":"## 1.2 Tratamento de dados faltantes\n\nEm 1.1.3 vimos que as colunas workclass, occupation e native.country s\u00e3o as que apresentam dados faltantes, portanto, iremos analis\u00e1-las mais a fundo.","4ed115f7":"# 3 Transforma\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas\nComo dito anteriormente, devemos transformar as vari\u00e1veis categ\u00f3ricas em num\u00e9ricas para que seja poss\u00edvel construir um classificador kNN.","3742ac82":"## 1.1 An\u00e1lises iniciais","f9257bdd":"Cria\u00e7\u00e3o do arquivo .csv:","9940d5fa":"A princ\u00edpio, n\u00e3o \u00e9 poss\u00edvel observar algum outro dado que determine a falta de dados em workclass, portanto, os dados vazios ser\u00e3o preenchidos com a moda 'private', pois representam aproximadamente 70% de todas as ocorr\u00eancias.","ddf6ae19":"# 4 Classificadores","0ef9dddb":"A princ\u00edpio n\u00e3o foi observada nenhuma correla\u00e7\u00e3o relevante entre as vari\u00e1veis num\u00e9ricas.","c24dd4b2":"## 2.2 An\u00e1lise individual das categoria de dados","ac05916c":"# 2. An\u00e1lise Explorat\u00f3ria\nSe\u00e7\u00e3o onde ser\u00e3o feitas an\u00e1lises mais aprofundadas sobre os dados, como eles se relacionam e sua rela\u00e7\u00e3o com a vari\u00e1vel de classe.","2995b866":"Neste caso, \u00e9 ainda mais evidente como 'United-States' se sobressai sobre os demais. Sendo assim, preencheremos os dados vazios com a moda, 'United-States'.","0278c0fb":"# PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es\n### Uso de classificadores na base Adult\nHash: 40\n\nConstru\u00e7\u00e3o de classificadores para a vari\u00e1vel de renda, se \u00e9 inferior ou superior a 50k, baseado nos dados da database Adult","78ce4f78":"### 1.2.3 Native Country","200ce272":"## 2.1 Correlograma das vari\u00e1veis num\u00e9ricas","867719e9":"### 1.2.2 Occupation","e7556fa7":"## 4.3 Regress\u00e3o Log\u00edstica","6da532f1":"### 1.1.3 Informa\u00e7\u00f5es sobre os tipos de dados da Database","fef98d38":"### 1.1.1 Dimens\u00e3o da Database"}}