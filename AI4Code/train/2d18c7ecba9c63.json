{"cell_type":{"8d284154":"code","92279551":"code","d047dc33":"code","ddba8779":"code","a7f7888f":"code","833c8f8f":"code","41675e96":"code","7cf1239a":"code","a85cb713":"code","fcfa2c5e":"code","2ba4169a":"code","9d19537f":"code","f8e21606":"code","d3d345e4":"code","d6be5462":"code","8726f8b0":"code","f89a79f6":"code","7f2d43a1":"code","236ee730":"code","aa6e7bbc":"code","d747f902":"code","72a97558":"code","d93ed022":"code","21745f0c":"code","fb06261e":"code","fa9e9120":"code","5abfcc2d":"code","0694532c":"code","50e43f62":"code","faea6a2e":"markdown","0b7e59a7":"markdown","634bf651":"markdown","c3df4dbb":"markdown","1338069d":"markdown","40b2e05f":"markdown","573b0608":"markdown","f378f4c7":"markdown","2f46e6b4":"markdown","a1ab639a":"markdown","38f7a61b":"markdown","0427a40d":"markdown","791893cc":"markdown"},"source":{"8d284154":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92279551":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.decomposition import PCA\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier","d047dc33":"# \u0414\u043b\u044f \u0432\u0430\u0448\u0435\u0433\u043e \u0443\u0434\u043e\u0431\u0441\u0442\u0432\u0430 \u0441\u043f\u0438\u0441\u043a\u0438 \u0441 \u0438\u043c\u0435\u043d\u0430\u043c\u0438 \u0440\u0430\u0437\u043d\u044b\u0445 \u043a\u043e\u043b\u043e\u043d\u043e\u043a\n\n# \u0427\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\nnum_cols = [\n    'ClientPeriod',\n    'MonthlySpending',\n    'TotalSpent'\n]\n\n# \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\ncat_cols = [\n    'Sex',\n    'IsSeniorCitizen',\n    'HasPartner',\n    'HasChild',\n    'HasPhoneService',\n    'HasMultiplePhoneNumbers',\n    'HasInternetService',\n    'HasOnlineSecurityService',\n    'HasOnlineBackup',\n    'HasDeviceProtection',\n    'HasTechSupportAccess',\n    'HasOnlineTV',\n    'HasMovieSubscription',\n    'HasContractPhone',\n    'IsBillingPaperless',\n    'PaymentMethod'\n]\n\nfeature_cols = num_cols + cat_cols\ntarget_col = 'Churn'","ddba8779":"# Custom transformer which relaces spaces by zeros in TotalSpent column and\n# converts it to floats. Returns pd.DataFrame\nclass TotalSpentTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # replace spaces by zeros\n        SImp = SimpleImputer(missing_values = \" \", fill_value = \"0\", strategy=\"constant\")\n        SImp.fit(X[[\"TotalSpent\"]])\n        new_TotalSpent = SImp.transform(X[[\"TotalSpent\"]])\n\n        # convert strings to float\n        new_TotalSpent = new_TotalSpent.astype(float)\n\n        # create new dataframe without changing input one\n        newX = X.assign(**{\"TotalSpent\" : new_TotalSpent})\n        return newX\n\ndef ClientPeriodTransformer(X):\n    # replace spaces by zeros\n    SImp = SimpleImputer(missing_values = 0, fill_value = 1, strategy=\"constant\")\n    SImp.fit(X[[\"ClientPeriod\"]])\n    new_ClientPeriod = SImp.transform(X[[\"ClientPeriod\"]])\n\n    new_TotalSpent = X[[\"TotalSpent\"]].copy()\n    new_TotalSpent.loc[X[\"TotalSpent\"] == 0, \"TotalSpent\"] = X[X[\"TotalSpent\"] == 0][\"MonthlySpending\"]\n\n    newX = X.assign(**{\"TotalSpent\" : new_TotalSpent, \"ClientPeriod\": new_ClientPeriod})\n    return newX\n\ndef add_spend_ratio(X):\n    newX = X.assign(**{\"spend_ratio\" : X[\"TotalSpent\"] \/ X[\"MonthlySpending\"]})\n    return newX\n\ndef add_monthly_avg(X):\n    newX = X.assign(**{\"MonthlyAvg\" : X[\"TotalSpent\"] \/ X[\"ClientPeriod\"]})\n    return newX\n\ndef add_last_more_than_avg(X):\n    newX = X.assign(**{\"LastMoreThanAvg\" : (X[\"MonthlySpending\"] \/ X[\"MonthlyAvg\"]).astype(int)})\n    return newX\n\ndef add_MonthlySpendingLog(X):\n    newX = X.assign(**{\"MonthlySpendingLog\" : np.log(X[\"MonthlySpending\"])})\n    return newX\n\ndef add_TotalSpentLog(X):\n    newX = X.assign(**{\"TotalSpentLog\" : np.log(X[\"TotalSpent\"])})\n    return newX\n\ndef remove_TotalSpent_MonthlySpending(X):\n    old_cols = X.columns\n    new_cols = [c for c in old_cols if c not in [\"TotalSpent\", \"MonthlySpending\"]]\n    newX = X[new_cols]\n    return newX\n\ndef myOneHotEncoderFunc(X, cat_cols=None):\n    ohe = OneHotEncoder(sparse=False)\n    encodedX = ohe.fit_transform(X[cat_cols])\n    encoded_cols = ohe.get_feature_names(cat_cols)\n    encodedX_df = pd.DataFrame(encodedX, columns=encoded_cols, index=X.index)\n    \n    non_cat_cols = [col for col in X.columns if col not in cat_cols]\n    \n    encoded_cols_filtered = []\n    for col in cat_cols:\n        encoded_cols_filtered.extend([c for c in encoded_cols if c.startswith(col + \"_\")][:-1])\n    newX = pd.concat([X[non_cat_cols], encodedX_df[encoded_cols_filtered]], axis=1)\n    return newX\n\ndef myOneHotEncoderTransformer(cat_cols):\n    return FunctionTransformer(myOneHotEncoderFunc, kw_args={\"cat_cols\":cat_cols})\n\ndef print_roc_auc_score(model, X, y):\n    roc_aucs = cross_val_score(model, X, y, cv=5, scoring=\"roc_auc\", n_jobs=-1)\n    print(f\"scores: {roc_aucs}\")\n    print(f\"avg: {roc_aucs.mean()}\")\n    print(f\"std: {roc_aucs.std()}\")","a7f7888f":"# Load data and split into train\/test\ndata = pd.read_csv('\/kaggle\/input\/advanced-dls-spring-2021\/train.csv')\nX = data[feature_cols]\ny = data[target_col]","833c8f8f":"# Combine all default data transformations into single pipeline\nfrom sklearn.pipeline import Pipeline\n\npreprocessing_pipeline = Pipeline(\n    [(\"TotalSpent\", TotalSpentTransformer()),\n     (\"SpendRatio\", FunctionTransformer(add_spend_ratio)),\n\n     (\"ClientPeriod\", FunctionTransformer(ClientPeriodTransformer)),\n     \n     (\"MonthlyAvg\", FunctionTransformer(add_monthly_avg)),\n     (\"LastMoreThanAvg\", FunctionTransformer(add_last_more_than_avg)),\n\n     (\"MonthlySpendingLog\", FunctionTransformer(add_MonthlySpendingLog)),\n     (\"TotalSpentLog\", FunctionTransformer(add_TotalSpentLog)),\n    ]\n)\n\nnum_cols = num_cols + [\"spend_ratio\"]\n","41675e96":"if_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n    IsolationForest(contamination=0.02)\n)\nif_pipeline.fit(X)\nanomaly_scores = if_pipeline.predict(X)","7cf1239a":"anomaly_df = pd.DataFrame(anomaly_scores, columns=[\"anomaly\"])\n\nA = pd.concat([y, anomaly_df, X], axis=1)\nA[A[\"anomaly\"] == -1]\n\n# X=X[anomaly_scores==1]\n# y=y[anomaly_scores==1]\n","a85cb713":"logreg_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n    StandardScaler(),\n#     PCA(n_components=23),\n    \n    LogisticRegression(penalty=\"l2\", C=10, l1_ratio=None, random_state=2, solver=\"saga\", max_iter=10000),\n)\n\nprint_roc_auc_score(logreg_pipeline, X, y)","fcfa2c5e":"# Testing logreg params\nparams = [\n    {\n#         \"logisticregression__C\": [100, 10, 1, 0.1, 0.01, 0.001],\n#         \"logisticregression__penalty\": [\"l2\", \"none\"],\n        \"logisticregression__class_weight\": [\"balanced\", None],\n#         \"logisticregression__l1_ratio\": [None]\n    },\n\n#     {\n#         \"logisticregression__C\": [100, 10, 1, 0.1, 0.01, 0.001],\n#         \"logisticregression__penalty\": [\"elasticnet\"],\n#         \"logisticregression__class_weight\": [\"balanced\", None],\n#         \"logisticregression__l1_ratio\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n#     }\n]\n\n\nlogreg_grid = GridSearchCV(logreg_pipeline, params, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\nlogreg_grid.fit(X, y)\nprint(logreg_grid.best_params_)\nlogreg_grid.cv_results_['mean_test_score']","2ba4169a":"nb_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n    StandardScaler(),\n    GaussianNB()\n)\n\nprint_roc_auc_score(nb_pipeline, X, y)","9d19537f":"svc_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n    StandardScaler(),\n    SVC(probability=True, C=0.5, kernel=\"poly\", gamma=\"scale\", class_weight=\"balanced\", degree=1)\n)\n\nprint_roc_auc_score(svc_pipeline, X, y)","f8e21606":"params = [{\n#                \"svc__C\": [10, 5, 1, 0.5, 0.1, 0.05, 0.01, 0.005],\n#                \"svc__kernel\": [\"linear\", \"rbf\", \"sigmoid\"],\n#                \"svc__gamma\": [\"scale\", \"auto\"],\n               \"svc__class_weight\": [\"balanced\", None],\n          },\n\n#           {\n#                \"svc__C\": [10, 5, 1, 0.5, 0.1, 0.05, 0.01, 0.005],\n#                \"svc__kernel\": [\"poly\"],\n#                \"svc__gamma\": [\"scale\", \"auto\"],\n#                \"svc__class_weight\": [\"balanced\", None],\n#                \"svc__degree\": [1, 2, 3, 4]\n#           }\n]\n\nlogreg_grid = GridSearchCV(svc_pipeline, params, cv=3, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\nlogreg_grid.fit(X, y)\nprint(logreg_grid.best_params_)\nlogreg_grid.cv_results_['mean_test_score']","d3d345e4":"catboost_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    CatBoostClassifier(iterations=400,\n                       depth=4,\n                       learning_rate=0.05,\n                       loss_function='Logloss',\n                       verbose=False,\n                       cat_features=cat_cols,\n                       random_seed = 4,\n                       l2_leaf_reg = 40,\n                       eval_metric='AUC')\n)\n\nprint_roc_auc_score(catboost_pipeline, X, y)","d6be5462":"params = {\n    \"catboostclassifier__depth\": [4, 6, 8, 10],\n#     \"catboostclassifier__learning_rate\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5, 1],\n#     \"catboostclassifier__l2_leaf_reg\": [0.1, 0.5, 1, 10, 20, 40, 60],\n#     \"catboostclassifier__iterations\": [100, 200, 500],\n#     \"catboostclassifier__random_seed\": [1, 2, 3, 4, 5, 6, 7, 8, 9], # test random seed just for fun =)\n}\n\ncb_grid = GridSearchCV(catboost_pipeline, params, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\ncb_grid.fit(X, y)\nprint(cb_grid.best_params_)\ncb_grid.cv_results_['mean_test_score']","8726f8b0":"xgb_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n    XGBClassifier(n_jobs=-1,\n                  use_label_encoder=False,\n                  learning_rate=0.1,\n                  max_depth=1,\n                  n_estimators=200)\n\n)\n\nprint_roc_auc_score(xgb_pipeline, X, y)","f89a79f6":"params = {\n#     \"xgbclassifier__n_estimators\": [50, 100, 200, 500, 1000],\n#     \"xgbclassifier__max_depth\": [1, 2, 4, 6, 8, 10],\n#     \"xgbclassifier__learning_rate\": [0.001, 0.1, 1, 10],\n\n    \"xgbclassifier__max_depth\": [1, 2],\n}\n\ndt_grid = GridSearchCV(xgb_pipeline, params, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\ndt_grid.fit(X, y)\nprint(dt_grid.best_params_)\ndt_grid.cv_results_['mean_test_score']","7f2d43a1":"dtree_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n    DecisionTreeClassifier(min_samples_leaf=15, max_depth=5, random_state=2)\n)\n\nprint_roc_auc_score(dtree_pipeline, X, y)","236ee730":"params = {\n    \"decisiontreeclassifier__min_samples_leaf\": [1, 5, 10, 15, 20],\n    \"decisiontreeclassifier__max_depth\": [5, 10, 15, 20, 100],\n}\n\ndt_grid = GridSearchCV(dtree_pipeline, params, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\ndt_grid.fit(X, y)\nprint(dt_grid.best_params_)\ndt_grid.cv_results_['mean_test_score']","aa6e7bbc":"random_forest_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n#     PCA(n_components=23),\n    RandomForestClassifier(n_estimators=200, min_samples_leaf=20, max_depth=100, random_state=2,\n                           class_weight=\"balanced\",\n                           criterion=\"entropy\"\n                          )\n)\n\nprint_roc_auc_score(random_forest_pipeline, X, y)","d747f902":"params = {\n#     \"randomforestclassifier__n_estimators\": [20, 50, 100, 200, 500],\n#     \"randomforestclassifier__min_samples_leaf\": [1, 5, 10, 15, 20, 25, 30],\n#     \"randomforestclassifier__max_depth\": [5, 10, 15, 20, 100],\n    \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"],\n#     \"randomforestclassifier__class_weight\" : [\"balanced\", \"balanced_subsample\", None]\n}\n\nrf_grid = GridSearchCV(random_forest_pipeline, params, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\nrf_grid.fit(X, y)\nprint(rf_grid.best_params_)\nrf_grid.cv_results_['mean_test_score']","72a97558":"knn_pipeline = make_pipeline(\n    preprocessing_pipeline,\n    myOneHotEncoderTransformer(cat_cols),\n    PCA(n_components=23),\n    StandardScaler(),\n    \n    KNeighborsClassifier(n_neighbors=40, weights=\"uniform\", p=1, metric='manhattan')\n)\n\nprint_roc_auc_score(knn_pipeline, X, y)","d93ed022":"params = {\n#     \"kneighborsclassifier__n_neighbors\": [1,2, 4, 6, 8, 10, 15, 20, 30, 40, 50, 70, 100],\n    \"kneighborsclassifier__weights\": [\"uniform\", \"distance\"],\n#     \"kneighborsclassifier__p\": [1, 2],\n#     \"kneighborsclassifier__metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]\n}\n\nrf_grid = GridSearchCV(knn_pipeline, params, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\nrf_grid.fit(X, y)\nprint(rf_grid.best_params_)\nrf_grid.cv_results_['mean_test_score']","21745f0c":"estimators = [(\"logreg\", logreg_pipeline),\n              (\"dtree\", dtree_pipeline),\n#               (\"rf\", random_forest_pipeline),\n#               (\"cb\", catboost_pipeline),\n#               (\"knn\", knn_pipeline),\n              (\"nb\", nb_pipeline),\n#               (\"svc\", svc_pipeline),\n#               (\"xgb\", xgb_pipeline),\n             ]\nfinal_estimator = LogisticRegression(max_iter=10000, solver=\"saga\", C=1)\n\nstacking = StackingClassifier(estimators=estimators, \n                              final_estimator=final_estimator,\n                              cv=5,\n                              stack_method=\"predict_proba\",\n                              passthrough=False)\n\nprint_roc_auc_score(stacking, X, y)","fb06261e":"params = {\n    \"logreg__logisticregression__C\": [100, 10, 1, 0.1, 0.01, 0.001],\n#     \"logreg__logisticregression__penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n#     \"logreg__logisticregression__l1_ratio\": [0.1, 0.5, 0.9],\n\n    \"dtree__decisiontreeclassifier__min_samples_leaf\": [1, 5, 10, 20],\n#     \"dtree__decisiontreeclassifier__max_depth\": [5, 10, 15, 20, 100],\n\n#     \"rf__randomforestclassifier__n_estimators\": [50, 100, 200, 500, 1000],\n#     \"rf__randomforestclassifier__min_samples_leaf\": [1, 5, 10, 20, 30],\n#     \"rf__randomforestclassifier__max_depth\": [5, 10, 15, 20, 100],\n#     \"rf__randomforestclassifier__criterion\": [\"gini\", \"entropy\"],\n#     \"rf__randomforestclassifier__class_weight\" : [\"balanced\", \"balanced_subsample\", None],\n\n#     (n_estimators=200, min_samples_leaf=30, max_depth=15, \n#     \"rf__randomforestclassifier__n_estimators\": [100, 200, 500, 1000],\n#     \"rf__randomforestclassifier__min_samples_leaf\": [1, 10, 30],\n#     \"rf__randomforestclassifier__max_depth\": [5, 10, None],\n#     \"rf__randomforestclassifier__criterion\": [\"gini\"],\n#     \"rf__randomforestclassifier__class_weight\" : [\"balanced\", \"balanced_subsample\", None],\n\n    \n#     \"cb__catboostclassifier__depth\": [2, 4, 6, 8, 10],\n#     \"cb__catboostclassifier__learning_rate\": [0.05, 0.1, 0.5, 1],\n#     \"cb__catboostclassifier__l2_leaf_reg\": [0.1, 1, 10, 30, 60],\n#     \"cb__catboostclassifier__iterations\": [50, 100, 200, 500, 1000],\n\n#     \"knn__kneighborsclassifier__n_neighbors\": [1, 2, 3, 4, 5, 10, 20, 30, 50],\n#     \"knn__kneighborsclassifier__weights\": [\"uniform\", \"distance\"],\n#     \"knn__kneighborsclassifier__p\": [1, 2],\n#     \"knn__kneighborsclassifier__metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"],\n\n    \n#     \"svc__svc__C\": [1, 0.1, 0.01, 0.001],\n#     \"svc__svc__kernel\": [\"linear\", \"rbf\", \"sigmoid\", \"poly\"],\n#     \"svc__svc__class_weight\": [\"balanced\", None],\n\n#     \"xgb__xgbclassifier__n_estimators\": [50, 100, 200, 500, 1000],\n#     \"xgb__xgbclassifier__max_depth\": [2, 4, 6, 8, 10],\n#     \"xgb__xgbclassifier__learning_rate\": [0.05, 0.1, 1, 10],\n}\n\n\nrf_grid = GridSearchCV(stacking, params, cv=3, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\n# rf_grid = RandomizedSearchCV(stacking, params, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\nrf_grid.fit(X, y)\nprint(rf_grid.best_params_)\nrf_grid.cv_results_['mean_test_score']","fa9e9120":"class StackBaseTransformer(BaseEstimator, TransformerMixin):\n    estimators = [(\"logreg\", logreg_pipeline),\n                  (\"dtree\", dtree_pipeline),\n                  (\"rf\", random_forest_pipeline),\n                  (\"cb\", catboost_pipeline),\n                  (\"knn\", knn_pipeline),\n                  (\"nb\", nb_pipeline),\n                  (\"svc\", svc_pipeline),\n                  (\"xgb\", xgb_pipeline),\n                 ]\n    \n    def fit(self, X, y=None):\n        for name, model in self.estimators:\n            model.fit(X, y)\n\n    def transform(self, X):\n        newX = pd.DataFrame()\n        for name, model in self.estimators:\n            newX[name] = model.predict_proba(X)[:, 1].round(2)\n        return newX\n\nSBT = StackBaseTransformer()\nSBT.fit(X, y)\nX_sbt = SBT.transform(X)","5abfcc2d":"pd.concat([y, X_sbt, X], axis=1)","0694532c":"sns.heatmap(X_sbt.corr(), annot=True)","50e43f62":"best_model = stacking\nbest_model.fit(X, y) # refit model on whole data\n\nX_private = pd.read_csv('\/kaggle\/input\/advanced-dls-spring-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/advanced-dls-spring-2021\/submission.csv')\nsubmission['Churn'] = best_model.predict_proba(X_private)[:, 1]\nsubmission.to_csv('.\/my_submission.csv', index=False, columns=[\"Id\", \"Churn\"])","faea6a2e":"# Logistic regression","0b7e59a7":"# KNeighborsClassifier","634bf651":"# Manual fit stacking","c3df4dbb":"# Stacking","1338069d":"# choose model for private data","40b2e05f":"# IsolationForest","573b0608":"# Naive Bayes","f378f4c7":"# SVC","2f46e6b4":"# XGBoost","a1ab639a":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f","38f7a61b":"# DecisionTreeClassifier","0427a40d":"# CatBoost","791893cc":"# RandomForestClassifier"}}