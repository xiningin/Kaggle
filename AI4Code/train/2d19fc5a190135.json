{"cell_type":{"c94a0fb1":"code","ba30fe9a":"code","726867fd":"code","42505a17":"code","0800ecb3":"code","4f3ef48e":"code","1b645bfc":"code","cbb89c40":"code","543b1f06":"code","22370c20":"code","76e33ae0":"code","c06da8b3":"code","04558dc8":"code","011db44e":"code","64a8afca":"code","3f7b8d7c":"code","9bc76dfb":"code","828a416b":"code","f883b59e":"code","01c26854":"code","751b415b":"code","666eec75":"code","7208bb0c":"code","0409810c":"code","491b6aaf":"code","902ea3da":"code","ed392566":"code","b210cca3":"code","199a37de":"code","240da111":"code","e4a5dd30":"code","1e235ab2":"code","cc6e9773":"code","269fbbb1":"code","b5c9260d":"code","c5f55a49":"code","acd12ebf":"code","ab52601c":"code","72d44252":"code","a49306f7":"code","defa50c7":"code","9ce30cbb":"code","53d1f02d":"code","b6b22c90":"code","0291cbb0":"code","e2abd605":"code","fcd09244":"code","c540d1a0":"code","927944cf":"code","802b62f3":"code","abda442b":"code","6b02818f":"code","ea83ee1b":"code","e637cff7":"code","a36c3ccf":"code","26e7706f":"code","038d2bf9":"code","ce220b3c":"code","3c38d704":"code","a7ede840":"code","0a5724b7":"code","3801f108":"code","37ae1313":"code","8e96a932":"code","45642340":"code","98d57409":"code","48c3eca3":"code","405da376":"code","9a7b6025":"code","16a5b9d8":"code","f329dd0c":"code","a41b4f9a":"code","a661dbc8":"code","ff0fdc41":"code","607b0eb8":"code","0c6c5b02":"code","d7f6be39":"code","85c8ab29":"code","5e690b53":"code","1384d1d4":"code","b6635ac8":"code","56fe1f34":"code","ee434af0":"code","91fb5e78":"code","54d3caac":"code","e0c78909":"code","796e708e":"code","24762de0":"code","de5aca4c":"code","ceaadd5e":"code","f7748dc9":"code","b458cf87":"code","611fa6ba":"code","28aab1f6":"code","b3a45687":"code","fc7caa1a":"code","b3f131d6":"code","eb56da56":"code","9f7f68f0":"code","dbea840f":"code","80f9fe5e":"code","5e3ca9cd":"code","5185045d":"code","d518e315":"code","e4aacf2c":"code","f858bb3a":"code","765c006d":"code","d868ad96":"code","8d47c83c":"code","c6c87e4e":"code","3fc0e608":"code","ed5b1fe9":"code","31471421":"code","77676bf4":"code","c57367c7":"code","b2c296f8":"code","b8c06bb3":"code","601103eb":"code","baa2431f":"code","1f87e73e":"code","4a3291eb":"code","05401fa2":"code","6ab4ebd7":"code","9e26c55e":"code","75c3ce93":"code","de7383f7":"code","0b24ba10":"code","a9da2fb4":"code","9e7a3447":"code","d4689084":"code","66b1c917":"code","d90a813e":"code","c4fcf453":"code","945cd0a1":"markdown","eb963bb3":"markdown","5107b94c":"markdown","79905000":"markdown","2e4605f8":"markdown","07f36220":"markdown","cd0f58e5":"markdown","7c839e93":"markdown","fc4cf40a":"markdown","b4c4c5a3":"markdown","10a0652d":"markdown","0d49307e":"markdown","73a21484":"markdown","957d742f":"markdown","cea2a64a":"markdown","9f61f158":"markdown","358f5570":"markdown","99d30577":"markdown","9555e1e8":"markdown","420b0889":"markdown","1ac38633":"markdown","89796c82":"markdown","63c815d6":"markdown","5faf24c0":"markdown","19b43fa5":"markdown","2a8f8135":"markdown","b6870cad":"markdown","7e1e8ab7":"markdown","80a5ed21":"markdown","50d9f91e":"markdown","a661d7c7":"markdown","29a9f061":"markdown","95fb9928":"markdown","767c049d":"markdown","2b604fec":"markdown","bc291ada":"markdown","fcf2e651":"markdown","8a057387":"markdown","f2463014":"markdown","1dd6605a":"markdown","876c086d":"markdown","c1ad999f":"markdown","b3158b46":"markdown","9fab824f":"markdown","6656ef69":"markdown","e06ee1df":"markdown","b6a8500d":"markdown","d2a23df1":"markdown","7ea54dc4":"markdown","bc87adda":"markdown","e572217f":"markdown","8b89c185":"markdown","34dd9b07":"markdown","b81778d7":"markdown","afc5a776":"markdown","6380afc1":"markdown","511b4454":"markdown","28ba399a":"markdown","ec7fd451":"markdown","a6baf5dc":"markdown","bdccb60d":"markdown","78f33bae":"markdown","b72d4926":"markdown","5b2a77bc":"markdown","6db9655e":"markdown","acc326ce":"markdown","213058ee":"markdown","82d11435":"markdown","641f9570":"markdown","ddc2f698":"markdown","f8e7f10b":"markdown","d5cefc4e":"markdown","0db24ed9":"markdown","8b8295be":"markdown","3441990b":"markdown","32aa169b":"markdown","9b61c012":"markdown","46ed646f":"markdown","36772496":"markdown","18e38178":"markdown","7a78d7dc":"markdown","9ac6dc0c":"markdown","525dc32f":"markdown","e2b4c8bb":"markdown","642dd5db":"markdown","b42b26db":"markdown","e6b24ca3":"markdown","59ee506c":"markdown","6da13eef":"markdown","091b8fb2":"markdown","eed5568e":"markdown"},"source":{"c94a0fb1":"import pandas as pd             #pandas for using dataframe and reading csv file(s)\nimport numpy as np              #numpy for vector operations and basic maths\nimport matplotlib.pyplot as plt #for plotting\n%matplotlib inline              \nimport seaborn as sns           #for making plots\nfrom haversine import haversine #for working with latitudinal and longitudinal data points\nimport math                     #for basic math operations\nimport warnings\nfrom pandas.plotting import parallel_coordinates #for multivariate plots\nwarnings.filterwarnings('ignore') #ignore deprecation warnings","ba30fe9a":"#importing data\ndata = pd.read_csv('nyc_taxi_trip_duration.csv')","726867fd":"#first 20 instances using \"head()\" function\ndata.head(20)","42505a17":"#last 20 instances using \"tail()\" function\ndata.tail(20)","0800ecb3":"#finding out the shape of the data using \"shape\" variable: Output (rows, columns)\ndata.shape","4f3ef48e":"#Printing all the columns present in data\ndata.columns","1b645bfc":"#Checking for NaN values present in data\ndata.isna().sum()","cbb89c40":"#Checking for Null values present in data\ndata.isnull().sum()","543b1f06":"# A closer look at the data types present in the data\ndata.dtypes","22370c20":"#Identifying variables with integer datatype\ndata.dtypes[data.dtypes == 'int64']","76e33ae0":"#Converting vendor_id to category datatype\ndata['vendor_id'] = data['vendor_id'].astype('category')\ndata.dtypes","c06da8b3":"#Converting passenger_count to category datatype\ndata['passenger_count'] = data['passenger_count'].astype('category')\ndata.dtypes","04558dc8":"#Identifying variables with object datatype\ndata.dtypes[data.dtypes == 'object']","011db44e":"#Converting the object data type variables to their respective datatype\ndata['id'] = data['id'].astype('category')\ndata['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])\ndata['dropoff_datetime'] = pd.to_datetime(data['dropoff_datetime'])\ndata['store_and_fwd_flag'] = data['store_and_fwd_flag'].astype('category')","64a8afca":"#Modifying values of the 'id' variable by removing the redundant 'id' part present in all values\ndef modify_id(x):\n    return x[2:]\ndata['id'] = data['id'].apply(modify_id)\ndata.head(10)","3f7b8d7c":"data.tail(10)","9bc76dfb":"#Checking\ndata['id'] = data['id'].astype('category')\ndata.dtypes","828a416b":"# Identifying variables with float datatype\ndata.dtypes[data.dtypes == 'float64']","f883b59e":"#Next, for convenience, we shall add a new column for trip_duration_minutes\ndata['trip_duration_minutes'] = data['trip_duration'].apply(lambda x: x\/60)","01c26854":"#We shall also make a feature for distance of the trip in kilometers (km)\ndef calc_distance(data):\n    pickup = (data['pickup_latitude'], data['pickup_longitude'])\n    drop = (data['dropoff_latitude'], data['dropoff_longitude'])\n    return haversine(pickup, drop)\ndata['distance'] = data.apply(lambda x: calc_distance(x), axis = 1)","751b415b":"#And lastly, we shall make a feature for the average speed of the trip in km\/hr\ndata['speed'] = (data.distance\/(data.trip_duration\/3600))","666eec75":"data.head()","7208bb0c":"#Obtain day names for each value\ndata.pickup_datetime.apply(lambda x: x.day_name())","0409810c":"#Obtain month names for each value\ndata.pickup_datetime.apply(lambda x: x.month_name())","491b6aaf":"data.head()","902ea3da":"# create time based features for pickup_datetime \ndata['pickup_datetime_moy'] = data.pickup_datetime.dt.month\ndata['pickup_datetime_hour'] = data.pickup_datetime.dt.hour","ed392566":"# create more features for pickup_datetime \ndata['pickup_datetime_woy'] = data.pickup_datetime.dt.weekofyear\ndata['pickup_datetime_dow'] = data.pickup_datetime.dt.dayofweek\ndata['pickup_datetime_doy'] = data.pickup_datetime.dt.dayofyear","b210cca3":"# create time based features for dropoff_datetime \ndata['dropoff_datetime_moy'] = data.dropoff_datetime.dt.month\ndata['dropoff_datetime_hour'] = data.dropoff_datetime.dt.hour\ndata['dropoff_datetime_woy'] = data.dropoff_datetime.dt.weekofyear\ndata['dropoff_datetime_dow'] = data.dropoff_datetime.dt.dayofweek\ndata['dropoff_datetime_doy'] = data.dropoff_datetime.dt.dayofyear","199a37de":"data.head()","240da111":"data.tail()","e4a5dd30":"data.dtypes","1e235ab2":"data.describe()","cc6e9773":"# Numerical datatypes\ndata.select_dtypes(include=['int64','float64','Int64']).dtypes","269fbbb1":"# segregating variables into groups\npickup_dropoff_location = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']\ntrip_details = ['trip_duration','trip_duration_minutes', 'distance', 'speed']\npickup_dropoff_time = ['pickup_datetime_moy', 'dropoff_datetime_moy', 'pickup_datetime_hour', 'dropoff_datetime_hour', 'pickup_datetime_woy', 'dropoff_datetime_woy', 'pickup_datetime_dow', 'dropoff_datetime_dow', 'pickup_datetime_doy', 'dropoff_datetime_doy']","b5c9260d":"# custom function for easy and efficient analysis of numerical univariate\n\ndef UVA_numeric(data, var_group):\n  '''\n  Univariate_Analysis_numeric\n  takes a group of variables (INTEGER and FLOAT) and plot\/print all the descriptives and properties along with KDE.\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot\/print it\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,3), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    mini = data[i].min()\n    maxi = data[i].max()\n    ran = data[i].max()-data[i].min()\n    mean = data[i].mean()\n    median = data[i].median()\n    mode = data[i].mode()\n    st_dev = data[i].std()\n    skew = data[i].skew()\n    kurt = data[i].kurtosis()\n\n    # calculating points of standard deviation\n    points = mean-st_dev, mean+st_dev\n\n    #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.kdeplot(data[i], shade=True)\n    sns.lineplot(points, [0,0], color = 'black', label = \"std_dev\")\n    sns.scatterplot([mini,maxi], [0,0], color = 'orange', label = \"min\/max\")\n    sns.scatterplot([mean], [0], color = 'red', label = \"mean\")\n    sns.scatterplot([median], [0], color = 'blue', label = \"median\")\n    sns.scatterplot([mode], [0], color = 'green', label = \"mode\")\n    plt.xlabel('{}'.format(i), fontsize = 20)\n    plt.ylabel('density')\n    plt.title('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n                                                                                                   round(kurt,2),\n                                                                                                   round(skew,2),\n                                                                                                   (round(mini,2),round(maxi,2),round(ran,2)),\n                                                                                                   round(mean,2),\n                                                                                                   round(median,2)))\n                                                                                           ","c5f55a49":"UVA_numeric(data,pickup_dropoff_location)","acd12ebf":"# copying pickup_dropoff_location\npdl_data = data[pickup_dropoff_location]\n\n# filtering using loc\npdl_data = pdl_data.loc[(pdl_data.pickup_longitude > -74.2) & (pdl_data.pickup_longitude < -73.7)]\npdl_data = pdl_data.loc[(pdl_data.pickup_latitude > 40.5) & (pdl_data.pickup_latitude < 40.95)]\npdl_data = pdl_data.loc[(pdl_data.dropoff_longitude > -74.2) & (pdl_data.dropoff_longitude < -73.7)]\npdl_data = pdl_data.loc[(pdl_data.dropoff_latitude > 40.5) & (pdl_data.dropoff_latitude < 40.95)]\n\n# checking how many points are removed\nlen(data), len(pdl_data)","ab52601c":"UVA_numeric(pdl_data,pickup_dropoff_location)","72d44252":"UVA_numeric(data,trip_details)","a49306f7":"data.distance[data.distance == 0 ].count()","defa50c7":"# copying trip_details\ntd_data = data[trip_details]\n\n# filtering all trip_details variables using loc\ntd_data = td_data.loc[(td_data.trip_duration < 7200)]\ntd_data = td_data.loc[(td_data.trip_duration_minutes < 120)]\ntd_data = td_data.loc[(td_data.distance < 150)]\ntd_data = td_data.loc[(td_data.speed < 105)]\n\n# checking how many points are removed\nlen(data), len(td_data)","9ce30cbb":"UVA_numeric(td_data,trip_details)","53d1f02d":"UVA_numeric(data,pickup_dropoff_time) ","b6b22c90":"#Taking into consideration the points mentioned about week of year, we shall make a new column for only year and confirm that only the year 2016 is present\ndata['pickup_datetime_year'] = data.pickup_datetime.dt.year\ndata['pickup_datetime_year'].describe()","0291cbb0":"#dropping column pickup_datetime_year\ndata.drop('pickup_datetime_year', axis=1, inplace=True)\ndata.head()","e2abd605":"data.dtypes","fcd09244":"#change the pickup_datetime_woy and dropoff_datetime_woy values of 53 to 1\ndata.loc[(data.pickup_datetime_woy == 53),'pickup_datetime_woy'] = 1\ndata.loc[(data.dropoff_datetime_woy == 53),'dropoff_datetime_woy'] = 1\ndata.head()","c540d1a0":"#confirming that pickup_datetime_woy does not have values of 53 anymore\ndata[data.pickup_datetime_woy == 53]","927944cf":"#confirming that dropoff_datetime_woy does not have values of 53 anymore\ndata[data.dropoff_datetime_woy == 53]","802b62f3":"#Plotting the distributions again to see the effect of replacing incorrect values\nUVA_numeric(data,pickup_dropoff_time) ","abda442b":"data.select_dtypes(exclude=['int64','float64','Int64']).dtypes","6b02818f":"# Custom function for easy visualisation of Categorical Variables\ndef UVA_variable(data, var):\n\n  '''\n  Univariate_Analysis_categorical\n  takes a categorical variable and plots\/prints all the value_counts and a barplot.\n  '''\n  # setting figure_size\n  size = len(var)\n  plt.figure(figsize = (7*size,5), dpi = 100)\n\n  # for every variable\n  for j,i in enumerate(var):\n    norm_count = data[i].value_counts(normalize = True)\n    n_uni = data[i].nunique()\n\n  #Plotting the variable with every information\n    plt.subplot(1,size,j+1)\n    sns.barplot(norm_count, norm_count.index , order = norm_count.index)\n    plt.xlabel('fraction\/percent', fontsize = 20)\n    plt.ylabel('{}'.format(i), fontsize = 20)\n    plt.title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,norm_count))","ea83ee1b":"UVA_variable(data, ['passenger_count'])","e637cff7":"UVA_variable(data, ['vendor_id'])","a36c3ccf":"UVA_variable(data, ['store_and_fwd_flag'])","26e7706f":"data.isna().sum()","038d2bf9":"# custom function for easy outlier analysis\n\ndef UVA_outlier(data, var_group, include_outlier = True):\n  '''\n  Univariate_Analysis_outlier:\n  takes a group of variables (INTEGER and FLOAT) and plot\/print boplot and descriptives\n  Runs a loop: calculate all the descriptives of i(th) variable and plot\/print it \n\n  data : dataframe from which to plot from\\n\n  var_group : {list} type Group of Continuous variables\n  include_outlier : {bool} whether to include outliers or not, default = True\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (10*size,8), dpi = 200)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    quant25 = data[i].quantile(0.25)\n    quant75 = data[i].quantile(0.75)\n    IQR = quant75 - quant25\n    med = data[i].median()\n    whis_low = med-(1.5*IQR)\n    whis_high = med+(1.5*IQR)\n\n    # Calculating Number of Outliers\n    outlier_high = len(data[i][data[i]>whis_high])\n    outlier_low = len(data[i][data[i]<whis_low])\n\n    if include_outlier == True:\n      print(include_outlier)\n      #Plotting the variable with every information\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('With Outliers\\nOutlier (low\/high) = {} \\n'.format((outlier_low,outlier_high)))\n                                                                                                   \n      \n    else:\n      # replacing outliers with max\/min whisker\n      data2 = data[var_group][:]\n      data2[i][data2[i]>whis_high] = whis_high+1\n      data2[i][data2[i]<whis_low] = whis_low-1\n      \n      quant25 = data2[i].quantile(0.25)\n      quant75 = data2[i].quantile(0.75)\n      IQR = quant75 - quant25\n      med = data2[i].median()\n      whis_low = med-(1.5*IQR)\n      whis_high = med+(1.5*IQR)\n      outlier_high = len(data2[i][data2[i]>whis_high])\n      outlier_low = len(data2[i][data2[i]<whis_low])\n    \n      # plotting without outliers\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data2[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n'.format(round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2))\n                                                                                                   ))","ce220b3c":"#changing passenger_count to integer datatype only for this section to work with the function \ndata['passenger_count'] = data['passenger_count'].astype('int64')\nUVA_outlier(data, ['passenger_count'],) ","3c38d704":"UVA_outlier(data, ['passenger_count'], include_outlier=False)","a7ede840":"#revert back to categorical\ndata['passenger_count'] = data['passenger_count'].astype('category')","0a5724b7":"UVA_outlier(data, pickup_dropoff_location,)","3801f108":"UVA_outlier(data, pickup_dropoff_location, include_outlier=False)","37ae1313":"UVA_outlier(data, trip_details,)","8e96a932":"UVA_outlier(data, trip_details, include_outlier=False) ","45642340":"UVA_outlier(data, pickup_dropoff_time,)","98d57409":"UVA_outlier(data, pickup_dropoff_time, include_outlier=False) ","48c3eca3":"# isolating numerical datatypes\nnumerical = data.select_dtypes(include=['int64','float64','Int64'])[:]\nnumerical.dtypes","405da376":"# calculating correlation\ncorrelation = numerical.dropna().corr()\ncorrelation","9a7b6025":"# plotting heatmap using Pearson Coeff, Kendall's Tau, and Spearman Coeff for all numerical variables\nplt.figure(figsize=(36,6), dpi=140)\nfor j,i in enumerate(['pearson','kendall','spearman']):\n  plt.subplot(1,3,j+1)\n  correlation = numerical.dropna().corr(method=i)\n  sns.heatmap(correlation, linewidth = 2)\n  plt.title(i, fontsize=18)","16a5b9d8":"# Grouping variables\npickup_dropoff_location = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']\ntrip_details = ['trip_duration','trip_duration_minutes', 'distance', 'speed']\npickup_dropoff_time = ['pickup_datetime_moy', 'dropoff_datetime_moy', 'pickup_datetime_hour', 'dropoff_datetime_hour', 'pickup_datetime_woy', 'dropoff_datetime_woy', 'pickup_datetime_dow', 'dropoff_datetime_dow', 'pickup_datetime_doy', 'dropoff_datetime_doy']","f329dd0c":"# scatter plot for pickup_dropoff_location variables\nplt.figure(dpi=140)\nsns.pairplot(numerical[pickup_dropoff_location])","a41b4f9a":"#taking log of every value and dividing by 100,000 to negate outliers\nvar = []\nvar.extend(pickup_dropoff_location)\nvar.extend(trip_details)\nvar.extend(pickup_dropoff_time)\nfor column in var:\n  mini=1\n  if numerical[column].min()<0:\n    mini =  abs(numerical[column].min()) + 1\n  \n  numerical[column] = [i+mini for i in numerical[column]]\n  numerical[column] = numerical[column].map(lambda x : np.log(x)\/100000)","a661dbc8":"# scatter plot for pickup_dropoff_location variables\nplt.figure(dpi=140)\nsns.pairplot(numerical[pickup_dropoff_location])","ff0fdc41":"# scatter plot for trip_details variables\nplt.figure(dpi=140)\nsns.pairplot(numerical[trip_details])","607b0eb8":"#if we remember from Univariate Analysis, we found that there were approx. 3000 observations with distance=0. We shall use a scatter plot to analyze the relation between this distance value and trip_duration_minutes\nfiltered_dist = data.loc[(data.distance == 0) & (data.trip_duration_minutes < 120), ['distance','trip_duration_minutes']]\nplt.scatter(filtered_dist.trip_duration_minutes, filtered_dist.distance , s=1, alpha=0.5)\nplt.ylabel('Distance in km')\nplt.xlabel('Trip Duration in Minutes')\nplt.show()","0c6c5b02":"data.distance.mean()","d7f6be39":"#if we also remember from Univariate Analysis, we found that there were approx. 3000 observations with distance=0. We shall use a scatter plot to analyze the relation between this distance value and trip_duration_minutes\nfiltered_dist = data.loc[(data.distance == 0) & (data.trip_duration_minutes < 120), ['distance','trip_duration_minutes']]\nplt.scatter(filtered_dist.trip_duration_minutes, filtered_dist.distance , s=1, alpha=0.5)\nplt.ylabel('Distance in km')\nplt.xlabel('Trip Duration in Minutes')\nplt.show()","85c8ab29":"# scatter plot for pickup_dropoff_time variables\nplt.figure(dpi=140)\nsns.pairplot(numerical[pickup_dropoff_time])","5e690b53":"def TwoSampZ(X1, X2, sigma1, sigma2, N1, N2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sampled Z-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import norm\n  ovr_sigma = sqrt(sigma1**2\/N1 + sigma2**2\/N2)\n  z = (X1 - X2)\/ovr_sigma\n  pval = 2*(1 - norm.cdf(abs(z)))\n  return pval","1384d1d4":"def TwoSampT(X1, X2, sd1, sd2, n1, n2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sample T-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import t as t_dist\n  ovr_sd = sqrt(sd1**2\/n1 + sd2**2\/n2)\n  t = (X1 - X2)\/ovr_sd\n  df = n1+n2-2\n  pval = 2*(1 - t_dist.cdf(abs(t),df))\n  return pval","b6635ac8":"def Bivariate_cont_cat_hypoth1(data, cont, cat):\n  #creating 2 samples, passenger_counts <= 2 (x1) and 2 < passenger_counts < 7 (x2)\n  x1 = data[cont][data[cat].isin([0,1,2])][:]\n  x2 = data[cont][data[cat].isin([3,4,5,6])][:]\n                  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.std()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot(['passenger_counts <= 2','2 < passenger_counts < 7'], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')\n  ","56fe1f34":"Bivariate_cont_cat_hypoth1(data, 'trip_duration_minutes', 'passenger_count') ","ee434af0":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'2'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')\n  ","91fb5e78":"Bivariate_cont_cat(data, 'trip_duration_minutes', 'vendor_id', 1)","54d3caac":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'N'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')","e0c78909":"Bivariate_cont_cat(data, 'trip_duration_minutes', 'store_and_fwd_flag', 'Y')","796e708e":"Bivariate_cont_cat_hypoth1(data, 'distance', 'passenger_count') ","24762de0":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'2'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')","de5aca4c":"Bivariate_cont_cat(data, 'distance', 'vendor_id', 1)","ceaadd5e":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'N'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')","f7748dc9":"Bivariate_cont_cat(data, 'distance', 'store_and_fwd_flag', 'Y')","b458cf87":"data.dtypes[data.dtypes == 'category']","611fa6ba":"def BVA_categorical_plot(data, tar, cat):\n  '''\n  take data and two categorical variables,\n  calculates the chi2 significance between the two variables \n  and prints the result with countplot & CrossTab\n  '''\n  #isolating the variables\n  data = data[[cat,tar]][:]\n\n  #forming a crosstab\n  table = pd.crosstab(data[tar],data[cat],)\n  f_obs = np.array([table.iloc[0][:].values,\n                    table.iloc[1][:].values])\n\n  #performing chi2 test\n  from scipy.stats import chi2_contingency\n  chi, p, dof, expected = chi2_contingency(f_obs)\n  \n  #checking whether results are significant\n  if p<0.05:\n    sig = True\n  else:\n    sig = False\n\n  #plotting grouped plot\n  sns.countplot(x=cat, hue=tar, data=data)\n  plt.title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n\n  #plotting percent stacked bar plot\n  #sns.catplot(ax, kind='stacked')\n  ax1 = data.groupby(cat)[tar].value_counts(normalize=True).unstack()\n  ax1.plot(kind='bar', stacked='True',title=str(ax1))\n  int_level = data[cat].value_counts()","28aab1f6":"# converting passenger_count to integer first, segregating customers into segments, removing passenger_count_group values of 'str'\ndata['passenger_count'] = data['passenger_count'].astype('int64')\nvendor = data[['passenger_count','vendor_id']][:]\nvendor['passenger_count_group'] = 'str'\nvendor['passenger_count_group'][vendor['passenger_count']<=2] = 'low passenger count'\nvendor['passenger_count_group'][(vendor['passenger_count']>2) & (vendor['passenger_count']<7)] = 'high passenger count'\nvendor = vendor[vendor.passenger_count_group != 'str']\n","b3a45687":"BVA_categorical_plot(vendor, 'vendor_id', 'passenger_count_group')","fc7caa1a":"# converting passenger_count to integer first, segregating customers into segments, removing passenger_count_group values of 'str'\ndata['passenger_count'] = data['passenger_count'].astype('int64')\nstore_forward = data[['passenger_count','store_and_fwd_flag']][:]\nstore_forward['passenger_count_group'] = 'str'\nstore_forward['passenger_count_group'][store_forward['passenger_count']<=2] = 'low passenger count'\nstore_forward['passenger_count_group'][(store_forward['passenger_count']>2) & (store_forward['passenger_count']<7)] = 'high passenger count'\nstore_forward = store_forward[store_forward.passenger_count_group != 'str']\n","b3f131d6":"BVA_categorical_plot(store_forward, 'store_and_fwd_flag', 'passenger_count_group')","eb56da56":"BVA_categorical_plot(data, 'vendor_id', 'store_and_fwd_flag')","9f7f68f0":"def Grouped_Box_Plot(data, cont, cat1, cat2):\n    # boxplot\n    sns.boxplot(x=cat1, y=cont, hue=cat2, data=data, orient='v')\n    plt.title('Boxplot')","dbea840f":"data['trip_duration_mins_log'] = np.log(data['trip_duration_minutes'].astype('float'))\nGrouped_Box_Plot(data,'trip_duration_mins_log', 'passenger_count', 'vendor_id')","80f9fe5e":"Grouped_Box_Plot(data,'trip_duration_mins_log', 'store_and_fwd_flag', 'vendor_id')","5e3ca9cd":"Grouped_Box_Plot(data,'trip_duration_mins_log', 'passenger_count', 'store_and_fwd_flag')","5185045d":"data.head()","d518e315":"import folium\ndef show_fmaps(data, path=1):\n    \"\"\"function to generate map and add the pick up and drop coordinates\n    1. Path = 1 : Join pickup (blue) and drop(red) using a straight line\n    \"\"\"\n    map_1 = folium.Map(location=[40.8, -74.2], zoom_start=9,tiles='Stamen Toner') # manually added centre\n    data.sample(frac=1)\n    data_reduced = data.iloc[1:2000]\n    for i in range(data_reduced.shape[0]):\n        pick_long = data.loc[data.index ==i]['pickup_longitude'].values[0]\n        pick_lat = data.loc[data.index ==i]['pickup_latitude'].values[0]\n        dest_long = data.loc[data.index ==i]['dropoff_longitude'].values[0]\n        dest_lat = data.loc[data.index ==i]['dropoff_latitude'].values[0]\n        folium.Marker([pick_lat, pick_long], icon=folium.Icon(color='green',icon='play')).add_to(map_1)\n        folium.Marker([dest_lat, dest_long], icon=folium.Icon(color='red',icon='stop')).add_to(map_1)\n    return map_1","e4aacf2c":"osm = show_fmaps(data, path=1)\nosm","f858bb3a":"#make a new copy of our data\ndata_cleaned = data.copy()\ndata_cleaned.head()","765c006d":"#we shall drop those rows that have passenger_count values of 0,7, and 9. We first change datatype to integer for convenience and then convert it back to category after removal\ndata_cleaned['passenger_count'] = data_cleaned['passenger_count'].astype('int64')\ndata_cleaned=data_cleaned[data_cleaned.passenger_count<=6]\ndata_cleaned=data_cleaned[data_cleaned.passenger_count!=0]\ndata_cleaned['passenger_count'] = data_cleaned['passenger_count'].astype('category')\ndata_cleaned['passenger_count'].value_counts()","d868ad96":"data_cleaned.shape","8d47c83c":"#we shall drop those rows that have passenger_count values of 0,7, and 9.\ndata_cleaned=data_cleaned[data_cleaned.pickup_latitude>=40.6]\ndata_cleaned=data_cleaned[data_cleaned.pickup_latitude<=40.95]\ndata_cleaned=data_cleaned[data_cleaned.dropoff_latitude>=40.6]\ndata_cleaned=data_cleaned[data_cleaned.dropoff_latitude<=40.95]\ndata_cleaned=data_cleaned[data_cleaned.pickup_longitude>=-74.2]\ndata_cleaned=data_cleaned[data_cleaned.pickup_longitude<=-73.70]\ndata_cleaned=data_cleaned[data_cleaned.dropoff_longitude>=-74.2]\ndata_cleaned=data_cleaned[data_cleaned.dropoff_longitude<=-73.70]\ndata_cleaned.shape","c6c87e4e":"#Looking at the distributions of the above variables\nUVA_numeric(data_cleaned,pickup_dropoff_location)","3fc0e608":"data_cleaned.distance[data_cleaned.distance == 0].count()","ed5b1fe9":"data_cleaned['distance'].loc[data_cleaned['distance']==0] = data.distance.mean()","31471421":"data_cleaned['distance'].loc[data_cleaned['distance']==0].count()","77676bf4":"data_cleaned.shape","c57367c7":"#checking how many outlier values will be removed for trip_duration > 3600\ndata_cleaned.trip_duration[data_cleaned.trip_duration > 3600 ].count()","b2c296f8":"#removing the outliers and cleaning the dataset\ndata_cleaned=data_cleaned[data_cleaned.trip_duration<=3600]","b8c06bb3":"#removing trip_duration_mins_log feature as it was used only for data visualization and will not be needed anymore\ndata_cleaned.drop([\"trip_duration_mins_log\"], axis = 1, inplace = True)","601103eb":"UVA_numeric(data_cleaned,trip_details)","baa2431f":"data_cleaned.trip_duration","1f87e73e":"data_cleaned.shape","4a3291eb":"data_cleaned.speed.describe()","05401fa2":"#next we shall get rid of outliers in the speed column, i.e speed > 55 and replace speed values of 0 with mean value of 14.39 km\/hr\ndata_cleaned.speed[data_cleaned.speed > 55].count()","6ab4ebd7":"data_cleaned=data_cleaned[data_cleaned.speed<=55]\ndata_cleaned['speed'].loc[data_cleaned['speed']==0] = data.speed.mean()","9e26c55e":"UVA_numeric(data_cleaned,trip_details)","75c3ce93":"data_cleaned['speed'].loc[data_cleaned['speed']==0].count()","de7383f7":"(len(data)), (len(data_cleaned))","0b24ba10":"data_cleaned=data_cleaned[data_cleaned.distance<=30]","a9da2fb4":"UVA_numeric(data_cleaned,trip_details)","9e7a3447":"#removing trip_duration_minutes feature too as it was used only for data visualization and will not be needed anymore\ndata_cleaned.drop([\"trip_duration_minutes\"], axis = 1, inplace = True)","d4689084":"(len(data)), (len(data_cleaned))","66b1c917":"data_cleaned.describe()","d90a813e":"data_cleaned.dtypes","c4fcf453":"data_cleaned.shape","945cd0a1":"From our earlier categorical-categorical bivariate analysis we saw that Vendor 2 taxis did not have any values of store_and_fwd_flag = 'Y' or, in words, that Vendor 2 taxis did not store and forward trips, because the vehicle did not have a connection to the server. ","eb963bb3":"*   Looking at the above distributions, we can say that we did a decent job on removing heavy outliers and just managed to remove a mere 7,643 values from 729,322 values. If we remember from our previous analysis of latitudes and longitudes, we put a limit to make sure distances faired well between the 5 boroughs of NYC. However, now looking at the above distribution as well as kurtosis and skewness values of distance, we do feel tempted to remove a few more outliers to make our dataset consistent. Hence, we can move ahead and just remove some more outliers by keeping a maximum limit to distance of 30 km. We shall make no more changes after this, as it would result in losing key insights from our model eventually.","5107b94c":"**Final Summary of pickup_dropoff_location:**\n\n*    From the above KDE plots, we can conclude that the removal of outlier values from both latitude and longitudinal data did lower skewness and kurtosis by a big margin. Moreover, in the process we lost few amount of observations (729322-728194 = 1128), which would not hinder further EDA analysis, but provide a better picture.\n\n*    Therefore, we can put the following limits on latitudinal and longitudinal data:\n     *    Latitudinal data range should be between 40.6 to 40.95\n     *    Longitude data range be between -74.2 to -73.70\n\n**Things to Investigate Further in EDA:**\n*    Removal of the extreme values and Outliers in the dataset by following the limits we have set\n*    Trip durations relation with outlier values of all features associated with the pickup_dropoff_location group","79905000":"*    **Variables like 'id', 'pickup_datetime', 'dropoff_datetime', and 'store_and_fwd_flag' are of type object**. This means that **Pandas was not able to recognise the datatype** of these four variables.","2e4605f8":"Summary:\n\n*    **vendor_id** is a unique, nominal code indicating the provider\/business associated with the trip record. Note that there are only ***2 different vendors\/businesses providing the taxi trips in our dataset***. Therefore, it needs to be **converted to a category**.\n\n*    **passenger_count** represents the number of passengers in the vehicle (driver entered value). **However, it does not take on continuous values and we shall consider it as a categorical variable.**.\n\n*    **trip_duration** is duration of the trip in seconds and we are **okay with it as Integer**.","07f36220":"From our previous Univariate as well as Bivariate analysis, we uncovered a few interesting individual as well correlated findings for these variables. We put forth a few assumptions that we can put the following limits on trip_details features:\n*    **trip_duration data range can be reduced from 1 second to 3600 seconds.**\n*    **distance data range could be reduced from 1 km to 40 km and speed data range can be reduced from 1 km\/hr to 55 km\/hr.** \n*    **These restrictions or removal of outliers in this method basically signifies that we shall be concentrating mainly on those trips within the 5 boroughs of NYC, as the data suggests, including some leeway for traffic.**\n\nWe see below that there are approx. 2844 observations now, after removing some rows before, with distance = 0 and deleting those observations would mean losing out on information that might be useful. **From the scatterplot in the Bivariate Analysis section, we concluded that it would be better to replace these distance values with their mean value (not the mean from data_cleaned but from data) rather than deleting them.**","cd0f58e5":"### pickup_dropoff_time","7c839e93":"### Float Data Type","fc4cf40a":"*    ***These look alright as is and should remain as float datatype***","b4c4c5a3":"**Inferences**\n1.    This validates our finding that there exist many outliers in our pickup_dropoff_time data. Moreover, there is no apparent correlation present between the pickup_dropoff_time variables.","10a0652d":"**Summary**\n\n* store_and_fwd_flag:\n  *  Almost a full majority of trip records were not held in-vehicle memory before sending to the vendor because the vehicle did not have a connection to the server.\n\n**Things to investigate further down:**\n* Relation between store_and_fwd_flag or flag type with distance travelled, trip duration, variables in pickup_time group, and passenger counts.","0d49307e":"# Model Building","73a21484":"*   Now we are done breaking down the pick_up datetime variable into granular forms, as seen above, which will **help us better analyze information extracted from the pickup time and trip duration.** We are also done with the Variable identification and typecasting process and will now start the Univariate Analysis portion of the EDA, followed by Bivariate Analysis, and, lastly, Multivariate Analysis.","957d742f":"**Result**: Number of passengers in a taxi on a certain trip has a significant effect on which type of vendor they will ride with. Hence, we can reject the null hypothesis that taxis with higher passenger_count, greater than 2 but less than 7 passengers, are less likely to belong to Vendor 2.","cea2a64a":"### Getting rid of outlier values of passenger_count","9f61f158":"### **6.  Do taxis that store and forward trips, because the vehicle did not have a connection to the server, travel greater distances?**","358f5570":"**Summary of passenger_count:**\n\n*    **passenger_count**:\n    *    Median Number of Passengers in a Taxi = 1\n    *    **Most taxis, roughly 85%, carry 1-2 passengers**\n    *    **skewness must be positive**, as passenger_count is **significantly biased towards lesser number of passengers** and this seems logical too\n    *    **kurtosis must be high too**; The distribution, thus, is leptokurtic. In essence, extreme values and Outliers are very likely to be present in passenger_count, as seen by values greater than 6. \n\n\n**Things to Investigate Further down the road:**\n*    Removal of the extreme values and Outliers, as can be seen in the range of the distribution (0 minimum - 9 maximum). passenger_count values that are 0,7, and 9 can be dropped because their counts compared to the rest in the dataset is very trivial.\n*    As per the NYC.gov website, the maximum amount of passengers allowed in a yellow taxicab by law is four in a four passenger taxicab or five passengers in a five passenger taxicab, except that an additional passenger must be accepted if such a passenger is under the age of seven and is held on the lap of an adult passenger seated in the rear. \n*   Therefore, we can assume that **6 passengers, at maximum, can ride in a NYC taxi i.e. 5 adults + 1 minor.**\n*   ***Keeping the above point in mind, we can move ahead to remove these Outliers of passenger_count and visualize these plots again to gain a better understanding of the distribution of passenger_count. This will be seen in the section named Univariate Analyis: Outliers***","99d30577":"### Outlier treatment for distance, speed, and trip_duration","9555e1e8":"## Univariate Analysis: Outliers ","420b0889":"**Summary of trip_details:**\n\n*    **trip_duration_minutes**:\n    *    trip_duration uses the seconds unit to denote the duration and, hence, for convenience we shall be analyzing trip_duration_minutes\n    *    Median = 11.05 minutes\n    *    skewness for both trip_duration and trip_duration_minutes are bound to be the same and are **significantly right or positively skewed** \n    *    kurtosis value too is bound to be the same for both and is 87142.46. As seen by the values, the distributions are highly leptokurtic. In essence, extreme values and Outliers are very likely to be present in both features. For example, we see values greater than 5000 minutes or, in other words, trips that went on for more than 3 days.\n    *    An important point to keep in mind is that **NYC is renowned for traffic and congestion, which would add a hefty amount to trip_duration even for short distances**. Hence, when considering dealing with outliers, we shall be more careful of considering this factor and be a bit more lenient in removing these outliers.\n    *    Another key point to note is that there exist several trips that have durations of 0 seconds or 0 minutes \n    \n    \n*    **distance (Note: represented in km)**:\n    *    Median = 2.1 km\n    *    An interesting find is that the **minimum value associated with distance is 0 and there are 2901 observations with distance = 0.** This could denote the following: drop off location is same as the pickup location, customer could've cancelled the trip right after booking\/confirming it or driver could've also cancelled the trip after confirming it, **connectivity or software issues with held-in vehicle memory (this can be analyzed further in the Bivariate Analysis section with the feature store_and_fwd_flag). This finding will also be analyzed further in relation to the trip duration features to extract more convincing information.**\n    *    **skewness = 40.98**  : **significantly right or positively skewed**, just like both trip duration features as expected.\n    *    **kurtosis = 9795.09**; The distribution is highly leptokurtic. In essence, extreme values and Outliers are very likely to be present in both features. \n    *    According to internet sources, most NYC taxi cabs do not travel outside city limits; however, **some cabs do occasionally take riders to New Jersey and also have the right to refuse for doing so.** These rides from NYC to New Jersey involve riders negotiating prices with the cab drivers and it often ends up being very expensive, as the driver has to return to NYC without a fare and, hence, riders have to pay a two-way fare. \n    *    **The distance from NYC to New Jersey is about 74 miles or 119 kilometres, which suprisingly translates to about a difference of 1 latitude degree!** Therefore, it can be safe to conclude that trips greater than 120 kilometres can be considered as outliers. Moreover, it's illegal for taxi drivers to refuse a fare in any of NYC's five boroughs\n\n\n*    **speed (Note: represented in km\/hr)**:\n    *    Median = 12.8 km\/hr\n    *    **skewness = 194.01**  : **significantly right or positively skewed**, just like both trip duration features as expected.\n    *    **kurtosis = 76874.41**; The distribution is highly leptokurtic. In essence, extreme values and Outliers are very likely to be present in both features. For example, we see speed values of much more than 200km\/hr in the dataset and these values\n    *    According to the NYC.gov website, **the speed limit in NYC (citywide) is 25 miles per hour (mph) or 40 km\/hr, unless otherwise posted, and the speed limit on New York State highways (statewide) is 55 mph or 88.5 km\/hr, unless otherwise posted.** However, the highest posted speed limit in New York is 65 mph or 105 km\/hr, found only on limited-access freeways. Therefore, we can safely conclude that all speeds greater than 105 km\/hr be treated as outliers. \n\n**Things to Investigate Further down the road:**\n*    Removal of the extreme values and Outliers, as can be seen in the skewness and kurtosis values \n*   ***Keeping the above summary details in mind, we can move ahead to remove these Outliers in the trip_details group and visualize these plots again to gain a better understanding of the distributions.***","1ac38633":"## NYC Taxi Trip Duration","89796c82":"**List of Hypotheses and investigation to perform under this combination.**\n\n1.  Are taxis with higher passenger_counts, greater than 2 but less than 7 passengers, more likely to have higher trip durations?\n2.  Is Vendor 1 less likely to deal with higher trip durations than Vendor 2 does?\n3.  Do taxis that store and forward trips, because the vehicle did not have a connection to the server, experience higher trip duration?\n4. Do taxis with higher passenger_counts, greater than 2 but less than 7 passengers, travel greater distances?\n5. Does Vendor 2 deal with higher distances to travel than Vendor 1 does?\n6. Do taxis that store and forward trips, because the vehicle did not have a connection to the server, travel greater distances?","63c815d6":"### pickup_dropoff_location","5faf24c0":"**Summary**\n\n* vendor_id:\n  *  About 53.5% of vendors belong to vendor 2 and the rest to vendor 1.\n\n**Things to investigate further down:**\n* Relation between vendor_id with distance travelled, trip duration, variables in pickup_time group, and passenger counts for taxis of both vendors","19b43fa5":"### **4.  Do taxis with higher passenger_counts, greater than 2 but less than 7 passengers, travel greater distances?**","2a8f8135":"**From the scatterplot above, it would be better to replace these distance values with their mean value rather than deleting them. We shall pursue this in the data preprocessing section.**","b6870cad":"*    ***We shall now extract important time-based features for better EDA experience***","7e1e8ab7":"### vendor_id, store_and_fwd_flag with Trip Duration","80a5ed21":"### Problem Statement: What is the duration of each trip at the point it starts ","50d9f91e":"We are using one continuous variable that is trip_duration and two categorical variables, vendor_id and passenger_count to derive insights related to trip_dur ation. Note carefully that in order to obtain clear boxplots, we had to take log values of our featured column trip_duration_minutes. This is because our target variable, trip_duration, has heavy outliers that would make it very difficult to analyze the boxplots, but changing its unit to minutes and then taking its log gives us a clearer, detailed picture as shown below.","a661d7c7":"**Inferences**\n1.    This validates the high correlation between distance and trip duration variables. We also observe positive correlations between speed and other variables of the trip_details group.\n2.    This high correlation can be used for feature engineering during later stages.","29a9f061":"**Therefore, max value proves that only the year 2016 is present and we can go ahead to change the week of year values of 53 to 1. We also shall not be needing this column, so it's better we delete it now.**","95fb9928":"**Inferences**\n\n1.    Taxis that store and forward trips, because the vehicle did not have a connection to the server, did experience higher trip duration, as seen in the barplot, and p-value results are significantly different too, as p-value < 0.05. Results of the pivot table for mean mean_trip_duration for taxis carrying more than 2 but less than 7 passengers are also higher.\n2.    Although the boxplot does not represent the above relation very clearly, due to the presence of high outliers in the taxis that did NOT store and forward trips, if we do get rid of those outliers and zoom in on the boxplots, we would be able to see the relation clearly. \n\n**Result**\n\nWe can confidently reject the null hypothesis that taxis that store and forward trips, because the vehicle did not have a connection to the server, experience lower trip duration.","767c049d":" ### trip_details","2b604fec":"**Inferences**\n\n1.    Although taxis with higher passenger_counts, greater than 2 but less than 7 passengers, do travel greater distances as seen in the barplot, the p-value results are insignificant, as p-value > 0.05. \n2.    Although the boxplot represents that there are significant outliers for passenger_count 1 and 2, the distances travelled by those taxis are still a little less than their counterpart. \n\n**Result**\n\nWe cannot reject the null hypothesis that taxis with higher passenger_counts, greater than 2 but less than 7 passengers, travel less distances.","bc291ada":"**Therefore, as can be seen in the code above, we have successfully replaced distance=0 values with a mean value of approx. 3.1 and, simultaneously, values of speed would change too respectively.**  We shall now move ahead to remove outlier values for speed and trip_duration, which would simultaneously change trip_duration_minutes values. As discussed in the previous sections and above, **we shall reduce the trip_duration data range from 1 second to 3600 seconds. We shall also change speed values of 0 km\/hr to their mean value in the original dataset and keep only those values < 55 km\/hr or the citywide limit.**","fcf2e651":"### store_and_fwd_flag","8a057387":"### **1.  Are taxis with higher passenger_counts, greater than 2 but less than 7 passengers, more likely to have higher trip durations?**","f2463014":"**Final Summary of trip_details:**\n\n*    From the above KDE plots, we can conclude that the removal of certain outlier values, as discussed above, from trip_details group did lower skewness and kurtosis by a big margin. Moreover, in the process we lost few amount of observations (729322-728226 = 1096), which would not hinder further EDA analysis, but provide a better picture.\n\n*    However, we should note from all these KDE plots above that **the distributions are still right or positively skewed as well as leptokurtic. The removal of outliers in the original trip_details data, with respect to restrictions set by the NYC government, did still result in few outliers in the new KDE plots**. Therefore, this signifies that we can **better our performance on the EDA process by being stricter with outlier removal, in terms of removing those observations of interstate travel (NYC to NJ), and still not lose key or essential insights that can be generated**. \n\n*    Therefore, we can put the following limits on trip_details features:\n     *    **trip_duration_minutes data range can be reduced from 1 minute to 60 minutes and trip_duration data range can be reduced from 1 second (impractical but we'll use it) to 3600 seconds.**\n     *    **distance data range could be reduced from 1 km to 40 km and speed data range can be reduced from 1 km\/hr (impractical but we'll use it) to 55 km\/hr.** \n     *    **These restrictions or removal of outliers in this method basically signifies that we shall be concentrating mainly on those trips within the 5 boroughs of NYC, as the data suggests, including some leeway for traffic.**\n\n**Things to Investigate Further in EDA:**\n*    Removal of the extreme values and Outliers in the dataset by following the limits we have set\n*    Trip durations relation with outlier values of all features associated with the pickup_dropoff_location group","1dd6605a":"**The scatter plot is is not meaningful due to the presence of outliers**","876c086d":"# Multivariate Analysis","c1ad999f":"*    As can be seen above, we have converted 'id' and 'store_and_fwd_flag' to **category**. Due to the 'id' variable's format, we shall have to modify all of its values by removing the redundant 'id' part present in all values. We will also keep the 'id' variable as 'category', **since 'id' represents a unique identifier for each trip and most probably won't be used for analysis**. We change both 'pickup_datetime' and 'dropoff_datetime' to **datetime datatypes**. We will further investigate the datatime datatypes and extract more information from them.","b3158b46":"## Univariate: Missing Values","9fab824f":"## Bivariate Analysis: Continuous-Categorical variables\n","6656ef69":"We are using a grouped boxplot to comply with the objective of determining the trip_duration using various categorical features. We'll use vendor_id, passenger_count, and store_and_fwd_flag categorical features and derive insights from the boxplots.","e06ee1df":"### Object Data Type","b6a8500d":"# Exploratory Data Analysis","d2a23df1":"### **3.  Do taxis that store and forward trips, because the vehicle did not have a connection to the server, experience higher trip duration?**","7ea54dc4":"*    ***Although we already did convert both variables to datetime datatypes, we dont have to specify a format by using directives as it is already formatted correctly and we shall be using the 24 hour clock***","bc87adda":"### pickup_dropoff_time","e572217f":"### Scatterplot\n","8b89c185":"**Inferences**\n\n1.    Taxis that store and forward trips, because the vehicle did not have a connection to the server, did significantly travel higher distances, as seen in the barplot, because p-value < 0.05. Results of the pivot table for  mean distance of taxis that store and forward trips are also higher.\n2.    Although the boxplot does not represent the above relation very clearly, due to the presence of high outliers in the taxis that did NOT store and forward trips, if we do get rid of those outliers and zoom in on the boxplots, we would be able to see the relation clearly. \n\n**Result**\n\nWe can confidently reject the null hypothesis that taxis that store and forward trips, because the vehicle did not have a connection to the server, did not travel greater distances.","34dd9b07":"This boxplot supports our earlier bivariate analysis that taxis that store and forward trips, because the vehicle did not have a connection to the server, did experience higher trip duration and p-value results are significantly different too, as p-value < 0.05. Moreover, this relation is present for all non-outlier passenger count values (1-6) as seen in the boxplot and it should be noted that passenger_count value of 6 did not have any trips that did store and forward trips.","b81778d7":"### passenger_count, store_and_fwd_flag with Trip Duration","afc5a776":"**Inferences**\n\n1.    Taxis carrying more than 2 but less than 7 passengers (to remove outlier passenger of 7 and 9) had higher trip durations, as seen in the barplot, and p-value results are significantly different too, as p-value < 0.05. Results of the pivot table for mean mean_trip_duration for taxis carrying more than 2 but less than 7 passengers are also higher.\n2.    Boxplot shows a similar distribution, although with high outliers for vendor 1, and this further reinforces the above relation.\n\n**Result**\n\nWe can confidently reject the null hypothesis that Vendor 1 is more likely to deal with higher trip durations than Vendor 2 does.","6380afc1":"### vendor_id, passenger_count with Trip Duration","511b4454":"There are a lot of variables visible at once, so let's narrow this down by looking **at one datatype at once**. We will start with **int64** data type.\n","28ba399a":"### **2.  Is Vendor 1 less likely to deal with higher trip durations than Vendor 2 does?**","ec7fd451":"# Pickup, Dropoff Visualization on NYC Map using Folium","a6baf5dc":"### datetime Data Type","bdccb60d":"*   **This brings us to the end of our data preprocessing section and we can now focus on model building with our cleaned data!**","78f33bae":"### **5.  Does Vendor 2 deal with higher distances to travel than Vendor 1 does?**","b72d4926":"### passenger_count","5b2a77bc":"### 2. Are taxis with higher passenger_counts, greater than 2 but less than 7 passengers, more likely to store and forward trips, because the vehicle did not have a connection to the server?","6db9655e":"## Bivariate : Categorical-Categorical","acc326ce":"**Inferences**\n1.    After negating a lot of outliers, a higher positive correlation between pickup_latitude and dropoff_latitude is observed.\n2.    A correlation was still not observed between pickup_longitude and dropoff_longitude.","213058ee":"#### List of Hypotheses to check under this combination\n1.   Are taxis with higher passenger_counts, greater than 2 but less than 7 passengers, more likely to belong to Vendor 2?\n2.   Are taxis with higher passenger_counts, greater than 2 but less than 7 passengers, more likely to store and forward trips, because the vehicle did not have a connection to the server?\n3.   Does Vendor 2 deal with trips that are more likely to store and forward trips, because the vehicle did not have a connection to the server?","82d11435":"### pickup_dropoff_location","641f9570":"*    We should recall that passenger_count values of 0,7, and 9 will be dropped in the data preprocessing section coming up soon and, hence, we can ignore those values for analysis now. \n*    In general, we see a similar distribution of trip_duration among the rest of the non-outlier passenger_counts. If we recall from our earlier bivariate continuous-categorical analysis, we concluded that taxis with higher passenger_counts, greater than 2 but less than 7 passengers, are more likely to have higher trip durations. Moreover, we also concluded that Vendor 1 is less likely to deal with higher trip durations than Vendor 2 does and that their differences were significant. The latter hypothesis may not seem so convincing by just looking at the boxplots, but if we look closely at the whiskers and outliers, we see that trip duration values of Vendor 2 have a lot more outliers than those of Vendor 1, which must be reinforcing that relation.","ddc2f698":"**The useful variables here are passenger_count, vendor_id and store_and_fwd_flag. Since they are singular and belong to different groups, we will not group them and use them as is, unlike the approach we applied for Numerical Variables.**","f8e7f10b":"## Univariate Analysis : Categorical Variables","d5cefc4e":"* The Spearman correlation seems to have higher correlation values in same areas of the heatmap where they are less in the Pearson and Kendall correlations. \n*  Too many variables with insignificant correlation.\n*  Major correlation lies between distance and trip duration variables, expectedly. **Hence, with these results, it would be more interesting to analyze correlations of numerical with categorical data.**","0db24ed9":"**Result**: Number of passengers in a taxi on a certain trip has a significant effect on whether the trip record was held in-vehicle memory before sending to the vendor. Hence, we cannot reject the null hypothesis that taxis with higher passenger_count, greater than 2 but less than 7 passengers, are less likely to store and forward trips, because the vehicle did not have a connection to the server","8b8295be":"## Bivariate Analysis : Numerical-Numerical","3441990b":"### Integer Data Type","32aa169b":"### passenger_count","9b61c012":"**Summary of pickup_time:**\n\n*    **pickup_datetime_moy and dropoff_datetime_moy**:\n    *     Our dataset contains only data for the first 6 months of the year and from the distribution seen, most of the months share almost the same number of trips. **Months 1 and 2 or January and February respectively saw the least number of trips, as expected, because it is the coldest month in NYC. Spring Season or Months 3-5 (March-May) saw the highest number of trips reported, as expected.**\n    \n    \n*    **pickup_datetime_hour and dropoff_datetime_hour**:\n    *    The lowest number of taxi trips, overall, occur between hours 0-5 or 12am to 5am. After 5am, traffic keeps increasing till around 8am\/9am, mostly owing to the fact that people are travelling to work\/office or school, and then stays the same at that level until about 5pm\/6pm. Then rush hour or peak traffic is observed from 6pm onwards until 10pm, as people are leaving from work\/office to go home. This type of distribution is expectedly typical in most metropolitan cities too.\n    \n\n*    **pickup_datetime_woy and dropoff_datetime_woy**:\n    *    An important fact to keep in mind is that there are approx. 52 weeks in a year. We observe a steady distribution across all the weeks, from week 1 to week 27 (up until July begins). Also, our data only includes data for the first 6 months (therefore, not including July). However, we see another peak at the 53rd week of the year, which seems like those values corresponding to week 53 are outliers. Remember, we said that there are approx. 52 weeks in a year, so how can we get a value of 53? Does this imply the beginning of a new year, 2017? It cannot since we only have vlaues from the year 2016. We shall investigate this abnormality in the data below!\n    \n    \n*    **pickup_datetime_dow and dropoff_datetime_dow**:\n    *    Again, we see a pretty consistent distribution of the number of trips across the different days of the week, with week 4 or Friday having the greatest amount of trips.\n    \n    \n*    **pickup_datetime_doy and dropoff_datetime_doy**:\n    *    Another important relation to notice is that day of year and week of year should follow similar distributions and, hence, validate each other. Here, the day of year distribution seems alright without any apparent abnormalities, unlike week of year. Therefore, this signifies that we will have to explore week of year more closely, as mentioned above. \n\n**Things to Investigate Further down the road:**\n*    Week of year abnormality checking seen below","46ed646f":"## Univariate Analysis: Numerical Variables","36772496":"### 3. Does Vendor 2 deal with trips that are more likely to store and forward trips, because the vehicle did not have a connection to the server?","18e38178":"## Box Plot","7a78d7dc":"### Getting rid of outlier values in all variables belonging to the pickup_dropoff_location group","9ac6dc0c":"## Variable Identification and Typecasting","525dc32f":"### trip_details","e2b4c8bb":"# Data Preprocessing for Model Building","642dd5db":"### vendor_id","b42b26db":"**Summary of pickup_dropoff_location:**\n\n*    **pickup_longitude and dropoff_longitude**:\n    *    Median = -73.98\n    *    **Both are centered around -74 to -73**\n    *    **-444.22 <= skewness <= -449.89**  : both are **significantly left or negatively skewed** \n    *    **306781 <= kurtosis <= 309925.36**; As seen by the values, the distributions are highly leptokurtic. In essence, extreme values and Outliers are very likely to be present in both features.\n\n*    **pickup_latitude and dropoff_latitude**:\n    *    Median = 40.75\n    *    **Both are centered around 40.5 to 41.5**\n    *    **skewness**  : both have completely opposite skewness, with pickup_latitude having a right or positive skew and dropoff_latitude with a left or negative skew. This is because of very distant pickup and dropoff locations, which lead to extreme values for trip duration. Both are **significantly skewed too**.\n    *    **19348.41 <= kurtosis <= 5639.24**; As seen by the values, the distributions are highly leptokurtic. In essence, extreme values and Outliers are very likely to be present in both features.\n\n**Things to Investigate Further down the road:**\n*    Removal of the extreme values and Outliers, as can be seen in the skewness and kurtosis values \n*    For latitude values, **each degree of latitude is approximately 69 miles or 111 kilometers apart. Keeping this fact in mind, we are confident that many outliers exist in this category as the maximum pickup_latitude value is 51.88 and the maximum dropoff_latitude value is 43.92.** \n*   Therefore, a difference of about 8 latitudes between pickup and dropoff seems abnormal and, hence, we shall have to remove these kind of outliers.\n*   Because we are investigating NYC taxi trips, **most of the trips are located in the 5 Boroughs of NYC: The Bronx (40.8448 N, 73.8648 W), Queens (40.7282 N, 73.7949 W), Staten Island (40.5795 N, 74.1502 W), Manhattan (40.7831 N, 73.9712 W), Brooklyn (40.6782 N, 73.9442 W). Therefore, we can remove outliers keeping these latitude and longitude values in mind.**\n*   ***Keeping the above point in mind, we can move ahead to remove these Outliers in the pickup_dropoff_location group and visualize these plots again to gain a better understanding of the distributions.***","e6b24ca3":"**Inferences**\n\n1.    Taxis carrying more than 2 but less than 7 passengers (to remove outlier passenger of 7 and 9) had higher trip durations, as seen in the barplot, and p-value results are significantly different too, as p-value < 0.05. Results of the pivot table for mean mean_trip_duration for taxis carrying more than 2 but less than 7 passengers are also higher.\n2.    Although the boxplot does not represent the above relation very clearly, due to the presence of high outliers, if we do get rid of those outliers and zoom in on the boxplots, we would be able to see the relation clearly.\n\n**Result**\n\nWe can confidently reject the null hypothesis that taxis with higher passenger_counts, greater than 2 passengers but less than 7 passengers, are less likely to have higher trip durations.","59ee506c":"**Inferences**\n\n1.    Although Vendor 2 deals with higher distances to travel than Vendor 1 does as seen in the barplot and mean distance values, the p-value results are insignificant, as p-value > 0.05. \n2.    The boxplot represents that there are significant outliers for vendor 1, but lesser for vendor 2\n\n**Result**\n\nWe cannot reject the null hypothesis that Vendor 2 deals with lower distances, on average, to travel than Vendor 1 does.","6da13eef":"As discussed previously in the Univariate Analysis for Numerical Variables section, we concluded that we can put the following limits on latitudinal and longitudinal data, including both pickup and dropoff:\n*    Latitudinal data range should be between 40.6 to 40.95\n*    Longitude data range be between -74.2 to -73.70","091b8fb2":"### Recall that we did not have any missing values in our dataset, so we can jump straight to outlier removal","eed5568e":"### 1.  Are taxis with higher passenger_count, greater than 2 but less than 7 passengers, more likely to belong to  Vendor 2?\n"}}