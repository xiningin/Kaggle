{"cell_type":{"51e9eab0":"code","7ca2ffaf":"code","3fe99800":"code","141bc765":"code","2ac5bdde":"code","1546c9c3":"code","775ae794":"code","db6410d7":"code","6e633f5d":"code","0a5bcb44":"code","dfeca6dc":"code","94fbba7a":"code","d0164453":"code","93d1eb70":"code","51a0c641":"code","f87bc5d4":"code","4f51b0a5":"code","07d521bf":"code","bfc85e14":"code","01ea1371":"code","34fa3a81":"code","a2e68e61":"code","1bdfd5bb":"code","5a035067":"code","114dfc32":"code","ab327a11":"code","0c209e09":"code","42aeca33":"code","19f723c1":"code","208b8cf8":"code","e695fb6f":"code","05f9c92e":"code","a12ca032":"code","b668b390":"code","6a192e93":"code","cb6d19d7":"code","972fef5f":"code","e78b68fe":"code","015ee0d1":"code","291df724":"code","54e358d2":"code","7847d570":"code","3f1cf6e5":"code","5e69ec36":"code","45a3489d":"code","808b3e5d":"code","eef56a61":"code","36a33b09":"code","142cbb46":"code","a4aa06e4":"code","f9e1e4d7":"code","38d12a8f":"code","cfae2671":"code","e85f9979":"code","2c1695f1":"code","a1a6addc":"code","5d83a583":"code","9f432cb7":"code","de18a5fc":"code","f2f719dd":"code","1e1f8ea3":"code","3b2f4e53":"code","e25168b5":"code","ae2a5b46":"code","1ccbde69":"code","eaff16fb":"code","3e67a60f":"code","e62f23d3":"code","7debe3dd":"code","d0deeb95":"code","a30ce4b9":"code","83565149":"code","42c152a1":"code","211d92b9":"code","9838b96a":"code","67fe0672":"code","08cb6ae3":"code","a5bef899":"code","f72426e3":"code","883b4a63":"code","1647adfe":"code","328beff5":"code","c70723f2":"code","31b1f3f3":"code","99d59b5a":"code","2bc08185":"code","cc3e87ab":"code","e60d82c9":"code","80a81a5a":"code","07164262":"code","ba2cff05":"code","bb858971":"code","b7df855e":"markdown","ac1c8e74":"markdown","4ddea153":"markdown","4037387f":"markdown","3df85330":"markdown","6736588f":"markdown","12f97dd7":"markdown","2bd30a42":"markdown","19401b1f":"markdown","b5336a67":"markdown","e6c62ff1":"markdown","c7cd59e7":"markdown","b4e1f0ba":"markdown","8031024a":"markdown","7e14b8e9":"markdown","381a0098":"markdown","1a30d216":"markdown","71b1ad27":"markdown","a4e19ce2":"markdown","98d5df57":"markdown","b2934de1":"markdown","756c1a8d":"markdown","d6158eda":"markdown","91777bf2":"markdown","1657d157":"markdown","890b0a90":"markdown","4529d7a5":"markdown","c4368175":"markdown","339ee6a1":"markdown","c4586910":"markdown","fbf8413e":"markdown","3f572052":"markdown","9379423d":"markdown","f8bdecf4":"markdown","5db9e0f9":"markdown","be4b4926":"markdown","24bd2fa5":"markdown","e9b25eda":"markdown","f5fd656f":"markdown","836eb248":"markdown","3d1b8778":"markdown","2d065c88":"markdown","779ae529":"markdown","e95cd09b":"markdown","dc9bb627":"markdown","bff3f22f":"markdown","a0b1fed9":"markdown","984017f8":"markdown","d92dabe0":"markdown","c5f63b04":"markdown","9ad5f3f4":"markdown","e7929dcc":"markdown","c58beb85":"markdown","5874a577":"markdown","893fe53d":"markdown","7b2fd2f3":"markdown","3aefbc4d":"markdown","9b1bdc00":"markdown","a277c4b2":"markdown","b97f2e0e":"markdown"},"source":{"51e9eab0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport sklearn as sk","7ca2ffaf":"#plt.rcParams.keys()","3fe99800":"%matplotlib inline\n\nplt.style.use('seaborn')\nsns.set(style=\"darkgrid\")\nplt.rcParams['figure.figsize'] = (10.0, 8.0)\nplt.rcParams['xtick.labelsize'] = 14 \nplt.rcParams['ytick.labelsize'] = 14 \nplt.rcParams['axes.labelsize'] = 18\n\nsns.set(font_scale=1.8)\nsns.set(style=\"darkgrid\")\n\npd.options.display.max_columns = 100\npd.options.display.max_rows = 100\npd.options.mode.chained_assignment = None\npd.set_option('display.float_format', lambda x: '%.4f' % x)\nnp.set_printoptions(formatter={'float_kind':'{:f}'.format})\n\nclass color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'","141bc765":"# Default of credit card clients: predict DEFAULT\ndf = pd.read_csv('..\/input\/default\/default of credit card clients.csv')\ndf.head()","2ac5bdde":"print(df.shape)\ndf.shape[0] - df.dropna().shape[0]\n","1546c9c3":"df.head()","775ae794":"df = df.rename(columns=str.lower)\ndf = df.rename(columns={'education': 'educ', 'marriage': 'status', 'pay_0': 'pay_1'})","db6410d7":"df = df.drop(columns=['id'])","6e633f5d":"df.columns.to_list()","0a5bcb44":"df.isna().any()","dfeca6dc":"df.isna().mean()","94fbba7a":"df = df.dropna()\ndf.default.value_counts(dropna=False)","d0164453":"df.describe()","93d1eb70":"pay_cols = ['pay_1', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\npay_cols = [col.lower() for col in pay_cols]\n\nfor col in pay_cols:\n    fil = (df[col] == -2) | (df[col] == -1) | (df[col] == 0)\n    df.loc[fil, col] = 0\n    \ndf.pay_1.value_counts()","51a0c641":"df_no_dummies = df\nnon_dummy_df = df \ndf = pd.get_dummies(df)\ncols = [col.replace(' ', '_') for col in df.columns]\ndf.columns = cols\ndf.head()","f87bc5d4":"df.dtypes","4f51b0a5":"df.describe()","07d521bf":"ax = df.sex_female.value_counts(normalize=True).plot(kind='bar')\nax.set_xlabel(\"Gender\", size=18)\nax.set_xticklabels(['Female', 'Male'], rotation = 0)\nax.tick_params(axis='both', which='major', labelsize=14)\ndf.sex_female.value_counts(normalize=True)","bfc85e14":"ax = df_no_dummies.educ.value_counts(normalize=True).plot(kind='bar')\nax.set_xlabel(\"Education\")\nax.set_xticklabels(ax.get_xticklabels(), rotation = 0)#, ha=\"right\")\ndf_no_dummies.educ.value_counts(normalize=True)","01ea1371":"ax = df_no_dummies.status.value_counts(normalize=True).plot(kind='bar')\nax.set_xlabel(\"Status\")\nax.set_xticklabels(ax.get_xticklabels(), rotation = 0)  #, ha=\"right\")\ndf_no_dummies.status.value_counts(normalize=True)","34fa3a81":"sns.set(font_scale=1.6)\n\nax = df.default.value_counts(normalize=True).plot(kind='bar')\nax.set_xticklabels(['Not_defaulted', 'defaulted'], rotation = 0)\nax.tick_params(axis='both', which='major', labelsize=14)\ndf.default.value_counts(normalize=True)","a2e68e61":"sns.set(font_scale=1.6)\n\nplt.title('Age distribution')\ndf.age.hist(bins=17)","1bdfd5bb":"sns.set(font_scale=1.25)\n\nplt.figure(figsize=(14,8))\nax = df.limit_bal.hist(bins=50)\nax.set_xticks(np.linspace(0, 1000000, 11))\nax.set_xlim(0,750000)\nplt.title('Credit(Limit_Bal) distribution')\n","5a035067":"for i in range(1, 7):\n    col = 'pay_' + str(i)\n    print('Column', col, ':\\n', df[col].value_counts().sort_index()\\\n          .plot(kind='bar', figsize=(7,4)), '\\n\\n')\n    plt.title('value counts for column: {}'.format(col), fontsize=18)\n    plt.show()","114dfc32":"for i in range(1, 7):\n    col = 'bill_amt' + str(i)\n    print(df[col].plot(kind='hist', figsize=(7,4), bins=40), '\\n\\n')\n    plt.title('Histogram for column: {}'.format(col), fontsize=18)\n    plt.show()","ab327a11":"sns.set(font_scale=1.8)\n\nfig, ax1 = plt.subplots(figsize=(14,8))\ns = sns.boxplot(ax = ax1, x=\"sex\", y=\"limit_bal\", hue=\"sex\",data=non_dummy_df,\\\n                palette=\"PRGn\",showfliers=True)\nplt.title(\"Limit Balance Box plot by Gender\", fontsize=24)\n","0c209e09":"sns.set(font_scale=1.8)\n\nfig, ax1 = plt.subplots(figsize=(14, 8))\nsns.boxplot(x=\"educ\", y=\"limit_bal\", hue='sex', data=df_no_dummies)\nplt.title(\"Limit Balance Box plot by Gender & Edcuation\", fontsize=24)\n","42aeca33":"sns.set(font_scale=1.8)\n\nfig, ax1 = plt.subplots(figsize=(14,8))\ns = sns.boxplot(ax = ax1, x=\"status\", y=\"limit_bal\", hue=\"sex\",data=non_dummy_df,\\\n                palette=\"PRGn\",showfliers=True)\nplt.title(\"Limit Balance Box plot by Status\", fontsize=24)\n","19f723c1":"fig, ax = plt.subplots(figsize=(20,10))\nsns.set(font_scale=2)\nsns.barplot(x=\"sex\", y=\"default\", data=non_dummy_df, hue=\"educ\", capsize=.05)\nplt.legend(loc = 'best', bbox_to_anchor=(0, 1), fontsize=18)\nplt.title(\"Default average & confidence intervals by Education level & Gender\", fontsize=30)","208b8cf8":"fig, ax = plt.subplots(figsize=(20,10))\nsns.set(font_scale=2)\nsns.barplot(x=\"sex\", y=\"default\", data=non_dummy_df, hue=\"status\", capsize=.05)\nplt.legend(loc = 'upper left', bbox_to_anchor=(0, 1), fontsize=18)\nplt.title(\"Default average & confidence intervals by Status & Gender\", fontsize=30)","e695fb6f":"cols = ['pay_amt' + str(i) for i in range(1,7)]\ndf[cols].describe()","05f9c92e":"sns.set(style=\"white\")\n\ncorr = df.corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nf, ax = plt.subplots(figsize=(10, 8))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.9, vmin=-0.9, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.title(\"Correlation Matrix\", fontsize=18)","a12ca032":"plt.style.use('seaborn')\nsns.set(font_scale=1.4)\nplt.figure(figsize=(10,8))\nplt.title('Default correlation with features')\n\ndf.corr()['default'].drop('default').plot(kind='barh')","b668b390":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\ndf = df.astype(float)\ndf = df.dropna()\nscale = MinMaxScaler()\ndf_to_scale = df\nscaled = scale.fit_transform(df_to_scale)\nscaled_df = pd.DataFrame(scaled, columns=df_to_scale.columns)\nscaled_df.sample(5)","6a192e93":"from sklearn.model_selection import train_test_split\n\ntest_size = round(0.2 * len(scaled_df))\ntrain, test = train_test_split(scaled_df, test_size=test_size, random_state=0, shuffle=True)\n\nlabel = 'default'\n\nx_train, y_train = train.drop(label, axis=1), train[label]\nx_test, y_test = test.drop(label, axis=1), test[label]","cb6d19d7":"train_not_scaled, test_not_scaled = train_test_split(df, test_size=test_size,\\\n                                                     random_state=0, shuffle=True)\n\nlabel = 'default'\n\nx_train_not_scaled, y_train_not_scaled = train_not_scaled.drop(label, axis=1), train_not_scaled[label]\nx_test_not_scaled, y_test_not_scaled = test_not_scaled.drop(label, axis=1), test_not_scaled[label]","972fef5f":"x_train.shape, y_train.shape, x_test.shape, y_test.shape\n","e78b68fe":"df.default.value_counts(dropna=False)","015ee0d1":"y_train.value_counts(dropna=False)","291df724":"y_test.value_counts(dropna=False)","54e358d2":"acc = len(df[df.default==0])\/len(df)\npred = np.zeros(len(df))\nf1 = sk.metrics.f1_score(df.default, pred)\nprint('Beanchmark Accuracy:', acc)\nprint('Beanchmark F1:', f1) # it'll be 0..","7847d570":"from sklearn.neighbors import KNeighborsClassifier\n\ntrain_acc = []\ntest_acc = []\n\ntrain_f1 = []\ntest_f1 = []\n\nk_vals = list(range(5, 41, 5))\n\nvals = k_vals\n\nfor k in vals:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train_not_scaled, y_train_not_scaled)\n    \n    train_acc.append(knn.score(x_train_not_scaled, y_train_not_scaled))\n    test_acc.append(knn.score(x_test_not_scaled, y_test_not_scaled))\n    \n    y_pred_train = knn.predict(x_train_not_scaled)\n    y_pred_test = knn.predict(x_test_not_scaled)\n\n    train_f1.append(sk.metrics.f1_score(y_train, y_pred_train))\n    test_f1.append(sk.metrics.f1_score(y_test, y_pred_test))\n","3f1cf6e5":"sns.set(font_scale=1.5)\n# This will plot the accuracies as a function of k.\n\nfig = plt.figure(figsize=(10, 8))\nax1 = fig.add_subplot()\nax1.plot(vals, train_acc, '-o', label='Training Accuracy')\nax1.plot(vals ,test_acc, '-o', label='Testing Accuracy')\nax1.set_ylabel(\"Accuracy\")\nax1.set_xlabel(\"k\")\nplt.title('KNN accuracy by K - NOT scaled data')\nplt.legend(fontsize=14)\nplt.show()\n\n# This will plot the f1 score as a function of k.\n\nfig = plt.figure(figsize=(10, 8))\nax1 = fig.add_subplot()\nax1.plot(vals, train_f1, '-o', label='Training Accuracy')\nax1.plot(vals ,test_f1, '-o', label='Testing Accuracy')\nax1.set_ylabel(\"F1 score\")\nax1.set_xlabel(\"k\")\nplt.title('KNN F1 score by K - NOT scaled data')\nplt.legend(fontsize=14)\nplt.show()","5e69ec36":"k = 30\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(x_train_not_scaled, y_train_not_scaled)\ny_pred_test = knn.predict(x_test_not_scaled)\npred_df = pd.DataFrame({'KNN_not_scaled': y_pred_test})\npred_df['Beanchmark'] = 0","45a3489d":"from sklearn.neighbors import KNeighborsClassifier\n\ntrain_acc = []\ntest_acc = []\n\ntrain_f1 = []\ntest_f1 = []\n\nk_vals = list(range(5, 41, 5))\nvals = k_vals\n\nfor k in vals:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train, y_train)\n    \n    test_acc.append(knn.score(x_test, y_test))\n    train_acc.append(knn.score(x_train, y_train))\n    \n    y_pred_train = knn.predict(x_train)\n    y_pred_test = knn.predict(x_test)\n\n    train_f1.append(sk.metrics.f1_score(y_train, y_pred_train))\n    test_f1.append(sk.metrics.f1_score(y_test, y_pred_test))\n","808b3e5d":"\n# This will plot the accuracies as a function of k.\n\nfig = plt.figure(figsize=(10, 8))\nax1 = fig.add_subplot()\nax1.plot(vals, train_acc, '-o', label='Training Accuracy')\nax1.plot(vals ,test_acc, '-o', label='Testing Accuracy')\nax1.set_ylabel(\"Accuracy\")\nax1.set_xlabel(\"k\")\nplt.title('KNN accuracy by K - scaled data')\nplt.legend(fontsize=14)\nplt.show()\n\n\n# This will plot the f1 score as a function of k.\n\nfig = plt.figure(figsize=(10, 8))\nax1 = fig.add_subplot()\nax1.plot(vals, train_f1, '-o', label='Training F1 Score')\nax1.plot(vals ,test_f1, '-o', label='Testing F1 Score')\nax1.set_ylabel(\"F1 Score\")\nax1.set_xlabel(\"k\")\nplt.title('KNN F1 Score by K - scaled data')\nplt.legend(fontsize=14)\nplt.show()","eef56a61":"k = 25\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(x_train_not_scaled, y_train_not_scaled)\ny_pred_test = knn.predict(x_test_not_scaled)\npred_df['KNN_scaled'] = y_pred_test","36a33b09":"from sklearn.tree import DecisionTreeClassifier\n\nmax_depth_vals = range(3, 19, 3)\n\nmin_samples_vals = range(1, 101, 10)\n\nfor depth in max_depth_vals:\n    \n    train_acc = []\n    test_acc = []\n    \n    train_f1 = []\n    test_f1 = []\n    \n    for min_sample in min_samples_vals:\n        classifier = DecisionTreeClassifier(random_state=0, \\\n                                            max_depth=depth, min_samples_leaf=min_sample)\n        classifier.fit(x_train_not_scaled, y_train_not_scaled)\n        \n        train_acc.append(classifier.score(x_train_not_scaled, y_train_not_scaled))\n        test_acc.append(classifier.score(x_test_not_scaled, y_test_not_scaled))\n        \n        y_pred_train = classifier.predict(x_train_not_scaled)\n        y_pred_test = classifier.predict(x_test_not_scaled)\n\n        train_f1.append(sk.metrics.f1_score(y_train, y_pred_train))\n        test_f1.append(sk.metrics.f1_score(y_test, y_pred_test))\n\n    # This will plot the Accuracy Scores as a function of k.\n  \n    fig, ax = plt.subplots(figsize=(7, 5))\n    plt.plot(min_samples_vals, train_acc, '-o', label = 'Training Accuracy')\n    plt.plot(min_samples_vals, test_acc, '-o', label = 'Test Accuracy')\n    ax.set_xlabel('Min Samples Leaf', fontsize=16)\n    ax.set_ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy for Decision Tree with Maximum depth = {} by min_samples leaf'.format(depth)\\\n              , fontsize=18)\n    plt.legend(fontsize=14)\n    plt.show()\n    print('\\n')\n\n    # This will plot the F1 Scores as a function of k.\n\n    fig = plt.figure(figsize=(7, 5))\n    ax1 = fig.add_subplot()\n    ax1.plot(min_samples_vals, train_f1, '-o', label = 'Training F1 Score')\n    ax1.plot(min_samples_vals, test_f1, '-o', label = 'Test F1 Score')\n    ax1.set_ylabel(\"F1 Score\", fontsize=16)\n    ax1.set_xlabel('Min Samples Leaf', fontsize=16)\n    plt.title('F1 Score for Decision Tree with Maximum depth = {} by min_samples leaf'.format(depth)\\\n              , fontsize=18)\n    plt.legend(fontsize=14)\n    plt.show()\n    print('\\n\\n\\n\\n')\n","142cbb46":"max_depth = 15\nmin_samples_leaf = 60\nclassifier = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\nclassifier.fit(x_train_not_scaled, y_train_not_scaled)\ny_pred_test = classifier.predict(x_test_not_scaled)\npred_df['Decision_tree'] = y_pred_test","a4aa06e4":"from sklearn.tree import export_graphviz\nfrom IPython.display import SVG\nfrom graphviz import Source\n\n\ndef plot_tree(tree, features, labels):\n    graph = Source(export_graphviz(tree, feature_names=features, class_names=labels, filled = True))\n    display(SVG(graph.pipe(format='svg')))\n\ntree = DecisionTreeClassifier(max_depth=6, min_samples_leaf=60, random_state=0)\ntree.fit(x_train, y_train)\nplot_tree(tree, features=x_train.columns, labels=['Not Default', 'Default'])","f9e1e4d7":"from sklearn.ensemble import RandomForestClassifier\n\nmax_depth_vals = range(3, 19, 3)\n\nn_estimators_values = range(10, 200, 20)\n\nfor depth in max_depth_vals:\n    \n    train_acc = []\n    test_acc = []\n    \n    train_f1 = []\n    test_f1 = []\n    \n    for n in n_estimators_values:\n        classifier = RandomForestClassifier(random_state=0, n_estimators=n, \\\n                                        max_depth=depth, min_samples_leaf=60) \n                                    # The paramters we decided on earlier\n        classifier.fit(x_train_not_scaled, y_train_not_scaled)\n        \n        train_acc.append(classifier.score(x_train_not_scaled, y_train_not_scaled))\n        test_acc.append(classifier.score(x_test_not_scaled, y_test_not_scaled))\n        \n        y_pred_train = classifier.predict(x_train_not_scaled)\n        y_pred_test = classifier.predict(x_test_not_scaled)\n\n        train_f1.append(sk.metrics.f1_score(y_train, y_pred_train))\n        test_f1.append(sk.metrics.f1_score(y_test, y_pred_test))\n\n    # This will plot the Accuracy Scores as a function of k.\n\n    fig, ax = plt.subplots(figsize=(7, 5))\n    plt.plot(n_estimators_values, train_acc, '-o', label = 'Training Accuracy')\n    plt.plot(n_estimators_values, test_acc, '-o', label = 'Test Accuracy')\n    ax.set_xlabel('n_estimators', fontsize=16)\n    ax.set_ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy for Random Forest with Maximum depth = {} by n_estimators'.format(depth)\\\n              , fontsize=18)\n    plt.legend(fontsize=14)\n    plt.show()\n    print('\\n')\n\n    # This will plot the F1 Scores as a function of k.\n\n    fig = plt.figure(figsize=(7, 5))\n    ax1 = fig.add_subplot()\n    ax1.plot(n_estimators_values, train_f1, '-o', label = 'Training F1 Score')\n    ax1.plot(n_estimators_values, test_f1, '-o', label = 'Test F1 Score')\n    ax1.set_ylabel(\"F1 Score\", fontsize=16)\n    ax1.set_xlabel('n_estimators', fontsize=16)\n    plt.title('F1 Score for Random Forest with Maximum depth = {} by n_estimators'.format(depth)\\\n              , fontsize=18)\n    plt.legend(fontsize=14)\n    plt.show()\n    print('\\n\\n\\n\\n')\n","38d12a8f":"n_of_trees = 100\nclassifier = RandomForestClassifier(random_state=0, n_estimators=n_of_trees, \\\n                                        max_depth=15, min_samples_leaf=60) \n                                    # The paramters we decided on earlier\nclassifier.fit(x_train_not_scaled, y_train_not_scaled)\npred_df['random_forest_pred'] = classifier.predict(x_test_not_scaled)","cfae2671":"sns.set(font_scale=1.6)\n\ntmp = pd.DataFrame({'Feature': x_train.columns, 'Feature importance': classifier.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance', ascending=False)\n\nplt.figure(figsize = (10, 8))\nplt.title('Features importance of Random Forest')\ns = sns.barplot(x='Feature', y='Feature importance', data=tmp)\ns.set_xticklabels(s.get_xticklabels(), rotation=90)\nplt.show()   ","e85f9979":"from sklearn.ensemble import AdaBoostClassifier\n\nmax_depth_vals = range(5, 18, 4)\n\nn_estimators_values = range(40, 161, 40)\n\nfor depth in max_depth_vals:\n    \n    train_acc = []\n    test_acc = []\n    \n    train_f1 = []\n    test_f1 = []\n    \n    for n in n_estimators_values:\n        base_estimator = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=120)\n                                        # AdaBoost tends to oferfit, so we'll use more suited paramters.\n        classifier = AdaBoostClassifier(random_state=0, n_estimators=n, \\\n                                        base_estimator=base_estimator)\n        classifier.fit(x_train_not_scaled, y_train_not_scaled)\n        \n        train_acc.append(classifier.score(x_train_not_scaled, y_train_not_scaled))\n        test_acc.append(classifier.score(x_test_not_scaled, y_test_not_scaled))\n        \n        y_pred_train = classifier.predict(x_train_not_scaled)\n        y_pred_test = classifier.predict(x_test_not_scaled)\n\n        train_f1.append(sk.metrics.f1_score(y_train, y_pred_train))\n        test_f1.append(sk.metrics.f1_score(y_test, y_pred_test))\n\n    # This will plot the Accuracy Scores as a function of k.\n\n    fig, ax = plt.subplots(figsize=(7, 5))\n    plt.plot(n_estimators_values, train_acc, '-o', label = 'Training Accuracy')\n    plt.plot(n_estimators_values, test_acc, '-o', label = 'Test Accuracy')\n    ax.set_xlabel('n_estimators', fontsize=16)\n    ax.set_ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy for AdaBoost with Maximum depth = {} by n_estimators'.format(depth)\\\n              , fontsize=18)\n    plt.legend(fontsize=14)\n    plt.show()\n    print('\\n')\n\n    # This will plot the F1 Scores as a function of k.\n\n    fig = plt.figure(figsize=(7, 5))\n    ax1 = fig.add_subplot()\n    ax1.plot(n_estimators_values, train_f1, '-o', label = 'Training F1 Score')\n    ax1.plot(n_estimators_values, test_f1, '-o', label = 'Test F1 Score')\n    ax1.set_ylabel(\"F1 Score\", fontsize=16)\n    ax1.set_xlabel('n_estimators', fontsize=16)\n    plt.title('F1 Score for AdaBoost with Maximum depth = {} by n_estimators'.format(depth)\\\n              , fontsize=18)\n    plt.legend(fontsize=14)\n    plt.show()\n    print('\\n\\n\\n\\n')\n","2c1695f1":"n_of_trees = 40\nbase_estimator = DecisionTreeClassifier(max_depth=15, min_samples_leaf=60)\n                                # The paramters we decided on earlier\nclassifier = AdaBoostClassifier(random_state=0, n_estimators=n_of_trees, base_estimator=base_estimator)\nclassifier.fit(x_train_not_scaled, y_train_not_scaled)\npred_df['AdaBoost'] = classifier.predict(x_test_not_scaled)","a1a6addc":"sns.set(font_scale=1.6)\n\ntmp = pd.DataFrame({'Feature': x_train.columns, 'Feature importance': classifier.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance', ascending=False)\n\nplt.figure(figsize = (10, 8))\nplt.title('Features importance of AdaBoost')\ns = sns.barplot(x='Feature', y='Feature importance', data=tmp)\ns.set_xticklabels(s.get_xticklabels(), rotation=90)\nplt.show()   ","5d83a583":"from sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression(penalty='l1', solver='liblinear')\nclassifier.fit(x_train, y_train)\n\ny_pred_test = classifier.predict(x_test)\ny_pred_train = classifier.predict(x_train)\n\nacc_train = classifier.score(x_train, y_train)\nacc_test = classifier.score(x_test, y_test)\n\nf1_train = sk.metrics.f1_score(y_train, y_pred_train)\nf1_test = sk.metrics.f1_score(y_test, y_pred_test)\n\n\npred_df['logistic_regression'] = y_pred_test\n\nprint('Accuracy for train:', acc_train)\nprint('F1 Score for train:', f1_train, '\\n')\n\nprint('Accuracy for test:', acc_test)\nprint('F1 Score for test:', f1_test)","9f432cb7":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","de18a5fc":"x_train.shape","f2f719dd":"## train data\nclass trainData(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n\ntrain_data = trainData(torch.FloatTensor(x_train.values), \n                       torch.FloatTensor(y_train))\n## test data    \nclass testData(Dataset):\n    \n    def __init__(self, X_data):\n        self.X_data = X_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n    \n\ntest_data = testData(torch.FloatTensor(x_test.values))","1e1f8ea3":"BATCH_SIZE = 64\ntrain_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(dataset=test_data, batch_size=1)","3b2f4e53":"class binaryClassification(nn.Module):\n    def __init__(self):\n        super(binaryClassification, self).__init__()\n        # Number of input features is 12.\n        self.layer_1 = nn.Linear(30, 64) \n        self.layer_2 = nn.Linear(64, 64)\n        self.layer_out = nn.Linear(64, 1) \n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.1)\n        self.batchnorm1 = nn.BatchNorm1d(64)\n        self.batchnorm2 = nn.BatchNorm1d(64)\n        \n    def forward(self, inputs):\n        x = self.relu(self.layer_1(inputs))\n        x = self.batchnorm1(x)\n        x = self.relu(self.layer_2(x))\n        x = self.batchnorm2(x)\n        x = self.dropout(x)\n        x = self.layer_out(x)\n        \n        return x","e25168b5":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","ae2a5b46":"LEARNING_RATE = 0.001\nmodel = binaryClassification()\nmodel.to(device)\nprint(model)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","1ccbde69":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum\/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","eaff16fb":"EPOCHS = 50\nmodel.train()\nfor e in range(1, EPOCHS+1):\n    epoch_loss = 0\n    epoch_acc = 0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_pred = model(X_batch)\n        \n        loss = criterion(y_pred, y_batch.unsqueeze(1))\n        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n        \n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n\n    print(f'Epoch {e+0:03}: | Loss: {epoch_loss\/len(train_loader):.5f} |\\\n    Acc: {epoch_acc\/len(train_loader):.3f}')\n","3e67a60f":"y_pred_list = []\nmodel.eval()\nwith torch.no_grad():\n    for X_batch in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_tag = torch.round(y_test_pred)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]\npred_df['NN'] = y_pred_list","e62f23d3":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y_pred_list)","7debe3dd":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_list))","d0deeb95":"from string import ascii_uppercase\nfrom sklearn.metrics import confusion_matrix\n\nplt.figure(figsize=(12, 10))\nconfm = confusion_matrix(y_test, y_pred_list)\ndf_cm = pd.DataFrame(confm, index=['Predicted No Default', 'Predicted Default'], columns=['Not Default', 'Default'])\n\nax = sns.heatmap(df_cm, cmap='Oranges', annot=True, fmt='g')","a30ce4b9":"pred_df['default'] = test.default.reset_index(drop=True)\np = pred_df\npred_df.head()","83565149":"pred_df = p\npred_df['model_avg'] = pred_df[['random_forest_pred', 'AdaBoost', 'NN']].mean(axis=1).round(decimals=0)\n","42c152a1":"acc = []\nf1 = []\nmodels = pred_df.drop('default', axis=1).columns\n\nfor model in models:\n    acc.append(sk.metrics.accuracy_score(pred_df.default, pred_df[model]))\n    f1.append(sk.metrics.f1_score(pred_df.default, pred_df[model]))\n\ncomparison = pd.DataFrame({'Model': models, 'Accuracy': acc, 'F1 Score': f1})\ncomparison","211d92b9":"acc = []\nf1 = []\nmodels = pred_df.drop('default', axis=1).columns\n\nfor model in models:\n    acc.append(sk.metrics.accuracy_score(pred_df.default, pred_df[model]))\n    f1.append(sk.metrics.f1_score(pred_df.default, pred_df[model]))\n\ncomparison = pd.DataFrame({'Model': models, 'Accuracy': acc, 'F1 Score': f1})\ncomparison","9838b96a":"fig, ax = plt.subplots(figsize=(18,10))\nsns.set(font_scale=1.3)\n\nvalues = comparison.Accuracy.values\nclrs = ['grey' if (x < max(values)) else 'red' for x in values ]\n\ngraph = sns.barplot(x=\"Model\", y=\"Accuracy\", data=comparison, palette= clrs)\n\nfor p in graph.patches:\n        graph.annotate('{:.0f}%'.format(p.get_height()*100), (p.get_x()+0.42, p.get_height()),\n                    ha='center', va='bottom')\nplt.title(\"Accuracy Comparison by Model\", fontsize=20)","67fe0672":"fig, ax = plt.subplots(figsize=(18,10))\nsns.set(font_scale=1.2)\nsns.barplot(x=\"Model\", y=\"F1 Score\", data=comparison, capsize=.05)\nplt.title(\"F1 Score Comparison by Model\", fontsize=20)","08cb6ae3":"train_acc = []\ntest_acc = []\n\ntrain_f1 = []\ntest_f1 = []\n\npercents = [0.1, 0.3, 0.5, 0.7, 1]\n\nx_train_not_scaled = x_train_not_scaled.reset_index(drop=True)\ny_train_not_scaled = y_train_not_scaled.reset_index(drop=True)\n\nfor p in percents:\n    x_train_to_use = x_train_not_scaled.iloc[: int(p * len(x_train_not_scaled))]\n    y_train_to_use = y_train_not_scaled.iloc[: int(p * len(y_train_not_scaled))]\n\n    n_of_trees = 100\n    classifier = RandomForestClassifier(random_state=0, n_estimators=n_of_trees, \\\n                                            max_depth=15, min_samples_leaf=60) \n                                        # The paramters we decided on earlier\n    classifier.fit(x_train_to_use, y_train_to_use)\n    \n    test_acc.append(classifier.score(x_test_not_scaled, y_test_not_scaled))\n    train_acc.append(classifier.score(x_train_to_use, y_train_to_use))\n    \n    y_pred_train = classifier.predict(x_train_to_use)\n    y_pred_test = classifier.predict(x_test_not_scaled)\n\n    train_f1.append(sk.metrics.f1_score(y_train_to_use, y_pred_train))\n    test_f1.append(sk.metrics.f1_score(y_test_not_scaled, y_pred_test))\n","a5bef899":"sns.set(font_scale=1.5)\n# This will plot the accuracies as a function of % of data.\n\nfig = plt.figure(figsize=(10, 8))\nax1 = fig.add_subplot()\nax1.plot(percents, train_acc, '-o', label='Training Accuracy')\nax1.plot(percents ,test_acc, '-o', label='Testing Accuracy')\nax1.set_ylabel(\"Accuracy\")\nax1.set_xlabel(\"% Of Data\")\nplt.title('Random Forest Accuracy by % of data')\nplt.legend(fontsize=14)\nplt.show()\n\n\n# This will plot the f1 score as a function of % of data.\n\nfig = plt.figure(figsize=(10, 8))\nax1 = fig.add_subplot()\nax1.plot(percents, train_f1, '-o', label='Training F1 Score')\nax1.plot(percents ,test_f1, '-o', label='Testing F1 Score')\nax1.set_ylabel(\"F1 Score\")\nax1.set_xlabel(\"% Of Data\")\nplt.title('Random Forest F1 Score by % of data')\nplt.legend(fontsize=14)\nplt.show()","f72426e3":"pred_df = pred_df.drop('model_avg', axis=1)\npred_df.head()","883b4a63":"from statsmodels.regression.linear_model import OLS\n\nx_cols = ['ln_min_wage', 'arab', 'gender', 'constant']\n\nols = OLS(pred_df.default, pred_df.drop(['default', 'Beanchmark'], axis=1)).fit()\n\nols.summary()\n","1647adfe":"dic = dict(ols.params)\nsum_params = sum(dic.values())","328beff5":"compare = pd.DataFrame(columns=['Model', 'weight'])\ncompare['Model'] = dic.keys()\ncompare['weight'] = dic.values()\nnorm_weight = [param\/sum_params for param in ols.params]\ncompare['norm_weight'] = norm_weight\nc = compare\ncompare","c70723f2":"compare = c\ncompare_t = compare.T\ncompare_t = compare_t.rename(columns=compare_t.iloc[0])\ncompare_t = compare_t.iloc[1:]\ncompare = compare_t.T\ncompare_t","31b1f3f3":"pred_df['final_model'] = compare_t.iloc[0]['KNN_not_scaled']*pred_df.KNN_not_scaled\\\n    + compare_t.iloc[0]['KNN_scaled']*pred_df.KNN_scaled\\\n    + compare_t.iloc[0]['Decision_tree']*pred_df.Decision_tree\\\n    + compare_t.iloc[0]['random_forest_pred']*pred_df.Decision_tree\\\n    + compare_t.iloc[0]['AdaBoost']*pred_df.AdaBoost\\\n    + compare_t.iloc[0]['logistic_regression']*pred_df.logistic_regression\\\n    + compare_t.iloc[0]['NN']*pred_df.NN\n\n\npred_df.final_model = pred_df.final_model.round()\npred_df.head()\n","99d59b5a":"pred_df['final_norm_model'] = compare_t.iloc[1]['KNN_not_scaled']*pred_df.KNN_not_scaled\\\n    + compare_t.iloc[1]['KNN_scaled']*pred_df.KNN_scaled\\\n    + compare_t.iloc[1]['Decision_tree']*pred_df.Decision_tree\\\n    + compare_t.iloc[1]['random_forest_pred']*pred_df.Decision_tree\\\n    + compare_t.iloc[1]['AdaBoost']*pred_df.AdaBoost\\\n    + compare_t.iloc[1]['logistic_regression']*pred_df.logistic_regression\\\n    + compare_t.iloc[1]['NN']*pred_df.NN\n\n\npred_df.final_norm_model = pred_df.final_norm_model.round()\npred_df.head()","2bc08185":"acc = []\nf1 = []\nmodels = pred_df.drop('default', axis=1).columns\n\nfor model in models:\n    acc.append(sk.metrics.accuracy_score(pred_df.default, pred_df[model]))\n    f1.append(sk.metrics.f1_score(pred_df.default, pred_df[model]))\n\ncomparison = pd.DataFrame({'Model': models, 'Accuracy': acc, 'F1 Score': f1})\ncomparison","cc3e87ab":"fig, ax = plt.subplots(figsize=(18,10))\nsns.set(font_scale=1.3)\n\nvalues = comparison.Accuracy.values\nclrs = ['grey' if (x < max(values)) else 'red' for x in values ]\n\ngraph = sns.barplot(x=\"Model\", y=\"Accuracy\", data=comparison, palette=clrs)\n\nfor p in graph.patches:\n        graph.annotate('{:.0f}%'.format(p.get_height()*100), (p.get_x()+0.42, p.get_height()),\n                    ha='center', va='bottom')\nplt.title(\"Accuracy Comparison by Model\", fontsize=20)","e60d82c9":"# compare standalone models for binary classification\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom matplotlib import pyplot\n\n\n# get a list of models to evaluate\ndef get_models():\n    models = dict()\n    models['lr'] = LogisticRegression()\n    models['knn'] = KNeighborsClassifier()\n    models['cart'] = DecisionTreeClassifier()\n    models['svm'] = SVC()\n    models['bayes'] = GaussianNB()\n    return models\n\n\n# evaluate a given model using cross-validation\ndef evaluate_model(model):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    return scores","80a81a5a":"X, y = scaled_df.drop('default', axis=1), scaled_df.default\n# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model)\n    results.append(scores)\n    names.append(name)\n    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n# plot model performance for comparison\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","07164262":"from sklearn.ensemble import StackingClassifier\n\n\ndef get_stacking():\n    # define the base models\n    level0 = list()\n    level0.append(('lr', LogisticRegression()))\n    level0.append(('knn', KNeighborsClassifier()))\n    level0.append(('cart', DecisionTreeClassifier()))\n    level0.append(('svm', SVC()))\n    level0.append(('bayes', GaussianNB()))\n    # define meta learner model\n    level1 = LogisticRegression()\n    # define the stacking ensemble\n    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n    return model","ba2cff05":"def get_models():\n    models = dict()\n    models['lr'] = LogisticRegression()\n    models['knn'] = KNeighborsClassifier()\n    models['cart'] = DecisionTreeClassifier()\n    models['svm'] = SVC()\n    models['bayes'] = GaussianNB()\n    models['stacking'] = get_stacking()\n    return models","bb858971":"X, y = scaled_df.drop('default', axis=1), scaled_df.default\n\n# get the models to evaluate\nmodels = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model)\n    results.append(scores)\n    names.append(name)\n    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n# plot model performance for comparison\nplt.boxplot(results, labels=names, showmeans=True)\nplt.show()","b7df855e":"Drop unneeded columns","ac1c8e74":"This histogram seems reasonable(based on the fact that the minimum age is 21).\n","4ddea153":"What are the statistics of the data?","4037387f":"# Thank you for your time!","3df85330":"We can notice that there is a major overfitting. We can also notice that the y axes has really small differences both on F1 and Accuracy(usually diff<1%).\nIt seems that 40 is the best number of trees and max_depth = 5 is the best max_depth. Let's see what is the feature importance:","6736588f":"# KNN - on SCALED data","12f97dd7":"# Logistic regression","2bd30a42":"Categorical values to 1-hot","19401b1f":"We have 30000 examples and 25 columns (24 features and one label). 68 rows with NA values. Let's look at the data","b5336a67":"# Data exploration","e6c62ff1":"In this case it's 0 (not survived), let's check its performance on both train and test","c7cd59e7":"Since the number of null values is really small, we'll simply drop them.","b4e1f0ba":"# Decision Tree","8031024a":"Check all values are indeed numeric","7e14b8e9":"# Load Data","381a0098":"Distribution of the age in our data:","1a30d216":"# Preprocessing","71b1ad27":"Because there are different scales in our data, we'll use standard scalar which is less sensitive to outliers.","a4e19ce2":"The accuracy improved. and the F1 score improved by a lot. Based on this graphs we'll choose k = 25.","98d5df57":"As this is a classification problem that is a little unbalanced in its labels, we'll use F1 & accuracy as our evaluation metric.","b2934de1":"We can notice that the y axes has really small differences both on F1 and Accuracy(diff<1%).\nIt seems that 100 is the best number of trees. Let's see what is the feature importance:","756c1a8d":"It seems that the strongest relationships are regarding repayment status(pay_x) the link is positive, and it seems that the link decreases with the number of months before the current month.\nSame goes for the payment amount(pay_amt_x), just with negative and less significant correlations. \nAnother notable correlation is with the amount of given credit(limit_bal)","d6158eda":"It doesn't seem better than the benchmark even when when it's performing best on the test set(k = 30). Also, we know that KNN can highly suffer from features that are in different scales. So let's run it on scaled data","91777bf2":"According to our documentation, the PAY_n variables indicate the number of months of delay and indicates \"pay duly\" with -1. Then what is -2 and 0? It seems to me that the label has to be adjusted to 0 for pay duly. Let's fix this.","1657d157":"# Neural Networks with pyTorch","890b0a90":"### Some personal settings","4529d7a5":"# Performance vs. amount of data","c4368175":"# Let's plot the Decision Tree","339ee6a1":"Let's scale the x values","c4586910":"### Train and test split","fbf8413e":"# Running KNN - on NOT scaled data","3f572052":"The performance on train and test is almost equal, our best algorithm should beat this performance!","9379423d":"Now, let's see a correlation matrix heat map, and try to find interesting relations","f8bdecf4":"Based on this graphs we decided to go with min_samples_leaf=60 and max_tree_depth=15","5db9e0f9":"Let's look for missing data","be4b4926":"And now plot correlations to default","24bd2fa5":"About ~22% of the clients defaulted. A small unbalanced dataset, we'll remember that.","e9b25eda":"Now, let's see how default differs with respect to other features.","f5fd656f":"# Data Cleaning & Preprocessing","836eb248":"# Averaging models","3d1b8778":"All features are numeric, that's great.","2d065c88":"# Stacking models - with Sklearn function","779ae529":"The benchmark would be the most common label in the train set","e95cd09b":"# Evaluation + Benchmark","dc9bb627":"Here we can see the distribution of the credit that was given","bff3f22f":"Again, any comments will be welcomed","a0b1fed9":"Change column names to be more convenient ","984017f8":"## Variables\nThere are 25 variables:\n\n* ID: ID of each client\n* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family\/supplementary credit\n* SEX: Gender (1=male, 2=female)\n* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n* AGE: Age in years\n* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n* PAY_2: Repayment status in August, 2005 (scale same as above)\n* PAY_3: Repayment status in July, 2005 (scale same as above)\n* PAY_4: Repayment status in June, 2005 (scale same as above)\n* PAY_5: Repayment status in May, 2005 (scale same as above)\n* PAY_6: Repayment status in April, 2005 (scale same as above)\n* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n* default.payment.next.month: Default payment (1=yes, 0=no)\n","d92dabe0":"We plot will plot this with max_depth = 6 just so we'll be able to keep track on the tree.","c5f63b04":"And let's split for NOT scaled data as well.","9ad5f3f4":"Let's take a look at the some features distributions","e7929dcc":"# Stacking models - normal average","c58beb85":"# Introduction\nThis notebook was created as part of a Machine Learning academic course. Any feedback is more than welcome.","5874a577":"# Random Forest","893fe53d":"It seems that the score doesn't improve when we go from 70% to 100%. Hence, we wouldn't use more data.","7b2fd2f3":"Check how many examples and how many features are in the dataset","3aefbc4d":"We have about 30k obs', so let's use 80% for train and 20% for test.","9b1bdc00":"# AdaBoost","a277c4b2":"Let's check the credit limit distribution VS sex.","b97f2e0e":"### Let's make sure all columns are as documented."}}