{"cell_type":{"80d85575":"code","d7e6750c":"code","ae907da2":"code","309a7533":"code","c8c34075":"code","d68b1555":"code","48ec5100":"code","35226d28":"code","02da9f8e":"code","bf4418a6":"code","d506878d":"code","c76f4045":"code","9f1a2456":"markdown","6c4e1469":"markdown","a37a538f":"markdown","2394d014":"markdown","998c05a7":"markdown","ddbed914":"markdown","f4a39536":"markdown","5eff1edc":"markdown","5bdf2677":"markdown","0d8345b2":"markdown","f32a0154":"markdown","026ea543":"markdown","cfbf08f9":"markdown"},"source":{"80d85575":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_validate, cross_val_predict\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix\n\nsns.set_style(\"whitegrid\")\n              \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","d7e6750c":"df = pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndf.head()","ae907da2":"df.isnull().sum(axis = 0)","309a7533":"df.describe().round(2)","c8c34075":"class_size = ds = df['DEATH_EVENT'].value_counts().reset_index()\nsns.barplot(x=\"index\", y=\"DEATH_EVENT\", data=class_size)\nplt.xlabel('DEATH_EVENT')\nplt.ylabel('Count')\nplt.show()","d68b1555":"# Select Features and Target\nx = df.drop(columns='DEATH_EVENT', axis=1)\ny = df[['DEATH_EVENT']]","48ec5100":"import warnings\nwarnings.filterwarnings('ignore')\n\n# Scaling\nx_scaling = preprocessing.StandardScaler().fit(x).transform(x)\n\n# Create Model\nreglog_0 = LogisticRegression()\nscores = cross_validate(reglog_0, x_scaling, y, cv=10,\n                         scoring=('accuracy', 'precision', 'recall'),\n                         return_train_score = True)\n\nprint(\"Evaluation Scores:\")\nprint(\"Logistic Regression Accuracy:\", \"{:.2f}%\".format(scores['test_accuracy'].mean()*100))\nprint(\"Logistic Regression Precission :\", \"{:.2f}%\".format(scores['test_precision'].mean()*100))\nprint(\"Logistic Regression Recall :\", \"{:.2f}%\".format(scores['test_recall'].mean()*100))","35226d28":"y_predict_reglog = cross_val_predict(reglog_0, x_scaling, y, cv=10)\nconf_mat = confusion_matrix(y, y_predict_reglog)\n\nsns.heatmap(conf_mat, annot=True, cmap=\"viridis\", fmt='g')\nplt.xlabel('\\nPredict Label')\nplt.ylabel('True Label')\nplt.show()","02da9f8e":"# Handling Imbalance Data using Random Over Sampling\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\n\nx_resampled, y_resampled = make_classification(n_samples=1000, n_features=2, n_redundant=0,\n                                                   n_clusters_per_class=1, flip_y=0, \n                                                   random_state=1)\nros = RandomOverSampler(random_state=0)\nx_resampled, y_resampled = ros.fit_resample(x_resampled, y_resampled)\n\nprint(sorted(Counter(y_resampled).items()))","bf4418a6":"class_size_resample = pd.DataFrame(data=y_resampled, columns=[\"DEATH_EVENT_RESAMPLE\"])\nclass_size_resample = class_size_resample['DEATH_EVENT_RESAMPLE'].value_counts().reset_index()\n\nsns.barplot(x=\"index\", y=\"DEATH_EVENT_RESAMPLE\", data=class_size_resample)\nplt.xlabel('DEATH_EVENT_RESAMPLE')\nplt.ylabel('Count')\nplt.show()","d506878d":"scores = cross_validate(reglog_0, x_resampled, y_resampled, cv=10,\n                         scoring=('accuracy', 'precision', 'recall'),\n                         return_train_score = True)\n\nprint(\"Evaluation Scores After Oversampling:\")\nprint(\"Logistic Regression Accuracy:\", \"{:.2f}%\".format(scores['test_accuracy'].mean()*100))\nprint(\"Logistic Regression Precission :\", \"{:.2f}%\".format(scores['test_precision'].mean()*100))\nprint(\"Logistic Regression Recall :\", \"{:.2f}%\".format(scores['test_recall'].mean()*100))","c76f4045":"y_predict_resample = cross_val_predict(reglog_0, x_resampled, y_resampled, cv=10)\nconf_mat_resample = confusion_matrix(y_resampled, y_predict_resample)\n\nsns.heatmap(conf_mat_resample, annot=True, cmap=\"viridis\", fmt='g')\nplt.xlabel('\\nPredict Label')\nplt.ylabel('True Label')\nplt.show()","9f1a2456":"* Target Data has imbalance size\n* Logistic Regression before handling imbalance data has lower evaluation scores","6c4e1469":"From the barchart above, the size of target data has imbalance.","a37a538f":"# Import Library and Load Dataset","2394d014":"# Conlusion","998c05a7":"Statistics descriptive can be see below.","ddbed914":"# Handling Imbalance Target","f4a39536":"Before do analysis, I need to import library dan load dataset. In this analysis, I use numpy, pandas, matplotlib, seaborn, sklearn and imblearn.","5eff1edc":"# Data Exploration","5bdf2677":"# Logistic Regression After Handling Imbalace Target","0d8345b2":"# Logistic Regression","f32a0154":"In this dataset has no missing value. So, I dont need to handling missing value","026ea543":"![](https:\/\/bjcardio.co.uk\/wp-content\/uploads\/2020\/04\/BANNER-Heart-Failure.jpg)","cfbf08f9":"The five rows of dataset can be see below."}}