{"cell_type":{"7396662d":"code","35369143":"code","252e80ef":"code","3521b959":"code","24c162bf":"code","c77e1db3":"code","5c4b6c2e":"code","6a5605dc":"code","99955cda":"code","c49efc80":"code","aa5eaa1d":"code","4719c7b0":"code","57273192":"code","6fc31149":"code","201625fa":"code","ca639a4a":"code","a201a24c":"code","9493f1fb":"code","d729afae":"code","e378847a":"code","be4251d7":"code","a9ba96d9":"markdown","372c12f9":"markdown","faa1c019":"markdown","3fddbfd7":"markdown","3ce571c5":"markdown","d79be11e":"markdown","23e1f1da":"markdown","2bb624d8":"markdown","e567732a":"markdown","400b05f7":"markdown"},"source":{"7396662d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# plotly\n# import plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport seaborn as sns\nimport json\n# word cloud library\nfrom wordcloud import WordCloud\n\n# matplotlib\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","35369143":"#reading datas\ncatrends = pd.read_csv(\"..\/input\/youtube-new\/CAvideos.csv\")\ndetrends = pd.read_csv(\"..\/input\/youtube-new\/DEvideos.csv\")\nfrtrends = pd.read_csv(\"..\/input\/youtube-new\/FRvideos.csv\")\ngbtrends = pd.read_csv(\"..\/input\/youtube-new\/GBvideos.csv\")\nintrends = pd.read_csv(\"..\/input\/youtube-new\/INvideos.csv\")\nustrends = pd.read_csv(\"..\/input\/youtube-new\/USvideos.csv\")\n\ngeneraltrends_full = pd.concat([catrends,detrends,frtrends,gbtrends,intrends,ustrends])\n\n","252e80ef":"#general analysis about datas and comparing\ncatrends.info()\nintrends.info()\nfrtrends.info()\n\n#we see that there is no NaN data","3521b959":"ustrends.head()\n","24c162bf":"catrends = catrends[[\"trending_date\",\"title\",\"channel_title\",\"publish_time\",\"views\",\"likes\",\"dislikes\",\"comment_count\",\"category_id\",\"video_id\"]]\nustrends = ustrends[[\"trending_date\",\"title\",\"channel_title\",\"publish_time\",\"views\",\"likes\",\"dislikes\",\"comment_count\",\"category_id\",\"video_id\"]]\ndetrends = detrends[[\"trending_date\",\"title\",\"channel_title\",\"publish_time\",\"views\",\"likes\",\"dislikes\",\"comment_count\",\"category_id\",\"video_id\"]]\nfrtrends = frtrends[[\"trending_date\",\"title\",\"channel_title\",\"publish_time\",\"views\",\"likes\",\"dislikes\",\"comment_count\",\"category_id\",\"video_id\"]]\nintrends = intrends[[\"trending_date\",\"title\",\"channel_title\",\"publish_time\",\"views\",\"likes\",\"dislikes\",\"comment_count\",\"category_id\",\"video_id\"]]\ngbtrends = gbtrends[[\"trending_date\",\"title\",\"channel_title\",\"publish_time\",\"views\",\"likes\",\"dislikes\",\"comment_count\",\"category_id\",\"video_id\"]]\n\n","c77e1db3":"ustrends.trending_date.unique()","5c4b6c2e":"#detecting how much trend data per a day\ndataperday=0\ntrenddays = [int(each.replace(\".\",\"\")) for each in ustrends[\"trending_date\"]]\nfor i in trenddays:\n    if(i==171411):\n        dataperday+=1\n    else:\n        break\nprint(dataperday)\n#we see that there are 200 content in a day.","6a5605dc":"ustrends.head()","99955cda":"ustrends.title.value_counts().values.mean()","c49efc80":"# times to stay in trend averages\nustrenddates = ustrends.title.value_counts().values.mean()\ncatrenddates = catrends.title.value_counts().values.mean()\ndetrenddates = detrends.title.value_counts().values.mean()\nfrtrenddates = frtrends.title.value_counts().values.mean()\ngbtrenddates = gbtrends.title.value_counts().values.mean()\nintrenddates = intrends.title.value_counts().values.mean()\n\nlabels = ['United States','Canada','Germany','France','United Kingdom','India']\npielist = [ustrenddates,catrenddates,detrenddates,frtrenddates,gbtrenddates,intrenddates]\n\n#figure\n\nfig = {\n    'data' : \n    [\n        {\n            \"values\": pielist,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .5]},\n          \"name\": \"General Stay in trend rates\",\n          \"hoverinfo\":\"label+percent+name\",\n          \"hole\": .25,\n          \"type\": \"pie\"\n        },\n    ],\n\n    'layout' :\n    {\n        \"title\":\"Trends According to Countries\",\n        \"annotations\": [\n            { \"font\": { \"size\": 20},\n              \"showarrow\": True,  # Title's arrow\n              \"text\": \"Average Trend Days\",\n                \"x\": 0.20,\n                \"y\": 1\n    },\n        ]\n    }\n}\niplot(fig)","aa5eaa1d":"#Adding Country column manually\ncatrends[\"Country\"] = \"Canada\"\ndetrends[\"Country\"] = \"Germany\"\nfrtrends[\"Country\"] = \"France\"\ngbtrends[\"Country\"] = \"United Kingdom\"\nintrends[\"Country\"] = \"India\"\nustrends[\"Country\"] = \"United States\"\n#sum of data of all countries\ngeneraltrends = pd.concat([catrends,detrends,frtrends,gbtrends,intrends,ustrends])\ngeneraltrends","4719c7b0":"generaltrends.groupby(['Country']).count()","57273192":"labels = generaltrends.groupby(['Country']).count().index\ndatasize = generaltrends.groupby(['Country']).count()[\"title\"]\n\n\n# import graph objects as \"go\"\nimport plotly.graph_objs as go\n\n#create trace1\ntrace1 = go.Bar(\n            x = labels,\n            y = datasize,\n            name = \"Number of Trend Videos\",\n            marker = dict(color = 'rgba(255, 174, 255, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n)\n\ndata = [trace1]\nlayout= go.Layout(barmode=\"group\")\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n                ","6fc31149":"# trends.likes.value_counts().sum() is number of liked videos\n# ustrends.likes.sum()    sum of all likes\ncountrylikerate = []\ncountrydislikerate = []\ncountryviewrate = []\ncountrycommentrate = []\ncountrylist = list(generaltrends.Country.unique())\nfor i in countrylist:\n    likes = generaltrends.likes[generaltrends.Country ==i] #like numbers for each country\n    likerates = sum(likes)\/len(likes)\n    countrylikerate.append(likerates)\n    \nfor j in countrylist:\n    dislikes = generaltrends.dislikes[generaltrends.Country ==j] #like numbers for each country\n    dislikerates = sum(dislikes)\/len(dislikes)\n    countrydislikerate.append(dislikerates)\n\nfor k in countrylist:\n    views = generaltrends.views[generaltrends.Country ==k] #like numbers for each country\n    viewrates = sum(views)\/len(views)\n    countryviewrate.append(viewrates)\nfor l in countrylist:\n    comments = generaltrends.comment_count[generaltrends.Country ==l] #like numbers for each country\n    commentrates = sum(comments)\/len(comments)\n    countrycommentrate.append(commentrates)\n\n\n#creating traces\ntrace1 = go.Bar(\n                x = countrylist,\n                y = countrylikerate,\n                name = \"Like Rates For Trend Videos\",\n                marker = dict(color = 'rgba(255, 174, 255, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = countrylist)\n\ntrace2 = go.Bar(\n                x = countrylist,\n                y = countrydislikerate,\n                name = \"Dislike Rates For Trend Videos\",\n                marker = dict(color = 'rgba(25, 174, 55, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = countrylist)\n\n\ntrace3 = go.Bar(\n                x = countrylist,\n                y = countryviewrate,\n                name = \"View Rates For Trend Videos\",\n                marker = dict(color = 'rgba(255, 174, 55, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = countrylist)\n\n\ntrace4 = go.Bar(\n                x = countrylist,\n                y = countrycommentrate,\n                name = \"Comment Rates For Trend Videos\",\n                marker = dict(color = 'rgba(25, 174, 255, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = countrylist)\n\n\ndata = [trace1,trace2,trace3,trace4]\nlayout = go.Layout(barmode = \"group\")\nfig = go.Figure(data=data,layout = layout)\niplot(fig)","201625fa":"#inserting categories from json files\ngeneraltrends[\"category_id\"] = generaltrends[\"category_id\"].astype(str)\ngeneraltrends_full['category_id'] = generaltrends_full['category_id'].astype(str)  # we store original data\n\n\ncategory_id = {}\n\nwith open('..\/input\/youtube-new\/US_category_id.json', 'r') as f:\n    data = json.load(f)\n    for category in data['items']:\n        category_id[category['id']] = category['snippet']['title']\n        \ngeneraltrends.insert(4, 'category', generaltrends['category_id'].map(category_id))\ngeneraltrends_full.insert(4, 'category', generaltrends_full['category_id'].map(category_id))\n","ca639a4a":"#From Canada \n\nlabels = generaltrends.category[generaltrends[\"Country\"] == \"Canada\"].value_counts().index\ndata = generaltrends.category[generaltrends[\"Country\"] == \"Canada\"].value_counts().values\n\n#visualization\nplt.figure(figsize=(15,8))\nax = sns.barplot(y=labels,x=data)\nplt.grid()\nplt.title(\"Youtube Viewing Categories of Canada\",color=\"r\")\nplt.xlabel(\"View value of Categories\",color=\"gray\")\nplt.ylabel(\"Categories\",color=\"gray\")","a201a24c":"#From Germany\n\nlabels = generaltrends.category[generaltrends[\"Country\"] == \"Germany\"].value_counts().index\ndata = generaltrends.category[generaltrends[\"Country\"] == \"Germany\"].value_counts().values\n\n#visualization\nplt.figure(figsize=(15,8))\nax = sns.barplot(y=labels,x=data)\nplt.grid()\nplt.title(\"Youtube Viewing Categories of Germany\",color=\"r\")\nplt.xlabel(\"View value of Categories\",color=\"gray\")\nplt.ylabel(\"Categories\",color=\"gray\")","9493f1fb":"#From France\n\nlabels = generaltrends.category[generaltrends[\"Country\"] == \"France\"].value_counts().index\ndata = generaltrends.category[generaltrends[\"Country\"] == \"France\"].value_counts().values\n\n#visualization\nplt.figure(figsize=(15,8))\nax = sns.barplot(y=labels,x=data)\nplt.grid()\nplt.title(\"Youtube Viewing Categories of France\",color=\"r\")\nplt.xlabel(\"View value of Categories\",color=\"gray\")\nplt.ylabel(\"Categories\",color=\"gray\")","d729afae":"#From United Kingdom \n\nlabels = generaltrends.category[generaltrends[\"Country\"] == \"United Kingdom\"].value_counts().index\ndata = generaltrends.category[generaltrends[\"Country\"] == \"United Kingdom\"].value_counts().values\n\n#visualization\nplt.figure(figsize=(15,8))\nax = sns.barplot(y=labels,x=data)\nplt.grid()\nplt.title(\"Youtube Viewing Categories of United Kingdom\",color=\"r\")\nplt.xlabel(\"View value of Categories\",color=\"gray\")\nplt.ylabel(\"Categories\",color=\"gray\")","e378847a":"#From India\n\nlabels = generaltrends.category[generaltrends[\"Country\"] == \"India\"].value_counts().index\ndata = generaltrends.category[generaltrends[\"Country\"] == \"India\"].value_counts().values\n\n#visualization\nplt.figure(figsize=(15,8))\nax = sns.barplot(y=labels,x=data)\nplt.grid()\nplt.title(\"Youtube Viewing Categories of India\",color=\"r\")\nplt.xlabel(\"View value of Categories\",color=\"gray\")\nplt.ylabel(\"Categories\",color=\"gray\")","be4251d7":"#From United States\n\nlabels = generaltrends.category[generaltrends[\"Country\"] == \"United States\"].value_counts().index\ndata = generaltrends.category[generaltrends[\"Country\"] == \"United States\"].value_counts().values\n\n#visualization\nplt.figure(figsize=(15,8))\nax = sns.barplot(y=labels,x=data)\nplt.grid()\nplt.title(\"Youtube Viewing Categories of United States of America\",color=\"r\")\nplt.xlabel(\"View value of Categories\",color=\"gray\")\nplt.ylabel(\"Categories\",color=\"gray\")","a9ba96d9":"# INTRODUCTION\n* In this kernel, we will investigate youtube trends.\n\n<br>Content:\n1. [Loading Data](#1)\n1. [Basic skimming on our data](#2)\n1. [How long usually a Video Can Trend in Different Countries](#3)\n1. [Number of Youtube Trending Videos in 6 countries](#4)\n1. [How many likes, dislikes, views and comments get by different countries](#5)\n1. [ Users like videos from which CATEGORY the most?](#6)","372c12f9":"<a id=\"1\"><\/a> <br>\n# Loading Datas","faa1c019":"### Observation\n\nAccording to the pie plot, it can be seen that United Kingdom at top of the enduring trend list follow by US and India. Unlike that 3 countries, Canada, Germany and France have very few video can last long in trending.","3fddbfd7":"<a id=\"4\"><\/a> <br>\n## Number of Youtube Trending Videos in 6 countries","3ce571c5":"<a id=\"2\"><\/a> <br>\n## Basic skimming on our data","d79be11e":"<a id=\"5\"><\/a> <br>\n## How many likes, dislikes, views and comments get by different countries?","23e1f1da":"### Observation\nAccording to bar plot, we observe that in UK, People genererally watch and like videos unlike their low population according to USA and India. They watch youtube videos million times. Of course this data is coming from trend videos so we deduce that people watch same contents simultaneously. UK citizens can be manipulated easily by popular youtube content creators.","2bb624d8":"### Setting datas what we need\n### Escaping from unnecessary columns actually","e567732a":"<a id=\"3\"><\/a> <br>\n## How long usually a video can trend in different countries","400b05f7":"<a id=\"6\"><\/a> <br>\n# Users like videos from which CATEGORY the most?"}}