{"cell_type":{"911d8ad1":"code","8e8c6bef":"code","609fc548":"code","2370e59d":"code","54325f10":"code","0729294e":"code","615cf5fa":"code","eaae5bae":"code","86fdff38":"code","e54e4ad2":"code","01ee2250":"code","dac734da":"code","b8ca5b05":"code","5b2df7b4":"code","02dbbc95":"code","ec6df925":"code","59cbb91e":"code","b8a711c9":"code","0ff1ce5a":"code","32733797":"markdown"},"source":{"911d8ad1":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport re","8e8c6bef":"data = pd.read_csv('..\/input\/lstm-sentiment-analysis\/Sentiment.csv')\ndata.head()","609fc548":"data[\"sentiment\"].unique()","2370e59d":"data.columns","54325f10":"data.shape","0729294e":"data[\"text\"].head()","615cf5fa":"data = data[[\"text\" , \"sentiment\"]]\ndata.head()","eaae5bae":"#removing 'Nentral' i just need Positive and Ngative\ndata = data[data.sentiment != 'Neutral']\ndata['sentiment'].unique()","86fdff38":"#converting all words to lowercase , and then remove all special characters\ndata[\"text\"] = data[\"text\"].apply(lambda x : x.lower())\ndata[\"text\"] = data[\"text\"].apply(lambda x : re.sub('[^a-zA-Z0-9\\s]' , ' ' , x))\n\ndata[\"text\"].head()","e54e4ad2":"#remove 'rt'\nfor idx , row in data.iterrows():\n    row[0] = row[0].replace('rt' , '')\n    \ndata['text'].head() ","01ee2250":"#the number of Positive and Negative values\nprint(\"The number of Positive values = \" , data[data.sentiment == \"Positive\"].size)\nprint(\"The number of Negative values = \" , data[data['sentiment'] =='Negative'].size)","dac734da":"max_features= 2000\ntokenizer = keras.preprocessing.text.Tokenizer(num_words=max_features , split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = keras.preprocessing.sequence.pad_sequences(X)\n\nX.shape","b8ca5b05":"#splitting the data\ny = pd.get_dummies(data['sentiment']).values\nvalidation_size = 1500\nX_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.33 , random_state = 42 , shuffle = True)\nX_valid , y_valid = X_test[:validation_size] , y_test[:validation_size]\nX_test , y_test = X_test[validation_size:] , y_test[validation_size:]\nX_train.shape , X_valid.shape , X_test.shape","5b2df7b4":"#building the LSTM model\nembed_dim = 128\nlstm_out = 196\n\nmodel = keras.models.Sequential([\n    keras.layers.Embedding(max_features , embed_dim , input_length = X.shape[1]),\n    keras.layers.SpatialDropout1D(0.3),\n    keras.layers.LSTM(lstm_out , dropout = 0.2 , recurrent_dropout = 0.2),\n    keras.layers.Dense(2 , activation = 'softmax')\n])\n\nmodel.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])\nmodel.summary()","02dbbc95":"#fitting the model\nbatch_size = 32\nmodel.fit(X_train , y_train , batch_size = batch_size , epochs = 10 ,verbose = 2,  validation_data=(X_valid , y_valid))","ec6df925":"#evaluate the model\nscore , accuracy = model.evaluate(X_test , y_test , verbose = 2 , batch_size = batch_size)\nprint(\"score : %.2f\"%score)\nprint(\"accuracy : %.2f\"%accuracy)","59cbb91e":"#test a predicted tweet\ntwt = ['The life is very good and all peoples are happy']\n\ntwt = tokenizer.texts_to_sequences(twt)\ntwt = keras.preprocessing.sequence.pad_sequences(twt , maxlen= 28 , dtype = 'int32' , value = 0)\nprint(twt)","b8a711c9":"sentiment = model.predict(twt , batch_size = 1 , verbose = 2)[0]","0ff1ce5a":"#checking positive or negative\nif(np.argmax(sentiment) == 0):\n    print(\"negative\")\nelif (np.argmax(sentiment) == 1):\n    print(\"positive\")","32733797":"**Thank you !**"}}