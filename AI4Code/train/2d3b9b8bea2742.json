{"cell_type":{"fd20afb0":"code","7d8d3b49":"code","c6be6680":"code","5d386b07":"code","63d5b9d1":"code","c722809f":"code","0aded6eb":"code","56249ca9":"code","c380f3c3":"code","6645f428":"code","de2a1001":"code","29d47b0c":"code","82549073":"code","cdbc49b2":"code","3f33b950":"code","47ebf679":"markdown","4fd8abae":"markdown","c42da44e":"markdown","980df0cf":"markdown","09d282ce":"markdown","789dc729":"markdown","f6e41cbc":"markdown"},"source":{"fd20afb0":"!pip install '\/kaggle\/input\/dlibpkg\/dlib-19.19.0'\n","7d8d3b49":"!pip install '\/kaggle\/input\/face-recognition\/face_recognition_models-0.3.0\/face_recognition_models-0.3.0'\n","c6be6680":"!pip install '\/kaggle\/input\/face-recognition\/face_recognition-0.1.5-py2.py3-none-any.whl'\n","5d386b07":"!pip install '\/kaggle\/input\/imageio-ffmpeg\/imageio_ffmpeg-0.3.0-py3-none-manylinux2010_x86_64.whl'\n","63d5b9d1":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nimport glob\nimport cv2\nfrom albumentations import *\nfrom tqdm import tqdm_notebook as tqdm\nimport gc\n\nfrom keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\nfrom keras.optimizers import Adam\nimport face_recognition\nimport imageio\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')\nPATH = '..\/input\/deepfake-detection-challenge\/'\nprint(os.listdir(PATH))","c722809f":"for dirname, _, filenames in os.walk('\/kaggle\/input\/meso-pretrain'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0aded6eb":"from IPython.display import HTML\nfrom base64 import b64encode\nvid1 = open('\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/ytddugrwph.mp4','rb').read()\ndata_url = \"data:video\/mp4;base64,\" + b64encode(vid1).decode()\nHTML(\"\"\"\n<video width=600 controls>\n      <source src=\"%s\" type=\"video\/mp4\">\n<\/video>\n\"\"\" % data_url)","56249ca9":"class Video:\n    def __init__(self, path):\n        self.path = path\n        self.container = imageio.get_reader(path, 'ffmpeg')\n        self.length = self.container.count_frames()\n#         self.length = self.container.get_meta_data()['nframes']\n        self.fps = self.container.get_meta_data()['fps']\n    \n    def init_head(self):\n        self.container.set_image_index(0)\n    \n    def next_frame(self):\n        self.container.get_next_data()\n    \n    def get(self, key):\n        return self.container.get_data(key)\n    \n    def __call__(self, key):\n        return self.get(key)\n    \n    def __len__(self):\n        return self.length","c380f3c3":"IMGWIDTH = 256\n\nclass Classifier:\n    def __init__():\n        self.model = 0\n    \n    def predict(self, x):\n        return self.model.predict(x)\n    \n    def fit(self, x, y):\n        return self.model.train_on_batch(x, y)\n    \n    def get_accuracy(self, x, y):\n        return self.model.test_on_batch(x, y)\n    \n    def load(self, path):\n        self.model.load_weights(path)\n\n\nclass Meso4(Classifier):\n    def __init__(self, learning_rate = 0.001):\n        self.model = self.init_model()\n        optimizer = Adam(lr = learning_rate)\n        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n    \n    def init_model(self): \n        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n        \n        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n        x1 = BatchNormalization()(x1)\n        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n        \n        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n        x2 = BatchNormalization()(x2)\n        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n        \n        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n        x3 = BatchNormalization()(x3)\n        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n        \n        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n        x4 = BatchNormalization()(x4)\n        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n        \n        y = Flatten()(x4)\n        y = Dropout(0.5)(y)\n        y = Dense(16)(y)\n        y = LeakyReLU(alpha=0.1)(y)\n        y = Dropout(0.5)(y)\n        y = Dense(1, activation = 'sigmoid')(y)\n\n        return KerasModel(inputs = x, outputs = y)\n\nclass MesoInception4(Classifier):\n    def __init__(self, learning_rate = 0.001):\n        self.model = self.init_model()\n        optimizer = Adam(lr = learning_rate)\n        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n    \n    def InceptionLayer(self, a, b, c, d):\n        def func(x):\n            x1 = Conv2D(a, (1, 1), padding='same', activation='relu')(x)\n            \n            x2 = Conv2D(b, (1, 1), padding='same', activation='relu')(x)\n            x2 = Conv2D(b, (3, 3), padding='same', activation='relu')(x2)\n            \n            x3 = Conv2D(c, (1, 1), padding='same', activation='relu')(x)\n            x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='relu')(x3)\n            \n            x4 = Conv2D(d, (1, 1), padding='same', activation='relu')(x)\n            x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='relu')(x4)\n\n            y = Concatenate(axis = -1)([x1, x2, x3, x4])\n            \n            return y\n        return func\n    \n    def init_model(self):\n        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n        \n        x1 = self.InceptionLayer(1, 4, 4, 2)(x)\n        x1 = BatchNormalization()(x1)\n        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n        \n        x2 = self.InceptionLayer(2, 4, 4, 2)(x1)\n        x2 = BatchNormalization()(x2)\n        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n        \n        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n        x3 = BatchNormalization()(x3)\n        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n        \n        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n        x4 = BatchNormalization()(x4)\n        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n        \n        y = Flatten()(x4)\n        y = Dropout(0.5)(y)\n        y = Dense(16)(y)\n        y = LeakyReLU(alpha=0.1)(y)\n        y = Dropout(0.5)(y)\n        y = Dense(1, activation = 'sigmoid')(y)\n\n        return KerasModel(inputs = x, outputs = y)","6645f428":"tf.test.is_gpu_available(\n    cuda_only=False,\n    min_cuda_compute_capability=None\n)","de2a1001":"classifier = Meso4()\nclassifier.load('\/kaggle\/input\/meso-pretrain\/Meso4_DF')\n\n# classifier = MesoInception4()\n# classifier.load('\/kaggle\/input\/meso-pretrain\/MesoInception_DF')\n\n# 0 fake\n# 1 real ","29d47b0c":"submit = []","82549073":"save_interval = 150 # perform face detection every {save_interval} frames\nmargin = 0.2\nfor vi in os.listdir('\/kaggle\/input\/deepfake-detection-challenge\/test_videos'):\n#     print(os.path.join(\"\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/\", vi))\n    re_video = 0.5\n    try:\n        video = Video(os.path.join(\"\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/\", vi))\n        re_imgs = []\n        for i in range(0,video.__len__(),save_interval):\n            img = video.get(i)\n            face_positions = face_recognition.face_locations(img)\n            for face_position in face_positions:\n                offset = round(margin * (face_position[2] - face_position[0]))\n                y0 = max(face_position[0] - offset, 0)\n                x1 = min(face_position[1] + offset, img.shape[1])\n                y1 = min(face_position[2] + offset, img.shape[0])\n                x0 = max(face_position[3] - offset, 0)\n                face = img[y0:y1,x0:x1]\n\n                inp = cv2.resize(face,(256,256))\/255.\n                re_img = classifier.predict(np.array([inp]))\n    #             print(vi,\": \",i , \"  :  \",classifier.predict(np.array([inp])))\n                re_imgs.append(re_img[0][0])\n        re_video = np.average(re_imgs)\n        if np.isnan(re_video):\n            re_video = 0.5\n    except:\n        re_video = 0.5\n    submit.append([vi,1.0-re_video])\n#     submit.append([vi,re_video])\n\n#     submit[vi] = 1.0-re_video\n#     print(vi,\": \",str(1.0-re_video))\n","cdbc49b2":"submission = pd.DataFrame(submit, columns=['filename', 'label']).fillna(0.5)\nsubmission.sort_values('filename').to_csv('submission.csv', index=False)","3f33b950":"submission","47ebf679":"# Predict","4fd8abae":"read video and extract frame from video","c42da44e":"# Read video","980df0cf":"# Load model","09d282ce":" predict video by combie image","789dc729":"First import all dataset contain library you need.<br>\n\nTo install dlib without internet, add the dataset: https:\/\/www.kaggle.com\/carlossouza\/dlibpkg <br>\nTo install ace-recognition without internet, add the dataset: https:\/\/www.kaggle.com\/minhtam\/face-recognition<br>\nTo install ace-recognition without internet, add the dataset: https:\/\/www.kaggle.com\/minhtam\/imageio-ffmpeg<br>\n","f6e41cbc":"# Model Meso4"}}