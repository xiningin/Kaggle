{"cell_type":{"110e9658":"code","6e81543f":"code","0d6641a9":"code","0f8a002d":"code","b9062351":"code","016dd030":"code","6efe9455":"code","48257acb":"code","9820f893":"code","b8da6da8":"code","f79c72f8":"code","8504d6d1":"code","04815643":"code","c9600cd9":"code","29c8bee7":"code","703ac9f4":"code","046659cf":"code","dee6c6a5":"code","988bdedd":"code","40065856":"code","6979e731":"code","2aa1e7c6":"markdown","9126700b":"markdown","5e4b59de":"markdown","a9f4cf76":"markdown","5b174792":"markdown","67745b30":"markdown","7b245b0e":"markdown","81c93389":"markdown","c4f17358":"markdown","042d7ab9":"markdown","84034539":"markdown","9dd09a6e":"markdown","3bac87ba":"markdown","8438af72":"markdown","f605d352":"markdown","d2dcdc68":"markdown","4f60c200":"markdown","8252845f":"markdown"},"source":{"110e9658":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6e81543f":"import pandas as pd \ntrain_df = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv',sep=',')\ntest_df = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv', sep = ',')","0d6641a9":"train_df.head()","0f8a002d":"train_df.label.unique()","b9062351":"# Mapping Classes\nclothing = {0 : 'T-shirt\/top',\n            1 : 'Trouser',\n            2 : 'Pullover',\n            3 : 'Dress',\n            4 : 'Coat',\n            5 : 'Sandal',\n            6 : 'Shirt',\n            7 : 'Sneaker',\n            8 : 'Bag',\n            9 : 'Ankle boot'}","016dd030":"print(train_df.isnull().any().sum())\nprint(test_df.isnull().any().sum())","6efe9455":"import numpy as np\ntrain_data = np.array(train_df, dtype = 'float32')\ntest_data = np.array(test_df, dtype='float32')","48257acb":"x_train = train_data[:,1:]\/255 #Skip 1st column as it is a label data\ny_train = train_data[:,0] # 1st column is label\nx_test= test_data[:,1:]\/255\ny_test=test_data[:,0]","9820f893":"from sklearn.model_selection import train_test_split\nx_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 1)\nprint(\"x_train shape: \" + str(x_train.shape))\nprint(\"x_validate shape: \" + str(x_validate.shape))\nprint(\"x_test shape: \" + str(x_test.shape))\nprint(\"y_train shape: \" + str(y_train.shape))\nprint(\"y_validate shape: \" + str(y_validate.shape))\nprint(\"y_test shape: \" + str(y_test.shape))","b8da6da8":"height = width = 28\nx_train = x_train.reshape(x_train.shape[0],height,width,1)\nx_validate = x_validate.reshape(x_validate.shape[0],height,width,1)\nx_test = x_test.reshape(x_test.shape[0],height,width,1)\nprint(\"x_train shape: \" + str(x_train.shape))\nprint(\"x_validate shape: \" + str(x_validate.shape))\nprint(\"x_test shape: \" + str(x_test.shape))","f79c72f8":"from keras.models import Sequential\nfrom keras.layers import Activation,Conv2D, MaxPooling2D, BatchNormalization, Dense, Dropout, Flatten\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),kernel_initializer='glorot_uniform',input_shape=(height, width, 1),name='conv0'))\nmodel.add(BatchNormalization(axis = 1, name = 'bn0'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name='max_pool0'))\nmodel.add(Dropout(0.25))\n          \nmodel.add(Conv2D(64, kernel_size=(3, 3), name='conv1'))\nmodel.add(BatchNormalization(axis = 1, name = 'bn1'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name='max_pool1'))\nmodel.add(Dropout(0.25))\n          \nmodel.add(Conv2D(128, (3, 3), activation='relu', name='conv2'))\n\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu',name = 'fc'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()","8504d6d1":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nplot_model(model, to_file='model.png')\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","04815643":"model.compile(loss ='sparse_categorical_crossentropy', optimizer= 'Adam',metrics =['accuracy'])","c9600cd9":"history = model.fit(x_train,y_train,batch_size=128,epochs=50,verbose=1,validation_data=(x_validate,y_validate))","29c8bee7":"import matplotlib.pyplot as plt\n\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validate'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validate'], loc='upper left')\nplt.show()","703ac9f4":"score = model.evaluate(x_test, y_test)\nprint('Loss: '+ str(score[0]))\nprint('Accuracy: '+ str(score[1]))","046659cf":"#get the predictions for the test data\npredicted_classes = model.predict_classes(x_test)\n\n#get the indices to be plotted\ny_true = test_df.iloc[:, 0]\n\nclasses = ['T-shirt\/Top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_true, predicted_classes, target_names = classes))","dee6c6a5":"confusion_mtx = confusion_matrix(y_true, predicted_classes) \nprint(confusion_mtx)","988bdedd":"import itertools\nplt.imshow(confusion_mtx, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('confusion_matrix')\nplt.colorbar()\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=90)\nplt.yticks(tick_marks, classes)\n#Following is to mention the predicated numbers in the plot and highligh the numbers the most predicted number for particular label\nthresh = confusion_mtx.max() \/ 2.\nfor i, j in itertools.product(range(confusion_mtx.shape[0]), range(confusion_mtx.shape[1])):\n    plt.text(j, i, confusion_mtx[i, j],\n    horizontalalignment=\"center\",\n    color=\"white\" if confusion_mtx[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","40065856":"correct = np.nonzero(predicted_classes==y_true)[0]\ni = 1\nfor correct in np.nditer(correct[:9]):\n    plt.subplot(3,3,i)\n    i += 1\n    plt.imshow(x_test[correct].reshape(28,28), cmap='Greens', interpolation='none')\n    plt.title(\"Predicted : \" + str(clothing[predicted_classes[correct]]) + \"\\n\"+\"Actual : \" + str(clothing[y_true[correct]]))\n    plt.tight_layout()","6979e731":"incorrect = np.nonzero(predicted_classes!=y_true)[0]\ni = 1\nfor incorrect in np.nditer(incorrect[:9]):\n    plt.subplot(3,3,i)\n    i += 1\n    print()\n    plt.imshow(x_test[incorrect].reshape(28,28), cmap='Reds', interpolation='none')\n    plt.title(\"Predicted : \" + str(clothing[predicted_classes[incorrect]]) + \"\\n\"+\"Actual : \" + str(clothing[y_true[incorrect]]))\n    plt.tight_layout()","2aa1e7c6":"Split training data as 80% training set and 20% validation set using scikit learn's train_test_split method.\nValidation set will not update weights and bias of the neural network. \nIt is used to verify neural network performance before validating on test data.","9126700b":"Let's define a CNN model.","5e4b59de":"Let's have a look at classification report which provides details about precision, recall and f1-score.","a9f4cf76":"Let's check few items which are predicted incorrectly.","5b174792":"Check if there is any NaN value or not","67745b30":"Convert dataframes into numpy array so it can be feed to the convolution neural network which will be created using tensorflow and keras.","7b245b0e":"Compile the model","81c93389":"Plot the model","c4f17358":"Let's check few items which are predicted correctly.","042d7ab9":"Reshape the x data array in the shape (no of elements, image height, image width, channels). As these are not RGB image, here channel is 1.","84034539":"Train the model on fix number of epochs (iteration of training set).\nHere batch size indicate that after 128 training data (here 1 batch) weights and bias updates during single epoch training.","9dd09a6e":"Separate label data as y and image data as x and rescale it to (0,1) range from (0,255) range","3bac87ba":"Let's plot the confution matrix for better visulization","8438af72":"Let's check model's performance using confution matrix.\n\n[More details on confusion matrix](https:\/\/towardsdatascience.com\/understanding-confusion-matrix-a9ad42dcfd62)\n\n[Other ways to evaluate model's performance](https:\/\/towardsdatascience.com\/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15)","f605d352":"Here 1st column is label and rest of columns have values for the 784 pixels - 28 x 28 image size. ","d2dcdc68":"Let's read the csv files using pandas read_csv which provides data in form of pandas dataframe.","4f60c200":"Let's have a look at the data","8252845f":"Let's evaluate the model on test set"}}