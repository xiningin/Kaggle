{"cell_type":{"44a09943":"code","3b3cb320":"code","38c5473f":"code","9c46bd53":"code","748cec72":"code","e560cc53":"code","6fec11d7":"code","3f18ec70":"code","f19d3702":"code","c659c99c":"code","3eaa2eae":"code","35cec58a":"code","23e945b4":"code","2bf452ac":"code","183a1488":"code","7602b47a":"code","88ea32c1":"code","18265f5c":"code","7f64e9e4":"code","9d42526e":"code","359aceea":"code","ac163eb8":"code","058ebbce":"code","dee20655":"code","6428fbc9":"code","1e8a150a":"code","e13a7698":"code","8321aa26":"code","1f84e2d3":"code","5ba70fe5":"code","d806799c":"code","1b00fa86":"code","9746efb3":"code","d1be65d1":"code","0e9be6d6":"markdown","9d20584c":"markdown","3dd7e61f":"markdown","8d739a0b":"markdown","0e05a2ab":"markdown","c1a36164":"markdown","790fb02d":"markdown","e6d38df8":"markdown","e30de3db":"markdown","e3a640d5":"markdown","800feb38":"markdown","b401ea44":"markdown","35c1b4a4":"markdown","77417791":"markdown","3cf18f45":"markdown","262fc77e":"markdown","40a860d3":"markdown","e55c38e4":"markdown","551001e0":"markdown","8f24a545":"markdown","66fdd07e":"markdown","b6f10ebd":"markdown","a546552c":"markdown","1afe8c35":"markdown","30aafdcc":"markdown"},"source":{"44a09943":"# Import dos m\u00f3dulos\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport sys\n\nfrom datetime import datetime\n\n#graficos\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#cross-validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n#modelos de ML\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC, NuSVC, LinearSVC\n\n#metricas\nimport sklearn.metrics as metrics\n\n#normaliza\u00e7\u00e3o\nfrom sklearn.preprocessing import Normalizer\n\n#dados de treino\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n#resample\nfrom sklearn.utils import resample\n\n#\nimport pickle\n\n#fun\u00e7\u00f5es \nimport funcoes as f","3b3cb320":"#!wget -O gold.parquet https:\/\/www.dropbox.com\/s\/3m0xqogz5gi2moy\/gold.parquet?dl=1","38c5473f":"#!ls \/content","9c46bd53":"work_dir = \"content\"\nwork_dir2 = 'RESULTADO_ML'\n\n#leitura dos dados de entrada\ndf_bruto = pd.read_parquet(work_dir +\"\/gold.parquet\", engine=\"pyarrow\")\ndf_bruto.shape","748cec72":"f.relatorio(df_bruto)","e560cc53":"df_bruto.info()","6fec11d7":"df_bruto.head(3)","3f18ec70":"# n\u00e3o iremos utilizar estas duas colunas no treinamento e no teste\ndf_preparado = df_bruto.drop(['key', 'timestamp'], axis=1)\n","f19d3702":"#criando o atributo dias_ultima_compra\ndf_preparado['dias_ultima_compra'] = df_preparado['ultima_compra'].apply(lambda x : f.diff_days(datetime.now().date(), x))\n\n#excluindo o atributo ultima_compra\ndf_preparado = df_preparado.drop(['ultima_compra'], axis=1)\ndf_preparado.head(1)","c659c99c":"df_preparado.groupby('cnae_id').size().sort_values(ascending = False).to_csv(\"cnae.csv\")\n","3eaa2eae":"#tratando valores nulos de cnae_id\ndf_preparado['cnae_id'] = df_preparado['cnae_id'].replace(np.nan,'0')","35cec58a":"#h\u00e1 valores cnae_id que s\u00e3o identicos em numeros, mas diferem na m\u00e1scara\n\ndf_preparado['cnae_id_mod']  = df_preparado['cnae_id'].map(f.somenteNumeros)\ndisplay(df_preparado.groupby('cnae_id').size().sort_values(ascending = False)       \n        , df_preparado.groupby('cnae_id_mod').size().sort_values(ascending = False))","23e945b4":"#retirando caracteres (\/-.) de cnae_id\n\ndf_preparado['cnae_id']  = df_preparado['cnae_id'].map(f.somenteNumeros)\n\n\ndf_preparado = df_preparado.drop(['cnae_id_mod'], axis=1)","2bf452ac":"df_preparado.sort_values(by = 'cnae_id', ascending  = False).head(1)","183a1488":"df_preparado.groupby('cnae_id').size().sort_values(ascending = False)","7602b47a":"# Substitui valores nulos por N\u00c3O INFORMADO nas colunas categ\u00f3ricas\ncolunas_cat =['city', 'state']\ndf_preparado[colunas_cat] = df_preparado[colunas_cat].fillna(value='N\u00c3O INFORMADO')","88ea32c1":"# Substitui valores nulos por 0 nas colunas num\u00e9ricas\ncolunas_numericas = ['pedidos_4_meses','pedidos_8_meses','pedidos_12_meses','itens_4_meses','itens_8_meses','itens_12_meses']\ndf_preparado[colunas_numericas] = df_preparado[colunas_numericas].fillna(value=0)\n\nf.relatorio(df_preparado)","18265f5c":"# n\u00e3o iremos utilizar estas duas colunas no treinamento e no teste\ndf_preparado = df_preparado.drop(['city', 'state'], axis=1)","7f64e9e4":"# transformar colunas categ\u00f3ricas em num\u00e9ricas\n#df_preparado = pd.get_dummies(df_preparado, columns=[\"city\", \"state\", \"cnae_id\"])\n\n\ndf_preparado = pd.get_dummies(df_preparado, columns=[\"cnae_id\"])\n#df_preparado.head(1)","9d42526e":"df_preparado.columns","359aceea":"#MELHORIA: AMPLIANDO OS DADOS DE TREINO\n# na primeira tentativa, foi considerado como dados de treino todo o conjunto de registros,\n# e dados de valida\u00e7\u00e3o os 20% do conjunto de registros\n\n\n## seleciona as tuplas com r\u00f3tulos\n#df_to_train = df_preparado[df_preparado[\"defaulting\"].notnull()]\n#\n## remove a coluna defaulting dos dados de treinamento para n\u00e3o gerar overfiting\n#X = df_to_train.drop('defaulting', axis=1)\n#\n## Transforma a vari\u00e1vel a predizer de boolean para inteiro\n#le = LabelEncoder()\n#y = le.fit_transform(df_to_train.defaulting.values)\n#\n## Divis\u00e3o em conjunto de treinamento e valida\u00e7\u00e3o (0.2)\n#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)","ac163eb8":"#MELHORIA: AMPLIANDO OS DADOS DE TREINO\n\n#X_train  = X\n#y_train  = y\n\n#print(X_train.shape)\n#print(y_train.shape)\n#print(X_valid.shape)\n#print(y_valid.shape)","058ebbce":"display(\"total: \", df_preparado.shape, \"defaulting\", df_preparado.groupby(\"defaulting\").size())","dee20655":"# seleciona as tuplas com r\u00f3tulos\ndf = df_preparado[df_preparado[\"defaulting\"].notnull()]\n\n# Transforma a vari\u00e1vel a predizer de boolean para inteiro\nle = LabelEncoder()\ndf['defaulting_int'] = le.fit_transform(df.defaulting.values)\n\n# remove a coluna defaulting dos dados de treinamento para n\u00e3o gerar overfiting\ndf = df.drop('defaulting', axis=1)\n\n#separando as classes\ndf_majoritario = df[df.defaulting_int ==0]\ndf_minoritario = df[df.defaulting_int ==1]\n\n\n# Fazer Upsample classe minorit\u00e1ria\ndf_minotirario_upsampled = resample(df_minoritario,\n                                 replace = True,     # sample with replacement\n                                 n_samples = len(df_majoritario),    # to match majority class\n                                 random_state = 123) # reproducible results\n\n# Fazer undersample classe majorit\u00e1ria\ndf_majoritario_undersampled = resample(df_majoritario,\n                                 replace=False,     # sample with replacement\n                                 n_samples=len(df_minoritario),    # to match majority class\n                                 random_state=123) # reproducible results\n\n# Combinar as classes novamente (undersampled)\ndf_undersampled = pd.concat([df_minoritario, df_majoritario_undersampled])\n\n# Combinar as classes novamente (upersampled)\ndf_upersampled = pd.concat([df_majoritario, df_minotirario_upsampled])\n\n\nprint(df_undersampled.shape)\nprint(df_upersampled.shape)\n","6428fbc9":"#pergundar qual tipo de sampler usar\n#tipo_resample = input(\"Digite 1 para undersampler ou 2 para upersample\")\ntipo_resample = '2'\nif (tipo_resample == '1'):\n    df_resampled = df_undersampled\nelse:\n    df_resampled = df_upersampled\n\n\n##REPROGRAMANDO VARIAVEIS\nX = df_resampled.drop('defaulting_int', axis=1)\nY = df_resampled['defaulting_int']\n","1e8a150a":"f.resumo(X, 5)","e13a7698":"#MELHORIA: NORMALIZA\u00c7\u00c3O\n#OBS.: foi implementado, em alguns cen\u00e1rios, a normaliza\u00e7\u00e3o dos dados, por\u00e9m sem muito ganho de acur\u00e1cia.\n\n## Gerando os dados normalizados\n#scaler = Normalizer().fit(X)\n#normalizedX = scaler.transform(X)\n#\n## Sumarizando os dados transformados\n#print(\"Dados Originais: \\n\\n\", X.values)\n#print(\"\\nDados Normalizados: \\n\\n\", normalizedX)","8321aa26":"#X = normalizedX\n#y = np.array(Y)\n\n## Divis\u00e3o em conjunto de treinamento e valida\u00e7\u00e3o\n#X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=1)\n#\n#\n#print(X_train.shape)\n#print(y_train.shape)\n#print(X_valid.shape)\n#print(y_valid.shape)","1f84e2d3":"## Divis\u00e3o em conjunto de treinamento e valida\u00e7\u00e3o\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=1)","5ba70fe5":"# Preparando a lista de modelos\n\nfrom sklearn.linear_model import LogisticRegression\n\nmodelos = []\nmodelos.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\nmodelos.append(('Decision_Tree_Classifier', DecisionTreeClassifier()))\n\n#ensemblers\nmodelos.append(('Random_Forest_Classifier', RandomForestClassifier()))\nmodelos.append(('AdaBoost_Classifier', AdaBoostClassifier()))\n\n#nearest neighbors\nmodelos.append(('KNeighbors_Classifier', KNeighborsClassifier()))\n\n#support vector classification\nmodelos.append(('SVC', SVC()))\n\n\nmodelos.append(('Logistic Regression', LogisticRegression()))\n\n# Avaliando cada modelo em um loop\nresultados = []\nnomes = []\n\n# Definindo os valores para o n\u00famero de folds\nnum_folds = 10\nseed = 7\n\nfor nome, modelo in modelos:\n    nomes.append(nome)\n\n    # cross validation\n    kfold = KFold(n_splits = num_folds, random_state = seed)\n    cv_results = cross_val_score(modelo, X_train, y_train, cv = kfold, scoring = 'accuracy')    \n    #cv_results = cross_val_score(modelo, X, Y, cv = kfold, scoring = 'accuracy')    \n    resultados.append(cv_results)\n    msg = \"Score cross-validation de %s: M\u00e9dia: %f, Desvio padr\u00e3o: (%f)\" % (nome, cv_results.mean(), cv_results.std())\n    print(msg)   \n\n    #Treinando o modelo\n    modelo = modelo.fit(X_train,y_train) \n\n    # Salvando o modelo\n    arquivo = work_dir2 +\"\/\"+nome+\".sav\"\n    pickle.dump(modelo, open(arquivo, 'wb'))\n    msg2 = \"Modelo \"+nome+\" salvo!\"\n    print(msg2)\n","d806799c":"#dados de teste\n\ndf_test = df_preparado[df_preparado[\"defaulting\"].isnull()]\nX_test = df_test.drop('defaulting', axis=1)\ndf_test.shape","1b00fa86":"df_test","9746efb3":"for nome, modelo in modelos:\n    arquivo = work_dir2 +\"\/\"+nome+\".sav\"\n  # Carregando o arquivo\n    modelo_carregado = pickle.load(open(arquivo, 'rb'))\n    msg3 = \"Modelo \"+nome+\" carregado!\"\n    print(msg3)\n\n  # Print do resultado\n  # Fazendo previs\u00f5es com os dados de valida\u00e7\u00e3o\n    y_pred = modelo.predict(X_valid)  \n \n  # Resultado\n    print(\"M\u00e9tricas de \"+nome)\n    print(\"ROC AUC:\",metrics.roc_auc_score(y_valid, y_pred)) \n    print(\"Acur\u00e1cia:\",metrics.accuracy_score(y_valid, y_pred)) \n    print(\"F1 score:\",metrics.f1_score(y_valid, y_pred))\n    print(\"************************************\")\n    \n  # Fazendo previs\u00f5es com os dados de teste\n    y_test = modelo.predict(X_test)\n\n  #Resultado final\n    output = df_test.assign(inadimplente = y_test)\n    output = output.loc[:, ['client_id','inadimplente']]\n\n  #Salvando o resultado final\n    output.to_csv(work_dir2 +\"\/\"+nome+\".csv\", index=False)\n","d1be65d1":"#from google.colab import files\n\n#for nome in nomes:\n#    files.download(nome+\".csv\") ","0e9be6d6":"Foi utilizado o df_upersampled para o treinamento, por possuir 14000 registros.","9d20584c":"A sa\u00edda do modelo \u00e9 salvo em um arquivo csv, contendo as colunas \"client_id\" e \"inadimplente\". Estas colunas ser\u00e3o utilizadas para avaliar a acur\u00e1cia do modelo. Por isso, o resultado da predi\u00e7\u00e3o em *y_test* \u00e9 adicionada em uma nova coluna (inadimplente) do DataFrame df_test.","3dd7e61f":"## Classifica\u00e7\u00e3o utilizando Pandas e Scikit-learn\n\nNeste notebook iremos fazer a predizer os clientes inadimplentes utilizando a biblioteca [Scikit-learn](https:\/\/scikit-learn.org\/) e o Pandas. Iremos desenvolver, neste notebook, um modelo capaz de predizer se o cliente est\u00e1 ou n\u00e3o inadimplente, ou seja, uma tarefa de classifica\u00e7\u00e3o bin\u00e1ria.","8d739a0b":"## Leitura dos dados\n\nO trecho de c\u00f3digo abaixo cria uma vari\u00e1vel *work_dir*, que ir\u00e1 apontar para o caminho no sistema de arquivos onde est\u00e3o os dados de entrada e onde a sa\u00edda ser\u00e1 escrita. Como os dados de entrada est\u00e3o no formato Parquet, o Pandas ir\u00e1 utilizar o motor de leitura Pyarrow para conseguir ler este formato de dados e aumentar a performance de leitura e transforma\u00e7\u00f5es no DataFrame.","0e05a2ab":"Os dados de teste s\u00e3o gerados e armazenados em *X_test*, excluindo a coluna *defaulting* que desejamos predizer. O modelo faz a predi\u00e7\u00e3o e tem como sa\u00edda os valores da predi\u00e7\u00e3o em *y_test*.","c1a36164":"## Considera\u00e7\u00f5es Finais\n\nAgora \u00e9 com **voc\u00ea**! Ainda existe muito espa\u00e7o para melhoria na acur\u00e1cia do modelo que desenvolvemos at\u00e9 agora. Utilize o material complementar abaixo para modificar este notebook e construir um algoritmo melhor.\n\n- [Curso de Aprendizado de M\u00e1quina de Stanford com Andrew Ng](https:\/\/www.coursera.org\/learn\/machine-learning)\n- [M\u00e3os \u00e0 Obra: Aprendizado de M\u00e1quina com Scikit-Learn & TensorFlow](https:\/\/www.amazon.com.br\/M%C3%A3os-Obra-Aprendizado-Scikit-Learn-TensorFlow\/dp\/8550803812)\n- [Introduction to Machine Learning with Python](https:\/\/www.amazon.com.br\/Introduction-Machine-Learning-Andreas-Mueller\/dp\/1449369413)\n- [Data Science do Zero](https:\/\/www.amazon.com.br\/Data-Science-zero-Joel-Grus\/dp\/857608998X)\n- [Customer Churn Classification Using Predictive Machine Learning Models](https:\/\/towardsdatascience.com\/customer-churn-classification-using-predictive-machine-learning-models-ab7ba165bf56)","790fb02d":"*MELHORIA: TRATAMENTO DE NULOS EM ATRIBUTOS CATEGORICOS E NUMERICOS*","e6d38df8":"## Preparando o ambiente\n\n","e30de3db":"Foram testados alguns cen\u00e1rios de pre-processamento, conforme pode ser visto no [RELAT\u00d3RIO DE TESTES](#5)    ","e3a640d5":"O Dataframe *output* \u00e9 escrito no formato CSV para gerar a sa\u00edda do algoritmo de aprendizado de m\u00e1quina constru\u00eddo neste notebook.","800feb38":"## Predi\u00e7\u00e3o sobre os dados de testes\n\nNesta \u00faltima etapa, o modelo busca predizer se o cliente est\u00e1 ou n\u00e3o inadimplente sobre os dados de teste (coluna defaulting igual a nulo). Os dados de teste ficar\u00e3o armazenados no DataFrame *df_test*. ","b401ea44":"*MELHORIA: TRATAMENTO DE NULOS E EXCLUS\u00c3O DE CARACTERES ESPECIAIS EM CNAE_ID*  \n\nObs.: retirei os caracteres do campo cnae_id, para reduzir a quantidade de atributos gerados com a fun\u00e7\u00e3o get_dummies, pois foi constatado que havia ids que eram id\u00eanticos em n\u00fameros, mas n\u00e3o na m\u00e1scara.   \nAp\u00f3s fazer o treinamento com e sem esse tratamento, constatou-se que houve pouca diferen\u00e7a na pontua\u00e7\u00e3o, conforme pode ser visto no [RELAT\u00d3RIO DE TESTES](#5)    ","35c1b4a4":"<a id='5'><\/a>\n**RELAT\u00d3RIO DE TESTES** ","77417791":"## Treinamento e Avalia\u00e7\u00e3o do modelo\n\nNesta etapa iremos treinar os classificadores\nOs dados de treinamento est\u00e3o armazenados em *X_train* (features) e *y_train* (r\u00f3tulo). A predi\u00e7\u00e3o \u00e9 realizada com os dados de treinamento em *X_valid*.","3cf18f45":"*MELHORIA: EXCLUS\u00c3O DOS CAMPOS CITY E STATE*  \n\nObs.: fiz a exclus\u00e3o para tentar realizar a redu\u00e7\u00e3o de dimensionalidade, pois n\u00e3o sabia como fazer considerando atributos categ\u00f3ricos. A exclus\u00e3o tamb\u00e9m foi para testar o comportamento do algoritmo e, portanto, n\u00e3o h\u00e1 uma justificativa pautada em t\u00e9cnicas existentes para essa exclus\u00e3o.\n","262fc77e":"O esquema \u00e9 apresentado na linha abaixo, para que possamos visualizar o modelo de dados que iremos trabalhar.","40a860d3":"Dentre os algoritmos de ML elencados abaixo, o que teve maior acur\u00e1cia foi o LinearDiscriminantAnalysis, em seguida o DecisionTreeClassifier.\nLinearDiscriminantAnalysis teve as pontua\u00e7\u00f5es 0.78970 e 0.80171, conforme relat\u00f3rio de testes ao final deste.","e55c38e4":"O nosso *dataset* cont\u00e9m os dados de treinamento e de teste do nosso modelo. Aqui os dados de teste s\u00e3o aqueles que **n\u00e3o** possuem r\u00f3tulo e ser\u00e3o utilizados na solu\u00e7\u00e3o final. Dentro dos dados de treinamento (\"defaulting is not null\") vamos dividir nosso *dataset* entre dados de treinamento do modelo e dados de valida\u00e7\u00e3o, sendo 80% para o primeiro conjunto e 20% para o segundo. Queremos predizer o valor da coluna *defaulting*, mas ela \u00e9 do tipo boolean e deve ser transformada para o tipo inteiro para o nosso algoritmo de aprendizado de m\u00e1quina conseguir fazer a classifica\u00e7\u00e3o.\n","551001e0":"*MELHORIA: BALANCEAMENTO DAS CLASSES*  \n\nFoi realizada o balanceamento de classes, pois o r\u00f3tulo \"defaulting\" possui 7000 registros TRUE e 3000 registros FALSE, portanto, est\u00e1 desbalanceada.","8f24a545":"## Sele\u00e7\u00e3o do modelo preditivo","66fdd07e":"Para **avaliar** a acur\u00e1cia do modelo, o resultado da predi\u00e7\u00e3o *y_pred* \u00e9 comparado com o resultado esperado *y_valid* para gerar as m\u00e9tricas ROC, Acur\u00e1cia e F1.","b6f10ebd":"INCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA   \nAMPLIANDO OS DADOS DE TREINO\n\nResultado Kaggle:  \n**<font color = 'green'>LinearDiscriminantAnalysis (.78970)<\/font>** \n\n\n##############################################################################################################################\n\nINCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA \nTRATAMENTO DE NULOS   \nBALANCEAMENTO  \n\n+EXCLUS\u00c3O DOS CAMPOS CITY E STATE   \n\n*Modelo LinearDiscriminantAnalysis carregado!*  \n*M\u00e9tricas de LinearDiscriminantAnalysis*  \n*ROC AUC: 0.8045749252887551*  \n*Acur\u00e1cia: 0.8060714285714285*  \n*F1 score: 0.7585593597154291*  \n*\n*Modelo Decision_Tree_Classifier carregado!*  \n*M\u00e9tricas de Decision_Tree_Classifier*  \n*ROC AUC: 0.9039471314300526*  \n*Acur\u00e1cia: 0.9035714285714286*  \n*F1 score: 0.9073438572409059*  \n*\n\nResultado Kaggle:  \n<font color = 'green'>LinearDiscriminantAnalysis (.80018)<\/font>   \nDecision_Tree_Classifier (.77423)\n\n##############################################################################################################################\n\nINCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA  \nTRATAMENTO DE NULOS (EM ATRIBUTOS NUMERICOS E CATEGORICOS)    \nBALANCEAMENTO  \n\n+RETIRANDO CARACTERES DO CAMPO CNAE_ID   \n\n\n*Modelo LinearDiscriminantAnalysis carregado!*  \n*M\u00e9tricas de LinearDiscriminantAnalysis*  \n*ROC AUC: 0.8034766432009323*  \n*Acur\u00e1cia: 0.8042857142857143*  \n*F1 score: 0.7802726543704892*  \n\n*Modelo Decision_Tree_Classifier carregado!*  \n*M\u00e9tricas de Decision_Tree_Classifier*  \n*ROC AUC: 0.9217155752982711*  \n*Acur\u00e1cia: 0.9214285714285714*  \n*F1 score: 0.9236641221374046*  \n\nResultado Kaggle:  \nDecision_Tree_Classifier (.78760)  \nLinearDiscriminantAnalysis (.77961)\n##############################################################################################################################\n\n\nINCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA  \nTRATAMENTO DE NULOS (EM ATRIBUTOS NUMERICOS E CATEGORICOS)    \nBALANCEAMENTO  \n\n+EXCLUIDO CAMPOS CITY E STATE   \n+RETIRANDO CARACTERES DO CAMPO CNAE_ID  \n\n*Modelo LinearDiscriminantAnalysis carregado!*  \n*M\u00e9tricas de LinearDiscriminantAnalysis*  \n*ROC AUC: 0.8017232186272725*  \n*Acur\u00e1cia: 0.8032142857142858*  \n*F1 score: 0.7552199022656597*  \n\n*Modelo Decision_Tree_Classifier carregado!*  \n*M\u00e9tricas de Decision_Tree_Classifier*  \n*ROC AUC: 0.9082387229007505*  \n*Acur\u00e1cia: 0.9078571428571428*  \n*F1 score: 0.911522633744856*  \n\n*Modelo Random_Forest_Classifier carregado!*  \n*M\u00e9tricas de Random_Forest_Classifier*  \n*ROC AUC: 0.9415315945525209*  \n*Acur\u00e1cia: 0.9414285714285714*  \n*F1 score: 0.9417613636363636*  \n\n*Modelo AdaBoost_Classifier carregado!*  \n*M\u00e9tricas de AdaBoost_Classifier*  \n*ROC AUC: 0.8077128741111058*  \n*Acur\u00e1cia: 0.8089285714285714*  \n*F1 score: 0.7722435078756918*  \n\n*Modelo KNeighbors_Classifier carregado!*  \n*M\u00e9tricas de KNeighbors_Classifier*  \n*ROC AUC: 0.7745187330442339*  \n*Acur\u00e1cia: 0.7742857142857142*  \n*F1 score: 0.779483600837404*  \n\n*Modelo SVC carregado!*  \n*M\u00e9tricas de SVC*  \n*ROC AUC: 0.5642154439126089*  \n*Acur\u00e1cia: 0.565*  \n*F1 score: 0.514354066985646*  \n\n*Modelo Logistic Regression carregado!*  \n*M\u00e9tricas de Logistic Regression*  \n*ROC AUC: 0.5*  \n*Acur\u00e1cia: 0.5039285714285714*  \n*F1 score: 0.0*  \n\n\nResultado Kaggle:  \n**<font color = 'blue'>LinearDiscriminantAnalysis (.80171)<\/font>**  \nDecision_Tree_Classifier (.77423)\n\n###########################################################################################################################\n\nINCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA  \nTRATAMENTO DE NULOS (EM ATRIBUTOS NUMERICOS E CATEGORICOS)    \nBALANCEAMENTO  \n\n+EXCLUIDO CAMPOS CITY E STATE  \n+RETIRANDO CARACTERES DO CAMPO CNAE_ID  \n+NORMALIZACAO\n\n*Modelo LinearDiscriminantAnalysis carregado!*  \n*M\u00e9tricas de LinearDiscriminantAnalysis*  \n*ROC AUC: 0.5826112224275071*  \n*Acur\u00e1cia: 0.5796428571428571*  \n*F1 score: 0.6938881664499351*  \n\n*Modelo Decision_Tree_Classifier carregado!*  \n*M\u00e9tricas de Decision_Tree_Classifier*  \n*ROC AUC: 0.7340481223585741*  \n*Acur\u00e1cia: 0.7332142857142857*  \n*F1 score: 0.7575462512171374*  \n\n\nResultado Kaggle:  \nDecision_Tree_Classifier(.75675)  \nLinearDiscriminantAnalysis(.50000)\n###########################################################################################################################\n\nINCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA  \nTRATAMENTO DE NULOS (EM ATRIBUTOS NUMERICOS E CATEGORICOS)    \nBALANCEAMENTO  \n\n+EXCLUIDO CAMPOS CITY E STATE  \n+EXCLUIDO CAMPO CNAE_ID\n\n*Modelo LinearDiscriminantAnalysis carregado!*  \n*M\u00e9tricas de LinearDiscriminantAnalysis*  \n*ROC AUC: 0.5670288829055263*  \n*Acur\u00e1cia: 0.5657142857142857*  \n*F1 score: 0.6265356265356266*  \n\n*Modelo Decision_Tree_Classifier carregado!*  \n*M\u00e9tricas de Decision_Tree_Classifier*  \n*ROC AUC: 0.8640793640831909*  \n*Acur\u00e1cia: 0.8635714285714285*  \n*F1 score: 0.8710330857528696*  \n\nResultado Kaggle:  \nDecision_Tree_Classifier (.66843)  \nLinearDiscriminantAnalysis(.55461)  \n\n###########################################################################################################################\n\nINCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA  \nTRATAMENTO DE NULOS (EM ATRIBUTOS NUMERICOS E CATEGORICOS)    \nBALANCEAMENTO  \n\n+CONCATENANDO CAMPOS CITY E STATE  \n+RETIRANDO CARACTERES DO CAMPO CNAE_ID  \n+NORMALIZACAO\n\n*Modelo LinearDiscriminantAnalysis carregado!*  \n*M\u00e9tricas de LinearDiscriminantAnalysis*  \n*ROC AUC: 0.6939109506250132*  \n*Acur\u00e1cia: 0.6932142857142857*  \n*F1 score: 0.7167820639630729*  \n\n*Modelo Decision_Tree_Classifier carregado!*  \n*M\u00e9tricas de Decision_Tree_Classifier*  \n*ROC AUC: 0.753132208672066*  \n*Acur\u00e1cia: 0.7521428571428571*  \n*F1 score: 0.7786989795918366*  \n\n\nResultado Kaggle: n\u00e3o submeti \n\n###########################################################################################################################\n\nINCLUS\u00c3O DO ATRIBUTO DIAS_ULTIMA_COMPRA  \nTRATAMENTO DE NULOS (EM ATRIBUTOS NUMERICOS E CATEGORICOS)    \nBALANCEAMENTO  \n\n+CONCATENANDO CAMPOS CITY E STATE  \n+RETIRANDO CARACTERES DO CAMPO CNAE_ID  \n+SEM NORMALIZACAO\n\n*Modelo LinearDiscriminantAnalysis carregado!*  \n*M\u00e9tricas de LinearDiscriminantAnalysis*  \n*ROC AUC: 0.806328349862415*  \n*Acur\u00e1cia: 0.8071428571428572*  \n*F1 score: 0.78330658105939*  \n\n*Modelo Decision_Tree_Classifier carregado!*  \n*M\u00e9tricas de Decision_Tree_Classifier*  \n*ROC AUC: 0.924589732325312*  \n*Acur\u00e1cia: 0.9242857142857143*  \n*F1 score: 0.9265927977839336*  \n\n\nResultado Kaggle:\nDecision_Tree_Classifier (.79349)  \nLinearDiscriminantAnalysis (.78275)\n\n###############################################################################################################################\n","a546552c":"*MELHORIA: INCLUS\u00c3O DE ATRIBUTO DIAS_ULTIMA_COMPRA*\n\ndias_ultima_compra: quantidade de dias corridos em que o cliente efetuou a \u00faltima compra","1afe8c35":"## Engenharia de Features\n\nEngenharia de Features \u00e9 o processo de usar o conhecimento de dom\u00ednio sobre os dados para criar *features* que fazem os algoritmos de aprendizado de m\u00e1quina funcionar da forma que esperamos. \n\nPrimeiramente, iremos remover do DataFrame as features que n\u00e3o iremos utilizar na classifica\u00e7\u00e3o. As features *key* e *timestamp* s\u00e3o removidas por n\u00e3o terem correla\u00e7\u00e3o com o fato do cliente estar ou n\u00e3o inadimplente. ","30aafdcc":"As colunas categ\u00f3ricas s\u00e3o transformadas para valores num\u00e9ricos utilizando a fun\u00e7\u00e3o [get_dummies](https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.23.4\/generated\/pandas.get_dummies.html) do Pandas. Essa Engenharia de Features \u00e9 importante para que o classificador funcione corretamente."}}