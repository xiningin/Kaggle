{"cell_type":{"754c53d8":"code","485eacfe":"code","ab2919fd":"code","a927a1dd":"code","c22d5752":"code","9e673380":"code","2ed49776":"code","5d86467c":"code","3cfbab08":"code","a6bb8073":"code","5b188dae":"code","27ada911":"code","099c8c86":"code","ae054051":"code","bcb37bc2":"code","6a711922":"code","fbb1ebbc":"code","838b8212":"code","f1197372":"code","21416d8e":"code","2a364987":"code","c892be81":"code","a03c6f9e":"code","b105e2f1":"code","811fddfa":"code","5eeabade":"code","721a1e0d":"code","731de7b4":"code","8b85c50f":"code","4c190af3":"code","78c4814e":"markdown","928dea9f":"markdown","7bebbec0":"markdown","e13736b6":"markdown","fc517cb3":"markdown","bc4936c6":"markdown","eeffd0c0":"markdown","8a810a5b":"markdown","ed9b5409":"markdown","4ca7ac87":"markdown","d8340459":"markdown","bf5319d8":"markdown","892cd7e8":"markdown","7106a136":"markdown","3d598770":"markdown","2862784d":"markdown","6f8d67ff":"markdown","86076858":"markdown","06ce5ead":"markdown","d02dffb7":"markdown","67a0498e":"markdown","917c8828":"markdown","7bbfe466":"markdown","81f7c02e":"markdown","116bbf01":"markdown","93758378":"markdown","105714df":"markdown","af22290d":"markdown","8f5118cd":"markdown"},"source":{"754c53d8":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","485eacfe":"dataset = pd.read_csv('\/kaggle\/input\/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)","ab2919fd":"dataset.head()","a927a1dd":"dataset.shape","c22d5752":"dataset.info()","9e673380":"dataset.describe()","2ed49776":"fig=plt.figure(figsize=(5,5))\ncolors=[\"blue\",'pink']\npos=dataset[dataset['Liked']==1]\nneg=dataset[dataset['Liked']==0]\nck=[pos['Liked'].count(),neg['Liked'].count()]\nlegpie=plt.pie(ck,labels=[\"Positive\",\"Negative\"],\n                 autopct ='%1.1f%%', \n                 shadow = True,\n                 colors = colors,\n                 startangle = 45,\n                 explode=(0, 0.1))","5d86467c":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nstop=stopwords.words('english')","3cfbab08":"from wordcloud import WordCloud\npositivedata = dataset[ dataset['Liked'] == 1]\npositivedata =positivedata['Review']\nnegdata = dataset[dataset['Liked'] == 0]\nnegdata= negdata['Review']\n\ndef wordcloud_draw(dataset, color = 'white'):\n    words = ' '.join(dataset)\n    cleaned_word = \" \".join([word for word in words.split()\n                              if(word!='food' and word!='place')\n                            ])\n    wordcloud = WordCloud(stopwords=stop,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(10, 7))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Positive words are as follows\")\nwordcloud_draw(positivedata,'white')\nprint(\"Negative words are as follows\")\nwordcloud_draw(negdata)","a6bb8073":"corpus = []\nfor i in range(0, 1000):\n  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n  review = review.lower()\n  review = review.split()\n  ps = PorterStemmer()\n  all_stopwords = stopwords.words('english')\n  all_stopwords.remove('not')\n  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n  review = ' '.join(review)\n  corpus.append(review)\nprint(corpus)","5b188dae":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:, -1].values","27ada911":"X","099c8c86":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","ae054051":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","bcb37bc2":"y_pred = classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","6a711922":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","fbb1ebbc":"from sklearn import metrics","838b8212":"print(\"Naive Bayes Accuracy:\",metrics.accuracy_score(y_test, y_pred))","f1197372":"from sklearn.linear_model import LogisticRegressionCV\n\nclassifier=LogisticRegressionCV(cv=6,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=500).fit(X_train,y_train)\n\ny_pred1 = classifier.predict(X_test)","21416d8e":"print(np.concatenate((y_pred1.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","2a364987":"from sklearn.metrics import confusion_matrix,accuracy_score\ncm = confusion_matrix(y_test, y_pred1)\nprint(cm)","c892be81":"print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, y_pred1))","a03c6f9e":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train,y_train)\npreds=classifier.predict(X_test)","b105e2f1":"print(np.concatenate((preds.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","811fddfa":"cm = confusion_matrix(preds,y_test)\nprint(cm)","5eeabade":"print(\"Randon Forest Accuracy:\",metrics.accuracy_score(preds,y_test))","721a1e0d":"import xgboost as xgb\nxgb=xgb.XGBClassifier()\nxgb.fit(X_train,y_train)","731de7b4":"preds2=xgb.predict(X_test)\nprint(np.concatenate((preds2.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n","8b85c50f":"cm = confusion_matrix(preds2,y_test)\nprint(cm)","4c190af3":"print(\"XGBoost model Accuracy:\",metrics.accuracy_score(y_test, preds2))","78c4814e":"# importing the dataset","928dea9f":"# Predicting the Test set results","7bebbec0":"# Making the Confusion Matrix","e13736b6":"# Making the Confusion Matrix","fc517cb3":"# Sentiment analysis\nhere we first Remove special characters, then stemming the text and after that Remove the stopwords from the reviews.\n\n","bc4936c6":"# Sentiment count\nhere, we will see number of negative and positive reviews in the given data set, to make sure whether the datset is balanced or not.","eeffd0c0":"# importing the libraries","8a810a5b":"# Sentiment Analysis of Restaurant Reviews ","ed9b5409":"# Predicting the Test set results","4ca7ac87":"# accuracy for Logistic Regression Model","d8340459":"# importing libraries from nltk for cleaning the text.","bf5319d8":"Here, our main target is to predict the number of positive and negative reviews (given as 1 or 0) based on sentiments by using different classification models.","892cd7e8":"positive words are highlighted as great, delicious, amazing, nice etc.\n\nnegative words are highlighted as never, terrible, horrible, bad, disappointed etc.","7106a136":"# Making the Confusion Matrix","3d598770":"# Conclusion\nhere we observed that both Logistic regression model and random forest model performed highest accuracy by getting 77.5% and 75%, whereas naive bayes and XGBoost model performed less accuracy.","2862784d":"# some basic information regarding the dataset is as follows:","6f8d67ff":"# Let's see positive and negative words by using WordCloud.","86076858":"# Predicting the Test set results","06ce5ead":"# Splitting the dataset into the Training set and Test set.","d02dffb7":"# Training the Naive Bayes model on the Training set","67a0498e":"# Training the Random Forest Classifier on the Training set","917c8828":"# Training the Logistic Regression model on the Training set","7bbfe466":"# Accuracy for XGBoost model","81f7c02e":"# Training the XGBoost Model on the training set","116bbf01":"# Creating the Bag of Words model\nhere we will apply count vactorization process.","93758378":"# Making the Confusion Matrix","105714df":"# Accuracy for Random Forest Classifier","af22290d":"# Predicting the Test set results","8f5118cd":"# accuracy for naive bayes model"}}