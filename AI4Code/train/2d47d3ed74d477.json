{"cell_type":{"bbc2dc86":"code","84159320":"code","f59cda0d":"code","8b003f78":"code","88d70033":"code","0f91ae2e":"code","9446e472":"code","d35e89ab":"code","4842a2c7":"code","2bc1de5b":"code","64729fd9":"code","e65eaffc":"code","9bb1fe13":"code","27bf43a4":"code","6190d285":"code","3822c5ff":"markdown","2452a70e":"markdown","2e995e06":"markdown","ccaa5667":"markdown","51d77ab4":"markdown","f99991d4":"markdown"},"source":{"bbc2dc86":"# import libs\nimport glob, pylab, pandas as pd\nimport pydicom, numpy as np\nimport random\nimport json\nimport time\nimport copy\nimport pydicom\nimport torchvision\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom PIL import Image, ImageDraw, ImageFont\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches, patheffects\n\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import datasets, transforms\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import lr_scheduler\nfrom pathlib import Path\n\n# from fastai.conv_learner import *\n# from fastai.dataset import *\n# from fastai.dataset import ImageClassifierData","84159320":"# see input dir\n!ls ..\/input","f59cda0d":"PATH = Path('..\/input')\n# read training lables\ntrain_bb_df = pd.read_csv(PATH\/'stage_2_train_labels.csv')\ntrain_bb_df.head()","8b003f78":"train_bb_df['duplicate'] = train_bb_df.duplicated(['patientId'], keep=False)\n# see data\ntrain_bb_df[train_bb_df['duplicate']].head()","88d70033":"detailed_df = pd.read_csv(PATH\/'stage_2_detailed_class_info.csv')\n# merge two df\nclass_df = train_bb_df.merge(detailed_df, on=\"patientId\")\n# class_df.head()\ncsv_df = class_df.filter(['patientId', 'Target'], )\ncsv_df = csv_df.set_index('patientId', )\n# detailed_df.head() , \nclass_df.head(10)\n# csv_df.head()","0f91ae2e":"# these are dcm image files. Lets load them\n# ! ls {PATH}'\/stage_1_test_images' | head","9446e472":"class CDataset(Dataset):\n    def __init__(self, ds, img_dir, class_df, transform=None, ext=None): \n        self.ds = ds\n        self.img_dir = img_dir\n        self.class_df = class_df\n        self.ext = ext or '.dcm'\n        self.transform = transforms.Compose(transform) if transform else None\n        \n    def __len__(self): \n        return len(self.ds)\n    \n    def read_dicom_image(self, loc):\n        # return numpy array\n        img_arr = pydicom.read_file(loc.as_posix()).pixel_array\n        img_arr = img_arr\/img_arr.max()\n        img_arr = (255*img_arr).clip(0, 255).astype(np.uint8)\n        img_arr = Image.fromarray(img_arr).convert('RGB') # model expects 3 channel image\n        return img_arr\n        \n    def __getitem__(self, i):\n        img = self.read_dicom_image(self.ds[i])\n        if self.transform:\n            img = self.transform(img)\n        patientId = self.ds[i].name.split('.')[0]\n        kls = self.class_df[self.class_df['patientId'] == patientId]\n        return img, kls.iloc[0].Target","d35e89ab":"# img_dir = PATH\/'stage_1_train_images'\nimg_dir = PATH\/'stage_2_train_images'\nsample = random.sample(list(img_dir.iterdir()), 400) # sample\n# sample = list(img_dir.iterdir())\ntrain, test = train_test_split(sample)\n\ntransform = [transforms.Resize(224), transforms.RandomHorizontalFlip() , transforms.ToTensor()]\ntrain_ds = CDataset(train, img_dir, class_df, transform=transform)\ntest_ds = CDataset(test, img_dir, class_df, transform=transform)","4842a2c7":"batch_size=32\nsz=224\ntrain_dl = DataLoader(train_ds, batch_size=batch_size,)\ntest_dl = DataLoader(test_ds, batch_size=batch_size)","2bc1de5b":"def show_img(im, figsize=None, ax=None):\n    if not ax: \n        fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    return ax\n\ndef draw_outline(o, lw):\n  o.set_path_effects([patheffects.Stroke(\n      linewidth=lw, foreground='black'), patheffects.Normal()])\n\ndef draw_rect(ax, b):\n    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n    draw_outline(patch, 4)\n\ndef draw_text(ax, xy, txt, sz=14):\n    text = ax.text(*xy, txt, verticalalignment='top', color='white', fontsize=sz, weight='bold')\n    draw_outline(text, 1)","64729fd9":"image, klass = next(iter(train_dl))\nfig, axes = plt.subplots(1, 4, figsize=(12, 2))\nfor i,ax in enumerate(axes.flat):\n    image, klass\n#     ima=image[i].numpy().transpose((1, 2, 0))\n    ima=image[i][0]\n    b = klass[i]\n    ax = show_img(ima, ax=ax)\n    draw_text(ax, (0,0), b)\n\nplt.tight_layout()","e65eaffc":"use_gpu = torch.cuda.is_available()\ndataloaders = {'train': train_dl, 'val':test_dl}\n               \ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)  # Set model to training mode\n            else:\n                model.train(False)  # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            data_loader = dataloaders[phase]\n            for data in data_loader:\n                # get the inputs\n                inputs, labels = data\n\n                # wrap them in Variable\n                if use_gpu:\n                    inputs = Variable(inputs.cuda(),requires_grad=True)\n                    labels = Variable(labels.cuda())\n                else:\n                    inputs, labels = Variable(inputs), Variable(labels)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                outputs = model(inputs)\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n\n                # backward + optimize only if in training phase\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                # statistics\n                running_loss += loss.data[0] * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(data_loader.dataset)\n            epoch_acc = running_corrects \/ len(data_loader.dataset)\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","9bb1fe13":"device = torch.cuda.set_device(0)\n\nmodel_ft = torchvision.models.resnet18(pretrained=True)\n\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\ncriterion = nn.CrossEntropyLoss()\nmodel_ft = model_ft.cuda()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.Adam(model_ft.parameters())\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\nsince = time.time()","27bf43a4":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10)","6190d285":"! nvidia-smi ","3822c5ff":"Lets train our model and check classification accuracy","2452a70e":"Import libs","2e995e06":"We are randomly sampling 400 images. This for testing our code.","ccaa5667":"row 4 shows, there is bouding box in image with given x & y. First 4 image don't have any bounding box\n### check if duplicate bounding box are present for any patient","51d77ab4":"Loading all train images in memory causes memory overflow. Kernel will restart. \nWe creating dataset to read images, then apply transformation.","f99991d4":"1. With resnet 18, transformation.RandomResizedCrop(224) & random sample of 400 images we reached to 85%\n1. With resnet18, only horizontal flip transformation & random sample of 400 images we reached to 84%\n1. <img src=\"attachment:image.png\" width=\"400\">\n1. With resnet18, Adam optimizer, val loss reduces to 85%"}}