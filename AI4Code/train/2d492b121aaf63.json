{"cell_type":{"36b32a63":"code","0b46e2e8":"code","9774c890":"code","8f265716":"code","5ea545ad":"code","2c55d9e0":"code","2141969b":"code","cd1ec7a0":"code","4136b606":"code","bc93c95e":"code","a3a0deaa":"code","d983eddc":"code","4b4e4ecb":"code","17953117":"code","dd4941c5":"code","7ab45558":"markdown","64674efa":"markdown","ccae2d41":"markdown","b7733a6e":"markdown","f22c4cd9":"markdown","9677716c":"markdown","9b361b5d":"markdown","8fa8ba99":"markdown","c10576fd":"markdown","f329089a":"markdown","a31ae5a6":"markdown","8fd371e9":"markdown","47532fc7":"markdown"},"source":{"36b32a63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nimport keras\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)","0b46e2e8":"def normalize_histograms(im): #normalizes the histogram of images\n    im1=im.copy()\n    for i in range(3):\n        imi=im[:,:,i]\n        #print(imi.shape)\n        minval=np.min(imi)\n        maxval=np.max(imi)\n        #print(minval,maxval)\n        imrange=maxval-minval\n        im1[:,:,i]=(255\/(imrange+0.0001)*(imi-minval)) # imi-minval will turn the color range between 0-imrange, and the scaleing will stretch the range between 0-255\n    return im1","9774c890":"def read_and_process_image(filename,im_size):\n        im=cv2.imread(filename) #read image from file \n        \n        gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # convert 2 grayscale\n        _,thresh = cv2.threshold(gray,10,255,cv2.THRESH_BINARY) # turn it into a binary image\n        contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) # find contours\n        if len(contours) != 0:\n            #find the biggest area\n            cnt = max(contours, key = cv2.contourArea)\n                      \n            #find the bounding rect\n            x,y,w,h = cv2.boundingRect(cnt)                  \n\n            crop = im[y:y+h,x:x+w]# crop image\n            crop1=cv2.resize(crop,(im_size,im_size)) # resize to im_size X im_size size\n            crop1=normalize_histograms(crop1)\n            return crop1\n        else:\n            return( normalize_histograms(cv2.resize(im,(im_size,im_size))) )         ","8f265716":"def prepare_data(files,labels_orig,im_size):\n    images=[]\n    labels=[]\n    for i,f in enumerate(files):\n        im=read_and_process_image(f,im_size)\n        l=labels_orig[i]\n        \n        imb=im+0.05*im # brighter image\n        \n        imd=im-0.05*im #deemer image\n        \n        imlr= cv2.flip(im,0)\n        imud= cv2.flip(im,1)\n        \n        imblr=cv2.flip(imb,0)\n        imbud=cv2.flip(imb,1)\n        \n        imdlr=cv2.flip(imd,0)\n        imdud=cv2.flip(imd,1)\n        \n        #add all the images an labels   \n        images.append(im)\n        labels.append(l)\n        \n\n        images.append(imb)\n        labels.append(l)\n        \n\n        images.append(imd)\n        labels.append(l)\n        \n  \n        images.append(imlr)\n        labels.append(l)\n        \n       \n        images.append(imud)\n        labels.append(l)\n        \n        images.append(imblr)\n        labels.append(l)\n        \n        \n        images.append(imbud)\n        labels.append(l)\n        \n        images.append(imdlr)\n        labels.append(l)\n        \n        \n        images.append(imdud)\n        labels.append(l)\n        \n        \n    return(np.array(images),np.array(labels))\n    ","5ea545ad":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#Create a list of image files and labels\n\nfiles=[] #store the filenames here\nlabels=[] #store the labels here\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith('.png'):\n            files.append(os.path.join(dirname, filename))\n            l=np.zeros(4)\n            if filename.startswith('NL'):\n                l[0]=1\n            elif filename.startswith('ca'):\n                l[1]=1\n            elif filename.startswith('Gl'):\n                l[2]=1\n            elif filename.startswith('Re'):\n                l[3]=1\n            labels.append(l)\n\n        \nprint(len(labels),len(files))        \n\n#Shuffle the files and labels\ncombined = list(zip(files, labels)) # combine the lists\nnp.random.shuffle(combined) # shuffle two lists together to keep order\nfiles[:], labels[:] = zip(*combined) #unzip the shuffled lists\n#print(files,labels)\n\n# Train test devide (70:30)\nindex=int(len(files)*0.7)\n\n#size of the images\nim_size=128\n\n# training data\nfiles_train=files[:index]\nlabels_train=labels[:index]\n\nX_train,Y_train=prepare_data(files_train,labels_train,im_size)\nX_train=X_train\/255\n# test data\nfiles_test=files[index:]\nlabels_test=labels[index:]\n\nX_test,Y_test=prepare_data(files_test,labels_test,im_size)\nX_test=X_test\/255","2c55d9e0":"index=19\nprint(X_test[index].shape)\n#im1=normalize_histograms(X_test[index])\nplt.imshow(X_test[index])\n#plt.imshow(X_test[index])\nprint(Y_test[index], np.sum(X_test[index]),np.max(X_test[index]))\n","2141969b":"# GRADED FUNCTION: identity_block\n\ndef identity_block(X, f, filters, stage, block):\n    \"\"\"\n    X -- input tensor \n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string\/character, used to name the layers, depending on their position in the network\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)  \n\n    \n    # Second component of main path (\u22483 lines)\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (\u22482 lines)\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (\u22482 lines)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","cd1ec7a0":"def convolutional_block(X, f, filters, stage, block, s = 2):\n    \"\"\"    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string\/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n\n    # Second component of main path (\u22483 lines)\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path (\u22482 lines)\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH #### (\u22482 lines)\n    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (\u22482 lines)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    \n    return X","4136b606":"def ResNetS(input_shape = (128, 128, 3), classes = 4,filters=[5,5,10]):\n    \"\"\"\n    Implementation of a simpler version (ResNet10 if you may) of the popular ResNet50:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n    \"\"\"\n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((2, 2))(X_input)\n    \n    # Stage 1\n    X = Conv2D(10, (5, 5), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = filters, stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, filters, stage=2, block='b')\n    X = identity_block(X, 3, filters, stage=2, block='c')\n\n    # Stage 3 \n    X = convolutional_block(X, f=3, filters=filters, stage=3, block='a', s=2)\n    X = identity_block(X, 3, filters, stage=3, block='b')\n    X = identity_block(X, 3, filters, stage=3, block='c')\n    X = identity_block(X, 3, filters, stage=3, block='d')\n\n    # Stage 4 \n    X = convolutional_block(X, f=3, filters=filters, stage=4, block='a', s=2)\n    X = identity_block(X, 3, filters, stage=4, block='b')\n    X = identity_block(X, 3, filters, stage=4, block='c')\n    X = identity_block(X, 3, filters, stage=4, block='d')\n    X = identity_block(X, 3, filters, stage=4, block='e')\n    X = identity_block(X, 3, filters, stage=4, block='f')\n    \n    # Stage 5 \n    X = X = convolutional_block(X, f=3, filters=filters, stage=5, block='a', s=2)\n    X = identity_block(X, 3, filters, stage=5, block='b')\n    X = identity_block(X, 3, filters, stage=5, block='c')\n\n    # AVGPOOL \n    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0),kernel_regularizer=keras.regularizers.l1_l2(l1=0.5,l2=0.25))(X)\n    X = BatchNormalization(name = 'output')(X)\n    X = Activation('softmax')(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNetS')\n\n    return model","bc93c95e":"def genCNN(input_shape = (128, 128, 3), classes = 4, filters=[16,32,64,128]):\n\n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((2, 2))(X_input)\n    \n    # Stage 1\n    X = Conv2D(filters[0], (5, 5), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = Conv2D(filters[1], (5, 5), strides = (2, 2), padding='same',name = 'conv2', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv2')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n    \n    # Stage 3\n    X = Conv2D(filters[2], (5, 5), strides = (1, 1), padding='same',name = 'conv3', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv3')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), padding='same',strides=(1, 1))(X)\n   \n    # Stage 4\n    X = Conv2D(filters[3], (5, 5), padding='same',strides = (1, 1), name = 'conv4', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv4')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), padding='same',strides=(1, 1))(X)\n  \n    #dense layer\n    X = Flatten()(X)\n    X = Dense(classes,name='fc_l2', kernel_initializer = glorot_uniform(seed=0),kernel_regularizer=keras.regularizers.l1_l2(l1=0.5,l2=0.5))(X)\n    X = BatchNormalization(name = 'dense')(X)\n    X = Activation('relu')(X)\n    \n    X = Dense(classes,name='fc_l3', kernel_initializer = glorot_uniform(seed=0),kernel_regularizer=keras.regularizers.l1_l2(l1=0.5,l2=0.5))(X)\n    X = BatchNormalization(name = 'dense1')(X)\n    X = Activation('relu')(X)\n    \n    # output layer\n    X = Dense(classes, name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0),kernel_regularizer=keras.regularizers.l1_l2(l1=0.5,l2=0.5))(X)\n    X = BatchNormalization(name = 'output')(X)\n    X = Activation('softmax')(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNetS')\n\n    return model","a3a0deaa":"# Create and compile the ResNet models\nresnet_s = ResNetS(input_shape = (128, 128, 3), classes = 4,filters=[16,16,32])\nresnet_s.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","d983eddc":"#train the resnet model\nprint('Training resnet....')\nhistory=resnet_s.fit(X_train, Y_train, validation_data=(X_test,Y_test),epochs = 20, batch_size = 32)\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n#print('Saving resnet...')\n#resnet_s.save('resnet_s_200.h5')","4b4e4ecb":"preds1 = resnet_s.evaluate(X_test, Y_test)\nprint (\"resnet Loss = \" + str(preds1[0]))\nprint (\"resnet Test Accuracy = \" + str(preds1[1]))","17953117":"\n#Create and compile the generic CNN models\ngcnn=genCNN(input_shape = (128, 128, 3), classes = 4,filters=[16,16,32,32])\ngcnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","dd4941c5":"#train the general cnn model\n\nprint(' Training generic CNN..')\nhistory=gcnn.fit(X_train, Y_train, epochs = 50, validation_data=(X_test,Y_test), batch_size = 32)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n#print('Saving resnet...')\n#resnet_s.save('resnet_s_200.h5')\n#print('Saving generic CNN...')\n#gcnn.save('gcnn.h5')","7ab45558":"## Make predictions using the mini ResNet model","64674efa":"## Create and compile the mini-Resnet model","ccae2d41":"## Step3: Pull the model together","b7733a6e":"## Read and process images\n    The following function reads an image from a file, autocrops it and scales it to 128X128. \n    We also need to do additional processing. \n    For instance, I noticed that some of the images are too dim compared to the others. \n    And this is not specific to a class label, this has to do with lighting conditions when the picture was taken. \n    We need to make sure that all images have the same range of values, i.e. histogram normalization, i.e. ensure that the base of the color histogram stretches from 0-255. \n    Note, that this is not the same as histogram equalization, where the shape of the histogram is flattened over a full base.\n    \n    I suspect that histogram equalization may loose some defining features of disease classes.","f22c4cd9":"# Build CNN with ResNet architechture\n## Step1: Define Identity Block\n    Input to the shortcut has the same dimension as the output activation. \n","9677716c":"# Training the Generic CNN models","9b361b5d":"## Step2: Define convolution Block\n In this case there is a CONV2D layer in the shortcut path. The CONV2D layer is used to resize the shortcut input  to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. \n","8fa8ba99":"# A generic convolutional neural network model","c10576fd":"## Train the mini-Resnet model","f329089a":"# Library imports","a31ae5a6":"# Prepare input data","8fd371e9":"## Prepare the data from a list of files\n    The following function:\n    * Reads an image from a fils\n    * flips it from left to right\n    * flips it upside down\n    * add all three images and their labes to the dataset ","47532fc7":"## The following code\n1. prepares the list of image files and corresponding labels\n2. reads and processes images in those files \n3. prepares training and testing data for modeling\n"}}