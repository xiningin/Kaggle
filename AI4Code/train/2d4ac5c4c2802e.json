{"cell_type":{"98ce5004":"code","faf52b92":"code","4b740bc9":"code","dab61278":"code","2bf800f9":"code","9e8fb931":"code","992d98af":"code","ad8d7dc2":"code","d0b3d212":"code","e9c4df3b":"code","fe4fb5e4":"code","28a5f2ec":"code","8afcb5c5":"code","a503c2d9":"code","04c19b36":"code","4ba3388b":"markdown","ebc68d0d":"markdown","a71e3692":"markdown","e6676976":"markdown","5721fa91":"markdown","d5fbdebe":"markdown","0bc98d6f":"markdown","58413c01":"markdown","b6b4caba":"markdown"},"source":{"98ce5004":"import numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm","faf52b92":"import json\nimport os\nfrom os.path import join as path_join\n\n\ndef load_data(path):\n    tasks = pd.Series()\n    for file_path in os.listdir(path):\n        task_file = path_join(path, file_path)\n\n        with open(task_file, 'r') as f:\n            task = json.load(f)\n\n        tasks[file_path[:-5]] = task\n    return tasks","4b740bc9":"train_tasks = load_data('..\/input\/abstraction-and-reasoning-challenge\/training\/')\nevaluation_tasks = load_data('..\/input\/abstraction-and-reasoning-challenge\/evaluation\/')\ntest_tasks = load_data('..\/input\/abstraction-and-reasoning-challenge\/test\/')\n\ntrain_tasks.head()","dab61278":"import torch\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam\nfrom torch.nn import Conv2d\nfrom torch import FloatTensor, LongTensor\n\n\n\ndef inp2img(inp):\n    inp = np.array(inp)\n    img = np.full((10, inp.shape[0], inp.shape[1]), 0, dtype=np.uint8)\n    for i in range(10):\n        img[i] = (inp==i)\n    return img\n\n\nclass TaskSolver:        \n    def train(self, task_train, n_epoch=30):\n        \"\"\"basic pytorch train loop\"\"\"\n        self.net = Conv2d(in_channels=10, out_channels=10, kernel_size=5, padding=2)\n        \n        criterion = CrossEntropyLoss()\n        optimizer = Adam(self.net.parameters(), lr = 0.1)\n        \n        for epoch in range(n_epoch):\n            for sample in task_train:\n                inputs = FloatTensor(inp2img(sample['input'])).unsqueeze(dim=0)\n                labels = LongTensor(sample['output']).unsqueeze(dim=0)\n                \n                optimizer.zero_grad()\n                outputs = self.net(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        \n        return self\n            \n    def predict(self, task_test):\n        predictions = []\n        with torch.no_grad():\n            for sample in task_test:\n                inputs = FloatTensor(inp2img(sample['input'])).unsqueeze(dim=0)\n                outputs = self.net(inputs)\n                pred =  outputs.squeeze(dim=0).cpu().numpy().argmax(0)\n                predictions.append(pred)\n                                     \n        return predictions","2bf800f9":"def input_output_shape_is_same(task):\n    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n\ndef calk_score(task_test, predict):\n    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]","9e8fb931":"def evaluate(tasks):\n    ts = TaskSolver()\n    result = []\n    predictions = []\n    for task in tqdm(tasks):\n        if input_output_shape_is_same(task):\n            ts.train(task['train'])\n            pred = ts.predict(task['test'])\n            score = calk_score(task['test'], pred)\n        else:\n            pred = [el['input'] for el in task['test']]\n            score = [0]*len(task['test'])\n        \n        predictions.append(pred)\n        result.append(score)\n       \n    return result, predictions","992d98af":"train_result, train_predictions = evaluate(train_tasks)\ntrain_solved = [any(score) for score in train_result]\n\ntotal = sum([len(score) for score in train_result])\nprint(f\"solved : {sum(train_solved)} from {total} ({sum(train_solved)\/total})\")","ad8d7dc2":"evaluation_result, evaluation_predictions = evaluate(evaluation_tasks)\nevaluation_solved = [any(score) for score in evaluation_result]\n\ntotal = sum([len(score) for score in evaluation_result])\nprint(f\"solved : {sum(evaluation_solved)} from {total} ({sum(evaluation_solved)\/total})\")","d0b3d212":"import matplotlib.pyplot as plt\nfrom matplotlib import colors\n\n\ncmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n    \ndef plot_pictures(pictures, labels):\n    fig, axs = plt.subplots(1, len(pictures), figsize=(2*len(pictures),32))\n    for i, (pict, label) in enumerate(zip(pictures, labels)):\n        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n        axs[i].set_title(label)\n    plt.show()\n    \n\ndef plot_sample(sample, predict=None):\n    if predict is None:\n        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n    else:\n        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])","e9c4df3b":"for task, prediction, solved in tqdm(zip(train_tasks, train_predictions, train_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","fe4fb5e4":"for task, prediction, solved in tqdm(zip(evaluation_tasks, evaluation_predictions, evaluation_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","28a5f2ec":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\ndef make_pediction(tasks):\n    ts = TaskSolver()\n    result = pd.Series()\n    for idx, task in tqdm(test_tasks.iteritems()):\n        if input_output_shape_is_same(task):\n            ts.train(task['train'])\n            pred = ts.predict(task['test'])\n        else:\n            pred = [el['input'] for el in task['test']]\n        \n        for i, p in enumerate(pred):\n            result[f'{idx}_{i}'] = flattener(np.array(p).tolist())\n       \n    return result","8afcb5c5":"submission = make_pediction(test_tasks)\nsubmission.head()","a503c2d9":"submission = submission.reset_index()\nsubmission.columns = ['output_id', 'output']\nsubmission.to_csv('submission.csv', index=False)\nsubmission","04c19b36":"for task, prediction in tqdm(zip(train_tasks, train_predictions)):\n    if input_output_shape_is_same(task):\n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","4ba3388b":"# Results","ebc68d0d":"# All train tasks predictions","a71e3692":"# Prediction","e6676976":"# Data Loading","5721fa91":"# Visualize\n\nvisualize solved tasks","d5fbdebe":"### train solved tasks","0bc98d6f":"### evaluation solved tasks","58413c01":"**Solving tasks using one Conv2d(in_channels=10, out_channels=10, kernel_size=5, padding=2)","b6b4caba":"# Model"}}