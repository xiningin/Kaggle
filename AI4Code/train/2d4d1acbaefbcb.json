{"cell_type":{"eb077818":"code","7267ad8f":"code","f7e9934f":"code","9ac4681a":"code","2edd47eb":"code","f161e7ac":"code","80651352":"code","151fdcb9":"code","a2cef1e7":"code","3520369d":"code","162c8b51":"code","896115b4":"code","0c81680b":"code","2f703c41":"code","0fa60e7a":"code","e969b11b":"code","3254ee1c":"code","e87db69a":"code","15dc4884":"code","cbe395e7":"code","8671b733":"code","b1c39f55":"code","a6e77410":"code","5652cdee":"code","8a9aae03":"code","bb05c164":"code","75de2ef5":"code","96f13cd2":"code","132f312d":"code","a486eb92":"code","ae67d03d":"code","63cda29c":"markdown","c04ea917":"markdown","8cfc25c9":"markdown","cc5bfda0":"markdown","b03e47f6":"markdown","d2ab57f7":"markdown","95749c58":"markdown","5387e73d":"markdown","568f188e":"markdown","495287ed":"markdown","c4fb5d2a":"markdown"},"source":{"eb077818":"#Run once per session\n!pip install fastai2","7267ad8f":"# grab vision related APIs\nfrom fastai2.basics import *\nfrom fastai2.vision.all import *\nfrom fastai2.callback.all import *","f7e9934f":"# Download our data\n\npath = untar_data(URLs.MNIST)","9ac4681a":"items= get_image_files(path)\nitems[0]","2edd47eb":"# create an image object with ImageBlock\n\nimg = PILImageBW.create(items[0])\nimg.show()","f161e7ac":"# Split our data with GrandparentSplitter, which will make use of a train and valid folder.\n\nsplits = GrandparentSplitter(train_name='training', valid_name='testing')\nsplits = splits(items)","80651352":"# understand what it's split with?\nsplits[0][:5], splits[1][:5]","151fdcb9":"dsrc = Datasets(items, tfms=[[PILImageBW.create],[parent_label, Categorize]],\n                   splits=splits)","a2cef1e7":"show_at(dsrc.train, 3)","3520369d":"tfms = [ToTensor(), CropPad(size=34, pad_mode=PadMode.Zeros), RandomCrop(size=28)]\ngpu_tfms = [IntToFloatTensor(), Normalize()]","162c8b51":"\ndls = dsrc.dataloaders(bs=128, after_item=tfms, after_batch=gpu_tfms)","896115b4":"dls.show_batch()","0c81680b":"# passing as a batch\nxb, yb = dls.one_batch()\nxb.shape, yb.shape","2f703c41":"# no of classes and class labels\ndls.vocab","0fa60e7a":"def conv(ni, nf):\n    return nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1)","e969b11b":"def bn(nf): return nn.BatchNorm2d(nf)","3254ee1c":"def ReLU(): return nn.ReLU(inplace=True)","e87db69a":"# five CNN layers, 1 -> 32 -> 10\n\nmodel = nn.Sequential(\n            conv(1,8),\n            bn(8),\n            ReLU(),\n            conv(8,16),\n            bn(16),\n            ReLU(),\n            conv(16, 32),\n            bn(32),\n            ReLU(),\n            conv(32,16),\n            bn(16),\n            ReLU(),\n            conv(16,10),\n            bn(10),\n            Flatten() # and flatten it into a single dimention of predictions\n)","15dc4884":"learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn.summary()","cbe395e7":"learn.lr_find()","8671b733":"learn.fit_one_cycle(3, lr_max=1e-1)","b1c39f55":"def conv2(ni, nf):\n    return ConvLayer(ni, nf, stride=2)","a6e77410":"net = nn.Sequential(conv2(1,8),\n                   conv2(8,16),\n                   conv2(16,32),\n                   conv2(32,16),\n                   conv2(16,10),\n                   Flatten())","5652cdee":"learn = Learner(dls, net, loss_func=CrossEntropyLossFlat(), metrics=accuracy)","8a9aae03":"learn.fit_one_cycle(3, lr_max=1e-1)","bb05c164":"class ResBlock(Module):\n    def __init__(self, nf):\n        self.conv1 = ConvLayer(nf, nf)\n        self.conv2 = ConvLayer(nf, nf)\n  \n    def forward(self, x): return x + self.conv2(self.conv1(x))","75de2ef5":"net = nn.Sequential(\n    conv2(1,8),\n    ResBlock(8),\n    conv2(8,16),\n    ResBlock(16),\n    conv2(16,32),\n    ResBlock(32),\n    conv2(32,16),\n    ResBlock(16),\n    conv2(16,10),\n    Flatten()\n)","96f13cd2":"net","132f312d":"def conv_and_res(ni, nf): return nn.Sequential(conv2(ni, nf), ResBlock(nf))","a486eb92":"net = nn.Sequential(\n    conv_and_res(1,8),\n    conv_and_res(8,16),\n    conv_and_res(16,32),\n    conv_and_res(32,16),\n    conv2(16,10),\n    Flatten()\n)","ae67d03d":"learn = Learner(dls, net, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn.fit_one_cycle(3, lr_max=1e-1)","63cda29c":"# Contents\n\n* [<font size=4>Installing fastai and downloading data<\/font>](#1)\n* [<font size=4>Peeking at the data<\/font>](#2)\n* [<font size=4>Basic Model<\/font>](#3)\n* [<font size=4>Simplifying Things<\/font>](#4)\n* [<font size=4>Making a resnet kinda of model<\/font>](#5)\n* [<font size=4>Ending Notes<\/font>](#6)","c04ea917":"\nAwesome! We're building a pretty substantial model here. Let's try to make it even simpler. We know we call a convolutional layer before each ResBlock and they all have the same filters, so let's make that layer!","8cfc25c9":"## Installing fastai and downloading data <a id='1'>","cc5bfda0":"## Making a ResNet kinda of model <a id='5'>\n\nThe ResNet architecture is built with what are known as ResBlocks. Each of these blocks consist of two ConvLayers that we made before, where the number of filters do not change. Let's generate these layers.\n\n[A brief description of what's ResBlocks is mentioned in this kernel](https:\/\/www.kaggle.com\/kurianbenoy\/solving-kannada-mnist-with-fastai)","b03e47f6":"**Tranformations**\n- ToTensor: Converts to tensor\n- CropPad and RandomCrop: Resizing transforms\n- Applied on the CPU via after_item\n\n**Enables GPU usage(gpu_tfms)**\n- IntToFloatTensor: Converts to a float\n- Normalize: Normalizes data","d2ab57f7":"# Acknowledgment\n\nThis notebook is a fork from fastai2 megastudy group conducted by [Zach Mueller](https:\/\/www.kaggle.com\/muellerzr). More details about the online study group and fantastic fastai2 resources can be found in the [Practical Deep Learning for Coders 2.0 repo](https:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0\/)","95749c58":"# Image Classification Models from scratch\nIn this kernel, I will briefly discuss about writing Image classification models from scratch using fastaiv2 and Pytorch. Right now fastaiv2 is right now scheduled to be properly released in June 2020. If you want to check more about the new version of fast.ai [do read this paper](https:\/\/arxiv.org\/abs\/2002.04688)\n\n<font size=3 color=\"red\">Please upvote this kernel if you like it.<\/font>","5387e73d":"## Simplifying Things <a id='4'>\n\nConvLayer contains a Conv2d, BatchNorm2d, and an activation function","568f188e":"## Peeking at the data <a id='2'>","495287ed":"## Basic model <a id='3'>\n\nOur models are made up of layers, and each layer represents a matrix multiplication to end up with our final y. For this image problem, we will use a Convolutional layer, a Batch Normalization layer, an Activation Function, and a Flattening layer","c4fb5d2a":"# Ending note <a id=\"6\"><\/a>\n\nOur final trained model with `Resnet kind of architecture` gives **99.2% accuracy**\n\n<font size=4 color=\"red\">This concludes my fastaiv2 kernel heavily borrowed from @muellerzr. Please upvote this kernel if you like it. It motivates me to produce more quality content :)<\/font>\n"}}