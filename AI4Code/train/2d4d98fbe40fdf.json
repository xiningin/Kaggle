{"cell_type":{"c1ef725b":"code","ee7b8c09":"code","203c5cf7":"code","a3cd5a5e":"code","4ee6781d":"code","a1bc17c9":"code","eacb1dbf":"code","a77f5ac9":"code","6ce7af25":"code","844a048a":"code","e91d3f31":"code","a1b4023b":"code","ec2484e4":"code","05963794":"code","600af0b1":"code","30bda09d":"code","102cbdde":"code","ea3dd97f":"code","12e375be":"code","326541c6":"code","91c2834f":"code","dafea0cb":"code","566fa236":"code","542d47c8":"code","443bb859":"code","6b022905":"markdown"},"source":{"c1ef725b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee7b8c09":"train = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/sample_submission.csv')","203c5cf7":"train[train['GrLivArea'] > 4500].index\ntrain = train.drop(train[train['GrLivArea'] > 4500].index)","a3cd5a5e":"train[train['GrLivArea'] > 4500].index","4ee6781d":"train = train.drop(train[train['TotalBsmtSF'] > 3000].index)","a1bc17c9":"train = train.drop(train[train['GarageArea'] > 1200].index)","eacb1dbf":"alldata = pd.concat([train, test])\n\npd.options.display.max_columns = 999\n\nalldata.head(5)","a77f5ac9":"train.corr()['SalePrice'].sort_values()","6ce7af25":"import seaborn as sns\n\nsns.scatterplot(alldata['OverallQual'], alldata['SalePrice'])","844a048a":"sns.scatterplot(alldata['GrLivArea'], alldata['SalePrice'])","e91d3f31":"sns.scatterplot(alldata['TotalBsmtSF'], alldata['SalePrice'])","a1b4023b":"sns.scatterplot(alldata['GarageArea'], alldata['SalePrice'])","ec2484e4":"alldata['size'] = alldata['GrLivArea'] + alldata['TotalBsmtSF']\nalldata['final_size'] = alldata['size'] + alldata['GarageArea']\nalldata['allsize'] = alldata['final_size'] + alldata['LotArea'] * 0.1\n","05963794":"alldata2 = alldata.drop(columns = ['SalePrice', 'Id'])\nalldata2.head(5)","600af0b1":"alldata2 = alldata2.fillna(-1)","30bda09d":"alldata2['MSSubClass'] = alldata2['MSSubClass'].astype(object)","102cbdde":"alldata3 = pd.get_dummies(alldata2)\nalldata3","ea3dd97f":"from sklearn.preprocessing import RobustScaler\n\nrs = RobustScaler()\n\nalldata4 = rs.fit_transform(alldata3)","12e375be":"alldata4 = pd.DataFrame(alldata4, columns = alldata3.columns)","326541c6":"train2 = alldata4[:len(train)]\ntest2 = alldata4[len(train):]","91c2834f":"from sklearn.linear_model import Ridge\n\nridge = Ridge(alpha = 14)\n\nridge.fit(train2, np.log(train['SalePrice']))\n\nresult = ridge.predict(test2)\n\nresult","dafea0cb":"from sklearn.model_selection import cross_val_score\n\nfor i in [10,11,12,13,14,15,16,17,18,19,20]:\n    print(i)\n    R_cv = Ridge(alpha = i)\n    score = cross_val_score(R_cv, train2, train['SalePrice'],\n                           n_jobs = -1, cv = 10, \n                           scoring = 'neg_mean_squared_error').mean()\n    \n    print(np.sqrt(-score))","566fa236":"sub","542d47c8":"sub['SalePrice'] = np.exp(result)\nsub","443bb859":"sub.to_csv('sub2.csv', index = 0)","6b022905":"# \uad50\ud638\uc791\uc6a9"}}