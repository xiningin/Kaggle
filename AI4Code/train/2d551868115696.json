{"cell_type":{"bcccb6b6":"code","e3912931":"code","df02feaf":"code","9ef43b0d":"code","5a98f095":"code","05905224":"code","fbde38bf":"code","3f650429":"code","79145375":"code","eb7a66b5":"code","03af2c82":"code","a8cb2e17":"code","699bfdbc":"code","f49caae8":"code","2dcbe4b6":"code","51774904":"markdown","7fd9f022":"markdown","080b795a":"markdown","1330dd43":"markdown","1d448138":"markdown","94643f65":"markdown"},"source":{"bcccb6b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3912931":"from scipy.optimize import minimize\nimport matplotlib.pyplot as plt\n\ndef drawdown(return_series: pd.Series):\n    \"\"\"Takes a time series of asset returns.\n       returns a DataFrame with columns for\n       the wealth index, \n       the previous peaks, and \n       the percentage drawdown\n    \"\"\"\n    wealth_index = 1000*(1+return_series).cumprod()\n    previous_peaks = wealth_index.cummax()\n    drawdowns = (wealth_index - previous_peaks)\/previous_peaks\n    return pd.DataFrame({\"Wealth\": wealth_index, \n                         \"Previous Peak\": previous_peaks, \n                         \"Drawdown\": drawdowns})\n   \ndef skewness(r):\n    \"\"\"\n    Alternative to scipy.stats.skew()\n    Computes the skewness of the supplied Series or DataFrame\n    Returns a float or a Series\n    \"\"\"\n    demeaned_r = r - r.mean()\n    # use the population standard deviation, so set dof=0\n    sigma_r = r.std(ddof=0)\n    exp = (demeaned_r**3).mean()\n    return exp\/sigma_r**3\n\n\ndef kurtosis(r):\n    \"\"\"\n    Alternative to scipy.stats.kurtosis()\n    Computes the kurtosis of the supplied Series or DataFrame\n    Returns a float or a Series\n    \"\"\"\n    demeaned_r = r - r.mean()\n    # use the population standard deviation, so set dof=0\n    sigma_r = r.std(ddof=0)\n    exp = (demeaned_r**4).mean()\n    return exp\/sigma_r**4\n\nimport scipy.stats\ndef is_normal(r, level=0.01):\n    \"\"\"\n    Applies the Jarque-Bera test to determine if a Series is normal or not\n    Test is applied at the 1% level by default\n    Returns True if the hypothesis of normality is accepted, False otherwise\n    \"\"\"\n    if isinstance(r, pd.DataFrame):\n        return r.aggregate(is_normal)\n    else:\n        statistic, p_value = scipy.stats.jarque_bera(r)\n        return p_value > level\n    \n    \n    \n    \ndef semideviation(r):\n    \"\"\"\n    Returns the semideviation aka negative semideviation of r\n    r must be a Series or a DataFrame\n    \"\"\"\n    is_negative = r < 0\n    return r[is_negative].std(ddof=0)\n\n\ndef var_historic(r, level=5):\n    \"\"\"\n    Returns the historic Value at Risk at a specified level\n    i.e. returns the number such that \"level\" percent of the returns\n    fall below that number, and the (100-level) percent are above\n    \"\"\"\n    if isinstance(r, pd.DataFrame):\n        return r.aggregate(var_historic, level=level)\n    \n    elif isinstance(r, pd.Series):\n        return -np.percentile(r, level)\n    else:\n        raise TypeError(\"Expected r to be a Series or DataFrame\")\n\n\ndef cvar_historic(r, level=5):\n    \"\"\"\n    Computes the Conditional VaR of Series or DataFrame\n    \"\"\"\n    if isinstance(r, pd.Series):\n        is_beyond = r <= -var_historic(r, level=level)\n        return -r[is_beyond].mean()\n    elif isinstance(r, pd.DataFrame):\n        return r.aggregate(cvar_historic, level=level)\n    else:\n        raise TypeError(\"Expected r to be a Series or DataFrame\")\n\n\nfrom scipy.stats import norm\ndef var_gaussian(r, level=5, modified=False):\n    \"\"\"\n    Returns the Parametric Gauusian VaR of a Series or DataFrame\n    If \"modified\" is True, then the modified VaR is returned,\n    using the Cornish-Fisher modification\n    \"\"\"\n    # compute the Z score assuming it was Gaussian\n    z = norm.ppf(level\/100)\n    if modified:\n        # modify the Z score based on observed skewness and kurtosis\n        s = skewness(r)\n        k = kurtosis(r)\n        z = (z +\n                (z**2 - 1)*s\/6 +\n                (z**3 -3*z)*(k-3)\/24 -\n                (2*z**3 - 5*z)*(s**2)\/36\n            )\n    return -(r.mean() + z*r.std(ddof=0))\n\n\ndef annualize_rets(r, periods_per_year):\n    \"\"\"\n    Annualizes a set of returns\n    \n    \"\"\"\n    compounded_growth = (1+r).prod()\n    n_periods = r.shape[0]\n    return compounded_growth**(periods_per_year\/n_periods)-1\n\n\ndef annualize_vol_using_ret(returns, period):\n    a = returns.std()*(period**0.5)\n    return a\n\ndef annualize_vol_compiled(vol, period):\n    a = vol*(period**0.5)\n    return a\n\n\ndef semideviation(r):\n    \"\"\"\n    Returns the semideviation aka negative semideviation of r\n    r must be a Series or a DataFrame, else raises a TypeError\n    \"\"\"\n    if isinstance(r, pd.Series):\n        is_negative = r < 0\n        return r[is_negative].std(ddof=0)\n    elif isinstance(r, pd.DataFrame):\n        return r.aggregate(semideviation)\n    else:\n        raise TypeError(\"Expected r to be a Series or DataFrame\")\n        \n        \ndef get_ind_returns():\n    \"\"\"\n    Load and format the Ken French 30 Industry Portfolios Value Weighted Monthly Returns\n    \"\"\"\n    ind = pd.read_csv(\"data\/ind30_m_vw_rets.csv\", header=0, index_col=0)\/100\n    ind.index = pd.to_datetime(ind.index, format=\"%Y%m\").to_period('M')\n    ind.columns = ind.columns.str.strip()\n    return ind\n\ndef transform_to_executable(ind, formating = \"%Y%m\"):\n    ind.index = pd.to_datetime(ind.index, format=formating).to_period('M')\n    ind.columns = ind.columns.str.strip()\n    return ind\n\n\ndef portfolio_return(weights, returns):\n    \"\"\"\n    Computes the return on a portfolio from constituent returns and weights\n    weights are a numpy array or Nx1 matrix and returns are a numpy array or Nx1 matrix\n    \"\"\"\n    return weights.T @ returns\n\n\n\ndef portfolio_vol(weights, covmat):\n    \"\"\"\n    Computes the vol of a portfolio from a covariance matrix and constituent weights\n    weights are a numpy array or N x 1 maxtrix and covmat is an N x N matrix\n    \"\"\"\n    return (weights.T @ covmat @ weights)**0.5\n\n\ndef plot_ef2(n_points, er, cov):\n    \"\"\"\n    Plots the 2-asset efficient frontier\n    \"\"\"\n    import numpy as np\n    if er.shape[0] != 2 or er.shape[0] != 2:\n        raise ValueError(\"plot_ef2 can only plot 2-asset frontiers\")\n    weights = [np.array([w, 1-w]) for w in np.linspace(0, 1, n_points)]\n    rets = [portfolio_return(w, er) for w in weights]\n    vols = [portfolio_vol(w, cov) for w in weights]\n    ef = pd.DataFrame({\n        \"Returns\": rets, \n        \"Volatility\": vols\n    })\n    return ef.plot.line(x=\"Volatility\", y=\"Returns\", style=\".-\")\n\n\n\ndef minimize_vol(target_return, er, cov):\n    \n    \"\"\"\n    Returns the optimal weights that achieve the target return\n    given a set of expected returns and a covariance matrix\n    \"\"\"\n    import numpy as np\n    from scipy.optimize import minimize\n    n = er.shape[0]\n    init_guess = np.repeat(1\/n, n)\n    bounds = ((0.0, 1.0),) * n # an N-tuple of 2-tuples!\n    # construct the constraints\n    weights_sum_to_1 = {'type': 'eq',\n                        'fun': lambda weights: np.sum(weights) - 1\n    }\n    return_is_target = {'type': 'eq',\n                        'args': (er,),\n                        'fun': lambda weights, er: target_return - portfolio_return(weights,er)\n    }\n    weights = minimize(portfolio_vol, init_guess,\n                       args=(cov,), method='SLSQP',\n                       options={'disp': False},\n                       constraints=(weights_sum_to_1,return_is_target),\n                       bounds=bounds)\n    return weights.x\n\n\n\n\n\ndef optimal_weights(n_points, er, cov):\n    \"\"\"\n    n_points = number of portfolios generated\n    er = annualized returns\n    cov = coveriance matrix\n    \"\"\"\n    target_rs = np.linspace(er.min(), er.max(), n_points)\n    weights = [minimize_vol(target_return, er, cov) for target_return in target_rs]\n    return weights\n\n\ndef plot_ef(n_points, er, cov, style='.-', legend=False, show_cml=False, riskfree_rate=0, show_ew=False, show_gmv=False):\n    \"\"\"\n    Plots the multi-asset efficient frontier\n    \"\"\"\n    weights = optimal_weights(n_points, er, cov)\n    rets = [portfolio_return(w, er) for w in weights]\n    vols = [portfolio_vol(w, cov) for w in weights]\n    ef = pd.DataFrame({\n        \"Returns\": rets, \n        \"Volatility\": vols\n    })\n    ax = ef.plot.line(x=\"Volatility\", y=\"Returns\", style=style, legend=legend)\n    if show_cml:\n        ax.set_xlim(left = 0)\n        # get MSR\n        w_msr = msr(riskfree_rate, er, cov)\n        r_msr = portfolio_return(w_msr, er)\n        vol_msr = portfolio_vol(w_msr, cov)\n        \n        # add CML\n        cml_x = [0, vol_msr]\n        cml_y = [riskfree_rate, r_msr]\n        ax.plot(cml_x, cml_y, color='green', marker='o', linestyle='dashed', linewidth=2, markersize=10)\n    if show_ew:\n        n = er.shape[0]\n        w_ew = np.repeat(1\/n, n)\n        r_ew = portfolio_return(w_ew, er)\n        vol_ew = portfolio_vol(w_ew, cov)\n        \n        # add EW\n        ax.plot([vol_ew], [r_ew], color='goldenrod', marker='o', markersize=10)\n    if show_gmv:\n        w_gmv = gmv(cov)\n        r_gmv = portfolio_return(w_gmv, er)\n        vol_gmv = portfolio_vol(w_gmv, cov)\n        \n        # add EW\n        ax.plot([vol_gmv], [r_gmv], color='midnightblue', marker='o', markersize=10)\n        \n        return ax\n    \n    \n    \ndef get_portfolios(er, cov, show_cml=True, riskfree_rate=0, show_ew=True, show_gmv=True):\n     '''\n     er -> annulized returns\n     cov -> covariance matrix of the returns\n    \n     Gets the portfolio weights:\n     Maximum shape ratio\n     Global minimum variance\n     Equally weighted\n     '''\n    \n     if show_cml:\n        # get MSR\n        w_msr = msr(riskfree_rate, er, cov)\n        r_msr = portfolio_return(w_msr, er)\n        vol_msr = portfolio_vol(w_msr, cov)\n        msrD = pd.DataFrame(data = np.round(w_msr,3), index = er.index)\n        print(\"MSR portfolio is:\")\n        #print(np.round(w_msr,3))\n        print(msrD)\n        msrD.plot.bar(figsize=(15, 6), title = \"MSR\")\n        \n    \n    \n     if show_gmv:\n        w_gmv = gmv(cov)\n        r_gmv = portfolio_return(w_gmv, er)\n        vol_gmv = portfolio_vol(w_gmv, cov)\n        gmvD = pd.DataFrame(data = np.round(w_gmv,3), index = er.index)\n        print(\"GMV protfolio is:\")\n        #print(np.round(w_gmv,4))\n        print(gmvD)\n        gmvD.plot.bar(figsize=(15, 6), title = \"GMW\")\n        \n     if show_ew:\n        n = er.shape[0]\n        w_ew = np.repeat(1\/n, n)\n        r_ew = portfolio_return(w_ew, er)\n        vol_ew = portfolio_vol(w_ew, cov)\n        ewD = pd.DataFrame(data = np.round(w_ew,3), index = er.index)\n        print(\"EW portfolio is:\")\n        #print(np.round(w_ew,2))\n        print(ewD)\n        ewD.plot.bar(figsize=(15, 6), title = \"EW\")\n        \n     \n\n        \n    \n    \n\ndef get_oreturns_volatility_table(n_points, er, cov):\n    \n    weights = optimal_weights(n_points, er, cov)\n    rets = [portfolio_return(w, er) for w in weights]\n    vols = [portfolio_vol(w, cov) for w in weights]\n    ef = pd.DataFrame({\n        \"Returns\": rets, \n        \"Volatility\": vols\n    })\n    return ef\n\n\ndef plot_risk_averse_portfolio(volatility_table):\n    a = volatility_table\n    plt.axvline(x=min(a['Volatility']), color = 'red')\n    plt.plot(a['Volatility'],a['Returns'])\n    plt.show()\n    val = a[a['Volatility'] == min(a['Volatility'])]\n    print (\"Minimum volatility in \" + str(round(min(a['Volatility']),3)))\n    print (\"The coresponding return is \" + str(round(val.iloc[0]['Returns'],3)))\n\n    \n    \ndef msr(riskfree_rate, er, cov):\n    \"\"\"\n    Returns the weights of the portfolio that gives you the maximum sharpe ratio\n    given the riskfree rate and expected returns and a covariance matrix\n    \"\"\"\n    n = er.shape[0]\n    init_guess = np.repeat(1\/n, n)\n    bounds = ((0.0, 1.0),) * n # an N-tuple of 2-tuples!\n    # construct the constraints\n    weights_sum_to_1 = {'type': 'eq',\n                        'fun': lambda weights: np.sum(weights) - 1\n    }\n    def neg_sharpe(weights, riskfree_rate, er, cov):\n        \"\"\"\n        Returns the negative of the sharpe ratio\n        of the given portfolio\n        \"\"\"\n        r = portfolio_return(weights, er)\n        vol = portfolio_vol(weights, cov)\n        return -(r - riskfree_rate)\/vol\n\n    weights = minimize(neg_sharpe, init_guess,\n                       args=(riskfree_rate, er, cov), method='SLSQP',\n                       options={'disp': False},\n                       constraints=(weights_sum_to_1,),\n                       bounds=bounds)\n    return weights.x\n    \ndef gmv(cov):\n    \"\"\"\n    Returns the weights of the Global Minimum Volatility portfolio\n    given a covariance matrix\n    \"\"\"\n    n = cov.shape[0]\n    return msr(0, np.repeat(1, n), cov)\n\ndef portfolio_destrib(target_return, retPerAn, covarianceMatrix):\n    minvol = minimize_vol(target_return, retPerAn, covarianceMatrix)\n    msrD = pd.DataFrame(data = np.round(minvol,3), index = retPerAn.index)\n    print(msrD)\n    msrD.plot.bar(figsize=(15, 6), title = \"MSR\")","df02feaf":"!pip install yfinance","9ef43b0d":"import yfinance as yf\nimport pandas as pd\nimport numpy as np\n\n\n#define the ticker symbol\ntickerSymbol = ['MSFT','AAPL', 'AMD', 'BRK-B']","5a98f095":"#get data on this ticker\nStocks = pd.DataFrame()\nStocks.index.names = ['Date']","05905224":"for ticker in tickerSymbol:\n    tickerData = yf.download(ticker,'2015-01-01','2020-05-01')\n    tickerData = pd.DataFrame([tickerData['Close']]).T\n    tickerData.columns = [ticker]\n    \n    Stocks = pd.merge(Stocks,tickerData,on='Date',how='right')","fbde38bf":"Stocks","3f650429":"returns = Stocks\/Stocks.shift(1) - 1\nreturns","79145375":"lifetime_ret = (returns+1).prod()-1\nlifetime_ret","eb7a66b5":"retPerAn = annualize_rets(returns, 252)\nretPerAn","03af2c82":"covarianceMatrix  = returns.cov()\ncovarianceMatrix","a8cb2e17":"plot_ef(20, retPerAn, covarianceMatrix, legend=True, show_gmv=True, show_ew=True)","699bfdbc":"get_portfolios(retPerAn, covarianceMatrix)","f49caae8":"portfolio_destrib(0.25, retPerAn, covarianceMatrix)","2dcbe4b6":"portfolio_return(gmv(covarianceMatrix),retPerAn)","51774904":"Getting the GMV (Global minimum variance) expected return.","7fd9f022":"Plotting the efficient frontier for the best 20 portfolios in terms of return per unit of risk.","080b795a":"Installing required packages.","1330dd43":"Diversification cannot really be observed here, but just for demonstration purposes, we will use these famous stocks.","1d448138":"Getting the best portfolio out of these 4 stocks given that we are aiming at 25% return per year.","94643f65":"# All Functions needed for the process"}}