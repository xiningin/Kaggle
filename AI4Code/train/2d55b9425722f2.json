{"cell_type":{"b98d6bdb":"code","ad80438d":"code","b4a3d172":"code","052bdfcc":"code","f54c9a52":"code","4bf9d348":"code","a4832cd8":"code","a0e2fdd3":"code","e6baac33":"code","e20cfba6":"code","40f03d65":"code","2cfddeac":"code","1b8d7bc7":"code","8a3edc40":"code","a7ecf0e1":"code","f58de592":"code","13b27c77":"code","f100707b":"code","feea470d":"code","67031d0f":"code","830a5d5c":"code","e4f21b7a":"code","6cf486fe":"code","9f1cbdb4":"code","f5505d2f":"code","a133984d":"code","8db612ac":"code","70f1c0f5":"code","2f887361":"code","2bd16c9d":"code","28563077":"code","ed13b0f2":"code","2dd59130":"code","8bae6ef1":"code","1ba0a56b":"code","de9feb4d":"code","20c3b3c1":"code","7a977cf1":"code","05e85507":"code","886cc1dd":"code","348c03eb":"code","efe15421":"code","8ed12e24":"code","5447a822":"code","1d16c9aa":"code","54a05317":"code","6fee5ad2":"code","7309462b":"code","f308cbd2":"code","ab24fe98":"code","7ba9ec05":"code","267cb594":"code","c6f1c198":"code","aa810fa0":"code","788cb746":"code","2627fec4":"code","3109ec9d":"code","12a12cd3":"code","96cdd9cf":"code","fb52fb79":"code","18d9c325":"code","bdeadba2":"code","7ac7bc2f":"code","8eb6d069":"code","4aa1f045":"code","7f05249d":"code","55770f08":"code","3a7659b9":"code","2dd77abf":"code","144f3237":"code","856b5563":"code","c301ada2":"code","569c16af":"code","34e866a6":"code","e7f559e6":"code","f9102c2f":"code","99188cca":"markdown","e459dc20":"markdown","39a9b356":"markdown","dc75f8bb":"markdown","ad66ae54":"markdown","4cf512e3":"markdown","3bde7139":"markdown","7b30b9fd":"markdown","6a4937d7":"markdown","bf111ef1":"markdown","39224d50":"markdown","54a4d760":"markdown","b9e920c6":"markdown","2891ecb8":"markdown","949fe234":"markdown","ef1c0e37":"markdown","ba9c0c83":"markdown","a6688bc7":"markdown","07be6966":"markdown","7e64de2e":"markdown","9b2932d4":"markdown","010e7af6":"markdown","1f2a4ba5":"markdown","84fce65e":"markdown","e39a9a58":"markdown","4205dc54":"markdown","096960f7":"markdown","9b744456":"markdown","0aaf0485":"markdown","340058f5":"markdown","089d3f9e":"markdown","6b818bae":"markdown","17cdad36":"markdown","5ebc51d3":"markdown","305055c2":"markdown","12b1f9ae":"markdown","3d7db38b":"markdown","951aabe4":"markdown","8faa1a47":"markdown","e18f29aa":"markdown","7077d748":"markdown","d670e6a6":"markdown","3880563c":"markdown","986074fd":"markdown","cd266feb":"markdown","a4831d19":"markdown","b44bd6c0":"markdown","972c41bb":"markdown","0c773576":"markdown","e4e6bc33":"markdown","b0d55b06":"markdown","9d74e14d":"markdown","048c5e99":"markdown"},"source":{"b98d6bdb":"# Import Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\npd.pandas.set_option('display.max_columns',None)\nimport warnings\nwarnings.filterwarnings('ignore')","ad80438d":"# Read Dataset\ndataset= pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","b4a3d172":"dataset.shape","052bdfcc":"dataset.head()","f54c9a52":"for feature in dataset:\n    if dataset[feature].isnull().sum()>1:\n        print(feature,\":\", np.round(dataset[feature].isnull().mean(),4),'%')","4bf9d348":"for feature in dataset:\n    if dataset[feature].isnull().sum()>1:\n        data = dataset.copy()\n        # convert nul value into '1' and not null into \"0\"\n        data[feature] = np.where(data[feature].isnull(),1,0)\n        # Draw a grap to see the relation between salesPrice and features\n        data.groupby(feature)[\"SalePrice\"].median().plot.bar()\n        plt.show()","a4832cd8":"print(\"id is {}\".format(len(dataset.Id)))","a0e2fdd3":"numerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'O']\nprint(\"The length of Numerical_values is :\",len(numerical_features))\ndataset[numerical_features].head()","e6baac33":"# Extract the year variables from the numerical_features\nyear_feature = [feature for feature in numerical_features if 'Year' in feature or \"Yr\" in feature]\nyear_feature","e20cfba6":"# Analyze the Temporal variable \n\nfor feature in year_feature:\n    print(feature,dataset[feature].unique())\n","40f03d65":"# Analyze the Temporal Datetime Variable \n\ndataset.groupby(\"YrSold\")[\"SalePrice\"].median().plot()\nplt.xlabel(\"YrSold\")\nplt.ylabel(\"Median of Sale Price\")\nplt.title(\"YrSold vs Sales Price\")\n\n\n","2cfddeac":"dataset.groupby(\"GarageYrBlt\")[\"SalePrice\"].median().plot()\nplt.xlabel(\"GarageYrBlt\")\nplt.ylabel(\"Median of Sale Price\")\nplt.title(\"GarageYrBlt vs Sales Price\")","1b8d7bc7":"dataset.groupby(\"YearRemodAdd\")[\"SalePrice\"].median().plot()\nplt.xlabel(\"YearRemodAdd\")\nplt.ylabel(\"Median of Sale Price\")\nplt.title(\"YearRemodAdd vs Sales Price\")","8a3edc40":"dataset.groupby(\"YearBuilt\")[\"SalePrice\"].median().plot()\nplt.xlabel(\"YearBuilt\")\nplt.ylabel(\"Median of Sale Price\")\nplt.title(\"YearBuilt vs Sales Price\")","a7ecf0e1":"for feature in year_feature:\n    if feature != \"YrSold\":\n        data=dataset.copy()\n        # Analyze the difference between yrsold and other temporal variable\n        data[feature] = data['YrSold'] - data[feature]\n        plt.scatter(data[feature],data[\"SalePrice\"])\n        plt.xlabel(feature)\n        plt.ylabel(\"SalePrice\")\n        plt.show()\n\n        \n        \n        \n        ","f58de592":"# Discrete Feature\ndiscrete_Feature = [feature for feature in numerical_features if len(dataset[feature].unique())<25\n                    and feature not in year_feature+[\"Id\"] ]\n\nprint(\"The Discrete feature is :\",len(discrete_Feature))\ndiscrete_Feature","13b27c77":"dataset[discrete_Feature].head()","f100707b":"for feature in discrete_Feature:\n    data = dataset.copy()\n    data.groupby(feature)[\"SalePrice\"].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel(\"SalePrice\")\n    plt.show()","feea470d":"# continous Feature\ncontinous_Feature = [feature for feature in numerical_features if feature not in discrete_Feature+year_feature+[\"Id\"] ]\n\nprint(\"The Continous feature is :\",len(continous_Feature))\ncontinous_Feature","67031d0f":"for feature in continous_Feature:\n    data = dataset.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"SalePrice\")\n    plt.show()","830a5d5c":"# Logarithmic Transformation\nfor feature in continous_Feature:\n    data = dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] =  np.log(data[feature])\n        data[\"SalePrice\"] = np.log(data[\"SalePrice\"])\n        plt.scatter(data[feature],data[\"SalePrice\"])\n        plt.xlabel(feature)\n        plt.ylabel(\"SalePrice\")\n        plt.show()","e4f21b7a":"for feature in continous_Feature:\n    data = dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] =  np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.title(feature)\n        plt.show()","6cf486fe":"categorical_feature = [feature for feature in dataset.columns if dataset[feature].dtypes ==\"O\"]\nprint(len(categorical_feature))\ncategorical_feature","9f1cbdb4":"dataset[categorical_feature].head()","f5505d2f":"for feature in categorical_feature:\n    data = dataset.copy()\n    data.groupby(feature)[\"SalePrice\"].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel(\"SalePrice\")\n    plt.show()","a133984d":"# handle the missing value of categorical values\n\nfeature_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and  dataset[feature].dtypes ==\"O\"]\nfor feature in feature_nan:\n    print(\"{} percentage is {}%\".format(feature,np.round(dataset[feature].isnull().mean(),4)))\n","8db612ac":"dataset[feature_nan].isnull().sum()","70f1c0f5":"less_nan_feature = ['MasVnrType','BsmtQual','BsmtCond','BsmtFinType1','BsmtExposure','BsmtFinType2','GarageType','GarageFinish',\n                   'GarageQual','GarageCond']\nless_nan_feature","2f887361":"for feature in less_nan_feature:\n    fat = dataset[feature].value_counts()\n    print(feature,fat)","2bd16c9d":"def Impute_nan(dataset,variable):\n    frequent_category = dataset[variable].value_counts().index[0]\n    dataset[variable].fillna(frequent_category,inplace=True)\n\nfor feature in less_nan_feature:\n        Impute_nan(dataset,feature)    ","28563077":"dataset[feature_nan].isnull().sum()","ed13b0f2":"high_categorical_nan = ['FireplaceQu','Fence','Alley','MiscFeature','PoolQC']\nhigh_categorical_nan","2dd59130":"# Replace a null values to a new category\ndef Replace_Missig_Values_to_new_category(dataset,feature_nan):\n    data=dataset.copy()\n    data[feature_nan] = data[feature_nan].fillna('Missing')\n    return data\ndataset = Replace_Missig_Values_to_new_category(dataset,high_categorical_nan)\ndataset[high_categorical_nan].isnull().sum()\n","8bae6ef1":"dataset[\"Electrical\"] = np.where(dataset[\"Electrical\"].isnull(),data[\"Electrical\"].fillna('Missing'),data[\"Electrical\"])","1ba0a56b":"dataset[feature_nan].isnull().sum()","de9feb4d":"# Lets check the numerical missing values\nnumerical_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and  dataset[feature].dtypes !=\"O\"]\nfor feature in numerical_nan:\n    print(\"{} percentage is {}%\".format(feature,np.round(dataset[feature].isnull().mean(),4)))\n\n","20c3b3c1":"dataset[numerical_nan].head(25)","7a977cf1":"# now handle the null values of numerical values\nfor feature in numerical_nan:\n        median_values = dataset[feature].median()\n        dataset[feature].fillna(median_values,inplace=True)\ndataset[numerical_nan].isnull().sum()","05e85507":"dataset[year_feature].head()","886cc1dd":"# Lets Check the Temporal variable and convert into the numbers\nfor feature in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n    dataset[feature]= dataset[\"YrSold\"]-dataset[feature]","348c03eb":"dataset[year_feature].head()","efe15421":"# seprate the skew feature thats have not 0 value ,,'1stFlrSF','GrLivArea','SalePrice'\n\nskew_numerical_feature= ['LotFrontage','LotArea','1stFlrSF','GrLivArea','SalePrice']\n\nfor feature in skew_numerical_feature:\n    dataset[feature] = np.log(dataset[feature])\n\n","8ed12e24":"dataset[categorical_feature].head()","5447a822":"label_encoder = LabelEncoder()\none_hot_encoder = OneHotEncoder()","1d16c9aa":"for feature in categorical_feature:\n    print(dataset[feature].unique())\n    dataset[feature]=label_encoder.fit_transform(dataset[feature])\n    print(dataset[feature].unique())","54a05317":"dataset.to_csv(\"Encoded_data.csv\")","6fee5ad2":"dataset.head()","7309462b":"feature_scale =[feature for feature in dataset.columns if feature not in ['Id','SalePrice']]\n\n\nscaler = MinMaxScaler()\ndataset[feature_scale] = scaler.fit_transform(dataset[feature_scale])\n","f308cbd2":"dataset[feature_scale].head()","ab24fe98":"dataset.head()","7ba9ec05":"# Seprate the dependent and independent feature\n\n# Dependent feature:\ny= dataset[[\"SalePrice\"]]\n\n# for getting independent feature ,we need to drop Id and salePrice from dataset\n\n#independent feature\n\nX= dataset.drop(['Id','SalePrice'],axis=1)","267cb594":"X.head()","c6f1c198":"#Apply feature selection \n# 1:firstly i apply lasso regression to get the suitable value of alpha.\n\n# 2:if the value of alpha is high then less number of feature will selected.\n\n# 3: then i apply feature_selection model for select the suitable feature from dataset\nlasso = Lasso(alpha=0.005,random_state=0)\nfeature_selection_model = SelectFromModel(lasso)\nfeature_selection_model.fit(X, y)","aa810fa0":"feature_selection_model.get_support()","788cb746":"# View the Selected feature \nselected_feature = X.columns[(feature_selection_model.get_support())]\nselected_feature","2627fec4":"print(\"Total feature length is {}\".format((X.shape[1])))\n\nprint(\"Selected feature length is {}\".format(len(selected_feature)))\n\n#print(\" UnSelected feature length is {}\".format(np.sum(sel_.estimator_.coef_ == 0)))","3109ec9d":"#Spliting into training and testing dataset\nX_train, X_test, y_train,y_test =  train_test_split(X,y,test_size=0.25,random_state=0)","12a12cd3":"model = LinearRegression()\nmodel.fit(X,y)\n","96cdd9cf":"#predict the values\npredict_LRM = model.predict(X_test)","fb52fb79":"meanSQ_LRM= np.round(mean_squared_error(y_test,predict_LRM),6)\nadjust_r2_LRM = np.round(r2_score(y_test,predict_LRM)*100,3)\nmean_ABE_LRM = np.round(mean_absolute_error(y_test,predict_LRM),6)\nroot_MSE_LRM = np.round(np.sqrt(meanSQ_LRM),6)","18d9c325":"print(\"Adjusted R_Square of Linear Regression :\",adjust_r2_LRM)\nprint(\"Mean_Square_Error of Linear Regression :\",meanSQ_LRM)\nprint(\"Mean_Absolute_Error of Linear Regression :\",mean_ABE_LRM)\nprint(\"Root_Mean_Square_Error of Linear Regression :\",root_MSE_LRM)","bdeadba2":"regressor_svm = SVR()\nregressor_svm.fit(X,y)","7ac7bc2f":"#predict the values\npredict_SVR =regressor_svm.predict(X_test)","8eb6d069":"meanSQ_SVR= np.round(mean_squared_error(y_test,predict_SVR),6)\nadjust_r2_SVR = np.round(r2_score(y_test,predict_SVR)*100,3)\nmean_ABE_SVR = np.round(mean_absolute_error(y_test,predict_SVR),6)\nroot_MSE_SVR = np.round(np.sqrt(meanSQ_SVR),6)","4aa1f045":"print(\"Mean_Square_Error of Support Vector Regression :\",meanSQ_SVR)\nprint(\"Adjusted R_Square of Support Vector Regression :\",adjust_r2_SVR)\nprint(\"Mean_Absolute_Error of Support Vector Regression :\",mean_ABE_SVR)\nprint(\"Root_Mean_Square_Error of Support Vector Regression :\",root_MSE_SVR)","7f05249d":"#fit the model on dependent and \nrandom_forest = RandomForestRegressor()\nrandom_forest.fit(X_train,y_train)","55770f08":"#predict the values\npredict_RFR = random_forest.predict(X_test)","3a7659b9":"meanSQ_RFR= np.round(mean_squared_error(y_test,predict_RFR),6)\nadjust_r2_RFR = np.round(r2_score(y_test,predict_RFR)*100,3)\nmean_ABE_RFR = np.round(mean_absolute_error(y_test,predict_RFR),6)\nroot_MSE_RFR = np.round(np.sqrt(meanSQ_RFR),6)\n","2dd77abf":"print(\"Mean_Square_Error of Random Forest Regressor :\",meanSQ_RFR)\nprint(\"Adjusted R_Square of Random Forest Regressor :\",adjust_r2_RFR)\nprint(\"Mean_Absolute_Error of Random Forest Regressor :\",mean_ABE_RFR)\nprint(\"Root_Mean_Square_Error Random Forest Regressor :\",root_MSE_RFR)","144f3237":"GBR = GradientBoostingRegressor()\nGBR.fit(X_train,y_train)","856b5563":"#predict the values\npredict_GBR = GBR.predict(X_test)","c301ada2":"meanSQ_GBR= np.round(mean_squared_error(y_test,predict_GBR),6)\nadjust_r2_GBR = np.round(r2_score(y_test,predict_GBR)*100,3)\nmean_ABE_GBR = np.round(mean_absolute_error(y_test,predict_GBR),6)\nroot_MSE_GBR = np.round(np.sqrt(meanSQ_GBR),6)\n","569c16af":"print(\"Adjusted R_Square of Gradient Boosting Regressor :{}\".format(adjust_r2_GBR))\nprint(\"Mean_Square_Error of Gradient Boosting Regressor :{}\".format(meanSQ_GBR))\nprint(\"Mean_Absolute_Error of Gradient Boosting Regressor :{}\".format(mean_ABE_GBR))\nprint(\"Root_Mean_Square_Error Gradient Boosting Regressor :{}\".format(root_MSE_GBR))","34e866a6":"data={'LinearRegression':[meanSQ_LRM,mean_ABE_LRM ,root_MSE_LRM,adjust_r2_LRM],\n      \"Support_Vector_Regression\":[meanSQ_SVR,mean_ABE_SVR,root_MSE_SVR,adjust_r2_SVR,],\n      \"Random_Forest_Regressor\":[meanSQ_RFR,mean_ABE_RFR,root_MSE_RFR,adjust_r2_RFR],\n     \"Gradient_Boosting_Regressor\":[meanSQ_GBR,mean_ABE_GBR,root_MSE_GBR,adjust_r2_GBR]}","e7f559e6":"Evaluation =pd.DataFrame(data,index=['Mean_Square_Error','Mean_Absolute_Error','Root_Mean_Square_Error','Adjusted_R2'])","f9102c2f":"Evaluation","99188cca":"## **Outliers** <a class=\"anchor\" id=\"1.3\"><\/a>","e459dc20":"#### Model Implementation","39a9b356":" ## **1: Data Analysis Phase** <a class=\"anchor\" id=\"1\"><\/a>","dc75f8bb":"## **Regression Model** <a class=\"anchor\" id=\"4.2\"><\/a>","ad66ae54":"### **Continous Variable** <a class=\"anchor\" id=\"1.2.3\"><\/a>","4cf512e3":"#### Model Implementation","3bde7139":"## **Categorical feature** <a class=\"anchor\" id=\"1.4\"><\/a>","7b30b9fd":"### **Gradient Boosting Regressor** <a class=\"anchor\" id=\"4.3.2\"><\/a>","6a4937d7":"# House Price: Advanced Regression Techniques","bf111ef1":"## **Handling  Missing values of Numerical Feature** <a class=\"anchor\" id=\"2.2\"><\/a>","39224d50":"## **Encoding of categorical Features** <a class=\"anchor\" id=\"2.4\"><\/a>","54a4d760":"It is a Boosting technique.","b9e920c6":"# **Predict Results Score** <a class=\"anchor\" id=\"5\"><\/a>","2891ecb8":"Now analyze the numerical values to see the distribution of gausian","949fe234":"# **Feature Engineering Phase** <a class=\"anchor\" id=\"2\"><\/a>","ef1c0e37":"### Relationship between  categorical feature and dependent feature","ba9c0c83":"  # **Model Building** <a class=\"anchor\" id=\"4\"><\/a>","a6688bc7":"we see the relationship between missing values and SalesPrise , we need to convert the missing values into some meaningful\nvalues","07be6966":"Now the distribution is not a normal so we apply log function to make normal distribution of Gausian ","7e64de2e":"## **Numerical Features** <a class=\"anchor\" id=\"1.2\"><\/a>","9b2932d4":"####  Model Evaluation","010e7af6":" There are two types of Ensemble Techniques \n ","1f2a4ba5":"The feature thats dtype is object is called  a Categorical feature","84fce65e":"##### 2: Boosting\n1:ADA Boosting\n\n2:Gardient Boosting\n\n3:XgBoost.","e39a9a58":" we use Bagging technique and use RandomForestRegressor ","4205dc54":"Features that dtype is not \"object\" is called Numerical features","096960f7":"1: Linear Regression Model\n2: Support Vector Regression","9b744456":"### There are many missing values so there is need to see the relation between SalesPrise and missing values","0aaf0485":"\"Outliers are the values that are too large or too small\"    \nIt is always in continous variable and not in categorical values","340058f5":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Content\n1.\t[Data Analysis](#1)\n   - 1.1 [Missing Values](#1.1)\n   - 1.2 [Numerical Features](#1.2)\n        - 1.2.1 [Temporal Variable](#1.2.1)\n        - 1.2.2 [Discrete Variable](#1.2.2)\n        - 1.2.3 [Continous Variable](#1.2.3)\n   - 1.3 [Outliers](#1.3)\n   - 1.4 [Categorical feature ](#1.4)\n2.\t[Feature Engineering](#2)\n   - 2.1 [Handling Missing values of categorical Feature](#2.1)\n   - 2.2 [Handling Missing values of Numerical Feature ](#2.2)\n   - 2.3 [Encoding of categorical Features ](#2.4)\n   - 2.4 [Feature Scaling ](#2.5)\n   - 2.5 [Seprate the depedent and independent variable](#2.6)\n3.\t[Feature Selection](#3)\n   - 3.1 [Implementation of SelectFromModel using Lasso](#3.1)\n4.\t[Model Building](#4)\n   - 4.1 [Train Test Split ](#4.1)\n   - 4.2 [Regression Model](#4.2)\n        - 4.2.1 [Linear Regression](#4.2.1)\n        - 4.2.2 [Support Vector Regression](#4.2.2)\n   - 4.3 [Ensemble Techniques](#4.3)\n        - 4.3.1 [Random Forest Regressor](#4.3.1)\n        - 4.3.2 [Gradient Boosting Regressor](#4.3.2)\n5.\t[Predict Results Score](#5)\n       \n   ","089d3f9e":"### **Missing Values** <a class=\"anchor\" id=\"1.1\"><\/a>","6b818bae":"#### Model Implementation","17cdad36":"## **Seprate the  depedent and independent variable** <a class=\"anchor\" id=\"2.6\"><\/a>","5ebc51d3":"## **Train Test Split** <a class=\"anchor\" id=\"4.1\"><\/a>","305055c2":"# **Feature Selection** <a class=\"anchor\" id=\"3\"><\/a>","12b1f9ae":"#### Model Implementation","3d7db38b":"Temporal values (eg:Datetime Variable)","951aabe4":"### **Temporal Variable** <a class=\"anchor\" id=\"1.2.1\"><\/a>","8faa1a47":"####  Model Evaluation","e18f29aa":"### **Implementation of SelectFromModel using Lasso** <a class=\"anchor\" id=\"3.1\"><\/a>","7077d748":"### **Discrete Variable** <a class=\"anchor\" id=\"1.2.2\"><\/a>","d670e6a6":"##### 1:Bagging(Bootstrap aggregation):\n   1:Random Forest\n ","3880563c":"####  Model Evaluation","986074fd":"#####  According to the numbers , SVR is the best model .","cd266feb":"### Compare the Results of Models","a4831d19":"## **Feature Scaling** <a class=\"anchor\" id=\"2.5\"><\/a>","b44bd6c0":"### **Support Vector Regression** <a class=\"anchor\" id=\"4.2.2\"><\/a>","972c41bb":"## **Ensemble Techniques** <a class=\"anchor\" id=\"4.3\"><\/a>","0c773576":"####  Model Evaluation","e4e6bc33":"From our dataset \"id\" is not required ","b0d55b06":"### **Random Forest Regressor** <a class=\"anchor\" id=\"4.3.1\"><\/a>","9d74e14d":"### **Linear Regression** <a class=\"anchor\" id=\"4.2.1\"><\/a>","048c5e99":"## **Handling  Missing values of categorical Feature** <a class=\"anchor\" id=\"2.1\"><\/a>"}}