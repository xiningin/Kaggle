{"cell_type":{"4597845d":"code","f4d5e1e5":"code","74482fb1":"code","9fa3696f":"code","8d206a90":"code","056ab763":"code","2075c2f9":"code","1c3b2d29":"code","c5212674":"code","38c0e31b":"code","76893562":"code","0685c56d":"code","ad5a0932":"code","dab69212":"code","0c41bdfa":"code","39ed7105":"code","af7e1327":"markdown","d0cd1b0e":"markdown","40471ddf":"markdown","b7f882cb":"markdown","364f5291":"markdown","1e065392":"markdown","d39c3eef":"markdown","e6d71c99":"markdown","d9c31d1d":"markdown","6055d319":"markdown","220c3954":"markdown"},"source":{"4597845d":"import pandas as pd\r\nimport seaborn as sns\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nfrom sklearn import preprocessing\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.ensemble import RandomForestRegressor\r\nfrom sklearn.preprocessing import RobustScaler\r\nfrom sklearn import metrics\r\n\r\n%matplotlib inline","f4d5e1e5":"train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\r\ntrain.set_index('Id', inplace=True)\r\ntest.set_index('Id', inplace=True)\r\n","74482fb1":"train.describe()\r\n","9fa3696f":"test.describe()","8d206a90":"corr = train.corr()\r\ncorr_1=corr['SalePrice'].copy()\r\n\r\ncorr_1.sort_values(inplace=True, ascending=False)\r\ncorr_1=pd.DataFrame(corr_1)\r\ncorr_1.rename(columns = {'SalePrice':'Correlation'}, inplace=True)\r\n\r\nplt.figure(figsize=(10,10))\r\nsns.heatmap(corr_1, annot=True)","056ab763":"# Removing outliers for a better model\r\ntrain.drop(train[(train['GrLivArea']>4000) &( train['SalePrice']<200000)].index, inplace=True)\r\ntrain.drop(train[(train['GarageArea']>1200)&(train['SalePrice']<300000)].index, inplace=True)\r\ntrain.drop(train[(train['GarageCars']>3)].index, inplace=True)\r\n\r\nall_data = pd.concat([train, test])\r\n\r\n# Removing low correlation columns\r\nall_data.drop([\"PoolArea\", \"MoSold\", \"3SsnPorch\", \"BsmtFinSF2\", \"BsmtHalfBath\",\"MiscVal\", \"LowQualFinSF\", \r\n               \"YrSold\", \"OverallCond\", \"MSSubClass\",\"EnclosedPorch\",\"KitchenAbvGr\"],\r\n               axis = 1, inplace=True)\r\ntest.drop([\"PoolArea\", \"MoSold\", \"3SsnPorch\", \"BsmtFinSF2\", \"BsmtHalfBath\",\"MiscVal\", \"LowQualFinSF\", \r\n           \"YrSold\", \"OverallCond\", \"MSSubClass\",\"EnclosedPorch\",\"KitchenAbvGr\"],\r\n           axis = 1, inplace=True)\r\n\r\n# Checking the percentage of null values\r\nnull_vals = ( all_data.isnull().sum()\/all_data.isnull().count() ).sort_values(ascending=False)\r\nnull_vals = pd.DataFrame(null_vals)\r\nnull_vals.rename(columns = {0:'Null Percent'}, inplace=True)\r\ndisplay(null_vals.head(15))\r\nall_data","2075c2f9":"#Dropping columns with high null values\r\nall_data.drop(train[['PoolQC','MiscFeature','Alley','Fence']],axis=1, inplace=True)\r\ntest.drop(train[['PoolQC','MiscFeature','Alley','Fence']],axis=1, inplace=True)\r\n\r\n\r\n# Filling in the remaining null values\r\nnum_cols = test.select_dtypes(exclude='object').columns\r\ncat_cols = all_data.select_dtypes(include='object').columns\r\n\r\nfor col in num_cols:\r\n    all_data[col].fillna(all_data[col].mean(), inplace=True)\r\n\r\nfor col in cat_cols:\r\n    all_data[col].fillna(all_data[col].mode()[0], inplace=True)\r\n\r\n\r\nnull_vals = ( all_data.isnull().sum()\/all_data.isnull().count() ).sort_values(ascending=False)\r\nnull_vals = pd.DataFrame(null_vals)\r\nnull_vals.rename(columns = {0:'Null Percent'}, inplace=True)\r\ndisplay(null_vals.head(15))","1c3b2d29":"g=sns.pairplot(train, y_vars='SalePrice', dropna=True, \r\n               x_vars=['GrLivArea','GarageArea','TotalBsmtSF','1stFlrSF'],\r\n               kind = 'scatter');\r\ng.fig.set_size_inches(24,6)\r\n","c5212674":"g=sns.pairplot(train,y_vars='SalePrice', dropna=True, \r\n               x_vars=['OverallQual','GarageCars'],\r\n               kind = 'hist');\r\ng.fig.set_size_inches(26,13)\r\n","38c0e31b":"sns.displot(train['SalePrice'], kde=True)\r\n\r\n# Change to log to get a normalised distribution for better perf\r\ntrain['SalePrice'] = np.log(train['SalePrice'])\r\n\r\nsns.displot(train['SalePrice'], kde=True)\r\n","76893562":"LabelEncoder = preprocessing.LabelEncoder()\r\n\r\nall_data[cat_cols]=all_data[cat_cols].apply(LabelEncoder.fit_transform)\r\nall_data.head(20)","0685c56d":"train_rfr = all_data[:len(train)]\r\ntrain_rfr['SalePrice'] = np.log(train_rfr['SalePrice'])\r\n\r\nx_train_rfr = train_rfr.drop('SalePrice', axis=1)\r\ny_train_rfr = train_rfr['SalePrice']\r\n\r\n# Scaling the data\r\nmms = RobustScaler().fit(x_train_rfr)\r\nx_train_rfr = mms.transform(x_train_rfr)\r\n# 1000\r\nregressor = RandomForestRegressor(n_estimators = 1000, n_jobs=-1)\r\n\r\nX_train, X_test, y_train, y_test = train_test_split(x_train_rfr, y_train_rfr, test_size=0.2 )\r\nregressor.fit(X_train, y_train)\r\n","ad5a0932":"y_pred = regressor.predict(X_test)\r\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","dab69212":"test_rfr = all_data[len(train):]\r\ntest_rfr.drop('SalePrice', axis=1, inplace=True)\r\ntest_rfr = mms.transform(test_rfr)\r\n\r\n","0c41bdfa":"final_pred = regressor.predict(test_rfr)\r\n","39ed7105":"final_pred\r\nsubmit = pd.DataFrame(final_pred)\r\nsubmit.rename(columns = {0:'SalePrice'}, inplace=True)\r\nsubmit.index=test.index\r\nsubmit['SalePrice'] = np.exp(submit['SalePrice'])\r\n\r\nsubmit.to_csv('submit.csv')","af7e1327":"## Making the Model\r\n\r\n### Cross Validation","d0cd1b0e":"### Submitting ","40471ddf":"# Predicting House Prices","b7f882cb":"## Label Encoding","364f5291":"## Looking at high correlation plots in detail","1e065392":"### Predicting values for the test dataset","d39c3eef":"## Cleaning Data","e6d71c99":"### All the imports","d9c31d1d":"## Predicting for the test dataset","6055d319":"## Correlation with SalePrice","220c3954":"### Reading the data"}}