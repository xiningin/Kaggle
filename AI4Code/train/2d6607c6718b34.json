{"cell_type":{"476673ed":"code","51a849fb":"code","6d8812e9":"code","644c5f56":"code","d7fffb5b":"code","ee69589f":"code","c59705b4":"code","1a570d85":"code","9d8cdb28":"code","e53823df":"code","e7f6609a":"code","93e0efe8":"code","36567f02":"code","e2d6ed01":"code","fee248fc":"code","245699c9":"code","4fd1ba94":"code","ea78d7a2":"code","390d02bb":"code","672ffe83":"code","6bf176ed":"code","f299c9af":"code","7625492e":"code","6ff4d24e":"code","cb884cdd":"code","b3f98275":"code","110deb54":"code","66866869":"code","25741f6b":"code","ade77888":"markdown","c80329ca":"markdown","38a3bb01":"markdown","b677c351":"markdown","1d828ec5":"markdown","87882320":"markdown","de097ada":"markdown","72dbef40":"markdown","7332ef73":"markdown","711765c9":"markdown","7b07235c":"markdown","4d1e4dc6":"markdown","4c0e8b5c":"markdown","c1c4c6d2":"markdown","cc065efa":"markdown","e9bc13e7":"markdown","63f871ed":"markdown","c083724b":"markdown","9067da3b":"markdown","7e726379":"markdown","2345853b":"markdown","cbc33f79":"markdown","e333d51f":"markdown"},"source":{"476673ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51a849fb":"# Import the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import DBSCAN \nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import MeanShift\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import AffinityPropagation\nfrom sklearn.cluster import OPTICS","6d8812e9":"data = pd.read_csv('\/kaggle\/input\/mall-customers\/Mall_Customers.csv')","644c5f56":"X = data.iloc[:, [3, 4]].values","d7fffb5b":"plt.figure(figsize=(15,10))\nsns.set(style = 'whitegrid')\nplt.title('Distribution',fontsize=15)\nplt.axis('off')\nsns.distplot(X,color='orange')\nplt.xlabel('Distribution')\nplt.ylabel('#Customers')","ee69589f":"plt.figure(figsize=(22,10))\nsns.countplot(data['Annual Income (k$)'], palette = 'rainbow')\nplt.title('Distribution of Annual Income (k$)', fontsize = 20)\nplt.show()","c59705b4":"plt.figure(figsize=(15,10))\nsns.set(style = 'whitegrid')\nsns.distplot(data['Annual Income (k$)'],color='g')\nplt.title('Distribution of Annual Income(k$)', fontsize = 15)\nplt.xlabel('Range of Annual Income(k$)')\nplt.ylabel('#Customers')","1a570d85":"plt.figure(figsize=(15,10))\nsns.countplot(data['Age'], palette = 'cool')\nplt.title('Distribution of Age', fontsize = 20)\nplt.show()","9d8cdb28":"plt.figure(figsize=(15,10))\nsns.set(style = 'whitegrid')\nsns.distplot(data['Age'],color='m')\nplt.title('Distribution of Age', fontsize = 15)\nplt.xlabel('Range of Age')\nplt.ylabel('#Customers')","e53823df":"plt.figure(figsize=(25,10))\nsns.countplot(data['Spending Score (1-100)'], palette = 'copper')\nplt.title('Distribution of Spending Score (1-100)', fontsize = 20)\nplt.show()","e7f6609a":"plt.figure(figsize=(15,10))\nsns.set(style = 'whitegrid')\nsns.distplot(data['Spending Score (1-100)'],color='r')\nplt.title('Distribution of Spending Score (1-100)', fontsize = 15)\nplt.xlabel('Range of Spending Score (1-100)')\nplt.ylabel('#Customers')","93e0efe8":"plt.figure(figsize=(10,10))\nsize = data['Genre'].value_counts()\ncolors = ['pink', 'yellow']\nplt.pie(size, colors = colors, explode = [0, 0.15], labels = ['Female', 'Male'], shadow = True, autopct = '%.2f%%')\nplt.title('Gender', fontsize = 15)\nplt.axis('off')\nplt.legend()\nplt.show()","36567f02":"sns.catplot(x=\"Genre\", kind=\"count\", palette=\"cool\", data=data)","e2d6ed01":"plt.figure(figsize=(15,10))\nplt.title('Heatmap',fontsize=15)\nsns.heatmap(X,cmap='BuPu')","fee248fc":"plt.figure(figsize=(15,10))\nsns.heatmap(data.corr(), cmap = 'Greens', annot = True)\nplt.title('Heatmap for the Data', fontsize = 15)\nplt.show()","245699c9":"sns.pairplot(data)","4fd1ba94":"# Use of the elbow method to find the optimal number of clusters\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.figure(figsize=(15,15))\nplt.scatter(range(1, 11),wcss,c='b',s=100)\nplt.plot(range(1, 11),wcss,c='r',linewidth=4)\nplt.title('The Elbow Method',fontsize=20)\nplt.xlabel('Number of clusters',fontsize=20)\nplt.ylabel('Within-cluster-sum-of-squares',fontsize=20)\nplt.show()","ea78d7a2":"# Train the K-Means model on the dataset\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 0)\ny_kmeans = kmeans.fit_predict(X)","390d02bb":"# Visualization of the clusters of customers\nplt.figure(figsize=(15,15))\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 60, c = 'c', label = '#1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 60, c = 'g', label = '#2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 60, c = 'm', label = '#3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 60, c = 'b', label = '#4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 60, c = 'r', label = '#5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 100, c = 'yellow', label = 'Centroids')\nplt.title('Clusters',fontsize=20)\nplt.xlabel('Annual Income (k$)',fontsize=20)\nplt.ylabel('Spending Score (1-100)',fontsize=20)\nplt.legend()\nplt.show()","672ffe83":"# Use the dendrogram to find the optimal number of clusters\nplt.figure(figsize=(25,15))\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.title('Dendrogram',fontsize=20)\nplt.xlabel('Customers',fontsize=20)\nplt.ylabel('Euclidean distances',fontsize=20)\nplt.show()","6bf176ed":"# Train the Hierarchical Clustering model on the dataset\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)","f299c9af":"# Visualization of the clusters of customers\nplt.figure(figsize=(15,15))\nplt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 60, c = 'm', label = '#1')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 60, c = 'r', label = '#2')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 60, c = 'b', label = '#3')\nplt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 60, c = 'g', label = '#4')\nplt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 60, c = 'c', label = '#5')\nplt.title('Clusters',fontsize=20)\nplt.xlabel('Annual Income (k$)',fontsize=20)\nplt.ylabel('Spending Score (1-100)',fontsize=20)\nplt.legend()\nplt.show()","7625492e":"def dbscan(X, eps, min_samples):\n    ss = StandardScaler()\n    X = ss.fit_transform(X)\n    db = DBSCAN(eps=eps, min_samples=min_samples)\n    db.fit(X)\n    y_pred = db.fit_predict(X)\n    plt.figure(figsize=(10,10))\n    plt.title('Clusters',fontsize=20)\n    plt.xlabel('Annual Income (k$)',fontsize=20)\n    plt.ylabel('Spending Score (1-100)',fontsize=20)\n    plt.legend()\n    plt.scatter(X[:,0], X[:,1],c=y_pred, cmap='coolwarm')\n    plt.title(\"DBSCAN\")","6ff4d24e":"dbscan(X,eps=0.275,min_samples=5)","cb884cdd":"brc = Birch(n_clusters=5)\nbrc.fit(X)\nbrc_y_pred = brc.predict(X)\nplt.figure(figsize=(10,10))\nplt.title('Clusters',fontsize=20)\nplt.xlabel('Annual Income (k$)',fontsize=20)\nplt.ylabel('Spending Score (1-100)',fontsize=20)\nplt.legend()\nplt.scatter(X[:,0], X[:,1],c=brc_y_pred, cmap='coolwarm')\nplt.title(\"BIRCH\")","b3f98275":"gmm = GaussianMixture(n_components=5)\ngmm.fit(X)\ngmm_y_pred = gmm.predict(X)\nplt.figure(figsize=(10,10))\nplt.title('Clusters',fontsize=20)\nplt.xlabel('Annual Income (k$)',fontsize=20)\nplt.ylabel('Spending Score (1-100)',fontsize=20)\nplt.legend()\nplt.scatter(X[:,0], X[:,1],c=gmm_y_pred, cmap='coolwarm')\nplt.title(\"Gaussian Mixture Model\")","110deb54":"ap = AffinityPropagation(random_state=0)\nap.fit(X)\nap_y_pred = ap.predict(X)\nplt.figure(figsize=(10,10))\nplt.title('Clusters',fontsize=20)\nplt.xlabel('Annual Income (k$)',fontsize=20)\nplt.ylabel('Spending Score (1-100)',fontsize=20)\nplt.legend()\nplt.scatter(X[:,0], X[:,1],c=ap_y_pred, cmap='spring')\nplt.title(\"Affinity Propagation Model\")","66866869":"ms = MeanShift(bandwidth=2)\nms.fit(X)\nms_y_pred = ms.predict(X)\nplt.figure(figsize=(10,10))\nplt.title('Clusters',fontsize=20)\nplt.xlabel('Annual Income (k$)',fontsize=20)\nplt.ylabel('Spending Score (1-100)',fontsize=20)\nplt.legend()\nplt.scatter(X[:,0], X[:,1],c=ms_y_pred, cmap='seismic')\nplt.title(\"MeanShift Model\")","25741f6b":"opt = OPTICS(min_samples=5)\nopt_y_pred = opt.fit_predict(X)\nplt.figure(figsize=(10,10))\nplt.title('Clusters',fontsize=20)\nplt.xlabel('Annual Income (k$)',fontsize=20)\nplt.ylabel('Spending Score (1-100)',fontsize=20)\nplt.legend()\nplt.scatter(X[:,0], X[:,1],c=opt_y_pred, cmap='inferno')\nplt.title(\"OPTICS Model\")","ade77888":"**Visualizing data**","c80329ca":"**Import libraries**","38a3bb01":"# DBSCAN","b677c351":"# K-Means Clustering","1d828ec5":"The customers in first cluster(cyan) have average annual income as well as average spending score.In case of the second cluster(green),customers with lower annual income but higher spending score belong to it.People with both higher annual income and higher spending score belong to third cluster(magenta).The customers in fourth cluster(blue) have lower annual income and lower spending score.People in fifth cluster(red) have lower spending score but have a high annual income!","87882320":"Don't think they are that impressive!","de097ada":"# Gaussian Mixture Model","72dbef40":"# Hierarchical Clustering","7332ef73":"Training time!","711765c9":"Visualization!","7b07235c":"Quite impressive!!","4d1e4dc6":"We will use the elbow method to check the optimal number of clusters","4c0e8b5c":"Here comes the training part","c1c4c6d2":"Nice!","cc065efa":"**Please upvote this notebook if you like it.Have a nice day!Thank you..**","e9bc13e7":"**Import the dataset**","63f871ed":"# Birch","c083724b":"Not that good:(","9067da3b":"Let us visualize the dendrogram :)","7e726379":"# Affinity Propagation","2345853b":"# Mean Shift","cbc33f79":"As you can see the optimal number of clusters is five!","e333d51f":"# OPTICS"}}