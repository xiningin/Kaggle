{"cell_type":{"bd3ba89f":"code","23c7a0e8":"code","647270f7":"code","2e37d8d9":"code","da22e0cf":"code","04cb922b":"code","5563aa9d":"code","90f6e2ef":"code","70807cc6":"code","eb440604":"code","be22b50c":"code","251b177a":"code","043f2694":"code","093e325f":"code","123a7477":"code","857ba734":"code","da8da180":"code","c68d07cc":"code","955db70b":"code","a7668970":"code","367cb900":"code","cad91421":"code","4b443e8b":"code","7b22b324":"code","09cc2f39":"code","8a30104d":"markdown","76418419":"markdown","db1881ba":"markdown"},"source":{"bd3ba89f":"# Import the general libraries\n\nimport os \nimport pandas as pd \nimport sklearn \nimport matplotlib.pyplot as plt\n\n# Import all specific modules\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","23c7a0e8":"# Verify the dataset path \n\nos.listdir('..\/input\/heart-disease-uci')","647270f7":"# Import the dataset\n\ndf_heart = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","2e37d8d9":"# Show the dataset\n\ndf_heart.head()","da22e0cf":"# Save the dataset without target row\n\ndf_heart_features = df_heart.drop(['target'], axis=1)\ndf_heart_features.head()","04cb922b":"# Create a df just with target row\n\ndf_target = df_heart['target']\ndf_target.head()","5563aa9d":"# We gonna normalize the data\n\ndf_heart_features = StandardScaler().fit_transform(df_heart_features)","90f6e2ef":"# Cut train test and test split \n\nX_train, X_test, y_train, y_test = train_test_split(df_heart_features, df_target, test_size=0.3, random_state=42)","70807cc6":"# We gonna review the size\n\nprint(\" X_train size: \" ,X_train.shape)\nprint(\" y_train size: \" ,y_train.shape)","eb440604":"# Config to apply pca \n\npca = PCA(n_components = 3)","be22b50c":"# we fit pca for own train data\n\npca.fit(X_train)","251b177a":"# We are the same with IPCA and we add batch_size to keep training slowly and combine with the final result\n\nipca = IncrementalPCA(n_components=3, batch_size=10)","043f2694":"# we fit ipca for own train data \n\nipca.fit(X_train)","093e325f":"'''We are going to graph what the pca automatically generated for me on the x-axis, against the y-axis, \nthe value of the importance in each of these components, so we can identify which ones are really important \nfor our model'''\n\nplt.plot(range(len(pca.explained_variance_)), pca.explained_variance_ratio_)\nplt.show()","123a7477":"# We gonna config the logistic regression \n\nregLog = LogisticRegression(solver='lbfgs')","857ba734":"# We gonna config the train data of PCA\n\ndf_train = pca.transform(X_train)\ndf_test = pca.transform(X_test)","da8da180":"# We send data at logistic regression\n\nregLog.fit(df_train, y_train)","c68d07cc":"# We gonna calcula the score\n\nprint(\"Score PCA: \", regLog.score(df_test, y_test))","955db70b":"# We gonna config the train data of IPCA\n\ndf_train = ipca.transform(X_train)\ndf_test = ipca.transform(X_test)","a7668970":"# We send data at logistic regression\n\nregLog.fit(df_train, y_train)","367cb900":"# We gonna calcula the score\n\nprint(\"SCORE IPCA: \", regLog.score(df_test, y_test))","cad91421":"# Apply polynomial kernel function\nkpca = KernelPCA(n_components=4, kernel='poly' )\n    \n# Fit the data\nkpca.fit(X_train)\n \n# Apply the algoritm to test and train dataset\ndt_train = kpca.transform(X_train)\ndt_test = kpca.transform(X_test)\n \n# Apply logistic regression later reduce the dimensionality\nlogistic = LogisticRegression(solver='lbfgs')\n \n# Train the model\nlogistic.fit(dt_train, y_train)\n \n# Print the results\nprint(\"SCORE KPCA: \", logistic.score(dt_test, y_test))","4b443e8b":"knn_class = KNeighborsClassifier().fit(X_train, y_train)\nknn_prediction = knn_class.predict(X_test)\nprint('='*64)\nprint('SCORE con KNN: ', accuracy_score(knn_prediction, y_test))","7b22b324":"estimators = {\n        'LogisticRegression' : LogisticRegression(),\n        'SVC' : SVC(),\n        'LinearSVC' : LinearSVC(),\n        'SGD' : SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5),\n        'KNN' : KNeighborsClassifier(),\n        'DecisionTreeClf' : DecisionTreeClassifier(),\n        'RandomTreeForest' : RandomForestClassifier(random_state=0)\n    }\nfor name, estimator in estimators.items():\n    bag_class = BaggingClassifier(base_estimator=estimator, n_estimators=50).fit(X_train, y_train)\n    bag_predict = bag_class.predict(X_test)\n    print('='*64)\n    print('SCORE Bagging with {} : {}'.format(name, accuracy_score(bag_predict, y_test)))","09cc2f39":"# Definimos nuestro clasificador, definimos 50 arbole y le agregamos el ajuste\n# Define the classifier, define 50 threes and add the fit\nboost = GradientBoostingClassifier(n_estimators=50).fit(X_train, y_train)\n\n# Generate the predictions \nboost_pred = boost.predict(X_test)\nprint(\"=\"*64)\nprint(\"GradientBoostingClassifier: \", accuracy_score(boost_pred, y_test)) \n\nestimators = range(10, 200, 10)\ntotal_accuracy = []\nfor i in estimators:\n    boost = GradientBoostingClassifier(n_estimators=i).fit(X_train, y_train)\n    boost_pred = boost.predict(X_test)\n\n    total_accuracy.append(accuracy_score(y_test, boost_pred))\n    \nplt.plot(estimators, total_accuracy)\nplt.xlabel('Estimators')\nplt.ylabel('Accuracy')\nplt.show()","8a30104d":"## Apply All Clasifiers","76418419":"## Apply a kernel PCA","db1881ba":"## Boosting"}}