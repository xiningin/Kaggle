{"cell_type":{"2d8165e6":"code","2b775ccc":"code","9abbeab6":"code","9401fb8d":"code","ac1e18bd":"code","b59d9240":"code","e3945af5":"code","3b77653a":"code","bf5eda76":"code","719301c4":"code","d66f4ae8":"code","2561a874":"code","0d0e5598":"code","e697624c":"code","d0622631":"code","8105e152":"markdown","b002c7a3":"markdown","ed886f54":"markdown"},"source":{"2d8165e6":"%matplotlib inline\nimport pandas as pd\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\npd.set_option('display.max_columns', 99)\npd.set_option('display.max_rows', 99)\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\nimport datetime as dt","2b775ccc":"import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nimport seaborn as sns\nsns.set_palette(sns.color_palette('tab20', 20))\n\nimport plotly.express as px\nimport plotly.graph_objects as go","9abbeab6":"DATEFORMAT = '%Y-%m-%d'\n\n\ndef get_comp_data(COMP):\n    train = pd.read_csv(f'{COMP}\/train.csv')\n    test = pd.read_csv(f'{COMP}\/test.csv')\n    print(train.shape, test.shape)\n    train['Country_Region'] = train['Country_Region'].str.replace(',', '')\n    test['Country_Region'] = test['Country_Region'].str.replace(',', '')\n\n    train['Location'] = train['Country_Region'] + '-' + train['Province_State'].fillna('')\n\n    test['Location'] = test['Country_Region'] + '-' + test['Province_State'].fillna('')\n\n    train['LogConfirmed'] = to_log(train.ConfirmedCases)\n    train['LogFatalities'] = to_log(train.Fatalities)\n    train = train.drop(columns=['Province_State'])\n    test = test.drop(columns=['Province_State'])\n\n    country_codes = pd.read_csv('..\/input\/covid19-metadata\/country_codes.csv', keep_default_na=False)\n    train = train.merge(country_codes, on='Country_Region', how='left')\n    test = test.merge(country_codes, on='Country_Region', how='left')\n\n    train['DateTime'] = pd.to_datetime(train['Date'])\n    test['DateTime'] = pd.to_datetime(test['Date'])\n    \n    return train, test\n\n\ndef process_each_location(df):\n    dfs = []\n    for loc, df in tqdm(df.groupby('Location')):\n        df = df.sort_values(by='Date')\n        df['Fatalities'] = df['Fatalities'].cummax()\n        df['ConfirmedCases'] = df['ConfirmedCases'].cummax()\n        df['LogFatalities'] = df['LogFatalities'].cummax()\n        df['LogConfirmed'] = df['LogConfirmed'].cummax()\n        df['LogConfirmedNextDay'] = df['LogConfirmed'].shift(-1)\n        df['ConfirmedNextDay'] = df['ConfirmedCases'].shift(-1)\n        df['DateNextDay'] = df['Date'].shift(-1)\n        df['LogFatalitiesNextDay'] = df['LogFatalities'].shift(-1)\n        df['FatalitiesNextDay'] = df['Fatalities'].shift(-1)\n        df['LogConfirmedDelta'] = df['LogConfirmedNextDay'] - df['LogConfirmed']\n        df['ConfirmedDelta'] = df['ConfirmedNextDay'] - df['ConfirmedCases']\n        df['LogFatalitiesDelta'] = df['LogFatalitiesNextDay'] - df['LogFatalities']\n        df['FatalitiesDelta'] = df['FatalitiesNextDay'] - df['Fatalities']\n        dfs.append(df)\n    return pd.concat(dfs)\n\n\ndef add_days(d, k):\n    return dt.datetime.strptime(d, DATEFORMAT) + dt.timedelta(days=k)\n\n\ndef to_log(x):\n    return np.log(x + 1)\n\n\ndef to_exp(x):\n    return np.exp(x) - 1","9401fb8d":"COMP = '..\/input\/covid19-global-forecasting-week-4\/'\nstart = dt.datetime.now()\ntrain, test = get_comp_data(COMP)\ntrain.shape, test.shape\ntrain.head(2)\ntest.head(2)","ac1e18bd":"train[train.geo_region.isna()].Country_Region.unique()\ntrain = train.fillna('#N\/A')\ntest = test.fillna('#N\/A')\n\ntrain[train.duplicated(['Date', 'Location'])]\ntrain.count()\nTRAIN_START = train.Date.min()\nTEST_START = test.Date.min()\nTRAIN_END = train.Date.max()\nTEST_END = test.Date.max()\nTRAIN_START, TRAIN_END, TEST_START, TEST_END\n\ntrain_w2, test_w2 = get_comp_data('..\/input\/covid19-global-forecasting-week-2')\ntrain_w2.shape, test_w2.shape\ntrain_w3, test_w3 = get_comp_data('..\/input\/covid19-global-forecasting-week-3')\ntrain_w3.shape, test_w3.shape","b59d9240":"top_submissions = dict(\n    beluga = '..\/input\/covid-19-w3-a-few-charts-and-submission\/submission.csv',\n    Kaz = '..\/input\/gbr-169v3-v2\/submission.csv',\n    Lockdown = '..\/input\/gbt3n\/submission.csv',\n    PDD = '..\/input\/cv19w3-v3fix-cpmp-oscii-belug-full-8118\/submission.csv',\n    KGMON = '..\/input\/covid19-w3-submission-blend-4-models\/submission.csv',\n    Vopani = '..\/input\/covid-19-w3-lgb-mad\/submission.csv',\n    OsciiArt = '..\/input\/covid-19-lightgbm-with-weather-2\/submission.csv',\n    Northquay = '..\/input\/c19-wk3-uploader\/submission.csv',\n)\ntop_submissions\n\npredictions = train.copy()\npredictions.shape\n\nSUBM_DIR = '.\/data\/subms\/'\nfor team, f in top_submissions.items():\n    s = pd.read_csv(f)\n    s = s.merge(test_w3, on='ForecastId')\n    s = s[['Location', 'Date', 'ConfirmedCases', 'Fatalities']]\n    \n    predictions = predictions.merge(s, on=['Location', 'Date'], suffixes = ['', f' ({team})'], how='outer')\n    s.shape\n    s.tail(2)\n\n","e3945af5":"daily_total = predictions.groupby('Date').sum().reset_index()\ndaily_total = daily_total[daily_total.Date > train_w3.Date.max()]\ncols = ['Date'] + [c for c in predictions.columns if c.startswith('Confirmed')]\n\nmelted = pd.melt(daily_total[cols], id_vars='Date')\n\nfig2 = px.line(melted, x='Date', y='value', color='variable')\n_ = fig2.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'W3 Submissions - Confirmed Cases [Updated: {TRAIN_END}]'\n)\nfig2.show()","3b77653a":"daily_total = predictions.groupby('Date').sum().reset_index()\ndaily_total = daily_total[daily_total.Date > train_w3.Date.max()]\ncols = ['Date'] + [c for c in predictions.columns if c.startswith('Fatalities')]\n\nmelted = pd.melt(daily_total[cols], id_vars='Date')\n\nfig2 = px.line(melted, x='Date', y='value', color='variable')\n_ = fig2.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'W3 Submissions - Fatalities [Updated: {TRAIN_END}]'\n)\nfig2.show()","bf5eda76":"top_submissions = dict(\n    beluga = '..\/input\/covid-19-a-few-charts-and-a-simple-baseline\/submission.csv',\n    Kaz = '..\/input\/gr1621-v2\/submission.csv',\n    KGMON = '..\/input\/covid19-w2-final-v2\/submission.csv',\n    Vopani = '..\/input\/covid19-metadata\/w2_submission_Vopani.csv',\n    OsciiArt = '..\/input\/covid19-metadata\/w2_submission_OsciiArt.csv',\n    DAV = '..\/input\/kernel303a0b031a\/submission.csv'\n)\ntop_submissions\n\npredictions = train.copy()\npredictions.shape\n\nSUBM_DIR = '.\/data\/subms\/'\nfor team, f in top_submissions.items():\n    s = pd.read_csv(f)\n    s = s.merge(test_w2, on='ForecastId')\n    s = s[['Location', 'Date', 'ConfirmedCases', 'Fatalities']]\n    \n    predictions = predictions.merge(s, on=['Location', 'Date'], suffixes = ['', f' ({team})'], how='outer')\n    s.shape\n    s.tail(2)","719301c4":"melted","d66f4ae8":"daily_total = predictions.groupby('Date').sum().reset_index()\ndaily_total = daily_total[daily_total.Date > train_w2.Date.max()]\ncols = ['Date'] + [c for c in predictions.columns if c.startswith('Confirmed')]\n\nmelted = pd.melt(daily_total[cols], id_vars='Date')\n\nfig2 = px.line(melted[melted.Date <= '2020-04-30'], x='Date', y='value', color='variable')\n_ = fig2.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'W2 Submissions - Confirmed Cases [Updated: {TRAIN_END}]',\n    width = 1600,\n    height = 800,\n)\nfig2.show()","2561a874":"daily_total = predictions.groupby('Date').sum().reset_index()\ndaily_total = daily_total[daily_total.Date > train_w2.Date.max()]\ncols = ['Date'] + [c for c in predictions.columns if c.startswith('Fatalities')]\n\nmelted = pd.melt(daily_total[cols], id_vars='Date')\n\nfig2 = px.line(melted[melted.Date <= '2020-04-30'], x='Date', y='value', color='variable')\n_ = fig2.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'W2 Submissions - Fatalities [Updated: {TRAIN_END}]',\n    width = 1600,\n    height = 800,\n)\nfig2.show()","0d0e5598":"train_w1, test_w1 = get_comp_data('..\/input\/covid19-metadata')\ntrain_w1.shape, test_w1.shape\n\ntop_submissions = dict(\n    RalphNeumann='..\/input\/covid19-metadata\/w1_RalphNeumann_submission.csv',\n    StephenKeller='..\/input\/covid19-metadata\/w1_StephenKeller_submission.csv', \n    beluga='..\/input\/covid19-metadata\/w1_beluga_submission.csv',\n    OsciiArt='..\/input\/covid19-metadata\/w1_OsciiArt_submission.csv'   \n)\ntop_submissions\n\npredictions = train.copy()\npredictions.shape\n\nSUBM_DIR = '.\/data\/subms\/'\nfor team, f in top_submissions.items():\n    s = pd.read_csv(f)\n    s = s.merge(test_w1, on='ForecastId')\n    s = s[['Location', 'Date', 'ConfirmedCases', 'Fatalities']]\n    \n    predictions = predictions.merge(s, on=['Location', 'Date'], suffixes = ['', f' ({team})'], how='outer')\n    s.shape\n    s.tail(2)","e697624c":"daily_total = predictions.groupby('Date').sum().reset_index()\ndaily_total = daily_total[daily_total.Date > train_w1.Date.max()]\ncols = ['Date'] + [c for c in predictions.columns if c.startswith('Confirmed')]\n\nmelted = pd.melt(daily_total[cols], id_vars='Date')\n\nfig2 = px.line(melted[melted.Date <= '2020-04-23'], x='Date', y='value', color='variable')\n_ = fig2.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'W1 Submissions - Confirmed Cases [Updated: {TRAIN_END}]'\n)\nfig2.show()","d0622631":"daily_total = predictions.groupby('Date').sum().reset_index()\ndaily_total = daily_total[daily_total.Date > train_w2.Date.max()]\ncols = ['Date'] + [c for c in predictions.columns if c.startswith('Fatalities')]\n\nmelted = pd.melt(daily_total[cols], id_vars='Date')\n\nfig2 = px.line(melted[melted.Date <= '2020-04-23'], x='Date', y='value', color='variable')\n_ = fig2.update_layout(\n    yaxis_type=\"log\",\n    title_text=f'W1 Submissions - Fatalities [Updated: {TRAIN_END}]'\n)\nfig2.show()","8105e152":"# Week 2","b002c7a3":"# Week 1","ed886f54":"# Week 3"}}