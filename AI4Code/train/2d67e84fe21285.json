{"cell_type":{"626d1181":"code","f242a5a0":"code","5dff2c67":"code","6ee6f293":"code","6f6b9de7":"code","cf83bf41":"code","2566cf93":"code","9fdeb649":"code","c0227e44":"code","091d44a9":"code","0b7bdba3":"code","e30cdf25":"code","dbc1f295":"code","47b8b70a":"code","08ed0dad":"code","80fbf905":"code","e0a5d1ea":"code","36cfc1d4":"code","4e27eaa2":"code","2a244360":"markdown","acced19e":"markdown","e9520639":"markdown","f141f053":"markdown","b2c066e8":"markdown","e4ed95b7":"markdown","35f25b31":"markdown","25fc2067":"markdown","18197335":"markdown","cbc0bc99":"markdown","aa1f3905":"markdown","b0365764":"markdown","048c2791":"markdown","08877aaf":"markdown","7e420b8a":"markdown","aa8f731f":"markdown","3428f311":"markdown","5175623e":"markdown"},"source":{"626d1181":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\n\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai.vision import *\nfrom torchvision.models import *\nfrom glob import iglob\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nfrom IPython.display import Image\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n","f242a5a0":"data_dir='..\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data'\ntrain_dir = \"..\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/train\/*\/*.jpg\"\ndata_path = Path(data_dir)","5dff2c67":"\nfig, ax = plt.subplots(1,5, figsize=(20,4))\nfig.suptitle('car image examples',fontsize=20)\n# choose some images to plot\ncnt = 1\nplt.figure(1)\n\nfor img_path in iglob(train_dir):\n    img = cv2.imread(img_path)\n    plt.subplot(1,5,cnt)\n    plt.imshow(img)\n    #ax[0,cnt].imshow(img)\n    cnt += 1\n    if cnt > 5:\n        break","6ee6f293":"\n# As we count the statistics, we can check if there are any completely black or white images\nx_tot = np.zeros(3)\nx2_tot = np.zeros(3)\ncnt = 0\n\nfor img_path in iglob(train_dir):\n    imagearray = cv2.imread(img_path).reshape(-1,3)\/255.\n    x_tot += imagearray.mean(axis=0)\n    x2_tot += (imagearray**2).mean(axis=0)\n    cnt += 1\n    \nchannel_avr = x_tot\/cnt\nchannel_std = np.sqrt(x2_tot\/cnt - channel_avr**2)\nchannel_avr,channel_std","6f6b9de7":"# Create ImageDataBunch using fastai data block API\nbatch_size = 64\ndata = ImageDataBunch.from_folder(data_path,  \n                                  valid_pct=0.2,\n                                  ds_tfms=get_transforms(do_flip=True,flip_vert=False, max_rotate=30, max_zoom=0.1, max_lighting=0.1),\n                                  size=224,\n                                  bs=batch_size, \n                                  num_workers=0).normalize([tensor([0.454952, 0.460148, 0.470733]), tensor([0.302969, 0.294664, 0.295581])])\n                                  # Normalize with training set stats. These are means and std's of each three channel and we calculated these previously in the stats step.","cf83bf41":"Image('..\/input\/screen-shots\/Screen Shot_model summary.png')","2566cf93":"def getLearner():\n    return cnn_learner(data, resnet34, pretrained=True, path='.', metrics=accuracy, ps=0.5, callback_fns=ShowGraph)\nlearner = getLearner()","9fdeb649":"# some trick to make sure the pretrained weight gets downloaded correctly\n!cp ..\/input\/resnet34\/resnet34.pth \/tmp\/.cache\/torch\/checkpoints\/resnet34-333f7ec4.pth","c0227e44":"def getLearner():\n    return cnn_learner(data, resnet34, pretrained=True, path='.', metrics=accuracy, ps=0.5, callback_fns=ShowGraph)\nlearner = getLearner()","091d44a9":"Image('..\/input\/screen-shots\/Screen Shot_resnet34_fit.png')","0b7bdba3":"# We can use lr_find with different weight decays and record all losses so that we can plot them on the same graph\n# Number of iterations is by default 100, but at this low number of itrations, there might be too much variance\n# from random sampling that makes it difficult to compare WD's. I recommend using an iteration count of at least 300 for more consistent results.\nlrs = []\nlosses = []\nwds = [1e-6, 1e-5, 1e-4]\niter_count = 300\n\nfor wd in wds:\n    learner = getLearner() #reset learner - this gets more consistent starting conditions\n    learner.lr_find(wd=wd, num_it=iter_count)\n    lrs.append(learner.recorder.lrs)\n    losses.append(learner.recorder.losses)","e30cdf25":"_, ax = plt.subplots(1,1)\nmin_y = 4\nmax_y = 7\nfor i in range(len(losses)):\n    ax.plot(lrs[i], losses[i])\n    min_y = min(np.asarray(losses[i]).min(), min_y)\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Learning Rate\")\nax.set_xscale('log')\n#ax ranges may need some tuning with different model architectures \nax.set_xlim((1e-4,3e-1))\nax.set_ylim((min_y - 0.02,max_y))\nax.legend(wds)\nax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))","dbc1f295":"max_lr = 1e-2\nwd = 1e-2\n# 1cycle policy\nlearner_one_cycle = getLearner()\nlearner_one_cycle.fit_one_cycle(cyc_len=10, max_lr=max_lr, wd=wd)","47b8b70a":"learner_one_cycle.recorder.plot_lr()","08ed0dad":"# before we continue, lets save the model at this stage\nlearner_one_cycle.save('resnet34_stage1', return_path=True)","80fbf905":"# unfreeze and run learning rate finder again\nlearner_one_cycle.unfreeze()\nlearner_one_cycle.lr_find(wd=wd)\n\n# plot learning rate finder results\nlearner_one_cycle.recorder.plot()","e0a5d1ea":"# Now, smaller learning rates. This time we define the min and max lr of the cycle\nlearner_one_cycle.fit_one_cycle(cyc_len=10, max_lr=slice(5e-5,5e-4))\n# Save the finetuned model\nlearner_one_cycle.save('resnet34_stage2')","36cfc1d4":"# predict the validation set with our model\ninterp = ClassificationInterpretation.from_learner(learner_one_cycle)\ninterp.most_confused()","4e27eaa2":"interp.plot_top_losses(9, figsize=(20,20))","2a244360":" # **2. Data Preprocessing**","acced19e":"Note: I just noticed there is a method  `data.batch_stats()` can probably do the same thing.","e9520639":"After 10 epochs of training at learning rate 0.003, the accuracy reaches ~62%. We can see that from the plotted losses, both training and validation loss gets flattened out. The model get stuck at saddle point and gradient descent becomes very small.Large learning rate might be able to drive the model out of local minima, so we try to use one-cycle-policy.","f141f053":"We want to select the largest weight decay that gets to a low loss and has the highest learning rate before shooting up. From the grid search of WD within range of 1e-4 ~ 1e-6, we don't see much difference. So I choose to use WD = 1e-5 to proceed. I select the learning rate around 1e-2 where it is close to the bottom but still descending.\n\n## 3.4 Unfreeze all the layers and fine-tune the model\nI train only the heads while keeping the rest of the model frozen. Otherwise, the random initialization of the head weights could harm the relatively well-performing pre-trained weights of the model. After the heads have adjusted and the model somewhat works, we can continue to train the rest of the weights. Fastai already take care of the part that freeze the base weight and unfreeze the head when loading a pretrained model. By default, Fastai cut the base model at the last convolutional layer and add:\n* an AdaptiveConcatPool2d layer,\n* a Flatten layer,\n* blocks of [BatchNorm, Dropout, Linear, ReLU] layers.","b2c066e8":"We can see that the learning rate starts from lower and reaches the `max_lr` in the middle. Then it slows back down near the end. The idea is that we start with a low warm-up learning rate and gradually increase it to high. The higher rate is having a regularizing effect as it won't allow the model to settle for sharp and narrow local minima but pushes for wider and more stable one.\n\nIn the middle of our cycle, we start to lower the learning rate as we are hopefully in a good stable area. This means that we start to look for the minima within that area.","e4ed95b7":"# **1. Introduction**\nThe Car data set contains 8,144 car images and 196 classes of car Make, Year, and Model. This gives ~40 images per class in average, which is a relative few images compared to the number of classifications. So, I choose to start with a pre-trained ResNet34, and avoid too complicated models to ease the overfitting issue. The model is first trained only the head layers, and followed by fine tuning the weights of the base model. The overfitting is the biggest corcerned in this project. Data augmentation and One-cycle-policy are used to reduce overfitting. One cycle policy also help prevent the model get stuck at local minima.\n\nThis Notebook follows three main parts:\n\nThe data preprocessing  \nThe CNN modeling \nThe results analysis  \n\nThe model is built on fastai due to its easiness of implementing learning rate sweep and 1 cycle policy.","35f25b31":"## 3.2 Show a failure example with fixed learning rate training (lr = 0.003)\nI do a fixed learning rate training on the model. Without optimizing learning rate, you can see the model gets stuck in local optima after couple epochs.","25fc2067":"## 2.2 Compute image statistics\nCalculating statistics will give channel averages of [0.454952, 0.460148, 0.470733], and standard deviation of [0.302969, 0.294664, 0.295581]. Ths info will later apply to the standardization of our dataset.","18197335":"## 3.3 Evaluate learning rate and weight decay with One-Cycle-Policy\nOne cycle policy is proposed by Leslie Smith, arXiv, April 2018. The policy cycles the learning rate between lower bound and upper bound during a complete tra. This approach can help get out from the saddle point (local minimum). A cycle is an iteration where we go from lower bound learning rate to higher bound and back to lower bound. when learning rate is higher, the learning rate works as regularisation method and keep network from overfitting. This helps the network to avoid steep areas of loss and land better flatter minima. In addititon, Fastai library has implemented a training function for one cycle policy that can be used with only a few lines of code.\n\nFirst, we find the optimal learning rate and weight decay values. The optimal learning rate is just before the base of the loss and before the start of divergence. It is important that choosing the maximum learning rate at the point where the loss is still descending.\n\nAs for the weight decay that is the regularization L2 penalty of the weight applied at the optimizer, Leslie proposes to select the largest one that will still let us train at a high learning rate. Also, smaller datasets and architectures seem to require larger values for weight decay while larger datasets and deeper architectures seem to require smaller values.  I do a small grid search with 1e-4, 1e-5 and 1e-6 weight decays.","cbc0bc99":"# **ResNet34 fine tune with 1 cycle policy- 87% Acc**\n### Yulin Chen, PhD\n#### 03\/08\/2019\n\n* **1. Introduction**\n* **2. Data Preprocessing**\n    * 2.1 Data visualization\n    * 2.2 Computing image statistics\n    * 2.3 Data standardization and data augmentation\n* **3. Convolutional Neural Network with Fastai**\n    * 3.1 Define the base model with ResNet34\n    * 3.2 Show a failure example of fixed learning rate\n    * 3.3 Evaluate learning rate and weight decay with One-Cycle-Policy\n    * 3.4 Unfreeze the head and train the model\n    * 3.5 Unfreeze all the layers and fine-tune the model\n* **4. Evaluate the model**\n    * 4.1 Confusion list\n    * 4.2 Gradient-weighted Class Activation Mapping","aa1f3905":"The accuracy of the model that is only trained the top layer gets ~75% after 10 epochs, which is much better than using fixed learning rate.","b0365764":"## 2.1 Data visualization\nThe size of the Images in the dataset are not consistent, but fastai will take care of that when feeding images to ImageDataBuntch.","048c2791":"## 4.1 Confusion list\nConfusion matrix can help us understand if there are certain classes that get predicted wrong more easily than others. The number of classifications are too large to plot with confusion matrix. I print out the list instead. `most_confused` method gives us sorted descending list of largest non-diagonal entries of **confusion matrix, presented as actual, predicted, number of occurrences**.   \n  \nThe confusion list indicates that 'Dodge Caliber Wagon' with slightly high frenquency of wrong prediction.","08877aaf":"## 4.2 Gradient-weighted Class Activation Mapping (Grad-CAM)  \nThis method produces a coarse localization map highlighting the areas that the model considers important for the classification decision. The visual explanation gives transparency to the model making it easier to notice if it has learned the wrong things. More details can refer to the [paper](http:\/\/openaccess.thecvf.com\/content_ICCV_2017\/papers\/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf).  \n  \n  The followings are Grad-CAM with 9 highest loss in the validation dataset.","7e420b8a":"# **4. Evaluate the model**\nAfter another 10 epoches of training, the model is able to reach 87% of accuracy at the validation set. At the end of the training epochs,  the validation performance starts seperating from the training performance. This means that the model starts overfitting during the small learning rates. This is a good place to stop.  ","aa8f731f":"## 2.3 Data standardization and augmentation\nThere are couple of ways we can use to avoid overfitting; more data, augmentation, regularization and less complex model architectures. The image augmentations that I use are defined as follow: \n\n* random rotation (< 30 degree)\n* random flip (horizontal)\n* random lighting (< 10%)\n* random zoom (< 10%)\n\nThen I load the images to an ImageDataBunch which standardize the image size to be 224, and the data are ready for training. ","3428f311":"# **3. Convolutional Neural Network with Fastai**\n## 3.1 Define the base model with ResNet34\nIn ML production pipeline, it is a good idea to start with a relatively simple model. With a simple model, we can very quickly see if there are some unexpected problems like bad data quality that will make any further investments into the model tuning not worth it. As shown in figure below (ref). Here I use a pretrained convnet model and transfer learning to adjust the weights to the data. Going for a deeper model architecture will start overfitting faster, especially when we only have ~40 images per classification in average. Here I use a ResNet34 model, which is implemented with double- or triple- layer skips as a residual component, in order to prevent vanishing gradient when network get deep.\n\nI use Fast.ai V1 software library that is built on PyTorch. What I like about Fast.ai is that it includes many recent advancements in deep learning research, for example: Learning rate finder, discriminative learning rates, batchnorm freezing, one-cycle policy, etc.  \n\n[*reference: https:\/\/arxiv.org\/abs\/1605.07678*](https:\/\/arxiv.org\/abs\/1605.07678)","5175623e":"## 3.5 Finetuning the baseline model\nNext, I unfreeze all the trainable parameters from the base model and continue its training.\n\nThe model already performs well, as I unfreeze the bottom layers that have been pre-trained with a large number of general images to detect common shapes and patterns, all weights are mostly adjusted. We should now train with much lower learning rates."}}