{"cell_type":{"83082d1f":"code","c52fb39f":"code","10f8368e":"code","af371275":"code","729def33":"code","aa2935b4":"code","1a2e1404":"code","97ebc545":"code","17465e4a":"code","6ab20a3e":"code","a652f848":"code","b5aad884":"code","89df9e93":"code","eda1c2f9":"code","c56b01a0":"code","a138493b":"code","6da91570":"code","d339a33f":"code","6a9718b5":"code","2d8b9a26":"code","ff540bb9":"code","21cef3c2":"code","f911f7b5":"code","9a0b4e57":"code","0d799aa1":"code","d778d682":"code","195c6b9a":"code","048e6a10":"code","9c5955b1":"code","92ee6a13":"code","605b37b8":"code","d6d0f07d":"code","36e9ffaa":"code","495f189e":"markdown","52eb2991":"markdown","fd6593b1":"markdown","2a5a211c":"markdown","0cc2e2be":"markdown","c7f64349":"markdown","fe115c26":"markdown","d2ee092c":"markdown","6ab9c8d7":"markdown","f05fc4ca":"markdown","3656f70c":"markdown"},"source":{"83082d1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c52fb39f":"from tensorflow import keras\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport matplotlib.image as image\nimport numpy as np","10f8368e":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1,5,figsize = (20, 20))\n    axes = axes.flatten()\n    \n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        \n    plt.tight_layout()\n    plt.show()","af371275":"train_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train'\ntest_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation'\n\ntrain_horses = train_path + \"\/horses\"\ntrain_humans = train_path + \"\/humans\"","729def33":"seed = 42\nimg_size = 128","aa2935b4":"def plot_image(img, i):\n    plt.subplot(1, 4, i + 1)\n    plt.imshow(img)\n    plt.show()\n    \nfor i in range(2):\n    n = i + 5\n    img1 = image.imread(train_horses + \"\/horse01-\" + str(n) + \".png\")\n    img2 = image.imread(train_humans + \"\/human01-0\" + str(n) + \".png\")\n    plot_image(img1, i)\n    plot_image(img2, i)\n\nimg = image.imread(train_horses + \"\/horse01-1.png\")\nnp.array(img).shape","1a2e1404":"train_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range=20, # 40\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=(img_size,img_size),\n    class_mode='binary',\n    shuffle=True,\n    seed=seed\n)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=(img_size, img_size),\n    class_mode='binary',\n    seed=seed\n)","97ebc545":"train_generator.class_indices","17465e4a":"images_to_show = [train_generator[3][0][0] for i in range(5)]\nplotImages(images_to_show)","6ab20a3e":"model_simple = keras.Sequential([\n    #     layers.Flatten(input_shape=(img_size,img_size,3)),\n    keras.Input(shape=(img_size, img_size, 3)),\n    layers.Flatten(),\n    layers.Dense(256, activation=\"relu\"),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\"),\n])\n\n# Construir el modelo y ver la arquitectura\nmodel_simple.build((img_size,img_size))\nmodel_simple.summary()","a652f848":"model_simple.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory = model_simple.fit(\n    train_generator,\n#     steps_per_epoch = 20,\n    epochs = 30, \n    verbose = 1,\n    validation_data = test_generator,\n#     validation_steps = 20\n)","b5aad884":"def plot_metric(history, metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history['val_' + metric])\n    plt.title('Model '+ metric)\n    plt.xlabel(\"epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train \" + metric, 'val '+ metric])\n    plt.show()\n\nplot_metric(history,\"loss\")\nplot_metric(history,\"accuracy\")\n","89df9e93":"model_complex = keras.Sequential([\n    keras.Input(shape=(img_size, img_size, 3)),\n    layers.Flatten(),\n    layers.Dense(2048, activation=\"relu\"),\n    layers.Dense(1024, activation=\"relu\"),\n    layers.Dense(512, activation=\"relu\"),\n    layers.Dense(1, activation=\"sigmoid\"),\n])\n\n\nmodel_complex.build((img_size,img_size))\nmodel_complex.summary()","eda1c2f9":"model_complex.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory_2 = model_complex.fit(\n    train_generator,\n#     steps_per_epoch = 100,\n    epochs = 30, \n    verbose = 1,\n    validation_data=test_generator,\n#     validation_steps=100\n)","c56b01a0":"plot_metric(history_2,\"loss\")\nplot_metric(history_2,\"accuracy\")","a138493b":"model_complex_3 = keras.Sequential([\n    keras.Input(shape=(img_size, img_size, 3)),\n    \n    layers.Flatten(),\n    layers.BatchNormalization(),\n    layers.Dense(2048, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dense(1024, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dense(512, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dense(1, activation=\"sigmoid\"),\n])\n\n\nmodel_complex_3.build((img_size,img_size))\nmodel_complex_3.summary()","6da91570":"model_complex_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory_3 = model_complex_3.fit(\n    train_generator,\n#     steps_per_epoch = 20,\n    epochs = 30, \n    verbose = 1,\n    validation_data = test_generator,\n#     validation_steps = 20\n)","d339a33f":"plot_metric(history_3,\"loss\")\nplot_metric(history_3,\"accuracy\")","6a9718b5":"model_complex_4 = keras.Sequential([\n    keras.Input(shape=(img_size, img_size, 3)),\n    \n    layers.Flatten(),\n    layers.BatchNormalization(),\n    layers.Dense(2048, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n    layers.BatchNormalization(),\n    layers.Dense(1024, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n    layers.BatchNormalization(),\n    layers.Dense(512, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n    layers.BatchNormalization(),\n    layers.Dense(1, activation=\"sigmoid\"),\n])\n\n\nmodel_complex_4.build((img_size,img_size))\nmodel_complex_4.summary()","2d8b9a26":"model_complex_4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory_4 = model_complex_4.fit(\n    train_generator,\n#     steps_per_epoch = 20,\n    epochs = 30, \n    verbose = 1,\n    validation_data = test_generator,\n#     validation_steps = 20\n)","ff540bb9":"plot_metric(history_4,\"loss\")\nplot_metric(history_4,\"accuracy\")","21cef3c2":"model_complex_5 = keras.Sequential([\n    keras.Input(shape=(img_size, img_size, 3)),\n    \n    layers.Flatten(),\n    layers.BatchNormalization(),\n    layers.Dense(2048, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n    layers.Dropout(0.5),\n    layers.BatchNormalization(),\n    layers.Dense(1024, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n    layers.Dropout(0.5),\n    layers.BatchNormalization(),\n    layers.Dense(512, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n    layers.Dropout(0.5),\n    layers.BatchNormalization(),\n    layers.Dense(1, activation=\"sigmoid\"),\n])\n\n\nmodel_complex_5.build((img_size,img_size))\nmodel_complex_5.summary()","f911f7b5":"model_complex_5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory_5 = model_complex_5.fit(\n    train_generator,\n    epochs = 30, \n    verbose = 1,\n    validation_data = test_generator,\n)","9a0b4e57":"plot_metric(history_5,\"loss\")\nplot_metric(history_5,\"accuracy\")","0d799aa1":"optimizer = keras.optimizers.Adam(learning_rate=0.001)\nmodel_complex_5.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nhistory_6 = model_complex_5.fit(\n    train_generator,\n    epochs = 60, \n    verbose = 1,\n    validation_data = test_generator,\n)","d778d682":"plot_metric(history_6,\"loss\")\nplot_metric(history_6,\"accuracy\")","195c6b9a":"model_complex_7 = keras.Sequential(\n    [\n        keras.Input(shape=(img_size, img_size, 3)),\n        # =============================\n        # ...CAPAS CONVOLUCIONALES...\n        # =============================\n        layers.Flatten(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n        layers.Dropout(0.5),\n        layers.Dense(512, activation=\"relu\", kernel_regularizer = keras.regularizers.l2(0.03)),\n        layers.Dropout(0.5),\n        layers.BatchNormalization(),\n        layers.Dense(1, activation=\"sigmoid\")\n    ]\n)\n\nmodel_complex_7.build((img_size, img_size))\nmodel_complex_7.summary()\n\noptimizer_7 = keras.optimizers.Adam(learning_rate=0.001)\nmodel_complex_7.compile(loss = 'binary_crossentropy', optimizer=optimizer_7, metrics=['accuracy'])","048e6a10":"history_7 = model_complex_7.fit(\n    train_generator,\n    steps_per_epoch=20,  \n    epochs=30,\n    shuffle=True,\n    verbose=1,\n    validation_data=test_generator,\n    validation_steps=20\n)","9c5955b1":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1.1])\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 10])\nplt.show()","92ee6a13":"import PIL\nimport requests\nfrom io import BytesIO\n\n# https:\/\/stackoverflow.com\/a\/23489503\ndef get_image(url):\n    response = requests.get(url)\n    im = PIL.Image.open(BytesIO(response.content))\n    im = im.resize((img_size,img_size), PIL.Image.ANTIALIAS)\n    display(im)\n    im = np.asarray(im)\/255\n    im = im.reshape(1,-1)\n    \n    return im\n\nhuman = get_image('https:\/\/www.kindpng.com\/picc\/m\/154-1542577_full-body-guy-in-suit-png-transparent-png.png')\n\nhorse = get_image('https:\/\/www.winnerscircle-equine.com\/storage\/app\/media\/3j.jpg')","605b37b8":"print('human shape ', human.shape)\nprint('horse shape ', horse.shape)","d6d0f07d":"horse_r = model_complex_7.predict(horse)\n\nhorse_r[0][0]*100","36e9ffaa":"human_r = model_complex_7.predict(human)\n\nhuman_r[0][0]*100","495f189e":"### 5- Arquitectura con BatchNormalization, kernel_regularizer & dropout","52eb2991":"### Crear los generadores de imagenes","fd6593b1":"## Test con data real","2a5a211c":"### 7- Arquitectura con BatchNormalization, kernel_regularizer, dropout y custom optimizer","0cc2e2be":"## Ver un par de imagenes","c7f64349":"## Arquitectura un poquito m\u00e1s compleja","fe115c26":"## 3- Arquitectura con BatchNormalization","d2ee092c":"## Horses vs Humans\n\nVan a crear un notebook de kaggle para probar su clasificador neuronal binario a partir del dataset (https:\/\/www.kaggle.com\/sanikamal\/horses-or-humans-dataset) \n\nIndicaciones:\n\n- Considere una arquitectura neuronal simple primero.\n- Deben utilizar Image Augmentation (ImageDataGenerator de Keras).\n- Considere utilizar BatchNormalization y Dropout\n- Los optimizadores de moda son SGD, Adam, Adamax, RMSprop\n- Considere modificar el learning rate comno hyperparametro del optimizador\n- Debe probar el clasificadfor con imagenes de personas reales y caballos reales.\n- https:\/\/www.kindpng.com\/picc\/m\/154-1542577_full-body-guy-in-suit-png-transparent-png.png\n- https:\/\/www.winnerscircle-equine.com\/storage\/app\/media\/3j.jpg\n\nDebe entregar en un txt la ruta de su cuaderno de Kaggle. Recuerde probar primero que su ruta es accesible en otro browser.\n\nSu clasificador es binario, considere utilizar softmax o sigmoid para comparar su utilidad.\n","6ab9c8d7":"### 6- Arquitectura con BatchNormalization, kernel_regularizer, dropout y custom optimizer","f05fc4ca":"## Arquitectura Simple","3656f70c":"### 4- Arquitectura con BatchNormalization y kernel_regularizer"}}