{"cell_type":{"5ade778f":"code","a09d275f":"code","e4895d96":"code","3b250ca0":"code","b1e4e0f5":"code","cc2aad32":"code","5070aa40":"code","8b6d632b":"code","5a6aa727":"code","566e537a":"code","e0380efe":"code","26a83464":"code","6d78c930":"code","9a57b438":"code","bd78ceb7":"code","f66324a9":"code","ce4a0148":"code","5fb0326f":"code","151350db":"code","39bb8eb5":"markdown","4b113ff8":"markdown"},"source":{"5ade778f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a09d275f":"train_data = pd.read_csv('\/kaggle\/input\/2020-10-29\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/2020-10-29\/test.csv')","e4895d96":"import matplotlib.pyplot as plt\nimport seaborn as sns","3b250ca0":"corr = train_data.corr()\nplt.figure(figsize=(14, 10))\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\nplt.show()","b1e4e0f5":"plt.figure(figsize=(10, 8))\nplt.subplot(2,2,1)\nplt.title('col1-col2')\nplt.plot(train_data['col_1'], train_data['col_2'])\n\nplt.subplot(2,2,2)\nplt.title('col6-col7')\nplt.plot(train_data['col_6'], train_data['col_7'])\nplt.show()","cc2aad32":"sorted(train_data['col_5'].unique())","5070aa40":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nlabel = le.fit_transform(train_data['col_5'])\nlabel","8b6d632b":"for column in train_data.columns:\n    plt.title(column+'-col_5')\n    sns.boxplot(x=label, y=column, data=train_data)\n    plt.show()","5a6aa727":"for column in train_data.columns:\n    plt.title(column+'-col_5')\n    sns.violinplot(x=label, y=column, data=train_data)\n    plt.show()","566e537a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","e0380efe":"train = train_data.drop(['id', 'col_5'], axis=1)\nlabel = le.fit_transform(train_data['col_5'])\nlabel","26a83464":"X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2, random_state=42)","6d78c930":"rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n\nrf.fit(X_train, y_train)\n\nX_test_pred = rf.predict(X_test)\nX_test_pred","9a57b438":"inverse_X_test_pred = le.inverse_transform(X_test_pred)\ninverse_y_test = le.inverse_transform(y_test)\n\ninverse_X_test_pred","bd78ceb7":"from sklearn.metrics import mean_absolute_error\n\nmean_absolute_error(inverse_X_test_pred, inverse_y_test)","f66324a9":"test = test_data.drop(['id'], axis=1)\npred = rf.predict(test)\ninverse_pred = le.inverse_transform(pred)\ninverse_pred","ce4a0148":"id_df = pd.DataFrame(test_data['id']).rename(columns={0:'id'})\npred_df = pd.DataFrame(inverse_pred).rename(columns={0:'col_5'})","5fb0326f":"result = pd.concat([id_df, pred_df], axis=1)\nresult","151350db":"result.to_csv('submission.csv', header=True, index=False)","39bb8eb5":"If you've found any features, apply them on your works right now!","4b113ff8":"co1-col2, col6-col7 have very high correlation. Let's plot."}}