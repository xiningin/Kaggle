{"cell_type":{"74f9fc1a":"code","2990e7f1":"code","88780f5e":"code","b2e9987f":"code","e0a54c56":"code","ae739608":"code","ff1e9728":"code","bfcce68a":"code","049e82a3":"code","be692169":"code","23a9a255":"code","9a4e46e1":"code","c8ab31d0":"code","12b1ffb2":"markdown"},"source":{"74f9fc1a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2990e7f1":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport joblib","88780f5e":"SEED = 1111\n\n#tf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\nimport datatable\n\ndatatable_frame = datatable.fread('..\/input\/jane-street-market-prediction\/train.csv')\n#df_raw = pd.read_csv('..\/input\/jane-street-market-prediction\/train.csv')\ndf_raw = datatable_frame.to_pandas()\n\ndf_raw = df_raw.query('date > 85').reset_index(drop = True) \ndf_raw = df_raw[df_raw['weight'] != 0]\n\n\ndf_raw['action'] = ((df_raw['resp'].values) > 0).astype(int)","b2e9987f":"LOCAL_TRAIN_TEST_SPLIT = False\nLOCAL_TEST = False","e0a54c56":"if LOCAL_TRAIN_TEST_SPLIT:\n    df_train, df_test = train_test_split(df_raw, test_size=0.2, shuffle=True, random_state=150)\nelse:\n    df_train = df_raw","ae739608":"features = [c for c in df_train.columns if \"feature\" in c]\n\nf_median = df_train[features].median(axis=0)\n\nneutral_values = f_median\n\ndf_train.fillna(neutral_values,inplace=True)","ff1e9728":"f_median.to_csv('median_pd_130_features.csv')","bfcce68a":"resp_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']\n\nX_train = df_train.loc[:, df_train.columns.str.contains('feature')]\n\ny_train = np.stack([(df_train[c] > 0).astype('int') for c in resp_cols]).T\n\ny_action_train = df_train['action'].to_numpy()","049e82a3":"if LOCAL_TRAIN_TEST_SPLIT:\n    df_test.fillna(neutral_values,inplace=True)\n\n    X_test = df_test.loc[:, df_test.columns.str.contains('feature')]\n\n    y_test = np.stack([(df_test[c] > 0).astype('int') for c in resp_cols]).T\n\n    y_action_test = df_test['action'].to_numpy()","be692169":"xgb_clfs = []\nfor i in range(len(resp_cols)):\n    print('classifier', i, 'is training')\n    xgb_clf = (xgb.XGBClassifier(n_estimators=500, \n                                 max_depth=8, \n                                 subsample=0.9,\n                                 learning_rate=0.05,\n                                 objective='binary:logistic', \n                                 tree_method='gpu_hist'))\n    xgb_clf.fit(X_train, y_train[:,i])\n    xgb_clfs.append(xgb_clf)","23a9a255":"for i in range(len(resp_cols)):\n    joblib.dump(xgb_clfs[i], \"xgb\" + str(i) + \"-n-500-d-8-sub-0.9-lr-0.05.joblib\")","9a4e46e1":"if LOCAL_TEST:\n    five_preds = []\n\n    for i in range(len(resp_cols)):\n        pred_prob = xgb_clfs[i].predict_proba(X_test)[:,1]    # arr[0] is the probability for class 0, arr[1] is the probability for class 1\n        five_preds.append(pred_prob)\n    five_preds = np.array(five_preds).T\n\n\n    th = 0.5\n\n    f_get_action = np.median\n    preds = f_get_action(five_preds, axis=1)\n    actions_predicted = np.where(preds >= th, 1, 0).astype(int)\n\n    print(preds.shape)\n    print(actions_predicted.shape)\n\n    print(metrics.accuracy_score(y_action_test, actions_predicted))","c8ab31d0":"if not LOCAL_TEST:\n    f_get_action= np.median\n\n    th=0.5\n\n    models = xgb_clfs\n    import janestreet\n    from tqdm import tqdm\n    env = janestreet.make_env()\n    for (test_df, pred_df) in tqdm(env.iter_test()):\n        if test_df['weight'].item() > 0:\n            x_tt = test_df.loc[:, features].values\n            if np.isnan(x_tt.sum()):\n                #x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n                x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * neutral_values.values\n            five_preds = []\n\n            for i in range(len(resp_cols)):\n                pred_prob = xgb_clfs[i].predict_proba(x_tt)[:,1]    # arr[0] is the probability for class 0, arr[1] is the probability for class 1\n                five_preds.append(pred_prob)\n            five_preds = np.array(five_preds).T\n\n            f_get_action = np.median\n            preds = f_get_action(five_preds, axis=1)\n            actions_predicted = np.where(preds >= th, 1, 0).astype(int)\n            pred_df.action = actions_predicted\n        else:\n            pred_df.action = 0\n        env.predict(pred_df)","12b1ffb2":"## XGBoost"}}