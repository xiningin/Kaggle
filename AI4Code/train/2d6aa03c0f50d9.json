{"cell_type":{"ddfae49e":"code","959ac13b":"code","3de4926f":"code","9d363a3c":"code","f5ccd611":"code","39045ab2":"code","4682976e":"code","0f595e89":"code","e822141c":"code","2159ee3a":"code","c9ea1f44":"code","cc497c5b":"code","e9d70f86":"code","914e70d4":"code","8b891168":"code","08320dc5":"code","77284203":"markdown","a46988e4":"markdown","2f606c16":"markdown","16a7cdfb":"markdown","825e5b93":"markdown","1bbe0207":"markdown"},"source":{"ddfae49e":"DEGUB = False","959ac13b":"import os\nfrom logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer\n\n%matplotlib inline\ntqdm.pandas()","3de4926f":"def get_logger(\n    filename=\"log\",\n    disable_stream_handler=False,\n    disable_file_handler=False\n):\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n\n    if not disable_stream_handler:\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n\n    if not disable_file_handler:\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler2)\n\n    return logger","9d363a3c":"logger = get_logger(\"log\")\n\nINPUT_DIR = \"..\/input\/ailab-ml-training-2\/\"\n\ntrain_df = pd.read_csv(os.path.join(INPUT_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(INPUT_DIR, \"test.csv\"))\n\npretrained_weights = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(pretrained_weights)\nbackbone = BertModel.from_pretrained(pretrained_weights)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","f5ccd611":"train_df.head()","39045ab2":"train_df = train_df.fillna({\"item_description\": \"No description.\"})\ntest_df = test_df.fillna({\"item_description\": \"No description.\"})","4682976e":"train_df[\"item_description_length\"] = train_df[\"item_description\"].progress_apply(lambda x: len(x.split()))\ntest_df[\"item_description_length\"] = test_df[\"item_description\"].progress_apply(lambda x: len(x.split()))\nprint(max(train_df[\"item_description_length\"].max(), test_df[\"item_description_length\"].max()))\nsns.distplot(train_df[\"item_description_length\"], kde=False, label=\"train\")\nsns.distplot(test_df[\"item_description_length\"], kde=False, label=\"test\")\nplt.legend()\nplt.show()","0f595e89":"train_df[\"price_log1p\"] = np.log1p(train_df[\"price\"])","e822141c":"class MercariDataset(Dataset):\n    def __init__(self, names, descriptions, prices, tokenizer, maxlen=512):\n        super().__init__()\n        self.names = names\n        self.descriptions = descriptions\n        self.prices = prices\n        self.tokenizer = tokenizer\n        self.maxlen = maxlen\n    \n    def __len__(self):\n        return len(self.names)\n    \n    def __getitem__(self, idx):\n        name = self.names[idx]\n        description = self.descriptions[idx]\n        \n        tokens = tokenizer.encode(name, description, max_length=self.maxlen, pad_to_max_length=True)\n        tokens = torch.tensor(tokens)\n        attn_mask = (tokens != 0).long()\n        price = torch.tensor(self.prices[idx])\n        \n        return tokens, attn_mask, price","2159ee3a":"class MercariBert(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n        self.reg_fc = nn.Linear(768, 1, bias=True)\n    \n    def forward(self, x, mask):\n        x, _ = self.backbone(x, attention_mask=mask)\n        x = x[:, 0]\n        x = self.reg_fc(x)\n        return x","c9ea1f44":"dev_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True)\ndev_df = dev_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\nlogger.info(f\"dev: {len(dev_df)}, val: {len(val_df)}\")","cc497c5b":"dev_datasets = MercariDataset(dev_df[\"name\"], dev_df[\"item_description\"], dev_df[\"price_log1p\"],\n                              tokenizer=tokenizer, maxlen=128)\nval_datasets = MercariDataset(val_df[\"name\"], val_df[\"item_description\"], val_df[\"price_log1p\"],\n                              tokenizer=tokenizer, maxlen=128)\n\ndev_dataloader = DataLoader(dev_datasets, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_datasets, batch_size=32, shuffle=False)","e9d70f86":"model = MercariBert(backbone).to(DEVICE)\noptimizer = Adam(model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()","914e70d4":"for epoch in tqdm(range(1)):\n    dev_losses = []\n    model.train()\n    for i, (x, mask, y) in enumerate(tqdm(dev_dataloader, leave=False)):\n        optimizer.zero_grad()\n        \n        x = x.to(dtype=torch.long, device=DEVICE)\n        mask = mask.to(dtype=torch.long, device=DEVICE)\n        y = y.to(dtype=torch.float32, device=DEVICE)\n        \n        y_pred = model(x, mask).view(-1)\n        loss = criterion(y_pred, y)\n        loss.backward()\n        optimizer.step()\n        \n        dev_losses.append(loss.item())\n        \n        if (i + 1) % 200 == 0:\n            logger.info(\"iter: {}\/{}, moving loss - {:.5f}\".format(\n                i + 1, len(dev_dataloader), np.mean(dev_losses[-200:])\n            ))\n        \n        if DEGUB and (i + 1) >= 400:\n            break\n    \n    val_losses = []\n    model.eval()\n    for i, (x, mask, y) in enumerate(val_dataloader):\n        x = x.to(dtype=torch.long, device=DEVICE)\n        mask = mask.to(dtype=torch.long, device=DEVICE)\n        y = y.to(dtype=torch.float32, device=DEVICE)\n        \n        with torch.no_grad():\n            y_pred = model(x, mask).view(-1)\n            loss = criterion(y_pred, y)\n        \n        val_losses.append(loss.item())\n        \n        if DEGUB and (i + 1) >= 400:\n            break\n    \n    logger.info(\"epoch: {}, loss - {:.5f}, val_loss - {:.5f}\".format(\n        epoch + 1, np.mean(dev_losses), np.mean(val_losses)\n    ))","8b891168":"test_datasets = MercariDataset(test_df[\"name\"], test_df[\"item_description\"], test_df[\"shipping\"],\n                               tokenizer=tokenizer, maxlen=128)\ntest_dataloader = DataLoader(test_datasets, batch_size=32, shuffle=False)\n\ntest_preds = []\nmodel.eval()\nfor i, (x, mask, _) in enumerate(tqdm(test_dataloader)):\n    x = x.to(dtype=torch.long, device=DEVICE)\n    mask = mask.to(dtype=torch.long, device=DEVICE)\n    with torch.no_grad():\n        y_pred = model(x, mask).view(-1)\n    test_preds.append(y_pred.cpu().numpy())\n    if DEGUB and (i + 1) >= 400:\n        break\ntest_preds = np.concatenate(test_preds, axis=0)\n\ntest_preds = np.where(test_preds < 0.0, 0.0, test_preds)\ntest_preds = np.exp(test_preds) - 1","08320dc5":"sub_df = pd.DataFrame()\nsub_df[\"test_id\"] = test_df[\"test_id\"]\nsub_df[\"price\"] = test_preds\nsub_df.to_csv(\"submission.csv\", index=False)","77284203":"## Inference","a46988e4":"## Training","2f606c16":"## Dataset\/Module","16a7cdfb":"## Preprocessing","825e5b93":"## Libraries","1bbe0207":"## Loading"}}