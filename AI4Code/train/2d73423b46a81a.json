{"cell_type":{"11ec0c52":"code","b5623240":"code","48859a03":"code","11ab428b":"code","e261fae9":"code","f632c9c0":"code","6a3b4584":"code","c2cc4372":"code","b33d7365":"code","1dfffafc":"markdown","53b411b2":"markdown","f9c5632c":"markdown"},"source":{"11ec0c52":"!pip install efficientnet","b5623240":"# ==================\n# Library\n# ==================\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nimport tensorflow as tf, re, math\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\nfrom efficientnet.tfkeras import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nfrom tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\nimport glob","48859a03":"# ==================\n# Constant\n# ==================\nTRAIN_PATH = '..\/input\/used-car-price-forecasting\/train.csv'\nTEST_PATH = '..\/input\/used-car-price-forecasting\/test.csv'\nTRAIN_IMG_PATH = \"..\/input\/used-car-price-forecasting\/images\/train_images\/\"\nSAVE_PATH = \"train_eff0.npy\"","11ab428b":"# ===============\n# Settings\n# ===============\nimg_size = 224\nbatch_size = 16","e261fae9":"# ====================\n# Function\n# ====================\n\n\ndef build_model(dim=256):\n    inp = tf.keras.layers.Input(shape=(dim,dim,3))\n    base = efn.EfficientNetB0(input_shape=(dim,dim,3),weights='imagenet',include_top=False) #\u4eca\u56de\u306feEfficientNet B0\u3092\u4f7f\u3044\u307e\u3059\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    model = tf.keras.Model(inputs=inp,outputs=x)\n    return model\n\n\ndef load_images(img_path):\n    img = load_img(img_path,target_size=(img_size,img_size))\n    img = img_to_array(img)\n    img = preprocess_input(img)\n    return img","f632c9c0":"# ======================\n# Main\n# ======================\ntrain_df = pd.read_csv(TRAIN_PATH)\nm = build_model(dim=img_size)\ncar_ids = train_df['id'].values\nn_batches = len(car_ids) \/\/ batch_size + 1","6a3b4584":"m.summary()","c2cc4372":"features = np.zeros((len(train_df), 1280)) #model\u306e\u5927\u304d\u3055\u306b\u5fdc\u3058\u3066\u3001features\u306e\u5217\u6570\u3092\u5909\u3048\u3066\u304f\u3060\u3055\u3044\nn = 0\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_cars = car_ids[start:end]\n    batch_images = np.zeros((len(batch_cars),img_size,img_size,3))\n    for i,car_id in enumerate(batch_cars):\n        try:\n            batch_images[i] = load_images(f\"{TRAIN_IMG_PATH}{car_id}.jpg\")\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,car_id in enumerate(batch_cars):\n        features[n,:] = batch_preds[i]\n        n += 1","b33d7365":"np.save(\"train_ef0.npy\",features)","1dfffafc":"# \u753b\u50cf\u304b\u3089\u62bd\u51fa\u3057\u305f\u7279\u5fb4\u91cf\u306f\u3001\u305d\u306e\u307e\u307e\u3001\u3082\u3057\u304f\u6b21\u5143\u524a\u6e1b\u3057\u3066LightGBM\u306a\u3069\u306e\u7279\u5fb4\u91cf\u306b\u3057\u3066\u304f\u3060\u3055\u3044!","53b411b2":"\u203b\u4eca\u56de\u306ftrain data\u3060\u3051\u3092\u5bfe\u8c61\u306b\u3057\u3066\u3044\u307e\u3059\u3002test data\u306f\u540c\u69d8\u306e\u65b9\u6cd5\u3067\u5bfe\u5fdc\u304f\u3060\u3055\u3044\u3002","f9c5632c":"\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u3066\u3001\u753b\u50cf\u304b\u3089\u7279\u5fb4\u91cf\u3092\u62bd\u51fa\u3059\u308b\u65b9\u6cd5\u3067\u3059\u3002  \u4e0b\u8a18notebook\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002  \nhttps:\/\/www.kaggle.com\/christofhenkel\/extract-image-features-from-pretrained-nn\n\nSettings\u3067\u4e0b\u8a18\u8a2d\u5b9a\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\n- Accelerator\u3092GPU\n- Internet\u3092ON"}}