{"cell_type":{"13d748a3":"code","c690ef96":"code","a7793a13":"code","ce9066c8":"code","810c83bf":"code","73ab8d93":"code","327dbdb9":"code","b9c3c98f":"code","574281d3":"code","ec15f0d8":"code","08c31c4e":"code","e19b53ec":"code","9a3d6943":"code","9db6da89":"code","54394a11":"code","38d4d16b":"code","bdfafad5":"code","1fc76efc":"code","1eea5457":"code","ffc2c1db":"code","3a1393ff":"code","6ebc4dd2":"code","0635db0e":"code","7aa7ae43":"code","83a5be14":"code","89445f94":"code","5eaacc76":"code","374e8e32":"code","66db00d4":"code","56351ece":"code","0276fd9f":"code","fb00cc7b":"code","c2785020":"code","9621f87e":"code","c9006726":"code","f6976a17":"code","fc5b8f95":"code","1398542b":"code","2f1bd229":"code","04a0d428":"markdown","3cbd4ef8":"markdown","98bcd82e":"markdown","ef66f788":"markdown","8531d126":"markdown","8754b99e":"markdown","7b99faaa":"markdown","63ca2143":"markdown","f0a61119":"markdown","c1e026e6":"markdown","365f7673":"markdown","ecb805f7":"markdown","7cd81199":"markdown","e07c3e5a":"markdown","0ddfc73f":"markdown","58a541b5":"markdown","baddcecf":"markdown","9e018667":"markdown","66f3b81a":"markdown","bc71a1cd":"markdown","32b5e8db":"markdown","89c69d41":"markdown","5a46ccb0":"markdown","df9cf55c":"markdown","91953a2d":"markdown"},"source":{"13d748a3":"# Data Manipulation and Linear Algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nimport matplotlib.pyplot as plt\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore')","c690ef96":"data = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","a7793a13":"data.info()","ce9066c8":"data.head()","810c83bf":"fig, axes = plt.subplots(figsize=(20, 8), nrows=1, ncols=2)\n\nsns.countplot(x=\"Outcome\", data=data, palette=['#5bde54',\"#de5454\"], ax=axes[0])\naxes[0].set_title(\"Count of Outcome variable\")\naxes[0].set_ylabel(\"Count\")\naxes[0].set_xticklabels([\"Healty\", \"Diabetic\"])\n\nplt.pie(data.Outcome.value_counts(), autopct='%.1f%%', labels=[\"Healty\", \"Diabetic\"], colors=['#5bde54',\"#de5454\"])\naxes[1].set_title(\"Count of Outcome variable\")\n\nplt.show()","73ab8d93":"data.describe()","327dbdb9":"# Replacing 0 by nan to calculate the null values\ndata[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = data[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","b9c3c98f":"# Missing Values\ndata.isnull().sum()","574281d3":"plt.rcParams[\"figure.figsize\"] = (10, 8)\nplt.rcParams[\"figure.dpi\"] = 80\nsns.heatmap(data.corr(), annot=True, cmap=\"viridis\")\nplt.show()","ec15f0d8":"def distributon_plot(x):\n    fig, axes = plt.subplots(figsize=(20, 8), nrows=1, ncols=2)\n\n    sns.histplot(x=x, hue=\"Outcome\", data=data, palette=['#5bde54',\"#de5454\"], ax=axes[0])\n    axes[0].set_title(f\"{x} Distribution Histplot\")\n    axes[0].legend([\"Diabetic\", \"Healthy\"])\n    axes[0].set_ylabel(\"Density \/ Count\")\n\n    sns.kdeplot(x=x, hue=\"Outcome\", data=data, palette=['#5bde54',\"#de5454\"], ax=axes[1])\n    axes[1].set_title(f\"{x} Distribution Kdeplot\")\n    axes[1].legend([\"Diabetic\", \"Healthy\"])\n    axes[1].set_ylabel(\"Density \/ Count\")\n\n    plt.show()","08c31c4e":"# Gets two Median Valuse for Both Outcomes Seprately\ndef median_target(var):   \n    temp = data[data[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp","e19b53ec":"distributon_plot(\"Insulin\")","9a3d6943":"median_target('Insulin')","9db6da89":"data.loc[(data['Outcome'] == 0 ) & (data['Insulin'].isnull()), 'Insulin'] = 102.5\ndata.loc[(data['Outcome'] == 1 ) & (data['Insulin'].isnull()), 'Insulin'] = 169.5","54394a11":"distributon_plot(\"Glucose\")","38d4d16b":"median_target('Glucose')","bdfafad5":"data.loc[(data['Outcome'] == 0 ) & (data['Glucose'].isnull()), 'Glucose'] = 107\ndata.loc[(data['Outcome'] == 1 ) & (data['Glucose'].isnull()), 'Glucose'] = 140","1fc76efc":"distributon_plot(\"SkinThickness\")","1eea5457":"median_target(\"SkinThickness\")","ffc2c1db":"data.loc[(data['Outcome'] == 0 ) & (data['SkinThickness'].isnull()), 'SkinThickness'] = 27\ndata.loc[(data['Outcome'] == 1 ) & (data['SkinThickness'].isnull()), 'SkinThickness'] = 32","3a1393ff":"distributon_plot(\"BloodPressure\")","6ebc4dd2":"median_target('BloodPressure')","0635db0e":"data.loc[(data['Outcome'] == 0 ) & (data['BloodPressure'].isnull()), 'BloodPressure'] = 70\ndata.loc[(data['Outcome'] == 1 ) & (data['BloodPressure'].isnull()), 'BloodPressure'] = 74.5","7aa7ae43":"distributon_plot(\"BMI\")","83a5be14":"median_target('BMI')","89445f94":"data.loc[(data['Outcome'] == 0 ) & (data['BMI'].isnull()), 'BMI'] = 30.1\ndata.loc[(data['Outcome'] == 1 ) & (data['BMI'].isnull()), 'BMI'] = 34.3","5eaacc76":"distributon_plot(\"Age\")\ndistributon_plot(\"Pregnancies\")\ndistributon_plot(\"DiabetesPedigreeFunction\")","374e8e32":"sns.pairplot(data, hue=\"Outcome\")\nplt.show()","66db00d4":"data.isnull().sum()","56351ece":"data.head()","0276fd9f":"X = data.drop(\"Outcome\", axis=1).values\ny = data.Outcome","fb00cc7b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","c2785020":"sc = StandardScaler()\n\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","9621f87e":"MLA_compare = pd.DataFrame()\n\ndef MLA_testing(MLA, X_train, X_test):\n    row_index = 0\n    for classifier in MLA:\n        classifier.fit(X_train, y_train)\n\n        y_pred = classifier.predict(X_test)\n        classifier_accuracy_score = accuracy_score(y_test, y_pred)\n\n        kfold_accuracy = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n\n        MLA_name = classifier.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'Accuracy Score'] = classifier_accuracy_score*100\n        MLA_compare.loc[row_index, 'K-Fold Accuracy'] = kfold_accuracy.mean()*100\n\n        print(MLA_name, \"Done\")\n        row_index+=1","c9006726":"MLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False),\n    CatBoostClassifier()  \n    ]\n\nMLA_testing(MLA=MLA, X_train=X_train, X_test=X_test)","f6976a17":"# Scaled Data Used Here\nMLA = [    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    \n    #SVM\n    svm.LinearSVC(max_iter=10000), \n]\nMLA_testing(MLA=MLA, X_test=X_test_scaled, X_train=X_train_scaled)","fc5b8f95":"MLA_compare = MLA_compare.sort_values(by=\"Accuracy Score\", ascending=False).reset_index(drop=True)[:10]\nMLA_compare","1398542b":"classifier = CatBoostClassifier()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\ncm = confusion_matrix(y_test, y_pred)","2f1bd229":"print(\"Test Accuracy : \", accuracy, \"\\n\")\n\nprint(\"Confusion Matrix \\n\", cm, \"\\n\")\n\nplt.rcParams[\"figure.figsize\"] = (6, 5)\nplt.rcParams[\"figure.dpi\"] = (100)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='2.0f')\nplt.show()","04a0d428":"# Comparing Models","3cbd4ef8":"#### Insulin's medians by the target are really different ! 102.5 for a healthy person and 169.5 for a diabetic person","98bcd82e":"## Glucose","ef66f788":"## Missing Values","8531d126":"## Splitting the dataset into the Training set and Test set","8754b99e":"## Blood Pressure","7b99faaa":"## All Features Pair Plot","63ca2143":"#### As you can see the minimum value for Glucose, BloodPressure, skinThickness, Insulin and BMI is 0 which is practically not possible which suggests us that it is a faulty value.","f0a61119":"# Data Overview","c1e026e6":"## Loading Data","365f7673":"# Import Necessary Libraries","ecb805f7":"# Machine Learning - Multiple Model Testing","7cd81199":"## BMI","e07c3e5a":"# Using CatBoostClassifier","0ddfc73f":"## Feature Scaling - Scaling Data for Some Models","58a541b5":"## Top 10 Best Performing Models","baddcecf":"### Final Check for Null Values in Data","9e018667":"#### CatBoostClassifier Performed the Best with 90.26% Accuracy and 88.6% CrossVal-Accuracy","66f3b81a":"#### To fill these Nan values the data distribution needs to be understood against the target.","bc71a1cd":"## Insulin","32b5e8db":"## Skin Thickness","89c69d41":"# Replace Missing Values and EDA","5a46ccb0":"# Credits\n#### https:\/\/www.kaggle.com\/vincentlugat\/pima-indians-diabetes-eda-prediction-0-906","df9cf55c":"## Dataframe to store all the accuracy scores for Comparison and Analysis","91953a2d":"# Prepare Dataset"}}