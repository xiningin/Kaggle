{"cell_type":{"3d26ac99":"code","609ebba1":"code","57968856":"code","a662b512":"code","ef4c39bf":"code","36e18258":"code","44b9491b":"code","ce5f44b6":"code","e9fd2f3b":"code","3fe803d9":"code","1d2fd37f":"code","4f686323":"code","29514e72":"code","fb0a1561":"code","7920927d":"code","268d1799":"code","09e97f05":"code","2ba0e4d0":"code","cab8c8e4":"code","c2d114a5":"code","6023af70":"code","c6a06d34":"code","18a57957":"code","9544a973":"code","eb9d399d":"code","b5d90f26":"code","d8d76a7c":"code","9103b764":"code","6d3b0b73":"code","a4fdc263":"code","8b807b1d":"code","2c6181f5":"code","62302605":"code","1f681cd4":"code","9bcd5d45":"code","f9d22182":"code","7fd73450":"code","9bdc10de":"code","d4f9e09d":"code","dd565e64":"code","72193952":"code","935f47e6":"code","5389ec18":"code","6c9cd9ed":"code","5d26a9c8":"code","e532d3ff":"code","9755f234":"code","3731ca6d":"code","ce7e38f9":"code","3649027e":"code","b42efd7f":"markdown","3df27f3e":"markdown","c0efd018":"markdown","eeae60d1":"markdown","c9539d22":"markdown","97c0d3ca":"markdown","b31cb41b":"markdown"},"source":{"3d26ac99":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","609ebba1":"import pandas as pd\n### Let's import our data\n\ntitanic =pd.read_csv('..\/input\/titanic\/train.csv')\ntest= pd.read_csv('..\/input\/titanic\/test.csv')\n\n","57968856":"titanic= pd.DataFrame(titanic)\nprint(titanic)\n\n# convert into dataframe using pandas","a662b512":"titanic.head()","ef4c39bf":"titanic.Age.describe()\n","36e18258":"titanic.shape","44b9491b":"titanic.info()","ce5f44b6":"titanic.columns.values","e9fd2f3b":"list(titanic)","3fe803d9":"titanic.dtypes","1d2fd37f":"# concate test and train dataset\n\ntitanic = titanic.append(test , ignore_index = True)\ntitanic.head()","4f686323":"#check for any other unusable values\n\ntitanic.isnull().sum()","29514e72":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n#initialize label endoce as first step.\nle = LabelEncoder()\n\ntitanic['Sex'] = le.fit_transform(titanic['Sex'].values)\n\n# or you can use pd.dummies","fb0a1561":"titanic = titanic.drop('Name', axis=1,)\ntitanic = titanic.drop('Ticket', axis=1,)\ntitanic = titanic.drop('Fare', axis=1,)\ntitanic= titanic.drop('Cabin', axis=1,)\ntitanic= titanic.drop('Embarked', axis=1,)\n#dropping columns which is not important","7920927d":"titanic.info()\n\ntitanic.head()","268d1799":"titanic=titanic[~titanic['Age'].isna()]\n# dropping null values","09e97f05":"titanic=titanic[~titanic['Survived'].isna()]","2ba0e4d0":"titanic.info()\ntitanic.head()","cab8c8e4":"sns.barplot(x='Pclass', y='Sex', data=titanic)\n","c2d114a5":"# Countplot\nsns.catplot(x =\"Survived\", hue =\"Sex\", \nkind =\"count\", data = titanic)","6023af70":"# Violinplot Displays distribution of data \n# across all levels of a category.\nsns.violinplot(x =\"Sex\", y =\"Age\", \ndata = titanic, split = True)","c6a06d34":"sns.barplot(x ='Pclass', y ='Survived',data = titanic)\nprint(\"Percentage of Pclass = 1 who survived:\", titanic[\"Survived\"][titanic[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 2 who survived:\", titanic[\"Survived\"][titanic[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 3 who survived:\", titanic[\"Survived\"][titanic[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)","18a57957":"sns.set_style('whitegrid')\nsns.countplot(x='Sex',data=titanic)","9544a973":"sns.set_style('whitegrid')\nsns.countplot(x='Sex',hue= 'Survived',data=titanic,palette='RdBu_r')","eb9d399d":"sns.distplot(titanic['Age'].dropna(),kde=False,color='darkred',bins=40)\n","b5d90f26":"sns.countplot(x='Survived',data=titanic)","d8d76a7c":"\ntitanic['Age'].hist(color='green',bins=40,figsize=(8,4))\n","9103b764":"sns.boxplot(x=\"Pclass\", y=\"Sex\", data=titanic)\nsns.swarmplot(x=\"Pclass\", y=\"Sex\", data=titanic,color ='.24')\n","6d3b0b73":"cols=['Pclass','Age','Sex']\npd.plotting.scatter_matrix(titanic[cols], figsize = (10, 10), diagonal = 'kde')\n","a4fdc263":"\ntitanic['Age'].mean()\n","8b807b1d":"titanic.plot.scatter(x=\"Pclass\", y=\"Age\")\n","2c6181f5":"y =titanic['Survived']","62302605":"X=titanic['Sex']","1f681cd4":"\nX=titanic.iloc[:,:4].values\ny=titanic.iloc[:, 1].values\nprint(X)\nprint(y)","9bcd5d45":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test =train_test_split(X,y,test_size =0.2,random_state=0)","f9d22182":"#Using LogisticRegression\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train,y_train)","7fd73450":"y_pred= regressor.predict(X_test)\nprint(y_pred)","9bdc10de":"from sklearn.metrics import r2_score\nr2_score(y_pred,y_test)","d4f9e09d":"from sklearn.svm import SVC\nmodel1 = SVC()\nmodel1.fit(X_train,y_train)\n\npred_y = model1.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Acc=\",accuracy_score(y_test,pred_y))","dd565e64":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nconfusion_mat = confusion_matrix(y_test,pred_y)\nprint(confusion_mat)\nprint(classification_report(y_test,pred_y))","72193952":"#Using KNN Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel2 = KNeighborsClassifier(n_neighbors=5)\nmodel2.fit(X_train,y_train)\ny_pred2 = model2.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred2))","935f47e6":"\n#Using GaussianNB\nfrom sklearn.naive_bayes import GaussianNB\nmodel3 = GaussianNB()\nmodel3.fit(X_train,y_train)\ny_pred3 = model3.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred3))","5389ec18":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nconfusion_mat = confusion_matrix(y_test,y_pred3)\nprint(confusion_mat)\nprint(classification_report(y_test,y_pred3))\n","6c9cd9ed":"#Using Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nmodel4 = DecisionTreeClassifier(criterion='entropy',random_state=7)\nmodel4.fit(X_train,y_train)\ny_pred4 = model4.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred4))","5d26a9c8":"\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nconfusion_mat = confusion_matrix(y_test,y_pred4)\nprint(confusion_mat)\nprint(classification_report(y_test,y_pred4))","e532d3ff":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix , accuracy_score, roc_auc_score,roc_curve,classification_report","9755f234":"\nlr = LogisticRegression(solver='liblinear',random_state=3)\nlr.fit(X_train,y_train)\n\ny_test_pred = lr.predict(X_test)\n\nprint('Accuracy_score:',accuracy_score(y_test,y_test_pred))","3731ca6d":"\n#Other Classification models\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import ExtraTreesClassifier","ce7e38f9":"dt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\nknn = KNeighborsClassifier()\ngnb = GaussianNB()\ner = ExtraTreesClassifier()\n","3649027e":"#CV\n\nseed = 7\n\nmodels = []\n\nmodels.append(('Losgistic Regression', lr))\nmodels.append(('Random Forest', rf))\nmodels.append(('KNN', knn))\nmodels.append(('Decision Tree', dt))\nmodels.append(('Gaussian', gnb))\nmodels.append(('ExtraTreesRegressor', er))\n","b42efd7f":"## Importing","3df27f3e":"# OR","c0efd018":"# Data visualization\n","eeae60d1":"![titanic.jpg](attachment:titanic.jpg)","c9539d22":"# Thank you !","97c0d3ca":"\n\n<h1 style=\"text-align: center\">Titanic disaster Dataset<\/h1>","b31cb41b":"### Splitting the dataset into train and test,\n## then  Importing  models  from sklearn  to train the  model and test it ."}}