{"cell_type":{"05cf8b47":"code","3d008ec0":"code","3f968afb":"code","8a459970":"code","e645364c":"code","bb87dff3":"code","3b4137c8":"code","dde10e70":"code","174cff47":"code","f8256607":"markdown"},"source":{"05cf8b47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","3d008ec0":"#Load the libraries and data...\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\ndata = pd.read_csv('..\/input\/train.csv')","3f968afb":"print(data.head(3))","8a459970":"#Grab the relevant data, scale the predictor variable, and add a column of 1s for the gradient descent...\nx = data['GrLivArea']\ny = data['SalePrice']\n#print(x)\nx = (x - x.mean()) \/ x.std()\nprint(x.shape[0])\nx = np.c_[np.ones(x.shape[0]), x] \nprint(x[0][0])","e645364c":"print(x)\n#print(y)\nprint(np.random.rand(2))","bb87dff3":"#GRADIENT DESCENT\n\nalpha = 0.01 #Step size\niterations = 2000 #No. of iterations\nm = y.size #No. of data points\nnp.random.seed(123) #Set the seed\ntheta = np.random.rand(2) #Pick some random values to start with\n\n\n#GRADIENT DESCENT\ndef gradient_descent(x, y, theta, iterations, alpha):\n    past_costs = []\n    past_thetas = [theta]\n    for i in range(iterations):\n        prediction = np.dot(x, theta)\n        error = prediction - y\n        cost = 1\/(2*m) * np.dot(error.T, error)\n        past_costs.append(cost)\n        theta = theta - (alpha * (1\/m) * np.dot(x.T, error))\n        past_thetas.append(theta)\n        \n    return past_thetas, past_costs\n\n#Pass the relevant variables to the function and get the new values back...\npast_thetas, past_costs = gradient_descent(x, y, theta, iterations, alpha)\ntheta = past_thetas[-1]\nprint(theta)\n#Print the results...\nprint(\"Gradient Descent: {:.2f}, {:.2f}\".format(theta[0], theta[1]))","3b4137c8":"#Plot the cost function...\nplt.title('Cost Function J')\nplt.xlabel('No. of iterations')\nplt.ylabel('Cost')\nplt.plot(past_costs)\nplt.show()","dde10e70":"#Animation\n\n#Set the plot up,\nfig = plt.figure()\nax = plt.axes()\nplt.title('Sale Price vs Living Area')\nplt.xlabel('Living Area in square feet (normalised)')\nplt.ylabel('Sale Price ($)')\nplt.scatter(x[:,1], y, color='red')\nline, = ax.plot([], [], lw=2)\nannotation = ax.text(-1, 700000, '')\nannotation.set_animated(True)\nplt.close()\n\n#Generate the animation data,\ndef init():\n    line.set_data([], [])\n    annotation.set_text('')\n    return line, annotation\n\n# animation function.  This is called sequentially\ndef animate(i):\n    x = np.linspace(-5, 20, 1000)\n    y = past_thetas[i][1]*x + past_thetas[i][0]\n    line.set_data(x, y)\n    annotation.set_text('Cost = %.2f e10' % (past_costs[i]\/10000000000))\n    return line, annotation\n\nanim = animation.FuncAnimation(fig, animate, init_func=init,\n                               frames=300, interval=0, blit=True)\n\nanim.save('animation.gif', writer='imagemagick', fps = 30)","174cff47":"#Display the animation...\nimport io\nimport base64\nfrom IPython.display import HTML\n\nfilename = 'animation.gif'\n\nvideo = io.open(filename, 'r+b').read()\nencoded = base64.b64encode(video)\nHTML(data='''<img src=\"data:image\/gif;base64,{0}\" type=\"gif\" \/>'''.format(encoded.decode('ascii')))","f8256607":"**Acknowledgements**: I've primariliy used the material from [Andrew Ng's Coursera course][1] for this, but have also been helped by [this article][2] and [this one][3]. I used some code for the animation from [this kernel][4].\n\n  [1]: https:\/\/www.coursera.org\/learn\/machine-learning\n  [2]: http:\/\/tillbergmann.com\/blog\/python-gradient-descent.html\n  [3]: http:\/\/aimotion.blogspot.co.uk\/2011\/10\/machine-learning-with-python-linear.html\n  [4]: https:\/\/www.kaggle.com\/ronaldtroncoso20\/d\/START-UMD\/gtd\/global-terrorism-trends-animation"}}