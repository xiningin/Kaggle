{"cell_type":{"4ad5d3db":"code","9eed7f33":"code","703ecfa0":"code","dfb2bad8":"code","f70caf17":"code","4f4e29a7":"code","9c4c2971":"code","5d5b801b":"code","94b0c8c4":"code","f4a375f7":"code","b9f81ac8":"code","5fed3f62":"code","c45094e9":"code","bd7676a7":"code","aa836017":"code","882a1634":"code","a93726a5":"code","e10ce35d":"code","924b5bbd":"markdown","88496890":"markdown","c1e997b8":"markdown","f369d210":"markdown","a39ff6fe":"markdown","fdb53f76":"markdown","25db90e8":"markdown","139ab97c":"markdown","1d7a19c1":"markdown","38a6000c":"markdown","1be15e8b":"markdown","c6e84a43":"markdown"},"source":{"4ad5d3db":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import nn\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","9eed7f33":"X_train = np.load(\"\/kaggle\/input\/mhsmadataset\/x_64_train.npy\")\ny_train_vacuole = np.load(\"\/kaggle\/input\/mhsmadataset\/y_vacuole_train.npy\")\ny_train_acrosome = np.load(\"\/kaggle\/input\/mhsmadataset\/y_acrosome_train.npy\")\ny_train_head = np.load(\"\/kaggle\/input\/mhsmadataset\/y_head_train.npy\")\n\n# check shapes of input\ndisplay(X_train.shape)\ndisplay(y_train_vacuole.shape)\ndisplay(y_train_acrosome.shape)\ndisplay(y_train_head.shape)\n\n# check for NaN values\ndisplay(np.isnan(np.sum(X_train)))\ndisplay(np.isnan(np.sum(y_train_vacuole)))\ndisplay(np.isnan(np.sum(y_train_acrosome)))\ndisplay(np.isnan(np.sum(y_train_head)))","703ecfa0":"X_valid = np.load(\"\/kaggle\/input\/mhsmadataset\/x_64_valid.npy\")\ny_valid_vacuole = np.load(\"\/kaggle\/input\/mhsmadataset\/y_vacuole_valid.npy\")\ny_valid_acrosome = np.load(\"\/kaggle\/input\/mhsmadataset\/y_acrosome_valid.npy\")\ny_valid_head = np.load(\"\/kaggle\/input\/mhsmadataset\/y_head_valid.npy\")\n\n# check shapes of input\ndisplay(X_valid.shape)\ndisplay(y_valid_vacuole.shape)\ndisplay(y_valid_acrosome.shape)\ndisplay(y_valid_head.shape)\n\n# check for NaN values\ndisplay(np.isnan(np.sum(X_valid)))\ndisplay(np.isnan(np.sum(y_valid_vacuole)))\ndisplay(np.isnan(np.sum(y_valid_acrosome)))\ndisplay(np.isnan(np.sum(y_valid_head)))","dfb2bad8":"X_test = np.load(\"\/kaggle\/input\/mhsmadataset\/x_64_test.npy\")\ny_test_vacuole = np.load(\"\/kaggle\/input\/mhsmadataset\/y_vacuole_test.npy\")\ny_test_acrosome = np.load(\"\/kaggle\/input\/mhsmadataset\/y_acrosome_test.npy\")\ny_test_head = np.load(\"\/kaggle\/input\/mhsmadataset\/y_head_test.npy\")\n\n# check shapes of input\ndisplay(X_test.shape)\ndisplay(y_test_vacuole.shape)\ndisplay(y_test_acrosome.shape)\ndisplay(y_test_head.shape)\n\n# check for NaN values\ndisplay(np.isnan(np.sum(X_test)))\ndisplay(np.isnan(np.sum(y_test_vacuole)))\ndisplay(np.isnan(np.sum(y_test_acrosome)))\ndisplay(np.isnan(np.sum(y_test_head)))","f70caf17":"i = 11\nf = i*25\ns = i*50\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,10))\n\nax1.imshow(X_train[f])\nax1.text(0.05, 0.1,\n         f\"vacuole: {y_train_vacuole[f]}\\nacrosome: {y_train_acrosome[f]}\\nhead: {y_train_head[f]}\", \n         horizontalalignment='left',\n         verticalalignment='center',\n         transform=ax1.transAxes)\n\nax2.imshow(X_train[s], cmap='gray')\nax2.text(0.05, 0.1,\n         f\"vacuole: {y_train_vacuole[s]}\\nacrosome: {y_train_acrosome[s]}\\nhead: {y_train_head[s]}\", \n         horizontalalignment='left',\n         verticalalignment='center',\n         transform=ax2.transAxes)","4f4e29a7":"class ImagesDataset(torch.utils.data.Dataset):\n    def __init__(self, images, vacuoles, acrosomes, heads, imagesize):\n        self.imagesize = imagesize\n        self.images = images \/ 255.0\n        self.vacuoles = vacuoles\n        self.acrosomes = acrosomes\n        self.heads = heads\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, item):\n        return {\n            'images': self.images[item].astype(\"float32\").reshape(1, self.imagesize, self.imagesize),\n            'vacuoles': torch.tensor(self.vacuoles[item], dtype=torch.long),\n            'acrosomes': torch.tensor(self.vacuoles[item], dtype=torch.long),\n            'heads': torch.tensor(self.vacuoles[item], dtype=torch.long)\n        }","9c4c2971":"train_dataset = ImagesDataset(images=X_train,\n                              vacuoles=y_train_vacuole,\n                              acrosomes=y_train_acrosome,\n                              heads=y_train_head,\n                              imagesize=X_train.shape[1]\n                             )\nvalid_dataset = ImagesDataset(images=X_valid,\n                              vacuoles=y_valid_vacuole,\n                              acrosomes=y_valid_acrosome,\n                              heads=y_valid_head,\n                              imagesize=X_valid.shape[1]\n                             )\ntest_dataset = ImagesDataset(images=X_test,\n                              vacuoles=y_test_vacuole,\n                              acrosomes=y_test_acrosome,\n                              heads=y_test_head,\n                              imagesize=X_test.shape[1]\n                             )\nBATCH_SIZE = 64\ntrain_dataloader = DataLoader(train_dataset,\n                             batch_size=BATCH_SIZE)\nvalid_dataloader = DataLoader(valid_dataset,\n                             batch_size=BATCH_SIZE)\ntest_dataloader = DataLoader(test_dataset,\n                             batch_size=BATCH_SIZE)\n\n","5d5b801b":"import gc\n# del model\n# del optimizer\n# del loss_fn\ntorch.cuda.empty_cache()\ngc.collect()\n!nvidia-smi","94b0c8c4":"class ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        self.cnn_layers = nn.Sequential(\n            nn.Conv2d(1, 128, kernel_size=4, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(128, 256, kernel_size=4, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Flatten()\n        )\n        self.fc = nn.Linear(57600, 512)\n        self.fc2 = nn.Linear(512, 2)\n    def forward(self, item):\n        out = self.cnn_layers(item)\n        out = self.fc(out)\n        out = self.fc2(out)\n        return out\nmodel = ImageClassifier().to(device)","f4a375f7":"loss_fn = nn.CrossEntropyLoss().to(device)\n\nLR, EPS, WEIGHT_DECAY = 1e-4, 1e-08, 0.01\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=LR,\n    eps=EPS,\n    weight_decay=WEIGHT_DECAY\n)","b9f81ac8":"def train_ep(dataloader, model, loss_fn, optimizer, device, n_all, mode):\n    all = len(dataloader)\n    losses = []\n    corrects = 0\n    model.train()\n    n = 0\n    for d in dataloader:\n        images = d['images'].to(device)\n        targets = d[mode].to(device)\n        outputs = model(images)\n\n        _, pred = torch.max(outputs, dim=1)\n        corrects += torch.sum(pred == targets)\n\n        loss = loss_fn(outputs, targets)\n        losses.append(loss.item())\n\n        loss.backward()\n#         nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        n += 1\n        print(f\"batch {n} \/ {all} -- loss: {loss.item():.5f}\")\n    return corrects.item() \/ n_all  * 100, np.mean(losses)","5fed3f62":"def eval_ep(dataloader, model, loss_fn, device, n_all, mode):\n    all = len(dataloader)\n    losses = []\n    loss = 0\n    corrects = 0\n    n = 0\n    model.eval()\n    with torch.no_grad():\n        for d in dataloader:\n            images = d['images'].to(device)\n            targets = d[mode].to(device)\n            outputs = model(images)\n\n            _, pred = torch.max(outputs, dim=1)\n            corrects += torch.sum(pred == targets)\n\n            loss = loss_fn(outputs, targets)\n            losses.append(loss.item())\n            n += 1\n            print(f\"batch {n} \/ {all} -- loss: {loss.item():.5f}\")\n\n    return corrects.item() \/ n_all * 100, np.mean(losses)","c45094e9":"EPOCHS = 20\nlosses_valid = []\nlosses_train = []\nacc_valid = []\nacc_train = []\nbest_acc = 0\n\nmode = \"vacuoles\"\n# mode = \"acrosomes\"\n# mode = \"heads\"\n\n\nfor i in range(EPOCHS):\n    train_c, train_l = train_ep(train_dataloader, model, loss_fn, optimizer, device, X_train.shape[0], mode=mode)\n    print(f\"Epoch {i} ------ train corrects {train_c}    train losses {train_l}\")\n    losses_train.append(train_l)  \n    acc_train.append(train_c)  \n\n    valid_c, valid_l = eval_ep(valid_dataloader, model, loss_fn, device, X_valid.shape[0], mode=mode)\n    print(f\"Epoch {i} ------ valid corrects {valid_c}      vali losses {valid_l}\")\n    losses_valid.append(valid_l)\n    acc_valid.append(valid_c)\n\n    if valid_c > best_acc:\n        state = {\n            'state_dict': model.state_dict(),\n            'optimizer': optimizer.state_dict()\n        }\n        torch.save(state, \"myModel\")\n        best_acc = valid_c","bd7676a7":"state = torch.load(\"myModel\")\nmodel.load_state_dict(state['state_dict'])\noptimizer.load_state_dict(state['optimizer'])","aa836017":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n# ax1.title(\"Training and Validation Accuracy\")\nprint(ax1.title)\nax1.plot(acc_valid,label=\"val\")\nax1.plot(acc_train,label=\"train\")\nax1.set_xlabel(\"iterations\")\nax1.set_ylabel(\"accuracy\")\nax1.legend()\n\nax2.plot(losses_valid,label=\"val\")\nax2.plot(losses_train,label=\"train\")\nax2.set_xlabel(\"iterations\")\nax2.set_ylabel(\"loss\")\nax2.legend()","882a1634":"test_accuracy, test_loss = eval_ep(test_dataloader, model, loss_fn, device, X_test.shape[0], mode=mode)\nprint(f\"Accuracy: {test_accuracy}, loss: {test_loss}\\n\")\n\nnb_classes = 2\n\nconfusion_matrix = torch.zeros(nb_classes, nb_classes)\nwith torch.no_grad():\n    for i, d in enumerate(test_dataloader):\n        images = d['images'].to(device)\n        targets = d[mode].to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, dim=1)\n        for t, p in zip(targets, preds):\n                confusion_matrix[t, p] += 1\n\nscores = pd.DataFrame(index=['negative', 'positive', 'average'], columns=['precision', 'recall', 'F1-Score'])\nfor i, label in enumerate([\"negative\", \"positive\"]):\n    p = scores.loc[label, 'precision'] = (confusion_matrix[i, i] \/ confusion_matrix[i].sum()).item()\n    r = scores.loc[label, 'recall'] = (confusion_matrix[i, i] \/ confusion_matrix[:, i].sum()).item()\n    scores.loc[label, 'F1-Score'] = (2*p*r) \/ (p+r)\nscores.loc['average'] = scores.mean().values","a93726a5":"scores","e10ce35d":"label2class = {0: 'negative', 1: 'positive'}\n\nplt.figure(figsize=(15,10))\nsns.set(font_scale=1.8)\n\nclass_names = list(label2class.values())\ndf_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\nheatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","924b5bbd":"# Create Dataset and DataLoader","88496890":"# Some of the images","c1e997b8":"# Model training and validating","f369d210":"## valid data","a39ff6fe":"# Input dataframes","fdb53f76":"## train data","25db90e8":"## Accuracy and Loss of test","139ab97c":"## Loss and Accuracy plots for train and validation dataset","1d7a19c1":"# Test dataset and scores","38a6000c":"## F1 score, precision and recall","1be15e8b":"## confusion matrix","c6e84a43":"## test data"}}