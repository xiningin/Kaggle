{"cell_type":{"f1cb34e6":"code","ed8a0fd4":"code","904fb831":"code","8b88950c":"code","ab1feed3":"code","7e265fb9":"code","5e84f39a":"code","c303edd7":"code","d36bd302":"code","696053f5":"code","f80fbe1e":"code","dcff6308":"code","b6d129fa":"code","567296ef":"code","11c70415":"code","473da92d":"code","58ab42a0":"code","c1af8d4c":"code","18b86b08":"code","1e38a71f":"code","024bc2ca":"code","b4bc8e92":"code","43d129fe":"code","fcd1808f":"code","28bef722":"code","df669752":"code","ecb99662":"code","8739c495":"code","b5605007":"code","0d202411":"code","509ec0ab":"code","d54d944f":"code","6172168f":"code","9c9f95a9":"code","8d1d0867":"code","62ee304c":"code","edc922c5":"code","6d998c3a":"code","cd662f74":"code","0f4baff6":"code","3a4426ff":"markdown","1697c51f":"markdown","db67cb42":"markdown","10e5f331":"markdown","3ae40bf7":"markdown","4092e07e":"markdown","4d7c03c3":"markdown","1aff11d2":"markdown"},"source":{"f1cb34e6":"import re\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport string\nimport nltk\nimport warnings \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n\nfrom nltk import PorterStemmer,WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\n\n%matplotlib inline","ed8a0fd4":"train = pd.read_csv('..\/input\/sentiment-analysis-on-movie-reviews\/train.tsv.zip', sep=\"\\t\")\ntest = pd.read_csv('..\/input\/sentiment-analysis-on-movie-reviews\/test.tsv.zip', sep=\"\\t\")\nsampleSubmission = pd.read_csv('..\/input\/sentiment-analysis-on-movie-reviews\/sampleSubmission.csv')\n\ntrain_original = train.copy()\ntest_original = test.copy()\n\n\ntrain.head()","904fb831":"train.isnull().sum()","8b88950c":"train.info()","ab1feed3":"print(train[\"SentenceId\"].value_counts())\n","7e265fb9":"print(train[\"Sentiment\"].unique())\n\nplt.rcParams['figure.figsize'] = (13, 7)\n\n#sns.set(style=\"white\")\n\nsns.countplot(train[\"Sentiment\"], palette='deep')\n\nplt.title('Sentiment count in train set', fontsize = 20)\n","5e84f39a":"def Preprocess(df):\n\n\n    for i in df['Phrase']:\n        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n        i = tokenizer.tokenize(i)\n\n        \n#------------------------------------------------------------------------------------------------\n        \n    tokenized_review_1 = df['Phrase'].apply(lambda x: x.split())\n    \n\n\n#------------------------------------------------------------------------------------------------\n\n\n\n    ps = PorterStemmer()\n    WL = WordNetLemmatizer()\n\n    stemmed_review = tokenized_review_1.apply(lambda x: [ps.stem(i) for i in x])\n    lemmatized_review = tokenized_review_1.apply(lambda x: [WL.lemmatize(i) for i in x])\n\n\n#------------------------------------------------------------------------------------------------\n\n\n    stop = stopwords.words('english')\n    stemmed_review = stemmed_review.apply(lambda x: [item for item in x if item not in stop])\n    lemmatized_review = lemmatized_review.apply(lambda x: [item for item in x if item not in stop])\n\n    \n\n\n\n#------------------------------------------------------------------------------------------------\n\n    for i in range(len(stemmed_review)):\n        stemmed_review[i] = ' '.join(stemmed_review[i])\n\n    df['stemmed_review'] = stemmed_review\n\n    \n    for i in range(len(lemmatized_review)):\n        lemmatized_review[i] = ' '.join(lemmatized_review[i])\n\n    df['lemmatized_review'] = lemmatized_review\n\n\n\n    df = df[df[\"stemmed_review\"] != '']\n    df = df[df[\"lemmatized_review\"] != '']\n","c303edd7":"Preprocess(train)","d36bd302":"Preprocess(test)","696053f5":"train.head()","f80fbe1e":"print(\"normal\")\nprint(\"-\"*100)\n\nprint(train['Phrase'][0])\nprint(\"\\nafter stemming\")\nprint(\"-\"*100)\n\nprint(train['stemmed_review'][0])\n\nprint(\"\\nafter lemmatizing\")\nprint(\"-\"*100)\nprint(train['lemmatized_review'][0])\n","dcff6308":"plot_train = train.copy()\nplot_train","b6d129fa":"plot_train[\"Sentiment\"].unique()","567296ef":"positive_words = plot_train[plot_train[\"Sentiment\"] !=  0 ]\npositive_words = positive_words[positive_words[\"Sentiment\"] !=  1 ]\npositive_words = positive_words[positive_words[\"Sentiment\"] !=  2 ]\n\n\n\nnegative_words = plot_train[plot_train[\"Sentiment\"] !=  3 ]\nnegative_words = negative_words[negative_words[\"Sentiment\"] !=  4 ]\nnegative_words = negative_words[negative_words[\"Sentiment\"] !=  2 ]\n","11c70415":"negative_words[\"Sentiment\"].unique()","473da92d":"print(negative_words.shape)\nprint(positive_words.shape)","58ab42a0":"plot_all_words = ' '.join(text for text in train['lemmatized_review'])\n\nplot_positive_words = ' '.join(text for text in positive_words['lemmatized_review'])\n\nplot_negative_words = ' '.join(text for text in negative_words['lemmatized_review'])\n\nplot_positive_words[0:1000]\n","c1af8d4c":"plot_negative_words[0:1000]","18b86b08":"import matplotlib.pyplot as plt \nimport seaborn as sns\nfrom wordcloud import WordCloud,ImageColorGenerator\nfrom PIL import Image\nimport urllib\nimport requests\n\nMask = np.array(Image.open(r'..\/input\/triangle\/kisspng-black-triangle-computer-icons-symbol-arrow-5af0f4cd97c624.0510697015257407496217.jpg'))\n\nimage_colors = ImageColorGenerator(Mask)\n\n# Now we use the WordCloud function from the wordcloud library \nwc = WordCloud(background_color='white', height=1500, width=4000,mask=Mask).generate(plot_all_words)\n\nplt.figure(figsize=(10,20))\n\n# interpolation is used to smooth the image generated \nplt.imshow(wc.recolor(),interpolation=\"spline36\")\n\n#'none', 'nearest', 'bilinear', 'bicubic', 'spline16',\n#           'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',\n#           'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'\n        \nplt.axis('off')\nplt.show()","1e38a71f":"Mask1 = np.array(Image.open(r'..\/input\/likeee\/lll.png'))\n\nimage_colors = ImageColorGenerator(Mask1)\n\n#def grey_color_func(word, font_size, position, orientation, random_state=None,\n #                   **kwargs):\n #   return \"hsl(0, 0%%, %d%%)\" % random.randint(60, 100)\n\n# Now we use the WordCloud function from the wordcloud library \nwc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask1).generate(plot_positive_words)\n\nplt.figure(figsize=(10,20))\n\n# interpolation is used to smooth the image generated \nplt.imshow(wc.recolor(color_func=image_colors),interpolation=\"spline36\")\n\n#'none', 'nearest', 'bilinear', 'bicubic', 'spline16',\n#           'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',\n#           'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'\n        \nplt.title(\"positive words\", fontsize=20)\n\nplt.axis('off')\nplt.show()","024bc2ca":"import random\n\n\nMask2 = np.array(Image.open(r'..\/input\/dislikee\/dislike.jpg'))\n\nimage_colors = ImageColorGenerator(Mask2)\n\n# Now we use the WordCloud function from the wordcloud library \nwc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask2).generate(plot_negative_words)\n\nplt.figure(figsize=(10,20))\n\n# interpolation is used to smooth the image generated \nplt.imshow(wc.recolor(color_func=image_colors),interpolation=\"hamming\")\n\n#interpolation : 'none', 'nearest', 'bilinear', 'bicubic', 'spline16',\n#                'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',\n#                'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'\n\nplt.title(\"negative words\", fontsize=20)\n        \nplt.axis('off')\nplt.show()","b4bc8e92":"from tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","43d129fe":"y_train_NN = train[\"Sentiment\"]\n\nx_Train_stemmed_NN = train[\"stemmed_review\"]\nx_test_stemmed_NN = test[\"stemmed_review\"]\n\nx_Train_lemmatized_NN = train[\"lemmatized_review\"]\nx_test_lemmatized_NN = test[\"lemmatized_review\"]","fcd1808f":"x_Train_stemmed_NN.shape, y_train_NN.shape ,x_test_stemmed_NN.shape\n","28bef722":"tokenize = Tokenizer()\ntokenize.fit_on_texts(x_Train_stemmed_NN.values)\n\n#X_test = test.stemmed_review\nX_train_stemmed = tokenize.texts_to_sequences(x_Train_stemmed_NN)\nX_test_stemmed = tokenize.texts_to_sequences(x_test_stemmed_NN)\n\ntokenize.fit_on_texts(x_Train_lemmatized_NN.values)\n\nX_train_lemmatized = tokenize.texts_to_sequences(x_Train_lemmatized_NN)\nX_test_lemmatized = tokenize.texts_to_sequences(x_test_lemmatized_NN)","df669752":"X_train_stemmed = pad_sequences(X_train_stemmed).astype(float)\nX_test_stemmed = pad_sequences(X_test_stemmed).astype(float)\n\nX_train_lemmatized = pad_sequences(X_train_lemmatized)\nX_test_lemmatized = pad_sequences(X_test_lemmatized)\n\n","ecb99662":"EMBEDDING_DIM = 100\nunknown = len(tokenize.word_index)+1\nmodel = Sequential()\nmodel.add(Embedding(unknown, EMBEDDING_DIM))\nmodel.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2 ))\nmodel.add(Dense(5, activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","8739c495":"model.summary()","b5605007":"model.fit(X_train_stemmed, y_train_NN, batch_size=128, epochs=7, verbose=1)","0d202411":"final_pred = model.predict_classes(X_test_stemmed)\nfinal_pred","509ec0ab":"test[\"Sentiment\"] = final_pred\ntest[\"Sentiment\"].value_counts()","d54d944f":"train[\"Sentiment\"].value_counts()","6172168f":"NB_data = pd.concat([train, test], ignore_index=True)\n","9c9f95a9":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n\npipeline = Pipeline([\n    ('bow',CountVectorizer(analyzer=\"word\")),  # strings to token integer counts\n    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w\/ Naive Bayes classifier\n])","8d1d0867":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n\nx_train,x_test,y_train,y_test = train_test_split(NB_data['stemmed_review'], NB_data['Sentiment'], test_size=0.2, random_state=42)\n\npipeline.fit(x_train,y_train)\nn_b_predictions = pipeline.predict(x_test)\nprint(classification_report(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(confusion_matrix(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(pipeline.score(x_train,y_train))\nprint(accuracy_score(n_b_predictions,y_test))","62ee304c":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n\nx_train,x_test,y_train,y_test = train_test_split(NB_data['lemmatized_review'], NB_data['Sentiment'], test_size=0.2, random_state=42)\n\npipeline.fit(x_train,y_train)\nn_b_predictions = pipeline.predict(x_test)\nprint(classification_report(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(confusion_matrix(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(pipeline.score(x_train,y_train))\nprint(accuracy_score(n_b_predictions,y_test))","edc922c5":"tokenize = Tokenizer()\ntokenize.fit_on_texts(x_train.values)\nX_test = test.stemmed_review\nX_train = tokenize.texts_to_sequences(x_train)\nX_test = tokenize.texts_to_sequences(X_test)","6d998c3a":"X_train = pad_sequences(X_train)\nX_test = pad_sequences(X_test)","cd662f74":"model.fit(X_train, y_train, batch_size=128, epochs=7, verbose=1)","0f4baff6":"final_pred2 = model.predict_classes(X_test_stemmed)\nfinal_pred2","3a4426ff":"## 4- Predicting sentiment for overall set with Naive bayes and NN","1697c51f":"Welcome to my kernel sentiment analysis on The Rotten Tomatoes movie review.\n\nAs this is my first time working on sentiment analysis problem, i will try to go through some basic process like tokenizing, stemming, lemmatizing, wordclouds, get rid of stop words and so on, also i will try to predict the sentiment in  test set, train set and the combination of the train and test set\n\nif you have any suggest,advice or correction please don't hesitate to write it, i think it will be very helpful for me.\n\nwe will go through these topics:\n        \n        1- Text Preprocessing\n        2- Word Clouds\n        3- Predicting sentiment for test data Using NN\n        4- Predicting sentiment for overall set with Naive bayes and NN","db67cb42":"**using stemmed data**","10e5f331":"## 3- Predicting sentiment for test data Using NN","3ae40bf7":"## 2- Word Clouds","4092e07e":"NN with lemmatized data","4d7c03c3":"## 1- Text Preprocessing","1aff11d2":"**using lemmatized data**"}}