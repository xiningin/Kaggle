{"cell_type":{"e15d0d73":"code","539ad262":"code","c7f850ff":"code","dfa172b3":"code","b3c18957":"code","ebd33c04":"code","69e64e1d":"code","03717599":"code","a6d77220":"code","2d96f39f":"code","9ecfeb4d":"code","2a062ad1":"code","20f7eb75":"code","35decc7c":"code","7b1458f0":"code","c293d03d":"code","ca36968b":"code","a2f62cae":"code","1470f30c":"code","b4c08410":"code","a688b500":"code","d8e12020":"code","8d58dad9":"code","77da5043":"code","4380528d":"code","93c893b4":"code","c6351b4b":"code","8a6110de":"code","fe657afa":"code","9a0dc9a4":"code","70ee7c05":"markdown","0240a27b":"markdown","f886b25c":"markdown","d0109fe7":"markdown","ce95f263":"markdown","cab48965":"markdown","a513e5ae":"markdown","86ceda62":"markdown","a936c959":"markdown","dd31eaae":"markdown","f43e4c6a":"markdown","f1cde0c3":"markdown","43791a4b":"markdown","ce234cd2":"markdown","648b6de8":"markdown","b0299dac":"markdown","7ed8de76":"markdown","458c452d":"markdown"},"source":{"e15d0d73":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook as tqdm\nimport os\nprint(os.listdir(\"..\/input\"))","539ad262":"#https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df\n\nimport matplotlib.pyplot as plt\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n\ndf_train = import_data(\"..\/input\/train.csv\")\ndf_train.shape","c7f850ff":"df_train.head()","dfa172b3":"plt.style.use('ggplot')\nplt.figure(figsize=(13,5))\n\nplt.subplot(1,3,1)\nsns.countplot(df_train['event'])\nplt.xlabel(\"State of the pilot\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.title(\"Target repartition\", fontsize=15)\n\nplt.subplot(1,3,2)\nsns.countplot('experiment', hue='event', data=df_train)\nplt.xlabel(\"Experiment and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Experiments\", fontsize=15)\n\nplt.subplot(1,3,3)\nsns.countplot('event', hue='seat', data=df_train)\nplt.xlabel(\"Seat and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Seat\", fontsize=15)\nplt.show()","b3c18957":"# Just looking at a single trial for now\nsubset = df_train.loc[(df_train['crew'] == 1) & (df_train['experiment'] == 'CA')]\nsubset.sort_values(by='time')\n\n# remove the high frequency signals by scipy\nfrom scipy import signal\nb, a = signal.butter(8,0.05)\ny = signal.filtfilt(b, a, subset['r'], padlen=150)\n\nplt.style.use('seaborn')\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nplt.title(\"Respiratoin Trend\", fontsize=15)\nplt.plot(subset['r'][3000:4024])\nplt.subplot(1,2,2)\nplt.plot(y[3000:4024])\nplt.title(\"Respiratoin Trend after remove the high frequency signals\", fontsize=15)","ebd33c04":"from biosppy.signals import ecg, resp\n\nout = resp.resp(y,sampling_rate=256, show=False)\n\nplt.plot(out['resp_rate_ts'], out['resp_rate'])\nplt.ylabel('Respiratory frequency [Hz]')\nplt.xlabel('Time [s]')\nplt.title(\"Respiratoin Rate\", fontsize=15)","69e64e1d":"plt.style.use('bmh')\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.violinplot(x='event', y='ecg', data=df_train.sample(50000))\nplt.ylabel(\"Electrocardiogram Signal (\u00b5V)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Electrocardiogram signal influence\", fontsize=15)\n\nplt.subplot(1,2,2)\nsns.distplot(df_train['ecg'], label='Train set')\nplt.legend()\nplt.xlabel(\"Electrocardiogram Signal (\u00b5V)\", fontsize=12)\nplt.title(\"Electrocardiogram Signal Distribution\", fontsize=15)","03717599":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nb, a = signal.butter(8,0.05)\ny = signal.filtfilt(b, a, subset['ecg'], padlen=150)\nplt.plot(y[3000:4024])\nplt.title(\"Electrocardiogram Trend\", fontsize=15)\n\n#Convert ECG into heart rate data by Biosppy to detect the R waves\nplt.subplot(1,2,2)\nout = ecg.ecg(signal=subset['ecg'], sampling_rate=256, show=False)\nplt.plot(out['heart_rate_ts'], out['heart_rate'])\nplt.ylabel('Heart Rate (BPM)')\nplt.xlabel('Time [s]');\nplt.title(\"Electrocardiogram Heart Rate\", fontsize=15)","a6d77220":"eeg_features = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\"]\n\nplt.figure(figsize=(20,25))\n\ni = 0\nfor egg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.boxplot(x='event', y=egg, data=df_train.sample(50000), showfliers=False)","2d96f39f":"plt.figure(figsize=(20,25))\nplt.title('EEG features distributions')\ni = 0\n\nfor eeg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.distplot(df_train.sample(10000)[eeg], label='Train set', hist=False)\n    plt.xlim((-500, 500))\n    plt.legend()\n    plt.xlabel(eeg, fontsize=12)","9ecfeb4d":"df_train['fp1_f7'] = df_train['eeg_fp1'] - df_train['eeg_f7']\ndf_train['f7_t3'] = df_train['eeg_f7'] - df_train['eeg_t3']\ndf_train['t3_t5'] = df_train['eeg_t3'] - df_train['eeg_t5']\ndf_train['t5_o1'] = df_train['eeg_t5'] - df_train['eeg_o1']\ndf_train['fp1_f3'] = df_train['eeg_fp1'] - df_train['eeg_f7']\ndf_train['f3_c3'] = df_train['eeg_f3'] - df_train['eeg_c3']\ndf_train['c3_p3'] = df_train['eeg_c3'] - df_train['eeg_p3']\ndf_train['p3_o1'] = df_train['eeg_p3'] - df_train['eeg_o1']\n\ndf_train['fz_cz'] = df_train['eeg_fz'] - df_train['eeg_cz']\ndf_train['cz_pz'] = df_train['eeg_cz'] - df_train['eeg_pz']\ndf_train['pz_poz'] = df_train['eeg_pz'] - df_train['eeg_poz']\n\ndf_train['fp2_f8'] = df_train['eeg_fp2'] - df_train['eeg_f8']\ndf_train['f8_t4'] = df_train['eeg_f8'] - df_train['eeg_t4']\ndf_train['t4_t6'] = df_train['eeg_t4'] - df_train['eeg_t6']\ndf_train['t6_o2'] = df_train['eeg_t6'] - df_train['eeg_o2']\ndf_train['fp2_f4'] = df_train['eeg_fp2'] - df_train['eeg_f4']\ndf_train['f4_c4'] = df_train['eeg_f4'] - df_train['eeg_c4']\ndf_train['c4_p4'] = df_train['eeg_c4'] - df_train['eeg_p4']\ndf_train['p4_o2'] = df_train['eeg_p4'] - df_train['eeg_o2']","2a062ad1":"df_train.head()","20f7eb75":"df_train.shape","35decc7c":"df_train.info()","7b1458f0":"from sklearn.preprocessing import LabelEncoder\nLE1 = LabelEncoder()\nLE2 = LabelEncoder()\n\ndf_train['experiment'] = LE1.fit_transform(df_train['experiment'])\ndf_train['event'] = LE2.fit_transform(df_train['event'])","c293d03d":"df_train.head()","ca36968b":"df_train['pilot'] = 100 * df_train['seat'] + df_train['crew']\nprint(\"Number of pilots : \", len(df_train['pilot'].unique()))","a2f62cae":"df_train.head()","1470f30c":"from sklearn.preprocessing import MinMaxScaler\ndef normalize_by_pilots(df):\n    pilots = df[\"pilot\"].unique()\n    for pilot in tqdm(pilots):\n        ids = df[df[\"pilot\"] == pilot].index\n        scaler = MinMaxScaler()\n        df.loc[ids, features_m] = scaler.fit_transform(df.loc[ids, features_m])\n    return df","b4c08410":"features_m = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\",'fp1_f7', 'f7_t3', 't3_t5', 't5_o1', 'fp1_f3', 'f3_c3', 'c3_p3', 'p3_o1', 'fz_cz', 'cz_pz',\n                'pz_poz', 'fp2_f8', 'f8_t4', 't4_t6', 't6_o2', 'fp2_f4', 'f4_c4', 'c4_p4', 'p4_o2']","a688b500":"df_train = normalize_by_pilots(df_train)\ndf_train.head()","d8e12020":"y = df_train['event']\ndf_train.drop(['event'], axis=1, inplace=True)\ndf_train.shape","8d58dad9":"df_train.head()","77da5043":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n%matplotlib inline\nlista = range(1,47)\naa=[]\nbb=[]\nfor f in tqdm(lista):\n    aa.append(f)\n    pca = PCA(n_components=f).fit(df_train)\n    \na = 0\nfor e in lista:\n    a=a+pca.explained_variance_ratio_[e-1]\n    bb.append(a)","4380528d":"fig, ax = plt.subplots(figsize = (10,6))\nplot = plt.plot(aa, bb, '-o')\nax.set_xlabel(\"Dimensions\")\nax.set_ylabel(\"Variance_ratio\"); ","93c893b4":"# Apply PCA for dimension reduction\npca = PCA(n_components=10).fit(df_train)\nX_pca = pca.transform(df_train)\nprint(sum(pca.explained_variance_ratio_)) ","c6351b4b":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_pca, y, test_size = 0.2)","8a6110de":"from imblearn.over_sampling import SMOTE\nX_train, y_train = SMOTE().fit_resample(X_train, y_train.ravel())","fe657afa":"from sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\n\nparams = {\"objective\" : \"multiclass\",\n              \"num_class\": 4,\n              \"metric\" : \"multi_error\",\n              \"num_leaves\" : 30,\n              \"min_child_weight\" : 50,\n              \"learning_rate\" : 0.1,\n              \"bagging_fraction\" : 0.7,\n              \"feature_fraction\" : 0.7,\n              \"bagging_seed\" : 420,\n              \"verbosity\" : -1\n         }\n\nXGB = XGBClassifier()\n\n# XGB = XGBClassifier(max_depth=5, learning_rate=0.01, n_estimators=100, gamma=0, min_child_weight=1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.005)","9a0dc9a4":"XGB.fit(X_train,y_train)\nprint (\"accuracy_score on testing data of XGBoost: {:.4f}\".format(accuracy_score(y_val, XGB.predict(X_val))))","70ee7c05":"For this experiment, I chose the middle montage because it's one that's used clinically and I'm familiar with. To montage the data, you just have to subtract the value of one electrode from another.","0240a27b":"## 5.2 Imbalance learning","f886b25c":" ## 3.4 Split data as feature & Label","d0109fe7":"## 2.4 Electroencephalogram (EEG)","ce95f263":"# 2. Data Exploration\n## 2.1 Target\/Experiment","cab48965":"## 2.2 Respiration\nThis is a simple measure of the rise and fall of the chest. It represents muscle activity of the diaphragm and abdomen. We know that when someone is physiologically stressed, this rate increases.","a513e5ae":"# 5. Model Training\n## 5.1 Split data as training & testing set","86ceda62":"# 1. Import Data","a936c959":"## 5.3 Model Training","dd31eaae":"## 4.2 PCA for dimension reduction\nBased on PCA result, we reduce dimension from 47 to 10 in order to avoid overfit problem.","f43e4c6a":"## 3.3 Normalizing\nWe apply a Min\/Max Scaler for each pilot.","f1cde0c3":"## 2.3 Electrocardiogram (ECG)","43791a4b":"## 3.2 OneHotEncoding","ce234cd2":"Use Biosppy to filter data to get useful insignts and count the respiration rate","648b6de8":"# 4. PCA\n## 4.1 PCA dimension Survey","b0299dac":"# 3. Data Preprocess\n## 3.1 Electroencephalogram recordings\nThe EEG data is prepared in a fairly typical arrangement of 20 electrodes across the scalp. The letter in each lead signifies the part of the brain that that lead is nearest to (Temporal, Frontal, Parietal etc), with odd numbers on the left, evens on the right. Usually in the clinic, we don't look at the electrical potentials at each electrode, but at the potential difference between pairs of electrodes. This gives us an idea of the electrical field in the brain region between these two points as a way to infer what the brain is doing in that region. \n\n![10-20 Montage system](https:\/\/ai2-s2-public.s3.amazonaws.com\/figures\/2017-08-08\/f2861bea35e87ac1fe5c053e4cc58911d28d112f\/3-Figure1-1.png)","7ed8de76":"This kernel try to use PCA to reduce dimention and train model with XGBoost. The final result is acceptable. Thanks for above kernels:\n* Memory Saving: https:\/\/www.kaggle.com\/sarmat\/sklearn-lgbm-ensemble-baseline\n* Data Exploration: https:\/\/www.kaggle.com\/theoviel\/starter-code-eda-and-lgbm-baseline\n* Data Preprocess: https:\/\/www.kaggle.com\/stuartbman\/introduction-to-physiological-data\/comments","458c452d":"The datatype of experiment and event is category. It need be handle with onehotencoding."}}