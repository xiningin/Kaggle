{"cell_type":{"bb965497":"code","e7a1d773":"code","72160996":"code","9f3f4480":"code","50e6cee6":"code","b9adf295":"code","6ee0b0cc":"code","073d0177":"code","9dc41c40":"code","fe611739":"code","2031998d":"code","a26f2a99":"code","1fe2a494":"code","fa5334cb":"code","773b1ea4":"code","bd81cbef":"code","8c4bd115":"code","f0073d12":"code","e8797371":"code","8ce45a9e":"code","a740a071":"code","545ff8ac":"code","18ffaa45":"code","6d3f0544":"code","8cfa810d":"markdown","61de80ee":"markdown","e61748e9":"markdown","f4e7f794":"markdown","c6df49be":"markdown"},"source":{"bb965497":"\nimport os\nimport glob\nimport shutil\nimport json\nimport keras\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.layers import Dense, Flatten, Dropout, Conv2D, Activation, MaxPooling2D, BatchNormalization\n","e7a1d773":"work_dir = '..\/input\/cassava-leaf-disease-classification\/'\nos.listdir(work_dir) \ntrain_path = '\/kaggle\/input\/cassava-leaf-disease-classification\/train_images'","72160996":"data = pd.read_csv(work_dir + 'train.csv')\ndata.head()","9f3f4480":"print(Counter(data['label'])) # checking labels","50e6cee6":"data.dtypes","b9adf295":"print(os.listdir(work_dir))\ndata_dir = work_dir\n","6ee0b0cc":"sns.set_style(\"dark\")\nplt.figure(figsize=(10,8))\nsns.countplot(data[\"label\"], edgecolor=\"black\", palette=\"mako\")\n","073d0177":"df_train = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\ndf_train.head()\ndf_train[\"label\"] = df_train[\"label\"].astype(str) #convert to str as we want to use Categorical Cross Entropy (CCE) later on\n\n","9dc41c40":"path = \"..\/input\/cassava-leaf-disease-classification\/train_images\/\"\ndf0 = df_train[df_train[\"label\"] == \"0\"]\nfiles = df0[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()\n","fe611739":"df1 = df_train[df_train[\"label\"] == \"1\"]\nfiles = df1[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()\n","2031998d":"df2 = df_train[df_train[\"label\"] == \"2\"]\nfiles = df2[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()\n","a26f2a99":"df3 = df_train[df_train[\"label\"] == \"3\"]\nfiles = df3[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()\n","1fe2a494":"df3 = df_train[df_train[\"label\"] == \"3\"]\nfiles = df3[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()\n","fa5334cb":"data = pd.read_csv(work_dir + 'train.csv')\ndata.head()","773b1ea4":"# Importing the json file with labels\n\nf = open(work_dir + 'label_num_to_disease_map.json')\nreal_labels = json.load(f)\nreal_labels = {int(k):v for k,v in real_labels.items()}\n\ndata['class_name'] = data.label.map(real_labels)\n\nfrom sklearn.model_selection import train_test_split\n\ntrain,val = train_test_split(data, test_size = 0.2, random_state = 2, stratify = data['class_name'])\n\nIMG_SIZE = 380\nsize = (IMG_SIZE,IMG_SIZE)\nn_CLASS = 5\n\ndatagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n                    rotation_range = 40,\n                    width_shift_range = 0.2,\n                    height_shift_range = 0.2,\n                    shear_range = 0.2,\n                    zoom_range = 0.2,\n                    horizontal_flip = True,\n                    vertical_flip = True,\n                    fill_mode = 'nearest')\n\ntrain_set = datagen.flow_from_dataframe(train,directory = train_path,\n                         seed=42,\n                         x_col = 'image_id',\n                         y_col = 'class_name',\n                         target_size = size,\n                         #color_mode=\"rgb\",\n                         class_mode = 'categorical',\n                         interpolation = 'nearest',\n                         shuffle = True,\n                         batch_size = 20)\n\nval_set = datagen.flow_from_dataframe(val,directory = train_path,\n                         seed=42,\n                         x_col = 'image_id',\n                         y_col = 'class_name',\n                         target_size = size,\n                         #color_mode=\"rgb\",\n                         class_mode = 'categorical',\n                         interpolation = 'nearest',\n                         shuffle = True,\n                         batch_size = 20)\n\n\n","bd81cbef":"def create_model():\n  model = Sequential()\n  #use Batch Normalization for every conv and dense layers\n  model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu',input_shape = (IMG_SIZE, IMG_SIZE, 3)))\n  model.add(BatchNormalization())\n  \"\"\"\n  Batch normalization may be used on the inputs to the layer before or after the activation function in the previous layer. \n  It may be more appropriate after the activation function if for s-shaped functions like the hyperbolic tangent and logistic function.\n  \"\"\"\n  model.add(Dropout(0.25))\n  model.add(Conv2D(64, kernel_size= (3,3), activation='relu'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Conv2D(128, kernel_size= (3,3), activation='relu'))\n  model.add(BatchNormalization())\n  model.add(Dropout(0.25))\n  model.add(Conv2D(128, kernel_size= (3,3), activation='relu'))\n  model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Flatten())\n  model.add(Dense(64, activation='relu'))\n  model.add(BatchNormalization())\n  model.add(Dropout(0.33))\n  model.add(Dense(32, activation= 'relu'))\n  model.add(BatchNormalization())\n  model.add(Dense(n_CLASS, activation='softmax'))\n  # model.summary()\n  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n  return model\n","8c4bd115":"model = create_model()\nmodel.summary()\n","f0073d12":"keras.utils.plot_model(model)\n","e8797371":"model = model\nfilepath = \"weights_best.h5\"\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n    \n    \nhistory = model.fit_generator(\n           train_set,\n           steps_per_epoch=train_set.n\/\/train_set.batch_size,\n           epochs=20,\n           validation_data=val_set,\n           validation_steps=val_set.n\/\/val_set.batch_size,  callbacks=callbacks_list)","8ce45a9e":"# Plot results\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'g', label='Training accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'g', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n","a740a071":"TEST_DIR = '..\/input\/cassava-leaf-disease-classification\/test_images\/'\n","545ff8ac":"test_images = os.listdir(TEST_DIR)\npredictions = []\n\nfor image in test_images:\n    img = Image.open(TEST_DIR + image)\n    img = img.resize(size)\n    img = np.expand_dims(img, axis=0)\n    predictions.extend(model.predict(img).argmax(axis = 1))\n","18ffaa45":"predictions\n","6d3f0544":"\n# Creating the CSV for final submission\n\nsub = pd.DataFrame({'image_id': test_images, 'label': predictions})\ndisplay(sub)\nsub.to_csv('submission.csv', index = False)\n","8cfa810d":"#  **1: Cassava Brown Streak Disease**","61de80ee":"# **2: Cassava Green Mottle**","e61748e9":"# **3: Cassava Mosiac Disease**","f4e7f794":"# **0: Cassava Bacterial Blight**","c6df49be":"# **4: Healthy**"}}