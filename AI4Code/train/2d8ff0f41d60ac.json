{"cell_type":{"8232fc2f":"code","874b57d8":"code","98129af1":"code","4f46ecc6":"code","de022a41":"code","cc1357e4":"code","beeeaa56":"code","c1a989f8":"code","61af841b":"code","84159816":"code","ebc00571":"code","a3ea2814":"code","412e077f":"code","f8f5c462":"code","ba93c7af":"code","5e9ded88":"code","4172d541":"code","678c590d":"code","444af64e":"code","92ce665f":"code","6fe2a19f":"code","0d551440":"code","2eb791e1":"code","4a63fd3d":"code","ba5f4f3d":"code","fa66f11f":"code","66fc7667":"code","65f0c30e":"code","98d90855":"code","487572ca":"code","e7219d46":"code","44544211":"code","755b44ee":"code","1d3f2233":"code","85332e3d":"code","87a4eb4c":"code","f755beca":"code","741890bb":"code","c5dd5a36":"code","de1d37a0":"code","fbc2b917":"code","440b7279":"code","fcab8ada":"code","de7fbd7d":"code","26f67403":"code","b3d09cb9":"code","bad6684c":"code","e50fbe79":"code","27e22f1c":"code","6d07cdfb":"code","eca5b75b":"code","0e905f47":"code","8a3fa3cb":"code","9956a9d1":"code","73d5a21b":"markdown","c91cd64b":"markdown","ea65071e":"markdown","527d9a18":"markdown","34aed82b":"markdown","e9882041":"markdown","5965926b":"markdown","95469763":"markdown","c3e23931":"markdown","db4bbf9e":"markdown","cc042325":"markdown","24b9b474":"markdown","9c7a8990":"markdown","573e07c9":"markdown","2dc70579":"markdown","a8a8eae5":"markdown","82f5d3f1":"markdown","78ba59f5":"markdown","4116e033":"markdown","0979a9fc":"markdown","b57f6654":"markdown","8f1642bc":"markdown","ae68d5c2":"markdown","4fe8f7c2":"markdown","71e66d0c":"markdown","ac542ff7":"markdown","4ffa3a0c":"markdown","9d4bb14f":"markdown","375ad7a3":"markdown","b459d1ad":"markdown","584367d6":"markdown","2b957449":"markdown","0fb1715b":"markdown","3ccb0827":"markdown"},"source":{"8232fc2f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport seaborn as sns\nimport warnings \nimport string\nimport re\nimport itertools\nfrom bs4 import BeautifulSoup\nfrom collections import Counter\nfrom wordcloud import WordCloud\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n## Modelling :\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,auc,roc_curve,confusion_matrix,make_scorer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nimport nltk\nfrom nltk.corpus import stopwords\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n#nltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\n","874b57d8":"### Read the dataset:\nKaggle=1\nif Kaggle==0:\n    review=pd.read_csv(\"Reviews.csv\",parse_dates=[\"Time\"])\nelse:\n    review=pd.read_csv(\"..\/input\/Reviews.csv\",parse_dates=[\"Time\"])","98129af1":"review.head()","4f46ecc6":"review.describe()","de022a41":"print(\"There are {} unique product IDs and there are {} uniques users who have submitted their reviews.\".format(review['ProductId'].nunique(),review['UserId'].nunique()))","cc1357e4":"plt.figure(figsize=(8,8))\nax=sns.countplot(review['Score'],color='skyblue')\nax.set_xlabel(\"Score\")\nax.set_ylabel('Count')\nax.set_title(\"Distribution of Review Score\")","beeeaa56":"## Borrowed from https:\/\/www.kaggle.com\/neilash\/team-ndl-algorithms-and-illnesses\n\nplt.scatter(review.Score, review.HelpfulnessDenominator, c=review.Score.values, cmap='tab10')\nplt.title('Useful Count vs Rating')\nplt.xlabel('Rating')\nplt.ylabel('Useful Count')\nplt.xticks([i for i in range(1,6)]);","c1a989f8":"### Borrowed from https:\/\/www.kaggle.com\/neilash\/team-ndl-algorithms-and-illnesses\n\n# Create a list (cast into an array) containing the average usefulness for given ratings\nuse_ls = []\n\nfor i in range(1, 6):\n    use_ls.append([i, np.sum(review[review.Score == i].HelpfulnessDenominator) \/ np.sum([review.Score == i])])\n    \nuse_arr = np.asarray(use_ls)","61af841b":"plt.scatter(use_arr[:, 0], use_arr[:, 1], c=use_arr[:, 0], cmap='tab10', s=200)\nplt.title('Average Useful Count vs Rating')\nplt.xlabel('Rating')\nplt.ylabel('Average Useful Count')\nplt.xticks([i for i in range(1, 6)]);","84159816":"useful_rating=review.sort_values('HelpfulnessDenominator',ascending=False)\n","ebc00571":"# Print most helpful reviews:\nfor i in useful_rating.Text.iloc[:3]:\n    print(i,'\\n')","a3ea2814":"## Print least helpful reviews :\nfor i in useful_rating.Text.iloc[-3:]:\n    print(i,'\\n')","412e077f":"useful=review.groupby('ProfileName')['HelpfulnessDenominator'].mean().reset_index().sort_values('HelpfulnessDenominator',ascending=False)","f8f5c462":"useful.head()","ba93c7af":"plt.figure(figsize=(8,8))\nax=sns.barplot(x='ProfileName',y='HelpfulnessDenominator',data=useful[:5],palette=sns.color_palette(palette=\"viridis_r\"))\nax.set_title(\"Average Usefulness Rating by Profile-Top 5 Users\")\nax.set_xlabel(\"Profile Name\")\nax.set_ylabel(\"Average People\")\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)","5e9ded88":"scores=review.groupby('ProfileName')['Score'].mean().reset_index().sort_values(by='Score',ascending=False)\nscores.head()","4172d541":"plt.figure(figsize=(8,8))\nax=sns.barplot(x='ProfileName',y='Score',data=scores[:10],palette=sns.color_palette(palette=\"viridis_r\"))\nax.set_title(\"Users with most positive scores-Top 10 Users\")\nax.set_xlabel(\"Profile Name\")\nax.set_ylabel(\"Average Score\")\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)","678c590d":"review['review_length']=review['Text'].str.len()","444af64e":"length=review.groupby('ProfileName')['review_length'].mean().reset_index().sort_values(by='review_length',ascending=False)\nlength.head()","92ce665f":"plt.figure(figsize=(8,8))\nax=sns.barplot(x='ProfileName',y='review_length',data=length[:10],palette=sns.color_palette(palette=\"viridis_r\"))\nax.set_title(\"Average Length of the review-Top 10 Users\")\nax.set_xlabel(\"Profile Name\")\nax.set_ylabel(\"Average Length\")\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)","6fe2a19f":"review_sample=review.sample(10000)","0d551440":"y=review_sample['Score']\nx=review_sample['Text']\nX_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=100,stratify=y)","2eb791e1":"print('Dimensions of train:{}'.format(X_train.shape),'\\n','Dimensions of test:{}'.format(X_test.shape))","4a63fd3d":"y_train.value_counts()","ba5f4f3d":"y_test.value_counts()","fa66f11f":"y_train.describe()","66fc7667":"### Some preprocessing exercise in train dataset: - Inspired  from https:\/\/www.kaggle.com\/c\/word2vec-nlp-tutorial#part-1-for-beginners-bag-of-words\ndef review_to_words(raw_review):\n    # Function to convert a raw review to a string of words\n    # The input is a single string (a raw review), and \n    # the output is a single string (a preprocessed review)\n    #\n    # 1. Remove HTML\n    review_text = BeautifulSoup(raw_review).get_text() \n    #\n    # 2. Remove non-letters        \n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n    #\n    # 3. Convert to lower case, split into individual words\n    text_words = letters_only.lower()                          \n    #              \n    # \n    #4.Remove stopwords and Tokenize the text\n    tokens = nltk.word_tokenize(text_words)\n    tokens_text = [word for word in tokens if word not in set(nltk.corpus.stopwords.words('english'))]\n    #\n    #5.Lemmantize using wordnetLemmantiser:\n    lemmantizer=WordNetLemmatizer()\n    lemma_text = [lemmantizer.lemmatize(tokens) for tokens in tokens_text]\n    #\n    # 6. Join the words back into one string separated by space, \n    # and return the result.\n    return( \" \".join( lemma_text ))   ","65f0c30e":"# Get the number of reviews based on the dataframe column size\n\n\n# Initialize an empty list to hold the clean reviews\nX_train_clean = []\n\n# Loop over each review; create an index i that goes from 0 to the length\n# of the movie review list \nfor text in tqdm(X_train):\n    # Call our function for each one, and add the result to the list of\n    # clean reviewsb\n    X_train_clean.append(review_to_words(text))","98d90855":"#https:\/\/www.kaggle.com\/nilanml\/imdb-review-deep-model-94-89-accuracy\n##Creating bag of words model :\n\nvectorizer=CountVectorizer(ngram_range=(1,1)) \ntrain_feature=vectorizer.fit_transform(X_train_clean)\n\ntfidf_transformer=TfidfVectorizer(ngram_range=(1,1))\ntrain_feature_tfidf=tfidf_transformer.fit_transform(X_train_clean)","487572ca":"# Get the number of reviews based on the dataframe column size\n\n\n# Initialize an empty list to hold the clean reviews\nX_test_clean = []\n\n# Loop over each review; create an index i that goes from 0 to the length\n# of the movie review list \nfor text in tqdm(X_test):\n    # Call our function for each one, and add the result to the list of\n    # clean reviews\n    X_test_clean.append(review_to_words(text))","e7219d46":"test_feature=vectorizer.transform(X_test_clean)\ntest_feature_tfidf=tfidf_transformer.transform(X_test_clean)","44544211":"prediction=dict()","755b44ee":"nb=MultinomialNB()\nnb.fit(train_feature, y_train)","1d3f2233":"prediction['Naive']=nb.predict(test_feature)","85332e3d":"print(accuracy_score(y_test,prediction['Naive']))","87a4eb4c":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","f755beca":"class_names = set(review['Score'])\ncnf_matrix = confusion_matrix(y_test, prediction['Naive'])\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, Naive Bayes Model')\n","741890bb":"nb.fit(train_feature_tfidf,y_train)\nprediction['Naive_TFIDF']=nb.predict(test_feature_tfidf)","c5dd5a36":"print(accuracy_score(y_test,prediction['Naive_TFIDF']))","de1d37a0":"lr=LogisticRegression()","fbc2b917":"lr.fit(train_feature,y_train)","440b7279":"prediction['Logit']=lr.predict(test_feature)","fcab8ada":"print(accuracy_score(y_test,prediction['Logit']))","de7fbd7d":"lr.fit(train_feature_tfidf,y_train)","26f67403":"prediction['Logit_TFIDF']=lr.predict(test_feature_tfidf)","b3d09cb9":"print(accuracy_score(y_test,prediction['Logit_TFIDF']))","bad6684c":"sm=SMOTE(random_state=100)","e50fbe79":"X_sm,y_sm=sm.fit_sample(train_feature_tfidf,y_train)","27e22f1c":"Counter(y_sm)","6d07cdfb":"scorer=make_scorer(accuracy_score)","eca5b75b":"# parameter grid\nnaive=MultinomialNB()\nparam_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n\n# Initialize Grid Search Model\nmodel = GridSearchCV(estimator=naive, param_grid=param_grid, scoring=scorer,\n                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=5)\n","0e905f47":"# Fit Grid Search Model\nmodel.fit(X_sm, y_sm)  # Using the TF-IDF model for training .\nprint(\"Best score: %0.3f\" % model.best_score_)\nprint(\"Best parameters set:\")\nbest_parameters = model.best_estimator_.get_params()\nfor param_name in sorted(param_grid.keys()):\n    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))","8a3fa3cb":"prediction['Naive_SMOTE']=model.predict(test_feature_tfidf)","9956a9d1":"class_names = set(review['Score'])\ncnf_matrix = confusion_matrix(y_test, prediction['Naive_SMOTE'])\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, Naive Bayes Model(After SMOTE and Grid Search)')\n","73d5a21b":"### Logistic Regression Model","c91cd64b":"The number of reviews for rating 5 is on the higher side compared to other scores . Lets check if the rating is correlated with the helpfulness .","ea65071e":"We have our scores for each of the reviews along with the review text.A model can be developed to predict the scores given the review . We first split the data to train and test .(80-20 ratio) .Considering huge size of the dataset , we sample 2L of the dataset and model the data.","527d9a18":"Lets check out who has consistently provided most positive scores .","34aed82b":"The explanations for the variables are as follows:\n\n* IdRow - Unique Identifier for rows\n* ProductId - Unique identifier for the product\n* UserId - Unqiue identifier for the user\n* ProfileName - Profile name of the user\n* HelpfulnessNumerator - Number of users who found the review helpful\n* HelpfulnessDenominator - Number of users who indicated whether they found the review helpful or not\n* Score - Rating between 1 and 5\n* Time - Timestamp for the review\n* Summary - Brief summary of the review\n* Text - Text of the review","e9882041":"### Grid Search:","5965926b":"### Overview of the dataset","95469763":"It is interesting to note that there are many users who found review score 1 more helpful . I think that such reviews might have helped them to avoid a particular food.Lets check few samples of such reviews.","c3e23931":"### Naive Bayes Model","db4bbf9e":"**Work in progress**","cc042325":"Clearly , the most helpful reviews is on the negative side which the reviewers have provided whereas the least helpful is on the neutal side -atleast from the samples part.","24b9b474":"On an average 923 people have found BabbChuck \"BabbChuck\" review helpful and 878 people have found reviews by P. Schmidt review's helpful.","9c7a8990":"For modelling we use both Countvectorizer and TF-IDF models and compare the accuracy between the two.","573e07c9":"The accuracy of the model has not improved.Infact,it has decreased.","2dc70579":"### Some EDA :","a8a8eae5":"Lets check the rating distribution . ","82f5d3f1":"The plot tells us that on an average most of the users have left positive reviews in the blog . \n\nLets see who has written most lengthy reviews on an average.","78ba59f5":"Thus by using SMOTE and cross validation we have improved the accuracy to 93 %.But since this is an imbalanced dataset , it will be wise to use metrics like confusion matrix,f1-score,precision-recall instead of accuracy score since this will be misleading. Lets apply the model to the test dataset and check the confusion matrix.","4116e033":"The model has been trained on an imbalanced data .Therefore lets apply oversampling methods to the dataset and retrain the model for improving the score . Also ,Lets try to improve the model with grid search.Lets create a scoring criteria first .We define accuracy score as the metric.","0979a9fc":"From the summary statistics, we see that on an average 2 people found the review helpful and the average rating of the food has been 4.18.","b57f6654":"### Reading the dataset","8f1642bc":"We see that the scores are skewed towards the high scores therefore we can see its an imbalanced dataset.","ae68d5c2":"# Amazon Fine Foods Review - An EDA and Modelling ","4fe8f7c2":"### Text Classification:","71e66d0c":"The accuracy of the model is 66 % .Lets plot the confusion matrix.","ac542ff7":"Thus by using SMOTE we have oversampled the dataset to match the scores with the top score.","4ffa3a0c":"From the confusion matrix it is seen that reviews having scores 1,2,3,4 are also predicted as 5 . This means that the model is not good enough to differentiate between the scores with the review words.","9d4bb14f":"Thus we have remove the HTML tags using BeautifulSoup , removed the punctuations , converted the text to lower case ,tokenized the text and used wordnet Lemmatizer after which the review text looks clean .Lets apply them all over the train data .","375ad7a3":"Lets check top 5 persons whose reviews people have found most reviews.","b459d1ad":"The dataset provided to us presents the review listing of fine foods from Amazon from Oct 1999 to Oct 2012 (13 Years) . From the overview of the dataset we understand that  there are 568,454 reviews given by 256,059 users on 74,258 products with 260 users given more than  50 reviews.The dataset presents a great opportunity to explore in various dimensions like - users who always provide positive reviews , negative reviews , topic modelling , sentiment analysis etc . This kernel is an attempt in those lines .","584367d6":"Both the accuracy of the model with logistic is around 67 % .","2b957449":"### Import necessary libraries ","0fb1715b":"Lets initiate a grid search with 5 fold cross validation.","3ccb0827":"Lets check the prediction with TF-IDF model."}}