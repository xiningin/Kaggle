{"cell_type":{"1c8ac5c8":"code","c53e4ca9":"code","fd189647":"code","97b4b31c":"code","6be7f075":"code","0814d000":"code","2ee0a2d3":"code","07bad2c6":"code","bc156cf6":"code","38942923":"code","f6d466cd":"code","734fb202":"code","ee58be98":"code","1645c8ce":"code","f286dddd":"code","81570b89":"code","bb942efd":"code","d21428e4":"code","723d7f0d":"code","2e5e676f":"code","8aee065d":"code","ec150425":"code","2dcbe331":"code","b8df5281":"code","cfb35692":"code","0ffb3105":"code","6f9bf4f0":"code","4605915b":"code","0acedc8c":"code","270616c2":"code","b6bb10f6":"code","0d4ab5f8":"code","fc909173":"code","5bcfa7b9":"code","1ba70038":"code","5f8223ff":"code","4eb66aff":"code","8dbe08f1":"code","d4fcbee2":"code","a4fb7e30":"code","f0f27433":"code","207ba9cf":"code","46f9d9d8":"code","6c7551b3":"code","978a7bae":"code","d8530bb1":"code","93e4e1e4":"code","996a533b":"code","b77889fb":"code","884944f3":"code","e210aba5":"code","7699c86e":"markdown","be51a303":"markdown","85981f75":"markdown","53e2b1ff":"markdown","32871127":"markdown","36b55d83":"markdown","4ff44c37":"markdown","d561802b":"markdown","8cd9caee":"markdown","f9013266":"markdown","d1b86955":"markdown","cc1de4bf":"markdown","b4c2f122":"markdown","f041435b":"markdown","9fcb2984":"markdown","654e597d":"markdown","0bc19438":"markdown","fb330465":"markdown","7d3355e6":"markdown","61608e5a":"markdown","d059db21":"markdown","3e7e31f8":"markdown","0a6d0a0f":"markdown"},"source":{"1c8ac5c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c53e4ca9":"pip install lucifer-ml","fd189647":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nplt.style.use('dark_background')\nimport plotly.express as px\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_roc_curve\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nfrom tqdm import tqdm_notebook\n\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')","97b4b31c":"from luciferml.preprocessing import Preprocess as prep","6be7f075":"data = pd.read_csv('\/kaggle\/input\/water-potability\/water_potability.csv')","0814d000":"data.head()","2ee0a2d3":"data.info()","07bad2c6":"data.describe()","bc156cf6":"data.shape","38942923":"data.isnull().sum()","f6d466cd":"data = data.dropna()","734fb202":"data.isnull().sum()","ee58be98":"data.shape","1645c8ce":"plt.figure(figsize=(10,6)) #setting the figure size\nsns.countplot(data['Potability'], palette='rocket') # checking the class count of potable water\nplt.title('Potability count', weight='bold')\nplt.tight_layout()","f286dddd":"non_potable = data[data['Potability']==0]\npercent_non_potable = len(non_potable)\/ len(data)\nprint('The percentage of non potable water is: {}%'.format(round(percent_non_potable * 100,4)))","81570b89":"def Pie_chart(data, column_name):\n    \n    '''\n    Function to create a pie chart;\n        data: takes the data as input.\n        column_name: takes the column name as input.\n    '''\n    \n    values = data[column_name].value_counts() # taking the values of a particular columns\n    labels = data[column_name].unique() # taking the unique data\n    pie, ax = plt.subplots(figsize = (12,6))\n    \n    patches, text, autotext = ax.pie(values, labels = labels, shadow = True, autopct = '%1.2f%%', pctdistance = 0.5, explode = [0.06]*data[column_name].unique())\n    \n    plt.title(column_name, color='white') #title of the chart\n    plt.legend(patches, labels, loc='best') # display the legend\n    plt.setp(text, color='black') # text color\n    plt.axis('equal')\n    plt.setp(autotext, color='black')# text color\n    autotext[0].set_color('black')\n    autotext[1].set_color('red')\n    plt.tight_layout()\n    plt.show()\n    \nPie_chart(data, 'Potability') # function calling","bb942efd":"data_2 = data[['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity',\n       'Organic_carbon', 'Trihalomethanes', 'Turbidity']]","d21428e4":"data_2.shape","723d7f0d":"def find_distributions(data):\n    '''This is a function to find the distributions of each data columns;\n        data : takes data as input.\n    '''\n    \n    features = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity',\n       'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n    \n    plt.figure(figsize=(16,16))\n    for i in tqdm_notebook(range(len(data.columns)), desc = 'Wait, the graph is fetching'):\n        plt.subplot(3,3,i+1)\n        sns.distplot(data[data.columns[i]], color='lightcoral', rug=True)\n        plt.title(data.columns[i], weight='bold')\n        plt.tight_layout()\n        \nfind_distributions(data_2)","2e5e676f":"def finding_overall_view(data):\n    '''Function to create an overview of a whole datset;\n        data: takes data as a input variable\n    '''\n    \n    sns.pairplot(data, hue='Potability', palette='OrRd')\n    plt.tight_layout()\n    \nfinding_overall_view(data)","8aee065d":"data.hist(bins=20, color = 'blue', figsize=(16,16))\nplt.tight_layout()","ec150425":"data.columns","2dcbe331":"def attributes_and_potability(data):\n    '''\n    Function to find the relationship between attributes and potability;\n        data: takes data as input for the operation\n    '''\n    features = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity',\n       'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n    for var in tqdm_notebook(features, desc = 'The graph is fetching'):\n        plt.figure(figsize=(16,10))\n        sns.histplot(data = data, x = data[var], hue ='Potability') # histogram\n        plt.title(var) # title of the plot\n        \nattributes_and_potability(data)","b8df5281":"plt.figure(figsize=(16,12))\nmatrix = np.triu(data.corr()) # matrix to return k -th diagonal zeroed values.\nsns.heatmap(data.corr(), annot=True, mask=matrix, cmap='OrRd') # creating correlational map\nplt.title('Correlational Map', weight='bold');","cfb35692":"def correct_skewness(data):\n    \n    '''\n        Function to correct the data skewness;\n            data: takes data as input.\n                (Funtion takes data for the operation and uses except column to exclude that particular colum\n                from the datset.)\n    '''\n    data_set = prep.skewcorrect(data, except_columns=['Potability'])\n    return data_set\n\ndata_set = correct_skewness(data) # function calling","0ffb3105":"data_set.head()","6f9bf4f0":"X = data_set.iloc[:,:-1].values\ny = data_set.iloc[:,-1].values\n\nX.shape, y.shape","4605915b":"scaler = StandardScaler()\nX = scaler.fit_transform(X)\nX","0acedc8c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) # data splitting 80-20% to avoid over fitting","270616c2":"X_train, y_train = shuffle(X_train, y_train) # data shuffling","b6bb10f6":"X_train.shape, X_test.shape","0d4ab5f8":"y_train.shape, y_test.shape","fc909173":"# pipelines\n\npipeline = make_pipeline(RobustScaler()) # creating a pipeline for all the models\nRandom_forest = make_pipeline(pipeline, RandomForestClassifier(random_state=0, min_samples_leaf = 2, n_estimators = 1000))\nDecision_tree = make_pipeline(pipeline, DecisionTreeClassifier(random_state=0))\nLogistic_regression = make_pipeline(pipeline, LogisticRegression(random_state=0))\nsvc = make_pipeline(pipeline, SVC(random_state=0))\nKNeighbors = make_pipeline(pipeline, KNeighborsClassifier())\nAda_boost = make_pipeline(pipeline, AdaBoostClassifier(random_state=0))\nxgboost = make_pipeline(pipeline, XGBClassifier())\ngradientboost = make_pipeline(pipeline, GradientBoostingClassifier(random_state=0))","5bcfa7b9":"param_dist = {\n    'RandomForest':Random_forest,\n    'DecisionTree':Decision_tree,\n    'LogisticRegression':Logistic_regression,\n    'svc':svc,\n    'KNeighbors':KNeighbors,\n    'AdaBoost':Ada_boost,\n    'XGB':xgboost,\n    'GD':gradientboost\n}","1ba70038":"def MODEL(model):\n    \n    '''\n    The function to create a model with accuracy score and confusion matrix;\n        model: Takes different model alogirthm as an input for the operation.\n    '''\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print('The accuracy score of the model is: {}%'.format(accuracy_score(y_test, y_pred)))\n    print('-'*50)\n    print(confusion_matrix(y_test, y_pred))\n    print(classification_report(y_test, y_pred))","5f8223ff":"def model_evaluation(parameter_dictionary):\n    \n    '''\n        Function to find the model accuracy score, classification report;\n            parameter_dictionary: takes as an input, which is a dictionary containing the pipeline for the\n                                  individual model.\n    '''\n    \n    for name, model in parameter_dictionary.items():\n        print('-'*50)\n        print(name)\n        evaluation = MODEL(model)\n    return evaluation\nevaluation = model_evaluation(param_dist)","4eb66aff":"# Model Architecture\n\nmodel = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\nmodel.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Dense(units = 252, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(units = 516, activation = 'relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\n\n# output layer\nmodel.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid')) #output for potable or non potable","8dbe08f1":"model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])","d4fcbee2":"M = model.fit(X_train, y_train, batch_size=12, epochs=100, verbose=1)","a4fb7e30":"model_evaluation = model.evaluate(X_test, y_test)","f0f27433":"plt.plot(M.history['accuracy'], 'bo-', label = 'accuracy')\nplt.title('Model Traning Accuracy', weight='bold')\nplt.legend();","207ba9cf":"plt.plot(M.history['loss'], label = 'loss', color='red')\nplt.title('Model Traning Loss', weight='bold')\nplt.legend();","46f9d9d8":"ann_pred = model.predict(X_test)\nann_pred = (ann_pred > 0.5)","6c7551b3":"accuracy_score(y_test, ann_pred)","978a7bae":"print(classification_report(y_test, ann_pred))","d8530bb1":"accuracy_score_model = {\n    'RandomForest':71.9,\n    'DecisionTree':61.6,\n    'LogisticRegression':63,\n    'svc':73.6,\n    'KNeighbors':65,\n    'AdaBoost':60,\n    'XGB':66,\n    'GD':68,\n    'ANN':70\n}","93e4e1e4":"def models_overview(accuracy_score_model):\n    \n    '''\n        Function to analys the models highest performence;\n            accuracy_score_model: takes as an input for the operation.\n    '''\n    \n    \n    model_accuracy = list(accuracy_score_model.values())\n    model_name = list(accuracy_score_model.keys())\n\n    g = sns.barplot(x = model_accuracy, y = model_name,palette='OrRd')\n    plt.title('Models Overview', weight='bold');\n    return g\n    \nover_view = models_overview(accuracy_score_model)","996a533b":"svc = SVC(random_state=0)\nsvc.fit(X_train, y_train)","b77889fb":"y_pred = svc.predict(X_test)","884944f3":"def pop(y_test, y_pred, X_test, svc):\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True)\n    plot_roc_curve(svc, X_test, y_test)\n    print(classification_report(y_test, y_pred))\n    \npop(y_test, y_pred, X_test, svc)","e210aba5":"print('The accuracy score of the model is: {}% '.format(round(accuracy_score(y_test, y_pred)*100, 2)))","7699c86e":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Data Visualization<\/h1>\n\n\n<\/div>\n","be51a303":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:white;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Summary<\/h1>\n    <h3 style=\"text-align:center;font-weight: bold;\">In this case, Support Vector Performed Best.<\/h3>\n    \n\n<\/div>","85981f75":"\n\nDropping all the missing values.","53e2b1ff":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Data Preprocessing<\/h1>\n\n\n<\/div>\n","32871127":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#f1f1f6;\n           color:black;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h3 style=\"text-align:left;font-weight: bold;\">If you like my work, please Upvote!!! <\/h3>\n    \n    \n\n<\/div>","36b55d83":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:white;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Inference<\/h1>\n    <p style=\"text-align:center;font-weight: bold;\">1. Support Vector Machine shows better accuracy of 73%.<\/p>\n    <p style=\"text-align:center;font-weight: bold;\">2.The recall value for '0' is 0.93 which is great.<\/p>    \n    <p style=\"text-align:center;font-weight: bold;\">3. The recall value for '1' is 0.41 which is far better than other algorithms.<\/p>\n    <p style=\"text-align:center;font-weight: bold;\">4. precision and recall holds a top priority while selecting the best model.<\/p>\n\n    \n   \n<\/div>","4ff44c37":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:110%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">What is Potable Water?<\/h1>\n    <h3 style=\"text-align:center;font-weight: bold\">Potable water, also known as drinking water, comes from surface and ground sources and is treated to levels that meet state and federal standards for consumption.<\/h3>\n\n\n<\/div>\n\n\n\n\n","d561802b":"## **Let's create Artifical Neural Network model. Let's see whether this model can bring better accuracy scores with greater recall and precision.**","8cd9caee":"Inference;\n* Only 40% of the water is potable.\n* More than half of water is non potable (60%).","f9013266":"**Look at the columns 'ph','sulfate',and 'Trihalomethanes' from the above dataset. All of these contains missing values.**\n* Which, if either, the missing values don't exist?\n* Which, if either, the missing values weren't recorded?","d1b86955":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:'White';\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Selecting the best Model<\/h1>\n\n\n<\/div>","cc1de4bf":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Finding Correlation<\/h1>\n\n\n<\/div>\n","b4c2f122":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Importing Dataset.<\/h1>\n\n\n<\/div>\n","f041435b":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Exploratory Data Analysis<\/h1>\n\n\n<\/div>\n","9fcb2984":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> Model Building<\/h1>\n\n\n<\/div>","654e597d":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Water\ud83d\udca7\ud83d\udca6\ud83d\udca7 Potability Prediction.<\/h1>\n\n\n<\/div>\n","0bc19438":"**Yayyyyy!!! No Null values**","fb330465":"**The plot look's like a corona virus structure!!!!!! isn't it? haha!!!**","7d3355e6":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Importing Libraries.<\/h1>\n\n\n<\/div>\n","61608e5a":"   ![](https:\/\/media.giphy.com\/media\/LI6TgnchmtJ60\/giphy.gif)\n   [Source](https:\/\/media.giphy.com\/media\/LI6TgnchmtJ60\/giphy.gif)","d059db21":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:110%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:White;\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Do you know?\ud83e\udd14<\/h1>\n    <h3 style=\"text-align:center;font-weight: bold\">The average person drinks 8 cups per day, equaling to 1\/2 gallon per day and 182.5 gallons per year.<\/h3>\n\n\n<\/div>\n\n\n\n\n","3e7e31f8":"### Inference;\n* The data shows very less correlation between all the features.\n* Certain column seems to be skewed, let's correct the skewed columns.\n","0a6d0a0f":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           font-size:120%;\n           font-family:cursive;\n           letter-spacing:0.5px;\n           background-color:#ff0412;\n           color:'White';\n           font-family:cursive;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\"> ANN  Model<\/h1>\n\n\n<\/div>"}}