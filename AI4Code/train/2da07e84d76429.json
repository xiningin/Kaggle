{"cell_type":{"bed178a6":"code","656d97d4":"code","702ddde3":"code","6d7783c9":"code","0c5aa1cd":"code","c0b4e1ea":"code","a88eb8ec":"code","c6ad1c31":"code","342d784c":"code","a34a3e51":"code","0ea89e8f":"code","8e261a92":"code","c4b8dbf7":"code","fbc788c4":"code","7aa54e93":"code","ae9c29ff":"code","0fe8e6a0":"code","b48e8e63":"code","2e6b10d9":"code","44071f97":"code","1940cc67":"code","0bc235b8":"code","75ae4a7a":"code","07241db8":"code","69d4e7d4":"code","887b2bf4":"code","7df40176":"code","8aaff5d2":"code","abad2b63":"code","1f784069":"code","bdd0792d":"code","1dceb867":"code","a68e24f0":"code","83e6ae6d":"code","a290af08":"code","66d53129":"code","3295367c":"code","cb31d05c":"code","f3c51d52":"code","308b454c":"code","ea848e4c":"code","aa676e22":"code","b7049154":"code","c9049bf2":"code","9a1efc76":"code","dc4a2f4b":"code","a1a798be":"code","ee3917df":"code","bc033838":"code","7b20bd46":"code","1691d74e":"code","02ca2084":"code","753782b5":"code","fa7d3113":"code","b3b8443b":"code","59c88da9":"code","390d317c":"markdown","3457d6f0":"markdown","557e7ccb":"markdown","85dee190":"markdown","db4c3d8a":"markdown","00375788":"markdown","0c7ec0c1":"markdown","5cb1187f":"markdown","3033458a":"markdown","2afd5099":"markdown","1607d2b8":"markdown","7230f9dc":"markdown","68dc39c3":"markdown","512c49d5":"markdown","8783a65d":"markdown","2db490d8":"markdown","3e236d93":"markdown","e1e211be":"markdown","b6ed7f39":"markdown","f3d6bbe4":"markdown","bc9ccffd":"markdown","90925c5f":"markdown","0d7c96e4":"markdown","7c5581b5":"markdown","ba4bb4e4":"markdown","acbd9b0b":"markdown","eaed24f3":"markdown","caf9ae66":"markdown","763e5267":"markdown","3b9002d1":"markdown","9559724d":"markdown","82222414":"markdown","69712444":"markdown","a2e7cd4b":"markdown","c80cd357":"markdown","02022c6f":"markdown","ee0fd153":"markdown","8e91fbe1":"markdown","6ba9d06e":"markdown","639a67d5":"markdown","b6df83bd":"markdown"},"source":{"bed178a6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport scipy as sp\nimport warnings\nimport datetime\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n","656d97d4":"data=pd.read_csv('\/kaggle\/input\/hotel-booking-demand\/hotel_bookings.csv')\n\n","702ddde3":"data.head()","6d7783c9":"data.describe()      #description of dataset ","0c5aa1cd":"data.info()\n","c0b4e1ea":"data.shape   #119390 rows and 32 columns","a88eb8ec":"data.value_counts()\n","c6ad1c31":"data.columns","342d784c":"data.dtypes","a34a3e51":"data.isnull().sum()","0ea89e8f":"data.isnull().any()","8e261a92":"data.isnull().all()","c4b8dbf7":"data.hist(figsize=(20,14))\nplt.show()\n\n","fbc788c4":"sns.boxplot(x='children',y='company',data=data)","7aa54e93":"sns.stripplot(x='company',y='hotel',data=data)","ae9c29ff":"sns.jointplot(x='arrival_date_week_number', y= 'company', data=data)\n","0fe8e6a0":"sns.relplot(x='company',y='agent',data=data)","b48e8e63":"sns.lineplot(x='company',y='agent',data=data)","2e6b10d9":"sns.regplot(x='company',y='agent',data=data)","44071f97":"sns.catplot(x='company',y='hotel',data=data)","1940cc67":"sns.scatterplot(x='company',y='agent',data=data)\n","0bc235b8":"plt.style.use(\"default\")\nsns.kdeplot(x='company',y='agent',data=data)","75ae4a7a":"sns.violinplot(x='company',y='hotel',data=data)","07241db8":"sns.lmplot(x='company',y='agent',data=data)","69d4e7d4":"sns.heatmap(data.corr(), annot = True, cmap = 'viridis')\n\n","887b2bf4":"data=data.drop(['country','agent','company'],axis=1)\n","7df40176":"data=data.dropna()\n","8aaff5d2":"data.isnull().sum()\n","abad2b63":"data['hotel'].unique()\n\n\n\n","1f784069":"data['deposit_type'].unique()","bdd0792d":"data['arrival_date_month'].unique()\n","1dceb867":"#lets find the categorialfeatures\nlist_1=list(data.columns)\n","a68e24f0":"list_cate=[]\nfor i in list_1:\n    if data[i].dtype=='object':\n        list_cate.append(i)\n","83e6ae6d":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\n","a290af08":"for i in list_cate:\n    data[i]=le.fit_transform(data[i])\n","66d53129":"data","3295367c":"\ny=data['hotel']\nx=data.drop('hotel',axis=1)\n\n\n\n\n","cb31d05c":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)\n","f3c51d52":"print(len(x_train))\nprint(len(x_test))\nprint(len(y_train))\nprint(len(y_test))","308b454c":"from sklearn.linear_model import LogisticRegression\nreg = LogisticRegression()\nreg.fit(x_train,y_train)                         \n","ea848e4c":"from sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.metrics import classification_report\ny_pred_reg=reg.predict(x_test)\nacc_reg = accuracy_score(y_test, y_pred_reg)\nprint(\"Classification Report is:\\n\",classification_report(y_test,y_pred_reg))\nprint(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred_reg))\nprint(\"Training Score:\\n\",reg.score(x_train,y_train)*100)\nprint(f\"Accuracy Score of Logistic Regression is : {acc_reg}\")\n\n\n","aa676e22":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\n\ny_pred_knn = knn.predict(x_test)\n\nacc_knn = accuracy_score(y_test, y_pred_knn)\nconf = confusion_matrix(y_test, y_pred_knn)\nclf_report = classification_report(y_test, y_pred_knn)\n\nprint(f\"Accuracy Score of KNN is : {acc_knn}\")\nprint(f\"Confusion Matrix : \\n{conf}\")\nprint(f\"Classification Report : \\n{clf_report}\")\n","b7049154":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(max_depth=6, random_state=123,criterion='entropy')\n\ndtree.fit(x_train,y_train)\n","c9049bf2":"y_pred=dtree.predict(x_test)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nscore","9a1efc76":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nrfc=RandomForestClassifier()\nrfc.fit(x_train,y_train)","dc4a2f4b":"y_pred=rfc.predict(x_test)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nscore\n","a1a798be":"from sklearn.ensemble import AdaBoostClassifier\nadb = AdaBoostClassifier(base_estimator = None)\nadb.fit(x_train,y_train)\n","ee3917df":"y_pred=adb.predict(x_test)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nscore","bc033838":"from sklearn.ensemble import GradientBoostingClassifier\ngbc=GradientBoostingClassifier()\ngbc.fit(x_train,y_train)\n","7b20bd46":"y_pred=gbc.predict(x_test)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nscore","1691d74e":"from xgboost import XGBClassifier\n\nxgb =XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)\n\nxgb.fit(x_train, y_train)\n","02ca2084":"y_pred=xgb.predict(x_test)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nscore","753782b5":"from sklearn.ensemble import ExtraTreesClassifier\netc = ExtraTreesClassifier(n_estimators=100, random_state=0)\netc.fit(x_train,y_train)\n","fa7d3113":"y_pred=etc.predict(x_test)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nscore","b3b8443b":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn import tree\nmodel = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\nmodel.fit(x_train, y_train)\nmodel.score(x_test,y_test)\n","59c88da9":"data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndata\n","390d317c":"![](https:\/\/hire.refactored.ai\/upload-nct\/portfolio_images\/137\/capture%20111.png)","3457d6f0":"**Decision trees use multiple algorithms to decide to split a node into two or more sub-nodes. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. ... The decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.**\n","557e7ccb":"**XGBoost is a popular and efficient open-source implementation of the gradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm, which attempts to accurately predict a target variable by combining the estimates of a set of simpler, weaker models.**\n","85dee190":"# LOADING THE DATASET","db4c3d8a":"**KDE PLOT (DENSITY PLOT)**\n\n**KDE Plot described as Kernel Density Estimate is used for visualizing the Probability Density of a continuous variable. It depicts the probability density at different values in a continuous variable. We can also plot a single graph for multiple samples which helps in more efficient data visualization.**","00375788":"# 9.Bagging Classifier","0c7ec0c1":"**REGPLOT**\n\n**This method is used to plot data and a linear regression model fit. ... If strings, these should correspond with column names in \u201cdata\u201d. When pandas objects are used, axes will be labeled with the series name. data: This is dataframe where each column is a variable and each row is an observation.**","5cb1187f":"**CATPLOT**\n\n**Catplot is a relatively new addition to Seaborn that simplifies plotting that involves categorical variables. In Seaborn version v0. 9.0 that came out in July 2018, changed the older factor plot to catplot to make it more consistent with terminology in pandas and in seaborn.**","3033458a":"**JOINTPLOT**\n\n**Seaborn's jointplot displays a relationship between 2 variables (bivariate) as well as 1D profiles (univariate) in the margins. This plot is a convenience class that wraps JointGrid.**\n\n","2afd5099":"**An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.**\n","1607d2b8":"**By default, the KNeighborsClassifier looks for the 5 nearest neighbors. We must explicitly tell the classifier to use Euclidean distance for determining the proximity between neighboring points.**","7230f9dc":"**LMPLOT**\n\n**Plot data and regression model fits across a FacetGrid. This function combines regplot() and FacetGrid . It is intended as a convenient interface to fit regression models across conditional subsets of a dataset. ... However, always think about your particular dataset and the goals of the visualization you are creating.**\n","68dc39c3":"# CONCLUSION : \n\n**So we get a accuracy score of 97 % using the Random Forest Classifier which is highest among all models** ","512c49d5":"# 2. KNeighborsClassifier","8783a65d":"**A random forest classifier. A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.**","2db490d8":"# TRAINING AND TESTING DATA","3e236d93":"***If you liked this notebook, please UPVOTE it.***","e1e211be":"# 6. Gradient Boosting Classifier","b6ed7f39":"**STRIPPLOT**\n\n**A strip plot is a graphical data anlysis technique for summarizing a univariate data set. ... The strip plot is an alternative to a histogram or a density plot. It is typically used for small data sets (histograms and density plots are typically preferred for larger data sets).**","f3d6bbe4":"# 3. DECISION TREE CLASSIFIER","bc9ccffd":"# Hotel Booking Demand -EDA AND PREDICTION","90925c5f":"# 7. XGBClassifier","0d7c96e4":"# 5. AdaBoostClassifier","7c5581b5":"**HISTOGRAM**","ba4bb4e4":"**Checking Null Values**\n\n","acbd9b0b":"**A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. ... The base estimator to fit on random subsets of the dataset.**\n","eaed24f3":"**Extremely Randomized Trees Classifier(Extra Trees Classifier) is a type of ensemble learning technique which aggregates the results of multiple de-correlated decision trees collected in a \u201cforest\u201d to output it's classification result.**","caf9ae66":"**Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).**\n","763e5267":" # 4.Random Forest Classifier\n","3b9002d1":"**SCATTER PLOT**\n\n**A scatter plot (aka scatter chart, scatter graph) uses dots to represent values for two different numeric variables. The position of each dot on the horizontal and vertical axis indicates values for an individual data point. Scatter plots are used to observe relationships between variables.**","9559724d":"# IMPORTING THE LIBRARIES","82222414":"**RELPLOT**\n\n**This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. ... relplot() combines a FacetGrid with one of two axes-level functions: scatterplot() (with kind=\"scatter\" ; the default)**\n","69712444":"**Gradient boosting classifiers are a group of machine learning algorithms that combine many weak learning models together to create a strong predictive model. Decision trees are usually used when doing gradient boosting.**\n","a2e7cd4b":"# MODELS\n\n# 1. Logistic Regression","c80cd357":"# Exploratory Data Analysis","02022c6f":" **A histogram is basically used to represent data provided in a form of some groups.It is accurate method for the graphical representation of numerical data distribution.It is a type of bar plot where X-axis represents the bin ranges while Y-axis gives information about frequency.**\n","ee0fd153":"**VIOLIN PLOT**\n\n**A violin plot is a method of plotting numeric data. ... While a box plot only shows summary statistics such as mean\/median and interquartile ranges, the violin plot shows the full distribution of the data. The difference is particularly useful when the data distribution is multimodal (more than one peak).**\n","8e91fbe1":"**BOXPLOT**\n\n**A boxplot is a standardized way of displaying the distribution of data based on a five number summary (\u201cminimum\u201d, first quartile (Q1), median, third quartile (Q3), and \u201cmaximum\u201d). ... It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed.**","6ba9d06e":"# 8. ExtraTreesClassifier","639a67d5":"**LINEPLOT**\n\n**A Line plot can be defined as a graph that displays data as points or check marks above a number line, showing the frequency of each value.**\n","b6df83bd":"**Task : To predict the possibilty of a booking** "}}