{"cell_type":{"8a594849":"code","e24f6c19":"code","007e1f82":"code","c5c70178":"code","1f014b6b":"code","143b2346":"code","16e8a2a1":"code","c5e8eeba":"code","700eae3d":"code","4d13118f":"code","b32aa94d":"code","afed1926":"code","dac60ba3":"code","bfbe50d4":"code","c7036d45":"code","36eab98e":"code","a1667694":"code","3cbf24f3":"code","4d8122c1":"code","162d4b42":"code","236fd6fb":"code","1cf2426e":"code","4fcfaa53":"code","f6f423bc":"code","ed0347cd":"code","f231e8eb":"code","fb45101f":"code","cd6e24de":"code","f04747b6":"code","403a10c9":"code","994a8207":"code","be143a09":"code","a41e761a":"code","08471248":"code","54d88a0d":"code","2203113e":"code","b8ebba2b":"code","cfbad27d":"code","7a2db27a":"code","d8bca546":"code","1a1ed0de":"code","283115d2":"code","1c512250":"code","d4103574":"code","bbf43e86":"code","f4eabcb3":"code","a338952c":"markdown","147c1b2c":"markdown","4f8c8aea":"markdown","1d65c508":"markdown","d10d8fc6":"markdown","1f212042":"markdown","3bd7ce00":"markdown","7ef06c02":"markdown","a522c5a1":"markdown","c6541363":"markdown","f950cba1":"markdown","cf876270":"markdown","ce4d6bd1":"markdown","d5b4b775":"markdown","7d188cf6":"markdown","3e4f9de9":"markdown","0fd6e71b":"markdown","9eb792cc":"markdown","af9fd20f":"markdown","807c5b05":"markdown","824d3efa":"markdown","4c8ed35c":"markdown","ebfba972":"markdown","1d3eb1f6":"markdown","e5693f11":"markdown","d93c4e67":"markdown","6ac629bf":"markdown","c63abf63":"markdown","14fada43":"markdown","60f70439":"markdown","5d2f31c8":"markdown","c3465cc3":"markdown","5b111a04":"markdown","506cb50e":"markdown","bc45d6c1":"markdown","44160afa":"markdown","e86df7d9":"markdown","b29e8fcc":"markdown","3874ebb0":"markdown","d1c6aff9":"markdown"},"source":{"8a594849":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e24f6c19":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics","007e1f82":"# loading the data \nsales_data = pd.read_csv('\/kaggle\/input\/bigmart-sales-data\/Train.csv')\n#checking the first 5 rows of the dataframe\nsales_data.head()","c5c70178":"# checking the number of data points(different products present in the dataset) & number of features\nsales_data.shape","1f014b6b":"# getting some information about the dataset\nsales_data.info()","143b2346":"# checking for missing values\nsales_data.isnull().sum()","16e8a2a1":"# mean value of \"Item_Weight\" column\nsales_data['Item_Weight'].mean()","c5e8eeba":"# filling the missing values in \"Item_weight column\" with \"Mean\" value\nsales_data['Item_Weight'].fillna(sales_data['Item_Weight'].mean(), inplace=True)","700eae3d":"# mode of \"Outlet_Size\" column\nsales_data['Outlet_Size'].mode()","4d13118f":"# filling the missing values in \"Outlet_Size\" column with Mode\n#Here we take Outlet_Size column & Outlet_Type column since they are correlated\nmode_of_Outlet_size = sales_data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))","b32aa94d":"print(mode_of_Outlet_size)","afed1926":"miss_values = sales_data['Outlet_Size'].isnull()","dac60ba3":"print(miss_values)","bfbe50d4":"sales_data.loc[miss_values, 'Outlet_Size'] = sales_data.loc[miss_values,'Outlet_Type'].apply(lambda x: mode_of_Outlet_size[x])","c7036d45":"# checking for missing values\nsales_data.isnull().sum()","36eab98e":"#stastical measures about the data\nsales_data.describe()","a1667694":"sns.set()","3cbf24f3":"# Item_Weight distribution\n#plt.figure(figsize=(5,5))\nsns.distplot(sales_data['Item_Weight'], color='purple')\nplt.show()","4d8122c1":"# Item Visibility distribution\n#plt.figure(figsize=(5,5))\nsns.distplot(sales_data['Item_Visibility'], color='purple')\nplt.show()","162d4b42":"# Item MRP distribution\n#plt.figure(figsize=(5,5))\nsns.distplot(sales_data['Item_MRP'], color='purple')\nplt.show()","236fd6fb":"# Item_Outlet_Sales distribution\n#plt.figure(figsize=(5,5))\nsns.distplot(sales_data['Item_Outlet_Sales'], color='purple')\nplt.show()","1cf2426e":"# Outlet_Establishment_Year column\n#plt.figure(figsize=(5,5))\nsns.countplot(x='Outlet_Establishment_Year', data=sales_data)\nplt.show()","4fcfaa53":"# Item_Fat_Content column\n#plt.figure(figsize=(5,5))\nsns.countplot(x='Item_Fat_Content', data=sales_data)\nplt.show()","f6f423bc":"# Item_Type column\nplt.figure(figsize=(25,7))\nsns.countplot(x='Item_Type', data=sales_data)\nplt.show()","ed0347cd":"# Outlet_Size column\n#plt.figure(figsize=(5,5))\nsns.countplot(x='Outlet_Size', data=sales_data)\nplt.show()","f231e8eb":"sales_data.head()","fb45101f":"sales_data['Item_Fat_Content'].value_counts()","cd6e24de":"sales_data.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)","f04747b6":"sales_data['Item_Fat_Content'].value_counts()","403a10c9":"encoder = LabelEncoder()","994a8207":"sales_data['Item_Identifier'] = encoder.fit_transform(sales_data['Item_Identifier'])\n\nsales_data['Item_Fat_Content'] = encoder.fit_transform(sales_data['Item_Fat_Content'])\n\nsales_data['Item_Type'] = encoder.fit_transform(sales_data['Item_Type'])\n\nsales_data['Outlet_Identifier'] = encoder.fit_transform(sales_data['Outlet_Identifier'])\n\nsales_data['Outlet_Size'] = encoder.fit_transform(sales_data['Outlet_Size'])\n\nsales_data['Outlet_Location_Type'] = encoder.fit_transform(sales_data['Outlet_Location_Type'])\n\nsales_data['Outlet_Type'] = encoder.fit_transform(sales_data['Outlet_Type'])","be143a09":"sales_data.head()","a41e761a":"#Let's have all the features in X & target in Y\nX = sales_data.drop(columns='Item_Outlet_Sales', axis=1)\nY = sales_data['Item_Outlet_Sales']","08471248":"# X contains features\nprint(X)","54d88a0d":"# Y contains target\nprint(Y)","2203113e":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)","b8ebba2b":"print(X.shape, X_train.shape, X_test.shape)","cfbad27d":"regressor = XGBRegressor()","7a2db27a":"#fit the model\n#Training data is in X_train and the corresponding price value is in the Y_train\nregressor.fit(X_train, Y_train)","d8bca546":"sales_data_prediction = regressor.predict(X_train)","1a1ed0de":"# In order to check the performance of the model we find the R squared Value\nr2_sales = metrics.r2_score(Y_train, sales_data_prediction)\nprint('R Squared value = ', r2_sales)","283115d2":"# prediction on test data\ndata_prediction = regressor.predict(X_test)","1c512250":"# R squared Value\nr2_data = metrics.r2_score(Y_test, data_prediction)","d4103574":"print('R Squared value = ', r2_data)","bbf43e86":"input_data = (156, 9.300, 0, 0.016047, 4, 249.8092, 9, 1999,1, 0, 1)\n#input_data_as_numpy_array = np.asarray(input_data)\n#input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n#prediction = regressor.predict(input_data_reshaped)\n#print(prediction)\n#print(\"The initial value is \",prediction[0])\nprint(\"The sales for the first product in the dataset is predicted as \", sales_data_prediction[0])","f4eabcb3":"print(\"Thus we have built the model to predict the sales & have performed the evaluation successfully\")","a338952c":"* Hence from the above graph we can observe that we have the item weight from 5 Kg to 20 Kg & we have maximum values around 12 Kg where the mean is 12.85 Kg\n\n* Therefore in this 8523 products the average weight is about 12.8 Kg","147c1b2c":" \n**IN ORDER TO DEAL WITH THE MISSING VALUES**","4f8c8aea":"**Thus we don't have any missing values in a numerical column & a categorical column**","1d65c508":"**SPLITTING THE DATA INTO TRAINING DATA & TESTING DATA**","d10d8fc6":"Hence, we have successfully cleaned the data in Item_Fat_Content column","1f212042":"**Replacing the missing values in the \"Outlet_Size\"column**","3bd7ce00":"**EVALUATION**\n\nThe R2 score is a very important metric that is used to evaluate the performance of a regression-based machine learning model. It is pronounced as R squared and is also known as the coefficient of determination. It works by measuring the amount of variance in the predictions explained by the dataset.","7ef06c02":"**False** represents it is not null that means the **value is present**\n\n**True** represents a particular **value is missing**","a522c5a1":"* From the above graph we can observe the different items or food types we have such as dairy, soft drinks, meat, fruits & vegetables, household etc \n\n* Hence totally we have about 16 Item_Type values in this case where we have more values in the fruits & vegetables column and snack foods column","c6541363":"**SPLITTING FEATURES AND TARGET INTO X & Y RESPECTIVELY**\n\nWe know that the data in the \"Item_Outlet_Sales\" column is the target & remaining are the features","f950cba1":"* From the above graph we can observe that the data in the Item_Fat_Content column has to be cleaned since we have columns such as Low fat,low fat & Lf which is same & must be put into a single particular label.Similarly we have Regular & reg where we need to put this into a single entity.\n\n* Hence, we need to pre process this data so we will be dealing with this in a later point of time after the visualization of the data","cf876270":"We can observe that\n\n* X contains the original data which is 8523\n\n* X_trains contains 80% of the data which is 6818\n\n* X_test contains 20% of the data which is 1705","ce4d6bd1":"**Hence, we are having 8523 different products with 12 features**","d5b4b775":"**PREDICTION OF THE DATA**","7d188cf6":"From the above pivot table, we can observe that \n\n* If the outlet type is Grocery Store in most of the cases the outlet size(mode) is Small\n* If the outlet type is Supermarket Type1 in most of the cases the outlet size(mode) is Small\n* If the outlet type is Supermarket Type2 in most of the cases the outlet size(mode) is Medium\n* If the outlet type is Supermarket Type3 in most of the cases the outlet size(mode) is Medium","3e4f9de9":"* Hence from the above graph we can observe that we have the outlet establishment from the year 1985, 1987 and all the way to 2009 \n\n* Therefore these are the years on which different outlets or different stores have been established \n\n* We can also observe that a lots of stores are established in the year 1985 & less in the year 1998 & all the others years are almost same","0fd6e71b":"**MACHINE LEARNING MODEL**","9eb792cc":"**STAY SAFE**\ud83c\udfe1 & **STAY HEALTHY**\ud83d\udc69\n\n**HAPPY LEARNING** \u270d & **KEEP KAGGLING** \ud83d\udc69\ud83c\udffb\n\n","af9fd20f":"**IMPORTING LIBRARIES**","807c5b05":"**DATA VISUALIZATION**\n\n* Data visualization is the graphical representation of information and data. \n* It enables decision makers to see analytics presented visually, so they can grasp difficult concepts or identify new patterns ","824d3efa":"**It is important to note that Item_Outlet_Sales is the target variable which we are going to predict & the remaining are the feature variables**","4c8ed35c":"**BUILDING A PREDICTIVE SYSTEM**\n\n* Building a predictive system inorder to find the sales for the first product from the dataset","ebfba972":"* Hence from the above graph we can observe that Item_Outlet_Sales feature is positively skewed","1d3eb1f6":"**Categorical Features:**\n\n* Item_Identifier : categories of different products\n\n* Item_Fat_Content : It tells us whether it has high fat content or low fat content or \n  regular fat content\n\n* Item_Type : It tells us whether it has meat or soft drink & such kind of things\n\n* Outlet_Identifier : It tells us the unique ID of the outlet\n\n* Outlet_Size : it tells us whether it is medium,high or small in size\n\n* Outlet_Location_Type : It tells us whether it is tier 1 or tier 2 & such kind of things\n\n* Outlet_Type : It tells us whether it is supermarket or grocerry store","e5693f11":"**LOADING THE DATA**","d93c4e67":"**PREPROCESSING OF DATA**","6ac629bf":"**Mean --> average**\n\n* The Mean value of a dataset is the average value i.e. a number around which a whole data is spread out. All values used in calculating the average are weighted equally when defining the Mean\n\n* In this case, in order to convert the missing values in the numerical column, we use mean of that particular column\n\n**Mode --> most repeated value**\n\n* The mode is the value that appears most frequently in a data set. A set of data may have one mode, more than one mode, or no mode at all.The mode can be the same value as the mean and\/or median, but this is usually not the case.\n\n* In this case, in order to convert the missing values in the categorical feature, we use the mode of that particular column","c63abf63":"We can observe that we are having 1463 missing values in the Item_Weight column & we are having about 2410 missing values in the Outlet_Size column","14fada43":"**LABEL ENCODING:**\n*     Label Encoding refers to the convertion of the labels into a numeric form so as to convert them into the machine-readable form. Machine learning algorithms can then decide in a better way how those labels must be operated. It is an important pre-processing step for the structured dataset in supervised learning.\n\n*     In simple terms, taking all the categorical values & transforming them into some numerical values","60f70439":"**UNDERSTANDING OF THE PROBLEM STATEMENT:**\n    \n*   According to the quote, \"Success in sales is the sum of small efforts, repeated day in & day out\"\n  \n*   Let us consider a supermarket has several outlets or several stores around the world & they want us to predict the sales which they can expect.\n\n**APPLICATION OF PREDICTING THE SALES:**\n   \n*    We can tell the company what are all the challenges they may face\n   \n*    What are the brands or products which is sold the most & other such kind of things\n   \n*    This helps sales team to understand which product to sell & which product to promote & other such kind of things\n   \n*    They can also make several marketing plans(let's say that a particular product in a particular store is getting sold the most & we may find some insights from it - as of why this product is getting sold the most & this helps the company to make better marketing decisions)\n    \n","5d2f31c8":"**VISUALIZATION OF CATEGORICAL FEATURES**","c3465cc3":"**VISUALIZATION OF NUMERICAL FEATURES**","5b111a04":"**Replacing the missing values in the \"Item_Weight\"column**","506cb50e":"* From the above graph, we can observe that we have three outlet_Size in this case which is medium, small & high","bc45d6c1":"**ANALYSING THE DATA**","44160afa":"**SUPERVISED LEARNING:**\n\n*  It is defined by its use of labeled datasets to train algorithms that to classify data or predict outcomes accurately. \n\n* Basically supervised learning is when we teach or train the machine using data that is well labeled.\n\n* In this particular project, the labels are the target which is more precise.\n\n* In this case the targets are sales amount\n\n**REGRESSION:**\n\n* Regression means predicting a particular value especially continuous value (i.e.sales)","e86df7d9":"* Hence from the above graph we can observe that Item_Visibility feature is positively skewed","b29e8fcc":"* Hence, we have only numerical values in our data where these categories are given some specific numerical values if it is unique\n\n* Therefore we have successfully encoded categorical columns into numerical values which is an important data preprocessing step.","3874ebb0":"**MACHINE LEARNING MODEL TRAINING - XGBoost Regressor**\n\nExtreme Gradient Boosting (XGBoost) is an open-source library that provides an efficient and effective implementation of the gradient boosting algorithm.XGBoost is an efficient implementation of gradient boosting that can be used for regression predictive modeling.","d1c6aff9":"* From the above graph, we can observe that we have good amount of products for 50 MRP,  100 MRP ,200 MRP & then we have less products \n\n* Hence we have more products in the range of 100 MRP - 180 MRP"}}