{"cell_type":{"c67a1fda":"code","4668b737":"code","e3614dfe":"code","58b35f92":"code","198e2827":"code","2957fa0b":"code","a5c9e8e8":"code","29f088ed":"code","933ca10b":"code","6d9edc28":"code","01bd76bc":"code","151bb23f":"code","5cfa11d7":"code","64da66dc":"code","9c1bb967":"code","61020e28":"code","04547876":"code","d804f584":"code","f95c4e29":"code","b326a0be":"code","eb27a50f":"code","b6bbe07b":"code","a21ff323":"code","f4814fb2":"code","50b5364a":"code","87f7376b":"code","a2c4a2ce":"code","a185ea3f":"code","4fb06916":"code","8eb89338":"code","f4c9231e":"code","1ca01075":"code","7301ef34":"code","182a9206":"code","7330ba6c":"code","bf0fc3bc":"code","99bca915":"code","5d14e63b":"code","4783f6c0":"code","c8383c1e":"code","3e231c4c":"code","b94808a5":"code","937ac665":"code","1fd3f0fc":"code","38ac9875":"code","3e43dcfa":"code","3f0351eb":"code","0145d8b5":"code","f6249bd1":"code","5651dc23":"code","ed7e5f91":"code","9f0c2ca4":"code","38ed1d1a":"code","407fe493":"code","bb3f6f33":"code","1aa85430":"code","7f627bfb":"code","d5d2c5a4":"code","dfb35282":"code","fc470f94":"code","2efbbf75":"code","34d3a124":"code","621a818e":"code","6240421a":"code","0ab85548":"code","0c06066a":"code","a9d1007d":"code","a3dcfd28":"code","42d1f932":"code","136794ab":"code","81f51323":"code","8c14b97f":"code","bfa83d1f":"code","09f2a966":"code","b142a1d8":"markdown","c05085b2":"markdown","1184ca38":"markdown","2a310e53":"markdown","5e03d397":"markdown","142f895e":"markdown","608c2e90":"markdown","778534cd":"markdown","45942d97":"markdown","1b87e218":"markdown","f45170b8":"markdown","803a919d":"markdown","cce07154":"markdown","cd97066e":"markdown","ac2f7c2c":"markdown","2763fc8f":"markdown","dd95ea1d":"markdown","d09b644e":"markdown","43f15186":"markdown","10d342db":"markdown","3161e814":"markdown","e7a06708":"markdown","0553d532":"markdown","fc21a06b":"markdown","39437556":"markdown","4bc26800":"markdown","ec7c5433":"markdown","6b310980":"markdown","81ff02d2":"markdown"},"source":{"c67a1fda":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4668b737":"df=pd.read_csv('..\/input\/insurance\/insurance.csv')\ndf.head()\n","e3614dfe":"df.info()","58b35f92":"df.describe()","198e2827":"df.isnull().sum()","2957fa0b":"print(df['sex'].value_counts())\nprint()\nprint(df['region'].value_counts())\nprint()\nprint(df['smoker'].value_counts())","a5c9e8e8":"sns.pairplot(df)","29f088ed":"df_corr=df[['age','bmi','children','charges']]\ndf_corr.corr()","933ca10b":"df_healthy=df[(df['bmi']>18.5) & (df['bmi']<24.9)]\na=df_healthy.count()\nprint('healthy_people:')\nprint(a)\ndf_healthy_region=df_healthy.groupby('region')\ndf_healthy_region.describe().round(2)","6d9edc28":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n                col=\"region\", height=4, data=df_healthy)","01bd76bc":"sns.catplot(x=\"sex\", y=\"age\", hue=\"smoker\",\n                col=\"region\", height=4, data=df_healthy)","151bb23f":"df_underweight=df[(df['bmi']<18.5)]\na=df_underweight.count()\nprint('underweight_people:')\nprint(a)\ndf_underweigh_region=df_underweight.groupby('region')\ndf_underweigh_region.describe().round(2)\n","5cfa11d7":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n                col=\"region\", height=4, data=df_underweight)","64da66dc":"sns.catplot(x=\"sex\", y=\"age\", hue=\"smoker\",\n                col=\"region\", height=4, data=df_underweight)","9c1bb967":"df_overweight=df[(df['bmi']>24.9)]\nb=df_overweight.count()\nprint('overweight_people:')\nprint(b)\ndf_overweight_region=df_overweight.groupby('region')\ndf_overweight_region.describe().round(2)","61020e28":"sns.catplot(x=\"sex\", y=\"charges\", hue=\"smoker\",\n                col=\"region\", height=4, data=df_overweight)","04547876":"sns.catplot(x=\"sex\", y=\"age\", hue=\"smoker\",\n                col=\"region\", height=4, data=df_overweight)","d804f584":"sns.lmplot(x=\"age\", y=\"charges\", hue=\"smoker\",col=\"sex\",markers=[\"o\", \"x\"] ,data=df)","f95c4e29":"sns.lmplot(x=\"bmi\", y=\"charges\", hue=\"smoker\",col=\"sex\",markers=[\"o\", \"x\"] ,data=df)","b326a0be":"sns.displot(data=df, x=\"charges\", kde=True)","eb27a50f":"import numpy.random as nr\nfrom scipy.stats import shapiro\n# seed the random number generator\nnr.seed(1)\n# normality test\nstat, p = shapiro(df['charges'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","b6bbe07b":"x=df['charges']\nprint(np.shape(x))\n# In order to feed x to sklearn, it should be a 2D array (a matrix)\n# Therefore, we must reshape it \nx1 = x.values.reshape(-1,1)\nprint(np.shape(x1))\n","a21ff323":"df.isnull().sum()","f4814fb2":"from pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import QuantileTransformer\nfrom matplotlib import pyplot\n# perform a normal quantile transform of the dataset\ntrans = QuantileTransformer(n_quantiles=1000, output_distribution='normal',random_state=300)\ndata = trans.fit_transform(x1)\n# convert the array back to a dataframe\ndataset = DataFrame(data,columns=['Charges'])\n# histograms of the variables\ndataset.hist()\npyplot.show()","50b5364a":"df['Charges']=dataset['Charges']\ndf.drop(['charges'],axis=1,inplace=True)\n","87f7376b":"df=df[df['Charges']<3]\ndf=df[df['Charges']>-3]\ndf.head()","a2c4a2ce":"df.reset_index(inplace=True)\n#df.dropna(inplace=True)\n","a185ea3f":"# inverse transformation checking\na=trans.inverse_transform(trans.transform(x1))\nb1=pd.DataFrame(a,columns=['Charges'])\nb1.head(5)","4fb06916":"import numpy as np\nimport statsmodels.api as sm\nimport pylab\n\nsm.qqplot(df['Charges'], line='45')\npylab.show()","8eb89338":"from scipy.stats import shapiro\n# seed the random number generator\nnr.seed(1)\n# normality test\nstat, p = shapiro(df['Charges'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","f4c9231e":"df.drop(['index'],axis=1,inplace=True)","1ca01075":"import numpy.random as nr\nfrom statsmodels.graphics.gofplots import qqplot\nfrom matplotlib import pyplot\n# seed the random number generator\nnr.seed(1)\n# q-q plot\nqqplot(df['age'], line='s')\npyplot.show()","7301ef34":"x=df['bmi']\nprint(np.shape(x))\n# In order to feed x to sklearn, it should be a 2D array (a matrix)\n# Therefore, we must reshape it \nx1 = x.values.reshape(-1,1)\nprint(np.shape(x1))","182a9206":"from pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import QuantileTransformer\nfrom matplotlib import pyplot\n# perform a normal quantile transform of the dataset\ntrans = QuantileTransformer(n_quantiles=1000, output_distribution='normal',random_state=300)\ndata = trans.fit_transform(x1)\n# convert the array back to a dataframe\ndataset = DataFrame(data,columns=['BMI'])\n# histograms of the variables\ndataset.hist()\npyplot.show()","7330ba6c":"df['BMI']=dataset['BMI']\ndf.drop(['bmi'],axis=1,inplace=True)\n\ndf=df[df['BMI']<3]\ndf=df[df['BMI']>-3]\ndf.head()","bf0fc3bc":"# inverse transformation\na=trans.inverse_transform(trans.transform(x1))\nb1=pd.DataFrame(a,columns=['BMI'])\nb1.head()","99bca915":"sns.displot(data=df, x='BMI', kde=True,bins=20)","5d14e63b":"df.reset_index(inplace=True)","4783f6c0":"from scipy.stats import shapiro\n# seed the random number generator\nnr.seed(1)\n# normality test\nstat, p = shapiro(df['BMI'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","c8383c1e":"import numpy.random as nr\nfrom statsmodels.graphics.gofplots import qqplot\nfrom matplotlib import pyplot\n# seed the random number generator\nnr.seed(1)\n# q-q plot\nqqplot(df['BMI'], line='s')\npyplot.show()","3e231c4c":"df.drop(['index'],axis=1,inplace=True)","b94808a5":"df.head()","937ac665":"sns.pairplot(df)","1fd3f0fc":"f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize =(15,3))\nax1.scatter(df['age'],df['Charges'])\nax1.set_title('age and charges')\nax2.scatter(df['children'],df['Charges'])\nax2.set_title('children and charges')\nax3.scatter(df['BMI'],df['Charges'])\nax3.set_title('BMI and charges')\n\n\nplt.show()\n","38ac9875":"# central tendency theorem\na = np.array(df['Charges'])\nsample_num = len(df)\nsample_size = 50\n\nmean_sample_values = []\n\nfor i in range(sample_num):\n    sample_mean = np.mean(np.random.choice(a, sample_size, replace=True))\n    mean_sample_values.append(sample_mean) ","3e43dcfa":"import scipy.stats as ss\nplt.figure(figsize=(12, 8))\nplt.title('Charges Distribution', size=18)\nplt.xlabel('charges', size=18)\nsns.distplot(a, fit=ss.norm, color='blue', kde=False)","3f0351eb":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvariables = df[['age','BMI','children']]\n\n# we create a new data frame which will include all the VIFs\n# note that each variable has its own variance inflation factor as this measure is variable specific (not model specific)\nvif = pd.DataFrame()\n\n# here we make use of the variance_inflation_factor, which will basically output the respective VIFs \nvif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n# Finally, I like to include names so it is easier to explore the result\nvif[\"Features\"] = variables.columns\nvif","0145d8b5":"data= pd.get_dummies(df, drop_first=True)\ndata.head()","f6249bd1":"data.columns.values","5651dc23":"cols=['age', 'children', 'BMI', 'sex_male', 'smoker_yes',\n       'region_northwest', 'region_southeast', 'region_southwest','Charges']","ed7e5f91":"data = data[cols]\ndata.head()","9f0c2ca4":"inputs=data.drop(['Charges'],axis=1)\ntargets=data['Charges']\n","38ed1d1a":"# Import the scaling module\nfrom sklearn.preprocessing import StandardScaler\n\n# Create a scaler object\nscaler = StandardScaler()\n# Fit the inputs (calculate the mean and standard deviation feature-wise)\nscaler.fit(inputs)\n# Scale the features and store them in a new variable (the actual scaling procedure)\ninputs_scaled = scaler.transform(inputs)","407fe493":"# Import the module for the split\nfrom sklearn.model_selection import train_test_split\n\n# Split the variables with an 80-20 split and some random state\n# To have the same split as mine, use random_state = 365\nx_train, x_test, y_train, y_test = train_test_split(inputs_scaled, targets, test_size=0.2, random_state=365)","bb3f6f33":"import statsmodels.api as sm\n# Add a constant. Esentially, we are adding a new column (equal in lenght to x), which consists only of 1s\nx = sm.add_constant(x_train)\n# Fit the model, according to the OLS (ordinary least squares) method with a dependent variable y and an independent x\nresults = sm.OLS(y_train,x_train).fit()","1aa85430":"results.summary()\n# DF Model = The model degree of freedom.","7f627bfb":"import sklearn.linear_model as sl\nreg=sl.LinearRegression()\nreg.fit(x_train,y_train)","d5d2c5a4":"# coefficient of model\nreg.coef_","dfb35282":"# Find the R-squared of the model\nreg.score(x_train,y_train)","fc470f94":"# # Obtain the bias (intercept) of the regression\nreg.intercept_","2efbbf75":"y_hat= reg.predict(x_train)","34d3a124":"#checking relation between y_train and y_hat\nplt.scatter(y_train, y_hat, alpha=0.2)","621a818e":"# normality (zero mean and same variance) of errors\nsns.distplot(y_train-y_hat)\nplt.title(\"residuals PDF\",size=18)","6240421a":"# Create a regression summary where we can compare them with one-another\nreg_summary=pd.DataFrame(inputs.columns.values,columns=['features'])\nreg_summary['weights']=reg.coef_\nreg_summary","0ab85548":"import sklearn.feature_selection as sf\n# There are two output arrays\n# The first one contains the F-statistics for each of the regressions\n# The second one contains the p-values of these F-statistics\np_values = sf.f_regression(x_train,y_train)[1].round(4)\np_values\n\n# hence this shows Sex, regions should be removed as they are unwanted variables","0c06066a":"yhat_test=reg.predict(x_test)\nplt.scatter(y_test,yhat_test)\n# this is showing that Y-pred and Y-test samples are not much linear","a9d1007d":"sns.distplot((y_test-yhat_test),bins=50);","a3dcfd28":"from sklearn import metrics\nprint('MAE:', metrics.mean_absolute_error(y_test, yhat_test)) # average error\nprint('MSE:', metrics.mean_squared_error(y_test, yhat_test))\n#There is no correct value for MSE. Simply put, the lower the value the better and 0 means the model is perfect\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, yhat_test)))\n\n# The MAE is a linear score which means that all the individual differences are weighted equally in the average. \n# The RMSE is a quadratic scoring rule which measures the average magnitude of the error. ... \n# Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors.","42d1f932":"#Import resampling and modeling algorithms\nfrom sklearn.utils import resample # for Bootstrap sampling\nvalues = data.values","136794ab":"#Lets configure Bootstrap\n\nn_iterations = 20  #No. of bootstrap samples to be repeated (created)\nn_size = int(len(data) * 0.8 ) #Size of sample, picking only 80% of the given data in every bootstrap sample","81f51323":"#Lets run Bootstrap\nstats = list()\nfor i in range(n_iterations):\n\n    #prepare train & test sets\n    train = resample(values, n_samples = n_size) #Sampling with replacement.\n    test = np.array([x for x in values if x.tolist() not in train.tolist()]) \n    #picking rest of the data not considered in training sample\n    \n    #fit model\n    model = sl.LinearRegression()\n    model.fit(train[:,:-1], train[:,-1]) #model.fit(X_train,y_train)\n    \n    #evaluate model\n    predictions = model.predict(test[:,:-1]) #model.predict(X_test)\n    #accuracy_score(y_test, y_pred)\n    score=np.sqrt(metrics.mean_squared_error(test[:,-1], predictions))\n    \n    #caution, overall accuracy score can mislead when classes are imbalanced\n    \n    print(score)\n    stats.append(score)\nprint(\"Average Error: \", np.mean(score))\n# for regression evaluation MAE, MSE, RMSE and R^2 used \n# accuracy_score is for classification tasks only. For regression you should use something different","8c14b97f":"from sklearn.model_selection import KFold","bfa83d1f":"X, y = values[:, :-1], values[:, -1]","09f2a966":"from numpy import array\nfrom sklearn.model_selection import KFold\n# data sample\n# prepare cross validation\nkfold = KFold(10)\n# enumerate splits\nscores = []\nfor train, test in kfold.split(X):\n    X_train, X_test = X[train], X[test]\n    y_train, y_test = y[train], y[test]\n    \n    score=np.sqrt(metrics.mean_squared_error(reg.fit(X_train, y_train).predict(X_test), y_test))\n    scores.append(score)\n    print(score)\n    \nprint('Average:',np.mean(scores))\n    ","b142a1d8":"### Overweight People","c05085b2":"### Quantile Transformation","1184ca38":"### QQ Plot for normality test of Charges","2a310e53":"### Healthy People","5e03d397":"## Testing","142f895e":"Column Descriptions\n\nage: age of primary beneficiary\n\nsex: insurance contractor gender, female, male\n\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg \/ m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n\nchildren: Number of children covered by health insurance \/ Number of dependents\n\nsmoker: Smoking\n\nregion: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n\ncharges: Individual medical costs billed by health insurance","608c2e90":"#### checking for normality","778534cd":"### Data Summary","45942d97":"### K-Fold Cross- Validation Method","1b87e218":"## Hence Linear Model with technique 'OLS' doesnt gives us the good model Prediction ","f45170b8":"### Classifying and counting total no. of 'sex' , 'region ' ,'smoker'","803a919d":"### Quantile-Quantile plot for normailty Test for Age","cce07154":"# Linear Regression Model (OLS)","cd97066e":"# changing Charges distribution into Normal Distribution","ac2f7c2c":"### Finding Null Values","2763fc8f":"### quanatile transform","dd95ea1d":"## Linear Model evaluation using Resampling Methods ","d09b644e":"#### Checking for Linearity","43f15186":"### Data types","10d342db":"### train\/test split","3161e814":"# Exploratory Data analysis","e7a06708":"# Checking 'BMI Distribution' ","0553d532":"### Normality Test  (Shapiro - Wilk Test)","fc21a06b":"### Underweight People","39437556":"### Creating dumies","4bc26800":"### Bootstrap Method","ec7c5433":"### Normality Test  (QQ-plot Test)","6b310980":"### Correlation","81ff02d2":"####  checking for multi collinear"}}