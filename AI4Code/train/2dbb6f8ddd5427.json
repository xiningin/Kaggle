{"cell_type":{"ad8b3478":"code","060a71d2":"code","b82df18d":"code","1090eab7":"code","825a06fd":"code","84d49adb":"code","f9947950":"code","36c1f049":"code","1e361867":"code","4bd3ff35":"code","409a14fb":"code","4a40900f":"code","1669b65c":"code","a33a5752":"code","ee07dfbe":"code","bdd1963e":"code","d2b41797":"code","fae19e8d":"code","72756005":"code","c9bb77d0":"code","8d55a134":"code","b139408c":"code","a0fe589a":"code","7d8e1792":"code","eb840966":"code","302d52be":"code","faecf6e6":"code","06e737f0":"code","223c178e":"code","8e83089c":"code","ed2cc32c":"code","ef517217":"code","b18b174c":"code","cbc38021":"code","b7ed6b58":"code","8c0a128f":"code","e9061779":"markdown","0093782c":"markdown","ab738e1c":"markdown","710c6b48":"markdown","d04c76ee":"markdown","cbc7b07f":"markdown","bb5de512":"markdown","54f63d73":"markdown","615dd583":"markdown","cb91e11e":"markdown","a937f178":"markdown","38f67003":"markdown"},"source":{"ad8b3478":"! pip install pyspark","060a71d2":"from pyspark.sql import SparkSession, DataFrame, functions as F\nfrom pyspark.ml.feature import Imputer, StringIndexer, VectorIndexer, VectorAssembler, OneHotEncoderEstimator, PCA, Bucketizer\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml import Pipeline\n\nimport pandas as pd\nimport pandas_profiling\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b82df18d":"# For EDA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","1090eab7":"spark = SparkSession.builder.appName(\"Titanic-Dataset\").config('spark.driver.memory','15g').getOrCreate()\nspark\n# spark.stop()","825a06fd":"sdf_train = spark.read.csv('\/kaggle\/input\/titanic\/train.csv', inferSchema = True, header = True)\nsdf_test = spark.read.csv('\/kaggle\/input\/titanic\/test.csv', inferSchema = True, header = True)","84d49adb":"def _clean_dataset(sdf: DataFrame, col_to_convert: list, col_to_impute: list) -> DataFrame:\n    for col in col_to_convert:\n        sdf = sdf.withColumn(col,sdf[col].cast('double'))\n    col_to_impute += col_to_convert\n\n    imputer = Imputer(inputCols = col_to_impute, outputCols = col_to_impute)\n    sdf = imputer.fit(sdf).transform(sdf)\n    \n    return sdf","f9947950":"def _handle_missing_age(sdf: DataFrame) -> DataFrame:\n    _sdf = sdf\n    _sdf = _sdf.withColumn('Age', \n           F.when((F.isnull(_sdf['Age'])) & (_sdf['Initial'] == 'Mr') , 33 )\\\n            .otherwise(F.when((F.isnull(_sdf['Age'])) \n                              & (_sdf['Initial'] == 'Mrs') , 36)\\\n            .otherwise(F.when((F.isnull(_sdf['Age'])) \n                              & (_sdf['Initial'] == 'Master') , 5)\\\n            .otherwise(F.when((F.isnull(_sdf['Age'])) \n                              & (_sdf['Initial'] == 'Miss') , 22)\\\n            .otherwise(F.when((F.isnull(_sdf['Age'])) \n                              & (_sdf['Initial'] == 'Other') , 46)\\\n            .otherwise(_sdf['Age']) )))))\n    return _sdf","36c1f049":"def _evaluate_initials(sdf: DataFrame) -> DataFrame:\n    dizip_initials = {k:v for k,v in (zip(['Mlle','Mme','Ms','Dr',\n                                           'Major','Lady','Countess',\n                                           'Jonkheer','Col','Rev',\n                                           'Capt','Sir','Don'],\n                                         ['Miss','Miss','Miss',\n                                          'Mr','Mr','Mrs','Mrs',\n                                          'Other','Other','Other',\n                                          'Mr','Mr','Mr']))}\n    _sdf = sdf.withColumn('Initial',  F.regexp_extract( sdf['Name'], ('([A-Za-z]+)\\.'),1 ) )\n    _sdf = _sdf.replace(dizip_initials,1,'Initial')\n    return _sdf\n","1e361867":"def _create_family_size(sdf: DataFrame) -> DataFrame :\n    _sdf = sdf.withColumn('FamilySize', sdf['Parch'] + sdf['SibSp'] + 1 )\n    \n    return _sdf\n","4bd3ff35":"sdf_train_cleaned = _clean_dataset ( \n    _handle_missing_age(\n    _evaluate_initials(\n    _create_family_size(sdf_train)\n    )) \n    ,['Ticket','SibSp','Parch'],['Fare'] \n)\n\nsdf_test_cleaned = _clean_dataset ( \n    _handle_missing_age(\n    _evaluate_initials(\n    _create_family_size(sdf_test)\n    )) \n    ,['Ticket','SibSp','Parch'],['Fare'] \n)\n\nsdf_train_cleaned.limit(5).toPandas().T","409a14fb":"pdf_sdf_train = sdf_train_cleaned.toPandas()\npdf_sdf_train.T","4a40900f":"fig, ax = plt.subplots(1,2, figsize=(16,8))\nax[0].set_title('barplot: Age ratio with Initial')\nsns.barplot(x= pdf_sdf_train['Initial'], y=pdf_sdf_train['Age'],ax=ax[0])\n\nax[1].set_title('violinplot: Age ratio with Initial')\nsns.violinplot(pdf_sdf_train['Initial'],pdf_sdf_train['Age'], ax=ax[1])","1669b65c":"# derive AgeGroup from age and sex\npdf_sdf_train['AgeGroup'] = None\npdf_sdf_train.loc[((pdf_sdf_train['Sex'] == 'male') & (pdf_sdf_train['Age'] <= 15)), 'AgeGroup'] = 'boy'\npdf_sdf_train.loc[((pdf_sdf_train['Sex'] == 'female') & (pdf_sdf_train['Age'] <= 15)), 'AgeGroup'] = 'girl'\npdf_sdf_train.loc[((pdf_sdf_train['Sex'] == 'male') & (pdf_sdf_train['Age'] > 15)), 'AgeGroup'] = 'adult male'\npdf_sdf_train.loc[((pdf_sdf_train['Sex'] == 'female') & (pdf_sdf_train['Age'] > 15)), 'AgeGroup'] = 'adult female'\npdf_sdf_train['AgeGroup'].value_counts()","a33a5752":"fig, ax = plt.subplots(1,2,figsize=(16,7))\nax[0].set_title('pointplot: Survived ratio for Age group')\nsns.pointplot(pdf_sdf_train['AgeGroup'],pdf_sdf_train['Survived'],ax=ax[0])\nax[1].set_title('countplot: Survived ratio for Age group')\nsns.countplot(pdf_sdf_train['AgeGroup'],hue= pdf_sdf_train['Survived'],ax=ax[1])","ee07dfbe":"fig, ax = plt.subplots(1,2,figsize=(16,8))\nax[0].set_title('pointplot: Survived ratio with Pclass')\nsns.pointplot(pdf_sdf_train['Pclass'],pdf_sdf_train['Survived'],ax=ax[0])\nax[1].set_title('countplot: Survived ratio with Pclass')\nsns.countplot(pdf_sdf_train['Pclass'],hue= pdf_sdf_train['Survived'],ax=ax[1])","bdd1963e":"fig, ax = plt.subplots(1,2, figsize=(16,8))\nax[0].set_title('barplot: Survived ratio with Pclass')\nsns.barplot( pdf_sdf_train['Pclass'], pdf_sdf_train['Survived'], ax=ax[0])\n\nax[1].set_title('countplot: Survived ratio with Pclass')\nsns.countplot(x=pdf_sdf_train['Pclass'], hue=pdf_sdf_train['Survived'], ax=ax[1])","d2b41797":"fig, ax = plt.subplots(1,2, figsize=(16,8))\nax[0].set_title('countplot: Survived ratio with Sex')\nsns.countplot(x=pdf_sdf_train['Sex'],hue= pdf_sdf_train['Survived'],ax=ax[0])\n\nax[1].set_title('barplot: Survived ratio with Sex')\nsns.barplot(pdf_sdf_train['Sex'], pdf_sdf_train['Survived'],ax=ax[1])\n","fae19e8d":"plt.figure(figsize=(12,24))\n# plt.xticks(rotation=90)\nsns.countplot(y=pdf_sdf_train['Age'],hue= pdf_sdf_train['Survived'],orient='h')","72756005":"pd.Categorical(pdf_sdf_train['Sex'])","c9bb77d0":"import numpy as np\nplt.figure(figsize=(25,10))\nplt.xticks(rotation=90)\nplt.axvspan(np.size(pdf_sdf_train[pdf_sdf_train['Age'] < 12]['Age'].unique())\n            ,np.size(pdf_sdf_train[pdf_sdf_train['Age'] < 50]['Age'].unique())\n            ,alpha = 0.25\n            , color = 'green') # without alpha = 0.25, it will be dark green!\nprint(np.size(pdf_sdf_train[pdf_sdf_train['Age'] < 12]['Age'].unique()))\nprint(np.size(pdf_sdf_train[pdf_sdf_train['Age'] < 50]['Age'].unique()))\n\nsns.barplot(pdf_sdf_train['Age'],pdf_sdf_train['Survived'], ci=None) # ci box plot details","8d55a134":"plt.figure(figsize=(25,10))\nplt.title('Age distribution among all Pasengers')\nsns.distplot(pdf_sdf_train['Age'])","b139408c":"plt.subplot(1,2,1)\n# plt.figure(figsize=(25,10))\nplt.title('Age distribution for Survived')\nplt.axis([0,100,0,100])\nsns.distplot(pdf_sdf_train[pdf_sdf_train.Survived == 1]['Age'],kde=False)\n\nplt.subplot(1,2,2)\nplt.title('Age distribution for Non Survived')\nsns.distplot(pdf_sdf_train[pdf_sdf_train.Survived == 0]['Age'],kde=False)\n\nplt.subplots_adjust(right=1.7)\n# plt.show()","a0fe589a":"g = sns.FacetGrid(pdf_sdf_train,col='Survived')\ng = g.map(sns.distplot,'Age')","7d8e1792":"g = sns.kdeplot(pdf_sdf_train['Age']\n                [(pdf_sdf_train['Survived']==0) \n                                     & (pdf_sdf_train['Age'].notnull())],\n                color='Red',shade=True)\ng = sns.kdeplot(pdf_sdf_train['Age']\n                [(pdf_sdf_train['Survived']==1)  \n                                     & (pdf_sdf_train['Age'].notnull())],\n                color='Green',shade=True)\ng.set_xlabel('Age')\ng.set_ylabel('Frequency')\ng = g.legend(['Not Survived','Survived'])","eb840966":"# https:\/\/homepage.divms.uiowa.edu\/~luke\/classes\/STAT4580\/stripplot.html\nsns.stripplot(x=\"Survived\", y=\"Age\",data=pdf_sdf_train,jitter=True)","302d52be":"sns.pairplot(pdf_sdf_train)","faecf6e6":"numeric_cols = ['PassengerId','Survived', 'Pclass',\n                'Age', 'SibSp','Parch','Ticket','Fare'] \nnumeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \nstring_features = [ 'Embarked', 'Sex'] ","06e737f0":"_stages = []\nstring_indexer =  [StringIndexer(inputCol = column , \\\n                                 outputCol = column + '_StringIndexer', \n                                 handleInvalid = \"skip\") for column in string_features]\n\none_hot_encoder = [OneHotEncoderEstimator(\n    inputCols = [column + '_StringIndexer' for column in string_features ], \\\n    outputCols =  [column + '_OneHotEncoderEstimator' for column in string_features ])]\n\nvect_indexer = [VectorIndexer(\n    inputCol = column + '_OneHotEncoderEstimator',\n    outputCol = column + '_VectorIndexer', \n    maxCategories=10) for column in string_features]\n\nfamilt_size_splits = [1, 2, 5, 7, 100] \nbucketizer = Bucketizer(splits = familt_size_splits, \n                        inputCol = 'FamilySize',\n                        outputCol = 'bucketized_FamilySize')\n\nnumeric_features += ['bucketized_FamilySize']\n\nassemblerInput =  [f  for f in numeric_features]  \nassemblerInput += [f + \"_VectorIndexer\" for f in string_features]\nvector_assembler = VectorAssembler(inputCols = assemblerInput, \\\n                                   outputCol = 'VectorAssembler_features')\n\n_stages += string_indexer\n_stages += one_hot_encoder\n_stages += vect_indexer\n_stages += [bucketizer]\n_stages += [vector_assembler]\n","223c178e":"_stages","8e83089c":"pipeline = Pipeline(stages = _stages)","ed2cc32c":"model = pipeline.fit(sdf_train_cleaned)","ef517217":"sdf_transformed_train = model.transform(sdf_train_cleaned)\nsdf_transformed_train.limit(5).toPandas().T","b18b174c":"\nrf = RandomForestClassifier(labelCol = 'Survived', \n                            featuresCol = 'VectorAssembler_features', \n                            numTrees = 100, \n                            maxDepth = 4, \n                            maxBins = 1000)\n_stages += [rf]","cbc38021":"_stages","b7ed6b58":"pipeline = Pipeline(stages = _stages)\nmodel = pipeline.fit(sdf_train_cleaned)\n\nsdf_predict = model.transform(sdf_test_cleaned)","8c0a128f":"sdf_predict.toPandas().profile_report()","e9061779":"# Data IO","0093782c":"Resources:  \nhttps:\/\/www.kaggle.com\/bombatkarvivek\/data-analysis-and-feature-extraction-with-python\/edit\/run\/14851611    \nhttps:\/\/www.kaggle.com\/codesail\/titanic-explore-features-with-explanation  ","ab738e1c":"# ML Model","710c6b48":"# Feature Engineering","d04c76ee":"# BarPlot vs CountPlot","cbc7b07f":"\n# BarPlot vs ViolinPlot","bb5de512":"# PointPlot vs CountPlot","54f63d73":"This notebook includes:  \n1. ML pipeline like data io, feature engineering and ml with PySpark libs    \n2. EDA with seaborn like pairplot, barplot, distplot, stripplot\n3. EDA with pandas profiler","615dd583":"**With manually treating features :**","cb91e11e":"***The ML Pipeline Steps***:\n- [Data IO](#Data-IO)\n- [Data Cleaning](#Data-Cleaning)\n- [Feature Engineering](#Feature-Engineering)\n- [ML Model](#ML-Model)\n","a937f178":"# Data Cleaning","38f67003":"**With pyspark.ml.feature methods :**  "}}