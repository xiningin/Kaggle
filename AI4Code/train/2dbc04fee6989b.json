{"cell_type":{"3bfbd190":"code","11e5095e":"code","0a850940":"code","0e574ff0":"code","d67c4bb0":"code","de9f2ad3":"code","28894c1c":"code","d627594a":"code","f0c6f732":"code","db63565a":"code","08e8f734":"code","10fe2230":"code","97c2b73f":"code","ecac435e":"code","25927305":"code","a883a1a7":"code","e766562b":"code","191370cc":"code","eb81f739":"code","aa4da791":"code","314438b7":"code","b4350c8c":"code","299dcf25":"code","cf42b3d4":"code","42aed905":"code","efa9a3ce":"code","8b6a1439":"code","865a8277":"code","ea1dc5b4":"code","2f298a29":"markdown","a7218dda":"markdown","0e68647c":"markdown","d61b693d":"markdown","a4049ed9":"markdown","a22af1bf":"markdown","10717323":"markdown","a635ea82":"markdown"},"source":{"3bfbd190":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11e5095e":"import numpy as np\nimport pandas as pd\n%matplotlib inline\n\nimport matplotlib \nimport matplotlib.pyplot as plt\nimport seaborn as sns","0a850940":"train = pd.read_csv('..\/input\/fake-news\/train.csv')\ntest = pd.read_csv('..\/input\/fake-news\/test.csv')\ntrain.shape ,test.shape","0e574ff0":"train.sample(4)","d67c4bb0":"train.isna().sum()","de9f2ad3":"# Percentage of missing value columns\ntrain.isna().sum()\/len(train)*100","28894c1c":"x = train.drop('label' ,axis =1)\ny = train['label']\nx.head(3)","d627594a":"train = train.dropna()\ntrain.shape","f0c6f732":"text_df = train.copy()\ntext_df.reset_index(inplace =True)\ntext_df.head(5)","db63565a":"text_df['title'][6]","08e8f734":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0,len(text_df)):\n    review = re.sub('[^a-zA-Z]' ,' ',text_df['title'][i])\n    review = review.lower()\n    review = review.split()\n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\n","10fe2230":"#Applying Vectorizer for text Processing\nfrom sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer ,HashingVectorizer\ncv = CountVectorizer(max_features= 5000 , ngram_range= (1,3))\nX = cv.fit_transform(corpus).toarray()\nX.shape","97c2b73f":"cv.get_feature_names()","ecac435e":"y = text_df['label']\ny.shape","25927305":"from sklearn.model_selection import train_test_split\nx_train ,x_test ,y_train ,y_test =train_test_split(X,y ,test_size = .30 , random_state = 101)\nx_train.shape ,x_test.shape ,y_train.shape ,y_test.shape","a883a1a7":"# randomforest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(x_train ,y_train)\npred = rf.predict(x_test)\npred","e766562b":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy   =\",accuracy_score(y_test ,pred))","191370cc":"test.sample()","eb81f739":"test.isna().sum()","aa4da791":"test.dtypes","314438b7":"# Handling missing value\nfor i in test.columns:\n    test [i] = test[i].fillna(test[i].mode()[0])","b4350c8c":"test.shape\ntest.reset_index(inplace =True)","299dcf25":"corpus_test = []\nfor i in range(0 ,len(test)):\n    a = re.sub('[^a-zA-Z]' ,' ' , test['title'][i])\n    a = a.lower()\n    a = a.split()\n    \n    a = [ps.stem(word) for word in a if not word in stopwords.words('english')]\n    a = ' '.join(a)\n    corpus_test.append(a)\ncorpus_test","cf42b3d4":"#Vectorizer\ntst = cv.fit_transform(corpus_test).toarray()\ntst.shape","42aed905":"# Accuracy for TEST\np = rf.predict(tst)\np","efa9a3ce":"submission = pd.read_csv('..\/input\/fake-news\/submit.csv')\nsubmission.shape","8b6a1439":"submission.head(3)","865a8277":"predictin = pd.DataFrame(p)\npredictin ['id'] = submission['id']\npredictin['label'] = predictin[0]\npredictin = predictin.drop(0 ,axis =1)\npredictin","ea1dc5b4":"my_submission = predictin.to_csv()","2f298a29":"# Importing the Libaraies","a7218dda":"# Loading the Dataset","0e68647c":"# Model Buildig","d61b693d":"# Test Dataset","a4049ed9":"# Handling Missing Value","a22af1bf":"# Dependent & Indepedent Variables","10717323":"# Spliting the Train test","a635ea82":"# Handling Unstructured Data"}}