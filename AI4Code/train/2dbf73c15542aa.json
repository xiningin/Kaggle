{"cell_type":{"4cf7856f":"code","32e1ec7e":"code","1cbd681e":"code","9a8ecf97":"code","12151862":"code","395942a9":"code","95c2dbfa":"code","f7ee8527":"code","c12d669d":"code","dd42c814":"code","50547efd":"code","bc821b2e":"code","77b7e5aa":"code","d123bf1c":"code","426f4147":"code","80cf276a":"code","06d38bbd":"code","78b351cb":"code","0faefd7f":"code","97224818":"code","e4cacbe5":"code","500d3e1e":"code","063ed455":"code","64adc9f6":"code","519b6c45":"code","fe4377cf":"code","9414a15b":"code","8a07db46":"code","50bad7f8":"code","1de7298a":"code","9c1d1890":"code","32e52f94":"code","9f619500":"code","00f5b18a":"code","3700a0ba":"code","e58cb13c":"code","7d6aba40":"code","31cc90b4":"code","3a952c72":"code","633b85b6":"code","1180f60f":"code","6c410477":"code","6c34f8a4":"code","f8b5ae10":"code","b2bfcdbc":"code","21bd5d30":"code","ed1d855d":"code","0edc6434":"code","2b039120":"code","3876509f":"code","09e638ad":"code","368c8786":"code","e7b89285":"code","2d6ac0a1":"code","f9264913":"code","69d99c93":"code","785ab4aa":"code","aa0fa9a9":"code","2cd0ea6f":"code","b6dfbc55":"code","206ab387":"code","c5e635f4":"code","4202f68c":"code","08990517":"code","74cbedeb":"markdown","5821bc69":"markdown","e32772db":"markdown","77183202":"markdown"},"source":{"4cf7856f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","32e1ec7e":"\nimport numpy as np\nimport os\nfrom matplotlib import pyplot as plt\nimport cv2\nimport random\nimport pickle\n\n\nfile_list = []\nclass_list = []\n\nDATADIR = \"..\/input\/mendeleydatabloodsmearanalysis\/PBC_dataset_normal_DIB\/PBC_dataset_normal_DIB\"\n\n# All the categories you want your neural network to detect\nCATEGORIES = [\"basophil\",\"eosinophil\",\"erythroblast\",\"ig\",\"lymphocyte\",\"monocyte\",\"neutrophil\",\"platelet\"]\n\n# The size of the images that your neural network will use\nIMG_SIZE = 359\n\n# Checking or all images in the data folder\n'''for category in CATEGORIES :\n    path = os.path.join(DATADIR, category)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img))'''\n        \n\ntraining_data = []\n\ndef create_training_data():\n    for category in CATEGORIES :\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)\n        m = 0\n        print(category)\n        for imagename in os.listdir(path):\n            if m<200:\n                print(os.path.join(path, imagename))\n                final_img = preprocessing_img(cv2.cvtColor(cv2.imread(os.path.join(path, imagename)), cv2.COLOR_BGR2RGB))\n                plt.imshow(return_crop(final_img))\n                plt.show()\n                training_data.append([return_crop(final_img), class_num])\n                m+=1\n                print(m)\n            else:\n                break\n\n            \n\ncreate_training_data()\n\nrandom.shuffle(training_data)\n\nX1 = [] #features\ny1 = [] #labels\n\nfor features, label in training_data:\n\tX1.append(features)\n\ty1.append(label)\n\n","1cbd681e":"X1 = np.array(X1).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\n# Creating the files containing all the information about your model\npickle_out = open(\"X1.pickle\", \"wb\")\npickle.dump(X1, pickle_out)\npickle_out.close()\n\npickle_out = open(\"y1.pickle\", \"wb\")\npickle.dump(y1, pickle_out)\npickle_out.close()","9a8ecf97":"from sklearn.model_selection import train_test_split\nx_tr, x_te, y_tr, y_te = train_test_split(X1, y1, )","12151862":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv3D, MaxPooling2D\nimport pickle\nfrom keras.models import model_from_json\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\n\n# Opening the files about data\n\n#data from threshold preprocessing\nX = pickle.load(open(\"..\/input\/pickled-mendeley\/X.pickle\", \"rb\"))\ny = pickle.load(open(\"..\/input\/pickled-mendeley\/y.pickle\", \"rb\"))\n\n#data from mask preprocessing \nX1 = pickle.load(open(\"..\/input\/new-data\/X1.pickle\", \"rb\"))\ny1 = pickle.load(open(\"..\/input\/new-data\/y1.pickle\", \"rb\"))","395942a9":"import numpy as np\nimport keras\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Dropout, MaxPool2D, Input, Softmax, Activation, Flatten, \nconcatenate,AveragePooling2D\nfrom keras.models import Model\nfrom keras import optimizers\nimport os\nprint(os.listdir(\"..\/input\"))\nimport cv2\nimport scipy\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils.vis_utils import plot_model\nfrom keras.utils.np_utils import to_categorical\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","95c2dbfa":"X = np.array(X)\ny = np.array(y)\nxtr, xte, ytr, yte = train_test_split(X, y,test_size = 0.3, shuffle = True)\n\ny_trainHot = to_categorical(ytr, num_classes = 8)\ny_testHot = to_categorical(yte, num_classes = 8)","f7ee8527":"def keras_model(block_num=2):\n    inp = Input(shape=(200,200,3))\n    k = BatchNormalization()(inp)\n    k = Conv2D(32, (7,7), padding=\"same\",activation=\"relu\",strides=(2,2))(k)\n    k = MaxPool2D(pool_size=(3, 3), padding=\"same\",strides=(2,2))(k) \n    k = Conv2D(32, (3,3), padding=\"same\",activation=\"relu\",strides=(1,1))(k)\n    k = MaxPool2D(pool_size=(3, 3), padding=\"same\",strides=(2,2))(k)\n    for j in range(1,block_num+1):\n        out_conv = []\n        for i in [(1,1),(3,3),(5,5),(0,0)]:\n            p = k\n            if i == (1,1):\n                p = Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p)\n                out_conv.append(Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p))\n            elif i == (0,0):\n                p = MaxPool2D(pool_size=(2, 2), padding=\"same\",strides=(1,1))(p)\n                out_conv.append(Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p))\n            else:\n                p = Conv2D(32, (1,1), padding=\"same\",activation=\"relu\")(p)\n                p = Conv2D(32, i, padding=\"same\",activation=\"relu\")(p)\n                out_conv.append(Conv2D(32, i, padding=\"same\",activation=\"relu\")(p))\n        x = concatenate(out_conv, axis = -1)\n        k = x\n    x = MaxPool2D(pool_size=(7, 7), padding=\"same\",strides=(2,2))(x)\n    x = Flatten()(x)\n    y = Dense(8 ,activation=\"softmax\")(x)\n    model = Model(inp, y)\n    opt = optimizers.Adam(lr=0.01,decay=0.0001)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=\"adam\",\n                  metrics=['accuracy'])\n    return model\nmodel = keras_model(4)\nmodel.summary()","c12d669d":"filepath = \".\/cells.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\nhistory = model.fit(xtr,\n         y_trainHot,\n         epochs = 40,\n         batch_size = 32,\n         validation_data = (xte,y_testHot),\n         callbacks = callbacks_list,\n         verbose = 1)\nmodel.save(\"cells.h5\")","dd42c814":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","50547efd":"history_dict = history.history\nhistory_dict.keys()\nplt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\n\nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n","bc821b2e":"model.load_weights(filepath)\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagentrain = ImageDataGenerator(featurewise_center=False,\n                samplewise_center=False,\n                featurewise_std_normalization=False,\n                samplewise_std_normalization=False,\n                zca_whitening=False, zca_epsilon=1e-06,\n                rotation_range=5, width_shift_range=0.0,\n                height_shift_range=0.0, brightness_range=None,\n                shear_range=0, zoom_range=0.0,\n                channel_shift_range=0.0, fill_mode='nearest',\n                cval=0.0, horizontal_flip=True, vertical_flip=True,\n                rescale=None, preprocessing_function=None,\n                data_format=None, validation_split=0.0)\ndatagentrain.fit(xtr)\nhistory = model.fit_generator(datagentrain.flow(xtr, y_trainHot, batch_size=32),\n                    steps_per_epoch=64,\n                    epochs=45,\n                    workers=4,\n                    use_multiprocessing=True,validation_data = (xte,y_testHot),\n         callbacks = callbacks_list,)","77b7e5aa":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","d123bf1c":"#Accuracy Plot\nhistory_dict = history.history\nhistory_dict.keys()\nplt.clf()   # clear figure\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\n\nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","426f4147":"predictions = model.predict(xte)","80cf276a":"CATEGORIES = [\"basophil\",\"eosinophil\",\"erythroblast\",\"ig\",\"lymphocyte\",\"monocyte\",\"neutrophil\",\"platelet\"]","06d38bbd":"fig=plt.figure(figsize=(20,5))\ncolumns = 8\nrows = 3\nax = []\n\nfor i in range(columns*rows):\n    img = xte[i-1].copy()\n    ax.append(fig.add_subplot(rows, columns, i+1))\n    ax[-1].set_title(str(CATEGORIES[list(predictions[i-1][:]).index(max(np.array(predictions)[i-1,:]))]))\n    plt.axis('off')\n    plt.imshow(img)\n","78b351cb":"import glob\nimport cv2\nimport numpy as np\nimport skimage\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import ndimage as ndi\nimport time\nfrom skimage import (\n    color, feature, filters, io, measure, morphology, segmentation, util\n)\nimage = cv2.cvtColor(cv2.imread('..\/input\/mendeleydatabloodsmearanalysis\/PBC_dataset_normal_DIB\/PBC_dataset_normal_DIB\/monocyte\/MO_103089.jpg'), cv2.COLOR_BGRA2RGB)\nplt.imshow(image)\nplt.axis('off')\nplt.show()","0faefd7f":"def get_norm_img(a, display = False):\n    img = a.copy()\n    norm_img= cv2.merge((np.divide(img[:,:,0],np.sum(img, axis = 2))*255\n               ,np.divide(img[:,:,1],np.sum(img, axis = 2))*255\n               ,np.divide(img[:,:,2],np.sum(img, axis = 2))*255))\n    norm_img = norm_img.astype(np.uint8)\n    \n    if display:\n        plt.imshow(norm_img)\n        plt.title('Normalised Image')\n        plt.axis('off')\n        plt.show()\n    return norm_img.copy()\n\nnorm_image = get_norm_img(image.copy(), True)\n","97224818":"def contrast_enhance(img, x = 1, display = False):\n    #-----Converting image to LAB Color model----------------------------------- \n    norm_img = img.copy()\n    try:\n        lab = cv2.cvtColor(norm_img.copy(), cv2.COLOR_RGB2LAB)\n    except:\n        lab = cv2.cvtColor(cv2.cvtColor(norm_img.copy(), cv2.COLOR_GRAY2RGB), cv2.COLOR_RGB2LAB)\n    #-----Splitting the LAB image to different channels-------------------------\n    l, a, b = cv2.split(lab.copy())\n    #-----Applying CLAHE to L-channel-------------------------------------------\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    if(x == 1):\n        cl = clahe.apply(l.copy())\n    else:\n        cl = clahe.apply(a.copy())\n    #-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n    limg = cv2.merge((cl.copy(),a.copy(),b.copy()))\n    #-----Converting image from LAB Color model to RGB model--------------------\n    final = cv2.cvtColor(limg.copy(), cv2.COLOR_LAB2RGB)\n    if display:\n        res_1 = np.hstack((l,a,b,cl))\n        res_2 = np.hstack((lab,limg,final))\n        plt.figure(figsize=(20,40))\n        plt.axis('off')\n        plt.imshow(res_1)\n        plt.show()\n        plt.figure(figsize=(20,40))\n        plt.axis('off')\n        plt.imshow(res_2)\n        plt.show()\n    return final\n    #_____END_____#\nfinal = contrast_enhance(norm_image.copy(), 1, True)","e4cacbe5":"def wbc_rgb_man(img, display = False):\n    final = img.copy()\n    final = cv2.merge((np.add(final[:,:,0], final[:,:,2])\/\/2, final[:,:,1:])).astype(np.uint8)\n    if(display):\n        plt.axis('off')\n        plt.title('rgb manipulated, contrast enhanced, norm image')\n        plt.imshow(final)\n        plt.show()\n    return final\nfinal = wbc_rgb_man(final.copy(), True)","500d3e1e":"invert_contrast_img = cv2.bitwise_not(final.copy())\nplt.imshow(invert_contrast_img)\nplt.axis('off')\nplt.title('inverted image')\nplt.show()","063ed455":"a = ['RED','GREEN','BLUE']\nprint(a)\nred_channel_img = invert_contrast_img[:,:,0]\ngreen_channel_img = invert_contrast_img[:,:,1]\nblue_channel_img = invert_contrast_img[:,:,2]\nres = np.hstack((red_channel_img,green_channel_img,blue_channel_img)) #stacking images side-by-side\nplt.figure(figsize=(20,40))\nplt.axis('off')\nplt.imshow(res, 'gray')\nplt.show()","64adc9f6":"def plot_channel_histogram(img_input, display = False):\n    histogram_data = np.array(np.unique(img_input, return_counts=True))\n    indices = list(histogram_data[0])\n    values = list(histogram_data[1])\n    bins = range(256)\n    hist_values = []\n    for i in range(256):\n        if i in indices:\n            hist_values.append(values[indices.index(i)])\n        else:\n            hist_values.append(0)\n    if display:\n        fig = plt.figure()\n        ax = fig.add_axes([0,0,1,1])\n        ax.bar(bins,hist_values)\n        plt.title('COLOR HISTOGRAM')\n        plt.show()\n    return dict({'indices':indices, 'values':values})","519b6c45":"data_orig = plot_channel_histogram(blue_channel_img.copy(), True)","fe4377cf":"def find_nearest(array, value):\n    array = np.asarray(array)\n    idx = (np.abs(array - value)).argmin()\n    return array[idx]","9414a15b":"def get_thresh(data, display = False):\n    indices = data['indices']\n    values = data['values']\n    avg_px = np.sum(np.multiply(indices, values))\/\/np.sum(values)\n    \n    avg_px = find_nearest(indices, avg_px)\n    UT = np.sum(np.multiply(indices[indices.index(avg_px):],values[indices.index(avg_px):]))\/\/np.sum(values[indices.index(avg_px):])\n    \n    LT = np.sum(np.multiply(indices[0:indices.index(avg_px)+1],values[0:indices.index(avg_px)+1]))\/\/np.sum(values[0:indices.index(avg_px)+1])\n    if display:\n        print('LT = ',LT)\n        print('avg = ',avg_px)\n        print('UT = ',UT)\n    return dict({'avg':avg_px,'UT':UT,'LT':LT})\nthresholds_orig = get_thresh(data_orig.copy(), True) ","8a07db46":"def foreground_enhancement(channel_img,thresh, n = 1, display = False):\n    avg_px = thresh['avg']\n    UT = thresh['UT']\n    LT = thresh['LT']\n    frgnd_enhanced_1 = channel_img.copy()\n    frgnd_enhanced_2 = channel_img.copy()\n    frgnd_enhanced_3 = channel_img.copy()\n    frgnd_enhanced_1[channel_img>(avg_px+LT)\/\/2] = 0\n    frgnd_enhanced_2[channel_img>avg_px\/\/2] = 0\n    frgnd_enhanced_3[channel_img>(avg_px+UT)\/\/2] = 0\n    for i in range(channel_img.shape[0]):\n        for j in range(channel_img.shape[1]):\n            if channel_img[i,j]<=(avg_px+LT)\/\/2:\n                frgnd_enhanced_1[i,j] = channel_img[i,j]\n            else:\n                frgnd_enhanced_1[i,j] = 0\n            if channel_img[i,j]<=avg_px:\n                frgnd_enhanced_2[i,j] = channel_img[i,j]\n            else:\n                frgnd_enhanced_2[i,j] = 0\n            if channel_img[i,j]<=(avg_px+UT)\/\/2:\n                frgnd_enhanced_3[i,j] = channel_img[i,j]\n            else:\n                frgnd_enhanced_3[i,j] = 0\n    if display:\n        res = np.hstack((frgnd_enhanced_1,frgnd_enhanced_2,frgnd_enhanced_3))\n        plt.imshow(res, 'gray')\n        plt.axis('off')\n        plt.show()\n    if n==1:\n        return frgnd_enhanced_1\n    elif n==2:\n        return frgnd_enhanced_2\n    elif n==3:\n        return frgnd_enhanced_3\nbg_region = foreground_enhancement(blue_channel_img.copy(),thresholds_orig, 1, True)\nplt.imshow(bg_region, 'gray')\nplt.title('selected background region')\nplt.axis('off')\nplt.show()","50bad7f8":"def binarizing_img(enh_reg,n = 1,display = False):\n    gray_img = enh_reg.copy()\n    plt.imshow(gray_img,'gray')\n\n    blur_img = cv2.medianBlur(gray_img.copy(),5)\n\n    ret,th1 = cv2.threshold(blur_img,127,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    '''th2 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n                cv2.THRESH_BINARY,11,2)\n    th3 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n                cv2.THRESH_BINARY,11,2)'''\n\n    images = [blur_img, th1]\n    if display:\n        titles = ['Original Image', 'Global Thresholding (v = 127)']\n        for i in range(2):\n            plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n            plt.title(titles[i])\n            plt.xticks([]),plt.yticks([])\n        plt.show()\n    return images[n]\nbg_region_binary = binarizing_img(bg_region.copy(), 1, True)","1de7298a":"def morph_img(gray, n = 1):\n    # noise removal\n    kernel = np.ones((3,3),np.uint8)\n    opening = cv2.morphologyEx(gray.copy(),cv2.MORPH_OPEN,kernel, iterations = 6)\n    # sure background area\n    sure_bg = cv2.dilate(opening,kernel,iterations=8)\n    if n==1:\n        return opening\n    elif n==2:\n        return sure_bg\n#opening = morph_img(bg_region_binary.copy())\n#plt.imshow(opening, 'gray')","9c1d1890":"data_orig = plot_channel_histogram(green_channel_img.copy(), True)","32e52f94":"thresholds_orig = get_thresh(data_orig.copy(), True)","9f619500":"fg_region = foreground_enhancement(green_channel_img.copy(),thresholds_orig,1, True)","00f5b18a":"fg_reg_binary = binarizing_img(fg_region.copy())","3700a0ba":"def filling_holes(morphed_img, display = False):\n    #filling holes\n    des = cv2.bitwise_not(morphed_img.copy())\n    contour,hier = cv2.findContours(des,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n\n    for cnt in contour:\n        cv2.drawContours(des,[cnt],0,255,-1)\n\n    gray = cv2.bitwise_not(des)\n    if display:\n        plt.imshow(np.hstack((morphed_img,des,gray)), 'gray')\n        plt.axis('off')\n        plt.title('Images From the Process')\n        plt.show()\n\n        plt.imshow(gray, 'gray')\n        plt.axis('off')\n        plt.title('Holes Filled')\n        plt.show()\n   \n    return gray","e58cb13c":"def draw_contours(image, filled):\n    contours, hierarchy = cv2.findContours(filled.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    test_img = image.copy()\n    for i in range(len(contours)):\n        color_contours = (0, 0, 0) # green - color for contours\n        # draw ith contour\n        cv2.drawContours(test_img, np.array(contours), i, color_contours, 2, 8, hierarchy)\n    #plt.imshow(test_img)\n    return test_img, contours","7d6aba40":"def return_reg_3d(imgr, reg):\n    return_img = imgr.copy()\n    return_img[reg == 0] = 0\n    #plt.imshow(return_img)\n    return return_img\n#return_img = return_reg_3d(image.copy(), bg_region_binary.copy())\n                ","31cc90b4":"def return_reg_2d(img2, reg):\n    return_img1 = img2.copy()\n    return_img1[reg == 0] = 0\n    plt.imshow(return_img1)\n    return return_img1","3a952c72":"def get_logic_area(main_cell, new_contours):\n    m,n,c = 0,0,0\n    for i in range(np.array(new_contours).shape[0]):\n        if m<np.array(new_contours)[i].shape[0]:\n            m=np.array(new_contours)[i].shape[0]\n            n = i\n            \n    img = main_cell.copy()\n    cv2.drawContours(img, new_contours, n, 255, -1) # Draw filled contour in mask\n    out = np.zeros_like(img) # Extract out the object and place into output image\n    out[img == 255] = img[img == 255]\n    mask = cv2.subtract(out[:,:,0], out[:,:,1])\n    final_cell = main_cell.copy()\n    for i in range(mask.shape[0]):\n        for j in range(mask.shape[1]):\n            if mask[i,j] == 255:\n                final_cell[i,j] = main_cell[i,j]\n            else:\n                final_cell[i,j] = 0\n    return final_cell, mask","633b85b6":"def return_relevant(im1,filled_img):\n    img11 = im1.copy()\n    img11[filled_img == 255] = 0\n    return img11\n    ","1180f60f":"filled_img = return_reg_2d(filling_holes(fg_reg_binary.copy()),bg_region_binary.copy())\nplt.imshow(filled_img)\nplt.axis('off')\nplt.show()\nmain_cell = return_reg_3d(image.copy(), bg_region_binary.copy())\nplt.imshow(main_cell)\nplt.axis('off')\nplt.show()","6c410477":"main_cell1 = return_relevant(main_cell.copy(), filled_img.copy())\nplt.imshow(main_cell1)\nplt.axis('off')\nplt.show()","6c34f8a4":"test = main_cell[:,:,0].copy()\narr = main_cell[:,:,0].copy().reshape(-1)[::-1]\narr[::-1].sort()\nval = int(np.mean(arr[0:10000]))\nfor i in range(main_cell[:,:,0].shape[0]):\n    for j in range(main_cell[:,:,0].shape[1]):\n        if test[i,j] >= val:\n            test[i,j] = 0\nplt.imshow(test)\nplt.axis('off')\nplt.show()","f8b5ae10":"final_wbc = return_reg_3d(image.copy(), test.copy())\ncontoured_img,contours = draw_contours(final_wbc.copy(), filled_img.copy())\nfinal_cell, mask = get_logic_area(contoured_img, contours)\n\nplt.imshow(np.hstack((final_wbc, contoured_img, final_cell)))\nplt.figure(figsize=(15, 30))\nplt.axis('off')\nplt.show()\n\n\nplt.imshow(final_cell)\nplt.axis('off')\nplt.show()","b2bfcdbc":"def getting_maincell(img_channel, img12, mode = 1,display = False, bg = 1, fg = 1):\n    red_channel_img = img_channel[:,:,0]\n    green_channel_img = img_channel[:,:,1]\n    blue_channel_img = img_channel[:,:,2]\n    if display:\n        a = ['RED','GREEN','BLUE']\n        print(a)\n        res = np.hstack((red_channel_img,green_channel_img,blue_channel_img)) #stacking images side-by-side\n        plt.figure(figsize=(20,40))\n        plt.axis('off')\n        plt.imshow(res, 'gray')\n        plt.show()\n    \n    data_bg = plot_channel_histogram(blue_channel_img.copy())\n    data_fg = plot_channel_histogram(green_channel_img.copy())\n\n    \n    thresholds_bg = get_thresh(data_bg)\n    thresholds_fg = get_thresh(data_fg)\n    \n    \n    bg_region = foreground_enhancement(blue_channel_img.copy(),thresholds_bg, bg)\n    fg_region = foreground_enhancement(green_channel_img.copy(),thresholds_fg,fg)\n    if display:\n        bg_fg = np.hstack((bg_region, fg_region))\n        plt.imshow(bg_fg,'gray')\n        plt.show()\n\n    bg_reg_binary = binarizing_img(bg_region.copy())\n    fg_reg_binary = binarizing_img(fg_region.copy())\n    \n    if display:\n        bg_fg_binary = np.hstack((bg_reg_binary,fg_reg_binary))\n        plt.imshow(bg_fg_binary, 'gray')\n        plt.axis('off')\n        plt.show()\n\n    filled_img = return_reg_2d(filling_holes(fg_reg_binary.copy()),bg_reg_binary.copy())\n    #plt.imshow(filled_img)\n    #plt.show()\n    main_cell = return_reg_3d(img12.copy(), bg_reg_binary.copy())\n    '''plt.imshow(main_cell)\n    plt.axis('off')\n    plt.show()'''\n    if mode == 1:\n        test = main_cell[:,:,0].copy()\n        arr = main_cell[:,:,0].copy().reshape(-1)[::-1]\n        arr[::-1].sort()\n        val = int(np.mean(arr[0:10000]))\n        for i in range(main_cell[:,:,0].shape[0]):\n            for j in range(main_cell[:,:,0].shape[1]):\n                if test[i,j] >= val:\n                    test[i,j] = 0\n    else:\n        final_cell = return_relevant(main_cell.copy(), filled_img.copy())\n        plt.imshow(final_cell)\n        plt.show()\n        return final_cell\n    final_wbc = return_reg_3d(img12.copy(), test.copy())\n    '''contoured_img,contours = draw_contours(final_wbc.copy(), filled_img.copy())\n    final_cell, n_mask = get_logic_area(contoured_img, contours)'''\n    plt.imshow(final_wbc)\n    plt.axis('off')\n    plt.show()\n    return final_wbc","21bd5d30":"def preprocessing_img(img, mode = 1):\n    norm_img = get_norm_img(img.copy())\n    final = contrast_enhance(norm_img.copy())\n    final = wbc_rgb_man(final.copy())\n    invert_contrast_img = cv2.bitwise_not(final.copy())\n    final_wbc = getting_maincell(invert_contrast_img.copy(), img.copy(), mode, True)\n    return final_wbc","ed1d855d":"final_wbc = preprocessing_img(image)","0edc6434":"final_wbc = preprocessing_img(image, 2)","2b039120":"def get_mask(final_wbc, display = False):\n    w_mask = final_wbc.copy()\n    w_mask[final_wbc != [0,0,0]] = 255\n    w_mask = cv2.cvtColor(w_mask, cv2.COLOR_RGB2GRAY)\n    if display:\n        plt.imshow(w_mask)\n        plt.title('WBC MASK')\n        plt.axis('off')\n        plt.show()\n    return w_mask","3876509f":"def return_crop(final_wbc, mode = 1, display = False):\n    if mode == 1:\n        return final_wbc[0:359,0:359]\n    else:\n        w_mask = get_mask(final_wbc)\n        x,y,w,h = cv2.boundingRect(w_mask.copy())\n        if display:\n            plt.imshow(final_wbc[y:y+200,x:x+200])\n    return final_wbc[y:y+200,x:x+200]","09e638ad":"final_wbc = preprocessing_img(image, 2)","368c8786":"w_mask = get_mask(final_wbc.copy(), True)\nw_mask = cv2.morphologyEx(w_mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7)), iterations = 2)\nw_mask = cv2.morphologyEx(w_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7)), iterations = 7)\nplt.imshow(w_mask)\nplt.title('mask after closing')\nplt.axis('off')\nplt.show()","e7b89285":"x,y,w,h = cv2.boundingRect(w_mask.copy())\nfinal_img = cv2.rectangle(image.copy(), (x-25,y-25),(x+175, y+175), (255,0,0), 3)\nplt.imshow(np.hstack((final_img, cv2.cvtColor(cv2.rectangle(w_mask.copy(), (x-25,y-25),(x+175, y+175), (255,0,0), 3), cv2.COLOR_GRAY2RGB))))\nplt.title('Drawing a bounding box around wbc')\nplt.axis('off')\nplt.show()","2d6ac0a1":"[x,y,w,h] = cv2.boundingRect(w_mask.copy())\ncropped_img = image[y:y+3*h\/\/2, x:x+3*w\/\/2].copy()\ncropped_mask = w_mask[y:y+3*h\/\/2, x:x+3*w\/\/2].copy()\nintensity = cropped_img.sum(axis=2)\n#print(intensity)\nintensity_val = np.max(intensity)\n#print(intensity_val)\nprint('THRESHOLD INTENSITY VALUE'+str(intensity_val))\nresult = np.where(intensity == intensity_val)\n#print(result)\nval = cropped_img[result].mean(axis = 0).astype(int)\nprint(val)\nfor i in range(cropped_mask.shape[0]):\n    for j in range(cropped_mask.shape[1]):\n        if cropped_mask[i,j] != 0:\n            cropped_img[i,j,:] = val\nplt.imshow(cropped_img)\nplt.title('after removing non rbc region')\nplt.axis('off')\nplt.show()\ncropped_img[:,:,2] = cv2.GaussianBlur(cropped_img[:,:,2].copy(),(5,5),8)\nplt.imshow(cropped_img)\nplt.title('after applying gaussian blur')\nplt.axis('off')\nplt.show()\nclean_image = image.copy()\nclean_image[y:y+3*h\/\/2, x:x+3*w\/\/2] = cropped_img\nplt.imshow(clean_image)\nplt.title('final clean image')\nplt.axis('off')\nplt.show()","f9264913":"red = contrast_enhance(clean_image.copy(),2, True)\nplt.imshow(red)\nplt.title('contrast enhancement of TYPE 2 applied on clean image')\nplt.axis('off')\nplt.show()","69d99c93":"a = ['RED','GREEN','BLUE']\nprint(a)\nred_invert = cv2.bitwise_not(clean_image.copy())\nred_channel_img = red_invert[:,:,0]\ngreen_channel_img = red_invert[:,:,1]\nblue_channel_img = red_invert[:,:,2]\nres = np.hstack((red_channel_img,green_channel_img,blue_channel_img)) #stacking images side-by-side\nplt.figure(figsize=(20,40))\nplt.axis('off')\nplt.imshow(res, 'gray')\nplt.show()","785ab4aa":"green_channel_img = cv2.cvtColor(contrast_enhance(green_channel_img.copy()), cv2.COLOR_RGB2GRAY)\nplt.imshow(green_channel_img, 'gray')","aa0fa9a9":"data_red = plot_channel_histogram(green_channel_img.copy())","2cd0ea6f":"gray = foreground_enhancement(green_channel_img.copy(),get_thresh(data_red), 2)\nplt.imshow(gray, 'gray')\nplt.title('foreground enhancement for rbcs')\nplt.axis('off')\nplt.show()","b6dfbc55":"binary_img = binarizing_img(gray, 1)\nplt.imshow(binary_img, 'gray')","206ab387":"binary_img = filling_holes(binary_img.copy())\nplt.imshow(binary_img, 'gray')","c5e635f4":"binary_img = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations = 7)\nplt.imshow(binary_img)","4202f68c":"from skimage import measure\nlabels = measure.label(cv2.bitwise_not(binary_img),connectivity = 2)\ndistance = ndi.distance_transform_edt(labels.copy())\nlocal_maxi = feature.peak_local_max(distance, indices=False,\n                                    min_distance=10)\nmarkers = measure.label(local_maxi)\nsegmented_cells = segmentation.watershed(-distance, markers, mask=labels, watershed_line = True)\n\nfig, ax = plt.subplots(ncols=2, figsize=(10, 5))\nax[0].imshow(binary_img.copy(), cmap='gray')\nax[0].set_title('Overlapping nuclei')\nax[0].axis('off')\nax[1].imshow(color.label2rgb(segmented_cells, bg_label=0))\nax[1].set_title('Segmented nuclei')\nax[1].axis('off')\nplt.show()","08990517":"props = measure.regionprops(segmented_cells)\nar = 0\nc = 0\nfor prop in props:\n    final_img = cv2.rectangle(final_img, (prop.bbox[1], prop.bbox[0]), (prop.bbox[3],prop.bbox[2]), (0,255,0), 3) \n    c+=1\nprint('RBC COUNT: '+str(c))\nplt.imshow(final_img)\nplt.title('Labeled RBCs')\nplt.axis('off')\nplt.show()","74cbedeb":"# RBC COUNTING","5821bc69":"# Getting the WBC inner region","e32772db":"**END OF RBC COUNTING**","77183202":"# Preprocessing Functions Explained"}}