{"cell_type":{"8533f170":"code","4b4b6271":"code","b150ad73":"code","d6058510":"code","a1d6d0ca":"code","545d7c63":"code","76b5775d":"code","bf3c3edd":"code","6d50ca4a":"code","1ce8d958":"code","25525957":"code","16153e46":"code","58a0f00a":"code","e354cf0e":"code","b9d7c39e":"code","ccf518a0":"code","9fb726f8":"code","8a4b4393":"code","26344965":"code","f43e66e7":"code","ad4ef4c7":"code","bf64958e":"code","575ec3c5":"code","33d27379":"code","e4baae21":"code","2c6ac5d9":"code","abbec3ef":"code","a67ca316":"code","cade0674":"code","29dd4d90":"code","54f4e3c8":"code","856f9d9a":"code","318edaf1":"code","53554917":"code","cd4fe38b":"code","d9f3833e":"code","c59f82b1":"code","d9d32613":"code","3a0904d2":"code","cd204453":"code","fd301222":"code","c772c3c1":"code","5891a776":"code","514cdb9e":"markdown","50727860":"markdown","43b83085":"markdown","1b8c0bcd":"markdown","c0b22d2d":"markdown","20ab7b42":"markdown","23938914":"markdown"},"source":{"8533f170":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n# Required libraries\n# We will try several Machine Learning platforms\nfrom __future__ import print_function\nfrom builtins import str\nfrom builtins import range\n\nimport os\nimport sys\nimport tarfile\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom io import BytesIO\n\nimport bson\nimport json \nimport skimage\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn import *\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nimport time\n#import datetime as dt\nfrom datetime import datetime as dt\nimport multiprocessing\nimport psutil\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\n# Config the matplotlib backend as plotting inline in IPython\n%matplotlib inline\n\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\nprint(\"pandas --version : \", pd.__version__)\nprint(\"python --version : \", sys.version)\nPyVersion = sys.version\nprint(os.listdir(\"..\/input\"))","4b4b6271":"# From https:\/\/www.kaggle.com\/theoviel\/load-the-totality-of-the-data \n# https:\/\/www.kaggle.com\/xhlulu\/load-entire-dataset-with-7-gb-ram-fork\ndtypes = {\n        'MachineIdentifier':                                    'category',\n        'ProductName':                                          'category',\n        'EngineVersion':                                        'category',\n        'AppVersion':                                           'category',\n        'AvSigVersion':                                         'category',\n        'IsBeta':                                               'int8',\n        'RtpStateBitfield':                                     'float16',\n        'IsSxsPassiveMode':                                     'int8',\n        'DefaultBrowsersIdentifier':                            'float16',\n        'AVProductStatesIdentifier':                            'float32',\n        'AVProductsInstalled':                                  'float16',\n        'AVProductsEnabled':                                    'float16',\n        'HasTpm':                                               'int8',\n        'CountryIdentifier':                                    'int16',\n        'CityIdentifier':                                       'float32',\n        'OrganizationIdentifier':                               'float16',\n        'GeoNameIdentifier':                                    'float16',\n        'LocaleEnglishNameIdentifier':                          'int8',\n        'Platform':                                             'category',\n        'Processor':                                            'category',\n        'OsVer':                                                'category',\n        'OsBuild':                                              'int16',\n        'OsSuite':                                              'int16',\n        'OsPlatformSubRelease':                                 'category',\n        'OsBuildLab':                                           'category',\n        'SkuEdition':                                           'category',\n        'IsProtected':                                          'float16',\n        'AutoSampleOptIn':                                      'int8',\n        'PuaMode':                                              'category',\n        'SMode':                                                'float16',\n        'IeVerIdentifier':                                      'float16',\n        'SmartScreen':                                          'category',\n        'Firewall':                                             'float16',\n        'UacLuaenable':                                         'float32',\n        'Census_MDC2FormFactor':                                'category',\n        'Census_DeviceFamily':                                  'category',\n        'Census_OEMNameIdentifier':                             'float16',\n        'Census_OEMModelIdentifier':                            'float32',\n        'Census_ProcessorCoreCount':                            'float16',\n        'Census_ProcessorManufacturerIdentifier':               'float16',\n        'Census_ProcessorModelIdentifier':                      'float16',\n        'Census_ProcessorClass':                                'category',\n        'Census_PrimaryDiskTotalCapacity':                      'float32',\n        'Census_PrimaryDiskTypeName':                           'category',\n        'Census_SystemVolumeTotalCapacity':                     'float32',\n        'Census_HasOpticalDiskDrive':                           'int8',\n        'Census_TotalPhysicalRAM':                              'float32',\n        'Census_ChassisTypeName':                               'category',\n        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n        'Census_PowerPlatformRoleName':                         'category',\n        'Census_InternalBatteryType':                           'category',\n        'Census_InternalBatteryNumberOfCharges':                'float32',\n        'Census_OSVersion':                                     'category',\n        'Census_OSArchitecture':                                'category',\n        'Census_OSBranch':                                      'category',\n        'Census_OSBuildNumber':                                 'int16',\n        'Census_OSBuildRevision':                               'int32',\n        'Census_OSEdition':                                     'category',\n        'Census_OSSkuName':                                     'category',\n        'Census_OSInstallTypeName':                             'category',\n        'Census_OSInstallLanguageIdentifier':                   'float16',\n        'Census_OSUILocaleIdentifier':                          'int16',\n        'Census_OSWUAutoUpdateOptionsName':                     'category',\n        'Census_IsPortableOperatingSystem':                     'int8',\n        'Census_GenuineStateName':                              'category',\n        'Census_ActivationChannel':                             'category',\n        'Census_IsFlightingInternal':                           'float16',\n        'Census_IsFlightsDisabled':                             'float16',\n        'Census_FlightRing':                                    'category',\n        'Census_ThresholdOptIn':                                'float16',\n        'Census_FirmwareManufacturerIdentifier':                'float16',\n        'Census_FirmwareVersionIdentifier':                     'float32',\n        'Census_IsSecureBootEnabled':                           'int8',\n        'Census_IsWIMBootEnabled':                              'float16',\n        'Census_IsVirtualDevice':                               'float16',\n        'Census_IsTouchEnabled':                                'int8',\n        'Census_IsPenCapable':                                  'int8',\n        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n        'Wdft_IsGamer':                                         'float16',\n        'Wdft_RegionIdentifier':                                'float16',\n        'HasDetections':                                        'int8'\n        }","b150ad73":"train_df = pd.read_csv('..\/input\/train.csv', nrows = 200, dtype=dtypes)\ncolumns = train_df.columns\ntrain_df = pd.read_csv('..\/input\/train.csv', nrows = 2000000, usecols= columns, dtype=dtypes)\n#train_df.info() ","d6058510":"numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64'] \nnumerical_columns = [c for c,v in dtypes.items() if v in numerics] \ncategorical_columns = [c for c,v in dtypes.items() if v not in numerics] ","a1d6d0ca":"train_df.shape","545d7c63":"train_df.to_pickle(\"train_df.pkl\")","76b5775d":"# MEAN ENCODINGS\nfor elt in numerical_columns:\n    if elt != 'HasDetections':\n        m_id = elt \n        target = 'HasDetections' \n        new_column = pd.DataFrame(columns=[m_id+'_mean_target']) \n        # mean encoding of variables\n        train_df[m_id+'_mean_target'] = new_column[m_id+'_mean_target'] \n        cumsum = train_df.groupby(m_id)[target].cumsum() - train_df[target] \n        cumcnt = train_df.groupby(m_id).cumcount() \n        train_df[m_id+'_mean_target'] = cumsum\/cumcnt\n    \ntrain_df.shape","bf3c3edd":"labels_df = train_df['HasDetections']\ntrain_df = train_df.drop(['MachineIdentifier'], axis=1) \ncolumns = train_df.columns \ntrain_df.shape","6d50ca4a":"train_df.head(2)","1ce8d958":"col = list(columns)\ncol.remove('HasDetections')\n#print(col), len(col)\nlen(col)","25525957":"# DATA SPLITING\nX_train, X_test, y_train, y_test = train_test_split(train_df[col], labels_df, test_size=0.2, \n                                                    random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, \n                                                    random_state=42)\n\nn_features = X_train.shape[1]\nn_classes = len(np.unique(y_train))\nprint(\"n_features : {}\\nn_classes : {}\\nX_train.shape : {}\".format(n_features, n_classes, \n                                                                   X_train.shape))","16153e46":"X_train.shape, X_val.shape, X_test.shape","58a0f00a":"y_train.shape, y_val.shape, y_test.shape","e354cf0e":"print('Start training...')\n# train\ngbm = lgb.LGBMClassifier(objective='binary',\n                        num_leaves=31,\n                        learning_rate=0.05,\n                        n_estimators=20)\ngbm.fit(X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        eval_metric='auc',\n        early_stopping_rounds=100)\n\nprint('Start predicting...')\n# predict\n#y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\ny_pred = gbm.predict(X_test, num_iteration=10)\n# eval\nprint('The log_loss of prediction is:', log_loss(y_test, y_pred))\nprint('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))\n\n# feature importances\nprint('\\nNumber of features :', len(list(gbm.feature_importances_)))\nprint('Features :', train_df.columns)\nprint('Importances :', list(gbm.feature_importances_))\nprint('\\nFeature importances :', dict(zip(train_df.columns,list(gbm.feature_importances_))))\n\n# The log_loss of prediction is: 12.769218206519513 , roc_auc_score is: 0.630302822037965\n# for test size == 20% and val size == 20%\n# 0.630302822037965\n# log_loss: 12.587463101120566 et roc_auc_score: 0.6355364487531907 for mean encoding with dummify.\n# log_loss: 12.494988259947414 et roc_auc_score: 0.638198925649798 for mean encoding without dummify.","b9d7c39e":"# FEATURES TUNING IF NECESSARY\n## For example, we could remove least important features if required\n## And also use the best parameters provided by the grid search Cross Validation\n# Here I reuse the same previous splits instead of recreate a new one.\nX_train = pd.DataFrame(X_train, columns=col) \nX_val = pd.DataFrame(X_val, columns=col) ","ccf518a0":"X_train.head(2)","9fb726f8":"X_val.head(2)","8a4b4393":"# In case I decide to delete the features with lower importance to see how that could improve the result\n# Using the Feature importances Dictionary\nfeature_importances_dic = dict(zip(train_df.columns,list(gbm.feature_importances_)))\nbanned_columns = []\nfor key in feature_importances_dic:\n    if feature_importances_dic[key]==0:\n        banned_columns.append(key)\nprint(\"len banned_columns:\", len(banned_columns))\nprint(\"banned_columns:\\n\", banned_columns)\n\nnew_cols = [c for c in train_df.columns if c not in banned_columns]\nnew_cols = list(new_cols)\nif 'HasDetections' in new_cols:\n    new_cols.remove('HasDetections')\nprint(\"new columns:\\n\", new_cols) \nlen(new_cols)","26344965":"X_train_new = X_train[new_cols] \nX_val_new = X_val[new_cols] \nX_test_new = X_test[new_cols] \nX_train_new.shape, X_val_new.shape, X_test_new.shape ","f43e66e7":"# TRAINING\n# specify your configurations as a dict\n# Use the best parameters provided by the grid search Cross Validation\nparams = {\"objective\": \"binary\",\n          #\"sigmoid\":1.0,\n          \"task\": \"train\",\n          \"boosting_type\": \"gbdt\",\n          \"learning_rate\": 0.05,\n          \"num_leaves\": 31, # 31, 20\n          \"max_bin\": 256,\n          \"min_data_in_leaf\": 5, # Problem  2000\n          \"feature_fraction\": 0.6, # 0.6\n          \"verbosity\": 0,\n          \"seed\": 0,\n          \"drop_rate\": 0.1, # 0.1\n          \"is_unbalance\": False,\n          \"max_drop\": 50,\n          \"min_child_samples\": 10,\n          \"min_child_weight\": 1e-06, # 5\n          \"min_split_gain\": 0,\n          \"colsample_bytree\": 0.6343275033,\n          \"max_depth\": 8, # 8\n          #\"n_estimators\": 500, # 500\n          \"nthread\": -1,\n          \"reg_alpha\": 0,\n          \"reg_lambda\": 1e-06,# 1\n          #\"silent\": True,\n          \"subsample_for_bin\": 50000, # 50000\n          \"subsample_freq\": 1, # 1\n          #\"min_data\":1,\n          #\"min_data_in_bin\":1,\n          'metric': {'binary_logloss'},\n          'bagging_fraction': 0.8,\n          'bagging_freq': 5,\n          #'num_iterations':1000,\n          \"subsample\": 0.733\n          }","ad4ef4c7":"# create dataset for lightgbm\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n#lgb_train = lgb.Dataset(X_train_new, y_train)\n#lgb_eval = lgb.Dataset(X_val_new, y_val, reference=lgb_train)\n\n\nprint('Start training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=2000,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=120)\n\nprint('Save model...')\n# save model to file\ngbm.save_model('model.txt')","bf64958e":"print('Start predicting...')\n# predict\ny_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n#y_pred = gbm.predict(X_test_new, num_iteration=gbm.best_iteration)\n# eval\n#print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\nprint('The log_loss of prediction is:', log_loss(y_test, y_pred))\nprint('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))\n# The log_loss of prediction is: 0.6147321812202021 and the roc_auc_score is: 0.7143388814690966\n# for test size == 10% and val size == 20%\n# With dummification, log_loss: 0.6103008030367194 and roc_auc_score: 0.7168178922141861\n# Without dummification, log_loss: 0.6067172451965305 and roc_auc_score: 0.7217849368889165","575ec3c5":"print('Loading model to predict...')\n# load model to predict\nbst = lgb.Booster(model_file='model.txt')\n# can only predict with the best iteration (or the saving iteration)\ny_pred = bst.predict(X_test)\nprint('The log_loss of prediction is:', log_loss(y_test, y_pred))\nprint('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))","33d27379":"gbm.best_iteration, bst.best_iteration","e4baae21":"!ls","2c6ac5d9":"# We will now save the parameters in order to reuse them in another kernel for submission\ndel train_df\ntrain_df = pd.read_pickle(\"train_df.pkl\")\ntrain_df.shape","abbec3ef":"train_df2 = pd.read_csv('..\/input\/train.csv', nrows = 200, dtype=dtypes)\ncolumns = train_df2.columns\ncolumns = list(columns)\ncolumns.remove('HasDetections')\ntest_df = pd.read_csv('..\/input\/test.csv', nrows = 2000, usecols= columns, dtype=dtypes)\n\nfor elt in numerical_columns: \n    if elt != 'HasDetections': \n        m_id = elt \n        target = 'HasDetections' \n        new_column = pd.DataFrame(columns=[m_id+'_mean_target']) \n        # mean encoding of variables\n        test_df[m_id+'_mean_target'] = new_column[m_id+'_mean_target'] \n        cumsum = train_df.groupby(m_id)[target].cumsum() - train_df[target] \n        cumcnt = train_df.groupby(m_id).cumcount() \n        test_df[m_id+'_mean_target'] = cumsum\/cumcnt\n        \ntest_df.shape","a67ca316":"xtest = test_df[col] \npreds = gbm.predict(xtest, num_iteration=gbm.best_iteration) # data_has_header=False ","cade0674":"len(preds) ","29dd4d90":"test_df.shape","54f4e3c8":"sub_sample_df = pd.read_csv('..\/input\/sample_submission.csv')\nlen(sub_sample_df)","856f9d9a":"sub_sample_df.head(2)","318edaf1":"if len(sub_sample_df) == len(preds):\n    submission = pd.DataFrame({'MachineIdentifier': sub_sample_df[\"MachineIdentifier\"], \n                               'HasDetections': preds})\n    submission.head(10)\nelse:\n    print(\"The prediction size must be: {}, but we got: {}\".format(len(sub_sample_df), len(preds)))","53554917":"#submission.to_csv(\"Micro_MP_LGBMsubmission.csv\", index=False)","cd4fe38b":"del test_df ","d9f3833e":"# np.savez Cannot handle categorical data, I have to try pandas to_pickle.","c59f82b1":"#### Backup the 'model.txt' file, the train_df. \ndel X_train\nX_test.to_pickle(\"X_test.pkl\")\nX_test_new.to_pickle(\"X_test_new.pkl\")\ny_test.to_pickle(\"y_test.pkl\") ","d9d32613":"del train_df, X_train_new, X_val_new, X_val, X_test_new, X_test","3a0904d2":"!ls","cd204453":"#### For reusing \nX_test = pd.read_pickle(\"X_test.pkl\")\nX_test.shape","fd301222":"!tar cvf 'model_backup.tar' 'model.txt' ","c772c3c1":"import shutil \nshutil.make_archive('model_backup', 'zip', '.', 'model.txt') ","5891a776":"!ls","514cdb9e":"### 5- SUBMISSION FILE CREATION","50727860":"### 3- First training & Hyperparameter Optimization","43b83085":"#### In order to reuse the saved variables for test prediction and submission, in case there is not enough memory space on Kaggle","1b8c0bcd":"#### <font color='red'>Please, unlock this part *(transform into code cell)* for fine-tuning phase.<\/font>\n### ### Hyperparameter Optimization ##############\n#### other scikit-learn modules\nestimator = lgb.LGBMClassifier(num_leaves=31)\n\n#### The parameters used are in comment below, it will take too long time to run them here\nparam_grid = {\n    'learning_rate': [0.1],\n    'n_estimators': [100, 500],\n    'num_leaves': [20, 31],\n    'min_data_in_leaf': [5, 10],\n    'reg_alpha': [0],\n    'reg_lambda': [1e-6], \n    'bagging_fraction': [0.8, 0.9],\n    'min_child_samples': [10, 20],\n    'min_child_weight': [1e-6], \n    'max_bin': [256]\n}\n\ngbm = GridSearchCV(estimator, param_grid, cv=5)\n\ngbm.fit(X_train, y_train)\n\nprint('\\n\\nBest parameters found by grid search are:', gbm.best_params_)\n\n'''\nparam_grid = {\n    'learning_rate': [0.01, 0.1, 0.05, 0.07, 1],\n    'n_estimators': [20, 40, 100, 500],\n    'num_leaves': [20, 31, 50, 127],\n    'min_data_in_leaf': [5, 10, 20, 50, 100],\n    'reg_alpha': [0, 1e-3, 1e-6],\n    'reg_lambda': [0, 1e-3, 1e-6], \n    'bagging_fraction': [0.5, 0.6, 0.7, 0.8, 0.9],\n    'min_child_samples': [10, 20, 30],\n    'min_child_weight': [5, 1e-3, 1e-6], \n    'max_bin': [255, 256]\n}\n'''\n####","c0b22d2d":"### 2- Data splitting","20ab7b42":"### 1- Data loading and Data Engineering\nLet us reduce the data size in memory","23938914":"### 4- Fine Tuning & Evaluation"}}