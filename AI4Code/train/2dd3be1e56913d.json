{"cell_type":{"077c119f":"code","eea752ef":"code","d558eb6f":"code","62eb5ad0":"code","440f5bec":"code","0d391824":"code","f5b44ef3":"code","bd28adb1":"code","79958f48":"code","b4e8d2d4":"code","6e589cbf":"code","460a941d":"code","53009e31":"code","290347e7":"markdown","1c91d6fd":"markdown","99098c54":"markdown","39b599e2":"markdown","1d3c8f5a":"markdown","50b2b1a8":"markdown","80347f75":"markdown","ba7bb81c":"markdown","fe67e3dc":"markdown","5f174102":"markdown","73a4f502":"markdown","2193a6cb":"markdown","82724429":"markdown","c68e0e74":"markdown","1981867a":"markdown","87bc0f58":"markdown"},"source":{"077c119f":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eea752ef":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","d558eb6f":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory(\"..\/input\/traffic-light-detection-dataset\/train_dataset\",\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')","62eb5ad0":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_set = test_datagen.flow_from_directory(\"..\/input\/traffic-light-detection-dataset\/test_dataset\",\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","440f5bec":"cnn = tf.keras.models.Sequential()","0d391824":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))","f5b44ef3":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","bd28adb1":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","79958f48":"cnn.add(tf.keras.layers.Flatten())","b4e8d2d4":"cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))","6e589cbf":"cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","460a941d":"cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","53009e31":"cnn.fit(x = training_set, validation_data = test_set, epochs = 5)","290347e7":"# Importing the libraries","1c91d6fd":"# Step 2 - Pooling","99098c54":"# Part 3 - Training the CNN","39b599e2":"# Preprocessing the Training set","1d3c8f5a":"# Step 3 - Flattening","50b2b1a8":"# Step 1 - Convolution","80347f75":"# Compiling the CNN","ba7bb81c":"# Preprocessing the Test set","fe67e3dc":"# Initialising the CNN","5f174102":"# Training the CNN on the Training set and evaluating it on the Test set","73a4f502":"# Step 4 - Full Connection","2193a6cb":"# Get Accuracy 100%.","82724429":"# Step 5 - Output Layer","c68e0e74":"# Adding a second convolutional layer","1981867a":"# Part 2 - Building the CNN","87bc0f58":"# Part 1 - Data Preprocessing"}}