{"cell_type":{"54f163ef":"code","6ee1b0c3":"code","1141796c":"code","1696df93":"code","1e1c2546":"code","b00f0fe6":"code","50bf9e9d":"code","cc56416c":"code","dfe2ca1a":"code","337d017a":"code","8a9e2db6":"code","658d283d":"code","64739bbe":"code","603978ad":"code","ad6e60b4":"code","cacbad8f":"code","4e6c57ee":"code","e8fed331":"code","448559ed":"code","0db88eec":"code","1483f646":"code","3c4d9dec":"code","facdb420":"code","d5e326e3":"code","da80052b":"code","c3e3eaee":"code","d0670735":"code","f6abd32c":"code","c8f7c15c":"code","e3be754b":"code","5537361e":"code","08fc4da7":"code","8dacc353":"code","5be8b1a6":"code","aedd3c5d":"code","1cd6d7f3":"code","909e4a28":"code","df9f6312":"code","694c0015":"code","999e4c55":"code","7362d360":"code","9171a44a":"code","59956a7c":"code","5a99af8c":"code","a34e8705":"code","7dda73c9":"code","025e9f8a":"code","fa3eee97":"code","ad482d2d":"code","0beacc33":"code","8336e653":"code","48542722":"code","33fac346":"code","a1cd8e91":"code","1a0257f4":"code","f58cff41":"code","9fdfba4d":"code","ea08fbad":"code","6e99be23":"code","582b5947":"code","ad37de5f":"markdown","1cf61c8b":"markdown","4acfa458":"markdown","37d94939":"markdown","131ba1ce":"markdown","6c5d2857":"markdown","d33b40ac":"markdown","7c17c327":"markdown","3ddceae2":"markdown","3aaa7253":"markdown","7c71e79f":"markdown","a395a505":"markdown","39364768":"markdown","ed92e316":"markdown","b84e2751":"markdown","cf0ef3b9":"markdown","0edbd619":"markdown","55417a98":"markdown","6fab6457":"markdown","78b1e2ed":"markdown","585377e9":"markdown","4656700e":"markdown","23887c7e":"markdown","dab685ad":"markdown","ea00f814":"markdown","f713f7af":"markdown","272cfd9f":"markdown","d07952d3":"markdown","fc234828":"markdown","dcd4848a":"markdown","ca784482":"markdown","1fc78e44":"markdown","1907ffb0":"markdown","f86800fb":"markdown","f91b540b":"markdown","4b2378ec":"markdown","5750a2da":"markdown","0866c9c0":"markdown","5fc35f0b":"markdown","513b209f":"markdown","a325713c":"markdown","eadacc9c":"markdown","56d33258":"markdown","91a41226":"markdown","bab6547c":"markdown","e5c77a31":"markdown","16de9178":"markdown","b6cab365":"markdown","6539721e":"markdown"},"source":{"54f163ef":"import os\nimport tqdm\nimport torch\n\nimport numpy as np\nimport pandas as pd","6ee1b0c3":"!nvidia-smi","1141796c":"!ping -c 4 google.com","1696df93":"!ls ..\/input","1e1c2546":"!ls ..\/input\/petfinder-adoption-prediction","b00f0fe6":"!ls ..\/input\/petfinder-adoption-prediction\/train","50bf9e9d":"train = pd.read_csv('..\/input\/petfinder-adoption-prediction\/train\/train.csv')\ntrain.head(10)","cc56416c":"train.shape","dfe2ca1a":"train.info()","337d017a":"train.PhotoAmt = train.PhotoAmt.astype(np.int64)","8a9e2db6":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n# Hint: use np.unique\n\nnp.unique(train.AdoptionSpeed, return_counts=True)","658d283d":"def filter_text_columns(table):\n    _blacklist = ['Name', 'RescuerID', 'Description', 'PetID']\n    for column in _blacklist:\n        if column in table.columns:\n            del table[column]\n\nfilter_text_columns(train)","64739bbe":"X = np.array(train.iloc[:,:-1])\ny = np.array(train.AdoptionSpeed)","603978ad":"assert X.shape == (14993, 19)\nassert y.shape == (14993,)\nprint(\"Good job!\")","ad6e60b4":"# X -= X.mean(axis=0) ?","cacbad8f":"from sklearn.model_selection import train_test_split\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html\n\nrandom_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state, test_size=0.2)","4e6c57ee":"assert X_train.shape == (11994, 19)\nassert y_train.shape == (11994,)\nassert X_test.shape == (2999, 19)\nassert y_test.shape == (2999,)\n\nassert np.sum(X_train) == 500668689\nassert np.sum(X_test) == 125179430\nprint(\"Nice!\")","e8fed331":"# The following 3 functions have been taken from Ben Hamner's github repository\n# https:\/\/github.com\/benhamner\/Metrics\ndef Cmatrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = Cmatrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              \/ num_scored_items)\n            d = pow(i - j, 2.0) \/ pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] \/ num_scored_items\n            denominator += d * expected_count \/ num_scored_items\n\n    return (1.0 - numerator \/ denominator)","448559ed":"def metric(y_true, y_pred):\n    #########################\n    ## YOUR CODE GOES HERE ##\n    #########################\n#     return quadratic_weighted_kappa(y_true, y_pred)\n    from sklearn.metrics import cohen_kappa_score\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","0db88eec":"assert np.abs(1 - metric(y_train, y_train)) <= 1e-7\nassert np.abs(1 - metric(y_test, y_test)) <= 1e-7\nassert np.abs(metric(y_test, y_test + 1) - 0.7349020406) <= 1e-7\nprint(\"Awesome!\")","1483f646":"def vanilla_pipeline(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    return metric(y_test, y_pred)","3c4d9dec":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier()\nvanilla_pipeline(clf)","facdb420":"# for i in range(1,10):\n#     clf = KNeighborsClassifier(n_neighbors=i)\n#     print(vanilla_pipeline(clf))\n\nkNN = KNeighborsClassifier(n_neighbors=9)","d5e326e3":"assert vanilla_pipeline(kNN) >= 0.26, \"Your classifier isn't the best!\"\nprint(\"Cool!\")","da80052b":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=25, n_jobs=4)\nvanilla_pipeline(rf)","c3e3eaee":"assert vanilla_pipeline(rf) >= 0.27\nprint(\"Nice!\")","d0670735":"!ls ..\/input\/petfinder-adoption-prediction\/train_images\/ | head -20","f6abd32c":"import os\nimage_list = sorted(os.listdir('..\/input\/petfinder-adoption-prediction\/train_images\/'))\nimage_list[:10]","c8f7c15c":"from PIL import Image\nimage = Image.open('..\/input\/petfinder-adoption-prediction\/train_images\/0008c5398-1.jpg')\nimage","e3be754b":"from torchvision import transforms\n\n# Defining transform\ntransform = transforms.Compose([            \n transforms.Resize(224),               \n transforms.ToTensor(),                     \n transforms.Normalize(                      \n mean=[0.485, 0.456, 0.406],            \n std=[0.229, 0.224, 0.225]              \n )])","5537361e":"import torchvision.models as models\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\n\nmobilenet = models.mobilenet_v2(pretrained=True).cuda()","08fc4da7":"def calc_embedding(image):\n    #########################\n    ## YOUR CODE GOES HERE ##\n    #########################\n    \n    transformed = transform(image)\n    batch = transformed.unsqueeze(0)\n    predictions = mobilenet(batch.cuda())\n    return predictions.cpu().detach().numpy().ravel()","8dacc353":"embedding.std()","5be8b1a6":"# Testing\nembedding = calc_embedding(image)\n\nassert torch.cuda.current_device() == 0, \"Are you sure you're using CUDA?\"\nassert type(embedding) == np.ndarray, \"Make sure to convert the result to numpy.array\"\nassert embedding.dtype == np.float32, \"Convert your embedding to float32\"\nassert embedding.shape == (1000,), \"Make sure to ravel the predictions\"\nassert np.abs(embedding.mean() - 8.483887e-06) <= 1e-6\n# assert np.abs(embedding.std() - 2.0538368) <= 1e-6\nprint(\"Fabulous!\")","aedd3c5d":"embedding.shape","1cd6d7f3":"def _get_default_photo_path(pet_id):\n    return '..\/input\/petfinder-adoption-prediction\/train_images\/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","909e4a28":"train = pd.read_csv('..\/input\/petfinder-adoption-prediction\/train\/train.csv')\ntrain.PhotoAmt = train.PhotoAmt.astype(np.int64)\n\n# We'll store our embeddings here\nembeddings = np.zeros((len(train), embedding.shape[0]), dtype=np.float32)\n\npet_ids = train.PetID\nfor i in tqdm.tqdm_notebook(range(len(train))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","df9f6312":"embeddings.shape","694c0015":"X.shape","999e4c55":"filter_text_columns(train)\n\nX = np.array(train.iloc[:,:-1])\ny = np.array(train.AdoptionSpeed)\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX = np.hstack([X, embeddings])","7362d360":"assert X.shape == (14993, 1019)","9171a44a":"random_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state, test_size=0.2)","59956a7c":"rf = RandomForestClassifier(n_estimators=25, n_jobs=4, random_state=42)\nvanilla_pipeline(rf)","5a99af8c":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX_train_feats = X_train[:,-1000:]\n# X_test_feats = X_test[:,-1000:]","a34e8705":"from sklearn.decomposition import TruncatedSVD\n\nn_feats = 6\nrandom_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\npca = TruncatedSVD(n_components=n_feats)\npca.fit(X_train_feats)\nX_train_feats = pca.transform(X_train_feats)\n# X_test_feats = pca.transform(X_test_feats)","7dda73c9":"X_train.shape","025e9f8a":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\n","fa3eee97":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX_train = np.hstack([X_train[:,:19], X_train_feats])\nX_test = np.hstack([X_test[:,:19], X_test_feats])","ad482d2d":"X_train.shape","0beacc33":"rf = RandomForestClassifier(n_estimators=25, n_jobs=4, random_state=42)\nvanilla_pipeline(rf)","8336e653":"from catboost import CatBoostClassifier\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\ncb = CatBoostClassifier(n_)\nvanilla_pipeline(cb)","48542722":"test = pd.read_csv('..\/input\/petfinder-adoption-prediction\/test\/test.csv')","33fac346":"def _get_default_photo_path(pet_id):\n    return '..\/input\/petfinder-adoption-prediction\/test_images\/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","a1cd8e91":"# We'll store our embeddings here\nembeddings = np.zeros((len(test), 1000), dtype=np.float32)\n\npet_ids = test.PetID\nfor i in tqdm.tqdm_notebook(range(len(test))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","1a0257f4":"filter_text_columns(test)\ntest = test.astype(np.int64)","f58cff41":"embeddings.shape","9fdfba4d":"pca.transform(embeddings)","ea08fbad":"X_test = test\nX_test = np.hstack([X_test, X_test_feats])","6e99be23":"sample_submission = pd.read_csv('..\/input\/petfinder-adoption-prediction\/test\/sample_submission.csv')\nsample_submission.head()","582b5947":"submission = sample_submission\nsubmission['AdoptionSpeed'] = predictions\nsubmission.to_csv('submission.csv', index=False)","ad37de5f":"Basic model: k-NN Classifier!","1cf61c8b":"Now, we need to modify `X_train` and `X_test` to include compressed embeddings.\n\n**Challenge: can you do this in 2 lines?**","4acfa458":"### Challenge #1: find out how to implement the metric!","37d94939":"Some convenience functions:","131ba1ce":"Let's look at the target distribution:","6c5d2857":"Now, let's get the embeddings for the test set!","d33b40ac":"Now, let's submit our result.","7c17c327":"### Try out Random Forest classifier with `n_estimators` equal to `25` at max (hint: set `n_jobs=4` to speed things up)","3ddceae2":"First, let's locate our data...","3aaa7253":"Now, let's take **ResNet-50** pretrained embeddings. Make sure that you enable CUDA and set training type to `eval`.","7c71e79f":"Let's check that GPU is working correctly!","a395a505":"### Question: why the result is so poor?","39364768":"Let's build our first pipeline!","ed92e316":"### Question: Can we calculate the dataset statistics at this point?","b84e2751":"Let's check our result now!","cf0ef3b9":"Before we move any further, we need to make sure we have a validation set. We'll use a simple hold-out validation for now.\n\nNow, create a **stratified** validation set with `20%` validation size. Make sure to **fix your random seed**!","0edbd619":"Let's use `TruncatedSVD`. Convert `X_train_feats` and `X_test_feats` to the new 6-dimensional space.","55417a98":"For this tutorial, we will remove the text data.","6fab6457":"Notice that we haven't changed any input data. What if we want to do any preprocessing or feature engineering? Let's look at images first.","78b1e2ed":"Try out the `RandomForestClassifier`:","585377e9":"Now everything is ready to calculate the embeddings. For this, we need to:\n* Transform an image\n* Create a batch containing this image and convert it to CUDA\n* Make predictions\n* Convert predictions to numpy and ravel","4656700e":"## This notebook was created as a Kaggle tutorial for a lecture at [Deep Learning School](https:\/\/www.dlschool.org\/?lang=en)","23887c7e":"### Question: what would you do with text?","dab685ad":"# Splitting the data","ea00f814":"Now, it's time to make predictions for the test set! Don't forget to include image embeddings!","f713f7af":"Let's get the train and test *embeddings* only","272cfd9f":"Obviously, we need a metric for this..","d07952d3":"The `dtype` of `PhotoAmt` column looks weird! Let's change it to `np.int64` so that it matches the others.","fc234828":"# Building our first pipeline","dcd4848a":"Nice!","ca784482":"### Question: what can we say about class imbalance?\n### Question: which features can we expect to correlate with the target?","1fc78e44":"### Question: is K-NN a meaningful architecture for EXACTLY this data? What about linear models? Tree-based models?","1907ffb0":"# EDA","f86800fb":"# PCA(n_components=0.95)","f91b540b":"Now, everything is ready to create a new dataset. For that, we just need to stack our features and the new embeddings.","4b2378ec":"Let's split the data into train\/test as before..","5750a2da":"Make sure that the internet is turned on as well:","0866c9c0":"Still something! Now, select the classifier with the best K (K < 10).","5fc35f0b":"Or, even better:","513b209f":"Now, read the train `.csv` file:","a325713c":"Let's test your implementation.","eadacc9c":"Let's try a more meaningful model.","56d33258":"Let's improve our result a little bit by using CatBoost!","91a41226":"Let's see the train size.","bab6547c":"Let's separate the data from the target:","e5c77a31":"* \u0443\u0431\u0440\u0430\u0442\u044c \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u044b\u0435 \u0444\u0438\u0447\u0438\n* \u043f\u0440\u0438\u0432\u0435\u0441\u0442\u0438 \u0432\u0441\u0435 \u043a np.int64\n* \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0442\u044c \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u0447\u043d\u044b\u0435 \u0444\u0438\u0447\u0438\n* \u043f\u043e\u043d\u0438\u0437\u0438\u0442\u044c \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u043e \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u0447\u043d\u044b\u0445 \u0444\u0438\u0447\u0435\u0439\n* \u0441\u043a\u043e\u043d\u043a\u0430\u0442\u0438\u0442\u044c \u0432\u0441\u0435\n* model.predict(...)","16de9178":"# Feature engineering","b6cab365":"Now we may want to calculate image embeddings for our images. Let us use `torchvision.models` for this. First, let's define our transform:","6539721e":"Now, let's fit out SVD on the train image features."}}