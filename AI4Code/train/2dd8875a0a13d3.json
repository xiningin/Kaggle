{"cell_type":{"31554a7e":"code","d7a6babf":"code","1719e0cb":"code","73c57c91":"code","34d9e74a":"code","4e0b8986":"code","97e22ad6":"code","e432c504":"code","fbafc576":"code","33125e83":"code","467a4fd7":"code","393bf405":"code","18865ce8":"code","1b91a12f":"code","f217d593":"code","2effa03e":"code","5ac4062a":"code","c451a055":"code","be26a555":"code","41e654f4":"code","33a6300b":"code","b7f825e6":"code","b82ed43a":"code","61e77564":"code","cfc0bafa":"code","316e1635":"code","ec289048":"code","0b5c4ea1":"code","b9a19f94":"code","e5e6eb5a":"code","17e231e0":"code","f9c6c983":"code","3b835c5c":"markdown","76b84d7b":"markdown","591488f4":"markdown","f4ce9779":"markdown","64521a34":"markdown","973b577d":"markdown","3b7ecc07":"markdown","faae7526":"markdown","dbeaf8a2":"markdown","ca237bd9":"markdown","11d01c50":"markdown","56bb99f5":"markdown","b514e1fd":"markdown","45048e3b":"markdown","45d1a1c5":"markdown","70f4bf84":"markdown","0d83911b":"markdown","7a65f7a7":"markdown","660b1d68":"markdown","1a8bff30":"markdown","203675df":"markdown","6a0f387b":"markdown","5081e952":"markdown","7c1323f0":"markdown","5e9b62ee":"markdown","e010f49f":"markdown","72fea004":"markdown","cf17de94":"markdown","a715fac7":"markdown","77593e95":"markdown","a4ba2cb1":"markdown","add926fc":"markdown","c3d9fdcc":"markdown"},"source":{"31554a7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.ignore(\"warnings\")\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7a6babf":"import torch\nimport torch.nn as nn # neural networks\nimport torch.nn.functional as F\nfrom PIL import Image # PIL library for read images\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time","1719e0cb":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \nprint(\"Device:\", device)","73c57c91":"def read_images(path, num_img):\n    array = np.zeros([num_img, 64*32]) # it looks like zero array [number_of_images, 64*32] 64*32 (2048 column)\n    i = 0\n    for img in os.listdir(path):\n        img_path = path + \"\/\/\" + img \n        img = Image.open(img_path, mode = \"r\")\n        data = np.asarray(img, dtype = \"uint8\")\n        data = data.flatten() # 1x2048\n        array[i,:] = data # 1x2048(64*32) img to new array\n        i += 1\n    return array","34d9e74a":"train_negative_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Train\/neg'\nnum_train_neg_img = 43390\ntrain_negative_array = read_images(train_negative_path, num_train_neg_img)","4e0b8986":"print(\"x_train_negative_array_shape:\", train_negative_array.shape)\ntrain_negative_array","97e22ad6":"test_negative_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Test\/neg'\nnum_test_neg_img = 22050\ntest_negative_array = read_images(test_negative_path, num_test_neg_img)","e432c504":"print(\"x_test_negative_array_shape:\", test_negative_array.shape)\ntest_negative_array","fbafc576":"train_positive_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Train\/pos'\nnum_train_pos_img = 10208\ntrain_positive_array = read_images(train_positive_path, num_train_pos_img)","33125e83":"print(\"x_train_positive_array_shape:\", train_positive_array.shape)\ntrain_positive_array","467a4fd7":"test_positive_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Test\/pos'\nnum_test_pos_img = 5944\ntest_positive_array = read_images(test_positive_path, num_test_pos_img)","393bf405":"print(\"x_test_positive_array_shape:\", test_positive_array.shape)\ntest_positive_array","18865ce8":"x_train_negative_tensor = torch.from_numpy(train_negative_array) ## numpy to tensor for using torch\nprint(\"x_train_negative_tensor:\", x_train_negative_tensor.size())\ny_train_negative_tensor = torch.zeros(num_train_neg_img, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_train_negative_tensor:\", y_train_negative_tensor.size())","1b91a12f":"x_test_negative_tensor = torch.from_numpy(test_negative_array[:20855,:]) ## numpy to tensor for using torch\nprint(\"x_test_negative_tensor:\", x_test_negative_tensor.size())\ny_test_negative_tensor = torch.zeros(20855, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_test_negative_tensor:\", y_test_negative_tensor.size())","f217d593":"x_train_positive_tensor = torch.from_numpy(train_positive_array) ## numpy to tensor for using torch\nprint(\"x_train_positive_tensor:\", x_train_positive_tensor.size())\ny_train_positive_tensor = torch.ones(num_train_pos_img, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_train_positive_tensor:\", y_train_positive_tensor.size())","2effa03e":"x_test_positive_tensor = torch.from_numpy(test_positive_array) ## numpy to tensor for using torch\nprint(\"x_test_positive_tensor:\", x_test_positive_tensor.size())\ny_test_positive_tensor = torch.ones(num_test_pos_img, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_test_positive_tensor:\", y_test_positive_tensor.size())","5ac4062a":"x_train = torch.cat((x_train_negative_tensor, x_train_positive_tensor), 0)\ny_train = torch.cat((y_train_negative_tensor, y_train_positive_tensor), 0)\nprint(\"x_train:\", x_train.size())\nprint(\"y_train:\", y_train.size())","c451a055":"x_test = torch.cat((x_test_negative_tensor, x_test_positive_tensor), 0)\ny_test = torch.cat((y_test_negative_tensor, y_test_positive_tensor), 0)\nprint(\"x_test:\", x_test.size())\nprint(\"y_test:\", y_test.size())","be26a555":"plt.imshow(x_train[45001,:].reshape(64, 32),)","41e654f4":"plt.imshow(x_train[45001,:].reshape(64, 32), cmap = \"gray\")","33a6300b":"num_epochs = 50 #5000\nnum_classes = 2\nbatch_size = 100 #8933\nlr = 0.00001\n\n","b7f825e6":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv1 = nn.Conv2d(1, 10, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 16, 5)\n        \n        self.fc1 = nn.Linear(16*13*5, 520) # fully connected layer\n        self.fc2 = nn.Linear(520, 130) \n        self.fc3 = nn.Linear(130, num_classes)\n        \n# # conv1 > relu > pooling > conv2 > relu > pooling > flatten > fc1 > relu > fc2 > relu > output\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x))) \n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16*13*5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    ","b82ed43a":"import torch.utils.data\n\ntrain = torch.utils.data.TensorDataset(x_train, y_train)\ntrainloader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = \"True\")\n\ntest = torch.utils.data.TensorDataset(x_test, y_test)\ntestloader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = \"True\")\n\nnet = Net().to(device) #for gpu\/cpu","61e77564":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr = lr, momentum = 0.8)\n\n","cfc0bafa":"start = time.time()\ntrain_acc = []\ntest_acc = []\nloss_list = []\n\nuse_gpu = True # False for cpu\n\nfor epoch in range(num_epochs): \n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs = inputs.view(inputs.size(0), 1, 64, 32) # reshape\n        inputs = inputs.float() # float\n        \n        #use gpu\n        if use_gpu:\n            if torch.cuda.is_available():\n                inputs, labels = inputs.to(device), labels.to(device)\n\n        #zero gradient\n        optimizer.zero_grad()\n        \n        #forward\n        outputs = net(inputs)\n        \n        #loss\n        loss = criterion(outputs, labels)\n        \n        #back\n        loss.backward()\n        \n        #update weights\n        optimizer.step()\n        \n    #test\n    \n    correct = 0\n    total = 0\n    with torch.no_grad(): # cancel back propagation\n        for data in testloader:\n            images, labels = data \n            images = images.view(images.size(0), 1, 64, 32)\n            images = images.float()\n            \n            #use gpu\n            if use_gpu:\n                if torch.cuda.is_available():\n                    images, labels = images.to(device), labels.to(device)\n            \n            outputs = net(images)\n            \n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    acc1 = 100 * (correct \/ total)\n    print(\"accuracy test\", acc1)\n    test_acc.append(acc1)\n    \n    #train\n    \n    correct = 0\n    total = 0\n    with torch.no_grad(): # cancel back propagation\n        for data in trainloader:\n            images, labels = data \n            images = images.view(images.size(0), 1, 64, 32)\n            images = images.float()\n            \n            #use gpu\n            if use_gpu:\n                if torch.cuda.is_available():\n                    images, labels = images.to(device), labels.to(device)\n            \n            outputs = net(images)\n            \n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    acc2 = 100 * (correct \/ total)\n    print(\"accuracy train\", acc2)\n    train_acc.append(acc2)\n    \nprint(\"train is done\")\n    \nend = time.time()\nprocess_time = (end - start) \/ 60\nprint(\"process time:\", process_time)","316e1635":"fig, ax1 = plt.subplots()\nplt.plot(loss_list, label = \"Loss\", color = \"blue\")\nax2 = ax1.twinx()\nax2.plot(np.array(test_acc)\/100, label = \"Test Acc\", color = \"green\")\nax2.plot(np.array(train_acc)\/100, label = \"Train Acc\", color = \"red\")\nax1.legend()\nax2.legend()\nax1.set_xlabel(\"Epoch\")\nfig.tight_layout()\nplt.title(\"Loss vs Test Accuracy\")\nplt.show()\n","ec289048":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.ignore(\"warnings\")\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b5c4ea1":"import torch\nimport torch.nn as nn # neural networks\nimport torch.nn.functional as F\nfrom PIL import Image # PIL library for read images\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport torch.utils.data\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \nprint(\"Device:\", device)\n\n#read images func\n\ndef read_images(path, num_img):\n    array = np.zeros([num_img, 64*32]) # it looks like zero array [number_of_images, 64*32] 64*32 (2048 column)\n    i = 0\n    for img in os.listdir(path):\n        img_path = path + \"\/\/\" + img \n        img = Image.open(img_path, mode = \"r\")\n        data = np.asarray(img, dtype = \"uint8\")\n        data = data.flatten() # 1x2048\n        array[i,:] = data # 1x2048(64*32) img to new array\n        i += 1\n    return array\n\n#read train negative\ntrain_negative_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Train\/neg'\nnum_train_neg_img = 43390\ntrain_negative_array = read_images(train_negative_path, num_train_neg_img)\nx_train_negative_tensor = torch.from_numpy(train_negative_array[:42000, :]) ## numpy to tensor for using torch\nprint(\"x_train_negative_tensor:\", x_train_negative_tensor.size())\ny_train_negative_tensor = torch.zeros(42000, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_train_negative_tensor:\", y_train_negative_tensor.size())\n\n#read train positive \ntrain_positive_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Train\/pos'\nnum_train_pos_img = 10208\ntrain_positive_array = read_images(train_positive_path, num_train_pos_img)\nx_train_positive_tensor = torch.from_numpy(train_positive_array[:10000, :]) ## numpy to tensor for using torch\nprint(\"x_train_positive_tensor:\", x_train_positive_tensor.size())\ny_train_positive_tensor = torch.ones(10000, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_train_positive_tensor:\", y_train_positive_tensor.size())\n\n#concat train\nx_train = torch.cat((x_train_negative_tensor, x_train_positive_tensor), 0)\ny_train = torch.cat((y_train_negative_tensor, y_train_positive_tensor), 0)\nprint(\"x_train:\", x_train.size())\nprint(\"y_train:\", y_train.size())\n\n\n#read test negative\ntest_negative_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Test\/neg'\nnum_test_neg_img = 22050\ntest_negative_array = read_images(test_negative_path, num_test_neg_img)\nx_test_negative_tensor = torch.from_numpy(test_negative_array[:18056,:]) ## numpy to tensor for using torch\nprint(\"x_test_negative_tensor:\", x_test_negative_tensor.size())\ny_test_negative_tensor = torch.zeros(18056, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_test_negative_tensor:\", y_test_negative_tensor.size())\n\n#read test positive\ntest_positive_path = r'\/kaggle\/input\/lsifir\/LSIFIR\/Classification\/Test\/pos'\nnum_test_pos_img = 5944\ntest_positive_array = read_images(test_positive_path, num_test_pos_img)\nx_test_positive_tensor = torch.from_numpy(test_positive_array) ## numpy to tensor for using torch\nprint(\"x_test_positive_tensor:\", x_test_positive_tensor.size())\ny_test_positive_tensor = torch.ones(num_test_pos_img, dtype = torch.long) ## this is y_train tensor for labels\nprint(\"y_test_positive_tensor:\", y_test_positive_tensor.size())\n\n#concat test\nx_test = torch.cat((x_test_negative_tensor, x_test_positive_tensor), 0)\ny_test = torch.cat((y_test_negative_tensor, y_test_positive_tensor), 0)\nprint(\"x_test:\", x_test.size())\nprint(\"y_test:\", y_test.size())\n\n#hyperparameter\nnum_epochs = 20 #100\nnum_classes = 2\nbatch_size = 100 #2000\nlr = 0.00001\n\ntrain = torch.utils.data.TensorDataset(x_train, y_train)\ntrainloader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = \"True\")\n\ntest = torch.utils.data.TensorDataset(x_test, y_test)\ntestloader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = \"True\")","b9a19f94":"# x > conv > bn > relu > max pool > layer 1> layer 2> layer 3> avgpool > flatten > fc > output\n\n\ndef conv3x3(in_planes, output_planes, stride = 1):\n    return nn.Conv2d(in_planes, output_planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n\ndef conv1x1(in_planes, output_planes, stride = 1):\n    return nn.Conv2d(in_planes, output_planes, kernel_size = 1, stride = stride, bias = False)\n\nclass BasicBlock(nn.Module):\n    \n    expansion = 1\n    \n    def __init__(self, inplanes, planes, stride = 1, downsample = None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace = True)\n        self.drop = nn.Dropout(0.9)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n        \n    def forward(self, x):\n        identity = x #shortcut\n        \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.drop(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.drop(out) \n        \n        if self.downsample is not None:\n            identity = self.downsample(x)\n            \n        out = out + identity\n        out = self.relu(out)\n        return out\n        \nclass ResNet(nn.Module):\n    \n    def __init__(self, block, layers, num_classes = num_classes):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace = True)\n        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n        self.layer1 = self._make_layer(block, 64, layers[0], stride = 1)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride = 2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride = 1)\n    \n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(256*block.expansion, num_classes)\n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)       \n        \n    def _make_layer(self, block, planes, blocks, stride = 1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes*block.expansion:\n            downsample = nn.Sequential(\n                        conv1x1(self.inplanes, planes*block.expansion, stride),\n                        nn.BatchNorm2d(planes*block.expansion))\n            \n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes*block.expansion\n         \n        for _ in range(1,blocks):\n            layers.append(block(self.inplanes, planes))\n            \n        return nn.Sequential(*layers)\n    \n        \n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        \n        return x        ","e5e6eb5a":"model = ResNet(BasicBlock, [2,2,2]).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = lr)","17e231e0":"# delete \"\"\"(at the beginning and end) while you run the code\n\n\"\"\"loss_list = []\ntrain_acc = []\ntest_acc = []\nuse_gpu = True\n\ntotal_step = len(trainloader)\n\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(trainloader):\n        \n        images = images.view(images.size(0), 1, 64, 32)\n        images = images.float()\n        \n        if use_gpu:\n            if torch.cuda.is_available():\n                images, labels = images.to(device), labels.to(device)\n                \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n        \n        #backward and optimization \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i % 2 == 0:\n            print(\"epoch: {} {}\/{}\".format(epoch, i, total_step))\n         \n        # train \n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for data in trainloader:\n                images, labels = data\n                images = images.view(images.size(0), 1, 64, 32)\n                images = images.float()\n                \n                if use_gpu:\n                    if torch.cuda.is_available():\n                        images, labels = images.to(device), labels.to(device)\n                \n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                \n        print(\"Accuracy train: %d %%\" %(100*correct\/total))\n        train_acc.append(100*correct\/total)\n            \n        # test \n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for data in testloader:\n                images, labels = data\n                images = images.view(images.size(0), 1, 64, 32)\n                images = images.float()\n                \n                if use_gpu:\n                    if torch.cuda.is_available():\n                        images, labels = images.to(device), labels.to(device)\n                \n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                \n        print(\"Accuracy test: %d %%\" %(100*correct\/total))\n        test_acc.append(100*correct\/total)\n        \n        loss_list.append(loss.item())\n        \n        \n            \n            \"\"\"","f9c6c983":"fig, ax1 = plt.subplots()\nplt.plot(loss_list, label = \"Loss\", color = \"blue\")\nax2 = ax1.twinx()\nax2.plot(np.array(test_acc)\/100, label = \"Test Acc\", color = \"green\")\nax2.plot(np.array(train_acc)\/100, label = \"Train Acc\", color = \"red\")\nax1.legend()\nax2.legend()\nax1.set_xlabel(\"Epoch\")\nfig.tight_layout()\nplt.title(\"Loss vs Test Accuracy\")\nplt.show()","3b835c5c":"## Hyperparameter","76b84d7b":"# GPU or CPU? \n\n* CUDA is a parallel computing platform and programming model developed by Nvidia for general computing on its own GPUs (graphics processing units).\n* CUDA enables developers to speed up compute-intensive applications by harnessing the power of GPUs for the parallelizable part of the computation.\n* if you have CUDA, you can use your GPU. There is a code below this area, it can be useful for train your model with GPU. Print section shows which power unit that you use now.","591488f4":"# Loss Function and Optimizer","f4ce9779":"Accuracy = 98.45","64521a34":"# Tensor for Positive Images\n\n* Using torch.ones because of using Positive Images","973b577d":"# Introduction\n\n* The database consists of FIR images collected from a vehicle driven in outdoors urban scenarios. Images were acquired with an Indigo Omega imager, with a resolution of 164x129 pixels, a grey-level scale of 14 bits, and focal length of 318 pixels.\n\n* The camera was mounted on the exterior of the vehicle, to avoid infrared filtering of the windshield. Recorded images were manually annotated, where each pedestrian is labelled as a bounding box. To prevent bias introduced by border artifacts their height is subsequently upscaled by 5%. \n\n![image.png](attachment:image.png)\n\nThe dataset is divided in two: \n    1. Classification dataset: positives and randomly sampled negatives with a fixed height-width ratio of (1\/2) and rescaled to 64x32 pixels, \n    2. Detection Dataset: Original positive and negative images with annotations.\n    \n    \n**Note:** Only upright persons, with height over 10 pixels are annotated. Annotations may not be 100%right; in some exceptional cases, parts of the pedestrians may fall outside of the bounding box. Partially occluded pedestrians, or pedestrians not entirely contained inside the image are not labeled. The images were acquired in sequences thus, eventually, two consecutive images may in fact be the same.\n\n\n","3b7ecc07":"# Tensor for Negative Images\n\n* Using torch.zeros because of using Negative Images","faae7526":"# Concating Tensors","dbeaf8a2":"## Classification Database\n\n1. The classification Database is divided in a Train and a Test subset. \n2. The Train set contains 10208 positives and 43390 negatives, while the Test set contains 5944 positives and 22050 negatives. \n3. The annotated bounding boxes are resized to a constant aspect ratio (w\/h) = 0.5 by changing their width appropriately. Any bounding box below 10 pixels in height is ignored. \n4. The remaining bounding boxes are resized to 64x32 pixels using bilinear interpolation. \n5. The negative samples were randomly selected from images not containing pedestrians.","ca237bd9":"# Read Data Images","11d01c50":"## Test Dataset","56bb99f5":"## Train Dataset","b514e1fd":"# Train a Network","45048e3b":"# Converting Numpy to Tensor","45d1a1c5":"# Read Negative Images","70f4bf84":"* We will train our model with CNN and ResNet algorithms via Pytorch. \n* Example of CNN architecture\n![image.png](attachment:image.png)\n","0d83911b":"# Visualization of Images","7a65f7a7":"# Create CNN Model\n\n* In a convolution neural network we try to learn some matricies, which are called kernels, convolutional matrix or mask. These kernels are features present in the images. It can be some border, some shape, or even some complex parts like nose, eyes etc.\n\n![image.png](attachment:image.png)","660b1d68":"![image.png](attachment:image.png)","1a8bff30":"## Define Functions Model","203675df":"## Detection Database\n\n1. The detection dataset was acquired in 13 different sessions, each containing a varying number of images. \n2. It comprises 15224 14 bit one channel images, with dimension 164x129 pixels. \n3. The Train set contains 6159 images, and the Test set contains 9065 images. \n4. Folders 'Train' and 'Test' correspond, respectively, to original training and testing images. Both folders have one subfolder for each independent sequence and a folder for the annotations files. ","6a0f387b":"## Test Dataset","5081e952":"## Train Dataset","7c1323f0":"![image.png](attachment:image.png)","5e9b62ee":"## Test Dataset","e010f49f":"## Train Dataset","72fea004":"# Create ResNet Model\n\n* If you train your data with ResNet Model you can run code after this section","cf17de94":"## Train Dataset","a715fac7":"# Importing","77593e95":"## Test Dataset","a4ba2cb1":"# Read Positive Images","add926fc":"## Train Dataset","c3d9fdcc":"## Test Dataset"}}