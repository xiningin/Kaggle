{"cell_type":{"603d79f7":"code","3b806a07":"code","43646898":"code","e0c9395e":"code","e91d6388":"code","2c560fbf":"code","0f51acc2":"code","908f86a1":"code","5bb18bb7":"code","daa864eb":"code","05fa9f1b":"code","b4de4939":"code","2fe6ee65":"code","820e4d0e":"code","14f107bb":"code","35f3ffba":"code","5d196176":"code","08854bf6":"code","a50b64a1":"code","335c4074":"code","83e35c93":"code","9c2d50a7":"markdown","9c0daa36":"markdown","991fe47e":"markdown","ed0a9e40":"markdown","dd7217db":"markdown","4f64f4eb":"markdown","e8486c22":"markdown","4015cf88":"markdown","5bfb9020":"markdown","579c18e0":"markdown","d2fd1759":"markdown","61ca1bc1":"markdown","524fa170":"markdown","aff392c7":"markdown"},"source":{"603d79f7":"\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","3b806a07":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","43646898":"!pip install -U --pre efficientnet\nimport efficientnet.keras as efn\n","e0c9395e":"PATH='..\/input\/chest_xray\/'\ntraining_path=os.path.join(PATH, 'chest_xray\/train')\ntesting_path=os.path.join(PATH, 'chest_xray\/test')","e91d6388":"bs=8\nimg_size=384\nepoch=5\n","2c560fbf":"train_aug=ImageDataGenerator(rescale=1.\/255,validation_split=0.2,rotation_range=15,fill_mode='nearest')\ntest_aug=ImageDataGenerator(rescale=1.\/255)\n","0f51acc2":"train_gen=train_aug.flow_from_directory(batch_size=bs,directory=training_path,shuffle=True,target_size=(img_size,img_size),class_mode='categorical')\nvalid_gen=train_aug.flow_from_directory(batch_size=bs,directory=training_path,shuffle=True,target_size=(img_size,img_size),class_mode='categorical',subset='validation')\ntest_gen=test_aug.flow_from_directory(batch_size=1,directory=testing_path,shuffle=False,target_size=(img_size,img_size),class_mode='categorical')","908f86a1":"matrix=[\"accuracy\",\n        tf.keras.metrics.TruePositives(name='tp'),\n        tf.keras.metrics.FalsePositives(name='fp'),\n        tf.keras.metrics.TrueNegatives(name='tn'),\n        tf.keras.metrics.FalseNegatives(name='fn'), \n        #keras.metrics.BinaryAccuracy(name='bin_accuracy'),\n        #keras.metrics.Precision(name='precision'),\n        #keras.metrics.Recall(name='recall'),\n        tf.keras.metrics.AUC(name='auc'),\n    ]","5bb18bb7":"def eff_model():\n    base_model=efn.EfficientNetB0(weights='imagenet',include_top=False,pooling='avg',input_shape=(img_size,img_size,3))\n    x= tf.keras.layers.Flatten()(base_model.output)\n    x =tf.keras.layers.Dense(1024,activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x =tf.keras.layers.Dense(512,activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x =tf.keras.layers.Dense(256,activation='relu')(x)\n    x =tf.keras.layers.Dense(3,activation='softmax')(x)\n    \n    return tf.keras.Model(base_model.input,x)\n\n\ndef compiler():\n    opt=tf.keras.optimizers.Adam(learning_rate=1e-3,amsgrad=True)\n    model=eff_model()\n    model.compile(optimizer=opt,loss=tf.keras.losses.CategoricalCrossentropy(),metrics=matrix)\n    \n    return model","daa864eb":"model=compiler()","05fa9f1b":"chk_path='kaggle\/working\/weights'\nmodel_chk_callback=tf.keras.callbacks.ModelCheckpoint(\n  filepath=chk_path,\n  save_weights_only=True,\n  monitor='val_accuracy',\n  mode='max',\n  save_best_only=True,\n  verbose=1,\n)\n","b4de4939":"reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=2,min_lr=1e-7,verbose=1)\n\nearly=tf.keras.callbacks.EarlyStopping(monitor='val_accruracy',patience=6)","2fe6ee65":"STEP_SIZE_TRAIN=train_gen.n\/\/train_gen.batch_size\nSTEP_SIZE_VALID=valid_gen.n\/\/valid_gen.batch_size\n\n# Already calculated - this would make model to learn more from samples which low in number in our case - Covid\nclassweights={0: 4.357,\n             1:1.462,\n             2:0.4792}\n#2.23929825 1.58637832 0.52000326\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch=STEP_SIZE_TRAIN,\n    epochs=5,\n    validation_data=valid_gen,\n    validation_steps=STEP_SIZE_VALID,\n    callbacks=[model_chk_callback,reduce_lr,early],\n    class_weight=classweights,\n    verbose=1\n)  ","820e4d0e":"from sklearn.metrics import confusion_matrix\ny_test =test_gen.classes\nnb_samples = len(y_test)\npred = model.predict_generator(test_gen, nb_samples)\npred= np.argmax(pred, axis=1)\n\nprint(pred)\n\n\nmatrix = confusion_matrix(y_test, pred)\nmatrix = matrix.astype('float')\n#cm_norm = matrix \/ matrix.sum(axis=1)[:, np.newaxis]\nprint(matrix)\n\n\nclass_acc = [matrix[i,i]\/np.sum(matrix[i,:]) if np.sum(matrix[i,:]) else 0 for i in range(len(matrix))]\nprint('Sens covid: {0:.3f}, Normal: {1:.3f}, pneumonia : {2:.3f}'.format(class_acc[0],class_acc[1],class_acc[2]))\nppvs = [matrix[i,i]\/np.sum(matrix[:,i]) if np.sum(matrix[:,i]) else 0 for i in range(len(matrix))]\nprint('PPV :covid {0:.3f}, Normal {1:.3f}, pneumonia: {2:.3f}'.format(ppvs[0],ppvs[1],ppvs[2]))","14f107bb":"from distutils.dir_util import copy_tree\n\nfromDir='..\/input'\ntoDir= 'temp'\n\ncopy_tree(fromDir,toDir)","35f3ffba":"gan_corona='temp\/GAN_Images\/corona'\ntrain_corona='temp\/chest_xray\/chest_xray\/train\/CORONA\/'\nprint (len([name for name in os.listdir(train_corona) if os.path.isfile(os.path.join(train_corona, name))]))","5d196176":"import shutil\nimport glob2 as glob\nfor filename in glob.glob(os.path.join(gan_corona, '*.*')):\n    shutil.copy2(filename, train_corona)","08854bf6":"training_path='temp\/chest_xray\/chest_xray\/train'\ntesting_path='temp\/chest_xray\/chest_xray\/test'\ntrain_gen=train_aug.flow_from_directory(batch_size=bs,directory=training_path,shuffle=True,target_size=(img_size,img_size),class_mode='categorical')\nvalid_gen=train_aug.flow_from_directory(batch_size=bs,directory=training_path,shuffle=True,target_size=(img_size,img_size),class_mode='categorical',subset='validation')\ntest_gen=test_aug.flow_from_directory(batch_size=1,directory=testing_path,shuffle=False,target_size=(img_size,img_size),class_mode='categorical')","a50b64a1":"model_net=compiler()","335c4074":"STEP_SIZE_TRAIN=train_gen.n\/\/train_gen.batch_size\nSTEP_SIZE_VALID=valid_gen.n\/\/valid_gen.batch_size\n\n# Already calculated - this would make model to learn more from samples which low in number in our case - Covid\nclassweights={0: 2.23929825,\n             1:1.58637832,\n             2:0.52000326}\n\n\n#2.23929825 1.58637832 0.52000326\nhistory = model_net.fit_generator(\n    train_gen,\n    steps_per_epoch=STEP_SIZE_TRAIN,\n    epochs=5,\n    validation_data=valid_gen,\n    validation_steps=STEP_SIZE_VALID,\n    callbacks=[model_chk_callback,reduce_lr,early],\n    class_weight=classweights,\n    verbose=1\n)  ","83e35c93":"from sklearn.metrics import confusion_matrix\ny_test =test_gen.classes\nnb_samples = len(y_test)\npred = model_net.predict_generator(test_gen, nb_samples)\npred= np.argmax(pred, axis=1)\n\nprint(pred)\n\n\nmatrix = confusion_matrix(y_test, pred)\nmatrix = matrix.astype('float')\n#cm_norm = matrix \/ matrix.sum(axis=1)[:, np.newaxis]\nprint(matrix)\n\n\nclass_acc = [matrix[i,i]\/np.sum(matrix[i,:]) if np.sum(matrix[i,:]) else 0 for i in range(len(matrix))]\nprint('Sens covid: {0:.3f}, Normal: {1:.3f}, pneumonia : {2:.3f}'.format(class_acc[0],class_acc[1],class_acc[2]))\nppvs = [matrix[i,i]\/np.sum(matrix[:,i]) if np.sum(matrix[:,i]) else 0 for i in range(len(matrix))]\nprint('PPV :covid {0:.3f}, Normal {1:.3f}, pneumonia: {2:.3f}'.format(ppvs[0],ppvs[1],ppvs[2]))","9c2d50a7":"# Model","9c0daa36":"I am fine tuning Efficient net B0 , where it has many levels. B0 to B7","991fe47e":"# Time to Train GAN images too","ed0a9e40":"## Introduction\nGreetings Everyone this is showing how GANs improve accuracy, I am using Efficient Net which is an SOTA Image classifier and Compare the results.","dd7217db":"Let's Load data First","4f64f4eb":"Here is our metrics which would observe during each epoch","e8486c22":"# Data loading and pipelining\n","4015cf88":"# Training Time \n**I am taking 5 epochs only**","5bfb9020":"# Libraries","579c18e0":"# Damn impressive results\n**Almost same in covid but Normal and pneumonia has increased which is an overall better technique , this has proved my point **\n","d2fd1759":"**Here is the model architecture**\n\n![](https:\/\/gitcdn.xyz\/cdn\/Tony607\/blog_statics\/36894ad880dc3e645513efc36cc070c4cd0d3d7c\/images\/efficientnet\/building_blocks.png)","61ca1bc1":"## What is GAN?\nA generative adversarial network (GAN) has two parts:\n\n* The generator learns to generate plausible data. The generated instances become negative training examples for the discriminator.\n* The discriminator learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n\n\nWhen training begins, the generator produces obviously fake data, and the discriminator quickly learns to tell that it's fake:\n\n![](https:\/\/developers.google.com\/machine-learning\/gan\/images\/bad_gan.svg)\n\nAs training progresses, the generator gets closer to producing output that can fool the discriminator:\n\n![](https:\/\/developers.google.com\/machine-learning\/gan\/images\/ok_gan.svg)\n\nFinally, if generator training goes well, the discriminator gets worse at telling the difference between real and fake. It starts to classify fake data as real, and its accuracy decreases.\n\n![](https:\/\/developers.google.com\/machine-learning\/gan\/images\/good_gan.svg)\n\n\n","524fa170":"## Impressive results within 5 epochs only","aff392c7":"**Here it begins **"}}