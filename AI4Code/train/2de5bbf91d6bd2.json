{"cell_type":{"06b3a93a":"code","e290e891":"code","b6a9ca97":"code","aebef525":"code","7f83401a":"code","b470b972":"code","e9c86e6b":"code","aae47dfd":"code","ac12c489":"code","0773fc69":"code","217c258f":"code","db006b66":"code","f909c315":"code","f6e5a7a3":"code","9fcd6c63":"code","c561e57d":"code","18e972cf":"markdown"},"source":{"06b3a93a":"import tarfile\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport PIL\nimport PIL.Image\n","e290e891":"#Configure GPU acceleration\ntf.config.list_physical_devices('GPU')","b6a9ca97":"#Data Prep\no = tarfile.open(\"..\/input\/17-category-flowers\/17flowers.tgz\")\no.extractall()","aebef525":"#defining paths to the pictures\nDir =  '.\/jpg'\nImage_path = pd.read_csv(Dir + '\/files.txt',names = ['Image'])\nN = Image_path.shape[0]\nprint('Number of Images:', N)","7f83401a":"#sample image\nPIL.Image.open(Dir + '\/' +Image_path['Image'][50])","b470b972":"#Defining Labels\n#First 80 corresponds to first type and next 80 refers the next\nY= np.zeros((N,1))\nJ = 0\nfor i in np.arange(N):\n    Y[i] = J\n    if (i+1) % 80 == 0:\n        J += 1\nY = Y.astype('int')\n\n\nprint( 'Number of classes:', np.max(Y))\nprint( 'Number of samples in each class:', np.sum(Y==0))","e9c86e6b":"#global variables\n\nPaths = Dir + '\/'+ Image_path['Image']\n\n#data variables\nsize = (500,500)\nChannels = 3\ninput_shape=[500,500,Channels]\nClasses = 17\n\n\n#training variables\nAUTO = tf.data.experimental.AUTOTUNE\nbatch_size = 16\nEPOCHS= 50\nVERBOSE =1","aae47dfd":"\n#spliting the data into training and test splits\nX_train, X_test, y_train, y_test = train_test_split(Paths, Y, test_size=0.1, random_state=15)\n    \nprint(\"Number of training samples:\", X_train.shape[0])\nprint(\"Number of test samples:\", X_test.shape[0])\n","ac12c489":"def image_proces(Path, labels):\n    \"\"\"\n    inputs: Tensorflow Dataset that contains the following two properties\n        Path: Paths to images\n        labels: image labels\n        \n    output: Tensorflow Dataset that contains\n        data: processed images\n        labels: image labels\n    \n    Function:\n    Takes a tensorflow dataset of image paths and decodes the images into numpy arrays. The images are then resized.\n    \"\"\"\n    data = tf.io.read_file(Path)\n    data = tf.image.decode_jpeg(data, channels=3)\n    data = tf.image.resize(data, size)\n    #data = tf.image.per_image_standardization(data)\n    return data,labels\n\ndef import_image(Paths,labels):\n    \"\"\"\n    inputs:\n    Paths: a list of paths to the images\n    Y: a list of labels (flower ids)\n    \n    outputs:\n    dataset: a tensorflow datset that contains images which are decoded and resized\n    \n    Function: \n    Takes a list of paths and returns a formatted tensorflow dataset\n    \"\"\"\n    dataset = tf.data.Dataset.from_tensor_slices((Paths,labels))\n    dataset = dataset.map(image_proces,num_parallel_calls=AUTO)\n    return dataset\n\n\ntrain_dataset= import_image(X_train,y_train)\nval_dataset= import_image(X_test,y_test)\n","0773fc69":"#sample inspect\ninspect= list(train_dataset.take(1).as_numpy_iterator())\nprint('Input Shape:',inspect[0][0].shape, 'Example Label:',inspect[0][1])","217c258f":"\n\ndef create_model(input_shape):\n    \"\"\"\n    Input: \n    Input Shape: the shape of the input image\n    \n    Output:\n    Tensorflow model\n    \n    The function creates a CNN model for classification\n    \"\"\"\n    inputs = tf.keras.Input(shape=(input_shape))\n    norm =  tf.keras.layers.experimental.preprocessing.Normalization()\n    x = norm(inputs)\n    x = tf.keras.layers.Conv2D(90,10,padding='same', activation='relu')(x)\n    \n    x = tf.keras.layers.GlobalMaxPooling2D()(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    #x = tf.keras.layers.Dense(50,activation=\"relu\", dtype='float32')(x)\n    #x = tf.keras.layers.BatchNormalization()(x)\n    outputs = tf.keras.layers.Dense(Classes,activation=\"softmax\", dtype='float32')(x)\n        \n    model = tf.keras.Model(inputs, outputs)\n    return model\n\nmodel = create_model(input_shape)\nmodel.summary()\n","db006b66":"#Defining dataset settings\ntrain_dataset = train_dataset.cache()\ntrain_dataset = train_dataset.shuffle(2048).batch(batch_size)\ntrain_dataset = train_dataset.prefetch(AUTO)\n\nval_dataset = val_dataset.cache()\nval_dataset = val_dataset.batch(batch_size)\nval_dataset = val_dataset.prefetch(AUTO)","f909c315":"def compile_model(model, lr):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    \n\n    return model","f6e5a7a3":"#defining callbacks \nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,\n                              patience=3, mode='max', min_delta=0.0001,verbose=1)\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max', min_delta=0.0001,verbose=1)\n\n","9fcd6c63":"model = compile_model(model, lr=0.001)\nHistory = model.fit(train_dataset, \n                epochs=EPOCHS,\n                callbacks=[reduce_lr,callback],\n                validation_data = val_dataset,  \n                verbose=VERBOSE\n               )","c561e57d":"plt.figure(1)\nplt.plot(History.history['accuracy'][1:],label='Train')\nplt.plot(History.history['val_accuracy'][1:],label='Valid')\nplt.title('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure(2)\nplt.plot(History.history['loss'][1:],label='Train')\nplt.plot(History.history['val_loss'][1:],label='Valid')\nplt.xlabel('Epoch')\nplt.title('Loss')\nplt.legend()\nplt.show()","18e972cf":"Here is a 17 class flower classifier using a small CNN.\n\nFor a full explaination on classification using Keras, please check out:\nhttps:\/\/www.kaggle.com\/eugenehu\/tpu-accelerated-keras-approach-tutorial"}}