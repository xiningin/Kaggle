{"cell_type":{"e1163e92":"code","e474949c":"code","a0cf6cfe":"code","5e81c7da":"code","1b40264f":"code","d4e91e6c":"markdown"},"source":{"e1163e92":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_selection import VarianceThreshold\nfrom tensorflow.keras import layers,regularizers,Sequential,backend,callbacks,optimizers,metrics,losses\nimport tensorflow as tf\nimport sys\nsys.path.append('..\/input\/iterative-stratification\/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","e474949c":"# Import train data, drop sig_id, cp_type\n\ntrain_features = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\nnon_ctl_idx = train_features.loc[train_features['cp_type']!='ctl_vehicle'].index.to_list()\ntrain_features = train_features.drop(['sig_id','cp_type','cp_dose','cp_time'],axis=1)\ntrain_targets_scored = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_scored = train_targets_scored.drop('sig_id',axis=1)\nlabels_train = train_targets_scored.values\n\n# Drop training data with ctl vehicle\n\ntrain_features = train_features.iloc[non_ctl_idx]\ndata_train = train_features.values\nlabels_train = labels_train[non_ctl_idx]\n\n# Import test data\n\ntest_features = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ntest_features = test_features.drop(['sig_id','cp_dose','cp_time'],axis=1)\ndata_test = test_features.drop('cp_type',axis=1).values","a0cf6cfe":"n_labels = labels_train.shape[1]\nn_features = data_train.shape[1]\nn_train = data_train.shape[0]\nn_test = data_test.shape[0]\n\n\n# Prediction Clipping Thresholds\n\np_min = 0.001\np_max = 0.999\n\n# Evaluation Metric with clipping and no label smoothing\n\ndef logloss(y_true, y_pred):\n    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n    return -backend.mean(y_true*backend.log(y_pred) + (1-y_true)*backend.log(1-y_pred))\n\n\n# Generate Seeds\n\nn_seeds = 1\n\n## I seed the np rng with a fixed seed and then use it to generate the random seeds for the MSKF. \n## Keep the same seed for different models that you plan to ensemble\/blend so that their OOF performance is comparable.\n## Verify that the array \"seeds\" has unique integers. For eg. if np.random is seeded with 0, n_seeds = 6 results in 5 unique seeds.\nnp.random.seed(1)\nseeds = np.random.randint(0,100,size=n_seeds)\n\n# Training Loop\n\nn_folds = 5\ny_pred = np.zeros((n_test,n_labels))\noof = tf.constant(0.0)\nhists = []\nbias = tf.keras.initializers.Constant(np.log(labels_train.mean(axis=0)))\nfor seed in seeds:\n    fold = 0\n    mskf = MultilabelStratifiedKFold(n_splits=n_folds,shuffle=True,random_state=seed)\n    for train, test in mskf.split(data_train,labels_train):\n        X_train = data_train[train]\n        X_test = data_train[test]\n        y_train = labels_train[train]\n        y_test = labels_train[test]\n\n        # Define NN Model\n\n        model = Sequential()\n        model.add(layers.Dropout(0.4))\n        model.add(layers.Dense(1024))\n        model.add(layers.Activation('swish'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.Dropout(0.1))\n        model.add(layers.Dense(1024))\n        model.add(layers.Activation('swish'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.Dropout(0.1))\n        model.add(layers.Dense(n_labels, activation='sigmoid', bias_initializer=bias))\n        model.compile(optimizer=optimizers.Adam(learning_rate=5*1E-5), loss=losses.BinaryCrossentropy(label_smoothing=0.001),\n                      metrics=metrics.BinaryCrossentropy())\n        reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_binary_crossentropy', factor=0.5, patience=5, mode='min', min_lr=1E-5)\n        early_stopping = callbacks.EarlyStopping(monitor='val_binary_crossentropy', min_delta=1E-5, patience=15, mode='min',restore_best_weights=True)\n\n        hist = model.fit(X_train,y_train, batch_size=128, epochs=192,verbose=0,validation_data = (X_test,y_test),callbacks=[reduce_lr, early_stopping])\n        hists.append(hist)\n        \n        # Save Model\n        model.save('LabelSmoothed_seed_'+str(seed)+'_fold_'+str(fold))\n\n        # OOF Score\n        y_val = model.predict(X_test)\n        oof += logloss(tf.constant(y_test,dtype=tf.float32),tf.constant(y_val,dtype=tf.float32))\/(n_folds*n_seeds)\n\n        # Run prediction\n        y_pred += model.predict(data_test)\/(n_folds*n_seeds)\n\n        fold += 1\n","5e81c7da":"# Analysis of Training\n\ntf.print('OOF score is ',oof)\n\nplt.figure(figsize=(12,8))\n\nhist_trains = []\nhist_lens = []\nfor i in range(n_folds*n_seeds):\n    hist_train = (hists[i]).history['binary_crossentropy']\n    hist_trains.append(hist_train)\n    hist_lens.append(len(hist_train))\nhist_train = []\nfor i in range(min(hist_lens)):\n    hist_train.append(np.mean([hist_trains[j][i] for j in range(n_folds*n_seeds)]))\n\nplt.plot(hist_train)\n\nhist_vals = []\nhist_lens = []\nfor i in range(n_folds*n_seeds):\n    hist_val = (hists[i]).history['val_binary_crossentropy']\n    hist_vals.append(hist_val)\n    hist_lens.append(len(hist_val))\nhist_val = []\nfor i in range(min(hist_lens)):\n    hist_val.append(np.mean([hist_vals[j][i] for j in range(n_folds*n_seeds)]))\n\nplt.plot(hist_val)\n\nplt.yscale('log')\nplt.xlabel('Epochs')\nplt.ylabel('Average Logloss')\nplt.legend(['Training','Validation'])","1b40264f":"# Generate submission file, Clip Predictions\n\nsub = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')\nsub.iloc[:,1:] = np.clip(y_pred,p_min,p_max)\n\n# Set ctl_vehicle to 0\nsub.iloc[test_features['cp_type'] == 'ctl_vehicle',1:] = 0\n\n# Save Submission\nsub.to_csv('submission.csv', index=False)","d4e91e6c":"# Demonstration of Label smoothing\n\n### The competition metric punishes highly confident incorrect answers. In this notebook, I show that a simple modification where the labels are smoothed to a small extent, and predictions clipped to prevent prediction probabilities close to 0 and 1 boosts performance significantly\n\n### Inspired by this post https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/185593\n\n\n### For more ideas, check out my other notebooks:\n* [Pretrained Model Inference and Blending Starter](https:\/\/www.kaggle.com\/rahulsd91\/moa-starter-inference-blending-pretrained-models)\n* [Multi-input ResNet Architecture ](https:\/\/www.kaggle.com\/rahulsd91\/moa-multi-input-resnet-model)\n* [Autoencoder based approach](https:\/\/www.kaggle.com\/rahulsd91\/moa-autoencoder-features-only-lb-0-01884)\n\n### Best Version by LB Score (if not current) : V10\n\n#### Version 15: No scaling, drop cp_dose\/cp_time\n\n#### Version 14: StandardScaler, remove WeightNormalization, no clipping for validation monitor metric\n\n#### Version 12: Add WeightNormalization layer to bias initialization\n\n#### Version 11: Test of bias initialization ([Idea from here](https:\/\/www.kaggle.com\/tolgadincer\/moa-tensorflow-fast-convergence) )\n\n#### Version 10: Increased NN units\n\n#### Version 8: Using keras's native label smoothing option\n\n#### Version 7: Save Models for Blending\n\n#### Version 6: Add Seed Averaging"}}