{"cell_type":{"45bad49e":"code","9a1f1f4f":"code","e7d6c3c5":"code","f3611b90":"code","bd2d86c0":"code","2d827db0":"code","efe40ae8":"code","6e998c98":"code","3d3d8d5c":"code","f45f0370":"code","18b8de0c":"code","44641bc0":"code","95806996":"code","552a65a1":"code","1f1a39d3":"code","b0501c70":"code","54e25532":"markdown","a60dd174":"markdown","6830bea2":"markdown","793d6012":"markdown","f4f454dc":"markdown","2425fcc8":"markdown","85eb2305":"markdown","0f2db8f0":"markdown","84265a5a":"markdown","4a7a3167":"markdown","a8615349":"markdown","af98eb98":"markdown","9ca970b2":"markdown","e70dc30c":"markdown"},"source":{"45bad49e":"# SET THIS VARIABLE TO TRUE TO RUN KERNEL QUICKLY\n# AND TEST FOR BUGS. ONLY 10000 ROWS OF DATA IS LOADED\nDebug = False\n\n# IMPORT LIBRARIES\nimport pandas as pd, numpy as np, os, gc\n\n# LOAD THESE BUT DONT ENCODE\nMM = ['AvSigVersion','Census_OSVersion','Census_OSBuildRevision','AppVersion','EngineVersion']\n\n# LOAD AND NUMERIC ENCODE\nNE = ['Census_SystemVolumeTotalCapacity','Census_PrimaryDiskTotalCapacity']\n\n# LOAD AND STATISTICAL ONE-HOT-ENCODE\nOHE = [ 'RtpStateBitfield','DefaultBrowsersIdentifier', 'AVProductStatesIdentifier',\n        'AVProductsInstalled', 'AVProductsEnabled', 'CountryIdentifier', 'CityIdentifier', \n        'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'Processor', 'OsBuild', 'OsSuite',\n        'SmartScreen','Census_MDC2FormFactor', 'Census_OEMNameIdentifier', \n        'Census_ProcessorCoreCount', 'Census_ProcessorModelIdentifier', \n        'Census_OSUILocaleIdentifier', 'Census_PrimaryDiskTypeName',\n        'Census_HasOpticalDiskDrive', 'Census_TotalPhysicalRAM', 'Census_ChassisTypeName',\n        'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n        'Census_InternalPrimaryDisplayResolutionHorizontal',\n        'Census_InternalPrimaryDisplayResolutionVertical',\n        'Census_PowerPlatformRoleName', 'Census_InternalBatteryType',\n        'Census_InternalBatteryNumberOfCharges', 'Census_OSEdition', 'Census_GenuineStateName',\n        'Census_ActivationChannel', 'Census_FirmwareManufacturerIdentifier', 'Census_IsTouchEnabled', \n        'Census_IsPenCapable', 'Census_IsAlwaysOnAlwaysConnectedCapable', 'Wdft_IsGamer', \n        'Wdft_RegionIdentifier', 'OsBuildLab', 'OrganizationIdentifier','Platform',\n        'Census_OEMModelIdentifier', 'IsProtected', 'IeVerIdentifier','Firewall', \n        'Census_ProcessorManufacturerIdentifier','Census_OSInstallTypeName',\n        'Census_OSWUAutoUpdateOptionsName','Census_IsFlightingInternal',\n        'Census_FlightRing','Census_ThresholdOptIn','Census_FirmwareVersionIdentifier',\n        'Census_IsSecureBootEnabled','Census_IsWIMBootEnabled']\n\n# DONT LOAD THESE\nXX = ['SMode','IsBeta', 'OsVer', 'OsPlatformSubRelease', 'SkuEdition', 'AutoSampleOptIn', 'PuaMode',\n     'UacLuaenable', 'Census_ProcessorClass', 'Census_OSArchitecture', 'Census_OSBranch',\n     'Census_OSBuildNumber', 'Census_OSSkuName', 'Census_OSInstallLanguageIdentifier',\n     'Census_IsPortableOperatingSystem', 'Census_IsFlightsDisabled', 'Census_IsVirtualDevice',\n     'IsSxsPassiveMode','ProductName','HasTpm','Census_DeviceFamily']\n\n# DONT LOAD THIS\nXXX = ['MachineIdentifier']\n\n# LOAD ALL AS CATEGORIES\ndtypes = {}\nfor x in OHE+NE+MM: dtypes[x] = 'category'\ndtypes['HasDetections'] = 'int8'\n\n# LOAD TRAIN CSV FILE\nif Debug:\n    df_train = pd.read_csv('..\/input\/microsoft-malware-prediction\/train.csv', usecols=dtypes.keys(), dtype=dtypes,nrows=10000)\nelse:\n    df_train = pd.read_csv('..\/input\/microsoft-malware-prediction\/train.csv', usecols=dtypes.keys(), dtype=dtypes)\nif 5244810 in df_train.index:\n    df_train.loc[5244810,'AvSigVersion'] = '1.273.1144.0'\n    df_train['AvSigVersion'].cat.remove_categories('1.2&#x17;3.1144.0',inplace=True)\nprint ('Loaded',len(df_train),'rows of TRAIN.CSV!')\n\n# SHUFFLE TRAIN DATA\ndf_train = df_train.sample(frac=1)\ndf_train.reset_index(drop=True,inplace=True)\n\n# LOAD TEST CSV FILE\nif Debug:\n    df_test = pd.read_csv('..\/input\/microsoft-malware-prediction\/test.csv', usecols=list(dtypes.keys())[0:-1], dtype=dtypes,nrows=10000)\nelse:\n    df_test = pd.read_csv('..\/input\/microsoft-malware-prediction\/test.csv', usecols=list(dtypes.keys())[0:-1], dtype=dtypes)\nprint ('Loaded',len(df_test),'rows of TEST.CSV!')","9a1f1f4f":"import math\n\n# FACTORIZE\ndef factor_data(df_train, df_test, col):\n    df_comb = pd.concat([df_train[col],df_test[col]],axis=0)\n    df_comb,_ = df_comb.factorize(sort=True)\n    # MAKE SMALLEST LABEL 1, RESERVE 0\n    df_comb += 1\n    # MAKE NAN LARGEST LABEL\n    df_comb = np.where(df_comb==0, df_comb.max()+1, df_comb)\n    df_train[col] = df_comb[:len(df_train)]\n    df_test[col] = df_comb[len(df_train):]\n    del df_comb\n    mx = max(df_train[col].max(),df_test[col].max())+1\n    return mx\n    \n# OPTIMIZE MEMORY\ndef reduce_memory(df,col):\n    mx = df[col].max()\n    if mx<256:\n            df[col] = df[col].astype('uint8')\n    elif mx<65536:\n        df[col] = df[col].astype('uint16')\n    else:\n        df[col] = df[col].astype('uint32')\n    \n# LOG FREQUENCY ENCODE\ndef encode_FE_lg(df,col,verbose=1):\n    ln = 1\/df[col].nunique()\n    vc = (df[col].value_counts(dropna=False, normalize=True)+ln).map(math.log).to_dict()\n    nm = col+'_FE_lg'\n    df[nm] = df[col].map(vc)\n    df[nm] -= df[nm].min()\n    df[nm] = df[nm]\/df[nm].max()\n    df[nm] = df[nm].astype('float32')\n    if verbose==1:\n        print('FE encoded',col)\n    return [nm]\n\n# STATISTICAL CATEGORY ENCODE\ndef encode_CE(df, col, filter, zscore, tar='HasDetections', m=0.5, verbose=1):\n    cv = pd.DataFrame( df[col].value_counts(dropna=False) ).reset_index()\n    cv4 = df.groupby(col)[tar].mean().reset_index().rename({tar:'rate',col:'index'},axis=1)\n    d1 = set(cv['index'].unique())\n    cv = pd.merge(cv,cv4,on='index',how='left')\n    if (len( cv[ cv['index'].isna() ])!=0 ):\n        cv.loc[ cv['index'].isna(),'rate' ] = df.loc[ df[col].isna(),tar ].mean()\n    cv = cv[ cv[col]> (filter * len(df)) ]\n    cv['ratec'] = (df[tar].sum() - cv['rate']*cv[col])\/(len(df)-cv[col])\n    cv['sd'] = zscore * 0.5 \/ cv[col].map(lambda x: math.sqrt(x))\n    cv = cv[ (abs(cv['rate']-m)>=cv['sd']) | (abs(cv['ratec']-1+m)>=cv['sd']) ]\n    d2 = set(cv['index'].unique())\n    d = list(d1 - d2)\n    if (df[col].dtype.name=='category'):\n        if (not 0 in df[col].cat.categories):\n            df[col].cat.add_categories(0,inplace=True)\n        else:\n            print('###WARNING CAT 0 ALREADY EXISTS IN',col)\n    df.loc[ df[col].isin(d),col ] = 0\n    if verbose==1:\n        print('CE encoded',col,'-',len(d2),'values. Removed',len(d),'values')\n    mx = df[col].nunique()\n    return [mx,d2]\n\n# CATEGORY ENCODE FROM KEEP LIST\ndef encode_CE_test(df,col,d):\n    if (df[col].dtype.name=='category'):\n        if (not 0 in df[col].cat.categories):\n            df[col].cat.add_categories(0,inplace=True)\n        else:\n            print('###WARNING CAT 0 ALREADY EXISTS IN',col)\n    df.loc[ ~df[col].isin(d),col ] = 0\n    mx = df[col].nunique()\n    return [mx,d]","e7d6c3c5":"def makeNew(df,verbose=1,add=0,TS=True,data=0):\n\n    old = df.columns\n    \n    # FEATURE ENGINEER\n    df['AppVersion2'] = df['AppVersion'].apply(lambda x: x.split('.')[1]).astype('category')\n\n    if TS:\n        from datetime import datetime, date, timedelta\n\n        # AS timestamp\n        datedictAS = np.load('..\/input\/malware-timestamps\/AvSigVersionTimestamps.npy')[()]\n        df['DateAS'] = df['AvSigVersion'].map(datedictAS)\n\n        # OS timestamp\n        datedictOS = np.load('..\/input\/malware-timestamps-2\/OSVersionTimestamps.npy')[()]\n        df['DateOS'] = df['Census_OSVersion'].map(datedictOS)\n\n        df['Lag1'] = df['DateAS'] - df['DateOS']\n        df['Lag1'] = df['Lag1'].map(lambda x: x.days\/\/7)\n        df['Lag1'] = df['Lag1']\/52.0\n        df['Lag1'] = df['Lag1'].astype('float32')\n        df['Lag1'].fillna(0,inplace=True)\n        \n        if data!=0:\n            if data==1:\n                df['Lag5'] = datetime(2018,7,26) - df['DateAS'] # TRAIN\n            elif data==2:\n                df['Lag5'] = datetime(2018,9,27) - df['DateAS'] #PUBLIC TEST\n            elif data==3:\n                df['Lag5'] = datetime(2018,10,27) - df['DateAS'] #PRIVATE TEST\n            df['Lag5'] = df['Lag5'].map(lambda x: x.days\/\/1)\n            df.loc[ df['Lag5']<0, 'Lag5' ] = 0\n            df['Lag5'] = df['Lag5']\/365.0\n            df['Lag5'] = df['Lag5'].astype('float32')\n            df['Lag5'].fillna(0,inplace=True)\n\n        del df['DateAS'], df['DateOS']\n        del datedictAS, datedictOS\n        x=gc.collect()\n    \n    # NUMERIC ENCODE NE VARIABLES\n    for col in NE:\n        nm = col+'_NE'\n        df[nm] = df[col].astype('float32')\n        df[nm] \/= np.std(df[nm])\n    new = list(set(df.columns)-set(old))\n    ret = []\n    for x in new:\n        if str(df[x].dtype)=='category': # if cat\n            if add==1: OHE.append(x)\n        else: \n            ret.append(x)\n            df[x].fillna(df[x].mean(),inplace=True)\n    if verbose==1:\n        print('Engineered',len(new),'new features!')\n    return ret","f3611b90":"# GET FREQUENCY ENCODE LIST\nFE = []\nfor col in df_train.columns:\n    if col=='HasDetections': continue\n    if df_train[col].nunique()>10:\n        FE.append(col)\n\n# FEATURE ENGINEER \/ NEUMERIC ENCODE\nNUM = makeNew(df_train,verbose=0,add=1,data=1)\nmakeNew(df_test,verbose=0,data=2)\nprint('Engineered '+str(len(NUM))+' variables (including NE)')\nct = len(NUM)+1; cnew = ct\n    \n# FREQUENCY ENCODE\nfor x in FE:\n    NUM += encode_FE_lg(df_train,x,verbose=0)\n    encode_FE_lg(df_test,x,verbose=0)\n    #print(str(ct)+': FE: '+x)\n    ct += 1\nprint('Frequency encoded '+str(len(NUM)-cnew)+' variables')\n    \n# STATISTICAL CATEGORY ENCODE\ninps={}; tt = 0\nfor col in OHE:\n    factor_data(df_train,df_test,col)\n    d = encode_CE(df_train,col,0.001,1)[1]\n    encode_CE_test(df_test,col,d)\n    inps[col] = factor_data(df_train,df_test,col)\n    tt += inps[col]\n    reduce_memory(df_train,col)\n    reduce_memory(df_test,col)\n    #print(str(ct)+': CE: '+col)\n    ct += 1\n\n# REMOVE UNNEEDED\nfor x in np.unique(NE+MM):\n    del df_train[x]\n    if x!='AvSigVersion': del df_test[x]\nx = gc.collect()\n\nmm = round(df_train.memory_usage(deep=True).sum() \/ 1024**2)\nmm2 = round(df_test.memory_usage(deep=True).sum() \/ 1024**2)\nprint('Encoded '+str(len(NUM))+' non-CE variables and '+str(len(OHE))+' CE containing '+str(tt)+' unique values into '+str(mm)+' Mb memory')\nprint('Test memory is '+str(mm2)+' Mb')","bd2d86c0":"from keras import callbacks\nfrom sklearn.metrics import roc_auc_score\n\nclass printAUC(callbacks.Callback):\n    def __init__(self, X_train, y_train, inps, fes, X_val, y_val, k, ee):\n        super(printAUC, self).__init__()\n        self.bestAUC = 0\n        self.X_train = X_train\n        self.y_train = y_train\n        self.inps = inps\n        self.fes = fes\n        self.X_val = X_val\n        self.y_val = y_val\n        self.k = k\n        self.ee = ee\n        \n    def on_epoch_end(self, epoch, logs={}):\n        pred = self.model.predict([self.X_train[col] for col in self.inps] + [self.X_train[self.fes]])\n        aucTR = roc_auc_score(self.y_train, pred)\n        pred = self.model.predict([self.X_val[col] for col in self.inps] + [self.X_val[self.fes]])\n        auc = roc_auc_score(self.y_val, pred)\n        print (\"Train AUC: \" + str(round(aucTR,5))+\" - Validation AUC: \" + str(round(auc,5)))\n        if (self.bestAUC < auc) :\n            self.bestAUC = auc\n            self.model.save(\"bestNet\"+str(self.k)+\".h5\", overwrite=True)\n        return","2d827db0":"# DEFINE NETWORK ARCHITECTURE GROUPINGS\n# (1) GEOGRAPHICAL, (2) SOFTWARE\/VIRUS, (3) HARDWARE, (4) NAME\/MODEL\ngroups = [  ['CountryIdentifier','CityIdentifier','OrganizationIdentifier','GeoNameIdentifier',\n             'LocaleEnglishNameIdentifier','Census_OSInstallLanguageIdentifier','Census_OSUILocaleIdentifier',\n            'Wdft_RegionIdentifier'],\n            ['DefaultBrowsersIdentifier', 'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled',\n             'IsProtected', 'SMode', 'IeVerIdentifier', 'SmartScreen', 'Firewall','Census_IsSecureBootEnabled',\n            'Census_IsWIMBootEnabled','Wdft_IsGamer','Census_OSWUAutoUpdateOptionsName','Census_GenuineStateName',\n            'AppVersion2'],\n            ['Processor','Census_MDC2FormFactor','Census_DeviceFamily','Census_ProcessorCoreCount','Census_ProcessorClass',\n            'Census_PrimaryDiskTypeName','Census_HasOpticalDiskDrive','Census_TotalPhysicalRAM','Census_ChassisTypeName',\n            'Census_InternalPrimaryDiagonalDisplaySizeInInches', 'Census_InternalPrimaryDisplayResolutionHorizontal',\n            'Census_InternalPrimaryDisplayResolutionVertical', 'Census_PowerPlatformRoleName', 'Census_InternalBatteryType',\n            'Census_InternalBatteryNumberOfCharges','Census_IsTouchEnabled','Census_IsPenCapable',\n             'Census_IsAlwaysOnAlwaysConnectedCapable'],\n            ['Census_OEMNameIdentifier', 'Census_OEMModelIdentifier', 'Census_ProcessorManufacturerIdentifier',\n            'Census_ProcessorModelIdentifier','Census_FirmwareManufacturerIdentifier', 'Census_FirmwareVersionIdentifier']\n         ]","efe40ae8":"from keras.models import Model\nfrom keras.layers import Dense, Input, concatenate, BatchNormalization, Activation, Dropout, Embedding, Reshape\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import Adam\n\ndf_train_Y = df_train['HasDetections']\ndel df_train['HasDetections']\nx=gc.collect()\n\n#SPLIT TRAIN AND VALIDATION SET\nchunk = len(df_train)\/\/5\nidx = range(chunk*0,chunk\/\/2)\nidx2 = range(chunk\/\/2,chunk)\nidx3 = range(chunk,chunk*3)\nidx4 = range(chunk*3,chunk*5)\nX_val1 = df_train.loc[idx]\nY_val1 = df_train_Y.loc[idx]\nX_val2 = df_train.loc[idx2]\nY_val2 = df_train_Y.loc[idx2]\nX_train1 = df_train.loc[idx3]\nY_train1 = df_train_Y.loc[idx3]\nX_train2 = df_train.loc[idx4]\nY_train2 = df_train_Y.loc[idx4]\ndel df_train, df_train_Y\nx=gc.collect()","6e998c98":"ins = []; outs = {}\n# CREATE AN EMBEDDING FOR EACH CATEGORY VARIABLE\nfor k in inps.keys():\n    x = Input(shape=(1,))\n    ins.append(x)\n    y = np.int(inps[k])\n    x = Embedding(y, y, input_length=1)(x)\n    x = Reshape(target_shape=(y, ))(x)\n    outs[k]=x \n    \n# ORGANIZE EMBEDDINGS INTO GROUPS\nall = set(inps.keys())\nused = []\nouts2 = []\nfor k in groups:\n    g = [outs[x] for x in set(k).intersection(all)]\n    used += list(set(k).intersection(all))\n    x = concatenate(g)\n    s = sum([inps[x] for x in set(k).intersection(all)])\n    x = Dense(s\/\/2,kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    x = Activation('elu')(x)\n    outs2.append(x)\ng = [outs[x] for x in all-set(used)]\nx = concatenate(g)\ns = sum([inps[x] for x in all-set(used)])\nx = Dense(s\/\/2,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('elu')(x)\nouts2.append(x)\n\n# ORGANIZE FREQUENCY ENCODED AND NUMERICS INTO A GROUP\nx = Input(shape=(len(NUM), ))\nins.append(x)\nx = Dense(len(NUM)\/\/2,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('elu')(x) \n\n# CONNECT GROUPS TO DENSE LAYERS\nx = concatenate(outs2+[x])\nx = Dense(100,kernel_initializer='he_uniform')(x)\nx = Dropout(0.2)(x)\nx = BatchNormalization()(x)\nx = Activation('elu')(x)\nx = Dense(100,kernel_initializer='he_uniform')(x)\nx = Dropout(0.2)(x)\nx = BatchNormalization()(x)\nx = Activation('elu')(x)\nx = Dense(100,kernel_initializer='he_uniform')(x)\nx = Dropout(0.2)(x)\nx = BatchNormalization()(x)\nx = Activation('elu')(x)\nx = Dense(1,activation='sigmoid')(x)\n\nmodel = Model(inputs=ins, outputs=x)\nmodel.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n#annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)","3d3d8d5c":"epochs=10\nbatch=256\nfor k in range(epochs):\n    # SPLIT TRAINING DATA IN HALF TO FIT INTO GPU MEMORY\n    model.fit( [X_train1[col] for col in OHE] + [X_train1[NUM]],Y_train1,\n        batch_size=batch, epochs = 1, verbose=2, callbacks=[ #annealer, \n        printAUC(X_train1, Y_train1, OHE, NUM, X_val1, Y_val1, 0, k)],\n        validation_data = ([X_val1[col] for col in OHE] + [X_val1[NUM]],Y_val1) )\n    model.fit( [X_train2[col] for col in OHE] + [X_train2[NUM]],Y_train2,\n        batch_size=batch, epochs = 1, verbose=2, callbacks=[ #annealer, \n        printAUC(X_train2, Y_train2, OHE, NUM, X_val2, Y_val2, 0, k)],\n        validation_data = ([X_val2[col] for col in OHE] + [X_val2[NUM]],Y_val2) )\n    # SHUFFLE TRAIN\n    X_train1['HasDetections'] = Y_train1\n    X_train1 = X_train1.sample(frac=1)\n    Y_train1 = X_train1['HasDetections']\n    del X_train1['HasDetections']\n    X_train2['HasDetections'] = Y_train2\n    X_train2 = X_train2.sample(frac=1)\n    Y_train2 = X_train2['HasDetections']\n    del X_train2['HasDetections']\n    x=gc.collect()","f45f0370":"del model\ndel X_train1, Y_train1, X_val1, Y_val1\ndel X_train2, Y_train2, X_val2, Y_val2\ndel ins, outs, outs2, x\nx = gc.collect()","18b8de0c":"# LOAD BEST SAVED NET\nfrom keras.models import load_model\n\n# PREDICT TEST\npred = np.zeros((len(df_test),1))\nprint('Predicting test...')\nmodel = load_model('bestNet0.h5')\nidx = 0; chunk = 1000000\nif Debug: chunk = 5000\nct2 = 1;\nwhile idx < len(df_test):\n    idx2 = min(idx + chunk, len(df_test) )\n    idx = range(idx, idx2)\n    pred[idx] += model.predict( [df_test.iloc[idx][col] for col in OHE] + [df_test.iloc[idx][NUM]] )\n    print(' part '+str(ct2)+' done')\n    ct2 += 1\n    idx = idx2\ndel model\nx = gc.collect()","44641bc0":"from datetime import datetime\ndatedictAS = np.load('..\/input\/malware-timestamps\/AvSigVersionTimestamps.npy')[()]\ndf_test['Date'] = df_test['AvSigVersion'].map(datedictAS)\ndf_test['HasDetections'] = pred\ndf_test['X'] = df_test['Date'] - datetime(2018,11,20,4,0) \ndf_test['X'] = df_test['X'].map(lambda x: x.total_seconds()\/86400)\ndf_test['X'].fillna(0,inplace=True)\ns = 5.813888\ndf_test['F'] = 1.0\ndf_test['F'] = 1 - df_test['X']\/s\ndf_test.loc[df_test['X']<=0,'F'] = 1.0\ndf_test.loc[df_test['X']>s,'F'] = 0\ndf_test['HasDetections'] *= df_test['F']\npred = df_test['HasDetections']","95806996":"print('Writing submission file...')\nif Debug:\n    submit = pd.read_csv('..\/input\/microsoft-malware-prediction\/sample_submission.csv', nrows=10000)\nelse:\n    submit = pd.read_csv('..\/input\/microsoft-malware-prediction\/sample_submission.csv')\nsubmit['HasDetections'] = pred\nsubmit.to_csv('submission.csv', index=False)\nprint('Done!')","552a65a1":"import matplotlib.pyplot as plt    \nb = plt.hist(pred, bins=200)","1f1a39d3":"import calendar, math\n\ndef dynamicPlot(data,col, target='HasDetections', start=datetime(2018,4,1), end=datetime(2018,12,1)\n                ,inc_hr=0,inc_dy=7,inc_mn=0,show=0.99,top=5,top2=4,title='',legend=1,z=0,dots=False):\n    # check for timestamps\n    if 'Date' not in data:\n        print('Error dynamicPlot: DataFrame needs column Date of datetimes')\n        return\n    \n    # remove detection line if category density is too small\n    cv = data[(data['Date']>start) & (data['Date']<end)][col].value_counts(dropna=False)\n    cvd = cv.to_dict()\n    nm = cv.index.values\n    th = show * len(data)\n    sum = 0; lnn2 = 0\n    for x in nm:\n        lnn2 += 1\n        sum += cvd[x]\n        if sum>th:\n            break\n    top = min(top,len(nm))\n    top2 = min(top2,len(nm),lnn2,top)\n\n    # calculate rate within each time interval\n    diff = (end-start).days*24*3600 + (end-start).seconds\n    size = diff\/\/(3600*((inc_mn * 28 + inc_dy) * 24 + inc_hr)) + 5\n    data_counts = np.zeros([size,2*top+1],dtype=float)\n    idx=0; idx2 = {}\n    for i in range(top):\n        idx2[nm[i]] = i+1\n    low = start\n    high = add_time(start,inc_mn,inc_dy,inc_hr)\n    data_times = [low+(high-low)\/2]\n    while low<end:\n        slice = data[ (data['Date']<high) & (data['Date']>=low) ]\n        #data_counts[idx,0] = len(slice)\n        data_counts[idx,0] = 5000*len(slice['AvSigVersion'].unique())\n        for key in idx2:\n            if nan_check(key): slice2 = slice[slice[col].isna()]\n            else: slice2 = slice[slice[col]==key]\n            data_counts[idx,idx2[key]] = len(slice2)\n            if target in data:\n                data_counts[idx,top+idx2[key]] = slice2['HasDetections'].mean()\n        low = high\n        high = add_time(high,inc_mn,inc_dy,inc_hr)\n        data_times.append(low+(high-low)\/2)\n        idx += 1\n\n    # plot lines\n    fig = plt.figure(1,figsize=(15,3))\n    cl = ['r','g','b','y','m']\n    ax3 = fig.add_subplot(1,1,1)\n    lines = []; labels = []\n    if z==1: ax3.plot(data_times,data_counts[0:idx+1,0],'k')\n    for i in range(top):\n        tmp, = ax3.plot(data_times,data_counts[0:idx+1,i+1],cl[i%5])\n        if dots: ax3.plot(data_times,data_counts[0:idx+1,i+1],cl[i%5]+'o')\n        lines.append(tmp)\n        labels.append(str(nm[i]))\n    ax3.spines['left'].set_color('red')\n    ax3.yaxis.label.set_color('red')\n    ax3.tick_params(axis='y', colors='red')\n    if col!='ones': ax3.set_ylabel('Category Density', color='r')\n    else: ax3.set_ylabel('Data Density', color='r')\n    #ax3.set_yticklabels([])\n    if target in data:\n        ax4 = ax3.twinx()\n        for i in range(top2):\n            ax4.plot(data_times,data_counts[0:idx+1,i+1+top],cl[i%5]+\":\")\n            if dots: ax4.plot(data_times,data_counts[0:idx+1,i+1+top],cl[i%5]+\"o\")\n        ax4.spines['left'].set_color('red')\n        ax4.set_ylabel('Detection Rate', color='k')\n    if title!='': plt.title(title)\n    if legend==1: plt.legend(lines,labels,loc=2)\n    plt.show()\n        \n# INCREMENT A DATETIME\ndef add_time(sdate,months=0,days=0,hours=0):\n    month = sdate.month -1 + months\n    year = sdate.year + month \/\/ 12\n    month = month % 12 + 1\n    day = sdate.day + days\n    if day>calendar.monthrange(year,month)[1]:\n        day -= calendar.monthrange(year,month)[1]\n        month += 1\n        if month>12:\n            month = 1\n            year += 1\n    hour = sdate.hour + hours\n    if hour>23:\n        hour = 0\n        day += 1\n        if day>calendar.monthrange(year,month)[1]:\n            day -= calendar.monthrange(year,month)[1]\n            month += 1\n            if month>12:\n                month = 1\n                year += 1\n    return datetime(year,month,day,hour,sdate.minute)\n\n# CHECK FOR NAN\ndef nan_check(x):\n    if isinstance(x,float):\n        if math.isnan(x):\n            return True\n    return False","b0501c70":"df_test['ones'] = 1\ndynamicPlot(df_test, 'ones', inc_dy=2, legend=0,\n        title='Test.csv HasDetections Predictions. (Dotted line uses right y-axis. Solid uses left.)')","54e25532":"# Embeddings Neural Network - Microsoft Malware\nI'm excited to share my Microsoft Malware Neural Network. This NN uses two innovative designs that I'm proud to have discovered. It also uses embeddings to accept categorical variables into the network. It's part of an ensemble that scored 0.707 public LB (14th place out of 2450) described [here][1].\n* Similar variables are \"squeezed\" together forcing the network to PCA encode the group\n* High cardinality categorical variables are reduced using statistical hypothesis testing   \n\nBy executing this kernel, you train one fold of a 5-fold network and score 0.696 (+ - 0.001) public LB and 0.770 (+ - 0.003) private LB. If you ensemble the outputs from running this kernel 5 times, you score 0.699 public LB and 0.771 private LB! Below is an example of a \"squeeze\" grouping for geographical variables. The actual group receives 8 geographical variables. The full network employs 6 groupings.  \n  \n.  \n![image](http:\/\/playagricola.com\/Kaggle\/geographicalB31919.jpg)  \n  \n.  \n.  \nAfter the 6 groupings are created, they are fed into the remaining 3 hidden layers\n![image](http:\/\/playagricola.com\/Kaggle\/outputB31919.jpg)  \n  \n[1]: https:\/\/www.kaggle.com\/c\/microsoft-malware-prediction\/discussion\/84135","a60dd174":"# Train Embeddings Network\nAll of the training data won't fit into GPU memory, so we alternate training with half and half. This single kernel only trains one fold of a 5-fold NN. If you run this kernel 5 times and ensemble the 5 submission files, you will achieve 0.699 public LB.","6830bea2":"# Define AUC Callback\nThis callback displays AUC after each epoch.","793d6012":"# Encode Variables\nIn addition to statistically label encoding categorical variables (described above), we will add new variables of log frequency encoding for all categorical variables with cardinality over 10. [Time split validation][1] shows that these new variables increase our model's accuracy.  \n\n[1]: https:\/\/www.kaggle.com\/cdeotte\/time-split-validation-malware-0-68","f4f454dc":"# Define Variable Groupings\nAll variables in the same group get \"squeezed\" together and thus the group's dimension is reduced.","2425fcc8":"# Define Encoding Functions\nThis model uses a special statisical label encoding function which is explained in the kernel [here][1].  Here is a brief summary. When a categorical variable has many unique categories, each category value is hypothesis tested to see if it influences `HasDetections` rate. For example, say that `CountryIdentifier` has 222 unique values: 1, 2, 3, ..., 222. And we know that the average `HasDetections` rate is 0.5. Then for all observations from country, `k`, we test whether the rate of `HasDetections` deviates from 0.5 more than 1 standard deviation. If it does, we keep that category value. If it does not, we change that category value to a new category called `unhelpful`. In this specific example, the cardinality is reduced from 222 down to 115 thus removing 107 unhelpful values.  \n  \nAdditionally, we use log frequency encoding, label encoding, and memory optimization.\n  \n[1]: https:\/\/www.kaggle.com\/cdeotte\/neural-network-malware-0-67","85eb2305":"# Feature Engineering\nWe engineer `AppVersion2` which is the second number from `AppVersion`. For example `AppVersion2 = 18` when `AppVersion = 4.18.1807.18075`. This variable indicates whether Windows Defender has been updated to the latest version. And we engineer two time stamp variables. `Lag1 = AvSigVersion_Date - Census_OSVersion_Date` and `Lag2 = max(July 26,2018 - AvSigVersion_Date,0)`. When encoding the test data, we define `Lag2 = max(September 27,2018 - AvSigVersion_Date,0)` . The time stamp variables determine if a computer has an outdated `AvSigVersion`. EDA shows that these computers have decreased `HasDetections`. Presumably because they use their computers less or have better antivirus than Windows Defender. Lastly we clean the numeric values and normalize them.  \n  \n [Time split validation][1] shows that these new variables increase our model's accuracy.  \n\n[1]: https:\/\/www.kaggle.com\/cdeotte\/time-split-validation-malware-0-68","0f2db8f0":"# Display Predictions\nFirst we will display a histogram and next display a time series plot.","84265a5a":"# Predict Test Data\nWe will predict test.csv in chunks of 1 million.","4a7a3167":"# Write Submission File","a8615349":"# Result\nHere is the result of the output from running 1 kernel (1 fold). You can increase the score by 0.002 by ensembling the outputs from running this kernel 5 times. Trained neural networks have a lot of variance, so ensembling neural networks always helps.\n![image](http:\/\/playagricola.com\/Kaggle\/score31919.png)","af98eb98":"# Load Data","9ca970b2":"# Adjust Private Test Submission\nThe private test dataset is 33% outliers, explained [here][1], [here][4], [here][2], and [here][3]. Therefore we must adjust for these or our private test score will be terrible.  \n  \n[1]: https:\/\/www.kaggle.com\/c\/microsoft-malware-prediction\/discussion\/84745\n[2]: https:\/\/www.kaggle.com\/c\/microsoft-malware-prediction\/discussion\/84096\n[3]: https:\/\/www.kaggle.com\/c\/microsoft-malware-prediction\/discussion\/84227\n[4]: https:\/\/www.kaggle.com\/cdeotte\/private-leaderboard-0-750","e70dc30c":"# Build Embeddings Network\nAll statistically label encoded categorical variables are accepted into an embedding with input output ratio 1:1. Then similar variables are grouped as defined above. These groupings are fed into a common dense layer with input output ratio 2:1. This \"squeezes\" the variables together and finds reduced dimensional representation of the variables. Since the dense layer only uses identity activation, this mimics PCA. Each group contains the following number of variables  \n* Geographical Group - 8 variables\n* Hardware Group - 18 variables\n* Name\/Model Group - 6 variables\n* Software\/Virus Group - 15 variables\n* Miscellenous Group - 12 variables\n* Time Group - 33 variables  \n  \nEmbeddings are equivalent to one-hot-encoding a category variable. For example, suppose a categorical variable has 100 unique values. If we one-hot-encode it, we get 100 boolean variables. If we input those 100 variables into 100 units and send the outputs of those 100 units into 50 units. Then that is equivalent to sending a label encoded variable of 100 unique values into an embedding with a 100:50 input output. Below are some examples of groupings. In these examples, the categorical variables have 3 unique values and the embeddings are 3:3. Then the grouping squeezes 6 inputs down to 3 outputs (thus mimicking PCA) Keep in the mind that the true grouping has more variables being inputted into it.\n  \n![image](http:\/\/playagricola.com\/Kaggle\/geographicalB31919.jpg)  \n\n.  \n.  \n![image](http:\/\/playagricola.com\/Kaggle\/outputB31919.jpg)  \n  \n.  \n.  \n![image](http:\/\/playagricola.com\/Kaggle\/hardwareB31919.jpg)\n"}}