{"cell_type":{"1c5d349c":"code","e4a9eae8":"code","8849f22d":"code","33ad0c0b":"code","bef79210":"code","1ffddf44":"code","9d608052":"code","15c832c0":"code","41ddfb29":"code","60f91d26":"code","7cf26d7f":"code","21c5f2e6":"code","6a412fc2":"code","e3a284d3":"code","982fc908":"code","c0a68c2a":"code","74ddb9eb":"code","308eb1ce":"code","d7fa44bf":"code","ddef6d8b":"code","a8721bcd":"code","eb0ec7ee":"code","a092085c":"code","968f23c6":"code","450c9ec7":"code","f02b5dda":"code","2467dfd0":"code","4b56d3c4":"code","d452cbe8":"code","e2f958d2":"code","203ab0ee":"code","fc19d9de":"code","c0475042":"code","9da5c087":"code","d076e3fa":"code","95f46ac3":"code","67a6120c":"code","61486c3c":"markdown","8d07f261":"markdown","a0e2e3d9":"markdown","03965be6":"markdown","1cd3db6b":"markdown","11b5df6a":"markdown","702a04b5":"markdown","6fd4d07e":"markdown","a6025dab":"markdown","299ef5af":"markdown","77955dc4":"markdown"},"source":{"1c5d349c":"import numpy as np\nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt","e4a9eae8":"wine =pd.read_csv('..\/input\/winequalityred\/winequality-red.csv')\nwine\nwine1 =pd.read_csv('..\/input\/winequalityred\/winequality-red.csv')\nwine1","8849f22d":"wine.info()","33ad0c0b":"wine.describe()","bef79210":"wine.shape","1ffddf44":"wine.columns","9d608052":"wine.quality.value_counts()","15c832c0":"wine.isnull().sum()","41ddfb29":"wine.info()","60f91d26":"wine.hist(edgecolor='black',figsize=(15,15))\nplt.show()","7cf26d7f":"sns.pairplot(wine,hue='quality')\nplt.show()","21c5f2e6":"wine.quality.value_counts().plot.pie(explode=[0.1,0.1,0.1,0.1,0.1,0.1],autopct='%1.1f%%',shadow=True,figsize=(10,10))\nplt.show()","6a412fc2":"wine.corr()","e3a284d3":"wine.corr().style.background_gradient(cmap='coolwarm').set_precision(2)","982fc908":"wine=wine.drop('residual sugar',axis=1)","c0a68c2a":"wine=wine.drop('free sulfur dioxide',axis=1)","74ddb9eb":"wine=wine.drop('pH',axis=1)","308eb1ce":"wine","d7fa44bf":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score","ddef6d8b":"x=wine1.drop('quality',axis=1)\ny=wine1.quality","a8721bcd":"x.shape","eb0ec7ee":"y.shape","a092085c":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)","968f23c6":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\n#Fit the model\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n#Score\/Accuracy\nprint(\"Accuracy --> \", model.score(x_test, y_test)*100)\n","450c9ec7":"from sklearn.neighbors import KNeighborsClassifier ","f02b5dda":"knn=KNeighborsClassifier(n_neighbors=5,p=2)\nknn.fit(x_train,y_train)\n\nprint(knn.score(x_train,y_train))\nprint(knn.score(x_test,y_test))","2467dfd0":"k_range = list(range(1,25))\nscores=[]\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x,y)\n    y_pred = knn.predict(x)\n    scores.append(metrics.accuracy_score(y,y_pred))","4b56d3c4":"plt.plot(k_range,scores)\nplt.xlabel('value of k for knn')\nplt.ylabel('accuracy score')\nplt.title('accuracy scores for value of k of KNN')\nplt.show()","d452cbe8":"import xgboost as xgb","e2f958d2":"xgb_clf = xgb.XGBRFClassifier()\nxgb_clf = xgb_clf.fit(x_train,y_train)\n\nprint(xgb_clf.score(x_train,y_train))","203ab0ee":"from sklearn.tree import DecisionTreeClassifier","fc19d9de":"model1 = DecisionTreeClassifier(random_state=1)\nmodel1.fit(x_train, y_train)\ny_pred1 = model1.predict(x_test)\n\naccuracy5=model1.score(x_test,y_test)\nprint(accuracy5*100,'%')","c0475042":"from sklearn.naive_bayes import GaussianNB","9da5c087":"nvclass=GaussianNB()\nnvclass.fit(x_train,y_train)\ny_pr=nvclass.predict(x_test)\n\naccuracy4=nvclass.score(x_test,y_test)\nprint(accuracy4*100,'%')","d076e3fa":"#Import svm model\nfrom sklearn import svm\n#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n#Train the model using the training sets\nclf.fit(x_train, y_train)\n#Predict the response for test dataset\ny_pred = clf.predict(x_test)\n#Score\/Accuracy\nprint(\"Accuracy --> \", clf.score(x_test, y_test)*100)\n","95f46ac3":"from sklearn.ensemble import RandomForestClassifier","67a6120c":"ran_class=RandomForestClassifier()\nran_class.fit(x_train,y_train)\nran_predict=ran_class.predict(x_test)\n\naccuracy3=ran_class.score(x_test,y_test)\nprint(accuracy3*100,'%')","61486c3c":"we had no categorical variable so we dont need to transform the feature\nall ower feature are float","8d07f261":"# Naive Bayes","a0e2e3d9":"# SVM","03965be6":"# missing value","1cd3db6b":"we had no missing value ","11b5df6a":"# visualization","702a04b5":"# knn","6fd4d07e":"# XGBOOST","a6025dab":"# logistic regresiion","299ef5af":"# decision tree","77955dc4":"# Random Forest Classifier\n\n"}}