{"cell_type":{"3835f397":"code","16204236":"code","9d92e460":"code","25f1264a":"code","1ea67e61":"code","2fc5a352":"code","71342532":"code","7077de59":"code","59c964e9":"code","af392cbd":"code","3996940b":"code","b7961133":"code","3585d4b2":"code","b2f77855":"code","5d0a0a34":"code","22f18061":"code","dc239534":"code","f55ad193":"code","caafeca7":"code","1bbb6534":"code","be106833":"code","22a3ee25":"code","40930fca":"code","89474530":"code","07108d15":"code","d339ed17":"code","5b28030e":"code","93d6a858":"code","317fd176":"code","e81beb17":"code","facf0e74":"code","73f71b81":"code","3801a30a":"code","a578ce35":"code","b42e3129":"code","ef8e1e33":"code","66401a5d":"code","25777e5e":"code","408f9f11":"code","54f76387":"code","1f98c2b9":"code","2fc24225":"code","274a2b2a":"code","4d5716ec":"code","01ed66bc":"code","267e70c4":"code","312eddf9":"code","6d9fca00":"code","25d718a2":"code","533548cf":"code","67e5e5df":"code","53b8ba57":"code","05c1fb46":"code","66ed9435":"code","918371a8":"code","2d4db7ee":"code","11c67f13":"code","77194f09":"code","6c3756ea":"code","c908e70e":"code","2d1636f7":"code","d2bec77b":"code","372484fb":"code","ede71f43":"code","ab04d237":"code","b87f4358":"code","07b2d45a":"code","c0f4a2bb":"code","a4f3fc34":"code","b12dea8f":"code","887dd228":"code","f318b5bc":"code","291305f6":"code","1c524760":"code","9f5dd549":"code","2ea1ba90":"code","14083a88":"code","d7be713c":"code","0990db68":"markdown","19f3c4c4":"markdown","520f0047":"markdown","9ad5e286":"markdown","4d51063e":"markdown","9adee272":"markdown","b284030d":"markdown","bf052105":"markdown","b7d45660":"markdown","cc367a57":"markdown","553efc4e":"markdown","77f7be7e":"markdown","02bf5fe9":"markdown","d1ab4e71":"markdown","4d581ac7":"markdown","36930832":"markdown","d4cc5a21":"markdown","e27bfdff":"markdown","54518adc":"markdown","0a2e32f1":"markdown","332be996":"markdown","283fc3bb":"markdown","db6f4796":"markdown","e1255af9":"markdown","d5904cd8":"markdown","65fa3ce4":"markdown","b5e59983":"markdown"},"source":{"3835f397":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import model_selection\n\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\n\nsns.set(style='ticks')\n%matplotlib inline","16204236":"import os\nprint(os.listdir(\"..\/input\/\"))","9d92e460":"bank=pd.read_csv(\"..\/input\/Bank_Personal_Loan_Modelling.csv\")\n","25f1264a":"bank.head()","1ea67e61":"bank.columns","2fc5a352":"\"\"\"\u2022 ID : Customer ID\n\u2022 Age : Customer's age in completed years\n\u2022 Experience : #years of professional experience\n\u2022 Income : Annual income of the customer ($000)\n\u2022 ZIP Code : Home Address ZIP code.\n\u2022 Family : Family size of the customer\n\u2022 CCAvg : Avg. spending on credit cards per month ($000)\n\u2022 Education : Education Level. 1: Undergrad; 2: Graduate; 3:\nAdvanced\/Professional\n\u2022 Mortgage : Value of house mortgage if any. ($000)\n\u2022 Personal Loan : Did this customer accept the personal loan offered in the last campaign?\n\u2022 Securities Account : Does the customer have a securities account with the bank?\n\u2022 CD Account : Does the customer have a certificate of deposit (CD) account with the bank?\n\u2022 Online : Does the customer use internet banking facilities?\n\u2022 Credit card : Does the customer use a credit card issued byUniversalBank?\n\"\"\"","71342532":"#1.Age\nbank.apply(lambda x : sum(x.isnull()))\n","7077de59":"bank.apply(lambda x: len(x.unique()))\n","59c964e9":"bank.describe().transpose()","af392cbd":"bank.isnull().values.any()","3996940b":"bank.describe(include=\"all\").transpose()\n","b7961133":"plt.figure(figsize=(18,5))\nsns.set_color_codes()\nsns.distplot(bank[\"Age\"])\n","3585d4b2":"plt.figure(figsize=(16,4))\nsns.set_color_codes()\nsns.countplot(bank[\"Age\"])\n","b2f77855":"plt.figure(figsize=(12,4))\nsns.set_color_codes()\nsns.barplot(bank[\"Age\"],bank[\"Personal Loan\"])\n","5d0a0a34":"plt.figure(figsize=(12,4))\nsns.set_color_codes()\nsns.boxplot(y=bank[\"Age\"],x=bank[\"Personal Loan\"])\n","22f18061":"plt.figure(figsize=(12,4))\nsns.set_color_codes()\nsns.violinplot(y=bank[\"Age\"],x=bank[\"Personal Loan\"])\n","dc239534":"plt.figure(figsize=(12,4))\nsns.set_color_codes()\nsns.distplot(bank[\"Experience\"])\n\n\n","f55ad193":"plt.figure(figsize=(12,4))\nsns.set_color_codes()\nsns.distplot(bank[\"Income\"])\n\n\n","caafeca7":"plt.figure(figsize=(12,4))\nsns.set_color_codes()\nsns.distplot(bank[\"Family\"])\n\n\n","1bbb6534":"plt.figure(figsize=(12,4))\nsns.set_color_codes()\nsns.distplot(bank[\"CCAvg\"])","be106833":"sns.pairplot(bank.iloc[:,1:], hue='Personal Loan')","22a3ee25":"colormap = plt.cm.viridis # Color range to be used in heatmap\nplt.figure(figsize=(15,15))\nplt.title('Bank Correlation of attributes', y=1.05, size=19)\nsns.heatmap(bank.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n#There is no strong correlation between any two variables.\n#There is no strong correlation between any independent variable and class variable.","40930fca":"sns.pairplot(bank.iloc[:,1:])","89474530":"bank.head(1)","07108d15":"bank.corr()","d339ed17":"# there are 52 records with negative experience. Before proceeding any further we need to clean the same\nbank[bank['Experience'] < 0]['Experience'].count()","5b28030e":"#clean the negative variable\ndfExp = bank.loc[bank['Experience'] >0]\nnegExp = bank.Experience < 0\ncolumn_name = 'Experience'\nmylist = bank.loc[negExp]['ID'].tolist() # getting the customer ID who has negative experience\nmylist[:1]","93d6a858":"negExp.value_counts()\n","317fd176":"\"\"\"The following code does the below steps:\n\nFor the record with the ID, get the value of Age column\nFor the record with the ID, get the value of Education column\nFilter the records matching the above criteria from the data frame which has records with positive experience and take the median\nApply the median back to the location which had negative experience\n\"\"\"\n","e81beb17":"for id in mylist:\n    age = bank.loc[np.where(bank['ID']==id)][\"Age\"].tolist()[0]\n    education = bank.loc[np.where(bank['ID']==id)][\"Education\"].tolist()[0]\n    df_filtered = dfExp[(dfExp.Age == age) & (dfExp.Education == education)]\n    exp = df_filtered['Experience'].median()\n    bank.loc[bank.loc[np.where(bank['ID']==id)].index, 'Experience'] = exp\nbank.head()","facf0e74":"# checking if there are records with negative experience\nbank[bank['Experience'] < 0]['Experience'].count()\n","73f71b81":"bank.describe().transpose()\n","3801a30a":"#Influence of income and education on personal loan\u00b6\nsns.boxplot(x='Education',y='Income',hue='Personal Loan',data=bank)\n","a578ce35":"sns.boxplot(x=\"Education\", y='Mortgage', hue=\"Personal Loan\", data=bank,color='yellow')\n","b42e3129":"sns.countplot(x=\"Securities Account\", data=bank,hue=\"Personal Loan\")\n","ef8e1e33":"sns.countplot(x='Family',data=bank,hue='Personal Loan',palette='Set1')\n","66401a5d":"sns.countplot(x='CD Account',data=bank,hue='Personal Loan')\n","25777e5e":"sns.distplot( bank[bank['Personal Loan']==0]['CCAvg'], color = 'r')\nsns.distplot( bank[bank['Personal Loan']==1]['CCAvg'], color = 'g')\n","408f9f11":"print('Credit card spending of Non-Loan customers: ',bank[bank['Personal Loan']==0]['CCAvg'].median()*1000)\nprint('Credit card spending of Loan customers    : ', bank[bank['Personal Loan']==1]['CCAvg'].median()*1000)","54f76387":"fig, ax = plt.subplots()\ncolors = {1:'red',2:'yellow',3:'green'}\nax.scatter(bank['Experience'],bank['Age'],c=bank['Education'].apply(lambda x:colors[x]))\nplt.xlabel('Experience')\nplt.ylabel('Age')","1f98c2b9":"corr = bank.corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\n# create a mask so we only see the correlation values once\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","2fc24225":"sns.boxplot(x=bank['Family'],y=bank['Income'],hue=bank['Personal Loan'])\n# Looking at the below plot, families with income less than 100K are less likely to take loan,than families with \n# high income","274a2b2a":"X=bank.drop([\"ID\",\"Experience\",\"Personal Loan\"],axis=1)\ny=bank[\"Personal Loan\"]\n","4d5716ec":"X_train, X_test, y_train, y_test= train_test_split(X,y,random_state=11,test_size=0.3)","01ed66bc":"X_train.shape","267e70c4":"print(\"{0:0.2f}% data is in training set\".format((len(X_train)\/len(bank.index)) * 100))\nprint(\"{0:0.2f}% data is in test set\".format((len(X_test)\/len(bank.index)) * 100))","312eddf9":"# #replace 0 with mean value\n# rep_0=SimpleImputer(missing_values=0,strategy='mean')\n# cols = X_train.columns\n","6d9fca00":"# X_train=pd.DataFrame(rep_0.fit_transform(X_train))\n# x_test=pd.DataFrame(rep_0.fit_transform(X_test))\n# X_train.columns = cols\n# X_test.columns = cols\n# X_train.head()","25d718a2":"# Logistic Regression\nmodel=LogisticRegression(solver='liblinear')\nmodel.fit(X_train, y_train)\ny_predict=model.predict(X_test)\ncoef_df = pd.DataFrame(model.coef_)\ncoef_df['intercept'] = model.intercept_\nprint(coef_df)\n","533548cf":"model_score= model.score(X_test, y_test)\nprint(model_score)","67e5e5df":"cm = metrics.confusion_matrix(y_test, y_predict, labels=[1, 0])\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)","53b8ba57":"NNH = KNeighborsClassifier(n_neighbors= 5 , weights = 'distance' )\nNNH.fit(X_train,y_train)","05c1fb46":"predicted_labels = NNH.predict(X_test)\nNNH.score(X_test, y_test)\n","66ed9435":"# calculate accuracy measures and confusion matrix\nprint(\"Confusion Matrix\")\nmetrics.confusion_matrix(y_test, predicted_labels, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"M\",\"B\"]],\n                   columns = [i for i in [\"Predict M\",\"Predict B\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)","918371a8":"#The model fit substantially with a perfect score on the training set and only 91% accuracy on the test set.\n\n#SVM requires all the features to be on a similar scale. \n#We will need to rescale our data that all the features are approximately\n#on the same scale and than see the performance","2d4db7ee":"#Scale the data points using MinMaxScaler","11c67f13":"scalar=MinMaxScaler()\n","77194f09":"X_train_scaled=scalar.fit_transform(X_train)\nX_test_scaled=scalar.fit_transform(X_test)","6c3756ea":"#Fit SVM Model on Scale data and give your observation\n","c908e70e":"svc=SVC()\nsvc.fit(X_train_scaled,y_train)","2d1636f7":"print(\"Accutacy of Training data set : {:.2f}\".format(svc.score(X_train_scaled,y_train)))\nprint(\"Accutacy of Testing data set : {:.2f}\".format(svc.score(X_test_scaled,y_test)))","d2bec77b":"svc=SVC(C=1000)\nsvc.fit(X_train_scaled,y_train)","372484fb":"print(\"Accutacy of Training data set : {:.2f}\".format(svc.score(X_train_scaled,y_train)))\nprint(\"Accutacy of Testing data set : {:.2f}\".format(svc.score(X_test_scaled,y_test)))","ede71f43":"# Here, increasing C allows us to improve the model, resulting in 98.2% train set accuracy.","ab04d237":"# calculate accuracy measures and confusion matrix\nprint(\"Confusion Matrix\")\nmetrics.confusion_matrix(y_test, predicted_labels, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"M\",\"B\"]],\n                   columns = [i for i in [\"Predict M\",\"Predict B\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)\n","b87f4358":"gnb_model=GaussianNB()","07b2d45a":"gnb_model.fit(X_train,y_train.ravel())","c0f4a2bb":"gnb_model_pred=gnb_model.predict(X_train)","a4f3fc34":"print(\"Model accurace is GNB : {:.2f}\".format(metrics.accuracy_score(y_train,gnb_model_pred)))\nprint()","b12dea8f":"print(gnb_model_pred)\nprint(\"confusing matrics\")\ngnb_model_pred=gnb_model.predict(X_test)\ncm=metrics.confusion_matrix(y_test, gnb_model_pred, labels=[1, 0])\ncm","887dd228":"\ndf_cm=pd.DataFrame(cm,index=[i for i in [\"1\",\"0\"]],columns=[i for i in [\"predict 1\",\"predict 0\"]])\n#plt.figure(figsize=(7,5))\nsns.heatmap(df_cm,annot=True)","f318b5bc":"cm\n","291305f6":"print(\"classification Report\")","1c524760":"print(metrics.classification_report(y_test, gnb_model_pred, labels=[1, 0]))","9f5dd549":"train_set_indep = bank.drop(['Experience' ,'ID'] , axis = 1).drop(labels= \"Personal Loan\" , axis = 1)\ntrain_set_dep = bank[\"Personal Loan\"]\nX = np.array(train_set_indep)\nY = np.array(train_set_dep)\nX_Train = X[ :3500, :]\nX_Test = X[3501: , :]\nY_Train = Y[:3500, ]\nY_Test = Y[3501:, ]\n","2ea1ba90":"knn = KNeighborsClassifier(n_neighbors= 21 , weights = 'uniform', metric='euclidean')\nknn.fit(X_Train, Y_Train)    \npredicted = knn.predict(X_Test)\nacc = accuracy_score(Y_Test, predicted)\nprint(acc)","14083a88":"X=bank.drop(['Personal Loan','Experience','ID'],axis=1)\ny=bank.pop('Personal Loan')","d7be713c":"models = []\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('SVM', SVC()))\n\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n\tkfold = model_selection.KFold(n_splits=10, random_state=12345)\n\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n\tresults.append(cv_results)\n\tnames.append(name)\n\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n\tprint(msg)\n# boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n","0990db68":"# Question 5. Use different classification models (Logistic, K-NN and Na\u00efve Bayes) to predict the likelihood of a customer buying personal loans (25 marks)","19f3c4c4":"# KNN ( K - Nearest Neighbour ) with different value \n","520f0047":"Observation: \nThe graph show persons who have personal loan have a higher credit card average.\nAverage credit card spending with a median of 3800 dollar indicates a higher probability of personal loan.\nLower credit card spending with a median of 1400 dollars is less likely to take a loan. This could be useful information.\n\n","9ad5e286":"# 3. Exploring and preparing the data ","4d51063e":"Observation: Family size does not have any impact in personal loan. But it seems families with size of 3 are more likely to take loan. When considering future campaign this might be good association.\n\n","9adee272":"# Performance of our model with testing data\n","b284030d":"Observation : It seems the customers whose education level is 1 is having more income. However customers who has taken the personal loan have the same income levels\n\n","bf052105":"# Build kNN Model","b7d45660":"# Observation \nThe above plot show with experience and age have a positive correlation. As experience increase age also increases. Also the colors show the education level. There is gap in the mid forties of age and also more people in the under graduate level\n\n","cc367a57":"# Model comparison\u00b6\n","553efc4e":"# Performance of our model with training data","77f7be7e":"# Question 2. Study the data distribution in each attribute, share your findings (15 marks)","02bf5fe9":"# 2. Load data\n","d1ab4e71":"# Train Naive Bayes algorithm ","4d581ac7":"# Age feature is normally distributed with majority of customers falling between 30 years and 60 years of age. We can confirm this by looking at the describe statement above, which shows mean is almost equal to median\nExperience is normally distributed with more customer having experience starting from 8 years. Here the mean is equal to median. There are negative values in the Experience. This could be a data input error as in general it is not possible to measure negative years of experience. We can delete these values, because we have 3 or 4 records from the sample.\nIncome is positively skewed. Majority of the customers have income between 45K and 55K. We can confirm this by saying the mean is greater than the median\nCCAvg is also a positively skewed variable and average spending is between 0K to 10K and majority spends less than 2.5K\nMortgage 70% of the individuals have a mortgage of less than 40K. However the max value is 635K\nThe variables family and education are ordinal variables. The distribution of families is evenly distributes\n# there are 52 records with negative experience. Before proceeding any further we need to clean the same\n","36930832":"#  confusion matrix\n\nTrue Positives (TP): we correctly predicted that they do have loan 40\n\nTrue Negatives (TN): we correctly predicted that they don't have loan 1330\n\nFalse Positives (FP): we incorrectly predicted that they do have loan (a \"Type I error\") 31 Falsely predict positive Type I error\n\nFalse Negatives (FN): we incorrectly predicted that they don't have loan (a \"Type II error\") 112 Falsely predict negative Type II error","d4cc5a21":"print(\"Accuracy of traing data set : {:.2f}\".format(svc.score(X_train,y_train)))\nprint(\"Accuracy of tes data set : {:.2f}\".format(svc.score(X_test,y_test)))","e27bfdff":"# Conclusion\nThe aim of the universal bank is to convert there liability customers into loan customers.\nThey want to set up a new marketing campaign; \nhence, they need information about the connection between the variables given in the data.\nFour classification algorithms were used in this study.\n\nFrom the above graph , \nit seems like Decision LogisticRegression  or SVM have the highest accuracy and we can choose that as our final model","54518adc":"svc=SVC()\nsvc.fit(X_train,y_train)","0a2e32f1":"# 1. Load necessary libraries\n","332be996":"Inference : From the above chart it seems that customer who do not have personal loan and customer who has personal loan have high mortgage\n\n","283fc3bb":"Observation: Customers who does not have CD account , does not have loan as well. This seems to be majority. But almost all customers who has CD account has loan as well\n\n","db6f4796":"Observation\n\nIncome and CCAvg is moderately correlated.\nAge and Experience is highly correlated","e1255af9":"# Question 4. Create training and test datasets\nQuestatio (4). Split the data into training and test set in the ratio of 70:30 respectively (5 marks)","d5904cd8":"#  confusion matrix\n\nTrue Positives (TP): we correctly predicted that they do have loan 40\n\nTrue Negatives (TN): we correctly predicted that they don't have loan 1330\n\nFalse Positives (FP): we incorrectly predicted that they do have loan (a \"Type I error\") 31 Falsely predict positive Type I error\n\nFalse Negatives (FN): we incorrectly predicted that they don't have loan (a \"Type II error\") 112 Falsely predict negative Type II error","65fa3ce4":"Observation : Majority of customers who does not have loan have securities account\n\n","b5e59983":"# Evaluate Performance of kNN Model\n"}}