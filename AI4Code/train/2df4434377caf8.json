{"cell_type":{"d2ddb8ec":"code","34eceaa9":"code","8c09c640":"code","de959e0b":"code","17cb5c67":"code","1ab1c0f4":"code","0b249d5e":"code","2627ceba":"code","eda804b1":"code","5151fa99":"code","cdca2fc6":"code","0fc07cf6":"code","7e2c950a":"code","486dcafd":"code","a7cceeff":"code","a0b7b9d2":"code","4e5d87dc":"code","bd2462e2":"code","0432abc7":"code","a1e58612":"code","d3616e60":"code","e67439fe":"code","861c5cec":"code","5ba1dbcb":"code","f7b4242f":"code","8d8cf60f":"code","5df26c3a":"code","fede8215":"markdown","7e8749d1":"markdown","7aed6c53":"markdown","66dc76f5":"markdown","9553c30d":"markdown","b60f8f3b":"markdown","9645289e":"markdown","65be38f5":"markdown","9c9a9797":"markdown","b129c2bb":"markdown","f67353d2":"markdown","a174f9c1":"markdown","77832354":"markdown","e1a29aa4":"markdown","d95ff988":"markdown","f07e11a5":"markdown","a25b65c5":"markdown","b075b075":"markdown","4d2b2754":"markdown","ab2dd0c6":"markdown"},"source":{"d2ddb8ec":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob,string\npath = '..\/input\/coil-100\/coil-100\/*.png'\n#list files\nfiles=glob.glob(path)","34eceaa9":"import codecs\nfrom tqdm import tqdm\ndef contructDataframe(file_list):\n    \"\"\"\n    this function builds a data frame which contains \n    the path to image and the tag\/object name using the prefix of the image name\n    \"\"\"\n    data=[]\n    for file in tqdm(file_list):\n        data.append((file,file.split(\"\/\")[-1].split(\"__\")[0]))\n    return pd.DataFrame(data,columns=['path','label'])","8c09c640":"df=contructDataframe(files)","de959e0b":"df.tail(10)","17cb5c67":"import seaborn as sns\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\ncounts=df.groupby(df.label).size().reset_index(name=\"counts\")\ncounts.plot.bar()","1ab1c0f4":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.path, df.label, test_size=0.15,random_state=0,stratify= df.label)","0b249d5e":"X_train.groupby(y_train).size().reset_index(name=\"counts\").plot.bar()","2627ceba":"X_test.groupby(y_test).size().reset_index(name=\"counts\").plot.bar()","eda804b1":"from keras.preprocessing.image import load_img,img_to_array\nimport cv2\nX_train=[img_to_array(cv2.imread(file).astype(\"float\")\/255.0) for file in tqdm(X_train.values)]","5151fa99":"X_test=[img_to_array(cv2.imread(file).astype(\"float\")\/255.0) for file in tqdm(X_test.values)]","cdca2fc6":"import matplotlib.pyplot as plt\nimg = X_train[0]\nplt.imshow(img)\nplt.show()","0fc07cf6":"from sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer()\ny_train_categorical=encoder.fit_transform(y_train.values.reshape(-1, 1))\ny_test_categorical=encoder.transform(y_test.values.reshape(-1, 1))\n","7e2c950a":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras_sequential_ascii import sequential_model_to_ascii_printout\nfrom keras.optimizers import Adam\n\ndef build(width, height, depth, classes):\n    # initialize the model\n    model = Sequential()\n    # first set of convolutional layer.\n    model.add(Conv2D(30, (5, 5), input_shape=(128, 128, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    # second set convolutional layer.\n    model.add(Conv2D(15, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    #we will dropout 20% of the neurons to improve generalization.\n    model.add(Dropout(0.2))\n    # Flatten layer\n    model.add(Flatten())\n    # Fully connected layers\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    # Output layer\n    model.add(Dense(classes, activation='softmax'))\n    return model","486dcafd":"EPOCHS = 25\nINIT_LR = 1e-3\nBS = 32\nmodel=build(128,128,3,encoder.classes_.__len__())\n\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\nsequential_model_to_ascii_printout(model)","a7cceeff":"from keras.callbacks import EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\ncallbacks_list = [early_stopping]","a0b7b9d2":"X_train=np.array(X_train)\nX_test=np.array(X_test)","4e5d87dc":"X_train, X_validation, y_train_categorical, y_validation_categorical = train_test_split(X_train, y_train_categorical, test_size=0.15,random_state=0,stratify= y_train_categorical)","bd2462e2":"aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                         horizontal_flip=True, fill_mode=\"nearest\")","0432abc7":"hist = model.fit_generator(aug.flow(X_train, y_train_categorical, batch_size=BS), steps_per_epoch=len(X_train) \/\/ BS,\n                           epochs=EPOCHS,\n                           validation_data=(X_validation, y_validation_categorical),\n                           verbose=1,callbacks=callbacks_list)","a1e58612":"loss, accuracy = model.evaluate(X_test,y_test_categorical, verbose=2)\nprint('Accuracy: %f' % (accuracy*100),'loss: %f' % (loss*100))","d3616e60":"#generate plots\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nplt.figure()\nplt.plot(hist.history['loss'], lw=2.0, color='b', label='train')\nplt.plot(hist.history['val_loss'], lw=2.0, color='r', label='val')\nplt.title('CNN COIL-100')\nplt.xlabel('Epochs')\nplt.ylabel('Cross-Entropy Loss')\nplt.legend(loc='upper right')\nplt.show()\n\n","e67439fe":"plt.figure()\nplt.plot(hist.history['acc'], lw=2.0, color='b', label='train')\nplt.plot(hist.history['val_acc'], lw=2.0, color='r', label='val')\nplt.title('CNN COIL-100')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc='upper left')\nplt.show()","861c5cec":"prediction_test_c=model.predict(X_test)\nprediction_test=encoder.inverse_transform(prediction_test_c)\n\nprediction_train_c=model.predict(X_train)\nprediction_train=encoder.inverse_transform(prediction_train_c)\n\nprediction_validation_c=model.predict(X_validation)\nprediction_validation=encoder.inverse_transform(prediction_validation_c)","5ba1dbcb":"from sklearn.metrics import confusion_matrix\n%config InlineBackend.figure_format = 'retina'\ndef plot_cm(y,y_predict,classes,name):\n    plt.figure(figsize=(30, 30))\n    sns.heatmap(confusion_matrix(y,y_predict), \n            xticklabels=classes,\n            yticklabels=classes)\n    plt.title(name)\n    plt.show()","f7b4242f":"plot_cm(prediction_test,y_test.values,encoder.classes_,\"Test accuracy\")","8d8cf60f":"plot_cm(prediction_validation,encoder.inverse_transform(y_validation_categorical),encoder.classes_,\"Validation accuracy\")","5df26c3a":"plot_cm(prediction_train,encoder.inverse_transform(y_train_categorical),encoder.classes_,\"Train accuracy\")","fede8215":"Then we will evaluate our model using the test set to measure the accuracy in previously unseen cases.","7e8749d1":"Keras use numpy arrays as inputs so we must cast the arrays.","7aed6c53":"As the data set is pretty nice balanced (72 images per each object) we don't need to deal whit techniques to balanced it but we should implement other generalization techniques due to the small number of samples per each class, such as data augmentation for instance.","66dc76f5":"<a id='1.2'><\/a>\n### Reading the images \nAfterwards, we need to import the images and convert them into a compatible format for the CNN , there are many ways to perfom this task, th purpose of this notebook is to be intutive , for tuther uses I highly  recommend to make a look to the [Keras.ImageDataGenerator class](https:\/\/keras.io\/preprocessing\/image\/#imagedatagenerator-class) which also includes  real time data augmentation.","9553c30d":"<a id='3.'>Training and testing<\/a>\n## Training and testing\n\nFinally we will fit  our model  using the train and the validation set. We are using the generalization techniques defined previously such as:\n- Data augmentation\n- Dropout\n- EarlyStopping","b60f8f3b":"Then we will make the prediction for the test, validation and train set. This will help us to see how our model is performing in previously unseen data and detect if we have a problem whit over or underfitting and the generalization of the model.","9645289e":"<a id='1.3'><\/a>\n### Converting labels to one hot encoding\nThen we need to transform our labels from string format to a categorical format so we will use the one hot encoding to represent  the class as vector of zeros where the hot value indicates the class.\nI.e \"obj99\"--->[0,0,0.........,0,1,0] , \"obj2\"--->[0,1,0.........,0,1,0] and so on. \nThen our model prediction will return a vector of probabilities so we will determine the class choosing the biggest value.","65be38f5":"<a id='1.1'><\/a>\n### Split the train and test set\nThen we will split our data set in three parts:\n- **Train set:** this one is used to fit our model parameters.\n- **Validation set:** this one is used to tune the parametes of the model.\n- **Test set :** this one is used to measure the accuracy in unprevious seen data.\n\n___(we will split the train and validation set further to avoid tasks repetition)___","9c9a9797":"Finally we wil plot the confusion matrix for each of the predictions","b129c2bb":"<a id='2.'><\/a>\n## Model desing\nThen we will define our model using conv layers that allow us to input tensor of shape (n,n,d) dimensional with instead of (n,n) dimensional arrays this will help us to input each colour layer of the image and deal with the problem of the colour variation.\n\n- **Convolutional Layer**: This layer tries to find patterns in the images applying filters and then will generate feature maps, this first layer is composed by 30 filters with a size of 5x5  and applies a stride of 1 also uses the relu function as the activation function.\n- **Max pooling layer**: This layer will select the most important features from the conv layer generated feature maps this uses a pool size of 2 and stride equal to 1.\n\n- **Convolutional Layer**: This layer tries to find patterns in the images applying filters and then will generate feature maps, this first layer is composed by 15 filters with a size of 3x3  and applies a stride of 1 also uses the relu function as the activation function.\n- **Max pooling layer**: This layer will select the most important features from the conv layer generated feature maps this uses a pool size of 2 and stride equal to 1.\n- **Dropout layer**: This layer is used to improve the generalization of the model, in this case, this drops 20% of the neurons from the previous layer to force the weights to be distributed equivalently.\n- **Flatten layer**: this layer flattens the input tensor to create a single long feature vector to be used by the dense layer for the final classification.\n- **Dense layer**: this layer also tries to find some relationship between the features coming from the flattening layer.\n- **Output Layer(dense)**: The final layer has 100 neurons that correspond to each class, in this case, we used the softmax function to map a probability for each class.\n","f67353d2":"We used stratification to keep both of the datasets balanced as much as it possible.","a174f9c1":"<a id='2.2'><\/a>\n### Data Aumentation\nAfterwards, we will define an Image generator that will perform data augmentation, this is useful when we have a small number of samples per each class, this generator modifies the images and generates new samples for example in this one we are rotating the images, shifting the images and applying some zoom.\n\nThis process could improve significantly the generalization and the accuracy of the model.","77832354":"Then we will split the train set in two parts one for validation and the other one for training.","e1a29aa4":"## Data Handling \nThe prefix of the image name correponds to the object name\/ class so we need to extract this tag to contruct a labeled data set to train our model.","d95ff988":"<a id='2.1'><\/a>\n### Training params and generalization techniques.\nThen we will define the batch size to 32 samples and devide the training in 25 epochs , also we will use the adam optimizer to learn the parameters for our model, finally we are using the binary_crossentropy as loss the loss function widely use for muticlassification problems.","f07e11a5":"---\n# CNN for Image classification in COIL-100 database.\n---\n\n<br>\n<center>\n    <h3> Abstract <\/h3>\n<p>In the field of computer vision, image classification and object recognition have been a challenge for a long time due to the problems and limitations of traditional computer vision approaches.\nSome problems such as scale, rotation and colour variances have been a problem , since in 2012 Alex Krizhevsky used CNN  to win that year\u2019s ImageNet competition these networks have been some of the most influential innovations not only in computer vision but also in other unusual fields such as NLP due to its particular advantages and characteristics.<\/p>\n<\/center>\n\n### Introduction\n\nIn this kernel we are going to apply this kind of neural networks to classify a famous Object data set called \"Colombia object image library\"  which consists in a collection a of 7,200 images of 100 objects. Also we are goinf to apply some generalization and optimization techniques  to improve the perfomance of the model.\n\n### Table of contents.\n- <a href='#1.0'>1. Data Handling<\/a>\n> - <a href='#1.1'>1.1 Split the train and test set<\/a>\n> - <a href='#1.2'>1.2 Reading the images<\/a>\n> - <a href='#1.3'>1.3 Converting labels to one hot encoding<\/a>\n\n- <a href='#2.'>2. Model desing<\/a>\n> - <a href='#2.1'>2.1 Model desing<\/a>\n> - <a href='#2.2'>2.2 Data Aumentation<\/a>\n\n- <a href='#3.'>3. Training and testing<\/a>","a25b65c5":"Then we have all the images paths whit its label in a dataframe.","b075b075":"Then we will plot the accuracy and the loss behaviour in the train and validation set through the training process.","4d2b2754":"As sanity check we will make a look at the distribution of the data","ab2dd0c6":"Also, we will use the Early stopping technique which consists in monitoring the validation loss and stop the training when the model performance stops its improvement, this prevents overfitting and other generalization problems."}}