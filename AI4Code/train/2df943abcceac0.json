{"cell_type":{"34faeba7":"code","8b4de880":"code","d46f3da7":"code","b358c7d5":"code","826a5ebc":"code","f611ba6b":"code","8cd04004":"code","9e72d263":"code","2ea7aad2":"code","7a19e4f8":"code","7fb67946":"code","6a90d16a":"code","6f2e6f0d":"code","672ec581":"code","36625516":"code","afdb7892":"code","515e8fc4":"code","695621a7":"code","3884905a":"code","d81ca77b":"code","aa4770c9":"code","4e0ecade":"code","f48de35c":"code","7951f8f7":"code","d37fce2c":"code","c4b32f62":"code","6f0928ad":"code","898176db":"code","92947b69":"code","37a8dc04":"code","04eb3be6":"code","363055b9":"code","04b5a555":"markdown","bae2c555":"markdown","084c4148":"markdown","ed32fe3f":"markdown","8ad3f7ed":"markdown","3d15a34b":"markdown","bbbaba73":"markdown","9271b941":"markdown","22b41499":"markdown","e5267578":"markdown","4a369cca":"markdown","5079aa20":"markdown","670ca596":"markdown","e9ba8669":"markdown","75f60a9d":"markdown","779fd3cf":"markdown","8822d3b0":"markdown"},"source":{"34faeba7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8b4de880":"# default libraries\nimport numpy as np\nimport pandas as pd\n\n# for data preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# for classifier models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold, cross_val_score\nimport xgboost as xgb\n\n# for models evaluation\nfrom sklearn.metrics import confusion_matrix, accuracy_score","d46f3da7":"dataset = pd.read_csv(\"\/kaggle\/input\/adult-income-dataset\/adult.csv\")\ndataset.head()","b358c7d5":"dataset.shape","826a5ebc":"dataset.info()","f611ba6b":"dataset.isnull().sum()","8cd04004":"dataset.nunique()","9e72d263":"dataset['income'] = dataset['income'].map({'<=50K':0, '>50K':1})","2ea7aad2":"def init_check(df):\n    \"\"\"\n    A function to make initial check for the dataset including the name, data type, \n    number of null values and number of unique varialbes for each feature.\n    \n    Parameter: dataset(DataFrame)\n    Output : DataFrame\n    \"\"\"\n    columns = df.columns    \n    lst = []\n    for feature in columns : \n        dtype = df[feature].dtypes\n        num_null = df[feature].isnull().sum()\n        num_unique = df[feature].nunique()\n        lst.append([feature, dtype, num_null, num_unique])\n    \n    check_df = pd.DataFrame(lst)\n    check_df.columns = ['feature','dtype','num_null','num_unique']\n    check_df = check_df.sort_values(by='dtype', axis=0, ascending=True)\n    \n    return check_df","7a19e4f8":"#init_check?","7fb67946":"init_check(df=dataset)","6a90d16a":"def categorical_encoding(df, categorical_cloumns, encoding_method):\n    \"\"\"\n    A function to encode categorical features to a one-hot numeric array (one-hot encoding) or \n    an array with value between 0 and n_classes-1 (label encoding).\n    \n    Parameters:\n        df (pd.DataFrame) : dataset\n        categorical_cloumns  (string) : list of features \n        encoding_method (string) : 'one-hot' or 'label'\n    Output : pd.DataFrame\n    \"\"\"\n    \n    if encoding_method == 'label':\n        print('You choose label encoding for your categorical features')\n        encoder = LabelEncoder()\n        encoded = df[categorical_cloumns].apply(encoder.fit_transform)\n        return encoded\n    \n    elif encoding_method == 'one-hot':\n        print('You choose one-hot encoding for your categorical features') \n        encoded = pd.DataFrame()\n        for feature in categorical_cloumns:\n            dummies = pd.get_dummies(df[feature], prefix=feature)\n            encoded = pd.concat([encoded, dummies], axis=1)\n        return encoded","6f2e6f0d":"#categorical_encoding?","672ec581":"categorical_encoding(df=dataset, categorical_cloumns=['workclass','education'], encoding_method='one-hot')","36625516":"categorical_encoding(dataset, categorical_cloumns=['workclass','education'], encoding_method='label')","afdb7892":"y = dataset['income']","515e8fc4":"X = dataset.drop(columns='income', axis=1)\ncategorical_columns = X.select_dtypes(include=['object']).columns\nprint(categorical_columns)","695621a7":"encoded = categorical_encoding(X, categorical_cloumns=categorical_columns, encoding_method='one-hot')\nencoded.head()","3884905a":"X = X.drop(columns=categorical_columns, axis=1)\nX = pd.concat([X, encoded], axis=1)\nX.head()","d81ca77b":"X.shape","aa4770c9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","4e0ecade":"scaler=MinMaxScaler()\nX_train= pd.DataFrame(scaler.fit_transform(X_train))\nX_test = pd.DataFrame(scaler.transform(X_test))","f48de35c":"X_train.describe()","7951f8f7":"def data_preprocessing(df, features, target, encoding_method, test_size, random_state):\n    y = df[target]\n    \n    X = df[features]\n    \n    categorical_columns = X.select_dtypes(include=['object']).columns\n    \n    if len(categorical_columns) != 0 :\n        encoded = categorical_encoding(X, categorical_cloumns=categorical_columns, encoding_method=encoding_method)\n        X = X.drop(columns=categorical_columns, axis=1)\n        X = pd.concat([X, encoded], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    \n    scaler=MinMaxScaler()\n    X_train= pd.DataFrame(scaler.fit_transform(X_train))\n    X_test = pd.DataFrame(scaler.transform(X_test))\n    \n    return X_train, X_test, y_train, y_test","d37fce2c":"features = dataset.columns.drop('income')\n\nX_train, X_test, y_train, y_test = data_preprocessing(df=dataset, features=features, \n                                                      target='income', encoding_method = 'label',\n                                                      test_size=0.2, random_state=123)","c4b32f62":"print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","6f0928ad":"def classifiers_estimator(models, scoring, X_train, y_train, k_fold, shuffle, random_state):\n    \"\"\"\n    A function to estimate the performance of each classification model.\n    \n    Parameters:\n        models (string) : list of classificaton models\n        scoring (string) : quantifying the quality of predictions \n        X_train (np.array or pd.dataframe) : features variable of training data\n        y_train (np.array or pd.dataframe) : target of training data\n        k_fold (int) : number of folds\n        shuffle (boolean) : whether to shuffle the data before splitting into batches\n        random_state (int) : it is the seed used by the random number generator\n    \n    Output (pd.DataFrame) : model performance\n    \"\"\"\n    kf = KFold(n_splits=k_fold, shuffle=shuffle, random_state=random_state)\n    \n    results = []\n    for model in models:\n\n        if model == 'RF':\n            estimator = RandomForestClassifier()\n        elif model == 'LR':\n            estimator = RandomForestClassifier()\n        elif model == 'KNN':\n            estimator == KNeighborsClassifier(n_neighbors = 5)\n        elif model == 'XGB':\n            estimator == xgb.XGBClassifier()\n            \n        cv_results = cross_val_score(estimator=estimator, X=X_train, y=y_train, cv=kf, scoring=scoring, n_jobs=-1)\n        cv_mean_accuracy = cv_results.mean()\n        cv_std_accuracy = cv_results.std()\n        cv_max = cv_results.max()\n        cv_min = cv_results.min()\n        results.append([model, cv_mean_accuracy, cv_std_accuracy, cv_max, cv_min])\n        print('Finish %s model' %model)\n    \n    results_df = pd.DataFrame(results)\n    results_df.columns = ['Models','Mean','Std','Max','Min']\n    \n    return results_df","898176db":"#classifiers_estimator?","92947b69":"classifiers_estimator(['LR', 'RF', 'XGB'], 'accuracy', X_train, y_train, k_fold=6, shuffle=True, random_state=123)","37a8dc04":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nprint(rf.score(X_test, y_test))","04eb3be6":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Make a small change to the code below to use in this problem. \nperm = PermutationImportance(rf, random_state=123).fit(X_test, y_test)\n\n# uncomment the following line to visualize your results\neli5.show_weights(perm, feature_names = features.tolist(), top=150)","363055b9":"features  = ['education','capital-gain']\n\nX_train, X_test, y_train, y_test = data_preprocessing(df=dataset, features=features, \n                                                      target='income', encoding_method = 'label',\n                                                      test_size=0.2, random_state=123)\n\nclassifiers_estimator(['LR', 'RF', 'XGB'], 'accuracy', X_train, y_train, k_fold=10, shuffle=True, random_state=123)","04b5a555":"### a. Cleaning the data","bae2c555":"### a. Model performance comparison","084c4148":"# Adult income dataset","ed32fe3f":"## Step 5. Loop (Feature selection)","8ad3f7ed":"### b. Feature importance","3d15a34b":"### e. Data split and data scaling","bbbaba73":"1. We can speed up the analysis flow and make analysis more readable by modularizing data preprocess and moelliing process.\n2. What is the difference between the one-hot and label encoding on feature importance ?\n3. Data analysis is not a one-and-done process.","9271b941":"## Conclusion","22b41499":"### b. Making code modular ","e5267578":"### d. Feature engineering","4a369cca":"### c. Visualizing the data\n\nSkip","5079aa20":"## Step 2. Loading the dataset","670ca596":"### [Model evaluation: quantifying the quality of predictions](https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html)","e9ba8669":"=======================================================================================================","75f60a9d":"## Step 3. Exploratory data analysis EDA - Data cleaning and exploration","779fd3cf":"## Step 1. What is the goal of this analysis ?\nThe goal is to train a binary classifier on the training dataset to predict the column income_bracket which has two possible values \">50K\" and \"<=50K\" and evaluate the accuracy of the classifier with the test dataset. ","8822d3b0":"## Step 4. Data modelling"}}