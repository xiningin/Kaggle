{"cell_type":{"8e39133f":"code","5a9e844a":"code","e1eccf2e":"code","c1565f02":"code","a0272d02":"code","660bb628":"code","906bc9f2":"code","ae650307":"code","449eb96f":"code","841be0ea":"code","e276a7c1":"code","a56aaa35":"code","63ef71b8":"code","4b7adcf4":"markdown","8e5325c1":"markdown","6206a139":"markdown","1fbe4e0a":"markdown","6b9270a0":"markdown","21ab4425":"markdown","9162ed36":"markdown"},"source":{"8e39133f":"cd \/kaggle\/input","5a9e844a":"ls","e1eccf2e":"pip install livelossplot==0.5.2","c1565f02":"import tensorflow.keras as keras\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n%matplotlib inline\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\n\nfrom IPython.display import SVG, Image\nfrom livelossplot import PlotLossesKerasTF\nimport tensorflow as tf\nprint(\"Tensorflow version:\", tf.__version__)","a0272d02":"for expression in os.listdir(\"NITROHCS_V1.0\/\"):\n    print(str(len(os.listdir(\"NITROHCS_V1.0\/\" + expression))) + \" \" + expression + \" images\")","660bb628":"img_size = 48\nbatch_size = 64\n\ndatagen = ImageDataGenerator(zoom_range = 0.2, rescale=1.\/255, validation_split = 0.3)\n#ImageDataGenerator accepts the original data, randomly transforms it, and returns only the new, transformed data\n#Translations, Rotations, Changes in scale, Shearing, Horizontal (and in some cases, vertical) flips\n\ntrain_generator = datagen.flow_from_directory(\"NITROHCS_V1.0\/\",\n                                                    target_size=(img_size,img_size),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    subset='training',\n                                                    shuffle=True)\n\ndatagen_validation = ImageDataGenerator(horizontal_flip=True)\nvalidation_generator = datagen.flow_from_directory(\"NITROHCS_V1.0\/\",\n                                                    target_size=(img_size,img_size),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                              subset='validation',\n                                                    shuffle=True)","906bc9f2":"'''train_datagen = ImageDataGenerator(rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation') # set as validation data\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ batch_size,\n    epochs = nb_epochs)'''","ae650307":"# Initialising the CNN\nmodel = Sequential()\n\n# 1 - Convolution\nmodel.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(128,(5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(47, activation='softmax'))\n\nopt = Adam(lr=0.0005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","449eb96f":"'''steps_per_epoch = train_generator.n\/\/train_generator.batch_size\nvalidation_steps = validation_generator.n\/\/validation_generator.batch_size\nmodel.fit(\n        train_generator,\n        steps_per_epoch=steps_per_epoch,\n        epochs=20,\n        validation_data=validation_generator,\n        validation_steps=validation_steps)'''","841be0ea":"%%time\n\nepochs = 30\nsteps_per_epoch = train_generator.n\/\/train_generator.batch_size\nvalidation_steps = validation_generator.n\/\/validation_generator.batch_size\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=0.00001, mode='auto')\ncheckpoint = ModelCheckpoint(\"odia_weights.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\ncallbacks = [PlotLossesKerasTF(), checkpoint, reduce_lr]\n\nhistory = model.fit(\n    x=train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = validation_steps,\n    callbacks=callbacks\n)","e276a7c1":"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\naxes[0].set_title('Loss')\naxes[0].plot(history.history['loss'], label='Train')\naxes[0].plot(history.history['val_loss'], label='Validation')\naxes[0].legend()\n\naxes[1].set_title('Accuracy')\naxes[1].plot(history.history['accuracy'], label='Train')\naxes[1].plot(history.history['val_accuracy'], label='Validation')\naxes[1].legend()\n\nplt.show()","a56aaa35":"cd \/kaggle\/working\/","63ef71b8":"model_json = model.to_json()\nwith open(\"odia1.json\", \"w\") as json_file:\n    json_file.write(model_json)","4b7adcf4":"### Task 1: Import Libraries","8e5325c1":"### Task 4: Create CNN Model","6206a139":"### Task 2: Plot Sample Images","1fbe4e0a":"### Task 6: Train and Evaluate Model","6b9270a0":"<h2 align=center> Odia Character Recognition<\/h2>","21ab4425":"### Task 7: Represent Model as JSON String","9162ed36":"### Task 3: Generate Training and Validation Batches"}}