{"cell_type":{"df5d79c7":"code","0ce1c1fa":"code","2ce6bbe7":"code","f94db952":"code","7a862f75":"markdown","ba922453":"markdown","15e5eb89":"markdown","f943b723":"markdown","f9121fa5":"markdown","e3fac571":"markdown","dec954d3":"markdown"},"source":{"df5d79c7":"import pandas as pd\nimport numpy as np","0ce1c1fa":"def optimize_memory_usage(df, print_size=True):\n    # Function optimizes memory usage in dataframe.\n    \n    # Types for optimization.\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    # Memory usage size before optimize (Mb).\n    before_size = df.memory_usage().sum() \/ 1024**2    \n    for column in df.columns:\n        column_type = df[column].dtypes\n        if column_type in numerics:\n            column_min = df[column].min()\n            column_max = df[column].max()\n            if str(column_type).startswith('int'):\n                if column_min > np.iinfo(np.int8).min and column_max < np.iinfo(np.int8).max:\n                    df[column] = df[column].astype(np.int8)\n                elif column_min > np.iinfo(np.int16).min and column_max < np.iinfo(np.int16).max:\n                    df[column] = df[column].astype(np.int16)\n                elif column_min > np.iinfo(np.int32).min and column_max < np.iinfo(np.int32).max:\n                    df[column] = df[column].astype(np.int32)\n                elif column_min > np.iinfo(np.int64).min and column_max < np.iinfo(np.int64).max:\n                    df[column] = df[column].astype(np.int64)  \n            else:\n                if column_min > np.finfo(np.float32).min and column_max < np.finfo(np.float32).max:\n                    df[column] = df[column].astype(np.float32)\n                else:\n                    df[column] = df[column].astype(np.float64)    \n    # Memory usage size after optimize (Mb).\n    after_size = df.memory_usage().sum() \/ 1024**2\n    if print_size: print('Memory usage size: before {:5.4f} Mb - after {:5.4f} Mb ({:.1f}%).'.format(before_size, after_size, 100 * (before_size - after_size) \/ before_size))\n    return df","2ce6bbe7":"def import_data_from_csv(filePath):\n    # Load a dataframe from csv-file and optimize its memory usage.\n    df = pd.read_csv(filePath, parse_dates=True, keep_date_col=True)\n    # Show dataframe info before optimize.\n    print('-' * 80)\n    print(df.info())\n    print('-' * 80)\n    df = optimize_memory_usage(df)\n    # Show dataframe info after optimize.\n    print('-' * 80)\n    print(df.info())\n    print('-' * 80)\n    return df","f94db952":"df = import_data_from_csv('data.csv')","7a862f75":"Sample of usage:","ba922453":"Typically, data for analysis is quite large by itself and when loaded takes from hundreds of megabytes to gigabytes.\n\nIn addition, when loading data into a dataframe, numeric values do not always get the most suitable types, for example, **instead of int8, the int64 type is assigned**, which increases the amount of memory used for the dataframe significantly.\n\nThis function will allow you to quickly override the specified types if possible and in some cases significantly **reduce the memory size** for the dataframe.","15e5eb89":"Sample of result:\n\n![image.png](attachment:efc6e6a7-902d-42a0-bbb1-f98d60065937.png)\n\nAs you can see that when loading the dataframe, the types were assigned - float64 (1) and int64 (2), and after optimization they were converted to float32 (1), int16 (1) and int8 (1).","f943b723":"# Optimizing dataframe memory size by converting numeric types","f9121fa5":"Sample function for load data from csv:","e3fac571":"For example, using this function in [notebook here](https:\/\/www.kaggle.com\/ellavs\/tabular-playground-nov-21-very-simple-xgb) and get optimize memory over 50%:\n\n![image.png](attachment:49aebc58-016a-420b-844e-ea88f3e56416.png)","dec954d3":"# Load dataframe from csv with memory usage optimization (function)"}}