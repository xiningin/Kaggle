{"cell_type":{"b12517a3":"code","c7da4bf6":"code","5264d0af":"code","f3bb0722":"code","28ed5310":"code","d4e9cca5":"code","4b6de8a5":"code","d47c468a":"code","fea42206":"code","eac07600":"code","bd8c4c80":"code","6bc6afb5":"code","84af9051":"code","edb45161":"code","2120272d":"code","810fcf1f":"code","2804a004":"code","380f0185":"code","56de5ce0":"code","7d998fc5":"code","89021c8c":"code","1ea8f58b":"code","c2324a6f":"code","81968b48":"code","50f1811a":"code","7e34de25":"code","7beae1d6":"code","8b43d7d6":"code","ff2f68fc":"code","dd76b7f6":"code","2df9da27":"code","9e4b6dca":"code","d743816a":"code","a7737df8":"code","290b3983":"code","2b793388":"code","35975d3f":"code","dfc71ed8":"code","0d3fc387":"code","b3ab99e2":"code","46a6f7b8":"code","92616327":"code","f3cdebc8":"code","f3ae9abc":"code","c4c650fa":"markdown","2832e7f0":"markdown","28aba721":"markdown","bf8bab8d":"markdown","feda140b":"markdown","bafb4f00":"markdown","2269e9cb":"markdown","ddf36586":"markdown","20ee3957":"markdown","4ce6233e":"markdown","3886c4f0":"markdown","4a72467e":"markdown","485254d6":"markdown","bf5ef22d":"markdown","8c023d82":"markdown","963c5bf1":"markdown","0bf198a0":"markdown","513b9cb4":"markdown","ba90f370":"markdown","2758d97f":"markdown","429c275f":"markdown","07ad5871":"markdown"},"source":{"b12517a3":"!pip install --no-index -q --use-feature=2020-resolver -f ..\/input\/kaggle-l5kit-110 l5kit ","c7da4bf6":"!nvcc --version","5264d0af":"import l5kit\nimport torch\nimport torchvision\nl5kit.__version__, torch.__version__, torchvision.__version__, torch.cuda.is_available()","f3bb0722":"import os\nimport l5kit\nimport torch\nimport zarr\nimport pandas as pd\nimport numpy as np\nfrom l5kit.data import LocalDataManager, ChunkedDataset\nfrom l5kit.dataset import AgentDataset, EgoDataset","28ed5310":"os.environ[\"L5KIT_DATA_FOLDER\"] = \"..\/input\/lyft-motion-prediction-autonomous-vehicles\"","d4e9cca5":"dm = LocalDataManager()","4b6de8a5":"%%time\nsample_dataset = ChunkedDataset(dm.require('scenes\/sample.zarr'))\nsample_dataset.open()\nprint(sample_dataset)","d47c468a":"%%time\ntrain_dataset = ChunkedDataset(dm.require('scenes\/train.zarr'))\ntrain_dataset.open()\nprint(train_dataset)","fea42206":"%%time\nval_dataset = ChunkedDataset(dm.require('scenes\/validate.zarr'))\nval_dataset.open()\nprint(val_dataset)","eac07600":"%%time\ntest_dataset = ChunkedDataset(dm.require('scenes\/test.zarr'))\ntest_dataset.open()\nprint(test_dataset)","bd8c4c80":"del train_dataset\ndel val_dataset","6bc6afb5":"sample_dataset.scenes","84af9051":"sample_dataset.frames","edb45161":"sample_dataset.tl_faces","2120272d":"sample_dataset.agents","810fcf1f":"agents_df = pd.DataFrame.from_records(sample_dataset.agents, columns = ['centroid', 'extent', 'yaw', 'velocity', 'track_id', 'label_probabilities'])\nagents_df","2804a004":"agents_df.track_id.value_counts()","380f0185":"from l5kit.data import PERCEPTION_LABELS\n\nagents_df['label_probabilities'].map(np.argmax).map(lambda i: PERCEPTION_LABELS[i]).value_counts()","56de5ce0":"agents_df['label_probabilities'].map(np.max).map(lambda p: int(p * 10) \/ 10.).value_counts()","7d998fc5":"scene_df = pd.DataFrame.from_records(sample_dataset.scenes, columns=('frame_index_interval', 'host', 'start_time', 'end_time'))\nscene_df","89021c8c":"scene_df['host'].value_counts()","1ea8f58b":"frames_df = pd.DataFrame.from_records(sample_dataset.frames, columns = ['timestamp', 'agent_index_interval', 'traffic_light_faces_index_interval', 'ego_translation', 'ego_rotation'])\nframes_df","c2324a6f":"tl_faces_df = pd.DataFrame.from_records(sample_dataset.tl_faces, columns = ['face_id', 'traffic_light_id', 'traffic_light_face_status'])\ntl_faces_df","81968b48":"del sample_dataset","50f1811a":"test_dataset.scenes","7e34de25":"test_dataset.frames","7beae1d6":"test_dataset.agents","8b43d7d6":"test_dataset.tl_faces","ff2f68fc":"scene_df = pd.DataFrame.from_records(test_dataset.scenes, columns=('frame_index_interval', 'host', 'start_time', 'end_time'))\nscene_df","dd76b7f6":"agents_df = pd.DataFrame.from_records(zarr.array(test_dataset.agents[:50000]), \n                                      columns = ['centroid', 'extent', 'yaw', 'velocity', 'track_id', 'label_probabilities'])\nagents_df","2df9da27":"agents_df.track_id.value_counts()","9e4b6dca":"frames_df = pd.DataFrame.from_records(zarr.array(test_dataset.frames[:10000]), columns = ['timestamp', 'agent_index_interval', 'traffic_light_faces_index_interval', 'ego_translation', 'ego_rotation'])\nframes_df","d743816a":"CONFIG_DATA = {\n    \"format_version\": 4,\n    \"model_params\": {\n        \"model_architecture\": \"resnet50\",\n        # max is 99, but set to 101 never the less\n        \"history_num_frames\": 101,\n        \"history_step_size\": 1,\n        \"history_delta_time\": 0.1,\n        \"future_num_frames\": 50,\n        \"future_step_size\": 1,\n        \"future_delta_time\": 0.1,\n    },\n    \"raster_params\": {\n        \"raster_size\": [256, 256],\n        \"pixel_size\": [0.5, 0.5],\n        \"ego_center\": [0.25, 0.5],\n        \"map_type\": \"py_semantic\",\n        \"satellite_map_key\": \"aerial_map\/aerial_map.png\",\n        \"semantic_map_key\": \"semantic_map\/semantic_map.pb\",\n        \"dataset_meta_key\": \"meta.json\",\n        \"filter_agents_threshold\": 0.5,\n        \"disable_traffic_light_faces\": False,\n    },\n    \"test_dataloader\": {\n        \"key\": \"scenes\/test.zarr\",\n        \"batch_size\": 16,\n        \"shuffle\": False,\n        \"num_workers\": 4,\n    },\n}","a7737df8":"test_mask = np.load(f\"..\/input\/lyft-motion-prediction-autonomous-vehicles\/scenes\/mask.npz\")[\"arr_0\"]","290b3983":"from l5kit.rasterization import build_rasterizer\n\nrast = build_rasterizer(CONFIG_DATA, dm)","2b793388":"agent_dataset = AgentDataset(\n    CONFIG_DATA, test_dataset, rast, agents_mask=test_mask\n)","35975d3f":"len(agent_dataset)","dfc71ed8":"from tqdm.notebook import tqdm\nfrom itertools import islice\n\nitems = []\ntrack_ids = []\nfor i in tqdm(islice(agent_dataset, 20)):\n    track_ids.append(i['track_id'])\n    items.append(i)","0d3fc387":"len(track_ids), len(set(track_ids))","b3ab99e2":"items[0].keys()","46a6f7b8":"items[0]['track_id']","92616327":"[len(item['history_availabilities']) for item in items]","f3cdebc8":"items[0]['history_positions']","f3ae9abc":"items[0]['history_yaws']","c4c650fa":"## Explore Test Dataset","2832e7f0":"And softmax distributions?","28aba721":"### Agent labels","bf8bab8d":"Note that if you just do `pip install torch` with Internet (i.e. install from pypi index), it'll by default install the cuda 10.2 version which isn't compatible with cuda 10.1 version that comes with Kaggle GPU docker image. Here the dataset `kaggle-l5kit-110` has been setup to download cuda 10.1 version so you can proceed with no issues.\n\nWe can see the GPU and cuda version works correctly now.","feda140b":"## AgentDataSet","bafb4f00":"### Test Scenes","2269e9cb":"It seems that the average scene time is different (10.0s in test versus 24.8s in sample, train, and validate)","ddf36586":"### Frames","20ee3957":"### Test Frames (sample 10000)","4ce6233e":"**notice how the tailing 2 items (101 - 99) are empty**","3886c4f0":"## Explore sample dataset","4a72467e":"## Install `l5kit`","485254d6":"## Notebook setup\n\n1. accelerator type set to `GPU`\n1. mount `kaggle-l5kit-110` data volume\n1. turn off internet because it is required if you want to submission the notebook (also all dependencies are within the data valume)","bf5ef22d":"### Scenes","8c023d82":"And their tracks","963c5bf1":"### Test Agents (sample 50000)","0bf198a0":"### set env variable for data and initialize DataManager","513b9cb4":"Classifications?","ba90f370":"Scene hosts?","2758d97f":"## Package imports and setups","429c275f":"## Datasets\n\nAnd print a brief summary for all of them","07ad5871":"What are their track ids?"}}