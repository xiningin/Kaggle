{"cell_type":{"07f5a77d":"code","5d684af1":"code","924654c0":"code","0bdcd001":"code","679248b7":"code","bf5f14ad":"code","e653b793":"code","bb32eee5":"code","e058e5b3":"code","cb2ff1b7":"code","be2d0263":"code","17164a77":"code","6f9d2262":"code","92a2c12c":"code","4e35c7a1":"code","161ace37":"code","5e5d75c2":"code","0d55a19a":"code","d6918328":"code","0454bc68":"code","6348b7f9":"code","646edccf":"code","40e02479":"code","c0891c5e":"code","fefae3f8":"code","c489af3f":"code","db2eaefc":"code","1f96752c":"code","3ef5af99":"code","7b2cece0":"code","0009f093":"code","cebaa593":"code","11c5b5b7":"code","acff7922":"code","40ca79a0":"code","3edba48b":"code","33db8ac5":"code","af3abf3a":"markdown","92b9985e":"markdown","428eef62":"markdown","6750f7eb":"markdown","deca3bc7":"markdown","ae063d3c":"markdown","8aced81a":"markdown","d1052200":"markdown","163313c8":"markdown","60a5629f":"markdown","453647fd":"markdown","3ce584ab":"markdown","105fc2a8":"markdown","de3f4fb5":"markdown","8286dedd":"markdown","edb07483":"markdown","069ee8b5":"markdown","c1046a66":"markdown","681521a8":"markdown","88bdb5bb":"markdown"},"source":{"07f5a77d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5d684af1":"import warnings\nwarnings.filterwarnings(\"ignore\")","924654c0":"import matplotlib.pyplot as plt\n%matplotlib inline","0bdcd001":"from sklearn.model_selection import train_test_split","679248b7":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K","bf5f14ad":"train = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\n(train.head(5))","e653b793":"test = pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head(5)","bb32eee5":"x_train = train.iloc[:,1:].values.astype(\"float32\")\ny_train = train.iloc[:,0].values.astype(\"int32\")\ny_train = y_train.reshape(y_train.shape[0],1)\nx_test = test.values.astype(\"float32\")","e058e5b3":"x_train.shape, y_train.shape, x_test.shape","cb2ff1b7":"x_train = x_train.reshape(x_train.shape[0], 28, 28)\n\nfor i in range(6,9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i])","be2d0263":"x_train = x_train.reshape(x_train.shape[0], 28,28,1)","17164a77":"x_train.shape","6f9d2262":"mean_value = x_train.mean().astype(\"float32\")\nstd_value = x_train.mean().astype(\"float32\")\n\ndef standardize(x):\n    return (x-mean_value)\/std_value","92a2c12c":"from keras.utils.np_utils import to_categorical\n\ny_train = to_categorical(y_train)\nprint(y_train.shape)\nnum_classes = y_train.shape[1]\nprint(num_classes)","4e35c7a1":"# plot any label (for ex 10th label)\n\nplt.title(y_train[9])\nplt.plot(y_train[9])\nplt.xticks(range(10))\nplt.show()","161ace37":"# seed for reproducibility\n\nseed = 43\nnp.random.seed(seed)","5e5d75c2":"from keras.models import Sequential\nfrom keras.layers.core import Dropout, Dense, Lambda, Flatten\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, MaxPooling2D, Convolution2D","0d55a19a":"model = Sequential()\nmodel.add(Lambda(standardize, input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation=\"softmax\"))\n\nprint(\"input shape : \", model.input_shape)\nprint(\"output shape : \", model.output_shape)","d6918328":"from keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(lr=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","0454bc68":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()","6348b7f9":"from sklearn.model_selection import train_test_split\nx = x_train\ny = y_train\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n\nbatches = gen.flow(x_train, y_train, batch_size=64)\nval_batches = gen.flow(x_val, y_val, batch_size=64)","646edccf":"history = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3, validation_data=val_batches, validation_steps=val_batches.n)","40e02479":"history_dict = history.history\nhistory_dict","c0891c5e":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nloss_values = history_dict[\"loss\"]\nval_loss_values = history_dict[\"val_loss\"]\nepochs = range(1, len(loss_values)+1)\n\nplt.plot(epochs, loss_values, \"-bo\")\nplt.plot(epochs, val_loss_values, \"-b+\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Losses\")\nplt.show()","fefae3f8":"acc_values = history_dict[\"acc\"]\nval_acc_values = history_dict[\"val_acc\"]\nplt.plot(epochs, acc_values, \"-ro\")\nplt.plot(epochs, val_acc_values, \"-r+\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.show()","c489af3f":"def get_fc_model():\n    model = Sequential([Lambda(standardize, input_shape=(28,28,1)),Flatten(),Dense(512, activation='relu'),Dense(10, activation='softmax')])\n    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])\n    return model\n\nfc = get_fc_model()\nfc.optimizer.lr=0.01","db2eaefc":"history = fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, validation_data=val_batches, validation_steps=val_batches.n)","1f96752c":"from keras.layers import Convolution2D, MaxPooling2D","3ef5af99":"def get_cnn_model():\n    model = Sequential( [Lambda(standardize, input_shape=(28,28,1)), Convolution2D(32,(3,3), activation=\"relu\"), Convolution2D(32,(3,3), activation='relu'), MaxPooling2D(), Convolution2D(64,(3,3), activation='relu'), Convolution2D(64,(3,3), activation='relu'), MaxPooling2D(), Flatten(), Dense(512, activation='relu'), Dense(10, activation='softmax') ] )\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","7b2cece0":"model = get_cnn_model()\nmodel.optimizer.lr=0.01","0009f093":"history = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, validation_data=val_batches, validation_steps=val_batches.n)","cebaa593":"gen = ImageDataGenerator( rotation_range=8, width_shift_range=0.08, shear_range=0.3, height_shift_range=0.08, zoom_range=0.08 )\nbatches = gen.flow(x_train, y_train, batch_size=64)\nval_batches = gen.flow(x_val, y_val, batch_size=64)","11c5b5b7":"model.optimizer.lr=0.001\nhistory = model.fit_generator( generator=batches, steps_per_epoch=batches.n, epochs=1, validation_data=val_batches, validation_steps=val_batches.n )","acff7922":"from keras.layers.normalization import BatchNormalization","40ca79a0":"def get_bn_model():\n    model = Sequential( [ Lambda(standardize, input_shape=(28,28,1)), Convolution2D(32,(3,3), activation='relu'),BatchNormalization(axis=1),Convolution2D(32,(3,3), activation='relu'),MaxPooling2D(),BatchNormalization(axis=1),Convolution2D(64,(3,3), activation='relu'),BatchNormalization(axis=1),Convolution2D(64,(3,3), activation='relu'),MaxPooling2D(),Flatten(),BatchNormalization(),Dense(512, activation='relu'),BatchNormalization(),Dense(10, activation='softmax') ] )\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","3edba48b":"model = get_bn_model()\nmodel.optimizer.lr=0.01\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, validation_data=val_batches, validation_steps=val_batches.n)","33db8ac5":"model.optimizer.lr=0.01\ngen = image.ImageDataGenerator()\nbatches = gen.flow(X, y, batch_size=64)\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)","af3abf3a":"**load train and test data**","92b9985e":"**Convolutional neural network**","428eef62":"Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. Adding another Dense Layer to model.","6750f7eb":"****Preprocessing the digit images****","deca3bc7":"**import libraries**","ae063d3c":"Before making network ready for training we have to make sure to add below things:\n\nA loss function: to measure how good the network is\n\nAn optimizer: to update network as it sees more data and reduce loss value\n\nMetrics: to monitor performance of network","8aced81a":"The complete notebook is inspired and adopted by the kernal [https:\/\/www.kaggle.com\/poonaml\/deep-neural-network-keras-way](http:\/\/) from Poonam Ligade.\n","d1052200":"**Linear Model**","163313c8":"**Reference**","60a5629f":"**feature standardization**","453647fd":"**Data Augmentation**\n\nIt is tehnique of showing slighly different or new images to neural network to avoid overfitting. And to achieve better generalization. In case you have very small dataset, you can use different kinds of data augmentation techniques to increase your data size. Neural networks perform better if you provide them more data.\n\nDifferent data aumentation techniques are as follows:\n\nCropping\nRotating\nScaling\nTranslating\nFlipping\nAdding Gaussian noise to input images etc.","3ce584ab":"**Data Visualization**","105fc2a8":"**Batch Normalization**","de3f4fb5":"**Designing neural network architecture**","8286dedd":"**cross validation**","edb07483":"Batch Normalization helps to fine tune hyperparameters more better and train really deep neural networks.","069ee8b5":"**compile network**","c1046a66":"**Fully connnected model**","681521a8":"**one hot encoding of labels**","88bdb5bb":"Lets create a simple model from Keras Sequential layer.\n\nLambda layer performs simple arithmetic operations like sum, average, exponentiation etc.\n\nIn 1st layer of the model we have to define input dimensions of our data in (rows,columns,colour channel) format. (In theano colour channel comes first)\n\nFlatten will transform input into 1D array.\nDense is fully connected layer that means all neurons in previous layers will be connected to all neurons in fully connected layer. In the last layer we have to specify output dimensions\/classes of the model. Here it's 10, since we have to output 10 different digit labels."}}