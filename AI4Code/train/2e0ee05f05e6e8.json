{"cell_type":{"d24327eb":"code","2ac397e4":"code","4ff395cf":"code","9ef07762":"code","8d1a4ec4":"code","e0a86ff7":"code","c376f2ae":"code","fbacbd2d":"code","c15053a0":"code","a1f5b586":"code","1a2b6573":"code","0160442e":"code","b3c11ecd":"code","581dc899":"code","ae8b2fe5":"code","6bb364e2":"code","e4fe1bc6":"code","2a339da2":"code","2fda5132":"code","ed08336e":"code","83527bcf":"code","9612048e":"code","f9716682":"code","a3fc8bf8":"code","7274a316":"code","19185d85":"code","a8bcde26":"code","60dd4126":"code","cada334d":"code","8c93f3a3":"code","220b66c9":"code","243c0afa":"code","8013ab96":"code","a2bcd43a":"code","3baec091":"code","5fcd20fe":"code","054028ba":"code","10a02dd8":"code","fcd198f1":"code","0f7d4183":"code","467d11be":"code","f11a96e1":"code","c770320b":"code","0c342902":"code","9dc57615":"code","27d05f3c":"code","f7885a72":"code","9405c72d":"code","b63f8fab":"code","90e1d045":"code","1e21d247":"code","eedb26d4":"code","4679893c":"code","688e1e2c":"code","157ba9c3":"code","142b9d93":"code","35864e40":"code","e773d5b3":"code","2922f3f8":"code","64cd58ea":"code","eb4bb90c":"code","3a432082":"code","e38c2fa0":"code","e8934f2f":"code","f0eb4279":"code","b2976d11":"code","f6780048":"code","98112477":"code","64299eda":"code","f0718f06":"code","0cdc694b":"code","cc41d151":"code","b6abd584":"code","1ca62a7a":"code","862326bc":"code","b5a8cf50":"code","c73c0f4b":"code","4c80e203":"code","7d35018e":"code","6ecfef76":"markdown","a59f6df8":"markdown","4d326e4e":"markdown","be7014dc":"markdown","244bd29a":"markdown","3a1fa51a":"markdown","78c77873":"markdown","d0b67084":"markdown","34e57a1f":"markdown","f3e80a82":"markdown","9304087d":"markdown","543d974a":"markdown","5e6e8b5e":"markdown","bdb121ad":"markdown","3424b1db":"markdown","537b979d":"markdown","e0a2fdcd":"markdown","fd23c641":"markdown","85bd2e7b":"markdown","0bb2bfc2":"markdown","50904f6e":"markdown","b4fd3280":"markdown","20f621ee":"markdown"},"source":{"d24327eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2ac397e4":"#importing usefull lib\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings as wr\nwr.filterwarnings(\"ignore\")\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","4ff395cf":"#reading the data using pandas read_csv. \n#It's ofthen used pandas fuction to read csc file.\nimport pandas as pd\ndf1=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf1.head()","9ef07762":"# checking the shape of data frame\ndf1.shape","8d1a4ec4":"#describe data frame\ndf1.describe()","e0a86ff7":"# extracting all columns from data frame for further uses\ndf1.columns.tolist()","c376f2ae":"# count NA values\ndf1.isnull().sum()","fbacbd2d":"# here we drop cabin bcz its have lots of NA vlues\n# here is no use of PassengerId and Ticket in training so drop it\ndf = df1.drop([\"PassengerId\", \"Ticket\", \"Cabin\"], axis = 1)\ndf.head()","c15053a0":"# here we will fill NA values with mean for numerical valuesand\n# with mode for categorical values\ndf[\"Age\"].fillna(df[\"Age\"].mean(), inplace = True)\ndf[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0], inplace = True)","a1f5b586":"df.info()","1a2b6573":"print(f'Number of people as 0 are {df.Survived.value_counts()[0]} and number of people surviced as 1 are {df.Survived.value_counts()[1]}')\nsns.countplot(df[\"Survived\"])","0160442e":"# here we will check outlliers\nf, ax = plt.subplots()\nsns.violinplot(data = df.iloc[:, 5:7])\nsns.despine(offset = 10, trim = True)","b3c11ecd":"f, ax = plt.subplots()\nsns.violinplot(data = df.iloc[:, 0:2])\nsns.swarmplot(data = df.iloc[:, 0:2], color = \"white\")","581dc899":"#here we are going to plot scaterplot to see data distribution\nsns.relplot(x = \"Pclass\", y = \"Age\", hue = \"Survived\", data = df);","ae8b2fe5":"# visualisation how many pasanger survived and how many dead\n#here we create a function for bar_chart\n#for avoiding write same code for defferent columns\n\ndef bar_chart(column):\n    survived = df[df[\"Survived\"] == 1][column].value_counts()\n    dead = df[df[\"Survived\"] == 0][column].value_counts()\n    df1 = pd.DataFrame([survived, dead])\n    df1.index = [\"Survived\", \"Dead\"]\n    df1.plot(kind = \"bar\", figsize = (10, 5))","6bb364e2":"bar_chart(\"Sex\")","e4fe1bc6":"#here we going to make bar chart on Pclass\nbar_chart(\"Pclass\")","2a339da2":"#here we going to make bar chart on sibsp\nbar_chart(\"SibSp\")","2fda5132":"bar_chart(\"Parch\")","ed08336e":"bar_chart(\"Embarked\")","83527bcf":"#visualization data on boxplot to see the uotliers\ndef box_plot(column):\n    df.boxplot(by = \"Survived\", column = [column], grid = True)","9612048e":"box_plot(\"Fare\")","f9716682":"#checking outliers on SibSp column\nbox_plot(\"SibSp\")","a3fc8bf8":"#ploting pair plot\ng = sns.PairGrid(df, hue = \"Survived\")\ng.map_diag(sns.histplot)\ng.map_offdiag(sns.scatterplot)\ng.add_legend","7274a316":"#By value_counts we can see total unique values\ndf[\"SibSp\"].value_counts()","19185d85":"#here we are checking largest values row on column sibsp\ndf.nlargest(12, [\"SibSp\"])","a8bcde26":"#now we are going to remove outliers\ndf=df.drop([159,180,201,324,792,846,863])\ndf.shape","60dd4126":"#here we are going to check outliers on parch\nbox_plot(\"Parch\")","cada334d":"df[\"Parch\"].value_counts()","8c93f3a3":"df.nlargest(12, [\"Parch\"])","220b66c9":"df = df.drop([678])\ndf.shape","243c0afa":"#here we are going to draw heatmap to check corelation between columns\nplt.figure(figsize = (10, 10))\nsns.heatmap(df.corr(), annot = True, linewidths = 0.05, fmt = '.2f', cmap = \"magma\")\nplt.show()","8013ab96":"df[\"Title\"] = df[\"Name\"].str.split(',', expand = True)[1].str.split('.', expand = True)[0]","a2bcd43a":"df[\"Title\"].unique()","3baec091":"df[\"Title\"]=df[\"Title\"].replace([\" Don\",\" Rev\",\" Dr\",\" Major\",\" Lady\",\" Sir\",\" Col\",\" Capt\",\" the Countess\",\" Jonkheer\"],\"Rare\")\ndf[\"Title\"]=df[\"Title\"].replace([\" Mlle\", \" Ms\"],\" Miss\")\ndf[\"Title\"]=df[\"Title\"].replace([\" Mme\",\" Mrs\"],\" Mr\")","5fcd20fe":"df[\"Title\"].unique()","054028ba":"#droping an relevant columns\n#dividing data X(features) and Y(outcome)\nx=df.drop([\"Fare\",\"Survived\",\"Age\",\"Name\"],axis=True)\ny=df[\"Survived\"]","10a02dd8":"print(x.shape)\nprint(y.shape)","fcd198f1":"x.head()","0f7d4183":"#Here we encode Embarked in Rank\nx.loc[x['Embarked'] == \"C\", 'Embarked'] = 0\nx.loc[x['Embarked'] == \"Q\", 'Embarked'] = 1\nx.loc[x['Embarked'] == \"S\", 'Embarked'] = 2","467d11be":"x.loc[x['Title'] == \" Mr\", 'Title'] = 0\nx.loc[x['Title'] == \" Miss\", 'Title'] = 1\nx.loc[x['Title'] == \" Master\", 'Title'] = 2\nx.loc[x['Title'] == \"Rare\", 'Title'] = 3","f11a96e1":"#here we encode Sex in rank\nx.loc[x['Sex'] == \"female\", 'Sex'] = 0\nx.loc[x['Sex'] == \"male\", 'Sex'] = 1","c770320b":"x.head()","0c342902":"x.isnull().sum()","9dc57615":"#here we going to split data in traing set and testing\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=0)","27d05f3c":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(random_state=40)\nlr.fit(x_train,y_train)\n\nprint(lr.score(x_test,y_test))","f7885a72":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\ndtc = DecisionTreeClassifier()\n\nparameters = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : range(2, 32, 1),\n    'min_samples_leaf' : range(1, 10, 1),\n    'min_samples_split' : range(2, 10, 1),\n    'splitter' : ['best', 'random']\n}\n\ngrid_search_dt = GridSearchCV(dtc, parameters, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_dt.fit(x_train, y_train)","9405c72d":"# best parameters\n\ngrid_search_dt.best_params_","b63f8fab":"dtc = DecisionTreeClassifier(criterion = 'gini', max_depth = 4, min_samples_leaf = 1,\n                             min_samples_split = 5, splitter = 'random')\ndtc.fit(x_train, y_train)","90e1d045":"print(dtc.score(x_test,y_test))","1e21d247":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier()\n\nparameters = {\n    'loss': ['deviance', 'exponential'],\n    'learning_rate': [0.001, 0.1, 1, 10],\n    'n_estimators': [100, 150, 180, 200]\n}\n\ngrid_search_gbc = GridSearchCV(gbc, parameters, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_gbc.fit(x_train, y_train)","eedb26d4":"# best parameters \n\ngrid_search_gbc.best_params_","4679893c":"gbc = GradientBoostingClassifier(learning_rate = 0.1, loss = 'exponential', n_estimators = 100)\ngbc.fit(x_train, y_train)","688e1e2c":"# accuracy score\nprint(gbc.score(x_test,y_test))","157ba9c3":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(random_state=40,min_impurity_decrease=0.002,min_weight_fraction_leaf=0.001)\n\nrfc.fit(x_train,y_train)\n\n#print(rfc.score(x_test,y_test))","142b9d93":"print(rfc.score(x_test,y_test))","35864e40":"from sklearn.svm import SVC\n\nsvc = SVC()\nparameters = {\n    'gamma' : [0.0001, 0.001, 0.01, 0.1],\n    'C' : [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20]\n}\n\ngrid_search = GridSearchCV(svc, parameters)\ngrid_search.fit(x_train, y_train)","e773d5b3":"# best parameters \n\ngrid_search.best_params_","2922f3f8":"svc = SVC(C = 1, gamma = 0.1)\nsvc.fit(x_train, y_train)","64cd58ea":"print(svc.score(x_test,y_test))","eb4bb90c":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)","3a432082":"print(knn.score(x_test,y_test))","e38c2fa0":"key = ['LogisticRegression','DecisionTreeClassifier','GradientBoostingClassifier','RandomForestClassifier','SVC','KNeighborsClassifier']\nmodel=[lr,dtc,gbc,rfc,svc,knn]","e8934f2f":"score=[]\nfor i in model:\n    sco = i.score(x_test,y_test)\n    score.append(sco)\nprint(score)\nprint(max(score))","f0eb4279":"plt.figure(figsize = (10,10))\nsns.barplot(x = score, y = key, palette='pastel')","b2976d11":"df2=pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ndf2.head()","f6780048":"df2[\"Title\"]=df2[\"Name\"].str.split(',',expand=True)[1].str.split('.',expand=True)[0]\ndf2[\"Title\"]=df2[\"Title\"].replace([\" Don\",\" Rev\",\" Dr\",\" Major\",\" Lady\",\" Sir\",\" Col\",\" Capt\",\" the Countess\",\" Jonkheer\"],\"Rare\")\ndf2[\"Title\"]=df2[\"Title\"].replace([\" Mlle\", \" Ms\",\" Dona\"],\" Miss\")\ndf2[\"Title\"]=df2[\"Title\"].replace([\" Mme\",\" Mrs\"],\" Mr\")\ndf2[\"Title\"].unique()","98112477":"mapping={' Mr':0, ' Miss':1, ' Master':2, 'Rare':3}\ndf2[\"Title\"]=df2[\"Title\"].map(mapping)","64299eda":"new_x=df2.drop([\"Cabin\",\"PassengerId\",\"Fare\",\"Age\",\"Name\",\"Ticket\"],axis=True)\nnew_x.head()","f0718f06":"new_x.isnull().sum()","0cdc694b":"#Here we encode Embarked in Rank\nnew_x.loc[new_x['Embarked'] == \"C\", 'Embarked'] = 0\nnew_x.loc[new_x['Embarked'] == \"Q\", 'Embarked'] = 1\nnew_x.loc[new_x['Embarked'] == \"S\", 'Embarked'] = 2","cc41d151":"new_x.loc[new_x['Sex'] == \"female\", 'Sex'] = 0\nnew_x.loc[new_x['Sex'] == \"male\", 'Sex'] = 1","b6abd584":"new_x.head()","1ca62a7a":"#here we used over best train model\nnew_predict=gbc.predict(new_x)\nprint(new_predict)","862326bc":"vip=np.array(new_predict).tolist()","b5a8cf50":"len(vip)","c73c0f4b":"df2.insert(2,column=\"Survived\",value=vip)\ndf2.head()","4c80e203":"df3=df2.drop(['Pclass','Title','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'],axis=1)\ndf3.head()","7d35018e":"df3.to_csv('Titanic_model_gbc.csv',index=False)\ndf3.head()","6ecfef76":"### Making title feature using Name","a59f6df8":"# Exploratory Data Analysis","4d326e4e":"## macking csv(PassengerId & survived) file to upload","be7014dc":"### Frome EDA we got\n\n***Cabin column have lots of null values so we drop it,\nTicket and paddenger Id is not usefull and does not have impact on survivl so drop it.\nPassenger travelling in higher class have more chance to survived\nFemales survived more then Males.\nIn the 1st class Females were more then Males it is also a resion that females have more chance to survived.\nPassenger travelling with siblings ,parents have more chance to survived.\nPassenger traveilling from Cherbourg port survived more than other port passenger.***","244bd29a":"##### In the above chart we can easily anlyse that females have more chance to survive.","3a1fa51a":"# Feature Engineering","78c77873":"### Training DecisionTreeClassifier","d0b67084":"### Gradient Boosting Classifier","34e57a1f":"# Model building","f3e80a82":"#### finaly we chose over best model ****GradientBoostingClassifier**** for prediction","9304087d":"### Support Vector Classifier (SVC)","543d974a":"##### By the above chart on Pclass we can say that first class passenger have more chance to survived","5e6e8b5e":"### Training LogisticRegression","bdb121ad":"### K Neighbors Classifier (KNN)","3424b1db":"##### here we can see outliers above 100 we can consideconsidered them as outliers","537b979d":"##### by the above chart we can say that there are more chance to survived for those who bord from Southamption\n\n##### Passenger traveilling from Cherbourg port survived more than other port passenger","e0a2fdcd":"#### Thanks","fd23c641":"### Traing RandomForestClassifier","85bd2e7b":"## Prediction on Test data\n****clean and feature selection same as training****","0bb2bfc2":"\n##### now we can replace many titles with a more comman name as Rare","50904f6e":"## Detecting outliers and removing them","b4fd3280":"##### there are more chance to survived who have 0 or 1 siblings","20f621ee":"## If you like please Do a up vote"}}