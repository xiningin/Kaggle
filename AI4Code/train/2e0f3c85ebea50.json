{"cell_type":{"7fd320e9":"code","16c01ed9":"code","626a3a06":"code","d793a87d":"code","e245c22b":"code","8fde2806":"code","e0cd0a8c":"code","910a7ee9":"code","d858c6bb":"code","308a8640":"markdown","0ee8b236":"markdown","b1e5d1de":"markdown","129109a2":"markdown","c615c4ad":"markdown","6756ea30":"markdown","2749b478":"markdown"},"source":{"7fd320e9":"import pandas as pd; pd.set_option('mode.chained_assignment','raise');\nimport numpy as np\nfrom scipy import stats\n","16c01ed9":"# Sample data:\nx = pd.Series([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\ny = pd.Series([1.16,1.3,1.16,1.15,1.2,1.19,1.13,1.11,1.22,1.08,1.14,1.41,1.09,1.11,1.44,1.33,1.24,1.06,1.11,1.11,1.09,1.26])\n","626a3a06":"value, pvalue = stats.ttest_ind(x, y, equal_var=False) # done as Welch-Test through equal_var = False\nprint(value, pvalue)\nif pvalue > 0.05:\n\tprint('Samples are likely drawn from the same distributions (fail to reject H0)')\nelse:\n\tprint('Samples are likely drawn from different distributions (reject H0)')\n","d793a87d":"a = pd.Series([123,178,179,124,144,120,119,119,118,122,126,127,125,130,129,121,120,117,123,126,126,118])\nb = a*y\n\nprint(stats.ttest_rel(x,y)) # Paired!\nprint(stats.ttest_rel(a,b)) # Paired!\n","e245c22b":"print(stats.ttest_rel(x,y))\n","8fde2806":"\nfrom numpy.random import seed\nfrom numpy.random import randn\nfrom scipy.stats import f_oneway\n# seed the random number generator\nseed(1)\n# generate three independent samples\ndata1 = 5 * randn(100) + 50\ndata2 = 5 * randn(100) + 50\ndata3 = 5 * randn(100) + 52 # This one has a different mean, so we expect to reject H0\n# compare samples\nstat, p = f_oneway(data1, data2, data3)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n\tprint('Same distributions (fail to reject H0)')\nelse:\n\tprint('Different distributions (reject H0)')","e0cd0a8c":"!pip install pingouin","910a7ee9":"import pingouin as pg\n# res = pg.rm_anova()\n\n# Alternative: https:\/\/www.statsmodels.org\/stable\/generated\/statsmodels.stats.anova.AnovaRM.html#statsmodels.stats.anova.AnovaRM\n\n    \n    ","d858c6bb":"#create data\ndf = pd.DataFrame({'technique': np.repeat(['A', 'B', 'C'], 5),\n                   'current_grade': [67, 88, 75, 77, 85,\n                                     92, 69, 77, 74, 88, \n                                     96, 91, 88, 82, 80],\n                   'exam_score': [77, 89, 72, 74, 69,\n                                  78, 88, 93, 94, 90,\n                                  85, 81, 83, 88, 79]})\n#view data \nfrom pingouin import ancova\n\n# here we compare three groups. Technique_A, technique_B and technique_C\n# we suspect that the current_grade may  be an important part in the final exam\n# score. So we want to control for it to see if the groups really differ when\n# ONLY looking at the final exam score (with current grade effects removed)\n\nancova(data=df, dv='exam_score', covar='current_grade', between='technique')\n# Result: p = 0.03155 ... so we reject H0. They are indeed different!\n\n\n# Checking with normal ANOVA if different (just out of curiosity)\nstat, p = f_oneway(df[df.technique == \"A\"].exam_score, df[df.technique == \"B\"].exam_score, df[df.technique == \"C\"].exam_score)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# This value is even higher! So it seems to be the case, that exam_score has an effect.\n","308a8640":"## ANCOVA Testing    \n\nANCOVA testing is an advancement to T-Test \/ ANOVA testing.\nIt will also test a hypothesis, but similar to linear regression it is\ncapable of controllig for a covariate. It can eliminate the effect of \na covariate by calculating the effects on the target variable and then\nsubstracting this effect from the investigated variable.\n\nThis can result in higher or lower significance, as the controlled covariate\nmay be either an important part for the target variable, and then therefore\nthe investigated variable is not as needed anymore to explain the effect.\nOr the result can be higher, as the controlled variable masks the effect\nlike some random noise.\n\n\n### Assumumptions:\n- Check ALL assumptions of ANOVA plus:\n- Same slopes accross different groups in the covariate\n- Homegenity of variances (Levene Test)\nVery good R code for this: https:\/\/www.reneshbedre.com\/blog\/ancova.html","0ee8b236":"## T-Test for paired data\n\nSame assumptions as for T-Test with unpaired data\nRemember, that also in this test the samples must be i.i.d.\n\nYou are just measuring the same instance but in a before \/ after scenario.\nIt is still not allowed that the same measuremt is repeated or also present in the other group.\n\nRemember that you CANNOT sort the array. This is important for the evaluation process of the paired data\n","b1e5d1de":"# Assumptions and prerequisites\n\n**This is no explanatory notebook, but rather a reference**\n\nALL of these tests assume real values data. You are NOT allowed to use them\non ordinal data or bounded data or intervals or categories etc.\n \nAll of the tests assume i.i.d.\n\nSee chi-squared tests for ordinal data\n\nAlmost ALWAYS the Welch-Test can be used instead of the T-test. Only for samples < 5 the t-test is better\nThe Welch-Test does NOT assume same variances.\n\nHowever, there is no equivalent for repeated measurements \/ paired data. Cause here we usually assume same variances\n\n\n","129109a2":"## T-Test revalidation if raw numbers are present\n  \nUsually our samples are paired. We measure values on a group. Then we measure the same values on the group after a treatment\nIn this case we use the paired T-Test. Recalculate the values and look for methodlogical errors in the study\n\n**Important:** Often a study does not report before and after values and ONLY report the differences. This is tricky as it will skew the T-Test. as we see in the following sample, where a is the x is a forced baseline of 1 aka 100% and y is the relative change in percent. \nIf we recalculate with real values (a) and then apply the ratio for the new array and run the t-test again, we get different results!\n","c615c4ad":"## T-Test with independent \/ unpaired data\n \n### Assumptions\n- Data is approx normally distributed\n- Data is real valued and not bounded\n- Samples are i.i.d.\n","6756ea30":"\n## ANOVA Testing\nIs done if MORE than 2 samples.\n\nThis will NOT tell us about a specific pair. It tells us only if ALL are the same, or AT LEAST ONE is different.\n\nSo often times it may be more helpful to test every combination with a T-Test \/ Welch-Test\n\n### Assumptions: \n- Samples are i.i.d.\n- normally distributed\n- Same variance for all samples\n- Data is NOT-Paired (Independent and NOT repeated measurements)","2749b478":"# ANOVA for paired data \/ repeated measurements\n \nhttps:\/\/www.reneshbedre.com\/blog\/repeated-measure-anova.html\n\n### Assumptions:\n- Check ALL assumptions of ANOVA plus:\n- TODO: https:\/\/www.reneshbedre.com\/blog\/repeated-measure-anova.html    "}}