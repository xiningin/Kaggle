{"cell_type":{"c26036ed":"code","56c4b4e2":"code","518b5c58":"code","ad2816fb":"code","14007bdb":"code","f19198fa":"code","de45f76f":"code","316dd3f6":"code","1a850f0e":"code","d1fd095b":"code","48712b55":"code","c9567696":"code","98af5412":"code","b2175ce6":"code","57865a14":"code","811818d4":"code","cf70fbc8":"code","6f89e1b3":"code","6448ac44":"code","e6e8e0ca":"code","0f508acf":"code","304c2fe2":"code","de571c1f":"code","df9a9dd7":"code","b716915f":"code","ee7be6d2":"code","6d715071":"code","4a4411da":"code","2a498e69":"code","18e1486e":"code","9facfc66":"code","7db4dfe9":"code","3340d312":"code","b80ccd8e":"code","b17e8848":"code","f30c4ee5":"code","f41b264c":"code","dbbe0c30":"code","d8db54a7":"code","57c957df":"code","fcccfbfc":"code","a669e864":"code","79e535ca":"code","987a44ba":"code","754e9522":"code","d1cec99e":"code","ebc388f8":"code","ea02ce90":"code","bcd0345e":"code","0d8a9f53":"code","4be9ff2d":"code","bc432f90":"code","6090339f":"code","e85464f2":"code","9adddc83":"code","c486690f":"code","ed2246c4":"code","1fcc67c8":"code","f0e2b4b2":"code","8f1032b0":"code","47ca9f3a":"code","7157de4a":"code","29a6bb1b":"code","d140728f":"code","70eeec42":"code","23d9dc6c":"code","6abfe4d0":"code","df6682c5":"code","7043be42":"code","5845ad9d":"code","1e45b293":"code","cc6b3daf":"code","2070ef71":"code","38e988e9":"code","1797fa7e":"code","ca88c46a":"code","c29c63a1":"code","3f4be144":"code","19728da6":"code","c0b027ad":"code","938b090e":"code","bc39201f":"markdown","175fa7b4":"markdown","708534b0":"markdown","f9213caf":"markdown","60f9a6d7":"markdown","19050f28":"markdown","84269c08":"markdown","96c3ae3d":"markdown","8cd0b6b8":"markdown","974ef9ce":"markdown","c825260b":"markdown","901f77c8":"markdown","74478efa":"markdown","a1c27b07":"markdown","f1f410f8":"markdown","0b472c60":"markdown","691293a5":"markdown","8f70947c":"markdown","170e4dd2":"markdown","b23a65a1":"markdown","a19d6c99":"markdown","37467093":"markdown","47995c00":"markdown","db8bfc14":"markdown","74400991":"markdown","43409c88":"markdown","06c11558":"markdown","d440a0ed":"markdown","3400da6b":"markdown","12b75e73":"markdown","81445706":"markdown","898b1c67":"markdown","4281cab8":"markdown","d0a5958c":"markdown","bf679ff6":"markdown","b748012f":"markdown","c59affff":"markdown","6a7a3c2b":"markdown","322f59d7":"markdown","f8d8c811":"markdown","cb85ccb7":"markdown","4737eac8":"markdown","037ee0f7":"markdown","b26b5a17":"markdown","c57aaee3":"markdown","14f62b52":"markdown","2319bab2":"markdown","fa2c04ac":"markdown","06f52bdb":"markdown"},"source":{"c26036ed":"#jai mata di","56c4b4e2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n","518b5c58":"customer = pd.read_csv('d:\/CC_GENERAL.csv')\n","ad2816fb":"customer.info()","14007bdb":"customer.drop(columns = \"CUST_ID\" , inplace = True)","f19198fa":"def con_var_summary(x):\n    return pd.Series([x.dtype\n                      ,x.isnull().count()\n                      , x.isnull().sum() ,x.mean() , x.sum() , x.var() ,x.std(), x.min() ,\n                      x.quantile(0.01) ,x.quantile(0.05) ,x.quantile(0.1) ,x.quantile(0.25) ,\n                      x.quantile( ) ,x.quantile(0.75) ,x.quantile(0.90) ,x.quantile(0.95) ,x.quantile(0.99) ,\n                     x.quantile(1)]\n                    ,index = ['data_type' ,'N' , 'nulls' , 'mean','sum ','VAR' , 'STD' , 'MIN'\n                             ,'P1','P5','P10' , 'Q1' , 'Q2' , 'Q3' , 'P90' ,'P95' , 'P99' , 'MAX'])","de45f76f":"customer.select_dtypes(['int64' , 'float64']).apply(con_var_summary)","316dd3f6":"customer.BALANCE.max() - 1.5* (customer.BALANCE.quantile(0.75) - customer.BALANCE.quantile(0.25))","1a850f0e":"customer.BALANCE.min() + 1.5* (customer.BALANCE.quantile(0.75) - customer.BALANCE.quantile(0.25))","d1fd095b":"customer.PURCHASES.max() - 1.5* (customer.PURCHASES.quantile(0.75) - customer.PURCHASES.quantile(0.25))","48712b55":"customer.PURCHASES.min() + 1.5* (customer.PURCHASES.quantile(0.75) - customer.PURCHASES.quantile(0.25))","c9567696":"def treat_outlier(x):\n    IQR = x.quantile(0.75) - x.quantile(0.25)\n    lb = x.quantile(0.01)\n    ub = x.quantile(0.99)\n    if x.max() > ub :\n         x.clip(lower = lb , upper = ub , inplace = True)  if x.min() < lb else x.clip(upper = ub , inplace = True)\n    elif x.min() < lb :\n        x.clip(lower = lb ,inplace = True)\n    return x","98af5412":"customer.apply(treat_outlier)","b2175ce6":"customer.apply(con_var_summary)","57865a14":"customer.isna().sum()","811818d4":"customer.CREDIT_LIMIT = customer.CREDIT_LIMIT.fillna(customer.CREDIT_LIMIT.mean())","cf70fbc8":"customer.isna().sum()","6f89e1b3":"round(customer.isna().sum()\/customer.count() , 2)","6448ac44":"customer.MINIMUM_PAYMENTS = customer.MINIMUM_PAYMENTS.fillna(customer.MINIMUM_PAYMENTS.mean())","e6e8e0ca":"customer.isna().sum()","0f508acf":"samp1 = customer[customer.MINIMUM_PAYMENTS.notnull() ]","304c2fe2":"from sklearn import metrics","de571c1f":"import scipy.stats as stats","df9a9dd7":"stats.pearsonr(samp1.PAYMENTS , samp1.MINIMUM_PAYMENTS)","b716915f":"sns.heatmap(customer.corr())\nplt.title('corrrelation between variables')\nplt.figure(figsize = (12,6))\nplt.show()","ee7be6d2":"customer.columns","6d715071":"stats.pearsonr(customer.ONEOFF_PURCHASES , customer.ONEOFF_PURCHASES_FREQUENCY)","4a4411da":"stats.pearsonr(customer.INSTALLMENTS_PURCHASES , customer.PURCHASES_INSTALLMENTS_FREQUENCY)","2a498e69":"customer.head()","18e1486e":"customer.columns","9facfc66":"customer_new = customer.drop(columns = ['PURCHASES' , 'CASH_ADVANCE' , 'PURCHASES_FREQUENCY' , 'ONEOFF_PURCHASES' , 'INSTALLMENTS_PURCHASES',\n                        'CASH_ADVANCE_TRX' , 'PURCHASES_TRX' , 'MINIMUM_PAYMENTS'])","7db4dfe9":"customer_new.shape","3340d312":"customer_new.TENURE.value_counts()","b80ccd8e":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ncustomer_scaled = pd.DataFrame(sc.fit_transform(customer_new))\ncustomer_scaled.columns = customer_new.columns\ncustomer_scaled","b17e8848":"from sklearn.decomposition import PCA\npca = PCA(n_components = 9)\npca.fit_transform(customer_scaled)","f30c4ee5":"pca.explained_variance_","f41b264c":"cum_variance = np.cumsum(round(pd.Series(pca.explained_variance_ratio_)*100,2))","dbbe0c30":"eigen_score = pd.DataFrame([pca.explained_variance_ , cum_variance] , index = ['eign_value' , 'cum_variance']).T\neigen_score","d8db54a7":"pca_final = PCA(n_components = 5)","57c957df":"dimensions = pd.DataFrame(pca_final.fit_transform(customer_scaled))\ndimensions.columns = ['C1' ,'C2' ,'C3' ,'C4' ,'C5']\ndimensions","fcccfbfc":"from sklearn.cluster import KMeans\nkm_3 = KMeans(n_clusters = 3 , random_state = 123)\nkm_3.fit(dimensions)","a669e864":"km_4 = KMeans(n_clusters = 4 , random_state = 123)\nkm_4.fit(dimensions)\nkm_5 = KMeans(n_clusters = 5 , random_state = 123)\nkm_5.fit(dimensions)\nkm_6 = KMeans(n_clusters = 6 , random_state = 123)\nkm_6.fit(dimensions)\nkm_7 = KMeans(n_clusters = 7 , random_state = 123)\nkm_7.fit(dimensions)\nkm_8 = KMeans(n_clusters = 8 , random_state = 123)\nkm_8.fit(dimensions)","79e535ca":"customer_new['cluster_3'] = km_3.labels_","987a44ba":"customer_new['cluster_4'] = km_4.labels_\ncustomer_new['cluster_5'] = km_5.labels_\ncustomer_new['cluster_6'] = km_6.labels_\ncustomer_new['cluster_7'] = km_7.labels_\ncustomer_new['cluster_8'] = km_8.labels_","754e9522":"customer_new.cluster_3.value_counts()\/customer_new.shape[0]","d1cec99e":"customer_new.cluster_4.value_counts()","ebc388f8":"customer_new.shape","ea02ce90":"customer_new.cluster_4.value_counts()\/customer_new.shape[0]","bcd0345e":"customer_new.cluster_5.value_counts()\/customer_new.shape[0]","0d8a9f53":"customer_new.cluster_6.value_counts()\/customer_new.shape[0]","4be9ff2d":"customer_new.cluster_7.value_counts()\/customer_new.shape[0]","bc432f90":"clusters = np.arange(2,21)\nsc_score_1 = []","6090339f":"clusters","e85464f2":"dimensions.shape","9adddc83":"dimensions.tail(5)","c486690f":"sc1_1 = []\nsc2_2 = []\nfor cluster in clusters:\n    km_1 = KMeans(n_clusters = cluster , random_state = 123)\n    km_1.fit(dimensions.head(4475))\n    sc_1 = metrics.silhouette_score(dimensions.head(4475) , km_1.labels_)\n    sc1_1.append(sc_1)","ed2246c4":"for cluster in clusters:\n    km_2 = KMeans(n_clusters = cluster , random_state = 123)\n    km_2.fit(dimensions.tail(4475))\n    sc_2 = metrics.silhouette_score(dimensions.tail(4475) , km_2.labels_)\n    sc2_2.append(sc_2)","1fcc67c8":"sc1_1","f0e2b4b2":"sc2_2","8f1032b0":"sc_score_1 = [(sc1_1[i] + sc2_2[i])\/2 for i in range(len(sc1_1))]","47ca9f3a":"sc_score_1","7157de4a":"sns.lineplot(x = clusters , y = sc_score_1)\nplt.xlabel('no. of clusters')\nplt.ylabel('sc_score')\nplt.show()\nplt.savefig(\"silhoutte_coeff_score.png\")","29a6bb1b":"a = [1,2,3]\nb = [4,5,6]","d140728f":"[(a[i]+b[i])\/2 for i in range(len(a))]","70eeec42":"clusters\n","23d9dc6c":"elbow_variance = []","6abfe4d0":"for cluster in clusters:\n    km_elbow_sample = KMeans(n_clusters = cluster , random_state = 123)\n    km_elbow_sample.fit(dimensions)\n    elbow = km_elbow_sample.inertia_\n    elbow_variance.append(elbow)","df6682c5":"elbow_variance","7043be42":"plt.figure(figsize = (10,5))\nplt.grid(True)\nsns.lineplot(x = clusters , y = elbow_variance , marker = 'o')\nplt.xlabel('NO. OF CLUSTERS')\nplt.ylabel('VARIANCE')\nplt.title('ELBOW PLOT')\nplt.savefig('elbow plot.png')","5845ad9d":"customer_new.head()","1e45b293":"c_3 =  customer_new.cluster_3.value_counts().sort_index() \nc_4 =  customer_new.cluster_4.value_counts().sort_index() \nc_5 = customer_new.cluster_5.value_counts().sort_index() \nc_6 = customer_new.cluster_6.value_counts().sort_index() \nc_7 = customer_new.cluster_7.value_counts().sort_index() \nc_8 = customer_new.cluster_8.value_counts().sort_index() \n","cc6b3daf":"seg_size = pd.concat([ pd.Series(customer_new.shape[0]), c_3 , c_4 , c_5 , c_6 , c_7 , c_8 ])","2070ef71":"seg_pct =seg_size.div(customer_new.shape[0])","38e988e9":"seg = pd.concat([seg_size , seg_pct] , axis =1 ).T","1797fa7e":"seg.index = ['segment_size' , 'segment_percentage']","ca88c46a":"seg","c29c63a1":"customer_new.head()","3f4be144":"summary_1 = pd.concat([customer_new.apply(lambda x: x.mean()).T , \n           customer_new.groupby('cluster_3').apply(lambda x: x.mean()).T ,\n           customer_new.groupby('cluster_4').apply(lambda x: x.mean()).T ,\n           customer_new.groupby('cluster_5').apply(lambda x: x.mean()).T ,\n           customer_new.groupby('cluster_6').apply(lambda x: x.mean()).T ,\n           customer_new.groupby('cluster_7').apply(lambda x: x.mean()).T ,\n           customer_new.groupby('cluster_8').apply(lambda x: x.mean()).T ] , axis =1)","19728da6":"profiling_output_final = pd.concat([seg , summary_1])\nprofiling_output_final.columns = ['Overall', 'KM3_1', 'KM3_2', 'KM3_3',\n                                'KM4_1', 'KM4_2', 'KM4_3', 'KM4_4',\n                                'KM5_1', 'KM5_2', 'KM5_3', 'KM5_4', 'KM5_5',\n                                'KM6_1', 'KM6_2', 'KM6_3', 'KM6_4', 'KM6_5','KM6_6',\n                                'KM7_1', 'KM7_2', 'KM7_3', 'KM7_4', 'KM7_5','KM7_6','KM7_7',\n                                'KM8_1', 'KM8_2', 'KM8_3', 'KM8_4', 'KM8_5','KM8_6','KM8_7','KM8_8',]\nprofiling_output_final","c0b027ad":"profiling_output_final.to_csv('credit card segment stats.csv')","938b090e":"the customers are divided into segments","bc39201f":"## and from the business point of view we need to make plans to\n* promote cash advance facility\n* promote usage of instalment purchase\n* promote usage of having credit card\n\n* And we need to make some strict rules of imposing interest on delay payments.","175fa7b4":"### as there exists only 9 variables i just want to do PCA  , to see whether i should reduce \/ make components or not","708534b0":"### we have two variables with missing values\n### credit limit\n### minimum payments due\n\n## TREATMENT\n### credit limit -  simply imputing by mean","f9213caf":"## as all the variables are in numerical data type , let us do some continous variables analysis","60f9a6d7":"## REJECTED","19050f28":"#### silhoutte score ranges from -1 to +1","84269c08":"## no missing values left","96c3ae3d":"## by elbow plot also , the number of suitable clusters is also 6","8cd0b6b8":"## let us fir see whether we can treat outliers by IQR method","974ef9ce":"## thus  , we can not go for IQR method to treat outliers as it's lower viscor side is affecting variance of my data ","c825260b":"## REJECTED","901f77c8":"## after reading the profiling output file \nwe came to a conclusion that \n# CLUSTER 6 \n% is the good solution. %","74478efa":"#### SILHOUTTE COEFF SCORE , basically determines that how similar my data point is to the other datapoints belonging \nto the same cluster and how dissimilar it is from the datapoints of the another cluster.","a1c27b07":"### BECAUSE OF MY SYSTEM PROBLEM THE COMPLETE DATA WAS NOT ABLE TO PROCESS AT A TIME , \nSO I DID THE CALCULATIONS FOR HALF HALF OF THE DATA AND LATER TOOK AN AVEAGE OF THAT","f1f410f8":"### though this is a categorical variable we do  not require to create dummies for this , \n### because it is an \n## ordinal categorical variable","0b472c60":"# Treating outliers","691293a5":"### again this is coming after Q3 of variable.","8f70947c":"### this above value is coming after Q3 of the variable.\n(EATING UP THE VARIANCE In THE DATA)","170e4dd2":"### CUST_ID is basically index of my data","b23a65a1":"## now calculating mean of every variable for each cluster\nbecause mean gives us a better image of data insight","a19d6c99":"## we are almost done with preparing our data and fitting our clustering model","37467093":"## only 0.04% data is missing from MINIMUM PAYMENTS so we can impute them by mean as well ","47995c00":"## we can also validate our conclusion by plotting a heat map.","db8bfc14":"## EVALUATION 1.\nCHECKING SEGMENT SIZE","74400991":"## CLUSTER 3 REJECTED , we cant accept a solution with number of clusters such that a cluster have more than 40% data","43409c88":"# here comes the most important part","06c11558":"## STANDARDIZING VARIABLES","d440a0ed":"#### by this we concluded that \npayments and minimum payments are not corelated. so we can not drop this ","3400da6b":"## PRINCIPAL COMPONENTS ANALYSIS","12b75e73":"### we'll make for say 3 to 8 clusters","81445706":"### WE ALREADDY KNOW:-\n    THAT , \n           on increasing number of clusters the variance captured in the data also increases.\n        but ,  after a certain point the rate by which the variance captured increses becomes very slow.\n        the point is known as elbow point. where increasing in number of clusters wont help much n capturing varianc\n","898b1c67":"# QUALITATIVE EVALUATION","4281cab8":"## by this we can conclude that NO. OF COMPONENTS = 5 ,WILL GIVE PERFECT RESULTS  ","d0a5958c":"## REJECTED","bf679ff6":"# CREDIT CARD SEGMENTATION CASE STUDY","b748012f":"## because of high correlations ,  and also from the business point of view i have decided to drop some variables.","c59affff":"### Eigen score","6a7a3c2b":"## ELBOW PLOT TEST","322f59d7":"# MISSING VALUE TREATMENT","f8d8c811":"## ACCEPTED","cb85ccb7":"### FROM THIS WE CAN CONCLUDE ACCORDING TO THE SIZE OF SEGMENT CLUSTER_6 IS A GOOD SOLUTION","4737eac8":"# CLUSTER EVALUATION","037ee0f7":"## purchase , puchase_trx , purchase frequency\nbecause the purchase information is further divided into one off and installment purchase. which gives us a better image of our customers.\n\n## Cash advance txn , cash advance\nthe information in these can be depicted by the information same as cash addvance frequency\n\n## minimum payments\nthe minimum payment due is basically depicts the customers who donot make payments regularly(unhealthy customers)\nthis can be explained by reverse of those who make paments on time.\nwhich is given by prc_full_payment(healthy customers)\n\n## balance\nhere we do not require the balance in credit card of customer.\nour main focus is on the SPENT  BY THE CUSTOMER\n\n## oneoff purchase and installment purchase\nbecause in one way or another they are depecting similar information as being provided by oneoff purchase frequency and installment puchase frequency","b26b5a17":"## QUANTITATIVE EVALUATION","c57aaee3":"## SILHOUTTE COEFFICIENT SCORE ANALYSIS","14f62b52":"### i just hope i dropped these variables in my perfect health and consious","2319bab2":"## by this we have a bit clearer image that our cluster 6 could be a good solution","fa2c04ac":"# KMEANS CLUSTERING MODEL","06f52bdb":"## NOTE:-\n    BEFORE WE MOVE ANY FURTHER.\n    A VERY IMPORTANT POINT THAT CAN BE SEEN FROM THE DATA IS..\n    THERE ARE SEVERAL VARIABLES THAT ARE NOTHING BUT REPLICATING THE INFORMATION PROVIDED BY OTHER VARIABLES.\n    (HIGHLY COLLINEAR).\n    THE LIST OF SUCH VARIABLES ARE.\n1. balance -  balance_frequency\n2. purchase - purchase frequency\n3. one-off puchase - one-off puchase frequency\n4. installment purchase - installment purchase frequency\n5. cash advance - cash advance frequency\n6. purchase - avg_purchase_txn\n7. cash advance - avg_cash_advtransaction\n8. purchase - purchase trx\n\n## dropping these variables is highly recommended"}}