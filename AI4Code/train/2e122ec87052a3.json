{"cell_type":{"d2551530":"code","ec53a745":"code","62722fb2":"code","5d791316":"code","360c1f12":"code","a3b26428":"code","3016f010":"code","0af97984":"code","d480a5bf":"code","c760878c":"code","8f7206d6":"code","53307982":"code","2d18f8cb":"code","e90b027b":"code","cb972efe":"code","f0e993e5":"code","99e78649":"code","53f95e97":"code","15a91ecc":"code","953d13fc":"code","d622e631":"code","9578e819":"code","506b2a46":"code","c0ed15f4":"code","623dfaf8":"code","f2bf47b9":"code","47020f9d":"markdown","d2650b40":"markdown","3ea76da8":"markdown","fdfff266":"markdown","29aa0e41":"markdown","9ab32455":"markdown","d8a7de77":"markdown","43b43459":"markdown","73c9d278":"markdown","4fd979ab":"markdown","a4f0d0b0":"markdown","d8a3ab2d":"markdown"},"source":{"d2551530":"from tensorflow.keras import Sequential,Model\nfrom tensorflow.keras.layers import Flatten, Dense, MaxPooling2D,Dropout, Conv2D, BatchNormalization,Add,Activation,Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n","ec53a745":"train_df=pd.read_csv('..\/input\/minst-fashion-dataset\/fashion-mnist_train.csv')\ntest_df=pd.read_csv('..\/input\/minst-fashion-dataset\/fashion-mnist_test.csv')","62722fb2":"print(train_df.shape)\nprint(test_df.shape)","5d791316":"train_df.head()","360c1f12":"print('Image Pixels: ', 785-1)\nprint('Lenght of each dimension: ', np.sqrt(784))","a3b26428":"X=train_df.iloc[:,1:]\ny=train_df.label\nX_test=test_df.iloc[:,1:]\ny_test=test_df.label","3016f010":"X.head(3)","0af97984":"import matplotlib.pyplot as plt\ndef pic_show(df,row):\n    plt.figure()\n    plt.imshow(df.iloc[row].values.reshape(28,28,1))\n    plt.axis('off')\n    plt.show()\n\npic_show(X,2)","d480a5bf":"def reshaper(df):\n    X=[]\n    for i in range(df.shape[0]):\n        pic=df.iloc[i].values.reshape(28,28,1)\n        X.append(pic)\n    return np.array(X)\n\n        ","c760878c":"X_test","8f7206d6":"X=reshaper(X)\nX_test=reshaper(X_test)","53307982":"X=X\/255.0\nX_test=X_test\/255.0","2d18f8cb":"X_train,X_val,y_train,y_val=train_test_split(X,y, test_size=0.2)","e90b027b":"X_train.shape","cb972efe":"from tensorflow.keras.utils import to_categorical\ny_train_one=to_categorical(y_train)\ny_val_one=to_categorical(y_val)\ny_test_one=to_categorical(y_test)","f0e993e5":"from tensorflow.keras.optimizers import SGD\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","99e78649":"\n             \ncandidates=[0.1,0.3,0.5,0.7,0.9]\n\nfor i in candidates:\n    model=Sequential([\n        Conv2D(64,3,activation='relu', input_shape=(28,28,1)),\n        BatchNormalization(),\n        MaxPooling2D(2),\n        Dropout(i),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dense(10, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                 metrics=['accuracy'],\n                 optimizer=sgd)\n    history=model.fit(X_train,y_train_one, batch_size=128,epochs=5,validation_data=(X_val,y_val_one), verbose=0)\n    print('Test accuracy for dropout value: ', str(i), model.evaluate(X_test,y_test_one,verbose=0)[1])","53f95e97":"import seaborn as sns\nplt.ylabel('Test Accuracy')\nplt.xlabel('Dropout Value')\nsns.barplot(x=[0.1,0.3,0.5,0.7,0.9],y=[0.915,0.912,0.912,0.90,0.87]);","15a91ecc":"model=Sequential([\n    Conv2D(64,3,activation='relu', input_shape=(28,28,1)),\n    BatchNormalization(),\n    MaxPooling2D(2),\n    Dropout(0.5),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(10, activation='softmax')\n])\nmodel.compile(loss='categorical_crossentropy',\n             metrics=['accuracy'],\n             optimizer=sgd)\nhistory=model.fit(X_train,y_train_one, batch_size=128,epochs=20,validation_data=(X_val,y_val_one), verbose=0)","953d13fc":"history_df=pd.DataFrame(history.history)\nhistory_df[['loss','val_loss']].plot();","d622e631":"print('Test Accuracy for Sequential Neural Network:', model.evaluate(X_test,y_test_one,verbose=0)[1])","9578e819":"input_tensor=Input(shape=(28,28,1))\nConv1=Conv2D(64,3, input_shape=(28,28,1))(input_tensor)\nA1=Activation('relu')(Conv1)\nBatchNor=BatchNormalization()(A1)\nPool1=MaxPooling2D(2)(BatchNor)\nPool1=Dropout(0.5)(Pool1)\nFlat=Flatten()(Pool1)\nD1=Dense(128, activation='relu')(Flat)\nD2=Dense(128, activation='relu')(Flat)\nD3=Add()([D2,D1])\noutput_tensor=Dense(10,activation='softmax')(D3)\nmodel=Model(inputs=input_tensor,outputs=output_tensor)","506b2a46":"from tensorflow.keras.utils import plot_model","c0ed15f4":"plot_model(model)","623dfaf8":"model.compile(loss='categorical_crossentropy',\n             metrics=['accuracy'],\n             optimizer=sgd)\nhistory=model.fit(X_train,y_train_one, batch_size=128,epochs=20,validation_data=(X_val,y_val_one), verbose=0)","f2bf47b9":"print('Test Accuracy for Functional Neural Network:', model.evaluate(X_test,y_test_one,verbose=0)[1])","47020f9d":"# Image from pixels","d2650b40":"# CNN Sequential Model\nImportant Notes:\n\nFor the starting point, 0.5 is generally good for  Dropout layer (True for Linear Neural Networks)(Claim). Although that's the case it's beneficial to try the other alternatives until finding the optimum value. \n\nLet's test it!\n\n### Precedure\nTry different dropout values in model with utilizg for loop.\n\nUse lower epoch for the convenience.\n\n\n","3ea76da8":"# CNN Functional Model\n\n### Procedure:\n\nAdd another Dense Layer after flatten layer, combine the outputs and run the functional model.\n\nFinally compare the accuracy between two!","fdfff266":"# Conclusion\n\nMaking more complex neural network models may improve the performance of the model. This improvement depends on the complexity that is added.\n\nDropout values generally did not change the accuracy of the model that much. 0.5 can be a good starting point as mentioned in the claim.\n","29aa0e41":"### Procedure:\nSelect values of each row separately by utilizing for loop and reshape them as (28,28,1). Finally collect modified data in a new list and return the data collection. ","9ab32455":"# Normalization","d8a7de77":"It seems like except dropout value of 0.9, test accuracy doesn't change that much. \n\nLet's try higher epoch and compare it with a functional neural network.","43b43459":"### Procedure:\nSelect values of each row separately and reshape them as (28,28,1). ","73c9d278":"### Procedure:\nDivide data to 255.0 to both converting the result a float and reduce the complexity of data. Normalization is a process in which the ratio between data remains same but the magnitude is decreased (Between 0 and 1). This is done by dividing all data to max value in dataset.\n\nFor example: [20,10]\n\nNormalized version:[1,0.5]\n\nFor colorscale, the maximum value is 255. That's why we divide all data to 255.0 ","4fd979ab":"# Defining Reshaper Function","a4f0d0b0":"One column for label. Rest of the columns should represent both height and width.","d8a3ab2d":"Therefore our dimensions should be (28,28,1).\n(1 represents grayscale)"}}