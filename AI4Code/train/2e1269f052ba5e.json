{"cell_type":{"7f7178ba":"code","b7a8e921":"code","34afb05d":"code","9a9212e2":"code","70f4bda3":"code","cface6f0":"code","c28f5456":"code","8b82694c":"code","edc411ac":"code","dd66e901":"code","dfdebcf8":"code","6c25f5c1":"code","151a277b":"code","7f4ddb4c":"code","905e161b":"code","09d5682d":"code","098df0dd":"code","92421062":"code","4382b68a":"code","b595fb85":"code","55632859":"code","7fc9c36e":"code","1635f4d6":"code","723926a1":"code","6ac17921":"code","b2c645e6":"code","9d804e56":"code","6fd41865":"code","48443526":"code","4dde08ee":"code","5b01c960":"code","7ef40595":"code","72705dc9":"code","068bb2df":"code","9238d34c":"code","c1d3f82d":"code","15070c18":"markdown","88dfd72c":"markdown","c3a0cf86":"markdown","2b4245bb":"markdown","b333288a":"markdown","c2a99cd2":"markdown","7c50406f":"markdown","83f8836f":"markdown","ca366032":"markdown","3fb10d13":"markdown"},"source":{"7f7178ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7a8e921":"#Importing some basic modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pylab as pl\n%matplotlib inline","34afb05d":"#getting the data\ndrug = pd.read_csv('\/kaggle\/input\/drug-classification\/drug200.csv')","9a9212e2":"#getting info for the dataset\ndrug.info()","70f4bda3":"#reading top 10 rows of data\ndrug.head(10)","cface6f0":"#basic statistics details\ndrug.describe()","c28f5456":"sn.set_theme(style=\"darkgrid\")\n\n#For Sex Column\nax = sn.countplot(x=\"Sex\", data=drug)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='bottom', color='black', size=12)\nplt.show()","8b82694c":"#For BP Column\nax = sn.countplot(x=\"BP\", data=drug)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='bottom', color='black', size=12)\nplt.show()","edc411ac":"#For Cholestrol Column\nax = sn.countplot(x=\"Cholesterol\", data=drug)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='bottom', color='black', size=12)\nplt.show()","dd66e901":"#For drug Column\nax = sn.countplot(x=\"Drug\", data=drug)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='bottom', color='black', size=12)\nplt.show()","dfdebcf8":"#Plotting histogram for numeric variables\ndrug[['Age','Na_to_K']].hist(bins=30, figsize=(9,9),)\npl.suptitle(\"Histogram For Each Numeric Input Variable\")\nplt.show()","6c25f5c1":"#Plotting boxplot for numeric variables\ndrug[['Age','Na_to_K']].plot(kind='box', subplots=True, layout=(2,2),figsize=(9,9),title='Box Plot Each Numeric Input Variable')\nplt.show()","151a277b":"#We have outliers in Na_to_K column, and should choose appropriate method to treat it.","7f4ddb4c":"from sklearn.preprocessing import LabelEncoder\n\ndef label_encoder(x):\n    le = LabelEncoder()\n    drug[x] = le.fit_transform(drug[x])","905e161b":"categ = [\"Sex\",\"BP\",\"Cholesterol\",\"Drug\"]\n\nfor l in categ:\n    label_encoder(l)","09d5682d":"drug.head()","098df0dd":"X = drug.drop('Drug', axis = 1)\nY = drug['Drug']","92421062":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, Y, random_state=0)","4382b68a":"#printing shape for our data\nprint('X_train',X_train.shape)\nprint('X_test',X_test.shape)\nprint('y_train',y_train.shape)\nprint('y_test',y_test.shape)","b595fb85":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","55632859":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","7fc9c36e":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier().fit(X_train, y_train)\nprint('Accuracy of Decision Tree classifier on training set: ', round((clf.score(X_train, y_train)),2))\nprint('Accuracy of Decision Tree classifier on test set: ', round((clf.score(X_test, y_test)),2))","1635f4d6":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues)  \nplt.figure(figsize = (12, 12))\nplt.show()","723926a1":"#Generating classification report\nfrom sklearn.metrics import classification_report\ny_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))","6ac17921":"#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint('Accuracy of K-NN classifier on training set: ', round((knn.score(X_train, y_train)),2))\nprint('Accuracy of K-NN classifier on test set: ', round((knn.score(X_test, y_test)),2))","b2c645e6":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(knn, X_test, y_test, cmap=plt.cm.Blues)  \nplt.figure(figsize = (12, 12))\nplt.show()","9d804e56":"#Generating classification report\nfrom sklearn.metrics import classification_report\ny_pred = knn.predict(X_test)\nprint(classification_report(y_test, y_pred))","6fd41865":"#Naive Bayes Gaussian\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\nprint('Accuracy of GNB classifier on training set: ',round((gnb.score(X_train, y_train)),2))\nprint('Accuracy of GNB classifier on test set: ',round((gnb.score(X_test, y_test)),2))","48443526":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(gnb, X_test, y_test, cmap=plt.cm.Blues)  \nplt.figure(figsize = (12, 12))\nplt.show()","4dde08ee":"#Generating classification report\nfrom sklearn.metrics import classification_report\ny_pred = gnb.predict(X_test)\nprint(classification_report(y_test, y_pred))","5b01c960":"#SVM\nfrom sklearn.svm import SVC\nsvm = SVC()\nsvm.fit(X_train, y_train)\nprint('Accuracy of SVM classifier on training set: ', round((svm.score(X_train, y_train)),2))\nprint('Accuracy of SVM classifier on test set: ', round((svm.score(X_test, y_test)),2))","7ef40595":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(svm, X_test, y_test, cmap=plt.cm.Blues)  \nplt.figure(figsize = (12, 12))\nplt.show()","72705dc9":"#Generating classification report\nfrom sklearn.metrics import classification_report\ny_pred = svm.predict(X_test)\nprint(classification_report(y_test, y_pred))","068bb2df":"#LDA Linear Discriminant Analysis\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\nlda.fit(X_train, y_train)\nprint('Accuracy of LDA classifier on training set: ',round((lda.score(X_train, y_train)),2))\nprint('Accuracy of LDA classifier on test set: ',round((lda.score(X_test, y_test)),2))","9238d34c":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(lda, X_test, y_test, cmap=plt.cm.Blues)  \nplt.figure(figsize = (12, 12))\nplt.show()","c1d3f82d":"#Generating classification report\nfrom sklearn.metrics import classification_report\ny_pred = lda.predict(X_test)\nprint(classification_report(y_test, y_pred))","15070c18":"# Gaussian Naive Bayes","88dfd72c":"# **Label Encoding**","c3a0cf86":"# score() for classicication models\nEvery estimator or model in Scikit-learn has a score method after being trained on the data.\n\nWhen we call score on classifiers, the method computes accuracy score by default (i.e.  #correct predictions \/ #all predictions). By default, the score method does not need the actual predictions. So, when we use:\n\nclf.score(X_test, y_test)\n\npprediction is done using X_test behind the scenes and uses the predictions to calculate accuracy score. ","2b4245bb":"# Decision Tree Model","b333288a":"# Support Vector Machine","c2a99cd2":"# K Nearest Neighbor","7c50406f":"# Linear Discriminant Analysis","83f8836f":"# Train Test Split","ca366032":"# Scaling the data","3fb10d13":"# **Exploratory Data Analysis**"}}