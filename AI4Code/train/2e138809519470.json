{"cell_type":{"fea5b7d6":"code","f07091b6":"code","ac7c2b5d":"code","28447b17":"code","784ce172":"code","800aabb3":"code","61a3dc44":"code","f8cbbf44":"code","b385b428":"code","f1e5f59e":"code","a24c03da":"code","fd900f95":"code","117936b0":"code","0239637c":"code","e0091b15":"code","9e0cea8d":"code","bbb3619f":"code","8cba2481":"code","c598f8bd":"code","ae902e6d":"code","34da40e1":"markdown"},"source":{"fea5b7d6":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport pandas as pd\nfrom PIL import Image, ImageOps, ImageEnhance\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.models import Model\nfrom keras.layers import *\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import Adam\nfrom tqdm import tqdm\n%matplotlib inline\n","f07091b6":"img_path = '..\/input\/i2a2-bone-age-regression\/images\/'","ac7c2b5d":"train_df = pd.read_csv('..\/input\/i2a2-bone-age-regression\/train.csv')\ntrain_df.head()\nprint(train_df.shape)","28447b17":"#i = 0\n#while i < 10:\n    #im = Image.open(os.path.join(img_path,train_df['fileName'][random.randint(0, 12611)]))\n    #plt.figure()\n    #plt.imshow(im)\n    #i = i+1","784ce172":"#img_format = []\n#img_size = []\n#for i in train_df['fileName']:\n    #im = Image.open(os.path.join(img_path,i))\n    #img_format.append(im.format)\n    #img_size.append(im.size)\n#print(len(img_size))\n#train_df = train_df.join(pd.DataFrame({'img_format': img_format,'img_size': img_size}, index=train_df.index))\n#train_df['img_format'] = img_format\n#train_df['img_size'] =  img_size","800aabb3":"#train_df.head()","61a3dc44":"one_two_hand = []\nX = []\nrandom.seed(29)\nfor i in tqdm(train_df['fileName']):\n    im = Image.open(os.path.join(img_path,i)).convert('RGB')\n    im = im.resize((256,256))\n    im = im.crop((25,25,225,225))\n    im = im.resize((256,256))\n    im_enh = ImageEnhance.Contrast(im)\n    im = im_enh.enhance(1)\n    rand_onetwo = random.randint(0,1)     \n    if rand_onetwo == 1:\n        im_flip_v = ImageOps.mirror(im)\n        imag = Image.new('RGB',(512,512), color=(100,100,100))\n        imag.paste(im,(0,128,256,384))\n        imag.paste(im_flip_v,(256,128,512,384))\n        imag = imag.resize((256,256))\n        if random.randint(0,1) == 1:\n           imag = ImageOps.flip(imag)\n        #plt.imshow(imag)\n        #plt.show()\n        imag_arr = np.asarray(imag)\n        X.append(imag_arr)\n        one_two_hand.append(0)\n    else:\n        im = im.resize((256,256))   \n        if random.randint(0,1) == 1:\n           im = ImageOps.flip(im) \n        #plt.imshow(im)\n        #plt.show()\n        im_arr = np.asarray(im)\n        X.append(im_arr)\n        one_two_hand.append(1)\nX_t = np.stack(X,axis=0) \ny_t = np.asarray(one_two_hand)\nprint(X_t.shape, y_t.shape)","f8cbbf44":"X_t = np.stack(X,axis=0)\ny_t = np.asarray(one_two_hand)","b385b428":"X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.33, random_state=42)","f1e5f59e":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","a24c03da":"input_ = Input((256, 256,3))\nx = input_\nx = Conv2D(10, kernel_size = (3,3), strides = (1, 1), padding = 'same', activation = 'relu')(x)\nx = Flatten()(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation  =  'sigmoid')(x)\nmodel = Model(input_, x)\nmodel.summary()","fd900f95":"batch_size = 200\nnum_epochs = 20\nlearning_rate = 1e-6\nmodel.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = learning_rate), metrics = ['acc'])","117936b0":"history = model.fit(X_train, y_train,\n          batch_size = batch_size,\n          epochs = num_epochs,\n          verbose = 1,\n          validation_data = (X_test, y_test))","0239637c":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.ylabel('acur\u00e1cia')\nplt.xlabel('\u00e9poca')\nplt.legend(['treino', 'valida\u00e7\u00e3o'], loc = 'upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.ylabel('loss')\nplt.xlabel('\u00e9poca')\nplt.legend(['treino', 'valida\u00e7\u00e3o'], loc = 'upper left')\nplt.show()","e0091b15":"test_df = pd.read_csv('..\/input\/i2a2-bone-age-regression\/test.csv')\n#test_df.head()\n#print(test_df.shape)","9e0cea8d":"X_teste = []\nfor i in test_df['fileName']:\n    im_test = Image.open(os.path.join(img_path,i)).convert('RGB')\n    im_test = im_test.resize((256,256))\n    im_arr_test = np.array(im_test)\n    X_teste.append(im_arr_test)\nX_tteste = np.stack(X_teste,axis=0) ","bbb3619f":"resultado = model.predict(X_tteste)\n#print(resultado)","8cba2481":"false_pos = 0\nfor i in range(0,len(resultado)):\n    if resultado[i] != 1:\n        #print(resultado[i])\n        #print(test_df['fileName'][i])\n        im = Image.open(os.path.join(img_path,test_df['fileName'][i]))\n        w, h = im.size\n        if w <= 800:\n            false_pos += 1\n        plt.title('Image: {} '.format(img_path,test_df['fileName'][i]))\n        plt.imshow(im)\n        plt.show()\nprint(\"imagens classificadas com duas m\u00e3os\", i)","c598f8bd":"false_neg = 0\nfor i in range(0,len(resultado)):\n    if resultado[i] == 1:\n        #print(resultado[i])\n        #print(test_df['fileName'][i])\n        im = Image.open(os.path.join(img_path,test_df['fileName'][i]))\n        w, h = im.size\n        if w > 800:\n            false_neg += 1\n        plt.title('Image: {} '.format(img_path,test_df['fileName'][i]))\n        plt.imshow(im)\n        plt.show()\nprint(\"imagens classificadas com uma m\u00e3o\", i)","ae902e6d":"print('false_positives', false_pos, 'false_negatives', false_neg)","34da40e1":"# Classifica\u00e7\u00e3o para diferenciar as imagens de raio-x com uma e duas m\u00e3os.\n\nApenas as imagens de teste cont\u00e9m esta caracter\u00edstica. As imagens de teste e treino parecem ter sido coletadas de fontes diferentes.\n\nUtilizou-se o processamento das imagens de treino (com uma m\u00e3o) para gerar, de forma aleat\u00f3ria, imagens com duas m\u00e3os.\n\nAs novas imagens geradas (com uma e duas m\u00e3os) s\u00e3o utilizadas para treinar uma CNN.\n\nAs imagens de teste n\u00e3o apresentam indica\u00e7\u00e3o se t\u00eam uma ou duas m\u00e3os, de forma que, foram analisadas, de forma amostral, por meio de inspe\u00e7\u00e3o visual.\n\nO algoritmo aplicado sobre as imagens de teste quase n\u00e3o gera falsos positivos (identificar uma m\u00e3o como sendo duas m\u00e3os) mas gera um consider\u00e1vel n\u00famero de falsos negativos.\n\nO crit\u00e9rio \"tamanho da imagem\"utilizado por [Walxiney Galv\u00e3o](https:\/\/www.kaggle.com\/walxineygalvao) em https:\/\/www.kaggle.com\/walxineygalvao\/i2a2-rsna-bones-age-prediction-xception parece ser mais preciso e menos custoso que este algoritmo.\n"}}