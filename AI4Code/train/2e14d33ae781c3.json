{"cell_type":{"f0b233fd":"code","c4f0ef0e":"code","4715f033":"code","bb39bb9b":"code","7a58068e":"code","e6553e4f":"code","cc77edb2":"code","678bea53":"code","236ba81a":"code","7fe0a338":"code","1a22a094":"code","7b543e96":"code","d5062ca6":"code","0ba0f42f":"code","bdfb936f":"code","668383d3":"markdown","ac5458db":"markdown","e2d192a9":"markdown","8633c02c":"markdown","404fb728":"markdown","5516ca45":"markdown","74776f9c":"markdown","e5ff4604":"markdown"},"source":{"f0b233fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4f0ef0e":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/sample_submission.csv')\ntrain","4715f033":"# Dropping the 'id' column\ntrain.drop(['id'], axis = 1, inplace = True)\ntest.drop(['id'], axis = 1, inplace = True)","bb39bb9b":"# Check any missing value\ntrain.info()","7a58068e":"X_train = train.drop(['target'], axis = 1)\ny_train = train['target']\nX_test = test.copy()","e6553e4f":"train['target'].describe()","cc77edb2":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.displot(y_train)\nplt.show()","678bea53":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","236ba81a":"from sklearn.model_selection import cross_val_score\n\ndef get_score(model, X = X_train, y = y_train, cv = 5):\n    scores = cross_val_score(model, X, y, cv = cv, n_jobs = -1, \n                             scoring = 'neg_mean_squared_error')\n    acc = np.sqrt(-scores)\n    return acc.mean()","7fe0a338":"from sklearn.model_selection import learning_curve\n\ndef plot_model(model, X = X_train, y = y_train, cv = 5):\n    sizes, train_scores, val_scores = learning_curve(model, X, y, cv = cv, \n                                                     scoring = 'neg_mean_squared_error')\n    \n    mean_train_score = np.mean(np.sqrt(-train_scores), axis = 1)\n    mean_val_score = np.mean(np.sqrt(-val_scores), axis = 1)\n    \n    plt.plot(sizes, mean_train_score, 'bo--',  label = 'Training score')\n    plt.plot(sizes, mean_val_score, 'go-', label = 'Cross-validation score')\n    \n    plt.title('Learning curve for ' + str(model).split('(')[0])\n    plt.xlabel('Training Set Size')\n    plt.ylabel('RMSE Score')\n    plt.legend(loc = 'best')\n    plt.grid()\n    plt.show()","1a22a094":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nprint(get_score(lin_reg))\nplot_model(lin_reg)","7b543e96":"from sklearn.linear_model import ElasticNet\n\nelasticnet_reg = ElasticNet()\nprint(get_score(elasticnet_reg))\nplot_model(elasticnet_reg)","d5062ca6":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor\n\nsplit = KFold(n_splits = 5)\nfor train_index, test_index in split.split(X_train):\n    X_train_new, X_test_new = X_train[train_index], X_train[test_index]\n    y_train_new, y_test_new = y_train[train_index], y_train[test_index]\n    \n    params = {\n        'boosting_type': 'gbdt', \n        'objective': 'regression',\n        'metric': 'RMSE',\n        'learning_rate': '0.05',\n        'n_jobs': -1, \n    }\n    \n    lgbm_reg = LGBMRegressor(**params)\n    lgbm_reg.fit(X_train_new, y_train_new)\n    y_pred = lgbm_reg.predict(X_test_new)\n\n    score = mean_squared_error(y_test_new, y_pred, squared = False)\n    \nscore.mean()","0ba0f42f":"params = {\n    'boosting_type': 'gbdt', \n    'objective': 'regression',\n    'metric': 'RMSE',\n    'learning_rate': '0.05',\n    'n_jobs': -1, \n}\n    \nmodel = LGBMRegressor(**params)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","bdfb936f":"submission['target'] = y_pred\nsubmission.to_csv('my_submission.csv', index = False)","668383d3":"## ElasticNet","ac5458db":"## Linear Regression","e2d192a9":"## EDA","8633c02c":"## Utility Functions","404fb728":"## LightGBM Regressor","5516ca45":"## Submission","74776f9c":"## Feature Scaling","e5ff4604":"## Target Distribution"}}