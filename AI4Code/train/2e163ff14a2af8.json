{"cell_type":{"efc81747":"code","9664491d":"code","e1a49fc4":"code","68ccdb5d":"code","754afba7":"code","e134f1e6":"code","19f5d3f7":"code","3ffafed9":"code","98f79ff3":"code","0f0dd175":"code","f47331ce":"code","f2229d4c":"code","e301b4ac":"code","8712b33e":"code","3263eddd":"code","ba830737":"code","5be3b5a0":"code","163420da":"code","9981e175":"code","23eed2f3":"code","20ce5e5d":"code","8031ee94":"code","fbaf23dc":"code","9091a52a":"code","cbf74b94":"code","58c62529":"code","dde77847":"code","594a514b":"code","255cae88":"code","2a91af4a":"code","0be13e14":"code","3c2c3844":"code","f8ef6c81":"code","57a36052":"code","ec4243e2":"code","71371927":"code","f258a88c":"code","4d2d767d":"code","6a1e7a5d":"code","66bd9e9c":"code","d08fef80":"code","9dbe943d":"code","d038f7e1":"code","c1f7eee1":"code","8d1c8e28":"code","017fa57b":"code","60f68610":"markdown","5b5c9acc":"markdown","b815f3f9":"markdown","bb9eb019":"markdown","f9a52870":"markdown","b56af0bf":"markdown","c0ac5497":"markdown","a1033901":"markdown","846b15c8":"markdown","82636ad2":"markdown","b2a79e80":"markdown","b573b8a3":"markdown","71dbba5b":"markdown","0e766029":"markdown","790872ed":"markdown","6ad411a2":"markdown","befdefb3":"markdown","3987b05a":"markdown","63d44e70":"markdown","6c6412fb":"markdown","1592b78a":"markdown","474b07ac":"markdown","94923821":"markdown","eb4c6087":"markdown","6f7e3851":"markdown","a2670d9f":"markdown","ea14612f":"markdown","6d202d31":"markdown","5f4d0f3c":"markdown","a0187208":"markdown","bb71482b":"markdown","99bdfdcd":"markdown","a9719c52":"markdown","fddd45f5":"markdown","c6eee779":"markdown","fe974c2f":"markdown","505cec67":"markdown","c2a62987":"markdown","149feade":"markdown","366dc7ff":"markdown","b84a7c93":"markdown","e5513736":"markdown","a4c15afa":"markdown","52d2c1fc":"markdown","0dbd56fc":"markdown"},"source":{"efc81747":"from glob import glob\n\nimport statsmodels.api as sm\n\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nimport pydicom\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')","9664491d":"train_df = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest_df = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/test.csv')\n\ntrain_df.head()","e1a49fc4":"print('Number of training samples:', train_df.shape[0])\nprint('Number of test samples:', test_df.shape[0])","68ccdb5d":"print('Number of NaN values in training set:', int(train_df.isna().sum().sum()))\nprint('Number of NaN values in test set:', int(test_df.isna().sum().sum()))","754afba7":"print('Number of unique patients:', len(train_df['Patient'].unique()))","e134f1e6":"# Thanks to Twinkle Khanna for the plot, couldn't figure out how to do it with Seaborn ;)\n# https:\/\/www.kaggle.com\/twinkle0705\/your-starter-notebook-for-osic\n\nnew_df = train_df.groupby(\n    [\n        train_df.Patient,\n        train_df.Age,train_df.Sex, \n        train_df.SmokingStatus\n    ]\n)['Patient'].count()\n\nnew_df.index = new_df.index.set_names(\n    [\n        'id',\n        'Age',\n        'Sex',\n        'SmokingStatus'\n    ]\n)\n\nnew_df = new_df.reset_index()\nnew_df.rename(columns = {'Patient': 'freq'},inplace = True)\n\nfig = px.bar(new_df, x='id',y ='freq',color='freq')\nfig.update_layout(\n    xaxis={'categoryorder':'total ascending'},\n    title='Distribution of images for each patient'\n)\nfig.update_xaxes(showticklabels=False)\nfig.show()","19f5d3f7":"ax = sns.distplot(train_df['Weeks'], bins=100)\nax.set_title('Distribution of Weeks')","3ffafed9":"ax = sns.distplot(train_df['FVC'], bins=100)\nax.set_title('Distribution of the target variable (FVC)')","98f79ff3":"fig = px.histogram(\n    train_df, \n    x='FVC',\n    nbins =100\n)\n\nfig.update_traces(\n    marker_color='rgb(158,202,225)', \n    marker_line_color='rgb(8,48,107)',\n    marker_line_width=1.5, \n    opacity=0.6\n)\n\nfig.update_layout(\n    title = 'Distribution of FVC'\n)\n\nfig.show()","0f0dd175":"fig = px.histogram(\n    new_df, \n    x='Age',\n    nbins = 42\n)\n\nfig.update_traces(\n    marker_color='rgb(158,202,225)', \n    marker_line_color='rgb(8,48,107)',\n    marker_line_width=1.5, \n    opacity=0.6\n)\n\nfig.update_layout(\n    title = 'Distribution of Age'\n)\n\nfig.show()","f47331ce":"temp = train_df.groupby('Sex').count()['Patient'].reset_index().sort_values(by='Patient',ascending=False)\ntemp.style.background_gradient(cmap='Reds')","f2229d4c":"fig = px.funnel_area(\n    names=temp['Sex'].values,\n    values=temp['Patient'].values,\n)\n\nfig.update_layout(\n    title = 'Distribution of Sex'\n)\n\nfig.show()","e301b4ac":"temp = train_df.groupby('SmokingStatus').count()['Patient'].reset_index().sort_values(by='Patient',ascending=False)\ntemp.style.background_gradient(cmap='Reds')","8712b33e":"fig = px.funnel_area(\n    names=temp['SmokingStatus'].values,\n    values=temp['Patient'].values,\n)\n\nfig.update_layout(\n    title = 'Distribution of SmokingStatus'\n)\n\nfig.show()","3263eddd":"fig = plt.figure(figsize=(10,6))\nax = sns.countplot(x=\"SmokingStatus\", hue=\"Sex\", data=train_df)\nfor p in ax.patches:\n    '''\n    https:\/\/www.kaggle.com\/rohitsingh9990\/panda-eda-better-visualization-simple-baseline\n    '''\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2,\n                height +3,\n                '{:1.2f}%'.format(100*height\/len(train_df)),\n                ha=\"center\")\n\nax.set_title('Bivariate analysis: Distribution of SmokingStatus with respect to Sex')","ba830737":"fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n\nsns.distplot(\n    train_df[train_df['Sex'] == 'Male']['Age'], \n    bins=30, \n    ax=ax, \n    kde_kws=\n        {\n            \"color\": \"blue\", \n            \"label\": \"Male\"\n        },\n    hist_kws=\n        {\n            \"linewidth\": 3,\n            \"color\": \"blue\"\n        }\n)\n\nsns.distplot(\n    train_df[train_df['Sex'] == 'Female']['Age'], \n    bins=30, \n    ax=ax,\n    kde_kws=\n        {\n            \"label\": \"Female\",\n            \"color\": 'mediumturquoise'\n        },\n    hist_kws=\n        {\n            'linewidth': 3,\n            'color': 'mediumturquoise',\n        }\n)\n\nfig.suptitle('Distribution of Age w.r.t. sex for unique patients')","5be3b5a0":"fig = px.histogram(\n    train_df, \n    x='Age',\n    color='Sex',\n    color_discrete_map=\n        {\n            'Male':'blue',\n            'Female':'mediumturquoise'\n        },\n    hover_data=train_df.columns\n)\n\nfig.update_layout(title='Distribution of Age w.r.t. sex for unique patients')\n\nfig.update_traces(\n    marker_line_color='black',\n    marker_line_width=1.5, \n    opacity=0.85\n)\n\nfig.show()","163420da":"# Plot overlapping distribution\n\nfig, ax = plt.subplots(1, 1, figsize=(7, 7))\n\nsns.distplot(\n    train_df[train_df['SmokingStatus'] == 'Never smoked']['Age'], \n    bins=30, \n    ax=ax, \n    kde_kws=\n        {\n            \"color\": \"khaki\", \n            \"label\": \"Never smoked\"\n        },\n    hist_kws=\n        {\n            \"linewidth\": 3,\n            \"color\": \"khaki\"\n        }\n)\n\nsns.distplot(\n    train_df[train_df['SmokingStatus'] == 'Currently smokes']['Age'], \n    bins=30, \n    ax=ax,\n    kde_kws=\n        {\n            \"label\": \"Currently smokes\",\n            \"color\": 'darksalmon'\n        },\n    hist_kws=\n        {\n            'linewidth': 3,\n            'color': 'darksalmon',\n        }\n)\n\nsns.distplot(\n    train_df[train_df['SmokingStatus'] == 'Ex-smoker']['Age'], \n    bins=30, \n    ax=ax,\n    kde_kws=\n        {\n            \"label\": \"Ex-smoker\",\n            \"color\": 'teal'\n        },\n    hist_kws=\n        {\n            'linewidth': 3,\n            'color': 'teal',\n        }\n)\n\nfig.suptitle('Distribution of Age w.r.t. SmokingStatus for unique patients')","9981e175":"fig = px.histogram(\n    train_df, \n    x='Age',\n    color='SmokingStatus',\n    color_discrete_map=\n        {\n            'Never smoked':'khaki',\n            'Currently smokes':'darksalmon',\n            'Ex-smoker': 'teal', \n        },\n    hover_data=train_df.columns\n)\n\nfig.update_layout(title='Distribution of Age w.r.t. SmokingStatus for unique patients')\n\nfig.update_traces(\n    marker_line_color='black',\n    marker_line_width=1.5, \n    opacity=0.85\n)\n\nfig.show()","23eed2f3":"fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n\nsns.distplot(\n    train_df[train_df['Sex'] == 'Male']['FVC'], \n    bins=30, \n    ax=ax, \n    kde_kws=\n        {\n            \"color\": \"blue\", \n            \"label\": \"Male\"\n        },\n    hist_kws=\n        {\n            \"linewidth\": 3,\n            \"color\": \"blue\"\n        }\n)\n\nsns.distplot(\n    train_df[train_df['Sex'] == 'Female']['FVC'], \n    bins=30, \n    ax=ax,\n    kde_kws=\n        {\n            \"label\": \"Female\",\n            \"color\": 'mediumturquoise'\n        },\n    hist_kws=\n        {\n            'linewidth': 3,\n            'color': 'mediumturquoise',\n        }\n)\n\nfig.suptitle('Distribution of FVC w.r.t. sex for unique patients')","20ce5e5d":"fig = px.histogram(\n    train_df, \n    x='FVC',\n    color='Sex',\n    color_discrete_map=\n        {\n            'Male':'blue',\n            'Female':'mediumturquoise'\n        },\n    hover_data=train_df.columns\n)\n\nfig.update_layout(title='Distribution of FVC w.r.t. sex for unique patients')\n\nfig.update_traces(\n    marker_line_color='black',\n    marker_line_width=1.5, \n    opacity=0.85\n)\n\nfig.show()","8031ee94":"# Plot overlapping distribution\n\nfig, ax = plt.subplots(1, 1, figsize=(7, 7))\n\nsns.distplot(\n    train_df[train_df['SmokingStatus'] == 'Never smoked']['FVC'], \n    bins=30, \n    ax=ax, \n    kde_kws=\n        {\n            \"color\": \"khaki\", \n            \"label\": \"Never smoked\"\n        },\n    hist_kws=\n        {\n            \"linewidth\": 3,\n            \"color\": \"khaki\"\n        }\n)\n\nsns.distplot(\n    train_df[train_df['SmokingStatus'] == 'Currently smokes']['FVC'], \n    bins=30, \n    ax=ax,\n    kde_kws=\n        {\n            \"label\": \"Currently smokes\",\n            \"color\": 'darksalmon'\n        },\n    hist_kws=\n        {\n            'linewidth': 3,\n            'color': 'darksalmon',\n        }\n)\n\nsns.distplot(\n    train_df[train_df['SmokingStatus'] == 'Ex-smoker']['FVC'], \n    bins=30, \n    ax=ax,\n    kde_kws=\n        {\n            \"label\": \"Ex-smoker\",\n            \"color\": 'teal'\n        },\n    hist_kws=\n        {\n            'linewidth': 3,\n            'color': 'teal',\n        }\n)\n\nfig.suptitle('Distribution of FVC w.r.t. SmokingStatus for unique patients')","fbaf23dc":"fig = px.histogram(\n    train_df, \n    x='FVC',\n    color='SmokingStatus',\n    color_discrete_map=\n        {\n            'Never smoked':'khaki',\n            'Currently smokes':'darksalmon',\n            'Ex-smoker': 'teal', \n        },\n    hover_data=train_df.columns\n)\n\nfig.update_layout(title='Distribution of FVC w.r.t. SmokingStatus for unique patients')\n\nfig.update_traces(\n    marker_line_color='black',\n    marker_line_width=1.5, \n    opacity=0.85\n)\n\nfig.show()","9091a52a":"sns.jointplot(x=\"Weeks\", y=\"FVC\", data=train_df)","cbf74b94":"X = train_df['Weeks'].values\ny = train_df['FVC'].values\n\nresults = sm.OLS(y, X).fit()\nprint(results.summary())","58c62529":"def plot_patient_level_weeks_vs_fvc(patient_id, ax):\n    X = train_df[train_df['Patient'] == patient_id]['Weeks'].values\n    y = train_df[train_df['Patient'] == patient_id]['FVC'].values\n    \n    ax.set_title(patient_id)\n    ax = sns.regplot(X, y, ax=ax, ci=None, line_kws={'color':'red'})","dde77847":"f, axes = plt.subplots(1, 3, figsize=(15, 5))\n\npatient_ids = train_df[\"Patient\"].sample(n=3).values\n\nfor i in range(3):\n    plot_patient_level_weeks_vs_fvc(patient_ids[i], axes[i])","594a514b":"sns.jointplot(x=\"Percent\", y=\"FVC\", data=train_df)","255cae88":"X = train_df['Percent'].values\ny = train_df['FVC'].values\n\nresults = sm.OLS(y, X).fit()\nprint(results.summary())","2a91af4a":"def load_scan(path):\n    slices = [pydicom.read_file(path + '\/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.InstanceNumber))\n    \n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices","0be13e14":"gkf = GroupKFold(n_splits=5)\n\nX = train_df[['Patient', 'Weeks', 'Percent', 'Age', 'Sex', 'SmokingStatus']].values\ny = train_df['FVC'].values\ngroups = train_df['Patient'].values\n\nfor i, (trn_, val_) in enumerate(gkf.split(X, y, groups)):\n    train_df.loc[val_, 'fold'] = i\n\ntrain_df['fold'] = train_df['fold'].astype(int)","3c2c3844":"p = []\n\nfor i in range(5):\n    f = set(train_df[train_df['fold'] == i]['Patient'].unique())\n    p.append(f)\n\nprint('Number of common patients across folds:', len(set.intersection(*p)))","f8ef6c81":"# Check distribution of patients within a fold\n\nfig, ax = plt.subplots(1, 5, figsize=(18, 3))\n\nfor i in range(5):\n    sns.countplot(train_df[train_df['fold'] == i]['Patient'], ax=ax[i])\n    ax[i].set_title(f'Fold {i+1}')\n    ax[i].xaxis.set_ticklabels([])\n\nfig.suptitle('Distribution of patients in folds')\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])","57a36052":"train_df.head()","ec4243e2":"train_df.to_csv('train_df.csv')","71371927":"# Quick label encoding\n\nle = LabelEncoder()\ntrain_df['Sex'] = le.fit_transform(train_df['Sex'])\ntest_df['Sex'] = le.transform(test_df['Sex'])\n\ntrain_df['SmokingStatus'] = le.fit_transform(train_df['SmokingStatus'])\ntest_df['SmokingStatus'] = le.transform(test_df['SmokingStatus'])","f258a88c":"def metric(actual_fvc, predicted_fvc, confidence, return_values = False):\n    \"\"\"\n        Calculates the modified Laplace Log Likelihood score for this competition.\n        Credits: https:\/\/www.kaggle.com\/rohanrao\/osic-understanding-laplace-log-likelihood\n    \"\"\"\n    sd_clipped = np.maximum(confidence, 70)\n    delta = np.minimum(np.abs(actual_fvc - predicted_fvc), 1000)\n    metric = - np.sqrt(2) * delta \/ sd_clipped - np.log(np.sqrt(2) * sd_clipped)\n\n    if return_values:\n        return metric\n    else:\n        return np.mean(metric)","4d2d767d":"param = {\n        'objective':'regression',\n        'metric': 'rmse',\n        'boosting_type': 'gbdt',\n        'learning_rate': 0.01,\n        'max_depth':-1\n}\n\ntarget = 'FVC'","6a1e7a5d":"def train_lgb_model(features):    \n    y_oof = np.zeros(train_df.shape[0])\n    y_test = np.zeros((test_df.shape[0], 5))\n\n    for f, (train_ind, val_ind) in enumerate(gkf.split(train_df, train_df, groups)):\n        print(f'Training on all folds except {f}, validation on {f}')\n        t_df, val_df = train_df.iloc[train_ind], train_df.iloc[val_ind]\n\n        model = LGBMRegressor()\n        model.fit(t_df[features], t_df[target])\n        \n        lgb.plot_importance(model, title=f'Feature importance - Fold {f+1}')\n\n        y_oof[val_ind] = model.predict(val_df[features])\n        y_test[:, f] = model.predict(test_df[features])\n    \n    return y_oof, y_test","66bd9e9c":"features = ['Weeks', 'Percent', 'Age', 'Sex', 'SmokingStatus']\ny_oof, y_test = train_lgb_model(features)","d08fef80":"train_df['oof_preds'] = y_oof\ntest_df['target'] = y_test.mean(axis=1)\n\nscore = metric(train_df[target], train_df['oof_preds'], np.std(train_df['oof_preds']))\n\nprint('OOF log-Laplace likelihood score:', score)","9dbe943d":"# Lagging features\n\ndef generate_lagging_features(df):\n    for i in [1, 2, 3]:\n        df['lag_FVC_'+str(i)] = df.groupby(['Patient'])['FVC'].transform(lambda x: x.shift(i))\n        df['lag_percent_'+str(i)] = df.groupby(['Patient'])['Percent'].transform(lambda x: x.shift(i))\n    \n    return df","d038f7e1":"# Running statistics\n\ndef generate_running_statistics(df):\n    for i in [3, 5, 7]:\n        df['rolling_FVC_mean_'+str(i)] = df.groupby(['Patient'])['FVC'].transform(lambda x: x.shift(1).rolling(i).mean())\n        df['rolling_FVC_std_'+str(i)]  = df.groupby(['Patient'])['FVC'].transform(lambda x: x.shift(1).rolling(i).std())\n        df['rolling_FVC_max_'+str(i)]  = df.groupby(['Patient'])['FVC'].transform(lambda x: x.shift(1).rolling(i).max())\n        \n        df['rolling_percent_mean_'+str(i)] = df.groupby(['Patient'])['Percent'].transform(lambda x: x.shift(1).rolling(i).mean())\n        df['rolling_percent_std_'+str(i)]  = df.groupby(['Patient'])['Percent'].transform(lambda x: x.shift(1).rolling(i).std())\n        df['rolling_percent_max_'+str(i)]  = df.groupby(['Patient'])['Percent'].transform(lambda x: x.shift(1).rolling(i).max())\n    \n    return df","c1f7eee1":"train_df = generate_lagging_features(train_df)\ntrain_df = generate_running_statistics(train_df)\n\ntest_df = generate_lagging_features(test_df)\ntest_df = generate_running_statistics(test_df)","8d1c8e28":"features = [x for x in list(train_df.columns) if x not in ['Patient', 'fold', 'FVC', 'oof_preds']]\ny_oof, y_test = train_lgb_model(features)","017fa57b":"train_df['oof_preds'] = y_oof\ntest_df['target'] = y_test.mean(axis=1)\n\nscore = metric(train_df[target], train_df['oof_preds'], np.std(train_df['oof_preds']))\n\nprint('OOF log-Laplace likelihood score:', score)","60f68610":"#### Percent vs FVC","5b5c9acc":"### NaN values?","b815f3f9":"#### Smoker status vs sex","bb9eb019":"No NaN values to handle, good news...","f9a52870":"Another good news, the distribution is almost uniform. No fat-tailed distributions which mean we don't have to worry about edge cases like a patient having 250 images and another one having only one. Our fold will be balanced and that's another great news for validation.","b56af0bf":"As you can see, no overlapping groups and the distribution of patients across the folds is close to being uniform and identical which is what we want. \n\nNow let's try to build a baseline model ;)","c0ac5497":"#### FVC (target value)\n\nNow let's look at the target value, it is key to have a sense of what the empirical distribution is.","a1033901":"#### Sex","846b15c8":"**Some notes**:\n- The age distribution of people currently smoking has multiple peaks and is discontinuous. It is not concentrated around a mean and is equally distributed between 50 and 70 year-old.\n- As expected, the ex-smoker are often older than the people who have never smoked. The standard deviation is equivalent between the two.","82636ad2":"As expected, most patient having pulmonary fibrosis were ex-smokers since we know smoking is one of the leading factor in the development of a pulmonary fibrosis. The proportion of non-smoker people is non neglectable as well, while smokers only account for a small portion of the training set.","b2a79e80":"#### Smoker vs Age","b573b8a3":"#### Age","71dbba5b":"# EDA","0e766029":"#### FVC vs smoker","790872ed":"#### Visualizing images\n\nNow let's try to visualize the DICOM images to gain a sense of what a CT scan looks like and how we can load a CT scan in a model.","6ad411a2":"The \"Currently Smokes\" distribution is more peaked around 2700ml.\n\n**Now let's plot continuous variables against the target.**","befdefb3":"**Overall we'll need to make sure that the distribution of the features are identical in all the folds we generate.** Otherwise, we might unintendedly create folds that are easier than others.","3987b05a":"Thanks for reading, if you like the notebook, don't forget to upvote ;)","63d44e70":"### Bivariate analysis","6c6412fb":"There are much more male samples than female samples. In a real-word, this might be a problem since the statistical model might be biased for female samples.","1592b78a":"On the contrary of patient distribution, this one is heavy-tailed (in its simplest definition, its kurtosis is higher than 3). Most patients have their FVC measurements taken few weeks **AFTER** the baseline CT scan.","474b07ac":"### Quick summary of available features\n\n- Patient: unique ID of a patient\n- Weeks: number of weeks pre or post the CT scan\n- FVC (target): the lung capacity in ml, which measures the severity of the fibrosis\n- Percent: a statistic which approximates the patient's FVC as a percent of the typical FVC for a person of similar characteristics\n- Age: age\n- Sex: sex\n- SmokingStatus: is the patient an ex-smoker? a non-smoker? a current smoker?","94923821":"### Feature engineering","eb4c6087":"Indeed, we find that as the number of weeks increases, the lung capacity worsens... There are some feature engineering to do: running average of the lung capacity, previous max, previous min...","6f7e3851":"This plot indicates a strong correlation between Percent and FVC. Again, there might have an heteroskedasticity issue.","a2670d9f":"Interesting to note we only have 5 test samples, which means we'll have to build a robust validation strategy and to not rely too much on the leaderboard score.","ea14612f":"#### Sex vs Age","6d202d31":"#### SmokingStatus","5f4d0f3c":"## Getting familiar with tabular data","a0187208":"TBC....","bb71482b":"# OSIC: EDA + Leak-free KFold CV + LGB Baseline\n\n## What is pulmanory fibrosis?\n\nThe word \u201cpulmonary\u201d means lung and the word \u201cfibrosis\u201d means **scar tissue**\u2014 similar to scars that you may have on your skin from an old injury or surgery. So, in its simplest sense, pulmonary fibrosis (PF) means **scarring in the lungs**. Over time, the scar tissue can destroy the normal lung and make it **hard for oxygen to get into your blood**. Low oxygen levels (and the stiff scar tissue itself) can cause you to feel short of breath, particularly when walking and exercising. Pulmonary fibrosis isn\u2019t just one disease. It is a **family of more than 200 different lung diseases that all look very much alike**. The PF family of lung diseases falls into an even larger group of diseases called the **interstitial lung diseases** (also known as ILD), which includes all of the diseases that have inflammation and\/or scarring in the lung. Some interstitial lung diseases don\u2019t include scar tissue. **When an interstitial lung disease does include scar tissue in the lung, we call it pulmonary fibrosis.**\n\n## Why is it important?\n\nNo one is certain how many people are affected by PF. One recent study estimated that idiopathic pulmonary fibrosis (or IPF, which is just one of more than 200 types of PF) affects 1 out of 200 adults over the age of 60 in the United States\u2014that translates to more than 200,000 people living with PF today. Approximately 50,000 new cases are diagnosed each year and as many as 40,000 Americans die from IPF each year.\n\n*From: https:\/\/www.pulmonaryfibrosis.org\/life-with-pf\/about-pf *\n\n![Screen%20Shot%202020-08-16%20at%205.01.41%20PM.png](attachment:Screen%20Shot%202020-08-16%20at%205.01.41%20PM.png)","99bdfdcd":"# Baseline model (Meta-features only)","a9719c52":"#### FVC vs sex","fddd45f5":"### Univariate analysis (distribution)\n\n#### Patient id\n\nOne of the key thing we'll need to handle is to make sure we don't introduce any leaks in our folds. Put simply, if we divide the dataset into 5 folds of equal size, since multiple CT scans come from one patient, having CT scan A from Patient 1 in the training set and CT scan B from the same Patient 1 in the test set will introduce a data leak since the meta-features will be learnt by the statistical model at training time.\n\nThis would have the effect of artificially boost our performance, which is not something we want. Indeed, we want to have a true reflect of our model performance. Let's first investigate the distribution of number of pictures per patient.\n\nThanks to Twinkle Khanna for the plot, couldn't figure out how to do it with Seaborn ;)\nhttps:\/\/www.kaggle.com\/twinkle0705\/your-starter-notebook-for-osic","c6eee779":"Now that we have a clear idea of what our data looks like. We need to build a robust validation strategy. Since there exist only 5 samples in the test set, we want to rely on an accurate validation score to make decisions.\nIn particular, we don't want to include any leak as explained higher in the notebook. We don't want one patient being in the training folds and the validation fold at the same time since the statistical model might have learnt the features of a patient. Our validation fold would not be an accurate test of whether our model is able to generalize.\n\nHence, let's try to use GroupKFold to create a K-fold partition with non-overlapping groups (here the Patient ID).","fe974c2f":"As expected, since the lung capacity of male is often larger than female, the distribution of FVC is shifted to the right.","505cec67":"After a quick training, we obtain a baseline meta-features-only score of **-7.504558251812265**. We can improve this score with further feature engineering as we shall see later.","c2a62987":"The distribution looks Gaussian. After trying to apply different transforms (Box-Cox, Square Root, Log), the distribution doesn't change much. A possible experiment might be to try to predict the log or the square root of the target variable.","149feade":"At first glance, female distribution has the largest standard deviation and a higher kurtosis (more females have an age in the tails) than the male distribution. Male distribution has a higher peak suggesting that male ages are more concentrated around the mean.","366dc7ff":"The Adjusted R-squared is **0.584**, which indicates that a significant part of the variance of FVC is explained by Weeks. That is corroborated by the fact the Omnibus test indicates that the explained variance is way higher than the unexplained variance. \n\nHowever this number should be carefully interpreted since as stated above the hypotheses of the statistical model might not be all respected. It could thus lead to an overestimation of the R-squared ratio. In particular, the Durbin-Watson statistics which is a measure of the auto-correlation of data is particularly close to 0, which indicates a positive autocorrelation.\n\nIntuitively though, we could think that the more weeks after the CT baseline, the more the lung capacity worsens and thus the less the FVC.\n\nLet's try to investigate a bit further to see if at the patient-level, the lung capacity declines over the weeks.","b84a7c93":"At first sight, it doesn't seem like there's a clear correlation between the number of Weeks before or after the baseline CT scan and the FVC. We need to be careful if we want to apply an ordinary least-square regression because all the hypotheses of the model are not respected.\n\nIn particular, it seems like the data is heretoskedastic which can make the OLS fail or give inexact results because of the failing of the least-square method. Let's try to do a quick regression.","e5513736":"# Generating leak-free folds","a4c15afa":"#### Weeks","52d2c1fc":"With feature engineering, our score is now **-7.211202141267011**, which is an improvement of our CV!","0dbd56fc":"#### Weeks vs FVC"}}