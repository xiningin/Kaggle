{"cell_type":{"4abde54a":"code","6ac645ff":"code","99a5dc4c":"code","29493058":"code","47d6b242":"code","f97c37fe":"code","d25fa5f0":"code","1fc4d5ce":"code","747993e2":"code","a2aa3ef5":"code","64e4a2bd":"code","dfd40d41":"code","254a751f":"code","574ce7af":"code","62a0369a":"code","ca399b6d":"code","00041199":"code","9125c43c":"code","4997a950":"code","33572ed6":"code","58c45d04":"code","68e707aa":"code","a92e197f":"code","3be497c8":"code","fb625172":"code","e9264c91":"code","663a23a8":"code","1e047b72":"code","8631ad65":"code","e62800f3":"code","be9c0fad":"code","2f47bc97":"code","ba19fa81":"code","77f4f2dd":"code","d036d825":"code","245e6726":"code","52678ba9":"code","029cbebf":"code","675dd1b1":"code","d4896de1":"code","075fe01c":"code","ab901177":"code","de8a5225":"code","586b5793":"code","c5b494d2":"code","e48a7424":"code","a38cfe64":"code","0b1a57eb":"code","95d8e1d5":"code","0b524b6c":"code","5e80ef6f":"code","b3f5f9b9":"code","6a412632":"code","0fb06f6e":"code","25a7ce39":"code","c1a1387e":"code","2a174041":"code","599dc4c7":"code","443045e0":"code","2358a012":"code","53970117":"code","558c1fb8":"code","155e8b30":"code","cfe1b2ff":"code","4b21c17d":"code","0707c018":"code","025d8677":"code","c9c96e68":"code","7299dd61":"code","b12b5521":"code","1bb44d5f":"code","76ae08c8":"code","3564be1f":"code","f33ee750":"code","d82e362b":"code","d13e019a":"code","9962ab59":"code","c89cc889":"code","c0e9bf06":"code","3e73cd01":"code","09de2f92":"code","f2df8d0d":"code","8348bfa5":"code","85c1b220":"code","1b24b28a":"code","06cc1154":"code","a8e26186":"code","bb35744f":"code","7dd20596":"code","036adae5":"code","38a5d6d1":"code","6f0afd6e":"code","347827b9":"code","629e8246":"code","0be931d0":"code","c650ea13":"code","c8a03ce1":"code","d1828fa0":"code","b75a206f":"code","5a2fe296":"code","e5c283e8":"code","769f61f0":"code","ab205030":"code","4a9e1dcc":"code","cd7b15d9":"code","c9554580":"code","c2df5324":"code","6b517332":"markdown","b9ea75c5":"markdown","55095eba":"markdown","97868017":"markdown","17f79dab":"markdown","83281ec4":"markdown","e2eb8ca4":"markdown","abd0899f":"markdown","f006629f":"markdown","5ea76e85":"markdown","e6c43c4d":"markdown","638fd475":"markdown","63a1544c":"markdown","6c0f315b":"markdown","03e0c48c":"markdown","ac31bbdc":"markdown","dd89105a":"markdown","5ff4f350":"markdown","98c0c4f2":"markdown","4b0b1d5b":"markdown","f9429d4f":"markdown","876aa8ad":"markdown","b600f288":"markdown","5e60ca75":"markdown","de0836df":"markdown","73145d27":"markdown","fced3535":"markdown","255e3b92":"markdown","f5f5d3c8":"markdown","b83c4dcc":"markdown","6cb51f5a":"markdown","6ec29e72":"markdown","df3df676":"markdown","704aaab6":"markdown","3ed1dcbe":"markdown","f2734842":"markdown","46a4db3e":"markdown"},"source":{"4abde54a":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","6ac645ff":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","99a5dc4c":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","29493058":"train.head()","47d6b242":"test.head()","f97c37fe":"train.info()","d25fa5f0":"train.describe().T","1fc4d5ce":"train['Pclass'].value_counts()","747993e2":"train['Sex'].value_counts()","a2aa3ef5":"train['SibSp'].value_counts()","64e4a2bd":"train['Parch'].value_counts()","dfd40d41":"train['Ticket'].value_counts()","254a751f":"train['Cabin'].value_counts()","574ce7af":"train['Embarked'].value_counts()","62a0369a":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","ca399b6d":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","00041199":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","9125c43c":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","4997a950":"train.head()","33572ed6":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","58c45d04":"train.describe().T","68e707aa":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","a92e197f":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","3be497c8":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","fb625172":"train.sort_values(\"Fare\", ascending=False).head()","e9264c91":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","663a23a8":"train.sort_values(\"Fare\", ascending=False).head()","1e047b72":"test.sort_values(\"Fare\", ascending=False)","8631ad65":"test['Fare'] = test['Fare'].replace(512.3292, 300)","e62800f3":"test.sort_values(\"Fare\", ascending=False)","be9c0fad":"train.isnull().sum()","2f47bc97":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","ba19fa81":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","77f4f2dd":"train.isnull().sum()","d036d825":"test.isnull().sum()","245e6726":"train.isnull().sum()","52678ba9":"test.isnull().sum()","029cbebf":"train[\"Embarked\"].value_counts()","675dd1b1":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","d4896de1":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","075fe01c":"train.isnull().sum()","ab901177":"test.isnull().sum()","de8a5225":"test[test[\"Fare\"].isnull()]","586b5793":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","c5b494d2":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","e48a7424":"test[\"Fare\"].isnull().sum()","a38cfe64":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","0b1a57eb":"train.isnull().sum()","95d8e1d5":"test.isnull().sum()","0b524b6c":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","5e80ef6f":"train.head()","b3f5f9b9":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","6a412632":"train.head()","0fb06f6e":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","25a7ce39":"train.head()","c1a1387e":"train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","2a174041":"test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","599dc4c7":"train.head()","443045e0":"test.head()","2358a012":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","53970117":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","558c1fb8":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","155e8b30":"train.isnull().sum()","cfe1b2ff":"test['Title'] = test['Title'].map(title_mapping)","4b21c17d":"test.head()","0707c018":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","025d8677":"train.head()","c9c96e68":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","7299dd61":"# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)","b12b5521":"train.head()","1bb44d5f":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","76ae08c8":"train.head()","3564be1f":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])","f33ee750":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","d82e362b":"train.head()","d13e019a":"train.head()","9962ab59":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","c89cc889":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","c0e9bf06":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","3e73cd01":"train.head()","09de2f92":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","f2df8d0d":"test.head()","8348bfa5":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","85c1b220":"train.head()","1b24b28a":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","06cc1154":"test.head()","a8e26186":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","bb35744f":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","7dd20596":"train.head()","036adae5":"test.head()","38a5d6d1":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","6f0afd6e":"train.head()","347827b9":"x_train.shape","629e8246":"x_test.shape","0be931d0":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","c650ea13":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","c8a03ce1":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","d1828fa0":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","b75a206f":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","5a2fe296":"xgb_cv_model.fit(x_train, y_train)","e5c283e8":"xgb_cv_model.best_params_","769f61f0":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","ab205030":"xgb_tuned =  xgb.fit(x_train,y_train)","4a9e1dcc":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","cd7b15d9":"test","c9554580":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","c2df5324":"output.head()","6b517332":"### Visualization","b9ea75c5":"# EDA","55095eba":"# Modeling, Evaluation and Model Tuning","97868017":"#### Sex vs survived:","17f79dab":"## Outlier Treatment","83281ec4":"### Embarked","e2eb8ca4":"#### Parch vs survived:","abd0899f":"### AgeGroup","f006629f":"### Classes of some categorical variables","5ea76e85":"## Logistic Regression","e6c43c4d":"### Basic summary statistics about the numerical data","638fd475":"### Embarked","63a1544c":"## Loading Data","6c0f315b":"## Spliting the train data","03e0c48c":"### Ticket","ac31bbdc":"# Data Preparation","dd89105a":"#### SibSp vs survived:","5ff4f350":"## Missing Value Treatment","98c0c4f2":"### Fare","4b0b1d5b":"## Analysis and Visualization of Numeric and Categorical Variables","f9429d4f":"## Gradient Boosting Classifier","876aa8ad":"### Embarked & Title","b600f288":"### Age","5e60ca75":"### Name - Title","de0836df":"**Titanic Survival Prediction:**\n\nUse machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","73145d27":"## Variable Transformation","fced3535":"## Deleting Unnecessary Variables","255e3b92":"## Random Forest","f5f5d3c8":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","b83c4dcc":"### Pclass","6cb51f5a":"#### Pclass vs survived:","6ec29e72":"### Family Size","df3df676":"# Deployment","704aaab6":"### Sex","3ed1dcbe":"### Cabin","f2734842":"## Feature Engineering","46a4db3e":"### Fare"}}