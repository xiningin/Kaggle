{"cell_type":{"1ca274a2":"code","9cbb5845":"code","7197f888":"code","2b085e28":"code","8416dc3b":"code","4cff55f6":"code","5f7ac2dd":"code","d10d5985":"code","2fc1a6e5":"code","b91e848b":"code","cc50f231":"code","4b5650d6":"code","34248d85":"code","a25d5016":"code","02ef27a6":"code","27995a30":"code","e11a08e3":"code","ad7de597":"code","e0c831e9":"code","a49b2d91":"code","44acc0f2":"code","b994f2ce":"code","d5087905":"code","8cb9b215":"code","1a29e0c4":"code","28e789da":"code","1ea0fcc6":"code","39fbb0b9":"code","8c62d8de":"code","36664802":"code","24210ad2":"code","7c6198e9":"code","3167f5b0":"code","208fa100":"code","b734bf76":"code","1b9ac293":"code","40aef9ad":"code","df6226ba":"code","334d5692":"code","1fe46b41":"code","9dbb251a":"code","9737561d":"markdown","2ecaab1a":"markdown","3c3e6d94":"markdown","bdbd6a74":"markdown","bd0c7717":"markdown","2879ee7c":"markdown","5a31b80e":"markdown","29662480":"markdown","674efe7e":"markdown","f3168ac0":"markdown","758eb4d7":"markdown","41a136fb":"markdown"},"source":{"1ca274a2":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport os\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom scipy import stats","9cbb5845":"path_in = '..\/input\/house-prices-advanced-regression-techniques\/'\nos.listdir(path_in)","7197f888":"df_train = pd.read_csv(path_in+\"train.csv\")\ndf_test = pd.read_csv(path_in+\"test.csv\")","2b085e28":"df_train.head()","8416dc3b":"df_test.head()","4cff55f6":"num=df_train.select_dtypes(exclude='object')\nnumcorr=num.corr()\nf,ax=plt.subplots(figsize=(17,1))\nsns.heatmap(numcorr.sort_values(by=['SalePrice'], ascending=False).head(1), cmap='PuRd_r')\nplt.title(\" Numerical features correlation with the sale price\", weight='bold', fontsize=18)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold', color='dodgerblue', rotation=0)\n\nplt.show()","5f7ac2dd":"# function that print the percentage of missing data in features of dataframe\ndef missingDataPercentage(dataframe):\n    total = dataframe.isnull().sum().sort_values(ascending=False)\n    print(\"missing data percentage\")\n    totalp = (total\/dataframe.shape[0])*100\n    print(pd.DataFrame(totalp[totalp >0]))\n","d10d5985":"# missing data in training set and testing set\nprint(\"training set\")\nmissingDataPercentage(df_train)\nprint(\"\\n \\n\"+'-'*25)\nprint(\"testing set\")\nmissingDataPercentage(df_test)","2fc1a6e5":"all_data_na = (df_train.isnull().sum() \/ len(df_train)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nf, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation=\"90\")\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel(\"Features\", fontsize=15)\nplt.ylabel(\"Percent of missing values\", fontsize=15)\nplt.title(\"Percent missing data by feature\", fontsize=15)","b91e848b":"# Nan poolQC value mean that there is no pool so we replace it with None\ndf = df_train.copy()\nds = df_test.copy()\ndf['PoolQC'] = df['PoolQC'].fillna('None')\nds['PoolQC'] = ds['PoolQC'].fillna('None')","cc50f231":"# Nan MiscFeature value mean that there is no Miscellaneous feature not covered in other categories so we replace it with None\ndf['MiscFeature'] = df['MiscFeature'].fillna('None')\nds['MiscFeature'] = ds['MiscFeature'].fillna('None')\n","4b5650d6":"# Nan Alley value mean that there is No alley access so we replace it with None\ndf['Alley'] = df['Alley'].fillna('None')\nds['Alley'] = ds['Alley'].fillna('None')\n","34248d85":"# Nan Fence value mean that there is No Fence so we replace it with None\ndf['Fence'] = df['Fence'].fillna('None')\nds['Fence'] = ds['Fence'].fillna('None')\n","a25d5016":"# Nan FireplaceQu value mean that there is No Fireplace so we replace it with None\ndf['FireplaceQu'] = df['FireplaceQu'].fillna('None')\nds['FireplaceQu'] = ds['FireplaceQu'].fillna('None')\n","02ef27a6":"# LotFrontage : Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood \n# so we can replace nan value in LotFrontage with the mean\ndf['LotFrontage'] = df['LotFrontage'].fillna(df_train['LotFrontage'].mean())\nds['LotFrontage'] = ds['LotFrontage'].fillna(df_train['LotFrontage'].mean())\n","27995a30":"# for GarageArea , GarageCars , GarageYrBlt :nan value mean that there is no Garage so i will replace it with 0\n\nfor i in ['GarageArea' , 'GarageCars' , 'GarageYrBlt']:\n    df[i] = df[i].fillna(0)\n    ds[i] = ds[i].fillna(0)\n\n","e11a08e3":"# for GarageType , GarageCond , GarageFinish , GarageQual: nan value mean that there is no garage so we replace it with None\nfor col in ['GarageType' , 'GarageCond' , 'GarageFinish' , 'GarageQual']:\n    df[col] = df[col].fillna(\"None\")\n    ds[col] = ds[col].fillna(\"None\")\n","ad7de597":"# for BsmtFinType2 , BsmtExposure , BsmtQual , BsmtFinType1 ,BsmtCond : nan value mean that there is no basement so we replace it with None\nfor col in ['BsmtFinType2' , 'BsmtExposure' , 'BsmtQual' , 'BsmtFinType1' ,'BsmtCond']:\n    df[col] = df[col].fillna(\"None\")\n    ds[col] = ds[col].fillna(\"None\")\n","e0c831e9":"for col in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']:\n    df[col] = df[col].fillna(0)\n    ds[col] = ds[col].fillna(0)    \n","a49b2d91":"# MasVnrArea , MasVnrType : NAn most likely means no masonry veneer for these houses. We can replace it with 0 for the area and None for the type.\ndf['MasVnrArea'] = df['MasVnrArea'].fillna(0)\ndf['MasVnrType'] = df['MasVnrType'].fillna('None')\nds['MasVnrArea'] = ds['MasVnrArea'].fillna(0)\nds['MasVnrType'] = ds['MasVnrType'].fillna('None')\n","44acc0f2":"# Electrical : It has one NAn value. Since this feature has mostly 'SBrkr', we can set that for the missing value.\ndf['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\nds['Electrical'] = ds['Electrical'].fillna(df['Electrical'].mode()[0])\n\n","b994f2ce":"#MSZoning (The general zoning classification) : 'RL' is by far the most common value. So we can fill in missing values with 'RL'\ndf['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])\nds['MSZoning'] = ds['MSZoning'].fillna(df['MSZoning'].mode()[0])\n\n","d5087905":"# Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.\ndf = df.drop(['Utilities'], axis=1)\nds = ds.drop(['Utilities'], axis=1)\n","8cb9b215":"# Functional : data description says NAn means typical\ndf[\"Functional\"] = df[\"Functional\"].fillna(\"Typ\")\nds[\"Functional\"] = ds[\"Functional\"].fillna(\"Typ\")\n","1a29e0c4":"# SaleType\ndf[\"SaleType\"] = df[\"SaleType\"].fillna(\"Oth\")\nds[\"SaleType\"] = ds[\"SaleType\"].fillna(\"Oth\")\n","28e789da":"# Exterior1st , Exterior2nd\n\ndf['Exterior1st'] = df['Exterior1st'].fillna('Other')\ndf['Exterior2nd'] = df['Exterior2nd'].fillna('Other')\n\nds['Exterior1st'] = ds['Exterior1st'].fillna('Other')\nds['Exterior2nd'] = ds['Exterior2nd'].fillna('Other')\n","1ea0fcc6":"# KitchenQual\n\ndf['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\nds['KitchenQual'] = ds['KitchenQual'].fillna(ds['KitchenQual'].mode()[0])\n","39fbb0b9":"# we can see now that there is no missing data\nprint(\"training set\")\nmissingDataPercentage(df)\nprint(\"\\n \\n\"+'-'*50)\nprint(\"testing set\")\nmissingDataPercentage(ds)","8c62d8de":"df","36664802":"# MSSubClass colum seems like categorical variable (values : {20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 160, 180, 190})\n# set(df_train['MSSubClass'].values)\ndf['MSSubClass'] = df['MSSubClass'].apply(str)\nds['MSSubClass'] = ds['MSSubClass'].apply(str)\n","24210ad2":"print(\"train data :\",df.shape)\nprint(\"test data :\",ds.shape)","7c6198e9":"#cocnatenate the train and test set \ndf_all = pd.concat([df,ds])","3167f5b0":"# list of categrical features \ncols = set(df_all.columns)\nnumcols = set(df_all._get_numeric_data().columns)\ncatcols = list(cols - numcols)\n","208fa100":"# categorical columns that have a order \nord_fields=['MSSubClass','ExterQual','LotShape','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1', 'BsmtFinType2','HeatingQC'\n            ,'Functional','FireplaceQu','KitchenQual', 'GarageFinish','GarageQual','GarageCond','PoolQC','Fence']\n\norders=[ \n        #msclass \n        ['20','30','40','45','50','60','70','75','80','85', '90','120','150','160','180','190'], \n        #ExterQual \n        ['Fa','TA','Gd','Ex'], \n        #LotShape \n        ['Reg','IR1' ,'IR2','IR3'], \n        #BsmtQual \n        ['None','Fa','TA','Gd','Ex'], \n        #BsmtCond \n        ['None','Po','Fa','TA','Gd','Ex'], \n        #BsmtExposure \n        ['None','No','Mn','Av','Gd'], \n        #BsmtFinType1 \n        ['None','Unf','LwQ', 'Rec','BLQ','ALQ' , 'GLQ' ], \n        #BsmtFinType2 \n        ['None','Unf','LwQ', 'Rec','BLQ','ALQ' , 'GLQ' ], \n        #HeatingQC \n        ['Po','Fa','TA','Gd','Ex'], \n        #Functional \n        ['Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'], \n        #FireplaceQu \n        ['None','Po','Fa','TA','Gd','Ex'], \n        #KitchenQual \n        ['Fa','TA','Gd','Ex'], \n        #GarageFinish\n        ['None','Unf','RFn','Fin'], \n        #GarageQual \n        ['None','Po','Fa','TA','Gd','Ex'], \n        #GarageCond \n        ['None','Po','Fa','TA','Gd','Ex'], \n        #PoolQC \n        ['None','Fa','Gd','Ex'], \n        #Fence \n        ['None','MnWw','GdWo','MnPrv','GdPrv'] ]\n\nfor i in range(len(orders)):\n    ord_en=OrdinalEncoder(categories = {0:orders[i]}) \n    df_all.loc[:,ord_fields[i]]=ord_en.fit_transform(df_all.loc[:,ord_fields[i]].values.reshape(-1,1))","b734bf76":"# imputing the rest of categorical var\ncols = set(df_all.columns)\nnumcols = set(df_all._get_numeric_data().columns)\ncatcols = list(cols - numcols)\ndf_all = pd.get_dummies(df_all,columns=catcols,drop_first=True)","1b9ac293":"# drop the id column\ndf_all.drop(['Id'],axis=1,inplace=True)","40aef9ad":"# recover training data and testing data\ndf_train = df_all[0:1460]\ndf_test = df_all[1460:]","df6226ba":"# drop the SalePrice from test data\ndf_test.drop(['SalePrice'],axis=1,inplace=True)\n","334d5692":"#splitting data\nfrom sklearn.model_selection import train_test_split , KFold , cross_val_score\n\nX = df_train.drop(['SalePrice'],axis=1)\ny = df_train['SalePrice']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)","1fe46b41":"import xgboost\nreg = xgboost.XGBRegressor()\nreg.fit(X, y)\n# reg.score(X_test, y_test)\n\nscores = cross_val_score(reg, X, y, cv=5)\nscores.mean()\n","9dbb251a":"#for submission \ndf_pred = pd.DataFrame(reg.predict(df_test))\ndf_sub = pd.read_csv(path_in+'sample_submission.csv')\ndata = pd.concat([df_sub['Id'],df_pred],axis=1)\ndata.columns=['Id','SalePrice']\ndata.to_csv('mysubmission.csv',index=False)\n","9737561d":"## 2) import train dataset","2ecaab1a":"## 3) handle missing data","3c3e6d94":"#### Percent missing data by feature","bdbd6a74":"## 1) import needed packages","bd0c7717":"#### testing dataset","2879ee7c":"### Imputing missing value and Feature engineering","5a31b80e":"#### Objective: Predict the SalePrice of houses using the dataset provided in Kaggle competition ","29662480":"#### training dataset","674efe7e":"## Modelling ","f3168ac0":"### Transforming some categorical variables to numerical","758eb4d7":" #### the correlation between numerical features and the target \"SalePrice\"","41a136fb":"we can see the higher correlation between sale price and \"*OverallQual ,GrLivArea..*\" , which is logical , better quality and bigger area = Higher price."}}