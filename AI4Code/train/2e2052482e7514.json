{"cell_type":{"25e0b592":"code","34fac441":"code","0dfdcf20":"code","5d31d7d2":"code","18ba51f5":"code","306ee608":"code","c5d80c88":"code","b3635ec9":"code","7c3790f0":"code","6afd55c5":"code","2fc94771":"code","d2c44e49":"code","bbfc788a":"code","7d8f93f6":"code","def7fcad":"code","d9f249be":"code","0c51ead1":"markdown","9f0cd3db":"markdown"},"source":{"25e0b592":"import numpy as np\nimport pandas as pd\nimport math\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Bidirectional\nfrom timeit import default_timer as timer ","34fac441":"data = pd.read_csv('..\/input\/my-moods\/daylio_export_2021_03_03.csv')\nmood_data = data[['full_date','mood','weekday']]\nmood_data = mood_data.set_index('full_date')\nmood_data.index = pd.to_datetime(mood_data.index,format='%d\/%m\/%Y')\nmood_data = mood_data.sort_index()\nmood_data","0dfdcf20":"replacements = {'mood':{'ok':2, 'good':3, 'bad':1, 'awful':0},\n                'weekday':{'Monday':0,'Tuesday':1,'Wednesday':2,'Thursday':3,'Friday':4,'Saturday':5,'Sunday':6}}\nmood_data = mood_data.replace(replacements)\nmood_data","5d31d7d2":"# convert an array of values into a dataset matrix\n\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset) - look_back - 1):\n        a = dataset[i:(i + look_back), :]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","18ba51f5":"# fix random seed for reproducibility\nnp.random.seed(0)\n\nmood_data = mood_data.values\n\n# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\n\n# split into train and test sets\ntrain_size = int(len(mood_data) * 0.67) \ntest_size = len(mood_data) - train_size\ntrain, test = mood_data[0:train_size, :], mood_data[train_size:len(mood_data), :]\n\ntrain = scaler.fit_transform(train)\ntest = scaler.transform(test)","306ee608":"# reshape into X=t and Y=t+1\nlook_back = 1\nX_train, y_train = create_dataset(train, look_back)  \nX_test, y_test = create_dataset(test, look_back)\n\n# reshape input to be  [samples, time steps, features]\nX_train = np.reshape(X_train, (X_train.shape[0], look_back, 2))\nX_test = np.reshape(X_test, (X_test.shape[0],look_back, 2))\n\n# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(100, input_shape=(look_back,2), return_sequences=True)) #the input shape needs to be a tuple of the look_back and the number_of_features\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='linear'))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory= model.fit(X_train, y_train,validation_split=0.33, epochs=50, batch_size=32)","c5d80c88":"graph_data = pd.DataFrame([np.array(history.history['loss']),np.array(history.history['val_loss'])])\ngraph_data = graph_data.T\ngraph_data.columns = ['Loss','Validation Loss']\nsns.lineplot(data=graph_data)","b3635ec9":"# make predictions\ny_pred = model.predict(X_test)\ny_pred_extended = np.zeros((len(y_pred),3))\ny_pred_extended[:,0] = y_pred.reshape(-1,1)[:,0]\n# May or may not need this inverse transform line, depending on whether X_test was scaled or not. If it was, we don't need it.\n# y_pred = scaler.inverse_transform(y_pred_extended)[:,0] \n\npred_data = pd.merge(pd.DataFrame(y_test),pd.DataFrame(y_pred),left_index=True, right_index=True)\npred_data.columns = ['Actual','Predicted by RNN']\nplt.figure(figsize=(18,6))\nsns.lineplot(data=pred_data,palette=\"Blues\")","7c3790f0":"sns.lineplot(data=pred_data[-20:-10],markers=True)","6afd55c5":"errors = {'MAE':metrics.mean_absolute_error(y_test,y_pred),\n          'RMSE':metrics.mean_squared_error(y_test,y_pred,squared=False)}\n\nerrors = pd.DataFrame(errors,index=['RNN'])\nerrors = np.round(errors,3)\nerrors","2fc94771":"scaler.inverse_transform(y_pred_extended[:,:2])","d2c44e49":"forecast = np.array([[0,0,0,0,0],[3,4,5,6,1]]).T #my forecast starts on a Thursday = 3\nforecast = scaler.transform(forecast)\nforecast","bbfc788a":"#TODO: Make forecast data. The first column (mood) will be added to iteratively, the second is weekday and won't change.","7d8f93f6":"print('The input shape is:',X_train.shape)","def7fcad":"# Not really sure what this is... ??\n\nprediction_list = np.array(mood_data[-28:])\n\nfor _ in range(6):\n    x = prediction_list[-28:]\n    x = x.reshape((28, 1, 2))\n    out = model.predict(x)[0][0]\n    prediction_list = np.append(prediction_list, out)\nprediction_list = prediction_list[28-1:]\n\nlast_date = mood_data.index.values[-1]\nprediction_dates = pd.date_range(last_date, periods=30+1).tolist()\nforecast = prediction_list\nforecast_dates = prediction_dates","d9f249be":"sns.lineplot(data=prediction_list)","0c51ead1":"Using this: https:\/\/stackoverflow.com\/questions\/42532386\/how-to-work-with-multiple-inputs-for-lstm-in-keras","9f0cd3db":"TODO:\n1. Try 7 day forecasting\n2. Try ARIMA\n3. Incorporate features into the RNN"}}