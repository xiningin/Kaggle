{"cell_type":{"203626e1":"code","d46b005c":"code","f9d7c0c5":"code","4a594603":"code","ae74a63b":"code","125d20ac":"code","2e07271c":"code","5bda9c57":"code","157c665a":"markdown","58ea680d":"markdown"},"source":{"203626e1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d46b005c":"!pip install rapidfuzz -qq","f9d7c0c5":"import matplotlib.pyplot as plt\nimport base64 \nfrom PIL import Image\nimport io\nfrom rapidfuzz import process, fuzz\nfrom tqdm import tqdm\nimport urllib","4a594603":"'''\nfor i in range(5):\n    filename = f'\/kaggle\/input\/wikipedia-image-caption\/train-0000{i}-of-00005.tsv'\n    df = pd.read_csv(filename, sep='\\t', usecols=['language'])\n    plt.figure(figsize=[20,3])\n    df[\"language\"].value_counts().plot(kind=\"bar\")\n'''","ae74a63b":"'''\ndf_test = pd.read_csv('\/kaggle\/input\/wikipedia-image-caption\/test.tsv', sep='\\t')\ndf_test['txt_from_url'] = df_test['image_url'].apply(lambda x: x.split('\/')[-1][:-4].replace('_', ' '))\ndf_captions = pd.read_csv('..\/input\/wikipedia-image-caption\/test_caption_list.csv')\ncaptions = df_captions['caption_title_and_reference_description'].tolist()\n\npreds_list = []\nfor ID, txt in tqdm(df_test[['id', 'txt_from_url']].values):\n    result = process.extract(txt, captions, scorer=fuzz.ratio, processor=None, limit=5)\n    for line in result:\n        preds_list.append([ID, line[0]])\n'''","125d20ac":"df_test = pd.read_csv('\/kaggle\/input\/wikipedia-image-caption\/test.tsv', sep='\\t')\ndf_test['txt_from_url'] = df_test['image_url'].apply(lambda x: urllib.parse.unquote(x).split('\/')[-1][:-4].replace('_', ' '))\ndf_captions = pd.read_csv('..\/input\/wikipedia-image-caption\/test_caption_list.csv')\ncaptions = df_captions['caption_title_and_reference_description'].tolist()","2e07271c":"preds_list = []\nfor ID, txt in tqdm(df_test[['id', 'txt_from_url']].values):\n    result = process.extract(txt, captions, scorer=fuzz.token_set_ratio, processor=None, limit=5)\n    for line in result:\n        preds_list.append([ID, line[0]])","5bda9c57":"sub = pd.DataFrame(preds_list, columns=['id', 'caption_title_and_reference_description'])\nsub.to_csv('submission.csv', index=None)","157c665a":"# Preditions only from image URLs\n- extract texts from the images urls\n- find captions that matche the extracted texts.\n\n## Updates (Sep 23)\n- use `urllib.parse.unquote` to decode percent-encoded sequences into Unicode characters\n- use `fuzz.token_set_ratio` as a scorer","58ea680d":"# Languages\nHistograms of languages in each train tsv file\n> \nTop 10 languages:\n1. en\n2. de\n3. fr\n4. en\n5. ru\n6. it\n7. nl\n8. pl\n9. ja\n10. uk"}}