{"cell_type":{"403a994e":"code","272d78dc":"code","672dec9b":"code","c2e967ad":"code","20bc9dd4":"code","de9125d4":"code","f487f304":"code","bfabb17c":"code","06b27222":"code","7f1ae977":"code","92bc1c2e":"code","99e906bf":"code","9f77edf6":"code","ddf7e4e1":"code","bcf348a1":"code","d74b4633":"code","41444ee7":"code","5959ffcd":"code","e1ff50c6":"code","803878ab":"code","74212d25":"code","3e329e7a":"code","09dca271":"code","b211260d":"code","3721908d":"code","c7eddd3f":"code","ff60b44c":"code","825c35b9":"code","1038cfc1":"code","47462ea0":"code","5459b028":"code","d736bd2d":"code","b7e2195a":"code","eb54cf95":"code","45eec066":"code","bff37076":"code","a14e5d85":"code","fc3244cc":"code","1bb7a8ce":"code","2fd22438":"code","82ead5e1":"code","83e79d63":"code","0325b894":"code","dda2f8e2":"code","941999de":"code","40ae4239":"code","99f285ab":"code","e62db195":"code","e218f41c":"code","e1e36832":"code","f33201a7":"code","5e5dd845":"code","267f485c":"code","c3b769a2":"code","10b36975":"code","d2e8c75a":"code","7c44aeff":"code","ef2ccb44":"code","4e9dc4e0":"code","873e96ae":"code","6baa18ae":"code","1faa0fcd":"code","c49bef5c":"code","dee9f2f1":"markdown","2d6ade65":"markdown","b47f5159":"markdown","03fc72d5":"markdown","ce146f75":"markdown","3c0c7bb4":"markdown","4409b8e5":"markdown","4f5df17d":"markdown","6c4abb99":"markdown","10a34298":"markdown","827129d5":"markdown","d61cf326":"markdown","cf20ee01":"markdown","2ec35243":"markdown","b4574d65":"markdown","3e83e3b1":"markdown","2e05d6af":"markdown","741c3248":"markdown","61c56e03":"markdown","a8c1b729":"markdown","f398abd4":"markdown","5fefe9d6":"markdown","0da1384f":"markdown","79ce58e0":"markdown","6f4891d4":"markdown","2006eef4":"markdown","2eed6016":"markdown","d760619f":"markdown","dd9e7581":"markdown","e78de7aa":"markdown","de741cab":"markdown"},"source":{"403a994e":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nimport plotly.express as px","272d78dc":"# Train\/test data Reading \n\ntrain_df = pd.read_csv(\"..\/input\/pubg-finish-placement-prediction\/train_V2.csv\")\n\ntest_df = pd.read_csv('..\/input\/pubg-finish-placement-prediction\/test_V2.csv')\n\nprint(train_df.shape,test_df.shape)","672dec9b":"# look at some of data points\ntrain_df.sample(10)","c2e967ad":"test_df.head(2)","20bc9dd4":"# data description\ntrain_df.describe()","de9125d4":"# data information\ntrain_df.info()","f487f304":"plt.figure(figsize=[25,12])\nsns.heatmap(train_df.corr(),annot = True,cmap = \"BuPu\");","bfabb17c":"id_cols = train_df.columns[:3]\n\nfor i in id_cols:\n  print(f\" {i} : {train_df[i].nunique()}\")","06b27222":"# taking a subset of data for plotting\nexp_df = train_df.sample(30_000)","7f1ae977":"fig = px.scatter(exp_df, x = \"assists\", y = \"kills\",color=\"winPlacePerc\",\n                 size=\"assists\",hover_name=\"Id\")\nfig.show()","92bc1c2e":"fig = px.scatter(exp_df, y = \"damageDealt\", x = \"heals\", log_y= False,\n                    color = \"kills\", hover_name = \"winPlacePerc\",\n                 size = \"damageDealt\"\n                   )\nfig.show()","99e906bf":"fig = px.scatter(exp_df, x = \"matchDuration\", y = \"walkDistance\",size = \"swimDistance\",\n                 color = \"revives\",width=1200, hover_name = \"winPoints\")\nfig.show()","9f77edf6":"fig = px.histogram(exp_df,x = \"winPlacePerc\",color = \"winPlacePerc\")\nfig.show()","ddf7e4e1":"# Dropping id columns for bot train\/test\n\ndata_train = train_df.drop(columns = id_cols)\ndata_test = test_df.drop(columns = id_cols)","bcf348a1":"data_train.columns","d74b4633":"data_train.isna().sum()","41444ee7":"data_test.isna().sum().any()","5959ffcd":"# filling one missing with mean\ndata_train[\"winPlacePerc\"] = data_train[\"winPlacePerc\"].fillna(np.mean(data_train.winPlacePerc))","e1ff50c6":"data_train.matchType.value_counts()","803878ab":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","74212d25":"data_train[\"matchType\"] = le.fit_transform(data_train[\"matchType\"])\ndata_test[\"matchType\"] = le.transform(data_test[\"matchType\"])","3e329e7a":"data = data_train.drop(\"winPlacePerc\",axis = 1)\ntarget = data_train[\"winPlacePerc\"]","09dca271":"from sklearn.preprocessing import StandardScaler\nsc  = StandardScaler()","b211260d":"data = sc.fit_transform(data)\ndata_test = sc.transform(data_test)","3721908d":"from sklearn.model_selection import train_test_split","c7eddd3f":"x_train,x_test, y_train,y_test = train_test_split(data,target, random_state = 1234, test_size = 0.2)\n\nprint(x_train.shape, x_test.shape)","ff60b44c":"from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRFRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport time\nimport pickle","825c35b9":"# define a pipeline to train a few models \npipeline = {\n      \"LinearRegression\" : make_pipeline(LinearRegression()),\n      \"RandomForestRegressor\" : make_pipeline(RandomForestRegressor()),\n      \"XGBRFRegressor\" : make_pipeline(XGBRFRegressor())\n}","1038cfc1":"# train the models on the trian data\n\nfitted_models = {}\n\nfor algo,pipeline in pipeline.items():\n  model = pipeline.fit(x_train[:50_000],y_train[:50_000])\n  fitted_models[algo] = model\n\n\nprint(\"Finished training..\")","47462ea0":"fitted_models","5459b028":"# train score\nfor model in fitted_models:\n  print(f\" Score for {model} is {fitted_models[model].score(x_train[:10_000],y_train[:10_000])}\")","d736bd2d":"# test score\nfor model in fitted_models:\n  print(f\" Score for {model} is {fitted_models[model].score(x_test[:10_000],y_test[:10_000])}\")","b7e2195a":"from sklearn.metrics import mean_absolute_error","eb54cf95":"pred_test = fitted_models[\"RandomForestRegressor\"].predict(x_test[:10_000])","45eec066":"print(f\"{mean_absolute_error(pred_test,y_test[:10_000]):.4f}\")","bff37076":"# subset of the large data for hyperparameter tuning\nx_train_small,x_test_small,y_train_small,y_test_small = x_train[:50_000],x_test[:30_000],y_train[:50_000],y_test[:30_000]","a14e5d85":"# function to tune an test the model\ndef train_and_eval(x_train,y_train,x_test,y_test, **params):\n    model = RandomForestRegressor(random_state=42, n_jobs = -1, **params)\n    model.fit(x_train,y_train)\n    train_mae = mean_absolute_error(model.predict(x_train),y_train)\n    test_mae = mean_absolute_error(model.predict(x_test),y_test)\n    return model,train_mae,test_mae","fc3244cc":"# test 1\nmodel,train_mae,test_mae = train_and_eval(x_train_small,y_train_small,x_test_small,y_test_small)\nprint(f\"Model : {model},\\n\\n train_mae : {train_mae:.4f}, test_mae : {test_mae:.4f}\\n\")","1bb7a8ce":"# test 2 \nmodel,train_mae,test_mae = train_and_eval(x_train_small,y_train_small,x_test_small,y_test_small, n_estimators = 30, max_depth = 10, min_samples_leaf = 3)\nprint(f\"Model : {model},\\n\\n train_mae : {train_mae:.4f}, test_mae : {test_mae:.4f}\\n\")","2fd22438":"# test 3\n\nmodel,train_mae,test_mae = train_and_eval(x_train_small,y_train_small,x_test_small,y_test_small, n_estimators = 50, max_depth = 5, min_samples_leaf = 3)\nprint(f\"Model : {model},\\n\\n train_mae : {train_mae:.4f}, test_mae : {test_mae:.4f}\\n\")","82ead5e1":"# test 3\n\nmodel,train_mae,test_mae = train_and_eval(x_train_small,y_train_small,x_test_small,y_test_small, n_estimators = 150, max_depth = 15, min_samples_leaf = 3)\nprint(f\"Model : {model},\\n\\n train_mae : {train_mae:.4f}, test_mae : {test_mae:.4f}\\n\")","83e79d63":"model = RandomForestRegressor(n_estimators = 110, max_depth = 13, min_samples_leaf = 3)","0325b894":"start = time.time()\nmodel.fit(x_train,y_train)\nend = time.time()","dda2f8e2":"print(f\"Finished training in {(end-start):.2f} seconds.\")","941999de":"# saving this model\n\nwith open(\"Model_RF.pkl\",\"wb\") as f:\n    pickle.dump(model,f)","40ae4239":"pred_train = model.predict(x_train)\nprint(mean_absolute_error(pred_train,y_train))","99f285ab":"pred_test = model.predict(x_test)\nprint(mean_absolute_error(pred_test,y_test))","e62db195":"from sklearn.tree import plot_tree, export_text","e218f41c":"model.estimators_[0]","e1e36832":"model.estimators_[109]","f33201a7":"plt.figure(figsize = [20,15])\nplot_tree(model.estimators_[0],max_depth = 2, feature_names=data_train.columns[:-1],filled = True,rounded = True);","5e5dd845":"plt.figure(figsize = [20,15])\nplot_tree(model.estimators_[109],max_depth = 2, feature_names=data_train.columns[:-1],filled = True,rounded = True);","267f485c":"importance_df = pd.DataFrame({\n    'feature': data_train.columns[:-1],\n    'importance': model.feature_importances_\n}).sort_values('importance', ascending=False)","c3b769a2":"importance_df[:10]","10b36975":"plt.title('Feature Importance')\nsns.barplot(data=importance_df.head(10), x='importance', y='feature');","d2e8c75a":"sample = pd.read_csv(\"..\/input\/pubg-finish-placement-prediction\/sample_submission_V2.csv\")","7c44aeff":"sample.shape","ef2ccb44":"pd.DataFrame(data_test)","4e9dc4e0":"predictions = model.predict(data_test)","873e96ae":"predictions[:10]","6baa18ae":"sample[\"winPlacePerc\"] = predictions","1faa0fcd":"sample","c49bef5c":"sample.to_csv(\"submission.csv\",index = False)","dee9f2f1":"> Probably should drop these later from both train\/test datasets.","2d6ade65":"## **3. Model**","b47f5159":"> Saving importances","03fc72d5":"> High kills  may be leading to early exit of the teams.\n","ce146f75":"- **Scaling numerical Features.**","3c0c7bb4":"> Train score","4409b8e5":"## **0. Data Reading and Description**","4f5df17d":"- **Assists v\/s KillPoints v\/s Kills v\/s WinPercentage**","6c4abb99":"### **Summary.**\n - Downlaoded a real world Datset\n - Prepare dataset\n - EDA\n - Data cleaning and splitting\n - Testing three models\n > Linear Regression,\n > Random Forest,\n > XG Boost\n\n - Performing hyperparamater tuning on Random Forest\n - Testing and making predictions\n\n Dataset from : https:\/\/www.kaggle.com\/c\/pubg-finish-placement-prediction","10a34298":"### Spitting into train\/test data","827129d5":"## **1. EDA**","d61cf326":"- **Mean Absolute error**","cf20ee01":"### Visualizations and weights","2ec35243":"- **DamageDealt v\/s Heals v\/s Kills v\/s winPlacePercentage.**","b4574d65":"- **Checking for null_values**","3e83e3b1":"# **PUBG Finish Placement Prediction**\n\n\n![\"Image\"](https:\/\/cdn.dnaindia.com\/sites\/default\/files\/styles\/full\/public\/2020\/10\/22\/933055-pubg-2.jpg)\n\n\n**Given over 65,000 games' worth of anonymized player data, split into training and testing sets, we have  to predict final placement from final in-game stats and initial player ratings.** \n","2e05d6af":"## **2. Data Pre-Processing**","741c3248":"- **Match Duration v\/s  Walk Distance v\/s Swim distance**","61c56e03":"### Libraries and Data information","a8c1b729":"> High kills leads to high healing but not particulary high win chances","f398abd4":"### I'll use Random Forest for further processes of hyperparameter tuning","5fefe9d6":"- **Encoding Categorical Data**","0da1384f":"- **Loooking at the dataset it seems to be a regression problem with ample amout of data, Moving forward I'll try to perform some EDA on the dataset, process the data and build a model suitable for best prediction.**","79ce58e0":"- **Correlation within the data**","6f4891d4":"### Make predictions on test data and submit\"","2006eef4":"### Making Predictions","2eed6016":"- **Nuber of unique values for ID's**","d760619f":"- **Splitting target and Data points**","dd9e7581":"- **Win Percentage Distribution**","e78de7aa":"### Train","de741cab":"> Test Score"}}