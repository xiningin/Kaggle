{"cell_type":{"5acc8101":"code","d67599e0":"code","2d30bfc3":"code","dacf9017":"code","db28a5db":"code","cdbc0ffb":"code","384c3805":"code","cd1df02d":"code","fa97ce70":"code","392df579":"code","1a71a025":"code","12db271e":"code","ef99fcf4":"code","f35f8344":"code","11fe5cd7":"code","7670d0a3":"code","8a86067c":"code","8b87509d":"code","a3802bca":"code","488e17aa":"code","b957c3c4":"code","6df9113a":"code","709ffc79":"code","97090e6e":"code","580a5504":"code","b76103e8":"code","d221540f":"code","d010988a":"code","8bd5db24":"code","5f1b0888":"code","ad5590c7":"code","972379f2":"code","c0d74024":"code","4b513d9b":"code","6bd7bfb2":"code","0e7fe3c5":"code","08fbd770":"code","77c57c53":"code","2b893f57":"code","030a9a24":"code","20fc864e":"code","48308567":"code","73ae4dd4":"code","cbd34f55":"code","eef63312":"markdown","77c98df9":"markdown","3a1e9b8f":"markdown"},"source":{"5acc8101":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d67599e0":"df_train = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/train.csv\")","2d30bfc3":"df_train.info()","dacf9017":"df_test = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/test.csv\")","db28a5db":"df_train.describe()","cdbc0ffb":"sns.distplot(df_train['revenue'])","384c3805":"df_train['City'].value_counts()","cd1df02d":"df_train['City Group'].value_counts()","fa97ce70":"df_test['City Group'].value_counts()","392df579":"df_train['Type'].value_counts()","1a71a025":"df_test['Type'].value_counts()","12db271e":"sns.catplot(x=\"Type\", y=\"revenue\", kind=\"swarm\", data=df_train);","ef99fcf4":"sns.catplot(x=\"City Group\", y=\"revenue\", kind=\"swarm\", data=df_train);","f35f8344":"df_train['Open Date'].value_counts()","11fe5cd7":"plt.figure(figsize=(20,20))\nsns.heatmap(df_train.corr())","7670d0a3":"sns.scatterplot(x=\"revenue\", y=\"P2\", hue=\"Type\", data=df_train)","8a86067c":"Y_train = df_train['revenue']","8b87509d":"Y_train.head()","a3802bca":"df_feat = df_train.drop(['revenue'], axis=1)\ndf_feat = df_feat.drop(['Id'], axis=1)\ndf_feat = df_feat.drop(['Open Date'], axis=1)\ndf_feat = df_feat.drop(['City'], axis=1)\ndf_feat = df_feat.drop(['Type'], axis=1)","488e17aa":"df_feat.head()","b957c3c4":"df_test = df_test.drop(['Id'], axis=1)\ndf_test = df_test.drop(['Open Date'], axis=1)\ndf_test = df_test.drop(['City'], axis=1)\ndf_test = df_test.drop(['Type'], axis=1)","6df9113a":"df_test.head()","709ffc79":"total = df_feat.isnull().sum().sort_values(ascending=False)\npercent = (df_feat.isnull().sum()\/df_feat.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","97090e6e":"df_feat.columns","580a5504":"\n\ndf_pcols = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15',\n       'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35',\n       'P36', 'P37']\nfor i, column in enumerate(df_pcols):\n    plt.figure()\n    sns.distplot(df_feat[column])","b76103e8":"from sklearn.preprocessing import StandardScaler","d221540f":"df_feat = pd.get_dummies(df_feat, prefix=['CityGroup'])","d010988a":"df_test = pd.get_dummies(df_test, prefix=['CityGroup'])","8bd5db24":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaled_features_train = scaler.fit_transform(df_feat)","5f1b0888":"scaled_features_test = scaler.fit_transform(df_test)","ad5590c7":"scaled_features_df_feat = pd.DataFrame(scaled_features_train, index=df_feat.index, columns=df_feat.columns)","972379f2":"scaled_features_df_test = pd.DataFrame(scaled_features_test, index=df_test.index, columns=df_test.columns)","c0d74024":"scaled_features_df_feat.head()","4b513d9b":"scaled_features_df_test.head()","6bd7bfb2":"from sklearn.ensemble import RandomForestRegressor","0e7fe3c5":"regr = RandomForestRegressor(n_estimators=20)\nregr.fit(scaled_features_df_feat,Y_train)","08fbd770":"predictions = regr.predict(scaled_features_df_test)","77c57c53":"from sklearn.linear_model import Lasso","2b893f57":"regr2 = Lasso(alpha=0.1)\nregr2.fit(scaled_features_df_feat,Y_train)","030a9a24":"predictions2 = regr2.predict(scaled_features_df_test)","20fc864e":"df_test1 = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/test.csv\")\nsub = pd.DataFrame()\nsub['Id'] = df_test1['Id']\nsub['Prediction'] = predictions\nsub.to_csv('submission.csv',index=False)","48308567":"df_test1 = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/test.csv\")\nsub = pd.DataFrame()\nsub['Id'] = df_test1['Id']\nsub['Prediction'] = predictions2\nsub.to_csv('submission2.csv',index=False)","73ae4dd4":"from IPython.display import FileLink\nFileLink(r'submission.csv')","cbd34f55":"from IPython.display import FileLink\nFileLink(r'submission.csv')","eef63312":"No missing data. Awesome !!","77c98df9":"From the above data, we see that there is no MB type restaurant in the training set. Let us plot revenue and type","3a1e9b8f":"I think we can remove this column as it does not provide much importance to revenue"}}