{"cell_type":{"f9d26063":"code","10ef46b3":"code","547f0f6b":"code","19de5a6d":"code","a00df857":"code","781ffdbd":"code","331f9f59":"code","4c50bade":"code","7de409b2":"code","babe1141":"code","4f169223":"code","9bbf2d08":"code","1e27eaa7":"code","4b3d9bd1":"code","49881366":"code","9972bbf3":"code","412dd158":"code","71d79854":"code","b8be432e":"code","6e813866":"code","0b01cd45":"code","d65d7584":"code","7e24ad95":"code","bd78b07e":"code","c6659523":"code","b97dc8a3":"code","2800dc08":"code","ec11e20d":"code","3b0773c4":"code","b5668954":"code","f2fc900c":"code","cae99ef9":"code","9196a0f1":"code","0d1871a4":"code","3b51389a":"code","9bde4eff":"code","af3a3beb":"code","2513c163":"code","00bf518b":"code","0ec212c6":"code","e3d4d364":"code","25e0a466":"code","5cb82809":"code","216fed9d":"code","bee9a441":"code","e9737595":"code","d8981789":"code","8c693abd":"code","366fe629":"code","d35e6fee":"code","b3c59b41":"code","193e443a":"code","91ac2d54":"code","037e9cec":"code","c24eeee1":"code","3c474d45":"code","98ceb663":"code","8af8cb78":"code","97dca752":"code","0f1d3581":"code","974f6ebf":"code","6e37cee6":"code","307ab45e":"code","d8a9dd6f":"code","bfdd5e75":"code","e67006f1":"code","4463d9a6":"code","05a56c67":"code","6f7bdf41":"code","ddb3cc4e":"code","d7a520ad":"code","200f3337":"code","97a66ea7":"code","0ee1f84c":"code","bb095880":"code","b534c1e9":"code","468df0b7":"code","62ccbb52":"code","7703b060":"code","74530ab4":"code","8e49b3f7":"code","a4d47ee2":"code","ec4461ab":"code","04815ec7":"code","242fcdc5":"code","d498a9f9":"code","0fd283a1":"code","790f9fff":"code","41565021":"code","be58a3d8":"markdown","ea1cfe5e":"markdown","a4c7a722":"markdown","6ea7244f":"markdown","a5761e70":"markdown","23828d43":"markdown","1b9b1724":"markdown","07cde7e3":"markdown","47762e15":"markdown","7629bbf6":"markdown","cced9e83":"markdown","750cfc90":"markdown","2cf40814":"markdown","8d9fa3a7":"markdown","94ce87c4":"markdown","7198979e":"markdown","5ec3e5b3":"markdown","051cccb7":"markdown","e4110fb0":"markdown","1af9fe26":"markdown","ad48621f":"markdown","da440d25":"markdown","cf7a7d91":"markdown","bd380eda":"markdown","37154501":"markdown","1d2b4e5f":"markdown","623611c5":"markdown","4734060e":"markdown","941e9e77":"markdown","ef78b562":"markdown","94cec4b2":"markdown","483accde":"markdown","04487622":"markdown","3e56203d":"markdown","e335e549":"markdown","3c1f9540":"markdown","d0468070":"markdown","2b90affa":"markdown","d1b75b5f":"markdown","ef570122":"markdown","47b2983c":"markdown","eb137e2d":"markdown"},"source":{"f9d26063":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nimport time\n\nimport cv2\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten\nfrom keras.optimizers import SGD, Adam, RMSprop\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","10ef46b3":"def load_and_process_data(directory):\n    # create lists to store images and labels\n    images = []\n    labels = []\n    # Iterate through the main folder\n    for root, dirs, files in os.walk(directory):\n        # Access the name of the inner folder example: paper_boat folder\n        f = os.path.basename(root)\n        for file in files:\n            # load the images\n            try:\n                #read the image\n                img = cv2.imread(root+'\/'+file)\n                #resize all images to the same dimention\n                img = cv2.resize(img, (300,300))\n                #convert image color to gray\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                #blur the image to remove noise\n                img = cv2.GaussianBlur(img, (5,5), 0)\n                #append all the images into the images list\n                images.append(img)\n                # Append the name of the inner folder\n                labels.append(f)\n                \n            # otherwise raise error \n            except Exception:\n                print('Error could not load all images')\n    \n    #convert images to an array\n    images = np.array(images)\n    #return images and labels\n    return (images, labels)","547f0f6b":"train_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\"\nvalidation_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\"\n\ntrain_images, train_labels = load_and_process_data(train_path)\nvalid_images, valid_labels = load_and_process_data(validation_path)","19de5a6d":"fig,ax=plt.subplots(5,5)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range(5):\n        num=np.random.randint(0,len(train_labels))\n        ax[i,j].imshow(train_images[num])\n        ax[i,j].set_title([train_labels[num]], size =15)\nplt.tight_layout()","a00df857":"# processing labels\n\ndef preprocess_labels(labels):\n    le = LabelEncoder()\n    \n    labels = le.fit_transform(labels)\n    labels = to_categorical(labels)\n    labels = np.array(labels)\n    labels = [int(i[0])for i in labels]\n    return labels","781ffdbd":"train_labels_lst = preprocess_labels(train_labels)\nvalid_labels_lst = preprocess_labels(valid_labels)","331f9f59":"# Train Test Split\n\ntrain_images, test_images, train_labels_lst, test_labels_lst = train_test_split(train_images, train_labels_lst, \n                                                                        test_size=0.25, random_state=20)","4c50bade":"# Normalize Images\n\ntrain_images = train_images \/ 255.0\ntest_images = test_images \/ 255.0\nvalid_images = valid_images \/ 255.0","7de409b2":"train_images.shape, test_images.shape, valid_images.shape","babe1141":"batch_size = 32\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(\n                                                           rotation_range=25,\n                                                           zoom_range=0.1,\n                                                           width_shift_range=0.1,\n                                                           height_shift_range=0.1,\n                                                           shear_range=0.2,\n                                                           horizontal_flip=True)\n\ntest_datagen = keras.preprocessing.image.ImageDataGenerator()\n\nval_datagen = keras.preprocessing.image.ImageDataGenerator()","4f169223":"train_gen = train_datagen.flow(train_images, train_labels_lst, batch_size=batch_size)\ntest_gen = test_datagen.flow(test_images, test_labels_lst, batch_size=batch_size)\nvalid_gen = val_datagen.flow(valid_images, valid_labels_lst, batch_size=batch_size,  shuffle=False)","9bbf2d08":"custom_model = keras.models.Sequential()\ncustom_model.add(Conv2D(64, (3,3), activation='relu', input_shape=(300,300,3)))\ncustom_model.add(MaxPooling2D(3,3))\n\ncustom_model.add(Conv2D(128, (3,3), activation='relu'))\ncustom_model.add(MaxPooling2D(2,2))\n\ncustom_model.add(Conv2D(128, (3,3), activation='relu'))\ncustom_model.add(MaxPooling2D(2,2))\n\ncustom_model.add(Conv2D(256, (3,3), activation='relu'))\ncustom_model.add(MaxPooling2D(2,2))\n\ncustom_model.add(Conv2D(256, (3,3), activation='relu'))\ncustom_model.add(MaxPooling2D(2,2))\n\ncustom_model.add(Flatten())\ncustom_model.add(BatchNormalization())\ncustom_model.add(Dense(96, activation='relu'))\ncustom_model.add(Dropout(0.45))\ncustom_model.add(Dense(32, activation='relu'))\ncustom_model.add(Dense(1, activation='sigmoid'))","1e27eaa7":"custom_model.summary()","4b3d9bd1":"# Compile Model\n\ncustom_model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])","49881366":"t1 = time.time()\nhistory = custom_model.fit_generator(train_gen, epochs=30, validation_data=test_gen)\nt2 = time.time()","9972bbf3":"print('Time to train model:',round((t2-t1)\/60, 2), 'minuts')","412dd158":"# plot model loss\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","71d79854":"# Plot model accuracy \nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","b8be432e":"# Train data evaluation\ntrain_score = custom_model.evaluate_generator(train_gen)\n\n# Test data evaluation\ntest_score = custom_model.evaluate_generator(test_gen)\n\n# Validation data evaluation\nvalid_score = custom_model.evaluate_generator(valid_gen)","6e813866":"print(\"Train_Accuracy = \", train_score[1])\nprint(\"Test_Accuracy = \", test_score[1])\nprint(\"Validation_Accuracy = \", valid_score[1])","0b01cd45":"# prediction \npred = custom_model.predict_generator(valid_gen)\npredicted_vals = [round(i[0]) for i in pred]","d65d7584":"# Confusion Matrix\n\nconfusion_matrix(valid_labels_lst, predicted_vals)","7e24ad95":"from tensorflow.keras.applications.vgg16 import VGG16\n\nbase_model = VGG16(input_shape = (300, 300, 3), # Shape of our images\ninclude_top = False, # Leave out the last fully connected layer\nweights = 'imagenet')","bd78b07e":"for layer in base_model.layers:\n    layer.trainable = False","c6659523":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\nx = layers.BatchNormalization()(x)\n\nx = layers.Dense(32, activation='relu')(x)\n\nx = layers.Dense(1, activation='sigmoid')(x)\n\nvgg_model = tf.keras.models.Model(base_model.input, x)","b97dc8a3":"vgg_model.summary()","2800dc08":"# Compile Model\n\nvgg_model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n","ec11e20d":"t1 = time.time()\nhistory = vgg_model.fit_generator(train_gen, epochs=10, validation_data=test_gen)\nt2 = time.time()","3b0773c4":"print('Time to train model:',round((t2-t1)\/60, 2), 'minuts')","b5668954":"# plot model loss\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","f2fc900c":"# Plot model accuracy \nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","cae99ef9":"# Train data evaluation\ntrain_score = vgg_model.evaluate_generator(train_gen)\n\n# Test data evaluation\ntest_score = vgg_model.evaluate_generator(test_gen)\n\n# Validation data evaluation\nvalid_score = vgg_model.evaluate_generator(valid_gen)","9196a0f1":"print(\"Train_Accuracy = \", train_score[1])\nprint(\"Test_Accuracy = \", test_score[1])\nprint(\"Validation_Accuracy = \", valid_score[1])","0d1871a4":"# prediction \npred = vgg_model.predict_generator(valid_gen)\npredicted_vals = [round(i[0]) for i in pred]","3b51389a":"# Confusion Matrix\n\ncm = confusion_matrix(valid_labels_lst, predicted_vals)\ncm","9bde4eff":"\nfrom tensorflow.keras.applications import ResNet50\n\nbase_model = ResNet50(input_shape=(300, 300 ,3), include_top=False, weights=\"imagenet\")","af3a3beb":"for layer in base_model.layers:\n    layer.trainable = False","2513c163":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\nx = layers.BatchNormalization()(x)\n\nx = layers.Dense(32, activation='relu')(x)\n#x = layers.Dense(16, activation='relu')(x)\n\nx = layers.Dense(1, activation='sigmoid')(x)\n\nres_net_model = tf.keras.models.Model(base_model.input, x)","00bf518b":"res_net_model.summary()","0ec212c6":"# Compile Model\n\nres_net_model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n\n","e3d4d364":"t1 = time.time()\nhistory = res_net_model.fit_generator(train_gen, epochs=50, validation_data=test_gen)\nt2 = time.time()","25e0a466":"print('Time to train model:',round((t2-t1)\/60, 2), 'minuts')","5cb82809":"# plot model loss\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","216fed9d":"# Plot model accuracy \nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","bee9a441":"# Train data evaluation\ntrain_score = res_net_model.evaluate_generator(train_gen)\n\n# Test data evaluation\ntest_score = res_net_model.evaluate_generator(test_gen)\n\n# Validation data evaluation\nvalid_score = res_net_model.evaluate_generator(valid_gen)","e9737595":"print(\"Train_Accuracy = \", train_score[1])\nprint(\"Test_Accuracy = \", test_score[1])\nprint(\"Validation_Accuracy = \", valid_score[1])","d8981789":"# prediction \npred = res_net_model.predict_generator(valid_gen)\npredicted_vals = [round(i[0]) for i in pred]","8c693abd":"# Confusion Matrix\n\ncm = confusion_matrix(valid_labels_lst, predicted_vals)\ncm","366fe629":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nbase_model = InceptionV3(input_shape = (300, 300, 3), include_top = False, weights = 'imagenet')","d35e6fee":"for layer in base_model.layers:\n    layer.trainable = False","b3c59b41":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\nx = layers.BatchNormalization()(x)\n\nx = layers.Dense(32, activation='relu')(x)\n\nx = layers.Dense(1, activation='sigmoid')(x)\n\ninception_model = tf.keras.models.Model(base_model.input, x)","193e443a":"inception_model.summary()","91ac2d54":"# compile model\n\ninception_model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n\n","037e9cec":"t1 = time.time()\nhistory = inception_model.fit_generator(train_gen, epochs=10, validation_data=test_gen)\nt2 = time.time()","c24eeee1":"print('Time to train model:',round((t2-t1)\/60, 2), 'minuts')","3c474d45":"# plot model loss\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","98ceb663":"# Plot model accuracy \nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","8af8cb78":"# Train data evaluation\ntrain_score = inception_model.evaluate_generator(train_gen)\n\n# Test data evaluation\ntest_score = inception_model.evaluate_generator(test_gen)\n\n# Validation data evaluation\nvalid_score = inception_model.evaluate_generator(valid_gen)","97dca752":"print(\"Train_Accuracy = \", train_score[1])\nprint(\"Test_Accuracy = \", test_score[1])\nprint(\"Validation_Accuracy = \", valid_score[1])","0f1d3581":"# prediction \npred = inception_model.predict_generator(valid_gen)\npredicted_vals = [round(i[0]) for i in pred]","974f6ebf":"# Confusion Matrix\n\ncm = confusion_matrix(valid_labels_lst, predicted_vals)\ncm","6e37cee6":"!pip install -U efficientnet","307ab45e":"import efficientnet.keras as efn\n\nbase_model = efn.EfficientNetB0(input_shape = (300, 300, 3), include_top = False, weights = 'imagenet')","d8a9dd6f":"for layer in base_model.layers:\n    layer.trainable = False","bfdd5e75":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\nx = layers.BatchNormalization()(x)\n\nx = layers.Dense(32, activation='relu')(x)\n\nx = layers.Dense(1, activation='sigmoid')(x)\n\nefficientnet = tf.keras.models.Model(base_model.input, x)","e67006f1":"efficientnet.summary()","4463d9a6":"# Compile Model\n\nefficientnet.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n\n","05a56c67":"t1 = time.time()\nhistory = efficientnet.fit_generator(train_gen, epochs=10, validation_data=test_gen)\nt2 = time.time()\n\n","6f7bdf41":"print('Time to train model:',round((t2-t1)\/60, 2), 'minuts')","ddb3cc4e":"# plot model loss\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","d7a520ad":"# Plot model accuracy \nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","200f3337":"# Train data evaluation\ntrain_score = efficientnet.evaluate_generator(train_gen)\n\n# Test data evaluation\ntest_score = efficientnet.evaluate_generator(test_gen)\n\n# Validation data evaluation\nvalid_score = efficientnet.evaluate_generator(valid_gen)","97a66ea7":"print(\"Train_Accuracy = \", train_score[1])\nprint(\"Test_Accuracy = \", test_score[1])\nprint(\"Validation_Accuracy = \", valid_score[1])","0ee1f84c":"# prediction \npred = efficientnet.predict_generator(valid_gen)\npredicted_vals = [round(i[0]) for i in pred]","bb095880":"# Confusion Matrix\n\ncm = confusion_matrix(valid_labels_lst, predicted_vals)\ncm","b534c1e9":"#!pip install -U efficientnet\n","468df0b7":"\nimport efficientnet.keras as efn\n\nbase_model = efn.EfficientNetB7(input_shape = (300, 300, 3), include_top = False, weights = 'imagenet')","62ccbb52":"for layer in base_model.layers:\n    layer.trainable = False","7703b060":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\nx = layers.BatchNormalization()(x)\nx = layers.Dense(1, activation='sigmoid')(x)\n\nefficientnet_b7 = tf.keras.models.Model(base_model.input, x)","74530ab4":"efficientnet_b7.summary()","8e49b3f7":"# Compile Model\n\nefficientnet_b7.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n","a4d47ee2":"t1 = time.time()\nhistory = efficientnet_b7.fit_generator(train_gen, epochs=10, validation_data=test_gen)\nt2 = time.time()","ec4461ab":"print('Time to train model:',round((t2-t1)\/60, 2), 'minuts')","04815ec7":"# plot model loss\nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","242fcdc5":"# Plot model accuracy \nsns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","d498a9f9":"# Train data evaluation\ntrain_score = efficientnet_b7.evaluate_generator(train_gen)\n\n# Test data evaluation\ntest_score = efficientnet_b7.evaluate_generator(test_gen)\n\n# Validation data evaluation\nvalid_score = efficientnet_b7.evaluate_generator(valid_gen)","0fd283a1":"print(\"Train_Accuracy = \", train_score[1])\nprint(\"Test_Accuracy = \", test_score[1])\nprint(\"Validation_Accuracy = \", valid_score[1])","790f9fff":"# prediction \npred = efficientnet_b7.predict_generator(valid_gen)\npredicted_vals = [round(i[0]) for i in pred]","41565021":"# Confusion Matrix\n\ncm = confusion_matrix(valid_labels_lst, predicted_vals)\ncm","be58a3d8":"# V3 -> Transfer Learning -> Inception","ea1cfe5e":"## Get Pre-trained model and build model","a4c7a722":"## Test Model","6ea7244f":"## Prediction","a5761e70":"## Prediction","23828d43":"## Get the Pre-trained model and build the model","1b9b1724":"## Test Model","07cde7e3":"## Get Pre-trained Model and Build the model","47762e15":"## Results - Accuracy:\n1. Custom CNN Network:\n - Train: 99.6%\n - Test: 100%\n - Validation: 84%\n2. VGG16:\n - Train: 100%\n - Test: 100%\n - Validation: 94%\n3. ResNet50:\n - Train: 99%\n - Test: 100%\n - Validation: 72%\n4. Inception:\n - Train: 100%\n - Test: 100%\n - Validation: 99.2%\n5. ExceptionNet B0:\n - Train: 100%\n - Test: 100%\n - Validation: 95%\n6. ExceptionNet B7:\n - Train: 100%\n - Test: 100%\n - Validation: 100%","7629bbf6":"# V4 -> Transfer Learning -> EfficientNet B0","cced9e83":"# Results and Conclusion","750cfc90":"## Prediction","2cf40814":"## Prediction","8d9fa3a7":"## Train Model","94ce87c4":"# V1 -> Transfer Learning -> VGG16","7198979e":"## Test Model","5ec3e5b3":"## Data visualiation","051cccb7":"## Test Model","e4110fb0":"## Test the Model","1af9fe26":"## Conclusion:\n- Used Train Set to split into train-test for training purpose and used validation set to compare the models\n- Overall, it can be concluded that pre-trained state-of-the-art performs better than custom model.\n- Couln't achive impressive results using ResNet50, which is surprising. (I might need to play with ResNet50 further)\n- ExceptionNet B7 shows exceptional results -> 100% accuracy for train, test and validation data.\n- Inception model works almost similar as well.","ad48621f":"## Test Model","da440d25":"## Load Data","cf7a7d91":"# Content\n1. Importing and Data Preparation\n2. V0 -> Custom CNN\n3. Transfer Learning\n4. V1 -> Transfer Learning -> VGG16\n5. V2 -> Transfer Learning -> ResNet50\n6. V3 -> Transfer Learning -> Inception\n7. V4 -> Transfer Learning -> EfficientNet B0\n8. V5 -> Transfer Learning -> EfficientNet B7\n9. Results and Conclusion\n\nNotes:\n- Running with GPU\n- It takes hours to run with CPU","bd380eda":"## Prediction","37154501":"## Prepare Data","1d2b4e5f":"## Model Training","623611c5":"![](https:\/\/images3.programmersought.com\/663\/14\/1415bedf2ee561a6bdab7b1d295ae7a7.png)","4734060e":"## Data Engineering","941e9e77":"## Train Model","ef78b562":"## Import Libraries","94cec4b2":"## Prediction","483accde":"## Get the Pre-trained Model and build the model","04487622":"# Transfer Learning\n\n- The rapid developments in Computer Vision, and by extension \u2013 image classification has been further accelerated by the advent of Transfer Learning. To put it simply, Transfer learning allows us to use a pre-existing model, trained on a huge dataset, for our own tasks. Consequently reducing the cost of training new deep learning models and since the datasets have been vetted, we can be assured of the quality.\n\n- As you can see, even the baseline B0 model starts at a much higher accuracy, which only goes on increasing, and that too with fewer parameters. For instance, EfficientB0 has only 5.3 million parameters!\n- I will cover the top 4 pre-trained models for Image Classification that are state-of-the-art (SOTA) and are widely used in the industry as well. \n    1. VGG16\n    2. ResNet50\n    3. Inception\n    4. EfficientNet\n- I have twicked their hyperparameters individually as needed","3e56203d":"# V2 -> Transfer Learning -> ResNet50","e335e549":"## Train Model","3c1f9540":"## Train Model","d0468070":"# V0 -> Custom CNN","2b90affa":"## Train the Model","d1b75b5f":"# Importing and Data Preparation","ef570122":"## Get the pre-trained Model and build the model","47b2983c":"## Model Building","eb137e2d":"# V5 -> Transfer Learning -> EfficientNet B7"}}