{"cell_type":{"e3cef840":"code","e4838092":"code","27e7af1f":"code","798b7efa":"code","751b2e74":"code","03f98f67":"code","3882530b":"code","c431acaf":"code","3482350a":"code","cbe2f08a":"code","4d0cae26":"code","a8ada499":"code","d04189f4":"code","76552b1c":"code","235f52d6":"code","1fefd60d":"code","46a7bad1":"code","becb62b1":"code","b50c849e":"code","bdd14d96":"code","42f14374":"code","1290e168":"markdown","87711392":"markdown","9a5185a7":"markdown","2218cb16":"markdown","5ba5a5c9":"markdown"},"source":{"e3cef840":"import cv2\nimport csv\nimport numpy as np\nimport pandas as pd\nimport numpy as np\nimport os","e4838092":"dataframe = pd.read_csv('\/kaggle\/input\/histopathologic-cancer-detection\/train_labels.csv')\ndataframe.head()","27e7af1f":"dataframe.info()","798b7efa":"dataframe.sort_values(by='id', inplace = True)\ndataframe.head()","751b2e74":"dataset_train_labels = pd.read_csv('..\/input\/histopathologic-cancer-detection\/train_labels.csv')\ndataset_train_labels.sort_values(by='id', inplace = True)\n\ndataset_train_labels.head()","03f98f67":"#Cantidad de im\u00e1genes en el set de datos, sin patolog\u00edas (0) y patol\u00f3gicas (1):\ndataframe['label'].value_counts()","3882530b":"#Im\u00e1genes para entrenamiento\nprint('Cantidad de im\u00e1genes para el entrenamiento:')\nprint(len(os.listdir('..\/input\/histopathologic-cancer-detection\/train')))\n\n#Im\u00e1genes para testeo\nprint('Cantidad de im\u00e1genes para testeo:')\nprint(len(os.listdir('..\/input\/histopathologic-cancer-detection\/test')))","c431acaf":"# Histograma de la cantidad de im\u00e1genes por clase.\nimport matplotlib.pyplot as plt\n\nclases = pd.read_csv('..\/input\/histopathologic-cancer-detection\/train_labels.csv', index_col=0)\nplt.xlabel(\"No patol\u00f3gicas - Patol\u00f3gicas.\")\nplt.ylabel(\"Cantidad de im\u00e1genes\")\nplt.hist(clases['label'], 3, color=\"blue\", ec='black')","3482350a":"# source: https:\/\/www.kaggle.com\/gpreda\/honey-bee-subspecies-classification\n\ndef draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n    \n    \"\"\"\n    Give a column in a dataframe,\n    this function takes a sample of each class and displays that\n    sample on one row. The sample size is the same as figure_cols which\n    is the number of columns in the figure.\n    Because this function takes a random sample, each time the function is run it\n    displays different images.\n    \"\"\"\n    \n\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n            im=cv2.imread(file)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=16)  \n    plt.tight_layout()\n    plt.show()\nIMAGE_PATH = ('..\/input\/histopathologic-cancer-detection\/train\/')\n\ndraw_category_images('label',4, dataframe, IMAGE_PATH)","cbe2f08a":"from __future__ import absolute_import, division, print_function, unicode_literals\ntry:\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\n\n# TensorFlow y tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.__version__)","4d0cae26":"files = os.listdir('..\/input\/histopathologic-cancer-detection\/train\/')\nfiles.sort()\n\ndataset_train = []\n\nfor i in os.listdir('..\/input\/histopathologic-cancer-detection\/train\/')[0:1000]:\n    dataset_train.append(cv2.imread('..\/input\/histopathologic-cancer-detection\/train\/'+i, cv2.IMREAD_GRAYSCALE)\/256.)\n\ndataset_train = np.array(dataset_train)\nprint(dataset_train.shape)","a8ada499":"dataset_train_labels = pd.read_csv('..\/input\/histopathologic-cancer-detection\/train_labels.csv')[0:1000]\ndataset_train_labels.sort_values(by='id', inplace = True)\n\ndataset_train_labels = np.array(dataset_train_labels)\n\nprint(dataset_train_labels.shape)","d04189f4":"# Divisi\u00f3n del set de entrenamiento:\nimg_train = []\nimg_test = []\n\nlong = (0.9*len(dataset_train))\n\nfor i in range(len(dataset_train)):\n  if i < long:\n    img_train.append((dataset_train[i]))\n  else:\n    img_test.append(dataset_train[i])\n\nimg_train = np.array(img_train).astype('float32')\nimg_test = np.array(img_test).astype('float32')\n    \nprint(img_train.shape)\nprint(img_test.shape)","76552b1c":"# Divisi\u00f3n de las etiquetas: \ntrain_labels = []\ntest_labels = []\n\nlong1 = (0.9*len(dataset_train_labels))\n\nfor i in range(len(dataset_train_labels)):\n  if i < long1:\n    train_labels.append(dataset_train_labels[i][1])\n  else:\n    test_labels.append(dataset_train_labels[i][1])\n        \ntrain_labels = np.array(train_labels).astype('float32')\ntest_labels = np.array(test_labels).astype('float32')\n\nprint(train_labels.shape)\nprint(test_labels.shape)","235f52d6":"model = keras.Sequential()\n\nmodel.add(keras.layers.Conv2D(filters=64, padding='valid', kernel_size=(3, 3), activation='relu', input_shape=(96,96,1)))\nmodel.add(keras.layers.MaxPooling2D(2, 2))\n\nmodel.summary()","1fefd60d":"model.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(120, activation='relu'))\nmodel.add(keras.layers.Dense(84, activation='relu'))\nmodel.add(keras.layers.Dense(10, activation = 'sigmoid'))","46a7bad1":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","becb62b1":"# Entrenamiento del modelo\nmodel.fit(img_train, train_labels, epochs = 20)","b50c849e":"test_loss, test_acc = model.evaluate(img_test,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","bdd14d96":"predicts = model.predict(img_test)\nthreshold = 0.5\npredicts = (predicts >= threshold).astype(int)","42f14374":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Etiqueta correcta')\n    plt.xlabel('Etiqueta predicha')\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ncm = confusion_matrix(test_labels, predicts)\ntn, fp, fn, tp = confusion_matrix(test_labels, predicts).ravel()\nplot_confusion_matrix(cm,[\"0\",\"1\"])","1290e168":"El desaf\u00edo de la competencia consta de crear un algoritmo para identificar el c\u00e1ncer metast\u00e1sico en peque\u00f1os parches de im\u00e1genes tomadas de exploraciones patol\u00f3gicas digitales m\u00e1s grandes.","87711392":"# **Detecci\u00f3n histopatol\u00f3gica del c\u00e1ncer.**","9a5185a7":"# **Exploraci\u00f3n del set de datos.**","2218cb16":"# **Modelo convolucional.**","5ba5a5c9":"Caracter\u00edsticas:\n1. Las im\u00e1genes tienen un tama\u00f1o de 96x96 pixeles.\n2. Una etiqueta positiva indica que la regi\u00f3n central de 32x32 pixeles de un parche contiene al menos un p\u00edxel de tejido tumoral. El tejido tumoral en la regi\u00f3n externa del parche no influye en la etiqueta."}}