{"cell_type":{"b230692b":"code","6b2e577c":"code","919d9563":"code","e4591c20":"code","43cff593":"code","90d3d2bf":"code","a9a96505":"code","4fddacc0":"code","0dcbbb4d":"code","d852c6af":"code","a48fe4ba":"code","74193173":"code","80cd0862":"code","c0cd641a":"code","37616126":"code","c508d5f5":"code","f00099b7":"code","d8651bfa":"code","4d566af8":"code","05f7ab0b":"code","072763ca":"code","5b52a485":"code","7babeb56":"code","9ce536fe":"code","dcc5bac2":"code","c6996f3d":"code","da4e9d2c":"code","8a30ea09":"code","ce2409fb":"code","b0bbe7ee":"code","f8d180ab":"code","003daa73":"code","104ece11":"code","f54be639":"markdown","ad6a903d":"markdown","df9c3989":"markdown","78e546d4":"markdown","4b3f7839":"markdown","16a69e5a":"markdown","ca405993":"markdown","9f40a0b9":"markdown","5bc6a960":"markdown","15b23db2":"markdown","240d8626":"markdown","7480cdff":"markdown","2abe6a62":"markdown","a6b27f32":"markdown","18f73253":"markdown","dad7c5f9":"markdown","cc7f181b":"markdown","3795a785":"markdown","09fd3296":"markdown","f4584789":"markdown","bcc630aa":"markdown","e35fee05":"markdown","fde7a93b":"markdown","fbccd651":"markdown","25ad7af5":"markdown","6f93b668":"markdown","c2902c63":"markdown"},"source":{"b230692b":"#Basic \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n%matplotlib inline\nsns.set(style='white', context='notebook', palette='deep')\n\nnp.random.seed(9)","6b2e577c":"#Specific\n\nimport matplotlib.image as mpimg\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport tensorflow as tf\n\nfrom keras.utils.np_utils import to_categorical #convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D,BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import LearningRateScheduler\n","919d9563":"#GPU testing \n\nif tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")\nprint(tf.test.is_built_with_cuda())","e4591c20":"train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('..\/input\/digit-recognizer\/test.csv')","43cff593":"y_train=train['label']\nX_train=train.drop(columns='label')","90d3d2bf":"# free some space\ndel train ","a9a96505":"sns.countplot(y_train)","4fddacc0":"X_train.isna().any().sum()","0dcbbb4d":"test.isna().any().sum()","d852c6af":"X_train \/=255.0\ntest \/=255.0","a48fe4ba":"X_train=X_train.values.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)","74193173":"#Cross-entropy loss needs OHE for target\ny_train=to_categorical(y_train,num_classes=10)","80cd0862":"#X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size = 0.25, random_state=2)","c0cd641a":"plt.imshow(X_train[0][:,:,0])","37616126":"X_train.shape","c508d5f5":"nets=6\nmodel=[0]*nets\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0) \n","f00099b7":"#Sequential model\nmodel[0]=Sequential()\n\n# 2 convolutional layers with 32 filters, 1 subsampling layer, 1 regularization layer\nmodel[0].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[0].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[0].add(MaxPool2D(pool_size=(2,2)))\nmodel[0].add(Dropout(0.25))\n\n# 2 convolutional layers with 64 filters, 1 subsampling layer, 1 regularization layer\nmodel[0].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[0].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[0].add(MaxPool2D(pool_size=(2,2)))\nmodel[0].add(Dropout(0.25))\n\n#Classification layers\nmodel[0].add(Flatten())  #Full conected layer needs 1D array on input\nmodel[0].add(Dense(256,activation='relu'))\nmodel[0].add(Dropout(0.5))\nmodel[0].add(Dense(10,activation='softmax'))\n\nmodel[0].compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'] )","d8651bfa":"model[1]=Sequential()\n\n# 2 convolutional layers with 32 filters, 1 subsampling layer, 1 regularization layer\nmodel[1].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[1].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[1].add(MaxPool2D(pool_size=(2,2)))\nmodel[1].add(Dropout(0.25))\n\n# 2 convolutional layers with 64 filters, 1 subsampling layer, 1 regularization layer\nmodel[1].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[1].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[1].add(MaxPool2D(pool_size=(2,2)))\nmodel[1].add(Dropout(0.25))\n\n#Classification layers\nmodel[1].add(Flatten())  #Full conected layer needs 1D array on input\nmodel[1].add(Dense(256,activation='relu'))\nmodel[1].add(Dropout(0.5))\nmodel[1].add(Dense(10,activation='softmax'))\n\nmodel[1].compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'] )","4d566af8":"#Sequential model\nmodel[2]=Sequential()\n\n# 2 convolutional layers, BatchNormalization, 1 subsampling layer, 1 regularization layer\nmodel[2].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[2].add(BatchNormalization())\nmodel[2].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[2].add(BatchNormalization())\nmodel[2].add(MaxPool2D(pool_size=(2,2)))\nmodel[2].add(Dropout(0.25))\n\n# 2 convolutional layers with 64 filters, BatchNormalization, 1 subsampling layer, 1 regularization layer\nmodel[2].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[2].add(BatchNormalization())\nmodel[2].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[2].add(BatchNormalization())\nmodel[2].add(MaxPool2D(pool_size=(2,2)))\nmodel[2].add(Dropout(0.25))\n\n#Classification layers\nmodel[2].add(Flatten())  #Full conected layer needs 1D array on input\nmodel[2].add(Dense(256,activation='relu'))\nmodel[2].add(BatchNormalization())\nmodel[2].add(Dropout(0.5))\nmodel[2].add(Dense(10,activation='softmax'))\n\nmodel[2].compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'] )","05f7ab0b":"#Sequential model\nmodel[3]=Sequential()\n\n# 2 convolutional layers, BatchNormalization, 1 subsampling layer, 1 regularization layer\nmodel[3].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[3].add(BatchNormalization())\nmodel[3].add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[3].add(BatchNormalization())\nmodel[3].add(MaxPool2D(pool_size=(2,2)))\nmodel[3].add(Dropout(0.25))\n\n# 2 convolutional layers with 64 filters, BatchNormalization, 1 subsampling layer, 1 regularization layer\nmodel[3].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[3].add(BatchNormalization())\nmodel[3].add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel[3].add(BatchNormalization())\nmodel[3].add(MaxPool2D(pool_size=(2,2)))\nmodel[3].add(Dropout(0.25))\n\n#Classification layers\nmodel[3].add(Flatten())  #Full conected layer needs 1D array on input\nmodel[3].add(Dense(256,activation='relu'))\nmodel[3].add(BatchNormalization())\nmodel[3].add(Dropout(0.5))\nmodel[3].add(Dense(10,activation='softmax'))\n\nmodel[3].compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'] )","072763ca":"#Sequential model\nmodel[4]=Sequential()\n\nmodel[4].add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\nmodel[4].add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\nmodel[4].add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\nmodel[4].add(MaxPool2D(pool_size=2))\nmodel[4].add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\nmodel[4].add(Conv2D(filters=192, kernel_size=3, padding='same', activation='relu'))\nmodel[4].add(MaxPool2D(pool_size=2))\nmodel[4].add(Conv2D(filters=192, kernel_size=5, padding='same', activation='relu'))\nmodel[4].add(MaxPool2D(pool_size=2, padding='same'))\nmodel[4].add(Flatten())\nmodel[4].add(Dense(256, activation='relu'))\nmodel[4].add(Dense(10, activation='softmax'))\n\nmodel[4].compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'] )","5b52a485":"#Sequential model\nmodel[5]=Sequential()\n\nmodel[5].add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\nmodel[5].add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\nmodel[5].add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\nmodel[5].add(MaxPool2D(pool_size=2))\nmodel[5].add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\nmodel[5].add(Conv2D(filters=192, kernel_size=3, padding='same', activation='relu'))\nmodel[5].add(MaxPool2D(pool_size=2))\nmodel[5].add(Conv2D(filters=192, kernel_size=5, padding='same', activation='relu'))\nmodel[5].add(MaxPool2D(pool_size=2, padding='same'))\nmodel[5].add(Flatten())\nmodel[5].add(Dense(256, activation='relu'))\nmodel[5].add(Dense(10, activation='softmax'))\n\nmodel[5].compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'] )","7babeb56":"# With data augmentation to prevent overfitting:\ndatagen = ImageDataGenerator(\n          featurewise_center=False,            # set input mean to 0 over the dataset\n          samplewise_center=False,             # set each sample mean to 0\n          featurewise_std_normalization=False, # divide inputs by std of the dataset\n          samplewise_std_normalization=False,  # divide each input by its std\n          zca_whitening=False,                 # apply ZCA whitening\n          rotation_range=10,                   # randomly rotate images in the range (degrees, 0 to 180)\n          zoom_range = 0.1,                    # Randomly zoom image \n          width_shift_range=0.1,               # randomly shift images horizontally (fraction of total width)\n          height_shift_range=0.1,              # randomly shift images vertically (fraction of total height)\n          horizontal_flip=False,               # randomly flip images\n          vertical_flip=False)                 # randomly flip images\n\ndatagen.fit(X_train)","9ce536fe":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)","dcc5bac2":"history = [0] * nets","c6996f3d":"epochs = 20\nfor j in range(nets):\n    print(\"CNN \",j+1)\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, y_train, test_size = 0.1)\n    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=32),\n        epochs = epochs, steps_per_epoch = X_train2.shape[0]\/\/32,  \n        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=1)\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n        j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))","da4e9d2c":"data={'CNN1':[history[0].history['val_accuracy'][19]],'CNN2':[history[1].history['val_accuracy'][19]],'CNN3':[history[2].history['val_accuracy'][19]],'CNN4':[history[3].history['val_accuracy'][19]],'CNN5':[history[4].history['val_accuracy'][19]],'CNN6':[history[5].history['val_accuracy'][19]]}\n\nhistories=pd.Series(data)\n                                \nhistories","8a30ea09":"#make the ensemble prediction on the validation set\nresults_ens = np.zeros( (X_val2.shape[0],10) ) \nfor j in range(nets):\n    results_ens = results_ens + model[j].predict(X_val2)\nresults_ens = np.argmax(results_ens,axis =1)","ce2409fb":"#get the score of the ensemble prediction\nfrom sklearn.metrics import accuracy_score\n\nY_val2=np.argmax(Y_val2,axis =1)\nens_acc=accuracy_score(results_ens,Y_val2)\n","b0bbe7ee":"print('Ensemble accuracy: {:.4f}'.format (ens_acc))","f8d180ab":"fig, ax = plt.subplots(2,1)\nax[0].plot(history[5].history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history[5].history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\nax[0].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history[5].history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history[5].history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax[1].grid(color='black', linestyle='-', linewidth=0.25)\nlegend = ax[1].legend(loc='best', shadow=True)","003daa73":"#Vizualization of single CNNs and the ensemble accuracy on validation set \naccs=[]\nfor i in range (nets):\n    accs.append(history[i].history['val_accuracy'][19])\n                 \naccs.append(ens_acc)\ncnns=['CNN1','CNN2','CNN3','CNN4','CNN5','CNN6','ENS']\n\nfig,ax=plt.subplots(figsize=(8,6))\nax=sns.barplot(x=cnns,y=accs)\nax.set(ylim=(0.98, 1.0))\n\nplt.show()","104ece11":"#predict the labels of the test \nresults = np.zeros( (test.shape[0],10) ) \nfor j in range(nets):\n    results = results + model[j].predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"predictions.csv\",index=False)","f54be639":"## Load data ","ad6a903d":"# Modeling (Ensemble of 6 CNN)","df9c3989":"## Encode target","78e546d4":"\u00a0## Define the model CNN_5\n","4b3f7839":"# Evaluation ","16a69e5a":"The notebook uses the ensemble of 6 CNN (inspired by  https:\/\/www.kaggle.com\/mohammedmurtuzalabib\/mnist-ensemble-of-5-cnns-0-99742).\n\nThere are 3 pairs of 2 CNN of the same architecture.\nFor the ensemble i chose 3 CNN architecture from Kaggle which give the best score (and augmented some of them with BatchNormalization layers).\nComparament of the ensemble and single CNNs quality is presented.\n","ca405993":"## Normalize data","9f40a0b9":"## Split into Target and Features","5bc6a960":"## Define the model CNN_1","15b23db2":"# Importing libraries","240d8626":"The dataset is balanced","7480cdff":"## Data augmentation","2abe6a62":"# Data Preparation ","a6b27f32":"## Split into train and validation set","18f73253":"##\u00a0Define the model CNN_4\n","dad7c5f9":"We can see that 3rd anf 4th CNN give the best quality. These nets are stolen from https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6 and augmented with BatchNormalization layers.","cc7f181b":"## Define the model CNN_2 ","3795a785":"Check balance in the target varible","09fd3296":"<h1>MNIST_Recognizer_CNN<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importing-libraries\" data-toc-modified-id=\"Importing-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Importing libraries<\/a><\/span><\/li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Data Preparation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>Load data<\/a><\/span><\/li><li><span><a href=\"#Split-into-Target-and-Features\" data-toc-modified-id=\"Split-into-Target-and-Features-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>Split into Target and Features<\/a><\/span><\/li><li><span><a href=\"#Check-for-null-and-missing-values\" data-toc-modified-id=\"Check-for-null-and-missing-values-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;<\/span>Check for null and missing values<\/a><\/span><\/li><li><span><a href=\"#Normalize-data\" data-toc-modified-id=\"Normalize-data-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;<\/span>Normalize data<\/a><\/span><\/li><li><span><a href=\"#Reshape\" data-toc-modified-id=\"Reshape-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;<\/span>Reshape<\/a><\/span><\/li><li><span><a href=\"#Encode-target\" data-toc-modified-id=\"Encode-target-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;<\/span>Encode target<\/a><\/span><\/li><li><span><a href=\"#Split-into-train-and-validation-set\" data-toc-modified-id=\"Split-into-train-and-validation-set-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;<\/span>Split into train and validation set<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Modeling-(Ensemble-of-6-CNN)\" data-toc-modified-id=\"Modeling-(Ensemble-of-6-CNN)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Modeling (Ensemble of 6 CNN)<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Define-the-model-CNN_1\" data-toc-modified-id=\"Define-the-model-CNN_1-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;<\/span>Define the model CNN_1<\/a><\/span><\/li><li><span><a href=\"#Define-the-model-CNN_2\" data-toc-modified-id=\"Define-the-model-CNN_2-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;<\/span>Define the model CNN_2<\/a><\/span><\/li><li><span><a href=\"#Define-the-model-CNN_3\" data-toc-modified-id=\"Define-the-model-CNN_3-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;<\/span>Define the model CNN_3<\/a><\/span><\/li><li><span><a href=\"#Define-the-model-CNN_4\" data-toc-modified-id=\"Define-the-model-CNN_4-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;<\/span>Define the model CNN_4<\/a><\/span><\/li><li><span><a href=\"#Define-the-model-CNN_5\" data-toc-modified-id=\"Define-the-model-CNN_5-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;<\/span>Define the model CNN_5<\/a><\/span><\/li><li><span><a href=\"#Define-the-model-CNN_6\" data-toc-modified-id=\"Define-the-model-CNN_6-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;<\/span>Define the model CNN_6<\/a><\/span><\/li><li><span><a href=\"#Data-augmentation\" data-toc-modified-id=\"Data-augmentation-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;<\/span>Data augmentation<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Evaluation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Training-and-validation-curves\" data-toc-modified-id=\"Training-and-validation-curves-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;<\/span>Training and validation curves<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Prediction\" data-toc-modified-id=\"Prediction-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Prediction<\/a><\/span><\/li><\/ul><\/div>","f4584789":"## Training and validation curves","bcc630aa":"## Train the network","e35fee05":"## Define the model CNN_6","fde7a93b":"## Check for null and missing values","fbccd651":"<font size=5 color=\"red\">Thank you for your attention! If you find this notebook useful, please, VOTE for it!!!<\/font>\n","25ad7af5":"# Prediction","6f93b668":"## Reshape","c2902c63":"##\u00a0Define the model CNN_3"}}