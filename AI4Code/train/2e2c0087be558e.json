{"cell_type":{"0bcae790":"code","189b5b8c":"code","7ca9bc3f":"code","a2ae1a17":"code","5a06391f":"code","8934cf6a":"code","25556f2c":"code","c305db1e":"code","04ef57a8":"code","40e38721":"code","c87b364d":"code","e35c68c2":"code","590d1162":"code","04255738":"code","0145d409":"code","2847a352":"code","6f25813e":"code","7b497984":"code","ea1df394":"code","ec80311d":"code","89ce78a8":"code","c76068b3":"code","8642646b":"markdown","76dde61e":"markdown","b795fe7a":"markdown","a1b058af":"markdown","e1eba3e7":"markdown","de733ccf":"markdown","312de04e":"markdown"},"source":{"0bcae790":"# import libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split","189b5b8c":"# download datasets from local files\n\ntrain = pd.read_csv('..\/input\/idao-2022-bootcamp-insomnia\/TRAIN.csv')\ntest = pd.read_csv('..\/input\/idao-2022-bootcamp-insomnia\/TEST.csv')\nsample_submission = pd.read_csv('..\/input\/idao-2022-bootcamp-insomnia\/sample_submission.csv')","7ca9bc3f":"print('train, test, sample_submission shapes')\nprint(train.shape, test.shape, sample_submission.shape)\ntrain.head(7)","a2ae1a17":"feat_research = pd.DataFrame(train.isna().sum() \/ train.shape[0], columns=['train_null_share'])\nfeat_research['test_null_share'] = test.isna().sum() \/ test.shape[0]\nfeat_research['train_dtypes'] = train.dtypes\nfeat_research['train_mean'] = train.mean()\nfeat_research['test_mean'] = test.mean()\n\nfeat_research","5a06391f":"# data distribution \n\nfig, ax = plt.subplots(len(train.columns)-1, 1)\nfig.set_figheight(25)\nfig.set_figwidth(15)\n\n\nfor i in range(1, len(test.columns)):\n    feat = train.columns[i]\n    ax[i-1].hist(train[feat], label=feat+'_train', alpha=0.5, color='blue')\n    ax[i-1].hist(test[feat], label=feat+'_test', alpha=0.5, color='red')\n    ax[i-1].legend()\n\nplt.show()","8934cf6a":"# train correlation matrix \n\nsns.heatmap(train.corr())\nplt.title('train_corr')\nplt.show()","25556f2c":"# test correlation matrix \n\nsns.heatmap(test.corr())\nplt.title('test_corr')\nplt.show()","c305db1e":"# drop *doctor* (correlated with *stress*, but less corrlatd with target) \ntrain = train.drop(columns=['doctor', 'id'])\ntest = test.drop(columns=['doctor', 'id'])","04ef57a8":"# fix nulls \n\n# pernicious_1 & pernicious_2 correelate with *sex* a little \n# so fill nulls with regard to it: \n# 1 for *sex* == 2 and 0, otherwise \npernicious_1_nan_male = np.where((np.isnan(test['pernicious_1']) & (test['sex']==2)), \n                               1, \n                               test['pernicious_1'])\ntest['pernicious_1'] = pernicious_1_nan_male\ntest['pernicious_1'] = test['pernicious_1'].fillna(0)\n\npernicious_2_nan_male = np.where((np.isnan(test['pernicious_2']) & (test['sex']==2)), \n                               1, \n                               test['pernicious_2'])\ntest['pernicious_2'] = pernicious_2_nan_male\ntest['pernicious_2'] = test['pernicious_2'].fillna(0)\n\n# fill in *sport* with median\ntest['sport'] = test['sport'].median()","40e38721":"# one-hot-encoding categorical features\n\nstress_train_ohe = pd.get_dummies(train['stress'], prefix='stress').drop(columns='stress_3')\nstress_test_ohe = pd.get_dummies(test['stress'], prefix='stress').drop(columns='stress_3')\n\ntrain = train.drop(columns='stress')\ntest = test.drop(columns='stress')\n\ntrain = train.join(stress_train_ohe)\ntest = test.join(stress_test_ohe)","c87b364d":"# *sex*: 1\/2 -> 0\/1\n\ntrain['sex'] -= 1","e35c68c2":"# train-test split \n\nX_train, X_val, y_train, y_val = train_test_split(train.drop(columns='insomnia'), \n                                                  train['insomnia'], \n                                                  test_size=0.3, \n                                                  random_state=13)","590d1162":"# create pipeline for logistic regression \n\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import log_loss\n\n\npipe = Pipeline([('scaler', StandardScaler()), \n                 ('lr', LogisticRegression(random_state=13))])\n\npipe.fit(X_train, y_train)\nlog_loss(y_val, pipe.predict_proba(X_val))","04255738":"# ! pip install catboost","0145d409":"# create pipeline for catboost classifier\n\nfrom catboost import CatBoostClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\npipe = Pipeline([('poly', PolynomialFeatures(2)), \n                  ('scaler', StandardScaler()), \n                 ('cbr', CatBoostClassifier(silent=True, random_seed=13))])\n\npipe.fit(X_train, y_train)\nlog_loss(y_val, pipe.predict_proba(X_val))","2847a352":"# catboostclassifier gridsearchcv \n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\n\n\npipe = Pipeline([('poly', PolynomialFeatures(1)), \n                  ('scaler', StandardScaler()), \n                  ('cbr', CatBoostClassifier(silent=True, random_seed=13, loss_function='Logloss'))])\n\ncbr_par = {'cbr__iterations': [20, 50, 100, 250], \n          'cbr__depth': [3, 5, 7]}\ncbr = CatBoostClassifier(silent=True)\ncbr_gscv = GridSearchCV(pipe, cbr_par)\ncbr_gscv.fit(X_train, y_train)\ncbr_best = cbr_gscv.best_estimator_\n\nprint('best params: {}'.format(cbr_gscv.best_params_))\nprint('logloss on best model: {}'.format(log_loss(y_val, cbr_best.predict_proba(X_val))))","6f25813e":"# feature importances for best model \n\nprint(X_train.columns) \ncbr_best.steps[2][1].feature_importances_","7b497984":"test_pred = cbr_best.predict_proba(test)[:, 1]\n\nplt.hist(test_pred)\nplt.title('test pred distribution')\nplt.show()","ea1df394":"test_submission = pd.DataFrame(sample_submission['id'])\ntest_submission['insomnia'] = test_pred\ntest_submission.head()","ec80311d":"# check shapes \n\nsample_submission.shape == test_submission.shape","89ce78a8":"sample_submission.head()","c76068b3":"test_submission.to_csv('test_submission.csv')","8642646b":"### Making a submission ","76dde61e":"### Training pipeline","b795fe7a":"### Feature overview ","a1b058af":"### Feature processing","e1eba3e7":"### Data","de733ccf":"#### Congrats on your first steps! ","312de04e":"This is a notebook for baseline submission. Feel free to use it as a starting point. "}}