{"cell_type":{"34183eb7":"code","87894b14":"code","e584a3b6":"code","4e02a889":"code","cf1252f6":"code","5df6e71f":"code","24937579":"code","d2584f8f":"code","b061eceb":"code","c6625251":"code","5ac1afa7":"markdown","fc055ec0":"markdown","9f16ff95":"markdown","41b6f9a8":"markdown","e4369e2a":"markdown","b19ca08f":"markdown"},"source":{"34183eb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87894b14":"import pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn import model_selection","e584a3b6":"TRAINING_FILE = \"\/kaggle\/input\/tabular-playground-series-may-2021\/train.csv\"\nTEST_FILE = \"\/kaggle\/input\/tabular-playground-series-may-2021\/test.csv\"","4e02a889":"df = pd.read_csv(TRAINING_FILE)\n\n# Transform \"target\" variable into integer\ndf[\"target\"] = df[\"target\"].map({'Class_1': 0, 'Class_2': 1, 'Class_3': 2, 'Class_4': 3})\n# Removing \"id\" column\ndf = df.drop(columns=[\"id\"])\n\n# Plotting distribution of target variable\nsns.countplot(x=df[\"target\"]);","cf1252f6":"df[\"kfold\"] = -1\ndf = df.sample(frac=1).reset_index(drop=True)\n# Using 20 splits to save time training the model\nkf = model_selection.StratifiedKFold(n_splits=10)\n\nfor fold, (trn_, val_) in enumerate(kf.split(X=df, y=df.target.values)):\n    df.loc[val_, \"kfold\"] = fold","5df6e71f":"svm_clf = SVC(kernel=\"rbf\", probability=True)","24937579":"# df = train file\n# df_test = test file\n\ndf_test_prep = pd.read_csv(TEST_FILE)\ndf_test = df_test_prep.drop([\"id\"], axis=1).values\n\n# Use fold \"2\" as train file = 10%\ndf_train = df[df.kfold == 2].reset_index(drop=True)\n# Use fold \"3\" as test file = 10% \ndf_valid = df[df.kfold == 3].reset_index(drop=True)\n       \nx_train = df_train.drop([\"target\", \"kfold\"], axis=1).values\ny_train = df_train.target.values\n    \nx_valid = df_valid.drop([\"target\", \"kfold\"], axis=1).values\ny_valid = df_valid.target.values","d2584f8f":"# TRAINING\nsvm_clf.fit(x_train, y_train)","b061eceb":"pred = svm_clf.predict_proba(df_test) \n\ny_test = pd.DataFrame(pred)\nsubmission = y_test.copy()\nsubmission.columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"]\nsubmission[\"id\"] = df_test_prep[\"id\"]","c6625251":"submission.head(10)","5ac1afa7":"# 1. Import the necessary libraries","fc055ec0":"# 5. Preparing and training the model","9f16ff95":"# 3. Very brief EDA (exploratory data analysis) ","41b6f9a8":"# 2. Preparation for loading the data","e4369e2a":"# 4. Creating folds with StratifiedKFold","b19ca08f":"## As we can see, Class 2 is overrepresented, while Class 1 is underrepresented. Therefore we apply stratification."}}