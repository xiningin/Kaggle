{"cell_type":{"aef47ec7":"code","ca8fafda":"code","4c1152f2":"code","9421626a":"code","60c4bbea":"code","1f79b00b":"code","24eb208b":"code","2413e666":"code","c7a0b8bb":"code","2f4277c6":"code","50de9082":"code","46cd692b":"code","0a8fe5d1":"code","10257d52":"code","6b3d2cbf":"code","c1ef8179":"code","08fa68ac":"code","206fcfc5":"code","90ded8f7":"code","82e7aeac":"code","6b345ea0":"code","2337438b":"code","9d492fd2":"code","ecbf8e6b":"code","8eac9a13":"code","dffa13e3":"code","592aea7f":"code","5044bb54":"code","56f9aa6e":"code","a5b1b0c0":"code","72c18e94":"code","c496508c":"code","4c195320":"markdown","a2f78ccd":"markdown","175f276f":"markdown"},"source":{"aef47ec7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # data vizul\nimport matplotlib.pyplot as plt  # data vizul\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ca8fafda":"data=pd.read_csv(\"..\/input\/weatherAUS.csv\")","4c1152f2":"data.head()","9421626a":"data.info()","60c4bbea":"data.count().sort_values() # first 4 future half - ilk 4 s\u00fctunu siliyoruz \u00e7\u00fcnk\u00fc yar\u0131s\u0131 bo\u015f.","1f79b00b":"data.shape","24eb208b":"data=data.drop(columns=[\"Sunshine\",\"Evaporation\",\"Cloud3pm\",\"Cloud9am\",\"Location\",\"Date\",\"RISK_MM\"],axis=1) ","2413e666":"data=data.dropna(how=\"any\") # delete all blank var - bo\u015f sat\u0131rlar\u0131 sildik.","c7a0b8bb":"data.shape","2f4277c6":"#delete outliers - Verimizden ayk\u0131r\u0131 uyu\u015fmayan verileri siliyoruz.(zscore)\nfrom scipy import stats\nz = np.abs(stats.zscore(data._get_numeric_data()))\nprint(z)\ndata= data[(z < 3).all(axis=1)]\nprint(data.shape)","50de9082":"data.corr() # corelation","46cd692b":"#heatmap\nf,ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(data.corr(), annot=True, linewidths=0.3,linecolor=\"red\", fmt= '.2f',ax=ax)\nplt.show()\n","0a8fe5d1":"plt.figure(figsize=(12,12))\nsns.countplot(data=data,x=\"MaxTemp\",order=data.MaxTemp.value_counts().iloc[:12].index)\nplt.show()","10257d52":"plt.figure(figsize=(12,12))\nsns.countplot(data=data,x=\"Temp9am\",order=data.Temp9am.value_counts().iloc[:12].index)\nplt.show()","6b3d2cbf":"plt.figure(figsize=(12,12))\nsns.countplot(data=data,x=\"Temp3pm\",order=data.Temp3pm.value_counts().iloc[:12].index)\nplt.show()","c1ef8179":"plt.figure(figsize=(6,6))\nsns.countplot(data=data,x=\"RainToday\")\nplt.show()","08fa68ac":"plt.figure(figsize=(10,10))\nsns.FacetGrid(data, hue=\"RainTomorrow\", height=6).map(sns.kdeplot, \"MinTemp\").add_legend()\nplt.ioff() \nplt.show()","206fcfc5":"plt.figure(figsize=(10,10))\nsns.FacetGrid(data, hue=\"RainTomorrow\", height=6).map(sns.kdeplot, \"MaxTemp\").add_legend()\nplt.ioff() \nplt.show()","90ded8f7":"plt.figure(figsize=(6,6))\nsns.boxplot(data=data,x=\"RainTomorrow\",y=\"Rainfall\")\nplt.show()","82e7aeac":"data.RainToday.isnull().sum()","6b345ea0":"data['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\ndata['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)","2337438b":"data.columns","9d492fd2":"#categorical dato to numerical\ntestData = data['RainTomorrow']\ndata = data.drop(columns=['RainTomorrow'])\ntrainData = pd.get_dummies(data,columns=['WindGustDir', 'WindDir3pm', 'WindDir9am']) #get_dummies","ecbf8e6b":"trainData.shape # (107868, 61)\ntestData.shape # (107868,)","8eac9a13":"testData=testData.values.reshape(-1,1)","dffa13e3":"testData.shape # (107868, 1) # because sklearn format.","592aea7f":"#transpose(T) train(x,y)  test(y,z) y e\u015fit olmal\u0131d\u0131r o sebeble T yapar\u0131z.\n# %%train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(trainData, testData, test_size=0.15, random_state=42)\n\nX_train = X_train.T\nX_test = X_test.T\n\n\nprint(\"x train: \",X_train.shape)\nprint(\"x test: \",X_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)\n","5044bb54":"# sklearn\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nlogReg=LogisticRegression()\nlogReg = LogisticRegression(random_state = 42,max_iter= 150)\nprint(\"test accuracy: {} \".format(logReg.fit(X_train.T, y_train).score(X_test.T, y_test)))\nprint(\"train accuracy: {} \".format(logReg.fit(X_train.T, y_train).score(X_train.T, y_train)))","56f9aa6e":"a=(X_test.T).iloc[99:106,:]","a5b1b0c0":"a","72c18e94":"pre=logReg.predict(a)","c496508c":"print(pre) #Haftl\u0131k tahmin.","4c195320":"**#more info RISK_MM for [here**](https:\/\/www.kaggle.com\/jsphyg\/weather-dataset-rattle-package\/discussion\/78316)**","a2f78ccd":"**first 4 future half - ilk 4 s\u00fctunu siliyoruz \u00e7\u00fcnk\u00fc yar\u0131s\u0131 bo\u015f**","175f276f":"#next step is to standardize our data - using MinMaxScaler\nfrom sklearn import preprocessing\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(data)\ntrainData = pd.DataFrame(scaler.transform(trainData), index=trainData.index, columns=trainData.columns)"}}