{"cell_type":{"82bcdf91":"code","c058f987":"code","f782d425":"code","b46bf03b":"code","80e2be48":"code","f18e8753":"code","28f04d6a":"code","418dc920":"code","28c61622":"code","93d5f538":"code","8febdc0e":"code","d7684f14":"code","2eb286e4":"code","21d85ffd":"code","04182b5e":"code","2735ab5e":"code","966c7f47":"code","6cddca18":"code","6b264157":"code","fb0d37a3":"code","1acdb50d":"code","1ca33504":"code","0c551aee":"code","61523f95":"code","c32218a9":"code","c9c4c936":"code","6213dbe6":"code","2c6cb8ea":"code","5d69b8ff":"code","a1d611c6":"code","efff2ba9":"code","8a191148":"code","062ed1ca":"code","3ba2e6b1":"code","b46ddcbc":"code","6ec082ac":"code","65187318":"code","024e34b8":"code","ea39948c":"code","51dddaba":"code","2a1d5d4e":"code","634267f1":"code","94b8bc2a":"code","4c94b1f0":"code","a1892bdd":"code","c652a424":"code","50743f15":"code","4dddf586":"code","da8e5087":"code","51cb49a8":"code","895e7004":"code","ae389c1c":"code","a282d1ef":"code","17d21bf4":"code","48bebc49":"markdown","7b4e5979":"markdown","adf3beb1":"markdown","c4e86cb8":"markdown","d1ecc88e":"markdown","8b93fb26":"markdown","af3fc0c5":"markdown","d1824adb":"markdown","b76c8587":"markdown","401843cf":"markdown","932477ac":"markdown","c7655268":"markdown","a51acfe0":"markdown","52933123":"markdown","086b1259":"markdown","1c304edf":"markdown","d38595dd":"markdown","a5ec84fc":"markdown","986b494d":"markdown","083793a2":"markdown","9188af25":"markdown","8e8cc52a":"markdown","17b7f08a":"markdown","efc4d09e":"markdown","df064bd4":"markdown","0c57ec7e":"markdown","29a1cbff":"markdown","5f8609a0":"markdown","c38893d8":"markdown","664f604b":"markdown","ae698c50":"markdown","beb020bd":"markdown"},"source":{"82bcdf91":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport requests, json, os, gc, re, warnings\nimport scipy.stats as st\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS\nfrom tqdm.auto import tqdm\n# from config import fec_api_key as api_key\nwarnings.filterwarnings('ignore')","c058f987":"# read in salaries data to get list of relevant schools\n# (those schools I have salary data for)\nsalaries_df = pd.DataFrame(pd.read_csv('..\/input\/texas-universities-salariesdonations\/Texas College Salaries 09-13-2021.csv'))\nsalaries_df['agency'].unique()","f782d425":"# change school names for better searching\nsalaries_df['agency'] = salaries_df['agency'].str.replace('UT', 'University of Texas')\nsalaries_df['agency'] = salaries_df['agency'].str.replace('TWU', \"Texas Woman's University\")\n\n# save school names to list for iterating through with API\nschool_list = salaries_df['agency'].unique()\nschool_list","b46bf03b":"# # set base and end URLs for FEC API\n# # documentation: https:\/\/api.open.fec.gov\/developers\n# base_url = f'https:\/\/api.open.fec.gov\/v1\/schedules\/schedule_a\/?api_key={api_key}&contributor_employer='\n# end_url = f'&per_page=100&contributor_type=individual&sort_hide_null=false&sort=-contribution_receipt_date&min_date=01%2F01%2F2019&is_individual=true&sort_null_only=false&page='\n\n# # empty list for data\n# all_data = []\n\n# # iterate through school names\n# for school_name in school_list:\n    \n#     print(f'Requesting {school_name} data....')\n    \n#     # build URL for school\n#     school_url = '%20'.join(school_name.split(' '))\n#     search_url = base_url + school_url + end_url + '1'\n    \n#     # API request and convert response to JSON\n#     first_result = requests.get(search_url)\n#     first_result_json = json.loads(first_result.text)\n    \n#     # add page donations list\n#     [all_data.append(donor) for donor in first_result_json['results']]\n    \n#     # find number of pages \n#     page_num = first_result_json['pagination']['pages']+1\n    \n#     # iterate through individual pages\n#     for i in tqdm(range(2, page_num)):\n#         search_url = base_url + school_url + end_url + str(i)\n#         result = requests.get(search_url)\n#         result_json = json.loads(first_result.text)\n#         [all_data.append for donor in result_json['results']]\n        \n#     print('Done.')\n    \n# # data to pandas dataframe\n# df = pd.DataFrame(all_data)\n# print(df.shape)\n\n# # save dataframe as csv\n# df.to_csv('..\/..\/data\/texas_universities_donor_data_2019_2021.csv')","80e2be48":"# FEC data\ndf = pd.DataFrame(pd.read_csv('..\/input\/texas-universities-salariesdonations\/texas_universities_donor_data_2019_2021.csv'))\n\nprint(f'FEC data shape: {df.shape}')\nprint(f'Salary data shape: {salaries_df.shape}')","f18e8753":"# limit number of columns\ndf = df[['contribution_receipt_date','contributor_first_name',\n         'contributor_last_name','committee_name','contributor_city',\n         'contributor_state','contribution_receipt_amount',\n         'contributor_aggregate_ytd','contributor_employer',\n         'contributor_occupation','contributor_id','transaction_id']]\n\ndf.head()","28f04d6a":"salaries_df.head()","418dc920":"# begin by removing negative donation rows from the dataframe\ndf = df.loc[df['contribution_receipt_amount']>0]\n\n# use np.where conditionals to make school names uniform\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower()=='texas state university',\n                                      'Texas State University', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('texas a&m'),\n                                      'Texas A&M', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer']=='TEXAS A&M UNIVERSITY SYSTEM HEALTH SCI',\n                                      'Texas A&M Health Science Center', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('texas tech'),\n                                      'Texas Tech', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('university of houston'),\n                                      'University of Houston', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('university of houston'),\n                                      'University of Houston', df['contributor_employer'])\n\nutt = df.loc[df.contributor_employer.str.lower().str.contains('tyler')]['contributor_employer'].unique().tolist()\ndf['contributor_employer'] = np.where(df['contributor_employer'].isin(utt),\n                                      'University of Texas Tyler', df['contributor_employer'])\n\nutd = ['UNIVERSITY OF TEXAS DALLAS',\n       'UNIVERSITY OF TEXAS - DALLAS', 'UNIVERSITY OF TEXAS AT DALLAS',\n       'THE UNIVERSITY OF TEXAS AT DALLAS','UNIVERSITY OF TEXAS, DALLAS',\n       'UNIVERSITY TEXAS AT DALLAS','UNIVERSITY OF TX DALLAS',\n       'UNIVERSITY OF TEXAS-DALLAS', 'UNIVERSITY OF TEXAS- DALLAS',\n       'UNIVERSITY. OF TX. AT DALLAS','UNIVERSITY OF TEXAS OF DALLAS',\n       'THE UNIVERSITY OR TEXAS AT DALLAS','UNIVERSITY OF TEXAS @ DALLAS']\ndf['contributor_employer'] = np.where(df['contributor_employer'].isin(utd),\n                                      'University of Texas Dallas', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('university of texas'),\n                                      np.where(df['contributor_employer'].str.lower().str.contains('san antonio'),\n                                      'University of Texas San Antonio', df['contributor_employer']), df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('sam houston'),\n                                      'Sam Houston State University', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('permian basin'),\n                                      'University of Texas Permian Basin', df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('university of t'),\n                                      np.where(df['contributor_employer'].str.lower().str.contains('arlington'),\n                                      'University of Texas Arlington', df['contributor_employer']), df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower().str.contains('texas wom'),\n                                      \"Texas Woman's University\", df['contributor_employer'])\n\ndf['contributor_employer'] = np.where(df['contributor_employer'].str.lower()==('sul ross'),\n                                      'Sul Ross', df['contributor_employer'])\n\natx = ['UNIVERSITY OF TEXAS','UNIVERSITY OF TEXAS AT AUSTIN','THE UNIVERSITY OF TEXAS AT AUSTIN']\ndf['contributor_employer'] = np.where(df['contributor_employer'].isin(atx),\n                                      'University of Texas Austin', df['contributor_employer'])\n\n# drop unwanted schools from the DF\ndf = df.loc[df['contributor_employer'].isin(school_list)]\n\n# convert contributor name data to title case\ndf = df.rename(columns={'contributor_employer':'agency',\n                        'contributor_first_name':'first_name',\n                        'contributor_last_name':'last_name'})\ndf['first_name'] = df['first_name'].str.title()\ndf['last_name'] = df['last_name'].str.title()\n\ndf","28c61622":"# clean up salary data before merge\n# split full_name from salaries_df into first and last name columns\nsalaries_df['first_name'] = salaries_df['full_name'].str.split(' ').str[0]\nsalaries_df['last_name'] = salaries_df['full_name'].str.split(' ').str[-1]\n\n# make emplyment_time column uniform\nsalaries_df['employment_time'] = salaries_df['employment_time'].str.lower()\n\n# add pay_type columns with np conditional (if \"p\/hour\" in salary column)\nsalaries_df['pay_type'] = np.where(salaries_df['salary'].str.contains('p\/hour'), \n                                   'Hourly', \n                                   'Yearly')\n\n# drop unwanted characters (last 4) from salary col\nsalaries_df['salary'] = np.where(salaries_df['salary'].str.contains('p\/hour'), \n                                 salaries_df['salary'].str[:-7], \n                                 salaries_df['salary'])\n\n# replace white space and commas with empty string\nsalaries_df['salary'] = salaries_df['salary'].str.replace(' ', '').str.replace(',', '')\n\n# convert salary column to float\nsalaries_df['salary'] = salaries_df['salary'].astype('float')\n\nsalaries_df.head()","93d5f538":"# remove non-salaried employees\nsalaries_df = salaries_df.loc[(salaries_df['pay_type']=='Yearly')\n                              &\n                              (salaries_df['employment_time']=='full-time')\n                              &\n                              (salaries_df['salary']>25000)]\n\n# remove salary outliers\nq1 = salaries_df['salary'].quantile(0.25)\nq3 = salaries_df['salary'].quantile(0.75)\niqr = q3 - q1\nsalaries_df = salaries_df[~((salaries_df['salary'] < (q1 - 1.5 * iqr)) \n                            |\n                            (salaries_df['salary'] > (q3 + 1.5 * iqr)))]\n\n\n# break salary into bins using pandas cut\nbin_num = 6\nsalaries_df['salary_level'] = pd.cut(salaries_df['salary'],\n                                     bins=bin_num,\n                                     labels=np.arange(bin_num))\n\nsalaries_df","8febdc0e":"salaries_df.salary_level.value_counts()","d7684f14":"# attempt to merge\nmerged_df = pd.merge(df, salaries_df, how='inner', on=['first_name','last_name','agency'])\nmerged_df","2eb286e4":"# remove unwanted columns\nwanted_cols = ['id','first_name','last_name','agency','department','job_title',\n               'employment_time','race','gender','hire_date','salary','salary_level',\n               'pay_type','committee_name','contribution_receipt_date', \n               'contribution_receipt_amount','contributor_aggregate_ytd',\n               'transaction_id']\nmerged_df = merged_df[wanted_cols]\nprint(f'Merged data shape: {merged_df.shape}')","21d85ffd":"fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,7))\ndf['full_name'] = df['first_name']+' '+df['last_name']\ndf.groupby('agency')['full_name'].nunique().sort_values(ascending=False)\\\n    .plot.bar(title='Total employee-donors per school (orginal dataset)', ax=ax1)\nmerged_df.groupby('agency')['id'].nunique().sort_values(ascending=False)\\\n    .plot.bar(title='Total employee-donors per school (merged dataset)', ax=ax2)\nplt.tight_layout()","04182b5e":"# chart donation data by school\n\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, figsize=(20,15)) # set subplots\n\n# graph total donation ammount per school\ndf.groupby('agency')['contribution_receipt_amount'].sum()\\\n    .sort_values(ascending=False)\\\n    .plot.bar(ax=ax1, title='Total contribution ammount per school ($)')\n\n# graph total donations per school\ndf.groupby('agency').size()\\\n    .sort_values(ascending=False)\\\n    .plot.bar(ax=ax2, title='Total transactions per school')\n\n# graph avg. donation ammount per school\ndf.groupby('agency')['contribution_receipt_amount'].mean()\\\n    .sort_values(ascending=False)\\\n    .plot.bar(ax=ax3, title='Avg. contribution ammount per transaction ($)')\n\n# graph median donation ammount per school\ndf.groupby('agency')['contribution_receipt_amount'].median()\\\n    .sort_values(ascending=False)\\\n    .plot.bar(ax=ax4, title='Median contribution ammount per transaction ($)')","2735ab5e":"# add month-year column based on 'contribution_receipt_date'\ndf['receipt_month'] = pd.to_datetime(df['contribution_receipt_date']).dt.to_period('M')\nmerged_df['receipt_month'] = pd.to_datetime(merged_df['contribution_receipt_date']).dt.to_period('M')\nmerged_df['receipt_year'] = pd.to_datetime(merged_df['contribution_receipt_date']).dt.year\nmerged_df.head()","966c7f47":"# chart donation data over time\nfig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, figsize=(10,12.5)) # set subplots\n\ndf.groupby('receipt_month')['contribution_receipt_amount'].mean()\\\n    .plot.line(ax=ax1, title='Mean donation ammount per month ($)')\n\ndf.groupby('receipt_month')['contribution_receipt_amount'].median()\\\n    .plot.line(ax=ax2, title='Median donation ammount per month ($)')\n\ndf.groupby('receipt_month')['contribution_receipt_amount'].sum()\\\n    .plot.line(ax=ax3, title='Total donation ammount per month ($)')\n\ndf.groupby('receipt_month').size()\\\n    .plot.line(ax=ax4, title='Total transactions per month')\n\nplt.tight_layout()","6cddca18":"# a multi-line graph charting total contribution ammount per month since 2019 per school\ndf.groupby(['receipt_month','agency']).size()\\\n    .to_frame().unstack()\\\n    .plot.line(title='Total donations over time by school ($)',figsize=(15,8))\n# plt.legend(bbox_to_anchor=(0.45, 1.0)) \nplt.tight_layout()","6b264157":"# attempt to chart donation data by job title\n\nfig, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(10,15))\n\nmerged_df.groupby('job_title')['contribution_receipt_amount'].mean()\\\n    .sort_values(ascending=False).iloc[:49]\\\n    .plot.bar(ax=ax1,title='Mean donation')\n\nmerged_df.groupby('job_title')['contribution_receipt_amount'].median()\\\n    .sort_values(ascending=False).iloc[:49]\\\n    .plot.bar(ax=ax2,title='Median donation')\n\nmerged_df.groupby('job_title')['contribution_receipt_amount'].sum()\\\n    .sort_values(ascending=False).iloc[:49]\\\n    .plot.bar(ax=ax3,title='Total donation')\n\nplt.subplots_adjust(hspace=1.5)","fb0d37a3":"# attempt to chart donation data by department\n\nfig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, figsize=(10,17))\n\nmerged_df.groupby('department')['contribution_receipt_amount'].mean()\\\n    .sort_values(ascending=False)[:20]\\\n    .plot.bar(ax=ax1,title='Mean donation')\n\nmerged_df.groupby('department')['contribution_receipt_amount'].median()\\\n    .sort_values(ascending=False)[:20]\\\n    .plot.bar(ax=ax2,title='Median donation')\n\nmerged_df.groupby('department')['contribution_receipt_amount'].sum()\\\n    .sort_values(ascending=False)[:20]\\\n    .plot.bar(ax=ax3,title='Total donation')\n\nmerged_df.groupby('department').size().sort_values(ascending=False)[:20]\\\n    .plot.bar(ax=ax4, title='Total transactions per department')\n\nplt.subplots_adjust(hspace=1.5)","1acdb50d":"# # get close matches for department, job_title data\n# from difflib import get_close_matches as gsm\n\n# gsm_depts = []\n# # gsm_jobs = []\n# for i in tqdm(range(len(merged_df))):    \n#     gsm_depts.append(', '.join(gsm(merged_df.department[i], merged_df.department)))\n# #     gsm_jobs.append(', '.join(gsm(merged_df.job_title[i], merged_df.job_title)))\n\n# salaries_df['dept_close_matches'] = gsm_depts\n# # salaries_df['job_close_matches'] = gsm_jobs\n\n# salaries_df","1ca33504":" # remove non-salaried employees\ntest_df = merged_df.groupby('id').agg({'agency':'first',\n                        'job_title':'first',\n                        'department':'first',\n                        'race':'first',\n                        'gender':'first',\n                        'hire_date':'first',\n                        'salary':'first',\n                        'salary_level':'first',\n                        'contribution_receipt_amount':[np.mean, np.sum],\n                        'transaction_id':'size',\n                        'committee_name':'nunique'})\n\ntest_df.columns = test_df.columns.get_level_values(0)\n\ncol_names = ['school','job_title','department','race',\n             'gender','hire_date','salary','salary_level',\n             'mean_donation','total_contribution',\n             'total_donations','num_recipients']\n\ntest_df.columns = col_names\n\ntest_df['remaining_income'] = test_df['salary'] - test_df['total_contribution']\n\ntest_df['donate_salary_percent'] = np.where(test_df['salary']>0, \n                                            (test_df['total_contribution']\/test_df['salary'])*100,\n                                            np.nan)\n\ntest_df","0c551aee":"fig, ((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2, figsize=(20,25)) # set subplots\ntest_df.groupby('salary_level').size()\\\n    .plot.bar(ax=ax1, title='Total donors per salary level')\ntest_df.groupby('salary_level')['total_donations'].sum()\\\n    .plot.bar(ax=ax2, title='Total transactions')\ntest_df.groupby('salary_level')['total_donations'].mean()\\\n    .plot.bar(ax=ax3, title='Avg. transactions per person')\ntest_df.groupby('salary_level')['total_contribution'].sum()\\\n    .plot.bar(ax=ax4, title='Total amount donated ($)')\nmerged_df.groupby('salary_level')['contribution_receipt_amount'].mean()\\\n    .plot.bar(ax=ax5, title='Avg. donation amount ($)')\ntest_df.groupby('salary_level')['num_recipients'].mean()\\\n    .plot.bar(ax=ax6, title='Avg. recipient number')\ntest_df.groupby('salary_level')['total_contribution'].mean()\\\n    .plot.bar(ax=ax7, title='Avg. total amount donated ($)')\ntest_df.groupby('salary_level')['total_contribution'].median()\\\n    .plot.bar(ax=ax8, title='Median total amount donated ($)')\nplt.subplots_adjust(hspace=.3)","61523f95":"label = ['Level 1','Level 2','Level 3','Level 4','Level 5','Level 6']\nmerged_df.groupby(['receipt_month','salary_level']).size()\\\n    .to_frame().unstack()\\\n    .plot.line(title='Total number of monthly donations over time by salary level',figsize=(15,8))\nplt.legend(labels=label)\nplt.tight_layout()","c32218a9":"merged_df.groupby(['receipt_month','salary_level'])['contribution_receipt_amount'].sum()\\\n    .to_frame().unstack()\\\n    .plot.line(title='Total monthly donation amount over time by salary level ($)',figsize=(15,8))\nplt.legend(labels=label)\nplt.tight_layout()","c9c4c936":"merged_df.loc[merged_df['receipt_month']<'2020-12']\\\n    .groupby(['receipt_month','salary_level'])['contribution_receipt_amount'].mean()\\\n    .to_frame().unstack()\\\n    .plot.line(title='Avg. donation amount per month over time by salary level (through Dec. 2020) ($)',figsize=(15,8))\nplt.legend(labels=label)\nplt.tight_layout()","6213dbe6":"fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, figsize=(15,10))\nmerged_df.groupby(['salary_level','receipt_year'])['contribution_receipt_amount'].mean()\\\n    .to_frame().unstack().plot.bar(title='Avg. individual donation amount per year',ax=ax1)\nmerged_df.groupby(['salary_level','receipt_year'])['contribution_receipt_amount'].median()\\\n    .to_frame().unstack().plot.bar(title='Median individual donation amount per year',ax=ax2)\nmerged_df.groupby(['salary_level','receipt_year'])['contribution_receipt_amount'].sum()\\\n    .to_frame().unstack().plot.bar(title='Total donation amount per year',ax=ax3)\nmerged_df.groupby(['salary_level','receipt_year']).size()\\\n    .to_frame().unstack().plot.bar(title='Total number of donations per year',ax=ax4)\n\nlabel=['2019','2020','2021']\nax1.legend(labels=label)\nax2.legend(labels=label)\nax3.legend(labels=label)\nax4.legend(labels=label)\n\nplt.tight_layout()","2c6cb8ea":"# remove donation outliers\nq1 = df['contribution_receipt_amount'].quantile(0.25)\nq3 = df['contribution_receipt_amount'].quantile(0.75)\niqr = q3 - q1\ndf_no_outliers = df[~((df['contribution_receipt_amount'] < (q1 - 1.5 * iqr)) \n                   |\n                   (df['contribution_receipt_amount'] > (q3 + 1.5 * iqr)))]\n\ndf_no_outliers.contribution_receipt_amount.plot.hist(grid=True, title='Donation size frequency', figsize=(10,5))\n\nplt.tight_layout()","5d69b8ff":"# remove donation outliers\nq1 = merged_df['contribution_receipt_amount'].quantile(0.25)\nq3 = merged_df['contribution_receipt_amount'].quantile(0.75)\niqr = q3 - q1\ndf_no_outliers = merged_df[~((merged_df['contribution_receipt_amount'] < (q1 - 1.5 * iqr)) \n                             |\n                             (merged_df['contribution_receipt_amount'] > (q3 + 1.5 * iqr)))]\n\ndf_no_outliers.groupby('salary_level')['contribution_receipt_amount'].plot.hist(grid=True, \n                                                                                bins=12,\n                                                                                title='Donation size frequency', \n                                                                                figsize=(10,5), alpha=0.7)\n\nplt.legend(title='Salary level')\nplt.tight_layout()","a1d611c6":"test_df.groupby('school')[['salary','total_contribution']].mean()\\\n    .sort_values(by='salary', ascending=False)\\\n    .plot.bar(stacked=True, figsize=(12,8), title='Mean salaries\/contributions')\nplt.legend(labels=['Avg. salary','Avg. total contribution'])","efff2ba9":"top100salaries = test_df.sort_values(by='total_contribution', ascending=False)[:100]\n\ntop100salaries.groupby('school')[['remaining_income','total_contribution']].mean()\\\n    .sort_values(by='remaining_income', ascending=False)\\\n    .plot.bar(stacked=True, figsize=(12,8), title='Top 100 mean salaries\/contributions')\n\nplt.legend(labels=['Avg. salary','Avg. total contribution'])","8a191148":"test_df.groupby('school')['donate_salary_percent'].median().sort_values(ascending=False).plot.bar()","062ed1ca":"top100salaries.sort_values(by='salary', ascending=False)[['remaining_income','total_contribution']]\\\n    .plot.bar(stacked=True, figsize=(15,8), \n              title='Total yearly contributions as part of Top 100 salaries',\n              ylim=(0,410000))\nplt.legend(labels=['Salary','Total contribution'])\nplt.tight_layout()","3ba2e6b1":"merged_df.loc[merged_df.id==83180].groupby('committee_name')['contribution_receipt_amount'].sum()","b46ddcbc":"merged_df.columns","6ec082ac":"top100donors = test_df.sort_values(by='total_contribution', ascending=False)[:100]\n\ntop100donors.sort_values(by='total_contribution', ascending=False)[['remaining_income','total_contribution']]\\\n    .plot.bar(stacked=True, figsize=(15,8), \n              title='Total yearly contributions as part of salaries for top 100 donors'\n#               ylim=(0,410000)\n             )\nplt.legend(labels=['Salary','Total contribution'])\nplt.tight_layout()","65187318":"top_percent_donors = test_df.dropna().sort_values(by='donate_salary_percent', ascending=False)[:50]\ntop_percent_donors['donate_salary_percent'].plot.bar(figsize=(15,8))","024e34b8":"plt.scatter(test_df['salary'], test_df['total_contribution'])\nplt.title('Salary vs. total contributions')\nplt.xlabel('Salary ($)')\nplt.ylabel('Total contributions ($)')\nplt.tight_layout()","ea39948c":"# creates linear regression plots\ndef regress(data, input1, input2):\n        \n    x = data[input1]\n    y = data[input2]\n    \n    # calculates linear regression\n    (slope, intercept, rvalue, pvalue, stderr) = st.linregress(x,y)\n    x = np.asarray(x, dtype=np.float64)\n    regress_values = x * slope + intercept\n    \n    print(regress_values)\n\n    # plots scatter plot and regresion\n    plt.figure(figsize=(10, 8))\n    plt.scatter(x, y)\n    plt.plot(x, regress_values,\"r-\")\n\n    # annotates graph with equation\n    line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n    plt.annotate(line_eq,xy=(min(x),min(y)),fontsize=15,color=\"red\")\n    plt.xlabel(input1)\n    plt.ylabel(input2)\n    plt.title(f'{input1} vs. {input2}')\n    \n    plt.tight_layout()\n    \n    # prints r squared value from linregress function\n    print(f'The r-squared is: {rvalue}')\n    \nregress(test_df, 'salary', 'total_contribution')","51dddaba":"regress(test_df, 'salary', 'total_donations')","2a1d5d4e":"regress(test_df, 'salary', 'mean_donation')","634267f1":"data = test_df.loc[test_df['job_title'].str.lower().str.contains('prof')]\nregress(data, 'salary', 'total_donations')","94b8bc2a":"regress(test_df, 'salary', 'donate_salary_percent')","4c94b1f0":"test_df.groupby('job_title')['total_contribution'].sum().sort_values(ascending=False)","a1892bdd":"test_df.groupby('gender')['total_donations'].sum().sort_values(ascending=False).plot.bar()","c652a424":"test_df.hire_date.value_counts()","50743f15":"# select data containing valid dates\ndata = test_df.loc[(test_df.hire_date.str.contains('\/'))\n                    &\n                    (test_df.hire_date!='Unavailable')]\n\n# convert string to datetime\ndata['hire_date'] = pd.to_datetime(data['hire_date'])\n\n# create hire date columns \ndata['hire_year_month'] = pd.to_datetime(data['hire_date']).dt.to_period('M')\ndata['hire_year'] = pd.to_datetime(data['hire_date']).dt.year\n\ndata.head()","4dddf586":"# donation amount and frequency by hire year\nfig, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(10,15))\ndata.groupby('hire_year')['total_contribution'].sum()\\\n    .plot.bar(title='Total contribution ammount by hire date', ax=ax1)\ndata.groupby('hire_year')['total_contribution'].mean()\\\n    .plot.bar(title='Avg. contribution ammount by hire date', ax=ax2)\ndata.groupby('hire_year')['total_donations'].mean()\\\n    .plot.bar(title='Total transactions by hire date', ax=ax3)","da8e5087":"data.groupby('hire_year').size().plot.bar()","51cb49a8":"data.loc[data.hire_year==1984]\n# ['total_contribution'].median()","895e7004":"# split dataset in half by salary donation percent\nhalf = int(len(test_df)\/2)\nbig_donors = test_df.sort_values(by='donate_salary_percent', ascending=False).iloc[:half]\nsmall_donors = test_df.sort_values(by='donate_salary_percent', ascending=False).iloc[half:]\nbig_donors","ae389c1c":"test_df.loc[test_df.total_donations==1]","a282d1ef":"job_words = ''\nstopwords = set(STOPWORDS)\n \n# iterate through the df\nfor val in merged_df['department']:\n     \n    val = str(val)\n \n    tokens = val.split()\n     \n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n     \n    job_words += \" \".join(tokens)+\" \"\n \nwordcloud = WordCloud(width = 800, height = 800,\n                background_color ='white',\n                stopwords = stopwords,\n                min_font_size = 10).generate(job_words)\n \n# plot WordCloud                       \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Donor departments')\nplt.tight_layout(pad = 0)\n \nplt.show()","17d21bf4":"merged_df.groupby('id',as_index=False).department.first().groupby('department').size().sort_values(ascending=False)","48bebc49":"## Read in data","7b4e5979":"I then decided to join the two datasets. Unfortunately, there were many spelling and name discrepancies. \n\nBy making the school and name data and uniform as possible, I merged the data based on employee-donor name and school name.","adf3beb1":"For this section, I grouped the dataset by individual donor and created several aggregate columns.","c4e86cb8":"We can learn a couple of things from these charts:\n\n1. The faculty and staff at UT Austin contribute the most money overall and make the most number of donations. This was expected given the sheer number of employees the school has. It is also important not to rule out errors in the dataset (misspelled or mislabeled data) or errors as a result of the merge.\n\n2. The difference in the average and median donation between schools, however, is much closer. Keep in mind, some of these schools (such as UT-PB) are barely represented in the datasets.\n\nIndividual contribution behavior is likely fairly uniform, regardless of school. ","d1ecc88e":"### Analyzing donations with salary","8b93fb26":"----\n## Transformations and cleaning","af3fc0c5":"Small donations are far more common, regardless of salary level.\n\nI find the spike in donation frequency at the 25 mark interesting. These are either recommended donation levels (likely the product of a fundraising campaign) or perhaps a natural tendency to settle on 25 or both. I'd be excited to learn which.","d1824adb":"UT Austin has, by far, the most donors represented in both datasets.","b76c8587":"From these charts, which show donation amounts and number of transactions by salary level, it appears that: \n1. The total number of transactions across salary levels roughly follows the total number of donors in those levels.\n2. The middle salary levels contribute the greatest total amount.\n3. The greater the salary, the greater the average donation amount and total amount.\n4. For the most part, the number of contributions increases with salary level.\n5. Average number of recipients increases with salary.","401843cf":"Before the merge, I removed outliers based on salary and split employees into six salary levels for easier analysis.","932477ac":"* These line graphs, which track donation activity over time, show a striking increase in total contribution amount and total donation transactions leading up to the 2020 election, with a rapid decline afterward. There is also a slight but mostly steady increase in total donations in the months and years leading up to July 2020.\n* The mean and median contributions increase with the election cycle as well. The increase rapidly in spring 2021.\n* With fewer total donations and fewer small donations following the election, the mean and median both spike.\n","c7655268":"----\n# Exploratory data analysis\n\nNote: For the purpose of these questions, it's not important who they're giving to.","a51acfe0":"### Wordclouds","52933123":"# Political contributions by Texas university employees","086b1259":"The result:","1c304edf":"# Supplementary analysis","d38595dd":"The shape of donation activity, though multiplied by the size of the school, appears fairly uniform across all represented schools.\n\nThis pattern likely coincides with donation campaigns, with activity ramping up at the end.\n\nIt is important to keep these trends in mind when designing a fundraising campaign.","a5ec84fc":"Not much can be made of job and department data until it is thoroughly cleaned. Though the charts are not reliable, it appears professors in humanities departments (English, History, etc.) contribute more often, while law professors and school admin contribute in greater amounts.\n\nI would like to narrow down the scope of the dataset before attempting to clean.","986b494d":"##### Salary dataset:","083793a2":"Despite the loss of data, the shape is still roughly the same.","9188af25":"![main-building-inscription-view-from-east.jpeg](attachment:0c5ef1dc-c137-4055-85b7-0af724d24b89.jpeg)","8e8cc52a":"### Analyzing donations","17b7f08a":"I found a recent dataset of Texas public university salaries online, then used the FEC's API to request data based on the same school.\n\nBy iterating through the list of schools, I obtained 124,253 political donation records for the relevant schools.","efc4d09e":"## API","df064bd4":"----\n\n# Obtaining the data\n","0c57ec7e":"These charts, which display donation activity over time based on salary level, show a few things:\n1. Higher salary levels contribue a greater total amount, especially during the climax of election season.\n2. Lower earners make many more donations during these final weeks and months. \n3. The average donation amount from higher earners greatly increases during these times.","29a1cbff":"Right away, we can see that the majority of donations are in small amounts.\n\nClearly, a large number of small donations can generate a lot of money.","5f8609a0":"##### FEC dataset:","c38893d8":"The join was about 50% successful. The loss of data was due to spelling and name discrepancies. Without a unique identifier, it was difficult to perfectly merge the two datasets.\n\nNevertheless, we still have 46,116 rows (64,000 without removing part-timers) of donation and salary data to work with. This was enough to discover big trends.","664f604b":"# Summary\n\nThis report and notebook represents my analysis of political donations among faculty, admin, and staff at universities throughout Texas. \n\n----\n\n\n## Key insights\n\n\n\n#### **Individual political donation activity follows the election cycle**\n* Total contributions and donation amounts ramp up toward the end of a big election or campaign, then drop off drastically. \n* This seems obvious, however, data aligning with anecdotal knowledge increases our confidence in those observations.\n* The pattern is the same regardless of school.\n* Why it\u2019s relent to you:\n    * This can be applied to the behavior of all donors.\n    * Because donations are often a product of timed fundraising campaigns, it is important to understand the pattern.\n        \n#### **Salary affects donation behavior**\n* Employees in higher salary categories contribute more money per donation and contribute more frequently.\n* Those in higher salary categories also tend to contribute to more causes.\n* Extreme outliers exist.\n    * For example, some employees in lower brackets contribute comparatively large amounts of money compared to even the biggest donors in higher brackets.\n    * Not all donation activity is easy to quantify.\n* Why it\u2019s relent to you:\n    * Average donation amount and donation frequency can be helpful during fundraising campaigns if targeting those in specific salary levels and wealth brackets.\n    \n#### **Most donations are small**\n* The majority of donations come in the form of small amounts.\n* The biggest factor affecting total funds raised is donation frequency and number of donors. \n    \n\n----\n\nSalary data from: https:\/\/texascollegesalaries.com\/\n\nDonation data from: https:\/\/www.fec.gov\/\n\nTableau presentation: https:\/\/public.tableau.com\/app\/profile\/travis.tyler\/viz\/university_poliotical_donors\/Story1?publish=yes","ae698c50":"### Analyzing by job\/department","beb020bd":"As expected, donation transactions spike in 2020 and fall below 2019 levels in 2021. \n\nNote: This data only goes up until October 2021."}}