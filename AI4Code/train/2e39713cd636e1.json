{"cell_type":{"23d46adb":"code","debce4e6":"code","f4c5ae1e":"code","145edabb":"code","5794bf44":"code","c8346daf":"code","332a4510":"code","7f7bb191":"code","9fd655eb":"code","6dc82b9f":"code","eb5cb156":"code","3a37f891":"code","f86be192":"code","9d74e46e":"code","277df540":"code","65d4a51c":"code","1a8f11ac":"code","0791fa3c":"code","6487ddd7":"code","5238df27":"code","2bbc0994":"code","27af7660":"code","c3dee402":"code","5cb40c16":"code","6d356def":"code","d8ce32c3":"code","002e1e51":"code","b8fdf50d":"code","9bfe9b8e":"code","1c23f024":"code","8320a2ba":"code","88588999":"code","638f209c":"code","824ed9e9":"code","58f40a3d":"code","fdfc7214":"code","4c3ff3c7":"code","9153165d":"markdown","4a1beb02":"markdown","41bb1d3a":"markdown","9f654272":"markdown","9d96e564":"markdown","c7f55cd5":"markdown","a690587d":"markdown","30b55535":"markdown","29fd66bf":"markdown","18af1edf":"markdown","a31d36f3":"markdown","b543a005":"markdown"},"source":{"23d46adb":"import os\nimport random\nimport platform\nimport itertools\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport lightgbm as lgbm\nimport scipy","debce4e6":"!pip freeze > requirements.txt","f4c5ae1e":"print('Python version:', platform.python_version())\nprint('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Matplotlib version:', matplotlib.__version__)\nprint('Seaborn version:', sns.__version__)\nprint('Scikit-Learn version:', sklearn.__version__)\nprint('LightGBM version:', lgbm.__version__)\nprint('Scipy version:', scipy.__version__)","145edabb":"SEED = 42\n\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)","5794bf44":"pd.set_option('display.width', None)\npd.set_option('display.max_column', None)","c8346daf":"df_train = pd.read_parquet('\/kaggle\/input\/shopee-marketing-data\/train_processed.parquet')\ndf_train","332a4510":"df_test = pd.read_parquet('\/kaggle\/input\/shopee-marketing-data\/test_processed.parquet')\ndf_test","7f7bb191":"df_train['day'] = pd.to_datetime(df_train['grass_date']).dt.dayofweek.astype('category')\ndf_test['day'] = pd.to_datetime(df_test['grass_date']).dt.dayofweek.astype('category')","9fd655eb":"del df_train['grass_date']\ndel df_test['grass_date']","6dc82b9f":"def fix_age(age):\n    if age < 18 or age >= 100:\n        return np.nan\n    else:\n        return age\n    \ndf_train['age'] = df_train['age'].apply(fix_age)\ndf_test['age'] = df_test['age'].apply(fix_age)","eb5cb156":"# # last_open_day\n# df_train['last_open_day_nan'] = df_train['last_open_day'].isnull()\n# df_train['last_open_day'] = df_train['last_open_day'].fillna(-1)\n\n# df_test['last_open_day_nan'] = df_test['last_open_day'].isnull()\n# df_test['last_open_day'] = df_test['last_open_day'].fillna(-1)\n\n# # last_login_day\n# df_train['last_login_day_nan'] = df_train['last_login_day'].isnull()\n# df_train['last_login_day'] = df_train['last_login_day'].fillna(-1)\n\n# df_test['last_login_day_nan'] = df_test['last_login_day'].isnull()\n# df_test['last_login_day'] = df_test['last_login_day'].fillna(-1)\n\n# # last_checkout_day\n# df_train['last_checkout_day_nan'] = df_train['last_checkout_day'].isnull()\n# df_train['last_checkout_day'] = df_train['last_checkout_day'].fillna(-1)\n\n# df_test['last_checkout_day_nan'] = df_test['last_checkout_day'].isnull()\n# df_test['last_checkout_day'] = df_test['last_checkout_day'].fillna(-1)\n\n# # attr_1\n# df_train['attr_1_nan'] = df_train['attr_1'].isnull()\n# df_train['attr_1'] = df_train['attr_1'].fillna(-1)\n\n# df_test['attr_1_nan'] = df_test['attr_1'].isnull()\n# df_test['attr_1'] = df_test['attr_1'].fillna(-1)\n\n# # attr_2\n# df_train['attr_2_nan'] = df_train['attr_2'].isnull()\n# df_train['attr_2'] = df_train['attr_2'].fillna(-1)\n\n# df_test['attr_2_nan'] = df_test['attr_2'].isnull()\n# df_test['attr_2'] = df_test['attr_2'].fillna(-1)\n\n# # attr_3\n# df_train['attr_3_nan'] = df_train['attr_3'].isnull()\n# df_train['attr_3'] = df_train['attr_3'].fillna(-1)\n\n# df_test['attr_3_nan'] = df_test['attr_3'].isnull()\n# df_test['attr_3'] = df_test['attr_3'].fillna(-1)\n\n# # age\n# df_train['age_nan'] = df_train['age'].isnull()\n# df_train['age'] = df_train['age'].fillna(-1)\n\n# df_test['age_nan'] = df_test['age'].isnull()\n# df_test['age'] = df_test['age'].fillna(-1)","3a37f891":"# domain\n# 1 -> 'other' domain from previous preprocessing\n# df_train['domain_nan'] = df_train['domain'].isnull()\ndf_train['domain'] = df_train['domain'].fillna(1)\n\n# df_test['domain_nan'] = df_test['domain'].isnull()\ndf_test['domain'] = df_test['domain'].fillna(1)","f86be192":"X = df_train.copy()\ndel X['open_flag']\n\nX_test = df_test.copy()\n\ny = df_train['open_flag'].to_numpy()","9d74e46e":"cat_feature = [\n    'country_code','attr_1', 'attr_2', 'attr_3',\n    'domain','day',\n#     'last_open_day_nan', 'last_login_day_nan',\n#     'last_checkout_day_nan', 'attr_1_nan', 'attr_2_nan',\n#     'attr_3_nan', 'age_nan', 'domain_nan',\n    \n]\ncat_feature_idx = [X.columns.get_loc(ct) for ct in cat_feature]\ncat_feature_idx","277df540":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import matthews_corrcoef\n\nK = [3, 5, 10]","65d4a51c":"param_dict = {\n    'learning_rate': [0.0075, 0.01, 0.0125],\n    'min_data_in_leaf': [20, 50],\n    'max_bin': [16, 102, 255],\n    'lambda': [\n        # l1, l2\n        [0.0, 0.0],\n        [0.001, 0.01],\n        [0.01, 0.1],\n        [1.0, 0.01],\n    ],\n    'n_estimators': [100, 125, 150]\n}\nparam_key = list(param_dict.keys())\nparam_item = list(param_dict.values())\nparam_item","1a8f11ac":"param_list = list(itertools.product(*param_item))\nparam_list[:10]","0791fa3c":"len(param_list)","6487ddd7":"df_model = pd.DataFrame(columns=[*param_key, *[f'model_{i}' for i in range(sum(K))], *[f'model_{i}_mcc' for i in range(sum(K))], 'average_mcc'])\ndf_model","5238df27":"skf_list = [StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED) for k in K]\n\nfor param in param_list:\n    ctr = 0\n    model = []\n    mcc_score = []\n    for skf in skf_list:\n        for train_idx, val_idx in skf.split(X, y):\n            X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n            y_train, y_val = y[train_idx], y[val_idx]\n\n            model.append(\n                lgbm.LGBMClassifier(\n                    # fixed\n                    is_unbalance=True,\n                    seed=SEED,\n                    extra_trees=True,\n\n                    min_data_per_group=1,\n                    boosting_type='goss',\n                    num_leaves=63,\n                    feature_fraction=0.9,\n                    # variable\n                    learning_rate=param[0],\n                    min_data_in_leaf=param[1],\n                    max_bin=param[2], \n                    lambda_l1=param[3][0],\n                    lambda_l2=param[3][1],\n                    n_estimators=param[4],\n                )\n            )\n            model[ctr].fit(\n                X_train, y_train,\n                categorical_feature=cat_feature_idx\n            )\n\n            y_val_pred = model[ctr].predict(X_val)\n            mcc_score.append(matthews_corrcoef(y_val, y_val_pred))\n\n            ctr += 1\n    df_model.loc[ df_model.shape[0] ] = [\n        *param,\n        *model,\n        *mcc_score,\n        sum(mcc_score) \/ len(mcc_score)\n    ]","2bbc0994":"df_model = df_model.sort_values(by=['average_mcc', 'learning_rate'], ascending=[False, True]).reset_index(drop=True)\ndf_model.loc[:1000].to_pickle('model.pkl')\n!ls -lah","27af7660":"pd.set_option('display.max_row', df_model.shape[0])","c3dee402":"df_model","5cb40c16":"pd.set_option('display.max_row', 10)","6d356def":"from sklearn.metrics import classification_report, f1_score, confusion_matrix, precision_score, matthews_corrcoef\n\ndef predict(X, mode='best_mean'):\n    if mode == 'best_mode':\n        y_preds = []\n        for i in range(sum(K)):\n            y_preds.append(df_model.loc[0, f'model_{i}'].predict(X))\n        y_preds = np.array(y_preds)\n        y_preds = scipy.stats.mode(y_preds)\n        y_preds = y_preds[0]\n        y_preds = y_preds.reshape(-1)\n    elif mode == 'best_mean':\n        y_preds = []\n        for i in range(sum(K)):\n            y_preds.append(df_model.loc[0, f'model_{i}'].predict_proba(X))\n        y_preds = np.mean(np.array(y_preds), axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    elif mode == 'ensemble_mode':\n        y_preds = []\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(df_model.loc[i, f'model_{j}'].predict(X))\n        y_preds = np.array(y_preds)\n        y_preds = scipy.stats.mode(y_preds)\n        y_preds = y_preds[0]\n        y_preds = y_preds.reshape(-1)\n    elif mode == 'ensemble_mean':\n        y_preds = []\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(df_model.loc[i, f'model_{j}'].predict_proba(X))\n        y_preds = np.mean(np.array(y_preds), axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    elif mode == 'weighted_ensemble_mean':\n        y_preds = []\n#         model_weight = df_model['average_mcc'].apply(lambda a: a\/df_model['average_mcc'].sum())\n        model_weight = []\n        for i in df_model.index:\n            model_weight.append(1 + np.log10(df_model.shape[0] - i + 1))\n        print(model_weight[:10])\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(\n                    df_model.loc[i, f'model_{j}'].predict_proba(X) *\n                    model_weight[i]\n                )\n        y_preds = np.array(y_preds)\n        y_preds = np.mean(y_preds, axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    else:\n        raise ValueError(\"Mode isn't supported\")\n    \n    return y_preds\n\ndef metrics(y_true, y_pred):\n    print('Weighted F1 Score :', f1_score(y_true, y_pred, average='weighted'))\n    print('MCC Score :', matthews_corrcoef(y_true, y_pred))\n    cm = confusion_matrix(y_true, y_pred)\n    cm = pd.DataFrame(cm, [0, 1], [0, 1])\n\n    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n    plt.show()","d8ce32c3":"y_train_pred = predict(X_train, mode='best_mode')\nmetrics(y_train, y_train_pred)","002e1e51":"y_train_pred2 = predict(X_train, mode='best_mean')\nmetrics(y_train, y_train_pred2)","b8fdf50d":"y_train_pred3 = predict(X_train, mode='ensemble_mode')\nmetrics(y_train, y_train_pred3)","9bfe9b8e":"y_train_pred4 = predict(X_train, mode='ensemble_mean')\nmetrics(y_train, y_train_pred4)","1c23f024":"y_train_pred5 = predict(X_train, mode='weighted_ensemble_mean')\nmetrics(y_train, y_train_pred5)","8320a2ba":"y_test_pred = predict(X_test, mode='best_mode')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_best_mode.csv', index=False)\n\ndf_submission","88588999":"y_test_pred2 = predict(X_test, mode='best_mean')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred2, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_best_mean.csv', index=False)\n\ndf_submission","638f209c":"y_test_pred3 = predict(X_test, mode='ensemble_mode')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred3, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_ensemble_mode.csv', index=False)\n\ndf_submission","824ed9e9":"y_test_pred4 = predict(X_test, mode='ensemble_mean')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred4, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_ensemble_mean.csv', index=False)\n\ndf_submission","58f40a3d":"y_test_pred5 = predict(X_test, mode='weighted_ensemble_mean')\n\ndf_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred5, name='open_flag')], axis=1)\ndf_submission.to_csv('submission_weighted_ensemble_mean.csv', index=False)\n\ndf_submission","fdfc7214":"lgbm.plot_importance(df_model.loc[0, 'model_0'], ignore_zero=False, figsize=(16,9))","4c3ff3c7":"lgbm.plot_split_value_histogram(df_model.loc[0, 'model_0'], 2)","9153165d":"# Changelog\n\n## Version 23\n\n* Final hyperparameter tuning\n* Use 3, 5 & 10 StratifiedKFold\n\n## Version 21\n\n* Tuning LightGBM parameter from version 20 result\n    * lambda pair : [0.0, 0.0], [0.001, 0.01], [0.01, 0.1], [0.01, 1.0], [1.0, 0.01]\n* Try different boosting_type\n* Change formula for weighted ensemble mean\n* Use 3 & 5 StratifiedKFold\n\n## Version 20\n\n* Tuning LightGBM parameter from version 18 result\n* Stop using validation data\n\n## Version 18\n\n* Tuning LightGBM parameter from version 16 result\n    * num_leaves : 63\n    * min_data_in_leaf : 20, 50\n    * bagging_fraction : **no diff**\n    * feature_fraction : 0.9, 1.0\n    * max_bin : 16, 102, 255\n    * min_data_per_group : 1\n* Use validation data to reduce overfit\n\n## Version 16\n\n* Tuning LightGBM parameter from version 15 result\n    * boosting_type : gbdt\n    * n_estimators : 100\n    * LR : 0.01\n    * num_leaves : 31, 63\n    * min_data_in_leaf : 20, 50\n\n## Version 15\n\n* Make submission for all mode\n* Fix dump `df_model`\n* Remove `age` from category feature\n\n## Version 13\n\n* Tuning LightGBM parameter\n* Add additional preprocessing\n* Add EDA\n\n## Version 10\n\n* Add additional preprocessing\n\n## Version 9\n\n* Use StratifiedKFold 3, 5, 10\n* Combine parameter from verison 4 & 5\n* Use mean and mode to predict data\n\n## Version 5\n\n* Use MCC score\n* Visualize LightGBM tree\n* Use different processed dataset\n* Specify categorical feature\n* Tweak parameter\n\n## Version 4\n\n* Attempt fix overfit\n* Tweak class weight\n\n## Version 2\n\n* Fix wrong row\n* Lower `max_bin` 255 -> 64\n* Increase `num_iterations` 5000 -> 10000\n\n## Version 1\n\n* Initial Code","4a1beb02":"## 4. Misc","41bb1d3a":"## 3. NaN","9f654272":"## 2. Anomaly","9d96e564":"# Visualize","c7f55cd5":"# Test","a690587d":"# Model","30b55535":"## 1. Timedate","29fd66bf":"# Dataset","18af1edf":"# Evaluate","a31d36f3":"# preprocessing","b543a005":"# Library"}}