{"cell_type":{"5c4b8b27":"code","7a7f326c":"code","301897e6":"code","a953d956":"code","6acc3d76":"code","45cf5810":"code","64719642":"code","ad25c898":"code","3a178610":"markdown","dc95a79f":"markdown","60bf92af":"markdown","f25285d4":"markdown","db13db72":"markdown"},"source":{"5c4b8b27":"!pip install -U spacy\n!pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_lg-0.2.4.tar.gz","7a7f326c":"from __future__ import unicode_literals, print_function\nfrom pathlib import Path\nfrom spacy.util import minibatch, compounding\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport itertools\nimport json\nimport nltk.data\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport spacy","301897e6":"# CONFIG\n\n# Data\nDIR_DATA_INPUT = os.path.join('\/kaggle', 'input', 'CORD-19-research-challenge')\nDIR_BIORXIV = os.path.join(DIR_DATA_INPUT, 'biorxiv_medrxiv', 'biorxiv_medrxiv', 'pdf_json')\nDIR_COMM = os.path.join(DIR_DATA_INPUT, 'comm_use_subset', 'comm_use_subset', 'pdf_json')\nDIR_CUSTOM = os.path.join(DIR_DATA_INPUT, 'custom_license', 'custom_license', 'pdf_json')\nDIR_NONCUSTOM = os.path.join(DIR_DATA_INPUT, 'noncomm_use_subset', 'noncomm_use_subset', 'pdf_json')\n\nDIR_DATA_OUTPUT = os.path.join('\/kaggle', 'working')\nPATH_AGG_JSON = os.path.join(DIR_DATA_OUTPUT, 'agg_data.json')","a953d956":"def extract_jsons_to_list(folder):\n    \"\"\"\n    Extracting 4 fields ('abstract', 'text', 'paper_id', 'title') from orginal Json file\n    :folder String, to location with Jsons\n    :return: Lists, with selected params\n    \"\"\"\n    results = []\n\n    files = os.listdir(folder)\n    for filename in tqdm(files, f'parsing {folder}'):\n        json_file = os.path.join(folder, filename)\n        file = json.load(open(json_file, 'rb'))\n        agg_abstract_file = ' '.join(\n            [abstract['text'] for abstract in file['abstract']])\n        text = ' '.join(\n            [text['text'] for text in file['body_text']])\n        results.append({\n            'abstract': agg_abstract_file,\n            'text': text,\n            'paper_id': file['paper_id'], \n            'title': file['metadata']['title']\n        })\n\n    return results\n\n\ndef save_json(file_to_save, path_to_save):\n    \"\"\"\n    Save in relevant Json format\n    :file_to_save DataFrame, file to save\n    :path_to_save String, lacation to save a file\n    \"\"\"\n    df = pd.DataFrame(file_to_save)\n    \n    df['json_output'] = df.apply(lambda x: {\n        'text': x.text, \"meta\":{'paper_id':x.paper_id, 'title': x.title}\n    }, axis=1)\n    df['json_output'].to_json(path_to_save, orient='records', lines=True)\n    \n\ndef filtr_covid_and_risk_factor(file_to_save, path_to_save):\n    \"\"\"\n    List filtering in abstact and text (filters: 'COVID-19' or 'SARS-CoV-2')\n    :file_to_save List, file to save\n    :path_to_save String, lacation to save a file\n    :return: DataFrame, valid data\n    \"\"\"\n    df = pd.DataFrame(file_to_save)\n    mask = df['abstract'].str.contains('COVID-19') | df['text'].str.contains('COVID-19') \\\n     | df['abstract'].str.contains('SARS-CoV-2') | df['text'].str.contains('SARS-CoV-2')\n    \n    abstracts = text_2_sentance(df[mask], 'abstract')\n    text = text_2_sentance(df[mask], 'text')\n    abstracts.extend(text)\n\n    save_json(abstracts, path_to_save)\n    \n    return df\n\n\ntokenizer = nltk.data.load('tokenizers\/punkt\/english.pickle')\ndef text_2_sentance(df, column):\n    \"\"\"\n    Save 3 senctance before and after sentance which contains `risk factor` expression\n    :df DataFrame, with text data\n    :column String, column name to process\n    :return: List, valid sentance\n    \"\"\"\n    df['sentances'] = df.apply(lambda x: tokenizer.tokenize(x[column]), axis = 1)\n    \n    valid_sentance = []\n    for _, row in tqdm(df.iterrows()):\n        sentance_range = set()\n        for index, singiel_sentance in enumerate(row['sentances']):\n            if 'risk factor' in singiel_sentance.lower():\n                sentance_range.update(\n                    range(index-3, index+4))\n        for valid_index in sentance_range:\n            if valid_index >=0 and valid_index < len(row['sentances']):\n                valid_sentance.append({\n                    'text': row['sentances'][valid_index],\n                    'paper_id': row['paper_id'], \n                    'title': row['title']\n                })\n                \n    return valid_sentance\n","6acc3d76":"# Generate Json for Marek\n\nbio = extract_jsons_to_list(DIR_BIORXIV)\ncomm = extract_jsons_to_list(DIR_COMM)\ncus = extract_jsons_to_list(DIR_CUSTOM)\nnon = extract_jsons_to_list(DIR_NONCUSTOM)\n\nlist_agg = bio + comm + cus + non\nresults = filtr_covid_and_risk_factor(list_agg, PATH_AGG_JSON)\n","45cf5810":"!wget https:\/\/raw.githubusercontent.com\/chopeen\/CORD-19\/master\/data\/annotated\/cord_19_rf_sentences_merged.json\n!ls -1","64719642":"new_list = []\nfile = json.load(open('cord_19_rf_sentences_merged.json', 'rb'))\n\ndf = pd.DataFrame(file)\n\nX_train, X_test = train_test_split(\n    df, test_size=0.2, random_state=42)\n\nX_train.to_json('train_abstract_teach.json', orient='records')\nX_test.to_json('test_abstract_teach.json', orient='records')","ad25c898":"!spacy train en models\/ train_abstract_teach.json test_abstract_teach.json --pipeline ner --base-model en_core_sci_lg  --replace-components","3a178610":"# Download data for training","dc95a79f":"# CODE","60bf92af":"# Train NER model","f25285d4":"# COVID-19 Open Research Dataset Challenge (CORD-19)\n\nChallenge repository at GitHub: https:\/\/github.com\/chopeen\/CORD-19\/\n\n## Team\n\n| Name               | Profile                                 |\n|--------------------|-----------------------------------------|\n| Adrianna Safaryn   | https:\/\/www.kaggle.com\/adriannasafaryn  |\n| Anna Haratym-Rojek | https:\/\/www.kaggle.com\/annaharatymrojek |\n| Cezary Szulc       | https:\/\/www.kaggle.com\/cezaryszulc      |\n| Marek Grzenkowicz  | https:\/\/www.kaggle.com\/chopeen          |\n\n## Goal\n\nWe wanted to use named entity recognition (NER) to highlight names of risk factors (RF). Our goal was\ntraining a **custom NER model for spaCy**, that could later be use to recognize risk factors in medical\npublications.\n\n![RF tags in Prodigy](https:\/\/raw.githubusercontent.com\/chopeen\/CORD-19\/master\/images\/ner.png)\n\n## Pipeline\n\n1. Data preprocessing to extract 'risk factor(s)' sentences\n2. Manual data annotation in Prodigy\n3. Pretraining different models - we experimented with different base models and trained a number of\n   *tok2vec* layers to maximize the F-score\n    - base models: `en_vectors_web_lg`, `en_core_web_lg`, `en_core_sci_lg`\n    - *tok2vec* layers were trained for: RF sentences, subset of abstracts, all abstracts\n4. Labelling more data by correcting the predictions of the top model trained in the previous step\n5. Go back to step #3 to pretrain a new model using more data and then label even more data\n6. Training the final model with all gathered annotations\n\n## Model performance\n\nEach iteration uses all datasets from the previous one and adds more annotations. For detailed information about every\ntrained model, see the notebook [train_experiments_2.ipynb](https:\/\/github.com\/chopeen\/CORD-19\/blob\/master\/train_experiments_2.ipynb).\n\n### Base model `en_core_sci_lg`\n\n| Iteration  | Datasets ([data\/annotated\/](https:\/\/github.com\/chopeen\/CORD-19\/tree\/master\/data\/annotated)) | Best F-score  |\n|------------|-------------------------------------------------|---------------|\n| 1          | `cord_19_rf_sentences`                          |   53.333      |\n| 2          | above + `cord_19_rf_sentences_correct`          | **75.630**    |\n| 3          | above + `cord_19_rf_sentences_correct_2`        |   74.894      |\n| 4          | above + `cord_19_rf_sentences_correct_3`        |   68.770      |\n\n### Base model `en_core_sci_md`\n\n| Iteration  | Datasets ([data\/annotated\/](https:\/\/github.com\/chopeen\/CORD-19\/tree\/master\/data\/annotated)) | Best F-score  | Download |\n|------------|-------------------------------------------------|---------------|------------------------------------------------------------------------------------------------------------|\n| 1          | `cord_19_rf_sentences`                          |   57.778      | [en_ner_rf_i1_md](https:\/\/kagglecord19.blob.core.windows.net\/risk-factor-ner\/en_ner_rf_i1_md-0.0.1.tar.gz) |\n| 2          | above + `cord_19_rf_sentences_correct`          | **74.380**    | [en_ner_rf_i2_md](https:\/\/kagglecord19.blob.core.windows.net\/risk-factor-ner\/en_ner_rf_i2_md-0.0.1.tar.gz) |\n| 3          | above + `cord_19_rf_sentences_correct_2`        |   74.236      | [en_ner_rf_i3_md](https:\/\/kagglecord19.blob.core.windows.net\/risk-factor-ner\/en_ner_rf_i3_md-0.0.1.tar.gz) |\n| 4          | above + `cord_19_rf_sentences_correct_3`        |   69.725      | [en_ner_rf_i4_md](https:\/\/kagglecord19.blob.core.windows.net\/risk-factor-ner\/en_ner_rf_i4_md-0.0.1.tar.gz) |\n\nUsing a smaller base model (`md` instead of `lg`) results in significantly smaller model, while the F-score\nmoves in both directions depending on the iteration.\n\n## Packaged models\n\nMedium models for iterations 1..4 can be installed using the download links from the table above.\n\nThe directory [test\/](https:\/\/github.com\/chopeen\/CORD-19\/tree\/master\/test) contains a demo of the models in action (separate Conda environment + notebook).\n\n## Key files and resources\n\n- Data preprocessing: [Kaggle notebook](https:\/\/www.kaggle.com\/cezaryszulc\/kaggle-covid-19-competition)\n- Training of *tok2vec* layers: [Kaggle notebook](https:\/\/www.kaggle.com\/chopeen\/spacy-with-gpu-support)\n- Full set of annotations:\n  - [cord_19_rf_sentences_merged.jsonl](https:\/\/github.com\/chopeen\/CORD-19\/blob\/master\/data\/annotated\/cord_19_rf_sentences_merged.jsonl) (dump of the Prodigy dataset)\n  - [cord_19_rf_sentences_merged.json](https:\/\/github.com\/chopeen\/CORD-19\/blob\/master\/data\/annotated\/cord_19_rf_sentences_merged.json) (spaCy JSON format)\n- Log of all experiments (including data annotation and model training): [train_experiments_2.ipynb](https:\/\/github.com\/chopeen\/CORD-19\/blob\/master\/train_experiments_2.ipynb)\n- Early experiments: [train_experiments_1.ipynb](https:\/\/github.com\/chopeen\/CORD-19\/blob\/master\/backup\/early_experiments\/train_experiments_1.ipynb)\n\n## Challenges\n\n- Detailed discussion posted at the Kaggle forum:\n  [Custom NER model to recognize risk factor names](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge\/discussion\/140451)\n- Question posted to the Prodigy support forum:\n  [Annotating compound entity phrases](https:\/\/support.prodi.gy\/t\/annotating-compound-entity-phrases\/2796)\n\n## Tools\n\n- [Prodigy](https:\/\/prodi.gy\/) - text annotation\n- [spaCy](https:\/\/spacy.io\/) - NLP and model training\n- [scispaCy](https:\/\/allenai.github.io\/scispacy\/) - specialized spaCy models for biomedical text processing\n- [Miniconda](https:\/\/docs.conda.io\/en\/latest\/miniconda.html) - environment setup (you can use\n  `conda env create -f environment.yml` to set up the Python environment with all packages and models)\n\n## Dataset citation\n\nCOVID-19 Open Research Dataset (CORD-19). 2020. Version 2020-03-13.  \nRetrieved from https:\/\/pages.semanticscholar.org\/coronavirus-research.  \nAccessed 2020-03-26. doi:10.5281\/zenodo.3715506\n\n## Notes\n\n1. [When to reject when annotating text for NER?](https:\/\/support.prodi.gy\/t\/when-to-reject-in-ner-manual-or-ner-make-gold\/892\/2)\n1. [When should I press accept, reject or ignore?](https:\/\/prodi.gy\/docs\/named-entity-recognition#manual-accept-reject)\n1. [`batch-train` is deprecated](https:\/\/prodi.gy\/docs\/recipes#deprecated)","db13db72":"# Split dataset for train and test sets"}}