{"cell_type":{"ac1e4a39":"code","65d06046":"code","04eb2433":"code","9d7f53f0":"code","0a09c22a":"code","a7e6f155":"code","813c48c9":"code","db3bff4c":"code","f7141e01":"code","e5e6860e":"code","13914359":"code","4db11414":"code","43ab2723":"code","7b38e2c4":"code","f766bf8c":"code","cc3e5f02":"code","3e09e5d7":"code","8fa68dd3":"code","fae5a3e3":"code","0aadbdba":"code","44ecf9a8":"code","7ed29144":"code","5c160a93":"code","ed336d50":"code","7b2d9285":"code","ac26dee1":"markdown","7e36e7fa":"markdown","ef3a04c1":"markdown","bb5a7395":"markdown","81da0f51":"markdown","ecb34567":"markdown","6a54de2b":"markdown","1cdef7ee":"markdown","10f8e839":"markdown","a9de0046":"markdown","b19ec041":"markdown","f0a115a2":"markdown","26a61407":"markdown","dd868f48":"markdown","70a0c011":"markdown"},"source":{"ac1e4a39":"import pandas as pd ","65d06046":"# #Pycaret needs to be installed\n!pip install pycaret","04eb2433":"#Let's read the data\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","9d7f53f0":"train['title']=train.Name.apply(lambda x: x.split('.')[0].split(',')[1].strip())\ntest['title']=test.Name.apply(lambda x: x.split('.')[0].split(',')[1].strip())","0a09c22a":"newtitles={\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"}","a7e6f155":"train['title']=train.title.map(newtitles)\ntest['title']=test.title.map(newtitles)","813c48c9":"train['Relatives']=train.SibSp+train.Parch\ntest['Relatives']=test.SibSp+test.Parch\n\ntrain['Ticket2']=train.Ticket.apply(lambda x : len(x))\ntest['Ticket2']=test.Ticket.apply(lambda x : len(x))","db3bff4c":"train['Cabin2']=train.Cabin.apply(lambda x : len(str(x)))\ntest['Cabin2']=test.Cabin.apply(lambda x : len(str(x)))","f7141e01":"train['Name2']=train.Name.apply(lambda x: x.split(',')[0].strip())\ntest['Name2']=test.Name.apply(lambda x: x.split(',')[0].strip())","e5e6860e":"from pycaret import classification\nclassification_setup = classification.setup(data = train,target = 'Survived',silent=True,)","13914359":"classification.compare_models()","4db11414":"lgb_classifier = classification.create_model('lightgbm')","43ab2723":"import numpy as np\nparams = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001],\n          'n_estimators':[100,250,500,750,1000,1250,1500,1750],\n          'max_depth': np.random.randint(1, (len(train.columns)*.85),20),\n          'max_features': np.random.randint(1, len(train.columns),20),\n          'min_samples_split':[2,4,6,8,10,20,40,60,100], \n          'min_samples_leaf':[1,3,5,7,9],\n          'criterion': [\"gini\", \"entropy\"]}\n\ntune_lgb = classification.tune_model(lgb_classifier, custom_grid = params)","7b38e2c4":"# Tune the model\nparams = {'alpha':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\ntune_ridge = classification.tune_model(classification.create_model('ridge'), custom_grid = params, n_iter=50, fold=50)","f766bf8c":"# ensemble boosting\nbagging = classification.ensemble_model(tune_lgb, method= 'Bagging')","cc3e5f02":"from pycaret.classification import blend_models\n# blending all models\nblend_all = blend_models(method='hard',estimator_list=classification.compare_models(sort='Accuracy',n_select=10))","3e09e5d7":"# create individual models for stacking\nridge_cls = classification.create_model('ridge')\nextre_tr = classification.create_model('et')\nlgb = classification.create_model('lightgbm')\ncat_cls = classification.create_model('catboost')\nlg_cls = classification.create_model('lr')\n","8fa68dd3":"from pycaret.classification import stack_models\n# stacking models\nstacker = stack_models(estimator_list = [ridge_cls, extre_tr, lgb, cat_cls, lg_cls])","fae5a3e3":"best = classification.automl(optimize = 'auc')\n","0aadbdba":"best\n# A stacked classifier it is!!","44ecf9a8":"# Validation Curve\nclassification.plot_model(tune_lgb, plot = 'vc')","7ed29144":"# AUC Curve\nclassification.plot_model(tune_lgb, plot = 'auc')","5c160a93":"# error Curve\nclassification.plot_model(tune_lgb, plot = 'error')","ed336d50":"y_pred = classification.predict_model(tune_lgb, data=test)","7b2d9285":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred['Label']\n    })\nsubmission.to_csv(\"submission.csv\", index=False)","ac26dee1":"# <a id=\"9\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\"> References<\/p>\n* https:\/\/www.kaggle.com\/aditi81k\/titanic-prediction-using-pycaret\n(Thanks Aditi)\n* https:\/\/pycaret.org\/\n(Official Documentation)\n* https:\/\/www.kaggle.com\/goldens\/titanic-on-the-top-with-a-simple-model\n(Feature engineering)","7e36e7fa":"* survival - Survival (0 = No; 1 = Yes)\n* class - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n* name - Name\n* sex - Sex\n* age - Age\n* sibsp - Number of Siblings\/Spouses Aboard\n* parch - Number of Parents\/Children Aboard\n* ticket - Ticket Number\n* fare - Passenger Fare\n* cabin - Cabin\n* embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","ef3a04c1":"\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\"> Titanic using PyCaret<\/p>","bb5a7395":"Happy Kaggling :)","81da0f51":"# <a id=\"4\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\">Model Comparison<\/p>","ecb34567":"* [1. Data Dictionary](#1)\n    \n* [2. Feature Engineering](#2)\n    \n* [3. Setting up Pycaret](#3)  \n    \n* [4. Model comparison](#4)  \n    \n* [5. Model selection](#5) \n\n* [6. Model tuning](#6) \n\n* [7. Model ensembling](#7) \n\n* [8. References](#9) ","6a54de2b":"# <a id=\"6\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\"> Model Tuning<\/p>","1cdef7ee":"# <a id=\"5\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\">Model Selection<\/p>","10f8e839":"**Feature engineering using these rules,and a few mentioned in the notebook in the reference:**\n\nPredict live for all males titled \u201cMaster\u201d whose entire family, excluding adult males, all live.\nPredict die for all females whose entire family, excluding adult males, all die.","a9de0046":"# <a id=\"3\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\"> Setting up Pycaret<\/p>\n\n\nThis is where magic happens.One line does all of these things:\n\n* I will tell the model to ignore certain ID features with high cardinality,the target column,and give my session an id.\n* I will also pass sex as a categorical feature here,and try rebalancing to see how it turns out.\n* I will pass multicollinearity handling as true so that it takes care of it.\n* I will normalize the data\n\n","b19ec041":"This function returns the best model out of all models created in the current active environment based on metric defined in optimize parameter. Run this code at the end of  your script.\nLet's see the best model up until now.","f0a115a2":"So you have a Kaggle account,what next?\n\nWhat if I tell you you can create your very first submission in less than 100 lines of code? Perhaps you're looking to become a contributor from a Novice.\n\nNo,I'm not talking the usual Logistic regression. I'm talking advanced Kaggle concepts like Feature engineering,Blending,Stackimg and Ensembling?\n\nWelcome Pycaret,a low Code library developed by Moez Ali,which helps professional data scientists develop prototypes quickly with very few lines of code.\n\nIt provides a great starting point to rule out what works for your data and what doesn't,so I highly recommend this.\nIn this code, We will read the data and create models and final predictions.\nI do recommend reading the official documentation while following along,and typing your own code by reading this notebook.\n\n*If you find this useful, Consider upvoting .If you have any feedbacks, please leave it in the comments.*","26a61407":"# <a id=\"1\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\"> Data Dictionary<\/p>","dd868f48":"# <a id=\"7\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\"> Model ensembling<\/p>","70a0c011":"# <a id=\"2\"><\/a>\n# <p style=\"background-color:#A291A7;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 30px;\">Feature Engineering<\/p>"}}