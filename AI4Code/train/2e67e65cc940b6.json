{"cell_type":{"e7af229f":"code","00d371bf":"code","9d28d0d2":"code","6f0d40b5":"code","abacc98a":"code","69ce49af":"code","7ca2d044":"code","985bd4f2":"code","e0ee801a":"code","eba72135":"markdown"},"source":{"e7af229f":"!python -m pip install doubtlab","00d371bf":"from sklearn.linear_model import LogisticRegression\n\nfrom doubtlab.ensemble import DoubtEnsemble\nfrom doubtlab.reason import CleanlabReason, ProbaReason, WrongPredictionReason\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n","9d28d0d2":"train=pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv')","6f0d40b5":"features = [col for col in train.columns if 'f' in col]\ny=train['target']\nX=train[features]","abacc98a":"scaler = StandardScaler()\nX = scaler.fit_transform(X)\n\nmodel = LogisticRegression(solver='liblinear',max_iter=1_000, random_state=42)\nmodel.fit(X, y)","69ce49af":"reasons = {\n    'proba': ProbaReason(model=model),\n    'wrong_pred': WrongPredictionReason(model=model)\n}\n\ndoubt = DoubtEnsemble(**reasons)\n# Get the ordered indices of examples worth checking again\nindices = doubt.get_indices(X, y)\n# Get dataframe with \"reason\"-ing behind the sorting\npredicates = doubt.get_predicates(X, y)","7ca2d044":"target_1 = predicates[predicates['predicate_wrong_pred']==0].shape[0]\ntarget_2 = predicates[predicates['predicate_wrong_pred']==1].shape[0]\nplt.figure(figsize=(15, 7))\nplt.pie([target_1,target_2], labels = [\"0\" , \"1\"],autopct='%1.1f%%',colors = [\"#17becf\", \"#1f77b4\"])\nplt.title('Wrong Prediction Reason')","985bd4f2":"predicates.to_csv('predicates.csv')","e0ee801a":"predicates.sample(n=100).head(40)","eba72135":"# Doubtlab\n\n\nDoubtlab provides general tricks that may help you find bad, or noisy, labels in your dataset. You can use doubtlab to check your own datasets for bad labels. Many of the methods that provided are based on the interaction between a dataset and a model trained on that dataset.\n\nDoubtlab provides many methods for bad\/noisy label detection.\n\n### General Reasons\n- **RandomReason:** assign doubt randomly, just for sure\n- **OutlierReason:** assign doubt when the model declares a row an outlier\n\n### Classification Reasons\n- **ProbaReason:** assign doubt when a models' confidence-values are low\n- **LongConfidenceReason:** assign doubt when a wrong class gains too much confidence\n- **ShortConfidenceReason:** assign doubt when the correct class gains too little confidence\n- **DisagreeReason:** assign doubt when two models disagree on a prediction\n- **OutlierReason:** assign doubt when the model declares a row an outlier\n- **CleanLabReason:** assign doubt according to cleanlab\n\n### Regression Reasons\n- **AbsoluteDifferenceReason:** assign doubt when the absolute difference is too high\n- **RelativeDifferenceReason:** assign doubt when the relative difference is too high\n\nhttps:\/\/github.com\/koaning\/doubtlab <br>\nhttps:\/\/koaning.github.io\/doubtlab\/ <br>\n"}}