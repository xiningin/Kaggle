{"cell_type":{"404232b8":"code","970eabb8":"code","a3b0a4ea":"code","ca0015d0":"code","1d4d9875":"code","c967bd6e":"code","ea58a5ed":"code","8c7314f7":"code","271b74ad":"code","f8476ea1":"code","fc51211b":"code","bafa7111":"code","0bebd6f1":"code","1dcde96b":"code","dc8f646e":"code","f5e791ad":"code","bcd7e0e8":"code","886fe041":"code","828a553c":"code","d0641cf0":"markdown","99be6878":"markdown","097df576":"markdown","b6f81b10":"markdown","e37c8ddb":"markdown","e338bda4":"markdown","dc8d037a":"markdown"},"source":{"404232b8":"!pip install -q imutils","970eabb8":"import os\nimport time\nimport shutil\n\nfrom imutils import paths\n\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import models\nfrom torchvision import transforms\nfrom torch.cuda.amp import autocast\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import densenet121\n\nfrom sklearn.metrics import classification_report","a3b0a4ea":"# define path to the original dataset\nDATA_PATH = \"..\/input\/food11-image-dataset\"\n \n# define base path to store our modified dataset\nBASE_PATH = \".\/\"\n \n# define paths to separate train, validation, and test splits\nTRAIN = os.path.join(BASE_PATH, \"training\")\nVAL = os.path.join(BASE_PATH, \"validation\")\nTEST = os.path.join(BASE_PATH, \"evaluation\") \n\n# initialize the list of class label names\nCLASSES = [\"Bread\", \"Dairy product\", \"Dessert\", \"Egg\", \"Fried food\", \"Meat\", \"Noodles-Pasta\", \"Rice\", \"Seafood\", \"Soup\", \"Vegetable-Fruit\"]\n \n# specify ImageNet mean and standard deviation and image size\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\nIMAGE_SIZE = 224\n\n# set the device to be used for training and evaluation\nDEVICE = torch.device(\"cuda\")\n \n# specify training hyperparameters\nLOCAL_BATCH_SIZE = 128\nPRED_BATCH_SIZE = 4\nEPOCHS = 20\nLR = 0.0001\n \n# define paths to store training plot and trained model\nPLOT_PATH = os.path.join(\".\/\", \"model_training.png\")\nMODEL_PATH = os.path.join(\".\/\", \"food_classifier.pth\")","ca0015d0":"def get_dataloader(rootDir, transforms, bs, shuffle=True):\n\t# create a dataset and use it to create a data loader\n\tds = datasets.ImageFolder(root=rootDir, transform=transforms)\n\tloader = DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=os.cpu_count(), pin_memory=True if DEVICE == \"cuda\" else False)\n    \n\t# return a tuple of the dataset and the data loader\n\treturn (ds, loader)","1d4d9875":"def copy_images(rootDir, destiDir):\n\t# get a list of the all the images present in the directory\n\timagePaths = list(paths.list_images(rootDir))\n\tprint(f\"[INFO] total images found: {len(imagePaths)}...\")\n    \n    # loop over the image paths\n\tfor imagePath in imagePaths:\n\t\t# extract class label from the filename\n\t\tfilename = imagePath.split(os.path.sep)[-1]\n\t\tlabel = imagePath.split(os.path.sep)[-2]\n        \n\t\t# construct the path to the output directory\n\t\tdirPath = os.path.sep.join([destiDir, label])\n        \n\t\t# if the output directory does not exist, create it\n\t\tif not os.path.exists(dirPath):\n\t\t\tos.makedirs(dirPath)\n            \n\t\t# construct the path to the output image file and copy it\n\t\tp = os.path.sep.join([dirPath, filename])\n\t\tshutil.copy2(imagePath, p)\n        \n    # calculate the total number of images in the destination directory and print it\n\tcurrentTotal = list(paths.list_images(destiDir))\n\tprint(f\"[INFO] total images copied to {destiDir}: {len(currentTotal)}...\")","c967bd6e":"# copy over the images to their respective directories\nprint(\"[INFO] copying images...\")\ncopy_images(os.path.join(DATA_PATH, \"training\"), TRAIN)\ncopy_images(os.path.join(DATA_PATH, \"validation\"), VAL)\ncopy_images(os.path.join(DATA_PATH, \"evaluation\"), TEST)","ea58a5ed":"class FoodClassifier(nn.Module):\n\tdef __init__(self, baseModel, numClasses):\n\t\tsuper(FoodClassifier, self).__init__()\n        \n\t\t# initialize the base model and the classification layer\n\t\tself.baseModel = baseModel\n\t\tself.classifier = nn.Linear(baseModel.classifier.in_features, numClasses)\n        \n\t\t# set the classifier of our base model to produce outputs from the last convolution block\n\t\tself.baseModel.classifier = nn.Identity()\n        \n    # we decorate the *forward()* method with *autocast()* to enable mixed-precision training in a distributed manner\n\t@autocast()\n\tdef forward(self, x):\n\t\t# pass the inputs through the base model and then obtain the classifier outputs\n\t\tfeatures = self.baseModel(x)\n\t\tlogits = self.classifier(features)\n        \n\t\t# return the classifier outputs\n\t\treturn logits","8c7314f7":"# determine the number of GPUs we have\nNUM_GPU = torch.cuda.device_count()\nprint(f\"[INFO] number of GPUs found: {NUM_GPU}...\")\n\n# determine the batch size based on the number of GPUs\nBATCH_SIZE = LOCAL_BATCH_SIZE * NUM_GPU\nprint(f\"[INFO] using a batch size of {BATCH_SIZE}...\")","271b74ad":"# define augmentation pipelines\ntrainTansform = transforms.Compose([\n\ttransforms.RandomResizedCrop(IMAGE_SIZE),\n\ttransforms.RandomHorizontalFlip(),\n\ttransforms.RandomRotation(90),\n\ttransforms.ToTensor(),\n\ttransforms.Normalize(mean=MEAN, std=STD)\n])\n\ntestTransform = transforms.Compose([\n\ttransforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n\ttransforms.ToTensor(),\n\ttransforms.Normalize(mean=MEAN, std=STD)\n])\n\n# create data loaders\n(trainDS, trainLoader) = get_dataloader(TRAIN, transforms=trainTansform, bs=BATCH_SIZE)\n(valDS, valLoader) = get_dataloader(VAL, transforms=testTransform, bs=BATCH_SIZE, shuffle=False)\n(testDS, testLoader) = get_dataloader(TEST, transforms=testTransform, bs=BATCH_SIZE, shuffle=False)","f8476ea1":"# load up the DenseNet121 model\nbaseModel = densenet121(pretrained=True)\n\n# loop over the modules of the model and if the module is batch norm, set it to non-trainable\nfor module, param in zip(baseModel.modules(), baseModel.parameters()):\n\tif isinstance(module, nn.BatchNorm2d):\n\t\tparam.requires_grad = False\n        \n# initialize our custom model and flash it to the current device\nmodel = FoodClassifier(baseModel, len(trainDS.classes))\nmodel = model.to(DEVICE)","fc51211b":"# if we have more than one GPU then parallelize the model\nif NUM_GPU > 1:\n\tmodel = nn.DataParallel(model)\n    \n# initialize loss function, optimizer, and gradient scaler\nlossFunc = nn.CrossEntropyLoss()\nopt = optim.Adam(model.parameters(), lr=LR * NUM_GPU)\nscaler = torch.cuda.amp.GradScaler(enabled=True)\n\n# initialize a learning-rate (LR) scheduler to decay the it by a factor of 0.1 after every 10 epochs\nlrScheduler = optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)\n\n# calculate steps per epoch for training and validation set\ntrainSteps = len(trainDS) \/\/ BATCH_SIZE\nvalSteps = len(valDS) \/\/ BATCH_SIZE\n\n# initialize a dictionary to store training history\nH = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [],\t\"val_acc\": []}","bafa7111":"# loop over epochs\nprint(\"[INFO] training the network...\")\nstartTime = time.time()\nfor e in tqdm(range(EPOCHS)):\n\t# set the model in training mode\n\tmodel.train()\n    \n\t# initialize the total training and validation loss\n\ttotalTrainLoss = 0\n\ttotalValLoss = 0\n    \n\t# initialize the number of correct predictions in the training and validation step\n\ttrainCorrect = 0\n\tvalCorrect = 0\n    \n\t# loop over the training set\n\tfor (x, y) in trainLoader:\n\t\twith torch.cuda.amp.autocast(enabled=True):\n\t\t\t# send the input to the device\n\t\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n            \n\t\t\t# perform a forward pass and calculate the training loss\n\t\t\tpred = model(x)\n\t\t\tloss = lossFunc(pred, y)\n            \n\t\t# calculate the gradients\n\t\tscaler.scale(loss).backward()\n\t\tscaler.step(opt)\n\t\tscaler.update()\n\t\topt.zero_grad()\n        \n\t\t# add the loss to the total training loss so far and calculate the number of correct predictions\n\t\ttotalTrainLoss += loss.item()\n\t\ttrainCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n        \n\t# update our LR scheduler\n\tlrScheduler.step()\n    \n    # switch off autograd\n\twith torch.no_grad():\n\t\t# set the model in evaluation mode\n\t\tmodel.eval()\n        \n\t\t# loop over the validation set\n\t\tfor (x, y) in valLoader:\n\t\t\twith torch.cuda.amp.autocast(enabled=True):\n\t\t\t\t# send the input to the device\n\t\t\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n                \n\t\t\t\t# make the predictions and calculate the validation loss\n\t\t\t\tpred = model(x)\n\t\t\t\ttotalValLoss += lossFunc(pred, y).item()\n                \n\t\t\t# calculate the number of correct predictions\n\t\t\tvalCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n            \n\t# calculate the average training and validation loss\n\tavgTrainLoss = totalTrainLoss \/ trainSteps\n\tavgValLoss = totalValLoss \/ valSteps\n    \n\t# calculate the training and validation accuracy\n\ttrainCorrect = trainCorrect \/ len(trainDS)\n\tvalCorrect = valCorrect \/ len(valDS)\n    \n    # update our training history\n\tH[\"train_loss\"].append(avgTrainLoss)\n\tH[\"train_acc\"].append(trainCorrect)\n\tH[\"val_loss\"].append(avgValLoss)\n\tH[\"val_acc\"].append(valCorrect)\n    \n\t# print the model training and validation information\n\tprint(\"[INFO] EPOCH: {}\/{}\".format(e + 1, EPOCHS))\n\tprint(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\n\tprint(\"Val loss: {:.6f}, Val accuracy: {:.4f}\".format(avgValLoss, valCorrect))\n    \n# display the total time needed to perform the training\nendTime = time.time()\nprint(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))","0bebd6f1":"# evaluate the network\nprint(\"[INFO] evaluating network...\")\nwith torch.no_grad():\n\t# set the model in evaluation mode\n\tmodel.eval()\n    \n\t# initialize a list to store our predictions\n\tpreds = []\n    \n\t# loop over the test set\n\tfor (x, _) in testLoader:\n\t\t# send the input to the device\n\t\tx = x.to(DEVICE)\n        \n\t\t# make the predictions and add them to the list\n\t\tpred = model(x)\n\t\tpreds.extend(pred.argmax(axis=1).cpu().numpy())\n        \n# generate a classification report\nprint(classification_report(testDS.targets, preds, target_names=testDS.classes))","1dcde96b":"# plot the training loss and accuracy\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(H[\"train_loss\"], label=\"train_loss\")\nplt.plot(H[\"val_loss\"], label=\"val_loss\")\nplt.plot(H[\"train_acc\"], label=\"train_acc\")\nplt.plot(H[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(PLOT_PATH)\n\n# serialize the model state to disk\ntorch.save(model.state_dict(), MODEL_PATH)","dc8f646e":"# determine the number of GPUs we have\nNUM_GPU = torch.cuda.device_count()\nprint(f\"[INFO] number of GPUs found: {NUM_GPU}...\")\n\n# determine the batch size based on the number of GPUs\nBATCH_SIZE = PRED_BATCH_SIZE * NUM_GPU\nprint(f\"[INFO] using a batch size of {BATCH_SIZE}...\")\n\n# define augmentation pipeline\ntestTransform = transforms.Compose([\n\ttransforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n\ttransforms.ToTensor(),\n\ttransforms.Normalize(mean=MEAN, std=STD)\n])","f5e791ad":"TEST = \".\/evaluation\"\n\n# calculate the inverse mean and standard deviation\ninvMean = [-m\/s for (m, s) in zip(MEAN, STD)]\ninvStd = [1\/s for s in STD]\n\n# define our denormalization transform\ndeNormalize = transforms.Normalize(mean=invMean, std=invStd)\n\n# create test data loader\n(testDS, testLoader) = get_dataloader(TEST,\ttransforms=testTransform, bs=BATCH_SIZE, shuffle=True)\n\n# load up the DenseNet121 model\nbaseModel = models.densenet121(pretrained=True)\n\n# initialize our food classifier\nmodel = FoodClassifier(baseModel, len(testDS.classes))\n\n# load the model state\nmodel.load_state_dict(torch.load(MODEL_PATH))","bcd7e0e8":"TEST","886fe041":"# if we have more than one GPU then parallelize the model\nif NUM_GPU > 1:\n\tmodel = nn.DataParallel(model)\n    \n# move the model to the device and set it in evaluation mode\nmodel.to(DEVICE)\nmodel.eval()\n\n# grab a batch of test data\nbatch = next(iter(testLoader))\n(images, labels) = (batch[0], batch[1])\n\n# initialize a figure\nfig = plt.figure(\"Results\", figsize=(10, 10 * NUM_GPU))","828a553c":"# switch off autograd\nwith torch.no_grad():\n\t# send the images to the device\n\timages = images.to(DEVICE)\n    \n\t# make the predictions\n\tpreds = model(images)\n    \n\t# loop over all the batch\n\tfor i in range(0, BATCH_SIZE):\n\t\t# initialize a subplot\n\t\tax = plt.subplot(BATCH_SIZE, 1, i + 1)\n        \n\t\t# grab the image, de-normalize it, scale the raw pixel intensities to the range [0, 255], and change the channel\n\t\t# ordering from channels first to channels last\n\t\timage = images[i]\n\t\timage = deNormalize(image).cpu().numpy()\n\t\timage = (image * 255).astype(\"uint8\")\n\t\timage = image.transpose((1, 2, 0))\n        \n\t\t# grab the ground truth label\n\t\tidx = labels[i].cpu().numpy()\n\t\tgtLabel = testDS.classes[idx]\n        \n\t\t# grab the predicted label\n\t\tpred = preds[i].argmax().cpu().numpy()\n\t\tpredLabel = testDS.classes[pred]\n        \n\t\t# add the results and image to the plot\n\t\tinfo = \"Ground Truth: {}, Predicted: {}\".format(gtLabel, predLabel)\n\t\tplt.imshow(image)\n\t\tplt.title(info)\n\t\tplt.axis(\"off\")\n        \n\t# show the plot\n\tplt.tight_layout()\n\tplt.show()","d0641cf0":"### Configuration","99be6878":"### Preparing the Dataset","097df576":"### import the necessary packages","b6f81b10":"### Creating the PyTorch Classifier","e37c8ddb":"### Train the PyTorch Classifier","e338bda4":"### Training inference","dc8d037a":"https:\/\/www.pyimagesearch.com\/2021\/10\/18\/introduction-to-distributed-training-in-pytorch\/"}}