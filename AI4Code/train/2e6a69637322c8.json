{"cell_type":{"92da7919":"code","67199acb":"code","9adb7066":"code","0456ae07":"code","237f3beb":"code","eb54c150":"code","5ec3c5d9":"code","9fcc91e5":"code","20af60bd":"code","8c9af5ea":"code","e9874d9a":"code","cdcc5588":"code","a1a2d6a4":"code","ed0d73ea":"code","7567408b":"code","7604ad63":"code","241253c8":"code","bab6461a":"code","af37c362":"code","2d65f946":"code","a163a487":"code","b8fedc47":"code","cef57a92":"code","4d31a28f":"code","5b59c8b6":"code","feee3d37":"code","e5674bb6":"code","1006c8f8":"code","0a2c3555":"code","c86e961d":"code","46d5f881":"markdown","749cda20":"markdown","f6d49ab4":"markdown","72a5d3fc":"markdown","91bf4150":"markdown","342bb681":"markdown","966b9379":"markdown","957b480a":"markdown","a3abd151":"markdown","061d890c":"markdown","4d412d79":"markdown","9396027d":"markdown","fd6527fe":"markdown","1e3d6814":"markdown","643163fd":"markdown","a8fd3fd4":"markdown"},"source":{"92da7919":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","67199acb":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.stem import PorterStemmer,WordNetLemmatizer\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom string import punctuation\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport tensorflow as tf","9adb7066":"true = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/True.csv\")\nfalse = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")","0456ae07":"true.head()","237f3beb":"false.head()","eb54c150":"true['category'] = 1\nfalse['category'] = 0","5ec3c5d9":"true.head()","9fcc91e5":"df = pd.concat([true,false]) ","20af60bd":"df.isna().sum()","8c9af5ea":"df.title.count()","e9874d9a":"df.subject.value_counts()","cdcc5588":"df['text'] = df['text'] + \" \" + df['title'] + \" \" + df['subject']\ndel df['title']\ndel df['subject']\ndel df['date']","a1a2d6a4":"df.head()","ed0d73ea":"stop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)","7567408b":"stop","7604ad63":"stemmer = PorterStemmer()\ndef stem_text(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            word = stemmer.stem(i.strip())\n            final_text.append(word)\n    return \" \".join(final_text)    ","241253c8":"df.text = df.text.apply(stem_text)","bab6461a":"plt.figure(figsize = (20,20))\nwc = WordCloud(max_words = 3000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df.text))\nplt.imshow(wc , interpolation = 'bilinear')","af37c362":"x_train,x_test,y_train,y_test = train_test_split(df.text,df.category)","2d65f946":"cv=CountVectorizer(min_df=0,max_df=1,ngram_range=(1,2))\n#transformed train reviews\ncv_train_reviews=cv.fit_transform(x_train)\n#transformed test reviews\ncv_test_reviews=cv.transform(x_test)\n\nprint('BOW_cv_train:',cv_train_reviews.shape)\nprint('BOW_cv_test:',cv_test_reviews.shape)","a163a487":"model = Sequential()\nmodel.add(Dense(units = 100 , activation = 'relu' , input_dim = cv_train_reviews.shape[1]))\nmodel.add(Dense(units = 50 , activation = 'relu'))\nmodel.add(Dense(units = 25 , activation = 'relu'))\nmodel.add(Dense(units = 10 , activation = 'relu'))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))","b8fedc47":"model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])","cef57a92":"model.fit(cv_train_reviews,y_train , epochs = 5)","4d31a28f":"pred = model.predict(cv_test_reviews)","5b59c8b6":"for i in range(len(pred)):\n    if(pred[i] > 0.5):\n        pred[i] = 1\n    else:\n        pred[i] = 0","feee3d37":"accuracy_score(pred,y_test)","e5674bb6":"cv_report = classification_report(y_test,pred,target_names = ['0','1'])\nprint(cv_report)","1006c8f8":"cm_cv = confusion_matrix(y_test,pred)\ncm_cv","0a2c3555":"cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1])\ncm_cv.index.name = 'Actual'\ncm_cv.columns.name = 'Predicted'","c86e961d":"plt.figure(figsize = (10,10))\nsns.heatmap(cm_cv,cmap= \"Blues\",annot = True, fmt='')","46d5f881":"# Fit the model","749cda20":"# Confusion Matrix","f6d49ab4":"# Importing Libraries","72a5d3fc":"# Remove noisy words from a text","91bf4150":"# Generating Word Cloud","342bb681":"# Check for missing values","966b9379":"# Merging the 2 datasets","957b480a":"# Loading Dataset","a3abd151":"# Define the model","061d890c":"# Prediction and Accuracy","4d412d79":"# Stemming and lemmatization","9396027d":"# Spliting training and testing data","fd6527fe":"# Compile the model","1e3d6814":"# First 5 records","643163fd":"# Text-2-Vector conversion ","a8fd3fd4":"# Evaluation"}}