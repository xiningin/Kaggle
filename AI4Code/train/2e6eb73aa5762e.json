{"cell_type":{"4bc227bf":"code","fd864d93":"code","cd89894f":"code","8c8e7deb":"code","fbd1bc7e":"code","bccb5318":"code","e041c5d8":"code","11a11682":"code","450e4bc2":"code","b40d6deb":"code","61643b3d":"code","46f4f017":"code","055e7090":"code","d4b41c1e":"code","14560ea4":"code","49024bcd":"code","587fd6e0":"code","8d27a33b":"code","2b819182":"code","9d49fef4":"code","9f10b554":"code","f0557dfc":"code","85854229":"code","84fb5a86":"code","fb3b5089":"code","c5259269":"code","33da8b13":"code","88e68e1f":"code","c6092682":"code","e8323e9d":"code","ebeaf7bc":"code","2ba13313":"code","37014ff2":"code","2b6d73af":"code","c3eaf249":"code","d4803b62":"code","1014b1c0":"code","fe455c73":"code","d84609da":"code","64f170c1":"code","9da572db":"code","176516b9":"code","57799357":"code","1e8fbdb8":"code","054c80a2":"code","983df5e1":"code","60812432":"code","2430ba73":"code","56741129":"code","4e5c2ff4":"code","8c19655a":"code","d12ce714":"code","be1bc2ce":"code","4a399441":"code","5d0bbce9":"code","efc6901b":"markdown","985080b4":"markdown","59fecd5a":"markdown","da2d1a2b":"markdown","0d92c55d":"markdown","39504052":"markdown","09bdc173":"markdown","656fbd7a":"markdown","166b205f":"markdown","070167d7":"markdown","33068493":"markdown","9fa3001d":"markdown","661616c0":"markdown","c68321fb":"markdown"},"source":{"4bc227bf":"#Call required libraries\nimport numpy as np            # Data manipulation\nfrom numpy import nan as NA\nimport pandas as pd           # Dataframe manipulatio \nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nimport os\nimport conda\nimport seaborn as sns\nfrom sklearn.cluster import KMeans #For clustering","fd864d93":"# Load data\ntaxi_df = pd.read_csv('..\/input\/taxi_final.csv', delimiter = ',', low_memory = True )","cd89894f":"# Column names\ntaxi_df.head(5)","8c8e7deb":"# Basic information about dataset\ntaxi_df.info()","fbd1bc7e":"# Drop useless columns\ntaxi_df.drop(['DateCreated', 'StartDateTime.1', 'Unnamed: 31'], axis=1, inplace=True)","bccb5318":"# Remove nulls and wrong values\ntaxi_df = taxi_df[taxi_df['FareAmount'] > 0]\ntaxi_df = taxi_df[taxi_df['GratuityAmount'] >= 0]\ntaxi_df = taxi_df[taxi_df['SurchargeAmount'] >= 0]\ntaxi_df = taxi_df[taxi_df['ExtraFareAmount'] >= 0]\ntaxi_df = taxi_df[taxi_df['TotalAmount'] > 0]\ntaxi_df = taxi_df[taxi_df['Milage'] > 0]\ntaxi_df = taxi_df[taxi_df['Milage'] < 500]","e041c5d8":"S=pd.DataFrame(taxi_df['FareAmount'].groupby(taxi_df['PROVIDER NAME']).sum())\nS = S.reset_index().sort_index(by='FareAmount',ascending=False)\nfig = plt.figure(figsize=(15,5))\nsns.barplot(y='FareAmount',x='PROVIDER NAME',data=S,palette=\"Blues_d\")","11a11682":"# Change data format\ntaxi_df['StartDateTime'] = pd.to_datetime(taxi_df['StartDateTime'], errors='coerce')\ntaxi_df['EndDateTime'] = pd.to_datetime(taxi_df['EndDateTime'])\n\n# Generate detailed columns of datetime\ntaxi_df['Date'] = taxi_df['StartDateTime'].dt.date\ntaxi_df['Hour'] = taxi_df['StartDateTime'].dt.hour\ntaxi_df['Weekday'] = taxi_df['StartDateTime'].dt.weekday\ntaxi_df['DayofWeek'] = taxi_df['StartDateTime'].dt.weekday_name","450e4bc2":"# Plot the heat map\ntime_map=pd.pivot_table(taxi_df,index=['DayofWeek'],columns =['Hour'],aggfunc='size')\nfig, ax = plt.subplots(figsize=(20,15)) \nax=sns.heatmap(time_map,linewidths=0.1,square=True,cmap='YlGnBu')","b40d6deb":"# Classify weekdays and weekend\nx = 0\ntaxi_df['IsWeekday'] = [x+1 if i<6 else x for i in taxi_df['Weekday']]","61643b3d":"# Remove nulls and wrong values\ntaxi_df['StartDateTime'].dropna(inplace=True)\ntaxi_df = taxi_df[taxi_df['StartDateTime'] < taxi_df['EndDateTime']]","46f4f017":"# Label Weekdays\ndf1 = DataFrame(taxi_df[taxi_df['IsWeekday']==1]['Hour'].value_counts().sort_index())\ndf1 = df1.reset_index()\ndf1.columns = ['Hour', 'Demand']\n\nkmeans = KMeans(n_clusters=3, random_state=0).fit(df1)\ndf1['WeekdayLabel'] = kmeans.labels_","055e7090":"# Weekdays time tiers\ndf1","d4b41c1e":"# Label Weekend\ndf2 = DataFrame(taxi_df[taxi_df['IsWeekday']==0]['Hour'].value_counts().sort_index())\ndf2 = df2.reset_index()\ndf2.columns = ['Hour', 'Demand']\n\nkmeans = KMeans(n_clusters=3, random_state=0).fit(df2)\ndf2['WeekendLabel'] = kmeans.labels_","14560ea4":"# Weekend time tiers\ndf2","49024bcd":"# Merge labels\ndf1 = df1.loc[:,['Hour', 'WeekdayLabel']]\ndf2 = df2.loc[:,['Hour', 'WeekendLabel']]","587fd6e0":"taxi_df = taxi_df.merge(df1, on = 'Hour')","8d27a33b":"taxi_df = taxi_df.merge(df2, on = 'Hour')","2b819182":"taxi_df.columns","9d49fef4":"# Split dataset into weekdays data and weekend data\nday_df = taxi_df[taxi_df['IsWeekday']==1].loc[:,['FareAmount', 'TotalAmount', 'IsWeekday', 'WeekdayLabel']]\nend_df = taxi_df[taxi_df['IsWeekday']==0].loc[:,['FareAmount', 'TotalAmount', 'IsWeekday', 'WeekendLabel']]","9f10b554":"# For weekdays\npeak = day_df[day_df['WeekdayLabel']==1]\noff_peak = day_df[day_df['WeekdayLabel']==0]","f0557dfc":"# For weekend\npeak_end = end_df[end_df['WeekendLabel']==2]\noff_peak_end = end_df[end_df['WeekendLabel']==1]","85854229":"# Generate list of price shift and demand shift\nelastic = 0.22\nprice_shift = np.linspace(0.01,2,200)\ndemand_shift = price_shift * elastic\nshift = list(zip(price_shift, demand_shift))","84fb5a86":"# Weekday, Based on TotalAmount\nrev_day = []\nfor x,y in shift:\n    peak_samp = peak.sample(frac=(1-y), random_state=1)\n    p = peak_samp['TotalAmount'].sum() * (1 + x)\n    rev_day.append(p)","fb3b5089":"# Weekday Peak time, Result, Based on TotalAmount\nrev_day = DataFrame(list(zip(price_shift, demand_shift, rev_day)), columns=['price_shift', 'demand_shift', 'revenue'])\npeak_day_max = rev_day.sort_values(by='revenue', ascending=False).head(1)\nrev_day.plot.kde()","c5259269":"peak_day_max['revenue shift']= max(rev_day['revenue'])\/peak['TotalAmount'].sum()-1\npeak_day_max","33da8b13":"# Weekend, Based on TotalAmount\nrev_end = []\nfor x,y in shift:\n    peak_end_samp = peak_end.sample(frac=(1-y), random_state=1)\n    p = peak_end_samp['TotalAmount'].sum() * (1 + x)\n    rev_end.append(p)","88e68e1f":"# Weekend Peak time, Result, Based on TotalAmount\nrev_end = DataFrame(list(zip(price_shift, demand_shift, rev_end)), columns=['price_shift', 'demand_shift', 'revenue'])\npeak_end_max = rev_end.sort_values(by='revenue', ascending=False).head(1)\nrev_end.plot.kde()","c6092682":"peak_end_max['revenue shift']= max(rev_end['revenue'])\/peak_end['TotalAmount'].sum()-1\npeak_end_max","e8323e9d":"# Weekdays, Generat a related list of demand shift, based on fare shift\nelastic = 0.22\nfare_shift = np.linspace(0.01,2,200)\ndemand_shift_day = []\nfor i in fare_shift:\n    a = (sum(peak['TotalAmount'] + peak['FareAmount'] * i)\/sum(peak['TotalAmount']) - 1)*elastic\n    demand_shift_day.append(a)","ebeaf7bc":"#Weekday High Peak, Analysis, only fare\nshift_day = list(zip(fare_shift, demand_shift))\nrev_day2 = []\nfor x,y in shift_day:\n    peak_samp2 = peak.sample(frac=(1-y), random_state=1)\n    p = sum(peak_samp2['TotalAmount'] + peak_samp2['FareAmount'] * x)\n    rev_day2.append(p)","2ba13313":"# Weekday Peak time, Result, Based on FareAmount\nrev_day2 = DataFrame(list(zip(fare_shift, demand_shift, rev_day2)), columns=['fare_shift', 'demand_shift', 'revenue'])\npeak_day_max2 = rev_day2.sort_values(by='revenue', ascending=False).head(1)\nrev_day2.plot.kde()","37014ff2":"peak_day_max2['revenue shift']= max(rev_day2['revenue'])\/peak['TotalAmount'].sum()-1\npeak_day_max2","2b6d73af":"# Weekend, Generat a related list of demand shift, based on fare shift\ndemand_shift_end = []\nfor i in fare_shift:\n    a = (sum(peak_end['TotalAmount'] + peak_end['FareAmount'] * i)\/sum(peak_end['TotalAmount']) - 1)*elastic\n    demand_shift_end.append(a)","c3eaf249":"#Weekend High Peak, Analysis, Based on FareAmount\nshift_end = list(zip(fare_shift, demand_shift_end))\nrev_end2 = []\nfor x,y in shift_end:\n    peak_end_samp2 = peak_end.sample(frac=(1-y), random_state=1)\n    p = sum(peak_end_samp2['TotalAmount'] + peak_end_samp2['FareAmount'] * x)\n    rev_end2.append(p)","d4803b62":"# Weekend Peak time, Result, Based on FareAmount\nrev_end2 = DataFrame(list(zip(fare_shift, demand_shift_end, rev_end2)), columns=['fare_shift', 'demand_shift', 'revenue'])\npeak_end_max2 = rev_end2.sort_values(by='revenue', ascending=False).head(1)\nrev_end2.plot.kde()","1014b1c0":"peak_end_max2['revenue shift']= max(rev_end2['revenue'])\/peak_end['TotalAmount'].sum()-1\npeak_end_max2","fe455c73":"# Generate list of price shift and demand shift\nelastic = 0.22\nprice_shift_off = np.linspace(-0.01,-1,100)\ndemand_shift_off = price_shift_off * elastic\nshift_off = list(zip(price_shift_off, demand_shift_off))","d84609da":"#Weekday Off-peak, Analysis\nrev_off_day = []\nfor x,y in shift_off:\n    off_samp = off_peak.sample(frac=(1+y), random_state=1, replace=True)\n    p = off_samp['TotalAmount'].sum() * (1 + x)\n    rev_off_day.append(p)","64f170c1":"# Weekday Off-peak time, Result, Based on TotalAmount\nrev_off_day = DataFrame(list(zip(price_shift_off, demand_shift_off, rev_off_day)), columns=['price_shift', 'demand_shift', 'revenue'])\noff_day_max = rev_off_day.sort_values(by='revenue', ascending=False).head(1)","9da572db":"plt.scatter(-rev_off_day['demand_shift'], rev_off_day['revenue'])\nplt.xlabel('Demand')\nplt.ylabel('Revenue')\nplt.title('Demand vs Revenue when Discount')\nplt.show","176516b9":"#Weekend Off-peak, Analysis\nrev_off_end = []\nfor x,y in shift_off:\n    off_samp = off_peak_end.sample(frac=(1-y), random_state=1, replace=True)\n    p = off_samp['TotalAmount'].sum() * (1 + x)\n    rev_off_end.append(p)","57799357":"# Weekday Off-peak time, Result, Based on TotalAmount\nrev_off_end = DataFrame(list(zip(price_shift_off, demand_shift_off, rev_off_end)), columns=['price_shift', 'demand_shift', 'revenue'])\noff_end_max = rev_off_end.sort_values(by='revenue', ascending=False).head(1)","1e8fbdb8":"plt.scatter(-rev_off_end['demand_shift'], rev_off_end['revenue'])\nplt.xlabel('Demand')\nplt.ylabel('Revenue')\nplt.title('Demand vs Revenue when Discount')\nplt.show","054c80a2":"# Set supply of Peak Time\ns_elastic = 0.28\nprice_shift = np.linspace(0.01,2,200)\nsupply_shift = price_shift * s_elastic\nsupply_day = (1+supply_shift) * len(peak)\nsupply_end = (1+supply_shift) * len(peak_end)","983df5e1":"#Weekday Peak Time, Result, per supply\nrev_day['supply'] = supply_day\nrev_day['TotalAmount per Trip'] = rev_day['revenue']\/rev_day['supply']\np_mean = peak['TotalAmount'].mean()\nrev_day['TotalAmount per Trip'].plot.kde()","60812432":"print('Original amount per trip(Weekday):', p_mean)\nrev_day.nlargest(1, columns='revenue')","2430ba73":"#Weekend Peak Time, Result, per supply\nrev_end['supply'] = supply_end\nrev_end['TotalAmount per Trip'] = rev_end['revenue']\/rev_end['supply']\nrev_end['TotalAmount per Trip'].plot.kde()\n","56741129":"print('Original amount per trip(Weekend):', peak_end['TotalAmount'].mean())\nrev_end.nlargest(1, columns='revenue')","4e5c2ff4":"# Set supply of Peak Time for Weekdays\nsupply_shift_day = np.array(demand_shift_day)  * (s_elastic\/elastic)\nsupply_day2 = (1+supply_shift_day) * len(peak)","8c19655a":"#Weekday Peak Time, Result, per supply\nrev_day2['supply'] = supply_day2\nrev_day2['TotalAmount per Trip'] = rev_day2['revenue']\/rev_day['supply']\nrev_day2['TotalAmount per Trip'].plot.kde()","d12ce714":"print('Original amount per trip(Weekday):', p_mean)\nrev_day2.nlargest(1, columns='revenue')","be1bc2ce":"# Set supply of Peak Time for Weekend\nsupply_shift_end = np.array(demand_shift_end)  * (s_elastic\/elastic)\nsupply_end2 = (1+supply_shift_end) * len(peak_end)","4a399441":"#Weekend Peak Time, Result, per supply\nrev_end2['supply'] = supply_end2\nrev_end2['TotalAmount per Trip'] = rev_end2['revenue']\/rev_end2['supply']\nrev_end2['TotalAmount per Trip'].plot.kde()\n","5d0bbce9":"print('Original amount per trip(Weekend):', peak_end['TotalAmount'].mean())\nrev_end2.nlargest(1, columns='revenue')","efc6901b":"### a. Based on TotalAmount","985080b4":"### b. Based on FareAmount","59fecd5a":"# **Taxi Dynamic Pricing System **   \nTeam Number: DC19022 - 1st March 2019\n____________________________________________________________________________________________________________________________________________","da2d1a2b":"## 5. TotalAmount per Trip","0d92c55d":"## 1. Data Processing","39504052":"\nIn conclusion, we seperate a week to weekday(Monday to Friday) and weekend(Saturday and Sunday), and define clusters of these two groups. We found that peak time is 12-7 pm and the off-peak time is 0-7 am on weekdays. For weekend, the peak time is 0-2 am and 2-7 pm, and the off-peak time is 4-9 am. To maximize the expected total amount per trip, the price should raise 12.79% for peak during weekday, and 22.63% during weekend peak.\n\nBased on our optimization model, when we are providing discount, the demand will increase as long as the total amount will decrease. The largest discount we can give is 100% off, since we can not exceed 100% and get negative revenue. So, this is a trade off. If we are looking for a high total amount, we should not give too much discount, such as 5% off or 10% off. If we just want to release the congestion as much as possible, we should have more discount like 70%\n","09bdc173":"### b. Basic Check of data","656fbd7a":"### b. Based on FareAmount","166b205f":"### a. Based on TotalAmount","070167d7":"## 2. Time clustering   \nTo label each hour in a day with off-peak-normal-peak, we apply **K-Means clustering** in python with scikit-learn. In the process of cleaning data, we remove the null and wrong data from dataset. Due to the different pattern between weekdays and weekend, we divide total dataset into two parts and develop clustering models separately. As a result, we found that peak time is 12-19 am and the off-peak time is 0-7 am on weekdays. For weekend, the peak time is 0-2 am and 14-19 am, and the off-peak time is 4-9 am.","33068493":"## 2. EDA","9fa3001d":"### a. Load Data\nFirst of all, we concatenate all 12 files into a total dataset file, solving wrong placement of delimiter. The total dataset file contain 12 months\u2019 data, which is over 4 GB. In order to handle this huge dataset file, we upload it to Kaggle for future processing.","661616c0":"## 4. Price Optimization for off-peak time","c68321fb":"## 3. Price Optimization for peak time"}}