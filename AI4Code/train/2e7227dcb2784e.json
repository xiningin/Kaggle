{"cell_type":{"1af3700b":"code","53935b3b":"code","559f43c6":"code","3d6e20aa":"code","d6f6105a":"code","e153a7e9":"code","9887e2a6":"code","a018d218":"code","637ffe4b":"code","5b54d660":"code","aa0bba1e":"code","36f30ce8":"code","aa14130f":"code","0b36618a":"code","fb67e556":"code","73e40026":"code","cf3194c2":"code","ccdb657f":"code","e25625c3":"code","d978a38a":"code","1d7a9d74":"code","6546544f":"code","e02114c4":"code","d9f9945b":"code","ebe49cdf":"code","bf67b6b3":"code","fc34e477":"code","2564716f":"code","cf8fb08f":"code","e148c733":"code","607cae25":"code","b22960c6":"code","4c284499":"code","3246a2f9":"code","4ba31940":"code","5dd9dc93":"code","f97fb17d":"code","28574315":"code","f9de7c66":"code","c99bcbea":"code","f4cbb49f":"code","17638d2b":"code","70f751de":"code","6cc90b73":"code","7e79fd64":"code","2d2ea4ca":"code","f143cb65":"code","0621581f":"code","9b8f55a1":"code","835ec6a8":"code","d48b94d1":"code","e894283c":"code","1c31c0e7":"code","57a0a034":"code","90642ed5":"code","47a4ab2c":"code","e9f56364":"code","f6b15d96":"code","50e48290":"code","d740990f":"code","2a32afd6":"code","42681506":"code","0ef75847":"markdown","ba01481b":"markdown","6c070d63":"markdown","d2e12360":"markdown","1051110c":"markdown","0740cddf":"markdown","7af4c50b":"markdown","2fa26624":"markdown","ecc40b20":"markdown"},"source":{"1af3700b":"#Import the packages\nimport pandas as pd\nimport numpy as np\nimport requests\nimport csv\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom scipy import stats\nfrom scipy.stats import norm, skew\nimport sklearn.metrics as metrics\nimport warnings  \nwarnings.filterwarnings('ignore')","53935b3b":"#download dataset\ndf = pd.read_excel('..\/input\/covid19\/dataset.xlsx', encoding='utf8')","559f43c6":"#Rename some important coluns to a simplier column name\ndf.rename(columns={\"Patient age quantile\": \"age_quantile\", \n                   \"SARS-Cov-2 exam result\": \"cov_2_result\",\n                   \"Patient addmited to regular ward (1=yes, 0=no)\": \"regular_ward\", \n                   \"Patient addmited to semi-intensive unit (1=yes, 0=no)\": \"semi_intensive\",\n                   \"Patient addmited to intensive care unit (1=yes, 0=no)\": \"UTI\"}, inplace= True)\n","3d6e20aa":"# Total missing values for each feature\ndf.isnull().sum()","d6f6105a":"# Total number of missing values\ndf.isnull().sum().sum()","e153a7e9":"#Let\u00b4s see the covid-19 result \ndf.cov_2_result.value_counts().plot(kind=\"bar\")","9887e2a6":"#create a dataset with only the positive results \npositive= df.loc[(df.cov_2_result == \"positive\")]\npositive.info()","a018d218":"positive.age_quantile.value_counts(ascending= False).plot(kind= \"bar\")","637ffe4b":"#mean age for patients in intensive care unit\npositive.groupby([\"UTI\"])[\"age_quantile\"].mean().plot(kind=\"bar\", alpha= 0.5)\nplt.title(\"Intensive care unit mean age\")\n","5b54d660":"#mean age of patients addmited to semi-intensive care unit\npositive.groupby([\"semi_intensive\"])[\"age_quantile\"].mean().plot(kind=\"bar\", alpha= 0.5)\nplt.title(\"Semi-intensive care unit mean age\")","aa0bba1e":"#mean age of patients addmited to regular ward\npositive.groupby([\"regular_ward\"])[\"age_quantile\"].mean().plot(kind=\"bar\", alpha= 0.5)\nplt.title(\"regular ward mean age\")","36f30ce8":"#Feature Engineering\n#missing data\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","aa14130f":"#mean of the hemoglobin for positive and negative covid-19 result\ndf.groupby([\"cov_2_result\"])[\"Hemoglobin\"].mean().plot(kind=\"bar\") ","0b36618a":"df2= df.dropna(subset=[\"Hemoglobin\"], how=\"any\")","fb67e556":"df2.info()","73e40026":"total = df2.isnull().sum().sort_values(ascending=False)\npercent = (df2.isnull().sum()\/df2.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)\n","cf3194c2":"#Drop all the columns with more than 20% missing values\ndf3 = df2.drop((missing_data[missing_data['Percent'] >= 0.60]).index,1)","ccdb657f":"df3.info()","e25625c3":"#check missing data\ntotal = df3.isnull().sum().sort_values(ascending=False)\npercent = (df3.isnull().sum()\/df3.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(15)\n","d978a38a":"df3 = df3.drop((missing_data[missing_data['Percent'] >= 0.20]).index,1)","1d7a9d74":"df3.info()","6546544f":"#check missing data\ntotal = df3.isnull().sum().sort_values(ascending=False)\npercent = (df3.isnull().sum()\/df3.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","e02114c4":"df3= df3.dropna(subset=[\"Neutrophils\"], how=\"any\")","d9f9945b":"#check missing data\ntotal = df3.isnull().sum().sort_values(ascending=False)\npercent = (df3.isnull().sum()\/df3.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","ebe49cdf":"df3= df3.dropna(subset=[\"Proteina C reativa mg\/dL\"], how=\"any\")","bf67b6b3":"#check missing data\ntotal = df3.isnull().sum().sort_values(ascending=False)\npercent = (df3.isnull().sum()\/df3.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)\n","fc34e477":"df3 = df3.drop((missing_data[missing_data['Percent'] >= 0.004]).index,1)","2564716f":"df3.info()","cf8fb08f":"#check missing data\ntotal = df3.isnull().sum().sort_values(ascending=False)\npercent = (df3.isnull().sum()\/df3.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","e148c733":"df3.head(15)","607cae25":"#mean Neutrophils for postive and negative covid-19 results\ndf3.groupby([\"cov_2_result\"])[\"Neutrophils\"].mean().plot(kind=\"bar\")","b22960c6":"#mean Proteina C reativa mg\/dL for postive and negative covid-19 results\ndf3.groupby([\"cov_2_result\"])[\"Proteina C reativa mg\/dL\"].mean().plot(kind=\"bar\")","4c284499":"#mean Mean corpuscular volume (MCV) for postive and negative covid-19 results\ndf3.groupby([\"cov_2_result\"])[\"Mean corpuscular volume (MCV)\"].mean().plot(kind=\"bar\")","3246a2f9":"#mean Leukocytes for postive and negative covid-19 results\ndf3.groupby([\"cov_2_result\"])[\"Leukocytes\"].mean().plot(kind=\"bar\")","4ba31940":"#mean Eosinophils for postive and negative covid-19 results\ndf3.groupby([\"cov_2_result\"])[\"Eosinophils\"].mean().plot(kind=\"bar\")","5dd9dc93":"#mean Basophils for postive and negative covid-19 results\ndf3.groupby([\"cov_2_result\"])[\"Basophils\"].mean().plot(kind=\"bar\")","f97fb17d":"#mean Hematocrit for postive and negative covid-19 results\ndf3.groupby([\"cov_2_result\"])[\"Hematocrit\"].mean().plot(kind=\"bar\")","28574315":"#Variables selection\nX= df3.drop([\"cov_2_result\"], axis=1)\nId= df3.loc[:, \"Patient ID\"]\ny = df3.loc[:, \"cov_2_result\"]\nX= X.drop([\"Patient ID\"], axis=1)\n\n#Transform y into a Dataframe\ny= pd.DataFrame(y)","f9de7c66":"X.info()","c99bcbea":"# Encoding categorical data\ny= pd.get_dummies(y, prefix=[\"covid\"], columns=[\"cov_2_result\"])\ny= y.drop([\"covid_negative\"], axis=1)","f4cbb49f":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","17638d2b":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","70f751de":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n","6cc90b73":"# Initialising the ANN\nclassifier = Sequential()","7e79fd64":"# Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu', input_dim = 19))\n","2d2ea4ca":"# Adding the second hidden layer\nclassifier.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu'))\n","f143cb65":"# Adding the output layer\nclassifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n","0621581f":"# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","9b8f55a1":"# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n","835ec6a8":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","d48b94d1":"print(y_pred)","e894283c":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n","1c31c0e7":"print(cm)","57a0a034":"from sklearn.metrics import accuracy_score\nprint(\"accuracy score: \", accuracy_score(y_test, y_pred))","90642ed5":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","47a4ab2c":"type(y_test)","e9f56364":"#examine the class distribution of the testig set\n#convert dataframe into series\ny_test= y_test.iloc[:,0]\ntype(y_test)","f6b15d96":"y_test.value_counts()","50e48290":"#calculate the percentage of ones\ny_test.mean()","d740990f":"#calculate the percentage of zeros\n1- y_test.mean()\n","2a32afd6":"#calculate null accuracy(for bonary classification problems coded 1\/0)\nmax(y_test.mean(), 1- y_test.mean())\n","42681506":"#calculate null accuracy(for multi-classfication problem)\ny_test.value_counts().head(1)\/len(y_test)","0ef75847":"\nLet\u00b4s drop more columns, there are too many missing values in most of the columns, if we decide to include them in our model, they might make our model way less efficient when making predictions.\nWe should not be afraid to delete the necessary columns, we don\u00b4t have much information about each patient to fulfill the missing values. In this case, it\u00b4s better to delete many columns and have good data instead of a lot of unprecise data. \n","ba01481b":"Let\u00b4s check again the missing values","6c070d63":"# Now we have a dataset with 603 rows and 22 columns, but we still have some missing values, let\u00b4s check it out the missing values one more time.","d2e12360":"Finally 0 missing values!!!!!","1051110c":"# Most of the variables have very high missing values, ranging from 76% to 99% missing values. \n\n# Patients tested positive for covid-19 present higher Hemoglobin than those tested negative.\n\n# Hemoglobin has 89% missing values, it\u00b4s a float type, this variable will be used as a parameter to delete missing rows. Float type data it\u00b4s better than categorical variables when most of the values are missing. So let\u00b4s drop any missing value for the hemoglobin","0740cddf":"# With a clean data, it\u00b4s time to more data visualization. \n# Let\u00b4s take the mean value for most of the independet variables according to the covid-19 result(positive or negative). The difference between positive and negative results are very clear.","7af4c50b":"We still have missing values, let\u00b4s drop some more columns ","2fa26624":"# Conclusion\n\nIt was a good decision to remove most of the columns and rows for the given dataset. It was also a good decision to favor only float variables since more information can be extracted by the model since many data had to be removed. \nWith Data exploration we could see that the blood test results for those with positive COVID-19 results have opposite results than those with negative COVID-19.\nArtificial neural network methodology gave us good results with a recall value of 72%. Given the lack of good data, less than 500 rows, 72% it\u00b4s a good indicator that the model might work even better with more data.\n","ecc40b20":"# Introduction\n\nAlbert Einstein Hospital data contains 111 columns and 88% missing values. The dataset is also a challenge because there isn\u00b4t any information about each patient except their age, which makes it difficult to fill out the missing data using more precise methods. Using different methods to fulfill the missing data with the mean value is great for some cases, but not for a bunch of medical exams results. \nFor all those reasons, I decided to delete every row and column necessary, I know how painful it is to delete so many missing values, but I needed clean data to get good results. \nThe methodology I choose it\u00b4s the Artificial Neural Network to predict the patients that have or not have a positive result for COVID-19.\nThe structure of the analysis is as follow:\n\n1. Import the packages and dataset\n2. Feature engineerig\n3. Variables selection\n4. Encoding categorical data\n5. Splitting the dataset into the Training set and Test set\n6. Feature Scaling\n7. Artificial neural network\n8. Predicting the Test set results\n9. Confusion Matrix\n10. Conclusion\n"}}