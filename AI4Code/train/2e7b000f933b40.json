{"cell_type":{"4590f2ea":"code","705200bc":"code","3b825e9a":"code","602ae691":"code","cf6be071":"code","17731586":"code","c64be72c":"code","77ff2e56":"code","a301e83d":"code","7084e0f0":"code","e531af68":"code","2aaf2656":"code","f182a773":"code","169001d3":"code","39ed8460":"code","5062f060":"code","e9c71d83":"code","3a304b72":"markdown","0f101dd0":"markdown","425f18a1":"markdown","ed31883b":"markdown","8e625919":"markdown","1ffe105a":"markdown","15d85cb9":"markdown"},"source":{"4590f2ea":"import pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\noriginal = pd.read_csv(\"Assignment-1_Data.csv\", delimiter=';')\ndf = original.copy()","705200bc":"df.info()","3b825e9a":"df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)","602ae691":"!pip install pycaret","cf6be071":"from pandas_profiling import ProfileReport\n\nprofile = ProfileReport(df, title=\"Pandas Profiling Report\")","17731586":"profile","c64be72c":"import missingno as msno\n%matplotlib inline\n\nmsno.matrix(df)","77ff2e56":"msno.bar(df)","a301e83d":"# We will drop all rows with NaN Itemname. \n# It makes no sense to have a model to predict which item is bought together with NaN.\ndf = df.dropna(subset=['Itemname'])","7084e0f0":"# Taking a sample of rows from the dataset, it is found that some rows are duplicated.\n# We will assume that those are due to purchasing multiple quantity of items.\n# Thus we won't drop those rows.\n\nsample = df.sample(10000)\nsample[sample.duplicated(keep=False)]","e531af68":"# Dropping weird Itemname\n\nmissing_keyword = ['missing', '?', 'throw', 'lost', 'find', 'damaged']\nunique_itemname = pd.Series(df['Itemname'].unique())\nmask = unique_itemname.apply(lambda x: x.islower() or any(i in x for i in missing_keyword))\ninvalid_itemname = unique_itemname[mask]\ninvalid_itemname","2aaf2656":"# We will drop those weird itemnames\n\ndf = df[df['Itemname'].apply(lambda x: x not in invalid_itemname.values)]","f182a773":"sample = df.sample(100000).dropna()\nby_bill = sample.groupby(['BillNo']).agg({'Quantity': 'sum', 'CustomerID': 'first'})\nbill_no_by_customer = by_bill.groupby(['CustomerID']).count()\nfg = sns.displot(bill_no_by_customer['Quantity'], kind='hist', height=6, aspect=2)\nfg.fig.suptitle(\"Distribution of number of bills per customer\")","169001d3":"unique_bill = df.groupby('BillNo').agg({'Date': 'first'}).reset_index()\nbill_by_month = unique_bill.groupby(by=pd.Grouper(key='Date', freq='M')).count()\nax = sns.lineplot(data=bill_by_month, x=bill_by_month.index.date, y='BillNo')\nplt.figure(figsize=(8, 10))\nax.set_title(\"Monthly number of bills over the year\")","39ed8460":"from pycaret.arules import *\n\nexp = setup(data=df, transaction_id='BillNo', item_id='Itemname')","5062f060":"# We have to greatly decrease the min_support threshold as the number of rows are huge\nmodel1 = create_model(threshold=0.5, min_support=0.01, low_memory=True)","e9c71d83":"model1","3a304b72":"Just doing some data visualizations","0f101dd0":"### Data Cleaning","425f18a1":"### Associative Rule Mining with PyCaret","ed31883b":"The distribution graph is right-skewed, with a few customers making unusually large amount of purchase.","8e625919":"Generally there is an increasing trend### Associative Rule Mining with PyCaret for number of transactions\/bills. The sharp decrease in monthly number of bills in 2012 is due to the fact that our dataset actually has no entries for year 2012.","1ffe105a":"### Overview","15d85cb9":"### EDA"}}