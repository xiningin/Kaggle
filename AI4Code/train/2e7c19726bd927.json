{"cell_type":{"669922f4":"code","a5f69777":"code","f9c26f0d":"code","de066ad4":"code","7b127d0d":"code","52b2e648":"code","5acd2eea":"code","a9430584":"code","0f0ceced":"code","03767004":"code","7911fc57":"code","bf5aa276":"code","10655cbd":"code","375c08d3":"code","f67f3051":"code","70a568b9":"code","f0e0e1bf":"code","efd5d91c":"code","7d4a100d":"code","8c4c23e7":"code","fa60d846":"code","3b523709":"code","413d094c":"code","e66727f5":"code","1fee5d8e":"code","0709dc4a":"code","1cbb5f1a":"code","b6833b5e":"code","5455cb2f":"code","568a789b":"code","16b57ef5":"code","4e36fe42":"code","0bf3c731":"code","db1e7e44":"code","f8a880fc":"code","e93f050d":"code","9ec8d9ab":"code","6ede201d":"code","f078e6e1":"code","7e92f61b":"code","ef79c396":"code","282056ac":"code","0ad161a0":"code","d46cbf45":"code","51ab263f":"code","5ae6bde4":"markdown","71169baf":"markdown","4aae4846":"markdown","bd866698":"markdown","49cec808":"markdown","98b0d3f7":"markdown","cdb97f01":"markdown","237ab33f":"markdown","f66ca07e":"markdown","70c95b2b":"markdown","6f5ee366":"markdown","6af44c4a":"markdown","3cf2f146":"markdown"},"source":{"669922f4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","a5f69777":"#Reading datasets train and test\ndf_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","f9c26f0d":"#Taking a copy\ntrain_copy = df_train.copy()\ntest_copy = df_test.copy()","de066ad4":"df_train.head()","7b127d0d":"df_test.head()","52b2e648":"# Review the dataset shape\ndf_train.shape, df_test.shape","5acd2eea":"#Drop ID column in train and test dataset as it has no influence over target\ndf_train.drop('Id', inplace=True, axis=1)\ndf_test.drop('Id', inplace=True, axis=1)","a9430584":"#Review dataset shape\ndf_train.shape, df_test.shape","0f0ceced":"# Handling Outliers\nplt.scatter(x=df_train['GrLivArea'], y=df_train['SalePrice'])\nplt.xlabel('Ground Live Area')\nplt.ylabel('SalePrice')\nplt.title('Sale Price VS Living Area')\nplt.show()","03767004":"#Let's remove ground area >4000\ndf_train[df_train['GrLivArea']>4000][['GrLivArea','SalePrice']]","7911fc57":"df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index","bf5aa276":"df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index, axis=0)","10655cbd":"# Review data for Outliers\nplt.scatter(x=df_train['GrLivArea'], y=df_train['SalePrice'])\nplt.xlabel('Ground Live Area')\nplt.ylabel('SalePrice')\nplt.title('Sale Price VS Living Area')\nplt.show()","375c08d3":"#Get total number of records for each dataset\nntrain = df_train.shape[0]\nntest = df_test.shape[0]\nntrain, ntest","f67f3051":"#Get target value\ny_train = df_train['SalePrice']","70a568b9":"df_alldata = pd.concat([df_train, df_test]).reset_index(drop=True)\ndf_alldata.head()","f0e0e1bf":"#Drop Target column from allData\ndf_alldata.drop('SalePrice', inplace=True, axis=1)","efd5d91c":"df_alldata.shape","7d4a100d":"#Find missing columns with missing data\nalldata_na = df_alldata.isnull().sum()\nalldata_na = alldata_na[alldata_na>0]\nalldata_na = alldata_na.sort_values(ascending=False)\nprint('Number of Cols with Null values to handle: ',len(alldata_na))","8c4c23e7":"#For selected columns below impute missing values with 'None'\nnonecols=['PoolQC','MiscFeature','Alley','Fence','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','MasVnrType','MSSubClass']\n\nfor col in nonecols:\n    df_alldata[col] = df_alldata[col].fillna('None')","fa60d846":"#For selected columns below impute missing values with 0\nzerocols = ['GarageYrBlt','GarageArea','GarageCars', 'BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','MasVnrArea']\n\nfor col in zerocols:\n    df_alldata[col]=df_alldata[col].fillna(0)","3b523709":"#For selected columns below fill null with mode\nmodecols=['MSZoning', 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType']\n\nfor col in modecols:\n    df_alldata[col] = df_alldata[col].fillna(df_alldata[col].mode()[0])","413d094c":"#Drop the Utilities column\ndf_alldata.drop('Utilities', inplace=True, axis=1)","e66727f5":"df_alldata['Functional'] = df_alldata.fillna('Typ')","1fee5d8e":"df_alldata['LotFrontage'] = df_alldata.groupby('Neighborhood')['LotFrontage'].transform(lambda x:x.fillna(x.median()))","0709dc4a":"#Review for any missing data again\nalldata_na = df_alldata.isnull().sum()\nalldata_na = alldata_na[alldata_na>0]\nprint('Cols with Missing Values: ',len(alldata_na))","1cbb5f1a":"# Transform some numeric col to categorical as they were\nnumtocatg = ['MSSubClass','OverallCond','YrSold','MoSold']\n\nfor col in numtocatg:\n    df_alldata[col] = df_alldata[col].astype(str)","b6833b5e":"#Adding one more feature\ndf_alldata['TotalSF'] = df_alldata['TotalBsmtSF'] + df_alldata['1stFlrSF'] + df_alldata['2ndFlrSF']","5455cb2f":"#Dataset with all cols\ndf_dataset = df_alldata.copy()","568a789b":"#Get Categorical col names\ncatg_cols = df_dataset.dtypes[df_dataset.dtypes=='object'].index\ncatg_cols","16b57ef5":"df_dataset.shape","4e36fe42":"#Perform One Hot Encoding without dummy variable trap\nfor col in catg_cols:\n    df_temp = df_dataset[col] #Get Col to OHE\n    df_temp = pd.get_dummies(df_temp, prefix=col)\n    tmp = df_temp.columns[0]\n    df_temp.drop(tmp, inplace=True, axis=1) #Drop a dummy variable\n    df_dataset = pd.concat([df_dataset, df_temp], axis=1) #Concate OHE cols to original DF\n    df_dataset.drop(col, inplace=True, axis=1) #Drop OHE column","0bf3c731":"df_dataset.shape","db1e7e44":"df_dataset.head()","f8a880fc":"df_train = df_dataset[:ntrain]\ndf_test = df_dataset[ntrain:]","e93f050d":"df_train.shape, df_test.shape","9ec8d9ab":"y_train.shape","6ede201d":"import xgboost as xgb\nfrom xgboost import XGBRegressor","f078e6e1":"model_xgb = XGBRegressor(objective='reg:squarederror', n_estimators=500, n_jobs=-1, gamma=0.1)","7e92f61b":"model_xgb.fit(df_train, y_train)","ef79c396":"prediction = model_xgb.predict(df_test)","282056ac":"prediction[:5]","0ad161a0":"srs_TestIds = test_copy['Id']","d46cbf45":"df_submission = pd.DataFrame({'Id':test_copy['Id'], 'SalePrice':prediction})\ndf_submission.head()","51ab263f":"df_submission.to_csv('Submission_xgb_v3.csv', index=False)","5ae6bde4":"# Secured Score - 0.13704","71169baf":"### Impute Missing Values Accordingly","4aae4846":"## Concatenate Train and Test Dataset","bd866698":"## Data Preprocessing","49cec808":"---","98b0d3f7":"# <center> My Simple Approach to predicting House Price <\/center>","cdb97f01":"---","237ab33f":"## Handling Null Values","f66ca07e":"## Model Prediction","70c95b2b":"### An up vote would be nice, if you liked it :)","6f5ee366":"### Split Training and Test Set","6af44c4a":"Thanks to Serigne's Kernel for helping in Data Transformation,  Please feel free to navigate to his kernel for more detailed analysis - https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard","3cf2f146":"## Creating Submission File"}}