{"cell_type":{"72082afe":"code","ffc4dc1a":"code","72b21d83":"code","d97c2ed2":"code","b1a43d1e":"code","b9b0190b":"code","609c5290":"code","4f90cfc2":"code","463dfd94":"code","b6becec0":"code","d0a5ed90":"code","9c36903b":"code","ac8a139d":"code","dd71f2e5":"code","f4a62890":"code","c7f5bda8":"code","d56ce418":"code","273f05b6":"code","b7f04752":"code","f98abb5e":"code","4b5d6036":"code","cc0f9bc7":"code","dcdef557":"code","0a6dcf24":"code","fc54a6eb":"code","0296af49":"code","975fb74b":"code","f6c05443":"code","0e6cd010":"code","7cb8aae0":"code","9a0108fd":"code","e9767b26":"code","ef606552":"code","d3558059":"code","c4b38d9f":"code","9899ccb2":"code","b86ad9a1":"code","6276061d":"code","ed5c86f1":"code","2fdaabf8":"code","e474a898":"code","11aba664":"code","d01e6bdc":"code","1cc77a0e":"code","3fd92346":"code","46aa9c08":"code","18af1210":"code","9db29971":"code","5a200e4b":"code","2a8032ae":"code","9e7181dc":"code","bfa950b4":"code","d4128113":"code","017ebe6b":"code","5b5b9682":"code","ee7a23fc":"code","f47af2db":"code","78dee819":"code","773a7147":"code","78f99ef0":"code","ef65456b":"code","112b1a31":"code","094b0d36":"code","faa2a44b":"markdown","2462fa7a":"markdown","a9e98b7d":"markdown","45f61dfa":"markdown","c04057c6":"markdown","3c062e5e":"markdown"},"source":{"72082afe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ffc4dc1a":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy \nimport skimage.external.tifffile as skimg\nfrom skimage.io import imread,imshow\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize","72b21d83":"im  = imread('\/kaggle\/input\/lgg-mri-segmentation\/lgg-mri-segmentation\/kaggle_3m\/TCGA_DU_7298_19910324\/TCGA_DU_7298_19910324_14.tif')","d97c2ed2":"imshow(im)","b1a43d1e":"grayim = rgb2gray(im)","b9b0190b":"imshow(grayim)","609c5290":"from skimage.exposure import histogram\nhist, hist_centers = histogram(grayim)","4f90cfc2":"markers = np.zeros_like(grayim)\nmarkers[grayim < 30] = 1\nmarkers[grayim > 150] = 2","463dfd94":"from skimage.filters import sobel\nelevation_map = sobel(grayim)","b6becec0":"imshow(elevation_map)","d0a5ed90":"from skimage.segmentation import watershed\nsegmentation = watershed(elevation_map, markers)","9c36903b":"from skimage.feature import canny\nedges = canny(grayim)","ac8a139d":"imshow(edges)","dd71f2e5":"import cv2 as cv\nimport numpy as np\nimport argparse\nfrom skimage.io import imread,imshow","f4a62890":"W = 52          # window size is WxW\nC_Thr = 0.43    # threshold for coherency\nLowThr = 35     # threshold1 for orientation, it ranges from 0 to 180\nHighThr = 57    # threshold2 for orientation, it ranges from 0 to 180","c7f5bda8":"def calcGST(inputIMG, w):\n    img = inputIMG.astype(np.float32)\n    # GST components calculation (start)\n    # J =  (J11 J12; J12 J22) - GST\n    imgDiffX = cv.Sobel(img, cv.CV_32F, 1, 0, 3)\n    imgDiffY = cv.Sobel(img, cv.CV_32F, 0, 1, 3)\n    imgDiffXY = cv.multiply(imgDiffX, imgDiffY)\n    \n    imgDiffXX = cv.multiply(imgDiffX, imgDiffX)\n    imgDiffYY = cv.multiply(imgDiffY, imgDiffY)\n    J11 = cv.boxFilter(imgDiffXX, cv.CV_32F, (w,w))\n    J22 = cv.boxFilter(imgDiffYY, cv.CV_32F, (w,w))\n    J12 = cv.boxFilter(imgDiffXY, cv.CV_32F, (w,w))\n    # GST components calculations (stop)\n    # eigenvalue calculation (start)\n    # lambda1 = J11 + J22 + sqrt((J11-J22)^2 + 4*J12^2)\n    # lambda2 = J11 + J22 - sqrt((J11-J22)^2 + 4*J12^2)\n    tmp1 = J11 + J22\n    tmp2 = J11 - J22\n    tmp2 = cv.multiply(tmp2, tmp2)\n    tmp3 = cv.multiply(J12, J12)\n    tmp4 = np.sqrt(tmp2 + 4.0 * tmp3)\n    lambda1 = tmp1 + tmp4    # biggest eigenvalue\n    lambda2 = tmp1 - tmp4    # smallest eigenvalue\n    # eigenvalue calculation (stop)\n    # Coherency calculation (start)\n    # Coherency = (lambda1 - lambda2)\/(lambda1 + lambda2)) - measure of anisotropism\n    # Coherency is anisotropy degree (consistency of local orientation)\n    imgCoherencyOut = cv.divide(lambda1 - lambda2, lambda1 + lambda2)\n    # Coherency calculation (stop)\n    # orientation angle calculation (start)\n    # tan(2*Alpha) = 2*J12\/(J22 - J11)\n    # Alpha = 0.5 atan2(2*J12\/(J22 - J11))\n    imgOrientationOut = cv.phase(J22 - J11, 2.0 * J12, angleInDegrees = True)\n    imgOrientationOut = 0.5 * imgOrientationOut\n    # orientation angle calculation (stop)\n    return imgCoherencyOut, imgOrientationOut\n","d56ce418":"imgIn = cv.imread('\/kaggle\/input\/lgg-mri-segmentation\/lgg-mri-segmentation\/kaggle_3m\/TCGA_DU_7298_19910324\/TCGA_DU_7298_19910324_14.tif', cv.IMREAD_GRAYSCALE)\n","273f05b6":"if imgIn is None:\n    print('Could not open or find the image: {}'.format(args.input))\n    exit(0)\nelse:\n    print('got it')\n","b7f04752":"imgCoherency, imgOrientation = calcGST(imgIn, W)\n_, imgCoherencyBin = cv.threshold(imgCoherency, C_Thr, 255, cv.THRESH_BINARY)\n_, imgOrientationBin = cv.threshold(imgOrientation, LowThr, HighThr, cv.THRESH_BINARY)","f98abb5e":"imgBin = cv.bitwise_and(imgCoherencyBin, imgOrientationBin)\nimgCoherency = cv.normalize(imgCoherency, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\nimgOrientation = cv.normalize(imgOrientation, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n","4b5d6036":"imshow(np.uint8(0.5*(imgIn + imgBin)))","cc0f9bc7":"imshow(imgOrientation)","dcdef557":"imshow(imgCoherency)","0a6dcf24":"from __future__ import print_function\nimport cv2 as cv\nimport numpy as np\nimport argparse\nimport random as rng\nfrom skimage.io import imread,imshow","fc54a6eb":"src = cv.imread('\/kaggle\/input\/lgg-mri-segmentation\/lgg-mri-segmentation\/kaggle_3m\/TCGA_DU_7298_19910324\/TCGA_DU_7298_19910324_14.tif')","0296af49":"# Show source image\nimshow(src)","975fb74b":"kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)","f6c05443":"# do the laplacian filtering as it is\n# well, we need to convert everything in something more deeper then CV_8U\n# because the kernel has some negative values,\n# and we can expect in general to have a Laplacian image with negative values\n# BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255\n# so the possible negative number will be truncated\nimgLaplacian = cv.filter2D(src, cv.CV_32F, kernel)\nsharp = np.float32(src)\nimgResult = sharp - imgLaplacian","0e6cd010":"# convert back to 8bits gray scale\nimgResult = np.clip(imgResult, 0, 255)\nimgResult = imgResult.astype('uint8')\nimgLaplacian = np.clip(imgLaplacian, 0, 255)\nimgLaplacian = np.uint8(imgLaplacian)","7cb8aae0":"# new sharpened img\nimshow(imgResult)","9a0108fd":"bw = cv.cvtColor(imgResult, cv.COLOR_BGR2GRAY)\n_, bw = cv.threshold(bw, 40, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n#binary image\nimshow( bw)","e9767b26":"dist = cv.distanceTransform(bw, cv.DIST_L2, 3)\n# Normalize the distance image for range = {0.0, 1.0}\n# so we can visualize and threshold it\ncv.normalize(dist, dist, 0, 1.0, cv.NORM_MINMAX)\n#Distance Transform Image\nimshow( dist)","ef606552":"_, dist = cv.threshold(dist, 0.4, 1.0, cv.THRESH_BINARY)\n# Dilate a bit the dist image\nkernel1 = np.ones((3,3), dtype=np.uint8)\ndist = cv.dilate(dist, kernel1)\n#Peaks\nimshow( dist)\n","d3558059":"dist_8u = dist.astype('uint8')\n# Find total markers\ncontours, _ = cv.findContours(dist_8u, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n# Create the marker image for the watershed algorithm\nmarkers = np.zeros(dist.shape, dtype=np.int32)\n# Draw the foreground markers\nfor i in range(len(contours)):\n    cv.drawContours(markers, contours, i, (i+1), -1)\n# Draw the background marker\ncv.circle(markers, (5,5), 3, (255,255,255), -1)\n#Markers\nimshow( markers*10000)","c4b38d9f":"cv.watershed(imgResult, markers)","9899ccb2":"mark = markers.astype('uint8')\nmark = cv.bitwise_not(mark)\n## Markers_v2\nimshow( mark)","b86ad9a1":"# Generate random colors\ncolors = []\nfor contour in contours:\n    colors.append((rng.randint(0,256), rng.randint(0,256), rng.randint(0,256)))\n# Create the result image\ndst = np.zeros((markers.shape[0], markers.shape[1], 3), dtype=np.uint8)\n# Fill labeled objects with random colors\nfor i in range(markers.shape[0]):\n    for j in range(markers.shape[1]):\n        index = markers[i,j]\n        if index > 0 and index <= len(contours):\n            dst[i,j,:] = colors[index-1]","6276061d":"# Visualize the final image\nimshow( dst)","ed5c86f1":"from skimage.filters import sobel_h\nimport matplotlib.pyplot as plt\n\nimage = imread('\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_CS_6669_20020102\/TCGA_CS_6669_20020102_10.tif', as_gray=True)\nimage_sobelh = sobel_h(image)\n\n# plotting images\nplt.subplot(121), imshow(image)\nplt.title('Original Image')\n\nplt.subplot(122),imshow(image_sobelh)\nplt.title('Horizontal Edge')\n\nplt.show()","2fdaabf8":"import numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom skimage.io import imread,imshow","e474a898":"img = cv2.imread('\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_CS_6669_20020102\/TCGA_CS_6669_20020102_10.tif')\n\n#lets improve the sharpness of the image before converting to gray\nkernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)\nimgLaplacian = cv2.filter2D(img, cv2.CV_32F, kernel)\nsharp = np.float32(img)\nimgResult = sharp - imgLaplacian\n\n# convert back to 8bits gray scale\nimgResult = np.clip(imgResult, 0, 255)\nimgResult = imgResult.astype('uint8')\nimgLaplacian = np.clip(imgLaplacian, 0, 255)\nimgLaplacian = np.uint8(imgLaplacian)\n\n\nimshow(imgResult)","11aba664":"gray = cv2.cvtColor(imgResult,cv2.COLOR_BGR2GRAY)\nret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)","d01e6bdc":"from skimage.feature import canny\nedges = canny(gray)","1cc77a0e":"imshow(edges)","3fd92346":"imshow(img)","46aa9c08":"imshow(thresh)","18af1210":"# noise removal\nkernel = np.ones((3,3),np.uint8)\nopening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n\n# sure background area\nsure_bg = cv2.dilate(opening,kernel,iterations=3)\n\n# Finding sure foreground area\ndist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\nret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n\n# Finding unknown region\nsure_fg = np.uint8(sure_fg)\nunknown = cv2.subtract(sure_bg,sure_fg)","9db29971":"imshow(unknown)","5a200e4b":"# Marker labelling\nret, markers = cv2.connectedComponents(sure_fg)\n\n# Add one to all labels so that sure background is not 0, but 1\nmarkers = markers+1\n\n# Now, mark the region of unknown with zero\nmarkers[unknown==255] = 0","2a8032ae":"imshow(markers)","9e7181dc":"markers = cv2.watershed(img,markers)\nimg[markers == -1] = [255,0,0]","bfa950b4":"imshow(markers)","d4128113":"import numpy as np\nimport matplotlib.pyplot as plt\nimport skimage.data as data\nimport skimage.segmentation as seg\nimport skimage.filters as filters\nimport skimage.draw as draw\nimport skimage.color as color\nimport cv2","017ebe6b":"def image_show(image, nrows=1, ncols=1, cmap='gray'):\n    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 14))\n    ax.imshow(image, cmap='gray')\n    ax.axis('off')\n    return fig, ax","5b5b9682":"image = cv2.imread('\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_CS_6669_20020102\/TCGA_CS_6669_20020102_10.tif')","ee7a23fc":"imshow(image)","f47af2db":"image_slic = seg.slic(image,n_segments=155)","78dee819":"image_show(color.label2rgb(image_slic, image, kind='avg'))","773a7147":"image_felzenszwalb = seg.felzenszwalb(image) \nimage_show(image_felzenszwalb)","78f99ef0":"np.unique(image_felzenszwalb).size","ef65456b":"image_felzenszwalb_colored = color.label2rgb(image_felzenszwalb, image, kind='avg')\nimage_show(image_felzenszwalb_colored)","112b1a31":"from skimage.feature import canny\ngray = cv2.cvtColor(image_felzenszwalb_colored,cv2.COLOR_BGR2GRAY)\nret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\nedges = canny(gray)","094b0d36":"image_show(edges)","faa2a44b":"# Image Segmentation with Watershed Algorithm","2462fa7a":"# sobel filter ","a9e98b7d":"# SLIC( Simple Linear Iterative Clustering)","45f61dfa":"# Felzenszwalb","c04057c6":"# Image Segmentation with Distance Transform and Watershed Algorithm","3c062e5e":"# Anisotropic image segmentation by a gradient structure tensor"}}