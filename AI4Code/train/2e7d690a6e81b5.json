{"cell_type":{"d98f76c3":"code","07933764":"code","afa83710":"code","434a44d6":"code","96a1aad2":"code","f4968826":"code","21126ef4":"code","850ae36c":"code","793abd94":"code","d81a08cc":"code","8bbebecd":"code","cdb197a3":"code","bb1e3d42":"code","93e1f8ed":"code","19ced722":"code","4e27945d":"code","7dd5df19":"code","24f17464":"code","56795525":"code","c0f2c0ff":"code","57e4c079":"code","e0729d59":"code","47e8b061":"code","c96b30dd":"code","846d3b07":"code","e504482b":"code","b0fa95ac":"code","4810ed45":"code","42f30b0b":"markdown","ed570670":"markdown","aa915b97":"markdown","2f6c24b9":"markdown","7c47a80e":"markdown"},"source":{"d98f76c3":"import os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB2\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\ndata_dir = '\/kaggle\/input\/petfinder-pawpularity-score'\n# need to Add Data petfinder-pawpularity-score at the right sidebar\ntrain = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ntest = pd.read_csv(os.path.join(data_dir, 'test.csv'))\nsample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))","07933764":"train.head()","afa83710":"sample_submission","434a44d6":"test.head()","96a1aad2":"def convert_id_to_jpg(Id: str) -> str:\n    return f'{Id}.jpg'","f4968826":"sample_train_image_fn = os.path.join(data_dir, 'train', convert_id_to_jpg(train['Id'][0]))\nsample_test_image_fn = os.path.join(data_dir, 'test', convert_id_to_jpg(test['Id'][0]))","21126ef4":"image_shape_list = [PIL.Image.open(os.path.join(data_dir, 'train', convert_id_to_jpg(ids))).size for ids in train['Id']]\n\ndf_image_shape = pd.DataFrame()\ndf_image_shape['image_shape'] = image_shape_list\ndf_image_shape","850ae36c":"df_image_shape['image_shape'].value_counts() \/ df_image_shape.shape[0] * 100","793abd94":"print(df_image_shape['image_shape'].apply(lambda x: x[0]).mean())\nprint(df_image_shape['image_shape'].apply(lambda x: x[1]).mean())","d81a08cc":"# mininum image size\ndf_image_shape['image_shape'].min()","8bbebecd":"# maximum image size\ndf_image_shape['image_shape'].max()","cdb197a3":"sample_train_image = PIL.Image.open(sample_train_image_fn)\nprint(sample_train_image.size)\nsample_train_image","bb1e3d42":"# Example Test Data\n# In addition to the training data, we include some randomly generated example test data to help you author submission code. \n# When your submitted notebook is scored, this example data will be replaced by the actual test data (including the sample submission).\n# The actual test data comprises about 6800 pet photos similar to the training set photos.\n\n# need to check actual test data set size is 128*128 or 405, 720\nsample_test_image = PIL.Image.open(sample_test_image_fn)\nprint(sample_test_image.size)\nsample_test_image","93e1f8ed":"train.describe()","19ced722":"test.describe()","4e27945d":"# Reference: \n# https:\/\/www.kaggle.com\/awsaf49\/tf-petfinder-image-tpu-train?scriptVersionId=77237363&cellId=39\n# https:\/\/keras.io\/examples\/vision\/image_classification_efficientnet_fine_tuning\/","7dd5df19":"IMG_SIZE = 224\ntarget_size = [IMG_SIZE, IMG_SIZE]\ninput_shape = (*target_size, 3)\nbatch_size = 32\nKFOLD = 5\nTRAIN = True\nIS_NORMALIZE_TARGET = True","24f17464":"def decode(path):\n    file_bytes = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(file_bytes, channels=3)\n    # forcefully resize & casting image is critical. \n    # keep origin image format and use efficientnet preprocessing\n    img = tf.cast(tf.image.resize_with_pad(img, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n    return tf.keras.applications.efficientnet.preprocess_input(img)","56795525":"def decode_with_labels(path, label):\n    return decode(path), tf.cast(label, tf.float32) if label is not None else None","c0f2c0ff":"def build_dataset(df: pd.DataFrame, is_train: bool = True):\n    img_path_list = df['Id'].apply(lambda x: os.path.join(data_dir, 'train' if is_train else 'test', convert_id_to_jpg(x))).tolist()\n    target = df['Pawpularity'].tolist() if is_train else None\n    \n    ds = tf.data.Dataset.from_tensor_slices((img_path_list, target))\n    if is_train:\n        ds = ds.repeat()\n    ds = ds.map(decode_with_labels, tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n    steps_per_epoch = df.shape[0] \/\/ batch_size\n    return ds, steps_per_epoch","57e4c079":"skf = KFold(n_splits=KFOLD, random_state=123, shuffle=True)\n\n\ntrain['fold'] = -1\n\nfor nth, (_, valid_index) in enumerate(skf.split(train)):\n    train.loc[valid_index, 'fold'] = nth","e0729d59":"# skf = StratifiedKFold(n_splits=KFOLD, random_state=123, shuffle=True)\n\n# train['fold'] = -1\n\n# for nth, (_, valid_index) in enumerate(skf.split(train, train['Pawpularity'])):\n#     train.loc[valid_index, 'fold'] = nth","47e8b061":"def build_model(input_shape=(*target_size, 3), drop_rate=0.20, use_img_augmentation=False):\n    \n    img_augmentation = Sequential(\n        [\n            layers.experimental.preprocessing.RandomRotation(factor=0.15),\n            layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n            layers.experimental.preprocessing.RandomFlip(),\n            layers.experimental.preprocessing.RandomContrast(factor=0.1),\n            layers.experimental.preprocessing.RandomCrop(IMG_SIZE, IMG_SIZE, seed=123),\n#             layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE)\n        ],\n        name=\"img_augmentation\",\n    )\n    \n    inputs = layers.Input(shape=input_shape)\n    x = img_augmentation(inputs) if use_img_augmentation else inputs\n\n    # downloaded pre-trained weights from tensorflow applications Efficientnet\n    # Downloading data from https:\/\/storage.googleapis.com\/keras-applications\/efficientnetb2_notop.h5\n    # !wget https:\/\/storage.googleapis.com\/keras-applications\/efficientnetb2_notop.h5\n    # load noisy-student pretrained weights with tf.applications.EfficientNetB2 failed.\n    pre_trained_model = '\/kaggle\/input\/efficientnetb2\/efficientnetb2_notop.h5'\n    model = EfficientNetB2(include_top=False, input_tensor=x, weights=pre_trained_model)\n\n#     # Freeze the pretrained weights\n#     model.trainable = False\n\n    # Rebuild top\n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)    \n    x = layers.Dense(128, activation='relu')(x)\n    # dropout to reduce overfitting.\n    x = layers.Dropout(drop_rate, name=\"top_dropout\")(x)\n    outputs = layers.Dense(1, activation=\"relu\", name=\"pred\")(x)\n\n\n    # Compile\n    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), \n        loss='mse', \n        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n    )\n    return model","c96b30dd":"def train_model(fold_idx: int) -> tf.keras.Model:\n    # without augmentation CV RMSE 17.XX train RMSE 19.XX\n    train_ds, train_steps = build_dataset(train[train['fold'] != fold_idx], True)\n    valid_ds, valid_steps = build_dataset(train[train['fold'] == fold_idx], True)\n    \n    tf.keras.backend.clear_session()\n    \n    monitor = 'val_loss'\n    best_weights_only = True\n\n#     checkpoint_path = f'model_ckpt_{fold_idx}'\n#     checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    es = tf.keras.callbacks.EarlyStopping(patience=3, monitor=monitor, restore_best_weights=best_weights_only)\n#     cp = tf.keras.callbacks.ModelCheckpoint(\n#         filepath=checkpoint_path,\n#         monitor=monitor,\n#         save_best_only=best_weights_only,\n#         save_weights_only=True,\n#     )\n\n    model = build_model(use_img_augmentation=False)\n    \n    model.fit(\n        train_ds, \n        steps_per_epoch=train_steps, \n        validation_data=valid_ds, \n        validation_steps=valid_steps, \n        epochs=100, \n        callbacks=[es]\n    )\n    return model","846d3b07":"def test_model(model: tf.keras.Model) -> np.ndarray:\n    test_ds, test_steps = build_dataset(test, False)\n\n    predicted_list = []\n    for inputs, _ in test_ds:\n        predicted = model(inputs)\n        predicted_list.append(predicted.numpy())\n        \n    return np.concatenate(predicted_list)","e504482b":"def valid_model(model: tf.keras.Model, i: int):\n    valid_ds, valid_steps = build_dataset(train[train['fold'] == i], True)\n\n    valid_predicted_list, valid_output_list = [], []\n\n    for steps, (inputs, outputs) in enumerate(valid_ds):\n        if steps >= valid_steps:\n            break\n\n        predicted = model(inputs)\n        valid_predicted_list.append(predicted.numpy())\n        valid_output_list.append(outputs.numpy())\n\n    valid_predicted_arr = np.concatenate(valid_predicted_list)\n    valid_output_arr = np.concatenate(valid_output_list)\n    print('='*20, f'{i}', '='*20)\n    print(f'validation RMSE: {np.mean((valid_output_arr - valid_predicted_arr)**2)**0.5}\\n')","b0fa95ac":"test_pred_list = []\n\nfor i in range(KFOLD):    \n    model = train_model(i)\n\n    predicted = test_model(model)\n    test_pred_list.append(predicted)\n    \npred_arr = np.mean(test_pred_list, axis=0)","4810ed45":"sample_submission['Pawpularity'] = pred_arr\nsample_submission.to_csv('submission.csv',index=False)\nsample_submission","42f30b0b":"# meta data information","ed570670":"# train image shape","aa915b97":"# build model","2f6c24b9":"# build tf dataset","7c47a80e":"# load data"}}