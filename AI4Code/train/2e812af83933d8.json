{"cell_type":{"1d99c2d5":"code","2333ae4b":"code","73e540ab":"code","0f6c2e18":"code","5bf47762":"code","0698f04c":"code","917b71ed":"code","405825bb":"code","26307be5":"code","639d196c":"code","7dde8fc3":"code","da2511fa":"code","e85a5846":"code","97bdda67":"code","ac543e1a":"code","8eff795c":"code","c7b4ba6a":"code","15f2ab82":"markdown","ed774de6":"markdown","6f2d8db7":"markdown","ab42c835":"markdown","039a9ea6":"markdown","5bed3bd2":"markdown","3f6b21b6":"markdown"},"source":{"1d99c2d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2333ae4b":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator","73e540ab":"gen = ImageDataGenerator(rescale=1.\/255,validation_split = 0.2,zoom_range=(0.99,0.99),dtype=tf.float32)","0f6c2e18":"train = gen.flow_from_directory(\"\/kaggle\/input\/brian-tumor-dataset\/Brain Tumor Data Set\/Brain Tumor Data Set\/\",\n                               target_size = (150,150),\n                               batch_size = 256,\n                               class_mode = \"binary\",\n                               color_mode = \"rgb\",\n                               shuffle = True,\n                               seed = 123,\n                               subset = \"training\")","5bf47762":"val = gen.flow_from_directory(\"\/kaggle\/input\/brian-tumor-dataset\/Brain Tumor Data Set\/Brain Tumor Data Set\/\",\n                               target_size = (150,150),\n                               batch_size = 8,\n                               class_mode = \"binary\",\n                               color_mode = \"rgb\",\n                               shuffle = True,\n                               seed = 123,\n                               subset = \"validation\")\nclasses = val.class_indices","0698f04c":"classes","917b71ed":"import seaborn as sns","405825bb":"t=0\nh=0\nfor i in range(15):\n    a, b = next(train)\n    for j in b:\n        if j == 1:\n            h+=1\n        else:t+=1\n\nsns.barplot(x=['tumor','healty'],y=[t,h])\n    ","26307be5":"import matplotlib.pyplot as plt\nbatch = next(train)\n\nplt.imshow(batch[0][0])","639d196c":"from keras.layers import Conv2D, MaxPool2D, LeakyReLU, BatchNormalization, Dropout, Dense, InputLayer, Flatten\nfrom keras.losses import BinaryCrossentropy\nfrom keras.optimizers import Adam","7dde8fc3":"model = keras.Sequential()\nmodel.add(InputLayer(input_shape=(150,150,3)))\nmodel.add(Conv2D(filters=32,kernel_size=3, activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(filters=64,kernel_size=3, activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPool2D())\n\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate=0.3))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate=0.3))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\n\nmodel.compile(optimizer=Adam(0.001),loss = BinaryCrossentropy(),metrics=['accuracy'])\n","da2511fa":"model.summary()","e85a5846":"tf.keras.utils.plot_model(\n    model, to_file='model.png', show_shapes=True,\n    show_layer_names=True,\n)","97bdda67":"from keras import utils, callbacks\nearlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n                                        patience=5, restore_best_weights = True)","ac543e1a":"history = model.fit(train,verbose=1,callbacks = [earlystopping],epochs=20,validation_data=(val))","8eff795c":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","c7b4ba6a":"plt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","15f2ab82":"# Plotting loss","ed774de6":"# Next step: Actually create a test set!\n# This model will be sufficient for this task, so no need for a bigger model.","6f2d8db7":"# Simple cnn","ab42c835":"# Plotting accuracy","039a9ea6":"# With grayscale as color mode we get high spikes in validation loss in training and substantially lower accuracy compared with a dataset with rgb color mode.","5bed3bd2":"# Model plot","3f6b21b6":"# Class distribution in training dataset"}}