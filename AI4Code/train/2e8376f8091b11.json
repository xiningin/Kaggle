{"cell_type":{"302dece7":"code","c1a1f406":"code","ecee01e2":"code","2ea6ac0f":"code","5fe91bbd":"code","9317dec0":"code","827e3961":"code","a4af8297":"code","31a0a3c5":"code","58ac5509":"code","b0d7fe03":"code","da0f7925":"code","b42c5c00":"code","85d06620":"code","64a83fe7":"code","2c0a4a26":"code","08f10b8a":"code","22572b25":"code","ef4bca93":"code","08f3aba3":"code","2113a9bb":"code","f085da43":"code","a1a65f93":"code","e56f67c4":"code","f949d8e9":"markdown","656787ae":"markdown","43455ee7":"markdown","c9ce918a":"markdown","01593baa":"markdown","0ec82a47":"markdown","4652b21c":"markdown","31ccc23a":"markdown","4abeba33":"markdown","0569085a":"markdown","a1ecd77c":"markdown","556b40c5":"markdown","051e3423":"markdown","843ef78a":"markdown","fb8a7f2e":"markdown","eba9776a":"markdown","ef2aa52e":"markdown","07150c50":"markdown","f522ba82":"markdown"},"source":{"302dece7":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","c1a1f406":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score","ecee01e2":"import warnings\nwarnings.filterwarnings(\"ignore\")","2ea6ac0f":"path = '\/kaggle\/input\/santander-customer-transaction-prediction\/'\nos.listdir(path)","5fe91bbd":"train_data = pd.read_csv(path+'train.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","9317dec0":"print('number of train samples:', len(train_data))\nprint('number of test samples:', len(test_data))\nprint('number of features:', len(train_data.columns)-2)","827e3961":"train_data['target'].value_counts()","a4af8297":"train_data.isnull().sum().sum(), test_data.isnull().sum().sum()","31a0a3c5":"pca = PCA().fit(train_data[train_data.columns[2:]])\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('No of components')\nplt.ylabel('Cumulative explained variance')\nplt.grid()\nplt.show()","58ac5509":"train_data['sum'] = train_data[train_data.columns[2:202]].sum(axis=1)\ntest_data['sum'] = test_data[test_data.columns[1:201]].sum(axis=1)\ntrain_data['mean'] = train_data[train_data.columns[2:202]].mean(axis=1)\ntest_data['mean'] = test_data[test_data.columns[1:201]].mean(axis=1)\ntrain_data['std'] = train_data[train_data.columns[2:202]].std(axis=1)\ntest_data['std'] = test_data[test_data.columns[1:201]].std(axis=1)\ntrain_data['min'] = train_data[train_data.columns[2:202]].min(axis=1)\ntest_data['min'] = test_data[test_data.columns[1:201]].min(axis=1)\ntrain_data['max'] = train_data[train_data.columns[2:202]].max(axis=1)\ntest_data['max'] = test_data[test_data.columns[1:201]].max(axis=1)","b0d7fe03":"def plot_distrubution():\n    fig, axs = plt.subplots(2, 5, figsize=(20, 5))\n    fig.subplots_adjust(hspace = 0.5, wspace=0.2)\n    axs = axs.ravel()\n    features = ['sum', 'mean', 'std', 'min', 'max']\n    bins = 50\n    for col in range(5):\n        axs[col].hist(train_data[features[col]], bins=bins, color='blue', alpha=0.7)\n        axs[col+5].hist(test_data[features[col]], bins=bins, color='red', alpha=0.7)\n        axs[col].set_title(features[col]+' - train')\n        axs[col+5].set_title(features[col]+' - test')\n        axs[col].set_ylabel('Frequence')\n        axs[col+5].set_ylabel('Frequence')\n        axs[col].grid()\n        axs[col+5].grid()\n        axs[col].set_yticks([])\n        axs[col+5].set_yticks([])","da0f7925":"plot_distrubution()","b42c5c00":"X_train = train_data[train_data.columns[2:]]\ny_train = train_data['target']\nX_test = test_data[test_data.columns[1:]]","85d06620":"assert(len(X_train.columns) == len(X_test.columns))","64a83fe7":"print('number of train samples:', len(X_train))\nprint('number of test samples:', len(X_test))","2c0a4a26":"min_max = MinMaxScaler()\nX_train = min_max.fit_transform(X_train)\nX_test = min_max.transform(X_test)","08f10b8a":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=2020)","22572b25":"print('number of train samples:', len(X_train))\nprint('number of val samples:', len(X_val))","ef4bca93":"model = xgb.XGBRegressor(objective='binary:logistic',\n                         n_estimators=300)\nmodel.fit(X_train, y_train)","08f3aba3":"y_val_pred = model.predict(X_val)\nroc_auc_score(y_val, y_val_pred)","2113a9bb":"y_test = model.predict(X_test)","f085da43":"output = pd.DataFrame({'ID_code': samp_subm['ID_code'],\n                       'target': y_test})","a1a65f93":"output['target'].describe()","e56f67c4":"output.to_csv('submission.csv', index=False)","f949d8e9":"# Model","656787ae":"# Write Output","43455ee7":"# Split Train And Val","c9ce918a":"This is a big dataset with 200,000 samples and 200 features:","01593baa":"Plot the distribution of the new features for train (upper row) and test (lower row) data:","0ec82a47":"# Intro\nWelcome to the [Santander Customer Transaction Prediction](https:\/\/www.kaggle.com\/c\/santander-customer-transaction-prediction\/overview)\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/10385\/logos\/header.png)\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. <\/span>","4652b21c":"# Define Train and Test Data","31ccc23a":"# Overview","4abeba33":"# Path\nDefine the input path and show the content of the input folder:","0569085a":"# PCA\nWe want to analyse if we can reduce the dimension of the features:","a1ecd77c":"# Libraries\nWe load some standard libraries and packages of sklearn.","556b40c5":"There are no missing values on the train and test data:","051e3423":"Predict test data:","843ef78a":"# Load Data","fb8a7f2e":"The target distribution is very imbalanced:","eba9776a":"From the cumulative variance, overall 99% is being captured by about 150 components. Hence, we can decide that the number of principal components for our dataset is 150. This is a reduction about 25%.","ef2aa52e":"# Scale Data","07150c50":"Predict validation data:","f522ba82":"# Feature Engineering\nFor every sample (row) we add the statistical features sum, mean, std, min and max:"}}