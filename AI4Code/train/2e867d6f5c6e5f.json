{"cell_type":{"d1b76b0a":"code","4c8caece":"code","85e9bac5":"code","a3583e60":"code","e5ced17d":"code","1f102851":"code","3b1cbbdc":"code","97c29895":"code","fb1e7937":"code","00d6e2bf":"code","ee9fe568":"code","97bdceab":"code","d4d6c082":"code","dba54229":"code","51b30b83":"code","7b69a902":"code","cffbb4cf":"code","f9b510bd":"code","81b965c5":"markdown","bb42ffe4":"markdown","bee75821":"markdown","926cfa97":"markdown","ed8e20fd":"markdown","4489779b":"markdown","caf1ddb5":"markdown","099cb0d0":"markdown"},"source":{"d1b76b0a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Sequential\nimport PIL\nimport pathlib","4c8caece":"import os\n\ndirectories = os.listdir('..\/input\/plant-village\/PlantVillage')\nfor directory in directories:\n    print(directory)","85e9bac5":"!cp -rf ..\/input\/plant-village\/PlantVillage\/Pepper__bell___Bacterial_spot .\/Pepper__bell___Bacterial_spot","a3583e60":"!cp -rf ..\/input\/plant-village\/PlantVillage\/Pepper__bell___healthy .\/Pepper__bell___healthy","e5ced17d":"CURRENT_DIR = os.getcwd()\ndataset_dir = pathlib.Path(CURRENT_DIR)\nprint(dataset_dir)","1f102851":"healthy_leaf = len(list(dataset_dir.glob('Pepper__bell___healthy\/*')))\nunhealthy_leaf = len(list(dataset_dir.glob('Pepper__bell___Bacterial_spot\/*')))\nprint(f'Number of Pepper_bell_healthy leaf: {healthy_leaf}')\nprint(f'Number of Pepper_bell_Bacterial_spot leaf: {unhealthy_leaf}')","3b1cbbdc":"BATCH_SIZE = 32\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nCHANNELS = 3\n\n# Training dataset\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    directory=dataset_dir,\n    batch_size=BATCH_SIZE,\n    validation_split=0.2,\n    subset='training',\n    seed=42,\n    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n)","97c29895":"# Validation dataset\nvalid_ds = tf.keras.utils.image_dataset_from_directory(\n    directory=dataset_dir,\n    batch_size=BATCH_SIZE,\n    validation_split=0.2,\n    subset='validation',\n    seed=42,\n    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n)","fb1e7937":"class_names = train_ds.class_names\nprint(class_names)","00d6e2bf":"plt.figure(figsize=(15,15))\nfor image, label in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i+1)\n        plt.imshow(image[i].numpy().astype('uint8'))\n        plt.title(class_names[label[i]])\n        plt.axis('off')\n        plt.tight_layout","ee9fe568":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nvalid_ds = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)","97bdceab":"numb_classes = 2\n\nmodel = Sequential([\n    layers.Rescaling(1.\/255, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(8, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(4, activation='relu'),\n    layers.Dense(numb_classes)\n])","d4d6c082":"model.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","dba54229":"model.summary()","51b30b83":"callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    restore_best_weights=True,\n    patience=5,\n    min_delta=0.02\n)","7b69a902":"epochs=15\n\nhistory = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=epochs,\n    batch_size=BATCH_SIZE,\n    callbacks=[callback]\n)","cffbb4cf":"train_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, train_loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","f9b510bd":"# Take a look at some results\nplt.figure(figsize=(15,15))\n\nfor img, label in valid_ds.take(1):\n    for i in range(9):\n        prediction = model.predict(img)\n        score = tf.nn.softmax(prediction[i])\n        ax = plt.subplot(3, 3, i+1)\n        plt.imshow(img[i].numpy().astype('uint8'))\n        plt.title('Truth: ' + class_names[label[i]] +\n                  \"\\n\" + 'Prediction: ' + class_names[np.argmax(score)] + \n                  '\\n' + 'Confidence: {:.2f} '.format(100 * np.max(score))),\n        plt.axis('off'),\n        plt.tight_layout","81b965c5":"# Create the dataset","bb42ffe4":"# Visualize training results","bee75821":"# Improvement\n- Create `test dataset` for testing the final results.\n- Apply `data augmentation` if there are many classes. With this case, there are only 2 classes. So the models behaves very well.\n","926cfa97":"# Import data","ed8e20fd":"# Visualize data","4489779b":"# Create a classification model","caf1ddb5":"The dataset isn't imbalanced.","099cb0d0":"Move the 2 subdirectories to the current working directory."}}