{"cell_type":{"3acf4173":"code","a9aed52e":"code","b575b6fe":"code","5a83e257":"code","5ed393c2":"code","51009f15":"code","e8a15bc1":"code","232f8f2b":"code","8f635438":"code","9b92033b":"code","bf02e621":"code","6c20aba0":"code","94fd3ffe":"code","cf46e398":"code","d37e5249":"code","e5f03f91":"code","c6d20b16":"code","d9dc3806":"code","65b40b0b":"code","dcf86444":"code","c8274ff9":"code","df6f83a6":"code","30283a8d":"code","cafee4c6":"code","b2811c22":"code","58b528d1":"code","d3fb5a0e":"code","89ec0871":"code","5c7f6317":"code","715de968":"markdown","f11c7a4b":"markdown","747fbbd4":"markdown","21ac7880":"markdown","c547d7fc":"markdown","c37cdfcc":"markdown"},"source":{"3acf4173":"%%capture\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!pip install '\/kaggle\/input\/ensembleboxes-106\/ensemble_boxes-1.0.6-py3-none-any.whl' -f .\/ --no-index --no-deps","a9aed52e":"import pydicom\nimport os\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport numpy as np\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom fastai.vision.all import *\nimport albumentations as A\nimport cv2\nfrom pathlib import Path\nfrom joblib import Parallel, delayed\nimport shutil\nfrom ensemble_boxes import *","b575b6fe":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm","5a83e257":"def dicom2np(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n        \n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef resize(img, max_size, keep_ratio=True, interpolation=cv2.INTER_LANCZOS4):\n    \n    if keep_ratio:\n        tfms = A.Compose(\n            [A.LongestMaxSize(max_size = max_size, interpolation = interpolation)])\n    else:\n        tfms = A.Compose(\n            [A.Resize(height = max_size, width = max_size, interpolation = interpolation)])\n        \n    tfmd = tfms(image=img)    \n   \n    return tfmd\n\ndef process_item(path):\n    \n    tfmd = resize(dicom2np(path), 1024)\n    \n    img_path = Path(*path.parts[3:]).with_suffix('.jpg')\n    cv2.imwrite('test\/' + img_path.name, tfmd['image'])","5ed393c2":"fast_sub = (pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv').shape[0] == 2477)","51009f15":"if fast_sub:\n    dicom_files = get_files(f'..\/input\/siim-covid19-detection\/test', extensions=['.dcm', '.dicom'])[:32]\nelse:\n    dicom_files = get_files(f'..\/input\/siim-covid19-detection\/test', extensions=['.dcm', '.dicom'])\n\nif not os.path.isdir('\/kaggle\/working\/test'):\n    os.makedirs('\/kaggle\/working\/test')\no = Parallel(n_jobs=4)(delayed(process_item)(f) for f in tqdm(dicom_files))","e8a15bc1":"img2path = {f.stem : f for f in dicom_files}\nimg2study = {f.stem : f.parent.parent.name for f in dicom_files}","232f8f2b":"if not os.path.isdir('\/kaggle\/working\/yolov5'):\n    shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5')","8f635438":"def read_results(file):\n    dicom_path = Path(*(['\/kaggle'] + list(img2path[file.stem].parts)[1:]))\n    with open(file, 'r') as f:\n        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    bbox = data[:,1:5]\n    conf = data[:,  5]\n    label = data[:, 0]\n    \n    dicom = pydicom.filereader.dcmread(dicom_path, stop_before_pixels=True)\n    width, height = dicom.Columns, dicom.Rows\n    \n    bbox[:,[0,1]] = bbox[:,[0,1]] - bbox[:,[2,3]]\/2\n    bbox[:,[2,3]] = bbox[:,[0,1]] + bbox[:,[2,3]]\n    \n    ids = file.stem\n    \n    return {'ids':ids, 'label':label, 'conf':conf, 'bbox':bbox, 'width': width, 'height':height}","9b92033b":"%%capture\n\ntest_dir = '\/kaggle\/working\/test'\n#img_size = 640\n\nweights_list = [\n    [' '.join([\n    '\/kaggle\/input\/siimcovid19-models\/yolov5s_10_640_BL1-CV0.pt',\n    '\/kaggle\/input\/siimcovid19-models\/yolov5s_10_640_BL1-CV1.pt',\n    '\/kaggle\/input\/siimcovid19-models\/yolov5s_10_640_BL1-CV2.pt',\n    '\/kaggle\/input\/siimcovid19-models\/yolov5s_10_640_BL1-CV3.pt']), 640, 0.001, 0.5],\n    [' '.join([\n    '\/kaggle\/input\/siimcovid19modelsv2\/yolov5m_30_768_BL2-CV0.pth',\n    '\/kaggle\/input\/siimcovid19modelsv2\/yolov5m_30_768_BL2-CV1.pth',\n    '\/kaggle\/input\/siimcovid19modelsv2\/yolov5m_30_768_BL2-CV2.pth',   \n    '\/kaggle\/input\/siimcovid19modelsv2\/yolov5m_30_768_BL2-CV3.pth']), 786, 0.001, 0.5],   \n]\n\nresults = []\n\nfor weights, img_size, conf, iou in weights_list:\n    !python detect.py --weights $weights\\\n    --img $img_size\\\n    --augment\\\n    --conf $conf\\\n    --iou $iou\\\n    --source $test_dir\\\n    --device 0\\\n    --save-txt --save-conf --exist-ok\n\n    txt_files = get_files('runs\/detect\/exp\/labels', extensions=['.txt'])\n    results.append([read_results(txt_file) for txt_file in txt_files])\n    shutil.rmtree('\/kaggle\/working\/yolov5\/runs\/detect\/exp\/labels')\n    \nresults = list(zip(*results))","bf02e621":"def fuse_and_scale(result):\n    \n    ids, labels, scores, bboxes, width, height = zip(*[d.values() for d in result])\n\n    iou_thr = 0.45\n    skip_box_thr = 0.0001\n    weights = [1] * len(labels)\n\n    bboxes, scores, labels = weighted_boxes_fusion(\n        bboxes, scores, labels,\n        weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    bboxes = bboxes * np.array([[width[0], height[0], width[0], height[0]]])\n    \n    return {'id':ids[0]+'_image', 'scores':scores, 'bboxes':bboxes, 'labels':labels}","6c20aba0":"%%capture\nfused_results = pd.DataFrame([fuse_and_scale(r) for r in results])\n#fused_results = results[0]","94fd3ffe":"def get_dls(df, presize, size, bs):\n\n    covid19 = DataBlock(\n        blocks=(ImageBlock(cls=PILImageBW), MultiCategoryBlock),\n        splitter = RandomSplitter(),\n        getters=[ColReader('path'), ColReader('label')],\n        item_tfms = Resize(presize, method='squish'),\n        batch_tfms = [*aug_transforms(size = size, mult=0.5), Normalize.from_stats(mean=0.53, std=0.23)]\n        )\n    return covid19.dataloaders(df, bs = bs, workers = 4)","cf46e398":"img_files = get_image_files('\/kaggle\/working\/test')\ndf = pd.DataFrame({'path': img_files})\ndf['ImageUID'] = df['path'].apply(lambda x: x.stem + '_image')\ndf['StudyUID'] = df['path'].apply(lambda x: img2study[x.stem] + '_study')\ndf['label'] = [[\"negative\", \"typical\", \"indeterminate\", \"atypical\"]] * len(df)\ndf.head()","d37e5249":"dls = get_dls(df, 768, 384, 64)\ntest_dl = dls.test_dl(img_files)\ntest_dl.show_batch()","e5f03f91":"class MultiHeadModel(Module):\n    def __init__(self, body, head1, head4):\n        self.body = body\n        self.head1 = head1\n        self.head4 = head4\n    \n    def forward(self, x):\n        features = self.body(x)\n        #ys = [self.head4(features), self.head1(features)]\n        #y = torch.cat(ys, dim = -1)\n        return self.head4(features)","c6d20b16":"class TransformerModel(Module):\n    def __init__(self, model):\n        self.model = model\n    \n    def forward(self, x):\n        y = self.model(x)\n        return y[:, :-1]\n    \nclass TransformerModelAux(Module):\n    def __init__(self, model):\n        self.model = model\n    \n    def forward(self, x):\n        y = self.model(x)\n        return y[:, -1:]","d9dc3806":"model_metadata = [\n    ['\/kaggle\/input\/siimcovid19modelsv2\/deit_base_patch16_384-CV0.pth', 'deit_base_patch16_384', 1, 512, 384, 32],\n    ['\/kaggle\/input\/siimcovid19modelsv2\/deit_base_patch16_384-CV1.pth', 'deit_base_patch16_384', 1, 512, 384, 32],\n    ['\/kaggle\/input\/siimcovid19modelsv2\/deit_base_patch16_384-CV2.pth', 'deit_base_patch16_384', 1, 512, 384, 32],\n    ['\/kaggle\/input\/siimcovid19modelsv2\/deit_base_patch16_384-CV3.pth', 'deit_base_patch16_384', 1, 512, 384, 32],\n    ['\/kaggle\/input\/siimcovid19modelsv2\/swin_base_patch4_window12_384-CV0.pth', 'swin_base_patch4_window12_384', 1, 512, 384, 32],\n    ['\/kaggle\/input\/siimcovid19modelsv2\/swin_base_patch4_window12_384-CV1.pth', 'swin_base_patch4_window12_384', 1, 512, 384, 32],\n    ['\/kaggle\/input\/siimcovid19modelsv2\/swin_base_patch4_window12_384-CV2.pth', 'swin_base_patch4_window12_384', 1, 512, 384, 32],\n    ['\/kaggle\/input\/siimcovid19modelsv2\/swin_base_patch4_window12_384-CV3.pth', 'swin_base_patch4_window12_384', 1, 512, 384, 32],  \n    ['\/kaggle\/input\/siimcovid19modelsv2\/twins_pcpvt_base-CV0.pth', 'twins_pcpvt_base', 1, 512, 384, 32],  \n    ['\/kaggle\/input\/siimcovid19modelsv2\/twins_pcpvt_base-CV1.pth', 'twins_pcpvt_base', 1, 512, 384, 32],  \n    ['\/kaggle\/input\/siimcovid19modelsv2\/twins_pcpvt_base-CV2.pth', 'twins_pcpvt_base', 1, 512, 384, 32],  \n    ['\/kaggle\/input\/siimcovid19modelsv2\/twins_pcpvt_base-CV3.pth', 'twins_pcpvt_base', 1, 512, 384, 32],  \n]","65b40b0b":"%%capture\n\npreds_acc = []\n\nfor weights, arch, cut, presize, size, bs in model_metadata:\n    \n    dls = get_dls(df, presize, size, bs)\n    test_dl = dls.test_dl(img_files)\n    \n    if cut < 0:\n        body = timm.create_model(arch, pretrained=False, num_classes = 0, in_chans = 1)\n        body = nn.Sequential(*list(body.children())[:cut])\n        head1 = create_head(num_features_model(body), 1, concat_pool=True)\n        head4 = create_head(num_features_model(body), 4, concat_pool=True)\n        model = MultiHeadModel(body, head1, head4)\n    \n    else:\n        model = timm.create_model(arch, pretrained=False, num_classes = 5, in_chans = 1)\n    \n    if torch.cuda.is_available():\n        model.load_state_dict(torch.load(weights))\n    else:\n        model.load_state_dict(torch.load(weights, map_location=torch.device('cpu')))\n        \n    learn = Learner(dls, model, loss_func = BCEWithLogitsLossFlat())\n    preds = learn.tta(dl = test_dl)[0]\n    preds_acc += [preds]\n    \n    \npreds_acc = torch.stack(preds_acc).mean(dim=0)\n# preds_acc, preds_acc_aux = torch.split(preds_acc, 4, dim=1)\npreds_acc, preds_acc_aux = preds_acc[:,:4], preds_acc[:,3:4]\npreds_acc.mean(dim = 0), preds_acc_aux.mean()","dcf86444":"vocab = [\"atypical\", \"indeterminate\", \"typical\", \"negative\"]","c8274ff9":"preds_df = pd.DataFrame(torch.cat([preds_acc, preds_acc_aux], dim = 1), columns = vocab + ['is_none'])\npreds_df['id'] = df['StudyUID']\npreds_df = preds_df.groupby('id').agg('mean').reset_index()\npreds_df.corr()","df6f83a6":"preds_df = preds_df.drop('is_none', axis = 1)","30283a8d":"preds_df_aux = pd.DataFrame({\n    'id': df['ImageUID'],\n    'is_none': preds_acc_aux.flatten()\n})","cafee4c6":"prediction_string = [' '.join([f'{v} {p:.6f} 0 0 1 1' for v, p in zip(list(preds_df.columns)[1:], pp)]) for pp in preds_df.drop('id', axis = 1).values]\nsubmission_study = pd.DataFrame({\n    'id': preds_df['id'],\n    'PredictionString': prediction_string\n}).sort_values('id').reset_index(drop=True)\nsubmission_study.head()","b2811c22":"submission_dummy = pd.DataFrame({\n    'id': preds_df_aux['id'],\n    'PredictionString': preds_df_aux['is_none'].apply(lambda x: f'none {x:.6f} 0 0 1 1')\n})\nsubmission_dummy.head()","58b528d1":"fused_results = fused_results.merge(preds_df_aux, on = 'id')\nfused_results['is_none'] = fused_results.apply(lambda x: [x['is_none']] * len(x.labels), axis = 1)\nfused_results['PredictionString'] = fused_results.apply(lambda x: ' '.join(f\"opacity {(score*(1-is_none)):.6f} {' '.join(map(str, map(round, bbox)))}\" for score, bbox, is_none in zip(x.scores, x.bboxes, x.is_none)), axis = 1)\n#fused_results.head()","d3fb5a0e":"submission_image = fused_results[['id', 'PredictionString']]\nsubmission_dummy['PredictionString'] = submission_dummy.merge(submission_image, on = 'id', how = 'outer').fillna('').apply(lambda x: x[1] + ' ' + x[2], axis = 1)","89ec0871":"submission = pd.concat([submission_study, submission_dummy])\nsubmission.to_csv('\/kaggle\/working\/submission.csv',index=False)\nsubmission","5c7f6317":"shutil.rmtree('\/kaggle\/working\/yolov5')\nshutil.rmtree('\/kaggle\/working\/test')","715de968":"### Study level prediction","f11c7a4b":"## Detection","747fbbd4":"### Image level prediction","21ac7880":"## Building the prediction Strings","c547d7fc":"### Final prediction","c37cdfcc":"## Classification"}}