{"cell_type":{"030d66d2":"code","76c2053c":"code","e79050c1":"code","227ba3d6":"code","ed2407e7":"code","e5f79289":"code","a2272095":"code","77df99d6":"code","7ecca935":"code","b75fdb05":"markdown","b1160305":"markdown"},"source":{"030d66d2":"import os \nimport json \nfrom pprint import pprint \nfrom copy import deepcopy \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport plotly.express as px \nimport plotly.graph_objects as go \nimport plotly.offline as py \nfrom wordcloud import WordCloud, STOPWORDS \nfrom collections import Counter \nfrom nltk.corpus import stopwords \nfrom sklearn.feature_extraction.text import CountVectorizer \nimport warnings \nwarnings.filterwarnings('ignore') \n","76c2053c":"df = pd.read_csv('..\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv') \ndf1 = pd.read_csv('..\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/clean_comm_use.csv')\n","e79050c1":"# make new dataframe for journal informations\ndff = df.copy()\ndff['WHO #Covidence'] = dff['WHO #Covidence'].str.replace('#','') \ndff['WHO #Covidence'] = dff['WHO #Covidence'].astype(\"Float32\").astype(\"Int32\")\njournal_unique = dff['journal'].value_counts().rename_axis('journal').reset_index(name='counts') \ncovidence_mean = dff.groupby('journal').mean().reset_index()\ndf_journal = pd.merge(journal_unique, covidence_mean, on=\"journal\")\ndf_journal.drop([\"Microsoft Academic Paper ID\",\"pubmed_id\"], axis = 1, inplace = True) \n","227ba3d6":"fig = px.bar(df_journal[:20], x='counts', y='journal', \n             title='Most Common Journals in the CORD-19 Dataset', orientation='h') \nfig.show() \n","ed2407e7":"temp = df_journal.sort_values(by=['WHO #Covidence'], ascending=False)\nfig = px.bar(temp[:20], x='WHO #Covidence', y='journal', \n             title='Highest WHO #Covidence of Journal', orientation='h') \nfig.show() ","e5f79289":"fig = go.Figure(data=go.Scatter(x=df_journal['has_full_text'], y=df_journal['journal'], \n                                mode='markers'))\nfig.update_layout(title_text = 'Distribution of \"has_full_text\" among journals')\nfig.update_layout(\n    xaxis=dict(autorange=True), \n    yaxis=dict(autorange=True, showticklabels=False)\n)\nfig.show()                ","a2272095":"def count_ngrams(dataframe,column,begin_ngram,end_ngram):\n    # adapted from https:\/\/stackoverflow.com\/questions\/36572221\/how-to-find-ngram-frequency-of-a-column-in-a-pandas-dataframe\n    word_vectorizer = CountVectorizer(ngram_range=(begin_ngram,end_ngram), analyzer='word')\n    sparse_matrix = word_vectorizer.fit_transform(df1['title'].dropna())\n    frequencies = sum(sparse_matrix).toarray()[0]\n    most_common = pd.DataFrame(frequencies, \n                               index=word_vectorizer.get_feature_names(), \n                               columns=['frequency']).sort_values('frequency',ascending=False)\n    most_common['ngram'] = most_common.index\n    most_common.reset_index()\n    return most_common\n\ndef word_cloud_function(df,column,number_of_words):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df1[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=number_of_words,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\ndef word_bar_graph_function(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()\n    \nthree_gram = count_ngrams(df1,'title',3,3)\nwords_to_exclude = [\"my\",\"to\",\"at\",\"for\",\"it\",\"the\",\"with\",\"from\",\"would\",\"there\",\"or\",\"if\",\"it\",\"but\",\"of\",\"in\",\"as\",\"and\",'NaN','dtype']\n","77df99d6":"plt.figure(figsize=(10,10))\nword_cloud_function(df1,'title',50000)","7ecca935":"fig = px.bar(three_gram.sort_values('frequency',ascending=False)[0:10], x=\"frequency\", y=\"ngram\",\n             title='Most Common 3-Words in Titles of Papers', orientation='h') \nfig.show()","b75fdb05":"## About this notebook\n\nI have created notebook for EDA - Journal Analysis and Word cloud\nWish everything goes fine ASAP - virus, ecocomy, etc..\n\nrefered parsing json and creating CSV from [this notebook](https:\/\/www.kaggle.com\/xhlulu\/cord-19-eda-parse-json-and-generate-clean-csv#Non-commercial-Use:-Generate-CSV) ","b1160305":"# Most Common word in Title"}}