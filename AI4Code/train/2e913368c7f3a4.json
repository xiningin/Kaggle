{"cell_type":{"e3ec93db":"code","03ad9313":"code","64997eb5":"code","e26785b5":"code","95d9dfc9":"code","d05481a8":"code","362c9d7c":"code","0b3b0906":"code","9fe3c5ca":"code","1e4ff6a5":"code","b8a82adb":"code","29a7ec0a":"code","b6a978da":"code","eddcafa0":"code","bcd73e00":"code","e5d9096f":"code","b05cfa17":"code","b55d5cec":"code","854d631b":"markdown","c01009a8":"markdown","fcaefc77":"markdown","7d602293":"markdown","42790d00":"markdown","7ba8ab63":"markdown","3b0da694":"markdown","2b4690c1":"markdown","c6266061":"markdown","28c3d371":"markdown","43cebfe4":"markdown","b0ecc96f":"markdown","e131a98c":"markdown","6d7c9c13":"markdown","89f0f53a":"markdown","2f1eac7c":"markdown"},"source":{"e3ec93db":"%%capture\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM\n!apt-get install -y -qq libboost-all-dev","03ad9313":"%%capture \n%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","64997eb5":"%%capture\n!cd LightGBM\/python-package\/;python3 setup.py install --precompile","e26785b5":"%%capture\n!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","95d9dfc9":"import glob\nimport pandas as pd\nimport numpy as np\nimport optuna\nimport random \n\nfrom sklearn import compose\nfrom sklearn import ensemble\nfrom sklearn import impute\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn import pipeline\nfrom sklearn import preprocessing\n\nimport lightgbm as lgbm\nimport xgboost as xgb\nimport catboost as cat\n\n\n# This is nice handy constant to turn on and off the GPU. When `False`\n# the notebook will ignore the GPU even when present.\nGPU_ENABLED = True\n\nif GPU_ENABLED:\n    # If we want to use the GPU, but we didn't enable it, the code will\n    # blow up. To make sure this doesn't happen, here I'm checking whether\n    # we truly have access to a GPU.\n    from tensorflow.python.client import device_lib\n    GPU_ENABLED = len(device_lib.list_local_devices()) >= 2\n\n# All of the models in this notebook are fitted in a k-fold cross-validation \n# manner. This constant represents the value of `k`. I got the best results \n# using 20 folds, but it takes around 8 hours to run this notebook on CPU \n# using 20 folds, so I set it to 10 here.\nCROSS_VALIDATION_FOLDS = 10","d05481a8":"df_train = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\n\ncont_features = [f for f in df_train.columns.tolist() if f.startswith('cont')]\ncat_features = [f for f in df_train.columns.tolist() if f.startswith('cat')]\n\ndummies = pd.get_dummies(df_train.append(df_test)[cat_features])\ndf_train[dummies.columns] = dummies.iloc[:len(df_train), :]\ndf_test[dummies.columns] = dummies.iloc[len(df_train): , :]","362c9d7c":"class Model(object):\n    \"\"\"\n    Base model class from which every specific model implementation will inherit.\n    Args:\n        - preprocessor: A standard sklearn pipeline component that will be used\n            to transform the data.\n        - model_params: A dictionary with the parameters that will be used\n            to construct the model.\n    \"\"\"\n    \n    def __init__(self, preprocessor=None, model_params={}):\n        self.preprocessor = preprocessor\n        self.model_params = model_params\n        self._model = None\n\n    def preprocess(self, datasets):\n        \"\"\"\n        Preprocesses the list of supplied datasets using the configured\n        preprocessor and returns the transformed data.\n        \"\"\"\n        \n        if self.preprocessor is None:\n            return datasets\n\n        if datasets is None or len(datasets) == 0:\n            return []\n\n        result = [self.preprocessor.fit_transform(datasets[0])]\n\n        for i in range(1, len(datasets)):\n            result.append(self.preprocessor.transform(datasets[i]))\n\n        return result\n\n    def predict(self, dataset):\n        \"\"\"\n        A pass-through function that runs predictions on a dataset.\n        \"\"\"\n        \n        if self._model is None:\n            return None\n\n        return self._model.predict(dataset)\n\n\nclass XGBModel(Model):\n    \"\"\"\n    A wrapper implementation of an XGBRegressor model.\n    \"\"\"\n    \n    def __init__(self, preprocessor=None, model_params={}):\n        super().__init__(preprocessor, model_params)\n\n    def fit(self, X_train, y_train, X_valid, y_valid, gpu_enabled=True):\n        \"\"\"\n        Fits an instance of the model on the supplied data.\n        Args:\n            - X_train: Train data.\n            - y_train: Train target.\n            - X_valid: Validation data.\n            - y_valid: Validation target.\n            - gpu_enabled: Whether we want to fit the model using the GPU.\n        \"\"\"\n        \n        if gpu_enabled:\n            self.model_params[\"tree_method\"] = \"gpu_hist\"\n            self.model_params[\"predictor\"] = \"gpu_predictor\"\n        else:\n            self.model_params[\"n_jobs\"] = -1\n\n        self._model = xgb.XGBRegressor(\n            objective=\"reg:squarederror\",\n            random_state=0, \n            **self.model_params\n        ) \n\n        self._model.fit(\n            X_train, \n            y_train, \n            early_stopping_rounds=300, \n            eval_set=[(X_valid, y_valid)], \n            verbose=False\n        )\n\n        return self._model\n\n\nclass LGBMModel(Model):\n    \"\"\"\n    A wrapper implementation of an LGBMRegressor model.\n    \"\"\"\n\n    def __init__(self, preprocessor=None, model_params={}):\n        super().__init__(preprocessor, model_params)\n\n    def fit(self, X_train, y_train, X_valid, y_valid, gpu_enabled=True):\n        \"\"\"\n        Fits an instance of the model on the supplied data.\n        Args:\n            - X_train: Train data.\n            - y_train: Train target.\n            - X_valid: Validation data.\n            - y_valid: Validation target.\n            - gpu_enabled: Whether we want to fit the model using the GPU.\n        \"\"\"\n        \n        if gpu_enabled:\n            self.model_params[\"device\"] = \"gpu\"\n            self.model_params[\"gpu_platform_id\"] = 0\n            self.model_params[\"gpu_device_id\"] = 0\n        else:\n            self.model_params[\"n_jobs\"] = -1\n\n        self._model = lgbm.LGBMRegressor(\n            objective='regression', \n            metric=\"rmse\",\n            random_state=0,\n            **self.model_params\n        )\n\n        self._model.fit(\n            X_train, \n            y_train, \n            early_stopping_rounds=300, \n            eval_set=[(X_valid, y_valid)], \n            verbose=False\n        )\n\n        return self._model\n\n\nclass CatBoostModel(Model):\n    \"\"\"\n    A wrapper implementation of a CatBoostRegressor model.\n    \"\"\"\n\n    def __init__(self, preprocessor=None, model_params={}):\n        super().__init__(preprocessor, model_params)\n\n    def fit(self, X_train, y_train, X_valid, y_valid, gpu_enabled=True):\n        \"\"\"\n        Fits an instance of the model on the supplied data.\n        Args:\n            - X_train: Train data.\n            - y_train: Train target.\n            - X_valid: Validation data.\n            - y_valid: Validation target.\n            - gpu_enabled: Whether we want to fit the model using the GPU.\n        \"\"\"\n        \n        if gpu_enabled:\n            self.model_params[\"task_type\"] = \"GPU\"\n            self.model_params[\"bootstrap_type\"] = \"Poisson\"\n\n        self._model = cat.CatBoostRegressor(\n            loss_function='RMSE', \n            random_state=0,\n            **self.model_params\n        )\n\n        self._model.fit(\n            X_train, \n            y_train, \n            early_stopping_rounds=300, \n            eval_set=[(X_valid, y_valid)], \n            verbose=False\n        )\n\n        return self._model\n\n    \nclass LassoModel(Model):\n    \"\"\"\n    A wrapper implementation of a Lasso model.\n    \"\"\"\n\n    def __init__(self, preprocessor=None, model_params={}):\n        super().__init__(preprocessor, model_params)\n\n    def fit(self, X_train, y_train, **kwargs):\n        \"\"\"\n        Fits an instance of the model on the supplied data.\n        Args:\n            - X_train: Train data.\n            - y_train: Train target.\n        \"\"\"\n        \n        self._model = linear_model.Lasso(\n            precompute=True,\n            positive=True, \n            random_state=999, \n            fit_intercept=True,\n            **self.model_params\n        )\n\n        self._model.fit(\n            X_train, \n            y_train\n        )\n\n        return self._model\n    ","0b3b0906":"class Trainer(object):\n    \"\"\"\n    Builds an ensemble of models using k-fold cross-validation.\n    \n    Args:\n        - df_train: Pandas dataframe containing the train data.\n        - df_test: Pandas dataframe containing the test data.\n        - folds: How many folds will be used for the k-fold cross-validation\n            process.\n    \"\"\"\n    \n    def __init__(self, df_train, df_test, folds=10):\n        self.df_train = df_train\n        self.df_test = df_test\n        self.folds = folds\n\n        self.predictions_valid = None\n        self.predictions_test = None\n\n    def fit(self, models, gpu_enabled=True):\n        \"\"\"\n        Fits each one of the supplied models in a k-fold cross-validation manner.\n        Args:\n            - models: The list of models that will be fitted.\n            - gpu_enabled: Whether we want to fit the models using the GPU.\n        Returns:\n            The list of MSE scores corresponding to each one of the \n            supplied models.\n        \"\"\"\n        \n        model_scores = dict()\n        self.predictions_valid = dict()\n        self.predictions_test = dict()\n\n        for model_index in range(len(models)):\n            model_scores.setdefault(model_index, [])\n            self.predictions_valid.setdefault(model_index, dict())\n            self.predictions_test.setdefault(model_index, [])\n\n        self.preprocessed_data = dict()\n        \n        kfold = model_selection.KFold(\n            n_splits=self.folds, \n            shuffle=True, \n            random_state=42\n        )\n\n        for fold, (train_idx, valid_idx) in enumerate(kfold.split(self.df_train)):\n            X_train, X_valid = self.df_train.iloc[train_idx], self.df_train.iloc[valid_idx]\n\n            y_train = X_train.target\n            y_valid = X_valid.target\n\n            X_train = X_train.drop([\"target\"], axis=1)\n            X_valid = X_valid.drop([\"target\"], axis=1)\n\n            for model_index, model in enumerate(models):\n                [xtrain, xvalid, xtest] = model.preprocess([\n                    X_train, \n                    X_valid, \n                    self.df_test\n                ])\n\n                model.fit(\n                    xtrain, \n                    y_train, \n                    X_valid=xvalid, \n                    y_valid=y_valid,\n                    gpu_enabled=gpu_enabled\n                )\n\n                yhat_valid = model.predict(xvalid)\n                yhat_test = model.predict(xtest)\n\n                valid_ids = X_valid.id.values.tolist()\n                self.predictions_valid[model_index].update(\n                    dict(zip(valid_ids, yhat_valid))\n                )\n\n                self.predictions_test[model_index].append(yhat_test)\n\n                rmse = metrics.mean_squared_error(y_valid, yhat_valid, squared=False)\n                model_scores[model_index].append(rmse)\n\n                print(f\"[FOLD {fold}] Model {model_index + 1} Score: {rmse}\")\n\n        print()\n        scores = []\n        for index in range(len(models)):\n            score = np.mean(model_scores[index])\n            scores.append(score)\n            print(f\"Model {index} Overall Score: {score}\")\n\n        return scores\n    \n    def get_prediction_data(self):\n        \"\"\"\n        Returns two new Pandas datasets: A train dataset containing \n        the predictions on the validation data, and a test dataset containing \n        the predictions on the test data.\n        \n        For example, if we fit 3 models, the output datasets will contain a \n        column with the predictions generated with each one of these models. \n        The columns will be named consecutively, i.e. `prediction_0` (predictions \n        generated by the first model,) `prediction_1` (predictions generated\n        by the second model,) and `prediction_2` (predictions generated by the \n        third model.)\n        \n        Both the `id` and `target` columns will be included in the resultant \n        train dataset. The `id` column will also be included in the resultant \n        `test` dataset.\n        \"\"\"\n        \n        if self.predictions_valid is None:\n            return None\n        \n        df_train_predictions = self.df_train[[\"id\", \"target\"]]\n        df_test_predictions = self.df_test[[\"id\"]]\n\n        number_of_trained_models = len(self.predictions_valid.keys())\n        for index in range(number_of_trained_models):\n            df_predictions_valid = pd.DataFrame.from_dict(\n                self.predictions_valid[index], orient=\"index\"\n            ).reset_index()\n            df_predictions_valid.columns = [\"id\", f\"prediction_{index}\"]\n\n            df_predictions_test = pd.DataFrame({\n                \"id\": self.df_test.id,\n                f\"prediction_{index}\": np.mean(\n                    np.column_stack(self.predictions_test[index]\n                ), axis=1)\n            })\n\n            df_train_predictions = df_train_predictions.merge(\n                df_predictions_valid, on=\"id\", how=\"left\"\n            )\n            df_test_predictions = df_test_predictions.merge(\n                df_predictions_test, on=\"id\", how=\"left\"\n            )\n\n        return df_train_predictions, df_test_predictions","9fe3c5ca":"numerical_preprocessor = pipeline.Pipeline(steps=[\n    (\"imputer\", impute.SimpleImputer(strategy=\"mean\")),\n    (\"scaler\", preprocessing.MinMaxScaler()),\n])\n\ncategorical_preprocessor = pipeline.Pipeline(steps=[\n    (\"imputer\", impute.SimpleImputer(strategy=\"most_frequent\")),\n    (\"ordinal\", preprocessing.OrdinalEncoder()),\n])\n\nonehot_preprocessor = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")","1e4ff6a5":"preprocessor1 = compose.ColumnTransformer(\n    transformers=[\n        (\"numerical\", numerical_preprocessor, cont_features),\n        (\"categorical\", categorical_preprocessor, cat_features),\n    ]\n)\n\npreprocessor2 = compose.ColumnTransformer(\n    transformers=[\n        (\"numerical\", numerical_preprocessor, cont_features),\n        (\"categorical\", categorical_preprocessor, [\n            \"cat0\", \"cat1\", \"cat2\", \"cat6\", \"cat7\", \"cat8\", \"cat9\"\n        ]),\n        (\"onehot\", onehot_preprocessor, [\"cat3\", \"cat4\", \"cat5\"])\n    ]\n)\n\npreprocessor3 = compose.ColumnTransformer(\n    transformers=[\n        (\"numerical\", numerical_preprocessor, cont_features),\n        (\"categorical\", categorical_preprocessor, [\"cat1\", \"cat5\", \"cat8\"]),\n        (\"passthrough\", \"passthrough\", [\"cat1_A\", \"cat3_C\", \"cat8_C\", \"cat8_E\"])\n    ]\n)","b8a82adb":"ensemble1_model1 = XGBModel(preprocessor1, model_params = {\n    'n_estimators': 9609,\n    'colsample_bytree': 0.1023603386994367,\n    'learning_rate': 0.05058244812315823,\n    'max_depth': 4,\n    'reg_alpha': 52.62163397880715,\n    'reg_lambda': 0.09796566981609614,\n    'subsample': 0.9362560643601167\n})\n\n\nensemble1_model2 = XGBModel(preprocessor2, model_params = {\n    'n_estimators': 7128,\n    'reg_alpha': 19.910244642239753,\n    'reg_lambda': 1.8655469044829698,\n    'subsample': 0.7843892199651581,\n    'learning_rate': 0.0315114451657133,\n    'max_depth': 5,\n    'colsample_bytree': 0.103069950932443\n})\n\n\nensemble1_model3 = XGBModel(preprocessor3, model_params = {\n    'n_estimators': 7144,\n    'reg_alpha': 3.9027631496250404e-05,\n    'reg_lambda': 38.44801773583271,\n    'subsample': 0.6,\n    'learning_rate': 0.04150001273205032,\n    'max_depth': 3,\n    'colsample_bytree': 0.11939190672649105\n})","29a7ec0a":"ensemble1 = Trainer(df_train, df_test, folds=CROSS_VALIDATION_FOLDS)\nensemble1.fit([ensemble1_model1, ensemble1_model2, ensemble1_model3], GPU_ENABLED)","b6a978da":"df_train_ensemble1, df_test_ensemble1 = ensemble1.get_prediction_data()\ndf_train_ensemble1","eddcafa0":"passthrough_preprocessor = compose.ColumnTransformer(\n    transformers=[(\n        \"passthrough\", \n        \"passthrough\", \n        [c for c in df_train_ensemble1.columns.tolist() if c.startswith(\"prediction\")]\n    )]\n)","bcd73e00":"ensemble2_model1 = XGBModel(passthrough_preprocessor, model_params={\n    'n_estimators': 10911,\n    'reg_alpha': 1.1662382319696787e-08,\n    'reg_lambda': 18.709461290330285,\n    'subsample': 0.5,\n    'learning_rate': 0.02841601836601206,\n    'max_depth': 2,\n    'colsample_bytree': 0.6137187091045387\n})\n\n\nensemble2_model2 = LGBMModel(passthrough_preprocessor, model_params = {\n    'n_estimators': 5000,\n    'learning_rate': 0.021040088115256594,\n    'max_depth': 1,\n    'num_leaves': 136,\n    'min_child_samples': 52\n})\n\n\nensemble2_model3 = CatBoostModel(passthrough_preprocessor, model_params = {\n    'iterations': 20969,\n    'od_wait': 2248,\n    'learning_rate': 0.010572354868717486,\n    'reg_lambda': 27.522864565371602,\n    'subsample': 0.022762417549602867,\n    'random_strength': 30.635308112394423,\n    'depth': 1,\n    'min_data_in_leaf': 20,\n    'leaf_estimation_iterations': 3\n})\n\n\nensemble2 = Trainer(\n    df_train_ensemble1, \n    df_test_ensemble1, \n    folds=CROSS_VALIDATION_FOLDS\n)\nensemble2.fit([ensemble2_model1, ensemble2_model2, ensemble2_model3], GPU_ENABLED)","e5d9096f":"df_train_ensemble2, df_test_ensemble2 = ensemble2.get_prediction_data()\ndf_train_ensemble2","b05cfa17":"passthrough_preprocessor = compose.ColumnTransformer(\n    transformers=[(\n        \"passthrough\", \n        \"passthrough\", \n        [c for c in df_train_ensemble1.columns.tolist() if c.startswith(\"prediction\")]\n    )]\n)\n\nfinal_model = LassoModel(passthrough_preprocessor, model_params={\n    'alpha': 0.0001, \n    'max_iter': 20000\n})\n\n\ntrainer = Trainer(\n    df_train_ensemble2, \n    df_test_ensemble2, \n    folds=CROSS_VALIDATION_FOLDS\n)\ntrainer.fit([final_model])","b55d5cec":"predictions = trainer.predictions_test[0]\ntarget = np.mean(np.column_stack(predictions), axis=1)\noutput = pd.DataFrame({'id': df_test.id, 'target': target})\noutput.to_csv('submission.csv', index=False)","854d631b":"For this second ensemble, I built another three models:\n\n1. An `XGBRegressor`.\n1. An `LGBMRegressor`.\n1. A `CatBoostRegressor`.\n\nIn this case, these models will be looking at the exact same data, but their characteristics are different, so hopefully, they'll learn different patterns from the data.\n\nI tuned the hyperparameters of each one of these models in a separate notebook.\n\nFinally, we can also fit all three models using the `Trainer` class. (Here is where the `Trainer` class starts paying off because we don't need to duplicate all of that code.)","c01009a8":"## Importing the libraries we need\n\nHere is where the competition-specific code begins.\n\nLet's import the libraries we need and define a couple of constants that we'll use throughout the notebook.","fcaefc77":"## Building the first ensemble\n\nI decided to build three different models:\n\n1. An `XGBRegressor` paired with `preprocessor1`.\n1. An `XGBRegressor` paired with `preprocessor2`.\n1. An `XGBRegressor` paired with `preprocessor3`.\n\nSince each model uses slightly different data, they should learn different things that we can later put together in a more robust model. Instead of using three `XGBRegressor` models, a better approach would've been using three completely different models. In this case, since the data is different for each model, the three `XGBRegressor` models do an excellent job of approaching the problem differently.\n\nI also experimented with an additional `LGBMRegressor` and a `CatBoostRegressor` for a total of five models. After a lot of back and forth, the solution with only the three `XGBRegressor` models was much better, so I got rid of the other models.\n\nI tuned the hyperparameters of each one of these models in a separate notebook.","7d602293":"## Building the second ensemble\n\nAt this point, we have the results of the first ensemble of models. We are now going to stack a second ensemble on top of it. The models of this second ensemble will use the predicted results of the first set of models as the input features. \n\nLet's prepare this new dataset:\n\n1. The training dataset contains the predictions of the first set of models on the validation data.\n2. The test dataset contains the predictions of the first set of models on the test data.\n\nThe implementation of the `get_prediction_data()` function combines the results of the ensemble models into the format we need.","42790d00":"We don't need to do any data transformation for this second ensemble because we are working with numerical columns with similar characteristics. \n\nThe `passthrough_preprocessor` transformer lets the relevant columns pass through (every column starting with `prediction_`) and drops the columns we don't need (like `id` and `target`.)","7ba8ab63":"## Recompiling LGBM with GPU support\n\nBy default, you can't use an `LGBMRegressor` model with GPU support. \n\nFor this competition, CPU training is out of the question, so let's recompile LGBM with GPU support.","3b0da694":"# 30 Days of ML - Stacked Ensembles\n\nThis was my first Kaggle competition and it was a lot of fun!\n\nThis solution ended in the top 4% of the private leaderboard.\n\nI like to think about this solution as \"**aggressive ensembling**.\" It turns out, this approach is very popular in Kaggle because it lets you squeeze as much performance as possible out of your solution.\n\nThere's one good thing here that I hope to reuse in other competitions: The `Trainer` class and the set of model classes that I built. This reduced the code footprint considerably and made experimentation much easier.\n\nSpecial thanks to [Abhishek Thakur](https:\/\/www.kaggle.com\/abhishek) and [Luca Massaron](https:\/\/www.kaggle.com\/lucamassaron). This notebook borrows many of the ideas they shared in the forums.","2b4690c1":"Now that every model of the first ensemble is defined, we can use the `Trainer` class to train them in a cross-validated manner.","c6266061":"## Preprocessing pipeline\n\nLet's define the preprocessing transformations that I will use with the original data.\n\nNotice that there are only three different transformations that I will be using:\n\n1. Scaling values using a Min-Max Scaler.\n2. Transforming categorical columns to ordinal values.\n3. One-hot encoding categorical columns.\n\nI combine all of this later to preprocess the data in different ways.","28c3d371":"## Building the final model\n\nWe need one more model to produce the final results.\n\nWe will stack this model on top of the second ensemble, and its goal will be to combine the predictions of each model into a final prediction.\n\nAs before, we will use the data produced by the second ensemble to train and evaluate this final model.","43cebfe4":"## Duplicating code sucks\n\nIt does big time.\n\nFor this competition, I'll be using several ensemble models stacked on top of each other. I didn't want to duplicate all of the boilerplate code to make that work, so I created a few classes that will help me keep the notebook as clean as possible. Bonus: Experimenting with this mini-framework should be way easier than having to make the exact change all over the notebook.\n\nFor this idea to work, I first created a wrapper class for each of the four different models I'll be using.","b0ecc96f":"## Loading the data\n\nLet's start by loading the train and test data.\n\nWe also want to extend the available features by generating dummies for all categorical columns. This was inspired by [Luca Massaron](https:\/\/www.kaggle.com\/lucamassaron)'s results on [this notebook](https:\/\/www.kaggle.com\/lucamassaron\/tutorial-feature-selection-with-boruta-shap).\n\nAt the end of this process, we should end up with a dataset with 82 columns.","e131a98c":"## Preparing the final submission\n\nWe trained a single model to get the final results directly from `trainer3.predictions_test[0]`. \n\nThis is an array with the prediction results of each one of the 10-fold models that we trained. We can compute the mean of these results and create the submission file.","6d7c9c13":"There are three different preprocessors here that I will use to transform the data for the first three different models:\n\n1. `preprocessor1`: Scales numerical columns and converts categorical columns to ordinal values.\n2. `preprocessor2`: Scales numerical columns, converts low-order categorical columns to ordinal values, and one-hot encodes high-order categorical columns.\n3. `preprocessor3`: Scales numerical columns, converts some of the categorical columns to ordinal values and keeps a list of dummy-generated columns untouched. As I mentioned before, this was inspired by [Luca Massaron](https:\/\/www.kaggle.com\/lucamassaron)'s results on [this notebook](https:\/\/www.kaggle.com\/lucamassaron\/tutorial-feature-selection-with-boruta-shap).\n\nEach one of these preprocessors will be used together with one of the models of the first ensemble.\n\nBy the way, I tried many different transformations. In the end, these were the ones that gave me the best results.","89f0f53a":"Just like before, let's use a transformer that allows the essential columns through and use a `Lasso` model to produce the final results.","2f1eac7c":"Let's now define the class where the fun stuff happens.\n\nThe `Trainer` class is the one I'll use to train all of the models. It encapsulates the k-fold cross-validation plumbing, predictions, and metrics."}}