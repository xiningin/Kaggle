{"cell_type":{"3b1e5a95":"code","a08b6060":"code","1f17a576":"code","6c61dbb2":"code","9661c47e":"code","8f659910":"code","224322a5":"code","1f7a5f9e":"code","94de9848":"code","9bccd53d":"code","da59bf23":"code","d658127f":"code","94548ed8":"code","81c5136e":"markdown","e5431438":"markdown","b0c329c2":"markdown","fd0e58b2":"markdown","a66b6443":"markdown","8026d92a":"markdown","4c5fc944":"markdown","243d32c7":"markdown","64d3e704":"markdown","91e1432c":"markdown"},"source":{"3b1e5a95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a08b6060":"import numpy as np\nimport pandas as pd\nfrom sklearn import datasets\n\ndataset = datasets.load_boston()\nX = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\ny = pd.DataFrame(data=dataset.target,columns=[\"value\"])\n","1f17a576":"X.describe()","6c61dbb2":"import matplotlib.pyplot as plt\nX.hist(bins=50, figsize=(20,15))\nplt.show()","9661c47e":"control_coeff_frame = pd.concat([X, y],axis=1)\ncorr_matrix = control_coeff_frame.corr()\ncorr_matrix[\"value\"].sort_values(ascending=False)#use sort_values () to sort the relationships with y in descending order(-1,1)","8f659910":"pd.plotting.scatter_matrix(X.iloc[:,0:4],alpha=0.5,figsize=(20,15))\n","224322a5":"X.plot(kind=\"scatter\",x=\"RM\",y=\"LSTAT\",alpha=0.5)","1f7a5f9e":"import seaborn as sns\n\nsns.heatmap(corr_matrix, \n            xticklabels=corr_matrix.columns.values,\n            yticklabels=corr_matrix.columns.values)","94de9848":"def minkowski_distance(point1,point2,p):\n    distance = 0\n    for i in range(len(point1)):\n        distance = distance+(abs(point1[i]-point2[i])**(1\/p))\n        \n    distance = distance**p\n    \n    return distance","9bccd53d":"p1=X.iloc[0]\np2=X.iloc[3]\nprint(\"Manhattan p=1:\",minkowski_distance(p1, p2, 1))\nprint(\"Euclidean p=2:\",minkowski_distance(p1, p2, 2))","da59bf23":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)","d658127f":"def calculate_distance_return_labels(X_train,X_test,y_train,k,p):\n    \n    test_values_predictions = []\n    \n    for i in range(len(X_test)):\n        points_labels_calculate = []\n        dist=[]\n        \n        for j in range(len(X_train)):\n            dist.append(minkowski_distance(X_test.iloc[i],X_train.iloc[j],p))\n            points_labels_calculate.append(y_train.iloc[j,0])\n\n        distance_for_X_test_point = pd.DataFrame(list(zip(dist, points_labels_calculate)),columns =['distance', 'y_train_labels']) \n        distance_for_X_test_point.sort_values(by=['distance'],inplace=True)\n        predict_value = distance_for_X_test_point.iloc[0:k,1].mean()\n        \n        test_values_predictions.append(predict_value)\n        \n    return test_values_predictions","94548ed8":"from sklearn.metrics import mean_absolute_error\n\npredicted_value = calculate_distance_return_labels(X_train,X_test,y_train,5,2)\nmean_absolute_error(y_test,predicted_value)","81c5136e":"**We use the correlation matrix we previously created to create the heat map chart, which indicates that the color darkens as the intensity of the negative relationship increases, and the color becomes cream as the intensity of the positive relationship increases.**","e5431438":"**To view the data distributions in the histogram:**","b0c329c2":"**We can examine the relations of the columns in the inputs with the output value by creating a correlation matrix.**","fd0e58b2":"**The mean absolute error metric is used in regression.**","a66b6443":"**The data set is divided into 80% train and 20% test set.**","8026d92a":"**We can view the relationship between the values of some columns in the input dataset with the scatter_matrix in the pandas library. As the alpha value decreases, the transparency of the image increases.**","4c5fc944":"**If we want to look at the relationship between the values of the two columns:**","243d32c7":"# **When the distance between the data in the i'th index in the test data set and the j'th data in the train data set is measured, the value of this data in the train data set is assigned to a list. Because when KNN algorithm is used for regression operations, it returns the average of the values in the output of the nearest k neighbor.**","64d3e704":"**The distance between the 2 data is based on the Minkowski distance as a metric. When p = 2, the Euclidean distance is calculated, when p = 1, the Manhattan distance is calculated.**","91e1432c":"**After loading the data set and separating it as input and output, we can look at some information about the values of X's columns with describe (). You can see what the columns in the dataset mean at [https:\/\/www.kaggle.com\/c\/boston-housing](http:\/\/) .**"}}