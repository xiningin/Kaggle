{"cell_type":{"45cbaff3":"code","e49f431e":"code","ce755dcd":"code","7d31ff06":"code","57c1a41f":"code","b31c80bc":"code","793376f6":"code","2b6499df":"code","807d77ab":"code","f2315098":"code","463d0a48":"code","f859d4d9":"code","72a3a97a":"code","1a385239":"code","3e6eb43e":"code","6f9f8294":"code","d166ab94":"code","8ff33c89":"code","c4d504f6":"code","b3abe41a":"code","3d362489":"code","644d18ce":"code","cb38006d":"code","f3f89f4d":"code","032b3eca":"code","3f8eb733":"code","01d5a38d":"code","0e0f618b":"code","b051c2d1":"code","e0869d9e":"code","be3148a8":"code","9945454a":"code","407edde3":"code","ab3fbc1b":"code","102763c4":"code","83f4b6d5":"markdown","686124b7":"markdown","14d8e14d":"markdown","a788ab7b":"markdown","bf1ba300":"markdown","7797fe32":"markdown","382f59d2":"markdown","a9c717be":"markdown","514aeea6":"markdown","c6b487bf":"markdown","47650a48":"markdown","7571a98d":"markdown","be0500e5":"markdown","da4f95e1":"markdown","97ec6b8c":"markdown","08da6a4f":"markdown","43b05609":"markdown","b0fcad58":"markdown","1be27083":"markdown","c57e85ad":"markdown","926c62a7":"markdown","074bc720":"markdown"},"source":{"45cbaff3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e49f431e":"import numpy as np\nimport pandas as pd\n\nimport scipy.stats as stats\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n                            \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","ce755dcd":"df= pd.read_csv('\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')","7d31ff06":"df.head()","57c1a41f":"df.shape","b31c80bc":"df.iloc[0,:]","793376f6":"df.describe()","2b6499df":"df.columns","807d77ab":"print(df.isna().any())","f2315098":"attFeatures = []\nfor i in df.columns:\n    attFeatures.append([i, df[i].nunique(), df[i].drop_duplicates().values])\npd.DataFrame(attFeatures, columns = ['Features', 'Unique Number', 'Values'])","463d0a48":"print(df.Department.unique())\nprint('\\n')\nprint(df.BusinessTravel.unique())\nprint('\\n')\nprint(df.EducationField.unique())\nprint('\\n')\nprint(df.Gender.unique())\nprint('\\n')\nprint(df.JobRole.unique())\nprint('\\n')\nprint(df.MaritalStatus.unique())\nprint('\\n')\nprint(df.Attrition.unique())","f859d4d9":"fig, ax = plt.subplots(1,2, figsize = (16,4))\nsns.distplot(df['DistanceFromHome'], ax = ax[0])\nsns.distplot(df['MonthlyIncome'], ax = ax[1])\nplt.show()","72a3a97a":"dfs = df.groupby(['Attrition', 'Gender']).size().reset_index()\ndfs","1a385239":"df_plot_Gen = df.groupby(['Attrition', 'Gender']).size().reset_index().pivot(columns = 'Attrition', index = 'Gender', values = 0)\ndf_plot_Gen","3e6eb43e":"df_plot_Gen.plot(kind = 'bar', stacked = True, color = ['c','y'])\nplt.show()","6f9f8294":"Inv_95th_pctl = df.JobInvolvement.quantile(0.95)\nPer_95th_pctl = df.PerformanceRating.quantile(0.95)\n\nprint(Inv_95th_pctl)\nprint(Per_95th_pctl)","d166ab94":"df_plot_Dep = df.groupby(['Attrition', 'Department']).size().reset_index().pivot(columns = 'Attrition', index = 'Department', values = 0)\ndf_plot_Ove = df.groupby(['Attrition', 'OverTime']).size().reset_index().pivot(columns = 'Attrition', index = 'OverTime', values = 0)\ndf_plot_Inv = df.groupby(['Attrition', 'JobInvolvement']).size().reset_index().pivot(columns = 'Attrition', index = 'JobInvolvement', values = 0)\ndf_plot_Per = df.groupby(['Attrition', 'PerformanceRating']).size().reset_index().pivot(columns = 'Attrition', index = 'PerformanceRating', values = 0)","8ff33c89":"fig, ax = plt.subplots(2, 2, figsize = (20, 12))\ndf_plot_Dep.plot(kind = 'bar', stacked = True, color = ['c','y'], ax = ax[0,0])\ndf_plot_Ove.plot(kind = 'bar', stacked = True, color = ['c','y'], ax = ax[0,1])\ndf_plot_Inv.plot(kind = 'bar', stacked = True, color = ['c','y'], ax = ax[1,0])\ndf_plot_Per.plot(kind = 'bar', stacked = True, color = ['c','y'], ax = ax[1,1])\nplt.show()","c4d504f6":"df_plot_Stock = df.groupby(['MaritalStatus', 'StockOptionLevel']).size().reset_index().pivot(columns = 'StockOptionLevel', index = 'MaritalStatus', values = 0)\ndf_plot_Stock","b3abe41a":"fig, ax = plt.subplots(2, 2, figsize = (20, 8))\nsns.scatterplot(data = df, x = \"MonthlyIncome\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[0,0])\nsns.scatterplot(data = df, x = \"DistanceFromHome\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[0,1])\nsns.scatterplot(data = df, x = \"YearsSinceLastPromotion\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[1,0])\nsns.scatterplot(data = df, x = \"HourlyRate\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[1,1])\nplt.show()","3d362489":"def qr_outliers(col):\n    outliers = []\n    \n    q1 = col.quantile(0.25)\n    q3 = col.quantile(0.75)\n    inter_qr = q3 - q1\n    lower_limit = q1 - 1.5 * inter_qr\n    upper_limit = q3 + 1.5 * inter_qr\n    for val in col:\n        if val > upper_limit or val < lower_limit:\n            outliers.append(val)\n    return outliers","644d18ce":"col_outliers = []\nfor col in df.columns:\n    if df[col].dtype == 'O' : continue\n    else : \n        outliers = qr_outliers(df[col])\n        if outliers != []:\n            col_outliers.append(col)\n            print(col,':' ,outliers)","cb38006d":"print('NumCompaniesWorked:', df.NumCompaniesWorked.unique())\nprint('PerformanceRating:', df.PerformanceRating.unique())\nprint('StockOptionLevel:', df.StockOptionLevel.unique())","f3f89f4d":"constant_cols = col_outliers[1:4]\ncol_outliers[1:4] = []\ncol_outliers","032b3eca":"def box_plot_outliers(cols, df):\n    fig, ax = plt.subplots(7,2, figsize = (8, 15))\n    \n    i = 0\n    j = 0\n    for col in cols:\n        #print(col)\n        sns.boxplot(df[col], ax = ax[i, j])\n\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        ax[i, j].set_ylabel(col)\n        j += 1\n\n        df.loc[df[col] > 0, col], fitted_lambda = stats.boxcox(df[df[col] > 0][col], lmbda = None)\n        sns.boxplot(df[col], ax = ax[i, j], color = '#FEE23E')\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        i += 1\n        j -= 1\n        \n    fig.suptitle('Before [left] and After [Right] BoxCox Transformation for Removing Outliers ', fontsize = 12)\n    fig.subplots_adjust(top = 0.98)\n    fig.tight_layout()\n    \n    plt.show()","3f8eb733":"box_plot_outliers(col_outliers, df)","01d5a38d":"def constant_cols_outliers(cols, df):\n    fig, ax = plt.subplots(3,2, figsize = (8, 5))\n    \n    i = 0\n    j = 0\n    for col in cols:\n        #print(col)\n        \n        sns.distplot(df[col], ax = ax[i, j])\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        ax[i, j].set_ylabel(col)\n        j += 1\n        \n        if col == 'NumCompaniesWorked':\n            df.loc[df[col] == 9, col] = np.mean(df[col])\n        elif col == 'PerformanceRating':\n            df.loc[df[col] == 4, col] = np.mean(df[col])\n        else:\n            df.loc[df[col] == 3, col] = np.mean(df[col])\n        \n        sns.distplot(df[col], ax = ax[i, j], color = 'y')\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        i += 1\n        j -= 1\n        \n    fig.suptitle('Before [left] and After [Right] mean imputation for Removing Constant value Outliers ', fontsize = 12)\n    fig.subplots_adjust(top = 0.98)\n    fig.tight_layout()\n    \n    plt.show()","0e0f618b":"constant_cols_outliers(constant_cols, df)","b051c2d1":"%%time\n#onehotenc = OneHotEncoder()\nlabelenc = LabelEncoder()\ndf['Attrition'] = labelenc.fit_transform(df['Attrition'])\ndf['Department'] = labelenc.fit_transform(df['Department'])\ndf['EducationField'] = labelenc.fit_transform(df['EducationField'])\ndf['Gender'] = labelenc.fit_transform(df['Gender'])\ndf['JobRole'] = labelenc.fit_transform(df['JobRole'])\ndf['MaritalStatus'] = labelenc.fit_transform(df['MaritalStatus'])\ndf['BusinessTravel'] = labelenc.fit_transform(df['BusinessTravel'])\ndf['OverTime'] = labelenc.fit_transform(df['OverTime'])","e0869d9e":"df.info()","be3148a8":"print(df.Over18.unique())\nprint(df.EmployeeCount.unique())\nprint(df.StandardHours.unique())\nprint(df.EmployeeNumber.unique())","9945454a":"df.drop('Over18', axis = 1, inplace = True)\ndf.drop('EmployeeCount', axis = 1, inplace = True)\ndf.drop('StandardHours', axis = 1, inplace = True)\ndf.drop('EmployeeNumber', axis = 1, inplace = True)","407edde3":"fig, ax = plt.subplots(1,1, figsize = (18,12))\nsns.heatmap(df.corr(), cmap = 'RdYlGn')\nplt.show()","ab3fbc1b":"fig, ax = plt.subplots(figsize = (12,6))\ndf_plot_Stock.plot(kind = 'bar', stacked = True, color = ['#388E3C','#8BC34A','#DCE775', '#FFF59D'], ax = ax)\n#plt.legend(labels = 'StockOptionLevel')\nplt.show()","102763c4":"df.drop('Attrition', axis = 1).corrwith(df.Attrition).sort_values(ascending = False)","83f4b6d5":"We have used label encoder to change the categorical data into numerical for simplicity. However, the algorithm might misunderstand the data. Since sequencing the categories doesn't mean any relationship between different categories. If the categories were something like low, medium and high, then using label encoder would be reasonable as there is a sequence relaitonship between these category values. But for categories such as HR, sales and R&D there is no such a relationship.","686124b7":"We can see that there is a high correlation between Attrition and OverTime. So, working overtime has a positive impact on attrition. In other words, employees are more likely to leave if they are made to work overtime.  ","14d8e14d":"### Outliers","a788ab7b":"## Data Preparation","bf1ba300":"To get a better understanding about the data, we will plot the distribution for some of the categorical variables. For example, how many male and female employees leave the company out of the total employees in the company.","7797fe32":"Now we check unique values for some of these parameters.","382f59d2":"### Descriptive statistics","a9c717be":"As we can see in the box plots above that MonthlyIncome has the most outliers followed by YearsAtCompany and TotalWorkingYears. In the yellow plots above, the columns are cleaned from outliers and the distribution becomes smoother for them.","514aeea6":"## Data Processing","c6b487bf":"Lets have a look at the categorical data and their distributions between different categories.","47650a48":"We look at the distribution for some of the numerical variables to gain some insights about the data. For example, we would like to know the distribution of impotant features like Distance from Home and Monthly income.","7571a98d":"### Removing constant columns","be0500e5":"Since we have different solutions for handling constant columns versus columns with outliers, we seperate these two. so we store the constant columns in constant_cols and keep the outlier columns in col_outliers.","da4f95e1":"Outliers can affect the performance of the model to a great extent. We'll look at the number of outliers and try to remove\/reduce them. Here the criteria for being an outlier is to be outside the upper and lower limit defined below.","97ec6b8c":"### Encoding Categorical Columns","08da6a4f":"### Feature Correlations","43b05609":"From the corrolation plot we can infer that:\n* Attrition has negative correlation with monthly income, total working years, Stock option Level, years at company, years in current role, years with current manager, job satisfactoin, job involvement, environment satisfaction and age.\n* Attrition has positive correlation only with over time, Marital status, and Distance from Home.\n* There is a high correlation between Percent salary hike and performance rating as well as job Level and monthly income.\n* Stock otpion has strong negative correlation with Marital Status. We will plot a barplot to have a closer look on how they relate.\n* Years at company, years in current role, years since last promotion, years with current manager, total working years, monthly income and job level are also correlated significantly.","b0fcad58":"## Data Visualization","1be27083":"Now lets look at the various correlations with the attrition sorted in the descending order.","c57e85ad":"From the plots above, it's difficult to find patterns of attrition. However, we certainly say that:\n\n* the attrition is not directly correlated with hourly rate. The number of attritions for low hourly rate people is as much as the number of attrition for high hourly rate people.\n* It appears that it is not much correlated with any of the variables except for MonthlyIncome to some extent as shown above. Other than that, the people with attrition are spread out the whole variable range.","926c62a7":"Here, we have calculated the 95th percentile for Job Involvement and Performance Rating\nscores. Subsequently, we have plotted their distributions. ","074bc720":"We will look at how attrition changes for some of the numerical variables. We'll plot some of the parameters such as Monthly Income, Distance from Home, years since last promotion, and hourly rate versus years at the company. We would like to see if staying long in the company affects any of these parameters, and how the patterns change for attrition group vs no attrition."}}