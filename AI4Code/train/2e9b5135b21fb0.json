{"cell_type":{"0bf84a95":"code","8e12c12c":"code","abb915e0":"code","8bd3d423":"code","ce30e45a":"code","2e1462b3":"code","509d2281":"code","947a21d9":"code","f4ae321c":"code","8a712418":"code","4bb662ed":"code","a830d25e":"code","1347ffad":"code","220cb961":"code","e8a58667":"code","a5b62220":"code","146f3424":"code","5e2686fc":"code","a3ce6744":"code","da0abaaf":"code","ccedeb99":"code","dc8372a2":"markdown","ea07306b":"markdown","134dab8a":"markdown","1e255eb9":"markdown","ebcbc215":"markdown","3583a2cb":"markdown","ba25d0d8":"markdown","c4902f0e":"markdown","a132a418":"markdown"},"source":{"0bf84a95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e12c12c":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndiabetes = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndiabetes.columns ","abb915e0":"diabetes.head()","8bd3d423":"print(\"Diabetes data set dimensions : {}\".format(diabetes.shape))","ce30e45a":"diabetes.groupby('Outcome').size()","2e1462b3":"diabetes.groupby('Outcome').hist(figsize=(9, 9))","509d2281":"diabetes.isnull().sum()\ndiabetes.isna().sum()","947a21d9":"#no living human should have 0 blood pressure\nprint(\"Total : \", diabetes[diabetes.BloodPressure == 0].shape[0])","f4ae321c":"# 0 is invalid reading for glucose\nprint(\"Total : \", diabetes[diabetes.Glucose == 0].shape[0])","8a712418":"# 0 is invalid for skin thickness\nprint(\"Total : \", diabetes[diabetes.SkinThickness == 0].shape[0])","4bb662ed":"print(\"Total : \", diabetes[diabetes.BMI == 0].shape[0])","a830d25e":"print(\"Total : \", diabetes[diabetes.Insulin == 0].shape[0])","1347ffad":"#remove row with 0\ndiabetes_mod = diabetes[(diabetes.BloodPressure != 0) & (diabetes.BMI != 0) & (diabetes.Glucose != 0)]\nprint(diabetes_mod.shape)","220cb961":"feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\nX = diabetes_mod[feature_names]\ny = diabetes_mod.Outcome","e8a58667":"#import libraries\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","a5b62220":"#initialize\nmodels = []\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('SVC', SVC()))\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('DT', DecisionTreeClassifier()))\nmodels.append(('GNB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('GB', GradientBoostingClassifier()))","146f3424":"#evaluation method - train test split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score","5e2686fc":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = diabetes_mod.Outcome, random_state=0)","a3ce6744":"names = []\nscores = []\nfor name, model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    scores.append(accuracy_score(y_test, y_pred))\n    names.append(name)\ntr_split = pd.DataFrame({'Name': names, 'Score': scores})\nprint(tr_split)","da0abaaf":"# evaluation method k fold cross validation\nfrom sklearn.model_selection import KFold\nnames = []\nscores = []\nfor name, model in models:\n    \n    kfold = KFold(n_splits=10, random_state=10) \n    score = cross_val_score(model, X, y, cv=kfold, scoring='accuracy').mean()\n    \n    names.append(name)\n    scores.append(score)\nkf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})\nprint(kf_cross_val)","ccedeb99":"#plot the accuracy\naxis = sns.barplot(x = 'Name', y = 'Score', data = kf_cross_val)\naxis.set(xlabel='Classifier', ylabel='Accuracy')\nfor p in axis.patches:\n    height = p.get_height()\n    axis.text(p.get_x() + p.get_width()\/2, height + 0.005, '{:1.4f}'.format(height), ha=\"center\") \n    \nplt.show()","dc8372a2":"1 means the person is diabetic and 0 means a person is not. We can identify that out of the 768 persons, 500 are labeled as 0 (non-diabetic) and 268 as 1 (diabetic)","ea07306b":"We can examine the data set using the pandas\u2019 head() method.","134dab8a":"# 4. Model Selection","1e255eb9":"We can find the dimensions of the data set using the panda Dataframes\u2019 \u2018shape\u2019 attribute. (rows,columns)","ebcbc215":"# 2. Data Cleaning","3583a2cb":"# 1. Data Exploration","ba25d0d8":"First, import the necessary libraries and import the data set. We can observe the mentioned columns in the data set.","c4902f0e":"# 3. Feature Engineering","a132a418":"**There are several factors to consider in the data cleaning process.**\n1. Duplicate or irrelevant observations.\n2. Bad labeling of data, same category occurring multiple times.\n3. Missing or null data points.\n4. Unexpected outliers."}}