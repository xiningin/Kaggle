{"cell_type":{"bb4489ba":"code","d985b3bc":"code","d08106c8":"code","c7058e4a":"code","3d13b0b8":"code","9c57d0b9":"code","65e6855c":"code","91892b82":"code","4ae66a8a":"code","b7b8e314":"code","91563f60":"code","7bacb84d":"code","bbfeb8f7":"code","56cc9b2d":"code","0ea6791e":"code","b469563d":"code","c54a9599":"code","0cbe87fc":"code","56822853":"code","8604a9e7":"code","232a9aa6":"markdown","51cfad53":"markdown","45fa6673":"markdown","af01d787":"markdown","7635ecdc":"markdown","b6050e42":"markdown","921c5f64":"markdown","01936877":"markdown","bde8f33a":"markdown","ff2f3643":"markdown"},"source":{"bb4489ba":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score","d985b3bc":"import os\nos.listdir('..\/input')","d08106c8":"data = pd.read_csv(\"..\/input\/adult-pmr3508\/train_data.csv\")\ndata = data.dropna()\ntest = pd.read_csv(\"..\/input\/adulttest\/adult.test.txt\",\n        names=[\n        \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education.num\", \"marital.status\",\n        \"occupation\", \"relationship\", \"race\", \"sex\", \"capital.gain\", \"capital.loss\",\n        \"hours.per.week\", \"native.country\", \"income\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\ntest = test.dropna()","c7058e4a":"data.head()","3d13b0b8":"data.dtypes","9c57d0b9":"def categorical_summarized(dataframe, x=None, y=None, hue=None, palette='Set1', verbose=True):\n    if x == None:\n        column_interested = y\n    else:\n        column_interested = x\n    series = dataframe[column_interested]\n    print(series.describe())\n    print('mode: ', series.mode())\n    if verbose:\n        print('='*80)\n        print(series.value_counts())\n\n    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)\n    plt.show()","65e6855c":"categorical_summarized(data, x = \"sex\", hue = \"income\", verbose = True)","91892b82":"categorical_summarized(data, x = \"education.num\", hue = \"income\", verbose = True)","4ae66a8a":"le = preprocessing.LabelEncoder()\ndata[\"workclass\"] = le.fit_transform(data[\"workclass\"])\ndata[\"education\"] = le.fit_transform(data[\"education\"])\ndata[\"marital.status\"] = le.fit_transform(data[\"marital.status\"])\ndata[\"occupation\"] = le.fit_transform(data[\"occupation\"])\ndata[\"relationship\"] = le.fit_transform(data[\"relationship\"])\ndata[\"race\"] = le.fit_transform(data[\"race\"])\ndata[\"sex\"] = le.fit_transform(data[\"sex\"])\ndata[\"native.country\"] = le.fit_transform(data[\"native.country\"])\ndata[\"income\"] = le.fit_transform(data[\"income\"])","b7b8e314":"train_target = data[\"income\"]\ncols = [col for col in data.columns if col not in [\"Id\", \"fnlwgt\", \"income\"]]\ntrain_data = data[cols]","91563f60":"test[\"workclass\"] = le.fit_transform(test[\"workclass\"])\ntest[\"education\"] = le.fit_transform(test[\"education\"])\ntest[\"marital.status\"] = le.fit_transform(test[\"marital.status\"])\ntest[\"occupation\"] = le.fit_transform(test[\"occupation\"])\ntest[\"relationship\"] = le.fit_transform(test[\"relationship\"])\ntest[\"race\"] = le.fit_transform(test[\"race\"])\ntest[\"sex\"] = le.fit_transform(test[\"sex\"])\ntest[\"native.country\"] = le.fit_transform(test[\"native.country\"])\ntest[\"income\"] = le.fit_transform(test[\"income\"])","7bacb84d":"test_target = test[\"income\"]\ncols2 = [col for col in test.columns if col not in [\"fnlwgt\", \"income\"]]\ntest_data = test[cols2]","bbfeb8f7":"score_max, k_max = 0, 0\nprint(\"Otimizando o valor de k para pesos uniformes...\")\nfor i in range(1,21):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_data, train_target)\n    pred = knn.predict(test_data)\n    score = accuracy_score(test_target, pred)\n    if score > score_max:\n        score_max = score\n        k_max = i\n        print(k_max, \" \u00e9 o melhor valor at\u00e9 o momento...\")\nprint(\"Valor de k \u2208 [1,20] \u00f3timo: \", k_max)\nprint(\"Acur\u00e1cia obtida: \", score_max)\nprint(\"Acur\u00e1cias de valida\u00e7\u00e3o cruzada: \", cross_val_score(knn, train_data, train_target, cv=10))","56cc9b2d":"train_target = data[\"income\"]\ncols = [col for col in data.columns if col not in [\"Id\", \"fnlwgt\", \"sex\", \"income\"]]\ntrain_data = data[cols]","0ea6791e":"test_target = test[\"income\"]\ncols2 = [col for col in test.columns if col not in [\"fnlwgt\", \"sex\", \"income\"]]\ntest_data = test[cols2]","b469563d":"knn = KNeighborsClassifier(n_neighbors=20)\nknn.fit(train_data, train_target)\npred = knn.predict(test_data)\nscore = accuracy_score(test_target, pred)\n\nprint(\"Acur\u00e1cia obtida: \", score)\nprint(\"Acur\u00e1cias de valida\u00e7\u00e3o cruzada: \", cross_val_score(knn, train_data, train_target, cv=10))","c54a9599":"train_target = data[\"income\"]\ncols = [col for col in data.columns if col not in [\"Id\", \"fnlwgt\", \"education\", \"income\"]]\ntrain_data = data[cols]","0cbe87fc":"test_target = test[\"income\"]\ncols2 = [col for col in test.columns if col not in [\"fnlwgt\", \"education\", \"income\"]]\ntest_data = test[cols2]","56822853":"knn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(train_data, train_target)\npred = knn.predict(test_data)\nscore = accuracy_score(test_target, pred)\n\nprint(\"Acur\u00e1cia obtida: \", score)\nprint(\"Acur\u00e1cias de valida\u00e7\u00e3o cruzada: \", cross_val_score(knn, train_data, train_target, cv=10))","8604a9e7":"id_index = pd.DataFrame({'Id' : list(range(len(pred)))})\nresult = pd.DataFrame({'income' : pred})","232a9aa6":"Vamos importar os arquivos csv com os dados de treino e de teste e, em seguida, j\u00e1 descartaremos quaisquer inst\u00e2ncias de dados faltantes ( _missing values_ ).","51cfad53":"Vamos fazer mais alguns testes, excluindo alguns atributos utilizados pelo classificador anteriormente. Note que \u00e9 relevante encontrar novamente o valor de k ideal para cada subconjunto de atributos. Para os testes a seguir, j\u00e1 foram definidos tais valores.","45fa6673":" \u00c9 clara a influ\u00eancia do tipo de educa\u00e7\u00e3o na renda do norteamericano m\u00e9dio.","af01d787":"Para processar os dados utilizando a biblioteca de KNN da SKLearn, precisamos transformar as vari\u00e1veis n\u00e3o num\u00e9ricas em num\u00e9ricas. Para isso, utilizaremos o m\u00e9todo LabelEncoder(), que associa, para cada inst\u00e2ncia \u00fanica de uma vari\u00e1vel, um inteiro, come\u00e7ando em 0. Depois, vamos definir _dataframes_ para treinar e testar o estimador.","7635ecdc":"Para melhor visualizar os dados, vamos utilizar uma fun\u00e7\u00e3o que exibe informa\u00e7\u00f5es acerca de uma determinada vari\u00e1vel, como: n\u00famero de ocorr\u00eancias, n\u00famero de valores distintos que a vari\u00e1vel assume, moda, frequ\u00eancia da moda, tipo de vari\u00e1vel e, se poss\u00edvel, quartis. Al\u00e9m disso, mostra parte dessas informa\u00e7\u00f5es em um gr\u00e1fico de barras.\n\nFonte: https:\/\/towardsdatascience.com\/a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn-a77889485baf","b6050e42":"Inicialmente, vamos importar as bibliotecas que ser\u00e3o utilizadas ao longo de nossa an\u00e1lise.","921c5f64":"Podemos tamb\u00e9m utilizar m\u00e9todos como .head() e .dtypes para compreender com que tipos de dados estamos trabalhando e qual \u00e9 a estrutura b\u00e1sica.","01936877":"Com base nas informa\u00e7\u00f5es acima, concluimos que h\u00e1 uma evidente desigualdade de g\u00eanero no que diz respeito ao sal\u00e1rio de norteamericanos, dado que a propor\u00e7\u00e3o de homens que ganham mais do que $50k \u00e9 muito superior \u00e0 equivalente feminina. Isso indica que a vari\u00e1vel _sex_ \u00e9 bastante relevante para a classifica\u00e7\u00e3o.","bde8f33a":"Para determinar o valor de k para o classificador KNN, vamos testar valores entre 1 e 20. Al\u00e9m disso, vamos realizar valida\u00e7\u00e3o cruzada com os dados de treino, com 10 divis\u00f5es.","ff2f3643":"# An\u00e1lise da base Adult do UCI Repository\n\n## PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es\n\n### Autor: Luca Tamashiro Decker\n### NUSP: 10770645\n\n### Data: 27\/09\/2019"}}