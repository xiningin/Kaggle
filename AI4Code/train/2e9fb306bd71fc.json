{"cell_type":{"3ef9c9ab":"code","eb2940d3":"code","ef379771":"code","e03c1726":"code","53eb1e2d":"code","109c71f5":"code","f3ebeeda":"code","f49b9cf3":"code","573eb3c5":"code","65c7ef08":"code","e41324e6":"code","d158094a":"code","a0fb500f":"code","c894509f":"markdown","d8103911":"markdown","a546bd58":"markdown","685e70c4":"markdown","220d2cb2":"markdown","519b085b":"markdown","42b2a494":"markdown","dcd6599c":"markdown","ebc6a9fb":"markdown","7579767f":"markdown","4a163dd2":"markdown","1ee12351":"markdown","07b478b4":"markdown","6ff31eac":"markdown","2c613dd0":"markdown","b7084461":"markdown","42391619":"markdown","3ba526b4":"markdown","b95c1ad2":"markdown","ddcc5907":"markdown"},"source":{"3ef9c9ab":"import numpy as np\nimport pandas as pd\n\nimport IPython\nimport tensorflow as tf\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","eb2940d3":"base_path = '..\/input\/binance-top-cryptocurrencies\/'\ndf_xlm = pd.read_csv(base_path + 'XLM.csv')['open']\ndf_xlm = pd.DataFrame({'open' : df_xlm.values})\n\ntrain_df, test_df = train_test_split(df_xlm, test_size=0.3, random_state=42)\nval_df = pd.read_csv(base_path + 'ADA.csv')['open']\nval_df = pd.DataFrame({'open' : val_df.values})","ef379771":"class WindowGenerator():\n    def __init__(self, input_width, label_width, shift,\n               train_df=train_df, val_df=val_df, test_df=test_df,\n               label_columns=None):\n        \n        # Store the raw data.\n        self.train_df = train_df\n        self.val_df = val_df\n        self.test_df = test_df\n\n        # Work out the label column indices.\n        self.label_columns = label_columns\n        if label_columns is not None:\n            self.label_columns_indices = {name: i for i, name in\n                                        enumerate(label_columns)}\n        self.column_indices = {name: i for i, name in\n                               enumerate(train_df.columns)}\n\n        # Work out the window parameters.\n        self.input_width = input_width\n        self.label_width = label_width\n        self.shift = shift\n\n        self.total_window_size = input_width + shift\n\n        self.input_slice = slice(0, input_width)\n        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n        self.label_start = self.total_window_size - self.label_width\n        self.labels_slice = slice(self.label_start, None)\n        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n    def __repr__(self):\n        return '\\n'.join([\n            f'Total window size: {self.total_window_size}',\n            f'Input indices: {self.input_indices}',\n            f'Label indices: {self.label_indices}',\n            f'Label column name(s): {self.label_columns}'])","e03c1726":"class WindowGenerator(WindowGenerator):\n    def __init__(self, input_width, label_width, shift,\n               label_columns=None):\n        super().__init__(input_width, label_width, shift,\n               label_columns=label_columns)\n\n    def make_dataset(self, data):\n        data = np.array(data, dtype=np.float32)\n        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n            data=data,\n            targets=None,\n            sequence_length=self.total_window_size,\n            sequence_stride=1,\n            shuffle=True,\n            batch_size=32,)\n\n        ds = ds.map(self.split_window)\n        return ds\n    \n    def split_window(self, features):\n        inputs = features[:, self.input_slice, :]\n        labels = features[:, self.labels_slice, :]\n        if self.label_columns is not None:\n            labels = tf.stack(\n                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n                axis=-1)\n\n        # Slicing doesn't preserve static shape information, so set the shapes\n        # manually. This way the `tf.data.Datasets` are easier to inspect.\n        inputs.set_shape([None, self.input_width, None])\n        labels.set_shape([None, self.label_width, None])\n        return inputs, labels\n\n    @property\n    def train(self):\n        return self.make_dataset(self.train_df)\n\n    @property\n    def val(self):\n        return self.make_dataset(self.val_df)\n\n    @property\n    def test(self):\n        return self.make_dataset(self.test_df)\n\n    @property\n    def example(self):\n        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n        result = getattr(self, '_example', None)\n        if result is None:\n            # No example batch was found, so get one from the `.train` dataset\n            result = next(iter(self.train))\n            # And cache it for next time\n            self._example = result\n        return result","53eb1e2d":"class WindowGenerator(WindowGenerator):\n    def __init__(self, input_width, label_width, shift,\n               label_columns=None):\n        super().__init__(input_width, label_width, shift,\n               label_columns=label_columns)\n        \n    def plot(self, model=None, plot_col='open', max_subplots=3):\n        inputs, labels = self.example\n        plt.figure(figsize=(12, 8))\n        plot_col_index = self.column_indices[plot_col]\n        max_n = min(max_subplots, len(inputs))\n        for n in range(max_n):\n            plt.subplot(max_n, 1, n+1)\n            plt.ylabel(f'{plot_col} [normed]')\n            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n                 label='Inputs', marker='.', zorder=-10)\n\n        if self.label_columns:\n            label_col_index = self.label_columns_indices.get(plot_col, None)\n        else:\n            label_col_index = plot_col_index\n\n        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n        \n        if model is not None:\n            predictions = model(inputs)\n            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                      marker='X', edgecolors='k', label='Predictions',\n                      c='#ff7f0e', s=64)\n\n        if n == 0:\n            plt.legend()\n\n        plt.xlabel('Time [h]')","109c71f5":"OUT_STEPS = 24\nmulti_window = WindowGenerator(input_width=24,\n                               label_width=OUT_STEPS,\n                               shift=OUT_STEPS)\n\nmulti_window.plot()\nmulti_window","f3ebeeda":"class MultiStepLastBaseline(tf.keras.Model):\n    def call(self, inputs):\n        return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n\nlast_baseline = MultiStepLastBaseline()\nlast_baseline.compile(loss=tf.losses.MeanSquaredError(),\n                      metrics=[tf.metrics.MeanAbsoluteError()])\n\nmulti_val_performance = {}\nmulti_performance = {}\n\nmulti_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\nmulti_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(last_baseline)","f49b9cf3":"class RepeatBaseline(tf.keras.Model):\n    def call(self, inputs):\n        return inputs\n\nrepeat_baseline = RepeatBaseline()\nrepeat_baseline.compile(loss=tf.losses.MeanSquaredError(),\n                        metrics=[tf.metrics.MeanAbsoluteError()])\n\nmulti_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\nmulti_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(repeat_baseline)","573eb3c5":"MAX_EPOCHS = 20\nnum_features = df_xlm.shape[1]\n\ndef compile_and_fit(model, window, patience=2):\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=patience,\n                                                    mode='min')\n\n    model.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer=tf.optimizers.Adam(),\n                metrics=[tf.metrics.MeanAbsoluteError()])\n\n    history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n    return history","65c7ef08":"multi_linear_model = tf.keras.Sequential([\n    # Take the last time-step.\n    # Shape [batch, time, features] => [batch, 1, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n    # Shape => [batch, 1, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_linear_model, multi_window)\n\nIPython.display.clear_output()\nmulti_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\nmulti_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_linear_model)","e41324e6":"multi_dense_model = tf.keras.Sequential([\n    # Take the last time step.\n    # Shape [batch, time, features] => [batch, 1, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n    # Shape => [batch, 1, dense_units]\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Shape => [batch, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_dense_model, multi_window)\n\nIPython.display.clear_output()\nmulti_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\nmulti_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_dense_model)","d158094a":"CONV_WIDTH = 3\nmulti_conv_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n    # Shape => [batch, 1, conv_units]\n    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n    # Shape => [batch, 1,  out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_conv_model, multi_window)\n\nIPython.display.clear_output()\n\nmulti_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\nmulti_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_conv_model)","a0fb500f":"multi_lstm_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, lstm_units]\n    # Adding more `lstm_units` just overfits more quickly.\n    tf.keras.layers.LSTM(32, return_sequences=False),\n    # Shape => [batch, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_lstm_model, multi_window)\n\nIPython.display.clear_output()\n\nmulti_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\nmulti_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\nmulti_window.plot(multi_lstm_model)","c894509f":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/1095652\/1842717\/81b3e916b94ca50abf884397c5641711\/dataset-cover.jpeg\" \/>\n<\/div>","d8103911":"Tensorflow [Time Series Tutorial](https:\/\/www.tensorflow.org\/tutorials\/structured_data\/time_series)","a546bd58":"<h1 id=\"window\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Window Generator Plot\n        <a class=\"anchor-link\" href=\"#window\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","685e70c4":"![cnn.png](attachment:b3a90960-905a-410d-abd2-f3a3a16298f0.png)","220d2cb2":"<h1 id=\"dense\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Dense\n        <a class=\"anchor-link\" href=\"#dense\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","519b085b":"<h1 id=\"repeat_baseline\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Repeat Baseline\n        <a class=\"anchor-link\" href=\"#repeat_baseline\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","42b2a494":"## Baselines","dcd6599c":"<h1 id=\"rnn\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Recurrent Neural Network\n        <a class=\"anchor-link\" href=\"#rnn\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","ebc6a9fb":"<h1 id=\"cnn\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Convolutional Neural Network\n        <a class=\"anchor-link\" href=\"#cnn\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","7579767f":"![baseline.png](attachment:3bfe88f3-1595-4469-a850-926a493a4761.png)","4a163dd2":"<h1 id=\"reference\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Reference\n        <a class=\"anchor-link\" href=\"#reference\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","1ee12351":"<h1 id=\"dataset\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","07b478b4":"<h1 id=\"window\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Window Generator Datasets\n        <a class=\"anchor-link\" href=\"#window\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","6ff31eac":"![rnn.png](attachment:01ee3094-1229-4b65-8bc2-52de7f33cf07.png)","2c613dd0":"![linear.png](attachment:73c26013-322b-4e52-8023-33cffce35e35.png)","b7084461":"## Compile and fit function","42391619":"![multistep.png](attachment:22947262-b455-4dc5-9475-8935d5571494.png)","3ba526b4":"<h1 id=\"linear\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Linear\n        <a class=\"anchor-link\" href=\"#linear\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","b95c1ad2":"<h1 id=\"baseline\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Baseline\n        <a class=\"anchor-link\" href=\"#baseline\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","ddcc5907":"<h1 id=\"window\" style=\"color:#ffb802; background:#071d35; border:0.5px dotted #ffb802;\"> \n    <center>Window Generator\n        <a class=\"anchor-link\" href=\"#window\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}