{"cell_type":{"430aa352":"code","6e59e9b6":"code","56cf9b51":"code","c18be985":"code","f0900355":"code","a0f4a2fa":"code","43b4ca29":"code","93b2a442":"code","a731c9c2":"code","c32474f5":"code","94705b6b":"code","78256417":"code","59867843":"code","821cf169":"code","d2c8f46e":"code","bc92a650":"code","a1c17731":"code","be452983":"code","9a9b3535":"code","0d095101":"code","31f07014":"code","218bd7fc":"code","324d04c2":"code","fc8ca5ca":"code","1883cb95":"code","d091d1a1":"code","2ab1a6b0":"code","99caa04a":"code","f0fa81a2":"code","93bd8756":"code","7f147a8d":"code","15b882d0":"code","2ba41c68":"code","fb3156b1":"code","62f02195":"code","a27c7bbf":"code","01b2631d":"code","737e6644":"code","baa6b141":"code","56281af2":"code","e1357fd1":"code","af6b26bd":"code","8a343d3e":"code","5e8134a3":"code","9731e5fc":"code","40b5da8c":"code","2ad82279":"code","73e1af92":"code","ffc108c9":"code","1e7e1975":"code","e1d53dd8":"markdown","aa99edf4":"markdown","7639be1e":"markdown"},"source":{"430aa352":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6e59e9b6":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox, boxcox_normmax\nfrom sklearn.preprocessing import LabelEncoder","56cf9b51":"import pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_id = test['Id']\ntrain.drop('Id', axis=1, inplace=True)\ntest.drop('Id', axis=1, inplace=True)\nprint(train.shape)\nprint(test.shape)","c18be985":"plt.scatter(x=train['GrLivArea'], y=train['SalePrice'])\nplt.show()","f0900355":"train = train.drop(train[(train['GrLivArea']>4000)&(train['SalePrice']<300000)].index)\nplt.scatter(x=train['GrLivArea'], y=train['SalePrice'])\nplt.show()\nntrain = train.shape[0]\nntest = test.shape[0]","a0f4a2fa":"train['SalePrice'] = np.log1p(train['SalePrice'])\nsns.distplot(train['SalePrice'], fit=norm)\ny_train = train.SalePrice.values","43b4ca29":"train = train.drop('SalePrice', axis=1)\ntrain_test = pd.concat((train, test))\nprint(train_test.shape)","93b2a442":"print(len(y_train))\nprint(train.shape)\nprint(ntrain)","a731c9c2":"na = 100 * train_test.isnull().sum()\/(len(train_test))\nna = na.drop(na[na==0].index).sort_values(ascending=False)\nna = pd.DataFrame(na, columns=['percentage'])","c32474f5":"_, _ = plt.subplots(figsize=(10,7))\nplt.xticks(rotation='90')\nsns.barplot(x=na.index, y=na['percentage'])","94705b6b":"cor_map = train.corr()\nplt.subplots(figsize=(12,8))\nsns.heatmap(cor_map)","78256417":"na_col = ('PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageType', \n          'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', \n          'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType', 'MSSubClass')\nfor col in na_col:\n    train[col] = train[col].fillna('None')\n    test[col] = test[col].fillna('None')\n    train_test[col] = train_test[col].fillna('None')","59867843":"zero_col = ('GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', \n            'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea')\nfor col in zero_col:\n    train[col] = train[col].fillna(0)\n    test[col] = test[col].fillna(0)\n    train_test[col] = train_test[col].fillna(0)","821cf169":"train['LotFrontage'] = train.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ntest['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ntrain_test['LotFrontage'] = train_test.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","d2c8f46e":"train = train.drop(['Utilities'], axis=1)\ntest = test.drop(['Utilities'], axis=1)\ntrain_test = train_test.drop(['Utilities'], axis=1)","bc92a650":"mode_col = ('MSZoning', 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType')\nfor col in mode_col:\n    train[col] = train[col].fillna(train[col].mode()[0])\n    test[col] = test[col].fillna(test[col].mode()[0])\n    train_test[col] = train_test[col].fillna(train_test[col].mode()[0])","a1c17731":"train['Functional'] = train['Functional'].fillna('Typ')\ntest['Functional'] = test['Functional'].fillna('Typ')\ntrain_test['Functional'] = train_test['Functional'].fillna('Typ')","be452983":"train_test_clean = pd.concat((train, test)).reset_index(drop=True)\ntrain_test_clean_na = 100 * train_test_clean.isnull().sum()\/len(train_test_clean)\nprint(pd.DataFrame({'missing': train_test_clean_na.sort_values(ascending=False)}))","9a9b3535":"str_col = ('MSSubClass', 'OverallCond', 'YrSold', 'MoSold')\nfor col in str_col:\n    train_test_clean[col] = train_test_clean[col].astype('str')\n    train_test[col] = train_test[col].astype('str')","0d095101":"enc_col = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\n","31f07014":"for col in enc_col:\n    lbl = LabelEncoder()\n    lbl.fit(train_test_clean[col])\n    train_test_clean[col] = lbl.transform(train_test_clean[col])","218bd7fc":"enc_col = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold']\nfor col in enc_col:\n    lbl = LabelEncoder()\n    lbl.fit(train_test[col])\n    train_test[col] = lbl.transform(train_test[col])","324d04c2":"train_test_clean['TotalSF'] = train_test_clean['TotalBsmtSF'] + train_test_clean['1stFlrSF'] + train_test_clean['2ndFlrSF']\ntrain_test['TotalSF'] = train_test['TotalBsmtSF'] + train_test['1stFlrSF'] + train_test['2ndFlrSF']","fc8ca5ca":"numerical_col = train_test_clean.dtypes[train_test_clean.dtypes != 'object'].index    #filter numerical columns\nskewness = pd.DataFrame(train_test_clean[numerical_col].skew().sort_values(ascending=False))\nskewness = skewness[abs(skewness)>0.75]\nfor feat in skewness.index:\n    train_test_clean[feat] = boxcox1p(train_test_clean[feat], 0.15)","1883cb95":"numerical_col = train_test.dtypes[train_test.dtypes != 'object'].index    #filter numerical columns\nskewness = pd.DataFrame(train_test[numerical_col].skew().sort_values(ascending=False))\nskewness = skewness[abs(skewness)>0.75]\nfor feat in skewness.index:\n    train_test[feat] = boxcox1p(train_test[feat], 0.15)","d091d1a1":"print(train_test_clean.shape)","2ab1a6b0":"train_test_clean = pd.get_dummies(train_test_clean)\ntrain_test = pd.get_dummies(train_test)\ntrain = train_test[:ntrain]\ntest = train_test[ntrain:]\nprint(train.shape)","99caa04a":"train_test_clean.to_csv('ttc.csv')\ntrain.to_csv('trainkk.csv')","f0fa81a2":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error as mse\nimport xgboost as xgb\nimport lightgbm as lgb","93bd8756":"n_fold = 5\n\ndef rmse_cv(model, train_2nd):\n    kf = KFold(n_fold, shuffle=True, random_state=42)\n    rmse = np.sqrt(-cross_val_score(model, train_2nd, y_train, scoring='neg_mean_squared_error', cv=kf))\n    return(rmse)","7f147a8d":"lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))","15b882d0":"GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)","2ba41c68":"KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)","fb3156b1":"ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))","62f02195":"model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)","a27c7bbf":"def stack(base):\n    i = 1\n    train_2nd = train\n    for model in base:\n        model.fit(train_2nd, y_train)\n        pred = model.predict(train_2nd)\n        pred = pd.DataFrame({i: pred})\n        train_2nd = pd.concat([train_2nd, pred], axis=1)\n        train_2nd[i] = train_2nd[i].fillna(method='ffill')\n        i = i + 1\n        train_2nd = train_2nd.dropna()\n    return train_2nd","01b2631d":"base = [lasso, GBoost, ENet, model_xgb, KRR]\nmeta = lasso","737e6644":"rmse_cv(meta, stack(base)).mean()","baa6b141":"def test2nd(base):\n    i = 1\n    test_2nd = test\n    train_2nd = train\n    for model in base:\n        model.fit(train_2nd, y_train)\n        pred_test = pd.DataFrame({i: model.predict(test_2nd)})\n        pred_train = pd.DataFrame({i: model.predict(train_2nd)})\n        test_2nd = pd.concat([test_2nd, pred_test], axis=1)\n        train_2nd = pd.concat([train_2nd, pred_train], axis=1)\n        test_2nd[i] = test_2nd[i].fillna(method='ffill')\n        train_2nd[i] = train_2nd[i].fillna(method='ffill')\n        i = i + 1\n        test_2nd = test_2nd.dropna()\n        train_2nd = train_2nd.dropna()\n    return test_2nd        ","56281af2":"test_2nd = test2nd(base)\ntrain_2nd = stack(base)","e1357fd1":"lasso.fit(stack(base), y_train)\npred_lasso_train = lasso.predict(train_2nd)\npred_lasso = np.expm1(lasso.predict(test_2nd.values))","af6b26bd":"np.sqrt(mse(y_train, pred_lasso_train))","8a343d3e":"model_xgb.fit(train_2nd, y_train)\npred_xgb_train = model_xgb.predict(train_2nd)\npred_xgb = np.expm1(model_xgb.predict(test_2nd))","5e8134a3":"np.sqrt(mse(y_train, pred_xgb_train))","9731e5fc":"GBoost.fit(train, y_train)\npred_gb_train = GBoost.predict(train)\npred_gb = np.expm1(GBoost.predict(test))","40b5da8c":"np.sqrt(mse(y_train, pred_gb_train))","2ad82279":"ENet.fit(train_2nd, y_train)\npred_enet_train = ENet.predict(train_2nd)\npred_enet = np.expm1(ENet.predict(test_2nd))","73e1af92":"np.sqrt(mse(y_train, pred_enet_train))","ffc108c9":"ensemble = pred_lasso * 0.3 + pred_xgb * 0.25 + pred_gb * 0.25 + pred_enet * 0.2","1e7e1975":"sub = pd.DataFrame()\nsub['Id'] = test_id\nsub['SalePrice'] = ensemble\nsub.to_csv('submission.csv', index=False)","e1d53dd8":"Part of this notebook refered to [Stacked Regressions : Top 4% on LeaderBoard](http:\/\/https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard)\nThanks for Serigne!\nI'm just a beginer. Practise for stacking ensembling.","aa99edf4":"**Modeling**","7639be1e":"Stack"}}