{"cell_type":{"fce16ab7":"code","9d91faf2":"code","9e4892c2":"code","5ba68ab5":"code","4f70a2f2":"code","df63ebf3":"code","b47c4c51":"code","1bc42afe":"code","ff9137f7":"code","2d33dd0e":"code","6b30d560":"code","84b13192":"code","c023946a":"markdown","d9985aab":"markdown","e63420bd":"markdown","1d6a97bb":"markdown","57d42680":"markdown","c162348a":"markdown"},"source":{"fce16ab7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport optuna\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer","9d91faf2":"def age_preprocessing(age):\n    age = age.fillna(age.mean())\n    age_s = age.map(lambda x:str(x)[0] if x>=10 else str(0))\n    age_s = age_s.map(lambda x:x if int(x)<=6 else \"7<=\")\n    return age_s\n\ndef sibsp_preprocessing(sibsp):\n    group_ids = []\n    for num in sibsp:\n        if num==0:\n            group_ids.append(\"alone\")\n        elif (num==1) or (num==2):\n            group_ids.append(\"small\")\n        elif num >= 3:\n            group_ids.append(\"large\")\n    return group_ids\n\ndef parch_preprocessing(parch):\n    group_ids = []\n    for num in parch:\n        if num==0:\n            group_ids.append(\"alone\")\n        elif (num==1) or (num==2):\n            group_ids.append(\"small\")\n        elif num >= 3:\n            group_ids.append(\"large\")\n    return group_ids\n\ndef fare_preprocessing(fare):\n    fare = fare.fillna(fare.mean())\n    new_bins = np.array([0, 10, 30, 100, 1000])\n    ids = np.digitize(fare, new_bins)\n    return ids\n\ndef ticket_preprocessing(ticket_df, N=5):\n    words = []\n    for ticket in ticket_df:\n        for word in ticket.split():\n            words.append(word.replace(\".\",\"\"))\n    count_df = pd.Series(words).value_counts().to_frame()\n    words_num_over_N = list(count_df[count_df[0]>=N].index)\n    print(\"---ticket over[ {} ]num words---\\n\".format(N), words_num_over_N,\"\\n\")\n    df_Ticket = pd.DataFrame(index=ticket_df.index, data=ticket_df.values, columns=[\"Ticket\"])\n    for word in words_num_over_N:\n        df_Ticket[\"T_\" + word] = df_Ticket[\"Ticket\"].map(lambda x:1 if word in x.replace(\".\",\"\").split() else 0)\n    df_Ticket[\"T_No_target\"] = pd.Series(df_Ticket.iloc[:,2:].sum(axis=1)).map(lambda x:1 if x==0 else 0)\n    return df_Ticket.drop(\"Ticket\",axis=1)\n\ndef cabin_preprocessing(cabin):\n    cabin = cabin.fillna(\"-\")\n    cabin_split_num = cabin.map(lambda x:str(x).count(\" \"))\n    cabin = cabin.map(lambda x:x[0])\n    return cabin, cabin_split_num\n\ndef name_preprocessing(name):\n    df_Name = pd.DataFrame(index=name.index)\n    #Title\n    df_Name[\"Title\"] = name.map(lambda x: x.split(', ')[1].split('. ')[0])\n    df_Name['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer', inplace=True)\n    df_Name['Title'].replace(['Don', 'Sir',  'the Countess', 'Lady', 'Dona'], 'Royalty', inplace=True)\n    df_Name['Title'].replace(['Mme', 'Ms'], 'Mrs', inplace=True)\n    df_Name['Title'].replace(['Mlle'], 'Miss', inplace=True)\n    df_Name['Title'].replace(['Jonkheer'], 'Master', inplace=True)\n    #Family_flag\n    Surname = name.map(lambda name:name.split(',')[0].strip())\n    count_df_over2 = Surname.value_counts().to_frame()\n    count_df_over2 = count_df_over2[count_df_over2[\"Name\"]>1]\n    df_Name['Family_flag'] = Surname.map(lambda x:1 if x in list(count_df_over2.index) else 0)\n    df_Name = pd.get_dummies(df_Name)\n    return df_Name\n\n###load data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\").set_index(\"PassengerId\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\").set_index(\"PassengerId\")\n\n###concat train_data and test_data\ndata = pd.concat([train_data.drop(\"Survived\",axis=1), test_data])\n\n###check null data\nprint(\"---null counts---\\n\",data.apply(lambda x: sum(x.isnull())),\"\\n\")\n\n### 1.Pclass   ### 2.Sex   ### 7.Embarked \n# No preprocessing. using get_dummies.\ndata = pd.get_dummies(data, columns=[\"Pclass\",\"Sex\",\"Embarked\"])\n#Sex is binary... better one variable than dummies..?\ndata[\"Sex\"] = data[\"Sex_female\"]\ndata = data.drop([\"Sex_male\",\"Sex_female\"], axis=1)\n\n### 3.Age\ndata[\"Age\"] = age_preprocessing(data[\"Age\"])\ndata = pd.get_dummies(data, columns=[\"Age\"])\n\n### 4.SibSp\ndata[\"SibSp\"] = sibsp_preprocessing(data[\"SibSp\"])\ndata = pd.get_dummies(data, columns=[\"SibSp\"])\n\n### 5.Parch  \ndata[\"Parch\"] = sibsp_preprocessing(data[\"Parch\"])\ndata = pd.get_dummies(data, columns=[\"Parch\"])\n\n### 6.Fare  \ndata[\"Fare\"] = fare_preprocessing(data[\"Fare\"])\ndata = pd.get_dummies(data, columns=[\"Fare\"])\n\n### 8.Ticket\ndf = ticket_preprocessing(data[\"Ticket\"], N=8)\ndata = pd.concat([data, df],axis=1)\ndata = data.drop(\"Ticket\",axis=1)\n\n### 9.Cabin  \ncabin, cabin_split_num = cabin_preprocessing(data[\"Cabin\"])\ndata[\"Cabin\"] = cabin\ndata = pd.get_dummies(data, columns=[\"Cabin\"])\ndata[\"Cabin_s_num\"] = cabin_split_num\n\n### 10.Name   \ndf = name_preprocessing(data[\"Name\"])\ndata = pd.concat([data, df],axis=1)\ndata = data.drop(\"Name\",axis=1)\n\ndata.head()","9e4892c2":"#Return train data and test data.\ntrain_processed = data.loc[train_data.index,:]\ntest_processed = data.loc[test_data.index,:]","5ba68ab5":"rfc = RandomForestClassifier()\nrfc.fit(train_processed, train_data[\"Survived\"])\npred_df = pd.DataFrame({\"column\":train_processed.columns, \"feature_importance\":rfc.feature_importances_})\npred_df = pred_df.sort_values(by=\"feature_importance\", ascending=True)\nplt.figure(figsize=(15,20))\nplt.barh(pred_df[\"column\"], pred_df[\"feature_importance\"])","4f70a2f2":"X_train, X_test, y_train, y_test = train_test_split(train_processed.values, train_data[\"Survived\"].values, train_size=0.85, stratify=train_data[\"Survived\"], random_state=0)","df63ebf3":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\n\nno_params_rnc_score = rfc.score(X_test, y_test)\n\nprint(\"-----benchmark-----\")\nprint(\"RandomForest_score\", no_params_rnc_score)","b47c4c51":"def objective(trial):\n    params_rfc = {\n        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 20),\n        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n        'min_samples_split': trial.suggest_int(\"min_samples_split\", 5, 20),\n        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n        'max_features': trial.suggest_int(\"max_features\", 2, X_train.shape[1]),\n        \"random_state\": 2021\n    }\n\n    model = RandomForestClassifier(**params_rfc)\n    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n    scores = cross_validate(model, X=X_train, y=y_train, cv=kf)\n    \n    return scores['test_score'].mean()\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\nprint(study.best_params)\nprint(study.best_value)\nrfc_best_param = study.best_params","1bc42afe":"rfc = RandomForestClassifier(**rfc_best_param)\nrfc.fit(X_train, y_train)\noptuna_rnc_score = rfc.score(X_test, y_test)\n\nprint(\"-----best_params_score-----\")\nprint(\"RandomForest_score\", optuna_rnc_score)","ff9137f7":"rfc = RandomForestClassifier(**rfc_best_param)\nrfc.fit(train_processed.values, train_data[\"Survived\"].values)","2d33dd0e":"sample_submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\nsubmission = sample_submission.copy()\nsubmission.Survived = rfc.predict(test_processed)\nsubmission.to_csv(\"submission.csv\",index=False)","6b30d560":"#check Survived counts\nprint(submission[\"Survived\"].value_counts())\nprint(\"\\nper_1\", sum(submission[\"Survived\"]==1) \/ len(submission))","84b13192":"submission","c023946a":"# Optuna stady notebook\n### I hope this is helpful to you.\u3000\u3000\u3000\u3000\u3000\u3000\u3000\n(I'd be happy to vote for you.)","d9985aab":"## RandomForest optuna stady","e63420bd":"# 2.Preprocessing\n### Preprocessing with EDA results\uff08See URL at the beginning of this notebook\uff09\nThere may be differences in the descriptions due to different versions.","1d6a97bb":"# 3.optuna stady!\nFrom here, we will implement optuna_stady.  \nHowever, there are many ways to implement it, so please understand that this is just an example.","57d42680":"## Titanic EDA is done in this notebook, so please refer to it!\nhttps:\/\/www.kaggle.com\/showeed\/starter-book-begginer-analysis","c162348a":"# 1.Library"}}