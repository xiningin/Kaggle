{"cell_type":{"61b56a5d":"code","0454fadc":"code","14dfcce4":"code","3d1cccc6":"code","5e97266a":"code","9693c723":"code","bc30d9bd":"code","15cc9ba7":"code","231d081f":"code","6ceba653":"code","bfede596":"code","a2df596e":"code","287502b8":"code","1b2c2779":"code","d8e1e0c6":"code","571fef8b":"code","a3c324be":"code","07998866":"code","6d22d772":"code","119f7b5f":"code","74f3a389":"code","2e96a866":"code","416743a5":"code","85febd1f":"code","15d2cdbd":"code","607b364c":"code","9ea7e5b1":"markdown","05827579":"markdown","b96be42e":"markdown","873f7a62":"markdown","55f4b18d":"markdown","25cfb195":"markdown","5d4b52be":"markdown","f00fcdb3":"markdown","03702ec7":"markdown","11af74a7":"markdown","8cade77d":"markdown","eca45422":"markdown","8d737107":"markdown"},"source":{"61b56a5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0454fadc":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\", index_col='PassengerId')\ntrain_data.head()","14dfcce4":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","3d1cccc6":"z=train_data.drop(['Name','Ticket','Cabin'],axis=1)\nt=test_data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)","5e97266a":"z.head()","9693c723":"t.head()","bc30d9bd":"x=z.iloc[:,1:]   \ny=train_data.iloc[:,0].values","15cc9ba7":"x.isnull().sum()","231d081f":"#checking \nt.isnull().sum()","6ceba653":"from sklearn.impute import SimpleImputer\ntheimputer = SimpleImputer(missing_values=np.nan,strategy='median')\ntheimputer.fit(x.iloc[:,2:3])\nx.iloc[:,2:3]=theimputer.transform(x.iloc[:,2:3])\n#filling the missing data of Embarked coloum\nimp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nimp.fit(x.iloc[:,[6]])\nx.iloc[:,[6]]=imp.transform(x.iloc[:,[6]])","bfede596":"#checking \nx.isnull().sum()","a2df596e":"#filling the missing data of Age coloum\ntheimputer.fit(t.iloc[:,[2]])\nt.iloc[:,[2]]=theimputer.transform(t.iloc[:,[2]])\n#filling the missing data of Fare coloum using mean strategy\ntheimputern2 = SimpleImputer(missing_values=np.nan,strategy='mean')\ntheimputern2.fit(t.iloc[:,[5]])\nt.iloc[:,[5]]=theimputern2.transform(t.iloc[:,[5]])","287502b8":"t.isnull().sum()","1b2c2779":"x.head()","d8e1e0c6":"t.head()","571fef8b":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2,random_state=1)","a3c324be":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\ncolumn=ColumnTransformer(transformers=[('encoder', OneHotEncoder(), ['Sex','Embarked'])],remainder='passthrough')\nxtrain= np.array(column.fit_transform(xtrain))\nxtest=np.array(column.fit_transform(xtest))\n#Encoding Categorical data\nt= np.array(column.fit_transform(t))","07998866":"print(xtrain)","6d22d772":"print(xtest)","119f7b5f":"print(t)","74f3a389":"#Feature scaling is essential as the range of all features should be in fixed range\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n#features to be scaled : age and fare\nxtrain= sc.fit_transform(xtrain)\nxtest = sc.transform(xtest)\n#Scaling the data of test\nt = sc.transform(t)","2e96a866":"#For my model Random Forest Classifier\n#To produce a more accurate result, it builds numerous decision trees and then merges them together.\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 1)\nclassifier.fit(xtrain, ytrain)","416743a5":"ypredict = classifier.predict(xtest)\nypredict\n","85febd1f":"#Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nconfussionMatrix = confusion_matrix(ytest, ypredict)\nprint(confussionMatrix)\naccuracy_score(ytest, ypredict)","15d2cdbd":"predict = classifier.predict(t)\npredict","607b364c":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predict})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","9ea7e5b1":"# Importing dataset","05827579":"# Handeling the missing data found","b96be42e":"* x is the matrix of the features\n* y is the independent variable\n* iloc is used to locate index (Rows and Columns)","873f7a62":"# Confusion Matrix","55f4b18d":"# Splitting the data into train and test","25cfb195":"# Feature scaling ","5d4b52be":"# Random Forest Classifier","f00fcdb3":"# Encoding Categorical data\nIn Machine learning we are require that input and output variables are numbers\n* Here we have the sex Column containg letters soit must be encoded to numbers before we can use it to fit and evaluate our mode","03702ec7":"# Check if there is a missing data\nthere is 2 ways how to handle our missing data which is either by:\n* removing it\n* replacing it by -Average or - median or - most used,the most classic way to handle this is to get average","11af74a7":"# Dropping some coluoms of our tables","8cade77d":"# submission","eca45422":"filling the missing data of Age and fare coloum","8d737107":"# Steps\n1. data preprocessing \n* importing the files(Dataset)\n* handeling missing data\n* splitting the dataset into training set and test set\n* encoding categorical data\n* Feature scaling\n2. model training\n3. model evaluation"}}