{"cell_type":{"63841b07":"code","9d14ca5d":"code","7d035b85":"code","06f5a349":"code","48e0b284":"code","4fd184a8":"code","df361166":"code","ce2f3a57":"code","fb716dc8":"code","fa52f8f8":"code","0679ae79":"code","8dbc2ce7":"code","54e9a683":"code","3f44a7aa":"code","182b6cb7":"code","70d4d76b":"code","22d5e582":"code","33f8d1a9":"markdown","9a83df24":"markdown","b71be7ab":"markdown","deb075d9":"markdown","8ba26aa8":"markdown","1e1a594b":"markdown","2f264a6f":"markdown","4229e1dd":"markdown"},"source":{"63841b07":"import pandas as pd\nimport numpy as np\nfrom sklearn import datasets","9d14ca5d":"data = datasets.load_boston()\ndf = pd.DataFrame(data['data']).set_axis(data['feature_names'], axis=1)\ndf['target'] = data['target']","7d035b85":"df.head()","06f5a349":"# Transform tabular data into vectors and matrixes for numpy to work with\nX = df.iloc[:,:-1].values\ny = df.target.values","48e0b284":"import random\ndef train_test_split(X, y, test_size):\n    # Index the array\n    indices = list(range(len(X)))\n    \n    # Find the train size, round() to avoid decimal values\n    train_size = round((1-test_size)*len(X))\n    \n    # Randomly shuffle the indices\n    random.shuffle(indices)\n    \n    # Split the training & testing samples\n    X_train= X[indices[:train_size]]\n    y_train = y[indices[:train_size]]\n    X_test = X[indices[train_size:]]\n    y_test = y[indices[train_size:]]\n    \n    return X_train, y_train, X_test, y_test","4fd184a8":"test_size = 0.2\nX_train, y_train, X_test, y_test = train_test_split(X, y, test_size)","df361166":"X_train.shape","ce2f3a57":"y_train.shape","fb716dc8":"# Fit training samples to the above equation to find the optimal weights, equivalent to sklearn's model.fit()\ndef normal_equation(X, y):\n    coef = np.dot((np.linalg.inv(np.dot(X.T,X))), np.dot(X.T,y))\n    return coef","fa52f8f8":"# Predict y_hat based on the weights\ndef predict(X_test, coefficients):\n    return np.dot(X_test, coefficients)","0679ae79":"coef = normal_equation(X_train, y_train)\npred = predict(X_test, coef)","8dbc2ce7":"def metrics(predictions, y_test):\n    \n    # Mean Absolute Error\n    MAE = np.mean(np.abs(predictions-y_test))\n\n    # Mean Squared Error (MSE) & RMSE \n    MSE = np.square(np.subtract(y_test,predictions)).mean() \n    RMSE = np.sqrt(MSE)\n\n    # R-Squared\n    rss = np.sum(np.square((y_test-predictions)))\n    mean = np.mean(y_test)\n    tss = np.sum(np.square(y_test-mean))\n    r_square = 1 - (rss\/tss)\n\n    return MAE, RMSE, r_square","54e9a683":"mae, rmse, r_sq = metrics(pred, y_test)","3f44a7aa":"print(f'the MAE is: {mae:.4f}')\nprint(f'the RMSE is: {rmse:.4f}')\nprint(f'the R-Squared is: {r_sq:.4f}')","182b6cb7":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","70d4d76b":"model = LinearRegression()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)","22d5e582":"mae = mean_absolute_error(y_test, pred)\nmse = mean_squared_error(y_test, pred)\nr_sq = model.score(X_test,y_test)\n\nprint(f'the MAE is: {mae:.4f}')\nprint(f'the RMSE is: {np.sqrt(mse):.4f}')\nprint(f'the R-Squared is: {r_sq:.4f}')","33f8d1a9":"The optimal beta or coefficients, i.e. the weights for differnt X's, can be found by the following formula, i.e. normal equation.","9a83df24":"Alternatively, R-Squared can be understood as follows.\\\n\\\n![image.png](attachment:6cddbb5b-5518-4de9-9a92-b25bb00fad88.png)\n\nWhere explained variation = total variation (TSS) - unexplained variation (RSS)","b71be7ab":"### Accuracy score","deb075d9":"### Build the algorithm","8ba26aa8":"Compute the score in terms of common metrics for regression tasks, namely MAE, RMSE, R-Squared. Notably, R-Squared is given by the following formula.\\\n\\\n![image.png](attachment:22b90130-8fc3-457a-949f-6b051ec9a283.png)\n\n* RSS: sum of squares of residual\n* TSS: total variation sum of squares","1e1a594b":"### Train test split","2f264a6f":"![image.png](attachment:bd84bf58-e616-42c3-b178-f531d74eb80e.png)","4229e1dd":"### Compare with Sklearn's LinearRegression()"}}