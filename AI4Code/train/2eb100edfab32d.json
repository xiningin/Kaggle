{"cell_type":{"12bcca54":"code","2c54a089":"code","4aca0caf":"code","20383065":"code","3dffa467":"code","072f2065":"code","eebdcccb":"code","edbc9151":"code","194b17d2":"code","b4ddf546":"code","ba826212":"code","82e2a49f":"code","35a12c51":"code","64e57e6d":"code","fe0b0c85":"code","68231072":"code","82d40621":"code","6af5ab6d":"code","08c952c1":"code","cd06985f":"code","9af82420":"code","f336e30f":"code","905d864d":"code","1ed795f0":"code","8b0f7084":"code","feb7c5e9":"code","f3a4c712":"code","60a4b992":"code","7be74681":"code","ac23edb1":"code","c3144e75":"code","d4972a07":"code","573b2677":"code","424024aa":"code","1d341a6c":"code","60a865ea":"code","ac9449db":"code","6912aa14":"code","54e11936":"code","6c0148f2":"code","fb60cac7":"code","0098c381":"code","3ce945ab":"code","22ab2d4e":"code","61636c74":"code","519a99dd":"code","24c17b4e":"code","5de483f8":"code","e957d522":"code","8ebb9c9b":"code","bc5586f7":"code","37a2ed88":"code","fecf3456":"code","d3b0c9bb":"code","99a2e2ab":"code","eb7bda8a":"code","ee266c34":"code","0c41d2b9":"code","44db5233":"code","d3c4b4c6":"code","8b23fe43":"code","cb80f9a2":"code","6b33a709":"code","2e917406":"code","23917196":"code","6ea9e9e8":"code","ce91b8fb":"code","1ccf5ec3":"code","49c42318":"code","07d3a1f1":"code","4c801ab3":"code","f7d0cf6a":"code","075cdee6":"code","6fd6789f":"markdown","e9a769a3":"markdown","744244c6":"markdown","a0565834":"markdown","0cc5014a":"markdown","0661d10f":"markdown","5f530b3f":"markdown","7706c633":"markdown","d21823e7":"markdown"},"source":{"12bcca54":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom IPython.display import display","2c54a089":"hr = pd.read_csv('..\/input\/hrdata\/hr.csv')\nhr.head()","4aca0caf":"display(hr.shape)","20383065":"#Identify the Data Types - Numpy\nhr_dd = pd.DataFrame(hr.dtypes,columns=['Numpy Dtype'])\n\n#Identify the unique values\nhr_dd['Nunique'] = hr.nunique()\n\n#Identify the Missing values\nhr_dd['MissingValues']=hr.isnull().sum()\n\n# Identify the count for each variable\nhr_dd['Count']=hr.count()\n\n# Identify the zero values for each variable\nhr_dd['ZeroValues']=(hr==0).sum()\n\nhr_dd","3dffa467":"# I am interested in knowing the descriptive statistics \n# of the numerical variables\nhr.describe(include=['number'])","072f2065":"# here the same procedure is applied on the categorical variables\nhr.describe(include=['object'])","eebdcccb":"hr","edbc9151":"fig, axes = plt.subplots(ncols=3, figsize=(10,5))\n\ng = sns.distplot(hr['satisfaction_level'],ax=axes[0])\ng = sns.distplot(hr['last_evaluation'],ax=axes[1])\ng = sns.distplot(hr['average_montly_hours'],ax=axes[2])","194b17d2":"#distirbution of categorical columns using counter plots\nfig, axes = plt.subplots(ncols=2,figsize=(12,6))\ng = sns.countplot(hr[\"sales\"], ax=axes[0])\nplt.setp(g.get_xticklabels(), rotation=45)\ng = sns.countplot(hr[\"salary\"], ax=axes[1])","b4ddf546":"#distirbution of other numerical features\nfig, axes = plt.subplots(ncols=3,figsize=(12,6))\ng = sns.countplot(hr[\"Work_accident\"], ax=axes[0])\ng = sns.countplot(hr[\"promotion_last_5years\"], ax=axes[1])\ng = sns.countplot(hr[\"left\"], ax=axes[2])","ba826212":"#distirbution of other numerical features\nfig, axes = plt.subplots(ncols=2,figsize=(12,6))\n\ng=hr['time_spend_company'].plot(kind='hist',ax=axes[0],bins=8)\ng.set_xlabel('time_spend_company')\ng.set_ylabel('count')\n\ng=hr['number_project'].plot(kind='hist',ax=axes[1],bins=6,color='lightgreen')\ng.set_xlabel('number_project')\ng.set_ylabel('count')","82e2a49f":"g = sns.heatmap(hr.corr(),annot=True,cmap=\"RdYlGn\")\nplt.title('correlation between different variables')","35a12c51":"from sklearn import preprocessing\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n# Converting string labels into numbers.\nhr['salary']=le.fit_transform(hr['salary'])","64e57e6d":"hr","fe0b0c85":"hr = hr.drop(labels=[\"sales\"],axis = 1)","68231072":"hr = hr.sample(n=10000,replace=True)","82d40621":"hr","6af5ab6d":"# Standardize features by removing the mean and scaling to \n# unit variance\nfrom sklearn.preprocessing import StandardScaler\n\nN = StandardScaler()\nN.fit(hr)\nhr_norm = N.transform(hr)","08c952c1":"from sklearn.decomposition import PCA\nfrom sklearn.manifold import Isomap","cd06985f":"# Linear dimensionality reduction using Singular Value Decomposition\n#of the data to project it to a lower dimensional space.\npca = PCA(n_components=2)\npca_representation = pca.fit_transform(hr_norm)","9af82420":"df_pca = pd.DataFrame(pca_representation)\ndf_pca.head(5)","f336e30f":"left_colors = hr[\"left\"].map(lambda s : \"g\"  if s==0 else \"r\")\ndf_pca.plot(x=0,y=1,kind='scatter', c = left_colors)","905d864d":"hr_stay = hr[hr[\"left\"]==0]\nhr_left = hr[hr[\"left\"]==1]","1ed795f0":"fig, axes = plt.subplots(ncols=3,figsize=(10,6))\nsns.catplot(y=\"satisfaction_level\",x=\"left\",data=hr,kind=\"box\",)\naxes[1].hist(hr_stay[\"satisfaction_level\"],bins=50,label=\"Stay\",alpha=0.7)\naxes[1].hist(hr_left[\"satisfaction_level\"],bins=50,label=\"Left\",alpha=0.7)\naxes[1].set_xlabel(\"Satifaction level\")\naxes[1].set_ylabel(\"Count\")\naxes[1].legend()\n\n\ng = sns.kdeplot(data=hr_stay[\"satisfaction_level\"],color='b',shade=True,ax=axes[2])\ng = sns.kdeplot(data=hr_left[\"satisfaction_level\"],color='g',shade=True, ax=axes[2])\ng.legend([\"Stay\",\"Left\"])\ng.set_xlabel('Satifsfaction level')\ng.set_ylabel('Density')\n\n\nplt.tight_layout()\nplt.gcf().clear()","8b0f7084":"fig, axes = plt.subplots(nrows=1,ncols=3,figsize=(10,6))\nsns.catplot(y=\"last_evaluation\",x=\"left\",data=hr,kind=\"box\")\naxes[1].hist(hr_stay[\"last_evaluation\"],bins=50,label=\"Stay\",alpha=0.7)\naxes[1].hist(hr_left[\"last_evaluation\"],bins=50,label=\"Left\",alpha=0.7)\naxes[1].set_xlabel(\"last_evaluation\")\naxes[1].set_ylabel(\"Count\")\naxes[1].legend()\n\ng = sns.kdeplot(data=hr_stay[\"last_evaluation\"],color='b',shade=True,ax=axes[2])\ng = sns.kdeplot(data=hr_left[\"last_evaluation\"],color='g',shade=True, ax=axes[2])\ng.legend([\"Stay\",\"Left\"])\ng.set_xlabel('last_evaluation')\ng.set_ylabel('Density')\n\n\nplt.tight_layout()\nplt.gcf().clear()","feb7c5e9":"fig, axes = plt.subplots(nrows=1,ncols=3,figsize=(10,6))\nsns.catplot(y=\"average_montly_hours\",x=\"left\",data=hr,kind=\"box\")\naxes[1].hist(hr_stay[\"average_montly_hours\"],bins=100,label=\"Stay\",alpha=0.7)\naxes[1].hist(hr_left[\"average_montly_hours\"],bins=100,label=\"Left\",alpha=0.7)\naxes[1].set_xlabel(\"average_montly_hours\")\naxes[1].set_ylabel(\"Count\")\naxes[1].legend()\n\ng = sns.kdeplot(data=hr_stay[\"average_montly_hours\"],color='b',shade=True,ax=axes[2])\ng = sns.kdeplot(data=hr_left[\"average_montly_hours\"],color='g',shade=True, ax=axes[2])\ng.legend([\"Stay\",\"Left\"])\ng.set_xlabel('average_montly_hours')\ng.set_ylabel('Density')\n\nplt.tight_layout()\nplt.gcf().clear()","f3a4c712":"salary_counts = hr.groupby(['left'])['salary'].value_counts(normalize=True).\\\nrename('percentage').mul(100).reset_index()\nsalary_counts","60a4b992":"g = sns.barplot(x='salary',y='percentage',data=salary_counts,\n            hue='left')\ng.set_ylabel('percentage')","7be74681":"hr = pd.read_csv('..\/input\/hrdata\/hr.csv')","ac23edb1":"sales_counts = hr.groupby(['left'])['sales'].value_counts(normalize=True).\\\nrename('percentage').mul(100).reset_index()\nsales_counts.head()","c3144e75":"g = sns.barplot(x='sales',y='percentage',data=sales_counts,\n            hue='left')\nplt.setp(g.get_xticklabels(), rotation=45)\ng.set_ylabel('percentage')","d4972a07":"work_acc_counts = hr.groupby(['left'])['Work_accident'].value_counts(normalize=True).\\\nrename('percentage').mul(100).reset_index()\ndisplay(work_acc_counts.head())\n\npromo_counts = hr.groupby(['left'])['promotion_last_5years'].value_counts(normalize=True).\\\nrename('percentage').mul(100).reset_index()\ndisplay(promo_counts)","573b2677":"fig, axes = plt.subplots(ncols=2,figsize=(10,3))\n\ng = sns.barplot(x='Work_accident',y='percentage',data=work_acc_counts,\n            hue='left',ax=axes[0])\ng.set_ylabel('percentage')\n\ng = sns.barplot(x='promotion_last_5years',y='percentage',data=promo_counts,\n            hue='left',ax=axes[1])\ng.set_ylabel('percentage')","424024aa":"fig, axes = plt.subplots(nrows=1,ncols=3,figsize=(10,5))\nsns.catplot(y=\"time_spend_company\",x=\"left\",data=hr,kind=\"box\")\naxes[1].hist(hr_stay[\"time_spend_company\"],bins=6,label=\"Stay\",alpha=0.7)\naxes[1].hist(hr_left[\"time_spend_company\"],bins=6,label=\"Left\",alpha=0.7)\naxes[1].set_xlabel(\"time_spend_company\")\naxes[1].set_ylabel(\"Count\")\naxes[1].legend()\n\ng = sns.kdeplot(data=hr_stay[\"time_spend_company\"],color='b',shade=True,ax=axes[2])\ng = sns.kdeplot(data=hr_left[\"time_spend_company\"],color='g',shade=True, ax=axes[2])\ng.legend([\"Stay\",\"Left\"])\ng.set_xlabel('time_spend_company')\ng.set_ylabel('Density')\n\n\nplt.tight_layout()\nplt.gcf().clear()","1d341a6c":"hr.groupby(['left']).agg({'time_spend_company':np.mean})","60a865ea":"fig, axes = plt.subplots(nrows=1,ncols=3,figsize=(10,5))\nsns.catplot(y=\"number_project\",x=\"left\",data=hr,kind=\"box\")\naxes[1].hist(hr_stay[\"number_project\"],bins=6,label=\"Stay\",alpha=0.7)\naxes[1].hist(hr_left[\"number_project\"],bins=6,label=\"Left\",alpha=0.7)\naxes[1].set_xlabel(\"number_project\")\naxes[1].set_ylabel(\"Count\")\naxes[1].legend()\n\ng = sns.kdeplot(data=hr_stay[\"number_project\"],color='b',shade=True,ax=axes[2])\ng = sns.kdeplot(data=hr_left[\"number_project\"],color='g',shade=True, ax=axes[2])\ng.legend([\"Stay\",\"Left\"])\ng.set_xlabel('number_project')\ng.set_ylabel('Density')\n\n\nplt.tight_layout()\nplt.gcf().clear()","ac9449db":"hr.groupby(['left']).agg({'number_project':np.mean})","6912aa14":"hr = pd.read_csv('..\/input\/hrdata\/hr.csv')","54e11936":"from sklearn import preprocessing\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n# Converting string labels into numbers.\nhr['salary']=le.fit_transform(hr['salary'])","6c0148f2":"hr","fb60cac7":"# pairplot uses scatterplots and histograms by default\ng = sns.pairplot(hr.drop(labels=['salary','sales','number_project'\\\n               ,'time_spend_company','Work_accident',\n               'promotion_last_5years'],axis=1),hue='left')\ng.map_diag(plt.hist)\ng.map_offdiag(plt.scatter)\ng.add_legend()","0098c381":"hr = pd.read_csv('..\/input\/hrdata\/hr.csv')\nhr.head()","3ce945ab":"hr.info()","22ab2d4e":"from sklearn import preprocessing\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n# Converting string labels into numbers.\nhr['salary']=le.fit_transform(hr['salary'])","61636c74":"hr = hr.drop(labels=[\"sales\"],axis = 1)","519a99dd":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nhr['number_project']=scaler.fit_transform(hr[['number_project']])\nhr['average_montly_hours']=scaler.fit_transform(hr[['average_montly_hours']])\nhr['Work_accident']=scaler.fit_transform(hr[['Work_accident']])\nhr['time_spend_company']=scaler.fit_transform(hr[['time_spend_company']])\nhr['promotion_last_5years']=scaler.fit_transform(hr[['promotion_last_5years']])\nhr['average_montly_hours'].tail()","24c17b4e":"hr.tail()","5de483f8":"x_train = pd.get_dummies(hr.drop(labels='left',axis=1))\ny_train = hr['left']","e957d522":"hr.left.value_counts(normalize=True).mul(100)","8ebb9c9b":"X = x_train[['satisfaction_level']]","bc5586f7":"X.ndim","37a2ed88":"X.shape","fecf3456":"#import estimator\nfrom sklearn.linear_model import LogisticRegression\n#instantiate estimator to crate an estimator object\nlr = LogisticRegression()\ntype(lr)","d3b0c9bb":"# use k-fold cross validation\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, shuffle = True, random_state = 1234)\nnew_scores = cross_val_score(lr,X,y_train,cv=kf)\ndisplay(new_scores)\ndisplay(new_scores.mean())","99a2e2ab":"# use stratified k-fold cross validation\nfrom sklearn.model_selection import cross_val_score\nnew_scores = cross_val_score(lr,x_train,y_train,cv=5)\ndisplay(new_scores)\ndisplay(new_scores.mean())","eb7bda8a":"X = x_train[['satisfaction_level','last_evaluation']]","ee266c34":"#import estimator\nfrom sklearn.linear_model import LogisticRegression\n#instantiate estimator to crate an estimator object\nlr = LogisticRegression()\ntype(lr)","0c41d2b9":"# use k-fold cross validation\nfrom sklearn.model_selection import cross_val_score\nkf = KFold(n_splits = 5, shuffle = True, random_state = 1234)\nnew_scores = cross_val_score(lr,X,y_train,cv=kf)\ndisplay(new_scores)\ndisplay(new_scores.mean())","44db5233":"# use stratified k-fold cross validation\nfrom sklearn.model_selection import cross_val_score\nnew_scores = cross_val_score(lr,X,y_train,cv=5)\ndisplay(new_scores)\ndisplay(new_scores.mean())","d3c4b4c6":"#import estimator\nfrom sklearn.tree import DecisionTreeClassifier\n#instantiate estimator to crate an estimator object\nDTC = DecisionTreeClassifier(max_depth=3)\n#Restricted the depth of the tree to 3 to build a simple tree\n#for better interpretability","8b23fe43":"DTC.fit(x_train,y_train)","cb80f9a2":"from sklearn.model_selection import cross_val_score\nkf = KFold(n_splits = 5, shuffle = True, random_state = 1234)\nnew_scores = cross_val_score(DTC,x_train,y_train,cv=kf)\ndisplay(new_scores)\ndisplay(new_scores.mean())","6b33a709":"#import estimator\nfrom sklearn.tree import DecisionTreeClassifier\n#instantiate estimator to crate an estimator object\nDTC = DecisionTreeClassifier(max_depth=4)\n\n#Restricted the depth of the tree to 3 to build a simple tree\n#for better interpretability","2e917406":"from sklearn.model_selection import cross_val_score\nkf = KFold(n_splits = 5, shuffle = True, random_state = 1234)\nnew_scores = cross_val_score(DTC,x_train,y_train,cv=kf)\ndisplay(new_scores)\ndisplay(new_scores.mean())","23917196":"x_train.shape","6ea9e9e8":"x_train.ndim","ce91b8fb":"#import estimator\nfrom sklearn.ensemble import RandomForestClassifier\n#instantiate estimator to crate an estimator object\nrfc = RandomForestClassifier(n_estimators=100)\ntype(rfc)","1ccf5ec3":"# use stratified k-fold cross validation\nnew_scores = cross_val_score(rfc,x_train,y_train,cv=5)\ndisplay(new_scores)\ndisplay(new_scores.mean())","49c42318":"rfc.fit(x_train,y_train)","07d3a1f1":"rfc.feature_importances_","4c801ab3":"feature_names = x_train.columns","f7d0cf6a":"feature_names","075cdee6":"importances = pd.DataFrame({'feature':x_train.columns,'importance':np.round(rfc.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=True).set_index('feature')\nimportances.plot.barh()","6fd6789f":"# 03. Data Dictionary","e9a769a3":"# 02. Load Data","744244c6":"# 04. Descriptive Statistics","a0565834":"# 01. Import Libraries","0cc5014a":"\nObjectives of building this code is as follows:\n\nwhy are our best and most experienced employees leaving prematurely (inference)\nusing statstical modeling try to predict which valuable employees will leave next (predictive)\n\nTo tackle the above objective, the notebook combines exploratory data analysis and modeling.\n\n\n\n\n","0661d10f":"# 06. Bivariate Analysis","5f530b3f":"# It is clear that the three most important factors for employee retention are satisfaction level, number of projects and the time spent in the company. Quite ironically the features Salary, promotion and the deparment are least important factors in determining the employee retention.","7706c633":"# Statistical Modelling","d21823e7":"# 05. Univariate Analysis"}}