{"cell_type":{"b42d1d43":"code","1b7e5682":"code","f82ab632":"code","8a1eb874":"code","54052f62":"code","742203c0":"code","f6f1480b":"code","71a27359":"code","4813a3fe":"code","063b0403":"code","ad70f49a":"code","f9a0bdf5":"code","9bd786d2":"code","3bb53d84":"code","e7bc3f65":"code","a181dba3":"code","da90b6ee":"code","b9217bbf":"code","677c8694":"code","0f748ca7":"code","143bfe75":"code","4e23979f":"code","2d470fa8":"code","4e682008":"code","ab4bd8b3":"code","06356bf4":"code","f38cd674":"code","516e8472":"code","897dec2f":"code","06a783e0":"markdown","dcdebc14":"markdown","e697f827":"markdown","3694da24":"markdown","b5f23aa2":"markdown","968da735":"markdown","ae6b118f":"markdown","89618934":"markdown","c2176d31":"markdown","ded7686a":"markdown","9e4a0e43":"markdown","22005bf2":"markdown","ec4dffcf":"markdown","1e08be4a":"markdown","cee9347e":"markdown","c44080a6":"markdown","6d2f1279":"markdown","16ee1964":"markdown","8d097ab1":"markdown","6d3b11b7":"markdown","59defa7f":"markdown","4ca66cbb":"markdown","7a81bca7":"markdown","eae0197e":"markdown","7f9ed115":"markdown","6c26a5a1":"markdown","68ce6f83":"markdown"},"source":{"b42d1d43":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.neighbors import NearestNeighbors\nfrom scipy.stats import randint\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom scrapy import Selector\nimport requests\nfrom scrapy.crawler import CrawlerProcess\nimport scrapy\nfrom scrapy.utils.project import get_project_settings","1b7e5682":"anime = pd.read_csv(\"..\/input\/anime.csv\")\nrating = pd.read_csv(\"..\/input\/rating.csv\")","f82ab632":"print(anime.shape)\nprint(anime.drop_duplicates().shape)\nprint(anime.info())\nanime.tail(15)","8a1eb874":"anime.replace(\"Unknown\", np.nan, inplace=True)\nanime[\"episodes\"] = anime[\"episodes\"].astype(float)","54052f62":"print(anime.isnull().sum())\nprint(anime[anime.isnull().any(axis=1)].shape)\nanime[anime.isnull().any(axis=1)].head()\n\n","742203c0":"nombres= anime[anime.isnull().any(axis=1)]\nnombres = nombres[\"name\"].values.tolist()\n\ntipoAnime=pd.get_dummies(anime[\"type\"]).columns\ntipoAnime=tipoAnime.str.strip().unique().tolist()\n\ngenero=anime[\"genre\"].str.get_dummies(sep=\",\").columns\ngenero=genero.str.strip().unique().tolist()","f6f1480b":"buscarURL = 'https:\/\/myanimelist.net\/search\/all?q='\nurlAnime = []\nfor i in nombres:\n    urlAnime.append(buscarURL + i)\n\n\nclass AnimeFcSpider(scrapy.Spider):\n    name = 'anime_fc'\n\n    def start_requests(self):  # start_requests method\n        for url2 in urlAnime:\n            yield scrapy.Request(url=url2,\n                                 callback=self.parse_front)\n\n    def parse_front(self, response):  # First parsing method\n        course_links = response.xpath('\/\/div[@class=\"picSurround di-tc thumb\"]\/a\/@href')\n        yield response.follow(url=course_links[0],\n                              callback=self.parse_pages)\n\n    def parse_pages(self, response):  # Second parsing method\n        crs_name = response.xpath('\/\/h1[@class=\"h1\"]\/span\/text()').extract_first()\n        crs_episodes = response.xpath('\/\/td[@class=\"spaceit\"]\/span[@id=\"curEps\"]\/text()').extract_first()\n        crs_rating = response.xpath('\/\/span[@itemprop=\"ratingValue\"]\/text()').extract_first()\n        crs_id = response.xpath('\/\/input[@name=\"aid\"]\/@value').extract_first()\n\n        crs_genre = response.xpath('\/\/div\/a\/@title').extract()\n        crs_genre = np.intersect1d(crs_genre, genero)\n        crs_genre = ','.join(map(str, crs_genre))\n\n        crs_type = response.xpath('\/\/div\/a\/text()').extract()\n        crs_type = np.intersect1d(crs_type,tipoAnime)\n        crs_type = ','.join(map(str, crs_type))\n       \n\n        list_name.append(crs_name)\n        list_genre.append(crs_genre)\n        list_type.append(crs_type)\n        list_episodes.append(crs_episodes)\n        list_rating.append(crs_rating)\n        list_id.append(crs_id)\n\n\n\nlist_name = list()\nlist_genre = list()\nlist_type = list()\nlist_episodes = list()\nlist_rating = list()\nlist_id = list()\n\ns = get_project_settings()\ns['CONCURRENT_REQUESTS_PER_IP'] = 16\ns['CONCURRENT_REQUESTS_PER_DOMAIN '] = 16\ns['DOWNLOAD_DELAY'] = 2.5\ns['CONCURRENT_REQUESTS'] = 32\ns['CONCURRENT_REQUESTS'] = 32\n\n\nprocess = CrawlerProcess(s)  # Run the Spider\nprocess.crawl(AnimeFcSpider)\nprocess.start()\n","71a27359":"DataNa = pd.DataFrame({\"anime_id\":list_id, \"name\":list_name,\"genre\":list_genre,\n                       \"type\":list_type, \"episodes\":list_episodes, \"rating\":list_rating})\n\nDataNa.replace(\"\", np.nan, inplace=True)\nDataNa.replace('?', np.nan, inplace=True)\n\nprint(DataNa.shape)\nprint(DataNa.isnull().sum())\nDataNa.head(10)","4813a3fe":"DataNa[\"anime_id\"] = DataNa[\"anime_id\"].astype(float)\nDataNa[\"episodes\"] = DataNa[\"episodes\"].astype(float)\nDataNa[\"rating\"] = DataNa[\"rating\"].astype(float)\nDataNa.info()","063b0403":"dataNueva= pd.merge(anime, DataNa,left_on=\"anime_id\",right_on=\"anime_id\", how=\"left\")\ndataNueva.info()\nprint(anime.isnull().sum())\nprint(anime[anime.isnull().any(axis=1)].shape)\n","ad70f49a":"dataNueva.loc[dataNueva[\"genre_x\"].isna(),\"genre_x\"] = dataNueva[\"genre_y\"]\ndataNueva.loc[dataNueva[\"type_x\"].isna(),\"type_x\"] = dataNueva[\"type_y\"]\ndataNueva.loc[dataNueva[\"episodes_x\"].isna(),\"episodes_x\"] = dataNueva[\"episodes_y\"]\ndataNueva.loc[dataNueva[\"rating_x\"].isna(),\"rating_x\"] = dataNueva[\"rating_y\"]\n","f9a0bdf5":"dataNueva.drop([\"name_y\", \"genre_y\", \"type_y\", \"episodes_y\", \"rating_y\"],axis=1,inplace=True)\ndataNueva.columns = dataNueva.columns.str.replace('_x', '')\n\nprint(dataNueva.isnull().sum())\nprint(dataNueva[dataNueva.isnull().any(axis=1)].shape)","9bd786d2":"anime=dataNueva.copy()\nprint(anime.groupby(\"type\")[\"episodes\"].describe())\n\nanime.loc[(anime[\"type\"]==\"OVA\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"OVA\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"Movie\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"Movie\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"Music\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"Music\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"ONA\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"ONA\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"Special\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"Special\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"TV\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"TV\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"].isna()) & (anime[\"episodes\"].isna()),\"episodes\"] = anime[\"episodes\"].median()\n\nprint(anime[anime.isnull().any(axis=1)].shape)\nprint(anime.isnull().sum())","3bb53d84":"anime[\"type\"].replace(np.nan, \"notype\", inplace=True)\nprint(anime.isnull().sum())","e7bc3f65":"anime[\"genre\"].replace(np.nan, \"nogenre\", inplace=True)\nprint(anime.isnull().sum())","a181dba3":"def impute_median(series):\n    return series.fillna(series.median())\n\nanime.rating = anime.groupby(['type', 'episodes'])[[\"rating\"]].transform(impute_median)\nanime.rating = anime.groupby(['genre', 'episodes'])[[\"rating\"]].transform(impute_median)\nanime[\"rating\"]=anime[\"rating\"].fillna(anime[\"rating\"].median())\nprint(anime.isnull().sum())\n","da90b6ee":"anime=anime.reset_index()","b9217bbf":"anime_data = pd.concat([anime[\"genre\"].str.get_dummies(sep=\",\"),\n                           anime[\"type\"].str.get_dummies(sep=\",\"),anime[[\"rating\"]],\n                            anime[[\"members\"]],anime[\"episodes\"]],axis=1)\n\nanime_data.head()\n","677c8694":"anime_data = MaxAbsScaler().fit_transform(anime_data)\nanime_data","0f748ca7":"KNNanime = NearestNeighbors(n_neighbors=7, algorithm='ball_tree').fit(anime_data)\ndistances, indices = KNNanime.kneighbors(anime_data)","143bfe75":"def nombres_indices(name):  # Toma el nombre del anime y devuelve su indice correspondiente\n    return anime[anime[\"name\"]==name].index.tolist()[0] \n","4e23979f":"def recomendados_por_anime(nombre):  # Muestra el grupo de animes m\u00e1s cercanos al consultado\n     found_id = nombres_indices(nombre)\n     for id in indices[found_id][1:]:\n            print(anime.loc[id][\"name\"])\n            \nrecomendados_por_anime(\"Naruto\")\n        \n       ","2d470fa8":"print(rating.shape)\nprint(rating.isnull().sum())\nrating.head()","4e682008":"merge = pd.merge(anime, rating, on=\"anime_id\", how=\"left\")\nmerge.head()","ab4bd8b3":"def similar_animes(id_anime):  # Trae todos los id_anime relacionados con un id_anime dado\n    \n    id_list=[]\n    found_id = anime[anime[\"anime_id\"]==id_anime].index.tolist()[0]  # Indice del id ingresado\n    for id in indices[found_id][1:]:\n            id_list.append(anime.loc[id][\"anime_id\"])\n            \n    return id_list  \n        \n            \ndef similar_animes_usuarios(id_user):  # Crea una lista con todos los animes relacionados con los animes visto por el usuario\n    \n    a = merge[merge[\"user_id\"]==id_user].anime_id.values\n    lista = []\n    for i in range(len(a)):\n        lista.append(similar_animes(a[i]))\n    return lista\n            \n        \ndef similar_animes_usuarios_freq(id_user): # Crea una lista con los 6 anime m\u00e1s recomendados del usuario\n    a=similar_animes_usuarios(id_user)\n    r= np.array([])\n    for i in range(5):\n        f1 = pd.Series( (v[i] for v in a))\n        r = np.append(r,f1)\n        \n    gh = merge[merge[\"user_id\"]==id_user].anime_id.values\n    rdiff=np.setdiff1d(r, gh)\n    kk = pd.DataFrame({'Column1':rdiff})\n    pda = pd.crosstab(index=kk[\"Column1\"].astype(int), columns= \"count\")\n    pda2 = pda.sort_values(\"count\", ascending=False).head(6).index.tolist() \n    \n    return pda2\n        \n    \ndef recomendados_usuario(id_user):  # Pasa de anime_id a los nombres de los anim\u00e9\n    \n    a=similar_animes_usuarios_freq(id_user)\n    for id in a:\n        print(anime[anime[\"anime_id\"]==id][\"name\"].values)\n        \n","06356bf4":"recomendados_usuario(3454)","f38cd674":"recomendados_usuario(8765)","516e8472":"recomendados_por_anime(\"Dragon Ball Z\")","897dec2f":"recomendados_por_anime(\"Pokemon\")","06a783e0":"#### Re-codificando variables\n\nNo era conveniente tener los g\u00e9neros apilados como categor\u00eda separadas por comas en una \u00fanica casilla, por lo que se separaron y pasaros a variables dicot\u00f3micas al igual que \"type\". Las variables restantes ser\u00e1n escaladas para no tener problemas con los algoritmos futuros, dado que utilizan distancias.","dcdebc14":"## Parte 2: Animes recomendados para cada usuario\n\nEn la parte 1 s\u00f3lo conseguimos encontrar animes similares a otros animes, pero no estamos recomendando nada al usuario, es por esto, que utilizaremos la data riting.csv que contiene informaci\u00f3n del usuario para crear un recomendado de anime seg\u00fan preferencias del usuario utilizando las distancias de similitud obtenidas en la parte 1.","e697f827":"#### Variable \"rating\"\n\nPara esta variable haremos una imputaci\u00f3n un poco m\u00e1s dirigida, se agrupar\u00e1 por \"type\" y \"epidodes\" y se calcular\u00e1 la mediana de rating con esa agrupaci\u00f3n para imputar rating. En caso que los grupos \"type\" y \"episodes\" no tengan una mediana para \"rating\" se agrupar\u00e1 por \"genre\" y \"epidodes\" y si a\u00fan as\u00ed no hay una mediana para \"rating\", entoces los datos nulos se reemplazar\u00e1n por la mediana global. ","3694da24":"#### Cargando Dataset","b5f23aa2":"Eliminamos las varibles nuevas dado que ya utilizamos sus valores. ","968da735":"#### Variable \"episodes\"\n\nLa primera variable a imputar es \"episodes\", dado que es la con mayor cantidad de NaN, para esto agruparemos por \"type\" y utilizaremos la mediana() de la cantidad de episodios de cada grupo.","ae6b118f":"### Explorando data riting\n\nEsta data contiene un id del usuario (user_id), el id del anime (anime_id) y la calificaci\u00f3n que da el usuario al anime (rating).\n\nNo contiene NaN, pero la variable rating contiene el valor -1 que significa que el usuario no calific\u00f3 el anime, esto puede ser considerado como un dato faltando.\n","89618934":"#### Preprocesando data obtenida con web scraping\n\nCambiamos el tipo de datos al mismo que la data original","c2176d31":"## Web Scraping para rellenar valores nulos","ded7686a":"### Utilizando funciones de recomendaci\u00f3n","9e4a0e43":"## Preprocesamiento data anime","22005bf2":"## Cargando datos y paquetes","ec4dffcf":"### Construyendo recomendador\n\nNecesitamos obtener todos los animes vistos por un usuario especifico, dado que seg\u00fan esto podemos capturar sus preferencias, luego de obtenidos los animes vistos por el usuario se procede a guardar en una lista con todos los animes similares a los que a visto el usuario (vecinos del algoritmo KNN ) excluyendo los que ha vistos (para no recomendar un anime que el usuario ya vio). Por \u00faltimo, se toma esta lista y se calcula la frecuencia de los animes que m\u00e1s se repiten en la lista y se ordenan de mayor a menor. \n\nLa funci\u00f3n ecomendados_usuario() devuelve los animes recomendados para el usuario.\n","1e08be4a":"Se resetea el \u00edndice de la data para no tener problemas en el futuro para buscar filas especificas","cee9347e":"### Explorando datos\n\nEn primera instancia se explora la existencia de casos duplicados, tambi\u00e9n la dimensi\u00f3n de la data y el tipo de dato de cada variable. Se observa que la variable \"episodes\" es de tipo object y no num\u00e9rico dado que contiene una categor\u00eda \"Unknown\" que indica que no se conoce la cantidad de episodios del anime, es por esto, que se procede a cambiar \"Unknown\" por NaN y luego el tipo de dato a num\u00e9rico.\n\n","c44080a6":"#### Animes recomendados por anime","6d2f1279":"### Construyendo data con variables para an\u00e1lisis","16ee1964":"#### Variable \"genre\"\n\nTenemos 45 anim\u00e9 con nulos en genero. pero dado que esta variable es muy importante en la elecci\u00f3n del anim\u00e9 (por conocimiento propio) una imputaci\u00f3n err\u00f3nea ser\u00eda grabe, por lo tanto haremos lo mismo que con \"type\" y crearemos una categor\u00eda para los nulos \"nogenre\"","8d097ab1":"### K vecino m\u00e1s cercano (KNN)\n\nEl K-Vecino m\u00e1s cercano es la opci\u00f3n que me pareci\u00f3 m\u00e1s aceptada, dado que es un algoritmo jer\u00e1rquico por lo cual no tenemos que elegir grupos a priori y es exactamente lo que estamos buscamos, explico: \n\nLo que necesitamos es un algoritmo que tome un anime (cada fila representa un anime diferente) y de acuerdo a sus caracter\u00edsticas (calificaci\u00f3n, g\u00e9neros, tipo y cantidad de episodios) pueda encontrar animes similares. KNN toma la distancia de una observaci\u00f3n con cada observaci\u00f3n de la data (importante tener los datos en la misma escala) y es exactamente lo que nos interesa rescatar, dado que es un claro indicador de similitud entre animes, adem\u00e1s nos da la opci\u00f3n de elegir los k vecinos m\u00e1s pr\u00f3ximos al anim\u00e9 buscado. \n\n(El objetivo no es encontrar cl\u00faster o grupos de anim\u00e9, si no desde un punto establecido en el espacio rescatar los puntos m\u00e1s pr\u00f3ximos)\n\nPar\u00e1metros KNN\n\nn_neighbors:\nEl n\u00famero de vecinos solo nos agrega m\u00e1s elementos en la salida, es decir, n_neighbors=k s\u00f3lo me indicar\u00e1 que \"\u00edndices\" tendr\u00e1 un vector de k-1 elementos correspondiente los \u00edndices de los vecinos m\u00e1s cercano del anime consultado.  \n\n\n","6d3b11b7":"#### Librer\u00edas ","59defa7f":"#### Variable \"type\"\n\nEsta variable tiene 9 nulos, podr\u00edamos inferir el tipo por la cantidad de cap\u00edtulos del anim\u00e9, pero justamente estos 9 anim\u00e9 no tienen esa informaci\u00f3n por lo que reemplazaremos el dato nulo por \"notype\" para no eliminar la observaci\u00f3n y as\u00ed perder informaci\u00f3n valiosa. \n","4ca66cbb":"### Indentificando NaN \n\nPodemos detectar que las variables \"genre\", \"type\", \"episodes\" y \"rating\" poseen datos faltantes, donde \"episodes\" es la variable con m\u00e1s datos faltantes, seguida por \"rating\". Por otro lado, \"genre\" y \"type\" tienen mucho menos de missing. En total la data tiene 464 NaN.","7a81bca7":"## Imputando datos nulos","eae0197e":"## Algoritmo no supervisado para encontrar elementos similares \n## Parte 1: Animes similares a un anime especifico","7f9ed115":"El siguiente paso es cruzar las datas anime y rating por la izquierda, dado que la data \"rating\" puede contener\nanimes que no se encuentran en la data \"anime\" y esto puede ser un problema en el futuro. ","6c26a5a1":"#### Animes recomendados por usuario","68ce6f83":"Cruzamos la data obtenida con la origianal para luego reemplazar los nulos con la informaci\u00f3n nueva"}}