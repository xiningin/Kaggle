{"cell_type":{"4596fe6f":"code","d135bccd":"code","58fde3bd":"code","bafbe9a6":"code","a7fcc08b":"code","9444a055":"code","e1268127":"code","aa8de925":"code","1a9736e2":"code","6e33ba71":"code","52631580":"code","1e485e36":"code","4e5ea106":"code","592fb2a4":"code","208b37ab":"code","8ccc3e6b":"code","298c6308":"code","e3c7b5bd":"code","e70996a5":"code","dca3a429":"code","13a7d115":"code","fb80456f":"code","c3d89669":"code","01898535":"code","6fe35d05":"code","6729f358":"code","e2ddaeed":"code","95bbb3f7":"code","23ead116":"code","bd9b7883":"code","09d7e27f":"code","6c69f7fe":"code","005ecf6a":"code","2e81fd50":"code","07c7d8de":"code","781b9ae6":"code","1eeee734":"code","c27d56e8":"code","5aa9057b":"code","fc7d35d2":"code","444df22d":"code","c6feadcf":"code","012fd716":"code","1e696015":"markdown","9657db33":"markdown","6d3836f1":"markdown","7b6da8d4":"markdown","c7aee742":"markdown","684733c8":"markdown","4906a554":"markdown","10dae4c7":"markdown","6cb4ac87":"markdown","9a0485d7":"markdown","051577bd":"markdown","39cd0639":"markdown","e4875a44":"markdown","7b29c6a6":"markdown","6afb26a9":"markdown","6b817f03":"markdown","32e86d44":"markdown","51a5db0f":"markdown","5b15591c":"markdown","07be80ed":"markdown","556fd8dd":"markdown","89c1298a":"markdown","5ed5cd22":"markdown","af8d203f":"markdown","a567e9b4":"markdown","b5d15c9d":"markdown","42a72e9d":"markdown","34fd48ee":"markdown","e3e542a1":"markdown","13fac400":"markdown","50bae44b":"markdown","0271ab22":"markdown","89ebbfc4":"markdown","9bf76697":"markdown","41612090":"markdown","b419a9b3":"markdown","ab9ac08f":"markdown","ee1cbe48":"markdown","ec5a40d4":"markdown","b9073876":"markdown","b07cc08a":"markdown","6ffd3146":"markdown","bf446b3e":"markdown","3865e07d":"markdown","36d59d0e":"markdown","203cace8":"markdown","4538adc5":"markdown"},"source":{"4596fe6f":"#Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\nimport warnings\nwarnings.filterwarnings('ignore')","d135bccd":"\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False","58fde3bd":"raw_data=pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")","bafbe9a6":"data=raw_data.copy()\ndata.head()","a7fcc08b":"data.shape","9444a055":"data.info()","e1268127":"data.describe()","aa8de925":"data.isnull().sum()","1a9736e2":"# Adding a column for the total marks.\ndata['total_marks']=data['math score']+data['reading score']+data['writing score']","6e33ba71":"data_numerical = data[['math score','reading score','writing score','total_marks']]\ndata_categorical=data[['gender','race\/ethnicity','parental level of education','lunch','test preparation course']]","52631580":"fig,ax=plt.subplots(2,2,figsize=(15,10))\nfor i,idx in enumerate(data_numerical.columns):\n    sns.histplot(ax=ax[i%2,i\/\/2],data=data_numerical[idx],kde=True)\n    ax[i%2,i\/\/2].set_title(idx)\n    ","1e485e36":"sns.kdeplot(data=data_numerical,shade=True)","4e5ea106":"# Skewness and kurtosis\ns_k=[]\nfor i in data_numerical.columns:\n    s_k.append([i,data_numerical[i].skew(),data_numerical[i].kurt()])\nskew_kurt=pd.DataFrame(s_k,columns=['Columns','Skewness','Kurtosis'])\nskew_kurt","592fb2a4":"fig,ax = plt.subplots(2,2,figsize=(15,12))\n\n#Math and reading scores\nax[0,0].scatter(x='math score',y='reading score',data=data[data['gender']=='male'],alpha=0.5,label='male')\nax[0,0].scatter(x='math score',y='reading score',data=data[data['gender']=='female'],alpha=0.5,label='female',color='brown')\nax[0,0].set_xlabel('Math Scores')\nax[0,0].set_ylabel('Reading Scores')\nax[0,0].set_title('Math and reading score')\nax[0,0].legend()\n\n# Mathematics and Writing Scores\nax[0,1].scatter(x='math score',y='writing score',data=data[data['gender']=='male'],alpha=0.5,label='male')\nax[0,1].scatter(x='math score',y='writing score',data=data[data['gender']=='female'],alpha=0.5,label='female',color='brown')\nax[0,1].set_xlabel('Math Scores')\nax[0,1].set_ylabel('Writing Scores')\nax[0,1].set_title('Math and writing score')\nax[0,1].legend()\n# Reading and writing Scores\nax[1,0].scatter(x='writing score',y='reading score',data=data[data['gender']=='male'],alpha=0.5,label='male')\nax[1,0].scatter(x='writing score',y='reading score',data=data[data['gender']=='female'],alpha=0.5,label='female',color='brown')\nax[1,0].set_xlabel('Reading Score')\nax[1,0].set_ylabel('Writing Score')\nax[1,0].set_title('Reading and writing score')\nax[1,0].legend()\nax[1,1].set_visible(False)","208b37ab":"color_map = ['lightgrey' for _ in range(5)]\ncolor_map[0] =color_map[1]='seagreen'\nfig,ax = plt.subplots(1,1,figsize=(12,5))\ndata_group = data['race\/ethnicity'].value_counts().sort_values(ascending=False)\nax.bar( data_group.index, data_group , width=0.4,color=color_map )\nax.grid(linestyle=':',axis='y',alpha=0.4)\nfor an in data_group.index:\n    ax.annotate(data_group[an],xy=(an,data_group[an]+10),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Number of people in different groups',fontweight='bold')\n","8ccc3e6b":"plt.figure(figsize=(15,10))\nfor indx,val in enumerate(data_categorical.columns):\n    plt.subplot(2,3,indx+1)\n    sns.swarmplot(x=data_categorical[val],y=data_numerical['total_marks'],palette='OrRd')","298c6308":"plt.figure(figsize=(10,5))\nsns.swarmplot(x=data_categorical['parental level of education'],y=data_numerical['total_marks'],palette='OrRd')","e3c7b5bd":"color_map = ['lightgrey' for _ in range(6)]\ncolor_map[0] =color_map[1]='seagreen'\nfig,ax = plt.subplots(1,1,figsize=(12,5))\ndata_group = data['parental level of education'].value_counts().sort_values(ascending=False)\nax.bar( data_group.index, data_group , width=0.4,color=color_map)\nax.grid(linestyle=':',axis='y',alpha=0.4)\nfor an in data_group.index:\n    ax.annotate(data_group[an],xy=(an,data_group[an]+10),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Education Level of Parents')\n","e70996a5":"data1=data[['gender','lunch','test preparation course']]\nfig,ax=plt.subplots(2,2,figsize=(10,10))\ncolor_map = ['lightgrey' for _ in range(2)]\ncolor_map[0] ='seagreen' #color highlight\nfor i,idx in enumerate(data1.columns):\n    z=data1[idx].value_counts().sort_index()\n    ax[i%2][i\/\/2].bar(z.index,z , color=color_map)\n    ax[i%2][i\/\/2].set_title(idx)  \n    ax[i%2][i\/\/2].grid(linestyle=':',axis='y',alpha=0.4)  \n    \nax[1][1].set_visible(False)\n    ","dca3a429":"highest_group = data.groupby(by='race\/ethnicity')['total_marks'].sum().sort_values(ascending=False).reset_index()\ncolor_map = ['lightgrey' for _ in range(5)]\ncolor_map[0] =color_map[1]='seagreen' #color highlight\nfig,ax = plt.subplots(1,1,figsize=(12,5))\nax.bar(highest_group['race\/ethnicity'],highest_group['total_marks'],color=color_map,width=0.55,linewidth=0.7)\nfor an in highest_group.index:\n    ax.annotate(highest_group['total_marks'][an],xy=(highest_group['race\/ethnicity'][an],highest_group['total_marks'][an]+1000),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Total marks of people')\nax.grid(axis='y',linestyle='-',alpha=0.2)","13a7d115":"parents= data.groupby(by='parental level of education')['total_marks'].sum().sort_values(ascending=False).reset_index()\ncolor_map = ['lightgrey' for _ in range(6)]\ncolor_map[0] =color_map[1]='seagreen' #color highlight\nfig,ax = plt.subplots(1,1,figsize=(12,5))\nax.bar(parents['parental level of education'],parents['total_marks'],color=color_map,width=0.55,linewidth=0.7)\nfor an in parents.index:\n    ax.annotate(parents['total_marks'][an],xy=(parents['parental level of education'][an],parents['total_marks'][an]+1000),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Parents effect')\nax.grid(axis='y',linestyle='-',alpha=0.2)","fb80456f":"plt.figure(figsize=(15,7))\ncolor_map = ['lightgrey' for _ in range(6)]\ncolor_map[0] ='seagreen' #color highlight\nplt.subplot(1, 3, 1)\nsns.barplot(x='test preparation course',y='math score',data=data,hue='gender',palette=color_map)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.barplot(x='test preparation course',y='reading score',data=data,hue='gender',palette=color_map)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.barplot(x='test preparation course',y='writing score',data=data,hue='gender',palette=color_map)\nplt.title('WRITING SCORES')\nplt.show()","c3d89669":"# Number of students who passed in math\ndata['maths_passed']= data['math score'].apply(lambda x : 'P' if x>40 else 'F')\ndata['maths_passed'].value_counts()","01898535":"# Number of students who passed in reading\ndata['reading_passed'] = data['reading score'].apply(lambda x: 'P' if x>40 else 'F')\ndata['reading_passed'].value_counts()","6fe35d05":"# Number of students who passed in writing.\ndata['writing_passed']=data['writing score'].apply(lambda x: 'P' if x>40 else 'F')\ndata['writing_passed'].value_counts()","6729f358":"plt.subplots(1,3,figsize=(15,7))\nplt.subplot(1,3,1)\nsns.countplot(x='gender',data=data,hue='maths_passed',palette=color_map)\nplt.title('Students who passed in maths')\nplt.subplot(1,3,2)\nsns.countplot(x='gender',data=data,hue='reading_passed',palette=color_map)\nplt.title('Students who passed in reading')\nplt.subplot(1,3,3)\nsns.countplot(x='gender',data=data,hue='writing_passed',palette=color_map)\nplt.title('Students who passed in writing')","e2ddaeed":"# Students percentage\ndata['Percentage']=data['total_marks']\/3  # Percentage = number\/100, here the highest marks =300. So,dividing by 3 gives the % .","95bbb3f7":"data['OverAll_PassStatus'] = data.apply(lambda x : 'F' if x['maths_passed'] == 'F' or \n                                    x['reading_passed'] == 'F' or x['writing_passed'] == 'F' else 'P', axis =1)","23ead116":"def GetGrade(Percentage, OverAll_PassStatus):\n    if ( OverAll_PassStatus == 'F'):\n        return 'F'    \n    if ( Percentage >= 80 ):\n        return 'A'\n    if ( Percentage >= 70):\n        return 'B'\n    if ( Percentage >= 60):\n        return 'C'\n    if ( Percentage >= 50):\n        return 'D'\n    if ( Percentage >= 40):\n        return 'E'\n    else: \n        return 'F'\n\ndata['Grade'] = data.apply(lambda x : GetGrade(x['Percentage'], x['OverAll_PassStatus']), axis=1)\ncolor_map[0] =color_map[1]='seagreen'\ngrades=data['Grade'].value_counts().sort_values(ascending=False)\nfig,ax=plt.subplots(1,1,figsize=(12,5))\nax.bar(grades.index,grades,color=color_map,width=0.55)\nfor an in grades.index:\n    ax.annotate(grades[an],xy=(an,grades[an]+5),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nax.set_title('Grades of students')\nax.grid(axis='y',linestyle='-',alpha=0.4)\nplt.show()","bd9b7883":"color_map = ['lightgrey' for _ in range(2)]\ncolor_map[0] ='seagreen'","09d7e27f":"fig,ax=plt.subplots(1,1,figsize=(12,5))\nsns.countplot(x='Grade',hue='gender',data=data,palette=color_map)\nax.set_title('Male and Female Students Grades')\nax.grid(axis='y',linestyle=':',alpha=0.4)\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)","6c69f7fe":"fig,ax=plt.subplots(1,1,figsize=(12,5))\nsns.countplot(x='Grade',hue='lunch',data=data,palette=color_map)\nax.set_title(' Relationship between grades and lunch')\nax.grid(axis='y',linestyle=':',alpha=0.4)\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)","005ecf6a":"fig,ax=plt.subplots(1,1,figsize=(12,5))\nsns.countplot(x='Grade',hue='test preparation course',data=data,palette=color_map)\nax.set_title('Test Preperation Course and Grades')\nax.grid(axis='y',linestyle=':',alpha=0.4)\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)","2e81fd50":"data_dummies = data[['gender', 'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course']]\ndata_dummies=pd.get_dummies(data_dummies)\ndata_dummies.head()","07c7d8de":"data_totalmarks=data['total_marks']","781b9ae6":"# Importing the libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor","1eeee734":"# Splitting the data into training and testing sets\nx_train,x_test,y_train,y_test = train_test_split(data_dummies,data_totalmarks,test_size=0.2,random_state=1)","c27d56e8":"#https:\/\/towardsdatascience.com\/what-are-the-best-metrics-to-evaluate-your-regression-model-418ca481755b\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\ndata_scores=[]\ndef EvaluatingModels(true_value,predicted_value,model):\n    MSE=mean_squared_error(true_value,predicted_value,squared=True) # If squared = True then its MSE, if squared = False then its RMSE\n    RMSE=mean_squared_error(true_value,predicted_value,squared=False)\n    MAE= mean_absolute_error(true_value,predicted_value)\n    R_Squared = r2_score(true_value,predicted_value)\n    data_scores.append([model,MSE,RMSE,MAE,R_Squared])\n    print(\"MSE:\", MSE)\n    print(\"MAE:\", MAE)\n    print(\"RMSE:\", RMSE)\n    print(\"R-squared:\", R_Squared)","5aa9057b":"linear_regressor=LinearRegression(normalize=True)\nlinear_regressor.fit(x_train,y_train)\nlin_prediction= linear_regressor.predict(x_test)\nEvaluatingModels(y_test,lin_prediction,'Linear Regression')","fc7d35d2":"regress_dtree=DecisionTreeRegressor(random_state=1)\ndtree_model = regress_dtree.fit(x_train,y_train)\ny_predtree = dtree_model.predict(x_test)\nEvaluatingModels(y_test,y_predtree,'Decision Tree Regression')","444df22d":"from sklearn.ensemble import RandomForestRegressor\nrf_regressor=RandomForestRegressor(random_state=1)\nrf_model=rf_regressor.fit(x_train,y_train)\ny_rfpred = rf_model.predict(x_test)\nEvaluatingModels(y_test,y_rfpred,'Random Forest Regression')","c6feadcf":"# https:\/\/towardsdatascience.com\/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e\nfeature_importances = pd.DataFrame(rf_model.feature_importances_,\n                                   index = x_train.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nplt.figure(figsize=(10,10))\nsns.barplot(x=feature_importances['importance'].values, y= feature_importances['importance'].index,palette='rocket_r')","012fd716":"df=pd.DataFrame(data_scores,columns=['Model','MSE','RMSE','MAE','R2'])\ndf","1e696015":"### Checking for missing values","9657db33":"### Which subject has the most number of failures?\n","6d3836f1":"Most of the students achieved a B Grade followed by Grade C. ","7b6da8d4":"We use One-Hot Encoding to encode categorical variables. Encoding is necessary because machine learning models do not work with categorical variables. For One-Hot Encoding we use pd.get_dummies()","c7aee742":"We can see that our numerical data follows the normal distribution.","684733c8":"### Creating dummy variables","4906a554":"#### Feature Importance Plot for Random Forest","10dae4c7":"#### How does gender effect the students performance individually","6cb4ac87":"### References","9a0485d7":"Most of the parents attended some college(226) and almost the same amount of people have an associate's degree. Parents who hold a master's degree are very few in number.","051577bd":"We can observe from the above figures that:\n1. Females students are more than male students.\n2. The students who have completed any course are less than the students who did not prepare.\n3. Students who prefer standard lunch are more in number than students who prefer free\/reduced lunch.","39cd0639":"#### Test Preperation Course and Grades","e4875a44":"#### Relationship between grades and lunch","7b29c6a6":"#### Male and Female Students Grades\n","6afb26a9":"1. https:\/\/www.kaggle.com\/spscientist\/student-performance-in-exams\n2. https:\/\/www.kaggle.com\/subinium\/simple-matplotlib-visualization-tips\n3. https:\/\/www.kaggle.com\/subinium\/kaggle-2020-visualization-analysis\n4. https:\/\/www.kaggle.com\/josephchan524\/studentperformanceregressor-rmse-12-26-r2-0-26","6b817f03":"We can see from the above figure that :\n1. Most of the scores fall between 40-100 range.\n2. Only a small portion of students scored less than 40.\n3. The scores increases linearly with each other.","32e86d44":"#### My other notebooks \n1) https:\/\/www.kaggle.com\/ruthvikpvs\/stroke-data-eda-and-prediction\n\n2) https:\/\/www.kaggle.com\/ruthvikpvs\/heart-attack-analysis-eda-and-prediction","51a5db0f":"### Feature Classification\nIt is good practice to categorize the numerical and categorical variables.","5b15591c":"#### Group  with most number of people\n","07be80ed":"#### Grading the Students","556fd8dd":"As a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric. \n","89c1298a":"#### Decision Tree Regression","5ed5cd22":"### Training the Models","af8d203f":"We can observe from the above graphs that most of the students score above 150 marks.","a567e9b4":"If we compare the three models we used for predictions. We can observe that:\n1. Linear regression performed far better than Decision Trees and Random Forest algorithms.\n2. The Mean Square Error value of Linear Regression is 1436 (on average the predictions have 1436 difference from the actual values)\n3. The R squared value of Decision Tree Regression is negative. R-squared values less than 0 means a horizontal line fits the data better than our model. So, decision tree regression is not suitable for our data.\n4. Random Forest performs better than Decision Trees but not as good as Linear Regression.\n5. Even though Linear Regression performs better than these models, the r_squared value is only 0.24 and the predictions are not accurate most of the time. ","b5d15c9d":"#### Descriptive Analytics","42a72e9d":"#### RandomForest Regression","34fd48ee":"#### Evaluating the performance of our regression models.","e3e542a1":"There are no missing values present in our dataset. ","13fac400":"### Do upvote the kernel if you find it useful. Feedback is highly appreciated. Thank You.","50bae44b":"### Categorical Scatterplots","0271ab22":"We use histograms to observe how the scores of students are distributed.","89ebbfc4":"Use the shape method to see the number of rows and columns in our dataset.","9bf76697":"#### Parents educational levels and students performance","41612090":"#### Comparing the performance","b419a9b3":"#### KDE plot","ab9ac08f":"#### Gender , Lunch and Test preperation","ee1cbe48":"R squared : Measures how much of variability in dependent variable can be explained by the model.\n\nMAE : Gives us the difference between the actual value and predicted value. (Eg: If the actual value is 10000 and the predicted value is 5000, then we can say that the actual value is 5000 more than the predicted value).\n\nMSE : Mean Square Error is an absolute measure of the goodness for the fit.","ec5a40d4":"As we cannot see the parental level of education clearly , I will plot it again.","b9073876":"\n#### Education level of Parents","b07cc08a":"#### Scatterplots for the numerical variables","6ffd3146":"#### Linear Regression","bf446b3e":"The students in Group C scored the most number of marks among all the groups followed by groups D,B,E and group A.","3865e07d":"* There are 1000 rows and 8 columns in our dataset.\n* The info() method gives the summary of our data. This us useful as we can check if there are any missing values present or not.","36d59d0e":"1. The number of people who failed in mathematics are more than other subjects.\n2. Overall the number of students who failed are significantly less than the students who passed.","203cace8":"Group C has the most number of people and Group A has the least amount of people.","4538adc5":"#### The group of people who scored the highest number of total marks"}}