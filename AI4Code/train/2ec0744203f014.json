{"cell_type":{"7cf2e923":"code","9e18fdce":"code","17b137e0":"code","6b897261":"code","0ca31257":"code","1cff2b1b":"code","71c3a021":"code","34e9a9b3":"code","7c927681":"code","48ee3997":"code","71cca428":"code","671f6a65":"code","e867be72":"code","792cd52f":"code","098a4980":"code","8d60a939":"code","4e207ef7":"code","6cad8d52":"code","d1684a16":"code","1b68089e":"code","dac773a2":"code","20f90e90":"code","c5915644":"code","6f775e81":"code","bc44f218":"code","32c08c82":"code","e3fd4bf2":"code","ef908058":"code","1b9c47fe":"code","7089614d":"code","3e4adb61":"code","3906dfee":"code","796846fa":"code","ddb32929":"code","f28c42c7":"code","d5befd6f":"code","f4a4737f":"code","b57f8672":"code","3c8de145":"code","a8c1fa56":"code","9bdde805":"code","c5bdf225":"code","b5e44b21":"code","c381abca":"code","32d1c08c":"code","18cb082a":"code","12a562d6":"code","0d20d412":"code","ea362b90":"code","c4ce3fb6":"code","2c520fb1":"code","61b1502d":"code","4652de5c":"code","b89844d4":"code","31b4f9cc":"code","972bfa96":"code","7570abc6":"code","ea38198a":"code","59051d15":"code","3db32e69":"code","ac8cdab2":"code","62b81156":"code","3d1d0d21":"code","1c34a492":"code","c110cee0":"code","64124ea7":"code","4501c26b":"code","74113755":"code","5318c568":"code","506e778b":"code","e8b06146":"code","cfd8416b":"code","8e866137":"code","c675e3da":"code","d6bb8b89":"code","24140592":"code","205ee91a":"code","d6b710c7":"code","2cb56721":"code","afe468cf":"code","2818109a":"markdown","ef36affc":"markdown","935399ca":"markdown","38ab7ae1":"markdown","ba1aa6a6":"markdown","803b05a9":"markdown","deb953e9":"markdown","8f800b2c":"markdown","4319cb99":"markdown","9c9955a9":"markdown","600b6674":"markdown","e4158d8f":"markdown","59bf1d7a":"markdown","ff50d267":"markdown","20ecd211":"markdown","fbf53259":"markdown","c93cf434":"markdown","d3a0ec7d":"markdown","ce9b34ad":"markdown"},"source":{"7cf2e923":"!pip install -U scikit-learn --q","9e18fdce":"import sklearn\nprint(sklearn.__version__)","17b137e0":"import pandas as pd\nfrom collections import Counter\nfrom itertools import product\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport optuna\nimport shap\nimport copy\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing,model_selection,decomposition,compose,pipeline,metrics,ensemble,impute\nfrom sklearn.utils import class_weight,compute_sample_weight\nfrom sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\nshap.initjs()","6b897261":"def Preprocessor(data,scaler):\n    \n    cat_cols = data.select_dtypes('object').columns.tolist()\n    num_cols = data.select_dtypes(exclude='object').columns.tolist()\n    \n    numerical_transformer = pipeline.Pipeline(steps=[\n        ('imputer',impute.SimpleImputer(\n            missing_values=np.nan,\n            strategy='most_frequent',\n            fill_value=None,\n            verbose=0,\n            copy=True,\n            add_indicator=False\n        )),\n        ('scaler',getattr(preprocessing,scaler)())\n    ])\n\n    categorical_transformer = pipeline.Pipeline(steps=[\n        ('imputer',impute.SimpleImputer(\n            missing_values=np.nan,\n            strategy='constant',\n            fill_value='missing',\n            verbose=0,\n            copy=True,\n            add_indicator=False\n        )),\n        ('encoder',preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-999))\n    ])\n\n    preprocessor = compose.ColumnTransformer(transformers=[\n        ('numerical_transformer',numerical_transformer,num_cols),\n        ('categorical_transformer',categorical_transformer,cat_cols)\n    ])\n    \n    preprocessor.fit(data)\n    return preprocessor,cat_cols,num_cols","0ca31257":"def cross_vall_split(df,n_split):\n    df['fold'] = None\n    kf = model_selection.KFold(n_splits=n_split,shuffle=True,random_state=1234)\n    for fold,(train_idx,valid_idx) in enumerate(kf.split(df)):\n        df.loc[valid_idx,'fold'] = fold\n    return df","1cff2b1b":"def kde_target(var_name, df):\n    \n    if df[var_name].dtype=='object':\n        print(\"Not a numeric column\")\n        return None\n    corr = df['loan_status'].corr(df[var_name])\n    \n    FullyPaid = df.loc[df['loan_status'] == 0, var_name].median()\n    Default = df.loc[df['loan_status'] == 1, var_name].median()\n    \n    plt.figure(figsize = (12, 6))\n    \n    sns.kdeplot(df.loc[df['loan_status'] == 0, var_name], label = 'Fully Paid',)\n    sns.kdeplot(df.loc[df['loan_status'] == 1, var_name], label = 'Default',)\n\n    \n    plt.xlabel(var_name); plt.ylabel('Density'); plt.title('%s Distribution' % var_name)\n    plt.legend();\n    \n    print('The correlation between %s and the TARGET is %0.4f' % (var_name, corr))\n    \n    print('Median value for FullyPaid = %0.4f' % FullyPaid)\n    print('Median value for Default = %0.4f' % Default)","71c3a021":"df = pd.read_feather('..\/input\/d\/ransakaravihara\/lending-club-loan-cleaned\/Cleaned_loandata.feather')","34e9a9b3":"for col in df.columns:\n    if df[col].isna().sum()>0:print(col,\"Has \",df[col].isna().sum(),\" null values\")","7c927681":"df['emp_title_test'] = df['emp_title'].fillna(\"missing\")","48ee3997":"df['emp_length_test'] = df['emp_length'].fillna(\"missing\")","71cca428":"cols_to_drop = ['emp_length_test','emp_title_test']","671f6a65":"df['issue_d_year'] = pd.DatetimeIndex(df['issue_d']).year  \ndf['issue_d_month'] = pd.DatetimeIndex(df['issue_d']).month  \ndf['last_pymnt_d_year'] = pd.DatetimeIndex(df['last_pymnt_d']).year  \ndf['last_pymnt_d_month'] = pd.DatetimeIndex(df['last_pymnt_d']).month \ndf['last_credit_pull_d_year'] = pd.DatetimeIndex(df['last_credit_pull_d']).year  \ndf['last_credit_pull_d_month'] = pd.DatetimeIndex(df['last_credit_pull_d']).month ","e867be72":"df['term'] = df.term.apply(lambda x:float(x[:2]))\ndf['int_rate'] = df.int_rate .apply(lambda x:float(x.replace(\"%\",\"\")))","792cd52f":"lstatus_map = {v:k for k,v in dict(enumerate(df['loan_status'].unique())).items()}","098a4980":"#encode target\ndf['loan_status'] = df['loan_status'].map(lstatus_map)","8d60a939":"int_to_lstatus = {val:key for key,val in lstatus_map.items()}","4e207ef7":"def plot_target_vs_cat(df,x,figsize=(30,20)):\n    if df[x].nunique()<=10:\n        nrows = round(df[x].nunique()\/2)\n        ncols = 2\n    elif df[x].nunique()<=30:\n        nrows = round(df[x].nunique()\/3)\n        ncols = 3\n    else:\n        print(\"Large unique values...skipping\")\n        return None\n    fig,ax = plt.subplots(nrows=nrows,ncols=ncols,figsize=figsize)\n    for axi,val in zip(ax.flatten(),df[x].unique()):\n        e = df.query(f\"{x}=='{val}'\").reset_index(drop=True)\n        e['loan_status'] = e['loan_status'].map(int_to_lstatus)\n        e = pd.DataFrame(e['loan_status'].value_counts()).reset_index()\n        colors = sns.color_palette('pastel')[0:len(e)]\n        axi.pie(e['loan_status'], labels = e['index'], colors = colors, autopct='%.0f%%')\n        axi.set_title(val,fontweight='bold')\n    plt.show()","6cad8d52":"df.select_dtypes('object').columns.tolist()","d1684a16":"plot_target_vs_cat(df,'emp_length_test',figsize=(30,30))","1b68089e":"# Filling na\ndf['emp_length'] = df['emp_length'].fillna('missing')","dac773a2":"top_20_emp = df\\\n            .groupby(['emp_title_test'])\\\n            .agg({\"id\":'count','loan_status':sum})\\\n            .reset_index()\\\n            .sort_values('id',ascending=False)\\\n            .head(20)\\\n            .reset_index(drop=True)\ntop_20_emp['default_ratio'] = top_20_emp['loan_status']\/top_20_emp['id']\ntop_20_emp","20f90e90":"df['emp_title'] = df['emp_title'].fillna('missing')\ndf['emp_title'] = df['emp_title'].apply(lambda s: s.lower())","c5915644":"plot_target_vs_cat(df,'revol_util',figsize=(30,30))","6f775e81":"plot_target_vs_cat(df,'home_ownership',figsize=(20,20))","bc44f218":"plot_target_vs_cat(df,'earliest_cr_line',figsize=(20,20))","32c08c82":"kde_target(\"loan_amnt\",df)","e3fd4bf2":"kde_target(\"funded_amnt\",df)","ef908058":"df['funded_amnt'].corr(df['loan_amnt'])","1b9c47fe":"cols_to_drop.append('funded_amnt')","7089614d":"kde_target(\"term\",df)","3e4adb61":"kde_target(\"int_rate\",df)","3906dfee":"kde_target(\"installment\",df)","796846fa":"kde_target(\"earliest_cr_line\",df)","ddb32929":"kde_target(\"dti\",df)","f28c42c7":"kde_target(\"tot_hi_cred_lim\",df)","d5befd6f":"df['last_pymnt_d_year'].fillna(df['last_pymnt_d_year'].median(),inplace=True)\ndf['last_pymnt_d_month'].fillna(df['last_pymnt_d_month'].median(),inplace=True)\ndf['last_credit_pull_d_year'].fillna(df['last_credit_pull_d_year'].median(),inplace=True)\ndf['last_credit_pull_d_month'].fillna(df['last_credit_pull_d_month'].median(),inplace=True)","f4a4737f":"datetime_cols = df.select_dtypes('datetime').columns.tolist()","b57f8672":"cols_to_drop.extend(datetime_cols)\nprint(cols_to_drop)","3c8de145":"df.drop(cols_to_drop,axis=1,inplace=True)","a8c1fa56":"scaler = 'None'","9bdde805":"y = df['loan_status'].map(int_to_lstatus)\ny.value_counts()","c5bdf225":"y = y.map(lstatus_map)","b5e44b21":"ids = df['id']","c381abca":"df.drop(['loan_status','id'],axis=1,inplace=True)","32d1c08c":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(df,y,test_size = 0.10 ,random_state = 2, stratify =y)\nx_train,x_valid,y_train,y_valid = train_test_split(x_train,y_train,test_size = 0.20 ,random_state = 2, stratify =y_train)\n\nx_train.shape,y_train.shape,x_test.shape,y_test.shape,x_valid.shape,y_valid.shape","18cb082a":"cat_cols = df.select_dtypes('object').columns.tolist()\nnum_cols = df.select_dtypes(exclude='object').columns.tolist()\n\nnumerical_transformer = pipeline.Pipeline(steps=[\n    ('scaler',getattr(preprocessing,scaler)() if scaler!='None' else None)\n])\n\ncategorical_transformer = pipeline.Pipeline(steps=[\n    ('encoder',preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=np.nan))\n])\n\npreprocessor = compose.ColumnTransformer(transformers=[\n    ('numerical_transformer',numerical_transformer,num_cols),\n    ('categorical_transformer',categorical_transformer,cat_cols)\n])","12a562d6":"preprocessor.fit(x_train)\n\nx_train = pd.DataFrame(preprocessor.transform(x_train),columns=x_train.columns)\nx_test = pd.DataFrame(preprocessor.transform(x_test),columns=x_train.columns)\nx_valid = pd.DataFrame(preprocessor.transform(x_valid),columns=x_train.columns)","0d20d412":"def xgb_f1(y, t, threshold=0.5):\n    \"\"\"Helper funcion for XGBoost f1_score\"\"\"\n    t = t.get_label()\n    y_bin = [1. if y_cont > threshold else 0. for y_cont in y]\n    return 'f1',metrics.f1_score(t,y_bin)","ea362b90":"model = xgb.XGBClassifier(n_estimators=20,use_label_encoder=False,tree_method='gpu_hist',gpu_id=0,random_state=1234)\nmodel.fit(x_train,y_train,eval_set=[(x_valid,y_valid)],eval_metric=xgb_f1,verbose=False)","c4ce3fb6":"test_predictions_xgb = model.predict(x_test)\ntrain_preds_xgb = model.predict(x_train)\nvalid_preds_xgb = model.predict(x_valid)\n\ntest_proba_xgb = model.predict_proba(x_test)\ntrain_proba_xgb = model.predict_proba(x_train)\nvalid_proba_xgb = model.predict_proba(x_valid)","2c520fb1":"cm_test_xgb = metrics.confusion_matrix(y_test,test_predictions_xgb)\ncm_train_xgb = metrics.confusion_matrix(y_train,train_preds_xgb)","61b1502d":"lgb_bst = lgb.LGBMClassifier(n_estimators=20,random_state=1234)\nlgb_bst.fit(x_train,y_train,eval_set=[(x_valid,y_valid)],early_stopping_rounds=10)","4652de5c":"test_predictions_lgb = lgb_bst.predict(x_test)\ntrain_preds_lgb = lgb_bst.predict(x_train)\nvalid_preds_lgb = lgb_bst.predict(x_valid)\n\ntest_proba_lgb = lgb_bst.predict_proba(x_test)\ntrain_proba_lgb = lgb_bst.predict_proba(x_train)\nvalid_proba_lgb = lgb_bst.predict_proba(x_valid)","b89844d4":"cm_test_lgb = metrics.confusion_matrix(y_test,test_predictions_lgb)\ncm_train_lgb = metrics.confusion_matrix(y_train,train_preds_lgb)","31b4f9cc":"fig,ax = plt.subplots(2,2,figsize=(15,15))\nmodel_cms = dict(zip(['LGB_TEST','LGB_TRAIN','XGB_TEST','XGB_TRAIN'],[cm_test_lgb,cm_train_lgb,cm_test_xgb,cm_train_xgb]))\n\nfor axi,con_mat in zip(ax.flatten(),model_cms):\n    sns.heatmap(model_cms[con_mat],annot=True,cmap='viridis',fmt=\".0f\",cbar=False,ax=axi,xticklabels=False,yticklabels=False)\n    axi.text(x=0.85,y=0,s=con_mat,backgroundcolor='y')","972bfa96":"xgb.plot_importance(model,max_num_features=20)\nplt.title(\"Top 20 features\")\nplt.show()","7570abc6":"explainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(x_train)","ea38198a":"print(f\"Check example of {int_to_lstatus[y_train.iloc[100]]}\")","59051d15":"shap.force_plot(explainer.expected_value, shap_values[100,:], x_train.iloc[100,:])","3db32e69":"print(f\"Check example of {int_to_lstatus[y_train.iloc[39]]}\")","ac8cdab2":"shap.force_plot(explainer.expected_value, shap_values[39,:], x_train.iloc[39,:])","62b81156":"shap.force_plot(explainer.expected_value, shap_values[:1000,:], x_train.iloc[:1000,:])","3d1d0d21":"shap.summary_plot(shap_values, x_train, plot_type=\"bar\")","1c34a492":"shap.summary_plot(shap_values, x_train)","c110cee0":"vals= np.abs(shap_values).mean(0)\nfeature_importance = pd.DataFrame(list(zip(x_train.columns,vals)),columns=['col_name','feature_importance_vals'])\nfeature_importance = feature_importance.sort_values(by=['feature_importance_vals'],ascending=False).reset_index(drop=True)","64124ea7":"features_to_use = feature_importance['col_name'][0:30].tolist()","4501c26b":"filtered_cols = copy.deepcopy(features_to_use)\nfiltered_cols.append('loan_status')","74113755":"df['loan_status'] = y","5318c568":"fig, ax = plt.subplots(figsize=(20, 15))\nsns.heatmap(\n        df[features_to_use].corr(), \n        cmap = sns.diverging_palette(220, 10, as_cmap = True),\n        square=True, \n        cbar=False,\n        ax=ax,\n#         annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 })\n\nplt.show()","506e778b":"del df['loan_status']","e8b06146":"features_to_use.remove('funded_amnt_inv')","cfd8416b":"features_to_use","8e866137":"bst_xgb = xgb.XGBClassifier(n_estimators=20,use_label_encoder=False,tree_method='gpu_hist',gpu_id=0,random_state=1234)\nbst_xgb.fit(x_train[features_to_use],y_train,eval_set=[(x_valid[features_to_use],y_valid)],eval_metric=xgb_f1,verbose=True)","c675e3da":"bst_lgb = lgb.LGBMClassifier(n_estimators=20,random_state=1234)\nbst_lgb.fit(x_train[features_to_use],y_train,eval_set=[(x_valid[features_to_use],y_valid)])","d6bb8b89":"test_predictions_lgb = bst_lgb.predict(x_test[features_to_use])\ntrain_preds_lgb = bst_lgb.predict(x_train[features_to_use])\nvalid_preds_lgb = bst_lgb.predict(x_valid[features_to_use])\n\ntest_predictions_xgb = bst_xgb.predict(x_test[features_to_use])\ntrain_preds_xgb = bst_lgb.predict(x_train[features_to_use])\nvalid_preds_xgb = bst_xgb.predict(x_valid[features_to_use])","24140592":"cm_test_lgb = metrics.confusion_matrix(y_test,test_predictions_lgb)\ncm_train_lgb = metrics.confusion_matrix(y_train,train_preds_lgb)\n\ncm_test_xgb = metrics.confusion_matrix(y_test,test_predictions_xgb)\ncm_train_xgb = metrics.confusion_matrix(y_train,train_preds_xgb)","205ee91a":"fig,ax = plt.subplots(2,2,figsize=(15,15))\nmodel_cms = dict(zip(['LGB_TEST','LGB_TRAIN','XGB_TEST','XGB_TRAIN'],[cm_test_lgb,cm_train_lgb,cm_test_xgb,cm_train_xgb]))\n\nfor axi,con_mat in zip(ax.flatten(),model_cms):\n    sns.heatmap(model_cms[con_mat],annot=True,cmap='viridis',fmt=\".0f\",cbar=False,ax=axi,xticklabels=True,yticklabels=True)\n    axi.text(x=0.85,y=0,s=con_mat,backgroundcolor='y')","d6b710c7":"features_to_use = features_to_use\nfeatures_to_use.extend(['id','loan_status'])","2cb56721":"df['id'] = ids\ndf['loan_status'] = y","afe468cf":"features_to_use  = list(set(features_to_use))\ndf[features_to_use].to_feather('train_loan_data.feather')","2818109a":"## Conclusion\n - Higher the number of payments on the loan there is high risk to loan to default","ef36affc":"#### Find home owner ship distribution against loan status","935399ca":"- Create new features","38ab7ae1":"### Feature engineering","ba1aa6a6":"#### plot whether emp_length feature has eny major impact on target. Also, find is there are any meaning behind missing emp_length","803b05a9":"##### LighGBM Modeling","deb953e9":"### Explain the model","8f800b2c":"### Plot selected numerical features against target","4319cb99":" - ##### Current model using morethan 80 features. Having such a large featueres tends to data pipeline more complicated and hard to maintain. Trying to reduce the no. of features","9c9955a9":"## Conclusion\n - Simmilar to the loan amount featue\n \n Cheking correlation of funded_amnt and loan_amnt","600b6674":"**Even our model preformed pretty well, saving the data for further model fine tuning. Not going to tune model in this notebook.**","e4158d8f":"### Modeling\n##### XGBoost Modeling","59bf1d7a":"## Conclusion\n - If loan amount ~10,000 or lower there is high chance to fully pay the loan","ff50d267":"#### **conclusion**\n - While all other emp_length features behave as same, emp_lenght missing behaving deferently. See the fully_paid\/default ratio of emp_title missing populations","20ecd211":"## Conclusion\n - Higher the installment amount there is high risk to loan will be default","fbf53259":"## As per above model test results,\n - LGB Model\n  - 0 predictions for loan defaults as fully paid\n  - 788 predictions for loan fully paid as loan defaults (This cause revenue loss for the bank)\n - XGB Model\n  - 8 predictions for loan defaults as fully paid\n  - 458 predictions for loan fully paid as loan defaults (This cause revenue loss for the bank but loss is lower than LGB)\n  \n**Hence, I'd Pick final model as XGB Model**","c93cf434":"## Conclusion\n - Higher the interest rate on the loan there is high risk to loan to default","d3a0ec7d":"#### emp_title_test vs target column impact","ce9b34ad":"- ### Conclusions\n - High installments caused to loan to default\n - Low inquries in past 6 mnths tends to loan to default\n - Higher the loan amount, the default chance is high\n - Higher the dti(borrower's debt repayment capacity) tends to fully paid the loan"}}