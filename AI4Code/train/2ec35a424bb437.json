{"cell_type":{"16261b91":"code","8129c96b":"code","0bbd074c":"code","305a96d4":"code","c8f7458e":"code","51e5118c":"code","bbc003c2":"code","7c7a668c":"code","d2c98ad8":"code","0275b3ec":"code","eb27e92c":"code","8fafb927":"code","e4618846":"code","2f0578cb":"markdown","8e7a5cec":"markdown","5d80afd1":"markdown","84532aca":"markdown","2e3b3dfe":"markdown","9a3b59a1":"markdown","3a5b8feb":"markdown","000d5149":"markdown","b4be7d29":"markdown","38f10a0e":"markdown","86f08255":"markdown","663a4eee":"markdown","c20f0482":"markdown","bd38e596":"markdown"},"source":{"16261b91":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n","8129c96b":"\nfake = pd.read_csv('..\/input\/fake-and-real-news-dataset\/Fake.csv', delimiter = ',')\ntrue = pd.read_csv('..\/input\/fake-and-real-news-dataset\/True.csv', delimiter = ',')\n","0bbd074c":"fake['sentiment']= 0\ntrue['sentiment']= 1\n\ndataset =pd.DataFrame()\ndataset = true.append(fake)","305a96d4":"column = ['date','subject']\ndataset = dataset.drop(columns=column)\ninput_array=np.array(dataset['title'])","c8f7458e":"import re\nimport nltk\n# ltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 40000):\n    review = re.sub('[^a-zA-Z]', ' ', input_array[i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","51e5118c":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 5000)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[0:40000, 2].values\n","bbc003c2":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n","7c7a668c":"# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\nprint(cm)\n","d2c98ad8":"from sklearn.linear_model import LogisticRegression\nclassifier1 = LogisticRegression(random_state = 0)\nclassifier1.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predL = classifier1.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm1 = confusion_matrix(y_test, y_predL)\n\nprint(cm1)","0275b3ec":"from sklearn.tree import DecisionTreeClassifier\nclassifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier2.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predD = classifier2.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm2 = confusion_matrix(y_test, y_predD)\n\nprint(cm2)\n","eb27e92c":"from sklearn.ensemble import RandomForestClassifier\nclassifier3 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier3.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predR = classifier3.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm3 = confusion_matrix(y_test, y_predR)\n\n\nprint(cm3)","8fafb927":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm5 = confusion_matrix(y_test, y_pred)\n\nprint(cm5)","e4618846":"from sklearn.neighbors import KNeighborsClassifier\nclassifier4 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier4.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predK = classifier4.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm4 = confusion_matrix(y_test, y_predK)\n","2f0578cb":"Fitting Naive Bayes to the Training set.\nCanculate accuracy form confusion matrix that is 88.58%.","8e7a5cec":"Fitting Decision Tree Classification to the Training set\nFinding accuracy by confusion matrix that is 89.70%\n","5d80afd1":"Fitting SVM to the Training set.\nFinding accuracy by confusion matrix that is 94.92%","84532aca":"Next part is most important, That is **claning the text and forming curpus**.\nsuch as removing symbols, stpwords,using porterstremer etc.\nI have selected 40000 title as input. you can chose these number depending on your system performance but not less than 10000.","2e3b3dfe":"Note:- Decision Tree and random forest take time so you have to be patient while running code.\nThank you.","9a3b59a1":"Hello there, we are going to use **Machine Learning to detect fake news**.So lets start.\nhere we are using following algorithms.\n\n\n**1.Naivy bayes\n2.logistic regression\n3.Decision Tree\n4.Random Forest\n5.KNN\n6.SVM(Support vector machine)**\n\n\nNote:-we can code one aspect in different ways. So my way of coding may be different from yours. but untimately output will be same.\n\nLets start with importing basic pakages","3a5b8feb":"Fitting K-NN to the Training set.\nhere , i have given 5 as n_neighbors value for simple processing time. if  you change value accuracy also changes.\nFinding accuracy by confusion matrix that is 94.92%","000d5149":"Now We are going to combine these two dataset to one dataset to simplify processing.\nalso to combine we need to add an extra column as sentiment to differtiate news as 1=true_news 0=fake_news","b4be7d29":"Column **'Date' and 'Subject'** are important to Descriptive analysis but here for prediction they are less important so i am going to drop these columns.\nAlso Created array of **'title' column as input_array** for preprocessing.","38f10a0e":"Splitting the dataset into the Training set and Test set","86f08255":"Fitting Logistic Regression to the Training set.\nFinding accuracy by confusion matrix that is 94.92%","663a4eee":"Importing datasets","c20f0482":"Now, We crate bag of world model. if you dont know just google it.\nAlso we are going to initialize  x and y that is x=independent_variable(title) y=dependent_variable(sentiment 0 or 1).\nI am going to select max features as 5000. this figure also depends on your preference.","bd38e596":"Fitting Random Forest Classification to the Training set.\nFinding accuracy by confusion matrix that is 92.37%\n"}}