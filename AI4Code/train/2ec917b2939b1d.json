{"cell_type":{"9899f96f":"code","a2176048":"code","4bfe8e61":"code","5cc790cd":"code","4082d14b":"code","9955562f":"code","496dfa5f":"code","881e8a8b":"code","ce97cff7":"code","806ef268":"code","82271b30":"code","9b0e12da":"code","8fcdf56c":"code","30901823":"code","ae101a67":"code","a7e256ee":"code","e38fa701":"code","42d3c5ea":"code","096599a7":"markdown","67de1032":"markdown"},"source":{"9899f96f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a2176048":"import tensorflow as tf\nfrom tensorflow import keras","4bfe8e61":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntrain_data","5cc790cd":"features = train_data.drop(['label'], axis=1)\nlabels = train_data['label']\n","4082d14b":"train_data.shape","9955562f":"\nmodel1 = keras.Sequential()\nmodel1.add(keras.layers.Dense(300,input_shape=(pixels,),activation=tf.nn.relu))\nmodel1.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nmodel1.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel1.fit(x=features, y=labels, batch_size=64, epochs=10)","496dfa5f":"model2 = keras.Sequential()\nmodel2.add(keras.layers.Dense(300,input_shape=(pixels,),activation=tf.nn.relu))\nmodel2.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nmodel2.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel2.fit(x=features, y=labels, batch_size=64, epochs=10)","881e8a8b":"model3 = keras.Sequential()\nmodel3.add(keras.layers.Dense(300,input_shape=(pixels,),activation=tf.nn.relu))\nmodel3.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nmodel3.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel3.fit(x=features, y=labels, batch_size=64, epochs=10)","ce97cff7":"model4 = keras.Sequential()\nmodel4.add(keras.layers.Dense(300,input_shape=(pixels,),activation=tf.nn.relu))\nmodel4.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nmodel4.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel4.fit(x=features, y=labels, batch_size=64, epochs=10)","806ef268":"features_mean = features-sum(features.sum())\/(features.shape[0]*features.shape[1])","82271b30":"features","9b0e12da":"features_mean","8fcdf56c":"n_model1 = keras.Sequential()\nn_model1.add(keras.layers.Dense(261,input_shape=(pixels,),activation=tf.nn.relu))\nn_model1.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nn_model1.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nn_model1.fit(x=features_mean, y=labels, batch_size=64, epochs=20)","30901823":"n_model2 = keras.Sequential()\nn_model2.add(keras.layers.Dense(210,input_shape=(pixels,),activation=tf.nn.relu))\nn_model2.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nn_model2.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nn_model2.fit(x=features_mean, y=labels, batch_size=64, epochs=20)","ae101a67":"n_model3 = keras.Sequential()\nn_model3.add(keras.layers.Dense(300,input_shape=(pixels,),activation=tf.nn.relu))\nn_model3.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nn_model3.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nn_model3.fit(x=features_mean, y=labels, batch_size=64, epochs=20)","a7e256ee":"n_model4 = keras.Sequential()\nn_model4.add(keras.layers.Dense(350,input_shape=(pixels,),activation=tf.nn.relu))\nn_model4.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nn_model4.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nn_model4.fit(x=features_mean, y=labels, batch_size=64, epochs=20)","e38fa701":"n_model4 = keras.Sequential()\nn_model4.add(keras.layers.Dense(400,input_shape=(pixels,),activation=tf.nn.relu))\n\nn_model4.add(keras.layers.Dense(10,activation=tf.nn.softmax))\nn_model4.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nn_model4.fit(x=features_mean, y=labels, batch_size=64, epochs=20)","42d3c5ea":"n_model4.a","096599a7":"In this example number of neurons per layer are descided by dividing previous layer neurons by 3","67de1032":"normalizing the data"}}