{"cell_type":{"559550f1":"code","9d76851e":"code","c69c78f0":"code","35043ce3":"code","ff2090d7":"code","f5455800":"code","3ac1c9a9":"code","56642bf5":"code","eb196357":"code","6b0d1b3e":"code","bf0b65fd":"code","934245e9":"code","2d32e89b":"code","5cf704ab":"code","4b41501c":"code","72f3e05b":"code","8ccf6505":"code","611d674b":"code","80f95333":"code","369d9c84":"code","b625c093":"code","61a4194d":"code","671be1f2":"code","b2e1b517":"code","31d0d4bc":"code","d1b7e57f":"code","857420e4":"code","1b554e67":"code","64ee9098":"code","19523a0e":"code","ef3677e2":"code","97f2bc5e":"code","18f3877d":"code","352b907a":"code","2d60b3a9":"code","76f15d8b":"code","39333e9d":"code","e9a6246b":"code","d720c03d":"markdown","597fd9c2":"markdown","0e0292ea":"markdown","ce1cc649":"markdown","da6be821":"markdown","4489c896":"markdown","2dc73562":"markdown","a80c2088":"markdown","4060f544":"markdown","009f041d":"markdown","0e64b832":"markdown","3aec09c8":"markdown","21f4c489":"markdown","6c9e6b59":"markdown","9990943e":"markdown","95e32c13":"markdown","01e7d4fc":"markdown","5a25583c":"markdown","06e13410":"markdown","7f1ea76e":"markdown","dc5baef5":"markdown","f601586c":"markdown","5ed58158":"markdown","a59201ff":"markdown","2a88ef4b":"markdown","af25feed":"markdown","d8dae728":"markdown","07c8e43d":"markdown","b203f215":"markdown","47160909":"markdown","cef5c263":"markdown","8cf6b0ff":"markdown","d1bf86ff":"markdown","0280a904":"markdown","964232a5":"markdown","89768978":"markdown","32fea960":"markdown","e4dad1b7":"markdown","c421025c":"markdown","a0533823":"markdown"},"source":{"559550f1":"import cv2 #OpenCv\nfrom IPython.display import Image","9d76851e":"image_path =r'..\/input\/chris-hemsworth-image\/group_girls.jpg'\ncascade_path = r'..\/input\/haar-cascade-xml-file\/haar_cascade.xml'","c69c78f0":"# showing the image\n\nImage(filename=image_path) ","35043ce3":"# create the cascade classifier\ncascade = cv2.CascadeClassifier(cascade_path)\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    scaleFactor=1.1,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n)","ff2090d7":"# print how many faces found\nprint(\"Total faces  \", len(faces))","f5455800":"# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)","3ac1c9a9":"cv2.imwrite('.\/group_girls.jpg', image)\nImage(filename='.\/group_girls.jpg')","56642bf5":"# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    \n    # CHANGING THE SCALING FACTOR FROM 1.1 TO 1.2\n    scaleFactor=1.2,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) ","eb196357":"# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/group_girls.jpg', image)\nImage(filename='.\/group_girls.jpg')","6b0d1b3e":"image_path =r'..\/input\/chris-hemsworth-image\/chris_1.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    \n    # CHANGING THE SCALING FACTOR FROM 1.1 TO 1.2\n    scaleFactor=1.2,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) \n\n# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_1.jpg', image)\nImage(filename='.\/chris_1.jpg')","bf0b65fd":"image_path =r'..\/input\/chris-hemsworth-image\/chris_4.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    \n    # CHANGING THE SCALING FACTOR FROM 1.1 TO 1.2\n    scaleFactor=1.2,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) \n\n# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_4.jpg', image)\nImage(filename='.\/chris_4.jpg')","934245e9":"image_path =r'..\/input\/chris-hemsworth-image\/chris_4.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    \n    # CHANGING THE SCALING FACTOR FROM 1.2 TO 1.5\n    scaleFactor=1.5,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) \n\n# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_4.jpg', image)\nImage(filename='.\/chris_4.jpg')","2d32e89b":"image_path =r'..\/input\/chris-hemsworth-image\/chris_6.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    \n    scaleFactor=1.5,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) \n\n# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_6.jpg', image)\nImage(filename='.\/chris_6.jpg')","5cf704ab":"image_path =r'..\/input\/chris-hemsworth-image\/chris_6.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    # scaling factor 1.2\n    scaleFactor=1.2,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) \n\n# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_6.jpg', image)\nImage(filename='.\/chris_6.jpg')","4b41501c":"image_path =r'..\/input\/chris-hemsworth-image\/chris_7.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    \n    # SCALING FACTOR 1.2\n    scaleFactor=1.2,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) \n\n# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_7.jpg', image)\nImage(filename='.\/chris_7.jpg')","72f3e05b":"# we take the photo containing both chris hemsworth and tom holland\nimage_path =r'..\/input\/chris-hemsworth-image\/chris_6.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# looping over the range 1.0 to 1.9\n\nface_list =[]\n\n\nfor i in [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]:\n    \n    # detect faces in the image\n    faces = cascade.detectMultiScale(\n    gray,\n    scaleFactor= i,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n    ) \n    \n    face_list.append(len(faces))","8ccf6505":"face_list","611d674b":"image_path =r'..\/input\/chris-hemsworth-image\/chris_4.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# looping over the range 1.0 to 1.9\n\nface_list =[]\n\nfor i in [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]:\n    \n    # detect faces in the image\n    faces = cascade.detectMultiScale(\n    gray,\n    scaleFactor= i,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n    ) \n    \n    face_list.append(len(faces))","80f95333":"face_list","369d9c84":"import collections\n\n#uploading chris_9 pic\nimage_path =r'..\/input\/chris-hemsworth-image\/chris_9.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# looping over the range 1.0 to 1.9\n\nface_list =[]\nface_values ={}\n\nfor i in [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]:\n    \n    # detect faces in the image\n    faces = cascade.detectMultiScale(\n    gray,\n    scaleFactor= i,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n    ) \n    \n    face_list.append(len(faces))\n    face_values.update({len(faces):faces})\n    \nprint(\"face_list is \", face_list)\n\n\n# helper function to pic the max occuring value from the face_list\n\n# variable to store the face value\nfvalue =0\n\nfor key, value in collections.Counter(face_list).items():\n    \n    if value == max(collections.Counter(face_list).values()):\n        fvalue = key\n        break\n        \nfor (X, Y, width, height) in face_values[fvalue]:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_9.jpg', image)\nImage(filename='.\/chris_9.jpg')","b625c093":"#uploading  pic\nimage_path =r'..\/input\/chris-hemsworth-image\/chris_11.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# looping over the range 1.0 to 1.9\n\nface_list =[]\nface_values ={}\n\nfor i in [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]:\n    \n    # detect faces in the image\n    faces = cascade.detectMultiScale(\n    gray,\n    scaleFactor= i,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n    ) \n    \n    face_list.append(len(faces))\n    face_values.update({len(faces):faces})\n    \nprint(\"face_list is \", face_list)\n\n\n# helper function to pic the max occuring value from the face_list\n\n# variable to store the face value\nfvalue =0\n\nfor key, value in collections.Counter(face_list).items():\n    \n    if value == max(collections.Counter(face_list).values()):\n        fvalue = key\n        break\n        \nfor (X, Y, width, height) in face_values[fvalue]:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_11.jpg', image)\nImage(filename='.\/chris_11.jpg')","61a4194d":"#uploading pic\nimage_path =r'..\/input\/chris-hemsworth-image\/chris_12.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# looping over the range 1.0 to 1.9\n\nface_list =[]\nface_values ={}\n\nfor i in [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]:\n    \n    # detect faces in the image\n    faces = cascade.detectMultiScale(\n    gray,\n    scaleFactor= i,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n    ) \n    \n    face_list.append(len(faces))\n    face_values.update({len(faces):faces})\n    \nprint(\"face_list is \", face_list)\n\n\n# helper function to pic the max occuring value from the face_list\n\n# variable to store the face value\nfvalue =0\n\nfor key, value in collections.Counter(face_list).items():\n    \n    if value == max(collections.Counter(face_list).values()):\n        fvalue = key\n        break\n        \nfor (X, Y, width, height) in face_values[fvalue]:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_12.jpg', image)\nImage(filename='.\/chris_12.jpg')","671be1f2":"\n#uploading chris_10 pic\nimage_path =r'..\/input\/chris-hemsworth-image\/chris_10.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# looping over the range 1.0 to 1.9\n\nface_list =[]\nface_values ={}\n\nfor i in [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]:\n    \n    # detect faces in the image\n    faces = cascade.detectMultiScale(\n    gray,\n    scaleFactor= i,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n    ) \n    \n    face_list.append(len(faces))\n    face_values.update({len(faces):faces})\n    \nprint(\"face_list is \", face_list)\n\n# helper function to pic the max occuring value from the face_list\n\n# variable to store the face value\nfvalue =0\n\nfor key, value in collections.Counter(face_list).items():\n    \n    if value == max(collections.Counter(face_list).values()):\n        fvalue = key\n        break\n        \nfor (X, Y, width, height) in face_values[fvalue]:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_10.jpg', image)\nImage(filename='.\/chris_10.jpg')","b2e1b517":"image_path =r'..\/input\/chris-hemsworth-image\/chris_10.jpg'\n\n# read the image\nimage = cv2.imread(image_path)\n\n# convert the image into grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n\n# detect faces in the image\nfaces = cascade.detectMultiScale(\n    gray,\n    \n    # SCALING FACTOR \n    scaleFactor=1.2,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n) \n\n# print how many faces found\nprint(\"Total faces  \", len(faces))\n\n# draw the rectangle around the faces in the image and render it\n\nfor (X, Y, width, height) in faces:\n    \n    # draw the rectangle from the given coordinates (X, Y) and width and height.\n    cv2.rectangle(image,  (X,Y), (X+width, Y+height), (0, 0, 255), 2)\n    \ncv2.imwrite('.\/chris_10.jpg', image)\nImage(filename='.\/chris_10.jpg')","31d0d4bc":"# install the library\n!pip install face_recognition","d1b7e57f":"import face_recognition","857420e4":"Image(filename = '..\/input\/chris-hemsworth-image\/chris_12.jpg')","1b554e67":"import tensorflow as tf\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","64ee9098":"# load image\n# dictionary to save image name mapped to their encodings\ndata = {}\nenc =[]\nimage_name =[]\nwith strategy.scope():\n    for i in [1, 4, 7]:\n        image = cv2.imread('..\/input\/chris-hemsworth-image\/chris_{}.jpg'.format(i))\n        # convert it into rgb\n        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # using 'cnn' model for encoding image \n        boxes = face_recognition.face_locations(image, model='cnn')\n        encodings = face_recognition.face_encodings(image, boxes, num_jitters=5)\n\n        enc.append(encodings)\n        image_name.append('chris_{}'.format(i))\n    \ndata = {'encodings': enc, 'image_name': image_name}","19523a0e":"# load image\nimage = cv2.imread('..\/input\/chris-hemsworth-image\/chris_12.jpg')\n# convert it into rgb\nrgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nboxes = face_recognition.face_locations(image, model='cnn')\nencodings = face_recognition.face_encodings(image, boxes, num_jitters=5)","ef3677e2":"matches = face_recognition.compare_faces(data['encodings'][0], encodings[0], tolerance=0.45)","97f2bc5e":"matches","18f3877d":"if True in matches:\n\n    matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n    counts = {}\n    \n    for i in matchedIdxs:\n        name = data[\"image_name\"][i]\n        counts[name] = counts.get(name, 0) + 1\n\n        name = max(counts, key=counts.get)","352b907a":"name","2d60b3a9":"import matplotlib.pyplot as plt\nfrom keras.preprocessing.image import load_img \n\nplt.imshow(load_img('..\/input\/chris-hemsworth-image\/chris_12.jpg'))","76f15d8b":"plt.imshow(load_img('..\/input\/chris-hemsworth-image\/chris_1.jpg'))","39333e9d":"plt.imshow(load_img('..\/input\/chris-hemsworth-image\/chris_4.jpg'))","e9a6246b":"plt.imshow(load_img('..\/input\/chris-hemsworth-image\/chris_7.jpg'))","d720c03d":"### So we see that sometimes it is 1.2 or 1.5 that detects the true face. So if you are given an image to detect how many faces are there? What should be the ideal scaling factor ?","597fd9c2":"This time it is perfect. But does it perform same for other images also ? Let us see","0e0292ea":"As we see here majority of the answers are two, hence there are two pictures.","ce1cc649":"## What is HAAR Cascade?\n\nHaar Cascade classifier is an effective object detection approach which was proposed by Paul Viola and Michael Jones in their paper, [\u201cRapid Object Detection using a Boosted Cascade of Simple Features\u201d](https:\/\/ieeexplore.ieee.org\/abstract\/document\/990517 ) in 2001. \n\nCascading means several classifiers are concatenated to each other, each classifiier uses the output collected from the previous classifier as an additional information. It is a kind of ensemble learning.\nCascading classifiers are trained with several hundred \"positive\" sample views of a particular object and arbitrary \"negative\" images of the same size. After the classifier is trained it can be applied to a region of an image and detect the object in question. These are made to operate fast on low-power CPUs such as cameras and phones. \n\n## Why it is named \"Haar\"? \n\nInitially Viola and Jones, they started working with RGB pixels values at each and every pixel of image, but it made the task of feature calculation computationally expensive. Viola and Jones used Haar wavelet and developed Haar-like features. \n\nA Haar-like feature considers adjacent rectangular regions at a specific location in a detection window, sums up the pixel intensities in each region and calculates the difference between these sums. This difference is then used to categorize subsections of an image. For example, with a human face, it is a common observation that among all faces the region of the eyes is darker than the region of the cheeks. Therefore, a common Haar feature for face detection is a set of two adjacent rectangles that lie above the eye and the cheek region.\n\n### **Alfred Haar was a mathematician who proposed Haar sequence\/wavelet. Hence the name Haar.**\n\nFollowing are the links that can help you understand more-\n\nhttps:\/\/docs.opencv.org\/3.4\/db\/d28\/tutorial_cascade_classifier.html\n\nhttps:\/\/en.wikipedia.org\/wiki\/Haar-like_feature\n\nhttps:\/\/en.wikipedia.org\/wiki\/Viola%E2%80%93Jones_object_detection_framework\n\n**GitHub Repository**\n\nhttps:\/\/github.com\/anaustinbeing\/haar-cascade-files\n\n","da6be821":"### NOOOOOOOOOOOOOOOOOOOOO......its still giving errors.","4489c896":"We have detected a face using cascade xml file. Now our task is to compare the faces i.e. whether the faces in the two images are similar or not. So we will make face encodings of some of the pictures of chris hemsworth and test it with one single image of chris hemsworth and will se whether it matches the faces in both the images or not. All the pictures of chris in the folder are different.","2dc73562":"ooooooo.....isn't he hot ????","a80c2088":"# First Picture","4060f544":"That's Good!!!","009f041d":"1.5 scaling factor didn't work on it....Lets try it with 1.2","0e64b832":"**Ooops!!!! How come 6 faces ?**","3aec09c8":"##### we will use face_recognition python package here to implement this task. For more info on this package https:\/\/face-recognition.readthedocs.io\/en\/latest\/face_recognition.html","21f4c489":"# Second Picture","6c9e6b59":"## Configuring TPU","9990943e":"Let us try with only scaling factor 1.2","95e32c13":"### So our chris_12 image has only matched with chris_1 image","01e7d4fc":"### After changing the scaling factor","5a25583c":"So there are total 5 faces. Let's see how the cascade performs on it.","06e13410":"So along with the faces it has captured something else which is not face. It can be improved by changing scaling factor.","7f1ea76e":"Well, we can't really say that any particular scaling factor is best, moreover it depends from image to image. Let us loop in range 1.1 to 1.9 and see what we get","dc5baef5":"As we can see majority of the answers are 1, hence only one face is there","f601586c":"In this notebook, we will create a very simple face detector using HAAR Cascade. Cascade is an xml file that contains data to detect object from the images. I have uploaded haar cascade xml file.","5ed58158":"## add the list of encodings of various images and ","a59201ff":"### Upload the image and cascade xml file","2a88ef4b":"# Face Recognition","af25feed":"It didn't capture the image yet......why ??? coz this cascade xml is for capturing the frontal face","d8dae728":"### Applying cascade on Chris Hemsworth Images","07c8e43d":"Yes, we got it now!!","b203f215":"## So we haven't touched some of the pics lets us just use them as test data, let's see whether our method of detecting face is correct or not","47160909":"#### Lets try with another one, the second pic in which chris is carrying a surfing boat","cef5c263":"# HAAR Cascade Face Detector Using OpenCV and Python","8cf6b0ff":"# Test Image","d1bf86ff":"Here we got wrong, lets change the scaling factor to 1.5","0280a904":"We will use all the images except chris_12.jpg. We will keep it for testing","964232a5":"# Importing Libraries","89768978":"## So here we conclude that none of them are really very good, but yeah for small purposes it's not that bad also.","32fea960":"# OOOOOOOPSSSSSS!!!!!!","e4dad1b7":"## Make the encodings","c421025c":"### It didn't match with image 4 and 7","a0533823":"## make encoding for chris_12.jpg"}}