{"cell_type":{"0d7432e6":"code","7704bf31":"code","60b1a71e":"code","c15ac2ff":"code","c02dec7a":"code","266558bf":"code","acef5299":"code","e7a7b99d":"code","5272c14a":"code","f9ad3501":"code","4b4a1039":"code","3973830e":"code","7f97816e":"code","9eb85e11":"code","1a3e238a":"code","3c6d1f42":"code","9c2c4bb1":"code","f4e60623":"code","14591d41":"code","6dde6921":"code","31ed88b4":"code","cc175eb1":"code","9d1c7941":"code","60a195bc":"markdown","54a1fc06":"markdown","b08505e3":"markdown","6a90e1fc":"markdown","b4781da2":"markdown","06526af1":"markdown","18186651":"markdown","8f391d23":"markdown","3646d663":"markdown","f78af953":"markdown","a933f88e":"markdown","d14bc64c":"markdown","64dca6c7":"markdown","1a77246e":"markdown","11152f11":"markdown","02d8bc0b":"markdown","477d6861":"markdown","5161db50":"markdown"},"source":{"0d7432e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7704bf31":"import matplotlib.pyplot as plt\nimport seaborn as sns","60b1a71e":"df_grad = pd.read_csv(\"..\/input\/Admission_Predict.csv\")","c15ac2ff":"df_grad.info()","c02dec7a":"plt.hist(df_grad['GRE Score'])","266558bf":"plt.hist(df_grad['TOEFL Score'])","acef5299":"plt.hist(df_grad['CGPA'])","e7a7b99d":"df_grad = df_grad.drop(['Serial No.'],axis =1)","5272c14a":"plt.figure(figsize = [10,10])\nsns.heatmap(df_grad.corr(),annot=True)","f9ad3501":"X = df_grad.drop(['Chance of Admit '],axis =1)\ny = df_grad['Chance of Admit ']","4b4a1039":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","3973830e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)","7f97816e":"from sklearn.linear_model import LinearRegression\nlin_regressor = LinearRegression()\nlin_regressor.fit(X_train,y_train)\nfrom sklearn.metrics import mean_squared_error\ny_predict = lin_regressor.predict(X_test)","9eb85e11":"print(\"Accuracy Level : \",lin_regressor.score(X_test, y_test)*100,' %')\nprint(\"Mean Squared Error is : \",np.sqrt(mean_squared_error(y_test,y_predict)))","1a3e238a":"plt.plot(range(len(y_test)),y_test)\nplt.plot(range(len(y_predict)),y_predict)","3c6d1f42":"from sklearn.ensemble import RandomForestRegressor\nrandom_regressor = RandomForestRegressor(n_estimators = 200)\nrandom_regressor.fit(X_train,y_train)\ny_predict = random_regressor.predict(X_test)","9c2c4bb1":"print(\"Accuracy Level : \",random_regressor.score(X_test, y_test)*100,' %')\nprint(\"Mean Squared Error is : \",np.sqrt(mean_squared_error(y_test,y_predict)))","f4e60623":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import Lasso,Ridge,BayesianRidge,ElasticNet,HuberRegressor,LinearRegression,LogisticRegression,SGDRegressor\nfrom sklearn.metrics import mean_squared_error\n\nmodels = [['DecisionTree :',DecisionTreeRegressor()],\n           ['Linear Regression :', LinearRegression()],\n           ['RandomForest :',RandomForestRegressor(n_estimators = 200)],\n           ['KNeighbours :', KNeighborsRegressor(n_neighbors = 2)],\n           ['SVM :', SVR()],\n           ['AdaBoostClassifier :', AdaBoostRegressor()],\n           ['GradientBoostingClassifier: ', GradientBoostingRegressor()],\n           ['Xgboost: ', XGBRegressor(max_depth = 6)],\n           ['CatBoost: ', CatBoostRegressor(logging_level='Silent')],\n           ['Lasso: ', Lasso()],\n           ['Ridge: ', Ridge()],\n           ['BayesianRidge: ', BayesianRidge()],\n           ['ElasticNet: ', ElasticNet()],\n           ['HuberRegressor: ', HuberRegressor()]]","14591d41":"RMS_score_model = {}\nACC_score_model = {}\nfor name_of_model,model_parms in models:\n    curr_model = model_parms\n    curr_model.fit(X_train, y_train)\n    curr_predict = curr_model.predict(X_test)\n    RMS_score_model[name_of_model] = np.sqrt(mean_squared_error(y_test, curr_predict))\n    ACC_score_model[name_of_model] = curr_model.score(X_test, y_test)*100","6dde6921":"from collections import OrderedDict\nRMS_sorted_scores_value = OrderedDict(sorted(RMS_score_model.items(), key=lambda x: x[1]))\nACC_sorted_scores_value = OrderedDict(sorted(ACC_score_model.items(), key=lambda x: x[1],reverse = True))","31ed88b4":"print('RMS Scores for the models are as follows :')\nRMS_sorted_scores_value","cc175eb1":"print('Accuracy Levels % for the models are as follows :')\nACC_sorted_scores_value","9d1c7941":"from sklearn.linear_model import LinearRegression\nlin_regressor = LinearRegression()\nlin_regressor.fit(X_train,y_train)\nfrom sklearn.metrics import mean_squared_error\ny_predict = lin_regressor.predict(X_test)\nplt.plot(range(len(y_test)),y_test)\nplt.plot(range(len(y_predict)),y_predict)\nprint(\"Accuracy Level : \",lin_regressor.score(X_test, y_test)*100,' %')\nprint(\"Mean Squared Error is : \",np.sqrt(mean_squared_error(y_test,y_predict)))","60a195bc":"**** Lets sort the RMS and Accuracies to print them in order ***","54a1fc06":"** Accuracy level decreased and MSE also increased indicating Linear model was better","b08505e3":"** Applying Logistic regression - Regression problem (Continuous dependent variable) **","6a90e1fc":"*** We can go with Linear regression which give good results as seen from stats above ***","b4781da2":"**** Lets run Linear model again to summarize ****","06526af1":"*** As seen above GRE Score, TOEFL, CGPA and Univ Rating are the determinants to Change to admission **","18186651":"*** Let me know your views and any inputs please.....","8f391d23":"********** Lets Drop the Serial No. Field - Not Significant *********","3646d663":"Reading the Dataset","f78af953":"** Lets plot the graph of test and predicted values","a933f88e":"Visualising the dataset","d14bc64c":"*** Lets Feature scale the variables *** ","64dca6c7":"** Lets Try to run all the regression models and compare the accuracies and MSE **","1a77246e":"** Lets now try RandomForest algorithm **","11152f11":"#******************  Importing Libraries     **************************","02d8bc0b":"*** Lets prep our variables for processing ***","477d6861":"***** Let see the corr of the field to the Chance of Admission *** ","5161db50":"** Lets Split the dataset into training and test sets **"}}