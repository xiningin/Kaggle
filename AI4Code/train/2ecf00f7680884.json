{"cell_type":{"0395ad46":"code","a17fedaf":"code","95490d13":"code","ba1654cc":"code","8f357a20":"code","cac43d2b":"code","7c991b38":"code","3003b297":"code","7318bb69":"markdown","a64a920b":"markdown","1e64a667":"markdown","bb542a4f":"markdown"},"source":{"0395ad46":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\n\n# Import H2O AutoML\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init(max_mem_size='16G')","a17fedaf":"# Read training set\ndata_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata_train.head()\n\n# Read evaluation set\ndata_eval = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndata_eval.head()\n","95490d13":"def feature_engineering(data):\n\n    # Column Pclass\n    dummies = pd.get_dummies(data['Pclass'], prefix='Pclass')\n    data = pd.concat([data, dummies], axis=1)\n    \n    # Column Name\n    data['Name_Mr'] = data['Name'].str.contains('Mr.').astype(int)\n    data['Name_Mrs'] = data['Name'].str.contains('Mrs.').astype(int)\n    data['Name_Miss'] = data['Name'].str.contains('Miss.').astype(int)\n    data['Name_Master'] = data['Name'].str.contains('Master.').astype(int)\n    data['Name_Doctor'] = data['Name'].str.contains('Dr.').astype(int)\n    data['Name_Ms'] = data['Name'].str.contains('Ms.').astype(int)\n    data['Name_Rev'] = data['Name'].str.contains('Rev.').astype(int)\n    data['Name_Major'] = data['Name'].str.contains('Major.').astype(int)\n    data['Name_OtherTitle']=((data.Name_Mr==0)&(data.Name_Mrs==0)&(data.Name_Miss==0)&(data.Name_Master==0)&(data.Name_Doctor==0)&(data.Name_Ms==0)&(data.Name_Rev==0)&(data.Name_Major==0)).astype(int)\n    \n    # Column Sex\n    data['Sex'] = data['Sex'].map({'male':0, 'female':1})\n    \n    # Column Ticket\n    data['Ticket_PC'] = data['Ticket'].fillna('').str.contains('PC').astype(int)\n    data['Ticket_CA'] = data['Ticket'].fillna('').str.contains('CA').astype(int)\n    data['Ticket_A\/5'] = data['Ticket'].fillna('').str.contains('A\/5').astype(int)\n    data['Ticket_A\/4'] = data['Ticket'].fillna('').str.contains('A\/4').astype(int)\n    data['Ticket_PP'] = data['Ticket'].fillna('').str.contains('PP').astype(int)\n    data['Ticket_SOTON'] = data['Ticket'].fillna('').str.contains('SOTON').astype(int)\n    data['Ticket_STON'] = data['Ticket'].fillna('').str.contains('STON').astype(int)\n    data['Ticket_SC\/Paris'] = data['Ticket'].fillna('').str.contains('SC\/PARIS').astype(int)\n    data['Ticket_W\/C'] = data['Ticket'].fillna('').str.contains('W\/C').astype(int)\n    data['Ticket_FCC'] = data['Ticket'].fillna('').str.contains('FCC').astype(int)\n    data['Ticket_LINE'] = data['Ticket'].fillna('').str.contains('LINE').astype(int)\n    data['Ticket_SOC'] = data['Ticket'].fillna('').str.contains('SOC').astype(int)\n    data['Ticket_SC'] = data['Ticket'].fillna('').str.contains('SC').astype(int)\n    data['Ticket_C'] = data['Ticket'].fillna('').str.contains('C ').astype(int)\n    data['Ticket_Numeric'] = data['Ticket'].str.isnumeric().astype(int)\n       \n    # Column Cabin\n    data['Cabin_A'] = data.Cabin.fillna('').str.contains('A').astype(int)\n    data['Cabin_B'] = data.Cabin.fillna('').str.contains('B').astype(int)\n    data['Cabin_C'] = data.Cabin.fillna('').str.contains('C').astype(int)\n    data['Cabin_D'] = data.Cabin.fillna('').str.contains('D').astype(int)\n    data['Cabin_E'] = data.Cabin.fillna('').str.contains('E').astype(int)\n    data['Cabin_F'] = data.Cabin.fillna('').str.contains('F').astype(int)\n    data['Cabin_G'] = data.Cabin.fillna('').str.contains('G').astype(int)\n    \n    # Column Embarked\n    dummies = pd.get_dummies(data['Embarked'], prefix='Embarked')\n    data = pd.concat([data, dummies], axis=1)\n    \n    # Drop columns\n    data.drop(columns=['PassengerId','Name', 'Ticket', 'Cabin', 'Embarked', 'Pclass'], inplace=True)\n    \n    return data","ba1654cc":"# Cleanse train set\ndata_train_cleansed = feature_engineering(data_train.copy())","8f357a20":"# Train AutoML Model\nH2O_train = h2o.H2OFrame(data_train_cleansed)\nx =H2O_train.columns\ny ='Survived'\nx.remove(y)\n\nH2O_train[y] = H2O_train[y].asfactor()\n\naml = H2OAutoML(max_models=20, seed=1)\naml.train(x=x, y=y, training_frame=H2O_train)\n\n# Print AutoML leaderboard\naml.leaderboard","cac43d2b":"# model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n# model = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])","7c991b38":"# Get train data accuracy\npred = aml.predict(h2o.H2OFrame(data_train_cleansed))\npred = pred.as_data_frame()['predict'].tolist()\n\naccuracy = sum(1 for x,y in zip(np.round(pred),data_train_cleansed.Survived) if x == y) \/ len(data_train_cleansed.Survived)\nprint('accuracy:',accuracy)","3003b297":"# Transform test set\ndata_eval_cleansed = feature_engineering(data_eval.copy())\n\nX_eval = data_eval_cleansed\n\ny_eval_pred = aml.predict(h2o.H2OFrame(X_eval))\ny_eval_pred = y_eval_pred.as_data_frame()['predict'].tolist()\n\noutput = pd.DataFrame({'PassengerId': data_eval.PassengerId, 'Survived': y_eval_pred})\noutput.to_csv('my_submission_202002015.csv', index=False)\nprint(\"Your submission was successfully saved!\")","7318bb69":"### 1. Load Data","a64a920b":"### 4. Predict Evalutaion Set","1e64a667":"### 2. Feature Engineering","bb542a4f":"### 3. Model Training"}}