{"cell_type":{"f212d482":"code","cd2304da":"code","6c898b17":"code","7a9afb75":"code","39ad4717":"code","2eae2032":"code","7a02f381":"code","c3052f6b":"code","056ec31c":"code","541d0bf3":"code","55a09f23":"code","376cee13":"code","6fcbd9f9":"code","f3605f51":"code","088f7b03":"code","50e72dd7":"code","026eac28":"code","4e04ec1b":"code","7af75795":"code","bfbe5921":"code","ce3bfeb0":"code","6454141a":"code","1ad56cf8":"code","bbdc56ad":"code","8f89471d":"code","92b38577":"code","a78db835":"code","4ae42513":"code","9a73f434":"code","723517e1":"code","c18b8afe":"code","c4638f07":"code","ba7333ba":"code","af1ec6dd":"code","26239566":"code","a480c792":"code","4ff9a0b2":"code","2991a508":"code","57fe7052":"code","b8e30a03":"code","7cd92dc6":"code","62260460":"code","88eae836":"code","3fc362c8":"code","6d7e3a47":"code","a35a06cb":"code","a97ff8ee":"code","f00c3711":"code","a3141f3e":"code","795f49e4":"markdown","bab98532":"markdown","a2ba30a4":"markdown","eb1e037c":"markdown","bcbd8888":"markdown","2b47d6b4":"markdown","baae1cb5":"markdown","46dcd717":"markdown","4d124f25":"markdown","fe7fa559":"markdown","d8f92a99":"markdown","df43d6b2":"markdown","df03f6e9":"markdown","7681182a":"markdown","5eaab30e":"markdown","8d161e34":"markdown","6624a641":"markdown","4a77d2ce":"markdown","95c11131":"markdown","b0255ddd":"markdown","625f4cf3":"markdown","cedc7a7f":"markdown","28c95581":"markdown","7008c7c9":"markdown"},"source":{"f212d482":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd2304da":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.dates import DateFormatter\nfrom datetime import datetime, timedelta, date\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf","6c898b17":"df = pd.read_csv('..\/input\/traffic-prediction-dataset\/traffic.csv', parse_dates=True, index_col='DateTime')\ndf.head()","7a9afb75":"df.describe()","39ad4717":"# extract year from date\ndf['Year'] = pd.Series(df.index).apply(lambda x: x.year).to_list()\n\n# extract month from date\ndf['Month'] = pd.Series(df.index).apply(lambda x: x.month).to_list()\n\n# extract day from date\ndf['Day'] = pd.Series(df.index).apply(lambda x: x.day).to_list()\n\n# extract hour from date\ndf['Hour'] = pd.Series(df.index).apply(lambda x: x.hour).to_list()","2eae2032":"df.drop('ID', axis=1, inplace=True)","7a02f381":"def make_hist(junction=1):\n    data = df[df['Junction'] == junction]\n    f, ax = plt.subplots(figsize=(17, 5))\n    ax = sns.histplot(data['Vehicles'], kde=True, stat='probability')\n    ax.set_title(f'Plot show the distribution of data in junction {junction}')\n    ax.grid(True, ls='-.', alpha=0.75)\n    plt.show()","c3052f6b":"make_hist(1)","056ec31c":"make_hist(2)","541d0bf3":"make_hist(3)","55a09f23":"make_hist(4)","376cee13":"df.tail(1).Year[0]","6fcbd9f9":"def make_time_series_plot(junction=1):\n    f, ax = plt.subplots(figsize=(17, 5))\n    data=df[df.Junction == junction]\n    ax = sns.lineplot(data=data, y='Vehicles', x='DateTime', ax=ax)\n    start = data.head(1)\n    end = data.tail(1)\n    ax.set_title(f'Plot show amounts of Vehicles in junction {junction} from {start.Month[0]}-{start.Year[0]} to {end.Month[0]}-{end.Year[0]}', fontsize=15)\n    ax.grid(True, ls='-.', alpha=0.75)\n    plt.show()","f3605f51":"make_time_series_plot(1)","088f7b03":"make_time_series_plot(2)","50e72dd7":"make_time_series_plot(3)","026eac28":"make_time_series_plot(4)","4e04ec1b":"f, ax = plt.subplots(3, 4, figsize=(20, 10))\n\nfor i, year in enumerate(range(2015, 2018)):\n  for j, junction in enumerate(range(1, 5)):\n    sns.lineplot(data=df[(df.Junction == junction) & (df.Year == year)], x='Month', y='Vehicles', ax=ax[i, j])\n    ax[i, j].grid(True, alpha=0.75, ls='-.')\n\nplt.xlabel('Year')\nplt.ylabel('Junction')\nf.suptitle('Line plot showing the pattern amounts of Vehicles by Year and by Junction', fontsize=20)\nplt.show()","7af75795":"f, axis = plt.subplots(3, 4, figsize=(20, 10))\n\nfor i, year in enumerate(range(2015, 2018)):\n  for j, junction in enumerate(range(1, 5)):\n    sns.histplot(df[(df.Junction == junction) & (df.Year == year)]['Vehicles'], kde=True, ax=axis[i, j], stat='probability')\n    axis[i, j].grid(True, alpha=0.75, ls='-.')\n\nplt.xlabel('Year')\nplt.ylabel('Junction')\nf.suptitle('Histogram showing the distribution of Vehicles by Year and by Junction', fontsize=20)\nplt.show()","bfbe5921":"standardization = lambda x: StandardScaler().fit_transform(x)","ce3bfeb0":"z_df = df.copy()\nz_df['Vehicles'] = standardization(z_df.Vehicles.values.reshape(-1, 1))\nz_df.head()","6454141a":"f, axis = plt.subplots(3, 4, figsize=(20, 10))\n\nfor i, year in enumerate(range(2015, 2018)):\n  for j, junction in enumerate(range(1, 5)):\n    sns.histplot(z_df[(z_df.Junction == junction) & (z_df.Year == year)]['Vehicles'], kde=True, ax=axis[i, j], stat='probability')\n    axis[i, j].grid(True, alpha=0.75, ls='-.')\n    \nplt.xlabel('Year')\nplt.ylabel('Junction')\nf.suptitle('Histogram showing the distribution of Vehicles by Year and by Junction when data transfrom to Z Score', fontsize=20)\nplt.show()","1ad56cf8":"f, axis = plt.subplots(3, 4, figsize=(20, 10))\n\nfor i, year in zip(range(3), range(2015, 2018)):\n  for j, junction in zip(range(4), range(1, 5)):\n    sns.boxplot(x=df[(df.Junction == junction) & (df.Year == year)]['Vehicles'], ax=axis[i, j])\n    axis[i, j].grid(True, alpha=0.75, ls='-.')\n\nplt.xlabel('Year')\nplt.ylabel('Junction')\nf.suptitle('Boxplot showing the range of amounts Vehicles by Year and by Junction', fontsize=20)\nplt.show()","bbdc56ad":"corr = df.corr()\nf, ax = plt.subplots(figsize=(16, 7))\nsns.heatmap(corr, annot=True, fmt='.2f', vmin=-1, vmax=1, square=True, linewidths=1)\nf.suptitle('Heatmap showing the correlation of data attributes', fontsize=20)\nplt.show()","8f89471d":"def get_list_data(dataf, drop=[]):\n  # drop c\u1ed9t DateTime \u1edf c\u00e1c data\n  for i in drop:\n    try:\n      dataf.drop(drop, axis=1, inplace=True)\n    except:\n      print(f\"{i} doesn't has in data\")\n  # create a list of dataframe has the data in that junction and remove the junction identify\n  dataf = [dataf[dataf.Junction == i].drop('Junction', axis=1) for i in range(5)]\n  return dataf","92b38577":"data = get_list_data(df)\nfor i in data:\n    print(i.head(1))","a78db835":"f, ax = plt.subplots(nrows=4, figsize=(20, 15))\nfor i in range(4):\n    ax[i].plot(data[i + 1].resample('D').sum().Vehicles, label=f'Vehicles of {i + 1} Junction', lw=2)\n    ax[i].grid(True, alpha=0.75, lw=1, ls='-.')\n    ax[i].set_title(f'Junction {i + 1}')\nf.suptitle('Plots show amounts of Vehicles by Junction, each Junction by day (24h)', fontsize=20);","4ae42513":"f, ax = plt.subplots(nrows=4, figsize=(20, 15))\nfor i in range(4):\n    ax[i].plot(data[i + 1].resample('M').sum().Vehicles, label=f'Vehicles of {i + 1} Junction', lw=2)\n    ax[i].grid(True, alpha=0.75, lw=1, ls='-.')\n    ax[i].set_ylabel('S\u1ed1 l\u01b0\u1ee3ng', fontsize=15)\n    ax[i].set_title(f'Junction {i + 1}')\nf.suptitle('Plots show amounts of Vehicles by Junction, each Junction by Month', fontsize=20);","9a73f434":"f, ax = plt.subplots(nrows=4, figsize=(22, 20))\nfor i in range(4):\n    ax[i].plot(data[i + 1].resample('12H').sum().Vehicles, label=f'Vehicles of {i + 1} Junction', lw=1)\n    ax[i].grid(True, alpha=0.75, lw=1, ls='-.')\n    ax[i].set_title(f'Junction {i + 1}')\nf.suptitle('Plots show amounts of Vehicles by Junction, each Junction by haft day(12h)', fontsize=20);","723517e1":"f, ax = plt.subplots(nrows=4, figsize=(22, 15))\nfor i in range(4):\n    ax[i].plot(data[i + 1].resample('6H').sum().Vehicles, label=f'Vehicles of {i + 1} Junction', lw=2)\n    ax[i].grid(True, alpha=0.75, lw=1, ls='-.')\n    ax[i].set_title(f'Junction {i + 1}')\nf.suptitle('Plots show amounts of Vehicles by Junction, each Junction by 1\/4 day (6h)', fontsize=20);","c18b8afe":"f, ax = plt.subplots(figsize=(17, 5))\nfoo = data[1][:400]\nfoo.Vehicles.plot(lw=3)\nfoo.Vehicles.rolling('D').mean().plot(lw=3)\nfoo.Vehicles.rolling('D').std().plot(lw=3)\nplt.legend(['Junction 1', 'Rolling Mean A Day', 'Rolling Std A Day'])\nplt.grid(True, alpha=0.75, ls='-.')\nplt.title('Plot show amounts of Vehicles first 400 hours', fontsize=20)\nplt.show()","c4638f07":"f, ax = plt.subplots(figsize=(17, 5))\nfoo = data[2][:400]\nfoo.Vehicles.plot(lw=3)\nfoo.Vehicles.rolling('D').mean().plot(lw=3)\nfoo.Vehicles.rolling('D').std().plot(lw=3)\nplt.legend(['Junction 2', 'Rolling Mean A Day', 'Rolling Std A Day'])\nplt.grid(True, alpha=0.75, ls='-.')\nplt.title('Plot show amounts of Vehicles first 400 hours', fontsize=20)\nplt.show()","ba7333ba":"f, ax = plt.subplots(figsize=(17, 5))\nfoo = data[3][:400]\nfoo.Vehicles.plot(lw=3)\nfoo.Vehicles.rolling('D').mean().plot(lw=3)\nfoo.Vehicles.rolling('D').std().plot(lw=3)\nplt.legend(['Junction 3', 'Rolling Mean A Day', 'Rolling Std A Day'])\nplt.grid(True, alpha=0.75, ls='-.')\nplt.title('Plot show amounts of Vehicles first 400 hours', fontsize=20)\nplt.show()","af1ec6dd":"f, ax = plt.subplots(figsize=(17, 5))\nfoo = data[4][:400]\nfoo.Vehicles.plot(lw=3)\nfoo.Vehicles.rolling('D').mean().plot(lw=3)\nfoo.Vehicles.rolling('D').std().plot(lw=3)\nplt.legend(['Junction 4', 'Rolling Mean A Day', 'Rolling Std A Day'])\nplt.grid(True, alpha=0.75, ls='-.')\nplt.title('Plot show amounts of Vehicles first 400 hours', fontsize=20)\nplt.show()","26239566":"def make_autocorrelation(junction=1):\n    f, ax = plt.subplots(figsize=(17, 6), nrows=2)\n    plot_acf(data[junction].Vehicles, title=f\"Autocorrelation of amounts of Vehicles in Junction {junction}\", ax=ax[0])\n    plot_pacf(data[junction].Vehicles, title=f\"Partial Autocorrelation of amounts of Vehicles Junction {junction}\", ax=ax[1])\n    plt.show()","a480c792":"make_autocorrelation(1)","4ff9a0b2":"make_autocorrelation(2)","2991a508":"make_autocorrelation(3)","57fe7052":"make_autocorrelation(4)","b8e30a03":"def make_metrics(models):\n    data = {\n        'name': [model.name for model in models[1:]],\n        'r2': [model.r2 for model in models[1:]],\n        'rmse': [model.rmse for model in models[1:]]\n    }\n    data['name'] = 'average R2 and sum RMSE'\n    data['r2'].append(np.mean(data['r2']))\n    data['rmse'].append(np.sum(data['rmse']))\n    return pd.DataFrame(data)","7cd92dc6":"z_data = get_list_data(z_df)\nfor i in z_data:\n    print(i.head(1))","62260460":"class Model:\n  def __init__(self, name, data, predict_features, test_size, ml_model):\n    self.name = name\n    self.data = data\n    self.predict_features = predict_features\n    self.is_trained = False\n    self.test_size = test_size\n    self.ml_model = ml_model\n    self.do_things()\n\n  def cal_rmse(self):\n    self.rmse = mean_squared_error(self.ytest, self.ypredict, squared=False)\n    return self.rmse\n\n  def prequisite(self, test_size):\n    self.features = [i for i in self.data.columns if i != self.predict_features]\n    self.X = self.data[self.features].values\n    self.y = self.data[self.predict_features].values\n    self.Xtrain, self.Xtest, self.ytrain, self.ytest = train_test_split(self.X, self.y, test_size=test_size)\n    return None\n\n  def fit(self):\n    self.is_trained = True\n    self.ml_model.fit(self.Xtrain, self.ytrain)\n    self.ypredict = self.ml_model.predict(self.Xtest)\n    return self.ml_model\n\n  def cal_r2_score(self):\n    self.r2 = r2_score(self.ytest, self.ypredict)\n    return self.r2\n\n  def do_things(self) -> None:\n    self.prequisite(self.test_size)\n    self.fit()\n    self.cal_rmse()\n    self.cal_r2_score()\n    return None\n\n  def feature_importances(self, ax) -> None:\n    feature_importances = self.ml_model.feature_importances_\n    index = lag_models[1].features\n    data = pd.DataFrame(pd.Series(feature_importances, index=index).nlargest(10)).reset_index()\n    data.columns = ['Features', 'Value']\n    g = sns.barplot(data=data, x='Features', y='Value', ax=ax)\n    for p in g.patches:\n        ax.annotate(\n            format(p.get_height(), '.2f'),\n            (p.get_x() + p.get_width() \/ 2, p.get_height() + 0.02),\n            ha='center', va='center', weight='bold', fontsize=9\n        )\n    ax.set_title(f'Plot of {self.name}', fontsize=12)\n    ax.grid(True, ls='-.', alpha=0.7)\n    ax.set_ylim(0, 1)\n\n  def __repr__(self) -> str:\n    if not self.is_trained:\n      return f'<{self.name}> (is not trained yet)>'\n    return f'<({self.name}: [R\u00b2 Score: {self.r2}], [RMSE: {self.rmse}])>'","88eae836":"models = [None]\nfor i in range(1, 5):\n    models += [\n        Model(\n            ml_model=RandomForestRegressor(),\n            name=f'Dataset of junction {i}',\n            data=data[i],\n            predict_features='Vehicles',\n            test_size=1\/4\n        )\n    ]\n    \nmake_metrics(models)","3fc362c8":"z_models = [None]\nfor i in range(1, 5):\n    z_models += [\n        Model(\n            ml_model=RandomForestRegressor(),\n            name=f'Dataset of junction {i}',\n            data=z_data[i],\n            predict_features='Vehicles',\n            test_size=1\/4\n        )\n    ]\n\nmake_metrics(z_models)","6d7e3a47":"lag_df = df.copy()\nfor i in range(1, 3):\n    lag_df[f'Vehicles_lag_{i}'] = df.Vehicles.shift(i)\n\n# drop all rows with nan, because lag data cause nan\nlag_df.dropna(inplace=True)\nlag_df.head()","a35a06cb":"lag_data = get_list_data(lag_df, drop=['Year'])\nfor i in lag_data:\n    print(i.head(1))","a97ff8ee":"lag_models = [None]\nfor i in range(1, 5):\n    lag_models += [\n        Model(\n            ml_model=RandomForestRegressor(),\n            name=f'Dataset of junction {i} with lag data',\n            data=lag_data[i],\n            predict_features='Vehicles',\n            test_size=1\/3\n        )\n    ]\n\nmake_metrics(lag_models)","f00c3711":"f, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 8))\nk = 1\nfor i in range(2):\n    for j in range(2):\n        lag_models[k].feature_importances(ax[i, j])\n        k += 1\nf.suptitle('Plots show how features in each dataset correlating to each model', fontsize=15, fontweight='bold')        \nf.tight_layout()","a3141f3e":"for junction in range(1, 5):\n    cur_time = lag_data[junction].tail(1).index[0] # get the current time, the last time of that dataset\n    end_time = pd.Timestamp(2017, 11, 1, 0, 0, 0) # the end time after 4 months that we want to predict\n    new_data = lag_data[junction].copy() # create a copy of dataset with that junction\n    features = lag_models[junction].features # get features of each models in that junction\n    while cur_time != end_time:\n        last = new_data.tail(1).copy() # get the last row of dataset, just make a copy!\n        new_data = pd.concat([new_data, last]) # concatenate the copy dataset with it's last row\n        for i in range(1, 3): # create lag data\n            new_data[f'Vehicles_lag_{i}'] = new_data.Vehicles.shift(i) # shift by periods i\n        new_data.iloc[len(new_data) - 1, [1, 2, 3]] = [cur_time.month, cur_time.day, cur_time.hour] # assign value for those columns\n        last = new_data[features].tail(1).values # create a new last data that drop all nan\n        new_data.iloc[len(new_data) - 1, 0] = round(lag_models[1].ml_model.predict(last)[0]) # predicting for vehicles\n        cur_time += timedelta(hours=1) # add to a cur_time 1 hour\n    new_data.index = pd.date_range(\n        start=lag_data[junction].head(1).index.values[0],\n        end=pd.Timestamp(2017, 11, 1, 0, 0, 0),\n        freq='H'\n    ) # reassign index with the new time range with start is the start of data\n      # and end time is the end time that initialize in start of the loop\n    new_data.to_csv(f'vehicles_for_next_4_months_in_junction_{junction}.csv') # to csv that file\n    print(f'|==Predicted for Junction {junction}==|')","795f49e4":"**Create a function to create a new dataset**","bab98532":"I make a `make_hist` function for making `histogram` with `kde` plot, for plotting 4 junction","a2ba30a4":"# Data Exploration","eb1e037c":"**Auto correlation plot**\n- The data lie outside the blue has 95% effect to data","bcbd8888":"# Some basic info about this dataset\n- Has 4 Junction","2b47d6b4":"In 4 plot, its can show us that `Vehicles` in each junction is normal distribution with skew","baae1cb5":"**Extract Year, Month, Day, Hour** from **index**\n- I split Year, Month, Day, Hour from data for plotting purpose","46dcd717":"**Z Score data distribution and Histogram with Z Score Vehicles form Data**\n- Mean = 0\n- Standard Deviation = 1","4d124f25":"**Create lag data**","fe7fa559":"**Normal data histogram**","d8f92a99":"**Create a make metrics function to return R\u00b2 Score and RMSE from a list of models**","df43d6b2":"**Drop the ID column**\nI think ID does not effect to this dataset, so just drop it!","df03f6e9":"**Heatmap about data attributes**\n- The value closer to 1 or -1 is best correlation to each other.\n- As close as to -1, that pair of attribute is more **negative** correlation.\n- As close as to 1, that pair of attribute is more **positive** correlation.\n- As close as to 0, that pair of attribute is **not** correlating to each other.","7681182a":"**Create a class for a frame for machine learning model**","5eaab30e":"# Conclusion\nThe highest RMSE is about 5.6, so when using last amounts of Vehicles to predict next hour amounts of Vehicles seem like that RMSE is raising. You guys can puts a review of your own into the comments section below. Be honest, i'm very newbie, so if has something may not right in my kernel, you can tell me about that, i'm very appreciate about that. Thanks for reading my kernel!","8d161e34":"**Lag data is appropriate for time series data, use for create the auto correlation**","6624a641":"- Month has **negative** correlation with Year\n- The correlation of Vehicles and Year is equal to Vehicles and Hour\n\n**=> Can drop Year or Hour because it's the same**","4a77d2ce":"**Training models for 4 junction with Z Score Normalization**","95c11131":"**Boxplot for Vehicles**\n- In boxplot, we can see a lot of outliers (those which is the dot)","b0255ddd":"**Some describe in this dataset**","625f4cf3":"**Training models for 4 junction with normal data**","cedc7a7f":"# Modeling","28c95581":"**Feature importances of a model**\n\n*The correlate value as close as 1 is best*","7008c7c9":"**Predict for next 4 months**\n\nI predict for each Junction separately. I use previous prediction amounts of Vehicles for predicting next amounts of Vehicles."}}