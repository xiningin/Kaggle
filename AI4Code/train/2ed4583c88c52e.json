{"cell_type":{"ac5424b1":"code","4c9d02b6":"code","3fe09e05":"code","433ee7f0":"code","4a32748f":"code","670ad45a":"code","5133140d":"code","47613b58":"markdown","742ac691":"markdown","3084974b":"markdown"},"source":{"ac5424b1":"import tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.python.client import device_lib\nimport numpy as np\n\nfrom matplotlib import cm as CM\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport scipy.io as io\nfrom PIL import Image\nimport PIL\nimport h5py\nimport os\nimport glob\nimport cv2\nimport random\nimport math\nimport sys\nimport itertools \n\nprint(tf.__version__)\n\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy)\n\nprint('Compute dtype: %s' % policy.compute_dtype)\nprint('Variable dtype: %s\\n\\n' % policy.variable_dtype)\n\nfor info in device_lib.list_local_devices():\n    if (info.name.find('GPU') != -1):\n        print(info)","4c9d02b6":"def getPath(data_type):\n    root = r'..\/input\/shanghaitech-with-people-density-map\/ShanghaiTech'\n    print(root)\n    if data_type.find('part_A')!=-1:\n        target_train = os.path.join(root,r'part_A\/train_data','images')\n        target_test = os.path.join(root,r'part_A\/test_data','images')\n\n    elif data_type.find('part_B')!=-1:\n        target_train = os.path.join(root,r'part_B\/train_data','images')\n        target_test = os.path.join(root,r'part_B\/test_data','images')\n\n    train_path = []\n    for img_path in glob.glob(os.path.join(target_train, '*.jpg')):\n        train_path.append(str(img_path))\n        \n    test_path = []\n    for img_path in glob.glob(os.path.join(target_test, '*.jpg')):\n        test_path.append(str(img_path))\n        \n    return train_path, test_path\n\ndef load_density(file_path):\n    gt_file = h5py.File(file_path, 'r')\n    groundtruth = np.asarray(gt_file['density'])\n    groundtruth = np.expand_dims(groundtruth, axis=-1)\n    return groundtruth\n\n# Get input image path\ntrain_paths, test_paths = getPath('part_B')\n# Get ground truth path\ngth_train = [path.replace('jpg', 'h5').replace('images', 'ground-truth-h5') for path in train_paths]\ngth_test = [path.replace('jpg', 'h5').replace('images', 'ground-truth-h5') for path in test_paths]\n\nprint('train len:', len(train_paths))\nprint('test len:', len(test_paths))\n\nprint(train_paths[0])\nprint(gth_train[0])\n\ntrain_labels=np.array([load_density(path) for path in gth_train]).astype('float16')\nprint(train_labels.shape)\ntest_labels=np.array([load_density(path) for path in gth_test]).astype('float16')\nprint(test_labels.shape)","3fe09e05":"target_type=tf.dtypes.float16\ndef load_img(path):\n    image_string=tf.io.read_file(path)\n    image=tf.image.decode_jpeg(image_string,channels=3)\n    image=tf.image.convert_image_dtype(image, target_type)\n    return image\n\ndef gen_translate_func(translate_range):\n    def translate_function(img, gth):\n        ratio=tf.random.uniform((2,), minval=translate_range[1], maxval=translate_range[0], dtype=tf.dtypes.int32)\n        ratio=tf.cast(ratio, target_type)\n\n        out_gth=tfa.image.translate(gth, ratio, 'BILINEAR')\n        out_img=tfa.image.translate(img, ratio, 'BILINEAR')\n\n        return out_img, out_gth\n    return translate_function\n\ndef gen_downsampling_func(downsampling, method='nearest', batch=True):\n    batchadd=1\n    if batch==False:\n        batchadd=0\n    @tf.function\n    def _downsampling_function_(img, gth):\n        down_ratio=downsampling\n        before_resize=tf.reduce_sum(gth)\n        gth_shape=tf.shape(gth)\n        out_gth=tf.image.resize(gth, (gth_shape[0+batchadd]\/\/down_ratio, gth_shape[1+batchadd]\/\/down_ratio), method=method,antialias=False)\n        out_gth=tf.cast(out_gth, dtype=target_type)\n        after_resize=tf.reduce_sum(out_gth)\n        if (before_resize >= 0.3) and (after_resize > 0.01):\n            out_gth=out_gth * before_resize \/ after_resize\n        return img, out_gth\n    return _downsampling_function_\n\ndef gen_randomcrop_func(crop_size, batch=True):\n    batchadd=1\n    if batch==False:\n        batchadd=0\n    @tf.function\n    def _random_crop_(img, gth):\n        \n        output_shape=tf.constant(crop_size)\n        img_shape=tf.shape(img)\n\n        ratio_x=tf.random.uniform((1,), minval=0, maxval=img_shape[1+batchadd]-output_shape[1], dtype=tf.dtypes.int32)[0]\n        ratio_y=tf.random.uniform((1,), minval=0, maxval=img_shape[0+batchadd]-output_shape[0], dtype=tf.dtypes.int32)[0]\n\n        out_img=tf.image.crop_to_bounding_box(img, ratio_y, ratio_x, output_shape[0], output_shape[1])\n        out_gth=tf.image.crop_to_bounding_box(gth, ratio_y, ratio_x, output_shape[0], output_shape[1])\n\n        return out_img, out_gth\n    return _random_crop_\n\ndef gen_coarsedrop_func(hole_count, hole_size, hole_prob=0.75):\n    def _dropout_(image, gth):\n        shape = tf.shape(image)\n        BATCH = shape[0]\n        IMG_WIDTH = shape[2]\n        IMG_HEIGHT = shape[1]\n        IMG_WIDTH_F = tf.cast(IMG_WIDTH, tf.float32)\n        IMG_HEIGHT_F = tf.cast(IMG_HEIGHT, tf.float32)\n        PROBABILITY = hole_prob\n        CT = hole_count\n        CROP_SIZE = tf.cast(hole_size,tf.int32)\n        # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([], 0.0, 1.0) < PROBABILITY, tf.int32)\n        if (P==0): return image, gth\n        \n        mask = tf.ones((IMG_HEIGHT,IMG_WIDTH,1))\n        for k in range(CT):\n            # CHOOSE RANDOM LOCATION\n            x = tf.cast( tf.random.uniform([],0.0,IMG_WIDTH_F),tf.int32)\n            y = tf.cast( tf.random.uniform([],0.0,IMG_HEIGHT_F),tf.int32)\n            # COMPUTE SQUARE\n            ya = tf.math.maximum(0,y-CROP_SIZE\/\/2)\n            yb = tf.math.minimum(IMG_HEIGHT,y+CROP_SIZE\/\/2)\n            xa = tf.math.maximum(0,x-CROP_SIZE\/\/2)\n            xb = tf.math.minimum(IMG_WIDTH,x+CROP_SIZE\/\/2)\n            # DROPOUT IMAGE\n            one = mask[ya:yb,0:xa,:]\n            two = tf.zeros([yb-ya,xb-xa,1]) \n            three = mask[ya:yb,xb:IMG_WIDTH,:]\n            middle = tf.concat([one,two,three],axis=1)\n            mask = tf.concat([mask[0:ya,:,:],middle,mask[yb:IMG_HEIGHT,:,:]],axis=0)\n        \n        # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n        mask = tf.cast(mask, dtype='float16')\n        return image*mask, gth*mask\n    return _dropout_\n\ndef basic_dataset(img_data, label_data, batch_size=1, flip=False, downsampling=1, buffer_size=32, shuffle=False):\n    input_data=tf.data.Dataset.from_tensor_slices(img_data)\n    input_data = input_data.map(load_img)\n    output_data=tf.data.Dataset.from_tensor_slices(label_data)\n\n    if flip:\n        input_data=input_data.concatenate(input_data.map(tf.image.flip_left_right))\n        output_data=output_data.concatenate(output_data.map(tf.image.flip_left_right))\n\n    dataset=tf.data.Dataset.zip((input_data, output_data))\n    if shuffle:\n        dataset = dataset.batch(batch_size).repeat().shuffle(buffer_size=buffer_size, reshuffle_each_iteration=True)\n    else:\n        dataset = dataset.batch(batch_size).repeat()\n\n    if downsampling!=1:\n        dataset=dataset.map(gen_downsampling_func(downsampling=downsampling))\n    return dataset\n\ndef crop_dataset(img_data, label_data, crop_size, flip, downsampling, batch_size=1, sample_method='bicubic', buffer_size=16, \nhole_count=0, hole_size=100, hole_prob=0.75):\n    dataset = basic_dataset(img_data, label_data, flip=flip, batch_size=batch_size, downsampling=1, shuffle=True, buffer_size=buffer_size)\n    dataset=dataset.map(gen_randomcrop_func(crop_size))\n    if hole_count!=0:\n        dataset=dataset.map(gen_coarsedrop_func(hole_count=hole_count, hole_size=hole_size, hole_prob=hole_prob))\n    if downsampling!=1:\n        dataset=dataset.map(gen_downsampling_func(downsampling=downsampling, method=sample_method))\n    return dataset\n\ndef translate_dataset(img_data, label_data, translate_range, flip, downsampling, batch_size=1, sample_method='bicubic', buffer_size=16, \nhole_count=0, hole_size=100, hole_prob=0.75):\n    dataset = basic_dataset(img_data, label_data, flip=flip, batch_size=batch_size, downsampling=1, shuffle=True, buffer_size=buffer_size)\n    dataset=dataset.map(gen_translate_func(translate_range))\n    if hole_count!=0:\n        dataset=dataset.map(gen_coarsedrop_func(hole_count=hole_count, hole_size=hole_size, hole_prob=hole_prob))\n    if downsampling!=1:\n        dataset=dataset.map(gen_downsampling_func(downsampling=downsampling, method=sample_method))\n    return dataset\n            \ndef show_images(images, cols = 2, titles = None, padding=1, axis=\"off\", channel1=CM.jet):\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    # if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    if titles is None: titles = [None for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    \n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images\/float(cols)), n + 1)\n\n        plt.axis(axis)\n        plt.subplots_adjust(wspace=padding, hspace=padding)\n\n        if (image.shape[2] == 1):\n            image = image[:,:,0]\n            plt.imshow(image, cmap=channel1)\n        elif np.any(image > 1.0):\n            plt.imshow(image \/ 255.0)\n        else:\n            plt.imshow(image)\n        a.set_title(title, fontsize=20)\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\ndef density_mae(y_truth, y_pred):\n    return tf.reduce_mean(tf.abs(tf.reduce_sum(y_truth, axis=(1,2,3))-tf.reduce_sum(y_pred, axis=(1,2,3))))","433ee7f0":"class ADConvolution(Layer):\n    def __init__(self, filters, kernel_size, kernel_initializer=RandomNormal(stddev=0.01), kernel_regularizer=None, vType=tf.dtypes.float32, log=False, use_bias=False, **kwargs):\n        super(ADConvolution, self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = kernel_size\n        self.padding = 'SAME'\n        self.strides = 1\n        self.kernel_initializer=kernel_initializer\n        self.kernel_regularizer=kernel_regularizer\n        self.log = log\n        self.vType = vType\n        self.use_bias = use_bias\n    def build(self, input_shape):\n        # ASSUME channel last\n        input_channel = input_shape[3]\n        kernel_shape = self.kernel_size + (input_channel, self.filters)\n        \n        self.dilated_conv1 = tf.keras.layers.Conv2D(1, (3,3),  padding=self.padding, \n                                                   kernel_initializer=self.kernel_initializer, \n                                                   kernel_regularizer=self.kernel_regularizer,\n                                                   use_bias=self.use_bias,\n                                                   activation=tf.math.sigmoid)\n        self.dilated_conv2 = tf.keras.layers.Conv2D(1, (3,3),  padding=self.padding, \n                                                   kernel_initializer=self.kernel_initializer, \n                                                   kernel_regularizer=self.kernel_regularizer,\n                                                   use_bias=self.use_bias,\n                                                   activation=tf.math.sigmoid)\n        self.dilated_conv3 = tf.keras.layers.Conv2D(1, (3,3),  padding=self.padding, \n                                                   kernel_initializer=self.kernel_initializer, \n                                                   kernel_regularizer=self.kernel_regularizer,\n                                                   use_bias=self.use_bias,\n                                                   activation=tf.math.sigmoid)\n        self.dilated_conv4 = tf.keras.layers.Conv2D(1, (3,3),  padding=self.padding, \n                                                   kernel_initializer=self.kernel_initializer, \n                                                   kernel_regularizer=self.kernel_regularizer,\n                                                   use_bias=self.use_bias,\n                                                   activation=tf.math.sigmoid)\n        # Feature Extraction\n        self.kernel = self.add_weight(\n            name='kernel',\n            shape=kernel_shape,\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=None,\n            trainable=True,\n            dtype=self.dtype)\n\n    def get_config(self):\n        config = super(ADConvolution, self).get_config()\n        config.update({\"kernel_size\": self.kernel_size})\n        config.update({\"filters\": self.filters})\n        return config\n    \n    def compute_output_shape(self, input_shape):\n        return input_shape[:3]+self.filters\n    \n    def call(self, x, with_dilation_map=False):\n        dilated_map_1 = self.dilated_conv1(x)\n        dilated_map_2 = self.dilated_conv2(x)\n        dilated_map_3 = self.dilated_conv3(x)\n        dilated_map_4 = self.dilated_conv4(x)\n\n\n        dilation_1 = tf.nn.conv2d(x, self.kernel, self.strides, self.padding, 'NHWC', 1)\n        dilation_2 = tf.nn.conv2d(x, self.kernel, self.strides, self.padding, 'NHWC', 2)\n        dilation_3 = tf.nn.conv2d(x, self.kernel, self.strides, self.padding, 'NHWC', 3)\n        dilation_4 = tf.nn.conv2d(x, self.kernel, self.strides, self.padding, 'NHWC', 4)\n\n        interpolation = dilation_1 * dilated_map_1 + dilation_2 * dilated_map_2 + dilation_3 * dilated_map_3 + dilation_4 * dilated_map_4\n        \n        result = interpolation\n        if with_dilation_map:\n            dilated_map = tf.concat([dilated_map_1,dilated_map_2,dilated_map_3,dilated_map_4], axis=-1)\n            return result, dilated_map\n        else:\n            return result\n        \n        \nclass ADNetwork(Model):\n    def __init__(self, backbone=None, middle_activation='relu', final_activation='sigmoid', dtype=tf.dtypes.float32, reg=(0,0), use_bias=False):\n        super(ADNetwork, self).__init__()\n        if (backbone == None):\n            self.backbone = self._VGG16_BACKBONE_(dtype)\n        else:\n            self.backbone = backbone\n        init=RandomNormal(stddev=0.01)\n        self.b0 = BatchNormalization()\n        \n        self.ad1 = ADConvolution(filters=512, kernel_size=(3, 3), kernel_initializer=init, vType=dtype, use_bias=use_bias)\n        self.b1 = BatchNormalization()\n        self.act1 = Activation(self.get_act(middle_activation))\n        \n        self.ad2 = ADConvolution(filters=512, kernel_size=(3, 3), kernel_initializer=init, vType=dtype, use_bias=use_bias)\n        self.b2 = BatchNormalization()\n        self.act2 = Activation(self.get_act(middle_activation))\n        \n        self.ad3 = ADConvolution(filters=512, kernel_size=(3, 3), kernel_initializer=init, vType=dtype, use_bias=use_bias)\n        self.b3 = BatchNormalization()\n        self.act3 = Activation(self.get_act(middle_activation))\n        \n        self.ad4 = ADConvolution(filters=256, kernel_size=(3, 3), kernel_initializer=init, vType=dtype, use_bias=use_bias)\n        self.b4 = BatchNormalization()\n        self.act4 = Activation(self.get_act(middle_activation))\n        \n        self.ad5 = ADConvolution(filters=128, kernel_size=(3, 3), kernel_initializer=init, vType=dtype, use_bias=use_bias)\n        self.b5 = BatchNormalization()\n        self.act5 = Activation(self.get_act(middle_activation))\n        \n        self.ad6 = ADConvolution(filters=64, kernel_size=(3, 3), kernel_initializer=init, vType=dtype, use_bias=use_bias)\n        self.b6 = BatchNormalization()\n        self.act6 = Activation(self.get_act(middle_activation))\n        \n        self.c7 = Conv2D(filters=1, kernel_size=(1, 1), dilation_rate=1, padding='same', use_bias=True, kernel_initializer=init)\n        self.act7 = Activation(self.get_act(final_activation))\n    def build(self, input_shape):\n        super(ADNetwork, self).build(input_shape=input_shape)\n        self.backbone.build(input_shape=input_shape)\n    def call(self, inputs, with_dilation_map=False):\n        x = self.backbone(inputs)\n        x = self.b0(x)\n        \n        if with_dilation_map:\n            x, dmap1 = self.ad1(x, with_dilation_map)\n        else:\n            x = self.ad1(x)\n        x = self.b1(x)\n        x = self.act1(x)\n        \n        if with_dilation_map:\n            x, dmap2 = self.ad2(x, with_dilation_map)\n        else:\n            x = self.ad2(x)\n        x = self.b2(x)\n        x = self.act2(x)\n        \n        if with_dilation_map:\n            x, dmap3 = self.ad3(x, with_dilation_map)\n        else:\n            x = self.ad3(x)\n        x = self.b3(x)\n        x = self.act3(x)\n        \n        if with_dilation_map:\n            x, dmap4 = self.ad4(x, with_dilation_map)\n        else:\n            x = self.ad4(x)\n        x = self.b4(x)\n        x = self.act4(x)\n        \n        if with_dilation_map:\n            x, dmap5 = self.ad5(x, with_dilation_map)\n        else:\n            x = self.ad5(x)\n        x = self.b5(x)\n        x = self.act5(x)\n        \n        if with_dilation_map:\n            x, dmap6 = self.ad6(x, with_dilation_map)\n        else:\n            x = self.ad6(x)\n        x = self.b6(x)\n        x = self.act6(x)\n        \n        x = self.c7(x)\n        x = self.act7(x)\n        \n        if with_dilation_map:\n            return tf.concat([x, dmap1, dmap2, dmap3, dmap4, dmap5, dmap6], axis=3)\n        else:\n            return x\n    \n    def _VGG16_BACKBONE_(self, dtype=tf.dtypes.float32):\n        vgg16 = VGG16(weights='imagenet', include_top=False)\n        vgg16.trainable=False\n\n        input_layer = Input(shape=(None, None, 3))\n        x = input_layer\n        x = Lambda(lambda batch: (batch - tf.constant([0.485,0.456,0.406], dtype=dtype)) \/ tf.constant([0.229,0.224,0.225], dtype=dtype))(x)\n        count = 0\n        for layer in vgg16.layers:\n            layer.trainable = False\n            x = layer(x)\n            if 'conv' in layer.name:\n                count+=1\n            if count == 10:\n                break;\n        return Model(input_layer, x)\n    def get_act(self, act):\n        activationDict = {\n            'sigmoid': tf.math.sigmoid,\n            'relu': tf.nn.relu,\n            'tanh': tf.math.tanh,\n            'leakyrelu': tf.nn.leaky_relu,\n            'elu': tf.nn.elu,\n            'softsign':tf.nn.softsign\n        }\n        return activationDict[act]","4a32748f":"sgd = SGD(lr = 1e-4, momentum = 0.7, nesterov=True)\nrms = RMSprop(lr=1e-3, momentum=0.7, decay=0.0001)\nnadam = Nadam(lr=1e-2)\n\noptimizer = rms\nloss = 'binary_crossentropy'\n\nbatch_size=8\ntrain_size=320\n\nval_gen = basic_dataset(train_paths[train_size:], train_labels[train_size:], batch_size=1, flip=False, downsampling=8, buffer_size=16, shuffle=False)\ntest_gen = basic_dataset(test_paths, test_labels, batch_size=1, flip=False, downsampling=8, buffer_size=16, shuffle=False)\ntrain_gen = crop_dataset(train_paths[:train_size], train_labels[:train_size], crop_size=(760,1000), flip=True, downsampling=8, batch_size=batch_size, sample_method='bicubic', buffer_size=8)\n\nfilepath = r'\/kaggle\/working\/ADNet'\nreduceLR=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_density_mae', factor=0.5, patience=5, verbose=1, min_delta=1e-8)\nearlyStop=tf.keras.callbacks.EarlyStopping(monitor='val_density_mae', patience=25, verbose=1, restore_best_weights=True)\nmonitor=tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_density_mae', verbose=0, save_best_only=True, save_weights_only=True)\n\nsub_model = ADNetwork(middle_activation='relu', final_activation='sigmoid', dtype=tf.dtypes.float16)\nsub_model.compile(optimizer=optimizer, loss=loss, metrics=[density_mae])\nsub_model.build(input_shape=(None, None, None, 3))\n\nprint('train baseline: ', np.mean( np.sum(train_labels[:train_size], axis=(1,2,3))))\nprint('val baseline: ', np.mean( np.sum(train_labels[320:], axis=(1,2,3))))\n\nsub_model.fit(train_gen, steps_per_epoch=int(train_size*2\/batch_size), epochs=80, verbose=1, use_multiprocessing=True,\n              max_queue_size=32, workers=6, validation_data=val_gen, validation_steps=80, callbacks=[earlyStop, monitor, reduceLR])\n\nsub_model.load_weights(filepath)\nsub_model.evaluate(val_gen, steps=80, verbose=1, workers=4)\nsub_model.evaluate(test_gen, steps=316, verbose=1, workers=4)","670ad45a":"for a,b in val_gen.take(1):\n    c = sub_model.call(a, with_dilation_map=True)\n    c = tf.cast(c, dtype='float32')\n    b = tf.cast(b, dtype='float32')\n    a = tf.cast(a, dtype='float32')\n    show_images([a[0], b[0], c[0,:,:,:1]], 1, ['',np.sum(b[0]),np.sum(c[0,:,:,:1])])\n    for i in range(6):\n        show_images([c[0,:,:,i:i+1] for i in range(1+i*4, 1+(i+1)*4)], 1 ,[np.mean(c[0,:,:,i:i+1]) for i in range(1+i*4, 1+(i+1)*4)])\n        \nfor a,b in val_gen.take(4):\n    c = sub_model.predict(a)\n    c = tf.cast(c, dtype='float32')\n    b = tf.cast(b, dtype='float32')\n    a = tf.cast(a, dtype='float32')\n    show_images([a[0], b[0], c[0]], 1, ['',np.sum(b[0]),np.sum(c[0])])","5133140d":"for a,b in test_gen.take(1):\n    c = sub_model.call(a, with_dilation_map=True)\n    c = tf.cast(c, dtype='float32')\n    b = tf.cast(b, dtype='float32')\n    a = tf.cast(a, dtype='float32')\n    show_images([a[0], b[0], c[0,:,:,:1]], 1, ['',np.sum(b[0]),np.sum(c[0,:,:,:1])])\n    for i in range(6):\n        show_images([c[0,:,:,i:i+1] for i in range(1+i*4, 1+(i+1)*4)], 1 ,[np.mean(c[0,:,:,i:i+1]) for i in range(1+i*4, 1+(i+1)*4)])\nfor a,b in test_gen.take(4):\n    c = sub_model.predict(a)\n    c = tf.cast(c, dtype='float32')\n    b = tf.cast(b, dtype='float32')\n    a = tf.cast(a, dtype='float32')\n    show_images([a[0], b[0], c[0]], 1, ['',np.sum(b[0]),np.sum(c[0])])","47613b58":"# Data Generator","742ac691":"# Load Ground Truth","3084974b":"# Network"}}