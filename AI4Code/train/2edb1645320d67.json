{"cell_type":{"4fc29d8b":"code","4411f780":"code","b567ed3b":"code","dd329477":"code","44cc4ea6":"code","cc127fe2":"code","2fa38fac":"code","9f1d4eed":"code","150e9411":"code","e0056781":"code","520d5881":"code","334f2614":"code","5dc142c3":"code","1d678a1f":"code","8a8afb06":"code","13292534":"code","2518f715":"code","2b5f2dcf":"code","3d159f76":"code","9c1e6e46":"code","91248156":"code","73388a69":"code","32bd1370":"code","06f772e6":"code","f5b09833":"code","72ae19cb":"code","460acfe4":"code","2d1ccdce":"code","f368478a":"code","6013a8f0":"code","83858cf4":"code","433d3c47":"code","8b6182c1":"code","d0b8244e":"code","ad6a8970":"code","7b44412d":"code","a6b7e3fc":"code","ebcb7951":"code","51c2fc76":"code","d5edca60":"code","70441de0":"code","2947610e":"code","9cda23fa":"code","c5910a4e":"code","6a637c81":"code","43302f63":"code","bad470e7":"code","7822e8b9":"code","e93d35fd":"code","d1585c41":"code","2c712ae1":"code","942fbb3b":"code","dc098af2":"markdown","15cdd1ac":"markdown"},"source":{"4fc29d8b":"from datetime import datetime\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn import metrics\n\nimport warnings\nwarnings.filterwarnings('ignore')","4411f780":"pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', None)\nplt.rcParams['figure.figsize'] = [6, 6]","b567ed3b":"features_to_select = 20","dd329477":"train = pd.read_csv('..\/input\/train.csv')\ntrain.head()","44cc4ea6":"train.Survived.sum()","cc127fe2":"train.Survived.count()","2fa38fac":"train.Survived.mean()","9f1d4eed":"train.info()","150e9411":"train.drop(columns=['Age', 'Cabin'], inplace=True)","e0056781":"train['Title'] = pd.DataFrame(train.Name.str.split(',', expand=True).values, columns=['LN', 'TFN'])\\\n                                 ['TFN'].str.split('.', expand=True)[0].str.strip()","520d5881":"train.Embarked = train.Embarked.fillna('S')","334f2614":"train.info()","5dc142c3":"test = pd.read_csv('..\/input\/test.csv')\ntest.head()","1d678a1f":"test['Title'] = pd.DataFrame(test.Name.str.split(',', expand=True).values, columns=['LN', 'TFN'])\\\n                               ['TFN'].str.split('.', expand=True)[0].str.strip()","8a8afb06":"test.info()","13292534":"test.drop(columns=['Age', 'Cabin'], inplace=True)","2518f715":"test.Fare = test.Fare.fillna(0)","2b5f2dcf":"test.info()","3d159f76":"# adjusting data situation so that columns after dummies match for both train and test sets\ntest.Parch = test.Parch.apply(lambda x: 6 if x == 9 else x)","9c1e6e46":"cat_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title']","91248156":"# train data groups\nprint('Train')\nfor col in cat_features:\n    train[col] = train[col].apply(str)\n    print(train.groupby(col).count()['PassengerId'])\n    print('Train\\n', train.groupby(col).mean()['Survived'])    ","73388a69":"# test data groups\nfor col in cat_features:\n    test[col] = test[col].apply(str)\n    print(test.groupby(col).count()['PassengerId'])","32bd1370":"train = pd.concat([train.Survived, train['Fare'], pd.get_dummies(train[cat_features], drop_first=True)], axis=1)\ntrain.head()","06f772e6":"hold_PassengerID = test['PassengerId']","f5b09833":"test = pd.concat([test['Fare'], pd.get_dummies(test[cat_features], drop_first=True)], axis=1)\ntest.head()","72ae19cb":"train.shape","460acfe4":"test.shape","2d1ccdce":"y_train = train.pop('Survived')\nX_train = sm.add_constant(train)","f368478a":"# run recursive feature selection to pick the recommended fields\nrfe = RFE(LogisticRegression(), features_to_select).fit(X_train, y_train)\ndf_rfe = pd.DataFrame(list(zip(X_train.columns, rfe.support_, rfe.ranking_)), columns=['feature', 'sel_flag', 'sel_rank'])\ndf_rfe[df_rfe.sel_flag].feature","6013a8f0":"def model():\n    logmodel = sm.GLM(y_train, X_train, family=sm.families.Binomial()).fit()\n    print(logmodel.summary())\n    return logmodel\n\ndef validate_model(cutoff, print_flag=False):\n    \n    y_train_pred = round(logmodel.predict(X_train), 6)\n\n    df_result = pd.DataFrame()\n    df_result['Survived_Train'] = y_train\n    df_result['Predicted Probability'] = y_train_pred\n    df_result['Survived'] = y_train_pred.apply(lambda x: 1 if x > cutoff else 0)\n\n    confusion = metrics.confusion_matrix(df_result.Survived_Train, df_result.Survived)\n    accuracy = round(metrics.accuracy_score(df_result.Survived_Train, df_result.Survived), 6)\n    \n    TP = confusion[1,1] # true positive \n    TN = confusion[0,0] # true negatives\n    FP = confusion[0,1] # false positives\n    FN = confusion[1,0] # false negatives\n\n    sensitivity = round(TP \/ float(TP+FN), 6)\n    specificity = round(TN \/ float(TN+FP), 6)\n\n    if print_flag:\n        print('\\nConfusion Matrix')\n        print(confusion)\n        print('\\nAccuracy')\n        print(accuracy)\n        print('\\nSensitivity (TP \/ [TP + FN])')\n        print(sensitivity)\n        print('\\nSpecificity (TN \/ [TN + FP])')\n        print(specificity)\n        \n    return accuracy, sensitivity, specificity\n\ndef find_ideal_cutoff():\n    df_cutoff = pd.DataFrame(columns = ['cutoff','accuracy','sensitivity','specificity'])\n    for cutoff in np.arange(0.0, 1.0, 0.05):\n        cutoff = round(cutoff, 2)\n        accuracy, sensitivity, specificity = validate_model(cutoff)\n        df_cutoff.loc[cutoff] = [cutoff, accuracy, sensitivity, specificity]\n    df_cutoff.plot.line(x='cutoff', y=['accuracy','sensitivity','specificity'], grid=True)\n    plt.grid(b=True, which='minor', linestyle='-')\n    plt.xticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n    plt.yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n    plt.show()\n    \n# create a dataframe that will contain the names of all the feature variables and their respective VIFs\ndef performVIFanalysis():\n    vif = pd.DataFrame()\n    vif['Features'] = X_train.columns\n    vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    print(vif)\n","83858cf4":"X_train = X_train[df_rfe[df_rfe.sel_flag].feature]\nlogmodel = model()","433d3c47":"find_ideal_cutoff()","8b6182c1":"df_hold = pd.DataFrame()","d0b8244e":"df_hold['const'] = X_train.pop('const') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","ad6a8970":"df_hold['Parch_6'] = X_train.pop('Parch_6') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","7b44412d":"df_hold['Title_Don'] = X_train.pop('Title_Don') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","a6b7e3fc":"df_hold['Title_Jonkheer'] = X_train.pop('Title_Jonkheer') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","ebcb7951":"df_hold['SibSp_5'] = X_train.pop('SibSp_5') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","51c2fc76":"df_hold['SibSp_8'] = X_train.pop('SibSp_8') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","d5edca60":"df_hold['Parch_4'] = X_train.pop('Parch_4') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","70441de0":"df_hold['Title_Rev'] = X_train.pop('Title_Rev') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","2947610e":"df_hold['Title_Dr'] = X_train.pop('Title_Dr') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","9cda23fa":"df_hold['Title_Mr'] = X_train.pop('Title_Mr') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","c5910a4e":"df_hold['Sex_male'] = X_train.pop('Sex_male') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","6a637c81":"df_hold['Parch_5'] = X_train.pop('Parch_5') # highest p-value\nlogmodel = model()\nfind_ideal_cutoff()","43302f63":"performVIFanalysis()","bad470e7":"chosen_prob_cutoff = 0.6\nvalidate_model(chosen_prob_cutoff, False)","7822e8b9":"X_test = test[X_train.columns]\ny_test_pred = round(logmodel.predict(X_test), 6)","e93d35fd":"df_out = pd.DataFrame()\ndf_out['PassengerID'] = hold_PassengerID\ndf_out['Survived'] = y_test_pred.apply(lambda x: 1 if x > chosen_prob_cutoff else 0)","d1585c41":"df_out['Survived'].sum()","2c712ae1":"df_out['Survived'].count()","942fbb3b":"df_out['Survived'].mean()","dc098af2":"- Null count in Age column is significant. We can drop this field because Title is a decent proxy.\n- Null count in Embarked column is not significant, just 2. But the field will be useful, so we impute nulls with 'S'.\n- Null count in Cabin column is significant. We can drop this field.","15cdd1ac":"- Null count in Age column is significant. We can drop this field because Title is a decent proxy.\n- Only one record with null in Fare field. We put zero and move on as the field will be useful.\n- Null count in Cabin column is significant. We can drop this column."}}