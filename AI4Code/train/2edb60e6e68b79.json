{"cell_type":{"7260378e":"code","bd8b230e":"code","85b71a2a":"code","bd027116":"code","9266a2e9":"code","1eb81d57":"code","204a0df8":"markdown","679823d9":"markdown","525b760c":"markdown","dc5ed5a7":"markdown","3522cf75":"markdown","c890cfe5":"markdown","a6fbeb0d":"markdown","113fc853":"markdown","b9baaf27":"markdown"},"source":{"7260378e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd8b230e":"from keras.applications.vgg16 import VGG16\nmodel = VGG16(weights='imagenet')\nprint(model.summary())","85b71a2a":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input,decode_predictions\nimport numpy as np\n\nimg_path = '\/kaggle\/input\/images\/dog.jpg'\n#There is an interpolation method to match the source size with the target size\n#image loaded in PIL (Python Imaging Library)\nimg = image.load_img(img_path,color_mode='rgb', target_size=(224, 224))\ndisplay(img)","bd027116":"# Converts a PIL Image to 3D Numy Array\nx = image.img_to_array(img)\nx.shape\n# Adding the fouth dimension, for number of images\nx = np.expand_dims(x, axis=0)","9266a2e9":"#mean centering with respect to Image\nx = preprocess_input(x)\nfeatures = model.predict(x)\np = decode_predictions(features)","1eb81d57":"p","204a0df8":"# What is the VGG Model?","679823d9":"# Loading a sample image","525b760c":"# Resizing to fit into VGGNet","dc5ed5a7":"# Using Pre-Trained model for prediction","3522cf75":"* This is a CNN Model which brought remarkable result in the 2014 ImageNet Challenge\n* Proposed by Karen Simonyan & Andrew Zisserman of Visual Geometry Group (VGG), Oxford University\n* The most striking thing of VGG over AlexNet, it had a relatively smaller Kernel (3 x 3) which was unform across all the layers\n* They have experimented over a set of ConvNet Models and VGG16,VGG19 were the best models","c890cfe5":"![image.png](attachment:image.png)","a6fbeb0d":"# Importing VGG Model","113fc853":"* These are models, which are networks with large number of parameters\n* Generally, training such a network is time and resource consuming\n* The pre-trained models for CV mostly are pretty general purpose too\n* We can use directly use this models, if we pick up any of the 1000 classes it is trained upon\n* Even if it's little bit different, we can remove the top layer and train the weight of that layer only (Transfer Learning)","b9baaf27":"# Why Pre-trained models?"}}