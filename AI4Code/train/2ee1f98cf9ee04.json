{"cell_type":{"c1858665":"code","29cd35a7":"code","3097ec43":"code","c2cd6697":"code","d304cc99":"code","b1503ae1":"code","a53ee5cc":"code","746023fe":"code","1783d892":"code","ebaee0ee":"code","b3a19c6c":"code","26c43882":"markdown","3e9e95e3":"markdown","a5ef89ab":"markdown","e7cac35f":"markdown","f8de1583":"markdown","d5c86ab1":"markdown"},"source":{"c1858665":"import os\nimport cv2\nimport time\nimport math\nimport psutil\nimport multiprocessing\n\nimport numpy as np # linear algebra\nfrom PIL import Image\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","29cd35a7":"print(os.listdir(\"..\/input\"))","3097ec43":"label_df = pd.read_csv('..\/input\/train.csv')\nsubmission_df = pd.read_csv('..\/input\/sample_submission.csv')\nlabel_df.head()","c2cd6697":"label_df['Id'].describe()","d304cc99":"# Display the most frequent ID (without counting new_whale)\nlabel_df['Id'].value_counts()[1:16].plot(kind='bar')","b1503ae1":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 3*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'Image']\n        image_id = df.loc[i,'Id']\n        img = cv2.imread(f'..\/input\/train\/{image_path}')\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n\ndisplay_samples(label_df)","a53ee5cc":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]\/2), math.ceil(pad_diff[0]\/2)\n    l, r = math.floor(pad_diff[1]\/2), math.ceil(pad_diff[1]\/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\ndef pad_and_resize_cv(image_path, dataset, desired_size=224):\n    img = cv2.imread(f'..\/input\/{dataset}\/{image_path}')\n    \n    pad_width = get_pad_width(img, max(img.shape))\n    padded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\n    \n    resized = cv2.resize(padded, (desired_size,)*2).astype('uint8')\n    \n    return resized\n\ndef pad_and_resize_pil(image_path, dataset, desired_size=224):\n    '''Experimental'''\n    im = Image.open(f'..\/input\/{dataset}\/{image_path}')\n    \n    old_size = im.size\n    ratio = float(desired_size)\/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    resized = im.resize(new_size)\n    im_array = np.asarray(resized)\n    \n    pad_width = get_pad_width(im_array, desired_size)\n    padded = np.pad(im_array, pad_width=pad_width, mode='constant', constant_values=0)\n    \n    return padded\n\n\ndef pad_and_resize(image_path, dataset, desired_size=224, mode='cv'):\n    if mode =='pil':\n        return pad_and_resize_pil(image_path, dataset, desired_size)\n    else:\n        return pad_and_resize_cv(image_path, dataset, desired_size)","746023fe":"img = cv2.imread(f'..\/input\/train\/{label_df.loc[0,\"Image\"]}')\n\npad_width = get_pad_width(img, max(img.shape))\npadded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\nresized = cv2.resize(padded, (224,224))\nplt.imshow(resized)","1783d892":"target_dummies = pd.get_dummies(label_df['Id'])\ntrain_label = target_dummies.columns.values\ny_train = target_dummies.values\nprint(y_train.shape)","ebaee0ee":"def process_dataset(dataset):\n    resized_imgs = []\n    \n    if dataset == 'train':\n        dataset_names = label_df[\"Image\"]\n    else:\n        dataset_names = submission_df['Image']\n\n    for image_path in dataset_names:\n        resized_imgs.append(pad_and_resize(image_path, dataset))\n\n    X = np.stack(resized_imgs)\n    return X","b3a19c6c":"start_time = time.time()\n\nwith multiprocessing.Pool(1) as pool: \n    X_train, X_test = pool.map(process_dataset, [\"train\", \"test\"])\n    \nprint(f\"Images loaded in {time.time() - start_time:.2f} sec\")","26c43882":"### Padding process and resizing with OpenCV","3e9e95e3":"## Preprocessing","a5ef89ab":"# Exploring and Preprocessing the input images\n\nThis kernel intends to explore the image dataset, and preprocess them to be 224x224 to match ImageNet, and make it compatible with most architectures in Keras or Tensorflow. The resulting data will be:\n* `X_train`: 25361x224x224x3\n* `X_test`: 7960x224x224x3\n* `y_train`: 25361x5005","e7cac35f":"The width of the image seem to be bigger than the height. We will have to pad the images, then resize them to 224x224x3","f8de1583":"## Exploration","d5c86ab1":"## Pad and resize all the images"}}