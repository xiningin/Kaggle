{"cell_type":{"d12e0713":"code","d108771a":"code","3c710ddf":"code","c5d2cf94":"code","ffacd20a":"code","cd8be75f":"code","f1086901":"code","30418916":"code","9cb87c00":"code","ad873811":"code","2cb29f4d":"code","90f42077":"code","7274cdd5":"code","29a20644":"code","d4c479a1":"code","b9412308":"code","43e83410":"code","fa1808e9":"code","1f39d20e":"code","d4d588bd":"code","9cfc3eaa":"code","7bacc1ae":"code","3bc7edbe":"code","a38c337e":"code","ee811544":"code","0ae55ff0":"code","89d5accc":"code","7a65cdef":"code","8da1806d":"code","e9c9559b":"code","3f2572eb":"code","e336f6b1":"code","daf2fc93":"code","deb0bb0d":"code","c4e74f8a":"code","8674694e":"code","f53de873":"code","5765f0f8":"code","4dad875d":"code","bf5ebbe4":"code","500a875e":"code","1887a169":"code","d7d4183d":"code","38837422":"code","039d31e6":"code","d1275d43":"code","6ecfe2fe":"code","1ba3de6b":"code","b70eb94b":"code","d43fb75e":"code","0da9a3d4":"code","d3257ad6":"code","c0ea2ca2":"code","77ce019c":"code","f2e92f1c":"code","7026de7f":"code","144d3db2":"code","242d1583":"code","248b7cc6":"code","c14c0a99":"code","eee2a81f":"code","97c59966":"code","47db3814":"code","0f82dffc":"code","79a1a28b":"code","1d8470d8":"code","2c22c7c0":"code","53d03993":"code","25e3e262":"code","11f4a621":"code","18338083":"code","3685ed68":"code","7f24e924":"code","4616e93f":"code","fd0812d5":"code","c6538741":"code","f3e78bd2":"code","bbe5fe04":"code","12a4b1dc":"code","4ae95c5a":"code","d3a2986f":"code","b07e79df":"code","d24fbdc1":"code","515414c6":"code","bbe118eb":"code","143368f6":"code","0dee2d72":"code","8c3e23be":"code","5822d9e6":"code","6ff36522":"code","71849150":"code","4306dc24":"code","1c96a109":"code","ee24076e":"code","17ffbdc4":"code","da14b8e5":"code","5a72457c":"code","bfac7e5c":"code","3e0bf4d2":"code","fb60ea9a":"code","342eef56":"code","1da4dff9":"code","465930b2":"code","93ec9bc7":"code","00283962":"code","76374afb":"code","f2fae99b":"code","6632753e":"code","08968941":"code","174a7eae":"code","515eb4b2":"code","3f79e72d":"code","73cdff9b":"code","30f05393":"code","6db0f4cb":"code","eba9504d":"code","c47be9ef":"code","64124490":"code","4274ce44":"code","7c3f43e5":"code","10ecdcc7":"code","2dedd41f":"code","3f44af82":"code","ade5479b":"code","22aef447":"code","07f31eb8":"code","f361c438":"code","ff783fa1":"code","4d782fcf":"code","f5a43766":"code","4b22f7c9":"code","0cf18fd3":"code","8b9826fd":"code","ff456849":"code","558da273":"code","67909717":"code","7915306b":"code","206fc911":"code","e7b903a2":"code","c02a732e":"code","4b34b130":"code","0fbbca20":"code","b8ebe7c4":"code","66ee0473":"code","67b170c9":"code","41e1e5e3":"code","bb34e30c":"code","9210c501":"code","3ff96e9a":"code","efef3674":"code","4f49c5dd":"code","fc77d4b5":"code","bbb84c4a":"code","71850361":"code","5e0c7e9e":"code","8291121c":"code","82ce54ff":"code","52f7af3c":"code","302bb623":"code","747de44f":"code","e5603f7b":"code","c4068e89":"code","8239709f":"code","1653f6b9":"code","49e60a79":"code","d2060b90":"code","ebbda56f":"code","93838c6d":"code","178aedad":"code","c5fbf05c":"code","5c77b10d":"code","93043787":"code","3ad8b946":"code","efc2fa4c":"code","c4544745":"code","a25dc595":"code","cd4fe993":"code","42729a98":"code","98777832":"code","b4c23d7d":"code","a1e4dabf":"code","85883116":"code","e49eb033":"code","3d93eec9":"code","50071b5b":"code","0ad97b75":"code","ac0d6e67":"code","35e1800a":"code","55fc4b90":"code","ee426c8b":"markdown","785a53d8":"markdown","26f9e3cd":"markdown","7201e9f6":"markdown","755b97f1":"markdown","65811d78":"markdown","92be980d":"markdown","be97b1bb":"markdown","310820cc":"markdown","1d7509ac":"markdown","a0b4d68c":"markdown","c4fbf436":"markdown","56f8a1f0":"markdown","adf7f158":"markdown","f4c4b392":"markdown","9dea28fb":"markdown","f376a7c2":"markdown","e7f7be00":"markdown","90a1e8f8":"markdown","928a509a":"markdown","c17b1b55":"markdown","f07856ef":"markdown","7d3a19ab":"markdown","4c4e43a9":"markdown","514723d1":"markdown","b63cb890":"markdown","fdf6e9df":"markdown","0d135c59":"markdown","4a05aece":"markdown","9cffb579":"markdown","77a84a4e":"markdown","207c49a7":"markdown","fc22ae22":"markdown","373f25a4":"markdown","1de94786":"markdown","1134af6c":"markdown","a8edd738":"markdown","88ecce44":"markdown","7c3ed7df":"markdown","281f0704":"markdown","227f6d77":"markdown","926721bf":"markdown","48d19f1a":"markdown","5510086b":"markdown","2f68869c":"markdown","dad94e8a":"markdown","234744b0":"markdown","c5e6d082":"markdown","502905b8":"markdown","b2c84e72":"markdown","712cb10c":"markdown","c54f1480":"markdown","595bf492":"markdown","c3183ba2":"markdown","4b46fa1e":"markdown","f692d00b":"markdown","909834dd":"markdown","07ac50fb":"markdown","2a829354":"markdown","015c21f8":"markdown","22a7f42d":"markdown","d7426a8e":"markdown","75bca9a6":"markdown","cfe4b5be":"markdown","14f268e7":"markdown","070c3054":"markdown","ad5ec59f":"markdown","84a65fdb":"markdown","3a79c3aa":"markdown","15958fcd":"markdown","b8c92803":"markdown","67e00555":"markdown","9536ca34":"markdown","ce207221":"markdown","fe4cfc9d":"markdown","14de1ed2":"markdown","c167e9a4":"markdown","d3e85011":"markdown","ec2bc166":"markdown","e903d007":"markdown","fdabcacd":"markdown","e2addff1":"markdown","b9ea8d2b":"markdown","f01f56ce":"markdown","cdb873ae":"markdown","811e3135":"markdown","5ec49f2c":"markdown","1f003250":"markdown","242c5896":"markdown","eb0ecfc2":"markdown","419da071":"markdown","ea8a6db1":"markdown","eadf7bb5":"markdown","edeea5f3":"markdown","27caae1e":"markdown","bf7b53e2":"markdown","438139ff":"markdown","14bb3c44":"markdown","b07d9c8d":"markdown","b49a2e31":"markdown","dbe73421":"markdown","0d1ad55c":"markdown","0848c0ee":"markdown","4a2ef99e":"markdown","0d72ef0d":"markdown","778689bf":"markdown","67fcf660":"markdown","ca255d7d":"markdown","713eda70":"markdown","fe2cf9f1":"markdown","4df4b58b":"markdown","97176cbf":"markdown","785100dd":"markdown","e173fc05":"markdown","9480fe09":"markdown","7d810592":"markdown","9cce25f3":"markdown","aa526fc1":"markdown","cbab5d23":"markdown","5dd0e247":"markdown","e848c9e3":"markdown","65c04f01":"markdown","9168eac5":"markdown","da4ae7f0":"markdown","c0749872":"markdown","8f244d34":"markdown","9660d53b":"markdown","b9d2c156":"markdown","45061923":"markdown"},"source":{"d12e0713":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","d108771a":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport missingno as msno\n\n# visulaisation\nfrom matplotlib.pyplot import xticks\n%matplotlib inline\nimport itertools\nimport copy\n\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn import metrics\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import precision_recall_curve","3c710ddf":"# Data display customization\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)","c5d2cf94":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ffacd20a":"# Importing Leads.csv\nLeaddata = pd.read_csv('\/kaggle\/input\/lead-scoring\/Leads.csv')\nLeaddata.head()","cd8be75f":"Data_dict = pd.read_excel(\"\/kaggle\/input\/lead-scoring\/Leads Data Dictionary.xlsx\",sheet_name= 'Sheet1', header= [1] ,skiprows = [0],  usecols=lambda x: 'Unnamed' not in x)\nData_dict","f1086901":"# To check the rows and columns of the data\n#Shape of dataset\nprint(\"There are {} countries and {} features: \".format(Leaddata.shape[0],Leaddata.shape[1]))","30418916":"# to check data type\nLeaddata.info()","9cb87c00":"# to get the basic statistics of the numerical column\n# Checking outliers at 1%, 5%, 10%, 25%,50%,75%,90%,95% and 99%\nLeaddata.describe(percentiles=[.01,.05,.1,.25,.5,.75,.90,.95,.99])","ad873811":"#checking duplicates\nsum(Leaddata.duplicated(subset = 'Prospect ID')) == 0","2cb29f4d":"#check for duplicates\nsum(Leaddata.duplicated(subset = 'Lead Number')) == 0","90f42077":"#dropping Lead Number since they have all unique values\nLeaddata.drop(['Lead Number'], 1, inplace = True)","7274cdd5":"# Calculating the Missing Values % contribution in DF\ndisplay(round(100*(Leaddata.isnull().sum()\/len(Leaddata.index)), 2))","29a20644":"# Plotting Null Count\nmsno.bar(Leaddata)\nplt.show()","d4c479a1":"# Percentage of Missing values in Lead data\nsns.set(style=\"whitegrid\")\nfig = plt.figure(figsize=(12,5))\nmissing = pd.DataFrame((Leaddata.isnull().sum())*100\/Leaddata.shape[0]).reset_index()\nmissing[\"type\"] = \"Lead Data\"\nax = sns.pointplot(\"index\",0,data=missing,hue=\"type\", palette=\"Set2\")\nplt.xticks(rotation =90,fontsize =12)\nplt.title(\"Percentage of Missing values in Lead data\",fontsize =14)\nplt.ylabel(\"Percentage of Missing values\",fontsize =14)\nplt.xlabel(\"Column Name\",fontsize =14)\nplt.show()","b9412308":"# Converting 'Select' values to NaN.\nLeaddata = Leaddata.replace('Select', np.nan)","43e83410":"#check null values again\ndisplay(round(100*(Leaddata.isnull().sum()\/len(Leaddata.index)), 2))","fa1808e9":"#Percentage of Missing values in application data\nfig = plt.figure(figsize=(12,5))\nmissing = pd.DataFrame((Leaddata.isnull().sum())*100\/Leaddata.shape[0]).reset_index()\nmissing[\"type\"] = \"Lead Data\"\nax = sns.pointplot(\"index\",0,data=missing,hue=\"type\", palette=\"Set2\")\nplt.xticks(rotation =90,fontsize =12)\nplt.title(\"Percentage of Missing values in Lead data\",fontsize =14)\nplt.ylabel(\"Percentage of Missing values\",fontsize =14)\nplt.xlabel(\"Column Name\", fontsize =14)\nplt.show()","1f39d20e":"# columns having more than 70 % of null values are actually useless , so for such columns , we will get rid of the column itself\nLeaddata = Leaddata.drop(Leaddata.loc[:,list(round(100*(Leaddata.isnull().sum()\/len(Leaddata.index)), 2)>50)].columns, 1)","d4d588bd":"#check null values again\ndisplay(round(100*(Leaddata.isnull().sum()\/len(Leaddata.index)), 2))","9cfc3eaa":"def countPlot(col_name, x = None):\n    ap = sns.countplot(x= col_name, data = Leaddata, palette=\"Set2\", hue = x )\n    for p in ap.patches:\n        ap.annotate('{:1.2f}%'.format((p.get_height()*100)\/float(len(Leaddata[col_name]))), \n                (p.get_x()+0.05, p.get_height()+20), size =12) ","7bacc1ae":"def valueCount(df):\n    for i in df:\n        print('Column \\\"' +i+ '\\\" value counts\\n')\n        print(df[i].value_counts(ascending=False,normalize=True), '\\n\\n')","3bc7edbe":"# Count Plot before Imputing the values\n#sns.set(style=\"white\")\nplt.figure(figsize =(15,4))\nplt.subplot(121)\ncountPlot('What matters most to you in choosing a course')\nxticks(rotation = 45)\nplt.subplot(122)\ncountPlot('What is your current occupation')\nxticks(rotation = 45)\nplt.show()","a38c337e":"null_col = Leaddata[['City', 'Specialization']]\nvalueCount(null_col) ","ee811544":"#impute 'Mumbai' in column 'City'\nLeaddata['City'] = Leaddata['City'].replace(np.nan, 'Mumbai')","0ae55ff0":"# So Let's make a category \"Others\" for missing values.\nLeaddata['Specialization'] = Leaddata['Specialization'].replace(np.nan, 'Not Specified')","89d5accc":"#combining Management Specializations \nLeaddata['Specialization'] = Leaddata['Specialization'].replace(['Finance Management','Human Resource Management',\n                                                           'Marketing Management','Operations Management',\n                                                           'IT Projects Management','Supply Chain Management',\n                                                    'Healthcare Management','Hospitality Management',\n                                                           'Retail Management'] ,'Management_Specializations')","7a65cdef":"Leaddata['Specialization'] = Leaddata['Specialization'].replace(['Services Excellence','E-Business',\n                                                                'Rural and Agribusiness','E-COMMERCE',] ,\n                                                                'Other Specilization')","8da1806d":"# Count Plot After Imputing the values\n#sns.set(style=\"white\")\nplt.figure(figsize =(15,4))\nplt.subplot(121)\ncountPlot('Specialization')\nxticks(rotation = 90)\nplt.subplot(122)\ncountPlot('City')\nxticks(rotation = 90)\nplt.show()","e9c9559b":"null_col = Leaddata[['What matters most to you in choosing a course','What is your current occupation']]\nvalueCount(null_col) ","3f2572eb":"# Impute Missing Values\nLeaddata['What is your current occupation'] = Leaddata['What is your current occupation'].replace(np.nan, 'Unemployed')","e336f6b1":"plt.figure(figsize =(15,4))\nsns.countplot(Leaddata['Country'],palette=\"Set2\")\nxticks(rotation = 90)\nplt.show()","daf2fc93":"#Leaddata[\"Country\"].value_counts(normalize=True)\nnull_col = Leaddata[[\"Country\"]]\nvalueCount(null_col)","deb0bb0d":"Leaddata.drop([ 'Country','What matters most to you in choosing a course','Tags',\n                'Asymmetrique Activity Index','Asymmetrique Activity Score',\n                'Asymmetrique Profile Index','Asymmetrique Profile Score'],\n                axis =1, inplace= True)","c4e74f8a":"# drop rows containing missing values\nLeaddata.dropna(inplace = True)","8674694e":"#check null values again\ndisplay(round(100*(Leaddata.isnull().sum()\/len(Leaddata.index)), 2))","f53de873":"# Plotting Null Count\nmsno.bar(Leaddata)\nplt.show()","5765f0f8":"# Code to check outliers for numerical columns based on boxplot\nnumerical = ['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']\nplt.figure(figsize =(15,5))\nfor i in enumerate(numerical):\n    plt.subplot(1,3, i[0]+1)\n    sns.boxplot(x= i[1], data = Leaddata,palette=\"Set2\",orient = 'v')","4dad875d":"# Check the distribution of Numerical columns\nnumerical = ['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']\nplt.figure(figsize =(15,5))\nfor i in enumerate(numerical):\n    plt.subplot(1,3, i[0]+1)\n    sns.violinplot(x= i[1], data = Leaddata,palette=\"Set2\",scale=\"count\", inner=\"quartile\", orient = 'v')","bf5ebbe4":"#Dist Plot for each Numerical Variables\na = ['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']\nfig = plt.figure(figsize =(15,5))\nfor i,j in itertools.zip_longest(a, range(len(a))):\n    plt.subplot(1,3,j+1)\n    ax = sns.distplot(Leaddata[i])","500a875e":"Leaddata.info()","1887a169":"# Converting datatype of categorical columns to object type from int\/float\n#Leaddata['Lead Number'] = Leaddata['Lead Number'].astype(object)\nLeaddata['Converted'] = Leaddata['Converted'].astype(object)","d7d4183d":"# to get the basic statistics of the numerical column\n# Checking outliers at 1%, 5%, 10%, 25%,50%,75%,90%,95% and 99%\nLeaddata.describe(percentiles=[.01,.05,.1,.25,.5,.75,.90,.95,.99])","38837422":"TotalVisits_q4 = Leaddata['TotalVisits'].quantile(0.99)\nTimeSpent_q4 = Leaddata['Total Time Spent on Website'].quantile(0.99)\nPageViews_q4 = Leaddata['Page Views Per Visit'].quantile(0.99)\n\nLeaddata['TotalVisits'][Leaddata['TotalVisits']>= TotalVisits_q4] = TotalVisits_q4\nLeaddata['Total Time Spent on Website'][Leaddata['Total Time Spent on Website']>= TimeSpent_q4] = TimeSpent_q4\nLeaddata['Page Views Per Visit'][Leaddata['Page Views Per Visit']>= PageViews_q4] = PageViews_q4","039d31e6":"Converted = (sum(Leaddata['Converted'])\/len(Leaddata['Converted'].index))*100\nConverted","d1275d43":"def pie_plot(column_name):\n    Leaddata[column_name].value_counts().plot.pie(autopct = \"%1.2f%%\",colors = sns.color_palette(\"Set2\",7),\n                            startangle = 60,labels=[\"No\",\"Yes\"],\n                            wedgeprops={\"linewidth\":2,\"edgecolor\":\"k\"},explode=[.1,0],shadow =True)\n    plt.title(\"Distribution of \"+column_name+\" \" , size = 12)\n    ","6ecfe2fe":"# Plot Distribution of Target variable\nplt.figure(figsize=(15,5))\nplt.subplot(121)\nap = sns.countplot(x= 'Converted', data = Leaddata,palette=\"Set2\")\nfor p in ap.patches:\n    ap.annotate('{:1.1f}%'.format((p.get_height()*100)\/float(len(Leaddata[\"Converted\"]))), (p.get_x()+0.05, p.get_height()+20))  \nplt.xticks(size = 16)\nplt.ylabel('converted' , size =16)\nplt.yticks(size = 16)\nplt.xlabel('count' , size =16)\nplt.title(\"How many Leads are Converted\", size =16)\nplt.subplot(122)\npie_plot(\"Converted\")\nplt.title(\"Distribution of Converted Leads\", size =16)\nplt.show()","1ba3de6b":"null_col = Leaddata[[\"Newspaper Article\",\"X Education Forums\",\"Newspaper\",\"Search\",\n\"Digital Advertisement\",\"Through Recommendations\",\"Do Not Email\",\"Do Not Call\"]]\nvalueCount(null_col) ","b70eb94b":"columns = [\"Newspaper Article\",\"X Education Forums\",\"Newspaper\", \"Search\",\n\"Digital Advertisement\",\"Through Recommendations\",\"Do Not Email\",\"Do Not Call\"] \nplt.figure(figsize=(15,8))\ni = 1\nfor A in columns:\n    plt.subplot(2,4,i)\n    pie_plot(A)\n    i= i+1","d43fb75e":"def pie_plot_2(column_name):\n    Leaddata[column_name].value_counts().plot.pie(autopct = \"%1.2f%%\",colors = sns.color_palette(\"Set2\",7),\n                            startangle = 60,labels=[\"No\"],\n                            wedgeprops={\"linewidth\":2,\"edgecolor\":\"k\"},shadow =True)\n    #plt.title(\"Distribution of \"+column_name+\" \" , size = 12)\n    ","0da9a3d4":"null_col = Leaddata[[\"I agree to pay the amount through cheque\",\n                     \"Get updates on DM Content\",\n                     \"Update me on Supply Chain Content\",\n                     \"Receive More Updates About Our Courses\"]]\nvalueCount(null_col) ","d3257ad6":"columns = [ \"I agree to pay the amount through cheque\",\n            \"Get updates on DM Content\",\"Magazine\",\n            \"Update me on Supply Chain Content\",\n            \"Receive More Updates About Our Courses\"] \nplt.figure(figsize=(15,5))\ni = 1\nfor A in columns:\n    plt.subplot(1,5,i)\n    pie_plot_2(A)\n    i= i+1","c0ea2ca2":"null_col = Leaddata[[\"Lead Origin\",\"What is your current occupation\",\"City\",\n                     \"A free copy of Mastering The Interview\"]]\nvalueCount(null_col) ","77ce019c":"categorical1 = [\"Lead Origin\",\"What is your current occupation\"]\nplt.figure(figsize=(15,4))\ni = 1\nfor A in categorical1:\n    plt.subplot(1,2,i)\n    countPlot(A)\n    i= i+1\n    xticks(rotation = 90)","f2e92f1c":"categorical2 = [\"City\",\"A free copy of Mastering The Interview\"]\nplt.figure(figsize=(15,4))\ni = 1\nfor A in categorical2:\n    plt.subplot(1,2,i)\n    countPlot(A)\n    i= i+1\n    xticks(rotation = 45)","7026de7f":"Leaddata[\"Lead Source\"].value_counts(normalize=True)\n# This variable looks useful","144d3db2":"#replacing 'google' with 'Google' and combining low frequency values\nLeaddata['Lead Source'] = Leaddata['Lead Source'].replace('google','Google')\nLeaddata['Lead Source'] = Leaddata['Lead Source'].replace(['Welingak Website', 'Referral Sites', 'Facebook',\n                                                           'bing','Click2call','Social Media','Press_Release',\n                                                           'Live Chat','WeLearn','testone','NC_EDM','welearnblog_Home',\n                                                           'blog','youtubechannel','Pay per Click Ads'] ,'Others')                                                   ","242d1583":"Leaddata[\"Last Notable Activity\"].value_counts(normalize=True)\n# This column looks useful","248b7cc6":"Leaddata['Last Notable Activity'] = Leaddata['Last Notable Activity'].replace(['View in browser link Clicked', \n                                                                               'Approached upfront', 'Resubscribed to emails',\n                                                                               'Email Received','Form Submitted on Website',\n                                                                              'Email Marked Spam','Had a Phone Conversation',\n                                                                              'Unreachable','Unsubscribed',\n                                                                              'Email Bounced','Email Link Clicked'] ,'Other Notable Activity')                                                   ","c14c0a99":"plt.figure(figsize=(15,4))\nplt.subplot(121)\ncountPlot(\"Lead Source\")\nxticks(rotation = 45)\nplt.subplot(122)\ncountPlot(\"Last Notable Activity\")\nxticks(rotation = 45)\nplt.show()","eee2a81f":"Leaddata[\"Last Activity\"].value_counts(normalize=True)","97c59966":"Leaddata.drop([ \"Newspaper Article\",\"X Education Forums\",\"Newspaper\", \"Search\",\n                \"Digital Advertisement\",\"Through Recommendations\",\"Do Not Email\",\n                \"Do Not Call\",\"I agree to pay the amount through cheque\",\n                \"Get updates on DM Content\",\"Magazine\",\"Last Activity\",\n                \"Update me on Supply Chain Content\",\n                \"Receive More Updates About Our Courses\"],\n                axis =1, inplace= True)","47db3814":"Leaddata.shape","0f82dffc":"Leaddata.head()","79a1a28b":"def countPlot2(col_name, x = None):\n    ax = sns.countplot(x= col_name, data = Leaddata, palette=\"Set2\", hue = x )","1d8470d8":"Leaddata.columns","2c22c7c0":"plt.figure(figsize=(15,4))\nplt.subplot(131)\nsns.boxplot(x='Converted', y='TotalVisits', data=Leaddata, palette=\"Set2\")\nplt.subplot(132)\nsns.boxplot(x='Converted', y='Total Time Spent on Website', data=Leaddata, palette=\"Set2\")\nplt.subplot(133)\nsns.boxplot(x='Converted', y='Page Views Per Visit', data=Leaddata, palette=\"Set2\")\nplt.show()","53d03993":"sns.set(style = 'white')\nfig = plt.figure(figsize =(20,20))\nsns.pairplot(data=Leaddata,diag_kind='kde',corner = True,\n             vars=['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit'],hue='Converted',palette=\"husl\")\nplt.show()","25e3e262":"# 'Lead Source', 'Converted',\nplt.figure(figsize=(12,5))\ncountPlot2(\"Lead Origin\",\"Converted\" )\nplt.show()","11f4a621":"plt.figure(figsize=(12,5))\ncountPlot2(\"Lead Source\",\"Converted\" )\nxticks(rotation = 45)\nplt.show()","18338083":"plt.figure(figsize=(12,5))\ncountPlot2(\"Specialization\",\"Converted\" )\nxticks(rotation = 45)\nplt.show()","3685ed68":"plt.figure(figsize=(12,5))\ncountPlot2(\"What is your current occupation\",\"Converted\" )\nxticks(rotation = 45)\nplt.show()","7f24e924":"plt.figure(figsize=(12,5))\ncountPlot2(\"City\",\"Converted\" )\nxticks(rotation = 45)\nplt.show()","4616e93f":"plt.figure(figsize=(12,5))\ncountPlot2(\"Last Notable Activity\",\"Converted\" )\nxticks(rotation = 45)\nplt.show()","fd0812d5":"plt.figure(figsize=(12,5))\ncountPlot2(\"A free copy of Mastering The Interview\",\"Converted\" )\nxticks(rotation = 45)\nplt.show()","c6538741":"var = [\"A free copy of Mastering The Interview\"]\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the housing list\nLeaddata[var] = Leaddata[var].apply(binary_map)","f3e78bd2":"Leaddata.head()","bbe5fe04":"Leaddata.columns","12a4b1dc":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndata = pd.get_dummies(data = Leaddata , columns=['Lead Origin', 'Lead Source', \n       'Specialization', 'What is your current occupation', 'A free copy of Mastering The Interview',\n       'City', 'Last Notable Activity'], drop_first=True)\ndata.head()","4ae95c5a":"data.shape","d3a2986f":"data = data.set_index('Prospect ID')","b07e79df":"# Putting feature variable to X\nX = data.drop(['Converted'], axis=1)","d24fbdc1":"X.head()","515414c6":"# Putting response variable to y\ny = data['Converted']\n\ny.head()","bbe118eb":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=333)","143368f6":"X_train.shape","0dee2d72":"X_test.shape","8c3e23be":"y_train.shape","5822d9e6":"y_train.dtype","6ff36522":"y_train = y_train.astype(float)","71849150":"y_train.dtype","4306dc24":"X_train.info()","1c96a109":"X_test.info()","ee24076e":"y_test.dtype","17ffbdc4":"y_test = y_test.astype(float)","da14b8e5":"y_test.dtype","5a72457c":"y_test.shape","bfac7e5c":"scaler = StandardScaler()\nX_train[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']] = scaler.fit_transform(X_train[['TotalVisits',\n                                                                                                              'Total Time Spent on Website','Page Views Per Visit']])\nX_train.head()","3e0bf4d2":"# Checking the Churn Rate\nConverted = (sum(data['Converted'])\/len(data['Converted'].index))*100\nConverted","fb60ea9a":"logreg = LogisticRegression()\nrfe = RFE(logreg, 18)             # running RFE with 18 variables as output\nrfe = rfe.fit(X_train, y_train)","342eef56":"rfe.support_","1da4dff9":"list(zip(X_train.columns, rfe.support_, rfe.ranking_))","465930b2":"# List of variables to be considered for model building\ncol1 = X_train.columns[rfe.support_]\ncol1","93ec9bc7":"# List of variables to be removed from data set\nX_train.columns[~rfe.support_]","00283962":"X_train_sm = sm.add_constant(X_train[col1])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","76374afb":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\ndef vif_show(X_vif):\n    vif = pd.DataFrame()\n    vif['Features'] = X_vif.columns\n    vif['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    print(vif)","f2fae99b":"vif_show(X_train[col1])","6632753e":"col2 = col1.drop('What is your current occupation_Housewife',1)","08968941":"col2","174a7eae":"X_train_sm = sm.add_constant(X_train[col2])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","515eb4b2":"vif_show(X_train[col2])","3f79e72d":"col3 = col2.drop('Lead Source_Others',1)","73cdff9b":"col3","30f05393":"X_train_sm = sm.add_constant(X_train[col3])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","6db0f4cb":"vif_show(X_train[col3])","eba9504d":"col4 = col3.drop('What is your current occupation_Unemployed',1)","c47be9ef":"col4","64124490":"X_train_sm = sm.add_constant(X_train[col4])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","4274ce44":"vif_show(X_train[col4])","7c3f43e5":"col5 = col4.drop('What is your current occupation_Student',1)","10ecdcc7":"col5","2dedd41f":"X_train_sm = sm.add_constant(X_train[col5])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","3f44af82":"vif_show(X_train[col5])","ade5479b":"col6 = col5.drop('Specialization_Media and Advertising',1)","22aef447":"col6","07f31eb8":"X_train_sm = sm.add_constant(X_train[col6])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","f361c438":"vif_show(X_train[col6])","ff783fa1":"col7 = col6.drop('Lead Origin_Lead Import',1)","4d782fcf":"col7","f5a43766":"X_train_sm = sm.add_constant(X_train[col7])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","4b22f7c9":"vif_show(X_train[col7])","0cf18fd3":"col8 = col7.drop('Last Notable Activity_Page Visited on Website',1)","8b9826fd":"col8","ff456849":"X_train_sm = sm.add_constant(X_train[col8])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","558da273":"vif_show(X_train[col8])","67909717":"# Getting the predicted values on the train set\ny_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]","7915306b":"y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_prob':y_train_pred})\ny_train_pred_final.head()","206fc911":"y_train_pred_final['predicted'] = y_train_pred_final.Converted_prob.map(lambda x: 1 if x > 0.5 else 0)\n# Let's see the head\ny_train_pred_final.head()","e7b903a2":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\nprint(confusion)","c02a732e":"# Let's check the overall accuracy.\naccuracy_train = metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted)\nprint(\"Train Data Accuracy: \" +str(round(accuracy_train,4)))","4b34b130":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","0fbbca20":"# Calculate sensitivity of our logistic regression model\nsensitivity_train = TP \/ float(TP+FN)\n# Let us calculate specificity\nspecificity_train = TN \/ float(TN+FP)\n# Calculate false postive rate - predicting churn when customer does not have churned\nfpRate_train =  FP\/ float(TN+FP)\n# positive predictive value \npositive_predictive_train = TP \/ float(TP+FP)\n# Negative predictive value\nngRate_train = TN \/ float(TN+ FN)","b8ebe7c4":"print(\"Printing all values before optimal cut-off calculation\\n\")\nprint(\"Train Data Accuracy:            {} \".format(round(accuracy_train,4)))\nprint(\"Train Data Specificity:         {} \".format(round(sensitivity_train,4)))\nprint(\"Train Data Sensitivity:         {} \".format(round(specificity_train,4)))\nprint(\"Train Data False postive rate:  {} \".format(round(fpRate_train,4)))\nprint(\"Train Data Positive predictive: {} \".format(round(positive_predictive_train,4)))\nprint(\"Train Data Negative predictive: {} \".format(round(ngRate_train,4)))","66ee0473":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","67b170c9":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Converted_prob, drop_intermediate = False )\ndraw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_prob)","41e1e5e3":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Converted_prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","bb34e30c":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","9210c501":"# Let's plot accuracy sensitivity and specificity for various probabilities.\nsns.set(style='whitegrid')\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","3ff96e9a":"y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_prob.map( lambda x: 1 if x > 0.35 else 0)\ny_train_pred_final.head()","efef3674":"y_train_pred_final['Lead_Score'] = y_train_pred_final.Converted_prob.map( lambda x: round((x*100),2))\ny_train_pred_final.head()","4f49c5dd":"# Let's check the overall accuracy.\naccuracy_train = metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)","fc77d4b5":"confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\nconfusion2","bbb84c4a":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","71850361":"# Calculate sensitivity of our logistic regression model\nsensitivity_train = TP \/ float(TP+FN)\n#calculate specificity\nspecificity_train = TN \/ float(TN+FP)\n# Calculate false postive rate - predicting churn when customer does not have churned\nfpRate_train = FP\/ float(TN+FP)\n# Positive predictive value \npositive_predictive_train = TP \/ float(TP+FP)\n# Negative predictive value\nngRate_train = TN \/ float(TN+ FN)","5e0c7e9e":"print(\"Printing all values post optimal cut-off calculation\\n\")\nprint(\"Train Data Accuracy:            {} \".format(round(accuracy_train,4)))\nprint(\"Train Data Specificity:         {} \".format(round(sensitivity_train,4)))\nprint(\"Train Data Sensitivity:         {} \".format(round(specificity_train,4)))\nprint(\"Train Data False postive rate:  {} \".format(round(fpRate_train,4)))\nprint(\"Train Data Positive predictive: {} \".format(round(positive_predictive_train,4)))\nprint(\"Train Data Negative predictive: {} \".format(round(ngRate_train,4)))","8291121c":"confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted)\nconfusion","82ce54ff":"# Precision\nconfusion[1,1]\/(confusion[0,1]+confusion[1,1])","52f7af3c":"# Recall\nconfusion[1,1]\/(confusion[1,0]+confusion[1,1])","302bb623":"# Calculate Recall\nrecall_train = recall_score(y_train_pred_final.Converted, y_train_pred_final.predicted)\n# Calculate Precision\nprecision_train = precision_score(y_train_pred_final.Converted , y_train_pred_final.predicted)\n# Calculate F1 Score\nF1_score_train =  (2* precision_train * recall_train)\/(precision_train + recall_train)","747de44f":"print(\"Printing all values post optimal cut-off calculation\\n\")\nprint(\"Train Data Precision:    {} \".format(round(precision_train,4)))\nprint(\"Train Data Recall:       {} \".format(round(recall_train,4)))\nprint(\"Train Data F1 Score:     {} \".format(round(F1_score_train,4)))","e5603f7b":"p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_prob)","c4068e89":"plt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.show()","8239709f":"#Preparing Test Dataset\nX_test[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']] = scaler.fit_transform(X_test[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']])\n\nX_train.head()","1653f6b9":"X_test = X_test[col8]\nX_test.head()","49e60a79":"X_test_sm = sm.add_constant(X_test)","d2060b90":"X_test_sm.shape","ebbda56f":"y_test_pred = res.predict(X_test_sm)","93838c6d":"y_test_pred[:10]","178aedad":"y_test.shape","c5fbf05c":"y_test_pred.shape","5c77b10d":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)\ny_pred_final_temp = pd.DataFrame(y_test_pred)\ny_pred_final = pd.merge(y_test_df,y_pred_final_temp,on='Prospect ID')\n# Appending y_test_df and y_pred_1\ny_pred_final.head()","93043787":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_prob'})","3ad8b946":"y_pred_final.head()","efc2fa4c":"y_pred_final['final_predicted'] = y_pred_final.Converted_prob.map(lambda x: 1 if x > 0.35 else 0)\ny_pred_final.head()","c4544745":"# Let's check the overall accuracy.\naccuracy_test = metrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_predicted)","a25dc595":"confusion2 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted )\nconfusion2","cd4fe993":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","42729a98":"# Let's see the sensitivity of our logistic regression model\nsensitivity_test = TP \/ float(TP+FN)\n\n# Let us calculate specificity\nspecificity_test = TN \/ float(TN+FP)","98777832":"print(\"Printing Accuracy, Specificity and Sensitivity of test data \\n\")\nprint(\"Test Data Accuracy:            {} \".format(round(accuracy_test,4)))\nprint(\"Test Data Specificity:         {} \".format(round(sensitivity_test,4)))\nprint(\"Test Data Sensitivity:         {} \".format(round(specificity_test,4)))","b4c23d7d":"# Assigning Lead Score\ny_pred_final['Lead_Score'] = y_pred_final.Converted_prob.map( lambda x: round((x*100),2))\ny_pred_final.head(10)","a1e4dabf":"confusion = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted )\nconfusion","85883116":"# Precision\nconfusion[1,1]\/(confusion[0,1]+confusion[1,1])","e49eb033":"# Recall\nconfusion[1,1]\/(confusion[1,0]+confusion[1,1])","3d93eec9":"recall_test = recall_score(y_pred_final.Converted, y_pred_final.final_predicted )\nprecision_test = precision_score(y_pred_final.Converted, y_pred_final.final_predicted )\nF1_score_test =  (2* precision_test * recall_test)\/(precision_test + recall_test)","50071b5b":"print(\"Printing Precision and Recall of test data\\n\")\nprint(\"Test Data Precision:    {} \".format(round(precision_test,4)))\nprint(\"Test Data Recall:       {} \".format(round(recall_test,4)))\nprint(\"Test Data F1 Score:     {} \".format(round(F1_score_test,4)))","0ad97b75":"print(\"Printing Results of Train Data\\n\")\nprint(\"Train Data Accuracy:     {} \".format(round(accuracy_train,4)))\nprint(\"Train Data Specificity:  {} \".format(round(sensitivity_train,4)))\nprint(\"Train Data Sensitivity:  {} \".format(round(specificity_train,4)))\nprint(\"Train Data Precision:    {} \".format(round(precision_train,4)))\nprint(\"Train Data Recall:       {} \".format(round(recall_train,4)))\nprint(\"Train Data F1 Score:     {} \".format(round(F1_score_train,4)))","ac0d6e67":"Lead_train = y_train_pred_final.copy()\nLead_train.drop([\"Converted\",\"Converted_prob\",\"predicted\",0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, \n                 \"final_predicted\"], 1, inplace = True)\nLead_train.reset_index(inplace=True)\nLead_train.sort_values(by=[\"Lead_Score\"], inplace=True, ascending=False)\nLead_train.head()","35e1800a":"print(\"Printing Results of Test Data \\n\")\nprint(\"Test Data Accuracy:     {} \".format(round(accuracy_test,4)))\nprint(\"Test Data Specificity:  {} \".format(round(sensitivity_test,4)))\nprint(\"Test Data Sensitivity:  {} \".format(round(specificity_test,4)))\nprint(\"Test Data Precision:    {} \".format(round(precision_test,4)))\nprint(\"Test Data Recall:       {} \".format(round(recall_test,4)))\nprint(\"Test Data F1 Score:     {} \".format(round(F1_score_test,4)))","55fc4b90":"Lead_test = y_pred_final.copy()\nLead_test.drop(['Converted', 'Converted_prob', 'final_predicted'], 1, inplace = True)\nLead_test.reset_index(inplace=True)\nLead_test.sort_values(by=['Lead_Score'], inplace=True, ascending=False)\nLead_test.head()","ee426c8b":"## Precision and Recall","785a53d8":"### Categorical Columns\n- Bar Plot for each caterogical column\n- Bar Plot for each caterogical column w.r.t target column i.e \"Converted\"","26f9e3cd":"### Model No 7\nUsing 12 variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_Page Visited on Website<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","7201e9f6":"**Indicates No duplicate values in Prospect ID**","755b97f1":"### Shape of Dataset","65811d78":"#### Last Notable Activity\n- We can group some of the lower frequency occuring labels under a common label 'Others'","92be980d":"**Looking at the p-values, it looks like some variables aren't really significant, in the presence of other variables**\n\n- What is your current occupation_Student\n- Specialization_Media and Advertising\t","be97b1bb":"### Feature Selection Using RFE","310820cc":"## Data Preperation","1d7509ac":"### Dist Plot for each Numerical Variables","a0b4d68c":"### Model No 8\nUsing 11 variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","c4fbf436":"### Describe Numerical Columns","56f8a1f0":"# Exploratory Data Analytics\n- Univariate Analysis\n- Bivariate Analysis\n- Multivariate Analysis","adf7f158":"### Model No 6\nUsing 13 variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Origin_Lead Import<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_Page Visited on Website<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","f4c4b392":"### NULL value Treatment","9dea28fb":"#### Inference:\n#### What matters most to you in choosing this course\n- We can see that 99 % of them has filled better career prospects\n- Column is highly skewed , we can drop this column\n\n#### What is your current occupation\n- Almost 86% entries are of Unemployed so we can impute \"Unemployed\" in the null columns, so we can definitely impute mising values as \"Unemployed\"","f376a7c2":"**The P-value of 'Lead Source_Others' is very high, so removing it from dataset.**","e7f7be00":"### Getting the predicted values on the train set","90a1e8f8":"### I agree to pay the amount through cheque\n- Indicates whether the customer has agreed to pay the amount through cheque or not.\n\n### Get updates on DM Content\n- Indicates whether the customer wants updates on the DM Content.\n\n### Update me on Supply Chain Content\n- Indicates whether the customer wants updates on the Supply Chain Content.\n\n### Receive More Updates About Our Courses\n- Indicates whether the customer chose to receive more updates about the courses.\n\n### Magazine\n- Indicating whether the customer had seen the ad in Magazine.","928a509a":"**Looking at the p-values, it looks like \"Last Notable Activity_Page Visited on Website\" variable isn't really significant, in the presence of other variables**","c17b1b55":"#### Checking VIF ","f07856ef":"## Metrics beyond simply accuracy","7d3a19ab":"#### Insights:\n- Lead Source : This variable looks useful\n- Last Notable Activity: This variable looks useful","4c4e43a9":"Clearly Prospect ID & Lead Number are two variables that are just indicative of the ID number of the Contacted People & one of them can be dropped.","514723d1":"### Model No 4\nUsing 15 variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Origin_Lead Import<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>Specialization_Media and Advertising<\/li>\n<li>What is your current occupation_Student<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_Page Visited on Website<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","b63cb890":"### Inference:\nOn checking the null value percentage in each column , it is evident that out of 37 columns present in the dataset , we have null values persent in 16 columns, and 11 of them has more than 25% of the null values, which is quite huge.\n1. Lead Source : 0.38%\n2. TotalVisits : 1.48 %\n3. Last Activity : 1.11 %   \n4. Country : 26.63 %\n5. Specialization : 15.56 %\n6. How did you hear about X Education : 23.88 %\n7. What is your current occupation : 29.11 %\n8. What matters most to you in choosing a course : 29.32 %\n9. Tags : 36.28%\n10. Lead Quality : 51.59 %\n11. Lead Profile :29.31\n12. City : 15.36%\n13. Asymmetrique Activity Index :45.64%\n14. Asymmetrique Profile Index : 45.64%\n15. Asymmetrique Activity Score : 45.64%\n16. Asymmetrique Profile Score : 45.64%\n\nTo impute it or discard these rows we will decide later.","fdf6e9df":"# Modelling\n- Data Preparation\n- Model creation\n","0d135c59":"#### Inference:\n#### Specialization\n- It maybe the case that lead has not entered any specialization as the one he wanted to mention is not available in the list, \n- Let's make a category \"Not Specified\" for missing values.\n- We see that specialization with Management in them have higher number of leads. So this is definitely a significant variable and should not be dropped.\n- We can combine Management Specializations because they show similar trends\n- we can replace specilization with low frequency with \"Other Specilization\"\n\n#### City\n- We see that Mumbai is filled for the maximum amount of the city values so we will impute null values in this column by Mumbai.","4a05aece":"### Datatype of columns","9cffb579":"**Looking at the p-values, it looks like all variables are significant, in the presence of other variables**","77a84a4e":"### Not selected value Treatment","207c49a7":"#### From the curve above, 0.35 is the optimum point to take it as a cutoff probability.","fc22ae22":"#### Insights:\n- Lead Origin : This variable looks useful\n- What is your current occupation : This variable looks useful\n- City : This column looks useful\n- A free copy of Mastering The Interview : seeing its countplot , the %ge of leads converting among No and yes is same, column look useful","373f25a4":"### Numerical Columns\n- Box Plot\n- Violin Plot\n- Distplot\n- Describe\n- Outliers Treatment","1de94786":"\n### Tags\n- Tags assigned to customers indicating the current status of the lead.\n- Null Value percentage: 36.29%\n- Since it is score variable, We can drop this column","1134af6c":"### Precision and recall tradeoff","a8edd738":"#### Dropping Columns","88ecce44":"#### We will treat following columns:\n- Lead Source : 0.39%\n- TotalVisits : 1.48%\n- Page Views Per Visit : 1.48%\n- Last Activity : 1.11%\n- Country : 26.63%\n- Specialization : 36.58%\n- How did you hear about X Education : 78.46%\n- What is your current occupation : 29.11%\n- What matters most to you in choosing a course : 29.32%\n- Tags : 36.29%\n- Lead Quality : 51.59%\n- Lead Profile : 74.19%\n- City : 39.71%\n- Asymmetrique Activity Index : 45.65%\n- Asymmetrique Profile Index : 45.65%\n- Asymmetrique Activity Score : 45.65%\n- Asymmetrique Profile Score : 45.65%","7c3ed7df":"As we can observe that there are select values for many column. This is because customer did not select any option from the list, hence it shows select. Select values are as good as NULL.","281f0704":"**Looking at the p-values, it looks like \"Lead Origin_Lead Import\" variables isn't really significant, in the presence of other variables**","227f6d77":"##### Creating a dataframe with the actual churn flag and the predicted probabilities","926721bf":"### Target Variable: Converted \n- Converted is the target variable, Indicates whether a lead has been successfully converted (1) or not (0).","48d19f1a":"- Using RFE(Recursive feature elimination) and manual (hybrid) approach","5510086b":"#### Checking VIF ","2f68869c":"### Model No 3\nUsing 16 variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Origin_Lead Import<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>Specialization_Media and Advertising<\/li>\n<li>What is your current occupation_Student<\/li>\n<li>What is your current occupation_Unemployed<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_Page Visited on Website<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","dad94e8a":"#### Checking VIF ","234744b0":"**Indicates No duplicate values in Lead Number**","c5e6d082":"### Lead Origin\n- The origin identifier with which the customer was identified to be a lead. Includes API, Landing Page Submission, etc.\n\n### What is your current occupation\n- Indicates whether the customer is a student, umemployed or employed.\n\n### City\n- The city of the customer.\n\n### A free copy of Mastering The Interview\n- Indicates whether the customer wants a free copy of 'Mastering the Interview' or not.","502905b8":"### Lead Source, TotalVisits, Page Views Per Visit, Last Activity\nRest of the columns have missing values under 2%, so we can drop these rows.\n- Lead Source : 0.39%\n- TotalVisits : 1.48%\n- Page Views Per Visit : 1.48%\n- Last Activity : 1.11%","b2c84e72":"**The P-value of \"Last Notable Activity_Page Visited on Website\t\" is very high, so removing it from dataset.**","712cb10c":"### Model No 1\nUsing all 18 RFE selected variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Origin_Lead Import<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Lead Source_Others<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>Specialization_Media and Advertising<\/li>\n<li>What is your current occupation_Housewife<\/li>\n<li>What is your current occupation_Student<\/li>\n<li>What is your current occupation_Unemployed<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_Page Visited on Website<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","c54f1480":"#### Insights\n- Last Activity : Last activity when the lead was closed from the sales team side. We can drop this column","595bf492":"#### Dropping Variables","c3183ba2":"## Precision and Recall","4b46fa1e":"\n#### Inference:\n#### Country\n- 95 % of the country is India.\n- Column is highly skewed , we can drop this column","f692d00b":"#### Using sklearn utilities for the same","909834dd":"**Variables have good value of VIF. So we need proceed with same**","07ac50fb":"#### Lead Source\n- We can group some of the lower frequency occuring labels under a common label 'Others'\n- We can combine columns 'google' and 'Google'","2a829354":"## Bivariate Analysis","015c21f8":"**Looking at the p-values, it looks like some variables aren't really significant, in the presence of other variables**\n\n- Last Notable Activity_Page Visited on Website\n- Specialization_Media and Advertising","22a7f42d":"An ROC curve demonstrates several things:\n\n- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.","d7426a8e":"**The P-value of \"What is your current occupation_Student\" is very high, so removing it from dataset.**","75bca9a6":"Columns having more than 50 % of null values are actually useless , so for such columns , we will get rid of the column itself","cfe4b5be":"## Importing libraries","14f268e7":"#### Insights:\n- Newspaper Article : 99.9% says No, this column does not tell much, We Can drop this column\n- X Education Forums : 99.9% says No, this column does not tell much, We Can drop this column\n- Newspaper : 99.9% says No, this column does not tell much, We Can drop this column\n- Digital Advertisement : 99.9% says No, this column does not tell much, We Can drop this column\n- Through Recommendations : 99.9% says No, this column does not tell much, We Can drop this column\n- Do Not Email : Most of them said No, this column does not tell much, We Can drop this column\n- Do Not Call : Most of them said No, this column does not tell much, We Can drop this column\n- Search : 99.8% says No, this column does not tell much, We Can drop this column","070c3054":"### Violin Plot for each Numerical Variables","ad5ec59f":"**The VIF of \"What is your current occupation_Unemployed\" is very high, so removing it from dataset.**","84a65fdb":"### Assigning Lead Score","3a79c3aa":"### Country\n- The country of the customer.\n- Null Value percentage: 26.63%","15958fcd":"### Asymmetrique Activity Index , Asymmetrique Profile Index, Asymmetrique Activity Score, Asymmetrique Profile Score\n\n- As we saw above that we have 45 % of the null values in this column and there seems to be too mucn variation in the parameter so it does not look reliable to impute the values. \n- Since these variables are created by sales team we can drop these variables.","b8c92803":"## Supress Warnings","67e00555":"**Looking at the p-values, it looks like \"Specialization_Media and Advertising\" variable isn't really significant, in the presence of other variables**\n","9536ca34":"### Making predictions on the test set","ce207221":"### Box Plot for each Numerical Variables","fe4cfc9d":"## Business Understanding\n\nAn education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses. \n\nThe company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%. \n\nNow, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as \u2018Hot Leads\u2019. If they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone. A typical lead conversion process can be represented using the following funnel:\n###              Lead Conversion Process - Demonstrated as a funnel ###\n![image.png](attachment:image.png)\n","14de1ed2":"### Model No 2\nUsing 17 variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Origin_Lead Import<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Lead Source_Others<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>SSpecialization_Media and Advertising<\/li>\n<li>What is your current occupation_Student<\/li>\n<li>What is your current occupation_Unemployed<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_Page Visited on Website<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","c167e9a4":"### Test data Result","d3e85011":"#### Checking VIF ","ec2bc166":"###  Train data result","e903d007":"## Business Objectives\n- Build a logistic regression model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted.\n- There are some more problems presented by the company which your model should be able to adjust to if the company's requirement changes in the future so you will need to handle these as well. These problems are provided in a separate doc file. Please fill it based on the logistic regression model you got in the first step. Also, make sure you include this in your final PPT where you'll make recommendations.\n","fdabcacd":"**Converting some binary variables (Yes\/No) to 1\/0**","e2addff1":"###  Plotting Null Count","b9ea8d2b":"**The P-value of \"Specialization_Media and Advertising\t\" is very high, so removing it from dataset.**","f01f56ce":"## Checking duplicates and Null\n   <ol>\n    <li>Plotting Null Count<\/li>\n    <li>Plotting Null Percentage<\/li>\n    <li>Not selected value Treatment<\/li>\n    <li>NULL value Treatment<\/li>\n   <\/ol>","cdb873ae":"#### Checking VIF ","811e3135":"#### Checking VIF ","5ec49f2c":"# Result","1f003250":"#### Checking VIF ","242c5896":"## Univariate Analysis\n   <ol>\n    <li>Numerical Columns<\/li>\n    <li>Categorical Columns<\/li>\n   <\/ol>","eb0ecfc2":"**Looking at the p-values, it looks like \"What is your current occupation_Housewife\" variable isn't really significant, in the presence of other variables**","419da071":"### Model Building","ea8a6db1":"# Python libraries \n- Supress Warnings\n- Importing libraries\n- Data display customization","eadf7bb5":"### Assigning Lead Score","edeea5f3":"#### Checking VIF ","27caae1e":"### What matters most to you in choosing this course\n- An option selected by the customer indicating what is their main motto behind doing this course.\n- Null Value percentage: 29.32%\n\n### What is your current occupation\n- What is your current occupation\n- Null Value percentage: 29.11%","bf7b53e2":"Now on we have to take care of the null values one by one, by looking at teh value its giving for the objective, we have to see what treatment would be good for such feature's null values.","438139ff":"### Lead Source\n- The source of the lead. Includes Google, Organic Search, Olark Chat, etc.\n\n### Last Notable Activity\n- The last notable acitivity performed by the student.","14bb3c44":"**Looking at the p-values, it looks like some variables aren't really significant, in the presence of other variables**\n\n- Lead Source_Others\n- Lead Origin_Lead Import","b07d9c8d":"**The P-value of 'What is your current occupation_Housewife' is very high, so removing it from dataset.**","b49a2e31":"### Specialization\n- The industry domain in which the customer worked before\n- Null Value percentage  36.58%\n\n### City\n- The city of the customer.\n- Null Value percentage 39.71","dbe73421":"This shows that many of the columns have huge null values, so we will check the percentage of null values per column\n","0d1ad55c":"## Data Loading","0848c0ee":"###  Feature Scaling","4a2ef99e":"# Introduction\n- **Business Understanding**\n- **Business Objectives**\n","0d72ef0d":"### Last Activity\n- Last activity performed by the customer. Includes Email Opened, Olark Chat Conversation, etc.","778689bf":"### Building model using statsmodel, for the detailed statistics","67fcf660":"#### For categorical variables with multiple levels, create dummy features (one-hot encoded)","ca255d7d":"##### Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0","713eda70":"**The VIF of \"Lead Origin_Lead Import\" is very high, so removing it from dataset.**","fe2cf9f1":"As we can see, there are a lot of leads generated in the initial stage (top) but only a few of them come out as paying customers from the bottom. In the middle stage, you need to nurture the potential leads well (i.e. educating the leads about the product, constantly communicating etc. ) in order to get a higher lead conversion.\n\nX Education has appointed us to help them select the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires us to build a model wherein we need to assign a lead score to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.","4df4b58b":"### Finding Optimal Cutoff Point","97176cbf":"### Newspaper Article\n- Indicating whether the customer had seen the ad in Newspaper Article.\n\n### X Education Forums\n- Indicating whether the customer had seen the ad in X Education Forums.\n\n### Newspaper\n- Indicating whether the customer had seen the ad in Newspaper.\n\n### Search\n- Indicating whether the customer had seen the ad.\n\n### Digital Advertisement\n- Indicating whether the customer had seen the ad .\n\n### Through Recommendations\n- Indicating whether the customer had seen the ad .\n\n### Do Not Email\n- An indicator variable selected by the customer wherein they select whether of not they want to be emailed about the course or not.\n\n### Do Not Call\n- An indicator variable selected by the customer wherein they select whether of not they want to be called about the course or not.","785100dd":"#### Using sklearn utilities for the same","e173fc05":"## Inspecting Dataframe\n   <ol>\n    <li>Shape of Dataset<\/li>\n    <li>Datatype of columns<\/li>\n    <li>Describe Numerical Columns<\/li>\n   <\/ol>","9480fe09":"#### Using Confusion Matrix ","7d810592":"# Reading and Understanding Data\n- Data Loading\n- Understanding Data Dictionary\n- Checking duplicates and Null\n- Inspecting Dataframe","9cce25f3":"#### Insights:\n- We have almost 38% conversion","aa526fc1":"###  Plotting the ROC Curve","cbab5d23":"### Plotting Null Percentage","5dd0e247":"## Group Members \n - **Manusmita Jha**\n - **Sanskriti Kumari**","e848c9e3":"Optimal cutoff probability is that prob where we get balanced sensitivity and specificity","65c04f01":"### Model No 5\nUsing 14 variables\n<ol>\n<li>Total Time Spent on Website<\/li>\n<li>Lead Origin_Landing Page Submission<\/li>\n<li>Lead Origin_Lead Add Form<\/li>\n<li>Lead Origin_Lead Import<\/li>\n<li>Lead Source_Google<\/li>\n<li>Lead Source_Olark Chat<\/li>\n<li>Lead Source_Reference<\/li>\n<li>Specialization_Not Specified<\/li>\n<li>Specialization_Media and Advertising<\/li>\n<li>What is your current occupation_Working Professional<\/li>\n<li>Last Notable Activity_Modified<\/li>\n<li>Last Notable Activity_Olark Chat Conversation<\/li>\n<li>Last Notable Activity_Page Visited on Website<\/li>\n<li>Last Notable Activity_SMS Sent<\/li>\n<\/ol>","9168eac5":"#### Insights:\n- I agree to pay the amount through cheque : 100% says No, We Can drop this column\n- Get updates on DM Content: 100% says No, We Can drop this column\n- Update me on Supply Chain Content : 100% says No, We Can drop this column\n- Receive More Updates About Our Courses : 100% says No, We Can drop this column\n- Magazine: 100% says No, We Can drop this column","da4ae7f0":"## Data display customization","c0749872":"We have almost 38% conversion","8f244d34":"**Outlier detected in coulmn \"TotalVisits\", \"Total Time Spent on Website\" and \"Page Views Per Visit\"**","9660d53b":"## Understanding Data Dictionary","b9d2c156":"#### Using confusion matrix","45061923":"# Lead Scoring Case Study"}}