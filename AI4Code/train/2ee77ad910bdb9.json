{"cell_type":{"aa77ef65":"code","ddf84ece":"code","62cb022f":"code","6804c0be":"code","258d7ecf":"code","1e6426ae":"code","e6411d26":"code","6269513b":"code","c2adf293":"code","4938ead8":"code","da380166":"code","464798c6":"code","c77f435e":"code","2d66b194":"code","97a3f1ac":"code","6a9f8b9c":"code","7c3a9616":"code","1674629e":"code","f6100ef7":"code","e9cf5985":"markdown","aadd6eb2":"markdown","08d4f7e1":"markdown","2b95cf65":"markdown","a820c91c":"markdown","9bd67566":"markdown","9c604e8c":"markdown","890ccaa1":"markdown","688cd9ee":"markdown","03ae962c":"markdown","ae5cabb8":"markdown","61500ff6":"markdown","41f43c23":"markdown","6bee5043":"markdown","f75b104d":"markdown","0413ea54":"markdown","23983170":"markdown","3757efb6":"markdown","66cd3f74":"markdown","ba7acdfd":"markdown","a1de016f":"markdown","6c6de8b2":"markdown","32cb799b":"markdown","56a46867":"markdown","b2545f58":"markdown","4cf66321":"markdown","535ce5a5":"markdown","1b1240f5":"markdown","161a0ff2":"markdown"},"source":{"aa77ef65":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\n\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline","ddf84ece":"train_csv_path = '..\/input\/train.csv'\ntest_csv_path = '..\/input\/test.csv'\n\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\n\n# have a glimpse of train dataframe structure\nn_train = len(train_df)\nn_pixels = len(train_df.columns) - 1\nn_class = len(set(train_df['label']))\nprint('Number of training samples: {0}'.format(n_train))\nprint('Number of training pixels: {0}'.format(n_pixels))\nprint('Number of classes: {0}'.format(n_class))\nprint(train_df.head())\n\n# have a glimpse of test dataframe structure\nn_test = len(test_df)\nn_pixels = len(test_df.columns)\nprint('Number of test samples: {0}'.format(n_test))\nprint('Number of test pixels: {0}'.format(n_pixels))\nprint(test_df.head())","62cb022f":"random_sel = np.random.randint(n_train, size=8)\n\ngrid = make_grid(torch.Tensor((train_df.iloc[random_sel, 1:].values\/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16, 2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off')\nprint(*list(train_df.iloc[random_sel, 0].values), sep = ', ')","6804c0be":"class MNISTDataset(Dataset):\n    \"\"\"MNIST dtaa set\"\"\"\n    \n    def __init__(self, dataframe, \n                 transform = transforms.Compose([transforms.ToPILImage(),\n                                                 transforms.ToTensor(),\n                                                 transforms.Normalize(mean=(0.5,), std=(0.5,))])\n                ):\n        df = dataframe\n        # for MNIST dataset n_pixels should be 784\n        self.n_pixels = 784\n        \n        if len(df.columns) == self.n_pixels:\n            # test data\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n        else:\n            # training data\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n            \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.transform(self.X[idx]), self.y[idx]\n        else:\n            return self.transform(self.X[idx])","258d7ecf":"RandAffine = transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2))","1e6426ae":"rotate = transforms.RandomRotation(degrees=45)\nshift = RandAffine\ncomposed = transforms.Compose([rotate,\n                               shift])\n\n# Apply each of the above transforms on sample.\nfig = plt.figure()\nsample = transforms.ToPILImage()(train_df.iloc[65,1:].values.reshape((28,28)).astype(np.uint8)[:,:,None])\nfor i, tsfrm in enumerate([rotate, shift, composed]):\n    transformed_sample = tsfrm(sample)\n\n    ax = plt.subplot(1, 3, i + 1)\n    plt.tight_layout()\n    ax.set_title(type(tsfrm).__name__)\n    ax.imshow(np.reshape(np.array(list(transformed_sample.getdata())), (-1,28)), cmap='gray')    \n\nplt.show()","e6411d26":"batch_size = 64\n\ntrain_transforms = transforms.Compose(\n    [transforms.ToPILImage(),\n     RandAffine,\n     transforms.ToTensor(),\n     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\nval_test_transforms = transforms.Compose(\n    [transforms.ToPILImage(),\n     transforms.ToTensor(),\n     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\ndef get_dataset(dataframe, dataset=MNISTDataset,\n                transform=transforms.Compose([transforms.ToPILImage(),\n                                              transforms.ToTensor(),\n                                              transforms.Normalize(mean=(0.5,), std=(0.5,))])):\n    return dataset(dataframe, transform=transform)","6269513b":"\"\"\"\nCode snippet is used for introduction, there is no need to run this cell\n\"\"\"\n\n# def resnet18(pretrained=False, **kwargs):\n#     \"\"\"Constructs a ResNet-18 model.\n#     Args:\n#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n#     \"\"\"\n#     model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n#     if pretrained:\n#         model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n#     return model","c2adf293":"\"\"\"\nCode snippet is used for introduction, there is no need to run this cell\n\"\"\"\n\n# class ResNet(nn.Module):\n\n#     def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n#                  groups=1, width_per_group=64, replace_stride_with_dilation=None,\n#                  norm_layer=None):\n#         super(ResNet, self).__init__()\n#         ...\n        \n#         # declaration of first convolutional layer\n#         self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,bias=False)\n#         ...\n        \n#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n#         ...\n    \n#     def forward(self, x):\n#         x = self.conv1(x)\n#         ....","4938ead8":"from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n\nclass MNISTResNet(ResNet):\n    def __init__(self):\n        super(MNISTResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10) # Based on ResNet18\n        # super(MNISTResNet, self).__init__(BasicBlock, [3, 4, 6, 3], num_classes=10) # Based on ResNet34\n        # super(MNISTResNet, self).__init__(Bottleneck, [3, 4, 6, 3], num_classes=10) # Based on ResNet50\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3,bias=False)\n\nmodel = MNISTResNet()\nprint(model)","da380166":"def train(train_loader, model, criterion, optimizer, epoch):\n    model.train()\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # if GPU available, move data and target to GPU\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        # compute output and loss\n        output = model(data)\n        loss = criterion(output, target)\n        \n        # TODO:\n        # 1. add batch metric (acc1, acc5)\n        # 2. add average metric top1=sum(acc1)\/batch_idx, top5 = sum(acc5)\/batch_idx\n        \n        # backward and update model\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (batch_idx + 1)% 100 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n                100. * (batch_idx + 1) \/ len(train_loader), loss.data.item()))","464798c6":"def validate(val_loader, model, criterion):\n    model.eval()\n    loss = 0\n    correct = 0\n    \n    for _, (data, target) in enumerate(val_loader):\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        output = model(data)\n        \n        loss += criterion(output, target).data.item()\n\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        \n    loss \/= len(val_loader.dataset)\n        \n    print('\\nOn Val set Average loss: {:.4f}, Accuracy: {}\/{} ({:.3f}%)\\n'.format(\n        loss, correct, len(val_loader.dataset),\n        100.0 * float(correct) \/ len(val_loader.dataset)))","c77f435e":"# example config, use the comments to get higher accuracy\ntotal_epoches = 20 # 50\nstep_size = 5     # 10\nbase_lr = 0.01    # 0.01\n\noptimizer = optim.Adam(model.parameters(), lr=base_lr)\ncriterion = nn.CrossEntropyLoss()\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()","2d66b194":"def split_dataframe(dataframe=None, fraction=0.9, rand_seed=1):\n    df_1 = dataframe.sample(frac=fraction, random_state=rand_seed)\n    df_2 = dataframe.drop(df_1.index)\n    return df_1, df_2\n\nfor epoch in range(total_epoches):\n    print(\"\\nTrain Epoch {}: lr = {}\".format(epoch, exp_lr_scheduler.get_lr()[0]))\n\n    train_df_new, val_df = split_dataframe(dataframe=train_df, fraction=0.9, rand_seed=epoch)\n    \n    train_dataset = get_dataset(train_df_new, transform=train_transforms)\n    val_dataset = get_dataset(val_df, transform=val_test_transforms)\n\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                               batch_size=batch_size, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n                                             batch_size=batch_size, shuffle=False)\n\n    train(train_loader=train_loader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n    validate(val_loader=val_loader, model=model, criterion=criterion)\n    exp_lr_scheduler.step()","97a3f1ac":"\"\"\"\nThe following code train model with extra original MNIST data.\nIt's unfair.\n\"\"\"\n\n# from torchvision.datasets import MNIST\n\n# train_transforms = transforms.Compose(\n#     [RandAffine,\n#      transforms.ToTensor(),\n#      transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\n# val_test_transforms = transforms.Compose(\n#     [transforms.ToTensor(),\n#      transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\n# train_dataset_all = MNIST('.', train=True, download=True,\n#                           transform=train_transforms)\n# test_dataset_all = MNIST('.', train=False, download=True,\n#                          transform=train_transforms)\n\n# train_loader = torch.utils.data.DataLoader(dataset=train_dataset_all,\n#                                            batch_size=batch_size, shuffle=True)\n# val_loader = torch.utils.data.DataLoader(dataset=test_dataset_all,\n#                                          batch_size=batch_size, shuffle=False)\n\n\n# for epoch in range(total_epoches):\n#     print(\"\\nTrain Epoch {}: lr = {}\".format(epoch, exp_lr_scheduler.get_lr()[0]))\n#     train(train_loader=train_loader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n#     validate(val_loader=val_loader, model=model, criterion=criterion)\n#     exp_lr_scheduler.step()","6a9f8b9c":"def prediciton(test_loader, model):\n    model.eval()\n    test_pred = torch.LongTensor()\n    \n    for i, data in enumerate(test_loader):\n        if torch.cuda.is_available():\n            data = data.cuda()\n            \n        output = model(data)\n        \n        pred = output.cpu().data.max(1, keepdim=True)[1]\n        test_pred = torch.cat((test_pred, pred), dim=0)\n        \n    return test_pred","7c3a9616":"test_batch_size = 64\ntest_dataset = get_dataset(test_df, transform=val_test_transforms)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=test_batch_size, shuffle=False)\n\n# tensor prediction\ntest_pred = prediciton(test_loader, model)\n\n# tensor -> numpy.ndarray -> pandas.DataFrame\ntest_pred_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1), test_pred.numpy()], \n                      columns=['ImageId', 'Label'])\n\n# show part of prediction dataframe\nprint(test_pred_df.head())","1674629e":"# import the modules we'll need\nfrom IPython.display import HTML\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a link and click to download\ncreate_download_link(test_pred_df, filename=\"submission.csv\")","f6100ef7":"test_pred_df.to_csv('submission.csv', index=False)","e9cf5985":"Define `train` function.","aadd6eb2":"The official ResNet model is designed for the classification task on RGB image dataset, e.g. ImagNet. The main difference between ImageNet and MNIST is the following two points:\n\n| Input Image  |      ImageNet      |       MNIST       |\n| :---------:  | :----------------: | :---------------: |\n|  Channels    |      3    |     1       |\n| Resolution   | 224 x 224  | 28 x 28  |\n| Classes  | 1000 | 10 |\nSo we should better do some modifications on the original networks to adapt for MNIST dataset. Specifically, add the following modifications:\n\n* **Change the first convolutional layer to accept single channel input**\n* **Change the stride of the first convolutional layer from 2 to 1**\n* **Change the last fc layer's output features from 1000 to 10**\n\nBefore we start, in order to know which part of the code to modify, let's take a look how we get a model when calling the `torchvision.models.resnet18()` function.\n\nHere is the source code of `torchvision.models.resnet18()`. When we construct the ResNet18 architecture, we are running the following procedure.","08d4f7e1":"## [Optional] How to get Acc 99.8% in title?","2b95cf65":"## Construct Data Sets from original csv file","a820c91c":"## Modified ResNet18 Model for MNIST","9bd67566":"### Train the network\nThere is only train set and test set in MNIST dataset. In a more general case, we should have three non-overlap datasets:\n* train set: used to train the model\n* val set: used to adjust the hyper-parameters, e.g., learning rate, total epoches, weight decay ...\n* test set: used to test our final model\n\nSo we can split the original train set into a new train set and a val set. Moreover, we can random select different samples every epoch.\n","9c604e8c":"### Random Rotation, Shift, Affine Transformation\nAs you may notice, there is a `transform` parameter in our `MNISTDataset`'s construction method.\n\nWe use the `RandomAffine` transform function in the `torchvision.transforms` module to augment data. \nHere is the [link](https:\/\/pytorch.org\/docs\/stable\/torchvision\/transforms.html#torchvision.transforms.RandomAffine).\n![image.png](attachment:image.png)\n\nAnd also, you can use any other transforms you want.\n","890ccaa1":"First, let's take a look at all available models in the torchvision package.\n\nThe models subpackage contains definitions for the following model architectures:\n- [AlexNet](https:\/\/arxiv.org\/abs\/1404.5997)\n- [VGG](https:\/\/arxiv.org\/abs\/1409.1556)\n- [ResNet](https:\/\/arxiv.org\/abs\/1512.03385)\n- [SqueezeNet](https:\/\/arxiv.org\/abs\/1602.07360)\n- [DenseNet](https:\/\/arxiv.org\/abs\/1608.06993)\n- [Inception](https:\/\/arxiv.org\/abs\/1512.00567) v3\n- [GoogLeNet](https:\/\/arxiv.org\/abs\/1409.4842)\n- [ShuffleNet](https:\/\/arxiv.org\/abs\/1807.11164) v2\n\nYou can construct a model with random weights by calling its constructor:\n```\n>>> resnet18 = models.resnet18()\n```\n\nIf you want to look closer to the source code of every model in torchvision package. You can find it on its official webpage or github repository. For example, the code of ResNet model is showed in the following page:\n- [torchvision.models.resnet](https:\/\/pytorch.org\/docs\/stable\/_modules\/torchvision\/models\/resnet.html)","688cd9ee":"Picture is more than word.","03ae962c":"### Modify the official ResNet for MNIST","ae5cabb8":"## Training and Evaluation","61500ff6":"Make sure to figure out the dataframe structure and the difference between the train dataframe and the test dataframe","41f43c23":"## Prediction on Test Set","6bee5043":"## Prepare the Dataset\nFor the training set, apply random affine transformation mentioned above and normalize pixel values to [-1, 1].\nFor the validation and test set, only apply nomalization.\n\nDefine a function `get_dataset()` as the PyTorch Dataset wrapper. There are two parameters:\n* `dataframe`: The Pandas Dataframe to construct the dataset.\n* `transform`: Transformations to be done when loading data.","f75b104d":"Actually, I noticed the discussion about [How to score 97%, 98%, 99%, and 100%](https:\/\/www.kaggle.com\/c\/digit-recognizer\/discussion\/61480)\n\nAs mentioned in the discussion, in order to get a 99.8% or higher accuracy, you have to add more data, which is unfair.\n\n> * 99.8%: To score 99.8% and higher, you need to have an incredibly lucky training session, or you need to train with the full original MNIST dataset of 70,000 images which unfairly contains Kaggle's \"test.csv\" images.\n\nHowever, we can have a try with all MNIST data.","0413ea54":"# MNIST with the new PyTorch 1.0.1\n----------------------------------------------\n\nThis kernel is based on PyTorch 1.0.1 which has many new features compared to the old version, for example, Variable removed...\nThis kernel shows how to use PyTorch in a simple way. A general PyTorch training and testing pipeline can be concluded into the following steps:\n1. Load original data in a specific data structure.\n2. Use the specific data structure to construct a PyTorch Dataset ([torch.utils.data.Dataset](https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/utils\/data\/dataset.html#Dataset))\n3. Create a neural networks, a Pytorch model([torch.nn.Module](https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/nn\/modules\/module.html#Module)), composed of many layers (e.g., [nn.Conv2d](https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/nn\/modules\/conv.html#Conv2d))\n4. Load a batch from a PyTorch Dataset and feed it into the model.\n5. Create a criterion (loss function) to compute loss.\n6. Once the loss is computed, use it to do the backward propagation to get the gradient for every parameter in the model.\n7. Use PyTorch optimizer (includes learning rate, weight decay and other hyper-parameters for training) to update the model.\n8. After training, test the model on the test set.\n\nShould you have any questions or suggestions, let's discuss in comments. :-)\nThis kernel is based on the kernel [CNN with PyTorch](https:\/\/www.kaggle.com\/juiyangchang\/cnn-with-pytorch-0-995-accuracy). Thanks for [Ryan Chang](https:\/\/www.kaggle.com\/juiyangchang)'s sharing.","23983170":"Define `validate` function.","3757efb6":"## Introduction\n--------\nThis kernel follows the pipeline mentioned above. Use only about a hundred lines, you can get over 99.8% accuracy on the test set.\n\nSo, let's start!\n","66cd3f74":"### Display some images","ba7acdfd":"The first two parameters:\n* `BasicBlock`: The basic block for building ResNet, defined in the same file ([torchvision.models.resnet](https:\/\/pytorch.org\/docs\/stable\/_modules\/torchvision\/models\/resnet.html)). There is another kind of building block --- Bottleneck.\n* `[2, 2, 2, 2]`: Each number denotes the number of Bottleneck or BasicBlock modules in a \"stage\". It depends on how deep you want the networks to be. For example, for ResNet18, it is `[2, 2, 2, 2]`; for ResNet34, it is `[3, 4, 6, 3]`.\n\nFurthermore, ResNet18 model is a Instance of `ResNet` Class. And continue searching for the declaration of `ResNet` class in the same file ([torchvision.models.resnet](https:\/\/pytorch.org\/docs\/stable\/_modules\/torchvision\/models\/resnet.html)). We get:","a1de016f":"Now here are what we want to modify:\n* The first convolutional layer declaration (input channels and stride)\n* The output features of the last fc layer (`num_classes` parameter)\n\nSo we can do the following modifications to get our MNISTResNet model.","6c6de8b2":"## Explore the Data","32cb799b":"## Save submission file","56a46867":"Set the hyper-parameters for training.\n\nRun 50 epoches with step_size=10, base_lr=0.01. Model will achieve over 99.5% accuracy on test set.","b2545f58":"### Download the prediction file\nUtil for download file in a kernel.\n\nReference: [Download a .csv file from a kernel](https:\/\/www.kaggle.com\/rtatman\/download-a-csv-file-from-a-kernel)","4cf66321":"First, in order to process the input data, here is the CSV file, we must understand its data structure.","535ce5a5":"### Pytorch Dataset Class\nDetails in [torch.data.dataset](https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/utils\/data\/dataset.html#Dataset)\n\nThe Pytorch's training pipeline is depicted in the following figure:\n\nMust contains following member functions, in other words, we have to rewrite these member functions to adapt for our custom dataset:\n* __init__()\n* __getitem__()\n* __len__()\n\nA more detailed [DATA LOADING AND PROCESSING TUTORIAL](https:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html) on PyTorch official website.","1b1240f5":"#### Visualize the Transformations","161a0ff2":"Again, picture is more than word."}}