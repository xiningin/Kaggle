{"cell_type":{"8ac86a0a":"code","2a7960ff":"code","8a7d7404":"code","5e9996c7":"code","da4605f4":"code","14cd68ad":"code","a5da1893":"code","c22d56db":"code","fd797479":"code","c911f0da":"code","089bfacb":"code","3145d72e":"code","6de353ee":"code","546090db":"code","b1f19e40":"code","64eaf6c7":"code","4d045b9e":"code","83b3aa89":"code","6b8afcc3":"code","2f1fd208":"code","49233b2c":"code","e9f57c71":"code","6966b102":"code","eaa65bb9":"code","47156227":"code","11605a89":"code","14da766a":"code","8c974a2e":"code","36834382":"code","bc72753f":"markdown","2647af2f":"markdown","ff8bf238":"markdown","fb50df0d":"markdown","8f5751f6":"markdown","efdad82b":"markdown","0ba580f1":"markdown","814dea7c":"markdown","14715b81":"markdown"},"source":{"8ac86a0a":"# import useful libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('whitegrid')\n\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostClassifier","2a7960ff":"# load in data and set seed, do a bit of cleaning\nBASE = '..\/input\/jobathon-analytics-vidhya\/'\nSEED = 2021\n\ntrain = pd.read_csv(f'{BASE}train.csv')\ntest = pd.read_csv(f'{BASE}test.csv')\nss = pd.read_csv(f'{BASE}sample_submission.csv')","8a7d7404":"# do a bit of cleaning\ntrain['Holding_Policy_Duration'] = pd.to_numeric(train['Holding_Policy_Duration'].str.replace('+', ''))\ntest['Holding_Policy_Duration'] = pd.to_numeric(test['Holding_Policy_Duration'].str.replace('+', ''))","5e9996c7":"# Prepare a few key variables to classify columns into categorical and numeric\nID_COL, TARGET_COL = 'ID', 'Response'\n\nfeatures = [c for c in train.columns if c not in [ID_COL, TARGET_COL]]\n\ncat_cols = ['City_Code',\n            'Region_Code',\n            'Accomodation_Type',\n            'Reco_Insurance_Type',\n            'Is_Spouse',\n            'Health Indicator',\n            'Holding_Policy_Type',\n            'Reco_Policy_Cat']\n\nnum_cols = [c for c in features if c not in cat_cols]","da4605f4":"train.head(3)","14cd68ad":"ss.head(3)","a5da1893":"# look at distribution of target variable\ntrain[TARGET_COL].value_counts(), train[TARGET_COL].value_counts(normalize=True)","c22d56db":"# look at which variables are null and if they were parsed correctly\ntrain.info()","fd797479":"test.info()","c911f0da":"# look at unique values in all columns\ntrain.nunique()","089bfacb":"test.nunique()","3145d72e":"# print top 5 values and plot data wrt target variable\nfor col in cat_cols:\n    if col != 'Region_Code': # too high granularity\n      print(f'Analysing: {col}\\nTrain top 5 counts:')\n      print(train[col].value_counts().head(5))\n      print('Test top 5 counts:')\n      print(test[col].value_counts().head(5))\n      plt.figure(figsize=(20,5))\n      sns.countplot(x=col, hue=TARGET_COL, data=train)\n      plt.show();\n      print('\\n')","6de353ee":"# plot kernel density plot and a boxplot of data wrt target variable\nfor col in num_cols:\n  print(f'Analysing: {col}')\n  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n  sns.kdeplot(train[col], ax=ax1)\n  sns.boxplot(x = train[TARGET_COL], y = train[col], ax=ax2)\n  plt.show();\n  print('\\n')","546090db":"for col in ['Reco_Policy_Premium']:\n  # plot kernel density plot and a boxplot of data wrt target variable\n  print(f'Analysing: {col}')\n  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n  sns.kdeplot(np.log1p(train[col]), ax=ax1)\n  sns.boxplot(x = train[TARGET_COL], y = np.log1p(train[col]), ax=ax2)\n  plt.show();\n  print('\\n')","b1f19e40":"# Correlation heatmap \n# not that useful for classification, especially with GBDTs\n# since DT-models are not influenced by multi-collinearity\nplt.figure(figsize=(22, 8))\nsns.heatmap(train[num_cols].corr(), annot=True);","64eaf6c7":"# Pairplots => these might take longer to render\nsns.pairplot(train[num_cols]);","4d045b9e":"# Data preparation\ny = train[TARGET_COL]\nX = train.drop([TARGET_COL, ID_COL], axis=1)\nX.head()","83b3aa89":"# Categorical features reminder\ncat_cols","6b8afcc3":"# fillnas and convert to right data types\nprint(X[cat_cols].info())\n\nX_filled = X.copy()\nX_filled['Health Indicator'] = X['Health Indicator'].fillna('NA')\nX_filled['Holding_Policy_Type'] = X['Holding_Policy_Type'].fillna(0).astype(np.int64)\n\nX_filled[cat_cols].info()","2f1fd208":"# Import train test split, then split the data into train and test set\n# Cross validation is not included in the baseline => model could overfit\nX_train, X_validation, y_train, y_validation = train_test_split(X_filled, y, train_size=0.8, random_state=SEED, shuffle=True, stratify=y)","49233b2c":"model = CatBoostClassifier(\n    random_seed=SEED,\n    eval_metric='AUC',\n)\nmodel.fit(\n    X_train, y_train,\n    cat_features=cat_cols,\n    use_best_model=True,\n    eval_set=(X_validation, y_validation),\n    verbose=50\n)\nprint('Model is fitted: ' + str(model.is_fitted()))\nprint('Model params:')\nprint(model.get_params())","e9f57c71":"print('Tree count: ' + str(model.tree_count_))","6966b102":"model.get_feature_importance(prettified=True)","eaa65bb9":"X_test = test.drop([ID_COL], axis=1)\nX_test.head()","47156227":"# fillnas and convert to right data types TEST\nprint(X_test[cat_cols].info())\n\nX_test_filled = X_test.copy()\nX_test_filled['Health Indicator'] = X_test['Health Indicator'].fillna('NA')\nX_test_filled['Holding_Policy_Type'] = X_test['Holding_Policy_Type'].fillna(0).astype(np.int64)\n\nX_test_filled[cat_cols].info()","11605a89":"contest_predictions = model.predict_proba(X_test_filled)[:,1]\nprint('Predictions:')\nprint(contest_predictions)","14da766a":"ss[TARGET_COL] = contest_predictions\nss.head()","8c974a2e":"ss.to_csv(\"Catboost_Baseline.csv\", index=False)","36834382":"# and we're done!\n'Done!'","bc72753f":"## Baseline Model\nAlright, after EDA of all variables, it's time to introduce the CatboostClassifier model with no tuning as a baseline.","2647af2f":"### Analysis of continuous variables\nPlotted boxplots by target variable and kernel density estimates for each continuous variable to draw interesting insight.","ff8bf238":"# Health Insurance Lead Prediction\n\n[Link to competition here!](https:\/\/datahack.analyticsvidhya.com\/contest\/job-a-thon\/)\n\nGo there and register to be able to download the dataset and submit your predictions.\n\nYour Client FinMan is a financial services company that provides various financial services like loan, investment funds, insurance etc. to its customers. FinMan wishes to cross-sell health insurance to the existing customers who may or may not hold insurance policies with the company. The company recommend health insurance to it's customers based on their profile once these customers land on the website. Customers might browse the recommended health insurance policy and consequently fill up a form to apply. When these customers fill-up the form, their Response towards the policy is considered positive and they are classified as a lead.\n\nOnce these leads are acquired, the sales advisors approach them to convert and thus the company can sell proposed health insurance to these leads in a more efficient manner.\n\nNow the company needs your help in building a model to predict whether the person will be interested in their proposed Health plan\/policy given the information about:\n\n- Demographics (city, age, region etc.)\n- Information regarding holding policies of the customer\n- Recommended Policy Information","fb50df0d":"### Looking at categorical columns\nBecause of all the categorical columns I decided to set a baseline in Catboost. Here are top 5 value counts and countplots for all of them, they prove useful.","8f5751f6":"#### Observations\nAll num cols except `Reco_Policy_Premium` seem to have bimodal distribution. `Reco_Policy_Premium` is slightly skewed to the left, let's try log-transformation.","efdad82b":"#### Observations\nLooks like there are not too many differences in target var distributions. :\/","0ba580f1":"#### Observations\nHere I am interested in the ratio of target variable in each category. If it is a lot different from the other ratios, the signal conveyed for that category is useful. ","814dea7c":"Looks like we have a lot of nulls in `Health Indicator`, `Holding_Policy_Duration`, and `Holding_Policy_Type`. :\/ Otherwise pandas parsed out the columns quite well.","14715b81":"## EDA starts\nFirst we look at the first few rows of train dataset."}}