{"cell_type":{"714e4228":"code","0ade59e7":"code","45ae3851":"code","875dbbaa":"code","326e6dec":"code","c352e7cf":"code","efc4fdc8":"code","c375df1c":"code","57b2a0b8":"code","b111cf28":"markdown","94301cb5":"markdown","56f9c26b":"markdown"},"source":{"714e4228":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten,AveragePooling2D\nfrom keras.optimizers import Adam, SGD\nfrom keras import Sequential\nimport matplotlib.pyplot as plt\nfrom keras.utils import plot_model\nimport cv2\nimport os\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ntrain_dir = '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/train\/'\ntest_dir = '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/test\/'","0ade59e7":"def count_exp(path, set_):\n    dict_ = {}\n    for expression in os.listdir(path):\n        dir_ = path + expression\n        dict_[expression] = len(os.listdir(dir_))\n    df = pd.DataFrame(dict_, index=[set_])\n    return df\ntrain_count = count_exp(train_dir, 'train')\ntest_count = count_exp(test_dir, 'test')\nprint(train_count)\nprint(test_count)","45ae3851":"print('training pictures\\n')\nplt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(train_dir):\n    img = load_img((train_dir + expression +'\/'+ os.listdir(train_dir + expression)[5]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()\n\nprint('testing pictures\\n')\nplt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(test_dir):\n    img = load_img((test_dir + expression +'\/'+ os.listdir(test_dir + expression)[5]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()","875dbbaa":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   zoom_range=0.3,\n                                   rotation_range=30,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   brightness_range=[0.4,1.5],\n                                   horizontal_flip=True)\n\ntraining_set = train_datagen.flow_from_directory(train_dir,\n                                                batch_size=32,\n                                                target_size=(224,224),\n                                                shuffle=True,\n                                                color_mode='rgb',\n                                                class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_set = test_datagen.flow_from_directory(test_dir,\n                                                batch_size=32,\n                                                target_size=(224,224),\n                                                shuffle=True,\n                                                color_mode='rgb',\n                                                class_mode='categorical')","326e6dec":"vgg = VGG16(weights='imagenet',\n              include_top=False,               \n              input_shape = (224,224,3))","c352e7cf":"for layer in vgg.layers:\n    layer.trainable = False","efc4fdc8":"vgg16Model = Sequential()\nvgg16Model.add(vgg)\nvgg16Model.add(Flatten())\nvgg16Model.add(Dense( 3, activation = \"softmax\"))\n\nvgg16Model.summary()","c375df1c":"steps_per_epoch = training_set.n \/\/ training_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\ncheckpoint = ModelCheckpoint(\"vgg16.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\nearlystop = EarlyStopping(monitor=\"val_accuracy\",patience=8,verbose=1)\n\nvgg16Model.compile(optimizer=\"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n\nhist = vgg16Model.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=25,\n                 callbacks=[checkpoint,earlystop],\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","57b2a0b8":"def plot_results(history):\n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,2)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(['train', 'test'], loc='upper left')\n\n    plt.subplot(1,2,1)\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title('model Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","b111cf28":" # Data","94301cb5":"# Model","56f9c26b":"# Results"}}