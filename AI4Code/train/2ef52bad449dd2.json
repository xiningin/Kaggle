{"cell_type":{"47c5b9bd":"code","b4dc02dc":"markdown","55337126":"markdown","61b420aa":"markdown","ae1f678e":"markdown","ed3e6298":"markdown","0a00ecb0":"markdown","4efa3681":"markdown","7406f8e9":"markdown","4e189b66":"markdown","6cc840dd":"markdown","0d228a5d":"markdown","4646e4b1":"markdown","c9b7ccf8":"markdown"},"source":{"47c5b9bd":"t <- summary(m1)$coefficients\/summary(m1)$standard.errors\npvalue <- (1-pnorm(abs(t), 0, 1))*2 ","b4dc02dc":"## c. Logistic Regression Equation\n$$ P(Y=1) =\\frac{e^z}{1+e^z} \\,\\,or \\, \\,\\frac{1}{1+e^\\mathrm{-z}} $$\n$$ z = b_0+b_1x_1+b_2x_2+...+b_dx_d +\\epsilon $$","55337126":"### Example: Drug inducing diabetes\n\n|                  | Drug (I) | Nothing (C) |\n|-----------------:|:--------:|:-----------:|\n|     Diabetic (E) |    IE    |      CE     |\n| Non-diabetic (N) |    IN    |      CN     |\n\n**Relative Ratio:**\n$$P_\\mathrm{Drug}(Diabetic) = \\frac{IE}{IE+IN}$$\n$$P_\\mathrm{Control}(Diabetic)= \\frac{CE}{CE+CN}$$\n\n$$RR_\\mathrm{Drug}(Diabetic)=\\frac{P_\\mathrm{Drug}(Diabetic) }{P_\\mathrm{Nothing}(Diabetic)}$$\n$$RR = \\frac{\\frac{IE}{IE+IN}}{\\frac{CE}{CE+CN}} = \\frac{IE(CE+CN)}{CE(IE+IN)}$$\n\n**Odds Ratio:**\n$$O_\\mathrm{Drug}(Diabetic) = \\frac{IE}{IN}$$\n$$O_\\mathrm{Control}(Non-Diabetic)= \\frac{CE}{CN}$$\n\n$$OR_\\mathrm{Drug}(Diabetic)=\\frac{O_\\mathrm{Drug}(Diabetic) }{O_\\mathrm{Nothing}(Diabetic)}$$\n$$OR = \\frac{\\frac{IE}{IN}}{\\frac{CE}{CN}} = \\frac{IE(CN)}{IN(CE)}$$","61b420aa":"# 3. Variables Interpretation\n## Prologue: RR & OR\nAs logistic regression outputs **probability**, RR (relative risk) and OR (odds ratio) is relevant in variable interpretation.\n\n### Example: Study Design\nIn designing studies, there are 2 distinct groups (x):\n1. Intervention (exposure)\n2. Control (non-exposure)\n\nThere are also 2 outcomes (assuming binary y):\n1. Event (Positive)\n2. Non-event (negative)\n\nThe following 2x2 matrix abbrievates the above with:\n\n|           | Intervention (I) | Control (C) |\n|:---------:|:----------------:|:-----------:|\n| Event (E) |        IE        |      CE     |\n| Non-event |        IN        |      CN     |\n\n","ae1f678e":"### Relative Risk (RR)\nRelative risk is the **comparison** between:\n- Probability of **event** with **intervention**\n$$ P_\\mathrm{Intervention} = \\frac{IE}{IE+IN}$$\n- and Probability of **event** in **control**\n$$ P_\\mathrm{Control} = \\frac{CE}{CE+CN}$$\n\nExpressed as **ratio**:\n$$RR_I(E)=\\frac{P_\\mathrm{I}(E)}{P_\\mathrm{C}(E)}$$\n\n$$RR = \\frac{\\frac{IE}{IE+IN}}{\\frac{CE}{CE+CN}} = \\frac{IE(CE+CN)}{CE(IE+IN)}$$\n\n**Interpretation:**\nThe probability of event with intervention is RR times greater\/lesser than without intervention.\n\n|  RR |                   Description                  |\n|:---:|:----------------------------------------------:|\n| = 1 |    Intervention **does not affect** outcome    |\n| < 1 | Intervention **decreases** event's probability |\n| < 1 | Intervention **increases** event's probability  |","ed3e6298":"## d. Multinomial Regression\nAssuming **3 levels** of Y, where Y = 0, 1, 2:\n- Where Y=0 is the baseline,\n\n|          | $$P(Y=0)$$          | $$P(Y=1)$$                                                        | $$P(Y=2)$$                                                        |\n|----------|---------------------|-------------------------------------------------------------------|-------------------------------------------------------------------|\n| Equation | $$1-P(Y=1)-P(Y=2)$$ | $$\\frac{e^{\\mathrm{z_1}}}{1+e^{\\mathrm{z_1}}+ e^{\\mathrm{z_2}}}$$ | $$\\frac{e^{\\mathrm{z_2}}}{1+e^{\\mathrm{z_1}}+ e^{\\mathrm{z_2}}}$$ |\n\nWhere:\n$$z_1=b_\\mathrm{1,0}+b_\\mathrm{1,1}x_1+b_\\mathrm{1,2}x_2+...+b_\\mathrm{1,d}x_d$$\n$$z_2=b_\\mathrm{2,0}+b_\\mathrm{2,1}x_1+b_\\mathrm{2,2}x_2+...+b_\\mathrm{2,d}x_d$$","0a00ecb0":"## b. Variable Importance\n\n|            Significance            |             Positivity             |             Negativity             |\n|:----------------------------------:|:----------------------------------:|:----------------------------------:|\n|              2-tailed              |              1-tailed              |              1-tailed              |\n| $$H_0: b_i \\leq 0\\\\ H_1: b_i > 0$$ | $$H_0: b_i \\leq 0\\\\ H_1: b_i > 0$$ | $$H_0: b_i \\geq 0\\\\ H_1: b_i < 0$$ |\n\nWe can perform significance testing via a 2-tailed t-test with sample R code: ","4efa3681":"# 1. Theory\n## a. Logistic Regression Model\nThe logistic curve (sigmoid function) has the form of \n$$P(Y=1) =\\frac{e^z}{1+e^z} \\,\\,or \\, \\,\\frac{1}{1+e^\\mathrm{-z}}$$ \n$$z = b_0+b_1x_1+b_2x_2+...+b_dx_d$$\n\nor is alternatively expressed as\n$$ h(x)=\\theta(s) $$\n\nwhere:\n$$s=\\sum_{\\mathrm{i=0}}^dw_i x_i =w^Tx$$\n![image.png](attachment:image.png)","7406f8e9":"### Odds Ratio\nOdds and odds ratio offers another interpretation towards probability.\n\n- If probability of event is 60%:\n- The odds of event is 60:40 or 1.5\n\nOdds ratio is the **comparison** between:\n- Odds of **event** with **intervention**, with\n$$O_\\mathrm{Intervention} = \\frac{IE}{IN}$$\n- Odds of **event** in **control**\n$$O_\\mathrm{Control} = \\frac{CE}{CN}$$\n\nExpressed in **ratio**:\n\n$$OR_I(E)=\\frac{O_\\mathrm{I}(E)}{O_\\mathrm{C}(E)}$$\n$$OR = \\frac{\\frac{IE}{IN}}{\\frac{CE}{CN}} = \\frac{IE(CN)}{IN(CE)}$$\n\n**Interpretation:**\n\nThe odds of event with intervention is **OR** times greater\/lesser than wihout intervention.\n\n|  OR |                   Description                  |\n|:---:|:----------------------------------------------:|\n| = 1 |    Intervention **does not affect** outcome    |\n| < 1 | Intervention **decreases** event's odds |\n| < 1 | Intervention **increases** event's odds  |","4e189b66":"### RR vs OR\n1. When **P(event) is small**, there will be **no preference** in picking either OR or RR. \n\nFor example, a **rare** disease:\n\n|           | Intervention | Control |\n|----------:|:------------:|:-------:|\n|     Event |     0.02     | 0.01    |\n| Non-event |     0.98     | 0.99    |\n\n$$RR_I(E)=\\frac{0.02}{0.01}$$\n\n$$OR_I(E)=\\frac{(\\frac{0.02}{0.98})}{(\\frac{0.01}{0.99})}=\\frac{0.0204}{0.0101}$$\n\nBoth methods are **comparable**, as the reduction in the denominator will not be large when computing odds.\n\n2. When **P(Event) is large**, **RR is preferred** over OR:\n\n|           | Intervention | Control |\n|----------:|:------------:|:-------:|\n|     Event |      0.4     | 0.3     |\n| Non-event |      0.6     | 0.7     |\n\n$$RR_I(E)=\\frac{0.4}{0.3}=1.33$$\n$$OR_I(E)=\\frac{(\\frac{0.4}{0.6})}{(\\frac{0.3}{0.7})} =\\frac{0.66667}{0.42857}=1.55$$\n\n- OR tend to overestimate event as P(Event) is high\n- However, OR is the commonly used metric in logistic regression","6cc840dd":"# 2. Model Interpretation\n## a. Confusion Matrix\nA confusion matrix plots **model's prediction** against its **labels**.\n\n|            | Predicted Yes     | Predicted No      |\n|------------|-------------------|-------------------|\n| Actual Yes | TP                | FN \/ Type 2 Error |\n| Actual No  | FP \/ Type 1 Error | TN                |\n\n- **Type 1 error** is the **rejection** of the null hypothesis to predict no when it is true\n- **Type 2 error** is the **non-rejection** of the null hypothesis to predict no when it is false\n\n### Interpretation \n|                     | Formula                                                  | Synonym \/ Elaboration                |\n|---------------------|----------------------------------------------------------|--------------------------------------|\n| True positive rate  | $$\\frac{TP}{Actual\\,Yes}$$                               | Sensitivity \/ Recall                 |\n| False positive rate | $$\\frac{FP}{Actual\\,No}$$                                | Fall-out \/ False alarm Ratio         |\n| True negative rate  | $$\\frac{TN}{Actual\\,No}$$                                | Specificity                          |\n| False negative rate | $$\\frac{FN}{Actual\\,Yes}$$                               | Miss rate                            |\n| Precision           | $$\\frac{TP}{Predicted\\,Yes}$$                            | Gauging model's ability              |\n| Prevalence          | $$\\frac{Actual\\,Yes}{Total\\,Obs}$$                       | In context of data set               |\n| F1 Score            | $$2(\\frac{Precision\\times Recall}{Precision + Recall})$$ | Balance between precision and recall |\n| Accuracy            | $$\\frac{TP \\, + \\,TN}{Total}$$                           | Gauging model's ability              |\n| Misclassification   | $$\\frac{FP \\, + \\,FN}{Total}$$                           | $$1- \\frac{TP \\, + \\, TN}{Total}$$   |\n\n## b. Likelihood Ratio (TBC)\n## c. Pseudo R-Squared (TBC) \n## d. Hosmer Lemeshow Test (TBC)","0d228a5d":"## b. Error\n- Logistic regression is used when **y is categorical**\n- However, since logistic regression **outputs a probability**\n- Hence, calculating error is not straightforward\n\nA threshold must be imposed to symbolize occurrence of event. \n\n### Method 1: Problem-dependent threshold\nFor e.g., to predict the invitation to either\n- Lower-entry community colleges (CC), or\n- Higher-entry requirements colleges (MIT)\n\n|           | C.C.    | MIT  |\n|-----------|---------|------|\n| Rarity    | Normal  | Rare |\n| Threshold | Average | High |\n| Example   | 0.5     | 0.99 |\n\n<br><\/br>\nA student will require a **high signal value** of **greater than 0.99 out of 1** to cross the threshold in order to be predicted to be invited to MIT. \n\n### Method 2: Probability of event\nWith virtue of statistical sampling, for a data set of\n- 10 MIT students, and\n- 990 non-MIT students\n\nWe can gauge threshold with 1 - Prevalence, with:\n$$ Threshold = P(Non-event)$$\n\n### Method 3: 0.5 as threshold\nThe most **general** method would then to be setting threshold as 0.5, but this would be less specific to both the learning situation and data set.\n\n#### Summary of Error\nError is a result of\n- **Unexplained variance** of signal, similar to linear regression\n- Hence, ultimately a signal **with noise** will be passed into the sigmoid function \n- This noise may then lead to misclassification when compared against **threshold**","4646e4b1":"## a. Coefficient of Variable\nAs we have established from the sigmoid function\n\n$$P(Y=1)=\\frac{1}{1+e^\\mathrm{-z}}$$\n$$O(Y=1)=\\frac{P(Y=1)}{1-P(Y=1)}=(\\frac{1}{1+e^\\mathrm{-z}}\\div \\frac{e^\\mathrm{-z}}{1+e^{-z}})=e^\\mathrm{z}$$\n\n### Continuous x\n\nWe can think of:\n\n- **Intervention** as 1 unit increase in x\n- **Control** no change in x\n\n$$OR_{\\mathrm{x+1}}(Y=1)=\\frac{O_\\mathrm{x+1}(Y=1)}{O_x(Y=1)} = \\frac{e^\\mathrm{z_\\mathrm{x+1}}}{e^z}=e^\\mathrm{b_i}$$\n\n**Interpretation**\n\nThe odds of Y = 1 are multiplied by e^bi times when x_i **increases by a unit**.\n\n### Categorical x\n- **Intervention** as x = 1\n- **Control** as x = 0\n\n$$OR_{\\mathrm{x=1}}(Y=1)=\\frac{O_\\mathrm{x=1}(Y=1)}{O_\\mathrm{x=0}(Y=1)} = \\frac{e^\\mathrm{z_\\mathrm{x=1}}}{e^z}=e^\\mathrm{b_i}$$\n\n**Interpretation**\n\nThe odds of Y = 1 are multiplied by e^bi times when **x_i = 1**.\n\n### Confidence interval \n\nWith reference to the previous table of\n\n|  OR |                   Description                  |\n|:---:|:----------------------------------------------:|\n| = 1 |    Intervention **does not affect** outcome    |\n| < 1 | Intervention **decreases** event's odds |\n| < 1 | Intervention **increases** event's odds  |\n\nIf the value of OR lies between **2.5 - 97.5% confidence interval**, it will satisfy the corresponding description with statistical significance.","c9b7ccf8":"## Prologue: Excel Interpretation\n![image.png](attachment:image.png)"}}