{"cell_type":{"f51e9a32":"code","8e02485f":"code","b5c1daac":"code","7793adbb":"code","166e3666":"code","47188968":"code","a2c8e3a7":"code","dc731216":"code","8cb5a7fc":"code","07dbc760":"code","847bb68c":"code","e378571a":"code","1a461c0b":"code","d6c2d6b0":"code","fd8aa098":"code","68b1c13a":"code","dec0daba":"code","b1f2b74f":"markdown","33eb680d":"markdown","2371ce84":"markdown","c0b7d858":"markdown","ab78b6bc":"markdown","5aa12f53":"markdown","c866ba74":"markdown","fd5421a7":"markdown"},"source":{"f51e9a32":"from nltk.corpus import stopwords\nfrom sklearn.linear_model import LogisticRegression","8e02485f":"import numpy as np\nimport pandas as pd","b5c1daac":"import string","7793adbb":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler","166e3666":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB","47188968":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","a2c8e3a7":"def cleaner(x):\n    return [a for a in (''.join([a for a in x if a not in string.punctuation])).split() if a.lower() not in stopwords.words('english')]","dc731216":"lr = LogisticRegression(solver='liblinear', random_state=777) ","8cb5a7fc":"Pipe = Pipeline([\n    ('bow',CountVectorizer(analyzer=cleaner)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n])","07dbc760":"train.drop('id',inplace = True,axis = 1)\ntest1 = test.drop('id',axis = 1)","847bb68c":"train.fillna('None',inplace=True)\ntest1.fillna('None',inplace=True)\ntest.fillna('None',inplace=True)","e378571a":"train","1a461c0b":"Pipe.fit(train[['text','keyword','location']].values,train['target'])","d6c2d6b0":"pred2 = Pipe.predict(test[['text','keyword','location']].values)\n\n","fd8aa098":"submit_pred = pd.Series(pred2)","68b1c13a":"submit_pred == pred2","dec0daba":"Submission = pd.DataFrame({\"id\" : test[\"id\"], \"target\":pred2})\nSubmission \n\nSubmission.to_csv('submission.csv',index=False)","b1f2b74f":"<html>\n    <font face='Courier' size = 3>Lets Make CSV FILE OF Prediction<\/font>","33eb680d":"<html>\n    <h1><i><font face='Courier' size = 10>Prediction<\/font><\/i><\/h1>","2371ce84":"<html>\n    <h1><i><font face='Courier' size = 10>Importing Libraries<\/font><\/i><\/h1>","c0b7d858":"<html>\n    <font face='Courier' size = 3>Now Lets Create the Function for removing stopwords and punctuations<\/font>","ab78b6bc":"<html>\n        <font face='Courier' size = 3>We are ready to make Pipeline for this Model<\/font>","5aa12f53":"<html>\n    <h1><i><font face='Courier' size = 10>Data Cleaning and the Model<\/font><\/i><\/h1>","c866ba74":"<html>\n    <font face='Courier' size = 3>Lets Check Out The Predictions<\/font>","fd5421a7":"<html>\n    <h1 align='center'><b>\n    <img src='https:\/\/media3.giphy.com\/media\/KAq5w47R9rmTuvWOWa\/giphy.gif' width=100 height=100>\n    <font color='sky blue' face='lucida handwriting'size=300>Py<\/font><font color='yellow' face='lucida handwriting' size=300>Tech<\/font><\/b><\/h1>\n   \n<\/html>"}}