{"cell_type":{"989e48d9":"code","800c0e22":"code","e929278b":"code","82ad46a4":"code","f6a84f01":"code","5a33e78d":"code","18a14eb5":"code","dd32a50e":"code","dcdbf5ba":"code","30f0b963":"code","883a25f4":"code","5e95552c":"code","1daff441":"code","9df32dc1":"code","1fe9b5f1":"code","c9af82f7":"code","bc92fbec":"code","e557f7a2":"code","651c8c6a":"code","ed7fb4f1":"code","8c12890c":"code","e2ec82d6":"code","22df10e0":"code","dbe27d12":"code","5c358ae8":"code","1b70b336":"code","57af76f8":"code","f245c4d6":"code","316cb2c5":"code","8a02f7ed":"code","b32a8219":"code","2343c2ef":"code","6dcb29cd":"code","d5c58983":"code","5b674f3b":"code","d5277400":"code","e53a91ce":"code","ceb352af":"code","bf2b0e2a":"code","51431f67":"markdown","5aab522e":"markdown","1aec3414":"markdown","51e08266":"markdown","bf0fbd3d":"markdown","aee98623":"markdown","0108acf4":"markdown","6f9f6739":"markdown","927e8af5":"markdown","9ee3b865":"markdown","4adfe92c":"markdown","2f57cf51":"markdown","8a7b6bbb":"markdown","d4efb03e":"markdown","bce499af":"markdown","edc6785a":"markdown","472fa3bf":"markdown","e52b1c23":"markdown","44134372":"markdown","cc101d5a":"markdown","f2927f30":"markdown","acc382fd":"markdown","a2e7ca7a":"markdown","1a5dad1b":"markdown","0e5a1d80":"markdown"},"source":{"989e48d9":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","800c0e22":"df = pd.read_csv('..\/input\/Mall_Customers.csv')","e929278b":"df.head(5)","82ad46a4":"df.describe()","f6a84f01":"sns.heatmap(df.drop(['CustomerID'],axis=1).corr(),annot=True,cmap='RdYlGn') \nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show","5a33e78d":"f, axes = plt.subplots(1, 3, figsize=(20, 5)) #sharex=True)\nsns.distplot(df['Annual Income (k$)'],color=\"red\", label=\"Annual Income (k$)\",ax=axes[0])\nsns.distplot(df['Age'],color=\"green\", label=\"Age\",ax=axes[1])\nsns.distplot(df['Spending Score (1-100)'],color=\"skyblue\", label=\"Spending Score\",ax=axes[2])","18a14eb5":"f, axes = plt.subplots(1, 3, figsize=(20, 5)) #sharex=True)\nsns.distplot(df['Annual Income (k$)'][df['Gender']==\"Male\"],color=\"salmon\", label=\"Annual Income (k$)\",ax=axes[0])\nsns.distplot(df['Annual Income (k$)'][df['Gender']==\"Female\"],color=\"skyblue\", label=\"Annual Income (k$)\",ax=axes[0])\n    \nsns.distplot(df['Age'][df['Gender']==\"Male\"],color=\"salmon\", label=\"Age\",ax=axes[1])\nsns.distplot(df['Age'][df['Gender']==\"Female\"],color=\"skyblue\", label=\"Age\",ax=axes[1])\n\nsns.distplot(df['Spending Score (1-100)'][df['Gender']==\"Male\"],color=\"salmon\", label=\"Spending Score\",ax=axes[2])\nsns.distplot(df['Spending Score (1-100)'][df['Gender']==\"Female\"],color=\"skyblue\", label=\"Spending Score\",ax=axes[2])\n\nplt.show()","dd32a50e":"f, axes = plt.subplots(1, 2, figsize=(30, 10)) #sharex=True)\nsns.swarmplot(x=\"Gender\", y=\"Spending Score (1-100)\",data=df, palette=\"Set2\", dodge=True, ax=axes[0])\nsns.swarmplot(x=\"Gender\", y=\"Annual Income (k$)\",data=df, palette=\"Set2\", dodge=True, ax=axes[1])","dcdbf5ba":"f, axes = plt.subplots(1, 2, figsize=(20, 10)) #sharex=True)\nsns.scatterplot(x=\"Age\", y=\"Spending Score (1-100)\",hue=\"Gender\", data=df, ax=axes[0])\nsns.scatterplot(x=\"Age\", y=\"Annual Income (k$)\",hue=\"Gender\", data=df, ax=axes[1])","30f0b963":"pd.scatter_matrix(df, figsize=(20,10))\nplt.show()","883a25f4":"sns.scatterplot(x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\",hue=\"Gender\", data=df)","5e95552c":"from mpl_toolkits.mplot3d import Axes3D","1daff441":"fig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\n\nxs = df['Age']\nys = df['Spending Score (1-100)']\nzs = df['Annual Income (k$)']\nax.scatter(xs, ys, zs, s=50, alpha=0.6, edgecolors='w')\n\nax.set_xlabel('Age')\nax.set_ylabel('Spending Score')\nax.set_zlabel('Annual Income')\n\nplt.show()","9df32dc1":"from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler","1fe9b5f1":"X_k = df['Annual Income (k$)'].values\ny_k = df['Spending Score (1-100)'].values","c9af82f7":"X_k1 = df[['Annual Income (k$)' , 'Spending Score (1-100)']].iloc[: , :].values","bc92fbec":"model = KMeans(n_clusters=5)\nmodel.fit(X_k1)","e557f7a2":"y_kmeans = model.fit_predict(X_k1)","651c8c6a":"model.labels_","ed7fb4f1":"unique_labels = set(model.labels_)\nfor c in unique_labels:  \n    plt.scatter(X_k1[model.labels_ == c, 0],\n                X_k1[model.labels_ == c, 1],\n                label='Cluster {}'.format(c))\nplt.xlabel('Income')\nplt.ylabel('Spending Score')\nplt.legend()\nplt.show()","8c12890c":"df_target = pd.DataFrame({'target':model.labels_})\ndf_new = pd.concat([df, df_target], axis=1, sort=False)\ndf_new = df_new.drop(['CustomerID'], axis=1)\ndf_new.head(5)","e2ec82d6":"X_new = df_new.drop(['target'],axis=1)\ny_new = df_new['target']\n\ndf_gender = pd.get_dummies(X_new['Gender'])\nX_new = X_new.drop(['Gender'],axis=1)\nX_new = pd.concat([X_new,df_gender],axis=1, sort=False)\n\nX_train, X_test, y_train, y_test = train_test_split(X_new,y_new,stratify=y_new,test_size=0.25,random_state=42)","22df10e0":"y_train_bin = pd.get_dummies(y_train)\ny_test_bin = pd.get_dummies(y_test)\nX_new.head(5)","dbe27d12":"dt = DecisionTreeClassifier()\nrf = RandomForestClassifier()","5c358ae8":"model_dt = dt.fit(X_train,y_train_bin)\nmodel_rf = rf.fit(X_train,y_train_bin)","1b70b336":"y_pred_dt = model_dt.predict(X_test)\ny_pred_rf = model_rf.predict(X_test)","57af76f8":"y_test_pred = y_test_bin.idxmax(axis=1).tolist()","f245c4d6":"dfrf_results_pred = pd.DataFrame({'0':y_pred_rf[:,0],\n                             '1':y_pred_rf[:,1],\n                             '2':y_pred_rf[:,2],\n                             '3':y_pred_rf[:,3],\n                             '4':y_pred_rf[:,4]})\n\nrf_pred = dfrf_results_pred.idxmax(axis=1).tolist()\n\nfinal_df_rf =  pd.DataFrame({'predicted':rf_pred,\n                         'actual':y_test_pred})\nfinal_df_rf.head(5)","316cb2c5":"dfdt_results_pred = pd.DataFrame({'0':y_pred_dt[:,0],\n                             '1':y_pred_dt[:,1],\n                             '2':y_pred_dt[:,2],\n                             '3':y_pred_dt[:,3],\n                             '4':y_pred_dt[:,4]})\n\ndt_pred = dfdt_results_pred.idxmax(axis=1).tolist()\n\nfinal_df =  pd.DataFrame({'predicted':dt_pred,\n                         'actual':y_test_pred})\nfinal_df.head(5)","8a02f7ed":"from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, confusion_matrix, accuracy_score","b32a8219":"X_feature_impt = X_train.keys().tolist()\ny_feature_impt = model_dt.feature_importances_\n\nplt.barh(X_feature_impt, y_feature_impt, align='center')\nplt.xlabel('Relative Importance')\nplt.title('Feature Importance')\nplt.show()","2343c2ef":"print(\"Decision Tree Scores\")\nprint(\"Accuracy: {}\".format(accuracy_score(y_test_bin,y_pred_dt)))\nprint(\"MAE (test): {}\".format(mean_absolute_error(y_test_bin, y_pred_dt)))\nprint(\"MSE (test): {}\".format(mean_squared_error(y_test_bin, y_pred_dt)))\n\nprint(\"Random Forest Scores\")\nprint(\"Accuracy: {}\".format(accuracy_score(y_test_bin,y_pred_rf)))\nprint(\"MAE (test): {}\".format(mean_absolute_error(y_test_bin, y_pred_rf)))\nprint(\"MSE (test): {}\".format(mean_squared_error(y_test_bin, y_pred_rf)))","6dcb29cd":"class_labels = list(y_train_bin.columns.values)\nclass_labels","d5c58983":"import itertools\nimport sklearn.metrics\n\ndef plot_confusion_matrix(y_test, y_pred, labels,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \n    See: http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n    \"\"\"\n    cm = sklearn.metrics.confusion_matrix(y_test, y_pred, labels=labels)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels, rotation=45)\n    plt.yticks(tick_marks, labels)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","5b674f3b":"pred1 = []\nfor yp in rf_pred:\n    pred1.append(int(yp))","d5277400":"main_test = []\npred = []\nfor yt in y_test_pred:\n    main_test.append(int(yt))\n    \nfor yp in dt_pred:\n    pred.append(int(yp))","e53a91ce":"print(main_test[1:5])\nprint(pred[1:5])","ceb352af":"plt.figure()\nplot_confusion_matrix(main_test, pred1, labels=class_labels,\n                      title='[Decision Tree] Confusion matrix, without normalization')\nplot_confusion_matrix(main_test, pred1, labels=class_labels, normalize=True,\n                      title='[Decision Tree] Confusion matrix')","bf2b0e2a":"plt.figure()\nplot_confusion_matrix(main_test, pred, labels=class_labels,\n                      title='[Decision Tree] Confusion matrix, without normalization')\nplot_confusion_matrix(main_test, pred, labels=class_labels, normalize=True,\n                      title='[Decision Tree] Confusion matrix')","51431f67":"# KMeans Clustering","5aab522e":"Intiating our models, fitting the training data and predicting on the test data","1aec3414":"Insights:\n\n1) Spending Scores tend to be higher among customer who are between 25-40 years old\n\n3) Female in general tend to have higher Spending Scores than compared to male, especially for females around the age of \n25-40\n\n3) The clustering of datapoints in the spending score and annual income plot seems to indicate certain types of consumer groups in te datasets with different spending behaviors","51e08266":"# Model Comparision and Evaluation","bf0fbd3d":"# (Additional) KNN, Random Forest & Decision Tree Classifier","aee98623":"Setting the number of clusters to 5","0108acf4":"The scatter matrix seems to indicate that there are some clusters to explore in the Spending Scores and Annual Income plot, lets see if we can distingush the plots between male and female and see if there is a trend","6f9f6739":"# Confusion Matrix for Random Forest Classifier","927e8af5":"Based on the clustering above in the 3d plot, we have our 5 target groups being classified into the 5 clusters already, we can use that as prediction targets and try to predict the which category a customer will fall under based on the current features using Random Forest & Decision Tree Classifier ","9ee3b865":"Based on the clusters, there are 5 groups of interest to us","4adfe92c":"# Approach to problem:\n    1) Exploratory Data Analysis (Understanding the structure of the dataset)\n    \n    2) KMeans Clustering (Classifying the customers into different Categories of Interest)\n    \n    3) (Additional) Using Decision Tree Classifier and Random Forest Classifier to predict the customer category identified\n       in Kmeans clustering using existing data","2f57cf51":"# Customer Segmentation Using KMeans and Machine Learning using Decision Tree and Random Forest","8a7b6bbb":"Let's try to cluster the datapoints in the Annual Income and Spending Scores plot using KMeans","d4efb03e":"No interesting trend, lets try a 3d plot","bce499af":"Any feedback is appreciated","edc6785a":"looks promising, moving on the comparison and evaluation","472fa3bf":"Let's get the general statistics of the dataset","e52b1c23":"The displot above seem to indicate for Annual Income and Age distributions, Male and Female share almost the same distribution but as for spending score, the distribution plot suggest that Female customers tend to have higher spending scores than compared to male customers. Let's try this on a and a bee swarm and scatter plot as well as a scatter matrix","44134372":"# Exploratory Data Analysis","cc101d5a":"# Confusion matrix for Decision Tree Classifier","f2927f30":"Let's visulise the correlation between each of the feature of the dataset","acc382fd":"Preparing the data","a2e7ca7a":"Spliting the data into training and testing datasets","1a5dad1b":"The only thing signifiant is the negative correlation between Spending Score and Age of -0.33 but its not negatively high enough to draw any conclusions. Maybe a displot may show us more","0e5a1d80":"A concentration of the data captures customers with Annual Incomes between 25-75k, an age group of beween 20-45 and a spending score of between 40-60, let's split this distribution between Male and Female"}}