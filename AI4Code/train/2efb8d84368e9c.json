{"cell_type":{"67bb5516":"code","0eaabad5":"code","8f0d1094":"code","656f9dfb":"code","8d048780":"code","2613d849":"code","2046e3d0":"code","7a0454cb":"code","aad93758":"code","13892461":"code","6b5b0b1b":"code","169fc796":"code","0ade5d5c":"code","1fb5115d":"code","f156fc06":"code","18687291":"code","a141dc30":"code","8843e32a":"code","e064cdcc":"code","d2ea49b2":"code","aa1d0dae":"code","43dfde9e":"code","2a37e51c":"code","ef60c92f":"code","21e1d83a":"code","d9c98fb0":"code","c68e771d":"code","6fa1beac":"code","d9444bae":"markdown","573d7abf":"markdown","245e3af7":"markdown","de1c4a21":"markdown","30d361c9":"markdown","a45366a3":"markdown","92b043d2":"markdown","ded19b45":"markdown","7cf837e1":"markdown","068e9669":"markdown","988d9501":"markdown","0dd13d35":"markdown","10aae487":"markdown","aa543a3a":"markdown","1ae0acb9":"markdown"},"source":{"67bb5516":"#Let's start with adding libraries I will use\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\n\n# plotly\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\n\n# word cloud library\nfrom wordcloud import WordCloud\n\n# matplotlib\nimport matplotlib.pyplot as plt\n\nfrom collections import Counter\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","0eaabad5":"df = pd.read_csv(\"..\/input\/covidtr\/Covid_vaka.csv\")\n\n# I want to see total hospital usage so I will add new column as \"Hastane_Kullan\u0131m\u0131\".\ndf[\"Hastane_Kullan\u0131m\u0131\"] = df.Toplan_Ent\u00fcbe + df.Toplam_Yogun_Bakim\ndf.tail()","8f0d1094":"df.describe()","656f9dfb":"\n\n# Then lets start with show change of \"Vaka\",\"Test_Sayisi\",\"Vaka_Test\" and \"Vaka\",\"Vefat\",\"Olum_Oran\" date by date \n# import graph objects as \"go\"\nimport plotly.graph_objs as go\n\n# Creating graph1\ngraph1 = go.Scatter(\n                    x = df.Tarih,\n                    y = df.Vaka_Test,\n                    mode = \"lines+markers\",\n                    name = \"Tarihe G\u00f6re Vaka Test Oran\u0131 \",\n                    marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n                    text= df.Vaka)\n\n\ndata = [graph1]\nlayout = dict(title = 'Tarihe G\u00f6re Vaka Analizi',\n              xaxis= dict(title= 'COVID',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = data, layout = layout)\niplot(fig)\n","8d048780":"import plotly.graph_objs as go\n\n# Creating graph2\ngraph2 = go.Scatter(\n                    x = df.Tarih,\n                    y = df.Aktif_Vaka,\n                    mode = \"lines+markers\",\n                    name = \"Aktif Vaka Durumu\",\n                    marker = dict(color = 'rgba(139 ,69, 19, 1.0)'),\n                    text= df.Vaka)\n\ndata = [graph2]\nlayout = dict(title = 'Aktif Vaka Durumu',\n              xaxis= dict(title= 'COVID',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = data, layout = layout)\niplot(fig)","2613d849":"# Creating graph3\ngraph3 = go.Scatter(\n                    x = df.Tarih,\n                    y = df.Toplan_Ent\u00fcbe,\n                    mode = \"lines+markers\",\n                    name = \"Ent\u00fcbe Hasta\",\n                    marker = dict(color = 'rgba(99 ,69, 72, 1.0)'),\n                    text= df.Toplan_Ent\u00fcbe)\ngraph4 = go.Scatter(\n                    x = df.Tarih,\n                    y = df.Toplam_Yogun_Bakim,\n                    mode = \"lines+markers\",\n                    name = \"Yo\u011fun Bak\u0131m Hasta\",\n                    marker = dict(color = 'rgba(21 ,98, 120, 1.0)'),\n                    text= df.Toplam_Yogun_Bakim)\ngraph5 = go.Scatter(\n                    x = df.Tarih,\n                    y = df.Hastane_Kullan\u0131m\u0131,\n                    mode = \"lines+markers\",\n                    name = \"Hastane Kullan\u0131m\u0131\",\n                    marker = dict(color = 'rgba(21 ,98, 19, 1.0)'),\n                    text= df.Hastane_Kullan\u0131m\u0131)\n\ndata = [graph3,graph4,graph5]\nlayout = dict(title = 'Hastane Kullan\u0131m De\u011fi\u015fimi',\n              xaxis= dict(title= 'COVID',ticklen= 10,zeroline= False)\n             )\nfig = dict(data = data, layout = layout)\niplot(fig)","2046e3d0":"# Train datam\u0131z\u0131 y\u00fckl\u00fcyoruz.\ndataset_train = pd.read_csv(\"..\/input\/covid-train\/Covid_train.csv\")\ndataset_train.head()","7a0454cb":"train = dataset_train.loc[:, [\"Aktif_Vaka\"]].values\ntrain","aad93758":"# Feature Scaling(normalizasyon)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\ntrain_scaled = scaler.fit_transform(train)\ntrain_scaled","13892461":"plt.plot(train_scaled)\nplt.show()","6b5b0b1b":"# 50 timesteps ve 1 output ile data structure\nX_train = []\ny_train = []\ntimesteps = 2\nfor i in range(timesteps, 58):\n    X_train.append(train_scaled[i-timesteps:i, 0])\n    y_train.append(train_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)","169fc796":"# Reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_train","0ade5d5c":"y_train","1fb5115d":"# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 250, batch_size = 32)","f156fc06":"# Test datam\u0131z\u0131 y\u00fckl\u00fcyoruz.\ndataset_test = pd.read_csv(\"..\/input\/covidtest\/Covid_test.csv\")\ndataset_test.head()","18687291":"real_vaka = dataset_test.loc[:, [\"Aktif_Vaka\"]].values\nreal_vaka","a141dc30":"# Tahmin edilen Aktif Vaka \ndataset_total = pd.concat((dataset_train['Aktif_Vaka'], dataset_test['Aktif_Vaka']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values.reshape(-1,1)\ninputs = scaler.transform(inputs)  # min max scaler\ninputs","8843e32a":"X_test = []\nfor i in range(timesteps, 27):\n    X_test.append(inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_vaka = regressor.predict(X_test)\npredicted_vaka = scaler.inverse_transform(predicted_vaka) #scale yapma diyorum.\n\n# Sonucu G\u00f6rselle\u015ftirme\nplt.plot(real_vaka, color = 'red', label = 'Ger\u00e7ek Vaka Durumu')\nplt.plot(predicted_vaka, color = 'blue', label = 'Tahmin Edilen Vaka Durumu')\nplt.title('Aktif Vaka')\nplt.xlabel('Zaman')\nplt.ylabel('Aktif Vaka')\nplt.legend()\nplt.show()","e064cdcc":"import numpy\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","d2ea49b2":"dataset = df.iloc[:,12].values\nplt.plot(dataset)\nplt.xlabel(\"Tarih\")\nplt.ylabel(\"Aktif Vaka\")\nplt.title(\"Aktif Vaka De\u011fi\u015fimi\")\nplt.show()","aa1d0dae":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype(\"float32\")\ndataset.shape","43dfde9e":"# De\u011ferlerimi normalize ediyorum \u00e7\u00fcnk\u00fc 0 ile 80000 aras\u0131nda kaybolacak verilerin \u00f6n\u00fcne ge\u00e7ip veri kaybetmek istemiyorum.\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","2a37e51c":"# Verisetimi train ve test olarak iki b\u00f6l\u00fcme ay\u0131r\u0131yorum. Datasetin %30 unu kuraca\u011f\u0131m modeli test etmek i\u00e7in %70 ini de modelimi e\u011fitmek i\u00e7in kullancam.\ntrain_size = int(len(dataset) * 0.70)\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(\"train size: {}, test size: {} \".format(len(train), len(test)))","ef60c92f":"time_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY) ","21e1d83a":"dataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)\n\ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","d9c98fb0":"model = Sequential()\nmodel.add(LSTM(10, input_shape=(1, time_stemp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","c68e771d":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","6fa1beac":"# shifting train\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.legend()\nplt.show()","d9444bae":"\u00dc\u00e7\u00fcnc\u00fc grafi\u011fimde ise bu s\u00fcre\u00e7te hastane kullan\u0131m\u0131n\u0131 anlatan bir grafik haz\u0131rlad\u0131m. Grafi\u011fin sa\u011f taraf\u0131nda bilgilendirdi\u011fim gibi ayr\u0131 ayr\u0131 ent\u00fcbe veya yo\u011fun bak\u0131m hasta say\u0131s\u0131n\u0131 ve ikisinin toplam\u0131n\u0131 g\u00f6steren toplam hastane kullan\u0131m\u0131n\u0131n g\u00fcnden g\u00fcne nas\u0131l de\u011fi\u015fti\u011fini g\u00f6receksiniz.","573d7abf":"# RNN Modeli Olu\u015fturmak","245e3af7":"\u0130kinci grafi\u011fimde ise 11.03.2020 tarihinden 31.05.2020 tarihine kadar \u00fclkemizdeki aktif vaka say\u0131s\u0131n\u0131n g\u00fcnden g\u00fcne de\u011fi\u015fimini g\u00f6stermek istedim. Grafikte noktalar\u0131n \u00fczerine geldi\u011finizde o g\u00fcne kadar olan toplam pozitif vaka say\u0131s\u0131n\u0131 ve hemen alt\u0131nda o g\u00fcne dair pozitif vaka say\u0131s\u0131n\u0131 g\u00f6receksiniz.","de1c4a21":"%1,23 loss de\u011feri ile modelimizi kurmu\u015f olduk ve verdi\u011fimiz de\u011ferlerin yeterli oldu\u011funu g\u00f6rd\u00fck.","30d361c9":"\u0130lk grafi\u011fimde 11.03.2020 tarihinden 31.05.2020 tarihine kadar \u00fclkemizde g\u00f6r\u00fclen vaka say\u0131s\u0131n\u0131n g\u00fcnden g\u00fcne de\u011fi\u015fimini g\u00f6stermek istedim. Grafikte noktalar\u0131n \u00fczerine geldi\u011finizde o g\u00fcne ait yeni vaka say\u0131s\u0131n\u0131 ve o g\u00fcn yap\u0131lan testlerin y\u00fczde ka\u00e7\u0131n\u0131n pozitif \u00e7\u0131kt\u0131\u011f\u0131n\u0131 g\u00f6receksiniz.","a45366a3":"# > **LSTM ile Gelecekteki Aktif Vaka Tahmini**\n\n31.05.2020 tarihine kadar olan aktif vaka say\u0131s\u0131ndaki de\u011fi\u015fimi e\u011fiterek daha sonras\u0131n\u0131 tahmin etmek istiyorum. Bunun i\u00e7in LSTM modelini kullanarak tarihsel geli\u015fimin tahminini yapmak istiyorum.","92b043d2":"# RNN Modelini Kullanarak Tahmin ve Bunun G\u00f6rselle\u015ftirmesi****","ded19b45":"Now lets look our data description. We can see our datas means, minimum and maximum points easily.","7cf837e1":"# > RNN ile Gelecek Aktif Vaka Tahmini\n11.03.2020 ile 07.05.2020 tarihleri aras\u0131ndaki verileri Train olarak,\n\n08.05.2020 ile 31.05.2020 tarhileri aras\u0131ndaki verileri Test olarak kullancam.","068e9669":"# LSTM Modeli Kurmak\n**\u015eimdi LSTM modelimi kurmak i\u00e7in istedi\u011fim train ve test datas\u0131 haz\u0131r hale gelmi\u015f oldu.\nLSTM modelim i\u00e7in 10 time step ve 50 epochs kullancam, batch boyutum ise 1 olacak. Optimizerim ise Adam Optimizasyonu olacak. B\u00f6ylece \u00e7ok d\u00fc\u015f\u00fck bir loss de\u011feri ile modelimi kurdum.**","988d9501":"# LSTM Modelini Kullanarak Tahmin ve Bunun G\u00f6rselle\u015ftirmesi","0dd13d35":"LSTM modeli ile yapm\u0131\u015f oldu\u011fumuz tahmini \u00f6zetlemek gerekirse, grafikte mavi ile g\u00f6sterilen \u00e7izgi ger\u00e7ek vaka say\u0131m\u0131z\u0131n tarihsel s\u00fcrecidir. Turuncu ile g\u00f6sterilen ise modelimizi olu\u015ftururken %70 oran\u0131nda e\u011fitmek i\u00e7in ay\u0131rd\u0131\u011f\u0131m\u0131z train k\u0131sm\u0131d\u0131r. Ye\u015fil ile g\u00f6sterilen k\u0131s\u0131m ise %30 olarak ay\u0131rd\u0131\u011f\u0131m\u0131z ve modelimizi test etmek i\u00e7in kulland\u0131\u011f\u0131m\u0131z test datam\u0131z. Modelimiz tabi ki de vaka say\u0131s\u0131n\u0131 net olarak tahmin edemedi \u00e7\u00fcnk\u00fc vaka say\u0131s\u0131n\u0131 etkileyen bilgisayar\u0131m\u0131z\u0131n d\u00fc\u015f\u00fcnemedi\u011fi baz\u0131 d\u0131\u015f etkenler var. Ama gelecekteki azal\u0131\u015f\u0131 tespit etti\u011fini rahatl\u0131kla s\u00f6yleyebiliriz.","10aae487":"G\u00f6r\u00fcnd\u00fc\u011f\u00fc \u00fczere RMSE de\u011ferim \u00e7ok d\u00fc\u015f\u00fck \u00e7\u0131kt\u0131. Bu da epoch, Batch ve optimizer anlam\u0131nda de\u011fi\u015ftirmem gereken bir\u015fey yok.","aa543a3a":"# >  **Covid-19'un G\u00fcnden G\u00fcne T\u00fcrkiye Ser\u00fcveni**","1ae0acb9":"# Sonu\u00e7\nBu kurdu\u011fumuz model ile vaka say\u0131s\u0131n\u0131n ini\u015f ve \u00e7\u0131k\u0131\u015f\u0131n\u0131 do\u011fru tahmin etti\u011fimizi g\u00f6rebiliriz ama bu say\u0131lar\u0131n do\u011fru tahminler olmad\u0131\u011f\u0131n\u0131 da g\u00f6r\u00fcyoruz. Tahmin etti\u011fimiz vaka say\u0131s\u0131n\u0131n ger\u00e7ekte olan vaka say\u0131s\u0131n\u0131n biraz \u00fczerinde oldu\u011funu s\u00f6ylemeliyiz. Ama g\u00f6r\u00fcyoruz ki aradaki fark \u00e7ok da g\u00f6ze batacak d\u00fczeyde de\u011fil. \u015eimdi de bunu LSTM algoritmas\u0131n\u0131 kullanarak yapal\u0131m ve bakal\u0131m aradaki fark veya farklar nelermi\u015f."}}