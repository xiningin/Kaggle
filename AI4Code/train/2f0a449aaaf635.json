{"cell_type":{"cbfbfea1":"code","e86b8b74":"code","ab9bceff":"code","d37fc2f1":"code","75988951":"code","09f32656":"code","e89fd1b1":"code","fff2ce1a":"code","f2bfcbca":"code","4ce5eb3b":"code","26c8c38c":"code","f97000d3":"code","c9157502":"code","b0614d10":"code","acb98ebd":"code","df23b80f":"code","6ed77a75":"code","0887110d":"code","986b2ee1":"code","e2fa893f":"code","5f7821a7":"code","6cd3a5c0":"code","e7134d83":"code","2ce523fb":"code","d33c26b8":"code","9a79806c":"code","a9868b48":"code","d5ca13b6":"code","50b672e8":"code","21cf7c14":"code","74fdfb88":"code","22191439":"code","ad59b4bd":"code","4427d679":"code","7df36f92":"code","46eca9a8":"code","1f19e13e":"code","91924a7c":"code","2d89323a":"code","ffe2ac34":"code","e90d584e":"code","68a87f1e":"code","3db383b2":"code","61ea9ae0":"code","08373c59":"code","45960d56":"code","3ed30ca6":"code","781c5b5a":"code","681c2dd6":"code","bebeb1ad":"code","c7455f57":"code","0f649622":"code","7be31945":"code","53957ddf":"code","4b936c16":"code","34843dfb":"code","4f01872c":"code","2a93482c":"code","0fa8ce6b":"code","471a4f2e":"code","48a782e8":"code","7f28f052":"code","a3e1ff93":"code","0c2f7575":"code","3db4bcf6":"code","d4b6a92e":"markdown","60a78924":"markdown","811c99c9":"markdown","5d24648d":"markdown","76c279f5":"markdown","737257b0":"markdown","523d05b6":"markdown","f0de1e56":"markdown","ad6eb460":"markdown","9f160768":"markdown","e92fd4a3":"markdown","fe85c807":"markdown","f37199e3":"markdown","83cfb8c0":"markdown","bc5c764a":"markdown"},"source":{"cbfbfea1":"# This Python 3 environment comes with many helpful analytics libraries installed\n\n# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set() # setting seaborn default for plots\n%matplotlib inline\n","e86b8b74":"TRAIN_PATH = '..\/input\/train.csv'\nTEST_PATH = '..\/input\/test.csv'\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)","ab9bceff":"train_df.columns","d37fc2f1":"train_df.head()","75988951":"train_df.describe()","09f32656":"train_df.info()","e89fd1b1":"test_df.info()","fff2ce1a":"train_df.isnull().sum()","f2bfcbca":"test_df.isnull().sum()","4ce5eb3b":"train_df['Survived'].value_counts()","26c8c38c":"def bar_chart(feature):\n    survived = train_df[train_df['Survived']==1][feature].value_counts()\n    dead = train_df[train_df['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","f97000d3":"bar_chart('Sex')","c9157502":"train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","b0614d10":"bar_chart('Pclass')","acb98ebd":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","df23b80f":"train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","6ed77a75":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","0887110d":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","986b2ee1":"train_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\ntrain_df.columns","e2fa893f":"train_test_data = [train_df, test_df] # combining train and test dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    ","5f7821a7":"train_df.columns","6cd3a5c0":"# train_df['Has_family'] = train_df['SibSp'] + train_df['Parch']\n# test_df['Has_family'] = test_df['SibSp'] + test_df['Parch']\n# train_df[train_df['Has_family']>0] = 1\n# test_df[test_df['Has_family']>0] = 1","e7134d83":"X_train_df = train_df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\nX_test_df = test_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])","2ce523fb":"y_train_df = train_df['Survived']","d33c26b8":"X_train_df.isnull().sum()","9a79806c":"X_test_df.isnull().sum()","a9868b48":"age_med = train_df.Age.median()\nX_train_df.Age.fillna(age_med, inplace=True)\nX_test_df.Age.fillna(age_med, inplace=True)","d5ca13b6":"# X_train_df.loc[ X_train_df['Age'] <= 5, 'Age']= 0\n# X_train_df.loc[(X_train_df['Age'] > 5) & (X_train_df['Age'] <= 16), 'Age'] = 1\n# X_train_df.loc[(X_train_df['Age'] > 16) & (X_train_df['Age'] <= 32), 'Age'] = 2\n# X_train_df.loc[(X_train_df['Age'] > 32) & (X_train_df['Age'] <= 48), 'Age'] = 3\n# X_train_df.loc[(X_train_df['Age'] > 48) & (X_train_df['Age'] <= 64), 'Age'] = 4\n# X_train_df.loc[ X_train_df['Age'] > 64, 'Age'] = 5\n# X_train_df","50b672e8":"# X_test_df.loc[ X_test_df['Age'] <= 5, 'Age']= 0\n# X_test_df.loc[(X_test_df['Age'] > 5) & (X_test_df['Age'] <= 16), 'Age'] = 1\n# X_test_df.loc[(X_test_df['Age'] > 16) & (X_test_df['Age'] <= 32), 'Age'] = 2\n# X_test_df.loc[(X_test_df['Age'] > 32) & (X_test_df['Age'] <= 48), 'Age'] = 3\n# X_test_df.loc[(X_test_df['Age'] > 48) & (X_test_df['Age'] <= 64), 'Age'] = 4\n# X_test_df.loc[ X_test_df['Age'] > 64, 'Age'] = 5","21cf7c14":"mod = X_train_df.Embarked.value_counts().argmax()\nX_train_df.Embarked.fillna(mod, inplace=True)","74fdfb88":"fare_med = train_df.Fare.median()\nX_test_df.Fare.fillna(fare_med, inplace=True)","22191439":"X_train_df.isnull().sum()","ad59b4bd":"X_test_df.isnull().sum()","4427d679":"X_train_df.columns","7df36f92":"X_train_df.replace({\"male\": 0, \"female\": 1}, inplace=True)\nX_test_df.replace({\"male\": 0, \"female\": 1}, inplace=True)\nX_train_df.replace({\"S\": 0, \"C\": 1, \"Q\": 2}, inplace=True)\nX_test_df.replace({\"S\": 0, \"C\": 1, \"Q\": 2}, inplace=True)","46eca9a8":"X_train_df.head()","1f19e13e":"X_train_df = pd.get_dummies(X_train_df, columns=['Pclass', 'Embarked', 'Title'], drop_first=True)\nX_test_df = pd.get_dummies(X_test_df, columns=['Pclass', 'Embarked', 'Title'], drop_first=True)\nX_train_df.head()","91924a7c":"X_test_df.head()","2d89323a":"# X_test_df['Age_5.0'] = 0","ffe2ac34":"X_train_df.shape, X_test_df.shape","e90d584e":"from sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\nX_train_sc = sc_X.fit_transform(X_train_df)\nX_test_sc = sc_X.transform(X_test_df)","68a87f1e":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n","3db383b2":"logi_clf = LogisticRegression(solver='lbfgs', max_iter=500)\nlogi_parm = {\"C\": [0.1, 0.5, 1, 5, 10, 50],\n            'random_state': [0,1,2,3,4,5]}\n\nsvm_clf = SVC(probability=True)\nsvm_parm = {'kernel': ['rbf', 'poly'], \n            'C': [1, 5, 50, 100, 500, 1000,1500,2000], \n            'degree': [3, 5, 7], \n       'gamma':[0.01,0.04,.1,0.2,.3,.4,.6],\n           'random_state': [0,1,2,3,4,5]}\n\ndt_clf = DecisionTreeClassifier()\ndt_parm = {'criterion':['gini', 'entropy'],\n          'random_state': [0,1,2,3,4,5]}\n\nknn_clf = KNeighborsClassifier()\nknn_parm = {'n_neighbors':[5, 10, 15, 20], \n            'weights':['uniform', 'distance'], \n            'p': [1,2]}\n\ngnb_clf = GaussianNB()\ngnb_parm = {'priors':['None']}\n\nclfs = [logi_clf, svm_clf, dt_clf, knn_clf]\nparams = [logi_parm, svm_parm, dt_parm, knn_parm] \nclf_names = ['logistic', 'SVM', 'DT', 'KNN', 'GNB']","61ea9ae0":"clfs_opt = []\nclfs_best_scores = []\nclfs_best_param = []\nfor clf_, param in zip(clfs, params):\n    clf = RandomizedSearchCV(clf_, param, cv=5)\n    clf.fit(X_train_sc, y_train_df)\n    clfs_opt.append(clf.best_estimator_)\n    clfs_best_scores.append(clf.best_score_)\n    clfs_best_param.append(clf.best_params_)","08373c59":"max(clfs_best_scores)","45960d56":"arg = np.argmax(clfs_best_scores)\nclfs_best_param[arg]","3ed30ca6":"gnb_score = cross_val_score(gnb_clf,X_train_sc, y_train_df, cv=5).mean()\ngnb_clf.fit(X_train_sc, y_train_df)\nclfs_opt.append(gnb_clf)\nclfs_best_scores.append(gnb_score)","781c5b5a":"all_Clfs_dict = {}\nall_Clfs_list = []\nfor name, clf in zip(clf_names, clfs_opt):\n    all_Clfs_dict[name] = clf\n    all_Clfs_list.append((name, clf))","681c2dd6":"max(clfs_best_scores)","bebeb1ad":"arg = np.argmax(clfs_best_scores)\nclfs_best_param[arg]","c7455f57":"clf = clfs_opt[arg]","0f649622":"clf","7be31945":"\"\"\"\"\npred = clf.predict(X_test_sc)\ntest_df = pd.read_csv(TEST_PATH)\ny_test_df = test_df['PassengerId']\ncols = ['PassengerId', 'Survived']\nsubmit_df = pd.DataFrame(np.hstack((y_test_df.values.reshape(-1,1),pred.reshape(-1,1))), \n                         columns=cols)\nsubmit_df.to_csv('submission_best_est.csv', index=False)\"\"\"\"","53957ddf":"submit_df.head()","4b936c16":"import sklearn.ensemble as ens ","34843dfb":"hard_voting_clf = ens.VotingClassifier(all_Clfs_list, voting='hard')\nhard_voting_clf.fit(X_train_sc, y_train_df)\ncross_val_score(hard_voting_clf,X_train_sc, y_train_df, cv=5).mean()","4f01872c":"\"\"\"\"\nclf = hard_voting_clf\npred = clf.predict(X_test_sc)\ntest_df = pd.read_csv(TEST_PATH)\ny_test_df = test_df['PassengerId']\ncols = ['PassengerId', 'Survived']\nsubmit_df = pd.DataFrame(np.hstack((y_test_df.values.reshape(-1,1),pred.reshape(-1,1))), \n                         columns=cols)\nsubmit_df.to_csv('submission_hard_voting_clf.csv', index=False)\"\"\"\"","2a93482c":"soft_voting_clf = ens.VotingClassifier(all_Clfs_list, voting='soft', weights=clfs_best_scores)\nsoft_voting_clf.fit(X_train_sc, y_train_df)\ncross_val_score(soft_voting_clf,X_train_sc, y_train_df, cv=5).mean()","0fa8ce6b":"\"\"\"\"\nclf = soft_voting_clf\npred = clf.predict(X_test_sc)\ntest_df = pd.read_csv(TEST_PATH)\ny_test_df = test_df['PassengerId']\ncols = ['PassengerId', 'Survived']\nsubmit_df = pd.DataFrame(np.hstack((y_test_df.values.reshape(-1,1),pred.reshape(-1,1))), \n                         columns=cols)\nsubmit_df.to_csv('submission_soft_voting_clf.csv', index=False)\"\"\"\"","471a4f2e":"clf = ens.BaggingClassifier(base_estimator=clfs_opt[arg])\nparam = {'n_estimators':[10,50,100,500,100],\n        'max_samples':[1.0, 0.9, 0.8],\n        'bootstrap_features':[False, True],\n        'random_state': [0,1,2,3,4,5]}\nbest_est_bagging = RandomizedSearchCV(clf, param, cv=5)\nbest_est_bagging.fit(X_train_sc, y_train_df)","48a782e8":"best_est_bagging.best_score_","7f28f052":"clf = best_est_bagging.best_estimator_\npred = clf.predict(X_test_sc)\ntest_df = pd.read_csv(TEST_PATH)\ny_test_df = test_df['PassengerId']\ncols = ['PassengerId', 'Survived']\nsubmit_df = pd.DataFrame(np.hstack((y_test_df.values.reshape(-1,1),pred.reshape(-1,1))), \n                         columns=cols)\nsubmit_df.to_csv('submission_bagging_best_clf.csv', index=False)","a3e1ff93":"\"\"\"\"\nclf = ens.RandomForestClassifier()\nparam = {'n_estimators':[10,50,100,500,100],\n         'criterion': ['gini', 'entropy'],}\nRF = RandomizedSearchCV(clf, param, cv=5)\nRF.fit(X_train_sc, y_train_df)\nRF.best_score_","0c2f7575":"\"\"\"\"\nclf = RF.best_estimator_\npred = clf.predict(X_test_sc)\ntest_df = pd.read_csv(TEST_PATH)\ny_test_df = test_df['PassengerId']\ncols = ['PassengerId', 'Survived']\nsubmit_df = pd.DataFrame(np.hstack((y_test_df.values.reshape(-1,1),pred.reshape(-1,1))), \n                         columns=cols)\nsubmit_df.to_csv('submission_RandomForest_clf.csv', index=False)\"\"\"\"","3db4bcf6":"#xtest=pd.concat([xtest, xtrain['Survived']])","d4b6a92e":"# Data Visualization","60a78924":"# Feature engineering","811c99c9":"### Random Forest","5d24648d":"* Categorical: Survived, Sex, and Embarked. Ordinal: Pclass. <br>\n* Continous: Age, Fare. <br>\n* Discrete: SibSp, Parch. <br>","76c279f5":"# Algorithms Training","737257b0":"### Hard Voting","523d05b6":"### Soft Voting","f0de1e56":"# Data Preprocessing","ad6eb460":"## Voting Ensembling","9f160768":"## Data Scaling","e92fd4a3":"# Lable Encoding","fe85c807":"# Ensempling Methods","f37199e3":"# OneHot Encoding","83cfb8c0":"## Bagging Ensembling","bc5c764a":"### Bagging Meta-estimator"}}