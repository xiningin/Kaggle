{"cell_type":{"f33eeb25":"code","8e0e2ac9":"code","26cf906b":"code","c3d45e55":"code","f3a19aa2":"code","d5e15d8a":"code","0c5574cc":"code","018d896c":"code","6e14ea08":"markdown","7d5a8f37":"markdown","cb2288d5":"markdown","4082a73d":"markdown","1591ef9f":"markdown","1ef58e90":"markdown","69acf304":"markdown","16ba9278":"markdown","54298cba":"markdown","b01506fa":"markdown","1fe7c319":"markdown","3340df6a":"markdown"},"source":{"f33eeb25":"import os\nimport numpy as np\nfrom scipy.fftpack import fft\nfrom scipy.io import wavfile\nfrom scipy import signal\nfrom glob import glob\nimport re\nimport pandas as pd\nimport gc\nfrom scipy.io import wavfile\n\nfrom keras import optimizers, losses, activations, models\nfrom keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom sklearn.model_selection import train_test_split\nimport keras","8e0e2ac9":"L = 16000\nlegal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n\n#src folders\nroot_path = r'..'\nout_path = r'.'\nmodel_path = r'.'\ntrain_data_path = os.path.join(root_path, 'input', 'train', 'audio')\ntest_data_path = os.path.join(root_path, 'input', 'test', 'audio')","26cf906b":"#FFT(Fast Fourier Transform)\ndef custom_fft(y, fs):\n    T = 1.0 \/ fs\n    N = y.shape[0]\n    yf = fft(y)\n    xf = np.linspace(0.0, 1.0\/(2.0*T), N\/\/2)\n    # FFT is simmetrical, so we take just the first half\n    # FFT is also complex, to we take just the real part (abs)\n    vals = 2.0\/N * np.abs(yf[0:N\/\/2])\n    return xf, vals\n\n#specgram? -> \uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8(spectrogram), \uc74c\uc131 \ub370\uc774\ud130\ub97c \ucc98\ub9ac\ud560 \ub54c \ub9ce\uc774 \ubcfc \uc218 \uc788\ub2e4.\n#\ud30c\ud615\uacfc \uc2a4\ud399\ud2b8\ub7fc\uc758 \ud2b9\uc9d5\uc774 \uacb0\ud569\ub41c \uac83\uc73c\ub85c, x\ucd95\uc740 \uc2dc\uac04, y\ucd95\uc740 \uc8fc\ud30c\uc218, z\ucd95\uc740 \uc9c4\ud3ed\uc744 \ub098\ud0c0\ub0c4. -> \uc18c\ub9ac\uc758 \uc2a4\ud399\ud2b8\ub7fc\uc744 \uc2dc\uac01\ud654\ud558\uc5ec \uadf8\ub798\ud504\ub85c \ud45c\ud604\ud558\ub294 \uae30\ubc95\n\n#specgram\uc744 \uacc4\uc0b0\ud558\ub294 \ud568\uc218(\ub85c\uadf8\ub97c \ucde8\ud55c\ub2e4)\n#\ub85c\uadf8\ub97c \ucde8\ud568\uc73c\ub85c\uc368 \uc5bb\ub294 \uc774\uc810? -> plot\uc744 \ud6e8\uc52c \uae54\ub054\ud558\uac8c \ud560 \uc218 \uc788\uace0, \uc0ac\ub78c\ub4e4\uc774 \ub4e3\ub294 \ubc29\uc2dd\uacfc \ube44\uc2b7\ud558\uac8c \ub9e4\uce6d\uc774 \ub420 \uac83.\n#\ub85c\uadf8\uc5d0 \ub300\ud55c \uc785\ub825 \uac12\uc73c\ub85c 0\uc774 \uc5c6\ub294\uc9c0 \ud655\uc778\ud574\uc57c \ud55c\ub2e4.\n\ndef log_specgram(audio, sample_rate, window_size=20,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate \/ 1e3))\n    noverlap = int(round(step_size * sample_rate \/ 1e3))\n    freqs, times, spec = signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return freqs, times, np.log(spec.T.astype(np.float32) + eps)","c3d45e55":"def list_wavs_fname(dirpath, ext='wav'):\n    print(dirpath)\n    fpaths = glob(os.path.join(dirpath, r'*\/*' + ext))\n    pat = r'.+\/(\\w+)\/\\w+\\.' + ext + '$'\n    labels = []\n    for fpath in fpaths:\n        r = re.match(pat, fpath)\n        if r:\n            labels.append(r.group(1))\n    pat = r'.+\/(\\w+\\.' + ext + ')$'\n    fnames = []\n    for fpath in fpaths:\n        r = re.match(pat, fpath)\n        if r:\n            fnames.append(r.group(1))\n    return labels, fnames","f3a19aa2":"def pad_audio(samples):\n    if len(samples) >= L: return samples\n    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n\ndef chop_audio(samples, L=16000, num=20):\n    for i in range(num):\n        beg = np.random.randint(0, len(samples) - L)\n        yield samples[beg: beg + L]\n\ndef label_transform(labels):\n    nlabels = []\n    for label in labels:\n        if label == '_background_noise_':\n            nlabels.append('silence')\n        elif label not in legal_labels:\n            nlabels.append('unknown')\n        else:\n            nlabels.append(label)\n    return pd.get_dummies(pd.Series(nlabels))","d5e15d8a":"labels, fnames = list_wavs_fname(train_data_path)\n\nnew_sample_rate = 8000\ny_train = []\nx_train = []\n\nfor label, fname in zip(labels, fnames):\n    sample_rate, samples = wavfile.read(os.path.join(train_data_path, label, fname))\n    samples = pad_audio(samples)\n    if len(samples) > 16000:\n        n_samples = chop_audio(samples)\n    else: n_samples = [samples]\n    for samples in n_samples:\n        resampled = signal.resample(samples, int(new_sample_rate \/ sample_rate * samples.shape[0]))\n        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n        y_train.append(label)\n        x_train.append(specgram)\nx_train = np.array(x_train)\nx_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\ny_train = label_transform(y_train)\nlabel_index = y_train.columns.values\ny_train = y_train.values\ny_train = np.array(y_train)\ndel labels, fnames\ngc.collect()","0c5574cc":"input_shape = (99, 81, 1)\nnclass = 12\ninp = Input(shape=input_shape)\nnorm_inp = BatchNormalization()(inp)\nimg_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(norm_inp)\nimg_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(img_1)\nimg_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\nimg_1 = Dropout(rate=0.2)(img_1)\nimg_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\nimg_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\nimg_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\nimg_1 = Dropout(rate=0.2)(img_1)\nimg_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\nimg_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\nimg_1 = Dropout(rate=0.2)(img_1)\nimg_1 = Flatten()(img_1)\n\ndense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(img_1))\ndense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(dense_1))\ndense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n\nmodel = models.Model(inputs=inp, outputs=dense_1)\nopt = optimizers.Adam()\n\nmodel.compile(optimizer=opt, loss=losses.binary_crossentropy)\nmodel.summary()\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=2017)\nmodel.fit(x_train, y_train, batch_size=16, validation_data=(x_valid, y_valid), epochs=3, shuffle=True, verbose=2)\n\nmodel.save(os.path.join(model_path, 'cnn.model'))","018d896c":"def test_data_generator(batch=16):\n    fpaths = glob(os.path.join(test_data_path, '*wav'))\n    i = 0\n    for path in fpaths:\n        if i == 0:\n            imgs = []\n            fnames = []\n        i += 1\n        rate, samples = wavfile.read(path)\n        samples = pad_audio(samples)\n        resampled = signal.resample(samples, int(new_sample_rate \/ rate * samples.shape[0]))\n        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n        imgs.append(specgram)\n        fnames.append(path.split('\\\\')[-1])\n        if i == batch:\n            i = 0\n            imgs = np.array(imgs)\n            imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n            yield fnames, imgs\n    if i < batch:\n        imgs = np.array(imgs)\n        imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n        yield fnames, imgs\n    raise StopIteration()","6e14ea08":"Train data folder \ub0b4\uc758 \ubaa8\ub4e0 wav file\uc744 \uac00\uc838\uc624\ub294 utility function","7d5a8f37":"\uc704\uc5d0\uc11c \uc120\uc5b8\ud55c \ud568\uc218\ub97c \uc774\uc6a9\ud574 X_train\uacfc y_train \uc0dd\uc131.\n\nlabel_index\ub294 pandas\uac00 \ub354\ubbf8 \uac12\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ud558\ub294 index\uc774\ubbc0\ub85c \ub098\uc911\uc5d0 \uc0ac\uc6a9\ud558\uae30 \uc704\ud574 \uc800\uc7a5\ud574\uc57c\ud568.","cb2288d5":"CNN \ub9cc\ub4e4\uae30.\n\n\uc0dd\uc131\ub41c specgram\ub4e4\uc740 (99, 81)\uc758 shape\uc778\ub370, Conv2D \uc5f0\uc0b0\uc744 \uc704\ud574\uc11c\ub294 \ubaa8\uc591\uc744 \ubcc0\uacbd\ud574\uc57c \ud55c\ub2e4.","4082a73d":"# Light-Weight CNN Tutorial (KOR)\n## Origin: https:\/\/www.kaggle.com\/alphasis\/light-weight-cnn-lb-0-74\n### Translated by siryuon","1591ef9f":"\ud6c8\ub828\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574 \uc608\uce21 \uc9c4\ud589.\n\nKaggle\uc740 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc81c\uacf5 x -> \uc9c4\ud589 \uc885\ub8cc.\n\n\uc774 \ub178\ud2b8\ubd81\uc740 wav file\uc758 Conv \uc5f0\uc0b0\uc5d0 \ub300\ud55c \uac1c\uad04\uc801\uc778 \ub0b4\uc6a9\uc774\ub77c\uace0 \ubcfc \uc218 \uc788\uc74c.","1ef58e90":"Test data\uac00 \ub108\ubb34 \ucee4\uc11c RAM\uc5d0 \uc798 \ub3cc\uc544\uac00\uc9c0 \uc54a\uc73c\ubbc0\ub85c \ud558\ub098\uc529 \ucc98\ub9ac\ud574\uc57c \ud55c\ub2e4.\n\nGenerator\uc778 test_data_generator\ub294 CNN\uc5d0 \ub123\uc744 \ud14c\uc2a4\ud2b8 wav file\uc758 \ubc30\uce58\ub97c \uc0dd\uc131.","69acf304":"Original Sample rate\ub294 16000. \uc5ec\uae30\uc11c\ub294 8000\uc73c\ub85c \uc904\uc5ec\uc900\ub2e4.","16ba9278":"pad_audio function\uc740 16000(1\ucd08) \ubbf8\ub9cc\uc758 \uc624\ub514\uc624\ub97c \ubaa8\ub450 \ub3d9\uc77c\ud55c \uae38\uc774\ub85c \ub9cc\ub4e4\uae30 \uc704\ud574 \uc81c\ub85c \ud328\ub529\uc744 \ud558\ub294 \ud568\uc218.  \n\nchop_audio function\ub294 \uae38\uc774\uac00 16000\ubcf4\ub2e4 \ud070 \uc624\ub514\uc624(ex. \ubc30\uacbd \uc18c\uc74c \ud3f4\ub354\uc758 wav file)\uc744 16000\uc73c\ub85c \uc798\ub77c\uc900\ub2e4. \ub610\ud55c, \ub9e4\uac1c\ubcc0\uc218 'num'\uc774 \uc9c0\uc815\ub41c \ud558\ub098\uc758 \ud070 wav file\uc5d0\uc11c \uc5ec\ub7ec chunk\ub97c \uc0dd\uc131.\n\nlabel_transform function\uc740 \ub808\uc774\ube14\uc744 \ub354\ubbf8 \uac12\uc73c\ub85c \ubcc0\ud658. \ub808\uc774\ube14\uc744 \uc608\uce21\ud558\uae30 \uc704\ud574 softmax\uc640 \ud568\uaed8 \uc0ac\uc6a9\ub41c\ub2e4.","54298cba":"DavidS\uac00 \uc791\uc131\ud588\ub358 function\uc778 custom_fft, log_specgram\uc744 \ubd88\ub7ec\uc628\ub2e4.  \nkaggle notebook: https:\/\/www.kaggle.com\/davids1992\/speech-representation-and-data-exploration\n\n\uc704 \ub178\ud2b8\ubd81\uc758 1.1\uc808(log_specgram), 1.5\uc808(custom_fft)\uc744 \ucc38\uace0.","b01506fa":"\ub370\uc774\ud130 \uc138\ud2b8\ub97c 8000\uc73c\ub85c \ub9ac\uc0d8\ud50c\ub9c1 \uac00\ub2a5 -> \uc911\uc694\ud558\uc9c0 \uc54a\uc740 \uc815\ubcf4\ub97c \ubc84\ub824 \ub370\uc774\ud130 \ud06c\uae30\ub97c \uc904\uc778\ub2e4. -> fft \uc0ac\uc6a9","1fe7c319":"\ubcf8 \ub178\ud2b8\ubd81\uc758 \ubaa9\ud45c -> \uacbd\ub7c9 CNN \uad6c\ucd95\n\ubcf8 \ub178\ud2b8\ubd81\uc5d0\uc11c\uc758 Input -> resampling\ub41c .wav file(rate 8000)\uc758 specgrams\n\n\ubcf8 \uce90\uae00 \ub178\ud2b8\ubd81\uc740 \ud558\ub4dc\uc6e8\uc5b4 \uc81c\ud55c\uc73c\ub85c \uc778\ud574 \uc6d0\ub798\uc758 \ucf54\ub4dc\uc640\ub294 \ub2e4\ub978 \ubc84\uc804.\n\n\ubcf8 \ub178\ud2b8\ubd81\uc73c\ub85c \uc5bb\uc740 \uacb0\uacfc\ub97c \ub611\uac19\uc774 \uc5bb\uc73c\ub824\uba74, epoch\ub97c 5\ub85c \uc124\uc815, chop_audio(num=1000)\uc744 \uc124\uc815\ud558\uace0, \ubaa8\ub4e0 Conv Layer\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \ub450 \ubc30 \ub298\ub824\uc57c \ud568.\n\n\ubcf8 \ub178\ud2b8\ubd81\uc740 Alex Ozerin\uc758 baseline\ubcf4\ub2e4 \uc57d\uac04 \uac1c\uc120\ub418\uc5c8\uc9c0\ub9cc, \uc6d0\ubcf8 .wav file(rate 16000)\uc744 \uc0ac\uc6a9\ud558\uba74 \ub354 \ub192\uc740 \uc810\uc218\ub97c \uc5bb\uc744 \uc218 \uc788\uc744 \uac83.","3340df6a":"\uacbd\ub7c9 CNN\uc774\uae30 \ub54c\ubb38\uc5d0 \uc131\ub2a5\uc774 \uc81c\ud55c\ub428.\n\n\uc131\ub2a5\uc744 \ub192\uc774\uae30 \uc704\ud574 \ud560 \uc218 \uc788\ub294 \ubc29\ubc95\ub4e4\n  - resampling file \ub300\uc2e0 \uc6d0\ubcf8 wav file \uc0ac\uc6a9\n  - chop_audio\ub97c \uc0ac\uc6a9\ud574 \ub354 \ub9ce\uc740 'silence' wav file \ub9cc\ub4e4\uae30\n  -  \ub354 \uae4a\uc740 CNN\uc744 \uc0ac\uc6a9\ud558\uac70\ub098 RNN \uc0ac\uc6a9\n  -  \ub354 \uae34 EPOCH\uc73c\ub85c \ud6c8\ub828"}}