{"cell_type":{"923dd904":"code","28bf38ac":"code","b91571af":"code","4c5763a7":"code","7ef4a696":"code","54479944":"code","40ec283f":"code","8b9aeae9":"code","f6052ee5":"code","1a88acf2":"code","cb666a1d":"code","8e192cee":"code","e377a953":"code","44585112":"code","ef9dd8ae":"code","bac200e8":"code","f65b7226":"code","2c6f4301":"code","d02315a6":"code","c582ff58":"code","762b5768":"code","ed9f1f1f":"code","6bfef418":"code","03b0816a":"code","c9d25096":"code","ed9fc4c2":"code","f6f95709":"code","d1230392":"code","98dedfb3":"code","203b1797":"code","652b7f23":"markdown","7f800d85":"markdown","0d507fda":"markdown","2d6d06b3":"markdown","b9030d4f":"markdown","34ba7691":"markdown","efe1ebf8":"markdown","51c94214":"markdown","a41a1385":"markdown","81d6458f":"markdown","0199c5f8":"markdown","3d4ceb3a":"markdown","c6e5d1bb":"markdown","198a3868":"markdown","fa4b2054":"markdown","3aca7fab":"markdown","3dcceaeb":"markdown","a6430ab0":"markdown","f72ad4a2":"markdown","5c69bf74":"markdown","0a858f43":"markdown","1162c5d3":"markdown","e8eaeb57":"markdown","eb9da587":"markdown","9831724e":"markdown","e0a08e31":"markdown","99965915":"markdown","e2a70df3":"markdown"},"source":{"923dd904":"import pandas as pd\nimport numpy as np\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/test.csv\")\n\nprint(train_data.info())\nprint(test_data.info())","28bf38ac":"footnote_text = \"One or more data cells have counts between 1-9 and have been suppressed in accordance with NCHS confidentiality standards.\"\nprint(train_data[train_data[\"COVID-19 Deaths\"].isna()].loc[train_data[\"Footnote\"] == footnote_text].info())\nprint(train_data[train_data[\"Total Deaths\"].isna()].loc[train_data[\"Footnote\"] == footnote_text].info())","b91571af":"train_data[\"COVID-19 Deaths\"].fillna(5, inplace=True)\ntrain_data[\"Total Deaths\"].fillna(5, inplace=True)\ntrain_data.drop(labels=\"Footnote\", axis=1, inplace=True)\nprint(train_data.info())","4c5763a7":"print(train_data[\"MMWR Week\"].unique())\nprint(train_data[\"Month\"].unique())\nprint(train_data[\"Year\"].unique())","7ef4a696":"import matplotlib.pyplot as plt\n\nprint(train_data[\"COVID-19 Deaths\"].describe())\nplt.boxplot(train_data[\"COVID-19 Deaths\"])\nplt.show()","54479944":"print(train_data[\"Total Deaths\"].describe())\nplt.clf()\nplt.boxplot(train_data[\"Total Deaths\"])\nplt.show()","40ec283f":"print(train_data[train_data[\"Group\"]==\"By Week\"][\"Total Deaths\"].describe(), \"\\n\")\n\nplt.clf()\nplt.boxplot(train_data[train_data[\"Group\"]==\"By Week\"][\"Total Deaths\"])\nplt.show()","8b9aeae9":"print(train_data[train_data[\"Group\"]==\"By Week\"][\"COVID-19 Deaths\"].describe())\n\nplt.clf()\nplt.boxplot(train_data[train_data[\"Group\"]==\"By Week\"][\"COVID-19 Deaths\"])\nplt.show()","f6052ee5":"print(train_data[train_data[\"Group\"]==\"By Week\"].loc[train_data[\"HHS Region\"]==\"United States\"][\"COVID-19 Deaths\"].describe())\n\nplt.clf()\nplt.boxplot(train_data[train_data[\"Group\"]==\"By Week\"].loc[train_data[\"HHS Region\"]==\"United States\"][\"COVID-19 Deaths\"])\nplt.show()","1a88acf2":"print(train_data[train_data[\"Group\"]==\"By Week\"].loc[train_data[\"HHS Region\"]==\"United States\"][\"Total Deaths\"].describe())\n\nplt.clf()\nplt.boxplot(train_data[train_data[\"Group\"]==\"By Week\"].loc[train_data[\"HHS Region\"]==\"United States\"][\"Total Deaths\"])\nplt.show()","cb666a1d":"hispanic = train_data[train_data[\"Race and Hispanic Origin Group\"]==\"Hispanic\"]\nhispanic_us = hispanic[hispanic[\"HHS Region\"]==\"United States\"]\nhispanic_us_week = hispanic_us[hispanic_us[\"Group\"]==\"By Week\"]\nhispanic_us_week_50 = hispanic_us_week[hispanic_us_week[\"Age Group\"]==\"50-64 years\"]\nplt.clf()\nplt.boxplot(hispanic_us_week_50[\"COVID-19 Deaths\"])\nplt.show()\nprint(hispanic_us_week_50[\"COVID-19 Deaths\"].describe())\noutliers = hispanic_us_week_50[\"COVID-19 Deaths\"].max() > hispanic_us_week_50[\"COVID-19 Deaths\"].mean()+hispanic_us_week_50[\"COVID-19 Deaths\"].std()*3\nprint(\"\\nOutliers in this subset:\", outliers)","8e192cee":"train_data = train_data[train_data[\"HHS Region\"]==\"United States\"]\nprint(train_data.info())","e377a953":"train_data = train_data[train_data[\"Group\"]==\"By Week\"]\ntrain_data.drop(labels=\"Month\", axis=1, inplace=True)\ntest_data.drop(labels=\"Month\", axis=1, inplace=True)\nprint(train_data.info(), \"\\n\")\nprint(test_data.info())","44585112":"print(train_data[\"Data As Of\"].unique())\nprint(train_data[\"HHS Region\"].unique())\nprint(train_data[\"Group\"].unique())\n\nprint(test_data[\"Data As Of\"].unique())\nprint(test_data[\"HHS Region\"].unique())\nprint(test_data[\"Group\"].unique())","ef9dd8ae":"train_data.drop(labels=[\"Data As Of\", \"HHS Region\", \"Group\"], axis=1, inplace=True)\ntest_data.drop(labels=[\"Data As Of\", \"HHS Region\", \"Group\"], axis=1, inplace=True)\nprint(train_data.info(), \"\\n\")\nprint(test_data.info())","bac200e8":"print(train_data[[\"Start Date\", \"End Date\", \"Week-Ending Date\"]].head())","f65b7226":"train_data.drop(labels=[\"End Date\", \"Week-Ending Date\", \"MMWR Week\", \"Year\"], axis=1, inplace=True)\ntest_data.drop(labels=[\"End Date\", \"Week-Ending Date\", \"MMWR Week\", \"Year\"], axis=1, inplace=True)\n\nprint(train_data.info(), \"\\n\")\nprint(test_data.info())","2c6f4301":"test_ids = test_data.id\ntrain_data.drop(labels=\"id\", axis=1, inplace=True)\ntest_data.drop(labels=\"id\", axis=1, inplace=True)\n\nprint(train_data.info(), \"\\n\")\nprint(test_data.info())","d02315a6":"train_data = pd.get_dummies(train_data, columns = [\"Race and Hispanic Origin Group\"])\ntest_data = pd.get_dummies(test_data, columns = [\"Race and Hispanic Origin Group\"])\n\nprint(train_data.info(), \"\\n\")\nprint(test_data.info())","c582ff58":"labels = [\"0-4 years\", \"5-17 years\", \"18-29 years\", \"30-39 years\", \"40-49 years\", \"50-64 years\", \"65-74 years\", \"75-84 years\", \"85 years and over\"]\ni = 0\nfor label in labels:\n    train_data.replace(label, i, inplace=True)\n    test_data.replace(label, i, inplace=True)\n    i+=1\n\nprint(train_data[\"Age Group\"].head(18))","762b5768":"train_data[\"Week\"] = train_data.groupby(\"Start Date\", sort=False).ngroup()\ntest_data[\"Week\"] = test_data.groupby(\"Start Date\", sort=False).ngroup()\n\ntrain_data.drop(labels=\"Start Date\", axis=1, inplace=True)\ntest_data.drop(labels=\"Start Date\", axis=1, inplace=True)\n\nprint(train_data.info(), \"\\n\")\nprint(test_data.info())","ed9f1f1f":"plt.clf\nplt.scatter(train_data[\"Age Group\"], train_data[\"COVID-19 Deaths\"])\nplt.xlabel(\"Age Group\")\nplt.ylabel(\"COVID-19 Deaths\")\nplt.show()","6bfef418":"plt.clf\nplt.scatter(train_data[\"Total Deaths\"], train_data[\"COVID-19 Deaths\"])\nplt.xlabel(\"Total Deaths\")\nplt.ylabel(\"COVID-19 Deaths\")\nplt.show()","03b0816a":"plt.clf\nplt.scatter(train_data[\"Week\"], train_data[\"COVID-19 Deaths\"])\nplt.show()","c9d25096":"print(train_data[\"Week\"].unique())\ntest_data[\"Week\"] += 22\nprint(test_data[\"Week\"].unique())","ed9fc4c2":"from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nX = train_data.drop(\"COVID-19 Deaths\", axis=1)\ny = train_data[\"COVID-19 Deaths\"]\n\nss = StandardScaler()\n\n# A high tolerance on the lasso and en pipes is necessary to avoid convergence warnings. Increasing max_iter greatly increases\n# run-time but does not improve model performance or avoid convergence warnigns. Increasing tolerance keeps a small run-time\n# and avoids convergence errors but model performance suffers. \nlr_pipe = Pipeline([('scaler', StandardScaler()), ('lr', LinearRegression())])\nlasso_pipe = Pipeline([('scaler', StandardScaler()), ('lasso', Lasso())])\nridge_pipe = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())])\nen_pipe = Pipeline([('scaler', StandardScaler()), ('en', ElasticNet())])\n\nlasso_param_grid = {\"lasso__alpha\": [0.1, 1, 10, 20, 50]}\nridge_param_grid = {\"ridge__alpha\": [1e-6, 1e-4, 1e-2, 1, 10]}\nen_param_grid = {\"en__alpha\": [0.1, 1, 10], \"en__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]}\n\nlr_tscv = TimeSeriesSplit(n_splits=10).split(X)\nlasso_tscv = TimeSeriesSplit(n_splits=10).split(X)\nen_tscv = TimeSeriesSplit(n_splits=10).split(X)\nridge_tscv = TimeSeriesSplit(n_splits=10).split(X)\n\nlasso_search = GridSearchCV(lasso_pipe, lasso_param_grid, cv=lasso_tscv, scoring=\"neg_root_mean_squared_error\")\nridge_search = GridSearchCV(ridge_pipe, ridge_param_grid, cv=ridge_tscv, scoring=\"neg_root_mean_squared_error\")\nen_search = GridSearchCV(en_pipe, en_param_grid, cv=en_tscv, scoring=\"neg_root_mean_squared_error\")\n\nlr_pipe.fit(X, y)\nlasso_search.fit(X, y)\nridge_search.fit(X, y)\nen_search.fit(X, y)\n\nlr_scores = pd.DataFrame(- cross_val_score(lr_pipe, X, y, cv=lr_tscv, scoring=\"neg_root_mean_squared_error\"))\nlasso_scores = pd.DataFrame(- lasso_search.cv_results_[\"mean_test_score\"])\nridge_scores = pd.DataFrame(- ridge_search.cv_results_[\"mean_test_score\"])\nen_scores = pd.DataFrame(- en_search.cv_results_[\"mean_test_score\"])\nprint(\"Linear Regression \\n\", lr_scores.describe())\nprint(\"\\nLasso Regression \\n\", lasso_scores.describe())\nprint(\"\\nRidge Regression \\n\", ridge_scores.describe())\nprint(\"\\nElasticNet Regression \\n\", en_scores.describe())","f6f95709":"import seaborn as sns\nplt.clf()\nsns.displot(lr_scores, legend=False)\nplt.title(\"Ordinary Least Squares\")\nplt.xlabel(\"RMSE\")\nplt.show()","d1230392":"lasso_tscv = TimeSeriesSplit(n_splits=10).split(X)\nlasso_scores = pd.DataFrame(- cross_val_score(lasso_search.best_estimator_, X, y, cv=lasso_tscv, scoring=\"neg_root_mean_squared_error\"))\nprint(\"\\nLasso Regression \\n\", lasso_scores.describe())\n\nridge_tscv = TimeSeriesSplit(n_splits=10).split(X)\nridge_scores = pd.DataFrame(- cross_val_score(ridge_search.best_estimator_, X, y, cv=ridge_tscv, scoring=\"neg_root_mean_squared_error\"))\nprint(\"\\nRidge Regression \\n\", ridge_scores.describe())\n\nen_tscv = TimeSeriesSplit(n_splits=10).split(X)\nen_scores = pd.DataFrame(- cross_val_score(en_search.best_estimator_, X, y, cv=en_tscv, scoring=\"neg_root_mean_squared_error\"))\nprint(\"\\nElasticNet Regression \\n\", en_scores.describe())\n\nplt.clf()\nsns.displot(lasso_scores, legend=False)\nplt.title(\"Lasso\")\nplt.xlabel(\"RMSE\")\nplt.show()\n\nplt.clf()\nsns.displot(ridge_scores, legend=False)\nplt.title(\"Ridge\")\nplt.xlabel(\"RMSE\")\nplt.show()\n\nplt.clf()\nsns.displot(ridge_scores, legend=False)\nplt.title(\"ElasticNet\")\nplt.xlabel(\"RMSE\")\nplt.show()","98dedfb3":"print(lasso_search.best_params_)","203b1797":"subset = train_data[train_data[\"Week\"]>=21]\nsubset = subset[subset[\"Week\"]<=38]\nX = subset.drop(\"COVID-19 Deaths\", axis=1)\ny = subset[\"COVID-19 Deaths\"]\n\nlasso_search.best_estimator_.fit(X, y)\n\nX_test = test_data\npredictions = lasso_search.best_estimator_.predict(X_test)\npredictions[predictions<0] = 0\noutput = pd.DataFrame({'id': test_ids, 'COVID-19 Deaths': predictions})\nprint(output.shape)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","652b7f23":"Plotting Age Group against COVID-19 Deaths we can clearly see that older people had many more weeks with more deaths, whereas people in Age Groups 0, 1, and 2 had almost no deaths relative to the others. There also seems to be a correlation between Total Deaths and COVID-19 Deaths:","7f800d85":"As Race and Hispanic Origin Group has been encoded, it's unwieldy to plot or print a correlation matrix for. I do, however, know from outside knowledge of this data that coronavirus has affected minority racial groups worse than non-minority racial groups. ","0d507fda":"Kaggle Username: skylarmarosi\n","2d6d06b3":"# Feature Selection and Engineering\nNow that the data is free of missing values and some scale based outliers, it's time to select which features to use for the models, see if any features can be engineered, and possibly standardize the data. There are several redundant and noninformative features in this data that can be dropped outright.","b9030d4f":"# Loading in the Data","34ba7691":"By plotting the Week against COVID-19 Deaths, we can see the spread of the disease and peaks where deaths were high:","efe1ebf8":"# Exploring Outliers\nBy their nature, id, Data As Of, Start Date, End Date, Group, Year, Month, MMWR Week, Week-Ending Date, HHS Region, Race and Hispanic Origin Group, Age Group, and Footnote can't have outliers.","51c94214":"Additionally, I'll add 22 to the test weeks since 0 would imply the beginning to the model. ","a41a1385":"At the end of this process, despite the huge number of entries we dropped, we still have a healthy number of training data points, 5328. This still leaves us with a train dataset that is ~460% larger than the test set. \n\nAs for the scale difference created by the difference in size of age and racial groups, standardization may need to be done. Either way, this is important and relevant information that the test data takes into account and that we cannot drop. ","81d6458f":"Now that we've removed all of the irrelevant features, it's time to add some relevant ones. Since Race and Hispanic Origin Group is categorical, it needs to be One Hot Encoded into numbers for the model to interpret.","0199c5f8":"Even when we plot just the entries on the time scale of a week, we get confusing results. The .describe() function shows maximums that are far outside 3 standard deviations of the mean, but when plotting the data we see a relatively smooth distribution up to the maximum for both features.\n\nThis is occuring for several reasons. One is that the data is divided into deaths by race, and there are many more of some races than others in America (Non-Hispanic White vs. Non-Hispanic American Indian or Alaska Native, for instance). Another is that the train data has 11 categories for the feature HHS Region, 1-10 and \"United States\". The numbers 1 through 10 correspond to different regions of the country, and \"United States\" means that that entry is considering deaths throughout all of the United States. Once again, we are considering data on different scales (and redundant data). ","3d4ceb3a":"# Exploring Missing Values\nIn the train data, Month is missing the vast majority of values since most rows are grouped by week rather than by month. The month could be retrieved from most columns grouped by week by extracting it from the starting date, except that some weeks start in one month and end in another. Month also must be missing for entries grouped by year. Since the test data is all grouped by week, I will likely remove the Month feature and all entries not grouped by week (I'll do this in a later section since that data might still be interesting to explore).\n\nMMWR Week and Week-Ending date both have a number of values equal to the number of rows grouped by week, and are missing values for those grouped by month and year. Since these are week specific, they cannot be imputed where missing. Since these missing values have to be missing by definition, either the features must be dropped, or the rows with missing values (i.e. those grouped by month or year) must be dropped. Since the test data is all grouped by week, I will likely remove the rows with missing values as they are on a different time scale (I'll do this later as well).\n\nCOVID-19 Deaths and Total Deaths also have a significant amount of missing values. Whenever a value in one or both of these columns, a footnote is present.","c6e5d1bb":"We can do the same for the other models by evaluating the best estimator found by GridSearchCV with a cross validation score. ","198a3868":"As a first impression, all four models have similar performance, with Lasso and ElasticNet having a higher RMSE than Ridge and Linear Regression. Simple Ordinary Least Squares has the lowest mean RMSE, although this doesn't mean that it performed the best. In fact, this data is a little misleading since it represents two different types of testing. The Linear Regression scores represent the distribution of scores across 10 time fold validations. The scores for the other models represent the distribution of mean scores across some number of models with differing hyperparameters. That's why the Linear Regression standard deviation is so much higher than that of the other models. The way we ultimately want to view our models is the first way, which we can already do with Linear Regression.","fa4b2054":"The test data also has all entries grouped by week, which means we need to drop the train entries that are grouped by month or year. Again, this doesn't lose any information since months and years are an arbitrary way of dividing up the information that we already have in the form of weeks. We can also drop the month column from the train and test datasets.","3aca7fab":"Age Group is also categorical in this dataset, but unlike Race and Hispanic Origin Group it is hierarchical. This is true for this specific question as well, since we know coronavirus is more severe for old people than young people. Thus, we can encode Age Group using ascending labels. ","3dcceaeb":"Now, we finally have a dataset with engineered features such that every feature is of type integer or float. There are also no redundant features, meaning every feature should be useful to us.","a6430ab0":"The footnote tells us that the values are missing because presenting them would violate NCHS confidentiality standards, and that the values would be between 1 and 9. We can thus replace each of the missing values with 5 or an individually generated random number from 1 to 9. I'll tentatively use 5 to fill in the missing values, but both approaches could be tested. \n\nThere are many missing values for the Footnote column, representing rows where information was not suppressed. This column could simply be encoded as a binary variable where 1 means the footnote is present and 0 means it is not. Another way to deal with the missing values is by simply dropping this feature since the information it represents will be imputed in the COVID-19 Deaths and Total Deaths columns. It also is not present in the test data. \n\nIn the test data, no values are missing except in the Month column, where all values are missing. Given that some weeks start in one month and end in another, this would be a messy metric were we to extract it from the Start Date. Notably, all entries in the test data are grouped by week. The Month column will thus be dropped from test data. ","f72ad4a2":"One final thing affecting the outliers in the data set is that the mean and standard deviation are skewed low since coronavirus deaths weren't recorded in the US until March of 2020 (espcially for COVID-19 Deaths but for both COVID-19 Deaths and Total Deaths, since COVID-19 heavily influenced Total Deaths).\n\nAs for what to do about the features affecting the scale of the death, the test set sheds some light on the issue. All entries in the test set are in the HHS Region \"United States\", meaning the model is not expected to use regional information to predict weekly deaths. This means that we can drop all entries in the train data that have a region other than \"United States\". This brings our number of entries down from 72,864 to 6624 (a tenth of the remainder, 66240, since it's the combination of 10 regions). Thankfully, this dramatic reduction in the number of entries doesn't lose any important information since our model doesn't need to know which region the deaths are coming from, just the total in the United States. ","5c69bf74":"\"id\" is not useful information for our models, so it's removed from the datasets but stored as a variable for final submission.","0a858f43":"This data is more reasonable (we can actually see the box in the box plot), but there is still a clear scale difference. If we subset the data to find the deaths for one race, on the time scale of a week, in the entire U.S., in a specific age group (which was also contorting the data, since there are more people from 18-29 than there are 85+ year olds, for instance), we finally get a box plot with a familiar shape:","1162c5d3":"Which leaves COVID-19 Deaths and Total Deaths as the columns to explore for outliers.","e8eaeb57":"We can also encode the start date to be a more useful ascending integer. ","eb9da587":"Start Date, End Date, and Week-Ending Date all essentially contain the same information but in different forms. MMWR Week and Year are not especially insightful when we already have the actual date. Only one of these features needs to be kept.","9831724e":"At first, it appears that both columns have some large outliers that demand consideration. However, this may be because we are putting deaths per week, deaths per month, and deaths per year on the same plot. ","e0a08e31":"# Building the Models\nNow it's time to build and evaluate four machine learning models to predict the test data. Those four models are Ordinary Least Squares Linear Regression, Ridge Regression, Lasso Regression, and Elastic Net Regression. As one final bit of data processing, the data is standardized using StandardScaler in a pipeline. Then, the models iteratively search through combinations of model-specific hyperparameters to see which provide the best score.","99965915":"These three columns have only one value repeated throughout the entire dataset, so they give us no additional information and can be dropped. ","e2a70df3":"# Selecting the Best Model to Generate Submission\nNow, all four models have had RMSE computed in the same way and plotted in the same way. Actually, not only were they plotted with the same method, but the plots all look remarkably similar, as do the summary statistics. Hyperparameter tuning and model selection, at least amongst these hyperparameters within these models, seems to have frustratingly little effect on the final performance. All models have average RMSEs in the upper 200s, standard deviations of about 190, and similiar minimums and maximums. The best model for all of these metrics, by a small margin, is the lasso model, with an alpha value of 10.\n\nAs for the distributions, each model has 4 instances of an RMSE roughly from 100 to 200, 3 instances of an RMSE from 200 to 300, 2 instances of an RMSE from 400 to 500, and 1 instances of an RMSE from 500 to 600. Why is the data this spread out? It's because of inherent flaws in some of the cross validation splits. If a linear model is tested on a time interval when coronavirus deaths are more symmetrical or linear, it will perform much better than on a time interval when coronavirus deaths have a more complex shape. We can use this fact to our advantage when generating test scores. By training the model on a small subset of recent data, we can predict a linear continuation of the current trend. Any deaths predicted below 0 (which will happen with a linear model that has a downward slope) are changed to 0. This method gives decent results with the test data. The regular Lasso Pipeline is used since it had the best summary statistics."}}