{"cell_type":{"5736fdf7":"code","8edeaf98":"code","ef826222":"code","971c6364":"code","5bac4d3a":"code","085d32ab":"code","ef3627c6":"code","6f6be305":"code","0363c367":"code","f31303b0":"markdown","3a8b49e0":"markdown","61148fe3":"markdown","0e77476b":"markdown"},"source":{"5736fdf7":"!pip install keras_applications gdown tensorflow_addons","8edeaf98":"import tensorflow as tf\nfrom tensorflow import keras\nfrom kaggle_datasets import KaggleDatasets\nimport numpy as np\n\nprint(\"Tensorflow version \" + tf.__version__)\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path() # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\"\nIMAGE_SIZE = [256, 256] # at this size, a GPU will run out of memory. Use the TPU\nEPOCHS = 30\nBATCH_SIZE = 128\n\nAUTO = tf.data.experimental.AUTOTUNE","ef826222":"MODEL_NAME = 'vggface'\n\ndef decode_image_test(image_data):\n    image = tf.io.decode_raw(image_data, tf.uint8)\n    image = tf.cast(image, tf.float32)  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [1024, 1024, 3]) # explicit size needed for TPU\n    image = tf.image.resize(image, IMAGE_SIZE)\n    \n    if MODEL_NAME == 'vggface':\n        image = tf.stack([image[..., 0] - 91.4953,\n                          image[..., 1] - 103.8827,\n                          image[..., 2] - 131.0912],\n                         axis = -1)\n    elif MODEL_NAME == 'vgg19':\n        image = tf.keras.applications.vgg19.preprocess_input(image)\n    elif MODEL_NAME == 'inception':\n        image = tf.keras.applications.inception_v3.preprocess_input(image)\n    elif MODEL_NAME == 'xception':\n        image = tf.keras.applications.xception.preprocess_input(image)\n    else:\n        raise Exception('No MODEL_NAME Specified!')\n    return image\n    \n\ndef read_labeled_tfrecord_test(example):\n    \n    LABELED_TFREC_FORMAT = {\n        \"id\": tf.io.FixedLenFeature([], tf.string), \n        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring\n        \"bmi\": tf.io.FixedLenFeature([], tf.float32),\n        'sex': tf.io.FixedLenFeature([], tf.string),\n    }\n    \n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image_test(example['image'])\n    sex = tf.cast(example['sex'], tf.string)\n    \n    \n    label = tf.cast(example['bmi'], tf.float32)\n    return image, label, sex # returns a dataset of (image, label) pairs\n\ndef get_test_dataset():\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(GCS_DS_PATH + '\/test.tfrec'), num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord_test, num_parallel_calls=AUTO)\n    dataset = dataset.map(lambda x, y, z: (x, y))\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\n\ndef get_test_dataset_males():\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(GCS_DS_PATH + '\/test.tfrec'), num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord_test, num_parallel_calls=AUTO)\n    dataset = dataset.filter(lambda x, y, z: z == b'Male')\n    dataset = dataset.map(lambda x, y, z: (x, y))\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset_females():\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(GCS_DS_PATH + '\/test.tfrec'), num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord_test, num_parallel_calls=AUTO)\n    dataset = dataset.filter(lambda x, y, z: z == b'Female')\n    dataset = dataset.map(lambda x, y, z: (x, y))\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ntest_dataset = get_test_dataset()\ntest_dataset_male = get_test_dataset_males()\ntest_dataset_female = get_test_dataset_females()\n","971c6364":"import matplotlib.pyplot as plt\n\nfor x, y in test_dataset_female:\n    break\n    \nplt.imshow(x[5])","5bac4d3a":"import matplotlib.pyplot as plt\n\nfor x, y in test_dataset_male:\n    break\n    \nplt.imshow(x[5])","085d32ab":"from tensorflow.keras.models import model_from_json\nimport json\nimport tensorflow_addons as tfa\n\n!gdown --id \"1vduJ8iyMRM6IdVL_4Lq5lQyVDDu4X9u8\" -O vgg19.json\n!gdown --id \"1hLnHMfCAuA-xn32e_VRCBfx3DdtHyU4-\" -O vgg19.h5\n\nwith open(\"\/kaggle\/working\/vgg19.json\", 'r') as f: json_data = json.load(f)\n    \nMODEL_NAME = 'vgg19'\ntest_dataset = get_test_dataset()\ntest_dataset_male = get_test_dataset_males()\ntest_dataset_female = get_test_dataset_females()\n\npredictor = model_from_json(json.dumps(json_data))\npredictor.load_weights(\"\/kaggle\/working\/vgg19.h5\")\npredictor.compile(loss = 'mean_squared_error', metrics=['mean_absolute_error'])\n\nprint(f\"{'='*50} Male MAE {'='*50}\")\npredictor.evaluate(test_dataset_male)\nprint(f\"{'='*50} Female MAE {'='*50}\")\npredictor.evaluate(test_dataset_female)\nprint(f\"{'='*50} Overall MAE {'='*50}\")\npredictor.evaluate(test_dataset)","ef3627c6":"from tensorflow.keras.models import model_from_json\nimport json\nimport tensorflow_addons as tfa\n\n!gdown --id \"10AvmpAgXvYfmzBeavaqR3gon4duTQhrk\" -O xception.json\n!gdown --id \"1noNyV3tZzAyUdy0GCyzt5WCFa3IvOYUr\" -O xception.h5\n\nwith open(\"\/kaggle\/working\/xception.json\", 'r') as f: json_data = json.load(f)\n    \nMODEL_NAME = 'xception'\ntest_dataset = get_test_dataset()\ntest_dataset_male = get_test_dataset_males()\ntest_dataset_female = get_test_dataset_females()\n\npredictor = model_from_json(json_data)\npredictor.load_weights(\"\/kaggle\/working\/xception.h5\")\npredictor.compile(loss = 'mean_squared_error', metrics=['mean_absolute_error'])\n\nprint(f\"{'='*50} Male MAE {'='*50}\")\npredictor.evaluate(test_dataset_male)\nprint(f\"{'='*50} Female MAE {'='*50}\")\npredictor.evaluate(test_dataset_female)\nprint(f\"{'='*50} Overall MAE {'='*50}\")\npredictor.evaluate(test_dataset)","6f6be305":"from tensorflow.keras.models import model_from_json\nimport json\nimport tensorflow_addons as tfa\n\n!gdown --id \"1Ug9ff2SH1LeYk8QvObvFrwB54T9np6Lb\" -O inception.json\n!gdown --id \"1kTYtc8ANbmBncN0Zp9WgKs8m2mTic3Nc\" -O inception.h5\n\nwith open(\"\/kaggle\/working\/inception.json\", 'r') as f: json_data = json.load(f)\n\nMODEL_NAME = 'inception'\ntest_dataset = get_test_dataset()\ntest_dataset_male = get_test_dataset_males()\ntest_dataset_female = get_test_dataset_females()\n    \npredictor = model_from_json(json_data)\npredictor.load_weights(\"\/kaggle\/working\/inception.h5\")\npredictor.compile(loss = 'mean_squared_error', metrics=['mean_absolute_error'])\n\nprint(f\"{'='*50} Male MAE {'='*50}\")\npredictor.evaluate(test_dataset_male)\nprint(f\"{'='*50} Female MAE {'='*50}\")\npredictor.evaluate(test_dataset_female)\nprint(f\"{'='*50} Overall MAE {'='*50}\")\npredictor.evaluate(test_dataset)","0363c367":"from tensorflow.keras.models import model_from_json\nimport json\nimport tensorflow_addons as tfa\n\n!gdown --id \"1EQSRM1qfHOPl8Q-CgRvFAIMIUWxyfXY6\" -O vggresnet50.json\n!gdown --id \"1MOPpCKeTHWnOHiSMc6LAcXQ0jyxEAB7v\" -O vggresnet50.h5\n\nwith open(\"\/kaggle\/working\/vggresnet50.json\", 'r') as f: json_data = json.load(f)\n    \n\nMODEL_NAME = 'vggface'\ntest_dataset = get_test_dataset()\ntest_dataset_male = get_test_dataset_males()\ntest_dataset_female = get_test_dataset_females()\n\npredictor = model_from_json(json_data)\npredictor.load_weights(\"\/kaggle\/working\/vggresnet50.h5\")\npredictor.compile(loss = 'mean_squared_error', metrics=['mean_absolute_error'])\n\nprint(f\"{'='*50} Male MAE {'='*50}\")\npredictor.evaluate(test_dataset_male)\nprint(f\"{'='*50} Female MAE {'='*50}\")\npredictor.evaluate(test_dataset_female)\nprint(f\"{'='*50} Overall MAE {'='*50}\")\npredictor.evaluate(test_dataset)","f31303b0":"# InceptionV3","3a8b49e0":"# VGG19 ","61148fe3":"# Xception","0e77476b":"# VGG Face"}}