{"cell_type":{"df2c34d3":"code","5a1ab498":"code","f1de3dbf":"code","7be88345":"code","a2d0d5fb":"code","43f9aeba":"code","45551499":"code","ee9a0739":"code","a8ab931a":"code","c5748efe":"code","f8ab72c1":"code","ec5e5ffa":"code","e435bccc":"code","4c8be2b5":"code","459c977b":"code","d5638b6a":"code","a226ea6e":"code","dbff93c2":"code","51101dba":"code","711ae440":"code","4eb209a9":"code","0bb2a8f0":"code","4d72f4b1":"code","dc89d4a4":"code","c2e99866":"code","416f2e08":"code","1be38d95":"code","5d60e7d3":"code","58e9b210":"code","0f019d8f":"code","5f6d91d9":"code","848f3d45":"code","fd2c10ad":"code","755590db":"code","df2099be":"code","99d47e60":"code","d61b8813":"code","55a82b7c":"code","9901fff7":"code","2aaeca75":"code","bd88e0f8":"code","6d6da2e1":"code","a94bb56b":"code","490fc867":"code","8c421061":"code","c8b3d676":"code","d6aa8919":"code","e1087fa7":"code","b0c8eccd":"code","b86a4693":"code","6f0779f1":"code","bfede863":"code","01e1265c":"code","c7b9961a":"code","63c7cb71":"code","f8862739":"code","1406730e":"code","fe86e9ff":"code","1b80de1a":"code","2e368706":"code","26cc42de":"code","406f5b55":"code","1bc1c59c":"markdown","a331b7d9":"markdown","07d87959":"markdown","291e825d":"markdown","27af3f7b":"markdown","adb39f30":"markdown","343ab5a8":"markdown"},"source":{"df2c34d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# indicates that we want our plots to be shown in our notebook and not in a sesparate viewer\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5a1ab498":"data_path='.\/..\/input\/nassCDS.csv'\ndata=pd.read_csv(data_path)\n","f1de3dbf":"data.describe()","7be88345":"data.head()","a2d0d5fb":"#drop the column unnamed because if of no relievant \ndata.drop('Unnamed: 0', axis=1, inplace=True)\n#replace the incorrect values with correct ones\ndata['dvcat'].replace('1-9km\/h','1-9',inplace=True)\ndata.head()\n","43f9aeba":"#filling the missing with the median value.\ndata.fillna( data.median(),inplace=True )\ndata.isnull().sum()","45551499":"def create_label_encoder_dict(df):\n    from sklearn.preprocessing import LabelEncoder\n    \n    label_encoder_dict = {}\n    for column in df.columns:\n        # Only create encoder for categorical data types\n        if not np.issubdtype(df[column].dtype, np.number) and column != 'Age':\n            label_encoder_dict[column]= LabelEncoder().fit(df[column])\n    return label_encoder_dict","ee9a0739":"label_encoders = create_label_encoder_dict(data)\nprint(\"Encoded Values for each Label\")\nprint(\"=\"*32)\nfor column in label_encoders:\n    print(\"=\"*32)\n    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))\n    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_))","a8ab931a":"# Apply each encoder to the data set to obtain transformed values\ndata2 = data.copy() # create copy of initial data set\nfor column in data2.columns:\n    if column in label_encoders:\n        data2[column] = label_encoders[column].transform(data2[column])\nprint(\"Transformed data set\")\nprint(\"*\"*20)\ndata2.head()","c5748efe":"data_agg=data2.groupby([\"yearVeh\"],as_index=False).agg({\"deploy\": \"sum\"})\nax=data_agg.plot('yearVeh', 'deploy', kind='bar', figsize=(17,5), color='#86bf91', zorder=2, width=0.85)\nax.set_xlabel(\"Year\", labelpad=20, size=12)\n# Set y-axis label\nax.set_ylabel(\"deploy\", labelpad=20, size=12)\nax.legend_.remove()\n","f8ab72c1":"data_agg=data2.groupby([\"dead\"],as_index=False).agg({\"seatbelt\": \"sum\"})\nax=data_agg.plot('dead', 'seatbelt', kind='bar', figsize=(17,5), color='blue', zorder=2, width=0.85)\nax.set_xlabel(\"dead\", labelpad=20, size=12)\n# Set y-axis label\nax.set_ylabel(\"seatbelt\", labelpad=20, size=12)\nax.legend_.remove()\n\n","ec5e5ffa":"data_agg=data2.groupby([\"yearVeh\"],as_index=False).agg({\"airbag\": \"sum\"})\nax=data_agg.plot('yearVeh', 'airbag', kind='bar', figsize=(17,5), color='#86bf91', zorder=2, width=0.85)\nax.set_xlabel(\"Year\", labelpad=20, size=12)\n# Set y-axis label\nax.set_ylabel(\"airbag present\", labelpad=20, size=12)\nax.legend_.remove()\n","e435bccc":"acc_count = data2.groupby(data2.injSeverity).injSeverity.count().plot(kind = 'bar')","4c8be2b5":"data.shape","459c977b":"data.columns","d5638b6a":"#comparing the dead between the deployment of airbag\nax=data['ageOFocc'].plot(kind='hist')\nax.set_xlabel(\"Age of Occupant\", labelpad=20, size=12)","a226ea6e":"sns.countplot(x='dead',hue='seatbelt', data=data)","dbff93c2":"sns.countplot(x='dead',hue='airbag', data=data)","51101dba":"x_data= data2[['airbag','seatbelt','deploy','frontal', 'sex', 'weight','ageOFocc', 'yearacc', 'yearVeh',\n       'injSeverity']]\ny_data=data2['dead']","711ae440":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.30)","4eb209a9":"# Import linear model package (has several regression classes)\nfrom sklearn.linear_model import LogisticRegression","0bb2a8f0":"# Create an instance of linear regression\nreg = LogisticRegression()","4d72f4b1":"reg.fit(X_train,y_train)","dc89d4a4":"test_predicted = reg.predict(X_test)\ntest_predicted","c2e99866":"reg.coef_","416f2e08":"from sklearn.metrics import mean_squared_error, r2_score, classification_report, accuracy_score","1be38d95":"classification_report(y_test,test_predicted)","5d60e7d3":"from sklearn.metrics import confusion_matrix","58e9b210":"#\ncm = confusion_matrix(y_test,test_predicted)","0f019d8f":"#explaining how accurate is the predictions\nscore=accuracy_score(y_test,test_predicted)","5f6d91d9":"# The mean squared error\nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, test_predicted))","848f3d45":"#Explained variance score: 1 is perfect prediction\n# R squared\nprint('Variance score: %.2f' % r2_score(y_test, test_predicted))","fd2c10ad":"plt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15);","755590db":"dead_count = data.groupby(data.dead).dead.count().plot(kind = 'bar')","df2099be":"treedata = data[['dead','airbag','seatbelt', 'deploy', 'injSeverity']]\ntreedata","99d47e60":"label_encoders = create_label_encoder_dict(treedata)\nprint(\"Encoded Values for each Label\")\nprint(\"=\"*32)\nfor column in label_encoders:\n    print(\"=\"*32)\n    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))\n    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values']  ).T)","d61b8813":"treedata2 = treedata.copy() # create copy of initial data set\nfor column in treedata2.columns:\n    if column in label_encoders:\n        treedata2[column] = label_encoders[column].transform(treedata2[column])\n\nprint(\"Transformed data set\")\nprint(\"=\"*32)\ntreedata2","55a82b7c":"# separate our data into dependent (Y) and independent(X) variables\nX_data = treedata2[['airbag','seatbelt','deploy']]\nY_data = treedata2['dead']","9901fff7":"# import Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree","2aaeca75":"clf = DecisionTreeClassifier(max_depth=90, criterion='entropy') ","bd88e0f8":"# build classifier\nclf.fit(X_data, Y_data)","6d6da2e1":"pd.DataFrame([ \"%.2f%%\" % perc for perc in (clf.feature_importances_ * 100) ], index = X_data.columns, columns = ['Feature Significance in Decision Tree'])","a94bb56b":"import graphviz\ndot_data = tree.export_graphviz(clf,out_file=None, \n                                feature_names=X_data.columns, \n                         class_names=label_encoders[Y_data.name].classes_,  \n                         filled=True, rounded=True,  proportion=True,\n                                node_ids=True, #impurity=False,\n                         special_characters=True)","490fc867":"graph = graphviz.Source(dot_data) \ngraph","8c421061":"k=(clf.predict(X_data) == Y_data) # Determine how many were predicted correctly","c8b3d676":"k.value_counts()","d6aa8919":"from sklearn.metrics import confusion_matrix","e1087fa7":"cm=confusion_matrix(Y_data, clf.predict(X_data), labels=Y_data.unique())\ncm","b0c8eccd":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    import itertools\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","b86a4693":"plot_confusion_matrix(cm,data2['dead'].unique())","6f0779f1":"# Apply each encoder to the data set to obtain transformed values\nneuraldata = data.copy() # create copy of initial data set\nfor column in data2.columns:\n    if column in label_encoders:\n        neuraldata[column] = label_encoders[column].transform(neuraldata[column])\n\nprint(\"Transformed data set\")\nprint(\"=\"*32)\ndata2.head(15)","bfede863":"# separate our data into dependent (Y) and independent(X) variables\nX_data = neuraldata[['yearVeh','airbag','weight']]\nY_data = neuraldata['deploy'] # actually department column\n","01e1265c":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30)","c7b9961a":"from sklearn.neural_network import MLPClassifier","63c7cb71":"#Create an instance of linear regression\nreg = MLPClassifier()\n#reg = MLPClassifier(hidden_layer_sizes=(8,120))","f8862739":"reg.fit(X_train,y_train)","1406730e":"reg.n_layers_ # Number of layers utilized\n","fe86e9ff":"# Make predictions using the testing set\ntest_predicted = reg.predict(X_test)\ntest_predicted","1b80de1a":"k=(reg.predict(X_test) == y_test) # Determine how many were predicted correctly","2e368706":"k.value_counts()\n","26cc42de":"cm=confusion_matrix(y_test, reg.predict(X_test), labels=y_test.unique())\ncm","406f5b55":"plt.figure(figsize=(9,16))\nplot_confusion_matrix(cm,data['deploy'].unique())","1bc1c59c":"**Confusion matrix given a visualization of the logistic regression**","a331b7d9":"# Apply each encoder to the data set to obtain transformed values\n","07d87959":"Trying Neural Networks","291e825d":"Injury Severity Count","27af3f7b":"plotting a bar chart of the number of vehicles that have an air bag deployed depending on the year of the car","adb39f30":"**Aim : Use a decision tree to identify a seatelt will save me whether or not an airbag is present**","343ab5a8":"Bar plot of people who wore a seatbelt vs those who died"}}