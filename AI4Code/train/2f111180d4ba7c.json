{"cell_type":{"0dd17432":"code","bbfc3b82":"code","c3688062":"code","c5aa4d3c":"code","6d898f10":"code","c065d02c":"code","0cad9a49":"code","731448da":"code","b62f3385":"code","8f7863b8":"code","3ea6e351":"code","af098243":"code","802f5733":"code","3cfb640a":"code","f5196469":"code","b3b508b4":"code","79737898":"code","e4ebdd95":"code","b42ee888":"code","a6bf76e6":"markdown","8d6969e1":"markdown","3de064fa":"markdown","c09486cf":"markdown","fde50c19":"markdown","674b442a":"markdown","6b201108":"markdown","01222f7e":"markdown","de32427d":"markdown","6d1c877f":"markdown","a2e40a35":"markdown","961d17b5":"markdown"},"source":{"0dd17432":"import sys\nsys.path.append('..\/input\/rich-text-formatting')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\n\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\nfrom wordcloud import WordCloud\nfrom plotly.offline import iplot\n\n\nfrom spacy.lang.hi import Hindi\nfrom spacy.lang.ta import Tamil\nfrom spacy.lang.hi import STOP_WORDS as hindi_stopwords\nfrom spacy.lang.ta import STOP_WORDS as tamil_stopwords\nfrom collections import Counter","bbfc3b82":"train_df = pd.read_csv(\"\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/test.csv\")\nsubmission_df = pd.read_csv(\"\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/sample_submission.csv\")","c3688062":"train_df.head()","c5aa4d3c":"language = train_df[\"language\"].value_counts()\nlanguage_df = pd.DataFrame({\"language\":language.index,\"frequency\":language.values})\nfig = px.bar(data_frame=language_df,x=\"language\",y=\"frequency\",title=\"Language Distribution\",color=\"language\",height=500,width=1000)\nfig.show()","6d898f10":"language = train_df[\"language\"].value_counts()\nlanguage_df = pd.DataFrame({\"language\":language.index,\"frequency\":language.values})\nhover_values = language.index\nfig = px.pie(values=language_df[\"frequency\"],labels=language_df[\"language\"],title=\"Language Distribution\",hover_name=hover_values)\nfig.show()","c065d02c":"hindi_context = train_df[train_df['language']=='hindi']['context'].str.len()\ntamil_context = train_df[train_df['language']=='tamil']['context'].str.len()\n\nfig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(\n    go.Histogram(x=list(hindi_context), name='Hindi Context'),\n    row=1, \n    col=1\n)\n\nfig.add_trace(\n    go.Histogram(x=list(tamil_context), name='Tamil Context'),\n    row=1, \n    col=2,\n)\n\n\n\n\nfig.update_layout(height=400, width=800, title_text=\"Character Count by Language\")\niplot(fig)","0cad9a49":"hindi = train_df[train_df['language']=='hindi']['context'].str.split().map(lambda x: len(x))\ntamil = train_df[train_df['language']=='tamil']['context'].str.split().map(lambda x: len(x))\n\nfig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(\n    go.Histogram(x=list(hindi), name='Hindi Context'),\n    row=1, \n    col=1\n)\n\nfig.add_trace(\n    go.Histogram(x=list(tamil), name='Tamil Context'),\n    row=1, \n    col=2,\n)\n\nfig.update_layout(height=400, width=800, title_text=\"Word Count Distribution by Language\")\niplot(fig)","731448da":"hindi_question = train_df[train_df['language']=='hindi']['question'].str.len()\ntamil_question = train_df[train_df['language']=='tamil']['question'].str.len()\nfig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(\n    go.Histogram(x=list(hindi), name='Hindi Question'),\n    row=1, \n    col=1\n)\n\nfig.add_trace(\n    go.Histogram(x=list(tamil), name='Tamil Question'),\n    row=1, \n    col=2,\n)\n\nfig.update_layout(height=400, width=800, title_text=\"Character Count by Language\")\niplot(fig)","b62f3385":"hindi_question = train_df[train_df['language']=='hindi']['question'].str.split().map(lambda x: len(x))\ntamil_question = train_df[train_df['language']=='tamil']['question'].str.split().map(lambda x: len(x))\nfig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(\n    go.Histogram(x=list(hindi), name='Hindi Question'),\n    row=1, \n    col=1\n)\n\nfig.add_trace(\n    go.Histogram(x=list(tamil), name='Tamil Question'),\n    row=1, \n    col=2,\n)\n\nfig.update_layout(height=400, width=800, title_text=\"Character Count by Language\")\niplot(fig)","8f7863b8":"def generate_word_cloud(font_path,text):\n    wordcloud = WordCloud(font_path=font_path,\n        width = 3000,\n        height = 2000,\n        background_color = 'black').generate_from_frequencies(text)\n    fig = plt.figure(\n        figsize = (40, 30),\n        facecolor = 'k',\n        edgecolor = 'k')\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.axis('off')\n    plt.tight_layout(pad=0)\n    plt.show()","3ea6e351":"!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Devanagari.zip\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Tamil.zip\n\n!unzip -qq Devanagari.zip\n!unzip -qq Tamil.zip","af098243":"# Get the text for both the languages\ntamil_text_question = \" \".join(train_df[train_df[\"language\"]==\"tamil\"][\"question\"])\nhindi_text_question = \" \".join(train_df[train_df[\"language\"]==\"hindi\"][\"question\"])","802f5733":"hindi_nlp = Hindi()\nhindi_nlp.max_length = 1030000 \nhindi_doc = hindi_nlp(hindi_text_question)\nhindi_tokens = set([token.text for token in hindi_doc])\nhindi_tokens_counter = Counter(hindi_tokens)\n\n\n# Get the tokens and frequencies for Tamil language\ntamil_nlp = Tamil()\ntamil_nlp.max_length = 1030000 \ntamil_doc = hindi_nlp(tamil_text_question)\ntamil_tokens = set([token.text for token in tamil_doc])\ntamil_tokens_counter = Counter(tamil_tokens)","3cfb640a":"generate_word_cloud(font_path=\"Devanagari\/Lohit-Devanagari.ttf\",text=hindi_tokens_counter)","f5196469":"generate_word_cloud(font_path=\"Tamil\/Lohit-Tamil.ttf\",text=tamil_tokens_counter)","b3b508b4":"# Get the text for both the languages\ntamil_text_context = \" \".join(train_df[train_df[\"language\"]==\"tamil\"][\"context\"])\nhindi_text_context = \" \".join(train_df[train_df[\"language\"]==\"hindi\"][\"context\"])","79737898":"hindi_nlp = Hindi()\nhindi_nlp.max_length = 7568961  # Specify more values as it contains more words in it .\n\nhindi_doc = hindi_nlp(hindi_text_context)\nhindi_tokens = set([token.text for token in hindi_doc])\nhindi_tokens_counter = Counter(hindi_tokens)\n\n\n# Get the tokens and frequencies for Tamil language\ntamil_nlp = Tamil()\ntamil_nlp.max_length = 7568961  # Specify more values as it contains more words in it .\n\ntamil_doc = hindi_nlp(tamil_text_context)\ntamil_tokens = set([token.text for token in tamil_doc])\ntamil_tokens_counter = Counter(tamil_tokens)","e4ebdd95":"generate_word_cloud(font_path=\"Devanagari\/Lohit-Devanagari.ttf\",text=hindi_tokens_counter)","b42ee888":"generate_word_cloud(font_path=\"Tamil\/Lohit-Tamil.ttf\",text=tamil_tokens_counter)","a6bf76e6":"## Hindi","8d6969e1":"## Tamil","3de064fa":"## There are some tamila and other text present here ,that's why some weird images is drawn","c09486cf":"## Tamil","fde50c19":"## From this we can see clearly that hindi text is more than tamil text","674b442a":"# Let's Explore Train Data ","6b201108":"# WordCloud for Question","01222f7e":"# WordCloud for Context","de32427d":"## Hindi","6d1c877f":"# Imports","a2e40a35":"## Analysis on Context data","961d17b5":"## Analysis on Question data "}}