{"cell_type":{"3ba45f22":"code","16591357":"code","4dc5de29":"code","42cf4c13":"code","3b994b07":"code","1f5eeb6d":"code","10fa0576":"code","811b2ef5":"code","e33991d4":"code","cd61ed1f":"code","ede998a4":"code","04364db0":"code","d5ca2608":"code","7ac54ee8":"code","144ed221":"code","6005c365":"code","d51005fa":"code","3d788a71":"code","69526c70":"code","f587672e":"code","d7562812":"code","6e3d6cbf":"code","736d6005":"code","e0bccce6":"code","f977f707":"code","66df38a3":"code","e4913058":"code","8a00ecf6":"code","b80dbfb0":"code","48079443":"code","f2586c92":"code","028747fb":"code","9340cc1b":"code","f30f0520":"code","5494f9ef":"code","2a03c02c":"code","8779dcfd":"code","8c6d08d1":"code","cc786c5d":"code","4837aa62":"code","8c695caf":"markdown","9b9f8906":"markdown","7fd652ba":"markdown"},"source":{"3ba45f22":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","16591357":"import csv\nX_train = pd.read_csv(\"\/kaggle\/input\/newsdata\/train.tsv\",quoting=csv.QUOTE_NONE, error_bad_lines=False, sep=\"\\t\", header=None)\nX_train.drop([0, 3, 4, 5, 6, 8, 9, 10, 11, 12], axis=1, inplace=True)\n\nX_test = pd.read_csv(\"\/kaggle\/input\/newsdata\/test.tsv\",quoting=csv.QUOTE_NONE, error_bad_lines=False, sep=\"\\t\", header=None)\nX_test.drop([0, 3, 4, 5, 6, 8, 9, 10, 11, 12], axis=1, inplace=True)\n\n\nX_train.head()","4dc5de29":"from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n","42cf4c13":"X_train.columns = ['target','text','party','source']\nX_test.columns = ['target','text','party','source']\n\nX_train.head()\n","3b994b07":"X_train.target.unique()","1f5eeb6d":"# from sklearn.preprocessing import OrdinalEncoder\n\n# ord_enc = OrdinalEncoder()\n# # X_train.fillna(0)\n# X_train[['party', 'source']] = X_train[['party','source']].fillna(value='NA')\n\n# X_train[\"party_code\"] = ord_enc.fit_transform(X_train[[\"party\"]])\n# X_train[\"source_code\"] = ord_enc.fit_transform(X_train[[\"source\"]])\n\n# X_test[['party', 'source']] = X_test[['party','source']].fillna(value='NA')\n\n# X_test[\"party_code\"] = ord_enc.fit_transform(X_test[[\"party\"]])\n# X_test[\"source_code\"] = ord_enc.fit_transform(X_test[[\"source\"]])\n\n# X_train.head()","10fa0576":"# from sklearn.feature_extraction.text import CountVectorizer\n# count_vectorizer = CountVectorizer()\n\n# example_train_vectors = count_vectorizer.fit_transform(X_train[\"text\"][0:5])","811b2ef5":"# print(example_train_vectors[0].todense().shape)\n# print(example_train_vectors[0].todense())","e33991d4":"# train_vectors = count_vectorizer.fit_transform(X_train[\"text\"])\n# test_vectors = count_vectorizer.transform(X_test[\"text\"])\n\n\nX_train[\"target\"] = X_train[\"target\"].map({ \"mostly-true\": 1,\"half-true\": 1,\"true\": 1,\"false\": 0,\"barely-true\": 0,\"pants-fire\": 0})\nX_test[\"target\"] = X_test[\"target\"].map({\"mostly-true\": 1,\"half-true\": 1,\"true\": 1,\"false\": 0,\"barely-true\": 0,\"pants-fire\": 0})\n\ny_train = X_train[\"target\"].copy()\ny_test = X_test[\"target\"].copy()","cd61ed1f":"y_train","ede998a4":"X_train","04364db0":"X_train['text'][0]","d5ca2608":"\nimport tensorflow as tf","7ac54ee8":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import Dropout","144ed221":"### Vocabulary size\nvoc_size=5000\n","6005c365":"messages=X_train.copy()\nmessages['text'][1]\n\nmessages_test  = X_test.copy()","d51005fa":"messages.reset_index(inplace=True)\nmessages_test.reset_index(inplace=True)","3d788a71":"import nltk\nimport re\nfrom nltk.corpus import stopwords","69526c70":"nltk.download('stopwords')\n","f587672e":"from nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n#     print(i)\n    review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","d7562812":"from nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus_test = []\nfor i in range(0, len(messages_test)):\n#     print(i)\n    review = re.sub('[^a-zA-Z]', ' ', messages_test['text'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus_test.append(review)","6e3d6cbf":"corpus\n","736d6005":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr","e0bccce6":"onehot_repr_test=[one_hot(words,voc_size)for words in corpus_test] \n# onehot_repr_","f977f707":"# embedding representation\nsent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)\n","66df38a3":"# embedding representation\nsent_length=20\nembedded_docs_test=pad_sequences(onehot_repr_test,padding='pre',maxlen=sent_length)\n# print(embedded_docs)","e4913058":"embedded_docs[0]\n","8a00ecf6":"\n## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","b80dbfb0":"## Creating model\nembedding_vector_features=40\nmodel1=Sequential()\nmodel1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel1.add(Bidirectional(LSTM(100)))\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(1,activation='sigmoid'))\nmodel1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model1.summary())\n","48079443":"len(embedded_docs),y.shape\n","f2586c92":"import numpy as np\nX_train=np.array(embedded_docs)\ny_train=np.array(y_train)","028747fb":"X_test=np.array(embedded_docs_test)\ny_test=np.array(y_test)","9340cc1b":"# X_final.shape,y_final.shape\n","f30f0520":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)\n","5494f9ef":"model1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)\n","2a03c02c":"y_pred1=model1.predict_classes(X_test)\n","8779dcfd":"from sklearn.metrics import confusion_matrix\n","8c6d08d1":"confusion_matrix(y_test,y_pred1)\n","cc786c5d":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred1)\n","4837aa62":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred1))","8c695caf":"Looking for the best Parameters on the RandomForestClassifier with GridSearchCV. The score just needs to be better than the linear model for now.","9b9f8906":"Testing out the count_vectorizer here:","7fd652ba":"Creating the vectors I want to use to train the model. In the future I could add in the other features of the dataset aswell to improve the training set."}}