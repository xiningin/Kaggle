{"cell_type":{"cceafb86":"code","89f00577":"markdown"},"source":{"cceafb86":"from nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport requests\nfrom bs4 import BeautifulSoup\nfrom nltk.probability import FreqDist\nfrom heapq import nlargest\nfrom collections import defaultdict\n\n\ndef clean(text: str):\n    \"\"\"\n    Cleans the passed in string by removing redundant new line and whitespace characters, then calling .strip() on the\n    string\n    :param text: A string to be cleaned\n    :return: Returns the cleaned string\n    \"\"\"\n    text_list = list(text)\n    i = 0\n    while i < len(text_list) - 1:\n        if (text_list[i] == '\\n' and text_list[i + 1] == '\\n') or (text_list[i] == ' ' and text_list[i + 1] == ' '):\n            text_list.pop(i)\n            i -= 1\n        i += 1\n    return ''.join(text_list).strip()\n\n\ndef descendant_tags(soup: BeautifulSoup, parent_tag: str, descendant_tag: str):\n    \"\"\"\n    Returns a list containing a parent tag's descendant tags\n    :param soup: A BeautifulSoup object\n    :param parent_tag: The parent tag type\n    :param descendant_tag: The descendant tag type to search for\n    :return: Returns a list containing all instances of the descendant tag found in the parent tag\n    \"\"\"\n    descendants = []\n    elements = soup.find_all(parent_tag)\n    for element in elements:\n        for child_element in element.findChildren():\n            if child_element.name == descendant_tag:\n                descendants.append(child_element)\n    return descendants\n\n\ndef tags_to_text(tags):\n    \"\"\"\n    Returns a string representing the contents of the passed in tag list separated by spaces\n    :param tags: A list of tags\n    :return: Returns the concatenated string\n    \"\"\"\n    text = ''\n    for tag in tags:\n        text += ' ' + tag.text\n    return text\n\n\ndef print_sentences(sentences):\n    \"\"\"\n    Prints the passed in sentences.\n    :param sentences: list\n    :return:\n    \"\"\"\n    for sentence in sentences:\n        print(sentence)\n\n\ndef summarize(url: str, display_data: bool = False):\n    \"\"\"\n    Summarizes an article using BeautifulSoup. Takes a URL string for the article, checks if the page has an article\n    tag, then prints the summarized text\n    :param url: The webpage URL\n    :param display_data: Print internal data for review and debug purposes\n    :return:\n    \"\"\"\n    response = requests.get(url)\n    response.encoding = 'utf-8'\n    data = response.text\n    soup = BeautifulSoup(data, features=\"html.parser\")\n\n    # text = ' '.join(map(lambda p: p.text, soup.find_all('article')))\n    text = tags_to_text(descendant_tags(soup, 'article', 'p'))\n    text = clean(text)\n\n    # text.encode('ascii', 'ignore')\n\n    sentences = sent_tokenize(text)\n    if display_data:\n        print('SENTENCES:', sentences, '\\n')\n\n    words = word_tokenize(text.lower())\n    # print('WORDS:', words, '\\n')\n\n    _stopwords = set(stopwords.words('english') + list(punctuation))\n    _stopwords.add(\"'s\")\n\n    if display_data:\n        print('_STOPWORDS', _stopwords, '\\n')\n\n    # Filter out stopword\n    words = [word for word in words if word not in _stopwords]\n    if display_data:\n        print('WORDS:', words, '\\n')\n\n    freq = FreqDist(words)\n    if display_data:\n        print('FREQ:', freq.__repr__(), '\\n')\n\n    if display_data:\n        print('NLARGEST:', nlargest(10, freq, key=freq.get), '\\n')\n\n    # We want to create a significant score ordered by highest frequency\n    ranking = defaultdict(int)\n    for i, sentence in enumerate(sentences):\n        for word in word_tokenize(sentence.lower()):\n            if word in freq:\n                ranking[i] += freq[word]\n\n    if display_data:\n        print('RANKING:', ranking, '\\n')\n\n    # Top 4 Sentences\n    sentences_idx = nlargest(4, ranking, key=ranking.get)\n    finalized_sentences = [sentences[j] for j in sorted(sentences_idx)]\n\n    if display_data:\n        print('SENTENCES_IDX:', finalized_sentences, '\\n')\n\n    print_sentences(finalized_sentences)\n\n\nsummarize(\"https:\/\/arstechnica.com\/cars\/2018\/10\/honda-will-use-gms-self-driving-technology-invest-2-75-billion\/\", True)\n","89f00577":"# TL;DR - Automated Gist\n## Find the most important words\n### Word Importance = Word Frequency\n## Compute a significance score for sentences based on words they contain\n### Significant score = Sum(Word Importance)\n## Pick the top most significant sentences\n\n* Retrieve Text\n* Preprocess Text\n* Extract Sentences\n\n#### Source: PluralSight - Natural Langauge Processing"}}