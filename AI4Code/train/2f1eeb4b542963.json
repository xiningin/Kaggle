{"cell_type":{"884ef955":"code","5e53e64a":"code","7f001fe0":"code","bd7e9b88":"code","4723c023":"code","4731acff":"code","3e5ba021":"code","f73147d5":"code","868e9bdd":"code","d1961d65":"code","312f53b8":"code","4acc1881":"code","df8e479f":"code","ba681c40":"code","9cc9bc8c":"code","c341f717":"code","04cc7f5c":"code","d00484d6":"code","cf052ac0":"code","168dccb0":"markdown","becbb85f":"markdown","75f6df9f":"markdown","4b8334ce":"markdown","4a269594":"markdown","9e3001ab":"markdown","4fcb07a5":"markdown","4265bfd3":"markdown","cdf82c44":"markdown","03a8c620":"markdown","8d9bb7d3":"markdown","781760be":"markdown","32d3e081":"markdown"},"source":{"884ef955":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.losses import categorical_crossentropy\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nprint(os.listdir(\"..\/input\"))","5e53e64a":"data = pd.read_csv('..\/input\/fer2013\/fer2013.csv')\n#check data shape\ndata.shape","7f001fe0":"# view first 5 rows of data\ndata.head(5)","bd7e9b88":"#check usage values\n#80% training, 10% validation and 10% test\ndata.Usage.value_counts()","4723c023":"#check target labels\nemotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\nemotion_counts = data['emotion'].value_counts(sort=False).reset_index()\nemotion_counts.columns = ['emotion', 'number']\nemotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\nemotion_counts","4731acff":"\n\n# Plotting a bar graph of the class distributions\nplt.figure(figsize=(6,4))\nsns.barplot(emotion_counts.emotion, emotion_counts.number)\nplt.title('Class distribution')\nplt.ylabel('Number', fontsize=12)\nplt.xlabel('Emotions', fontsize=12)\nplt.show()","3e5ba021":"def row2image(row):\n    pixels, emotion = row['pixels'], emotion_map[row['emotion']]\n    img = np.array(pixels.split())\n    img = img.reshape(48,48)\n    image = np.zeros((48,48,3))\n    image[:,:,0] = img\n    image[:,:,1] = img\n    image[:,:,2] = img\n    return np.array([image.astype(np.uint8), emotion])\n\nplt.figure(0, figsize=(16,10))\nfor i in range(1,8):\n    face = data[data['emotion'] == i-1].iloc[0]\n    img = row2image(face)\n    plt.subplot(2,4,i)\n    plt.imshow(img[0])\n    plt.title(img[1])\n\nplt.show()  ","f73147d5":"#split data into training, validation and test set\ndata_train = data[data['Usage']=='Training'].copy()\ndata_val   = data[data['Usage']=='PublicTest'].copy()\ndata_test  = data[data['Usage']=='PrivateTest'].copy()\nprint(\"train shape: {}, \\nvalidation shape: {}, \\ntest shape: {}\".format(data_train.shape, data_val.shape, data_test.shape))","868e9bdd":"# barplot class distribution of train, val and test\nemotion_labels = ['Angry', 'Digust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndef setup_axe(axe,df,title):\n    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)\n    axe.set_xticklabels(emotion_labels)\n    axe.set_xlabel(\"Emotions\")\n    axe.set_ylabel(\"Number\")\n    axe.set_title(title)\n    \n    # set individual bar lables using above list\n    for i in axe.patches:\n        # get_x pulls left or right; get_height pushes up or down\n        axe.text(i.get_x()-.05, i.get_height()+120, \\\n                str(round((i.get_height()), 2)), fontsize=14, color='dimgrey',\n                    rotation=0)\n\n   \nfig, axes = plt.subplots(1,3, figsize=(20,8), sharey=True)\nsetup_axe(axes[0],data_train,'train')\nsetup_axe(axes[1],data_val,'validation')\nsetup_axe(axes[2],data_test,'test')\nplt.show()","d1961d65":"#initilize parameters\nnum_classes = 7 \nwidth, height = 48, 48\nnum_epochs = 50\nbatch_size = 64\nnum_features = 64","312f53b8":"# CRNO stands for Convert, Reshape, Normalize, One-hot encoding\n# (i) convert strings to lists of integers\n# (ii) reshape and normalise grayscale image with 255.0\n# (iii) one-hot encoding label, e.g. class 3 to [0,0,0,1,0,0,0]\n\ndef CRNO(df, dataName):\n    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n    data_X = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1,width, height,1)\/255.0   \n    data_Y = to_categorical(df['emotion'], num_classes)  \n    print(dataName, \"_X shape: {}, \", dataName, \"_Y shape: {}\".format(data_X.shape, data_Y.shape))\n    return data_X, data_Y\n\n    \ntrain_X, train_Y = CRNO(data_train, \"train\") #training data\nval_X, val_Y     = CRNO(data_val, \"val\") #validation data\ntest_X, test_Y   = CRNO(data_test, \"test\") #test data","4acc1881":"model = Sequential()\n\n#module 1\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), input_shape=(width, height, 1), data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 2\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 3\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#flatten\nmodel.add(Flatten())\n\n#dense 1\nmodel.add(Dense(2*2*2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n#dense 2\nmodel.add(Dense(2*2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n#dense 3\nmodel.add(Dense(2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n#output layer\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n              metrics=['accuracy'])\n\nmodel.summary()","df8e479f":"# data generator\ndata_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True)\n\n\nes = EarlyStopping(monitor='val_loss', patience = 10, mode = 'min', restore_best_weights=True)\n\nhistory = model.fit_generator(data_generator.flow(train_X, train_Y, batch_size),\n                                steps_per_epoch=len(train_X) \/ batch_size,\n                                epochs=num_epochs,\n                                verbose=2, \n                                callbacks = [es],\n                                validation_data=(val_X, val_Y))","ba681c40":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(history.history['accuracy'])\naxes[0].plot(history.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(history.history['loss'])\naxes[1].plot(history.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","9cc9bc8c":"test_true = np.argmax(test_Y, axis=1)\ntest_pred = np.argmax(model.predict(test_X), axis=1)\nprint(\"CNN Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))","c341f717":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    #else:\n        #print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    fig, ax = plt.subplots(figsize=(12,6))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","04cc7f5c":"# Plot normalized confusion matrix\nplot_confusion_matrix(test_true, test_pred, classes=emotion_labels, normalize=True, title='Normalized confusion matrix')\nplt.show()","d00484d6":"model.save(\"model.h5\")","cf052ac0":"# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)","168dccb0":"# Intrduction\nThis is the implementation of Facial Expression Classification CNN model, for the problem of Guess Detection.\nThis CNN model is converted into a tensorflow lite model and integrated in our android application.","becbb85f":"# Confusion Matrix","75f6df9f":"# Building CNN Model\n**CNN Architecture**\n\n    Conv -> BN -> Activation -> Conv -> BN -> Activation -> MaxPooling\n    Conv -> BN -> Activation -> Conv -> BN -> Activation -> MaxPooling\n    Conv -> BN -> Activation -> Conv -> BN -> Activation -> MaxPooling\n    Flatten\n    Dense -> BN -> Activation\n    Dense -> BN -> Activation\n    Dense -> BN -> Activation\n    Output layer","4b8334ce":"# Training\nNumber of epochs = 50,\nBatch size = 64","4a269594":"# Dataset ","9e3001ab":"# Evaluate Test performance","4fcb07a5":"Looking at some images from the dataset...","4265bfd3":"# Visualise training performance","cdf82c44":"# Import libraries","03a8c620":"# Objectives\n1. To apply Convolutional neural networks (CNN) for facial expression recognition.\n2. To correctly classify each facial image into one of the seven facial emotion categories: anger, disgust, fear, happiness, sadness, surprise, and neutral.","8d9bb7d3":"# Saving the model","781760be":"# Pre-processing Data","32d3e081":"# Converting the CNN keras model to tflite\nThis is done so that the model can be easily integrated to an Android application."}}