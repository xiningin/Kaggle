{"cell_type":{"2df034cf":"code","4437c1ae":"code","fb8eb557":"code","1307e510":"code","771f59fa":"code","e753e3c7":"code","804bab61":"code","88086c9c":"code","e93dd47b":"code","ea620554":"code","bfd7872d":"code","f0dfdabc":"code","1424550c":"code","01d4ecb0":"code","a9bfb64d":"code","af213be2":"code","2eb86229":"code","39fe23ef":"code","3c5403d5":"code","92714296":"code","462f5ccf":"code","42a754ae":"code","e0b09c6b":"code","d54153e9":"markdown","ccc2361e":"markdown","d14ed4d2":"markdown","a3c2d1c4":"markdown","eb143366":"markdown","1763e44b":"markdown","7b1c2a79":"markdown","babaed97":"markdown","3d580698":"markdown","0d69c6f0":"markdown","32eacde2":"markdown","fdf51ec9":"markdown","ecbad070":"markdown","01f55912":"markdown","d980cc98":"markdown","5abadf21":"markdown","f3913dbe":"markdown"},"source":{"2df034cf":"from graphviz import Source\n\nSource(\"\"\"\ndigraph G {\n  raw_data [label=\"Input features\"];\n  preprocess_data [label=\"Learnable NN pre-processing\", shape=rect];\n\n  raw_data -> preprocess_data\n\n  subgraph cluster_0 {\n    color=grey;\n    a1[label=\"NN layer\", shape=rect];\n    b1[label=\"NN layer\", shape=rect];\n    a1 -> b1;\n    label = \"Model #1\";\n  }\n\n   subgraph cluster_1 {\n    color=grey;\n    a2[label=\"NN layer\", shape=rect];\n    b2[label=\"NN layer\", shape=rect];\n    a2 -> b2;\n    label = \"Model #2\";\n  }\n\n  subgraph cluster_2 {\n    color=grey;\n    a3[label=\"GradientBoost\", shape=rect];\n    label = \"Model #3\";\n  }\n\n  subgraph cluster_3 {\n    color=grey;\n    a4[label=\"Random Forest\", shape=rect];\n    label = \"Model #4\";\n  }\n  \n\n  preprocess_data -> a1;\n  preprocess_data -> a2;\n  preprocess_data -> a3;\n  preprocess_data -> a4;\n\n  b1  -> aggr;\n  b2  -> aggr;\n  a3 -> aggr;\n  a4 -> aggr;\n  \n  aggr [label=\"Aggregation (mean)\", shape=rect]\n  aggr -> predictions\n}\n\"\"\")","4437c1ae":"!pip install tensorflow_decision_forests -U --quiet","fb8eb557":"import os, glob, math, cv2, gc, logging\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow_decision_forests as tfdf\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nwarnings.filterwarnings(\"ignore\")\ntf.autograph.set_verbosity(0)\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\nprint(tf.__version__)","1307e510":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv').set_index(\"row_id\")\ntest = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv').set_index(\"row_id\")\n\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv\")","771f59fa":"train['date'] = pd.to_datetime(train['date'])\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\n\ntest['date'] = pd.to_datetime(test['date'])\ntest['year'] = test['date'].dt.year\ntest['month'] = test['date'].dt.month\ntest['day'] = test['date'].dt.day\ntest['dayofweek'] = test['date'].dt.dayofweek","e753e3c7":"train[\"month\"] = train[\"month\"].astype('category')\ntrain[\"dayofweek\"] = train[\"dayofweek\"].astype('category')\ntrain[\"day\"] = train[\"day\"].astype('category')\n\ntest[\"month\"] = test[\"month\"].astype('category')\ntest[\"dayofweek\"] = test[\"dayofweek\"].astype('category')\ntest[\"day\"] = test[\"day\"].astype('category')","804bab61":"fig, ax = plt.subplots(1, 4, figsize=(25, 8))\nsns.boxplot(data=train, x='country', y='num_sold', ax=ax[0])\nsns.boxplot(data=train, x='store', y='num_sold', ax=ax[1])\nsns.boxplot(data=train, x='product', y='num_sold', ax=ax[2])\nsns.boxplot(data=train, x='year', y='num_sold', ax=ax[3])\nplt.show()","88086c9c":"fig, ax = plt.subplots(2, 3, figsize=(25, 12))\nsns.violinplot(data=train, x='country', y='num_sold', ax=ax[0][0])\nsns.violinplot(data=train, x='store', y='num_sold', ax=ax[0][1])\nsns.violinplot(data=train, x='product', y='num_sold', ax=ax[0][2])\nsns.violinplot(data=train, x='year', y='num_sold', ax=ax[1][0])\nsns.violinplot(data=train, x='month', y='num_sold', ax=ax[1][1])\nsns.violinplot(data=train, x='dayofweek', y='num_sold', ax=ax[1][2])\nplt.show()","e93dd47b":"GDP_data = pd.read_csv(\"..\/input\/gdp-20152019-finland-norway-and-sweden\/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv\").set_index(\"year\")\nGDP_data.columns = ['Finland', 'Norway', 'Sweden']\nGDP_dictionary = GDP_data.unstack().to_dict()\ntrain[\"GDP\"] = train.set_index(['country','year']).index.map(GDP_dictionary.get)\ntest[\"GDP\"] = test.set_index(['country','year']).index.map(GDP_dictionary.get)\n\nsc = MinMaxScaler()\ntrain[\"GDP\"] = sc.fit_transform(train[\"GDP\"].values.reshape(-1,1))\ntest[\"GDP\"] = sc.transform(test[\"GDP\"].values.reshape(-1,1))","ea620554":"holidays_data = pd.read_csv(\"..\/input\/public-and-unofficial-holidays-nor-fin-swe-201519\/holidays.csv\")\ntrain[\"is_holiday\"] = train.date.isin(holidays_data[\"date\"]).astype(np.uint8)\ntest[\"is_holiday\"] = test.date.isin(holidays_data[\"date\"]).astype(np.uint8)","bfd7872d":"train_date = train[\"date\"]\ntest_date = test[\"date\"]\ntrain.drop([\"date\", \"year\"], inplace=True, axis=1)\ntest.drop([\"date\", \"year\"], inplace=True, axis=1)","f0dfdabc":"ohe_cols = [\"country\",\"store\",\"product\", \"month\", \"dayofweek\", \"day\"]\n\ntrain = pd.get_dummies(train, columns=[\"month\"], prefix=\"o_month\")\ntest = pd.get_dummies(test, columns=[\"month\"], prefix=\"o_month\")\n\ntrain = pd.get_dummies(train, columns=[\"day\"], prefix=\"o_day\")\ntest = pd.get_dummies(test, columns=[\"day\"], prefix=\"o_day\")\n\ntrain = pd.get_dummies(train, columns=[\"dayofweek\"], prefix=\"o_week\")\ntest = pd.get_dummies(test, columns=[\"dayofweek\"], prefix=\"o_week\")\n\ntrain = pd.get_dummies(train, columns=[\"country\",\"store\",\"product\"], prefix=\"ohe\")\ntest = pd.get_dummies(test, columns=[\"country\",\"store\",\"product\"], prefix=\"ohe\")\n\ntrain.head()","1424550c":"x_train, x_valid, y_train, y_valid = train_test_split(train[train.columns.tolist()[1:]], train.num_sold, test_size=0.2, random_state=42)\nprint(f\"x_train  shape: {x_train.shape}\")\nprint(f\"y_train  shape: {y_train.shape}\\n\")\nprint(f\"x_valid  shape: {x_valid.shape}\")\nprint(f\"y_valid  shape: {y_valid.shape}\")","01d4ecb0":"train_dataset = tf.data.Dataset.from_tensor_slices((x_train.values.astype(\"float32\"), y_train.values.astype(\"float32\"))).batch(64)\nvalid_dataset = tf.data.Dataset.from_tensor_slices((x_valid.values.astype(\"float32\"), y_valid.values.astype(\"float32\"))).batch(64)","a9bfb64d":"def seed_advanced_argument(seed):\n    return tfdf.keras.AdvancedArguments(yggdrasil_training_config=tfdf.keras.core.YggdrasilTrainingConfig(random_seed=seed))\n\ninputs = layers.Input(shape=(x_train.shape[-1],))\n\n# learnable pre-processing\nx = tf.keras.layers.Dense(1024, activation=tf.nn.relu6)(inputs)\npreprocess_features = tf.keras.layers.Dense(200, activation=tf.nn.relu6)(x)\n\npreprocessor = tf.keras.Model(inputs, preprocess_features)\n\n# Model #1: Neural Network 1\nm1_z1 = tf.keras.layers.Dense(256, activation=tf.nn.relu6)(preprocess_features)\nm1_z1 = tf.keras.layers.Dropout(0.2)(m1_z1)\nm1_z1 = tf.keras.layers.Dense(128, activation=tf.nn.relu6)(m1_z1)\nm1_pred = tf.keras.layers.Dense(1)(m1_z1)\n\n# Model #2: Neural Network 2\nm2_z1 = tf.keras.layers.Dense(128, activation=tf.nn.swish)(preprocess_features)\nm2_z1 = tf.keras.layers.Dropout(0.2)(m2_z1)\nm2_z1 = tf.keras.layers.Dense(64, activation=tf.nn.swish)(m2_z1)\nm2_pred = tf.keras.layers.Dense(1)(m2_z1)\n\n# Model #3: DF Gradient Boost Trees\nmodel_3 = tfdf.keras.GradientBoostedTreesModel(num_trees=10000, \n                                               advanced_arguments=seed_advanced_argument(1234), \n                                               task=tfdf.keras.Task.REGRESSION)\nm3_pred = model_3(preprocess_features)\n\n# Model #4: DF Random Forest\nmodel_4 = tfdf.keras.RandomForestModel(num_trees=2000,\n                                               advanced_arguments=seed_advanced_argument(2022), \n                                               task=tfdf.keras.Task.REGRESSION)\nm4_pred = model_4(preprocess_features)\n\nmean_nn_only = tf.reduce_mean(tf.stack([m1_pred, m2_pred], axis=0), axis=0)\nmean_nn_and_df = tf.reduce_mean(tf.stack([m1_pred, m2_pred, m3_pred, m4_pred], axis=0), axis=0)\n\n\nensemble_nn_only = tf.keras.models.Model(inputs, mean_nn_only)\nensemble_nn_and_df = tf.keras.models.Model(inputs, mean_nn_and_df)","af213be2":"plot_model(ensemble_nn_and_df, to_file=\"model.png\", show_shapes=True)","2eb86229":"def smape(y_true, y_pred):\n    denominator = (y_true + tf.abs(y_pred)) \/ 200.0\n    diff = tf.abs(y_true - y_pred) \/ denominator\n    diff = tf.where(denominator==0, 0.0, diff)\n    return tf.reduce_mean(diff)\n\ncb_es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, mode=\"min\", restore_best_weights=True, verbose=1)\ncb_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, mode=\"min\", min_lr=1e-6, verbose=1)\n\nensemble_nn_only.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=smape, metrics=[smape])\n\nhistory = ensemble_nn_only.fit(train_dataset, \n                               epochs=100,\n                               validation_data=valid_dataset,\n                               callbacks=[cb_es, cb_lr],\n                               verbose=2)","39fe23ef":"%%time\ntrain_dataset_with_preprocessing = train_dataset.map(lambda x,y: (preprocessor(x), y)).unbatch().batch(1024)\nvalid_dataset_with_preprocessing = valid_dataset.map(lambda x,y: (preprocessor(x), y)).unbatch().batch(1024)\n\nmodel_3.compile([smape])\nmodel_4.compile([smape])\n\nprint(\"\\n-------------#3 Training TFDF Gradinet Boost Trees -------------\\n\")\nmodel_3.fit(train_dataset_with_preprocessing)\nevaluation_df3_only = model_3.evaluate(valid_dataset_with_preprocessing, return_dict=True)\n\nprint(\"\\n-------------#4 Training TFDF Random Forest -------------\\n\")\nmodel_4.fit(train_dataset_with_preprocessing)\nevaluation_df4_only = model_4.evaluate(valid_dataset_with_preprocessing, return_dict=True)","3c5403d5":"print(\"Model Neural Network Only:\")\nevaluation_nn_only = ensemble_nn_only.evaluate(valid_dataset)\nprint(\"\\nModel TFDF Gradient Boost Trees Only:\")\nevaluation_df3_only = model_3.evaluate(valid_dataset_with_preprocessing, return_dict=True)\nprint(\"\\nModel TFDF Random Forest Only:\")\nevaluation_df4_only = model_4.evaluate(valid_dataset_with_preprocessing, return_dict=True)\n\nensemble_nn_and_df.compile(loss=smape, metrics=[smape])\nprint(\"\\nEnsembeled Neural Networks and TFDF Models:\")\nevaluation_nn_and_df = ensemble_nn_and_df.evaluate(valid_dataset, return_dict=True)","92714296":"sample_train_data = train.loc[(train[\"ohe_Finland\"]==1) & (train[\"ohe_KaggleMart\"]==1) & (train[\"ohe_Kaggle Hat\"]==1)]\np = ensemble_nn_and_df.predict(sample_train_data[sample_train_data.columns.tolist()[1:]]).astype('int32')","462f5ccf":"plt.figure(figsize=(25,8))\nsns.lineplot(y=sample_train_data[\"num_sold\"].values, x=train_date.unique())\nsns.lineplot(y=p.ravel(), x=train_date.unique())\nplt.legend([\"Actual\", \"Preds\"])\nplt.title(\"Num Sold for Hat at the Mart in Finland (Prediction VS Actual Selling)\")\nplt.show()","42a754ae":"preds = ensemble_nn_and_df.predict(test).astype('int32')\nsample_submission[\"num_sold\"] = preds.ravel()\nsample_submission.to_csv(\"submission.csv\", index=False)\nsample_submission","e0b09c6b":"p_1 = ensemble_nn_and_df.predict(test.loc[(test[\"ohe_Finland\"]==1) & (test[\"ohe_KaggleMart\"]==1) & (test[\"ohe_Kaggle Hat\"]==1)]).astype('int32')\np_2 = ensemble_nn_and_df.predict(test.loc[(test[\"ohe_Finland\"]==1) & (test[\"ohe_KaggleMart\"]==1) & (test[\"ohe_Kaggle Mug\"]==1)]).astype('int32')\np_3 = ensemble_nn_and_df.predict(test.loc[(test[\"ohe_Finland\"]==1) & (test[\"ohe_KaggleMart\"]==1) & (test[\"ohe_Kaggle Sticker\"]==1)]).astype('int32')\n\nplt.figure(figsize=(25,8))\nsns.lineplot(y=p_1.ravel(), x=test_date.unique())\nsns.lineplot(y=p_2.ravel(), x=test_date.unique())\nsns.lineplot(y=p_3.ravel(), x=test_date.unique())\nplt.title(\"Prediction for the Mart store in Finland\")\nplt.legend([\"Hat\", \"Mug\", \"Sticker\"])\nplt.show()","d54153e9":"# Some plots to get insight from data","ccc2361e":"# Load and Preprocess Data","d14ed4d2":"# Compose TensorFlow Decision Forests and Neural Networks\n\nThis notebook shows you how to compose multiple TensorFlow [Decision Forests](https:\/\/www.tensorflow.org\/decision_forests) and Neural Networks together using a common preprocessing layer and the [Keras functional API](https:\/\/keras.io\/guides\/functional_api\/).","a3c2d1c4":"## One-Hoe Encode Categorical Columns","eb143366":"# Add More Features\n\n - Thanks to [@carlmcbrideellis](https:\/\/www.kaggle.com\/carlmcbrideellis) for the [GDP dataset](https:\/\/www.kaggle.com\/carlmcbrideellis\/gdp-20152019-finland-norway-and-sweden).\n - Thanks to [@vpallares](https:\/\/www.kaggle.com\/vpallares) for the [Holidays dataset](https:\/\/www.kaggle.com\/vpallares\/public-and-unofficial-holidays-nor-fin-swe-201519).","1763e44b":"# Evaluate Models","7b1c2a79":"# Split Data and Make Dataset","babaed97":"Source: [Composing Decision Forest and Neural Network models](https:\/\/www.tensorflow.org\/decision_forests\/tutorials\/model_composition_colab)","3d580698":"# Create Submission","0d69c6f0":"# Create Model","32eacde2":"## Remove Redundant Columns","fdf51ec9":"# Train Neural Network Models \ud83e\udde0","ecbad070":"TFDF does not support (yet) GPUs and TPUs. Therefore, the training process may be slow. You can get much higher accuracy by amending the decision trees arguments (for example `num_trees` or increasing pre-processed features).","01f55912":"# Train TF Decision Forest Models (TFDF) \ud83c\udf84 \ud83c\udf34 \ud83c\udf33","d980cc98":"# Plot Test Predictions","5abadf21":"## Holidays","f3913dbe":"## GDP"}}