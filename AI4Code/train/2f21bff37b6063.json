{"cell_type":{"4a68af18":"code","cd56553c":"code","50c42356":"code","25d6bb07":"code","bb75523f":"code","9b20e5f3":"code","2810dc25":"code","0963a866":"code","70dfe0cc":"code","6cf7b8d5":"code","25b75214":"code","f9b1b84f":"code","76b802a6":"code","d5c480f6":"code","9ef22d39":"code","5813669e":"code","27799ef2":"code","44a7f7e6":"code","b3de51b2":"code","ea2e99f6":"code","da6987f2":"code","2b037421":"code","fcae600d":"code","46619109":"code","957a5418":"code","65198fb6":"code","e61a8acf":"code","13abfed8":"code","f357cff8":"code","ce467e3a":"code","4a51b02b":"code","022c8c79":"code","d7695c83":"code","0f7475ea":"code","003542ee":"code","ba0c1ac1":"code","d60867c5":"code","4407c2ad":"code","2010d24b":"code","69420299":"code","766c59e4":"code","cf5409fb":"code","b5136800":"code","be1eac09":"markdown","3ff20e54":"markdown","45a146e4":"markdown","50e0ceda":"markdown","7d129985":"markdown","95946ae4":"markdown","da1c2b79":"markdown","1728073e":"markdown","ec22dc8f":"markdown","74e91f71":"markdown","d57d0031":"markdown","447ffa36":"markdown","6b72bc86":"markdown","bbacde62":"markdown","3153ea27":"markdown","de1b3e56":"markdown","1ed07ce4":"markdown","534b3455":"markdown","66624d47":"markdown","7c0cf8b7":"markdown","7cb04998":"markdown","840f6fba":"markdown","251d3ff1":"markdown","937f994e":"markdown","9d3615da":"markdown","d268d673":"markdown"},"source":{"4a68af18":"#import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfilenum = 0\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/casia-dataset\/CASIA1\/Sp\/'):\n    for filename in filenames:\n        if filename.endswith('jpg'):\n            file_full_name = os.path.join(dirname, filename)\n            print(file_full_name)\n            filenum = filenum + 1\n        \nprint(filenum)\n# Any results you write to the current directory are saved as output.","cd56553c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\n#from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tqdm import tqdm\n\n\nsns.set(style='white', context='notebook', palette='deep')","50c42356":"from PIL import Image\nimport os\nfrom pylab import *\nimport re\nfrom PIL import Image, ImageChops, ImageEnhance","25d6bb07":"def get_imlist(path):\n    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')]","bb75523f":"def convert_to_ela_image(path, quality):\n    filename = path\n    #resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n    #ELA_filename = filename.split('.')[0] + '.ela.png'\n    resaved_filename = 'tempresaved.jpg'\n    ELA_filename = 'tempela.png'\n    \n    im = Image.open(filename).convert('RGB')\n    im.save(resaved_filename, 'JPEG', quality = quality)\n    resaved_im = Image.open(resaved_filename)\n    \n    ela_im = ImageChops.difference(im, resaved_im)\n    \n    extrema = ela_im.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n    scale = 255.0 \/ max_diff\n    \n    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n    \n    return ela_im","9b20e5f3":"Image.open('\/kaggle\/input\/casia-dataset\/casia\/CASIA2\/Au\/Au_sec_20098.jpg')","2810dc25":"convert_to_ela_image('\/kaggle\/input\/casia-dataset\/casia\/CASIA2\/Au\/Au_sec_20098.jpg', 90)","0963a866":"Image.open('\/kaggle\/input\/casia-dataset\/casia\/CASIA2\/Tp\/Tp_D_NRD_M_N_art10018_art10017_20102.jpg')","70dfe0cc":"convert_to_ela_image('\/kaggle\/input\/casia-dataset\/casia\/CASIA2\/Tp\/Tp_D_NRD_M_N_art10018_art10017_20102.jpg', 90)","6cf7b8d5":"dataset = pd.read_csv('\/kaggle\/input\/datasetforcasia2\/dataset_casia2.csv')","25b75214":"len(dataset)","f9b1b84f":"X = []\nY = []","76b802a6":"for index, row in dataset.iterrows():\n    X.append(array(convert_to_ela_image(row[0], 90).resize((128, 128))).flatten() \/ 255.0)\n    Y.append(row[1])","d5c480f6":"X = np.array(X)\nY = to_categorical(Y, 2)","9ef22d39":"X = X.reshape(-1, 128, 128, 3)","5813669e":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)","27799ef2":"print(len(X_train))\nprint(len(X_val))","44a7f7e6":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid', \n                 activation ='relu', input_shape = (128,128,3)))\nprint(\"Input: \", model.input_shape)\nprint(\"Output: \", model.output_shape)\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid', \n                 activation ='relu'))\nprint(\"Input: \", model.input_shape)\nprint(\"Output: \", model.output_shape)\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.25))\nprint(\"Input: \", model.input_shape)\nprint(\"Output: \", model.output_shape)\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation = \"softmax\"))","b3de51b2":"model.summary()","ea2e99f6":"from keras.optimizers import Adam","da6987f2":"optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n#optimizer = Adam()","2b037421":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","fcae600d":"early_stopping = EarlyStopping(monitor='val_acc',\n                              min_delta=0,\n                              patience=2,\n                              verbose=0, mode='auto')","46619109":"epochs = 30\nbatch_size = 100","957a5418":"history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n          validation_data = (X_val, Y_val), verbose = 1, callbacks=[early_stopping])","65198fb6":"model.save('new_model_casia.h5')","e61a8acf":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","13abfed8":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    \n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\nprint(type(Y_pred))\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","f357cff8":"print(Y_pred[0])\nprint(Y_pred_classes[0])","ce467e3a":"from keras.models import load_model\nmodel = load_model('\/kaggle\/input\/ela-cnn-casia2-premodel\/model_with_casia2.h5')","4a51b02b":"Image.open('\/kaggle\/input\/myimages1\/hetong.jpg')","022c8c79":"convert_to_ela_image('\/kaggle\/input\/myimages1\/hetong.jpg', 90)","d7695c83":"Au_filename = '\/kaggle\/input\/casia-dataset\/CASIA1\/Au\/Au_ani_0019.jpg'\nSp_filename = '\/kaggle\/input\/casia-dataset\/CASIA1\/Sp\/Sp_D_NNN_A_txt0023_txt0028_0132.jpg'\nX_pre = []\nX_pre = array(convert_to_ela_image(Sp_filename, 90).resize((128, 128))).flatten() \/ 255.0\nX_pre = np.array(X_pre)\nX_pre = X_pre.reshape(-1, 128, 128, 3)\nY_pred = model.predict(X_pre)\nprint(Y_pred.shape)\nY_pred_classes = np.argmax(Y_pred,axis = 1)\nprint(Y_pred_classes)","0f7475ea":"path_original = '\/kaggle\/input\/casia-dataset\/CASIA1\/Au\/'\npath_tampered = '\/kaggle\/input\/casia-dataset\/CASIA1\/Sp\/'\n\ntotal_orig = os.listdir(path_original)\ntotal_tampered = os.listdir(path_tampered)","003542ee":"len(total_orig),len(total_tampered)","ba0c1ac1":"images = []\n\nfor file in tqdm(total_orig):  #choose all pristine\n    try:\n        if file.endswith('jpg'):\n            if int(os.stat(path_original + file).st_size) > 10000:\n                line = path_original + file  + ',0\\n'\n                images.append(line)\n    except:\n        print(path_original+file)\n        \nfor file in tqdm(total_tampered):       #choose all tampered images\n    try:\n        if file.endswith('jpg'):\n            if int(os.stat(path_tampered + file).st_size) > 10000:\n                    line = path_tampered + file + ',1\\n'\n                    images.append(line)\n\n    except:\n          print(path_tampered+file)","d60867c5":"len(images)","4407c2ad":"X_f = []\nY_f = []\nlen(images)\nimage_name = []\nlabel = []\nfor i in tqdm(range(len(images))):\n    image_name.append(images[i][0:-3])\n    label.append(images[i][-2])","2010d24b":"print(image_name[798])\nprint(label[798])","69420299":"dataset = pd.DataFrame({'image':image_name,'class_label':label})\nfor index, row in dataset.iterrows():\n    X_f.append(np.array(convert_to_ela_image(row[0],90).resize((128, 128))).flatten() \/ 255.0)\n    Y_f.append(row[1])\n\nX_f = np.array(X_f)\nY_f = np.array(Y_f)","766c59e4":"X_f = X_f.reshape(-1, 128, 128, 3)\nY_f = to_categorical(Y_f, 2)     #y is one hot encoded","cf5409fb":"y_pred_cnn = model.predict(X_f)\ny_pred_cnn = np.argmax(y_pred_cnn,axis = 1)\n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_f,axis = 1) \n\nscore = metrics.precision_score(Y_true,y_pred_cnn, average= \"weighted\")\nprint(\"Precision score: {}\".format(score))\nscore = metrics.recall_score(Y_true, y_pred_cnn, average= \"weighted\")\nprint(\"Recall score: {}\".format(score))\nscore_lr1 = metrics.f1_score(Y_true, y_pred_cnn, average= \"weighted\")\nprint(\"F1 score: {}\".format(score_lr1))","b5136800":"cm = confusion_matrix(Y_true, y_pred_cnn)\nprint('Confusion matrix:\\n',cm)\n\nprint(classification_report(Y_true, y_pred_cnn))\n\nprint('Plot of Confusion Matrix')\ndf_cm = pd.DataFrame(cm, columns=np.unique(Y_true), index = np.unique(Y_true))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})  # font size","be1eac09":"For more information: [Indonesian documentation](https:\/\/github.com\/agusgun\/FakeImageDetector\/blob\/master\/docs\/Deteksi%20Pemalsuan%20Gambar%20dengan%20ELA%20dan%20Deep%20Learning.pdf)","3ff20e54":"### Confusion matrix","45a146e4":"With our own naked eyes, we are able to differ which is the ELA result of the real picture and which one is the result of fake image. By saying real here, what we mean is a non-CGI picture that is not fabricated\/edited in any way, e.g. splicing.","50e0ceda":"This is the result of the fake image after getting through ELA. We can compare the difference between the picture below and the real picture's ELA result.","7d129985":"### Define early stopping","95946ae4":"Let's open a real (not-fake) image as a sample.","da1c2b79":"### Accuracy and loss curves during training-validation","1728073e":"## Performance measure","ec22dc8f":"This is how it looks like after it is processed with error-level analysis (ELA).","74e91f71":"Agus Gunawan, Holy Lovenia, Adrian Hartanto Pramudita","d57d0031":"# Fake Image Detection with ELA and CNN","447ffa36":"#### Functions","6b72bc86":"This is how it looks like after it has been edited.","bbacde62":"### Sample: Real Image","3153ea27":"### Add optimizer","de1b3e56":"### Read dataset and conversion to ELA","1ed07ce4":"## Train-test split","534b3455":"![full-architecture](docs\/model-architecture.jpg \"Architecture\")","66624d47":"## Initial preparation","7c0cf8b7":"### Model training","7cb04998":"## CNN building","840f6fba":"### Reshape X","251d3ff1":"## Data preparation","937f994e":"### Sample: Fake Image","9d3615da":"### Normalization","d268d673":"\u5229\u7528\u6a21\u578b\u8fdb\u884c\u9884\u6d4b"}}