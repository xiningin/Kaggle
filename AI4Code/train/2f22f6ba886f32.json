{"cell_type":{"cce85f89":"code","8ad738df":"code","aeeb35fe":"code","a57465ad":"code","e7befcad":"code","a60ba727":"code","fbca89c7":"code","b8561d1d":"code","91b50c13":"code","1cb41a5f":"code","896436d8":"markdown","4bc8195c":"markdown","00307af6":"markdown","8dcd84fe":"markdown","d2422919":"markdown"},"source":{"cce85f89":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ad738df":"import matplotlib.pyplot as plt\n%matplotlib inline","aeeb35fe":"df = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')","a57465ad":"df.head()","e7befcad":"X = df.iloc[:,0:-1].values\ny = df.iloc[:,-1].values","a60ba727":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 40)","fbca89c7":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)","b8561d1d":"from sklearn.svm import SVC\nclf_svc = SVC(kernel = 'rbf', random_state = 1)\nclf_svc.fit(X_train, y_train)\n\nsvc_y_pred = clf_svc.decision_function(X_test)\n# svc_y_pred = clf_svc.predict(X_test)","91b50c13":"from sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\n\nclf_lr.fit(X_train, y_train)\n\nlr_y_pred = clf_lr.decision_function(X_test)\n# lr_y_pred = clf_lr.predict(X_test)","1cb41a5f":"from sklearn.metrics import roc_curve, auc\n\nlr_fpr, lr_tpr, threshold = roc_curve(y_test, lr_y_pred)\nlr_auc = auc(lr_fpr, lr_tpr)\n\nsvc_fpr, svc_tpr, threshold = roc_curve(y_test, svc_y_pred)\nsvc_auc = auc(svc_fpr, svc_tpr)\n\nplt.figure(figsize = (5,5), dpi=100)\nplt.plot(svc_fpr, svc_tpr, linestyle='-', label = \"SVC (auc  = %0.3f)\"%svc_auc)\nplt.plot(lr_fpr, lr_tpr, marker='.', label = \"Logistic (auc  = %0.3f)\"%lr_auc)\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.legend()\n\nplt.show()","896436d8":"From above its clear SVC is a good model, higher the AUC.. better the model.","4bc8195c":"Feature Scaling","00307af6":"# Logistic Classifier","8dcd84fe":"# Plot ROC and AUC","d2422919":"# SVM Classifier"}}