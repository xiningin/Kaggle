{"cell_type":{"39f514bf":"code","3126e513":"code","1763087d":"code","8021a65f":"code","0a7c02bd":"code","b8e53cf4":"code","3495c5a9":"code","884b4a6f":"code","1f4b8389":"code","3e738457":"code","335ab720":"code","93d98daa":"code","04945ce8":"code","dcb37ecf":"code","792b344c":"code","8c7ab23f":"code","ec59c506":"code","0682c0e2":"code","bfe6e44c":"markdown","7c474389":"markdown","3fe9e781":"markdown","85a72903":"markdown","ea0463a4":"markdown"},"source":{"39f514bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3126e513":"data = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndata.head()","1763087d":"# data frames from dictionary\ncountry = [\"Brazil\",\"Canada\", \"Germany\",\"UK\",\"Egypt\"]\npopulation = [\"211.742.618\",\"38.014.184\",\"83.694.929\",\"57.086.075\",\"94.400.000\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","8021a65f":"# Add new columns\ndf[\"continent\"] = [\"S.America\",\"N.America\",\"Europe\",\"Europe\",\"Africa\"]\ndf","0a7c02bd":"df[\"NoLA\"] = 0 #number of living aliens \ndf             #Broadcasting entire column","b8e53cf4":"# Plotting all data \ndata1 = data.loc[:,[\"trestbps\",\"chol\",\"thalach\"]]\n# it is confusing\ndata1.plot()","3495c5a9":"# subplots\ndata1.plot(subplots = True)\nplt.show()","884b4a6f":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"trestbps\",y = \"chol\")\nplt.show()","1f4b8389":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"thalach\",bins = 10,range= (0,250))","3e738457":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"thalach\",bins = 50,range= (0,250),ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"thalach\",bins = 50,range= (0,250),ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","335ab720":"data.describe()","93d98daa":"time_list = [\"2020-03-16\",\"2020-12-14\"]\nprint(type(time_list[1])) # As you can see date is string\n\ndatetime_object = pd.to_datetime(time_list) #turn to the datetime but actually it was string\nprint(type(datetime_object))","04945ce8":"data2 = data.tail()\ndate_list = [\"2020-03-16\",\"2020-03-19\",\"2021-03-10\",\"2021-03-16\",\"2021-04-16\"]\ndatetime_object = pd.to_datetime(date_list) \ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","dcb37ecf":"print(data2.loc[\"2021-04-16\"])\nprint(\"\\n\")\nprint(data2.loc[\"2020-03-16\":\"2021-03-10\"])","792b344c":"data2.resample(\"A\").mean()","8c7ab23f":"data2.resample(\"M\").mean()","ec59c506":"data2.resample(\"M\").first().interpolate(\"linear\") #interpolate from first value","0682c0e2":"data2.resample(\"M\").mean().interpolate(\"linear\") #interpolate with mean","bfe6e44c":"**INDEXING PANDAS TIME SERIES**\n\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","7c474389":"**RESAMPLING PANDAS TIME SERIES**\n\n1. Resampling: statistical method over different time intervals\n\nNeeds string to specify frequency like \"M\" = month or \"A\" = year\n2. Downsampling: reduce date time rows to slower frequency like from daily to weekly\n3. Upsampling: increase date time rows to faster frequency like from daily to hourly\n4. Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019","3fe9e781":"**BUILDING DATA FRAMES FROM SCRATCH**\n\n\nWe can build dataframe from dictionaries\n* zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","85a72903":"\n**STATISTICAL EXPLORATORY DATA ANALYSIS**\n\n\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","ea0463a4":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\n1. Plot\n2. Subplot\n3. Histogram:\n * bins: number of bins\n * range(tuble): min and max values of bins\n * normed(boolean): normalize or not, between 0 and 1\n * cumulative(boolean): compute cumulative distribution"}}