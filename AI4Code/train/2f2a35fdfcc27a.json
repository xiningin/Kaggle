{"cell_type":{"36bccd60":"code","0f4051d5":"code","46238257":"code","8ea7c216":"code","8b5f1ba0":"code","6e177e92":"code","d6e82eb4":"code","66c594a4":"code","f82decd0":"code","de7a1938":"code","1557f168":"code","dbe83ff3":"code","5b136628":"code","2a251d06":"code","9546b546":"code","170273fa":"code","5197d6ab":"code","719f8bbe":"code","82a6d0c6":"code","c7711563":"markdown","54729688":"markdown","cc55096c":"markdown","07b1b4ed":"markdown","9ef67700":"markdown","e7a746fb":"markdown","f1e7db3b":"markdown","6c10a1f0":"markdown","02917867":"markdown","19a53c9f":"markdown","77ca5525":"markdown","8b67af6f":"markdown","8e86cee9":"markdown","550ea7cd":"markdown","ad28a6f7":"markdown"},"source":{"36bccd60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0f4051d5":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, roc_auc_score\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nsns.set_style(\"dark\")\nimport warnings\nwarnings.filterwarnings('ignore')","46238257":"#Import datset\ndata = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndata.head(10)","8ea7c216":"data.info()","8b5f1ba0":"data.drop(['Unnamed: 32','id'], axis = 1 , inplace=True)","6e177e92":"data.describe()","d6e82eb4":"data.skew()","66c594a4":"#Visualizing Multidimensional Relationships\nplt.style.use('fivethirtyeight')\nsns.set_style(\"white\")\nsns.pairplot(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]], hue = 'diagnosis' , size=3)","f82decd0":"#create the correlation matrix heat map\nplt.figure(figsize=(10,6))\nsns.heatmap(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]].corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);\nplt.suptitle('Correlation Matrix')\n","de7a1938":"# Transform the 'yes' and 'no' values (target variable) to 1 and 0 respectively\ndata['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n\n#Scalling\nscaler =MinMaxScaler(feature_range=(0, 1))\nscaled_data =  pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n# Split the data to train and test sets\nX = scaled_data.loc[:, scaled_data.columns != 'diagnosis']\ny = scaled_data['diagnosis']","1557f168":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","dbe83ff3":"#Defining model evaluation function\ndef getModelEvaluationMetrics(classifier, model_name: str, x_test: pd.core.frame.DataFrame,\n                              y_test: pd.core.frame.DataFrame, y_predicted, plot_confusion_matrix=False,\n                              figsize=(10, 8)) -> np.ndarray:\n\n    conf_mat = confusion_matrix(y_true=y_test, y_pred=y_predicted)\n    print('Confusion matrix:\\n\\n {0}'.format(conf_mat))\n\n    if plot_confusion_matrix:\n        labels = ['M', 'B']\n        fig = plt.figure(figsize=figsize)\n        ax = fig.add_subplot(111)\n        cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n        fig.colorbar(cax)\n        ax.set_xticklabels([''] + labels)\n        ax.set_yticklabels([''] + labels)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('Predicted')\n        plt.ylabel('Expected')\n        plt.title(f'Confusion Matrix for {model_name}', fontweight='bold')\n        plt.show()\n\n    # Calculating the precision (tp\/tp+fp)\n    precision = str(np.round((conf_mat[1][1] \/ (conf_mat[1][1] +\n                              conf_mat[0][1])) * 100, 2))\n    print('The precision is: {0} %'.format(precision))\n\n    # Calculating the recall (tp\/tp+fn)\n    recall = str(np.round((conf_mat[1][1] \/ (conf_mat[1][1] +\n                           conf_mat[1][0])) * 100, 2))\n    print('The recall is: {0} %'.format(recall))\n\n    return conf_mat","5b136628":"#Defining function for performing a full ROC analysis\ndef createROCAnalysis(classifier, model_name: str, y_test: pd.core.series.Series, pred_probs: np.ndarray,\n                      plot_ROC_Curve=False, figsize=(10, 8)) -> int:\n   \n    if plot_ROC_Curve:\n        plt.figure(figsize=figsize)\n        plt.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier')\n        fp_rate, tp_rate, _ = roc_curve(y_test, pred_probs[:, 1])\n        plt.plot(fp_rate, tp_rate, marker='.', label=model_name)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve for {model_name}', fontweight='bold')\n        plt.grid(True, alpha=0.1, color='black')\n        plt.legend(loc='lower right')\n        plt.show()\n\n    # Calculate Area Under Curve (AUC) for the Receiver Operating\n    # Characteristics Curve (ROC)\n    auc_score = np.round(roc_auc_score(y_test, pred_probs[:, 1]), 4)\n    print(f'{model_name} - ROC AUC score: {auc_score}')\n\n    return auc_score","2a251d06":"# Instantiate the Random Forest model\n#Pre-tuned Hyperparameter of Random Forest Classifier on this dataset\n\nrf_class = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features=10, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=20, min_samples_split=20,\n            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n# Assign the above probabilities to the corresponding class ('no', 'yes')\nrf_class.fit(X_train, y_train)\nrf_y_pred = rf_class.predict(X_test)\n# Evaluate the model by using Recall\/Precission:\ngetModelEvaluationMetrics(classifier=rf_class, model_name='Random Forest',x_test=X_test, y_test=y_test,\n                              y_predicted=rf_y_pred, plot_confusion_matrix=True, figsize=(8,6))","9546b546":"# Evaluate the model by using ROC Curve:\nrf_pred_probs = rf_class.predict_proba(X_test)\ncreateROCAnalysis(classifier=rf_class, model_name='Random Forest', y_test=y_test, pred_probs=rf_pred_probs,\n                  plot_ROC_Curve=True, figsize=(8,6))","170273fa":"feature_importance = {}\nbest_estimator_fi = rf_class.feature_importances_\n\nfor feature, importance in zip(X_train.columns, best_estimator_fi):\n    feature_importance[feature] = importance\n\nimportances = pd.DataFrame.from_dict(feature_importance, orient='index').rename(columns={0: 'Gini Score'})\n\nimportances = importances.sort_values(by='Gini Score', ascending=False)\n# Plot for feature importance\nplt.figure(figsize=(20, 8))\nplt.style.use('fivethirtyeight')\nsns.set_style(\"white\")\nsns.barplot(x=importances.index[0:10],\n            y=importances['Gini Score'].iloc[0:10], palette='muted')\nplt.title(f'Importance for the Top 10 Features (Gini criterion) ',\n          fontweight='bold')\nplt.grid(True, alpha=0.1, color='black')\nplt.show()","5197d6ab":"sc = StandardScaler()\nX_s = sc.fit_transform(X)\n\npca = PCA(n_components = 10)\nX_pca = pca.fit_transform(X_s)\n\nPCA_df = pd.DataFrame()\n\nPCA_df['PCA_1'] = X_pca[:,0]\nPCA_df['PCA_2'] = X_pca[:,1]\n\nplt.plot(PCA_df['PCA_1'][data.diagnosis == 1],PCA_df['PCA_2'][data.diagnosis == 1],'o', alpha = 0.7, color = 'r')\nplt.plot(PCA_df['PCA_1'][data.diagnosis == 0],PCA_df['PCA_2'][data.diagnosis == 0],'o', alpha = 0.7, color = 'b')\nplt.xlabel('PCA 1')\nplt.ylabel('PCA 2')\nplt.legend(['Malignant','Benign'])\nplt.show()","719f8bbe":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\npca = PCA(n_components = 10)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\n# Assign the above probabilities to the corresponding class ('no', 'yes')\nrf_class.fit(X_train, y_train)\nrf_y_pred = rf_class.predict(X_test)\n# Evaluate the model by using Recall\/Precission:\ngetModelEvaluationMetrics(classifier=rf_class, model_name='Random Forest',x_test=X_test, y_test=y_test,\n                              y_predicted=rf_y_pred, plot_confusion_matrix=True, figsize=(8,6))","82a6d0c6":"# Evaluate the model by using ROC Curve:\nrf_pred_probs = rf_class.predict_proba(X_test)\ncreateROCAnalysis(classifier=rf_class, model_name='Random Forest', y_test=y_test, pred_probs=rf_pred_probs,\n                  plot_ROC_Curve=True, figsize=(8,6))\n","c7711563":"> # Exploratory Data Analysis (EDA)","54729688":"> Let's load libraries ","cc55096c":"**Let's drop the unnecessary data (NULL)**","07b1b4ed":"![image.png](attachment:f1190e9a-0b29-424b-aee0-a0acc7cb3b08.png)","9ef67700":"**Let\u2019s evaluate the same algorithms with a standardized copy of the dataset. Here, I use sklearn to scale and transform the data such that each attribute has a mean value of zero and a standard deviation of one.**","e7a746fb":"**The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.**","f1e7db3b":"> # Conclution\n\n**Using PCA I used only 10 components (important) from the dataset, though it contains 30 components! However, with PCA+RF the model slightly outweigh in recall, precision and ROC AUC score than that of the previous model.\n**\n* Random Forest Model Prediction without PCA\n\n**The precision is: 95.24 %\nThe recall is: 93.02 %\nROC AUC score: 0.9954**\n* Random Forest Model Prediction with PCA\n\n**The precision is: 97.62 %\nThe recall is: 95.35 %\nROC AUC score: 0.9974**","6c10a1f0":"> # Data Preprocessing\u00b6","02917867":"**The skew result show a positive (right) or negative (left) skew. Values closer to zero show less skew. From the graphs, we can see that radius_mean, perimeter_mean, area_mean, concavity_mean and concave_points_mean are useful in predicting cancer type due to the distinct grouping between malignant and benign cancer types in these features. We can also see that area_worst and perimeter_worst are also quite useful.**","19a53c9f":"> # Feature decomposition using Principal Component Analysis( PCA)","77ca5525":"# **Breast Cancer Wisconsin (Diagnostic) Data Set**","8b67af6f":"> # Breast Cancer Prediction","8e86cee9":"**Transform the 'M' and 'B' values (target variable) to 1 and 0 respectively. Following the encoding of the categorical features, we will continue with the normalization (scalling) of the numerical features. For this we will use the MinMax scalling method.**","550ea7cd":"> # Model Evaluation Metrics\u00b6\n\nFor model evaluation and To perform a full ROC analysis let's define two functions","ad28a6f7":"We will start with Dataset Description\n\nThe Breast Cancer datasets is available UCI machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.\n\nThe first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnosis (M=malignant, B=benign), respectively. The columns 3-32 contain 30 real-value features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.\n\n1= Malignant (Cancerous) - Present (M)\n0= Benign (Not Cancerous) -Absent (B\n\nAttribute Information:\n\n1) ID number\n2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)\nb) texture (standard deviation of gray-scale values)\nc) perimeter\nd) area\ne) smoothness (local variation in radius lengths)\nf) compactness (perimeter^2 \/ area - 1.0)\ng) concavity (severity of concave portions of the contour)\nh) concave points (number of concave portions of the contour)\ni) symmetry\nj) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant\n\n"}}