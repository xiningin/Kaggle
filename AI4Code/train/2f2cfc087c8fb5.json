{"cell_type":{"42596269":"code","b16e523f":"code","d68af275":"code","d0db1f98":"code","6ec030af":"code","9e728892":"code","a0c25d96":"code","1f606cd9":"code","ff632e6f":"code","99264050":"code","a61a902e":"code","4593619d":"code","fb2ad029":"code","ce03cfea":"code","cd3dfb97":"code","52e28efa":"code","61e8233a":"code","62cc74af":"code","73b5e546":"code","798f58a1":"code","36ded0de":"code","9d7637b6":"code","189437c9":"code","8b9fd074":"code","abf3e36f":"code","fe39effe":"code","ab314a9e":"code","a5a6b34b":"code","e79e0f72":"code","25a09ced":"code","27409dc4":"code","f5478f2c":"code","8fa5f90c":"code","45db39ef":"markdown","cb51f50c":"markdown","b2e971e6":"markdown","68c3bb63":"markdown","28764382":"markdown","5d4c9b07":"markdown","612efb69":"markdown","aef590b2":"markdown","8d3dd75c":"markdown","f9d1e66e":"markdown","e7efb292":"markdown","01fb56ac":"markdown","86a2b201":"markdown","39c120a6":"markdown","f1ba4396":"markdown","986280d2":"markdown","027e10c8":"markdown","8ac69ba8":"markdown","f2a31ad1":"markdown","ef67a437":"markdown","a7c1a024":"markdown","09aa7e91":"markdown","2fb27ce6":"markdown","ae1818e4":"markdown","22de2a9c":"markdown","8519da1a":"markdown","a76950cc":"markdown","a4ec9bfb":"markdown","df25c71f":"markdown","2b5033a4":"markdown","70c2b43b":"markdown","0549a4cd":"markdown","9d9ae5e2":"markdown"},"source":{"42596269":"#Import All Necessary libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns #Data Visulation \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical #convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\n\n\nimport keras \nfrom keras.datasets import mnist\nimport tensorflow as tf\n\nprint(\"Tensorflow version \" + tf.__version__)\n\n\nnp.random.seed(123)","b16e523f":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","d68af275":"#check the file in the dicretory \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d0db1f98":"#load data from that dicretory \ntrain_data=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","6ec030af":"#separate the independent and dependent variables (values of X and Y)\n\nY_train=train_data['label']\n\n#drop \"lable\" column \nX_train=train_data.drop('label', axis=1)\n","9e728892":"(x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()\n\nx_train1 = np.concatenate([x_train0, x_test0], axis=0)\ny_train1 = np.concatenate([y_train0, y_test0], axis=0)\n\nX_train_keras = x_train1.reshape(-1, 28*28)\nY_train_keras = y_train1\n","a0c25d96":"X_train = np.concatenate((X_train.values, X_train_keras))\nY_train = np.concatenate((Y_train, Y_train_keras))","1f606cd9":"print(X_train.shape)\nprint(Y_train.shape)","ff632e6f":"#Statistical summary for test data\nprint(test_data.shape)\ntest_data.head()","99264050":"#Counts images for every digit\nunique, counts = np.unique(Y_train, return_counts=True)\ndict(zip(unique, counts))","a61a902e":"\n\n\n#Diplay bar chart \nsns.set(context='notebook', style='darkgrid', palette='deep')\ng = sns.countplot(Y_train)","4593619d":"#convert values to float\nX_train = X_train.astype('float32')\nY_train = Y_train.astype('float32')\ntest_data=test_data.astype('float32')\n\n# Normalize the data\nX_train = X_train \/ 255.0\ntest_data = test_data \/ 255.0","fb2ad029":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","ce03cfea":"# Encode labels to one hot vectors (ex : 9 -> [0,0,0,0,0,0,0,0,0,1])\nY_train=to_categorical(Y_train, num_classes=10)\n\nprint(f\"Label size {Y_train.shape}\")\n","cd3dfb97":"# Split the train and the validation set for the fitting\n\nX_train, X_val, Y_train, Y_val=train_test_split(X_train, Y_train, test_size=0.10, random_state=44)\n\n# 10% for Validation data, 90% for training data","52e28efa":"#print the sizes of datasets\nprint(\"The size of X_train : {}\\nThe size of Y_train : {}\\nThe size of X_val   : {}\\nThe size of Y_val   : {}\\n\"\n      .format(X_train.shape,Y_train.shape,X_val.shape,Y_val.shape))\n\n","61e8233a":"#Conver X_train to shape (num_images, img_rows, img_cols) for plotting \nX_train_temp = X_train.reshape(X_train.shape[0], 28, 28)\n\nfig, axis = plt.subplots(3, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train_temp[i], cmap='binary')\n    digit = Y_train[i].argmax()\n    ax.set(title = f\"Real Number is {digit}\");","62cc74af":"model= Sequential()\n\nmodel.add(Conv2D(input_shape=(28,28,1), filters=32, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.10))\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.10))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(BatchNormalization())\n\n\n\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","73b5e546":"from keras.utils import plot_model\nplot_model(model, to_file='model_chart.png', show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage(\"model_chart.png\")","798f58a1":"#Define the optimizer\noptimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","36ded0de":"#cmpile the model\nmodel.compile(optimizer= optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","9d7637b6":"# Set a learning rate annealer\nlearning_rate_redcuing=ReduceLROnPlateau(monitor='val_accuracy', \n                                         patience=2,\n                                         verbose=1,\n                                         factor=0.5,\n                                         min_lr=0.00001)","189437c9":"#stops training when accuracy do not improved\n#earlystopper = EarlyStopping(monitor='val_accuracy', min_delta=0,\n               #              patience=6, verbose=1, mode='auto')","8b9fd074":"epochs = 50 # \nbatch_size = 64","abf3e36f":"#Do data augmentation to prevent overfitting\n\nimagegen=ImageDataGenerator(\n                            featurewise_center=False, #set input mean to 0 over the dataset\n                            samplewise_center=False, #set each sample mean to 0\n                            featurewise_std_normalization=False, #divide inputs by std of the dataset\n                            samplewise_std_normalization=False, #divide each input by its std\n                            zca_whitening=False, #apply ZCA whitening\n                            rotation_range=10, #randomly rotate images in the range (degrees, 0 to 180)\n                            zoom_range=0.1, #randomly zoom image \n                            width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n                            height_shift_range=0.1, #randomly shift images vertically (fraction of total height)\n                            horizontal_flip=False, #randomly flip images\n                            vertical_flip=False)\n    \nimagegen.fit(X_train)","fe39effe":"#Training data (Fit the model)\n\nhistory=model.fit_generator(imagegen.flow(X_train, Y_train,batch_size=batch_size),\n                                          epochs=epochs,\n                                          validation_data=(X_val, Y_val),\n                                          verbose=2,\n                                          steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                                          callbacks=[learning_rate_redcuing])\n                                          \n","ab314a9e":"#Save the model\nmodel.save(\"MNIST_CNN_Model.h5\")\nmodel.save_weights(\"MNIST_CNN_Model_weights.h5\")","a5a6b34b":"# Plot the loss and accuracy curves for training and validation \n\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"Validation Loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training Accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation Accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","e79e0f72":"# Predict the values from the validation dataset\nY_pred=model.predict(X_val)\n\n#Convert predictions classes to one hot vectors\nY_pred_classes=np.argmax(Y_pred, axis=1)\n\n# Convert validation observations to one hot vectors\nY_true=np.argmax(Y_val, axis=1)\n\n# compute the confusion matrix\nconfusion_mtx=confusion_matrix(Y_true, Y_pred_classes)\n\n# plot the confusion matrix\nplt.figure(figsize=(10, 10)) #The size of plot chart\nconf_plot=sns.heatmap(confusion_mtx, annot=True, fmt='d', linewidths=.1, linecolor='black', cmap=\"YlGnBu\", square=True)\n\n#set title and labels\nconf_plot.set(xlabel=\"Predicted label\", ylabel = 'True label', title='Confusion Matrix')","25a09ced":"#Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","27409dc4":"y_pred = model.predict(X_val)\nX_test_temp = X_val.reshape(X_val.shape[0], 28, 28)\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test_temp[i], cmap='binary')\n    ax.set(title = f\"Real Number is {Y_val[i].argmax()}\\nPredict Number is {y_pred[i].argmax()}\");","f5478f2c":"# predict results\nresults = model.predict(test_data)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","8fa5f90c":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"sample_submission.csv\",index=False)\n\nsubmission.head()","45db39ef":"# 2.4 Reshape\n","cb51f50c":"Some errors are due to an error in writing digits by hand","b2e971e6":"Confusion matrix can be very helpfull to see your model drawbacks.\n\nI plot the confusion matrix of the validation results.","68c3bb63":"# 2.6 Split training and valdiation set","28764382":"# 3.Convolutional Neural Network(CNN)","5d4c9b07":"# 5.1 Prediction validation results","612efb69":"# 4.1 Training and validation curves","aef590b2":"# 3.4 Training the dataset","8d3dd75c":"# 2.3 Normalization","f9d1e66e":"# 3.1 Define the model","e7efb292":"# 5.2 Submition","01fb56ac":"# 2.1 Load data","86a2b201":"# 5. Prediction and submition","39c120a6":"Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 0 -> [1,0,0,0,0,0,0,0,0,0]).","f1ba4396":"For most image data, the pixel values are integers with values between 0 and 255. Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1\n\n","986280d2":"We have 112,000 entries (every entry is image), and 8 labels (every label represens a digit from 0 to 9) and we have 784 columns (784 columns for pixels, every column represens a pixel in image). \nNote: The size is image is 28*28, so the total pixels for that image is 784 pixels","027e10c8":"# 4.2 Confusion matrix","8ac69ba8":"# 2.7 Data Visualization","f2a31ad1":"We know that keras has a MNIST dataset, I will merge this dataset with our dataset to increase the nunber of samples to get more accuracy","ef67a437":"# 4. Evaluate the model","a7c1a024":"For test data we have 28,000 entries (images)","09aa7e91":"# 3.2 Set the optimizer and annealer","2fb27ce6":"# 4.3 Compare True lables with misclassified lables","ae1818e4":"**TPU or GPU detection**","22de2a9c":"This notebook based on my modification of those notebooks:\n1. https:\/\/www.kaggle.com\/loveunk\/kaggle-digit-recognizer-keras-cnn-100-accuracy\n2. https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n3. https:\/\/www.kaggle.com\/elcaiseri\/mnist-simple-cnn-keras-accuracy-0-99-top-1","8519da1a":"# 2. Data preparation and preprocessing","a76950cc":"# 2.5 Label encoding","a4ec9bfb":"# 1. Introduction ","df25c71f":"Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.","2b5033a4":"You can see some of misclassified lables like 9 and 8; the model He cannot distinguish them in some images. Some thing to 6 and 0.\n\nNow, let us see those error by chart.\n\nI get the full code in the next cell from: https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6","70c2b43b":"This cell will enable TPU if is set accelerator as TPU when create the notebook","0549a4cd":"In this notebook I will use Convolutional Neural Network with Keras API to build Digit Recognizer model by use TPU.","9d9ae5e2":"# 3.3 Data augmentation"}}