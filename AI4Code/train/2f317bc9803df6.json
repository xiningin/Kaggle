{"cell_type":{"839235ce":"code","f9568c96":"code","ed2f0a66":"code","dd679428":"code","f73f5a45":"code","c5f0dd5a":"code","68722719":"code","f4b1b096":"code","041a81bb":"code","fd88227e":"code","657f29f4":"code","d71a96fa":"code","13f63bc0":"code","82f3e1fe":"code","9669a2e4":"code","dad5340d":"code","5b011cf7":"markdown","ea358f26":"markdown","50849f2f":"markdown","bb541854":"markdown","ec1f455e":"markdown","004016a8":"markdown"},"source":{"839235ce":"# training chart showing mAP score and iteration details\nfrom IPython.display import Image\nImage(\"..\/input\/wheat-yolov4-training-results\/chart_wheat_608.png\")","f9568c96":"# console output of the detection with default iou threshold\nImage(\"..\/input\/wheat-yolov4-training-results\/detect_map_wheat.JPG\")","ed2f0a66":"# console output of the detection with custom iou threshold\nImage(\"..\/input\/wheat-yolov4-training-results\/detect_map_wheat_thres.JPG\")","dd679428":"Image(\"..\/input\/wheat-yolov4-training-results\/2fd875eaa.jpg\")","f73f5a45":"Image(\"..\/input\/wheat-yolov4-training-results\/348a992bb.jpg\")","c5f0dd5a":"Image(\"..\/input\/wheat-yolov4-training-results\/51b3e36ab.jpg\")","68722719":"Image(\"..\/input\/wheat-yolov4-training-results\/51f1be19e.jpg\")","f4b1b096":"Image(\"..\/input\/wheat-yolov4-training-results\/53f253011.jpg\")","041a81bb":"Image(\"..\/input\/wheat-yolov4-training-results\/796707dd7.jpg\")","fd88227e":"Image(\"..\/input\/wheat-yolov4-training-results\/aac893a91.jpg\")","657f29f4":"Image(\"..\/input\/wheat-yolov4-training-results\/cb8d261a3.jpg\")","d71a96fa":"Image(\"..\/input\/wheat-yolov4-training-results\/cc3532ff6.jpg\")","13f63bc0":"Image(\"..\/input\/wheat-yolov4-training-results\/f5a1f0358.jpg\")","82f3e1fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/working\/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# import required libraries\nimport io\nimport time\nimport math\nimport cv2, colorsys\nfrom PIL import Image, ImageEnhance, ImageFilter\nimport imgaug.augmenters as iaa\nfrom matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n\nfrom functools import wraps, reduce\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.lite.python import interpreter as interpreter_wrapper\nfrom tensorflow.keras.layers import Conv2D, DepthwiseConv2D, Concatenate, MaxPooling2D, BatchNormalization, Activation, UpSampling2D, ZeroPadding2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.regularizers import l2\n\nprint(\"TensorFlow version is: {}\".format(tf.__version__))\nprint(\"Eager execution is: {}\".format(tf.executing_eagerly()))\nprint(\"Keras version is: {}\".format(tf.keras.__version__))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9669a2e4":"!python ..\/input\/yolo2keraswbf\/keras-YOLOv3-model-set\/tools\/evaluation\/validate_yolo.py --model_path=..\/input\/yolo2keraswbf\/keras-YOLOv3-model-set\/weights\/wheat_yolov4.h5 --image_file=..\/input\/global-wheat-detection\/test\/ --anchors_path=..\/input\/yolo2keraswbf\/keras-YOLOv3-model-set\/configs\/yolo4_anchors.txt --classes_path=..\/input\/yolo2kerastta\/keras-YOLOv3-model-set\/configs\/wheat_classes.txt --model_image_size=1024x1024","dad5340d":"print(\"+++++++++++++++++++++++++++++++++ Completed +++++++++++++++++++++++++++++++++++++++++++\")","5b011cf7":"1. TTA with WBF is not working with my YOLOv4.In this version I will use model trained on 1024x1024 resolution.","ea358f26":"**Below script will run on test images and then generate the submission file**","50849f2f":"**Framework used for the training: Darknet**\n**[https:\/\/github.com\/AlexeyAB\/darknet](http:\/\/)**\n\n**License of the above framework:**\n**[https:\/\/github.com\/AlexeyAB\/darknet\/blob\/master\/LICENSE](http:\/\/)**\n\n**++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Repository used for converting YOLOv4 weights into keras\/TF2:**\n**[https:\/\/github.com\/david8862\/keras-YOLOv3-model-set](http:\/\/)**\n\n**License of the above repository:**\n**[https:\/\/github.com\/david8862\/keras-YOLOv3-model-set\/blob\/master\/LICENSE](http:\/\/)**\n\n**++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Training Details:**\n* I prepared the annotation files as per required for AlexeyAB\/darknet's YOLOv4 from below kernel\n**[https:\/\/www.kaggle.com\/pabloberhauser\/creating-label-files-for-use-in-yolov4](http:\/\/)**\n \n* I followed following steps for the training:\n**[https:\/\/github.com\/AlexeyAB\/darknet#how-to-train-to-detect-your-custom-objects](http:\/\/)**\n\n* After lots of trial with different parameters in configuration I achieved best mAP score in training-\n\nwithout iou_thresh=0.05, mAP=0.931018\n\nwith iou_thresh=0.05, mAP=0.974559\n\n* I performed the training in my local system with following configurations-\nWindows 10, Core i7, GeForce GTX 1660 Ti, 16 GB RAM, CUDA 10.1, cuDNN 7.6.5\n\n* The final training took around 36 hours in completion\n\n**+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Preparing Submission File:**\n\nI have made required changes and added my logic in following file '..\/input\/yolo2keras\/keras-YOLOv3-model-set\/tools\/evaluation\/validate_yolo.py'\n\n**+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Problem Faced:**\n\n* Could not train the model with the higher resolution image in my system due to memory error.\n\n* Could not able to use the original darknet command '.\\darknet.exe detector test..' command to test the detection on new images. Since internet is not allowed and when I uploaded the compiled Darknet repo then I was getting permission denied error due to kaggl's input directory policy.\n\n* Could not use OpenCV-Python DNN module with YOLOv4 since current version of OpenCV does not support it.\n\n* Due to above issues, I converted the YOLOv4 weights into keras\/TF2 and then make inference out of it. Making the submission file was not easy with this.\n\n* Faced 'Submission csv not found' error many times while submitting the csv file.\n**+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Experiments**\n\n* with iou_threshold=0.4, score=0.6626\n* with iou_threshold=0.05, score decreased to 0.6426\n* with WBF code, score=0.6815\n* with TTA and WBF, score=0.6135\n* with improved TTA and WBF, score=0.6352\n","bb541854":"## Testing Result-","ec1f455e":"## YOLOv4 Training Result -","004016a8":"**In this notebook I have taken care of licensing rule.**\n\n**The repositories I am using in this notebook have licenses as required for this challenge.**\n\n**My this notebook also demonstrates how can we use Darknet's YOLOv4 with Keras and TensorFlow.**\n\n**We can also use OpenCV with YOLOv4 but current version of OpenCV does not support some new changes in YOLOv4.**\n\n**We can run this notebook with or without GPU**"}}