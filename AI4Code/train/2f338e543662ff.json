{"cell_type":{"9f866e1c":"code","0b291fdc":"code","62ffde0f":"code","e1207631":"code","3e57faaf":"code","c3e3ab1c":"code","aeb5b6ea":"code","8f4728c7":"code","a3f43c3d":"code","fb383e92":"code","6cbab3d7":"code","8834f337":"code","d9de20f5":"code","e5d15980":"code","c30a6417":"code","18cc4a5c":"code","493cfdf9":"code","b0f5a8b0":"code","1d80a9ae":"code","c388e91c":"markdown","959c4a72":"markdown","1ed3c4e4":"markdown","b6b1cede":"markdown","74a4a90f":"markdown","af962156":"markdown","1e9f1c16":"markdown","51a001a1":"markdown"},"source":{"9f866e1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b291fdc":"import os\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport cv2\nimport albumentations as A\nfrom sklearn import metrics as sk_metrics\nfrom skimage.io import imread\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split ","62ffde0f":"BASE_DIR = \"..\/input\/cassava-leaf-disease-classification\/\"\nTRAIN_PATH = BASE_DIR + \"train_images\/\"","e1207631":"with open(os.path.join(BASE_DIR, \"label_num_to_disease_map.json\")) as file:\n    map_classes = json.loads(file.read())\n    map_classes = {int(k) : v for k, v in map_classes.items()}\n    \nprint(json.dumps(map_classes, indent=4))","3e57faaf":"input_files = os.listdir(os.path.join(BASE_DIR, \"train_images\"))\nprint(f\"Number of train images: {len(input_files)}\")","c3e3ab1c":"datos = pd.read_csv(BASE_DIR+\"train.csv\")\ndatos","aeb5b6ea":"datos.groupby('label')['image_id'].count()","8f4728c7":"IMAGE_WIDTH = IMAGE_HEIGHT = 64\ndef cargar_fotos(directorio):\n    X = []\n    Y = []\n    for image in os.listdir(directorio):\n        foto = imread(directorio+image)\n        smallimage = cv2.resize(foto, (IMAGE_WIDTH, IMAGE_HEIGHT)) \n        X.append(smallimage) \n        category = datos[datos[\"image_id\"] == image]['label'].values[0]\n        Y.append(category)\n\n    return np.array(X), np.array(Y)","a3f43c3d":"X_train, y_train = cargar_fotos(TRAIN_PATH)","fb383e92":"plt.imshow(X_train[0]);","6cbab3d7":"# solo ejecutar una vez\nprint(\"Min:\", np.min(X_train))\nprint(\"Max:\", np.max(X_train))\n\nX_train = X_train \/ 255.0\n\nprint(\"Min:\", np.min(X_train))\nprint(\"Max:\", np.max(X_train))","8834f337":"from sklearn.utils import shuffle \n\nX_train, y_train = shuffle(X_train, y_train, random_state = 42)","d9de20f5":"X = X_train\ny = y_train","e5d15980":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","c30a6417":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3),   \n                        activation = 'relu',\n                       input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)),  \n    \n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(64, (3,3),\n                       activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation = 'relu'),\n    tf.keras.layers.Dense(5, activation = 'softmax') \n    \n])","18cc4a5c":"model.compile(optimizer = 'adam',      # que funcion de coste minimizar\n             loss = 'sparse_categorical_crossentropy', #sparse_categorical_crossentrophy si tuvieramos mas\n              metrics = ['accuracy'])","493cfdf9":"from keras.callbacks import EarlyStopping\nearlystop = EarlyStopping(patience=2)","b0f5a8b0":"history = model.fit(X_train,\n                   y_train,\n                   epochs = 5,\n                    callbacks = [earlystop],\n                   validation_split = 0.2)","1d80a9ae":"results = model.evaluate(X_test, y_test)\nprint(\"test loss, test acc:\", results)","c388e91c":"# Shuffle","959c4a72":"# Cargar las fotos","1ed3c4e4":"# Modelos","b6b1cede":"# Nombres Directorios","74a4a90f":"# Estandarizar","af962156":"# Direccion","1e9f1c16":"# Separar datos en train y test","51a001a1":"# Imports"}}