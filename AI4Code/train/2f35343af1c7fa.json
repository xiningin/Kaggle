{"cell_type":{"f16c6c67":"code","7aae2878":"code","ece294f3":"code","15d522d0":"code","f4d95379":"code","1df220c7":"code","5dfb5384":"code","26fa0218":"code","76fc8a27":"code","fab1fa41":"code","9e45423d":"code","0c8a2edf":"code","df1d9819":"code","26baeacd":"code","b00b2285":"code","10eef0df":"code","04b5d035":"code","4f7b6f36":"code","503c6f97":"code","73be6784":"code","bfa57e86":"code","25eb26b7":"code","af7f2af7":"code","3d747638":"code","9921f02a":"code","706186d3":"code","9b8d00b3":"code","3c628eee":"code","40030db1":"code","55cb3456":"code","97c36e7f":"code","1bf81a26":"code","4bd89b26":"code","4b9f30bc":"code","c3588891":"code","66aaaf49":"code","27533fa0":"code","58536ed3":"code","77a52cba":"code","16e06e90":"code","7147adeb":"markdown","fdd89df0":"markdown","0c37d983":"markdown","3ed94481":"markdown","cff1250b":"markdown","d0e928f7":"markdown","f8d64d2b":"markdown","44686b98":"markdown","e57e1916":"markdown","8d31d79d":"markdown"},"source":{"f16c6c67":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport os ","7aae2878":"os.makedirs('.\/COVID19-DATASET\/train\/covid19')\nos.makedirs('.\/COVID19-DATASET\/train\/normal')\n","ece294f3":"os.makedirs('.\/COVID19-DATASET\/test\/covid19')\nos.makedirs('.\/COVID19-DATASET\/test\/normal')","15d522d0":"os.makedirs('.\/COVID19-DATASET\/val\/covid19')\nos.makedirs('.\/COVID19-DATASET\/val\/normal')","f4d95379":"COVID_PATH = '..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/COVID'\nNORMAL_PATH = '..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Normal'","1df220c7":"from distutils.dir_util import copy_tree\nfromDirectory= '..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/COVID'\ntoDirectory='.\/COVID19-DATASET\/train\/covid19'\ncopy_tree(fromDirectory, toDirectory)","5dfb5384":"fromDirectory= '..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Normal'\ntoDirectory='.\/COVID19-DATASET\/train\/normal'\ncopy_tree(fromDirectory, toDirectory)","26fa0218":"fromDirectory= '..\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'\ntoDirectory='.\/COVID19-DATASET\/train\/covid19'\ncopy_tree(fromDirectory, toDirectory)","76fc8a27":"fromDirectory= ('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/COVID'[:1000])\ntoDirectory='.\/COVID19-DATASET\/test\/covid19'\ncopy_tree(fromDirectory, toDirectory)","fab1fa41":"fromDirectory= ('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Normal'[:1000])\ntoDirectory='.\/COVID19-DATASET\/test\/normal'\ncopy_tree(fromDirectory, toDirectory)","9e45423d":"from distutils.dir_util import copy_tree\nfromDirectory= ('..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\/NORMAL'[:200])\ntoDirectory='.\/COVID19-DATASET\/val\/normal'\ncopy_tree(fromDirectory, toDirectory)","0c8a2edf":"from distutils.dir_util import copy_tree\nfromDirectory= ('..\/input\/covid19-xray-images-using-cnn\/images\/test\/corona'[:200])\ntoDirectory='.\/COVID19-DATASET\/val\/covid19'\ncopy_tree(fromDirectory, toDirectory)","df1d9819":"train_path = '.\/COVID19-DATASET\/train'\nval_path = '.\/COVID19-DATASET\/val'\ntest_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/'\n#test_path= test_data","26baeacd":"# re-size all the images to a size VGG-16 expects.\nIMAGE_SIZE = [224, 224]\n\n# Set the batch size\nBATCH_SIZE = 32  # try reducing batch size or freeze more layers if your GPU runs out of memory\nNUM_EPOCHS = 5\nLEARNING_RATE = 0.0001\nNUM_CLASSES = 2 # We are aware of it.","b00b2285":"import os\nCLASSES = os.listdir(train_path)\nNUM_CLASSES = len(CLASSES)","10eef0df":"print(\"Class --> {} \\n and the length is : {}\".format(CLASSES, NUM_CLASSES))","04b5d035":"# Image Data Augmentation\n\ntrain_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)","4f7b6f36":"# Import the images from the train dataset.\n# Make sure to provide the same target size as initialied for the image size\ntraining_set = train_datagen.flow_from_directory(\n    directory = train_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","503c6f97":"test_datagen = ImageDataGenerator(rescale = 1.\/255)","73be6784":"# Import the images from the test dataset.\n\ntest_set = test_datagen.flow_from_directory(\n    directory = test_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","bfa57e86":"# Import the VGG 16 library as shown below and add preprocessing layer to the front of VGG\n# Here we will be using imagenet weights\n\nvgg = VGG16(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)","25eb26b7":"# don't train existing weights\nfor layer in vgg.layers:\n    layer.trainable = False","af7f2af7":"### Sample... for adding Pooling (optional)\n# global_average_layer = GlobalAveragePooling2D()\n\n# prediction = Dense(NUM_CLASSES,activation='softmax')","3d747638":"# our layers - you can add more if you want\nx = Flatten()(vgg.output)\n\nprediction = Dense(NUM_CLASSES, activation='softmax')(x)","9921f02a":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)","706186d3":"model.summary()","9b8d00b3":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","3c628eee":"history = model.fit(\n  training_set,\n  validation_data=test_set,\n  epochs=5,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","40030db1":"model.save('my_model.h5')","55cb3456":"val_path = '.\/COVID19-DATASET\/val'","97c36e7f":"# Generate Validation set.\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nvalidation_set = validation_datagen.flow_from_directory(\n    directory = val_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","1bf81a26":"validation_steps = 200\n\nloss0,accuracy0 = model.evaluate(validation_set, steps = validation_steps)\n\nprint(\"loss: {:.2f}\".format(loss0))\nprint(\"accuracy: {:.2f}\".format(accuracy0))","4bd89b26":"# Generate Validation set.\nvalidation_set2 = validation_datagen.flow_from_directory(\n    directory = val_path,\n    target_size = (224, 224),\n    batch_size = 1,\n    shuffle=False, \n    seed=42, \n    class_mode=\"binary\"\n)\n\n# validation_set2.reset()","4b9f30bc":"# just capture the loss and accuray into val variable... unlike in pervious code to capture into loss0 and accuracy0. Just to showcase alternate way.\n\nval = model.evaluate(validation_set, steps = validation_steps)\n\nprint(\"loss: {:.2f}\".format(val[0]))\nprint(\"accuracy: {:.2f}\".format(val[1]))","c3588891":"# summarize history for loss\n\nplt.plot(history.history['loss'], label='Train loss')\nplt.plot(history.history['val_loss'], label='Validation (Test) loss')\nplt.title('summarize history for loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","66aaaf49":"# summarize history for accuracy\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('summarize history for accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","27533fa0":"# get sample image to test.\nimg_normal = image.load_img('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Normal\/Normal-10.png', target_size = (224, 224))\nimg_pneumonia = image.load_img('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/person1947_bacteria_4876.jpeg', target_size = (224, 224))","58536ed3":"def model_predict(img, actual):\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis = 0)\n    x_processed = preprocess_input(x)\n    result = model.predict(x_processed)\n    if(result[0][0]<.50):\n        result=\"normal\"\n    else:\n        result=\"corona positive\"\n        \n    plt.figure()\n    plt.imshow(img)\n    plt.title('Actual : {} --> Predicted  : {}'.format(actual, result))\n    \n#     return result","77a52cba":"pred_normal = model_predict(img_normal, \"normal\")\npred_pneumonia = model_predict(img_pneumonia, \"corona positive\")","16e06e90":"img = image.load_img('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/Normal\/Normal-100.png', target_size = (224, 224))\n\npred = model_predict(img, \"\")","7147adeb":"# Load the Data \/ Images","fdd89df0":"# Import Required Library","0c37d983":"## For Training dataset","3ed94481":"**copy data from dataset in to train folder**","cff1250b":"# Evaluate the Model","d0e928f7":"# Predict","f8d64d2b":"# Define Constants","44686b98":"**copy data from dataset in to validation folder**","e57e1916":"## For Test Dataset","8d31d79d":"# Get the Path for Images"}}