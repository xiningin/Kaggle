{"cell_type":{"4efd4893":"code","d54e5a6b":"code","da8eb77d":"code","70b65e1d":"code","9f4d5641":"code","403546db":"code","1f8e6835":"code","3766586f":"code","87868d76":"code","17a61a0b":"markdown","3e61cba5":"markdown","6308c455":"markdown","b8a8ceca":"markdown","2aa85e5c":"markdown","41abc126":"markdown","6daec8f0":"markdown","80b0f176":"markdown","61a3e727":"markdown","112bca09":"markdown","2a539fcc":"markdown","cda0eebf":"markdown"},"source":{"4efd4893":"from mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\n%matplotlib inline","d54e5a6b":"import torch\nimport torchvision\nimport torch.nn as nn","da8eb77d":"from PIL import Image\ndef pil_loader(path):\n    # open path as file to avoid ResourceWarning (https:\/\/github.com\/python-pillow\/Pillow\/issues\/835)\n    with open(path, 'rb') as f:\n        img = Image.open(f)\n        return img.convert('RGB')\n\ndef find_classes(dir):\n    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\n\ndef default_loader(path):\n    from torchvision import get_image_backend\n    if get_image_backend() == 'accimage':\n        return accimage_loader(path)\n    else:\n        return pil_loader(path)\n\nfrom torchvision import datasets\nclass Scenes(datasets.ImageFolder):\n    def __init__(self, root, transform=None, target_transform=None,\n                 train=True):\n        imagelist_file = 'Images.txt'\n        if train:\n            imagelist_file = 'Train'+imagelist_file\n        else :\n            imagelist_file = 'Test' + imagelist_file\n        filesnames = open(os.path.join(root, imagelist_file)).read().splitlines()\n        self.root = os.path.join(root, 'indoorCVPR_09\/Images')\n        classes, class_to_idx = find_classes(self.root)\n\n        images = []\n\n        for filename in list(set(filesnames)):\n            target = filename.split('\/')[0]\n            path = os.path.join(root, 'indoorCVPR_09\/Images\/' + filename)\n            item = (path, class_to_idx[target])\n            images.append(item)\n\n        self.classes = classes\n        self.class_to_idx = class_to_idx\n        self.samples = images\n\n        self.imgs = self.samples\n        self.loader = default_loader\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.samples)","70b65e1d":"datasets = {x : Scenes(root='..\/input\/', train=True if x == 'train' else False)\n            for x in ['train', 'val']}\nprint(\"number of Datasets {}.\".format(len(datasets)))\nprint('Number of Classes {}.'.format(len(datasets['train'].classes)))\nfor dstype in datasets:\n    print('{} set contains {} images'.format(dstype, len(datasets[dstype])))","9f4d5641":"# Data transforms\nfrom torchvision import transforms\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","403546db":"datasets = {x : Scenes(root='..\/input\/', train=True if x == 'train' else False, \n                       transform=data_transforms[x])\n            for x in ['train', 'val']}\nclass_names = datasets['train'].classes\ndataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}","1f8e6835":"from torch.utils import data\ndataloaders = {x: data.DataLoader(datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=1)\n              for x in ['train', 'val']}","3766586f":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.01)  # pause a bit so that plots are updated","87868d76":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nimport torchvision\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","17a61a0b":"There is 2 txt file in the current version of the dataset:\n* TrainImages.txt: contains the file names of each training image. Total 67x80 images\n* TestImages.txt: contains the file names of each test image. Total 67x20 images\n","3e61cba5":"## Pytorch Dataset `Object`\n\n\nFirst we need to design Pytorch dataset object to hold data. This dataset object can intrect with pytorch _dataLoader_. We can see the effects in just a momemt","6308c455":"## Introduction\nThis starter kernal include how to read this dataset in pytorch and a simple EDA on Data. The primary dataset in the tutorial is MIT Scenes which can be downloaded from http:\/\/web.mit.edu\/torralba\/www\/indoor.html or using the dataset attached to the kernal.\n\nThe database contains 67 Indoor categories, and a total of 15620 images. The number of images varies across categories, but there are at least 100 images per category. All images are in jpg format. The images provided here are for research purposes only.","b8a8ceca":"## Reading Data in Pytorch\n\n\nwe are making a `dict` of datasets, test and validation set.","2aa85e5c":"visulizing a batch","41abc126":"## Data Transforms\n\nData Transforms are used to preprocess the data set before using as input for ML\/DL models.\nIn pytorch we can define our preprocessings in `torchvision.transforms.Compose` which can take a list of transforms. Although we can define own transforms but there are some predefined and cools transforms already avaliable in the pytorch library.\n\n*Note:* _these transforms are applied in the order of defination_","6daec8f0":"Loading Pytorch Libraries","80b0f176":"`torch.utils.data.DataLoader` helps Datasets to itrate, also we can create batches in our dataset and define number of workers to load datasets","61a3e727":"## Visulizating Data in Batch\n\nScience we have transformed our data to Tensors so it can't be displayed using `matplotlib` so we need to convert it back to numpy `ndarrays`","112bca09":"## Conclusion\nThis concludes your Reading in pytorch i hope this gives you a good idea how to load Data use data in pytorch. I'll soon be uploading a new tutorial traning a simple Nueral Network in pytorch.\n\nHave a nice Day Happy kaggling! ","2a539fcc":"## Loading common Packages\nLoading some common libraries and packages","cda0eebf":"Reloading Dataset with transforms applied on it"}}