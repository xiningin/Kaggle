{"cell_type":{"40c0b09a":"code","5cdfdbf9":"code","acb676f3":"code","6866ea0d":"code","6407e74c":"code","531ffc36":"code","4eb7c563":"code","331a01f4":"code","f5030544":"code","69225a1e":"code","a1785803":"code","834a6e0e":"code","49f7f128":"code","138b71e2":"code","594c81f1":"code","aeed12b0":"code","9e11945f":"code","4377c390":"code","b50bce3d":"code","b8832d1f":"code","a4acf8ff":"code","30c8635b":"code","e2596fe7":"code","933e2908":"code","15d087c2":"code","d7e33062":"code","53712a01":"code","5665391e":"markdown","11b10ff5":"markdown","9b6c7ba0":"markdown","c88680f5":"markdown","effb0eb9":"markdown","72d48bb4":"markdown","cfa59349":"markdown","26a32f1a":"markdown","36672d52":"markdown","0fc90910":"markdown"},"source":{"40c0b09a":"# Default imports present when loading a kaggle kernel\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))","5cdfdbf9":"#import the relevant libs\nimport cv2\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\nfrom PIL import Image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import np_utils\n\n# Deep Learning - Keras - Model\nimport keras\nfrom keras import models\nfrom keras.models import Model\nfrom keras.models import Sequential\n\n# Deep Learning - Keras - Layers\nfrom keras.layers import  Flatten\nfrom keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization\nfrom keras.layers.pooling import _GlobalPooling1D\nfrom keras.applications.nasnet import preprocess_input\n\n# Deep Learning - Keras - Model Parameters and Evaluation Metrics\nfrom keras import optimizers\nfrom keras.optimizers import Adam ","acb676f3":"parasitized_data = os.listdir('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/')\nprint(parasitized_data[:10]) #the output we get are the .png files\n\nuninfected_data = os.listdir('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/')\nprint('\\n')\nprint(uninfected_data[:10])","6866ea0d":"plt.figure(figsize = (12,12))\nfor i in range(6):\n    plt.subplot(1, 6, i+1)\n    img = cv2.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized' + \"\/\" + parasitized_data[i])\n    plt.imshow(img)\n    plt.title('PARASITIZED : 1')\n    plt.tight_layout()\nplt.show()","6407e74c":"plt.figure(figsize = (12,12))\nfor i in range(6):\n    plt.subplot(1, 6, i+1)\n    img = cv2.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected' + \"\/\" + uninfected_data[i+1])\n    plt.imshow(img)\n    plt.title('UNINFECTED : 0')\n    plt.tight_layout()\nplt.show()","531ffc36":"data = []\nlabels = []\nfor img in parasitized_data:\n    try:\n        img_read = plt.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/' + \"\/\" + img)\n        img_resize = cv2.resize(img_read, (64,64))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(1)\n    except:\n        None\n        \nfor img in uninfected_data:\n    try:\n        img_read = plt.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected' + \"\/\" + img)\n        img_resize = cv2.resize(img_read, (64, 64))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(0)\n    except:\n        None","4eb7c563":"plt.imshow(data[0])\nplt.show()","331a01f4":"image_data = np.array(data)\nlabels = np.array(labels)","f5030544":"idx = np.arange(image_data.shape[0])\nnp.random.shuffle(idx)\nimage_data = image_data[idx]\nlabels = labels[idx]","69225a1e":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.2, random_state = 101)","a1785803":"y_train = np_utils.to_categorical(y_train, num_classes = 2)\ny_test = np_utils.to_categorical(y_test, num_classes = 2)","834a6e0e":"print(f'SHAPE OF TRAINING IMAGE DATA : {x_train.shape}')\nprint(f'SHAPE OF TESTING IMAGE DATA : {x_test.shape}')\nprint(f'SHAPE OF TRAINING LABELS : {y_train.shape}')\nprint(f'SHAPE OF TESTING LABELS : {y_test.shape}')","49f7f128":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.layers import Input","138b71e2":"def buildModel(input_shape=(64, 64, 3), num_class=2):\n    inputs = Input(input_shape)\n    base_model = VGG16(include_top=False, input_shape=input_shape)\n    #base_model = VGG19(include_top=False, input_shape=input_shape)\n    x = base_model(inputs)\n\n    output1 = GlobalMaxPooling2D()(x)\n    output2 = GlobalAveragePooling2D()(x)\n    output3 = Flatten()(x)\n\n    outputs = Concatenate(axis=-1)([output1, output2, output3])\n\n    outputs = Dropout(0.5)(outputs)\n    outputs = BatchNormalization()(outputs)\n\n    if num_class>1:\n        outputs = Dense(num_class, activation=\"softmax\")(outputs)\n    else:\n        outputs = Dense(1, activation=\"sigmoid\")(outputs)\n\n    model = Model(inputs, outputs)\n\n    return model","594c81f1":"input_shape = (64, 64, 3)\nnum_class = 2\nmodel = buildModel(input_shape=input_shape, num_class=num_class)\nmodel.summary()","aeed12b0":"input_shape = (64, 64, 3) # for VGG19\nnum_class = 2\nmodel_19 = buildModel(input_shape=input_shape, num_class=num_class)\nmodel_19.summary()","9e11945f":"model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])","4377c390":"model_19.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])","b50bce3d":"model_history_vgg16 = model.fit(x_train, y_train, epochs = 12, batch_size = 32)","b8832d1f":"h_19 = model_19.fit(x_train, y_train, epochs = 12, batch_size = 32)","a4acf8ff":"plt.figure(figsize = (18,8))\nplt.plot(range(12), model_history_vgg16.history['accuracy'], label = 'Training Accuracy')\nplt.plot(range(12), model_history_vgg16.history['loss'], label = 'Taining Loss')\nplt.xlabel(\"Number of Epoch's\")\nplt.ylabel('Accuracy\/Loss Value')\nplt.title('Training Accuracy and Training Loss')\nplt.legend(loc = \"best\")","30c8635b":"plt.figure(figsize = (18,8))# VGG19\nplt.plot(range(12), h_19.history['accuracy'], label = 'Training Accuracy')\nplt.plot(range(12), h_19.history['loss'], label = 'Taining Loss')\nplt.xlabel(\"Number of Epoch's\")\nplt.ylabel('Accuracy\/Loss Value')\nplt.title('Training Accuracy and Training Loss')\nplt.legend(loc = \"best\")","e2596fe7":"predictions = model.evaluate(x_test, y_test)","933e2908":"print(f'LOSS : {predictions[0]}')\nprint(f'ACCURACY : {predictions[1]}')","15d087c2":"predictions_19 = model_19.evaluate(x_test, y_test)","d7e33062":"print(f'LOSS : {predictions_19[0]}')#vgg19\nprint(f'ACCURACY : {predictions_19[1]}')","53712a01":"!nvidia-smi","5665391e":"**Preprocessing the dataset**","11b10ff5":"**Test the model on test split set**","9b6c7ba0":"**Understanding the dataset**","c88680f5":"**Get the training started**","effb0eb9":"**Visualize the training learning curve **","72d48bb4":"**Get the CNN model ready for Transfer Learning**","cfa59349":"**Visualize the dataset**","26a32f1a":"**Split the dataset in Training and Test set with both classes equally spread in each set**","36672d52":"**Import the Pre trained Models**","0fc90910":"**Importing Libraries**"}}