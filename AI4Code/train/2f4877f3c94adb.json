{"cell_type":{"000a9316":"code","82f87c00":"code","1a08528f":"code","ff351566":"code","25689426":"code","754485d3":"code","73783ae0":"code","f6d2a5e8":"code","5859a632":"code","ac844aae":"code","4cd8b3a6":"code","8910f946":"code","9744b198":"code","d2bab9f4":"code","699e1f5e":"code","72b10603":"code","477646b2":"code","b94f0754":"code","d9ae74d2":"code","0e27e870":"code","bb39f562":"code","e560e9c2":"code","ee4c8301":"code","a1417ecf":"markdown","54052361":"markdown","bd4051c5":"markdown","f998f717":"markdown","8888fc26":"markdown","17bbe991":"markdown","e2350273":"markdown","4573a249":"markdown"},"source":{"000a9316":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint  #, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os, cv2, json\nfrom PIL import Image","82f87c00":"WORK_DIR = '..\/input\/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)","1a08528f":"print('Train images: %d' %len(os.listdir(\n    os.path.join(WORK_DIR, \"train_images\"))))","ff351566":"with open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))","25689426":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels.head()","754485d3":"sns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(figsize = (6, 4))\n\nfor i in ['top', 'right', 'left']:\n    ax.spines[i].set_visible(False)\nax.spines['bottom'].set_color('black')\n\nsns.countplot(train_labels.label, edgecolor = 'black',\n              palette = reversed(sns.color_palette(\"viridis\", 5)))\nplt.xlabel('Classes', fontfamily = 'serif', size = 15)\nplt.ylabel('Count', fontfamily = 'serif', size = 15)\nplt.xticks(fontfamily = 'serif', size = 12)\nplt.yticks(fontfamily = 'serif', size = 12)\nax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\nplt.show()","73783ae0":"sample = train_labels[train_labels.label == 0].sample(3)\nplt.figure(figsize=(15, 5))\nfor ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n    plt.subplot(1, 3, ind + 1)\n    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","f6d2a5e8":"sample = train_labels[train_labels.label == 1].sample(3)\nplt.figure(figsize=(15, 5))\nfor ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n    plt.subplot(1, 3, ind + 1)\n    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","5859a632":"sample = train_labels[train_labels.label == 2].sample(3)\nplt.figure(figsize=(15, 5))\nfor ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n    plt.subplot(1, 3, ind + 1)\n    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","ac844aae":"sample = train_labels[train_labels.label == 3].sample(3)\nplt.figure(figsize=(15, 5))\nfor ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n    plt.subplot(1, 3, ind + 1)\n    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","4cd8b3a6":"sample = train_labels[train_labels.label == 4].sample(3)\nplt.figure(figsize=(15, 5))\nfor ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n    plt.subplot(1, 3, ind + 1)\n    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","8910f946":"# Main parameters\nBATCH_SIZE = 8\n# STEPS_PER_EPOCH = len(train_labels)*0.8 \/ BATCH_SIZE\n# VALIDATION_STEPS = len(train_labels)*0.2 \/ BATCH_SIZE\nEPOCHS = 20\nTARGET_SIZE = 512","9744b198":"train_labels.label = train_labels.label.astype('str')\n\ntrain_datagen = ImageDataGenerator(validation_split = 0.2,\n                                     preprocessing_function = None,\n                                     rotation_range = 45,\n                                     zoom_range = 0.2,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.1,\n                                     height_shift_range = 0.1,\n                                     width_shift_range = 0.1)\n\ntrain_generator = train_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n\n\nvalidation_datagen = ImageDataGenerator(validation_split = 0.2)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"validation\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")","d2bab9f4":"img_path = os.path.join(WORK_DIR, \"train_images\", train_labels.image_id[20])\nimg = image.load_img(img_path, target_size = (TARGET_SIZE, TARGET_SIZE))\nimg_tensor = image.img_to_array(img)\nimg_tensor = np.expand_dims(img_tensor, axis = 0)\nimg_tensor \/= 255.\n\nplt.imshow(img_tensor[0])\nplt.axis('off')\nplt.show()","699e1f5e":"generator = train_datagen.flow_from_dataframe(train_labels.iloc[20:21],\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n\naug_images = [generator[0][0][0]\/255 for i in range(10)]\nfig, axes = plt.subplots(2, 5, figsize = (20, 10))\naxes = axes.flatten()\nfor img, ax in zip(aug_images, axes):\n    ax.imshow(img)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","72b10603":"\n#Building cnn model\ncnn_model = keras.models.Sequential([\n                                    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[512, 512, 3]),\n                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n                                    keras.layers.Conv2D(filters=64, kernel_size=3),\n                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n                                    keras.layers.Conv2D(filters=128, kernel_size=3),\n                                    keras.layers.MaxPooling2D(pool_size=(2,2)),                                    \n                                    keras.layers.Conv2D(filters=256, kernel_size=3),\n                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n\n                                    keras.layers.Dropout(0.5),                                                                        \n                                    keras.layers.Flatten(), # neural network beulding\n                                    keras.layers.Dense(units=128, activation='relu'), # input layers\n                                    keras.layers.Dropout(0.1),                                    \n                                    keras.layers.Dense(units=256, activation='relu'),                                    \n                                    keras.layers.Dropout(0.25),                                    \n                                    keras.layers.Dense(units=5, activation='softmax') # output layer\n])\n\n\n# compile cnn model\ncnn_model.compile(optimizer = Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","477646b2":"# save best model using vall accuracy\nmodel_path = '.\/CNN_Model.h5'\ncheckpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]","b94f0754":"cnn_model.summary()","d9ae74d2":"# train cnn model\n\n# EPOCHS = 20\nhistory = cnn_model.fit(train_generator, \n                          epochs= EPOCHS, \n                          verbose=1, \n                          validation_data= validation_generator,\n                          callbacks=callbacks_list)","0e27e870":"model_path2 = \".\/CNN_Model.h5\"\ncnn_model.save(model_path2)","bb39f562":"ss = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\nss","e560e9c2":"preds = []\n\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(cnn_model.predict(image)))\n\nss['label'] = preds\nss","ee4c8301":"ss.to_csv('submission.csv', index = False)","a1417ecf":"# Data Agumentation","54052361":"# Sequential CNN Model","bd4051c5":"# Cassava Brown Streak Disease (CBSD)","f998f717":"# Cassava Bacterial Blight (CBB)","8888fc26":"# Cassava Mosaic Disease (CMD)","17bbe991":"# Cassava Green Mottle (CGM)","e2350273":"# Healthy","4573a249":"# Sequential Model"}}