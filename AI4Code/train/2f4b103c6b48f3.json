{"cell_type":{"00348ccc":"code","ee07dba2":"code","01bda54b":"code","fb82310f":"code","3cc3a000":"code","cdb73fa5":"code","e4dc2c02":"code","5ea089a5":"code","79b054a2":"code","4fe62b05":"code","40dc9535":"code","9aa198a0":"code","f5604198":"code","68f9e6ac":"code","801a7134":"code","bb49b2e4":"code","9ac3c6f7":"code","8f4bb7a0":"code","375ede9e":"code","7ba1a3bc":"code","496412b2":"code","adf8257f":"code","213a095f":"code","e57730d3":"code","e01b6512":"code","8b057d98":"code","6963ebb5":"code","0d0d12f7":"code","b0964e8a":"code","791ee9bf":"code","657d23a6":"code","c05cc64c":"code","2f433fdb":"code","f97c637b":"code","45bba13d":"code","af9980d6":"code","2c0fe4a5":"code","edef695d":"code","39fa4b0f":"code","b34f5341":"code","5e732a49":"code","96d256d0":"code","80c02610":"code","0ee134b0":"code","3fa72449":"code","4709784a":"code","1f654f5b":"code","a5e7fd29":"code","8c9a6632":"code","ddc2c4dd":"code","b53c11fb":"code","b488ed32":"code","f7147eb0":"code","cad01d23":"code","676125e7":"code","81a3e870":"code","c56f5adc":"code","c3e6c1c3":"code","23c6500f":"code","83525cff":"code","e57163c3":"code","0dc56a89":"code","b96a19ed":"code","3f6a50dc":"code","92779084":"code","98a65a81":"code","9f111129":"code","4fed1208":"code","c940092d":"code","43b74d36":"code","c366e82e":"code","6ae88c85":"code","9fddc410":"code","5b9623f7":"code","d3c1debb":"code","ab295a1e":"code","ab1d5109":"code","79886fca":"code","924761f2":"code","78127c05":"code","0aa38204":"code","679e288d":"code","cea66516":"code","37050c09":"code","11fa7c0b":"code","37769b19":"code","7952f5b6":"code","d3703219":"code","d5433df6":"code","08f554d3":"code","9120829f":"code","911f1028":"code","77fc8d8e":"code","2ceaa226":"code","2d9d7803":"code","5c2b244d":"code","4be2a1b4":"code","e34d768c":"code","95cbc8af":"code","3ad2b4a0":"code","e37b1b26":"code","12d2497d":"code","93c7bcf3":"code","535bded7":"code","dd8905df":"code","4b6ab6c9":"code","49a0debb":"code","62972272":"code","9c06e212":"code","5244bdb1":"code","8cdf425a":"code","a9def1e9":"code","ce7d3178":"code","2dc246eb":"code","159ffef1":"code","0cd6e5be":"code","8fb92f8c":"code","e2377fcf":"code","fc3b205d":"code","6019aa89":"code","488c6212":"code","26919293":"code","61e79337":"code","5da21647":"code","2793be6e":"code","d81d7ef4":"code","5f8c109b":"code","01129e9e":"code","1de52e36":"code","9103dd1b":"code","b50bf6d5":"code","f7cf0a92":"code","fa777240":"code","cfc55eab":"code","d0825836":"code","85dd8734":"code","9b9ec380":"code","90939d66":"code","4a9be657":"code","0d249300":"code","86aa0b39":"code","f81f768b":"code","36bad176":"code","011f4737":"code","a4d6abbf":"code","b3a050b8":"code","44776646":"code","3fa40227":"code","66a5db8b":"code","103be0f6":"code","c5d1fdd0":"code","3c524cac":"code","a38547b3":"code","66b80524":"code","0ee9cd1c":"code","b9965c75":"code","f9293099":"code","56397e34":"code","0bbed9e5":"code","a0d73d1e":"code","faf65eb7":"code","5b13fe26":"code","4969b193":"code","42ac1d15":"code","e1e6089b":"code","d8b73622":"code","6fc60152":"code","587328fe":"code","32c90450":"code","ba96a03f":"code","7e2fba72":"code","7076e5e5":"code","033980a0":"code","858d3325":"code","c4e398f9":"code","74f72d7f":"code","be8137b5":"code","4c7a2e27":"code","516faf23":"code","3a1e76b2":"code","20b2d10b":"code","9edff44f":"code","5dc7b79a":"code","c795f527":"code","19819627":"code","746da5f6":"code","f7579ea8":"code","4ac8bcae":"code","6455f4ca":"code","3c41d806":"code","666b7edf":"code","84e1fc00":"code","6851e422":"code","2a23a86f":"code","50746ef2":"markdown","674a0bfd":"markdown","017d7726":"markdown","161604b5":"markdown","e9c5afa0":"markdown","480307e8":"markdown","800664ac":"markdown","acb48b4e":"markdown","7b181b8a":"markdown","00c0938a":"markdown","18ce0eab":"markdown","2b558b0e":"markdown","2388a498":"markdown","9a5393d8":"markdown","25efb348":"markdown","9c6224fc":"markdown","a34d01e8":"markdown","0f0d184a":"markdown","0605e458":"markdown","f448c110":"markdown","f35a1930":"markdown","b1ac700e":"markdown","d2212d7e":"markdown","3b6dcb93":"markdown","abd83f6a":"markdown","32ad42d2":"markdown","2137144a":"markdown","1173e690":"markdown","bfc3b265":"markdown","fa9e556a":"markdown","9bf7209b":"markdown","356ea0bd":"markdown","70061721":"markdown","5461824b":"markdown","b11eb136":"markdown","70b5d834":"markdown","03b4ec7f":"markdown","c0436b29":"markdown","613b5272":"markdown","67b67d1b":"markdown","39988761":"markdown","55ce29a4":"markdown","cc25b99d":"markdown","319415e1":"markdown","5c76b0cb":"markdown","0f2edaff":"markdown","d21f5706":"markdown","946202f3":"markdown","2969e00c":"markdown","209f61e9":"markdown","48641898":"markdown","27f67dd2":"markdown","36b3d0cd":"markdown","5087e298":"markdown","32ee4c0f":"markdown","9150d49c":"markdown","76916a3f":"markdown"},"source":{"00348ccc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ee07dba2":"#we import all package that we need\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport statsmodels as sm\nimport folium as fl\nfrom pathlib import Path\nfrom sklearn.impute import SimpleImputer\nsns.set()\n%matplotlib inline\npd.options.plotting.backend\npd.plotting.register_matplotlib_converters()","01bda54b":"dataFile = '\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv'\ncovid = pd.read_csv(dataFile)","fb82310f":"#see data \ncovid.head()","3cc3a000":"# data information\ncovid.info()","cdb73fa5":"# check if there exist a missing value\nmis = covid.isnull().sum()\nmis[mis>0]","e4dc2c02":"imputer = SimpleImputer(strategy='constant')#here I use constant because I cannot put another Province\/State\n#that we do not know or that does not correspond to his country\/region  \nimpute_covid = pd.DataFrame(imputer.fit_transform(covid), columns=covid.columns)\nimpute_covid.head()","5ea089a5":"#convert ObservationDate and Last Update object to datetime\n#convert confirmed, recovered, death to numeric\nimpute_covid['ObservationDate'] = pd.to_datetime(impute_covid['ObservationDate'])\nimpute_covid['Last Update'] = pd.to_datetime(impute_covid['Last Update'])\nimpute_covid['Confirmed'] = pd.to_numeric(impute_covid['Confirmed'], errors='coerce')\nimpute_covid['Recovered'] = pd.to_numeric(impute_covid['Recovered'], errors='coerce')\nimpute_covid['Deaths'] = pd.to_numeric(impute_covid['Deaths'], errors='coerce')","79b054a2":"#check\n#impute_covid.to_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data_clean.csv', index=False)\nimpute_covid.info()","4fe62b05":"filename = '\/kaggle\/input\/novel-corona-virus-2019-dataset\/COVID19_open_line_list.csv'\nopen_covid = pd.read_csv(filename)","40dc9535":"open_covid.head(3)","9aa198a0":"open_covid.info()","f5604198":"# check missing value \nmis_value = open_covid.isnull().sum()\nmis_value[mis_value>0]","68f9e6ac":"thresh_value = open_covid['date_confirmation'].isnull().sum() # the threshold missing value I take here is \n#that of date_confirmation columns  because I do not drop many value for another columns\n#we take only columns which a number missing value less than thresh_value\ncols_interest_missing = [col for col in open_covid.columns if open_covid[col].isnull().sum()<=thresh_value]\ncols_interest_missing","801a7134":"missing_covid = open_covid[cols_interest_missing].copy()","bb49b2e4":"#we can drop a nan value\ndrop_covid = missing_covid.dropna(axis=0)\ndrop_covid.isnull().any()","9ac3c6f7":"#see data dropped\ndrop_covid.head()","8f4bb7a0":"# some anomalies detected in the data \ndrop_covid['date_confirmation'][drop_covid['date_confirmation']=='25.02.2020-26.02.2020']","375ede9e":"drop_covid['date_confirmation'][drop_covid['date_confirmation']!='25.02.2020-26.02.2020']","7ba1a3bc":"#verification \ndrop_covid['date_confirmation'].iloc[11630:11750].values","496412b2":"# we fix this problem by remplacing '25.02.2020-26.02.2020' to '25.02.2020'\ndrop_covid = drop_covid.replace(to_replace='25.02.2020-26.02.2020', value='25.02.2020')","adf8257f":"#convert date_confirmation to datetime dtype\ndrop_covid.loc[:,'date_confirmation'] = pd.to_datetime(drop_covid['date_confirmation'], format=\"%d.%m.%Y\")","213a095f":"#see table if all is ok\ndrop_covid.isnull().any()","e57730d3":"#drop_covid.to_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/COVID19_open_clean.csv', index=False)\ndrop_covid.head()","e01b6512":"# see again data table\nimpute_covid.head(3)","8b057d98":"# we compute the active_confirmed\nimpute_covid['active_confirmed'] = impute_covid['Confirmed'].values - \\\n(impute_covid['Deaths'].values+impute_covid['Recovered'].values)","6963ebb5":"#check if all is ok\nimpute_covid.isnull().sum()[impute_covid.isnull().sum()>0]","0d0d12f7":"#ok we have no problem see table data\nimpute_covid.info()","b0964e8a":"impute_covid.corr()","791ee9bf":"features = [['Confirmed', 'Deaths'], ['Confirmed', 'Recovered'], ['Recovered', 'Deaths'], \\\n            ['Confirmed', 'active_confirmed']]\nvalues = [[impute_covid['Confirmed'], impute_covid['Deaths']],\\\n          [impute_covid['Confirmed'], impute_covid['Recovered']],\\\n          [impute_covid['Recovered'], impute_covid['Deaths']],\\\n          [impute_covid['Confirmed'], impute_covid['active_confirmed']]]","657d23a6":"fig = plt.figure(figsize=(20.5,10.5))\nfig.subplots_adjust(hspace=0.2, wspace=0.1)\nfor i in range(1,5):\n    ax = fig.add_subplot(2, 2, i)\n    col = features[i-1]\n    val = values[i-1]\n    ax.scatter(val[0], val[1])\n    ax.set_xlabel(col[0])\n    ax.set_ylabel(col[1])\n    ax.set_title('Feature curves')\nplt.show()","c05cc64c":"start_date = impute_covid.ObservationDate.min()\nend_date = impute_covid.ObservationDate.max()\nprint('Novel Covid-19 information:\\n 1. Start date = {}\\n 2. End date = {}'.format(start_date, end_date))","2f433fdb":"worldwide = impute_covid[impute_covid['ObservationDate'] == end_date]","f97c637b":"nb_country = len(worldwide['Country\/Region'].value_counts()) # number country\nworldwide['Country\/Region'].value_counts()","45bba13d":"world = worldwide.groupby('Country\/Region').sum()\nworld = world.sort_values(by=['Confirmed'], ascending=False)\nworld.head()","af9980d6":"print('================ Worldwide report ===============================')\nprint('== Information to {} on novel COVID-19 =========\\n'.format(end_date))\nprint('Tota confirmed: {}\\nTotal Deaths: {}\\nTotal Recovered: {}\\nTotal active confirmed: {}\\n\\\nTotal country Recorded: {} \\n'.format(\\\nworldwide.Confirmed.sum(), worldwide.Deaths.sum(), worldwide.Recovered.sum(), worldwide.active_confirmed.sum(),\\\n                                     nb_country))\nprint('==================================================================')","2c0fe4a5":"world.Confirmed.plot(kind='bar', title= 'novel Covid-19 in the Worldwide', figsize=(20,8), logy=True,legend=True)\nplt.ylabel('Total Cases')","edef695d":"world.Recovered.plot(kind='bar', title= 'novel Covid-19 in the Worldwide', figsize=(20,8), logy=True,\\\n                     colormap='Greens_r', legend=True)\nplt.ylabel('Total Recovered')","39fa4b0f":"world.Deaths.plot(kind='bar', title= 'novel Covid-19 in the Worldwide', figsize=(20,8), logy=True,\\\n                     colormap='Reds_r', legend=True)\nplt.ylabel('Total Deaths')","b34f5341":"world.active_confirmed.plot(kind='bar', title= 'novel Covid-19 in the Worldwide', figsize=(20,8), logy=True,\\\n                            legend=True)\nplt.ylabel('Total  Active Cases')","5e732a49":"world_table = world.reset_index()","96d256d0":"x = world_table[world_table['Country\/Region'] == 'France']\nbig_7 = world_table[world_table['Confirmed'] >= x.iloc[0,1]]","80c02610":"big_7.style.background_gradient(cmap='viridis')","0ee134b0":"axs = big_7.plot('Country\/Region', ['Confirmed', 'Deaths', 'Recovered', 'active_confirmed'], kind='barh',\\\n                 stacked=True, title='Country most affected by novel covid-19',\\\n                 figsize=(20,10.5),colormap='rainbow_r', logx=True, legend=True) \npd.plotting.table(data=world_table, rowLabels=world.index, colLabels=world.columns, ax=axs)\nplt.xlabel(' ')","3fa72449":"time_obs = impute_covid.groupby('ObservationDate')['Confirmed'].aggregate([np.sum])\ntime_obs.columns = ['Confirmed']","4709784a":"time_obs.plot(figsize=(20,8), title='novel COVID-19 in the Worldwide', kind='bar')\nplt.ylabel('Total Confirmed observation')","1f654f5b":"death_rate = impute_covid.groupby('ObservationDate')['Deaths'].aggregate([np.sum])\nrecovered_rate = impute_covid.groupby('ObservationDate')['Recovered'].aggregate([np.sum])\nactivecase_rate = impute_covid.groupby('ObservationDate')['active_confirmed'].aggregate([np.sum])\ndeath_rate.columns = ['Death rate']\nrecovered_rate.columns = ['Recovered rate']\nactivecase_rate.columns = ['Active confirmed rate']","a5e7fd29":"recovered_rate.plot(figsize=(15.5, 5), title='novel COVID-19 in the Worldwide', colormap='Greens_r', kind='bar')\nplt.ylabel('Total patient')","8c9a6632":"death_rate.plot(figsize=(15.5, 5), title='novel COVID-19 in the Worldwide', colormap='Reds_r', kind='bar')\nplt.ylabel('Total patient')","ddc2c4dd":"activecase_rate.plot(figsize=(15.5, 5), title='novel COVID-19 in the Worldwide', colormap='Blues_r', kind='bar')\nplt.ylabel('Total patient')","b53c11fb":"china = impute_covid[impute_covid['Country\/Region'] == 'Mainland China']","b488ed32":"chstar_date = china.ObservationDate.min()\nchend_date = china.ObservationDate.max()","f7147eb0":"print('Novel covid-19 China:\\n start date = {}\\n end date = {}'.format(chstar_date, chend_date))","cad01d23":"lastChina = china[china['ObservationDate'] == chend_date]\nlastChina.head()","676125e7":"print('================ China report ===================================')\nprint('== Information to {} on novel COVID-19 =========\\n'.format(chend_date))\nprint('Tota confirmed: {}\\nTotal Deaths: {}\\nTotal Recovered: {}\\nTotal active confirmed: {}\\n'.format(\\\nlastChina.Confirmed.sum(), lastChina.Deaths.sum(), lastChina.Recovered.sum(), lastChina.active_confirmed.sum()))\nprint('==================================================================')","81a3e870":"lastChina[['Province\/State', 'Confirmed', 'Deaths', 'Recovered', 'active_confirmed']].style.\\\nbackground_gradient(cmap='viridis')","c56f5adc":"province = lastChina.groupby('Province\/State').sum()\nprovince = province.sort_values(by=['Confirmed'], ascending=False)","c3e6c1c3":"province.plot(kind='bar', label='Confirmed',logy=True,figsize=(20,10), stacked=True,\\\n              title='China Province  with novel covid-19')\nplt.ylabel('Total patient')","23c6500f":"conf_china = china.groupby('ObservationDate')['Confirmed'].agg('sum')\nrec_china = china.groupby('ObservationDate')['Recovered'].agg('sum')\ndea_china = china.groupby('ObservationDate')['Deaths'].agg('sum')\nac_china = china.groupby('ObservationDate')['active_confirmed'].agg('sum')","83525cff":"conf_china.plot(figsize=(20,8), kind='bar',title='observationdate of patient confirmed in China')\nplt.ylabel('Total patient')","e57163c3":"rec_china.plot(figsize=(20,8), kind='bar',title='observationdate of patient recovered in China',\\\n               colormap='Greens_r')\nplt.ylabel('Total patient')","0dc56a89":"dea_china.plot(figsize=(20,8), kind='bar',title='observationdate of patient death in China', colormap='Reds_r')\nplt.ylabel('Total patient')","b96a19ed":"ac_china.plot(figsize=(20,8), kind='bar',title='observationdate of patient active confirmed in China')\nplt.ylabel('Total patient')","3f6a50dc":"rest_world = impute_covid[impute_covid['Country\/Region'] != 'Mainland China']","92779084":"rest_world.head()","98a65a81":"print('Novel covid-19 ROW:\\n start date = {}\\n end date = {}'.format(rest_world.ObservationDate.min(),\\\n                    rest_world.ObservationDate.max()))","9f111129":"row = rest_world[rest_world['ObservationDate'] == rest_world.ObservationDate.max()]","4fed1208":"print('================ ROW report =====================================')\nprint('== Information to {} on novel COVID-19 =========\\n'.format(chend_date))\nprint('Tota confirmed: {}\\nTotal Deaths: {}\\nTotal Recovered: {}\\nTotal active confirmed: {}\\n'.format(\\\nrow.Confirmed.sum(), row.Deaths.sum(), row.Recovered.sum(), row.active_confirmed.sum()))\nprint('==================================================================')","c940092d":"rw = row[['Country\/Region', 'Confirmed', 'Deaths', 'Recovered', 'active_confirmed']].\\\ngroupby('Country\/Region').sum()\nrwx = rw.sort_values(by=['Confirmed'], ascending=False)\nrwx.style.background_gradient(cmap='viridis')","43b74d36":"rwx.plot(kind='bar', figsize=(20,10), stacked=True, title='novel covid-19 in the rest of world', logy=True)\nplt.ylabel('Total patient')","c366e82e":"obs_conf_world = rest_world.groupby('ObservationDate')['Confirmed'].aggregate([np.sum]) # confirmed obs\nac_conf_world = rest_world.groupby('ObservationDate')['active_confirmed'].aggregate([np.sum]) # last upd obs\npatient_world_r = rest_world.groupby('ObservationDate')['Recovered'].aggregate([np.sum]) # lifetime \npatient_world_dea = rest_world.groupby('ObservationDate')['Deaths'].aggregate([np.sum]) # lifetime ","6ae88c85":"obs_conf_world.columns = ['Confirmed']\nac_conf_world.columns = ['active_onfirmed']\npatient_world_r.columns = ['Recovered'] \npatient_world_dea.columns = ['Deaths'] ","9fddc410":"obs_conf_world.plot(figsize=(20,8), title='novel covid-19 in the rest of the world',kind='bar')\nplt.ylabel('total patient')","5b9623f7":"ac_conf_world.plot(figsize=(20,8), title=\"novel covid-19 in the rest of the world\", kind='bar')\nplt.ylabel('total patient')","d3c1debb":"patient_world_r.plot(figsize=(20,10.5), title='novel covid-19 in the rest of the world', kind='bar', \\\n                     colormap='Greens_r')\nplt.ylabel('total patient')","ab295a1e":"patient_world_dea.plot(figsize=(20,10.5), title='novel covid-19 in the rest of the world', kind='bar', \\\n                     colormap='Reds_r')\nplt.ylabel('total patient')","ab1d5109":"from sklearn.preprocessing import MinMaxScaler\nimport datetime\nfrom keras.layers.recurrent import GRU\nfrom keras.layers import Dense, Input, Dropout \nfrom keras.optimizers import adam, rmsprop\nfrom keras.models import Model \nfrom keras.models import load_model \nfrom keras.callbacks import ModelCheckpoint","79886fca":"confirmed_case = impute_covid[['ObservationDate', 'Confirmed']]\nconfirmed_case = confirmed_case.set_index('ObservationDate')","924761f2":"confirmed_case.head(3)","78127c05":"# violin boxplot\nsns.violinplot(confirmed_case.Confirmed)\nplt.title('confirmed case violin boxplot')","0aa38204":"scaler = MinMaxScaler(feature_range=(0,1))\nconfirmed_case['scaled_cases']= scaler.fit_transform(np.array(confirmed_case.Confirmed).reshape(-1,1))","679e288d":"confirmed_case.head()","cea66516":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","37050c09":"fig = plt.figure(figsize=(15, 5.5))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nax1  = fig.add_subplot(1,2,1)\nax2 = fig.add_subplot(1,2,2)\nplot_acf(confirmed_case.scaled_cases, ax=ax1, lags=10)\nplot_pacf(confirmed_case.scaled_cases, ax=ax2, lags=10)\nplt.show()","11fa7c0b":"#split a data in train set and test set\nsplit_date = end_date - datetime.timedelta(days=3) + datetime.timedelta(hours=23, minutes=59,seconds=59)\ntrain = confirmed_case[confirmed_case.index <= split_date]\ntest = confirmed_case[confirmed_case.index > split_date]","37769b19":"print('train shape: {}\\ntest shape : {}'.format(train.shape, test.shape))","7952f5b6":"def makeXy(ts, nb_timesteps): \n    ''' \n    Input:  \n           ts: original time series \n           nb_timesteps: number of time steps in the regressors \n    Output:  \n           X: 2-D array of regressors \n           y: 1-D array of target  \n    ''' \n    X = [] \n    y = [] \n    for i in range(nb_timesteps, ts.shape[0]): \n        \n        X.append(list(ts.iloc[i-nb_timesteps:i])) \n        y.append(ts.iloc[i]) \n    X, y = np.array(X), np.array(y) \n    return X, y ","d3703219":"lookback = 2 # 3days back \n\nX_train, y_train = makeXy(train['scaled_cases'], lookback) \nprint('Shape of train arrays:', X_train.shape, y_train.shape) \n\nX_test, y_test = makeXy(test['scaled_cases'], lookback) \nprint('Shape of test arrays:', X_test.shape, y_test.shape) ","d5433df6":"Xtrain = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n\nXtest = X_test.reshape((X_test.shape[0], X_test.shape[1], 1)) \n\nn=  Xtrain.shape[1]\nprint('Shape of 3D arrays:', Xtrain.shape, Xtest.shape)","08f554d3":"# fix random seed for reproducibility\nnp.random.seed(7)","9120829f":"#Define input layer which has shape (None, 2) and of type float32. None indicates the number of instances\ninput_layer = Input(shape=(n,1), dtype='float32')","911f1028":"gru_layer1 = GRU(64, input_shape=(n,1), return_sequences=True)(input_layer)\ngru_layer2 = GRU(32, input_shape=(n,64), return_sequences=False)(gru_layer1)","77fc8d8e":"dropout_layer = Dropout(0.2)(gru_layer2)","2ceaa226":"#Finally the output layer gives prediction for the next day's confirmed case.\noutput_layer = Dense(1, activation='linear')(dropout_layer)","2d9d7803":"model = Model(inputs=input_layer, outputs=output_layer)\nmodel.compile(loss='mean_squared_error', optimizer='rmsprop')\nmodel.summary()","5c2b244d":"history = model.fit(x=Xtrain, y=y_train, batch_size=32, epochs=20,verbose=1, validation_data=(Xtest, y_test))","4be2a1b4":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","e34d768c":"#we compute a prediction\npreds = model.predict(Xtest)\npred_covid19 = scaler.inverse_transform(preds)\npred_covid19 = np.squeeze(pred_covid19)","95cbc8af":"from sklearn.metrics import mean_squared_error","3ad2b4a0":"#compute score\nrmse = np.sqrt(mean_squared_error(test.Confirmed.iloc[n:] , pred_covid19))\nprint('RMSE for the test set:', round(rmse, 4))","e37b1b26":"actual_pred = pd.DataFrame()\nactual_pred['actual'] = test.Confirmed.iloc[n:]\nactual_pred['predict'] =  pred_covid19","12d2497d":"valid = actual_pred.reset_index()","93c7bcf3":"valid.head()\n","535bded7":"valid.groupby('ObservationDate').sum().plot(kind='bar')\nplt.ylabel(' Total confirmed')","dd8905df":"#we take time_Obs see code above\ntime_obs.head()","4b6ab6c9":"x = []\nx.append(0)\nfor i in range(time_obs.shape[0]-1):\n    a = time_obs.iloc[i+1,0]-time_obs.iloc[i,0]\n    x.append(a\/time_obs.iloc[i,0])","49a0debb":"grown_rate = time_obs.reset_index()\ngrown_rate['grownRate'] = x\ngrown_rate.head()","62972272":"grown_rate.grownRate.plot(figsize=(10,5))\nplt.title('Confirmed case Grownth rate ')\nplt.ylabel('$Grownth rate$')\nplt.xlabel('$tau$')","9c06e212":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor # for next model below\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split","5244bdb1":"trend_model = make_pipeline(PolynomialFeatures(8), LinearRegression(normalize=True, fit_intercept=True))\ntrend_model.fit(np.array(grown_rate.index).reshape((-1,1)), grown_rate['grownRate'])","8cdf425a":"print('Trend model coefficient={} and intercept={}'.format(trend_model[1].coef_[0],trend_model[1].intercept_))","a9def1e9":"dt =np.array(grown_rate.index).reshape((-1,1)) \nfit_grown = trend_model.predict(dt)","ce7d3178":"errors = grown_rate['grownRate'] - fit_grown","2dc246eb":"upperlimits = [True, False] \nlowerlimits = [False, True] \nplt.figure(figsize=(10,5))\nplt.scatter(dt, grown_rate['grownRate'])\nplt.errorbar(dt, fit_grown,yerr = errors,  color='r', label='prediction and errors')\nplt.legend(loc='best')\nplt.show()","159ffef1":"#we compute score\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(fit_grown, grown_rate['grownRate'])))","0cd6e5be":"#score\ntrend_model.score(dt, grown_rate['grownRate'])","8fb92f8c":"from datetime import timedelta\nnext_date = str(end_date+timedelta(days=1))\nnew_date = pd.date_range(start=next_date, periods=3)\nndt = np.arange(len(new_date)) +len(time_obs)\nprint('new date {} correspond to new dt {}'.format(new_date, ndt))","e2377fcf":"# we compute a new grownth rate \nnew_rate = trend_model.predict(ndt.reshape((-1,1)))\nprint('Rate forecast: {}:'.format(new_rate))","fc3b205d":"pred_rate = pd.DataFrame()\nrate = grown_rate.set_index('ObservationDate')\npred_rate['prediction_grownthRate'] = new_rate \npred_rate.index=new_date","6019aa89":"#we concatenate the two data\ndata_plot = pd.concat([rate, pred_rate], sort=False)\ndata_plot.head(1)","488c6212":"data_plot[['grownRate', 'prediction_grownthRate']].plot(figsize=(10,5))\nplt.ylabel('growth rate')\nplt.title('growth rate forecast')","26919293":"residual = pd.Series(data=errors, index=grown_rate.index)","61e79337":"plt.figure(figsize=(8,8))\nresidual.plot()\nplt.xlabel('time index')\nplt.ylabel('Residual')\nplt.title('Residual between actual and prediction')","5da21647":"fig = plt.figure(figsize=(15, 5.5))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nax1  = fig.add_subplot(1,2,1)\nax2 = fig.add_subplot(1,2,2)\nplot_acf(residual, ax=ax1, lags=20)\nplot_pacf(residual, ax=ax2, lags=20)\nplt.show()","2793be6e":"from statsmodels.tsa import seasonal\nresidual_decompose = seasonal.seasonal_decompose(residual.tolist(), model='additive',period=7)","d81d7ef4":"_=residual_decompose.plot()","5f8c109b":"#we iinstall a packa\n!pip install pmdarima","01129e9e":"from statsmodels.graphics.gofplots import qqplot\nfrom pmdarima import *","1de52e36":"rate.shape","9103dd1b":"# check normality with qqplot\n_= qqplot(rate.grownRate, line='s')","b50bf6d5":"utils.plot_acf(rate.grownRate, alpha=0.05)","f7cf0a92":"utils.plot_pacf(rate.grownRate, alpha=0.05)","fa777240":"# we split our to tain and test set\nr_train, r_test = model_selection.train_test_split(rate.grownRate, train_size=56)","cfc55eab":"# we decompose a train set to see trend, seasonal and residual\n_=seasonal.seasonal_decompose(r_train.tolist(), model='additive',period=7).plot()","d0825836":"adf_test = arima.ADFTest()\npval, should_diff = adf_test.should_diff(r_train)\nprint('train set: p-value = {}, should_diff = {}'.format(pval, should_diff))","85dd8734":"# function for ndiff test\ndef ndiff_test(train):\n    kpss_diffs = arima.ndiffs(train, test='kpss', max_d=6)\n    adf_ndiffs = arima.ndiffs(train, test= 'adf', max_d=6 )\n    \n    return max(adf_ndiffs, kpss_diffs)","9b9ec380":"print('train set: Estimated differencing term: {}'.format(ndiff_test(r_train)) )","90939d66":"# estimate a seasonal differencing term D\nD = arima.nsdiffs(r_train, m=7)\nprint('train set: seasonal differencing term: {}'.format(D))","4a9be657":"from pmdarima.pipeline import Pipeline\nimport pmdarima as pm\narif = Pipeline([('boxcox', preprocessing.BoxCoxEndogTransformer(lmbda2=1e-6)), \\\n                 ('arima', pm.AutoARIMA(trace=True, suppress_warnings=True))])\narif.fit(r_train)","0d249300":"arif.summary()","86aa0b39":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\ndef forecast_one_step(modeled, n=1):\n    fc = modeled.predict(n_periods=n, return_conf_int=False)\n    #_, conf_init =  modeled.predict(n_periods=n, return_conf_int=True, inverse_transform=False)\n    return fc.tolist()[0]#, np.asanyarray(conf_init).tolist()[0])\n\ndef update_model(test, models):\n    forecasts = []\n    #confidence_intervals = []\n    for new_ob in test:\n        fc = forecast_one_step(models)\n        forecasts.append(fc)\n       # confidence_intervals.append(conf)\n    \n        # updates the existing model \n        models.update(np.array([new_ob]))\n        \n    return forecasts#, confidence_intervals","f81f768b":"fcast = update_model(r_test, arif)","36bad176":"print('MSE: {}'.format(np.sqrt(mean_squared_error(r_test,fcast))))","011f4737":"resid = r_test - fcast","a4d6abbf":"sns.distplot(resid)","b3a050b8":"plot_acf(resid, alpha=0.05)","44776646":"plt.figure(figsize=(10,5))\nresid.plot()","3fa40227":"# function for plotting\ndef viewing_forecast(train, test, forecast, train_label, test_label, fc_label, title):\n    \n    plt.figure(figsize=(12, 6))\n    fc_series =pd.Series(forecast, index=test.index)\n    ax = train.plot(label=train_label)\n    fc_series.plot(ax=ax, label=fc_label, alpha=0.7)\n    test.plot(ax=ax, label=test_label, alpha=0.7, color='green')\n    a = train.index.to_list()\n    b = train.index.max()\n    n = a.index(b)\n    ax.vlines(train.index[n], train.min(), train.max(), linestyles='dashdot', colors='r',\\\n              label='stop train set')\n    ax.set_xlabel('Date')\n    ax.set_ylabel(' Growth rate')\n    ax.set_title(title)\n    plt.legend()  ","66a5db8b":"viewing_forecast(r_train[22:], r_test, fcast, train_label='actual train', test_label='actual test', \\\n                 fc_label = 'prediction',\\\n                 title = 'Actual-Prediction plot')","103be0f6":"#if we need to know confirmed growth rate in the next day, we must take data for 5 days before for example.\nfcast # we see the date predicted","c5d1fdd0":"thr_date = end_date - timedelta(days=3)\nprevious_data = pd.Series(fcast[-5:-1], index=r_test.index[r_test.index >= thr_date])\nprevious_data","3c524cac":"fcast_data = update_model(r_test[3:] , arif)\nprint('forecast data: \\n {}\\n'.format(fcast_data)) \nfdate = pd.date_range(start=end_date+timedelta(days=1), periods=len(fcast_data))\nprint('Correspond to date:\\n {}'.format(fdate))","a38547b3":"# serie \nforecast_data = pd.Series(fcast_data, index=fdate)\n\n# concatenate previous and forecast data in evolution DataFrame\nevolution = pd.DataFrame()\nevolution = pd.concat([previous_data, forecast_data], sort=False)\n\n#check\nevolution.head(12)","66b80524":"#plotting\nax = evolution[:5].plot(figsize=(15,5), color='red', label='predicted', legend=True)\nr_test[4:] .plot(ax=ax, label='actual', legend=True)\nevolution[4:].plot(ax=ax, label='forecast',color='green', legend=True)\nax.vlines(r_test.index[-1], r_test.min(), r_test.max(), linestyles='dashdot', colors='black',\\\n              label='stop')\nax.set_ylabel(' Growth rate')\nplt.title('Growth rate covid-19 evolution')\nplt.legend(loc= 'best')  ","0ee9cd1c":"#importing package\nfrom fbprophet import Prophet","b9965c75":"rate.head()","f9293099":"# we respect the prophet structure data \npdata = rate.grownRate","56397e34":"# we check if all is ok.\npdat = pdata.reset_index()\npdat = pdat.rename(columns={'ObservationDate':'ds', 'grownRate':'y'})\npdat.head()","0bbed9e5":"m = Prophet(interval_width=0.95,changepoint_prior_scale=1.05)\nm.fit(pdat)","a0d73d1e":"# future days\nfutureDays = m.make_future_dataframe(periods=12)\nfutureDays.tail()","faf65eb7":"growth_rate_forecast = m.predict(futureDays)","5b13fe26":"growth_rate_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","4969b193":"#we plot graph\ngraph = m.plot(growth_rate_forecast)\nplt.title('growth rate worldwide forecasting')","42ac1d15":"graph1 = m.plot_components(growth_rate_forecast)","e1e6089b":"from fbprophet.diagnostics import cross_validation\nfrom fbprophet.diagnostics import performance_metrics","d8b73622":"#for cross validation we are taking the range of our data \ndf_cv = cross_validation(m, initial='30 days', period='2 days', horizon = '14 days')\ndf_cv.head(3)","6fc60152":"df_p = performance_metrics(df_cv)\ndf_p.head()","587328fe":"from fbprophet.plot import plot_cross_validation_metric\nufig = plot_cross_validation_metric(df_cv, metric='mape')","32c90450":"# we define a function that compute the growth rate\ndef grate(obs = None):\n    x = []\n    x.append(0)\n    for i in range(obs.shape[0]-1):\n        a = obs.iloc[i+1] - obs.iloc[i]\n        x.append(a\/obs.iloc[i])\n        \n    y = pd.DataFrame(x, columns=['growth_rate'],index=obs.index)\n    \n    return y.reset_index()","ba96a03f":"china_obs = china.groupby('ObservationDate')['Confirmed'].agg('sum')\nrow_obs = rest_world.groupby('ObservationDate')['Confirmed'].agg('sum')","7e2fba72":"import plotly.offline as py\nimport plotly.express as px\nimport cufflinks as cf\npy.init_notebook_mode(connected=False)\ncf.set_config_file(offline=True)","7076e5e5":"#plt.figure(figsize=(10,5))\n#china_obs.plot()\n#row_obs.plot()\n#plt.ylabel('Cummulative Confirmed Cases')\n#plt.title('China(Blue) vs ROW(Red) Covid 19 diseases')\nudf = pd.DataFrame({'chinaConfirmedCases':china_obs, 'rowConfirmedCases':row_obs})\nudf.iplot(title='Comparison between confirmed cases in China and ROW')","033980a0":"# we compute rate\n\nrate_china = grate(china_obs)\nrate_row = grate(row_obs)","858d3325":"cr = pd.DataFrame({'China_growth_rate':rate_china.growth_rate, 'Row_growth_rate':rate_row.growth_rate})\ncr.index = rate_china.ObservationDate\ncr.head()","c4e398f9":"cr.iplot(title='Comparison growth rate between China and ROW')","74f72d7f":"prate_china = rate_china.rename(columns={'ObservationDate':'ds', 'growth_rate':'y'})","be8137b5":"mc = Prophet(interval_width=0.95,changepoint_prior_scale=1.05)\nmc.fit(prate_china)","4c7a2e27":"cfutureDays = mc.make_future_dataframe(periods=10)\ncfutureDays.tail()","516faf23":"growth_china = mc.predict(cfutureDays)","3a1e76b2":"_=mc.plot(growth_china)","20b2d10b":"_= mc.plot_components(growth_china)","9edff44f":"prate_row = rate_row.rename(columns={'ObservationDate':'ds', 'growth_rate':'y'})","5dc7b79a":"mr = Prophet(interval_width=0.95, changepoint_prior_scale=4.05)\nmr.fit(prate_row)","c795f527":"rfutureDays = mr.make_future_dataframe(periods=10)","19819627":"growth_row = mr.predict(rfutureDays)","746da5f6":"_= mr.plot(growth_row)","f7579ea8":"_= mr.plot_components(growth_row)","4ac8bcae":"china_obs.head()","6455f4ca":"# we cumulate a number of confirmed cases weekly. so we can use resample method\nweekly_cases = china_obs.resample('W').aggregate([np.mean])","3c41d806":"weekly_cases = weekly_cases.reset_index()","666b7edf":"weekly_cases.iplot(x='ObservationDate', y='mean', title='Weekly Confirmed Cases Covid19 China',\n                  xTitle='Date', yTitle='Average confirmed cases')","84e1fc00":"decompose_weekly = seasonal.seasonal_decompose(x=china_obs, model='additive', period=7)","6851e422":"\ndecompose_weekly.seasonal.iplot()\n","2a23a86f":"# transmission rate can be a average confirmed case rate\nprint('Transmission rate in china: {} cases per day'.format(800\/7))","50746ef2":"**we are finishing data cleaning and we will start visualization our data**","674a0bfd":"**Time**  ","017d7726":"### Diagnostic our model IV\nwe are starting:","161604b5":"## Feature Statistics and Visualization","e9c5afa0":"we have determined a confirmed case grownth rate. We are going to use a model linearRegression and preprocessing our data using polynomialfeature to fit very well a nonlinear relationship.","480307e8":"# ROW growth rate forecast","800664ac":"We can approximate **average confirmed cases** like a logistic function.\n\nwe said ACC abbr Average Confirmed Cases in weekly is a formula\n\n> $ ACC(t_{weekly}) = \\dfrac{L}{1+exp(-k(t_{weekly}-t_{0,weekly})}) $\n\nwhere\n\n- $L$:  the curve's maximum value, and\n\n- $k$:  the logistic growth rate or steepness of the curve.\n\n- $t_{0,weekly}$: the $t_{weekly}-value$ of the sigmoid's midpoint. time is counted per week\n\nThe derivative is:\n> $\\dfrac{dACC}{dt} = k\\:ACC\\:(1 - \\dfrac{ACC}{L})$\n\nIf I consider ACC a average of people affected by covid 19 per week, we can say that $L$ is the carrying capacity of the population affected;(the maximum population affected size that a particular environment can sustain). ","acb48b4e":"You can see that we have anomaly format in the date_confirmation columns. how can fix it?  to fix that, we need to see the format of date_confirmation around 11586 to 11810 ","7b181b8a":"**Period = 7 days. this period can be a time that some people affected by covid 19 transmit a disease to another people or the season of covid 19 to generate or mutate.**","00c0938a":"our residual is iid.","18ce0eab":"What happens in the next days?","2b558b0e":"We see that pacf and acf give a same graph we can find p=3","2388a498":"lookback: How many timesteps back the input data should go.","9a5393d8":"r_train set is non stationary due to p-value > 0.05","25efb348":"From this plot, there exist seasonality or irreductible errors? we are going to find the answers. let's go.\n\n**Zero mean model**\n\nthe zero mean model have a constant mean and constant variance and show no predictable trends and seasonality. Observation from zero mean model are asumed to be independent and identically distrbuted(iid) andd represent random noise around the fixed mean, which has been deducted from the time series as a constant term.\n\n**seasonality model**\nthere manifest as periodic and repetitive fluctuation in a time serie and hence are modeled as sum of weigted sum of sine waves of known periodicity. \n\nto know if residual look like one of this two model below, we need to plot acf and pacf \n","9c6224fc":"## Data cleaning\nIn this part of notebook, I take two csv files covid_19_data and COVID19_open_line_list","a34d01e8":"**The Confirmed feature are a feature extremely important it can vary in the time. The next job is:**\n- find how the Confirmed feature behave in the time or local time\n- find how the Confirmed  feature behave in the different location.\n\n","0f0d184a":"Only Province\/State have a missing value. I can impute it because this variable is necessary for visualizing a data.","0605e458":"# Seasonality of Confirmed cases","f448c110":"I think there exist seasonality we are checking that using decomposition\nMA = 1\np = 0","f35a1930":"**Source** https:\/\/machinelearningmastery.com\/time-series-prediction-lstm-recurrent-neural-networks-python-keras\/\n\n**Source** *Avishek Pal_ PKS Prakash - Practical Time Series Analysis_ Master Time Series Data Processing, Visualization, and Modeling using Python-Packt Publishing (2017)*\n\n**Source** *Deep learning with python  Fran\u00e7ois Chollet*","b1ac700e":"**Correlation between feature over the time**","d2212d7e":"**# we see the seven country most affected by novel covid-19**","3b6dcb93":"In this part of our notebook, we are studying the confirmed behavior over time. To do that, we need to approximate our data as follows:\n> $\\dfrac{dcase}{case} = \\alpha(t)$\n\nSo, $dcase = case(t+\\tau) - case(t)$ and we have:\n\n> $\\alpha(t) = \\dfrac{case(t+\\tau) - case(t)}{case(t)} = \\dfrac{case(t+\\tau)}{case(t)} -1 $\n\nWe see that, $\\dfrac{case(t+\\tau)}{case(t)}$ is the **Grownth** for case where $ case(t) $ is the case on past day t, and $ case(t+\\tau)$ is the case on present day $ t + \\tau $. $\\tau$ is time between two date.\n\nIf we have $t_{i}$, $i=1,2,..N$, we can find the  growth rate $\\alpha$ as:\n> $\\alpha_{\\tau} = \\dfrac{case(t_{i}+\\tau)}{case(t_{i})} -1,\\qquad  \\forall i \\in \\mathcal{N}$.\n\nWe start. ","abd83f6a":"**Train model**","32ad42d2":"from this short course, we already do 1) and 2)(middle).\n\nas follows, we try to plot a residual to find if there exist a seasonal or irrecductible errors.","2137144a":"**Conclusion of Part I**\n\nFrom this work, we remark that:\n- Confirmed, Recovered and Death are two by two more correlated, we can do this approximation \n> - **Recovered = gof(Confirmed)**,  where **Death = f(Confirmed)** and **Recovered = g(Death)**\n\nSo, Confirmed feature is an important feature in this data. we can make a model based only on that feature. Confirmed feature depend on time.\n\nWe have seen qualitatively, how the COViD-19 is spreading in the World. The next part (part II),  we  find a model that predict the spread of covid-19 in the time.","1173e690":"# Day level information on covid-19 affected cases\n\n> **Task I**: Predict the spreading of corona virus \n- Can we help mitigate the secondary effect of covid-19 by predicting its spread?\n\nWe are going to answers this question\n\n## Part I","bfc3b265":"We see that feature: \n- Confirmed and Deaths are most correlated\n- Recovered and Deaths are more correlated\n- Confirmed and Recovered are more less correlated\n- active confirmed and confirmed are more correlated\n\nwe can check it in the figure below","fa9e556a":"**clean data from file COVID19_open_line_list.csv**","9bf7209b":"# Model III: Growth rate with autoregressive Model","356ea0bd":"## Verify stationarity ","70061721":"# Comparison of Confirmed Growth Rate and Forecasting (China vs ROW)","5461824b":"**part II**\n### Model I: Deep learning and time series  for predicting the spreading of novel covid-19 in world","b11eb136":"**Covid-19 into Province**\n> - patient confirmed\n> - patient recovered\n> - patient death","70b5d834":"## rest of the world\n\nwe are going to see the behavior of covid-19 in the rest of the world ","03b4ec7f":"this graph give us clearly information and I can do some approximation according to the correlation result below.\n- Confirmed feature ---> X\n- Deaths feature ---> Y\n- Recovered ---> Z\n\n> We can write\n- Y = f(X)\n- Z = g(Y)\n\nwe have\n> - Z = g(f(X)) \n\nfinally\n\n> - Z = gof(X). You understand why correlation between variable X and Z is 70.70%\n","c0436b29":"**Recall course**\n## Model for time series\n The purpose of time serie analysis is to develop a mathematical model that can explain the observed behavior of a time and possibly forecast the future state of the serie.\n \n The different model for time serie analysis is:\n \n 1- **zeros mean model**\n \n 2- **random walk**\n \n 3- **trend model**\n \n 4- **seasonality model**\n \nThe 4 steps generic approach of a time serie analysis as follows:\n\n1- *visualize the data at different granularities of the time index to reveal long run trends and seasonal fluctuation .*\n\n2- *fit trend line capture long run trends and plot the residuals to check for seasonality or irreductible error* \n\n3- *fit a harmonic regression model to capture seasonality* \n\n4- *plot the residual left by seasonality model to check for irreductible errors.*\n\nExtract from **Avishek Pal_ PKS Prakash - Practical Time Series Analysis_ Master Time Series Data Processing, Visualization, and Modeling using Python-Packt Publishing (2017)**","613b5272":"# China growth rate forecast","67b67d1b":"## Model II: Confirmed or Case behavior over time using growth rate","39988761":"**China**","55ce29a4":"**In this part I plot the country are most affected by the novel covid-19 on graph and table for the other country**","cc25b99d":"## Special China\n\nCOVID-19 come from this country that why I make attention to see the behaviour of this desease in that country.","319415e1":"Something is happening in that curve. **why china curve and row curve have a same break point?**. At this date 2020-02-12 appears a ncovid-19 and also date 2020-02-13 more people (15133) in china are confirmed cases.\n\nWhen we see a row curve, it is same with china curve but the day gap is 30 days (2020-02-12 to 2020-03-12). And again 2020-03-13 more people (16589) in  the rest of the world are are comfirmed cases at this date.\n\n**From these curves, my question is as follows: the break in the curve on 2020-03-12, tells us that there is another ncovid 19 in the rest of the world or else the ncovid 19 has mutated and has become something else on that date.** Please tell me if I'm wrong!","5c76b0cb":"**ACF and PACF for confirmed feature**","0f2edaff":"Source https:\/\/www.kaggle.com\/robikscube\/tutorial-time-series-forecasting-with-xgboost","d21f5706":"## Viewing forecast","946202f3":"Ok, we are finding a good model (**MAPE between 2 and 3**) that is fixing well our problem. So, we can now forecast evolution of covid 19 in the worldwide.\n\nI think that in the next days or month(April) China will not concern by this disease because their situation improve better and better many people who are affected by covid 19 recover a health. contrary in the rest of the world.\n\nThe next part in this notebook is to make a growth rate comparison between China and ROW. And if possible define the speed of contamination (confirmed cases)  ","2969e00c":"### The Worldwide confirmed, recovered, death and active confirmed ","209f61e9":"I think that **Period = 7 days**","48641898":"> **impute_covid**:\nwe are going to visualize this data and make some statistics to find the relevant information.","27f67dd2":"# Model IV: Confirmed growth rate with Prophet","36b3d0cd":"We know that time series can be expressed as **ts = trend + seasonal + cyclical + irregular**. But here we study only a seasonal part that contain a confirmed cases feature. To do that, we use this way:\n\n1- visualize weekly\n\n2- Decompose our time series to trend, seasonal and irregular\n\n3- give some conclusion\n\n** we use china_obs data for this work**","5087e298":"We realize that residual have trend and seasonal. So, we cannot continue to use this model we need another model more  adapted for this problem","32ee4c0f":"**Clean data from covid_19_data.csv file**","9150d49c":"**Location:  day level information on novel covid-19**","76916a3f":"## Upnext!"}}