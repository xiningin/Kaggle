{"cell_type":{"f3f78f5d":"code","b04b8ca9":"code","d2274510":"code","3ded39d5":"code","e0f35852":"code","f8fa4201":"code","706147c0":"code","02f1447e":"code","4295ead1":"code","2771ce3b":"code","2c5a2f8c":"code","8773e513":"code","e054ae1c":"code","42c5f668":"code","57862704":"code","93279f58":"code","903348e5":"markdown","70af3b83":"markdown","a9ef52f5":"markdown","cd613456":"markdown"},"source":{"f3f78f5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing import text, sequence\nfrom keras import backend as K\nfrom keras.models import load_model\nimport keras\nimport pickle\nprint(K.tensorflow_backend._get_available_gpus())\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b04b8ca9":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsub = pd.read_csv('..\/input\/sample_submission.csv')","d2274510":"train_data = train[\"comment_text\"]\nlabel_data = train[\"target\"]\ntest_data = test[\"comment_text\"]\ntrain_data.shape, label_data.shape, test_data.shape","3ded39d5":"tokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(list(train_data) + list(test_data))","e0f35852":"train_data = tokenizer.texts_to_sequences(train_data)\ntest_data = tokenizer.texts_to_sequences(test_data)","f8fa4201":"MAX_LEN = 200\ntrain_data = sequence.pad_sequences(train_data, maxlen=MAX_LEN)\ntest_data = sequence.pad_sequences(test_data, maxlen=MAX_LEN)","706147c0":"max_features = None","02f1447e":"max_features = max_features or len(tokenizer.word_index) + 1\nmax_features","4295ead1":"type(train_data), type(label_data.values), type(test_data)\nlabel_data = label_data.values","2771ce3b":"# Keras Model\n# Model Parameters\nNUM_HIDDEN = 256\nEMB_SIZE = 256\nLABEL_SIZE = 1\nMAX_FEATURES = max_features\nDROP_OUT_RATE = 0.2\nDENSE_ACTIVATION = \"sigmoid\"\nNUM_EPOCH = 1\n\n# Optimization Parameters\nBATCH_SIZE = 1000\nLOSS_FUNC = \"binary_crossentropy\"\nOPTIMIZER_FUNC = \"adam\"\nMETRICS = [\"accuracy\"]\n\nclass LSTMModel:\n    \n    def __init__(self):\n        self.model = self.build_graph()\n        self.compile_model()\n    \n    def build_graph(self):\n        model = keras.models.Sequential([\n            keras.layers.Embedding(MAX_FEATURES, EMB_SIZE),\n            keras.layers.CuDNNLSTM(NUM_HIDDEN),\n            keras.layers.Dropout(rate=DROP_OUT_RATE),\n            keras.layers.Dense(LABEL_SIZE, activation=DENSE_ACTIVATION)])\n        return model\n    \n    def compile_model(self):\n        self.model.compile(\n            loss=LOSS_FUNC,\n            optimizer=OPTIMIZER_FUNC,\n            metrics=METRICS)","2c5a2f8c":"model = LSTMModel().model\nmodel.fit(\n    train_data, \n    label_data, \n    batch_size = BATCH_SIZE, \n    epochs = NUM_EPOCH)","8773e513":"submission_in = '..\/input\/sample_submission.csv'\nsubmission_out = 'submission.csv'","e054ae1c":"result = model.predict(test_data)","42c5f668":"submission = pd.read_csv(submission_in, index_col='id')\nsubmission['prediction'] = result\nsubmission.reset_index(drop=False, inplace=True)","57862704":"submission.head()","93279f58":"submission.to_csv(submission_out, index=False)","903348e5":"#### Model","70af3b83":"#### Prediction","a9ef52f5":"#### Vectorize Data","cd613456":"### Preprocessing Data"}}