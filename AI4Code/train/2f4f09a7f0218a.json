{"cell_type":{"6f191621":"code","5a372274":"code","6a62db85":"code","df58fd25":"code","4c69458b":"code","9ef7b47f":"code","f78123da":"code","afa3744d":"code","d01bb571":"code","80df0cbd":"code","3c3fafac":"code","c94a765d":"code","4c5c9c05":"code","3d454b99":"code","03e955d0":"code","c6bdefdf":"code","2ffbe406":"code","e03d4326":"code","31092e11":"code","696ef578":"code","b2915767":"code","ae9fdaa8":"code","006b97af":"code","cdc7d2e9":"code","07b488b0":"code","39092b94":"code","66d4a023":"code","e8009ef9":"code","dbb6d542":"markdown","2e5dc8c5":"markdown","7ec669ec":"markdown","c643cc40":"markdown","c0375c06":"markdown","71647ee6":"markdown","e8b08b3b":"markdown","c49af4e4":"markdown","ebf86467":"markdown","c981369b":"markdown","cd0dbad8":"markdown"},"source":{"6f191621":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a372274":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","6a62db85":"credit_card_data=pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","df58fd25":"credit_card_data.head()","4c69458b":"credit_card_data.info()","9ef7b47f":"credit_card_data.isnull()","f78123da":"credit_card_data['Class'].value_counts()","afa3744d":"#separating the data from analysis\nlegit=credit_card_data[credit_card_data.Class==0]\nfraud=credit_card_data[credit_card_data.Class==1]","d01bb571":"print(legit.shape)\nprint(fraud.shape)","80df0cbd":"#statistical measures of the data\nlegit.Amount.describe()","3c3fafac":"fraud.Amount.describe()","c94a765d":"#compare the value for both transactions\ncredit_card_data.groupby('Class').mean()","4c5c9c05":"legit_sample=legit.sample(n=492)","3d454b99":"new_dataset=pd.concat([legit_sample,fraud],axis=0)","03e955d0":"new_dataset.head()","c6bdefdf":"new_dataset.tail()","2ffbe406":"new_dataset['Class'].value_counts()","e03d4326":"new_dataset.groupby('Class').mean()","31092e11":"X=new_dataset.drop(columns='Class',axis=1)\nY=new_dataset['Class']","696ef578":"print(Y)","b2915767":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)","ae9fdaa8":"print(X.shape,X_train.shape,X_test.shape)","006b97af":"model=LogisticRegression()","cdc7d2e9":"#training the logistic regression model with training data\nmodel.fit(X_train,Y_train)","07b488b0":"#accuracy on training data\nX_train_prediction=model.predict(X_train)\ntraining_data_accuracy=accuracy_score(X_train_prediction,Y_train)","39092b94":"print('Accuracy on training data: ',training_data_accuracy)","66d4a023":"#accuracy on test data\nX_test_prediction=model.predict(X_test)\ntest_data_accuracy=(X_test_prediction,Y_test)","e8009ef9":"print('Accuracy score on test data: ',test_data_accuracy)","dbb6d542":"Model Evaluation\n\n\nAccuracy Score","2e5dc8c5":"concating two dataframes","7ec669ec":"Model Training","c643cc40":"Logistic Regression","c0375c06":"Importing Dependencies","71647ee6":"Splitting the data into training data and testing data","e8b08b3b":"checking number of missing columns\n","c49af4e4":"Under-Sampling\n\n\nBuild a sample dataset containing similar distribution of normal transaction and fraudulent transactions\n\nnumber of fraudulent transaction->492","ebf86467":"This dataset is highly unbalanced.\n\n0-->Normal transaction\n1-->Fraudulent transaction","c981369b":"splitting the data into features and targets","cd0dbad8":"distribution of legit transactions and fraudulent transactions"}}