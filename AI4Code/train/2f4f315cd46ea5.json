{"cell_type":{"5b6c3e16":"code","f3b23203":"code","3f1afd66":"code","98c5e367":"code","e2c0b266":"code","66b7a933":"code","59a0cd66":"code","e8624f91":"code","5ac8f01b":"code","e7489bee":"code","243a25bd":"code","32b3a4a0":"code","c4539ff2":"code","bb5966d5":"code","21800a6c":"code","e094d8b3":"code","c2ebf155":"code","28a67b68":"code","3100be49":"markdown","cefeaa43":"markdown"},"source":{"5b6c3e16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f3b23203":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","3f1afd66":"df_train.drop(['Name','Ticket'], axis = 1,inplace=True)\ndf_test.drop(['Name','Ticket'], axis = 1,inplace=True)","98c5e367":"df_train['Age'].fillna(value=29,inplace=True)\ndf_test['Age'].fillna(value=29,inplace=True)","e2c0b266":"df_train['Embarked'].fillna(value='S',inplace=True)\t\ndf_test['Embarked'].fillna(value='S',inplace=True)","66b7a933":"df_train.Cabin.fillna(value='N',inplace=True)\ndf_train.Cabin = df_train.Cabin.str[:1]\n\ndf_test.Cabin.fillna(value='N',inplace=True)\ndf_test.Cabin = df_train.Cabin.str[:1]","59a0cd66":"df_test.Fare.fillna(value=32.2,inplace=True)","e8624f91":"df_train['Pclass'] = df_train['Pclass'].astype(str)\t\ndf_test['Pclass'] = df_test['Pclass'].astype(str)","5ac8f01b":"df_train.columns","e7489bee":"int_col = ['Age', 'SibSp', 'Parch','Fare']","243a25bd":"df_mean = df_train[int_col].mean(axis=0)\ndf_std = df_train[int_col].std(axis=0)","32b3a4a0":"df_test[int_col] = (df_test[int_col] - df_mean) \/ df_std\ndf_train[int_col] = (df_train[int_col] - df_mean) \/ df_std","c4539ff2":"df_train = pd.get_dummies(df_train)\ndf_test = pd.get_dummies(df_test)","bb5966d5":"col_X = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1',\n       'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Cabin_A', 'Cabin_B',\n       'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_N',\n       'Cabin_T', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\ncol_y = ['Survived']","21800a6c":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC,NuSVC\nfrom sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB,CategoricalNB,MultinomialNB","e094d8b3":"# aa = pd.DataFrame()\n# for ii in range(20):\n#     train_1,train_2 = train_test_split(df_train,test_size=0.25)   # \u5c06\u6570\u636e\u5206\u4e3a75%\u8bad\u7ec3\u96c6\u548c25%\u6d4b\u8bd5\u96c6\n#     mode_ada = [RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=8,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=9,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=10,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=11,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=12,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=13,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=14,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=15,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=16,min_samples_split=32,min_samples_leaf=1),\n#                 RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=17,min_samples_split=32,min_samples_leaf=1),\n#                 ]\n\n#     for jj in range(len(mode_ada)):\n#         mode_ada[jj].fit( train_1[col_X],train_1[col_y].values.ravel() )\n#         aa = aa.append( [ [ ii, jj, mode_ada[jj].score( train_1[col_X],train_1[col_y] ),    mode_ada[jj].score( train_2[col_X],train_2[col_y] )] ],ignore_index=True)\n# aa.groupby(by=[1]).mean().sort_values(by=[3],ascending=False)","c2ebf155":"mode = RandomForestClassifier(criterion='entropy',n_estimators=256,max_depth=10,min_samples_split=32,min_samples_leaf=1) # v3\nmode.fit( df_train[col_X],df_train[col_y].values.ravel() )","28a67b68":"df_test['Survived'] = mode.predict( df_test[col_X] )\ndf_test[ ['PassengerId','Survived'] ].to_csv('submission.csv',index=False)","3100be49":"# \u6570\u636e\u9884\u5904\u7406","cefeaa43":"# \u6a21\u578b"}}