{"cell_type":{"73739fec":"code","b532622b":"code","7a7df009":"code","dbe89d4f":"code","99ee5a86":"code","78a6995c":"code","4d607148":"code","33ae524e":"code","c269542e":"code","7899f207":"code","8c7c1e69":"code","26817535":"code","8b2a6443":"code","e971d70d":"code","a5e47a9d":"code","a3978cd0":"markdown","b449f65b":"markdown","ea5fdac2":"markdown","2d19170a":"markdown","bd478b78":"markdown","6f52a42c":"markdown"},"source":{"73739fec":"%%capture\n!pip uninstall -y shap\n!pip install https:\/\/github.com\/ceshine\/shap\/archive\/master.zip","b532622b":"import sys\nimport gc","7a7df009":"import torch.nn as nn\nimport torch\nfrom torch.nn.utils.weight_norm import weight_norm\nfrom sklearn import preprocessing\nimport shap\nimport numpy as np\nimport joblib","dbe89d4f":"%ls ..\/input\/","99ee5a86":"%ls ..\/input\/pytorch-baseline-model\/data\/cache\/model_cache\/","78a6995c":"MODEL = \"..\/input\/pytorch-baseline-model\/data\/cache\/model_cache\/snapshot_PUBG_0.02649101.pth\"","4d607148":"class MLPModel(nn.Module):\n    def __init__(self, num_features):\n        super().__init__()\n        self.model = nn.Sequential(\n            weight_norm(nn.Linear(num_features, 128)),\n            nn.ReLU(),\n            weight_norm(nn.Linear(128, 128)),\n            nn.ReLU(),\n            weight_norm(nn.Linear(128, 128)),\n            nn.ReLU(),\n            weight_norm(nn.Linear(128, 128)),\n            nn.ReLU(),          \n            weight_norm(nn.Linear(128, 1)),\n        )\n\n    def forward(self, input_tensor):\n        return torch.clamp(self.model(input_tensor), 0, 1)","33ae524e":"x_train, features = joblib.load(\"..\/input\/pytorch-baseline-model\/x_train_dump.jl.gz\")","c269542e":"DEVICE = \"cpu\"\nmodel = MLPModel(len(features)).to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL, map_location='cpu'))","7899f207":"%%time\ne = shap.DeepExplainer(\n        model, \n        torch.from_numpy(\n            x_train[np.random.choice(np.arange(len(x_train)), 10000, replace=False)]\n        ).to(DEVICE))","8c7c1e69":"%%time\nx_samples = x_train[np.random.choice(np.arange(len(x_train)), 500, replace=False)]\nprint(len(x_samples))\nshap_values = e.shap_values(\n    torch.from_numpy(x_samples).to(DEVICE)\n)","26817535":"shap_values.shape","8b2a6443":"import pandas as pd\ndf = pd.DataFrame({\n    \"mean_abs_shap\": np.mean(np.abs(shap_values), axis=0), \n    \"stdev_abs_shap\": np.std(np.abs(shap_values), axis=0), \n    \"name\": features\n})\ndf.sort_values(\"mean_abs_shap\", ascending=False)[:10]","e971d70d":"df.to_csv(\"feature_importances.csv\", index=False)","a5e47a9d":"shap.summary_plot(shap_values, features=x_samples, feature_names=features)","a3978cd0":"### Shap Values As a Data Frame","b449f65b":"Install my forck of the  *shap* package:\n\n(The PyTorchDeepExplainer from the official master branch needs some tweaking to work)","ea5fdac2":"## Deep Explainer\n\nHere we only use a small sample (500) to save time:","2d19170a":"# Preparation","bd478b78":"### Plotting Overall Shap Values","6f52a42c":"## Load a Model"}}