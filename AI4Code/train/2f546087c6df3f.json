{"cell_type":{"3be813b2":"code","86070e54":"code","89c3b062":"code","5b330273":"code","6b5cab64":"code","d0c6d63e":"code","7fa809c3":"code","b6db78da":"code","c603c1ba":"code","02104f89":"code","fd56d71a":"code","59c65f2e":"code","14411beb":"markdown","232d3dc2":"markdown"},"source":{"3be813b2":"import datatable as dt  # pip install datatable\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom lightgbm import LGBMClassifier","86070e54":"%%time\ntrain_pd = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/train.csv\")","89c3b062":"%%time\ntest_pd = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/test.csv\")","5b330273":"memory_usage_train = train_pd.memory_usage(deep=True) \/ 1024 ** 2\nmemory_usage_test = test_pd.memory_usage(deep=True) \/ 1024 ** 2\n\nmemory_usage_train.head(7)","6b5cab64":"memory_usage_train.sum()","d0c6d63e":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","7fa809c3":"reduced_train_pd = reduce_memory_usage(train_pd, verbose=True)\nreduced_test_pd = reduce_memory_usage(test_pd, verbose=True)","b6db78da":"y=reduced_train_pd['target'].reset_index(drop=True)\nX=reduced_train_pd.drop(['id','target'],axis=1).reset_index(drop=True)","c603c1ba":"test=reduced_test_pd.drop('id',axis=1)","02104f89":"from sklearn.model_selection import StratifiedKFold\n\nauc=[]\n\nparams={'reg_alpha': 8.158768860412389, 'reg_lambda': 8.793022151019823, \n        'colsample_bytree': 0.2, 'subsample': 0.4, 'learning_rate': 0.05,\n   'max_depth': -1, 'num_leaves': 24, 'min_child_samples': 68, 'cat_smooth': 91,\n        'objective': 'binary', 'random_state': 48,'n_estimators': 20000,'n_jobs': -1}\npreds=np.zeros(test.shape[0])\nskf = StratifiedKFold(n_splits=10)\nn=0\nfor train_index, test_index in skf.split(X, y):\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    model = LGBMClassifier(**params)\n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=200,eval_metric=\"auc\",verbose=50)\n    print(model.predict_proba(X_test))\n    auc.append(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n    preds += model.predict_proba(test)[:,1]\n    print(skf.n_splits)\n    print(f\"fold: {n+1}, auc: {auc[n]}\")\n    n+=1","fd56d71a":"preds += preds\/kf.n_splits","59c65f2e":"submission=pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv')\nsubmission['target'] = preds\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","14411beb":"### Import Libraries","232d3dc2":"### Reduce the memory of train and test data which is loaded using pandas"}}