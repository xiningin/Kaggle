{"cell_type":{"fe961f58":"code","cf7b7a6b":"code","f904d57f":"code","e5961076":"code","7aa9e36b":"code","4442257e":"code","03a248f1":"code","b159e390":"code","5d6e5621":"code","a7193e3c":"code","583ec28c":"code","a9374473":"code","68bf7aa0":"code","1c5bfb3f":"code","324ab57a":"code","a2ac319f":"code","669261a6":"code","3ef32f24":"code","7807c3c6":"code","9abc264e":"code","c205cb61":"code","3b413d5f":"markdown","d31f48c1":"markdown","0919af4b":"markdown","f0b764bb":"markdown","1e609874":"markdown","6bbd86d2":"markdown","54ceb0bc":"markdown","829cbd8a":"markdown"},"source":{"fe961f58":"import re\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Device:\", tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)","cf7b7a6b":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 25 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [180, 180]\nCLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]","f904d57f":"train_images = tf.data.TFRecordDataset(\n    \"gs:\/\/download.tensorflow.org\/data\/ChestXRay2017\/train\/images.tfrec\"\n)\ntrain_paths = tf.data.TFRecordDataset(\n    \"gs:\/\/download.tensorflow.org\/data\/ChestXRay2017\/train\/paths.tfrec\"\n)\n\nds = tf.data.Dataset.zip((train_images, train_paths))","e5961076":"COUNT_NORMAL = len(\n    [\n        filename\n        for filename in train_paths\n        if \"NORMAL\" in filename.numpy().decode(\"utf-8\")\n    ]\n)\nprint(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n\nCOUNT_PNEUMONIA = len(\n    [\n        filename\n        for filename in train_paths\n        if \"PNEUMONIA\" in filename.numpy().decode(\"utf-8\")\n    ]\n)\nprint(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))","7aa9e36b":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, \"\/\")\n    # The second to last is the class-directory\n    return parts[-2] == \"PNEUMONIA\"\n\n\ndef decode_img(img):\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    # resize the image to the desired size.\n    return tf.image.resize(img, IMAGE_SIZE)\n\n\ndef process_path(image, path):\n    label = get_label(path)\n    # load the raw data from the file as a string\n    img = decode_img(image)\n    return img, label\n\n\nds = ds.map(process_path, num_parallel_calls=AUTOTUNE)","4442257e":"ds = ds.shuffle(10000)\ntrain_ds = ds.take(4200)\nval_ds = ds.skip(4200)","03a248f1":"for image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","b159e390":"test_images = tf.data.TFRecordDataset(\n    \"gs:\/\/download.tensorflow.org\/data\/ChestXRay2017\/test\/images.tfrec\"\n)\ntest_paths = tf.data.TFRecordDataset(\n    \"gs:\/\/download.tensorflow.org\/data\/ChestXRay2017\/test\/paths.tfrec\"\n)\ntest_ds = tf.data.Dataset.zip((test_images, test_paths))\n\ntest_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n","5d6e5621":"def prepare_for_training(ds, cache=True):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.batch(BATCH_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","a7193e3c":"train_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\n\nimage_batch, label_batch = next(iter(train_ds))","583ec28c":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(20, 20))\n    for n in range(36):\n        ax = plt.subplot(6, 6, n + 1)\n        plt.imshow(image_batch[n] \/ 255)\n        if label_batch[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")","a9374473":"show_batch(image_batch.numpy(), label_batch.numpy())","68bf7aa0":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\ndef conv_block(filters, inputs):\n    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    outputs = layers.MaxPool2D()(x)\n\n    return outputs\n\n\ndef dense_block(units, dropout_rate, inputs):\n    x = layers.Dense(units, activation=\"relu\")(inputs)\n    x = layers.BatchNormalization()(x)\n    outputs = layers.Dropout(dropout_rate)(x)\n\n    return outputs","1c5bfb3f":"def build_model():\n    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n    x = preprocessing.Rescaling(1.0 \/ 255)(inputs)\n    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPool2D()(x)\n\n    x = conv_block(32, x)\n    x = conv_block(64, x)\n\n    x = conv_block(128, x)\n    x = layers.Dropout(0.2)(x)\n\n    x = conv_block(256, x)\n    x = layers.Dropout(0.2)(x)\n\n    x = layers.Flatten()(x)\n    x = dense_block(512, 0.7, x)\n    x = dense_block(128, 0.5, x)\n    x = dense_block(64, 0.3, x)\n\n    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model\n","324ab57a":"initial_bias = np.log([COUNT_PNEUMONIA \/ COUNT_NORMAL])\nprint(\"Initial bias: {:.5f}\".format(initial_bias[0]))\n\nTRAIN_IMG_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA\nweight_for_0 = (1 \/ COUNT_NORMAL) * (TRAIN_IMG_COUNT) \/ 2.0\nweight_for_1 = (1 \/ COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) \/ 2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(\"Weight for class 0: {:.2f}\".format(weight_for_0))\nprint(\"Weight for class 1: {:.2f}\".format(weight_for_1))","a2ac319f":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\", save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(\n    patience=10, restore_best_weights=True\n)","669261a6":"initial_learning_rate = 0.015\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100, decay_rate=0.99, staircase=True\n)","3ef32f24":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [\n        tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.Precision(name=\"precision\"),\n        tf.keras.metrics.Recall(name=\"recall\"),\n    ]\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss=\"binary_crossentropy\",\n        metrics=METRICS,\n    )\n\nhistory = model.fit(\n    train_ds,\n    epochs=100,\n    validation_data=val_ds,\n    class_weight=class_weight,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)","7807c3c6":"fig, ax = plt.subplots(2, 2, figsize=(20, 10))\nax = ax.ravel()\n\nfor i, met in enumerate([\"precision\", \"recall\", \"binary_accuracy\", \"loss\"]):\n    ax[i].grid()\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history[\"val_\" + met])\n    ax[i].set_title(\"Model {}\".format(met))\n    ax[i].set_xlabel(\"epochs\")\n    ax[i].set_ylabel(met)\n    ax[i].legend([\"train\", \"val\"])","9abc264e":"model.evaluate(test_ds, return_dict=True)","c205cb61":"for image, label in test_ds.take(1):\n    plt.imshow(image[0] \/ 255.0)\n    plt.title(CLASS_NAMES[label[0].numpy()])\n    plt.axis(\"off\")\n\nprediction = model.predict(test_ds.take(1))[0]\nscores = [1 - prediction, prediction]\n\nfor score, name in zip(scores, CLASS_NAMES):\n    print(\"This image is %.2f percent %s\" % ((100 * score), name))","3b413d5f":"# Build the CNN","d31f48c1":"# Correct for data imbalance","0919af4b":"# Fit the model","f0b764bb":"# Visualize the dataset","1e609874":"# Load the data","6bbd86d2":"# Train the model","54ceb0bc":"# Predict and evaluate results","829cbd8a":"## Defining callbacks"}}