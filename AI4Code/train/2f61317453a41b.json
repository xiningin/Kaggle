{"cell_type":{"741d5077":"code","600dde8e":"code","bd5e1d32":"code","0b795345":"code","bfa8c80b":"code","16a3b7a5":"code","1d0867e9":"code","3c5da453":"code","7ce5bbc9":"code","c4bffb06":"code","45ea3d2d":"code","17617226":"code","ca230a22":"code","ede8a305":"markdown","e86f6fa1":"markdown","1993bc6d":"markdown","d8b9d8fc":"markdown","2fdc62e5":"markdown","e22f4ad5":"markdown"},"source":{"741d5077":"import os\nimport re\nimport time\nimport string\nimport pickle\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\n\nimport torch\nimport torch.nn as nn\n\nimport seaborn as sns\n\nfrom nltk.stem import WordNetLemmatizer\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n\nfrom collections import defaultdict","600dde8e":"glove_path='..\/input\/glove6b100dtxt\/glove.6B.100d.txt'\nglove_embeddings={}\nwith open(glove_path) as file:\n    for line in file:\n        line=line.split()\n        word=line[0]\n        v=np.array(line[1:]).astype(np.float)\n        glove_embeddings[word]=v\nprint(len(glove_embeddings))","bd5e1d32":"class Tokenizer:\n    def __init__(self):\n        self.lemmatizer=WordNetLemmatizer()\n        self.nlp=English()\n    def __call__(self, doc):\n        tokens=[]\n        for token in self.nlp(doc):\n            if token.like_num or token.text=='':\n                continue\n            token=token.lower_.strip()\n            for p in string.punctuation:\n                token=token.replace(p, ' ')\n            token=token.split(' ')\n            token=[w for w in token if w!='']\n            tokens+=token\n        return tokens","0b795345":"MAX_SEQ_LEN=150\nBATCH_SIZE=128","bfa8c80b":"target_mean=-0.9625387984618096#train_df.target.mean()\ntarget_std=1.0382744351056232#train_df.target.std()\n\nprint(\"Taget Mean:\", target_mean)\nprint(\"Taget Std:\", target_std)","16a3b7a5":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, df, phase):\n        self.df=df\n        self.phase=phase\n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        doc=row.doc\n        \n        X=torch.zeros((MAX_SEQ_LEN, 100), dtype=torch.float32)\n        for i, word in enumerate(doc):\n            if i >= MAX_SEQ_LEN:\n                break\n            if word in glove_embeddings:\n                X[i]=torch.tensor(glove_embeddings[word])\n        \n        if self.phase=='train':\n            y=torch.tensor(row.normalized_target, dtype=torch.float32)\n            return (X, y)\n        return X\n    def __len__(self):\n        return len(self.df)","1d0867e9":"class ProjectionHead(nn.Module):\n    def __init__(self, in_features,out_feat):\n        super().__init__()\n        self.linear1=nn.Linear(in_features, 512)\n        self.bn=nn.BatchNorm1d(512)\n        self.dropout=nn.Dropout(0.2)\n        self.relu=nn.ReLU()\n        self.linear2=nn.Linear(512, out_feat)\n    def forward(self, x):\n        x=self.linear1(x)\n        x=self.bn(x)\n        x=self.dropout(x)\n        x=self.relu(x)\n        x=self.linear2(x)\n        return x\n\nclass Model(nn.Module):\n    def __init__(self, embedd_size, hidden_size):\n        super().__init__()\n        self.hidden_size=hidden_size\n        self.gru=nn.GRU(embedd_size, hidden_size, num_layers=2, \n                        dropout=0.2, bidirectional=True,batch_first=True)\n        self.bn=nn.BatchNorm1d(2*hidden_size)\n        self.relu=nn.ReLU()\n        self.dropout=nn.Dropout(0.2)\n        self.proj_head=ProjectionHead(2*hidden_size, 1)\n    def forward(self, x):\n        batch_size=x.shape[0]\n        (_, h_n)=self.gru(x)\n        h_n=h_n.view(2, 2, batch_size, self.hidden_size)\n        h_n=h_n[1, :, :, :].permute(1, 0, 2)\n        h_n1=h_n[:, 0, :]\n        h_n2=h_n[:, 1, :]\n        h=torch.cat([h_n1, h_n2], dim=1)\n        \n        h=self.bn(h)\n        h=self.relu(h)\n        h=self.dropout(h)\n        \n        y=self.proj_head(h)\n        return y","3c5da453":"models=[\n    torch.load('..\/input\/commonlit-glove-model\/model_1.pt'),\n    torch.load('..\/input\/commonlit-glove-model\/model_2.pt'),\n    torch.load('..\/input\/commonlit-glove-model\/model_3.pt'),\n    torch.load('..\/input\/commonlit-glove-model\/model_4.pt'),\n    torch.load('..\/input\/commonlit-glove-model\/model_5.pt')\n]","7ce5bbc9":"def infer(models, dataloader):\n    preds=[]\n    for X in dataloader:\n        y_hat=torch.zeros(X.shape[0])\n        for model in models:\n            model.eval()\n            with torch.no_grad():\n                y=model(X).view(-1)\n                y_hat+=(target_std*y) + target_mean\n            \n        preds+=list(y_hat.numpy()\/len(models))\n    return preds","c4bffb06":"tokenizer=Tokenizer()\n\ntest_df=pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ntest_df['doc']=test_df.excerpt.apply(tokenizer)\ntest_df.head()","45ea3d2d":"infer_test_dataset=Dataset(test_df, 'test')\ninfer_test_dataloader=torch.utils.data.DataLoader(infer_test_dataset, batch_size=200, shuffle=False)\ntest_df['target'] = infer(models, infer_test_dataloader)\n","17617226":"submission_df=test_df[['id', 'target']].copy()\nsubmission_df.head()","ca230a22":"submission_df.to_csv('submission.csv', index=False)","ede8a305":"# Submission","e86f6fa1":"# Load Glove 100-d vectors","1993bc6d":"# Configuration","d8b9d8fc":"lets us consider all the words that appear atleast in 5 documents","2fdc62e5":"# Model","e22f4ad5":"# Load Models"}}