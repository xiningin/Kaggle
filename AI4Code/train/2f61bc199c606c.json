{"cell_type":{"29b22e2b":"code","94ad0f09":"code","33e2ba30":"code","c94875c6":"code","03877f4a":"code","94a88610":"code","782b17e1":"code","c6cafe00":"code","cca32fb8":"code","a8a34660":"code","b061b5cd":"code","dc623ae7":"code","85b163d3":"code","ab631c7c":"code","018719f3":"code","787fb562":"code","2c12cf72":"code","012f134d":"code","88a3d7c3":"code","0b574beb":"code","72e82eab":"code","dfee9086":"markdown","d88810ff":"markdown","1fb3b23b":"markdown","248cd69a":"markdown","4a26c9c9":"markdown","78b5f3a7":"markdown","350dfcac":"markdown","52f51be8":"markdown","bc8f4b6f":"markdown","b7beaf74":"markdown","76017c00":"markdown","c8216822":"markdown","04654538":"markdown","52827ce3":"markdown","046ef485":"markdown","3b588b09":"markdown","125315ee":"markdown","7d9aaa19":"markdown","47c1c8f0":"markdown","a64a1a6b":"markdown","b4b07166":"markdown","df04b6f1":"markdown"},"source":{"29b22e2b":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics.regression import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LinearRegression, LassoCV, Lasso\nfrom sklearn.ensemble import RandomForestRegressor","94ad0f09":"data = pd.read_csv('..\/input\/winequality-white.csv')","33e2ba30":"data.head()","c94875c6":"data.info()","03877f4a":"y = data['quality']\nX = data.drop('quality', axis=1)\n\nX_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.3, random_state=17)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_holdout_scaled = scaler.transform(X_holdout)","94a88610":"linreg = LinearRegression()\nlinreg.fit(X_train_scaled, y_train);","782b17e1":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, linreg.predict(X_train_scaled)))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, linreg.predict(X_holdout_scaled)))","c6cafe00":"from eli5.sklearn.explain_weights import explain_linear_regressor_weights\n\nexplain_linear_regressor_weights(reg=linreg, feature_names=data.columns.drop('quality').tolist())","cca32fb8":"lasso1 = Lasso(alpha=0.01, random_state=17)\nlasso1.fit(X_train_scaled, y_train)","a8a34660":"lasso1_coef = pd.DataFrame({'coef': lasso1.coef_, 'coef_abs': np.abs(lasso1.coef_)},\n                          index=data.columns.drop('quality'))\nlasso1_coef.sort_values(by='coef_abs', ascending=False)","b061b5cd":"alphas = np.logspace(-6, 2, 200)\nlasso_cv = LassoCV(alphas=alphas, cv=5, random_state=17)\nlasso_cv.fit(X_train_scaled, y_train)","dc623ae7":"lasso_cv.alpha_","85b163d3":"lasso_cv_coef = pd.DataFrame({'coef': lasso_cv.coef_, 'coef_abs': np.abs(lasso_cv.coef_)},\n                          index=data.columns.drop('quality'))\nlasso_cv_coef.sort_values(by='coef_abs', ascending=False)","ab631c7c":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, lasso_cv.predict(X_train_scaled)))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, lasso_cv.predict(X_holdout_scaled)))","018719f3":"forest = RandomForestRegressor(random_state=17)\nforest.fit(X_train_scaled, y_train)","787fb562":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, forest.predict(X_train_scaled)))\nprint(\"Mean squared error (cv): %.3f\" % np.mean(np.abs(cross_val_score(forest, X_train_scaled, y_train, \n                                                                       scoring='neg_mean_squared_error'))))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, forest.predict(X_holdout_scaled)))","2c12cf72":"forest_params = {'max_depth': list(range(10, 25)), \n                  'max_features': list(range(6,12))}\n\nlocally_best_forest = GridSearchCV(RandomForestRegressor(n_jobs=-1, random_state=17), \n                                 forest_params, \n                                 scoring='neg_mean_squared_error',  \n                                 n_jobs=-1, cv=5,\n                                  verbose=True)\nlocally_best_forest.fit(X_train_scaled, y_train)","012f134d":"locally_best_forest.best_params_, locally_best_forest.best_score_","88a3d7c3":"print(\"Mean squared error (cv): %.3f\" % np.mean(np.abs(cross_val_score(locally_best_forest.best_estimator_,\n                                                        X_train_scaled, y_train, \n                                                        scoring='neg_mean_squared_error'))))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, \n                                                             locally_best_forest.predict(X_holdout_scaled)))","0b574beb":"rf_importance = pd.DataFrame(locally_best_forest.best_estimator_.feature_importances_, \n                             columns=['importance'], index=data.columns[:-1]) \nrf_importance.sort_values(by='importance', ascending=False)","72e82eab":"from eli5.sklearn.explain_weights import explain_rf_feature_importance\n\nexplain_rf_feature_importance(locally_best_forest.best_estimator_, feature_names=data.columns[:-1].tolist())","dfee9086":"**We are working with UCI Wine quality dataset (no need to download it \u2013 it's already there, in course repo and in Kaggle Dataset).**","d88810ff":"## Lasso regression","1fb3b23b":"**<font color='red'>Question 6:<\/font> What are mean squared errors of tuned RF model in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","248cd69a":"The dependency of wine quality on other features in hand is, presumable, non-linear. So Random Forest works better in this task.","4a26c9c9":"## Linear regression","78b5f3a7":"**<font color='red'>Question 4:<\/font> What are mean squared errors of tuned LASSO predictions on train and holdout sets?**","350dfcac":"**Separate the target feature, split data in 7:3 proportion (30% form a holdout set, use random_state=17), and preprocess data with `StandardScaler`.**","52f51be8":"<center>\n<img src=\"https:\/\/habrastorage.org\/files\/fd4\/502\/43d\/fd450243dd604b81b9713213a247aa20.jpg\">\n## Open Machine Learning Course\n<center>Author: [Yury Kashnitsky](https:\/\/www.linkedin.com\/in\/festline\/), Data Scientist at Mail.ru Group <br>\n    All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/) license.\nYou may use this material for any purpose (you can edit, correct and use it as example) exept commercial use with mandatory citation of author.","bc8f4b6f":"**Output RF's feature importance. Again, it's nice to present it as a DataFrame.**<br>\n**<font color='red'>Question 7:<\/font> What is the most important feature, according to the Random Forest model?**","b7beaf74":"**Train a Random Forest with out-of-the-box parameters, setting only random_state to be 17.**","76017c00":"**<font color='red'>Question 1:<\/font> What are mean squared errors of model predictions on train and holdout sets?**","c8216822":"**Train LassoCV with random_state=17 to choose the best value of $\\alpha$ in 5-fold cross-validation.**","04654538":"**<font color='red'>Question 5:<\/font> What are mean squared errors of RF model on the training set, in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","52827ce3":"**Which feature is the least informative in predicting wine quality, according to this LASSO model?**","046ef485":"**Make conclusions about the perdormance of the explored 3 models in this particular prediction task.**","3b588b09":"## Random Forest","125315ee":"**Sort features by their influence on the target feature (wine quality). Beware that both large positive and large negative coefficients mean large influence on target. It's handy to use `pandas.DataFrame` here.**\n\n**<font color='red'>Question 2:<\/font> Which feature this linear regression model treats as the most influential on wine quality?**","7d9aaa19":"**Train a LASSO model with $\\alpha = 0.01$ (weak regularization) and scaled data. Again, set random_state=17.**","47c1c8f0":"**Tune the `max_features` and `max_depth` hyperparameters with GridSearchCV and again check mean cross-validation MSE and MSE on holdout set.**","a64a1a6b":"**Train a simple linear regression model (Ordinary Least Squares).**","b4b07166":"**<font color='red'>Question 3:<\/font> Which feature is the least informative in predicting wine quality, according to the tuned LASSO model?**","df04b6f1":"# <center> Assignment #6 (demo).\n## <center>  Exploring OLS, Lasso and Random Forest in a regression task\n    \n<img src=https:\/\/habrastorage.org\/webt\/-h\/ns\/aa\/-hnsaaifymavmmudwip9imcmk58.jpeg width=30%>\n\n**Fill in the missing code and choose answers in [this](https:\/\/docs.google.com\/forms\/d\/1aHyK58W6oQmNaqEfvpLTpo6Cb0-ntnvJ18rZcvclkvw\/edit) web form.**"}}