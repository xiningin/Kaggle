{"cell_type":{"de3e981d":"code","ae2ed326":"code","831b2fb3":"code","26dbaebb":"code","330a7bf7":"code","0e65aa38":"code","44c837b7":"code","da781eb5":"code","add89dba":"code","af192529":"code","c4d8065d":"code","de9b7266":"code","33fb5c58":"code","0993ecec":"code","1a3f8746":"code","ecdf0bbe":"code","9ac1ad2f":"markdown","ca7823e5":"markdown","358a1090":"markdown","70ea1104":"markdown","b76b1b28":"markdown","53effcca":"markdown","90701a34":"markdown","d2dd9605":"markdown","f63a7026":"markdown","d11b408d":"markdown","994a5ad3":"markdown"},"source":{"de3e981d":"# Importing the required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #visualisation\nimport matplotlib.pyplot as plt #visualisation\n%matplotlib inline \nsns.set(color_codes=True)\nnp.random.seed(31415)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ae2ed326":"# Loading the CSV file into a pandas dataframe.\ndf = pd.read_csv(\"..\/input\/cars1\/CARS.csv\")\ndf.head(5)","831b2fb3":"colstocheck = df.columns\ndf[colstocheck] = df[colstocheck].replace({'\\$':''}, regex = True)\ndf[colstocheck] = df[colstocheck].replace({',':''}, regex = True)\ncol_mask=df.isnull().any(axis=0) \nprint(col_mask)\nrow_mask=df.isnull().any(axis=1)\ndf.loc[row_mask,col_mask]\ndf = df.dropna()\ndf['MSRP'] = df['MSRP'].astype(float)\ndf.head(5)","26dbaebb":"df = df.drop(['Make','Model','Type','Origin','DriveTrain','Invoice'],axis=1)\ndf.head(5)","330a7bf7":"# Importing all the required libraries\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","0e65aa38":"# Creating the Lasso Regression Model\nreg = linear_model.Lasso(alpha=0.1)","44c837b7":"X = df.drop(\"MSRP\", axis=1)\ny = df[\"MSRP\"]\nX = X.to_numpy()\nX.ndim","da781eb5":"y = y.to_numpy()\ny.ndim","add89dba":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","af192529":"# Fitting and predicting the trained values to the Lassor Regression Model\nreg.fit(X_train, y_train)\npred = reg.predict(X_test)\n# Printing the first five predicted values\npred[1:5]\n","c4d8065d":"plt.figure(figsize= (6, 6))\nplt.title(\"Visualizing the Regression using Lasso Regression algorithm\")\nsns.regplot(x=pred, y=y_test, color = \"teal\")\nplt.xlabel(\"New Predicted Price (MSRP)\")\nplt.ylabel(\"Old Price (MSRP)\")\nplt.show()","de9b7266":"print(\"Mean Absolute Error is :\", mean_absolute_error(y_test, pred))\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"Mean Squared Error is :\", mean_squared_error(y_test, pred))\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"Coeffients are : \", reg.coef_)\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"Intercepts are :\" ,reg.intercept_)\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"The R2 square value of Lasso is :\", r2_score(y_test, pred)*100)","33fb5c58":"model = RandomForestRegressor()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\n\nplt.figure(figsize= (6, 6))\nplt.title(\"Visualizing the Regression using Random Forest Regression algorithm\")\nsns.regplot(pred, y_test, color = 'teal')\nplt.xlabel(\"New Predicted Price (MSRP)\")\nplt.ylabel(\"Old Price (MSRP)\")\nplt.show()\n","0993ecec":"model = RandomForestRegressor()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\nprint(\"Mean Absolute Error is :\", mean_absolute_error(y_test, pred))\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"Mean Squared Error is :\", mean_squared_error(y_test, pred))\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"The R2 square value of RandomForest Regressor is :\", r2_score(y_test, pred)*100)\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")","1a3f8746":"model = LinearRegression()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\nplt.figure(figsize= (6, 6))\nplt.title(\"Visualizing the Regression Linear Regression Algorithm\")\nsns.regplot(pred, y_test, color = 'teal')\nplt.xlabel(\"New Predicted Price (MSRP)\")\nplt.ylabel(\"Old Price (MSRP)\")\nplt.show()","ecdf0bbe":"print(\"Mean Absolute Error is :\", mean_absolute_error(y_test, pred))\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"Mean Squared Error is :\", mean_squared_error(y_test, pred))\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"Coeffients are : \", model.coef_)\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"Intercepts are :\" ,model.intercept_)\nprint(\" \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \")\nprint(\"The R2 square value of Linear Regression is :\", r2_score(y_test, pred)*100)","9ac1ad2f":"**Plotting Lasso Regression**","ca7823e5":"**Preparing the data in an order that is supported by the algorithms**\n\nHere the data needs to be prepared in a particular order because wrong mismatch order of data can cause an error. The \u2018X\u2019 variable contains all the features except the MSRP and it of 2 dimensions. Similarly, the \u2018y\u2019 variable contains only MSRP values and its of 1 dimension. I have converted the data frames into a numpy array. Because it was initially giving me an error, then I came to know that most of the SciKit algorithms accept the input as an array. So I converted both the \u2018X\u2019 and the \u2018y\u2019 values to a numpy array. We can check the dimensions using ndim method. If the \u2018y\u2019 value is a two-dimension array then it cannot be fitted in the model because of the wrong order in the data frames. This is one of the most important steps that must be done before feeding the values to the model.","358a1090":"**Cleaning the data**\n\nIn this part I removed the $ sign and the commas (,) in the cars prices (MSRP).\n\nI also removed the rows that contain Nan values.\n\nI also converted the prices from integers to floats because it was causing problems when printing.\n","70ea1104":"**Implementing LASSO Regression**","b76b1b28":"**Discussion**\nThese models have the power to predict the outcome of future instances. The models predict the price (MSRP) of the car given the specifications or other features of the car. The model overall gives a score of 74.5% (Lasso Regression), 80.5% (Random Forest Regression), and 74.5% (Linear Regression).\n","53effcca":"**Implementing the algorithms**\n\nIn this assignment, I am implementing three different Machine Learning Algorithms, this is because every algorithm has a better prediction score and accuracy.\n\nThe first step involved in implementing the above algorithms is determining the dependent and independent variables. At this stage, I knew that the dependent variable is the price or MSRP and the independent variables are all variables excluding MSRP in my data set. The reason for this is I could see a pattern in my dataset. For example, if the engine size of the car was high then the price of the car was high and the same refers to Horsepower, Cylinders, Length, Wheelbase and many more. Because of this pattern, I predicted the price (MSRP) against all the features of the car.","90701a34":"**Random Forest Regression model**","d2dd9605":"**Providing statistical information that supports the model**\n\nThis step involves printing the results such as the Mean Absolute Error, Mean Squared Error Coefficient, Intercept and the r\u00b2_score. Out of these three, the r\u00b2_score is the important metric. It determines the accuracy or the score of the model. I have also included the score of the other algorithms such as Linear Regression, Random Forest.","f63a7026":"During Implementation of the models I will be dividing the data into two parts:\n1. Train data: Training data is the one wherein we train and fit the data to the algorithm.\n2. Test data: Testing data is the one wherein we test that data based on the trained data and check the performance of the model\n\nSplitting the data helps our model to predict more accurately because the model would be trained and tested with multiple data. Here the train and testing data is divided as 70 and 30.","d11b408d":"* **Removing irrelevant features.**\n\nI will remove some features such as Drive Train, Model, Invoice, Type, and Origin from this dataset. Because these features do not contribute to the prediction of price.","994a5ad3":"**Linear Regression model**"}}