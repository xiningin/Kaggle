{"cell_type":{"0ad20145":"code","7e0e5327":"code","51d88ca9":"code","1f88a4b1":"code","5cd5db15":"code","59dc8869":"code","afa7f4ad":"code","6af95156":"code","bdf0301d":"code","9780aa98":"code","b27bebad":"code","22c2ab01":"code","4dff57f5":"code","3c1a09e1":"code","e91d0154":"code","2e13809e":"code","8ffeb61b":"code","c8eb89d1":"code","9fc3efd0":"code","5cf2e72b":"markdown"},"source":{"0ad20145":"import numpy\nimport json\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom matplotlib.collections import PatchCollection\nfrom matplotlib.patches import Rectangle\nimport numpy as np\nmap_base_dir = '..\/input\/'\nmap_img_dir = '..\/input\/train\/images\/'","7e0e5327":"json_path = os.path.join(map_base_dir, 'annotation.json')\nwith open(json_path, 'r') as f:\n    annot_data = json.load(f)","51d88ca9":"image_df = pd.DataFrame(annot_data['images'])\nimage_df.sample(3)\nfig, m_axs = plt.subplots(2, 2, figsize = (10, 10))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), image_df.sample(4).iterrows()):\n    img_data = imread(os.path.join(map_img_dir, c_row['file_name']))\n    c_ax.imshow(img_data)","1f88a4b1":"annot_df = pd.DataFrame(annot_data['annotations'])\nannot_df.sample(3)","5cd5db15":"full_df = pd.merge(annot_df, image_df, how='left', left_on = 'image_id', right_on='id').dropna()\nprint(image_df.shape[0], '+', annot_df.shape[0], '->', full_df.shape[0])\nfull_df.sample(2)","59dc8869":"def create_boxes(in_rows):\n    #TODO: this seems to get a few of the boxes wrong so we stick to segmentation polygons instead\n    box_list = []\n    for _, in_row in in_rows.iterrows():\n        # bbox from the coco standard\n        (start_y, start_x, wid_y, wid_x) = in_row['bbox']\n        \n        box_list += [Rectangle((start_x, start_y), \n                         wid_y , wid_x\n                         )]\n    return box_list","afa7f4ad":"fig, m_axs = plt.subplots(2, 2, figsize = (10, 10))\nfor c_ax, (c_id, c_df) in zip(m_axs.flatten(), full_df.groupby('image_id')):\n    img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n    c_ax.imshow(img_data)\n    #c_ax.add_collection(PatchCollection(create_boxes(c_df), alpha = 0.25, facecolor = 'red'))\n    for _, c_row in c_df.iterrows():\n        xy_vec = np.array(c_row['segmentation']).reshape((-1, 2))\n        c_ax.plot(xy_vec[:, 0], xy_vec[:, 1], label = c_df['id_x'])","6af95156":"from matplotlib.path import Path\nfrom skimage.color import label2rgb\ndef rows_to_segmentation(in_img, in_df):\n    xx, yy = np.meshgrid(range(in_img.shape[0]), \n                range(in_img.shape[1]),\n               indexing='ij')\n    out_img = np.zeros(in_img.shape[:2])\n    for _, c_row in in_df.iterrows():\n        xy_vec = np.array(c_row['segmentation']).reshape((-1, 2))\n        c_ax.plot(xy_vec[:, 0], xy_vec[:, 1], label = c_df['id_x'])\n        xy_path = Path(xy_vec)\n        out_img += xy_path.contains_points(np.stack([yy.ravel(), \n                                                     xx.ravel()], -1)).reshape(out_img.shape)\n    return out_img","bdf0301d":"fig, m_axs = plt.subplots(3, 3, figsize = (15, 20))\nfor (c_ax, d_ax, f_ax), (c_id, c_df) in zip(m_axs,\n                                      full_df.groupby('image_id')):\n    img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n    c_ax.imshow(img_data)\n    out_img = rows_to_segmentation(img_data, c_df)\n    rgba_img = np.concatenate([img_data, \n                               np.clip(np.expand_dims(127*out_img+127, -1), 0, 255).astype(np.uint8)\n                              ], -1)\n    d_ax.imshow(rgba_img)\n    \n    f_ax.imshow(label2rgb(image=img_data, label=out_img, bg_label = 0))","9780aa98":"from sklearn.model_selection import train_test_split\ntrain_ids, valid_ids = train_test_split(image_df['id'], test_size = 0.25)\ntrain_df = full_df[full_df['image_id'].isin(train_ids)]\nvalid_df = full_df[full_df['image_id'].isin(valid_ids)]\nprint(train_df.shape[0], 'training boxes')\nprint(valid_df.shape[0], 'validation boxes')","b27bebad":"def batch_img_gen(in_df, batch_size):\n    all_groups = list(in_df.groupby('image_id'))\n    out_img, out_seg = [], []\n    while True:\n        for (_, c_df) in np.random.permutation(all_groups):\n            img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n            out_img += [img_data]\n            out_seg += [np.expand_dims(rows_to_segmentation(img_data, c_df), -1)]\n            if len(out_img)>=batch_size:\n                yield (np.stack(out_img, 0)\/255.0).astype(np.float32), np.stack(out_seg, 0).astype(np.float32)\n                out_img, out_seg = [], []\nvalid_gen = batch_img_gen(valid_df, 8)            ","22c2ab01":"from skimage.util.montage import montage2d\nt_x, t_y = next(valid_gen)\nprint('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\nprint('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\nmontage_rgb = lambda x: np.stack([montage2d(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nax1.imshow(montage_rgb(t_x))\nax2.imshow(montage2d(t_y[:, :, :, 0]), cmap = 'bone_r')","4dff57f5":"BLOCK_COUNT = 1\nEDGE_CROP = 16\nBASE_DEPTH = 16\nSPATIAL_DROPOUT = 0.25\nGAUSSIAN_NOISE = 0.1\nBATCH_SIZE = 24","3c1a09e1":"from keras import models, layers\ndef conv_bn(x, filt, dl_rate=(1,1), preblock = False):\n    y = layers.Convolution2D(filt, (3, 3), \n                             activation='linear', \n                             padding='same', \n                             dilation_rate=dl_rate,\n                            use_bias=False)(x)\n    if preblock: return y\n    y = layers.BatchNormalization()(y)\n    return layers.Activation('elu')(y)\n\nin_layer = layers.Input(t_x.shape[1:], name = 'RGB_Input')\npp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(in_layer)\npp_in_layer = layers.BatchNormalization()(pp_in_layer)\n\nc = conv_bn(pp_in_layer, BASE_DEPTH\/\/2)\nc = conv_bn(c, BASE_DEPTH\/\/2)\nc = conv_bn(c, BASE_DEPTH)\n\nskip_layers = [pp_in_layer]\nfor j in range(BLOCK_COUNT):\n    depth_steps = int(np.log2(t_x.shape[1])-2)\n    d = layers.concatenate(skip_layers+[conv_bn(c, BASE_DEPTH*2**j, (2**i, 2**i), preblock=True) \n                                        for i in range(depth_steps)])\n    d = layers.SpatialDropout2D(SPATIAL_DROPOUT)(d)\n    d = layers.BatchNormalization()(d)\n    d = layers.Activation('elu')(d)\n    # bottleneck\n    d = conv_bn(d, BASE_DEPTH*2**(j+1))\n    skip_layers += [c]\n    c = d\nd = layers.Convolution2D(1, (1, 1), activation='sigmoid', padding='same')(d)\nd = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\nd = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\nseg_model = models.Model(inputs = [in_layer],\n                    outputs = [d])\nseg_model.summary()","e91d0154":"import keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) \/ (union + smooth), axis=0)\ndef dice_p_bce(in_gt, in_pred):\n    return 0.05*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\ndef true_positive_rate(y_true, y_pred):\n    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))\/K.sum(y_true)\nseg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])","2e13809e":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('seg_model')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n                                   patience=3, \n                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_dice_coef\", \n                      mode=\"max\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","8ffeb61b":"valid_gen = batch_img_gen(valid_df, BATCH_SIZE)\nloss_history = [seg_model.fit_generator(batch_img_gen(train_df, BATCH_SIZE), \n                             steps_per_epoch=min(train_ids.shape[0]\/\/BATCH_SIZE, 100),\n                             epochs=2, \n                             validation_data = valid_gen,\n                             validation_steps = min(train_ids.shape[0]\/\/BATCH_SIZE, 50),\n                             callbacks=callbacks_list,\n                            workers=2)]","c8eb89d1":"seg_model.load_weights(weight_path)\nseg_model.save('full_best_model.h5')","9fc3efd0":"t_x, t_y = next(valid_gen)\nif t_x.shape[0]>16:\n    t_x = t_x[:16]\n    t_y = t_y[:16]\n    \nprint('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\nprint('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\npred_y = seg_model.predict(t_x)\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (24, 8))\nmontage_rgb = lambda x: np.stack([montage2d(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nax1.imshow(montage_rgb(t_x))\nax2.imshow(montage2d(t_y[:, :, :, 0]), cmap = 'bone_r')\nax2.set_title('Ground Truth')\nax3.imshow(montage2d(pred_y[:, :, :, 0]), cmap = 'bone_r')\nax3.set_title('Prediction')\nfig.savefig('pred_fig.png', dpi=300)","5cf2e72b":"# Convert Polygons to Segmentations\nWe can use the `Path` function of matplotlib on a `np.meshgrid` of $x,y$ values in order to convert the polygon into a binary image to use as the segmentation."}}