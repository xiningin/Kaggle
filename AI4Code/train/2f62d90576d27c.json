{"cell_type":{"27b6632b":"code","a6d0b41a":"code","491b74e8":"code","cfe120aa":"code","eac3c5b3":"code","f756cb0e":"code","8a57883f":"code","46bfe5ea":"code","3552e595":"code","66527d09":"code","fb0cfb8d":"code","1143df03":"code","3ea1803a":"code","e19b8f67":"code","d9e3c6cf":"code","c54da23a":"code","1e58d8e9":"code","a471aa6b":"code","068808f1":"code","3be9f9fc":"code","5d06bea5":"code","98643e59":"code","5462c53b":"code","69d3c175":"code","5a488f95":"code","b7b3fece":"markdown","60ad21e6":"markdown","74231145":"markdown","e71afbf1":"markdown","0c8a7f09":"markdown","a9a0a41b":"markdown","600c1b4a":"markdown","6961819e":"markdown","ffc6f44e":"markdown","61007a73":"markdown","0e30aeca":"markdown","230bb28b":"markdown","ae02e240":"markdown","1ddae8bd":"markdown","a70d6648":"markdown","56f3c777":"markdown","befbfbb9":"markdown","068fada6":"markdown","ef4cc582":"markdown","aa0b2c43":"markdown"},"source":{"27b6632b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Useful for plotting data\nimport matplotlib.dates as mdates # Matplotlib date format\nimport matplotlib.colors as colors\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","a6d0b41a":"NYSEpath = '\/kaggle\/input\/nyse'\nNYSEfundamentals = NYSEpath+'\/fundamentals.csv'\nNYSEprices = NYSEpath+'\/prices.csv'\nNYSEpricesAdj = NYSEpath+'\/prices-split-adjusted.csv'\nNYSEsecurities = NYSEpath+'\/securities.csv'","491b74e8":"NYSEprice_data = pd.read_csv(NYSEprices)\nNYSEpricesAdj_data = pd.read_csv(NYSEpricesAdj)\nNYSEfundamentals_data = pd.read_csv(NYSEfundamentals)\nNYSEsecurities_data = pd.read_csv(NYSEsecurities)\n","cfe120aa":"print(NYSEprice_data.head())\nprint(NYSEprice_data.describe())\nprint(\"There are \"+str(NYSEprice_data['symbol'].nunique())+\" Unique symbols\/tickers\")\n","eac3c5b3":"def lookup(ticker): #Will provide a tickerlookup from prices\/fundamentals table on which company the abbreviation is, \n    lookup = ticker\n    return NYSEsecurities_data[NYSEsecurities_data['Ticker symbol'] == lookup]\n","f756cb0e":"def singlePriceData(ticker,adjusted):\n    if(adjusted):\n            return NYSEpricesAdj_data[NYSEpricesAdj_data['symbol'] == ticker]\n    return NYSEprice_data[NYSEprice_data['symbol'] == ticker]","8a57883f":"#Single graph shows ALB's closing price, black bar below are all the dates overlapping\n\nSinglePriceData = singlePriceData('ALB',False)\nplt.plot('date', 'close', data=SinglePriceData)\nplt.show()\n\n","46bfe5ea":"\ndef GraphedData(ticker, adjusted = False): #Will plot a graph based on all data present on the provided ticker, Needs to be updated to a date range.\n    fig, ax = plt.subplots(nrows = 2, ncols = 2,figsize=(15,8))\n    LocalData = singlePriceData(ticker,adjusted)\n    \n    #Assign Data to graphs\n    ax[0][0].plot(LocalData['date'],LocalData['low'])\n    ax[0][1].plot(LocalData['date'],LocalData['high'])\n    ax[1][0].plot(LocalData['date'],LocalData['close'])\n    ax[1][1].plot(LocalData['date'],LocalData['volume'])\n    fmt_half_year = mdates.MonthLocator(interval=6)\n\n    #Add titles\n    plt.suptitle(lookup(ticker)['Security'].values[0])\n    ax[0][0].title.set_text('low')\n    ax[0][1].title.set_text('high')\n    ax[1][0].title.set_text('close')\n    ax[1][1].title.set_text('volume')\n    #Set tickers to appropriate scale\n    ax[0][0].xaxis.set_major_locator(fmt_half_year)\n    ax[0][1].xaxis.set_major_locator(fmt_half_year)\n    ax[1][0].xaxis.set_major_locator(fmt_half_year)\n    ax[1][1].xaxis.set_major_locator(fmt_half_year)\n    #Format Text\n    ax[0][0].tick_params(labelrotation=45)\n    ax[0][1].tick_params(labelrotation=45)\n    ax[1][0].tick_params(labelrotation=45)\n    ax[1][1].tick_params(labelrotation=45)\n    fig.tight_layout()\n    plt.show()","3552e595":"pip install pyportfolioopt","66527d09":"#Tutorial followed from https:\/\/www.youtube.com\/watch?v=bvDkel5whUY\n\nfrom pypfopt.efficient_frontier import EfficientFrontier\nfrom pypfopt import risk_models\nfrom pypfopt import expected_returns\n\n","fb0cfb8d":"#Caculate expected annualized returns and annualized sample covariance matrix\n#Covariance is very similar to correlation, essentially how much the variables differ together\n\nExpectedReturnDF = NYSEprice_data.drop(columns=['open','low','high','volume'])\nExpectedReturnDF = ExpectedReturnDF.pivot_table(index=pd.to_datetime(ExpectedReturnDF['date']),columns=['symbol'], values='close')\n\n\nmu = expected_returns.mean_historical_return(ExpectedReturnDF) # The mean\nS = risk_models.sample_cov(ExpectedReturnDF) # Covariance of every stock","1143df03":"S.head()\n","3ea1803a":"S.describe()","e19b8f67":"Min = S.describe().loc['min'].min()\nMax = S.describe().loc['max'].max()","d9e3c6cf":"arr = S.values.copy()\narr.resize(5, 5)\nCovarTest = pd.DataFrame(arr.T)\n\nplt.pcolormesh(CovarTest,vmin=-0.09, vmax=0.09)\nplt.colorbar(label='covariance')\nplt.show()\n\n","c54da23a":"mu.head()","1e58d8e9":"GraphedData('AAPL')","a471aa6b":"GraphedData('AAPL', adjusted = True)","068808f1":"#Caculate expected annualized returns and annualized sample covariance matrix\n#Covariance is very similar to correlation, essentially how much the variables differ together\n\nExpectedReturnDF = NYSEpricesAdj_data.drop(columns=['open','low','high','volume'])\nExpectedReturnDF = ExpectedReturnDF.pivot_table(index=pd.to_datetime(ExpectedReturnDF['date']),columns=['symbol'], values='close')\n\n\nmu = expected_returns.mean_historical_return(ExpectedReturnDF) # The mean\nS = risk_models.sample_cov(ExpectedReturnDF) # Covariance of every stock","3be9f9fc":"mu.head()","5d06bea5":"#This code will sometimes crash, ns why but im guessing it is partially randomized?\nef = EfficientFrontier(mu,S)\nweights = ef.max_sharpe()\ncleaned_weights = ef.clean_weights()\nef.portfolio_performance(verbose = True)","98643e59":"!pip install cvxopt\n!pip install cvxpy\n!pip install mip\n!pip install pulp","5462c53b":"from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n\nlatest_prices = get_latest_prices(ExpectedReturnDF)\nda = DiscreteAllocation(weights, latest_prices, total_portfolio_value=20000)\nallocation, leftover = da.greedy_portfolio() \n\nprint(\"Discrete Allocation: \", allocation)\nprint(\"Leftover: $\", leftover)\n","69d3c175":"portfolio = pd.DataFrame(columns = [\"Ticker\",\"Company name\", \"Discrete Value\"])\n\nfor key, value in allocation.items():\n    Item = lookup(key)['Security'].values[0]\n    portfolio = portfolio.append(pd.Series({\"Ticker\":key,\"Company name\":Item,\"Discrete Value\":value}),ignore_index=True)","5a488f95":"portfolio","b7b3fece":"Making changes to the original functions to add an \"adjusted\" parameter allows us to more closely represent the data we want to see, and viewing the same value once again (this time with adjusted split prices instead) shows:","60ad21e6":"This part of the code is allocating the \"percentile\" portions of each portfolio part to a stock. This may be simple enough, if we have 0.19 weight in APPL then just spend *0.19 * amount_in_portfolio* on APPL. \n\nThis produces a problem though, as stocks have discrete prices, APPL stock may be \u00a3100, but we want 50% APPl but only have \u00a3140 in our account.\n\nThis is why we want to introduce an [algorithm](https:\/\/pyportfolioopt.readthedocs.io\/en\/latest\/Postprocessing.html#post-processing) that can assign values to these weights that make sense.\n\n**Greedy algorithm** is the function we are using, it just just processes through the weights in two rounds and assigns them to their best suited value until it doesnt fit. We then calculate the value in the second round for the values we havent fit by seeing how far the current weight deviates to existing weight. \n\nA technique called **Integer Programming** is better suited, but currently i cant seem to get it to work in this enviroment as it throws errors about solvers not being installed.","74231145":"## AAPL (Apple Inc), with sharp decline in price?\n\nThis decline has an explanation. Within the data we are given, we have two historical price csv's. One for prices, and another for something called **prices-split adjusted**. This huge drop in price could be the data providing us with unadjusted prices.\n\n### But what are adjusted prices? Why do the stock prices drop so rapidly?\n\nCompanies, collectives and corporations have a selection of tools when it comes to their stocks and equity of a company you own. A publicly traded company (one available on NYSE or any other index) can do a select set of actions with their equities called \"[Corporate actions](https:\/\/www.investopedia.com\/terms\/c\/corporateaction.asp)\". These can be a range of complex manuvers decided by the executive board to:\n\n* **Start a merger\/aquisition** - Where we synergize two companies into one, or collectively purchase a companies equity outright.\n* **Spin-off** - Where a public company tries to sell shares\/part of its assets to start a new company\n* **Stock Split** - Where the number of stocks available is increased by a multiple, and decreased by an appropriating divisible. An example is if your company has 100 shares each at \u00a3100, you would split it to have 200 shares now each at \u00a350. This means the \"price\" of one stock drops but the value of the company isnt lost. Why would you do this? Well to increase liqudity in your stocks and to manually decrease stock price to a comfortable level.\n* ***Alongside these three, there are other actions but splits are all we needed to focus on***\n\nSo with this information, a quick google search to APPL stock prices in 2014 shows apple went through a **7:1 stock split** in 2014, meaning the price was decreased, and the amount of stocks available multiplied, by a factor of 7.","e71afbf1":"The above calculation shows the annual return for holding these weights, the volatility each year and the sharpe ratio. The Sharpe ration is a measurement of risk to return of a portfolio,\nAny unit of return and voilatilaty can be used, but in this case it is the Annual return and volatility shown.\n\nThis gives us (in the example i have right now) 2.07, but it may vary. This sharpe ration can be used to rank portfolios and find the **best portfolio**. \"You get more reward per volatility with a higher sharpe ratio\". ","0c8a7f09":"What does the relationship between these stocks look like? Can we spot any patterns? ","a9a0a41b":"We can use the data we have collected, the MU and covariance matrix and calculate the best allocation of funds to given derivatives. The calculation below plots out our estimated returns and risk and provides us with a few metrics.\n","600c1b4a":"We then take the mean value and append it into a pandas series as shown below:","6961819e":"So, With 20,000 Our portfolio would include these selection of stocks. The discrete amount is the amount of stocks we would want to own in each of these companies.\n\n## What's next?\n* Developing a form of hft (high frequency trader) for stocks like these would be a cool goal, something that utilizes live data from a broker to make decisions on a minute by minute scale maybe. I could focus on optimization and speed as well as the efficiency of indicators.\n* A self updating portfolio that doesnt crash as much as this one.\n* Integrating a semantical analysis of [news](https:\/\/newsapi.org\/)\/twitter\/[Reddit stocks](https:\/\/www.reddit.com\/r\/investing\/comments\/l3z5jq\/i_created_an_algo_that_tracks_the_most_hyped\/)\/[Other sources ](http:\/\/www.alternative-analytics.eu\/dashboard\/sentiment.html) to be taken into account when deciding which stocks to keep and which to dump","ffc6f44e":"# Portfolio optimization\n3 parts of the library are imported\n* [Efficient frontier](https:\/\/www.investopedia.com\/terms\/e\/efficientfrontier.asp) - Efficient frontiers rank portfolios based on their level of risk (xaxis) and return (yaxis). Normally this is compound annual growth rate (return) and the standard deviation (risk). We want a portfolio that has a good balance between what it can give us and how much it can actually lose!\n* Risk models - utilized to quantify this level of risk to a tangable figure. **Sometimes a good portfolio, is one where the securities arent related (have no covariance) so that if a crash occurs the entire portfolio isnt garbage lmao, essentially we dont put all our eggs (money) into one basket (tech companies).** This is what risk models do, calculate either the standard deviation\/covariance of stocks much like the heatmap below. This can be unrealistic though as we only have historical data when we use this. Some better examples are with semicovariance and [Exponential Covariance](https:\/\/reasonabledeviations.com\/2018\/08\/15\/exponential-covariance\/) but this part of portfolio optimization is highly researched and skeptically driven. No real room for customization.\n* Expected returns - Estimating how much money you can obtain from an investment is difficult. The problem with using historical data is the simple fact that you cannot 100% predict the future when it comes to securities. The main flaw with this feature is using the tools **correctly** and with **good inputs** for the best result. Expect no magic from this stage as it is purely for the **mean variance anaylsis stage**","61007a73":"\n* The image below shows the Expected frontier and the depiction of what an \"efficient\" portfolio would be. You would want your portfolio to land within the hyperbola (also called the Markowitz bullet). to ensure that it is the only portfolio where **\"no other portfolio exists with a higher expected return but with the same standard deviation of return\"**. The capital market line is the theoretical optimal portfolio combination of risk and return.\n\n<img src=\"https:\/\/static.seekingalpha.com\/uploads\/2017\/1\/24\/48093558-14852776561251774_origin.png\" alt=\"drawing\" width=\"400\"\/>\n\n\n","0e30aeca":"\nA cleaner view. Using the adjusted values can help us see the price of the overall company, rather than the equivalent shares as we take into account each and every split. It is more representative of companies that are able to perform. This means in analysis the adjusted price is recommended, but the price data is also useful.\n","230bb28b":"# Preperation and useful functions\n\nThe below portion of the code is dedicated to helper functions that will make my life alot easier later if i just implement methods to plot graphs, lookup meta data about a ticker and the price (non-adjusted) of a security.","ae02e240":"We can see below the two variables we have just made,\n* [the covariance matrix](https:\/\/www.investopedia.com\/terms\/c\/correlationcoefficient.asp) (S) shown below is the measurement of how the variables move together and their relationship from historical data. A positive number means as one increases the other will also increase, a negative number means they do not move together as such. This isnt a measurement of the **strength of correlation though**, but can be used to calculate that.\n","1ddae8bd":"This is an example heatmap of some popular stock options, we want low variance and covariance.\n\n<img src=\"https:\/\/pyportfolioopt.readthedocs.io\/en\/latest\/_images\/corrplot.png\" alt=\"drawing\" width=\"400\"\/>","a70d6648":"Much better, With this adjustment to the figures, we can finally take a stab at predicting what combination of tickers would make the best suited portfolio. \n### How do we know what a good portfolio is though?","56f3c777":"![](https:\/\/cdn.corporatefinanceinstitute.com\/assets\/rate-of-return2.png)\n\n![](https:\/\/g.foolcdn.com\/image\/?url=https%3A\/\/g.foolcdn.com\/editorial\/images\/195710\/daily2.png&w=2000&op=resize)","befbfbb9":"Well i can't right now but Im not supposed todo it by hand, besides this is only including 5 unlabeled stocks, whereas the NYSE has 500 available options","068fada6":"**Now we install pyportopt, a portfolio optimization library that is useful for analysing expected returns and analysing the risk of investment**","ef4cc582":"### We can see that on average, AAPL had a negative Annual return, Lets use the Graph method we made to inspect it.","aa0b2c43":"* The Mean (mu) is the mean historical return, from \"[Calculating annualised mean (daily) historical return from input (daily) asset prices](https:\/\/pyportfolioopt.readthedocs.io\/en\/latest\/ExpectedReturns.html)\". The formula for the return is:"}}