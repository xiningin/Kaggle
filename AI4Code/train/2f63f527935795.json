{"cell_type":{"1765c32e":"code","bd581731":"code","6902478c":"code","d01bf36c":"code","048cc15d":"code","919d7473":"code","8c0ed912":"code","fe80add3":"code","b698522b":"code","2ccb8be8":"code","51774caf":"code","d46d18fe":"code","9fe0a5da":"code","60b481e1":"code","dd550d67":"code","528b0df9":"code","d2ce138c":"code","2b6cc559":"code","978b4b2a":"code","6a74a9e6":"code","677e80ca":"code","3c0b3ae2":"code","e7ed770c":"code","03ed61f7":"code","4c2ee45c":"code","3f2ec762":"code","d3a6ba85":"code","8bc5853e":"code","d0d04c54":"code","d8f92e2f":"code","7e9bda36":"code","80c14e5d":"code","2cef60a8":"code","07e1d4ce":"code","3c8e1a0c":"code","d66c284d":"code","80d8120d":"code","5298c4c1":"code","961e8aaa":"code","b7fc6d2d":"code","c5e5a371":"code","f8e83e2d":"code","4f4733ee":"code","15b7d051":"code","cb45b27f":"code","093c8062":"code","e1f165e5":"code","c914b8d7":"code","4bbe1101":"code","4a11ecc0":"code","abc2e034":"code","3d8636da":"code","f43c4450":"code","29eea31a":"code","844d7eff":"code","84d85253":"code","2e5cbc56":"code","985400ea":"code","fc21a39b":"code","edad1f6d":"code","bf70b30d":"code","c560bcde":"code","1d11605f":"code","4d37aa53":"code","116e7cb0":"code","29b24276":"code","f8586b72":"code","c2d88419":"markdown","d62d0e7c":"markdown","c27ebe87":"markdown","d9de16cf":"markdown","3b052430":"markdown","71bfce8d":"markdown","9efc1091":"markdown","e81f4338":"markdown"},"source":{"1765c32e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","bd581731":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\n\npd.set_option('display.max_rows',500)\npd.set_option('display.max_columns',500)\ntrain_data.head(50)","6902478c":"#train_data.loc[train_data['Name'].str.contains('Oscar', na=False)]\ntrain_data.loc[train_data['Ticket']=='347077']\n","d01bf36c":"train_data.loc[train_data['Ticket']=='349909']","048cc15d":"print(train_data.shape)\nprint(train_data.info())\ntrain_data.describe()","919d7473":"def cat_var(data):\n    return list(data.select_dtypes(include = ['object']).columns)\n    \n\ndef num_var(data):\n    return list(data.select_dtypes(include = ['int64','float']).columns)\n\n\ndef var_transPclass(data):\n    data['Pclass'] = data['Pclass'].astype('object')\n    return data\n\nvar_trans = []\ntrain_data = var_transPclass(train_data)\nvar_trans = var_trans + ['Pclass']\n\nfeat_cat = cat_var(train_data)\nfeat_num = num_var(train_data)\nfeat_num.remove('Survived')\nfeat_num.remove('PassengerId')\nprint(feat_cat)\nprint(feat_num)\n","8c0ed912":"train_data[feat_num + ['Survived']].groupby(['Survived']).agg(['mean'])","fe80add3":"sns.pairplot(train_data[feat_num +['Survived']], hue = 'Survived')","b698522b":"sns.heatmap(train_data[feat_num].corr())","2ccb8be8":"train_data[feat_num].corr().Fare.sort_values(ascending = False)","51774caf":"\nfor col in train_data[feat_cat].columns:\n    sns.histplot(data = train_data[[col,'Survived']].loc[train_data[col].isnull() == False],x = col,hue = 'Survived',multiple = 'stack')\n    plt.title(col + ' Survived')\n    plt.figure()\n","d46d18fe":"train_data[feat_num + ['Survived']].groupby(['Survived']).agg(['mean'])","9fe0a5da":"train_data[feat_num + ['Survived','Sex']].groupby(['Survived','Sex']).agg(['mean'])","60b481e1":"def missing(data):\n    missing = data.isnull().sum().sort_values(ascending = False)\n    percent = data.isnull().sum() \/ data.isnull().count().sort_values(ascending = False)\n    missing_data = pd.concat([missing,percent], axis = 1, keys = ['Missing', 'Percentage'])\n    return missing_data.head()\n\nmissing(train_data)","dd550d67":"train_data.loc[train_data['Embarked'].isnull() == True]","528b0df9":"sns.histplot(data = train_data.loc[(train_data['Pclass'] == 1) \n                                   & (train_data['Sex'] == 'female') \n                                   & (train_data['Embarked'].isnull() == False)\n                                   & (train_data['Fare'] >= 80)\n                                   &  (train_data['Survived'] == 1)],x = 'Embarked')\n","d2ce138c":"train_data = train_data.drop(train_data.loc[train_data['PassengerId'].isin([62,830])].index)","2b6cc559":"sns.regplot(data = train_data.loc[train_data['Age']!= 0], x = 'SibSp', y = 'Age')\nx = np.array(train_data['SibSp'].loc[train_data['Age'].isnull() == False])\ny = np.array(train_data['Age'].loc[train_data['Age'].isnull() == False])\n\nm,b = np.polyfit(x,y,1)\n\nm,b","978b4b2a":"x = train_data['SibSp'].loc[train_data['Age'].isnull() == True]\ntrain_data['Age'].loc[train_data['Age'].isnull() == True] = m*x + b\n","6a74a9e6":"def var_transCabin(data):\n    data['Cabin'] = data['Cabin'].str[0]\n    data.loc[data['Cabin'].isnull() == True,'Cabin'] = 'No Cabin'\n    return data\n\ntrain_data = var_transCabin(train_data)\nvar_trans = var_trans + ['Cabin']","677e80ca":"sns.histplot(data = train_data.loc[train_data['Cabin'] != 'No Cabin'].sort_values(by='Cabin'),x = 'Cabin',hue = 'Survived',multiple = 'stack')\nplt.title('Cabin Survived')\nplt.figure()\nsns.histplot(data = train_data.loc[train_data['Cabin']  == 'No Cabin'],x = 'Cabin',hue = 'Survived',multiple = 'stack')\nplt.title('Cabin Survived')\nplt.figure()\n\ntrain_data[['Cabin','Survived']].groupby(['Cabin']).agg([lambda x: x.sum(),lambda x: x.count(), lambda x: x.sum() \/ x.count() * 100])","3c0b3ae2":"missing(train_data)","e7ed770c":"def var_transAddVar(data):\n    data['SibSpFlag'] = (data['SibSp'] != 0).astype('str')\n    data['ParchFlag'] =  (data['Parch'] != 0).astype('str')\n    data['SibSpParchFlag'] = data[['SibSpFlag','ParchFlag']].max(axis=1)\n    data['SibSpParch'] = data[['SibSp','Parch']].sum(axis=1)\n    data['Title'] = data['Name'].apply(lambda x: x.split(', ')[1].split('.')[0])\n    data['IndividualFare'] = (data['Fare']+1) \/ (data['SibSpParch']+1)\n    return data\n\ntrain_data = var_transAddVar(train_data)\nvar_trans = var_trans + ['AddVar']\n\nfeat_cat = feat_cat + ['SibSpFlag','ParchFlag','SibSpParchFlag','Title']\nfeat_cat.remove('Name')\nfeat_cat.remove('Ticket')\nfeat_num = feat_num + ['SibSpParch', 'IndividualFare']\nprint(feat_cat)\nprint(feat_num)","03ed61f7":"for col in train_data[feat_cat]:\n    sns.histplot(data = train_data,x = col,hue = 'Survived',multiple = 'stack')\n    plt.title(col +' Survived')\n    plt.figure()","4c2ee45c":"sns.histplot(data = train_data.sort_values(by = 'Cabin').loc[train_data['Cabin'] != 'No Cabin'],x = 'Cabin',hue = 'Survived',multiple = 'stack')\nplt.title('Cabin Survived')\nplt.figure()","3f2ec762":"def var_transCabin_Grouped(data):\n    data['Cabin_Grouped'] = 'No Cabin'\n    data.loc[data['Cabin'] !='No Cabin','Cabin_Grouped'] = 'Cabin'\n    return data\n\ntrain_data = var_transCabin_Grouped(train_data)\nvar_trans = var_trans + ['Cabin_Grouped']\n\nfeat_cat = feat_cat + ['Cabin_Grouped']\ntrain_data.head(5)\n\nsns.histplot(data = train_data,x = 'Cabin_Grouped',hue = 'Survived',multiple = 'stack')\nplt.title('Cabin_Grouped Survived')","d3a6ba85":"def var_transTitle(data):\n    data.loc[data['Title'].isin(set(data['Title']) - {'Mr','Mrs','Miss','Master'}),'Title'] = 'Other'\n    return data\n\ntrain_data = var_transTitle(train_data)\nvar_trans = var_trans + ['Title']\n\nsns.histplot(data = train_data,x = 'Title',hue = 'Survived',multiple = 'stack')\nplt.title('Title Survived')\nplt.figure()","8bc5853e":"#train_data = train_data.drop(columns= ['ParentChild'])\n\ndef var_transParentChild(data):\n    data.loc[data['Parch'] == 0,'ParentChild'] = 'No Parent\/Child'\n    data.loc[(data['ParentChild'].isnull() == True) & (data['Title'] == 'Mr'),'ParentChild'] = 'Father'\n    data.loc[(data['ParentChild'].isnull() == True) & (data['Title'] == 'Mrs'),'ParentChild'] = 'Mother'\n    data.loc[(data['ParentChild'].isnull() == True) & (data['Title'] == 'Miss'),'ParentChild'] = 'Daughter'\n    data.loc[(data['ParentChild'].isnull() == True) & (data['Title'] == 'Master'),'ParentChild'] = 'Son'\n    data.loc[(data['ParentChild'].isnull() == True) & (data['Sex'] == 'male'),'ParentChild'] = 'Father'\n    data.loc[(data['ParentChild'].isnull() == True) & (data['Sex'] == 'female'),'ParentChild'] = 'Mother'\n    return data\n\ntrain_data = var_transParentChild(train_data)\nvar_trans = var_trans + ['ParentChild']\n\nsns.histplot(data = train_data,x = 'ParentChild',hue = 'Survived',multiple = 'stack')\nplt.title('ParentChild Survived')","d0d04c54":"feat_cat = feat_cat + ['ParentChild']","d8f92e2f":"sns.pairplot(train_data[feat_num+['Survived']], hue = 'Survived')","7e9bda36":"sns.displot(train_data['Fare'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['Fare'], plot = plt)\n\nsns.displot(train_data['IndividualFare'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['IndividualFare'], plot = plt)","80c14e5d":"train_data.sort_values(by='IndividualFare',ascending = False).head(10)","2cef60a8":"train_data = train_data.drop(train_data.loc[train_data['PassengerId'].isin([259,738,680])].index)\n#train_data = train_data.drop(train_data.loc[train_data['Fare']==0].index)","07e1d4ce":"def var_transFareLog(data):\n    data['FareLog'] = np.log(data['Fare']+1)\n    data['IndividualFareLog'] = np.log(data['IndividualFare'])\n    return data\n\ntrain_data = var_transFareLog(train_data)\nvar_trans = var_trans + ['FareLog']\n\nsns.displot(train_data['FareLog'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['FareLog'], plot = plt)\nsns.displot(train_data['IndividualFareLog'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['IndividualFareLog'], plot = plt)","3c8e1a0c":"sns.displot(train_data['Age'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['Age'], plot = plt)","d66c284d":"sns.displot(train_data['SibSp'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['SibSp'], plot = plt)","80d8120d":"train_data['SibSpLog'] = np.log(train_data['SibSp']+1)\nsns.displot(train_data['SibSpLog'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['SibSpLog'], plot = plt)","5298c4c1":"sns.displot(train_data['Parch'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['Parch'], plot = plt)","961e8aaa":"train_data['ParchLog'] = np.log(train_data['Parch']+1)\nsns.displot(train_data['ParchLog'], kde = True)\nfig = plt.figure()\nres = stats.probplot(train_data['ParchLog'], plot = plt)","b7fc6d2d":"feat_num = feat_num + ['FareLog', 'IndividualFareLog']\n\nprint(feat_cat)\nprint(feat_num)","c5e5a371":"train_data[(feat_num + ['Survived'])].groupby(['Survived']).describe()","f8e83e2d":"for col in train_data[feat_cat]:\n    sns.histplot(data = train_data,x = col,hue = 'Survived',multiple = 'stack')\n    plt.title(col +' Survived')\n    plt.figure()","4f4733ee":"feat_num.remove('SibSp')\nfeat_num.remove('Parch')\n#feat_num.remove('SibSpParch')\nfeat_num.remove('Fare')\nfeat_num.remove('IndividualFare')\n#feat_cat.remove('Cabin')\n#feat_cat.remove('ParentChild')\n#feat_cat.remove('SibSpParchFlag')\n#feat_cat.remove('Title')\n#feat_cat.remove('Embarked')\n#feat_cat.remove('Pclass')\n\nprint(feat_num)\nprint(feat_cat)","15b7d051":"feat_num = ['Age', 'FareLog', 'IndividualFareLog']\nfeat_cat = ['Pclass', 'Sex', 'Embarked', 'SibSpFlag', 'ParchFlag', 'Title', 'Cabin_Grouped']\n\n","cb45b27f":"feature = train_data[feat_num].join(\n    pd.get_dummies(train_data[feat_cat]))\ny = train_data['Survived']","093c8062":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nx_scaled = feature.copy()\nx_scaled[feat_num] = scale.fit_transform(feature[feat_num])\nx_scaled.head()","e1f165e5":"from sklearn.model_selection import train_test_split\n\nxtrain,xtest,ytrain,ytest = train_test_split(x_scaled,y,test_size = 0.3,random_state = 50)","c914b8d7":"# Number of Trees in Random Forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 150, num = 10)]\n# Number of Features to Consider at every split\nmax_features = ['auto', 'sqrt']\n# Number of levels in tree\nmax_depth = [2,4]\n# Minimum number of sample required to split a node\nmin_sample_split = [2,5]\n# Minimum number of sample required at each node\nmin_sample_leaf = [1,2]\n# Method of selecting samples for training each tree\nbootstrap = [True,False]\n","4bbe1101":"param_grid =  {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_sample_split,\n               'min_samples_leaf': min_sample_leaf,\n               'bootstrap': bootstrap}\nprint(param_grid)","4a11ecc0":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nrf = RandomForestClassifier()\nrf_grid = GridSearchCV (estimator = rf, param_grid = param_grid, cv = 3, verbose = 2, n_jobs = 4)\nrf_grid.fit(xtrain,ytrain)","abc2e034":"rf_grid.best_params_","3d8636da":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nypred = rf_grid.predict(xtest)\n\ncv = cross_val_score(rf,xtrain,ytrain,cv=10)\nprint(cv, cv.mean())\nprint(confusion_matrix(ytest,ypred))\nprint(classification_report(ytest,ypred))\nprint(accuracy_score(ytest,ypred))","f43c4450":"rf_grid.fit(x_scaled,y)","29eea31a":"rf_grid.best_params_","844d7eff":"test_data = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_data.head()","84d85253":"test_data.info()","2e5cbc56":"missing(test_data)","985400ea":"test_data.loc[test_data['Fare'].isnull() ==True,'Fare'] = test_data.loc[(test_data['Pclass'] == 3) & (test_data['Fare'].isnull() ==False),'Fare'].mean()","fc21a39b":"sns.regplot(data = test_data.loc[test_data['Age']!= 0], x = 'Pclass', y = 'Age')\nx = np.array(test_data['Pclass'].loc[test_data['Age'].isnull() == False])\ny = np.array(test_data['Age'].loc[test_data['Age'].isnull() == False])\n\nm,b = np.polyfit(x,y,1)\n\nm,b\nx = test_data['Pclass'].loc[test_data['Age'].isnull() == True]\ntest_data['Age'].loc[test_data['Age'].isnull() == True] = m*x + b","edad1f6d":"missing(test_data)","bf70b30d":"var_trans","c560bcde":"test_data = var_transPclass(test_data)\ntest_data = var_transCabin(test_data)\ntest_data = var_transAddVar(test_data)\ntest_data = var_transCabin_Grouped(test_data)\ntest_data = var_transTitle(test_data)\ntest_data = var_transParentChild(test_data)\ntest_data = var_transFareLog(test_data)","1d11605f":"test_feature = test_data[feat_num].join(pd.get_dummies(test_data[feat_cat]))\n\ntest_feature.head(50)","4d37aa53":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nx_scaled_test = test_feature.copy()\nx_scaled_test[feat_num] = scale.fit_transform(test_feature[feat_num])\nx_scaled_test.head()","116e7cb0":"print(set(x_scaled.columns) - set(x_scaled_test.columns))\nprint(set(x_scaled_test.columns)-set(x_scaled.columns))","29b24276":"ypred = rf_grid.predict(x_scaled_test)\n\ntest_data['Survived'] = ypred","f8586b72":"submission = test_data[['PassengerId','Survived']]\nsubmission.to_csv('submission.csv', index = False)","c2d88419":"# Refine Variables\n1. SibSpFlag: If SibSp is 1 or more\n2. ParchFlag: If Parch is 1 or more\n3. SibSpParchFlag:If SibSp or Parch is 1 or more\n4. SibSpParch: Sum of SibSp and Parch\n5. Title: Name has title that can be used, grouped for simplification\n6. Cabin: Use first letter\n7. Cabain_Grouped: Has cabin or not\n8. ParentChild: Determine whether the passenger is Parent, Child or Other\n9. IndividualFare: Fare per individual averaged","d62d0e7c":"# Intial Discovery","c27ebe87":"# Titanic Disaster Machine Learning Project\n\nA bit Morbid, but the focus of this notebook is to predict which passengers survived the Titanic shipwreck. Random forest classifier will be used in this project to predict which passengers survived and which did not.\n\n(Highest Score achieved was 78.7% which is in the top 5% of the Leaderboard)","d9de16cf":"# Initial Thoughts\n\n**Pclass (int64)**: Seems to be some correlation there as majority of 3rd class did not survive and majority of 1st class did. **Feature**<br>\n**Name (object)**: Needs to be refined, Title might be worth investigating. **Transformation Required**<br>\n**Sex (object)**: High correlation with female having much higher survival rate. **Feature** <br>\n**Age (float64)**: Slight correlation with SibSp. Nothing stands out, **further investigation required** <br>\n**SibSp (int64)**: Slight Correlation with Age and Parch <br>\n**Parch (int64)**: Would be more useful to break this down to determine **which passenger was parent and which was child**, will refine this variable along with age to make better use of both. <br>\n**Ticket (object)**: Families tend to have same ticket number and there would be quite abit of investigation we can do here. 1. Survival per Family Size 2. Survival correlation within the family<br>\n**Fare (float64)**: Correlated with Pclass, unsure if this will add additional insight, Fare seems to be per family, would be worth awhile to convert this to individual fare price for further analysis. **Transformation Required** <br>\n**Cabin (object)**: Can be group using the first letter, **Transformation Required** <br>\n**Embarked (object)**: Passengers Embarked from S seems to have the lowest survival rate, I want to compare this variable with Pclass and see if there is correlation there. <br>\n\n\n# Extreme Hypothesis\n**Who has the highest chance of survival?**\n1st Class Female around her 30s with Sibling\/Spouse and Parent\/Child who has paid high Fare and has a Cabin, who has embarked from C\n\n**Who has the lowest chance of survival?**\n3rd Class Male around 30s with no Sibling\/Spouse and Parent\/Child who has paid low Fare and does not have a Cabin, who has embarked from S","3b052430":"# Time to use final test data","71bfce8d":"# Remove Outlier \/ Feature Engineering\nFare seems to have signifidcantly higher end in scale","9efc1091":"# Apply Random Forest Classifier","e81f4338":"# Missing Data\n**Embarked**: 2 passengers missing embarked, remove\n\n**Cabin**: Convert to initial letter for simpler classification, no cabin might potentially add insight also.\n        However, results might overfit the data.\n\n**Age**: ~20% without Age, slight correlation with Pclass and Parch"}}