{"cell_type":{"fd7bbd00":"code","198cba77":"code","c8e8bc16":"code","9113372f":"code","5e7a0299":"code","3ca9a329":"code","631f50b5":"code","235e1f04":"code","cf2e0857":"code","ad62dc25":"code","e6f8d4ba":"code","b9d981c0":"code","410e6beb":"code","1961d633":"code","168629f4":"code","23603f98":"code","ce3a7fbb":"code","72258900":"code","9e9af569":"code","59dd7a16":"code","25c5813d":"code","adb444c2":"code","9b7ff281":"code","d88ebba9":"code","26bfcbaf":"code","f82353c2":"code","e2d4d837":"code","f6cde45b":"code","01d47f84":"code","51b8cddb":"code","91207d88":"code","40adde29":"code","3bca5ed7":"code","5ef56b5b":"code","a574e029":"code","552555ae":"code","c2626fe1":"code","cb00c55c":"code","621540c3":"code","c20beef2":"code","5975c4c4":"code","4b9c3317":"code","f8e0a485":"code","7a78560f":"code","04282578":"markdown","6ca5b465":"markdown","43875c3f":"markdown","4f7148c3":"markdown","ee405e4f":"markdown","f223e1d1":"markdown","ffdc714c":"markdown","d5a22d83":"markdown","da73e76e":"markdown","18268b82":"markdown","b70cebee":"markdown","208be1bd":"markdown","8a7f6c8c":"markdown","1dcf7f0d":"markdown","7520301c":"markdown","389ccad2":"markdown","92dc6d15":"markdown","1fc5cec8":"markdown","ae4df98b":"markdown","3a05f8c9":"markdown","456c16f6":"markdown","0c1cfa19":"markdown","5b06d149":"markdown","8a224a83":"markdown","4d2da3cd":"markdown","2f0732e2":"markdown","e5643737":"markdown","2317db29":"markdown","265fd589":"markdown","0c662fbb":"markdown","285ebfb4":"markdown","e17d15ad":"markdown","7f253626":"markdown","e2f23b3b":"markdown"},"source":{"fd7bbd00":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import StratifiedKFold, cross_validate\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom hyperopt import hp, tpe, Trials, fmin, STATUS_OK, space_eval","198cba77":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain.head()","c8e8bc16":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.head()","9113372f":"submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","5e7a0299":"# check shape of the dataset\nprint('train shape:', train.shape)\nprint('test shape:', test.shape)","3ca9a329":"# total null values\nprint('---- train null ----\\n', train.isnull().sum())\nprint('\\n---- test null ----\\n', test.isnull().sum())","631f50b5":"# set seaborn style\nsns.set_palette('rainbow')\nsns.set_style('darkgrid')","235e1f04":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\ntrain['Survived'].value_counts().plot.pie(autopct='%1.1f%%', labels=['Dead', 'Survived'], ax=ax1)\nax1.set_title('Survived ratio', fontsize=16, y=1.05)\nax1.set_ylabel('')\n\nsns.heatmap(train.drop(['PassengerId'], axis=1).corr(), annot=True, fmt='.2f', cmap='rainbow', ax=ax2)\nax2.set_title('Feature correlation matrix', fontsize=16, y=1.05)\n\nplt.show()","cf2e0857":"fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\ntrain['Sex'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax1)\nax1.set_title('Sex ratio', fontsize=16, y=1.05)\nax1.set_ylabel('')\n\nsns.barplot(x='Sex', y='Survived', hue='Sex', data=train, ax=ax2)\nax2.set_title('Survival rate by Sex', fontsize=16, y=1.05)\nplt.show()","ad62dc25":"fig, ax = plt.subplots(1, 1, figsize=(8, 4))\nfig.suptitle('Age distribution by sex', fontsize=16, y=1.02)\n\nmale_age = train[train['Sex'] == 'male']['Age'].dropna()\nfemale_age = train[train['Sex'] == 'female']['Age'].dropna()\n\nax.hist([male_age, female_age], label=['male', 'female'], bins=16, stacked=True)\nax.set_xlabel('age')\nax.set_ylabel('count')\nax.legend()\n\nplt.show()","e6f8d4ba":"# create bins every 5\nbins = list(range(0, 66, 5))\n\n# category of age band for label\nage_cat = [str(age) + '-' + str(age+5) for age in bins[:-1]]\n\n# all sex\ncut, bins = pd.cut(train['Age'], bins, retbins=True)\ngroupby_all = train.groupby(cut)\nsurv_rate_a = groupby_all.sum()['Survived'].dropna() \/ groupby_all.count()['Survived'].dropna()\n\n# male\nmale = train.query('Sex == \"male\"')\ncut, bins = pd.cut(male['Age'], bins, retbins=True)\ngroupby_m = male.groupby(cut)\nsurv_rate_m = groupby_m.sum()['Survived'].dropna() \/ groupby_m.count()['Survived'].dropna()\n\n# female\nfemale = train.query('Sex == \"female\"')\ncut, bins = pd.cut(female['Age'], bins, retbins=True)\ngroupby_f = female.groupby(cut)\nsurv_rate_f = groupby_f.sum()['Survived'].dropna() \/ groupby_f.count()['Survived'].dropna()\n\n# convert train to DataFrame for survival rates by age-band\nsurv_rate_a = pd.DataFrame(index=age_cat, columns=['all'], data=surv_rate_a.values)\nsurv_rate_m = pd.DataFrame(index=age_cat, columns=['male'], data=surv_rate_m.values)\nsurv_rate_f = pd.DataFrame(index=age_cat, columns=['female'], data=surv_rate_f.values)\n\n# plot\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\nfig.suptitle('Survival rates by sex and age', fontsize=16, y=1.02)\n\nsns.barplot(x=surv_rate_a.index, y='all', data=surv_rate_a, ax=ax1)\nax1.set_xticklabels(surv_rate_m.index, rotation=90)\nax1.set_ylabel('survival rate')\nax1.set_title('all')\n\nsns.barplot(x=surv_rate_m.index, y='male', data=surv_rate_m, ax=ax2)\nax2.set_xticklabels(surv_rate_m.index, rotation=90)\nax2.set_xlabel('age')\nax2.set_ylabel('')\nax2.set_title('male')\n\nsns.barplot(x=surv_rate_f.index, y='female', data=surv_rate_f, ax=ax3)\nax3.set_xticklabels(surv_rate_f.index, rotation=90)\nax3.set_ylabel('')\nax3.set_title('female')\n\nplt.show()","b9d981c0":"fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\nsns.distplot(train['Fare'], kde=False, bins=18, ax=ax1)\nax1.set_title('Fare distribution', fontsize=16)\nax1.set_ylabel('count')\n\nfare_s0 = train[train['Survived'] == 0]['Fare'].dropna()\nfare_s1 = train[train['Survived'] == 1]['Fare'].dropna()\nax2.hist([fare_s0, fare_s1], label=['dead', 'survived'], bins=18)\nax2.set_title('Survived by Fare', fontsize=16)\nax2.set_xlabel('fare')\nax2.set_ylabel('count')\nax2.legend()\n\nplt.show()","410e6beb":"fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\ntrain['Pclass'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax1)\nax1.set_title('Pclass ratio', fontsize=16, y=1.05)\nax1.set_ylabel('')\n\nsns.barplot(x='Pclass', y='Survived', data=train, ax=ax2)\nax2.set_title('Survival rate by Pclass', fontsize=16, y=1.05)\n\nplt.show()","1961d633":"fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n\ntrain['SibSp'].value_counts().plot.pie(ax=ax1)\nax1.set_title('SibSp ratio', fontsize=16, y=1.05)\nax1.set_ylabel('')\n\nsns.barplot(x='SibSp', y='Survived', hue='Sex', data=train, ax=ax2)\nax2.set_title('Survival rate by SibSp and Sex', fontsize=16, y=1.05)\n\ntrain['Parch'].value_counts().plot.pie(ax=ax3)\nax3.set_title('Parch ratio', fontsize=16, y=1.05)\nax3.set_ylabel('')\n\nsns.barplot(x='Parch', y='Survived', hue='Sex', data=train, ax=ax4)\nax4.set_title('Survival rate by Parch and Sex', fontsize=16, y=1.05)\n\nplt.subplots_adjust(wspace=0.2,hspace=0.5)\nplt.show()","168629f4":"f,(ax1,ax2,ax3) = plt.subplots(1, 3, figsize=(18,4))\n\ntrain['Embarked'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax1)\nax1.set_title('Embarked ratio', fontsize=16, y=1.05)\nax1.set_ylabel('')\n\nsns.barplot(x='Embarked', y='Survived', data=train, ax=ax2)\nax2.set_title('Survival rates by Embarked', fontsize=16, y=1.05)\n\nsns.countplot('Embarked',hue='Pclass',data=train, ax=ax3)\nax3.set_title('Embarked rates by Pclass', fontsize=16, y=1.05)\n\nplt.show()","23603f98":"fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\ntrain['Cabin'].notnull().value_counts().plot.pie(autopct='%1.1f%%', labels=['null', 'not null'], ax=ax1)\nax1.set_title('Cabin null ratio', fontsize=16, y=1.05)\nax1.set_ylabel('')\n\ntmp = pd.DataFrame()\ntmp['Survived'] = train['Survived']\ntmp['CabinLevel'] = train['Cabin'].str[0]\ntmp['CabinLevel'].replace(np.nan, 'U', inplace=True)\nsns.barplot(x='CabinLevel', y='Survived', data=tmp, order=sorted(tmp['CabinLevel'].unique()), ax=ax2)\nax2.set_title('Survival rates by Cabin level', fontsize=16, y=1.05)\n\nplt.show()","ce3a7fbb":"combine = pd.concat([train, test], sort=False)","72258900":"# convert to numeric\ncombine['Sex'].replace(['male', 'female'], [0, 1], inplace=True)","9e9af569":"# fill NaN Ages with median\ncombine['Age'].fillna(combine['Age'].median(), inplace=True)","59dd7a16":"# standardize\nstandard = StandardScaler()\ncombine[['Age']] = standard.fit_transform(combine[['Age']])","25c5813d":"# Fill in the missing values with median\ncombine['Fare'].fillna(combine['Fare'].median(), inplace=True)","adb444c2":"# robust scaling\nrscaler = RobustScaler(quantile_range=(25., 75.))\ncombine[['Fare']] = rscaler.fit_transform(combine[['Fare']])","9b7ff281":"# logarithmic conversion\nprint('before:', combine['Fare'].skew())\ncombine['Fare'] = np.log1p(combine['Fare'])\nprint('after:', combine['Fare'].skew())","d88ebba9":"# normalize \ncombine['Pclass'] = (combine['Pclass'] - 1) \/ 2","26bfcbaf":"# add \"FamilySize\" column\ncombine['FamilySize'] = combine['SibSp'] + combine['Parch']","f82353c2":"# Visualization\nfig = sns.barplot(x='FamilySize', y='Survived', hue='Sex', data=combine)\nfig.set_title('Survival rates by FamilySize and Sex', fontsize=16, y=1.05)\nplt.show()","e2d4d837":"# standardize\nstandard = StandardScaler()\ncombine[['FamilySize']] = standard.fit_transform(combine[['FamilySize']])","f6cde45b":"# Fill in the missing values with mode\ncombine['Embarked'].fillna(combine['Embarked'].mode()[0], inplace=True)","01d47f84":"# one-hot encoding\ncombine = pd.get_dummies(combine, columns=['Embarked'], drop_first=True)","51b8cddb":"# extract titles from Names\ncombine['Title'] = combine.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ncombine['Title'].unique()","91207d88":"# Count titles\npd.crosstab(combine['Title'], combine['Sex'])","40adde29":"# Aggregate 10 or less titles as \"other\"\ncombine.loc[(combine['Title'] != 'Master')\\\n          & (combine['Title'] != 'Miss')\\\n          & (combine['Title'] != 'Mr')\\\n          & (combine['Title'] != 'Mrs'), 'Title'] = 'other'\npd.crosstab(combine['Title'], combine['Sex'])","3bca5ed7":"# Visualization\nfig = sns.barplot(x='Title', y='Survived', data=combine)\nfig.set_title('Survival rates by title', fontsize=16, y=1.05)\nplt.show()","5ef56b5b":"# convert to numeric\ncombine = pd.get_dummies(combine, columns=['Title'], drop_first=True)","a574e029":"# replace notnull to 1\ntmp = pd.DataFrame()\ntmp['Cabin'] = combine['Cabin']\ntmp['Cabin'].loc[tmp['Cabin'].notnull()] = 1\n# replace null to 0\ncombine['Cabin'] = tmp['Cabin']\ncombine['Cabin'].replace(np.nan, 0, inplace=True)","552555ae":"combine.head()","c2626fe1":"# remove unnecessary columns\ncombine_cleaned = combine.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket'], axis=1)\ncombine_cleaned.head()","cb00c55c":"# split combine_cleaned into train and test\ntrain = combine_cleaned[:train.shape[0]]\ntest = combine_cleaned[train.shape[0]:]\n\n# split feature and label\nX_train = train.drop('Survived', axis=1)\ny_train = train['Survived']\nX_test = test.drop('Survived', axis=1)\n\n# check the shapes\nprint('X_train shape:', X_train.shape)\nprint('y_train.shape:', y_train.shape)\nprint('X_test shape:', X_test.shape)","621540c3":"def hyperopt_and_pred(models, max_evals=100):\n    preds = []\n    \n    for model in models:\n        clf = model['classifier']\n        space = model['space']\n        \n        # define objective function\n        def objective(space):\n            # create model object\n            classifier = clf(**space)\n            # train the model\n            classifier.fit(X_train, y_train)\n            # cross validation\n            skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n            acc = cross_validate(estimator=classifier, X=X_train, y=y_train, cv=skf)\n            mean_acc = np.mean(acc['test_score'])\n            return{'loss': 1 - mean_acc, 'status': STATUS_OK}\n\n        print('='*10, str(clf).split('.')[-1].replace('\\'>', ''), '='*10)\n        \n        # create Trials object\n        trials = Trials()\n        # minimize the objective over the space\n        best = fmin(objective, space, algo=tpe.suggest, max_evals=max_evals, trials=trials, verbose=1)\n        # fit and predict\n        best_params = space_eval(space, best)\n        predict = clf(**best_params).fit(X_train, y_train).predict(X_test)\n        acc = 1 - trials.best_trial['result']['loss']\n        preds.append(predict)\n        \n        print('\\n', 'best parameters:', best_params)\n        print('accuracy:', f'{acc:.04f}', '\\n\\n')\n        \n    return preds","c20beef2":"# Set models and hyper-parameters to be optimized\nmodels = [\n    # Logistic Regression\n    {\n        'classifier': LogisticRegression,\n        'space': {\n            'C': hp.uniform('C', 0, 100),\n            'max_iter': hp.choice('max_iter', [2000]),\n            'solver': hp.choice('solver', ['lbfgs', 'liblinear', 'sag', 'saga'])\n        }\n    },\n    # Random Forest\n    {\n        'classifier': RandomForestClassifier,\n        'space': {\n            'n_estimators': hp.choice('n_estimators', np.arange(10, 401, 10)),\n            'max_depth': hp.uniform('max_depth', 1, 5),\n            'criterion': hp.choice('criterion', ['gini', 'entropy'])\n        }\n    },\n    # KNeighbors\n    {\n        'classifier': KNeighborsClassifier,\n        'space': {\n            'n_neighbors': hp.choice('n_neighbors', np.arange(1, 15))\n        }\n    },\n    # AdaBoost\n    {\n        'classifier': AdaBoostClassifier,\n        'space': {\n            'n_estimators': hp.choice('n_estimators', [30,50,100,200,300]),\n            'learning_rate': hp.uniform('learning_rate', 0.8, 1.4)\n        }\n    },\n    # SVC\n    {\n        'classifier': SVC,\n        'space': {\n            'C': hp.uniform('C', 0, 2),\n            'gamma': hp.loguniform('gamma', -8, 2),\n            'kernel': hp.choice('kernel', ['rbf', 'poly', 'sigmoid'])\n        }\n    },\n    # GBDT\n    {\n        'classifier': LGBMClassifier,\n        'space': {\n            'objective': hp.choice('objective', ['binary']),\n            'max_bin': hp.choice ('max_bin', np.arange(64, 513, 1)),\n            'num_leaves': hp.choice('num_leaves', np.arange(30, 201, 10)),\n            'max_depth': hp.choice('max_depth', np.arange(3, 10, 1)),\n            'learning_rate': hp.uniform('learning_rate', 0.03, 0.2)\n        }\n    },\n    # Multilayer perceptron\n    {\n        'classifier': MLPClassifier,\n        'space': {\n            'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [8, 16, 32, (8,8), (16,16)]),\n            'activation': hp.choice('activation', ['relu', 'tanh']),\n            'max_iter': hp.choice('max_iter', [3000])\n        }\n    }\n]","5975c4c4":"# fit and predict\npredictions = hyperopt_and_pred(models)","4b9c3317":"# check correlation of each predictions\nclf_names = [str(clf['classifier']).split('.')[-1].replace('\\'>', '') for clf in models]\ncorr_preds = pd.DataFrame(predictions).T.corr()\ncorr_preds.columns = clf_names\ncorr_preds.index = clf_names\nfig = sns.heatmap(corr_preds, annot=True, fmt='.2f', cmap='rainbow')\nfig.set_title('Predictions correlation matrix', fontsize=16, y=1.05)\nplt.show()","f8e0a485":"# take the average of the predictions\nensembled_pred = np.round(sum(predictions) \/ len(predictions)).astype('int')","7a78560f":"results = pd.Series(ensembled_pred, name='Survived')\nsubmission = pd.concat([submission['PassengerId'], results], axis=1)\nsubmission.to_csv('submission.csv', index=False)","04282578":"# Titanic - EDA, Hyperopt, CV & Ensembling modeling\nThis notebook covers EDA, feature engineering, hyper-parameter optimization, and ensemble process step-by-step. <br>I hope you find this notebook useful!","6ca5b465":"<a id=\"1.3\"><\/a>\n## 1.3 Check data<a id='Check data'><\/a>","43875c3f":"<a id=\"3.8\"><\/a>\n## 3.8 Name(Title)\nSince title represents rank, it may have influenced the priority of rescue. Therefore, separate the title from the name and check the survival rate for each title. Visualization shows that the survival rates of Mr and Master differ greatly even in men.","4f7148c3":"<a id=\"4.3\"><\/a>\n## 4.3 Merge predictions","ee405e4f":"<a id=\"3\"><\/a>\n<h1 style='background:deepskyblue; border:0; color:white'><center>3. Feature Engineering<\/center><\/h1>","f223e1d1":"<a id=\"3.1\"><\/a>\n## 3.1 Combine train and test\nCombine train and test so that you can do each future operation once.","ffdc714c":"<a id=\"2.8\"><\/a>\n## 2.8 Key Observations\n* Sex: The survival rate of females is significantly higher than that of males.\n* Age: Overall, the survival rate is high for female and low for male. Infants also have a high survival rate.\n* Fare: Fare is mostly in the low price range and the distribution is very distorted. In addition, the higher price range has a higher survival rate.\n* Pclass: Pclass is strongly correlated with survival. Better classes have higher survival rates.\n* Cabin: Passengers with Cabin have a higher survival rate than passengers without Cabin.","d5a22d83":"Since the number of people aged 65 and over is very small, it was excluded from these statistics.","da73e76e":"<a id=\"1.1\"><\/a>\n## 1.1 Import Libraries","18268b82":"<a id=\"2.3\"><\/a>\n## 2.3 Fare","b70cebee":"<a id=\"2.5\"><\/a>\n## 2.5 SibSp and Parch","208be1bd":"In one process, we optimize hyper-parameters of multiple models, train models, and predict at once, and finally integrate them.","8a7f6c8c":"<a id=\"1\"><\/a>\n<h1 style='background:deepskyblue; border:0; color:white'><center>1. Introduction<\/center><\/h1>","1dcf7f0d":"<a id=\"3.6\"><\/a>\n## 3.6 Family size\nSibSp and Parch should add up to the number of family size. (The number of singles is 0)\nThe graph shows that family size and the survival rate correlate.","7520301c":"<a id=\"3.7\"><\/a>\n## 3.7 Embarked\nFill in the missing values with the mode, and one hot encode them.","389ccad2":"<a id=\"5\"><\/a>\n<h1 style='background:deepskyblue; border:0; color:white'><center>5. Create submission<\/center><\/h1>","92dc6d15":"<a id=\"2.4\"><\/a>\n## 2.4 Pclass","1fc5cec8":"<a id=\"3.5\"><\/a>\n## 3.5 Pclass\nThe numbers 1,2,3 are meaningless, but the ordering relationship is. This value will be normalized as it is.","ae4df98b":"<a id=\"2.6\"><\/a>\n## 2.6 Embarked","3a05f8c9":"<a id=\"4.1\"><\/a>\n## 4.1 define function which optimize parameters and predict","456c16f6":"<a id=\"4.2\"><\/a>\n## 4.2 Set models and predict","0c1cfa19":"<a id=\"4\"><\/a>\n<h1 style='background:deepskyblue; border:0; color:white'><center>4. Optimization, fitting and prediction<\/center><\/h1>","5b06d149":"<a id=\"1.2\"><\/a>\n## 1.2 Load data<a id='Load data'><\/a>","8a224a83":"<a id=\"3.4\"><\/a>\n## 3.4 Fare\nComplement the missing values with the median and exclude the outliers with the robust scaling, and reduce skewness by logarithmic conversion.","4d2da3cd":"The correlation coefficients are generally 95% or less, and it seems worth ensemble.","2f0732e2":"<a id=\"3.2\"><\/a>\n## 3.2 Sex\nConvert Sex to binary for ease of learning.","e5643737":"<a id=\"2.2\"><\/a>\n## 2.2 Sex and Age","2317db29":"<a id=\"2.1\"><\/a>\n## 2.1 Overview","265fd589":"* [1. Introduction](#1)\n    * [1.1 Import Libraries](#1.1)\n    * [1.2 Load data](#1.2)\n* [2. Exploratory Data Analysis(EDA)](#2)\n    * [2.1 Overview](#2.1)\n    * [2.2 Sex and Age](#2.2)\n    * [2.3 Fare](#2.3)\n    * [2.4 Pclass](#2.4)\n    * [2.5 SibSp and Parch](#2.5)\n    * [2.6 Embarked](#2.6)\n    * [2.7 Cabin](#2.7)\n    * [2.8 Key Observations](#2.8)\n* [3. Feature Engineering](#3)\n    * [3.1 Combine train and test](#3.1)\n    * [3.2 Sex](#3.2)\n    * [3.3 Age](#3.3)\n    * [3.4 Fare](#3.4)\n    * [3.5 Pclass](#3.5)\n    * [3.6 Family size](#3.6)\n    * [3.7 Embarked](#3.7)\n    * [3.8 Name(Title)](#3.8)\n    * [3.9 Cabin](#3.9)\n    * [3.10 Arrange the data](#3.10) \n* [4. Optimization, fitting and prediction](#4)\n    * [4.1 define function which optimize parameters and predict](#4.1)\n    * [4.2 Set models and predict](#4.2)\n    * [4.3 Merge predictions](#4.3)\n* [5. Create submission](#5)","0c662fbb":"<a id=\"3.3\"><\/a>\n## 3.3 Age\nMissing values in Age are complemented by the median and standardized.","285ebfb4":"<a id=\"2\"><\/a>\n<h1 style='background:deepskyblue; border:0; color:white'><center>2. Exploratory Data Analysis(EDA)<\/center><\/h1>","e17d15ad":"<a id=\"2.7\"><\/a>\n## 2.7 Cabin","7f253626":"<a id=\"3.10\"><\/a>\n## 3.10 Arrange the data\nFinally, remove unnecessary columns and separate them into train and test again.","e2f23b3b":"<a id=\"3.9\"><\/a>\n## 3.9 Cabin\nSurvival rate varies depending on the presence or absence of Cabin. Therefore, the presence or absence of Cabin is converted into a binary value."}}