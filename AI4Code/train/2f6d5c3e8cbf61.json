{"cell_type":{"9a55b081":"code","d45d7977":"code","c1448142":"code","62064977":"code","2b267970":"code","3d334001":"code","24c34f7c":"code","01b14301":"code","b0e4aae4":"code","3e52df79":"code","67ffee33":"code","6e482ba9":"code","af60a11a":"code","a89c2475":"code","0dd57d28":"code","35d64b04":"code","5a77a042":"code","ba7a7656":"code","fb6b59cf":"code","ed2cb6dc":"code","4d7ac869":"code","cfa7405f":"code","ac8c92c2":"code","51532542":"code","4fd28350":"code","7a79a29c":"code","d295e69f":"code","8a3b90ad":"code","4fae121d":"code","ee21ab00":"markdown","d6e25bc6":"markdown","2e631034":"markdown","5d6207c8":"markdown","c5d10179":"markdown","b1934543":"markdown","d5cfc8ec":"markdown","92201aaf":"markdown","c7f14171":"markdown","0374fe42":"markdown","bd0b1597":"markdown","ab5c1904":"markdown","b02b5810":"markdown","57ab4af3":"markdown","1766801b":"markdown"},"source":{"9a55b081":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt, zipfile\nimport os\nimport glob\nimport math\nimport random\nimport time\nimport datetime\nimport shutil\nfrom tqdm import tqdm, tqdm_notebook\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nimport warnings\nfrom scipy import linalg\n\nimport xml.etree.ElementTree as ET \n\nimport cv2\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape,\\\nConv2DTranspose, Conv2D, Flatten, Dropout, Embedding, ReLU\nfrom tensorflow.keras.optimizers import Adam\n\nprint(os.listdir(\"..\/input\/stanford-dogs-dataset\"))","d45d7977":"image_width = 64\nimage_height = 64\nimage_channels = 3\nimage_sample_size = 10000\nimage_output_dir = '..\/output_images\/'\nimage_input_dir = '..\/input\/stanford-dogs-dataset\/images\/Images\/'\nimage_ann_dir = \"..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/\"\nOUT_DIR = Path('..\/output_images\/')\nTRAIN_DIR = Path('..\/input\/stanford-dogs-dataset\/images\/Images\/')","c1448142":"dog_breed_dict = {}\nfor annotation in os.listdir(image_ann_dir):\n    annotations = annotation.split('-')\n    dog_breed_dict[annotations[0]] = annotations[1]","62064977":"def read_image(src):\n    img = cv2.imread(src)\n    if img is None:\n        raise FileNotFoundError\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","2b267970":"def load_cropped_images(dog_breed_dict=dog_breed_dict, image_ann_dir=image_ann_dir, sample_size=20580, image_width=image_width, image_height=image_height, image_channels=image_channels):\n    curIdx = 0\n    acum = 0\n    breeds = []\n    dog_images_np = np.zeros((sample_size,image_width,image_height,image_channels))\n    for breed_folder in os.listdir(image_ann_dir):\n        for dog_ann in tqdm(os.listdir(image_ann_dir + breed_folder)):\n            try:\n                img = read_image(os.path.join(image_input_dir, breed_folder, dog_ann + '.jpg'))\n            except FileNotFoundError:\n                continue\n            \n            tree = ET.parse(os.path.join(image_ann_dir + breed_folder + '\/' + dog_ann))\n            root = tree.getroot()            \n            size = root.find('size')\n            width = int(size.find('width').text)\n            height = int(size.find('height').text)\n            objects = root.findall('object')\n            for o in objects:\n                bndbox = o.find('bndbox') \n                \n                xmin = int(bndbox.find('xmin').text)\n                ymin = int(bndbox.find('ymin').text)\n                xmax = int(bndbox.find('xmax').text)\n                ymax = int(bndbox.find('ymax').text)\n                \n                xmin = max(0, xmin - 4)        # 4 : margin\n                xmax = min(width, xmax + 4)\n                ymin = max(0, ymin - 4)\n                ymax = min(height, ymax + 4)\n\n                w = np.min((xmax - xmin, ymax - ymin))\n                w = min(w, width, height)                     # available w\n\n                if w > xmax - xmin:\n                    xmin = min(max(0, xmin - int((w - (xmax - xmin))\/2)), width - w)\n                    xmax = xmin + w\n                if w > ymax - ymin:\n                    ymin = min(max(0, ymin - int((w - (ymax - ymin))\/2)), height - w)\n                    ymax = ymin + w\n                \n            img_cropped = img[ymin:ymin+w, xmin:xmin+w, :]      # [h,w,c]\n            # Interpolation method\n            if xmax - xmin > image_width:\n                interpolation = cv2.INTER_AREA          # shrink\n            else:\n                interpolation = cv2.INTER_CUBIC         # expansion\n\n            img_cropped = cv2.resize(img_cropped, (image_width, image_height), interpolation=interpolation)  # resize\n            \n            dog_images_np[curIdx,:,:,:] = np.asarray(img_cropped)\n            dog_breed_name = dog_breed_dict[dog_ann.split('_')[0]]\n            breeds.append(dog_breed_name)\n            curIdx += 1\t\n                \n    return dog_images_np, breeds","3d334001":"start_time = time.time()\ndog_images_np, breeds = load_cropped_images(sample_size=20580)\nest_time = round(time.time() - start_time)\nprint(\"Feature loading time: {}.\".format(str(datetime.timedelta(seconds=est_time))))","24c34f7c":"print('Imagenes cargadas shape: ', dog_images_np.shape)\nprint('Labels cargados: ', len(breeds))","01b14301":"def plot_features(features, labels, image_width=image_width, image_height=image_height, image_channels=image_channels, examples=25, disp_labels=True): \n  \n    imgs = []\n    classes = []\n    for i in range(examples):\n        rnd_idx = np.random.randint(0, len(labels))\n        imgs.append(features[rnd_idx, :, :, :])\n        classes.append(labels[rnd_idx])\n    \n    \n    fig, axes = plt.subplots(round(math.sqrt(examples)), round(math.sqrt(examples)),figsize=(15,15),\n    subplot_kw = {'xticks':[], 'yticks':[]},\n    gridspec_kw = dict(hspace=0.3, wspace=0.01))\n    \n    for i, ax in enumerate(axes.flat):\n        if disp_labels == True:\n            ax.title.set_text(classes[i])\n        ax.imshow(imgs[i])","b0e4aae4":"print('Imprimiendo...')\nplot_features(dog_images_np \/ 255., breeds, examples=25, disp_labels=True)","3e52df79":"sample_size = 20580\nbatch_size = 32\nlr_initial_d = 0.0002\nlr_initial_g = 0.0002\nlr_decay_steps = 1000\nnoise_dim = 100","67ffee33":"dog_features_tf = tf.cast(dog_images_np, 'float32')\ntrain_dataset = tf.data.Dataset.from_tensor_slices(dog_features_tf).shuffle(sample_size).batch(batch_size)\nprint(train_dataset)","6e482ba9":"weight_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)","af60a11a":"def DogGenerator():\n    model = tf.keras.Sequential(\n        [\n            tf.keras.layers.Dense(8*8*512, use_bias=False, input_shape=(100,)),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Reshape((8, 8, 512)),\n            tf.keras.layers.Conv2DTranspose(256, (5,5), strides=(2,2), padding='same', use_bias=False,kernel_initializer=weight_initializer),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Dropout(0.3),\n            tf.keras.layers.Conv2DTranspose(128, (5,5), strides=(2,2), padding='same', use_bias=False,kernel_initializer=weight_initializer),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Dropout(0.3),\n            tf.keras.layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False,kernel_initializer=weight_initializer),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Dense(3,activation='tanh', use_bias=False,kernel_initializer=weight_initializer)\n        ]\n    )\n    \n    return model","a89c2475":"dog_generator = DogGenerator()\nprint(dog_generator.summary())","0dd57d28":"noise = tf.random.normal([1,noise_dim])\ngenerated_image = dog_generator(noise)\nplt.imshow(generated_image[0, :, :, :])\nprint(generated_image.shape)\nprint(noise.shape, tf.math.reduce_mean(noise).numpy(), tf.math.reduce_std(noise).numpy())\n","35d64b04":"def DogDiscriminator():\n    model = tf.keras.Sequential(\n        [\n            tf.keras.layers.Conv2D(64, (4,4), strides=(2,2), padding='same', input_shape=[image_width,image_height,3], kernel_initializer=weight_initializer),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=weight_initializer),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=weight_initializer),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n        ]\n    )\n    return model","5a77a042":"dog_discriminator = DogDiscriminator()\nprint(dog_discriminator.summary())","ba7a7656":"def smooth_positive_labels(y):\n    return y - 0.3 + (np.random.random(y.shape) * 0.5)\n\ndef smooth_negative_labels(y):\n    return y + np.random.random(y.shape) * 0.3\n\ndef noisy_labels(y, p_flip):\n    n_select = int(p_flip * int(y.shape[0]))\n    flip_ix = np.random.choice([i for i in range(int(y.shape[0]))], size=n_select)\n    \n    op_list = []\n    for i in range(int(y.shape[0])):\n        if i in flip_ix:\n            op_list.append(tf.subtract(1, y[i]))\n        else:\n            op_list.append(y[i])\n    \n    outputs = tf.stack(op_list)\n    return outputs","fb6b59cf":"generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_initial_g, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_initial_d, beta_1=0.5)\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)","ed2cb6dc":"def discriminator_loss(real_output, fake_output):\n    real_output_smooth = smooth_positive_labels(tf.ones_like(real_output))\n    fake_output_smooth = smooth_negative_labels(tf.zeros_like(fake_output))\n    real_loss = cross_entropy(real_output_smooth, real_output)\n    fake_loss = cross_entropy(fake_output_smooth, fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","4d7ac869":"def generator_loss(fake_output):\n    fake_output_smooth = smooth_negative_labels(tf.ones_like(fake_output))\n    return cross_entropy(fake_output_smooth, fake_output)","cfa7405f":"checkpoint_dir = '\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=dog_generator,discriminator=dog_discriminator)","ac8c92c2":"EPOCHS = 300\nnum_examples_to_generate = 16\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","51532542":"def train_step(images, G_loss, D_loss):\n    noise = tf.random.normal([batch_size, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = dog_generator(noise, training=True)\n        \n        real_output = dog_discriminator(images, training=True)\n        fake_output = dog_discriminator(generated_images, training=True)\n        \n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    G_loss.append(gen_loss.numpy())\n    D_loss.append(disc_loss.numpy())\n    \n    gradients_of_generator = gen_tape.gradient(gen_loss, dog_generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, dog_discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, dog_generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, dog_discriminator.trainable_variables))","4fd28350":"def plot_loss(G_losses, D_losses, epoch):\n    plt.figure(figsize=(10,5))\n    plt.title(\"Generator and Discriminator Loss - EPOCH {}\".format(epoch))\n    plt.plot(G_losses,label=\"G\")\n    plt.plot(D_losses,label=\"D\")\n    plt.xlabel(\"Iterations\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","7a79a29c":"def generate_and_save_images(model, epoch, test_input):\n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(10,10))\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow((predictions[i, :, :, :] * 127.5 + 127.5) \/ 255.)\n        plt.axis('off')\n    plt.show()","d295e69f":"def generate_test_image(model, noise_dim=noise_dim):\n    test_input = tf.random.normal([1, noise_dim])\n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(5,5))\n    plt.imshow((predictions[0, :, :, :] * 127.5 + 127.5) \/ 255.)\n    plt.axis('off') \n    plt.show()\n","8a3b90ad":"def train(dataset, epochs):\n    G_loss = []\n    D_loss = []\n    for epoch in tqdm(range(epochs)):\n        \n        start = time.time()\n        new_lr_d = lr_initial_d\n        new_lr_g = lr_initial_g\n        global_step = 0\n        \n        for image_batch in dataset:\n            train_step(image_batch, G_loss, D_loss)\n            global_step = global_step + 1\n         \n        if (epoch + 1) % 2 == 0:\n            plot_loss(G_loss, D_loss, epoch + 1)\n            generate_and_save_images(dog_generator, epoch + 1, seed)            \n        \n        G_loss = []\n        D_loss = []           \n\n        print ('Epoch: {} computed for {} sec'.format(epoch + 1, time.time() - start))\n\n    generate_and_save_images(dog_generator, epochs, seed)\n    checkpoint.save(file_prefix = checkpoint_prefix)\n    \n    print('Final epoch.')","4fae121d":"train(train_dataset, EPOCHS)","ee21ab00":"### **Se muestran algunas imagenes**","d6e25bc6":"# **Se declaran variables generales que se usar\u00e1n**","2e631034":"##### Optimizadores y funciones de perdida","5d6207c8":"# **Se importan las librerias necesarias para la creaci\u00f3n de la GAN**","c5d10179":"Suavizamiento del label","b1934543":"# **Generative Adversarial Network**","d5cfc8ec":"# **Entrenamiento**","92201aaf":"Ruido aleatorio","c7f14171":"### **Se recortan las imagenes**","0374fe42":"### **Discriminador**","bd0b1597":"##### Generador","ab5c1904":"### **Hiperparametros**","b02b5810":"### **Generador**","57ab4af3":"# **Se cargan las imagenes y se generan los features**","1766801b":"### **Funci\u00f3n para mostrar im\u00e1genes random**"}}