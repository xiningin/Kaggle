{"cell_type":{"023664d2":"code","efa64f5d":"code","78ec1ac6":"code","1089a904":"code","a0f30116":"code","1d934dde":"code","03dfcb70":"code","0b893675":"code","530ee27a":"code","6de0c3b5":"code","6f5c95f7":"code","bae72b70":"code","08fd593f":"code","44de4808":"code","e191bffe":"code","305dc9f9":"code","5ffe4d4a":"code","0922e3f0":"code","e44fe2df":"code","a4bca16d":"code","8f09ba12":"code","c0dba639":"code","498dad33":"code","597214c7":"code","86993e67":"code","9024deeb":"code","701189f7":"code","2e569dcf":"code","04aa160f":"code","e2ab5d6b":"code","c4485502":"code","2bb85113":"code","cfd872b4":"code","d2679551":"code","fd2ca1b4":"code","15426ffb":"code","19b380b2":"code","cdb46ed8":"code","b9e6fbf6":"code","04a0053b":"markdown","e67c7121":"markdown","f43a027f":"markdown","b45ff0b7":"markdown","cf4ec8e1":"markdown","4ef93ef1":"markdown","5e1c449d":"markdown","137dca2e":"markdown","d67ea3e1":"markdown","a356211b":"markdown","a9b73258":"markdown","38bf96ab":"markdown","49dc143d":"markdown","9da0cc1b":"markdown","46a61591":"markdown","2fe7051d":"markdown","09779df9":"markdown","44d2dc36":"markdown","b838bfff":"markdown","c4892179":"markdown","b172841a":"markdown"},"source":{"023664d2":"# import required libraries for dataframe and visualization\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\n# import required libraries for clustering\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","efa64f5d":"# Reading the data on which analysis needs to be done\n\nretail = pd.read_csv('..\/input\/online-retail-customer-clustering\/OnlineRetail.csv', sep=\",\", encoding=\"ISO-8859-1\", header=0)\nretail.head()","78ec1ac6":"retail.shape","1089a904":"retail.info()","a0f30116":"retail.describe()","1d934dde":"# Calculating the Missing Values % contribution in DF\n\nround(100*retail.isnull().sum()[retail.isnull().sum()!=0]\/len (retail),2)","03dfcb70":"# Droping rows having missing values\n\nretail = retail.dropna()\nretail.shape","0b893675":"# Changing the datatype of Customer Id as per Business understanding\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)","530ee27a":"# New Attribute : Monetary\n\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_m.head()","6de0c3b5":"# New Attribute : Frequency\n\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\nrfm_f.head()","6f5c95f7":"# Merging the two dfs\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\nrfm.head()","bae72b70":"# New Attribute : Recency\n\n# Convert to datetime to proper datatype\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')","08fd593f":"# Compute the maximum date to know the last transaction date\n\nmax_date = max(retail['InvoiceDate'])\nmax_date","44de4808":"# Compute the difference between max date and transaction date\n\nretail['Diff'] = max_date - retail['InvoiceDate']\nretail.head()","e191bffe":"# Compute last transaction date to get the recency of customers\n\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p.head()","305dc9f9":"# Extract number of days only\n\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm_p.head()","5ffe4d4a":"# Merge tha dataframes to get the final RFM dataframe\n\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\nrfm.head()","0922e3f0":"# Outlier Analysis of Amount Frequency and Recency\n\nattributes = ['Amount','Frequency','Recency']\nplt.rcParams['figure.figsize'] = [10,8]\nsns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"Attributes\", fontweight = 'bold')","e44fe2df":"# Removing (statistical) outliers for Amount\nQ1 = rfm.Amount.quantile(0.05)\nQ3 = rfm.Amount.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Recency\nQ1 = rfm.Recency.quantile(0.05)\nQ3 = rfm.Recency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Frequency\nQ1 = rfm.Frequency.quantile(0.05)\nQ3 = rfm.Frequency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]","a4bca16d":"# Rescaling the attributes\n\nrfm_df = rfm[['Amount', 'Frequency', 'Recency']]\n\n# Instantiate\nscaler = StandardScaler()\n\n# fit_transform\nrfm_df_scaled = scaler.fit_transform(rfm_df)\nrfm_df_scaled.shape","8f09ba12":"rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']\nrfm_df_scaled.head()","c0dba639":"# k-means with some arbitrary k\n\nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(rfm_df_scaled)","498dad33":"kmeans.labels_","597214c7":"# Elbow-Method\/SSD \n\nssd = []\nfor num_clusters in range(2,10):\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(rfm_df_scaled)\n    \n    ssd.append(kmeans.inertia_)\n    \n# plot the SSDs for each n_clusters\nplt.plot(ssd)","86993e67":"# Silhouette analysis\nfor num_clusters in range(2,10):\n    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(rfm_df_scaled)\n    \n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(rfm_df_scaled, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))\n    \n    ","9024deeb":"# Final model with k=4\nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(rfm_df_scaled)","701189f7":" kmeans.labels_","2e569dcf":"# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","04aa160f":"# Box plot to visualize Cluster Id vs Frequency\n\nsns.boxplot(x='Cluster_Id', y='Amount', data=rfm)","e2ab5d6b":"# Box plot to visualize Cluster Id vs Frequency\n\nsns.boxplot(x='Cluster_Id', y='Frequency', data=rfm)","c4485502":"# Box plot to visualize Cluster Id vs Recency\n\nsns.boxplot(x='Cluster_Id', y='Recency', data=rfm)","2bb85113":"# Single linkage: \n\nmergings = linkage(rfm_df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","cfd872b4":"# Complete linkage\n\nmergings = linkage(rfm_df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","d2679551":"# Average linkage\n\nmergings = linkage(rfm_df_scaled, method=\"average\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","fd2ca1b4":"# 4 clusters\ncluster_labels = cut_tree(mergings, n_clusters=4).reshape(-1, )\ncluster_labels","15426ffb":"# Assign cluster labels\n\nrfm['Cluster_Labels'] = cluster_labels\nrfm.head()","19b380b2":"#  Cluster Id vs Amount\n\nsns.boxplot(x='Cluster_Labels', y='Amount', data=rfm)","cdb46ed8":"sns.boxplot(x='Cluster_Labels', y='Frequency', data=rfm)","b9e6fbf6":"#  Cluster Id vs Recency\n\nsns.boxplot(x='Cluster_Labels', y='Recency', data=rfm)","04a0053b":"### K-Means Clustering","e67c7121":"**Complete Linkage<br>**\n\nIn complete linkage hierarchical clustering, the distance between two clusters is defined as the longest distance between two points in each cluster. For example, the distance between clusters \u201cr\u201d and \u201cs\u201d to the left is equal to the length of the arrow between their two furthest points. \n![](https:\/\/www.saedsayad.com\/images\/Clustering_complete.png)","f43a027f":"#### Cutting the Dendrogram based on K","b45ff0b7":"Hierarchical Clustering with 3 Cluster Labels\n- Customers with Cluster_label 3 are the customers with high amount of transactions as compared to other customers.\n- Customers with Cluster_Labels 3 are frequent buyers.\n- Customers with Cluster_Labels 3 are not recent buyers and hence least of importance from business point of view.\n* mist important customer is with cluster ID 1","cf4ec8e1":"### Rescaling the Attributes\n\nIt is extremely important to rescale the variables so that they have a comparable scale.|\nThere are two common ways of rescaling:\n\n1. Min-Max scaling \n2. Standardisation (mean-0, sigma-1) \n\nHere, we will use Standardisation Scaling.","4ef93ef1":"K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.<br>\n\nThe algorithm works as follows:\n\n- First we initialize k points, called means, randomly.\n- We categorize each item to its closest mean and we update the mean\u2019s coordinates, which are the averages of the items categorized in that mean so far.\n- We repeat the process for a given number of iterations and at the end, we have our clusters.","5e1c449d":"<a id=\"1\"><\/a> <br>\n# Recency, Frequency,Monetary Value (RFM)\n\n> **What Is Recency, Frequency, Monetary Value (RFM)?\nRecency, frequency, monetary value is a marketing analysis tool used to identify a company's or an organization's best customers by using certain measures. The RFM model is based on three quantitative factors:\n\n\n1. Recency: How recently a customer has made a purchase\n\n2. Frequency: How often a customer makes a purchase\n\n3. Monetary Value: How much money a customer spends on purchases","137dca2e":"### Inference:\nK-Means Clustering with 3 Cluster Ids\n- Customers with Cluster Id 3 are the customers with high amount of transactions as compared to other customers.\n- Customers with Cluster Id 3 are frequent buyers.\n- Customers with Cluster Id 3 are not recent buyers and hence least of importance from business point of view.\n\n* most important customer is With Cluster id 2","d67ea3e1":"<a id=\"5\"><\/a> <br>\n## Step 5 : Final Analysis","a356211b":"#### Elbow Curve to get the right number of Clusters\nA fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k.","a9b73258":"#### There are 2 types of outliers and we will treat outliers as it can skew our dataset\n- Statistical\n- Domain specific","38bf96ab":"### Hierarchical Clustering\n\nHierarchical clustering involves creating clusters that have a predetermined ordering from top to bottom. For example, all files and folders on the hard disk are organized in a hierarchy. There are two types of hierarchical clustering, \n- Divisive \n- Agglomerative.","49dc143d":"# 1. Step 1 : Reading and Understanding Data","9da0cc1b":"**Average Linkage:<br>**\n\nIn average linkage hierarchical clustering, the distance between two clusters is defined as the average distance between each point in one cluster to every point in the other cluster. For example, the distance between clusters \u201cr\u201d and \u201cs\u201d to the left is equal to the average length each arrow between connecting the points of one cluster to the other.\n![](https:\/\/www.saedsayad.com\/images\/Clustering_average.png)","46a61591":"<a id=\"2\"><\/a> <br>\n## Step 2 : Data Cleaning ","2fe7051d":"**Single Linkage:<br>**\n\nIn single linkage hierarchical clustering, the distance between two clusters is defined as the shortest distance between two points in each cluster. For example, the distance between clusters \u201cr\u201d and \u201cs\u201d to the left is equal to the length of the arrow between their two closest points.\n![](https:\/\/www.saedsayad.com\/images\/Clustering_single.png)","09779df9":"<a id=\"4\"><\/a> <br>\n## Step 4 : Building the Model","44d2dc36":"#### We are going to analysis the Customers based on below 3 factors:\n- R (Recency): Number of days since last purchase\n- F (Frequency): Number of tracsactions\n- M (Monetary): Total amount of transactions (revenue contributed)","b838bfff":"### Silhouette Analysis\n\n$$\\text{silhouette score}=\\frac{p-q}{max(p,q)}$$\n\n$p$ is the mean distance to the points in the nearest cluster that the data point is not a part of\n\n$q$ is the mean intra-cluster distance to all the points in its own cluster.\n\n* The value of the silhouette score range lies between -1 to 1. \n\n* A score closer to 1 indicates that the data point is very similar to other data points in the cluster, \n\n* A score closer to -1 indicates that the data point is not similar to the data points in its cluster.","c4892179":"<a id=\"3\"><\/a> <br>\n## Step 3 : Data Preparation","b172841a":"### Finding the Optimal Number of Clusters"}}