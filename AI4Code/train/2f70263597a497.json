{"cell_type":{"193bba6b":"code","2199596d":"code","b59b382c":"code","9fbf6b0d":"code","14fa89a5":"code","459f8d39":"code","60fe0731":"code","38acc349":"code","6cb3330e":"code","c6de66a6":"code","9aaf033c":"code","42e41e7e":"code","3b8e2840":"code","01241e29":"code","0f5745c8":"code","853744a0":"code","3db24628":"code","21227741":"code","315348ea":"code","181774c5":"code","091cc8c1":"code","986eb85f":"code","060a9c28":"code","26333c4d":"code","00f76e39":"code","56337cf8":"code","97c867aa":"code","90cfff3a":"code","b07db3e0":"markdown","61728cd8":"markdown","fe98eea6":"markdown","a2fe66d9":"markdown","82d312c8":"markdown","e88926d9":"markdown","3991fc8d":"markdown","01360ddd":"markdown","7335ccb1":"markdown","2d41cc6c":"markdown"},"source":{"193bba6b":"#IMPORTING LIBRARIES\nimport tensorflow as tf\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator","2199596d":"#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\ntraining_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","b59b382c":"#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1.\/255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","9fbf6b0d":"#defining the CNN as a sequence of layers.\ncnn = tf.keras.models.Sequential()","14fa89a5":"#adding 1st Convolutional layer\n#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))\n#activation function relu is applied to decrease any linearity that might have arrised while applying filters.","459f8d39":"# applying max pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","60fe0731":"#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","38acc349":"#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","6cb3330e":"#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())","c6de66a6":"#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","9aaf033c":"#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))","42e41e7e":"#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","3b8e2840":"#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)","01241e29":"cnn.save('catdog_cnn_model.h5')","0f5745c8":"from keras.models import load_model \nclassifier = load_model('catdog_cnn_model.h5')","853744a0":"import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","3db24628":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg')","21227741":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","315348ea":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg')","181774c5":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","091cc8c1":"image.load_img('..\/input\/cat-1-2\/WhatsApp Image 2021-07-10 at 22.07.03.jpeg')","986eb85f":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","060a9c28":"image.load_img('..\/input\/dog-12\/WhatsApp Image 2021-07-10 at 22.07.03 (2).jpeg')","26333c4d":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","00f76e39":"image.load_img('..\/input\/cat-13\/WhatsApp Image 2021-07-10 at 22.07.03 (1).jpeg')","56337cf8":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","97c867aa":"image.load_img('..\/input\/dog-13\/WhatsApp Image 2021-07-10 at 22.07.03 (3).jpeg')","90cfff3a":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","b07db3e0":"**STEP -3 ) FLATTENING**","61728cd8":"**STEP - 2) APPLYING MAX POOLING**","fe98eea6":"**STEP - 4 ) FULL CONNECTION**","a2fe66d9":"**0 MEANS CATS AND 1 MEANS DOGS**","82d312c8":"**IT'S A CAT**","e88926d9":"**IT'S A DOG**","3991fc8d":"# HERE CNN IS DIVIDED INTO 4 STEPS\n**1. CONVOLUTION**\n\n**2. POOLING**\n\n**3. FLATTENING**\n\n**4. FULL CONNECTION**","01360ddd":"**STEP - 1) ADDING CONVOLUTIONAL LAYER**","7335ccb1":"# **PREDICTING VALUES**","2d41cc6c":"**CLASSIYING WHETHER THEIR IS A DOG OR A CAT IN A PICTURE USING CNN.**\n"}}