{"cell_type":{"86ea8beb":"code","a59a9e10":"code","c51ed34c":"code","7c54a2d9":"code","47bf7182":"code","030cf083":"code","dcd67898":"code","0ea4a51f":"code","959425ef":"code","1f6c30c8":"code","0dbbaeec":"code","decf3b3a":"code","bd5da11d":"code","54aa2eb8":"code","4351d622":"code","9020c618":"code","41444613":"code","773af338":"code","2f2add91":"code","5cd10be3":"code","17877a79":"code","dba9d8ff":"code","a44dc202":"code","03368b18":"code","88aedc4c":"code","99e21e4b":"code","b39498c9":"code","4e7c81cb":"code","378c50df":"code","009b3db5":"code","f94eb422":"code","0db045a3":"code","150b2988":"code","3efd615a":"code","394d7704":"code","e3065718":"code","37b4e57b":"markdown","f780765b":"markdown","2c0096fc":"markdown","76966721":"markdown","5c496734":"markdown","8c955430":"markdown","1fafade7":"markdown"},"source":{"86ea8beb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom pandas_datareader import data\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a59a9e10":"train_data = pd.read_csv('..\/input\/covid19-global-forecasting-week-1\/train.csv')\ntest_data = pd.read_csv('..\/input\/covid19-global-forecasting-week-1\/test.csv')\n\ndata = [train_data, test_data]\n","c51ed34c":"train_data.shape","7c54a2d9":"train_data.columns","47bf7182":"train_data.isnull().sum()","030cf083":"arr1 = train_data['Country\/Region'].unique()\narr2 = arr2 = [i for i in range(163)]\n\ncountry_dict = dict(zip(arr1, arr2))","dcd67898":"country_dict","0ea4a51f":"for dataset in data:\n    dataset['Country_int'] = dataset['Country\/Region'].map(country_dict).astype(int)","959425ef":"train_data.head()","1f6c30c8":"test_data.head()","0dbbaeec":"test_data.columns","decf3b3a":"for j in train_data['Country\/Region'].unique():\n    l = train_data[(train_data['Country\/Region'] == j)]\n    len_state = len(l['Province\/State'].unique())\n    \n    if len_state != 1:\n        arr_state1 = l['Province\/State'].unique()\n        arr_state2 = [i for i in range(1,len_state+1)]\n        state_dict = dict(zip(arr_state1, arr_state2))\n\n        for dataset in data:\n            dataset['Province\/State'] = dataset['Province\/State'].map(state_dict)","bd5da11d":"train_data[train_data['Country\/Region'] == 'China'].head()","54aa2eb8":"for dataset in data:\n    dataset['Province\/State'].fillna(0, inplace=True)","4351d622":"train_data.head()","9020c618":"X= train_data.iloc[:,0:2]\nY = train_data.iloc[:,2]","41444613":"type(train_data.Date)","773af338":"for dataset in data:\n    dataset['Date'] = pd.to_datetime(dataset['Date'])","2f2add91":"for dataset in data:\n    dataset['Day'] = dataset.Date.apply(lambda x: x.day)\n    dataset['Month'] = dataset.Date.apply(lambda x: x.month)","5cd10be3":"train_data['ConfirmedCases'] = train_data['ConfirmedCases'].astype(int)\ntrain_data['Fatalities'] = train_data['Fatalities'].astype(int)","17877a79":"corr = train_data.corr()\nplt.figure(figsize=(11,7))\nsns.heatmap(corr, annot=True)","dba9d8ff":"X = train_data.drop(['Id', 'Country\/Region', 'Lat', 'Long', 'Date', 'ConfirmedCases', 'Fatalities', 'Province\/State'], axis=1)\ny1 = train_data['ConfirmedCases']\ny2 = train_data['Fatalities']\nX_test = test_data.drop(['ForecastId', 'Country\/Region', 'Lat', 'Long', 'Date', 'Province\/State'], axis=1)","a44dc202":"rt= DecisionTreeRegressor(random_state=0)\nmodel_r = rt.fit(X, y1)\n","03368b18":"XGB_regressor = XGBRegressor()\nXGB_regressor.fit(X, y1)\nXGB_regressor.score(X, y1)","88aedc4c":"y_pred = XGB_regressor.predict(X_test)","99e21e4b":"Random_Forest_regressor = RandomForestRegressor()\nRandom_Forest_regressor.fit(X, y1)\nRandom_Forest_regressor.score(X, y1)","b39498c9":"from sklearn import tree\nimport graphviz\ndot_data = tree.export_graphviz(rt, feature_names=list(X), class_names=sorted(Y.unique()), filled=True)\ngraphviz.Source(dot_data)","4e7c81cb":"FatalitiesPred = XGB_regressor.predict(X_test)\nFatalitiesPred = pd.DataFrame(FatalitiesPred, columns=['Fatalities'])","378c50df":"ConfirmedCasesPred = XGB_regressor.predict(X_test)\nConfirmedCasesPred = pd.DataFrame(ConfirmedCasesPred, columns=['ConfirmedCases'])","009b3db5":"ForecastId = test_data.ForecastId\nForecastId = pd.DataFrame(ForecastId)","f94eb422":"pred_file = pd.concat([ForecastId, ConfirmedCasesPred, FatalitiesPred], axis=1)","0db045a3":"pred_file.head()","150b2988":"pred_file.describe()","3efd615a":"Y_true = [X_test]  # Y_true = Y (original values)\n  \n# Calculated values\nY_pred = [pred_file]  # Y_pred = Y'\n  \n# Mean Squared Error\nMSE = np.square(np.subtract(Y_true,Y_pred)).mean()","394d7704":"MSE","e3065718":"pred_file.to_csv('submission.csv', index=False)","37b4e57b":"#  Casting to a specified dtype","f780765b":"# Selecting Target & Feature Variables","2c0096fc":"# creating a grid","76966721":"# Creating a model","5c496734":"# Visualing model","8c955430":"# Pred","1fafade7":"# Importing Dataset"}}