{"cell_type":{"0fe1ef35":"code","65e1bd51":"code","19fdacf5":"code","d2ab4c2a":"code","34de5e3a":"code","71d63480":"code","4caec9ea":"code","2c826c4f":"code","46af8f1a":"code","73a4e30f":"markdown","e5ba6194":"markdown","4cbe2300":"markdown","180f927d":"markdown"},"source":{"0fe1ef35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport pickle\nfrom sklearn import preprocessing\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport sys\nimport os\nfrom sklearn.metrics import recall_score\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print (os.path.join(dirname, filename))\n\nsys.path.append('\/kaggle\/input\/enrondataset\/')\nfrom feature_format import featureFormat as ft\nfrom feature_format import targetFeatureSplit as tfs\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65e1bd51":"real = \"\/kaggle\/input\/enrondataset\/final_project_dataset.pkl\"\nfinal = \"final_project_dataset_unix.pkl\"\n\nc = ''\noutsize = 0\nwith open(real, 'rb') as data:\n    c = data.read()\nwith open(final, 'wb') as output:\n    for i in c.splitlines():\n        outsize += len(i) + 1\n        output.write(i + str.encode('\\n'))","19fdacf5":"final_data = pickle.load(open(\"\/kaggle\/input\/enrondataset\/final_project_dataset_unix.pkl\", 'rb') )\n\nfinal_data.pop('TOTAL')\np1 = ft(final_data, ['poi','salary','total_payments'])\n\nprint(\"The number of people in the dataset:\",len(final_data))\nprint(list(final_data.keys())[0],\"\\n\",final_data[list(final_data.keys())[0]])\n\nfor z in range(len(p1)):\n        if p1[z][0]==True:\n            plt.scatter(p1[z][1],p1[z][2],color = 'b')\n        else:\n            plt.scatter(p1[z][1],p1[z][2],color = 'g')\n\nplt.ylabel('total_payments')\nplt.xlabel('salary')   \nplt.show()\nplt.figure(figsize=(10,10))\np2=ft(final_data,[\"poi\",\"total_payments\",\"loan_advances\"])\nfor z in range(len(p2)):\n    if p2[z][0]==True:\n        plt.scatter(p2[z][1],p2[z][2],color='b')\n    else:\n        plt.scatter(p2[z][1],p2[z][2],color='g')\nplt.ylabel('loan_advances')\nplt.xlabel('total_payments')   \nplt.show()\nplt.figure(figsize=(10,10))        \np3=ft(final_data,[\"poi\",\"total_stock_value\",\"exercised_stock_options\"])\nfor z in range(len(p3)):\n    if p3[z][0]==True:\n        plt.scatter(p3[z][1],p3[z][2],color='b')\n    else:\n        plt.scatter(p3[z][1],p3[z][2],color='g')\nplt.ylabel('exercised_stock_options')\nplt.xlabel('total_stock_value')   \nplt.show()\nplt.figure(figsize=(10,10))        \np4=ft(final_data,[\"poi\",\"salary\",\"loan_advances\",\"deferral_payments\"])\nfor z in range(len(p4)):\n    if p4[z][0]==True:\n        plt.scatter(p4[z][1],p4[z][2],color='b')\n    else:\n        plt.scatter(p4[z][1],p4[z][2],color='g')\nplt.ylabel('loan_advances')\nplt.xlabel('salary')   \nplt.show()\nplt.figure(figsize=(10,10))        \n","d2ab4c2a":"def dict_to_list(key,normalizer):\n    new_list=[]\n\n    for i in final_data:\n        if final_data[i][key]==\"NaN\" or final_data[i][normalizer]==\"NaN\":\n            new_list.append(0.)\n        elif final_data[i][key]>=0:\n            new_list.append(float(final_data[i][key])\/float(final_data[i][normalizer]))\n    return new_list\n\nfraction_from_poi_email=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\nfraction_to_poi_email=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\nj = 0\nfor i in final_data:\n    final_data[i][\"fraction_from_poi_email\"]=fraction_from_poi_email[j]\n    final_data[i][\"fraction_to_poi_email\"]=fraction_to_poi_email[j]\n    j+=1","34de5e3a":"final_feature_list = ['poi','shared_receipt_with_poi','fraction_from_poi_email','fraction_to_poi_email',\"deferral_payments\"]\nk = ft(final_data, final_feature_list)\nlabels, features = tfs(k)","71d63480":"X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size = 0.15)\nreg = LogisticRegression()\nx1=reg.fit(X_train,Y_train)\nprint(accuracy_score(Y_test, x1.predict(X_test)))","4caec9ea":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier()\nx2=clf.fit(X_train,Y_train)\nprint(accuracy_score(Y_test, x2.predict(X_test)))","2c826c4f":"from sklearn import svm\nclf2=svm.SVC()\nx3=clf2.fit(X_train,Y_train)\nprint(accuracy_score(Y_test, x3.predict(X_test)))","46af8f1a":"pickle.dump(final_data, open(\"my_dataset.pkl\", \"wb\") )\npickle.dump(final_feature_list, open(\"my_feature_list.pkl\", \"wb\") )\npickle.dump(x1, open(\"my_classifier.pkl\", \"wb\") )","73a4e30f":"***SVC***","e5ba6194":"***DECISION TREE CLASSIFIER***","4cbe2300":"***LOGISTIC REGRESSION***","180f927d":"**USING DIFFERENT ALGOS TO PREDICT ACCURACY**"}}