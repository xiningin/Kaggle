{"cell_type":{"f360048c":"code","f7d2f7d6":"code","f35dfc4d":"code","8d169973":"code","6580b2c1":"code","2384546d":"code","9257cb13":"code","679baf3f":"code","1efc7aef":"code","d12cf908":"code","eba534a8":"code","d11c6363":"code","ef872125":"code","35f972de":"code","20a0320d":"code","f4857b45":"code","eb8b493a":"code","18e8001a":"code","9c78cd24":"code","175ece6a":"code","764fae36":"code","950b2f9b":"code","210e8d74":"code","d3a1d309":"code","be7b97b4":"code","3c6fabe9":"code","9c3d8c4e":"code","bcface22":"code","b36633a1":"markdown","5e4bee6d":"markdown","7a4bf49f":"markdown","5aded74a":"markdown","50e1564e":"markdown","99e5b8f0":"markdown","d3365d6b":"markdown","2af269e9":"markdown","14060c5f":"markdown","a0e0b15c":"markdown"},"source":{"f360048c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f7d2f7d6":"import matplotlib.pyplot as plt\nimport seaborn as sns","f35dfc4d":"df=pd.read_csv('\/kaggle\/input\/fashion-clothing-products-catalog\/myntra_products_catalog.csv')","8d169973":"df.head()","6580b2c1":"df.info()","2384546d":"df1=df.groupby('ProductBrand')['ProductID'].count().sort_values(ascending=False).head(30)\ndf1.plot.bar()","9257cb13":"df1=df.groupby('ProductBrand')['Price (INR)'].mean().sort_values(ascending=False).head(30)\ndf1.plot.bar()","679baf3f":"df.groupby('Gender')['ProductID'].count().plot.pie(autopct=\"%1.1f%%\")","1efc7aef":"df2=df[df['Price (INR)']<10000]\ndf2['Price (INR)'].plot.hist()","d12cf908":"df.groupby('PrimaryColor')['ProductID'].count().plot.bar()","eba534a8":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\n\nlist_stopwords = set(stopwords.words('english'))","d11c6363":"df_nlp=df.copy()","ef872125":"df_nlp['ProductName2'] = df_nlp['ProductName'].str.lower()\ndf_nlp['ProductName2'] = df_nlp['ProductName2'].apply(word_tokenize)\ndf_nlp['ProductName2'] = df_nlp['ProductName2'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf_nlp['ProductName2'] = df_nlp['ProductName2'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf_nlp['ProductName2'] = df_nlp['ProductName2'].apply(lambda x : [word for word in x if len(word) > 1])","35f972de":"df_nlp['Description'] = df_nlp['Description'].str.lower()\ndf_nlp['Description'] = df_nlp['Description'].apply(word_tokenize)\ndf_nlp['Description'] = df_nlp['Description'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf_nlp['Description'] = df_nlp['Description'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf_nlp['Description'] = df_nlp['Description'].apply(lambda x : [word for word in x if len(word) > 1])","20a0320d":"df_nlp","f4857b45":"df_product=df_nlp['ProductName2'].explode()\ndf_product=pd.DataFrame(df_product)","eb8b493a":"pd.set_option('display.max_rows', 150)","18e8001a":"df_product.groupby('ProductName2')['ProductName2'].count().sort_values(ascending=False).head(150)","9c78cd24":"pip install wordcloud","175ece6a":"from wordcloud import WordCloud","764fae36":"df_shirt=df_nlp[df_nlp['ProductName'].str.contains('shirt|Shirt')]\ntext1 = df_shirt['Description']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'black',\n    stopwords = list_stopwords).generate(str(text1))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","950b2f9b":"text1_2 = df_shirt['ProductName2']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'black',\n    stopwords = list_stopwords).generate(str(text1_2))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","210e8d74":"df_jeans=df_nlp[df_nlp['ProductName'].str.contains('jeans|Jeans')]\ntext2 = df_jeans['Description']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'blue',\n    stopwords = list_stopwords).generate(str(text2))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","d3a1d309":"text2_2 = df_jeans['ProductName2']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'blue',\n    stopwords = list_stopwords).generate(str(text2_2))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","be7b97b4":"df_watch=df_nlp[df_nlp['ProductName'].str.contains('watch|Watch')]\ntext3 = df_watch['Description']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'green',\n    stopwords = list_stopwords).generate(str(text3))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","3c6fabe9":"text3_2 = df_watch['ProductName2']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'green',\n    stopwords = list_stopwords).generate(str(text3_2))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","9c3d8c4e":"df_bag=df_nlp[df_nlp['ProductName'].str.contains('bag|Bag')]\ntext4 = df_bag['Description']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'yellow',\n    stopwords = list_stopwords).generate(str(text4))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","bcface22":"text4_2 = df_bag['ProductName2']\nwordcloud = WordCloud(\n    width = 1500,\n    height = 1000,\n    background_color = 'yellow',\n    stopwords = list_stopwords).generate(str(text4_2))\nfig = plt.figure(\n    figsize = (20, 15),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","b36633a1":"![elle-ss18-trend-report-2a-1508859946.jpg](attachment:bedffe4f-b7aa-41a9-aa83-d59ea6718f65.jpg)\nimage from https:\/\/fashionableway.org\/cycle-of-fashion-trend\/","5e4bee6d":"# 2-1) I tired to find what kind of product categories are included in data.","7a4bf49f":"# 2-2) What is the trend in Shirt ?","5aded74a":"# 2 NLP Analysis to find trend","50e1564e":"# 2-4) What is the trend in Bag ?","99e5b8f0":"# 2-3) What is the trend in Watch ?","d3365d6b":"# 2-3) What is the trend in Jeans ?","2af269e9":"# I tried to find what is the trend in 'Shirt', 'Jeans', 'Watch' and 'Bag'.\n# By considering mords which used in 'Product Name' and 'Product Description', I analyzed whiat is the trend in each product categories.\n# \n# 1) Shirt\n\n# Prined or colored shirt will be cool now. Eapecially, blue shirt is popular this season. Slim will be also better this season.\n\n# 2) Jeans\n\n# Washed blue jeans are still popular. And 5 pocket may be nice. Skinny jeans is still popular this season.\n\n# 3) Watch\n\n# Octane is popular, especially,hyper lume and titan are popilar this season.\n\n# 4) Bag\n\n# Trolley bag is popular. And DKNY unisex bags will be also popular.","14060c5f":"# 1 Data preprocessing and visualization","a0e0b15c":"# I found the product categories,'shirt','tshirt','jeans','top','dress','trousers','sneakers','shoes','watch','sweatshirt','bag','heels','bra','sandals','jacket' etc...."}}