{"cell_type":{"5e81c3b2":"code","2de01afa":"code","0689e30f":"code","32b43f47":"code","7f1a28c8":"code","b296e18d":"code","1c0b5276":"code","4497db7c":"code","0b9df003":"code","87c49f7a":"code","2d9b5a96":"code","f193e7e3":"code","1fe05668":"code","7efb972b":"code","59fb0d42":"code","cd420630":"code","6b86c15c":"code","aed6a3c3":"code","24c80169":"code","863b7027":"code","409ebd9a":"code","9f9ee689":"code","3ec01d87":"code","2cc0afa6":"code","54d7adc7":"code","e5348f0b":"code","a1c24534":"code","d9259bac":"code","cca66023":"code","df8dcd1d":"markdown","5791bccd":"markdown","8df5a043":"markdown","91e1f8fb":"markdown","936e48e6":"markdown","49261182":"markdown","f2997ec7":"markdown","9164e139":"markdown","91a1f5de":"markdown","3b27bc96":"markdown","0454eb9c":"markdown","5882ff50":"markdown","dc737116":"markdown"},"source":{"5e81c3b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2de01afa":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nsample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","0689e30f":"sample_submission.head()","32b43f47":"train","7f1a28c8":"test","b296e18d":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncorr = train.corr(method = 'pearson')\nplt.figure(figsize=(12,9))\nsns.heatmap(corr, square = True, cmap = 'Blues')\n\nplt.show()","1c0b5276":"cols = corr.nlargest(10, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nplt.figure(figsize=(15,12))\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 15}, yticklabels=cols.values, xticklabels=cols.values, cmap = 'Blues')\nplt.show()","4497db7c":"sns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train[cols], size = 2.5)\nplt.show()","0b9df003":"train[cols].isnull().sum()","87c49f7a":"for i in range(7):\n    s = 710+i+1\n    plt.subplot(s)\n    plt.title(cols[i])\n    plt.boxplot(train[cols[i]], vert=0)\n    plt.show()","2d9b5a96":"train_corr = train[cols]\ntrain_outlier = pd.DataFrame(columns=cols)\nfor c in train_corr.columns:\n    quartile_1 = train_corr[c].quantile(0.25)\n    quartile_3 = train_corr[c].quantile(0.75)\n    IQR = quartile_3 - quartile_1\n    condition = (train_corr[c] >= (quartile_1 - 1.5 * IQR)) & (train_corr[c] <= (quartile_3 + 1.5 * IQR))\n    train_outlier[c]=train_corr[c][condition]","f193e7e3":"train_outlier","1fe05668":"train_outlier.dropna(inplace=True)","7efb972b":"target = train_outlier['SalePrice']\ndata = train_outlier[train_outlier.columns[1:]]\nfrom sklearn.model_selection import train_test_split\ndata_train, data_test, target_train, target_test = train_test_split(data, target, random_state = 0)","59fb0d42":"from sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom imblearn.pipeline import Pipeline\nimport sklearn.svm as svm\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('scaler', StandardScaler(), ['GrLivArea', 'TotalBsmtSF', 'YearBuilt'])])\n\nestimator = svm.SVR()\npipeline = Pipeline([('preprocessing', preprocessor), ('regression', estimator)])","cd420630":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nstratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\nparams = {\n    'regression__kernel': ['linear'],\n    'regression__C': [1, 10, 20, 40, 100],\n    'regression__epsilon': [0.01, 0.1]}\n\ngrid_search_estimator = GridSearchCV(pipeline, param_grid=params, cv=stratified_10_fold_cv, refit=True, n_jobs=-1)\ngrid_search_estimator.fit(data_train, target_train)","6b86c15c":"from sklearn.model_selection import cross_val_predict\n\nprediction = cross_val_predict(grid_search_estimator.best_estimator_, data_test, target_test)","aed6a3c3":"from sklearn.metrics import mean_squared_error\n\nMSE = mean_squared_error(target_test, prediction)\nRMSE = np.sqrt(MSE)\n\nprint(\"svr best RMSE :\", RMSE)\nprint(grid_search_estimator.best_params_)","24c80169":"test.head()","863b7027":"cols = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\ntest = test[cols]","409ebd9a":"test.isnull().sum()","9f9ee689":"import collections\n\nfor i in test[test['GarageCars'].isnull()].index:\n    test['GarageCars'][i] = collections.Counter(test[test['OverallQual']==test['OverallQual'][i]][test['FullBath']==test['FullBath'][i]]['GarageCars']).most_common(1)[0][0]\nfor i in test[test['TotalBsmtSF'].isnull()].index:\n    test['TotalBsmtSF'][i] = collections.Counter(test[test['OverallQual']==test['OverallQual'][i]][test['FullBath']==test['FullBath'][i]]['TotalBsmtSF']).most_common(1)[0][0]","3ec01d87":"test.isnull().sum()","2cc0afa6":"estimator = svm.SVR(kernel='linear', C=100, epsilon=0.1)\npipeline = Pipeline([('preprocessing', preprocessor), ('regression', estimator)])","54d7adc7":"train","e5348f0b":"pipeline.fit(data, target)","a1c24534":"prediction = pipeline.predict(test)\nMSE = mean_squared_error(sample_submission['SalePrice'], prediction)\nRMSE = np.sqrt(MSE)\n\nprint(\"svr best RMSE :\", RMSE)\nprint(grid_search_estimator.best_params_)","d9259bac":"sample_submission['SalePrice'] = prediction","cca66023":"sample_submission.to_csv('submission.csv',index = False)","df8dcd1d":"#### I got help from the following link.\nhttps:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\/notebook","5791bccd":"### best_parameter : regression__C': 100, 'regression__epsilon': 0.1, 'regression__kernel': 'linear'","8df5a043":"#### dropna","91e1f8fb":"### Outlier","936e48e6":"#### 'TotRmsAbvGrd' and 'GrLivArea', 'TotalBsmtSF' and '1stFlrSF', 'GarageCars' and 'GarageArea'\n#### These are each very similar.\n#### -> Drop","49261182":"### Load Datasets","f2997ec7":"#### rows : 1460 -> 1399","9164e139":"## Fill Null data","91a1f5de":"## Confirm Null data","3b27bc96":"#### There's no null data.","0454eb9c":"#### Make submission","5882ff50":"#### select top 10 corr","dc737116":"### SVM(SVR)"}}