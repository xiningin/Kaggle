{"cell_type":{"f6f0760b":"code","fa801afb":"code","5de34a2a":"code","0470600c":"code","15a97136":"code","25bb534e":"code","a13c55db":"code","f87ed3b7":"code","895a75c2":"code","74d908d3":"code","81172139":"code","f6d30ebb":"code","f71dba6b":"code","b09f5a7a":"code","9c064a4d":"code","1aa6db42":"code","53f8461e":"code","9481aed6":"code","698d8b3f":"markdown","b9fec532":"markdown","0a931f56":"markdown","34aa0b8e":"markdown","4a570666":"markdown","9b9cbfa5":"markdown","6f68f288":"markdown","5ff9c390":"markdown","0384cef4":"markdown","74677e75":"markdown","834cdd0c":"markdown"},"source":{"f6f0760b":"#importing libaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","fa801afb":"#importing dataset\nds = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","5de34a2a":"#reviewing dataset\nds.head()","0470600c":"#checking type of feaures\nds.info()","15a97136":"#dataset has 303 rows and 14 columns\nds.shape","25bb534e":"#checking for null values\nds.isnull().sum()","a13c55db":"#Plotting the distribution plot.\nplt.figure(figsize=(12,10))\np = 1\nfor i in ds:\n    if p<14:\n        plt.subplot(4,4,p)\n        sns.histplot(ds[i])\n        plt.xlabel(i)\n    p += 1\n    plt.tight_layout()\nplt.show()","f87ed3b7":"plt.figure(figsize=(16,14))\nsns.heatmap(ds.corr(), cmap='Blues', annot = True)\nplt.title(\"Correlation Map\", fontweight = \"bold\", fontsize=16)","895a75c2":"#defining dependent and independent variables\nx = ds.drop('target',axis = 1)\ny = ds['target']","74d908d3":"#splitting data into training and testing set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","81172139":"#training model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter = 10000)\nlr.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\ny_pred = lr.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nlra = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',lra)\nprint(\"Classification Report\",classification_report(y_test,y_pred))","f6d30ebb":"#training model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',p = 2)\nknn.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\ny_pred = knn.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nknna = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))\nprint(\"Classification Report\",classification_report(y_test,y_pred))","f71dba6b":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'linear')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva =accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))\nprint(\"Classification Report\",classification_report(y_test,y_pred))","b09f5a7a":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'rbf')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva2 = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))\nprint(\"Classification Report\",classification_report(y_test,y_pred))","9c064a4d":"#training model\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\ny_pred = nb.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nnba = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))\nprint(\"Classification Report\",classification_report(y_test,y_pred))","1aa6db42":"#training model\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'entropy')\ndt.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\ny_pred = dt.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\ndta = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))\nprint(\"Classification Report\",classification_report(y_test,y_pred))","53f8461e":"#training model\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 60, criterion = 'entropy',random_state = 0)\nrf.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report\ny_pred = rf.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nrfa = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))\nprint(\"Classification Report\",classification_report(y_test,y_pred))","9481aed6":"#comparing accuracies\nplt.figure(figsize= (8,7))\nac = [lra,knna,sva,sva2,nba,dta,rfa]\nname = ['Logistic Regression','knn','svm','Kernel Svm','Naive Bayes','Decision Tree', 'Random Forest']\nsns.barplot(x = ac,y = name,palette='pastel')\nplt.title(\"Plotting the Model Accuracies\", fontsize=16, fontweight=\"bold\")","698d8b3f":"**NAIVE BAYES**","b9fec532":"**SVM**","0a931f56":"**KERNEL SVM**","34aa0b8e":"**KNN**","4a570666":"**RANDOM FOREST**","9b9cbfa5":"**PREDICTING WHETHER A PATIENT HAS A HEART DISEASE OR NOT USING VARIOUS CLASSIFICATION MODELS.**\n\n**DATASET DESCRIPTION**\n\n**age** - age in years\n\n**sex** - (1 = male; 0 = female)\n\n**cp** - chest pain type\n\n**trestbps** - resting blood pressure (in mm Hg on admission to the hospital)\n\n**chol** - serum cholestoral in mg\/dl\n\n**fbs** - (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\n**restecg** - resting electrocardiographic results\n\n**thalach** - maximum heart rate achieved\n\n**exang** - exercise induced angina (1 = yes; 0 = no)\n\n**oldpeak** - ST depression induced by exercise relative to rest\n\n**slope** - the slope of the peak exercise ST segment\n\n**ca** - number of major vessels (0-3) colored by flourosopy\n\n**thal** - 3 = normal; 6 = fixed defect; 7 = reversable defect\n\n**target** - have disease or not (1=yes, 0=no)","6f68f288":"**LOGISTIC REGRESSION**","5ff9c390":"**DECISION TREE**","0384cef4":"**APPLYING MODELS**","74677e75":"**NO NULL VALUES**","834cdd0c":"**NO SIGNIFICANT CORRELATION**"}}