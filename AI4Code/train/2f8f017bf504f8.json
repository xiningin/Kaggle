{"cell_type":{"c75a2721":"code","b5a54efa":"code","9dd48b5d":"code","9188e449":"code","1f7d470d":"code","495bf965":"code","af0bb7f5":"code","8c7ad8f3":"code","05d827aa":"code","01ea47df":"code","154c6e08":"code","566fec4b":"code","76a5aaa3":"code","47bba28b":"code","f6f8592e":"code","e0b3ebea":"code","9fe79f2f":"code","9fa8a731":"code","2c7039f5":"markdown","921c072c":"markdown","4049e3dc":"markdown","e791aa38":"markdown","e6a0ea40":"markdown","a8805638":"markdown"},"source":{"c75a2721":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5a54efa":"data = pd.read_csv('..\/input\/youtube-new\/USvideos.csv')","9dd48b5d":"data.head()","9188e449":"# Data frames from dictionary\ncountry = ['Spain','France']\npopulation = ['11','12']\nlist_label = ['country','population']\nlist_col = [country,population]\nzipped = list(zip(list_label, list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","1f7d470d":"# Add new columns\ndf['capital'] = ['Madrid','Paris']\ndf","495bf965":"# Broadcasting\ndf['income'] = 0 #broadcastion entire column\ndf","af0bb7f5":"# Plotting all data \ndata1 = data.loc[:,[\"views\",\"likes\",\"dislikes\"]]\ndata1.plot()\n# it is confusing","8c7ad8f3":"# subplots\ndata1.plot(subplots = True)\nplt.show()","05d827aa":"# Scatter plot\ndata1.plot(kind = \"scatter\",x=\"likes\",y = \"dislikes\")\nplt.show()","01ea47df":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"likes\",bins = 50,range= (0,250))","154c6e08":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"likes\",bins = 50,range= (0,250),ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"likes\",bins = 50,range= (0,250),ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","566fec4b":"data.describe()","76a5aaa3":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # date is string\n# we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","47bba28b":"# In order practice lets take head of youtube data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\", \"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n#lets make date as index\ndata2 = data2.set_index(\"date\")\ndata2","f6f8592e":"# we will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","e0b3ebea":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","9fe79f2f":"# In real life (data is real. Not create from us like data2) we can solve this problem with interpolate\n# We can interpolate from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","9fa8a731":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","2c7039f5":"# RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method  over different time intervals\n     *   Needs string to specify frequency lime \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like 'linear','time' or 'index'","921c072c":"# BUILDING DATA FRAMES FROM SCATCH\n* Also we can build dataframe from dictionaries\n* zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","4049e3dc":"# 4. PANDAS FOUNDATION\n\n\n\n**REVIEW of PANDAS**\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n","e791aa38":"### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","e6a0ea40":"# INDEXING PANDAS TIME SERIES\n\n* datatime = object\n* parse_dates(boolean):Transform date or ISO 8601 (yyyy-mm-dd hh:mm:ss) format\n","a8805638":"### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"}}