{"cell_type":{"b93bb09e":"code","40c175fc":"code","3653f87e":"code","0baa6825":"code","f2f5d7a6":"code","46040d33":"code","e8e4a73d":"code","b28a5d5a":"code","33253f49":"code","e8169c64":"code","f6f2425f":"code","0cb508be":"code","ba9412f7":"code","61428c57":"code","2aea9d27":"code","855ed379":"code","4c3c257d":"code","0e05541d":"code","343fd404":"code","4ab41974":"code","c44135db":"code","d00fc0ff":"markdown","5f9ec137":"markdown","beaa502a":"markdown"},"source":{"b93bb09e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","40c175fc":"import pandas as pd\nitem_categories = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nitems = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nsales = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\nsample_submission = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nshops = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\ntest = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/test.csv\")","3653f87e":"!ls \/kaggle\/input\/*\n","0baa6825":"# Basic packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rd # generating random numbers\nimport datetime # manipulating date formats\n# Viz\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots\n\n\n# TIME SERIES\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","f2f5d7a6":"sales.head()","46040d33":"shops.head()","e8e4a73d":"# The datatype of date field is object. It needs to be chaged to Date-Time format. \nsales.info()","b28a5d5a":"#formatting the date column correctly\nsales.date = sales.date.apply(lambda x : datetime.datetime.strptime(x,'%d.%m.%Y'))\nprint(sales.info())","33253f49":"monthly_sales = sales.groupby(['date_block_num','shop_id','item_id'])['date','item_price','item_cnt_day'].agg({'date': ['min','max'],'item_price':'mean','item_cnt_day':'sum'})","e8169c64":"monthly_sales.head(100)","f6f2425f":"x = items.groupby('item_category_id').agg({'item_id':'count'})\n#x=x.sort_values(by='item_id',ascending=False)\nx=x.reset_index()\nprint(x)\n\n\nplt.figure(figsize=(25,15))\nax = sns.barplot(x.item_category_id, x.item_id)\nplt.title(\"No. Items per Category\")\nplt.ylabel('# of items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","0cb508be":"ts = sales.groupby('date_block_num')['item_cnt_day'].sum()\nts_sns = ts.reset_index()\n","ba9412f7":"plt.figure(figsize=(15,10))\nax = sns.lineplot(ts_sns.date_block_num,ts_sns.item_cnt_day)\nplt.show()","61428c57":"plt.figure(figsize=(16,6))\nplt.plot(ts.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(ts.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","2aea9d27":"import statsmodels.api as sm\n# multiplicative\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"multiplicative\")\nfig = res.plot()\nfig.show()","855ed379":"# Additive model\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"additive\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","4c3c257d":"# Stationarity tests\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n    \ntest_stationarity(ts)\n\n","0e05541d":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)): #12 to 32\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob\n","343fd404":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts_a=difference(ts)\nplt.plot(new_ts_a)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","4ab41974":"# now testing the stationarity again after de-seasonality\ntest_stationarity(new_ts)","c44135db":"test_stationarity(new_ts_a)","d00fc0ff":"we assume an additive model, then we can write\n\n> yt=St+Tt+Et \n\nwhere yt is the data at period t, St is the seasonal component at period t, Tt is the trend-cycle component at period tt and Et is the remainder (or irregular or error) component at period t\nSimilarly for Multiplicative model,\n\n> yt=St  x Tt x Et \n\n## Stationarity:\n\n![q](https:\/\/static1.squarespace.com\/static\/53ac905ee4b003339a856a1d\/t\/5818f84aebbd1ac01c275bac\/1478031479192\/?format=750w)\n\nStationarity refers to time-invariance of a series. (ie) Two points in a time series are related to each other by only how far apart they are, and not by the direction(forward\/backward)\n\nWhen a time series is stationary, it can be easier to model. Statistical modeling methods assume or require the time series to be stationary.\n\n\nThere are multiple tests that can be used to check stationarity.\n* ADF( Augmented Dicky Fuller Test) \n* KPSS \n* PP (Phillips-Perron test)\n\nLet's just perform the ADF which is the most commonly used one.\n\nNote: [Step by step guide to perform dicky fuller test in Excel](http:\/\/www.real-statistics.com\/time-series-analysis\/stochastic-processes\/dickey-fuller-test\/)\n\n[Another Useful guide](http:\/\/www.blackarbs.com\/blog\/time-series-analysis-in-python-linear-models-to-garch\/11\/1\/2016#AR) \n\n[good reference](https:\/\/github.com\/ultimatist\/ODSC17\/blob\/master\/Time%20Series%20with%20Python%20(ODSC)%20STA.ipynb)\n","5f9ec137":"### Now after the transformations, our p-value for the DF test is well within 5 %. Hence we can assume Stationarity of the series\n\n\nFind out, if our time-series is in AR process or MA process?","beaa502a":"Quick observations: There is an obvious \"seasonality\" (Eg: peak sales around a time of year) and a decreasing \"Trend\".\n\nLet's check that with a quick decomposition into Trend, seasonality and residuals.\n\n* https:\/\/machinelearningmastery.com\/decompose-time-series-data-trend-seasonality\/\n\n* https:\/\/medium.com\/better-programming\/a-visual-guide-to-time-series-decomposition-analysis-a1472bb9c930"}}