{"cell_type":{"a254505e":"code","87c6b9f8":"code","0e81b306":"code","a330e572":"code","47602b2d":"code","905ed2af":"code","794d9f12":"code","0ab18d42":"code","956bcb55":"code","39ae5b03":"code","0f6227cc":"code","5d046644":"code","827fc64c":"code","902690ee":"code","e20ae4f9":"code","a4497570":"code","3430ef58":"code","b28fc1b2":"code","db991aa9":"code","67fc65a2":"code","40446eb7":"code","f2125de8":"code","6761bf19":"code","cc9e086f":"code","ba1189b3":"code","0296afcd":"code","6c88630a":"markdown","e5e9de1e":"markdown","b44f3291":"markdown","50ec456a":"markdown","4d6af423":"markdown","5e8e6b88":"markdown","bf783790":"markdown","063fe7c6":"markdown","93372ebe":"markdown","1337dbc5":"markdown","8ade00ad":"markdown","205d261b":"markdown","79236154":"markdown","94f4fdf4":"markdown","84db0fd1":"markdown","c78886df":"markdown","af2f5f49":"markdown","f3f5163a":"markdown","24d7a405":"markdown"},"source":{"a254505e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87c6b9f8":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","0e81b306":"print(train.shape)\nprint(test.shape)","a330e572":"train_data = np.array(train,dtype='float32')\ntest_data = np.array(test,dtype='float32')","47602b2d":"X_train = train_data[:,1:]\/255\ny_train = train_data[:,0]\ntest = test_data[:,0:]\/255","905ed2af":"print(X_train.shape)\nprint(y_train.shape)","794d9f12":"print(X_train.max())\nprint(X_train.min())","0ab18d42":"import matplotlib.pyplot as plt\nplt.imshow(X_train[10].reshape(28,28))","956bcb55":"import tensorflow","39ae5b03":"print(y_train[10])\ny_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=10)\nprint(y_train[10])","0f6227cc":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import regularizers, optimizers","5d046644":"def train_and_test_loop(iterations, lr, Lambda, verb=True):\n\n    ## hyperparameters\n    iterations = iterations\n    learning_rate = lr\n    hidden_nodes = 256\n    output_nodes = 10\n        \n    model = Sequential()\n    model.add(Dense(hidden_nodes, input_shape=(784,), activation='relu'))\n    model.add(Dense(hidden_nodes, activation='relu'))\n    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n    \n    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    \n    # Fit the model\n    model.fit(X_train, y_train, epochs=iterations,batch_size=500, verbose= 1)","827fc64c":"def train_and_test_loop1(iterations, lr, Lambda, verb=True):\n\n    ## hyperparameters\n    iterations = iterations\n    learning_rate = lr\n    hidden_nodes = 256\n    output_nodes = 10\n        \n    model = Sequential()\n    model.add(Dense(hidden_nodes, input_shape=(784,), activation='relu'))\n    model.add(Dense(hidden_nodes, activation='relu'))\n    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n    \n    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    \n    # Fit the model\n    model.fit(X_train, y_train, epochs=iterations,batch_size=500, verbose= 1)\n    score = model.evaluate(X_train, y_train, verbose=0)\n    \n    return score","902690ee":"lr = 0.00001\nLambda = 0\ntrain_and_test_loop(1, lr, Lambda)","e20ae4f9":"lr = 0.00001\nLambda = 1e3\ntrain_and_test_loop(1, lr, Lambda)","a4497570":"lr = 1e-7\nLambda = 1e-7\ntrain_and_test_loop(20, lr, Lambda)","3430ef58":"lr = 1e8\nLambda = 1e-7\ntrain_and_test_loop(20, lr, Lambda)","b28fc1b2":"lr = 1e4\nLambda = 1e-7\ntrain_and_test_loop(20, lr, Lambda)","db991aa9":"import math\nfor k in range(1,10):\n    lr = math.pow(10, np.random.uniform(-7.0, 3.0))\n    Lambda = math.pow(10, np.random.uniform(-7,-2))\n    best_acc = train_and_test_loop1(100, lr, Lambda, False)\n    print(\"Try {0}\/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))","67fc65a2":"for k in range(1,5):\n    lr = math.pow(10, np.random.uniform(-4.0, -1.0))\n    Lambda = math.pow(10, np.random.uniform(-4,-2))\n    best_acc = train_and_test_loop1(100, lr, Lambda, False)\n    print(\"Try {0}\/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))","40446eb7":"lr = 2e-2\nLambda = 1e-4\ntrain_and_test_loop1(100, lr, Lambda)","f2125de8":"lr = 2e-2\nLambda = 1e-4\nhidden_nodes = 256\noutput_nodes = 10\nmodel = Sequential()\nmodel.add(Dense(hidden_nodes, input_shape=(784,), activation='relu'))\nmodel.add(Dense(hidden_nodes, activation='relu'))\nmodel.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n    \nsgd = optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9)\n# Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    \n # Fit the model\nmodel.fit(X_train, y_train, epochs=100,batch_size=500, verbose= 1)","6761bf19":"predections = model.predict_classes(test,verbose=1)","cc9e086f":"sub = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission = sub['ImageId']","ba1189b3":"pred = pd.DataFrame(data=predections ,columns=[\"Label\"])\nDT = pd.merge(submission , pred, on=None, left_index= True,\n    right_index=True)\nDT.head()","0296afcd":"DT.to_csv('submission.csv',index = False)","6c88630a":"Making lr and lambda very low","e5e9de1e":"Insanity check","b44f3291":"### looking at the shape again","50ec456a":"Model 2 (same as model 1 but this produces the score after evaluation)","4d6af423":"### converting to categorical labels","5e8e6b88":"## Modeling","bf783790":"### plot of one figure","063fe7c6":"### look at the shape","93372ebe":"### Runnning coarse search for 10 times with different lr and Lambda values each with 100 epochs.","1337dbc5":"Making lr very high to find the interval to test","8ade00ad":"# Submission","205d261b":"### Runnning with lr = 0.02 and Lambda = 1e-4","79236154":"Model 1","94f4fdf4":"## Fitting and Testing","84db0fd1":"### Refining the search as per the cases that give good accuracy","c78886df":"## check whether normalization is achieved","af2f5f49":"### Get data","f3f5163a":"### Now saving the data in the form of an array","24d7a405":"### converting and Normalising data to train and test"}}