{"cell_type":{"58b59791":"code","4502bee5":"code","8b2fb0e2":"code","79607d33":"markdown","ae2596a8":"markdown","1cc35b08":"markdown","c24d7833":"markdown","756c197a":"markdown"},"source":{"58b59791":"from tweepy import (Stream, OAuthHandler) # OAuth is an open standard for access delegation, commonly used as a way for Internet users to grant websites or applications access to their information on other websites but without giving them the passwords.\nfrom tweepy.streaming import StreamListener\nimport time # For time.sleep()\n\nC_KEY = 'INSERT_YOUR_OWN_HERE' # Consumer key\nC_SECRET = 'INSERT_YOUR_OWN_HERE'\nA_TOKEN = 'INSERT_YOUR_OWN_HERE' # Access token\nA_SECRET = 'INSERT_YOUR_OWN_HERE'\n\nclass Listener(StreamListener):\n    def on_status(self, status): # on_data() would print a lot more detailed data. on_status() focuses on status updates.\n        try:\n            save_file = open('twitDB.txt', 'a', encoding='utf-8') # a = append\n            save_file.write(str(time.time()) + ':: ' + status.text.replace('\\n', ' '))\n            save_file.write('\\n')\n            save_file.close()\n            return True\n        except BaseException as err: # BaseException is the base class for all built-in exceptions. Problems that could happen are connection issues.\n            print('Failed on_status, ', str(err))\n            time.sleep(5)\n    \n    def on_error(self, status):\n        print(status)\n        \nauth  = OAuthHandler(C_KEY, C_SECRET) # Authorizing ourselves\nauth.set_access_token(A_TOKEN, A_SECRET)\ntwitter_stream = Stream(auth, Listener())\ntwitter_stream.filter(track='car') # Filtering tweets. Possible params: locations, languages, follow (people). The default argument for all of these is None. NB very few accounts have geolocations.","4502bee5":"from tweepy import (Stream, OAuthHandler)\nfrom tweepy.streaming import StreamListener\n \nclass Listener(StreamListener):\n\n    tweet_counter = 0 # Static variable\n    \n    def login(self):\n        CONSUMER_KEY = 'INSERT_YOUR_OWN_HERE'\n        CONSUMER_SECRET = 'INSERT_YOUR_OWN_HERE'\n        ACCESS_TOKEN = 'INSERT_YOUR_OWN_HERE'\n        ACCESS_TOKEN_SECRET = 'INSERT_YOUR_OWN_HERE'\n\n        auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n        auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n        return auth\n    \n    def on_status(self, status):\n        Listener.tweet_counter += 1\n        print(str(Listener.tweet_counter) + '. Screen name = \"%s\" Tweet = \"%s\"'\n              %(status.author.screen_name, status.text.replace('\\n', ' ')))\n\n        if Listener.tweet_counter < Listener.stop_at:\n            return True\n        else:\n            print('Max num reached = ' + str(Listener.tweet_counter))\n            return False\n\n    def getTweetsByGPS(self, stop_at_number, latitude_start, longitude_start, latitude_finish, longitude_finish):\n        try:\n            Listener.stop_at = stop_at_number # Create static variable\n            auth = self.login()\n            streaming_api = Stream(auth, Listener(), timeout=60) # Socket timeout value\n            streaming_api.filter(follow=None, locations=[latitude_start, longitude_start, latitude_finish, longitude_finish])\n        except KeyboardInterrupt:\n            print('Got keyboard interrupt')\n\n    def getTweetsByHashtag(self, stop_at_number, hashtag):\n        try:\n            Listener.stopAt = stop_at_number\n            auth = self.login()\n            streaming_api = Stream(auth, Listener(), timeout=60)\n            # Atlanta area.\n            streaming_api.filter(track=[hashtag])\n        except KeyboardInterrupt:\n            print('Got keyboard interrupt')\n\nlistener = Listener()\nlistener.getTweetsByGPS(20, -84.395198, 33.746876, -84.385585, 33.841601) # Atlanta area. Tool to find coordinates for any place: http:\/\/boundingbox.klokantech.com\/ (use CSV as the output format)","8b2fb0e2":"import re\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import TweetTokenizer\n\npunctuation += '\u00b4\u0384\u2019\u2026\u201c\u201d\u2013\u2014\u2015\u00bb\u00ab' # string.punctuation misses these.\n\ncache_english_stopwords = stopwords.words('english') # Could speed up code by making this a set\n\ndef tweet_clean(tweet):\n    print('Original tweet:', tweet, '\\n')\n    # Remove HTML special entities (e.g. &amp;)\n    tweet_no_special_entities = re.sub(r'\\&\\w*;', '', tweet)\n    print('No special entitites:', tweet_no_special_entities, '\\n')\n    # Remove tickers (Clickable stock market symbols that work like hashtags and start with dollar signs instead)\n    tweet_no_tickers = re.sub(r'\\$\\w*', '', tweet_no_special_entities) # Substitute. $ needs to be escaped because it means something in regex. \\w means alphanumeric char or underscore.\n    print('No tickers:', tweet_no_tickers, '\\n')\n    # Remove hyperlinks\n    tweet_no_hyperlinks = re.sub(r'https?:\\\/\\\/.*\\\/\\w*', '', tweet_no_tickers)\n    print('No hyperlinks:', tweet_no_hyperlinks, '\\n')\n    # Remove hashtags\n    tweet_no_hashtags = re.sub(r'#\\w*', '', tweet_no_hyperlinks)\n    print('No hashtags:', tweet_no_hashtags, '\\n')\n    # Remove Punctuation and split 's, 't, 've with a space for filter\n    tweet_no_punctuation = re.sub(r'[' + punctuation.replace('@', '') + ']+', ' ', tweet_no_hashtags)\n    print('No punctuation:', tweet_no_punctuation, '\\n')\n    # Remove words with 2 or fewer letters (Also takes care of RT)\n    tweet_no_small_words = re.sub(r'\\b\\w{1,2}\\b', '', tweet_no_punctuation) # \\b represents a word boundary\n    print('No small words:', tweet_no_small_words, '\\n')\n    # Remove whitespace (including new line characters)\n    tweet_no_whitespace = re.sub(r'\\s\\s+', ' ', tweet_no_small_words)\n    tweet_no_whitespace = tweet_no_whitespace.lstrip(' ') # Remove single space left on the left\n    print('No whitespace:', tweet_no_whitespace, '\\n')\n    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n    tweet_no_emojis = ''.join(c for c in tweet_no_whitespace if c <= '\\uFFFF') # Apart from emojis (plane 1), this also removes historic scripts and mathematical alphanumerics (also plane 1), ideographs (plane 2) and more.\n    print('No emojis:', tweet_no_emojis, '\\n')\n    # Tokenize: Change to lowercase, reduce length and remove handles\n    tknzr = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True) # reduce_len changes, for example, waaaaaayyyy to waaayyy.\n    tw_list = tknzr.tokenize(tweet_no_emojis)\n    print('Tweet tokenize:', tw_list, '\\n')\n    # Remove stopwords\n    list_no_stopwords = [i for i in tw_list if i not in cache_english_stopwords]\n    print('No stop words:', list_no_stopwords, '\\n')\n    # Final filtered tweet\n    tweet_filtered =' '.join(list_no_stopwords) # ''.join() would join without spaces between words.\n    print('Final tweet:', tweet_filtered)\n\ns = '    RT @Amila #Test\\nTom\\'s newly listed Co. &amp; Mary\\'s unlisted     Group to supply tech for nlTK.\\nh.. $TSLA $AAPL https:\/\/ t.co\/x34afsfQsh'\ntweet_clean(s)","79607d33":"## 3. Cleaning tweets:","ae2596a8":"To get your own consumer key, consumer secret, access token and access secret, create a Twitter application: https:\/\/apps.twitter.com\/app\/new.","1cc35b08":"# Twitter Stream (and Cleaning Tweets)","c24d7833":"## 2. Another way of doing it:","756c197a":"## 1. One way of doing it:"}}