{"cell_type":{"1cdf588c":"code","c23bb871":"code","2bb2fde7":"code","cf0bf024":"code","5c8f5db0":"code","b255ee2c":"code","001493df":"code","cb77302d":"code","97b0142e":"code","9cef6798":"code","e7457efa":"code","0e2e8212":"code","ad1aa5d4":"code","42a22a50":"code","d966be50":"code","4b20efa7":"code","831959be":"code","af168fb4":"code","a6f1d2be":"code","f4538a8f":"code","5ed6128d":"code","d31325b8":"code","d105e783":"code","5e04e01b":"code","8cfb4342":"code","f0b15bec":"code","ab5998bb":"code","7acd046e":"markdown","743e9e0f":"markdown","ebf167f9":"markdown","a4111dab":"markdown","4d9e6af9":"markdown","3e9d68bb":"markdown","e9a184d9":"markdown","119329a4":"markdown","2d745b2a":"markdown","57e23481":"markdown"},"source":{"1cdf588c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom math import sqrt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c23bb871":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","2bb2fde7":"train.head()","cf0bf024":"train.info()","5c8f5db0":"test.info()","b255ee2c":"numeric_features = train.select_dtypes(include=[np.number])\nnumeric_features.dtypes","001493df":"numeric_features_cols = numeric_features.columns.tolist()","cb77302d":"print('The dataset has',len(numeric_features.dtypes),'numeric features')","97b0142e":"categorical_features = train.select_dtypes(exclude=[np.number])\ncategorical_features_cols = categorical_features.columns.tolist()\ncategorical_features.dtypes","9cef6798":"print('The dataset has',len(categorical_features.dtypes),'categorical variables.')","e7457efa":"msno.bar(train[numeric_features_cols])","0e2e8212":"msno.bar(train[categorical_features_cols])","ad1aa5d4":"sns.distplot(train['SalePrice'], kde=False);\nplt.title('House Prices', fontsize=18);\nplt.xlabel('Price', fontsize=16);\nplt.ylabel('Frequency', fontsize=16);","42a22a50":"train.SalePrice.describe()","d966be50":"fig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(train[numeric_features_cols].corr(), cmap=\"YlGnBu\");","4b20efa7":"corr_saleprice = train[numeric_features_cols].corr()\ncorr_saleprice['SalePrice'][corr_saleprice['SalePrice'] > 0.5]","831959be":"#We obtain the numeric columns that are positively correlated with SalePrice\npos_corr_saleprice_cols = corr_saleprice['SalePrice'][corr_saleprice['SalePrice'] > 0.5].index.tolist()\npos_corr_saleprice_cols","af168fb4":"#We remove SalePrice\npos_corr_saleprice_cols.remove('SalePrice')\npos_corr_saleprice_cols","a6f1d2be":"#Review if these columns have missing values\nmsno.bar(train[pos_corr_saleprice_cols])","f4538a8f":"X = train[pos_corr_saleprice_cols]\ny = np.log(train.SalePrice)","5ed6128d":"X_train, X_test, y_train, y_test = train_test_split(\n                          X, y, random_state=42, test_size=.3)","d31325b8":"lr = linear_model.LinearRegression()","d105e783":"model = lr.fit(X_train, y_train)","5e04e01b":"#Function score returns R^2\nmodel.score(X_test, y_test)","8cfb4342":"predictions = model.predict(X_test)","f0b15bec":"sqrt(mean_squared_error(y_test, predictions))","ab5998bb":"sqrt(mean_squared_error(np.log(y_test), np.log(predictions)))","7acd046e":"However, the [rules for this competition ](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\/overview\/evaluation) state that \"Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price.\". ","743e9e0f":"In this notebook, we do a quick EDA to the House Prices dataset and create a baseline model.","ebf167f9":"# Baseline Model","a4111dab":"How many missing values does the dataset have?","4d9e6af9":"The metric for this competition is RMSE (root mean squared error). We obtain MSE (mean squared error) and compute the square root of it.","3e9d68bb":"We build a linear model as a baseline with the numeric features that have correlation with SalePrice > 0.5.","e9a184d9":"Now, let's look at the correlation of SalePrice with the rest of numeric features.","119329a4":"Let's look more closely at the correlation.","2d745b2a":"# EDA\n\nFirst, let's have a look at the target variable.","57e23481":"How many numeric variables do we have? Which are categorical?"}}