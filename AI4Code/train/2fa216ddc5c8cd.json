{"cell_type":{"daa1dd77":"code","dc036184":"code","900b915e":"code","75eb0486":"code","aa0c8973":"code","17cb9a66":"code","216e7125":"code","0d82cfa2":"code","5a1fc7e7":"code","23bd6934":"code","4474bd14":"code","fc07fec8":"code","7f761c8f":"code","f6c4d501":"code","4489f799":"code","d505e34e":"code","00675605":"code","342e91ea":"code","4929a6ae":"code","baa63771":"code","1e17bd30":"code","15105e59":"code","9c490cfb":"code","c6989da0":"code","3531522a":"code","03ea128b":"code","22601b30":"code","d6c285eb":"code","d49f4a1e":"code","61edd034":"code","3ef1b6b8":"code","f34b6f95":"code","f7f62472":"code","373d3a34":"code","d5a98476":"code","b751749b":"code","44324ce5":"code","35a0dc38":"code","315f8140":"code","01752236":"code","16a84637":"code","47961e47":"code","9eeeffd8":"code","285297b7":"code","3a04b24c":"code","8cd862df":"code","f57df56a":"code","b5a5f1a1":"code","7b4aad67":"code","9a7f4fb3":"code","d3092bcc":"code","65d97074":"code","9753f712":"code","c58ee116":"code","7daf61fe":"code","9e6784b3":"code","34582ac3":"code","ad5d5df5":"code","f2c37992":"code","fc8296f7":"code","b8029bf8":"code","8f6af2dc":"code","b15fb2e7":"code","11143d11":"code","a69794a3":"code","d6efd6bd":"code","d66225f5":"code","4c4c9a4a":"code","b4bf46f5":"code","efffcc15":"code","0fcfc171":"code","89657a11":"code","0cfe048f":"code","fa47967c":"code","d4ecf82e":"code","99c30621":"code","18cfe9b6":"code","151c6760":"code","be1d4d26":"code","1fed3d4f":"code","d252b607":"code","f5d35a48":"code","6cec8fe8":"code","bf19f065":"code","394bb43f":"code","85bb4353":"code","8c3d84dd":"code","bea284fb":"code","abddfdef":"code","b51340d4":"code","5bcb297b":"code","8298c330":"code","8254b4fd":"code","2db79624":"code","c5025c18":"code","81b61e9b":"code","81f19da3":"code","b845de16":"code","0935d3e2":"code","3645291d":"code","5d7d957f":"code","d528f5ed":"code","3f6457e8":"code","a00856a3":"code","9e0c6a15":"code","b5c69275":"code","7d64d176":"code","84eefe30":"code","2eafcabf":"code","18a12446":"code","f21c532f":"code","f0a18a0e":"code","f184eba6":"code","1badd3a1":"code","a76ce9d7":"code","5175fe98":"code","35385874":"code","d1e79034":"code","0ade82d5":"code","8abfb537":"code","dac02da6":"code","f376c3fa":"code","234dcf17":"code","34394cb9":"code","db7b33a9":"code","dde7892a":"code","18edd988":"code","f2d96bad":"code","fd203543":"code","a5e78161":"code","3e7d8a4d":"code","fdf46a86":"code","5265053c":"code","ce3f95bb":"code","1191e71c":"code","d4b60d5f":"code","e8ecb3db":"code","bd4c8419":"code","bb52f960":"code","b6669748":"code","bbe46939":"code","a04efe8b":"code","f303cfda":"code","88000228":"code","e593e660":"code","6ca37141":"code","64dcc277":"code","e1800613":"code","ae7fb1a2":"code","7a50ee80":"code","07370c24":"code","fa57c873":"code","b4668ca4":"code","f725e62b":"code","d34cba67":"code","9cb245f6":"code","79df3a40":"code","43b53b8d":"code","7e47658a":"code","694c4d65":"code","00bc20b4":"code","139ee507":"code","efe5993f":"code","4b54ff2a":"code","89ee1748":"code","c330c5a8":"code","8b4825cb":"code","37f45f20":"code","a2928ad4":"code","0310901b":"code","61e5f4ce":"code","964448b6":"code","473a9f96":"code","68e4a826":"code","3087fe96":"code","0aae7ec2":"markdown","7801e10f":"markdown","fbb303a4":"markdown","2a6e766a":"markdown","1c1c91f5":"markdown","a76d4795":"markdown","21cd4aa3":"markdown","94fbeee9":"markdown","75c82aa1":"markdown","29f0b0d3":"markdown","428d5765":"markdown","0f9868b2":"markdown","7b2e3d93":"markdown","48d95072":"markdown","8006943c":"markdown","1936d228":"markdown","c3c4d51d":"markdown","762ebd7f":"markdown","811b9421":"markdown","8c3b98dc":"markdown","6207eaa7":"markdown","c9ad6812":"markdown","c2fbb3c2":"markdown","ef12f2d0":"markdown","2295abfc":"markdown","30279236":"markdown","30ecad08":"markdown","0c8f720a":"markdown","82e49628":"markdown","c4d4a6c0":"markdown","e2f0ed4f":"markdown","d48bc9dc":"markdown","31bbb783":"markdown","d21fcc47":"markdown","1dd2cfce":"markdown","a416b717":"markdown","f9f546b0":"markdown","9466fee9":"markdown","90b366ea":"markdown","cc19549b":"markdown","9e8b2ced":"markdown","dbdf92a1":"markdown","44dd94af":"markdown","7db1c845":"markdown","3c58f4eb":"markdown","5983eeae":"markdown","866ddaf1":"markdown","8155e691":"markdown","3e09f5c4":"markdown","2733ee42":"markdown","676e81cd":"markdown","c0253645":"markdown","47e52849":"markdown","9e3b8e38":"markdown","01549f3b":"markdown","817e3fa3":"markdown","045bb554":"markdown","dff71281":"markdown","5765ff67":"markdown","2f2818a0":"markdown","f4e3a5e9":"markdown","2249938a":"markdown","531a03af":"markdown","7e979078":"markdown","5949812e":"markdown","9c3013b2":"markdown","51e04251":"markdown","6971d625":"markdown","44b602ec":"markdown","d414333e":"markdown","071253c0":"markdown","f0750209":"markdown","08d893dd":"markdown","67ce003b":"markdown","17ceeb25":"markdown","8475b1e9":"markdown","5f8b4509":"markdown","f172b544":"markdown","d9870b4a":"markdown","d8f275e4":"markdown","2fb427a8":"markdown","7a4b7b1e":"markdown","73b96a02":"markdown","4acad3d9":"markdown","efa26da1":"markdown","fc34e81e":"markdown","2a63bf26":"markdown","cadfb285":"markdown","a3ba13d2":"markdown","be67ac59":"markdown","a79aea5e":"markdown","44891b44":"markdown","1e810b33":"markdown","fc4fdc76":"markdown","d0bf79ad":"markdown","5c864e62":"markdown","a8fa9bd7":"markdown","6837dcdb":"markdown","4b0c6802":"markdown","1dae4738":"markdown","b03a5cb1":"markdown","64cf6aaf":"markdown","fbc2e851":"markdown","a5b82c07":"markdown","21a4764a":"markdown","411f5c6a":"markdown","c3f0efd7":"markdown","b3212898":"markdown","8b318cd9":"markdown","1e017a11":"markdown","d465b72a":"markdown","d82ecd72":"markdown","51131047":"markdown","87327d06":"markdown","69e67729":"markdown","ae517846":"markdown","b997e52f":"markdown","dd521164":"markdown","26ed47ac":"markdown","11dcca79":"markdown","e93f6813":"markdown"},"source":{"daa1dd77":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.ticker import ScalarFormatter\nfrom matplotlib import gridspec\nsns.set()\nimport scipy as sp\nfrom scipy import stats\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor \nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import RFE\nfrom sklearn.svm import SVR\nimport math\n\n\n%config IPCompleter.greedy=True\n# en el caso de usar temas oscuros en el notebook\nplt.style.use(\"seaborn-dark\")\n\n\n#usados en desafio\n#import sys\n#!{sys.executable} -m pip install plotly\nimport plotly.express as px\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\npyo.init_notebook_mode(connected=True)","dc036184":"data = pd.read_csv(\"..\/input\/properati-dataset\/DS_Proyecto_01_Datos_Properati.csv\")\ndata = pd.DataFrame(data)","900b915e":"data.head()","75eb0486":"data.tail()","aa0c8973":"data.shape","17cb9a66":"data.isnull().any()","216e7125":"count=data[\"lat\"].isnull().sum()\nprint(\"la cantidad de valores nulos en lat es: \",count)\n\ncount1=data[\"lon\"].isnull().sum()\nprint(\"la cantidad de valores nulos en lon es: \",count1)\n\ncount2=data[\"bathrooms\"].isnull().sum()\nprint(\"la cantidad de valores nulos en bathrooms es: \",count2)\n\ncount3=data[\"surface_total\"].isnull().sum()\nprint(\"la cantidad de valores nulos en surface_total es: \",count3)\n\ncount4=data[\"surface_covered\"].isnull().sum()\nprint(\"la cantidad de valores nulos en surface_covered es: \",count4)","0d82cfa2":"tipos = data[\"property_type\"].unique()\ntipos = tipos.tolist()\nprint(tipos)","5a1fc7e7":"instancias = data[\"property_type\"].value_counts()\ninstancias","23bd6934":"plt.figure(figsize=(10,5))\nplt.yscale('log')\nplt.gca().yaxis.set_major_formatter(ScalarFormatter())\nax = sns.countplot(data = data, x = \"property_type\")\nax.set_xticklabels(ax.get_xticklabels(),rotation=40,ha=\"right\")\n\n\nplt.show()","4474bd14":"fig= plt.subplots(figsize=(20,18),constrained_layout=True)\ngrid = gridspec.GridSpec(2, 1, height_ratios=[1, 3])\n\nax1=plt.subplot(grid[0])\nsns.countplot(data=data,y=\"l2\",order=data[\"l2\"].value_counts().index,ax=ax1,color=\"g\")\n\nax1.set_yticklabels(ax1.get_yticklabels(),fontsize=\"medium\")\nax1.set_title(\"Distribucion segun el G.B.A.\", fontsize= 'large')\n\nax2=plt.subplot(grid[1])\nsns.countplot(data=data,x=\"l3\",order=data[\"l3\"].value_counts().index,ax=ax2,color=\"b\")\n\n\nax2.set_title(\"Distribucion segun barrios\", fontsize= 'large')\nax2.set_xticklabels(ax2.get_xticklabels(),rotation=90,ha=\"right\")\nplt.yticks(fontsize= 11)\nax1.grid()\nax2.grid()\nplt.show()","fc07fec8":"# COMPLETAR - AGREGAR TANTAS CELDAS COMO SEA NECESARIO\ndata_2 = data[((data['property_type'] == \"Departamento\") |(data['property_type'] == \"Casa\") | (data['property_type'] == \"PH\"))  & (data['l2'] == \"Capital Federal\")] \ndata_2.shape","7f761c8f":"figz= plt.figure()\nmask_cols= [\"property_type\",\"price\",\"surface_covered\",\"surface_total\",\"rooms\",\"bedrooms\",\"bathrooms\"]\ngraph=sns.pairplot(data_2[mask_cols],hue=\"property_type\")\ngraph.fig.set_size_inches(16,8)\nplt.grid()\nplt.show()","f6c4d501":"data_3 = data_2[mask_cols].copy()\ndata_3 = data_3.reindex(sorted(data_3.columns), axis=1)\n","4489f799":"data_3.describe()","d505e34e":"data_3[\"bathrooms\"].value_counts().sort_index()","00675605":"data_3[\"rooms\"].value_counts().sort_index()","342e91ea":"fig,(ax1,ax2) = plt.subplots(2,constrained_layout=True,figsize=(10,10))\nax1.set_title(\"outliers y superficie total\")\nax2.set_title(\"outliers y superficie cubierta\")\n\nsns.boxplot(data=data_3,x=\"surface_total\",ax=ax1)\nsns.boxplot(data=data_3,x=\"surface_covered\",ax=ax2)\nplt.grid()\nplt.show()","4929a6ae":"data_monoamb=data_3[(data_3[\"bedrooms\"] == 0) & (data_3[\"rooms\"] == 1)]\ndata_monoamb.sample(5)","baa63771":"unicos = data_3[\"property_type\"].unique()","1e17bd30":"for x in unicos:\n    Q1 = data_3[data_3[\"property_type\"]==x][\"surface_total\"].quantile(0.25)\n    Q3 = data_3[data_3[\"property_type\"]==x][\"surface_total\"].quantile(0.75)\n    IQR = Q3 - Q1\n    surface_min = data_3[data_3[\"property_type\"]==x][\"surface_total\"].quantile(0.01)\n    surface_max = Q3 + (IQR*1.5)\n    print(x)\n    print(\"la Superficie maxima es {} y la superficie minima es {} y el IQR {}\" .format(surface_max,surface_min,IQR))\n    print(\"-----------\")","15105e59":"dpto_New=data_3[data_3[\"property_type\"]==\"Departamento\"]\nph_New=data_3[data_3[\"property_type\"]==\"PH\"]\ncasa_New=data_3[data_3[\"property_type\"]==\"Casa\"]","9c490cfb":"dpto_New= dpto_New[(dpto_New.surface_total <= 177.0) & (dpto_New.surface_total >=25.0) ]\nph_New=ph_New[(ph_New.surface_total <= 275.0) & (ph_New.surface_total >=35.0) ]\ncasa_New=casa_New[(casa_New.surface_total <= 579.0) & (casa_New.surface_total >=56.0) ]","c6989da0":"figure,(ax1,ax2,ax3) = plt.subplots(3,constrained_layout=True,figsize=(10,10))\nax1.set_title(\"Relacion tipo de propiedad y superficie total\")\nax2.set_title(\"Relacion tipo de propiedad y superficie total\")\nax3.set_title(\"Relacion tipo de propiedad y superficie total\")\nsns.boxplot(data=dpto_New,x=\"surface_total\",y=\"property_type\",ax=ax1)\nsns.boxplot(data=ph_New,x=\"surface_total\",y=\"property_type\",ax=ax2)\nsns.boxplot(data=casa_New,x=\"surface_total\",y=\"property_type\",ax=ax3)\nax1.grid()\nax2.grid()\nax3.grid()\nplt.show()","3531522a":"conc_1=[dpto_New,ph_New,casa_New]\ndata_4= pd.concat(conc_1)\ndata_4.describe()","03ea128b":"sns.scatterplot(data=data_4, x='surface_total', y='surface_covered')\nplt.grid()\nplt.show()","22601b30":"data_4.describe()","d6c285eb":"data_4.drop(data_4.loc[data_4['surface_covered'] > data_4['surface_total']].index,inplace=True ,axis=0)","d49f4a1e":"data_4.describe()","61edd034":"sns.scatterplot(data=data_4, x='surface_total', y='surface_covered')\nplt.grid()\nplt.show()","3ef1b6b8":"unique= data_4[\"property_type\"].unique()\nfor x in unique:\n    Q1 = data_4[data_4[\"property_type\"]==x][\"price\"].quantile(0.25)\n    Q3 = data_4[data_4[\"property_type\"]==x][\"price\"].quantile(0.75)\n    IQR = Q3 - Q1\n    precio_min = data_4[data_4[\"property_type\"]==x][\"price\"].quantile(0.01)\n    precio_max = Q3 + (IQR*1.5)\n    print(x)\n    print(\"el precio maximo es {}, el precio minimo es {} y el IQR {}\" .format(precio_max,precio_min,IQR))\n    print(\"-------------------------------------------------------------------\")","f34b6f95":"dpto_New=data_4[data_4[\"property_type\"]==\"Departamento\"]\nph_New=data_4[data_4[\"property_type\"]==\"PH\"]\ncasa_New=data_4[data_4[\"property_type\"]==\"Casa\"]","f7f62472":"dpto_New= dpto_New[(dpto_New.price <= 440750.0) & (dpto_New.price >=62000.0) ]\nph_New=ph_New[(ph_New.price <= 447650.0) & (ph_New.price >=69900.0) ]\ncasa_New=casa_New[(casa_New.price <= 785000.0) & (casa_New.price >=99000.0) ]","373d3a34":"figure,(ax1,ax2,ax3) = plt.subplots(3,constrained_layout=True,figsize=(10,10))\nax1.set_title(\"Relacion tipo de propiedad y precio(En miles de Dolares)\")\nax2.set_title(\"Relacion tipo de propiedad y precio(En miles de Dolares)\")\nax3.set_title(\"Relacion tipo de propiedad y precio(En  Dolares)\")\nsns.boxplot(data=dpto_New,x=\"price\",y=\"property_type\",ax=ax1)\nsns.boxplot(data=ph_New,x=\"price\",y=\"property_type\",ax=ax2)\nsns.boxplot(data=casa_New,x=\"price\",y=\"property_type\",ax=ax3)\nax1.grid()\nax2.grid()\nax3.grid()\nplt.show()","d5a98476":"rooms_min_list=[]\nrooms_max_list=[]\n\nunique= data_4[\"property_type\"].unique()\nfor x in unique:\n    Q1 = data_4[data_4[\"property_type\"]==x][\"rooms\"].quantile(0.25)\n    Q3 = data_4[data_4[\"property_type\"]==x][\"rooms\"].quantile(0.75)\n    IQR = Q3 - Q1\n    rooms_min = Q1 - (IQR*1.5)\n    rooms_max = Q3 + (IQR*1.5)\n    \n    rooms_min_list.append(Q1 - (IQR*1.5))\n    rooms_max_list.append(Q3 + (IQR*1.5))\n    \n    print(x)\n    print(\"el numero maximo de rooms es {}, el numero minimo de rooms es {} y el IQR {}\" .format(rooms_max,rooms_min,IQR))\n    print(\"-------------------------------------------------------------------\")","b751749b":"for i in rooms_max_list:\n    ceil_max=math.ceil(i)\n    print(ceil_max)","44324ce5":"for i in rooms_min_list:\n    ceil_min=math.ceil(i)\n    print(ceil_min)","35a0dc38":"dpto_New=data_4[data_4[\"property_type\"]==\"Departamento\"]\nph_New=data_4[data_4[\"property_type\"]==\"PH\"]\ncasa_New=data_4[data_4[\"property_type\"]==\"Casa\"]","315f8140":"dpto_New= dpto_New[(dpto_New.rooms <= 5.0) & (dpto_New.rooms >=1.0) ]\nph_New=ph_New[(ph_New.rooms <= 6.0) & (ph_New.rooms >=2.0) ]\ncasa_New=casa_New[(casa_New.rooms <= 9.0) & (casa_New.rooms >=1.0) ]","01752236":"figure,(ax1,ax2,ax3) = plt.subplots(3,constrained_layout=True,figsize=(10,10))\nax1.set_title(\"Relacion tipo de propiedad y rooms\")\nax2.set_title(\"Relacion tipo de propiedad y rooms\")\nax3.set_title(\"Relacion tipo de propiedad y rooms\")\nsns.boxplot(data=dpto_New,x=\"rooms\",y=\"property_type\",ax=ax1)\nsns.boxplot(data=ph_New,x=\"rooms\",y=\"property_type\",ax=ax2)\nsns.boxplot(data=casa_New,x=\"rooms\",y=\"property_type\",ax=ax3)\nax1.grid()\nax2.grid()\nax3.grid()\nplt.show()","16a84637":"data_4[\"bathrooms\"].value_counts().sort_index()","47961e47":"bath_min_list=[]\nbath_max_list=[]\n\nunique= data_4[\"property_type\"].unique()\nfor x in unique:\n    Q1 = data_4[data_4[\"property_type\"]==x][\"bathrooms\"].quantile(0.25)\n    Q3 = data_4[data_4[\"property_type\"]==x][\"bathrooms\"].quantile(0.75)\n    IQR = Q3 - Q1\n    bath_min = data_4[data_4[\"property_type\"]==x][\"bathrooms\"].quantile(0.01)\n    bath_max = Q3 + (IQR*1.5)\n    \n    bath_min_list.append(data_4[data_4[\"property_type\"]==x][\"bathrooms\"].quantile(0.01))\n    bath_max_list.append(Q3 + (IQR*1.5))\n    \n    print(x)\n    print(\"el numero  maximo de bathrooms es {}, el numero minimo de bathrooms es {} y el IQR {}\" .format(bath_max,bath_min,IQR))\n    print(\"-------------------------------------------------------------------\")","9eeeffd8":"for i in bath_max_list:\n    floor_max=math.floor(i)\n    print(floor_max)","285297b7":"dpto_New=data_4[data_4[\"property_type\"]==\"Departamento\"]\nph_New=data_4[data_4[\"property_type\"]==\"PH\"]\ncasa_New=data_4[data_4[\"property_type\"]==\"Casa\"]","3a04b24c":"dpto_New= dpto_New[(dpto_New.bathrooms <= 3.0) & (dpto_New.bathrooms >=1.0) ]\nph_New=ph_New[(ph_New.bathrooms <= 3.0) & (ph_New.bathrooms >=1.0) ]\ncasa_New=casa_New[(casa_New.bathrooms <= 4.0) & (casa_New.bathrooms >=1.0) ]","8cd862df":"figure,(ax1,ax2,ax3) = plt.subplots(3,constrained_layout=True,figsize=(10,10))\nax1.set_title(\"Relacion tipo de propiedad y bathrooms\")\nax2.set_title(\"Relacion tipo de propiedad y bathrooms\")\nax3.set_title(\"Relacion tipo de propiedad y bathrooms\")\nsns.boxplot(data=dpto_New,x=\"bathrooms\",y=\"property_type\",ax=ax1)\nsns.boxplot(data=ph_New,x=\"bathrooms\",y=\"property_type\",ax=ax2)\nsns.boxplot(data=casa_New,x=\"bathrooms\",y=\"property_type\",ax=ax3)\nax1.grid()\nax2.grid()\nax3.grid()\nplt.show()","f57df56a":"data_4[\"bedrooms\"].value_counts().sort_index()","b5a5f1a1":"bed_min_list=[]\nbed_max_list=[]\n\nunique= data_4[\"property_type\"].unique()\nfor x in unique:\n    Q1 = data_4[data_4[\"property_type\"]==x][\"bedrooms\"].quantile(0.25)\n    Q3 = data_4[data_4[\"property_type\"]==x][\"bedrooms\"].quantile(0.75)\n    IQR = Q3 - Q1\n    precio_min = data_4[data_4[\"property_type\"]==x][\"bedrooms\"].quantile(0.01)\n    precio_max = Q3 + (IQR*1.5)\n    \n    bed_min_list.append(data_4[data_4[\"property_type\"]==x][\"bedrooms\"].quantile(0.01))\n    bed_max_list.append(Q3 + (IQR*1.5))\n    \n    print(x)\n    print(\"el numero maximo de bedrooms es {}, el numero minimo de bedrooms es {} y el IQR {}\" .format(precio_max,precio_min,IQR))\n    print(\"-------------------------------------------------------------------\")","7b4aad67":"for i in bed_max_list:\n    floor_max=math.floor(i)\n    print(floor_max)","9a7f4fb3":"dpto_New=data_4[data_4[\"property_type\"]==\"Departamento\"]\nph_New=data_4[data_4[\"property_type\"]==\"PH\"]\ncasa_New=data_4[data_4[\"property_type\"]==\"Casa\"]","d3092bcc":"dpto_New= dpto_New[(dpto_New.bedrooms <= 3.0) & (dpto_New.bedrooms >=1.0) ]\nph_New=ph_New[(ph_New.bedrooms <= 4.0) & (ph_New.bedrooms >=1.0) ]\ncasa_New=casa_New[(casa_New.bedrooms <= 5.0) & (casa_New.bedrooms >=1.0) ]","65d97074":"figure,(ax1,ax2,ax3) = plt.subplots(3,constrained_layout=True,figsize=(10,10))\nax1.set_title(\"Relacion tipo de propiedad y bedrooms\")\nax2.set_title(\"Relacion tipo de propiedad y bedrooms\")\nax3.set_title(\"Relacion tipo de propiedad y bedrooms\")\nsns.boxplot(data=dpto_New,x=\"bedrooms\",y=\"property_type\",ax=ax1)\nsns.boxplot(data=ph_New,x=\"bedrooms\",y=\"property_type\",ax=ax2)\nsns.boxplot(data=casa_New,x=\"bedrooms\",y=\"property_type\",ax=ax3)\nax1.grid()\nax2.grid()\nax3.grid()\nplt.show()","9753f712":"surface_min_list=[]\nsurface_max_list=[]\n\nunique= data_4[\"property_type\"].unique()\nfor x in unique:\n    Q1 = data_4[data_4[\"property_type\"]==x][\"surface_covered\"].quantile(0.25)\n    Q3 = data_4[data_4[\"property_type\"]==x][\"surface_covered\"].quantile(0.75)\n    IQR = Q3 - Q1\n    precio_min = data_4[data_4[\"property_type\"]==x][\"surface_covered\"].quantile(0.01)\n    precio_max = Q3 + (IQR*1.5)\n    \n    surface_min_list.append(data_4[data_4[\"property_type\"]==x][\"surface_covered\"].quantile(0.01))\n    surface_max_list.append(Q3 + (IQR*1.5))\n    \n    print(x)\n    print(\"el maximo de surface covered es {}, el minimo de surface covered es {} y el IQR {}\" .format(precio_max,precio_min,IQR))\n    print(\"-------------------------------------------------------------------\")","c58ee116":"dpto_New=data_4[data_4[\"property_type\"]==\"Departamento\"]\nph_New=data_4[data_4[\"property_type\"]==\"PH\"]\ncasa_New=data_4[data_4[\"property_type\"]==\"Casa\"]","7daf61fe":"dpto_New= dpto_New[(dpto_New.surface_covered <= 137.0) & (dpto_New.surface_covered >=26.0) ]\nph_New=ph_New[(ph_New.surface_covered <= 201.0) & (ph_New.surface_covered >=35.0) ]\ncasa_New=casa_New[(casa_New.surface_covered <= 420.5) & (casa_New.surface_covered >=56.33) ]","9e6784b3":"figure,(ax1,ax2,ax3) = plt.subplots(3,constrained_layout=True,figsize=(10,10))\nax1.set_title(\"Relacion tipo de propiedad y surface_covered\")\nax2.set_title(\"Relacion tipo de propiedad y surface_covered\")\nax3.set_title(\"Relacion tipo de propiedad y surface_covered\")\nsns.boxplot(data=dpto_New,x=\"surface_covered\",y=\"property_type\",ax=ax1)\nsns.boxplot(data=ph_New,x=\"surface_covered\",y=\"property_type\",ax=ax2)\nsns.boxplot(data=casa_New,x=\"surface_covered\",y=\"property_type\",ax=ax3)\nax1.grid()\nax2.grid()\nax3.grid()\nplt.show()","34582ac3":"conc_2=[dpto_New,ph_New,casa_New]\ndata_5= pd.concat(conc_2)\ndata_5.head(10)","ad5d5df5":"graph_f=sns.pairplot(data_5,hue=\"property_type\")\ngraph_f.fig.set_size_inches(16,8)\nplt.grid()\nplt.show()","f2c37992":"fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(12,8))\nfig.tight_layout(pad=7.0)\n\n\nsns.heatmap(data_5.corr(), annot = True,vmin=-1, vmax=1, center= 0,cmap= 'coolwarm',linewidths=3, linecolor='black',ax=ax1)\nmatrix = np.triu(data_5.corr())\nsns.heatmap(data_5.corr(), annot=True, mask=matrix,ax=ax2)","fc8296f7":"data_complete = pd.read_csv(\"..\/input\/properati-dataset\/DS_Proyecto_01_Datos_Properati.csv\")\ndata_complete = pd.DataFrame(data_complete)\n\ndata_map = data_complete[((data_complete['property_type'] == \"Departamento\") |(data_complete['property_type'] == \"Casa\") | (data_complete['property_type'] == \"PH\"))  & (data_complete['l2'] == \"Capital Federal\")] \ndata_map.head()","b8029bf8":"data_map.describe()","8f6af2dc":"print(data_map[\"lat\"].count())\nprint(data_map[\"lon\"].count())","b15fb2e7":"before_count_lat=data_map[\"lat\"].isnull().sum()\nprint(\"la cantidad de valores nulos en lat es: \",before_count_lat)\n\nbefore_count_lon=data_map[\"lon\"].isnull().sum()\nprint(\"la cantidad de valores nulos en lon es: \",before_count_lon)\n","11143d11":"data_map.dropna(subset=[\"lat\",\"lon\"],inplace=True)","a69794a3":"after_count_lat=data_map[\"lat\"].isnull().sum()\nprint(\"la cantidad de valores nulos en lat es: \",after_count_lat)\n\nafter_count_lon=data_map[\"lon\"].isnull().sum()\nprint(\"la cantidad de valores nulos en lon es: \",after_count_lon)","d6efd6bd":"data_map[\"property_type\"].value_counts()","d66225f5":"fig = px.scatter_mapbox(data_map, lat=\"lat\", lon=\"lon\", color=\"property_type\",hover_data=['price'],hover_name=\"title\",\n                        animation_frame=\"l3\",zoom=10,\n                        title=\"Mapa de Capital Federal para Departamentos,PH y Casa\",\n                       )\nfig.update_layout(mapbox_style=\"open-street-map\")\npyo.offline.plot(fig, filename = \"Mapa de Capital Federal para Departamentos,PH y Casa.html\")\nfig.show()","4c4c9a4a":"dataset =pd.read_csv(\"..\/input\/properati-dataset\/DS_Proyecto_01_Datos_Properati.csv\")","b4bf46f5":"dataset = dataset[((dataset['property_type'] == \"Departamento\") |\n                  (dataset['property_type'] == \"Casa\") |\n                  (dataset['property_type'] == \"PH\")) \n                  & (dataset['l2'] == \"Capital Federal\")]","efffcc15":"superficie_min=15\nsuperficie_max=1000\n\ndataset = dataset[(dataset.surface_total <= 1000) &\n                        (dataset.surface_total >= 15)]","0fcfc171":"dataset = dataset[(dataset.price <= 4000000)]","89657a11":"dataset.head()","0cfe048f":"mask_cols_datset=[\"surface_total\",\"surface_covered\",\"bathrooms\",\"bedrooms\",\"price\",\"rooms\"]\ndataset=dataset[mask_cols_datset]","fa47967c":"dataset.head()","d4ecf82e":"dataset=dataset.dropna()","99c30621":"dataset.shape","18cfe9b6":"X = dataset[[\"rooms\",\"surface_covered\",\"surface_total\",\"bedrooms\",\"bathrooms\"]]\ny = dataset[\"price\"]","151c6760":"X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.30,random_state=42)","be1d4d26":"regressor = LinearRegression()","1fed3d4f":"regressor.fit(X_train,y_train)","d252b607":"y_train_pred= regressor.predict(X_train)\ny_test_pred=regressor.predict(X_test)","f5d35a48":"MAE_train=mean_absolute_error(y_train,y_train_pred)\nMAE_test=mean_absolute_error(y_test,y_test_pred)\n\nRMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\nRMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\nr2_train= metrics.r2_score(y_train, y_train_pred)\nr2_test= metrics.r2_score(y_test, y_test_pred)\n\nadj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\nadj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",MAE_train)\nprint(\"El MAE en test es:\",MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",RMSE_train)\nprint(\"El RMSE en test es:\",RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",r2_train)\nprint(\"El r2 de test es:\",r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",adj_r2_train)\nprint(\"El r2 ajustado de test es:\",adj_r2_test)","6cec8fe8":"arbol_regressor = DecisionTreeRegressor(random_state=42)\nknn_regressor = KNeighborsRegressor()","bf19f065":"arbol_regressor.fit(X_train,y_train)\nknn_regressor.fit(X_train,y_train)","394bb43f":"y_arbol_pred_train = arbol_regressor.predict(X_train)\ny_arbol_pred_test = arbol_regressor.predict(X_test)\n\ny_knn_pred_train = knn_regressor.predict(X_train)\ny_knn_pred_test = knn_regressor.predict(X_test)","85bb4353":"arbol_MAE_train=mean_absolute_error(y_train,y_arbol_pred_train)\narbol_MAE_test=mean_absolute_error(y_test,y_arbol_pred_test)\n\narbol_RMSE_train=np.sqrt(mean_squared_error(y_train,y_arbol_pred_train))\narbol_RMSE_test=np.sqrt(mean_squared_error(y_test,y_arbol_pred_test))\n\narbol_r2_train= metrics.r2_score(y_train, y_arbol_pred_train)\narbol_r2_test= metrics.r2_score(y_test, y_arbol_pred_test)\n\narbol_adj_r2_train = 1 - ((1 - arbol_r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\narbol_adj_r2_test = 1 - ((1 - arbol_r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",arbol_MAE_train)\nprint(\"El MAE en test es:\",arbol_MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",arbol_RMSE_train)\nprint(\"El RMSE en test es:\",arbol_RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",arbol_r2_train)\nprint(\"El r2 de test es:\",arbol_r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",arbol_adj_r2_train)\nprint(\"El r2 ajustado de test es:\",arbol_adj_r2_test)","8c3d84dd":"knn_MAE_train=mean_absolute_error(y_train,y_knn_pred_train)\nknn_MAE_test=mean_absolute_error(y_test,y_knn_pred_test)\n\nknn_RMSE_train=np.sqrt(mean_squared_error(y_train,y_knn_pred_train))\nknn_RMSE_test=np.sqrt(mean_squared_error(y_test,y_knn_pred_test))\n\nknn_r2_train= metrics.r2_score(y_train, y_knn_pred_train)\nknn_r2_test= metrics.r2_score(y_test, y_knn_pred_test)\n\nknn_adj_r2_train = 1 - ((1 - knn_r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\nknn_adj_r2_test = 1 - ((1 - knn_r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",knn_MAE_train)\nprint(\"El MAE en test es:\",knn_MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",knn_RMSE_train)\nprint(\"El RMSE en test es:\",knn_RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",knn_r2_train)\nprint(\"El r2 de test es:\",knn_r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",knn_adj_r2_train)\nprint(\"El r2 ajustado de test es:\",knn_adj_r2_test)","bea284fb":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([regressor, arbol_regressor, knn_regressor]):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_train, y_train_pred)\n    r2_test= metrics.r2_score(y_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n    RMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","abddfdef":"MAX_DEPTH_range = range(1, 21)\nscores = []\narbol_r2_train_pred=[]\narbol_r2_test_pred=[]\n\nfor k in MAX_DEPTH_range:\n    arbol_regressor = DecisionTreeRegressor(max_depth=k,random_state=42)\n    arbol_regressor.fit(X_train, y_train)\n    scores.append(arbol_regressor.score(X_test, y_test))\n    \n    y_train_pred = arbol_regressor.predict(X_train)\n    arbol_r2_train = metrics.r2_score(y_train, y_train_pred)\n    arbol_r2_train_pred.append(arbol_r2_train)\n    \n    y_test_pred = arbol_regressor.predict(X_test)\n    arbol_r2_test = metrics.r2_score(y_test, y_test_pred)\n    arbol_r2_test_pred.append(arbol_r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(MAX_DEPTH_range,scores,marker=\"o\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_test_pred,marker=\"o\",label=\"test\")\n\nax1.set_xticks(MAX_DEPTH_range)\nax2.set_xticks(MAX_DEPTH_range)\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('max depth')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('max depth')\nax2.set_ylabel('r2')\n\nplt.show()","b51340d4":"k_range = range(1, 21)\nscores = []\nr2_train_pred=[]\nr2_train_test=[]\n\nfor k in k_range:\n    knn_regressor = KNeighborsRegressor(n_neighbors = k)\n    knn_regressor.fit(X_train, y_train)\n    scores.append(knn_regressor.score(X_test, y_test))\n    \n    y_train_pred = knn_regressor.predict(X_train)\n    r2_train = metrics.r2_score(y_train, y_train_pred)\n    r2_train_pred.append(r2_train)\n    \n    y_test_pred = knn_regressor.predict(X_test)\n    r2_test = metrics.r2_score(y_test, y_test_pred)\n    r2_train_test.append(r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(k_range,scores,marker=\"o\")\nax2.scatter(k_range,r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(k_range,r2_train_test,marker=\"o\",label=\"test\")\n\nax1.set_xticks(k_range)\nax2.set_xticks(k_range)\n\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('k')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('k')\nax2.set_ylabel('r2')\n\nplt.show()","5bcb297b":"arbol_optimo = DecisionTreeRegressor(max_depth= 17,random_state=42)\narbol_optimo.fit(X_train,y_train)\n\nknn_optimo = KNeighborsRegressor(n_neighbors=3)\nknn_optimo.fit(X_train,y_train)","8298c330":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([regressor, arbol_optimo, knn_optimo]):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_train, y_train_pred)\n    r2_test= metrics.r2_score(y_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","8254b4fd":"X = dataset[[\"rooms\",\"surface_covered\",\"surface_total\",\"bedrooms\",\"bathrooms\"]]\ny = dataset[\"price\"]","2db79624":"vif_data = pd.DataFrame() \nvif_data[\"features\"] = X.columns ","c5025c18":"vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n                          for i in range(len(X.columns))] ","81b61e9b":"print(vif_data)","81f19da3":"X = dataset[[\"rooms\",\"surface_covered\",\"surface_total\",\"bathrooms\"]]\nvif_data = pd.DataFrame() \nvif_data[\"features\"] = X.columns \nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n                          for i in range(len(X.columns))] \nprint(vif_data)","b845de16":"X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.30,random_state=42)","0935d3e2":"scale = preprocessing.StandardScaler()\nscale.fit(X_train)\nX_train = scale.transform(X_train)\nX_test = scale.transform(X_test)","3645291d":"X_train.max(), X_test.max()","5d7d957f":"new_regressor = LinearRegression()","d528f5ed":"new_regressor.fit(X_train,y_train)","3f6457e8":"new_y_train_pred= new_regressor.predict(X_train)\nnew_y_test_pred=new_regressor.predict(X_test)","a00856a3":"MAE_train=mean_absolute_error(y_train,y_train_pred)\nMAE_test=mean_absolute_error(y_test,y_test_pred)\n\nRMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\nRMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\nr2_train= metrics.r2_score(y_train, y_train_pred)\nr2_test= metrics.r2_score(y_test, y_test_pred)\n\nadj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\nadj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",MAE_train)\nprint(\"El MAE en test es:\",MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",RMSE_train)\nprint(\"El RMSE en test es:\",RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",r2_train)\nprint(\"El r2 de test es:\",r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",adj_r2_train)\nprint(\"El r2 ajustado de test es:\",adj_r2_test)","9e0c6a15":"new_arbol_regressor = DecisionTreeRegressor(random_state=42)\nnew_knn_regressor = KNeighborsRegressor()","b5c69275":"new_arbol_regressor.fit(X_train,y_train)\nnew_knn_regressor.fit(X_train,y_train)","7d64d176":"y_arbol_pred_train = new_arbol_regressor.predict(X_train)\ny_arbol_pred_test = new_arbol_regressor.predict(X_test)\n\ny_knn_pred_train = new_knn_regressor.predict(X_train)\ny_knn_pred_test = new_knn_regressor.predict(X_test)","84eefe30":"arbol_MAE_train=mean_absolute_error(y_train,y_arbol_pred_train)\narbol_MAE_test=mean_absolute_error(y_test,y_arbol_pred_test)\n\narbol_RMSE_train=np.sqrt(mean_squared_error(y_train,y_arbol_pred_train))\narbol_RMSE_test=np.sqrt(mean_squared_error(y_test,y_arbol_pred_test))\n\narbol_r2_train= metrics.r2_score(y_train, y_arbol_pred_train)\narbol_r2_test= metrics.r2_score(y_test, y_arbol_pred_test)\n\narbol_adj_r2_train = 1 - ((1 - arbol_r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\narbol_adj_r2_test = 1 - ((1 - arbol_r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",arbol_MAE_train)\nprint(\"El MAE en test es:\",arbol_MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",arbol_RMSE_train)\nprint(\"El RMSE en test es:\",arbol_RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",arbol_r2_train)\nprint(\"El r2 de test es:\",arbol_r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",arbol_adj_r2_train)\nprint(\"El r2 ajustado de test es:\",arbol_adj_r2_test)","2eafcabf":"knn_MAE_train=mean_absolute_error(y_train,y_knn_pred_train)\nknn_MAE_test=mean_absolute_error(y_test,y_knn_pred_test)\n\nknn_RMSE_train=np.sqrt(mean_squared_error(y_train,y_knn_pred_train))\nknn_RMSE_test=np.sqrt(mean_squared_error(y_test,y_knn_pred_test))\n\nknn_r2_train= metrics.r2_score(y_train, y_knn_pred_train)\nknn_r2_test= metrics.r2_score(y_test, y_knn_pred_test)\n\nknn_adj_r2_train = 1 - ((1 - knn_r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\nknn_adj_r2_test = 1 - ((1 - knn_r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",knn_MAE_train)\nprint(\"El MAE en test es:\",knn_MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",knn_RMSE_train)\nprint(\"El RMSE en test es:\",knn_RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",knn_r2_train)\nprint(\"El r2 de test es:\",knn_r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",knn_adj_r2_train)\nprint(\"El r2 ajustado de test es:\",knn_adj_r2_test)","18a12446":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([new_regressor, new_arbol_regressor, new_knn_regressor]):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_train, y_train_pred)\n    r2_test= metrics.r2_score(y_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","f21c532f":"MAX_DEPTH_range = range(1, 21)\nscores = []\narbol_r2_train_pred=[]\narbol_r2_test_pred=[]\n\nfor k in MAX_DEPTH_range:\n    new_arbol_regressor = DecisionTreeRegressor(max_depth=k,random_state=42)\n    new_arbol_regressor.fit(X_train, y_train)\n    scores.append(new_arbol_regressor.score(X_test, y_test))\n    \n    y_train_pred = new_arbol_regressor.predict(X_train)\n    arbol_r2_train = metrics.r2_score(y_train, y_train_pred)\n    arbol_r2_train_pred.append(arbol_r2_train)\n    \n    y_test_pred = new_arbol_regressor.predict(X_test)\n    arbol_r2_test = metrics.r2_score(y_test, y_test_pred)\n    arbol_r2_test_pred.append(arbol_r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(MAX_DEPTH_range,scores,marker=\"o\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_test_pred,marker=\"o\",label=\"test\")\n\nax1.set_xticks(MAX_DEPTH_range)\nax2.set_xticks(MAX_DEPTH_range)\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('max depth')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('max depth')\nax2.set_ylabel('r2')\n\nplt.show()","f0a18a0e":"k_range = range(1, 21)\nscores = []\nr2_train_pred=[]\nr2_train_test=[]\n\nfor k in k_range:\n    new_knn_regressor = KNeighborsRegressor(n_neighbors = k)\n    new_knn_regressor.fit(X_train, y_train)\n    scores.append(new_knn_regressor.score(X_test, y_test))\n    \n    y_train_pred = new_knn_regressor.predict(X_train)\n    r2_train = metrics.r2_score(y_train, y_train_pred)\n    r2_train_pred.append(r2_train)\n    \n    y_test_pred = new_knn_regressor.predict(X_test)\n    r2_test = metrics.r2_score(y_test, y_test_pred)\n    r2_train_test.append(r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(k_range,scores,marker=\"o\")\nax2.scatter(k_range,r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(k_range,r2_train_test,marker=\"o\",label=\"test\")\n\nax1.set_xticks(k_range)\nax2.set_xticks(k_range)\n\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('k')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('k')\nax2.set_ylabel('r2')\n\nplt.show()","f184eba6":"new_arbol_optimo = DecisionTreeRegressor(max_depth= 19,random_state=42)\nnew_arbol_optimo.fit(X_train,y_train)\n\nnew_knn_optimo = KNeighborsRegressor(n_neighbors=4)\nnew_knn_optimo.fit(X_train,y_train)","1badd3a1":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([new_regressor, new_arbol_optimo, new_knn_optimo]):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_train, y_train_pred)\n    r2_test= metrics.r2_score(y_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","a76ce9d7":"X = dataset[[\"rooms\",\"surface_covered\",\"surface_total\",\"bedrooms\",\"bathrooms\"]]\ny = dataset[\"price\"]","5175fe98":"%%time\nestimador = SVR(kernel=\"linear\")\nselector = RFE(estimador, n_features_to_select=3, step=1)\nselector = selector.fit(X,y)","35385874":"selector.support_","d1e79034":"selector.ranking_","0ade82d5":"X = dataset[[\"surface_covered\",\"bedrooms\",\"bathrooms\"]]\ny = dataset[\"price\"]","8abfb537":"X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.30,random_state=42)\nscale = preprocessing.StandardScaler()\nscale.fit(X_train)\nX_train = scale.transform(X_train)\nX_test = scale.transform(X_test)","dac02da6":"N_regressor = LinearRegression()\nN_regressor.fit(X_train,y_train)","f376c3fa":"new_y_train_pred= N_regressor.predict(X_train)\nnew_y_test_pred=N_regressor.predict(X_test)","234dcf17":"MAE_train=mean_absolute_error(y_train,new_y_train_pred)\nMAE_test=mean_absolute_error(y_test,new_y_test_pred)\n\nRMSE_train=np.sqrt(mean_squared_error(y_train,new_y_train_pred))\nRMSE_test=np.sqrt(mean_squared_error(y_test,new_y_test_pred))\n\nr2_train= metrics.r2_score(y_train, new_y_train_pred)\nr2_test= metrics.r2_score(y_test, new_y_test_pred)\n\nadj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\nadj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",MAE_train)\nprint(\"El MAE en test es:\",MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",RMSE_train)\nprint(\"El RMSE en test es:\",RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",r2_train)\nprint(\"El r2 de test es:\",r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",adj_r2_train)\nprint(\"El r2 ajustado de test es:\",adj_r2_test)","34394cb9":"N_arbol_regressor = DecisionTreeRegressor(random_state=42)\nN_knn_regressor = KNeighborsRegressor()","db7b33a9":"N_arbol_regressor.fit(X_train,y_train)\nN_knn_regressor.fit(X_train,y_train)","dde7892a":"y_arbol_pred_train = N_arbol_regressor.predict(X_train)\ny_arbol_pred_test = N_arbol_regressor.predict(X_test)\n\ny_knn_pred_train = N_knn_regressor.predict(X_train)\ny_knn_pred_test = N_knn_regressor.predict(X_test)","18edd988":"arbol_MAE_train=mean_absolute_error(y_train,y_arbol_pred_train)\narbol_MAE_test=mean_absolute_error(y_test,y_arbol_pred_test)\n\narbol_RMSE_train=np.sqrt(mean_squared_error(y_train,y_arbol_pred_train))\narbol_RMSE_test=np.sqrt(mean_squared_error(y_test,y_arbol_pred_test))\n\narbol_r2_train= metrics.r2_score(y_train, y_arbol_pred_train)\narbol_r2_test= metrics.r2_score(y_test, y_arbol_pred_test)\n\narbol_adj_r2_train = 1 - ((1 - arbol_r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\narbol_adj_r2_test = 1 - ((1 - arbol_r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",arbol_MAE_train)\nprint(\"El MAE en test es:\",arbol_MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",arbol_RMSE_train)\nprint(\"El RMSE en test es:\",arbol_RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",arbol_r2_train)\nprint(\"El r2 de test es:\",arbol_r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",arbol_adj_r2_train)\nprint(\"El r2 ajustado de test es:\",arbol_adj_r2_test)","f2d96bad":"knn_MAE_train=mean_absolute_error(y_train,y_knn_pred_train)\nknn_MAE_test=mean_absolute_error(y_test,y_knn_pred_test)\n\nknn_RMSE_train=np.sqrt(mean_squared_error(y_train,y_knn_pred_train))\nknn_RMSE_test=np.sqrt(mean_squared_error(y_test,y_knn_pred_test))\n\nknn_r2_train= metrics.r2_score(y_train, y_knn_pred_train)\nknn_r2_test= metrics.r2_score(y_test, y_knn_pred_test)\n\nknn_adj_r2_train = 1 - ((1 - knn_r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\nknn_adj_r2_test = 1 - ((1 - knn_r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n    \n\nprint(\"El MAE en train es:\",knn_MAE_train)\nprint(\"El MAE en test es:\",knn_MAE_test)\nprint(\"-------------------------------------------\")\nprint(\"El RMSE en train es:\",knn_RMSE_train)\nprint(\"El RMSE en test es:\",knn_RMSE_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 de train es:\",knn_r2_train)\nprint(\"El r2 de test es:\",knn_r2_test)\nprint(\"-------------------------------------------\")\nprint(\"El r2 ajustado de train es:\",knn_adj_r2_train)\nprint(\"El r2 ajustado de test es:\",knn_adj_r2_test)","fd203543":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([N_regressor, N_arbol_regressor, N_knn_regressor]):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_train, y_train_pred)\n    r2_test= metrics.r2_score(y_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","a5e78161":"MAX_DEPTH_range = range(1, 21)\nscores = []\narbol_r2_train_pred=[]\narbol_r2_test_pred=[]\n\nfor k in MAX_DEPTH_range:\n    N_arbol_regressor = DecisionTreeRegressor(max_depth=k,random_state=42)\n    N_arbol_regressor.fit(X_train, y_train)\n    scores.append(N_arbol_regressor.score(X_test, y_test))\n    \n    y_train_pred = N_arbol_regressor.predict(X_train)\n    arbol_r2_train = metrics.r2_score(y_train, y_train_pred)\n    arbol_r2_train_pred.append(arbol_r2_train)\n    \n    y_test_pred = N_arbol_regressor.predict(X_test)\n    arbol_r2_test = metrics.r2_score(y_test, y_test_pred)\n    arbol_r2_test_pred.append(arbol_r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(MAX_DEPTH_range,scores,marker=\"o\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_test_pred,marker=\"o\",label=\"test\")\n\nax1.set_xticks(MAX_DEPTH_range)\nax2.set_xticks(MAX_DEPTH_range)\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('max depth')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('max depth')\nax2.set_ylabel('r2')\n\nplt.show()","3e7d8a4d":"k_range = range(1, 21)\nscores = []\nr2_train_pred=[]\nr2_train_test=[]\n\nfor k in k_range:\n    N_knn_regressor = KNeighborsRegressor(n_neighbors = k)\n    N_knn_regressor.fit(X_train, y_train)\n    scores.append(N_knn_regressor.score(X_test, y_test))\n    \n    y_train_pred = N_knn_regressor.predict(X_train)\n    r2_train = metrics.r2_score(y_train, y_train_pred)\n    r2_train_pred.append(r2_train)\n    \n    y_test_pred = N_knn_regressor.predict(X_test)\n    r2_test = metrics.r2_score(y_test, y_test_pred)\n    r2_train_test.append(r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(k_range,scores,marker=\"o\")\nax2.scatter(k_range,r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(k_range,r2_train_test,marker=\"o\",label=\"test\")\n\nax1.set_xticks(k_range)\nax2.set_xticks(k_range)\n\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('k')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('k')\nax2.set_ylabel('r2')\n\nplt.show()","fdf46a86":"N_optimo_arbol = DecisionTreeRegressor(max_depth=20,random_state=42)\nN_optimo_knn = KNeighborsRegressor(n_neighbors=4)\n\nN_optimo_arbol.fit(X_train,y_train)\n\nN_optimo_knn.fit(X_train,y_train)","5265053c":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([N_regressor, N_optimo_arbol, N_optimo_knn]):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_train, y_train_pred)\n    r2_test= metrics.r2_score(y_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_train) - 1)) \/ (len(y_train) - X_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_test) - 1)) \/ (len(y_test) - X_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_test,y_test_pred))\n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","ce3f95bb":"dataset2 =pd.read_csv(\"..\/input\/properati-dataset\/DS_Proyecto_01_Datos_Properati.csv\")","1191e71c":"dataset2 = dataset2[((dataset2['property_type'] == \"Departamento\") |\n                  (dataset2['property_type'] == \"Casa\") |\n                  (dataset2['property_type'] == \"PH\")) \n                  & (dataset2['l2'] == \"Capital Federal\")]","d4b60d5f":"dataset2 = pd.get_dummies(data=dataset2,prefix=\"barrio\",columns=[\"l3\"])","e8ecb3db":"dataset2.columns","bd4c8419":"superficie_min=15\nsuperficie_max=1000\n\ndataset2 = dataset2[(dataset2.surface_total <= 1000) &\n                        (dataset2.surface_total >= 15)]","bb52f960":"dataset2 = dataset2[(dataset2.price <= 4000000)]","b6669748":"dataset2=dataset2.dropna()","bbe46939":"dataset2.describe()","a04efe8b":"dataset2.shape","f303cfda":"dataset2 = dataset2.drop(['start_date', 'end_date', 'created_on', 'lat', 'lon', 'l1', 'l2','currency', 'title', 'description',\"operation_type\"],axis=1)","88000228":"dataset2.columns","e593e660":"dpto_data= dataset2[dataset2[\"property_type\"]==\"Departamento\"]\ncasa_data =dataset2[dataset2[\"property_type\"]==\"Casa\"]\nph_data=dataset2[dataset2[\"property_type\"]==\"PH\"]","6ca37141":"dpto_data.columns","64dcc277":"X_d=dpto_data.drop([\"price\",\"rooms\",\"surface_total\",\"property_type\"],axis=1)\ny_d=dpto_data[\"price\"]","e1800613":"X_d_train,X_d_test,y_d_train,y_d_test=train_test_split(X_d,y_d,test_size=0.30,random_state=42)","ae7fb1a2":"scale = preprocessing.StandardScaler()\nscale.fit(X_d_train)\nX_d_train = scale.transform(X_d_train)\nX_d_test = scale.transform(X_d_test)","7a50ee80":"dpto_regressor = LinearRegression()\ndpto_regressor.fit(X_d_train,y_d_train)\n\ndpto_y_train_pred= dpto_regressor.predict(X_d_train)\ndpto_y_test_pred=dpto_regressor.predict(X_d_test)","07370c24":"dpto_arbol_regressor = DecisionTreeRegressor(random_state=42)\ndpto_knn_regressor = KNeighborsRegressor()\n\ndpto_arbol_regressor.fit(X_d_train,y_d_train)\ndpto_knn_regressor.fit(X_d_train,y_d_train)\n\n\ndpto_arbol_pred_train = dpto_arbol_regressor.predict(X_d_train)\ndpto_arbol_pred_test = dpto_arbol_regressor.predict(X_d_test)\n\ndpto_knn_pred_train = dpto_knn_regressor.predict(X_d_train)\ndpto_knn_pred_test = dpto_knn_regressor.predict(X_d_test)","fa57c873":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([dpto_regressor, dpto_arbol_regressor, dpto_knn_regressor]):\n    y_train_pred = model.predict(X_d_train)\n    y_test_pred = model.predict(X_d_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_d_train, y_train_pred)\n    r2_test= metrics.r2_score(y_d_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_d_train) - 1)) \/ (len(y_d_train) - X_d_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_d_test) - 1)) \/ (len(y_d_test) - X_d_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_d_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_d_test,y_test_pred))\n    \n    MAE_train=mean_absolute_error(y_d_train,y_train_pred)\n    MAE_test=mean_absolute_error(y_d_test,y_test_pred)\n    \n    \n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    print(\"--------------------------\")\n    print(\"MAE en train:\",MAE_train)\n    print(\"MAE en test:\",MAE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_d_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","b4668ca4":"MAX_DEPTH_range = range(1, 21)\nscores = []\narbol_r2_train_pred=[]\narbol_r2_test_pred=[]\n\nfor k in MAX_DEPTH_range:\n    dpto_arbol_regressor = DecisionTreeRegressor(max_depth=k,random_state=42)\n    dpto_arbol_regressor.fit(X_d_train, y_d_train)\n    scores.append(dpto_arbol_regressor.score(X_d_test, y_d_test))\n    \n    y_train_pred = dpto_arbol_regressor.predict(X_d_train)\n    arbol_r2_train = metrics.r2_score(y_d_train, y_train_pred)\n    arbol_r2_train_pred.append(arbol_r2_train)\n    \n    y_test_pred = dpto_arbol_regressor.predict(X_d_test)\n    arbol_r2_test = metrics.r2_score(y_d_test, y_test_pred)\n    arbol_r2_test_pred.append(arbol_r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(MAX_DEPTH_range,scores,marker=\"o\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_test_pred,marker=\"o\",label=\"test\")\n\nax1.set_xticks(MAX_DEPTH_range)\nax2.set_xticks(MAX_DEPTH_range)\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('max depth')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('max depth')\nax2.set_ylabel('r2')\n\nax1.grid()\nax2.grid()\nplt.grid()\nplt.show()","f725e62b":"%%time\nk_range = [3]\nscores = []\nr2_train_pred=[]\nr2_train_test=[]\n\nfor k in k_range:\n    dpto_knn_regressor = KNeighborsRegressor(n_neighbors = k)\n    dpto_knn_regressor.fit(X_d_train, y_d_train)\n    scores.append(dpto_knn_regressor.score(X_d_test, y_d_test))\n    \n    y_train_pred = dpto_knn_regressor.predict(X_d_train)\n    r2_train = metrics.r2_score(y_d_train, y_train_pred)\n    r2_train_pred.append(r2_train)\n    \n    y_test_pred = dpto_knn_regressor.predict(X_d_test)\n    r2_test = metrics.r2_score(y_d_test, y_test_pred)\n    r2_train_test.append(r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(k_range,scores,marker=\"o\")\nax2.scatter(k_range,r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(k_range,r2_train_test,marker=\"o\",label=\"test\")\n\nax1.set_xticks(k_range)\nax2.set_xticks(k_range)\n\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('k')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('k')\nax2.set_ylabel('r2')\n\nax1.grid()\nax2.grid()\nplt.grid()\nplt.show()","d34cba67":"dpto_optimo_arbol = DecisionTreeRegressor(max_depth=20,random_state=42)\ndpto_optimo_knn = KNeighborsRegressor(n_neighbors=3)\n\ndpto_optimo_arbol.fit(X_d_train,y_d_train)\n\ndpto_optimo_knn.fit(X_d_train,y_d_train)","9cb245f6":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([dpto_regressor, dpto_optimo_arbol, dpto_optimo_knn]):\n    y_train_pred = model.predict(X_d_train)\n    y_test_pred = model.predict(X_d_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_d_train, y_train_pred)\n    r2_test= metrics.r2_score(y_d_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_d_train) - 1)) \/ (len(y_d_train) - X_d_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_d_test) - 1)) \/ (len(y_d_test) - X_d_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_d_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_d_test,y_test_pred))\n    \n    MAE_train=mean_absolute_error(y_d_train,y_train_pred)\n    MAE_test=mean_absolute_error(y_d_test,y_test_pred)\n    \n    \n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    print(\"--------------------------\")\n    print(\"MAE en train:\",MAE_train)\n    print(\"MAE en test:\",MAE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_d_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","79df3a40":"X_p=ph_data.drop([\"price\",\"rooms\",\"surface_total\",\"property_type\"],axis=1)\ny_p=ph_data[\"price\"]","43b53b8d":"X_p_train,X_p_test,y_p_train,y_p_test=train_test_split(X_p,y_p,test_size=0.30,random_state=42)","7e47658a":"scale = preprocessing.StandardScaler()\nscale.fit(X_p_train)\nX_p_train = scale.transform(X_p_train)\nX_p_test = scale.transform(X_p_test)","694c4d65":"ph_regressor = LinearRegression()\nph_regressor.fit(X_p_train,y_p_train)\nph_y_train_pred= ph_regressor.predict(X_d_train)\nph_y_test_pred=ph_regressor.predict(X_d_test)\n\n\n\nph_arbol_regressor = DecisionTreeRegressor(random_state=42)\nph_knn_regressor = KNeighborsRegressor()\n\nph_arbol_regressor.fit(X_p_train,y_p_train)\nph_knn_regressor.fit(X_p_train,y_p_train)","00bc20b4":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([ph_regressor, ph_arbol_regressor, ph_knn_regressor]):\n    y_train_pred = model.predict(X_p_train)\n    y_test_pred = model.predict(X_p_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_p_train, y_train_pred)\n    r2_test= metrics.r2_score(y_p_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_p_train) - 1)) \/ (len(y_p_train) - X_p_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_p_test) - 1)) \/ (len(y_p_test) - X_p_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_p_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_p_test,y_test_pred))\n    \n    MAE_train=mean_absolute_error(y_p_train,y_train_pred)\n    MAE_test=mean_absolute_error(y_p_test,y_test_pred)\n    \n    \n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    print(\"--------------------------\")\n    print(\"MAE en train:\",MAE_train)\n    print(\"MAE en test:\",MAE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_p_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","139ee507":"MAX_DEPTH_range = range(1, 21)\nscores = []\narbol_r2_train_pred=[]\narbol_r2_test_pred=[]\n\nfor k in MAX_DEPTH_range:\n    ph_arbol_regressor = DecisionTreeRegressor(max_depth=k,random_state=42)\n    ph_arbol_regressor.fit(X_p_train, y_p_train)\n    scores.append(ph_arbol_regressor.score(X_p_test, y_p_test))\n    \n    y_train_pred = ph_arbol_regressor.predict(X_p_train)\n    arbol_r2_train = metrics.r2_score(y_p_train, y_train_pred)\n    arbol_r2_train_pred.append(arbol_r2_train)\n    \n    y_test_pred = ph_arbol_regressor.predict(X_p_test)\n    arbol_r2_test = metrics.r2_score(y_p_test, y_test_pred)\n    arbol_r2_test_pred.append(arbol_r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(MAX_DEPTH_range,scores,marker=\"o\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_test_pred,marker=\"o\",label=\"test\")\n\nax1.set_xticks(MAX_DEPTH_range)\nax2.set_xticks(MAX_DEPTH_range)\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('max depth')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('max depth')\nax2.set_ylabel('r2')\n\nax1.grid()\nax2.grid()\nplt.grid()\nplt.show()","efe5993f":"%%time\nk_range = range(1, 11)\nscores = []\nr2_train_pred=[]\nr2_train_test=[]\n\nfor k in k_range:\n    ph_knn_regressor = KNeighborsRegressor(n_neighbors = k)\n    ph_knn_regressor.fit(X_p_train, y_p_train)\n    scores.append(ph_knn_regressor.score(X_p_test, y_p_test))\n    \n    y_train_pred = ph_knn_regressor.predict(X_p_train)\n    r2_train = metrics.r2_score(y_p_train, y_train_pred)\n    r2_train_pred.append(r2_train)\n    \n    y_test_pred = ph_knn_regressor.predict(X_p_test)\n    r2_test = metrics.r2_score(y_p_test, y_test_pred)\n    r2_train_test.append(r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(k_range,scores,marker=\"o\")\nax2.scatter(k_range,r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(k_range,r2_train_test,marker=\"o\",label=\"test\")\n\nax1.set_xticks(k_range)\nax2.set_xticks(k_range)\n\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('k')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('k')\nax2.set_ylabel('r2')\n\nplt.show()","4b54ff2a":"ph_optimo_arbol = DecisionTreeRegressor(max_depth=19,random_state=42)\nph_optimo_knn = KNeighborsRegressor(n_neighbors=2)\n\nph_optimo_arbol.fit(X_p_train,y_p_train)\n\nph_optimo_knn.fit(X_p_train,y_p_train)","89ee1748":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([ph_regressor, ph_optimo_arbol, ph_optimo_knn]):\n    y_train_pred = model.predict(X_p_train)\n    y_test_pred = model.predict(X_p_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_p_train, y_train_pred)\n    r2_test= metrics.r2_score(y_p_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_p_train) - 1)) \/ (len(y_p_train) - X_p_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_p_test) - 1)) \/ (len(y_p_test) - X_p_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_p_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_p_test,y_test_pred))\n    \n    MAE_train=mean_absolute_error(y_p_train,y_train_pred)\n    MAE_test=mean_absolute_error(y_p_test,y_test_pred)\n    \n    \n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    print(\"--------------------------\")\n    print(\"MAE en train:\",MAE_train)\n    print(\"MAE en test:\",MAE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_p_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","c330c5a8":"X_c=casa_data.drop([\"price\",\"rooms\",\"surface_total\",\"property_type\"],axis=1)\ny_c=casa_data[\"price\"]","8b4825cb":"X_c_train,X_c_test,y_c_train,y_c_test=train_test_split(X_c,y_c,test_size=0.30,random_state=42)","37f45f20":"scale = preprocessing.StandardScaler()\nscale.fit(X_c_train)\nX_c_train = scale.transform(X_c_train)\nX_c_test = scale.transform(X_c_test)","a2928ad4":"casa_regressor = LinearRegression()\ncasa_regressor.fit(X_c_train,y_c_train)\n","0310901b":"casa_arbol_regressor = DecisionTreeRegressor(random_state=42)\ncasa_knn_regressor = KNeighborsRegressor()\n\ncasa_arbol_regressor.fit(X_c_train,y_c_train)\ncasa_knn_regressor.fit(X_c_train,y_c_train)\n","61e5f4ce":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([casa_regressor, casa_arbol_regressor, casa_knn_regressor]):\n    y_train_pred = model.predict(X_c_train)\n    y_test_pred = model.predict(X_c_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_c_train, y_train_pred)\n    r2_test= metrics.r2_score(y_c_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_c_train) - 1)) \/ (len(y_c_train) - X_c_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_c_test) - 1)) \/ (len(y_c_test) - X_c_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_c_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_c_test,y_test_pred))\n    \n    MAE_train=mean_absolute_error(y_c_train,y_train_pred)\n    MAE_test=mean_absolute_error(y_c_test,y_test_pred)\n    \n    \n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    print(\"--------------------------\")\n    print(\"MAE en train:\",MAE_train)\n    print(\"MAE en test:\",MAE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_c_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","964448b6":"MAX_DEPTH_range = range(1, 21)\nscores = []\narbol_r2_train_pred=[]\narbol_r2_test_pred=[]\n\nfor k in MAX_DEPTH_range:\n    casa_arbol_regressor = DecisionTreeRegressor(max_depth=k,random_state=42)\n    casa_arbol_regressor.fit(X_c_train, y_c_train)\n    scores.append(casa_arbol_regressor.score(X_c_test, y_c_test))\n    \n    y_train_pred = casa_arbol_regressor.predict(X_c_train)\n    arbol_r2_train = metrics.r2_score(y_c_train, y_train_pred)\n    arbol_r2_train_pred.append(arbol_r2_train)\n    \n    y_test_pred = casa_arbol_regressor.predict(X_c_test)\n    arbol_r2_test = metrics.r2_score(y_c_test, y_test_pred)\n    arbol_r2_test_pred.append(arbol_r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(MAX_DEPTH_range,scores,marker=\"o\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(MAX_DEPTH_range,arbol_r2_test_pred,marker=\"o\",label=\"test\")\n\nax1.set_xticks(MAX_DEPTH_range)\nax2.set_xticks(MAX_DEPTH_range)\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('max depth')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('max depth')\nax2.set_ylabel('r2')\n\nax1.grid()\nax2.grid()\nplt.grid()\nplt.show()","473a9f96":"k_range = range(1, 21)\nscores = []\nr2_train_pred=[]\nr2_train_test=[]\n\nfor k in k_range:\n    casa_knn_regressor = KNeighborsRegressor(n_neighbors = k)\n    casa_knn_regressor.fit(X_c_train, y_c_train)\n    scores.append(casa_knn_regressor.score(X_c_test, y_c_test))\n    \n    y_train_pred = casa_knn_regressor.predict(X_c_train)\n    r2_train = metrics.r2_score(y_c_train, y_train_pred)\n    r2_train_pred.append(r2_train)\n    \n    y_test_pred = casa_knn_regressor.predict(X_c_test)\n    r2_test = metrics.r2_score(y_c_test, y_test_pred)\n    r2_train_test.append(r2_test)\n    \n\nfig = plt.figure(figsize=(15,4))\n\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n\nax1.scatter(k_range,scores,marker=\"o\")\nax2.scatter(k_range,r2_train_pred,marker=\"o\",label=\"train\")\nax2.scatter(k_range,r2_train_test,marker=\"o\",label=\"test\")\n\nax1.set_xticks(k_range)\nax2.set_xticks(k_range)\n\n\nax2.legend()\n\n\nax1.set_title('exactitud')\nax1.set_xlabel('k')\nax1.set_ylabel('exactitud')\n\nax2.set_title('r2')\nax2.set_xlabel('k')\nax2.set_ylabel('r2')\n\nplt.show()","68e4a826":"casa_optimo_arbol = DecisionTreeRegressor(max_depth=17,random_state=42)\ncasa_optimo_knn = KNeighborsRegressor(n_neighbors=2)\n\ncasa_optimo_arbol.fit(X_c_train,y_c_train)\n\ncasa_optimo_knn.fit(X_c_train,y_c_train)","3087fe96":"models = ['Regresi\u00f3n lineal', '\u00c1rbol de Decisi\u00f3n', 'Vecinos m\u00e1s cercanos']\n\nfor i, model in enumerate([casa_regressor, casa_optimo_arbol, casa_optimo_knn]):\n    y_train_pred = model.predict(X_c_train)\n    y_test_pred = model.predict(X_c_test)\n    \n    print(f'Modelo: {models[i]}')\n    \n    r2_train= metrics.r2_score(y_c_train, y_train_pred)\n    r2_test= metrics.r2_score(y_c_test, y_test_pred)\n    \n    adj_r2_train = 1 - ((1 - r2_train) * (len(y_c_train) - 1)) \/ (len(y_c_train) - X_c_train.shape[1] - 1)\n    adj_r2_test = 1 - ((1 - r2_test) * (len(y_c_test) - 1)) \/ (len(y_c_test) - X_c_test.shape[1] - 1)\n\n    RMSE_train=np.sqrt(mean_squared_error(y_c_train,y_train_pred))\n    RMSE_test=np.sqrt(mean_squared_error(y_c_test,y_test_pred))\n    \n    MAE_train=mean_absolute_error(y_c_train,y_train_pred)\n    MAE_test=mean_absolute_error(y_c_test,y_test_pred)\n    \n    \n\n    print(\"R2 en Train:\", r2_train)\n    print(\"R2 ajustado en train:\", adj_r2_train)\n    print(\"--------------------------\")\n    print(\"R2 en test:\", r2_test)\n    print(\"R2 ajustado en Test:\", adj_r2_test)\n    print(\"--------------------------\")\n    print(\"RMSE en train:\",RMSE_train)\n    print(\"RMSE en test:\",RMSE_test)\n    print(\"--------------------------\")\n    print(\"MAE en train:\",MAE_train)\n    print(\"MAE en test:\",MAE_test)\n    \n\n    plt.figure(figsize = (14,4))\n   \n    ax = plt.subplot(1,2,2)\n    ax.scatter(y_c_test,y_test_pred, s =2)\n    \n    lims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n    ]\n    \n    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n    plt.xlabel('y (test)')\n    plt.ylabel('y_pred (test)')\n    \n    plt.tight_layout()\n    plt.show()","0aae7ec2":"##### --> Calculador de profundidad de arbol","7801e10f":"### <font color=green>\u2666 Elegir una m\u00e9trica apropiada para evaluar los resultados de los modelos.<\/font>\n#### --> Para el desarrollo del punto 3 se utilizaran las siguientes metricas de analisis:","fbb303a4":"#### --> Knn","2a6e766a":"   #####          --> La utilizacion del cuantil 0.01 es con motivo de evitar tener valores negativos en la superficie minima","1c1c91f5":"#### Conclusion: El modelo de Arbol de Decision solo dirigido a Departamentos sin optimizacion muestra excelentes metricas, incluso superando al modelo de Arbol de decision Optimizado.\n","a76d4795":"### --> A continuacion se presentan 2 tipos de tecnicas para eleccion y limpieza de features, seran vistas en EXTRA 1 Y EXTRA 2","21cd4aa3":"#### <font color=green>\u2666E. El rango de precios que toman las propiedades es muy amplio. Estudia la distribuci\u00f3n de esa variable y filtra por un valor razonable que te permita obtener gr\u00e1ficos comprensibles. Puede ser \u00fatil un boxplot para determinar un rango razonable.","94fbeee9":"## <font color=green>Extra: Analisis considerando la multicolinealidad","75c82aa1":"1. <font color=green>Carga el dataset usando las funcionalidades de Pandas. Imprimir cu\u00e1ntas filas y columnas tiene, y sus cinco primeras instancias.","29f0b0d3":"### Conclusion: \n#### \u2022 La profundidad optima del arbol de decision se encuentra en 17, valor que es justificado al comparar con el grafico de R2\n#### \u2022 El numero optimo de vecinos mas cercanos se encuentra en 3, donde encontramos una exactitud de 0.75, aunque el r2 en este caso se ve algo afectado si consideramos Train, aun asi en Test encontramos el punto mas alto en 3","428d5765":"#### Mejora de los modelos KNN y Arbol de Decision","0f9868b2":"##### <font color=green>\u2666 Descarta aquellas instacias con valores faltantes.","7b2e3d93":"### <font color=green>\u2666 Generar un modelo benchmark y evaluarlo.<\/font>","48d95072":"### Conclusion: Los Features \"rooms\" y \"bedrooms\" tienen una correlacion de mas de 30!, por lo tanto bedrooms o room puede ser eliminado","8006943c":"##### <font color=green>\u2666B. Algunas instancias tienen valores de superficie (surface_total) muy grandes y dificultan la correcta visualizaci\u00f3n. Estudia la distribuci\u00f3n de esa variable y filtra por un valor razonable que te permita obtener gr\u00e1ficos comprensibles. Puede ser \u00fatil un boxplot para determinar un rango razonable.\n##### <font color=green>\u2666C. Lo mismo ocurre con valores de superficie total muy chico.","1936d228":"##### --> Aqui tambien se utilizara el IQR por sobre el Z_score","c3c4d51d":"### <font color=green> \u2666 Realizar un Train\/Test split de los datos.<\/font>","762ebd7f":"5. <font color=green>**Filtrando el Dataset:** A partir de los resultados del punto 3. y 4., selecciona las tres clases m\u00e1s abundantes de tipos de propiedad y la regi\u00f3n con m\u00e1s propiedades publicadas. Crea un nuevo Data Frame con aquellas instancias que cumplen con esas condiciones e imprime su `shape`.","811b9421":"#### Conclusion: El modelo de Arbol de decision sin Optimizacion es el modelo que consigue mejores metricas dentro del grupo analizado con RFE, aun asi, este modelo obtiene peores metricas que el Modelo de Arbol de Decision Optimizado, por consiguiente este modelo ha vencido a los modelos bajo analisis con VIF Y RFE.","8c3b98dc":"##### <font color=green>\u2666 Selecciona aquellas propiedades cuya precio es menor 4000000 d\u00f3lares.","6207eaa7":"#### Mejora de los modelos KNN y Arbol de Decision","c9ad6812":"##### Para el grafico mostrado en la parte superior se decidio hacer un ajuste en \"Y\" y asi poder mostrar todos los tipos de propiedades, esto tiene como punto en contra de que reduce la exactitud del grafico para poder leer los valores, esto significa que es dificil inferir las cantidades a simple vista si los niveles de medicion son 1000, 10000 y 100000.","c2fbb3c2":"Los resultados son los siguientes:\n\n<font color=green>Modelo de Arbol de decision con Optimizacion:\n\n    *R2 en Train: 0.952\n    *R2 ajustado en train: 0.952\n\n    *R2 en test: 0.766\n    *R2 ajustado en Test: 0.766\n\n    *RMSE en train: 64721.069\n    *RMSE en test: 146092.758\n        \n<font color=green>Modelo de KNN dirigido a Casas con Optimizacion:\n    \n    *R2 en Train: 0.850\n    *R2 ajustado en train: 0.844\n\n    *R2 en test: 0.593\n    *R2 ajustado en Test: 0.550\n\n    *RMSE en train: 107927.370\n    *RMSE en test: 138907.629","ef12f2d0":"#### <font color=green>\u2666 Evaluar los modelos obtenidos. Para ello, eval\u00faa la m\u00e9trica elegida en el conjunto de Test y en el conjunto de Train. Tambi\u00e9n, realiza gr\u00e1ficos de valores reales vs. valores predichos.<\/font>\n","2295abfc":"Los resultados son los siguientes:\n\n<font color=green>Modelo de Arbol de decision con Optimizacion:\n\n    *R2 en Train: 0.952\n    *R2 ajustado en train: 0.952\n\n    *R2 en test: 0.766\n    *R2 ajustado en Test: 0.766\n\n    *RMSE en train: 64721.069\n    *RMSE en test: 146092.758\n        \n<font color=green>Modelo de Arbol de decision dirigido a Departamentos y sin Optimizacion:\n    \n    *R2 en Train: 0.969\n    *R2 ajustado en train: 0.969\n\n    *R2 en test: 0.888\n    *R2 ajustado en Test: 0.888\n\n    *RMSE en train: 52382.162\n    *RMSE en test: 101261.762\n    ","30279236":"##### <font color=green>\u2666 Selecciona las columnas rooms, bedrooms, bathrooms, surface_total, surface_covered y price.","30ecad08":"#### --> Por motivos de practicidad y en vistas de que los NaN representaban solamente el 5% de los valores, se tomo la decision de eliminarlos para facilitar el desarrollo del desafio","0c8f720a":"##### Para un primer vistazo de las variables presentadas, es conveniente la utilizacion de un PairPlot\n","82e49628":"#### Bathrooms","c4d4a6c0":"#### Bedrooms","e2f0ed4f":"### KNN y Arbol de decision","d48bc9dc":"#### Nota Importante: Tanto el uso de VIF,SVR y RFE nos ayudan a tratar con los features \"obligatorios\" de la consigna y al mismo tiempo a solo seleccionar los mejores de entre ellos para los modelos predictivos. Pero aun asi no es suficiente para logar un buen algoritmo predictivo que no sufra tantos errores, esto se puede deber a que se esta omitiendo informacion clave para las predicciones, como puede ser el \"barrio\"(existe la posibilidad de utilizar dummies para incluirlo) o tambien puede deberse a que quizas sea necesario tratar los 3 tipos de propiedades en modelos distintos. \n\n\n\n### <font color=red>En el siguiente apartado se trabajara con los barrios y se realizara un analisis para cada tipo de propiedad en particular:","31bbb783":"#### Como ya vimos en casos anteriores el cuantil 0.01 nos permite eliminar resultados negativos a la hora de utlizar el IQR","d21fcc47":"##### \u2666La siguiente operacion nos permite ver la cantidad de valores nulos que encontramos en cada columna","1dd2cfce":"Los resultados son los siguientes:\n\n<font color=green>Modelo de Arbol de decision con Optimizacion:\n\n    *R2 en Train: 0.952\n    *R2 ajustado en train: 0.952\n\n    *R2 en test: 0.766\n    *R2 ajustado en Test: 0.766\n\n    *RMSE en train: 64721.069\n    *RMSE en test: 146092.758\n        \n<font color=green>Modelo de Arbol de decision sin Optimizacion y con RFE:\n    \n    *R2 en Train: 0.871\n    *R2 ajustado en train: 0.871\n\n    *R2 en test: 0.743\n    *R2 ajustado en Test: 0.743\n\n    *RMSE en train: 106793.832\n    *RMSE en test: 152967.094\n    ","a416b717":"#### Conclusion: El modelo de Arbol de decision sin Optimizacion y con VIF muestra ser mejor que el modelo optimizado con VIF. Estos nuevos resultados parecen ser en extremo parecidos al modelo de Arbol de decision con Optimizacion. El primer modelo que vemos debajo, muestra mejores resultados en los Test, pero el segundo modelo mostrado muestra mejores resultados en Train. \n\n##### Para finalizar esta comparacion se decide elegir el modelo que muestra mejores resultados en Test, ya que es el area que realmente nos importa. En sintesis el Modelo de Arbol de decision con Optimizacion continua venciendo.","f9f546b0":"##### La Optimizacion de modelos fue establecida en Max_Depth=17 para Arbol y K-vecinos=2 para KNN","9466fee9":"##### <font color=green>Checkpoint: deber\u00edas obtener un dataset con 81019 instacias y 6 columnas","90b366ea":"#### --> El siguiente grafico nos permite observar que despues del filtrado ya ninguna propiedad tiene una superficie cubierta mayor a la superficie total","cc19549b":"#### --> Se utiliza \".shape\" para poder ver la cantidad de filas y columnas en el Dataset","9e8b2ced":"# Proyecto: An\u00e1lisis de mercado inmobiliario\n\n\u00a1Bienvenido\/a al primer proyecto de la carrera de Data Science de Acamica! \n\nEl objetivo de este proyecto es reproducir los pasos que har\u00eda un\/a Data Scientist cuando se enfrenta a una problem\u00e1tica real. Por eso, consta de tres secciones:\n* En la Parte 1, te presentamos la problem\u00e1tica sobre la cual vas a trabajar. En esta secci\u00f3n deber\u00e1s decidir qu\u00e9 datos te ayudar\u00e1n a trabajar en este problema y d\u00f3nde puedes conseguirlos.\n* En la Parte 2 te proveemos de un dataset para abordar la problem\u00e1tica planteada. Deber\u00e1s realizar un An\u00e1lisis Exploratorio de Datos sobre este dataset.\n* En la Parte 3, deber\u00e1s utilizar herramientas de Machine Learning para predecir la variable de inter\u00e9s.\n\n\nEn este proyecto vas a trabajar con un dataset de propiedades en venta publicado en el portal [Properati](www.properati.com.ar).\n\n**Importante:** recuerda que un notebook es un informe, por lo que debes ir explicando lo que haces a medida que resuelves las consignas. Es importante que quien que lo lea entienda el flujo de trabajo, qu\u00e9 quisiste hacer. Recuerda, simple y conciso es una combinaci\u00f3n ganadora. \n\n## Problema\n\nRecientemente te has incorporado al equipo de Datos de una gran inmobiliaria. La primera tarea que se te asigna es ayudar a los tasadores\/as a valuar las propiedades, ya que es un proceso dif\u00edcil y, a veces, subjetivo. Para ello, propones crear un modelo de Machine Learning que, dadas ciertas caracter\u00edsticas de la propiedad, prediga su precio de venta.\n\n### 1. Pensando como un\/a Data Scientist\n\nResponde la siguientes pregunta:\n1. \u00bfQu\u00e9 datos crees que te ayudar\u00edan a trabajar en el problema?\u00bfPor qu\u00e9?\n\n**Importante**: NO deber\u00e1s buscar esos datos, solamente justificar qu\u00e9 informaci\u00f3n crees que te ayudar\u00eda a resolver la problem\u00e1tica planteada.","dbdf92a1":"#### Conclusion: Los valores superiorees a 20000 seguramente sean outliers","44dd94af":"#### Vemos que los valores otorgados no son enteros, por ende usaremos el ceil, para elevarlos al entero mas cercano. La eleccion de esta decision se basa en que si hubiese seleccionado el metodo floor, habria obtenido un rooms de 0 en departamento y este era un valor outlier.","7db1c845":"#### Conclusion: bedrooms = 0 y rooms = 1 indican monoambientes","3c58f4eb":"## <font color=red>Analisis en Departamentos","5983eeae":"### Resultados con optimizacion","866ddaf1":"<font color=pink>**R2**\n\nEl coeficiente de determinaci\u00f3n (R2 o R-squared) mide la porci\u00f3n de la varianza de la variable objetivo que se puede explicar por el modelo.\n\nR2 tiene un valor m\u00e1ximo de 1 (cuando el modelo explica toda la varianza) , aunque puede tener valores negativos.\n\nUn problema importante que tiene R2 es que no nos indica si el modelo explica la varianza debido a que est\u00e1 sobreajustado (overfitted). Por eso una medida mejor es el Coeficiente de Determinacion ajustado (Adjusted R-squared), que tiene en consideracion la complejidad del modelo.\n\n$$1 - \\frac{(1 - R^2)(n-1)}{(n-k-1)}$$\n","8155e691":"#### Mejora de los modelos KNN y Arbol de Decision","3e09f5c4":"##### Se eliminan las features se\u00f1aladas por el RFE anteriormente.","2733ee42":"# EXTRA 2: utlizacion de RFE Y SVR para seleccion de features","676e81cd":"#### --> Arbol de regresion","c0253645":"##### --> En este primer grafico observamos que tenemos propiedades donde la superficie cubierta es mayor a la superficie total","47e52849":"### Establecemos un nuevo benchmark","9e3b8e38":"## Multicolinealidad \n#### Factor Inflaci\u00f3n de la Varianza\n* VIF = 1 : Las variables no est\u00e1n correlacionadas\n* VIF < 5 : Las variables tienen una correlaci\u00f3n moderada y se pueden quedar en el modelo\n* VIF >5 : Las variables est\u00e1n altamente correlacionadas y deben desaparecer del modelo.","01549f3b":"##### La Optimizacion de modelos fue establecida en Max_Depth=19 para Arbol y K-vecinos=2 para KNN","817e3fa3":"#### El Factor de Inflaci\u00f3n de Varianza (VIF, del ingl\u00e9s \u201cVariance Inflation Factor\u201d) de una variable independiente es en un valor que indica el grado de indecencia de esa variable. Para obtener el VIF en primer lugar ha de calcular la regresi\u00f3n lineal de una variable independiente frente a resto de variables independientes. Posteriormente se usa el R^2 de esta regresi\u00f3n para obtener el VIF de esta variable","045bb554":"#### Mejora de los modelos KNN y Arbol de Decision","dff71281":"#### Surface_Covered","5765ff67":"<font color=pink>**Ra\u00edz del Error Cuadr\u00e1tico Medio**\n\nLa Ra\u00edz del Error Cuadr\u00e1tico Medio (Root Mean Squared Error o RMSE) se diferencia del MSE en que el resultado se puede medir en las mismas unidades que la variable objetivo\n\n$$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i -\\hat{y}_i)^2}$$\n\n\nSin embargo, tiene un problema y es que da m\u00e1s importancia a los errores grandes.\nSe prefiere m\u00e1s en algunos casos porque los errores se cuadran primero al cuadrado antes de promediar, lo que supone una gran penalizaci\u00f3n en los errores grandes. Esto implica que RMSE es \u00fatil cuando no se desean errores grandes.","2f2818a0":"##### --> Vemos que tenemos un maximo de 14 bathrooms","f4e3a5e9":"#### <font color=green>\u2666F. Una vez filtrado el dataset, puedes utilizar la funci\u00f3n pairplot de Seaborn.","2249938a":"#### <font color=green>\u2666 Entre los modelos entrenados, \u00bfcu\u00e1l elegir\u00edas para utilizar?\u00bfPor qu\u00e9?<\/font>","531a03af":"### <font color=green>\u2666 Entrenar un modelo de vecinos m\u00e1s cercanos y un modelo de \u00e1rbol de decisi\u00f3n con hiperpar\u00e1metros iniciales de su elecci\u00f3n.<\/font>","7e979078":"#### Conclusion: El mejor modelo para analisis de PHs es el KNN optimizado dirigido a PHs, obteniendo mejores metricas que el Arbol de Decision sin optimizar dirigido a PH (Aunque la diferencia es minima).","5949812e":"##### Conclusion: La optimizacion de modelos fue establecida en Max_Depth=20 para el Arbol y K-Vecinos=3 para KNN","9c3013b2":"# <font color=green>Notas Finales:\n\n##### <font color=green>A lo largo del analisis del presente Dataset ha quedado comprobado que el Modelo de Arbol de Decision Optimizado se corona como el Mejor modelo para hacer un analisis grupal, por su simpleza se convierte en el modelo predilecto.\n\n##### <font color=green>Pero si quisieramos lograr un mayor grado de resultados, debemos optar por trabajar con Modelos individualizados para cada tipo de Propiedad, al menos esos fueron los resultados obtenidos en los analisis individuales de Departamentos y PHs, por otro lado, el caso de las casas dio resultados muy inferiores a los esperados. Posiblemente un mejor manejo de Features hubiese logrado mejores resultados, ya que hubo Features descartadas por no saber manejar o interpetrar su contenido, pero que seguramente a lo largo de la carrera se lograra.\n","51e04251":"##### <font color=green>\u2666 D. Las propiedades no pueden tener surface_covered mayor a surface_total. Si eso sucede, debes filtrar esas instancias.","6971d625":"   #####          --> La utilizacion del cuantil 0.01 es con motivo de evitar tener valores negativos en la superficie minima","44b602ec":"#### Conclusion: A pesar de que aun nos encontramos con features con VIFS altos, despues de analizar y testear eliminando uno por uno resulto que el modelo no mejoro,en todo caso empeoro,llegando al caso de dar un R2 de -0.86!!. Por lo antes expresado, se decide trabajar con las siguientes features.","d414333e":"---\n\n<br \/>\n<br \/>\n\n# RESPONDER SECCI\u00d3N 1 ANTES DE CONTINUAR\n\n<br \/>\n<br \/>\n\n---","071253c0":"3. <font color=green>**Tipos de propiedad**: \u00bfCu\u00e1ntos tipos de propiedad hay publicados seg\u00fan este dataset?\u00bfCu\u00e1ntos instancias por cada tipo de propiedad hay en el dataset? Responde esta pregunta usando las funcionalidad de Pandas y con un gr\u00e1fico apropiado de Seaborn. **Pistas**: Te puede ser \u00fatil googlear c\u00f3mo rotar las etiquetas del eje x.","f0750209":"#### Rooms","08d893dd":"##### <font color=green>\u2666 Selecciona aquellas propiedades cuya superficie total es menor a 1000 m2 y mayor a 15 m2.","67ce003b":"#### <font color=green>Nota del alumno: A lo largo del dataset se utilizaron tecnicas que ocasionan una demora en la ejecucion del mismo, estas seran al momento de utilizar RFE y al momento de hacer una optimizacion de KNN dirigido a Departamentos, el tiempo de demora fue calculado en 7 min (solamente para RFE y Opt. de KNN en dpto), por ello estuve en el dilema de si reducir el contenido del dataset o no. Finalmente preferi dejarlo porque creo que son factores que suman al proyecto. Por todo esto le pido paciencia a la hora de ejecutar el Notebook.\n\n##### Tiempo de ejecucion total de principio a fin: 15 min aprox","17ceeb25":"#### --> Debido a la cantidad de Features se debe bajar el numero de \"K-vecinos\" para reducir el gasto de memoria y no demorar tanto en funcionar,aun asi la demora existe.\n##### Por ello se probo con una gran variedad de K-vecinos y se termino dejando el numero que optimiza el modelo KNN, en este caso es 3.","8475b1e9":"#### Los valores superiores a 5 son poco representativos","5f8b4509":"# <font color=green>Agregados luego de la primera correccion de proyecto","f172b544":"### <font color=red>Analisis de Casas","d9870b4a":"### Conclusion:\n#### Arbol de decision: El numero optimo en cuanto a su profundidad se situa en 20, la exactitud esta en su punto mas alto y el R2 de test obtiene una peque\u00f1a mejora\n#### KNN: El numero optimo de vecinos mas cercanos se ubica en 4, alcanzando su maxima exactitud, pero en este caso el r2 de test se encuentra muy alejado del r2 de train","d8f275e4":"### Mejora en KNN y Arbol de Decision","2fb427a8":"## Respuesta\n\n* \u2666 Tipo de propiedad\n* \u2666cantidad de habitaciones\n* \u2666 cantidad de ba\u00f1os\n* \u2666 cantidad de ambientes o zonas\n* \u2666 tiene pileta o no\n* \u2666 tiene terraza o no\n* \u2666 tiene quincho o no\n* \u2666 antiguedad de la propiedad\n* \u2666 distancia a lugares de ocio\n* \u2666 distancia a centros de salud\n* \u2666 distancia escuelas o centros educativos\n* \u2666 costos fijos de la propiedad\n* \u2666 ubicacion geografica\n* \u2666 seguridad de la ubicacion geografica\n* \u2666 numero de pisos\n* \u2666 superficie de la propiedad\n* \u2666 tiene cocheras o no\n* \u2666 Remodelado o no\n* \u2666 amenities de la propiedad segun el caso\n","7a4b7b1e":"#### Conclusion: Los valores de roms superiores a 7 son poco representativos","73b96a02":"#### <font color=green>\u2666 Mejorar el desempe\u00f1o de sus modelos optimizando el n\u00famero de vecinos y la profundidad del \u00e1rbol, respectivamente.<\/font>\n","4acad3d9":"##### El objetivo de SVR es encajar tantos casos como sea posible entre las l\u00edneas mientras se limitan las infracciones de margen. Es decir Intenta encontrar una l\u00ednea que separe clases.","efa26da1":"#### --> Para el presente problema decidi utilizar el IQR por razones de mejorar el entendimiento del codigo (Antes de utilizar este metodo se probo \"Z_score\", pero fue descartado por el motivo se\u00f1alado)","fc34e81e":"0. Importa las librer\u00edas necesarias para trabajar en la consigna.","2a63bf26":"### Conclusion:\n#### Arbol de decision: El numero optimo en cuanto a su profundidad se situa en 19, la exactitud esta en su punto mas alto y el R2 de test obtiene una peque\u00f1a mejora\n#### KNN: El numero optimo de vecinos mas cercanos se ubica en 4, alcanzando su maxima exactitud, aunque es de destacar que tenemos una baja en r2 de train y al mismo tiempo un aumento milimetrico de r2 en test","cadfb285":"#### -> Metricas para arbol y knn","a3ba13d2":"#### --> Carga del dataset","be67ac59":"7. <font color=green>**Correlaciones:** Estudia la correlaci\u00f3n entre las variables `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered`, `price`. \u00bfCu\u00e1les son las mejores variables para predecir el precio?\u00bfQu\u00e9 diferencias encuentras seg\u00fan cada tipo de propiedad?","a79aea5e":"####  -->A continuacion se presenta una grafica con los tipos de propiedades y sus cantidades","44891b44":"### -->En el siguiente apartado se visualizan las primeras 5 instancias (head), asi como las 5 ultimas (tail)","1e810b33":"Los resultados son los siguientes:\n\n<font color=green>Modelo de Arbol de decision con Optimizacion:\n\n    *R2 en Train: 0.952\n    *R2 ajustado en train: 0.952\n\n    *R2 en test: 0.766\n    *R2 ajustado en Test: 0.766\n\n    *RMSE en train: 64721.069\n    *RMSE en test: 146092.758\n        \n<font color=green>Modelo de KNN dirigido a PHs con Optimizacion:\n    \n    *R2 en Train: 0.936\n    *R2 ajustado en train: 0.935\n\n    *R2 en test: 0.801\n    *R2 ajustado en Test: 0.797\n\n    *RMSE en train: 29478.645\n    *RMSE en test: 49213.621","fc4fdc76":"### 2. An\u00e1lisis Exploratorio de Datos\n\nEn esta secci\u00f3n, debes realizar un An\u00e1lisis Exploratorio de Datos sobre el dataset de propiedades de Properati. Es importante que respondas las siguientes preguntas durante el an\u00e1lisis:\n\n* \u00bfQu\u00e9 tama\u00f1o tiene el dataset?\u00bfCu\u00e1ntas instancias y cu\u00e1ntas columnas?\n* \u00bfCu\u00e1ntos valores faltantes hay en cada columna?\n* \u00bfC\u00f3mo es la distribuci\u00f3n de cada variable? Deber\u00e1s hacer histogramas para las variables num\u00e9ricas y gr\u00e1ficos de barras para las variables categ\u00f3ricas.\n* \u00bfC\u00f3mo se relacionan las variables entre s\u00ed?\u00bfQu\u00e9 tipo de gr\u00e1fico ser\u00e1 conveniente para presentar esta informaci\u00f3n?\n* \u00bfC\u00f3mo est\u00e1n correlacionadas las variables num\u00e9ricas?\u00bfQu\u00e9 tipo de gr\u00e1fico ser\u00e1 conveniente para presentar esta informaci\u00f3n?\u00bfCu\u00e1les ser\u00e1n los mejores predictores de la variable de inter\u00e9s?\n\nVas a encontrar instrucciones para responder estas preguntas. Es importante aclarar que estas instrucciones corresponden al **m\u00ednimo entregable** que esperamos en la consigna.\n\n**Comentarios sobre el dataset** \n1. Nosotros ya hicimos un *curado* sobre el dataset que puedes descargar directamente de la p\u00e1gina de Properati. Muchos de los pasos que hicimos para curar el conjunto de datos los veremos durante el Bloque 2 de la carrera.\n\n2. Si tienes dudas sobre qu\u00e9 representa alguna de las columnas, puedes consultar [aqu\u00ed](https:\/\/www.properati.com.ar\/data\/). Notar\u00e1s que algunas columnas fueron descartadas.\n\n3. `Capital Federal` refiere a la Ciudad de Buenos Aires. `Bs.As. G.B.A. Zona Norte`, `Bs.As. G.B.A. Zona Sur` y `Bs.As. G.B.A. Zona Oeste` son regiones que conforman el [Gran Buenos Aires](https:\/\/es.wikipedia.org\/wiki\/Gran_Buenos_Aires), un conjunto de ciudades que rodean a la Ciudad de Buenos Aires.\n\n","d0bf79ad":"## Analisis:\n* --> La Cantidad de 14 bathrooms posiblemente sea un outlier\n* --> La cantidad de 21 habitaciones posiblemente sea un outlier\n* --> La superficie cubierta y superficie total de 126062 es seguramente un outlier\n* --> Que el minimo de bedrooms sea igual a 0 indica la posibilidad de que existan Monoambientes o Flats\n* --> La columna precio si es dividida por mil mostrara los valores en miles de dolares, puede ayudar a mejorar la legibilidad","5c864e62":"Los resultados son los siguientes:\n\n<font color=green>Modelo de Arbol de decision con Optimizacion:\n\n    *R2 en Train: 0.952\n    *R2 ajustado en train: 0.952\n\n    *R2 en test: 0.766\n    *R2 ajustado en Test: 0.766\n\n    *RMSE en train: 64721.069\n    *RMSE en test: 146092.758\n        \n<font color=green>Modelo de Arbol de decision sin Optimizacion y con VIF:\n    \n    *R2 en Train: 0.966\n    *R2 ajustado en train: 0.966\n\n    *R2 en test: 0.759\n    *R2 ajustado en Test: 0.759\n\n    *RMSE en train: 54726.970\n    *RMSE en test: 148387.961\n    ","a8fa9bd7":"<font color=pink>**Error Absoluto Medio**\n\nEl Error Absoluto Medio (Mean Absolute Error o MAE) se define como:\n\n$$\\frac{1}{n}\\sum_{i=1}^{n}|y_i -\\hat{y}_i|$$\n\nMAE es la diferencia absoluta entre el valor objetivo y el valor \npredicho por el modelo. Es m\u00e1s robusto a los valores \nat\u00edpicos y no penaliza los errores extremadamente. \nMAE es una puntuaci\u00f3n lineal, lo que significa que todas \nlas diferencias individuales se ponderan por igual.\n","6837dcdb":"#### --> Para el desarrollo de este punto decidi utilizar 2 versiones de mapa de calor en vistas de lograr una mejor visualizacion","4b0c6802":"<font color=green>**Checkpoint:** deber\u00edas tener un dataset con 91485 instacias, 19 columnas.\n\n6. **Distribuciones y relaciones de a pares:** Estudia la distribuci\u00f3n y las relaciones de a pares de las variables `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered`, `price` para cada tipo de propiedad. Para ello, ten en cuenta:\n    1. Obtiene estad\u00edsticos que te sirvan para tener una primera idea de los valores que abarcan estas variables. \u00bfCu\u00e1les crees que toman valores que tal vez no tengan mucho sentido?\n    1. Algunas instancias tienen valores de superficie (`surface_total`) muy grandes y dificultan la correcta visualizaci\u00f3n. Estudia la distribuci\u00f3n de esa variable y filtra por un valor razonable que te permita obtener gr\u00e1ficos comprensibles. Puede ser \u00fatil un boxplot para determinar un rango razonable.\n    1. Lo mismo ocurre con valores de superficie total muy chico.\n    1. Las propiedades no pueden tener `surface_covered` mayor a `surface_total`. Si eso sucede, debes filtrar esas instancias.\n    1. El rango de precios que toman las propiedades es muy amplio. Estudia la distribuci\u00f3n de esa variable y filtra por un valor razonable que te permita obtener gr\u00e1ficos comprensibles. Puede ser \u00fatil un boxplot para determinar un rango razonable.\n    1. Una vez filtrado el dataset, puedes utilizar la funci\u00f3n `pairplot` de Seaborn.","1dae4738":"##### --> Calculador de Numero de Vecinos","b03a5cb1":"#### Gracias a .describe y el Pairplot podemos ver algunas de las relaciones existentes que llaman la atencion dentro del data set,como las siguientes:","64cf6aaf":"#### --> Se realiza un filtrado sobre los datos donde la superficie cubierta sea mayor a la superficie total","fbc2e851":"#### Conclusion: Los valores de bathrooms superiores a 6 son poco representativos","a5b82c07":"#### Conclusion: El modelo de KNN optimizado dirigido a Casas se muestra como el mejor modelo para la prediccion de precios de Casas, aunque sus metricas dejan mucho que desear, a la hora de compararlo con el Arbol de Decision Optimizado vemos que el KNN esta muy por debajo de las metricas del arbol.","21a4764a":"4. <font color=green>\u00bfDe qu\u00e9 regiones son las publicaciones? Haz gr\u00e1ficos de barras para las variables `l2` y `l3`. Si te animas, puedes hacer los dos gr\u00e1ficos usando `subplot` de Matplotlib. Dale un tama\u00f1o apropiado a la figura para que ambos gr\u00e1ficos se visualicen correctamente.","411f5c6a":"#### --> Boxplot de precio-tipo propiedad","c3f0efd7":"### 2.1 Desaf\u00edo\n\n<font color=green>En el dataset provisto hay mucha informaci\u00f3n, m\u00e1s all\u00e1 del problema planteado. Propone una pregunta que pueda ser respondida por el dataset e intenta responderla.\u00bfCu\u00e1les son los sesgos de la respuesta obtenida?(\u00bfCu\u00e1n generalizable es la respuesta obtenida?)\u00bfNecesitas informaci\u00f3n complementaria?\u00bfC\u00f3mo la obtendr\u00edas?\n\n<font color=green>Por ejemplo: \u00bfCu\u00e1l es el barrio m\u00e1s caro de Buenos Aires? Probablemente puedas responder esta pregunta con este dataset. Pero podria ocurrir que la respuesta est\u00e9 sesgada. \u00bfC\u00f3mo? Tal vez las propiedades m\u00e1s caras no se publican de forma online, sino que utilizan otro canal de venta.\n","b3212898":"Tanto para el analisis con un modelo sin optimizar como para un modelo ya con optimizaciones el Arbol de Decision obtiene los mejores resultados. Pero a pesar de la optimizacion los resultados no son tan buenos como los esperados(Apreciacion personal). <font color=green>Solo se ven peque\u00f1as mejoras en el apartado de R2 Test.\n\nLos resultados son los siguientes:\n\n<font color=green>Modelo Arbol de decision sin Optimizacion:\n\n    *R2 en Train: 0.968\n    *R2 ajustado en train: 0.968\n\n    *R2 en test: 0.747\n    *R2 ajustado en Test: 0.747\n\n    *RMSE en train: 52460.908\n    *RMSE en test: 152027.476\n\n<font color=green>Modelo de Arbol de decision con Optimizacion:\n\n    *R2 en Train: 0.952\n    *R2 ajustado en train: 0.952\n\n    *R2 en test: 0.766\n    *R2 ajustado en Test: 0.766\n\n    *RMSE en train: 64721.069\n    *RMSE en test: 146092.758\n","8b318cd9":"##### --> demora de 3 min aprox.","1e017a11":"#### <font color=green>A.Obtiene estad\u00edsticos que te sirvan para tener una primera idea de los valores que abarcan estas variables. \u00bfCu\u00e1les crees que toman valores que tal vez no tengan mucho sentido?","d465b72a":"#### --> Para el desafio utilizare informacion que no fue abordada en ningun momento en el Proyecto, me refiero a la latitud y longitud. Con estos datos se creara un mapa de Capital Federal con los 3 principales tipos de propiedad","d82ecd72":"#### --> Standarscaler ayuda a normalizar los datos y a que trabajen en un rango determinado","51131047":"##### <font color=green>\u2666 Selecciona aquellas propiedades en Capital Federal y cuyo tipo de propiedad es Departamento, PH o Casa.","87327d06":"#### <font color=green>\u2666 Ser cr\u00edtico\/a con la metodolog\u00eda utilizada. Por ejemplo, responde las siguientes preguntas: \u00bfQu\u00e9 informaci\u00f3n no est\u00e1s usando que podr\u00eda ayudar al modelo?\u00bfQu\u00e9 informaci\u00f3n puede estar dem\u00e1s o repetida?","69e67729":"2. <font color=green>**Valores Faltantes**: imprime en pantalla los nombres de las columnas y cu\u00e1ntos valores faltantes hay por columna.","ae517846":"#### La eleccion de floor se basa en que si el numero de bathrooms fuese establecido en 4(usando ceil en Departamento y PH), se estaria trabajando con numeros poco representativos.","b997e52f":"##### El m\u00e9todo RFE de sklearn se puede utilizar en cualquier estimador con un m\u00e9todo \".fit\" que una vez instalado producir\u00e1 un coef_ o feature_importances_  del atributo. El mismo funciona eliminando la caracter\u00edstica con la menor importancia de los datos y, a continuaci\u00f3n, vuelve a evaluar la importancia de la caracter\u00edstica, repitiendo el proceso hasta que se le dice que se detenga.","dd521164":"### <font color=green>\u2666 Seleccionar las variables predictoras (X) y la variable a predecir (y).<\/font> ","26ed47ac":"### 3. <font color=green>Machine Learning\n\n<font color=green>En esta secci\u00f3n, debes entrenar dos modelos de Machine Learning - uno de vecinos m\u00e1s cercanos y otro de \u00e1rboles de decisi\u00f3n -  para predecir el precio de las propiedades tipo `Departamento`, `PH` y `Casa`  en la Ciudad Aut\u00f3noma de Buenos Aires (`Capital Federal`). Para ello, no debes olvidarte de:\n\n* Elegir una m\u00e9trica apropiada para evaluar los resultados de los modelos.\n* Seleccionar las variables predictoras (`X`) y la variable a predecir (`y`). \n* Realizar un Train\/Test split de los datos.\n* Generar un modelo *benchmark* y evaluarlo.\n* Entrenar un modelo de vecinos m\u00e1s cercanos y un modelo de \u00e1rbol de decisi\u00f3n con hiperpar\u00e1metros iniciales de su elecci\u00f3n.\n* Evaluar los modelos obtenidos. Para ello, eval\u00faa la m\u00e9trica elegida en el conjunto de Test y en el conjunto de Train. Tambi\u00e9n, realiza gr\u00e1ficos de valores reales vs. valores predichos.\n* Mejorar el desempe\u00f1o de sus modelos optimizando el n\u00famero de vecinos y la profundidad del \u00e1rbol, respectivamente.\n* Entre los modelos entrenados, \u00bfcu\u00e1l elegir\u00edas para utilizar?\u00bfPor qu\u00e9? \n* Ser **cr\u00edtico\/a** con la metodolog\u00eda utilizada. Por ejemplo, responde las siguientes preguntas: \u00bfQu\u00e9 informaci\u00f3n no est\u00e1s usando que podr\u00eda ayudar al modelo?\u00bfQu\u00e9 informaci\u00f3n puede estar dem\u00e1s o repetida?\n\n<font color=green>Estos lineamientos corresponden al **m\u00ednimo entregable** de esta secci\u00f3n.\n\n\n<font color=green>**Importante:** para asegurarnos que trabajes con un dataset apropiados, debes volver a cargar los datos y realizar el siguiente filtrado:\n\n1. Selecciona aquellas propiedades en Capital Federal y cuyo tipo de propiedad es Departamento, PH o Casa.\n1. Selecciona aquellas propiedades cuya superficie total es menor a 1000 m2 y mayor a 15 m2.\n1. Selecciona aquellas propiedades cuya precio es menor 4000000 d\u00f3lares.\n1. Selecciona las columnas `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered` y `price`.\n1. Descarta aquellas instacias con valores faltantes.\n\n<font color=green>**Checkpoint:** deber\u00edas obtener un dataset con 81019 instacias y 6 columnas.","11dcca79":"### <font color=red>Analisis de PHs","e93f6813":"#### Ahora aplicamos la misma tecnica a las habitaciones"}}