{"cell_type":{"c9f3c838":"code","f126f23b":"code","a6d42fd7":"code","5f7ef667":"code","620b6c4f":"code","3b7d742a":"code","df590b03":"code","b91b40f4":"code","4934b46e":"code","615d741a":"code","b3cd5c0f":"code","a7728b9e":"code","bdcacaa5":"code","c1479b95":"code","fe298260":"markdown","3ebe6825":"markdown","2dbc7ceb":"markdown","227b78ec":"markdown"},"source":{"c9f3c838":"# import the necessary packages\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LassoCV\nfrom scipy.stats import boxcox\nimport matplotlib.pyplot as plt","f126f23b":"# load data\ndata = \"..\/input\/insurance\/insurance.csv\"\ndf = pd.read_csv(data)\n\n# show data (6 row)\ndf.head(6)","a6d42fd7":"df_encode = pd.get_dummies(data = df, columns = ['sex','smoker','region'])\ndf_encode.head()","5f7ef667":"# normalization\ny_bc,lam, ci= boxcox(df_encode['charges'],alpha=0.05)\ndf_encode['charges'] = np.log(df_encode['charges'])\n\ndf_encode.head()","620b6c4f":"X = df_encode.drop(\"charges\",axis=1)\ny = df_encode[\"charges\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nlasso_model = Lasso().fit(X_train,y_train)\nlasso_model","3b7d742a":"print(\"intercept: \", lasso_model.intercept_)\nprint(\"coef: \", lasso_model.coef_)","df590b03":"# coefficients for different lambda values\n\nalphas = 10**np.linspace(10, -2, 100) * 0.5\nlasso = Lasso()\ncoefs = []\n\nfor a in alphas:\n    lasso.set_params(alpha=a)\n    lasso.fit(X_train,y_train)\n    coefs.append(lasso.coef_)","b91b40f4":"ax = plt.gca()\nax.plot(alphas*2, coefs)\nax.set_xscale(\"log\")\nplt.axis(\"tight\")\nplt.xlabel(\"alpha\")\nplt.show()","4934b46e":"lasso.predict(X_test)[0:10]","615d741a":"y_pred = lasso.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","b3cd5c0f":"lasso_cv_model = LassoCV(alphas=None, cv=10, max_iter=100000, normalize=True)\nlasso_cv_model","a7728b9e":"lasso_cv_model.fit(X_train, y_train)","bdcacaa5":"lasso_cv_model.alpha_","c1479b95":"lasso_tuned = Lasso().set_params(alpha= lasso_cv_model.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","fe298260":"## Prediction","3ebe6825":"# Lasso Regression\n\nThe aim is to find the coefficients that minimize the sum of error squares by applying a penalty to these coefficients.\n\n- Lasso regression = L1\n- Ridge regression = L2\n\n- It has been proposed to eliminate the disadvantage of leaving the related-unrelated variables in the model of the Ridge regression.\n- Coefficients near zero in Lasso.\n- But when the L1 norm is big enough in lambda, some coefficients make it zero. Thus, it makes the selection of the variable.\n- It is very important to choose Lambda correctly, CV is used here too.\n- Ridge and Lasso methods are not superior to each other.\n\n<img src=\"https:\/\/i.ibb.co\/Nswq4kn\/Whats-App-Image-2020-08-17-at-23-08-10.jpg\" \/>","2dbc7ceb":"## Model Tuning","227b78ec":"## Model"}}