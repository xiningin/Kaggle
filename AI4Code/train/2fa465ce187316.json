{"cell_type":{"f41f96c1":"code","e5036254":"code","8aab2a40":"code","e59b32e9":"code","23efa225":"code","36394a1e":"code","bd8f7b02":"code","c3b21620":"code","7b6ded57":"code","c7c943fc":"code","90e88c18":"code","cf1f0f30":"markdown","04891ccc":"markdown","3ff9a55a":"markdown","e4592172":"markdown","368bffd4":"markdown","8682cb8a":"markdown"},"source":{"f41f96c1":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Layer, BatchNormalization, GlobalAveragePooling2D \nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nimport os\n\nfrom sklearn.model_selection import train_test_split","e5036254":"\nBASE_DIR = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'\nclasses = [i for i in os.listdir(BASE_DIR) if '.' not in i]\nclasses","8aab2a40":"image_paths = []\nimage_paths_gt = []\nimage_classes = np.array([[cls]*1000 for cls in classes]).reshape(-1)\nfor cls in classes:\n    gt = cls + ' GT'\n    image_paths.extend([os.path.join(BASE_DIR, cls,cls, i) for i in os.listdir(os.path.join(BASE_DIR, cls,cls))])\n    image_paths_gt.extend([os.path.join(BASE_DIR, cls,gt, i) for i in os.listdir(os.path.join(BASE_DIR, cls, gt))])\n    \n","e59b32e9":"img_shape = (590 , 445, 3)","23efa225":"data = pd.DataFrame({'path':image_paths, 'class':image_classes, })\ndata.head()","36394a1e":"data_gt = pd.DataFrame({'path':image_paths_gt, 'class':image_classes, })\ndata_gt.head()","bd8f7b02":"def get_generators(data, is_rgb =True):\n    color_mode = 'rgb' if is_rgb else 'grayscale'\n    data_full, data_remainder = train_test_split(data, stratify = data['class'], test_size = 0.2)\n    train_datagen = ImageDataGenerator(rescale=1.0\/255, validation_split=0.1)\n\n    test_datagen = ImageDataGenerator(rescale = 1.0\/255)\n    train_generator = train_datagen.flow_from_dataframe(data_full, x_col='path', y_col='class',\n         target_size=img_shape[:-1], color_mode=color_mode,\n        class_mode='categorical', batch_size=32, shuffle=True,\n        subset='training'\n        )\n    val_generator = train_datagen.flow_from_dataframe(data_full, x_col='path', y_col='class',\n         target_size=img_shape[:-1], color_mode=color_mode,\n        class_mode='categorical', batch_size=32, shuffle=True,\n        subset='validation'\n        )\n    test_generator = test_datagen.flow_from_dataframe(data_remainder, x_col = 'path', y_col = 'class', target_size = img_shape[:-1], color_mode = color_mode,class_mode = 'categorical')\n    return train_generator, val_generator, test_generator","c3b21620":"train_gen, val_gen, test_gen = get_generators(data)","7b6ded57":"model = Sequential([\n    Conv2D(16,(3,3), strides = 3, input_shape = img_shape),\n    MaxPooling2D(),\n    Conv2D(32, (3,3),strides=2),\n    \n    MaxPooling2D(),\n    Conv2D(64, (3,3)),\n    MaxPooling2D(),\n    Conv2D(64,(3,3)),\n    MaxPooling2D(),\n    Flatten(),\n    Dropout(0.5),\n    Dense(256, activation = 'relu'),\n    Dropout(0.5),\n    Dense(9, activation = 'softmax')\n])\nmodel.summary()","c7c943fc":"earlystop = EarlyStopping(patience = 10,restore_best_weights=True )\nschedule = ExponentialDecay(initial_learning_rate = 0.002, decay_steps = 1000, decay_rate = 0.7)\nmodel.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate =schedule), metrics = ['accuracy'])\nhistory = model.fit(train_gen, validation_data = val_gen,epochs = 100, callbacks = [earlystop])","90e88c18":"model.evaluate(test_gen)","cf1f0f30":"# Modelling","04891ccc":"# Result","3ff9a55a":"We get 99.2% accuracy. ","e4592172":"Even though I didn't use the ground-truth images, I kept them too. Maybe someone will work with them","368bffd4":"# Imports","8682cb8a":"# Preproccessing Data"}}