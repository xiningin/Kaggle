{"cell_type":{"d6530065":"code","860cd8e0":"code","267a0ded":"code","fe848eaf":"code","b86af67b":"code","5cc9d2ad":"code","ca9d698e":"code","b1806b40":"code","5af21923":"code","85bcf9a5":"code","02f4b7e4":"code","01c6d256":"code","95e59a17":"code","173da811":"code","cfda7a78":"markdown","f012de22":"markdown","323549d7":"markdown","451ad2be":"markdown","cedbbe44":"markdown","e7416fd5":"markdown","f69c014f":"markdown","3e5e327c":"markdown","751cadae":"markdown","43593b92":"markdown","b666243d":"markdown"},"source":{"d6530065":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import misc","860cd8e0":"# Image data\nimg = misc.ascent()","267a0ded":"def plot_img(img, plt_axis='on'):\n    plt.figure(figsize=(12, 12))\n    plt.grid(False)\n    plt.gray()\n    plt.axis(plt_axis)\n    plt.imshow(img)\n    plt.show()\n    \n    \nplot_img(img, plt_axis='off')","fe848eaf":"img_transformed = np.copy(img)\nsize_x = img_transformed.shape[0]\nsize_y = img_transformed.shape[1]\n\nprint(size_x, size_y)","b86af67b":"# This filter detects edges nicely, it creates a convolution that only passes \n# through sharp edges and straight lines.\nfilter_1 = [[0, 1, 0], [1, -4, 1], [0, 1, 0]]\n\n# Experiment with different values for fun effects.\nfilter_2 = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\nfilter_3 = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]","5cc9d2ad":"weight = 1","ca9d698e":"def apply_filter(img, filter, img_transformed, size_x, size_y):\n    for x in range(1, size_x - 1):\n        for y in range(1, size_y - 1):\n            convolution = 0.0\n            convolution = convolution + (img[x - 1, y - 1] * filter[0][0])\n            convolution = convolution + (img[x, y - 1] * filter[0][1])\n            convolution = convolution + (img[x + 1, y - 1] * filter[0][2])\n            convolution = convolution + (img[x - 1, y] * filter[1][0])\n            convolution = convolution + (img[x, y] * filter[1][1])\n            convolution = convolution + (img[x + 1, y] * filter[1][2])\n            convolution = convolution + (img[x - 1, y + 1] * filter[2][0])\n            convolution = convolution + (img[x, y + 1] * filter[2][1])\n            convolution = convolution + (img[x + 1, y + 1] * filter[2][2])\n            convolution = convolution * weight\n            if (convolution < 0):\n                convolution = 0\n            if (convolution > 255):\n                convolution = 255\n            img_transformed[x, y] = convolution\n            \n    return img_transformed","b1806b40":"img_transformed_1 = apply_filter(img, filter_1, np.copy(img_transformed), size_x, size_y)\nimg_transformed_1","5af21923":"# Plot the image. Note the size of the axes -- they are 512 by 512\nplot_img(img_transformed_1)","85bcf9a5":"img_transformed_2 = apply_filter(img, filter_2, np.copy(img_transformed), size_x, size_y)\nplot_img(img_transformed_2)","02f4b7e4":"img_transformed_3 = apply_filter(img, filter_3, np.copy(img_transformed), size_x, size_y)\nplot_img(img_transformed_3)","01c6d256":"def apply_max_pooling(img_transformed, size_x, size_y):\n    # Using transformed img as pooling is applied after conv layer\n    \n    new_x = int(size_x \/ 2)\n    new_y = int(size_y \/ 2)\n    newImage = np.zeros((new_x, new_y))\n    for x in range(0, size_x, 2):\n        for y in range(0, size_y, 2):\n            pixels = []\n            pixels.append(img_transformed[x, y])\n            pixels.append(img_transformed[x + 1, y])\n            pixels.append(img_transformed[x, y + 1])\n            pixels.append(img_transformed[x + 1, y + 1])\n            newImage[int(x \/ 2), int(y \/ 2)] = max(pixels)\n            \n    return newImage","95e59a17":"new_img = apply_max_pooling(np.copy(img_transformed_1), size_x, size_y)\nnew_img","173da811":"plot_img(new_img)","cfda7a78":"This code will show a (2, 2) `pooling` - `max pooling`. The idea here is to iterate over the image, and look at the pixel and it's immediate neighbours to the right, beneath, and right-beneath. Take the `largest of them` and load it into the new image. Thus the new image will be 1\/4 the size of the old -- with the dimensions on X and Y being halved by this process. You'll see that the `features get maintained despite this compression`!","f012de22":"**Vertical lines filter**","323549d7":"Loading the image by taking the `ascent` image from `scipy`. It's a nice, built-in picture with lots of angles and lines.","451ad2be":"# How does convolutions work?\n\nLet's explore how `convolutions` work by creating a basic convolution on a 2D Grey Scale image.","cedbbe44":"Now let's create a `convolution`. We will iterate over the image, `leaving a 1 pixel margin`, and multiply out each of the neighbors of the current pixel by the value defined in the filter.  i.e. the current pixel's neighbor above it and to the left will be multiplied by the top left item in the filter etc. We'll then multiply the result by the weight, and then ensure the result is in the range 0-255. Finally we'll load the new value into the `transformed image`. ","e7416fd5":"**Horizontal lines filter**","f69c014f":"The image is stored as a `numpy array`, so we can create the `transformed image` by just copying that array. Let's also get the dimensions of the image so we can loop over it later.","3e5e327c":"Now we can plot the image to see the `effect` of the convolution!","751cadae":"Now we can create a `filter` as a 3x3 array.","43593b92":"---","b666243d":"If all the digits in the filter don't add up to `0 or 1`, you should probably do a `weight` to get it to do so, for example, if your weights are 1, 1, 1, 1, 2, 1, 1, 1, 1. They add up to 10, so you would set a weight of .1 if you want to `normalize` them."}}