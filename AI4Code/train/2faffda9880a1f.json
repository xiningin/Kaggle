{"cell_type":{"240cb6bf":"code","0e53b568":"code","7f0318c4":"code","01b59d55":"code","bbe188da":"code","0781a529":"code","718c1ab2":"code","bc87a58b":"code","9bb5a4a3":"code","b908e36f":"code","fa33b7b4":"code","0249f588":"code","96201bbc":"code","17264841":"code","110895ca":"code","ffb3e610":"code","b3ab6c1d":"code","ef6a31e8":"code","6c04d8c4":"code","fb46a6e1":"code","57cec75a":"code","d67b7ede":"code","e05786da":"code","78642844":"code","ddb1171f":"code","1778dbe8":"code","4d442e10":"code","c8c3c934":"code","4ac3ec55":"code","5ab538df":"code","2569934f":"markdown","5fb10209":"markdown","987dbfd2":"markdown","9a3ddeeb":"markdown","17d1aba9":"markdown","1f1eca78":"markdown","c8136327":"markdown","fbd27ed2":"markdown","7b5b96c9":"markdown","6974d387":"markdown","1ea81435":"markdown","b1e109bd":"markdown","8f5dd788":"markdown","88a468ff":"markdown","d5272b31":"markdown","4869b382":"markdown"},"source":{"240cb6bf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport random\n\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom keras.utils.vis_utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom keras.utils.vis_utils import plot_model\nimport keras.backend as K\nfrom tensorflow.keras.layers import Dense, ZeroPadding2D, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, GlobalMaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Dropout, Add, Concatenate\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.optimizers import Adam, RMSprop","0e53b568":"TRAIN_DIR = \"\/kaggle\/input\/nnfl-lab-1\/training\/training\/\"\nTEST_DIR = \"\/kaggle\/input\/nnfl-lab-1\/testing\/testing\/\"","7f0318c4":"IMAGE_WIDTH=400\nIMAGE_HEIGHT=400\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\n\nbatch_size=32","01b59d55":"filenames = os.listdir(TRAIN_DIR)\ncategories = []\nfor filename in filenames:\n    category = filename.split('_')[0]\n    if category == 'chair':\n        categories.append(0)\n    elif category == 'kitchen':\n        categories.append(1)\n    elif category == 'knife':\n        categories.append(2)\n    elif category == 'saucepan':\n        categories.append(3)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\n\ndf.head()","bbe188da":"df['category'].value_counts().plot.bar()","0781a529":"sample = random.choice(filenames)\nimage = load_img(TRAIN_DIR+sample)\nplt.imshow(image)","718c1ab2":"df[\"category\"] = df[\"category\"].replace({0: 'chair', 1: 'kitchen', 2: 'knife', 3: 'saucepan'}) ","bc87a58b":"train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","9bb5a4a3":"train_df['category'].value_counts().plot.bar()","b908e36f":"validate_df['category'].value_counts().plot.bar()","fa33b7b4":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\n\nprint(\"Total iamges in train set - {}\".format(total_train))\nprint(\"Total iamges in validation set - {}\".format(total_validate))","0249f588":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    TRAIN_DIR, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    TRAIN_DIR, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","96201bbc":"input = Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n\nx1 = Conv2D(32, (3,3), activation='relu', padding='same')(input)\nx1 = BatchNormalization()(x1)\nx1 = MaxPooling2D(pool_size=(2, 2))(x1)\nx1 = Dropout(0.25)(x1)\n\nx1 = Conv2D(64, (3,3), activation='relu', padding='same')(x1)\nx1 = BatchNormalization()(x1)\nx1 = MaxPooling2D(pool_size=(2, 2))(x1)\nx1 = Dropout(0.25)(x1)\n\nx1 = Conv2D(128, (3,3), activation='relu', padding='same')(x1)\nx1 = BatchNormalization()(x1)\nx1 = MaxPooling2D(pool_size=(2, 2))(x1)\nx1 = Dropout(0.25)(x1)\n\nx1 = Conv2D(256, (3,3), activation='relu', padding='same')(x1)\nx1 = BatchNormalization()(x1)\nx1 = MaxPooling2D(pool_size=(2, 2))(x1)\nx1 = Dropout(0.25)(x1)\n\nx1 = Conv2D(512, (3,3), activation='relu', padding='same')(x1)\nx1 = BatchNormalization()(x1)\nx1 = MaxPooling2D(pool_size=(2, 2))(x1)\nx1 = Dropout(0.25)(x1)\n\nx1 = Conv2D(1024, (3,3), activation='relu', padding='same')(x1)\nx1 = BatchNormalization()(x1)\nx1 = MaxPooling2D(pool_size=(2, 2))(x1)\nx1 = Dropout(0.25)(x1)\n################################################################################\n\nx2 = Conv2D(32, (5,5), activation='relu', padding='same')(input)\nx2 = BatchNormalization()(x2)\nx2 = MaxPooling2D(pool_size=(2, 2))(x2)\nx2 = Dropout(0.25)(x2)\n\nx2 = Conv2D(64, (5,5), activation='relu', padding='same')(x2)\nx2 = BatchNormalization()(x2)\nx2 = MaxPooling2D(pool_size=(2, 2))(x2)\nx2 = Dropout(0.25)(x2)\n\nx2 = Conv2D(128, (5,5), activation='relu', padding='same')(x2)\nx2 = BatchNormalization()(x2)\nx2 = MaxPooling2D(pool_size=(2, 2))(x2)\nx2 = Dropout(0.25)(x2)\n\nx2 = Conv2D(256, (5,5), activation='relu', padding='same')(x2)\nx2 = BatchNormalization()(x2)\nx2 = MaxPooling2D(pool_size=(2, 2))(x2)\nx2 = Dropout(0.25)(x2)\n\nx2 = Conv2D(512, (5,5), activation='relu', padding='same')(x2)\nx2 = BatchNormalization()(x2)\nx2 = MaxPooling2D(pool_size=(2, 2))(x2)\nx2 = Dropout(0.25)(x2)\n\nx2 = Conv2D(1024, (5,5), activation='relu', padding='same')(x2)\nx2 = BatchNormalization()(x2)\nx2 = MaxPooling2D(pool_size=(2, 2))(x2)\nx2 = Dropout(0.25)(x2)\n################################################################################\n\nx3 = Conv2D(32, (7,7), activation='relu', padding='same')(input)\nx3 = BatchNormalization()(x3)\nx3 = MaxPooling2D(pool_size=(2, 2))(x3)\nx3 = Dropout(0.25)(x3)\n\nx3 = Conv2D(64, (7,7), activation='relu', padding='same')(x3)\nx3 = BatchNormalization()(x3)\nx3 = MaxPooling2D(pool_size=(2, 2))(x3)\nx3 = Dropout(0.25)(x3)\n\nx3 = Conv2D(128, (7,7), activation='relu', padding='same')(x3)\nx3 = BatchNormalization()(x3)\nx3 = MaxPooling2D(pool_size=(2, 2))(x3)\nx3 = Dropout(0.25)(x3)\n\nx3 = Conv2D(256, (7,7), activation='relu', padding='same')(x3)\nx3 = BatchNormalization()(x3)\nx3 = MaxPooling2D(pool_size=(2, 2))(x3)\nx3 = Dropout(0.25)(x3)\n\nx3 = Conv2D(512, (7,7), activation='relu', padding='same')(x3)\nx3 = BatchNormalization()(x3)\nx3 = MaxPooling2D(pool_size=(2, 2))(x3)\nx3 = Dropout(0.25)(x3)\n\nx3 = Conv2D(1024, (7,7), activation='relu', padding='same')(x3)\nx3 = BatchNormalization()(x3)\nx3 = MaxPooling2D(pool_size=(2, 2))(x3)\nx3 = Dropout(0.25)(x3)\n################################################################################\n\ny = Concatenate()([x1, x2, x3])\n\ny = Conv2D(1024, (3,3), activation='relu')(y)\ny = BatchNormalization()(y)\ny = MaxPooling2D(pool_size=(2, 2))(y)\ny = Dropout(0.25)(y)\n\ny = Flatten()(y)\n\ny = Dense(2048, activation='relu')(y)\n# y = BatchNormalization()(y)\n# y = Dropout(0.25)(y)\n\ny = Dense(96, activation='relu')(y)\n# y = BatchNormalization()(y)\n# y = Dropout(0.25)(y)\n\noutput = Dense(4, activation='softmax')(y)\n\nmodel = keras.Model(inputs=input, outputs=output, name=\"custom_model\")","17264841":"model.summary()","110895ca":"plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","ffb3e610":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearlystop = EarlyStopping(patience=10)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00000000001)\ncallbacks = [earlystop, learning_rate_reduction]\n\nmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.001), metrics=['accuracy'])","b3ab6c1d":"epochs=60\n\n\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","ef6a31e8":"model.save_weights(\"model.h5\")","6c04d8c4":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"Validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","fb46a6e1":"\ntest_filenames = os.listdir(TEST_DIR)\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","57cec75a":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    TEST_DIR, \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","d67b7ede":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","e05786da":"test_df['category'] = np.argmax(predict, axis=-1)\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['category'] = test_df['category'].replace(label_map)","78642844":"test_df.head()","ddb1171f":"test_df['category'] = test_df['category'].replace({ 'chair': 0, 'kitchen': 1, 'knife': 2, 'saucepan': 3})","1778dbe8":"test_df['category'].value_counts().plot.bar()","4d442e10":"sample_test = test_df.head(10)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(TEST_DIR+filename, target_size=IMAGE_SIZE)\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()","c8c3c934":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename']\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)","4ac3ec55":"submission_df.head()","5ab538df":"from IPython.display import HTML \nimport pandas as pd \nimport numpy as np\nimport base64 \n\n\ndef create_download_link(df, title = \"Download CSV file\",filename = \"data.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode()) \n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission_df)","2569934f":"# Save Model Weights","5fb10209":"# Create Testing Generator","987dbfd2":"# See predicted result with images","9a3ddeeb":"# Submission","17d1aba9":"# Prepare Data\n---\nBecause we will use image generator with `class_mode=\"categorical\"`. We need to convert column category into string. Then image generator will convert it to one-hot encoding which is good for our classification.\n\nSo we will convert 0 to chair, 1 to kitchen, 2 to knife and 3 to saucepan.","1f1eca78":"# Training Generator\n---\nImage Data Generator is important since it performs the operations in Data Augmentation.\n\nData augmentation encompasses a wide range of techniques used to generate \u201cnew\u201d training samples from the original ones by applying random jitters and perturbations.\n\n* Translations\n* Rotations\n* Changes in scale\n* Shearing\n* Horizontal (and in some cases, vertical) flips","c8136327":"# See Sample Image","fbd27ed2":"# Prepare Training Data","7b5b96c9":"# Prepare Test Data","6974d387":"# Fit Model","1ea81435":"# Visualize Training","b1e109bd":"# Import Libraries","8f5dd788":"# Predict","88a468ff":"# Define Constants and Folder Paths","d5272b31":"# Callbacks","4869b382":"# Build Model"}}