{"cell_type":{"91408d54":"code","23891441":"code","2d8f9e19":"code","3dde8ed1":"code","0864ee0c":"code","706bada1":"code","ee63f634":"code","c05a24fe":"code","22e54c5b":"code","70f88439":"code","3b4caf65":"code","7515d299":"code","958f2462":"code","c60ae61a":"code","d8245b90":"code","c629a0ba":"code","877df016":"code","0413b799":"markdown","60927dd5":"markdown","bf26f56c":"markdown","733e7ffe":"markdown","8671066c":"markdown","8f45707b":"markdown","d86597b8":"markdown","61708ebb":"markdown"},"source":{"91408d54":"from __future__ import print_function\n## Most Important\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\n\n## less Important\nfrom functools import partial\nimport os\nfrom scipy import stats\nimport missingno as msno\nimport joblib\nimport tarfile\nimport shutil\nimport urllib\n\n## Sklearn\nfrom sklearn import datasets\n## Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n## Metrics\nfrom sklearn.metrics import accuracy_score\n\n## tensorflow & Keras\n\nimport tensorflow as tf    ## i will use tf for every thing and for keras using tf.keras\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D","23891441":"train_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntrain_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/train')\n\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntrain_images_paths.head()","2d8f9e19":"img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 10))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1","3dde8ed1":"print('#of Instances in train_set :', len(train_images_paths))\nprint('#of Instances in train_labels :', len(train_labels))\n\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is :', img.shape)","0864ee0c":"train_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(train_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    train_full_set[idx] = img\n    \nprint('train_full_set.shape :', train_full_set.shape)\nprint('train_full_labels.shape :', train_full_labels.shape)","706bada1":"X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.2, shuffle=True, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)","ee63f634":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu',input_shape=(32, 32, 3)),\n    Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n    Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ),\n    Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Flatten(),\n \n    # Fully Connected Layer\n    tf.keras.layers.Dense(units = 1100, activation = 'relu'),\n    Dropout(0.4),\n\n    \n    tf.keras.layers.Dense(29, activation='sigmoid')\n \n])\nmodel.summary()","c05a24fe":"model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\nearly_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","22e54c5b":"history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=100, batch_size=32, callbacks=[early_stopp])","70f88439":"pd.DataFrame(history.history).plot(figsize=(10, 6));","3b4caf65":"loss_all_data, acc_all_data = model.evaluate(train_full_set, train_full_labels, verbose=0)\nprint('loss_all_data =>', loss_all_data)\nprint('acc_all_data =>', acc_all_data)","7515d299":"test_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\ntest_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()","958f2462":"len(test_images_paths)","c60ae61a":"test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(test_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    test_full_set[idx] = img\n    \nprint('test_full_set.shape =>', test_full_set.shape)","d8245b90":"y_preds_classes = np.argmax(model.predict(test_full_set), axis=-1)\ntest_labels['label'] = y_preds_classes","c629a0ba":"test_labels","877df016":"test_labels[['id', 'label']].to_csv('submission6.csv', index=False)","0413b799":"> # Read the training data","60927dd5":"> # Test Data","bf26f56c":"> # Submission","733e7ffe":"> # Design the model","8671066c":"> # Optimization Algorithm","8f45707b":"> # Evaluate the maodel","d86597b8":"> # Split Data","61708ebb":"> **Import libraries**"}}