{"cell_type":{"de7f9868":"code","60e60239":"code","2701184b":"code","e1ae150f":"code","b2e81b52":"code","251830d4":"code","6c92b1a4":"code","2064b9d0":"code","3645e66c":"code","20743e79":"code","ce1335c1":"code","c41a66ce":"code","5754dc0f":"markdown","5a444ec3":"markdown","063f5477":"markdown","03f03fce":"markdown"},"source":{"de7f9868":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","60e60239":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }<\/style>\"))\n\n# Python \u22653.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn \u22650.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# Common imports\nimport numpy as np\nimport os\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\nplt.rc('font', size=12) \nplt.rc('figure', figsize = (12, 5))\n\n# Settings for the visualizations\nimport seaborn as sns\nprint(sns.__version__)\nassert sns.__version__ >= \"0.10\"\nsns.set_style(\"whitegrid\")\nsns.set_context(\"notebook\", font_scale=1, rc={\"lines.linewidth\": 2,'font.family': [u'times']})\n\nimport pandas as pd\npd.set_option('display.max_rows', 25)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 50)\n\n# Ignore useless warnings (see SciPy issue #5998)\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")","2701184b":"train_set = pd.read_csv('\/kaggle\/input\/pricepredictionchallengedsub\/train_set.csv',index_col=0) \ntest_set = pd.read_csv('\/kaggle\/input\/pricepredictionchallengedsub\/test_set.csv',index_col=0)","e1ae150f":"# print the dataset size\nprint(\"There is\", train_set.shape[0], \"samples\")\nprint(\"Each sample has\", train_set.shape[1], \"features\")","b2e81b52":"train_set.head(10)","251830d4":"train_set.info()","6c92b1a4":"train_set.dtypes","2064b9d0":"# print those categorical features\ntrain_set.select_dtypes(include=['object']).head()","3645e66c":"# We can check how many different type there is in the dataset using the folliwing line\ntrain_set[\"Type\"].value_counts()","20743e79":"sns.countplot(y=\"Type\", data=train_set, color=\"c\")","ce1335c1":"## the features\nfeatures = ['Rooms','Landsize', 'BuildingArea', 'YearBuilt']\n## DEFINE YOUR FEATURES\nX = train_set[features].fillna(0)\ny = train_set[['Price']]\n\n## the model\n# KNeighborsRegressor\nfrom sklearn import neighbors\nn_neighbors = 3 \nmodel = neighbors.KNeighborsRegressor(n_neighbors)\n\n## fit the model\nmodel.fit(X, y)\n\n## predict training set\ny_pred = model.predict(X)\n\n## Evaluate the model and plot it\nfrom sklearn.metrics import mean_squared_error, r2_score\nprint(\"----- EVALUATION ON TRAIN SET ------\")\nprint(\"RMSE\",np.sqrt(mean_squared_error(y, y_pred)))\nprint(\"R^2: \",r2_score(y, y_pred))\n\n\nplt.scatter(y, y_pred)\nplt.xlabel('Price')\nplt.ylabel('Predicted price');\nplt.show()\n","c41a66ce":"## predict the test set and generate the submission file\nX_test = test_set[features].fillna(0)\ny_pred = model.predict(X_test)\n\ndf_output = pd.DataFrame(y_pred)\ndf_output = df_output.reset_index()\ndf_output.columns = ['index','Price']\n\ndf_output.to_csv('baseline.csv',index=False)","5754dc0f":"## BASELINE MODEL\nhttps:\/\/www.kaggle.com\/c\/mlub-housing-house-prediction\/notebooks\n\nThis is a simple model that uses the K-nearest Neighbors Regressor\n\nThis model only uses 4 feaures: 'Rooms','Landsize', 'BuildingArea', 'YearBuilt'\n\nCan you improve it?","5a444ec3":"It would be interesting to visualize all features (numerical and catergorical) in order to undertand them.\n\nCheck out this blog for plotting distribution: https:\/\/seaborn.pydata.org\/tutorial\/distributions.html\n\nSeaborn version of this blog can be different from the one intalled in your machine (version 0.11 has been just realeased) Check out this blog for plotting categorical data: https:\/\/seaborn.pydata.org\/tutorial\/categorical.html","063f5477":"# The problem\nThe machine learning is to predict the house price, but before that it is important to study the dataset and its features\n\n","03f03fce":"## Generate the submission file for the kaggle challenge"}}