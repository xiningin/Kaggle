{"cell_type":{"43483249":"code","82fe04d6":"code","dbd89144":"code","0adc6880":"code","2a5c928f":"markdown","776acaed":"markdown","59b8086c":"markdown","3487b9f7":"markdown","72232c3f":"markdown","afb2f988":"markdown"},"source":{"43483249":"#importing usefull and relevant libraries\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nimport numpy as np\nimport math\nimport h5py\n\nfrom keras import datasets\nfrom keras import losses\nfrom keras import callbacks\n\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import History\nfrom keras.callbacks import EarlyStopping\n\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.optimizers import SGD\nfrom keras.optimizers import Adam\nfrom keras.optimizers import RMSprop\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport os, warnings\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n        \n","82fe04d6":"# setting a number of possible image classifications, in our case it is binary: yes or no, True or False, 1 or 0, mask or no mask\nnum_classes = 2\n\n# using the pre set weights from resnet50 \nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# setting certain peramaters of our NN, such as activation function, loss function, optimization etc...\nmaskdetector = Sequential()\n\n# telling our network not to train the first layer, a key step in transfer learning\nmaskdetector.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmaskdetector.layers[0].trainable = False\n\n# activation, metrics, loss function, metrics\nmaskdetector.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmaskdetector.add(Dense(num_classes, activation='softmax'))\n\n# trimming the images as they go in\nimage_size = 224\n\n# augmenting our data, changing its orientation, width and height\ndata_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                   horizontal_flip=True,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2)\n\n# using non augmented data inorder to validate the network\ndata_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)","dbd89144":"# using our augmented and processed data inorder to train our network\ntrain_generator = data_generator_with_aug.flow_from_directory(\n        '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train',\n        target_size=(image_size, image_size),\n        batch_size=24,\n        class_mode='categorical')\n\n#setting our learning rate\nsgd = tf.keras.optimizers.SGD(learning_rate=1)\n\nvalidation_generator = data_generator_no_aug.flow_from_directory(\n        '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation',\n        target_size=(image_size, image_size),\n        class_mode='categorical')\n\n# setting a number of epochs as well as step size for running our network\nhistory = maskdetector.fit_generator(\n    train_generator,\n    steps_per_epoch=4,\n    epochs=20,\n    validation_data=validation_generator,\n    validation_steps=4)\n\n# plotting the loss\nfig, ax = plt.subplots(1, 1, figsize=(10,6))\nax.plot(np.sqrt(history.history['loss']), 'blue', label='train')\nax.plot(np.sqrt(history.history['val_loss']), 'orange' ,label='val')\nax.set_xlabel(r'No. of Epochs', fontsize=20)\nax.set_ylabel(r'Loss', fontsize=20)\nax.legend()\nax.tick_params(labelsize=20)\n\n# plotting the accuracy\nfig, ax = plt.subplots(1, 1, figsize=(10,6))\nax.plot(np.sqrt(history.history['accuracy']), 'blue', label='train')\nax.plot(np.sqrt(history.history['val_accuracy']), 'orange' ,label='val')\nax.set_xlabel(r'No. of Epochs', fontsize=20)\nax.set_ylabel(r'Accuracy', fontsize=20)\nax.legend()\nax.tick_params(labelsize=20)","0adc6880":"# redefining our model with new hyperparameters\nmaskdetector = Sequential()\n\n\n# setting momentum and learning rate \nepoch = 32\nlearning_rate = 1\ndecay_rate = learning_rate \/ epoch\nmomentum = 0.8\nsgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n\n\ndef step_decay(epoch):\n   initial_lrate = 1\n   drop = 0.5\n   epochs_drop = 10.0\n   learning_rate = initial_lrate * math.pow(drop,  \n           math.floor((1+epoch)\/epochs_drop))\n   return learning_rate\n\nlrate = LearningRateScheduler(step_decay)\n\nclass LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n       self.losses = []\n       self.learning_rate = []\n \n    def on_epoch_end(self, batch, logs={}):\n       self.losses.append(logs.get('loss'))\n       self.lr.append(step_decay(len(self.losses)))\n        \n\n\n# telling our network not to train the first layer\nmaskdetector.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmaskdetector.layers[0].trainable = False\n\n# activation function, metrics, optimizer, and loss function\nmaskdetector.compile(optimizer='sgd',\n                     loss='categorical_crossentropy',\n                     metrics=['accuracy'])\n\nmaskdetector.add(Dense(num_classes, activation='sigmoid'))\n\n# new level of augmentation\ndata_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                   horizontal_flip=True,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                             zoom_range=0.4)\n\n# using our augmented and processed data inorder to train our network\ntrain_generator = data_generator_with_aug.flow_from_directory(\n        '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train',\n        target_size=(image_size, image_size),\n        batch_size=64,\n        class_mode='categorical')\n\n# validation\nvalidation_generator = data_generator_no_aug.flow_from_directory(\n        '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation',\n        target_size=(image_size, image_size),\n        class_mode='categorical')\n\n# new step size and epochs\nhistory = maskdetector.fit_generator(\n    train_generator,\n    steps_per_epoch=4,\n    epochs=epoch,\n    validation_data=validation_generator,\n    validation_steps=1)\n\n# plotting the loss\nfig, ax = plt.subplots(1, 1, figsize=(10,6))\nax.plot(np.sqrt(history.history['loss']), 'blue', label='train')\nax.plot(np.sqrt(history.history['val_loss']), 'orange' ,label='val')\nax.set_xlabel(r'No. of Epochs', fontsize=20)\nax.set_ylabel(r'Loss', fontsize=20)\nax.legend()\nax.tick_params(labelsize=20)\n\n# plotting the accuracy\nfig, ax = plt.subplots(1, 1, figsize=(10,6))\nax.plot(np.sqrt(history.history['accuracy']), 'blue', label='train')\nax.plot(np.sqrt(history.history['val_accuracy']), 'orange' ,label='val')\nax.set_xlabel(r'No. of Epochs', fontsize=20)\nax.set_ylabel(r'Accuracy', fontsize=20)\nax.legend()\nax.tick_params(labelsize=20)","2a5c928f":"# Conclusion\n\n**Losses**\n\nAfter looking at our final predictions with the new stratageies and hyperparamaters implemented, we can see that we have reached an overall more optimal solution, however our descent is a bit more jumpy than that of the previous model, reaching higher highs and lower lows.\n\n**Accuracy**\n\nIn terms of accuracy the newer model is overall less accurate, but in our case, since we are classifying with our network, and anything over 80-90% accuracy (0.8-0.9) is adequite.\n\n**Over VS Under Fitting**\n\nLooking at the final results for our model, overfitting has not occured. We can tell that we have not over fit our model, as for the most part, the validation loss is lower than training loss, and the validation accuracy is higher than the training accuracy.\n\noverall the changes implemented into the second model have been a sucess, and our classifications have been more efficient and more accurate overall.","776acaed":"(\n\n''''\n            #implementing early stopping\n            tf.keras.callbacks.EarlyStopping(\n                monitor='val_loss', min_delta=0, patience=3, verbose=0,\n                mode='auto', baseline=None, restore_best_weights=False)\n\n            #all of our callbacks\n            model_callbacks = [\n                tf.keras.callbacks.EarlyStopping(monitor='loss',\n                                                    patience=3),\n            \n                tf.keras.callbacks.ModelCheckpoint(\n                    filepath=checkpoint_filepath,\n                    save_weights_only=True,\n                    monitor='val_accuracy',\n                    mode='max',\n                    save_best_only=True)\n                ]\n\n            #a brand new weights file, the main issue in our early stopping,\n            #to get a working weights file a pip download of the hp5 software was needed, \n            #which my laptop did not have sufficient acces for\n            checkpoint_filepath = '..\/input\/weightupdating\/newweight.h5'\n\n            #loading the new and improved weights \n            maskdetector.load_weights(checkpoint_filepath)\n\n''''\n\n)","59b8086c":"# Tuning\n\n**Old Hyperparameter Values**\n\n* Degree of Augmentation:\n                    Image width increase: 20%\n                    Image Hight increase: 20%                  \n* Batch Size:\n                    24               \n* Number of Epochs:\n                    20                   \n* Steps Per Epoch:\n                    4               \n* Activation Function:\n                    Softmax           \n* Optimization Function:\n                    SGD\n                    \n                    \n                    \n\n\n\n**New Hyperparameter Values**\n\n* Degree of Augmentation:\n                    Image width increase: 20%\n                    Image Hight increase: 20%   \n                    Image zoom: 40%\n* Batch Size:\n                    64\n* Number of Epochs:\n                    32\n* Steps Per Epoch:\n                    4\n* Validation Steps Epoch:\n                    1\n* Activation Function:\n                    Softmax\n* Optimization Function:\n                    SGD\n* Adaptive Learning rate","3487b9f7":"# Evaluation\n\nUpon viewing our graphics, it is clear that the hypothesis has been supported and the model was successful and accurate, however, could it be better? There are a few things that we can change in order to influence this this:\n\n**Degree to which the Data is Augmented**\n\nIn This neural network, as previously mentioned, data augmentation has been implemented to a certain degree.\nChanging the degree to which the data can be augmented, for example: changing the float that represents how       much the image can be stretched (which is currently at 0.2) to a higher value will make the network more         resilient when it comes to looking at significantly altered images in the validation set. However, this           alteration could also backfire, as it may cause the neural network to, in extreme cases, view images of non-     mask-wearing people as mask-wearing-people or vice versa, as training images may be so far distorted that         they are indistinguishable from one another when it comes to the validation set's images.\n    \n**Batch Size**\n    \nBatch size refers to the number of training samples, in our case images, that are worked through before our network begins to update itself. in general batch size should begin at around 30, however it can be increased until the batch size is equal to the size of the dataset itself, this is referred to as batch learning, and causes the model to make very large updates at one time, which may cause inaccuracies and will also cause a single epoch to take an extremeley long time.\nGenerally, it is said that a batch size of 32 or lower is most effective.\n\n**Number of Epochs**\n\nAn epoch is a single complete iteration of the data set, meaning it has been run and backpropagated (had weights edited based on assigned blame). Increasing the number of epochs will allow the network to spend more time learning, and will provide more accurate results, taking more time to do so. a lower number of epochs will take less time but also provide less accuracy. Of although more epochs will provide higher accuracy at some point, too many will just be a waste of time, meaning that it is best. Again, a number around 30 is usually the most beneficial. \n\n**Step Size**\n\nStep size is the degree to which the network edits its weights in the backpropagation stage of learning. Larger step sizes will get you to a result faster, however this result may only be locally optimal, which is a low loss and high accuracy, however not the lowest or highest. Having a smaller step size along with more epochs will eventually provide a globally optimal solution (the lowest loss; highest accuracy). Optimal step size is usually a small and positive value, between 0.1 and 1.\n\n**Activation function**\n\nThe activation function is the function that helps a neural network to analyse complex patterns within the data and does the actual math in order to make classifications. The function we are currently using is SoftMax, which is a form of logistic regression which provides us with output values in the range of 0-1, in our case mask or no mask.\n\n**Optimization Functions**\n\nThe current optimization function that is being implemented in our model is the sgd (stochastic gradient descent) optimizer. An optimizer is a function used in order to decide how much to edit the weights by. Other possible optimisation functions for our situation may include the Adam optimizer, which is arguably faster, but less accurate.\n\n**Steps Per Epoch**\n\nThe number of steps per epoch refers to the amount of batches of samples used in one epoch, for example, if the steps per epoch was 3, 3 batches would be used in one epoch. Since we are augmenting our data, steps per epoch is a crucial hyperparameter. We estimate a batch size with the function: training length\/\/batch size (training length refers to how long it takes to run the network), seeing as our neural network is a more simple classifier, it wont take to long to train, I estimate that it will take around a minute, so with an improved batch size of 32, we will have 60\/\/32, which equals around 2. Since we are augmenting our training data, we will multiply this function by 2 since there is more data being trained, leaving us with a batch size of 4 for our improved network.\n*Validation steps is the same but for the validation data, this will be set to 1 as there is less data.\n\n**Early stopping**\n\nEarly stopping is a techniqe which involves ending training before the set amount of epochs, as the network stops improving (hence the name). The weights at the time of stopping will be recorded and set as the starting point for the next run, causing the neural network to get better every time.\n\n**Adaptive Learning rate**\n\nSetting an adaptive learning rate will cause the learning rate to be updated as the neural network is training, this will cause better accuracy and loss aswell as a smoother gradient descent, all things we are looking for in a good neural network.","72232c3f":"# Afternote: Errors and Ommisions\n\nWhile looking to optimize my model a few ideas were unfortunatley scrapped and did not make it into the final iteration of the neural network.\n\nOne such example of this is the commented blocks of code below, the code for implementing early stopping and weight updates in the system. This idea was scrapped due to limitations with downloading the h5 software, inorder to create an empty and editable file for the weights to be transferred into.","afb2f988":"# Introduction\n\nGreetings,\nIn this Kaggle workbook we will be using neural networking techniques such as transfer learning and data augmentation, along with computer vision in order to classify if someone in an image is wearing a face mask or not.\n\n**Transfer Learning**\n\nTransfer learning is a deep learning method that involves using a pre trained model, that has already done all of the \"learning\", in our case ResNet50, removing the head and replacing it with our own, and applying it to a new problem while still retaining the knowledge of the previous neural network.\n\n**Data Augmentation**\n\nData augmentation is the process of altering our existing images in order to make it seem like we have more data than we actually do. Presume one of the images in our data set is flipped, or has had its contrast increased, would the network still be able to tell if a facemask is present in said image? That\u2019s is where data augmentation comes in, by purposefully flipping and colour swapping the images in our training data, we can provide the neural network with different situations to prepare for, without actually giving it more data.\n    \n**Hypothesis**\n    \nI hypothesise that this model will be efficient as well as accurate in classification, as it is:\n*      Performing a relatively simple process, as face masks provide multiple          obvious features, such as its uniform size and shape.\n*      implementing multiple techniques such as augmentation.\n"}}