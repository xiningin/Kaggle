{"cell_type":{"2532aa68":"code","3851b793":"code","1fd56ff3":"code","a8d7f6a8":"code","6097c30f":"code","85cd453d":"code","e96fe98e":"code","4e0532a0":"code","4b6a5157":"code","661976d9":"code","dbe1d18e":"code","eee33408":"code","c2f4a53c":"code","a252308b":"code","a8b70c4f":"code","f2ab7b26":"markdown","8044227c":"markdown","d7df2c0f":"markdown","f9838de8":"markdown","d0b82656":"markdown","4dc5326a":"markdown","4953fa02":"markdown","74c14d8f":"markdown","df4f0056":"markdown","bb9143ba":"markdown","8ee4d62e":"markdown","fcd568f8":"markdown","0dfdffb9":"markdown","d7867897":"markdown","a2c7c920":"markdown","aa5d0224":"markdown","1fd31407":"markdown","a6c0a40b":"markdown","ff86bf4a":"markdown","95b81da7":"markdown","d3cf43de":"markdown"},"source":{"2532aa68":"## Install and Import [need Internet on]\n\n!pip install transformers\nfrom transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n\n!pip install cdQA\n\nimport json,os\nimport pandas as pd\nimport pickle\nfrom tqdm import tqdm\nfrom cdqa.utils.download import download_squad, download_model, download_bnpp_data\nfrom ast import literal_eval\nfrom cdqa.pipeline import QAPipeline\nfrom cdqa.utils.filters import filter_paragraphs\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS ","3851b793":"## Prepare the CORD-19 dataset\ncfiles = []\nfor root, dirs, files in os.walk('..\/input\/CORD-19-research-challenge'):\n    for file in files:\n        if file.endswith('.json'):\n            cfiles.append(os.path.join(root, file))\n            \ndef to_covid_json(json_files):\n    jsonl = []\n    for file_name in tqdm(json_files):\n        row = {\"doc_id\": None, \"title\": None, \"abstract\": None, \"body\": None}\n\n        with open(file_name) as json_data:\n            data = json.load(json_data)\n\n            row['doc_id'] = data['paper_id']\n            row['title'] = data['metadata']['title']\n            \n            try:\n                abstract_list = [abst['text'] for abst in data['abstract']]\n                abstract = \"\\n\".join(abstract_list)\n                row['abstract'] = abstract\n            except:\n                 row['abstract'] = 'no abstract'\n            # And lastly the body of the text. \n            body_list = [bt['text'] for bt in data['body_text']]\n            body = \"\\n\".join(body_list)\n            row['body'] = body\n            \n        jsonl.append(row)\n    \n    return jsonl\n    \n\ndef get_data():\n    try:\n        with open('df_cache.pickle', 'rb') as f:\n            df = pickle.load(f)\n    except FileNotFoundError:\n        df = pd.DataFrame(to_covid_json(cfiles))\n        with open('df_cache.pickle', 'wb') as f:\n            pickle.dump(df, f)\n    return df\n\ndf = get_data()\n\ndf['paragraphs'] = df['abstract']\ndef lit(x):\n    k = [x]\n    l = literal_eval(str(k))\n    return l\ndf['paragraphs'] = df.paragraphs.apply(lambda x: lit(x))\ndf = filter_paragraphs(df)\ndf1 = df.loc[df['abstract'] == 'no abstract']['abstract']\ndf = df.drop(df1.index)","1fd56ff3":"cdqa_pipeline = QAPipeline(reader='\/kaggle\/input\/model\/covid_19_model_data.joblib')\ncdqa_pipeline.fit_retriever(df=df)","a8d7f6a8":"class output:\n    def __init__(self,query):\n        self.query  = query\n        \n    def result(self):\n        query = self.query\n        pred20 = cdqa_pipeline.predict(query,n_predictions=20,retriever_score_weight=0.5)\n        results = pd.DataFrame(pred20,columns = ['Answer','title','abstract','score'])\n        results['score'] = results['score'].div(100)\n        display(results)\n        self.results = results\n        return self.results\n    \n    # Store paragraph in a variable.\n    def summarizer_input(self,answer_df):\n        summarizer_input = []\n        for i in range(0, len(answer_df)):\n            paragraph = answer_df['abstract'][i]\n\n            word_search = answer_df['Answer'][i]\n\n            sentences_list = []\n            sentences_list = paragraph.split(\".\")\n\n            sentences_with_word = []\n            for sentence in sentences_list:\n                if sentence.count(word_search)>0:\n                    sentences_with_word.append(sentence)\n                    summarizer_input.append(sentence)\n\n        summarizer_paragraph = '. '.join(summarizer_input) + \".\"\n        return(summarizer_paragraph)\n    \n    def GenerateWC(self,answer_df, query, keywords):\n        '''\n        answer_df['score']: confidence \/ probability\n        answer_df['text']: the answer\n\n        e.g.\n        df = pd.DataFrame({'score':  [0.23, 0.3, 0.5],\n                           'text': ['corona is a problem!', 'die corona.', 'covid-19 is a new virus that causes problem.']})\n        query = 'Are there vaccines and therapeutics?'\n        keywords = 'corona, covid-19, drugs, clinical, effectiveness'\n        '''\n        # remove more stop words\n        stopwords = set(STOPWORDS) \n        add_query = set(query[:-1].split(' '))\n        add_keywords = set(keywords.split(', '))\n        add_stopwords = add_query.union(add_keywords)\n        stopwords = stopwords.union(add_stopwords)\n        \n        # prepare the mutiplied text according to the score\n        n = len(answer_df)\n        text = ' '\n        for i,row in answer_df.iterrows():\n            for k in range(int(np.round(1\/(1-row.score)))):\n                text = text + row.Answer[:-1] + ' '\n\n        # generate wordclound\n        wordcloud = WordCloud(width = 800, height = 800, \n                        background_color ='white', \n                        stopwords = stopwords, \n                        min_font_size = 10).generate(text) \n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis('off')\n        plt.show()\n\n###########\n\n# For summarization\n\n## We use BART transformers implementation to complete the summary generation task\n# see https:\/\/huggingface.co\/transformers\/model_doc\/bart.html?highlight=summarizer\n# Download the pretrained Bart model and tokenizer first, \n\nSummarize_model = BartForConditionalGeneration.from_pretrained('bart-large-cnn')\nBart_tokenizer = BartTokenizer.from_pretrained('bart-large-cnn')\n\ndef Summerization(summary_input, Summarize_model, Bart_tokenizer):\n    # Process the text needs to be summarized into BART inputs format\n    ARTICLE_TO_SUMMARIZE = summary_input\n    Summarize_inputs = Bart_tokenizer.batch_encode_plus([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n\n    # Generate Summary\n    summary_ids = Summarize_model.generate(Summarize_inputs['input_ids'], num_beams=4, min_length=20, max_length=100, early_stopping=False)\n    Generated_Summary = Bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n    \n    return Generated_Summary","6097c30f":"query ='what are the vaccines for treatment  covid-19 patients?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment, Antibody-Dependent Enhancement (ADE)'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","85cd453d":"query ='potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","e96fe98e":"query ='what is the best animal model prediction to used for human vaccine?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment, animal, model'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","4e0532a0":"query ='are there any therapeutics for covid-19?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","4b6a5157":"query ='what are the priorities of distribution of the newly proven therapeutics?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","661976d9":"query ='What are the efforts towards the coronavirus vaccine?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment, Antibody-Dependent Enhancement (ADE)'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","dbe1d18e":"query ='what are the challenges in developing animal models?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment, Antibody-Dependent Enhancement (ADE)'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","eee33408":"query ='what are Efforts to develop prophylaxis clinical studies?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment, Antibody-Dependent Enhancement (ADE)'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","c2f4a53c":"query ='Risk associated with covid 19 vaccines?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment, Antibody-Dependent Enhancement (ADE)'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","a252308b":"query ='Using animal models what are the responses of the immunity from vaccine?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment, Antibody-Dependent Enhancement (ADE)'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","a8b70c4f":"query ='ENTER YOUR QUESTION HERE?'\nout = output(query)\nk = out.result()\nstop_words = '2019-nCoV, covid, corona, covid-19, drugs, clinical, effectiveness, treatment'\nout.GenerateWC(k,query,stop_words)\nGenerated_Summary = Summerization(out.summarizer_input(k), Summarize_model, Bart_tokenizer)\nprint(Generated_Summary)","f2ab7b26":"## CDQA:\n\nWe install cdQA along with all the other standard python libraries for subsequent use.","8044227c":"In this code section, we feed the pre-processed abstract corpus to the CDQA Retriever.","d7df2c0f":"# 3. Task Results\n\nBelow are some example results generated using the above pipeline for the various CORD-19 tasks.[](http:\/\/)","f9838de8":"### Sub task: Efforts to develop prophylaxis clinical studies and prioritize in healthcare workers","d0b82656":"# 2. Approach Implementation","4dc5326a":"### Sub task: Approaches to evaluate risk for enhanced disease after vaccination\n","4953fa02":"# CORD-19 submission: Closed Domain Question & Answer (CDQA) Search & Summarize (CDQASS) on COVID-19 Literature\n\nBy Team Die Corona\n\n**Content:**\n\n1. Approach\n    * Introduction\n    * Current Pipeline\n2. Approach Implementation\n    * CDQA\n    * Pipeline Preparation\n3. Task Results\n    * Sub-Task Examples (Top Results, Summary & Wordcloud)\n    * Discussion of Results\n    * Future Work\n4. References\n5. Try it out!","74c14d8f":"### Sub task: Assays to evaluate vaccine immune response and process development for vaccines, alongside suitable animal models ","df4f0056":"### Sub task: Capabilities to discover a therapeutic (not vaccine) for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents.","bb9143ba":"In this code section, we prepare the CORD-19 dataset by sifting through the provided json files and creating a dataframe containing the article id, titles and abstract. \n\nWe also filter out any articles which do not contain abstracts. As discussed above, this may present limitations in our work in the sense that we might exclude relevant information from the article full text (especially, as we had no abstract to evaluate and therefore the article was eliminated from the abstract corpus altogether). ","8ee4d62e":"# Discussion of Results\n\nWhile the above results illustrate that the the CDQASS pipeline provides some first promising indications on where an user can find further information on their questions, it is clear that there are limitations in Machine Learning approaches for Natural Language Understanding tasks, particularly around Question & Answering and Summarizing. Although the first top answers across most tasks were found helpful, we expect further progress specific to COVID-19 search to take place especially on annotation of question-answer pairs as well as on summary generation. Outside of the CORD-19 challenge, we can expect further advances in NLU to result in even better models to tackle our pipeline and hopefully arrive at first results which our COVID-19 user community readily accept. Finally, the specific question text certainly influences the quality of the results and puts the burden on the CDQASS user to develop high quality questions.\n\n# Future Work\n\nAs a final piece, we summarize our future suggested work and count on the wider community to help mature our solution, thanks!\n\n1. Question generation to improve CDQA results relevance (e.g., feeding an initial question into a generative text model such as GPT-2, to then evaluate answers across multiple question variants.\n\n2. Full-text article retrieval and (possibly) reading to improve result relevance by increasing scope of search.\n\n3. Community supported Q&A and summarizer annotation for finetuning of the Reader and Summarizer models. CDQA already includes a user-friendly annotator feature which we can use as a starting point for the Reader. Idea is that users will annotate results in real-time as they are obtaining results from CDQASS.\n\n4. Additional community suggestions on results visualization. While the Wordcloud is a good first start, we would consider developing knowledge graphs to visualize how the article results relate to each other from both a ranking and referral perspective--especially, as a combined view on article references and CDQA relevance might provide an even better view on how the results finally relate to each other. \n\n5. Web-based search and results visualization interface.","fcd568f8":"### Sub task: Efforts to develop animal models and standardize challenge studies","0dfdffb9":"### Sub task: Exploration of use of best animal models and their predictive value for a human vaccine.","d7867897":"# 4. References\n\n[1] https:\/\/github.com\/cdqa-suite\/cdQA\n\n[2] https:\/\/towardsdatascience.com\/how-to-create-your-own-question-answering-system-easily-with-python-2ef8abc8eb5\n\n[3] https:\/\/github.com\/facebookresearch\/DrQA\/\n\n[4] https:\/\/arxiv.org\/abs\/1704.00051\n\n[5] https:\/\/huggingface.co\/transformers\/\n\n[6] https:\/\/arxiv.org\/abs\/1910.13461","a2c7c920":"### Sub task: Methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients.","aa5d0224":"## Pipeline Preparation:\n\nIn this code section, we define the classes for executing and providing results for the Retriever and Reader scoring on tf-idf search task and Q&A task respectively, as well as generate the abstractive summary and wordcloud of the top results. For our particular implementation, we selected the top 20 results. These classes are later on recalled to replicate the pipeline for multiple questions.","1fd31407":"# 1. Approach\n\n## Introduction: Closed Domain Question & Answer (CDQA) Search & Summarize (CDQASS) on COVID-19 Literature\n\n\nThe CDQA based COVID-19 Search & Summarize implemented here is based on a retriever-reader dual algorithmic approach developed by Andr\u00e9 Macedo Farias et al [1][2]. The CDQA model is inspired by the DrQA Open Domain Question Answer model, developed by Chen et al [3][4]. The main challenge with Question and Answering as a Natural Language Understanding task is that QA models often fail to perform when asked to produce an answer for a question from a large input text. To address this challenge the ODQA model was broken into two steps: 1) first, narrow down the input text to the top articles where the answer might be present (The Retriever) using search (e.g., tf-idf, BM25), and 2) out of the narrowed down input text, find the best potential answer (the Reader) using a Q&A model. For this reason, ODQA and its CDQA cousin can be considered as an approach to providing \"Machine Reading at Scale.\" In addition to CDQA, we also summarized the top answers via an abstractive summarizer and a WordCloud visualization to aid the user with a first glance of the results.\n\n## Current Pipeline\n\n![Die!%20Corona!%20Kaggle%20team%20-%20Pipeline.png](attachment:Die!%20Corona!%20Kaggle%20team%20-%20Pipeline.png)\n\nFigure 1 -- Illustration of algorithmic pipeline\n\nIn the retriever-reader dual model approach from CDQA (Figure 1, block 1.a), the user starts with a question similar to how one would ask a question in a web search engine. The retriever model then applies a TF-IDF type search, whereby the question string is compared to all of the article abstracts in our closed domain. For our closed domain, we included the 40,000+ article abstracts as our corpus. The top articles are identified based on a cosine similarity between the question string and abstract text. \n\nAs noted above, we limited the retriever data search to the abstracts as opposed to full articles. We chose this approach for two main reasons: 1) from a technical standpoint, feeding a large corpus for the closed domain resulted in memory crashes in our kaggle kernel which prevented us from using more than just the abstracts; 2) from a content and problem standpoint, we argue that abstracts will contain the most immediately relevant information a medical professional, researcher or policy maker will require as a starting point in their inquiry. We accepted this as a limitation to our corpus definition and recognize that we might leave out in some instances some very relevant information only found in the full article text; we will consider this as a future avenue of improvement.\n\nOnce we have identified the top articles that best address the question using a TF-IDF like ranking from the retriever model, we then proceed to the reader model (Figure 1, block 1.b). In this step, we again provide the input question as well as the abstract corpus. The pre-trained QA model (a DistilBERT implementation available from the Hugginface NLP library [5]) is then reading each selected abstract selected from the retriever in the first step, and providing an answer to the same question for each paragraph. Although it is possible to finetune the reader model by providing an annoted corpus, we selected the pretrained model for our implementation. Our proposal for future work would be to consider our tool being used by the wider user community, and implement a seamless annotation feature (available from the CDQA library) which would allow us to finetune our Reader and develop higher quality results.\n\nOnce the retriever and reader models are used, our solution presents the top k answers based on a weighted score between the retriever score (based on TF-IDF cosine similarity) and reader score (based on DistilBERT QA Q-A pair probability) (Figure 1, block 1.c). The standard CDQA implementation suggests a retriever score weight of 0.35 based on testing on the SQUAD v1.1 dataset, however we found that a higher weight of 0.5 resulted in answers containing text more relevant to the initial question.\n\nIn a set of downstream tasks, we've taken the output answers and related abstracts and further processed them into a final summary and related visual Wordcloud of the results. To aid the summarizer task, in a first step we have taken all of the abstracts and extracted the relevant sentences where predicted answers from the top-k results are contained (Figure 1, block 2.a). Afterwards, the relevant sentences are fed to the summarizer as a paragraph, out of which an abstractive summary is generated (a BART implementation from Lewis et al[6] based on the Hugginface NLP library [5]) (Figure 1, block 2.b). The motivation behind the summarizer pipeline is to aid the user in further sorting through the answers to get a high level view of the results and what could potentially be the key takeaways of the CDQA results. At the same time, we recognize the limitations of abstractive summarizers: even state of the art Natural Language summarizers are still evaluated on metrics (e.g., ROUGE-X, which measures n-gram overlap against annoted summaries) where there is no universal acceptance--especially as summary annotation is understandibly one of the most difficult human tasks in this space. In other words, if two human beings read the same text and are asked to produce a summary of the text, would they produce exactly the same summary? Although summarization (whether abstractive or extractive) faces inherent limitations, we still  believe it is a useful tool in providing the user with a first glance of the provided answers.\n","a6c0a40b":"### Sub task: Effectiveness of drugs being developed and tried to treat COVID-19 patients.","ff86bf4a":"### Sub task: Alternative models to aid decision makers in determining how to prioritize and distribute scarce, newly proven therapeutics as production ramps up. This could include identifying approaches for expanding production capacity to ensure equitable and timely distribution to populations in need.","95b81da7":"# 5. Try it out!\n\nIn the below code block, replace the text \"ENTER YOUR QUESTION HERE\" with your own question, and run it :)\n    \nIf you have words which you would like to omit from the wordcloud, we suggest you include them in the stop_words list as well.","d3cf43de":"\n### Sub task: Efforts targeted at a universal coronavirus vaccine."}}