{"cell_type":{"23370da8":"code","a85a9c93":"code","e247cadb":"code","cded9a24":"code","a8b54240":"code","216bdf83":"code","e14c18a4":"code","39f90d6b":"code","0b324bab":"code","3f5af37f":"code","86dce0b8":"code","c8326425":"code","45efaa1f":"code","fc9d394a":"code","3d33e302":"code","76d3b74d":"code","2d4577ae":"code","e307318c":"code","8bfd5cb0":"code","4b463586":"code","f6312a0f":"code","1891b446":"code","e3652eec":"code","e702cfc0":"code","e7762326":"code","b8cb5c2a":"code","65a6abe0":"code","6c694c9a":"code","75129df4":"code","f0dd2a2d":"code","15bff5dc":"code","bd6f2ae1":"code","d97babd9":"code","136c84fb":"code","9054b1c9":"code","f1cc0c4d":"code","60454853":"code","d6000b9b":"code","79f3ec02":"code","0414dd2f":"code","58b8464e":"code","44de5792":"code","a75fb225":"code","39c2ac40":"code","82eda133":"code","31ae3ce3":"code","ef3e3f57":"code","81b8ad77":"code","bca024be":"code","a256917e":"code","e54e1274":"code","4f9c07d5":"code","bc1e93cc":"code","e8fa53b8":"code","012e6b0a":"code","25cca8d3":"code","030b5e95":"markdown","c05ea500":"markdown","825fa16e":"markdown","d28a113c":"markdown","4b621f7b":"markdown","62a2c79f":"markdown","bfc40ac5":"markdown","0250b122":"markdown","4eb081cc":"markdown","93f706f4":"markdown","f9df123f":"markdown","7496312e":"markdown","13206acb":"markdown","59d4440c":"markdown","bc122750":"markdown","efaffd9a":"markdown","b0968e5e":"markdown","a1893990":"markdown","7711db7a":"markdown","67efc1a2":"markdown","33f3eb94":"markdown","46b8fef3":"markdown","c85cada2":"markdown","4ca7ca09":"markdown","b3131f8b":"markdown","7e48b8a2":"markdown","5545432b":"markdown","3dbf7456":"markdown","7b3e2371":"markdown","6ee4585a":"markdown","822822d5":"markdown","34f0bc02":"markdown","343cad0b":"markdown","b2efb33a":"markdown","10b3d768":"markdown","c0b13143":"markdown","9a03f68b":"markdown","8bd63ac6":"markdown","e1376d0c":"markdown","929715e5":"markdown","17d1192a":"markdown"},"source":{"23370da8":"import numpy as np\nimport pandas as pd\nimport scipy.special\nimport matplotlib.pyplot as plt\nimport os\nimport json","a85a9c93":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder","e247cadb":"from xgboost import XGBClassifier","cded9a24":"path_in = '..\/input\/data-science-bowl-2019\/'\nos.listdir(path_in)","a8b54240":"train_data = pd.read_csv(path_in+'train.csv', parse_dates=['timestamp'])\ntrain_labels = pd.read_csv(path_in+'train_labels.csv')\nspecs_data = pd.read_csv(path_in+'specs.csv')","216bdf83":"def plot_bar(data, name, width, lenght):\n    fig = plt.figure(figsize=(width, lenght))\n    ax = fig.add_subplot(111)\n    data_label = data[name].value_counts()\n    dict_train = dict(zip(data_label.keys(), ((data_label.sort_index())).tolist()))\n    names = list(dict_train.keys())\n    values = list(dict_train.values())\n    plt.bar(names, values)\n    ax.set_xticklabels(names, rotation=45)\n    plt.grid()\n    plt.show()","e14c18a4":"print('# samples train_data:', len(train_data))\nprint('# samples train_labels:', len(train_labels))\nprint('# samples specs:', len(specs_data))","39f90d6b":"train_data.head()","0b324bab":"train_labels.head()","3f5af37f":"specs_data.head()","86dce0b8":"cols_with_missing_train_data = [col for col in train_data.columns if train_data[col].isnull().any()]\ncols_with_missing_train_labels = [col for col in train_labels.columns if train_labels[col].isnull().any()]\ncols_with_missing_specs_data = [col for col in specs_data.columns if specs_data[col].isnull().any()]","c8326425":"print(cols_with_missing_train_data)\nprint(cols_with_missing_train_labels)\nprint(cols_with_missing_specs_data)","45efaa1f":"#train_data = train_data.loc[0: len(train_data.index)\/233]","fc9d394a":"train_data.columns","3d33e302":"train_data.dtypes","76d3b74d":"train_data['event_id'].value_counts()","2d4577ae":"train_data['game_session'].value_counts()","e307318c":"train_data['month'] = train_data['timestamp'].dt.month\ntrain_data['day'] = train_data['timestamp'].dt.weekday\ntrain_data['hour'] = train_data['timestamp'].dt.hour\ntrain_data['weekend'] = np.where((train_data['day'] == 5) | (train_data['day'] == 6), 1, 0)","8bfd5cb0":"features_cyc = {'month' : 12, 'day' : 7, 'hour' : 24}\nfor feature in features_cyc.keys():\n    train_data[feature+'_sin'] = np.sin((2*np.pi*train_data[feature])\/features_cyc[feature])\n    train_data[feature+'_cos'] = np.cos((2*np.pi*train_data[feature])\/features_cyc[feature])\ntrain_data = train_data.drop(features_cyc.keys(), axis=1)","4b463586":"encode_fields = ['description']\n# steps = 233\n# for i in range(steps):\n#     print('work on step: ', i+1)\n#     for encode_field in encode_fields:\n#         slice_from = i*len(train_data.index)\/steps\n#         slice_to = (i+1)*len(train_data.index)\/steps-1\n#         train_data.loc[slice_from:slice_to, encode_field] = train_data.loc[slice_from:slice_to, 'event_data'].apply(json.loads).apply(pd.Series)[encode_field]\ndel train_data['event_data']","f6312a0f":"plot_bar(train_data, 'title', 30, 5)","1891b446":"map_train_title = dict(zip(train_data['title'].value_counts().sort_index().keys(),\n                     range(1, len(train_data['title'].value_counts())+1)))","e3652eec":"train_data['title'] = train_data['title'].replace(map_train_title)","e702cfc0":"plot_bar(train_data, 'type', 9, 5)","e7762326":"train_data = pd.get_dummies(train_data, columns=['type'])","b8cb5c2a":"plot_bar(train_data, 'world', 9, 5)","65a6abe0":"train_data = pd.get_dummies(train_data, columns=['world'])","6c694c9a":"train_labels.columns","75129df4":"plot_bar(train_labels, 'title', 9, 5)","f0dd2a2d":"map_label_title = dict(zip(train_labels['title'].value_counts().sort_index().keys(),\n                     range(1, len(train_labels['title'].value_counts())+1)))","15bff5dc":"train_labels['title'] = train_labels['title'].replace(map_label_title)","bd6f2ae1":"train_labels['num_correct'].value_counts()","d97babd9":"#train_labels['num_incorrect'].value_counts()","136c84fb":"train_labels['accuracy'].describe()","9054b1c9":"plot_bar(train_labels, 'accuracy_group', 8, 4)","f1cc0c4d":"train_labels['accuracy_group'].value_counts().sort_index()","60454853":"specs_data.columns","d6000b9b":"specs_data['event_id']","79f3ec02":"specs_data['info'].value_counts()","0414dd2f":"specs_data.loc[0, 'args']","58b8464e":"train_data = pd.merge(train_data, train_labels,  how='right', on=['game_session','installation_id'])","44de5792":"no_features = ['accuracy_group', 'event_id', 'game_session', 'timestamp','installation_id',\n              'accuracy', 'num_correct', 'num_incorrect']\nX_train = train_data[train_data.columns.difference(no_features)].copy(deep=False)\ny_train = train_data['accuracy_group']\n\ndel X_train['title_y']\nX_train = X_train.rename(columns = {'title_x': 'title'})","a75fb225":"len(X_train.index), len(train_data.index)","39c2ac40":"X_train.head()","82eda133":"del train_data","31ae3ce3":"model = XGBClassifier(objective ='multi:softmax',\n                      learning_rate = 0.2,\n                      max_depth = 16,\n                      n_estimators = 350,\n                      random_state=2020,\n                      num_class = 4)\nmodel.fit(X_train,y_train)","ef3e3f57":"del X_train, y_train","81b8ad77":"test_data = pd.read_csv(path_in+'test.csv', parse_dates=['timestamp'])\nsamp_subm = pd.read_csv(path_in+'sample_submission.csv')","bca024be":"\"\"\" Extract new features from timestamp \"\"\"\ntest_data['month'] = test_data['timestamp'].dt.month\ntest_data['day'] = test_data['timestamp'].dt.weekday\ntest_data['hour'] = test_data['timestamp'].dt.hour\ntest_data['weekend'] = np.where((test_data['day'] == 5) | (test_data['day'] == 6), 1, 0)\n\n\"\"\" Encode cyclic features \"\"\"\nfeatures_cyc = {'month' : 12, 'day' : 7, 'hour' : 24}\nfor feature in features_cyc.keys():\n    test_data[feature+'_sin'] = np.sin((2*np.pi*test_data[feature])\/features_cyc[feature])\n    test_data[feature+'_cos'] = np.cos((2*np.pi*test_data[feature])\/features_cyc[feature])\ntest_data = test_data.drop(features_cyc.keys(), axis=1)\n\n\"\"\" Encode feature title \"\"\"\ntest_data['title'] = test_data['title'].replace(map_train_title)\n\n\"\"\" Encode feature type \"\"\"\ntest_data = pd.get_dummies(test_data, columns=['type'])\n\n\"\"\" Encode feature world \"\"\"\ntest_data = pd.get_dummies(test_data, columns=['world'])\n\n\"\"\" Delete feature event_data \"\"\"\ndel test_data['event_data']","a256917e":"X_test = test_data[test_data.columns.difference(no_features)].copy(deep=False)","e54e1274":"y_test = model.predict(X_test)","4f9c07d5":"y_temp = pd.DataFrame(y_test, index=test_data['installation_id'], columns=['accuracy_group'])","bc1e93cc":"y_temp_grouped = y_temp.groupby(y_temp.index).agg(lambda x:x.value_counts().index[0])","e8fa53b8":"output = pd.DataFrame({'installation_id': y_temp_grouped.index,\n                       'accuracy_group': y_temp_grouped['accuracy_group']})\noutput.index = samp_subm.index\noutput.to_csv('submission.csv', index=False)","012e6b0a":"output.head()","25cca8d3":"output['accuracy_group'].value_counts().sort_index()","030b5e95":"### Feature type\nMedia type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'. This is a categorical feature which we encode by one hot encoding technique.","c05ea500":"# Prepare Test Data\nWe repeat the data preparation of the train set.","825fa16e":"### Feature accuracy\nThis is a float fearure.","d28a113c":"### Feature info\nDescription of the event. There are 168 different types of informations.","4b621f7b":"# Prepare y_test for output\nWe group the results by the installation_id and take the most frequent accuracy_group.","62a2c79f":"### Feature installation_id\nRandomly generated unique identifier grouping game sessions within a single installed application instance.","bfc40ac5":"### Feature event_id\nRandomly generated unique identifier for the event type. <br>\nThere are dublictated codes.","0250b122":"# Merge data\nFor the first step we only merge the train_data with the train_label by the key . ","4eb081cc":"### Feature title\nTitle of the game or video. The feature title is a categorical feature with lot of categories. For the first we use a simple mapping.","93f706f4":"### Feature installation_id\nThe installation_id will typically correspond to one child.\nIt is dandomly generated unique identifier grouping game sessions within a single installed application instance.","f9df123f":"## Specs\nThis file gives the specification of the various event types.","7496312e":"### Feature timestamp\nIs the client-generated datetime. You can extract new features like month, day or hour. These are cyclic features which can be encoded. Additionally we create the feature weekend: 5 = saturday and 6 = sunday.","13206acb":"# Load Test Data","59d4440c":"### Feature event_count\n Incremental counter of events within a game session (offset at 1). Extracted from event_data.","bc122750":"# Write output","efaffd9a":"# Define X_test","b0968e5e":"# Missing data\n\nFortunately there are no missing data we have to deal.","a1893990":"# Define XGB Classifier\nFor the first step we use the XGB Classifier.","7711db7a":"### Feature num_incorrect\nThis is a numerical feature.","67efc1a2":"# Load Train Data\nThere is a column with a datetime information. So we can load as datetime type by parse_dates=['timestamp'].","33f3eb94":"# Show files in path","46b8fef3":"### Feature game_session\nRandomly generated unique identifier grouping events within a single game or video play session. <br>\nThere are dublictated codes.","c85cada2":"### Feature game_time\nTime in milliseconds since the start of the game session. Extracted from event_data.","4ca7ca09":"### Feature event_id\nGlobal unique identifier for the event type.","b3131f8b":"### Feature num_correct\nThis is a binary feature we can use without modification. ","7e48b8a2":"# Analysis & Overview\nFirst we do a simple analysis and show important kpis.","5545432b":"## Train data","3dbf7456":"### Feature event_code\nIdentifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from event_data.","7b3e2371":"## Train labels\nThis dataset demonstrates how to compute the ground truth for the assessments in the training set.","6ee4585a":"# Feature engineering\nThere are 3 keys:\n\n1) game_session, installation_id: to merge train data and train labels\n\n2) event_id: to merge train data and specs \n\nFor the idea of the feature engineering we reduce the train data and use a subset. ","822822d5":"# Load Libraries","34f0bc02":"# Define X_train and y_train\nThe featrue accuracy_group is the target which is to predict.","343cad0b":"# Help Function","b2efb33a":"### Feature args\nJSON formatted string of event arguments. Each argument contains:\n* name - Argument name.\n* type - Type of the argument (string, int, number, object, array).\n* info - Description of the argument.\n\nSo what can we do with the information?","10b3d768":"### Feature game_session\n Randomly generated unique identifier grouping events within a single game or video play session.","c0b13143":"### Feature title\nThe feature title is a categorical feature. For the first we use a simple mapping.","9a03f68b":"### Feature accuracy_group\nThis is the target we have to predict.","8bd63ac6":"# Welcome to the Data Science Bowl Competition\nThis notebook is a starter code for all beginners and easy to understand. <br>\nWe focus on\n* a simple analysis of the data,\n* create new features,\n* encoding and \n* scale data,\n* prepare data for train.\n\nWe use categorical feature encoding techniques, compare <br>\nhttps:\/\/www.kaggle.com\/drcapa\/categorical-feature-encoding-challenge-xgb\n\nIn this kernel we consider the train data. For prediction we must repeate all operations also for the test data. <br>\nAfter that we define X_train and y_train.\nThe aim of the competition is to predict the target accuracy_group:\n* 3: the assessment was solved on the first attempt,\n* 2: the assessment was solved on the second attempt,\n* 1: the assessment was solved after 3 or more attempts,\n* 0: the assessment was never solved.\n\nTo predict the test data we use a XGB Classifier.","e1376d0c":"### Feature event_data\nSemi-structured JSON formatted string containing the events parameters. Default fields are: event_count, event_code, and game_time; otherwise fields are determined by the event type. <br>\nNext we show how to encode the features of a dictionary. \nWithout loss of generality we consider only the feature *description*.\nIf you don't want to extract new features you can delete the column.","929715e5":"# Predict y_test","17d1192a":"### Feature world\nThe section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length\/Height), 'MAGMAPEAK' (Capacity\/Displacement), 'CRYSTALCAVES' (Weight). This is a categorical feature which we encode by one hot encoding technique."}}