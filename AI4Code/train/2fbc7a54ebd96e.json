{"cell_type":{"82347be3":"code","1190965f":"code","9df8b8f5":"code","5a4c96d8":"code","35649d18":"code","6afc1e18":"code","bfdc59ff":"code","5c138251":"code","a2bb60de":"markdown","5cb09730":"markdown","a1c534d7":"markdown","fd9999c4":"markdown"},"source":{"82347be3":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport re\nimport pandas as pd\nimport seaborn as sns\nfrom textwrap import wrap\n\nplt.rcParams[\"figure.dpi\"] = 100","1190965f":"df = pd.read_csv(\"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\")","9df8b8f5":"# By Andrada Olteanu\n# https:\/\/www.kaggle.com\/andradaolteanu\/siim-covid-19-box-detect-dcm-metadata\ndef show_values_on_bars(axs, h_v=\"v\", space=0.4):\n    '''Plots the value at the end of the a seaborn barplot.\n    axs: the ax of the plot\n    h_v: weather or not the barplot is vertical\/ horizontal'''\n    \n    def _show_on_single_plot(ax):\n        if h_v == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() \/ 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(round(_x, 5), round(_y, 5), format(round(value, 5), ','), ha=\"center\") \n        elif h_v == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, format(value, ','), ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs): _show_on_single_plot(ax)\n    else: _show_on_single_plot(axs)","5a4c96d8":"def our_countplot(column, df):\n    ax = sns.countplot(x=df[column].to_numpy()[1:])\n    plt.title(\"\\n\".join(wrap(df[column].to_numpy()[0], 60)))\n    plt.grid(axis=\"y\")\n    show_values_on_bars(ax)\n    _ = plt.xticks(rotation=90)\n    \n    \ndef re_filter(query, df_in):\n    global df\n    \n    r = re.compile(query)\n    newlist = list(filter(r.match, df_in.columns.to_list()))\n    \n    columns = [df[col].iloc[1:].unique().astype(\"str\") for col in newlist]\n    columns = [g[g != \"nan\"][0] for g in columns]\n    \n    g = df_in[newlist].count() - 1  # first row requires minus out. \n    g.index = columns\n    g = g.reset_index(level=0)\n    g.columns = [\"index\", \"count\"]\n    return g, columns, newlist[0]\n\n\ndef our_plot(query, df):\n    if query == \"Q3\": plt.figure(figsize=(12, 7))\n    try: our_countplot(query, df)\n    except KeyError:\n        out, columns, title_col = re_filter(query, df)\n        ax = sns.barplot(x=\"index\", y=\"count\", data=out)\n        show_values_on_bars(ax)\n        plt.xticks(rotation=90)\n        plt.grid(axis=\"y\")\n        plt.title(\"\\n\".join(wrap(df[title_col].to_numpy()[0].split(\"?\")[0] + \"?\", 60)))\n        \n        \ndef get_columns(query):\n    \"\"\"Given a question, e.g. 'Q7', return all column names that are 'Q7*'\"\"\"\n    r = re.compile(query)\n    return np.array(list(filter(r.match, df.columns.to_list())))","35649d18":"get_columns(\"Q7\")","6afc1e18":"# Query with retaining first row\nq = np.array(df[\"Q7_Part_3\"] == \"SQL\")\nq[0] = True\n\ndf_sql = df[q]\ndf_sql.head()","bfdc59ff":"our_plot(\"Q5\", df_sql)","5c138251":"our_plot(\"Q7\", df)","a2bb60de":"After looking through Q1 to Q6, one founds that apart from Q5, others have no useful information (whether they are SQL users or not, they have the same distributions of population). Q5 have a difference: \n\nMost people using SQL are found to be Student, Data Analyst, Data Scientist and Software Engineer. These aren't exceeding expectations. Example, even Data Engineer although low, aren't exceeding expectations because the total number of Data Engineers taking the query aren't many (466 of 668 uses SQL). What exceeds expectations is **Machine Learning Engineer (MLE)**.\n\nIt seems that MLE aren't very popular using SQL (491 of 1499) hence can deduce they're perhaps more targeting on the models development. \n\nFew months ago, Data Centric development had been introduced by Andrew Ng (https:\/\/www.youtube.com\/watch?v=06-AZXmwHjo&ab_channel=DeepLearningAI) (from ones' perspective, because that's how one got introduced to data centric, but it doesn't mean he might be the first to do data centric, it might be someone else or his team or another team or whatever, one didnt research on that). Perhaps it's time to start learning SQL and be prepared. Even though we could play around based on small subset of data, when we want to apply it to real world, in a pipeline, whatever an MLE played with needs to integrate to such pipeline, without much delay. SQL provides very quick way to work through data and it's important to translate whatever query one uses into SQL. \n\nFor example, if one plays with Pandas DataFrame and uses it's SQL-like commands, they're not the fastest way to deal with data cleaning (especially since Pandas itself runs on a single core only, while others like Spark DataFrame runs on all cores, and others like CUDF or BlazingSQL runs on GPU\/CUDA for preprocessing). \n\nThey're important. ","5cb09730":"2) It seems that people uses C++ (ignoring C here) as many as R (at least based on people who took the questionnaire). But Kaggle notebooks only support Python and R. Are there C++ (notebooks\/script) available to Kaggle community as well? Is there are difference in performance developing with Pytorch Python vs PyTorch C++ API? (we ignore TensorFlow here but it may well generalize to TF and other ML libraries, if they support both language). ","a1c534d7":"# Analysis QnA\nThe first thing to be questioned is whether the questionnaire is representative of Kaggle community. This is also our first assumption: *Assume that the questionnaire is a well represented subset of the Kaggle community*. \n\n(to be filled in)","fd9999c4":"1) What type of people uses SQL? Are they mainly business people? How much programming experience they have? \nWe are not answering what type of products they use here, we just want to know what community they represent. Given SQL importance, it is worth knowing what community aren't exposed to SQL and hence create targeted resources exposing them to SQL (and make it easy for them to take on SQL if they find it difficult somehow). "}}