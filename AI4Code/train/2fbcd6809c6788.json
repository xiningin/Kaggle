{"cell_type":{"4e64ee56":"code","7b33e4ec":"code","6decf50b":"code","93fbbd30":"code","fa1ab095":"code","6282898d":"code","78cd00c8":"code","f241d115":"code","bf5eff14":"code","813ceb1f":"code","748618e4":"code","962ce3e1":"code","69aa777f":"code","69a4d4dd":"code","e29b680c":"code","cf8e4998":"markdown","6e191699":"markdown","e4146d5d":"markdown","aded6caa":"markdown","84d6d7cd":"markdown","689f8c03":"markdown","256a6470":"markdown","c6ccb5c1":"markdown"},"source":{"4e64ee56":"import pandas as pd\nimport numpy as np\n\nimport requests\nfrom requests import get\nfrom bs4 import BeautifulSoup\n\nfrom time import sleep\nfrom random import randint","7b33e4ec":"# Creating the lists we want to write into\ntitles = []\nyears = []\ntime = []\nimdb_ratings = []\nmetascores = []\nvotes = []\nus_gross = []","6decf50b":"# Getting English translated titles from the movies\nheaders = {'Accept-Language': 'en-US, en;q=0.5'}","93fbbd30":"pages = np.arange(1, 1001, 50)\npages","fa1ab095":"# Storing each of the urls of 50 movies \nfor page in pages:\n    # Getting the contents from the each url\n    page = requests.get('https:\/\/www.imdb.com\/search\/title\/?groups=top_1000&start=' + str(page) + '&ref_=adv_nxt', headers=headers)\n    soup = BeautifulSoup(page.text, 'html.parser')\n    \n    # Aiming the part of the html we want to get the information from\n    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n    \n    # Controling the loop\u2019s rate by pausing the execution of the loop for a specified amount of time\n    # Waiting time between requests for a number between 2-10 seconds\n    sleep(randint(2,10))\n    \n    for container in movie_div:\n        # Scraping the movie's name\n        name = container.h3.a.text\n        titles.append(name)\n        \n        # Scraping the movie's year\n        year = container.h3.find('span', class_='lister-item-year').text\n        years.append(year)\n        \n        # Scraping the movie's length\n        runtime = container.find('span', class_='runtime').text if container.p.find('span', class_='runtime') else '-'\n        time.append(runtime)\n        \n        # Scraping the rating\n        imdb = float(container.strong.text)\n        imdb_ratings.append(imdb)\n        \n        # Scraping the metascore\n        m_score = container.find('span', class_='metascore').text if container.find('span', class_='metascore') else '-'\n        metascores.append(m_score)\n        \n        # Scraping votes and gross earnings\n        nv = container.find_all('span', attrs={'name':'nv'})\n        vote = nv[0].text\n        votes.append(vote)\n        grosses = nv[1].text if len(nv) > 1 else '-'\n        us_gross.append(grosses)","6282898d":"movies = pd.DataFrame({'movie':titles,\n                       'year':years,\n                       'time_minute':time,\n                       'imdb_rating':imdb_ratings,\n                       'metascore':metascores,\n                       'vote':votes,\n                       'gross_earning':us_gross})\n\nmovies.head()","78cd00c8":"movies.dtypes","f241d115":"# Cleaning 'year' column\nmovies['year'] = movies['year'].str.extract('(\\d+)').astype(int)\nmovies.head(3)","bf5eff14":"# Cleaning 'time_minute' column\nmovies['time_minute'] = movies['time_minute'].str.extract('(\\d+)').astype(int)\nmovies.head(3)","813ceb1f":"# Cleaning 'metascore' column\nmovies['metascore'] = movies['metascore'].str.extract('(\\d+)')\n# convert it to float and if there are dashes turn it into NaN\nmovies['metascore'] = pd.to_numeric(movies['metascore'], errors='coerce')","748618e4":"# Cleaning 'vote' column\nmovies['vote'] = movies['vote'].str.replace(',', '').astype(int)\nmovies.head(3)","962ce3e1":"# Cleaning 'gross_earning' column\n# left strip $ and right strip M \nmovies['gross_earning'] = movies['gross_earning'].map(lambda x: x.lstrip('$').rstrip('M'))\n# convert it to float and if there are dashes turn it into NaN\nmovies['gross_earning'] = pd.to_numeric(movies['gross_earning'], errors='coerce')\nmovies.head(3)","69aa777f":"movies.dtypes","69a4d4dd":"movies","e29b680c":"movies.to_csv('movies.csv')","cf8e4998":"# Web Scraping from IMDB Site:\n\n\nThis study is from Angelica Dietzel (https:\/\/medium.com\/@angelicacodes) and her blog posts in Medium (References). \n\nIn this study I build a step by step web scraper using Python.\n\nI scrape only the data I need.\n\nFor this study, I scrape data from IMDb\u2019s \u201cTop 1000\u201d movies. The information I gather from each movie are:\n* The title\n* The year it was released\n* How long the movie is\n* IMDb\u2019s rating of the movie\n* The Metascore of the movie\n* How many votes the movie got\n* The U.S. gross earnings of the movie\n\nLink of the IMDB website: https:\/\/www.imdb.com\/search\/title\/?groups=top_1000&ref_=adv_prv\n\n**References:**\n\nhttps:\/\/medium.com\/better-programming\/the-only-step-by-step-guide-youll-need-to-build-a-web-scraper-with-python-e79066bd895a\nhttps:\/\/medium.com\/better-programming\/how-to-scrape-multiple-pages-of-a-website-using-a-python-web-scraper-4e2c641cff8","6e191699":"## Scraping from the web page","e4146d5d":"There are 1000 movies and each page has 50 movies listed.\n\nSo the first 50 movies' url: \nhttps:\/\/www.imdb.com\/search\/title\/?groups=top_1000&ref_=adv_prv\n\nMovies from 51 to 100:\nhttps:\/\/www.imdb.com\/search\/title\/?groups=top_1000&start=51&ref_=adv_nxt\n\nMovies from 101 to 150:\nhttps:\/\/www.imdb.com\/search\/title\/?groups=top_1000&start=101&ref_=adv_nxt\n\n...","aded6caa":"## Creating the Data Set","84d6d7cd":"## Saving the data to a csv file","689f8c03":"## Cleaning the Data Set","256a6470":"## Loading the libraries","c6ccb5c1":"## Final Data Set"}}