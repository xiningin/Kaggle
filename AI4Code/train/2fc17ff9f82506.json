{"cell_type":{"6dfa1d60":"code","6250d2ed":"code","a2547734":"code","eb3520ac":"code","d2295d5f":"code","9dc4408e":"code","1adb8809":"code","52054dc2":"code","16e331c2":"code","e6c8c621":"code","c0da4f85":"code","6b42b3fc":"code","5b8df077":"code","eb6d1585":"code","ca14d09e":"code","380c48ad":"code","0d126dea":"code","080ed00e":"code","a7821fc0":"code","063111ee":"code","32a253c8":"code","923287d1":"code","ab011522":"code","7f4d0fe5":"code","4d885390":"code","79a40ab0":"code","8653edc8":"code","75130f30":"code","54a3fe7e":"code","6bcf1152":"code","43486ac1":"code","9b9ff180":"code","3ec07c98":"code","d3edcfc1":"code","2d17a5e7":"code","3c8df809":"code","7b933cba":"code","a16e95df":"code","b5f933da":"code","68e75524":"code","33071b3a":"code","4d19c2cc":"code","79322e98":"code","a977ca80":"code","28a3f0fb":"code","c0484591":"code","228d1670":"code","ee3387ad":"code","554127e4":"code","c833c0bb":"markdown","eef650be":"markdown","f90a1aa5":"markdown","617951a8":"markdown","a51d9558":"markdown","3c0f9ce4":"markdown","2b02fe1d":"markdown","d4db24d3":"markdown","8fdde272":"markdown","6936f69e":"markdown","9d22a5ba":"markdown","4a068a0c":"markdown","9677a43a":"markdown","7f10de98":"markdown","5f21d99c":"markdown","d894b476":"markdown","eb42621a":"markdown","adbb4264":"markdown","c87ed5ea":"markdown","0ae9721a":"markdown","8f06418a":"markdown"},"source":{"6dfa1d60":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_column',None)\n\nimport warnings\nwarnings.filterwarnings('ignore')","6250d2ed":"df= pd.read_csv('\/kaggle\/input\/hr-employee-attrition\/HR_Employee_Attrition_Data.csv')\ndf.head()","a2547734":"df.info()","eb3520ac":"df.isnull().sum()","d2295d5f":"df.describe()","9dc4408e":"blue_pair= sns.color_palette('Paired')[1]\nblue_pair_lit= sns.color_palette('Paired')[0]\nblue_tone=[ blue_pair, blue_pair_lit]\ndark_tone = [blue_pair, 'black']\ndark_tone_r = ['black',blue_pair]\ndark_tone_3 = [blue_pair_lit, blue_pair, 'black']\nblue_pastel= sns.color_palette('Pastel2')[0]\nred_pastel =sns.color_palette('Pastel2')[1]\nviogo_pastel = sns.color_palette('Pastel2')[2]\ngreen_pastel = sns.color_palette('Pastel2')[4]\nyellow_pastel = sns.color_palette('Pastel2')[5]\nsns.color_palette('Pastel2')","1adb8809":"#### Creating a highlight palette for Attrition\npalette_dic ={x: 'black' for x in df.Attrition.unique()}\n# print(palette_dic,'\\n')\npalette_dic['No']= blue_pair #'#24477f'\n\nmckinsey_color_palette = ['#24477f','#D9C666','#BFAE5A','#EA9C39','#053259']\n","52054dc2":"z= sns.blend_palette(['orange', 'white', 'green'])\norange=sns.color_palette(z)[1]","16e331c2":"# only \"explode\" the 2nd slice (i.e. 'Hogs')\n# basic pie chart\n# df.groupby('Gender').size().plot(kind='pie',autopct='%.2f',explode=explode, shadow=True,title=\"Gender\" ,colors=colors,)\n#plt.pie(sizes ,autopct='%.2f',explode=explode, shadow=True,title=\"Gender\" ,colors=colors,)  ## simple pie\n\nsizes =df.groupby('Attrition').size()\nexplode = (0, 0.1)   ### Split the 2nd category only\ncolors= sns.color_palette('Paired')[:2]\nlabel= ['Stayed','Attrition']\n\n### Donut chart\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes ,autopct='%.2f',labels=label, shadow=True,colors=colors)  ## removed explode=explode, startangle=90\n\n#draw circle\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal') \nplt.title('Percentage of Attrition')\nplt.tight_layout()\nplt.show()\n","e6c8c621":"%time\n# plt.style.use('dark_background')\ndf.hist(color=blue_pair_lit,edgecolor=blue_pair, linewidth=1.2, figsize=(15,15));","c0da4f85":"%time\nplt.figure(figsize=(15,8))\nsns.heatmap(df.corr(),cmap=colors, annot=True)","6b42b3fc":"# hfont = {'fontname':'Helvetica'}\n\n### scatter plot between monthly rate, hourly rate and daily rate : Also with monthly income\nplt.figure(figsize=(20,6))\nplt.subplot(1,3,1)\nsns.regplot(y='MonthlyRate', x= 'HourlyRate', data=df,scatter_kws={\"color\": \"black\"}, line_kws={\"color\": blue_pair})\nplt.subplot(1,3,2)\nsns.regplot(y='MonthlyRate', x= 'DailyRate', data=df,scatter_kws={\"color\": \"black\"}, line_kws={\"color\": blue_pair})\nplt.subplot(1,3,3)\nsns.regplot(y='MonthlyRate', x= 'MonthlyIncome', data=df,scatter_kws={\"color\": \"black\"}, line_kws={\"color\": blue_pair})\nplt.suptitle('Exploring relationship between Different Rates', fontsize=20, fontname='Bower')\nplt.show();","5b8df077":"plt.figure(figsize=(20,6))\nplt.subplot(1,3,1)\nsns.regplot(x='Education', y= 'HourlyRate', data=df, color='black', marker='x',scatter_kws={\"color\": \"black\"}, line_kws={\"color\": blue_pair})\nplt.subplot(1,3,2)\nsns.regplot(x='Education', y= 'MonthlyIncome', data=df,scatter_kws={\"color\": \"black\"}, line_kws={\"color\": blue_pair})\nplt.subplot(1,3,3)\nsns.regplot(y='DistanceFromHome', x= 'MonthlyIncome', data=df,scatter_kws={\"color\": \"black\"}, line_kws={\"color\": blue_pair})\nplt.suptitle('Exploring relationship between Education and payScale', fontsize=20, fontname='sans-serif')\nplt.show();","eb6d1585":"plot_yeam = ['red', 'Black']\n\nm = [\"Age\",\"PercentSalaryHike\",\"PerformanceRating\",\"WorkLifeBalance\",\"EnvironmentSatisfaction\",\"DistanceFromHome\"]\nj=1\nplt.figure(figsize=(15,10))\nfor i in m:\n    plt.subplot(2,3,j)\n    sns.scatterplot(data=df, x=i, y='JobSatisfaction', hue='Attrition', palette=plot_yeam, sizes=(20, 2000))\n    j=j+1\nplt.show()\n    ","ca14d09e":"l2=['Age', 'DistanceFromHome', 'HourlyRate','DailyRate', 'MonthlyRate', 'MonthlyIncome','PercentSalaryHike',\n    'YearsAtCompany', 'YearsInCurrentRole','YearsSinceLastPromotion', 'YearsWithCurrManager',\n    'NumCompaniesWorked', 'TrainingTimesLastYear','Education', 'EnvironmentSatisfaction',\n       'JobInvolvement', 'JobLevel', 'JobSatisfaction']\n\nj=1\nplt.figure(figsize=(22,15))\nfor i in l2:\n    plt.subplot(6,4,j)\n    sns.histplot(data=df, x=i, palette=dark_tone_r, hue='Attrition')\n    j=j+1\n    plt.tight_layout()\nplt.show()\n","380c48ad":"##### Hue don't support kind='reg'\ncolor=[blue_pair, 'Black']\ng= sns.JointGrid(data=df, x='JobSatisfaction', y=\"PercentSalaryHike\",  hue=\"Attrition\")\ng.plot(sns.scatterplot, sns.histplot);\n","0d126dea":"g= sns.JointGrid(data=df, x='JobSatisfaction', y=\"PerformanceRating\",  hue=\"Attrition\")\ng.plot(sns.scatterplot, sns.histplot);","080ed00e":"g= sns.JointGrid(data=df, x='JobSatisfaction', y=\"WorkLifeBalance\",  hue=\"Attrition\")\ng.plot(sns.scatterplot, sns.histplot);","a7821fc0":"g= sns.JointGrid(data=df, x='JobSatisfaction', y=\"EnvironmentSatisfaction\",  hue=\"Attrition\")\ng.plot(sns.scatterplot, sns.histplot);","063111ee":"g= sns.JointGrid(data=df, x='JobSatisfaction', y=\"DistanceFromHome\",  hue=\"Attrition\")\ng.plot(sns.scatterplot, sns.histplot);","32a253c8":"g= sns.JointGrid(data=df, x='JobSatisfaction', y=\"Age\",  hue=\"Attrition\")\ng.plot(sns.scatterplot, sns.histplot);","923287d1":"sns.jointplot(data=df, x='JobSatisfaction', y=\"Age\",  hue=\"Attrition\", palette= dark_tone)","ab011522":"sns.jointplot(data=df, x='JobSatisfaction', y=\"MonthlyIncome\",  hue=\"Attrition\", palette= dark_tone)","7f4d0fe5":"df.head(2)","4d885390":"def without_hue(plot, feature):\n    total = len(feature)\n    for p in plot.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width() \/ 2 - 0.05\n        y = p.get_y() + p.get_height()\n        ''' y = p.get_x() + p.get_width() \/ 2 - 0.05\n        x = p.get_y() + p.get_height()'''\n        ax.annotate(percentage, (x, y), size = 12)\n    #plt.show()","79a40ab0":"%%time\ncatergorical_features= df.select_dtypes(include='object')\n\n##### Defining a function to calculate percentage ######\ndef with_hue(plot, feature, Number_of_categories, hue_categories):\n    a = [p.get_height() for p in plot.patches]\n    patch = [p for p in plot.patches]\n    for i in range(Number_of_categories):\n        total = feature.value_counts().values[i]\n        for j in range(hue_categories):\n            percentage = '{:.1f}%'.format(100 * a[(j*Number_of_categories + i)]\/total)\n            x = patch[(j*Number_of_categories + i)].get_x() + patch[(j*Number_of_categories + i)].get_width() \/ 2 - 0.15\n            y = patch[(j*Number_of_categories + i)].get_y() + patch[(j*Number_of_categories + i)].get_height() \n            ax.annotate(percentage, (x, y), size = 12)\n    #plt.show()\n\ncatergorical_features2 = catergorical_features.drop('Attrition',axis=1)\nplt.figure(figsize=(22,30))\nj=1\nfor i in catergorical_features2:\n    plt.subplot(5,2,j)\n    ax= sns.countplot(x= df[i], data= df,hue='Attrition', palette='Paired')\n    plt.xticks(rotation=30, fontsize=13)\n    n= df[i].nunique()\n    with_hue(ax,df[i],n,2)\n    \n    j=j+1\nplt.tight_layout()\nplt.show()","8653edc8":"plt.figure(figsize=(22,30))\nplt.suptitle(\" Gender Distribution among different sectors \")\nj=1\nfor i in catergorical_features2.drop('Gender',axis=1):\n    plt.subplot(5,2,j)\n    ax= sns.countplot(x= df[i], data= df,hue='Gender', palette='Paired')\n    plt.xticks(rotation=30, fontsize=13)\n    n= df[i].nunique()\n    with_hue(ax,df[i],n,2)\n    j=j+1\nplt.tight_layout()\nplt.show()","75130f30":"df[df['Education']==2]","54a3fe7e":"### Relationship between Education and Education field\nprint(df.Education.unique(),'Total no of unique values :',df.Education.nunique(), '\\n')\nprint(df.EducationField.unique(),'Total no of unique values :',df.EducationField.nunique(),'\\n')\n\ndf[df['EducationField']=='Other']","6bcf1152":"a=df[df['EducationField']=='Other']\nak= a.groupby('Education')\n# to display all froup we can\nfor edu, edu_df in ak:\n    print(edu)\n    display(edu_df.head(7))","43486ac1":"###### Lets drop unnecessary columns 1st\ndata = df.drop({\"Over18\",'EmployeeCount','EmployeeNumber','StandardHours'}, axis=1)","9b9ff180":"from sklearn.preprocessing import LabelEncoder","3ec07c98":"########################-------- Label Encoding -----------########################\ndata[\"Attrition\"] = LabelEncoder().fit_transform(data['Attrition'])\ndata[\"BusinessTravel\"] = LabelEncoder().fit_transform(data['BusinessTravel'])\ndata[\"Department\"] = LabelEncoder().fit_transform(data['Department'])\ndata[\"EducationField\"] = LabelEncoder().fit_transform(data['EducationField'])\ndata[\"Gender\"] = LabelEncoder().fit_transform(data['Gender'])\ndata[\"JobRole\"] = LabelEncoder().fit_transform(data['JobRole'])\ndata[\"MaritalStatus\"] = LabelEncoder().fit_transform(data['MaritalStatus'])\ndata[\"OverTime\"] = LabelEncoder().fit_transform(data['OverTime'])","d3edcfc1":"data.head()","2d17a5e7":"from imblearn.over_sampling import SMOTE\n# But before normalization I need to split the data\ncols = list(data.columns)\ncols.remove(\"Attrition\")\nsampled,target = SMOTE().fit_resample(data[cols],data[\"Attrition\"])","3c8df809":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(sampled[cols],\n                                                 target,\n                                                 test_size = 0.25,\n                                                 shuffle=True)","7b933cba":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.fit_transform(X_test)","a16e95df":"print(\"Train Feature Size : \",len(X_train))\nprint(\"Train Label Size : \",len(Y_train))\nprint(\"Test Feature Size : \",len(X_test))\nprint(\"Test Label Size : \",len(Y_test))","b5f933da":"'''### Without this pip install flaml wasn't working on my notebook\n!pip install delayed\n!pip install imbalanced-learn''';","68e75524":"'''#Instal\n!pip install flaml\n\n#!pip install flaml[notebook]''';","33071b3a":"'''# import AutoML class from flaml package\nfrom flaml import AutoML\nautoml = AutoML()''';","4d19c2cc":"'''from sklearn.model_selection import train_test_split\nfrom flaml import AutoML \n\n##initialize an AutoML instance\nautoml_clf = AutoML()''';","79322e98":"'''!pip install imbalanced-learn\n!pip install delayed'''","a977ca80":"#from delayed.delay import delayed\nfrom sklearn.svm import SVC\nimport sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix","28a3f0fb":"classifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, Y_train)\n\n# Predicting the test set results\n\ny_pred = classifier.predict(X_test)\n\nprint(\"Train Accuracy : {:.2f} %\".format(accuracy_score(classifier.predict(X_train),Y_train)))\nprint(\"Test Accuracy : {:.2f} %\".format(accuracy_score(classifier.predict(X_test),Y_test)))\n\n# Making the Confusion Matrix \ncm = confusion_matrix(Y_test, y_pred)\n\nclasses = [\"0\",\"1\"]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=classes)\nfig, ax = plt.subplots(figsize=(6,6))\nplt.title(\"Confusion Matrix\")\ndisp = disp.plot(ax=ax, cmap='Blues')\nplt.show()","c0484591":"logistic_model = LogisticRegression(solver='liblinear',random_state=7).fit(X_train,Y_train)\nprint(\"Train Accuracy : {:.2f} %\".format(accuracy_score(logistic_model.predict(X_train),Y_train)))\nprint(\"Test Accuracy : {:.2f} %\".format(accuracy_score(logistic_model.predict(X_test),Y_test)))\n\ncm = confusion_matrix(Y_test,logistic_model.predict(X_test))\nclasses = [\"0\",\"1\"]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=classes)\nfig, ax = plt.subplots(figsize=(6,6))\nplt.title(\"Confusion Matrix\")\ndisp = disp.plot(ax=ax, cmap='Blues')\nplt.show()\nprint(cm)","228d1670":"random_forest = RandomForestClassifier(n_estimators=49, random_state=7).fit(X_train,Y_train)\nprint(\"Train Accuracy : {:.2f} %\".format(accuracy_score(random_forest.predict(X_train),Y_train)))\nprint(\"Test Accuracy : {:.2f} %\".format(accuracy_score(random_forest.predict(X_test),Y_test)))\n\ncm = confusion_matrix(Y_test,random_forest.predict(X_test))\nclasses = [\"0\",\"1\"]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=classes)\nfig, ax = plt.subplots(figsize=(6,6))\nplt.title(\"Confusion Matrix\")\ndisp = disp.plot(ax=ax, cmap='Blues')\nplt.show()","ee3387ad":"from xgboost import XGBClassifier","554127e4":"# fit model no training data\nxgb = XGBClassifier(n_estimators=750, random_state=7).fit(X_train,Y_train)\nprint(\"Train Accuracy : {:.2f} %\".format(accuracy_score(xgb.predict(X_train),Y_train)))\nprint(\"Test Accuracy : {:.2f} %\".format(accuracy_score(xgb.predict(X_test),Y_test)))\n\ncm = confusion_matrix(Y_test,random_forest.predict(X_test))\nclasses = [\"0\",\"1\"]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=classes)\nfig, ax = plt.subplots(figsize=(6,6))\nplt.title(\"Confusion Matrix\")\ndisp = disp.plot(ax=ax, cmap='Blues')\nplt.show()","c833c0bb":"# AutoMl : FLAML (Fast and Lightweight AutoML Library)","eef650be":"### Conclusion\n**Education and EducationField are not related at-all**","f90a1aa5":"## Quick peak at result\n1. [SVM                  , Accuracy on test dataset: 82%](#1)\n1. [Logistic Regression  , Accuracy on test dataset: 82%](#2)\n1. [Random Forest        , Accuracy on test dataset: 99%](#3)\n1. [XGBoost              ,  Accuracy on test dataset: 99%](#4)","617951a8":"### Creating a palette","a51d9558":"# Normalization","3c0f9ce4":"## This is imbalance dataset\nWhy a data set is imbalance?\n> when we look at faliur analysis\/defect analysis\/success rate etc generally it is skewed as a company would produce defected product due to manufacturing error which is quite low like 1-2% or success of apirant in upsc is 20% who appeared in the mains move to the final stage. \n\n1. Person working overtime has high chance of Attrition\n2. Attrition rate in order Single > Married > divorced ( Reasoning may be Single is more willing to take risk and might have more time when compared to married and divorced as he don't have to split time between family and work. Divorced have least Attrition because they want stability in life and switching job and managing family single handed is tough)\n","2b02fe1d":"### Further analysis of Relationship between Education and EducationFiled","d4db24d3":"### There is something **strange** in this dataset, I don't see any correlation between dependent variable which I though would be correlated. Lets investigate further","8fdde272":"\n![Hr attrition.PNG](attachment:6b9ec52b-f2e4-4a35-9eed-e6885a6075b7.PNG)\n\n![Hr attrition 2.PNG](attachment:da63436e-ddc6-4b7f-91e8-902e4897dae2.PNG)\n","6936f69e":"<p style = \"font-size : 20px; color : white ; font-family : 'Bower'; text-align : center; background-color : #053259; border-radius: 5px 5px;\">Prepare a model for the HR department to predict the Attrition and give the insights from the data\nabout the important factors associated with the attrition so that HR can take the corrective or\nprevintive measures to stop or control the attrition.<\/p>\n<p style = \"font-size : 20px; color : white ; font-family : 'Bower'; text-align : left; background-color : #053259; border-radius: 5px 5px;\">What Is Attrition?<br>\nThe term attrition refers to a gradual but deliberate reduction in staff numbers that occurs as employees retire or resign and are not replaced. It is commonly used to describe downsizing in a firm's employee pool by human resources (HR) professionals.<\/p>","9d22a5ba":"# Visualizing the data","4a068a0c":"<a id=3>\n\n# 3. Random Forest","9677a43a":"# 2.2 Catergorical Data Visualisation","7f10de98":"<a id=4>\n\n# 4. XGBoost","5f21d99c":"# Modeling","d894b476":"# Conclusion after EDA of Numerical data \n1. **Drop following ids**\n        1. EmployeeCount > constant i.e. 1\n        2. EmployeeNumber > index +1 \n        3. Over18 > All employee are 18+\n        4. StandardHours > 80hr is constant","eb42621a":"<a id=1>\n\n# 1. SVM ","adbb4264":"<p style = \"font-size : 40px; color : white ; font-family : 'Bower'; text-align : center; background-color : #053259; border-radius: 5px 5px;\"><strong>Employee Attrition Data<\/strong><\/p>","c87ed5ea":"# Feature Engineering","0ae9721a":"<a id=2>\n\n# 2. Logistic Regression","8f06418a":"####  Use group by on Education\n"}}