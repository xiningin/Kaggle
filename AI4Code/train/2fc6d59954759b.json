{"cell_type":{"8093c5a0":"code","c84a4a5c":"code","da2e94a8":"code","546dc2a6":"code","d7664f6d":"code","87d18ca2":"code","15e55c95":"code","70cac4ac":"code","4676db7e":"code","41dcb141":"code","28cc6d75":"code","8bf30646":"code","c65ec955":"code","1b3dc098":"code","996f65ac":"code","7a4c2c81":"code","91a5fe8d":"code","032fa6d4":"code","a0a27a17":"code","8815ff78":"code","ecc0149f":"code","dfb057f9":"markdown","bcb177bb":"markdown","81e4d4b2":"markdown","c75d6c88":"markdown","7eb0297b":"markdown"},"source":{"8093c5a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c84a4a5c":"df_train = pd.read_csv('..\/input\/train_V2.csv', nrows = 100000)\ndf_test = pd.read_csv('..\/input\/test_V2.csv', nrows = 100000)","da2e94a8":"df_train.head()","546dc2a6":"# importing important libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","d7664f6d":"# utility function 1\ndef mean_dev_stuff(df, column_name, limit = 20000):\n    if len(df) > limit:\n        df = df[:limit]\n    \n    data_bar = df[column_name].mean()\n    df[column_name+\"_squaredmean\"] = (df[column_name] - data_bar)**2\n    std_dev = (sum(df[column_name+\"_squaredmean\"])\/len(df))**0.5\n    \n    UCL = np.array([data_bar + 3 * std_dev]*len(df))\n    LCL = np.array([data_bar - 3 * std_dev]*len(df))\n    mean_line = np.array([data_bar]*len(df))\n    \n    new_df = pd.DataFrame({column_name : df[column_name], \"UCL\" : UCL, \"LCL\" : LCL, \"Mean\" : mean_line})\n    return new_df","87d18ca2":"# killing definition function\nkilldf_train = mean_dev_stuff(df_train, 'kills', 20000)\nkilldf_test = mean_dev_stuff(df_test, 'kills', 20000)","15e55c95":"# kills by a player\n\nplt.figure(figsize = (25, 10))\nplt.subplot(2,2,1)\nplt.plot(killdf_train.index ,killdf_train['kills'], color = \"pink\", linewidth = 1, label = \"Kills by players\")\nplt.plot(killdf_train.index, killdf_train['UCL'], color = \"red\", linewidth = 2, linestyle = \"--\", label = \"UCL\" )\nplt.plot( killdf_train.index, killdf_train['Mean']  , color = \"blue\", linewidth = 2, linestyle = \"--\", label = \"Mean\")\n\nplt.title(\"The Kill Records of first 20,000 players in training\", fontsize = 16)\nplt.xlabel(\"Player Index\")\nplt.legend(prop={'size':16})\nplt.tick_params(labelsize=16)\n\nplt.subplot(2,2,2)\nplt.plot(killdf_test.index ,killdf_test['kills'], color = \"orange\", linewidth = 1, label = \"Kills by players\")\nplt.plot(killdf_test.index, killdf_test['UCL'], color = \"red\", linewidth = 2, linestyle = \"--\", label = \"UCL\")\nplt.plot(killdf_test.index, killdf_test['Mean']  , color = \"blue\", linewidth = 2, linestyle = \"--\", label = \"Mean\")\n\nplt.title(\"The Kill Records of first 20,000 players in testing\", fontsize = 16)\nplt.xlabel(\"Player Index\")\nplt.legend(prop={'size':16})\nplt.tick_params(labelsize=16)\n","70cac4ac":"mean_df_train = killdf_train['Mean'].iloc[0]\nmean_df_test = killdf_test['Mean'].iloc[0]\nstd_dev_train = (killdf_train['UCL'].iloc[0] - mean_df_train)\/3\nstd_dev_test = (killdf_test[\"UCL\"].iloc[0] - mean_df_test)\/3\n\nprint(\"Mean in train : {:.5f}, Mean in test : {:.5f}\".format(mean_df_train, mean_df_test))\nprint(\"Standard Deviation in train : {:.5f}, Standard Deviation in test : {:.5f}\".format(std_dev_train, std_dev_test))","4676db7e":"damagedf_train = mean_dev_stuff(df_train, 'damageDealt')\ndamagedf_test = mean_dev_stuff(df_test, 'damageDealt')","41dcb141":"# damage dealt by a player\n\nplt.figure(figsize = (25, 10))\nplt.subplot(2,2,1)\nplt.plot(damagedf_train.index ,damagedf_train['damageDealt'], color = \"pink\", linewidth = 1, label = \"Damage dealt by players\")\nplt.plot(damagedf_train.index, damagedf_train['UCL'], color = \"red\", linewidth = 2, linestyle = \"--\", label = \"UCL\" )\nplt.plot( damagedf_train.index, damagedf_train['Mean']  , color = \"blue\", linewidth = 2, linestyle = \"--\", label = \"Mean\")\n\nplt.title(\"The Damage Dealings of first 20,000 players in training\", fontsize = 16)\nplt.xlabel(\"Player Index\")\nplt.legend(prop={'size':16})\nplt.tick_params(labelsize=16)\n\nplt.subplot(2,2,2)\nplt.plot(damagedf_test.index ,damagedf_test['damageDealt'], color = \"orange\", linewidth = 1, label = \"Damage dealt by players\")\nplt.plot(damagedf_test.index, damagedf_test['UCL'], color = \"red\", linewidth = 2, linestyle = \"--\", label = \"UCL\")\nplt.plot(damagedf_test.index, damagedf_test['Mean']  , color = \"blue\", linewidth = 2, linestyle = \"--\", label = \"Mean\")\n\nplt.title(\"The Damage Dealings of first 20,000 players in testing\", fontsize = 16)\nplt.xlabel(\"Player Index\")\nplt.legend(prop={'size':16})\nplt.tick_params(labelsize=16)\n","28cc6d75":"mean_df_train = damagedf_train['Mean'].iloc[0]\nmean_df_test = damagedf_test['Mean'].iloc[0]\nstd_dev_train = (damagedf_train['UCL'].iloc[0] - mean_df_train)\/3\nstd_dev_test = (damagedf_test[\"UCL\"].iloc[0] - mean_df_test)\/3\n\nprint(\"Mean in train : {:.5f}, Mean in test : {:.5f}\".format(mean_df_train, mean_df_test))\nprint(\"Standard Deviation in train : {:.5f}, Standard Deviation in test : {:.5f}\".format(std_dev_train, std_dev_test))","8bf30646":"# utility for encoding","c65ec955":"df_train[(df_train['damageDealt'] > 0) & (df_train['kills'] <= df_train['DBNOs'])][['damageDealt', 'kills', 'DBNOs']].head(20)","1b3dc098":"print(\"MIN : {}, MAX : {}, MEAN : {}\".format(min(df_train['matchDuration']), max(df_train['matchDuration']), df_train['matchDuration'].mean()))","996f65ac":"study_df = pd.read_csv('..\/input\/train_V2.csv', nrows = 1000000)","7a4c2c81":"study_df.info()","91a5fe8d":"Top10 = study_df[study_df['matchDuration'] >= 0.9]","032fa6d4":"Top10.head()","a0a27a17":"Top10.columns[3:]","8815ff78":"x = ['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills', 'heals',\n       'killPlace', 'killPoints', 'kills', 'killStreaks', 'longestKill',\n       'matchDuration', 'maxPlace', 'numGroups', 'rankPoints',\n       'revives', 'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints',\n       'winPlacePerc']","ecc0149f":"Top10.groupby(['matchType'], axis = 0)[x].mean()","dfb057f9":"# Data Check One : The amount of kills\n\nLet's have a look at the killing statistics of our players and see of it needs some tweaking or not!","bcb177bb":"# Utility Function 1\n\nThis will give me a ready to plot dataframe which will be contataining **Mean Line** , **Upper Control Limit** and **Lower Control Limit**.\n\n### Before we move on, what are upper and lower control limits?\n\n**The control limits of your control chart represent your process variation and help indicate when your process is out of control.**\nControl limits are the horizontal lines above and below the center line that are used to judge whether a process is out of control. The upper and lower control limits are based on the random variation in the process. By default, our control limits are displayed 3 standard deviations above and below the center line.\n\n### One may arguably ask, isn't control limits strictly for time based data?\n\nWell, lets just assume here that our index are strictly in an increasing period of time. That may or not be the best assumption yet, but let's keep moving for now","81e4d4b2":"This doesn't look like a huge deal to worry about either. Let's do something more interesting.","c75d6c88":"After having a look at the datasets right here, I don't think that this particular data has much difference in quality, so lets move to the next area of concern.\n\n# Data check two : The amount of damage dealt by a player","7eb0297b":"# Why this analysis?\n\nBefore going on to the statistical modelling part of the problem, one must make sure that the data he is going to train his model on the data which must be somewhat similar to the test data. Not only is this a good practice for production, but also of course, for this particular competition"}}