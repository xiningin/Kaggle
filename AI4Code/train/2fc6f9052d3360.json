{"cell_type":{"8b462486":"code","68552878":"code","108e329c":"code","a32d6470":"code","9dd965d9":"code","4fc196ca":"code","1e404e54":"code","9cb7784d":"code","301a2262":"code","3c18615e":"code","d1a6d022":"code","09776427":"code","6489566b":"code","a17d1980":"code","57eb9294":"code","a01f3f53":"code","23a35dd3":"code","68f02abe":"code","b42065be":"code","5456f062":"code","6ee3922e":"code","870d9164":"code","1eec6949":"code","1a26f2e6":"code","95545c6d":"code","8bad882f":"code","04881f62":"code","196f6716":"code","8ec28342":"code","8132dfe8":"code","5ecdda48":"code","85928e61":"code","bfea0ad1":"code","d4b916f9":"code","1f9b9147":"code","53189328":"code","fbadc907":"code","15241be6":"markdown","28206ca6":"markdown","8130c9ec":"markdown","0acfe408":"markdown","d9550e69":"markdown","0145eef5":"markdown","f52b8987":"markdown","c77e509f":"markdown","f21e446d":"markdown","3775a1af":"markdown"},"source":{"8b462486":"# from google.colab import drive\n# drive.mount('\/content\/drive')","68552878":"# on kaggle\nimport numpy as np #\nimport pandas as pd #\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        filepath = (os.path.join(dirname, filename))","108e329c":"# #on local \n# filepath = '..\/drivedata\/coursea_data.csv'","a32d6470":"# # on Google drive\n# filepath = \"\/content\/drive\/My Drive\/Colab Notebooks\/coursera\/data\/coursea_data.csv\"","9dd965d9":"df = pd.read_csv(filepath, index_col=0)","4fc196ca":"from collections import defaultdict\ndct_convert_unit = defaultdict(lambda:0)\ndct_convert_unit['k']  = 1000\ndct_convert_unit['m']  = 1000*1000\n\ndf['course_students_enrolled_unit'] = df['course_students_enrolled'].str[-1].apply(lambda x : dct_convert_unit[x])\ndf['course_students_enrolled'] = df['course_students_enrolled'].str[:-1].astype(float)\ndf['course_students_enrolled'] = df['course_students_enrolled'] * df['course_students_enrolled_unit'] \ndel df['course_students_enrolled_unit'] ","1e404e54":"ls_course_Certificate_type = ['COURSE','SPECIALIZATION' ,'PROFESSIONAL CERTIFICATE']\nls_course_difficulty = [ 'Beginner', 'Intermediate', 'Advanced','Mixed']","9cb7784d":"df.shape[0]","301a2262":"for _col  in df.columns:\n    if df[_col].dtype == 'object':  \n        display(pd.DataFrame(df[_col].value_counts()))","3c18615e":"for _col  in df.columns:\n    if df[_col].dtype == 'object':  \n        display(pd.DataFrame(df[_col].value_counts(normalize=True)*100).cumsum())","d1a6d022":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","09776427":"df.sort_values(by=\"course_students_enrolled\",ascending=True)","6489566b":"for _col  in ['course_Certificate_type','course_difficulty']:   \n    fig, ax = plt.subplots(figsize=(8,6), facecolor='w')\n    sns.countplot(x=_col, data=df, ax= ax, order = df[_col].value_counts().index, alpha=0.7)","a17d1980":"fig, ax = plt.subplots(figsize=(8,6), facecolor='w')\n# sns.countplot(x='course_Certificate_typea', hue ='course_difficulty', order = ls_course_Certificate_type,hue_order=ls_course_difficulty,  data=df, ax= ax, alpha=0.7)\n# ax.legend(loc='upper right')\ndf_pivot_cert_difficult = df[['course_Certificate_type', 'course_difficulty']].pivot_table(\n        index='course_difficulty', columns='course_Certificate_type',\n        aggfunc=len, fill_value=0)\ndf_pivot_cert_difficult = df_pivot_cert_difficult.loc[ls_course_difficulty,  ls_course_Certificate_type]\nsns.heatmap(df_pivot_cert_difficult, annot=True, fmt=\"1.1f\",cmap=\"Reds\")\n","57eb9294":"fig, ax = plt.subplots(figsize=(8,6), facecolor='w')\nsns.countplot(x='course_rating', data=df, ax= ax,hue = 'course_difficulty', order = sorted(list(set(df.course_rating))), hue_order=ls_course_difficulty, alpha=0.7)\nax.legend()\ndf_rating_dist =  df[['course_rating', 'course_difficulty']] \\\n    .pivot_table(\n        columns='course_difficulty', index='course_rating',\n        aggfunc=len, fill_value=0)\n\ndisplay(df_rating_dist.T)\n\n\ndf_rating_dist = 100*df_rating_dist\/df_rating_dist.sum()\nfig, ax = plt.subplots(figsize=(8,6), facecolor='w')\nls_xticklabel = list(df_rating_dist.index)\nfor i , _col in enumerate(ls_course_difficulty):\n    ax.bar(\n        list(map(lambda x: (0.2)*i+x, range(len((ls_xticklabel))))), \n        height=df_rating_dist[_col].values,\n        label=_col,\n        alpha=0.6, width=0.2)\nax.set_xticks(range(len((ls_xticklabel))))\nax.set_xticklabels(ls_xticklabel)\nplt.xlabel('coruse_rating')\nplt.ylabel('coruse_rating')\nax.legend()\n\ndf_rating_dist =  df[['course_rating', 'course_difficulty']] \\\n  .groupby('course_difficulty')['course_rating'].agg([\"mean\",\"std\"])\ndisplay(df_rating_dist)","a01f3f53":"fig, ax = plt.subplots(figsize=(8,6), facecolor='w')\nsns.countplot(x='course_rating', data=df, ax= ax,hue = 'course_Certificate_type', order = sorted(list(set(df.course_rating))), hue_order=ls_course_Certificate_type, alpha=0.7)\nax.legend()\ndf_rating_dist =  df[['course_rating', 'course_Certificate_type']] \\\n    .pivot_table(\n        columns='course_Certificate_type', index='course_rating',\n        aggfunc=len, fill_value=0)\n\ndisplay(df_rating_dist.T)\n\n\ndf_rating_dist = 100*df_rating_dist\/df_rating_dist.sum()\nfig, ax = plt.subplots(figsize=(8,6), facecolor='w')\nls_xticklabel = list(df_rating_dist.index)\nfor i , _col in enumerate(ls_course_Certificate_type):\n    ax.bar(\n        list(map(lambda x: (0.2)*i+x, range(len((ls_xticklabel))))), \n        height=df_rating_dist[_col].values,\n        label=_col,\n        alpha=0.6, width=0.2)\nax.set_xticks(range(len((ls_xticklabel))))\nax.set_xticklabels(ls_xticklabel)\nplt.xlabel('coruse_rating')\nplt.ylabel('count[%]')\nax.legend()\n\ndf_rating_dist =  df[['course_rating', 'course_Certificate_type']] \\\n  .groupby('course_Certificate_type')['course_rating'].agg([\"mean\",\"std\"])\ndisplay(df_rating_dist)\n","23a35dd3":"fig, ax = plt.subplots(figsize=(8,6), facecolor='w')\n_cert_type = 'PROFESSIONAL CERTIFICATE'\nsns.distplot(df.loc[:, \"course_students_enrolled\"],ax=ax, label = _cert_type)","68f02abe":"_cert_type","b42065be":"df_large = df[df.course_students_enrolled > 500000] \\\n  .sort_values(by=\"course_students_enrolled\", ascending =False)\nprint(df_large.shape[0])\ndisplay(df_large)","5456f062":"df_small = df[df.course_students_enrolled < 10000]\nprint(df_small.shape[0])\ndisplay(df_small)","6ee3922e":"import copy\n\ndf['log_course_students_enrolled'] = np.log10(df.course_students_enrolled)","870d9164":"display(pd.DataFrame(df.groupby('course_Certificate_type')['log_course_students_enrolled'].agg(['mean','std','count','min','max'])))\ndisplay(df.loc[df.course_Certificate_type == \"PROFESSIONAL CERTIFICATE\", [\"course_title\",\"course_organization\",\"course_students_enrolled\"]])\nfig, ax = plt.subplots(figsize=(8,6), facecolor='w')\nfor _cert_type in ls_course_Certificate_type:\n  sns.kdeplot(df.loc[df.course_Certificate_type == _cert_type, \"log_course_students_enrolled\"],ax=ax, label = _cert_type)\n# plt.xlim(-10000,500000)\nplt.xlabel('log course_students_enrolled')\nplt.ylabel('p')\n\n","1eec6949":"display(pd.DataFrame(df.groupby('course_difficulty')['course_students_enrolled'].agg(['mean','std','count','min','max'])))\nfig, ax = plt.subplots(figsize=(8,6), facecolor='w')\nfor _diff in ['Beginner', 'Intermediate', 'Mixed', 'Advanced']:\n  sns.kdeplot(df.loc[df.course_difficulty == _diff, \"course_students_enrolled\"],ax=ax, label = _diff)\n# plt.xlim(-10000,500000)\nplt.legend()\nplt.xlabel('course_students_enrolled')\nplt.ylabel('p')","1a26f2e6":"_col =\"course_organization\"\nfig, ax = plt.subplots(figsize=(8,6), facecolor='w')\nsns.countplot(x=_col, data=df, order=df[_col].value_counts().index, ax= ax, alpha=0.7)\ndf_org = pd.DataFrame(df[_col].value_counts())\nmean_part = df_org.mean().values[0]\nprint(\"mean: {0}\".format(mean_part))\nax.hlines(y=mean_part, xmin=0, xmax=ax.get_xlim()[1], color='r')\nax.set(xlim=(0,70))\nplt.xticks(rotation= 90)","95545c6d":"df_org = df_org.reset_index()\ndf_org.columns = ['course_organization', 'n_held']\ndf_org['course_organization_type'] = 'low_held'\ndf_org.loc[df_org['n_held']>mean_part,'course_organization_type']  = 'high_held'","8bad882f":"df_with_held = pd.merge(df  , df_org, on='course_organization', how='left')\nsns.pairplot(df_with_held,hue='course_organization_type',palette=\"husl\")","04881f62":"print(\"course_students_enrolled\")\ndf_with_held.groupby(['course_organization_type'])['course_students_enrolled'].agg(['mean','count','min','max'])","196f6716":"!pip install gensim\n!pip install -q wordcloud\n!pip install pycld2\nimport wordcloud\nimport nltk\nimport gensim\nfrom gensim import corpora\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger') \nimport unicodedata\nimport re\nimport string\nimport pycld2 as cld2","8ec28342":"\"\"\"\nSet up NLP\n\"\"\"\n\n# Constants\n# POS (Parts Of Speech) for: nouns, adjectives, verbs and adverbs\nDI_POS_TYPES = {'NN':'n', 'JJ':'a', 'VB':'v', 'RB':'r'} \nPOS_TYPES = list(DI_POS_TYPES.keys())\n\n# Constraints on tokens\nMIN_STR_LEN = 3\nRE_VALID = '[a-zA-Z]'\n\n# Get stopwords, stemmer and lemmatizer\nstopwords = nltk.corpus.stopwords.words('english')\nstemmer = nltk.stem.PorterStemmer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\n# Remove accents function\n# (Normalization Form Compatibility Decomposition)\ndef remove_accents(data):\n    return ''.join(x for x in unicodedata.normalize('NFKD', data) if x in string.ascii_letters or x == \" \")\n\ndef tokenize(sentence):\n    # Tokenize by sentense:\n    tokens = [word.lower() for sent in nltk.sent_tokenize(sentence) for word in nltk.word_tokenize(sent)]\n    ls_tokenized = []\n    for token in tokens:\n\n        # Remove accents\n        t = remove_accents(token)\n\n        # Remove punctuation\n        t = str(t).translate(string.punctuation)\n\n        #remove stop word\n        if t in stopwords:\n            continue\n\n        # remove signal etc...\n        if not re.search(RE_VALID, t):\n            continue\n\n        # #remove too short\n        # if len(t) < MIN_STR_LEN:\n        #   continue\n\n        #stem and lemma\n        # t = stemmer.stem(t)\n        # t = lemmatizer.lemmatize(t)#, pos=DI_POS_TYPES[])\n\n        ls_tokenized.append(t)\n    return ls_tokenized","8132dfe8":"# Detect monther language of title\ndf['course_title_lang'] = [cld2.detect(_title)[2][0][1]  for _title in df.course_title.values]","5ecdda48":"print(\"course_students_enrolled\")\ndf.groupby(['course_title_lang'])['course_students_enrolled'].agg(['mean','count','min','max']).sort_values(by='count')","85928e61":"df_en = df[df.course_title_lang=='en']\ndct_title = {i :tokenize(_token) for i, _token in enumerate(df_en.course_title.values)}\ndf_words = pd.DataFrame(nltk.FreqDist([flatten for inner in dct_title.values() for flatten in inner]),index=['count']).T.sort_values(by='count',ascending=False)","bfea0ad1":"fig, ax = plt.subplots(figsize=(20,6), facecolor='w')\ndf_words[df_words['count']>20].plot.bar(ax=ax)\nplt.xticks(rotation =75,fontsize=16)\nplt.xlabel('top appear words')\nplt.ylabel('count')\nprint(df_words.shape[0])","d4b916f9":"ls_top_words = list(df_words[df_words['count']>20].index)","1f9b9147":"df_top_words=pd.DataFrame(\n    {i :len(list(set(ls_top_words) & set(ls_words) )) for i , ls_words in enumerate(dct_title.values())},\n    index=['top_w_count']).T","53189328":"df_with_top_words = pd.concat([df_en.reset_index(drop=True),df_top_words],axis=1)","fbadc907":"_col = 'top_w_count'\nfig, ax = plt.subplots(figsize=(20,6), facecolor='w')\ndf_plot = df_with_top_words.groupby([_col])['course_students_enrolled'].agg(['mean']).reset_index()\nsns.regplot(data=df_plot, x='top_w_count', y='mean',ax=ax,scatter_kws={\"s\": 80, \"color\":\"r\"}, robust=True, ci=None)\nplt.xticks(rotation =0,fontsize=16)\nplt.xlim(-0.5,6.5)\nplt.xlabel('#top_word in title')\nplt.ylabel('mean #course_students_enrolled')","15241be6":"## Check categorical features\n","28206ca6":"## Items\n- course_title : Contains the course title.\n- course_organization : It tells which organization is conducting the courses.\n- courseCertificatetype : It has details about what are the different certifications available in courses.\n- course_rating : It has the ratings associated with each course.\n- course_difficulty : It tells about how difficult or what is the level of the course.\n- coursestudentsenrolled : It has the number of students that are enrolled in the course.","8130c9ec":"### Rating distribute","0acfe408":"### course_title\n- titles in these course has many languages.\n  - EN, RU, and so on\n  - => we detect langeage of title and normarize it\n  - Language detection using \"cld2\" is not correct completely. (Off course, theis package is amazing and very usefull!)\n    - -> I pick up ONLY english and analyze. \n- As following graph, these words are most frequent words in title,\n  - I deem that these words has some class, for instance programming, biz and so on ..., if you have time to analyze more, could you try LDA?\n  - Finally, I pick up words which appear more than 20title, I define these words as \"top words\",  then how many top words does title include? and how does #top words effect #user?\n    - Uhh... top words have power to attract user. ","d9550e69":"### certification type and difficulty\n- Course > Sepcial >> Pro\n  - Ex. \n      - Course : *Marchine Learning*\n      - SP : *Deep Learning*\n      - Pro : *IBM Data Science* \n  - <u>Maybe related to difficulty?<\/u>\n- Certification type and difficulty are linked?\n  - Heat map:\n    - Heat map prove below.","0145eef5":"### course_students_enrolled\n- course_students_enrolled distribution is long tail\n  - convet log scale\n- Break down analysis same as below\n  - couse = SP < Pro\n    - #Pro is few.\u3000But Many pro course have many students when looking each data      \n  - #student is not different between type of difficulty\n  - But  I want to know \"MIX\", what is meaning of MIX?","f52b8987":"## Check roughly","c77e509f":"### course_organization\n- course_organization distribution  has long tail\n- Focus in # of held \n  - Classify 2 class ... high vs low\n    - high held orgnizer got more users than lower class","f21e446d":"# My 6hour(3day*2h) challenge : TIme out  ","3775a1af":"- course_difficulty\n  - Just by looking, difficulty related to rating. \n    - Ex. this course is soooo difficult! I hate this course... orz \n  - But mean and std in each difficulty are almost same.\n    - it mean organizer set up course content cocommensurate with difficulty in many course\n    - 0.1 of distance is large different???\n- course_Certficate\n  - Same as below\n    - But a #Pro is very few. I cannot affirm this analysis\n"}}