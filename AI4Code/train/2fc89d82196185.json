{"cell_type":{"c6649b32":"code","0af74e91":"code","d90ccd3f":"code","b4751b54":"code","599ec2cf":"code","f8df33d6":"code","af06b8ec":"code","8e72d5ac":"code","fb94ed9f":"code","6746fd21":"code","af2e0e96":"code","bb6dbaaf":"code","4ab58256":"code","69c5322c":"code","cff230f5":"code","41d6ce6e":"markdown","c7bbb967":"markdown","308bdb41":"markdown","cb02ca2c":"markdown","0bebd6e7":"markdown","534d6408":"markdown","6ecd1f57":"markdown","4e639ccc":"markdown","702ab1ae":"markdown"},"source":{"c6649b32":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score, auc\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.metrics import recall_score, precision_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","0af74e91":"!wget https:\/\/raw.githubusercontent.com\/alexeygrigorev\/mlbookcamp-code\/master\/chapter-06-trees\/CreditScoring.csv","d90ccd3f":"df = pd.read_csv('CreditScoring.csv')\ndf.columns = df.columns.str.lower()","b4751b54":"status_values = {\n    1: 'ok',\n    2: 'default',\n    0: 'unk'\n}\n\ndf.status = df.status.map(status_values)\n\n\nhome_values = {\n    1: 'rent',\n    2: 'owner',\n    3: 'private',\n    4: 'ignore',\n    5: 'parents',\n    6: 'other',\n    0: 'unk'\n}\n\ndf.home = df.home.map(home_values)\n\nmarital_values = {\n    1: 'single',\n    2: 'married',\n    3: 'widow',\n    4: 'separated',\n    5: 'divorced',\n    0: 'unk'\n}\n\ndf.marital = df.marital.map(marital_values)\n\nrecords_values = {\n    1: 'no',\n    2: 'yes',\n    0: 'unk'\n}\n\ndf.records = df.records.map(records_values)\n\njob_values = {\n    1: 'fixed',\n    2: 'partime',\n    3: 'freelance',\n    4: 'others',\n    0: 'unk'\n}\n\ndf.job = df.job.map(job_values)","599ec2cf":"for c in ['income', 'assets', 'debt']:\n    df[c] = df[c].replace(to_replace=99999999, value=0)\ndf = df[df.status != 'unk'].reset_index(drop=True)\ndf['default'] = (df.status == 'default').astype(int)\ndel df['status']","f8df33d6":"categorical = [col for col in df.columns if df[col].dtypes == 'object']\nnumerical = [col for col in df.columns if col not in categorical]\nprint(\"Numerical Columns: \", numerical)\nprint(\"Categorical Columns: \", categorical)","af06b8ec":"from sklearn.model_selection import train_test_split\ndf_full_train, df_test = train_test_split(df, test_size = 0.2, random_state = 1)\ndf_train, df_valid = train_test_split(df_full_train, test_size = 0.25, random_state = 1)","8e72d5ac":"len(df_train) \/ len(df)","fb94ed9f":"for col in numerical:\n    auc_score = roc_auc_score(df_train.default, df_train[col])\n    if auc_score < 0.5:\n        auc_score = roc_auc_score(df_train.default, -df_train[col])\n    print(f'{col: <10}: {auc_score: .4f}')   ","6746fd21":"features = ['seniority', 'income', 'assets', 'records', 'job', 'home']\n\n\"\"\"one-hot encoding datasets\"\"\"\ndv = DictVectorizer()\ntrain_dict = df_train[features].to_dict(orient = 'records')\nval_dict = df_valid[features].to_dict(orient = 'records')\n\n\"\"\"Creating X_train, y_train, \"\"\"\nX_train = dv.fit_transform(train_dict)\nX_val = dv.transform(val_dict)\ny_train = df_train['default'].values\ny_valid = df_valid['default'].values\n\n\"\"\"Fitting the Model on Training Set\"\"\"\nmodel = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\nmodel.fit(X_train, y_train)\npredictions = model.predict_proba(X_val)[:, 1]\n\n\"\"\"AUC for this model\"\"\"\nauc_score = roc_auc_score(y_valid, predictions)\nprint(\"Answer 2: AUC of the model %s\" %round(auc_score, 3))","af2e0e96":"# function to get Precision and Recall scores for a given range of thresholds\n\ndef precision_recall_dataframe(y_val, y_pred, thresholds):\n    scores = []\n\n    for t in thresholds:\n        actual_positive = (y_val == 1)\n        actual_negative = (y_val == 0)\n\n        predict_positive = (y_pred >= t)\n        predict_negative = (y_pred < t)\n\n        tp = (predict_positive & actual_positive).sum()\n        tn = (predict_negative & actual_negative).sum()\n\n        fp = (predict_positive & actual_negative).sum()\n        fn = (predict_negative & actual_positive).sum()\n\n        scores.append((t, tp, fp, fn, tn))\n\n    columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n    df_scores = pd.DataFrame(scores, columns=columns)\n\n    df_scores['precision'] = df_scores.tp \/ (df_scores.tp + df_scores.fp)  \n    df_scores['recall'] = df_scores.tp \/ (df_scores.tp + df_scores.fn) \n        \n        \n    df_scores['tpr'] = df_scores.tp \/ (df_scores.tp + df_scores.fn)\n    df_scores['fpr'] = df_scores.fp \/ (df_scores.fp + df_scores.tn)\n    return df_scores[['threshold','precision', 'recall']]\n\n\"\"\"Calculating Precision and Recall for various thresholds\"\"\"\nth = np.arange(0, 1.01, 0.01)\ndf_scores = precision_recall_dataframe(y_valid, predictions, th)\n\n\"\"\"Plotting the data\"\"\"\nplt.plot(df_scores[['precision', 'recall']])\nplt.xlabel('Threshold')\nplt.title('Precision-Recall curves')\nplt.grid()\n","bb6dbaaf":"df_scores['f1'] = 2 * (df_scores.precision * df_scores.recall)\/(df_scores.precision + df_scores.recall)\ndf_scores[df_scores['f1'] == max(df_scores['f1'])]","4ab58256":"from sklearn.model_selection import KFold\n\nscores = []\n\n\"\"\"Using KFold from sklearn\"\"\"\nkfold = KFold(n_splits=5, shuffle=True, random_state=1)\n\n\"\"\"Iterate over different folds of full_train\"\"\"\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(df_full_train)):\n        \n        \"\"\"Split the data into train and validation\"\"\"\n        df_train = df_full_train.iloc[train_idx]\n        df_valid = df_full_train.iloc[val_idx]\n\n        y_train = df_train.default.values\n        y_valid = df_valid.default.values\n        \n        \"\"\"Apply one-hot-encoding using DictVectorizer\"\"\"\n        train_dict = df_train[features].to_dict(orient='records')\n        val_dict = df_valid[features].to_dict(orient='records')\n        \n        dv = DictVectorizer(sparse=False)\n\n        X_train = dv.fit_transform(train_dict)\n        X_val = dv.transform(val_dict)\n        \n        # Train Logistic regression on train part\n        model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n        model.fit(X_train, y_train)\n\n        # Use AUC to evaluate the model on validation part\n        y_pred = model.predict_proba(X_val)[:, 1]\n        auc = roc_auc_score(y_valid, y_pred)\n        \n        # save fold score\n        scores.append(auc)\n\n        print('fold %s roc-auc score: %s' %(fold, auc))\n\nprint(\"\\n Standard Deviation of Scores: %s\" %np.std(scores).round(3))        ","69c5322c":"scores = list()\n\"\"\"C Values\"\"\"\nC_values = [0.01, 0.1, 1, 10]\n\nkfold = KFold(n_splits=5, shuffle=True, random_state = 1)\n\n\"\"\"Iterate over the C values\"\"\"\nfor C in C_values:\n    kfold_scores = list()\n    \"\"\"Iterate over different folds of df_full_train\"\"\"\n    for train_idx, val_idx in kfold.split(df_full_train):\n            \n            df_train = df_full_train.iloc[train_idx, :]\n            df_val = df_full_train.iloc[val_idx, :]\n\n            y_train = df_train.default.values\n            y_val = df_val.default.values\n\n            train_dict = df_train[features].to_dict(orient='records')\n            val_dict = df_val[features].to_dict(orient='records')\n        \n            dv = DictVectorizer(sparse=False)\n        \n            X_train = dv.fit_transform(train_dict)\n            X_val = dv.transform(val_dict)\n\n            model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n            model.fit(X_train, y_train)\n\n            y_pred = model.predict_proba(X_val)[:, 1]\n            auc = roc_auc_score(y_val, y_pred)\n            \n            kfold_scores.append(auc)\n    \n    \"\"\"compute the mean and std of scores\"\"\"\n    mean_auc = np.mean(kfold_scores)\n    std = np.std(kfold_scores)\n    \n    \"\"\"save mean auc and std of current C value\"\"\"\n    kfold_scores.extend([mean_auc, std])\n    scores.append(kfold_scores)\n    \n    print(f'C={C:<5} average roc-auc: {mean_auc:.4f} +\/- {std:.3f}')","cff230f5":"df_AUC = pd.DataFrame(scores, columns = ['fold_1', 'fold_2', 'fold_3', 'fold_4', \n                                        'fold_5', 'mean_auc', 'std'], \n            index=[str(c) for c in C_values]).rename_axis('C')\n\ndf_AUC[df_AUC['mean_auc'] == max(df_AUC['mean_auc'])].reset_index()","41d6ce6e":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 5\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:<\/li>\n<ul>\n<li>KFold(n_splits=5, shuffle=True, random_state=1)<\/li>\n<li>Iterate over different folds of df_full_train<\/li>\n<li>Split the data into train and validation<\/li>\n<li>Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)<\/li>\n<li>Use AUC to evaluate the model on validation<\/li>\n<\/ul>\n<\/ul> \n<\/div>","c7bbb967":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 6\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Now let's use 5-Fold cross-validation to find the best parameter C<\/li>\n<ul>\n<li>Iterate over the following C values: [0.01, 0.1, 1, 10]<\/li>\n<li>Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)<\/li>\n<li>Compute the mean score as well as the std<\/li>\n<\/ul>\n<\/ul> \n<\/div>","308bdb41":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 3\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Now let's compute precision and recall for our model.<\/li>\n<ul>\n<li>Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01<\/li>\n<li>For each threshold, compute precision and recall<\/li>\n<li>Plot them<\/li>\n<\/ul>\n<\/ul> \n<\/div>","cb02ca2c":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Training the model. From now on, use these columns only: ['seniority', 'income', 'assets', 'records', 'job', 'home']\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:<\/li>\n<li>LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)<\/li>\n\n<\/ul> \n<\/div>","0bebd6e7":"<div style=\"background:#2b6684; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 4\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both.<\/li>\n<ul>\n<li>This is the formula for computing F1:<\/li>\n<li>$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$<\/li>\n<li>Where $P$ is precision and $R$ is recall.<\/li>\n<li>Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01<\/li>\n<\/ul>\n<\/ul> \n<\/div>","534d6408":"\n\n\n\n\n<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Your code\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n    <li>What are the categorical variables? What are the numerical?<\/li>    \n<\/ul> \n<\/div>\n\n","6ecd1f57":"<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Question 1:\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>ROC AUC could also be used to evaluate feature importance of numerical variables. Let's do that<\/li>\n<ul>\n<li>For each numerical variable, use it as score and compute AUC with the \"default\" variable<\/li> \n<li> Use the training dataset for that<\/li> \n    \n   \n<\/ul> \n<li>If your AUC is greater than 0.5, invert this variable by putting \"-\" in front<\/li>   \n<li>(e.g. -df_train['expenses'])<\/li> \n<li>AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.If your AUC is greater than 0.5, invert this variable by putting \"-\" in front<\/li>      \n<\/ul> \n<\/div>","4e639ccc":"<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>Homework 4<\/u>    \n<p style=\"font-family:cursive;font-size:17px; color:white\" > \n<a style=\"font-family:cursive;font-size:17px; color: yellow\" href=\"https:\/\/datatalks.club\/courses\/2021-winter-ml-zoomcamp.html\" target=\"_blank\"> <u>Link for the Course<\/u><\/a><\/p>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1\">A. Preapartion for assignment<\/a><\/li>    \n<ul>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.1\">Importing Data<\/a><\/li>   \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.2\">2. Code to de-code encoded numbers<\/a><\/li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.3\">3. Prepare the numerical variables <\/a><\/li>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.4\"> 4. Remove clients with unknown default status  <\/a><\/li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1.5\"> 5. Create the target variable  <\/a><\/li>  \n    <\/ul>\n\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#2\"> B.  Questions<\/a><\/li>    \n<\/div>    ","702ab1ae":"\n<div style=\"background:#2b6684;color:white; font-family:cursive;padding:0.5em;border-radius:0.2em;font-size:20px;color:yellow\">Task\n<ul style=\"font-family:cursive;font-size:15px;color:  white\">\n<li>Split the data into 3 parts: train\/validation\/test with 60%\/20%\/20% distribution. Use train_test_split funciton for that with random_state=1<\/li>\n \n<\/ul> \n<\/div>\n"}}