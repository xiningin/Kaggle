{"cell_type":{"1d8dfa7c":"code","f0891bba":"code","80d0bb9c":"code","7603deec":"code","4357fc94":"code","2dedeb5b":"code","53bf1af2":"code","aaa54a58":"code","0d2fbe33":"code","608299fb":"code","0c4e2aa9":"code","47beb0cb":"code","4a3382a1":"code","152d3672":"code","fd43ba18":"code","a1831013":"code","ed300cf6":"code","b5524d7a":"code","fdc5175e":"code","cd4e173d":"code","df3cf324":"code","f8c7481a":"code","89f6d0ec":"code","270a4e01":"code","04a2c710":"code","bf33d69c":"code","894e1465":"code","eceec590":"code","8a06e842":"code","3d5d1fad":"code","0ef01a4e":"code","325f2749":"code","b2f10c42":"code","e7fc4427":"code","60e6c897":"markdown","be01a0f3":"markdown","6fa4ba88":"markdown","1eca5c2e":"markdown","5760eb8a":"markdown","680600b7":"markdown","25736cf3":"markdown"},"source":{"1d8dfa7c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0891bba":"generation1 = pd.read_csv(os.path.join(dirname, filenames[-1]))\nweather1 = pd.read_csv(os.path.join(dirname, filenames[-2]))\ngeneration1['DATE_TIME'] = pd.to_datetime(generation1['DATE_TIME'], dayfirst=True)\nweather1['DATE_TIME'] = pd.to_datetime(weather1['DATE_TIME'], dayfirst=True)\n","80d0bb9c":"generation1","7603deec":"inverters = list(generation1['SOURCE_KEY'].unique())\nprint(f\"total number of inverters {len(inverters)}\")\n","4357fc94":"inverters[0]","2dedeb5b":"inv_1 = generation1[generation1['SOURCE_KEY']==inverters[0]]\nmask = ((weather1['DATE_TIME'] >= min(inv_1[\"DATE_TIME\"])) & (weather1['DATE_TIME'] <= max(inv_1[\"DATE_TIME\"])))\nweather_filtered = weather1.loc[mask]","53bf1af2":"weather_filtered.shape","aaa54a58":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=inv_1[\"DATE_TIME\"], y=inv_1[\"AC_POWER\"],\n                    mode='lines',\n                    name='AC Power'))\n\nfig.add_trace(go.Scatter(x=weather_filtered[\"DATE_TIME\"], y=weather_filtered[\"IRRADIATION\"],\n                    mode='lines',\n                    name='Irradiation', \n                    yaxis='y2'))\n\nfig.update_layout(title_text=\"Irradiation vs AC POWER\",\n                  yaxis1=dict(title=\"AC Power in kW\",\n                              side='left'),\n                  yaxis2=dict(title=\"Irradiation index\",\n                              side='right',\n                              anchor=\"x\",\n                              overlaying=\"y\"\n                             ))\n\nfig.show()","0d2fbe33":"df = inv_1.merge(weather_filtered, on=\"DATE_TIME\", how='left')\ndf = df[['DATE_TIME', 'AC_POWER', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']]\ndf","608299fb":"from sklearn.ensemble import IsolationForest","0c4e2aa9":"train_prp = .6\ntrain = df.loc[:df.shape[0]*train_prp]\ntest = df.loc[df.shape[0]*train_prp:]\n\nfeatures = ['AC_POWER', \"IRRADIATION\"]\nclf = IsolationForest(n_estimators=1000, max_samples='auto', contamination=.03, max_features=2, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\nclf.fit(train[features])\npred = clf.predict(test[features])\n\ntest['anomaly'] = pred\nanomalies = test[test['anomaly'] == -1][['AC_POWER']]\nanomalies = anomalies.rename(columns={'AC_POWER':'anomalies'})\ntest = test.merge(anomalies, left_index=True, right_index=True, how='left')\ntest","47beb0cb":"test.anomaly.value_counts()","4a3382a1":"pred = clf.predict(train[features])\n\ntrain['anomaly'] = pred\nanomalies = train[train['anomaly'] == -1][['AC_POWER']]\nanomalies = anomalies.rename(columns={'AC_POWER':'anomalies'})\ntrain = train.merge(anomalies, left_index=True, right_index=True, how='left')\ntrain","152d3672":"train.anomaly.value_counts()","fd43ba18":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=test[\"DATE_TIME\"], y=test[\"AC_POWER\"],\n                    mode='lines',\n                    name='AC Power'))\n\nfig.add_trace(go.Scatter(x=test[\"DATE_TIME\"], y=test[\"anomalies\"],\n                    name='Anomaly', \n                    mode='markers',\n                    marker=dict(color=\"red\",\n                                size=11,\n                                line=dict(color=\"red\",\n                                          width=2))))\n\nfig.update_layout(title_text=\"Anomalies Detected using Isolation Forest\",\n                  yaxis1=dict(title=\"AC Power in kW\"))\n\nfig.show()","a1831013":"x_min, x_max = (train['AC_POWER'].min(), train['AC_POWER'].max())\ny_min, y_max = (train['IRRADIATION'].min(), train['IRRADIATION'].max())\n\nxrange = np.linspace(x_min - (x_min*.2), x_max + (x_max*.2), 1000)\nyrange = np.linspace(y_min - (y_min*.2), y_max + (y_max*.2), 1000)\nxx, yy = np.meshgrid(xrange, yrange)\nZ = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)","ed300cf6":"\nn_train = train[['AC_POWER','IRRADIATION']].loc[train['anomaly']==1]\na_train = train[['AC_POWER','IRRADIATION']].loc[train['anomaly']==-1]\nn_test = test[['AC_POWER','IRRADIATION']].loc[test['anomaly']==1]\na_test = test[['AC_POWER','IRRADIATION']].loc[test['anomaly']==-1]\n\ntrace_specs = [\n    [n_train, 'anomaly', 'Train', 'square', 'green'],\n    [a_train, 'not anomaly', 'Train', 'square', 'red'],\n    [n_test, 'anomaly', 'Test', 'circle', 'blue'],\n    [a_test, 'not anomaly', 'Test', 'circle', 'orange']]\n\nfig = go.Figure(data=[\n    go.Scatter(\n        x=data[\"AC_POWER\"], y=data['IRRADIATION'],\n        name=f'{split} Split, Label {label}',\n        mode='markers', marker_symbol=marker,\n        marker=dict(color=color)\n    )\n    for data, label, split, marker, color in trace_specs\n])\n\n\nfig.add_trace(\n    go.Contour(\n        x=xrange,\n        y=yrange,\n        z=Z,\n        showscale=False,\n        colorscale='RdBu',\n        opacity=0.4,\n        name='Score',\n        hoverinfo='skip'\n    )\n)\nfig.update_layout(title=\"Isolation Forest Contour and Scatter Plot\", \n                  yaxis=dict(title=\"Irradiation index\"), \n                  xaxis=dict(title=\"Power in kW\"))\n\nfig.show()","b5524d7a":"df = df[[\"DATE_TIME\", \"AC_POWER\", \"AMBIENT_TEMPERATURE\", \"MODULE_TEMPERATURE\", \"IRRADIATION\"]]\ndf_timestamp = df[[\"DATE_TIME\"]]\ndf_ = df[[\"AC_POWER\", \"AMBIENT_TEMPERATURE\", \"MODULE_TEMPERATURE\", \"IRRADIATION\"]]","fdc5175e":"train_prp = .6\ntrain = df_.loc[:df_.shape[0]*train_prp]\ntest = df_.loc[df_.shape[0]*train_prp:]\n","cd4e173d":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(train)\nX_test = scaler.transform(test)\nX_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nX_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")","df3cf324":"from tensorflow.keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers","f8c7481a":"def autoencoder_model(X):\n    inputs = Input(shape=(X.shape[1], X.shape[2]))\n    L1 = LSTM(16, activation='relu', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)\n    L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n    L3 = RepeatVector(X.shape[1])(L2)\n    L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n    L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n    output = TimeDistributed(Dense(X.shape[2]))(L5)\n    model = Model(inputs=inputs, outputs=output)\n    return model","89f6d0ec":"model = autoencoder_model(X_train)\nmodel.compile(optimizer='adam', loss='mae')\nmodel.summary()","270a4e01":"epochs = 100\nbatch = 10\nhistory = model.fit(X_train, X_train, epochs=epochs, batch_size=batch, validation_split=.2, verbose=0).history\n","04a2c710":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=[x for x in range(len(history['loss']))], y=history['loss'],\n                    mode='lines',\n                    name='loss'))\n\nfig.add_trace(go.Scatter(x=[x for x in range(len(history['val_loss']))], y=history['val_loss'],\n                    mode='lines',\n                    name='validation loss'))\n\nfig.update_layout(title=\"Autoencoder error loss over epochs\",\n                  yaxis=dict(title=\"Loss\"),\n                  xaxis=dict(title=\"Epoch\"))\n\nfig.show()","bf33d69c":"X_pred = model.predict(X_train)\nX_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\nX_pred = scaler.inverse_transform(X_pred)\nX_pred = pd.DataFrame(X_pred, columns=train.columns)","894e1465":"scores = pd.DataFrame()\nscores['AC_train'] = train['AC_POWER']\nscores[\"AC_predicted\"] = X_pred[\"AC_POWER\"]\nscores['loss_mae'] = (scores['AC_train']-scores['AC_predicted']).abs()\n","eceec590":"fig = go.Figure(data=[go.Histogram(x=scores['loss_mae'])])\nfig.update_layout(title=\"Error distribution\", \n                 xaxis=dict(title=\"Error delta between predicted and real data [AC Power]\"),\n                 yaxis=dict(title=\"Data point counts\"))\nfig.show()","8a06e842":"X_pred = model.predict(X_test)\nX_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\nX_pred = scaler.inverse_transform(X_pred)\nX_pred = pd.DataFrame(X_pred, columns=train.columns)\nX_pred.index = test.index","3d5d1fad":"scores = X_pred\nscores['datetime'] = df_timestamp.loc[1893:]\nscores['real AC'] = test['AC_POWER']\nscores[\"loss_mae\"] = (scores['real AC'] - scores['AC_POWER']).abs()\nscores['Threshold'] = 200\nscores['Anomaly'] = np.where(scores[\"loss_mae\"] > scores[\"Threshold\"], 1, 0)\n","0ef01a4e":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=scores['datetime'], \n                         y=scores['loss_mae'], \n                         name=\"Loss\"))\nfig.add_trace(go.Scatter(x=scores['datetime'], \n                         y=scores['Threshold'],\n                         name=\"Threshold\"))\n\nfig.update_layout(title=\"Error Timeseries and Threshold\", \n                 xaxis=dict(title=\"DateTime\"),\n                 yaxis=dict(title=\"Loss\"))\nfig.show()","325f2749":"scores['Anomaly'].value_counts()","b2f10c42":"anomalies = scores[scores['Anomaly'] == 1][['real AC']]\nanomalies = anomalies.rename(columns={'real AC':'anomalies'})\nscores = scores.merge(anomalies, left_index=True, right_index=True, how='left')","e7fc4427":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"real AC\"],\n                    mode='lines',\n                    name='AC Power'))\n\nfig.add_trace(go.Scatter(x=scores[\"datetime\"], y=scores[\"anomalies\"],\n                    name='Anomaly', \n                    mode='markers',\n                    marker=dict(color=\"red\",\n                                size=11,\n                                line=dict(color=\"red\",\n                                          width=2))))\n\nfig.update_layout(title_text=\"Anomalies Detected LSTM Autoencoder\")\n\nfig.show()","60e6c897":"## Conclusion\n\nWe see that the LSTM Autoencoder approach is a more efficient way to detect anomalies, againts the Isolation Forest approach, perhaps with a larger dataset the Isolation tree could outperform the Autoencoder, having a faster and pretty good model to detect anomalies. \n\nWe can see from the Isolation Forest graph how the model is detecting anomalies, highlighting the datapoints from June 7th and June 14th.\n","be01a0f3":"# Inverter level Anomally detection","6fa4ba88":"### Graph observations\nWe can see that in June 7th and June 14th there are some misproduction areas that could be considered anomalies. Due to the fact that energy production should behave in a linear way to irradiation.","1eca5c2e":"### Observations\nHere we can see how the Isolation Forest Model is behaving. The yellow dots show us the anomalies detected on the test dataset as well as the red squares that show us the anomalies detected on the training dataset. These points do not follow the contour pattern of the graph and we can clearly see that the yellow dots on the far left are the points from June 7th and June 14th.","5760eb8a":"# LSTM Autoencoder approach","680600b7":"### Observation after building model\nWe see that the model does detect the misproduction areas in June 7th and June 14th, but also it is detecting anomalies in the peaks of most of the days. which personally I wouldn't consider anomalies.","25736cf3":"# Context\n\nIn the Solar Energy Industry it is common to have **misproduction problems** regarding various topics such as dirty solar panels, inverter failures, sensor issues and more. In this Notebook I will compare two approaches. The first one using **Isolation Forest** and the second an **LSTM Autoencoder**, to see which approach is the most efficient to detect anomalies in an AC Power timeseries."}}