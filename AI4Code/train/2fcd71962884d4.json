{"cell_type":{"966ebbbd":"code","0bd7cae6":"code","ae95f21e":"code","b81c86ec":"code","fa3d9940":"code","e655864d":"code","553a1509":"code","a80a9700":"markdown","63dd4083":"markdown","459dfa3d":"markdown","ee351fde":"markdown","47ddde31":"markdown","38ac08cd":"markdown","3fc75fad":"markdown","98c51ca1":"markdown","0ec99449":"markdown"},"source":{"966ebbbd":"!pip install tf-slim\nimport os\nimport numpy as np\nfrom PIL import Image\nfrom imageio import imread\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nimport tf_slim as slim\nfrom tf_slim.nets import inception\nimport tf_slim as slim\nimport cv2\nimport matplotlib.pyplot as plt","0bd7cae6":"ckpt_path = \"\/kaggle\/input\/inception_v3.ckpt\"\nimages_path = \"\/kaggle\/input\/animals\/*\"\nimg_width = 299\nimg_height = 299\nbatch_size = 16\nbatch_shape = [batch_size, img_height, img_width, 3]\nnum_classes = 1001\npredict_output = []\nclass_names_path = \"\/kaggle\/input\/imagenet_class_names.txt\"\nwith open(class_names_path) as f:\n    class_names = f.readlines()","ae95f21e":"X = tf.placeholder(tf.float32, shape=batch_shape)\n\nwith slim.arg_scope(inception.inception_v3_arg_scope()):\n    logits, end_points = inception.inception_v3(\n        X, num_classes=num_classes, is_training=False\n    )\n\npredictions = end_points[\"Predictions\"]\nsaver = tf.train.Saver(slim.get_model_variables())","b81c86ec":"def load_images(input_dir):\n    global batch_shape\n    images = np.zeros(batch_shape)\n    filenames = []\n    idx = 0\n    batch_size = batch_shape[0]\n    files = tf.gfile.Glob(input_dir)[:20]\n    files.sort()\n    for filepath in files:\n        with tf.gfile.Open(filepath, \"rb\") as f:\n            imgRaw = np.array(Image.fromarray(imread(f, as_gray=False, pilmode=\"RGB\")).resize((299, 299))).astype(np.float) \/ 255.0\n        # Images for inception classifier are normalized to be in [-1, 1] interval.\n        images[idx, :, :, :] = imgRaw * 2.0 - 1.0\n        filenames.append(os.path.basename(filepath))\n        idx += 1\n        if idx == batch_size:\n            yield filenames, images\n            filenames = []\n            images = np.zeros(batch_shape)\n            idx = 0\n    if idx > 0:\n        yield filenames, images","fa3d9940":"session_creator = tf.train.ChiefSessionCreator(\n        scaffold=tf.train.Scaffold(saver=saver),\n        checkpoint_filename_with_path=ckpt_path,\n        master='')","e655864d":"with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n    for filenames, images in load_images(images_path):\n        labels = sess.run(predictions, feed_dict={X: images})\n        for filename, label, image in zip(filenames, labels, images):\n            predict_output.append([filename, label, image])","553a1509":"for x in predict_output:\n    out_list = list(x[1])\n    topPredict = sorted(range(len(out_list)), key=lambda i: out_list[i], reverse=True)[:5]\n    plt.imshow((((x[2]+1)\/2)*255).astype(int))\n    plt.show()\n    print(\"Filename:\",x[0])\n    print(\"Displaying the top 5 Predictions for above image:\")\n    for p in topPredict:\n        print(class_names[p-1].strip())","a80a9700":"# Large Categories' Image Classification using Inception v3\n\nInception-v3 is a pre-trained convolutional neural network that is 48 layers deep, which is a version of the network already trained on more than a million images from the ImageNet database. This pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. As a result, the network has learned rich feature representations for a wide range of images. The network has an image input size of 299-by-299. \nThe model extracts general features from input images in the first part and classifies them based on those features in the second part.\n\n![](https:\/\/cloud.google.com\/tpu\/docs\/images\/inceptionv3onc--oview.png)\n\nInception v3 is a widely-used image recognition model that has been shown to attain greater than 78.1% accuracy on the ImageNet dataset and around 93.9% accuracy in top 5 results. The model is the culmination of many ideas developed by multiple researchers over the years. It is based on the original paper: \"[Rethinking the Inception Architecture for Computer Vision](https:\/\/arxiv.org\/abs\/1512.00567)\" by Szegedy, et. al.\n\nMore information about the Inception architecture can be found [here](https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/inception).","63dd4083":"Define function for loading images and resizing for sending to model for evaluation in RGB mode","459dfa3d":"# Classify Images using Model","ee351fde":"Hence, we can see model predictions are great.","47ddde31":"# Import Data","38ac08cd":"# Display Predicted Output ","3fc75fad":"# Data Loading\n\nSetup all initial variables with default file locations and respective values","98c51ca1":"# Create Inception v3 model","0ec99449":"# Load Pre-Trained Model"}}