{"cell_type":{"bd8a69cf":"code","2a0f625b":"code","f7495d67":"code","8df272bd":"code","b01f9f97":"code","4da5e814":"code","c7e72113":"code","847efe56":"code","60dee030":"code","5fd54fdf":"code","36fec195":"markdown","01151ca2":"markdown","844d74ae":"markdown","654390e9":"markdown","2143c9f1":"markdown","c516d4a4":"markdown","91092a15":"markdown","90630eb3":"markdown","45ae3aff":"markdown"},"source":{"bd8a69cf":"import numpy as np\nimport pandas as pd \n\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\nimport xgboost","2a0f625b":"df = pd.read_csv(\"..\/input\/passenger-list-for-the-estonia-ferry-disaster\/estonia-passenger-list.csv\")","f7495d67":"class DataProcess(BaseEstimator, TransformerMixin):\n    \"\"\" This is just a transformer that I will feed into a pipeline  \"\"\"\n    \n    def __init__(self):\n        self.columns_to_drop = [\"Firstname\", \"Lastname\", \"PassengerId\"]\n        self.country_ratio_param = pd.Series(np.nan)  ## This will be se tby fit\n        self.has_family_map = pd.Series(np.nan)\n    \n    def transform(self, X, y=None):\n        X_ = X.copy()\n        X_[\"Sex\"] = X_[\"Sex\"].map({\"M\": 0, \"F\": 1})\n        X_[\"Category\"] = X_[\"Category\"].map({\"C\": 0, \"P\": 1})\n        \n        X_[\"swedish\"] = X_[\"Country\"].apply(lambda x: x == \"Sweden\")\n        X_[\"estonian\"] = X_[\"Country\"].apply(lambda x: x == \"Estonia\")\n        X_[\"Country\"] = X_[\"Country\"].map(self.country_ratio_param)\n        \n        X_[\"has_family\"] = X_[\"Lastname\"].map(self.has_family_map)\n        \n        X_.drop(self.columns_to_drop, inplace=True, axis=1)\n        \n        assert not X_.isna().any().any(), f\"Missing values found: {X_.isna().any()}\"\n        \n        return X_\n    \n    def fit(self, X, y):\n        \"\"\" There is not anything to fit here \"\"\"\n        X_ = X.copy()\n        X_[\"Survived\"] = y\n        self.country_ratio_param = df.groupby(\"Country\")[\"Survived\"].apply(lambda x: x.sum()\/x.shape[0]).sort_values()\n        self.has_family_map = df.groupby(\"Lastname\", as_index=False)[\"Firstname\"].apply(lambda x: x.shape[0] > 1).set_index(\"Lastname\").squeeze()\n    \n    def fit_transform(self, X, y):\n        self.fit(X, y)\n        return self.transform(X)\n    \nprint(\"Processed DataFrame\")\nDataProcess().fit_transform(X=df.drop(\"Survived\", axis=1), y=df[\"Survived\"]).head()","8df272bd":"print(df.shape)\ndf.head()","b01f9f97":"survivors_by_country = df.groupby([\"Country\", \"Survived\"])[\"Age\"].count().sort_values().reset_index()\nsurvivors_by_country[\"Survived\"] = survivors_by_country[\"Survived\"].astype(str)\nsurvivors_by_country.rename(columns={\"Age\": \"nPeople\"}, inplace=True)\nfig = px.bar(survivors_by_country, x=\"Country\", y=\"nPeople\", color=\"Survived\")\nfig.layout.yaxis.title = \"# People\"\nfig.layout.title = \"# Survivors and Total passenders by country\"\nfig.show()","4da5e814":"country_survivor_ratio = df.groupby(\"Country\")[\"Survived\"].apply(lambda x: x.sum()\/x.shape[0]).sort_values()\nfig = px.bar(country_survivor_ratio.reset_index(), x=\"Country\", y=\"Survived\", title=\"Surviving Ratio per Country\")\nfig.layout.yaxis.title = \"Survivor Ratio [%]\"\nfig.show()","c7e72113":"grouped = df.groupby([\"Category\", \"Sex\"])[\"Survived\"].sum().reset_index()\npx.bar(grouped, y=\"Survived\", x=\"Category\", color=\"Sex\", title=\"Number of survivors per Category and Gender\")","847efe56":"%%time\n\n# I used a bigger param grid on previous commits. \nparams = {\n 'xgboost__booster': ['gbtree'], \n 'xgboost__colsample_bytree': [0.8], \n 'xgboost__eta': [0.05],\n 'xgboost__eval_metric': ['error'], \n 'xgboost__gamma': [0.5], \n 'xgboost__max_depth': [5],\n 'xgboost__min_child_weight': [1], \n 'xgboost__n_estimators': [100], \n 'xgboost__subsample': [1.0]}\n\npipeline = Pipeline([(\"data_process\", DataProcess()), (\"xgboost\", xgboost.XGBRFClassifier())])\nclf = GridSearchCV(pipeline, cv=StratifiedShuffleSplit(6, random_state=1), n_jobs=-1, scoring=[\"f1\", \"accuracy\"], refit=\"accuracy\",  param_grid=params)\n\nX = df.drop(\"Survived\", axis=1)\ny = df[\"Survived\"]\nclf.fit(X, y)\nprint(clf.best_params_)\npd.DataFrame(clf.cv_results_).sort_values(\"rank_test_f1\").head(1).T","60dee030":"# Feature importance\n_, ax = plt.subplots(figsize=(20, 5))\nxgboost.plot_importance(clf.best_estimator_[-1], ax=ax)\nplt.show()","5fd54fdf":"_, ax = plt.subplots(figsize=(30, 30))\nxgboost.plot_tree(clf.best_estimator_[-1], ax=ax, num_trees=0)\nplt.show()","36fec195":"# Fitting an xbgoost classifier","01151ca2":"# EDA\nFor now, let's just create some visualizations!","844d74ae":"## Number of survivors per Category and Gender. \n\n","654390e9":"# Conclusion\nI did not manage the beat this baseline, I got 86.7% accuracy. I decide to publish this notebook now because I ran out of ideas for now, but there is a separate model that I want to try (maybe next week). \n\nThe model performed very poorly with an f1 of 12.5%. I don't think it is possible to obtain a great classifier with this data, but maybe I can increase the accuracy until 90% using another type of model. ","2143c9f1":"## Custom transformer","c516d4a4":"## Feature Importance\nNow let's see what out classifier considers the most important features.","91092a15":"## Country Survivor Ratio\nThis is the ratio of survivors. In some instances this might not be at all significant, given that there are countries that only have 1 or two people on board.","90630eb3":"# Estonia Disaster analysis\nIn this notebook I try, and fail, to beat the 86% baseline using XGBOOST. I still decided to publish this just because I feel that i managed to create a nice enough pipeline that someone can just tweak the XGBOOST, or custom transformer, and try to get a better result. \n\nI have a few ideas for other models that I will try as soon as I have the time. ","45ae3aff":"## Number of deaths per country\nWhich countries suffered the highest casualties? "}}