{"cell_type":{"426ffdd2":"code","2d625ffd":"code","2fc67d2f":"code","4a1a18c8":"code","c2cb22db":"code","d74cd0d5":"code","9da7c528":"code","d3e5d350":"code","4a994f7d":"code","ce46bd18":"code","d7eac212":"code","e2337e73":"code","df577177":"code","624cc870":"code","9c3260ff":"code","2863d97c":"code","bbdb7956":"code","caff5759":"code","526f2f0b":"code","8593d56a":"code","70dfda45":"code","c6eacef4":"code","f0adac54":"code","25bfb4a0":"code","55fba783":"code","bae7893b":"code","aa661cae":"code","b6c4aba4":"code","10db75a3":"code","f89941d8":"code","7354d7e4":"code","7090c59e":"code","7c922a05":"code","2be282af":"code","a443c8e7":"code","e897b73e":"code","a932ebeb":"code","603ab857":"code","17d2a940":"code","a6d9fa98":"code","c54c1f6e":"code","1bb8475a":"code","6069724f":"code","db3f17c0":"code","f0dc7c7d":"code","7a6c7bb1":"code","a875566e":"code","1decce82":"code","1a4d4f01":"code","4b217078":"code","8e23109d":"code","ae35a15c":"code","7878e764":"code","17815a11":"code","36ef8a48":"code","fa22c61b":"code","4f7a0e8b":"code","4238f504":"code","e6e9b9eb":"code","85b7b810":"code","f3b078a9":"code","e8ae9f93":"code","15b86c55":"code","1df72426":"code","d41d97d7":"code","e2310bea":"code","1bba1409":"code","d6527218":"code","c8ac5fc7":"code","747b59a5":"code","135a6399":"code","df481537":"markdown","64608209":"markdown","0f3a911c":"markdown","a7f57d7d":"markdown","b5eccfa8":"markdown","ed32c33a":"markdown","9ca3715e":"markdown","8f5de04a":"markdown","81811c36":"markdown","6e9ec2da":"markdown","5148658b":"markdown","f990a96a":"markdown","e35cc457":"markdown","9fd3e0b3":"markdown","4b8df794":"markdown","165ddf58":"markdown","b6a4c072":"markdown","58534362":"markdown","5b40389b":"markdown","491e9be7":"markdown"},"source":{"426ffdd2":"#importing libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%pylab inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","2d625ffd":"data2017 = pd.read_csv(\"..\/input\/world-happiness\/2017.csv\")\ndata2017.head()","2fc67d2f":"data2017.info()","4a1a18c8":"data2017.isnull().sum().sum()","c2cb22db":"data2017.describe()","d74cd0d5":"plt.rcParams[\"figure.figsize\"] = (20,10)\ndata_plot = data2017.loc[:,['Whisker.high',\n       'Whisker.low', 'Economy..GDP.per.Capita.', 'Family',\n       'Health..Life.Expectancy.', 'Freedom', 'Generosity',\n       'Trust..Government.Corruption.', 'Dystopia.Residual', \"Happiness.Score\" ]]\ndata_plot.plot()\nplt.grid()\nplt.ylabel(\"Score\")\nplt.xlabel(\"Country Ranking\")","9da7c528":"data_plot = data2017.loc[:,['Economy..GDP.per.Capita.', 'Family',\n       'Health..Life.Expectancy.', 'Freedom', 'Generosity',\n       'Trust..Government.Corruption.', 'Dystopia.Residual']]\ndata_plot.plot()\nplt.grid()\nplt.ylabel(\"Score\")\nplt.xlabel(\"Country Ranking\")","d3e5d350":"sns.pairplot(data2017.iloc[:,2:])\nplt.show()","4a994f7d":"#creating correlation matrix\n\ncorr = data2017.corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(13, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr,annot= True, mask=mask, cmap= 'coolwarm', vmax=.9, center=0,\n            square=True, linewidths=.5, fmt= '.1f', cbar_kws={\"shrink\": .5})","ce46bd18":"c = corr.abs()\n\nsol = (c.where(np.triu(np.ones(c.shape), k=1).astype(np.bool))\n                 .stack()\n                 .sort_values(ascending=False))\nsol[:10]","d7eac212":"corr.iloc[:,1].sort_values()","e2337e73":"features_to_analyse = ['Whisker.high',\n       'Whisker.low','Economy..GDP.per.Capita.', 'Family',\n       'Health..Life.Expectancy.', 'Freedom', 'Generosity',\n       'Trust..Government.Corruption.', 'Dystopia.Residual', 'Happiness.Score']\nfig, ax = plt.subplots(round(len(features_to_analyse) \/ 3), 3, figsize = (18, 12))\nfor i, ax in enumerate(fig.axes):\n    if i < len(features_to_analyse) - 1:\n        sns.regplot(x=features_to_analyse[i],y='Happiness.Score', data=data2017[features_to_analyse], ax=ax)","df577177":"data2017 = data2017.drop(['Whisker.high','Whisker.low'], axis=1)","624cc870":"filter1 = data2017['Happiness.Score']>=7\nhappy_countries = data2017[filter1]\nhappy_countries[:10]","9c3260ff":"from sklearn.model_selection import train_test_split\n\nX= data2017.iloc[:,3:]\ny= data2017[\"Happiness.Score\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,shuffle=True)","2863d97c":"from sklearn.ensemble import RandomForestRegressor \n  \n # create regressor object \nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0) \n  \n# fit the regressor with x and y data \nregressor.fit(X_train, y_train) ","bbdb7956":"from sklearn.metrics import mean_squared_error\nprint('train score: {:.2f}'.format(regressor.score(X_train, y_train)))\nprint('test score: {:.2f}'.format(regressor.score(X_test, y_test)))\ny_predicted = regressor.predict(X_test)\nprint(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))","caff5759":"y_predicted = regressor.predict(X_test)\n\nfig, ax = plt.subplots()\nax.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nax.set_title(\"Actual vs Predicted Happiness Score\")\nplt.show()","526f2f0b":"names=X.columns\nsorted(zip(map(lambda x: round(x, 4), regressor.feature_importances_), names), reverse=True)","8593d56a":"Importance = pd.DataFrame({'Importance':regressor.feature_importances_*100},\n                         index = X_train.columns)\nImportance.sort_values(by ='Importance',\n                      axis = 0,\n                      ascending = True).plot(kind = 'barh',\n                                            color = 'r')\nplt.xlabel('Variable Importance')\nplt.gca().legend_ = None","70dfda45":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(X_train, y_train)\n\nprint('train score: {:.2f}'.format(model.score(X_train, y_train)))\nprint('test score: {:.2f}'.format(model.score(X_test, y_test)))\ny_predicted = model.predict(X_test)\nprint(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))","c6eacef4":"y_predicted = model.predict(X_test)\n\nfig, ax = plt.subplots()\nax.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nax.set_title(\"Actual vs Predicted Happiness Score\")\nplt.show()","f0adac54":"data2017_2 = data2017.drop('Economy..GDP.per.Capita.', axis=1)\nX= data2017_2.iloc[:,3:]\ny= data2017_2[\"Happiness.Score\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,shuffle=True)","25bfb4a0":"model = LinearRegression().fit(X_train, y_train)\n\nprint('train score: {:.2f}'.format(model.score(X_train, y_train)))\nprint('test score: {:.2f}'.format(model.score(X_test, y_test)))\ny_predicted = model.predict(X_test)\nprint(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))","55fba783":"undata = pd.read_csv(\"..\/input\/un-2017-country-profile-variables\/country_profile_variables.csv\")\nundata.head()","bae7893b":"undata.isnull().sum().sum()","aa661cae":"undata.shape","b6c4aba4":"c = undata.corr().abs()\n\nsol = (c.where(np.triu(np.ones(c.shape), k=1).astype(np.bool))\n                 .stack()\n                 .sort_values(ascending=False))\nsol[:10]","10db75a3":"corr_matrix = c\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.70)]\n\nto_drop\n","f89941d8":"undata.drop(to_drop, axis=1, inplace=True)","7354d7e4":"undata.shape","7090c59e":"data_all= pd.merge(left=data2017_2, right=undata,on=None, left_on='Country', right_on='country')\ndata_all.head()","7c922a05":"data_all = data_all.drop(\"country\", axis=1)","2be282af":"data_all.shape","a443c8e7":"data_all.info()","e897b73e":"data_last2 = data_all.drop(['GDP: Gross domestic product (million current US$)',\n       'GDP growth rate (annual %, const. 2005 prices)', \"GDP per capita (current US$)\"\n       , 'Economy: Agriculture (% of GVA)',\n       'Economy: Industry (% of GVA)',\n       'Employment: Agriculture (% of employed)',\n       'Unemployment (% of labour force)', 'International trade: Exports (million US$)',\n       'International trade: Imports (million US$)',\n       'International trade: Balance (million US$)' , \"Net Official Development Assist. received (% of GNI)\"], axis=1)","a932ebeb":"data_last2.head(3)","603ab857":"data_last2.describe(include=['object'])","17d2a940":"data_last2.info()","a6d9fa98":"data_last2 = data_last2.replace(to_replace='~0.0', value=0.0, regex=True)","c54c1f6e":"data_last2['Population growth rate (average annual %)'] = data_last2['Population growth rate (average annual %)'].astype(float)\ndata_last2[\"Fertility rate, total (live births per woman)\"] = data_last2[\"Fertility rate, total (live births per woman)\"].astype(float)\ndata_last2[\"Mobile-cellular subscriptions (per 100 inhabitants)\"] = data_last2[\"Mobile-cellular subscriptions (per 100 inhabitants)\"].astype(float)\ndata_last2[\"Threatened species (number)\"] = data_last2[\"Threatened species (number)\"].astype(float)\n","1bb8475a":"data_last2[\"Population age distribution (0-14 \/ 60+ years, %)\"].head()","6069724f":"data_last2[\"0-14 Age\"] =data_last2[\"Population age distribution (0-14 \/ 60+ years, %)\"].str.replace(\"\/\",\" \")\ndata_last2[\"60+ years Age\"] =data_last2[\"Population age distribution (0-14 \/ 60+ years, %)\"].str.replace(\"\/\",\" \")\n","db3f17c0":"child= []\nold= []\nfor i in range(data_last2.shape[0]):\n    child.append(data_last2[\"0-14 Age\"][i].split(\" \")[0])\n    old.append(data_last2[\"60+ years Age\"][i].split(\" \")[1])","f0dc7c7d":"data_last2[\"0-14 Age\"] = child\ndata_last2[\"60+ years Age\"]= old\n\ndata_last2[\"0-14 Age\"] = data_last2[\"0-14 Age\"].astype(float)\ndata_last2[\"60+ years Age\"] = data_last2[\"60+ years Age\"].astype(float)","7a6c7bb1":"data_last2[[\"0-14 Age\",\"60+ years Age\"] ]","a875566e":"data_last2 = data_last2[data_last2[\"Forested area (% of land area)\"] != 0.0]\ndata_last2[\"Forested area (% of land area)\"]","1decce82":"data_last2[\"Forested area Urban\"] =data_last2[\"Forested area (% of land area)\"].str.replace(\"\/\",\" \")\ndata_last2[\"Forested area Rural\"] =data_last2[\"Forested area (% of land area)\"].str.replace(\"\/\",\" \")\n","1a4d4f01":"data_last2 = data_last2.reset_index()\ndata_last2 = data_last2.drop(\"index\", axis=1)","4b217078":"data_last2[\"Forested area Urban\"]","8e23109d":"urban= []\nrural= []\nfor i in range(data_last2.shape[0]):\n    urban.append(data_last2[\"Forested area Urban\"][i].split(\" \")[0])\n    rural.append(data_last2[\"Forested area Rural\"][i].split(\" \")[1])","ae35a15c":"data_last2[\"Forested area Urban\"] = urban\ndata_last2[\"Forested area Rural\"] = rural","7878e764":"data_last2[\"Forested area Urban\"] = data_last2[\"Forested area Urban\"].astype(float)\ndata_last2[\"Forested area Rural\"] = data_last2[\"Forested area Rural\"].astype(float)","17815a11":"data_last2 = data_last2[data_last2['Balance of payments, current account (million US$)']!= \"...\"]","36ef8a48":"data_last2[\"Refugees and others of concern to UNHCR (in thousands)\"] = data_last2[\"Refugees and others of concern to UNHCR (in thousands)\"].astype(float)\ndata_last2[\"Infant mortality rate (per 1000 live births\"] = data_last2[\"Infant mortality rate (per 1000 live births\"].astype(float)\ndata_last2['Balance of payments, current account (million US$)'] = data_last2['Balance of payments, current account (million US$)'].astype(float)\ndata_last2['Employment: Services (% of employed)'] = data_last2['Employment: Services (% of employed)'].astype(float)\ndata_last2['Employment: Industry (% of employed)'] = data_last2['Employment: Industry (% of employed)'].astype(float)\n","fa22c61b":"data_last2.corr().iloc[:,1][data_last2.corr().iloc[:,1].abs().sort_values() >=0.4]","4f7a0e8b":"data_last3= data_last2[['Country', 'Happiness.Score', 'Family', 'Health..Life.Expectancy.',\n       'Freedom', 'Trust..Government.Corruption.', 'Dystopia.Residual',\n       'Urban population (% of total population)',\n       'Fertility rate, total (live births per woman)',\n       'Energy production, primary (Petajoules)',\n       'Mobile-cellular subscriptions (per 100 inhabitants)',\n       'Forested area Rural', 'Employment: Services (% of employed)', '0-14 Age',\n       '60+ years Age']]","4238f504":"X= data_last3.iloc[:,2:]\ny= data_last3[\"Happiness.Score\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, shuffle= True)\n","e6e9b9eb":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(X_train, y_train)\n\nprint('train score: {:.2f}'.format(model.score(X_train, y_train)))\nprint('test score: {:.2f}'.format(model.score(X_test, y_test)))\ny_predicted = model.predict(X_test)\nprint(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))","85b7b810":"from sklearn.covariance import EmpiricalCovariance, MinCovDet\n# fit a Minimum Covariance Determinant (MCD) robust estimator to data \nrobust_cov = MinCovDet().fit(data_last3.iloc[:,2:])\n# Get the Mahalanobis distance\ndata_last3[\"mahalanobis\"] = robust_cov.mahalanobis(data_last3.iloc[:,2:])\ndata_last3.head()","f3b078a9":"from scipy.stats import chi2\ndata_last3['p_value'] = 1 - chi2.cdf(data_last3['mahalanobis'], 12)\n\n# Extreme values with a significance level of 0.01\ndata_last3.loc[data_last3.p_value < 0.01].head(30).sort_values(by= \"mahalanobis\", ascending=False)","e8ae9f93":"data_last4 = data_last3[data_last3[\"mahalanobis\"] <=3000]","15b86c55":"data_last4 = data_last4.drop(\"mahalanobis\", axis=1)\ndata_last4 = data_last4.drop(\"p_value\", axis=1)","1df72426":"data_last3 = data_last3.drop(\"mahalanobis\", axis=1)\ndata_last3 = data_last3.drop(\"p_value\", axis=1)","d41d97d7":"data_last3.shape","e2310bea":"data_last4.shape","1bba1409":"data_last4.columns","d6527218":"features_to_analyse = ['Urban population (% of total population)',\n       'Fertility rate, total (live births per woman)',\n       'Energy production, primary (Petajoules)',\n       'Mobile-cellular subscriptions (per 100 inhabitants)',\n       'Forested area Rural', 'Employment: Services (% of employed)',\n       '0-14 Age', '60+ years Age', 'Happiness.Score']\nfig, ax = plt.subplots(round(len(features_to_analyse) \/ 3), 3, figsize = (18, 12))\nfor i, ax in enumerate(fig.axes):\n    if i < len(features_to_analyse) - 1:\n        sns.regplot(x=features_to_analyse[i],y='Happiness.Score', data=data_last4[features_to_analyse], ax=ax)","c8ac5fc7":"X= data_last4.iloc[:,2:]\ny= data_last4[\"Happiness.Score\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\n","747b59a5":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(X_train, y_train)\n\nprint('train score: {:.2f}'.format(model.score(X_train, y_train)))\nprint('test score: {:.2f}'.format(model.score(X_test, y_test)))\ny_predicted = model.predict(X_test)\nprint(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))","135a6399":"y_predicted = model.predict(X_test)\n\nfig, ax = plt.subplots()\nax.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nax.set_title(\"Actual vs Predicted Happiness Score\")\nplt.show()","df481537":"# Changing new columns to old ones","64608209":"### without GDP","0f3a911c":"#### To see clearly other features, we drop the whiskers and happiness score","a7f57d7d":"### A brief EDA","b5eccfa8":"Whiskers are highly correlated as predictable and also cant have them in other years' dataset, so I dropped them","ed32c33a":"#### The following columns:\nGDP per Capita, Family, Life Expectancy, Freedom, Generosity, Trust Government Corruption describe the extent to which these factors contribute in evaluating the happiness in each country. The Dystopia Residual metric actually is the Dystopia Happiness Score(1.85) + the Residual value or the unexplained value for each country as stated in the previous answer.","9ca3715e":"## Happiness Score Prediction","8f5de04a":"#### Brief Information :  \nThis dataset is from \"World Happiness Report\" in 2017. My aim is to analyze the features that effect happiness score and then predict it. But my point is not including GDP or any economical data. So the new prediction only contains social features. I added my new features from UN website dataset for 2017. We are gonna be looking at the happiness score data from other perspectives.","81811c36":"## new features correlation graphs","6e9ec2da":"Multiple Linear Regression worked better than Random Forest Regressor for this dataset. ","5148658b":"### Feature Selection","f990a96a":"#### creating a new dataframe from selected features which are correlated to the happiness score","e35cc457":"The first two rows have the highest Mahalanobis distance, so we drop them.","9fd3e0b3":"### Multivariate Outlier Detection with Mahalanobis Distance","4b8df794":"Score decreased a bit, now we add our new features.","165ddf58":"### Final Comments\n\nHappiness Score is positively correlated with the \"Urban population (% of total population)\" which means if people are living on urban areas more, happiness score is increasing. Also it is positively correlated with 'Forested area Rural' and it seems by looking these two features' correlation that the green life is effected for happiness score.\n\nFor the age distribution, happiness score is positively correlated with 60+ years age, and negatively correlated with 0-14 age and Fertility Rate. This gives us an insight. The more fertility rate increases the more 0-14 age people increases and generally happier countries have a dominance at older ages like Europe.\n\nIn conclusion, Happiness Score can be predicted without an economical data and we can have some insights that we should think over the social aspects and their reasons.\n\nHope u all enjoy ;)","b6a4c072":"### Dropping economical features","58534362":"### dropping highly correlated data","5b40389b":"### Forested Area","491e9be7":"We predicted happiness score with GDP feature 1.00 accuracy\nThen, we dropped the GDP data, and accuracy was 0.94\nAfter, we add our new 'social' features with accuracy 0.96\nLastly, applied multivariate outlier removing and our last accuracy is 0.98.\n\nThe aim was not increasing accuracy, buttrying to understand what other effects are there for happiness score either. \nBy the way, these scores can be changable when you run them again because of different train test split. But anyway, our point is to predict the score without economical data and have a high accuracy and we did it."}}