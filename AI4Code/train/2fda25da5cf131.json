{"cell_type":{"95247740":"code","95a41daf":"code","fd8a8a74":"code","256b4f74":"code","361e91ac":"code","2a79d194":"code","0fb13ad1":"code","cf2ae667":"code","1d567d08":"code","9279952c":"code","47986e14":"code","89caacc6":"code","69970752":"code","cea975c4":"code","f9125d0f":"code","445157de":"code","47038334":"code","4effdcb8":"code","9b734063":"code","b823865a":"code","cc778e64":"code","d2788bc8":"code","e5bfd7bc":"code","6acc1ecc":"code","143586f2":"code","eee03e15":"code","906e4118":"code","64c4ab7c":"code","834d314b":"code","0e2552ef":"code","05458c21":"code","dd3fef96":"code","5484a0eb":"code","f67fb1db":"code","dc182fa7":"code","e3375b06":"code","5a7d0160":"code","c00a9f83":"code","393488be":"code","6dab6ea8":"code","d1698b05":"code","3080d092":"code","e8ceccb7":"code","ba339720":"code","b5e7d6bb":"code","d03af9b1":"markdown","df30d58e":"markdown","aa23cbff":"markdown","7546b07d":"markdown","3a2b0cf1":"markdown","6b2a2930":"markdown","96166d0d":"markdown","b7d17f81":"markdown","48c48756":"markdown","78825db0":"markdown","65a1cd6c":"markdown","e702d4ce":"markdown","bfc346d5":"markdown","d639aaf1":"markdown","d90da158":"markdown","8e535692":"markdown","6dcede13":"markdown","0b6f9987":"markdown","47b718af":"markdown","13fefbf9":"markdown"},"source":{"95247740":"import numpy as np\nimport pandas as pd\n\n# Plot\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport seaborn as sns\n\n# Training and test data\nfrom sklearn.model_selection import train_test_split\n\n# AUC score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# Model\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# Submission\nimport riiideducation\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","95a41daf":"df_train = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv', \n                       nrows=10**6,\n                       dtype={'row_id': 'int64', \n                              'timestamp': 'int64', \n                              'user_id': 'int32',\n                              'content_id': 'int16',\n                              'content_type_id': 'int8',\n                              'task_container_id': 'int16',\n                              'user_answer': 'int8',\n                              'answered_correctly': 'int8',\n                              'prior_question_elapsed_time': 'float32',\n                              'prior_question_had_explanation': 'boolean'})","fd8a8a74":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n    return summary","256b4f74":"resumetable(df_train)","361e91ac":"plt.figure(figsize=(15, 5))\n\nplt.suptitle('Time between this interaction and first event', fontsize = 18)\nplt.hist(df_train['timestamp'], bins = 50, color = \"skyblue\")\nplt.ylabel('Count', fontsize = 15)\nplt.xlabel('timestamp', fontsize = 15)\n\nplt.show()","2a79d194":"plt.figure(figsize=(15, 5))\n\np = sns.distplot(df_train['user_id'])\np.set_title(\"Code for the user\", fontsize=18)\np.set_xlabel(\"user_id\", fontsize = 15)\np.set_ylabel(\"Probability\", fontsize = 15)\n\nplt.show()","0fb13ad1":"plt.figure(figsize=(15, 5))\n\np = sns.distplot(df_train['content_id'])\np.set_title(\"The user interaction\", fontsize = 18)\np.set_xlabel(\"content_id\", fontsize = 15)\np.set_ylabel(\"Probability\", fontsize = 15)\n\nplt.show()","cf2ae667":"plt.figure(figsize=(15, 5))\n\np3 = sns.distplot(df_train['task_container_id'])\np3.set_title(\"Code for the batch of questions or lectures\", fontsize = 18)\np3.set_xlabel(\"task_container_id\", fontsize = 15)\np3.set_ylabel(\"Probability\", fontsize = 15)\n\nplt.show()","1d567d08":"plt.figure(figsize=(15, 5))\n\np3 = sns.distplot(df_train['prior_question_elapsed_time'].dropna())\np3.set_title(\"How long it took a user to answer their previous question bundle\", fontsize = 18)\np3.set_xlabel(\"prior_question_elapsed_time\", fontsize = 15)\np3.set_ylabel(\"Probability\", fontsize = 15)\n\nplt.show()","9279952c":"plt.figure(figsize=(12, 5))\n\nfreq = len(df_train)\n\ng = sns.countplot(df_train['content_type_id'])\ng.set_title(\"\", fontsize = 18)\ng.set_xlabel(\"content_type_id\", fontsize = 15)\ng.set_ylabel(\"Count\", fontsize = 15)\n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x() + p.get_width() \/ 2., height + 3,\n          '{:1.2f}%'.format(height \/ freq * 100),\n          ha = \"center\", fontsize = 18)","47986e14":"plt.figure(figsize=(15, 5))\n\nfreq = len(df_train)\n\ng = sns.countplot(df_train['user_answer'])\ng.set_title(\"The user's answer to the question\", fontsize = 18)\ng.set_xlabel(\"user_answer\", fontsize = 15)\ng.set_ylabel(\"Count\", fontsize = 15)\n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x() + p.get_width() \/ 2., height + 3,\n          '{:1.2f}%'.format(height \/ freq * 100),\n          ha = \"center\", fontsize = 18)","89caacc6":"plt.figure(figsize=(15, 5))\n\nfreq = len(df_train)\n\ng = sns.countplot(df_train['answered_correctly'])\ng.set_title(\"If the user responded correctly\", fontsize = 18)\ng.set_xlabel(\"answered_correctly\", fontsize = 15)\ng.set_ylabel(\"Count\", fontsize = 15)\n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x() + p.get_width() \/ 2., height + 3,\n          '{:1.2f}%'.format(height \/ freq * 100),\n          ha = \"center\", fontsize = 18)","69970752":"plt.figure(figsize=(12, 5))\n\nfreq = len(df_train)\n\ng = sns.countplot(df_train['prior_question_had_explanation'])\ng.set_title(\"Whether or not the user saw an explanation and the correct response (s) \\n after answering the previous question bundle\",\n            fontsize = 18)\ng.set_xlabel(\"prior_question_had_explanation\", fontsize = 15)\ng.set_ylabel(\"Count\", fontsize = 15)\n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x() + p.get_width() \/ 2., height + 3,\n          '{:1.2f}%'.format(height \/ freq * 100),\n          ha = \"center\", fontsize = 18)","cea975c4":"plt.figure(figsize=(12, 5))\ng = sns.scatterplot(data = df_train, x = \"timestamp\", y = \"prior_question_elapsed_time\", hue = \"prior_question_had_explanation\", \n                style = \"prior_question_had_explanation\")\ng.set_xlabel(\"timestamp\", fontsize = 15)\ng.set_ylabel(\"prior_question_elapsed_time\", fontsize = 15)\n\nplt.show()","f9125d0f":"train = df_train[df_train['answered_correctly']!=-1]","445157de":"plt.figure(figsize=(15, 5))\n\nsns.relplot(\n    data= train, x = \"timestamp\", y = \"prior_question_elapsed_time\",\n    col = \"prior_question_had_explanation\", hue = \"answered_correctly\", style = \"answered_correctly\",\n    kind=\"scatter\"\n);","47038334":"used_data_types_dict = {\n    'row_id': 'int64',\n    'timestamp': 'int64',\n    'user_id': 'int32',\n    'content_id': 'int16',\n    'answered_correctly': 'int8',\n    'prior_question_elapsed_time': 'float16'\n}\n\ntrain_df = pd.read_csv(\n    '\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n    usecols = used_data_types_dict.keys(),\n    dtype=used_data_types_dict, \n    index_col = 0\n)","4effdcb8":"features_df = train_df.iloc[:int(9 \/10 * len(train_df))]\ntrain_df = train_df.iloc[int(9 \/10 * len(train_df)):]","9b734063":"train_questions_only_df = features_df[features_df['answered_correctly']!=-1]\ngrouped_by_user_df = train_questions_only_df.groupby('user_id')\nuser_answers_df = grouped_by_user_df.agg({'answered_correctly': ['mean', 'count', 'std']}).copy()\nuser_answers_df.columns = ['mean_user_accuracy', 'questions_answered', 'std_user_accuracy']","b823865a":"grouped_by_content_df = train_questions_only_df.groupby('content_id')\ncontent_answers_df = grouped_by_content_df.agg({'answered_correctly': ['mean', 'count', 'std'] }).copy()\ncontent_answers_df.columns = ['mean_accuracy', 'question_asked', 'std_accuracy']","cc778e64":"import gc\n\ndel features_df\ndel grouped_by_user_df\ndel grouped_by_content_df\n\ngc.collect()","d2788bc8":"features = [\n    'timestamp',\n    'mean_user_accuracy', \n    'questions_answered',\n    'std_user_accuracy',\n    'mean_accuracy', \n    'question_asked',\n    'std_accuracy',\n    'prior_question_elapsed_time'\n]\ntarget = 'answered_correctly'","e5bfd7bc":"train_df = train_df[train_df[target] != -1]","6acc1ecc":"train_df = train_df.merge(user_answers_df, how='left', on='user_id')\ntrain_df = train_df.merge(content_answers_df, how='left', on='content_id')\ntrain_df","143586f2":"train_df = train_df[features + [target]]","eee03e15":"train_df = train_df.replace([np.inf, -np.inf], np.nan)\ntrain_df = train_df.fillna(0)\ntrain_df","906e4118":"# Function to reduce the df size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","64c4ab7c":"# Reducing memory\ntrain_df = reduce_mem_usage(train_df)","834d314b":"# Training and test data\ntrain_df, test_df = train_test_split(train_df, random_state = 123, test_size = 0.2)","0e2552ef":"# Creating the model\nmodel_LR = LogisticRegression()\n\n# Training the model\nmodel_LR.fit(train_df[features], train_df[target])","05458c21":"ns_probs = [0 for _ in range(len(train_df[target]))]","dd3fef96":"# predict probabilities\nLR_probs = model_LR.predict_proba(train_df[features])\n\n# keep probabilities for the positive outcome only\nLR_probs = LR_probs[:, 1]\n\n# calculate scores\nns_auc = roc_auc_score(train_df[target], ns_probs)\nLR_auc = roc_auc_score(train_df[target], LR_probs)\n\n# result print\nprint('Logistic: ROC AUC = %.3f' % (LR_auc * 100))","5484a0eb":"# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(train_df[target], ns_probs)\nLR_fpr, LR_tpr, _ = roc_curve(train_df[target], LR_probs)\n\n# figure size\nplt.rcParams[\"figure.figsize\"] = (9, 5)\n\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle = '--', label = 'No Skill')\npyplot.plot(LR_fpr, LR_tpr, linestyle = '-', label = 'Logistic')\n\n# axis labels\npyplot.xlabel('False Positive Rate', fontsize = 15)\npyplot.ylabel('True Positive Rate', fontsize = 15)\n\n# show the legend\npyplot.legend(fontsize = 15)\n\n# show the plot\npyplot.show()","f67fb1db":"# Creating the model\nmodel_XGB = XGBClassifier()\n\n# Training the model\nmodel_XGB.fit(train_df[features], train_df[target])","dc182fa7":"# predict probabilities\nXGB_probs = model_XGB.predict_proba(train_df[features])\n\n# keep probabilities for the positive outcome only\nXGB_probs = XGB_probs[:, 1]\n\n# calculate scores\nns_auc = roc_auc_score(train_df[target], ns_probs)\nXGB_auc = roc_auc_score(train_df[target], XGB_probs)\n\n# result print\nprint('XGBoost: ROC AUC = %.3f' % (XGB_auc * 100))","e3375b06":"# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(train_df[target], ns_probs)\nXGB_fpr, XGB_tpr, _ = roc_curve(train_df[target], XGB_probs)\n\n# figure size\nplt.rcParams[\"figure.figsize\"] = (9, 5)\n\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle = '--', label = 'No Skill')\npyplot.plot(XGB_fpr, XGB_tpr, linestyle = '-', label = 'XGBoost', color = \"red\")\n\n# axis labels\npyplot.xlabel('False Positive Rate', fontsize = 15)\npyplot.ylabel('True Positive Rate', fontsize = 15)\n\n# show the legend\npyplot.legend(fontsize = 15)\n\n# show the plot\npyplot.show()","5a7d0160":"# Creating the model\nmodel_LGBM = LGBMClassifier()\n\n# Training the model\nmodel_LGBM.fit(train_df[features], train_df[target])","c00a9f83":"# predict probabilities\nLGBM_probs = model_LGBM.predict_proba(train_df[features])\n\n# keep probabilities for the positive outcome only\nLGBM_probs = LGBM_probs[:, 1]\n\n# calculate scores\nns_auc = roc_auc_score(train_df[target], ns_probs)\nLGBM_auc = roc_auc_score(train_df[target], LGBM_probs)\n\n# result print\nprint('Logistic: ROC AUC = %.3f' % (LGBM_auc * 100))","393488be":"# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(train_df[target], ns_probs)\nLGBM_fpr, LGBM_tpr, _ = roc_curve(train_df[target], LGBM_probs)\n\n# figure size\nplt.rcParams[\"figure.figsize\"] = (9, 5)\n\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle = '--', label = 'No Skill')\npyplot.plot(LGBM_fpr, LGBM_tpr, linestyle = '-', label = 'LGBM', color = \"green\")\n\n# axis labels\npyplot.xlabel('False Positive Rate', fontsize = 15)\npyplot.ylabel('True Positive Rate', fontsize = 15)\n\n# show the legend\npyplot.legend(fontsize = 12)\n\n# show the plot\npyplot.show()","6dab6ea8":"feat_importance = pd.DataFrame()\nfeat_importance[\"feature\"] = train_df[features].columns\nfeat_importance[\"value\"] = model_LGBM.feature_importances_\nfeat_importance.sort_values(by='value', ascending=False, inplace=True)\n\nplt.figure(figsize=(8,10))\nax = sns.barplot(y=\"feature\", x=\"value\", data=feat_importance)","d1698b05":"new_feat = [\n    'timestamp',\n    'mean_accuracy', \n    'question_asked',\n    'prior_question_elapsed_time'\n]\n\ntrain_df_new = train_df[new_feat]","3080d092":"# Creating the model\nmodel_LGBM_par = LGBMClassifier(\n    objective='binary',\n    boosting='gbdt',\n    learning_rate = 0.05,\n    max_depth = 8,\n    num_leaves = 80,\n    n_estimators = 400,\n    bagging_fraction = 0.8,\n    feature_fraction = 0.9)\n\n# Training the model\nmodel_LGBM_par.fit(train_df_new, train_df[target])","e8ceccb7":"# predict probabilities\nLGBM_par_probs = model_LGBM_par.predict_proba(train_df_new)\n\n# keep probabilities for the positive outcome only\nLGBM_par_probs = LGBM_par_probs[:, 1]\n\n# calculate scores\nns_auc = roc_auc_score(train_df[target], ns_probs)\nLGBM_par_auc = roc_auc_score(train_df[target], LGBM_par_probs)\n\n# result print\nprint('Logistic: ROC AUC = %.3f' % (LGBM_par_auc * 100))","ba339720":"env = riiideducation.make_env()\n\niter_test = env.iter_test()","b5e7d6bb":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.merge(user_answers_df, how = 'left', on = 'user_id')\n    test_df = test_df.merge(content_answers_df, how = 'left', on = 'content_id')\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(value = False).astype(bool)\n    test_df.fillna(value = -1, inplace = True)\n    \n    test_df['answered_correctly'] = model_LGBM_par.predict_proba(test_df[new_feat])[:,1]\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","d03af9b1":"* The XGboost and LightGBM models showed very close accuracy, with a slight advantage for the XGboost. However, XGboost's processing time is much longer than LightGBM, which has a disadvantage.\n* With the time gain in LightGBM processing, I will adjust some parameters to see if we have an increase in accuracy.\n* But before creating a new model with new parameters, let's see which features were most important for the previous LightGBM model.","df30d58e":"### Extreme Gradient Boosting - XGBoost","aa23cbff":"<div class=\"alert alert-block alert-info\">\nShould you like this notebook or was it useful, please do UPVOTE! \ud83d\udc4d.\n<\/div>","7546b07d":"# To be continued...","3a2b0cf1":"# Model","6b2a2930":"# Exploratory Data Analysis","96166d0d":"# Preparing features","b7d17f81":"Removing the null value from the answered_correctly variable","48c48756":"# Loading Data","78825db0":"### Importing libraries","65a1cd6c":"### Training data\n\nrow_id: ID code for the row.\n\ntimestamp: the time between this user interaction and the first event from that user.\n\nuser_id: ID code for the user.\n\ncontent_id: ID code for the user interaction\n\ncontent_type_id: 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n\ntask_container_id: Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a task_container_id. Monotonically increasing for each user.\n\nuser_answer: the user's answer to the question, if any. Read -1 as null, for lectures.\n\nanswered_correctly: if the user responded correctly. Read -1 as null, for lectures.\n\nprior_question_elapsed_time: How long it took a user to answer their previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Note that the time is the total time a user took to solve all the questions in the previous bundle.\n\nprior_question_had_explanation: Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.","e702d4ce":"Since the training data is very large and the kaggle memory does not support it, so I will generate a sample of 1M observations.","bfc346d5":"### Logistic Regression","d639aaf1":"### LightGBM","d90da158":"I will use some models and compare them.","8e535692":"### Reference:\nhttps:\/\/www.kaggle.com\/isaienkov\/riiid-answer-correctness-prediction-eda-modeling","6dcede13":"## Submission","0b6f9987":"## Features overview","47b718af":"Summary table of training data. Showing data type, missing, unique values and their first three values.","13fefbf9":"# Introduction\n\nIn this competition, your challenge is to create algorithms for \"Knowledge Tracing,\" the modeling of student knowledge over time. The goal is to accurately predict how students will perform on future interactions. You will pair your machine learning skills using Riiid\u2019s EdNet data.\n\nIn this notebook we will first take a general look at the data. After the exploratory analysis of the data, I will create some models to compare their accuracy."}}