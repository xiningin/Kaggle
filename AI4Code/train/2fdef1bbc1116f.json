{"cell_type":{"4b955628":"code","e0b726f6":"code","aa236338":"code","848aee0d":"code","bef766f1":"code","1686ae81":"code","5235d197":"code","72641fc5":"code","441e9021":"code","fdc7e018":"code","05e65a6f":"code","1eb20496":"code","e9d25af4":"code","92e1edad":"code","7c2aa299":"code","056f7ece":"code","e779d305":"code","82b4a356":"code","5fae0bdf":"markdown","9afaeb8b":"markdown","10584034":"markdown","7a41a15e":"markdown","6d0f99c0":"markdown","52af0769":"markdown","eea99b67":"markdown","93c0bb45":"markdown","2d9f5f7a":"markdown","18601e14":"markdown"},"source":{"4b955628":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport matplotlib.image as mpimg\n\nfrom sklearn.model_selection import train_test_split\n\nimport pickle\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nfrom tensorflow.keras import layers","e0b726f6":"# Load the training data into a DataFrame named 'train'. \n# Print the shape of the resulting DataFrame. \n# You do not need the test data in this notebook. \n\ntrain = pd.read_csv(f'..\/input\/histopathologic-cancer-detection\/train_labels.csv', dtype=str)\n\nprint('Training Set Size:', train.shape)\n\ntrain.head()","aa236338":"# # Lets play with 1% data to check if all code works\n# # Comment this when running the entire code\n# ignore, train = train_test_split(train, test_size=0.01, random_state=1, stratify=train.label)\n# print('Training Set Size:', train.shape)","848aee0d":"train['id'] = train['id'].apply(lambda x: f'{x}.tif')\ntrain.head()","bef766f1":"(train.label.value_counts() \/ len(train)).to_frame().sort_index().T","1686ae81":"train_path = \"..\/input\/histopathologic-cancer-detection\/train\"\nprint('Training Images:', len(os.listdir(train_path)))\n\nsample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(8,8))\n\nfor i, row in sample.iterrows():\n\n    img = mpimg.imread(f'..\/input\/histopathologic-cancer-detection\/train\/{row.id}')    \n    label = row.label\n\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n        \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","5235d197":"train_df, valid_df = train_test_split(train, test_size=0.2, random_state=1, stratify=train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","72641fc5":"# Create image data generators for both the training set and the validation set. \n# Use the data generators to scale the pixel values by a factor of 1\/255. \n\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\nvalid_datagen = ImageDataGenerator(rescale=1\/255)","441e9021":"# Complete the code for the data loaders below. \n\nBATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (96,96)\n)\n\nvalid_loader = train_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (96,96)\n)","fdc7e018":"TR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","05e65a6f":"SEED = 1\n\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal_and_vertical\", seed=SEED, input_shape=(96,96,3)),\n    layers.RandomRotation(0.5, seed=SEED),\n    layers.RandomZoom(0.3, 0.3, seed=SEED),\n    layers.RandomContrast(0.3, seed=SEED),\n    layers.RandomTranslation(0.3, 0.3, seed=SEED)\n])\n\n\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\ncnn = Sequential([\n    \n    # Cropping2D(cropping=((32, 32), (32, 32)), input_shape=(96,96,3)),\n    \n    data_augmentation,\n    \n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.3),\n    BatchNormalization(),\n\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    BatchNormalization(),\n\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.4),\n    Dense(16, activation='relu'),\n    Dropout(0.3),\n    BatchNormalization(),\n    Dense(2, activation='softmax')\n])\n\ncnn.summary()","1eb20496":"# Define an optimizer and select a learning rate. \n# Then compile the model. \n\nopt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","e9d25af4":"%%time \n\n# Complete one or more training runs. \n# Display training curves after each run. \n\nh1 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 35,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1,\n    use_multiprocessing=True, \n    workers=8\n)\n\nhistory = h1.history\nprint(history.keys())","92e1edad":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","7c2aa299":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","056f7ece":"%%time \n\nh2 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 35,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1,\n    use_multiprocessing=True, \n    workers=8\n)","e779d305":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","82b4a356":"cnn.save('cancer_model_v01.h5')\npickle.dump(history, open(f'cancer_history_v01.pkl', 'wb'))","5fae0bdf":"# View Sample of Images","9afaeb8b":"# Data Generators","10584034":"# Build Network","7a41a15e":"# Train Network","6d0f99c0":"# Save Model and History","52af0769":"# Load dataset","eea99b67":"# Label Distribution","93c0bb45":"Lets update the dataset to include filename extensions","2d9f5f7a":"# Import namespaces","18601e14":"# Training Run 2"}}