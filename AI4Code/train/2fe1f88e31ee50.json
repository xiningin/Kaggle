{"cell_type":{"a3fd8d45":"code","c0abe153":"code","474fb1ae":"code","5d0f7799":"code","71ba7e65":"code","7962f80f":"code","b8153619":"code","5ca8900f":"code","91b4eacf":"code","70a35f72":"code","88c9ade9":"code","e0f206f7":"code","1a82724b":"code","272cbbf3":"code","d36242fc":"code","7b6006e0":"code","92b978f4":"markdown","0a2cd09e":"markdown","ac5730f0":"markdown","cb273bc1":"markdown","53bb3750":"markdown","e2489991":"markdown","5e3891eb":"markdown","b7c51e9d":"markdown","9316ae03":"markdown","0a2afacb":"markdown","13466906":"markdown"},"source":{"a3fd8d45":"INPUT_DIR = '\/kaggle\/input\/'\n\nTEST_SIZE = 0.3\nRANDOM_STATE = 128\n\nBATCH_SIZE = 8\nNUM_WORKERS = 0","c0abe153":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations import Normalize, Compose\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nimport glob","474fb1ae":"class RandomFaceDataset(Dataset):\n    def __init__(self, img_dirs, labels, preprocess=None):\n        '''\n        Parameters:\n            img_dirs: The directories that contain face images.\n                Each directory coresponding to a video in the original training data.\n            labels: Corresponding labels {'FAKE': 1, 'REAL', 0} of videos\n            \n        '''\n        self.img_dirs = img_dirs\n        self.labels = labels\n        self.preprocess = preprocess\n\n    def __len__(self):\n        return len(self.img_dirs)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_dir = self.img_dirs[idx]\n        label = self.labels[idx]\n        face_paths = glob.glob(f'{img_dir}\/*.png')\n\n        sample = face_paths[np.random.choice(len(face_paths))]\n        \n        face = cv2.imread(sample, 1)\n        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n\n        if self.preprocess is not None:\n            augmented = self.preprocess(image=face)\n            face = augmented['image']\n        \n        return {'face': face, 'label': np.array([label], dtype=float)}","5d0f7799":"all_train_dirs = glob.glob(INPUT_DIR + 'deepfake-detection-faces-*')\nfor i, train_dir in enumerate(all_train_dirs):\n    print('[{:02}]'.format(i), train_dir)","71ba7e65":"all_dataframes = []\nfor train_dir in all_train_dirs:\n    df = pd.read_csv(os.path.join(train_dir, 'metadata.csv'))\n    df['path'] = df['filename'].apply(lambda x: os.path.join(train_dir, x.split('.')[0]))\n    all_dataframes.append(df)\n\ntrain_df = pd.concat(all_dataframes, ignore_index=True, sort=False)","7962f80f":"train_df","b8153619":"# Remove videos that don't have any face\ntrain_df = train_df[train_df['path'].map(lambda x: os.path.exists(x))]","5ca8900f":"train_df","91b4eacf":"train_df['label'].replace({'FAKE': 1, 'REAL': 0}, inplace=True)","70a35f72":"train_df","88c9ade9":"label_count = train_df.groupby('label').count()['filename']\nprint(label_count)","e0f206f7":"X = train_df['path'].to_numpy()\ny = train_df['label'].to_numpy()","1a82724b":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)","272cbbf3":"preprocess = Compose([\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1)\n])\n\ntrain_dataset = RandomFaceDataset(\n    img_dirs=X_train,\n    labels=y_train,\n    preprocess=preprocess\n)\nval_dataset = RandomFaceDataset(\n    img_dirs=X_val,\n    labels=y_val,\n    preprocess=preprocess\n)\n\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS\n)\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS\n)","d36242fc":"for batch in tqdm(train_dataloader):\n    face_batch = batch['face']\n    label_batch = batch['label']\n    \n    print(type(face_batch), face_batch.shape)\n    print(type(label_batch), label_batch.shape)\n\n    break","7b6006e0":"for batch in tqdm(val_dataloader):\n    face_batch = batch['face']\n    label_batch = batch['label']\n    \n    print(type(face_batch), face_batch.shape)\n    print(type(label_batch), label_batch.shape)\n\n    break","92b978f4":"<a id=\"test_the_dataloaders\"><\/a>\n# Test the dataloaders\n[Back to Table of Contents](#toc)","0a2cd09e":"<a id=\"split_training_data\"><\/a>\n# Split training data\n[Back to Table of Contents](#toc)","ac5730f0":"<a id=\"get_all_train_directories\"><\/a>\n# Get all train directories\nReturn all directories that match a specific pattern\n\n[Back to Table of Contents](#toc)","cb273bc1":"<a id=\"toc\"><\/a>\n# Table of Contents\n1. [Introduction](#introduction)\n1. [Configure hyper-parameters](#configure_hyper_parameters)\n1. [Import libraries](#import_libraries)\n1. [Define useful classes](#define_useful_classes)\n1. [Get all train directories](#get_all_train_directories)\n1. [Construct DataFrame for training data](#construct_dataframe_for_training_data)\n1. [Split training data](#split_training_data)\n1. [Create datasets and dataloaders](#create_datasets_and_dataloaders)\n1. [Test the dataloaders](#test_the_dataloaders)\n1. [Conclusion](#conclusion)","53bb3750":"<a id=\"conclusion\"><\/a>\n# Conclusion\nIt's quite easy to load a bunch of datasets into a Kaggle kernel, isn't it?\nNext, let feed these faces and labels to your hungry classifier to see whether it can learn something from these FAKE and REAL faces :3\n\nI'll daily update the list of preprocessed datasets in this discussion topic -> [*Other useful datasets*](https:\/\/www.kaggle.com\/c\/deepfake-detection-challenge\/discussion\/128954).\n\nDo we truly get better classifiers when we have more data? Let's try =]]\n\n---\n[Back to Table of Contents](#toc)","e2489991":"<a id=\"introduction\"><\/a>\n# Introduction\nIn this kernel, I'll provide a simple example to demonstrate how to load data from multiple Kaggle datasets and feed all of these to a PyTorch Dataset. The custom Dataset created in this kernel is just a demo, you can modify it or create a new one to fit your own purpose.\n\nAll the datasets used in this demo was listed in this dicussion -> [*Other useful datasets*](https:\/\/www.kaggle.com\/c\/deepfake-detection-challenge\/discussion\/128954).\n\n---\n[Back to Table of Contents](#toc)","5e3891eb":"<a id=\"create_datasets_and_dataloaders\"><\/a>\n# Create datasets and dataloaders\n[Back to Table of Contents](#toc)","b7c51e9d":"<a id=\"import_libraries\"><\/a>\n# Import libraries\n[Back to Table of Contents](#toc)","9316ae03":"<a id=\"configure_hyper_parameters\"><\/a>\n# Configure hyper-parameters\n[Back to Table of Contents](#toc)","0a2afacb":"<a id=\"construct_dataframe_for_training_data\"><\/a>\n# Construct DataFrame for training data\n[Back to Table of Contents](#toc)","13466906":"<a id=\"define_useful_classes\"><\/a>\n# Define useful classes\n[Back to Table of Contents](#toc)"}}