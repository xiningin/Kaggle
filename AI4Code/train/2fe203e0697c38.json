{"cell_type":{"cc35f99c":"code","456c66e2":"code","600758dc":"code","20e0c10d":"code","0cd5ba3e":"code","6c1f89c5":"code","4b80c44d":"code","cb50e7d4":"code","3d96f771":"code","a4cd828c":"code","fd989663":"code","714d2537":"code","0cf22dd6":"code","0e7b6d89":"code","6e5d17c5":"code","e5ce1765":"code","bf13d9ec":"code","19c55ff3":"code","19becbb8":"code","4b07074c":"code","67792f2c":"code","dc671505":"code","eabf5660":"code","f02f35db":"code","ff536fe1":"code","b88a46bc":"code","7b845ee4":"code","6c93e4a0":"code","1fbc0c79":"code","b5f12c62":"code","bea9556d":"code","01ea1a5e":"code","4ba6e294":"code","370a7a0f":"code","3573fcad":"code","923bccc8":"code","871c279d":"code","67548b88":"code","1b72d6af":"code","f6d2d349":"code","4c9ce0b5":"code","0596817d":"code","f00213af":"code","26320ef1":"markdown","6653a2ab":"markdown","27587eab":"markdown","b9696e4a":"markdown","b3f99b25":"markdown","d23f35e1":"markdown","d315b639":"markdown","79e7ab0c":"markdown","9d7fb082":"markdown","d875c8c6":"markdown","f240bc90":"markdown","a3ceee06":"markdown","ae2c18c2":"markdown","6696f765":"markdown","f482176c":"markdown","f03eec99":"markdown","e45f7acb":"markdown","57793559":"markdown","beb0ac3d":"markdown","65786c93":"markdown","f325a91f":"markdown","3dfc8a09":"markdown","ac0a0a5d":"markdown","63835424":"markdown","84a38b78":"markdown","4ca95812":"markdown","ca47a98d":"markdown","9e5be85c":"markdown","67000b87":"markdown","706d44c5":"markdown","fd07079f":"markdown","1e8da32d":"markdown","84d41b1f":"markdown","59fb8d8c":"markdown","62a0ab34":"markdown","cf71b0c6":"markdown","3f60bff3":"markdown","59a75cd9":"markdown"},"source":{"cc35f99c":"# packages\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\n\n# data split\nfrom sklearn.model_selection import train_test_split\n\n# SMOTE\nfrom imblearn.over_sampling import SMOTE\n\n# scaling\nfrom sklearn.preprocessing import StandardScaler\n\n# tune\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# model Evaluation\nfrom sklearn import metrics\n\n# display HTML, Js apps\nfrom IPython.core.display import display, HTML, Javascript\n\n# plotly offline\nfrom plotly.offline import download_plotlyjs,init_notebook_mode\ninit_notebook_mode(connected=True)","456c66e2":"# data import\n\ndf = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","600758dc":"# drop the ID column\n\ndf = df.drop('id',axis=1)","20e0c10d":"# head of the data\n\ndf.head()","0cd5ba3e":"df.info()","6c1f89c5":"# stats\ndf.describe()","4b80c44d":"# pairplot\nplt.style.use('seaborn-dark')\nsns.pairplot(df,hue='stroke',palette='Dark2');\nplt.tight_layout()","cb50e7d4":"# Stroke\n\ndf[df['stroke']== 1].describe().T","3d96f771":"Stroke_plot = df['stroke'].value_counts().reset_index()\nStroke_plot.columns = ['stroke','count']\n\npx.pie(Stroke_plot,values='count',names='stroke',template='plotly',title='Stroke')","a4cd828c":"%%HTML\n<div class='tableauPlaceholder' id='viz1616573055765' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;St&#47;StrokedatasetEDA&#47;Stroke_Dashboard_2&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='StrokedatasetEDA&#47;Stroke_Dashboard_2' \/><param name='tabs' value='yes' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;St&#47;StrokedatasetEDA&#47;Stroke_Dashboard_2&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1616573055765');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.minHeight='1500px';vizElement.style.maxHeight=(divElement.offsetWidth*1.77)+'px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","fd989663":"plt.figure(figsize=(10,6))\nsns.set_context(context='notebook',font_scale=1.2)\nsns.heatmap(df[['age','avg_glucose_level','bmi']].corr(method='pearson'),cmap='Blues',annot=True);\nplt.tight_layout()","714d2537":"cat_columns = ['gender','hypertension', 'heart_disease', 'ever_married',\n       'work_type', 'Residence_type','smoking_status','stroke']\n\nnum_columns = ['age','avg_glucose_level','bmi']","0cf22dd6":"# visual check for to ensure null values are not represented with other values like -999, -1, ?,-111\n\nfor feature in df[cat_columns].columns:\n    print('\\n ')\n    print('*************','Column name:',feature,'*************')\n    print('1. Unique vlaues:',df[feature].unique())\n    print(' ')\n    print('2. Min values:',df[feature].min())\n    print(' ')\n    print(df[feature].value_counts(1)*100)\n    print(' ')\n    print('**************************************************')\n    print('***************-end-******************************')\n    print('\\n ')","0e7b6d89":"# num., columns\n\nfor feature in df[num_columns].columns:\n    print('*******','Column name:',feature,'*******')\n    \n    print('Min values:',df[feature].min())\n      \n    print('***********-end-***********')\n    print('\\n')","6e5d17c5":"# convert string to numeric using map\n\n# gender\ndf['gender'] = df['gender'].map({\n'Male': int(0),\n'Female':int(1),\n'Other':int(2)})\n\n# ever_married\ndf['ever_married'] = df['ever_married'].map({\n'Yes':int(1), \n'No':int(0)})\n\n# work_type\ndf['work_type'] = df['work_type'].map({\n'Private':int(3), \n'Self-employed':int(4),\n'Govt_job':int(2), \n'children':int(1), \n'Never_worked':int(0)})\n\n# Residence_type\ndf['Residence_type'] = df['Residence_type'].map({\n'Urban':int(2), \n'Rural':int(1)})\n\n# smoking_status\ndf['smoking_status'] = df['smoking_status'].map({\n'formerly smoked':int(1),\n'never smoked':int(2), \n'smokes':int(3),\n'Unknown':int(0)})","e5ce1765":"df.info()","bf13d9ec":"# missing values\nmissing_value = 100 * df.isnull().sum()\/len(df)\nmissing_value = missing_value.reset_index()\nmissing_value.columns = ['variables','missing values in percentage']\nmissing_value = missing_value.sort_values('missing values in percentage',ascending=False)\n\n# barplot\nfig = px.bar(missing_value, y='missing values in percentage',x='variables',title='Missing values % in each column',\n             template='ggplot2',text='missing values in percentage');\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\n\nfig.show()","19c55ff3":"# missing values imputation\n\ndf['bmi'] = df['bmi'].fillna(df['bmi'].mean())","19becbb8":"# check for null values\n\ndf.isna().sum()","4b07074c":"# checking for duplicates\n\ndup = df.duplicated()\ndup.sum()","67792f2c":"# outlier\n#\"\"\"\nplt.style.use('fivethirtyeight')\noutlier= df.plot(kind='box',figsize=(20,7));\nplt.xticks(rotation=70);\nplt.title('Outlier in data');\n\n#\"\"\"","dc671505":"#\"\"\"\ndef treat_outlier(x):\n    sorted(x)\n    q1,q3=np.percentile(x,[25,75])\n    iqr=q3-q1\n    l_r=q1-(1.5*iqr)\n    u_r=q3+(1.5*iqr)\n    return l_r,u_r  \n#\"\"\"","eabf5660":"\n#\"\"\"\n\nfor i in df[num_columns].columns:\n    lr,ur = treat_outlier(df[i])\n    df[i] = np.where(df[i]>ur,ur,df[i])\n    df[i] = np.where(df[i]<lr,lr,df[i])\n#\"\"\"","f02f35db":"# outlier\n\nplt.style.use('fivethirtyeight')\noutlier= df.plot(kind='box',figsize=(20,7));\nplt.xticks(rotation=70);\nplt.title('Outlier in data');","ff536fe1":"## drop target variable for training\n\nX = df.drop(['stroke'],axis = 1)\ny = df.pop('stroke')","b88a46bc":"## data split\n\nX_train, X_test,y_train,y_test = train_test_split(X, y,test_size=0.30,random_state=1)","7b845ee4":"## before oversampling\n\nplt.figure(figsize=(7,4))\nsns.countplot(x=y_train);\nplt.title(' before oversampling');\nprint(y_train.value_counts(1)*100)## percentage of Stroke labels","6c93e4a0":"## SMOTE oversampling\n\nSMOTE_oversample = SMOTE(random_state=1)\nX_train,y_train = SMOTE_oversample.fit_resample(X_train, y_train.ravel())","1fbc0c79":"## Scaling data\n\nsc = StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","b5f12c62":"from sklearn.tree import DecisionTreeClassifier\n\nDT_model= DecisionTreeClassifier()\n\n# fit the model\nDT_model.fit(X_train,y_train)\n\n# model score\npredict_train_DT = DT_model.predict(X_train)\npredict_test_DT = DT_model.predict(X_test)\n\n# accuracy score\nDT_train_score = DT_model.score(X_train,y_train)\nDT_test_score = DT_model.score(X_test,y_test)\n\n# f1-score\nDT_f1_score = metrics.f1_score(y_test, predict_test_DT)\n\nprint('Accuracy on Train set',DT_train_score)\nprint('Accuracy on Test set',DT_test_score)\nprint('F1-score on Test set:',DT_f1_score)\nprint('\\n')\nprint(metrics.classification_report(y_test, predict_test_DT))","bea9556d":"from sklearn.ensemble import RandomForestClassifier\n\n# create object model\nRF_model = RandomForestClassifier()\n\n# fit the model\nRF_model.fit(X_train,y_train)\n\n# model score\npredict_train_RF = RF_model.predict(X_train)\npredict_test_RF = RF_model.predict(X_test)\n\n# accuracy score\nRF_train_score = RF_model.score(X_train,y_train)\nRF_test_score = RF_model.score(X_test,y_test)\n\n# f1-score\nRF_f1_score = metrics.f1_score(y_test,predict_test_RF)\n\nprint('Accuracy on Train set',RF_train_score)\nprint('Accuracy on Test set',RF_test_score)\nprint('F1-score on Test set:',RF_f1_score)\nprint(metrics.classification_report(y_test,predict_test_RF))","01ea1a5e":"from sklearn.linear_model import LogisticRegression\n\nLR_model = LogisticRegression(max_iter=2000)\n\n# fit the model\nLR_model.fit(X_train, y_train)\n\ny_predict_LR = LR_model.predict(X_test)\n\n# model score\npredict_train_LR = LR_model.predict(X_train)\npredict_test_LR = LR_model.predict(X_test)\n\n# accuracy score\nLR_train_score = LR_model.score(X_train,y_train)\nLR_test_score = LR_model.score(X_test,y_test)\n\n# f1-score\nLR_f1_score = metrics.f1_score(y_test,predict_test_LR)\nLR_recall = metrics.recall_score(y_test,predict_test_LR)\n\nprint('Accuracy on Train set',LR_train_score)\nprint('Accuracy on Test set',LR_test_score)\nprint('F1-score on Test set:',LR_f1_score)\nprint(metrics.classification_report(y_test, predict_test_LR))","4ba6e294":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n\nLDA = LinearDiscriminantAnalysis(solver='svd')\n\n# fit the model\nLDA.fit(X_train, y_train)\n\ny_predict_LDA = LDA.predict(X_test)\n\n# model score\npredict_train_LDA = LDA.predict(X_train)\npredict_test_LDA = LDA.predict(X_test)\n\n# accuracy score\nLDA_train_score = LDA.score(X_train,y_train)\nLDA_test_score = LDA.score(X_test,y_test)\n\n# f1-score\nLDA_f1_score = metrics.f1_score(y_test,predict_test_LDA)\nLDA_recall = metrics.recall_score(y_test, predict_test_LDA)\n\nprint('Accuracy on Train set',LDA_train_score)\nprint('Accuracy on Test set',LDA_test_score)\nprint('F1-score on Test set:',LDA_f1_score)\nprint(metrics.classification_report(y_test, predict_test_LDA))\n","370a7a0f":"from sklearn.naive_bayes import GaussianNB\n\nNB_model = GaussianNB()\n\n# fit the model\nNB_model.fit(X_train, y_train)\n\ny_predict_NB = NB_model.predict(X_test)\n\n# model score\npredict_train_NB = NB_model.predict(X_train)\npredict_test_NB = NB_model.predict(X_test)\n\n# accuracy score\nNB_train_score = NB_model.score(X_train,y_train)\nNB_test_score = NB_model.score(X_test,y_test)\n\n# f1-score\nNB_f1_score = metrics.f1_score(y_test,predict_test_NB)\nNB_recall = metrics.recall_score(y_test, predict_test_NB)\n\nprint('Accuracy on Train set',NB_train_score)\nprint('Accuracy on Test set',NB_test_score)\nprint('F1-score on Test set:',NB_f1_score)\nprint(metrics.classification_report(y_test, predict_test_NB))\n","3573fcad":"from sklearn.model_selection import GridSearchCV\n\n#\"\"\"\nparameters= {'max_depth':[7,10],\n            'max_features':[4,5,6],\n            'min_samples_split' : [90,100],\n            'min_samples_leaf' : [20,30]}\n\n\nDT = RandomForestClassifier()\n\nDT_model_tune = GridSearchCV(DT, param_grid = parameters, cv=3)\n\nDT_model_tune.fit(X_train,y_train)","923bccc8":"DT_model_tune.best_params_","871c279d":"DT_model_tune= DecisionTreeClassifier(min_samples_split=90,min_samples_leaf= 20,\n max_features= 6,max_depth=10)\n\n# fit the model\nDT_model_tune.fit(X_train,y_train)\n\n# model score\npredict_train_DT = DT_model_tune.predict(X_train)\npredict_test_DT = DT_model_tune.predict(X_test)\n\n# accuracy score\nDT_train_score = DT_model_tune.score(X_train,y_train)\nDT_test_score = DT_model_tune.score(X_test,y_test)\n\n# f1-score\nDT_f1_score = metrics.f1_score(y_test, predict_test_DT)\nDT_recall = metrics.recall_score(y_test, predict_test_DT)\n\nprint('Accuracy on Train set',DT_train_score)\nprint('Accuracy on Test set',DT_test_score)\nprint('F1-score on Test set:',DT_f1_score)\nprint('\\n')\nprint(metrics.classification_report(y_test, predict_test_DT))","67548b88":"from sklearn.model_selection import RandomizedSearchCV\n\n# to get best parameters\n\n# fine Tune the model using RandomizedSearchCV\n\n#\"\"\"\nparameters= {'n_estimators':[400,500],\n            'max_depth':[7,10],\n            'max_features':[4,5],\n            'min_samples_split' : [100,150],\n            'min_samples_leaf' : [30,40]}\n\n\nrf = RandomForestClassifier()\n\nrf_model_tune = RandomizedSearchCV(rf, param_distributions = parameters, cv=3,n_iter = 20, verbose=2, random_state=42)\n\nrf_model_tune.fit(X_train,y_train)\n\n#\"\"\"","1b72d6af":"rf_model_tune.best_params_","f6d2d349":"# finding best parameters are iterative process\n\n## n_estimators= 400,min_samples_split= 100,min_samples_leaf=30,max_features= 6,max_depth=11,bootstrap= False ## f1-score .228\n\n# create object model\nRF_model = RandomForestClassifier(n_estimators= 400,min_samples_split= 100,min_samples_leaf=30,max_features= 6,max_depth=11,bootstrap= False)\n\n# fit the model\nRF_model.fit(X_train,y_train)\n\n# model score\npredict_train_RF = RF_model.predict(X_train)\npredict_test_RF = RF_model.predict(X_test)\n\n# accuracy score\nRF_train_score = RF_model.score(X_train,y_train)\nRF_test_score = RF_model.score(X_test,y_test)\n\n# f1-score\nRF_f1_score = metrics.f1_score(y_test,predict_test_RF)\nRF_recall = metrics.recall_score(y_test,predict_test_RF)\nprint('Accuracy on Train set',RF_train_score)\nprint('Accuracy on Test set',RF_test_score)\nprint('F1-score on Test set:',RF_f1_score)\nprint(metrics.classification_report(y_test,predict_test_RF))","4c9ce0b5":"feature_score = pd.DataFrame(RF_model.feature_importances_, index =df.columns,  columns=['Feature_importance']).sort_values('Feature_importance', ascending=False)\n\nplt.rcParams.update({'font.size': 22})\nplt.style.use('fivethirtyeight')\nfeature_score.plot(kind='bar',figsize=(10,6));\nplt.xticks(rotation=70);\nplt.title('Feature Importance Random forest');","0596817d":"model_compare = pd.DataFrame({\n    \n'Models':['Desicion Tree','RandomForestClassifier','LogisticRegression','LinearDiscriminantAnalysis','Naive_Bayes'],\n'f1_score':[DT_f1_score, RF_f1_score, LR_f1_score, LDA_f1_score, NB_f1_score],\n'recall':[DT_recall, RF_recall, LR_recall, LDA_recall, NB_recall],\n'Accuracy on train set':[DT_train_score,RF_train_score,LR_train_score,LDA_train_score,NB_train_score],\n'Accuracy on test set':[DT_test_score, RF_test_score,LR_test_score,LDA_test_score,NB_test_score]\n\n})\n\nmodel_compare = model_compare.sort_values('recall',ascending=False)","f00213af":"model_compare.style.background_gradient(cmap='Greens')","26320ef1":"* <a href=\"#packages\">1.1.Packages<\/a> \n* <a href=\"#EDA\">1.2.EDA<\/a>\n* <a href=\"#Tableau-dashboard\">1.3.Tableau_dashboard<\/a>\n* <a href=\"#preprocessing\">1.4.preprocessing<\/a>\n* <a href=\"#Modeling\">2.1.Modeling<\/a>\n* <a href=\"#feature-Importance\">2.2.feature_Importance<\/a>\n* <a href=\"#Model-comparison\">2.3.Model_comparison<\/a>\n* <a href=\"#Reference\">2.4.Reference<\/a>","6653a2ab":"# <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">Stroke predicton\n\n## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">Objective\n    \n    \n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">To build the model which predicts the stroke","27587eab":"# Thank you!!! and feel free to post your suggestions","b9696e4a":"# Model comparison\n\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> here our objective is higher f1-score and f1-score is mean of precision and  recall\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> we also need higher recall because the problem we are dealing with does need more True Positive\n","b3f99b25":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> iv. Linear Discriminant Analysis","d23f35e1":"## insights\n* we can see that there is a high-class imbalance in the above pair plot nearly one or two redpoint which represent the stroke that can cause the issue in the model which we create\n* we can solve this issue using statistical oversampling or under-sampling methods, here can use SMOTE\n* In the above Age vs BMI, we can observe that if the age is above 55 and BMI above 30 has a higher chance of stroke and referring average BMI is 18.5 \u2013 24.9 which is normal weight\n* The higher the age more the chance of stroke","d315b639":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#02BFB3;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:0.10px\">\n<p style=\"padding: 25px;\n              color:white;\n          text-align:center;\">1.1 Packages\n<\/p>\n<\/div>","79e7ab0c":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> iv. Outliers","9d7fb082":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#02BFB3;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:0.10px\">\n<p style=\"padding: 25px;\n            color:white;\n          text-align:center;\">Index\n<\/p>\n<\/div>","d875c8c6":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#02BFB3;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:0.10px\">\n<p style=\"padding: 25px;\n              color:white;\n          text-align:center;\">Tableau dashboard\n<\/p>\n<\/div>","f240bc90":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> v. data split","a3ceee06":"# EDA","ae2c18c2":"<div style=\"color:white;\n           display:fill;\n           border-radius:15px;\n           background-color:#02BFB3;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:0.10px\">\n<p style=\"padding: 25px;\n              color:white;\n          text-align:center;\">1.4 Preprocessing\n<\/p>\n<\/div>","6696f765":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> ii. Random forest","f482176c":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> ii. RandomForestClassifier","f03eec99":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> i. Desicion Tree model","e45f7acb":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> ii.Data Encoding","57793559":"## stroke","beb0ac3d":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> iii. LogisticRegression","65786c93":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">vi. Oversampling","f325a91f":"* Tableau Tutorial https:\/\/www.youtube.com\/watch?v=6mBtTNggkUk\n* https:\/\/www.mygreatlearning.com\/blog\/linear-discriminant-analysis-or-lda\/  LDA part\n","3dfc8a09":"* We can observer that age variable has some minimum values of 0.080 which shows us that this not sutiable value for age and we need a data cleaning","ac0a0a5d":"# Tableau dashboard","63835424":"<div style=\"color:white;\n           display:fill;\n           border-radius:25px;\n           background-color:#02BFB3;\n           font-size:220%;\n           font-family:Arial;\n           letter-spacing:0.5px\">\n<p style=\"padding: 25px;\n              color:white;\">1.2 Exploratory data analysis\n<\/p>\n<\/div>\n","84a38b78":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">vii. Scaling","4ca95812":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> i. Desicion Tree model","ca47a98d":"# Modeling\n\n\n\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">i.  Desicion tree\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">ii. Random forest\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">iii.LogisticRegression\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">iv. Linear Discriminant Analysis\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">V. Naive bayes","9e5be85c":"\n* <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">Data set is higly imbalanced stroke instance 4.87% and normal is 95.1%","67000b87":"# Tune the model \ud83c\udf9b\ud83c\udfaf","706d44c5":"* people who had a stroke have a mean age of 67 and a BMI of above 30","fd07079f":"# feature Importance\n\n* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\">Feature importance of Random forest shows us which are feature are most help full to predict the target or output","1e8da32d":"# packages","84d41b1f":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> V. Naive bayes","59fb8d8c":"# Preprocessing\n\n## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> i. Data cleaning","62a0ab34":"# Reference\n","cf71b0c6":"* <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> linear Discriminant Analysis and Logistic regression has the balance of f1-score and recall score","3f60bff3":"## <span style=\"font-family: Arial;font-size:1.2em;color:#0B58E8\"> iii. Missing values","59a75cd9":"# Correlation"}}