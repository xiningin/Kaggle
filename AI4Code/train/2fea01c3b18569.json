{"cell_type":{"0af8a5a3":"code","1397748a":"code","6d5b826f":"code","2cf7a83f":"code","cad5622d":"code","1974a9e0":"code","33356770":"code","7f5ed2cc":"code","4d4712c5":"code","455806e6":"code","4fdb545b":"code","6eff8afb":"code","a5f12a16":"code","c535b889":"code","ff6c95d5":"code","6744d462":"code","5d312f54":"code","afbc3539":"code","ce53f7a7":"code","b56266cb":"code","63238209":"code","32c02972":"code","f6b87d33":"code","bf71515d":"code","4cf0402d":"code","3fca7917":"code","0d9303eb":"code","106c5835":"code","ca7e776e":"code","a9fffd81":"code","6fdff157":"code","cb709efe":"code","3efb590e":"code","acb67c7b":"code","90f4591d":"code","7541bbbc":"code","fe41f736":"code","16c31e27":"code","5bb686cd":"code","92345dfb":"code","54d90dc7":"code","a712cde5":"code","0adddf42":"code","11b7d0e5":"code","3a2ac446":"code","75f59ac1":"code","546bd310":"markdown","cbfa4f51":"markdown"},"source":{"0af8a5a3":"# \u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0434\u043b\u044f \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438\n# Required for visualization\n!pip install pycocotools","1397748a":"# \u041d\u0443\u0436\u043d\u043e \u0434\u043b\u044f \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0440\u0430\u0437\u043c\u0435\u0440\u0430 bbox \u043f\u0440\u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0438 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n# Needed to resize bbox when resizing image\n!pip install ..\/input\/biblioteki\/bibliot\/albumentations-0.5.2","6d5b826f":"import csv\nimport numpy as np\nimport json\nimport ast\nimport pandas as pd\nimport datetime\nimport cv2\nimport albumentations as A","2cf7a83f":"# \u041e\u0442\u0431\u0438\u0440\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0438\u043c\u0435\u044e\u0442\u0441\u044f \u0434\u0430\u043d\u043d\u044b\u0435 \u043e \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u0445 BBOX\n# Selecting images for which there is data on BBOX coordinates\ntr = pd.read_csv('..\/input\/binary-csv\/bincsv\/train_binary.csv')\nvl = pd.read_csv('..\/input\/binary-csv\/bincsv\/val_binary.csv')\nvl.loc[vl['id']=='2f12dbb2caf2']","cad5622d":"# For training with 4 classes\ntr = tr[(tr['label_encoded']>0) & (tr['label']!='none 1 0 0 1 1')]\ntr","1974a9e0":"# For training with 2 classes\ntr = tr[(tr['binary_label']>0) & (tr['label']!='none 1 0 0 1 1')]\ntr","33356770":"tr.to_csv('.\/tr_last.csv', index=False)","7f5ed2cc":"len(tr)","4d4712c5":"# For training with 4 classes\nvl = vl[(vl['label_encoded']>0) & (vl['label']!='none 1 0 0 1 1')]","455806e6":"# For training with 2 classes\nvl = vl[(vl['binary_label']>0) & (vl['label']!='none 1 0 0 1 1')]","4fdb545b":"vl.to_csv('.\/vl_last.csv', index=False)","6eff8afb":"len(vl)","a5f12a16":"tr = pd.read_csv('.\/tr_last.csv')\nvl = pd.read_csv('.\/vl_last.csv')\nvl.loc[vl['id']=='2f12dbb2caf2']","c535b889":"# Labels for classification\n# \u041c\u0435\u0442\u043a\u0438 \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\nlabels = {\n0:\"Negative for Pneumonia\",\n1:\"Typical Appearance\",\n2:\"Indeterminate Appearance\",\n3:\"Atypical Appearance\"}","ff6c95d5":"# Labels for classification\n# \u041c\u0435\u0442\u043a\u0438 \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\nlabels = {\n0:\"negative\",\n1:\"opacity\"}","6744d462":"now = datetime.datetime.now()\n\ndata = dict(\n    images=[\n        # license, url, file_name, height, width, date_captured, id\n    ],\n    type='instances',\n    annotations=[\n        # segmentation, area, iscrowd, image_id, bbox, category_id, id\n    ],\n    categories=[\n        # supercategory, id, name\n    ],\n)","5d312f54":"class_name_to_id = {}\nfor i, each_label in enumerate(labels):\n    class_name = each_label\n    class_id = i\n    class_name_to_id[class_name] = class_id\n    data['categories'].append(dict(\n        supercategory=None,\n        id=class_id,\n        name=str(class_name),\n    ))","afbc3539":"data","ce53f7a7":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u044b \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 API:\n# encode - \u041a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0434\u0432\u043e\u0438\u0447\u043d\u044b\u0435 \u043c\u0430\u0441\u043a\u0438 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e RLE.\n# decode - \u0434\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0434\u0432\u043e\u0438\u0447\u043d\u044b\u0435 \u043c\u0430\u0441\u043a\u0438, \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e RLE.\n# merge - \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0438\u043b\u0438 \u043f\u0435\u0440\u0435\u0441\u0435\u0447\u0435\u043d\u0438\u0435 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u043c\u0430\u0441\u043e\u043a.\n# iou - \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u044c \u043f\u0435\u0440\u0435\u0441\u0435\u0447\u0435\u043d\u0438\u0435 \u043f\u043e \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044e \u043c\u0430\u0441\u043e\u043a.\n# area - \u0420\u0430\u0441\u0447\u0435\u0442\u043d\u0430\u044f \u043e\u0431\u043b\u0430\u0441\u0442\u044c \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u043c\u0430\u0441\u043e\u043a.\n# toBbox - \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0438\u0432\u0430\u044e\u0449\u0438\u0435 \u0440\u0430\u043c\u043a\u0438, \u043e\u043a\u0440\u0443\u0436\u0430\u044e\u0449\u0438\u0435 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u0430\u0441\u043a\u0438.\n# frPyObjects - \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043c\u043d\u043e\u0433\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u0438\u043a\u0430, bbox \u0438 \u043d\u0435\u0441\u0436\u0430\u0442\u043e\u0433\u043e RLE \u0432 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0443\u044e \u043c\u0430\u0441\u043a\u0443 RLE.\n\n#  Rs     = encode( masks )\n#  masks  = decode( Rs )\n#  R      = merge( Rs, intersect=false )\n#  o      = iou( dt, gt, iscrowd )\n#  a      = area( Rs )\n#  bbs    = toBbox( Rs )\n#  Rs     = frPyObjects( [pyObjects], h, w )\n\n# In the API the following formats are used:\n#  Rs      - [dict] Run-length encoding of binary masks\n#  R       - dict Run-length encoding of binary mask\n#  masks   - [hxwxn] Binary mask(s) (must have type np.ndarray(dtype=uint8) in column-major order)\n#  iscrowd - [nx1] list of np.ndarray. 1 indicates corresponding gt image has crowd region to ignore\n#  bbs     - [nx4] Bounding box(es) stored as [x y w h]\n#  poly    - Polygon stored as [[x1 y1 x2 y2...],[x1 y1 ...],...] (2D list)\n#  dt,gt   - May be either bounding boxes or encoded masks\n# Both poly and bbs are 0-indexed (bbox=[0 0 1 1] encloses first pixel).","b56266cb":"# JSON \u0434\u043b\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 512*512\n# JSON for 512 * 512 images\ntrain_out_file = '.\/train_1280_annotations.json'\nval_out_file = '.\/val_1280_annotations.json'\ndata_val = data.copy()\ndata_val['images'] = []\ndata_val['annotations'] = []\ndata_train = data.copy()\ndata_train['images'] = []\ndata_train['annotations'] = []\n# JSON \u0434\u043b\u044f \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n# JSON original images\ntrain_original_out_file = '.\/train_annotations.json'\nval_original_out_file = '.\/val_annotations.json'\ndata_original_val = data.copy()\ndata_original_val['images'] = []\ndata_original_val['annotations'] = []\ndata_original_train = data.copy()\ndata_original_train['images'] = []\ndata_original_train['annotations'] = []","63238209":"len(tr)","32c02972":"im_size = 512","f6b87d33":"# \u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0442\u043e\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 bbox\n# Image transformer and bbox\ntransform = A.Compose(\n    [\n        A.Resize(height = im_size , width = im_size, p=1),\n    ], \n    p=1.0,  bbox_params=A.BboxParams( format='coco', min_area=0,  min_visibility=0, label_fields=['labels']  ))        ","bf71515d":"for idx in range(len(tr)):\n    image_id = tr.iloc[idx].id\n    class_id = tr.iloc[idx].label_encoded #binary_label\n    path = tr.iloc[idx].path\n    img = cv2.imread((path), cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#.astype(np.float32)\n    width = im_size #int(tr.iloc[idx].w)\n    height = im_size #int(tr.iloc[idx].h)\n    data_train['images'].append(dict(\n            file_name = image_id+'.png',\n            width = width,\n            height = height,\n            date_captured=None,\n            id=int(idx)))\n\n    try:\n        a = tr.iloc[idx].boxes\n        boxes = ast.literal_eval(a)\n        for box in boxes:\n            x1= float(box['x'])\n            y1 = float(box['y'])\n            w = float(box['width'])\n            h = float(box['height'])\n            bb = []\n            bbox = [\n                    int(x1),\n                    int(y1),\n                    int(w),\n                    int(h)]\n            bb.append(bbox)\n            a = int(class_id)\n            b = str(class_id)\n            ct = {f'{a}:{b}'}\n            sample = transform(image=img, bboxes=bb, labels=b)\n            tr_boxes = sample['bboxes']\n            x_1 = tr_boxes[0][0]\n            y_1 = tr_boxes[0][1]\n            w_1 = tr_boxes[0][2]\n            h_1 = tr_boxes[0][3]\n            b_b = [int(x_1), int(y_1), int(w_1), int(h_1)]\n            tr_labels = sample['labels']\n            area = (w_1)*(h_1)\n            data_train['annotations'].append(dict(id=len(data_train['annotations']),\n                                                          area=round(area,3), \n                                                          bbox=b_b,\n                                                          iscrowd= 0, #1,\n                                                          image_id=int(idx),\n                                                          category_id=int(tr_labels[0])))\n                                                          #segmentation = rl ))\n    except ValueError:\n        print(image_id)\n    \n#     with open(train_out_file, 'w') as f:\n#         json.dump(data_train, f, indent=4)","4cf0402d":"data_train","3fca7917":"def myconverter(obj):\n    if isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, datetime.datetime):\n        return obj.__str__()","0d9303eb":"with open(train_out_file, 'w') as f:\n    json.dump(data_train, f, default=myconverter)#indent=4)","106c5835":"for idx in range(len(vl)):\n    image_id = vl.iloc[idx].id\n    class_id = vl.iloc[idx].label_encoded #binary_label\n    path = vl.iloc[idx].path\n    img = cv2.imread((path), cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#.astype(np.float32)\n    width = im_size #int(vl.iloc[idx].w)\n    height = im_size #int(vl.iloc[idx].h)\n    data_val['images'].append(dict(\n            file_name = image_id+'.png',\n            width = width,\n            height = height,\n            date_captured=None,\n            id=int(idx)))\n\n    try:\n        a = vl.iloc[idx].boxes\n        boxes = ast.literal_eval(a)\n        for box in boxes:\n            x1= float(box['x'])\n            y1 = float(box['y'])\n            w = float(box['width'])\n            h = float(box['height'])\n            bb = []\n            bbox = [\n                    int(x1),\n                    int(y1),\n                    int(w),\n                    int(h)]\n            bb.append(bbox)\n            a = int(class_id)\n            b = str(class_id)\n            ct = {f'{a}:{b}'}\n            sample = transform(image=img, bboxes=bb, labels=b)\n            vl_boxes = sample['bboxes']\n            x_1 = vl_boxes[0][0]\n            y_1 = vl_boxes[0][1]\n            w_1 = vl_boxes[0][2]\n            h_1 = vl_boxes[0][3]\n            b_b = [int(x_1), int(y_1), int(w_1), int(h_1)]\n            vl_labels = sample['labels']\n            area = (w_1)*(h_1)\n            data_val['annotations'].append(dict(id=len(data_val['annotations']),\n                                                          area=round(area,3), \n                                                          bbox=b_b,\n                                                          iscrowd= 0, #1,\n                                                          image_id=int(idx),\n                                                          category_id=int(vl_labels[0])))\n                                                          #segmentation = rl ))\n    except ValueError:\n        print(image_id)\n    \n#     with open(train_out_file, 'w') as f:\n#         json.dump(data_train, f, indent=4)","ca7e776e":"data_val","a9fffd81":"def myconverter(obj):\n    if isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, datetime.datetime):\n        return obj.__str__()","6fdff157":"with open(val_out_file, 'w') as f:\n    json.dump(data_val, f, default=myconverter)#indent=4)","cb709efe":"len(tr)","3efb590e":"for idx in range(len(tr)):\n    image_id = tr.iloc[idx].id\n    class_id = tr.iloc[idx].label_encoded\n    width = int(tr.iloc[idx].w)\n    height = int(tr.iloc[idx].h)\n    data_original_train['images'].append(dict(\n            file_name = image_id+'.jpg',\n            width = width,\n            height = height,\n            date_captured=None,\n            id=int(idx)))\n\n    try:\n        a = tr.iloc[idx].boxes\n        boxes = ast.literal_eval(a)\n        for box in boxes:\n            x1= float(box['x'])\n            y1 = float(box['y'])\n            w = float(box['width'])\n            h = float(box['height'])\n            bbox =[\n                    x1,\n                    y1,\n                    w,\n                    h]\n            area = (w)*(h)\n            data_original_train['annotations'].append(dict(id=len(data_original_train['annotations']),\n                                                      area=area, \n                                                      bbox=bbox,\n                                                      iscrowd= 0, #1,\n                                                      image_id=int(idx),\n                                                      category_id=int(class_id)))\n                                                      #segmentation = rl ))\n    except ValueError:\n        print(image_id)\n    \n#     with open(train_out_file, 'w') as f:\n#         json.dump(data_train, f, indent=4)","acb67c7b":"data_original_train","90f4591d":"def myconverter(obj):\n    if isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, datetime.datetime):\n        return obj.__str__()","7541bbbc":"with open(train_original_out_file, 'w') as f:\n    json.dump(data_original_train, f, default=myconverter)#indent=4)","fe41f736":"len(vl)","16c31e27":"for idx in range(len(vl)):\n    image_id = vl.iloc[idx].id\n    class_id = vl.iloc[idx].label_encoded\n    width = int(vl.iloc[idx].w)\n    height = int(vl.iloc[idx].h)\n    data_original_val['images'].append(dict(\n            file_name = image_id+'.jpg',\n            width = width,\n            height = height,\n            date_captured=None,\n            id=int(idx)))\n\n    try:\n        a = vl.iloc[idx].boxes\n        boxes = ast.literal_eval(a)\n        for box in boxes:\n            x1= float(box['x'])\n            y1 = float(box['y'])\n            w = float(box['width'])\n            h = float(box['height'])\n            bbox =[\n                    x1,\n                    y1,\n                    w,\n                    h]\n            area = (w)*(h)\n            data_original_val['annotations'].append(dict(id=len(data_original_val['annotations']),\n                                                      area=area, \n                                                      bbox=bbox,\n                                                      iscrowd= 0, #1,\n                                                      image_id=int(idx),\n                                                      category_id=int(class_id)))\n                                                      #segmentation = rl ))\n    except ValueError:\n        print(image_id)\n    \n#     with open(train_out_file, 'w') as f:\n#         json.dump(data_train, f, indent=4)","5bb686cd":"data_original_val","92345dfb":"def myconverter(obj):\n    if isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, datetime.datetime):\n        return obj.__str__()","54d90dc7":"with open(val_original_out_file, 'w') as f:\n    json.dump(data_original_val, f, default=myconverter)#indent=4)","a712cde5":"# \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f\n# Visualization\nfrom pycocotools.coco import COCO\nimport cv2\nfrom matplotlib import pyplot as plt","0adddf42":"BOX_COLOR = (255, 0, 0) # Red\nTEXT_COLOR = (255, 255, 255) # White\n\n\ndef visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n    \"\"\"Visualizes a single bounding box on the image\"\"\"\n    x_min, y_min, w, h = bbox\n    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n\n    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n\n    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n    cv2.putText(\n        img,\n        text=class_name,\n        org=(x_min, y_min - int(0.3 * text_height)),\n        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n        fontScale=0.35, \n        color=TEXT_COLOR, \n        lineType=cv2.LINE_AA,\n    )\n    return img","11b7d0e5":"def visualize(image, bboxes, category_ids, category_id_to_name):\n    img = image.copy()\n    for bbox, category_id in zip(bboxes, category_ids):\n        class_name = category_id_to_name[category_id]\n        img = visualize_bbox(img, bbox, class_name)\n    plt.figure(figsize=(12, 12))\n    plt.axis('off')\n    plt.imshow(img)","3a2ac446":"json_file = '.\/train_512_annotations.json'","75f59ac1":"font = cv2.FONT_HERSHEY_PLAIN\ncoco=COCO(json_file)\ncats = coco.loadCats(coco.getCatIds())\nids = list(sorted(coco.imgs.keys()))\nimg_id = ids[617]\nann_ids = coco.getAnnIds(imgIds=img_id) # \u043d\u043e\u043c\u0435\u0440\u0430 \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0439 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441 \u0431\u043e\u043a\u0441\u0430\u043c\u0438 \u0438 \u043f\u0440\ncoco_annotation = coco.loadAnns(ann_ids)\npath = coco.loadImgs(img_id)[0]['file_name']\nclasses = [obj[\"category_id\"] for obj in coco_annotation]\n\nimg = cv2.imread(f'..\/input\/coco-512\/siim_512\/train_512\/{path}', cv2.IMREAD_COLOR)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nnum_objs = len(coco_annotation)\nboxes = [] # \u0441\u043f\u0438\u0441\u043e\u043a \u0431\u043e\u043a\u0441\u043e\u0432 \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 \u0432\u043e\u043a \u04451,\u04431,\u04452,\u04432\ncats = coco.loadCats(classes)# \u041d\u0430\u0439\u0442\u0438 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044e \u043f\u043e \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0443 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438\nc = []\nd = []\nfor cat in cats:\n    a = cat['id']\n    b = cat['name']\n    c.append(a)\n    d.append(b)\nct = dict(zip(c, d))\nfor i in range(num_objs):\n    xmin = coco_annotation[i]['bbox'][0]-1\n    ymin = coco_annotation[i]['bbox'][1]-1\n    xmax = coco_annotation[i]['bbox'][2]-1\n    ymax = coco_annotation[i]['bbox'][3]-1\n    box = [xmin, ymin, xmax, ymax]\n    boxes.append(box)\nvisualize(img, boxes, classes, ct)","546bd310":"   # JSON \u0434\u043b\u044f \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n   # JSON for original images","cbfa4f51":"# JSON \u0434\u043b\u044f \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n# JSON for modified images"}}