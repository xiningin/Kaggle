{"cell_type":{"e0141895":"code","47e13011":"code","ff4f94e2":"code","e0c4192e":"code","a3005b54":"code","20117788":"code","32eb7f06":"code","f19a04ba":"code","45b31bf3":"code","8e7763e3":"code","61a91721":"code","cfd93c32":"code","5f2237c0":"code","b3cb3d3b":"code","653babdf":"code","355250f1":"code","9d6a3a2a":"code","879bd54e":"code","5b423675":"code","f1d0754e":"code","be5f05c5":"code","5511623b":"code","49a4a0b5":"code","c4a7669c":"code","27213afd":"code","f15b7b68":"code","204a5054":"code","a4af7de8":"code","b646d6ab":"code","8d32fc64":"code","303eb5d7":"code","458b5550":"code","a73b4bbb":"code","e2b555bf":"markdown","c2593f39":"markdown","0f6904f9":"markdown","9b155b4e":"markdown","d9d8702c":"markdown","c9a5db69":"markdown","fd0faa2f":"markdown","e94bcc03":"markdown","c5d24f12":"markdown","015aa4eb":"markdown","422e8329":"markdown","52b50c2e":"markdown","4acf165c":"markdown","e03b47e4":"markdown","4b834b76":"markdown","6eb8be22":"markdown"},"source":{"e0141895":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47e13011":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split,cross_val_score\n\nimport scipy.stats as stats\nimport seaborn as sns\n\nimport category_encoders as ce\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport re\n\nfrom textblob import TextBlob\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n\nimport math\nstopwords = set(stopwords.words('english'))","ff4f94e2":"df = pd.read_csv('..\/input\/amazon-kindle-book-review-for-sentiment-analysis\/preprocessed_kindle_review .csv')\n\ndf_copy = df.copy()\ndf_copy.head()","e0c4192e":"df_copy.isnull().sum()","a3005b54":"df_copy.info()","20117788":"df_copy.shape","32eb7f06":"df_copy['review'] = df_copy['summary'] + df_copy['reviewText']","f19a04ba":"df_copy = df_copy.drop(['Unnamed: 0','summary','reviewText'],axis=1)","45b31bf3":"sns.countplot(x=\"rating\", data=df_copy)","8e7763e3":"df_copy.loc[df_copy['rating'] == 3,'score'] = 'Neutral'\ndf_copy.loc[df_copy['rating'] < 3,'score'] = 'Negative'\ndf_copy.loc[df_copy['rating'] > 3,'score'] = 'Positive'","61a91721":"sns.countplot(x=\"score\", data=df_copy)","cfd93c32":"import string\n\n# remove all numbers with letters attached to them\nalphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n\n# .lower() - convert all strings to lowercase \npunc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n\n# Remove all '\\n' in the string and replace it with a space\nremove_n = lambda x: re.sub(\"\\n\", \" \", x)\n\n# Remove all non-ascii characters \nremove_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)\n\n# Apply all the lambda functions wrote previously through .map on the comments column\ndf_copy['review'] = df_copy['review'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)","5f2237c0":"df_copy['review']","b3cb3d3b":"df_copy['review'] = df_copy['review'].apply(lambda x: ' '.join([corpus for corpus in x.split() if corpus not in stopwords]))","653babdf":"df_copy['review']","355250f1":"stemmer = nltk.stem.SnowballStemmer('english')\ndf_copy.stem_review = df_copy.review.apply(lambda x: \" \".join(stemmer.stem(x) for x in x.split()))\ndf_copy.stem_review","9d6a3a2a":"Neutral = df_copy.loc[df_copy['score'] == 'Neutral']\nPositive = df_copy.loc[df_copy['score'] == 'Positive']\nNegative = df_copy.loc[df_copy['score'] == 'Negative']","879bd54e":"text = ' '.join(Neutral['review']).lower()\n\ndef wc(data,bgcolor,title):\n    plt.figure(figsize = (70,70))\n    wc = WordCloud(background_color = bgcolor, max_words = 10000,  max_font_size = 50)\n    wc.generate(text)\n    plt.imshow(wc)\n    plt.axis('off')\n\nwc(text,'black','Most Used Words')","5b423675":"text = ' '.join(Positive['review']).lower()\n\ndef wc(data,bgcolor,title):\n    plt.figure(figsize = (100,100))\n    wc = WordCloud(background_color = bgcolor, max_words = 10000,  max_font_size = 50)\n    wc.generate(text)\n    plt.imshow(wc)\n    plt.axis('off')\n\nwc(text,'black','Most Used Words')","f1d0754e":"text = ' '.join(Negative['review']).lower()\n\ndef wc(data,bgcolor,title):\n    plt.figure(figsize = (100,100))\n    wc = WordCloud(background_color = bgcolor, max_words = 10000,  max_font_size = 50)\n    wc.generate(text)\n    plt.imshow(wc)\n    plt.axis('off')\n\nwc(text,'black','Most Used Words')","be5f05c5":"def get_top_nwords(x, n, i):\n    vec = CountVectorizer(ngram_range=(i,i)).fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key=lambda x:x[1], reverse=True)\n    return words_freq[:n]","5511623b":"words = get_top_nwords(df_copy['review'], 20, 1) \n\ndf_bi = pd.DataFrame(words, columns=['Unigram', 'Frequency'])\ndf_bi = df_bi.set_index('Unigram')\nfig = px.bar(df_bi,title=\"Top Frequency\")\nfig.show()","49a4a0b5":"words = get_top_nwords(df_copy['review'], 20, 2) \n\ndf_bi = pd.DataFrame(words, columns=['bi-gram', 'Frequency'])\ndf_bi = df_bi.set_index('bi-gram')\nfig = px.bar(df_bi,title=\"Top Frequency\")\nfig.show()","c4a7669c":"words = get_top_nwords(df_copy['review'], 20, 3) \n\ndf_bi = pd.DataFrame(words, columns=['Trigram', 'Frequency'])\ndf_bi = df_bi.set_index('Trigram')\nfig = px.bar(df_bi,title=\"Top Frequency\")\nfig.show()","27213afd":"list_cols = ['score']\n\nce_oe = ce.OrdinalEncoder(cols=list_cols,handle_unknown='impute')\ndf_session_ce_ordinal = ce_oe.fit_transform(df_copy)\n\ndf_session_ce_ordinal.tail()","f15b7b68":"vec_tfidf = TfidfVectorizer()\nX = vec_tfidf.fit_transform(df_session_ce_ordinal.review)\nY = df_session_ce_ordinal.score","204a5054":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)","a4af7de8":"nb = MultinomialNB()\nnb.fit(X_train, y_train)\n\ny_pred = nb.predict(X_test)","b646d6ab":"df_2 = pd.DataFrame({'Actual' : y_test, 'Prediction' : y_pred})\ndf_2.head()","8d32fc64":"print('Train Score = {:.2f}'.format(nb.score(X_train, y_train)))\nprint('Test Score = {:.2f}'.format(nb.score(X_test, y_test)))","303eb5d7":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nlist_k =[]\nlist_ac = []\n\nlist_nn = []\nlist_score = []\n\nfor k in range(1, 31): # K = 1~30\n  # KNeighborsClassifier\n  knc = KNeighborsClassifier(n_neighbors=k)\n  knc.fit(X_train, y_train)\n\n  Y_pred = knc.predict(X_test)\n\n  score = knc.score(X_test, y_test)\n  print(\"[%d] score: {:.2f}\".format(score) % k)\n\n  list_nn.append(k)\n  list_score.append(score)","458b5550":"plt.xlabel(\"n_neighbors\")\nplt.ylabel(\"score\")\nplt.plot(list_nn, list_score)","a73b4bbb":"knc = KNeighborsClassifier(n_neighbors=19)\nknc.fit(X_train, y_train)\n\nY_pred = knc.predict(X_test)\n\nscore = knc.score(X_test, y_test)\nprint(\"[%d] Final score: {:.2f}\".format(score) % k)","e2b555bf":"**Negative**","c2593f39":"**Positive**","0f6904f9":"# Cleaning Text","9b155b4e":"**Neutral**","d9d8702c":"# N-gram","c9a5db69":"# KNeighborsClassifier","fd0faa2f":"# Ordinal Encoding","e94bcc03":"# StopWord","c5d24f12":"# TfidfVectorizer","015aa4eb":"**Trigram**","422e8329":"# EDA","52b50c2e":"**Unigram**","4acf165c":"# MultinomialNB","e03b47e4":"# wordcloud","4b834b76":"**bi-gram**","6eb8be22":"# stemming"}}