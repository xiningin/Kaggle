{"cell_type":{"2e0b2d58":"code","c1971181":"code","2b3e8829":"code","892eafe9":"code","18553436":"code","aab57636":"code","79c5f517":"code","54c4f18f":"code","20b0a959":"code","619252f9":"code","0b66ceb6":"code","497dfbbb":"code","4d6eb78e":"code","9f722901":"code","df355a26":"code","f512d280":"code","9fa78ea1":"code","9f3376a8":"code","f25c27ba":"code","0f5d47c1":"code","9f05a074":"code","4212db32":"code","690dfc60":"code","eb8b5850":"code","e0d5838e":"code","6f34671d":"code","3bd216f6":"code","37493612":"code","23ead061":"code","bb0b77a7":"code","2f76dba9":"code","3c1f7d42":"code","baab99b2":"markdown","048c9d10":"markdown","03549ad2":"markdown"},"source":{"2e0b2d58":"#Importing the libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n","c1971181":"#Reading the data\ndf_train = pd.read_csv('..\/input\/housetrain.csv')\n","2b3e8829":"#View the variables\ndf_train.columns","892eafe9":"#Descriptive statistics summary\ndf_train['SalePrice'].describe()","18553436":"#Histogram for visualising the spread\nsns.distplot(df_train['SalePrice']);","aab57636":"#To check the skewness and kurtosis of the data\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","79c5f517":"#Scatterplot 1\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis = 1)\ndata.plot.scatter(x = var, y = 'SalePrice', ylim = (0,800000));","54c4f18f":"#Scatterplot 2\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis = 1)\ndata.plot.scatter(x = var, y = 'SalePrice', ylim = (0,800000));","20b0a959":"#Boxplot 1\nvar = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis = 1)\nf, ax = plt.subplots(figsize = (8, 6))\nfig = sns.boxplot(x = var, y = \"SalePrice\", data = data)\nfig.axis(ymin = 0, ymax = 800000);","619252f9":"#Boxplot 2\nvar = 'YearBuilt'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis = 1)\nf, ax = plt.subplots(figsize = (16, 8))\nfig = sns.boxplot(x = var, y = \"SalePrice\", data = data)\nfig.axis(ymin = 0, ymax = 800000);\nplt.xticks(rotation = 90);","0b66ceb6":"#Correlation matrix - Heatmap style\ncorrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","497dfbbb":"#Correlation matrix with SalePrice\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","4d6eb78e":"#Scatterplots\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","9f722901":"#Missing values\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","df355a26":"#Dealing with missing values\ndf_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\ndf_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\ndf_train.isnull().sum().max()","f512d280":"#Data standardisation\nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","9fa78ea1":"#Checking outliers\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis = 1)\ndata.plot.scatter(x = var, y = 'SalePrice', ylim = (0,800000));","9f3376a8":"#Removing outliers\ndf_train.sort_values(by = 'GrLivArea', ascending = False)[:2]\ndf_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\ndf_train = df_train.drop(df_train[df_train['Id'] == 524].index)","f25c27ba":"#Bivariate Analysis\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis = 1)\ndata.plot.scatter(x = var, y = 'SalePrice', ylim = (0,800000));","0f5d47c1":"#Histogram and normal probability plot\nsns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","9f05a074":"#Applying log transformation\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","4212db32":"#Transformed histogram and normal probability plot\nsns.distplot(df_train['SalePrice'], fit = norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot = plt)","690dfc60":"#Histogram and normal probability plot\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)","eb8b5850":"#Data transformation\ndf_train['GrLivArea'] = np.log(df_train['GrLivArea'])","e0d5838e":"#Transformed histogram and normal probability plot\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)","6f34671d":"#Histogram and normal probability plot\nsns.distplot(df_train['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt)","3bd216f6":"#Create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0 (as significant number of data points below 0)\ndf_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1","37493612":"#Transform data\ndf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","23ead061":"#Histogram and normal probability plot\nsns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","bb0b77a7":"#Scatterplot for homoscedasticity\nplt.scatter(df_train['GrLivArea'], df_train['SalePrice']);","2f76dba9":"#Scatterplot\nplt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], df_train[df_train['TotalBsmtSF']>0]['SalePrice']);","3c1f7d42":"#Convert categorical variable into dummy variable\ndf_train = pd.get_dummies(df_train)","baab99b2":"After exploring the data through visualisations, the next step involves analysing the data to result in powerful insights. ","048c9d10":"The first and most important step of any data-driven study is to explore and understand the data using visualisations. This gives us a better understanding of the underlying trends\/patterns in the dataset, the variations in the different variables, and their interactions. ","03549ad2":"Till now, correlations were found based on manually selected variables. \nHowever, to explore any other possible correlations which you one might not know about, following can be done."}}