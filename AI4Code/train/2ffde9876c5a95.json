{"cell_type":{"914bcfee":"code","ee5ce810":"code","d79306a1":"code","17f75609":"code","bc7e447c":"code","38042633":"code","3cdf1c5c":"code","236c231f":"code","179ab880":"code","ab90b56e":"markdown","64dd0080":"markdown","64ec5ac3":"markdown","4b29173e":"markdown","4742384b":"markdown","3010e50e":"markdown","f211d944":"markdown","fd8fb7ca":"markdown","0a157fca":"markdown","4de209be":"markdown","d5931994":"markdown","1b4195e3":"markdown"},"source":{"914bcfee":"import os\nimport numpy as np \nimport pandas as pd \n\nfrom scipy.special import softmax","ee5ce810":"path = \"..\/input\/jigsaw-multilingual-toxic-comment-classification\/\"\nrecord = \"..\/input\/buffer\/\"\n\nbase = record + \"submission-9462.csv\"\nmonos = [\"submission-it-9467.csv\",\n         \"submission-pt-9470.csv\",\n         \"submission-es-9467.csv\",\n         \"submission-tr-9470.csv\",\n         \"submission-fr-9473.csv\",]\n\nget_lang = lambda x: x.split('-')[1]","d79306a1":"test = pd.read_csv(path + \"test.csv\")\ndic_ids = {k:v.id for k,v in test.groupby([\"lang\"])}","17f75609":"sub = pd.read_csv(base)\nfor m in monos:\n    res = pd.read_csv(record + m)\n    ids = dic_ids[get_lang(m)]\n    sub.loc[ids,\"toxic\"] = res.toxic[ids]\n\nsub.head()","bc7e447c":"adj = {\n    \"fr\":1.04,\n    \"es\":1.06,\n    \"pt\":.96,\n    \"it\":.97,\n    \"tr\":.98,\n}\nfor l,v in adj.items():\n    ids = dic_ids[l]\n    sub.loc[ids,\"toxic\"] *= v\n\nsub.head()","38042633":"weight = lambda x: softmax(1\/(1-x))\n\ndef mix_result(subs,pbs):\n    toxics = np.array([df.toxic.values for df in subs])\n    w = weight(np.array(pbs))\n    print([\"{:.3f}\".format(i) for i in w])\n    return toxics.T@w","3cdf1c5c":"sub1 = pd.read_csv(record+\"submission-public-mix-9482.csv\")\nsub[\"toxic\"] = mix_result([sub,sub1],[.9508,.9482])\nsub.head()","236c231f":"sub1 = pd.read_csv(record+\"submission-1st-place-9550.csv\")\nsub2 = pd.read_csv(record+\"submission-2nd-place-9522.csv\")\nsub[\"toxic\"] = mix_result([sub,sub2,sub1],[.9514,.9522,.9550])\nsub.head()","179ab880":"sub.to_csv('submission.csv', index=False)","ab90b56e":"**We can achieve <span style=\"color:red\"> lb.9557<\/span> here.**\n\n1. Ensemble with 2rd (.9522) alone:  <span style=\"color:red\"> lb.9535<\/span>\n2. Ensemble with 1st (.9550) alone:  <span style=\"color:red\"> lb.9553<\/span>\n3. Blend 1st(.9550) with 2rd(.9522):  <span style=\"color:red\"> lb.9556<\/span>","64dd0080":"**Another.0006 bost to <span style=\"color:red\"> lb.9514<\/span>**","64ec5ac3":"# About this notebook\n\nJMTC-20 is my first competition. I attended it near the end date and did not get a medal (30 places lower than bronze line).\n\nAfter the end of competition, I read the discussion hold by [1st-place](https:\/\/www.kaggle.com\/c\/jigsaw-multilingual-toxic-comment-classification\/discussion\/160862). their impressive ideas and extensive trys of technique makes me want to learn by reproducing their result, at least part of it.\n\nThey said they would release their code soon, but only a post-processing part is public. Hence, I implement my own multiple mono-lingual models achiving <span style=\"color:red\">lb.9508<\/span>. Hope this notebook and its previous ones can help other beginers of this JMTC-20 task.","4b29173e":"# Start Ensemble","4742384b":"**We get .0008 bost to <span style=\"color:red\"> lb.9508<\/span>**","3010e50e":"<h3>Ensemble with public 1st and 2nd kernels<\/h3>","f211d944":"# Combine all monolinguish models with base XLM-R","fd8fb7ca":"# Further improvement\n\n1. Try variable padding in [4th-place](https:\/\/www.kaggle.com\/c\/jigsaw-multilingual-toxic-comment-classification\/discussion\/160980)\n2. Try augmentation, futher corpus generation with qseudo-labels, in [2nd-place](https:\/\/www.kaggle.com\/xiwuhan\/jmtc-2nd-place-solution?scriptVersionId=37463887)\n3. Try to fine-tune like [Jigsaw20 XLM-R lb0.9487 singel model](https:\/\/www.kaggle.com\/hmendonca\/jigsaw20-xlm-r-lb0-9487-singel-model)\n\n.......","0a157fca":"**Here, we can obtain <span style=\"color:red\"> lb.9500<\/span>**","4de209be":"<h3>Public Score milestone<\/h3>\n\n* [Basic XLM-R model with balanced data](https:\/\/www.kaggle.com\/mint101\/basic-xlm-r-lb-9442-intro?scriptVersionId=39822772):  <span style=\"color:red\">(.942X - .9442)<\/span>\n* Ensemble of XLM-R model:  <span style=\"color:red\">(.9455)<\/span>\n* [Pseudo-lableling on XLM-R](https:\/\/www.kaggle.com\/mint101\/example-code-of-pseudo-label-on-xlm-r) for one turn:  <span style=\"color:red\">(.9462)<\/span>\n* [Transfer to monolinguish models](https:\/\/www.kaggle.com\/mint101\/transfer-to-monolingual-mix):  <span style=\"color:red\">(.9467-.9473)<\/span>\n* Combine all monolinguish models:  <span style=\"color:red\">(.9500)<\/span>\n* Adjusting according to [4th-place](https:\/\/www.kaggle.com\/c\/jigsaw-multilingual-toxic-comment-classification\/discussion\/160980):  <span style=\"color:red\">(.9508)<\/span>\n* Mix with [simple ensemble on public kernels before end date](https:\/\/www.kaggle.com\/mint101\/lb-9482-by-simple-public-result-bf-end-ensemble): <span style=\"color:red\"> (.9514) <\/span>\n\n<br\/>\n    \n * Mix with the public version of [1st](https:\/\/www.kaggle.com\/rafiko1\/1st-place-jigsaw-post-processing-example\/output) and [2rd](https:\/\/www.kaggle.com\/xiwuhan\/jmtc-2nd-place-solution?scriptVersionId=37463887) results (just for fun): <span style=\"color:red\">(.9557)<\/span>\n    \n    \n<u>I just transfer XLM-R result to monolinguish models and combine once. This result can be further used to train XLM-R and further transfer. According to [1st-place](https:\/\/www.kaggle.com\/c\/jigsaw-multilingual-toxic-comment-classification\/discussion\/160862), this pattern is doable and may provide another .001+ boost. I just stop here as I have run out of TPU quota.<\/u>","d5931994":"<h3>Ensemble with public available kernels before end data<\/h3>\n\nhttps:\/\/www.kaggle.com\/mint101\/lb-9482-by-simple-public-result-bf-end-ensemble is my simple ensemble of public available kernels before end data. I used the before adjustment version (lb.9473) in the competition.","1b4195e3":"# Adjustment according to [4th-place](https:\/\/www.kaggle.com\/c\/jigsaw-multilingual-toxic-comment-classification\/discussion\/160980)"}}