{"cell_type":{"1532c936":"code","86af305b":"code","5c42ff03":"code","ea58fe03":"code","4de2435e":"code","4b739523":"code","472df919":"code","71a9fc55":"code","8996b522":"code","2e0a6a6a":"code","ec733bd5":"code","b90c7a51":"code","8d5fc44c":"code","26c6e534":"code","30308499":"markdown","2a96cd18":"markdown","c9ce3abe":"markdown"},"source":{"1532c936":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86af305b":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/cusersmarildownloadsweeklycsv\/weekly.csv', delimiter=';', encoding = \"utf8\", nrows = nRowsRead)\ndf.dataframeName = 'weekly.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","5c42ff03":"from random import seed\nfrom random import randrange\nfrom csv import reader\nfrom math import sqrt","ea58fe03":"from sklearn.preprocessing import LabelEncoder\n\n#fill in mean for floats\nfor c in df.columns:\n    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n        df[c].fillna(df[c].mean())\n\n#fill in -999 for categoricals\ndf = df.fillna(-999)\n# Label Encoding\nfor f in df.columns:\n    if df[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[f].values))\n        df[f] = lbl.transform(list(df[f].values))\n        \nprint('Labelling done.')","4de2435e":"df = pd.get_dummies(df)","4b739523":"one_hot_encoded_training_predictors = pd.get_dummies(df)","472df919":"# Load a CSV file\ndef load_csv(filename):\n\tdataset = list()\n\twith open(filename, 'r') as file:\n\t\tcsv_reader = reader(file)\n\t\theadings = next(csv_reader) \n\t\tfor row in csv_reader:\n\t\t\tif not row:\n\t\t\t\tcontinue\n\t\t\tdataset.append(row)\n\treturn dataset","71a9fc55":"# Convert string column to float\ndef str_column_to_float(dataset, column):\n\tfor row in dataset:\n\t\trow[column] = float(row[column].strip())\n\n# Find the min and max values for each column\ndef dataset_minmax(dataset):\n\tminmax = list()\n\tfor i in range(len(dataset[0])):\n\t\tcol_values = [row[i] for row in dataset]\n\t\tvalue_min = min(col_values)\n\t\tvalue_max = max(col_values)\n\t\tminmax.append([value_min, value_max])\n\treturn minmax\n\n# Rescale dataset columns to the range 0-1\ndef normalize_dataset(dataset, minmax):\n\tfor row in dataset:\n\t\tfor i in range(len(row)):\n\t\t\trow[i] = (row[i] - minmax[i][0]) \/ (minmax[i][1] - minmax[i][0])","8996b522":"# Split a dataset into k folds\ndef cross_validation_split(dataset, n_folds):\n\tdataset_split = list()\n\tdataset_copy = list(dataset)\n\tfold_size = int(len(dataset) \/ n_folds)\n\tfor i in range(n_folds):\n\t\tfold = list()\n\t\twhile len(fold) < fold_size:\n\t\t\tindex = randrange(len(dataset_copy))\n\t\t\tfold.append(dataset_copy.pop(index))\n\t\tdataset_split.append(fold)\n\treturn dataset_split","2e0a6a6a":"# Calculate root mean squared error\ndef rmse_metric(actual, predicted):\n\tsum_error = 0.0\n\tfor i in range(len(actual)):\n\t\tprediction_error = predicted[i] - actual[i]\n\t\tsum_error += (prediction_error ** 2)\n\tmean_error = sum_error \/ float(len(actual))\n\treturn sqrt(mean_error)","ec733bd5":"# Evaluate an algorithm using a cross validation split\ndef evaluate_algorithm(dataset, algorithm, n_folds, *args):\n\tfolds = cross_validation_split(dataset, n_folds)\n\tscores = list()\n\tfor fold in folds:\n\t\ttrain_set = list(folds)\n\t\ttrain_set.remove(fold)\n\t\ttrain_set = sum(train_set, [])\n\t\ttest_set = list()\n\t\tfor row in fold:\n\t\t\trow_copy = list(row)\n\t\t\ttest_set.append(row_copy)\n\t\t\trow_copy[-1] = None\n\t\tpredicted = algorithm(train_set, test_set, *args)\n\t\tactual = [row[-1] for row in fold]\n\t\trmse = rmse_metric(actual, predicted)\n\t\tscores.append(rmse)\n\treturn scores","b90c7a51":"# Make a prediction with coefficients\ndef predict(row, coefficients):\n\tyhat = coefficients[0]\n\tfor i in range(len(row)-1):\n\t\tyhat += coefficients[i + 1] * row[i]\n\treturn yhat\n\n# Estimate linear regression coefficients using stochastic gradient descent\ndef coefficients_sgd(train, l_rate, n_epoch):\n\tcoef = [0.0 for i in range(len(train[0]))]\n\tfor epoch in range(n_epoch):\n\t\tfor row in train:\n\t\t\tyhat = predict(row, coef)\n\t\t\terror = yhat - row[-1]\n\t\t\tcoef[0] = coef[0] - l_rate * error\n\t\t\tfor i in range(len(row)-1):\n\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n\t\t\t# print(l_rate, n_epoch, error)\n\treturn coef\n\n# Linear Regression Algorithm With Stochastic Gradient Descent\ndef linear_regression_sgd(train, test, l_rate, n_epoch):\n\tpredictions = list()\n\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n\tfor row in test:\n\t\tyhat = predict(row, coef)\n\t\tpredictions.append(yhat)\n\treturn(predictions)","8d5fc44c":"#Snippet by Joseph Chan https:\/\/www.kaggle.com\/josephchan524\/housepricesregressor-using-lightgbm\n\n#Label Encoding\n#%% MultiColumnLabelEncoder\n# Code snipet found on Stack Exchange \n# https:\/\/stackoverflow.com\/questions\/24458645\/label-encoding-across-multiple-columns-in-scikit-learn\nfrom sklearn.preprocessing import LabelEncoder\n\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                # convert float NaN --> string NaN\n                output[col] = output[col].fillna('NaN')\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n\n# store the catagorical features names as a list      \ncat_features = df.select_dtypes(['object']).columns.to_list()\n\n# use MultiColumnLabelEncoder to apply LabelEncoding on cat_features \n# uses NaN as a value , no imputation will be used for missing data\ndf_encoded = MultiColumnLabelEncoder(columns = cat_features).fit_transform(df)","26c6e534":"# Linear Regression \nseed(1)\n# load and prepare data\nfilename = '..\/input\/cusersmarildownloadsweeklycsv\/weekly.csv'\ndataset = load_csv(filename)\nfor i in range(len(dataset[0])):\n\tstr_column_to_float(dataset, i)\n# normalize\nminmax = dataset_minmax(dataset)\nnormalize_dataset(dataset, minmax)\n# evaluate algorithm\nn_folds = 5\nl_rate = 0.01\nn_epoch = 50\nscores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\nprint('Scores: %s' % scores)\nprint('Mean RMSE: %.3f' % (sum(scores)\/float(len(scores))))","30308499":"#Codes by Sufyan Cunningham  https:\/\/www.kaggle.com\/sufyancunningham\/white-whine-quality-sgd-scratch","2a96cd18":"#I tried to encode. Though it didn't work.","c9ce3abe":"![](https:\/\/i.ytimg.com\/vi\/ZqjDy8QJGp8\/maxresdefault.jpg)youtube.com"}}