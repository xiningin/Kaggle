{"cell_type":{"e911610c":"code","7b8f263b":"code","b02ee5f6":"code","fb14f7eb":"code","986a3a78":"code","a47b4e35":"code","b66ebaaa":"code","2b15ae8e":"code","07a52fe2":"code","9a411df6":"markdown","b4cfdaca":"markdown","1c2399dc":"markdown","7db67da2":"markdown","1689e48c":"markdown","0b89cfba":"markdown","b4d58ca9":"markdown","92f2bfef":"markdown","67619327":"markdown","b3bd558c":"markdown"},"source":{"e911610c":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf    ","7b8f263b":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\nnb_classes = len(class_names)\nIMAGE_SIZE = (150, 150)","b02ee5f6":"## Thanks to Vincent for this function - https:\/\/www.kaggle.com\/vincee\/intel-image-classification-cnn-keras\n\n## Function definition\ndef load_data():\n    \"\"\"\n        Load the data:\n            - 14,034 images to train the network.\n            - 3,000 images to evaluate how accurately the network learned to classify images.\n    \"\"\"\n    \n    datasets = ['\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train', '\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            curr_label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in os.listdir(os.path.join(dataset, folder)):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                curr_img = cv2.imread(img_path)\n                curr_img = cv2.resize(curr_img, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(curr_img)\n                labels.append(curr_label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output\n\n## Function Call\n(train_images, train_labels), (test_images, test_labels) = load_data()\n","fb14f7eb":"train_images = train_images \/ 255.0 \ntest_images = test_images \/ 255.0\n\ntrain_images, train_labels = shuffle(train_images, train_labels)","986a3a78":"def display_examples(class_names, images, labels):\n    \"\"\"\n        Display 25 images from the images array with its corresponding labels\n    \"\"\"\n    \n    fig = plt.figure(figsize=(20,20))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i])\n        plt.xlabel(class_names[labels[i]])\n    plt.show()\n\n    ## Function call\ndisplay_examples(class_names, train_images, train_labels)\n","a47b4e35":"from keras.utils import np_utils\ny_train = np_utils.to_categorical(train_labels, 6)\ny_test = np_utils.to_categorical(test_labels, 6)","b66ebaaa":"from keras.applications import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Conv2D, Flatten, BatchNormalization, Dropout, MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nvgg_conv = VGG16(weights='imagenet',\n                  include_top=False,input_shape=(150,150,3))\n## Disabling training from VGG layers\nvgg_conv.trainable=False\n\n## Instantiating model\nvgg_conv.trainable=False\ntransfer_model = Sequential()\ntransfer_model.add(vgg_conv)\ntransfer_model.add(Flatten())\ntransfer_model.add(Dropout(0.25))\ntransfer_model.add(Dense(64, activation='relu'))\ntransfer_model.add(Dropout(0.25))\ntransfer_model.add(Dense(6, activation='softmax'))\n\n\n## Model summary\ntransfer_model.summary()","2b15ae8e":"optimizer = Adam(lr=0.2e-3, beta_1=0.9, beta_2=0.999, amsgrad=False)\n\ntransfer_model.compile(optimizer,loss='binary_crossentropy',metrics=[\"accuracy\"])\n\n## I know binary_crossentropy is not recommended for multiclass problems.\n## But I saw somebody use it and surprisingly it gave better results.","07a52fe2":"train_gen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\n# fits the model on batches with real-time data augmentation:\nhistory = transfer_model.fit_generator(train_gen.flow(train_images, y_train, batch_size=32),\n                              steps_per_epoch=len(train_images) \/ 32, epochs=3,\n                              validation_data = (test_images, y_test))","9a411df6":"## Compiling model","b4cfdaca":"## Preparing target","1c2399dc":"## Scaling and shuffeling data","7db67da2":"## Dictionary mapping for labels","1689e48c":"## Import Packages","0b89cfba":"## Loading data","b4d58ca9":"## Plotting sample images","92f2bfef":"## Model training with real time data augmentation","67619327":"## This is my take on transfer learning (VGG16) approach for image classification. Currently it gives 95.5% validation accuracy in just 3 epochs.\n\n## With finer tuning in learning rate I was able to achieve 96% validation accuracy.\n\nSagar Patel\n\nConsultant Data Scientist\n\nsagarpatel.exe@gmail.com\n\nhttps:\/\/www.linkedin.com\/in\/codesagar\/","b3bd558c":"## Transfer Learning using VGG16"}}