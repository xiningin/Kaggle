{"cell_type":{"e79b7ea3":"code","dd685cea":"code","e2732cf9":"code","53445a4e":"code","f9958522":"code","6fed3d0b":"code","bb4973cf":"code","c023cbd3":"code","4150aa9e":"code","90f34c24":"code","a3880581":"code","4b550cf3":"code","1db588e7":"code","ed175fe0":"markdown","6edd5ead":"markdown","84065110":"markdown","2632f419":"markdown","3a49d0d6":"markdown","b85edc3b":"markdown","fb28be14":"markdown","2e4d62d2":"markdown","968b0058":"markdown","56887860":"markdown"},"source":{"e79b7ea3":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.optimize import curve_fit\nimport os\n\ndf_train = pd.read_csv(\"..\/input\/liverpool-ion-switching\/train.csv\")\ndf_test  = pd.read_csv(\"..\/input\/liverpool-ion-switching\/test.csv\")","dd685cea":"def make_batches(df, dataset=\"train\"):\n    batches = []\n    batch_size = [500000, 100000]\n    if dataset == \"train\":\n        for idx in range(10):\n            batches.append(df[idx * batch_size[0]: (idx + 1) * batch_size[0]])\n    else:\n        for idx in range(10):\n            batches.append(df[idx * batch_size[1]: (idx + 1) * batch_size[1]])\n        for idx in range(2):\n            base = 10 * batch_size[1]\n            batches.append(df[base + idx * batch_size[0]: base + (idx + 1) * batch_size[0]])\n    return batches\n\ndf_train = make_batches(df_train, \"train\")\ndf_test = make_batches(df_test, \"test\")","e2732cf9":"def plot_all(train, test, suffix=\"\"):\n    plt.figure(figsize=(25, 5))\n    plt.subplot(\"211\")\n    plt.title(\"Train \" + suffix)\n    plt.ylabel(\"Signal\")\n    plt.xticks(np.arange(0, 501, 50))\n    for x in train:\n        plt.plot(x['time'], x['signal'], linewidth=.1)\n    plt.grid()\n    plt.subplot(\"212\")\n    plt.title(\"Test \" + suffix)\n    plt.ylabel(\"Signal\")\n    plt.xticks(np.arange(500, 701, 10))\n    for x in test:\n        plt.plot(x['time'], x['signal'], linewidth=.1)\n    plt.grid()\n\nplot_all(df_train, df_test, \"Original\")","53445a4e":"linear_train_idx = [1]\nlinear_test_idx = [0, 1, 4, 6, 7, 8]\n\nplt.figure(figsize=(30, 4))\nplt.subplot(\"171\")\nplt.title(\"Train 1 (part)\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.plot(df_train[1]['time'][0:100000], df_train[1]['signal'][0:100000], linewidth=.1)\nplt.grid()\nplt.ylim([np.min(df_train[1]['signal'][0:100000]), np.min(df_train[1]['signal'][0:100000]) + 15])\nfor n, idx in enumerate(linear_test_idx):\n    plt.subplot(\"17\" + str(n + 2))\n    plt.title(\"Test \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.ylim([np.min(df_test[idx]['signal']), np.min(df_test[idx]['signal']) + 15])\n    plt.plot(df_test[idx]['time'], df_test[idx]['signal'], linewidth=.1)\n    plt.grid()","f9958522":"def poly1(x, a, b):\n    return a*(x - b)\n\n\ndef linear_drift_fit(data):\n    x = data['time']\n    y = data['signal']\n    popt, _ = curve_fit(poly1, x, y)\n    print(popt)\n    return popt\n    \n\nlinear_params = []\nlinear_params.append(linear_drift_fit(df_train[linear_train_idx[0]][0:100000]))\nfor idx in linear_test_idx:\n    linear_params.append(linear_drift_fit(df_test[idx]))\n    \nplt.figure(figsize=(30, 4))\nplt.subplot(\"171\")\nplt.title(\"Train 1 (part)\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.plot(df_train[1]['time'][0:100000], df_train[1]['signal'][0:100000], linewidth=.1)\nplt.plot(df_train[1]['time'][0:100000], poly1(df_train[1]['time'][0:100000], *linear_params[0]), 'y')\nplt.grid()\nplt.ylim([np.min(df_train[1]['signal'][0:100000]), np.min(df_train[1]['signal'][0:100000]) + 15])\nfor n, idx in enumerate(linear_test_idx):\n    plt.subplot(\"17\" + str(n + 2))\n    plt.title(\"Test \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.ylim([np.min(df_test[idx]['signal']), np.min(df_test[idx]['signal']) + 15])\n    plt.plot(df_test[idx]['time'], df_test[idx]['signal'], linewidth=.1)\n    plt.plot(df_test[idx]['time'], poly1(df_test[idx]['time'], *linear_params[1 + n]), 'y')\n    plt.grid()","6fed3d0b":"def linear_drift(x, x0):\n    return 0.3 * (x - x0)\n\n\ndef remove_linear_drift(data, dataset=\"train\"):\n    if dataset == \"train\":\n        data[1].loc[data[1].index[0:100000], 'signal'] = data[1].signal[0:100000].values - linear_drift(data[1].time[0:100000].values, data[1].time[0:1].values)\n    else:\n        for idx in linear_test_idx:\n            data[idx].loc[data[idx].index[0:100000], 'signal'] = data[idx].signal[0:100000].values - linear_drift(data[idx].time[0:100000].values, data[idx].time[0:1].values)\n            \n    return data\n\ndf_train = remove_linear_drift(df_train, \"train\")\ndf_test = remove_linear_drift(df_test, \"test\")","bb4973cf":"plot_all(df_train, df_test, \"- Linear Drift Removed\")","c023cbd3":"parabola_train_idx = [6, 7, 8, 9]\nparabola_test_idx = [10]\n\nplt.figure(figsize=(30, 4))\nfor n, idx in enumerate(parabola_train_idx):\n    plt.subplot(\"15\" + str(n + 1))\n    plt.title(\"Train \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.plot(df_train[idx]['time'], df_train[idx]['signal'], linewidth=.1)\n    plt.grid()\n    plt.ylim([np.min(df_train[idx]['signal']), np.min(df_train[idx]['signal']) + 18])\nplt.subplot(\"155\")\nplt.title(\"Test 10\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.ylim([np.min(df_test[10]['signal']), np.min(df_test[10]['signal']) + 18])\nplt.plot(df_test[10]['time'], df_test[10]['signal'], linewidth=.1)\nplt.grid()","4150aa9e":"def my_sin(x, A, ph, d):\n    frequency = 0.01\n    omega = 2 * np.pi * frequency\n    return A * np.sin(omega * x + ph) + d\n\n\ndef parabolic_drift_fit(data):\n    x = data['time']\n    y = data['signal']\n\n    frequency = 0.01\n    omega = 2 * np.pi * frequency\n    M = np.array([[np.sin(omega * t), np.cos(omega * t), 1] for t in x])\n    y = np.array(y).reshape(len(y), 1)\n\n    (theta, _, _, _) = np.linalg.lstsq(M, y)\n    \n    A = np.sqrt(theta[0,0]**2 + theta[1,0]**2)\n    ph = math.atan2(theta[1,0], theta[0,0])\n    d = theta[2,0]\n\n    popt = [A, ph, d]\n    print(popt)\n    return popt\n\n\nparabola_params = []\nfor idx in parabola_train_idx:\n    parabola_params.append(parabolic_drift_fit(df_train[idx]))\nparabola_params.append(parabolic_drift_fit(df_test[parabola_test_idx[0]]))    \n    \nplt.figure(figsize=(30, 4))\nfor n, idx in enumerate(parabola_train_idx):\n    plt.subplot(\"15\" + str(n + 1))\n    plt.title(\"Train \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.plot(df_train[idx]['time'], df_train[idx]['signal'], linewidth=.1)\n    plt.plot(df_train[idx]['time'], my_sin(df_train[idx]['time'], *parabola_params[n]), 'y')\n    plt.grid()\n    plt.ylim([np.min(df_train[idx]['signal']), np.min(df_train[idx]['signal']) + 18])\nplt.subplot(\"155\")\nplt.title(\"Test 10\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.ylim([np.min(df_test[10]['signal']), np.min(df_test[10]['signal']) + 18])\nplt.plot(df_test[10]['time'], df_test[10]['signal'], linewidth=.1)\nplt.plot(df_test[10]['time'], my_sin(df_test[10]['time'], *parabola_params[-1]), 'y')\nplt.grid()\n","90f34c24":"def parabolic_drift(x, t=0):\n    f = 0.01\n    omega = 2 * np.pi * f\n    return 5 * np.sin(omega * x + t * np.pi)\n\n\ndef remove_parabolic_drift(data, dataset=\"train\"):\n    if dataset == \"train\":\n        for idx in parabola_train_idx:\n            data[idx].loc[data[idx].index[0:500000], 'signal'] = data[idx].signal[0:500000].values - parabolic_drift(data[idx].time[0:500000].values, (idx % 2))\n    else:\n        data[10].loc[data[10].index[0:500000], 'signal'] = data[10].signal[0:500000].values - parabolic_drift(data[10].time[0:500000].values)\n            \n    return data\n\ndf_train = remove_parabolic_drift(df_train, \"train\")\ndf_test = remove_parabolic_drift(df_test, \"test\")","a3880581":"plot_all(df_train, df_test, \"- Without Drift\")","4b550cf3":"def plot_dist(data, labels, m):\n    plt.title(\"Signal Distribution Model \" + str(m))\n    for i, x in enumerate(data):\n        x = x['signal']\n        sns.distplot(x, label=labels[i], kde=True, bins=np.arange(np.min(x), np.max(x), 0.01))\n#         sns.distplot(x, label=labels[i], kde=True)\n    plt.xlabel(\"signal value\")\n    plt.ylabel(\"frequency\")\n    plt.legend(loc=\"best\")    \n    \n\nM = [[df_train[0], df_train[1], df_test[0], df_test[3], df_test[8], df_test[10], df_test[11]],\n     [df_train[2], df_train[6], df_test[4]],\n     [df_train[3], df_train[7], df_test[1], df_test[9]],\n     [df_train[4], df_train[9], df_test[5], df_test[7]],\n     [df_train[5], df_train[8], df_test[2], df_test[6]]]\nlabels = [[\"train 0\", \"train 1 (line)\", \"test 0 (line)\", \"test 3\", \"test 8 (line)\", \"test 10 (sine)\", \"test 11\"],\n          [\"train 2\", \"train 6 (sine)\", \"test 4 (line)\"],\n          [\"train 3\", \"train 7 (sine)\", \"test 1 (line)\", \"test 9\"],\n          [\"train 4\", \"train 9 (sine)\", \"test 5\", \"test 7 (line)\"],\n          [\"train 5\", \"train 8 (sine)\", \"test 2\", \"test 6 (line)\"]]\n\nplt.figure(figsize=(25, 8))\nfor i in range(5):\n    plt.subplot(\"15\" + str(i + 1))\n    plot_dist(M[i], labels[i], i)","1db588e7":"df_train_clean = df_train[0]\ndf_test_clean = df_test[0]\nfor df in df_train[1:]:\n    df_train_clean = pd.concat([df_train_clean, df], ignore_index=True)\nfor df in df_test[1:]:\n    df_test_clean = pd.concat([df_test_clean, df], ignore_index=True)\n\ndf_train_clean.to_csv(\"train_wo_drift.csv\", index=False, float_format=\"%.4f\")\ndf_test_clean.to_csv(\"test_wo_drift.csv\", index=False, float_format=\"%.4f\")","ed175fe0":"It is ~~almost certain~~ that all data have the same slope => **0.3**. Let's remove it.","6edd5ead":"The optimum A is 5 for all batches and the optimum phase is 0 or \\\\(\\pi\\\\) \n\n$$\n\\begin{align}\nA_{opt} &= 5 \\\\\n\\varphi_{opt} &= \n\\begin{cases}\n0 & \\text{ if train 6, train 8, test 10} \\\\ \n\\pi & \\text{ if train 7, train 9} \n\\end{cases}\n\\end{align}\n$$\n\nLet's remove this drift.","84065110":"# Parabolic drift\n\nThis kind of drift has more candidates. It could be a polynomial, a trigonometric, or something else. In this notebook, I'll assume it as a **sine function.**\n","2632f419":"# How to fit a sine function\n\n$$\n\\hat{y} = A \\sin (\\omega x + \\varphi) + \\delta\n$$\n\nBecause each batch has the same length (50s), omega should be \\\\( \\omega = \\frac{2\\pi}{50 \\times 2} \\\\).\nBut it's not easy to find \\\\(A\\\\) and \\\\(\\varphi\\\\) with this form. \n\nLet's apply harmonic addition to the equation above.\n\n$$\n\\begin{align}\n\\hat{y} &= A \\sin (\\omega x + \\varphi) + \\delta \\\\\n&= A \\sin (\\omega x) \\cos (\\varphi) + A \\cos (\\omega x) \\sin (\\varphi) + \\delta \\\\\n&= A \\cos (\\varphi) \\sin (\\omega x) + A \\sin (\\varphi) \\cos (\\omega x) + \\delta \n\\end{align}\n$$\n\nNow we can represent it as a linear system.\n\n$$\n\\begin{bmatrix}\n\\sin(\\omega x_1) & \\cos(\\omega x_1) & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\sin(\\omega x_N) & \\cos(\\omega x_N) & 1\n\\end{bmatrix}\n\\begin{bmatrix}\nA\\cos(\\varphi) \\\\\nA\\sin(\\varphi) \\\\\n\\delta\n\\end{bmatrix} = \n\\begin{bmatrix}\ny_1 \\\\ \\vdots \\\\ y_N\n\\end{bmatrix}\n$$\n\nwhere \\\\(\\mathbf{x} = (x_1, \\cdots, x_N) \\\\) is  ```df['time']``` and \\\\(\\mathbf{y} = (y_1, \\cdots, y_N) \\\\) is ```df['signal']``` with \\\\(N=500000 \\\\)\n\nor simply,\n$$\n\\mathbf{M}\\mathbf{\\theta} = \\mathbf{y}\n$$\n\n\nWe can find \\\\(\\mathbf{\\theta} \\\\) that minimizes the squared Euclidean 2-norm.\nThen, we can find our target parameters \\\\( A \\\\) and \\\\( \\varphi \\\\) from \\\\( \\mathbf{\\theta} = (\\theta_1, \\theta_2, \\theta_3) \\\\)\n\n$$\nA = \\sqrt{\\theta_1^2 + \\theta_2^2} \\\\\n\\varphi = \\arctan(\\frac{\\theta_2}{\\theta_1})\n$$","3a49d0d6":"# Save data\n\nI uploaded this data to [here][1]\n\n[1]:https:\/\/www.kaggle.com\/eunholee\/iondatawithoutdrift","b85edc3b":"# Linear drift\n\n~~It's easy to~~ figure out what linear drift function looks like.\n\n(**Update:** It turns out it's not easy...! Linear drift is not actually linear. Check here[1]. )\n\n[1]:https:\/\/www.kaggle.com\/c\/liverpool-ion-switching\/discussion\/137537","fb28be14":"# Two types of drift\n\nAs you can see in the blow, there are two types of drift in our dataset, linear and parabolic drift.","2e4d62d2":"# Comparison of distributions\n\nLet's see if the distribution of a clean version matches the distribution of existing data in the same model.","968b0058":"# Introduction\n\nIn this notebook, I'll share my approach to finding synthetic drift function. It is no secret that the drift has been artificially added. In this competition's paper [here][1], you can find the description of the data like below:\n> *\"In some datasets additional drift was applied to the final data with MATLAB\"*\n\nThere's an excellent explanation for the drift. Please check Chris' explanation: [What is Drift?][2] \n\n\n\n[1]:https:\/\/www.nature.com\/articles\/s42003-019-0729-3\n[2]:https:\/\/www.kaggle.com\/c\/liverpool-ion-switching\/discussion\/133874\n[3]:https:\/\/www.kaggle.com\/friedchips\/clean-removal-of-data-drift","56887860":"+) I'm not a native English speaker. Please let me know if there's a wrong sentence or anything you don't understand."}}