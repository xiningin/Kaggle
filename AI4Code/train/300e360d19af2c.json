{"cell_type":{"ca1c953c":"code","57100806":"code","856285ff":"code","4549a16e":"code","aa564bd5":"code","cc4a8359":"code","37e5dcaf":"code","a20158ef":"code","83c1ad86":"code","559c384e":"code","37f0be4c":"code","9e8d3e6c":"code","63c51d82":"code","568d9f5b":"code","ae811f26":"markdown","220fa4e5":"markdown","36f66d74":"markdown","e981b364":"markdown","4d4704e4":"markdown","1a2b89d4":"markdown","f8d1a372":"markdown","76f08fc2":"markdown","e73bebe7":"markdown","b0e9e354":"markdown","b33ee3f4":"markdown","f8f5377b":"markdown","550adccb":"markdown","b60dd237":"markdown","504c7183":"markdown","e84b620f":"markdown","7fc06585":"markdown","e9aa3368":"markdown","cd511d70":"markdown","490db50f":"markdown"},"source":{"ca1c953c":"import gc\nimport sys\nimport warnings\nfrom joblib import Parallel, delayed\nfrom pathlib import Path\n\nimport ipywidgets as widgets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.tsa.deterministic import (CalendarFourier,\n                                           CalendarSeasonality,\n                                           CalendarTimeTrend,\n                                           DeterministicProcess)\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers.experimental.preprocessing import StringLookup\n\nwarnings.simplefilter(\"ignore\")\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)","57100806":"# Helper function to unpack json found in daily data\ndef unpack_json(json_str):\n    return pd.DataFrame() if pd.isna(json_str) else pd.read_json(json_str)\n\n\ndef unpack_data(data, dfs=None, n_jobs=-1):\n    if dfs is not None:\n        data = data.loc[:, dfs]\n    unnested_dfs = {}\n    for name, column in data.iteritems():\n        daily_dfs = Parallel(n_jobs=n_jobs)(\n            delayed(unpack_json)(item) for date, item in column.iteritems())\n        df = pd.concat(daily_dfs)\n        unnested_dfs[name] = df\n    return unnested_dfs","856285ff":"data_dir = Path('..\/input\/mlb-player-digital-engagement-forecasting\/')\n\ndf_names = ['seasons', 'teams', 'players', 'awards']\n\nfor name in df_names:\n    globals()[name] = pd.read_csv(data_dir \/ f\"{name}.csv\")\n\nkaggle_data_tabs = widgets.Tab()\n# Add Output widgets for each pandas DF as tabs' children\nkaggle_data_tabs.children = list([widgets.Output() for df_name in df_names])\n\nfor index in range(0, len(df_names)):\n    # Rename tab bar titles to df names\n    kaggle_data_tabs.set_title(index, df_names[index])\n    \n    # Display corresponding table output for this tab name\n    with kaggle_data_tabs.children[index]:\n        display(eval(df_names[index]))\n\ndisplay(kaggle_data_tabs)","4549a16e":"%%time\n# Define dataframes to load from training set\ndfs = [\n    'nextDayPlayerEngagement',  # targets\n    'playerBoxScores',  # features\n    # Other dataframes available for features:\n    # 'games',\n    # 'rosters',\n    # 'teamBoxScores',\n    # 'transactions',\n    # 'standings',\n    # 'awards',\n    # 'events',\n    # 'playerTwitterFollowers',\n    # 'teamTwitterFollowers',\n]\n\n# Read training data\ntraining = pd.read_csv(\n    data_dir \/ 'train.csv',\n    usecols=['date'] + dfs,\n)\n\n# Convert training data date field to datetime type\ntraining['date'] = pd.to_datetime(training['date'], format=\"%Y%m%d\")\ntraining = training.set_index('date').to_period('D')\nprint(training.info())","aa564bd5":"%time\n# Unpack nested dataframes and store in dictionary `training_dfs`\ntraining_dfs = unpack_data(training, dfs=dfs)\nprint('\\n', training_dfs.keys())","cc4a8359":"# Players in the test set. We'll filter our data for only this set of players\npids_test = players.playerId.loc[\n    players.playerForTestSetAndFuturePreds.fillna(False)\n].astype(str)\n\n# Name of target columns\ntargets = [\"target1\", \"target2\", \"target3\", \"target4\"]\n\n\ndef make_playerBoxScores(dfs: dict, features):\n    X = dfs['playerBoxScores'].copy()\n    X = X[['gameDate', 'playerId'] + features]\n    # Set dtypes\n    X = X.astype({name: np.float32 for name in features})\n    X = X.astype({'playerId': str})\n    # Create date index\n    X = X.rename(columns={'gameDate': 'date'})\n    X['date'] = pd.PeriodIndex(X.date, freq='D')\n    # Aggregate multiple games per day by summing\n    X = X.groupby(['date', 'playerId'], as_index=False).sum()\n    return X\n\n\ndef make_targets(training_dfs: dict):\n    Y = training_dfs['nextDayPlayerEngagement'].copy()\n    # Set dtypes\n    Y = Y.astype({name: np.float32 for name in targets})\n    Y = Y.astype({'playerId': str})\n    # Match target dates to feature dates and create date index\n    Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n    Y['date'] = pd.to_datetime(Y['date'])\n    Y = Y.set_index('date').to_period('D')\n    Y.index = Y.index - 1\n    return Y.reset_index()\n\n\ndef join_datasets(dfs):\n    dfs = [x.pivot(index='date', columns='playerId') for x in dfs]\n    df = pd.concat(dfs, axis=1).stack().reset_index('playerId')\n    return df\n\n\ndef make_training_data(training_dfs: dict,\n                       features,\n                       targets,\n                       fourier=4,\n                       test_size=30):\n    # Process dataframes\n    X = make_playerBoxScores(training_dfs, features)\n    Y = make_targets(training_dfs)\n    # Merge for processing\n    df = join_datasets([X, Y])\n    # Filter for players in test set\n    df = df.loc[df.playerId.isin(pids_test), :]\n    # Convert from long to wide format\n    df = df.pivot(columns=\"playerId\")\n    # Restore features and targets\n    X = df.loc(axis=1)[features, :]\n    Y = df.loc(axis=1)[targets, :]\n    # Fill missing values in features\n    X.fillna(-1, inplace=True)\n    # Create temporal features\n    fourier_terms = CalendarFourier(freq='A', order=fourier)\n    deterministic = DeterministicProcess(\n        index=X.index,\n        order=0,\n        seasonal=False,  # set to True for weekly seasonality\n        additional_terms=[fourier_terms],\n    )\n    X = pd.concat([X, deterministic.in_sample()], axis=1)\n    # Create train \/ validation splits\n    X_train, X_valid, y_train, y_valid = train_test_split(\n        X,\n        Y,\n        test_size=test_size,\n        shuffle=False,\n    )\n    return X_train, X_valid, y_train, y_valid, deterministic","37e5dcaf":"%%time\n# Columns to select from playerBoxScores, all numeric\nfeatures = [\n    \"hits\",\n    \"strikeOuts\",\n    \"homeRuns\",\n    \"runsScored\",\n    \"stolenBases\",\n    \"strikeOutsPitching\",\n    \"inningsPitched\",\n    \"strikes\",\n    \"flyOuts\",\n    \"groundOuts\",\n    \"errors\",\n]\n\n# Number of days to use for the validation set\ntest_size = 30\n\nX_train, X_valid, y_train, y_valid, deterministic = make_training_data(\n    training_dfs, \n    features=features, \n    targets=targets,\n    fourier=4,  # number of Fourier pairs describing annual seasonality\n    test_size=test_size,\n)","a20158ef":"def seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\n        \"husl\",\n        n_colors=X[period].nunique(),\n    )\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}\/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") \/ pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual\",\n            \"Semiannual\",\n            \"Quarterly\",\n            \"Bimonthly\",\n            \"Monthly\",\n            \"Biweekly\",\n            \"Weekly\",\n            \"Semiweekly\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Density\")\n    ax.set_title(\"Periodogram\")\n    return ax","83c1ad86":"# Select players in top decile of engagement\ndeciles = pd.qcut(y_train.mean().mean(level=1), q=10)\npids_top_decile = deciles.index[deciles == deciles.max()]\ny_top_decile = y_train.loc(axis=1)[:, pids_top_decile]\n\n# Create average engagement series\ny_top_decile_avg = (y_top_decile \/ y_top_decile.max(axis=0)).mean(axis=1)\ny_top_decile_avg.name = \"target\"\n\n# Yearly plot\nS = y_top_decile_avg.to_frame()\nS[\"month\"] = S.index.month  # the frequency\nS[\"year\"] = S.index.year  # the period\n_ = seasonal_plot(S, y=\"target\", period=\"year\", freq=\"month\")\n\n# Weekly plot\nS = y_top_decile_avg.to_frame()\nS[\"day\"] = S.index.dayofweek  # the frequency\nS[\"week\"] = S.index.week  # the period\n_ = seasonal_plot(S, y=\"target\", period=\"week\", freq=\"day\")","559c384e":"_ = plot_periodogram(y_top_decile_avg)","37f0be4c":"# Hyperparameters\nHIDDEN = 1024\nACTIVATION = 'relu'  # could try elu, gelu, swish\nDROPOUT_RATE = 0.5\nLEARNING_RATE = 1e-2\nBATCH_SIZE = 32\n\nOUTPUTS = y_train.shape[-1]\nmodel = keras.Sequential([\n    layers.Dense(HIDDEN, activation=ACTIVATION),\n    layers.BatchNormalization(),\n    layers.Dropout(DROPOUT_RATE),\n    layers.Dense(HIDDEN, activation=ACTIVATION),\n    layers.BatchNormalization(),\n    layers.Dropout(DROPOUT_RATE),\n    layers.Dense(HIDDEN, activation=ACTIVATION),\n    layers.BatchNormalization(),\n    layers.Dropout(DROPOUT_RATE),\n    layers.Dense(OUTPUTS),\n])","9e8d3e6c":"%%time\noptimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\nmodel.compile(optimizer=optimizer, loss='mae', metrics=['mae'])\n\nearly_stopping = keras.callbacks.EarlyStopping(patience=3)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=BATCH_SIZE,\n    epochs=100,\n    callbacks=[early_stopping],\n)","63c51d82":"def make_test_data(test_dfs: dict, features, deterministic):\n    X = make_playerBoxScores(test_dfs, features)\n    X = X.merge(pids_test, how='right')\n    X['date'] = X.date.fillna(method='ffill').fillna(method='bfill')\n    X.fillna(-1, inplace=True)\n    # Convert from long to wide format\n    X = X.pivot(index='date', columns=\"playerId\")\n    # Create temporal features\n    X = pd.concat([\n        X,\n        deterministic.out_of_sample(steps=1, forecast_index=X.index),\n    ],\n                  axis=1)\n    return X\n\n\ndef make_predictions(model, X, columns, targets):\n    y_pred = model.predict(X)\n    y_pred = pd.DataFrame(y_pred, columns=columns, index=X.index).stack()\n    y_pred[targets] = y_pred[targets].clip(0, 100)\n    y_pred['date_playerId'] = [\n        (date + 1).strftime('%Y%m%d') + '_' + str(playerId)\n        for date, playerId in y_pred.index\n    ]\n    y_pred.reset_index('playerId', drop=True, inplace=True)\n    y_pred = y_pred[['date_playerId'] + targets]  # reorder\n    y_pred.index = pd.Int64Index(\n        [int(date.strftime('%Y%m%d')) for date in y_pred.index], name='date')\n    return y_pred","568d9f5b":"%%time\nimport mlb\n\nenv = mlb.make_env()\niter_test = env.iter_test()\n\nfor (test_df, sample_prediction_df) in iter_test:\n    # Unpack features from test_df\n    test_dfs = unpack_data(test_df, dfs=['playerBoxScores'])\n    X = make_test_data(test_dfs, features, deterministic)\n\n    # Create predictions\n    y_pred = make_predictions(\n        model,\n        X,\n        columns=y_train.columns,\n        targets=targets,\n    )\n    submission = (\n        sample_prediction_df\n        [['date_playerId']]\n        .reset_index()  #  preserve index 'date'\n        .merge(y_pred, how='left', on='date_playerId')\n        .set_index('date')  #  restore index 'date'\n    )\n\n    # Submit predictions\n    env.predict(submission)  # constructs submissions.csv","ae811f26":"# Getting Started with MLB Player Digital Engagement Forecasting #","220fa4e5":"# Create Submission #","36f66d74":"From these plots, digital player engagement appears to have a strong annual component, but little or no weekly component.\n\nWe can verify this with the *periodogram*. The periodogram illustrates the strength of the frequencies within a signal -- specifically, the variance of the sine \/ cosine Fourier component oscillating at that frequency.","e981b364":"For this getting started notebook, we'll just use a simple feedforward network.","4d4704e4":"Both of these visualizations indicate yearly (or annual) seasonality in the engagement time series, which motivated our decision to use yearly Fourier features when constructing our feature set.","1a2b89d4":"# Data Exploration #","f8d1a372":"Defined in the next cell are a number of functions that will process our data into training and validation splits.","76f08fc2":"# Create Training Data #","e73bebe7":"There is a lot more data available than what we'll use in this notebook. See the [data documentation](https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/data) on the competition page for a complete description the *MLB Player Digital Engagement Forecasting* competition data. And be sure to check out Google data scientist Alok Pattani's in depth data exploration: [MLB Player Digital Engagement Data Exploration](https:\/\/www.kaggle.com\/alokpattani\/mlb-player-digital-engagement-data-exploration).","b0e9e354":"# Explainable AI and Hyperparameter Tuning with Vertex #\n\n[This complementary notebook](https:\/\/www.kaggle.com\/ryanholbrook\/vertex-ai-with-mlb-player-digital-engagement) demonstrates how to run this notebook in Vertex AI Notebooks. You'll learn how to use **Explainable AI (XAI)** to refine your features and how to tune your model with **Vertex Vizier**.","b33ee3f4":"### Construct training and validation splits","f8f5377b":"A *seasonal plot* can reveal seasonal effects in a time series. Let's look at seasonal plots for players in the top 10% of average engagement, one for yearly seasonality and one for weekly seasonality.","550adccb":"There are a number of supplementary files in addition to the training data.","b60dd237":"Welcome to the Getting Started notebook for the *MLB Digital Engagement Forecasting* competition! This notebook is a complete start-to-finish guide to entering this competition. We will:\n- load and join the data,\n- explore time series properties,\n- create a feature set,\n- train a neural network, and\n- make a submission.\n\nAs this is a *code competition*, be aware that your submission will be a notebook to make predictions during the test period. Read more about [code competitions](https:\/\/www.kaggle.com\/docs\/competitions#notebooks-only-competitions).\n\nIn the complementary notebook, [Vertex AI with MLB Player Digital Engagement](https:\/\/www.kaggle.com\/ryanholbrook\/vertex-ai-with-mlb-player-digital-engagement), we'll also demonstrate some of the capabilities of **Vertex AI**, Google's new unified AI platform:\n- using **Vertex AI Notebooks** on Google Cloud Platform\n- exploring **Explainable AI** on Vertex AI to refine your features\n- hyperparameter tuning with **Vertex Vizier**","504c7183":"The training data is a time-indexed collection of nested JSON fields containing information about each player. The targets are contained in the `nextDayPlayerEngagement` column, while the remaining columns contain data you could use to construct features. For this getting started notebook, we'll only use features from the `playerBoxScores` dataframe.","e84b620f":"To complete a submission for this competition, we'll need to commit this notebook and submit the resulting submission file it creates,`submissions.csv`. From the notebook editor:\n- make sure *Internet* is turned off in **Settings**,\n- click the **Save Version** button to the upper right,\n- make sure *Save and Run All (Commit)* is selected, and\n- click **Save**.\n\nOnce the commit completes (should only be three or four minutes):\n- select from the menubar **File -> Version History**,\n- select from the ellipsis menu of the latest version **... -> Submit to Competition**, and\n- click **Submit**\n\nKaggle will rerun the notebook on the public test set and display the score on the public leaderboard. [**My Submissions**](https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/submissions) will show the status of the submission: currently running, succeeded, or failed.\n\nThe submission requirements for code competitions can be somewhat exacting. If you're having trouble, checkout our [**Code Competitions - Errors & Debugging Tips**](https:\/\/www.kaggle.com\/docs\/competitions#notebooks-only-FAQ).","7fc06585":"### Read and extract dataframes","e9aa3368":"The next cell illustrates how you to create a submission for this competition. As this is a code competition that relies on a time series module, submissions must follow the requirements described on the [Evaluation Page](https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/overview\/evaluation) and [Data Page](https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/data).","cd511d70":"In this cell we'll define the features we want to use from `playerBoxScores`. This frame contains player statistics for every game in the training period. We've chosen just a few from the many available. The `make_training_data` function also adjoins some features modeling annual seasonality, motivated by our data exploration in the next section.","490db50f":"# Model #"}}