{"cell_type":{"407f4baf":"code","f043271f":"code","54ce50c6":"code","299a400b":"code","e2077d3f":"code","3695b5a4":"code","f62070ec":"code","37564376":"code","451f699d":"code","da738e02":"markdown"},"source":{"407f4baf":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:75% !important; }<\/style>\"))","f043271f":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nfrom sklearn import preprocessing\ndef load_df(csv_path='.\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [\"{}.{}\".format(column, subcolumn) for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    df = df.loc[:, (df != df.iloc[0]).any()] \n    print(\"Loaded {}. Shape: {}\".format(os.path.basename(csv_path), df.shape))\n    return df","54ce50c6":"train = load_df('..\/input\/train.csv')\ntrain = train.drop(['trafficSource.campaignCode', 'sessionId'], axis = 1) # \u0423\u0431\u0435\u0440\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 \u0441 \u043e\u0434\u043d\u0438\u043c \u043d\u0435 NaN \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c \u0438 ID. \u0442\u0440\u0430\u043d\u0437\u0430\u043a\u0446\u0438\u0438\ntest = load_df('..\/input\/test.csv')\ntest = test.drop(['sessionId'], axis = 1)\n\n# \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0434\u0430\u0442\u044b\ntrain['date'] = pd.to_datetime(train['date'], format = '%Y%m%d')\ntrain['visitStartTime_'] = pd.to_datetime(train['visitStartTime'], unit='s')\ntest['date'] = pd.to_datetime(test['date'], format = '%Y%m%d')\ntest['visitStartTime_'] = pd.to_datetime(test['visitStartTime'], unit='s')\n# \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0442\u0438\u043f \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\ntrain[\"totals.transactionRevenue\"] = train[\"totals.transactionRevenue\"].astype('float')","299a400b":"# \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\ntrain['hits_by_pageviews'] = train['totals.hits'].astype(float) \/ train['totals.pageviews'].astype(float)\ntest['hits_by_pageviews'] = test['totals.hits'].astype(float) \/ test['totals.pageviews'].astype(float)\n\ntrain['day_of_week'] = train['visitStartTime_'].dt.day_name()\ntest['day_of_week'] = test['visitStartTime_'].dt.day_name()\ntrain['hour'] = train['visitStartTime_'].dt.hour\ntest['hour'] = test['visitStartTime_'].dt.hour\ntrain['day'] = train['visitStartTime_'].dt.day\ntest['day'] = test['visitStartTime_'].dt.day","e2077d3f":"train[\"totals.transactionRevenue\"].fillna(0, inplace=True)\ntrain_y = train[\"totals.transactionRevenue\"].values\ntrain_id = train[\"fullVisitorId\"].values\ntest_id = test[\"fullVisitorId\"].values\n\n\n# label encode the categorical variables and convert the numerical variables to float\ncat_cols = [\"channelGrouping\", \"device.browser\", \n            \"device.deviceCategory\", \"device.operatingSystem\", \n            \"geoNetwork.city\", \"geoNetwork.continent\", \n            \"geoNetwork.country\", \"geoNetwork.metro\",\n            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n            \"trafficSource.adwordsClickInfo.adNetworkType\", \n            \"trafficSource.adwordsClickInfo.gclId\", \n            \"trafficSource.adwordsClickInfo.page\", \n            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n            \"trafficSource.keyword\", \"trafficSource.medium\", \n            \"trafficSource.referralPath\", \"trafficSource.source\",\n            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect',\n            'day_of_week', 'hour', 'day', 'device.isMobile']\nfor col in cat_cols:\n    print(col)\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train[col].values.astype('str')) + list(test[col].values.astype('str')))\n    train[col] = lbl.transform(list(train[col].values.astype('str')))\n    test[col] = lbl.transform(list(test[col].values.astype('str')))\n\n\nnum_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", 'totals.bounces',  'totals.newVisits', 'hits_by_pageviews', 'visitStartTime']    \nfor col in num_cols:\n    train[col] = train[col].astype(float)\n    test[col] = test[col].astype(float)\n\n\n    \n# Split the train dataset into development and valid based on time \ndev_df = train[train['date']<='2017-05-31']\nval_df = train[train['date']>'2017-05-31']\ndev_y = np.log1p(dev_df[\"totals.transactionRevenue\"].values)\nval_y = np.log1p(val_df[\"totals.transactionRevenue\"].values)\n\ndev_X = dev_df[cat_cols + num_cols] \nval_X = val_df[cat_cols + num_cols] \ntest_X = test[cat_cols + num_cols] ","3695b5a4":"import lightgbm as lgb\ndef run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\", \n        \"num_leaves\" : 30,\n        \"min_child_samples\" : 100,\n        \"learning_rate\" : 0.1,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.5,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    pred_val_y = model.predict(val_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, pred_val_y\n\n# Training the model #\npred_test, model, pred_val = run_lgb(dev_X, dev_y, val_X, val_y, test_X)","f62070ec":"from sklearn import metrics\npred_val[pred_val<0] = 0\nval_pred_df = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\nval_pred_df[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\nval_pred_df[\"PredictedRevenue\"] = np.expm1(pred_val)\n#print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))\nval_pred_df = val_pred_df.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\nprint(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))","37564376":"sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\npred_test[pred_test<0] = 0\nsub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\nsub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\nsub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\nsub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\nsub_df.to_csv(\"baseline_lgb.csv\", index=False)","451f699d":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(12,18))\nlgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance\", fontsize=15)\nplt.show()","da738e02":"if bounds then revenue = 0"}}