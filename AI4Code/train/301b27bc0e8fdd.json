{"cell_type":{"54bf4380":"code","54cc1610":"code","6238a227":"code","15a54884":"code","462ea806":"code","4a26255c":"code","7cf33a92":"code","2536ff66":"code","96d3e223":"code","65b5f826":"code","9c51114c":"code","d679bb28":"code","2b165611":"code","f0461dd2":"code","2fb45a62":"code","cb34c91a":"code","df75f7c4":"code","58269a5e":"code","b975ed77":"code","82eca41f":"code","781bdadc":"code","d7a991d3":"code","9b712fee":"code","c8c0795b":"code","3d356f8b":"code","05baaf91":"code","454e4fbe":"code","6f3b1b19":"code","bd626879":"code","e13cd7d7":"code","76861129":"code","51163b38":"code","833a7cfb":"code","b93d89d0":"code","e3afb04c":"code","84fc5e8e":"code","6f39602e":"code","c8308f01":"code","ef9556c4":"code","66ef868a":"code","e932c650":"code","2e04f8ef":"code","ad618e95":"markdown","4cc71381":"markdown","c4347626":"markdown","ce59a2e5":"markdown","526c931a":"markdown","64a44dde":"markdown","b9d9d93c":"markdown","593dbb79":"markdown","a0be9401":"markdown","ed762a26":"markdown","8202c185":"markdown"},"source":{"54bf4380":"#LIBRARIES\nimport os\nimport numpy as np\nimport pandas as pd\n\n#VISUALIZATION\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#MACHINE LEARNING\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","54cc1610":"#importing data \ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\ncombine = [train_df,test_df]","6238a227":"train_df.head()","15a54884":"train_df.tail()","462ea806":"train_df.info()\ntest_df.info()","4a26255c":"train_df.describe(include='all')","7cf33a92":"#Parch and Survival\ntrain_df[['Parch','Survived']].groupby(['Parch'],as_index=False).mean().sort_values(by='Survived',ascending=False)","2536ff66":"#SibSp and survival\ntrain_df[['SibSp','Survived']].groupby(['SibSp'],as_index=False).mean().sort_values(by='Survived',ascending=False)","96d3e223":"#Sex and Survival\ntrain_df[['Sex','Survived']].groupby(['Sex'],as_index=False).mean().sort_values(by='Survived',ascending=False)","65b5f826":"#Pclass and Survival\ntrain_df[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean().sort_values(by='Survived',ascending=False)","9c51114c":"# Age vs Survival\ng=sns.FacetGrid(train_df,col='Survived')\ng.map(plt.hist,'Age',bins=20)","d679bb28":"# Age and Pclass vs Survival \ng=sns.FacetGrid(train_df,col='Survived',row='Pclass',size=2.5,aspect=2)\ng.map(plt.hist,'Age',bins=20)","2b165611":"# adding Sex, Embarked and Pclass to the model\ngrid=sns.FacetGrid(train_df,row='Embarked',size=2.5,aspect=1.6)\ngrid.map(sns.pointplot,'Pclass','Survived','Sex',palette='deep')\ngrid.add_legend()","f0461dd2":"#visualising based on Sex, Fare\ngrid=sns.FacetGrid(train_df,row='Embarked',col='Survived',size=2.2,aspect=1.6)\ngrid.map(sns.barplot, 'Sex','Fare',ci=None)\ngrid.add_legend()","2fb45a62":"print('Before', train_df.shape, test_df.shape,combine[0].shape,combine[1].shape)\n\ntrain_df= train_df.drop(['Ticket','Cabin'],axis=1)\ntest_df= test_df.drop(['Ticket','Cabin'],axis=1)\ncombine= [train_df,test_df]\n\nprint('After', train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","cb34c91a":"for dataset in combine:\n    dataset=dataset.drop(['Name'],axis=1)\n    \ncombine=[train_df,test_df]","df75f7c4":"#converting categorical values to numerical\nmap1={'male':0,'female':1}\nmap2={'S':1,'Q':2,'C':3}\ntrain_df=train_df.replace({'Sex':map1,'Embarked':map2})\ntest_df=test_df.replace({'Sex':map1,'Embarked':map2})\ncombine=[train_df,test_df]\n\ntrain_df.describe()","58269a5e":"#Filling the missing values in Age\ng=sns.FacetGrid(train_df,row='Embarked',col='Survived',size=4,aspect=2)\ng.map(sns.pointplot,'Sex','Age',palette='deep')\ng.add_legend()","b975ed77":"#filling the missing values of Age from the above observation with median\nfor dataset in combine:\n    guess_age=dataset[:]['Age'].median()\n\ntrain_df[:]['Age']=train_df[:]['Age'].fillna(guess_age)\ntest_df[:]['Age']=test_df[:]['Age'].fillna(guess_age)\ncombine=[train_df,test_df]\nfor dataset in combine:\n    dataset.describe()\n","82eca41f":"for dataset in combine:\n    guess=dataset[:]['Embarked'].median()\n\ntrain_df[:]['Embarked']=train_df[:]['Embarked'].fillna(guess)\ncombine=[train_df,test_df]\nfor dataset in combine:\n    dataset.describe()","781bdadc":"for dataset in combine:\n    guess_fare=dataset[:]['Fare'].median()\n\ntest_df[:]['Fare']=train_df[:]['Fare'].fillna(guess_fare)\ncombine=[train_df,test_df]\nfor dataset in combine:\n    dataset.describe()","d7a991d3":"#creating a new feature for age called Age bands\ntrain_df['AgeBand']=pd.cut(train_df['Age'],5)\ntrain_df[['AgeBand','Survived']].groupby(('AgeBand'),as_index=False).mean().sort_values(by='AgeBand',ascending=True)","9b712fee":"#categorizing into age bands\nfor dataset in combine:\n    dataset.loc[dataset['Age']<=16,'Age'] = 0\n    dataset.loc[(dataset['Age']>16) & (dataset['Age']<=32),'Age'] = 1\n    dataset.loc[(dataset['Age']>32) & (dataset['Age']<=48),'Age'] = 2\n    dataset.loc[(dataset['Age']>48) & (dataset['Age']<=64),'Age'] = 3\n    dataset.loc[dataset['Age']>64,'Age'] = 4\n\ncombine=[train_df,test_df]\ntrain_df.head()\n    ","c8c0795b":"#dropping the AgeBand feature\ntrain_df=train_df.drop(['AgeBand','Name'],axis=1)\ncombine=[train_df,test_df]\ntrain_df.head()","3d356f8b":"#create one more feature combining SibSp and Parch\nfor dataset in combine:\n    dataset['FamilySize']=dataset['SibSp']+dataset['Parch']+1\ntrain_df[['FamilySize','Survived']].groupby(['FamilySize'],as_index=False).mean().sort_values(by='Survived',ascending=False)\ncombine=[train_df,test_df]\ntrain_df.head()","05baaf91":"#from above we can create a feature for whether a person is alone\nfor dataset in combine:\n    dataset.loc[dataset['FamilySize']<=1,'IsAlone'] = 1\n    dataset.loc[dataset['FamilySize']>1,'IsAlone'] = 0\n    \ncombine=[train_df,test_df]\ntrain_df.head()","454e4fbe":"#dropping redundant features namely SibSp, Parch, FamilySize\ntrain_df=train_df.drop(['SibSp','Parch','FamilySize'],axis=1)\ncombine=[train_df,test_df]\ntrain_df.head()","6f3b1b19":"#similar to the AgeBand we can also create FareBand\ntrain_df['FareBand']=pd.cut(train_df['Fare'],5)\ntrain_df[['FareBand','Survived']].groupby('FareBand',as_index=True).mean().sort_values(by='Survived',ascending=False)","bd626879":"#converting into numerical categories\ncombine=[train_df,test_df]\nfor dataset in combine:\n    dataset.loc[dataset['Fare']<=102,'Fare'] = 1\n    dataset.loc[(dataset['Fare']>102) & (dataset['Fare']<=205), 'Fare'] = 2\n    dataset.loc[(dataset['Fare']>205) & (dataset['Fare']<=308), 'Fare'] = 3\n    dataset.loc[(dataset['Fare']>308) & (dataset['Fare']<=410), 'Fare'] = 4\n    dataset.loc[dataset['Fare']>410, 'Fare'] = 5\ncombine=[train_df,test_df]\n\ntrain_df.head()","e13cd7d7":"#dropping FareBand\ntrain_df=train_df.drop(['FareBand'],axis=1)\ncombine=[train_df,test_df]\n\ntrain_df.head(10)","76861129":"test_df.head(10)","51163b38":"test_df=test_df.drop(['Name','SibSp','Parch'],axis=1)\ntest_df.head()","833a7cfb":"for dataset in combine:\n    dataset.info()","b93d89d0":"# creating train and test sets\nX_train=train_df.drop('Survived',axis=1)\nY_train=train_df['Survived']\nX_test=test_df.drop('PassengerId',axis=1)\n\nX_train.shape, Y_train.shape, X_test.shape","e3afb04c":"#Logistic Regression\nlogreg=LogisticRegression()\nlogreg.fit(X_train,Y_train)\nY_predict=logreg.predict(X_test)\nacc_log=round(logreg.score(X_train,Y_train)*100,2)\nacc_log","84fc5e8e":"# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train,Y_train)\nY_predict=svc.predict(X_test)\nacc_svc=round(svc.score(X_train,Y_train)*100,2)\nacc_svc","6f39602e":"# KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train,Y_train)\nY_predict=knn.predict(X_test)\nacc_knn=round(knn.score(X_train,Y_train)*100,2)\nacc_knn","c8308f01":"# Gaussian Naive Bayes\ngaussian=GaussianNB()\ngaussian.fit(X_train,Y_train)\nY_predict=gaussian.predict(X_test)\nacc_gaussian=round(gaussian.score(X_train,Y_train)*100,2)\nacc_gaussian","ef9556c4":"# Random Forest Classifier\nrfc=RandomForestClassifier()\nrfc.fit(X_train,Y_train)\nY_predict=rfc.predict(X_test)\nacc_rfc=round(rfc.score(X_train,Y_train)*100,2)\nacc_rfc","66ef868a":"# Tabulating the values\nmodels = pd.DataFrame({\n    'Model':['Logistic_Regression','Support_Vector_Machine','KNN','GaussianNB','Random_Forest_Classifier'],\n    'Score':[acc_log, acc_svc, acc_knn, acc_gaussian, acc_rfc]})\nmodels.sort_values(by='Score',ascending=False)","e932c650":"submission=pd.DataFrame({\n            \"PassengerId\":test_df['PassengerId'],\n            \"Survived\":Y_predict})\nsubmission.head()","2e04f8ef":"filename='Titanic_Survival.csv'\nsubmission.to_csv(filename,index=False)\n","ad618e95":"*Females were more likely to be survived*\n\n*People having 1 to 2 siblings and a spouse are more likely to survive*\n\n> **Visualising the above info**","4cc71381":"> **Dropping the other features namely Cabin, Passenger ID, Ticket**","c4347626":"> **Looking out for missing and incomplete data**","ce59a2e5":"> **We also need to drop certain features**\n\n**Cabin** is highly incomplete, so drop it\n\n**Passenger ID, Name** and **Ticket** may also be dropped as they are irrelevant in determining the survival.","526c931a":"> **Previewing the data**","64a44dde":"> **Submission**","b9d9d93c":"*High fare class are likely to survive*\n\n*Survival also depends on the port of Embarkment*\n\n*So we finally decided upon the features that are to be used*","593dbb79":"Out of 891 survived, 577 are male(~65%).\n\nMost of the survived(644) embarked from port **S(~72%)**.\n\nSo from here Age and Embarked play a important role in suvival rate. So we need to fill up the missing values.","a0be9401":"> **So, Random Forest Classifier is the best classifier with an accuracy of 97.08%**","ed762a26":"> ** Columns having missing values are**\n\n1.*Train data - Age,Embarked, Cabin*\n\n2.*Test data - Age, Cabin*","8202c185":"> **We also need to visualize based on certain columns**"}}