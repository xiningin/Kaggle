{"cell_type":{"89229506":"code","a7d2f9a4":"code","bb7ec040":"code","f80a1b55":"code","332c49aa":"code","249e3cf5":"code","2a927350":"code","b813cde3":"code","94db27ca":"code","d38eb84d":"code","140b7b56":"code","ca97aa5f":"code","cd853dfe":"code","e0474f9e":"code","6fcfbf7d":"code","46d9f57f":"code","7ad6608e":"code","c943c7a0":"code","2ac27f2a":"code","0b17de35":"code","96b60a8c":"code","8f0fb669":"code","a45ab1db":"code","b5647113":"code","8390b7e5":"code","14eecb23":"code","a7a5c65c":"code","3c1b119b":"code","80f20dcd":"code","5c0605a8":"code","71015e96":"code","ba33c825":"code","a6758ca7":"code","810b848d":"code","dc9332fd":"code","d337ef17":"code","f5fc5a7d":"code","576f6370":"code","b8733d9b":"code","7de9343e":"code","29a483f3":"code","6bb3fe98":"code","672d80d6":"code","e8d9a853":"code","51819a97":"code","066816c0":"code","9d4926d8":"code","79e11363":"code","923878b0":"code","3c5be5c9":"code","4a69ac07":"code","acf469e3":"code","2cb22752":"code","4b43a9ee":"code","36f59929":"code","d6583be2":"code","c6d9126f":"code","5231730e":"code","1e53f70d":"code","31909837":"code","c53b01db":"code","91cdb5ca":"code","d3c25f1a":"code","0d355ac1":"code","6342dec9":"code","552e99a3":"code","93ecbabf":"code","d14dad28":"code","cd2ba786":"code","320ada5d":"code","0e60fd60":"code","246347d4":"markdown","9049e4c4":"markdown","e1901977":"markdown","8f4a3a69":"markdown","1d703525":"markdown","ad1c2e18":"markdown","96531319":"markdown","8a4cac60":"markdown","44079ee9":"markdown","7762c4f3":"markdown","5e86ff20":"markdown","c5fb99ba":"markdown","ee6f8102":"markdown","d82a31e7":"markdown","71808622":"markdown","86c970e4":"markdown"},"source":{"89229506":"import os\nimport sys\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nimport missingno as msno\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 14})\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom pandas_profiling import ProfileReport \n\nfrom IPython.display import Image\nfrom wordcloud import WordCloud, STOPWORDS\nfrom IPython.display import Markdown, display, Image, display_html","a7d2f9a4":"class DfOverview:\n    \"\"\"\n        Give an overview for a given data frame, \n        like null persentage for each columns, \n        unique value percentage for each columns and more\n    \"\"\"\n\n    def __init__(self, df: pd.DataFrame) -> None:\n        self.df = df\n\n    def missing_value(self) -> None:\n        nullSum = self.df.isna().sum()\n        return [col for col in nullSum]\n\n    def unique_values(self) -> None:\n        return [self.getUniqueCount(column) for column in self.df]\n\n    def percentage(self, list):\n        return [str(round(((value \/ self.df.shape[0]) * 100), 2)) + '%' for value in list]\n\n    def getOverview(self) -> None:\n\n        _labels = [column for column in self.df]  # Only numeric columns\n        _count = self.df.count().values\n        _unique = [self.df[column].value_counts().shape[0] for column in self.df]\n        _missing_values = self.missing_value()\n\n        columns = [\n            'label',\n            'count',\n            'none_count',\n            'none_percentage',\n            'unique_value_count',\n            'unique_percentage',\n            'dtype']\n        data = zip(\n            _labels,\n            _count,\n            _missing_values,\n            self.percentage(_missing_values),\n            _unique,\n            self.percentage(_unique),\n            self.df.dtypes\n        )\n        new_df = pd.DataFrame(data=data, columns=columns)\n        new_df.set_index('label', inplace=True)\n        new_df.sort_values(by=[\"none_count\"], inplace=True)\n        return new_df","bb7ec040":"def view_df(df, subset=[], color='#66F582'):\n    df = df.reset_index()\n    style = df.style.set_table_attributes(\"style='display:inline'\").\\\n        bar(subset=subset, axis=1, color=color)\\\n        .format({\"label\": lambda x: x.upper()})\\\n        .set_properties(**{'background-color': 'white', 'color': 'black'})\n    display_html(style._repr_html_(), raw=True)","f80a1b55":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\nfiles = []\n\nfor file in filenames:\n    df = pd.read_csv(dirname + \"\/\" + filenames[0], index_col = None, header = 0)\n    district_id = file.split('.')[0]\n    df['district_id'] = district_id\n    files.append(df)\n    \nengagement = pd.concat(files)\nengagement = engagement.reset_index(drop = True)\nengagement['time'] = pd.to_datetime(engagement['time'])\n\ndistricts_info = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\nproducts_info = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')","332c49aa":"profile = ProfileReport( districts_info, title='Pandas profiling report ' , html={'style':{'full_width':True}})\nprofile.to_notebook_iframe()","249e3cf5":"districts_info.head(5)","2a927350":"df_overview = DfOverview(districts_info.drop(columns=['district_id']))\ndf_ = df_overview.getOverview()\nview_df(df_, [\"count\", \"none_count\", \"unique_value_count\"])","b813cde3":"districts_info = districts_info[districts_info.state.notna()].reset_index(drop=True)","94db27ca":"def get_mode(df, state, locale, column):\n    values = df[(df.locale == locale)]\n    if(len(list(values[column].mode()))>0):\n        return values[column].mode()[0]\n    else:\n        return None","d38eb84d":"def replace_with_mode(value, state, locale, column):\n    if str(value)!= 'nan':\n        return value\n    else: \n        return get_mode(districts_info, state, locale, column)","140b7b56":"districts_info['county_connections_ratio'] = districts_info.apply(lambda x: replace_with_mode(x['county_connections_ratio'], x['state'], x['locale'], \"county_connections_ratio\"), axis=1)\ndistricts_info['pct_free\/reduced'] = districts_info.apply(lambda x: replace_with_mode(x['pct_free\/reduced'], x['state'], x['locale'], \"pct_free\/reduced\"), axis=1)\ndistricts_info['pp_total_raw'] = districts_info.apply(lambda x: replace_with_mode(x['pp_total_raw'], x['state'], x['locale'], \"pp_total_raw\"), axis=1)","ca97aa5f":"df_overview = DfOverview(districts_info.drop(columns=['district_id']))\ndf_ = df_overview.getOverview()\nview_df(df_, [\"count\", \"none_count\", \"unique_value_count\"])","cd853dfe":"print(districts_info['state'].unique())","e0474f9e":"print(districts_info['locale'].unique())","6fcfbf7d":"print(districts_info['pct_black\/hispanic'].unique())","46d9f57f":"def insert_average(x):\n    first = x.split(\" \")[0][1:-1]\n    last = x.split(\" \")[1][1:-1]\n    if(last == \"\"):\n        last = x.split(\" \")[1][:-1]\n    return (float(first)+float(last))\/2","7ad6608e":"print(districts_info['pct_black\/hispanic'].unique())","c943c7a0":"districts_info['pct_black\/hispanic'] = districts_info['pct_black\/hispanic'].apply(lambda x: insert_average(x))","2ac27f2a":"print(districts_info['county_connections_ratio'].unique())","0b17de35":"districts_info['county_connections_ratio'] = districts_info['county_connections_ratio'].apply(lambda x: insert_average(x))","96b60a8c":"print(districts_info['county_connections_ratio'].unique())","8f0fb669":"print(districts_info['pct_free\/reduced'].unique())","a45ab1db":"districts_info['pct_free\/reduced'] = districts_info['pct_free\/reduced'].apply(lambda x: insert_average(x))","b5647113":"print(districts_info['pct_free\/reduced'].unique())","8390b7e5":"print(districts_info['pp_total_raw'].unique())","14eecb23":"districts_info['pp_total_raw'] = districts_info['pp_total_raw'].apply(lambda x: insert_average(x))","a7a5c65c":"print(districts_info['pp_total_raw'].unique())","3c1b119b":"districts_info.head(10)","80f20dcd":"profile = ProfileReport( products_info, title='Pandas profiling report ' , html={'style':{'full_width':True}})\nprofile.to_notebook_iframe()","5c0605a8":"df_overview = DfOverview(products_info.drop(columns=['LP ID']))\ndf_ = df_overview.getOverview()\nview_df(df_, [\"count\", \"none_count\", \"unique_value_count\"])","71015e96":"products_info = products_info[products_info['Provider\/Company Name'].notna()].reset_index(drop=True)","ba33c825":"def get_mode(df, company, column):\n    values = df[(df[\"Provider\/Company Name\"] == company)]\n    if(len(list(values[column].mode()))>0):\n        return values[column].mode()[0]\n    else:\n        return None","a6758ca7":"def replace_with_mode(value, company, column):\n    if str(value)!= 'nan':\n        return value\n    else: \n        return get_mode(products_info, company, column)","810b848d":"products_info['Sector(s)'] = products_info.apply(lambda x: replace_with_mode(x['Sector(s)'], x['Provider\/Company Name'], \"Sector(s)\"), axis=1)\nproducts_info['Primary Essential Function'] = products_info.apply(lambda x: replace_with_mode(x['Primary Essential Function'], x['Provider\/Company Name'], \"Primary Essential Function\"), axis=1)","dc9332fd":"products_info.dropna(inplace=True)","d337ef17":"print(products_info['Sector(s)'].unique())","f5fc5a7d":"print(products_info['Primary Essential Function'].unique())","576f6370":"# Splitting up the Primary Essential Function\n\nproducts_info['primary_function_main'] = products_info['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_info['primary_function_sub'] = products_info['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_info['primary_function_sub'] = products_info['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproducts_info.drop(\"Primary Essential Function\", axis=1, inplace=True)","b8733d9b":"df_overview = DfOverview(products_info.drop(columns=['LP ID']))\ndf_ = df_overview.getOverview()\nview_df(df_, [\"count\", \"none_count\", \"unique_value_count\"])","7de9343e":"df_overview = DfOverview(engagement)\ndf_ = df_overview.getOverview()\nview_df(df_, [\"count\", \"none_count\", \"unique_value_count\"])","29a483f3":"engagement['engagement_index'] = engagement['engagement_index'].fillna(0)","6bb3fe98":"engagement['year'] = pd.DatetimeIndex(engagement['time']).year\nengagement['month'] = pd.DatetimeIndex(engagement['time']).month\nengagement['day'] = pd.DatetimeIndex(engagement['time']).day\nengagement['DayOfWeek'] = engagement.time.dt.dayofweek\nengagement['WeekOfYear'] = engagement.time.dt.weekofyear\nengagement['Weekend'] = engagement['DayOfWeek'].apply(lambda x: 1 if x >= 6 else 0)\nengagement['Weekday'] = engagement['DayOfWeek'].apply(lambda x: 1 if x < 6 else 0)","672d80d6":"df_overview = DfOverview(engagement)\ndf_ = df_overview.getOverview()\nview_df(df_, [\"count\", \"none_count\", \"unique_value_count\"])","e8d9a853":"districts_info.head(5)","51819a97":"px.histogram(districts_info, x='state', color=\"locale\").update_xaxes(categoryorder='total ascending')","066816c0":"df = px.data.tips()\nfig = px.bar(districts_info, y=\"state\", color='locale', orientation='h',\n             title='Count of districts in the available States')\nfig.update_xaxes(categoryorder = 'total ascending')\nfig.show()","9d4926d8":"df = px.data.tips()\nsunb_data = districts_info[['state', 'locale']]\nsunb_data = sunb_data.groupby(['state', 'locale']).size().reset_index(name='count')\nfig = px.sunburst(sunb_data, path=['state', 'locale'], values='count')\nfig.show()","79e11363":"state_abb = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}","923878b0":"districts_info['state_abb'] = districts_info['state'].map(state_abb)\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Count of districts in the available States\",\n    title_font = dict(\n            family = \"monospace\",\n            size = 25,\n            color = \"black\"\n            ),\n    geo_scope = 'usa'\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations = districts_info['state_abb'].value_counts().to_frame().reset_index()['index'],\n        zmax = 1,\n        z = districts_info['state_abb'].value_counts().to_frame().reset_index()['state_abb'],\n        locationmode = 'USA-states',\n        marker_line_color = 'white',\n        geo = 'geo',\n        colorscale = \"Reds\", \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()","3c5be5c9":"products_info.head(5)","4a69ac07":"cloud = WordCloud(width=1080, height=270,background_color='white').generate(\" \".join(products_info['Product Name'].astype(str)))\nplt.figure(figsize=(22, 10))\nplt.imshow(cloud)\nplt.axis('off');","acf469e3":"px.histogram(products_info, x='primary_function_sub', color=\"primary_function_main\").update_xaxes(categoryorder='total ascending')","2cb22752":"px.histogram(products_info, x='primary_function_sub', color=\"Sector(s)\").update_xaxes(categoryorder='total ascending')","4b43a9ee":"px.histogram(products_info, x='primary_function_main', color=\"primary_function_sub\").update_xaxes(categoryorder='total ascending')","36f59929":"freq = products_info.groupby(['Provider\/Company Name']).count()\nfreq.sort_values(by=['Product Name'], ascending=False )[:10]","d6583be2":"df = px.data.tips()\nsunb_data = products_info[['primary_function_main', 'Provider\/Company Name', 'Sector(s)']]\nsunb_data = sunb_data.dropna()\nsunb_data = sunb_data.groupby(['primary_function_main','Provider\/Company Name']).size().reset_index(name='count')\nfig = px.sunburst(sunb_data, path=['primary_function_main','Provider\/Company Name'], values='count')\nfig.show()","c6d9126f":"engagement.head()","5231730e":"plt.figure(figsize=(15,12))\nsns.set_style('whitegrid')\nsns.stripplot(x=\"month\", y=\"pct_access\", data=engagement)\nplt.show()","1e53f70d":"districts_info","31909837":"districts_info.info()","c53b01db":"products_info = products_info.rename(columns={\"LP ID\": \"lp_id\"})\ndf = pd.merge(engagement, products_info, on='lp_id')\ndistricts_info['district_id'] = districts_info['district_id'].astype(str)\ndf = pd.merge(df, districts_info, on='district_id')\n\ndf.head(5)","91cdb5ca":"daily_trend = df.groupby(['day', 'Sector(s)']).agg({'engagement_index': 'mean', 'pct_access': 'mean'})\ndaily_trend = daily_trend.unstack().swaplevel(0, 1, 1).sort_index(1)","d3c25f1a":"def plot_trend(df, columns, feature, title, x_label=\"\", y_label=\"\", labels=['']):\n  plt.figure(figsize=(18, 6))\n  for i in range(len(columns)):\n    sns.lineplot(x=df.index, y=df[columns[i]][feature], label=labels[i])\n  plt.title(title, fontsize=15, fontweight='bold')\n  plt.ylabel(x_label, fontsize=14)\n  plt.xlabel(y_label, fontsize=14)\n  plt.show()","0d355ac1":"columns = df['Sector(s)'].unique()\nplot_trend(daily_trend, columns, 'engagement_index', 'Average daily sales for 3 years', labels=columns)","6342dec9":"plot_trend(daily_trend, columns, 'pct_access', 'Average daily sales for 3 years', labels=columns)","552e99a3":"daily_trend = df.groupby(['day', 'primary_function_main']).agg({'engagement_index': 'mean', 'pct_access': 'mean'})\ndaily_trend = daily_trend.unstack().swaplevel(0, 1, 1).sort_index(1)","93ecbabf":"columns = df['primary_function_main'].unique()\nplot_trend(daily_trend, columns, 'engagement_index', 'Average daily sales for 3 years', labels=columns)","d14dad28":"monthly_trend = df.groupby(['month', 'primary_function_main']).agg({'engagement_index': 'mean', 'pct_access': 'mean'})\nmonthly_trend = monthly_trend.unstack().swaplevel(0, 1, 1).sort_index(1)","cd2ba786":"plot_trend(monthly_trend, columns, 'engagement_index', 'Average daily sales for 3 years', labels=columns)","320ada5d":"plot_trend(monthly_trend, columns, 'pct_access', 'Average daily sales for 3 years', labels=columns)","0e60fd60":"monthly_trend = df.groupby(['time', 'primary_function_main']).agg({'engagement_index': 'mean', 'pct_access': 'mean'})\nmonthly_trend = monthly_trend.unstack().swaplevel(0, 1, 1).sort_index(1)","246347d4":"## Joining store and train datasets","9049e4c4":"After preprocessing, we are left with a reduced districts_info dataframe with 176 districts and the product_info dataframe looks are follows:","e1901977":"### ENGAGEMENT\n\nThe engagement file includes information about engagement of students with learning products in various school districts for the entire year 2020:\n\n- `time` - date.\n- `lp_id` - the unique identifier of the product.\n- `pct_access` - percentage of students in the district have at least one page-load event of a given product and on a given day.\n- `engagement_index` - total page-load events per one thousand students of a given product and on a given day.\n- `district_id`","8f4a3a69":"Dropping Districts with NaN States","1d703525":"## Exploration","ad1c2e18":"## Preprocessing","96531319":"### Provide","8a4cac60":"## Imports","44079ee9":"### Engagement","7762c4f3":"### DISTRICTS\n\nThe districts file includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab:\n\n- `distrist_id`\n- `state`\n- `locale`\n- `pct_black\/hispanic` - percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data.\n- `pct_free\/reduced` - percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data.\n- `county_connections_ratio` - ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version).\n- `pp_total_raw` - per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project.\n\n","5e86ff20":"### District","c5fb99ba":"## Data","ee6f8102":"Replace the other non values with the mode in local","d82a31e7":"### PRODUCTS\n\nThe product file includes information about the characteristics of the top 372 products with most users in 2020:\n\n- `LP ID` - the unique identifier of the product.\nURL\n- `Product Name`\n- `Provider\/Company Name`\n- `Sector(s)` - sector of education where the product is used.\n- `Primary Essential Function` - the basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled.","71808622":"### Lets handle the non values first","86c970e4":"# COVID-19 Impact on Digital Learning"}}