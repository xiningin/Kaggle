{"cell_type":{"2f42e810":"code","71b56f1d":"code","1b681901":"code","8c7ef705":"code","6313cdc6":"code","3f227fd9":"code","bf12f917":"code","3cdb2f73":"code","fad07b75":"code","6c3b4715":"code","20e0d319":"code","d9d4ab10":"code","d0d2c64f":"code","3b8cf2f1":"code","dd44658a":"code","a92d0dc8":"code","3fc75021":"code","83b95e48":"code","6a422032":"code","8858bdcb":"code","10890387":"code","fd528718":"code","cfa65f54":"code","6520617d":"code","4d53d001":"code","c8697a33":"code","ddb80620":"code","81b3f806":"code","7af0f013":"code","fbb1992f":"code","46207d01":"code","bf165c0c":"code","8af1ca72":"code","2ac6dfc3":"code","0c9a8754":"code","c6a205c8":"code","544acd42":"code","b26808f4":"code","88151007":"code","288e0356":"code","a8d1a2e7":"code","36f521d6":"code","f1c627e9":"code","1b2d50be":"code","ff094db5":"code","1e41cd58":"code","5282bacf":"code","d373aad3":"code","94a77ce1":"code","77da119e":"code","a5b561f4":"code","49fc9423":"code","07156082":"code","54af8244":"code","4a4b587e":"code","6c275db7":"code","525cde91":"markdown","0af8f226":"markdown","b1cd5ef0":"markdown","c1f8348c":"markdown","34487489":"markdown","2f29d9ca":"markdown","17dc7de5":"markdown","e7e8f907":"markdown","0b765752":"markdown","c8fe6361":"markdown","0cf22be9":"markdown","bf35c438":"markdown","ea6e3e7f":"markdown","1ade3736":"markdown","bc89c412":"markdown","d6658ec1":"markdown","92322768":"markdown","a1d642cd":"markdown","cc6c296d":"markdown","a743c63e":"markdown","8b336246":"markdown","18d431cb":"markdown","f24fbcb5":"markdown","72447466":"markdown","1b18e2a0":"markdown","12c33d65":"markdown","856983f9":"markdown","9ad1a5b1":"markdown","3d8b666b":"markdown","1ecf91e7":"markdown","604cd74c":"markdown","9d47903e":"markdown","4c5cc666":"markdown"},"source":{"2f42e810":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","71b56f1d":"from datetime import datetime","1b681901":"# Plotly\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.figure_factory as ff\nprint(plotly.__version__)\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected=True)","8c7ef705":"#plot_bgcolor=\"#f5efe3\"\n#plot_bgcolor=\"#faf7e6\"\n#plot_bgcolor=\"#faf6e9\"\n#plot_bgcolor=\"#fffdf6\"\nplot_bgcolor = \"#fcfaf1\"\npaper_bgcolor = plot_bgcolor","6313cdc6":"%%time\ntrain_df = pd.read_feather(\"..\/input\/data-preprocessing\/train_preprocessed.feather\")","3f227fd9":"%%time\ntest_df = pd.read_feather(\"..\/input\/data-preprocessing\/test_preprocessed.feather\")","bf12f917":"train_df.columns","3cdb2f73":"train_df.info()","fad07b75":"train_df.shape","6c3b4715":"test_df.shape","20e0d319":"train_df.head(10)","d9d4ab10":"feats_to_examine = [\"device.browser\",\n                \"device.browserSize\",\n                \"device.browserVersion\",\n                \"device.deviceCategory\",\n                \"device.flashVersion\",\n                \"device.isMobile\",\n                \"device.language\",\n                \"device.mobileDeviceBranding\",\n                \"device.mobileDeviceInfo\",\n                \"device.mobileDeviceMarketingName\",\n                \"device.mobileDeviceModel\",\n                \"device.mobileInputSelector\",\n                \"device.operatingSystem\",\n                \"device.operatingSystemVersion\",\n                \"device.screenColors\",\n                \"device.screenResolution\"]\nunique_values_per_feature = []\nnum_unique_values = []\nfor fname in feats_to_examine: \n    unique_vals = train_df[fname].unique()\n    unique_values_per_feature.append(':'.join([str(v) for v in unique_vals]))\n    num_unique_values.append(len(unique_vals))\nunique_feats_df = pd.DataFrame({'feature': feats_to_examine, 'unique_values': unique_values_per_feature, 'unique_values_count': num_unique_values})\nunique_feats_df.sort_values(by=[\"unique_values_count\"], ascending=False)","d0d2c64f":"feats_to_examine = [\"geoNetwork.city\",\n                \"geoNetwork.cityId\",\n                \"geoNetwork.continent\",\n                \"geoNetwork.country\",\n                \"geoNetwork.latitude\",\n                \"geoNetwork.longitude\",\n                \"geoNetwork.metro\",\n                \"geoNetwork.networkDomain\",\n                \"geoNetwork.networkLocation\",\n                \"geoNetwork.region\",\n                \"geoNetwork.subContinent\"]\nunique_values_per_feature = []\nnum_unique_values = []\nfor fname in feats_to_examine: \n    unique_vals = train_df[fname].unique()\n    unique_values_per_feature.append(':'.join([str(v) for v in unique_vals]))\n    num_unique_values.append(len(unique_vals))\nunique_feats_df = pd.DataFrame({\"feature\": feats_to_examine, \"unique_values\": unique_values_per_feature, \"unique_values_count\": num_unique_values})\nunique_feats_df.sort_values(by=[\"unique_values_count\"], ascending=False)","3b8cf2f1":"feats_to_examine = train_df.columns\nunique_values_per_feature = []\nnum_unique_values = []\nfor fname in feats_to_examine: \n    unique_vals = train_df[fname].unique()\n    unique_values_per_feature.append(':'.join([str(v) for v in unique_vals]))\n    num_unique_values.append(len(unique_vals))\nunique_feats_df = pd.DataFrame({\"feature\": feats_to_examine, \"unique_values\": unique_values_per_feature, \"unique_values_count\": num_unique_values})\nunique_feats_df = unique_feats_df.sort_values(by=[\"unique_values_count\"], ascending=False)\n\n# Plot\ntrace = go.Bar(y=unique_feats_df[\"unique_values_count\"], \n               x=unique_feats_df[\"feature\"], marker=dict(color=\"#fa360a\"))\ndata = [trace]\nlayout = go.Layout(title=\"Count of unique values per feature\",\n                   xaxis=dict(title=\"Feature\", tickfont=dict(size=8, color=\"grey\")), \n                   yaxis=dict(type=\"log\", title=\"# of unique values\", tickfont=dict(size=8, color=\"grey\"), showgrid=False), \n                   plot_bgcolor=plot_bgcolor, \n                   paper_bgcolor=paper_bgcolor, height=700)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","dd44658a":"unique_feats_df","a92d0dc8":"feats_to_examine = unique_feats_df[unique_feats_df[\"unique_values_count\"] > 1].sort_index()[\"feature\"].values\ndataset_size = train_df.shape[0]\nmissing_percentage = [100.0 * train_df[fname].isna().sum() \/ dataset_size for fname in feats_to_examine]\nmissing_percentage_df = pd.DataFrame({\"feature\": feats_to_examine, \"missing_percentage\": missing_percentage})\nmissing_percentage_df = missing_percentage_df.sort_values(by=[\"missing_percentage\"], ascending=False)\ntrace = go.Bar(y=missing_percentage_df[\"missing_percentage\"], \n               x=missing_percentage_df[\"feature\"], marker=dict(color=\"#fa360a\"))\ndata = [trace]\nlayout = go.Layout(title=\"Missing data percentage of {} features\".format(len(feats_to_examine)), \n                   xaxis=dict(title=\"Feature\", tickfont=dict(size=8, color=\"grey\")), \n                   yaxis=dict(title=\"Missing percentage (%)\", tickfont=dict(size=8, color=\"grey\"), showgrid=False), \n                   plot_bgcolor=plot_bgcolor, paper_bgcolor=paper_bgcolor)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","3fc75021":"useful_features = unique_feats_df[unique_feats_df[\"unique_values_count\"] > 1].sort_index()[\"feature\"].values.tolist()\nuseful_features","83b95e48":"train_df[useful_features].info()","6a422032":"missing_percentage_df[missing_percentage_df[\"missing_percentage\"] > 90]","8858bdcb":"useful_features.remove(\"trafficSource.campaignCode\")\nprint(\"Number of useful features: {}\".format(len(useful_features)))","10890387":"# Helper functions\ndef replace_with_0(val):\n    if not val:\n        return 0\n    return val\n\ndef to_yes_or_no(bool_val):\n    if bool_val:\n        return \"yes\"\n    return \"no\"","fd528718":"train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].fillna(0.0)\ntrain_df[[\"totals.transactionRevenue\"]].head()","cfa65f54":"train_df[[\"device.isMobile\"]].groupby(\"device.isMobile\")[\"device.isMobile\"].count()","6520617d":"train_df[\"device.isMobile\"] = train_df[\"device.isMobile\"].apply(to_yes_or_no)","4d53d001":"train_df[[\"device.isMobile\"]].groupby(\"device.isMobile\")[\"device.isMobile\"].count()","c8697a33":"train_df[[\"device.isMobile\"]].head()","ddb80620":"def convert_to_datetime(yyyymmdd):\n    return datetime.strptime(yyyymmdd, \"%Y%m%d\")","81b3f806":"train_df[\"date\"] = train_df[\"date\"].apply(str).apply(convert_to_datetime)\ntrain_df[\"date\"].head()","7af0f013":"train_df[\"date.year\"] = train_df[\"date\"].apply(lambda x: x.year)\ntrain_df[\"date.month\"] = train_df[\"date\"].apply(lambda x: x.month)\ntrain_df[\"date.day\"] = train_df[\"date\"].apply(lambda x: x.day)","fbb1992f":"train_df[\"visitStartTime\"] = train_df[\"visitStartTime\"].apply(datetime.fromtimestamp)","46207d01":"train_df[\"visitStartTime.year\"] = train_df[\"visitStartTime\"].apply(lambda x: x.year)\ntrain_df[\"visitStartTime.month\"] = train_df[\"visitStartTime\"].apply(lambda x: x.month)\ntrain_df[\"visitStartTime.day\"] = train_df[\"visitStartTime\"].apply(lambda x: x.day)\ntrain_df[\"visitStartTime.hour\"] = train_df[\"visitStartTime\"].apply(lambda x: x.hour)\ntrain_df[\"visitStartTime.minute\"] = train_df[\"visitStartTime\"].apply(lambda x: x.minute)","bf165c0c":"train_df[\"totals.newVisits\"] = train_df[\"totals.newVisits\"].apply(replace_with_0)","8af1ca72":"train_df[\"totals.newVisits\"].value_counts()","2ac6dfc3":"train_df[\"totals.bounces\"] = train_df[\"totals.bounces\"].apply(replace_with_0)","0c9a8754":"train_df[\"totals.bounces\"].value_counts()","c6a205c8":"train_df[\"totals.transactionRevenue\"].astype(\"float32\").describe()","544acd42":"num_zero_revenues_rows = sum(train_df[\"totals.transactionRevenue\"].astype(\"float32\") == 0)\nnum_revenues_rows = sum(train_df[\"totals.transactionRevenue\"].astype(\"float32\") > 0)","b26808f4":"trace = go.Bar(x=[\"Zero revenues\", \"Non-zero revenues\"], \n               y=[num_zero_revenues_rows, num_revenues_rows], \n               marker=dict(color=\"#fa360a\"))\ndata = [trace]\nlayout = go.Layout(title=\"Training data: count of zero vs non-zero revenues\", \n                   xaxis=dict(title=\"totals.transactionRevenue\", tickfont=dict(color=\"grey\")), \n                   yaxis=dict(type=\"log\", title=\"Number of data points\", showgrid=False, tickfont=dict(color=\"grey\")), \n                   plot_bgcolor=plot_bgcolor, \n                   paper_bgcolor=paper_bgcolor)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","88151007":"trace = go.Histogram(x=train_df[train_df[\"totals.transactionRevenue\"].astype(\"float32\")>0][\"totals.transactionRevenue\"].astype(\"float32\").apply(np.log), \n                     marker=dict(color=\"#fa360a\"))\ndata = [trace]\nlayout = go.Layout(title=\"Distribution of transaction revenue\", \n                   xaxis=dict(title=\"np.log(df['totals.transactionRevenue'])\", tickfont=dict(color=\"grey\")),\n                   yaxis=dict(title=\"#count\", showgrid=False, showline=False), \n                   plot_bgcolor=plot_bgcolor, paper_bgcolor=paper_bgcolor)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","288e0356":"def generate_subplot_titles(features):\n    subplot_titles = []\n    for f in features:\n        subplot_titles.append(f + \" (all train)\")\n        subplot_titles.append(f + \" (revenue > 0)\")\n    return subplot_titles","a8d1a2e7":"def plot_feature_counts(feats_to_plot, subplot_titles, log_yaxis=None):\n    nrows = len(feats_to_plot)\n    ncols = 2\n    height = nrows * 300\n    width = 900\n    font_size = 8\n    fig = tools.make_subplots(rows=nrows, cols=ncols, subplot_titles=subplot_titles)\n    for i, v in enumerate(feats_to_plot):\n        count_feature_vals1 = train_df[v].value_counts()\n        trace1 = go.Bar(x=count_feature_vals1.index.values, y=count_feature_vals1.values)\n        count_feature_vals2 = train_df[train_df[\"totals.transactionRevenue\"].astype(\"float32\")>0][v].value_counts()\n        trace2 = go.Bar(x=count_feature_vals2.index.values, y=count_feature_vals2.values)\n        fig.append_trace(trace1, i+1, 1)\n        fig.append_trace(trace2, i+1, 2)\n    fig[\"layout\"].update(height=height, \n                         width=width, \n                         title=\"Feature distribution: all data vs revenue > 0 data\", \n                         showlegend=False, \n                         plot_bgcolor=plot_bgcolor, \n                         paper_bgcolor=paper_bgcolor)\n    # 1. set subplot title font size\n    # https:\/\/github.com\/plotly\/plotly.py\/issues\/985\n    for i in fig[\"layout\"][\"annotations\"]:\n        i[\"font\"] = dict(size=font_size)\n    # 2. set subplot tick font size\n    for plot_num in range(1, (nrows * ncols) + 1):\n        fig[\"layout\"][\"xaxis\"+str(plot_num)].update(tickfont=dict(size=font_size,color=\"black\"))\n        fig[\"layout\"][\"yaxis\"+str(plot_num)].update(tickfont=dict(size=font_size,color=\"black\"), showgrid=False, showline=False, zeroline=False)\n    # 3. log y axis \n    if log_yaxis:\n        for row_num in range(0, nrows):\n            if log_yaxis[row_num]:\n                fig[\"layout\"][\"yaxis\"+str(row_num * 2 + 1)].update(type=\"log\")\n                fig[\"layout\"][\"yaxis\"+str(row_num * 2 + 2)].update(type=\"log\")                \n    iplot(fig)","36f521d6":"feats_to_plot = [\"channelGrouping\"]\nsubplot_titles = generate_subplot_titles(feats_to_plot)\nplot_feature_counts(feats_to_plot, subplot_titles, log_yaxis=[True])","f1c627e9":"train_df[[\"date\", \"visitStartTime\"]].head(25)","1b2d50be":"train_df[[\"date\", \"visitStartTime\"]].tail(25)","ff094db5":"(train_df[\"visitStartTime.day\"] - train_df[\"date.day\"]).value_counts()","1e41cd58":"train_df[(train_df[\"visitStartTime.day\"] - train_df[\"date.day\"]) == -29 ][[\"visitStartTime.day\", \"date.day\"]].head()","5282bacf":"train_df[(train_df[\"visitStartTime.day\"] - train_df[\"date.day\"]) == -27 ][[\"visitStartTime.day\", \"date.day\"]].head()","d373aad3":"train_df[(train_df[\"visitStartTime.day\"] - train_df[\"date.day\"]) == -30 ][[\"visitStartTime.day\", \"date.day\"]].head()","94a77ce1":"train_df = train_df.drop([\"date\", \"date.year\", \"date.month\", \"date.day\"], axis=1)","77da119e":"train_df.columns","a5b561f4":"feats_to_plot = [\"device.browser\",\n                \"device.deviceCategory\",\n                \"device.isMobile\",\n                \"device.operatingSystem\"]\nsubplot_titles = generate_subplot_titles(feats_to_plot)\nplot_feature_counts(feats_to_plot, subplot_titles, log_yaxis=[True, True, True, True])","49fc9423":"feats_to_plot = [\"geoNetwork.city\",\n                \"geoNetwork.continent\",\n                \"geoNetwork.country\",\n                \"geoNetwork.metro\",\n                \"geoNetwork.networkDomain\",\n                \"geoNetwork.region\",\n                \"geoNetwork.subContinent\"]\nsubplot_titles = generate_subplot_titles(feats_to_plot)\nplot_feature_counts(feats_to_plot, subplot_titles, log_yaxis=[True, True, True, True, True, True, True])","07156082":"data_by_country_count = train_df[\"geoNetwork.country\"].value_counts()\ndata = [dict(\n    type = \"choropleth\",\n    locations = data_by_country_count.index.values,\n    locationmode = \"country names\",\n    z = data_by_country_count.values,\n    text = data_by_country_count.index.values,\n    colorscale = \"Viridis\",\n    autocolorscale = False,\n    reversescale = True,\n    marker = dict(line = dict(color = \"rgb(180,180,180)\", width = 0.5)),\n    colorbar = dict(title=\"Count\")\n)]\nlayout = dict(title=\"Data distribution by country (all train data)\", height=600, width=800, geo=dict(showframe=False))\nfig = dict(data=data, layout=layout)\niplot(fig, validate=False)","54af8244":"data_by_country_count = train_df[train_df['totals.transactionRevenue'].astype(\"float32\")>0]['geoNetwork.country'].value_counts()\ndata = [dict(\n    type = \"choropleth\",\n    locations = data_by_country_count.index.values,\n    locationmode = \"country names\",\n    z = data_by_country_count.values,\n    text = data_by_country_count.index.values,\n    colorscale = \"Viridis\",\n    autocolorscale = False,\n    reversescale = True,\n    marker = dict(line = dict(color = \"rgb(180,180,180)\", width = 0.5)),\n    colorbar = dict(title=\"Count\")\n)]\nlayout = dict(title=\"Data distribution by country (revenue > 0 data)\", height=600, width=800, geo=dict(showframe=False))\nfig = dict(data=data, layout=layout)\niplot(fig, validate=False)","4a4b587e":"feats_to_plot = [\"totals.bounces\",\n                \"totals.hits\",\n                \"totals.newVisits\",\n                \"totals.pageviews\"]\nsubplot_titles = generate_subplot_titles(feats_to_plot)\nplot_feature_counts(feats_to_plot, subplot_titles, log_yaxis=[True, True, True, True])","6c275db7":"non_zero_revenue_train_df = train_df[train_df[\"totals.transactionRevenue\"].astype(\"float32\") > 0.0]\nnon_zero_revenue_train_df.shape","525cde91":"1. **totals.transactionRevenue**: \nReplace NA values with 0.0\n\n2. **device.isMobile**: \nReplace \"False\" with \"no\", \"True\" with \"yes\" \n\n3. Parse the *date* column and add  **year, month, day** columns out of *date* column\n\n4. Parse the  *visitStartTime* column and  **year, month, day, hour, minute** columns out of *visitStartTime*\n\n5. **totals.newVisits**:  Replace None with 0. \n6. **totals.bounces**: Replace None with 0.\n","0af8f226":"### Summary of revenues","b1cd5ef0":"# First look at the data","c1f8348c":"# Look into unique values of all columns\nIt seems some of the \"device\" and \"geoNetwork\" feature columns contain only one values. We can extend that to the whole dataset in general and try to keep only columns that have more than one unique values. This process will serve to focus only on a handful of features.","34487489":"# Examine unique values of geoNetwork.* columns","2f29d9ca":"**totals.bounces**: Replace None with 0.","17dc7de5":"It's pretty clear, \"date\" and \"visitStartTime\" are same. We can just use one set of values and drop the redundant columns. ","e7e8f907":"**device.isMobile**: \nReplace \"False\" with \"no\", \"True\" with \"yes\" ","0b765752":"**totals.newVisits**:  Replace None with 0. ","c8fe6361":"### How many data points that have non-zero revenues?","0cf22be9":"# Further data processing","bf35c438":"## Target variable (totals.transactionRevenue)","ea6e3e7f":"## Features","1ade3736":"### Distribution of *channelGrouping*","bc89c412":"# Examine unique values of device.* features\nThis step will be useful whether the values present in the columns make sense. Some of the \"device.\" columns contain \"not available in demo dataset\" values. Quick look at unique values of those columns can give us further clues. ","d6658ec1":"### Map: Data distribution by country (based on geoNetwork.country)","92322768":"# Discard unimportant features\nIt's clear that some of the columns with only one value are not going to be useful for both EDA and modeling. So, let's keep only important features  ","a1d642cd":"# Missing values","cc6c296d":"### Distribution of revenues","a743c63e":"Some of the trafficSource variables have more than 90% of the data missing. We can't just ignore them as there may be a relationship with the target variable *totals.transactionRevenue*.  However, we can safely remove the trafficSource.campaignCode from the list of useful variables as it has only one occurrence in the training data. ","8b336246":"Parse the  *visitStartTime* column and  **year, month, day, hour, minute** columns out of *visitStartTime*","18d431cb":"## Features vs target variable (TODO)","f24fbcb5":"Parse date column and add 3 additional columns","72447466":"### Distribution of totals features","1b18e2a0":"**totals.transactionRevenue**: \nReplace NA values with 0.0","12c33d65":"# EDA\nLet's perform analysis on target and feature columns.\n\n**Target variable**\n   1. Summary of revenues\n   2. How many data points that have non-zero revenues?\n   2. Distribution of revenues\n\n**Features**\n   1. Distribution of channelGrouping\n   2. What is the difference between \"date\" and \"visitStartTime\" columns?\n   1. Distribution of device features\n   2. Distribution of geoNetwork features\n   3. Map: Data distribution by country (based on geoNetwork.country)\n   4. Distribution of totals features\n\n**Features vs target variable**   \n   1. Revenues by device features","856983f9":"# Imports","9ad1a5b1":"### What is the difference between \"date\" and \"visitStartTime\" columns?","3d8b666b":"It seems many of the columns are not useful. We can easily discard them.  Let's continue examine unique values other columns. ","1ecf91e7":"From the above side-by-side display of *date* and *visitStartTime*, for some entries, the date is advanced by +1 day for the visitStartTime. We want to quantify weather this is true for all cases, to see if there are other variations. If it's the former, we can simply drop *\"date\", \"date.year\", \"date.month\"* and *\"date.day\"* columns and use the additional columns from *visitStartTime*","604cd74c":"# Load datasets\n\nLoads preprocessed datasets according to  https:\/\/www.kaggle.com\/julian3833\/1-quick-start-read-csv-and-flatten-json-fields ","9d47903e":"### Distribution of geoNetwork.* features","4c5cc666":"### Distribution of device features"}}