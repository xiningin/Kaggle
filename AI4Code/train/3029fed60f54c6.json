{"cell_type":{"6ca4ed5f":"code","4c768a4a":"code","00a40ca0":"code","305e3805":"code","e9e68d56":"code","a97741cc":"code","3e865c24":"code","807a9c74":"code","c926f6d5":"code","058297f8":"code","fae8f74d":"code","ebf062bf":"code","6f07dc88":"code","259db88c":"code","64040e4d":"code","d9aa9484":"code","c6a8a39f":"code","2d4b6eb9":"code","ca08930d":"code","efb9d3d2":"code","e7d49b17":"code","5d621659":"code","f8c4677e":"code","31e02848":"code","6ef90121":"code","8c736f1a":"code","0c278733":"code","92682e8d":"code","422d507b":"code","8743efda":"code","645b64e7":"code","93c84601":"code","979e0a97":"code","ca0b316c":"code","ba1c0ea6":"code","ddeb50fc":"code","43bb82b0":"code","440c30b2":"code","b3c41476":"code","821de50a":"markdown","d1693fb8":"markdown","8f58d9c6":"markdown","b2d1f204":"markdown","fbfe6f11":"markdown","53159d8a":"markdown","c1d43714":"markdown","a2ca6668":"markdown","89ad3f70":"markdown","d7deaffa":"markdown","a89bd7ed":"markdown","0e14be9c":"markdown","5d3c80cc":"markdown"},"source":{"6ca4ed5f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4c768a4a":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n%matplotlib inline\nplt.style.use('ggplot')\nmpl.rcParams['axes.unicode_minus'] = False","00a40ca0":"test = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv', parse_dates=[\"datetime\"])\ntrain = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv', parse_dates=[\"datetime\"])","305e3805":"train.head()","e9e68d56":"test.head()","a97741cc":"train.shape","3e865c24":"test.shape","807a9c74":"train.info()","c926f6d5":"import missingno as msno\n\nmsno.matrix(test, figsize = (12, 5))","058297f8":"train['humidity'].value_counts().head(10)","fae8f74d":"fig, axes = plt.subplots(nrows=2)\nfig.set_size_inches(18,10)\n\nplt.sca(axes[0])\nplt.xticks(rotation=30, ha='right')\naxes[0].set(ylabel='Count',title=\"train windspeed\")\nsns.countplot(data=train, x=\"windspeed\", ax=axes[0])\n\nplt.sca(axes[1])\nplt.xticks(rotation=30, ha='right')\naxes[1].set(ylabel='Count',title=\"test windspeed\")\nsns.countplot(data=test, x=\"windspeed\", ax=axes[1])","ebf062bf":"data = train.append(test)\ndata.reset_index(inplace=True)\ndata.drop('index',inplace=True,axis=1)","6f07dc88":"train[\"year\"] = train[\"datetime\"].dt.year\ntrain[\"month\"] = train[\"datetime\"].dt.month\ntrain[\"day\"] = train[\"datetime\"].dt.day\ntrain[\"hour\"] = train[\"datetime\"].dt.hour\ntrain[\"dayofweek\"] = train[\"datetime\"].dt.dayofweek\ntrain.shape","259db88c":"test[\"year\"] = test[\"datetime\"].dt.year\ntest[\"month\"] = test[\"datetime\"].dt.month\ntest[\"day\"] = test[\"datetime\"].dt.day\ntest[\"hour\"] = test[\"datetime\"].dt.hour\ntest[\"dayofweek\"] = test[\"datetime\"].dt.dayofweek\ntest.shape","64040e4d":"train.head()","d9aa9484":"from sklearn.ensemble import RandomForestClassifier\n\ndef predict_windspeed(data):\n    \n    dataWind0 = data.loc[data['windspeed'] == 0]\n    dataWindNot0 = data.loc[data['windspeed'] != 0]\n    wCol = [\"season\", \"weather\", \"humidity\", \"month\", \"temp\", \"year\", \"atemp\"]\n    dataWindNot0[\"windspeed\"] = dataWindNot0[\"windspeed\"].astype(\"str\")\n    rfModel_wind = RandomForestClassifier()\n    rfModel_wind.fit(dataWindNot0[wCol], dataWindNot0[\"windspeed\"])\n    wind0Values = rfModel_wind.predict(X = dataWind0[wCol])\n    predictWind0 = dataWind0\n    predictWindNot0 = dataWindNot0\n    predictWind0[\"windspeed\"] = wind0Values\n    data = predictWindNot0.append(predictWind0)\n    data[\"windspeed\"] = data[\"windspeed\"].astype(\"float\")\n    data.reset_index(inplace=True)\n    data.drop('index', inplace=True, axis=1)\n    \n    return data","c6a8a39f":"train = predict_windspeed(train)\ntest = predict_windspeed(test)","2d4b6eb9":"train","ca08930d":"fig, axes = plt.subplots(nrows=2)\nfig.set_size_inches(18,10)\n\nplt.sca(axes[0])\nplt.xticks(rotation=30, ha='right')\naxes[0].set(ylabel='Count',title=\"train windspeed\")\nsns.countplot(data=train, x=\"windspeed\", ax=axes[0])\n\nplt.sca(axes[1])\nplt.xticks(rotation=30, ha='right')\naxes[1].set(ylabel='Count',title=\"test windspeed\")\nsns.countplot(data=test, x=\"windspeed\", ax=axes[1])","efb9d3d2":"categoricalFeatureNames = [\"season\",\"holiday\",\"workingday\",\"weather\",\"dayofweek\",\"month\",\"year\",\"hour\"]\nnumericalFeatureNames = [\"temp\",\"humidity\",\"windspeed\",\"atemp\"]\ndropFeatures = ['casual',\"count\",\"datetime\",\"day\",\"registered\"]","e7d49b17":"for var in categoricalFeatureNames:\n    train[var] = train[var].astype(\"category\")\n    test[var] = test[var].astype(\"category\")","5d621659":"datetimecol = test[\"datetime\"]\nyLabels = train[\"count\"]\nyLablesRegistered = train[\"registered\"]\nyLablesCasual = train[\"casual\"]","f8c4677e":"test","31e02848":"train  = train.drop(dropFeatures,axis=1)\ntest  = test.drop(['datetime','day'],axis=1)","6ef90121":"test.shape","8c736f1a":"train.shape","0c278733":"def rmsle(y, y_,convertExp=True):\n    if convertExp:\n        y = np.exp(y),\n        y_ = np.exp(y_)\n    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n    calc = (log1 - log2) ** 2\n    return np.sqrt(np.mean(calc))","92682e8d":"from sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nimport warnings\npd.options.mode.chained_assignment = None\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# Initialize logistic regression model\nlModel = LinearRegression()\n\n# Train the model\nyLabelsLog = np.log1p(yLabels)\nlModel.fit(X = train,y = yLabelsLog)\n\n# Make predictions\npreds = lModel.predict(X= train)\nprint (\"RMSLE Value For Linear Regression: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))","422d507b":"ridge_m_ = Ridge()\nridge_params_ = { 'max_iter':[3000],'alpha':[0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000]}\nrmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False)\ngrid_ridge_m = GridSearchCV( ridge_m_,\n                          ridge_params_,\n                          scoring = rmsle_scorer,\n                          cv=5)\nyLabelsLog = np.log1p(yLabels)\ngrid_ridge_m.fit( train, yLabelsLog )\npreds = grid_ridge_m.predict(X= train)\nprint (grid_ridge_m.best_params_)\nprint (\"RMSLE Value For Ridge Regression: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))\n\nfig,ax= plt.subplots()\nfig.set_size_inches(12,5)\ndf = pd.DataFrame(grid_ridge_m.cv_results_)\ndf[\"alpha\"] = df[\"params\"].apply(lambda x:x[\"alpha\"])\ndf[\"rmsle\"] = df[\"mean_test_score\"].apply(lambda x:-x)\nsns.pointplot(data=df,x=\"alpha\",y=\"rmsle\",ax=ax)","8743efda":"lasso_m_ = Lasso()\n\nalpha  = 1\/np.array([0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000])\nlasso_params_ = { 'max_iter':[3000],'alpha':alpha}\n\ngrid_lasso_m = GridSearchCV( lasso_m_,lasso_params_,scoring = rmsle_scorer,cv=5)\nyLabelsLog = np.log1p(yLabels)\ngrid_lasso_m.fit( train, yLabelsLog )\npreds = grid_lasso_m.predict(X= train)\nprint (grid_lasso_m.best_params_)\nprint (\"RMSLE Value For Lasso Regression: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))\n\nfig,ax= plt.subplots()\nfig.set_size_inches(12,5)\ndf = pd.DataFrame(grid_lasso_m. cv_results_)\ndf[\"alpha\"] = df[\"params\"].apply(lambda x:x[\"alpha\"])\ndf[\"rmsle\"] = df[\"mean_test_score\"].apply(lambda x:-x)\nsns.pointplot(data=df,x=\"alpha\",y=\"rmsle\",ax=ax)\n","645b64e7":"from sklearn.ensemble import RandomForestRegressor\nrfModel = RandomForestRegressor(n_estimators=100)\nyLabelsLog = np.log1p(yLabels)\nrfModel.fit(train,yLabelsLog)\npreds = rfModel.predict(X= train)\nprint (\"RMSLE Value For Random Forest: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))","93c84601":"from sklearn.ensemble import GradientBoostingRegressor\ngbm = GradientBoostingRegressor(n_estimators=4000,alpha=0.01)\nyLabelsLog = np.log1p(yLabels)\ngbm.fit(train,yLabelsLog)\npreds = gbm.predict(X= train)\nprint (\"RMSLE Value For Gradient Boost: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))","979e0a97":"train.info()","ca0b316c":"for var in categoricalFeatureNames:\n    train[var] = train[var].astype(\"float\")\n    test[var] = test[var].astype(\"float\")","ba1c0ea6":"from xgboost import XGBRegressor\nxgb = XGBRegressor(n_estimators = 500, learning_rate = 0.1, max_depth = 4)\nyLabelsLog = np.log1p(yLabels)\nxgb.fit(train,yLabelsLog)\npreds = xgb.predict(train)\nprint (\"RMSLE Value For XGBboost: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))","ddeb50fc":"# predsTest = xgb.predict(test)\n# fig,(ax1,ax2)= plt.subplots(ncols=2)\n# fig.set_size_inches(12,5)\n# sns.distplot(yLabels,ax=ax1,bins=50)\n# sns.distplot(np.exp(predsTest),ax=ax2,bins=50)","43bb82b0":"# submission = pd.DataFrame({\n#         \"datetime\": datetimecol,\n#         \"count\": [max(0, x) for x in np.exp(predsTest)]\n#     })\n# submission.to_csv('bike_predictions_xgb.csv', index=False)","440c30b2":"predsTest = gbm.predict(X= test)\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsns.distplot(yLabels,ax=ax1,bins=50)\nsns.distplot(np.exp(predsTest),ax=ax2,bins=50)","b3c41476":"submission = pd.DataFrame({\n        \"datetime\": datetimecol,\n        \"count\": [max(0, x) for x in np.exp(predsTest)]\n    })\nsubmission.to_csv('bike_predictions_gbm_separate_without_fe.csv', index=False)","821de50a":"# **Exploratory Data**","d1693fb8":"# **Regularization Model - Lasso**","8f58d9c6":"# **Feature Engineering**","b2d1f204":"**RMSLE Scorer**","fbfe6f11":"# **Feature Selection**\n**Coercing To Categorical Type**","53159d8a":"# **Regularization Model - Ridge**\n\nReference : https:\/\/m.blog.naver.com\/PostView.nhn?blogId=gustn3964&logNo=221431933811&proxyReferer=https:%2F%2Fwww.google.com%2F","c1d43714":"# **About Dataset**\n\n**Overview**\n\nBike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.\n\n**Data Fields**\n\n* datetime - hourly date + timestamp\n* season - 1 = spring, 2 = summer, 3 = fall, 4 = winter\n* holiday - whether the day is considered a holiday\n* workingday - whether the day is neither a weekend nor holiday\n* weather -\n  * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n  * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n  * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n  * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n* temp - temperature in Celsius\n* atemp - \"feels like\" temperature in Celsius\n* humidity - relative humidity\n* windspeed - wind speed\n* casual - number of non-registered user rentals initiated\n* registered - number of registered user rentals initiated\n* count - number of total rentals (Dependent Variable)","a2ca6668":"# **Reference**\n* https:\/\/www.kaggle.com\/viveksrinivasan\/eda-ensemble-model-top-10-percentile\n* https:\/\/github.com\/corazzon\/KaggleStruggle\/blob\/master\/bike-sharing-demand\/bike-sharing-demand-EDA.ipynb","89ad3f70":"# **Ensemble Models - Random Forest**","d7deaffa":"# **Ensemble Model - Gradient Boost**","a89bd7ed":"# **Linear Regression Model**","0e14be9c":"# **Ensemble Model - XGBooster**\n\nReference : https:\/\/lsjsj92.tistory.com\/547","5d3c80cc":"**Dropping Unncessary Variables**"}}