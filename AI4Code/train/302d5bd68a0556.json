{"cell_type":{"98dabeef":"code","fd931b23":"code","a1e2e041":"code","e2f49e17":"code","a1522d6b":"code","0ab0e320":"code","b158a91b":"code","b0a8a65d":"code","a38ab467":"code","7633e848":"code","7783d62b":"code","393d650d":"code","4c726be6":"code","98f2d907":"code","5e674000":"code","55dab607":"code","8571aa66":"code","e420ab75":"code","9ecc29cb":"code","c4d1c39c":"code","71ed942d":"code","baacaa30":"code","3a109105":"code","aad42a6d":"code","3933ecc4":"code","0fd21682":"code","8deb8c6b":"code","3aaefb50":"code","09a49fd9":"code","df762799":"code","3184ff11":"code","162d6163":"code","b6201a07":"code","dec66d18":"code","79a42ec6":"code","983e42a0":"code","3f936143":"markdown","3815febd":"markdown","ed731354":"markdown","cd1dd7d2":"markdown","0a0ef836":"markdown","b1f7ffb6":"markdown","dde248a7":"markdown","a7a97820":"markdown","f130eb84":"markdown","9671c530":"markdown","1e97812e":"markdown","a566c090":"markdown","bd5139b9":"markdown","b8a3b634":"markdown","94c6a76f":"markdown","66ab2f32":"markdown","4e9a56f6":"markdown","557696e9":"markdown","d4adafb1":"markdown","a72c8b7f":"markdown","cee8fba3":"markdown","1d0f37b1":"markdown","3fa346b6":"markdown","e3d81dfa":"markdown","a6e496a8":"markdown","a696733d":"markdown","ae3aeba0":"markdown","529c18fa":"markdown","dcea2011":"markdown","3acbae50":"markdown","19183b89":"markdown","79bfc528":"markdown","a7e6dcfe":"markdown","6440031f":"markdown","85850be7":"markdown","9d077845":"markdown","e027a832":"markdown","1391b9ee":"markdown","f1bb599e":"markdown","10d71c86":"markdown","0a9f7932":"markdown","c83920b1":"markdown","cc9d9147":"markdown","53876e6f":"markdown","d77705c6":"markdown","311ea507":"markdown","67b90a71":"markdown","0152e709":"markdown","5129fc1d":"markdown","adedd4ef":"markdown","d89d715f":"markdown","b94547d0":"markdown","b9e6ec7d":"markdown","a850ae9e":"markdown","3bf1d814":"markdown","1dd96d9f":"markdown","032d5a21":"markdown","f62996d7":"markdown","204b98c8":"markdown","dc4607a2":"markdown","97e90d86":"markdown","cc7fe6da":"markdown","2011e3d9":"markdown","e6793018":"markdown","c364a19f":"markdown","592900ff":"markdown","0230eacf":"markdown","bd0e8c1d":"markdown","e35f90e7":"markdown","4bced431":"markdown","9e26bb4b":"markdown","fbbb15ee":"markdown","45cedcc5":"markdown","4c6d44a3":"markdown","80ff7cfb":"markdown","37fb25f0":"markdown","821341cb":"markdown","0a39e1c2":"markdown","678046c3":"markdown","278c94bf":"markdown","c62190c0":"markdown","7f1c0f2e":"markdown","ea4cec35":"markdown","a4725ffa":"markdown","576f911f":"markdown"},"source":{"98dabeef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fd931b23":"import pandas as pd\nimport numpy as np\nimport string\nimport nltk\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.svm import LinearSVC\nfrom sklearn import svm, linear_model\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom math import sqrt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.ensemble import VotingClassifier \nsns.set(color_codes=True)\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nimport random\nfrom sklearn.metrics import accuracy_score\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score","a1e2e041":"review_data0 = pd.read_csv('..\/input\/boardgamegeek-reviews\/bgg-13m-reviews.csv', index_col=0)\nreview_data0.head()","e2f49e17":"review_data0.shape","a1522d6b":"review_data2=review_data0[~review_data0.comment.str.contains(\"NaN\",na=True)]\nreview_data2.head()","0ab0e320":"review_data2.shape","b158a91b":"review_data2.describe()","b0a8a65d":"#plot histogram of ratings\nnum_bins = 70\nn, bins, patches = plt.hist(review_data2.rating, num_bins, facecolor='green', alpha=0.9)\n\n#plt.xticks(range(9000))\nplt.title('Histogram of Ratings')\nplt.xlabel('Ratings')\nplt.ylabel('Count')\nplt.show()","a38ab467":"review_data2.head()\nreview_data3=review_data2.sample(n=30000)\nreview_data3.head()","7633e848":"review_data3.dtypes","7783d62b":"review_data3.isna().sum()","393d650d":"review_data3['word_count']  = review_data3.comment.str.len()\n\nnum_bins = 70\nn, bins, patches = plt.hist(review_data3.word_count, num_bins, facecolor='green', alpha=0.9)\n\n#plt.xticks(range(9000))\nplt.title('Histogram of Word Count')\nplt.xlabel('Word Count')\nplt.ylabel('Count')\nplt.show()","4c726be6":"#lowercase and remove punctuation\nreview_data3['cleaned'] = review_data3['comment'].str.lower().apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n\n# stopword list to use\nstopwords_list = stopwords.words('english')\nstopwords_list.extend(('game','play','played','players','player','people','really','board','games','one','plays','cards','would')) \n\nstopwords_list[-10:]\n\n#remove stopwords\nreview_data3['cleaned'] = review_data3['cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))\nreview_data3.head()","98f2d907":"num_bins = 70\nn, bins, patches = plt.hist(review_data3.rating, num_bins, facecolor='green', alpha=0.9)\n\n#plt.xticks(range(9000))\nplt.title('Histogram of Ratings')\nplt.xlabel('Ratings')\nplt.ylabel('Count')\nplt.show()","5e674000":"Counter(\" \".join(review_data3[\"cleaned\"]).split()).most_common(50)[:50]","55dab607":"from wordcloud import WordCloud\nfrom collections import Counter\n\nneg = review_data3.loc[review_data3['rating'] < 3]\npos = review_data3.loc[review_data3['rating'] > 8]\n\n\nwords = Counter([w for w in \" \".join(pos['cleaned']).split()])\n\nwc = WordCloud(width=400, height=350,colormap='plasma',background_color='white').generate_from_frequencies(dict(words.most_common(100)))\nplt.figure(figsize=(20,15))\nplt.imshow(wc, interpolation='bilinear')\nplt.title('Common Words in Positive Reviews', fontsize=20)\nplt.axis('off');\nplt.show()\n\n\nwords = Counter([w for w in \" \".join(neg['cleaned']).split()])\n\nwc = WordCloud(width=400, height=350,colormap='plasma',background_color='white').generate_from_frequencies(dict(words.most_common(100)))\nplt.figure(figsize=(20,15))\nplt.imshow(wc, interpolation='bilinear')\nplt.title('Common Words in Negative Reviews', fontsize=20)\nplt.axis('off');\nplt.show()","8571aa66":"print('Mean: ', review_data3.rating.mean())\nprint('Median: ', review_data3.rating.median())\nprint('Mode: ', review_data3.rating.mode())","e420ab75":"def calc_rmse(errors, weights=None):\n    n_errors = len(errors)\n    if weights is None:\n        result = sqrt(sum(error ** 2 for error in errors) \/ n_errors)\n    else:\n        result = sqrt(sum(weight * error ** 2 for weight, error in zip(weights, errors)) \/ sum(weights))\n    return result\n\n#if the score is far from mean (high or low scores), weight those reviews and ratings more when assessing model accuracy\ndef calc_weights(scores):\n    peak = 6.851\n    return tuple((10 ** (0.3556 * (peak - score))) if score < peak else (10 ** (0.2718 * (score - peak))) for score in scores)\n\n\ndef assess_model( model_name, test, predicted):\n    error = test - predicted\n    rmse = calc_rmse(error)\n    mae = mean_absolute_error(test, predicted)\n    weights = calc_weights(test)\n    weighted_rmse = calc_rmse(error, weights = weights)\n    \n    \n    print(model_name)\n    print('RMSE:',rmse)\n    print('Weighed RMSE:', weighted_rmse)\n    print('MAE:', mae)","9ecc29cb":"X_train, X_test, y_train, y_test = train_test_split(review_data3.cleaned, review_data3.rating, random_state=44,test_size=0.20)\n\nmodel_nb = Pipeline([\n    ('count_vectorizer', CountVectorizer(lowercase = True, stop_words = stopwords.words('english'))), \n    ('tfidf_transformer',  TfidfTransformer()), #weighs terms by importance to help with feature selection\n    ('classifier', MultinomialNB()) ])\n    \nmodel_nb.fit(X_train,y_train.astype('int'))\nlabels = model_nb.predict(X_test)\nmat = confusion_matrix(y_test.astype('int'), labels)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\n\nassess_model(\"Multinomial NB\", y_test,labels)\nacc = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('\\n****Test accuracy is',(acc))","c4d1c39c":"#Experimented with adding different numbers of n-grams, 1-2 seems to have best performance\nmodel_nb2 = Pipeline([\n    ('count_vectorizer', CountVectorizer( ngram_range=(1,2), lowercase = True, stop_words = stopwords.words('english'))), \n    ('tfidf_transformer',  TfidfTransformer()), #weighs terms by importance to help with feature selection\n    ('classifier', MultinomialNB()) ])\n    \nmodel_nb2.fit(X_train,y_train.astype('int'))\nlabels = model_nb2.predict(X_test)\nmat = confusion_matrix(y_test.astype('int'), labels)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\n\nassess_model(\"Multinomial NB n-grams 1-2\", y_test,labels)\nacc = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('\\n****Test accuracy is',(acc))","71ed942d":"# Convert the data in vector fpormate\ntf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\ntf_idf_train = tf_idf_vect.fit_transform(X_train)\ntf_idf_test = tf_idf_vect.transform(X_test)\n\nalpha_range = list(np.arange(0,30,1))\nlen(alpha_range)","baacaa30":"from sklearn.naive_bayes import MultinomialNB\ny_train=y_train.astype('int')\n\nalpha_scores=[]\n\nfor a in alpha_range:\n    clf = MultinomialNB(alpha=a)\n    scores = cross_val_score(clf, tf_idf_train, y_train, cv=5, scoring='accuracy')\n    alpha_scores.append(scores.mean())\n    print(a,scores.mean())","3a109105":"# Plot b\/w misclassification error and CV mean score.\nimport matplotlib.pyplot as plt\n\nMSE = [1 - x for x in alpha_scores]\n\n\noptimal_alpha_bnb = alpha_range[MSE.index(min(MSE))]\n\n# plot misclassification error vs alpha\nplt.plot(alpha_range, MSE)\n\nplt.xlabel('hyperparameter alpha')\nplt.ylabel('Misclassification Error')\nplt.show()","aad42a6d":"optimal_alpha_bnb","3933ecc4":"model_nb = Pipeline([\n    ('count_vectorizer', CountVectorizer(lowercase = True, stop_words = stopwords.words('english'))), \n    ('tfidf_transformer',  TfidfTransformer()), #weighs terms by importance to help with feature selection\n    ('classifier', MultinomialNB(alpha=optimal_alpha_bnb)) ])\n    \nmodel_nb.fit(X_train,y_train.astype('int'))\nlabels = model_nb.predict(X_test)\nmat = confusion_matrix(y_test.astype('int'), labels)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\n\nassess_model(\"Multinomial NB\", y_test,labels)\nacc = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('\\n****Test accuracy is',(acc))","0fd21682":"model_svc = make_pipeline(TfidfVectorizer(ngram_range=(1,3)), svm.SVC(kernel=\"linear\",probability=True))\nmodel_svc.fit(X_train, y_train.astype('int'))\nlabels = model_svc.predict(X_test)\n\nmat = confusion_matrix(y_test.astype('int'), labels)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\n\nassess_model(\"Linear SVC model\", y_test,labels)\nacc = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('\\n****Test accuracy is',(acc))","8deb8c6b":"review_data2.head()\nrating1_subset = review_data2[review_data2['rating']==1] \nrating1_subset.head()\n\n# Slect 100 sample that have rating =1\nr1=rating1_subset.sample(2000)\nr1.head()\n\n\nrating2_subset = review_data2[review_data2['rating']==2] \nrating2_subset.head()\n# Slect 100 sample that have rating =2\nr2=rating2_subset.sample(2000)\nr2.head()\n\nrating3_subset = review_data2[review_data2['rating']==3] \nrating3_subset.head()\n# Slect 100 sample that have rating =3\nr3=rating3_subset.sample(2000)\nr3.head()\n\nrating4_subset = review_data2[review_data2['rating']==4] \nrating4_subset.head()\n# Slect 100 sample that have rating =4\nr4=rating4_subset.sample(2000)\nr4.head()\n\nrating5_subset = review_data2[review_data2['rating']==5] \nrating5_subset.head()\n# Slect 100 sample that have rating =5\nr5=rating5_subset.sample(2000)\nr5.head()\n\nrating6_subset = review_data2[review_data2['rating']==6] \nrating6_subset.head()\n# Slect 100 sample that have rating =6\nr6=rating6_subset.sample(2000)\nr6.head()\n\nrating7_subset = review_data2[review_data2['rating']==7] \nrating7_subset.head()\n# Slect 100 sample that have rating =7\nr7=rating7_subset.sample(2000)\nr7.head()\n\nrating8_subset = review_data2[review_data2['rating']==8] \nrating8_subset.head()\n# Slect 100 sample that have rating =8\nr8=rating8_subset.sample(2000)\nr8.head()\n\nrating9_subset = review_data2[review_data2['rating']==9] \nrating9_subset.head()\n# Slect 100 sample that have rating=9\nr9=rating9_subset.sample(2000)\nr9.head()\n\nrating10_subset = review_data2[review_data2['rating']==10] \nrating10_subset.head()\n# Slect 100 sample that have rating=10\nr10=rating10_subset.sample(2000)\nr10.head()","3aaefb50":"review_balance=df = r1.append([r2, r3,r4,r5,r6,r7,r8,r9,r10])\nreview_balance.head()","09a49fd9":"review_balance.shape","df762799":"#lowercase and remove punctuation\nreview_balance['cleaned'] = review_balance['comment'].str.lower().apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n\n# stopword list to use\nstopwords_list = stopwords.words('english')\nstopwords_list.extend(('game','play','played','players','player','people','really','board','games','one','plays','cards','would')) \n\nstopwords_list[-10:]\n\n#remove stopwords\nreview_balance['cleaned'] = review_balance['cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))\nreview_balance.head()","3184ff11":"#plot histogram of ratings\nnum_bins = 70\nn, bins, patches = plt.hist(review_balance.rating, num_bins, facecolor='green', alpha=0.9)\n\n#plt.xticks(range(9000))\nplt.title('Histogram of Ratings')\nplt.xlabel('Ratings')\nplt.ylabel('Count')\nplt.show()","162d6163":"X_train1, X_test1, y_train1, y_test1 = train_test_split(review_balance.cleaned, review_balance.rating, test_size=0.20)\nmodel_svc_balance = make_pipeline(TfidfVectorizer(ngram_range=(1,3)), svm.SVC(kernel=\"linear\",probability=True))\nmodel_svc_balance.fit(X_train1, y_train1.astype('int'))\nlabels = model_svc_balance.predict(X_test1)\n\nmat = confusion_matrix(y_test1.astype('int'), labels)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\n\nassess_model(\"Linear SVC Balanced model\", y_test1,labels)\nacc = accuracy_score(y_test1.astype('int'),labels, normalize=True) * float(100)\nprint('\\n****Test accuracy is',(acc))","b6201a07":"X_train, X_test, y_train, y_test = train_test_split(review_data3.cleaned, review_data3.rating, test_size=0.20)\nlabels = model_svc_balance.predict(X_test)\n\nmat = confusion_matrix(y_test.astype('int'), labels)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\n\nassess_model(\"Linear SVC model\", y_test,labels)\nacc = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('\\n****Test accuracy of re-trained SVC is',(acc))","dec66d18":"\nX_train, X_test, y_train, y_test = train_test_split(review_data3.cleaned, review_data3.rating, test_size=0.20)\n\nEnsemble = VotingClassifier(estimators=[('model_svc_unbalance',model_svc), ('model_svc_balance', model_svc_balance )],\n                        voting='soft',\n                        weights=[3, 1])\n\nEnsemble.fit(X_train,y_train.astype(int))\n\n\nlabels = Ensemble.predict(X_test)\nmat = confusion_matrix(y_test.astype(int), labels)\nax = sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\nassess_model(\"Ensemble model\", y_test,labels)\nacc = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('\\n****Test accuracy of Ensemble SVC is',(acc))","79a42ec6":"X_train, X_test, y_train, y_test = train_test_split(review_data3.cleaned, review_data3.rating, test_size=0.20)\n\nlabels = model_svc.predict(X_test)\nlabels_2 = model_svc_balance.predict(X_test)\n\n\npred = pd.concat([pd.DataFrame(y_test).reset_index().rating,pd.Series(labels),pd.Series(labels_2)],axis=1)\npred.columns = ['rating','model_1','model_2']\n\npred = pd.concat([pd.DataFrame(y_test).reset_index().rating,pd.Series(labels),pd.Series(labels_2)],axis=1)\npred.columns = ['rating','model_1','model_2']\n\npred['final'] = np.where(pred.model_2 >= 3, np.where(pred.model_2 <= 9, pred.model_1, pred.model_2), pred.model_2)\n#pred['final'] = np.where(pred.model_2 <= 9, pred.model_1, pred.model_2)\npred.tail()","983e42a0":"mat = confusion_matrix(pred.rating.astype(int), pred.final)\nax = sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False )\nplt.xlabel('true label')\nplt.ylabel('predicted label');\nplt.show()\nassess_model(\"Ensemble model\", pred.rating,pred.final)\n\nacc = accuracy_score(pred.rating.astype(int),pred.final, normalize=True) * float(100)\nprint('\\n****Test accuracy of Ensemble SVC is',(acc))","3f936143":"# Import Library","3815febd":"# It is clear that orginal data size is too big (13170073 rows) and needs lot of memory to calculate, so we will take subsample data to develop the model. I have taken 30,000 data for developing the model.","ed731354":"# Orginal data file has 13,170,073 rows without cleaning and 5 columns. We will Remove all NaN rows from comment columns","cd1dd7d2":"# Making lowercase, removing punctuation and stop words from Balanced sample","0a0ef836":"# Now combined all 20,000 samples with 2000 samples for each rating-**Balanced Sample**","b1f7ffb6":"# Data Description\nThe orginal Board game data is vast (1GB-1,31,70,073 rows data for review file) and time consuming process to clean, that needs excellent memory of the computer. So to avoid complexity this project has taken 30,000 unbalnced and 20,000 balanced data set for the aanalysis and model development. The file contains\n* GameID\n* Rating\n* comment\n","dde248a7":"# Challenges and Improvements","a7a97820":"The main purpose of the project is predicting the rating of the game based on the given reviews and understanding how the test classification machine learning algorithm works and improving the outputs on existing references. The second purpose is providing good documentation for the whole process","f130eb84":"# All the above models are simply predicting reviews around the average rating accept SVC model. MNB and MNB-N-grams did not predict any low reviews. This is because the training data is so unbalanced that it can't detect a negative review.","9671c530":"# To obtain the best accuracy MNB, MNB with N-grams, linear-SVC, Ensemble models was conducted. The accuracy for different models in case of unbalaced data set was: MNB accuaracy 27% with hyperparameter 1, MNB with N-grams 27% and SVC accuracy was 29%. But due to unbalaced data, all these models captured prediction around the mean, it was not able to capture most of the negative rating (<5) and very high positive rating (>8). SVC models performs better than MNB and MNB-N-grams and it captured both low and high rating. To overcome this problem a 20,000 balanced sample was created by taking 2000 samples from each rating. Then the SVC model was trained with balanced sample, after that SVC model was used to predict on unbalanced dataset. It was found that balanced training model accuracy was less than unbalced models, but it was able to capture all kinds of rating. SVC Balanced accuracy was 25% and SVC-unbalanced test accuracy was 20%, here we train and test SVC models only as we got previously that SVC performs better than MNB and MNB-N-grams in terms of best accuracy of the prediction. Voting Ensemable shows accuacy 29% while Joining Ensemble shows 66% accuracy which is outstanding results for this project. SVC balnced and SVC unbalced model was joined in this best model to predict the rating on unbalanced dataset. This study concludes that Ensemble model performs best than any other models with highest accuarcy. ","1e97812e":"#  Lets start with importing our orinal data source file","a566c090":"The Naive Bayes classifier is a simple probabilistic classifier which is based on Bayes theorem with strong and na\u00efve independence assumptions. It is one of the most basic text classification techniques with various applications in email spam detection, personal email sorting, document categorization, sexually explicit content detection, language detection and sentiment detection. Despite the na\u00efve design and oversimplified assumptions that this technique uses, Naive Bayes performs well in many complex real-world problems.","bd5139b9":"An n-gram is defined either as a textual sequence of length n, or similarly, as a sequence of n adjacent \u2018textual units\u2019, in both cases extracted from a particular document.  A \u2018textual unit\u2019 can be identified at a byte, character or word level depending on the context of interest. N-Grams are the basic method for text categorization.  It is also a statistical based approach for classifying text.  The N is the number of keywords used for dividing  the  input  text.   Based  on  the  number  of  keywords  used,  the  N-gramsare called as 2-grams, 3-grams, etc.","b8a3b634":"# Plot histogram of word count","94c6a76f":" # plot histogram of ratings of our unbalanced sample","66ab2f32":"# SVC model performs better than any others model as Accuracy= 29% which is greater than MNB and MNB-N-grams","4e9a56f6":"The 30 thousands unbalanced data was splitted as train and test set for the modeling, then pipeline was used to tune the model. \n\n* count_vectorizer - Breaks up the text into a matrix with each word (called \"token\" in NLP) being the column of the matrix and the value being the count of occurences.\n\n* ngram_range - Optional parameter to extract the text in groups of 2 or more words together. This is useful because the modifiers such as 'not' can be used to change the following word's meaning.\n* stopwords - Removes any words from the stopwords list created in the data exploration step.\n* lowercase - Converts all text into lowercase.\n* tfidf_transformer - Weighs terms by importance to help with feature selection.\n* classifier - two types of models was used, multi-class classification, Multinomial NB and LinearSVC\n\nModel performance will be judged with the accuracy value","557696e9":"# Models Name and\tAccuracy:\n# Multinomial Na\u00efve Bayes(MNB) for Unbalanced dataset\t27%\n# MNB with N-grams for Unbalanced dataset\t27%\n# SVC-Linear for Unbalanced dataset\t29%\n# SVC-Linear Re-trained with Balanced Dataset\t25%\n# SVC-Linear Re-trained on Unbalanced dataset\t20%\n# Ensemble Model with Voting Classifier\t29%\n# Ensemble Model with Balanced and Unbalanced SVC\t66%\n","d4adafb1":"# Board Game Geek Rating Prediction Based on Comments.\n# Author: Md Mintu Miah, ID:1001405116","a72c8b7f":"# Like, fun, good, great,much, get,time, rules, well, playing are the top 10 words repeated within the comment. Now, lets define the rating as positive (rating>8) and negative (<3) and display top 100 positive words and negative words that are very useful to predict the rating. ","cee8fba3":"# Ensemble Model","1d0f37b1":"* so, our balanced sample has total 2000 rows from 200 samples for each rating. Lets clean these balance sample once again","3fa346b6":"# Summary","e3d81dfa":"* A word cloud of positive (rating > 8) and negative (rating < 3) reviews was generated as above. The positive word cloud contains mostly positive 100 words, the negative word cloud contains a mix of 100 words that are not necessarily negative","a6e496a8":"We have made lower case of all words in comment, removed punctuation and stop words to get the unique, meaningful and clear comments for the analysis. Lower case will halp to get same format of similar kinds of word. stopwords do not carry any meaningful significance.","a696733d":"01. https:\/\/www.kaggle.com\/jvanelteren\/boardgamegeek-reviews\n02. https:\/\/www.kaggle.com\/ngrq94\/boardgamegeek-reviews-eda-final\n03. https:\/\/github.com\/jushih\/Sentiment-Analysis\n04. https:\/\/boardgamegeek.com\/wiki\/page\/BoardGameGeek_FAQ\n05. http:\/\/www.site.uottawa.ca\/~stan\/csi5387\/DMNB-paper.pdf\n06. https:\/\/pdfs.semanticscholar.org\/fa18\/59e0bffa436150b785e3d2ff4c6f1bbd4ccd.pdf\n07. https:\/\/subscription.packtpub.com\/book\/big_data_and_business_intelligence\/9781789345070\/3\/ch03lvl1sec30\/svm-for-churn-prediction\n08. http:\/\/blog.datumbox.com\/machine-learning-tutorial-the-naive-bayes-text-classifier\/\n09. https:\/\/towardsdatascience.com\/ensemble-learning-using-scikit-learn-85c4531ff86a\n10. https:\/\/kavita-ganesan.com\/what-are-stop-words\/#.XrOIDcB7mUk","ae3aeba0":"# #join results of SVC models on balanced and unbalanced data to create ensemble model","529c18fa":"# Analysis Steps or Methods","dcea2011":"# Now define Necessary function to calculate RMSE,Weighted RMSE MAF and model assessment","3acbae50":"#  Multinomial Naive Bayes","19183b89":"So, Remove all NaN rows from comment column","79bfc528":"# The challanging of this project was handling big data,selecting the sample size and finding the best machine leaning algorithm and impliment them in a proper way to make the model best performed. I tried with different sample sizes, accuracy varied with the sample size. I have taken the sample size that can be handled with kaggle server and minimize run time, at the same time, shows good accuaracy rate. One of the another challanges was finding the good accuarcy from the model. This projects has given overview of performance of different models in terms of accuracy over the existing references.","a7e6dcfe":"** Although now it has captured all rating catagory but the accuracy is less than unbalanced sample. ","6440031f":"** we will use .shape to see the number of rows and columns in our data file","85850be7":"# lets check mean, median and mode of rating of our unbalced sample","9d077845":"# Let us create a Balanced sample that have 2000 sample from each rating","e027a832":"# It seems that the accuracy has decreased after using balnced data as the training. Although it has captured all rating class but the error rate is high as we have got accuracy only 29% while it was 30% from SVC model in case of unbalanced data but it was biased results.","1391b9ee":"* Stop Words: Stop words are basically a set of commonly used words in any language, not just English.The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead. For example, in the context of a search engine, if your search query is \u201chow to develop information retrieval applications\u201d, If the search engine tries to find web pages that contained the terms \u201chow\u201d, \u201cto\u201d \u201cdevelop\u201d, \u201cinformation\u201d, \u201dretrieval\u201d, \u201capplications\u201d the search engine is going to find a lot more pages that contain the terms \u201chow\u201d, \u201cto\u201d than pages that contain information about developing information retrieval applications because the terms \u201chow\u201d and \u201cto\u201d are so commonly used in the English language. If we disregard these two terms, the search engine can actually focus on retrieving pages that contain the keywords: \u201cdevelop\u201d \u201cinformation\u201d \u201cretrieval\u201d \u201capplications\u201d \u2013 which would bring up pages that are actually of interest.","f1bb599e":"# Support  Vector Machine- Linear SVC","10d71c86":"# Lets try Linear SVC Model","0a9f7932":"* It is found that hyper-parameter 1 performs best to predict the rating,our MNB automatically use hyperparameter 1. so already did this model.","c83920b1":"* our current rating data is float type and comment is object or combination of text, links, numbers and so on. ","cc9d9147":"# Purpose of the Project","53876e6f":"* we do not have any missing data as we already removed all missing data very begining of the data exploration","d77705c6":"![image.png](attachment:image.png)","311ea507":"# References","67b90a71":"# Making lowercase, removing punctuation and stop words","0152e709":"# Ensemble model with voting classifier shows only 29% accuracy which is still same with our SVC-unbalanced model (29%).","5129fc1d":"# Finally use the retrain SVC model to test the prediction of unbalanced data","adedd4ef":"Linear SVM is the newest extremely fast machine learning algorithm for solving multiclass classification problems from ultra large data sets that implements an original proprietary version of a cutting plane algorithm for designing a linear support vector machine.The objective of a Linear SVC (Support Vector Classifier) is to fit to the data, returning a \"best fit\" hyperplane that divides, or categorizes the training data.After getting the hyperplane, then the model can be feeded with test sample to classify the \"predicted\" class.\n\n![image.png](attachment:image.png)\nSVM uses kernel function, which finds the linear hyperplane that separates classes with the maximum margin. The above diagram shows how the data points (that is, support vectors) belonging to two different classes (red versus blue) are separated using the decision boundary based on the maximum margin. \n\n\n\n\n","d89d715f":"Text analysis is becoming important for Revealing imformation from text content. Due to advancement of machine learning algorithm, now the text analysis is very flexible and interesting in Neuro-lingistic field. The purpose of this project was predicting the game rating based on comments left by the users. For the purpose of the analysis, 30,000 unbalanced and 20,000 balanced random sample was taken from orginal board game geek data. To obtain the best accuracy MNB, MNB with N-grams, linear-SVC, Ensemble model for balanced SVC and Unbalanced SVC under joining condition and VotingClassifier condition was conducted. The accuracy for different experiment in case of unbalaced data set was: MNB accuaracy 27% with hyperparameter 1, MNB with N-grams 27% and SVC accuracy was 29%. But there was problem with these models due to unbalaced data used for training the model, it was not able to capture most of the negative rating (<5) and very high positive rating (>8). To overcome this problem a 20,000 balanced sample was created by taking 2000 samples from each rating. Then the SVC model was trained with balanced sample, after that SVC model was used to predict on unbalanced dataset. It was found that balanced training model accuracy was less than unbalced models, but it was able to capture all kinds of rating. SVC Balanced accuracy was 23% and SVC-unbalanced test accuracy was 20%, here we train SVC model only as we got that SVC performs better than MNB and MNB-N-grams in terms of the accuracy of the prediction. This project conducted two types of ensemable models: Voting Ensemable shows accuacy 29% while Joining Ensemble shows 66% accuracy which was outstanding results for this project. SVC balnced and SVC unbalced model was joined in this best model to predict on unbalced data.This study concludes that Ensemble model performs best than any other models with highest accuarcy. The challanging of this project was selecting the sample size and finding the best machine leaning algorithm and impliment them in a proper way. ","b94547d0":"* The above histrogram shows us the frequency of word in our data set.","b9e6ec7d":"# Lets do MNB model to predict the rating based on comments","a850ae9e":"# Executive Summary","3bf1d814":"# Stll our current data table has 26,37,755 rows and 5 columns which is huge. Before taking sample, lets check the description of data and rating bar graph to get the idea of rating frequency in whole data","1dd96d9f":"The Board Game Geek (BGG) database is a collection of data and information on traditional board games. The game information was recorded to intend for posterity, historical research, and user-contributed ratings. All the information within the database was meticulously and voluntarily entered on a game-by-game basis by board game user. This information is freely offered through flexible queries and \"data mining\". BoardGameGeek's ranking charts are ordered using the BGG Rating, which is based on the Average Rating. Game Rating was scaled 1 to 10 to present the sentiment. Understanding the popularity of the game depends on information provided by users, which is very important. For this project, board game reviews was used to predict the rating of the game using Machine learning Algorithm. Three kinds of Machine learning Algorithms (MNB, MNB_N-grams,SVC and Ensemble models) was used here for the whole projects.","032d5a21":"# Lets check with different hyperparameter for MNB Model","f62996d7":"# From histogram, it is clear that the highest rating frquency is 7 and than 8,6. The rating is included decimal like 4.2,4.3, 4.4,4.5,5.5,6.5,7.5 and others. But for our analysis we will take the rounded intiger value of rating.","204b98c8":"# To overcome this situation. we need to create a balnace data set as the subset of orinal data to train the model, then we need to use that model to predict on the unbalanced sample. In this case, we will train SVC model as it performs better than other two.","dc4607a2":"# Now lets start with our Board Game Geek Data","97e90d86":"# Unbalanced Sample Analysis with MNB, MNB-N-Grams and SVC -\n\n01. Board Game Geek Data Exploration\n02. Cleaning the data \n03. Taking 30,000 unbalanced random Sample\n04. Understanding the unbalanced sample\n05. Top 50 negative and Positive word identification and word cloud for them\n06. Multinomial Naive Bayes,Multinomial Naive Bayes with N-grams(1,2) and Linear SVC model for unbalanced Sample \n\n# Balanced Sample Analysis with Best Model SVC-\n07. Forming 10,000 random Balanced Sample from orginal data with 2000 samples from each rating (1-10)\n08. Traing the best performed SVC model with Balanced Data set\n09. Apply the balanced trained SVC model to predict unbalanced test data\n\n# Ensemble model Development with Balanced and unbalanced SVC model\n10. Ensemble model with voting classifier\n11. Ensemble model with joining Balced and Unbalced SVC model\n\n","cc7fe6da":"* Lets check data type with dtypes command","2011e3d9":"# Now we are ready to re-train our SVC model with the balance data","e6793018":"Voting classification techniqes in the ensemable predicts based on major votes. For example, if we use three models and they predict [1,0,1]target variable, the final prediction that the ensemble model would make would be 1, since two out of the three models predicted 1.","c364a19f":"# We removed all missing comments row, now lets see the shape of the file","592900ff":"* Lets check if we have any missing data yet","0230eacf":"So, it is clear that our unbalced sample has similar rating pattern like orginal sample.","bd0e8c1d":"# Naive Bayes Classifier","e35f90e7":"* We need only rating and comment columns, but we will keep all as it will not hamper our preocess of analysis","4bced431":"# WOOOW! Finally we have got 66% accuracy which is best than any others model we discussed here. It has also captured all kinds of rating from our data set rather than capturing rating close the mean.","9e26bb4b":"# Take different values of alpha in cross validation  and finding the accuracy score","fbbb15ee":"# Lets try us with Ensemble model to see the performance.\n# Create ensemble model using VotingClassifier","45cedcc5":"# Lets see word clouds for positive words and negative words","4c6d44a3":"# Lets do MNB model with N-grams to predict the rating based on comments","80ff7cfb":"# The accuracy of MNB model with N-grams is almost same of MNB (27 %) for unbalanced sample but the problem of the above model is that it also did not predict rating 1-4 and 8-9 (confusion Matrix), it has only predicted around the average value of the rating (6.85).","37fb25f0":"Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction.Every model has its strengths and weaknesses. Ensemble models can be beneficial by combining individual models to help hide the weaknesses of an individual model.","821341cb":"Multinominal Naive Bayes (MNB) algorithm has been widely used in text classification due to its computational advantage and simplicity. MNB maximizes likelihood rather than conditional likelihood or accuracy.The task of text classification can be approached from a Bayesian learning perspective, which assumes that the word distributions in documents are generated by a specific parametric model, and the parameters can be estimated from the training data. Beolow Equation  shows Multinominal Naive Bayes (MNB) model which is one such parametric model commonly used in text classification\n![image.png](attachment:image.png)\nwhere fi is the number of occurrences of a word wi in a document d, P(wijc) is the conditional probability that a word wi may happen in a document d given the class value c, and n is the number of unique words appearing in the document d.Conditional probability P(wijc) can be determined using the relative frequency of the word wi in documents belonging to class c.\n![image.png](attachment:image.png)\nwhere fic is the number of times that a word wi appears in all documents with the class label c, and fc is the total number of words in documents with class label c in T.\n\nOne advantage of the Multinominal Naive Bayes model is that it can make predictions efficiently.","0a39e1c2":"# If you see the above bar diagram, then it is clear that all rating have same number of samples which we named balanced sample. Now lets work with this balance sample. First, we will re-train our SVC model with balanced sample, then we will apply this model to predict test set from unbalanced sanple.","678046c3":"# We have already done this using MNB model. ","278c94bf":"# Now lets take 30,000 samples (Unbalanced)","c62190c0":" # The accuracy of MNB model is 27 % for unbalanced sample but the problem of the above model is that it did not predict rating 1-4 and 8-9 (confusion Matrix), it has only predicted around the average value of the rating (6.85)","7f1c0f2e":"# Multinomial Naive Bayes with N-grams","ea4cec35":"# Now lets see top 50 common words","a4725ffa":"# Now lets see the balanced rating","576f911f":"# Introduction"}}