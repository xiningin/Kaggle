{"cell_type":{"35fe9df9":"code","e2ef9eaf":"code","efc9998f":"code","1d308565":"code","765ef14d":"code","b5097f6d":"code","8029656e":"code","2a3741b7":"code","be222f9a":"code","0f8c670f":"code","f3ebf362":"code","3efe6026":"code","8dfb406c":"code","0d7a4317":"code","a6836835":"code","e1503605":"code","3df506de":"code","bbf00ef2":"code","9aff236e":"code","5c60694b":"code","4f07520a":"code","10381ee3":"code","8935577d":"code","3e36b6a2":"code","f7c0ae45":"code","8be562df":"code","2e8f88a5":"code","c11baa58":"code","287c5738":"code","cd974585":"code","ffa707e4":"code","562d20c3":"code","66ce0467":"code","7d151917":"code","6e3032ac":"code","008e3c2b":"code","affbc7d8":"code","68a2776f":"code","46c05dd9":"code","0468c67a":"code","45d7a65c":"code","925d1474":"code","e3b34184":"code","70549f02":"code","44925620":"code","f7a4fe9d":"code","a8490380":"code","90f6dcec":"code","d84acccd":"code","2377a25a":"code","9706f6ae":"code","bef37f2f":"code","e5057fcb":"code","e7506b61":"code","4337915a":"code","3cd9628d":"code","fe839b18":"code","94c40dd9":"code","d4ad88fc":"code","d2c915e5":"code","f2ca6d11":"code","5be71b78":"code","a47ec031":"code","2cceab1d":"code","59965f88":"code","dbabdb96":"code","51090f25":"code","5e62e28e":"code","800d7341":"code","aa542597":"code","3c668025":"code","fc0d29b0":"code","656894b5":"code","7f5b24e6":"code","3294b8c5":"code","e383c2b1":"code","7a0c1bf5":"code","65c8019c":"code","a698d417":"code","2c1cad3c":"code","1ac5e9d4":"code","780da415":"code","ef6fa29f":"code","91e1d4a0":"code","341432e0":"code","02fcf6c0":"code","3aebd902":"code","95e9cc54":"code","2038cdf3":"code","9f5357ec":"code","bcfc1bf5":"code","986aa6e6":"code","936f4a6e":"code","1b5f1a08":"code","3153163b":"code","bb8333d1":"code","3e6e009b":"code","9190a865":"code","7d465d90":"code","9d00f361":"code","7d124ba0":"code","cfd74756":"code","f37317ba":"code","a18bf5aa":"code","8b849cef":"code","207aeec0":"code","61d14e9b":"code","0e1e9a53":"code","35f4fde6":"code","156b1da8":"code","4632c55b":"code","8913bf6d":"code","5f1ab9b1":"code","df5ca867":"markdown","67c8ff7c":"markdown","98e19883":"markdown","3a676553":"markdown","498ee2f3":"markdown","6b4cf1ea":"markdown","cecc0154":"markdown","490dbc3d":"markdown","af156d6c":"markdown","0018799c":"markdown","4d72ff90":"markdown","2263c7ce":"markdown","982c2c4f":"markdown","7334b3e6":"markdown","e21032c5":"markdown","46fa6281":"markdown","1c244a7f":"markdown"},"source":{"35fe9df9":"#Importing important libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e2ef9eaf":"#Loading data\npath='..\/input\/cars-dataset\/automobileEDA.csv'\ndf = pd.read_csv(path)\ndf.head(20)","efc9998f":"#Changing the datatype of 'price' column.\ndf[['price']].replace(df['price'],df['price'].astype(dtype='int32'))","1d308565":"dict1={'Not diesel-0':(df[['diesel']]==0).values.sum(),'Diesel-1':(df[['diesel']]==1).values.sum()}\ndict2={'Not gas-0':(df[['gas']]==0).values.sum(),'gas-1':(df[['gas']]==1).values.sum()}\nprint (dict1)\nprint (dict2)","765ef14d":"df.head(40)","b5097f6d":"#Finding missing values.\nmissing_values=df.isnull()","8029656e":"# Displaying columns with null values. [False: number of non-missing values; True:Number of missing values]\n# Horsepower-binned has 1 missing value and stroke has 4 missing values.\nfor column in missing_values.columns.values.tolist():\n    print (column)\n    total=missing_values[column].value_counts()\n    print (total)","2a3741b7":"# Showing the datatypes of each column in df dataset.\ndf.dtypes","be222f9a":"#Include='all' will show unique, top, freq values for each column of df dataset.\ndf.describe(include='all')","0f8c670f":"df['stroke'].describe(include='all')","f3ebf362":"#Calculating the mean of 'stroke' column.\navg_stroke=df['stroke'].mean(axis=0)","3efe6026":"# Replacing the missing values in stroke column with mean. \ndf['stroke'].replace(np.nan,avg_stroke,inplace=True)","8dfb406c":"#Replacing missing values in horsepower-binned column with 'Low' because 'Low' has been repeated max. number of times. \ndf['horsepower-binned'].replace(np.nan,'Low',inplace=True)","0d7a4317":"missing_values=df.isnull()","a6836835":"for column in missing_values.columns.values.tolist():\n    print (column)\n    total=missing_values[column].value_counts()\n    print (total)","e1503605":"#Showing the result for columns with datatype of object.\ndf.describe(include=['object'])\n","3df506de":"#Grouping the features 'make' and 'body-style' on the basis of the mean of the prices.\ndata_1=df[['make','body-style','price']]\ngrp_data=data_1.groupby(['make','body-style'],as_index=False).mean()","bbf00ef2":"grp_data","9aff236e":"# Making one pivot table for easier interpretation.\npiv_d=grp_data.pivot(index='make',columns='body-style')\npiv_d","5c60694b":"# Filling null values with 0 in pivot data.\npiv_d2=piv_d.fillna(0)\npiv_d2","4f07520a":"data_p=piv_d2.values\ndata_p[0,1]","10381ee3":"# Plotting heatmap for easier understanding of correlation of features with each other.\nfig, ax=plt.subplots()\nim=ax.pcolor(piv_d2,cmap='RdBu')\nrowlabels=piv_d2.columns.levels[1]\ncolumnlabels=piv_d2.index\nax.set_xticks(np.arange(piv_d2.shape[1])+0.5,minor=False)\nax.set_yticks(np.arange(piv_d2.shape[0])+0.5,minor=False)\nax.set_xticklabels(rowlabels,minor=False)\nax.set_yticklabels(columnlabels,minor=False)\nplt.xticks(rotation=90)\nfig.show(ax)\nfig.colorbar(im)\nplt.show()","8935577d":"# Importing important libraries.\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\n","3e36b6a2":"df.shape","f7c0ae45":"df.describe(include='object')","8be562df":"df_obj=df[['make','aspiration','num-of-doors','body-style','drive-wheels','engine-location','engine-type','num-of-cylinders','fuel-system','horsepower-binned']]","2e8f88a5":"# Applying label encoder to all the features with object datatypes.\nP=df_obj.apply(LabelEncoder().fit_transform)\n","c11baa58":"df_1=df.assign(make=P[['make']])\ndf_1.head(5)","287c5738":"df_1=df_1.drop(columns=['aspiration','num-of-doors','body-style','drive-wheels','engine-location','engine-type','num-of-cylinders','fuel-system','horsepower-binned'],axis=1)","cd974585":"df_1.head()","ffa707e4":"df_2=df_1.assign(aspiration=P[['aspiration']],num_of_doors=P[['num-of-doors']],body_style=P[['body-style']],drive_wheels=P[['drive-wheels']],engine_location=P[['engine-location']],engine_type=P[['engine-type']],num_of_cylinders=P[['num-of-cylinders']],fuel_system=P[['fuel-system']],horsepower_binned=P[['horsepower-binned']])","562d20c3":"df_2.info()","66ce0467":"# Making a dataframe for each object type features with their values.\nbrand_values=pd.DataFrame({'Brand':np.unique(df_obj[['make']]),'Values':np.unique(P[['make']])})\naspiration_values=pd.DataFrame({'aspiration':np.unique(df_obj[['aspiration']]),'Values':np.unique(P[['aspiration']])})\nDoors_values=pd.DataFrame({'Doors':np.unique(df_obj[['num-of-doors']]),'Values':np.unique(P[['num-of-doors']])})\nbody_style=pd.DataFrame({'Body-style':np.unique(df_obj[['body-style']]),'Values':np.unique(P[['body-style']])})\ndrive_wheels=pd.DataFrame({'drive-wheels':np.unique(df_obj[['drive-wheels']]),'Values':np.unique(P[['drive-wheels']])})\nengine_location=pd.DataFrame({'engine-location':np.unique(df_obj[['engine-location']]),'Values':np.unique(P[['engine-location']])})\nengine_type=pd.DataFrame({'engine-type':np.unique(df_obj[['engine-type']]),'Values':np.unique(P[['engine-type']])})\nnum_of_cylinders=pd.DataFrame({'num-of-cylinders':np.unique(df_obj[['num-of-cylinders']]),'Values':np.unique(P[['num-of-cylinders']])})\nfuel_system=pd.DataFrame({'fuel-system':np.unique(df_obj[['fuel-system']]),'Values':np.unique(P[['fuel-system']])})\nhorsepower_binned=pd.DataFrame({'horsepower-binned':np.unique(df_obj[['horsepower-binned']]),'Values':np.unique(P[['horsepower-binned']])})","7d151917":"c=df_obj.assign(price=df_1[['price']])","6e3032ac":"# Grouping the feature 'make' w.r.t sum of prices corresponding to each feature.\ncat=c[['make','price']].groupby(['make'],as_index=False).sum().sort_values(by='price',ascending=False).reset_index(drop=True)","008e3c2b":"cat","affbc7d8":"# Toyota has the highest count of approx. 32 in our dataset.\n# Mercury has the lowest count of approx. 1 in our dataset.\nsns.set_style(style='darkgrid')\nax=sns.countplot(y='make',data=df_obj,order=df_obj['make'].value_counts().index)\nplt.show()\n","68a2776f":"# Toyota has the highest total of prices.\n# Mercury has the lowest total of prices.\nsns.barplot(y='make',x='price',data=cat)\nplt.show()","46c05dd9":"# Cars in sedan body style category are the highest.\n# Cars in convertible category are the lowest.\nsns.countplot(x='body-style',data=df_obj)\nplt.show()","0468c67a":"cat2=c[['body-style','price']].groupby(['body-style'],as_index=False).sum().sort_values(by='price',ascending=False)","45d7a65c":"cat2.reset_index(drop=True)","925d1474":"# Cars with sedan body style have the maximum sum of prices.\nsns.barplot(x='body-style',y='price',data=cat2)\nplt.show()","e3b34184":"cat['make'][0]","70549f02":"df_obj=df_obj.assign(price=df_2[['price']])","44925620":"df_obj.columns","f7a4fe9d":"aspiration_values","a8490380":"# importing important library\nimport scipy","90f6dcec":"# This function will calculate the pearson-correlation and p-values w.r.t prices for each features in the dataset.\ndef p_corr(data):\n    stats=[]\n    for i in range(29):\n        col=data.columns[i]\n        stats.append(scipy.stats.pearsonr(data[col],data['price']))\n    return stats","d84acccd":"s=p_corr(df_2)","2377a25a":"# This function will create a list of array for pearson-correlation values\ndef sta(s):\n    st=[]\n    for i in range(29):\n        st.append(s[i][0])\n    return st\n    ","9706f6ae":"pear=sta(s)","bef37f2f":"pear","e5057fcb":"pc=pd.DataFrame({'pearson_correlation':pear})","e7506b61":"ind=pc.reset_index(drop=True,inplace=True)\npc","4337915a":"# This function will create the list of array for P-Values.\ndef p_val(v):\n    pvl=[]\n    for i in range(29):\n        pvl.append(v[i][1])\n    return (pvl)","3cd9628d":"pvalue=p_val(s)","fe839b18":"pvalue","94c40dd9":"pvalue","d4ad88fc":"Pvaluedf=pd.DataFrame({'P-Value':pvalue})","d2c915e5":"Pvaluedf","f2ca6d11":"# Here, a new column ['P-value'] has been added to the pc dataframe.\nstatsdf=pc.assign(P_Value=Pvaluedf[['P-Value']])","5be71b78":"statsdf","a47ec031":"coldf=pd.DataFrame(data=df_2.columns.values.tolist(),columns=['Features'])","2cceab1d":"coldf","59965f88":"coldf","dbabdb96":"Final_df=coldf.reset_index(drop=True,inplace=False)","51090f25":"Final_df","5e62e28e":"# A dataframe will be created by adding two columns to the Final_df dataframe so as to make the interpreation of values easy.\nstats_df=Final_df.assign(Pearson_coefficient=statsdf[['pearson_correlation']],p_value=statsdf[['P_Value']])","800d7341":"stats_df","aa542597":"# Assigning features which are highly correlated with the prices to X.\n# Assigning target 'price' to y.\nX=df_2[['wheel-base','length','width','curb-weight','engine-size','bore','stroke','horsepower','city-mpg','highway-mpg','city-L\/100km','drive_wheels','fuel_system']]\ny=df_2[['price']]","3c668025":"#Importing important libraries.\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","fc0d29b0":" # Dividing X and y dataset into training and test dataset.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","656894b5":"print (X_train.shape,y_train.shape)\nprint (X_test.shape,y_test.shape)","7f5b24e6":"sns.regplot(df_2['highway-mpg'],df_2['price'])\nplt.show()","3294b8c5":"# Predicting prices on the basis of 'highway-mpg'.\nx1=np.array(df_2['highway-mpg'][:134])\ny1=np.array(df_2['price'][:134])","e383c2b1":"xt=np.array(df_2['highway-mpg'][134:]).reshape(-1,1)\nyt=np.array(df_2['price'][134:])","7a0c1bf5":"x1=x1.reshape(-1,1)","65c8019c":"sl=LinearRegression()","a698d417":"model1=sl.fit(x1,y1)","2c1cad3c":"pre=model1.predict(xt)","1ac5e9d4":"pre[:4]","780da415":"lr=LinearRegression()","ef6fa29f":"model2=lr.fit(X_train,y_train)","91e1d4a0":"prediction=model2.predict(X_test)","341432e0":"score=model2.score(X_test,y_test)\nprint (score)","02fcf6c0":"# In this graph predicted prices are very close to the actual prices. But, their is still some error in values after 30000.\nplt.figure(figsize=(12, 10))\nax1=sns.distplot(y_test,hist=False,color='red',label='actual prices')\nsns.distplot(prediction,hist=False,label='predicted prices',ax=ax1)\nplt.title('Actual vs predicted Values for Price')\nplt.xlabel('Price (in dollars)')\nplt.ylabel('Proportion of Cars')\nplt.show()","3aebd902":"# From this graph we can say that this graph is not linear.\nplt.figure(figsize=(12,10))\nsns.regplot(df_2['highway-mpg'],df_2['price'],fit_reg=False)\nplt.show()","95e9cc54":"#Function for plotting the polynomial graph.\ndef PlotPolly(model, independent_variable, dependent_variabble, Name):\n    x_new = np.linspace(15, 55, 201)\n    y_new = model(x_new)\n\n    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n    ax = plt.gca()\n    ax.set_facecolor((0.898, 0.898, 0.898))\n    fig = plt.gcf()\n    plt.xlabel(Name)\n    plt.ylabel('Price of Cars')\n    \n    plt.show()\n    plt.close()\n    return y_new","2038cdf3":"x=df_2['highway-mpg']\ny=df_2['price']\n    ","9f5357ec":"# Here we use a polynomial of the 3rd order (cubic) \nf = np.polyfit(x, y, 3)\np = np.poly1d(f)\nprint(p)","bcfc1bf5":"plt.figure(figsize=(12,10))\ny_p=PlotPolly(p,x,y,'highway-mpg')","986aa6e6":"y_p","936f4a6e":"from sklearn.preprocessing import PolynomialFeatures","1b5f1a08":"m=PolynomialFeatures(degree=2)","3153163b":"model2=m.fit_transform(X_train,y_train)","bb8333d1":"model2.shape","3e6e009b":"X_train.shape","9190a865":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler","7d465d90":"Input=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]","9d00f361":"pipe=Pipeline(Input)\npipe","7d124ba0":"model3=pipe.fit(X_train,y_train)","cfd74756":"ymodel=model3.predict(X_test)","f37317ba":"ymodel[:3]","a18bf5aa":"ymodel.shape","8b849cef":"X_=np.array(df_2['highway-mpg']).reshape(-1,1)\ny_=np.array(df_2['price']).reshape(-1,)","207aeec0":"X_.shape,y_.shape","61d14e9b":"model1=lr.fit(X_,y_)","0e1e9a53":"#Accuracy is approx. 49 percenton the basis of single feature 'highway-mpg'.\nmodel1.score(X_,y_)","35f4fde6":"model2=lr.fit(X_train,y_train)\n","156b1da8":"pr=model2.predict(X_train)","4632c55b":"# Accuracy is approx. 79 percent.\nmodel2.score(X_test,y_test)","8913bf6d":"from sklearn.metrics import r2_score","5f1ab9b1":"#Accuracy is approx 67 percent for 'highway-mpg' feature.\nr_squared = r2_score(y, p(x))\nprint('The R-square value is: ', r_squared)","df5ca867":"# Multiple linear Regression","67c8ff7c":"# Polynomial regression score","98e19883":"We will build a pipeline to make the data processing easy.","3a676553":"Now, since we have cleaned our data, next step is to preprocess the data by transforming the features with object datatype to some binary and int dataypes so that machine learning algorithms can understand the data.","498ee2f3":"# Exploratory data Analysis","6b4cf1ea":"# Making a dataframe with columns consisting of pearson-correlation and p-value","cecc0154":"# Finding pearson correlation and p-value for each column w.r.t price.","490dbc3d":"# Pipeline","af156d6c":"Now, from the dataframe 'stats_df', we will find the features with high pearson-correlation with prices and make a seperate dataframe for it.","0018799c":"# Polynomial regression","4d72ff90":"# Multiple linear Regression score","2263c7ce":"# Simple Linear Regression","982c2c4f":"# Conclusion","7334b3e6":"Hence, we can say that multiple linear regression is the best model to predict the prices as it has high r^2 score of approx. 80 percent compare to other models.\n\nAlso, the best features to use for prediction are:-\n1- Wheel-base\n2- Length\n3- Width\n4- Curb-weight\n5- Engine-size\n6- Bore\n7- Stroke\n8- Horsepower\n9- City-mpg\n10- Highway-mpg\n11- City-L\/100km\n12- Drive_wheels\n13- Fuel_system","e21032c5":"# Calculating R-2 score and listing the best model for prediction","46fa6281":"# Simple linear regression score","1c244a7f":"# Data modelling"}}