{"cell_type":{"6eb7d6e4":"code","a126cfd0":"code","e9005c06":"code","d60c0594":"code","3395bf99":"code","50280432":"code","1350a4f4":"code","41cea1cb":"code","bc5e7e05":"code","31005b99":"code","2a6c23ba":"code","3137fd7c":"code","88d835ae":"code","155d8520":"code","3ac0b09c":"code","dcd59ecc":"code","96e854e0":"code","4b382e8e":"code","50044430":"code","a2aa3329":"code","db334fa3":"code","8b9385d3":"code","5b70d5ec":"code","46bf599e":"code","472df6ee":"code","51a915b7":"code","e3f067ac":"code","058777b8":"code","5b04515a":"code","cbfe9d93":"code","9cc0b873":"code","768a1d31":"code","e1ff5d58":"code","8e1941cc":"code","b120f358":"code","4f027df1":"code","cfcbb409":"code","67133760":"code","ff22cfbd":"code","814d2a53":"markdown","3e5e4fa9":"markdown","2ed392eb":"markdown","72bbfc50":"markdown","0a8adcd1":"markdown","1e1cc7a9":"markdown","a9838b68":"markdown","55f76c3f":"markdown","8d1b9299":"markdown","852439f6":"markdown","fb9d70e2":"markdown","a74aef2a":"markdown","10a366d0":"markdown","e8dcb7f4":"markdown","5a7ebb03":"markdown","ec2dfced":"markdown","9610f74f":"markdown","77e14dd2":"markdown","75e6906a":"markdown","bb90bb67":"markdown","4cb63d90":"markdown","95510dad":"markdown","3da38929":"markdown","54e23ed1":"markdown","23009817":"markdown","7c312a2e":"markdown","f36d0a60":"markdown","0ce5b588":"markdown"},"source":{"6eb7d6e4":"# Basic libraries\nimport numpy as np\nimport pandas as pd\n\n# model libraries\nfrom sklearn.model_selection import train_test_split\nimport tensorflow\nimport keras\n#from sklearn.ensemble import RandomForestClassifier\n#from sklearn.model_selection import KFold\n#from sklearn.model_selection import GridSearchCV\n\n# model accuracy check\nfrom sklearn import metrics\n\n# plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","a126cfd0":"# read the data\ntrain_file = '..\/input\/digit-recognizer\/train.csv'\ntest_file = '..\/input\/digit-recognizer\/test.csv'\n\ndf_train = pd.read_csv(train_file)\ndf_test = pd.read_csv(test_file)\n","e9005c06":"df_train.head()","d60c0594":"df_train.shape","3395bf99":"# columns pixel0....pixel785 are independent variable of a digit\n# column label contains the digit (dependent variable)\n\ndf_train.columns","50280432":"df_test.shape","1350a4f4":"df_test.columns","41cea1cb":"# no null values in train dataset\n\ndf_train.isnull().values.any()","bc5e7e05":"df_train.info()","31005b99":"# print the frequency of each label\n\nprint(df_train['label'].value_counts())\nsns.countplot(df_train['label'])","2a6c23ba":"plt.figure(figsize=(12,4))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    plt.imshow(df_train.drop(['label'],axis=1).values[i].reshape(28,28) )\n    plt.axis('off')\nplt.show()\n\n# print corresponding labels:\nprint(list(df_train['label'].loc[0:9]))\nprint(list(df_train['label'].loc[10:19]))\nprint(list(df_train['label'].loc[20:29]))","3137fd7c":"plt.figure(figsize=(12,4))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    plt.imshow(df_test.values[i].reshape(28,28) )\n    plt.axis('off')\nplt.show()","88d835ae":"X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['label'],axis=1),\n                                                   df_train['label'],\n                                                   test_size = 0.2,\n                                                   random_state=13)","155d8520":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","3ac0b09c":"X_train.head()","dcd59ecc":"y_train.head()","96e854e0":"# y_train = keras.utils.to_categorical(y_train)\n# y_test = keras.utils.to_categorical(y_test)\n\nn_cols = X_train.shape[1]\nprint(\"Number of input columns: {0}\".format(n_cols))\n\nn_features = len(y_train.unique())\nprint(\"Number of output features: {0}\".format(n_features))\n","4b382e8e":"# let's convert labels to categorical variable\ny_train = keras.utils.to_categorical(y_train, n_features)\ny_test = keras.utils.to_categorical(y_test, n_features)","50044430":"y_train, y_test","a2aa3329":"# Let's do the same with X variables. \n# data has pixels with max values of 255. So will divide values with 255 to scale the data\nX_train = X_train \/ 255\nX_test = X_test \/ 255","db334fa3":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import RMSprop\nfrom keras.optimizers import SGD\n\nm = Sequential()\nm.add(Dense(512,activation='relu',input_shape=(n_cols,)))\nm.add(Dropout(0.5))\nm.add(Dense(256,activation='relu'))\nm.add(Dropout(0.5))\nm.add(Dense(128,activation='relu'))\nm.add(Dropout(0.5))\nm.add(Dense(64,activation='relu'))\nm.add(Dropout(0.5))\nm.add(Dense(n_features,activation='softmax'))\n\nm.summary()","8b9385d3":"m.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n#m.compile(optimizer=SGD(),loss='categorical_crossentropy',metrics=['accuracy'])\n","5b70d5ec":"n_batch_size = 256\nn_epochs = 200\nhistory = m.fit(X_train, y_train, batch_size=n_batch_size, epochs=n_epochs, validation_data=(X_test,y_test))\n","46bf599e":"plt.plot(history.history['val_acc'],'b')\nplt.plot(history.history['acc'],'r')","472df6ee":"plt.plot(history.history['val_loss'],'b')\nplt.plot(history.history['loss'],'r')","51a915b7":"y_pred = np.round(m.predict(X_test)).astype('int64')\ny_pred","e3f067ac":"# remove the categories from y_pred\n# select the indix with the maximum probability\ny_pred1 = np.argmax(y_pred,axis = 1)\ny_pred1","058777b8":"# do the same for y_test\n# select the index with the maximum probability\ny_test1 = np.argmax(y_test,axis = 1)\ny_test1","5b04515a":"# print the frequency of each label\n\ny = pd.DataFrame(y_pred1)\ny.columns=['label']\nprint(y['label'].value_counts())\n\ny[y['label'] < 0] = 0\ny[y['label'] > 9] = 9\n\nsns.countplot(y['label'])","cbfe9d93":"print('Accuracy score for y_test: ', metrics.accuracy_score(y_test1,y_pred1))","9cc0b873":"pd.DataFrame(metrics.confusion_matrix(y_test1,y_pred1))","768a1d31":"# combine actual and predicted in a single df\nX_test['actual'] = y_test1\nX_test['pred'] = y_pred1","e1ff5d58":"X_test_err = X_test[X_test['actual'] != X_test['pred']]\nprint(X_test_err.shape[0],\"predictions are wrong\")","8e1941cc":"for i in range (10):\n    act=X_test_err['actual'].values[i]\n    prd=X_test_err['pred'].values[i]\n    print(\"actual {0} ; predicted {1}\".format(act,prd))\n    plt.figure(figsize=(1,1))\n    plt.imshow(X_test_err.drop(['actual','pred'], axis=1).values[i].reshape(28,28))\n    plt.axis(\"off\")\n    plt.show()","b120f358":"# # normalize the input data\ndf_test = df_test \/ 255\npred = m.predict(df_test)\npred","4f027df1":"# select the index with the maximum probability\npred = np.argmax(pred,axis = 1)\npred","cfcbb409":"\nfor i in range(11):  \n    print('Prediction {0}'.format(pred[i]))\n    plt.figure(figsize=(1,1))\n    plt.imshow(df_test.values[i].reshape(28,28) )\n    plt.axis('off')\n    plt.show()\n","67133760":"pred = pd.Series(pred,name=\"Label\")","ff22cfbd":"submit = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred],axis = 1)\n\nsubmit.to_csv(\"cnn_mnist_fewsteps_keras.csv\",index=False)","814d2a53":"### Explore Train Dataset","3e5e4fa9":"Few of the images are easy but tricky. \n\nModel should be trained further with augmented images to achieve better accuracy","2ed392eb":"# 4. Model test on validation set (y_test)\n\nWIll run it on X_test and result set would be validated against y_test","72bbfc50":"### Perform train-test split\n\nTrain data set is divided in 80:20 ratio for train\/test\n","0a8adcd1":"### Basic data check","1e1cc7a9":"### keras Model\n\n","a9838b68":"Display few images and their respective predicted labels","55f76c3f":"# 5. Final Submission","8d1b9299":"### Validation accuracy","852439f6":"# 2. Data read, preparation and explore","fb9d70e2":"Data used from kaggle competition link: https:\/\/www.kaggle.com\/c\/digit-recognizer\/","a74aef2a":"# 1. Introduction\n\nThis is the simplest demonstration of keras model using tensorflow as backend. \nI achieved accuracy of 97% which is not very great but its still descent. Moreover the model is built with default options so it still have scope for improvement. \n\nInitially, my accuracy was not that good and it did not improved beyond 85% despite multiple epochs. Then I tried with below options and accuracy improved to current levels.\n\n1. Hot-encoding the labels. \n\n2. Scaling X variables. \n\n3. Trying different optimisers\n\n4. Increasing epochs\n\n5. Adjusting dropout rate\n","10a366d0":"I end this notebook here with leaving further scope of improvement to keras. Share your improvement ideas in comments. If you found this notebook helpful or you just liked it, some upvotes would be very much appreciated. It will keep me motivated :)\n\nThanks for visiting. ","e8dcb7f4":"### Validation loss","5a7ebb03":"### Read data files","ec2dfced":"This notebook is divided into below 4 section:\n1. Introduction\n2. Data read, preparation and explore\n3. RandomForest GridSearch\n4. Model test on validation set\n5. Result Submission\n","9610f74f":"Finally, time to run model on required test set and sumbit the result on Kaggle","77e14dd2":"### Import libraries","75e6906a":"Many predictions went wrong. Lets draw few of them. ","bb90bb67":"Building models on personal computer has its own limitations. Like in this case, training with more epochs and using more custom parameters will eat into computer resources. I plan to run GridSearch with more customized parameters option on AWS cloud solution and let it take time that it needs.","4cb63d90":"### Run on test data (df_test) and display few test images","95510dad":"Each digit image is of 28x28 size which is total of 784 pixels. These pixel values are stored in columns pixel0....pixel785 (independent variable) for a digit. \nColumn label contains the corresponding digit (dependent variable).","3da38929":"# Few steps with keras","54e23ed1":"From test, display few initial images. Need to predict the lable for these. ","23009817":"From train set, display few initial images and corresponding labels:","7c312a2e":"Test data set contains 784 pixel values for a digit. It does not contain the label.\n\nNeed to indentify the digit based on the 784 pixels. ","f36d0a60":"# 3. keras model building\n\nKeras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. \n\nBeing able to go from idea to result with the least possible delay is key to doing good research.\n","0ce5b588":"Model is doing a good job, but fails for distorted images. "}}