{"cell_type":{"c2aeda1b":"code","87d8b2bb":"code","beb69d42":"code","f2185411":"code","55d954f4":"code","83eec575":"code","376ea9c2":"code","64b2fdc9":"code","ab75f51e":"code","69bed38f":"code","4b45da4d":"code","48fd087f":"code","f0663174":"code","c543c456":"code","e5ff05f6":"code","3695a208":"code","0b5e5f35":"code","736ffa31":"code","01e3cf5a":"code","1d95940f":"code","cf412702":"code","b7da562a":"code","198653db":"code","40b75769":"code","addf6801":"code","1fda4b3a":"code","9d42f970":"code","2fafc6f5":"code","5ed1e16b":"code","6356a012":"code","248e0941":"code","c0a1aaa3":"code","0af837a2":"code","3ef5daea":"code","3c8007a0":"code","f335d29a":"code","e97ec4cb":"code","ac459038":"code","3ab8c94c":"code","579480af":"code","edb4ba95":"code","7ac731e1":"code","4ec57a14":"code","32a76c4f":"code","66a1b9e8":"code","4657f4eb":"code","f7f4614a":"code","d35ec06e":"code","5acffae1":"code","0632c698":"code","ade2224b":"code","fd5647d8":"code","0015e053":"code","6957c9fe":"code","d2f84aa6":"code","45638fa4":"code","58e3a107":"code","ff06c3e7":"code","c1e20287":"code","bdac3b24":"code","4f79d208":"code","525561ee":"code","227a6ff1":"code","5cd96793":"code","79037c80":"code","6b3776d2":"code","f9ecaafe":"code","f87a5063":"code","d5934059":"code","63c02031":"code","daef77a1":"code","6fd20865":"code","4f3c2497":"code","5f738691":"code","0f770c91":"code","8733ef11":"code","bcdef1c0":"code","1a86c2e1":"code","db09c2bd":"code","6de86dda":"code","1bd8ce5f":"code","91581a5e":"code","9e4a438b":"code","c796db81":"code","b6771714":"code","188dd375":"code","381602c9":"code","96447318":"code","8945b5e5":"code","aadda7b6":"code","2e6f2c54":"code","7d21b34b":"code","662cf803":"code","ce182864":"code","cf87ea43":"code","791a61ca":"code","278ce8e1":"code","dcbff81d":"code","e1793a11":"code","de128a70":"markdown","5f8fed06":"markdown","4f55dce4":"markdown","83551792":"markdown","6382a574":"markdown","254da33f":"markdown","7f55eab4":"markdown","033e1eca":"markdown","5d825ae0":"markdown","aa375e3d":"markdown","68aff9e2":"markdown","a0327614":"markdown","cf5f11d7":"markdown","00faa917":"markdown","19af0c24":"markdown","aab42a16":"markdown","c87a0ea3":"markdown","9e01b989":"markdown","a547142a":"markdown"},"source":{"c2aeda1b":"import tensorflow as tf\nimport datetime, os","87d8b2bb":"from numpy.random import seed\nseed(888)\nimport tensorflow\ntensorflow.random.set_seed(404)","beb69d42":"import os\nimport numpy as np\nimport tensorflow as tf\n\nimport itertools\n \nfrom tensorflow import keras\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n \n# from tensorflow.keras import Sequential\n# from tensorflow.keras.layers import Conv2D, Flatten, Dense ,Dropout\n \nfrom IPython.display import display\nfrom keras.preprocessing.image import array_to_img\n# from keras.callbacks import TensorBoard\n \nfrom time import strftime\n \nfrom sklearn.metrics import confusion_matrix\n \n \nimport matplotlib.pyplot as plt\n \n%matplotlib inline","f2185411":"from keras.callbacks import TensorBoard\nTensorBoard(log_dir='.\/log')\n%load_ext tensorboard","55d954f4":"LOG_DIR = 'tensorboard_cifar_logs\/'\n\nLABEL_NAMES = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\nIMAGE_WIDTH = 32\nIMAGE_HEIGHT = 32\nIMAGE_PIXELS = IMAGE_WIDTH * IMAGE_HEIGHT\nCOLOR_CHANNELS = 3\nTOTAL_INPUTS = IMAGE_PIXELS * COLOR_CHANNELS\nNR_CLASSES = 10\n\nVALIDATION_SIZE = 10000\nSMALL_TRAIN_SIZE = 1000","83eec575":"(x_train_all, y_train_all), (x_test, y_test) = cifar10.load_data()","376ea9c2":"type(cifar10)\n# type(x_train_all)","64b2fdc9":"# x_train_all[0]","ab75f51e":"pic = array_to_img(x_train_all[7])\ndisplay(pic)","69bed38f":"y_train_all.shape","4b45da4d":"y_train_all[7][0]","48fd087f":"LABEL_NAMES[y_train_all[7][0]]","f0663174":"plt.imshow(x_train_all[4])\nplt.xlabel(LABEL_NAMES[y_train_all[4][0]], fontsize=15)\nplt.show()","c543c456":"plt.figure(figsize=(15,5))\n\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    plt.yticks([])\n    plt.xticks([])\n    plt.xlabel(LABEL_NAMES[y_train_all[i][0]], fontsize=14)\n    plt.imshow(x_train_all[i])","e5ff05f6":"x_train_all[0].shape","3695a208":"nr_images, x, y, c = x_train_all.shape\nprint(f'images = {nr_images} \\t| width = {x} \\t| height = {y} \\t| channels = {c}')","0b5e5f35":"x_test.shape","736ffa31":"type(x_train_all[0][0][0][0])","01e3cf5a":"x_train_all, x_test = x_train_all \/ 255.0, x_test \/ 255.0","1d95940f":"type(x_train_all[0][0][0][0])","cf412702":"x_train_all[0][0][0][0]","b7da562a":"x_train_all = x_train_all.reshape(x_train_all.shape[0], TOTAL_INPUTS)","198653db":"x_train_all.shape","40b75769":"x_test = x_test.reshape(len(x_test), TOTAL_INPUTS)\nprint(f'Shape of x_test is {x_test.shape}')","addf6801":"x_val = x_train_all[:VALIDATION_SIZE]\ny_val = y_train_all[:VALIDATION_SIZE]\nx_val.shape","1fda4b3a":"x_train = x_train_all[VALIDATION_SIZE:]\ny_train = y_train_all[VALIDATION_SIZE:]\nx_train.shape","9d42f970":"x_train_xs = x_train[:SMALL_TRAIN_SIZE]\ny_train_xs = y_train[:SMALL_TRAIN_SIZE]","2fafc6f5":"x_train_xs.shape","5ed1e16b":"model_1 = Sequential([\n    Dense(units=128, input_dim=TOTAL_INPUTS, activation='relu', name='m1_hidden1'),\n    Dense(units=64, activation='relu', name='m1_hidden2'),\n    Dense(16, activation='relu', name='m1_hidden3'),\n    Dense(10, activation='softmax', name='m1_output')\n])\n\nmodel_1.compile(optimizer='adam', \n                loss='sparse_categorical_crossentropy', \n                metrics=['accuracy'])\n","6356a012":" type(model_1)","248e0941":"model_1.summary()","c0a1aaa3":"32*32*3*128","0af837a2":"32*32*3*128 + 128","3ef5daea":"32*32*3*128 + 128 + (128*64 + 64) + (64*16 + 16) + (16*10 + 10)","3c8007a0":"model_2 = Sequential()\nmodel_2.add(Dropout(0.2, seed=42, input_shape=(TOTAL_INPUTS,)))\nmodel_2.add(Dense(128, activation='relu', name='m2_hidden1'))\nmodel_2.add(Dense(64, activation='relu', name='m2_hidden2'))\nmodel_2.add(Dense(16, activation='relu', name='m2_hidden3'))\nmodel_2.add(Dense(10, activation='softmax', name='m2_output'))\n\nmodel_2.compile(optimizer='adam', \n                loss='sparse_categorical_crossentropy', \n                metrics=['accuracy'])","f335d29a":"model_3 = Sequential()\nmodel_3.add(Dropout(0.2, seed=42, input_shape=(TOTAL_INPUTS,)))\nmodel_3.add(Dense(128, activation='relu', name='m3_hidden1'))\nmodel_3.add(Dropout(0.25, seed=42))\nmodel_3.add(Dense(64, activation='relu', name='m3_hidden2'))\nmodel_3.add(Dense(16, activation='relu', name='m3_hidden3'))\nmodel_3.add(Dense(10, activation='softmax', name='m3_output'))\n\nmodel_3.compile(optimizer='adam', \n                loss='sparse_categorical_crossentropy', \n                metrics=['accuracy'])","e97ec4cb":"# def train_model():\n  \n#   model_1 = Sequential([\n#       Dense(units=128, input_dim=TOTAL_INPUTS, activation='relu', name='m1_hidden1'),\n#       Dense(units=64, activation='relu', name='m1_hidden2'),\n#       Dense(16, activation='relu', name='m1_hidden3'),\n#       Dense(10, activation='softmax', name='m1_output')\n#   ])\n \n#   model_1.compile(optimizer='adam', \n#                   loss='sparse_categorical_crossentropy', \n#                   metrics=['accuracy'])\n \n \n#   logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n#   tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n \n#   model_1.fit(x_train_xs,y_train_xs,callbacks=[tensorboard_callback])","ac459038":"# train_model()","3ab8c94c":"%tensorboard --logdir logs","579480af":"# def get_tensorboard(model_name):\n\n#     folder_name = f'{model_name} at {strftime(\"%H %M\")}'\n#     dir_paths = os.path.join(LOG_DIR, folder_name)\n\n#     try:\n#         os.makedirs(dir_paths)\n#     except OSError as err:\n#         print(err.strerror)\n#     else:\n#         print('Successfully created directory')\n\n#     return TensorBoard(log_dir=dir_paths)","edb4ba95":" import datetime","7ac731e1":"logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)","4ec57a14":"%%time\n\nmodel_1.fit(x_train_xs,y_train_xs)","32a76c4f":"# %%time\n\n# model_1.fit(x_train_xs,y_train_xs,callbacks=[tensorboard_callback])","66a1b9e8":"# %%time\n\n# model_1.fit(x_train_xs,y_train_xs)","4657f4eb":"# %tensorboard --logdir logs","f7f4614a":"x_train_xs.shape","d35ec06e":"%%time\nnr_epochs = 20\nmodel_1.fit(x_train_xs, y_train_xs, epochs=nr_epochs,\n            )","5acffae1":"# %tensorboard --logdir logs","0632c698":"samples_per_batch = 1000","ade2224b":"x_train_xs.shape","fd5647d8":"# %%time\n# nr_epochs = 20\n# model_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback])","0015e053":"# %tensorboard --logdir logs","6957c9fe":"%%time\nnr_epochs = 20\nmodel_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs)","d2f84aa6":"# %%time\n# nr_epochs = 150\n# model_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback], verbose=0)","45638fa4":"%%time\nnr_epochs = 150\nmodel_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs)","58e3a107":"# %%time\n# nr_epochs = 50\n# model_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback])","ff06c3e7":"# %%time\n# nr_epochs = 50\n# model_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback])","c1e20287":"# %%time\n# nr_epochs = 150\n# model_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback], verbose=0, validation_data=(x_val, y_val))","bdac3b24":"# %%time\n# nr_epochs = 150\n# model_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback], verbose=0, validation_data=(x_val, y_val))","4f79d208":"# %tensorboard --logdir logs","525561ee":"%%time\nnr_epochs = 150 \nmodel_1.fit(x_train_xs, y_train_xs, batch_size=samples_per_batch, epochs=nr_epochs\n            , validation_data=(x_val, y_val))","227a6ff1":"# %tensorboard --logdir logs","5cd96793":"# %%time\n# nr_epochs = 100\n# model_1.fit(x_train, y_train, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback], verbose=0, validation_data=(x_val, y_val))","79037c80":"# %tensorboard --logdir logs","6b3776d2":"# %%time\n# nr_epochs = 100\n# model_2.fit(x_train, y_train, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback], verbose=0, validation_data=(x_val, y_val))","f9ecaafe":"%%time\nnr_epochs = 100\nmodel_2.fit(x_train, y_train, batch_size=samples_per_batch, epochs=nr_epochs,\n             validation_data=(x_val, y_val))","f87a5063":"# %tensorboard --logdir logs","d5934059":"# %%time\n# nr_epochs = 100\n# model_3.fit(x_train, y_train, batch_size=samples_per_batch, epochs=nr_epochs,\n#             callbacks=[tensorboard_callback], verbose=0, validation_data=(x_val, y_val))","63c02031":"%%time\nnr_epochs = 100\nmodel_3.fit(x_train, y_train, batch_size=samples_per_batch, epochs=nr_epochs,\n             validation_data=(x_val, y_val))","daef77a1":"%%time\nnr_epochs = 100\nmodel_1.fit(x_train, y_train, batch_size=samples_per_batch, epochs=nr_epochs,\n             validation_data=(x_val, y_val))","6fd20865":"x_val[0].shape","4f3c2497":"y_val[0]","5f738691":"test = np.expand_dims(x_val[0], axis=0)\ntest.shape","0f770c91":"np.set_printoptions(precision=3)","8733ef11":"model_3.predict(test)","bcdef1c0":"model_3.predict(x_val).shape","1a86c2e1":"model_3.predict_classes(test)","db09c2bd":"np.argmax(model_3.predict(test), axis=-1)","6de86dda":"# y_val[2][0]","1bd8ce5f":"for number in range(10):\n    test_img = np.expand_dims(x_val[number], axis=0)\n    predicted_val = model_3.predict_classes(test_img)[0]\n    print(f'Actual value: {y_val[number][0]} vs. predicted: {predicted_val}')","91581a5e":"model_3.metrics_names","9e4a438b":"x_test.shape","c796db81":"test_loss, test_accuracy = model_3.evaluate(x_test, y_test)\nprint(f'Test loss is {test_loss:0.3} and test accuracy is {test_accuracy:0.1%}')","b6771714":"# LABEL_NAMES","188dd375":"predictions = model_3.predict_classes(x_test)\nconf_matrix = confusion_matrix(y_true=y_test, y_pred=predictions)","381602c9":"conf_matrix.shape","96447318":"conf_matrix","8945b5e5":"nr_rows = conf_matrix.shape[0]\nnr_cols = conf_matrix.shape[1]","aadda7b6":"conf_matrix.max()","2e6f2c54":"conf_matrix.min()","7d21b34b":"conf_matrix[0][0]","662cf803":"conf_matrix[0,1]","ce182864":"plt.figure(figsize=(7,7), dpi=95)\nplt.imshow(conf_matrix, cmap=plt.cm.Greens)\n\nplt.title('Confusion Matrix', fontsize=16)\nplt.ylabel('Actual Labels', fontsize=12)\nplt.xlabel('Predicted Labels', fontsize=12)\n\ntick_marks = np.arange(NR_CLASSES)\nplt.yticks(tick_marks, LABEL_NAMES)\nplt.xticks(tick_marks, LABEL_NAMES)\n\nplt.colorbar()\n\nfor i, j in itertools.product(range(nr_rows), range(nr_cols)):\n    plt.text(j, i, conf_matrix[i, j], horizontalalignment='center',\n             color='white' if conf_matrix[i, j] > conf_matrix.max()\/2 else 'black')\n    \n\nplt.show()","cf87ea43":"# True Positives\nnp.diag(conf_matrix)","791a61ca":"recall = np.diag(conf_matrix) \/ np.sum(conf_matrix, axis=1)\nrecall","278ce8e1":"precision = np.diag(conf_matrix) \/ np.sum(conf_matrix, axis=0)\nprecision","dcbff81d":"avg_recall = np.mean(recall)\nprint(f'Model 3 recall score is {avg_recall:.2%}')","e1793a11":"avg_precision = np.mean(precision)\nprint(f'Model 3 precision score is {avg_precision:.2%}')\n\nf1_score = 2 * (avg_precision * avg_recall) \/ (avg_precision + avg_recall)\nprint(f'Model 3 f score is {f1_score:.2%}')","de128a70":"# Predictions on Individual Images","5f8fed06":"**Task:** Calculate the average precision for the model as a whole. Print this out. Then calculate the f-score for the model as a whole. ","4f55dce4":"# Define the Neural Network using Keras","83551792":"# Explore the Data","6382a574":"### Create a small dataset (for illustration)","254da33f":"First Hidden Layer = 32x32x3x128","7f55eab4":"> **Task:** Write a for loop where you print out the actual value and the predicted value for the first 10 images in the valuation dataset. ","033e1eca":"# Tensorboard (visualising learning)","5d825ae0":"### Create Validation Dataset","aa375e3d":"**Challenge:** Write a for loop to display the first 10 images from the ```x_train_all``` array in a row. Show the name of the label below the picture. Remove the ugly tick marks. *Hint* use matplotlib. ","68aff9e2":"\n\n```\n```\n\n# Preprocess Data","a0327614":"# Imports","cf5f11d7":"**Challenge:** Create a third model, ```model_3``` that has two dropout layers. The second dropout layer should be added after the first hidden layer and have a dropout rate of 25%. ","00faa917":"# Constants","19af0c24":"**Challenge:** Create two numpy arrays ```x_train``` and ```y_train``` that have the shape (40000, 3072) and (40000, 1) respectively. They need to contain the last 40000 values from ```x_train_all``` and ```y_train_all``` respectively. ","aab42a16":"### Confusion Matrix","c87a0ea3":"# Get the Data","9e01b989":"# Evaluation","a547142a":"# Fit the Model"}}