{"cell_type":{"543e6d93":"code","9a746d70":"code","23805565":"code","9d66b423":"code","56d02fec":"code","cdbd9c91":"code","b0290142":"code","80d78e2e":"code","e3e4a1e2":"code","7835dbab":"code","2329cafb":"code","620482cb":"code","a1074736":"code","a410bf39":"code","038202ff":"code","26cac905":"code","3c2468cb":"code","b96ebfec":"markdown","c45704e0":"markdown","e0c68f77":"markdown","d8fa6f90":"markdown","3dd37c61":"markdown","2942740a":"markdown","1db6dc2c":"markdown","a17aacdc":"markdown","947b7663":"markdown","e05013b0":"markdown","b7a4647c":"markdown","9f8abd2a":"markdown","67d44271":"markdown","66519f5d":"markdown","a7afbec9":"markdown"},"source":{"543e6d93":"#The below code is included to make the plots expandable.\n%matplotlib notebook\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random","9a746d70":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/pcaploty\/pca_plotter.py\", dst = \"..\/working\/pca_plotter.py\")\n\n# import all our functions\nfrom pca_plotter import PCAPlotter","23805565":"#The image data is taken , normalized and splitted into train and validation sets of 128*128 resolution images.\ntrain_datagen=ImageDataGenerator(rescale=1\/255.,validation_split=0.1)\ntrain_set=train_datagen.flow_from_directory(\"..\/input\/age-prediction\/20-50\/20-50\/train\",target_size=(128,128),shuffle=True,batch_size=2048,class_mode='categorical',subset='training')\nvalidation_set=train_datagen.flow_from_directory(\"..\/input\/age-prediction\/20-50\/20-50\/train\",target_size=(128,128),batch_size=4000,class_mode='categorical',subset='validation')","9d66b423":"def plot_triplets(examples,example_labels):\n    plt.figure(figsize=(10, 3))\n    for i in range(3):\n        plt.subplot(1, 4, 1 + i)\n        plt.imshow(np.reshape(examples[i], (128,128,3)))\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(example_labels[i])\n    plt.show()","56d02fec":"#The train_set shape is(batchs,2(i.e [image data,labels]),2048,128*128 for image data (or) 1 for labels)\nplot_triplets([train_set[0][0][1], train_set[1][0][0], train_set[2][0][4]],[20+np.argmax(train_set[0][1][1]),20+np.argmax(train_set[1][1][0]),20+np.argmax(train_set[2][1][4])])","cdbd9c91":"# b_c = total_number_of_batches-1 i.e 30103\/\/2048\ndef create_batch(batch_size=256,b_c=14):\n    #arrays for triplet images is created\n    x_anchors = np.zeros((batch_size*b_c, 128,128,3))\n    x_positives = np.zeros((batch_size*b_c, 128,128,3))\n    x_negatives = np.zeros((batch_size*b_c, 128,128,3))\n    #arrays for respective labels.\n    y_ind_pos = []\n    y_ind_neg = []\n    \n    #the j for loop goes over batches\n    for j in range(1,b_c+1):\n        #the i for loop goes over the batch images\n        for i in range(0, batch_size):\n            # We need to find an anchor, a positive example and a negative example\n            random_index = random.randint(0, 2048 - 1) #a random index is generated.\n            x_anchor = train_set[j-1][0][random_index]\n            y = np.argmax(train_set[j-1][1][random_index],axis=-1) #np.argmax is used as the labels are one-hot encodings i.e 2 = [0 0 1 0 0] for 5 category set.\n            \n            indices_for_pos = np.squeeze(np.where(np.argmax(train_set[j-1][1],axis=-1) == y)) #Only the index of images that contains the same label as anchor is chosen.\n            indices_for_neg = np.squeeze(np.where(np.argmax(train_set[j-1][1],axis=-1) != y)) #The index of images that contains the label other than that of anchor is chosen.\n            \n            x_positive = train_set[j-1][0][indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]]\n            x_negative_ind =random.randint(0, len(indices_for_neg) - 1)\n            x_negative = train_set[j-1][0][indices_for_neg[x_negative_ind]]\n\n            x_anchors[i*j] = x_anchor\n            x_positives[i*j] = x_positive\n            x_negatives[i*j] = x_negative\n            #20 is added just for our reference as we are dealing with people between 20 and 50 ages.\n            y_ind_pos.append(20+y)\n            y_ind_neg.append(20+np.argmax(train_set[j-1][1][x_negative_ind],axis=-1))\n        \n    return [x_anchors, x_positives, x_negatives],[y_ind_pos[0],y_ind_pos[0],y_ind_neg[0]]","b0290142":"examples = create_batch(1,1)\n#example[0] contains the image data and example[1] contains the labels for the respective images.\nprint(examples[0],examples[1])","80d78e2e":"plot_triplets(examples[0],examples[1])","e3e4a1e2":"#A tensorflow model that returns an embeddiing of size 64 is created.\nemb_size = 64\nembedding_model = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(128,128,3)),\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.Dense(emb_size, activation='sigmoid')\n])\n\nembedding_model.summary()","7835dbab":"example = np.expand_dims(train_set[0][0][1], axis=0)\nexample_emb = embedding_model.predict(example)\n#Prints the embedding of an image from train_set\nprint(example_emb)","2329cafb":"#input layers for respective elements in the triplet.\ninput_anchor = tf.keras.layers.Input(shape=(128,128,3))\ninput_positive = tf.keras.layers.Input(shape=(128,128,3))\ninput_negative = tf.keras.layers.Input(shape=(128,128,3))\n#An embedding layer is created as above.\nembedding_anchor = embedding_model(input_anchor)\nembedding_positive = embedding_model(input_positive)\nembedding_negative = embedding_model(input_negative)\n#Concatenating the embeddings obtained from above.\noutput = tf.keras.layers.concatenate([embedding_anchor, embedding_positive, embedding_negative], axis=1)\n\nnet = tf.keras.models.Model([input_anchor, input_positive, input_negative], output)\nnet.summary()","620482cb":"alpha = 0.2 #This value is not mandatory to change.\n\ndef triplet_loss(y_true, y_pred):\n    anchor, positive, negative = y_pred[:,:emb_size], y_pred[:,emb_size:2*emb_size], y_pred[:,2*emb_size:]\n    positive_dist = tf.reduce_mean(tf.square(anchor - positive), axis=1)\n    negative_dist = tf.reduce_mean(tf.square(anchor - negative), axis=1)\n    #After calculating the mean squared error , loss is calculated.\n    return tf.maximum(positive_dist - negative_dist + alpha, 0.) ","a1074736":"def data_generator(batch_size=256):\n    while True:\n        x,_= create_batch(batch_size)\n        y = np.zeros((batch_size, 3*emb_size)) #As the model does not need the labels for training although the framework does need it to be mentioned, sparse array is sent.\n        yield x, y","a410bf39":"#It will take some time for training as triplets are formed only before training for each epoch.\nbatch_size = 4\nepochs = 16\n\nnet.compile(loss=triplet_loss, optimizer=tf.keras.optimizers.Adam(\n    learning_rate=0.002))\n\n_ = net.fit(\n    data_generator(batch_size),\n    steps_per_epoch=1,\n    epochs=epochs, verbose=1,\n    callbacks=[\n        #PCAPlot is used to plot the embeddings and loss for each epoch of both train_set and validation_set using pca.\n        PCAPlotter(\n            plt, embedding_model,\n            train_set[0][0], np.argmax(train_set[0][1],axis=-1)),\n        PCAPlotter(\n            plt, embedding_model,\n            validation_set[0][0], np.argmax(validation_set[0][1],axis=-1)\n        )]\n)","038202ff":"#I have included two weights after training it along this notbook and used the best one below.\nnet.load_weights(\"..\/input\/agebasedfacecategorizer\/saved_final_weights.h5\")","26cac905":"from sklearn.decomposition import PCA\nimport seaborn as sns\nimport pandas as pd","3c2468cb":"pred=[]\nplt.figure(figsize=(8,4))\nfor j in range(14):\n    p=embedding_model.predict(train_set[j][0])\n    pca_out=PCA(n_components=2).fit_transform(p)\n    pred.append(pca_out)\n\npred=np.concatenate(np.array(pred),axis=0)\npca_df= pd.DataFrame(pred,columns=['pca1','pca2'])\npca_cat = pd.concat([pca_df,pd.DataFrame({\"Labels\":np.argmax(train_set[j][1],axis=-1)})],axis=1)\ncmap=sns.cubehelix_palette(n_colors=31,dark=.4, light=.8,as_cmap=True)\nax=sns.scatterplot(x='pca1',y='pca2',hue=\"Labels\",data= pca_cat,palette=\"Set2\",size=\"Labels\",sizes=(20, 200))\nplt.show()","b96ebfec":"# Importing and Visualizing the Data","c45704e0":"The above explained method is just a try against the End-to-End CNN approach. \nThis approach can be used in case of less training examples where it will overperform the traditional approach.\nHowever here it performed quite well despite this noisy dataset.\nThank You!","e0c68f77":"# Siamese Network\nThis is where the real magic happens.","d8fa6f90":"# Importing the required Modules","3dd37c61":"# Visualization using PCA","2942740a":"# Model Training and Evaluation using PCA ","1db6dc2c":"For visualization of training loss and pca plot, refer to previous versions (1,2,3,4) of this notebook.","a17aacdc":"# Triplet Loss Function","947b7663":"# Data Generator","e05013b0":"# Creating a Batch of Triplets\nTriplets = Anchor(original) , Positive(similar as anchor) , Negative(other than anchor)","b7a4647c":"Credits : Pcaploty is taken from coursera's project network and a minor change done by me.","9f8abd2a":"# Embedding Neural Network","67d44271":"## Function for plotting the triplet image data. We will see it later.","66519f5d":"You can clearly see that the first two images(anchor and positive) are from same age and the third(negative) is from different age chosen randomly. ","a7afbec9":"The below code block is only for kaggle users."}}