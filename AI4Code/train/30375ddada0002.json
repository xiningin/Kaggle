{"cell_type":{"a9104184":"code","085c9b3a":"code","5ab32255":"code","f8cccab9":"code","803dbe9b":"code","c9098865":"code","3d5aff9a":"code","5bddf5df":"code","dac17e7b":"code","851fe786":"code","6a5036a4":"code","43756e6b":"code","79608b3d":"code","42644a5c":"code","095737e6":"code","e5d9a11c":"code","035ce9ba":"code","b425c0dd":"code","c5a17b48":"code","a0db7cd8":"code","925e37bb":"code","d2db9f64":"code","eb673105":"code","826f0b63":"code","dfee8cee":"code","529e5d41":"code","26583231":"code","c4dbf68c":"code","e8542b47":"code","e8e5ef9c":"code","e4e60057":"markdown","25835d98":"markdown","37ccd135":"markdown","99297cad":"markdown","48effea3":"markdown","baccd8a2":"markdown","d3a619e1":"markdown","187ade41":"markdown","1a64ef81":"markdown","90f1e8fc":"markdown","bbcf9401":"markdown","80d4e71b":"markdown","a18e8f1a":"markdown","63e4a657":"markdown","7b6df648":"markdown","afe8f932":"markdown","a611e9ca":"markdown","d933336f":"markdown","d6ffe3d6":"markdown","bb7c1c17":"markdown","695653f2":"markdown","01f3d0e0":"markdown","db37bd77":"markdown","b47a1f20":"markdown","cea00f5a":"markdown","bd53937b":"markdown","ef06a985":"markdown"},"source":{"a9104184":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\n\n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd \n\n# scipy clusturing\nfrom scipy.cluster.hierarchy import linkage, fcluster,dendrogram \n\n# data preproc\nfrom sklearn import preprocessing \nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# data visualization\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport plotly.express as px\n\nfrom matplotlib.colors import ListedColormap\n\nfrom matplotlib.collections import LineCollection\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","085c9b3a":"def display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n    for d1, d2 in axis_ranks: # On affiche les 3 premiers plans factoriels, donc les 6 premi\u00e8res composantes\n        if d2 < n_comp:\n\n            # initialisation de la figure\n            fig, ax = plt.subplots(figsize=(7,6))\n\n            # d\u00e9termination des limites du graphique\n            if lims is not None :\n                xmin, xmax, ymin, ymax = lims\n            elif pcs.shape[1] < 30 :\n                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n            else :\n                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])\n\n            # affichage des fl\u00e8ches\n            # s'il y a plus de 30 fl\u00e8ches, on n'affiche pas le triangle \u00e0 leur extr\u00e9mit\u00e9\n            if pcs.shape[1] < 30 :\n                plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),\n                   pcs[d1,:], pcs[d2,:], \n                   angles='xy', scale_units='xy', scale=1, color=\"grey\")\n                # (voir la doc : https:\/\/matplotlib.org\/api\/_as_gen\/matplotlib.pyplot.quiver.html)\n            else:\n                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]\n                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))\n            \n            # affichage des noms des variables  \n            if labels is not None:  \n                for i,(x, y) in enumerate(pcs[[d1,d2]].T):\n                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :\n                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n            \n            # affichage du cercle\n            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n            plt.gca().add_artist(circle)\n\n            # d\u00e9finition des limites du graphique\n            plt.xlim(xmin, xmax)\n            plt.ylim(ymin, ymax)\n        \n            # affichage des lignes horizontales et verticales\n            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n\n            # nom des axes, avec le pourcentage d'inertie expliqu\u00e9\n            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n\n            plt.title(\"Cercle des corr\u00e9lations (F{} et F{})\".format(d1+1, d2+1))\n            plt.show(block=False)\n        \ndef display_factorial_planes(X_projected, n_comp, pca, axis_ranks, labels=None, alpha=1, illustrative_var=None):\n    for d1,d2 in axis_ranks:\n        if d2 < n_comp:\n \n            # initialisation de la figure       \n            fig = plt.figure(figsize=(7,6))\n        \n            # affichage des points\n            if illustrative_var is None:\n                plt.scatter(X_projected[:, d1], X_projected[:, d2], alpha=alpha)\n            else:\n                illustrative_var = np.array(illustrative_var)\n                for value in np.unique(illustrative_var):\n                    selected = np.where(illustrative_var == value)\n                    plt.scatter(X_projected[selected, d1], X_projected[selected, d2], alpha=alpha, label=value)\n                plt.legend()\n\n            # affichage des labels des points\n            if labels is not None:\n                for i,(x,y) in enumerate(X_projected[:,[d1,d2]]):\n                    plt.text(x, y, labels[i],\n                              fontsize='14', ha='center',va='center') \n                \n            # d\u00e9termination des limites du graphique\n            boundary = np.max(np.abs(X_projected[:, [d1,d2]])) * 1.1\n            plt.xlim([-boundary,boundary])\n            plt.ylim([-boundary,boundary])\n        \n            # affichage des lignes horizontales et verticales\n            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n\n            # nom des axes, avec le pourcentage d'inertie expliqu\u00e9\n            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n\n            plt.title(\"Projection des individus (sur F{} et F{})\".format(d1+1, d2+1))\n            plt.show(block=False)\n\ndef display_scree_plot(pca):\n    scree = pca.explained_variance_ratio_*100\n    plt.bar(np.arange(len(scree))+1, scree)\n    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n    plt.xlabel(\"rang de l'axe d'inertie\")\n    plt.ylabel(\"pourcentage d'inertie\")\n    plt.title(\"Eboulis des valeurs propres\")\n    plt.show(block=False)\n\ndef plot_dendrogram(Z, names):\n    plt.figure(figsize=(10,25))\n    plt.title('Hierarchical Clustering Dendrogram')\n    plt.xlabel('distance')\n    dendrogram(\n        Z,\n        labels = names,\n        orientation = \"left\",\n    )\n    plt.savefig('Dendrogram.png')\n    plt.show()","5ab32255":"# load cleaned data\ndata = pd.read_csv('..\/input\/cleandata\/golden_source.csv', sep=',', error_bad_lines=False, low_memory=False)\ndata.head(3)","f8cccab9":"data = data.fillna(0)","803dbe9b":"data.set_index('product_name',inplace=True)","c9098865":"quant_features = [\n'energy_100g',\n'saturated-fat_100g',\n'trans-fat_100g',\n'cholesterol_100g',\n'carbohydrates_100g',\n'sugars_100g',\n'fiber_100g',\n'proteins_100g',\n'salt_100g',\n'sodium_100g',\n'vitamin-a_100g',\n'vitamin-c_100g',\n'calcium_100g',\n'nutrition-score-fr_100g'\n]\n\nfeatures = ['additives_n',\n'ingredients_from_palm_oil_n',\n'ingredients_that_may_be_from_palm_oil_n',\n'energy_100g',\n'fat_100g',\n'saturated-fat_100g',\n'trans-fat_100g',\n'cholesterol_100g',\n'carbohydrates_100g',\n'sugars_100g',\n'fiber_100g',\n'proteins_100g',\n'salt_100g',\n'sodium_100g',\n'vitamin-a_100g',\n'vitamin-c_100g',\n'calcium_100g',\n'iron_100g',\n'nutrition-score-fr_100g',\n'nutrition-score-uk_100g'\n]\n\n\ndegrees = 90\n\nfig = plt.figure(figsize=(17, 12))\nax = plt.axes()\nplt.xticks(rotation=degrees)\n\nsns.boxplot(data=data[quant_features]).set_title('features boxplot');","3d5aff9a":"from pandas.plotting import scatter_matrix\nscatter_matrix(data[quant_features],figsize=(25,25));","5bddf5df":"fig, ax = plt.subplots(figsize=(20,20))  \nsns.heatmap(data[quant_features].corr(),annot = False,square=True);","dac17e7b":"# Separating out the features\ndata.replace([np.inf, -np.inf], 0, inplace=True)\nx = data[features].values\n\n# Separating out the target\ny = data['nutrition-score-fr_100g'].values\nhue = pd.DataFrame(y)\n\nscaler = StandardScaler()\nscaler.fit(x)\nX_scaled = scaler.transform(x)\nX_scaled = np.nan_to_num(X_scaled, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n\npca = PCA(n_components=10)\npca.fit(X_scaled)\n\nX_pca = pca.transform(X_scaled)","851fe786":"plt.matshow(pca.components_,cmap='viridis');\nplt.yticks([0,1,2,3,4,5,6,7,8,9], ['1st component', '2nd component','3rd component','4th component', '5th component','6th component','7th component','8th component','9th component','10th component']);\nplt.colorbar();\nplt.xticks(range(len(features)),features, rotation = 90, fontsize=14, ha = 'left');\nplt.xlabel('Feature');\nplt.ylabel('Principal component');","6a5036a4":"exp_var_cumul = np.cumsum(pca.explained_variance_ratio_)\n\npx.area(\n    x=range(1, exp_var_cumul.shape[0] + 1),\n    y=exp_var_cumul,\n    labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}\n)\n","43756e6b":"exp_var_pca = pca.explained_variance_ratio_\n\ncum_sum_eigenvalues = np.cumsum(exp_var_pca)\n#\n#\n# Create the visualization plot\n#\nfig = plt.figure(figsize=(10,10))\nplt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\nplt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\nplt.ylabel('Explained variance ratio')\nplt.xlabel('Principal component index')\nplt.show()","79608b3d":"x = X_pca[:,0]\ny = X_pca[:,1]\nz = X_pca[:,2]\n%matplotlib widget\nplt.rcParams[\"figure.figsize\"] = [15, 25]\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig = plt.figure()\n\ncmap = ListedColormap(sns.color_palette(\"husl\", 256).as_hex())\nax = fig.gca(projection='3d')\nsc = ax.scatter(x, y, z, s=40, c=x, marker='o', cmap=cmap, alpha=1)\nax.set_xlabel(\"PC1\")\nax.set_ylabel(\"PC2\")\nax.set_zlabel(\"PC3\")\n\nplt.legend();\n\nplt.show()","42644a5c":"x = X_pca[:,7]\ny = X_pca[:,8]\nz = X_pca[:,9]\n\n%matplotlib widget\nplt.rcParams[\"figure.figsize\"] = [15, 25]\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig = plt.figure()\n\ncmap = ListedColormap(sns.color_palette(\"husl\", 256).as_hex())\nax = fig.gca(projection='3d')\nsc = ax.scatter(x, y, z, s=40, c=x, marker='o', cmap=cmap, alpha=1)\nax.set_xlabel(\"PC1\")\nax.set_ylabel(\"PC2\")\nax.set_zlabel(\"PC3\")\n\nplt.legend();\n\nplt.show()","095737e6":"sample = data[quant_features].sample(n = 1000)\n\n# pr\u00e9paration des donn\u00e9es pour le clustering\nX = sample.values\nnames = sample.index\n\n# Centrage et R\u00e9duction\nstd_scale = preprocessing.StandardScaler().fit(X)\nX_scaled = std_scale.transform(X)\n\n# Clustering hi\u00e9rarchique\nZ = linkage(X_scaled, 'ward')\n\n# Affichage du dendrogramme\nplot_dendrogram(Z, names);\n","e5d9a11c":"clusters = fcluster(Z,t=40,criterion='distance')\n\nidg = np.argsort(clusters)\n\n#affichage des observations et leurs groupes\nclusters = pd.DataFrame(sample.index[idg],clusters[idg])\nclusters.to_csv('PCA_clusters.csv',sep=',', index = True)","035ce9ba":"#k-means sur les donn\u00e9es centr\u00e9es et r\u00e9duites\nfrom sklearn import cluster\nkmeans = cluster.KMeans(n_clusters=5)\nkmeans.fit(sample)\n\n#index tri\u00e9s des groupes\nidk = np.argsort(kmeans.labels_)\n\n#affichage des observations et leurs groupes\ngroups = pd.DataFrame(sample.index[idk],kmeans.labels_[idk])\ngroups.to_csv('Kmeans_clusters.csv',sep=',', index = True)\n","b425c0dd":"#correspondance avec les groupes de la CAH\npd.crosstab(clusters.index,kmeans.labels_)","c5a17b48":"#librairie pour \u00e9valuation des partitions\nfrom sklearn import metrics\n\n#utilisation de la m\u00e9trique \"silhouette\"\n#faire varier le nombre de clusters de 2 \u00e0 10\nres = np.arange(9,dtype=\"double\")\nfor k in np.arange(9):\n    km = cluster.KMeans(n_clusters=k+2)\n    km.fit(sample)\n    res[k] = metrics.silhouette_score(sample,km.labels_)\n    #print(res)\n    \n#graphique\nfig = plt.figure(figsize=(10,5))\nplt.title(\"Silhouette\")\nplt.xlabel(\"# of clusters\")\nplt.plot(np.arange(2,11,1),res)\nplt.show()","a0db7cd8":"#moyenne par variable\nm = sample.mean()\n\n#TSS\nTSS = sample.shape[0]*sample.var(ddof=0)\nprint(TSS)","925e37bb":"#data.frame conditionnellement aux groupes\ngb = sample.groupby(kmeans.labels_)\n\n#effectifs conditionnels\nnk = gb.size()\nprint(nk)","d2db9f64":"#moyennes conditionnelles\nmk = gb.mean()\n\n# print(mk)\nmk_no_energy = mk.drop(\"energy_100g\",axis=1)\nmk.plot.bar(y=mk_no_energy.columns,figsize=(15,10))","eb673105":"# print(mk)\nmk.plot.bar(y=mk.columns,figsize=(15,10))","826f0b63":"#pour chaque groupe \u00e9cart \u00e0 la moyenne par variable\nEMk = (mk-m)**2\n\n#pond\u00e9r\u00e9 par les effectifs du groupe\nEM = EMk.multiply(nk,axis=0)\n\n#somme des valeurs => BSS\nBSS = np.sum(EM,axis=0)\nprint(BSS)","dfee8cee":"BSS_ = BSS[1:]\nBSS_","529e5d41":"BSS_.plot.bar(x = BSS_.index,y = BSS_, figsize=(5, 5))","26583231":"#carr\u00e9 du rapport de corr\u00e9lation\n#variance expliqu\u00e9e par l'appartenance aux groupes\n#pour chaque variable\n\nR2 = BSS\/TSS\nprint(R2)","c4dbf68c":"R2.plot.bar(x = R2.index,y = R2, figsize=(5, 5))","e8542b47":"acp = PCA(n_components=3).fit_transform(sample)\n\n# projeter dans le plan factoriel\n# avec un code couleur diff\u00e9rent selon le groupe\n\n\nfig = plt.figure(figsize=(10,10))\nfor couleur,k in zip(['red','blue','lawngreen','aqua','black','yellow','brown'],[0,1,2,3,4,5,6]):    \n    plt.scatter(acp[kmeans.labels_==k,0],acp[kmeans.labels_==k,1],c=couleur)\n\nplt.show() ","e8e5ef9c":"fig = plt.figure(figsize=(10,10))\nfor couleur,k in zip(['red','blue','lawngreen','aqua','black','yellow','brown'],[0,1,2,3,4,5,6]):    \n    plt.scatter(acp[kmeans.labels_==k,1],acp[kmeans.labels_==k,2],c=couleur)","e4e60057":"### Partie 2 : Analyse univari\u00e9e","25835d98":"Import des donn\u00e9es \u00e0 l'aide du package pandas.","37ccd135":"Cette partie d\u00e9fini une m\u00e9thode graphique custom pour visualizer un dendogramme","99297cad":"### Partie 7 : Id\u00e9e d'application","48effea3":"### Partie 8 : Conclusion","baccd8a2":"Pour conclure, FeedMe poss\u00e8de un MVP qui permet de plannifer un r\u00e9gime selon les besoins des utilisateurs. Une extension possible serait de cr\u00e9er un module qui proposerait des activit\u00e9s physiques pour accompagner le r\u00e9gime.","d3a619e1":"**Plan**\n\n0. Id\u00e9e d'application\n1. Mise en place\n2. Rappel de l'analyse univari\u00e9e P3 01\n3. Analyse multivari\u00e9e\n4. ACP\n5. HCPC\n6. KNN\n7. MVP et utilisation des r\u00e9sultats\n8. Conclusion\n","187ade41":"Dans cette partie, nous reprenons quelques \u00e9l\u00e9ments d'analyse univari\u00e9e men\u00e9e sur les variables quantitatives de notre dataset. Il s'agit dans un premier temps d'un graphique boite \u00e0 moustache qui nous permet d'avoir une id\u00e9e g\u00e9n\u00e9rale sur la distribution de chaque variable.","1a64ef81":"Nous remarquons ainsi la pr\u00e9sence de corr\u00e9lations entre les features ( exemple : sugars_100g vs carbohydrates_100G entre autres ). \nCeci sugg\u00e8re donc la n\u00e9cessit\u00e9 d'une analyse par composantes principales afin de projetter notre dataset sur les bons axes.","90f1e8fc":"\n![image.png](attachment:269cd956-3bdb-4376-a65a-1d615bd1a49c.png)","bbcf9401":"Dans cette partie, nous proc\u00e9dons \u00e0 une autre m\u00e9thode de clustering qui est le K-means.","80d4e71b":"il semble d'apr\u00e8s le graphique pr\u00e9c\u00e9dent que le nombre optimal de clusters se situe autour de 5.","a18e8f1a":"### Partie 5 : K-Means","63e4a657":"La premi\u00e8re composante caract\u00e9rise les individus ayant des projections positives sur 'energy_100g' et 'nutrition-score-fr_100g', mais aussi port\u00e9 par les variables ( saturated-fat_100g et proteins ). Cet axe permet donc de selectionner des ingr\u00e9dients destin\u00e9s \u00e0 un r\u00e9gime g\u00e9n\u00e9rique de perte de poids et d'amelioration de la qualit\u00e9 de la nutrition.\n\nLe deuxi\u00e8me axe quand \u00e0 lui caract\u00e9rise les ingr\u00e9dients ayant un surplus de sel ou sodium, donc \u00e0 \u00e9viter.\n\nLe troisi\u00e8me axe concerne les variables proteins_100g et saturated-fat_100g, ainsi que energy_100g et nutrition-score-fr_100g. Il s'agit clairement d'un axe pour selectionner des ingr\u00e9dients pour des profils athl\u00e8tes sportifs ou pour des r\u00e9gimes prot\u00e9in\u00e9s pour une perte de poids, ou pour une prise de muscle.\n\nLe quatri\u00e8me axe caract\u00e9rise les aliments riches en fibre, id\u00e9aux pour des programmes de prise de masse musculaire.\n\nLe 5\u00e8me axe concerne les aliments riches en vitamine A et en Calcium, pour des personnes souhaitant renforcer leur ossature, ou d\u00e9sireux de r\u00e9cup\u00e9rer d'une blessure osseuse ou fracture.\n\nLe 6\u00e8me axe est destin\u00e9 aux aliments riches en vitamines C, donc pour les personnes d\u00e9sireuses d'un boost instantann\u00e9 en energie non grasse, le 7\u00e8me avec mati\u00e8re grasse transform\u00e9e.","7b6df648":"### Partie 1 : L'environnement\nInstallation de packages utiles \u00e0 l'aquisition de la donn\u00e9e ainsi que les diff\u00e9rents traitements statistiques et visualisation.\n","afe8f932":"On s'attend \u00e0 une matrice un peu plus diagonale si nos clusters sont \"homog\u00e8nes\", mais ce n'est pas le cas. Nous allons donc exploiter la PCA avec le clustering hierarchique HCPC.","a611e9ca":"FeedMe se basera donc sur les axes de la PCA. Le r\u00e9gime choisi par l'utilisateur sera expliqu\u00e9 par un ou plusieurs axes. Le back-end de FeedMe selectionnera donc les ingr\u00e9dients qui ont une contribution positive \u00e0 l'axe ou aux axes principaux. Ensuite un KNN sera utilis\u00e9 sur les individus pr\u00e9c\u00e9dents afin des les partitionner en clusters, et ainsi l'IA de FeedMe pourra composer une recette \u00e0 partir de ces clusters. Une note pr\u00e9visionnelle est calcul\u00e9e pour chaque recette g\u00e9n\u00e9r\u00e9e pour le calendrier, et l'IA recevra les ratings de l'utilisateur afin d'affiner le m\u00e9lange des ingr\u00e9dients. Il s'agit d'un probl\u00e8me d'optimisation classique sous contrainte ( l'objectif est de minimiser l'erreur de composition de la recette sous des crit\u00e8res de calories quotidiennes maximales \u00e0 ne pas d\u00e9passer ), l'IA de FeedMe pourra explorer l'espace des solutions et trouver un minimum par gradient descendant boost\u00e9.","d933336f":"### Partie 4 : HCPC","d6ffe3d6":"### P3 02 : Concevez une application au service de la sant\u00e9 publique\n**Motivation et objectifs**\n\nL'agence \"Sant\u00e9 publique France\" a lanc\u00e9 un appel \u00e0 projets pour trouver des id\u00e9es innovantes d\u2019applications en lien avec l'alimentation.\n\nPour cel\u00e0, Le jeu de donn\u00e9es Open Food Fact est disponible sur le site officiel. Les variables sont d\u00e9finies \u00e0 cette adresse https:\/\/world.openfoodfacts.org\/data\/data-fields.txt.\n\nL'objectif de ce notebook est de :\n\n1. Pr\u00e9senter l'application FeedMe\n2. Effectuer une analyse univari\u00e9e pour chaque variable int\u00e9ressante, afin de synth\u00e9tiser son comportement.\n3. Confirmer ou infirmer les hypoth\u00e8ses  \u00e0 l\u2019aide d\u2019une analyse multivari\u00e9e. Effectuer les tests statistiques appropri\u00e9s pour v\u00e9rifier la significativit\u00e9 des r\u00e9sultats\n4. \u00c9laborer une id\u00e9e d\u2019application. Identifier des arguments justifiant la faisabilit\u00e9 (ou non) de l\u2019application \u00e0 partir des donn\u00e9es Open Food Facts\n","bb7c1c17":"\nCi dessous une visualisation partielle des clusters tir\u00e9s de la PCA (disponible en output du notebook) : \n\n\n![image.png](attachment:3e1319a2-f41d-41f3-b6e7-651d2f425788.png)\n","695653f2":"L\u2019id\u00e9e est de comparer les moyennes des variables actives conditionnellement aux groupes. Il\nest possible de quantifier globalement l\u2019amplitude des \u00e9carts avec la proportion de variance\nexpliqu\u00e9e (carr\u00e9 du rapport de corr\u00e9lation). La d\u00e9marche peut \u00eatre \u00e9tendue aux variables\nillustratives. Pour les cat\u00e9gorielles, nous confronterions les distributions conditionnelles.\nL\u2019approche est simple et les r\u00e9sultats faciles \u00e0 lire. Rappelons cependant que nous ne tenons\npas compte des liaisons entre les variables dans ce cas.\n","01f3d0e0":"Nous nous int\u00e9ressons dans cette section \u00e0 la recherche de relations de corr\u00e9lation lin\u00e9aires possibles entre nos variables quantitatives. En effet, si nos variables sont correl\u00e9es, les analyses tir\u00e9es ne couvriront pas l'ensemble de la variabilit\u00e9 disponible dans le dataset (i.e on n'expliquera qu'une partie de la variance totale du nuage de points ). Si tel est le cas, nous aurons besoin d'un proc\u00e9d\u00e9 qui permet de d\u00e9correler les variables explicatives et de projetter le nuage d'ingr\u00e9dients sur les axes d\u00e9correl\u00e9s.","db37bd77":"### Partie 3 : Analyse multivari\u00e9e","b47a1f20":"Nous remarquons quelques relations \u00e9videntes telles que la corr\u00e9lation lin\u00e9aire quasi parfaite entre sodium et salt, et un semblant de relation positive entre les variables energy_100g et nutrition-score-fr_100g.\n\nMaintenant nous pr\u00e9sentons le graphique heatmap des corr\u00e9lations lin\u00e9aires entre nos variables :","cea00f5a":"Dans cette partie nous souhaitons proc\u00e9der \u00e0 un clustering hierarchique afin d'en d\u00e9river des clusters d'ingr\u00e9dients.","bd53937b":"### Partie 0 : Id\u00e9e d'application\n\nPour r\u00e9pondre au challenge \"sant\u00e9 publique france\", nous proposons une application de gestion des repas selon le profil de la personne ainsi que ses objectifs. \n\nL'application aura pour but donc d'exploiter un maximum de donn\u00e9es disponibles afin de g\u00e9n\u00e9rer des programmes de di\u00e8te et proposer ainsi une alimentation en ligne avec les r\u00e9sultats esp\u00e9r\u00e9s par l'utilisateur de 'FeedMe' ( nom de l'application ).\n\nL'utilisateur de FeedMe aura l'opportunit\u00e9 de cr\u00e9er son user profile en important son profil Facebook, et aura donc \u00e0 d\u00e9finir son profil alimentaire ( r\u00e9gime souhait\u00e9 ou objectif \u00e0 atteindre ) ainsi qu'un profil sportif ( nombre de s\u00e9ances d'exercice par semaine, habitudes sportives ). Ce questionnaire permettra \u00e0 FeedMe de calculer une moyenne de calories quotidiennes n\u00e9cessaires \u00e0 l'utilisateur et en d\u00e9rivera une recette ad\u00e9quate. Cette derni\u00e8re recevra une note de l'utilisateur et servira \u00e0 entra\u00eener une IA ( re-inforcement learning ) afin d'am\u00e9liorer le contenu des recettes et le rapprocher des envies du user tout en conservant les bonnes propri\u00e9t\u00e9s n\u00e9cessaires. Cette IA ne proposera jamais le m\u00eame plat pendant le m\u00eame mois, afin d'\u00e9viter toute routine pouvant entra\u00eener un d\u00e9couragement.","ef06a985":"### Partie 4 : ACP"}}