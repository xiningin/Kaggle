{"cell_type":{"95a44e2e":"code","efed037f":"code","ade17d0f":"code","c11759f4":"code","8e8cfc30":"code","813bbe30":"code","56fc06aa":"code","d04b9580":"code","bb687d91":"code","360538af":"code","103f2a1e":"code","4035acb6":"code","7860c512":"code","031339d0":"code","633c5450":"code","11923e49":"markdown","65e451af":"markdown","da16e1e5":"markdown","ef0e8b6a":"markdown","629060ce":"markdown","fd1564e6":"markdown","c3e7da8a":"markdown","351b31e8":"markdown"},"source":{"95a44e2e":"import numpy as np\nimport pandas as pd \nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport keras_tuner as kt\nimport tensorflow as tf\nimport gc","efed037f":"class Config:\n    validation_split = 0.15\n    dataset_name = \"tabular-playground-series-nov-2021\"\n    train_path = \"\/kaggle\/input\/%s\/train.csv\"%(dataset_name)\n    test_path = \"\/kaggle\/input\/%s\/test.csv\"%(dataset_name)\n    sample_submission_path = \"\/kaggle\/input\/%s\/sample_submission.csv\"%(dataset_name)\n    id_field = \"id\"\n    label_field = \"target\"\n    hyperparameter_tuning_trial = 50\n    epochs = 50\n    train_with_fulldataset = True\n    sample_rate = 0.05\n    model_path = \"model.h5\"\n    submission_path = \"submission.csv\"\n    batch_size = 1024\nconfig = Config()","ade17d0f":"train_features = pd.read_csv(config.train_path)\ntrain_features.head()","c11759f4":"train_features.pop(config.id_field)\ntrain_targets = train_features.pop(config.label_field)","8e8cfc30":"train_max = train_features.max()\ntrain_features = train_features \/ train_max","813bbe30":"X_train, X_val, y_train, y_val = train_test_split(train_features, train_targets, test_size=config.validation_split, random_state=42)","56fc06aa":"X_train.shape, X_val.shape, y_train.shape, y_val.shape","d04b9580":"del train_features\ndel train_targets\ngc.collect()","bb687d91":"train_indices = np.random.choice(X_train.shape[0], int(X_train.shape[0] * config.sample_rate))\nX_train_subset = X_train.iloc[train_indices]\ny_train_subset = y_train.iloc[train_indices]\nval_indices = np.random.choice(X_val.shape[0], int(X_val.shape[0] * config.sample_rate))\nX_val_subset = X_val.iloc[val_indices]\ny_val_subset = y_val.iloc[val_indices]","360538af":"def build_model(hp):\n    inputs = tf.keras.layers.Input((100))\n    x = tf.keras.layers.Reshape((10, 10, 1))(inputs)\n    for i in range(3):\n        x = keras.layers.Conv2D(\n            16 * (2 ** i), \n            3,\n            padding=\"same\"\n        )(x)\n        x = tf.keras.layers.AveragePooling2D(2)(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(hp.Choice(\"dropout\", [0.1, 0.2, 0.3, 0.4, 0.5]))(x)\n    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n    model = keras.Model(inputs=inputs, outputs=output)\n    adam = keras.optimizers.Adam(learning_rate=hp.Float(\"learing_rate\", 1e-5, 5e-3))\n    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"accuracy\", keras.metrics.AUC()])\n    return model","103f2a1e":"tuner = kt.BayesianOptimization(\n    build_model,\n    objective=kt.Objective(\"val_auc\", direction=\"max\"),\n    max_trials=config.hyperparameter_tuning_trial,\n    directory=\"tps_conv2d2\"\n)\ntuner.search(x=X_train_subset, y=y_train_subset, epochs=5, batch_size=config.batch_size, validation_data=(X_val_subset, y_val_subset))\nbest_model = tuner.get_best_models()[0]\nkeras.utils.plot_model(best_model, show_shapes=True)","4035acb6":"# One of best parameters: {'learing_rate': 0.0032666153628411114}\nbest_hp = tuner.get_best_hyperparameters()[0]\nbest_hp.get_config()[\"values\"]","7860c512":"if not config.train_with_fulldataset:\n    model = best_model\nelse:\n    keras.backend.clear_session()\n    model = tuner.hypermodel.build(best_hp)\n    early_stopping = keras.callbacks.EarlyStopping(patience=10)\n    model_checkpoint = keras.callbacks.ModelCheckpoint(config.model_path, save_best_only=True)\n    reduce_lr =  keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=1e-7)\n    history = model.fit(x=X_train, y=y_train, epochs=config.epochs, batch_size=config.batch_size, validation_data=(X_val, y_val), callbacks=[early_stopping, model_checkpoint, reduce_lr])\n    model.load_weights(config.model_path)\n    pd.DataFrame(history.history).plot()","031339d0":"del X_train\ndel y_train\ndel X_val\ndel y_val\ngc.collect()","633c5450":"test = pd.read_csv(config.test_path)\n_ = test.pop(config.id_field)\ntest = test \/ train_max\ny_pred = model.predict(test).reshape(-1)\nprint(y_pred.shape)\nsample_submission = pd.read_csv(config.sample_submission_path)\nsample_submission[config.label_field] = y_pred\nsample_submission.to_csv(config.submission_path, index=False)","11923e49":"## Submission","65e451af":"## Configuration","da16e1e5":"## Model Development","ef0e8b6a":"### Choose a small sample for hyperparameter tuning","629060ce":"## Import and preprocess datasets","fd1564e6":"## TPS-11-21: Conv2D","c3e7da8a":"Here is best parameters:","351b31e8":"## Setup"}}