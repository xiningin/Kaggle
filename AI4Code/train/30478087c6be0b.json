{"cell_type":{"1ed590dd":"code","e571e222":"code","e5d4b089":"code","42ea74c8":"code","5d481722":"code","28a5192d":"code","a5dc5b94":"code","98fc2df0":"code","e60f36c7":"code","d94686f3":"code","fdb6ea5b":"code","039cb1e8":"code","1334a6c6":"code","4a92c63e":"code","c2831189":"code","42a8f91d":"code","4fc2b5b5":"code","2cc39d48":"code","20bc4c12":"markdown","15326210":"markdown","a457c13c":"markdown","57f43b52":"markdown","a66af743":"markdown","15229461":"markdown","cafaf8c6":"markdown","306f398a":"markdown","b2388d63":"markdown","8293762d":"markdown"},"source":{"1ed590dd":"#Import the required libraries\nimport pandas as pd\nimport numpy as np\n#Library used for initial visualization\nimport matplotlib.pyplot as plt \n#Library used for initial visualization\nimport csv \nimport ast\nimport re\n%matplotlib inline","e571e222":"\n#Load the data set\ncredits_csv=pd.read_csv('..\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv')#change file path\nmovies_csv=pd.read_csv('..\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv')#change file path\ndata=pd.merge(credits_csv, movies_csv, left_on='movie_id', right_on='id')\n#To drop columns that have been repeated\ndata=data.drop(['id','title_x'],axis=1) \n#Renaming particular columns\ndata.rename(columns={'title_y':'title'}, inplace=True) \n#Descriptive Statistics on the numberical data\ndata.describe() ","e5d4b089":"#Checking outliers in numberical variables\ndata.boxplot()","42ea74c8":"#Checking for null values\ndata.isnull().sum()","5d481722":"#check the datatype for each of the column in the dataset\ndata.dtypes","28a5192d":"#This cell should be run only once because the values once converted are no longer string type \ndata[\"genres\"]=data[\"genres\"].apply(ast.literal_eval)\ndata[\"spoken_languages\"]=data[\"spoken_languages\"].apply(ast.literal_eval)\ndata[\"cast\"]=data[\"cast\"].apply(ast.literal_eval)\ndata[\"crew\"]=data[\"crew\"].apply(ast.literal_eval)\ndata[\"keywords\"]=data[\"keywords\"].apply(ast.literal_eval)","a5dc5b94":"from nltk.stem import PorterStemmer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\nps = PorterStemmer()","98fc2df0":"from collections import Counter\ndef tf(overview):\n    vector_length=0\n    overview_words=re.sub(\"[^\\w'-]\",\" \", str(overview).lower()).split()\n    stemmed_words=list()\n    for word in overview_words:\n        stemmed_words.append(ps.stem(word))\n    overview_words=Counter(stemmed_words) \n    \n    words_dicts=dict()\n    for word,count in overview_words.items():\n        vector_length+=((1+np.log10(count))**(2))\n    vector_length=vector_length**(0.5)\n    for word,count in overview_words.items():\n        words_dicts.update({ps.stem(word):((1+np.log10(count))\/vector_length)})\n    return words_dicts","e60f36c7":"#pass a list of documents\ndef idf(idf_data): \n    idf_dict=dict()\n    for docs in idf_data:\n        doc_words=re.sub(\"[^\\w'-]\",\" \", str(docs).lower()).split()\n        stemmed_words=list()\n        for word in doc_words:\n            stemmed_words.append(ps.stem(word))\n        \n        doc_words=list(set(stemmed_words))\n        for word in doc_words:\n            if ps.stem(word.lower()) not in idf_dict.keys():\n                idf_dict.setdefault(ps.stem(word.lower()), 1)\n            else:\n                idf_dict[ps.stem(word.lower())]+=1\n    for key,value in idf_dict.items():\n        idf_dict[key]=np.log10(len(idf_data)\/value)\n    return idf_dict\n       ","d94686f3":"actors=list()\n\nfor i in range(0,len(data.index)):\n    actors.append([d['name'].strip() for d in data['cast'][i] if d['order'] == 0 or d['order'] == 1 or d['order'] == 2])\n    \nlabels=['actor1','actor2','actor3','actor4','actor5']\nactors_df=pd.DataFrame.from_records(actors,columns=labels,exclude=['actor4','actor5'])","fdb6ea5b":"#We apply TF-IDF on overview and make a new dataframe with only top 5 important words in each document.\ntfidf_column=[]\nidf_dict=idf(data[\"overview\"])\nfor overview in data[\"overview\"]:        \n    tfidf_dict=tf(overview)\n    for key,value in tfidf_dict.items():\n        tfidf_dict[key]=value*idf_dict[key]\n    tfidf_dict=sorted(tfidf_dict, key=tfidf_dict.get, reverse=True)[:5]\n    tfidf_column.append(tfidf_dict)\nimportantwords_df=pd.DataFrame(tfidf_column,columns=[\"Key1\",\"Key2\",\"Key3\",\"Key4\",\"Key5\"])\nimportantwords_df","039cb1e8":"genre_list=[]\nfor genre in data[\"genres\"]:\n    for d in genre:\n        if d['name'] not in genre_list:\n            genre_list.append(d['name'])\n\nall_movies=[]\nfor genre in data[\"genres\"]:\n    movie_genres=dict()\n    for gen in genre_list:\n        movie_genres.setdefault(gen, 0)\n    for d in genre:\n        movie_genres[d['name']]=1\n    all_movies.append(movie_genres)\ngenres_df=pd.DataFrame(all_movies)","1334a6c6":"#We extract the Director from the list of crew members and create a new column that has the director of each movie.\ndirectors_list=list()\nfor crew in data[\"crew\"]:\n    director_flag=0\n    for d in crew:\n        if d['job']==\"Director\":\n            directors_list.append({\"Director\":d['name']})\n            director_flag=1\n            break\n    if director_flag==0:\n        directors_list.append({\"Director\":''})\n\ndirectors_df=pd.DataFrame(directors_list)","4a92c63e":"keywords_column=list()\nfor movie_keywords in data[\"keywords\"]:\n    keywords=''\n    for d in movie_keywords:\n        keywords=keywords+ps.stem(d['name'])+' '\n    keywords_column.append(keywords.strip())\n    \nkeywords_df=pd.DataFrame(keywords_column)\n\ntfidf_column2=[]\nidf_dict2=idf(keywords_df[0])\nfor docs in keywords_df[0]:        \n    tfidf_dict=tf(docs)\n    for key,value in tfidf_dict.items():\n        tfidf_dict[key]=value*idf_dict2[key]\n    tfidf_dict=sorted(tfidf_dict, key=tfidf_dict.get, reverse=True)[:5]\n    tfidf_column2.append(tfidf_dict)\nkeywords_5df=pd.DataFrame(tfidf_column2,columns=[\"Keyword1\",\"Keyword2\",\"Keyword3\",\"Keyword4\",\"Keyword5\"])","c2831189":"#Concatenating\nresult=pd.concat([data,actors_df,directors_df,genres_df,importantwords_df,keywords_5df],axis=1)\n#Normalizing vote_average to change the range to 0 to 1\nresult[\"vote_average\"]=result[\"vote_average\"]*0.1","42a8f91d":"import ipywidgets as widgets\n\nuser_movie=widgets.Dropdown(\n    options=sorted(list(result[\"title\"])),\n    description='Please choose a movie:',\n    disabled=False,\n    value='Battleship'\n)\nuser_movie","4fc2b5b5":"import sklearn.metrics.pairwise\nprint(\"Movie selected is \"+user_movie.value)\nuser_profile=result.loc[result['title']==str(user_movie.value)]\n\nuser_profile=user_profile.drop(['cast','crew','popularity', 'budget', 'genres', 'homepage', 'keywords','original_title','overview', 'production_companies','production_countries','release_date', 'revenue', 'runtime', 'spoken_languages', 'status','tagline','vote_count'],axis=1)\nactor1=user_profile['actor1'].tolist()\nactor2=user_profile['actor2'].tolist()\nactor3=user_profile['actor3'].tolist()\noriginal_language=user_profile['original_language'].tolist()\nDirector=user_profile['Director'].tolist()\nKey1=user_profile['Key1'].tolist()\nKey2=user_profile['Key2'].tolist()\nKey3=user_profile['Key3'].tolist()\nKey4=user_profile['Key4'].tolist()\nKey5=user_profile['Key5'].tolist()\nKeyword1=user_profile['Keyword1'].tolist()\nKeyword2=user_profile['Keyword2'].tolist()\nKeyword3=user_profile['Keyword3'].tolist()\nKeyword4=user_profile['Keyword4'].tolist()\nKeyword5=user_profile['Keyword5'].tolist()\n\n\nactor_list=[actor1[0],actor2[0],actor3[0]]\nkey_list=[Key1[0],Key2[0],Key3[0],Key4[0],Key5[0]]\nkeyword_list=[Keyword1[0],Keyword2[0],Keyword3[0],Keyword4[0],Keyword5[0]]\n\n\nuser_profile['actor1'] = np.where(user_profile.actor1.isin(actor1),1,0)\nuser_profile['actor2'] = np.where(user_profile.actor2.isin(actor2),1,0)\nuser_profile['actor3'] = np.where(user_profile.actor3.isin(actor3),1,0)\nuser_profile['original_language'] = np.where(user_profile.original_language.isin(original_language),1,0)\nuser_profile['Director'] = np.where(user_profile.Director.isin(Director),1,0)\nuser_profile['Key1'] = np.where(user_profile.Key1.isin(Key1),1,0)\nuser_profile['Key2'] = np.where(user_profile.Key2.isin(Key2),1,0)\nuser_profile['Key3'] = np.where(user_profile.Key3.isin(Key3),1,0)\nuser_profile['Key4'] = np.where(user_profile.Key4.isin(Key4),1,0)\nuser_profile['Key5'] = np.where(user_profile.Key5.isin(Key5),1,0)\nuser_profile['Keyword1'] = np.where(user_profile.Keyword1.isin(Keyword1),1,0)\nuser_profile['Keyword2'] = np.where(user_profile.Keyword2.isin(Keyword2),1,0)\nuser_profile['Keyword3'] = np.where(user_profile.Keyword3.isin(Keyword3),1,0)\nuser_profile['Keyword4'] = np.where(user_profile.Keyword4.isin(Keyword4),1,0)\nuser_profile['Keyword5'] = np.where(user_profile.Keyword5.isin(Keyword5),1,0)\n\nitem_profiles=result.drop(['cast','crew','popularity', 'budget', 'genres', 'homepage', 'keywords','original_title','overview', 'production_companies','production_countries','release_date', 'revenue', 'runtime', 'spoken_languages', 'status','tagline','vote_count'],axis=1)\nitem_profiles=item_profiles.loc[~(data['original_title']==str(user_movie.value))]\nitem_profiles['actor1'] = np.where(item_profiles.actor1.isin(actor_list),1,0)\nitem_profiles['actor2'] = np.where(item_profiles.actor2.isin(actor_list),1,0)\nitem_profiles['actor3'] = np.where(item_profiles.actor3.isin(actor_list),1,0)\nitem_profiles['original_language'] = np.where(item_profiles.original_language.isin(original_language),1,0)\nitem_profiles['Director'] = np.where(item_profiles.Director.isin(Director),1,0)\nitem_profiles['Key1'] = np.where(item_profiles.Key1.isin(key_list),1,0)\nitem_profiles['Key2'] = np.where(item_profiles.Key2.isin(key_list),1,0)\nitem_profiles['Key3'] = np.where(item_profiles.Key3.isin(key_list),1,0)\nitem_profiles['Key4'] = np.where(item_profiles.Key4.isin(key_list),1,0)\nitem_profiles['Key5'] = np.where(item_profiles.Key5.isin(key_list),1,0)\n\nitem_profiles['Keyword1'] = np.where(item_profiles.Keyword1.isin(keyword_list),1,0)\nitem_profiles['Keyword2'] = np.where(item_profiles.Keyword2.isin(keyword_list),1,0)\nitem_profiles['Keyword3'] = np.where(item_profiles.Keyword3.isin(keyword_list),1,0)\nitem_profiles['Keyword4'] = np.where(item_profiles.Keyword4.isin(keyword_list),1,0)\nitem_profiles['Keyword5'] = np.where(item_profiles.Keyword5.isin(keyword_list),1,0)\n\n\nitem_profiles\nx=user_profile.drop(['title','movie_id'],axis=1)\ny=item_profiles.drop(['title','movie_id'],axis=1)\n\n\narr = sklearn.metrics.pairwise.cosine_similarity(x,y, dense_output=True)\narr_index=arr.argsort()\narr_index=arr_index.ravel()\nfinal_df=pd.DataFrame(arr_index).tail(5)\nfinal_df\nitem_profiles=item_profiles.iloc[final_df[0]]\nitem_profiles=item_profiles.iloc[::-1]\nitem_profiles","2cc39d48":"print(\"Recommended Movies for \"+ user_movie.value + \": \\n\\n\"+'\\n'.join(list(item_profiles[\"title\"])))","20bc4c12":"Now, for looking at the genres of the movie we are going to make a dataframe that gets all the genres from the movies and creates a dummy variable that gives 0 or 1 respective to if that movie corresponds to that genre or not.","15326210":"Now we start processing our data based on our requirements\nWe are processing following columns that we discussed to be using initially.\n\nNow we have to process our data to extract actors from the dataset we will be using the main actors in a movie to do so we will only be using the main three actors of the movie which are represented in the cast of the movie as actor with order 0,1 and 2. We create a dataframe that has the top three actors in each movie.","a457c13c":"# \nFollowing libraries are required for text manipulation and text mining of the overview and keywords in the movie. Stemmer is used to extract only the stem of a word.\n\nAfter looking at the whole dataset I have decided to use only the following columns:-\n\nOverview (Description of the movie can suggest the type of movie and give us the keywords in a movie for example say we have Superman, the movie is based on a comic so most likely comic will be a keyword in the overview)\n\nGenres (Genre is very indicative of the taste of the user and thus must be used)\n\nKeywords (These are keywords pre existing in the data that can be said to be tags representing a movie)\n\nActors (A person watches a movie if he likes a particular actor and that is why we need to include main actors but not all actors as supporing actors are not much of interest)\n\nDirector (People often go for watching a movie based on the director as a director who has a good reputation in the industry is more sort after)\n\nLanguage (Language which the movie is indicate of a person's native language)\n\nvoting_average (The score of the movie and how much it has been rated overall)","57f43b52":"This following functions takes in a document and calculates the term-frequencies and returns the dictionary with frequencies for each word in the document.\n\nThough the TF formula used here is different from what we studied in the class which was just calculating the total count of each word in each document.\n\nHere rather we have documents(overviews) which are very different in lengths so TF alone will not be indicative enough. Thus we normalize them by calculating (1+log(word_count)) and then normalizing these across all the documents by dividing this by vector length.\n\nReference:- https:\/\/www.analyticsvidhya.com\/blog\/2015\/08\/beginners-guide-learn-content-based-recommender-systems\/\n\nThe formula used here is :- (1+np.log10(word_count))\/vector_length)","a66af743":"The following function is used to calculate idf from a set of documents that is passed using a list and we calculate idf for each term.\n\nThe motivation behind idf(inverse document frequency) is that all the words in a document are not necessarily useful in modelling the topics for that document.\n\nIn the function we use a loop to iteratre over each document and split it into words and stem the words that is extracting only the root of that word because words can be in different forms. Then we use idf formula to calculate idf for each unique word in the set of documents.\n\nFormula used for calculating the IDF is :- np.log10(number of documents\/number of documents containg that word)","15229461":"We concatenate all the columns that we have processed and create a new result dataset that we will use to make the user and item profiles.","cafaf8c6":"Now for the list of keywords that exists in our movie dataset already are basically the search tags that represent the movie and the we extract the keywords that have the highest tf-idf among the list of words as those keywords are the most unique tags for each movie.","306f398a":"User selection\u00b6\nThis is the user selection that we need use to create the user profile.\n\nYou can make the user selection multiple times but you need to run the next cell too with it.","b2388d63":"Above is a dropdown when you run the notebook you can choose the movie using this drop down.\n\nI have run the notebook and selecting the movie as \"Battleship\"\n\nSteps Followed:- We create a user profile and first the row from the dataset that corresponds to users selected movie. We use original_language, actors, director, keys(from overview) and keywords and code 1 or 0 for each movie. For the user profile each of the above is 1. Then we drop irrelevant columns. We subset the data to remove the user's selection from the original dataset. We compute the cosine similarities between to dataset(one dataset represents user profile and other represents item profiles) We sort the cosine similarities by lowest to highest. We pick the last 5. Recommend the 5 movies we picked","8293762d":"Movie Recommender System using Text Mining\nIn this modern era, all the companies have started using recommender systems more and more to enhance their customer experience. There are two basic types of recommender systems algorithm namely Collabrative filtering based and content-based filtering (also known as pensonality-based approach). Both these approaches are used heavily. I will be discussing the former approach that is the content-based approach. Let me discuss few examples of this approach first-\n\n\u2022 Pandora uses the properties of songs and artist (around 400 and so variables) to create different types of stations for users like pop artist and pop songs are listed under the same station.\n\n\u2022 Content based systems are also used by e-commerce companies to suggest items to the user based on filters set by the user.\n\nRecommender systems are information filtering tools that aspire to predict the rating for users and items, predominantly from big data to recommend their likes. Movie recommendation systems provide a mechanism to assist users in classifying users with similar interests. This makes recommender systems essentially a central part of websites and e-commerce applications.\n\nNow, that we have some rough sketch on what a content based system does. Lets talk about the algorithm on a high level and understand how does this work. So basically, we have to create different profiles for the pool of items among which we need to make the recommendations and we create a profile based on user's choice or previous items they have rated highly. Once this is done, we compare these in n-dimensional space and compute the similarity between them and recommend those items to the user which are the most similar to the user's profile.\n\nMotivation\u00b6\nMotivation behind this movie recommender system is say a user searches for a movie that he likes then it is upto which movies should we recommend to him that he can look at after that movie. This is the similar approach that is used by big companies like Netflix, IMDB for recommending movies based on user choice. A similar approach is used by amazon to show suggested items in their catalog once a user clicks and opens a particular item. This helps companies to show users only those items that are relevant to them.\n\nMethodology\u00b6\nSo the methodology for this tutorial is based on the same algorithm.\n\nI have used a movie dataset where user profile will be created by using user's selection.\nWe compare these user's selection with all the movies in the dataset.\nWe compare these profiles(vectors) using cosine similarities. (To make these profiles we will have to process our dataset into data that will be required for making vectors)\nTo create the user profiles and the item profiles I will be using keywords from the movie's overview (which are calculated using Tf-Idf) and similarly, among the tags for each I have calculated the top tags that represent that movie. I will also be using features like movie ratings, actors, director etc to create profiles."}}