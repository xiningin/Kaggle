{"cell_type":{"869342bc":"code","ff588a09":"code","5ed3c7f3":"code","d45668dc":"code","8dc7b994":"code","f7f832b5":"code","9d88e3f1":"code","632e7992":"code","a6a9fb15":"code","a4aeaaa1":"code","e2aa698a":"code","4979adb7":"code","b7c00d9b":"code","04a9520a":"code","cda847cd":"code","ffd46827":"code","c3dcd94b":"code","4b360c17":"code","27024170":"code","fe07b203":"code","91bd06b8":"code","6c3a6d30":"code","88c1c9fa":"code","d70a423a":"code","4652e354":"code","d831d2dd":"code","6d589fe3":"markdown","029ffd5d":"markdown","92a4a6de":"markdown","c6cd9557":"markdown","a6403c7b":"markdown","eb0b5d80":"markdown","5c8b114e":"markdown","a74257ae":"markdown","f3ecba07":"markdown","fc9d0326":"markdown","ac1b2808":"markdown","03a8fc77":"markdown","3ce238a2":"markdown","8ab34ed6":"markdown","e2c3a857":"markdown","254fe824":"markdown","8232b893":"markdown","6dd42918":"markdown","d4ba5483":"markdown"},"source":{"869342bc":"import numpy as np # No words for this package\nimport pandas as pd # Data Processing\nimport matplotlib.pyplot as plt # Ploting Results\nimport cv2 # Image Processing\nimport math # I don't know why this is not built-in\nimport random # Neural Nets Love Randomly Organized Stuff :p\n\n# Machine Learning Tools\nfrom torch import tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import save_image\nfrom torch import from_numpy\nfrom torch import optim\nfrom torch import tensor\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.optim as opt\nimport torch","ff588a09":"def get_data_from_each_class(dataset, labels, flt_percent=0.05):\n    df = []\n    for x in range(len(labels.keys())):\n        flt = dataset.loc[dataset.label == x]\n        flt = flt.sample(int(flt_percent*flt.count()[0]))\n        try:\n            df = df.append(flt)\n        except:\n            df = flt\n    return df","5ed3c7f3":"# Load Data\ntrain_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')\n\n#Labels \nlabels = {0 : \"T-shirt\/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n#Reverse Labels \nreverse_labels = {\"T-shirt\/top\":0 , \"Trouser\":1 , \"Pullover\":2 , \"Dress\":3 , \"Coat\":4 ,\n          \"Sandal\":5 , \"Shirt\":6 , \"Sneaker\":7 , \"Bag\":8 , \"Ankle Boot\":9 }\n#Color Maps\nlabels_color_map = {0 : [255,0,0], 1: [98,98,98], 2: [0,0,255], 3: [255,255,0], 4: [255,0,255],\n          5: [0,255,255], 6: [128,0,128], 7:[98,0,128], 8: [0,128,128], 9:[0,255,0] }","d45668dc":"train_data = get_data_from_each_class(train_data, labels, flt_percent=0.05)\ntest_data = get_data_from_each_class(test_data, labels, flt_percent=0.05)\nprint(\"Train Samples\",train_data.count()[0])\nprint(\"Test Samples\",test_data.count()[0])\n#Shuffle Data\ntrain_data = train_data.sample(train_data.count()[0])\ntest_data = test_data.sample(test_data.count()[0])","8dc7b994":"import copy\ntarget = np.zeros((28,28))\ni,j = np.indices((28,28))\n\ngausian_target = ((27 - abs(13-i)*1.42)*(27 - abs(13-j)*1.42)) \/ (28*28)\ngausian_not_target = (1-gausian_target)\/9\nno_target_channels = np.zeros([28,28,10])\nfor x in range(10):\n    no_target_channels[:,:,x] = gausian_not_target\n    \ndef convert_to_image_array(data):\n    img_data = []\n    img_target_data = []\n    img_label = []\n    # Append the samples to the samples list\n    for j, s in enumerate(data.values):\n        # First column contain labels, hence index should start from 1\n        img = np.array(data.iloc[j, 1:]).reshape(28,28,1)\/255\n        img_target = copy.deepcopy(no_target_channels)\n        label = data.iloc[j, 0]\n        img_target[:,:,label] = gausian_target\n        img_data.append(img)\n        img_label.append(label)\n        img_target_data.append(img_target)\n    return img_data, img_target_data, img_label","f7f832b5":"train_images, train_img_target, train_labels = convert_to_image_array(train_data)\ntest_images, test_img_target, test_labels = convert_to_image_array(test_data)","9d88e3f1":"def create_data(images_set, target_set, number_of_images = 100, max_objs_per_image = 10, images_resolution = [256, 256]):\n    Q, P = [], []\n    for u in range(number_of_images):\n        obj_count = random.randint(3,max_objs_per_image)\n        image = np.zeros([images_resolution[0], images_resolution[1], 1])\n        target_data = np.zeros([images_resolution[0], images_resolution[1], 10])\n        for i in range(obj_count):\n            x = 28*random.randint(1,images_resolution[0]\/\/28-1)\n            y = 28*random.randint(1,images_resolution[1]\/\/28-1)\n            img_idx = random.randint(0, len(images_set)-1) \n            X = images_set[img_idx]\n            Y = target_set[img_idx]\n            target_data[x:x+28,y:y+28,:]\n            image[x:x+28,y:y+28,:] = X\n            target_data[x:x+28,y:y+28,:] = Y\n        image = np.clip(image, 0, 255)\n        Q.append(image)\n        P.append(target_data)\n    return Q, P","632e7992":"X_test, Y_test = create_data(test_images, test_img_target,number_of_images = 5, max_objs_per_image = 10, images_resolution = [256, 256])\nX_train, Y_train = create_data(train_images, train_img_target,number_of_images = 100, max_objs_per_image = 4, images_resolution = [128, 128])","a6a9fb15":"def plot_sample_images(data_sample_images,data_sample_labels,cmap=\"Blues\"):\n    f, ax = plt.subplots(5,8, figsize=(16,10))\n\n    for i, img in enumerate(data_sample_images):\n        ax[i\/\/8, i%8].imshow(img.reshape(img.shape[0],img.shape[1]), cmap=cmap)\n        ax[i\/\/8, i%8].axis('off')\n        ax[i\/\/8, i%8].set_title(labels[data_sample_labels[i]])\n    plt.show()  \n    \nplot_sample_images(train_images[:40],train_labels[:40], \"Greys\")","a4aeaaa1":"def plot_input_output_data(image, seg_data, cmap0=\"Blues\", cmap1=\"Blues\"):\n    # Plot the sample images now\n    plt.imshow(image.reshape(image.shape[0],image.shape[1]), cmap=cmap0)\n    plt.axis('off')\n    plt.title(\"Input\")\n    f, ax = plt.subplots(2,5, figsize=(16,10))\n    for i in range(10):\n        ax[(i)\/\/5, (i)%5].imshow(seg_data[:,:,i], cmap=cmap1)\n        ax[(i)\/\/5, (i)%5].axis('off')\n        ax[(i)\/\/5, (i)%5].set_title(labels[i]+\" Channel\")\n        \ndef prediction_as_colour(image, seg_data_y, size=(5,5),threshold=0.5):\n    prediction_color = np.zeros([image.shape[0],image.shape[1],3])\n    for x in labels_color_map.keys():\n        prediction_color += np.stack((np.where(seg_data_y[:,:,x]>threshold,1,0),)*3, axis=-1)*labels_color_map[x]\n    plt.gcf().set_size_inches(size)\n    plt.imshow(image.reshape([image.shape[0],image.shape[1]]),cmap=\"Greys\")\n    plt.show()\n    plt.gcf().set_size_inches(size)\n    plt.imshow(prediction_color\/255)\n    \n    legends = []\n    import matplotlib.patches as mpatches\n    for x in range(10):\n        legends.append(mpatches.Patch(color=np.array(labels_color_map[x])\/255, label=labels[x]))\n    plt.legend(handles=legends, bbox_to_anchor=(1.5,0.5))\n\ndef get_boxes(pred,bbsize=(27,27),threshold=0.5):\n    bbox = []\n    prob = []\n    detected_class = []\n    x = int(bbsize[1]\/2)\n    y = int(bbsize[0]\/2)\n    \n    for i in range(pred.shape[1]):\n        for j in range(pred.shape[2]):\n            arg = np.argmax(pred[:,i,j])\n            if((pred[arg,i,j]>threshold) and (i>=y) and (j>=x)):\n                prob.append(pred[arg,i,j])\n                detected_class.append(arg)\n                bbox.append([j-x,i-y,j+x,i+y])\n    bbox = np.array(bbox)\n    return bbox, detected_class, prob\n\ndef non_max_suppression(bbox, clss, prob, threshold=0):\n    pick_bbox = []\n    pick_class = []\n    pick_prob = []\n    while len(bbox)>0:\n\n        x1 = bbox[:,0]\n        y1 = bbox[:,1]\n        x2 = bbox[:,2]\n        y2 = bbox[:,3]\n\n        idx = np.argmax(prob)\n        pick_bbox.append(bbox[idx])\n        pick_class.append(clss[idx])\n        pick_prob.append(prob[idx])\n\n        xx1 = np.maximum(x1[idx], x1)\n        yy1 = np.maximum(y1[idx], y1)\n        xx2 = np.minimum(x2[idx], x2)\n        yy2 = np.minimum(y2[idx], y2)\n\n        w = np.maximum(0, xx2 - xx1 + 1)\n        h = np.maximum(0, yy2 - yy1 + 1)\n\n        area = w*h\n        overlap = area\/area[idx]\n        bbox = np.delete(bbox, np.where(overlap > threshold)[0],axis=0)\n        clss = np.delete(clss, np.where(overlap > threshold)[0])\n        prob = np.delete(prob, np.where(overlap > threshold)[0])\n    \n    return pick_bbox, pick_class, pick_prob\n\ndef draw_bounding_box_from_model_output(im, output, size=(5,5), threshold=0.9):\n    bbox, cls, prob = get_boxes(output,threshold=threshold)\n    bbox, cls, prob = non_max_suppression(bbox,cls,prob)\n    \n    sample = copy.deepcopy(im.reshape(im.shape[0],im.shape[1])*255)\n    for i in range(len(bbox)):\n        cv2.rectangle(sample, (bbox[i][0], bbox[i][1]), (bbox[i][2], bbox[i][3]), 255)\n        pred = str(\"%.1f\"%float(prob[i]*100))\n        cv2.putText(sample, labels[cls[i].item()], (bbox[i][0]+1, bbox[i][1]-1), cv2.FONT_HERSHEY_PLAIN, 0.8, 255)\n        cv2.putText(sample, pred+\"%\", (bbox[i][0]-1, bbox[i][3]+10), cv2.FONT_HERSHEY_PLAIN, 0.8, 255)\n\n    plt.gcf().set_size_inches(size)\n    plt.grid(False)\n    plt.imshow(sample, cmap='Greys')\n    return sample, bbox, cls, prob","e2aa698a":"plot_input_output_data(train_images[50], train_img_target[50], \"Greys\", \"gray\")","4979adb7":"prediction_as_colour(X_train[0], Y_train[0], threshold=0.5 )","b7c00d9b":"def simulate_model_output(image):\n    image = np.transpose(np.array(image), (2,0,1))\n    return from_numpy(np.array([image])).float()\nsample, bbox, cls, prob = draw_bounding_box_from_model_output(X_test[-1], simulate_model_output(Y_test[-1])[0], size=(10,10))","04a9520a":"def tensor2image(tensor):\n    return np.transpose(tensor.numpy(), (1,2,0))\n\ndef tensor_batch2image_batch(tensor):\n    return np.transpose(tensor.numpy(), (0,2,3,1))\n\ndef image2tensor(image):\n    image = np.transpose(np.array(image), (2,0,1))\n    return from_numpy(np.array(image)).float()\n\ndef image_batch2tensor(image_batch):\n    batch = np.transpose(np.array(image_batch), (0,3,1,2))\n    return from_numpy(np.array(batch)).float()\n\nclass imageDatasetBuilder(Dataset):\n    def __init__(self, images_in, images_out, limit_dataset_size=None, transform=None):\n        self.images_in = images_in\n        self.images_out = images_out\n        self.x, self.y = [], []\n        for x in range(len(self.images_in)):\n            self.x.append(image2tensor(self.images_in[x]))\n            self.y.append(image2tensor(self.images_out[x]))\n        self.x = self.x\n        self.y = self.y\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self,idx):\n        return self.x[idx], self.y[idx]","cda847cd":"X_train = np.array(X_train)\nY_train = np.array(Y_train)\nprint(X_train.shape)\nprint(Y_train.shape)","ffd46827":"batch_size = 50\n\ndb = imageDatasetBuilder(X_train, Y_train)\nprint(len(db))\ndata_loader = DataLoader(db, batch_size=batch_size)\n\nx, y = next(iter(data_loader))\nprint(x.shape)\nprint(y.shape)","c3dcd94b":"def create_conv(n_feat, kernel_size, bias=True):\n    return nn.Conv2d(\n        n_feat, n_feat, kernel_size,\n        padding=(kernel_size \/\/ 2), bias=bias)\n\n\nclass ResBlock(nn.Module):\n    def __init__(\n        self, n_feat, kernel_size,\n        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n\n\n        super(ResBlock, self).__init__()\n        modules_body = []\n        for i in range(2):\n            modules_body.append(create_conv(n_feat, kernel_size, bias))\n            if bn: modules_body.append(nn.BatchNorm2d(n_feat))\n            if i == 0: modules_body.append(act)\n\n        self.body = nn.Sequential(*modules_body)\n        self.res_scale = res_scale\n\n    def forward(self, x):\n        res = self.body(x).mul(self.res_scale)\n        res += x\n\n        return res\n\nclass Model(nn.Module):\n    def __init__(self, n_features ,n_resblocks, in_channels=1, out_channels=10):\n        super(Model, self).__init__()\n        self.start = nn.Conv2d(in_channels, n_features, 3, padding=1, bias=True)\n        resblocks = []\n        for i in range(n_resblocks):\n            resblocks.append(ResBlock(n_features, 3, res_scale=0.15))\n    \n        resblocks.append(nn.Conv2d(n_features, n_features, 3, padding=1, bias=True))\n        self.resblocks = nn.Sequential(*resblocks)\n        self.end = nn.Conv2d(n_features, out_channels, 3, padding=1, bias=True)\n        self.act_end = nn.Softmax2d()\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ n))\n                m.bias.data.zero_()\n\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n                \n    def forward(self, x):\n        xs = self.start(x)\n        x = self.resblocks(xs)\n        x = self.end(x)\n        x = self.act_end(x)\n        return x","4b360c17":"load_model = False\n#load_from_path = \"fmnist_bbResNet_2000.ptp\"\ntrain_model = True","27024170":"model = Model(128,4).cuda()\nif load_model:\n    model.load_state_dict(torch.load(load_from_path))\n\ndummy_input = torch.ones((1,1,256,256)).cuda().float()\nprint('Model Input Shape:',dummy_input.shape)\nprint('Model Output Shape:',model(dummy_input).shape)\nprint(model)","fe07b203":"# Train\ndef train(data_loader, model,\n          num_epochs = 5000,\n          epoch_interval_save_sample = 1000,\n          learning_rate_a = 1e-3,\n          learning_rate_b = 1e-4,\n          cut_learning_rate = 0.009):\n    criterion = nn.MSELoss()\n    optimizer = opt.Adamax(\n        model.parameters(), lr=learning_rate_a, weight_decay=1e-6)\n    imgs = []\n    losses = []\n\n    using_LR = 'A'\n    rand = db[random.randint(0,len(db))]\n    for epoch in range(num_epochs):\n        for data in data_loader:\n            x_, y_ = data\n            optimizer.zero_grad()\n            x = Variable(x_).cuda()\n            y = Variable(y_).cuda()\n            # ===================forward=====================\n            output = model(x)\n            loss = criterion(output, y)\n            # ===================backward====================\n            loss.backward()\n            optimizer.step()\n        # ===================log========================\n        losses.append(loss.data.item())\n        if (loss.data.item() <= cut_learning_rate):\n            using_LR = 'B'\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = learning_rate_b\n        else:\n            using_LR = 'A'\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = learning_rate_a\n\n        print('Using LR_'+using_LR+' epoch [{}\/{}], loss:{:.8f}'\n              .format(epoch+1, num_epochs, loss.data.item()), end='\\r')\n        if ((epoch+1) % epoch_interval_save_sample == 0):\n            x = Variable(rand[0]).cuda()\n            output = model(x.unsqueeze_(0))\n            imgs.append([(rand[0],rand[1]),output.cpu().data])\n            torch.save(model.state_dict(), \"fmnist_bbResNet_\"+str(epoch+1)+\".ptp\")\n            #save_image(pic, '.\/dc_img\/image_{}.png'.format(epoch))\n    return imgs, losses","91bd06b8":"num_epochs = 2000\nepoch_interval_save_sample = 1000\nif(train_model): \n    imgs, losses = train(data_loader, model,\n                         num_epochs = num_epochs,\n                         epoch_interval_save_sample = epoch_interval_save_sample,\n                         learning_rate_a = 1e-4,\n                         learning_rate_b = 1e-6,\n                         cut_learning_rate = 0.009)\n","6c3a6d30":"if(train_model):\n    x = [x for x in range(len(losses))]\n    plt.plot(x, losses)","88c1c9fa":"if(train_model):\n    for i in range(len(imgs)):\n        print(\"epoch\",(i+1)*epoch_interval_save_sample)\n        x = tensor2image(imgs[i][0][0])\n        y = tensor2image(imgs[i][1][0])\n        Y = tensor2image(imgs[i][0][1])\n        plot_input_output_data(x, y, \"Greys\", \"gray\")\n        plt.show()","d70a423a":"def push_batch_model(im_bach, model, is_normalized=False):\n    with(torch.no_grad()):\n        im_t = image_batch2tensor(im_bach)\n        X1 = Variable(im_t).cuda()\n        output = model(X1).cpu().data\n        return output\n\noutput = push_batch_model(X_test[:100], model)","4652e354":"for x in range(5):\n    _im, _bbox, _classes, _probs = draw_bounding_box_from_model_output(\n        X_test[:100][x], output[x], size=(8,8), threshold=0.5)\n    plt.show()","d831d2dd":"plot_input_output_data(\n    X_test[:100][-1], tensor_batch2image_batch(output)[-1], cmap0=\"Greys\", cmap1=\"gray\")\nplt.show()","6d589fe3":"Here is the DataLoader so that the GPU does not run out of memory. ","029ffd5d":"Another representation would be to draw the classes probabilities diferent colours!","92a4a6de":"Creating Test Scenarios","c6cd9557":"Assessing the training process:","a6403c7b":"# Visualization Functions","eb0b5d80":"Here is some visualization of both the training strategy and the expected output!","5c8b114e":"# Training\nOur GPU seams lazy, let us put it to work..","a74257ae":"Hmmm ok.. how about those bounding boxes?","f3ecba07":"Based on the distributions, we can draw bounding boxes around the most probable distribution, *note: these are the test targets*","fc9d0326":"Dataframe To Usable Matrix Data:","ac1b2808":"Here is the Archtecture of our Convolutional Neural Network:","03a8fc77":"We basically make a normal distribution around the center of the image using different channels to represent diferent classes","3ce238a2":"## 2D Challange 1 - Bounding Box ResNet\n\nLet's try to implement a crude Resnet for object detection","8ab34ed6":"# Building and Training ResNet!","e2c3a857":"Here we simply persuade the training to take new shape so torch will like it!","254fe824":"Checking Data Integrity","8232b893":"## Loading Fashion MNIST","6dd42918":"What did ResNet Learn? ","d4ba5483":"# Testing\n\nAs defined earlier, let us push some data through the network and watch the results"}}