{"cell_type":{"b9626df4":"code","255022dd":"code","b821adff":"code","bf455e4e":"code","0f7e7028":"code","a120d059":"code","f98c2bdb":"code","fdc6c987":"code","61adee9b":"code","e8e8c0c1":"code","543c1588":"code","d93e73de":"code","903f44fe":"code","5afe38f0":"code","c7ca78b7":"code","976207f4":"code","18cd431c":"code","fc26b02b":"code","f2b8bcd2":"code","b80ce20f":"code","6e285ab6":"code","c3825e38":"code","c8d699d7":"code","ee9c63eb":"code","1d76b2d0":"code","3aa9c057":"code","4865ca6a":"code","79afd0fa":"code","8ee49748":"code","7df88a77":"code","cab5a1b5":"code","d4c2d584":"code","0bdab2aa":"code","b3dede16":"code","30b17bf1":"code","ecc0cede":"markdown","6078c81b":"markdown","2fafa597":"markdown","006be9d2":"markdown","5bbc4483":"markdown","4c175315":"markdown","29fd14c0":"markdown","64a05287":"markdown","36e6a3c7":"markdown","5e46761a":"markdown","8d4316e0":"markdown","98524927":"markdown","49181062":"markdown","465d3297":"markdown","9e4058fb":"markdown"},"source":{"b9626df4":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression, Ridge, TheilSenRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy import stats\nimport tensorflow as tf\nfrom tensorflow.keras.utils import normalize\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten","255022dd":"dataset = pd.read_csv(\"..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv\")  \ndataset.head()","b821adff":"dataset.info()","bf455e4e":"dataset.describe()","0f7e7028":"sns.boxplot(dataset['price'])","a120d059":"# See all unique neighborhoods\nall_boroughs = dataset['neighbourhood_group'].unique()\n\n# Isolate neighborhood and price\nneigh = dataset[['neighbourhood_group', 'price']]\n\n# Isolate Each Neighborhood\ndef get_borough_price_data(df, name):\n    \n    query = \"neighbourhood_group == '\" + name + \"'\"\n    df = neigh.query(query)\n    mean_price = np.mean(df['price'])\n    return df, mean_price\n\n[bk, bk_avg_price] = get_borough_price_data(neigh, \"Brooklyn\")\n[m, m_avg_price] = get_borough_price_data(neigh, \"Manhattan\")\n[bx, bx_avg_price] = get_borough_price_data(neigh, \"Bronx\")\n[q, q_avg_price] = get_borough_price_data(neigh, \"Queens\")\n[s, s_avg_price] = get_borough_price_data(neigh, \"Staten Island\")\n\n# Concatenate\navg_prices_by_borough = [bk_avg_price, m_avg_price, q_avg_price, s_avg_price, bx_avg_price]","f98c2bdb":"# Plot Average Price by Borough\nfig = plt.figure()\nbar = fig.subplots()\nbar.bar(all_boroughs, avg_prices_by_borough)\nbar.set_title(\"Average Prices of Nightly AirBnb Rental by Neighborhood\")\nbar.set_xlabel(\"Neighborhoods\")\nbar.set_ylabel(\"Price ($)\");","fdc6c987":"# Remove non-numerical features\ndata = dataset.select_dtypes(exclude='object')\ndata = data.drop(columns=['id', 'host_id'])\nunscored_data = data.dropna()\ndata.head()\ncols = data.columns\n\n# Remove some outliers with z-scoring\nz_scores = np.abs(stats.zscore(unscored_data)) # calculate z scores\nprint(\"Max before removal: \" + str(data['price'].max()))\ndata = unscored_data[(z_scores < 2).all(axis=1)] # filter for only values with z scores less than 2\nsns.boxplot(data['price'])\nprint(\"Max after removal: \" + str(data['price'].max()))\ndata.describe()","61adee9b":"# Scale data\nscaler = StandardScaler()\nscaler.fit(data)\nscaled_data = scaler.transform(data)\n\n# Estimating required number of components\ndigits = [i for i in range(1,9)]\nexplained_var = []\nfor i in digits:\n    pca = PCA()\n    explained_var.append(pca.fit(scaled_data).explained_variance_ratio_.cumsum()[i-1])\n\nplt.plot(digits, explained_var)\nplt.title(\"Cumulated Variance by Number of Components\")\nplt.xlabel(\"# of Components\")\nplt.ylabel(\"Variance\")\n\n# Fit PCA, than transform data\npca = PCA(n_components=7) # Can be any number\npca.fit(scaled_data) # Fit pca model\npca_data = pca.transform(scaled_data) # scale data to two components\n\nfig = plt.figure(figsize=(8,8))\np = fig.subplots()\np.scatter(pca_data[:,0], pca_data[:,1], c=data['price']) # visualize pca","e8e8c0c1":"print(\"Explained variance ratio: {}\".format(pca.explained_variance_ratio_))\nprint(\"Explained Variance: {}\".format(pca.explained_variance_ratio_.cumsum()))\n\n# Plot components by each feature\ncomponents = pd.DataFrame(pca.components_, columns = cols)\nsns.heatmap(components)","543c1588":"# Isolate desired data\nreg_data = data[['latitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'price']]\n\n# Set x to all features except price and set y to price\nx_train, x_test, y_train, y_test = train_test_split(reg_data.drop('price', axis=1), reg_data['price'], test_size=0.3, random_state=101)\nx_train = np.array(x_train)\nx_test = np.array(x_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\n# Scale data separately for x and y\nx_scale = StandardScaler().fit(x_train)\nx_train = x_scale.transform(x_train)\nx_test = x_scale.transform(x_test)\n\ny_scale = StandardScaler().fit(y_train.reshape(-1,1))\ny_train = y_scale.transform(y_train.reshape(-1,1))\ny_test = y_scale.transform(y_test.reshape(-1,1))\n\n# Create Model and train with scaled data\nlm = LinearRegression()\nlm.fit(x_train, y_train)\npred = lm.predict(x_test)\n\nfig = plt.figure(figsize=(9,10))\nl, res = fig.subplots(2)\n\n# Unscale data to get results\nunscaled_predictions = y_scale.inverse_transform(pred)\nunscaled_test_values = y_scale.inverse_transform(y_test)\n\nl.scatter(unscaled_test_values, unscaled_predictions)\nl.set_xlabel(\"Test Values\")\nl.set_ylabel(\"Predicted Values\")\n\nres.scatter(unscaled_test_values, unscaled_test_values-unscaled_predictions)\nres.set_title(\"Residuals vs Predicted Values\")\nres.set_xlabel(\"Test Values\")\nres.set_ylabel(\"Residuals\")","d93e73de":"mean_from_set = data['price'].mean()\nmean_from_model = y_scale.inverse_transform(pred).mean()\nprint(\"Actual mean price: {}\\nPredicted mean price: {}\".format(mean_from_set,mean_from_model))\nmse = metrics.mean_squared_error(y_test, pred)\nprint(\"MSE: \" + str(mse))\nprint(\"RMSE: \" + str(np.sqrt(mse)))","903f44fe":"def test_against_samples(num, data, model, x_scale, y_scale):\n    test_listing = data.sample(num)\n\n    # Isolate same features from testing\n    test = test_listing[['latitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month']]\n\n    # Scale testing data, then use model to predict\n    test_pred = model.predict(x_scale.transform(test))\n\n    # Unscale predictions to get final results\n    try:\n        test_pred = y_scale.inverse_transform(test_pred).transpose()\n    except ValueError:\n        test_pred = y_scale.inverse_transform(test_pred.reshape(-1,1)).transpose()\n    \n    return test_pred, test_listing","5afe38f0":"def plot_samples(test_listing, test_pred, model_name):\n    \n    bar_x1 = [i-0.5 for i in range(1,n_tests+1)]\n    bar_x2 = [i+0.5 for i in bar_x1]\n    \n    try:\n        vals = []\n        for space in test_pred:\n            for val in space:\n                vals.append(val)\n\n        fig = plt.figure(figsize=(8,8))\n        ax = fig.subplots()\n        ax.bar(bar_x1, test_listing['price'], width=0.3, color='navy')\n        ax.bar(bar_x2, vals, width=0.3, color='r')\n        ax.set_xlabel(\"Trials\")\n        ax.set_ylabel(\"Prices\")\n        ax.set_title(\"Bar Plot of Real Prices (Navy) vs Predicted Prices (Red) for {} Model\".format(model_name))\n    except: \n        bar_x1 = [i-0.5 for i in range(1,n_tests+1)]\n        bar_x2 = [i+0.5 for i in bar_x1]\n\n        fig = plt.figure(figsize=(8,8))\n        ax = fig.subplots()\n        ax.bar(bar_x1, test_listing['price'], width=0.3, color='navy')\n        ax.bar(bar_x2, test_pred, width=0.3, color='r')\n        ax.set_xlabel(\"Trials\")\n        ax.set_ylabel(\"Prices\")\n        ax.set_title(\"Real Prices (Navy) vs Predicted Prices (Red) for {} Model\".format(model_name))\n        \n    fig = plt.figure(figsize=(10,10))\n    ax = fig.subplots()\n    ax.plot(range(1,n_tests+1), test_listing['price'], color='navy')\n    ax.plot(range(1,n_tests+1), test_pred.reshape(-1,1), color='red')\n    ax.set_title(\"Line Plot of Real Prices (Navy) vs Predicted Prices (Red) for {} Model\".format(model_name))\n    ax.set_ylabel(\"Prices\")\n    ax.set_xlabel(\"Trials\")","c7ca78b7":"# Testing against samples\n\nn_tests = 5000\n\n(test_pred, test_listing) = test_against_samples(n_tests, data, lm, x_scale, y_scale)\n\nplot_samples(test_listing, test_pred, 'LinearRegression')","976207f4":"# Trying another Regression Model\nridge = Ridge()\nridge.fit(x_train, y_train)\nridge_pred = ridge.predict(x_test)\n\nfig = plt.figure(figsize=(9,10))\nreg, res = fig.subplots(2)\n\nunscaled_predictions_r = y_scale.inverse_transform(ridge_pred)\nunscaled_test_values = y_scale.inverse_transform(y_test)\n\nreg.scatter(unscaled_test_values, unscaled_predictions_r)\nreg.set_xlabel(\"Test Values\")\nreg.set_ylabel(\"Predicted Values\")\nreg.set_title(\"Test vs Predicted Prices\")\n\nres.scatter(unscaled_test_values, unscaled_test_values-unscaled_predictions_r)\nres.set_title(\"Residuals vs Predicted Values\")\nres.set_xlabel(\"Test Values\")\nres.set_ylabel(\"Residuals\")","18cd431c":"mse = metrics.mean_squared_error(y_test, ridge_pred)\nprint(\"MSE: \" + str(mse))\nprint(\"RMSE: \" + str(np.sqrt(mse)))","fc26b02b":"# Testing against a real posting\ntest_pred, test_listing = test_against_samples(n_tests, data, ridge, x_scale, y_scale)\nplot_samples(test_listing, test_pred, \"Ridge\")","f2b8bcd2":"mean_from_set = data['price'].mean()\nmean_from_model = y_scale.inverse_transform(ridge_pred).mean()\nprint(\"Actual mean price: {}\\nPredicted mean price: {}\".format(mean_from_set,mean_from_model))","b80ce20f":"# Trying a Theil Sen Regression, which may be resilient to outliers\nts = TheilSenRegressor().fit(x_train, np.ravel(y_train))\nts_pred = ts.predict(x_test)\n\nfig = plt.figure(figsize=(9,10))\nreg, res = fig.subplots(2)\n\nunscaled_predictions_ts = y_scale.inverse_transform(ts_pred)\nunscaled_test_values = y_scale.inverse_transform(np.ravel(y_test))\n\nreg.scatter(unscaled_test_values, unscaled_predictions_ts)\nreg.set_xlabel(\"Test Values\")\nreg.set_ylabel(\"Predicted Values\")\nreg.set_title(\"Test vs Predicted Prices\")\n\nres.scatter(unscaled_test_values, unscaled_test_values-unscaled_predictions_ts)\nres.set_title(\"Residuals vs Predicted Values\")\nres.set_xlabel(\"Test Values\")\nres.set_ylabel(\"Residuals\")","6e285ab6":"mse = metrics.mean_squared_error(y_test, ts_pred)\nprint(\"MSE: \" + str(mse))\nprint(\"RMSE: \" + str(np.sqrt(mse)))","c3825e38":"mse = metrics.mean_squared_error(y_test, ts_pred)\nprint(\"MSE: \" + str(mse))\nprint(\"RMSE: \" + str(np.sqrt(mse)))","c8d699d7":"# Testing against a real posting\ntest_pred, test_listing = test_against_samples(n_tests, data, ts, x_scale, y_scale)\nplot_samples(test_listing, test_pred, 'Theil Sen')","ee9c63eb":"mean_from_set = data['price'].mean()\nmean_from_model = y_scale.inverse_transform(ts_pred).mean()\nprint(\"Actual mean price: {}\\nPredicted mean price: {}\".format(mean_from_set,mean_from_model))","1d76b2d0":"# Trying a Random Forest\nrfr = RandomForestRegressor(n_estimators=4, random_state=0)\nrfr.fit(x_train, y_train)\nrfr_pred = rfr.predict(x_test)\n\nfig = plt.figure(figsize=(9,10))\nreg, res = fig.subplots(2)\n\nunscaled_predictions_rfr = y_scale.inverse_transform(rfr_pred)\nunscaled_test_values = y_scale.inverse_transform(np.ravel(y_test))\n\nreg.scatter(unscaled_test_values, unscaled_predictions_rfr)\nreg.set_xlabel(\"Test Values\")\nreg.set_ylabel(\"Predicted Values\")\nreg.set_title(\"Test vs Predicted Prices\")\n\nres.scatter(unscaled_test_values, unscaled_test_values-unscaled_predictions_rfr)\nres.set_title(\"Residuals vs Predicted Values\")\nres.set_xlabel(\"Test Values\")\nres.set_ylabel(\"Residuals\")","3aa9c057":"mse = metrics.mean_squared_error(y_test, rfr_pred)\nprint(\"MSE: \" + str(mse))\nprint(\"RMSE: \" + str(np.sqrt(mse)))","4865ca6a":"# Testing against a real posting\ntest_pred, test_listing = test_against_samples(n_tests, data, rfr, x_scale, y_scale)\nplot_samples(test_listing, test_pred, \"Random Forest Regressor\")\n\ndiff = []\ncount=0\nfor price in test_listing['price']:\n    diff.append(np.abs(price - test_pred[count]))\n    count+=1\nprint('mean difference between test and predicted prices: {}'.format(np.mean(diff)))","79afd0fa":"mean_from_set = data['price'].mean()\nmean_from_model = y_scale.inverse_transform(rfr_pred).mean()\nprint(\"Actual mean price: {}\\nPredicted mean price: {}\".format(mean_from_set,mean_from_model))","8ee49748":"# Testing random forest with a listing found on Airbnb: https:\/\/www.airbnb.com\/rooms\/7858468?source_impression_id=p3_1592509914_6%2FQO7PfPMYw1WBTO&guests=1&adults=1\n# lat, min_nights, num_reviews, reviews_per month (not listed, num_reviews \/ reviews_per_month)\nreal_listing_values = np.array([40.763168, 1, 357, 15]) \nreal_listing_values = real_listing_values.reshape(1,-1)\nreal_price = 100\n\nreal_pred = rfr.predict(x_scale.transform(real_listing_values))\nreal_pred = y_scale.inverse_transform(real_pred.reshape(-1,1))\n\nprint(\"Real Price of Airbnb: \" + str(real_price))\nprint(\"Price Predicted by Random Forest Model: \" + str(real_pred[0]))","7df88a77":"# Saving model\nimport pickle\nimport datetime\n\ninp = input(\"Do you want to save?: Y\/N\\nRemember to change the model number before saving\\n\")\nif inp == \"Y\" or inp =='y':\n    filename = \"Random_Forest_Model{}.pkl\".format(datetime.datetime.now())\n    pickle.dump(rfr, open(filename, 'wb'))\n\n# Saving the scalers\npickle.dump(x_scale, open('x_scale.pkl', 'wb'))\npickle.dump(y_scale, open('y_scale.pkl', 'wb'))","cab5a1b5":"# Splitting data for neural network\nx = reg_data.drop('price', axis=1)\ny = reg_data['price']\n\nx_train, x_test, y_train, y_test = train_test_split(x,y)","d4c2d584":"x_scale_mm = MinMaxScaler()\nx_scale_mm.fit(x)\ny_scale_mm = MinMaxScaler()\ny_scale_mm.fit(y.to_numpy().reshape(-1,1))\n\nx_train_s = x_scale_mm.transform(x_train)\nx_test_s = x_scale_mm.transform(x_test)\ny_train_s = y_scale_mm.transform(y_train.to_numpy().reshape(-1,1))\ny_test_s = y_scale_mm.transform(y_test.to_numpy().reshape(-1,1))\n\nnn = Sequential()\n\nnn.add(Flatten())\nnn.add(Dense(512))\nnn.add(Activation('relu'))\nnn.add(Dropout(0.4))\n\nnn.add(Dense(128))\nnn.add(Activation('relu'))\nnn.add(Dropout(0.4))\n\nnn.add(Dense(1)) # Output 1 value\nnn.add(Activation('linear'))\n\nnn.compile(optimizer='adam', loss='mse', metrics=['mae'])\n\nnn.fit(x_train_s, y_train_s, epochs=6, batch_size=16, validation_split=0.1)","0bdab2aa":"val_loss, val_error = nn.evaluate(x_test_s, y_test_s, verbose=0)\nprint('Validation loss: {}'.format(val_loss))\nprint('Mean Squared Error: {}'.format(val_error))\nprint('RMSE: {}'.format(np.sqrt(val_error)))","b3dede16":"test_listings = reg_data.sample(n_tests)\n\n# Isolate same features from testing\ntest = test_listings[['latitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month']]\nmultipred = y_scale_mm.inverse_transform(nn.predict(x_scale_mm.transform(test)))\n\nprint('Predicted mean: {}'.format(multipred.mean()))\nprint('Sample mean: {}'.format(test_listings['price'].mean()))\n\n\nbar_x1 = [i-0.5 for i in range(1,n_tests+1)]\nbar_x2 = [i+0.5 for i in bar_x1]\nvals = []\nfor space in multipred:\n    for val in space:\n        vals.append(val)\nfig = plt.figure(figsize=(8,8))\nax = fig.subplots()\nax.bar(bar_x1, test_listings['price'], width=0.3, color='navy')\nax.bar(bar_x2, vals, width=0.3, color='r')\nax.set_xlabel(\"Trials\")\nax.set_ylabel(\"Prices\")\nax.set_title(\"Real Prices (Navy) vs Predicted Prices (Red) for Multilayer Perceptron\")\n\nfig = plt.figure(figsize=(10,10))\nax = fig.subplots()\nax.plot(range(1,n_tests+1), test_listings['price'], color='navy')\nax.plot(range(1,n_tests+1), multipred, color='red')\n\ndiff = []\ncount = 0\nfor i in test_listings['price']:\n    diff.append(np.abs(i - multipred[count]))\n    count+=1\nmean_diff = np.mean(diff)\nprint('mean difference between actual and predicted price: {}'.format(mean_diff))","30b17bf1":"pred = nn.predict(x_scale_mm.transform(real_listing_values))\nprint('price predicted by Multilayer Perceptron model: {}'.format(y_scale_mm.inverse_transform(pred)))","ecc0cede":"Again, this model seems to center its predictions around the mean, missing outlier results.","6078c81b":"Unlike the other regression models used so far, this model seems to be less restricted to the mean price when determining predictions. However, the difference is not too drastic.","2fafa597":"Borough seems to make a difference... but what about more qualitative features?","006be9d2":"Predictions seem to be more accurate closer to the mean, but it struggles with outliers.","5bbc4483":"Principal Component Analysis","4c175315":"Data Visualization and Characterization","29fd14c0":"Trying a Neural Network","64a05287":"Using a dataset containing details of Airbnb listings in New York City, I will attempt to create a model to accurately predict the price of a NYC Airbnb. ","36e6a3c7":"Even with tweaking the neural network architecture and parameters, the Random Forest algorithm performs better both in general and with outliers. ","5e46761a":"Seems to have respectable MSE and RMSE","8d4316e0":"Has similar error metrics to the previous model.","98524927":"This model seems to perform slightly worse based on the error metrics.","49181062":"The random forest has the most accurate predictions of the regression models that have been used. Unlike the previous models, the predicted values are not centered around the mean, but rather appear to match closely with the provided values. ","465d3297":"It appears that the number of reviews, reviews per month, the minimum nights, and the latitude correlate the most with the first component, which has the largest effect on the variance. These factors are understandable: the higher number of reviews and frequency of reviews would indicate a lot of engagement with renters, the latitude provides information about the specific neighborhood. Minimum nights is less obvious, but may have some relation to the frequency that the listing is rented. ","9e4058fb":"Seems like there are a lot of outliers, I'll try to remove them later"}}