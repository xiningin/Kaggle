{"cell_type":{"46b8375c":"code","016d63df":"code","08673281":"code","0a6c0d12":"code","dbb2cbeb":"code","ca94ba82":"code","327ada73":"code","f3ade0d7":"code","ec0a6b9a":"code","148e7ed6":"code","48393721":"code","51ee705a":"code","94fc6db4":"code","c6ec4a1c":"code","c0acee45":"code","8e8366dd":"code","876be3ee":"code","0aeab9a6":"code","c87db275":"code","f5b7eecc":"code","847e038f":"code","bb35cc1b":"code","28f45906":"code","c49bb7e2":"code","eed73e99":"code","84c840da":"code","cff259dd":"code","63f46434":"code","86c393cb":"code","a79b45e5":"code","c35c4c55":"code","010687ed":"code","27e88c55":"code","21082200":"code","ad8102df":"code","7014595d":"code","db5bc74f":"code","74508af5":"code","eab20160":"code","dae7f35c":"code","90d42b29":"code","b30f4ad5":"code","06e339c0":"code","69d88c1f":"markdown","5834fb44":"markdown","2a8836cb":"markdown","b5a73e5c":"markdown","2232fdf2":"markdown","0d844f42":"markdown","2ec55e10":"markdown","461eb32f":"markdown","d1801526":"markdown"},"source":{"46b8375c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","016d63df":"data = pd.read_csv('\/kaggle\/input\/house-prices\/data.csv')","08673281":"data.columns","0a6c0d12":"data.head(2)","dbb2cbeb":"data.shape","ca94ba82":"data.isna().sum()\/(data.shape[0]\/100)","327ada73":"data.drop(data[data.target.isna()].index, inplace=True)","f3ade0d7":"data.shape","ec0a6b9a":"import re\ndef make_target(x):\n    x = re.sub('[^0-9]', '', x)\n    x = int(x)\n    return x","148e7ed6":"data.target = data.target.apply(make_target)\ndata.target.describe()","48393721":"def make_features_float(x):\n    if x == -1.0: return x\n    x = re.sub('1 1\/2', '1.5', x)\n    x = re.sub('[^0-9,\\.]', '', x)\n    x = re.sub(',', '.', x)\n    try:\n        x = float(x)\n    except:\n        x = -1.0\n    return x\ndef make_status(x):\n    if x.startswith('Coming soon'): x = 'coming soon'\n    x = x.lower()\n    x = re.sub('[^a-z]', ' ', x)\n    x = re.sub(r'\\b\\w{,2}\\b', '', x)\n    x = re.sub(r'\\s+', ' ', x)\n    return x\n\ndef make_propertyType(x):\n    x = x.lower()\n    x = re.sub('[^a-z]', ' ', x)\n    x = 1 if x.startswith('single family') else 0\n    return x\n\ndef make_fireplace(x):\n    if x == -1: return x\n    x = x.lower()\n    x = re.sub('yes', '1', x)\n    x = re.sub('no', '0', x)\n    if 'fireplace' in x: \n        x = '1'\n    try:\n        x = int(x)\n    except:\n        x = 0\n    return x","51ee705a":"cat_features = ['status', 'state']\ncolumns_to_drop = ['street', 'mls-id', 'MlsId', 'schools', 'homeFacts', 'city', 'zipcode']","94fc6db4":"data['status'] = data['status'].fillna('')\ndata['status'] = data['status'].apply(make_status)","c6ec4a1c":"data['city'] = data['city'].fillna('other')\ntop_city = data['city'].value_counts()[:200].index\ndata['city'] = data['city'].apply(lambda r: r if r in top_city else 'other')","c0acee45":"data['propertyType'] = data['propertyType'].fillna('')\ndata['propertyType'] = data['propertyType'].apply(make_propertyType)","8e8366dd":"data['fireplace'] = data['fireplace'].fillna(-1)\ndata['fireplace'] = data['fireplace'].apply(make_fireplace)","876be3ee":"data['private pool'] = data['private pool'].fillna('No')\ndata['private pool'] = data['private pool'].map({'Yes':1, 'No':0})\ndata['PrivatePool'] = data['PrivatePool'].fillna('No')\ndata['PrivatePool'] = data['PrivatePool'].map({'Yes':1, 'No':0, 'yes':1})\ndata['PrivatePool'] = data['private pool'] | data['PrivatePool']\ndata.drop(['private pool'], axis=1, inplace=True)","0aeab9a6":"data.baths = data.baths.fillna(-1.0)\ndata.baths = data.baths.apply(make_features_float)\ndata.sqft = data.sqft.fillna(-1.0)\ndata.sqft = data.sqft.apply(make_features_float)\ndata.beds = data.beds.fillna(-1)\ndata.beds = data.beds.apply(make_features_float)\ndata.stories = data.stories.fillna(-1)\ndata.stories = data.stories.apply(make_features_float)","c87db275":"data['homeFacts'] = data['homeFacts'].apply(eval)","f5b7eecc":"def make_homeFacts(x):\n    x = x.get('atAGlanceFacts', -1)\n    if x == -1: return -1\n    x = x[0]\n    if x.get('factLabel') == 'Year built':\n        x = x.get('factValue')\n    try:\n        x = int(x)\n    except:\n        x = -1\n    return x","847e038f":"data['year_built'] = data['homeFacts'].apply(make_homeFacts)","bb35cc1b":"data.drop(columns_to_drop, axis=1, inplace=True)","28f45906":"data.describe(include='all')","c49bb7e2":"data = pd.concat([data, pd.get_dummies(data['status'])], axis=1)\n\ndata.drop('status', axis=1, inplace=True)","eed73e99":"# data = pd.concat([data, pd.get_dummies(data['zipcode'])], axis=1)\n# data.drop('zipcode', axis=1, inplace=True)\ndata = pd.concat([data, pd.get_dummies(data['state'])], axis=1)\ndata.drop('state', axis=1, inplace=True)","84c840da":"x_train, x_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=0)","cff259dd":"x_train.shape, y_train.shape, x_test.shape, y_test.shape","63f46434":"# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LinearRegression.html\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.BayesianRidge.html\nfrom sklearn.linear_model import LinearRegression, BayesianRidge\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDRegressor.html?highlight=sgdregressor\nfrom sklearn.linear_model import SGDRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeRegressor.html\nfrom sklearn.tree import DecisionTreeRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsRegressor.html?highlight=kneighborsregressor\nfrom sklearn.neighbors import KNeighborsRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVR.html?highlight=svr#sklearn.svm.SVR\nfrom sklearn.svm import SVR\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestRegressor.html?highlight=randomforestregressor#sklearn.ensemble.RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.ExtraTreesRegressor.html?highlight=randomforestregressor\nfrom sklearn.ensemble import ExtraTreesRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingRegressor.html?highlight=randomforestregressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor\nfrom sklearn.ensemble import StackingRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.VotingRegressor.html#sklearn.ensemble.VotingRegressor\nfrom sklearn.ensemble import VotingRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nimport sklearn.metrics\n'''\u043f\u0440\u043e \u043e\u0448\u0438\u0431\u043a\u0438 \u043f\u043e\u0434\u0440\u043e\u0431\u043d\u0435\u0435 \u0442\u0443\u0442 https:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.metrics'''","86c393cb":"def my_evaluate(clf, x_train, y_train, x_test, y_test, mode='all'):\n    own_predict = clf.predict(x_train)\n    '''\u043c\u044b \u0437\u043d\u0430\u0435\u043c, \u0447\u0442\u043e \u0434\u043e\u043c\u0430 \u043d\u0435 \u043c\u043e\u0433\u0443\u0442 \u0441\u0442\u043e\u0438\u0442\u044c \u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u0446\u0435\u043d\u0443, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435'''\n    own_predict = np.where(own_predict < 1, 1, own_predict)\n    '''\u043d\u0430\u0439\u0434\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u044d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u043d\u043e\u0435 1% \u0432 \u0434\u0435\u043d\u0435\u0436\u043d\u043e\u043c \u0432\u044b\u0440\u0430\u0436\u0435\u043d\u0438\u0438'''\n    one_percent = (y_train.max() - y_train.min())\/100\n    \n    predict = clf.predict(x_test)\n    predict = np.where(predict < 1, 1, predict)\n    if mode=='all':\n        print(f'''\\t\\t\\t\\town evaluate \\t\\t\\tevaluate on test\nExplained variance score:\\t{metrics.explained_variance_score(y_test, predict)}\\t\\t{metrics.explained_variance_score(y_test, predict)}\\n\nMax error:\\t\\t\\t{metrics.max_error(y_train, own_predict)\/one_percent}\\t\\t{metrics.max_error(y_test, predict)\/one_percent}\\n\nMean absolute error:\\t\\t{metrics.mean_absolute_error(y_train, own_predict)\/one_percent}\\t\\t{metrics.mean_absolute_error(y_test, predict)\/one_percent}\\n\nMean squared error:\\t\\t{metrics.mean_squared_error(y_train, own_predict)\/(one_percent**2)}\\t\\t{metrics.mean_squared_error(y_test, predict)\/(one_percent**2)}\\n\nMean squared log error:\\t\\t{metrics.mean_squared_log_error(y_train, own_predict)}\\t\\t{metrics.mean_squared_log_error(y_test, predict)}\\n\nMedian absolute error:\\t\\t{metrics.median_absolute_error(y_train, own_predict)\/one_percent}\\t\\t{metrics.median_absolute_error(y_test, predict)\/one_percent}\\n\nR^2 score:\\t\\t\\t{metrics.r2_score(y_train, own_predict)}\\t\\t{metrics.r2_score(y_test, predict)}''')\n    else:\n        print(f'''\\t\\t\\t\\town evaluate \\t\\t\\tevaluate on test\nMean squared log error:\\t\\t{metrics.mean_squared_log_error(y_train, own_predict)}\\t\\t{metrics.mean_squared_log_error(y_test, predict)}\\n\n''')","a79b45e5":"my_lr = LinearRegression()\nmy_lr.fit(x_train, y_train)","c35c4c55":"my_evaluate(my_lr, x_train, y_train, x_test, y_test)","010687ed":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, RobustScaler","27e88c55":"pipe_standart = Pipeline([('scaler', StandardScaler()), ('lin_reg', LinearRegression())])\npipe_standart.fit(x_train, y_train)\nmy_evaluate(pipe_standart, x_train, y_train, x_test, y_test)","21082200":"pipe_robust = Pipeline([('scaler', RobustScaler()), ('lin_reg', LinearRegression())])\npipe_robust.fit(x_train, y_train)\nmy_evaluate(pipe_robust, x_train, y_train, x_test, y_test)","ad8102df":"'''\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043e\u0442\u0431\u043e\u0440\u0430 \u041a \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043f\u043e \u0438\u0445 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0431\u043b\u0438\u0437\u043e\u0441\u0442\u0438 \u043a \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439'''\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression # \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439 \u0432\u044b\u0445\u043e\u0434\u043d\u043e\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import ExtraTreesClassifier","7014595d":"'''\u043e\u0431\u0443\u0447\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0432\u044b\u0431\u043e\u0440\u0430 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u044f \u043a\u0441\u0438-\u043a\u0432\u0430\u0434\u0440\u0430\u0442 \u0438 \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u043b\u0443\u0447\u0448\u0438\u0435 10 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432'''\nbestfeatures = SelectKBest(score_func=f_regression, k=50)\nfit = bestfeatures.fit(x_train,y_train)\n'''\u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0441 \u0438\u0445 \u0432\u0435\u0441\u043e\u043c \u0438 \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c 10 \u043b\u0443\u0447\u0448\u0438\u0445'''\nfeatureScores =  pd.DataFrame({'Features':x_train.columns, 'Score': fit.scores_})\nprint(featureScores.nlargest(50,'Score'))","db5bc74f":"'''\u0442\u0443\u0442 \u0441\u0442\u043e\u0438\u0442 \u043f\u043e\u0438\u0433\u0440\u0430\u0442\u044c \u0441 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0438 \u043f\u0440\u043e\u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b'''\nx_train_6 = x_train[featureScores.nlargest(6,'Score').Features.values]\nx_test_6 = x_test[featureScores.nlargest(6,'Score').Features.values]\nmy_lr_6 = LinearRegression()\nmy_lr_6.fit(x_train_6, y_train)\nmy_evaluate(my_lr, x_train, y_train, x_test, y_test, 1)\nmy_evaluate(my_lr_6, x_train_6, y_train, x_test_6, y_test, 1)","74508af5":"embeded_lr_selector = SelectFromModel(LinearRegression(), max_features=6)\nembeded_lr_selector.fit(x_train, y_train)\n\nembeded_lr_support = embeded_lr_selector.get_support()\nembeded_lr_feature = x_train.loc[:,embeded_lr_support].columns.tolist()\nprint(featureScores.nlargest(6,'Score'))\nprint(str(embeded_lr_feature), 'selected features')","eab20160":"my_lr_10 = LinearRegression()\nmy_lr_10.fit(x_train[embeded_lr_feature], y_train)\nmy_evaluate(my_lr, x_train, y_train, x_test, y_test, 1)\nmy_evaluate(my_lr_10, x_train[embeded_lr_feature], y_train, x_test[embeded_lr_feature], y_test, 1)","dae7f35c":"embeded_lr_feature.extend(featureScores.nlargest(6,'Score').Features.values)\nmy_lr_12 = LinearRegression()\nmy_lr_12.fit(x_train[embeded_lr_feature], y_train)\nmy_evaluate(my_lr, x_train, y_train, x_test, y_test, 1)\nmy_evaluate(my_lr_12, x_train[embeded_lr_feature], y_train, x_test[embeded_lr_feature], y_test, 1)","90d42b29":"import seaborn as sns\n\ncorrmat = data.corr()\ntop_corr_features = corrmat.index\n# plt.figure(figsize=(20,20))\n#plot heat map\n# g=sns.heatmap(x_train[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","b30f4ad5":"data[top_corr_features].corr().loc['target', data[top_corr_features].corr().loc['target', :]>0.05]","06e339c0":"dtr = DecisionTreeRegressor()\ndtr.fit(x_train, y_train)\ndtr_6 = DecisionTreeRegressor()\ndtr_6.fit(x_train_6, y_train)\nmy_evaluate(dtr, x_train, y_train, x_test, y_test)\nmy_evaluate(dtr_6, x_train_6, y_train, x_test_6, y_test)","69d88c1f":"\u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u043c\u0435\u043d\u044c\u0448\u0435\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432. \u041e\u0442\u0431\u0438\u0440\u0430\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u0438 \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0443\u044e \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0443\u044e \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c","5834fb44":"\u0421\u0434\u0435\u043b\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438 \u0432 \u0440\u0430\u0437\u0440\u0435\u0437\u0435 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u0442\u0438\u043f\u043e\u0432 \u043c\u0435\u0442\u0440\u0438\u043a","2a8836cb":"### 1. \u0421\u0442\u0440\u043e\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0431\u0435\u0437 \u043a\u0430\u043a\u0438\u0445-\u043b\u0438\u0431\u043e \u043c\u043e\u0434\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0439 \u0434\u0430\u043d\u043d\u044b\u0445","b5a73e5c":"## \u0421\u0442\u0440\u043e\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u0438, \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 \u0434\u043e\u043c\u043e\u0432","2232fdf2":"\u0418\u0442\u0430\u043a \u0432\u0438\u0434\u0438\u043c, \u0447\u0442\u043e \u0441\u043a\u0430\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u0442 \u043b\u0438\u0448\u044c \u043a \u0443\u0445\u0443\u0434\u0448\u0435\u043d\u0438\u044e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 \u0434\u043b\u044f \u0434\u0430\u043d\u043d\u043e\u0439 \u0437\u0430\u0434\u0430\u0447\u0438","0d844f42":"### \u0412\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043b\u0443\u0447\u0448\u0438\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 (feature selection)","2ec55e10":"\u0421\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043f\u0440\u0438\u043d\u0446\u0438\u043f \u0432\u044b\u0431\u043e\u0440\u0430 \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","461eb32f":"\u0412\u044b\u0431\u043e\u0440 N \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u043b\u044c\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","d1801526":"\u0412\u0438\u0434\u0438\u043c, \u0447\u0442\u043e \u043f\u043e \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u043c \u0442\u0438\u043f\u0430\u043c \u043e\u0448\u0438\u0431\u043e\u043a \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0431\u043e\u043b\u044c\u0448\u0438\u0435 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u044f.\n\u041d\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442\u0435 \u0434\u0430\u044e\u0442 \u0431\u043e\u043b\u0435\u0435 \u0442\u043e\u0447\u043d\u0443\u044e \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438, \u0442\u0430\u043a \u043a\u0430\u043a \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u044b\u0442\u0430\u0435\u0442\u0441\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c\n\u0434\u0430\u043d\u043d\u044b\u0435, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0435\u0449\u0435 \u043d\u0435 \u0432\u0438\u0434\u0435\u043b\u0430."}}