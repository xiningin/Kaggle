{"cell_type":{"06f9902c":"code","da1e76b5":"code","b15928c9":"code","77f36852":"code","d5001e75":"code","96217e76":"code","e6152ef4":"code","935e44c9":"code","d572871a":"code","c97f8449":"code","fa3a0f47":"markdown"},"source":{"06f9902c":"import os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, utils\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nseed = 69\n\ntorch.manual_seed(seed)\nnp.random.seed(seed)","da1e76b5":"class MnistDataset(Dataset):\n    def __init__(self, csv_file, transform=None, train=True):\n        '''\n        Args:\n            csv_file (string)\n            transform (callable, optional)\n        '''\n        \n        self.mnist = pd.read_csv(csv_file)\n        self.train = train\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.mnist)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n    \n\n\n        \n        if self.train:\n            img = self.mnist.iloc[idx].values[1:]\n            img = np.reshape(img, (28,28))\n            img = img \/ 255\n            img = Image.fromarray(img)      \n            \n            label = self.mnist.iloc[idx][0]\n            label = np.array(label)\n            \n            if self.transform:\n                img = self.transform(img)\n                \n            sample = {\"label\": torch.from_numpy(label), \"image\":img}\n                \n        else:\n            \n            img = self.mnist.iloc[idx].values[0:]\n            img = np.reshape(img, (28,28))\n            img = img \/ 255\n            img = Image.fromarray(img)      \n            \n            if self.transform:\n                img = self.transform(img)\n                \n            sample = {\"image\": img}\n             \n        return sample\n\nclass ToTensor(object):\n    def __call__(self, sample):\n        image, label = sample['image'], sample['label']\n\n        return {'image': torch.from_numpy(image),\n                'label': torch.from_numpy(label)}","b15928c9":"training_split = 0.8\nbatch_size = 64\n\nmnist_train_dataset = MnistDataset(\"..\/input\/digit-recognizer\/train.csv\", transform=transforms.Compose([\n                                                                                    transforms.RandomRotation(2.8),\n                                                                                    transforms.ToTensor(),\n                                                                                    transforms.Normalize((0.130,), (0.3081)),\n                                                                                     ]))\nmnist_test_dataset = MnistDataset(\"..\/input\/digit-recognizer\/test.csv\", train=False, transform=transforms.Compose([\n                                                                                    transforms.ToTensor(),\n                                                                                    transforms.Normalize((0.130,), (0.3081)),\n                                                                                     ]))\n\ntrain_length = int(training_split * len(mnist_train_dataset))\nvalidation_length = len(mnist_train_dataset) - train_length\n\ntrain_dataset, validation_dataset = torch.utils.data.random_split(mnist_train_dataset, (train_length, validation_length))\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(mnist_test_dataset, batch_size=1, shuffle=False)","77f36852":"imgs_ = 6\nfig = plt.figure()\nplt.figure(figsize=(15,imgs_))\nfor i in range(imgs_):\n    ax = plt.subplot(1, imgs_, i+1)\n    ax.set_title('sample #{}'.format(i))\n    plt.imshow(np.reshape(mnist_train_dataset[i][\"image\"], (28,28)), cmap='gray')\n    \nplt.show()","d5001e75":"learning_rate = 0.005\ndevice = torch.device('cuda')\n#device = torch.device('cpu')\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout2d(0.25)\n        self.dropout2 = nn.Dropout2d(0.3)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\nmodel = CNN().to(device)\noptimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n# scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\ncriterion = nn.CrossEntropyLoss()","96217e76":"def train(epoch, loader, log_interval=500):\n    # Set model to training mode\n    model.train()\n    \n    # Loop over each batch from the training set\n    for batch_idx, data in enumerate(train_loader):\n        \n        variables = data[\"image\"].to(device)\n        target = data[\"label\"].to(device)\n\n        # Zero gradient buffers\n        optimizer.zero_grad() \n        \n        # Pass data through the network\n        output = model(variables)\n        # Calculate loss\n        loss = F.nll_loss(output, target)\n\n        # Backpropagate\n        loss.backward()\n        \n        # Update weights\n        optimizer.step()\n        \n        if batch_idx % log_interval == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * batch_size, len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.data.item()))\n\ndef validate(loss, accuracy_list, loader):\n    model.eval()\n    val_loss, correct = 0, 0\n    \n    for data in loader:\n        variables = data[\"image\"].to(device)\n        target = data[\"label\"].to(device)\n        \n        \n        output = model(variables)\n        val_loss += F.nll_loss(output, target, reduction='sum').item()\n        \n        pred = output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n\n    val_loss \/= len(loader)\n    loss.append(val_loss)\n\n    accuracy = 100. * correct.to(torch.float32) \/ len(loader.dataset)\n    accuracy_list.append(accuracy)\n    \n    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        val_loss, correct, len(loader.dataset), accuracy))","e6152ef4":"epochs = 65\n\nloss_, acc_ = [], []\nfor epoch in range(1, epochs + 1):\n    train(epoch, train_loader)\n    validate(loss_, acc_ , validation_loader)","935e44c9":"model.eval()\noutput_list = []\nfor idx, data in enumerate(test_loader):\n    output = model(data[\"image\"].float().to(device))\n    output_list.append([idx+1, (output.data.max(1)[1].cpu().numpy().tolist()[0])])","d572871a":"len(output_list) == len(mnist_test_dataset)\n","c97f8449":"#export to csv\npd.DataFrame(output_list, columns=[\"ImageId\", \"Label\"]).to_csv(\"predictions.csv\", index=False)","fa3a0f47":"# Running on test set"}}