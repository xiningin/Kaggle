{"cell_type":{"ce65d997":"code","b00cb7af":"code","aa15b7f7":"code","6e70d0f7":"code","6d9dd852":"code","a2b13cab":"code","328e060c":"code","b66b4b98":"code","977559c5":"code","37318e43":"code","b8354a25":"code","8f69171a":"code","a6b4ece9":"code","ef78f9b2":"code","b3a7da36":"code","62d6becf":"code","dce31461":"code","864601aa":"code","bdfdd790":"code","83083a98":"code","30690772":"code","08c4acb7":"code","3fdfc6ea":"code","5e03341b":"code","48f0f4df":"code","48a929e7":"code","171e52f8":"code","94cc1f13":"code","2898202d":"code","1b1840de":"code","51b1ddce":"code","8e1b0e09":"code","ac9eca2c":"code","180ca3c3":"code","04cea2e9":"code","879b108d":"code","ba5e1318":"code","839778ab":"code","9211de83":"code","86c1447d":"code","213a6d1e":"code","a164e35d":"code","5889c1f7":"code","59e36191":"code","dd9abbae":"code","023fe287":"code","d776f684":"markdown","aa166ba7":"markdown","18b248d4":"markdown","e4475ad7":"markdown","ae9a039e":"markdown","72c8c03c":"markdown","ed4fe94d":"markdown","d613d5cf":"markdown","2caaff1c":"markdown","16c56b18":"markdown","cd619a89":"markdown","9f810c39":"markdown","1037e37f":"markdown"},"source":{"ce65d997":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b00cb7af":"import pandas as pd","aa15b7f7":"# Read the data\ndata_churn = pd.read_csv('\/kaggle\/input\/churndataset\/Churn.csv')","6e70d0f7":"data_churn.head(2)","6d9dd852":"# Check data types and missing values\ndata_churn.info()","a2b13cab":"data_churn.shape","328e060c":"# for detailed report\n# pandas_profiling.ProfileReport(data_churn)","b66b4b98":"# Drop the columns which are not useful\ndata_churn.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)","977559c5":"# Create dummies for columns \ndf = pd.get_dummies(data_churn, ['Geography', 'Gender'], drop_first = True)","37318e43":"df.head(2)","b8354a25":"df.shape","8f69171a":"feature_columns = df.columns.difference(['Exited'])\nfeature_columns","a6b4ece9":"# Separate X variables and Y variable\nX = df[feature_columns]\ny = df['Exited']","ef78f9b2":"X.shape","b3a7da36":"y.shape","62d6becf":"# Split the data\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 111)","dce31461":"# Apply scaling transformation to converge quickly\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test  = sc.transform(X_test)","864601aa":"X_train.shape","bdfdd790":"X_train","83083a98":"X_test","30690772":"# Import the necessary libraries\nimport keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense","08c4acb7":"# Create the model with network [11, 6, 6, 1]\n\nmodel = Sequential()","3fdfc6ea":"# Model with network (11, 6, 6, 1)\n# Input layers = 11 inputs, two hidden layers with 6 neurons each and one output layer\n\n# Input layer and Hidden layer1\nmodel.add(Dense(6, activation = 'relu', input_dim = 11))\n\n# Hidden layer2\nmodel.add(Dense(6, activation = 'relu'))\n\n# Output layer\nmodel.add(Dense(1, activation = 'sigmoid'))\n","5e03341b":"# Above, we have defined the model\n\n# Now lets compile the model with loss function\/Optimizer\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","48f0f4df":"# model.fit?","48a929e7":"# fit the model\nmodel.fit(X_train, y_train, batch_size = 10, epochs = 20)","171e52f8":"# predict the test data\ny_test_pred = model.predict(X_test)\ny_test_pred","94cc1f13":"# calculate the score\nimport sklearn.metrics as metrics\n\nmetrics.roc_auc_score(y_test, y_test_pred)","2898202d":"# how to save the model\n# model.save('pavan')\n\n# how to load the model\n# from keras.models import load_model\n# model = load_model('pavan')\n\nmodel.summary()","1b1840de":"# Import necessary libraries\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport torch.utils.data\nimport torch.optim as optim","51b1ddce":"X_train","8e1b0e09":"type(X_train)","ac9eca2c":"# Convert numpy array to tensor\n\n# Train data\nX_train = torch.from_numpy(X_train)\ny_train = torch.from_numpy(y_train.values).view(-1,1)\n\n# Test data\nX_test  = torch.from_numpy(X_test)\ny_test = torch.from_numpy(y_test.values).view(-1,1)","180ca3c3":"type(X_train)","04cea2e9":"type(X_test)","879b108d":"X_train","ba5e1318":"type(y_train)","839778ab":"y_train","9211de83":"class ANN(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(ANN, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 6)           # Input layer and Hidden layer1\n        self.fc2 = nn.Linear(6,6)                    # Hidden layer1 and Hidden layer2\n        self.output_layer = nn.Linear(6, output_dim) # Hidden layer2 and Output layer\n\n    # feed forward function    \n    def forward(self,x):\n        x = F.relu(self.fc1(x))                      # Activation function for hidden layer1\n        x = F.relu(self.fc2(x))                      # Activation function for hidden layer2\n        x = F.sigmoid(self.output_layer(x))          # Activation function for output layer\n        return x\n\n","86c1447d":"# Neural network model\n\nmodel = ANN(input_dim = 11, output_dim = 1)\n\nprint(model)\n","213a6d1e":"# Loss function (Binary Cross Entropy loss)\ncriterion = nn.BCELoss()\n\n# Optimizer  \noptimizer = optim.Adam(model.parameters(), lr = 0.01)","a164e35d":"model.eval()","5889c1f7":"# calculate the loss of test data before weight updates\n\ndata_test   = Variable(X_test).float()\ntarget_test = Variable(y_test).type(torch.FloatTensor)\n\n# predict test data\ny_pred_test = model(data_test)\nbefore_train = criterion(y_pred_test.squeeze(), target_test)\n\n# Print the loss before training the test data\nprint('Test loss before training' , before_train.item())","59e36191":"model.train()\n\nfor epoch in range(1000):\n    data = Variable(X_train).float()\n    target = Variable(y_train).type(torch.FloatTensor)\n    \n    # forward pass\n    output = model(data)\n    loss   = criterion(output, target)\n    \n    # Backward pass (set grad to zero, pass the loss backward, apply optimizer and update weights)\n    optimizer.zero_grad() # Sets gradients to zero for each iteration\n    loss.backward()       # Perform backward pass to compute gradients\n    optimizer.step()      # Update weights \n    \n    if (epoch+1) % 10 == 0:\n        print ('epoch [{}\/{}], Loss: {:.3f}'.format(epoch+1, 1000, loss.item()))","dd9abbae":"# Calculate the test loss after updating the weights\n\ndata_test   = Variable(X_test).float()\ntarget_test = Variable(y_test).type(torch.FloatTensor)\n\n# predict test data\ny_pred_test = model(data_test)\nafter_train = criterion(y_pred_test.squeeze(), target_test)\n\n# Print the loss after training the test data\nprint('Test loss after training' , after_train.item())","023fe287":"metrics.roc_auc_score(y_test, y_pred_test.squeeze().detach().numpy())","d776f684":"## Pytorch","aa166ba7":"### 'Loss function' and 'Optimizer'","18b248d4":"# <center> Pytorch Implementation <center>","e4475ad7":"# <center> Keras Implementation <center>","ae9a039e":"### For better understanding of Keras\/Pytorch, please see below link\n\nhttps:\/\/deepsense.ai\/keras-or-pytorch\/","72c8c03c":"## <center> Neural network architecture <center>","ed4fe94d":"**Class 'Module' from 'nn' package is used to implement Neural network**\n\n**Layers are defined inside the constructor of the class**\n\n**Forward propagation steps are defined in forward function**\n","d613d5cf":"**Keras is a high-level API capable of running on top of TensorFlow, CNTK and Theano. It has gained favor for its ease of use and syntactic simplicity, facilitating fast development.**","2caaff1c":"### Train the model","16c56b18":"![pic.png](attachment:pic.png)","cd619a89":"## Keras","9f810c39":"## This Notebook covers basic implementation of 'keras' and 'Pytorch'","1037e37f":"**Pytorch is a lower-level API focused on direct work with array expressions. It has gained immense interest, becoming a preferred solution for academic research, and applications of deep learning requiring optimizing custom expressions.**"}}