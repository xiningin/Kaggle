{"cell_type":{"359e7202":"code","0e78a608":"code","7fd0f3b0":"code","70b5f4fa":"code","e4b929d5":"code","db6f84ab":"code","e9496eec":"code","62ea4a30":"code","0cf45dc3":"code","f43bc0cc":"code","51c29428":"code","569a7eab":"code","91558bfe":"code","87aff20a":"code","6dcb7f78":"code","b462d0b0":"code","1e7c480e":"code","086aae58":"code","a1f6039c":"code","bf22e8d9":"code","fac97ce0":"code","7a3aaf8e":"code","95872761":"code","586aa82c":"code","6ebcdca7":"code","13d2bc21":"code","fac0ecd6":"code","1386fb1c":"code","01bf9587":"code","b370fa56":"code","da212aaf":"code","f57ed401":"code","405e53d8":"code","acf7d4ec":"code","d7e8373c":"code","625fa874":"code","cc9e91fe":"code","d15aeebb":"code","d0c4ab32":"code","cbfc2584":"code","e390b5b9":"code","6517c07e":"code","8e94d2b5":"code","b82d32ee":"markdown","70c916f4":"markdown","3638177a":"markdown"},"source":{"359e7202":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e78a608":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","7fd0f3b0":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [train_df , test_df]","70b5f4fa":"print(train_df.columns.values)","e4b929d5":"'Survived' in train_df","db6f84ab":"train_df.head(5)","e9496eec":"train_df.describe","62ea4a30":"train_df.shape","0cf45dc3":"train_df.info()\nprint('--'*56)\ntest_df.info()","f43bc0cc":"cat_features = train_df.select_dtypes(include = [np.object])\ncat_features.sample(5)","51c29428":"train_df.groupby('Sex').Survived.agg(['mean' , 'count']).sort_values('count' , ascending = False)","569a7eab":"train_df.groupby('Ticket').Survived.agg(['mean' , 'count']).sort_values('count' , ascending = False)","91558bfe":"train_df.groupby('Embarked').Survived.agg(['mean' , 'count']).sort_values('count' , ascending = False)","87aff20a":"train_df.Cabin.sample(10)","6dcb7f78":"train_df.Cabin.value_counts()","b462d0b0":"train_df.corr()","1e7c480e":"'Survived' in train_df\n","086aae58":"sns.violinplot(x = 'Sex', y = 'Age'  , data = train_df)","a1f6039c":"train_df.corr()","bf22e8d9":"#Data visulaization \nsns.heatmap(train_df.corr().abs()[['Survived']].sort_values('Survived'))","fac97ce0":"features_df = train_df.drop('Survived', axis=1)\nnum_features = features_df.select_dtypes(np.number)\nnum_features.sample(5)","7a3aaf8e":"train_df.groupby('Pclass').Survived.agg(['mean' , 'count']).sort_values('count' , ascending = False)","95872761":"sns.violinplot(x = 'Sex', y = 'Pclass'  , data = train_df)","586aa82c":"train_df.groupby('Sex').Pclass.agg(['mean' , 'count']).sort_values('count' , ascending = False)","6ebcdca7":"sns.violinplot(x = 'Survived', y = 'Fare'  , data = train_df)","13d2bc21":"train_df.groupby('Fare').Survived.agg(['mean' , 'count']).sort_values('count' , ascending = False)","fac0ecd6":"cat_features = train_df.select_dtypes(include=[np.object])\ncat_features = cat_features[['Sex', 'Ticket']]\ncat_features.head(5)","1386fb1c":"pd.get_dummies(cat_features).head(5)","01bf9587":"# More robust way to do feature pre-processing.\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\nfeatures_df = train_df.drop('Survived', axis=1)\nFEATURE_COLUMNS = features_df.columns\nNUM_FEATURES = features_df.select_dtypes(include=[np.number]).columns\nCAT_FEATURES = ['Sex', 'Ticket']\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n    ('scaler', StandardScaler()),\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('one_hot', OneHotEncoder(handle_unknown='ignore')),\n])\n\npreprocessor = ColumnTransformer(\n  transformers=[\n      ('num', numeric_transformer, NUM_FEATURES),\n      ('cat', categorical_transformer, CAT_FEATURES)\n  ])","b370fa56":"features_df = preprocessor.fit_transform(train_df.drop('Survived', axis=1))\nfeatures_df.shape","da212aaf":"features_df","f57ed401":"target = train_df['Survived']\ntarget.shape","405e53d8":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features_df, target, test_size=0.25)","acf7d4ec":"from sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nbaseline = DummyClassifier(strategy='most_frequent')\n#model = LogisticRegressionCV()\nmodel = RandomForestClassifier()","d7e8373c":"baseline.fit(x_train, y_train)\nmodel.fit(x_train, y_train)","625fa874":"from sklearn.metrics import classification_report\nbaseline_predictions = baseline.predict(x_test)\nmodel_predictions = model.predict(x_test)","cc9e91fe":"print(classification_report(y_test, baseline_predictions))","d15aeebb":"print(classification_report(y_test, model_predictions))","d0c4ab32":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')","cbfc2584":"sub_model = RandomForestClassifier()\nsub_model.fit(features_df, target)\n\ntest_features = preprocessor.transform(test_df[train_df.drop('Survived', axis=1).columns])\npredictions = sub_model.predict(test_features)","e390b5b9":"sub_df = pd.DataFrame({'PassengerId' : test_df.PassengerId, 'Survived': predictions})\nsub_df.head()","6517c07e":"sub_df.to_csv('titanic_gender_submission.csv', index=False)","8e94d2b5":"%ls '..\/input'","b82d32ee":"# Analyse by describing data :\npandas also helps desribe the datasets answering following questions early in our project.\n# which features are avilable in the dataset ?\nnoting the features names for directly manipluating or analyzing these , These features names are described on the kaggle data here ","70c916f4":"# Validation","3638177a":"# Acquire data :\nThe Python pandas as package helps us work with our datasets, we start by acquiring the training and testing dataset into pandas DataFrame , we also combine these datasets to run certain operations on both datasets together"}}