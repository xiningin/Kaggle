{"cell_type":{"ba6567ce":"code","df9cf39e":"code","d49a95cb":"code","ce68c9b2":"code","6a78632e":"code","31c77ec9":"code","6a4f103a":"code","b8eab882":"code","b9381ffe":"code","598712e9":"code","f1209700":"code","13fb11aa":"code","1464e1fe":"code","11bcecaf":"code","031909ce":"code","c2ff5006":"code","2b3a49b0":"code","1bbe0d99":"code","60f71cf6":"code","b826c002":"code","a08cc360":"markdown","9a77957c":"markdown","9a2aa679":"markdown","e8d453d4":"markdown","7b9c027b":"markdown","1a717037":"markdown","ec3dac52":"markdown","9445cc2b":"markdown","0c041a40":"markdown","023ddcd7":"markdown","7c53a4ed":"markdown","06ac6fe1":"markdown"},"source":{"ba6567ce":"# Arquivo de dados\nimport os\nprint(os.listdir(\"..\/input\"))","df9cf39e":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn_pandas import CategoricalImputer\nimport seaborn as sns\nimport matplotlib.pyplot as plt","d49a95cb":"df = pd.read_csv(\"\/kaggle\/input\/hmeq.csv\")\ndf.head(5)","ce68c9b2":"df.info()","6a78632e":"df.isnull().sum().sort_values()","31c77ec9":"df.JOB.value_counts(dropna=False)","6a4f103a":"# Para os casos NAN de job vamos considerar desempregado\ndf.JOB = df.JOB.fillna(\"Unemployed\")","b8eab882":"df.REASON.value_counts(dropna=False)","b9381ffe":"#Para os casos NAN vamos considerar que n\u00e3o se sabe, \"Unknown\"\ndf.REASON = df.REASON.fillna(\"Unknown\")","598712e9":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","f1209700":"df.hist(bins=30, figsize=(15, 10))\nplt.show()","13fb11aa":"df.fillna(0,inplace=True)","1464e1fe":"df_dum = pd.get_dummies(df, columns=[\"REASON\",\"JOB\"], drop_first=True)","11bcecaf":"df_dum.head(5)","031909ce":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier as RFC\nfrom sklearn.model_selection import GridSearchCV\n\nX, y = df_dum.drop(\"BAD\",axis=1),df_dum[\"BAD\"]\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.2, random_state=42)\n\n\nrfc = RFC(n_estimators=100)\nrfc.fit(X_train,y_train)\ny_pred = rfc.predict(X_valid)","c2ff5006":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\naccuracy = accuracy_score(y_valid, y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0),\"\\n\")\nconf_mat = confusion_matrix(y_true=y_valid, y_pred=y_pred)\nprint('Confusion matrix:\\n', conf_mat)\nprint('\\nClassification Report:\\n',classification_report(y_valid, y_pred))","2b3a49b0":"n_estimators = [100, 110,120]\nmax_depth = [5, 8, 15, 25, 30]\nmin_samples_split = [2, 5]\nmin_samples_leaf = [1, 2, 5] \n\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf)\n\ngridF = GridSearchCV(RFC(), hyperF, cv = 3, verbose = 1, \n                      n_jobs = -1)\nbestF = gridF.fit(X_train, y_train)","1bbe0d99":"bestF.best_params_","60f71cf6":"rfc = RFC(max_depth= 25,\n            min_samples_leaf= 1,\n            min_samples_split= 2,\n            n_estimators= 120)\nrfc.fit(X_train,y_train)\ny_pred = rfc.predict(X_valid)\naccuracy = accuracy_score(y_valid, y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0),\"\\n\")\nconf_mat = confusion_matrix(y_true=y_valid, y_pred=y_pred)\nprint('Confusion matrix:\\n', conf_mat)\nprint('\\nClassification Report:\\n',classification_report(y_valid, y_pred))","b826c002":"print('Confusion matrix:\\n', conf_mat)","a08cc360":"Depois do tuning de hyperameter a perforamnce de nosso modelo caiu, preferiu-se deixar a padr\u00e3o, por\u00e9m n_estimators = 100","9a77957c":"**B\u00f4nus 3:**\n    \nExplique o que \u00e9 `recall` na matriz de confus\u00e3o acima e d\u00ea 1 exemplo onde isso pode ser \u00fatil.","9a2aa679":"# IESB\n# Gradua\u00e7\u00e3o em Ci\u00eancia de Dados\n## Disciplina - Minera\u00e7\u00e3o de Dados e Intelig\u00eancia Computacional\n## Avalia\u00e7\u00e3o - 04\/05\/2020\n\n### Descri\u00e7\u00e3o\nA base de dados \"Home Equity\" possui dados pessoas e informa\u00e7\u00f5es de empr\u00e9stimo de 5.960 empr\u00e9stimos recentes. Para cada empr\u00e9stimo existem 12 vari\u00e1veis registradas.\nA vari\u00e1vel alvo (`BAD`) indica quando o cliente n\u00e3o pagou o empr\u00e9stimo (valor 1), e quando ele honrou o compromisso (valor 0).\n\n### Objetivo\nCriar um modelo de ML usando RandomForest para prever se determinado cliente ir\u00e1 ou n\u00e3o honrar o empr\u00e9stimo contra\u00eddo.\n\nO desempenho do modelo deve ser medido pela m\u00e9trica de acur\u00e1cia (`accuracy_score`).","e8d453d4":"## Quest\u00e3o 2\n- Os dados foram importados corretamente, os tipos est\u00e3o corretos","7b9c027b":"## Quest\u00e3o 1\n- Dados carregados","1a717037":"**Itens avaliados:**\n\n1. Carregamento dos dados\n2. Verifica\u00e7\u00e3o para saber se os dados foram importados corretamente\n3. Pr\u00e9-processamento dos dados (preenchimento de valores em branco, transforma\u00e7\u00e3o de texto em n\u00famero)\n4. Separar dados em treino e valida\u00e7\u00e3o\n5. Instanciar e treinar uma `RandomForest`\n6. Avalia\u00e7\u00e3o da performance do modelo pela m\u00e9trica de acur\u00e1cia (`accuracy_score`).\n7. Buscar a melhoria da acur\u00e1cia mudando os par\u00e2metros do modelo RandomForest.","ec3dac52":"# B\u00f4nus\n\nAp\u00f3s terminar o exerc\u00edcio e verificar que est\u00e1 cumprindo todos os itens a serem avaliados, voc\u00ea pode fazer os itens a seguir para ganhar pontos extra na prova:","9445cc2b":"**B\u00f4nus 1:**\n    \nPlote uma matriz de confus\u00e3o nas previs\u00f5es dos dados de valida\u00e7\u00e3o.","0c041a40":"- Precis\u00e3o avalia quanto dos casos que n\u00e3o previmos como positive na verdade s\u00e3o positive. Isso pode ser \u00fatil quando devemos priorizar n\u00e3o ter um erro em meio do que dizemos ser positivo.\n- Por exemplo n\u00f3s n\u00e3o queremos errar o lan\u00e7amento de foguete para outra planeta. Nossa rota prevista tem que estar correta.\n- ou no caso acima, se for priorizada a precis\u00e3o, isso signfica que quando o cara \u00e9 mal pagante, n\u00f3s queremos ter mais certeza poss\u00edvel de que n\u00e3o ser\u00e1 tomada medidas dr\u00e1sticas contra a pessoa errada. Ou seja, n\u00f3s somos mais abertos a mal pagantes adentrarem em nosso esquema.","023ddcd7":"## Quest\u00e3o 3\n- Foi aplicado fillna 0 nas colunas n\u00famero e fillna(string) apropriada para cada caso de coluna objeto\n- Foi feito o getdummies apropriado","7c53a4ed":"**B\u00f4nus 2:**\n    \nExplique o que \u00e9 `precis\u00e3o` na matriz de confus\u00e3o acima e d\u00ea 1 exemplo onde isso pode ser \u00fatil.","06ac6fe1":"- Recall avalia quanto dos casos que deveriamos prever como positive n\u00e3o previmos.\n- No caso do modelo acima, avaliaria quantos porcentos de n\u00e3o pagantes previmos dentre todos os pagantes.\n- Essa m\u00e9trica pode ser priorizada, quando queremos ter certeza que englobamos todos os n\u00e3o pagantes, e n\u00e3o fazemos tanta quest\u00e3o de confundir um bom pagante por um mal pagante. Ou seja temos politica zero de abertura a mal pagantes."}}