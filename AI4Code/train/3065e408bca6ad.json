{"cell_type":{"a6f7b6bd":"code","87e9caf4":"code","a66e98c0":"code","d5983501":"code","368d7c2b":"code","52a29848":"code","bc184c62":"code","f1aa16d1":"code","f0143711":"code","206a8290":"markdown","45940425":"markdown"},"source":{"a6f7b6bd":"!pip install talos","87e9caf4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.activations import relu, elu\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K\nimport talos as ta\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.preprocessing.image import img_to_array\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport PIL \nfrom keras import regularizers\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nimport keras\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport random\nimport pickle\nimport cv2\nimport os\n\n# Any results you write to the current directory are saved as output.","a66e98c0":"train = pd.read_csv('..\/input\/sign_mnist_train.csv')\ntest = pd.read_csv('..\/input\/sign_mnist_test.csv')\nlabels = train['label'].values\ntrain.drop('label', axis = 1, inplace = True)\nimages = train.values\nimages = np.array([np.reshape(i, (28, 28)) for i in images])\nimages = np.array([i.flatten() for i in images])\nfrom sklearn.preprocessing import LabelBinarizer\nlabel_binrizer = LabelBinarizer()\nlabels = label_binrizer.fit_transform(labels)","d5983501":"x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3)","368d7c2b":"x_train = x_train \/ 255\nx_test = x_test \/ 255\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","52a29848":"aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n            horizontal_flip=True, fill_mode=\"nearest\")\n\nparams = {'lr': (0.1, 0.01,1 ),\n     'epochs': [10,5,15],\n     'dropout': (0, 0.40, 0.8),\n     'optimizer': [\"Adam\",\"Adagrad\",\"sgd\"],\n     'loss': [\"binary_crossentropy\",\"mean_squared_error\",\"mean_absolute_error\"],\n     'last_activation': [\"softmax\",\"sigmoid\"],\n     'activation' :[\"relu\",\"selu\",\"linear\"],\n     'clipnorm':(0.0,0.5,1),\n     'decay':(1e-6,1e-4,1e-2),\n     'momentum':(0.9,0.5,0.2),\n     'l1': (0.01,0.001,0.0001),\n     'l2': (0.01,0.001,0.0001),\n     'No_of_CONV_and_Maxpool_layers':[1,2],\n     'No_of_Dense_Layers': [2,3,4],\n     'No_of_Units_in_dense_layers':[64,32],\n     'Kernal_Size':[(3,3),(5,5)],\n     'Conv2d_filters':[60,40,80,120],\n     'pool_size':[(3,3),(5,5)],\n     'padding':[\"valid\",\"same\"]\n    }\n\n","bc184c62":"def Talos_Model(X_train, y_train, X_test, y_test, params):\n    #parameters defined\n    lr = params['lr']\n    epochs=params['epochs']\n    dropout_rate=params['dropout']\n    optimizer=params['optimizer']\n    loss=params['loss']\n    last_activation=params['last_activation']\n    activation=params['activation']\n    clipnorm=params['clipnorm']\n    decay=params['decay']\n    momentum=params['momentum']\n    l1=params['l1']\n    l2=params['l2']\n    No_of_CONV_and_Maxpool_layers=params['No_of_CONV_and_Maxpool_layers']\n    No_of_Dense_Layers =params['No_of_Dense_Layers']\n    No_of_Units_in_dense_layers=params['No_of_Units_in_dense_layers']\n    Kernal_Size=params['Kernal_Size']\n    Conv2d_filters=params['Conv2d_filters']\n    pool_size_p=params['pool_size']\n    padding_p=params['padding']\n    \n    #model sequential\n    model=Sequential()\n    \n    for i in range(0,No_of_CONV_and_Maxpool_layers):\n        model.add(Conv2D(Conv2d_filters, Kernal_Size ,padding=padding_p))\n        model.add(Activation(activation))\n        model.add(MaxPooling2D(pool_size=pool_size_p,strides=(2,2)))\n    \n    \n    model.add(Flatten())\n    \n    for i in range (0,No_of_Dense_Layers):\n        model.add(Dense(units=No_of_Units_in_dense_layers,activation=activation, kernel_regularizer=regularizers.l2(l2),\n                  activity_regularizer=regularizers.l1(l1)))\n    \n    \n    model.add(Dense(units=40,activation=activation))\n    \n    model.add(Dense(units=24,activation=activation))\n    if optimizer==\"Adam\":\n        opt=keras.optimizers.Adam(lr=lr, decay=decay, beta_1=0.9, beta_2=0.999)\n    if optimizer==\"Adagrad\":\n        opt=keras.optimizers.Adagrad(lr=lr, epsilon=None, decay=decay)\n    if optimizer==\"sgd\":\n        opt=keras.optimizers.SGD(lr=lr, momentum=momentum, decay=decay, nesterov=False)\n    \n    model.compile(loss=loss,optimizer=opt,\n                 metrics=['accuracy'])\n    \n    out = model.fit(X_train, y_train, epochs=params['epochs'])\n\n    return out,model","f1aa16d1":"h = ta.Scan(x_train, y_train, params=params, model=Talos_Model, dataset_name='DR', experiment_no='1', grid_downsample=.01)","f0143711":"r = ta.Reporting(h)\n\nr.best_params()","206a8290":"# About \nIn this notebook you will learn\n\nHow to select your hyperparameters With the help of talos Library\nWe will Optimize the values of \n\n\n* Learning Rate\n* Epochs\n* Dropout\n* Optimizer\n* Loss Function\n* last Activation\n* Activation\n* ClipNorm\n* Decay\n* Momentum\n* L1 Regularization\n* L2 Regularization\n* Number of Convolutional and MaxPooling Layer\n* Number of Dense Layer\n* Number of Dense Units\n* Kernal Size\n* Conv2s Filters\n* Pool Size\n* Padding\n\n\n","45940425":"# Now after this you Get your Hyperparameters\nYou can also use random search and grid Search for this."}}