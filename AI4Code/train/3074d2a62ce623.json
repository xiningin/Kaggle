{"cell_type":{"7016310f":"code","5ff987b4":"code","1b78370f":"code","21ebfabb":"code","a2e4dcad":"code","f5ea2afc":"code","f066ea55":"code","a2a9ad2b":"code","ed171ce5":"code","3dea5558":"code","0ba94943":"code","d14cb57f":"markdown","6ca8f20f":"markdown"},"source":{"7016310f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn import *\nimport nltk, datetime\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5ff987b4":"train = pd.read_csv('..\/input\/sales_train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nitems = pd.read_csv('..\/input\/items.csv')\nitem_categories = pd.read_csv('..\/input\/item_categories.csv')\nshops = pd.read_csv('..\/input\/shops.csv')\nprint('train:', train.shape, 'test:', test.shape)","1b78370f":"train.head()","21ebfabb":"submission.head()","a2e4dcad":"train.item_cnt_day.plot()\nplt.title(\"Number of products sold per day\");","f5ea2afc":"train.item_price.hist()\nplt.title(\"Item Price Distribution\");","f066ea55":"from wordcloud import WordCloud\nimport random\n\ndef grey_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n    return \"hsl(0, 0%%, %d%%)\" % random.randint(60, 100)\n\nitem = ' '.join(items.item_name).lower()\n# wordcloud for display address\nplt.figure(figsize=(12,6))\nwc = WordCloud(background_color='gold', max_font_size=200,\n                            width=1600,\n                            height=800,\n                            max_words=400,\n                            relative_scaling=.5).generate(item)\nplt.imshow(wc.recolor(color_func=grey_color_func, random_state=3))\n#plt.imshow(wc)\nplt.title(\"Items\", fontsize=20)\nplt.savefig('items-wordcloud.png')\nplt.axis(\"off\");","a2a9ad2b":"from wordcloud import WordCloud\nimport random\n\n\nitem_cat = ' '.join(item_categories.item_category_name).lower()\n# wordcloud for display address\nplt.figure(figsize=(12,6))\nwc = WordCloud(background_color='black', max_font_size=200,\n                            width=1600,\n                            height=800,\n                            max_words=400,\n                            relative_scaling=.5).generate(item_cat)\nplt.imshow(wc)\n#plt.imshow(wc)\nplt.title(\"Items Categories\", fontsize=20)\nplt.savefig('items-cat-wordcloud.png')\nplt.axis(\"off\");","ed171ce5":"from wordcloud import WordCloud\nimport random\n\n\nshop = ' '.join(shops.shop_name).lower()\n# wordcloud for display address\nplt.figure(figsize=(12,6))\nwc = WordCloud(background_color='white', max_font_size=200,\n                            width=1600,\n                            height=800,\n                            max_words=400,\n                            relative_scaling=.5).generate(shop)\nplt.imshow(wc)\n#plt.imshow(wc)\nplt.title(\"shops\", fontsize=20)\nplt.savefig('shops-wordcloud.png')\nplt.axis(\"off\");","3dea5558":"#Make Monthly\ntrain['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')\ntrain['month'] = train['date'].dt.month\ntrain['year'] = train['date'].dt.year\ntrain = train.drop(['date','item_price'], axis=1)\ntrain = train.groupby([c for c in train.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\ntrain = train.rename(columns={'item_cnt_day':'item_cnt_month'})\n#Monthly Mean\nshop_item_monthly_mean = train[['shop_id','item_id','item_cnt_month']].groupby(['shop_id','item_id'], as_index=False)[['item_cnt_month']].mean()\nshop_item_monthly_mean = shop_item_monthly_mean.rename(columns={'item_cnt_month':'item_cnt_month_mean'})\n#Add Mean Feature\ntrain = pd.merge(train, shop_item_monthly_mean, how='left', on=['shop_id','item_id'])\n#Last Month (Oct 2015)\nshop_item_prev_month = train[train['date_block_num']==33][['shop_id','item_id','item_cnt_month']]\nshop_item_prev_month = shop_item_prev_month.rename(columns={'item_cnt_month':'item_cnt_prev_month'})\nshop_item_prev_month.head()\n#Add Previous Month Feature\ntrain = pd.merge(train, shop_item_prev_month, how='left', on=['shop_id','item_id']).fillna(0.)\n#Items features\ntrain = pd.merge(train, items, how='left', on='item_id')\n#Item Category features\ntrain = pd.merge(train, item_categories, how='left', on='item_category_id')\n#Shops features\ntrain = pd.merge(train, shops, how='left', on='shop_id')\n","0ba94943":"test['month'] = 11\ntest['year'] = 2015\ntest['date_block_num'] = 34\n#Add Mean Feature\ntest = pd.merge(test, shop_item_monthly_mean, how='left', on=['shop_id','item_id']).fillna(0.)\n#Add Previous Month Feature\ntest = pd.merge(test, shop_item_prev_month, how='left', on=['shop_id','item_id']).fillna(0.)\n#Items features\ntest = pd.merge(test, items, how='left', on='item_id')\n#Item Category features\n\ntest = pd.merge(test, item_categories, how='left', on='item_category_id')\n#Shops features\ntest = pd.merge(test, shops, how='left', on='shop_id')\ntest['item_cnt_month'] = 0.\n","d14cb57f":"### Feature Engineering\n#### Text features","6ca8f20f":"###  Target Variable Item count per day for month"}}