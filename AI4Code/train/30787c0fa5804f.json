{"cell_type":{"275d816b":"code","59ae9600":"code","cf516f65":"code","41fcffe2":"code","b3b62cb3":"code","a84acab3":"code","7f173e63":"code","a37539d9":"code","fcbac42e":"code","f0082339":"code","36b3cc08":"code","2db1f13f":"code","cdab4dd6":"code","8eb09df3":"code","74eec929":"code","0be19566":"code","b46d574b":"code","364e41d9":"code","eecc4a52":"code","65bb130b":"code","a85cbf2e":"code","0c05d78e":"code","12a23957":"markdown"},"source":{"275d816b":"!pip install \/kaggle\/input\/kerasapplications -q\n!pip install \/kaggle\/input\/efficientnet-keras-source-code\/ -q --no-deps\n\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport re\nimport tensorflow_addons as tfa\nimport efficientnet.tfkeras as efn","59ae9600":"root_dir = \"..\/input\/ranzcr-clip-catheter-line-classification\"  \nimages_train_dir = os.path.join(root_dir, \"train\")\ntrain_dir = os.path.join(root_dir, 'train.csv')\ntrain_annotations_dir = os.path.join(root_dir, 'train_annotations.csv')","cf516f65":"train_df = pd.read_csv(train_dir)\nprint(\"there are: \" + str(train_df.shape[0]) + \" datapoints\" )\ndisplay(train_df.head(10))","41fcffe2":"print(\"There are: \" + str(train_df['PatientID'].unique().shape[0]) + \" Unique patients\")","b3b62cb3":"_ = plt.figure(figsize = (7,7))\nsns.barplot(x = train_df.columns[1:-1] ,y = train_df.sum(axis = 0)[1:-1])\nplt.xticks(rotation = 60) \nplt.show()","a84acab3":"annotations_pd = pd.read_csv(train_annotations_dir)\ndisplay(annotations_pd.head(10))","7f173e63":"def draw_circle(coordinate, image):\n    \n    image = cv2.circle(image, coordinate, 10, (255,0,0), 30)\n    \n    return image\n\ndef annotate_image(image, annotations):\n    \n    annotations = re.sub(r'[\\[\\],]', '', annotations).split()\n    \n    for i in range(len(annotations) \/\/2):\n        \n        coordinates = (int(annotations[i*2]), int(annotations[i * 2 + 1]))\n        image = draw_circle(coordinates, image)\n    \n    return image","a37539d9":"for i in range(8):\n    \n    image_dir = os.path.join(images_train_dir, str(annotations_pd.iloc[i,0]) + \".jpg\")\n    image = cv2.imread(image_dir, cv2.IMREAD_COLOR)\n    _ = plt.figure(figsize =(10,10))\n    plt.subplot(1,2,1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    image = annotate_image(image, annotations_pd.iloc[i,2])\n    plt.subplot(1,2,2)\n    plt.imshow(image)\n    plt.title(\"Annotated Image\")\n    plt.show()","fcbac42e":"seed = 456\nbatch_size = 2\nnp.random.seed(seed)\ntf.random.set_seed(seed)","f0082339":"train_dir_tfr = os.path.join(root_dir, \"train_tfrecords\")","36b3cc08":"#functions to read the TFRecords\n\nimage_size = 750\nautotune = tf.data.experimental.AUTOTUNE\n\nfeature_map = {\n        'ETT - Abnormal' : tf.io.FixedLenFeature([], tf.int64),\n        'ETT - Borderline' : tf.io.FixedLenFeature([], tf.int64),\n        'ETT - Normal' : tf.io.FixedLenFeature([], tf.int64),\n        \"NGT - Abnormal\" : tf.io.FixedLenFeature([], tf.int64),\n        'NGT - Borderline' : tf.io.FixedLenFeature([], tf.int64),\n        'NGT - Incompletely Imaged' : tf.io.FixedLenFeature([], tf.int64),\n        'NGT - Normal' : tf.io.FixedLenFeature([], tf.int64),\n        'CVC - Abnormal' : tf.io.FixedLenFeature([], tf.int64),\n        'CVC - Borderline': tf.io.FixedLenFeature([], tf.int64),\n        'CVC - Normal': tf.io.FixedLenFeature([], tf.int64),\n        'StudyInstanceUID' : tf.io.FixedLenFeature([], tf.string),\n        'Swan Ganz Catheter Present' : tf.io.FixedLenFeature([], tf.int64),\n        'image' : tf.io.FixedLenFeature([], tf.string)\n        }\n\ndef read_tfr(example):\n    \n    example = tf.io.parse_single_example(example, feature_map)\n    \n    image = tf.io.decode_jpeg(example['image'])\n    \n    image = tf.image.grayscale_to_rgb(image)\n    \n    image = tf.image.resize(image, (image_size,image_size))\n    \n    if augm:\n        \n        image = augment(image)\n    \n    \n    image = image \/ 255\n    \n    features = tf.stack([\n        example['ETT - Abnormal'],\n        example['ETT - Borderline'],\n        example['ETT - Normal'],\n        example[\"NGT - Abnormal\"],\n        example['NGT - Borderline'],\n        example['NGT - Incompletely Imaged'],\n        example['NGT - Normal'],\n        example['CVC - Abnormal'],\n        example['CVC - Borderline'],\n        example['CVC - Normal'],\n        example['Swan Ganz Catheter Present']\n        ])\n    \n    \n    return image, features\n\n\ndef load_ds(filenames, aug):\n    \n    tfrecords = tf.data.TFRecordDataset(filenames)\n    \n    tfrecords = tfrecords.map(read_tfr, num_parallel_calls = autotune)\n    \n    return tfrecords\n\ndef augment(image):\n    \n    decider = tf.random.uniform(shape = (1,1), minval = 0, maxval = 1)\n    \n    if decider > 0.5:\n        dx_dy = tf.random.uniform(shape = (1,2), minval = -20, maxval = 20)\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n        image = tf.image.random_brightness(image, 0.5)\n        image = tf.image.random_contrast(image, 0.2, 0.5)\n\n        image = tfa.image.translate(image, dx_dy)\n\n    \n    return image\n\ndef class_func(images, label):\n    return label\n    \n    \ndef get_ds(filenames, aug):\n    \n    global augm\n    \n    augm = aug\n\n    \n    ds = load_ds(filenames,augm)\n    ds = ds.batch(batch_size)\n    #ds = ds.shuffle(512)\n    #ds = ds.cache()\n    ds = ds.repeat()\n    ds = ds.prefetch(autotune)\n    \n    return ds\n    ","2db1f13f":"#splitting the dataset\nvalidation_split = 0.2\nTFR_fnames = tf.io.gfile.glob(train_dir_tfr + '\/*.tfrec')\nTFR_fnames_train = TFR_fnames[int(len(TFR_fnames) * validation_split):]\nTFR_fnames_valid = TFR_fnames[:int(len(TFR_fnames) * validation_split)]","cdab4dd6":"train_ds = get_ds(TFR_fnames_train, True)\nvalid_ds = get_ds(TFR_fnames_valid, False)","8eb09df3":"# creating the model\ndef create_model(base_model):\n    \n    inputs = tf.keras.Input(shape = (image_size, image_size, 3,))\n    med_out = base_model(inputs)\n    med_out = tf.keras.layers.GlobalAveragePooling2D()(med_out)\n  # med_out = tf.keras.layers.Dense(1024, activation = 'relu')(med_out)\n    outputs = tf.keras.layers.Dense(11, activation = 'sigmoid')(med_out)\n    \n    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n    \n    model.summary()\n    \n    optimizer = tf.keras.optimizers.Adam(9e-6)\n    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = [tf.keras.metrics.AUC(multi_label=True)])\n    \n    return model\n\nEfficientNet = efn.EfficientNetB7(\n        include_top = False,\n        weights = '..\/input\/efficientnet-b7-no-top-keras\/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5',\n        input_shape = (image_size, image_size,3))\n\n\nefficient = create_model(EfficientNet)\n\nefficient.load_weights(\"..\/input\/catheter-models-trained-with-tpu\/efficientB7.h5\")\n","74eec929":"train_samples = sum(1 for _ in tf.data.TFRecordDataset(TFR_fnames_train))\nvalid_samples = sum(1 for _ in tf.data.TFRecordDataset(TFR_fnames_valid))\nprint(\"There are: \" + str(train_samples) + \" train samples and \" + str(valid_samples) + \" validation samples\")","0be19566":"#epochs = 15\n\n#callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_auc',\n#                                              mode = 'max',\n#                                             patience = 1  ,\n#                                             restore_best_weights = True)]\n\n#efficient.fit(train_ds, epochs = epochs,\n#             validation_data = valid_ds, steps_per_epoch = train_samples\/\/batch_size,\n#             validation_steps = valid_samples \/\/ batch_size, callbacks = callbacks)","b46d574b":"#callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_auc_1',\n                                             # mode = 'max',\n                                             #patience = 1  ,\n                                             #restore_best_weights = True)]\n\n#resnet50.fit(train_ds, epochs = epochs,\n#             validation_data = valid_ds, steps_per_epoch = train_samples\/\/batch_size,\n#             validation_steps = valid_samples \/\/ batch_size, callbacks = callbacks)","364e41d9":"train_ds = None\nvalid_ds = None\ntest_dir = \"..\/input\/ranzcr-clip-catheter-line-classification\/test_tfrecords\"\nTFR_fnames_test = tf.io.gfile.glob(test_dir + '\/*.tfrec')\n\ntest_feature_map = {\n    \"StudyInstanceUID\" : tf.io.FixedLenFeature([], tf.string),\n    \"image\" : tf.io.FixedLenFeature([], tf.string)\n    }\n\ndef read_tfr(example):\n    \n    example = tf.io.parse_single_example(example, test_feature_map)\n    \n    image = tf.io.decode_jpeg(example['image'])\n    \n    image = tf.image.resize(image, (image_size,image_size))\n    \n    image = tf.image.grayscale_to_rgb(image)\n    \n    image = image \/ 255\n    \n    return image\n\n\n\ndef load_ds(filenames):\n    \n    tfrecords = tf.data.TFRecordDataset(filenames)\n    \n    tfrecords = tfrecords.map(read_tfr, num_parallel_calls = autotune)\n    \n    return tfrecords\n    \n    \ndef get_ds(filenames):\n    \n    ds = load_ds(filenames)\n    ds = ds.batch(4)\n    ds = ds.prefetch(autotune)\n    \n    return ds\n\ndef read_ids(example):\n    \n    example = tf.io.parse_single_example(example, test_feature_map)\n    ids = example['StudyInstanceUID']\n    \n    \n    return ids\n\ndef load_ds_ids(filenames):\n    \n    tfrecords = tf.data.TFRecordDataset(filenames)\n    \n    tfrecords = tfrecords.map(read_ids, num_parallel_calls = autotune)\n    \n    return tfrecords\n    \n    \ndef get_ds_ids(filenames):\n    \n    ds = load_ds_ids(filenames)\n    ds = ds.batch(test_samples)\n    ds = ds.prefetch(autotune)\n    \n    return ds\n\ntest_samples = sum(1 for _ in tf.data.TFRecordDataset(TFR_fnames_test))\ntest_ds = get_ds(TFR_fnames_test)\ntest_ids = get_ds_ids(TFR_fnames_test)","eecc4a52":"results1 = efficient.predict(test_ds, batch_size = 4)\n#results2 = resnet50.predict(test_ds, batch_size = 4)\n#results = (results1 + results2) \/ 2\nresults = pd.DataFrame(results1)","65bb130b":"#getting the ids of the test_results\nids = next(iter(test_ids)).numpy()\nfor i in range(ids.shape[0]):\n    ex = str(ids[i])\n    ex = ex[2:-1]\n    ids[i] = ex\nids = pd.Series(ids)","a85cbf2e":"columns = ['StudyInstanceUID', 'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n           \"NGT - Abnormal\", 'NGT - Borderline','NGT - Incompletely Imaged',\n           'NGT - Normal', 'CVC - Abnormal','CVC - Borderline',\n           'CVC - Normal','Swan Ganz Catheter Present']","0c05d78e":"results_df = pd.concat([ids, results], axis = 1)\nresults_df.columns = columns \ndisplay(results_df.head(10))\nresults_df.to_csv('submission.csv', index = False)","12a23957":"Checking for unique patients"}}