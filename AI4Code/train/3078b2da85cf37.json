{"cell_type":{"3602fd1a":"code","adba2509":"code","1ff43a53":"code","fb026139":"code","af486d49":"code","083b0149":"code","1b45e5f4":"code","cc68e30c":"code","1495cd89":"code","7ba8d4b5":"code","b4393a0e":"code","92e742f0":"code","13ecdbd0":"code","8e2d4125":"code","fae9c1c1":"code","c8dbf74c":"code","9c67fc11":"code","7f5103e1":"code","aa083143":"code","0fea831d":"code","eb117eb9":"code","e32b9b32":"code","2847a8b5":"code","7800c00a":"code","30ad3caa":"code","b4f84a8b":"code","044b085e":"code","64edcd6a":"code","69f83191":"code","42eb0c03":"code","0ced2709":"code","806cca6a":"code","cdbde12a":"code","2a74ea10":"code","a95e7751":"code","998429f7":"code","6f10b5cf":"code","029026cf":"code","59956e57":"code","6175b4ae":"code","d8e81219":"code","25ddd065":"code","e39dc92b":"code","072035a8":"code","6c4eebef":"code","130cbe38":"code","e43271b5":"code","b0b80f40":"markdown","8956ef7d":"markdown","39995ef3":"markdown","c9caee03":"markdown","22c403d1":"markdown","dad3584f":"markdown","a717d70a":"markdown","8259bc48":"markdown","953144ee":"markdown","36aec0b2":"markdown","8a0d38fc":"markdown","4079c4a2":"markdown","3b8c2572":"markdown","1812ea0b":"markdown","bfcda069":"markdown","ef3c59d8":"markdown"},"source":{"3602fd1a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","adba2509":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n\ntrain.head()","1ff43a53":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntest.head()","fb026139":"train['Pclass'].value_counts().plot(kind='bar')\n# Third class has more passengers as compared to first and second, so it is a unbalanced data.","af486d49":"train['Sex'].value_counts().plot(kind='bar')\n# Males are more than females","083b0149":"train['Age'].hist()\n# Right Tailed distribution","1b45e5f4":"train['SibSp'].hist()","cc68e30c":"train['Parch'].hist()","1495cd89":"train['Embarked'].value_counts().plot(kind='bar')","7ba8d4b5":"train['Survived'].value_counts().plot(kind='bar')\n#UNBALANCED, Classifiers would be the best approach","b4393a0e":"#Survived and Sex\nSS = pd.crosstab(train['Survived'],train['Sex'])\nSS.div(SS.sum(1),axis=0).plot(kind='bar',stacked=True) # Dividing for proportion\n#This shows that the proportion of males survived is less than the proportion of females.","92e742f0":"#Survived with age\n#Age is between 0.42 to 80\n\nbins = [0,5,15,25,40,60,80]\ngroup = ['Infants','Kids','Young','Adults','Old','Elder']\ntrain['Age_bin']=pd.cut(train['Age'],bins,labels=group)\nSA= pd.crosstab(train['Age_bin'],train['Survived'])\nSA.div(SA.sum(1),axis=0).plot(kind='bar',stacked= True)\n#Shows more proportion of infants survived than elders.","13ecdbd0":"train= train.drop(columns=['Age_bin'])","8e2d4125":"#Embarked with Survived\nES= pd.crosstab(train['Embarked'],train['Survived'])\nES.div(ES.sum(1),axis=0).plot(kind='bar',stacked= True)","fae9c1c1":"#Pclass with Survived\nPS= pd.crosstab(train['Pclass'],train['Survived'])\nPS.div(PS.sum(1),axis=0).plot(kind='bar',stacked= True)","c8dbf74c":"#SibSp with Survived\nSBS= pd.crosstab(train['SibSp'],train['Survived'])\nSBS.div(SBS.sum(1),axis=0).plot(kind='bar',stacked= True)","9c67fc11":"#Parch with Survived\nPAS= pd.crosstab(train['Parch'],train['Survived'])\nPAS.div(PAS.sum(1),axis=0).plot(kind='bar',stacked= True)","7f5103e1":"X_train = train.drop(['Survived'],1)\ny_train = train['Survived']\nX_test = test\nprint(X_train.shape)\nprint(X_test.shape)","aa083143":"df = X_train.append(X_test)\ndf.shape","0fea831d":"df['Family_Size']= df['SibSp']+df['Parch']","eb117eb9":"df.isnull().sum()\n#Remove cabin as 687\/889 are missing. Remove Age as imputing 177 values i.e. 20% of data can give wrong results.\n#Remove Age_bin as its not reqd.","e32b9b32":"#For embarked, first see data\ndf['Embarked'].describe()\n# I think mode of Embarked that is 'S' should be imputed as it comes in 72% of the data.\ndf['Age']= df['Age'].fillna(df['Age'].mean())","2847a8b5":"df['Embarked']= df['Embarked'].fillna('S')","7800c00a":"df['Cabin']= df['Cabin'].fillna('U') #'U' For unknown","30ad3caa":"df['Fare'].mean()","b4f84a8b":"df['Fare']= df['Fare'].fillna(df['Fare'].mean) # Doesn't matter as survival shouldn't depend on Fare","044b085e":"df.isnull().sum()","64edcd6a":"df.dtypes","69f83191":"df['Pclass']= df['Pclass'].astype('object')\ndf['Family_Size']= df['Family_Size'].astype('object')\ndf['Sex']= df['Sex'].astype('object')\ndf['SibSp']= df['SibSp'].astype('object')\ndf['Parch']= df['Parch'].astype('object')\ndf['Cabin']= df['Cabin'].astype('object')\ndf['Embarked']= df['Embarked'].astype('object')","42eb0c03":"df.shape","0ced2709":"df.dtypes","806cca6a":"df =df.drop(columns=['Name','Fare','Ticket','SibSp','Parch'])\n\ndf = pd.get_dummies(df,columns=['Pclass','Sex','Cabin','Embarked','Family_Size']) #Making dummies of categorical variables","cdbde12a":"df.head()","2a74ea10":"x_train = df[:891].copy()\nx_test = df[891:].copy()\nx_train.shape,x_test.shape","a95e7751":"#split the train data into train and valid set\ndef split_vals(a,n): return a[:n], a[n:]\nvalid_count =60\nn_trn = len(x_train)-valid_count\nx_train1, x_valid1 = split_vals(x_train, n_trn)\ny_train1, y_valid1 = split_vals(y_train, n_trn)","998429f7":"x_train1.shape,y_train1.shape,x_valid1.shape,y_valid1.shape\n","6f10b5cf":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 100,max_depth=8)\nclassifier.fit(x_train1, y_train1)\nclassifier.score(x_train1, y_train1)","029026cf":"y_predict=classifier.predict(x_valid1)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_valid1,y_predict)","59956e57":"importance = classifier.feature_importances_\n# summarize feature importance\nfor i,v in enumerate(importance):\n    if v>0.01:\n        print('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance","6175b4ae":"to_keep=['PassengerId','Age','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male','Cabin_U','Embarked_C','Embarked_S','Family_Size_0','Family_Size_1','Family_Size_2']","d8e81219":"x_train1.iloc[:,197]","25ddd065":"x_train = x_train[to_keep]\nx_train","e39dc92b":"m = RandomForestClassifier(n_estimators=100,max_depth=8)\nm.fit(x_train,y_train)\nm.score(x_train,y_train)","072035a8":"x_test = x_test[to_keep]\noutput=m.predict(x_test).astype(int)","6c4eebef":"output.shape","130cbe38":"submission= pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission.iloc[:,1] = output","e43271b5":"submission.to_csv('results_final1',index=False)","b0b80f40":"# Making Final Model","8956ef7d":"# Coverting the categorical features into numeric form by applying the get_dummies function","39995ef3":"# Finalising Features based on importance","c9caee03":"# Bivariate Analysis","22c403d1":"# Univariate Analysis","dad3584f":"# Building Models for Training and testing","a717d70a":"# Getting Data","8259bc48":"# **Importing Libraries**","953144ee":"## Family Size\n**SibSp and Parch together tell the family size. A family is always grouped together and hence more chances of survival. Or atleast some relation with survival.**","36aec0b2":"# Making Submission File","8a0d38fc":"# Feature Engineering","4079c4a2":"# Understand problem statement\n\nWe have to predict whether a person will survive or die based on certain parameters. \nGeneral Knowledge: So, it is a binary classification problem. We mostly use logistic regression for prediction if data is balanced. Else, random forests\/tree-based classfiers are used.","3b8c2572":"# Making Hypothesis\nAccording to me, 'Survived'will depend on:\n* Sex\n* Age\n* Embarked\n\nNote: There may be other factors.\n","1812ea0b":"# Removing unimportant columns (By intuition)","bfcda069":"# Missing Value","ef3c59d8":"# Combining train and test data"}}