{"cell_type":{"094bf0cb":"code","495645ee":"code","7afa28d0":"code","57679fb0":"code","07951a40":"code","18b3dbad":"code","97ac6f3c":"code","2563eba0":"code","3eaca34d":"code","3a666e0e":"code","eb3586a2":"code","3e04c0dc":"code","0653b5bc":"code","e24a00df":"code","53d0f4dd":"code","d1f9efed":"code","cbda6c00":"code","36483fc7":"code","33e0ff9a":"code","b7170e59":"code","9ea026ee":"code","692335f5":"code","791e9ab4":"code","609d4450":"code","ed5a79a3":"code","13ad80eb":"code","807ae3b2":"markdown","fa97023e":"markdown","356a23f0":"markdown","1d1037e6":"markdown","a8fd691d":"markdown","7b2f4858":"markdown","645a88a4":"markdown","8c225b58":"markdown","919208bb":"markdown","c93d3d59":"markdown","332b25c0":"markdown","6f3b034c":"markdown","2c8f475b":"markdown","e17126f6":"markdown","b7fce64c":"markdown","08c7a507":"markdown"},"source":{"094bf0cb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport os","495645ee":"# Make some settings for pandas and plotting\npd.set_option('display.max_rows',50)\npd.set_option('display.max_columns',50)\nplt.rcParams['font.size']=12","7afa28d0":"train_data_dir=\"..\/input\/dogs-cats-images\/dog vs cat\/dataset\/training_set\"\ntest_data_dir=\"..\/input\/dogs-cats-images\/dog vs cat\/dataset\/test_set\"","57679fb0":"train_dogs = train_data_dir+'\/dogs'\ntrain_cats = train_data_dir+'\/cats'\ntest_dogs = test_data_dir+'\/dogs'\ntest_cats = test_data_dir+'\/cats'\n\nprint(len(os.listdir(train_cats)))\nprint(len(os.listdir(train_dogs)))\nprint(len(os.listdir(test_cats)))\nprint(len(os.listdir(test_dogs)))","07951a40":"plt.imshow(plt.imread(train_data_dir+'\/cats\/cat.1.jpg'))","18b3dbad":"plt.imshow(plt.imread(test_data_dir+'\/cats\/cat.4001.jpg'))","97ac6f3c":"plt.imshow(plt.imread(train_data_dir+'\/dogs\/dog.1.jpg'))","2563eba0":"plt.imshow(plt.imread(test_data_dir+'\/dogs\/dog.4001.jpg'))","3eaca34d":"plt.imread(train_data_dir+'\/cats\/cat.100.jpg').shape","3a666e0e":"plt.imread(test_data_dir+'\/cats\/cat.4100.jpg').shape","eb3586a2":"plt.imread(train_data_dir+'\/dogs\/dog.100.jpg').shape","3e04c0dc":"plt.imread(test_data_dir+'\/dogs\/dog.4100.jpg').shape","0653b5bc":"# we will import image data generator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","e24a00df":"ImageDataGenerator?","53d0f4dd":"train_image_generator=ImageDataGenerator(rescale=1.\/255,horizontal_flip=0.2,shear_range=0.2,zoom_range=0.2)\nval_image_generator=ImageDataGenerator(rescale=1.\/255)","d1f9efed":"# We will resize the images so that all the images in the dataset will be of the same size\nimage_height,image_width = 150,150\n# Here we will take the batch size as per our requirement\nbatch_size=32 ","cbda6c00":"train_data_gen=train_image_generator.flow_from_directory(directory=train_data_dir, target_size=(image_width,image_height),\n                                                        shuffle=True, batch_size=batch_size, classes=['cats','dogs'],\n                                                        class_mode='binary')","36483fc7":"val_data_gen=val_image_generator.flow_from_directory(directory=test_data_dir, target_size=(image_height,image_width),\n                                                    batch_size=batch_size,class_mode='binary')","33e0ff9a":"def Plotimages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()        ","b7170e59":"# using an indexing to generate different images of a same image\naugmented_images = [train_data_gen[0][0][2] for i in range(5)]\n\nPlotimages(augmented_images)","9ea026ee":"# import the libraries for the model building\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Dense,Flatten","692335f5":"# import model\nmodel=Sequential()\n# import layers\nmodel.add(Conv2D(filters=32,kernel_size=(3,3), input_shape=(image_height,image_width,3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))","791e9ab4":"# check the summary of the model\nmodel.summary()","609d4450":"# compiling the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","ed5a79a3":"%%time\n# Fitting CNN Model\nmodel.fit_generator(generator= train_data_gen,\n#                     steps_per_epoch= 8005\/\/batch_size,\n                    steps_per_epoch= 120,                    \n                    epochs= 10,\n                    validation_data= val_data_gen,\n#                     validation_steps= 2023\/\/batch_size\n                    validation_steps= 32)\n\n# %%time\n# # Fitting the model\n# model.fit_generator(generator=train_data_gen, steps_per_epoch=100, epochs=10, \n#                     validation_data=val_data_gen, validation_steps=100)","13ad80eb":"pd.DataFrame(model.history.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.show()","807ae3b2":"We can see that our data is clearly balanced as both  the training and testing data consists of 4000 and 1000 images  each of cats and dogs respectively","fa97023e":"We will import the data","356a23f0":"import the important libraries","1d1037e6":"To visualise the data properly we will use this below data","a8fd691d":"We have the training images in the train_data_dir and testing images in the test_data_dir.\n\nNow we will check that how many images we have of the cats and dogs in the training as well testing directory","7b2f4858":"\nHere make sure we perform all this operations only on the training data. to generate more images not on the validation data(except rescale) as it for just checking out how the model created from the training dataset is performing\n\n* rescale=1.\/255 , we normalized the data for the algorithm to understand\n* horizontal_flip=0.2 , we flipped the data or made the mirror image of the original image horizontaly\n* shear_range=0.2 , cutting certain parts of the images and putting somewhere else\n* zoom_range=0.2 , we zoomed the image\n* many other parameters can also be performed on this imagedatagenerator\n\nBy doing this we are creating more images for the training dataset","645a88a4":"Plot the images\n","8c225b58":"now let us visualise the data manually","919208bb":"**We will perform CNN on Cats and Dogs Dataset.**","c93d3d59":"Above we created a function just to have look at the augmentation of the images","332b25c0":"Now from above we can clearly say that our images are of different shapes . So we will convert all the images in a fixed shape which our model can understand\n\nAlso the no of images are less in this data so we will need to augment the data, also we will need to rescale the data as it will be of varied range, all this task can be done using image data generator","6f3b034c":"Here we have classes in ['cats','dogs'], so the classification cats will take a label of 0 and dogs will take a label of 1\n\nLet us look at the augmented images ","2c8f475b":"Now we will apply all the above parameters which we defined on the dataset","e17126f6":"Here we can change this following parameters for different images train_image_generator=ImageDataGenerator(rescale=1.\/255, horizontal_flip=0.2, shear_range=0.2, zoom_range=0.2)\n\n**Build a Model**","b7fce64c":"Now we will import the ImageDataGenerator function into a varible we want with the parameters we want","08c7a507":"now after visualising let us check the shape of the random images"}}