{"cell_type":{"aa74f544":"code","1120c4ad":"code","2a116bb8":"code","2a878487":"code","4388c317":"code","d1237d66":"code","4cbf9c24":"code","fa984acd":"code","8ce925aa":"code","98c4fe38":"code","86fb37d0":"code","8eaa9a5c":"code","bcd4a3a5":"code","558d4bc1":"code","45f0fe95":"code","0640bc29":"code","c14a5d4f":"code","05cbc296":"code","808d672f":"code","aaff6f00":"code","485320d8":"code","11d2c9a7":"code","8edb8dee":"code","eadeaa52":"code","7407e3c8":"code","e825677a":"code","90116d3a":"code","6cf756dc":"code","89ef1a82":"code","469b376e":"code","dec4fd19":"code","3af5ba7e":"code","6f199dd5":"code","67d7878c":"code","97af1e5d":"code","36624dae":"code","fd35803a":"code","a448d5e0":"code","1222d730":"code","bbbed74f":"code","550f10aa":"code","c5b092aa":"code","f6a981ad":"code","078c0eb3":"code","bc0adc53":"code","822af3c5":"code","7c2ba5e4":"code","ebb48cf9":"code","d87cc55e":"code","3943d204":"code","ab4abe89":"code","08000e5f":"code","f461c139":"code","431c0da8":"code","1f252fc6":"code","6d9be6a6":"code","e9dc0595":"code","f6b23683":"code","a84c863c":"code","e3f22dec":"code","9e767067":"code","41113778":"code","8d9810cf":"markdown","5f4a495f":"markdown","6531c5a4":"markdown","29c0c2f4":"markdown","fa9b3edb":"markdown","caeb2a3e":"markdown","837eee6b":"markdown","4dd69eaa":"markdown","33bd47ed":"markdown","75a43896":"markdown","33512b58":"markdown","d5750612":"markdown","9c8f8885":"markdown","3b29d452":"markdown","c10ce073":"markdown","9fab79d2":"markdown","c9cb85ea":"markdown","9b47df7e":"markdown","c52bb660":"markdown","6594808e":"markdown","5e97cea2":"markdown","5ed7bf3e":"markdown","012fe7dc":"markdown","b0e93d4d":"markdown","4c321443":"markdown","47ff8749":"markdown","83323eb1":"markdown","fb72de0c":"markdown","406df452":"markdown","698957f8":"markdown","1bb04b49":"markdown","45c373ec":"markdown","c44595a3":"markdown","d2c3987e":"markdown","4c892dbe":"markdown","390cb41d":"markdown","5726d6be":"markdown","39fed311":"markdown","e208fb68":"markdown","45d5d238":"markdown","5ac284b1":"markdown"},"source":{"aa74f544":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport sklearn\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_validate\nimport warnings\nfrom plotly.offline import iplot\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        path=(os.path.join(dirname, filename))\n\ndata = pd.read_csv(path)","1120c4ad":"data=data.iloc[:,1:21]\nprint(\"original shape is:\",data.shape)\ndata.head()\n","2a116bb8":"data.isnull().sum()\n#data.isna().sum()","2a878487":"data.describe()","4388c317":"from sklearn import preprocessing\ndf1=data.iloc[:,0:1]\nle = preprocessing.LabelEncoder()\ndf1=le.fit_transform(df1)\ndf1=pd.DataFrame(data=df1, index=range(df1.shape[0]),columns=[\"Attrition_Flag\"])","d1237d66":"sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\nplt.figure(figsize=(7, 5))\nsns.countplot(x=\"Attrition_Flag\", data=data, palette='pastel');","4cbf9c24":"df2=data.iloc[:,1:2]\n#df2.head()","fa984acd":"g=sns.distplot(df2,color=\"r\",  label=\"Customer_Age\")\ng.legend()\nplt.show()","8ce925aa":"df3=data.iloc[:,2:3]\n#df3.head()","98c4fe38":"df3=le.fit_transform(df3)\ndf3=pd.DataFrame(data=df3, index=range(df3.shape[0]),columns=[\"Gender\"])","86fb37d0":"g=sns.distplot(df3,color=\"r\",  label=\"Gender\")\ng.legend()\nplt.show()\n","8eaa9a5c":"df4=data.iloc[:,3:4]\n#df4.head()","bcd4a3a5":"g=sns.distplot(df4,color=\"r\",  label=\" Dependent_count\")\ng.legend()\nplt.show()\n","558d4bc1":"df5=data.iloc[:,4:5]\n#df5.head()","45f0fe95":"df5=le.fit_transform(df5)\ndf5=pd.DataFrame(data=df5, index=range(df5.shape[0]),columns=[\"Education_Level\"])\n\ng=sns.distplot(df5,color=\"r\",  label=\"Education_Level\")\ng.legend()\nplt.show()\n","0640bc29":"df6=data.iloc[:,5:6]\n#df6.head()","c14a5d4f":"df6=le.fit_transform(df6)\ndf6=pd.DataFrame(data=df6, index=range(df6.shape[0]),columns=[\"Maritial_Status\"])\n\ng=sns.distplot(df6,color=\"r\",  label=\"Maritial_Status\")\ng.legend()\nplt.show()\n","05cbc296":"df7=data.iloc[:,6:7]\n#df7.head(4)","808d672f":"df7=le.fit_transform(df7)\ndf7=pd.DataFrame(data=df7, index=range(df7.shape[0]),columns=[\"Income_Category\"])\n\ng=sns.distplot(df7,color=\"r\",  label=\"Income_Category\")\ng.legend()\nplt.show()\n","aaff6f00":"df8=data.iloc[:,7:8]\n#df8.head()","485320d8":"df8=le.fit_transform(df8)\ndf8=pd.DataFrame(data=df8, index=range(df8.shape[0]),columns=[\"Card_Category\"])\n\ng=sns.distplot(df8,color=\"r\",  label=\"Card_Category\")\ng.legend()\nplt.show()","11d2c9a7":"df9=data.iloc[:,8:9]\n#df9.head()","8edb8dee":"df9=le.fit_transform(df9)\ndf9=pd.DataFrame(data=df9, index=range(df9.shape[0]), columns=[\"Months_on_book\"])\n\ng=sns.distplot(df9,color=\"r\",  label=\"Months_on_book\")\ng.legend()\nplt.show()","eadeaa52":"df10=data.iloc[:,9:10]\n#df10.head()\n#df10.describe()","7407e3c8":"g=sns.distplot(df10,color=\"r\",  label=\"Months_on_book\")\ng.legend()\nplt.show() ","e825677a":"df11=data.iloc[:,10:11]\n#df11.head()\n","90116d3a":"g=sns.distplot(df11,color=\"r\",  label=\"Months_Inactive_12_mon\")\ng.legend()\nplt.show() ","6cf756dc":"df12=data.iloc[:,11:12]\n#df12.head()\n#df12.describe()","89ef1a82":"g=sns.distplot(df12,color=\"r\",  label=\"Contacts_Count_12_mon\")\ng.legend()\nplt.show() ","469b376e":"df13=data.iloc[:,12:13]\n#df13.head()\n#df13.describe()","dec4fd19":"g=sns.distplot(df13,color=\"r\",  label=\"Credit_Limit\")\ng.legend()\nplt.show() ","3af5ba7e":"df14=data.iloc[:,13:14]\n#df14.head()\n#df14.describe()","6f199dd5":"g=sns.distplot(df14,color=\"r\",  label=\"Total_Revolving_Bal\")\ng.legend()\nplt.show() ","67d7878c":"df15=data.iloc[:,14:15]\n#df15.head()\n#df15.describe()","97af1e5d":"g=sns.distplot(df15,color=\"r\",  label=\"Avg_Open_To_Buy\")\ng.legend()\nplt.show() ","36624dae":"df16=data.iloc[:,15:16]\n#df16.head()\n#df16.describe()","fd35803a":"g=sns.distplot(df16,color=\"r\",  label=\"Total_Amt_Chng_Q4_Q1\")\ng.legend()\nplt.show() ","a448d5e0":"df17=data.iloc[:,16:17]\n#df17.head()\n#df17.describe()","1222d730":"g=sns.distplot(df17,color=\"r\",  label=\"Total_Trans_Amt\")\ng.legend()\nplt.show() ","bbbed74f":"df18=data.iloc[:,17:18]\n#df18.head()\n#df18.describe()","550f10aa":"g=sns.distplot(df18,color=\"r\",  label=\"Total_Trans_Ct\")\ng.legend()\nplt.show() ","c5b092aa":"df19=data.iloc[:,18:19]\n#df19.head()\n#df19.describe()","f6a981ad":"g=sns.distplot(df19,color=\"r\",  label=\"Total_Ct_Chng_Q4_Q1\")\ng.legend()\nplt.show() ","078c0eb3":"df20=data.iloc[:,19:20]\n#df20.head()\n#df20.describe()","bc0adc53":"g=sns.distplot(df20,color=\"r\",  label=\"Avg_Utilization_Ratio\")\ng.legend()\nplt.show() ","822af3c5":"numerical = pd.concat([df2,df9,df13,df14,df15,df16,df17,df18,df19,df20],axis=1)\nprint(\"numerical dataframe's shape is:\", numerical.shape)\n#numerical.head()","7c2ba5e4":"categorical = pd.concat([df3,df4,df5,df6,df7,df8,df10,df11,df12],axis=1)\nprint(\"categorical dataframe's shape is:\", categorical.shape)\n#categorical.head()","ebb48cf9":"dataframe = pd.concat([df1,df3,df4,df5,df6,df7,df8,df10,df11,df12,df2,df9,df13,df14,df15,df16,df17,df18,df19,df20],axis=1)\nprint(\"dataframe's shape is:\", dataframe.shape)","d87cc55e":"korelasyon=dataframe.corr()\nmatrix = np.triu(dataframe.corr())\nfigure, axis=plt.subplots(figsize=(18,15))\nsns.heatmap(korelasyon, annot=True,mask=matrix,cmap=\"rocket\")","3943d204":"import scipy.stats as ss   #Statistic \n\ncateg = pd.concat([df1,categorical],axis=1)\n\ndef cramers_corrected_stat(x, y):\n    result = -1\n    conf_matrix = pd.crosstab(x, y)\n    if conf_matrix.shape[0] == 2:\n        correct = False\n    else:\n        correct = True\n    chi2, p = ss.chi2_contingency(conf_matrix, correction=correct)[0:2]\n    n = sum(conf_matrix.sum())\n    phi2 = chi2\/n\n    r, k = conf_matrix.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))\/(n-1))\n    rcorr = r - ((r-1)**2)\/(n-1)\n    kcorr = k - ((k-1)**2)\/(n-1)\n    result = np.sqrt(phi2corr \/ min((kcorr-1), (rcorr-1)))\n    return round(result, 6), round(p, 6)\n\n\nfor var in categorical:\n    \n    x = categorical[var]\n    y = categ['Attrition_Flag']\n    cramersV, p = cramers_corrected_stat(x, y)\n    print(f'For variable {var}, Cramer\\'s V: {cramersV} and p value: {p}')","ab4abe89":"num = pd.concat([df1,numerical],axis=1)\nfor var in numerical:\n    gp = num[[var, 'Attrition_Flag']].groupby(['Attrition_Flag'])\n    gp_array = [group[var].to_numpy() for name, group in gp]\n    kstat, p = ss.kruskal(*gp_array)\n    kstat, p = round(kstat, 6), round(p, 6)\n    print(f'For variable {var}, Kruskal-Wallis H-test: {kstat} and p value: {p}')\n    ","08000e5f":"dataframe=pd.concat([df1,df2,df3,df4,df5,df6,df7,df10,df11,df12,df13,df14,df16,df17,df18,df19,df20],axis=1)\nnumlist=dataframe.loc[:,dataframe.nunique()>7].columns\nprint(numlist)","f461c139":"def clean_outliers(df, features):\n    for i in features:\n        Q1=df[i].quantile(0.25)\n        Q3=df[i].quantile(0.75)\n        IQR= (Q3-Q1)\n        print(\"Feature {} has min value: {} max value: {}\".format(i, Q1-IQR*1.5,Q3+IQR*1.5))\n        df=df[((df[i]>(Q1-IQR*1.5))&(df[i]<(Q3+IQR*1.5)))]\n    return df","431c0da8":"df_clean=clean_outliers(dataframe, numlist)\nprint(\"New shape: \",df_clean.shape)\n","1f252fc6":"y=df_clean[\"Attrition_Flag\"]\nx=df_clean.iloc[:,1:]","6d9be6a6":"from imblearn.over_sampling import SMOTENC\nxv=x.values\nyv=y.values\nsmote_nc = SMOTENC(categorical_features=[df_clean[\"Attrition_Flag\"].min(), df_clean[\"Attrition_Flag\"].max()], random_state=0)\nx, y = smote_nc.fit_resample(xv, yv)\nx = pd.DataFrame(data=x, index=range(x.shape[0]))\ny= pd.DataFrame(data=y, index=range(y.shape[0]),columns=[\"Attrition_Flag\"])\nprint(\"new feature shape: \",x.shape)\nprint(\"new target shape: \",y.shape)","e9dc0595":"sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\nplt.figure(figsize=(7, 5))\nsns.countplot(x=\"Attrition_Flag\", data=y, palette='pastel');","f6b23683":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score as ass\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import cross_val_score, KFold, GridSearchCV,train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.covariance import LedoitWolf\nfrom sklearn.covariance import MinCovDet\nfrom sklearn.covariance import OAS\nfrom sklearn.covariance import GraphicalLasso\nfrom sklearn.datasets import make_hastie_10_2\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\n","a84c863c":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=42)","e3f22dec":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","9e767067":"model = [DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier()]","41113778":"for i in model:\n    params={'max_leaf_nodes':[i for i in range(2,20)]}\n    score = GridSearchCV(i, param_grid=params, scoring='recall')\n    score.fit(x_train,y_train)\n    print(score.best_params_)\n    print(score.best_estimator_)\n    print(f\"Recall score: {score.best_score_}\")\n    pred=score.predict(x_test)\n    print(f\"Recall score of test data: {recall_score(y_test, pred)}\")\n    print(classification_report(y_test,pred))\n    sns.heatmap(confusion_matrix(y_test,pred), annot=True)\n    plt.show()","8d9810cf":"* \"Feature-8: Months on book\" has a p value > 0.05 which is 0.123, and it is correlated with customer age. Thus, we will eliminate it.\n* \"Feature-1: Customer Age\" has a p value > 0.05 which is 0.078, but still can be used since it is close to the edge.","5f4a495f":"**1.8 Feature-7 : Card_Category**\n* Categorical","6531c5a4":"# 4. Prediction Models\n","29c0c2f4":"**1.2 Feature-1 : Customer_Age**\n\n* Numerical","fa9b3edb":"**1.11 Feature-10 : Months_Inactive_12_mon**\n\n* Categorical","caeb2a3e":"**1.16 Feature-15 : Total_Amt_Chng_Q4_Q1**\n\n* Numerical\n","837eee6b":"Be sure if there is any null or NA value in the dataframe, luckly we do not have.","4dd69eaa":"We clean the outliers due to IQR analysis.","33bd47ed":"**1.15 Feature-14 : Avg_Open_To_Buy**\n\n* Numerical\n","75a43896":"**1.6 Feature-5 : Marital_Status**\n\n* Categorical","33512b58":"**1.10 Feature-9 : Total_Relationship_Count**\n* Categorical","d5750612":"\n**1.12 Feature-11 : Contacts_Count_12_mon**\n\n* Categorical\n\n","9c8f8885":"# **2. EDA**\n\n**2.1 Exploratory Data Anaylsis**\n \nWe will check :\n\n* Multi collinearity\n* P-values\n* Outlier Clear by Feature deep-dive & IQR Method","3b29d452":"**2.2 Categorical Featur Cramer\u2019s V**\n\nCramer\u2019s V is a number between 0 and 1 that indicates how strongly two categorical variables are associated. If we'd like to know if 2 categorical variables are associated, our first option is the chi-square independence test. A p-value close to zero means that our variables are very unlikely to be completely unassociated in some population. However, this does not mean the variables are strongly associated; a weak association in a large sample size may also result in p = 0.000.","c10ce073":"* \"Feature-7: Card category\" has a p-value > 0.05 which is 0.525 and correlated with credit limit and avg_open to buy so we can eliminate it\n* \"Feature-5: Maritial status\" has a p-value > 0.05 which is 0.108\n* \"Feature-3: Dependent Count\" has a p-value > 0.05 which is 0.091 but still can be acceptable\n","9fab79d2":"**1.18 Feature-17 : Total_Trans_Ct**\n\n* Numerical\n","c9cb85ea":"**1.3 Feature-2 : Gender**\n* Categorical","9b47df7e":"**1.9 Feature-8 : Months_on_book**\n* Numerical","c52bb660":"**Data Augmentation by SMOTE**","6594808e":"# 3. Outlier Cleaning\n\nFor outlier detection, the best practice is to use IQR method. This method helps us to illustrate the data distrubution as a box plot. The difference between Q3 (75%) and Q1 (25%) is called the Inter-Quartile Range It tells about the distribution characteristics of the data. It gives data's range, boundries and skewness. As can be seen the figure below that a box plot enables us to draw inference from it for an ordered data.\n\nIQR = Q3 - Q1 Lower Bound: (Q1 - 1.5 IQR) Upper Bound: (Q3 + 1.5 IQR)","5e97cea2":"**1.13 Feature-12 : Credit_Limit**\n\n* Numerical\n\n","5ed7bf3e":"**1.17 Feature-16 : Total_Trans_Amt**\n\n* Numerical\n","012fe7dc":"Total DataFrame","b0e93d4d":"Now, this dataset consists of 10,000 customers mentioning their age, salary, marital_status, credit card limit, credit card category, etc. There are nearly 18 features.\n\nWe have only 16.07% of customers who have churned. Thus, it's a bit difficult to train our model to predict churning customers. We will see what to do about it :))\n\n* **Attrition_Flag** ;          target\t\t;categorical \n* **Customer_Age**  ;         feature-1\t;numerical \n* **Gender**          ;            feature-2\t;categorical \n* **Dependent_count**  ;           feature-3\t;categorical \n* **Education_Level**   ;          feature-4\t;categorical; Has Unknowns  \n* **Marital_Status**     ;         feature-5\t;categorical; Has Unknowns \n* **Income_Category**     ;        feature-6\t;;categorical; Has Unknowns \n* **Card_Category**        ;       feature-7\t;categorical\t \n* **Months_on_book**        ;      feature-8\t;numerical\t\n* **Total_Relationship_Count** ;   feature-9\t;categorical \n* **Months_Inactive_12_mon**    ;  feature-10\t;categorical \n* **Contacts_Count_12_mon**      ; feature-11\t; categorical \n* **Credit_Limit**     ;           feature-12\t;numerical \n* **Total_Revolving_Bal** ;        feature-13\t;numerical \n* **Avg_Open_To_Buy**      ;       feature-14\t;numerical \n* **Total_Amt_Chng_Q4_Q1**  ;      feature-15\t;numerical \n* **Total_Trans_Amt**;             feature-16\t;numerical \n* **Total_Trans_Ct**  ;            feature-17\t;numerical \n* **Total_Ct_Chng_Q4_Q1**    ;     feature-18\t;df19;numerical\n* **Avg_Utilization_Ratio**   ;    feature-19\t;df20;numerical\n","4c321443":"**1.5 Feature-4 : Education_Level**\n\n* Categorical","47ff8749":"Attrition flag data distrubition after :)","83323eb1":"# **CHURN ANALYSIS EDA & PREDICTION & FRIENDLY EXPLANATIONS**\n\n![chrn](https:\/\/cdn.coil.com\/cdn-cgi\/image\/format=auto,fit=scale-down,w=1920\/images\/iZjzZF7ZTWOX87Fx_Uv9qw.png)","fb72de0c":"**1.7 Feature-6 : Income_Category**\n* Categorical","406df452":"Categorical Features","698957f8":"**2.3 Numerical Features Handling: Kruskal-Wallis H-test**\n \n\nThe Kruskal-Wallis H test is also called the \"one-way ANOVA on ranks\". It is a rank-based nonparametric test that can be used to determine if there are statistically significant differences between two or more groups of an independent variable on a continuous or ordinal dependent variable.","1bb04b49":"**1.4 Feature-3 : Dependent_count**\n\n* Categorical","45c373ec":"Numerical features","c44595a3":"# 5. Results\n\n* Decision tree 90%\n* Random Forest 93%\n* Gradient Boost 97%\n\n\nWe got 97.2& Recall and 97% f1 score with Gradient Boosting. But still it is a mystery that how it will work on real life since we increase the data with SMOTE.","d2c3987e":"**1.19 Feature-18 : Total_Ct_Chng_Q4_Q1**\n\n* Numerical\n","4c892dbe":"* Credit limit and Avg_Open_To_Buy features are directly correlated = 1. Thus, we can eliminate one of them\n* Customer age and Months_On_book are higly correlated >0.75\n* Total_Trans_Ct and Total_Trans_Amt are higly correlated >0.75","390cb41d":"**1.20 Feature-19 : Avg_Utilization_Ratio**\n\n* Numerical\n","5726d6be":"**1.14 Feature-13 : Total_Revolving_Bal**\n\n* Numerical\n","39fed311":"**1.1 Target (Output) : Attrition_Flag**\n\n* Categorical","e208fb68":"**Conclusion of correlation and p-value check**\n\n*We will drop the features:*\n\n*  Feature-7 : Card Category (df8)\n*  Feature-14: Avg_Open_To_Buy (df15)\n*  Feature-8 : Months on book (df9) \n\n*We will check the performance of the parameters with k-fold cross validation:*\n\n* Feature-5: Maritial Status (df6)\n* Feature-3: Dependent Count (df4)\n* Feature-1: Customer Age (df2)\n","45d5d238":"# 1. Feature Deep Dive & EDA","5ac284b1":"Standartization is neccessary for the scale of the features"}}