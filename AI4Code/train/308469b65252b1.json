{"cell_type":{"7f622724":"code","be586977":"code","f463d8a9":"code","5a6bb032":"code","d1c82d97":"code","822dcbc9":"code","2f20f3ad":"code","5645d932":"code","40145e24":"code","924f91b7":"code","25fa03bd":"markdown","7f5a6ee0":"markdown","832b8432":"markdown","d02a9c9c":"markdown","6ad3a17e":"markdown","90ff8068":"markdown","57a70b32":"markdown"},"source":{"7f622724":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be586977":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","f463d8a9":"df[\"quality\"].describe()","5a6bb032":"quality_mapping = {\n    3: 0,\n    4: 1,\n    5: 2,\n    6: 3,\n    7: 4,\n    8: 5,\n}","d1c82d97":"df.loc[:, \"quality\"] = df.quality.map(quality_mapping)","822dcbc9":"# Shuffling the dataset\ndf = df.sample(frac=1).reset_index(drop=True)\n\n# Selecting the first 1,000 rows for \"train\"\ndf_train = df.head(1000)\n\n# Selecting the remaining 599 rows for \"test\"\ndf_test = df.tail(599)","2f20f3ad":"from sklearn import tree\nfrom sklearn import metrics\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclf = tree.DecisionTreeClassifier(max_depth=7)\ncols = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol']\n\nclf.fit(df_train[cols], df_train.quality)","5645d932":"# Predictions on the train set\ntrain_predictions = clf.predict(df_train[cols])\n# Predictions on the test set\ntest_predictions = clf.predict(df_test[cols])\n# Calculating accuracy\ntrain_accuracy = metrics.accuracy_score(df_train[\"quality\"], train_predictions)\n# Calculating accuracy of predictions on test set\ntest_accuracy = metrics.accuracy_score(df_test[\"quality\"], test_predictions)","40145e24":"matplotlib.rc(\"xtick\", labelsize=20)\nmatplotlib.rc(\"ytick\", labelsize=20)\n\ntrain_accuracies = [0.5]\ntest_accuracies = [0.5]\n\nfor depth in range(1, 25):\n    clf = tree.DecisionTreeClassifier(max_depth=depth)\n    cols = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol']\n    \n    # Train model\n    clf.fit(df_train[cols], df_train.quality)\n    # Create train and test predictions\n    train_predictions = clf.predict(df_train[cols])\n    test_predictions = clf.predict(df_test[cols])\n    # Calculate training and test accuracies\n    train_accuracy = metrics.accuracy_score(df_train[\"quality\"], train_predictions)\n    test_accuracy = metrics.accuracy_score(df_test[\"quality\"], test_predictions)\n    # Append accuracies\n    train_accuracies.append(train_accuracy)\n    test_accuracies.append(test_accuracy)\n    \n# Create plots\nplt.figure(figsize=(10, 5))\nsns.set_style(\"whitegrid\")\nplt.plot(train_accuracies, label=\"train accuracy\")\nplt.plot(test_accuracies, label=\"test accuracy\")\nplt.legend(loc=\"upper left\", prop={\"size\" : 15})\nplt.xticks(range(0, 26, 5))\nplt.xlabel(\"max_depth\", size=20)\nplt.ylabel(\"accuracy\", size=20)\nplt.show()","924f91b7":"b = sns.countplot(x=\"quality\", data=df)\nb.set_xlabel(\"quality\", fontsize=20)\nb.set_ylabel(\"count\", fontsize=20)","25fa03bd":"### => Use a \"max depth\" of 11 for the DecisionTreeClassifier to achieve highest accuracy","7f5a6ee0":"# 3. Training a Decision Tree model","832b8432":"# 1. Mapping the \"quality\" column from 0 to 6","d02a9c9c":"# 2. Splitting the dataset into a \"train\" and a \"test\" set","6ad3a17e":"# 4. Testing the accuracy of the model","90ff8068":"### 4.1 Creating a plot with different values for \"max_depth\"","57a70b32":"### => Choose a stratified k-fold because of unequal distribution!"}}