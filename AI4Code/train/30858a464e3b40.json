{"cell_type":{"8c4d400c":"code","56359158":"code","2b67c79c":"code","67672279":"code","56fa7b62":"code","298cc0fa":"code","2b5120cb":"code","343875b4":"code","d690f7c8":"code","c1717896":"code","468ad48f":"code","d6966582":"code","7bfd40eb":"code","1942f750":"code","34b9dc77":"code","8094480e":"code","df9b93e8":"code","8689f809":"code","34a2fd3c":"code","2faeb3f7":"code","e83fe656":"code","9637fbef":"code","098a2180":"code","b9007733":"code","2762806f":"code","c3a2d0bd":"code","20b1514e":"code","12d8eb3c":"code","77809212":"code","be097663":"code","88f5ce21":"code","1b99ff52":"code","dd4ab781":"code","c753e97e":"code","22e09900":"code","a0b5c5bd":"code","aaa420da":"code","2ce4cd8e":"code","c6a4d088":"code","248454fb":"code","e5afd445":"code","6095ba58":"code","6cd31087":"code","71070c6e":"code","85ce9d7f":"code","08f41036":"code","2d6a61de":"code","631321e9":"code","f40a0d36":"code","0d4f3a71":"code","c0bd705a":"code","308ccd35":"code","cfd3174a":"code","4d5f551b":"code","f9a7e99b":"code","06c9d7f3":"code","72c0564f":"code","fa29f19a":"code","82add2bd":"code","ece27c31":"code","e6db7936":"code","adce2231":"code","690be6b2":"code","f5b7da77":"code","02ed7cfc":"code","b4b1fac9":"code","74ad093e":"code","4b8c1e4e":"code","f6a269c1":"code","964329e6":"code","783838c0":"code","7a57aade":"code","20c7e3d4":"code","1bbc12c5":"code","9d2ebac0":"code","8790549f":"code","c4cc4e3f":"code","21c34ce6":"code","45d902ee":"code","9f54786a":"code","f64fe132":"markdown","af06cc04":"markdown","8ffb4ecb":"markdown","2be1008c":"markdown","4f1753a2":"markdown","072dc3d8":"markdown","a8655c73":"markdown","f82bfe33":"markdown","59a91567":"markdown","de94a7f3":"markdown","c0d2376c":"markdown","0f6b4df1":"markdown","240aa389":"markdown","662f0b64":"markdown","16d6d03a":"markdown","ee729408":"markdown","ef16a397":"markdown","368e3562":"markdown","0c27a2b7":"markdown","ba84da1d":"markdown","a209a10a":"markdown","7cbfe56d":"markdown","5fa3b184":"markdown","117f01c5":"markdown","578332c1":"markdown","6888b5fe":"markdown","cd61b2b2":"markdown","38ec99a7":"markdown","376edf46":"markdown","01a4211d":"markdown","8da212c0":"markdown","cb28da5d":"markdown","047ecaff":"markdown","df8539e1":"markdown","aa4aa113":"markdown","83d0cd1c":"markdown","5f65a655":"markdown","7ccf1ee0":"markdown","2dfa0810":"markdown","ebcffdfb":"markdown","9e749190":"markdown","f16fccec":"markdown","375107ce":"markdown","2a11b2cf":"markdown","7e82ad38":"markdown","e89395de":"markdown","3efc87ac":"markdown","e077b6c3":"markdown","70000a79":"markdown","8b4680c9":"markdown","4e7a39bd":"markdown","41d2458f":"markdown","3ed292e3":"markdown","031352fb":"markdown","c3842336":"markdown","88792f96":"markdown","2f883253":"markdown","95efd70a":"markdown","cc1f1932":"markdown","b02b9fd0":"markdown","4f031efb":"markdown","a161a72d":"markdown","ed2ffa74":"markdown","5af7f9b8":"markdown","bda2d9c4":"markdown","206fe10d":"markdown","e5f5fded":"markdown","c214f226":"markdown","e256626c":"markdown","aa5b96d4":"markdown","f1d9e3cb":"markdown","06c37ad7":"markdown","8dc013f2":"markdown","8f670056":"markdown","56e572b9":"markdown","773f9790":"markdown","55f203a0":"markdown","294b9788":"markdown","9e3c4b32":"markdown","036d3263":"markdown","fa3762cf":"markdown","78fd1696":"markdown","78b211af":"markdown","31b12ea8":"markdown","77113329":"markdown","45de443a":"markdown","aae9c246":"markdown","ef70bc76":"markdown","0a41803c":"markdown","3b423425":"markdown","dcb2361f":"markdown","741f8300":"markdown","7f9cbd2d":"markdown","f617031e":"markdown","3b0ff890":"markdown","8413fd7b":"markdown","e70f6b8f":"markdown","a6166d67":"markdown","cec173f5":"markdown","9eb2f6de":"markdown","794f1eae":"markdown","fb6a52fb":"markdown","8cf122ba":"markdown","6acb407e":"markdown","699f62fa":"markdown"},"source":{"8c4d400c":"from sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import *\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.impute import *\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\nfrom scipy.stats import shapiro\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import *\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport ipywidgets as widgets\nfrom sklearn.compose import make_column_selector, make_column_transformer\n\n\n\n\n# Importamos nuestro propio fichero de utilidades\nimport md_grupoa_practica1extra_ficheroutilidad as utils\n\n","56359158":"seed = 27912","2b67c79c":"train_size = 0.7","67672279":"# =============================================================================\n# Funciones creadas por nosotros\n# =============================================================================\n    \n#Funcion para realizar gr\u00e1ficos de caja\ndef plot_boxplot(data):\n    \n    var = data.columns\n    data = widgets.fixed(data)\n\n    widgets.interact(_plot_boxplot, data=data, var=var)\n\n#Funci\u00f3n auxiliar para gr\u00e1ficos de caja    \ndef _plot_boxplot(data, var):\n    return data[var].iplot(kind=\"box\")\n\n#Funci\u00f3n para calcular los outliers de las variables pasadas por par\u00e1metros para un conjunto de datos pasado por pa\u00e1metros tambi\u00e9n \ndef calc_outliers(data, variables):\n    min=99999\n    max=0\n    total=0\n    total_variables=len(variables)\n    for var in variables:\n        outlier = []\n        aux= data[var]\n        q1= np.percentile(aux,25)\n        q3= np.percentile(data[var],75)\n        IQR= q3-q1\n        UF= q3+(1.5*IQR)\n        LF= q1-(1.5*IQR)\n        for s in data[var].values:\n            if(s>UF or s<LF):\n                outlier.append(s)\n        if(len(outlier)<min):\n            min= len(outlier)\n            minvar= var\n        if(len(outlier)>max):\n            max=len(outlier)\n            maxvar=var\n        print(f\"El n\u00famero de outliers de la variable {var} es: {len(outlier)}\")\n        print(f\"Siendo los outliers los siguientes: {outlier}\")\n        print(\"\")\n        total=total+len(outlier)\n    print(\"----Conclusiones----\")\n    print(f\"El total de outliers que tenemos en el conjunto de datos es de: {total}\")\n    print(f\"Con una media de  {total\/len(variables)} outliers por variable\")\n    print(f\"El mayor n\u00famero de outliers lo encontramos en la variable {maxvar} con {max} outliers\")\n    print(f\"El menor n\u00famero de outliers lo encontramos en la variable {minvar} con {min} outliers\")\n    print(\"--------------------\")\n\n\n\n#Funci\u00f3n para calcular el porcentaje de ceros en variables que no deber\u00edan de tener ceros\ndef ZeroCount(Data, param):\n    for s in param:\n        aux=Data[s]\n        zeros=aux.astype(bool).sum(axis=0)\n        totalval=np.product(aux.shape)\n        result= (1-(zeros\/totalval)) * 100    \n        #print(result)\n        print(f\"El porcentaje de ceros en la variable {s} es del {result:.2f}% \")\n        \n#Funci\u00f3n generar un diagrama de barras para analizar la potencia discriminativa de los valores perdidos de una variable con respecto a la variable clase\ndef _ValPerdidos_VarClase(data,param,clase):\n    aux = data.copy()\n    ValPerdidos = []\n    \n    #Comprobamos todos los casos en los que la variable dada tiene valores perdidos\n    for i in aux.index:\n        if(aux.loc[i,param]==0):\n            ValPerdidos.append('ConValoresPerdidos')\n        else:\n            ValPerdidos.append('SinValoresPerdidos')\n            \n    #A\u00f1adimos un nuevo atributo indicando los casos en los que hay valores perdidos\n    aux.loc[:,'valperdidos']= ValPerdidos\n    \n    #Generaci\u00f3n del diagrama de barras apilado\n    title = 'Valores perdidos de '+ param +' con respecto a la variable clase'\n    x = aux.valperdidos\n    color = clase\n    barnorm = \"fraction\"\n    a = px.histogram(x=x, color=color, barnorm=barnorm, title=title)\n    return a\n        \n\n#Funci\u00f3n para calcular el porcentaje de valores nulos en variables\ndef MissingValuesCount(Data, param):\n    Nan= Data.isnull().sum()\n    for s in param:\n        Aux =Data[s]\n        TotalVal= np.product(Aux.shape)\n        NanSum = Aux.isnull().sum()\n        result= (NanSum\/TotalVal)*100  \n        print(f\"El porcentaje de valores nulos en la variable {s} es del {result:.2f}% \")\n\n\n#Funci\u00f3n para eliminar outliers\ndef outlier_rejection(X, y, seed):\n    model = IsolationForest(random_state=seed)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]\n\n\n#Funci\u00f3n para realizar la evaluacion de bases de datos medicas\ndef EvaluationWClassRepo(model,\n             X_train, X_test,\n             y_train, y_test):\n    \n    clf = model.fit(X_train, y_train)\n    \n    y_pred = clf.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    d = dict(enumerate(y_test.cat.categories))\n    a=\"% s\" % d.get(0)\n    b=\"% s\" % d.get(1)\n    labels=[a,b]\n    print(classification_report(y_test, y_pred, target_names=labels))\n    \n    disp = plot_confusion_matrix(clf, X_test, y_test)\n    \n    accuracy= accuracy*100\n\n    disp.ax_.set_title(f\" Tasa de precisi\u00f3n = {accuracy:.2f}\"+\"%\")\n    ","56fa7b62":"filepathWisconsin = \"..\/input\/breast-cancer-wisconsin-data\/data.csv\"\nindexWisconsin = \"id\"\ntargetWisconsin = \"diagnosis\"\ndataWisconsin = utils.load_data(filepathWisconsin, indexWisconsin, targetWisconsin)\ndataWisconsin.sample(5, random_state=seed)","298cc0fa":"dataWisconsin = dataWisconsin.drop(dataWisconsin.columns[31], axis = 'columns')\ndataWisconsin.sample(5, random_state=seed)","2b5120cb":"(XWisconsin, yWisconsin) = utils.divide_dataset(dataWisconsin, target=\"diagnosis\")","343875b4":"XWisconsin.sample(5, random_state=seed)","d690f7c8":"yWisconsin.sample(5, random_state=seed)","c1717896":"(XWisconsin_train, XWisconsin_test, yWisconsin_train, yWisconsin_test) = train_test_split(XWisconsin, yWisconsin,\n                                                      stratify=yWisconsin,\n                                                      random_state=seed,\n                                                      train_size=train_size)","468ad48f":"XWisconsin_train.sample(5, random_state=seed)","d6966582":"XWisconsin_test.sample(5, random_state=seed)","7bfd40eb":"yWisconsin_train.sample(5, random_state=seed)","1942f750":"yWisconsin_test.sample(5, random_state=seed)","34b9dc77":"filepath = \"..\/input\/pima-indians-diabetes-database\/diabetes.csv\"\nindexDiabetes = None\ntargetDiabetes = \"Outcome\"\ndataDiabetes = utils.load_data(filepath, indexDiabetes, targetDiabetes)\ndataDiabetes.sample(5, random_state=seed)","8094480e":"(XDiabetes, yDiabetes) = utils.divide_dataset(dataDiabetes, target=\"Outcome\")","df9b93e8":"XDiabetes.sample(5, random_state=seed)","8689f809":"yDiabetes.sample(5, random_state=seed)","34a2fd3c":"(XDiabetes_train, XDiabetes_test, yDiabetes_train, yDiabetes_test) = train_test_split(XDiabetes, yDiabetes,\n                                                      stratify=yDiabetes,\n                                                      random_state=seed,\n                                                      train_size=train_size)","2faeb3f7":"XDiabetes_train.sample(5, random_state=seed)","e83fe656":"XDiabetes_test.sample(5, random_state=seed)","9637fbef":"yDiabetes_train.sample(5, random_state=seed)","098a2180":"yDiabetes_test.sample(5, random_state=seed)","b9007733":"dataWisconsin_test= utils.join_dataset(XWisconsin_test,yWisconsin_test)\ndataWisconsin_train= utils.join_dataset(XWisconsin_train,yWisconsin_train)\n\ndataDiabetes_test= utils.join_dataset(XDiabetes_test,yDiabetes_test)\ndataDiabetes_train= utils.join_dataset(XDiabetes_train,yDiabetes_train)","2762806f":"dataWisconsin_train.shape","c3a2d0bd":"dataWisconsin_train.info(memory_usage=False)","20b1514e":"yWisconsin_train.cat.categories","12d8eb3c":"utils.plot_histogram(dataWisconsin_train)","77809212":"utils.plot_barplot(dataWisconsin_train)\nB,M= yWisconsin_train.value_counts()\nprint('Numero de masas benigneas: ',B)\nprint('Numero de masas malignas : ',M)","be097663":"utils.plot_pairplot(dataWisconsin_train, target=\"diagnosis\")","88f5ce21":"mean_train = dataWisconsin_train.iloc[:,[0,1,2,3,4,5,6,7,8,9,30]]\nse_train = dataWisconsin_train.iloc[:,[10,11,12,13,14,15,16,17,18,19,30]]\nworst_train = dataWisconsin_train.iloc[:,[20,21,22,23,24,25,26,27,28,29,30]]\nutils.plot_pairplot(mean_train, target=\"diagnosis\")","1b99ff52":"utils.plot_pairplot(se_train, target=\"diagnosis\")","dd4ab781":"utils.plot_pairplot(worst_train, target=\"diagnosis\")","c753e97e":"fig, ax = plt.subplots()\nsns.heatmap(mean_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","22e09900":"fig, ax = plt.subplots()\nsns.heatmap(se_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","a0b5c5bd":"fig, ax = plt.subplots()\nsns.heatmap(worst_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","aaa420da":"plot_boxplot(dataWisconsin_train)","2ce4cd8e":"calc_outliers(dataWisconsin_train, ['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean',\n      'radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se',\n      'radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst',]\n)","c6a4d088":"dataDiabetes_train.shape","248454fb":"dataDiabetes_train.info(memory_usage=False)","e5afd445":"yDiabetes.cat.categories","6095ba58":"utils.plot_histogram(dataDiabetes_train)","6cd31087":"param=[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n\nutils.ZeroCount(dataDiabetes_train,param)","71070c6e":"utils._ValPerdidos_VarClase(dataDiabetes_train,\"SkinThickness\",dataDiabetes_train.Outcome)","85ce9d7f":"utils._ValPerdidos_VarClase(dataDiabetes_train,\"Insulin\",dataDiabetes_train.Outcome)","08f41036":"utils.plot_barplot(dataDiabetes_train)\nS,N= yDiabetes_train.value_counts()\nprint('Numero de Diabetes: ',S)\nprint('Numero de no Diabetes: ',N)","2d6a61de":"utils.plot_pairplot(dataDiabetes_train, target=\"Outcome\")","631321e9":"fig, ax = plt.subplots()\nsns.heatmap(dataDiabetes_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","f40a0d36":"utils.plot_boxplot(dataDiabetes_train)","0d4f3a71":"calc_outliers(dataDiabetes_train, ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n)","c0bd705a":"#Estimador para eliminar outliers\nOutlierRejection = FunctionSampler(func=utils.outlier_rejection, kw_args={\"seed\":seed})","308ccd35":"preproceserWinsconsin = make_column_transformer(('drop',['radius_mean','radius_se','radius_worst','concave points_mean',\n          'concave points_se','concave points_worst']),\n                                                remainder='passthrough')\n","cfd3174a":"#Variables para sustituir ceros\nfeatures1 = 'Glucose|BloodPressure'\nfeatures2 = 'BMI'\n#Variables que no hay que tocar\nfeatures3 = 'DiabetesPedigreeFunction|Age'\n\n#Estimador para integers\nreplace0Integer_Estimator = make_pipeline(SimpleImputer(strategy=\"median\",missing_values=0 ))\n#Estimador para reales\nreplace0Float_Estimator = make_pipeline(SimpleImputer(strategy=\"mean\",missing_values=0 ))\n\npreproceserDiabetes = make_column_transformer(\n    (replace0Integer_Estimator, make_column_selector(pattern= features1)),\n    (replace0Float_Estimator, make_column_selector(pattern= features2)),\n     ('passthrough', make_column_selector(pattern= features3)))\n\n","4d5f551b":"#Generaci\u00f3n del modelo zero_r\nzero_r_model = DummyClassifier(strategy=\"most_frequent\")\n#Generaci\u00f3n del modelo de \u00e1rbol de decision\ntree_model = DecisionTreeClassifier(random_state=seed)","f9a7e99b":"discretizerUWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizerQWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizerKWinsconsin = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")\n","06c9d7f3":"\n#Modelo de \u00e1rbol de decis\u00f3n con eliminaci\u00f3n de variables predictoras muy relacionadas\npreprocess_treemodel_Winsconsin=make_pipeline(preproceserWinsconsin, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones y con eliminaci\u00f3n\n# de variable predictoras muy relacionadas\npreprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerUWinsconsin,tree_model)\npreprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerQWinsconsin,tree_model)\npreprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,discretizerKWinsconsin,tree_model)","72c0564f":"\n#Modelo de \u00e1rbol de decis\u00f3n con eliminaci\u00f3n de variables predictoras muy relacionadas \n#eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_Winsconsin=make_pipeline(OutlierRejection, preproceserWinsconsin, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones y con eliminaci\u00f3n\n# de variable predictoras muy relacionadas y eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_discretizeU_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerUWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeQ_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerQWinsconsin,tree_model)\nextra_preprocess_treemodel_discretizeK_Winsconsin=make_pipeline(preproceserWinsconsin,OutlierRejection,discretizerKWinsconsin,tree_model)\n\n","fa29f19a":"discretizerUDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")\ndiscretizerQDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"quantile\")\ndiscretizerKDiabetes = KBinsDiscretizer(n_bins=3, strategy=\"kmeans\")","82add2bd":"#Modelo de \u00e1rbol de decisi\u00f3n con sustituci\u00f3n de ceros\npreprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones y sustituci\u00f3n de ceros\npreprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,discretizerUDiabetes,tree_model)\npreprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,discretizerQDiabetes,tree_model)\npreprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,discretizerKDiabetes,tree_model)\n","ece27c31":"\n#Modelo de \u00e1rbol de decisi\u00f3n con sustituci\u00f3n de ceros y eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection, tree_model)\n\n#Modelo de \u00e1rbol de decisi\u00f3n con tres tipos de discretizaciones, sustituci\u00f3n de ceros y eliminaci\u00f3n de outliers\nextra_preprocess_treemodel_discretizeU_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerUDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeQ_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerQDiabetes,tree_model)\nextra_preprocess_treemodel_discretizeK_Diabetes=make_pipeline(preproceserDiabetes,OutlierRejection,discretizerKDiabetes,tree_model)","e6db7936":"utils.EvaluationWClassRepo(zero_r_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","adce2231":"utils.EvaluationWClassRepo(tree_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","690be6b2":"utils.EvaluationWClassRepo(preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","f5b7da77":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","02ed7cfc":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","b4b1fac9":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)\n","74ad093e":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","4b8c1e4e":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","f6a269c1":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","964329e6":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Winsconsin,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","783838c0":"utils.EvaluationWClassRepo(zero_r_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","7a57aade":"utils.EvaluationWClassRepo(tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","20c7e3d4":"utils.EvaluationWClassRepo(preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","1bbc12c5":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","9d2ebac0":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","8790549f":"utils.EvaluationWClassRepo(preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","c4cc4e3f":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","21c34ce6":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeU_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","45d902ee":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeQ_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","9f54786a":"utils.EvaluationWClassRepo(extra_preprocess_treemodel_discretizeK_Diabetes,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","f64fe132":"Lo primero que vamos a hacer es cargar la base de datos utilizando Outcome como variable objetivo y como la base de datos carece de una variable identificadora que se pueda utilizar como \u00edndice, no utilizaremos ninguna variable (None) como variable indice ya que en ese caso, el m\u00e9todo load_data gener\u00e1 un indice de forma autom\u00e1tica.","af06cc04":"Respecto a estas graficas podemas darnos cuenta que las variables continuas radius, perimeter y area estan muy relacionados (en los tres grupos de variables predictoras mean, se y worst), obviamente esto puede ser por que para obtener el perimetro y el area es necesario saber el radio. Entonces, ser\u00eda factible descartar radius ya que ser\u00eda una variable simple de la que se obtienen las variables derivadas perimeter y area, y estas dos tendr\u00edas m\u00e1s informaci\u00f3n a la hora de generar los modelos que la variable radius.\nTambi\u00e9n podemos observar que la mejor forma de realizar una discretizaci\u00f3n \u00f3ptima ser\u00eda utilizando dos intervalos y quizas la mejor estrategia ser\u00eda utilizar KMeans, pero hay tantos casos que no se puede estar seguro a simple vista.","8ffb4ecb":"A continuaci\u00f3n le aplicaremos al modelo de \u00e1rbol de decisi\u00f3n el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al \u00e1rbol de decisi\u00f3n discretizado con 3 intervalos y todas las posibles estrategias de discretizaci\u00f3n.","2be1008c":"### **Descripci\u00f3n del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables ","4f1753a2":"Los modelos que evaluaremos ser\u00e1n el modelo zero_r y el modelo de arbol de decision que usar\u00e1 la semilla que estamos usando durante todo el problema.","072dc3d8":"Teniendo en cuenta que la base de datos Pima Indians diabetes surge de un problema m\u00e9dico y por ello, la m\u00e9trica normalmente utilizada para estos problemas es la que tendremos que emplear para la evaluaci\u00f3n, el recall o tasa de verdaderos positivos. Dicha tasa la podemos ver en la estructura classsification report que generar\u00e1 el m\u00e9todo EvalutationWClassRepo. \nFinalmente, al utilizarse la base de datos para predecir de forma diagn\u00f3stica si un paciente tiene diabete o no, consideraremos que dicho an\u00e1lisis da positivo si la variable objetivo Outcome tiene el valor 1, es decir; la tasa de verdaderos positivos se observar\u00e1 teniendo en cuenta que un positivo quiere decir que el paciente tiene diabetes.","a8655c73":"Para ello vamos a recurrir al m\u00e9todo _ValPerdidos_VarClase de nuestro fichero de utilidad, al cu\u00e1l tras pasarle como par\u00e1metros un conjunto de datos, el nombre de una variable predictora y la variable objetivo del conjunto de datos; crear\u00e1 un diagrama de barras \"apilado\" con dos barras, siendo la primera una representacion normalizada de los casos del conjunto de datos en los que la variable predictora (que hemos pasado como par\u00e1metro)  no tiene valores perdidos y la segunda la que si tiene valores perdidos. Adem\u00e1s, cada una de las barras estar\u00e1 dividida en base a los valores de la variable objetivo que hemos pasado como par\u00e1metro anteriormente, representado el porcentaje de casos del conjunto de datos que toman los distintos valores de dicha variable objetivo(en el caso de la variable objetivo del conjunto de datos dataDiabetes_train dichos valores ser\u00e1n 0 o 1). Este tipo de gr\u00e1fico nos p\u00e9rmitir\u00e1 comprobar la potencia discriminativa de los valores perdidos de una variable predictora con respecto a la variable clase.","f82bfe33":"Diagrama de caja","59a91567":"En esta parte aplicaremos el preprocesamiento en base a las modificaciones que hemos visto que necesitan los conjuntos de datos durante el an\u00e1lisis exploratorio.","de94a7f3":"Podemos observar que en nuestro conjunto de datos hay m\u00e1s casos en los que la variable objetivo Outcome indicaba que el paciente tenia diabetes (350) que en los que la variable objetivo Outcome indicaba que el paciente no tenia diabetes (187). Al haber tanta diferencia entre el n\u00famero de los casos en los que el paciente tiene o no diabetes podemos decir que el problema est\u00e1 desbalanceado.","c0d2376c":"Primero mostramos el n\u00famero de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","0f6b4df1":"Podemos observar que el conjunto de datos tiene 398 casos y 31 variables,siendo estas quizas demasiadas para que se reprensenten con claridad en algunos de los gr\u00e1ficos que vamos a utilizar","240aa389":"# 2. Acceso y almacenamiento de datos","662f0b64":"Debido a que estamos utilziando el m\u00e9todo .iplot para generar los diagramas de cajas y que este m\u00e9todo no genera diagramas de caja en los que se resalten los outliers presentes en una variable (como si hacen otros diagramas de cajas generados mediante seaborn o plotly express), y que no sabemos si estos gr\u00e1ficos ser\u00e1n visibles cuando hagamos el commit del notebook; hemos decidido apoyar las conclusiones que sacariamos de un diagrama de cajas mediante una funci\u00f3n que hemos creado nosostros mismos. \nDicha funci\u00f3n se llama calc_outliers y tras pasarle un conjunto de datos y el nombre de las variables de dicho conjunto de datos en las que queremos buscar la presencia de outliers como par\u00e1metros, te devuelve el n\u00famero de outliers presentes en cada una de las variables solicitadas, un array con cada uno de los outliers presentes en cada variable y una conclusi\u00f3n final con el n\u00famero total de outliers en el conjunto de datos, la media de outliers por variable en el conjunto de datos, la variable con el mayor n\u00famero de outliers con el n\u00famero de outliers que posee y la variable con el menor n\u00famero de outliers con el corresponideinte n\u00famero de outliers.\nDicho esto, el resultado de la ejecuci\u00f3n de dicha funci\u00f3n para el conjunto de datos de entrenamiento de Winsconsin pas\u00e1ndole tamb\u00eden como par\u00e1metro el nombre de todas las variables predictoras del conjunto ser\u00eda el siguiente:","16d6d03a":"A continuacion vamos a realizar un diagrama de barras:","ee729408":"## *5.2 Pima Indians diabetes*","ef16a397":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","368e3562":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlaci\u00f3n:","0c27a2b7":"A continuaci\u00f3n mostramos el tipo de cada una de las variables del conjunto de datos con el m\u00e9todo .info:","ba84da1d":"Donde podemos observar que de las 9 variables, todas son de tipo entero excepto tres; BMI y DiabetesPedigreeFunction que son de tipo real (dato que tendremos que tener en cuenta si las modificamos en el preprocesamiento), y Outcome que es de tipo categ\u00f3rico y es la que tomaremos como variable objetivo.","a209a10a":"> ### *Modelos sin preprocesamiento*","7cbfe56d":"A continuaci\u00f3n vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XDiabetes_train y yDiabetes_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XDiabetes_test y yDiabetes_test) (30% del subconjunto incial)\n\nEsta divisi\u00f3n la realizaremos con el m\u00e9todo train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la pr\u00e1ctica).","5fa3b184":"El n\u00famero de casos del conjunto de datos es 537 mientras que el n\u00famero de variables es 9","117f01c5":"# 5. Algoritmos de clasificaci\u00f3n","578332c1":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de \u00e1rbol de decisi\u00f3n. Como hemos mencionado en el an\u00e1lisis exploratorio utilizaremos 3 intervalos y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar","6888b5fe":"A continuacion vamos a realizar un diagrama de barras:","cd61b2b2":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero a\u00f1adi\u00e9ndoles un estimador que elimina outliers. Este estimador lo hemos a\u00f1adido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminaci\u00f3n de outliers puede generar sobreajuste y empeorar los resultados de la evaluaci\u00f3n; por lo tanto vamos a evaluar tanto las pipelines sin eliminaci\u00f3n de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","38ec99a7":"Como hemos indicado en el preprocesamiento de esta base de datos lo que tendremos que hacer ser\u00e1:\n* Sustituir los valores cero de las variables continuas Glucose, BloodPressure y BMI\n* Eliminar una variable predictora del par de variables predictoras Age y Pregnancies por su alto coeficiente de correlaci\u00f3n\n* Eliminar las variables predictoras Insulin y SkinThickness por la alta cantidad de valores perdidos que tienen y la ausencia de poder discriminativo de estos.\n* Dejar el resto de variables del conjunto igual.\n\nPara la sustituci\u00f3n de valores cero de las variables predictoras Glucose, BloodPressure y BMI utilizaremos el estimador SimpleImputer pero teniendo en cuenta que BMI se trata de una variable real y que las otras dos se tratan de variables enteras, tendremos que generar un estimador para cada tipo de variable (entera y real) modificando la estrategia de b\u00fasqueda, pues aunque lo normal es utilizar la media para la sustituci\u00f3n de valores ruidosos, al ser Glucose y BloodPresure enteros, no se puede introducir de repente un valor con decimales (la media podr\u00eda tener o no decimales) por ello el simpleImputer que afectar\u00e1 a las variables enteras utilizar\u00e1 la estrategia \"median\" sustituyendo los ceros por el valor m\u00e1s \"centrado\" entre todos  y que claramente ser\u00e1 de tipo entero y sin decimales. Ambos SimpleImputer (de enteros y decimales) los \"combinaremos\" con un m\u00e9todo make_column_transformer donde le pasaremos a cada estimador las variables correspondientes asign\u00e1ndolas al par\u00e1metro pattern del make_column_selector. Para dejar al resto de variables igual simplemente declararemos las variables predictoras que no se deben de tocar en un par\u00e1metro aparte y se introducir\u00e1n en el make_column_transformer pero en vez de pasarle un estimador como par\u00e1metro introduciremos el valor 'passthrough' que simplemente dejar\u00e1 igual las variables predictoras. Finalmente si queremos eliminar las variables predictoras que hemos acordado en el an\u00e1lisis exploratorio bastar\u00e1 con no incluirlas en el make_colum_transformer.","376edf46":"La base de datos Pima Indians diabetes tiene el objetivo de predecir de forma diagn\u00f3stica si un paciente tiene o no diabetes, bas\u00e1ndose en ciertas mediciones ya realizadas e incluidas en la base de datos. Algunas restricciones se han establecido en la seleccion de las instacias para la base de datos. En particular, todos los pacientes son mujeres con al menos 21 a\u00f1os con herencia del pueblo Pima (que \u00e9s un grupo de ind\u00edgenas de Estados Unidos que viven en Arizona). Las distitnas variables que maneja la base de datos son las siguientes:\n\n1. Pregnancies: Variable discreta que indica el n\u00famero de veces que ha estado embarazada la paciente.\n2. Glucose: Variable continua entera que indica la concentraci\u00f3n de glucosa en plasma de la paciente tras 2 horas de que se la haya realizado una prueba oral de tolerancia a la glucosa.\n3. BloodPresure: Variable continua entera que indica la presi\u00f3n arterial diast\u00f3lica de la paciente en mm\/hg.\n4. SkinThickness: Variable continua entera que indica el espesor del pliegue cut\u00e1neo del triceps de la paciente en mm\n5. Insulin: Variable continua entera que indica el suelo insulino tras 2 horas de la paciente en mu U\/ml\n6. BMI: Variable continua real que indica el \u00edndice de masa corporal de la paciente dado por la divis\u00f3n del peso en kg entre la altura en metros al cuadrado\n7. DiabetesPedigreeFunction: Variable continua real que indica el resultado de la funci\u00f3n de pedigree.\n8. Age: Variable continua entera que indica la edad del paciente.\n9. Outcome: Variable categ\u00f3rica que puede tener los valores 1 o 0. Esta variable categ\u00f3rica tomar\u00e1 el valor 1 en el caso de que la paciente tenga diabetes y tomar\u00e1 el valor 0 en el caso de que la paciente no tenga diabetes.\n\nLa variable objetivo de este problema ser\u00eda outcome, mientras que el resto ser\u00e1n variables predictoras.\nComo conclusi\u00f3n, recordar que los modelos generados por esta base de datos tendr\u00e1n la finalidad de que, dependiendo de los valores de las variables predictoras, intentar diagnosticar si un paciente tiene diabetes o no \"rellenando\" el valor de la variable objetivo Outcome.\n\n","01a4211d":"Si observamos la gr\u00e1ficas podemos observar dos detalles importantes:\n* Lo primero es que no todas las variables predictoras tienen una distribuci\u00f3n normal con tendencia central en forma de campana de gauss, solamente las variables predictoras SkinThickness, BMI, BloodPresure y Glucose; mientras que el resto de variables predictoras ( Age, Pregnancies, Insulin y DiabetesPedigreeFunction) poseen una distribuci\u00f3n con tendencia exponencial decreciente. De hecho en ciertas variables predictoras como DiabetesPedigreeFunction o Insulin, en sus gr\u00e1ficas podemos empezar a apreciar la aparici\u00f3n de outliers que comprobaremos m\u00e1s tarde con los gr\u00e1ficos de caja.\n* Lo segundo es que en las gr\u00e1ficas se puede observar como ciertas variables continuas toman valores perdidos, es decir toman el valor 0 cuando seg\u00fan la l\u00f3gica de los valores que pueden tomar dichas variables continuas, ser\u00eda imposible que dichas variables continuas tuvisen como valor un 0. Dichas variables continuas son Glucose (un paciente no puede tener 0 de glucosa), BloodPresure (un paciente no puede tener 0 de presi\u00f3n sangu\u00ednea), SkinThickness (la piel de un paciente debe de tener grosor), Insulin (un paciente ha de tener insulina) y BMI (el \u00edndice de masa corporal de una persona no puede ser 0).","8da212c0":"A continuaci\u00f3n le aplicaremos al modelo de \u00e1rbol de decisi\u00f3n el estimador con el preprocesamiento que hemos desarrolado en el apartado anterior. No se lo aplicamos al modelo zeroR porque no le afectaria. Tambien le aplicamos el estimador al \u00e1rbol de decisi\u00f3n discretizado con 2 intervalos y todas las posibles estrategias de discretizaci\u00f3n.","cb28da5d":"### **Descripci\u00f3n del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables ","047ecaff":"Si realizamos una observaci\u00f3n de esta muestra, podemos darnos cuenta de que destaca una variable llamada Unnamed 32, ya que en la muestra todos los sus valores son nulos (NaN). Si nos descargamos el fichero .csv de la base de datos Breast Cancer Wisconsin, podemos observar que esta variable es ruido ya que se ha introducido por error a la hora de cargar el conjunto de datos pues en el fichero se ha introducido una coma de m\u00e1s y al cargarlo esa coma la toma como otra variable, para ser exactos como la variable Unnamed32.\nPor ello lo que vamos a hacer a continuaci\u00f3n es eliminar dicha columna (mediante el m\u00e9todo de pandas drop) del conjunto de datos dataWisconsin y ense\u00f1aremos otra muestra de dicho conjunto de datos para confirmar si se ha borrado correctamente.","df8539e1":"Como dato aclaratorio, tambi\u00e9n podriamos haber generado el estimador utilizando el transformador 'passthrough' y seleccionado todas las variables predictoras con las que nos queremos quedar sin igualar el par\u00e1metro remainder a passthrough, pues esto har\u00e1 que las variables que no le especifiquemos las borrar\u00e1 del conjunto de datos; b\u00e1sicamente es hacer el proceso que hemos hecho con el estimador al rev\u00e9s.","aa4aa113":"Por lo tanto, las conclusiones que podemos sacar esque, aunque hay una variable predictora en el conjunto de datos sin ning\u00fan outlier (concave points_worst) el n\u00famero total de outliers que tenemos en el conjunto de datos es demasiado grande (435) y dichos outliers est\u00e1n presentes en pr\u00e1cticamente todas las variables predictoras, por lo que se probar\u00e1 a utilizar un estimador que elimine los outliers para comprobar si mejoran los resultados de los distintos modelos al usarlo.","83d0cd1c":"A continuaci\u00f3n vamos a dividir nuestros subconjunto de datos en otros dos:\n*  uno que sirva como muestra de entrenemiento (XWisconsin_train y yWisconsin_train) (70% del subconjunto inicial)\n*  el otro que sirva como muestra de prueba (XWisconsin_test y yWisconsin_test) (30% del subconjunto incial)\n\nEsta divisi\u00f3n la realizaremos con el m\u00e9todo train_test_split.\n\nFinalmente mostraremos una muestra de cada uno de los subconjuntos obtenidos de forma aleatoria (utilizando la semilla que hemos definido al principio de la pr\u00e1ctica).","5f65a655":"A continuaci\u00f3n debido a las conclusiones del histograma, vamos a obtener el porcentaje de ceros que tienen estas variables continuas con el m\u00e9todo del fichero de utilidad ZeroCount y as\u00ed comproboremos la cantidad de ruido que tienen estas variables continuas y si vale la pena tenerlas en cuenta para el preprocesamiento:","7ccf1ee0":"El proceso de evaluaci\u00f3n de modelos lo realizaremos siguiendo los siguientes pasos para cada uno de los subapartados de la evaluaci\u00f3n (uno para cada uno de las bases de datos que hemos tratado):\n1. Mencion de la m\u00e9trica que utilizaremos para elegir el mejor modelo de los evaluados, que depender\u00e1 de la naturaleza del problema del que trata la base de datos que utilicemos\n2. Mostrar el resultado de la evaluaci\u00f3n sobre el conjunto de datos correspondiente de los modelos que usan los algoritmos ZeroR y el \u00e1rbol de decisi\u00f3n sin inclusi\u00f3n de estimadores extra, el resultado de la evaluaci\u00f3n sobre el conjunto de datos correspondiente de la pipeline resultado de aplicarle al \u00e1rbol de decisi\u00f3n el preprocesamiento b\u00e1sico del conjunto de datos correspondiente y otras tres pipelines que le aplican al \u00e1rbol de decis\u00f3n las tres tipos de discretizaciones mencionadas anteriormente y el preprocesamiento b\u00e1sico; y finalmente el resultado de la evaluaci\u00f3n sobre el conjunto de datos corresponidente de las \u00faltimas 4 pipelines a\u00f1adi\u00e9ndoles un estimador de eliminaci\u00f3n de outliers. La evaluci\u00f3n se realizar\u00e1 utilizando la funci\u00f3n del fichero de utilidad utils EvaluationWClassRepo\n3. Redacci\u00f3n de una peque\u00f1a conclusi\u00f3n que resuma los resultados obtenidos y los detalles m\u00e1s importantes de estos.","2dfa0810":"### **Visualizaci\u00f3n de las variables**","ebcffdfb":"Lo \u00fanico que podemos observar es lo que hemos mencionado al principio de este an\u00e1lisis, al ser 30 variables predictoras, algunas representaciones gr\u00e1ficas pueden no verse con claridad y este es un ejemplo. Por ello lo que vamos a hacer es dividir el diagrama de puntos entre tres, uno para cada uno de los tres tipos que pueden tener las variables predictoras: mean, se y worst.","9e749190":"Teniendo en cuenta que la base de datos Breast cancer winsconsin surge de un problema m\u00e9dico y por ello, la m\u00e9trica normalmente utilizada para estos problemas es el recall o tasa de verdaderos positivos, es la que tendremos que que emplear para la evaluaci\u00f3n. Dicha tasa la podemos ver en la estructura classsification report que generar\u00e1 el m\u00e9todo EvalutationWClassRepo. \nFinalmente, al utilizarse la base de datos para predecir el resultado del an\u00e1lisis de una masa mamaria, consideraremos que dicho an\u00e1lisis da positivo si el diagn\u00f3stico es maligno,es decir; la tasa de veraderos positivos se observar\u00e1 teniendo en cuenta que un positivo quiere decir que la masa mamaria es maligna.","f16fccec":"Para comprobar algunas de las conclusiones que hemos realizado en el apartado anterior vamos a generar una matriz de correlaci\u00f3n:","375107ce":"Para empezar generamos los distintos discretizadores que aplicaremos al modelo de \u00e1rbol de decisi\u00f3n. Como hemos mencionado en el an\u00e1lisis exploratorio utilizaremos 2 intervalos y probaremos todas las estrategias al no tener claro del todo cual hay que utilizar.","2a11b2cf":"En el siguiente paso dividimos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con las variables objetivo (Y). Despu\u00e9s mostramos una muestra (sample) de los subconjuntos creados.","7e82ad38":"A continuaci\u00f3n mostramos los distitnos valores que pueden tomar nuestras variables categ\u00f3ricas con el m\u00e9todo .categories:","e89395de":"Como hemos concluido en el an\u00e1lisis exploratorio, en los tres grupos de variables predictoras (mean,se y worst) se pueden apreciar dos ternas de variables predictoras, donde estas est\u00e1n muy correlacionadas entre s\u00ed, ya que en cada una de estas ternas hay dos variables derivadas de la tercera variable de la terna que es una variable simple. Por ello en el preprocesamiento vamos a generar un estimador que elimine las dos variables simples (radius y concave points) de todos los grupos de variables (mean,se y worst) del conjunto  de datos para que no influyan en la generaci\u00f3n del modelo ya que aportan menos informaci\u00f3n de la que aportan las variables que derivan de ellos.\nPara la generaci\u00f3n del estimador vamos a utilizar el m\u00e9todo make_column_transformer de la libreria sklearn.compose y vamos a indicar como par\u00e1metro del transformador 'drop' para que elimine la lista de variables predictoras de las que hemos hablado con anteriorioridad, adem\u00e1s; hemos indicado que para el resto de variables del conjunto el estimador simplemente no las toque igualando el par\u00e1metro remainder como 'passthrough'.","3efc87ac":"La base de datos Breast Cancer Winscosin es el resultado del an\u00e1lisis de una imagen digitalizada de un aspirado con aguja fina (FNA) de una masa mamaria. El an\u00e1lisis se realiza teniendo en cuenta las distinas variables que maneja la base de datos las cuales son:\n\n1. ID number: Es un n\u00famero creciente que servir\u00e1 de identificador para cada uno de los casos de la base de datos.\n2. Diagnosis: Variable categ\u00f3rica que guardar\u00e1 el resultado del an\u00e1lisis de la masa mamaria. Si tiene el valor B en caso de que la masa sea benignea y M en caso de que la masa sea maligna. Esta variable categ\u00f3rica ser\u00e1 la que tomemos como variable objetivo.\n3. radius: Variable continua real que guardar\u00e1 la media de las distancias desde el centro hasta los puntos del per\u00edmetro de la masa.\n4. texture: Variable continua real que guardar\u00e1 la desviaci\u00f3n est\u00e1ndar de los valores de la escala de grises de la masa.\n5. perimeter: Variable continua real que guardar\u00e1 el per\u00edmetro de la masa.\n6. area: Variable real que guardar\u00e1 el per\u00edmetro de la masa.\n7. smoothness: Variable continua real que guardar\u00e1 la variaci\u00f3n local en longitudes de radio de la masa.\n8. compactness: Variable continua real resultante de la operaci\u00f3n perimeter^2 \/ area - 1.0 (los valores de la variable real corresponde a los de la masa)\n9. concavity: Variable continua real que representa la severidad de las porciones c\u00f3ncavas del contorno de la masa.\n10. concave points: Variable real que represente el numero de porciones c\u00f3ncavas  del contorno de la masa.\n11. symmetry: Variable continua real que representa la simetria de la masa.\n12. fractal dimension (\"coastline approximation\" - 1): Variable continua real que representa la aproximaci\u00f3n de la linea costera de la masa\n\nLas dos primeras variables son variables de informaci\u00f3n y el resto son variables continuas que se computan para cada caso de la masa mamaria analizada. Para estas \u00faltimas variables habr\u00e1 tres tipos para cada uno de los casos:\n\n    -Variable_mean: Guardar\u00e1 el valor medio de la variable.\n    -Variable_se: Guardar\u00e1 el error est\u00e1ndar de la variable.\n    -Variable_worst: Guardar\u00e1 el peor valor (media de los tres valores m\u00e1s grandes) de la variable.\n\nComo conclusion la base de datos se utilizar\u00e1 en nuestro estudio para generar un modelo que prediga seg\u00fan unos valores si la masa mamaria analiza es B (Benigna) o M (Maligna)\n","e077b6c3":"## *1.1 Variables globales*","70000a79":"Cargamos la base de datos Breast cancer wisconsin  tratando la variable identificadora id como indice y la variable diagnosis como variable objetivo. Finalmente mostramos una muestra del conjunto de datos cargados","8b4680c9":"## *3.1 Breast cancer Winsconsin*","4e7a39bd":"## *2.2 Pima Indians diabetes*","41d2458f":"A continuaci\u00f3n podemos observar gracias al metodo .info ,que devuelve informaci\u00f3n del conjunto de datos incluyendo el tipo de sus variables, que de cada una de las 31 variables que hay 30 son del tipo real y una que es del tipo categorico (Que es la variable que usaremos como variable objetivo, diagnosis)","3ed292e3":"# 3. Analisis exploratorio","031352fb":"Para empezar vamos a cargar las librerias que utilizaremos durante el desarrollo de la pr\u00e1ctica","c3842336":"## *4.2 Pima Indians diabetes*","88792f96":"Fijamos el tama\u00f1o del conjunto de entrenamiento:","2f883253":"## *5.1 Breast cancer Winsconsin*","95efd70a":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","cc1f1932":"Tras observar el histograma que hemos obtenido sobre el conjunto de datos de entrenamiento, podemos sacar las siguientes conclusiones:\n* La primera conclusi\u00f3n que podemos sacar esque cada una de las variables perteneciente a un grupo (mean, se o worst) poseen una distribuci\u00f3n similar, con alguna excepci\u00f3n. Por ejemplo, las variables del grupo del valor medio (mean), tienen una distribuci\u00f3n normal con tendencia central en forma de campana de gauss, a excepci\u00f3n, de las variables continuas area_mean, compactness_mean, concavity_mean y concave points_mean, que tienen una distribuci\u00f3n con tendencia exponencial decreciente. Por otra parte, las variables del grupo del error medio (se) poseen una distribuci\u00f3n exponencial decreciente apreciable en todas las variables del grupo. Finalmente, las variables del grupo del peor valor (worst) tienen una distribuci\u00f3n normal con tenencia central en forma de campana de gauss, a excepci\u00f3n, de las variables continuas area_worst compactness_worst, concavity_worts y fractal dimension_worst.\n* La segunda conclusi\u00f3n que podemos sacar esque entre las 31 variables del conjunto de datos de entrenamiento, no hemos observado que haya presencia de datos no v\u00e1lidos ni indicios de outliers. No obstante; durante la realizaci\u00f3n de este an\u00e1lisis exploratorio realizaremos un diagrama de caja para cada una de las variables para analizar de forma m\u00e1s detallada la presencia de outliers.","b02b9fd0":"Vamos a empezar realizando un histograma sobre el conjunto de datos de entrenamiento:","4f031efb":"> ### *Modelos con el preprocesamiento extra*","a161a72d":"### **Visualizaci\u00f3n de las variables**","ed2ffa74":"Para acabar el an\u00e1lisis exploratorio vamos a realizar un diagrama de cajas para comprobar si podr\u00edan haber outliers en las variables del conjunto de datos:","5af7f9b8":"Al igual que para el gr\u00e1fico anterior vamos a realizar tres matrices distintas una para cada uno de los tipos que pueden tener las variables predictoras; mean,se y worst.","bda2d9c4":"> ### *Conclusiones*","206fe10d":"## *6.1 Breast cancer Winsconsin*","e5f5fded":"Y despu\u00e9s lo vamos a ejecutar para la variable predictora Insulin cuyos valores son en un 48,60% valores perdidos:","c214f226":"## *2.1 Breast cancer Winsconsin*","e256626c":"En esta parte generaremos los modelos que vamos a evaluar y las pipelines que saldr\u00e1n como resultado de aplicar a dichos modelos los estimadores que hemos creado en el apartado anterior (que tambi\u00e9n evaluaremos posteriormente).","aa5b96d4":"Al observar la matriz nos podemos dar cuenta de que el par de variables predictoras Glucose-Age y Glucose-Insulin est\u00e1n relacionados pero no lo suficiente para eliminar una de estas variables en el preprocesamiento; no obstante, el par de variables Age-Pregnancies es el m\u00e1s relacionado del conjunto de datos y quizas deberiamos de eliminar una de estas variables predictoras durante el preprocesamiento, siendo quizas, la m\u00e1s favorable a esta eliminaci\u00f3n la variable predictora pregnancies, ya que en principio podemos suponer que aporta menos informaci\u00f3n que la variable predictora Age a los modelos que vamos a generar para nuestro conjunto de datos pues creemos que la edad(Age) es un factor m\u00e1s relevante para la aparici\u00f3n de la enfermedad diabetes que el n\u00famero de embarazos(Pregnancies).","f1d9e3cb":"Podemos observar que diagnosis es una variable categ\u00f3rica que puede tomar el valor B en caso de que el resultado del diagnosis de la masa del paciente sea benigna y M en el caso de que el resultado del diagnosis de la masa del paciente sea maligno.","06c37ad7":"> ### *Modelos con el preprocesamiento extra*","8dc013f2":"Fijamos la semilla que utilizaremos:","8f670056":"Estas son las funciones auxiliares que hemos creado para esta pr\u00e1ctica y que hemos a\u00f1adido a nuestro utils:","56e572b9":"> ### *Modelos con el preprocesamiento desarrollado anteriormente*","773f9790":"## *1.2 Funciones auxiliares*","55f203a0":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluaci\u00f3n de modelos son las siguientes:\n* El mejor modelo que hemos obtenido ha sido el modelo del \u00e1rbol de decisi\u00f3n sin discretizaci\u00f3n y con el preprocesamiento b\u00e1sico con una tasa de verdaderos positivos de 0.62.\n* Si tenemos en cuenta la tasa de verdaderos positivos media (La media de la tasa de verdaderos positivos para positivo de diabetes y positivo de que no tenga diabetes), el mejor modelo es el del \u00e1rbol de decisi\u00f3n con el preprocesamiento b\u00e1sico y con una discretizaci\u00f3n basada en igual anchura, pues su tasa de verdaderos positivos media es de 0,71.\n* En general la tasa de veraderos positivos que hemos obtenidos de todos los modelos es bastante baja, siendo la m\u00e1s alta 0.62 y la m\u00e1s baja (sin tener en cuenta la del modelo ZeroR) ha sido 0,44; siendo esta a la vez la tasa de verdaderos positivos del modelo del \u00e1rbol de decisi\u00f3n con el preprocesamiento b\u00e1sico y con una discretizaci\u00f3n basada en k-medias y la del modelo del \u00e1rbol de decisi\u00f3n con el preprocesamiento extra y con una discretizaci\u00f3n basada en igual anchura.\n* La eliminaci\u00f3n de outliers ha podido sobreajustar parte de los modelos que usaban el preprocesamiento extra, ya que en la mayor\u00eda de estos modelos se han obtenido peores resultados para la tasa de verdaderos positivos con respecto al mismo modelo con el preprocesamiento b\u00e1sico, siendo una excepci\u00f3n el modelo  de \u00e1rbol de decisi\u00f3n con discretizaci\u00f3n basado en K medians cuya tasas de verdaderos positivos es 0.46 cuando se eliminan outliers y 0.44 sin la eliminaci\u00f3n de outliers.\n* En el caso de la discretizaci\u00f3n, lo m\u00e1s recomendable es no realizar una discretizaci\u00f3n a este conjunto de datos si usamos como modelo un \u00e1rbol de decisi\u00f3n, sin embargo la discretizaci\u00f3n que mejores resultados ha dado sin eliminaci\u00f3n de outliers es la de igual frecuencia (con una tasa de verdaderos positivos de 0.59) y con eliminaci\u00f3n de outliers es la basada en K medians (con una tasa de verdaderos positivos de 0.46). No obstante; est\u00e1n ambas por debajo del modelo del \u00e1rbol de decisi\u00f3n sin discretizar con o sin eliminaci\u00f3n de outliers (pero como m\u00ednimo con el preprocesamiento b\u00e1sico).\n","294b9788":"### **Preeliminares del analisis exploratiro**\n\n","9e3c4b32":"Las conclusiones que podemos sacar esque el total de valores outliers en el conjunto de datos es bastante alta (114) y estan presentes en todas las variables predictoras del conjunto de datos, siendo la variable predictora que menos tiene 1, pero sigue teniendo como m\u00ednimo un outlier. Por lo tanto se justifica el uso de un estimador cuya funci\u00f3n sea eliminar outliers para modelar este conjunto de datos y as\u00ed comprobar si mejoran los resultados con respecto a un modelo que no elimine dichos outliers.","036d3263":"## *6.2 Pima Indians diabetes*","fa3762cf":"## *4.1 Breast cancer Winsconsin*","78fd1696":"Finalmente hemos generado cuatro pipelines extra, que son las mismas cuatro pipelines anteriores pero a\u00f1adi\u00e9ndoles un estimador que elimina outliers. Este estimador lo hemos a\u00f1adido en cuatro pipelines extra aparte en vez de integrarlo todo junto porque sabemos que el proceso de eliminaci\u00f3n de outliers puede generar sobreajuste y empeorar los resultados de la evaluaci\u00f3n; por lo tanto vamos a evaluar tanto las pipelines sin eliminaci\u00f3n de outliers como las que si que lo hacen y comparar los resultados obtenidos en el siguiente apartado.","78b211af":"Aplicando la misma justificaci\u00f3n que hemos desarrolado para los diagramas de cajas del conjunto de datos de Winsconsin, vamos a ejecutar la funci\u00f3n calc_outliers para apoyar los resultados del diagrama de cajas:","31b12ea8":"## *3.2 Pima Indians diabetes*","77113329":"Continuaremos mostrando los distitnos valores que pueden tomar nuestras variables categ\u00f3ricas con el m\u00e9todo .categories:","45de443a":"Continuaremos con el an\u00e1lisis exploratorio realizando un diagrama de puntos:","aae9c246":"Las conclusiones que podemos sacar esque en los tres grupos de variables predictoras podemos presenciar que hay dos ternas de variables predictoras donde se presencia un alto grado de correlaci\u00f3n entre sus miembros:\n* La primera terna consta de las variables continuas radius, perimeter y \u00e1rea, las cuales presentan un alto nivel de correlaci\u00f3n debido a que perimeter y \u00e1rea son variables derivadas de radio. \n* La segunda terna consta de las variables continuas concavity, concave points y compactness las cuales tambi\u00e9n presentan un alto nivel de correlaci\u00f3n debido a que compactness y concavity son variables derivadas de concave points.\nPor lo tanto, en el preprocesamiento no deberiamos de tener en cuenta las variables simples(radius y concave points) y utilizar solo las variables derivadas de estas ultimas ya que aportar\u00e1n m\u00e1s informaci\u00f3n al modelo.\n","ef70bc76":"Primero mostramos el n\u00famero de casos y variables del conjunto de datos de entrenamiento con el metodo .shape","0a41803c":"> ### *Conclusiones*","3b423425":"Podemos observar que la variable Outcome es una variable categ\u00f3rica num\u00e9rica que puede tomar los valores 0 o 1 en caso negativo o afirmativo de que el paciente tenga diabetes respectivamente.","dcb2361f":"Lo que podemos observar esque el porcentaje de ruido que tienen variables continuas como BloodPresure, Glucose o BMI es aceptable, mientras que el de las variables continuas Insulin y SkinThickness (48.60% y 29.24% de ruido respectivamente) es demasiado alto, por lo tanto, a continuaci\u00f3n vamos a analizar la potencia discriminativa de los valores perdidos de estas variables continuas con respecto a la variable clase, antes de concluir en si se deber\u00edan o no tenerse en cuenta a la hora de generar los modelos.","741f8300":"# 4. Preprocesamiento de datos","7f9cbd2d":"> ### *Modelos sin preprocesamiento*","f617031e":"Antes de empezar el analisis exploratorio obtendremos los conjuntos de entrenamiento y de test para todas las bases de datos sobre las que realizaremos el an\u00e1lisis exploratorio. Para ello volvemos a unir (usando el m\u00e9todo join_dataset del fichero utils) los conjuntos de variables predictoras con la variable clase de los subconjuntos de entrenamiento y de test de todas las bases de datos.","3b0ff890":"Explicado el m\u00e9todo, lo vamos a ejecutar para la variable predictora SkinThickness cuyos valores son en un 29,6% valores perdidos:","8413fd7b":"Como podemos apreciar, los valores perdidos de estas dos variables predictoras no tienen una gran potencia discriminatoria, ya que la diferencia de porcentajes de casos en base al valor de la variable predictora Outcome no var\u00eda mucho entre los casos con valores perdidos y sin valores perdidos:\n* \u00b1 0.05 (\u00b15%) en el caso de la variable predictora SkinThickness.\n* \u00b1 0.03 (\u00b13%)en el caso de la variable predictora Insulin.\n\nPor lo tanto podemos concluir, que al carecer de poder discriminativo los valores perdidos de las variables SkinThickness e Insulin y al poseer ambas un alto porcentaje de valores perdidos (29,6% y 48,60%), es recomendable que no las tengamos en cuenta a la hora de generar nuestros modelos.","e70f6b8f":"Podemos observar que hay ciertas variables predictoras muy relacionadas entre si, como Age y Pregnancies, Glucose y Age o Glucose e Insulin; por lo que quizas en procesos posteriores deberiamos eliminar alguno de los miembros de estos pares de variables predictoras. Tamb\u00eden podemos darnos cuenta de que si realizamos una discretizaci\u00f3n quizas deber\u00edamos de realizarla con 3 intervalos, el problema, esque los datos est\u00e1n tan juntos que en principio no podemos definir ninguna estrategia de discretizaci\u00f3n correcta para este conjunto de datos.","a6166d67":"Empezamos el preprocesamiento definiendo el estimador que hara uso de la funci\u00f3n outlier_rejection del fichero de utilidad utils para eliminar outliers. Este estimador se utilizar\u00e1 posteriormente en la generaci\u00f3n de modelos aplicandos\u00e9 al conjunto de datos.","cec173f5":"Tras confirmar que se ha borrado correctamente Unamed32, el siguiente paso consitir\u00e1 en dividir el conjunto de datos en dos subconjuntos; uno con las variables predictoras (X) y otro con las variables objetivo (Y). Despu\u00e9s mostramos una muestra (sample) de los subconjuntos creados.","9eb2f6de":"Continuaremos con el an\u00e1lisis exploratorio realizando un diagrama de puntos:","794f1eae":"# 6. Evaluacion de modelos","fb6a52fb":"#\u00a0Pr\u00e1ctica 1: An\u00e1lisis exploratorio de datos, preprocesamiento y validaci\u00f3n de modelos de clasificaci\u00f3n\n\n###\u00a0Miner\u00eda de Datos: Curso acad\u00e9mico 2020-2021\n\n### Profesorado:\n\n* Juan Carlos Alfaro Jim\u00e9nez\n* Jos\u00e9 Antonio G\u00e1mez Mart\u00edn\n\n\n\n### Integrantes:\n\n* Gonzalo Pinto Perez\n* Yeremi Martin Huaman Torres","8cf122ba":"# 1. Preeliminares","6acb407e":"Las conclusiones que hemos obtenido tras analizar los resultados de la evaluaci\u00f3n de modelos son las siguientes:\n* Los dos mejores modelos son el modelo del \u00e1rbol de decisi\u00f3n con el preprocesamiento b\u00e1sico y con discretizaci\u00f3n de igual frecuencia y el modelo del \u00e1rbol de decisi\u00f3n con el preprocesamiento extra y con una discretizaci\u00f3n de igual frecuencia. Ambos tienen una tasa de verdaderos positivos del 0.92.\n* Si tenemos en cuenta la tasa de verdaderos positivos media (La media de la tasa de verdaderos positivos para positivo benigneo y positivo maligno), el mejor modelo ser\u00eda el \u00e1rbol de decisi\u00f3n con el preprocesamiento extra y con una discretizaci\u00f3n de igual frecuencia, con un tasa de verdaderos positivos media del 0.93.\n* En general hemos obtenido una tasa de verdaderos positivos alta para todos nuestros modelos (el m\u00e1s bajo sin contar el modelo ZeroR ha sido 0.64, que pertenece al modelo del \u00e1rbol de decisi\u00f3n con el preprocesamiento b\u00e1sico y con una discretizaci\u00f3n de igual anchura).\n* El preprocesamiento extra,la eliminaci\u00f3n de outliers, es posible que haya sobreajustado la mayoria de modelos generados para este conjunto de datos con este preprocesamiento, ya que los modelos que han eliminado outliers han tenido peores resultados que su contraparte sin eliminaci\u00f3n de outliers(o iguales en el caso del modelo del \u00e1rbol de decisi\u00f3n con preprocesamiento extra y con una discretizaci\u00f3n de igual frecuencia).\n* La mejor discretizaci\u00f3n para el modelo de \u00e1rboles de decisi\u00f3n es la de igual frecuencia, eliminado o no outliers, teniendo ambos una tasa de verdaderos positivos del 0.92.","699f62fa":"Observamos que en nuestro conjunto de datos entrenamientos hay m\u00e1s casos en el que el diagn\u00f3stico final fue benigneo(250)que en el que el diagn\u00f3stico final fue maligno (148), esto quiere decir que el problema est\u00e1 desbalanceado."}}