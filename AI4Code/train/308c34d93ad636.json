{"cell_type":{"98af9a7b":"code","6ae8a18a":"code","2581df34":"code","f2ccdc9c":"code","c40835d7":"code","ccf7177e":"code","1947a600":"code","a619c41c":"code","af440291":"code","1eff2b8c":"code","30487aea":"code","94d59f85":"code","cec0a89e":"code","ca78326c":"code","8aabab55":"code","ec23cdc6":"markdown","cd89ffda":"markdown","c2eb1ebf":"markdown","1264a0ef":"markdown","bc0b617a":"markdown","d5f9cfca":"markdown","aa07b826":"markdown","e74a6da6":"markdown","9697b270":"markdown"},"source":{"98af9a7b":"import numpy as np\nimport pandas as pd\n\nimport os\n#print(os.listdir(\"..\/input\/pmr-3508-tarefa-2\/\"))\nspam = pd.read_csv(\"..\/input\/spam-tarefa2\/train_data.csv\",header=0, index_col=-1)","6ae8a18a":"print(spam.shape)\nspam.head()","2581df34":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.grid()\nplt.errorbar(range(54),y=spam.loc[spam['ham']==True].mean(axis=0).iloc[:-4], yerr=spam.loc[spam['ham']==True].std(axis=0).iloc[:-4], fmt='-o', label='ham')\nplt.errorbar(range(54),y=spam.loc[spam['ham']==False].mean(axis=0).iloc[:-4], yerr=spam.loc[spam['ham']==False].std(axis=0).iloc[:-4], fmt='-o', label='spam')\nplt.legend()","f2ccdc9c":"plt.grid()\nplt.errorbar(range(54,57),y=spam.loc[spam['ham']==True].mean(axis=0).iloc[-4:-1], yerr=spam.loc[spam['ham']==True].std(axis=0).iloc[-4:-1], fmt='-o', label = 'ham')\nplt.errorbar(range(54,57),y=spam.loc[spam['ham']==False].mean(axis=0).iloc[-4:-1], yerr=spam.loc[spam['ham']==False].std(axis=0).iloc[-4:-1], fmt='-o', label='spam')\nplt.legend()","c40835d7":"indices = [1,3,5,6,7,8,10,15,16,17,18,19]+list(range(21,27))+list(range(28,46))+[47,48]+list(range(51,54)) #Indices dos features","ccf7177e":"from sklearn.naive_bayes import BernoulliNB\nfrom sklearn.model_selection import cross_val_score\nX = spam.iloc[:,indices]\ny = spam['ham']\nclf = BernoulliNB()\nscores = cross_val_score(clf, X, y, cv=10)\nprint(\"Bernoulli Naive Bayes:\")\nprint(\"Acur\u00e1cia m\u00e9dia: \"+str(np.mean(scores)))\nprint(\"Desvio padr\u00e3o: \"+str(np.std(scores)))","1947a600":"from sklearn.naive_bayes import MultinomialNB\nX = spam.iloc[:,indices]\ny = spam['ham']\nclf = MultinomialNB()\nscores = cross_val_score(clf, X, y, cv=10)\nprint(\"Multinomial Naive Bayes:\")\nprint(\"Acur\u00e1cia m\u00e9dia: \"+str(np.mean(scores)))\nprint(\"Desvio padr\u00e3o: \"+str(np.std(scores)))","a619c41c":"from sklearn.neighbors import KNeighborsClassifier\nX = spam.iloc[:,indices]\ny = spam['ham']\nmean_scores = []\nstd_scores = []\nfor i in range(1,11):\n    clf = KNeighborsClassifier(n_neighbors=i,p=1, weights='distance')\n    scores = cross_val_score(clf, X, y, cv=10)\n    mean_scores.append(np.mean(scores))\n    std_scores.append(np.std(scores))\nprint(\"KNN (valida\u00e7\u00e3o cruzada realizada para k variando de 1 a 10):\")\nprint(\"k para m\u00e1xima acur\u00e1cia m\u00e9dia: \"+str(np.argmax(mean_scores)+1))\nprint(\"M\u00e1xima acur\u00e1cia m\u00e9dia: \"+str(np.amax(mean_scores)))\nprint(\"Desvio padr\u00e3o para m\u00e1xima acur\u00e1cia m\u00e9dia: \"+str(std_scores[np.argmax(mean_scores)]))","af440291":"plt.errorbar(range(1,11), mean_scores, yerr=1.96*np.array(std_scores), fmt='-o')\nplt.title(\"Acur\u00e1cia m\u00e9dia da valida\u00e7\u00e3o cruzada para valores de k\")\nplt.ylabel(\"Acur\u00e1cia\")\nplt.xlabel(\"k\")","1eff2b8c":"test_feats = pd.read_csv(\"..\/input\/spam-tarefa2\/test_features.csv\",header=0)\nn_neighbors = 7\nX = spam.iloc[:,indices]\ny = spam['ham']\nclf = KNeighborsClassifier(n_neighbors=n_neighbors,p=1, weights='distance')\n#clf = BernoulliNB()\nclf.fit(X,y) # Treinamento do classificador com base de treino\npredicted_labels = clf.predict(test_feats.iloc[:,indices])\ntest_feats.head()","30487aea":"#test_feats = pd.read_csv(\"..\/input\/spam-tarefa2\/test_s.csv\",header=0)\nprediction = pd.read_csv(\"..\/input\/spam-tarefa2\/sample_submission_1.csv\",header=0)\nprediction['ham'] = predicted_labels\n#prediction.index.rename('Id',inplace=True)\nprediction.head()","94d59f85":"prediction.to_csv(\"submission.csv\", index=False)","cec0a89e":"from sklearn.model_selection import train_test_split\nX = spam.iloc[:,indices]\ny = spam['ham']\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state=1)\nclf = KNeighborsClassifier(n_neighbors=n_neighbors,p=1, weights='distance')\n#clf = BernoulliNB()\nclf.fit(X_train,y_train)\ny_pred = clf.predict_proba(X_test)","ca78326c":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, y_pred[:,1], pos_label=True) #TODO valida\u00e7\u00e3o cruzada!!!\nplt.plot(fpr,tpr)\nplt.title(\"Curva ROC\")\nplt.xlabel('1 - Specificity')\nplt.ylabel('Sensitivity')","8aabab55":"from sklearn.metrics import fbeta_score\nf_beta = []\nfor i in range(11):\n    f_beta.append(fbeta_score(y_test, y_pred[:,1]>=i*0.1, beta=3))\nplt.plot([0.1*i for i in range(11)],f_beta)\nplt.title(\"F_beta para beta = 3\")\nplt.xlabel('Threshold de probabilidade')\nplt.ylabel('F_beta')\nprint(\"F_beta max : \"+str(np.amax(f_beta)))\nprint(\"Threshold de probabilidade para F_beta max : \"+str(0.1*np.argmax(f_beta)))\nprint(\"FPR esperado para threshold de F_beta max : \"+str(fpr[np.argmin(np.abs(thresholds-0.1*np.argmax(f_beta)))]))","ec23cdc6":"### Defini\u00e7\u00e3o dos features a utilizar na classifica\u00e7\u00e3o\nDurante a an\u00e1lise, essa lista foi modificada algumas vezes para experimentar configura\u00e7\u00f5es diferentes","cd89ffda":"### Reutilizando o melhor classificador obtido para plotar sua curva ROC e calcular F_beta","c2eb1ebf":"### Leitura dos dados de treino e imports","1264a0ef":"### Verificando a vari\u00e2ncia e a m\u00e9dia de cada feature para os dois labels\nPermite verificar quais features discriminam bem spam de ham","bc0b617a":"### Formata\u00e7\u00e3o dos labels com os indices da submiss\u00e3o e escritura em arquivo","d5f9cfca":"### Leitura dos dados de teste, defini\u00e7\u00e3o do classificador a ser usado e previs\u00e3o dos labels","aa07b826":"### Verifica\u00e7\u00e3o do formato dos dados (tamanho e header)","e74a6da6":"### Valida\u00e7\u00e3o cruzada k-fold com k=10 para Naive Bayes e KNN","9697b270":"### Discuss\u00e3o de poss\u00edveis melhorias:\nUma poss\u00edvel melhoria seria o uso de outros embeddings, como TF-IDF por exemplo. A verifica\u00e7\u00e3o do e-mail de origem pode auxiliar na classifica\u00e7\u00e3o mas n\u00e3o \u00e9 suficiente pois nem sempre o e-mail que nos envia spam \u00e9 suspeito (quem envia spam tenta simular e-mails de empresas id\u00f4neas)."}}