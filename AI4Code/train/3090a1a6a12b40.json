{"cell_type":{"f768c416":"code","7135eeea":"code","b5df3e66":"code","ef67758f":"code","12726abd":"code","2d5ba170":"code","39d049d6":"code","019ad33a":"code","c81767b4":"code","df8df81f":"code","f162e201":"code","f3754976":"code","39ba3fa6":"markdown","f4b00c5e":"markdown","37fac370":"markdown","96efb7a5":"markdown","9709c9be":"markdown","a3f7b353":"markdown","8038035e":"markdown","873860c8":"markdown"},"source":{"f768c416":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom matplotlib.colors import LinearSegmentedColormap\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport seaborn as sns\nimport missingno\nimport calendar","7135eeea":"CMAP = [\"#69C9D6\", \"#8AC964\"]\nLP_CMAP = {0 : CMAP[0], 1 : CMAP[1]}\n\ncmap_learnplatform = LinearSegmentedColormap.from_list('mycmap', ['#69C9D6',\"#66C9D6\", \"#7AC997\", \"#93C948\", '#8AC964'])\n\nfig, ax = plt.subplots(figsize=(12, 2))\nfig.subplots_adjust(bottom=0.5)\n\ncmap = mpl.cm.cool\nnorm = mpl.colors.Normalize(vmin=0, vmax=1)\n\ncb1 = mpl.colorbar.ColorbarBase(ax, cmap=cmap_learnplatform,\n                                norm=norm,\n                                orientation='horizontal',\n                               ticks=[0,1])\ncb1.set_label('Colormap from LearnPlatform logo' , size=16)\ncb1.ax.set_xticklabels(['Low', 'High'], size=12)\n\nfig.show()","b5df3e66":"products_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\n\ndistricts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\") # For merge (left join), from int64 to object\ndistricts_info['district_id'] = districts_info['district_id'].apply(str) # For merge (left join), from int64 to string\n\npath = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nall_files = glob.glob(path + \"\/*.csv\")\n\ncollect = []\n\nfor filename in all_files:\n    temp_df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    temp_df[\"district_id\"] = district_id\n    collect.append(temp_df)\n    \nengagement_data = pd.concat(collect)\nengagement_data = engagement_data.reset_index(drop=True)\n\ndf = pd.merge(left=engagement_data, right=products_info, how='left', left_on='lp_id', right_on='LP ID', sort=False)\ndf = pd.merge(left=df, right=districts_info, how='left', left_on='district_id', right_on='district_id', sort=False)\n\ndel [[products_info, districts_info, engagement_data]] #for memory saving\n\ndf['time'] = pd.to_datetime(df['time'])\ndf['Year'] = df['time'].dt.year\ndf['Month'] = df['time'].dt.month\ndf['Week'] = df['time'].dt.isocalendar().week\n\ndf['pct_engagement'] = df['engagement_index']\/1000\n\ndf['locale_2'] = np.where(df['locale'].str.contains('Rural'), 'Rural', 'Urban')\n\n# To save memory - delete non-useful columns\n\ndf = df.drop(['lp_id','URL', 'engagement_index'], axis=1)","ef67758f":"connections_data = pd.read_csv(\"..\/input\/fcc-form-477-data-as-of-december-31-2018\/county_connections_dec_2018.csv\")\n\n# to exclude Value -9999 = data withheld to maintain firm confidentiality :\nconnections_data = connections_data[connections_data['ratio'] > 0] \n\n# to get household weighted connectivity ratio as state level :\nconnections_data['hhs_times_ratio'] = connections_data['hhs'] * connections_data['ratio']\nconnections_data_temp = connections_data.groupby('statename')\nconnections_data = connections_data_temp['hhs_times_ratio'].sum() \/ connections_data_temp['hhs'].sum()\nconnections_data = pd.DataFrame({'state':connections_data.index, 'county_connections_ratio(FCC)':connections_data.values}) # series to dataframe\n\ndf = pd.merge(left=df, right=connections_data, how='left', left_on='state', right_on='state', sort=False) # add on main df\n\ndel [connections_data] #for memory saving","12726abd":"FCC19_44A1_APDX2 = pd.read_csv(\"..\/input\/fcc1944a1pages5054-appendix2\/FCC-19-44A1-pages-50-54_appendix2.csv\")\n\ndf = pd.merge(left=df, right=FCC19_44A1_APDX2, how='left', left_on=['state','locale_2'], right_on=['state','locale_2'], sort=False) # add on main df\n\ndel [FCC19_44A1_APDX2] #for memory saving","2d5ba170":"conn_engage_data = df.groupby(['state']) \\\n       .agg(count=('pct_engagement', 'count'), mean=('pct_engagement', 'mean')) \\\n       .reset_index()\n\n#State list sort by high engagement index\nHigh_Eng_List = conn_engage_data.sort_values(by='mean', ascending=False).state.values \n\n#Data for Heatmap : State and locale\nconn_engage_heat = df.groupby(['locale','state']) \\\n       .agg(count=('pct_engagement', 'count'), mean=('pct_engagement', 'mean')) \\\n       .reset_index()\nconn_engage_heat = conn_engage_heat.pivot(\"locale\", \"state\", \"mean\")\nconn_engage_heat = conn_engage_heat.reindex(['City','Suburb','Town','Rural']) #Sort locale\nconn_engage_heat = conn_engage_heat[High_Eng_List] #Sort state\n\nlabels = conn_engage_heat.fillna(0) * 100\nlabels = labels.astype('int64').astype('str').replace(\"0\", \"\")+ \"%\"\n\nfig = plt.figure(figsize=(20,6))\nfig.patch.set_facecolor('#EEEEEE')\nfig.patch.set_alpha(1.0)\n\nax1 = sns.heatmap(conn_engage_heat, vmin=0.07, vmax=0.31, linewidths=0, cmap = cmap_learnplatform, cbar=True, annot=labels, fmt = '')\nax1.patch.set_facecolor('#FFFFFF')\nax1.patch.set_alpha(1.0)\n\ncbar = ax1.collections[0].colorbar\ncbar.set_ticks([0.07, 0.14, 0.31])\ncbar.set_ticklabels(['7% (Bottom20%)', '14% (Median)', '31% (Top20%)'])\n\nax1 = plt.xticks(rotation = 70, size=12)\nax1 = plt.yticks(rotation = 0 , size=14)\n\nax1 = plt.xlabel(\"State\")\nax1 = plt.ylabel(\"Locale\")\n\nax1 = plt.title('Unit: Engagement%\\nPeriod: 2020', fontsize = 11, loc='right')\nax1 = plt.title('Average Engagement by States and Locale',\n          fontsize = 18,\n          fontweight = 'heavy',\n          loc='center', \n          pad=30); #semi-colon for hide text before graph output","39d049d6":"conn_engage_locale_2 = df.groupby(['state', 'locale_2', 'county_connections_ratio(FCC)']) \\\n       .agg(count=('pct_engagement', 'count'), mean=('pct_engagement', 'mean')) \\\n       .reset_index()\n\nfig = plt.figure(figsize=(15,7))\n\nplt.tight_layout()\n\nfig.patch.set_facecolor('#EEEEEE')\nfig.patch.set_alpha(1.0)\n\nax1 = plt.subplot(1,2,1)\n\nax1 = sns.scatterplot(data=conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Urban'], x=\"county_connections_ratio(FCC)\", y=\"mean\", hue=\"mean\", palette=cmap_learnplatform, s=300)\nax1.patch.set_facecolor('#FFFFFF')\nax1.patch.set_alpha(1.0)\nax1.get_legend().remove()\n\ndef label_point(x, y, val, ax):\n    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n    for i, point in a.iterrows():\n        ax.text(point['x']-0.005, point['y']+0.01, str(point['val']))\nlabel_point(conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Urban'][\"county_connections_ratio(FCC)\"], conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Urban'][\"mean\"], conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Urban'][\"state\"], plt.gca()) \n\n#X\ucd95 & Y\ucd95 \ud45c\uc2dc \ubc84\uadf8 \uc788\uc74c\nvals = ax1.get_yticks()\nax1.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n\nvals = ax1.get_xticks()\nax1.set_xticklabels(['{:,.0%}'.format(x) for x in vals])\n\nax1 = plt.xlim(0.75, 1.00)\nax1 = plt.ylim(0   , 0.90)\n\nax1 = plt.axhline(0.13, 0, 1, color='lightskyblue', linestyle='--', linewidth='3')\nax1 = plt.text(0.982, 0.14, 'Median\\n(13%)', fontsize=12, fontweight='bold', color='lightskyblue', horizontalalignment='center')\n\nax1 = plt.xlabel(\"County Connections Ratio(FCC)\")\nax1 = plt.ylabel(\"Engagement% (mean)\")\n\nax1 = plt.gca().spines['right'].set_visible(False)\nax1 = plt.gca().spines['top'].set_visible(False)\nax1 = plt.gca().spines['left'].set_visible(True)\nax1 = plt.gca().spines['bottom'].set_visible(True)\n\nax1 = plt.title('City, Suburb, Town', fontsize = 9, loc='right')\nax1 = plt.title('Urban',\n          fontsize = 20,\n          fontweight = 'heavy',\n          loc='center', \n          pad=10); #semi-colon for hide text before graph output\n\nax2 = plt.subplot(1,2,2)\n\nax2 = sns.scatterplot(data=conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Rural'], x=\"county_connections_ratio(FCC)\", y=\"mean\", hue=\"mean\", palette=cmap_learnplatform, s=300)\nax2.patch.set_facecolor('#FFFFFF')\nax2.patch.set_alpha(1.0)\nax2.get_legend().remove()\n\ndef label_point(x, y, val, ax):\n    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n    for i, point in a.iterrows():\n        ax.text(point['x']-0.005, point['y']+0.01, str(point['val']))\nlabel_point(conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Rural'][\"county_connections_ratio(FCC)\"], conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Rural'][\"mean\"], conn_engage_locale_2[conn_engage_locale_2['locale_2'] == 'Rural'][\"state\"], plt.gca()) \n\n#X\ucd95 & Y\ucd95 \ud45c\uc2dc \ubc84\uadf8 \uc788\uc74c\nvals = ax2.get_yticks()\nax2.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n\nvals = ax2.get_xticks()\nax2.set_xticklabels(['{:,.0%}'.format(x) for x in vals])\n\nax2 = plt.xlim(0.75, 1.00)\nax2 = plt.ylim(0   , 0.90)\n\nax2 = plt.axhline(0.31, 0, 1, color='limegreen', linestyle='--', linewidth='3')\nax2 = plt.text(0.982, 0.26, 'Median\\n(31%)', fontsize=12, fontweight='bold', color='limegreen', horizontalalignment='center')\n\nax2 = plt.xlabel(\"County Connections Ratio(FCC)\")\nax2 = plt.ylabel(\"Engagement% (mean)\")\n\nax2 = plt.gca().spines['right'].set_visible(False)\nax2 = plt.gca().spines['top'].set_visible(False)\nax2 = plt.gca().spines['left'].set_visible(True)\nax2 = plt.gca().spines['bottom'].set_visible(True)\n\nax2 = plt.title('Rural only', fontsize = 9, loc='right')\nax2 = plt.title('Rural',\n          fontsize = 20,\n          fontweight = 'heavy',\n          loc='center', \n          pad=10); #semi-colon for hide text before graph output\n\n","019ad33a":"state_coverage_locale = df.groupby(['state', 'locale_2', 'Connected%_of_Pop.']) \\\n       .agg(count=('pct_engagement', 'count'), mean=('pct_engagement', 'mean')) \\\n       .reset_index()\n\nfig = plt.figure(figsize=(15,7))\n\nplt.tight_layout()\n\nfig.patch.set_facecolor('#EEEEEE')\nfig.patch.set_alpha(1.0)\n\nax1 = plt.subplot(1,2,1)\n\nax1 = sns.scatterplot(data=state_coverage_locale[state_coverage_locale['locale_2'] == 'Urban'], x=\"Connected%_of_Pop.\", y=\"mean\", hue=\"mean\", palette=cmap_learnplatform, s=300)\nax1.patch.set_facecolor('#FFFFFF')\nax1.patch.set_alpha(1.0)\nax1.get_legend().remove()\n\ndef label_point(x, y, val, ax):\n    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n    for i, point in a.iterrows():\n        ax.text(point['x']-0.005, point['y']+0.01, str(point['val']))\nlabel_point(state_coverage_locale[state_coverage_locale['locale_2'] == 'Urban'][\"Connected%_of_Pop.\"], \n            state_coverage_locale[state_coverage_locale['locale_2'] == 'Urban'][\"mean\"], \n            state_coverage_locale[state_coverage_locale['locale_2'] == 'Urban'][\"state\"], plt.gca()) \n\n#X\ucd95 & Y\ucd95 \ud45c\uc2dc \ubc84\uadf8 \uc788\uc74c\nvals = ax1.get_yticks()\nax1.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n\nvals = ax1.get_xticks()\nax1.set_xticklabels(['{:,.0%}'.format(x) for x in vals])\n\nax1 = plt.xlim(0.60, 1.00)\nax1 = plt.ylim(0   , 0.90)\n\nax1 = plt.axhline(0.13, 0, 1, color='lightskyblue', linestyle='--', linewidth='3')\nax1 = plt.text(0.800, 0.14, 'Median\\n(13%)', fontsize=12, fontweight='bold', color='lightskyblue', horizontalalignment='center')\n\nax1 = plt.xlabel(\"Connected%_of_Pop.\")\nax1 = plt.ylabel(\"Engagement% (mean)\")\n\nax1 = plt.gca().spines['right'].set_visible(False)\nax1 = plt.gca().spines['top'].set_visible(False)\nax1 = plt.gca().spines['left'].set_visible(True)\nax1 = plt.gca().spines['bottom'].set_visible(True)\n\nax1 = plt.title('City, Suburb, Town', fontsize = 9, loc='right')\nax1 = plt.title('Urban',\n          fontsize = 20,\n          fontweight = 'heavy',\n          loc='center', \n          pad=10); #semi-colon for hide text before graph output\n\nax2 = plt.subplot(1,2,2)\n\nax2 = sns.scatterplot(data=state_coverage_locale[state_coverage_locale['locale_2'] == 'Rural'], x=\"Connected%_of_Pop.\", y=\"mean\", hue=\"mean\", palette=cmap_learnplatform, s=300)\nax2.patch.set_facecolor('#FFFFFF')\nax2.patch.set_alpha(1.0)\nax2.get_legend().remove()\n\ndef label_point(x, y, val, ax):\n    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n    for i, point in a.iterrows():\n        ax.text(point['x']-0.005, point['y']+0.01, str(point['val']))\nlabel_point(state_coverage_locale[state_coverage_locale['locale_2'] == 'Rural'][\"Connected%_of_Pop.\"], state_coverage_locale[state_coverage_locale['locale_2'] == 'Rural'][\"mean\"], state_coverage_locale[state_coverage_locale['locale_2'] == 'Rural'][\"state\"], plt.gca()) \n\n#X\ucd95 & Y\ucd95 \ud45c\uc2dc \ubc84\uadf8 \uc788\uc74c\nvals = ax2.get_yticks()\nax2.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n\nvals = ax2.get_xticks()\nax2.set_xticklabels(['{:,.0%}'.format(x) for x in vals])\n\nax2 = plt.xlim(0.60, 1.00)\nax2 = plt.ylim(0   , 0.90)\n\nax2 = plt.axhline(0.31, 0, 1, color='limegreen', linestyle='--', linewidth='3')\nax2 = plt.text(0.800, 0.245, 'Median\\n(31%)', fontsize=12, fontweight='bold', color='limegreen', horizontalalignment='center')\n\nax2 = plt.xlabel(\"County Connections Ratio(FCC)\")\nax2 = plt.ylabel(\"Engagement% (mean)\")\n\nax2 = plt.gca().spines['right'].set_visible(False)\nax2 = plt.gca().spines['top'].set_visible(False)\nax2 = plt.gca().spines['left'].set_visible(True)\nax2 = plt.gca().spines['bottom'].set_visible(True)\n\nax2 = plt.title('Rural only', fontsize = 9, loc='right')\nax2 = plt.title('Rural',\n          fontsize = 20,\n          fontweight = 'heavy',\n          loc='center', \n          pad=10); #semi-colon for hide text before graph output\n","c81767b4":"Census2017 = pd.read_csv(\"..\/input\/us-census-demographic-data\/acs2017_county_data.csv\")\n\nCensus2017 = Census2017.drop(['CountyId','Income', 'IncomeErr', 'IncomePerCapErr',], axis=1)\n\nCensus2017['Hispanic'] = Census2017['TotalPop'] * Census2017['Hispanic'] \/ 100\nCensus2017['White'] = Census2017['TotalPop'] * Census2017['White'] \/ 100\nCensus2017['Black'] = Census2017['TotalPop'] * Census2017['Black'] \/ 100\nCensus2017['Native'] = Census2017['TotalPop'] * Census2017['Native'] \/ 100\nCensus2017['Asian'] = Census2017['TotalPop'] * Census2017['Asian'] \/ 100\nCensus2017['Pacific'] = Census2017['TotalPop'] * Census2017['Pacific'] \/ 100\n\nCensus2017['IncomePerCap'] = Census2017['TotalPop'] * Census2017['IncomePerCap'] #for get weight average later\n\nCensus2017['Poverty'] = Census2017['TotalPop'] * Census2017['Poverty'] \/ 100\nCensus2017['ChildPoverty'] = Census2017['TotalPop'] * Census2017['ChildPoverty'] \/ 100\nCensus2017['Professional'] = Census2017['TotalPop'] * Census2017['Professional'] \/ 100\nCensus2017['Service'] = Census2017['TotalPop'] * Census2017['Service'] \/ 100\nCensus2017['Office'] = Census2017['TotalPop'] * Census2017['Office'] \/ 100\nCensus2017['Construction'] = Census2017['TotalPop'] * Census2017['Construction'] \/ 100\nCensus2017['Production'] = Census2017['TotalPop'] * Census2017['Production'] \/ 100\nCensus2017['Drive'] = Census2017['TotalPop'] * Census2017['Drive'] \/ 100\nCensus2017['Carpool'] = Census2017['TotalPop'] * Census2017['Carpool'] \/ 100\nCensus2017['Transit'] = Census2017['TotalPop'] * Census2017['Transit'] \/ 100\nCensus2017['Walk'] = Census2017['TotalPop'] * Census2017['Walk'] \/ 100\nCensus2017['OtherTransp'] = Census2017['TotalPop'] * Census2017['OtherTransp'] \/ 100\nCensus2017['WorkAtHome'] = Census2017['TotalPop'] * Census2017['WorkAtHome'] \/ 100\nCensus2017['MeanCommute'] = Census2017['TotalPop'] * Census2017['MeanCommute'] \/ 100\nCensus2017['Carpool'] = Census2017['TotalPop'] * Census2017['Carpool'] \/ 100\n\nCensus2017['PrivateWork'] = Census2017['TotalPop'] * Census2017['PrivateWork'] \/ 100\nCensus2017['PublicWork'] = Census2017['TotalPop'] * Census2017['PublicWork'] \/ 100\nCensus2017['SelfEmployed'] = Census2017['TotalPop'] * Census2017['SelfEmployed'] \/ 100\nCensus2017['FamilyWork'] = Census2017['TotalPop'] * Census2017['FamilyWork'] \/ 100\nCensus2017['Unemployment'] = Census2017['TotalPop'] * Census2017['Unemployment'] \/ 100\n\n# Group by state\nCensus2017 = Census2017.groupby(['State']).sum()\n\n# Get ratio\nCensus2017['Men'] = Census2017['Men'] \/ Census2017['TotalPop'] * 100\nCensus2017['Women'] = Census2017['Women'] \/ Census2017['TotalPop'] * 100\n\nCensus2017['Hispanic'] = Census2017['Hispanic'] \/ Census2017['TotalPop'] * 100\nCensus2017['White'] = Census2017['White'] \/ Census2017['TotalPop'] * 100\nCensus2017['Black'] = Census2017['Black'] \/ Census2017['TotalPop'] * 100\nCensus2017['Native'] = Census2017['Native'] \/ Census2017['TotalPop'] * 100\nCensus2017['Asian'] = Census2017['Asian'] \/ Census2017['TotalPop'] * 100\nCensus2017['Pacific'] = Census2017['Pacific'] \/ Census2017['TotalPop'] * 100\n\nCensus2017['IncomePerCap'] = Census2017['IncomePerCap'] \/ Census2017['TotalPop'] #get weight average by state level\n\nCensus2017['Poverty'] = Census2017['Poverty'] \/ Census2017['TotalPop'] * 100\nCensus2017['ChildPoverty'] = Census2017['ChildPoverty'] \/ Census2017['TotalPop'] * 100\nCensus2017['Professional'] = Census2017['Professional'] \/ Census2017['TotalPop'] * 100\nCensus2017['Service'] = Census2017['Service'] \/ Census2017['TotalPop'] * 100\nCensus2017['Office'] = Census2017['Office'] \/ Census2017['TotalPop'] * 100\nCensus2017['Construction'] = Census2017['Construction'] \/ Census2017['TotalPop'] * 100\nCensus2017['Production'] = Census2017['Production'] \/ Census2017['TotalPop'] * 100\nCensus2017['Drive'] = Census2017['Drive'] \/ Census2017['TotalPop'] * 100\nCensus2017['Carpool'] = Census2017['Carpool'] \/ Census2017['TotalPop'] * 100\nCensus2017['Transit'] = Census2017['Transit'] \/ Census2017['TotalPop'] * 100\n\nCensus2017['VotingAgeCitizen'] = Census2017['VotingAgeCitizen'] \/ Census2017['TotalPop'] * 100\n\nCensus2017['Walk'] = Census2017['Walk'] \/ Census2017['TotalPop'] * 100\nCensus2017['OtherTransp'] = Census2017['OtherTransp'] \/ Census2017['TotalPop'] * 100\nCensus2017['WorkAtHome'] = Census2017['WorkAtHome'] \/ Census2017['TotalPop'] * 100\nCensus2017['MeanCommute'] = Census2017['MeanCommute'] \/ Census2017['TotalPop'] * 100\nCensus2017['Carpool'] = Census2017['Carpool'] \/ Census2017['TotalPop'] * 100\n\nCensus2017['Employed'] = Census2017['Employed'] \/ Census2017['TotalPop'] * 100\n\nCensus2017['PrivateWork'] = Census2017['PrivateWork'] \/ Census2017['TotalPop'] * 100\nCensus2017['PublicWork'] = Census2017['PublicWork'] \/ Census2017['TotalPop'] * 100\nCensus2017['SelfEmployed'] = Census2017['SelfEmployed'] \/ Census2017['TotalPop'] * 100\nCensus2017['FamilyWork'] = Census2017['FamilyWork'] \/ Census2017['TotalPop'] * 100\nCensus2017['Unemployment'] = Census2017['Unemployment'] \/ Census2017['TotalPop'] * 100\n\n# df = pd.merge(left=df, right=Census2017, how='left', left_on=['state'], right_on=['State'], sort=False) # add on main df\n\n# del [Census2017] #for memory saving","df8df81f":"district_df = df.groupby(['district_id', 'state', 'locale_2', 'Connected%_of_Pop.']) \\\n       .agg(count=('pct_engagement', 'count'), mean=('pct_engagement', 'mean')) \\\n       .reset_index()\n\ndistrict_df = pd.merge(left=district_df, right=Census2017, how='left', left_on=['state'], right_on=['State'], sort=False) # add on main df\n\ndistrict_df = district_df.drop(['count'], axis=1)\ndistrict_df.rename(columns = {'mean' : 'Engagement%'}, inplace=True)\n\nEngagment_median = district_df['Engagement%'].median()\n\ndistrict_df['Target'] = np.where(district_df['Engagement%'] >= Engagment_median, 1, 0)\n\n","f162e201":"covid19_data = pd.read_csv(\"..\/input\/us-counties-covid-19-dataset\/us-counties.csv\")\ncovid19_data['date'] = pd.to_datetime(covid19_data['date'])\ncovid19_data['year'] = covid19_data['date'].dt.year\ncovid19_data = covid19_data[covid19_data[\"year\"]==2020]\ncovid19_day_data = covid19_data.groupby('date')['cases'].sum().to_frame().reset_index()\ncovid19_day_data['Week'] = covid19_day_data['date'].dt.isocalendar().week\ncovid19_day_data = covid19_day_data.groupby('Week')['cases'].sum().to_frame()\ncovid19_day_data['new_cases'] = covid19_day_data['cases'].diff()\ncovid19_day_data['new_cases'][4] = 13 # Nan for input value\ncovid19_day_data = covid19_day_data.drop([53]) # not 7 days on week 53 on year 2020","f3754976":"# Data for line graph\nengage_trend = df.groupby('Week')['pct_engagement'].mean()\n\n# Graph Drewaing \nfig = plt.figure(figsize=(12,5))\n\nfig.patch.set_facecolor('#F3F7FF')\nfig.patch.set_alpha(1.0)\n\nax1 = sns.lineplot(engage_trend.index, engage_trend.values)\n\nvals = ax1.get_yticks()\nax1.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n\nax1.patch.set_facecolor('#F3F7FF')\nax1.patch.set_alpha(1.0)\n\nax2 = ax1.twinx()\nax2 = sns.barplot(covid19_day_data.index, covid19_day_data['new_cases'], color=\"blue\")\n\nax1 = plt.gca().spines['right'].set_visible(False)\nax1 = plt.gca().spines['top'].set_visible(False)\nax1 = plt.gca().spines['left'].set_visible(True)\nax1 = plt.gca().spines['bottom'].set_visible(True)\n\n\nax1 = plt.ylabel(\"Engagement% (mean)\")\n\n# ax1 = plt.axhline(0, 8, 0, color='black', linestyle='--', linewidth='1')\n\nax1 = plt.title('(Unit) Engagement Index\/1000\\n(Engagement) Total page load events\\n(Period) 2021\\n', fontsize = 9, loc='right')\nax1 = plt.title('Engagement Trend',\n          fontsize = 16,\n          fontweight = 'heavy',\n          loc='center', \n          pad=30); #semi-colon for hide text before graph output","39ba3fa6":"# Pre-Processing","f4b00c5e":"To Be Developed","37fac370":"# About LearnPlatform\n<br>\n<br>\n<center>\n<iframe width=\"600\" height=\"337\" src=\"https:\/\/www.youtube.com\/embed\/Fy19PNEXe1M\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>\n<br>\n**LearnPlatform in 100 seconds** (YouTube, 2020, [Link](https:\/\/youtu.be\/Fy19PNEXe1M))\n<\/center>\n<br>\nLaunched in 2014, LearnPlatform is home to an award-winning team of educators, researchers, technologists and thought leaders who build and deliver ground-breaking tools that increase the capacity of educators and their organizations to research, select and evaluate digital learning products that best meet the current needs of their students. \n\n*(From LearnPlatform, [About-Us](https:\/\/learnplatform.com\/about-us))*","96efb7a5":"Internet Access Services: Status as of December 31, 2018\nData Dictionary for County-Level Data from FCC Form 477 (N=3,234)\n\n* statename = State Name\n* hhs = Households, in thousands (Census: 2014-2018 5-year ACS)\n* ratio = residential \/ hhs\n* Value -9999 = data withheld to maintain firm confidentiality\n\nData From [FCC (Federal Communications Commission)](https:\/\/www.fcc.gov\/form-477-county-data-internet-access-services) ","9709c9be":"# What is the picture of digital connectivity and engagement in 2020?","a3f7b353":"<br>\n<br>\n<img src=\"https:\/\/i.imgur.com\/ckHd3Ko.png\" width=\"700px\">","8038035e":"Urban: City > Sub-Urban > Town\nRubal","873860c8":"# Demographic"}}