{"cell_type":{"f9a9c8dd":"code","682fb095":"code","055558e8":"code","144b6335":"code","47dad5d6":"code","da4a1413":"code","70d5a68c":"code","729ab38d":"code","5cfe7bdb":"code","02866c15":"code","4d51df1e":"code","7843fb08":"code","310bca13":"code","52920297":"code","39d2ca7c":"code","aa128fbe":"code","cc93e50f":"code","8d1af91f":"code","55287fd3":"code","9bf0eddb":"code","321cbf73":"markdown","ee6c5e5b":"markdown","29183793":"markdown","7d1fe2ff":"markdown","bce900f2":"markdown"},"source":{"f9a9c8dd":"import pandas as pd\nimport numpy as np\nimport re\n\nDIR_DATA_A = \"..\/input\/ukara-test-phase\"\nDIR_DATA_B = \"..\/input\/ukara-test-phase\"\nDIR_DATA_FINAL_A = \"..\/input\/ukara-training-bi-lstm-with-word2vec-for-data-a\"\nDIR_DATA_FINAL_B = \"..\/input\/ukara-training-bi-lstm-with-word2vec-for-data-b\"","682fb095":"!ls \"..\/input\/ukara-test-phase\"","055558e8":"data_A_train = pd.read_csv(\"{}\/data_train_A.csv\".format(DIR_DATA_A))\ndata_A_dev = pd.read_csv(\"{}\/data_dev_A.csv\".format(DIR_DATA_A))\ndata_A_test = pd.read_csv(\"{}\/data_test_A.csv\".format(DIR_DATA_A))\n\ndata_B_train = pd.read_csv(\"{}\/data_train_B.csv\".format(DIR_DATA_B))\ndata_B_dev = pd.read_csv(\"{}\/data_dev_B.csv\".format(DIR_DATA_B))\ndata_B_test = pd.read_csv(\"{}\/data_test_B.csv\".format(DIR_DATA_B))\n\n\ndf_final_A = pd.read_csv(\"{}\/df_final_A_test.csv\".format(DIR_DATA_FINAL_A))\ndf_dev_A = pd.read_csv(\"{}\/df_final_A_dev.csv\".format(DIR_DATA_FINAL_A))\ndf_cv_A = pd.read_csv(\"{}\/df_final_A_cv.csv\".format(DIR_DATA_FINAL_A))\n\ndf_final_B = pd.read_csv(\"{}\/df_final_B_test.csv\".format(DIR_DATA_FINAL_B))\ndf_dev_B = pd.read_csv(\"{}\/df_final_B_dev.csv\".format(DIR_DATA_FINAL_B))\ndf_cv_B = pd.read_csv(\"{}\/df_final_B_cv.csv\".format(DIR_DATA_FINAL_B))","144b6335":"data_A_train.head()","47dad5d6":"data_A_dev.head()","da4a1413":"data_A_test.head()","70d5a68c":"df_final_A.head()","729ab38d":"df_cv_A.head()","5cfe7bdb":"from sklearn.metrics import precision_score, recall_score, f1_score\ndef lr_cv_threshold(data_train, data_cv, threshold=None):\n    if threshold==None:\n        print(\"Threshold is not set. Searching..\")\n        for thresholdt in range(400, 700, 1):\n            cur_bin_pred_cv = [1 if x>=thresholdt\/1000 else 0 for x in data_cv]\n            f1 = f1_score(data_train, cur_bin_pred_cv)\n            precision = precision_score(data_train, cur_bin_pred_cv)\n            recall = recall_score(data_train, cur_bin_pred_cv)\n\n            print(\"score %.3f: %.5f, %.5f, %.5f\" % (thresholdt\/1000, f1, precision, recall))\n        \n    else:\n        print(\"Threshold is set. Using {} as threshold.\".format(threshold))\n        cur_bin_pred_cv = [1 if x>=threshold else 0 for x in data_cv]\n        f1 = f1_score(data_train, cur_bin_pred_cv)\n        precision = precision_score(data_train, cur_bin_pred_cv)\n        recall = recall_score(data_train, cur_bin_pred_cv)\n        print(\"score %.3f: %.5f, %.5f, %.5f\" % (threshold, f1, precision, recall))\n    ","02866c15":"# lr_cv_threshold(data_A_train[\"LABEL\"].values, df_cv_A[\"LABEL\"].values)","4d51df1e":"print(\"Cross-validation: \")\nlr_cv_threshold(data_A_train[\"LABEL\"].values, df_cv_A[\"LABEL\"].values, threshold=0.5)\nprint(\"\\nDev Data: \")\nlr_cv_threshold(data_A_dev[\"LABEL\"].values, df_dev_A[\"LABEL\"].values, threshold=0.5)\nprint(\"\\nTest Data: \")\nlr_cv_threshold(data_A_test[\"LABEL\"].values, df_final_A[\"LABEL\"].values, threshold=0.5)","7843fb08":"# lr_cv_threshold(data_B_train[\"LABEL\"].values, df_cv_B[\"LABEL\"].values)","310bca13":"print(\"Cross-validation: \")\nlr_cv_threshold(data_B_train[\"LABEL\"].values, df_cv_B[\"LABEL\"].values, threshold=0.5)\nprint(\"\\nDev Data: \")\nlr_cv_threshold(data_B_dev[\"LABEL\"].values, df_dev_B[\"LABEL\"].values, threshold=0.5)\nprint(\"\\nTest Data: \")\nlr_cv_threshold(data_B_test[\"LABEL\"].values, df_final_B[\"LABEL\"].values, threshold=0.5)","52920297":"print(\"Dev Data Result\")\nprediction = np.array([])\nlabel = np.array([])\n\nprediction = np.append(prediction, [1 if x>=0.5 else 0 for x in df_dev_A[\"LABEL\"].values])\nlabel = np.append(label, data_A_dev[\"LABEL\"].values)\n\nprediction = np.append(prediction, [1 if x>=0.5 else 0 for x in df_dev_B[\"LABEL\"].values])\nlabel = np.append(label, data_B_dev[\"LABEL\"].values)\n\nf1 = f1_score(label, prediction)\nprecision = precision_score(label, prediction)\nrecall = recall_score(label, prediction)\n\nprint(\"F1:\\t\\t%.5f \\nPrecision:\\t%.5f \\nRecall:\\t\\t%.5f\" % (f1, precision, recall))","39d2ca7c":"print(\"Test Data Result\")\nprediction = np.array([])\nlabel = np.array([])\n\nprediction = np.append(prediction, [1 if x>=0.5 else 0 for x in df_final_A[\"LABEL\"].values])\nlabel = np.append(label, data_A_test[\"LABEL\"].values)\n\nprediction = np.append(prediction, [1 if x>=0.5 else 0 for x in df_final_B[\"LABEL\"].values])\nlabel = np.append(label, data_B_test[\"LABEL\"].values)\n\n\nf1 = f1_score(label, prediction)\nprecision = precision_score(label, prediction)\nrecall = recall_score(label, prediction)\n\nprint(\"F1:\\t\\t%.5f \\nPrecision:\\t%.5f \\nRecall:\\t\\t%.5f\" % (f1, precision, recall))","aa128fbe":"df_final_A[\"LABEL\"] = df_final_A[\"LABEL\"].apply(lambda x: 1 if x>=500\/1000 else 0)\ndf_final_A.head()","cc93e50f":"df_final_B[\"LABEL\"] = df_final_B[\"LABEL\"].apply(lambda x: 1 if x>=500\/1000 else 0)\ndf_final_B.head()","8d1af91f":"df_final = pd.concat([df_final_A, df_final_B])\ndf_final= df_final.reset_index(drop=True)\nprint(df_final.shape)\ndf_final.head()","55287fd3":"df_final[\"LABEL\"].value_counts()","9bf0eddb":"df_final.to_json('{}\/predictions_test.json'.format(\".\"), orient='records')","321cbf73":"# DATA B","ee6c5e5b":"# COMBINE","29183793":"# Dev & Test Combination Result","7d1fe2ff":"# DATA A","bce900f2":"# UKARA: Combine Data A and Data B Result\n\nThis notebook produced the final result in my Ukara NLP Challenge submission. For more information, check the repository. \n\n\nRepository: [https:\/\/github.com\/ilhamfp\/ukara-1.0-challenge](https:\/\/github.com\/ilhamfp\/ukara-1.0-challenge)"}}