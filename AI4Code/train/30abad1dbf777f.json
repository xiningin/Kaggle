{"cell_type":{"b7386acb":"code","0c5d9494":"code","bf45af2a":"code","11d2d8b2":"code","36152e5a":"code","5a4498c9":"code","28b45dc0":"code","ec0b58b7":"code","5140377a":"code","ddc296dc":"code","5aed64d2":"code","ac174212":"code","74a9687e":"code","90646b85":"code","46ab5a4a":"code","1045f01e":"code","c17de8ca":"code","461c186f":"code","9e172471":"code","18b85570":"code","0082852e":"markdown"},"source":{"b7386acb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport gc","0c5d9494":"train = pd.read_csv('..\/input\/train.csv')\ntest  = pd.read_csv('..\/input\/test.csv')","bf45af2a":"print(\"train.csv. Shape: \",train.shape)\nprint(\"test.csv. Shape: \",test.shape)","11d2d8b2":"train_data = train\ntest_data = test\nsub_id = test['id']","36152e5a":"for i in [train_data,test_data]:\n    i['date'] = i['date'].apply(lambda e: e.split('T')[0])\n    i['yr_renovated'] = i['yr_renovated'].apply(lambda x: np.nan if x == 0 else x)\n    i['renovated'] = i['yr_renovated'].apply(lambda x: np.nan if x == 0 else x)\n    i['yr_renovated'] = i['yr_renovated'].fillna(i['yr_built'])\n    i['renovated'] = i['renovated'].fillna(0)\n    i['yr_renovated'] = i['yr_renovated'].astype('int')\n\ntrain.loc[train.renovated > 0,'renovated']= 1.0\ntest.loc[test.renovated > 0,'renovated']= 1.0","5a4498c9":"change_columns = ['bedrooms', 'sqft_living', 'sqft_lot','sqft_above',\n       'sqft_basement','sqft_living15', 'sqft_lot15']\n\nfor i in change_columns:\n    train_data[i] = np.log1p(train[i].values)\n    test_data[i] = np.log1p(test[i].values)","28b45dc0":"for df in [train_data,test_data]:\n    # \ubc29\uc758 \uc804\uccb4 \uac2f\uc218 \n    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n    # \uac70\uc2e4\uc758 \ube44\uc728 \n    df['sqft_ratio'] = df['sqft_living'] \/ df['sqft_lot']\n    # \ucd1d \uba74\uc801\n    df['sqft_total_size'] = df['sqft_above'] + df['sqft_basement']\n    # \uba74\uc801 \ub300\ube44 \uac70\uc2e4\uc758 \ube44\uc728 \n    df['sqft_ratio_1'] = df['sqft_living'] \/ df['sqft_total_size']\n    df['sqft_ratio15'] = df['sqft_living15'] \/ df['sqft_lot15']","ec0b58b7":"train_data = train_data.drop(['id'], axis=1)\ntest_data = test_data.drop(['id'], axis=1)","5140377a":"train_data['date'] = pd.to_datetime(train_data['date'].astype('str'))\ntest_data['date'] = pd.to_datetime(test_data['date'].astype('str'))\nfor i in [train_data, test_data]:\n    i['year'] = i['date'].dt.year\n    i['month'] = i['date'].dt.month\n    \ntrain_data = train_data.drop('date', axis=1)\ntest_data = test_data.drop('date', axis=1)","ddc296dc":"x = train_data.loc[:,:]\ny = train_data.loc[:,'price']\nx_test = test_data.loc[:,:]\nx = x.drop(['price'], axis=1)\nlog_y = np.log1p(y)","5aed64d2":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","ac174212":"n_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x.values)\n    rmse= np.sqrt(-cross_val_score(model, x.values, y, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","74a9687e":"model_xgb = xgb.XGBRegressor(colsample_bytree=0.4, gamma=0.0468, \n                             learning_rate=0.05, max_depth=6, \n                             min_child_weight=1.7817, n_estimators=15000,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.8, silent=1,\n                             random_state =25, nthread = -1)\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leave=2,\n                              learning_rate=0.05, n_estimators=15000,\n                              max_bin = 80, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\nmodel_gb = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =25)","90646b85":"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\ndef rmse_expm1(y, y_pred):\n    return np.sqrt(mean_squared_error(np.expm1(y), np.expm1(y_pred)))","46ab5a4a":"model_xgb.fit(x, log_y)\nxgb_train_pred = model_xgb.predict(x)\nxgb_pred = model_xgb.predict(x_test)\nxgb_pred = np.expm1(xgb_pred)\nprint(rmse_expm1(log_y, xgb_train_pred))","1045f01e":"model_lgb.fit(x, log_y)\nlgb_train_pred = model_lgb.predict(x)\nlgb_pred = model_lgb.predict(x_test)\nlgb_pred = np.expm1(lgb_pred)\nprint(rmse_expm1(log_y, lgb_train_pred))","c17de8ca":"model_gb.fit(x, log_y)\ngb_train_pred = model_gb.predict(x)\ngb_pred = model_gb.predict(x_test)\ngb_pred = np.expm1(gb_pred)\nprint(rmse_expm1(log_y, gb_train_pred))","461c186f":"print('RMSE score on train data:')\nprint(rmse_expm1(log_y,xgb_train_pred*0.4 + lgb_train_pred*0.4 + gb_train_pred*0.2 ))","9e172471":"ensemble = xgb_pred*0.4 + lgb_pred*0.4 + gb_pred*0.2","18b85570":"sub1 = pd.DataFrame(data={'id':sub_id,'price':ensemble})\nsub1.to_csv('submission1.csv', index=False)","0082852e":"\ud574\ub2f9 \ucee4\ub110\uc740 \uce90\uae00\ucf54\ub9ac\uc544 2\ucc28 \uba38\uc2e0\ub7ec\ub2dd \ub300\ud68c\uc5d0 \ucc38\uac00\ud558\uae30 \uc704\ud574 \uc791\uc131\ud55c \ucee4\ub110\ub85c, \ub2e4\ub978 \ubd84\ub4e4\uc758 \ucee4\ub110\uc744 \ub9ce\uc774 \ucc38\uace0\ud558\uc600\uc2b5\ub2c8\ub2e4.  \n\ub610\ud55c, \ube44\uc2b7\ud55c \ub300\ud68c\uc600\ub358 [House Prices: Advanced Regression Techniques](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques)\n\uc5d0 \uc0ac\uc6a9\ub418\uc5c8\ub358 \ucee4\ub110\uc744 \ucc38\uace0\ud574\uac00\uba70 \uc801\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \nhttps:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard  \n\ud574\ub2f9 \ucee4\ub110\uc774 \ub300\ud68c\uc758 \uc131\uaca9\ub3c4 \ube44\uc2b7\ud588\uace0, \uae30\ubcf8\uc744 \uc798 \uc124\uba85\ud55c \ucee4\ub110\uc774\uae30\uc5d0 \ucc38\uace0\ud558\uc600\uace0, \uc18c\uac1c\ud574\ub4dc\ub9bd\ub2c8\ub2e4.  \n\uc774\ubc88 \ub300\ud68c\uc5d0 \ucc38\uac00\ud558\uae30 \uc704\ud574 \ucc38\uace0\ud588\ub358 \ucee4\ub110\uc785\ub2c8\ub2e4.  \n\ud2b9\uc815 \ubd80\ubd84\ub9cc \ucc38\uace0\ud55c \ucee4\ub110\ub3c4 \uc788\uace0, \uc5ec\ub7ec \ubd80\ubd84\uc744 \ucc38\uace0\ud55c \ubd80\ubd84\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc544\ub798\uc5d0 \uc801\ud78c \ub0b4\uc6a9\ub9cc \ucc38\uace0\ud55c \uac83\uc740 \uc544\ub2d9\ub2c8\ub2e4.  \n\n(\ubca0\uc774\uc2a4\ub77c\uc778, \uc804\ucc98\ub9ac)  \nhttps:\/\/www.kaggle.com\/chocozzz\/house-price-prediction-eda-updated-2019-03-12  \nhttps:\/\/www.kaggle.com\/kcs93023\/2019-ml-month-2nd-baseline  \nhttps:\/\/www.kaggle.com\/harangdev\/skewed-feature-target-log  \n\n(\uc2a4\ud0dc\ud0b9, \uc559\uc0c1\ube14, \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130)  \nhttps:\/\/www.kaggle.com\/yeonmin\/default-eda-stacking-introduction  \nhttps:\/\/www.kaggle.com\/janged\/xgb-lgb  \nhttps:\/\/www.kaggle.com\/marchen911\/xgboost-lightgbm-catboost  \nhttps:\/\/www.kaggle.com\/ivoryrabbit\/a-note-on-using-a-single-model-xgboost  \n\n\ucee4\ub110\ub4e4\uc744 \ub9ce\uc774 \ucc38\uace0\ud574\uac00\uba70 \ub9cc\ub4e4\uc5c8\uae30 \ub54c\ubb38\uc5d0, EDA\ub294 \ub530\ub85c \uc9c4\ud589\ud558\uc9c0 \uc54a\uace0,  \n\ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4 \uc81c\ucd9c\ud558\ub294 \uacfc\uc815\ub9cc \uc788\uc2b5\ub2c8\ub2e4. \uc704\uc758 \ucee4\ub110\ub4e4\uc5d0\uc11c \ub9ce\uc740 \uc2dc\uac01\ud654 \uc790\ub8cc\uc640 \uc778\uc0ac\uc774\ud2b8\ub97c \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4 !    \n+\ucd94\uac00)\uc774\uc81c \uc194\ub8e8\uc158\ub4e4\uc774 \ubaa8\ub450 \uacf5\uac1c\ub418\ub2c8 \ub354 \ub9ce\uc740 \uc815\ubcf4\ub97c \uc5bb\uc744 \uc218 \uc788\uc744 \ub4ef \ud569\ub2c8\ub2e4."}}