{"cell_type":{"084ee1d3":"code","96df2b75":"code","5734360c":"code","2404267d":"code","ca2e98f3":"code","9ced799b":"code","71944720":"code","3627d39a":"code","8d6d520e":"code","69fbae5c":"code","dfe1d6ec":"code","51427cde":"code","889a5173":"code","928f416d":"code","0d8dc4c1":"code","4525f36d":"code","d3eb8784":"code","2c85aafd":"code","3b5408e7":"code","4b9edc50":"code","37d793cb":"code","8cf6ba49":"code","fd511d34":"markdown"},"source":{"084ee1d3":"import pathlib \nimport PIL\nimport tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom keras.preprocessing.image import load_img\nimport os\n\n\"\"\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/dataset\/Data Challenge\/Train_Dataset\/0'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n","96df2b75":"import sklearn\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom sklearn.model_selection import train_test_split\n\ndef load_Valeo_folder(path, target_size=None, verbose=True):\n    X = []\n    y = []\n    i = 0\n    for fname in os.listdir(path):\n        if '1' in fname:\n            for dirname, _, filenames in os.walk(os.path.join(path,fname)):            \n                for filename in filenames:\n                        \n                        X.append(\n                            np.array(load_img(os.path.join(dirname,filename),color_mode=\"grayscale\", target_size=target_size))\n                        )\n                        y.append(1)\n        elif '0' in fname:\n            for dirname, _, filenames in os.walk(os.path.join(path,fname)):\n                for filename in filenames:\n                        \n                        X.append(\n                            np.array(load_img(os.path.join(dirname,filename),color_mode=\"grayscale\", target_size=target_size))\n                        )\n                        y.append(0)\n        i+=1\n        if verbose and i % 50 == 0:\n            print('{0:.2f} % loaded'.format(100*(i\/len(os.listdir(path)))))\n    return np.array(X), np.array(y)\n  \n\n\n\ndef load_preprocessed_Valeo(base_folder, target_size=None, \n                                    verbose=True):\n    if verbose:\n        print(\"Loading training set\")\n    X_train, y_train = load_Valeo_folder(base_folder, \n                                                 target_size=target_size,\n                                                 verbose=verbose)\n    X_train = preprocess_input(X_train)\n\n    return X_train, y_train\n\n# The call is here:\nX_train, y_train = load_preprocessed_Valeo(pathlib.Path('\/kaggle\/input\/dataset\/Data Challenge\/Train_Dataset\/'), target_size=(260, 260))\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n\nprint(X_train.shape, y_train.shape, X_val.shape, y_val.shape)","5734360c":"data_dir = pathlib.Path('\/kaggle\/input\/dataset\/Data Challenge\/Train_Dataset\/')\n\nimage_count = len(list(data_dir.glob('*\/*.jpg')))\nprint(image_count)\n\ndata_dir = pathlib.Path('\/kaggle\/input\/dataset\/Data Challenge\/Train_Dataset\/')\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir,\n                                                               validation_split=0.2,\n                                                               subset=\"training\",\n                                                               label_mode='binary',\n                                                               seed=123,\n                                                               image_size=(260,260),\n                                                               batch_size=32,\n                                                               color_mode=\"grayscale\")\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir,\n                                                             validation_split=0.2,\n                                                             subset=\"validation\",\n                                                             seed=123,\n                                                             label_mode='binary',\n                                                             image_size=(260,260),\n                                                             batch_size=32,\n                                                             color_mode=\"grayscale\")\n","2404267d":"import matplotlib.pyplot as plt\n\nclass_names = train_ds.class_names\nprint(class_names)\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","ca2e98f3":"\"\"\"class_names = train_ds.class_names\nprint(class_names)\n\nimport matplotlib.pyplot as plt\nnew_train_ds=tf.cast(train_ds,tf.uint8)\n\ntrain_ds\nplt.figure(figsize=(10, 10))\nfor images, labels in tf.cast(train_ds.take(1),(tf.uint8,tf.uint8)):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")\"\"\"\n","9ced799b":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break\nfrom tensorflow.keras import backend as kb\n\n\ndef loss_pred(y_true,y_pred):\n    neg_y_true = tf.subtract(1.0,tf.cast(y_true,tf.float32))\n    neg_y_pred = tf.subtract(1.0,tf.cast(y_pred,tf.float32))\n    fp = kb.sum(tf.multiply(neg_y_true,tf.cast(y_pred,tf.float32)))\n    fn = kb.sum(tf.multiply(y_true,tf.cast(neg_y_pred,tf.float32)))\n    \n    return tf.multiply(tf.divide(1.0,tf.cast(tf.size(y_true),tf.float32)),\n                       tf.add(fn,tf.multiply(100.0,fp)))\n\n\ndef mean_pred(y_true,y_pred):\n    return tf.sqrt(tf.divide(tf.reduce_sum(tf.pow(tf.subtract(y_true,y_pred),2.0)),tf.cast(tf.size(y_true),tf.float32)))","71944720":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(500).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\nfor image_batch, labels_batch in val_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break\n\n","3627d39a":"import os\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\n!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O \/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n    \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '\/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npre_trained_model = InceptionV3(\n    input_shape=(260, 260, 3), include_top=False, weights=None)\npre_trained_model.load_weights(local_weights_file)\n\n","8d6d520e":"for layer in pre_trained_model.layers:\n  layer.trainable = False\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape:', last_layer.output_shape)\nlast_output = last_layer.output","69fbae5c":"from tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)\n\n# Configure and compile the model\nmodel = Model(pre_trained_model.input, x)\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=0.0001),\n              metrics=['acc'])\n\n","dfe1d6ec":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Retrieve a list of accuracy results on training and validation data\n# sets for each training epoch\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\n# Retrieve a list of list results on training and validation data\n# sets for each training epoch\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Get number of epochs\nepochs = range(len(acc))\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\n# Plot training and validation loss per epoch\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Training and validation loss')","51427cde":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    validation_split=0.3,\n    horizontal_flip=True)\n\n# Note that the validation data should not be augmented!\nval_datagen = ImageDataGenerator(rescale=1.\/255,validation_split=0.3)\n\ntrain_generator = train_datagen.flow_from_directory(\n        data_dir, # This is the source directory for training images\n        target_size=(260, 260),  # All images will be resized to 150x150\n        batch_size=32,\n        subset='training',\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using val_datagen generator\nvalidation_generator = val_datagen.flow_from_directory(\n        data_dir,\n        target_size=(260, 260),\n        batch_size=32,\n        subset='validation',\n        class_mode='binary')\n\n","889a5173":"history = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=6,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)","928f416d":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Retrieve a list of accuracy results on training and validation data\n# sets for each training epoch\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\n# Retrieve a list of list results on training and validation data\n# sets for each training epoch\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Get number of epochs\nepochs = range(len(acc))\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\n# Plot training and validation loss per epoch\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Training and validation loss')","0d8dc4c1":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras import layers, losses\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=2,\n      validation_data=validation_generator,\n      validation_steps=50,\n      verbose=2)\ndata_augmentation = Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n                                                 input_shape=(260, \n                                                              260,\n                                                              1)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)\n\nmodel1 = Sequential([\n      data_augmentation,\n     layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(260,260,1)),\n    Conv2D(filters=6, kernel_size=5, strides=1, padding='valid', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPool2D(pool_size=2),\n    Conv2D(filters=16, kernel_size=5, strides=1, padding='valid', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPool2D(pool_size=2),\n    Flatten(),\n    Dense(units=120, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(units=84, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(units=1, activation=\"sigmoid\")\n])\n\nmodelup = Sequential([\n  layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(260,260,1)),\n    Conv2D(filters=6, kernel_size=5, strides=1, padding='valid', activation=\"relu\"),\n    MaxPool2D(pool_size=2),\n    Conv2D(filters=16, kernel_size=5, strides=1, padding='valid', activation=\"relu\"),\n    MaxPool2D(pool_size=2),\n    Flatten(),\n    Dense(units=120, activation=\"relu\"),\n    Dense(units=84, activation=\"relu\"),\n    Dense(units=1, activation=\"sigmoid\")\n])\n\n\nmodel2 = Sequential([\n    layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(260,260,1)),\n    Conv2D(filters=6, kernel_size=(11,11), strides=(4,4), activation='relu'),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    Conv2D(filters=24, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    Conv2D(filters=24, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    Conv2D(filters=16, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    Flatten(),\n    Dense(120, activation='relu'),\n    Dropout(0.5),\n    Dense(84, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n\n\nmodel3 = Sequential([\n    layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(260,260,1)),\n    Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n    Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n    MaxPool2D(pool_size=(2,2)),\n    Dropout(0.25),\n    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n    MaxPool2D(pool_size=(2,2)),\n    Dropout(0.25),\n    Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n    Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n    MaxPool2D(pool_size=(2,2)),\n    Dropout(0.25),\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])","4525f36d":"import tensorflow_addons as tfa\n\noptimizer= tf.keras.optimizers.RMSprop(0.001)\n\n#SGD Model\n\nmodelSGD.compile(loss=tf.keras.losses.binary_crossentropy ,\n                 optimizer=tf.optimizers.SGD(lr=0.001),metrics=['binary_accuracy']) \n\n#RMSprop Model\n\nmodelRMS.compile(loss=tf.keras.losses.binary_crossentropy ,\n                 optimizer=tf.keras.optimizers.RMSprop(0.001),metrics=['binary_accuracy']) \n\nmodelRMS.compile(loss=tf.keras.losses.binary_crossentropy ,optimizer=tf.optimizers.SGD(lr=0.001),metrics=['binary_accuracy']) #\n\nmodel1.compile(loss=tf.keras.losses.binary_crossentropy ,optimizer=tf.optimizers.SGD(lr=0.001),metrics=['binary_accuracy']) #keras.losses.binary_crossentropy \/\/ SigmoidFocalCrossEntropy\n\n\nmodel1.summary()\n\nepochs=20\nhistory = model1.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","d3eb8784":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\nimport matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(20)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n\n","2c85aafd":"# librairies communes\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Librairies tensorflow\nfrom tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.python.keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","3b5408e7":"# losses functions (essais non-concluants)\nimport numpy as np\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import confusion_matrix\n\n\"\"\"\nExample of custom metric script.\nThe custom metric script must contain the definition of custom_metric_function and a main function\nthat reads the two csv files with pandas and evaluate the custom metric.\n\n\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\n\ndef custom_loss_function(dataframe_y_true, dataframe_y_pred):\n\n    tn, fp, fn, tp = confusion_matrix(dataframe_y_true, dataframe_y_pred).ravel()\n\n    lambda_ = 100\n    score = 1 \/ len(dataframe_y_true) * (fn + lambda_ * fp)\n    return score\n\nmodel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\"\"\"\n\n\"\"\"\ndef custom_metric_function(dataframe_y_true, dataframe_y_pred):\n\n    tn, fp, fn, tp = confusion_matrix(dataframe_y_true, dataframe_y_pred).ravel()\n\n    lambda_ = 100\n    score = 1 \/ len(dataframe_y_true) * (fn + lambda_ * fp)\n    return score\n\"\"\"\n\ndef customLoss(yTrue,yPred):\n    return K.sum(K.log(yTrue) - K.log(yPred))\n\ndef keras_custom_function(y_actual,y_predicted):\n    custom_loss_value= K.mean(K.sum(K.square(y_actual-y_predicted\/10)))\n    return custom_loss_value\n\ndef binary_specificity(y_true, y_pred):\n\n    TN = tf.logical_and(tf.cast(K.round(y_true),tf.int32) == 0, tf.cast(K.round(y_pred),tf.int32) == 0)\n    TP = tf.logical_and(tf.cast(K.round(y_true),tf.int32) == 1, tf.cast(K.round(y_pred),tf.int32) == 1)\n\n    FP = tf.logical_and(tf.cast(K.round(y_true),tf.int32)== 0,tf.cast(K.round(y_pred),tf.int32) == 1) #les pi\u00e8ces d\u00e9fectueuses sont identifi\u00e9es 0\n    FN = tf.logical_and(tf.cast(K.round(y_true),tf.int32) == 1, tf.cast(K.round(y_pred),tf.int32) == 0)\n\n    FN = K.sum(K.variable(FN))\n    FP = K.sum(K.variable(FP))\n    \n    recall = (FN + FP * 100.0) \/ 1990.0 #on accorde 100x plus d'importance aux FP\n\n    return recall\n\n\n\nkeras_model.compile(loss=binary_specificity, optimizer=\"adam\", metrics=['accuracy']) #loss= binary_specificity\"\"\"\nepochs=10\nhistory = keras_model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","4b9edc50":"\"\"\"from sklearn.metrics import confusion_matrix\n\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  '..\/input\/dataset\/Data Challenge\/test',\n  label_mode=None,\n  image_size=(260,260),\n  batch_size=32,\n  color_mode=\"grayscale\")\"\"\"\n","37d793cb":"import numpy as np\nimport pandas as pd\nfrom keras.preprocessing.image import load_img\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nimport os\n\ndirtest = '\/kaggle\/input\/dataset\/Data Challenge\/test\/Test_Dataset'\ndf = pd.DataFrame(columns=['images','labels'])\nfichier = pd.read_csv('..\/input\/y-images\/Y_Test_Inputs.csv')\n\n\n\"\"\"print(os.path.join(dirtest, fichier.loc[0].images))\nimage = load_img(os.path.join(dirtest, fichier.loc[0].images),color_mode=\"grayscale\",target_size=(260,260))\nimg_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = tf.expand_dims(img_array, 0)  # Convert single image to a batch.\npredictions = model.predict(input_arr)\ndf.append({'images': fichier.loc[1].images, 'labels': int(predictions.round().astype('int'))}, ignore_index=True)\"\"\"\n\nfor i in range(len(fichier)):\n    image = load_img(os.path.join(dirtest, fichier.loc[i].images),color_mode=\"grayscale\",target_size=(260,260,1))\n    img_array = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = tf.expand_dims(img_array, 0)  # Convert single image to a batch.\n    predictions = model1.predict(input_arr)\n    df=df.append({'images': fichier.loc[i].images, 'labels': int(predictions.round().astype('int'))}, ignore_index=True)\n\n","8cf6ba49":"df.to_csv('result4.csv', index=False)","fd511d34":"IMPLEMENTATION OF ANN "}}