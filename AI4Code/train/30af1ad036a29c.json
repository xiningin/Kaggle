{"cell_type":{"5498a498":"code","aae7bb58":"code","c302b382":"code","eadd5ce2":"code","5d4c162b":"code","a64de545":"code","940b2af0":"code","99d44da1":"code","9a2a7e5a":"code","1bb1fb0b":"code","85f07eae":"code","b3506a91":"code","157a5f19":"code","34fe743c":"code","a56c233e":"code","9b5e8f8f":"code","e2409255":"code","813163a7":"code","a287a5ba":"code","5e6db484":"markdown","f1ceddf7":"markdown","23bf4ee8":"markdown","f54085f6":"markdown","b5feda1f":"markdown","dc35ac07":"markdown"},"source":{"5498a498":"import tensorflow as tf\nfrom tensorflow.keras import backend as K\nimport tensorflow.keras.layers as layer\nfrom tensorflow.keras.applications.vgg16 import VGG16\nimport tensorflow_addons as tfa\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\nimport pickle\n\n\nfrom random import randint, seed\nimport itertools\nimport cv2","aae7bb58":"class SpectralTransform(tf.keras.layers.Layer):\n    def __init__(self,filters=64,kernel_size=3,padding='same',downsample=False):\n        super().__init__()\n        self.filters=filters\n        self.kernel_size=kernel_size\n        self.padding=padding\n        self.downsample=downsample\n        \n    def call(self,x,training=False):\n        x=self.down(x)\n        \n        x=self.conv1(x)\n        x=tf.nn.relu(self.bn(x,training=training))\n        skip=x\n        \n        #fft\n        x=tf.transpose(x,perm=[0,3,1,2]) #bchw\n        xfft=tf.signal.rfft(x)\n        xr,xi=tf.math.real(xfft),tf.math.imag(xfft)\n        x=tf.concat([xr,xi],axis=1) #b2chw\n        x=tf.transpose(x,perm=[0,2,3,1]) #bhw2c\n        x=tf.nn.relu(self.bnfft(self.convfft(x),training=training))\n        x=tf.transpose(x,perm=[0,3,1,2]) #b2chw\n        xr,xi=tf.split(x,num_or_size_splits=2,axis=1)\n        x=tf.complex(xr,xi)\n        x=tf.signal.irfft(x)\n        x=tf.transpose(x,perm=[0,2,3,1])\n        x=self.conv2(x+skip)\n        \n        return x\n    \n    \n    def build(self,input_shape):\n        self.conv1=tf.keras.layers.Conv2D(filters=self.filters,kernel_size=1,use_bias=False,\n                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))\n        \n        self.bn=tf.keras.layers.BatchNormalization()\n        \n        self.convfft=tf.keras.layers.Conv2D(filters=self.filters*2,kernel_size=1,use_bias=False,\n                                           kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))\n        self.bnfft=tf.keras.layers.BatchNormalization()\n        \n        self.conv2=tf.keras.layers.Conv2D(filters=self.filters,kernel_size=1,use_bias=False,\n                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))\n        \n        if self.downsample:\n            self.down=tf.keras.layers.AveragePooling2D()\n        else:\n            self.down=tf.keras.layers.Lambda(lambda x:x)","c302b382":"class FourierConvolution(tf.keras.layers.Layer):\n    def __init__(self,filters=64,kernel_size=3,padding='same',downsample=False):\n        super().__init__()\n        self.filters=filters\n        self.kernel_size=kernel_size\n        self.padding=padding\n        self.downsample=downsample\n        \n    def call(self,x,training=False):\n\n        Local,Global=tf.split(x, num_or_size_splits=2, axis=-1)\n        f1=self.conv1(Local)\n        f2=self.conv2(Local)\n        f3=self.conv3(Global)\n        f4=self.sp(Global,training=training)\n\n        Local=tf.nn.relu(self.bn1(f1+f3,training=training))\n        Global=tf.nn.relu(self.bn2(f2+f4,training=training))\n        \n        return tf.concat([Local,Global],axis=-1)\n    \n    \n    def build(self,input_shape):\n        self.sp=SpectralTransform(self.filters\/\/2,self.kernel_size,self.padding,self.downsample)\n        self.conv1=tf.keras.layers.Conv2D(filters=self.filters\/\/2,kernel_size=self.kernel_size,\n                                          strides=2 if self.downsample else 1,\n                                          padding=self.padding,use_bias=False,\n                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))\n        self.conv2=tf.keras.layers.Conv2D(filters=self.filters\/\/2,kernel_size=self.kernel_size,\n                                          strides=2 if self.downsample else 1,\n                                          padding=self.padding,use_bias=False,\n                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))\n        self.conv3=tf.keras.layers.Conv2D(filters=self.filters\/\/2,kernel_size=self.kernel_size,\n                                          strides=2 if self.downsample else 1,\n                                          padding=self.padding,use_bias=False,\n                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))\n        \n        self.bn1=tf.keras.layers.BatchNormalization()\n        self.bn2=tf.keras.layers.BatchNormalization()","eadd5ce2":"class ResBlock(tf.keras.layers.Layer):\n    def __init__(self):\n        super().__init__()\n        \n    def call(self,x,training=False):\n        skip=x\n        x=self.ffc1(x,training=training)\n        x=self.ffc2(x,training=training)\n        return x+skip\n        \n    \n    def build(self,input_shape):\n        self.ffc1=FourierConvolution(filters=input_shape[-1])\n        self.ffc2=FourierConvolution(filters=input_shape[-1])","5d4c162b":"class Upsample(tf.keras.layers.Layer):\n    def __init__(self,filters):\n        super().__init__()\n        self.filters=filters\n        \n    def call(self,x,training=False):\n        x=self.conv(x)\n        x=tf.nn.relu(self.bn(x,training=training))\n        return x\n    \n    def build(self,input_shape):\n        self.conv=tf.keras.layers.Conv2DTranspose(filters=self.filters,kernel_size=3,\n                                                  strides=2,padding='same',use_bias=False,\n                                                  kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)\n                                                 )\n        self.bn=tf.keras.layers.BatchNormalization()","a64de545":"class Generator(tf.keras.Model):\n    def __init__(self,nres=9,ndownsample=3,base=64):\n        super().__init__()\n        self.downsample=tf.keras.Sequential([FourierConvolution(64,kernel_size=7,downsample=True)])\n        \n        for i in range(1,ndownsample+1):\n            nc=2**i\n            self.downsample.add(FourierConvolution(base*nc,downsample=True))\n            \n        self.resblocks=tf.keras.Sequential([ResBlock() for i in range(nres)])\n        \n        \n        self.upsample=tf.keras.Sequential([\n            Upsample(base*(2**(ndownsample-i))) for i in range(1,ndownsample+1)\n        ])\n        \n        self.upsample.add(tf.keras.layers.Conv2DTranspose(filters=3,kernel_size=7,\n                                                          strides=2,padding='same',activation='tanh',\n                                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)))\n            \n    \n    def call(self,x,training=False):\n        x,mask=x\n        \n        x=tf.concat([x,mask],axis=-1)\n        \n        x=self.downsample(x,training=training)\n        \n        x=self.resblocks(x,training=training)\n        \n        x=self.upsample(x,training=training)\n        return x","940b2af0":"def block(x,filters,kernel_size=4,strides=2,padding='same',norm=True):\n    x=layer.Conv2D(filters=filters,kernel_size=kernel_size,\n                   strides=strides,padding=padding,\n                  kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))(x)\n    \n    if norm:\n        x=layer.BatchNormalization()(x)\n        \n    x=layer.LeakyReLU(0.2)(x)\n    return x","99d44da1":"def Discriminator():\n    x=layer.Input((None,None,3))\n    \n    f1=block(x,64,norm=False)\n    f2=block(f1,128)\n    f3=block(f2,256)\n    f4=block(f3,512)\n    f5=block(f4,512,strides=1)\n    f6=layer.Conv2D(filters=1,kernel_size=4,\n                    padding='same',kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01))(f5) #16x16\n    \n    return tf.keras.Model(inputs=[x],outputs=[f1,f2,f3,f4,f5,f6])","9a2a7e5a":"img_size=256\nbatch_size=30\nlr=1e-4\nepochs=20\nAUTOTUNE = tf.data.experimental.AUTOTUNE","1bb1fb0b":"pth='..\/input\/imagenet\/imagenet'\npth_mask='..\/input\/inpainting-mask-generator\/mask'\n\n#train\ntrain_folder=sorted(os.listdir(f'{pth}\/train'))\ntrain_mask_folder=sorted(os.listdir(f'{pth_mask}\/train'))\ndf_train=pd.DataFrame(np.vstack([train_folder,train_mask_folder]).T,columns=['pth','pth_mask'])\ndf_train['pth']=df_train['pth'].apply(lambda x: os.path.join(f'{pth}\/train\/{x}'))\ndf_train['pth_mask']=df_train['pth_mask'].apply(lambda x: os.path.join(f'{pth_mask}\/train\/{x}'))\n\n\n#val\nval_folder=sorted(os.listdir(f'{pth}\/val'))\nval_mask_folder=sorted(os.listdir(f'{pth_mask}\/val'))\ndf_val=pd.DataFrame(np.vstack([val_folder,val_mask_folder]).T,columns=['pth','pth_mask'])\ndf_val['pth']=df_val['pth'].apply(lambda x: os.path.join(f'{pth}\/val\/{x}'))\ndf_val['pth_mask']=df_val['pth_mask'].apply(lambda x: os.path.join(f'{pth_mask}\/val\/{x}'))","85f07eae":"def get_image(path,path_mask):\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image=tf.cast(tf.image.resize(image,(img_size,img_size)),'float32')\n    image=tf.keras.layers.Rescaling(1\/127.5,offset=-1.)(image)\n    \n    mask = tf.image.decode_jpeg(tf.io.read_file(path_mask), channels=1)\n    mask=tf.cast(tf.image.resize(mask,(img_size,img_size)),'float32')\n    mask=mask\/255.\n    return image,1-mask","b3506a91":"ds_train=tf.data.Dataset.from_tensor_slices((df_train['pth'],df_train['pth_mask'])).map(get_image,num_parallel_calls=AUTOTUNE).\\\n                        batch(batch_size,drop_remainder=True)\n\nds_val=tf.data.Dataset.from_tensor_slices((df_val['pth'],df_val['pth_mask'])).map(get_image,num_parallel_calls=AUTOTUNE).\\\n                        batch(batch_size,drop_remainder=True)","157a5f19":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ndef preprocessing(x,mask):\n    x=x*0.5+0.5\n    x=(x-mean)\/std\n    return x\n\ndef VGG():\n    vgg16=VGG16(include_top=False,weights=None)\n    vgg16.load_weights('..\/input\/vgg16-weights\/pytorch_to_keras_vgg16.h5',by_name=True)\n    vgg16.trainable=False\n    \n    layer_names=[f'block{c[0]}_conv{c[1]}' for c in [(1,1),(1,2),(2,1),(2,2),(3,1),(3,2),(3,3),(4,1),(4,2),(4,3)]]\n    \n    outputs = [vgg16.get_layer(name).output for name in layer_names]\n    \n    return tf.keras.Model([vgg16.input], outputs)","34fe743c":"loss_obj=tf.nn.sigmoid_cross_entropy_with_logits\n\ndef discriminator_loss(real,generated,mask):\n    mask=tf.image.resize(mask,real.shape[1:-1])>0\n    mask=tf.cast(mask,'float32')\n    real_loss = tf.reduce_mean(loss_obj(tf.ones_like(real), real))\n    generated_loss_real = tf.reduce_mean(loss_obj(tf.ones_like(generated), generated)*(1-mask))\n    generated_loss_fake = tf.reduce_mean(loss_obj(tf.zeros_like(generated), generated)*mask)\n    total_disc_loss = real_loss + generated_loss_real+generated_loss_fake\n    return total_disc_loss \n\ndef generator_loss(generated,mask):\n    #mask=tf.image.resize(mask,generated.shape[1:-1])>0\n    #mask=tf.cast(mask,'float32')\n    return tf.reduce_mean(loss_obj(tf.ones_like(generated), generated))\n\ndef gradient_penalty(disc,x, x_gen):\n    epsilon = tf.random.uniform([x.shape[0], 1, 1, 1], 0.0, 1.0)\n    x_hat = epsilon * x + (1 - epsilon) * x_gen\n    with tf.GradientTape() as t:\n        t.watch(x_hat)\n        d_hat =disc(x_hat)\n    gradients = t.gradient(d_hat, x_hat)\n    ddx = tf.sqrt(tf.reduce_sum(gradients ** 2, axis=[1, 2]))\n    d_regularizer = tf.reduce_mean((ddx - 1.0) ** 2)\n    return d_regularizer","a56c233e":"def l2(real,generated):\n    return tf.reduce_mean(tf.keras.losses.mean_squared_error(real, generated))\n\ndef perceptual_loss(real,generated):\n    loss=0\n    for r,g in zip(real,generated):\n        loss+=l2(r,g)\n    return loss","9b5e8f8f":"def show(x,mask,model,n=6):\n    x_masked= x*(1-mask)\n    \n    x_pred=model([x_masked,mask],training=False)\n    \n    mask = tf.concat([mask for _ in range(3)], -1)\n    \n    fig,ax=plt.subplots(nrows=3,ncols=n,figsize=(8,8))\n    \n    for i in range(3):\n        for j in range(n):\n            if i==1:\n                x=x_masked\n                ax[i,j].imshow(x[j]*0.5+0.5*(1-mask)[j])\n            elif i==0:\n                ax[i,j].imshow(x[j]*0.5+0.5)\n            elif i==2:\n                x=x_pred\n                ax[i,j].imshow(x[j]*0.5+0.5)\n    plt.savefig('.\/fig.jpg')\n    plt.show()","e2409255":"vgg=VGG()\n\n@tf.function\ndef train_step(x,mask,G,D,optG,optD):\n    \n    with tf.GradientTape(persistent=True) as tape:\n        x_masked= x*(1-mask)\n        \n        x_prime=G([x_masked,mask],training=True)\n        \n        #adversarial\n        Dmap_real=D(x,training=True)\n        Dmap_fake=D(x_prime,training=True)\n        \n        fmap_real=Dmap_real[:-1]\n        fmap_fake=Dmap_fake[:-1]\n        \n        preal=Dmap_real[-1]\n        pfake=Dmap_fake[-1]\n        \n        Dloss=discriminator_loss(preal,pfake,mask)\n        GPloss=gradient_penalty(D,x,x_prime)\n        Gloss=generator_loss(pfake,mask)\n        \n        #perceptual\n        vggmap_real=vgg(preprocessing(x,0.))\n        vggmap_fake=vgg(preprocessing(x_prime,mask))\n        \n        Perceptualloss=perceptual_loss(vggmap_real,vggmap_fake)\n        \n        Disc_Perceptualloss=perceptual_loss(fmap_real,fmap_fake)\n        \n        \n        GenLoss=10*Gloss+0.1*Perceptualloss+100*Disc_Perceptualloss\n        \n        DiscLoss=10*Dloss+1e-3*GPloss\n    \n        \n    Ggrad=tape.gradient(GenLoss,G.trainable_variables)\n    Dgrad=tape.gradient(DiscLoss,D.trainable_variables)\n    optG.apply_gradients(zip(Ggrad,G.trainable_variables))\n    optD.apply_gradients(zip(Dgrad,D.trainable_variables))\n    \n    return GenLoss,DiscLoss,Gloss,Dloss","813163a7":"def train():\n    tf.random.set_seed(999)\n    G=Generator()\n    D=Discriminator()\n    optG=tf.keras.optimizers.Adam(learning_rate=1e-3)\n    optD=tf.keras.optimizers.Adam(learning_rate=1e-4)\n    \n    ckpt = tf.train.Checkpoint(G=G,D=D,optG=optG,optD=optD)\n    ckpt_manager = tf.train.CheckpointManager(ckpt,'.\/ckpt', max_to_keep=1)\n    print('start training')\n    for epoch in range(epochs):\n        if epoch%2==0:\n            print('sampling')\n            for x,mask in ds_val:\n                show(x,mask,G)\n                break \n                \n            #save\n            ckpt_manager.save()\n            G.save_weights('.\/generator\/gen_weights')\n            D.save_weights('.\/discriminator\/disc_weights')\n            \n        loop=tqdm(ds_train)\n        for x,mask in loop:\n            GenLoss,DiscLoss,Gloss,Dloss=train_step(x,mask,G,D,optG,optD)\n            loop.set_postfix(loss=f'GenLoss:{GenLoss} DiscLoss:{DiscLoss} Gloss:{Gloss} Dloss:{Dloss}')\n    return G","a287a5ba":"G=train()","5e6db484":"## Generator","f1ceddf7":"## Train","23bf4ee8":"## Objective","f54085f6":"## Discriminator","b5feda1f":"# Training","dc35ac07":"# Model"}}