{"cell_type":{"323e82ec":"code","ff1a00a6":"code","2e8ca97b":"code","9beac5d4":"code","736f0f5f":"code","b63f12e2":"code","d3fb1c76":"code","7b611396":"code","a520fea8":"code","3c3e2b71":"code","e5bb7782":"code","6a291d4d":"code","9303abe0":"code","7fcaa101":"code","23cac944":"code","d240bb63":"code","c610cecd":"code","44405fe7":"code","a1a33fe9":"code","f4994ffd":"code","721cad82":"code","ca6936c0":"code","613c9c40":"code","a5cffa94":"code","9588da25":"code","45816068":"code","9ac88104":"code","ac4cef14":"code","54a586ba":"code","df05d5f9":"code","8cd805e4":"code","018bb878":"code","27ea04e5":"code","176ab63a":"code","49a1f1fd":"markdown","235407ad":"markdown","a597a548":"markdown","dc55b2fd":"markdown","67bd6ed5":"markdown"},"source":{"323e82ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport copy\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom tqdm import tnrange, tqdm_notebook as tqdm\n\n# Any results you write to the current directory are saved as output.","ff1a00a6":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","2e8ca97b":"TRAIN_PATH = \"..\/input\/train\/\"\ntrain_files = list(os.listdir(TRAIN_PATH))[100:]\nf = TRAIN_PATH+train_files[1]","9beac5d4":"im = mpimg.imread(f); im.shape","736f0f5f":"plt.imshow(im)\nplt.show()","b63f12e2":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms","d3fb1c76":"trainalldf = pd.read_csv(\"..\/input\/train.csv\") #, nrows=100)","7b611396":"trainalldf.count()","a520fea8":"whaleids = sorted(list(trainalldf['Id'].drop_duplicates()))\nprint(whaleids[:5]); print(len(whaleids))","3c3e2b71":"whaleids_dict = dict((k,v) for v,k in enumerate(whaleids))","e5bb7782":"BS = 32\nimage_input_size = 224\nresnet18 = torchvision.models.resnet18(pretrained=True)\nfor p in resnet18.parameters():\n    p.requires_grad = False # Freeze all existing layers","6a291d4d":"#model = nn.Sequential(*list(resnet18.children())[:-1], nn.Linear(512, len(whaleids)))\nresnet18.fc = nn.Linear(512, len(whaleids))","9303abe0":"resnet18.to('cuda')","7fcaa101":"norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\ninv_normalize = transforms.Normalize(\n    mean=[-0.485\/0.229, -0.456\/0.224, -0.406\/0.255],\n    std=[1\/0.229, 1\/0.224, 1\/0.255]\n)\n\ntransforms_dict = {\n    'train': transforms.Compose([transforms.RandomResizedCrop(image_input_size),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.ToTensor(),\n                                 norm]),\n    'val': transforms.Compose([transforms.Resize(image_input_size),\n                                 transforms.CenterCrop(image_input_size),\n                                 transforms.ToTensor(),\n                                 norm])\n}\n","23cac944":"class WhaleImageDataset(torchvision.datasets.folder.ImageFolder):\n    def __init__(self, ROOT_PATH, tfm, images, targets=None):\n        self.ROOT_PATH = ROOT_PATH\n        self.images = images\n        self.targets = targets\n        self.trans = tfm\n        self.loader = torchvision.datasets.folder.default_loader\n    \n    def __getitem__(self, index):\n        f = self.ROOT_PATH + self.images[index]\n        im = self.loader(f)\n        if self.targets is None: # Test mode has no targets\n            return self.trans(im)\n        return self.trans(im), self.targets[index]\n    \n    def __len__(self):\n        return len(self.images)\n    ","d240bb63":"trainallimages = trainalldf['Image'].values\ntrainallids = trainalldf['Id'].values\ntrainallclasses = np.array([whaleids_dict[id] for id in trainallids])","c610cecd":"from sklearn.model_selection import ShuffleSplit","44405fe7":"splitter = ShuffleSplit(n_splits=1, test_size=0.1)\n(train_idxs, val_idxs) = next(splitter.split(trainallimages, trainallclasses))\nidxs = {'train': train_idxs, 'val': val_idxs}","a1a33fe9":"#train_images, train_classes = trainallimages[train_idxs], trainallclasses[train_idxs]\n#val_images, val_classes = trainallimages[val_idxs], trainallclasses[val_idxs]\nimages_dict = {phase: trainallimages[idxs[phase]] for phase in ['train', 'val']}\nclasses_dict = {phase: trainallclasses[idxs[phase]] for phase in ['train', 'val']}","f4994ffd":"datasets_dict = {phase: WhaleImageDataset(TRAIN_PATH, transforms_dict[phase], images_dict[phase], classes_dict[phase]) for phase in ['train','val']}","721cad82":"im, c = datasets_dict['train'][1]\nprint(im.shape)\nim = im.permute(1,2,0)\nim2 = inv_normalize(im)\nprint(im2.shape)\nplt.imshow(im2)\nplt.show()","ca6936c0":"#train_dl = torch.utils.data.DataLoader(train_image_dataset, batch_size=BS, shuffle=True, num_workers=4)\n#val_dl = torch.utils.data.DataLoader(val_image_dataset, batch_size=BS, shuffle=True, num_workers=4)\ndataloaders_dict = {phase: torch.utils.data.DataLoader(datasets_dict[phase], batch_size=BS, shuffle=True, num_workers=1, pin_memory=True) \n                    for phase in ['train', 'val']}","613c9c40":"#X_batch, y_batch = next(iter(dataloaders_dict['train']))","a5cffa94":"opt = torch.optim.SGD(resnet18.fc.parameters(), lr=0.001, momentum=0.9)\ncrit = nn.CrossEntropyLoss()","9588da25":"NUM_EPOCHS = 30\n\nval_acc_history = []\n\nbest_model_wts = copy.deepcopy(resnet18.state_dict())\nbest_acc = 0.0\n\nfor epoch in range(NUM_EPOCHS):\n    print('Epoch {}\/{}'.format(epoch, NUM_EPOCHS - 1))\n    print('-' * 10)\n    \n    for phase in ['train', 'val']:\n        if phase == 'train':\n            resnet18.train()\n        else:\n            resnet18.eval()\n        \n        running_loss = 0.0\n        running_corrects = 0\n            \n        for X_batch, y_batch in dataloaders_dict[phase]:\n            X_batch = X_batch.to('cuda')\n            y_batch = y_batch.to('cuda')\n            \n            opt.zero_grad()\n            \n            outputs = resnet18(X_batch)\n            \n            loss = crit(outputs, y_batch)\n            \n            _, preds = torch.max(outputs, 1)\n            \n            if phase == 'train':\n                loss.backward()\n                opt.step()\n                \n            running_loss += loss.item() * X_batch.size(0)\n            running_corrects += torch.sum(preds == y_batch.data)\n            \n        epoch_loss = running_loss \/ len(dataloaders_dict[phase].dataset)\n        epoch_acc = running_corrects.double() \/ len(dataloaders_dict[phase].dataset)\n        \n        if phase == 'val' and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = copy.deepcopy(resnet18.state_dict())\n        if phase == 'val':\n            val_acc_history.append(epoch_acc)\n        \n        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))     \n\n    print('\\n')\n    \nprint('Best acc: {:.4f}'.format(best_acc))\nresnet18.load_state_dict(best_model_wts)","45816068":"torch.save(resnet18.state_dict(), '.\/resnet18.model')","9ac88104":"resnet18.load_state_dict(torch.load('.\/resnet18.model'))","ac4cef14":"def avprec_cutoff(inds, targets, N=5, m=1):\n    rels = (inds.numpy() == targets.numpy()).astype('int')\n    pks = []\n    for ki in range(1,N+1):\n        pk = rels[:,0:ki].sum(axis=1).reshape(-1,1)\/ki\n        pks.append(pk\/m)\n\n    return (np.concatenate(pks, axis=1) * rels).sum(axis=1)","54a586ba":"npwhaleids = np.array(whaleids)\ngap_num = 0.0\ngap_count = 0\n\nfor x_batch, y_batch in tqdm(dataloaders_dict['val']):\n    x_batch = x_batch.to('cuda')\n    outputs = resnet18(x_batch)\n    predinds = torch.argsort(outputs, dim=1, descending=True)[:,:5]\n    \n    gap_num += avprec_cutoff(predinds.to('cpu'), y_batch.view(-1,1), 5,1).sum()\n\n    gap_count += y_batch.shape[0]\n\nprint(gap_num\/gap_count)","df05d5f9":"resnet18.eval()\nTEST_PATH = \"..\/input\/test\/\"\nimages_test = list(os.listdir(TEST_PATH))\ndataset_test = WhaleImageDataset(TEST_PATH, transforms_dict['val'], images_test)\ndataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BS, shuffle=False, num_workers=1, pin_memory=True)","8cd805e4":"npwhaleids = np.array(whaleids)\ntest_classnames = []\nfor test_batch in tqdm(dataloader_test):\n    test_batch = test_batch.to('cuda')\n    outputs = resnet18(test_batch)\n    predinds = torch.argsort(outputs, dim=1, descending=True)[:,:5]\n    \n    whalestrs = npwhaleids[predinds.to('cpu').detach().numpy()].tolist()\n    \n    test_classnames.extend([\" \".join(s) for s in whalestrs])\n","018bb878":"testdf = pd.DataFrame({'Image': images_test, 'Id': test_classnames})","27ea04e5":"testdf.to_csv('submission.csv', index=False)","176ab63a":"from IPython.display import FileLink\nFileLink('submission.csv')","49a1f1fd":"## Apply to test set","235407ad":"## Calc metrics","a597a548":"## Cut resnet into new model","dc55b2fd":"## Set up optimiser","67bd6ed5":"## Split data into train\/val"}}