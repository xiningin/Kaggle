{"cell_type":{"aa1a05d0":"code","ba27252c":"code","9d5c7cc8":"code","d0866d7c":"code","8b2c20d7":"code","85629d8b":"code","4a4f420f":"code","a2d2a128":"code","e4078d90":"code","24658f33":"code","e2fffbd3":"code","f21835e6":"code","a0efbb8e":"code","d2bb3d73":"code","0e30b07c":"code","e7caf30b":"code","e03858e5":"code","48295711":"code","9d4ea16d":"code","e8f9ab02":"code","e072fd3c":"code","a0960ca7":"code","114fe23d":"code","e19047e1":"code","c3fdd8fb":"code","acb2eaea":"code","14ba4334":"code","83835763":"code","27290a90":"code","34d79d80":"code","b3c30b9b":"code","41c818e9":"code","26f24131":"code","97c4e1c5":"code","0c171d84":"code","7ca4c5c8":"code","4af5db5a":"code","6b4f6c6b":"code","013a93cd":"code","9547f168":"code","ff944b89":"code","bec232fc":"code","4453646d":"code","3ca1e78f":"code","eeb99f08":"code","c79b7eef":"code","7d571af4":"code","357fa7b0":"code","fc8d390a":"code","9f3995ae":"code","a05050ec":"code","93280e2d":"code","df218c91":"code","3cc2f5ad":"code","4fa44905":"code","a174e771":"code","cf4b5e47":"code","dbc9e25f":"code","3a216529":"code","e5a63fbe":"code","2989eac2":"code","cc44c114":"code","c53fdc16":"code","bdd744bb":"code","0e384f09":"code","e1a6d259":"code","62d6aba2":"code","e69c19ca":"code","a548b552":"code","e48e9061":"code","b94e3d8f":"code","90faad18":"markdown","84c835b9":"markdown","aff4a25d":"markdown","adb6bca5":"markdown","af2d4284":"markdown","c09c96bb":"markdown","2e1b09ff":"markdown","4dac91ba":"markdown","13bca62a":"markdown","bfd45de4":"markdown","2d75fcb0":"markdown","b818866c":"markdown","6b1c9bb0":"markdown","999c9e28":"markdown","5c84f5f0":"markdown","7cd88a7d":"markdown","30f0baed":"markdown","72ef24f2":"markdown","cd50f252":"markdown","7335709b":"markdown","ab85ad21":"markdown","6d74c66d":"markdown","fdaa4c88":"markdown","399f1306":"markdown","9a5008ae":"markdown","487ab3c8":"markdown","383c1653":"markdown","4488d089":"markdown","1ff40119":"markdown","5b1b38f0":"markdown","beedeac3":"markdown","8838efde":"markdown","a32e20f0":"markdown","7e3aa724":"markdown","ea7bfe65":"markdown","9d7b128d":"markdown","3c3c3dff":"markdown","badf8be5":"markdown","6839366e":"markdown","01ed6f6b":"markdown"},"source":{"aa1a05d0":"!pip install researchpy","ba27252c":"import pandas as pd\npd.set_option('display.max_rows',None)\n\nimport numpy as np\nimport sklearn\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom pandas_profiling import ProfileReport\nimport statsmodels.api as sm\nfrom sklearn.base import TransformerMixin\nfrom scipy import stats\nimport researchpy as rp\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport warnings\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\n","9d5c7cc8":"df_train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\").reset_index(drop=True)\ndf_test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\").reset_index(drop=True)","d0866d7c":"df_train_temp  = df_train.copy()\ndf_test_temp  = df_test.copy()\n\n\ndf_train_temp['train_data']  = 1\ndf_test_temp['train_data']  = 0\ndf = pd.concat([df_train_temp, df_test_temp], axis=0,sort=False)","8b2c20d7":"df.head(10)","85629d8b":"# profile_report = ProfileReport(df, title='House Price - Pandas Report',explorative=True)\nprofile_report = ProfileReport(df, title='House Price - Pandas Report')\n","4a4f420f":"# show pandas profil report\nprofile_report.to_notebook_iframe()","a2d2a128":"df.columns","e4078d90":"numerical_df = df[list(df._get_numeric_data().columns)].reset_index(drop=True)\ncategorical_df = df[list(set(df.columns) - set(df._get_numeric_data().columns))].reset_index(drop=True)\n\nprint (\"Number of numeric columns = {}\".format(len(numerical_df)))\nprint (\"Number of categorical columns = {}\".format(len(categorical_df)))","24658f33":"# This function to extract the descriptive stats of numerical features\ndef extractSummmary(df):\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Missing %'] = (df.isnull().sum()\/df.isnull().count()*100).values\n    summary['Uniques'] = df.nunique().values\n    summary['Uniques %'] = (df.nunique().values\/df.count()*100).values\n    summary['Median'] = df.median().values\n    summary['Mean'] = df.mean().values\n    summary['Max'] = df.max().values\n    summary['Min'] = df.min().values    \n    summary['std'] = df.std().values\n    \n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=10),2) \n    return summary\n\n\n# This function to extract the descriptive stats of categorical features\ndef extractSummmaryCategory(df):\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values\n    summary['Missing %'] = (df.isnull().sum()\/df.isnull().count()*100).values\n\n    summary['Uniques'] = df.nunique().values\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=10),2) \n    return summary\n\n","e2fffbd3":"summary =extractSummmary(numerical_df)\nsummary.sort_values('Uniques %',ascending=False)","f21835e6":"\nsummary =extractSummmaryCategory(categorical_df)\nsummary.sort_values('Missing %',ascending=False).head(10)\n","a0efbb8e":"categorical_df.describe()","d2bb3d73":"categorical_df.mode()","0e30b07c":"# df.drop('Id',axis=1,inplace=True)\nnumerical_df.drop('Id',axis=1,inplace=True)","e7caf30b":"# find out the features which has more than 40% null values\npercent_categorical = (categorical_df.isnull().sum()\/categorical_df.isnull().count()*100).sort_values(ascending=False)\nprint((percent_categorical[percent_categorical > 15]).index)\n\npercent_numerical = (numerical_df.isnull().sum()\/numerical_df.isnull().count()*100).sort_values(ascending=False)\nprint((percent_numerical[percent_numerical > 15]).index)\n","e03858e5":"# Drop the features\ncategorical_df = categorical_df.drop((percent_categorical[percent_categorical > 15]).index,1).reset_index(drop=True)\nnumerical_df = numerical_df.drop([key for key in (percent_numerical[percent_numerical > 15]).index if key != 'SalePrice'],1).reset_index(drop=True)\n","48295711":"target_feature = 'SalePrice'\n\ndef plot_boxplot(df, column, target_feature):\n    sns.boxplot(x=column, y=target_feature, data = df)\n\ndef plot_dist(df,columns,f):\n    ax1 = f.add_subplot(121)\n    \n    sns.distplot(df[columns],kde_kws={'bw': 0.1})\n    ax2 = f.add_subplot(122)\n    stats.probplot(df[columns], plot=ax2)\n\ndef plot_bar(df,column):\n    sns.barplot(column,'SalePrice',data = df, alpha=0.9)\n#     sns.barplot(df.index, df.values, alpha=0.9)\n\n    \n","9d4ea16d":"\nfor i,column in enumerate(numerical_df.columns):\n    f = plt.figure(figsize=(20,10))\n    plot_boxplot(numerical_df, column,target_feature)\n","e8f9ab02":"\nfor i,column in enumerate(numerical_df.columns):\n    f = plt.figure(figsize=(20,5))\n    plot_dist(numerical_df, column,f)","e072fd3c":"for i,column in enumerate(numerical_df.columns):\n    f = plt.figure(figsize=(20,5))\n    plot_bar(numerical_df,column)","a0960ca7":"def is_varaince_same(sample_01,sample_02,dependent_col):\n    #     Ho: same variance\n    #     H1: Varaicne are different\n\n    \n    print('\\n\\n\\n-------------------------------------levene test for variance -------------------------\\n')\n    laven_test_result = stats.levene(sample_01[dependent_col], sample_02[dependent_col])\n    print(laven_test_result)\n    return laven_test_result.pvalue\n\ndef is_normally_dist(sample_01,sample_02,dependent_col):\n\n    fig = plt.figure(figsize=(15,12))\n    ax = fig.add_subplot(3,1,1)\n    \n    diff = scale(np.array(sample_01[dependent_col]) - np.array(sample_02[dependent_col], dtype=np.float))\n    \n    # Distribution  \n    df_diff = pd.DataFrame(diff)\n    ax = fig.add_subplot(3,1,1)\n    df_diff.plot.hist()\n    \n    #     Shapiro wilk test for normality\n    #     H0 : Normally distributed\n    #     H1: \n    print('\\n\\n\\n -------------------- shapiro test for normality ---------------------\\n')\n    print(stats.shapiro(diff))\n    ax = fig.add_subplot(3,1,2)\n\n    #     QQ plot \n    stats.probplot(diff, plot=ax, dist='norm')\n    \n    \ndef box_plot(df,independent_col,dependent_col):\n    # Box plot \n    df.boxplot(column=[dependent_col], by=independent_col,figsize=(12,9))\n    \n\n\ndef t_test(df, independent_col, dependent_col,sample_01,sample_02):\n    #     fig = plt.figure()\n    #     ax = fig.add_subplot(3,1,1)\n    \n           \n    print('\\n\\n\\n----------------------------------- Describe ----------------------------------\\n')\n    print(df.groupby(independent_col)[dependent_col].describe())\n    \n    box_plot(df,independent_col,dependent_col)\n\n    #     Lavene's test \n    laven_test_result = is_varaince_same(sample_01,sample_02,dependent_col)\n    if laven_test_result > 0.05:\n        laven_variances = True\n    else:\n        laven_variances = False\n\n    #     Check normality\n    is_normally_dist(sample_01,sample_02,dependent_col)\n    \n    \n\n    #     Independent t-test by using scipy.stats\n    print('\\n\\n\\n------------------------------ Independent T- Test ----------------------------------\\n')\n    print(stats.ttest_ind(sample_01[dependent_col], sample_02[dependent_col]))\n    \n\n    #     Independent t-test using researchpy\n    variances =False\n    print('\\n\\n\\n-------------------------RP : T- Test ---------------------------------\\n')\n    descriptives, results = rp.ttest(sample_01[dependent_col], sample_02[dependent_col],equal_variances= laven_variances)\n    print(descriptives)\n    print('\\n\\n\\n------------------------------------------------------------------------------\\n')\n    print(results)\n    print('--------------------------------------------------------------------------------\\n')","114fe23d":"percent_categorical = categorical_df[categorical_df.columns].nunique()\nprint((percent_categorical[percent_categorical == 2]).index)\n","e19047e1":"numerical_df.columns","c3fdd8fb":"numerical_df['SalePrice'].values ","acb2eaea":"categorical_df['SalePrice'] = numerical_df['SalePrice'].values \nfor col in (percent_categorical[percent_categorical == 2]).index: \n    independent_col = col\n    values = categorical_df[col].value_counts().index\n    dependent_col ='SalePrice'\n    sample_01 = categorical_df[(categorical_df[independent_col] == values[0])]\n    sample_02 = categorical_df[(categorical_df[independent_col] == values[1])]\n    if sample_01.shape[0] > sample_02.shape[0]:\n        sample_val =  sample_02.shape[0]\n        sample_01 = sample_01.sample(sample_val)\n    else :\n        sample_val =  sample_01.shape[0]\n        sample_02 = sample_02.sample(sample_val)\n        \n        \n    if sample_val > 3:\n        t_test(categorical_df,col,dependent_col,sample_01,sample_02)\n    else:\n        print('Minimum 3 samples are required ')","14ba4334":"# Extract the details to replace in below function\n\nfor col in (percent_categorical[percent_categorical > 2]).index:\n    print(\"elif independent_col == '\" + col +\"' :\")\n    anova_cnd = []\n    anova_cnd.append(\"one_way_anova= stats.f_oneway(\")\n    for feature in categorical_df[col].unique():\n        anova_cnd.append(\"category_cols[dependent_col][category_cols[independent_col] == '\" + str(feature)+\"'],\")\n    \n    anova_cnd.append(\")\")\n    anova_str = ''.join(anova_cnd)\n    print(anova_str)\n    print('\\n')","83835763":"def one_way_anova(category_cols,independent_col,dependent_col):\n    print('\\n -------------------- describe ---------------------\\n')\n    print(category_cols.groupby(independent_col)[dependent_col].describe().T)\n    \n    \n    box_plot(category_cols,independent_col,dependent_col)\n    \n    print('\\n\\n -------------------- One way anova ---------------------\\n')\n     \n\n    if independent_col == 'Functional' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Typ'],category_cols[dependent_col][category_cols[independent_col] == 'Min1'],category_cols[dependent_col][category_cols[independent_col] == 'Maj1'],category_cols[dependent_col][category_cols[independent_col] == 'Min2'],category_cols[dependent_col][category_cols[independent_col] == 'Mod'],category_cols[dependent_col][category_cols[independent_col] == 'Maj2'],category_cols[dependent_col][category_cols[independent_col] == 'Sev'],)\n    \n    elif independent_col == 'GarageCond' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'Po'],category_cols[dependent_col][category_cols[independent_col] == 'Ex'],)\n\n    elif independent_col == 'HouseStyle' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == '2Story'],category_cols[dependent_col][category_cols[independent_col] == '1Story'],category_cols[dependent_col][category_cols[independent_col] == '1.5Fin'],category_cols[dependent_col][category_cols[independent_col] == '1.5Unf'],category_cols[dependent_col][category_cols[independent_col] == 'SFoyer'],category_cols[dependent_col][category_cols[independent_col] == 'SLvl'],category_cols[dependent_col][category_cols[independent_col] == '2.5Unf'],category_cols[dependent_col][category_cols[independent_col] == '2.5Fin'],)\n\n    elif independent_col == 'PavedDrive' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Y'],category_cols[dependent_col][category_cols[independent_col] == 'N'],category_cols[dependent_col][category_cols[independent_col] == 'P'],)\n\n    elif independent_col == 'BsmtQual' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Ex'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],)\n\n    elif independent_col == 'Condition2' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Norm'],category_cols[dependent_col][category_cols[independent_col] == 'Artery'],category_cols[dependent_col][category_cols[independent_col] == 'RRNn'],category_cols[dependent_col][category_cols[independent_col] == 'Feedr'],category_cols[dependent_col][category_cols[independent_col] == 'PosN'],category_cols[dependent_col][category_cols[independent_col] == 'PosA'],category_cols[dependent_col][category_cols[independent_col] == 'RRAn'],category_cols[dependent_col][category_cols[independent_col] == 'RRAe'],)\n\n    elif independent_col == 'ExterCond' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],category_cols[dependent_col][category_cols[independent_col] == 'Po'],category_cols[dependent_col][category_cols[independent_col] == 'Ex'],)\n\n    elif independent_col == 'BsmtExposure' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'No'],category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'Mn'],category_cols[dependent_col][category_cols[independent_col] == 'Av'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],)\n\n    elif independent_col == 'KitchenQual' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Ex'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],)\n\n    elif independent_col == 'HeatingQC' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Ex'],category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],category_cols[dependent_col][category_cols[independent_col] == 'Po'],)\n\n    elif independent_col == 'LotShape' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Reg'],category_cols[dependent_col][category_cols[independent_col] == 'IR1'],category_cols[dependent_col][category_cols[independent_col] == 'IR2'],category_cols[dependent_col][category_cols[independent_col] == 'IR3'],)\n\n    elif independent_col == 'Exterior1st' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'VinylSd'],category_cols[dependent_col][category_cols[independent_col] == 'MetalSd'],category_cols[dependent_col][category_cols[independent_col] == 'Wd Sdng'],category_cols[dependent_col][category_cols[independent_col] == 'HdBoard'],category_cols[dependent_col][category_cols[independent_col] == 'BrkFace'],category_cols[dependent_col][category_cols[independent_col] == 'WdShing'],category_cols[dependent_col][category_cols[independent_col] == 'CemntBd'],category_cols[dependent_col][category_cols[independent_col] == 'Plywood'],category_cols[dependent_col][category_cols[independent_col] == 'AsbShng'],category_cols[dependent_col][category_cols[independent_col] == 'Stucco'],category_cols[dependent_col][category_cols[independent_col] == 'BrkComm'],category_cols[dependent_col][category_cols[independent_col] == 'AsphShn'],category_cols[dependent_col][category_cols[independent_col] == 'Stone'],category_cols[dependent_col][category_cols[independent_col] == 'ImStucc'],category_cols[dependent_col][category_cols[independent_col] == 'CBlock'],)\n\n    elif independent_col == 'Exterior2nd' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'VinylSd'],category_cols[dependent_col][category_cols[independent_col] == 'MetalSd'],category_cols[dependent_col][category_cols[independent_col] == 'Wd Shng'],category_cols[dependent_col][category_cols[independent_col] == 'HdBoard'],category_cols[dependent_col][category_cols[independent_col] == 'Plywood'],category_cols[dependent_col][category_cols[independent_col] == 'Wd Sdng'],category_cols[dependent_col][category_cols[independent_col] == 'CmentBd'],category_cols[dependent_col][category_cols[independent_col] == 'BrkFace'],category_cols[dependent_col][category_cols[independent_col] == 'Stucco'],category_cols[dependent_col][category_cols[independent_col] == 'AsbShng'],category_cols[dependent_col][category_cols[independent_col] == 'Brk Cmn'],category_cols[dependent_col][category_cols[independent_col] == 'ImStucc'],category_cols[dependent_col][category_cols[independent_col] == 'AsphShn'],category_cols[dependent_col][category_cols[independent_col] == 'Stone'],category_cols[dependent_col][category_cols[independent_col] == 'Other'],category_cols[dependent_col][category_cols[independent_col] == 'CBlock'],)\n\n    elif independent_col == 'BsmtFinType2' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Unf'],category_cols[dependent_col][category_cols[independent_col] == 'BLQ'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],category_cols[dependent_col][category_cols[independent_col] == 'ALQ'],category_cols[dependent_col][category_cols[independent_col] == 'Rec'],category_cols[dependent_col][category_cols[independent_col] == 'LwQ'],category_cols[dependent_col][category_cols[independent_col] == 'GLQ'],)\n\n    elif independent_col == 'LotConfig' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Inside'],category_cols[dependent_col][category_cols[independent_col] == 'FR2'],category_cols[dependent_col][category_cols[independent_col] == 'Corner'],category_cols[dependent_col][category_cols[independent_col] == 'CulDSac'],category_cols[dependent_col][category_cols[independent_col] == 'FR3'],)\n\n    elif independent_col == 'MasVnrType' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'BrkFace'],category_cols[dependent_col][category_cols[independent_col] == 'None'],category_cols[dependent_col][category_cols[independent_col] == 'Stone'],category_cols[dependent_col][category_cols[independent_col] == 'BrkCmn'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],)\n\n    elif independent_col == 'GarageQual' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],category_cols[dependent_col][category_cols[independent_col] == 'Ex'],category_cols[dependent_col][category_cols[independent_col] == 'Po'],)\n\n    elif independent_col == 'RoofMatl' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'CompShg'],category_cols[dependent_col][category_cols[independent_col] == 'WdShngl'],category_cols[dependent_col][category_cols[independent_col] == 'Metal'],category_cols[dependent_col][category_cols[independent_col] == 'WdShake'],category_cols[dependent_col][category_cols[independent_col] == 'Membran'],category_cols[dependent_col][category_cols[independent_col] == 'Tar&Grv'],category_cols[dependent_col][category_cols[independent_col] == 'Roll'],category_cols[dependent_col][category_cols[independent_col] == 'ClyTile'],)\n\n    elif independent_col == 'LandContour' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Lvl'],category_cols[dependent_col][category_cols[independent_col] == 'Bnk'],category_cols[dependent_col][category_cols[independent_col] == 'Low'],category_cols[dependent_col][category_cols[independent_col] == 'HLS'],)\n\n    elif independent_col == 'Foundation' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'PConc'],category_cols[dependent_col][category_cols[independent_col] == 'CBlock'],category_cols[dependent_col][category_cols[independent_col] == 'BrkTil'],category_cols[dependent_col][category_cols[independent_col] == 'Wood'],category_cols[dependent_col][category_cols[independent_col] == 'Slab'],category_cols[dependent_col][category_cols[independent_col] == 'Stone'],)\n\n    elif independent_col == 'Electrical' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'SBrkr'],category_cols[dependent_col][category_cols[independent_col] == 'FuseF'],category_cols[dependent_col][category_cols[independent_col] == 'FuseA'],category_cols[dependent_col][category_cols[independent_col] == 'FuseP'],category_cols[dependent_col][category_cols[independent_col] == 'Mix'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],)\n\n    elif independent_col == 'MSZoning' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'RL'],category_cols[dependent_col][category_cols[independent_col] == 'RM'],category_cols[dependent_col][category_cols[independent_col] == 'C (all)'],category_cols[dependent_col][category_cols[independent_col] == 'FV'],category_cols[dependent_col][category_cols[independent_col] == 'RH'],)\n\n    elif independent_col == 'BldgType' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == '1Fam'],category_cols[dependent_col][category_cols[independent_col] == '2fmCon'],category_cols[dependent_col][category_cols[independent_col] == 'Duplex'],category_cols[dependent_col][category_cols[independent_col] == 'TwnhsE'],category_cols[dependent_col][category_cols[independent_col] == 'Twnhs'],)\n\n    elif independent_col == 'Neighborhood' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'CollgCr'],category_cols[dependent_col][category_cols[independent_col] == 'Veenker'],category_cols[dependent_col][category_cols[independent_col] == 'Crawfor'],category_cols[dependent_col][category_cols[independent_col] == 'NoRidge'],category_cols[dependent_col][category_cols[independent_col] == 'Mitchel'],category_cols[dependent_col][category_cols[independent_col] == 'Somerst'],category_cols[dependent_col][category_cols[independent_col] == 'NWAmes'],category_cols[dependent_col][category_cols[independent_col] == 'OldTown'],category_cols[dependent_col][category_cols[independent_col] == 'BrkSide'],category_cols[dependent_col][category_cols[independent_col] == 'Sawyer'],category_cols[dependent_col][category_cols[independent_col] == 'NridgHt'],category_cols[dependent_col][category_cols[independent_col] == 'NAmes'],category_cols[dependent_col][category_cols[independent_col] == 'SawyerW'],category_cols[dependent_col][category_cols[independent_col] == 'IDOTRR'],category_cols[dependent_col][category_cols[independent_col] == 'MeadowV'],category_cols[dependent_col][category_cols[independent_col] == 'Edwards'],category_cols[dependent_col][category_cols[independent_col] == 'Timber'],category_cols[dependent_col][category_cols[independent_col] == 'Gilbert'],category_cols[dependent_col][category_cols[independent_col] == 'StoneBr'],category_cols[dependent_col][category_cols[independent_col] == 'ClearCr'],category_cols[dependent_col][category_cols[independent_col] == 'NPkVill'],category_cols[dependent_col][category_cols[independent_col] == 'Blmngtn'],category_cols[dependent_col][category_cols[independent_col] == 'BrDale'],category_cols[dependent_col][category_cols[independent_col] == 'SWISU'],category_cols[dependent_col][category_cols[independent_col] == 'Blueste'],)\n\n    elif independent_col == 'ExterQual' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Ex'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],)\n\n    elif independent_col == 'RoofStyle' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Gable'],category_cols[dependent_col][category_cols[independent_col] == 'Hip'],category_cols[dependent_col][category_cols[independent_col] == 'Gambrel'],category_cols[dependent_col][category_cols[independent_col] == 'Mansard'],category_cols[dependent_col][category_cols[independent_col] == 'Flat'],category_cols[dependent_col][category_cols[independent_col] == 'Shed'],)\n\n    elif independent_col == 'Heating' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'GasA'],category_cols[dependent_col][category_cols[independent_col] == 'GasW'],category_cols[dependent_col][category_cols[independent_col] == 'Grav'],category_cols[dependent_col][category_cols[independent_col] == 'Wall'],category_cols[dependent_col][category_cols[independent_col] == 'OthW'],category_cols[dependent_col][category_cols[independent_col] == 'Floor'],)\n\n    elif independent_col == 'GarageType' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Attchd'],category_cols[dependent_col][category_cols[independent_col] == 'Detchd'],category_cols[dependent_col][category_cols[independent_col] == 'BuiltIn'],category_cols[dependent_col][category_cols[independent_col] == 'CarPort'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],category_cols[dependent_col][category_cols[independent_col] == 'Basment'],category_cols[dependent_col][category_cols[independent_col] == '2Types'],)\n\n    elif independent_col == 'BsmtCond' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'TA'],category_cols[dependent_col][category_cols[independent_col] == 'Gd'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],category_cols[dependent_col][category_cols[independent_col] == 'Fa'],category_cols[dependent_col][category_cols[independent_col] == 'Po'],)\n\n    elif independent_col == 'GarageFinish' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'RFn'],category_cols[dependent_col][category_cols[independent_col] == 'Unf'],category_cols[dependent_col][category_cols[independent_col] == 'Fin'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],)\n\n    elif independent_col == 'SaleType' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'WD'],category_cols[dependent_col][category_cols[independent_col] == 'New'],category_cols[dependent_col][category_cols[independent_col] == 'COD'],category_cols[dependent_col][category_cols[independent_col] == 'ConLD'],category_cols[dependent_col][category_cols[independent_col] == 'ConLI'],category_cols[dependent_col][category_cols[independent_col] == 'CWD'],category_cols[dependent_col][category_cols[independent_col] == 'ConLw'],category_cols[dependent_col][category_cols[independent_col] == 'Con'],category_cols[dependent_col][category_cols[independent_col] == 'Oth'],)\n\n    elif independent_col == 'BsmtFinType1' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'GLQ'],category_cols[dependent_col][category_cols[independent_col] == 'ALQ'],category_cols[dependent_col][category_cols[independent_col] == 'Unf'],category_cols[dependent_col][category_cols[independent_col] == 'Rec'],category_cols[dependent_col][category_cols[independent_col] == 'BLQ'],category_cols[dependent_col][category_cols[independent_col] == 'nan'],category_cols[dependent_col][category_cols[independent_col] == 'LwQ'],)\n\n    elif independent_col == 'SaleCondition' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Normal'],category_cols[dependent_col][category_cols[independent_col] == 'Abnorml'],category_cols[dependent_col][category_cols[independent_col] == 'Partial'],category_cols[dependent_col][category_cols[independent_col] == 'AdjLand'],category_cols[dependent_col][category_cols[independent_col] == 'Alloca'],category_cols[dependent_col][category_cols[independent_col] == 'Family'],)\n\n    elif independent_col == 'LandSlope' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Gtl'],category_cols[dependent_col][category_cols[independent_col] == 'Mod'],category_cols[dependent_col][category_cols[independent_col] == 'Sev'],)\n\n    elif independent_col == 'Condition1' :\n        one_way_anova= stats.f_oneway(category_cols[dependent_col][category_cols[independent_col] == 'Norm'],category_cols[dependent_col][category_cols[independent_col] == 'Feedr'],category_cols[dependent_col][category_cols[independent_col] == 'PosN'],category_cols[dependent_col][category_cols[independent_col] == 'Artery'],category_cols[dependent_col][category_cols[independent_col] == 'RRAe'],category_cols[dependent_col][category_cols[independent_col] == 'RRNn'],category_cols[dependent_col][category_cols[independent_col] == 'RRAn'],category_cols[dependent_col][category_cols[independent_col] == 'PosA'],category_cols[dependent_col][category_cols[independent_col] == 'RRNe'],)\n    else:\n        one_way_anova = 'no_feature'\n\n    if one_way_anova == 'no_feature':\n        pass\n    else :\n        print(one_way_anova)\n    \n        X = pd.get_dummies(category_cols[independent_col])\n        y = category_cols[dependent_col]    \n        print('\\n\\n\\n --------------------  OLS  ---------------------\\n')\n        result = sm.OLS(y, X).fit()\n        print(result.summary())","27290a90":"categorical_df['SalePrice'] = numerical_df['SalePrice'].values \nfor col in (percent_categorical[percent_categorical > 2]).index: \n    print('\\n\\n\\n --------------------  '+ col +' ---------------------')\n \n    independent_col = col\n    values = categorical_df[col].value_counts().index\n    dependent_col ='SalePrice'\n    one_way_anova(categorical_df,col,dependent_col)\n","34d79d80":"from statsmodels.formula.api import ols\ndef two_way_Anova(df,independent_dependent_col):\n    print(independent_dependent_col)\n    model = ols(independent_dependent_col,df ).fit()\n    print(model.summary())\n    print('\\n\\n\\n\\n-------------------------------Two Way Anova -----------------------------------------\\n')\n    print(sm.stats.anova_lm(model))\n    return model\n    ","b3c30b9b":"model = two_way_Anova(df, 'SalePrice ~ C(HouseStyle)+ C(Utilities)')","41c818e9":"model = two_way_Anova(df, 'SalePrice ~ C(SaleCondition)+ C(SaleType)')","26f24131":"# required imports\nfrom scipy.stats import chi2_contingency\n\ndef caclucalte_Chi2(columns_0,columns_1):\n    data_crosstab = pd.crosstab(chi2_df[columns_0], chi2_df[columns_1], margins = False) \n    stat, p, dof, expected = chi2_contingency(data_crosstab)\n    alpha = 0.05\n    print('significance=%.3f, p=%.3f' % (alpha, p))\n    if p <= alpha:\n        print(f' Given variables [{columns_0},{columns_1}] are independent ')\n    else:\n        print(f'Given variables [{columns_0},{columns_1}] are dependent')\n    return stat, p\n","97c4e1c5":"categorical_df.drop('SalePrice', axis=1, inplace=True)","0c171d84":"\nfrom sklearn import preprocessing\n#  Insread of label encoder, we can create the dict and map it with column values \ndef label_encoder(category_df):\n    category_cols = category_df\n    category_cols.dropna(inplace=True)\n    lbl_df = pd.DataFrame()\n    le = preprocessing.LabelEncoder()\n    for column in category_cols.columns:\n        lbl_df[column] = le.fit_transform(category_cols[column])\n    return lbl_df\n\nchi2_df = label_encoder(categorical_df.copy())\nchi2_df.reset_index(drop=True,inplace=True)","7ca4c5c8":"# data_crosstab = pd.crosstab(chi2_df['sex'], chi2_df['city'], margins = False) \n\nfrom itertools import permutations\nfor columns in list(permutations(chi2_df.columns, 2)):    \n    caclucalte_Chi2(columns[0],columns[1])\n","4af5db5a":"abs(numerical_df.var())","6b4f6c6b":"abs(numerical_df.corr()[\"SalePrice\"][abs(numerical_df.corr()[\"SalePrice\"])>0.5].drop('SalePrice')).index.tolist()","013a93cd":"#correlation matrix\nf, ax = plt.subplots(figsize=(20, 18))\nsns.heatmap( numerical_df.corr(), vmax=.8, annot=True,cmap='RdYlGn',annot_kws={'size':10});\n","9547f168":"col_vif_dict = {}\nnumerical_df_temp = numerical_df.copy()\nnumerical_df_temp.dropna(inplace=True)\nfor cols in numerical_df_temp.columns:\n    y = numerical_df_temp.loc[:, numerical_df_temp.columns == cols]\n    x = numerical_df_temp.loc[:, numerical_df_temp.columns != cols]\n    model = sm.OLS(y, x)\n    results = model.fit()\n    rsq = results.rsquared\n    vif = round(1 \/ (1 - rsq), 2)\n    col_vif_dict[cols] = vif","ff944b89":"col_vif_dict","bec232fc":"multicolinear_features = [key for key,value in col_vif_dict.items() if value > 30 and key not in ['SalePrice','train_data'] ]","4453646d":"multicolinear_features","3ca1e78f":"# drop the columns \nnumerical_df.drop(multicolinear_features, inplace=True, axis=1)\n","eeb99f08":"def out_iqr(df ):\n    for column in df.columns:\n        global lower,upper\n        \n        q25, q75 = np.quantile(df[column], 0.25), np.quantile(df[column], 0.75)\n        # calculate the IQR\n        iqr = q75 - q25\n        # calculate the outlier cutoff\n        cut_off = iqr * 1.5\n        # calculate the lower and upper bound value\n        lower, upper = q25 - cut_off, q75 + cut_off\n        \n        # Calculate the number of records below and above lower and above bound value respectively\n        df1 = df[df[column] > upper]\n        df2 = df[df[column] < lower]\n        if  df1.shape[0]+ df2.shape[0] > 0 and iqr > 0.0: \n            print('\\n'+ column)\n            print('The IQR is',iqr)\n            print('The lower bound value is', lower)\n            print('The upper bound value is', upper)\n            print('Total number of outliers are', df1.shape[0]+ df2.shape[0])\n            df.loc[(df[column] > upper) | (df[column] < lower),column] = np.nan\n\n    return df   ","c79b7eef":"numerical_df = out_iqr(numerical_df)\n","7d571af4":"# checking missing data\ntotal = numerical_df.isnull().sum().sort_values(ascending = False)\npercent = (numerical_df.isnull().sum()\/numerical_df.isnull().count()*100).sort_values(ascending = False)\nmissing_df_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_df_data.head(21)","357fa7b0":"# checking missing data\ntotal = categorical_df.isnull().sum().sort_values(ascending = False)\npercent = (categorical_df.isnull().sum()\/categorical_df.isnull().count()*100).sort_values(ascending = False)\nmissing_df_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_df_data.head(21)\n","fc8d390a":"# List the column which has 20 % null value\ndef filterProblematicColumns(df,threshold):\n    listOfColumnNames = []\n    for col in df.columns.tolist():\n        if df[col].isnull().sum()> threshold:\n            listOfColumnNames.append(col)\n            print(col)\n    \n    return listOfColumnNames\n\n# Set threshold for categorical features\nportion = 0.20\nthreshold = categorical_df.shape[0] * portion\ncolumnsToDrop = filterProblematicColumns(categorical_df, threshold)\n\n# categorical_features = categorical_features.drop(columns=columnsToDrop)\n\n# Set threshold for categorical features\nportion = 0.20\nthreshold = numerical_df.shape[0] * portion\ncolumnsToDrop = filterProblematicColumns(numerical_df, threshold)\n# numerical_features = numerical_features.drop(columns=columnsToDrop)\n","9f3995ae":"class MissingImputer(TransformerMixin):\n    def __init__(self):\n        pass\n#         Categorical features : most frequent value : Mode() \n#         Continious features : average value : mean() \n\n    def fit(self, X, y=None):\n\n        self.fill = pd.Series(\n            [\n                X[c].value_counts().index[0]\n                if X[c].dtype == np.dtype(\"O\")\n                else X[c].mean()\n                for c in X\n            ],\n            index=X.columns,\n        )\n\n        return self\n\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)","a05050ec":"categorical_df = MissingImputer().fit_transform(categorical_df)\n","93280e2d":"numerical_df = MissingImputer().fit_transform(numerical_df)\n","df218c91":"summary =extractSummmary(numerical_df)\nsummary.head(20)\n","3cc2f5ad":"summary =extractSummmaryCategory(categorical_df)\nsummary.head(20)","4fa44905":"def one_hot_encoding(df,all_columns,prefixs=None):\n    df_one_hot = pd.get_dummies(df, \n                         columns=all_columns, \n                         prefix= prefixs, \n                         drop_first=True)\n    return df_one_hot\n\ndef frequency_encoding(df, columns):\n    for column in columns: \n        fe = df.groupby(column).size()\/len(df)\n        df[column]=df[column].map(fe)\n    return df ","a174e771":"summary = pd.DataFrame(index = categorical_df.columns)\nsummary['Unique'] = categorical_df[categorical_df.columns].nunique().values\nsummary.head(100)","cf4b5e47":"categorical_df = one_hot_encoding(categorical_df,categorical_df.columns)\n","dbc9e25f":"numerical_df.reset_index(drop=True, inplace=True)\ncategorical_df.reset_index(drop=True, inplace=True)","3a216529":"all_df = pd.concat([numerical_df,categorical_df],axis=1)\n# df.loc[df['column_name'] == some_value]\n\nfinal_df = all_df.loc [all_df['train_data'] == 1]\nfinal_df_test = all_df.loc [all_df['train_data'] == 0]\n\n\n","e5a63fbe":"final_df_test.count()","2989eac2":"final_df_test.drop('SalePrice', axis=1,inplace=True)","cc44c114":"\ntarget_col = 'SalePrice'\nX = final_df.loc[:, final_df.columns != target_col]\ny = final_df.loc[:, target_col]\nx_train, x_test, y_train, y_test = train_test_split(X, np.log(y), \n                                                    test_size=0.33, \n                                                    random_state=42)","c53fdc16":"# Normalizing the Data\nx_train = (x_train - x_train.mean())\/x_train.std()\nx_test = (x_test - x_test.mean())\/x_test.std()","bdd744bb":"from lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nimport math\nxgb =XGBRegressor( booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=4, min_child_weight=1.5, n_estimators=2400,\n             n_jobs=1, nthread=None, objective='reg:linear',\n             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n             silent=None, subsample=0.8, verbosity=1)\n\n\nlgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=12000, \n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.4, \n                                       )","0e384f09":"xgb.fit(x_train, y_train)\nlgbm.fit(x_train, y_train,eval_metric='rmse')","e1a6d259":"predict1 = xgb.predict(x_test)\npredict = lgbm.predict(x_test)","62d6aba2":"from sklearn import metrics\nprint('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict1))))\nprint('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict))))","e69c19ca":"xgb.fit(X,y)\nlgbm.fit(X, y,eval_metric='rmse')","a548b552":"predict4 = lgbm.predict(final_df_test)\npredict3 = xgb.predict(final_df_test)\npredict_y = ( predict3*0.45 + predict4 * 0.55)\n\n","e48e9061":"submission = pd.DataFrame({\n        \"Id\": df_test[\"Id\"],\n        \"SalePrice\": predict_y\n    })\nsubmission.to_csv('..\/working\/submission.csv', index=False)","b94e3d8f":"print('Done')","90faad18":"#### Categorical : Frequency Count Plot :\n* Frequency plots are a visual tool used to analyze numerical data by showing the pattern of how often different values occur","84c835b9":"#### Since the data distribution is not same for the train and test dataset, we need to merge these datasets  and split it later. ","aff4a25d":"A t-test is a type of inferential statistic used to determine if there is a significant difference between the means of two groups, which may be related in certain features\n\n<b> Null hypothesis (H0): u1 = u2, which translates to the mean of sample_01 is equal to the mean of sample 02 <br>\n    Alternative hypothesis (H1): u1 ? u2, which translates to the means of sample01 is not equal to sample 02 <\/b>\n","adb6bca5":"## Glimpse on the data","af2d4284":"### Removing Multicolinearity using VIF:\n\nCheck the multicolinearity and drop the features which are colinear with ither features ","c09c96bb":"Create function to set mean value to numerical features and mode value to categorical features","2e1b09ff":"## Converting cateogrical columns to Numeric\n","4dac91ba":"#### I have tested for some but you can for other features","13bca62a":"impute mean value to numerical features ","bfd45de4":"#### Continious Featuers : Box Plot:\n*     This graph shows the shape of the distribution, its central value, and its variability.\n    \n*     Boxplots are a standardized way of displaying the distribution of data based on a five number summary (\u201cminimum\u201d, first quartile (Q1), median, third quartile (Q3), and \u201cmaximum\u201d).","2d75fcb0":"### Check variance :\nCheck the variacne if it is very low then those features you can drop ","b818866c":"#### Check the missing percentage of missing data and drop those columns","6b1c9bb0":"## Retrieve the data ","999c9e28":"Lavene\u2019s Test:\n\n    Lavene\u2019s test is used to test the variance of two or more category is same or not.\n    Null Hypothesis: Population from which two samples are drawn have equal variance \n    If Levene\u2019s test shows that null hypothesis nee\tds to be rejected \n    - Use two sample t-test for unequal  variances (Welch\u2019s t-test)\n    - Else you can use independent two sample  t-test for equal variance \n\n","5c84f5f0":"### Model Building","7cd88a7d":"#### Categorical Features :Data correctness:\n","30f0baed":"### Anova Test : Two Way:\n\nA two-way ANOVA test is a statistical test used to determine the effect of two nominal predictor variables on a continuous outcome variable.","72ef24f2":"### Standardize data","cd50f252":"### Chi2 Test","7335709b":"## Univariate Analysis","ab85ad21":"### Anova Test : One Way","6d74c66d":"## Descriptive Analysis","fdaa4c88":"## Deal With Outliers:\n\nIn below function we are finding the outliers and set it to null so that we can impute it.  ","399f1306":"**Note: This is very big notebook so it takes time to reload. Please read the complete notebook. Thanks.**\n\n## Summary: \n\n    1. Introduction\n    2. Retrieving the Data\n    3. Glimpse of Data\n    4. Extract pandas profile report for further analysis\n    5. Descriptive Analysis\n    6. Clean the data \n            6.1 Drop the featuers which has more than 15% null values \n            6.2 Drop the feature which has unique values\n    7. Univariate Analysis\n            7.1 Continious Features: Check outliers and distribution using Box Plot\n            7.2 Continious Features: Check the normal distribution\n            7.3 Categorical Features Frequency Count \n            7.4 T-Test : One Sample Location :T-Test\n            7.5 Anova : One Way\n    8. Bivariate Analysis\n            8.1 T-Test : Two Sample Location T-Test\n            8.2 Anova : Two way anova\n            8.3 Chi2 Test\n            8.4 Check variance\n            8.5 Correlation\n            8.6 Pair Plot  \n            8.7 Removing Multicolinearity using VIF\n    9.  Deal with outliers \n    10. Deal with missing values \n    11. Converting cateogrical columns to Numeric\n    12. Feature Selection\n    13. Standardize data\n    14. Model Building\n    15. Accuracy \n","9a5008ae":"impute mode value to categorical features ","487ab3c8":"## Impute Missing Data:\n\nyou can use multiple technique to impute missing value.\n<br>\nMore details :\nhttps:\/\/www.kaggle.com\/questions-and-answers\/174064","383c1653":"## Introduction \n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.","4488d089":"The one-way analysis of variance (ANOVA) is used to determine whether there are any statistically significant differences between the means of two or more independent (unrelated) groups (although you tend to only see it used when there are a minimum of three, rather than two groups).\n\n<b> H0: No difference between means, i.e. ?x1 = ?x2 = ?x3 <br>\n Ha: Difference between means exist somewhere, i.e. ?x1 ? ?x2 ? ?x3, or ?x1 = ?x2 ? ?x3, or ?x1 ? ?x2 = ?x3","1ff40119":"### T-test","5b1b38f0":"#### One Sample Location :T-Test","beedeac3":"#### Numerical Features :Data correctness:\n","8838efde":"### Correlation","a32e20f0":"## Bivariate Analysis","7e3aa724":"#### Pandas profiling : Report analysis:\nYou need to check below things:\n    1. Cardinality\n    2. Missing Values\n    3. Skewnes & Kurtosis\n    4. Unique Value\n    5. Zeros\n    6. Check Hormality (Normality) \n    7. Check correlation \n    8. Check IQR\n    9. Check minimum and maximum value \n    10. Check Variance \n","ea7bfe65":"## ANOVA\n\n* T-test are useful to compare the differences between two groups\/categories. T-test will tell you whether the averages across two groups or categories are different and if the difference are significant.\n* Running multiple significance tests to compare across many groups is risky and leads to Type1 Error. Hence we need to use ANOVA.","9d7b128d":"#### Drop the featuers which has more than 15% null values ","3c3c3dff":"#### Continious Featuers : Data Distribution:\n* The Q-Q plot, or quantile-quantile plot, is a graphical tool to help us assess if a set of data plausibly came from some theoretical distribution such as a Normal or exponential.\n*  distplot lets you show a histogram with a line on it","badf8be5":"## Clean the data","6839366e":"* T-Test is most common and simple statistical test.\n* Used to learn about averages across two categories.\n\n* One- sample location : Compare average of certain category  with constant\n![image.png](attachment:image.png)","01ed6f6b":"ANOVA: \n\n* Looks for multiple groups of populations, compares their means to produce one score and one significance value.\n* Perform a single ANOVA test to know whether the mean si different between these groups.\n* Null Hypothesis: all groups are at an equal mean\n* Alternate Hypothesis: all groups are NOT at an equal mean\n* F-Stat:\n![image.png](attachment:image.png)\n\n    If the groups are similar, F ~ 1 <br>\n    If the groups are different, F will be large\n\n"}}