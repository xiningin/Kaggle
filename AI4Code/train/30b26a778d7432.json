{"cell_type":{"bca64241":"code","49e4c984":"code","888cb768":"code","7429dd5b":"code","da28c059":"code","9b50aa40":"code","54aea6f8":"code","55e55a27":"code","489e5632":"code","ccd7087b":"code","df3c8149":"code","752b3023":"code","d5c63e7b":"code","f91582df":"code","6ae9ede1":"code","7acdf181":"code","c50f9d4c":"markdown","9e2c565e":"markdown","9673785c":"markdown","65c9f35b":"markdown","d3426f75":"markdown"},"source":{"bca64241":"import time\nfrom datetime import datetime\n\n#measure notebook running time\nstart_time = time.time()\n\n%matplotlib inline\n\n# backbone\nimport os, warnings\nimport numpy as np \nfrom numpy.random import seed\nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# DNN\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\nfrom keras import regularizers, models, layers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import metrics\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#from tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomHeight,RandomWidth,RandomTranslation,RandomContrast,RandomZoom\nimport tensorflow as tf\n\n\nfrom sklearn.model_selection import train_test_split\n\nsns.set(style='white', context='notebook', palette='deep')\nwarnings.simplefilter('ignore')\nprint(\"loaded ...\")","49e4c984":"TRAIN = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\n\n#quadruple set,since I am using random preprocessing\nTRAIN = pd.concat([TRAIN, TRAIN, TRAIN, TRAIN])\n#5x\n#TRAIN = pd.concat([TRAIN, TRAIN, TRAIN, TRAIN, TRAIN])\nTRAIN.shape","888cb768":"labels = to_categorical(TRAIN.label, num_classes=10)\nTRAIN = TRAIN.drop('label', axis=1)\nTRAIN = TRAIN.to_numpy() \/ 255","7429dd5b":"TEST = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nTEST = TEST.to_numpy() \/ 255","da28c059":"TRAIN = TRAIN.reshape(-1, 28, 28,1)\nTEST = TEST.reshape(-1, 28, 28,1)","9b50aa40":"plt.imshow(TEST[3])\nplt.show()","54aea6f8":"X_train, X_test, y_train, y_test = train_test_split(TRAIN, labels, test_size = 0.3, random_state = 13, stratify=labels)","55e55a27":"def plot_loss(loss,val_loss):\n    plt.figure()\n    plt.plot(loss)\n    plt.plot(val_loss)\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper right')\n    plt.show()\n\ndef plot_accuracy(acc,val_acc):\n    plt.figure()\n    plt.plot(acc)\n    plt.plot(val_acc)\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show() ","489e5632":"# Reproducibility\nRANDOM_SEED = 1313\ndef set_seed(sd=13):\n    seed(sd)\n    np.random.seed(sd)\n    tf.random.set_seed(sd)\n    os.environ['PYTHONHASHSEED'] = str(sd)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed(RANDOM_SEED)","ccd7087b":"DNN = Sequential()\nDNN.add(Input(shape = (28,28,1), name = 'input'))\n\n#preproc\nDNN.add(RandomContrast(factor=0.15, seed=RANDOM_SEED))\n#DNN.add(RandomRotation(factor=0.05, seed=RANDOM_SEED))\nDNN.add(RandomRotation(factor=0.05, seed=RANDOM_SEED))\nDNN.add(RandomZoom(height_factor=0.02,width_factor=0.02, seed=RANDOM_SEED))\n##\n\nDNN.add(Conv2D(64, kernel_size= (3,3), activation = 'relu', padding=\"same\")) \nDNN.add(BatchNormalization())\nDNN.add(MaxPool2D(2))\nDNN.add(Dropout(0.2, seed = RANDOM_SEED)) \n\nDNN.add(Conv2D(128, kernel_size= (3,3), activation = 'relu', padding=\"same\"))\nDNN.add(BatchNormalization())\nDNN.add(MaxPool2D(2))\nDNN.add(Dropout(0.2, seed = RANDOM_SEED)) \n\nDNN.add(Conv2D(256, kernel_size= (3,3), activation = 'relu', padding=\"same\"))\nDNN.add(BatchNormalization())\nDNN.add(MaxPool2D(2))\nDNN.add(Dropout(0.2, seed = RANDOM_SEED))\n\nDNN.add(Flatten())\n\nDNN.add(Dense(256, activation = 'relu'))\nDNN.add(Dropout(0.1, seed = RANDOM_SEED))\n\nDNN.add(Dense(64, activation = 'relu'))\nDNN.add(BatchNormalization())\n\nDNN.add(Dense(10, activation = 'softmax', name = \"output\"))\nDNN.summary()","df3c8149":"%%time\nDNN.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=1e-03), metrics=['accuracy'])\nearly_stopping_monitor = EarlyStopping(patience=5, monitor='val_accuracy')\n#checkpoint = ModelCheckpoint(\"weights.hdf5\", monitor = 'val_accuracy', save_best_only = True)\nDNN.fit(X_train,y_train, validation_data=(X_test,y_test), callbacks=[early_stopping_monitor], epochs=200, batch_size=256, verbose=0);\n#DNN.fit(X_train,y_train, validation_data=(X_test,y_test), callbacks=[early_stopping_monitor, checkpoint], epochs=200, batch_size=256, verbose=0);\n#DNN.load_weights(\"weights.hdf5\")\n#DNN.load_weights(\"weights.hdf5\")","752b3023":"%%time\nplot_loss(DNN.history.history['loss'], DNN.history.history['val_loss'])\nplot_accuracy(DNN.history.history['accuracy'], DNN.history.history['val_accuracy'])\n\n_, train_dnn_accuracy = DNN.evaluate(X_train, y_train)\n_, dnn_accuracy = DNN.evaluate(X_test, y_test)\nprint('Train accuracy: {:.2f} %'.format(train_dnn_accuracy*100))\nprint('Accuracy: {:.2f} %'.format(dnn_accuracy*100))\nprint('Overfit: {:.2f} % '.format((train_dnn_accuracy - dnn_accuracy)*100))","d5c63e7b":"results = DNN.predict(TEST)\npredictions = pd.Series(np.argmax(results, axis = 1),name=\"Label\")","f91582df":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predictions],axis = 1)\nsubmission.head(10)","6ae9ede1":"submission.to_csv('submission.csv', index=False)\nprint(\"Submission was successfully saved!\")","7acdf181":"end_time = time.time()\nprint(\"Notebook run time: {:.1f} seconds. Finished at {}\".format(end_time - start_time, datetime.now()) )","c50f9d4c":"# DigitRecognizer\n","9e2c565e":"# Predict","9673785c":"## Split","65c9f35b":"# Submission","d3426f75":"# DNN"}}