{"cell_type":{"814a6d9e":"code","d37953ec":"code","e0a9d5e6":"code","4e4d972f":"code","9328c658":"code","def971a0":"code","a7b205a8":"code","59f348ac":"code","688b6388":"code","46bc9ece":"code","27ef15e1":"code","26da9d43":"code","6c9df3bc":"code","16638a82":"code","c1c05500":"code","dfa78822":"code","9e3c1cb7":"code","2ebe44d0":"code","3c9b2c9b":"code","b1a2bcc6":"code","39004e63":"code","fbff0942":"code","980cbd6a":"code","1fe858f0":"code","66abd4bc":"code","f2b570cb":"code","a490c4aa":"code","509f4a84":"code","28a8051e":"code","849dfc10":"code","706cddf7":"code","adf3a487":"code","a3e332c2":"code","a837ce99":"code","1ae89e07":"code","bd05ec13":"code","bfab00c8":"code","b96447e7":"code","d029cee8":"code","a7b0817c":"code","2ca2ba32":"code","505ab6e5":"markdown","845f3b0c":"markdown","a0fc2877":"markdown","7d1c562d":"markdown","5ed81b87":"markdown","2af47956":"markdown","95552d35":"markdown","2b9bde4c":"markdown","3430fd9d":"markdown","94e78268":"markdown","d3477199":"markdown","430eab75":"markdown","aa8f803c":"markdown","6847ab88":"markdown","f4fd92ad":"markdown"},"source":{"814a6d9e":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nimport warnings\nwarnings.filterwarnings('ignore')","d37953ec":"train = pd.read_csv('..\/input\/forest-cover-type-prediction\/train.csv')\ntrain.drop('Id', axis=1, inplace=True)\ntest = pd.read_csv('..\/input\/forest-cover-type-prediction\/test.csv')","e0a9d5e6":"print(\"Training data shpae: \", train.shape)\nprint(\"Test data shpae: \", test.shape)","4e4d972f":"train.head(10)","9328c658":"train.info()","def971a0":"train.describe()","a7b205a8":"print(\"There are missing values in the training dataset: \", train.isnull().sum().values.sum() > 0)\nprint(\"There are missing values in the test dataset: \", test.isnull().sum().values.sum() > 0)","59f348ac":"plt.title(\"Distribution of cover type\")\nsns.barplot(train['Cover_Type'].value_counts().index, train['Cover_Type'].value_counts().values)\nplt.show()","688b6388":"soil_type = train.loc[:, 'Soil_Type1':'Soil_Type40'].stack()\nsoil_type = pd.Series(soil_type[soil_type!=0].index.get_level_values(1))\nfor i in range(soil_type.size):\n    soil_type.values[i] = int((soil_type.values[i])[9:])","46bc9ece":"wilderness_area = train.loc[:, 'Wilderness_Area1':'Wilderness_Area4'].stack()\nwilderness_area = pd.Series(wilderness_area[wilderness_area!=0].index.get_level_values(1))\nfor i in range(wilderness_area.size):\n    wilderness_area.values[i] = int((wilderness_area.values[i])[15:])","27ef15e1":"data = pd.concat([train.iloc[:, 0:10], wilderness_area, soil_type, train['Cover_Type']], axis=1)\ndata = data.rename(columns={0:'Wilderness_Area', 1:'Soil_Type'})","26da9d43":"data.head()","6c9df3bc":"pd.crosstab(data['Wilderness_Area'], data['Cover_Type'])","16638a82":"sns.catplot(data=data, kind='count', x='Cover_Type', hue='Wilderness_Area')\nplt.title('Distribution of cover type between wilderness areas')\nplt.show()","c1c05500":"pd.crosstab(data['Cover_Type'], data['Soil_Type'])","dfa78822":"data.groupby(['Cover_Type']).mean()","9e3c1cb7":"columns = data.columns[:-3]","2ebe44d0":"for column in columns:\n    sns.displot(data, x=data[column], hue='Cover_Type', kind='kde', fill=True, palette='Paired')\n    plt.title(column + ' distribution between cover types')\n    plt.show()","3c9b2c9b":"for column in columns:\n    sns.boxplot(x='Cover_Type', y=column, data=data, palette='Paired')\n    plt.title(column + ' distribution between cover types')\n    plt.show()","b1a2bcc6":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler","39004e63":"scaler = MinMaxScaler()\ntrain['Slope'] = scaler.fit_transform(np.array(train['Slope']).reshape(-1,1))","fbff0942":"columns = ['Elevation', 'Aspect', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', \n           'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\nscaler = MinMaxScaler()\nfor column in columns:\n    train[column] = scaler.fit_transform(np.array(train[column]).reshape(-1,1))","980cbd6a":"plt.figure(figsize=(10,10))\nsns.heatmap(data.corr().round(2), annot=True)\nplt.show()","1fe858f0":"from sklearn.model_selection import train_test_split","66abd4bc":"X_train, X_test, y_train, y_test = train_test_split(train.drop(['Cover_Type'], axis=1), train['Cover_Type'], random_state=42)","f2b570cb":"from sklearn.linear_model import LogisticRegression","a490c4aa":"lr = LogisticRegression(C=1)\nlr.fit(X_train, y_train)","509f4a84":"print(\"Accuracy on training set: \", lr.score(X_train, y_train))\nprint(\"Accuracy on test set: \", lr.score(X_test, y_test))","28a8051e":"from sklearn.ensemble import RandomForestClassifier","849dfc10":"rfc = RandomForestClassifier(n_estimators=1000)\nrfc.fit(X_train, y_train)","706cddf7":"print(\"Accuracy on training set: \", rfc.score(X_train, y_train))\nprint(\"Accuracy on test set: \", rfc.score(X_test, y_test))","adf3a487":"from sklearn.model_selection import cross_val_score","a3e332c2":"cross_val_score(rfc, X_train, y_train, cv=3, scoring='accuracy')","a837ce99":"from sklearn.model_selection import cross_val_predict","1ae89e07":"y_train_pred = cross_val_predict(rfc, X_train, y_train, cv=5)","bd05ec13":"from sklearn.metrics import confusion_matrix","bfab00c8":"conf_matrix = confusion_matrix(y_train, y_train_pred)\nconf_matrix","b96447e7":"plt.rcParams[\"figure.figsize\"] = (8, 8)\nplt.matshow(conf_matrix, interpolation ='nearest', cmap='plasma')\nplt.title(\"Confusion matrix\", fontdict={'fontsize':12})\nplt.colorbar()\nplt.show()","d029cee8":"row_sums = conf_matrix.sum(axis=1, keepdims=True)\nnorm_conf_matrix = conf_matrix \/ row_sums","a7b0817c":"np.fill_diagonal(norm_conf_matrix, 0)\n\nplt.rcParams[\"figure.figsize\"] = (8, 8)\nplt.matshow(norm_conf_matrix, interpolation ='nearest', cmap='plasma')\nplt.title('Plot of the errors\\n (divided by number of observations in the corresponding class)', fontdict={'fontsize':12})\nplt.colorbar()\nplt.show()","2ca2ba32":"submission = pd.DataFrame()\nsubmission['Id'] = test['Id']\nsubmission['Cover_Type'] = rfc.predict(test.drop('Id', axis=1))\nsubmission.set_index('Id', inplace=True)\nsubmission.to_csv('submission.csv')","505ab6e5":"At the beginning I will convert our train dataset to have Soil Type and Wilderness Area in single columns. Then I will present data in contingency table to check whether there is significant difference in proportions between groups. ","845f3b0c":"### Building model\n\n","a0fc2877":"#### Conclusions:\n\nWe have 56 columns in our train dataset but only 12 attributes (without ID and our target variable) because there are 4 columns dedicated to wilderness area and 40 columns dedicated to soil type. <br\/>\nAll attributes are of type int (wilderness area and soil type columns are binary which means that they can have only value 0 or 1). <br\/>\nWe do not have to deal with missing values in our datasets. ","7d1c562d":"We can see that wilderness area and soil type have significant influence on cover type because there are a lot of zeros in our tables which means that certain types of cover occur only in certain conditions.","5ed81b87":"<b>1) Goal: to predict the forest cover type from strictly cartographic variables.<\/b>\n\n<b>2) Data description<\/b><br\/>\nThe training set (15120 observations) contains both features information and the cover type. Each observation is a 30m x 30m patch.<br\/>\nThere are 4 binary columns for wilderness area and 40 binary columns for soil type in which 0 = absence and 1 = presence. <br\/>\nSeven cover types (our target variable): spruce\/fir, lodgepole pine, ponderosa pine, cottonwood\/willow, aspen, douglas-fir, krummholz.\n\n","2af47956":"Let's now evaluate our model using K-fold cross-validation.","95552d35":"### Exploratory data analysis","2b9bde4c":"From above plot we can see that many Lodgepole Pine (1 type) are classified as Spruce\/Fir (0 type) and another way around. ","3430fd9d":"We can see that we have the same number of occurences for each type of cover.","94e78268":"Now let's focus on remaining attributes.","d3477199":"### Quick overview of our data","430eab75":"### Making predictions","aa8f803c":"The next step is to build confusion matrix to see how our model make predictions.","6847ab88":"## Forest Cover Type Prediction\n\n_[Kaggle competition](https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/overview)_\n\nAuthor: Piotr Cichacki<br\/>\nDate: 18.02.2021","f4fd92ad":"### Our target variable: cover type"}}