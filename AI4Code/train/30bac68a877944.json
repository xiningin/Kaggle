{"cell_type":{"d4cbbf6b":"code","53a9be85":"code","764bea6b":"code","80f11514":"code","1e9504a8":"code","c4f79506":"code","6f16bbea":"code","dcee745e":"code","c52807d4":"code","e6151710":"code","e47c2af2":"code","04ebc70b":"code","86056e60":"code","73f71694":"code","9e1089e0":"code","85f4b073":"code","a3cf3dbc":"code","ae7b568e":"code","f92147db":"code","c86f280a":"code","36526a40":"code","68757ad2":"code","5dbf0bae":"code","865682e0":"code","76709616":"markdown","0ee44813":"markdown"},"source":{"d4cbbf6b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","53a9be85":"from fastai.vision import *\nfrom fastai.metrics import error_rate\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport numpy as np \n\nimport matplotlib.pyplot as plt\nimport time\nimport os\n","764bea6b":"from fastai.callbacks import ActivationStats\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')","80f11514":"#path = untar_data(URLs.MNIST_SAMPLE)\n#data = ImageDataBunch.from_folder(path)\n#learn = cnn_learner(data, models.resnet18, callback_fns=ActivationStats)\n#learn = Learner(data, simple_cnn((3,16,16,2)), callback_fns=ActivationStats)\n#learn.wd = 0.0001\n#learn.fit(2)\n\n#bs = 192\n#xfit = np.linspace(0, bs-1,bs)\n#mean_y = learn.activation_stats.stats[0][1][-(bs-1):]\n#std_y = learn.activation_stats.stats[1][1][-(bs-1):]\n# Visualize the result\n#plt.plot(xfit, mean_y, '-', color='gray')\n\n#plt.fill_between(xfit, mean_y - std_y, mean_y + std_y,\n#                 color='gray', alpha=0.2)","1e9504a8":"class_names = os.listdir('..\/input\/mushrooms\/Mushrooms\/')","c4f79506":"bs = 64\npath = Path(\"..\/input\/mushrooms\/Mushrooms\/\")\nfnames = []\nfor fpath in class_names:\n    print(path\/f'{fpath}\/')\n    fnames += get_image_files(path\/f'{fpath}\/')","6f16bbea":"np.random.seed(2)\npat = r\"\/(\\w+)\/\\d+(_).+\\.jpg$\"\ndata = ImageDataBunch.from_name_re('.', fnames, pat, ds_tfms=get_transforms(), size=224, bs=bs, num_workers = 0).normalize(imagenet_stats)\ntrain_dataset, test_dataset = torch.utils.data.random_split(data.train_ds, [len(data.train_ds) - 600, 600])\n","dcee745e":"data = DataBunch.create(train_dataset.dataset, data.valid_ds, test_dataset.dataset, num_workers = 0)","c52807d4":"data.show_batch(rows=3, figsize=(5,5))","e6151710":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","e47c2af2":"learn = create_cnn(data, models.resnet34, metrics=[accuracy])","04ebc70b":"learn.fit_one_cycle(4, max_lr = 1e-2)","86056e60":"learn.freeze_to(-2)","73f71694":"learn.lr_find()\nlearn.recorder.plot()","9e1089e0":"learn.fit_one_cycle(2, max_lr=slice(1e-6,5e-4))","85f4b073":"learn.unfreeze()","a3cf3dbc":"learn.lr_find()\nlearn.recorder.plot()","ae7b568e":"learn.fit_one_cycle(5, max_lr=slice(1e-6,5e-5))","f92147db":"learn.recorder.plot_losses()","c86f280a":"learn.recorder.plot_metrics()","36526a40":"preds,y,losses = learn.get_preds(with_loss=True)\ninterp = ClassificationInterpretation(learn, preds, y, losses)\ninterp.plot_top_losses(9, figsize=(10,10))\n","68757ad2":"interp.plot_confusion_matrix(figsize=(10,10))\n","5dbf0bae":"preds_test,y_test, losses_test= learn.get_preds(ds_type=data.test_ds, with_loss=True)","865682e0":"print(\"Accuracy on test set: \", accuracy(preds_test,y_test).item())","76709616":"### load data and create test set","0ee44813":"## Fix to load Truncated images"}}