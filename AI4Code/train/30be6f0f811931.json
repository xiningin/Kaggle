{"cell_type":{"be563e97":"code","da86a251":"code","82c20287":"code","faa33156":"code","745dd539":"code","004219c0":"code","bd7c4af2":"code","c6a1362e":"code","d78ee6fb":"code","79e3986b":"markdown"},"source":{"be563e97":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da86a251":"from collections import Counter","82c20287":"def read_docu(file):\n    \n    all_words = []\n    \n    with open(file, \"r\", encoding = \"utf-8\") as input_file:\n        for line in input_file:\n            line = line.lower()\n            line = line.strip().split()\n            all_words += line\n        return(all_words)","faa33156":"def word_counter(all_words):\n    \n    word_count = Counter()\n    for word in all_words:\n        word_count[word] += 1\n    return(word_count.values())","745dd539":"def draw_zipfian_curve(word_count):\n    plt.plot(sorted(word_count, reverse = True), marker = \"o\")\n    plt.xscale(\"log\")\n    plt.yscale(\"log\")\n    plt.xlabel(\"log(Rank)\")\n    plt.ylabel(\"log(Frequency)\")\n    plt.show()","004219c0":"def zipfian_plot(file):\n    word_corpus = read_docu(file)\n    counts = word_counter(word_corpus)\n    draw_zipfian_curve(counts)","bd7c4af2":"zipfian_plot(\"..\/input\/prosody-annotated-recited-finnish-poetry\/text\/44.txt\")","c6a1362e":"df= pd.read_csv('..\/input\/prosody-annotated-recited-finnish-poetry\/text\/44.txt', sep='\\t', error_bad_lines=False)\ndf.head()","d78ee6fb":"#Code By Paul Mooney\n\nprosody_file = '..\/input\/prosody-annotated-recited-finnish-poetry\/text\/3.txt'\nwith open(prosody_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(3000))","79e3986b":"#Codes by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook"}}