{"cell_type":{"520bf837":"code","02e4ebfd":"code","60c7e13e":"code","d82fedf0":"code","21a4fce1":"code","baa26dc7":"code","633f1a14":"code","a4260bec":"code","75c01c54":"code","6fd1a2c3":"code","0e1c80db":"code","3fefbfc6":"code","5c2a9975":"code","857a51ca":"code","733e74d6":"code","b837b378":"code","bf67619e":"markdown","aa040b7c":"markdown","8d958e5e":"markdown","f12cf0d1":"markdown","c2a86994":"markdown","5fc6eb98":"markdown","a85181d8":"markdown","d294062a":"markdown","8aab7fd3":"markdown","583b152f":"markdown","ee704d57":"markdown","03c8dee4":"markdown","1e20a722":"markdown","7badc772":"markdown","641c65a5":"markdown","cd953b4d":"markdown"},"source":{"520bf837":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir('..\/input'))\nprint(os.listdir(\"..\/input\/writefeaturetablefromsmotedartset\"))\nprint(os.listdir('..\/input\/normalizesomethingdifferentfeatures'))\n# Any results you write to the current directory are saved as output.","02e4ebfd":"\"\"\"\n\nThis script is forked from chia-ta tsai's kernel of which he said:\n\nThis script is forked from iprapas's notebook \nhttps:\/\/www.kaggle.com\/iprapas\/ideas-from-kernels-and-discussion-lb-1-135\n\n#    https:\/\/www.kaggle.com\/ogrellier\/plasticc-in-a-kernel-meta-and-data\n#    https:\/\/www.kaggle.com\/c\/PLAsTiCC-2018\/discussion\/70908\n#    https:\/\/www.kaggle.com\/meaninglesslives\/simple-neural-net-for-time-series-classification\n#\n\"\"\"\n\nimport sys, os\nimport argparse\nimport time\nfrom datetime import datetime as dt\nimport gc; gc.enable()\nfrom functools import partial, wraps\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nnp.warnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom tsfresh.feature_extraction import extract_features\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","60c7e13e":"\ndef multi_weighted_logloss(y_true, y_preds, classes, class_weights):\n    \"\"\"\n    refactor from\n    @author olivier https:\/\/www.kaggle.com\/ogrellier\n    multi logloss for PLAsTiCC challenge\n    \"\"\"\n    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n    # Trasform y_true in dummies\n    y_ohe = pd.get_dummies(y_true)\n    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n    # Transform to log\n    y_p_log = np.log(y_p)\n    # Get the log for ones, .values is used to drop the index of DataFrames\n    # Exclude class 99 for now, since there is no class99 in the training set\n    # we gave a special process for that class\n    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n    # Get the number of positives for each class\n    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n    # Weight average and divide by the number of positives\n    class_arr = np.array([class_weights[k] for k in sorted(class_weights.keys())])\n    y_w = y_log_ones * class_arr \/ nb_pos\n\n    loss = - np.sum(y_w) \/ np.sum(class_arr)\n    return loss","d82fedf0":"def lgbm_multi_weighted_logloss(y_true, y_preds):\n    \"\"\"\n    refactor from\n    @author olivier https:\/\/www.kaggle.com\/ogrellier\n    multi logloss for PLAsTiCC challenge\n    \"\"\"  \n    # Taken from Giba's topic : https:\/\/www.kaggle.com\/titericz\n    # https:\/\/www.kaggle.com\/c\/PLAsTiCC-2018\/discussion\/67194\n    # with Kyle Boone's post https:\/\/www.kaggle.com\/kyleboone\n    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n    class_weights = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n\n    loss = multi_weighted_logloss(y_true, y_preds, classes, class_weights)\n    return 'wloss', loss, False\n\n\ndef xgb_multi_weighted_logloss(y_predicted, y_true, classes, class_weights):\n    loss = multi_weighted_logloss(y_true.get_label(), y_predicted, \n                                  classes, class_weights)\n    return 'wloss', loss","21a4fce1":"\ndef save_importances(importances_):\n    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n    return importances_","baa26dc7":"\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nimport numpy as np # linear algebra\nimport pandas as pd\n\n#modify to work with kfold\n#def smoteAdataset(Xig, yig, test_size=0.2, random_state=0):\ndef smoteAdataset(Xig_train, yig_train, Xig_test, yig_test):\n    \n        \n    sm=SMOTE(random_state=2)\n    Xig_train_res, yig_train_res = sm.fit_sample(Xig_train, yig_train.ravel())\n\n        \n    return Xig_train_res, pd.Series(yig_train_res), Xig_test, pd.Series(yig_test)","633f1a14":"\ndef lgbm_modeling_cross_validation(params,\n                                   full_train, \n                                   y, \n                                   classes, \n                                   class_weights, \n                                   nr_fold=12, \n                                   random_state=1):\n\n    # Compute weights\n    w = y.value_counts()\n    weights = {i : np.sum(w) \/ w[i] for i in w.index}\n   # print(weights)\n   # weights=class_weights\n    clfs = []\n    importances = pd.DataFrame()\n    folds = StratifiedKFold(n_splits=nr_fold, \n                            shuffle=True, \n                            random_state=random_state)\n    \n    oof_preds = np.zeros((len(full_train), np.unique(y).shape[0]))\n    for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n        trn_x, trn_y = full_train.iloc[trn_], y.iloc[trn_]\n        val_x, val_y = full_train.iloc[val_], y.iloc[val_]\n        \n                \n        trn_xa, trn_y, val_xa, val_y=smoteAdataset(trn_x.values, trn_y.values, val_x.values, val_y.values)\n        trn_x=pd.DataFrame(data=trn_xa, columns=trn_x.columns)\n    \n        val_x=pd.DataFrame(data=val_xa, columns=val_x.columns)\n        \n        clf = LGBMClassifier(**params)\n        clf.fit(\n            trn_x, trn_y,\n            eval_set=[(trn_x, trn_y), (val_x, val_y)],\n            eval_metric=lgbm_multi_weighted_logloss,\n            verbose=100,\n            early_stopping_rounds=50,\n            sample_weight=trn_y.map(weights)\n        )\n        clfs.append(clf)\n\n        oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n        print('no {}-fold loss: {}'.format(fold_ + 1, \n              multi_weighted_logloss(val_y, oof_preds[val_, :], \n                                     classes, class_weights)))\n    \n        imp_df = pd.DataFrame({\n                'feature': full_train.columns,\n                'gain': clf.feature_importances_,\n                'fold': [fold_ + 1] * len(full_train.columns),\n                })\n        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n\n    score = multi_weighted_logloss(y_true=y, y_preds=oof_preds, \n                                   classes=classes, class_weights=class_weights)\n    print('MULTI WEIGHTED LOG LOSS: {:.5f}'.format(score))\n    df_importances = save_importances(importances_=importances)\n    df_importances.to_csv('lgbm_importances.csv', index=False)\n    \n    return clfs, score","a4260bec":"\ndef predict_chunk(df_, clfs_, features, train_mean):\n    # Group by object id    \n    agg_ = df_\n    # Merge with meta data\n    full_test = agg_.reset_index()\n    #print(full_test.head())\n\n    full_test = full_test.fillna(0)\n    full_test = full_test.round(5)\n    # Make predictions\n    preds_ = None\n    for clf in clfs_:\n        if preds_ is None:\n            preds_ = clf.predict_proba(full_test[features]) \/ len(clfs_)\n        else:\n            preds_ += clf.predict_proba(full_test[features]) \/ len(clfs_)\n            \n    #going to recalc 99 below anyways\n    # Compute preds_99 as the proba of class not being any of the others\n    # preds_99 = 0.1 gives 1.769\n    preds_99 = np.ones(preds_.shape[0])\n    \n    \n    for i in range(preds_.shape[1]):\n        preds_99 *= (1 - preds_[:, i])\n\n    # Create DataFrame from predictions\n    preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in clfs_[0].classes_])\n    preds_df_['object_id'] = full_test['object_id']\n    preds_df_['class_99'] = 0.14 * preds_99 \/ np.mean(preds_99) \n\n    return preds_df_","75c01c54":"def process_test(clfs, \n                 testdf,\n                 full_train,\n                 train_mean,\n                 filename='submission.csv',\n                 chunks=40615):\n\n    import time\n\n    start = time.time()\n    chunks = 40615\n    testdf=testdf.round(5)\n    \n    testdf.to_csv(filename, index=False)\n    for i_c, df in enumerate(pd.read_csv(filename, chunksize=chunks, iterator=True)):\n\n        print(df.shape)\n        preds_df = predict_chunk(df_=df,\n                                 clfs_=clfs,\n                                 features=full_train.columns,\n                                 train_mean=train_mean)\n\n        if i_c == 0:\n            preds_df.to_csv('predictions.csv', header=True, mode='a', index=False)\n        else:\n            preds_df.to_csv('predictions.csv', header=False, mode='a', index=False)\n\n        del preds_df\n        gc.collect()\n\n        print('%15d done in %5.1f minutes' % (chunks * (i_c + 1), (time.time() - start) \/ 60), flush=True)\n\n    return","6fd1a2c3":"best_params = {\n            'device': 'cpu', \n            'objective': 'multiclass', \n            'num_class': 14, \n            'boosting_type': 'gbdt', \n            'n_jobs': -1, \n            'max_depth': 6, \n            'n_estimators': 1000, \n            'subsample_freq': 2, \n            'subsample_for_bin': 5000, \n            'min_data_per_group': 100, \n            'max_cat_to_onehot': 4, \n            'cat_l2': 1.0, \n            'cat_smooth': 59.5, \n            'max_cat_threshold': 32, \n            'metric_freq': 10, \n            'verbosity': -1, \n            'metric': 'multi_logloss', \n            'xgboost_dart_mode': False, \n            'uniform_drop': False, \n            'colsample_bytree': 0.5, \n            'drop_rate': 0.173, \n            'learning_rate': 0.025, \n            'max_drop': 5, \n            'min_child_samples': 10, \n            'min_child_weight': 200.0, \n            'min_split_gain': 0.01, \n            'num_leaves': 7, \n            'reg_alpha': 0.1, \n            'reg_lambda': 0.00023, \n            'skip_drop': 0.44, \n            'subsample': 0.75}\n","0e1c80db":"#Here is a change from the script\n#training features\ntrainingDartDf=pd.read_csv('..\/input\/writefeaturetablefromsmotedartset\/trainingFeatures1039.csv')\ntrainingJimsDf=pd.read_csv('..\/input\/normalizesomethingdifferentfeatures\/traindfNormal.csv')\nif 'Unnamed: 0' in trainingDartDf.columns:\n    trainingDartDf=trainingDartDf.drop('Unnamed: 0', axis=1)\nprint(trainingDartDf.shape)\n#trainingDartDf.head()\ncolumnsToAdd=['outlierScore', 'hipd', 'lipd', 'highEnergy_transitory_1.0_TF',\n          'highEnergy_transitory_1.5_TF', 'lowEnergy_transitory_1.0_TF', \n          'lowEnergy_transitory_1.5_TF']\n\nfor column in columnsToAdd:\n    trainingDartDf.loc[:,column]=trainingJimsDf.loc[:,column]\n\ntraindf=trainingDartDf\n\n#from the 1.052 kernel\ndel traindf['hostgal_specz']\ndel traindf['ra'], traindf['decl'], traindf['gal_l'], traindf['gal_b']\ndel traindf['ddf']\n\n\nprint(traindf.shape)\ntraindf.head()","3fefbfc6":"    #test features\n    testDartDf=pd.read_csv('..\/input\/writefeaturetablefromsmotedartset\/feat_0.648970_2018-11-23-09-00.csv')\n    testJimsDf=pd.read_csv('..\/input\/normalizesomethingdifferentfeatures\/testdfNormal.csv')\n\n    if 'Unnamed: 0' in testDartDf.columns:\n        testDartDf=testDartDf.drop('Unnamed: 0', axis=1)\n    print(testDartDf.shape)\n    testDartDf.head()\n\n    for column in columnsToAdd:\n        testDartDf.loc[:,column]=testJimsDf.loc[:,column]\n\n    testdf=testDartDf\n\n    #from the 1.052 kernel\n    del testdf['hostgal_specz']\n    del testdf['ra'], testdf['decl'], testdf['gal_l'], testdf['gal_b']\n    del testdf['ddf']\n\n    testdf.shape","5c2a9975":"full_train=traindf\nif 'target' in full_train:\n    y = full_train['target']\n    del full_train['target']\n\nclasses = sorted(y.unique())    \n# Taken from Giba's topic : https:\/\/www.kaggle.com\/titericz\n# https:\/\/www.kaggle.com\/c\/PLAsTiCC-2018\/discussion\/67194\n# with Kyle Boone's post https:\/\/www.kaggle.com\/kyleboone\nclass_weights = {c: 1 for c in classes}\nclass_weights.update({c:2 for c in [64, 15]})\nprint('Unique classes : {}, {}'.format(len(classes), classes))\nprint(class_weights)\n","857a51ca":"\nif 'object_id' in full_train:\n    oof_df = full_train[['object_id']]\n    del full_train['object_id'] \n    #del full_train['distmod'] \n\ntrain_mean = full_train.mean(axis=0)\n#train_mean.to_hdf('train_data.hdf5', 'data')\npd.set_option('display.max_rows', 500)\n#print(full_train.describe().T)\n#import pdb; pdb.set_trace()\nfull_train.fillna(0, inplace=True)\nprint(full_train.shape)\nfull_train.head()\n","733e74d6":"for cindex in full_train.columns:\n    full_train.loc[:,cindex]=np.float64(full_train.loc[:,cindex])\n\neval_func = partial(lgbm_modeling_cross_validation, \n                        full_train=full_train, \n                        y=y, \n                        classes=classes, \n                        class_weights=class_weights, \n                        nr_fold=12, \n                        random_state=1)\n\nbest_params.update({'n_estimators': 1000})\n    \n    # modeling from CV\nclfs, score = eval_func(best_params)","b837b378":"\nfilename = 'subm_{:.6f}_{}.csv'.format(score, \n                 dt.now().strftime('%Y-%m-%d-%H-%M'))\nprint('save to {}'.format(filename))\n# TEST\n\n\nprocess_test(clfs, \n             testdf,\n             full_train,\n             train_mean=train_mean, \n             filename=filename,\n             chunks=40615)\n\n\npdf = pd.read_csv('predictions.csv')\npdf.to_csv(filename, index=False)","bf67619e":"## Load and merge the training data\n- trainingDartDf is from Chai-Ta Tsai's kernel\n- trainingJimsDf is from my somethingDifferent kernel\n","aa040b7c":"## Kernels and discussions used in this kernel\n- [Olivier's kernel](https:\/\/www.kaggle.com\/ogrellier\/plasticc-in-a-kernel-meta-and-data)\n- [Alexander Firsov's kernel](https:\/\/www.kaggle.com\/alexfir\/fast-test-set-reading)\n- [Iprapas' kernel](https:\/\/www.kaggle.com\/iprapas\/ideas-from-kernels-and-discussion-lb-1-135)\n- [Chia-Ta Tsai's kernel](https:\/\/www.kaggle.com\/cttsai\/forked-lgbm-w-ideas-from-kernels-and-discuss)\n- [Lving's kernel](https:\/\/www.kaggle.com\/qianchao\/smote-with-imbalance-data)\n- [My something different kernel](https:\/\/www.kaggle.com\/jimpsull\/something-different)\n- [My Smote the training set kernel](https:\/\/www.kaggle.com\/jimpsull\/smote-the-training-sets)","8d958e5e":"## Prep training data for Olivier & company's cross validation methods","f12cf0d1":"## Surprisingly making changes to these parameters didn't have a big impact on score\n- I thought adding Smote since they optimized would leave room for re-optimization\n- But couldn't get scores to come up ","c2a86994":"## This method is our biggest contribution to our current score\n- This smote method improved iprapas kernel from 1.135 --> 1.110 and Chia-Ta Tsai's from 1.080 --> 1.052\n- The biggest challeng in integrating it was the data structures (pandas DataFrames vs Numpy arrays, mixed usage of data structures)","5fc6eb98":"## Function to save feature importances (not sure who authored it)","a85181d8":"## The purpose of this kernel is to bring together features\n- the first 69 are from our 1.080 kernel which came via Oliver, Iprapas, and Chia-ta Tsai\n- integrating smote brought that to 1.052\n- Adding my custom features improved 0.015\n- ongoing efforts and tried and failed lists at the end of the kernel\n","d294062a":"## This is Olivier and Iprapas method but we integrated our Smote method into it","8aab7fd3":"## Olivier's functions","583b152f":"## Remove the end effect with good chunksize choice\n- testdf.shape[0]%40615=0 so there's no special 'end case'","ee704d57":"## Load the test data\n- be careful with memory\n- if you bring together features from multiple sources it is best to delete the dataframes once you have the features you need","03c8dee4":"## Continue prepping traindf for cross validation, save object_ids","1e20a722":"## The first two lines (or lack thereof) have caused me more headache than I can count\n- it has to do with numpy data types when native data types are expected","7badc772":"## These methods have several contributors\n- I'm not sure that they're still needed now that I've extracted the features from Chia-Ta Tsai's script\n- But when I tried to run the prediction on test all at once the kernel crashed\n- So I modified to read testdf in chunks and predict bit by bit","641c65a5":"## Chai-Ta Tsai's naming convention\n- stores the CV score and the timestamp in the filename","cd953b4d":"## From Chia-Ta Tsai's script"}}