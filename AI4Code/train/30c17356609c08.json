{"cell_type":{"1e3ce652":"code","1c93b43e":"code","b5593c29":"code","adaa1113":"code","37991701":"code","48b871c7":"code","1e5c03f9":"code","d6e14e06":"code","c0ec77fd":"code","dc18a722":"code","217e7f59":"code","0e2312b6":"code","8734ae61":"code","c9605ca5":"code","5cf57488":"code","71f29c28":"code","2a7c14cc":"code","0b59c073":"code","67022a78":"code","ffa37c68":"code","cd7cf8a9":"code","19c9249c":"code","b898d23e":"code","a2aa5afa":"code","becddf77":"code","81214acf":"code","cf275893":"code","7dddbd93":"code","c86a4769":"code","89aa7e76":"code","963395a4":"code","747e5a1d":"code","8d2693a1":"code","929eff73":"code","5754305b":"code","dada8baa":"code","ab736eeb":"code","2d4d289c":"code","65ee2468":"code","66c69249":"code","d73c73a7":"code","7eb8a0ff":"code","8a982185":"code","d40b0cdb":"code","95d751d3":"code","05f40104":"code","7e9ddea3":"code","bde55146":"code","3d59ae2e":"code","a52438bd":"code","e0e5d349":"code","ef3f4e5e":"markdown","21c4cf96":"markdown","9d65ee61":"markdown","abe8ebdb":"markdown","f62b728e":"markdown","4026c159":"markdown","d457e159":"markdown","9a33a758":"markdown","71dc5054":"markdown","fa7fb8da":"markdown","035791e4":"markdown","0d510b6a":"markdown","60492573":"markdown","aca4460e":"markdown","a4aceace":"markdown","0ddb56e4":"markdown","5839f832":"markdown","db7dc1ce":"markdown","5eae76ff":"markdown","43557912":"markdown","5f47518b":"markdown","787b1e0b":"markdown","7b2b33f4":"markdown","6534b4db":"markdown","c7b54c1f":"markdown","0e255fd2":"markdown","a495136f":"markdown","ab2b338a":"markdown","3f5c85d8":"markdown","3c024328":"markdown","e5a32bd7":"markdown","96c245c0":"markdown","57723f81":"markdown"},"source":{"1e3ce652":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom matplotlib.pyplot import rcParams\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score\n\nplt.style.use(\"ggplot\")\nrcParams[\"figure.figsize\"] = 8, 6\nwarnings.filterwarnings(\"ignore\")\n","1c93b43e":"train_data = pd.read_csv(\"\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv\")\nsample_subms = pd.read_csv(\"\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/sample_submission.csv\")","b5593c29":"train_data","adaa1113":"data_dict = {\n            \"enrollee_id\" : \"Unique ID for candidate\",\n            \"city\": \"City code\",\n            \"city_development_index\" : \"Developement index of the city (scaled)\",\n            \"gender\": \"Gender of candidate\",\n            \"relevent_experience\": \"Relevant experience of candidate\",\n            \"enrolled_university\": \"Type of University course enrolled if any\",\n            \"education_level\": \"Education level of candidate\",\n            \"major_discipline\": \"Education major discipline of candidate\",\n            \"experience\": \"Candidate total experience in years\",\n            \"company_size\": \"No of employees in current employer's company\",\n            \"company_type\" : \"Type of current employer\",\n            \"last_new_job\": \"Difference in years between previous job and current job\",\n            \"training_hours\": \"Training hours completed\",\n            \"target\": \"0 \u2013 Not looking for job change, 1 \u2013 Looking for a job change\"\n            }","37991701":"def custom_describe(data):\n    \n    index = list(data.columns)\n    columns = [\"Dtype\", \"No. Missings\", \"Pct. Missings(%)\", \"Most Frequent Val.\", \"Meaning\"]\n    dtypes = list(data.dtypes.values)\n    no_missings = np.array(data.isna().sum().values)\n    pct_missings = np.round((no_missings \/ len(data)) * 100, 2)\n    frequents = [data[col].mode()[0] for col in index]\n    meanings = [data_dict[col] for col in index]\n    describe = pd.DataFrame(index=index, columns=columns)\n    describe[\"Dtype\"] = dtypes\n    describe[\"No. Missings\"] = no_missings\n    describe[\"Pct. Missings(%)\"] = pct_missings\n    describe[\"Most Frequent Val.\"] = frequents\n    describe[\"Meaning\"] = meanings\n    \n    return describe\n\ndf = train_data.copy()\ncustom_describe(df)","48b871c7":"sns.heatmap(df.corr(), annot=True, cmap=\"mako\")\nplt.title(\"Correlation Between Features\");","1e5c03f9":"print(f\"Number of Unique Candidates at This Research : {df['enrollee_id'].nunique()}\")","d6e14e06":"drop_cols = [] # For redundant features\ndrop_cols.append(\"enrollee_id\")","c0ec77fd":"df[\"target\"] = df[\"target\"].astype(int)\ndf[\"target\"].value_counts()","dc18a722":"labels = [\"Not looking for a job\", \"Looking for a job\"]\nvalues = list(df[\"target\"].value_counts().values)\n\nplt.figure(figsize=(6,6))\nplt.pie(values, labels=labels, autopct=\"%1.1f%%\",\n        colors=[\"#81dce4\", \"#a5244c\"], \n        center=(6, 6), shadow=True,\n        explode = [0.02, 0.02], startangle=90)\nplt.title(\"Target Variable\");","217e7f59":"print(\"Importance of Target with City Codes\")\ndf.groupby(\"city\").agg([\"mean\", \"count\"])[\"target\"].sort_values(\"count\", ascending=False)","0e2312b6":"drop_cols.append(\"city\")","8734ae61":"male_pct = np.round((len(df.loc[df[\"gender\"] == \"Male\"]) \/ len(df)) * 100, 1)\nfemale_pct = np.round((len(df.loc[df[\"gender\"] == \"Female\"]) \/ len(df)) * 100, 1)\nother_pct = np.round((len(df.loc[df[\"gender\"] == \"Other\"]) \/ len(df)) * 100, 1)\nnan_pct = np.round((df[\"gender\"].isna().sum() \/ len(df)) * 100, 1)\nsns.countplot(df[\"gender\"], palette=\"YlOrBr\")\nplt.title(f\"Male pct = {male_pct}%\\nFemale pct = {female_pct}%\\nOther pct = {other_pct}%\\nNan pct = {nan_pct}%\")\nplt.legend();","c9605ca5":"gender_mapping = {\"Female\": 0, \"Male\": 1, \"Other\": 2}","5cf57488":"df[\"relevent_experience\"].value_counts()","71f29c28":"sns.countplot(df[\"relevent_experience\"], palette=\"nipy_spectral\")\nplt.title(\"Relevent Experience\")\nplt.xlabel(\"\");","2a7c14cc":"relevent_experience_mapping = {\"No relevent experience\": 0, \"Has relevent experience\": 1}","0b59c073":"df.groupby(\"enrolled_university\").agg([\"mean\", \"count\"])[\"target\"]","67022a78":"sns.countplot(x=\"enrolled_university\", hue=\"target\",\n              palette=\"rocket_r\", data=df)\nplt.title(\"Enrolled Universities with Target Perspective\");","ffa37c68":"enrollment_mapping = {\"no_enrollment\": 0, \"Part time course\": 1, \"Full time course\": 2}","cd7cf8a9":"df.groupby(\"education_level\").agg([\"mean\", \"count\"])[\"target\"]","19c9249c":"labels = list(df[\"education_level\"].value_counts().index)\nvalues = list(df[\"education_level\"].value_counts().values)\n\nplt.figure(figsize=(8,8))\nplt.pie(values, labels=labels, autopct=\"%1.1f%%\",\n        colors=[\"#7fcc00\", \"#ff3a33\", \"#f7ff66\", \"#3339ff\", \"#99ffa9\"],\n        shadow=True, explode = [0.03, 0.03, 0.03, 0.03, 0.03],\n        startangle=270)\nplt.title(\"Education Level\");","b898d23e":"education_mapping = {\"Phd\": 0, \"Masters\": 1, \"Graduate\": 2,\n                     \"High School\": 3, \"Primary School\": 4}","a2aa5afa":"df.groupby(\"major_discipline\").agg([\"mean\", \"count\"])[\"target\"]","becddf77":"def category_target(col_name,x, y):\n    \n    categories = list(df[\"major_discipline\"].value_counts().index)\n    palettes = [\"PuBu\", \"YlOrBr_r\", \"gist_stern\", \"bwr\", \"Wistia\", \"plasma\"]\n    n = len(categories)\n    plt.figure(figsize=(21, 14))\n    for i in range(n):\n        cat = categories[i]\n        plt.subplot(x, y, i + 1)\n        sns.countplot(df.loc[df[col_name] == cat, \"target\"], palette=palettes[i])\n        plt.xlabel(\"\")\n        plt.title(cat)\n        \n        \ncategory_target(\"major_discipline\", x=2, y=3)","81214acf":"discipline_mapping = {\"Business Degree\": 0, \"STEM\": 1,\n                      \"Humanities\": 2, \"Arts\": 3,\n                      \"Other\": 4, \"No Major\": 5}","cf275893":"df.groupby(\"experience\").agg([\"mean\", \"count\"])[\"target\"].sort_values(\"mean\")","7dddbd93":"experience_mapping = {\"<1\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5,\n                      \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9, \"10\": 10, \"11\": 11,\n                      \"12\": 12, \"13\": 13, \"14\": 14, \"15\": 15, \"16\": 16,\n                      \"17\": 17, \"18\": 18, \"19\": 19, \"20\": 20, \">20\": 21}","c86a4769":"df.groupby(\"company_size\").agg([\"mean\", \"count\"])[\"target\"]","89aa7e76":"company_size_mapping = {\"10000+\": 0,\n                        \"5000-9999\": 1,\n                        \"1000-4999\": 2,\n                        \"500-999\": 3,\n                        \"100-500\": 4,\n                        \"50-99\": 5,\n                        \"10\/49\": 6,\n                        \"<10\": 7}","963395a4":"df.groupby(\"company_type\").agg([\"mean\", \"count\"])[\"target\"].sort_values(\"mean\", ascending=False)","747e5a1d":"order = list(df[\"company_type\"].value_counts().index)\nsns.countplot(y=\"company_type\", data=df,\n              palette=\"twilight_shifted_r\", order=order)\nplt.title(\"Company Type\")\nplt.ylabel(\"\");","8d2693a1":"company_type_mapping = {\"Other\": 0,\n                        \"Early Stage Startup\": 1,\n                        \"Public Sector\": 2,\n                        \"NGO\": 3,\n                        \"Pvt Ltd\": 4,\n                        \"Funded Startup\": 5}","929eff73":"df.groupby(\"last_new_job\").agg([\"mean\", \"count\"])[\"target\"]","5754305b":"labels = list(df[\"last_new_job\"].value_counts().index)\nvalues = list(df[\"last_new_job\"].value_counts().values)\n\nplt.figure(figsize=(7, 7))\nplt.pie(values, labels=labels, autopct=\"%1.1f%%\",\n        colors=['#ff9999','#66b3ff','#99ff99','#ffcc99', '#ff66d1', '#8cff66'],\n        explode=[0.02, 0.02, 0.02, 0.02, 0.02, 0.02],\n        startangle=180)\nplt.title(\"Last New Job\");","dada8baa":"last_new_job_mapping = {\"never\": 0,\n                        \"1\": 1,\n                        \"2\": 2,\n                        \"3\": 3,\n                        \"4\": 4,\n                        \">4\": 5}","ab736eeb":"plt.figure(figsize=(8,6))\nsns.histplot(df[\"training_hours\"])\nplt.title(\"Training Hours\")\nplt.axvline(df[\"training_hours\"].mean(), c=\"r\", label=\"Mean\")\nplt.axvline(df[\"training_hours\"].median(), c=\"g\", label=\"Median\")\nplt.legend();","2d4d289c":"df.drop(drop_cols, axis=1, inplace=True)\n\n# gender Column\ndf[\"gender\"] = df[\"gender\"].map(gender_mapping)\ndf[\"gender\"].fillna(df[\"gender\"].mean(), inplace=True)\n\n# relevent_experience Column\ndf[\"relevent_experience\"] = df[\"relevent_experience\"].map(relevent_experience_mapping)\n\n# enrolled_university Column\ndf[\"enrolled_university\"] = df[\"enrolled_university\"].map(enrollment_mapping)\ndf[\"enrolled_university\"].fillna(df[\"enrolled_university\"].mean(), inplace=True)\n\n# education_level Column\ndf[\"education_level\"] = df[\"education_level\"].map(education_mapping)\ndf[\"education_level\"].fillna(df[\"education_level\"].mean(), inplace=True)\n\n# major_discipline Column\ndf[\"major_discipline\"] = df[\"major_discipline\"].map(discipline_mapping)\ndf[\"major_discipline\"].fillna(df[\"major_discipline\"].mean(), inplace=True)\n\n# experience Column\ndf[\"experience\"] = df[\"experience\"].map(experience_mapping)\ndf[\"experience\"].fillna(df[\"experience\"].mean(), inplace=True)\n\n# company_size Column\ndf[\"company_size\"] = df[\"company_size\"].map(company_size_mapping)\ndf[\"company_size\"].fillna(df[\"company_size\"].mean(), inplace=True)\n\n# company_type Column\ndf[\"company_type\"] = df[\"company_type\"].map(company_type_mapping)\ndf[\"company_type\"].fillna(df[\"company_type\"].mean(), inplace=True)\n\n# last_new_job Column\ndf[\"last_new_job\"] = df[\"last_new_job\"].map(last_new_job_mapping)\ndf[\"last_new_job\"].fillna(df[\"last_new_job\"].mean(), inplace=True)","65ee2468":"custom_describe(df)","66c69249":"df.corr().style.background_gradient(cmap=\"YlGnBu\")","d73c73a7":"from sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score","7eb8a0ff":"scaler = StandardScaler()\n\nX = df.drop(\"target\", axis=1)\ny = df[\"target\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nX_train_sc = scaler.fit_transform(X_train)\nX_test_sc = scaler.transform(X_test)","8a982185":"params = {\"max_depth\": list(range(2, 11)), # Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit\n          \"eta\": [0.01, 0.05, 0.1], # Learning Rate : Step size shrinkage used in update to prevents overfitting\n          \"n_estimators\": list(range(100,600, 100)), # Number of boosting rounds. If it increases model fit better, but fitting time also increases.\n          \"subsample\": [0.5, 0.7, 1], # Represents the fraction of observations to be sampled for each tree. A lower values prevent overfitting but might lead to under-fitting.\n         }\n\nxgb_clf = XGBClassifier(eval_metric=\"auc\")\ngrid_search = GridSearchCV(estimator = xgb_clf,\n                           param_grid = params,\n                           cv=5,\n                           return_train_score=True)\ngrid_search.fit(X_train_sc, y_train)","d40b0cdb":"grid_search.best_estimator_","95d751d3":"print(f\"Mean Train Score : {np.round(grid_search.cv_results_['mean_train_score'].mean(), 2)}\")\nprint(f\"Mean Validation Score : {np.round(grid_search.cv_results_['mean_test_score'].mean(), 2)}\")","05f40104":"model = XGBClassifier(n_estimators=200, \n                      eta=0.01,\n                      eval_metric=\"auc\",\n                      subsample=0.7,\n                      max_depth=6)\n\nmodel.fit(X_train_sc, y_train)\nunseen_test_set = model.predict(X_test_sc)","7e9ddea3":"print(\"\\t\\t\\tClassification Report:\\n\\n\",classification_report(y_test, unseen_test_set))","bde55146":"test_data","3d59ae2e":"def transform_data(data):\n    \n    # Dropping unnecessary colums\n    data.drop(drop_cols, axis=1, inplace=True)\n    \n    # gender Column\n    data[\"gender\"] = data[\"gender\"].map(gender_mapping)\n    data[\"gender\"].fillna(data[\"gender\"].mean(), inplace=True)\n\n    # relevent_experience Column\n    data[\"relevent_experience\"] = data[\"relevent_experience\"].map(relevent_experience_mapping)\n\n    # enrolled_university Column\n    data[\"enrolled_university\"] = data[\"enrolled_university\"].map(enrollment_mapping)\n    data[\"enrolled_university\"].fillna(data[\"enrolled_university\"].mean(), inplace=True)\n\n    # education_level Column\n    data[\"education_level\"] = data[\"education_level\"].map(education_mapping)\n    data[\"education_level\"].fillna(data[\"education_level\"].mean(), inplace=True)\n\n    # major_discipline Column\n    data[\"major_discipline\"] = data[\"major_discipline\"].map(discipline_mapping)\n    data[\"major_discipline\"].fillna(data[\"major_discipline\"].mean(), inplace=True)\n\n    # experience Column\n    data[\"experience\"] = data[\"experience\"].map(experience_mapping)\n    data[\"experience\"].fillna(data[\"experience\"].mean(), inplace=True)\n\n    # company_size Column\n    data[\"company_size\"] = data[\"company_size\"].map(company_size_mapping)\n    data[\"company_size\"].fillna(data[\"company_size\"].mean(), inplace=True)\n    \n    # company_type Column\n    data[\"company_type\"] = data[\"company_type\"].map(company_type_mapping)\n    data[\"company_type\"].fillna(data[\"company_type\"].mean(), inplace=True)\n\n    # last_new_job Column\n    data[\"last_new_job\"] = data[\"last_new_job\"].map(last_new_job_mapping)\n    data[\"last_new_job\"].fillna(data[\"last_new_job\"].mean(), inplace=True)\n    \n    return data\n\ntransform_data(test_data)","a52438bd":"prediction_data = test_data.values\npredictions_data = scaler.transform(prediction_data)\n\npredictions = model.predict(prediction_data)\npredictions","e0e5d349":"sample_subms[\"target\"] = predictions\nsample_subms","ef3f4e5e":"XGBoost, which stands for Extreme Gradient Boosting, is a scalable, distributed gradient-boosted decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.\n\nIt\u2019s vital to an understanding of XGBoost to first grasp the machine learning concepts and algorithms that XGBoost builds upon: supervised machine learning, decision trees, ensemble learning, and gradient boosting.\n\nSupervised machine learning uses algorithms to train a model to find patterns in a dataset with labels and features and then uses the trained model to predict the labels on a new dataset\u2019s features.","21c4cf96":"<a id=\"section-4\"><\/a>\n## Exploratory Data Analysis(EDA)","9d65ee61":"# HR Analytics - Job Change of Data Scientists","abe8ebdb":"<a id=\"subsection-15\"><\/a>\n### last_new_job Column","f62b728e":"* [Introduction](#section-1)\n* [Understanding the Data](#section-2)\n    - [Brief Description of Columns](#subsection-3)\n* [Exploratory Data Analysis](#section-4)\n    - [target Column](#subsection-5)\n    - [city & city_develpoment_index Columns](#subsection-6)\n    - [gender Column](#subsection-7)\n    - [relevent_experience Column](#subsection-8)\n    - [enrolled_university Column](#subsection-9)\n    - [education_level Column](#subsection-10)\n    - [major_discipline Column](#subsection-11)\n    - [experience Column](#subsection-12)\n    - [company_size Column](#subsection-13)\n    - [company_type Column](#subsection-14)\n    - [last_new_job Column](#subsection-15)\n    - [training_hours Column](#subsection-16)\n* [Encoding & Dealing with Missing Values](#section-17)\n* [Data Preprocessing Part(Getting Ready for ML)](#section-18)\n* [XGBoost Classifier](#section-19)\n    - [Model Fitting & Optimization](#subsection-20)\n    - [Choosing the Right Parameters](#subsection-21)\n    - [Making Prediction](#subsection-22)\n* [Final](#section-23)","4026c159":"<a id=\"section-1\"><\/a>\n## Introduction","d457e159":"<a id=\"section-18\"><\/a>\n## Data Preprocessing Part(Getting Ready for ML)","9a33a758":"<a id=\"subsection-9\"><\/a>\n### enrolled_university Column","71dc5054":"A company which is active in Big Data and Data Science wants to hire data scientists among people who successfully pass some courses which conduct by the company. Many people signup for their training. Company wants to know which of these candidates are really wants to work for the company after training or looking for a new employment because it helps to reduce the cost and time as well as the quality of training or planning the courses and categorization of candidates. Information related to demographics, education, experience are in hands from candidates signup and enrollment.\n\nThis dataset designed to understand the factors that lead a person to leave current job for HR researches too. By model(s) that uses the current credentials,demographics,experience data you will predict the probability of a candidate to look for a new job or will work for the company, as well as interpreting affected factors on employee decision.\n\nThe whole data divided to train and test . Target isn't included in test but the test target values data file is in hands for related tasks. A sample submission correspond to enrollee_id of test set provided too with columns : enrollee _id , target","fa7fb8da":"<a id=\"subsection-3\"><\/a>\n#### Brief Description of Columns","035791e4":"<a id=\"subsection-14\"><\/a>\n### company_type Column","0d510b6a":"Our target seems unbalanced. At the measuring performance stage we won't just look at accuracy score.","60492573":"<a id=\"subsection-20\"><\/a>\n### Model Fitting & Optimization","aca4460e":"<a id=\"subsection-12\"><\/a>\n### experience Column","a4aceace":"##### Important Notes: \n* The dataset is imbalanced.\n* Most features are categorical (Nominal, Ordinal, Binary), some with high cardinality.\n* Missing imputation can be a part of your pipeline as well.","0ddb56e4":"<a id=\"subsection-16\"><\/a>\n### training_hours Column","5839f832":"<a id=\"subsection-22\"><\/a>\n### Making Prediction","db7dc1ce":"<a id=\"section-17\"><\/a>\n## Encoding & Dealing with Missing Values","5eae76ff":"<a id=\"subsection-21\"><\/a>\n### Choosing the Right Parameters","43557912":"<a id=\"subsection-13\"><\/a>\n### company_size Column","5f47518b":"<a id=\"subsection-7\"><\/a>\n### gender Column","787b1e0b":"#### Transforming Test Data for Prediction","7b2b33f4":"![data_scientist_guy.jpeg](attachment:2a17c8d0-cb4a-44e4-bd00-f9b6b714fe49.jpeg)","6534b4db":"Instead of 'city' column we will use 'city_development_index' column. Because of they have same meaning and 'city_development_index' column has a numerical value we will drop 'city' column.","c7b54c1f":"<a id=\"section-23\"><\/a>\n## Final","0e255fd2":"<a id=\"subsection-8\"><\/a>\n### relevent_experience Column","a495136f":"<a id=\"section-19\"><\/a>\n## XGBoost Classifier","ab2b338a":"<a id=\"subsection-11\"><\/a>\n### major_discipline Column","3f5c85d8":"<a id=\"subsection-5\"><\/a>\n### target Column ","3c024328":"<a id=\"subsection-6\"><\/a>\n### city & city_development_index Columns ","e5a32bd7":"<a id=\"section-2\"><\/a>\n## Understanding the Data ","96c245c0":"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data and apply knowledge and actionable insights from data across a broad range of application domains. Data science is related to data mining, machine learning and big data.","57723f81":"<a id=\"subsection-10\"><\/a>\n### education_level Column"}}