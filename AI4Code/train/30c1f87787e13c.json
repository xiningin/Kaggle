{"cell_type":{"5e76af7a":"code","9cc1e96f":"code","19881fd3":"code","d7de9685":"code","e597589c":"code","73c027e5":"code","ba7d6117":"code","e9a5bb1c":"code","bc59298f":"code","d5543eaf":"code","3de4b50f":"code","c5bf68c2":"code","d19d0dde":"code","03bcbbc7":"code","7e5edf21":"code","e1ef332c":"code","3171c64c":"code","0a9d90f2":"code","118a7c0c":"code","a90e7a32":"code","59b622a3":"code","8ac69061":"code","08404340":"code","aed9a3c8":"code","e9e42148":"code","6f897033":"code","6f70ea80":"code","04d7aa89":"code","d0dfb054":"code","23c623a3":"code","92ef966c":"code","13ee79f3":"code","658c6315":"code","553eff5a":"code","67763137":"code","ad83f2b4":"code","f84d953a":"code","c265bac7":"code","8d579e4d":"code","44aefb89":"code","e3363576":"code","07909fa7":"code","6ee808dc":"code","c01c4cc7":"code","d5dfc80a":"code","4fa00e2e":"code","12af20b5":"code","7a13f5cf":"code","9cc8df8c":"code","2bd30a3d":"code","64cfe98a":"code","d2eab2d4":"code","402ca5a7":"code","0c6f6ce2":"code","c7a0eaa5":"code","5d5de491":"code","26a3b9c6":"code","6562dd3c":"code","5f5b7fd1":"code","88d8fb88":"code","903687b4":"code","51b02068":"code","cc67dd8a":"code","d1c6a27b":"code","058e4e30":"code","564c0527":"code","a860c76d":"code","645cb84c":"code","1722a07d":"code","6473a5da":"code","33b6e79b":"markdown","dd48fae5":"markdown","2e72fae8":"markdown","6dc082b6":"markdown","60d693be":"markdown","2364eb97":"markdown","b51e3272":"markdown","3baa7e2b":"markdown","90962820":"markdown","e2875925":"markdown","8ba7fcac":"markdown","344f285d":"markdown","2abfa95d":"markdown","83bfc3ae":"markdown","001b9af3":"markdown","d42435cc":"markdown","91936a17":"markdown","3d49f62f":"markdown","16f8a612":"markdown","25fcef9c":"markdown","850c2b20":"markdown","67196a7b":"markdown","f99649ab":"markdown","7d610550":"markdown","272795fd":"markdown","b8419bb5":"markdown","1068c4f5":"markdown","268d646b":"markdown","fb71ec2a":"markdown","fa3a94df":"markdown","77b5e04d":"markdown","c425eb68":"markdown","a48e5ced":"markdown","8af8389a":"markdown","f43a51d9":"markdown","a3d67780":"markdown","f69fabf3":"markdown","6007874b":"markdown","2239c6ed":"markdown","4d8810f1":"markdown","2560eba6":"markdown","d845dbc6":"markdown","f55a9156":"markdown","9cdd64df":"markdown","b09a4bcc":"markdown"},"source":{"5e76af7a":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9cc1e96f":"df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","19881fd3":"df.head()","d7de9685":"df.info()","e597589c":"# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u043a\u043b\u044e\u0447\u0435\u0432\u044b\u0445 \u0441\u043b\u043e\u0432\ndf.loc[:,'keyword'].nunique()","73c027e5":"# \u0447\u0430\u0441\u0442\u043e\u0442\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f keywords\ndf.loc[:,'keyword'].value_counts()","ba7d6117":"# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u043b\u043e\u043a\u0430\u0446\u0438\u0439\ndf.loc[:,'location'].nunique()","e9a5bb1c":"# \u0447\u0430\u0441\u0442\u043e\u0442\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 location\ndf.loc[:,'location'].value_counts()","bc59298f":"# \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nprint(df.groupby('target')['target'].count())\n\n# \u043f\u0440\u043e\u0446\u0435\u043d\u0442 target=1\ntarget_count = df[df['target'] == 1]['target'].count()\ntotal = df['target'].count()\ntarget_share = target_count\/total\nprint(\"\u0414\u043e\u043b\u044f \u0434\u0430\u043d\u043d\u044b\u0445, \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0449\u0438\u0445 \u0440\u0435\u0430\u043b\u043d\u044b\u0435 \u043f\u0440\u043e\u0438\u0441\u0448\u0435\u0441\u0442\u0432\u0438\u044f \\\"target=1\\\" {0:.2f}\".format(target_share))\n\n# \u0433\u0438\u0441\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u0430\ndf[df['target'] == 0]['target'].astype(int).hist(label='\u0424\u0435\u0439\u043a', grid = False, bins=1, rwidth=0.8)\ndf[df['target'] == 1]['target'].astype(int).hist(label='\u0420\u0435\u0430\u043b\u044c\u043d\u044b\u0435', grid = False, bins=1, rwidth=0.8)\nplt.xticks((0,1),('\u0424\u0435\u0439\u043a', '\u0420\u0435\u0430\u043b\u044c\u043d\u044b\u0435'))\nplt.show()","d5543eaf":"# \u0442.\u043a. \u0432 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0435 location \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0434\u043b\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u043a\u0430\u0440\u0442\u044b, \u0442\u043e \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043d\u043e\u0432\u0443\u044e \u0431\u0430\u0437\u0443 world-cities-database\n# \u0432 \u044d\u0442\u043e\u0439 \u0431\u0430\u0437\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u0430\u043d\u0435 \u0438\u043b\u0438 \u0433\u043e\u0440\u043e\u0434\u0443 \u043f\u0440\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u044b \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b latitude \/ longitude\n\nlatlong = pd.read_csv(\"\/kaggle\/input\/world-cities-database\/worldcitiespop.csv\")\nlatlong.head()","3de4b50f":"# \u043f\u0435\u0440\u0435\u043c\u0438\u043c\u0435\u043d\u0443\u0435\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0443 AccentCity \u0432 Location \u0434\u043b\u044f \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044f \u0441 \u043d\u0430\u0448\u0435\u0439 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0439 \u0431\u0430\u0437\u043e\u0439\nlatlong.rename(columns={\"AccentCity\": \"location\"}, inplace=True)\nlatlong.head()","c5bf68c2":"# \u041f\u043e\u043b\u0443\u0447\u0438\u043c \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u044f location \u0438 latitude \/ longitude \u0434\u043b\u044f \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0432 \u0438\u0441\u0445\u043e\u0434\u043d\u0443\u044e \u0431\u0430\u0437\u0443, \u0443\u0434\u0430\u043b\u0438\u043c \u0434\u0443\u0431\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u0440\u043e\u043a\u0438 \u0438 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 location\nlatlong_grouped = latlong[['location', 'Latitude', 'Longitude', 'Population']].drop_duplicates()\nlatlong_grouped = latlong_grouped[latlong_grouped.location != 'None']","d19d0dde":"# \u043e\u0442\u0441\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u0431\u0430\u0437\u0443 \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u043f\u043e \u0430\u043b\u0444\u0430\u0432\u0438\u0442\u0443 \u043f\u043e location (\u043f\u043e \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430\u043d\u0438\u044e) \u0438 \u0437\u0430\u0442\u0435\u043c \u043f\u043e population (\u043f\u043e \u0443\u0431\u044b\u0432\u0430\u043d\u0438\u044e)\nlatlong_grouped.sort_values(['location', 'Population'], ascending=[True, False], inplace=True)","03bcbbc7":"latlong_grouped.shape","7e5edf21":"# \u0443\u0434\u0430\u043b\u0438\u043c \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u044e\u0449\u0438\u0435\u0441\u044f \u0433\u043e\u0440\u043e\u0434\u0430 \u0438\u0437 \u0431\u0430\u0437\u044b, \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 \u0433\u043e\u0440\u043e\u0434\u0430 \u0438\u0437 \u0434\u0443\u0431\u043b\u0435\u0439, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043d\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n# \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0441\u0440\u0430\u0432\u043d\u0438\u043c \u0442\u0435\u043a\u0443\u0449\u0443\u044e \u0441\u0442\u0440\u043e\u043a\u0443 \u0438 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0443\u044e (shift \u0441\u043c\u0435\u0449\u0430\u0435\u0442 \u043d\u0430 \u043e\u0434\u043d\u0443 \u0441\u0442\u0440\u043e\u043a\u0443 \u0432\u043f\u0435\u0440\u0451\u0434), \u0435\u0441\u043b\u0438 \u043e\u043d\u0438 \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u044e\u0442\u0441\u044f, \u0442\u043e \u043c\u044b \u0438\u0445 \u043d\u0435 \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u043c \u0432 \u0431\u0430\u0437\u0443\nlatlong_cleaned = latlong_grouped[latlong_grouped['location'] != latlong_grouped['location'].shift()]\n# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c \u0431\u0430\u0437\u044b\nlatlong_cleaned.shape","e1ef332c":"# \u0434\u043b\u044f \u0431\u0430\u0437\u044b \u0441\u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0434\u0443\u0431\u043b\u0438 \u043d\u0435 \u0443\u0434\u0430\u043b\u044f\u043b\u0438\u0441\u044c\nlatlong_grouped[latlong_grouped['location'] == 'Birmingham']","3171c64c":"# \u0434\u043b\u044f \u0431\u0430\u0437\u044b \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0434\u0443\u0431\u043b\u0438 \u043b\u043e\u043a\u0430\u0446\u0438\u0439 \u0431\u044b\u043b\u0438 \u043e\u0447\u0438\u0449\u0435\u043d\u044b\nlatlong_cleaned[latlong_cleaned['location'] == 'Birmingham']","0a9d90f2":"# \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b \u043a \u043d\u0430\u0448\u0435\u0439 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0439 \u0431\u0430\u0437\u0435 \u0442\u0432\u0438\u0442\u043e\u0432\ndf_latlong = pd.merge(df, latlong_cleaned, left_on='location', right_on='location', how='left')\n#df_latlong = df.set_index('location').join(latlong.set_index('location'), how='left', on=['location'])\ndf_latlong.head()","118a7c0c":"df_latlong.shape","a90e7a32":"# \u041e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u043b\u043e\u043a\u0430\u0446\u0438\u0438, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b\ndf_latlong[~df_latlong['Latitude'].isna()]","59b622a3":"# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438\ndf_latlong_real = df_latlong[(~df_latlong['Latitude'].isna()) & (df_latlong['target'] == 1)]\nprint( len( df_latlong_real ) )","8ac69061":"# \u043f\u0440\u0438\u043c\u0435\u0440 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438\ndf_latlong_real.head()","08404340":"# \u041d\u0430\u043d\u0435\u0441\u0451\u043c \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0435 \u0442\u0432\u0438\u0442\u044b \u043d\u0430 \u043a\u0430\u0440\u0442\u0443\nimport folium\nfrom folium.plugins import HeatMap\n\ndf_latlong_real.Latitude.fillna(0, inplace = True)\ndf_latlong_real.Longitude.fillna(0, inplace = True) \ntwits = df_latlong_real[['Latitude', 'Longitude']]\n\nRealTwitsMap=folium.Map(location=[0,0],zoom_start=2)\nHeatMap(data=twits, radius=12).add_to(RealTwitsMap)\nRealTwitsMap","aed9a3c8":"# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438\ndf_latlong_fake = df_latlong[(~df_latlong['Latitude'].isna()) & (df_latlong['target'] == 0)]\nprint( len( df_latlong_fake ) )","e9e42148":"# \u043f\u0440\u0438\u043c\u0435\u0440 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438\ndf_latlong_fake.head()","6f897033":"# \u041d\u0430\u043d\u0435\u0441\u0451\u043c \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435 \u0442\u0432\u0438\u0442\u044b \u043d\u0430 \u043a\u0430\u0440\u0442\u0443\nimport folium\nfrom folium.plugins import HeatMap\n\ndf_latlong_fake.Latitude.fillna(0, inplace = True)\ndf_latlong_fake.Longitude.fillna(0, inplace = True) \ntwits = df_latlong_fake[['Latitude', 'Longitude']]\n\nFakeTwitsMap=folium.Map(location=[0,0],zoom_start=2)\nHeatMap(data=twits, radius=12).add_to(FakeTwitsMap)\nFakeTwitsMap","6f70ea80":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0438 \u043e\u0431\u043b\u0430\u043a\u0430 \u0447\u0430\u0441\u0442\u043e \u0443\u043f\u043e\u0442\u0440\u0435\u0431\u043b\u044f\u0435\u043c\u044b\u0445 \u0441\u043b\u043e\u0432\nfrom wordcloud import WordCloud,STOPWORDS\n\ndef wordcloud_img(data):\n    plt.figure(figsize = (20,20))\n    wc = WordCloud(min_font_size = 3, \n                   background_color=\"white\",  \n                   max_words = 3000, \n                   width = 1000, \n                   height = 600, \n                   stopwords = STOPWORDS).generate(str(\" \".join(data)))\n    plt.imshow(wc,interpolation = 'bilinear')","04d7aa89":"wordcloud_img(df[df['target'] == 1]['text'])","d0dfb054":"wordcloud_img(df[df['target'] == 0]['text'])","23c623a3":"from urllib.parse import unquote","92ef966c":"# \u0432\u044b\u0432\u0435\u0434\u0435\u043c \u0432\u0441\u0435 \u0441\u043b\u043e\u0432\u0430 \u0441 urlencoded-\u0441\u0438\u043c\u0432\u043e\u043b\u0430\u043c\u0438 (\u0443 \u043d\u0438\u0445 \u0432\u0441\u0435\u0433\u0434\u0430 \u0441\u0442\u043e\u0438\u0442 \u0437\u043d\u0430\u043a \"%\")\nfor phrase in df['keyword']:\n    phrase  = str(phrase)\n    if('%' in phrase):\n        print(phrase)","13ee79f3":"# \u0434\u0435\u043b\u0430\u0435\u043c \u0437\u0430\u043c\u0435\u043d\u0443\nfor i, phrase in enumerate(df['keyword']):\n    phrase  = str(phrase)\n    if('%20' in phrase):\n        df.loc[i, 'keyword'] = df.loc[i, 'keyword'].replace('%20', ' ')\n\n# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c\n# \u0432\u044b\u0432\u0435\u0434\u0435\u043c \u0432\u0441\u0435 \u0441\u043b\u043e\u0432\u0430 \u0441 urlencoded-\u0441\u0438\u043c\u0432\u043e\u043b\u0430\u043c\u0438 (\u0443 \u043d\u0438\u0445 \u0432\u0441\u0435\u0433\u0434\u0430 \u0441\u0442\u043e\u0438\u0442 \u0437\u043d\u0430\u043a \"%\")\nfor phrase in df['keyword']:\n    phrase  = str(phrase)\n    if('%' in phrase):\n        print(phrase)","658c6315":"# \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 c\u0442\u043e\u043b\u0431\u0446\u0430\u0445\ndf.isna().sum()","553eff5a":"def location_and_keyword_fill_nan(df):\n    #\u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0434\u043b\u044f keywords \u0437\u0430\u043c\u0435\u043d\u0438\u043c \u043d\u0430 None\n    df.keyword.fillna('None', inplace = True)\n\n    #\u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0434\u043b\u044f location \u0437\u0430\u043c\u0435\u043d\u0438\u043c \u043d\u0430 None\n    df.location.fillna('None', inplace = True)\n\nlocation_and_keyword_fill_nan(df)\n\n# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c\ndf.isna().sum()","67763137":"# \u0432\u0435\u0440\u043d\u0451\u043c \u0438\u043d\u0434\u0435\u043a\u0441\u044b \u0442\u0435\u0445 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u043c\u0430\u0441\u0441\u0438\u0432\u0430 target (\u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439), \u0433\u0434\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 0\ntarget_np = df['target'].astype(int).to_numpy()\nfake_twits_ids = np.argwhere(target_np == 0).flatten()\nprint('\u0412\u0441\u0435\u0433\u043e fake_twits: ', len(fake_twits_ids))\nfake_twits_ids","ad83f2b4":"# \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0430\u0435\u043c \u043c\u0430\u0441\u0441\u0438\u0432 \u0441 id \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432\nfrom sklearn.utils import shuffle\nfake_twits_ids = shuffle(fake_twits_ids, random_state = 42)\n\n# \u0432\u044b\u0431\u0435\u0440\u0435\u043c \u0432 \u043d\u0435\u043c \"\u043b\u0438\u0448\u043d\u0438\u0435\" id \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432\n# \u0442.\u0435. \u0432\u043e\u0437\u044c\u043c\u0451\u043c \u0432\u0441\u0435 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b \u043f\u043e\u0441\u043b\u0435 \u043d\u043e\u043c\u0435\u0440\u0430 3271 \u0438\u0437 \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0430\u043d\u043d\u043e\u0433\u043e \u043c\u0430\u0441\u0441\u0438\u0432\u0430 fake_twits_ids\nfake_twits_ids_to_drop = fake_twits_ids[len(np.argwhere(target_np == 1).flatten()):]\n\n# \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0435\u043c \u043a\u043e\u043b-\u0432\u043e \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0443\u0436\u043d\u043e \u0432\u044b\u0431\u0440\u043e\u0441\u0438\u0442\u044c \u0438\u0437 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0434\u043b\u044f \u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043a\u0438, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0438\u0445 id\nprint(len(fake_twits_ids_to_drop))\nfake_twits_ids_to_drop","f84d953a":"# \u0442.\u043a. \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u0435\u0440\u043c\u0435\u0448\u0430\u043d\u044b, \u0442\u043e \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0430\u043d\u0438\u044f \u043b\u0438\u0448\u043d\u0438\u0445 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432, \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0431\u0443\u0434\u0435\u0442 \u0440\u0435\u043f\u0440\u0435\u0437\u0435\u043d\u0442\u0430\u0442\u0438\u0432\u043d\u043e\u0439\ndf_balanced = df.drop(df.index[fake_twits_ids_to_drop])\n\n# \u043e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430\ndf_balanced.shape","c265bac7":"# \u0442\u0435\u043f\u0435\u0440\u044c \u0432\u0438\u0434\u0438\u043c, \u0447\u0442\u043e \u043a\u043b\u0430\u0441\u0441\u044b \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u044b.\ndf_balanced['target'].value_counts()","8d579e4d":"# \u0433\u0438\u0441\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u0430\ndf_balanced[df_balanced['target'] == 0]['target'].astype(int).hist(label='\u0424\u0435\u0439\u043a', grid = False, bins=1, rwidth=0.8)\ndf_balanced[df_balanced['target'] == 1]['target'].astype(int).hist(label='\u0420\u0435\u0430\u043b\u044c\u043d\u044b\u0435', grid = False, bins=1, rwidth=0.8)\nplt.xticks((0,1),('\u0424\u0435\u0439\u043a', '\u0420\u0435\u0430\u043b\u044c\u043d\u044b\u0435'))\nplt.show()","44aefb89":"def location_and_keyword_to_bool_category(df):\n    df.loc[df['location'] == 'None', 'location_bool'] = 0\n    df.loc[df['location'] != 'None', 'location_bool'] = 1\n    df.loc[df['keyword'] == 'None', 'keyword_bool'] = 0\n    df.loc[df['keyword'] != 'None', 'keyword_bool'] = 1\n\nlocation_and_keyword_to_bool_category(df_balanced)\n\n# \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c\ndf_balanced","e3363576":"# \u0434\u0435\u043b\u0430\u0435\u043c \u043f\u043e\u0434\u043e\u0431\u043d\u044b\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0434\u043e \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0438 \u043d\u0430 train \u0438 test,\u0442.\u043a. \u0442\u0430\u043a\u0438\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0430 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u044f\u0442 \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e \u043e\u0442\u0432\u044b\u0431\u043e\u0440\u043a\u0438\n# \u043a \u0442\u043e\u043c\u0443 \u0436\u0435 X_train \u0438 X_test, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043e\u0431\u0440\u0430\u0437\u0443\u044e\u0442\u0441\u044f \u043f\u043e\u0441\u043b\u0435 train_test_split \u044f\u0432\u043b\u044f\u044e\u0442\u0441\u044f \u043a\u043e\u043f\u0438\u044f\u043c\u0438 \u0431\u0430\u0437\u044b \u0438 \u043d\u0430 \u043a\u043e\u043f\u0438\u044f\u0445 \u0442\u0430\u043a\u0438\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0434\u0435\u043b\u0430\u0442\u044c \u0441\u043b\u043e\u0436\u043d\u0435\u0435 (\u043c\u043e\u0436\u0435\u0442 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c\u0441\u044f \u043e\u0448\u0438\u0431\u043a\u0430\u043e \u0442\u043e\u043c, \u0447\u0442\u043e \u0440\u0430\u0431\u043e\u0442\u044b \u0432\u0435\u0434\u0443\u0442\u0441\u044f \u043d\u0430 \u043a\u043e\u043f\u0438\u0438 \u0438 \u0442.\u043f.)\n# regular expressions library\nimport re\n\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0435\u0434\u0438\u043d\u0438\u0447\u043d\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0430\ndef single_text_clean(text):\n    # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0442\u0435\u043a\u0441\u0442 \u0432 \u043d\u0438\u0436\u043d\u0438\u0439 \u0440\u0435\u0433\u0438\u0441\u0442\u0440\n    text = text.lower()\n    # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c https:\/\/ \u0438 \u0442.\u043f. \u0430\u0434\u0440\u0435\u0441\u0430 \u0432 \u0442\u0435\u043a\u0441\u0442 \"URL\"\n    text = re.sub('((www\\.[^\\s]+)|(https?:\/\/[^\\s]+))','URL',text)\n    # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0438\u043c\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f @username \u0432 \"AT_USER\"\n    text = re.sub('@[^\\s]+','AT_USER', text)\n    # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u0435\u043d\u044b\u0435 \u043f\u0440\u043e\u0431\u0435\u043b\u044b \u0432 \u043e\u0434\u0438\u043d \u043f\u0440\u043e\u0431\u0435\u043b\n    text = re.sub('[\\s]+', ' ', text)\n    # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0445\u044d\u0448\u0442\u0435\u0433 #\u0442\u0435\u043c\u0430 \u0432 \"\u0442\u0435\u043c\u0430\"\n    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n    return text\n\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0442\u0435\u043a\u0441\u0442\u0430 \u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u0445 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430 \n# (\u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0443\u044e \u0444\u0443\u043d\u043a\u0446\u0438\u044e single_text_clean \u043a \u0440\u0430\u0437\u043d\u044b\u043c \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c)\ndef text_columns_clean(df):\n    text_columns_to_clean = ['keyword', 'location', 'text']\n    for column in text_columns_to_clean:\n        df.loc[:, column] = df[column].apply(single_text_clean)\n\ntext_columns_clean(df_balanced)\n\n# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c\ndf_balanced","07909fa7":"import nltk\nfrom nltk.corpus import stopwords\nimport string\n\nstop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)","6ee808dc":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u043b\u0430\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 (ADJ), \u0433\u043b\u0430\u0433\u043e\u043b\u043e\u0432 (VERB), \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 (NOUN) \u0438 \u043d\u0430\u0440\u0435\u0447\u0438\u0439 (ADV)\nfrom nltk.corpus import wordnet as wn\n\ndef get_simple_pos(tag):\n    if tag.startswith('J'):\n        return wn.ADJ\n    elif tag.startswith('V'):\n        return wn.VERB\n    elif tag.startswith('N'):\n        return wn.NOUN\n    elif tag.startswith('R'):\n        return wn.ADV\n    else:\n        return wn.NOUN\n\n# \u041b\u0435\u043c\u043c\u0430\u0442\u0438\u0437\u0430\u0446\u0438\u044f \nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import pos_tag\n\n# (\u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u0435\u043c \u0432\u0441\u0451 \u043b\u0438\u0448\u043d\u0435\u0435 \u0432 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0438, \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u043c \u0441\u043b\u043e\u0432\u0430 \u043a \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0439 \u0444\u043e\u0440\u043c\u0435\u0438 \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0438\u0445 \u0441\u043f\u0438\u0441\u043e\u043a)\n# 'Once upone a time a man walked into a door' -> ['upone', 'time', 'man', 'walk', 'door']\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            pos = pos_tag([i.strip()])\n            word = lemmatizer.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n            final_text.append(word.lower())\n    return final_text   \n\n# \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u043b\u0435\u043c\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u0432 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0435\n# ['upone', 'time', 'man', 'walk', 'door'] -> 'upone time man walk door '\ndef join_text(text):\n    string = ''\n    for i in text:\n        string += i.strip() +' '\n    return string\n\n# \u0417\u0430\u043f\u0443\u0441\u043a \u043b\u0435\u043c\u043c\u0430\u0442\u0438\u0437\u0430\u0446\u0438\u0438 \u0438 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043d\u043e\u0432\u043e\u0433\u043e \u043f\u043e\u043b\u044f \u0441 \u043b\u0435\u043c\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u044f\u043c\u0438 'text_lemma'\ndf_balanced.loc[:, 'text'] = df_balanced['text'].apply(lemmatize_words).apply(join_text)\n\n# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c\ndf_balanced","c01c4cc7":"# \u0443\u0434\u0430\u043b\u0438\u043c \u043d\u0435 \u043d\u0443\u0436\u043d\u043e\u0435 \u043d\u0430\u043c \u0431\u043e\u043b\u044c\u0448\u0435 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0435 \u043f\u043e\u043b\u0435 id (\u043e\u043d\u043e \u0435\u0441\u0442\u044c \u0432 \u0438\u043d\u0434\u0435\u043a\u0441\u0435)\ndf_balanced = df_balanced.drop(['id'], axis=1)\n\nfrom sklearn.model_selection import train_test_split\n\n# \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u043d\u0430 X \u0438 y\ny = df_balanced['target']\nX = df_balanced.drop(['target'], axis=1)\n\n# \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u043d\u0430 train \u0438 test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)\n\n# \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c\nX_train.shape","d5dfc80a":"X_train","4fa00e2e":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# \u041f\u0440\u0438\u0441\u0432\u043e\u0435\u043d\u0438\u0435 \u0432\u0435\u0441\u043e\u0432 \u0441\u043b\u043e\u0432\u0430\u043c \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c TfidfVectorizer\ntv = TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,2))\ntv_X_train = tv.fit_transform(X_train['text'])\ntv_X_test = tv.transform(X_test['text'])\n\nprint('TfidfVectorizer_train:', tv_X_train.shape)\nprint('TfidfVectorizer_test:', tv_X_test.shape)","12af20b5":"# \u043f\u0435\u0440\u0435\u0432\u0435\u0440\u043d\u0451\u043c \u0441\u0442\u043e\u043b\u0431\u0446\u044b \u0441\u043e \u0441\u043b\u043e\u0432\u0430\u043c\u0438 \u0438\u0437 sparse \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0441 \u043e\u0434\u043d\u0438\u043c \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u043c \u0432 numpy \u043c\u0430\u0441\u0441\u0438\u0432 \u0441\u043e \u043c\u043d\u043e\u0433\u0438\u043c\u0438 \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c\u0438\ntv_X_train = tv_X_train.toarray()\ntv_X_test = tv_X_test.toarray()","7a13f5cf":"# \u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 tv_X_train\/test\nfrom sklearn.preprocessing import StandardScaler\n\ndef scaling_train(tv_X_train):\n    scaler_tv = StandardScaler(copy=False)\n    tv_X_train_scaled = scaler_tv.fit_transform(tv_X_train)\n    # \u0442\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c tv_X_train\/test sparse numpy \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0432 pandas Data Frame\n    tv_X_train_pd_scaled = pd.DataFrame(data=tv_X_train_scaled, \n                             index=X_train.index, \n                             columns=np.arange(0, np.size(tv_X_train_scaled,1)))\n    return tv_X_train_pd_scaled, scaler_tv\n\ndef scaling_test(tv_X_test, scaler_tv):\n    tv_X_test_scaled = scaler_tv.transform(tv_X_test)\n    # \u0442\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c tv_X_train\/test sparse numpy \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0432 pandas Data Frame\n    tv_X_test_pd_scaled = pd.DataFrame(data=tv_X_test_scaled, \n                             index=X_test.index, \n                             columns=np.arange(0, np.size(tv_X_test_scaled,1)))\n    return tv_X_test_pd_scaled\n\ntv_X_train_pd_scaled, scaler_tv = scaling_train(tv_X_train)\ntv_X_test_pd_scaled = scaling_test(tv_X_test, scaler_tv)\n\n# \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c\ntv_X_train_pd_scaled.shape, tv_X_test_pd_scaled.shape","9cc8df8c":"# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c pandas dataframe \u0432 numpy array \u0434\u043b\u044f pytorch \u043c\u043e\u0434\u0435\u043b\u0438\ntv_X_train_pd_scaled_arr = tv_X_train_pd_scaled.to_numpy()\ntv_X_test_pd_scaled_arr = tv_X_test_pd_scaled.to_numpy()","2bd30a3d":"tv_X_test_pd_scaled_arr","64cfe98a":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\n# funtools - \u0440\u0430\u0431\u043e\u0442\u0430 \u0441 \u0444\u0443\u043d\u043a\u0446\u0438\u044f\u043c\u0438 \u0432\u044b\u0441\u0448\u0435\u0433\u043e \u043f\u043e\u0440\u044f\u0434\u043a\u0430\n# partial - \u0438\u0437\u043c\u0435\u043d\u044f\u0435\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u0432 \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u0434\u0430\u043d\u043d\u044b\u0445 \u0444\u0443\u043d\u043a\u0446\u0438\u0439 \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043e\u0434\u043d\u0443 \u0437\u0430 \u0434\u0440\u0443\u0433\u043e\u0439\nfrom functools import partial\n\n# \u0434\u0435\u043b\u0430\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0439 \u0432\u044b\u0431\u043e\u0440\u043e\u043a \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u044b\u043c\u0438 (\u044d\u0442\u043e \u0430\u043d\u0430\u043b\u043e\u0433 random_state \u0432 sklearn)\ntorch.manual_seed(42)","d2eab2d4":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0434\u0435\u0432\u0430\u0439\u0441, \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442\u044c \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0430 (\u0435\u0441\u043b\u0438 \u0443 \u043d\u0430\u0441 CPU, \u0442\u043e \u0431\u0443\u0434\u0435\u0442 \u043d\u0430 CPU, \u0435\u0441\u043b\u0438 GPU, \u0442\u043e - \u043d\u0435 GPU)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","402ca5a7":"# \u043a\u043b\u0430\u0441\u0441 \u0434\u043b\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0438 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 Pytorch\n# \u043e\u043d \u043d\u0430\u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u043a\u043b\u0430\u0441\u0441 Dataset\n# df_tfidf - \u044d\u0442\u043e df \u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0432 tf-idf (\u0442.\u0435. \u044d\u0442\u043e \u043c\u0430\u0442\u0440\u0438\u0446\u0430 tv_X_train \u0438\u043b\u0438 tv_X_test)\n# df - \u044d\u0442\u043e \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0431\u0430\u0437\u0430 df_balanced\n\nclass TwitsDataset(Dataset):\n    def __init__(self, tv_X_train_array, y_train):\n        df = pd.DataFrame(index=y_train.index)\n        \n        # \u0442\u0435\u043a\u0441\u0442 \u043f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043e\u0447\u0438\u0449\u0435\u043d, \u043b\u0435\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d \u0438 \u043f\u0440\u0435\u0432\u0440\u0430\u0449\u0435\u043d \u0432 \u0442\u043e\u043a\u0435\u043d\u044b \u043d\u0430 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0445 \u0448\u0430\u0433\u0430\u0445\n        df['tfidf_vector'] = [vector.tolist() for vector in tv_X_train_array]\n        \n        self.tfidf_vector = df.tfidf_vector.tolist()\n        self.targets = y_train.tolist()\n    \n    def __getitem__(self, i):\n        return (\n            self.tfidf_vector[i],\n            self.targets[i]\n        )\n    \n    def __len__(self):\n        return len(self.targets)","0c6f6ce2":"for i, vector in enumerate(tv_X_train):\n    print(vector)\n    vector.tolist()\n    if(i ==  5): break","c7a0eaa5":"# \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u043a\u043b\u0430\u0441\u0441 \u0438 \u0438\u0445 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435\n\n# \u043d\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 tf-idf\ndataset = TwitsDataset(tv_X_train_pd_scaled_arr, y_train)","5d5de491":"# \u0422.\u043a. \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043c\u044b \u0443\u0436\u0435 \u0440\u0430\u043d\u0435\u0435 \u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043b\u0438, \u0442\u043e \u043d\u0430 \u0434\u0430\u043d\u043d\u043e\u043c \u0448\u0430\u0433\u0435 \u043d\u0435 \u0431\u0443\u0434\u0435\u043c \u0435\u0451 \u0432\u044b\u0434\u0435\u043b\u044f\u0442\u044c \u0438\u0437 \u0442\u0435\u043a\u0443\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 (\u0442\u0435\u0441\u0442\u043e\u0432\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0432 \u044d\u0442\u043e\u0442 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043d\u0435 \u0432\u0445\u043e\u0434\u0438\u0442)\nfrom torch.utils.data.dataset import random_split\n\ndef split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\n    \"\"\"Split dataset into train, validation, and test.\"\"\"\n    test_length = int(len(corpus) * test_ratio)\n    valid_length = int(len(corpus) * valid_ratio)\n    train_length = len(corpus) - valid_length - test_length\n    return random_split(\n        corpus, lengths=[train_length, valid_length, test_length],\n    )\n\ntrain_dataset, valid_dataset, test_dataset = split_train_valid_test(dataset, valid_ratio=0.2, test_ratio=0.0)\nlen(train_dataset), len(valid_dataset), len(test_dataset)\n# \u044d\u0442\u043e \u043d\u0435 \u0437\u043d\u0430\u0447\u0438\u0442, \u0447\u0442\u043e Test-\u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0443 \u043d\u0430\u0441 = 0, \u043f\u0440\u043e\u0441\u0442\u043e \u043e\u043d\u0430 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0430 \u0432 \u0434\u0440\u0443\u0433\u043e\u043c \u043c\u0435\u0441\u0442\u0435 \u0438 \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f tv_X_test \n# (\u0430 \u043d\u0430 \u0434\u0430\u043d\u043d\u043e\u043c \u0448\u0430\u0433\u0435 \u043c\u044b \u043f\u0440\u043e\u0441\u0442\u043e \u043d\u0435 \u0432\u044b\u0434\u0435\u043b\u044f\u043b\u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u0438\u0437 tv_X_train, \u0442.\u043a. \u0443 \u043d\u0430\u0441 \u0443\u0436\u0435 \u0435\u0441\u0442\u044c tv_X_test)","26a3b9c6":"# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0435 train_dataset\nprint('\u0427\u0438\u0441\u043b\u043e \u0437\u0430\u043f\u0438\u0441\u0435\u0439:', len(train_dataset), '\\n')\n\nimport random\n# \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043e\u0434\u043d\u0438\u0445 \u0438 \u0442\u0435\u0445 \u0436\u0435 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\nrandom.seed(a=42, version=2)\n\nrandom_idx = random.randint(0,len(train_dataset)-1)\nprint('\u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b \u0438\u043d\u0434\u0435\u043a\u0441 \u0438\u0437 dataset:', random_idx, '\\n')\ntfidf_vector, sample_target = train_dataset[random_idx]\nprint('\u0420\u0430\u0437\u043c\u0435\u0440 \u0432\u0435\u043a\u0442\u043e\u0440\u0430 TF-IDF:', len(tfidf_vector), '\\n')\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u0442\u0430\u0440\u0433\u0435\u0442\u0430:', sample_target, '\\n')","6562dd3c":"# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0435 valid_dataset\nprint('\u0427\u0438\u0441\u043b\u043e \u0437\u0430\u043f\u0438\u0441\u0435\u0439:', len(valid_dataset), '\\n')\n\nrandom.seed(a=42, version=2)\nrandom_idx = random.randint(0,len(valid_dataset)-1)\nprint('\u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b \u0438\u043d\u0434\u0435\u043a\u0441 \u0438\u0437 dataset:', random_idx, '\\n')\ntfidf_vector, sample_target = valid_dataset[random_idx]\nprint('\u0420\u0430\u0437\u043c\u0435\u0440 \u0432\u0435\u043a\u0442\u043e\u0440\u0430 TF-IDF:', len(tfidf_vector), '\\n')\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u0442\u0430\u0440\u0433\u0435\u0442\u0430:', sample_target, '\\n')","5f5b7fd1":"# \u0437\u0430\u0433\u0440\u0443\u0437\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f Pytorch (\u0433\u0440\u0443\u0437\u0438\u0442 \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0431\u0430\u0442\u0447\u0430\u043c)\nBATCH_SIZE = 512\n\ndef collate(batch):\n    tfidf = torch.FloatTensor([item[0] for item in batch])\n    target = torch.LongTensor([item[1] for item in batch])\n    return tfidf, target\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate)","88d8fb88":"# \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0435 train_loader\nprint('\u0427\u0438\u0441\u043b\u043e training batches:', len(train_loader), '\\n')\n\nrandom.seed(a=42, version=2)\nbatch_idx = random.randint(0, len(train_loader)-1)\nexample_idx = random.randint(0, BATCH_SIZE-1)\n\nprint(\"Batch index: \", batch_idx)\nprint(\"Example index: \", example_idx)\n\nfor i, fields in enumerate(train_loader):\n    tfidf, target = fields\n    if i == batch_idx:\n        print('\u0420\u0430\u0437\u043c\u0435\u0440 \u0432\u0435\u043a\u0442\u043e\u0440\u0430 TF-IDF:', len(tfidf[example_idx]), '\\n')\n        #print('\u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 TF-IDF: ', tfidf[example_idx], '\\n')\n        print('\u0422\u0438\u043f TF-IDF: ', type(tfidf[example_idx]), '\\n')\n        #print('\u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u0442\u0430\u0440\u0433\u0435\u0442: ', target[example_idx], '\\n')\n        print('\u0422\u0438\u043f \u0442\u0430\u0440\u0433\u0435\u0442\u0430: ', type(target[example_idx]), '\\n')","903687b4":"# \u0441\u0442\u0440\u043e\u0438\u043c \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c (\u0412\u0430\u0440\u0438\u0430\u043d\u0442 2 - CNN \u043d\u0430 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0445 TF-IDF)\n\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\nclass Reorder(nn.Module):\n    def forward(self, input):\n        return input.permute((0, 2, 1))\n\nclass FeedfowardTextClassifier(nn.Module):\n    def __init__(self, device, vocab_size, hidden1, hidden2, hidden3, hidden4, num_labels, batch_size):\n        super(FeedfowardTextClassifier, self).__init__()\n        self.device = device\n        self.batch_size = batch_size\n\n        self.convnet = nn.Sequential(\n            nn.Conv1d(in_channels=vocab_size,\n                      out_channels=hidden1, \n                      kernel_size=1),\n            nn.ELU(),\n            nn.Dropout(p=0.5),\n            nn.Conv1d(in_channels=hidden1, \n                      out_channels=hidden2,\n                      kernel_size=1, \n                      #stride=1\n                     ),\n            nn.ELU(),\n            nn.Dropout(p=0.5),\n        )\n        self.fc = nn.Linear(hidden2, 2)\n    \n    def forward(self, x):\n        batch_size = len(x)\n        if batch_size != self.batch_size:\n            self.batch_size = batch_size\n\n        features = self.convnet(x)\n        \n        # \u043f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f convnet \u0443\u0434\u0430\u043b\u044f\u0435\u043c 3-\u0435\u0435 \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u0435 (\u0438\u043d\u0434\u0435\u043a\u0441 = 2) \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c\u044e 1\n        features = features.squeeze(dim=2)\n        \n        prediction_vector = self.fc(features)\n        return prediction_vector\n        \n# \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u044b \u0441\u043a\u0440\u044b\u0442\u044b\u0445 \u0441\u043b\u043e\u0451\u0432\nHIDDEN1 = 512\nHIDDEN2 = 128\nHIDDEN3 = 128\nHIDDEN4 = 128\n\ntfidf_model = FeedfowardTextClassifier(\n    vocab_size=len(tfidf_vector),\n    hidden1=HIDDEN1,\n    hidden2=HIDDEN2,\n    hidden3=HIDDEN3,\n    hidden4=HIDDEN4,\n    num_labels=2,\n    device=device,\n    batch_size=BATCH_SIZE,\n)","51b02068":"# \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0438\u043c \u043d\u0430 GPU\ntfidf_model = tfidf_model.to(device)\ntfidf_model","cc67dd8a":"# Loss-\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0438 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\n\nfrom torch import optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nLEARNING_RATE = 4e-2\n\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, tfidf_model.parameters()),\n    lr=LEARNING_RATE,\n)\n\nscheduler = CosineAnnealingLR(optimizer, 1)","d1c6a27b":"# \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0438 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0448\u0430\u0433\u0438 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438\n\ndef train_epoch(model, optimizer, train_loader):\n    model.train()\n    total_loss, total = 0, 0\n    for i, (tfidf, target) in enumerate(train_loader):\n        \n        inputs = tfidf\n        # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043d\u043e\u0432\u0443\u044e \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c: \u043a\u0430\u043d\u0430\u043b \u0434\u043b\u044f \u0432\u0445\u043e\u0434\u0430 \u0432 cnn      \n        inputs = inputs.unsqueeze(dim=2)\n        \n        #print(inputs.shape)\n        \n        # \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0438\u043c \u043d\u0430 GPU\n        inputs = inputs.to(device)\n        target = target.to(device)\n        \n        # Reset gradient\n        optimizer.zero_grad()\n        \n        # Forward pass\n        output = model(inputs)\n        \n        # Compute loss\n        loss = criterion(output, target)\n        \n        # Perform gradient descent, backwards pass\n        loss.backward()\n\n        # Take a step in the right direction\n        optimizer.step()\n        scheduler.step()\n\n        # Record metrics\n        total_loss += loss.item()\n        total += len(target)\n\n    return total_loss \/ total\n\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0438 \u0448\u0430\u0433\u0438 \u0434\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\ndef validate_epoch(model, valid_loader):\n    model.eval()\n    total_loss, total = 0, 0\n    with torch.no_grad():\n        for tfidf, target in valid_loader:\n            inputs = tfidf\n            \n            # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043d\u043e\u0432\u0443\u044e \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c: \u043a\u0430\u043d\u0430\u043b \u0434\u043b\u044f \u0432\u0445\u043e\u0434\u0430 \u0432 cnn\n            inputs = inputs.unsqueeze(dim=2)\n            \n            # \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0438\u043c \u043d\u0430 GPU\n            inputs = inputs.to(device)\n            target = target.to(device)\n            \n            #print(\"Val: \", inputs.shape)\n            \n            # Forward pass\n            output = model(inputs)\n\n            # Calculate how wrong the model is\n            loss = criterion(output, target)\n\n            # Record metrics\n            total_loss += loss.item()\n            total += len(target)\n\n    return total_loss \/ total","058e4e30":"# \u0442\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c\nfrom tqdm import tqdm\n\nmax_epochs = 50\nn_epochs = 0\ntrain_losses = []\nvalid_losses = []\n\nfor epoch_num in range(max_epochs):\n\n    train_loss = train_epoch(tfidf_model, optimizer, train_loader)\n    valid_loss = validate_epoch(tfidf_model, valid_loader)\n    \n    tqdm.write(\n        f'\u044d\u043f\u043e\u0445\u0430 #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.2e}\\tvalid_loss: {valid_loss:.2e}\\n',\n    )\n    \n    # Early stopping (\u0440\u0430\u043d\u043d\u044f\u044f \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430) \u0435\u0441\u043b\u0438 \u0442\u0435\u043a\u0443\u0449\u0438\u0439 valid_loss (\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043e\u0448\u0438\u0431\u043a\u0438 \u0434\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438) \u0431\u043e\u043b\u044c\u0448\u0435 \u0447\u0435\u043c 10 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0445 valid losses\n    if len(valid_losses) > 7 and all(valid_loss >= loss for loss in valid_losses[-8:]):\n        print('Stopping early')\n        break\n    \n    \n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    n_epochs += 1","564c0527":"# \u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a loss-\u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0441\u043b\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438\nepoch_ticks = range(1, n_epochs + 1)\nplt.plot(epoch_ticks, train_losses)\nplt.plot(epoch_ticks, valid_losses)\nplt.legend(['Train Loss', 'Valid Loss'])\nplt.title('Losses') \nplt.xlabel('Epoch #')\nplt.ylabel('Loss')\nplt.xticks(epoch_ticks)\nplt.show()","a860c76d":"# \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u043a\u043b\u0430\u0441\u0441 \u0438 \u0438\u0445 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435\ntest_dataset = TwitsDataset(tv_X_test, y_test)","645cb84c":"# \u0437\u0430\u0433\u0440\u0443\u0437\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f Pytorch (\u0433\u0440\u0443\u0437\u0438\u0442 \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0431\u0430\u0442\u0447\u0430\u043c)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate)","1722a07d":"# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0435 test_loader\nprint('\u0427\u0438\u0441\u043b\u043e training batches:', len(test_loader), '\\n')\n\nrandom.seed(a=42, version=2)\nbatch_idx = random.randint(0, len(test_loader)-1)\nexample_idx = random.randint(0, BATCH_SIZE-1)\n\nfor i, fields in enumerate(test_loader):\n    tfidf, target = fields\n    if i == batch_idx:\n        print('\u0420\u0430\u0437\u043c\u0435\u0440 \u0432\u0435\u043a\u0442\u043e\u0440\u0430 TF-IDF:', len(tfidf[example_idx]), '\\n')\n        print('\u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u0442\u0430\u0440\u0433\u0435\u0442: ', target[example_idx], '\\n')","6473a5da":"# \u042d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u044c Pytorch CNN-\u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 TFIDF\nfrom sklearn.metrics import classification_report\n\ntfidf_model.eval()\ntest_accuracy, n_examples = 0, 0\ny_true, y_pred = [], []\n\nwith torch.no_grad():\n    for tfidf, target in test_loader:\n        # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043d\u043e\u0432\u0443\u044e \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c: \u043a\u0430\u043d\u0430\u043b \u0434\u043b\u044f \u0432\u0445\u043e\u0434\u0430 \u0432 cnn\n        tfidf = tfidf.unsqueeze(dim=2)\n        \n        inputs = tfidf.to(device)\n        target = target.to(device)\n        \n        probs = tfidf_model(inputs)\n        \n        probs = probs.detach().cpu().numpy()\n        predictions = np.argmax(probs, axis=1)\n        target = target.cpu().numpy()\n        \n        y_true.extend(predictions)\n        y_pred.extend(target)\n        \nprint(classification_report(y_true, y_pred))","33b6e79b":"# Pytorch \u043c\u043e\u0434\u0435\u043b\u044c","dd48fae5":"\u0422.\u043a. \u043d\u0438 \u043e\u0434\u043d\u043e\u0439 \u0444\u0440\u0430\u0437\u044b \u043d\u0435 \u0432\u044b\u0432\u0435\u0434\u0435\u043d\u043e, \u043d\u043e \u0432\u0441\u0435 \u0437\u0430\u043c\u0435\u043d\u044b \u043f\u0440\u043e\u0448\u043b\u0438 \u0443\u0441\u043f\u0435\u0448\u043d\u043e \u0438 \u0431\u043e\u043b\u044c\u0448\u0435 \u043d\u0435\u0442 urlencoded-\u0441\u043b\u043e\u0432\u043e\u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u0439","2e72fae8":"### \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u043d\u0430 training \u0438 validation \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n* Training: \u043d\u0430 \u043d\u0435\u0439 \u0431\u0443\u0434\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u0442\u044c\n* Validation: \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0434\u043b\u044f \u0442\u044e\u043d\u043d\u0433\u0430 \u0433\u0438\u043f\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 (\u0447\u0442\u043e\u0431\u044b \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0435 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0430\u043b\u0430\u0441\u044c)\n* Testing: \u0434\u043b\u044f \u0444\u0438\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u043e\u0446\u0435\u043d\u043a\u0438 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 - \u044d\u0442\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0443 \u043d\u0430\u0441 \u0443\u0436\u0435 \u0435\u0441\u0442\u044c (\u0431\u044b\u043b\u0430 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0430 \u043d\u0430 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0445 \u0448\u0430\u0433\u0430\u0437 \u0432\u044b\u0448\u0435)","6dc082b6":"### \u0421\u0442\u043e\u043f-\u0441\u043b\u043e\u0432\u0430","60d693be":"# 4.2. \u0420\u0430\u0437\u0431\u0438\u0432\u043a\u0430 \u043d\u0430 train \u0438 test","2364eb97":"\u0432\u043e \u0432\u0441\u0435\u0445 \u0441\u043b\u0443\u0447\u0430\u044f\u0445 \u0443 \u043d\u0430\u0441 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u043e\u0431\u0435\u043b \u0437\u043d\u0430\u043a\u043e\u043c \"%20\", \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043c\u044b \u0435\u0433\u043e \u043f\u0440\u043e\u0441\u0442\u043e \u0437\u0430\u043c\u0435\u043d\u0438\u043c \u043d\u0430 \u043e\u0431\u044b\u0447\u043d\u044b\u0439 \u043f\u0440\u043e\u0431\u0435\u043b","b51e3272":"## \u0410\u043d\u0430\u043b\u0438\u0437 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","3baa7e2b":"\u0412\u044b\u0432\u043e\u0434: \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e\u0447\u0442\u0438 \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u044b, \u043d\u043e \u043d\u0435 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e.\n\u0412\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u043c \u0440\u0430\u0437\u0434\u0435\u043b\u0435 \u043c\u044b \u043f\u0440\u043e\u0432\u0435\u0434\u0451\u043c \u043f\u043e\u043b\u043d\u0443\u044e \u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043a\u0443 \u043f\u0443\u0442\u0451\u043c \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u043d\u0438\u044f \u043b\u0438\u0448\u043d\u0438\u0445 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 (\u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0430\u0435\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u0444\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0438 \u0443\u0434\u0430\u043b\u0438\u043c \u043e\u0442\u0442\u0443\u0434\u0430 \u043b\u0438\u0448\u043d\u0438\u0435 1071 \u044d\u043b\u0435\u043c\u0435\u043d\u0442 (= 4342 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 - 3271 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432)).","90962820":"# 2. \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","e2875925":"### \u041d\u043e\u0432\u044b\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435","8ba7fcac":"# 3. \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","344f285d":"### \u0434\u0435\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c keywords","2abfa95d":"# 4. \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","83bfc3ae":"# 5. \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f\n","001b9af3":"\u0412\u0432\u0435\u0434\u0451\u043c 2 \u043d\u043e\u0432\u044b\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435:\n1. location_bool - \u0444\u0430\u043a\u0442 \u043d\u0430\u043b\u0438\u0447\u0438\u044f\/\u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0438\u044f \u043b\u043e\u043a\u0430\u0446\u0438\u0438 \u0432 \u0442\u0432\u0438\u0442\u0435.\n2. keyword_bool - \u0444\u0430\u043a\u0442 \u043d\u0430\u043b\u0438\u0447\u0438\u044f\/\u043e\u0442\u0441\u0443\u0441\u0442\u0432\u0438\u044f \u043a\u043b\u044e\u0447\u0435\u0432\u043e\u0433\u043e \u0441\u043b\u043e\u0432\u0430 \u0432 \u0442\u0432\u0438\u0442\u0435.","d42435cc":"### Stemming \u0438 Lemmatization","91936a17":"**\u041a\u0430\u0440\u0442\u0430 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432**","3d49f62f":"TFIDFVectorizer \u043a\u0430\u0436\u0434\u043e\u043c\u0443 \u0441\u043b\u043e\u0432\u0443 \u0441\u0442\u0430\u0432\u0438\u0442 \u0447\u0430\u0441\u0442\u043e\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f, \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u043f\u0440\u043e\u043f\u043e\u0440\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e \u0441\u0447\u0435\u0442\u0443, \u043d\u043e \u0441\u043c\u0435\u0449\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u0447\u0430\u0441\u0442\u043e\u0442\u0443 \u0441\u043b\u043e\u0432\u0430 \u0432 \u043a\u043e\u0440\u043f\u0443\u0441\u0435.","16f8a612":"**\u0412\u044b\u0432\u043e\u0434\u044b:** \u043f\u043e\u0432\u0435\u0440\u0445\u043d\u043e\u0441\u0442\u043d\u043e \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u044f \u0434\u0432\u0430 \u043e\u0431\u043b\u0430\u043a\u0430, \u043d\u0430 \u043f\u0435\u0440\u0432\u044b\u0439 \u0432\u0437\u0433\u043b\u044f\u0434 \u043c\u043e\u0436\u043d\u043e \u0443\u0432\u0438\u0434\u0435\u0442\u044c \u044f\u0432\u043d\u044b\u0435 \u043e\u0442\u043b\u0438\u0447\u0438\u044f. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u043e \u043f\u043e\u0436\u0430\u0440\u0430\u0445 (fire), \u0430 \u0442\u0430\u043a\u0436\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u0441 \u043f\u0440\u0438\u0441\u0442\u0430\u0432\u043a\u043e\u0439 New \u0438 \u0442\u0430\u043a\u0438\u0435 \u0431\u0435\u0434\u0441\u0442\u0432\u0438\u044f \u043a\u0430\u043a flood (\u043d\u0430\u0432\u043e\u0434\u043d\u0435\u043d\u0438\u044f) \u0438 storm (\u0448\u0442\u043e\u0440\u043c), \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u043e \u0441\u043c\u0435\u0440\u0442\u0438 (death) \u0447\u0430\u0449\u0435 \u043d\u043e\u0441\u044f\u0442 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0439 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440 (\u044d\u0442\u0438 \u0441\u043b\u043e\u0432\u0430 \u0440\u0435\u0436\u0435 \u0443\u043f\u043e\u0442\u0440\u0435\u0431\u043b\u044f\u044e\u0442\u0441\u044f \u0432 \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u043d\u043e\u043c \u0441\u043c\u044b\u0441\u043b\u0435), \u0442\u043e\u0433\u0434\u0430 \u043a\u0430\u043a \u0442\u0432\u0438\u0442\u044b \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0435 \u0442\u0430\u043a\u0438\u0435 \u0441\u043b\u043e\u0432\u0430 \u043a\u0430\u043a https, Love, \u043e\u0431\u043e\u0440\u043e\u0442 will (\u043e\u0431\u043e\u0437\u043d\u0430\u0447\u0430\u044e\u0449\u0438\u0439, \u0447\u0442\u043e \u0447\u0442\u043e-\u0442\u043e \u043f\u0440\u043e\u0438\u0437\u043e\u0439\u0434\u0451\u0442 \u0432 \u0431\u0443\u0434\u0443\u0449\u0435\u043c) \u0447\u0430\u0449\u0435 \u0438\u043c\u0435\u044e\u0442 \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u043d\u044b\u0439 (\u0432 \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\u0435 \u043d\u0430\u0448\u0435\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430 - \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0439) \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440 \u0438 \u043d\u0435 \u0438\u043c\u0435\u044e\u0442 \u043f\u043e\u0434 \u0441\u043e\u0431\u043e\u0439 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0439.\n","25fcef9c":"\u0432 \u043e\u0447\u0438\u0449\u0435\u043d\u043d\u043e\u0439 \u0431\u0430\u0437\u0435 latlong_cleaned \u0434\u0443\u0431\u043b\u0435\u0439 \u0431\u043e\u043b\u044c\u0448\u0435 \u043d\u0435\u0442 - \u043c\u044b \u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u0433\u043e\u0440\u043e\u0434\u0430 \u0441 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u043d\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u0435\u043c","850c2b20":"# 1. \u041f\u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0437\u0430\u0434\u0430\u0447\u0438\n* **\u041a\u0430\u043a\u0430\u044f \u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f (\u0447\u0442\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c):** \u041f\u043e \u0442\u0435\u043a\u0441\u0442\u0443 \u0442\u0432\u0438\u0442\u0430 \u043e \u043a\u0430\u0442\u0430\u0441\u0442\u0440\u043e\u0444\u0435 \u0431\u0443\u0434\u0435\u043c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0442\u044c \u043e \u0440\u0435\u0430\u043b\u044c\u043d\u043e\u043c \u043b\u0438 \u0431\u0435\u0434\u0441\u0442\u0432\u0438\u0438 \u0438\u0434\u0451\u0442 \u0440\u0435\u0447\u044c (\"\u041d\u043e\u0432\u044b\u0435 \u043b\u0435\u0441\u043d\u044b\u0435 \u043f\u043e\u0436\u0430\u0440\u044b \u0432\u043e \u0424\u043b\u043e\u0440\u0438\u0434\u0435\") \u0438\u043b\u0438 \u0432 \u0442\u0435\u043a\u0441\u0442\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u043d\u044b\u0439 \u0441\u043c\u044b\u0441\u043b (\"\u043e\u043d \u0441\u0433\u043e\u0440\u0430\u0435\u0442 \u043e\u0442 \u043b\u044e\u0431\u0432\u0438\" \u0438 \u0442.\u043f.).\n* **\u0417\u0430\u0434\u0430\u0447\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0438\u043b\u0438 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 (\u0438\u043b\u0438 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0438\u0437\u0430\u0446\u0438\u0438, \u0438\u043b\u0438 \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0442\u0435\u043a\u0441\u0442\u0430 \u0438\u043b\u0438 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f \u043c\u0435\u0434\u0438\u0446\u0438\u043d\u0441\u043a\u0438\u0445 \u0441\u043d\u0438\u043c\u043a\u043e\u0432, ...)?** NLP \u0437\u0430\u0434\u0430\u0447\u0430 \u0431\u0438\u043d\u0430\u0440\u043d\u043e\u0439 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0442\u0435\u043a\u0441\u0442\u043e\u0432. \u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u043e\u0442\u0435\u0441\u0442\u0438\u0440\u0443\u0435\u043c \u0420\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044e \u0438 Pytorch\n* **\u041a\u0430\u043a\u0443\u044e \u043c\u0435\u0442\u0440\u0438\u043a\u0443(\u0438) \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430:** \u0414\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c F1, \u0430 \u0442\u0430\u043a\u0436\u0435 Precision, Recall","67196a7b":"\u0414\u043b\u044f \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u0447\u0438 \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 keyword (\u043a\u043b\u044e\u0447\u0435\u0432\u0430\u044f \u0444\u0440\u0430\u0437\u0430 \u0432 \u0432 \u0442\u0432\u0438\u0442\u0435, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0437\u0443\u0435\u0442 \u043f\u0440\u043e\u0438\u0441\u0448\u0435\u0441\u0442\u0432\u0438\u0435), location (\u0433\u0435\u043e\u0433\u0440\u0430\u0444\u0438\u0435\u0447\u0441\u043a\u043e\u0435 \u043c\u0435\u0441\u0442\u043e, \u0433\u0434\u0435 \u043c\u043e\u0433\u043b\u043e \u043f\u0440\u043e\u0438\u0437\u043e\u0439\u0442\u0438 \u043f\u0440\u043e\u0438\u0441\u0448\u0435\u0441\u0442\u0432\u0438\u0435) \u0438 text (\u0442\u0435\u043a\u0441\u0442 \u0442\u0432\u0438\u0442\u0430)","f99649ab":"\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432, \u0434\u043b\u044f\u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b = 504","7d610550":"### \u0421\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","272795fd":"# 4.3. \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0442\u0435\u043a\u0441\u0442\u0430 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f","b8419bb5":"### \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0442\u0435\u043a\u0441\u0442 \u0432 \u0431\u043e\u043b\u0435\u0435 \u0443\u0434\u043e\u0431\u043d\u044b\u0439 \u0432\u0438\u0434 (\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u0435\u043c URL, \u0445\u044d\u0448\u0442\u0435\u0433\u0438 \u0438 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 \u0432 \u0442\u0435\u043a\u0441\u0442\u0435)","1068c4f5":"\u0424\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0443 \u043d\u0430\u0441 \u0431\u043e\u043b\u044c\u0448\u0435 - 4342, \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u043c\u0435\u043d\u044c\u0448\u0435 - 3271.\n\u0414\u043b\u044f \u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430\u043c \u043d\u0430\u0434\u043e \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0430\u0442\u044c \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0435 \u0442\u0432\u0438\u0442\u044b \u0438 \u043e\u0431\u0440\u0435\u0437\u0430\u0442\u044c \u043d\u0430 \u043b\u0438\u0448\u043d\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e (\u043d\u0430 1071 \u0448\u0442\u0443\u043a).\n\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043b\u0438\u0448\u043d\u0438\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0431\u0443\u0434\u0435\u043c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u043a\u0430\u043a \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u043c\u0438\u043d\u0443\u0441 \u043a\u043e\u043b\u0438\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432, \u0442.\u0435.:\n> 4342 - 3271 = 1071","268d646b":"\u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0434\u0443\u0431\u043b\u0435\u0439 \u043b\u043e\u043a\u0430\u0446\u0438\u0439 \u0432 \u0431\u0430\u0437\u0435 \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438","fb71ec2a":"# \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u0443\u0435\u043c \u0442\u0430\u0440\u0433\u0435\u0442 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438","fa3a94df":"# 4.1. \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445","77b5e04d":"\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c Stemming (\u043f\u043e\u0438\u0441\u043a \u043e\u0441\u043d\u043e\u0432\u044b \u0441\u043b\u043e\u0432\u0430) Lemmatization (\u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u043a \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0439 \u0444\u043e\u0440\u043c\u0435: \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u043a \u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u043c\u0443 \u0447\u0438\u0441\u043b\u0443, \u043c\u0443\u0436\u0441\u043a\u043e\u043c\u0443 \u0440\u043e\u0434\u0443, \u0433\u043b\u0430\u0433\u043e\u043b\u043e\u0432 \u043a \u0438\u043d\u0444\u0438\u043d\u0438\u0442\u0438\u0432\u0443 \u0438 \u0442.\u043f) \u0434\u043b\u044f \u0441\u043e\u043a\u0440\u0430\u0449\u0435\u043d\u0438\u044f \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0441\u043b\u043e\u0432\u043e\u0444\u043e\u0440\u043c: am, are, is -> be; car, cars, car's, cars' -> car etc. https:\/\/ru.wikipedia.org\/wiki\/\u0421\u0442\u0435\u043c\u043c\u0438\u043d\u0433 https:\/\/ru.wikipedia.org\/wiki\/\u041b\u0435\u043c\u043c\u0430\u0442\u0438\u0437\u0430\u0446\u0438\u044f","c425eb68":"\u0421\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u044f 2 \u043a\u0430\u0440\u0442\u044b (\u0434\u043b\u044f \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438\u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u043e \u043f\u0440\u043e\u0438\u0441\u0448\u0435\u0441\u0442\u0432\u0438\u044f\u0445) \u043c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u043a\u0430\u0440\u0434\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u0440\u0430\u0437\u043b\u0438\u0447\u0438\u0439 \u0432 \u0433\u0435\u043e\u0433\u0440\u0430\u0444\u0438\u0438 \u0442\u0432\u0438\u0442\u043e\u0432 \u043d\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f, \u043f\u043e \u043a\u0440\u0430\u0439\u043d\u0435\u0439 \u043c\u0435\u0440\u0435 \u0432\u0438\u0437\u0443\u0430\u043b\u044c\u043d\u043e \u043d\u0435\u043b\u044c\u0437\u044f \u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u0447\u0442\u043e \u0432 \u043a\u0430\u043a\u0438\u0445-\u0442\u043e \u0433\u0435\u043e\u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0440\u0435\u0433\u0438\u043e\u043d\u0430\u0445 \u0431\u043e\u043b\u044c\u0448\u0435 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0438\u043b\u0438 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 (\u043c\u044b \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u043b\u0438 \u0442\u0432\u0438\u0442\u044b \u0433\u0435\u043e\u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u0438 \u043d\u0430 \u043a\u0430\u0440\u0442\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e heatmap, \u0447\u0442\u043e \u0431\u044b \u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434\u044b \u043f\u043e \u0431\u043e\u043b\u0435\u0435-\u043c\u0435\u043d\u0435\u0435 \u0440\u0435\u043f\u0440\u0435\u0437\u0435\u043d\u0442\u0430\u0442\u0438\u0432\u043d\u044b\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0430\u043c, \u0442.\u043a. \u043f\u043e \u043a\u0430\u0436\u0434\u043e\u043c\u0443 \u0433\u043e\u0440\u043e\u0434\u0443 \u0432 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0434\u043b\u044f \u0440\u0435\u043f\u0440\u0435\u0437\u0435\u043d\u0442\u0430\u0442\u0438\u0432\u043d\u044b\u0445 \u0432\u044b\u0432\u043e\u0434\u043e\u0432 (\u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c 40-50 \u0442\u0432\u0438\u0442\u043e\u0432 \u043d\u0430 \u0433\u043e\u0440\u043e\u0434)).","a48e5ced":"### \u0417\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043f\u0440\u043e\u043f\u0443c\u043a\u0438","8af8389a":"## \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0441\u0442\u044c","f43a51d9":"**\u041a\u0430\u0440\u0442\u0430 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432**","a3d67780":"### \u041e\u0431\u043b\u0430\u043a\u043e \u0447\u0430\u0441\u0442\u043e \u0443\u043f\u043e\u0442\u0440\u0435\u0431\u043b\u044f\u0435\u043c\u044b\u0445 \u0441\u043b\u043e\u0432 \u0434\u043b\u044f \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432[](http:\/\/)","f69fabf3":"\u0412\u0441\u0435\u0433\u043e \u043d\u0430\u043c \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b \u0434\u043b\u044f 895 \u043b\u043e\u043a\u0430\u0446\u0438\u0439.\n\u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043a\u0430\u0440\u0442\u044b \u043d\u0430 \u0431\u0430\u0437\u0435\u044d\u0442\u0438\u0445 \u043b\u043e\u043a\u0430\u0446\u0438\u0439.","6007874b":"## \u0410\u043d\u0430\u043b\u0438\u0437 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0435\u0439 \u043c\u0435\u0436\u0434\u0443 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438 \u0438 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439","2239c6ed":"### TFIDF","4d8810f1":"### \u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438 \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432 \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0433\u0435\u043e\u0433\u0440\u0430\u0444\u0438\u0438","2560eba6":"\u0418\u0442\u043e\u0433\u043e \u0443 \u043d\u0430\u0441 391 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0439 \u0442\u0432\u0438\u0442 \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438","d845dbc6":"\u041e\u0431\u043b\u0430\u043a\u043e \u0441\u043b\u043e\u0432 \u0434\u043b\u044f \u0444\u0435\u0439\u043a\u043e\u0432\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432","f55a9156":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0441\u0442\u043e\u043f-\u0441\u043b\u043e\u0432 (\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u0432\u043b\u0438\u044f\u044e\u0442 \u043d\u0430 \u0430\u043d\u0430\u043b\u0438\u0437, \u0442\u0430\u043a\u0438\u0435 \u043a\u0430\u043a he, have, it, the \u0438 \u0442.\u043f.), \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043a \u0441\u0442\u043e\u043f-\u0441\u043b\u043e\u0432\u0430\u043c \u043f\u0443\u043d\u043a\u0442\u0443\u0430\u0446\u0438\u044e","9cdd64df":"\u041e\u0431\u043b\u043e\u043a\u043e \u0441\u043b\u043e\u0432 \u0434\u043b\u044f \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0432\u0438\u0442\u043e\u0432","b09a4bcc":"\u0432\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u043b\u043e\u0432\u0430 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0434\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c, \u0442.\u043a. \u043e\u043d\u0438 \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 urlencoded (%20, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043e\u0437\u043d\u0430\u0447\u0430\u0435\u0442 \u043f\u0440\u043e\u0431\u0435\u043b)"}}