{"cell_type":{"df35b8bf":"code","a7dd65b8":"code","8a0f500c":"code","1a1696f4":"code","b1f73403":"code","0714c29f":"code","ce3ec8a2":"code","e1956ce5":"code","5dfaef60":"code","b3faed4b":"code","49925625":"code","e5eba501":"code","0d6f7694":"code","1be94e2a":"code","fea3dda9":"code","99cb2795":"code","159586e7":"code","ebd80b4a":"code","c6c423d6":"code","51fa1d22":"code","e75c0abb":"code","1a8f6229":"code","1c191841":"code","74565b44":"code","91229ebb":"code","08befddb":"code","7d858f4f":"code","345dfe79":"code","2241fb84":"code","1fe91a8c":"code","607e8016":"code","65de929b":"code","5cc62827":"code","bde39f06":"code","b3fe9a8c":"code","6e1dd6ae":"code","c6b745c3":"code","9acacc66":"code","4ff365e3":"code","2e7b06b7":"code","3bcf16e0":"code","af944bbf":"markdown","90e85d95":"markdown","b7892be8":"markdown","15d455c2":"markdown","7fa956d4":"markdown","3065463b":"markdown","6821a049":"markdown","214b2e71":"markdown","1c32c980":"markdown","faec765b":"markdown"},"source":{"df35b8bf":"# 1. Regular Exploratory Data Analysis (EDA) Tools and Plotting Library  \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport sklearn\n\n%matplotlib inline\nplt.style.use(\"seaborn-whitegrid\")","a7dd65b8":"# importing data\ndf = pd.read_csv(\"..\/input\/bluebook-for-bulldozers\/TrainAndValid.csv\", \n                 low_memory= False, \n                 parse_dates= [\"saledate\"]) # low_memory = False it helps to allocate RAM\ndf.info()","8a0f500c":"df.isna().sum()","1a1696f4":"fig, ax = plt.subplots(figsize = (10,6))\nax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])","b1f73403":"df.sort_values(by=[\"saledate\"], inplace= True, ascending=True)\ndf.head()","0714c29f":"df_tmp = df.copy()","ce3ec8a2":"df_tmp[\"saleYear\"] = df_tmp.saledate.dt.year\ndf_tmp[\"saleMonth\"] = df_tmp.saledate.dt.month\ndf_tmp[\"saleDay\"] = df_tmp.saledate.dt.day\ndf_tmp[\"saleDayofWeek\"] = df_tmp.saledate.dt.dayofweek\ndf_tmp['saleDayofYear'] = df_tmp.saledate.dt.dayofyear","e1956ce5":"df_tmp.T","5dfaef60":"# we dont need saledate column anymore\ndf_tmp.drop([\"saledate\"], axis = 1, inplace = True)","b3faed4b":"df_tmp.head()","49925625":"# trying to get more info about data \npd.crosstab(df_tmp.saleYear, df_tmp.state)","e5eba501":"# Converting all string type data to category type\nfor label, content in df_tmp.items():\n  if pd.api.types.is_string_dtype(content):\n    df_tmp[label] = content.astype('category').cat.as_ordered()","0d6f7694":"df_tmp.info()","1be94e2a":"# checking the missing data ratio\ndf_tmp.isna().sum()\/len(df_tmp)","fea3dda9":"# Filling Numeric values \nfor label, content in df_tmp.items():\n  if pd.api.types.is_numeric_dtype(content):\n    if pd.isna(content).sum():\n      df_tmp[label + \"_is_missing\"] = pd.isna(content)\n      df_tmp[label] = content.fillna(content.median())","99cb2795":"# Filling Category Values\nfor label, content in df_tmp.items():\n  if not pd.api.types.is_numeric_dtype(content):\n      df_tmp[label + \"_is_missing\"] = pd.isna(content)\n      # adding + 1 to categorical values as empty values it reflect as -1\n      df_tmp[label] = pd.Categorical(content).codes + 1 ","159586e7":"df_tmp.isna().sum()","ebd80b4a":"df_tmp","c6c423d6":"np.random.seed(42)\n# Data before 2012 is traning data and data of 2012 is validation data\ndf_val = df_tmp[df_tmp.saleYear == 2012]\ndf_train = df_tmp[df_tmp.saleYear != 2012]\n\n# #Splitting into X and y\nX_train, y_train = df_train.drop(\"SalePrice\", axis = 1), df_train['SalePrice']\nX_valid, y_valid = df_val.drop(\"SalePrice\", axis = 1), df_val['SalePrice']\n\nlen(X_train), len(y_train), len(X_valid), len(y_valid)","51fa1d22":"np.random.seed(42)\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_jobs= -1)\n\n#Fitting Traning Data:\nmodel.fit(X_train, y_train)","e75c0abb":"model.score(X_valid, y_valid)","1a8f6229":"from sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n\n# Function for Root Mean Square log Error \ndef rmsle(y_test, y_preds):\n  \"\"\"\n  Calcualte Root Mean Square log Error between predictions and true labels\n  \"\"\"\n  return np.sqrt(mean_squared_log_error(y_test, y_preds))\n\n# Function to evaluate model on few different metrics \ndef model_scores(model):\n  train_preds = model.predict(X_train)\n  valid_preds = model.predict(X_valid)\n  scores = {\"Traning MAE\" : mean_absolute_error(y_train, train_preds),\n           \"Valid MAE\" : mean_absolute_error(y_valid, valid_preds),\n           \"Traning RMSLE\" : rmsle(y_train, train_preds),\n           \"Valid RMSLE\" : rmsle(y_valid, valid_preds),\n           \"Traning R^2 \" : r2_score(y_train, train_preds),\n           \"Valid R^2\" : r2_score(y_valid, valid_preds)}\n  return scores","1c191841":"# Changing max sample value to reduce output time\n%%time\nnp.random.seed(42)\nmodel = RandomForestRegressor(n_jobs= -1, random_state= 42, max_samples= 10000)\n\n\nmodel.fit(X_train, y_train)","74565b44":"%%time\nmodel_scores(model)","91229ebb":"%%time\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Making a grid of hyperperameters\nrf_grid = {\"n_estimators\" : np.arange(10,100,10),\n           \"max_depth\" : [None, 3, 5, 10],\n           \"min_samples_split\" : np.arange(2, 20, 2),\n           \"min_samples_leaf\" : np.arange(1,20,2),\n           \"max_features\" : [0.5, 1, \"sqrt\", \"auto\"],\n           \"max_samples\" : [10000]}\n\nrs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs= -1, random_state= 42),\n                              param_distributions = rf_grid, \n                              n_iter = 2,\n                              cv = 5,\n                              verbose = True)\n\nrs_model.fit(X_train, y_train)","08befddb":"# getting best parameters :\nrs_model.best_params_","7d858f4f":"# evaluating score \nmodel_scores(rs_model)","345dfe79":"%time \n# Updating Hyperparameters\n\nideal_model = RandomForestRegressor(n_estimators=40,\n                                    min_samples_leaf = 1,\n                                    min_samples_split = 14,\n                                    max_features = 0.5,\n                                    n_jobs = -1,\n                                    max_samples = None, \n                                    random_state = 42)","2241fb84":"%%time\n# Fitting Data to our ideal model \nideal_model.fit(X_train, y_train)","1fe91a8c":"# Model Score \nmodel_scores(ideal_model)","607e8016":"df_test = pd.read_csv(\"..\/input\/bluebook-for-bulldozers\/Test.csv\",\n                      low_memory = False, \n                      parse_dates = [\"saledate\"])\ndf_test.head()","65de929b":"# Preprocessing Test Data \ndef preprocess_data(df_test):\n  \"\"\"\n  Preprocessing Data and tranforming it to match our train and valid data formate\n  \"\"\"\n  df_test[\"saleYear\"] = df.saledate.dt.year\n  df_test[\"saleMonth\"] = df.saledate.dt.month\n  df_test[\"saleDay\"] = df.saledate.dt.day\n  df_test[\"saleDayofWeek\"] = df.saledate.dt.dayofweek\n  df_test[\"saleDayofYear\"] = df.saledate.dt.dayofyear\n\n  df_test.drop(\"saledate\", axis = 1, inplace = True)\n\n  # Filling Numeric rows with median \n  for label, content in df_test.items():\n    if pd.api.types.is_numeric_dtype(content):\n      if pd.isna(content).sum():\n        df_test[label + \"_is_missing\"] = pd.isna(content)\n        df_test[label] = content.fillna(content.median())\n  # Filling category missing data and turning them into numbers\n    if not pd.api.types.is_numeric_dtype(content):\n        df_test[label + \"_is_missing\"] = pd.isna(content)\n        df_test[label] = pd.Categorical(content).codes + 1\n  return df_test","5cc62827":"df_test_processed = preprocess_data(df_test)\ndf_test_processed","bde39f06":"# Using set() we can check if columns are different :\nset(X_train.columns) - set(df_test_processed.columns)","b3fe9a8c":"# Adding \" auctioneerID_is_missing\" Column \ndf_test_processed[\"auctioneerID_is_missing\"] = False\ndf_test_processed.head()","6e1dd6ae":"# Making Predictions using precessed test data\ntest_preds = ideal_model.predict(df_test_processed)\ntest_preds","c6b745c3":"# Formating Predictions into a dataframe\ndf_preds =pd.DataFrame()\ndf_preds[\"SalesID\"] = df_test_processed['SalesID']\ndf_preds[\"SalesPrice\"] = test_preds\ndf_preds","9acacc66":"ideal_model.feature_importances_","4ff365e3":"# Function for plotting feature importance\ndef plot_features(columns, importances, n=20):\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importances\": importances})\n          .sort_values(\"feature_importances\", ascending=False)\n          .reset_index(drop=True))\n    \n    # Plot the dataframe\n    fig, ax = plt.subplots()\n    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature importance\")\n    ax.invert_yaxis()","2e7b06b7":"features_barh = plot_features(X_train.columns, ideal_model.feature_importances_)","3bcf16e0":"df[\"Enclosure\"].value_counts()","af944bbf":"#### Hyperparameter Tuning\n- RandomizedSearchCV","90e85d95":"#### Feature Engineering :","b7892be8":"#### Traning a model with best hyperparameters\nNote : These parameters are found after 100 iterations of RandomizedSearchCV","15d455c2":"#### Importing Test data CSV","7fa956d4":"#### Splitting Data :","3065463b":"#### Filling Missing Value","6821a049":"Predicting Sale Price of Bulldozers :\n1. Problem Defination \n    - How well we can predict the future sale price of bulldozers\n    - Prediction on basis of given characteristics \n    - Sale price of simillar bulldozers\n\n2. Data https:\/\/www.kaggle.com\/c\/bluebook-for-bulldozers\/data\n    - Data is downloaded from Kaggle Blue Book for Bulldozers Competition :\n    - Train.csv is the training set, which contains data through the end of 2011.\n    - Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You  makepredictions on this set throughout the majority of the competition. Your score on this set is used to create   the public leaderboard.\n    - Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n\n3. Evaluation https:\/\/www.kaggle.com\/c\/bluebook-for-bulldozers\/overview\/evaluation\n    - The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n\n4. Features (Data)\n    - kaggle provide a data dictionary detailing of all the features of the data set\n    - https:\/\/www.kaggle.com\/c\/bluebook-for-bulldozers\/data?select=Data+Dictionary.xlsx","214b2e71":"# Feature Importance :\n- To Figure out which features from the data are most important in predicting SalePrice","1c32c980":"#### Evaluation \n- We will be using Root Mean Square Log Error ","faec765b":"#### Modelling :"}}