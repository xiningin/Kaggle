{"cell_type":{"7c571dfe":"code","6c82186d":"code","d32bd0ea":"code","c5cf8417":"code","5edd6022":"code","da221c69":"code","8191e81a":"code","697d16c3":"code","55bdffc4":"code","790827a4":"code","e63dccf8":"code","27f36c01":"code","6d61d8f9":"code","d741f788":"code","52e95f7b":"code","19564cd8":"code","0fca8232":"code","581f3f93":"code","105159ec":"code","9d511f2f":"code","0b095c3f":"code","a9464563":"code","2067abd3":"code","79746b5d":"code","1643efa3":"code","d0f1c3e5":"code","37b4d993":"code","67ffb8f7":"markdown","3e590657":"markdown","f03ece63":"markdown","9f621ce1":"markdown","2ac60338":"markdown","72de1250":"markdown","ad9bd9ff":"markdown","d1a0aec7":"markdown","ce69d587":"markdown"},"source":{"7c571dfe":"import pandas as pd \nfrom sklearn.feature_selection import RFECV\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nimport tensorflow as tf\n\nimport warnings\nimport matplotlib.gridspec as gridspec\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nwarnings.filterwarnings(\"ignore\")\nfrom scipy import stats\nfrom scipy.stats import shapiro\nfrom scipy.stats import anderson\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import mannwhitneyu\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.decomposition import PCA\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import ClusterCentroids\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn import preprocessing\nfrom sklearn.manifold import TSNE\nfrom mpl_toolkits.mplot3d import Axes3D\n","6c82186d":"import keras\nfrom keras.datasets import imdb\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM, BatchNormalization\nfrom keras.layers.wrappers import Bidirectional # new! \nfrom keras.callbacks import ModelCheckpoint \n\nimport os\nfrom sklearn.metrics import roc_auc_score \nimport matplotlib.pyplot as plt \n%matplotlib inline","d32bd0ea":"data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\nprint(data.head())\nprint(data['Class'].value_counts())\nprint(data.columns)","c5cf8417":"X = data[['V27', 'V4', 'V10', 'V14', 'V28', 'V20', 'V21', 'V16', 'V13', 'V24']]\ny = data['Class']","5edd6022":"X.head()","da221c69":"X= data[['V27', 'V4', 'V10', 'V14', 'V28', 'V20', 'V21', 'V16', 'V13', 'V24']]\nX = X.loc[:,:].apply(lambda x: round(x,2))\nmm_scaler = preprocessing.StandardScaler()\nX.columns\nX[['V27', 'V4', 'V10', 'V14', 'V28', 'V20', 'V21', 'V16', 'V13', 'V24']] = mm_scaler.fit_transform(X[['V27', 'V4', 'V10', 'V14', 'V28', 'V20', 'V21', 'V16', 'V13', 'V24']])\n","8191e81a":"X.head()","697d16c3":"def logist_regression(X_sampling, y_sampling, sampling_type,XR_test, yR_test):\n   \n   #### logistic regression part and grid search \n   lr7 = LogisticRegression()\n   penalty = ['l1', 'l2']\n   C = [0.001,0.01,0.1,1,10,100]\n   hyperparameters = dict(C=C, penalty=penalty)\n   gridsearch = GridSearchCV(lr7, hyperparameters, cv=3, verbose=1)\n   best_model_gs = gridsearch.fit(X_sampling, y_sampling)\n   predictions7 = best_model_gs.predict(XR_test)\n\n   #### printing the right metrics\n   print(metrics.classification_report(yR_test,predictions7))\n   print(metrics.confusion_matrix(yR_test,predictions7))\n    \n    \n   #### plotting the sampling distribution\n   datafra = pd.DataFrame(data=y_sampling, index=range(len(y_sampling)), columns=['Class'])\n   datafra.Class.value_counts().index \n   #fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=False, sharey=False,figsize=[12,12])\n   fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3, sharex=False, sharey=False,figsize=[12,4])\n   sns.barplot(x=datafra.Class.value_counts().index, y=datafra.Class.value_counts(), data=datafra, ax = ax1)\n   \n   ####plotting the heatmap for confusion matrix\n   metric = metrics.confusion_matrix(yR_test,predictions7)\n   confusion_dataframe = pd.DataFrame(data=metric, index=['Actual_Negative', 'Actual_Positive'], columns=['Guessed_Negative', 'Guessed_Positive',])\n   #confusion_dataframe\n   sns.heatmap(confusion_dataframe, annot=True, fmt=\"d\", cmap=\"YlGnBu\", ax = ax2)\n   \n    \n   #### plotting the ROC and AUC curve\n   fpr, tpr, _ = (metrics.roc_curve(yR_test,predictions7))\n   ax3.plot(fpr, tpr)\n   roc_auc = auc(fpr, tpr)\n   ax3.plot([0, 1], [0, 1], 'k--', label='AUC = %0.3f'% roc_auc)\n   ax3.legend(loc='lower right')\n   ax3.plot([0,1],[0,1],'r--')\n   ax3.set_xlim([-0.1,1.0])\n   ax3.set_ylim([-0.1,1.01])\n   ax3.set_ylabel('True Positive Rate')\n   ax3.set_xlabel('False Positive Rate')\n   plt.tight_layout()\n   plt.show()\n   print(f'Area Under the Curve: {round(roc_auc,2)}')","55bdffc4":"XN_train, XN_test, yN_train, yN_test = train_test_split(X, y, test_size=0.33, random_state=42)","790827a4":"rus = RandomUnderSampler(random_state=0) \nrus.fit(XN_train, yN_train) \nX_smn, y_smn = rus.fit_resample(XN_train, yN_train)\nlogist_regression(X_smn, y_smn, \"RANDOM UNDER-sampling\",XN_test, yN_test)","e63dccf8":"pca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(X)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal_component_1', 'principal_component_2'])\nprint(pca.get_params())\nprint(principalComponents.shape)","27f36c01":"finalDf = pd.concat([principalDf, data['Class']], axis = 1)\nprint(finalDf.head())\nprint(pca.explained_variance_ratio_)\nfeatures = finalDf.columns\nfeatures = finalDf.columns","6d61d8f9":"X_pca= finalDf[features].drop('Class',axis=1)\ny_pca = finalDf['Class']\nXP_train, XP_test, yP_train, yP_test = train_test_split(X_pca, y_pca, test_size=0.33, random_state=42)\n","d741f788":"rus = RandomUnderSampler(random_state=0)\nrus.fit(XP_train, yP_train)\nX_pca, y_pca = rus.fit_resample(XP_train, yP_train)\nprint(len(X_pca))\nlogist_regression(X_pca, y_pca, \"RANDOM UNDER-sampling\",XP_test, yP_test)","52e95f7b":"XN_train, XN_test, yN_train, yN_test = train_test_split(X_smn, y_smn, test_size=0.20, random_state=42)","19564cd8":"input_train = XN_train\ntarget_train = yN_train\nyN_test= yN_test\nXN_test= XN_test\ntarget_train\nprint(f'Shape of Input Training Data {input_train.shape} ')\nprint(f'Shape of Target Training Data {target_train.shape} ')","0fca8232":"from tensorflow.keras.callbacks import EarlyStopping","581f3f93":"def ANN(x_train, x_test, y_train, y_test):\n  model = Sequential()\n  model.add(Dense(256, activation='relu', kernel_initializer='glorot_uniform', input_shape=(10,)))\n  model.add(Dropout(0.2))\n  model.add(Dense(128,kernel_initializer='glorot_uniform', activation='relu'))\n  model.add(Dropout(0.2))\n  \n  model.add(Dense(128,kernel_initializer='glorot_normal', activation='relu'))\n  model.add(Dense(64,kernel_initializer='glorot_uniform', activation='relu'))\n  model.add(Dense(32,kernel_initializer='glorot_uniform', activation='relu'))\n  model.add(BatchNormalization())\n  model.add(Dense(1, activation='sigmoid'))\n  \n  rms = keras.optimizers.RMSprop(lr=0.0005, rho=0.9)\n  model.compile(loss='binary_crossentropy', optimizer=rms, metrics=['accuracy'])\n\n  model.summary()\n  #checkpoint_name = '..\/input\/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n  #checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=True,  save_best_only = True, mode ='auto')\n  #callbacks_list = [checkpoint]\n\n\n  early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n  model.fit(x_train, y_train, \n          batch_size=64, epochs=100, verbose=1, \n          validation_data=(x_test, y_test), callbacks=[early_stop])\n  \n  return model\n","105159ec":"Model1 = ANN(input_train, XN_test, target_train, yN_test)","9d511f2f":"np.bincount(yN_train)","0b095c3f":"from sklearn.metrics import classification_report,confusion_matrix\npredictions = Model1.predict_classes(XN_test)","a9464563":"predictions= predictions.reshape(-1,)\npredictions","2067abd3":"def model_performance(target, predictions):\n  fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3, sharex=False, sharey=False,figsize=[16,4])\n  ax1.bar(x=target.value_counts().index.astype(str), height=target.value_counts().to_list(), data=target, color=['b','r'])\n  metric = metrics.confusion_matrix(target,predictions)\n  confusion_dataframe = pd.DataFrame(data=metric, index=['Actual_Negative', 'Actual_Positive'], columns=['Guessed_Negative', 'Guessed_Positive'])\n  sns.heatmap(confusion_dataframe, annot=True, fmt=\"d\", cmap=\"YlGnBu\", ax = ax2)\n  fpr, tpr, _ = (metrics.roc_curve(target,predictions))\n  plt.plot(fpr, tpr)\n  fpr, tpr, _ = (metrics.roc_curve(target,predictions))\n  ax3.plot(fpr, tpr)\n  roc_auc = auc(fpr, tpr)\n  ax3.plot([0, 1], [0, 1], 'k--', label='AUC = %0.3f'% roc_auc)\n  ax3.legend(loc='lower right')\n  ax3.plot([0,1],[0,1],'r--')\n  ax3.set_xlim([-0.1,1.0])\n  ax3.set_ylim([-0.1,1.01])\n  ax3.set_ylabel('True Positive Rate')\n  ax3.set_xlabel('False Positive Rate')\n  plt.tight_layout()\n  print(f'Area Under the Curve: {round(roc_auc,2)}')\n  plt.show()","79746b5d":"model_performance(pd.Series(yN_test), pd.Series(predictions))\nprint(metrics.classification_report(yN_test,predictions))","1643efa3":"new_data = pd.concat([data[X.columns], data['Class']], axis=1)\nnew_data= new_data[new_data['Class']==1]\nx_new_data = new_data.iloc[:,:-1].values\ny_new_data = new_data.iloc[:,-1].values\npredictions = Model1.predict_classes(x_new_data)\nprint(predictions.shape)\npredictions = predictions.reshape(-1,)\npredictions.shape","d0f1c3e5":"np.bincount(predictions)\npredictions","37b4d993":"model_performance(pd.Series(y_new_data), pd.Series(predictions))\nprint(metrics.classification_report(y_new_data,predictions))","67ffb8f7":"**MODELING USING KERAS AND ANN**\n\n","3e590657":"SAMPLING","f03ece63":"EFFECT OF PCA ON MODEL PERFORMANCE","9f621ce1":"MODELING","2ac60338":"Model performed really well especially in low False Negative, So only 13 transactions out of 492 Fraud transaction will not be captured by this model.\n\n\n\n\n\n\n","72de1250":"LOGISTIC REGRESSION USING PCA COMPONENTS","ad9bd9ff":"READING IN THE DATA AND PROCESSING IT","d1a0aec7":"SCALING THE DATA USING THE StandardScaler","ce69d587":"USING THE SUBSET OF COLUMNS BASED ON THE CORRELATION MATRIX"}}