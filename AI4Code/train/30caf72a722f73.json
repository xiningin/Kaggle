{"cell_type":{"ece18b0b":"code","d02573a4":"code","9e8c2a28":"code","c66d3ce9":"code","586eb7db":"code","4501c676":"code","9abe0992":"code","61c5a3a4":"code","63e13a48":"code","182f037a":"code","5ad72240":"markdown","eb43fdea":"markdown","81807c44":"markdown","e382d428":"markdown","ac0438cc":"markdown","66840b09":"markdown","d8927aa8":"markdown","5076cd25":"markdown","7eabbfd5":"markdown","251c95b2":"markdown","e5746d07":"markdown","ff2aad4b":"markdown"},"source":{"ece18b0b":"# Importing Libraries\n\nfrom imageio import imread\nfrom PIL import Image\nimport imageio\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport numpy as np\n\nfrom PIL import Image, ImageEnhance\n%matplotlib inline \n\nimport cv2 # for openCV","d02573a4":"image1 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000002.jpg', 0)\nimage2 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000015.jpg', 0)\nimage3 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000017.jpg', 0)\nimage4 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000024.jpg', 0)\nimage5 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000046.jpg', 0)\nimage6 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000052.jpg', 0)\nimage7 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000003.jpg', 0)\nimage8 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000063.jpg', 0)\nimage9 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000067.jpg', 0)\nimage10 = cv2.imread('..\/input\/crowd-counting\/frames\/frames\/seq_000092.jpg', 0)","9e8c2a28":"def preview(image_set, titles, figsize): # This is fucntion to preview all images before processing\n    \n    for p in range(len(image_samples)):\n        plt.figure(figsize = (figsize,figsize)) \n        plt.subplot(5,2,p+1)\n        plt.imshow(image_samples[p],'gray')\n        plt.title(titles[p])\n        plt.xticks([]),plt.yticks([])\n\ndef crop(image, start_y, end_y, start_x, end_x): # To crop the image\n       \n    img_cropped = image[start_y:end_y, start_x:end_x]\n    \n    return img_cropped\n\ndef resize(image, width, height): # To resize the image\n\n    img_resized = cv2.resize(image,(width,height))\n\n    return img_resized\n\ndef gamma_correction(image, y): # To control the overall brightness of an image\n    \n    gamma_correct = np.array(255 * (image \/ 255) ** y , dtype='uint8')\n    \n    return gamma_correct\n\ndef threshold(image): # For object segmenting, this changes the pixels to make the image easier to analyze\n    \n    thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 255, 19)\n    thresh = cv2.bitwise_not(thresh)\n\n    return thresh\n\ndef dilation_erosion(image): # Adding and removing pixels in the image to smoothen out the shape\n    \n    kernel = np.ones((15,15), np.uint8)\n    img_dilation = cv2.dilate(image, kernel, iterations=1)\n    img_erode = cv2.erode(img_dilation,kernel, iterations=1)\n\n    # clean all noise after dilatation and erosion\n    img_erode = cv2.medianBlur(img_erode, 7)\n    \n    return img_erode\n\ndef labeling(image_set, titles): # Counts to total number of objects in an image segment\n    \n    for i in range(len(images)):\n        \n        ret, labels = cv2.connectedComponents(images[i])\n        label_hue = np.uint8(179 * labels \/ np.max(labels))\n        blank_ch = 255 * np.ones_like(label_hue)\n        labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n        labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n        labeled_img[label_hue == 0] = 0\n        \n        count = str(ret-1)\n\n        plt.title('People counted in ' + titles[i] + ': ' + count)\n        plt.imshow(images[i])\n        plt.show()\n        \n        count = int(count)\n        \n        if count < 5:\n            print(\"Population Density: LOW\")\n            print(\"Remarks: Low Risk of COVID-19 Transmission\")\n            print(\"\")\n        \n        elif count > 5 and count < 8:\n            print(\"Population Density: MODERATE\")\n            print(\"Remarks: Moderate Risk of COVID-19 Transmission\")\n            print(\"\")\n        \n        else:\n            print(\"Population Density: HIGH\")\n            print(\"Remarks: High Risk of COVID-19 Transmission\")\n            print(\"\")\n\ndef plotting(image_set, titles, rows, cols, figsize):\n    \n    for i in range(len(images)):\n        plt.figure( figsize = (figsize,figsize) )\n        plt.subplot(rows, cols, i+1)\n        \n        plt.imshow(images[i],'gray')\n        plt.title(titles[i])","c66d3ce9":"images = [image1, image2, image3, image4, image5, image6, image7, image8, image9, image10]\ntitles = ['Image 1', 'Image 2', 'Image 3', 'Image 4', 'Image 5', 'Image 6', 'Image 7', 'Image 8', 'Image 9', 'Image 10']\n\nplotting(images, titles, 5, 2, 18)\n\nprint(\"Image size for all images (height, width):\", (image1.shape))","586eb7db":"# Cropping segments from the 10 images\n\nprint(\"These will be the images we're going to process:\")\nprint(\"\")\n\ncropped_1 = crop(image1, 100, 380, 380, 600)\ncropped_2 = crop(image2, 30, 200, 350, 525)\ncropped_3 = crop(image3, 15, 160, 100, 275) \ncropped_4 = crop(image4, 30, 200, 390, 600) \ncropped_5 = crop(image5, 15, 350, 0, 320) \ncropped_6 = crop(image6, 15, 160, 100, 275)\ncropped_7 = crop(image7, 10, 600, 2, 350) \ncropped_8 = crop(image8, 30, 340, 400, 600) \ncropped_9 = crop(image9, 290, 490, 160, 330) \ncropped_10 = crop(image10, 20, 490, 240, 525) \n\nimages = [cropped_1, cropped_2, cropped_3, cropped_4, cropped_5, cropped_6, cropped_7, cropped_8, cropped_9, cropped_10]\ntitles = ['Cropped Image 1', 'Cropped Image 2', 'Cropped Image 3', 'Cropped Image 4', 'Cropped Image 5', 'Cropped Image 6', 'Cropped Image 7', 'Cropped Image 8', 'Cropped Image 9', 'Cropped Image 10']\n\nplotting(images, titles, len(images), 1, 40)\n\nfor s in range (len(images)):\n    print(titles[s], \"size (height, width): \", images[s].shape)\nprint(\"\")\n","4501c676":"# For image 1\n\nmultiplier = 2\n\nresized_1 = resize(cropped_1, (cropped_1.shape[1])*multiplier, (cropped_1.shape[0])*multiplier)\nresized_2 = resize(cropped_2, (cropped_2.shape[0])*multiplier, (cropped_2.shape[1])*multiplier)\nresized_3 = resize(cropped_3, (cropped_3.shape[1])*multiplier, (cropped_3.shape[0])*multiplier)\nresized_4 = resize(cropped_4, (cropped_4.shape[1])*multiplier, (cropped_4.shape[0])*multiplier)\nresized_5 = resize(cropped_5, (cropped_5.shape[1])*multiplier, (cropped_5.shape[0])*multiplier)\nresized_6 = resize(cropped_6, (cropped_6.shape[1])*multiplier, (cropped_6.shape[0])*multiplier)\nresized_7 = resize(cropped_7, (cropped_7.shape[1])*multiplier, (cropped_7.shape[0])*multiplier)\nresized_8 = resize(cropped_8, (cropped_8.shape[1])*multiplier, (cropped_8.shape[0])*multiplier)\nresized_9 = resize(cropped_9, (cropped_9.shape[1])*multiplier, (cropped_9.shape[0])*multiplier)\nresized_10 = resize(cropped_10, (cropped_10.shape[1])*multiplier, (cropped_10.shape[0])*multiplier)\n\nimages = [resized_1, resized_2, resized_3, resized_4, resized_5, resized_6, resized_7, resized_8, resized_9, resized_10]\ntitles = ['Resized Image 1', 'Resized Image 2', 'Resized Image 3', 'Resized Image 4', 'Resized Image 5', 'Resized Image 6', 'Resized Image 7', 'Resized Image 8', 'Resized Image 9', 'Resized Image 10']\n\nplotting(images, titles, len(images), 1, 50)\n\nfor r in range (len(images)):\n    print(titles[r], \"size (height, width): \", images[r].shape)\nprint(\"\")","9abe0992":"gamma_1 = gamma_correction(resized_1, 1.2)\ngamma_2 = gamma_correction(resized_2, 4.8)\ngamma_3 = gamma_correction(resized_3, 3.0)\ngamma_4 = gamma_correction(resized_4, 1.9)\ngamma_5 = gamma_correction(resized_5, 0.5)\ngamma_6 = gamma_correction(resized_6, 1.8)\ngamma_7 = gamma_correction(resized_7, 0.5)\ngamma_8 = gamma_correction(resized_8, 2.2)\ngamma_9 = gamma_correction(resized_9, 2.5)\ngamma_10 = gamma_correction(resized_10, 5.2)\n\nimages = [gamma_1, gamma_2, gamma_3, gamma_4, gamma_5, gamma_6, gamma_7, gamma_8, gamma_9, gamma_10]\ntitles = ['Gamma Correction Image 1', 'Gamma Correction Image 2', 'Gamma Correction Image 3', 'Gamma Correction Image 4', 'Gamma Correction Image 5', 'Gamma Correction Image 6','Gamma Correction Image 7', 'Gamma Correction Image 8', 'Gamma Correction Image 9', 'Gamma Correction Image 10']\n\nplotting(images, titles, len(images), 1, 40)","61c5a3a4":"threshold_1 = threshold(gamma_1)\nthreshold_2 = threshold(gamma_2)\nthreshold_3 = threshold(gamma_3)\nthreshold_4 = threshold(gamma_4)\nthreshold_5 = threshold(gamma_5)\nthreshold_6 = threshold(gamma_6)\nthreshold_7 = threshold(gamma_7)\nthreshold_8 = threshold(gamma_8)\nthreshold_9 = threshold(gamma_9)\nthreshold_10 = threshold(gamma_10)\n\nimages = [threshold_1, threshold_2, threshold_3, threshold_4, threshold_5, threshold_6, threshold_7, threshold_8, threshold_9, threshold_10]\ntitles = ['Thresholding Image 1', 'Thresholding Image 2', 'Thresholding Image 3', 'Thresholding Image 4', 'Thresholding Image 5', 'Thresholding Image 6', 'Thresholding Image 7', 'Thresholding Image 8', 'Thresholding Image 9', 'Thresholding Image 10']\n\nplotting(images, titles, len(images), 1, 40)","63e13a48":"dlt_er_1 = dilation_erosion(threshold_1)\ndlt_er_2 = dilation_erosion(threshold_2)\ndlt_er_3 = dilation_erosion(threshold_3)\ndlt_er_4 = dilation_erosion(threshold_4)\ndlt_er_5 = dilation_erosion(threshold_5)\ndlt_er_6 = dilation_erosion(threshold_6)\ndlt_er_7 = dilation_erosion(threshold_7)\ndlt_er_8 = dilation_erosion(threshold_8)\ndlt_er_9 = dilation_erosion(threshold_9)\ndlt_er_10 = dilation_erosion(threshold_10)\n\nimages = [dlt_er_1, dlt_er_2, dlt_er_3, dlt_er_4, dlt_er_5, dlt_er_6, dlt_er_7, dlt_er_8, dlt_er_9, dlt_er_10]\ntitles = ['Dilation and Erosion Image 1', 'Dilation and Erosion Image 2', 'Dilation and Erosion Image 3', 'Dilation and Erosion Image 4', 'Dilation and Erosion Image 5', 'Dilation and Erosion Image 6', 'Dilation and Erosion Image 7', 'Dilation and Erosion Image 8', 'Dilation and Erosion Image 9', 'Dilation and Erosion Image 10']\n\nplotting(images, titles, len(images), 1, 40)","182f037a":"images = [dlt_er_1, dlt_er_2, dlt_er_3, dlt_er_4, dlt_er_5, dlt_er_6, dlt_er_7, dlt_er_8, dlt_er_9, dlt_er_10]\ntitles = ['Image 1', 'Image 2', 'Image 3', 'Image 4', 'Image 5', 'Image 6', 'Image 7', 'Image 8', 'Image 9', 'Image 10']\n\nlabeling(images, titles)","5ad72240":"# Initializing Image Assets\n\nReading an image using openCV requires two parameters:\n\ncv2.imread(path, flag)\n\nPath - specifies the location of the image\nFlag - specifies the way in which image should be read.\n\nThere are three types of flags:\n* cv2.IMREAD_COLOR: It specifies to load a color image. Any transparency of image will be neglected. It is the default flag. Alternatively, we can pass integer value 1 for this flag.\n* cv2.IMREAD_GRAYSCALE: It specifies to load an image in grayscale mode. Alternatively, we can pass integer value 0 for this flag.\n* cv2.IMREAD_UNCHANGED: It specifies to load an image as such including alpha channel. Alternatively, we can pass integer value -1 for this flag.\n\nIn this program we used the shorthand notation for reading 10 images in grayscale which is shown below","eb43fdea":"# Cropping the images\n\n* Due to several objects present in an image aside from people, the program cannot give accurate results.\n* As a solution we have to crop segments of an image and we will process them one by one.\n\n* This pre-defined function requires 5 parameters:\n\ncrop(the image, starting y-value, ending y-value, starting x-value, ending x-value)\n\n* Note that the origin of the x and y axis starts from the upper left corner of the image\n\n* Here we performed the cropping function","81807c44":"# CCS221-ALTERNATIVE LEARNING ASSESSMENT (ALA)-Midterm\n\nSection: BSCS 1-A\n\nMembers:\n* Jasper Damasco\n* Mathew Adriane Briones\n* Karen Arroyo\n* Dean Hope Talamera","e382d428":"# Contrast adjusting with gamma correction y\n\nNote:\n\n* The first parameter takes the image generated from resize() in the previous function\n* We have to perform trial and error when assigning the y-values in gamma correction taken by the 2nd parameter until we get the right object count when labeling.","ac0438cc":"# Labeling\n\n* The final part where we generate the object count from each image segment","66840b09":"# Local adaptative threshold\n\n* This is where image segmentation is performed\n* It takes the image from gamma_correction() above\n* The white parts are the objects generated* This is where image segmentation is performed\n* The white parts are the objects generated","d8927aa8":"# Results:\n\n* Experiment 1 (May 14, 2021) \n\n> In the first experiment, the fundamental processes for image segmentation were applied (Conversion > Contrast Adjustment > Thresholding > Dilation\/Erosion > Labeling).\n> \n> Gaussian thresholding was used in the Adaptive Local Threshold in which the program gave inaccurate results.\n\n \n* Experiment 2 (May 15, 2021) - Used Mean Thresholding\n\n> In the 2nd experiment, gaussian thresholding was replaced with mean thresholding. Object counting using mean thresholding was somehow improved but still significantly inaccurate.\n> \n> It was hypothesized that it may have to do with the other objects aside from people, after running a few experiments, the hypothesis appeared to be correct. So it was decided to crop each of the images in parts where other objects appear minimal.\n \n* Experiment 3 (May 16, 2021) - Applied Cropping and Code Optimization\n\n\n> In the 3rd experiment, the sample image was cropped where there are no other objects present except for the people. The same process was then applied and it gave significantly accurate object count.\n> \n> Before applying the process to the other images, the code was optimized by the use of functions for efficiency and to avoid redundancy of the image segmentation processes.\n \n* Experiment 4 (May 17, 2021) - Utilized For Loops and Further Code Optimization\n\n\n> In the last experiment the program made use of \u2018for loops\u2019 to iterate through a series of 10 images following the same process of cropping to labeling. This made the code efficient and flexible to perform the segmentation on any set of images.\n \n# Limitations:\n\n* The program cannot yield accurate results when there are objects alongside with people, this serves as interference for the program and thus it is required to crop part of an image sample where the objects other than people are minimal.\n\n* In the study, image thresholding is highly dependent on image lighting and contrast where there are sharp differences between black and white and thus trial and error must be performed in testing the Y-values for gamma correction until the object count generated is correct\/accurate.\n \n# References:\n* [1] By Associated Press, Jennings, B. R., & By Agence France-Presse. (2020, August 7). How Philippines Got Runaway COVID-19 Caseload, an Outlier in Asia. Voice of America. [https:\/\/www.voanews.com\/covid-19-pandemic\/how-philippines-got-runaway-covid-19-caseload-outlier-asia](http:\/\/)\n\n* [2] COVID-19 and Your Health. (2020, February 11). Centers for Disease Control and Prevention. [https:\/\/www.cdc.gov\/coronavirus\/2019-ncov\/prevent-getting-sick\/social-distancing.html](http:\/\/)\n\n* [3] Mena, F. (2018, November 24). Crowd Counting. Kaggle. [https:\/\/www.kaggle.com\/fmena14\/crowd-counting](http:\/\/)\n\n* [4] Kilimou, E. (2019, October 20). Images Processing: Segmentation and Objects Counting with Python and OpenCV. Medium: Analytics Vidhya. [https:\/\/medium.com\/analytics-vidhya\/images-processing-segmentation-and-objects-counting-in-an-image-with-python-and-opencv-216cd38aca8e](http:\/\/)\n","5076cd25":"# Resizing the image\n\n* The required parameters are as follows:\n\nresize(the image, width, height)\n\n* The purpose of the multiplier variable is for easy scaling while maintaining the aspect ratio\n* Here the image is resized into twice its original size* The required parameters are as follows:","7eabbfd5":"# Project Title: Population Density Detection Using Image Segmentation and Object Counting\n\n# Introduction:\n\n   During these times under the COVID-19 pandemic, people are required to stay inside of their homes and observe proper safety health protocols to avoid the spread of the disease, these safety protocols include social isolation, frequent hand washing and disinfecting, wearing of face masks and face shield outside and observing proper social distancing.\n    \n   Since people can spread the virus before they know they are sick, it is important to stay at least 6 feet away from others when possible, even if you or they do not have any symptoms. Social distancing is especially important for people who are at higher risk for severe illness from COVID-19 (CDC, 2020).\n\n   However, according to a report by Ralph Jennings in August 2020, the Philippines has been suffering high rates of COVID-19 spreading due to the early uplifting of the initial stay-home orders. The increase of cases is also due to the fact that people struggle to practice social distancing despite strict rules. \n \n# Problem:\n\n* People not following social distancing especially in public and crowded areas. The more people are in a particular area, the higher the risk of COVID-19 spreading.\n \n# Solutions\/Objectives:\n\nGeneral Objective:\n\n* Making a population density detection program that uses the concepts of segmentation and objects counting with Python and OpenCV in order to identify whether a specific area is crowded with people or not.\n\nSpecific Objectives:\n\n* Making a python code with OpenCV for object (people) segmentation and counting. Integer numbers will be used for counting.\n* Detecting the number of people in an image based on object count in order to gather information whether an area is crowded or not.\n* Implement proper disciplinary actions regarding social distancing whether the program finds the sample image crowded with people.\n \nData:\n\n* The dataset to be utilized by this project is composed by RGB images of frames in a video (as inputs) and the object counting on every frame, this is the number of pedestrians (object) in the image. The images are 480x640 pixels at 3 channels of the same spot recorded by a webcam in a mall but it has a different number of people on every frame, which is a problem of crowd counting.\n\n* In this project, we will only make use of 10 images randomly selected from the dataset.\n\n# METHODOLOGY\n\nEach image will go through the following processes:\n\nPre-Processing:\n\n* Reading in Grayscale - reading\/converting images to grayscale is required in order to have only one channel image.\n* Cropping - due to several objects present in an image aside from people, the program cannot give accurate results. As a solution we have to crop segments of an image and we will process them one by one.\n* Resizing - making images larger increases the image pixels for easy image analysis.\n* Contrast Adjustment using Gamma Correction - image contrast adjustment is required to avoid edge detecting problems.\n \nProcessing:\n\n* Adaptive Local Thresholding - this method is used to binarize the pre-processed image, it is used to separate objects from the background based on the difference in pixel intensities of each region.\n* Dilation and Erosion - this is used to connect nearest regions in order to have one region per object. Dilation adds pixels to the boundaries of objects in an image, while erosion removes pixels on object boundaries.\n* Labeling - to label connected regions of each object and to detect whether there is low, moderate or high risk of COVID-19 transmission based on object count.\n","251c95b2":"# Dilatation and erosion\n\n* This takes the image from the above function\n* Dilation - adds pixels to the boundaries of an object\n* Erosion - removes pixels on object boundaries","e5746d07":"# Defining functions to be used","ff2aad4b":"\n# Preview of all images in grayscale\n\n* This is just to show the images we're going to process"}}