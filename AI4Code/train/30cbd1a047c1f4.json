{"cell_type":{"eca427f5":"code","a34ebc70":"code","d3d6fc93":"code","1e7d19b8":"code","eefbb1eb":"code","56fe7933":"code","e87bf429":"code","c4435eae":"code","0a61fbe1":"code","646f7f67":"code","1201520d":"code","55e61bdd":"code","8eff9d89":"code","5588c720":"code","f08affaa":"code","cb643cba":"code","ad32a028":"code","5d87eb42":"code","c3907318":"code","a48b42b7":"code","7178f785":"code","b83ef88c":"code","007b0d7f":"code","05603718":"code","613dedfc":"code","df624a6e":"code","7e7b396b":"code","568ba9b4":"code","6cef4dc4":"code","2d91db9b":"code","2ed430ba":"code","e8c8b15b":"code","f1262eec":"code","858d1395":"markdown"},"source":{"eca427f5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import log_loss, mean_squared_error, roc_auc_score\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a34ebc70":"df_train = pd.read_csv('..\/input\/titanic\/train.csv', index_col=0)\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\n\ndf_train.head()","d3d6fc93":"df_test.head()","1e7d19b8":"df_train.info()","eefbb1eb":"df_test.info()","56fe7933":"df_train.describe()","e87bf429":"df_train[df_train.duplicated()]","c4435eae":"df_test[df_test.duplicated()]","0a61fbe1":"df_train.groupby(['Survived']).count()","646f7f67":"df_train.nunique()","1201520d":"df_train.shape","55e61bdd":"df_test.shape","8eff9d89":"print('Missing values in train dataset:', df_train.isna().sum()) \nprint('-----------------------------------')\nprint('Missing values in test dataset:', df_test.isna().sum())","5588c720":"features= df_train.drop(['Survived', 'Cabin', 'Name'], axis= 1)\ny= df_train['Survived']","f08affaa":"numerical_features = [cname for cname in features.columns if (features[cname].dtype == \"int64\" or features[cname].dtype == \"float64\")]\nprint(\"Numerical Columns =\", numerical_features)","cb643cba":"n_features = [cname for cname in df_train.columns if (df_train[cname].dtype == \"int64\" or df_train[cname].dtype == \"float64\")]\nprint(\"Numerical Columns =\", n_features)","ad32a028":"categorical_features = [cname for cname in features.columns if features[cname].dtype == \"object\"]\nprint(\"Categorical Columns =\", categorical_features)","5d87eb42":"for col in numerical_features:\n    fig = plt.figure(figsize=(9, 4))\n    sns.kdeplot(df_train[col], shade=True, edgecolor='black', linewidth=1.5, alpha=0.9, zorder=3)\n    plt.show()","c3907318":"fig = plt.figure(figsize=(9, 4))\nchart_df = pd.DataFrame(df_train['Survived'].value_counts() \/ len(df_train) * 100)\nsns.barplot(x=chart_df.index, y=chart_df['Survived'], zorder=3, edgecolor='black', linewidth=1.5)","a48b42b7":"fig = plt.figure(figsize=(20, 10))\nsns.heatmap(df_train[n_features].corr(), vmin=-1, vmax=1, annot=True, square=True, \n            cbar_kws={\"orientation\": \"horizontal\"}, cbar=False, fmt='.1g')","7178f785":"all_data = pd.concat([df_train, df_test])\n\nfig, ax = plt.subplots(3, 2, figsize=(14, 12))\nfor i, feature in enumerate(n_features):\n    plt.subplot(3, 2, i+1)\n    sns.histplot(all_data[feature], \n                 color=\"blue\", \n                 kde=True, \n                 bins=100)\n    plt.xlabel(feature, fontsize=9)\nplt.show()","b83ef88c":"numerical_transformer_steps = [\n    ('imputer', SimpleImputer(strategy= 'median')),\n    ('scaler', StandardScaler())]\nnumerical_transformer= Pipeline(steps= numerical_transformer_steps)\n\n\ncategorical_transformer_steps= [\n    ('imputer', SimpleImputer(strategy= 'constant', fill_value= 'missing')),\n    ('onehot', OneHotEncoder(handle_unknown= 'ignore'))\n]\ncategorical_transformer= Pipeline(steps= categorical_transformer_steps)\n\n\ncol_transformers= [\n    ('num', numerical_transformer, numerical_features),\n    ('cat', categorical_transformer, categorical_features)\n]\npreprocessor= ColumnTransformer(transformers= col_transformers)","007b0d7f":"X_train, X_val, y_train, y_val= train_test_split(features, y, test_size= 0.2, random_state= 12)","05603718":"# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n# Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n}\n# XGBOOST parameters\nxgb_params= {\n    #learning_rate = 0.02,\n     'n_estimators': 2000,\n     'max_depth': 4,\n     'min_child_weight': 2,\n     #'gamma': 1,\n     'gamma': 0.9,                        \n     'subsample': 0.8,\n     'colsample_bytree': 0.8,\n     'objective': 'binary:logistic',\n     'nthread': -1,\n     'scale_pos_weight': 1\n}\n","613dedfc":"et = ExtraTreesClassifier(**et_params)\nrf = RandomForestClassifier(**rf_params)\nsvc= SVC(**svc_params)\ngbm= xgb.XGBClassifier(**xgb_params)","df624a6e":"model_et= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', et)\n])\nmodel_et.fit(X_train, y_train)\npreds_et = model_et.predict(X_val)\nmodel_et.score(X_train, y_train)","7e7b396b":"model_rf= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', rf)\n])\nmodel_rf.fit(X_train, y_train)\npreds_rf = model_rf.predict(X_val)\nmodel_rf.score(X_train, y_train)","568ba9b4":"model_svc= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', svc)\n])\nmodel_svc.fit(X_train, y_train)\npreds_svc = model_svc.predict(X_val)\nmodel_svc.score(X_train, y_train)","6cef4dc4":"model_gbm= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', gbm)\n])\nmodel_gbm.fit(X_train, y_train)\npreds_gbm = model_gbm.predict(X_val)\nmodel_gbm.score(X_train, y_train)","2d91db9b":"test_features= df_test.drop(['Cabin', 'Name'], axis= 1)","2ed430ba":"y_pred= model_gbm.predict(test_features)","e8c8b15b":"submission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": y_pred\n    })","f1262eec":"submission.to_csv('submission.csv', index=False)","858d1395":"## Learning More About the data"}}