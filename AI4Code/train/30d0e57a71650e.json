{"cell_type":{"e9b8ca40":"code","81f2b20a":"code","25c4727f":"code","76f3fde4":"code","236587b0":"code","3f251d51":"code","fe3d6d77":"code","c563b6e5":"code","477fb5d4":"code","d80fccc9":"code","8c9d4a33":"code","fcbc0293":"code","79e4cd1b":"code","4df20f08":"markdown","e3bc5247":"markdown","8728efa2":"markdown","b5f87ec1":"markdown","22c61130":"markdown","a8168886":"markdown","e5a5c06c":"markdown","bcaff148":"markdown","f21fb104":"markdown"},"source":{"e9b8ca40":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfrom pathlib import Path","81f2b20a":"from fastai import *\nfrom fastai.vision import *\n\npath=Path(\"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\")","25c4727f":"data = ImageDataBunch.from_folder(path,test='test',train='train',valid='val', size=224)\ndata.show_batch(rows=3)","76f3fde4":"print(data.classes)\nlen(data.classes),data.c","236587b0":"from fastai.metrics import error_rate\nlearn = cnn_learner(data, models.resnet34, metrics=error_rate, model_dir=\"\/tmp\/model\/\")","3f251d51":"learn.fit_one_cycle(4)","fe3d6d77":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nprint(len(data.valid_ds)==len(losses)==len(idxs))\n\ninterp.plot_top_losses(9)","c563b6e5":"interp.plot_confusion_matrix()","477fb5d4":"interp.most_confused(min_val=2)","d80fccc9":"learn.unfreeze()","8c9d4a33":"from fastai.vision import get_transforms\n\ntransforms=get_transforms(max_rotate=45, max_zoom=1.5, max_lighting=0.5, max_warp=0.3)\ndata = ImageDataBunch.from_folder(path,test='test',train='train', ds_tfms=transforms, valid='val', size=224)","fcbc0293":"learn.lr_find()\nlearn.recorder.plot()\nplt.title(\"Loss Vs Learning Rate\")\nplt.show()","79e4cd1b":"learn.fit_one_cycle(4, max_lr=slice(1e-6,1e-3))","4df20f08":"We have reduced our error rate but its still not as close as some of the top kernels in this Dataset. Other things we can do to reduce our error rate is to use a bigger CNN like ResNet-50, use a different optimizer, train for more epochs or try to implement more ResBlocks.","e3bc5247":"Lets see how many classes we are working with.","8728efa2":"Our model was only 82% accurate. Can we improve the accuracy even more? Possibly we can try unfreezing all the layers of resnet, try to find a better learning rate than the default value, and data augmentation.\n\n## Unfreezing\nThe reason our model was being built so fast is because we only been training the last few layers that were added to the end of Resnet by the Fast.AI team. This allowed us to avoid training the weights of the earlier layers and focus training only on the last few layers. The problem with this method is we are trying to use Transfer Learning to a dataset that Resnet probably never seen before. We know from Visualizing and understand Convolutional models by Matthew D. Zeiler and Rob Fergus that Resnet learned features that were relevant to the dataset it was initially trained on. esnet probably has not learned the actual deep features of the images properly. Therefore we need to unfreeze the earlier layers to force Resnet to learn more accurate features.\n\nUnfreezing, fine-tuning, and learning rates","b5f87ec1":"## Learning Rate\n\nLearning rate (LR) is the hyperparameter that determines how much a model should change. Choosing the right LR is crucial to having a model to converge on the weights that reduce error the most. Choosing a LR too small can take too long for the model to converge to the minimum. Choosing a LR to large can cause the model to converge to a subpotimal minimum or never converge at all.\n\nWe can use learn.lr_find() and learn.recorder.plot() to pick a learning rate thats ideal","22c61130":"For this project I'm going to see how well fast.ai's vision library can identify which patient has pneumonia and which doesn't.\n\nI will first build a simple model using just the basic ResNet-34. From there we will try to optimize it with the techniques learned from Fast.AI lessons.","a8168886":"We can see that from 1e-06 to 1e-02 the learning rate isable to sufficently reduce loss. However past 1e-02 the loss dramatically increases. Therefore we should choose a LR before 1e-02. Jeremy (the Fast.AI lecturer) recommends to pick a LR one fold before the loss sky-rockets. Therefore we are going to pick a LR <= 1e-03. We can also go with 1e-06 as the LR but that will take a long time for training. What Fast.AI allows us to do is pass a range of LR to the training sessions. Since we know that LR is fine up to 1e-02 we can just train the earlier layers with a large LR and then start fine turning with a smaller LR.   ","e5a5c06c":"Lets create a basic CNN and see how well it performs.","bcaff148":"## Data Augmentation\n\nData augmentation is basically modifying the data in certain ways that the underlying features still present but the CNN is still presented with a picture that is different from the original. Fast.AI allows many different transformation and we will apply all of them except invertion. I won't invert the image since x-ray pictures are all ways taken with the patient facing the doctor.","f21fb104":"As we can see with each epoch the training loss and error rate drops. But after epoch 1 we can see that validation loss adn error rate start to increase. This is due to the model overfitting to the training data (validation loss > training loss).\n\nLets explore what kind of images our model mislabelled."}}