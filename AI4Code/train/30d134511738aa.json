{"cell_type":{"c4c05f08":"code","f377d6cf":"code","f0653352":"code","59632ff2":"code","d82a1ad1":"code","d3b31fe4":"code","c43b366c":"code","3e61284f":"code","5d493317":"code","97f57c9c":"code","c48ebb78":"code","b18beae7":"code","57adaa1b":"code","25c9d810":"code","33c0beee":"code","bf4a5b8b":"code","50c53401":"code","7de0130d":"code","9c8999b1":"code","34c3085a":"code","c950a49c":"markdown","77e9c25e":"markdown"},"source":{"c4c05f08":"! pip install tensorflow==1.15","f377d6cf":"import tensorflow as tf\nprint(tf.version)","f0653352":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport matplotlib.pyplot as plt\n","59632ff2":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport numpy as np\nimport shap\nimport keras.backend as K\nimport json","d82a1ad1":"# load pre-trained model and choose two images to explain\n# VGG16 model, with weights pre-trained on ImageNet.\nmodel = VGG16(weights='imagenet', include_top=True)","d3b31fe4":"model.summary()","c43b366c":"# load the ImageNet class names\nurl = \"https:\/\/s3.amazonaws.com\/deep-learning-models\/image-models\/imagenet_class_index.json\"\nfname = shap.datasets.cache(url)\nwith open(fname) as f:\n    class_names = json.load(f)\nclass_names","3e61284f":"len(class_names)","5d493317":"X,y = shap.datasets.imagenet50()\nX.shape, y.shape","97f57c9c":"to_explain = X[[39,41]]","c48ebb78":"y[[39,41]]","b18beae7":"plt.imshow(X[39][:,:,0])","57adaa1b":"plt.imshow(X[41][:,:,0])","25c9d810":"idx_class = np.argmax(model.predict(to_explain)[0])\nclass_names[str(idx_class)]","33c0beee":"idx_class = np.argmax(model.predict(to_explain)[1])\nclass_names[str(idx_class)]","bf4a5b8b":"# explain how the input to the 7th layer of the model explains the top two classes\ndef map2layer(x, layer):\n    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n    return K.get_session().run(model.layers[layer].input, feed_dict)","50c53401":"e = shap.GradientExplainer((model.layers[7].input, model.layers[-1].output), map2layer(preprocess_input(X.copy()), 7))","7de0130d":"shap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)","9c8999b1":"# get the names for the classes\nindex_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)","34c3085a":"# plot the explanations\nshap.image_plot(shap_values, to_explain, index_names)","c950a49c":"# Explaining Keras decisions on ImageNet with SHAP GradientExplainer\n\n* VGG16: https:\/\/arxiv.org\/pdf\/1409.1556.pdf\n","77e9c25e":"## Explaining"}}