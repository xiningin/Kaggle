{"cell_type":{"7c8fbaec":"code","20f92e85":"code","25795352":"code","116ab75e":"code","bb2fb532":"code","bad734bb":"code","aec092f1":"code","e8a1f3f4":"code","ed8f0ee9":"code","b9c7d643":"code","5219b607":"code","564f452c":"code","1aef535f":"code","b8b897d1":"code","028269f7":"code","39e078f1":"code","a503ea95":"code","28e2120d":"code","6b393d88":"code","e51843be":"code","2a3491d0":"code","42d894c5":"code","f77f0dfa":"code","c26cb1c7":"code","0a783268":"code","25c2ebca":"code","76633755":"code","06be4587":"code","c96b9acc":"code","6099ae62":"code","4fbdddb6":"code","996ab0eb":"code","c6001493":"code","02462bfc":"code","2def893f":"code","ae91c303":"code","9905df61":"code","0c1e2019":"code","f1df6cd5":"code","654c42d9":"code","12a992f8":"code","431b9ac5":"code","9bce1581":"code","8fd16237":"code","21a96d5c":"code","6e982126":"code","1b37fff6":"code","657c98ea":"code","39d6300a":"code","6a6b49e5":"code","24d264fc":"code","6ea5bc25":"code","8f324553":"code","56971e43":"markdown","cfd91bbd":"markdown","51b77718":"markdown","78529f48":"markdown","141dbc4a":"markdown","05e49b2b":"markdown","f57d7f03":"markdown","3ece728e":"markdown","13f766f4":"markdown","54cc5db2":"markdown","9d1be2b2":"markdown","075526b2":"markdown","8f8f6772":"markdown","2641d337":"markdown","e0b0e787":"markdown","1c1898ef":"markdown","fd56b8b4":"markdown","a498a4d4":"markdown","46975c63":"markdown","0c79dc0e":"markdown","201ce879":"markdown","0a7adf13":"markdown","58900cc5":"markdown","47ea5dc9":"markdown","335429a9":"markdown","e14f7860":"markdown","9062a351":"markdown","19a816b2":"markdown","d113a36e":"markdown","d28025e8":"markdown","a52f97e9":"markdown","638766f7":"markdown","411cf0be":"markdown","0ef27acd":"markdown","4b11e088":"markdown","7679d498":"markdown","40725601":"markdown","8e9c7861":"markdown","af6ab48c":"markdown","251fddb7":"markdown","5308ff6d":"markdown","7ddbc833":"markdown","badab1c8":"markdown","f20303b1":"markdown","2752d2d2":"markdown","5b063f16":"markdown","3293639f":"markdown","330001f4":"markdown","79a84c7e":"markdown"},"source":{"7c8fbaec":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","20f92e85":"#---------- configs\npd.set_option('max_rows',100)\npd.set_option('max_columns',100)","25795352":"### loading data\ndf_train = pd.read_csv(r\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\",index_col=0)\ndf_test = pd.read_csv(r\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\",index_col=0)\ndf_all = pd.concat([df_train,df_test],axis=0) #to handle data processing in one call\n\ndef get_train_test_df(all_df,train_length=len(df_train)):\n    cpy_all_df = all_df.copy()\n    return cpy_all_df.loc[:train_length], cpy_all_df.loc[train_length+1:]\n\n### display data types and get a hint on NaNs.\ndf_all.info()","116ab75e":"df_train_prep,df_test_prep = get_train_test_df(df_all,train_length=len(df_train))","bb2fb532":"plt.figure(figsize=(16,12))\nsns.heatmap(df_train_prep.isna(),yticklabels=False,cbar=False,cmap='mako')\nplt.show()","bad734bb":"plt.figure(figsize=(16,12))\nsns.heatmap(df_test_prep.isna(),yticklabels=False,cbar=False,cmap='mako')\nplt.show()","aec092f1":"features_na = (df_all.drop(columns=['SalePrice'],axis=1).isna().sum() \/ len(df_all) ) * 100\nprint('N of Features with Missing Values : ' , len(features_na[features_na > 0]))\nprint('Percentage of Missing Values for each feature  (%): ')\nprint(features_na[features_na > 0].sort_values(ascending = False))","e8a1f3f4":"df_all[df_all['GarageType'].isna()][['GarageYrBlt' , 'GarageCars', 'GarageArea']].sum()","ed8f0ee9":"#first differentiate the NA from the rest. (using the train data only to see distribution with saleprice)\ndef lotfrontage_NA(df):\n     if pd.isna(df['LotFrontage']): #is na => 0\n        return 'Is NA'\n     else:\n        return 'Is not NA'\ndf_train['LotFrontageNA']  = df_train[['LotFrontage']].apply(lotfrontage_NA,axis=1)","b9c7d643":"sns.histplot(data=df_train,x= 'SalePrice' ,hue='LotFrontageNA',kde=True ,hue_order=['Is NA','Is not NA'],alpha=0.8)\nplt.title('House With\\out LotFrontage vs Price Distribution')\nplt.show()","5219b607":"sns.catplot(data=df_train,x='LotFrontageNA',y='SalePrice',kind=\"strip\",marker='^',alpha=0.8)\nplt.title(\"Relation to Target Variable\")\nplt.show()","564f452c":"df_all[df_all['BsmtExposure'].isna()][['BsmtFullBath' ,'BsmtHalfBath' ,'TotalBsmtSF']].sum()","1aef535f":"df_all[df_all['TotalBsmtSF'].isna()][['BsmtFullBath' ,'BsmtHalfBath' ,'BsmtExposure','BsmtFinType1','BsmtCond','BsmtQual']]","b8b897d1":"df_all[df_all['BsmtFinSF1'].isna()][['BsmtFinSF2', 'BsmtUnfSF','BsmtFullBath' ,'BsmtHalfBath' ,'BsmtExposure','BsmtFinType1','BsmtCond','BsmtQual']]","028269f7":"df_all[df_all['MasVnrType'].isna()][['MasVnrArea']]","39e078f1":"df_all[df_all.index == 2611]","a503ea95":"df_all[df_all['MSZoning'].isna()]","28e2120d":"#get a copy for modification\ndf_all_prep = df_all.copy() ","6b393d88":"#-- making modifications easier\ndef new_feature_data_series(df_prep,df_original,col_name,function,new_col_name):\n       df_prep[new_col_name]  = df_original[col_name].apply(function,axis=1)\n\ndef encode_data_series(df_prep,df_original,col_name,from_vals,to_vals):\n    df_prep[col_name] = df_original[col_name].replace(from_vals,to_vals,inplace=False)","e51843be":"all_cols_with_NA = list(df_all_prep.isna().any()[df_all_prep.isna().any()].index) #get all NA Columns\n\nall_categorical_cols = df_all_prep.select_dtypes('object').columns.tolist() #get Categorical NA Columns\n\nexclude_cols = ['MSZoning','Utilities', 'Functional' ,'Exterior1st' ,'Exterior2nd','SaleType','Electrical','KitchenQual'] # for different treatment\nall_na_cols_ready = [x for x in all_cols_with_NA if x in all_categorical_cols and x not in exclude_cols]\n\ndf_all_prep[all_na_cols_ready] = df_all_prep[all_na_cols_ready].fillna(value='_None_')","2a3491d0":"# GarageCars,GarageArea => 0 .. use oldest year built the GarageYrBlt\nencode_data_series(df_all_prep,df_all,['GarageCars'],[np.nan],0)\nencode_data_series(df_all_prep,df_all,['GarageArea'],[np.nan],0)\nencode_data_series(df_all_prep,df_all,['GarageYrBlt'],[np.nan],df_train['GarageYrBlt'].min())","42d894c5":"# using the median from Neighborhood for LotFrontage NA\ndf_all_prep[\"LotFrontage\"] = df_all.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median())) ","f77f0dfa":"# BsmtFullBath, BsmtHalfBath, TotalBsmtSF => 0\nencode_data_series(df_all_prep,df_all,['BsmtFullBath'],[np.nan],0)\nencode_data_series(df_all_prep,df_all,['BsmtHalfBath'],[np.nan],0)\nencode_data_series(df_all_prep,df_all,['TotalBsmtSF'],[np.nan],0)\n\nencode_data_series(df_all_prep,df_all,['BsmtFinSF1'],[np.nan],0)\nencode_data_series(df_all_prep,df_all,['BsmtFinSF2'],[np.nan],0)\nencode_data_series(df_all_prep,df_all,['BsmtUnfSF'],[np.nan],0)\n","c26cb1c7":"# MasVnrArea => 0 \nencode_data_series(df_all_prep,df_all,['MasVnrArea'],[np.nan],0)","0a783268":"# MSZoning from Neighborhood Mode\ndf_all_prep[\"MSZoning\"] = df_all_prep.groupby(\"Neighborhood\")[\"MSZoning\"].transform(lambda x: x.fillna(x.mode().iloc[0]))","25c2ebca":"rest = ['Utilities', 'Functional' ,'Exterior1st' ,'Exterior2nd','SaleType','Electrical','KitchenQual']\nfor na_col in rest:\n    encode_data_series(df_all_prep,df_all,[na_col],[np.nan],df_train[na_col].mode().tolist())","76633755":"df_all_prep.drop(columns='SalePrice').isna().sum().sum()","06be4587":"lst_num_t_obj = ['MSSubClass','OverallQual','OverallCond','YrSold','MoSold']\ndf_all_prep[lst_num_t_obj] = df_all_prep[lst_num_t_obj].astype('object')","c96b9acc":"df_train_prep,df_test_prep = get_train_test_df(df_all_prep) #-- we will use the train data.","6099ae62":"numerical_columns = list(df_all_prep.select_dtypes(exclude=['object']).columns)\n\ndef plot_numerical_histogram(df,x_cols=[],rows = 2,cell_size = 4):\n    size = len(x_cols)\n    cols = size \/\/ rows\n    fig,axes = plt.subplots(rows,cols,figsize=(cols * cell_size, rows * cell_size))\n    fig.suptitle(\"Variable Histogram\")\n    for i,axe in enumerate(axes.flatten()):\n        if(i < size):\n            sns.histplot(df[x_cols[i]],ax=axe)\n            median = df[x_cols[i]].median()\n            axe.set_title(x_cols[i] + f' ,Median : {median:0.1f}')\n            axe.axvline(median, color ='red',lw=2, alpha = 0.55)\n        else:\n            print('subplots > n of columns, change n of rows')\n            break \n    plt.tight_layout()\n    plt.show()\nplot_numerical_histogram(df_all_prep,numerical_columns,rows=8)","4fbdddb6":"drop_indices= set(  df_train_prep[df_train_prep['LotFrontage'] >250].index.tolist()+ \n        df_train_prep[df_train_prep['MasVnrArea'] > 1500].index.tolist() +\n        df_train_prep[df_train_prep['BsmtFinSF1'] > 5000].index.tolist() + \n        df_train_prep[df_train_prep['TotalBsmtSF'] > 5000].index.tolist() + \n        df_train_prep[df_train_prep['1stFlrSF'] > 4000].index.tolist()+\n        df_train_prep[df_train_prep['GrLivArea'] > 5000].index.tolist())\nprint('Total Dropped : ' ,len(drop_indices))\ndf_train_prep_no = df_train_prep.drop(index=drop_indices, inplace = False)","996ab0eb":"#log transform skewed numeric features:\nfrom scipy.stats import skew\n\ndf_train_prep_ns = df_train_prep_no.copy()\ndf_test_prep_ns = df_test_prep.copy()\n\nnumerical_columns = list(df_train_prep_no.select_dtypes(exclude=['object']).columns)\n\nskewed_cols = df_train_prep_no[numerical_columns].apply(lambda x: skew(x.dropna()))  \nskewed_cols = skewed_cols[skewed_cols > 0.75]\nskewed_cols = skewed_cols.index\n\ndf_train_prep_ns[skewed_cols] = np.log1p(df_train_prep_no[skewed_cols])\ndf_test_prep_ns[skewed_cols] = np.log1p(df_test_prep[skewed_cols])","c6001493":"#adding Helpful features\ndef totalAreaSum(df):\n    return df.sum()\n\n# train\nnew_feature_data_series(df_train_prep_ns,df_train_prep_ns,\n                        ['1stFlrSF','2ndFlrSF','BsmtFinSF1','BsmtFinSF2'],totalAreaSum,'TotalAreaSF')\n\nnew_feature_data_series(df_train_prep_ns,df_train_prep_ns,\n                        ['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch'],totalAreaSum,'TotalPorchSF')\n\n# test\nnew_feature_data_series(df_test_prep_ns,df_test_prep_ns,\n                        ['1stFlrSF','2ndFlrSF','BsmtFinSF1','BsmtFinSF2'],totalAreaSum,'TotalAreaSF')\nnew_feature_data_series(df_test_prep_ns,df_test_prep_ns,\n                        ['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch'],totalAreaSum,'TotalPorchSF')","02462bfc":"#check SalePrice after skewness\nsns.histplot(data=df_train_prep_ns['SalePrice'])\nplt.show()","2def893f":"numerical_columns = list(df_train_prep_ns.drop('SalePrice',axis=1).select_dtypes(exclude=['object']).columns)\n\ndef plot_numerical_with_target(df,x_cols=[],target_col='SalePrice',rows = 2,cell_size = 4):\n    size = len(x_cols)\n    cols = (size) \/\/ (rows)\n    fig,axes = plt.subplots(rows+1,cols,figsize=(cols * cell_size, rows * cell_size))\n    \n    if (size > cols * rows ):\n        print('subplots < n of columns, change n of rows')\n    for i,axe in enumerate(axes.flatten()):\n        if(i < size):\n            sns.regplot(data=df,x=x_cols[i],y=target_col,ax=axe,scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\n        else:\n            #print('subplots > n of columns, change n of rows')\n            break \n    #plt.suptitle(\"Sale Price vs Variable\")\n    plt.tight_layout()\n    plt.show()\nplot_numerical_with_target(df_train_prep_ns,numerical_columns,rows=8)","ae91c303":"#---- Categorical Relations to Sale Price\ncategorical_columns = list(df_train_prep_ns.select_dtypes(include=['object']).columns)\n\ndef plot_categorical_with_target(df,cat_cols=[],target_col='y',rows = 2,cell_size = 4):\n    size = len(cat_cols)\n    cols = size \/\/ rows\n    fig,axes = plt.subplots(rows,cols,figsize=(cols * cell_size, rows * cell_size))\n    if (size > cols * rows ):\n        print('subplots < n of columns, change n of rows')\n    for i,axe in enumerate(axes.flatten()):\n        if(i < len(cat_cols)):\n            df_g = df.groupby(cat_cols[i],as_index =False)[[target_col]].median()\n            #--- restored to real original price for better visualization of the difference\n            df_g[target_col] = np.exp(df_g[target_col]) \n\n            sns.barplot(data=df_g,x=cat_cols[i],y=target_col,ax=axe)\n            axe.tick_params(axis='x',labelrotation = 90)\n\n            \n        else:\n            #print('subplots > n of columns, change n of rows')\n            break\n    plt.tight_layout()\n    plt.show()\n\nplot_categorical_with_target(df_train_prep_ns,categorical_columns,target_col='SalePrice',rows=10)","9905df61":"df_train_prep_c = df_train_prep_ns.copy() \ndf_test_prep_c = df_test_prep_ns.copy() #-- we will use same categorical info from train to test...\n\n# categorical_columns = list(df_train_prep_c.select_dtypes(include=['object']).columns)\nselected_ordinal_features = ['ExterQual','ExterCond','BsmtQual','BsmtCond','Condition1','Condition2',\n                             'HeatingQC','KitchenQual','FireplaceQu','GarageQual',\n                            'GarageCond','PoolQC','Fence','SaleCondition','OverallQual']\n\ndef encode_ordinal_byPrices(df_train,df_test,df_train_original,df_test_original,cat_cols=[],target_col='y'):\n    for col in cat_cols:\n        df_g = df_train_original.groupby(col,as_index =False)[[target_col]].median() #get mean\n        df_g[target_col] = np.exp(df_g[target_col]) \n        list_of_order = df_g.sort_values(by=target_col,ignore_index=True)[col].tolist() #--sorted from min to max\n        encode_data_series(df_train,df_train_original,[col],list_of_order,list(range(len(list_of_order)))) #encoded by order\n        encode_data_series(df_test,df_test_original,[col],list_of_order,list(range(len(list_of_order)))) #encoded by order\n        \nencode_ordinal_byPrices(df_train_prep_c,df_test_prep_c,df_train_prep_ns,df_test_prep_ns,selected_ordinal_features,target_col='SalePrice')","0c1e2019":"plot_categorical_with_target(df_train_prep_c,selected_ordinal_features,target_col='SalePrice',rows=4)","f1df6cd5":"# ~ one hot encode the rest..\ndf_train_prep_f = pd.get_dummies(df_train_prep_c)\ndf_test_prep_f  = pd.get_dummies(df_test_prep_c)","654c42d9":"#-- some features has other options so i will drop them for now\ndf_train_prep_f.columns.difference(df_test_prep_f.columns)","12a992f8":"df_train_prep_f = df_train_prep_f.drop(axis=1,columns=df_train_prep_f.columns.difference(df_test_prep_f.columns) )","431b9ac5":"print('Difference : ' ,len(df_train_prep_f.columns.difference(df_test_prep_f.columns)))","9bce1581":"df_corr = df_train_prep_f.corr()\ndf_sorted_corr = df_corr['SalePrice'].abs().sort_values(ascending=False)\ncorrelation_threshold =  0.5 #for visualization\nhigh_corr_cols = df_sorted_corr[df_sorted_corr > correlation_threshold].index.tolist()","8fd16237":"plt.figure(figsize=(14,14))\nsns.heatmap(df_corr.loc[high_corr_cols,high_corr_cols],annot=True,square=True,linewidths=1,cmap='mako',cbar=False)\nplt.show()","21a96d5c":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.metrics import make_scorer","6e982126":"# select features based on correlations\ndf_corr = df_train_prep_f.corr()\ndf_sorted_corr = df_corr['SalePrice'].abs().sort_values(ascending=False)[1:]\ncorrelation_threshold =  0.15\nselected_corr_cols = df_sorted_corr[df_sorted_corr > correlation_threshold].index.tolist()\n\nexclude_lst = []\n\nselected_features = [col for col in selected_corr_cols if col not in exclude_lst]\n\ntrain = df_train_prep_f.copy()\nX = train[selected_features]\ny = train[\"SalePrice\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n\n#trying poly feature , working without it now..\npoly_features = PolynomialFeatures(degree=1)\nX_train_poly = poly_features.fit_transform(X_train)\nX_test_poly = poly_features.transform(X_test)","1b37fff6":"lreg = LinearRegression()\nlreg.fit(X_train_poly,y_train)\ny_train_predict = lreg.predict(X_train_poly)\ny_test_predict = lreg.predict(X_test_poly)\n\ny_train_predict[y_train_predict<0] = 0 \ny_test_predict[y_test_predict<0] = 0 \n\n## mse for logs\ny_train_mse_error_log = mean_squared_error(y_train,y_train_predict)\ny_test_mse_error_log = mean_squared_error(y_test,y_test_predict)\n\ny_train_mse_error = mean_squared_error(np.exp(y_train),np.exp(y_train_predict))\ny_test_mse_error = mean_squared_error(np.exp(y_test),np.exp(y_test_predict))\n\ny_train_r2 = r2_score(y_train,y_train_predict)\ny_test_r2 = r2_score(y_test,y_test_predict)\n\nprint('RMSE(Logs) : ')\nprint('\\t Train : ',np.sqrt(y_train_mse_error_log))\nprint('\\t Test  : ',np.sqrt(y_test_mse_error_log))\n\nprint('RMSE : ')\nprint('\\t Train : ',np.sqrt(y_train_mse_error))\nprint('\\t Test  : ',np.sqrt(y_test_mse_error))\n\nprint('R2 % : ')\nprint('\\t Train : ',y_train_r2*100)\nprint('\\t Test : ',y_test_r2*100)","657c98ea":"cv = KFold(n_splits=7, random_state=1,shuffle=True)\nlreg = RidgeCV(alphas=list(np.arange(0,1,0.01)),normalize=True,scoring='neg_mean_squared_error' ,cv=cv)\nlreg.fit(X_train_poly,y_train)\ny_train_predict = lreg.predict(X_train_poly)\ny_test_predict = lreg.predict(X_test_poly)\n\ny_train_predict[y_train_predict<0] = 0 \ny_test_predict[y_test_predict<0] = 0 \n\n## mse for logs\ny_train_mse_error_log = mean_squared_error(y_train,y_train_predict)\ny_test_mse_error_log = mean_squared_error(y_test,y_test_predict)\n\ny_train_mse_error = mean_squared_error(np.exp(y_train),np.exp(y_train_predict))\ny_test_mse_error = mean_squared_error(np.exp(y_test),np.exp(y_test_predict))\n\ny_train_r2 = r2_score(y_train,y_train_predict)\ny_test_r2 = r2_score(y_test,y_test_predict)\n\nprint('RMSE(Logs) : ')\nprint('\\t Train : ',np.sqrt(y_train_mse_error_log))\nprint('\\t Test : ',np.sqrt(y_test_mse_error_log))\n\nprint('RMSE : ')\nprint('\\t Train : ',np.sqrt(y_train_mse_error))\nprint('\\t Test : ',np.sqrt(y_test_mse_error))\n\nprint('R2 % : ')\nprint('\\t Train : ',y_train_r2*100 )\nprint('\\t Test : ',y_test_r2*100 )","39d6300a":"lreg.alpha_","6a6b49e5":"lreg = Ridge(alpha=0.05,  normalize=True)\nlreg.fit(X_train_poly,y_train)\ny_train_predict = lreg.predict(X_train_poly)\ny_test_predict = lreg.predict(X_test_poly)\n\ny_train_predict[y_train_predict<0] = 0 \ny_test_predict[y_test_predict<0] = 0 \n\n## mse for logs\ny_train_mse_error_log = mean_squared_error(y_train,y_train_predict)\ny_test_mse_error_log = mean_squared_error(y_test,y_test_predict)\n\ny_train_mse_error = mean_squared_error(np.exp(y_train),np.exp(y_train_predict))\ny_test_mse_error = mean_squared_error(np.exp(y_test),np.exp(y_test_predict))\n\ny_train_r2 = r2_score(y_train,y_train_predict)\ny_test_r2 = r2_score(y_test,y_test_predict)\n\nprint('RMSE(Logs) : ')\nprint('\\t Train : ',np.sqrt(y_train_mse_error_log))\nprint('\\t Test : ',np.sqrt(y_test_mse_error_log))\n\nprint('RMSE : ')\nprint('\\t Train : ',np.sqrt(y_train_mse_error))\nprint('\\t Test : ',np.sqrt(y_test_mse_error))\n\nprint('R2 % : ')\nprint('\\t Train : ',y_train_r2*100 )\nprint('\\t Test : ',y_test_r2*100 )","24d264fc":"#cv = RepeatedKFold(n_splits=7,n_repeats=3, random_state=1)\ncv = KFold(n_splits=10, random_state=1,shuffle=True)\n\nscores = cross_val_score(lreg, X_train_poly,y_train,scoring='neg_mean_squared_error' ,cv=cv, verbose = 0)\n\nprint(\"RMSE(LOG) : \",np.mean(np.sqrt( -scores)) )\n\nscoresACC = cross_val_score(lreg, X_train_poly,y_train,scoring='r2' ,cv=cv)\nprint('R2 : ' ,np.mean(scoresACC))","6ea5bc25":"Kaggle_test = df_test_prep_f[selected_features]\nKaggle_test_poly = poly_features.transform(Kaggle_test)\npredsX = lreg.predict(Kaggle_test_poly)\npredsXexp = np.expm1(predsX)\npredsXexp[-1:-10:-1]","8f324553":"df_test_prep_c['SalePrice'] = predsXexp\ndf_test_prep_c[[\"SalePrice\"]].to_csv('submission472.csv', index=True)","56971e43":"##### Handling Numerical data That Need Categorical Treatment (for emphasizing Linear relationships)","cfd91bbd":"##### Numerical Exploration","51b77718":"### Data fields\n\n* MSSubClass: Identifies the type of dwelling involved in the sale.\n* MSZoning: Identifies the general zoning classification of the sale.\n* LotFrontage: Linear feet of street connected to property\n* LotArea: Lot size in square feet\n* Street: Type of road access to property\n* Alley: Type of alley access to property\n* LotShape: General shape of property\n* LandContour: Flatness of the property\n* Utilities: Type of utilities available\n* LotConfig: Lot configuration\n* LandSlope: Slope of property\n* Neighborhood: Physical locations within Ames city limits\n* Condition1: Proximity to various conditions\n* Condition2: Proximity to various conditions (if more than one is present)\n* BldgType: Type of dwelling\n* HouseStyle: Style of dwelling\n* ... rest in the data description txt file","78529f48":"---\n### Multivariate Exploration\n##### Correlations","141dbc4a":"* adding basic features","05e49b2b":"---\n##### For MasVnrArea\n* Q: does the missing values mean MasVnrType = None ?\n* using MasVnrType.. we see","f57d7f03":"### Visualize Missing Values for each feature \n* [Test And Train] are seperated for better visualization","3ece728e":"---\n#### Univariate Exploration","13f766f4":"#### Helper Functions","54cc5db2":"---\n## Problem Statement :\n* This competition challenges you to predict the final price of each home.","9d1be2b2":"* same for BsmtFinSF1, BsmtFinSF2, BsmtUnfSF use 0.","075526b2":"### Imports","8f8f6772":"---\n#### Bivariate Exploration\n* Exploring each variable and their relation to the target variable\n    * Numerical Features we will use regression plots (~scatter plots with regression lines).\n    * Categroical Features we will use bar or count plots.","2641d337":"### Linear Regression","e0b0e787":"---\n#### I will use ordinal encoding technique for features that has some order depending on the data description text file  and using the  mean of the sale price \n* like (Fence quality, Pool quality,GarageCond: Garage condition ..)\n* other options like onehot encoding will be used for the rest.","1c1898ef":"* Rest..","fd56b8b4":"---\n##### For MSZoning\n* Q: what about MSZoning ?","a498a4d4":"* from the above i think the **NA values** in the lot frontage has the same  target (SalePrice) distribution of the **non NA values** in the lot frontage and hence the missing values can be considered missing randomly.\n* we can use methods of imputation like **median** since the distribution is right skewed.\n* by reading great notebooks from this competition the idea of using the median from Neighborhood makes more sense to use.","46975c63":"* from the data description text we find the following \n    * MSSubClass ,OverallQual,OverallCond ,MoSold, YrSold.","0c79dc0e":"---\n# Model Training","201ce879":"* from the above result the observations with NA match with No Basement at the BsmtExposure Column..\n* except for TotalBsmtSF\n* i will use 0 for BsmtFullBath,BsmtHalfBath with NA\n* for TotalBsmtSF we need a better reason as to why","0a7adf13":"### Ridge CV Regularization","58900cc5":"* Visualize the results ...","47ea5dc9":"* dropping outliers (from the train data)","335429a9":"---\n### Summary of Missing Data\n* we have 34 features with missing values \n    * (we will explore each one of them from the data description text file to see the reason why its missing!)\n---\n* PoolQC: Pool quality\t: NA => No Pool\n* MiscFeature: Miscellaneous feature not covered in other categories : NA => None\n* Alley: NA => No alley access\n* Fence : NA => No Fence     \n* FireplaceQu : NA => No Fireplace\n* **LotFrontage** : NA (no details on why its missing we will investigate it) maybe not having frontal connection to street?\n---\n* **GarageYrBlt**: NA (no details on why its missing we will investigate it) maybe no Garage.?\n* GarageType,GarageFinish,GarageQual,GarageCond ,GarageType: NA => No Garage\n* **GarageCars,GarageArea** = No Garage maybe?.\n---\n* BsmtFinType2,BsmtExposure,BsmtFinType1,BsmtCond,BsmtQual : NA => No Basement\n* **BsmtFullBath ,BsmtHalfBath** : no details but there might be no bathroom in basement?\n* **TotalBsmtSF : no basement?**\n* **BsmtFinSF1, BsmtFinSF2, BsmtUnfSF : no basement?** \n---\n* MasVnrType : NA -> None\n* **MasVnrArea** : no details about NA.\n* **MSZoning** : no details about NA.\n* **Utilities** :  no details about NA only 2 observations with missing values\n* **Functional** :  no details about NA only 2 observations with missing values\n* **Exterior2nd ,Exterior1st** : are the same missing observation.\n* **SaleType** : no details about NA.\n* **Electrical** : no details about NA.\n* **KitchenQual** : no details about the NA.\n","e14f7860":"##### Categorical Exploration","9062a351":"---\n##### For BsmtFullBath ,BsmtHalfBath ,TotalBsmtSF\n* Q: does the missing values mean no Basement?\n* using BsmtExposure(used because it has the highest percentage of missing) we know NA means No Basement ,lets compare..","19a816b2":"* fixing skeweness","d113a36e":"### Percentage of Missing Values for each feature  (%) in All Data","d28025e8":"--- \n### Investigate missing data ( not Having NA Definition in the data_description text file)","a52f97e9":"#### From the Previous Section we investigated most of the missing data .. now i will apply the following...\n* for all the data with NA description => will be filled with '_NONE_'\n* for the rest :\n    * use 0 for GarageCars,GarageArea , use oldest year built the GarageYrBlt\n    * using the median from Neighborhood for LotFrontage NA.\n    * use 0 for BsmtFullBath, BsmtHalfBath, TotalBsmtSF.\n    * use 0 for MasVnrArea..\n    * use most frequent MSZoning from Neighborhood for MSZoning.\n    * use most frequent Utilities, Functional ,Exterior1st ,Exterior2nd,SaleType,Electrical,KitchenQual","638766f7":"* i might use the most frequent MSZoning from Neighborhood like the lotfrontage idea.","411cf0be":"---\n## Data Visualization & Processing","0ef27acd":"* from the above result the observations with NA match with No Garage at the GarageType Column\n* i will use 0 for GarageCars,Area , and might use oldest the GarageYrBlt instead of zero which may introduce new skewness to the distribution of GarageYrBlt.","4b11e088":"---\n## Linear Regression Predictions","7679d498":"* Feature idea to indicate if there is a Garage or not for that house !","40725601":"---\n##### For GarageYrBlt , GarageCars, GarageArea\n* Q: does the missing values mean no Garage?\n* from GarageType we know NA means No Garage ,lets compare","8e9c7861":"* i may add interesting features later .. lets see model performance :)","af6ab48c":"### Cross Validation","251fddb7":"* Yes all of them have no area but.. interestingly we find a suspicious value for an observation that is assumed to be 0 for record 2611 \n* it makes no sense to have None Masonry vene but have an area for it. may be tried later..","5308ff6d":"* Great! now we have almost all the Variables encoded and fixed their linear relationship with Target","7ddbc833":"---\n##### For LotFrontage \n* Q: does it mean something having no lot frontage?\n* Q: what is the Sale Price Distribution for a house with NA lotFrontage vs a house with lotFrontage?","badab1c8":"---\n## Data Preparation","f20303b1":"---\n##### For Utilities,Functional,Exterior1st ,Exterior2nd,SaleType,Electrical,KitchenQual\n* these are 1 or 2 observations missing i will use the most frequent mostly for imputation.","2752d2d2":"* All data with NA Description","5b063f16":"* most of the linear relationships benefited from handling outliers and skewness ","3293639f":"* i think its safe to use 0 for TotalBsmtSF as apparently all basment values are 0!.","330001f4":"#### Finished Handling Missing Values\n---","79a84c7e":"* from the above some linear relationshipscan be further improved by proper handling to outliers and skewed distributions.\n* [LotFrontage > ~250] ,[MasVnrArea > ~1500] , [BsmtFinSF1 > 5000],[TotalBsmtSF > 5000] , [1stFlrSF > 4000]\n* [GrLivArea > ~5000]\n* another idea about summing total basement area, total floor area , OpenPorch+EnclosedPorch..etc is good to counter the problem of zeros which impact the linearity. "}}