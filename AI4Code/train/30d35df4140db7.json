{"cell_type":{"5c39df8f":"code","59a959c3":"code","b36d6602":"code","c3ab91e4":"code","2fb8cb0c":"code","97c6b565":"code","94d83f80":"code","cf8e8c41":"code","19782f6f":"code","6ade2992":"code","869edd6f":"code","4db491e7":"code","b26eee06":"code","9dccd5f7":"code","b2baddc1":"code","1003a24a":"code","36912400":"markdown","d0cac1e5":"markdown","54e7b1c8":"markdown"},"source":{"5c39df8f":"########################################## KAGGLE SPECIFIC CODE ####################################################\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n###################################################################################################################","59a959c3":"# Kaggle has peformed data acquisition for us, use it\nfrom sklearn.utils import shuffle\ndf = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")  # it has features and labels\nkaggle_competition_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")  # for the Kaggle competition; it features but has no labels!","b36d6602":"##### 3. data exploration using descriptive statistics and visualization\n# Some options:\n# 3a. find out for each feature: data type\n# 3b. find out for each feature: numerical, nominal categorical, ordinal categorical\n# 3c. heat map to find correlations between features and between features and target variable\n\n# just a pretty random tryout\nmen = df.loc[df.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nprint(\"% of men who survived:\", rate_men)\n\nmen = df.loc[df.Sex == 'female'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nprint(\"% of women who survived:\", rate_men)\n\ndf.head()","c3ab91e4":"print('\\n## Dataframe description')\ndf.describe()","2fb8cb0c":"df.info()","97c6b565":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.heatmap(df.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap=plt.cm.viridis, linecolor='white', linewidths=0.1)","94d83f80":"hidden = ['Age', 'PassengerId', 'Ticket', 'SibSp', 'Name', 'Embarked']\n\ndef convertDataSet(data):\n    data = shuffle(data)\n    data['Cabin'].fillna('U', inplace=True)\n\n    data['Sex'] = data['Sex'].map({'female':0, 'male':1})\n    data['Cabin'] = data['Cabin'].apply(lambda cabin: ord(cabin[0]))\n    return data\n\ndef filter(data):\n    return data.drop(hidden, 1)\n\ndf = convertDataSet(df)\nkaggle_competition_data = filter(convertDataSet(kaggle_competition_data))\n\nplt.figure(figsize=(10,7))\nsns.heatmap(df.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap=plt.cm.viridis, linecolor='white', linewidths=0.1)\n\ndf = filter(df)","cf8e8c41":"sns.heatmap(kaggle_competition_data.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap=plt.cm.viridis, linecolor='white', linewidths=0.1)","19782f6f":"# Correlation compared to survival rate. 1 to skip survived column (obvious 1:1)\ndf[df.columns[1:]].apply(lambda x: x.corr(df['Survived']))","6ade2992":"survived = df['Survived']\n# Drop labels\ntraining = df.drop('Survived', axis=1)\n# to remember what part is df and what part is kaggle_competition_data\ndf_len = len(df)\n\ntrain_X = training[:int(df_len * 0.6)]\nvalidation_X = training[int(df_len * 0.6):int(df_len * 0.8)]\ntest_X = training[int(df_len * 0.8):]\n\ntrain_y = survived[:int(df_len * 0.6)]\nvalidation_y = survived[int(df_len * 0.6):int(df_len * 0.8)]\ntest_y = survived[int(df_len * 0.8):]\n\n# add kaggle_competition_data to training\ntraining = pd.concat([training, kaggle_competition_data], axis=0)\n\ntrain_X = training[:int(df_len * 0.6)]\nvalidation_X = training[int(df_len * 0.6):int(df_len * 0.8)]\ntest_X = training[int(df_len * 0.8):df_len]\nkaggle_competition_data = training[df_len:]","869edd6f":"df['Pclass'].value_counts().plot(kind='bar', cmap=plt.cm.viridis)","4db491e7":"df['Sex'].map({1: 'female', 0: 'male'}).value_counts().plot(kind='bar', cmap=plt.cm.viridis)","b26eee06":"sns.heatmap(training.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap=plt.cm.viridis, linecolor='white', linewidths=0.1)","9dccd5f7":"# Based on the data exploration, let's skip the features 'PassengerId', 'Name', 'Ticket', 'Cabin'\nfeatures = train_X.columns\n# Can we use Cabin?\nfeatures = [f for f in features if f not in hidden]\ntrain_X = train_X[features]\nvalidation_X = validation_X[features]\ntest_X = test_X[features]\ntrain_X = train_X[features]\nkaggle_competition_X = kaggle_competition_data[features]  # renamed to kaggle_competition_X as we need kaggle_competition_data later","b2baddc1":"##### 6. modeling: model training\n# 6a. algorithm selection\n# 6b. hyperparameter tuning\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nfor n_estimators in [10, 100, 250, 500]:\n    for max_depth in [1, 5, 50]:\n        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=1)\n        model.fit(train_X, train_y)\n        predictions = model.predict(test_X)\n        accuracy = accuracy_score(test_y, predictions)\n        print('Accuracy of prediction using', n_estimators, 'estimators and a max depth of', max_depth, ':', accuracy)\n\nmodel = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=1)\nmodel.fit(train_X, train_y)\n\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import plot_roc_curve\n\nplot_confusion_matrix(model, test_X, test_y)\nplot_roc_curve(model, test_X, test_y)\n\nfrom sklearn.tree import plot_tree\nplt.figure(figsize=(50,15))\nplot_tree(model.estimators_[0], filled=True)\nplt.show()","1003a24a":"##### 7. modeling: model evaluation\npredictions = model.predict(train_X)\nprint('accuracy_score of prediction on train_data', accuracy_score(train_y, predictions))\n\npredictions = model.predict(test_X)\nprint('accuracy_score of prediction on test_data', accuracy_score(test_y, predictions))\n\npredictions = model.predict(validation_X)\nprint('accuracy_score of prediction on validation_data', accuracy_score(validation_y, predictions))","36912400":"## 3. Data exploration using descriptive statistics and visualization\n","d0cac1e5":"## 1. Problem description and objective\n* problem description: Titanic sank on maiden voyage after colliding with an iceberg, killing 2\/3 of the passengers\n* objective: predict if a passenger survived or not (binary classification problem)","54e7b1c8":"![Data Science Lifecycle](https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/team-data-science-process\/media\/overview\/tdsp-lifecycle2.png)\n\nPlease note that this is not a linear process. There will be iterations of the whole process but also of parts of the process.\n\nSteps of the data science lifecycle:\n1. problem description and objective\n\n2. data acquisition\n  * early negotiating data access with stakeholders too reduce risk\n  * storing the data securely and according to privacy regulations (GDPR)\n  * spend your time wisely. More data samples? More features? Artificially augment data?\n\n3. data exploration using descriptive statistics and visualization\n\n  some options:\n  * find out for each feature: data type\n  * find out for each feature: numerical, nominal categorical, ordinal categorical\n  * heat map to find correlations between features and between features and target variable\n\n4. data preprocessing \n  * dealing with mising data\n  * encode categorical features as dummy variables\n\n5. modeling: feature selection\n\n6. modeling: model training\n  * algorithm selection\n  * hyperparameter tuning\n\n7. modeling: model evaluation\n  * choosing evaluation metric\n  \n8. deployment of the model\n  * appify the model\n  * continuous monitoring of model performance\n"}}