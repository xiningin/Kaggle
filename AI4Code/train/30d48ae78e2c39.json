{"cell_type":{"bc080a3e":"code","85f351f1":"code","1ee1f67b":"code","ce24bba9":"code","87b3a0d0":"code","37308f9d":"code","662a99ee":"code","9d5f94f6":"markdown","e075bd7e":"markdown","367072ac":"markdown","993d25a7":"markdown","54f3ff17":"markdown","bcfaf24c":"markdown"},"source":{"bc080a3e":"# Importing the libraries\nprint('Importing libraries...')\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix\nimport datetime\nprint('Success!')\nprint('Natus Vincere CS:GO Win Predictor 0.02 by Ravehorn.')","85f351f1":"# Parameters of the call\ndef params(argument):\n    if argument == 'team_1':\n        return 'Natus Vincere'\n    elif argument == 'team_2':\n        return 'fnatic'\n    elif argument == '_map':\n        return 'Mirage'\n    elif argument == 'rank_1':\n        return 867\n    elif argument == 'rank_2':\n        return 583\n    raise NameError","1ee1f67b":"# Importing the dataset\nprint('Importing data...')\ndataset = pd.read_csv('..\/input\/csgo-professional-matches\/results.csv')\ndataset['date'] = pd.to_datetime(dataset['date'])\n_2019 = datetime.date(2019, 1, 1)\n_2019 = pd.to_datetime(_2019)\ndataset = dataset.loc[dataset['date'] >= _2019]\ndataset_p1 = dataset.loc[dataset['team_1'] == params('team_1')]\ndataset_p2 = dataset.loc[dataset['team_2'] == params('team_1')]\ndataset_p3 = dataset.loc[(dataset['team_1'] == params('team_2')) & (dataset['team_2'] != params('team_1'))]\ndataset_p4 = dataset.loc[(dataset['team_2'] == params('team_2')) & (dataset['team_1'] != params('team_1'))]\ndataset = pd.concat([dataset_p1, dataset_p2, dataset_p3, dataset_p4])\nX = dataset.iloc[:, [1, 2, 3, 14, 15]].values\ny = dataset.iloc[:, 6].values\nprint('Success!')","ce24bba9":"# Start function\ndef choice():\n    print('Starting to learn...')\n    user_choice = '1'\n    if user_choice == '1':\n        learn()\n    elif user_choice == '2':\n        print('Programm finished.')\n    else:\n        print('\\nYou probably pressed the wrong button, try again!')\n        choice()","87b3a0d0":"# Learning accuracy function, %\ndef accuracy():\n    global X\n    global y\n    print('Evaluating accuracy...')\n    # Encoding categorical data\n    onehotencoder = OneHotEncoder()\n    X_new = onehotencoder.fit_transform(X[:, 0:2]).toarray()\n    X_new = X_new[:, 1:]\n    X = X[:, [3, 4]]\n    X = np.concatenate((X, X_new), axis=1)\n\n    # Splitting the dataset into the Training set and Test set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n\n    # Fitting XGBoost\n    classifier = XGBClassifier(n_estimators=500, learning_rate=0.00001,\n                               max_depth=7, subsample=0.8, colsample_bytree=0.8, gamma=5)\n    classifier.fit(X_train, y_train)\n\n    # Predicting the Test set results\n    y_pred = classifier.predict(X_test)\n\n    # Making confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    cm_sum = cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1]\n    avg_acc = (cm[0][0] + cm[1][1]) \/ cm_sum * 100\n    # Returning average accuracy of the algorithm\n    return avg_acc","37308f9d":"# Main predict function\ndef learn():\n    global X\n    global y\n    team_1 = params('team_1')\n    team_2 = params('team_2')\n    rank_1 = params('rank_1')\n    rank_2 = params('rank_2')\n    _map = params('_map')\n    X_test = np.array([[team_1, team_2, _map, rank_1, rank_2]])\n    # Encoding categorical data\n    print('Encoding data...')\n    onehotencoder = OneHotEncoder()\n    X_new_transformed = onehotencoder.fit_transform(X[:, 0:2]).toarray()\n    X_new_transformed = X_new_transformed[:, 1:]\n    X_transformed = X[:, [3, 4]]\n    X_transformed = np.concatenate((X_transformed, X_new_transformed), axis=1)\n    X_test_new_transformed = onehotencoder.transform(X_test[:, 0:2]).toarray()\n    X_test_new_transformed = X_test_new_transformed[:, 1:]\n    X_test_transformed = X_test[:, [3, 4]]\n    X_test_transformed = np.concatenate((X_test_transformed, X_test_new_transformed), axis=1)\n    print('Success!')\n    print('Splitting the dataset...')\n    # Splitting the dataset into the Training set and Test set\n    X_train, X_test_old, y_train, y_test_old = train_test_split(X_transformed, y, test_size=1)\n    print('Success!')\n    print('Fitting XGBoost...')\n    # Fitting XGBoost\n    classifier = XGBClassifier(n_estimators=500, learning_rate=0.00001,\n                               max_depth=7, subsample=0.8, colsample_bytree=0.8, gamma=5)\n    classifier.fit(X_train, y_train)\n    print('Success!')\n    print('Predicting')\n    # Predicting\n    y_pred = classifier.predict(X_test_transformed)\n    print('Success!')\n    accuracy_final = accuracy()\n    # Predicting the Test set results\n    print(f'Accuracy of the algorithm: {accuracy_final}%')\n    if y_pred == 2:\n        print(f'Algorithm predicts that {team_1} will win {team_2}.')\n    elif y_pred == 1:\n        print(f'Algorithm predicts that {team_2} will win {team_1}.')\n    else:\n        print('An unexpected error has occured.')\n    print('Programm finished.')","662a99ee":"choice()","9d5f94f6":"I also wanted to say big thank you to [Mateus Dauernheimer Machado](https:\/\/www.kaggle.com\/mateusdmachado), who provided the dataset and helped me improve my model.","e075bd7e":"P.S. I also decided not to use the ELO algorithm, since it has certain drawbacks and is already implemented. From my understanding, ML, DL, ELO or MMR for example could underperform in 5v5 competitive games, such as CS:GO, Dota 2, etc, because of many factors. But I decided to try ML, because that is what brings me joy.\nI'm very happy that I tried and did this research.","367072ac":"**Thank you for trying out my model!**","993d25a7":"P.S. This is my first notebook and I'm new to machine learning. I know there may be a lot of bugs, issues, etc. And I would be very keen if somebody could help me, or criticise me, because I really want to get better. I'm always open to being criticised.\nIn the middle of the development, I realised that it's pretty hard to predict the outcome of the match even using ML algorithms (those I know, of course).\nThis is why I first calculated the function for evaluating overall model accuracy, and then I used it to predict the actual outcome of the match that could have possibly happened.\nDon't expect it to be higher than 70%. If it is higher - it may be biased and\/or overfitted (as far as I know for esports).","54f3ff17":"Again, big thanks to the database scraper, you gave me a wonderful opportunity to explore and learn!","bcfaf24c":"**This is XGBoost model that tries to predict whether NaVi CS:GO will win or lose their next match.**"}}