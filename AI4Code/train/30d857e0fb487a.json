{"cell_type":{"802ee8c9":"code","367b4fe7":"code","a74aed91":"code","8f472d50":"code","5b573dbf":"code","c2d4fbc9":"code","43ed95b6":"code","a627fc5d":"code","3dd73942":"code","7d6c04db":"code","640adfd9":"code","cf89f167":"code","d2958f74":"code","36bfeb66":"code","a617d722":"markdown","799e3174":"markdown","c3da746a":"markdown","5eb09fcc":"markdown","791c1d00":"markdown","14e4062c":"markdown","a4082b61":"markdown","525d6ebd":"markdown","c15c72d9":"markdown","49848079":"markdown"},"source":{"802ee8c9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","367b4fe7":"test_df= pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv')\nsub_df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\ndf= pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv')\ndisplay(df.sample(5))\nprint('shape of training dataset: ',df.shape)\nprint('shape of test dataset:     ',test_df.shape)\nprint('shape of sub sample:       ',sub_df.shape)","a74aed91":"df.target.hist();","8f472d50":"df.describe().T","5b573dbf":"df.info()","c2d4fbc9":"sns.heatmap(df.isnull(), cmap='Blues')","43ed95b6":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","a627fc5d":"df = reduce_mem_usage(df)\ntest_df = reduce_mem_usage(test_df)","3dd73942":"%%time\ndf.hist(figsize=(22,28))\nplt.show()","7d6c04db":"%%time\ndf.corr()","640adfd9":"!pip install -U lightautoml","cf89f167":"from lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task","d2958f74":"%%time\ntask = Task('binary')\nautoml = TabularAutoML(task = task, timeout = 8 * 3600, cpu_limit = 4, \n                       general_params = {'use_algos': [['cb']]}, \n                       selection_params = {'mode': 0})\noof_pred = automl.fit_predict(df, roles = {'target': 'target', 'drop': ['id']}, verbose = 2)\nsub_df['target'] = automl.predict(test_df).data[:, 0]","36bfeb66":"sub_df.to_csv('sub_light_AutoML.csv', index = False)","a617d722":"## Reducing memory usage on disk\/Ram","799e3174":"# What I found About the data in this Notebook:\n1. Data doesn't have any missing values\n2. Data is not correlated with each other nor with **target**\n\n## What does this notebook cover:\n1. EDA\n2. Size reduction of dataframe\n3. Tried LightAutoML","c3da746a":"### Data is not Correlated\nData isn't correlated to target or other features at all","5eb09fcc":"We don't having any missing data","791c1d00":"# Modeling with AutoMl","14e4062c":"# Visualizing the data","a4082b61":"Target is almost equally distributed!!!","525d6ebd":"## Observation\n1. All feature have -ve value in min except target and id.\n2. Mean is mostly in single digit for all features with 2 exceptions (f2: 306 & f35: 55)\n3. STD is mostly single digit or less except f2 and f35","c15c72d9":"Model credit goes to [This Notebook]('https:\/\/www.kaggle.com\/alexryzhkov\/lightautoml-november-21')","49848079":"## lets check the **distribution of target** feature"}}