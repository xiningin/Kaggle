{"cell_type":{"34330389":"code","951c26d7":"code","f81f17bd":"code","87f0d505":"code","ff87e81c":"code","2cd263ba":"code","cefdd07f":"code","56ded153":"code","988af9ce":"code","1476a8e2":"code","19facffe":"code","2cef140f":"code","8769e9fb":"code","8777478f":"code","a8dfea91":"code","e12c7b63":"code","e9e47514":"code","ba5f1f78":"code","b3637019":"code","aa13026e":"code","5871a062":"code","89c32ca4":"code","4a08680e":"code","50e93d81":"code","8594cc8d":"code","ad8f2a52":"code","c3bfec04":"code","62208fe7":"code","a3ee34b5":"code","102fdfc6":"code","cec9cdc0":"code","2a3fdbd8":"code","3071f62d":"code","81c3ae1b":"code","0ec93408":"code","e4a7ba2e":"code","d92059fe":"code","7321d776":"code","305ec2a0":"code","14a4f289":"code","001eb9c8":"code","65d0d0c1":"code","6a0ac28e":"code","4bb29fe5":"code","52000fd8":"code","8be6248d":"code","9d645d35":"code","bea2dba3":"code","04d52e9a":"code","885d8acf":"code","384eddb7":"code","49cbef73":"code","39400942":"code","848e262a":"markdown","2968ba7d":"markdown","48180fd5":"markdown","40df6e04":"markdown","177177d1":"markdown","61104a63":"markdown","9d32eefd":"markdown","db8d136d":"markdown","aa17f53b":"markdown","b73afa63":"markdown","5b36297e":"markdown","ac2c803c":"markdown","eb7d5d5f":"markdown","a5308126":"markdown","984e9351":"markdown","18b24f05":"markdown","4de82c4f":"markdown","fcbba35c":"markdown","7a3c0b02":"markdown","1258d233":"markdown","5e76fe25":"markdown","1587f861":"markdown","b79236df":"markdown","1a9750dd":"markdown","b9b4a0a0":"markdown","44947d9f":"markdown","a5952639":"markdown","61bda18c":"markdown","c9703b74":"markdown","f531944a":"markdown","49627243":"markdown","1ec078d5":"markdown","364a9009":"markdown","086f9731":"markdown","9115a097":"markdown","ce96e2bd":"markdown","b1498e4c":"markdown","ffcafb9b":"markdown","782f3723":"markdown","70f21b52":"markdown","a711ebe5":"markdown","82caa551":"markdown","5ae9fe47":"markdown","8c100f41":"markdown","55338710":"markdown","4d30e89a":"markdown","fbf3893f":"markdown","bff7ba13":"markdown","8745ec84":"markdown","76973144":"markdown","07b72dac":"markdown","351c51cc":"markdown","d779b264":"markdown","04cdcb8e":"markdown","c9d068ff":"markdown","d32582ad":"markdown","aa34cfe5":"markdown","0a818c37":"markdown","9c7ba70b":"markdown","5d713d98":"markdown"},"source":{"34330389":"import pandas as pd\nimport numpy as np\nimport math\nimport time\nfrom tqdm import tqdm\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nfrom sklearn.metrics import mean_absolute_error\n\nnp.random.seed(123)","951c26d7":"def linear_trend(t, k=1):\n    \"\"\"\n    linear_trend = k*t\n    \"\"\"\n    return k*t.reshape(-1,1)\n\ndef cyclical_component_1(t):\n    \"\"\"\n    cyclical_component_1 = t * sin(t) + 200 + NormalNoise(0, t\/3)  \n    \"\"\"\n    noise = t\/3 * np.random.randn(t.shape[0])\n    f = lambda t: t * np.sin(t) + 200\n    vfunc = np.vectorize(f)\n    f_time = vfunc(t)\n    return (f_time+noise).reshape(-1,1)\n\ndef cyclical_component_2(t, period):\n    \"\"\"\n    cyclical_component_2 = 100 * sin(t \/\/ period) + 2*t\n    \"\"\"\n    f = lambda t: 100 * np.sin(t \/\/ period) + 100 + 2*t\n    vfunc = np.vectorize(f)\n    f_time = vfunc(t)\n    return f_time.reshape(-1,1)\n\ndef target_ts(features):\n    \"\"\"\n    target_ts = averaged sum of features\n    \n    returns: y = 1\/n * Sum  exogenous_i\n    \"\"\"\n    a = (np.ones(features.shape[1])\/features.shape[1]).reshape(-1,1)\n    y = features @ a\n    return y","f81f17bd":"t = np.arange(0, 200)\nexog = pd.DataFrame(\n    np.concatenate([linear_trend(t, 0.3), cyclical_component_1(t), cyclical_component_2(t, period=2)], axis = 1),\n    columns=['linear_trend', 'cyclical_component_1', 'cyclical_component_2'])\n\ny = pd.DataFrame(target_ts(exog.values), columns=['y'])","87f0d505":"fig, ((ax1, ax2, ax3,)) = plt.subplots(1, 3, figsize=(10, 5))\nfig.subplots_adjust(top=2, bottom=1, right=2, left=0, wspace=0.2)\n\nax1.plot(t, exog['linear_trend'])\nax1.set_title(\"Exogenous feature 1: linear_trend\", fontsize=20)\n\nax2.plot(t, exog['cyclical_component_1'])\nax2.set_title('Exogenous feature 2: cyclical_component_1', fontsize=20)\n\nax3.plot(t, exog['cyclical_component_2'])\nax3.set_title('Exogenous feature 3: cyclical_component_2', fontsize=20)\nplt.show()\n\nplt.figure(figsize=(14, 6))\nplt.plot(t, y['y'])\nplt.title('Target: average of features', fontsize=20)\nplt.show()","ff87e81c":"y[\"ds\"] = pd.date_range(start='1\/1\/2018', periods=len(y), freq='M')","2cd263ba":"y.head()","cefdd07f":"exog[\"ds\"] = pd.date_range(start='1\/1\/2018', periods=len(exog), freq='M')","56ded153":"exog.head()","988af9ce":"N = 100\n\ny_train = y.iloc[:N]\ny_test = y.iloc[N:]\n\nexog_train = exog.iloc[:N]\nexog_test = exog.iloc[N:]","1476a8e2":"del y_test[\"y\"]","19facffe":"y_train.head()","2cef140f":"exog_train.head()","8769e9fb":"data_train_joined_2_regressor = pd.merge(y_train, exog_train[['linear_trend', 'cyclical_component_1', 'ds']], on = \"ds\")\ndata_test_joined_2_regressor = pd.merge(y_test, exog_test[['linear_trend', 'cyclical_component_1', 'ds']], on = \"ds\")\n\n# Take first 3 points for prediction\ndata_test_joined_2_regressor = data_test_joined_2_regressor[:10].copy()\n\nprint('Train shape: {0}'.format(data_train_joined_2_regressor.shape))\nprint(\"Test shape: {0}\".format(data_test_joined_2_regressor.shape))","8777478f":"data_train_joined_2_regressor.head()","a8dfea91":"data_test_joined_2_regressor","e12c7b63":"from fbprophet import Prophet\n\nmodel = Prophet(n_changepoints=1)","e9e47514":"model.add_seasonality(name='yearly', period=365, fourier_order=1, prior_scale=0.1, mode='multiplicative') \nmodel.add_seasonality(name='monthly', period=30, fourier_order=1, prior_scale=0.1, mode='multiplicative')","ba5f1f78":"model.add_regressor('linear_trend', mode=\"multiplicative\")\nmodel.add_regressor('cyclical_component_1', mode=\"additive\")","b3637019":"model.fit(data_train_joined_2_regressor)","aa13026e":"forecast = model.predict(data_test_joined_2_regressor)","5871a062":"forecast.head()","89c32ca4":"fig1 = model.plot(forecast)","4a08680e":"fig2 = model.plot_components(forecast)","50e93d81":"model.params","8594cc8d":"df_train = model.setup_dataframe(data_train_joined_2_regressor)\ndf_train.head(5)","ad8f2a52":"df_test = model.setup_dataframe(data_test_joined_2_regressor)\ndf_test.head(5)","c3bfec04":"# Start of the time\nstart = data_train_joined_2_regressor[\"ds\"].min()\n\n# Timedelta to the end of training data\nt_scale = data_train_joined_2_regressor[\"ds\"].max() - start \n\n# scaled time to the range [0, 1]\nt = ((data_test_joined_2_regressor[\"ds\"] - start) \/ t_scale).values\nprint(\"Standartized time: {0}\".format(t))","62208fe7":"print(\"Standartized time by prophet: {0}\".format(df_test[\"t\"].values))","a3ee34b5":"mu_train = data_train_joined_2_regressor['linear_trend'].mean()\nstd_train = data_train_joined_2_regressor['linear_trend'].std()\n\nprint(\"Standartized f1 regressor by our calculations: {0}\".format(\n    ((data_test_joined_2_regressor['linear_trend'] - mu_train) \/ std_train).values))","102fdfc6":"print(\"Standartized f1 regressor by prophet: {0}\".format(df_test[\"linear_trend\"].values))","cec9cdc0":"changepoint_ts = model.changepoints_t\nprint(\"Changepoints: {0}\".format(changepoint_ts))","2a3fdbd8":"# Just extracted the indices of the minimum and maximum\ni0, i1 = df_train['ds'].idxmin(), df_train['ds'].idxmax()\n\n# Calculate the time difference for a standardized time\nT = df_train['t'].iloc[i1] - df_train['t'].iloc[i0] \n\n# Calculate k\nk = (df_train['y_scaled'].iloc[i1] - df_train['y_scaled'].iloc[i0]) \/ T\n\n# Calculate m\nm = df_train['y_scaled'].iloc[i0] - k * df_train['t'].iloc[i0]\n\nprint(\"initial value for k: {0}\".format(k))\nprint(\"initial value for m: {0}\".format(m))","3071f62d":"k = np.nanmean(model.params['k'])\nm = np.nanmean(model.params['m'])\n\nprint(\"Value for k after stan optimization: {0}\".format(k))\nprint(\"Value for m after stan optimization: {0}\".format(m))","81c3ae1b":"deltas = np.nanmean(model.params['delta'], axis = 0)\ngammas = -changepoint_ts * deltas","0ec93408":"gammas = -changepoint_ts * deltas\n\nk_t = k * np.ones_like(t)\nm_t = m * np.ones_like(t)\n\nfor s, t_s in enumerate(changepoint_ts):\n    indx = t >= t_s\n    k_t[indx] += deltas[s]\n    m_t[indx] += gammas[s]\n\ntrend = k_t * t + m_t","e4a7ba2e":"floor = 0\ntrend = trend * model.y_scale + floor","d92059fe":"print(\"Manually calculated trend: {0}\".format(trend))","7321d776":"print(\"Trend calculated by Prophet: {0}\".format(forecast.trend.values))","305ec2a0":"seasonal_components = model.predict_seasonal_components(df_test)\nseasonal_components.head()","14a4f289":"seasonal_features, _, component_cols, _ = model.make_all_seasonality_features(df_test)","001eb9c8":"seasonal_features.head()","65d0d0c1":"t = np.array(\n    (data_test_joined_2_regressor[\"ds\"] - pd.datetime(1970, 1, 1))\n    .dt.total_seconds()\n    .astype(np.float)\n) \/ (3600 * 24.)\nprint(\"Time in month passed from 01.01.1970 for every test point: {0}\".format(t))","6a0ac28e":"model.seasonalities","4bb29fe5":"period = model.seasonalities['yearly'][\"period\"]\nseries_order = model.seasonalities[\"yearly\"][\"fourier_order\"]\n\nnp.column_stack([\n    fun((2.0 * (i + 1) * np.pi * t \/ period))\n    for i in range(series_order)\n    for fun in (np.sin, np.cos)\n])","52000fd8":"component_cols","8be6248d":"# Extract the data\nX = seasonal_features.values\n\n# For each seasonal component we calculate\nfor component in component_cols.columns:\n    \n    # Here, in fact, we leave the beta non-zero only in those positions where we have 1\n    # This is equivalent to the fact that we just made up a mask so that later in the matrix seasonal_features take\n    # only the parameters we need\n    beta_c = model.params['beta'] * component_cols[component].values\n    \n    # This is a basic dot product, that is, for each date it's easy\n    # multiply the scaled value by the trained beta and add\n    # only the parameters that we need\n    comp = np.matmul(X, beta_c.transpose())\n    \n    # If we have additive feature, then we should scale, that is also obvious\n    if component in model.component_modes['additive']:\n         comp *= model.y_scale\n    \n    # Exactly this will be in  'multiplicative' and 'additive'\n    df_test[component] = np.nanmean(comp, axis=1)","9d645d35":"df_test","bea2dba3":"additive_terms = model.params[\"beta\"].squeeze()[5] * seasonal_features[\"cyclical_component_1\"] * model.y_scale\nprint(\"Manually calculated additive terms: {0}\".format(additive_terms.values))","04d52e9a":"print(\"Additive terms calculated by Prophet: {0}\".format(\n    seasonal_components[\"additive_terms\"].values))","885d8acf":"multiplicative_terms = (model.params[\"beta\"].squeeze()[0] * seasonal_features[\"yearly_delim_1\"] + \n        model.params[\"beta\"].squeeze()[1] * seasonal_features[\"yearly_delim_2\"] + \n        model.params[\"beta\"].squeeze()[2] * seasonal_features[\"monthly_delim_1\"] + \n        model.params[\"beta\"].squeeze()[3] * seasonal_features[\"monthly_delim_2\"] + \n        model.params[\"beta\"].squeeze()[4] * seasonal_features[\"linear_trend\"])\nprint(\"Manually calculated multiplicative terms: {0}\".format(multiplicative_terms.values))","384eddb7":"print(\"Multiplicative terms calculated by Prophet: {0}\".format(\n    seasonal_components[\"multiplicative_terms\"].values))","49cbef73":"prediction = trend * (1 + multiplicative_terms) + additive_terms\nprint(\"Manually calculated prediction: {0}\".format(prediction.values))","39400942":"forecast = model.predict(data_test_joined_2_regressor)\nprint(\"Prediction calculated by Prophet: {0}\".format(forecast[\"yhat\"].values))","848e262a":"**Add two seasonal components with multiplicative mode**","2968ba7d":"# What is the Prophet model?","48180fd5":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/trend_k_m.png\" width=\"100%\">","40df6e04":"# Example of Prophet model with two exogenous features and two seasonal components","177177d1":"As we can see we have obtained the same result.","61104a63":"Prophet requires data with specific format. The input to Prophet is always a dataframe with two columns: ds and y.\n- The ds (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp\n- The y column must be numeric, and represents the measurement we wish to forecast.","9d32eefd":"# Synthetic data generation","db8d136d":"At first Prophet transforms dataframe to the special format (we use prophet's function) - it just takes initial dataframe and does some transformations and preprocessing: \n- scaling of the target (y_scaled), \n- creates columns \"t\", that is just scale of time to range \\[0, 1\\], \n- standartization of exogenous features (subtraction of training mean and division by training variance per feature)","aa17f53b":"### Next step is to obtain $k$ and $m$ as initial points for stan optimization","b73afa63":"**Add one regressor with multiplicative mode and one regressor with additive mode**","5b36297e":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/trend_middle.png\" width=\"100%\">","ac2c803c":"**So, we obtained standartization of features and time, using parameters $\\mu$ and $\\sigma$ that were calculated using train data.**","eb7d5d5f":"<img src=\"https:\/\/github.com\/uselessskills\/auto_ml\/blob\/master\/Prophet_analysis\/pngs\/multiplicative_product_new.png?raw=true\" width=\"100%\">","a5308126":"Let's check standartization of the regressors","984e9351":"<img src=\"https:\/\/github.com\/uselessskills\/auto_ml\/blob\/master\/Prophet_analysis\/pngs\/final_product.png?raw=true\" width=\"100%\">","18b24f05":"**Below we calculate the fourier coefficients for yearly seasonal component**","4de82c4f":"**As we can see our manual prediction by Prophet completely formula coincides with Prophet model output!**","fcbba35c":"### Fit model","7a3c0b02":"Were obtained the same coefficients (as in seasonal_features) and the regressor is also the same.","1258d233":"Extract the changepoint obtained for standartized time","5e76fe25":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/additive_terms_new.png\" width=\"100%\">","1587f861":"### Destandartization trend component (in our case we have lower bound  - parameter floor - is equal to zero)","b79236df":"### Calculate deltas and gammas","1a9750dd":"**Create train and test datasets with two exogenous regressors**","b9b4a0a0":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/stan.png\" width=\"100%\">\n\nWhere by $s_m$ and $s_a$ we denote coefficients (fourier coefficients and standartized regressor values) for multiplicative and additive terms respectively.","44947d9f":"Next step is to calculate seasonal_components. To do this we will explore prophet functions, that are used to predict seasonal components.","a5952639":"**Prepare dataframe of exogenous regressors with the same dates**","61bda18c":"Create t, to calculate fourier series","c9703b74":"It's just a cross-tab matrix that shows for each feature what columns it met in seasonal_matrix + there we  added some special names to distinguish between regressors and not regressors and so on. \n\nNow we understand how to take into account \"additive_terms\" and \"multiplicative_terms\" for the final prediction. Note that these two columns will always be in obtained dataframes for seasonal components, and their sum will always be equal to 1.\n","f531944a":"### Now we will understand how to obtain the matrix component_cols","49627243":"Prophet prediction is a dataframe, where target prediction sits in 'yhat' column, prediction interval bounded by 'yhat_lower' and 'yhat_upper'. The rest columns contains predictions of trend, additive and multiplicative terms and copy of features that were argument in the prediction method.","1ec078d5":"# Import packages","364a9009":"Let us denote by $r_1$, $r_2$ standartized value for regressor $f_1$ anf $f_2$ respectively.\n$\\phi_{sin_Y}$, $\\phi_{cos_Y}$ denotes the fourier coefficient for yearly seasonal component.\n$\\phi_{sin_M}$, $\\phi_{cos_M}$ denotes the fourier coefficient for monthly seasonal component.\n\n- **Then the multiplicative term in this case will be just $\\phi_{sin_Y} * \\beta_{0} + \\phi_{cos_Y} * \\beta_{1}$ + $\\phi_{sin_M} * \\beta_{2} + \\phi_{cos_M} * \\beta_{3} + r_1 * \\beta_4$**\n\n- **And additive will be $r_2 \\beta_5$**\n\nLet's check this:","086f9731":"Let's check standartization of the time","9115a097":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/fourier_new.png\" width=\"50%\">","ce96e2bd":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/trend_gamma_delta.png\" width=\"100%\">","b1498e4c":"## Check model prediction manually ","ffcafb9b":"### Make a prediction","782f3723":"**Additive \u0438 multiplicative are the same. So, the final prediction is:**","70f21b52":"# Train-test split","a711ebe5":"## Final prediction","82caa551":"Prophet model has 5 training parameters: \n- $k$ - base trend, \n- $m$ - offset parameter, \n- $\\delta = \\{\\delta_i\\}_{i = 0}^{\\#changepoints}$ - changing of trend in changepoints, \n- $\\beta = \\{ \\beta_i\\}_{i = 0}^{Z}$ - parameters for Fourier series (seasonal component) and extra regressors (exogenous features), where $Z = 2 * \\sum_{i: \\text{seasonal-features}}\\left(\\text{Seasonal-order}(i) \\right)+ \\# \\{\\text{exogenous regressors}\\}$, \n- $\\sigma$ - level of noise,\n- $mu_{\\text{train}}$, $std_{\\text{train}}$ - mean and std value, calculated for each the $i$-th regressor on train. \n\nFormula above doesn't take into account some detailes, for example that time is standartized.\n\n","5ae9fe47":"# About this notebook\n\nIn this notebook we analyze how Prophet creates predictions. \nWe start from training Prophet model on synthetic data and then we go step-by-step through prediction process.\n\nThis tutorial was created during my internship in Deloitte Analytics Institute (Moscow office) https:\/\/cisdai.ru\/en\/.   \n\nI appreciate the help of the following people: Kirill Tsyganov, Alexey Kozionov, Alexander Andreev, Jaroslav Bologov, Nurlan Shagadatov.  \n","8c100f41":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/changepoints_prior_scale.png\" width=\"100%\">\nThis image was taken from original Facebook Prophet documentation, see https:\/\/facebook.github.io\/prophet\/docs\/trend_changepoints.html","55338710":"<img src=\"https:\/\/github.com\/uselessskills\/auto_ml\/blob\/master\/Prophet_analysis\/pngs\/additive_product_new.png?raw=true\" width=\"100%\">","4d30e89a":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/multiplicative_terms_new.png\" width=\"100%\">","fbf3893f":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/final_formula_new.png\" width=\"100%\">","bff7ba13":"Parameter **changepoint_prior_scale** affects only in MCMC mode. \nChangepoint_prior_scale is used as initial parameter $\\tau$ for prior for $delta$  ~ $Laplace(0, \\tau)$. Stan optimization uses priors for optimization procedure, that obtains estimation on parameters. \n\nIn the case when we set changepoint_prior_scale is equal to 0.5, we have more flexibility for prior for $\\delta$ in opposite to changepoint_prior_scale=0.001 . And this will influence on estimation of this parameter. This effect we see on the plot.","8745ec84":"**We have obtained the same additive terms**","76973144":"# Data preprocessing for Prophet","07b72dac":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/trend_full.png\" width=\"100%\">","351c51cc":"Let's make a Prophet model in which we will make a prediction for the first three points from the test data. \n1. We consider **two multiplicative seasonal components** (yearly, montly) with fourier order is equal to one\n2. We add **two exogenous regressors** (out of three that were used to create target (y) time-series): one with multiplicative mode, another one with additive mode.","d779b264":"**After stan optimization we will have the following parameters.**","04cdcb8e":"In the dataframe seasonal features we have the following data:\n- First two columns are responsable for yearly seasonal component, and so we have fourier coefficients in this columns for yearly component. \n- In The 3rd and the 4-th columns fourier coefficient for monthly seasonal component, and finally in the 5-th and the 6-th columns we have just standartized regressors.\n\n\n**Formulas for calculating coefficients in the columns, that are responsible for seasonal components (this formulas for columns for one seasonal component):**\n$$\nA[i, j] = [\\text{j is even}]*Cos(2 \\pi i (j + 1) \/ period) + [\\text{j is odd}]*Sin(2 \\pi i (j + 1) \/ period)\n$$\n\nwhere $i$ is a time index and $j$ is a fourier order for the component","c9d068ff":"Create model with only one changepoint","d32582ad":"# Multiplicative and additive terms","aa34cfe5":"<img src=\"https:\/\/raw.githubusercontent.com\/uselessskills\/auto_ml\/master\/Prophet_analysis\/pngs\/changepoints_process.png\" width=\"100%\">\nThis image was taken from original Facebook Prophet documentation, see https:\/\/facebook.github.io\/prophet\/docs\/trend_changepoints.html","0a818c37":"The code below describes how to calculate complete trend component of prediction","9c7ba70b":"**Remove target variable from the test dataset**","5d713d98":"## Prophet model initializiation"}}