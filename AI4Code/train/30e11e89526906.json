{"cell_type":{"8f38856f":"code","e6bba9ae":"code","f1ff5373":"code","47eed077":"code","ddd19699":"code","88550a7f":"code","04caaf20":"code","2f64af81":"code","bcf84753":"code","2fafbe10":"code","6fa59d07":"code","0c4955cb":"markdown","a8b950dc":"markdown","24c73623":"markdown","86ac8809":"markdown","f5e20ec8":"markdown","7616820a":"markdown","ef7d3864":"markdown","b85867f0":"markdown","9e51e0ae":"markdown"},"source":{"8f38856f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e6bba9ae":"!pip install ..\/input\/installs\/tensorboard-2.2.0-py3-none-any.whl -qqq\n!pip install ..\/input\/installs\/pytorch_lightning-0.9.0-py3-none-any.whl -qqq","f1ff5373":"import pytorch_lightning as pl\nimport torch\n\nprint(f'PyTorch Lightning: {pl.__version__}')\nprint(f'PyTorch: {torch.__version__}')","47eed077":"# IMPORTS\nimport os\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn.functional as F\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom sklearn.model_selection import train_test_split\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n","ddd19699":"# CONFIG\n\n# Data\nclass config:\n    DATA_DIR = '..\/input\/lish-moa\/'\n    # MLP Training\n    BATCH_SIZE = 32\n    EPOCHS = 10\n    LR = 3e-4\n    MOMENTUM = 0.9\n    NUM_CLASSES = 206\n","88550a7f":"# DATASET\n\nclass MOADataset():\n    def __init__(self, root, key='train'):\n        self.data_dir = os.path.join(os.path.expanduser(root))\n\n        # key - train or valid or test\n        self.key = key\n        self.df, self.target = self.process_df()\n        self.df = self.df.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)\n        self.target = self.target.drop(['sig_id'], axis=1)\n\n    def __getitem__(self, index):\n        row, target = self.df.iloc[index].values, self.target.iloc[index].values\n        return torch.from_numpy(row).float(), torch.from_numpy(target).long()\n\n    def __len__(self):\n        return len(self.df)\n\n    def process_df(self):\n        if self.key == 'train':\n            features = pd.read_csv(os.path.join(self.data_dir, 'train_features.csv'))\n            labels = pd.read_csv(os.path.join(self.data_dir, 'train_targets_scored.csv'))\n            features, _, labels, _ = train_test_split(\n                features,\n                labels,\n                test_size=0.2,\n                random_state=0,\n            )\n        elif self.key == 'valid':\n            features = pd.read_csv(os.path.join(self.data_dir, 'train_features.csv'))\n            labels = pd.read_csv(os.path.join(self.data_dir, 'train_targets_scored.csv'))\n            _, features, _, labels = train_test_split(\n                features,\n                labels,\n                test_size=0.2,\n                random_state=0,\n            )\n        elif self.key == 'test':\n            features = pd.read_csv(os.path.join(self.data_dir, 'test_features.csv'))\n            labels = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n\n        return features, labels\n\n\nclass MOADataModule(pl.LightningDataModule):\n    def __init__(self, data_dir, batch_size, num_classes):\n        super().__init__()\n\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.num_classes = num_classes\n\n    def prepare_data(self):\n        pass\n\n    def setup(self, stage=None):\n        if stage == 'fit':\n            self.tabular_train = MOADataset(\n                self.data_dir,\n                key='train',\n            )\n            self.tabular_valid = MOADataset(\n                self.data_dir,\n                key='valid',\n            )\n\n            assert self.tabular_train.df.shape[1] == self.tabular_valid.df.shape[1]\n            self.num_features = self.tabular_train.df.shape[1]\n\n        if stage == 'test' or stage is None:\n            self.tabular_test = MOADataset(\n                self.data_dir,\n                key='test',\n            )\n\n    def train_dataloader(self):\n        return DataLoader(self.tabular_train, batch_size=self.batch_size, shuffle=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.tabular_valid, batch_size=self.batch_size, shuffle=False)\n\n    def test_dataloader(self):\n        return DataLoader(self.tabular_test, batch_size=self.batch_size, shuffle=False)\n","04caaf20":"# MODEL\n\nclass MOAModel(pl.LightningModule):\n    def __init__(self, num_features, num_classes, learning_rate=2e-4, hidden_size=64):\n\n        super().__init__()\n\n        self.hidden_size = hidden_size\n        self.learning_rate = config.LR\n\n        # Build model\n        self.model = nn.Sequential(\n            nn.Linear(num_features, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_size, num_classes),  # batchsize x num_classes\n        )\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n    def forward(self, x):\n        x = self.model(x)\n        return x  # batchsize x num_classes\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y.type_as(y_hat))\n        result = pl.TrainResult(minimize=loss)\n        result.log('train_loss', loss, prog_bar=True)\n        return result\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y.type_as(y_hat))\n        result = pl.EvalResult(checkpoint_on=loss)\n        result.log('val_loss', loss, prog_bar=True)\n        return result\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        preds = F.sigmoid(logits)\n        result = pl.EvalResult()\n        result.write('preds', preds, filename='predictions.pt')\n        return result\n\n","2f64af81":"# TRAINING\nDATA_DIR = config.DATA_DIR\n\npl.seed_everything(1234)\n\ndm = MOADataModule(\n    data_dir=DATA_DIR,\n    batch_size=config.BATCH_SIZE,\n    num_classes=config.NUM_CLASSES,\n)\ndm.setup(stage='fit')\nmodel = MOAModel(dm.num_features, dm.num_classes)","bcf84753":"# add multiple loggers\ntb_logger = pl.loggers.TensorBoardLogger('tb_logs\/', name='default')\ncsv_logger = pl.loggers.CSVLogger('csv_logs\/', name='default')\n\ntrainer = pl.Trainer(\n    # fast_dev_run=config.DEBUG,\n    # num_sanity_val_steps=5,\n    # limit_train_batches=5,\n    # limit_val_batches=5,\n    # limit_test_batches=5,\n    gpus=(1 if torch.cuda.is_available() else 0),\n    max_epochs=config.EPOCHS,\n    progress_bar_refresh_rate=30,\n    weights_summary='top',\n#     logger=[tb_logger, csv_logger],\n)\n\ntrainer.fit(model, datamodule=dm)","2fafbe10":"# TESTING\n\ntrainer.test(model=model, datamodule=dm)","6fa59d07":"sample_submission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')\nsample_cols = list(sample_submission.columns)[1:]\n\npred_values = torch.load('predictions.pt')\npreds = pd.DataFrame([x['preds'] for x in pred_values], columns=sample_cols)\n\nsubmission = pd.concat([sample_submission[['sig_id']], preds], axis=1)\nsubmission.head()\n\nsubmission.to_csv('submission.csv', index=False)","0c4955cb":"## INFERENCE","a8b950dc":"## DATASET","24c73623":"## CONFIG","86ac8809":"## Installs\nThis kernel needs to have Internet Off. So have to upload wheel files and install them manually :(","f5e20ec8":"## TODO:\n\n- [x] PyTorch Lightning Baseline\n- [ ] Handle the Categorical Cols (cp_type, cp_time, cp_dose) as Dummies or Embeddings\n- [ ] Multilabel Stratified Split for Validation dataset\n- [ ] K-fold CV\n- [ ] Better Architecture","7616820a":"## MODEL","ef7d3864":"TRAINING","b85867f0":"# MOA Submission with PyTorch Lightning","9e51e0ae":"## SUBMISSION"}}