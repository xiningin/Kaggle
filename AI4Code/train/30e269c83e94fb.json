{"cell_type":{"ea5bf990":"code","14b05991":"code","9d5c2c84":"code","02aeebe3":"code","7d0abff2":"code","a71b7357":"code","31f961bb":"code","dee4dd91":"code","c7fb0d52":"code","3588da79":"code","56497b13":"code","25415fef":"code","00440c3e":"code","311503d0":"code","a79404cb":"code","b9ba7e6e":"code","4e9325a8":"code","6eff17ab":"code","897c318a":"code","40d6b36b":"code","74dc5425":"code","9dbe13ca":"code","73931cea":"code","0036b6f0":"code","c9f64f5a":"code","ce10aab5":"code","5ecbf8b4":"code","3a2e1269":"code","686154aa":"code","949b3d1e":"code","b6694015":"code","fa8b8a39":"code","8ed8ccca":"code","e77de623":"code","3e0184b1":"code","7cf0eeac":"code","6435d233":"code","76219e16":"code","1dc76ef0":"code","e55dee23":"code","7da03347":"code","e54a1aa5":"code","03bcbb37":"code","6ae25e2c":"code","0c8a41ae":"code","b455fd2c":"code","b04c2a09":"code","6f3da9a7":"code","65a5de9e":"code","8b5586b5":"code","7e78586d":"code","c6b64983":"code","0f7bbe89":"code","c22bd90f":"markdown","3aad596d":"markdown","f755c418":"markdown","69609e7d":"markdown","d752a3fa":"markdown","cf398735":"markdown","af95b6f7":"markdown","9551d30a":"markdown","adc0dfda":"markdown","2efa1b2d":"markdown","04bbc26a":"markdown","1ba1bce6":"markdown","dd558b8a":"markdown","17b7df06":"markdown","a2ac220e":"markdown","8b13efc8":"markdown","2cfdb21d":"markdown","a6f44d0f":"markdown","d8bafb69":"markdown","0552d65c":"markdown","d7056270":"markdown","3062a418":"markdown","030096b2":"markdown","b0a97f4c":"markdown","5991e7c0":"markdown","6b5fa155":"markdown","ed2d9b11":"markdown","c64d394d":"markdown","2b47e97a":"markdown","c53b6849":"markdown","4ece5fc2":"markdown","a5c7390c":"markdown","f453fbf7":"markdown","6ca09b1a":"markdown","e5329150":"markdown","25f6f991":"markdown","c53fbf61":"markdown","bf9c9fb3":"markdown","bdbf1ce5":"markdown","270873d0":"markdown"},"source":{"ea5bf990":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14b05991":"# data analysis and wrangling\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","9d5c2c84":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","02aeebe3":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","7d0abff2":"concatenate=[train_data,test_data]","a71b7357":"print(train_data.columns)\nprint(train_data.info())\nprint(test_data.info())","31f961bb":"# Only object columns\ntrain_data.describe(include=['O'])","dee4dd91":"train_data[['Pclass','Survived']].groupby('Pclass').mean()","c7fb0d52":"train_data[['Sex','Survived']].groupby('Sex').mean()","3588da79":"train_data[['SibSp','Survived']].groupby('SibSp').mean().sort_values(by='Survived',ascending=False)","56497b13":"train_data[['Parch','Survived']].groupby('Parch').mean().sort_values(by='Survived',ascending=False)","25415fef":"v=sns.FacetGrid(train_data,col='Survived')\nv.map(plt.hist,'Age',bins=10,color='red')","00440c3e":"v=sns.FacetGrid(train_data,col='Survived',row='Pclass')\nv.map(plt.hist,'Age',bins=10,color='green')\nv.add_legend()","311503d0":"v=sns.FacetGrid(train_data,col='Survived',row='Pclass')\nv.map(sns.scatterplot,'Age','Sex',color='orange')\nv.add_legend()","a79404cb":"v=sns.FacetGrid(train_data,row='Embarked')\nv.map(sns.pointplot,'Pclass','Survived','Sex')\nv.add_legend()","b9ba7e6e":"v=sns.FacetGrid(train_data,col='Survived')\nv.map(sns.barplot,'Fare')\nv.add_legend()","4e9325a8":"train_data=train_data.drop(['PassengerId','Ticket','Cabin'],axis=1)\ntest_data=test_data.drop(['Ticket','Cabin'],axis=1)\n","6eff17ab":"concatenate=[train_data,test_data]","897c318a":"for dataset in concatenate:\n    dataset['Title']=dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n    \npd.crosstab(train_data['Title'],train_data['Sex'])\n# train_data['Title'].unique().tolist()","40d6b36b":"for dataset in concatenate:\n    dataset['Title']=dataset['Title'].replace('Ms','Miss')\n    dataset['Title']=dataset['Title'].replace('Mme','Miss')\n    dataset['Title']=dataset['Title'].replace('Mlle','Miss')\n    dataset['Title']=dataset['Title'].replace('Sir','Mr')\n    dataset['Title']=dataset['Title'].replace(['Col','Don','Rev','Dr','Major','Lady','Capt','Countess','Jonkheer','Dona'],'uncommon')\n    \ntrain_data[['Title','Survived']].groupby('Title').mean().sort_values(by='Survived',ascending=False)    ","74dc5425":"category={'Mr':1,'Mrs':2,'Miss':3,'Master':4,'uncommon':5}\nfor dataset in concatenate:\n    dataset['Title']=dataset['Title'].map(category)\n    \ntrain_data.head()","9dbe13ca":"train_data=train_data.drop('Name',axis=1)\ntest_data=test_data.drop('Name',axis=1)\ntrain_data.head()","73931cea":"train_data.info()\n","0036b6f0":"concatenate=[train_data,test_data]\n","c9f64f5a":"for dataset in concatenate:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_data.head()","ce10aab5":"guess=np.zeros(5)\nguess","5ecbf8b4":"for dataset in concatenate:\n    for i in range(1,6):\n        gg=dataset[(dataset['Title'] == i)]['Age'].dropna()\n        ages = gg.median()\n#             print(gg)\n        guess[i-1] =  ages\n    \n        \nprint(guess)             \n          ","3a2e1269":"for dataset in concatenate:   \n    for i in range(1,6):\n            dataset.loc[(dataset['Age'].isnull()) & (dataset['Title']==i),'Age']=guess[i-1]\n            print(guess[i-1])\n    dataset['Age']=dataset['Age'].astype(int)","686154aa":"train_data['Age_Group']=pd.cut(train_data['Age'],5)\ntrain_data[['Age_Group','Survived']].groupby('Age_Group').mean()","949b3d1e":"for dataset in concatenate:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 4\n    dataset.loc[ dataset['Age'] > 64, 'Age']= 5\ntrain_data.head()","b6694015":"train_data=train_data.drop('Age_Group',axis=1)\nconcatenate=[train_data,test_data]\ntrain_data.head()","fa8b8a39":"for dataset in concatenate:\n    dataset['Family'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_data[['Family', 'Survived']].groupby(['Family']).mean().sort_values(by='Survived', ascending=False)\n# train_data[train_data['Family']==1]","8ed8ccca":"for dataset in concatenate:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['Family'] == 1, 'IsAlone'] = 1\n\ntrain_data[['IsAlone', 'Survived']].groupby(['IsAlone']).mean()","e77de623":"train_data = train_data.drop(['Parch', 'SibSp', 'Family'], axis=1)\ntest_data = test_data.drop(['Parch', 'SibSp', 'Family'], axis=1)\nconcatenate = [train_data, test_data]\n\ntrain_data.head()","3e0184b1":"for dataset in concatenate:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    \ntrain_data[['Embarked', 'Survived']].groupby(['Embarked']).mean().sort_values(by='Survived', ascending=False)\n","7cf0eeac":"for dataset in concatenate:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'Q': 1, 'C': 2} ).astype(int)\n\ntrain_data.head()","6435d233":"test_data['Fare'].fillna(test_data['Fare'].dropna().median(), inplace=True)\ntest_data.head()","76219e16":"train_data['FareBand'] = pd.qcut(train_data['Fare'], 4)\ntrain_data[['FareBand', 'Survived']].groupby(['FareBand']).mean().sort_values(by='FareBand', ascending=True)","1dc76ef0":"for dataset in concatenate:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_data = train_data.drop(['FareBand'], axis=1)\nconcatenate = [train_data, test_data]\n    \nprint(train_data.head())\nprint(test_data.head())","e55dee23":"from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold","7da03347":"X_train = train_data.drop(\"Survived\", axis=1)\nY_train = train_data[\"Survived\"]\nX_test  = test_data.drop('PassengerId',axis=1).copy()\n","e54a1aa5":"LR = LogisticRegression()\nLR.fit(X_train, Y_train)\nY_pred = LR.predict(X_test)\nacc_LR = round(LR.score(X_train, Y_train) * 100, 2)\nacc_LR","03bcbb37":"svc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","6ae25e2c":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","0c8a41ae":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","b455fd2c":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","b04c2a09":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","6f3da9a7":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","65a5de9e":"\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","8b5586b5":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","7e78586d":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_LR, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","c6b64983":"submission = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\n\nsubmission","0f7bbe89":"submission.to_csv(\"submission.csv\",index=False)","c22bd90f":"## Correlation between Survived and Fare.\n* Passengers who paid higher fare more survived.","3aad596d":"* On train dataset  the Age, Cabin, Embarked columns have null values.\n* On test dataset  the Age, Cabin columns have null values.\n* On train dataset, 7 features are int or float and on test 6.\n* On both datasets, 5 features are object.","f755c418":"# SVM","69609e7d":"# Perceptron","d752a3fa":"#### Passengers on Pclass=1 have more lucky to survive.","cf398735":"Fill null values for Embarked with 'S' because most freq. value is S.","af95b6f7":"Convert Embarked to categorical value.","9551d30a":"Drop Age_Group","adc0dfda":"# Naive Bayse","2efa1b2d":"Drop Family,ParCh and SibSp","04bbc26a":"## Correlation between Age, Sex and Survived\n* Almost all women on Pclass=1 and Pclass=2 survived.\n","1ba1bce6":"#### From the code below we understand that:\n* We have 891 unique names \n* Just 2 values for Sex:Male,Female. Males are on top with 577 freq. (64.7%).\n* Just 3 values for Embarked and S is on top with 644 freq. (72%).\n* Ticket  has 681 unique values.","dd558b8a":"Now we can predict and use Machine Learning Techniques.\n* We use these Machine Learning Techniques:\n1. Random Forest\n2. Decision Tree\n3. KNN\n4. Support Vector Machines\n5. Logistic Regression\n6. Linear SVC\n7. Stochastic Gradient Decent\n8. Perceptron\n9. Naive Bayes","17b7df06":"Group ages.","a2ac220e":"Category of Fare","8b13efc8":"Convert Sex to categorical.","2cfdb21d":"First, we want to extract title of names and after that drop name because we don't need names.","a6f44d0f":"# Decision Tree","d8bafb69":"Find Ages for null values by Title.","0552d65c":"## Correlation between Age and Survived\n* Passengers with 80 years old survived.\n* Correlation between Age and SurvivedPassengers with 15-25 years old not survived.","d7056270":"Convert Title to categorical.","3062a418":"# Stochastic Gradient Descent","030096b2":"Combine Parch and SibSp columns","b0a97f4c":"We have null values on Age column.","5991e7c0":"# KNN","6b5fa155":"# Data Cleaning\n Drop Ticket, Cabin and PassengerId","ed2d9b11":"Now we can drop name from both datasets.","c64d394d":"# Best Models are Random Forest and Decision Tree","2b47e97a":"Seperate Fare ","c53b6849":"Find how many of passengers are alone.","4ece5fc2":"# Visualizing data","a5c7390c":"# LinearSVC","f453fbf7":"#### Women have more lucky to survive.","6ca09b1a":"## Correlation between Age, Pclass and Survived\n* Most of the passengers on Pclass=1 survived.\n* Most of the passengers on Pclass=3 not survived.\n* Almost all children with age 5 or low on Pclass=2 survived.","e5329150":"First, we should do some preprocessing. We concat boh dataframes to do all operations on both of them.","25f6f991":"Replace the titles.","c53fbf61":"## Correlation between Embarked, Sex, Pclass and Survived\n* In Embarked=C males survived better.\n* In Embarked=S and Embarked=Q females survived better.","bf9c9fb3":"* I think there is correlation between [Age,Sex,Pclass] and survival.\n* and no correlation between [PassengerId,Name,Ticket,Cabin] and survival. So, maybe should drop them.","bdbf1ce5":"# Logistic Regression","270873d0":"# Random Forest"}}