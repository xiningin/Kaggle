{"cell_type":{"4505c210":"code","27d80116":"code","034d8ef1":"code","3ebfd76f":"code","0963a754":"code","1427b4d6":"code","b20e6bbd":"code","2b5509ed":"code","81846fee":"code","86d55b04":"code","767f7713":"code","815bf164":"code","8eb8bef1":"code","aa2e4acb":"code","02db5ebc":"code","2f3958d3":"code","07d8bcf6":"code","a12433ec":"code","ced27214":"code","1d68523b":"code","a0b50e6d":"code","fcb02f39":"code","54f332ee":"code","edf8b7d9":"code","d8d258b7":"code","0b4dec13":"code","d83ced0c":"code","2e9d8e0a":"markdown","14396d0c":"markdown","856047dc":"markdown","2079deea":"markdown","4318e57e":"markdown","a7cbfbc0":"markdown"},"source":{"4505c210":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.metrics import mean_squared_error\nimport pickle\nprint(os.listdir(\"..\/input\"))\n","27d80116":"names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS',\n         'RAD', 'TAX', 'PRTATIO', 'B', 'LSTAT', 'MEDV']\ndataset = pd.read_csv(\"..\/input\/housing.csv\",delim_whitespace=True,names=names)","034d8ef1":"print(dataset.shape)","3ebfd76f":"print(dataset.dtypes)","0963a754":"#pd.set_option('display.width',500)\nprint(dataset.head(5))","1427b4d6":"dataset.describe()","b20e6bbd":"dataset.corr()","2b5509ed":"dataset.hist(sharex=False,sharey=False,xlabelsize=1,ylabelsize=1)\nplt.show()","81846fee":"dataset.plot(kind=\"density\",subplots=True,layout=(4,4),sharex=False,sharey=False,fontsize=1)\nplt.show()","86d55b04":"dataset.plot(kind=\"box\",subplots=True,layout=(4,4),sharex=False,sharey=False,fontsize=1)\nplt.show()","767f7713":"pd.plotting.scatter_matrix(dataset,figsize=(10,10))\nplt.show()","815bf164":"fig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(dataset.corr(),vmin=-1,vmax=1,interpolation='none')\nfig.colorbar(cax)\nticks = np.arange(0,14,1)\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nplt.show()","8eb8bef1":"array = dataset.values\nX = array[:,0:13]\nY = array[:,13]\nvalidation_size = 0.2\nseed = 7\nX_train,X_validation,Y_train,Y_validation = train_test_split(X,Y,test_size=validation_size,random_state=seed)","aa2e4acb":"num_folds = 10\nscoring = 'neg_mean_squared_error'","02db5ebc":"models = {}\nmodels[\"LR\"] = LinearRegression()\nmodels[\"LASSO\"] = Lasso()\nmodels[\"EN\"] = ElasticNet()\nmodels[\"CART\"] = DecisionTreeRegressor()\nmodels[\"KNN\"] = KNeighborsRegressor()\nmodels[\"SVM\"] = SVR()","2f3958d3":"results = []\nfor key in models:\n    kfold = KFold(n_splits=num_folds,random_state=seed)\n    cv_result = cross_val_score(models[key],X_train,Y_train,cv=kfold,scoring=scoring)\n    results.append(cv_result)\n    print(\"%s: %f, %f\" %(key,cv_result.mean(),cv_result.std()))","07d8bcf6":"fig = plt.figure()\nfig.suptitle(\"Algorithm Comparison\")\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(models.keys())\nplt.show()","a12433ec":"pipelines = {}\npipelines[\"ScalarLR\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"LR\",LinearRegression())])\npipelines[\"ScalarLASSO\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"LASSO\",Lasso())])\npipelines[\"ScalarEN\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"EN\",ElasticNet())])\npipelines[\"ScalarKNN\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"KNN\",KNeighborsRegressor())])\npipelines[\"ScalarCART\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"CART\",DecisionTreeRegressor())])\npipelines[\"ScalarSVM\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"SVM\",SVR())])\n\nresults = []\nfor key in pipelines:\n    kfold = KFold(n_splits=num_folds,random_state=seed)\n    cv_result = cross_val_score(pipelines[key],X_train,Y_train,cv=kfold,scoring=scoring)\n    results.append(cv_result)\n    print(\"%s: %f, %f\" %(key,cv_result.mean(),cv_result.std()))","ced27214":"fig = plt.figure()\nfig.suptitle(\"Algorithm Comparison\")\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(pipelines.keys())\nplt.show()","1d68523b":"scaler = StandardScaler().fit(X_train)\nrescaleX = scaler.transform(X_train)\nparam_grid = {'n_neighbors':[1,3,5,7,9,11,13,15,17,19,21]}\nmodel = KNeighborsRegressor()\nkfold = KFold(n_splits=num_folds,random_state=seed)\ngrid = GridSearchCV(estimator=model,param_grid=param_grid,scoring=scoring,cv=kfold)\ngrid_result = grid.fit(X=rescaleX,y=Y_train)\nprint(\"best_score:\",grid_result.best_score_)\nprint(\"best_params:\",grid_result.best_params_)","a0b50e6d":"ensembers = {}\nensembers[\"ScalarAB\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"AB\",AdaBoostRegressor())])\nensembers[\"ScalarABKNN\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"ABKNN\",AdaBoostRegressor(KNeighborsRegressor(n_neighbors=3)))])\nensembers[\"ScalarABLR\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"ABLR\",AdaBoostRegressor(LinearRegression()))])\nensembers[\"ScalarRFT\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"RFT\",RandomForestRegressor())])\nensembers[\"ScalarETR\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"ETR\",ExtraTreesRegressor())])\nensembers[\"ScalarGRB\"] = Pipeline([(\"Scalar\",StandardScaler()),(\"GRB\",GradientBoostingRegressor())])","fcb02f39":"results = []\nfor key in ensembers:\n    kfold = KFold(n_splits=num_folds,random_state=seed)\n    cv_result = cross_val_score(ensembers[key],X_train,Y_train,cv=kfold,scoring=scoring)\n    results.append(cv_result)\n    print(\"%s: %f, %f\" %(key,cv_result.mean(),cv_result.std()))","54f332ee":"fig = plt.figure(figsize=(10,10))\nfig.suptitle(\"Algorithm Comparison\")\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(ensembers.keys())\nplt.show()","edf8b7d9":"scaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nparam_grid = {'n_estimators': [10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900]}\nmodel = GradientBoostingRegressor()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X=rescaledX, y=Y_train)\nprint('\u6700\u4f18\uff1a%s \u4f7f\u7528%s' % (grid_result.best_score_, grid_result.best_params_))","d8d258b7":"scaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nparam_grid = {'n_estimators': [5, 10, 20, 30, 40, 50, 60, 70, 80]}\nmodel = ExtraTreesRegressor()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X=rescaledX, y=Y_train)\nprint('\u6700\u4f18\uff1a%s \u4f7f\u7528%s' % (grid_result.best_score_, grid_result.best_params_))","0b4dec13":"#\u8bad\u7ec3\u6a21\u578b\nscaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\ngbr = ExtraTreesRegressor(n_estimators=80)\ngbr.fit(X=rescaledX, y=Y_train)\n# \u8bc4\u4f30\u7b97\u6cd5\u6a21\u578b\nrescaledX_validation = scaler.transform(X_validation)\npredictions = gbr.predict(rescaledX_validation)\nprint(mean_squared_error(Y_validation, predictions))","d83ced0c":"model_file = \"model.sav\"\nwith open(model_file,mode='wb') as model_f:\n    pickle.dump(gbr,model_f)","2e9d8e0a":"**Data is not preprocessed the LinearRegression is the best Algorithm**","14396d0c":"****  KNN n_neighbors parameters is 3****","856047dc":"**2. Data is preprocessed.**","2079deea":"**1. Data is not preprocessed.**","4318e57e":"**Data is not preprocessed the KNN is the best Algorithm**","a7cbfbc0":"**We optimize the KNN parameters**"}}