{"cell_type":{"5c97d035":"code","5d891a9d":"code","dc672394":"code","32c12bad":"code","206d1785":"code","f6f4089d":"code","c13236a9":"code","3af84dc7":"code","109cddd8":"code","5b480442":"code","f230cc07":"code","bc8ba361":"code","609cfebb":"code","3f1d5c12":"code","5f921920":"code","ffd5bf55":"code","c21b52cf":"code","cac63c70":"code","bf853adb":"code","a72822e4":"code","54b9591b":"code","18f52b3a":"code","dc83a9aa":"code","e07e2855":"code","40decdad":"code","978a7a29":"code","c97ed621":"code","03ec056a":"code","610de435":"code","d814478f":"code","1a4fdac8":"code","3db1ab37":"code","0df66e42":"code","f1379c83":"code","abb24fc2":"code","f82a8705":"code","ff5ecfe5":"code","4e65ab3a":"code","b68ca204":"code","06dbd7a5":"code","537b9134":"code","06033524":"code","b1d4cf68":"code","9fa957f0":"code","ef842b9f":"code","2bb4110f":"code","7362045d":"code","c621fe27":"code","37cde765":"code","fd2f9740":"code","158daa27":"code","77aa5669":"code","0ed75bc0":"code","51467e57":"code","0525c4ef":"code","d2882bbc":"code","e9dd3daf":"code","a6e5d1ea":"code","6c849389":"code","4838708d":"code","afc146c4":"code","5822aaa8":"code","ef53ec7f":"code","be5c7230":"code","95e10a5d":"code","cc579fd0":"code","0def7dbe":"code","2778ba73":"code","04148d92":"code","ed8dcd97":"code","53fd4008":"code","0fb3fda1":"code","76bb2646":"code","4a6940e5":"code","209993be":"code","68e537d0":"code","b88c7584":"code","c239299f":"code","bf66e477":"code","ccd15eb6":"markdown","d330861e":"markdown","f1be0adf":"markdown","b638a6c5":"markdown","431a575e":"markdown","69ee44ae":"markdown","aa0ea7f9":"markdown","d6904f64":"markdown","c425a2a8":"markdown","01d0ab7d":"markdown","79a69f84":"markdown","b5f2806a":"markdown","80d9a6c6":"markdown","67101ebd":"markdown","fd2a7a39":"markdown","d31cc57c":"markdown","094ad586":"markdown","5c4f9704":"markdown","dec8e5ed":"markdown","7d3093ef":"markdown","1a47d253":"markdown","efbf9579":"markdown"},"source":{"5c97d035":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","5d891a9d":"#importing the dataset\n\ndata_analyst_jobs = pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv')\ndata_analyst_jobs","dc672394":"print(data_analyst_jobs.isnull().sum()) #checking for null values in the dataset\nprint(data_analyst_jobs.info()) #checking the general information of the dataset: non-null count, d-type, etc","32c12bad":"data_analyst_jobs['Easy Apply'] = data_analyst_jobs['Easy Apply'].fillna(False).astype(bool) #As seen in dataset, Easy Apply column has -1 values, replacing them with boolean value False\ndata_analyst_jobs['Easy Apply'].value_counts() # Checking for value count of Easy Apply column","206d1785":"#removing unwanted columns\ndata_analyst_jobs.drop(['Unnamed: 0', 'Competitors', 'Easy Apply'], axis = 1, inplace = True) #Removing unwanted columns as they are not important for my further analysis","f6f4089d":"data_analyst_jobs.replace(['-1'], [np.nan], inplace=True)\ndata_analyst_jobs.replace(['-1.0'], [np.nan], inplace=True)\ndata_analyst_jobs.replace([-1], [np.nan], inplace=True)","c13236a9":"data_analyst_jobs.isnull().sum()  #After replacing -1 with nan, we can see that there are null values in the dataset","3af84dc7":"data_analyst_salary = data_analyst_jobs['Salary Estimate'].str.split(\"-\",expand=True,)\n\nminimum_salary = data_analyst_salary[0]\nminimum_salary = minimum_salary.str.replace('K',' ')\n\n\nmaximum_salary = data_analyst_salary[1].str.replace('(Glassdoor est.)', ' ')\nmaximum_salary = maximum_salary.str.replace('(', ' ')\nmaximum_salary = maximum_salary.str.replace(')', ' ')\nmaximum_salary = maximum_salary.str.replace('K', ' ')\n\nmaximum_salary = maximum_salary.str.replace('$', ' ').fillna(0).astype('int')\nminimum_salary = minimum_salary.str.replace('$', ' ').fillna(0).astype('int')","109cddd8":"data_analyst_jobs['Minimum Salary'] = minimum_salary\ndata_analyst_jobs['Maximum Salary'] = maximum_salary\n\ndata_analyst_jobs.drop('Salary Estimate',axis = 1,inplace = True)","5b480442":"data_analyst_jobs['Company Name'] = data_analyst_jobs['Company Name'].str.replace('\\n.*', ' ')","f230cc07":"Location = data_analyst_jobs['Location'].str.split(\",\",expand=True,)\nLocation_City = Location[0]\nLocation_State = Location[1]\ndata_analyst_jobs['Location City'] = Location_City\ndata_analyst_jobs['Location State'] = Location_State\ndata_analyst_jobs.drop('Location',axis = 1, inplace = True)\n\nHQ = data_analyst_jobs['Headquarters'].str.split(\",\",expand=True)\nHeadquarters_City = HQ[0]\nHeadquarters_State = HQ[1]\ndata_analyst_jobs['Headquarters City'] = Headquarters_City\ndata_analyst_jobs['Headquarters State'] = Headquarters_State\ndata_analyst_jobs.drop('Headquarters',axis = 1, inplace = True)\n","bc8ba361":"department = data_analyst_jobs['Job Title'].str.split(',', expand = True)\n#data_analyst_jobs['Job Title'], data_analysu_jobs['Department']\ndata_analyst_jobs['Job Title'], data_analyst_jobs['Department'] = department[0],department[1]","609cfebb":"data_analyst_jobs.drop('Department',1, inplace = True)","3f1d5c12":"data_analyst_jobs['Job Title'].value_counts()\n","5f921920":"data_analyst_jobs['Job Title'] = data_analyst_jobs['Job Title'].str.replace('Sr.', 'Senior')","ffd5bf55":"data_analyst_jobs.info()","c21b52cf":"data_analyst_jobs['Type of ownership'].value_counts()","cac63c70":"data_analyst_jobs['Industry'].value_counts()","bf853adb":"data_analyst_jobs['Sector'].value_counts()","a72822e4":"data_analyst_jobs['Revenue'].value_counts()","54b9591b":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].replace('Unknown \/ Non-Applicable', None)\n# data['Revenue']=data['Revenue'].replace('Unknown \/ Non-Applicable', None)","18f52b3a":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('$', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('(USD)', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('(', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace(')', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace(' ', '')","dc83a9aa":"data_analyst_jobs['Revenue'].value_counts()","e07e2855":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('2to5billion', '2billionto5billion')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('5to10billion ', '5billionto10billion ')\n","40decdad":"data_analyst_jobs['Revenue'].value_counts()","978a7a29":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].replace('million', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].replace('10+billion', '10billionto11billion')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('Lessthan1million', '0millionto1million')","c97ed621":"data_analyst_jobs['Revenue'].value_counts()","03ec056a":"data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('million', ' ')\ndata_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].str.replace('billion', '000 ')","610de435":"data_analyst_jobs['Revenue'].value_counts()\n","d814478f":"Revenue = data_analyst_jobs['Revenue'].str.split(\"to\",expand=True)","1a4fdac8":"Revenue[0].value_counts()","3db1ab37":"Revenue[1].value_counts()","0df66e42":"data_analyst_jobs['Revenue'].value_counts()","f1379c83":"data_analyst_jobs['Minimum Revenue'] = Revenue[0]\ndata_analyst_jobs['Maximum Revenue'] = Revenue[1]\n","abb24fc2":"data_analyst_jobs['Maximum Revenue'] = pd.to_numeric(data_analyst_jobs['Maximum Revenue'])\ndata_analyst_jobs['Minimum Revenue'] = pd.to_numeric(data_analyst_jobs['Minimum Revenue'])","f82a8705":"data_analyst_jobs.drop('Revenue',1,inplace=True)","ff5ecfe5":"data_analyst_jobs","4e65ab3a":"data_analyst_jobs['Size'].value_counts()","b68ca204":"data_analyst_jobs['Size'] = data_analyst_jobs['Size'].str.replace('employees', '')\n","06dbd7a5":"data_analyst_jobs['Size'] = data_analyst_jobs['Size'].str.replace('+', 'plus')\ndata_analyst_jobs['Size'] = data_analyst_jobs['Size'].replace('Unknown', None)\n\n","537b9134":"data_analyst_jobs['Size'] = data_analyst_jobs['Size'].str.replace('10000plus', '10000 to 10001')","06033524":"size = data_analyst_jobs['Size'].str.split(\"to\",expand=True)","b1d4cf68":"data_analyst_jobs['Minimum Size'] = size[0]\ndata_analyst_jobs['Maximum Size'] = size[1]\ndata_analyst_jobs","9fa957f0":"data_analyst_jobs.drop('Size',1,inplace = True)","ef842b9f":"# def contains_word(s, w):\n#     return f' {w} ' in f' {s} '\n\n# # def rev(text):\n# #     #if contains_word(text,'billion') is True:\n# #     text.str.replace('billion','')\n         \n# #     return text\n\n# def revenue(text):\n#     if contains_word(text,'billion') is True:\n#         max_rev = float(data_analyst_jobs['Maximum Revenue'].replace(\"billion\", \" \").strip())*1000\n#         #revenue = float(maxRev[0].replace('+','').strip())*100\n#     return max_rev\n\n# data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].apply(lambda text: clean_revenue(text))","2bb4110f":"f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\nsns.despine(left=True)\nsns.distplot(data_analyst_jobs['Minimum Salary'],color = 'r',ax = axes[0])\nsns.distplot(data_analyst_jobs['Maximum Salary'],ax = axes[1])\nplt.legend();","7362045d":"sns.boxplot(x = data_analyst_jobs['Rating']);","c621fe27":"data_analyst_jobs['Minimum Size'] = data_analyst_jobs['Minimum Size'].astype('float')\ndata_analyst_jobs['Maximum Size'] = data_analyst_jobs['Maximum Size'].astype('float')\n\n","37cde765":"f, axes = plt.subplots(1, 2, figsize=(20, 5), sharex=True)\nsns.boxplot(x = data_analyst_jobs['Minimum Size'], ax = axes[0],palette='Set1');\nsns.boxplot(x = data_analyst_jobs['Maximum Size'], ax = axes[1],palette='Set2');","fd2f9740":"plt.subplots(figsize=(10,10))\nsplot = sns.barplot(x=data_analyst_jobs['Job Title'].value_counts()[0:20].index,y=data_analyst_jobs['Job Title'].value_counts()[0:20], palette = 'winter_r')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Job Title',fontsize=15)\nplt.ylabel('Job Count',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=15)\nplt.title('Top 20 Job Title Counts',fontsize=25);\n\n# for index, row in data_analyst_jobs.iterrows():\n#     splot.text(row.name,row.tip, round('Job Title',2), color='black', ha=\"center\")\n","158daa27":"plt.subplots(figsize=(15,15))\nsplot = sns.barplot(x = data_analyst_jobs['Company Name'][0:20], y = data_analyst_jobs['Maximum Revenue'][0:20], data = data_analyst_jobs, palette = 'spring')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\n\nplt.xlabel('Company Name',fontsize=15)\nplt.ylabel('Maximum revenue in million dollars',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Maximum Revenue of top 20 Companies',fontsize=25);","77aa5669":"data_analyst_jobs['Average Revenue'] = data_analyst_jobs[['Minimum Revenue','Maximum Revenue']].mean(axis=1)\n","0ed75bc0":"avg_rev = data_analyst_jobs['Average Revenue'][0:20]\navg_rev","51467e57":"plt.subplots(figsize=(20,15))\nsplot = sns.barplot(x = data_analyst_jobs['Company Name'][0:20], y = data_analyst_jobs['Average Revenue'][0:20], data = data_analyst_jobs, palette = 'summer')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Company Name')\nplt.ylabel('Average revenue in million dollars')\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Average Revenue of top 20 Companies',fontsize=25);\n","0525c4ef":"data = data_analyst_jobs.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata","d2882bbc":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 cities', barmode = 'group')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","e9dd3daf":"data1 = data_analyst_jobs.groupby('Job Title')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata1","a6e5d1ea":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 job titles', barmode = 'stack')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","6c849389":"data_analyst_jobs['Average Salary'] = data_analyst_jobs[['Minimum Salary', 'Maximum Salary']].mean(axis = 1)","4838708d":"import plotly.express as px\nfig = px.scatter(data_analyst_jobs, x=data_analyst_jobs['Rating'], y= data_analyst_jobs['Average Salary'])\nfig.update_layout(title = 'Relation between average salary and rating of companies')\nfig.show()\n","afc146c4":"data2 = data_analyst_jobs.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).head(25)\ndata2","5822aaa8":"fig = px.line(x=data2['Average Revenue'], y=data2.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","ef53ec7f":"data3 = data_analyst_jobs.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).tail(25)\ndata3","be5c7230":"fig = px.line(x=data3['Average Revenue'], y=data3.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","95e10a5d":"data4 = pd.DataFrame(data_analyst_jobs['Sector'].value_counts())\ndata4","cc579fd0":"import plotly.express as px\nfig = px.pie(data4, values=data4['Sector'], names=data4.index)\nfig.update_layout(title = 'Percentage of Different Sectors with requirement of Data Analyst Roles')\nfig.show()\n","0def7dbe":"data5 = pd.DataFrame(data_analyst_jobs['Industry'].value_counts().head(25))\ndata5","2778ba73":"import plotly.express as px\nfig = px.pie(data5, values=data5['Industry'], names=data5.index)\nfig.update_layout(title = 'Percentage of top 25 Industries with requirement of Data Analyst Roles')\nfig.show()\n\n","04148d92":"data6 = pd.DataFrame(data_analyst_jobs['Type of ownership'].value_counts())\ndata6\n\nimport plotly.express as px\nfig = px.pie(data6, values=data6['Type of ownership'], names=data6.index)\nfig.update_layout(title = 'Type of ownership')\nfig.show()\n\n\n","ed8dcd97":"data7 = pd.DataFrame(data_analyst_jobs['Headquarters City'].value_counts().head(25))\ndata7\n\nimport plotly.express as px\nfig = px.pie(data7, values=data7['Headquarters City'], names=data7.index)\nfig.update_layout(title = 'Top 25 Headquarter City')\nfig.show()\n\n\n\n","53fd4008":"data8 = pd.DataFrame(data_analyst_jobs['Location City'].value_counts().head(25))\ndata8\n\nimport plotly.express as px\nfig = px.pie(data8, values=data8['Location City'], names=data8.index)\nfig.update_layout(title = 'Top 25 Job Locations')\nfig.show()\n\n\n\n\n","0fb3fda1":"from wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image","76bb2646":"plt.subplots(figsize=(15,15))\nwc = WordCloud()\ntext = data_analyst_jobs['Job Title']\nwc.generate(str(' '.join(text)))\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()","4a6940e5":"# import nltk\n# from nltk.corpus import stopwords\n# import re\n# from nltk.stem.porter import PorterStemmer\n# print(stopwords.words('english'))\n\n# stop_words = set(stopwords.words('english'))\n# jobdes = data_analyst_jobs['Job Description'].to_csv()\n# jobdes = jobdes.split(' ')\n# jobdes = jobdes.lower()\n# jobdes","209993be":"\n# skills = ['python', 'java','c', 'r','c++', 'hadoop', 'communication']\n\n# for word in all_words:\n#     print(word)","68e537d0":"usa_map = data_analyst_jobs.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_map = usa_map.reset_index()\nusa_map.head(20)\n","b88c7584":"cities = usa_map['Location City']\ncities.head(20)\n\n['Daly City','Marin City', 'Los Gatos', 'Berkeley', 'San Jose', 'Cupertino','Santa Clara', 'Pico Rivera', 'Whittier','Far Rockaway', 'Secaucus', 'Sunnyvale', 'Menlo Park', 'Elk Grove Village', 'Glenview', 'Maywood', 'Northfield', 'Stanford', 'San Francisco', 'El Cajon']","c239299f":"usa_maps = data_analyst_jobs.groupby('Location State')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_maps = usa_maps.reset_index()\n\nusa_maps = usa_maps.drop([3, 0])\nusa_maps","bf66e477":"import plotly.express as px\n\nfig = px.choropleth(locations= ['AZ','NJ','NY','CO','IL','NC','VA','SC','WA','PA','DE','TX','KS','FL','IN','OH','GA','UT'], \n                    locationmode=\"USA-states\", \n                    color=[94.494845, 90.232558, 89.026087, 89.022727, 88.829268,85.233333, 85.125000, 83.000000, 82.759259, 77.824561, 75.909091, 74.116751, 67.000000, 66.666667, 61.000000, 58.800000, 56.000000, 48.454545],\n                    labels={'color':'Maximum Salary', 'locations':'State'},\n                    scope=\"usa\") \n\n\nfig.update_layout(\n    \n    title_text = 'Top 20 States with Maximum Salary',\n    geo_scope='usa'\n)\nfig.show()","ccd15eb6":"**Creating separate columns of Size as minimum and maximum size**","d330861e":"**Cleaning the Revenue column**","f1be0adf":"**Creating two separate columns of Revenue as Minimum and Maximum Revenue**","b638a6c5":"**Making city and state columns for both Location and Headquaters**","431a575e":"# **1. Data Cleaning**","69ee44ae":"Checking values from the columns for cleaning","aa0ea7f9":"Distribution of minimum and maximum salary of all Data Analyst job titles","d6904f64":"**If you like my notebook, give it an upvote! Suggestions for improvements are welcomed!**","c425a2a8":"# 2. Statistics","01d0ab7d":"**Separating department and from job title column**","79a69f84":"**Word Cloud of Job Titles**","b5f2806a":"# 3. Data Visualization# ","80d9a6c6":"Checking for outliers in company size","67101ebd":"Data Ananlysis on 'Data Analyst Jobs' Data Set.\n\n1. Data Cleaning\n2. Statistics\n3. Data Visulization\n","fd2a7a39":"**Cleaning the Size column**","d31cc57c":"Creating 'Average Revenue' column","094ad586":"Creating a new DataFrame 'use_maps' consisting of 'Location State', 'Minimum Salary' and 'Maximum Salary' columns for ploting choropleth map for top 20 states with maximum salary.","5c4f9704":"Checking for outliers in Company Ratings","dec8e5ed":"I have implemented some newly gained data analysis and visualization skills on 'Data Analyst Jobs'\n\nYou can also check my similar work on:\n1. [Analysis of Data Engineer Jobs](https:\/\/www.kaggle.com\/samruddhim\/analysis-of-data-engineer-jobs)\n2. [Analysis of Data Scientist Jobs](https:\/\/www.kaggle.com\/samruddhim\/analysis-of-data-scientist-jobs)","7d3093ef":"Since, department has too many missing values (2023\/2253), it can be dropped.","1a47d253":"**Creating separate columns of Salary Estimate as minimum and maximum salary**","efbf9579":"**Replacing -1 with nan**"}}