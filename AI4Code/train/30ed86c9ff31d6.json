{"cell_type":{"e19b030d":"code","985b4daf":"code","b01032b8":"code","125a182f":"code","2eef95ba":"code","2e06bd24":"code","356a7951":"code","15f1e71b":"code","9b455eb4":"code","12cfd153":"code","b21c1965":"code","cf360a6d":"code","d6fbb7ee":"code","6f57991c":"code","0d404c05":"code","59dc49cc":"code","5f316eba":"code","025c4dc6":"code","f03174c5":"code","25eea711":"code","744918d1":"code","54809eeb":"code","203548af":"code","a80439da":"code","bfe000fb":"markdown","4dcff534":"markdown","24376cb7":"markdown"},"source":{"e19b030d":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom scipy.fft import fft,fftfreq\nfrom sklearn.preprocessing import StandardScaler","985b4daf":"#loading the dataset using pandas\ndata = pd.read_csv(\"..\/input\/powerqualitydistributiondataset1\/PowerQualityDistributionDataset1.csv\")","b01032b8":"#The dataset is already preprocessed\ndata.drop(data.columns[[0]],axis=1,inplace=True)\ndata.shape","125a182f":"data.head()","2eef95ba":"#here we are constructing the array which will finally contain the column names\nheader =[]\nfor i in range(1,129):\n    header.append(\"Col\"+str(i))\ndata_out = data['output'] ","2e06bd24":"data.drop(['output'],axis=1,inplace=True)\ndata_arr = data.to_numpy()","356a7951":"data_arr.shape","15f1e71b":"#here we are overwritting the dataframe with the waves which we obtained after doing fourier transformation\nn = data_arr.shape[0]\nfor i in range(0,n):\n    data_arr[i][0:128] = np.abs(fft(data_arr[i][0:128]))","9b455eb4":"data_arr.shape","12cfd153":"#here we are performing normalization\ntransform = StandardScaler()\ndata_arr = transform.fit_transform(data_arr)","b21c1965":"#converting the numpy array back to data frame\ndata = pd.DataFrame(data_arr,columns=header)\ndata['output'] = data_out","cf360a6d":"data","d6fbb7ee":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data.loc[:,data.columns != 'output'],data['output'],test_size=0.2)","6f57991c":"# get_dummies function is used here to perform one hot encoding of the y_* numpy arrays\ny_train_hot = pd.get_dummies(y_train)\ny_test_hot = pd.get_dummies(y_test)","0d404c05":"print(\"Training\",x_train.shape)\nprint(y_train_hot.shape)\nprint(\"Test\",x_test.shape)\nprint(y_test_hot.shape)","59dc49cc":"from sklearn.ensemble import RandomForestClassifier\n\nmodelR = RandomForestClassifier(24) \n\n\n\n# fit the model\n\nmodelR.fit(x_train,y_train_hot)","5f316eba":"predict_testR=modelR.predict(x_test)\npredict_testR","025c4dc6":"from sklearn.metrics import accuracy_score\n\naccuracy_test=accuracy_score(y_test_hot,predict_testR)\naccuracy_test","f03174c5":"from sklearn.naive_bayes import GaussianNB \n\nmodelN = GaussianNB() \n\nmodelN.fit(x_train, y_train) ","25eea711":"predict_testN=modelN.predict(x_test)\npredict_testN","744918d1":"accuracy_test=accuracy_score(y_test,predict_testN)\naccuracy_test","54809eeb":"from sklearn.svm import SVC \n\nmodelS = SVC()  \nmodelS.fit(x_train, y_train)  ","203548af":"predict_testS=modelS.predict(x_test)\npredict_testS","a80439da":"from sklearn.metrics import accuracy_score\n\naccuracy_test=accuracy_score(y_test,predict_testS)\naccuracy_test","bfe000fb":"The data transformation steps employed here are as follows:\n\n1) Fourier Transform\n2) Normalization","4dcff534":"### Model creation and training","24376cb7":"### Data transformation"}}