{"cell_type":{"74da02c2":"code","388b2f66":"code","89da2584":"code","1ab2c2a5":"code","ed8f3f7b":"code","87f24154":"code","5ae09dc8":"code","0dccf8f3":"code","91398fee":"code","81637adc":"code","0f371129":"code","cbbceeda":"code","ab61810d":"code","de6d96c0":"code","a663b13e":"code","2b7362c8":"code","242cd7ac":"code","5d767084":"code","42baa300":"code","ff326f90":"code","c9fbd2cf":"code","547c8e20":"code","74e39ace":"code","2fc3d6c8":"code","ad90de03":"code","230a897e":"code","0bfb9a7b":"code","48ec4aad":"code","384f8984":"code","94467c18":"code","9d94ab2d":"code","e72a43e1":"markdown","129a181c":"markdown","3f0e6613":"markdown","140309aa":"markdown","2e1f514a":"markdown","f652053f":"markdown","7b7ce48a":"markdown","8fdb2b27":"markdown","f8402d75":"markdown","d5b4190e":"markdown","c003d38f":"markdown","e2b6240f":"markdown","6f4f48e3":"markdown","727448ad":"markdown"},"source":{"74da02c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\n\nimport plotly\nplotly.offline.init_notebook_mode(connected=True)\n\nimport matplotlib\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","388b2f66":"df = pd.read_csv('..\/input\/29-public-domain-bibles-with-verse-character-count\/6-BBE\/bible-in-basic-english.csv', delimiter=',', encoding = \"ISO-8859-2'\")\ndf.head(3)","89da2584":"df.isnull().sum()","1ab2c2a5":"df[\"Book\"].value_counts()","ed8f3f7b":"phil = df[(df['Book']=='Philemon')].reset_index(drop=True)\nphil.head()","87f24154":"# 2nd row, 4th column \n\ndf.iloc[2,3]","5ae09dc8":"# 2nd row, 4th column \n\ndf.iloc[4,3]","0dccf8f3":"!pip install -U spacy","91398fee":"# 2nd row, 4th column \n\ndf.iloc[31101,3]","81637adc":"!python -m spacy download en_core_web_lg","0f371129":"!python -m spacy download en_core_web_sm","cbbceeda":"!pip install wordcloud","ab61810d":"import spacy\nnlp = spacy.load('en_core_web_sm')\n\n# Create a nlp object\ndoc = nlp(\"And God said, Let there be light: and there was light.\")\n\nfor token in doc:\n    print(token.text, token.pos_, token.dep_)","de6d96c0":"nlp.pipe_names","a663b13e":"nlp.disable_pipes('tagger', 'parser')","2b7362c8":"nlp.pipe_names","242cd7ac":"# 3rd row, 4th column \n\nphil.iloc[3,3]","5d767084":"doc = nlp(\"I give praise to God at all times and make prayer for you.\")\nfor token in doc:\n    print(token.text)","42baa300":"nlp = spacy.load('en_core_web_sm')  #Must write that otherwise won't render correctly\n\n# Iterate over the tokens\nfor token in doc:\n    # Print the token and its part-of-speech tag\n    print(token, token.tag_, token.pos_, spacy.explain(token.tag_))","ff326f90":"from spacy import displacy\n\ndoc = nlp(\"And God said, Let there be light: and there was light.\")\ndisplacy.render(doc, style=\"dep\" , jupyter=True)","c9fbd2cf":"nlp = spacy.load('en_core_web_sm')\n\n# Create an nlp object\ndoc = nlp(\"And God said, Let there be light: and there was light.\")\n \n# Iterate over the tokens\nfor token in doc:\n    # Print the token and its part-of-speech tag\n    print(token.text, \"-->\", token.dep_)","547c8e20":"spacy.explain(\"nsubj\"), spacy.explain(\"ROOT\"), spacy.explain(\"aux\"),spacy.explain('nmod'), spacy.explain(\"advcl\"), spacy.explain(\"dobj\")","74e39ace":"nlp = spacy.load('en_core_web_sm')\n\n# Create an nlp object\ndoc = nlp(\"And God said, Let there be light: and there was light.\")\n \n# Iterate over the tokens\nfor token in doc:\n    # Print the token and its part-of-speech tag\n    print(token.text, \"-->\", token.lemma_)","2fc3d6c8":"nlp = spacy.load('en_core_web_sm')\n\n# Create an nlp object\ndoc = nlp(\"And God said, Let there be light: and there was light.\")\n \nsentences = list(doc.sents)\nlen(sentences)","ad90de03":"for sentence in sentences:\n     print (sentence)","230a897e":"nlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"And God said, Let there be light: and there was light.\")\n#See the entity present\nprint(doc.ents)\nfor ent in doc.ents:\n    print(ent.text, ent.start_char, ent.end_char, ent.label_)","0bfb9a7b":"from spacy import displacy\nnlp = spacy.load(\"en_core_web_sm\")\ndoc= nlp(\"\"\"And God said, Let there be light: and there was light. I give praise to God at all times and make prayer for you. Naming the light, Day, and the dark, Night. And there was evening and there was morning, the first day. The grace of the Lord Jesus be with the saints. So be it. \"\"\")\n\nentities=[(i, i.label_, i.label) for i in doc.ents]\nentities","48ec4aad":"displacy.render(doc, style = \"ent\",jupyter = True)","384f8984":"nlp = spacy.load(\"en_core_web_lg\")\ntokens = nlp(\"And God said, Let there be light: and there was light.\")\n\nfor token in tokens:\n    print(token.text, token.has_vector, token.vector_norm, token.is_oov)","94467c18":"nlp = spacy.load(\"en_core_web_lg\")  # make sure to use larger model!\ntokens = nlp(\"And God said, Let there be light: and there was light.\")\n\nfor token1 in tokens:\n    for token2 in tokens:\n        print(token1.text, token2.text, token1.similarity(token2))","9d94ab2d":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nnlp = spacy.load(\"en_core_web_lg\")  # make sure to use larger model!\ntokens = nlp(\"And God said, Let there be light: and there was light. Jesus, The grace of the Lord Jesus be with the saints. So be it. I give praise to God at all times and make prayer for you. Naming the light, Day, and the dark, Night. And there was evening and there was morning, the first day. The grace of the Lord Jesus be with the saints. So be it.\")\n\nnewText =''\nfor word in tokens:\n if word.pos_ in ['ADJ', 'NOUN']:\n  newText = \" \".join((newText, word.text.lower()))\n\nwordcloud = WordCloud(stopwords=STOPWORDS).generate(newText)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","e72a43e1":"![](https:\/\/i.pinimg.com\/564x\/7d\/e1\/73\/7de1733e53f52692b1897e1c71c51708.jpg)pinterest.com","129a181c":"#Entity Detection\n\nIt can't be short below. Hence, I added some lines to the doc=nlp Line.","3f0e6613":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSR6qVjp9wBLgbU-Ms7ngPqhayZSr-zjpuHWg&usqp=CAU)casasbahia.com.br","140309aa":"#Wow there are so many files that I didn't know that exists. It's hard to pick\/choose one.","2e1f514a":"#That's all I will make with that respectful data.","f652053f":"![](https:\/\/20quotes.com\/images\/124957.jpg)20quotes.com","7b7ce48a":"#Sentence Boundary Detection (SBD)","8fdb2b27":"#Named Entity Recognition (NER)","f8402d75":"#Create an NLP object","d5b4190e":"#Lemmatization","c003d38f":"#Part-Of-Speech (POS) Tagging","e2b6240f":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: black;\"><b style=\"color:#DAA520;\">Let there be the Light with Spacy<\/b><\/h1><\/center>","6f4f48e3":"#Tokenization","727448ad":"#Similarity"}}