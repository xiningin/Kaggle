{"cell_type":{"3cef079b":"code","21cad047":"code","4d351b86":"code","79914307":"code","576ed2a2":"code","033afb2a":"code","8258e4f4":"code","9deb1bcc":"code","c7a2003a":"code","e734c645":"code","8c4877bf":"code","76469ce4":"code","5937fd54":"code","079fa08b":"code","528e798d":"code","212d5a71":"code","335e4f4e":"code","5401b836":"code","bf761a9c":"code","a75f3ae0":"code","c077daae":"code","e7e59ef4":"code","6dd3843a":"code","ede90664":"code","6be0c629":"code","fc06f691":"code","cf16155f":"code","82385b3f":"code","9d070305":"code","4167811a":"code","75e7748f":"code","cd09f01a":"code","09aff67c":"code","b679a606":"code","2769425f":"code","13554cd3":"code","13769448":"code","c10c936e":"code","e94ddb34":"code","1370b263":"code","447a10e6":"code","c2995852":"code","b915e6a6":"code","044288e0":"code","e1403cd2":"code","0ce2ab5e":"code","3fa1c289":"code","cbda64f2":"code","885e8bc7":"markdown","4ad29283":"markdown","bbdfa3d6":"markdown","01186949":"markdown","935f4176":"markdown","b679ae2f":"markdown","f05fbbe2":"markdown","ac65cc04":"markdown"},"source":{"3cef079b":"import pandas as pd\nimport numpy as np","21cad047":"df = pd.read_csv('..\/input\/text-classifier\/train_data.csv')\ntest = pd.read_csv('..\/input\/text-classifier\/valid_data.csv')","4d351b86":"df.head()","79914307":"df.action.unique()","576ed2a2":"df.object.unique()","033afb2a":"df.location.unique()","8258e4f4":"test.location.unique()","9deb1bcc":"test.object.unique()","c7a2003a":"test.action.unique()","e734c645":"df.info()","8c4877bf":"df['transcription'] = df['transcription'].str.lower() #Lower case\ntest['transcription'] = test['transcription'].str.lower()\npuncs = list(\"?:!.,;\") # Replacing punctuations with nothing\nfor i in puncs:\n    df['transcription'] = df['transcription'].str.replace(i,'')\n    test['transcription'] = test['transcription'].str.replace(i,'') ","76469ce4":"from nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\nnot_to_remove = {'on','off'} # Removing on and off from stopwords\nstop = stopwords.words()\nstop = [ele for ele in stop if ele not in not_to_remove]","5937fd54":"removed_train = []\nremoved_test = []\nfor i in range(0,len(df)):\n    removed_train.append(\" \".join([word for word in str(df['transcription'][i]).split() if word not in stop]))\nfor i in range(0,len(test)):\n    removed_test.append(\" \".join([word for word in str(test['transcription'][i]).split() if word not in stop]))","079fa08b":"df['transcription'] = removed_train\ntest['transcription'] = removed_test","528e798d":"df.head()","212d5a71":"df1 = df.copy()\ntest1 = test.copy()","335e4f4e":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_a=LabelEncoder()\nlabelencoder_o=LabelEncoder()\nlabelencoder_l=LabelEncoder()\nlabelencoder_a_test=LabelEncoder()\nlabelencoder_o_test=LabelEncoder()\nlabelencoder_l_test=LabelEncoder()\ny_train_action = labelencoder_a.fit_transform(df['action'].values)\ny_train_object = labelencoder_o.fit_transform(df['object'].values)\ny_train_location = labelencoder_l.fit_transform(df['location'].values)\ny_test_action = labelencoder_a_test.fit_transform(test1['action'].values)\ny_test_object = labelencoder_o_test.fit_transform(test1['object'].values)\ny_test_location = labelencoder_l_test.fit_transform(test1['location'].values)\n#For RNN\ndf_RNN = df.copy()\ndf_RNN['action'] = labelencoder_a.fit_transform(df['action'].values)\ndf_RNN['object'] = labelencoder_o.fit_transform(df['object'].values)\ndf_RNN['location'] = labelencoder_l.fit_transform(df['location'].values)","5401b836":"from sklearn.feature_extraction.text import TfidfVectorizer","bf761a9c":"ngram_range = (1,2)\nmax_features = 4\ntfidf = TfidfVectorizer(encoding='utf-8',\n                        ngram_range=ngram_range,\n                        stop_words=None,\n                        lowercase=False,\n                        max_features=max_features,\n                        )","a75f3ae0":"features_train = tfidf.fit_transform(df1['transcription']).toarray()\nprint(features_train.shape)\nfeatures_test = tfidf.transform(test1['transcription']).toarray()\nprint(features_test.shape)","c077daae":"from xgboost import XGBClassifier\nmodel = XGBClassifier()\nmodel_action= XGBClassifier()\nmodel_object= XGBClassifier()\nmodel_location= XGBClassifier()\n\nmodel_action.fit(features_train,y_train_action)\nmodel_object.fit(features_train,y_train_object)\nmodel_location.fit(features_train,y_train_location)","e7e59ef4":"y_pred_action = model_action.predict(features_test)\ny_pred_object = model_object.predict(features_test)\ny_pred_location = model_location.predict(features_test)","6dd3843a":"y_pred_action","ede90664":"labelencoder_a_test.inverse_transform(y_pred_action)","6be0c629":"from sklearn.metrics import classification_report\nprint(classification_report(y_test_action,y_pred_action))","fc06f691":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","cf16155f":"tokenizer = Tokenizer(num_words=4)\ntokenizer.fit_on_texts(df1['transcription'])","82385b3f":"sequences = tokenizer.texts_to_sequences(df1['transcription'])","9d070305":"MAXLEN = 7\nX = pad_sequences(sequences, maxlen=MAXLEN)","4167811a":"y = df_RNN.iloc[:,1:]","75e7748f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state = 42)","cd09f01a":"X_train.shape","09aff67c":"from keras.models import Sequential\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input\nfrom keras.layers.embeddings import Embedding\nimport datetime,os\nimport tensorflow as tf","b679a606":"main_input = Input(shape=(MAXLEN,), dtype='int32', name='main_input')\nx = Embedding(4, 7, input_length=MAXLEN)(main_input)\n#x = Dropout(0.1)(x)\nx = LSTM(100)(x)","2769425f":"len_list = [len(df.action.unique()), len(df.object.unique()) , len(df.location.unique())]\nlabel_names = ['action','object','location']","13554cd3":"output_array = []\nmetrics_array = {}\nloss_array = {}\nfor i in range(0,3):\n    categorical_output = Dense(len_list[i], activation='softmax', name=label_names[i])(x)\n    output_array.append(categorical_output)\n    metrics_array[label_names[i]] = 'sparse_categorical_accuracy'\n    loss_array[label_names[i]] = 'sparse_categorical_crossentropy'","13769448":"model = Model(inputs=main_input, outputs=output_array)\nmodel.compile(optimizer='adam',\n              loss=loss_array,\n              metrics = metrics_array)\n#For TensorBoard\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)","c10c936e":"y_test_output=[]\nfor col in label_names:\n    y_test_output.append(y_test[col])","e94ddb34":"y_train_output=[]\nfor col in label_names:\n    y_train_output.append(y_train[col])","1370b263":"history = model.fit(X_train, y_train_output,\n          epochs=50, batch_size=64,validation_data=(X_test,y_test_output),verbose=1);","447a10e6":"import matplotlib.pyplot as plt\nacc      = history.history['action_sparse_categorical_accuracy']\nval_acc  = history.history[ 'val_action_sparse_categorical_accuracy']\nloss     = history.history['val_action_loss']\nval_loss = history.history['val_action_loss' ]\nepochs   = range(len(acc)) # Get number of epochs\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","c2995852":"tokenizer = Tokenizer(num_words=4)\ntokenizer.fit_on_texts(test1['transcription'])\nsequences = tokenizer.texts_to_sequences(test1['transcription'])\nMAXLEN = 7\nX_test = pad_sequences(sequences, maxlen=MAXLEN)","b915e6a6":"t = [y_test_action,y_test_object,y_test_location]","044288e0":"preds = model.predict(X_test)","e1403cd2":"from sklearn.metrics import f1_score","0ce2ab5e":"for i in range(0,len(df.action.unique())):\n    print(df.action.unique()[i] + \": \",f1_score(t[0],np.argmax(preds[0],axis=1), average=None)[i])","3fa1c289":"for i in range(0,len(df.object.unique())):\n    print(df.object.unique()[i] + \": \",f1_score(t[1],np.argmax(preds[1],axis=1), average=None)[i])","cbda64f2":"for i in range(0,len(df.location.unique())):\n    print(df.location.unique()[i] + \": \",f1_score(t[2],np.argmax(preds[2],axis=1), average=None)[i])","885e8bc7":"**Removing Punctuations**","4ad29283":"# **Model Build**","bbdfa3d6":"# **Trying RNN**","01186949":"**Label Encoding**","935f4176":"# **Data Pre-Processing**","b679ae2f":"# **Test Data**","f05fbbe2":"# **F1 - Score**","ac65cc04":"**Model**"}}