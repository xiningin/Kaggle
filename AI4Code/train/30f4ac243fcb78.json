{"cell_type":{"31b060dc":"code","bde9b0fa":"code","151d2826":"code","2c60bd0e":"code","da1cf6b3":"code","294fc6d8":"code","fb8874f1":"code","c841f277":"code","fee4e6c6":"code","e8c3849e":"code","50d894f2":"code","0351dd92":"code","5e6dcb6a":"code","6ec07825":"code","216d36f8":"code","e1231b68":"markdown","0a17f525":"markdown","26f922fd":"markdown","f26a6a58":"markdown","f41b561a":"markdown","c9c6c349":"markdown","3cd2f168":"markdown","8d358c87":"markdown","05581cff":"markdown"},"source":{"31b060dc":"#importing required packages\nimport pandas as pd\nimport numpy as numpy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn import tree\nfrom sklearn import metrics\nfrom sklearn import ensemble\nfrom sklearn import linear_model\n","bde9b0fa":"#importing the test data\ndata=pd.read_csv(\"..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")\ndata.head(10)\n\n","151d2826":"data.dtypes","2c60bd0e":"data.shape","da1cf6b3":"data.isna().sum()","294fc6d8":"def fill_na_tree(data):\n    df=data.copy(deep=True)\n    #I am gonna fill NaN with \"NONE\" for categorical features\n    categorical_feat=[feat for feat in df.columns if feat not in (\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\")]\n    for cate in categorical_feat:  \n        df[cate].fillna(\"NONE\",inplace=True)\n        \n    #filling NaN in numerical data\n    #for tree methods there is no need of normalization hence we are filling just with its mean\n    for feat in df.columns:\n        if feat not in categorical_feat:\n            df[feat].fillna(df[feat].mean(),inplace=True)\n    #dropping loan_id as it has no meaning\n    df.drop(['Loan_ID'],axis=1)\n    return df\n        \n    ","fb8874f1":"def  label_encoding(df):\n    lbl_enc=preprocessing.LabelEncoder()\n    df.loc[:,'Loan_Status']=lbl_enc.fit_transform(df.Loan_Status.values)\n    categorical_feat=[feat for feat in df.columns if feat not in (\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\")]\n    for feature in categorical_feat:\n        lbl_enc=preprocessing.LabelEncoder()\n        df.loc[:,feature]=lbl_enc.fit_transform(df[feature].values)\n        \n    return df","c841f277":"def create_fold(data,fold_value):\n    #shuffling the data before spliting into k-fold\n    data=data.sample(frac=1).reset_index(drop=True)\n    #creating k-fold clm\n    data['kfold']=-1\n    #creating instance for stratified k-fold\n    kf=model_selection.StratifiedKFold(n_splits=fold_value)\n    \n    for fld,(target,values) in enumerate(kf.split(X=data,y=data.Loan_Status.values)):\n            data.loc[values,'kfold']=fld\n    \n    return data\n    \n    ","fee4e6c6":"def build_tree_model(data,fold_value):\n    data=fill_na_tree(data)\n    data=label_encoding(data)\n    data=create_fold(data,fold_value)\n    features=[i for i in data.columns if i not in ['kfold','Loan_Status','Loan_ID']]\n    for fold in range(fold_value):\n        #train and test split    \n        train=data[data.kfold!=fold].reset_index(drop=True)\n        valid=data[data.kfold==fold].reset_index(drop=True)\n        print(train.shape)\n        print(valid.shape)\n        #preparing model\n        clf = tree.DecisionTreeClassifier()\n        clf = clf.fit(train[features].values,train.Loan_Status.values)\n        # predict on validation data\n        # we need the probability values as we are calculating AUC\n        # we will use the probability of 1s\n        valid_preds = clf.predict_proba(valid[features].values)[:, 1]\n        # get roc auc score\n        auc = metrics.roc_auc_score(valid.Loan_Status.values, valid_preds)\n        f1= metrics.f1_score(valid.Loan_Status.values, valid_preds)\n        # print auc\n        print(f\"Fold = {fold}, AUC = {auc},F1={f1}\")\n    ","e8c3849e":"if __name__==\"__main__\":\n    build_tree_model(data,3)","50d894f2":"def build_random_forest_model(data,fold_value):\n    data=fill_na_tree(data)\n    data=label_encoding(data)\n    data=create_fold(data,fold_value)\n    features=[i for i in data.columns if i not in ['kfold','Loan_Status','Loan_ID']]\n    for fold in range(fold_value):\n        #train and test split    \n        train=data[data.kfold!=fold].reset_index(drop=True)\n        valid=data[data.kfold==fold].reset_index(drop=True)\n        print(train.shape)\n        print(valid.shape)\n        #preparing model\n        clf = ensemble.RandomForestClassifier(max_depth=2, random_state=0)\n        clf = clf.fit(train[features].values,train.Loan_Status.values)\n        # predict on validation data\n        # we need the probability values as we are calculating AUC\n        # we will use the probability of 1s\n        valid_preds = clf.predict_proba(valid[features].values)[:, 1]\n        # get roc auc score\n        auc = metrics.roc_auc_score(valid.Loan_Status.values, valid_preds)\n        #f1= metrics.f1_score(valid.Loan_Status.values, valid_preds)\n        # print auc\n        print(f\"Fold = {fold}, AUC = {auc},\")\n    ","0351dd92":"if __name__==\"__main__\":\n    build_random_forest_model(data,3)","5e6dcb6a":"def build_logistic_regression_model(data,fold_value):\n    data=fill_na_tree(data)\n    data=label_encoding(data)\n    data=create_fold(data,fold_value)\n    features=[i for i in data.columns if i not in ['kfold','Loan_Status','Loan_ID']]\n    for fold in range(fold_value):\n        #train and test split    \n        train=data[data.kfold!=fold].reset_index(drop=True)\n        valid=data[data.kfold==fold].reset_index(drop=True)\n        #preparing model\n        clf = linear_model.LogisticRegression(random_state=0,solver='liblinear')\n        clf = clf.fit(train[features].values,train.Loan_Status.values)\n        # predict on validation data\n        # we need the probability values as we are calculating AUC\n        # we will use the probability of 1s\n        valid_preds = clf.predict_proba(valid[features].values)[:, 1]\n        # get roc auc score\n        auc = metrics.roc_auc_score(valid.Loan_Status.values, valid_preds)\n        # print auc\n        print(f\"Fold = {fold}, AUC = {auc},\")","6ec07825":"if __name__==\"__main__\":\n    build_logistic_regression_model(data,2)","216d36f8":"####################################end#################################################","e1231b68":"I didn't check any correlation and variance with the data as its was already has little features so I dont want to remove any of that.","0a17f525":"Now we are gonna do label encoding to change the categorical data to numeric data","26f922fd":"#### Here I tried simple tricks and tried with some ML models.I will learn more on how to optimize and how to perform better with this data.Please comment If you have any suggestion and support me .Thank you","f26a6a58":"### Trying with logistic regression","f41b561a":"### Its time to create stratified k-fold ","c9c6c349":"When datasets is given we have to first choose the correct cross-validation method and its evaluation metric.\nHere the data given is skewed datasets which can be clearly seen in above cell hence we are choosing stratified k fold cross-validation and since it is skewed classification we may using F1 or ROC as a evaluation metric","3cd2f168":"I have tried different fold to avoid overfitting for different models.","8d358c87":"After choosing this,its time to do some feature engineering","05581cff":"### Trying Random Forest Model"}}