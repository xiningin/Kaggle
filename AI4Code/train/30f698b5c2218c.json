{"cell_type":{"86e0d706":"code","8b0acff0":"code","59e4a44c":"code","1e93bd8c":"code","616bd46c":"code","69d875bd":"code","50c4bfb0":"code","5546e818":"code","b4e20af7":"code","f07a4e4f":"code","6e403eaf":"markdown","94e6bbc9":"markdown","bbcbb168":"markdown","773b1ae0":"markdown","50818bef":"markdown","30c9f20f":"markdown","dc063bf2":"markdown","43a92c6c":"markdown"},"source":{"86e0d706":"# Standard imports\nimport os\nfrom pprint import pprint\nimport json\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom tqdm import trange\nfrom colorama import Fore, Back, Style\nimport time\nfrom glob import glob\n\n# For plotting\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# For model building\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\n# For Transfomers\nfrom transformers import AutoTokenizer, BertModel\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8b0acff0":"cfg = {}\ncfg['train_csv'] = \"..\/input\/commonlitreadabilityprize\/train.csv\"\ncfg['test_csv'] = \"..\/input\/commonlitreadabilityprize\/test.csv\"\ncfg['sample_sub'] = \"..\/input\/commonlitreadabilityprize\/sample_submission.csv\"\ncfg['epochs'] = 20\ncfg['max-len'] = 256\ncfg['train_bs'] = 8\ncfg['val_bs'] = 16\ncfg['active-model'] = '..\/input\/bert-base-uncased'\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\npprint(cfg)\nprint(f\"\\nCurrent Device : {DEVICE}\")","59e4a44c":"# Creating a data loader class\n\nclass BERTDataset(Dataset):\n    def __init__(self, txt):\n        self.txt = txt\n        self.tokenizer = AutoTokenizer.from_pretrained(cfg['active-model'])\n        self.max_len = cfg['max-len']\n    \n    def __len__(self):\n        return len(self.txt)\n    \n    def __getitem__(self, idx):        \n        # I have oberverd that some of the sentences have new line character\n        txt = str(self.txt[idx]).replace(\"\\n\", \"\")\n        \n        # Inputs from hugging face tokenizer\n        inputs = self.tokenizer.encode_plus(\n            txt, \n            add_special_tokens = True,\n            max_length = self.max_len,\n            truncation = True,\n            padding = 'max_length',\n        )\n        \n        \n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        token_type_ids = inputs[\"token_type_ids\"] \n        \n        return {\n            'ids' : torch.tensor(ids, dtype = torch.long),\n            'mask' : torch.tensor(mask, dtype = torch.long),\n            'token_type_ids' : torch.tensor(token_type_ids, dtype = torch.long),\n        }","1e93bd8c":"class BERTBaseUncased(nn.Module):\n    def __init__(self):\n        super(BERTBaseUncased, self).__init__()\n        \n        self.bert = BertModel.from_pretrained(cfg['active-model'])\n        self.drop = nn.Dropout(0.2)\n        self.relu = nn.ReLU()\n        self.linear = nn.Linear(768, 10)\n        self.out = nn.Linear(10, 1)\n    \n    def forward(self, ids, mask):\n        outs= self.bert(\n            ids, \n            attention_mask = mask,            \n        )\n        \n        mean_pool = torch.mean(outs[0], 1)\n        x = self.linear(mean_pool)\n        x = self.relu(x)\n        x = self.drop(x)\n        output = self.out(x)\n        \n        return output","616bd46c":"test_df = pd.read_csv(cfg['test_csv'])\ntest_df","69d875bd":"def run():\n\n    test_dataset = BERTDataset(test_df['excerpt'].values)\n    test_dataloader = DataLoader(\n                            test_dataset,\n                            batch_size = cfg['val_bs'],\n                            num_workers = 4,\n                            shuffle = False,\n                            pin_memory = True\n                        )\n\n    model_paths = glob(\"..\/input\/bestbertbaseuncasedmodelsclrp\/*.pth\")\n    test_predictions = []\n    \n\n    for idx in trange(len(model_paths), desc = \"Making Predictions\", bar_format=\"{l_bar}%s{bar:50}%s{r_bar}\" % (Fore.CYAN, Fore.RESET), position = 0, leave = True):\n        \n        cur_model_path = model_paths[idx]\n        cur_state = torch.load(cur_model_path)\n        cur_model = BERTBaseUncased()\n        cur_model.load_state_dict(cur_state['state_dict'])\n        cur_model.to(DEVICE)\n        cur_model.eval()\n        \n        cur_preds = []\n        \n        with torch.no_grad():\n            for d in test_dataloader:\n                ids = d['ids'].to(DEVICE)\n                mask = d['mask'].to(DEVICE)\n                \n                output = cur_model(ids, mask)\n                \n                output = output.squeeze(-1)\n                \n                cur_preds.append(output.cpu().numpy())\n            \n            cur_preds = np.concatenate(cur_preds)\n            test_predictions.append(cur_preds)\n            \n    \n    return test_predictions             \n","50c4bfb0":"test_preds = run()","5546e818":"pprint(test_preds)","b4e20af7":"sample_sub = pd.read_csv(cfg['sample_sub'])\nsample_sub['target'] = np.array(test_preds).mean(axis = 0)\nsample_sub","f07a4e4f":"sample_sub.to_csv(\"submission.csv\", index = False)","6e403eaf":"# Loading Models","94e6bbc9":"# Loading Test Data","bbcbb168":"# Importing Modules","773b1ae0":"Thanks to [ABHISHEK THAKUR](https:\/\/www.kaggle.com\/abhishek) for [this...](https:\/\/www.kaggle.com\/abhishek\/bert-base-uncased)","50818bef":"# Building DataLoader","30c9f20f":"Here, I will build an ensemble of my trained models..\nYou can check my training notebook [here...](https:\/\/www.kaggle.com\/hotsonhonet\/helpme)","dc063bf2":"# Inference ","43a92c6c":"# CONFIG"}}