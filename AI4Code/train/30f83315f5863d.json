{"cell_type":{"ed0e8fc6":"code","caa8b559":"code","e8f49243":"code","987707fc":"code","8a24f27f":"code","f10baefc":"code","52b664c0":"code","862423e9":"code","e9d080c0":"code","4fcbcea4":"markdown","dd79ba83":"markdown","e08e4d49":"markdown","83430d7f":"markdown","5f9cbd4e":"markdown","bd9676b8":"markdown","ba1e2681":"markdown","f8d00dfe":"markdown","c41b3590":"markdown","f722bb1f":"markdown","182a834d":"markdown"},"source":{"ed0e8fc6":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import r2_score\nfrom matplotlib import pyplot as plt","caa8b559":"filepath = '..\/input\/Admission_Predict_Ver1.1.csv'\ndf = pd.read_csv(filepath)\ndf.columns","e8f49243":"df.rename(columns = {'Chance of Admit ': 'Chance of Admit', 'LOR ': 'LOR'}, inplace = True)\ndf.columns","987707fc":"corr = df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(10, 8))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center= .6,\n            square=True, linewidths=2, cbar_kws={\"shrink\": .75})\nplt.savefig(fname = 'corr graph', dpi = 400)\nplt.show()","8a24f27f":"def isValuable(df, compareTo, plim, pcoefLim):\n    \"\"\"\n    Determines whether certain elements of inputed DataFrame are statistically relevant to the 'comparedto' column\n    df = DataFrame\n    compareTo = column to compare\n    plim = limit on p value to be considered relevant\n    pcoefLim = limit on pcoef value to be considered relevant\n    \"\"\"\n    dictDf = df.to_dict('series')\n    effectors = []\n    for column in df:\n        if (df[column].dtype != 'object'):\n            if not (df[column].equals(df[compareTo])):\n                pcoef, p = stats.pearsonr(df[compareTo], df[column])\n                print(\"{} compared to {}\".format(column, compareTo))\n                print((\"The pcoef is: {}\\nThe p_value is: {}\").format(pcoef, p))\n                if (pcoef > pcoefLim) or (pcoef < -pcoefLim) and (p < plim):\n                    effectors.append(column)\n                    sns.regplot(x = df[column], y = df[compareTo], data=df, marker = '.')\n                    plt.ylim(0,)\n                    plt.show()\n                    print(\".......ADDED.......\")\n                else:\n                    print(\".....NOT ADDED.....\")\n                print(\"\")\n        else:\n            columnName = df[column].name\n            grouped = df[[columnName, compareTo]].groupby(columnName)\n            uniqueElements = dictDf[column].unique()\n            elements = []\n            for thing in uniqueElements:\n                try:\n                    specialGroup = grouped.get_group(thing)[compareTo]\n                    elements.append(specialGroup)\n                except:\n                    pass\n            f, p = stats.f_oneway(*elements)\n            print((\"After ANOVA Analysis of {} compared to {}:\\nF Value: {}\\nP Value: {}\").format(columnName, compareTo, f, p))\n            if (p < plim):\n                effectors.append(column)\n                sns.boxplot(x= df[column], y=df[compareTo], data=df)\n                plt.show()\n                print(\".......ADDED.......\")\n            print(\"\")\n    return effectors\neffectors = isValuable(df, 'Chance of Admit', .01, .5)\nprint('Valuable:', effectors)\n","f10baefc":"X = df[effectors]\ny = df['Chance of Admit']","52b664c0":"XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size = .3, random_state = 1)\nMLR = LinearRegression()\nMLR.fit(XTrain, yTrain)\nr2 = MLR.score(XTest, yTest)\nprint((\"Split R^2 Score: {:.5}\").format(r2))\nMLR.fit(X, y)\nr2 = MLR.score(X, y)\nprint((\"Full R^2 Score:  {:.5}\").format(r2))","862423e9":"#to avoid data conversion warnings\nX = X.astype('float64')\nXTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size = .3, random_state = 1)\n#creating pipeline\nInput=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(degree=3)), ('model',LinearRegression())]\npipe = Pipeline(Input)\npipe.fit(XTrain, yTrain)\nyhat = pipe.predict(XTest)\n#getting R^2\nr2_p = r2_score(yTest, yhat)\nprint(\"R^2 Score: \", r2_p)","e9d080c0":"# \"Perfect student\"\ninput = [[340, 120, 1, 5, 5, 10, 1]]\n#          1    2   3  4  5  6   7\n# 1 - 'GRE Score' out of 340 \n# 2 - 'TOEFL Score' out of 120\n# 3 - 'University Rating' out of 5 (1 is top 20%, 5 bottom 20%)\n# 4 - 'SOP' - Statement of Purpose strength out of 10\n# 5 - 'LOR' - Letter of Rec strength out of 10\n# 6 - 'CGPA'- Cumulative GPA out of 10\n# 7 - 'Research' - research or no research 0 or 1\nprediction = MLR.predict(input)\nprint(\"The odds that you get into a no. {} ranked school is: {:.3%}\".format(input[0][2], prediction[0]))","4fcbcea4":"#### Correlation Plot using Seaborn ####","dd79ba83":"### Understanding Data with Matplotlib and Scipy Stats ###\nUsed scipy.stats to calculate various correlation coeffecients based on whether data type within column is a number or object. If it is an object it creates a box plot and determines correlation with different math. Then the function outputs a list of all statistically relevant columns.\n\n*NOTE*: I wrote this function in a previous program and reused it in this one. There aren't any object only columns.","e08e4d49":"#### Pipeline Attempt ####\nDid not work as well :(","83430d7f":"#### Importing libraries ####","5f9cbd4e":"Built in a little tester so user can try to determine their odds! Working on 3d plot graphing prediciton vs actual given (X = CGPA, Y = GRE Score, Z = Chance of Admit)","bd9676b8":"### Fiting Model with LinearRegression and with a PolyFeatures Pipeline ###\nEnded up with not to bad R^2, but I was still skeptical whether this actually is true. So I did a train_test_split to verify correlation. Previously had my PolynomialFeatures model with a higher R^2 but after further investigation (train_test_split) I was overfitting the data, hence the poor R^2 with split data.\n","ba1e2681":"Predicting Graduate Admission Rates\n------------------------------\nThis is my work after learning data science throughout the last couple weeks. This is also my first time writing in Python. If you see problems with my code (as in any unconventional syntax or methods) or if you could help me explore ways to achieve a better fit please leave a comment and I'll try to implement it! I would not recommend using this as a guide, but if it helps you in any way...cool!","f8d00dfe":"## Understanding Data ##\nUsing Seaborn and Matplotlib to plot correlations to understand which variables are relevant visually","c41b3590":"### Ending Note ##\nWhat would you change about my code to make it more accurate\/better? I am trying to improve both my code and the way I think about wrangling data. This community has been really fun to learn from and interact with so far, thank you for any feedback.","f722bb1f":"\n#### 'Chance of Admit ' and 'LOR ' has an extra space so we will remove it ####","182a834d":"#### Loading Data ####"}}