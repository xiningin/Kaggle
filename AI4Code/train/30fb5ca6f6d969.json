{"cell_type":{"085e1f58":"code","b0a66c23":"code","4bd6c873":"code","19ae701e":"code","18620bbe":"code","458b7d79":"code","d6a9a560":"code","0d8e2bfd":"code","2c0e274c":"code","e7ae6d16":"code","31c2958b":"code","d6bcbb6f":"code","e3b07fc9":"code","39734782":"code","b15128dc":"code","ee686730":"code","71434590":"code","e32fe00f":"code","79e110b3":"code","7d6cca1a":"code","db0cbe36":"code","37db7ed1":"code","eab5c6fd":"code","3329bfe4":"code","afc49984":"markdown","63003709":"markdown","6297ad15":"markdown","689ac2c6":"markdown","cc7b9a6f":"markdown","e1814d84":"markdown","f571c524":"markdown","12c956a0":"markdown","9d080688":"markdown","b85d022f":"markdown","0a3a02dc":"markdown","42a042fa":"markdown","38019630":"markdown","ce76aca7":"markdown","bb13a157":"markdown","78964755":"markdown","4b71c9a0":"markdown","1766cabc":"markdown","a55e2a0a":"markdown","7032ca1a":"markdown","c62c4bfa":"markdown","4f9998e5":"markdown","ec9ed73b":"markdown","22c7fbf7":"markdown"},"source":{"085e1f58":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nimport pandas as pd\nimport numpy as np","b0a66c23":"df = pd.read_csv('..\/input\/Tweets.csv')\ndf.head()","4bd6c873":"sentiment_counts = df.airline_sentiment.value_counts()\nnumber_of_tweets = df.tweet_id.count()\nprint(sentiment_counts)\n","19ae701e":"dff = df.groupby([\"airline\", \"airline_sentiment\" ]).count()[\"name\"]\ndff['American']","18620bbe":"airlines=df.airline.unique()\npositive_percentage = []\nnegative_percentage = []\nneutral_percentage = []\nfor i in airlines:\n    positive_percentage.append((dff[i].positive\/dff[i].sum())*100)\n    negative_percentage.append((dff[i].negative\/dff[i].sum())*100)\n    neutral_percentage.append((dff[i].neutral\/dff[i].sum())*100)\npercentage_data = [positive_percentage,negative_percentage,neutral_percentage]\npercentage_data = np.array(percentage_data)\npercentage_data=percentage_data.reshape(6,3)","458b7d79":"my_series = pd.DataFrame(data=percentage_data, index =airlines)\nmy_series[0] = positive_percentage\nmy_series[1] = negative_percentage\nmy_series[2] = neutral_percentage\nmy_series","d6a9a560":"import matplotlib.pyplot as plt\nimport matplotlib.style\n%matplotlib inline\nimport matplotlib.style\nfrom matplotlib.pyplot import subplots\n\nfig, ax = subplots()\nmy_colors =['blue','red','green']\nmy_series.plot(kind='bar', stacked=False, ax=ax, color=my_colors, figsize=(14, 7), width=0.8)\nax.legend([\"Postive Percentage\",\"Negative Percentage\",\"Neutral Percentage\"])\nplt.title(\"Percentages of Sentiments, Tweets Sentiments Analysis Airlines, 2017\")\nplt.show()","0d8e2bfd":"data = df[['text','airline_sentiment']]\ndata.head()","2c0e274c":"data.loc[:,('airline_sentiment')] = data.airline_sentiment.map({'neutral':0, 'positive':1,'negative':2})\ndata.head()","e7ae6d16":"positive_sentiment_words = ''\nnegative_sentiment_words = ''\nneutral_sentiment_words = ''\nneutral = data[data.airline_sentiment == 0]\npositive = data[data.airline_sentiment ==1]\nnegative = data[data.airline_sentiment ==2]","31c2958b":"import nltk,re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nstop_words = set(stopwords.words('english'))\nwordnet_lemmatizer = WordNetLemmatizer()\nfor val in neutral.text:\n    text = val.lower()\n    only_letters = re.sub(\"[^a-zA-Z]\", \" \",text) \n    tokens = nltk.word_tokenize(only_letters )[2:]\n    for word in tokens:\n        if word not in stop_words:\n            word = wordnet_lemmatizer.lemmatize(word)\n            neutral_sentiment_words =  neutral_sentiment_words + word + ' '\n            \nfor val in positive.text:\n    text = val.lower()\n    only_letters = re.sub(\"[^a-zA-Z]\", \" \",text) \n    tokens = nltk.word_tokenize(only_letters )[2:]\n    for word in tokens:\n        if word not in stop_words:\n            word = wordnet_lemmatizer.lemmatize(word)\n            positive_sentiment_words =  positive_sentiment_words + word + ' '\n            \nfor val in negative.text:\n    text = val.lower()\n    only_letters = re.sub(\"[^a-zA-Z]\", \" \",text) \n    tokens = nltk.word_tokenize(only_letters )[2:]\n    for word in tokens:\n        if word not in stop_words:\n            word = wordnet_lemmatizer.lemmatize(word)\n            negative_sentiment_words =  negative_sentiment_words + word + ' '\n            \n            \n","d6bcbb6f":"from wordcloud import WordCloud\nneutral_wordcloud = WordCloud(width=600, height=400).generate(neutral_sentiment_words)\npositive_wordcloud = WordCloud(width=600, height=400).generate(positive_sentiment_words)\nnegative_wordcloud = WordCloud(width=600, height=400).generate(negative_sentiment_words)\n","e3b07fc9":"plt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(neutral_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","39734782":"plt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(positive_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()\n","b15128dc":"plt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(negative_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","ee686730":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\ndata['text'] = data['text'].apply(lambda x: x.lower())\ndata['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\nX_train,X_test,y_train,y_test = train_test_split(data[\"text\"],data[\"airline_sentiment\"], test_size = 0.2, random_state = 10)\nprint(\"train tuples\",X_train.shape)\nprint(\"test tuples\",X_test.shape)\nprint(\"train labels\",y_train.shape)\nprint(\"test labels\",y_test.shape)\nvect = CountVectorizer()\nvect.fit(X_train)\nX_train_df = vect.transform(X_train)\nX_test_df = vect.transform(X_test)","71434590":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\nmodel.fit(X_train_df,y_train)\nresult=model.predict(X_test_df)","e32fe00f":"print(\"Accuracy Score:\",accuracy_score(y_test,result))","79e110b3":"from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train_df,y_train)\nresult=clf.predict(X_test_df)","7d6cca1a":"print(\"Accuracy Score:\",accuracy_score(y_test,result))\n","db0cbe36":"import keras\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding, LSTM, SpatialDropout1D\nfrom keras.callbacks import ModelCheckpoint\nimport os\nfrom sklearn.metrics import roc_auc_score\nfrom keras.preprocessing.text import Tokenizer\nmax_fatures = 2000\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)\n\nembed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(3,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())\n\nY = pd.get_dummies(data['airline_sentiment']).values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)","37db7ed1":"batch_size = 256\nhistory = model.fit(X_train, \n                    Y_train, \n                    epochs = 10, \n                    batch_size=batch_size, \n                    validation_data=(X_test, Y_test))","eab5c6fd":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","3329bfe4":"models = ['Naive Bayes','SVM','LSTM']\naccuracy = [76.09,60.82,81.11]\nresult_frame = pd.DataFrame(data = accuracy,index = models)\n\nfig, ax = subplots()\nmy_colors =['blue','red','green']\nresult_frame.plot(kind='bar', stacked=False, ax=ax, color=my_colors, figsize=(12, 4), width=0.4)\nax.legend([\"Percentage\"])\nplt.title(\"Comparison of different models on Twitter Sentiments\")\nplt.show()","afc49984":"# Results","63003709":"## Converting sentences into vectors in order to feed it to Naive Bayes and SVM\n## Splitting data into training and test data ( test_size = 0.2 )","6297ad15":"## Accuracy = 60.82%","689ac2c6":"## Model 2 - SVM","cc7b9a6f":"## Read Data","e1814d84":"# Data Preprocessing","f571c524":"## Model 1 - Naive Bayes","12c956a0":"## Model 3 - LSTM","9d080688":"## Fitting Model\n### Accuracy Achieved = 81.11%","b85d022f":"## As we are interested in only 2 columns for our purpose of classfication, we are taking subset of whole data frame","0a3a02dc":"## Converting labels into integers \n### neutral = 0\n### positive = 1\n### negative = 2","42a042fa":"## Chart displays the sentiment of each airline in percentage","38019630":"# Classification","ce76aca7":"## Neutral Sentiments Wordcloud","bb13a157":"## Positive Sentiments WordCloud","78964755":"### Model 3 - Accuracy Graph","4b71c9a0":"## Tokenizing, Lematizing and removing stop words from data","1766cabc":"## Converting sentiments of indivual airline into percentages","a55e2a0a":"# WordCloud","7032ca1a":"## Seperating rows based on their labels","c62c4bfa":"## Accuracy = 76.09%","4f9998e5":"# Data Analysis\n## Some Insights","ec9ed73b":"### Conclusion\nAs we can see from graph that deep learning model (LSTM) outperforms other two models in terms of accuracy","22c7fbf7":"## Negative Sentiments WordCloud"}}