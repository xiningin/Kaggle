{"cell_type":{"8560f93c":"code","d15000bf":"code","a20fb0ae":"code","9e64201b":"code","ec477888":"code","7e827f84":"code","f58b0f40":"code","2db520c2":"code","52d34acd":"code","cc5a7a02":"code","ed4d5336":"code","2d975090":"code","62bd795e":"code","52775286":"code","9461a4e3":"code","29f178bb":"code","10db3ded":"code","e07c0242":"code","821e0043":"code","2c265923":"code","d09eaf73":"code","1e640c2e":"code","82837f63":"code","d71dc62b":"code","b7301f27":"code","e386d9d4":"code","f0b69175":"code","ecb3dc8b":"code","da8bc6cf":"code","a9d204ff":"code","63657985":"code","49eb176b":"code","9e09568e":"code","70969f36":"code","50b67345":"code","3e06a522":"code","756f697f":"code","ee9fc865":"code","3a7d2ad8":"code","0b6d30d1":"code","5860582f":"code","5f6bc433":"code","dfd8a4e4":"code","9ae951c6":"code","e502fc44":"code","9e467e8b":"code","1197bfda":"code","efe58248":"code","e9d05384":"code","c83e9433":"code","5b2870e2":"code","10822a7b":"code","c0791a0c":"code","f07e6ed8":"code","39c11095":"code","d784f6db":"code","128437a5":"code","96063a66":"code","69902ee1":"code","032018e8":"code","90c970e3":"code","bf4f2f35":"code","10789751":"code","ecc211a4":"code","71a5d564":"code","88b1125a":"code","a2fa8192":"code","7597317c":"code","9e443200":"code","dcb97b70":"code","4e590b02":"code","807878d4":"code","f642fa9c":"code","df5c5ca9":"code","cf793446":"code","9e8f5541":"code","0abbfa9a":"markdown","996f29b3":"markdown","c22cd6df":"markdown","dc2318ff":"markdown","82082aee":"markdown","213f74f3":"markdown","112d9937":"markdown","df679786":"markdown","a633cdf9":"markdown","f52162bf":"markdown"},"source":{"8560f93c":"## Import necessary Libraries.\n\nimport pandas as pd ## Pandas Library (will use to load data,create data frame...etc).\nimport numpy as np ## Numpy Library ( will use to convert data frame to array or creating array etc...).\nimport os ## For connecting to machine to get path for reading\/writing files.\nimport matplotlib.image as mpimg ## To load image.\nimport matplotlib.pyplot as plt ## For Visualizaton.\nfrom keras.preprocessing import image ## To load Image and convert it into array.\nfrom tqdm import tqdm ## To print Progress bars.\nfrom sklearn.model_selection import train_test_split ## To split train data into train and validation data.\nfrom keras.utils import to_categorical ## One hot Encoding.\nfrom keras.models import Sequential ## Sequential Model.\nfrom keras.layers import Dense ## Fully connected layer(all inputs connected to all nodes).\nfrom keras.layers import Dropout ## For Regularaization (drops couple of nodes based on integer passed to constructor).\nfrom keras.layers import Flatten ## To convert array  into 1D(one dimesional).\nfrom keras.layers import Conv2D ## Convolution two dimensional layer .\nfrom keras.layers import MaxPool2D ## fecthing important features\/ reducing dimensions.\nfrom keras.optimizers import RMSprop # Optimizer.\nfrom keras.preprocessing.image import ImageDataGenerator # Image Augmentation.\nfrom keras.callbacks import ReduceLROnPlateau # Call backs\/Early stopping.","d15000bf":"## Set max how many rows and columns you want to display in jupyter notebook.\npd.options.display.max_columns = 200 \npd.get_option('display.max_rows') \npd.set_option('display.max_rows',None) ","a20fb0ae":"## Get the file path and file name from kaggel.\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))","9e64201b":"## Images path.\nimage_path = '\/kaggle\/input\/emergency-vs-nonemergency-vehicle-classification\/train\/images\/'","ec477888":"## Load train and test data sets.\ntrain = pd.read_csv('\/kaggle\/input\/emergency-vs-nonemergency-vehicle-classification\/train\/train.csv',header='infer',sep=',')\ntest = pd.read_csv('\/kaggle\/input\/emergency-vs-nonemergency-vehicle-classification\/test.csv',header='infer',sep=',')","7e827f84":"## Print dimensions of train and test data.\nprint(train.shape)\nprint(test.shape)","f58b0f40":"## Check first record from train data.\ntrain.head(1)","2db520c2":"## Check last record from train data.\ntrain.tail(1)","52d34acd":"## Check first record from test data.\ntest.head(1)","cc5a7a02":"## Check last record from test data.\ntest.tail(1)","ed4d5336":"## Get summary statistics of train data.\ntrain.describe(include='all')","2d975090":"## Get summary statistics of test data.\ntest.describe(include='all')","62bd795e":"## Get column data types of train data.\ntrain.dtypes","52775286":"## Get column data types of test data.\ntest.dtypes","9461a4e3":"## Check index range for train data.\ntrain.index","29f178bb":"## Check index range for test  data.\ntest.index","10db3ded":"## Check column names for train data.\ntrain.columns","e07c0242":"## Check column names for test data.\ntest.columns","821e0043":"## Check null values for train data.\ntrain.isna().sum()","2c265923":"## Check null values for test data.\ntest.isna().sum()","d09eaf73":"## Display list of image names, which are there in images folder.\n#print(os.listdir(image_path))","1e640c2e":"## Method will read list of images in the given path and returns image list.\ndef get_images_list(path):\n    image_list = [] ## Initialize empty list.\n    for img in tqdm(os.listdir(path)): ## Get list of image names from the given path and process each image names.\n        image_list.append(img) ## add image name to image list.\n    return image_list","82837f63":"## Get image list for the the given path.\nimage_list = get_images_list(image_path)","d71dc62b":"## Check size of the image_list.\nlen(image_list)","b7301f27":"## Print first image name from image_list.\nimage_list[0]","e386d9d4":"## Plot sample images based on given image location.\ndef display_sample_images(path):\n    plt.figure(figsize=(20,6)) ## Set Figure Size.\n    for ind,image_name in tqdm(enumerate(os.listdir(path))): ## enumerate() function iterates list and return index,value.\n        img = mpimg.imread(os.path.join(path,image_name)) ## imread() reads the image from the given path and image name.\n        if ind<10: ## Based on this condition it prints only 10 images.\n            plt.subplot(2,5,ind+1) ## Add a subplot to the current figure(2 rows,5 columns and current index).\n            plt.imshow(img) ## Displays image.\n            plt.axis('off') ## Axis values will off.\n            plt.title(ind) ## Setting title name to image.","f0b69175":"## Display first 10 images.\ndisplay_sample_images(image_path)","ecb3dc8b":"## Image Size\nIMG_SIZE = 28","da8bc6cf":"## Load training images from the given path based on image names which are there in train data and convert them into array.\ndef load_train_data(img_path):\n    train_data = [] ## Initialize empty list\n    for img in tqdm(train['image_names']): ## Get list of image names from train data and process each image name.\n        if img in image_list: ## If the image name is present in image list then only we have to read image.\n            path = os.path.join(img_path, img) ## Location of the the image.\n            img = image.load_img(path,                              ## Load image from the given path and\n                                 target_size=(IMG_SIZE,IMG_SIZE,3), ## Keep image size as 28X28X3(height,width,color channels) and\n                                 grayscale=False)                   ## grayscale is false indicates that image is color image.\n            img = image.img_to_array(img) ## Convert image pixels into an array.\n            img = img\/255 ## Normalize the train data (CNN converg faster on [0..1] data than on [0..255]).\n            train_data.append(img) ## Add normalized image pixel array to train data.      \n    return np.array(train_data) ## Convert list into an array and returns it.","a9d204ff":"## Get training data for the given image path.\ntrain_data = load_train_data(image_path)","63657985":"## Display sample train image.\nplt.imshow(train_data[1491], cmap = 'gist_gray')","49eb176b":"## Get size of the train_data.\nlen(train_data)","9e09568e":"## Check dimensions of the train data.\ntrain.shape","70969f36":"## Check image size.\nlen(image_list)","50b67345":"## Load testing images from the given path based on images names which are there in test data and convert them into array.\ndef load_test_data(image_path):\n    test_data = []  ## Initialize empty list\n    for img in tqdm(test['image_names']): ## Get list of image names from test data and process each image name.\n        if img in image_list: ## If the image name is present in image list then only we have to read image.\n            path = os.path.join(image_path, img) ## Location of the the image.\n            img = image.load_img(path,                              ## Load image from the given path and\n                                 target_size=(IMG_SIZE,IMG_SIZE,3), ## Keep image size as 28X28X3(height,width,color channels) and\n                                 grayscale=False)                   ## grayscale is false indicates that image is color image.\n            img = image.img_to_array(img) ## Convert image pixels into an array.\n            img = img\/255 ## Normalize the test data (CNN converg faster on [0..1] data than on [0..255]).\n            test_data.append(img) ## Add normalized image pixel array to test data.\n    return np.array(test_data) ## Convert list into an array and returns it.","3e06a522":"## Get testing data for the given image path.\ntest_data = load_test_data(image_path)","756f697f":"## Check dimensions of test data.\ntest.shape","ee9fc865":"## Check size of the test_data.\nlen(test_data)","3a7d2ad8":"## Display sample test image.\nplt.imshow(test_data[0], cmap = 'gist_gray')","0b6d30d1":"## Do one hot encoding on target\/label varible.\ny = train['emergency_or_not'].values ## Fetch label\/target values(0\/1).\ny = to_categorical(y) ## Converts a class vector (integers) to binary class matrix.","5860582f":"## Check sample value of target after doing one hot encoding.\ny[0]","5f6bc433":"## Check sample record of target after doing one hot encoding.\ny[5]","dfd8a4e4":"## Split the train data into train and validation data.\nX_train, X_test, y_train, y_test = train_test_split(train_data,       ## Features(i\/p).\n                                                    y,                ## Traget(0\/p).\n                                                    random_state=474, ## It is the seed used by the random number generator.\n                                                    test_size=0.2)    ## % of train and validation division.(80:20)","9ae951c6":"# Define the model structure.\n\n## Instantiate Sequential model.\nmodel = Sequential()\n\n# Convolution layer with feature map size 3X3,32 filters,input shape 28X28X3,Relu Activation function.\nmodel.add(Conv2D(32,  ##  Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n                 kernel_size=(3, 3), ## An integer or tuple\/list of 2 integers, specifying the height and width of the 2D convolution window.Can be a single integer to specify the same value for all spatial dimensions(Feature Map).\n                 padding = 'Same', ## one of \"valid\" or \"same\" (padding is added to the frame of the image to allow for more space for the kernel to cover the image).\n                 activation='relu', ## Activation function.If you don't specify anything, no activation is applied.\n                 input_shape=(28,28,3))) ## Input shapes(28X28X3).\n\n## Convolution layer with feature map size 3X3,64 filters,Relu Activation function.\nmodel.add(Conv2D(64,\n                 kernel_size=(3, 3), \n                 padding = 'Same',\n                 activation='relu'))\n\n## Maxpooling layer with kernal size 2X2,default stride (pool_size).\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n## Droput 25% Nodes.\nmodel.add(Dropout(0.25))\n\n## Convert array data into one dimensional data.\nmodel.add(Flatten())\n\n## Fully connected layer with 128 output shape,Relu Activation function.\nmodel.add(Dense(128, activation='relu'))\n\n## Dropouts 50% Nodes.\nmodel.add(Dropout(0.5))\n\n## Fully connnected layer with 2 output shape,Softmax activation function.\nmodel.add(Dense(2, activation='softmax'))","e502fc44":"# Compile the model.\nmodel.compile(loss='categorical_crossentropy',  ## String (name of objective function) or objective function or`Loss` instance.\n              optimizer='Adam',                 ## String (name of optimizer) or optimizer instance.\n              metrics=['accuracy'])             ## List of metrics to be evaluated by the model during training and testing.","9e467e8b":"# Fit the model.\nmodel.fit(X_train,                            ## Input\/Training data.\n          y_train,                            ## Labels\/Targe\/Output data.\n          epochs=30,                          ## Number of epochs to train the model.\n          validation_data=(X_test, y_test))   ## On which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data(Validation  data).            ","1197bfda":"## Get predictions for test data\nprediction = model.predict_classes(test_data)","efe58248":"## Print first value from predictions\nprediction[0]","e9d05384":"## Copy test data into temp\ntemp = test.copy()","c83e9433":"## Add predictions data to temp data frame with 'emergency_or_not' column name\ntemp ['emergency_or_not'] = prediction","5b2870e2":"## Check first 5 records from temp data\ntemp.head()","10822a7b":"## Check dimensions of data\ntest.shape","c0791a0c":"## Get size of predictions data\nlen(prediction)","f07e6ed8":"## Copy 'image_names', 'emergency_or_not' columns data from temp to to_submit\nto_submit = temp[['image_names', 'emergency_or_not']]","39c11095":"## Check the data value count for 'emergency_or_not' column\nto_submit.emergency_or_not.value_counts()","d784f6db":"## Store to_submit data into a csv file with name Keras_Predictions \nto_submit.to_csv('Keras_Predictions.csv',index = False)","128437a5":"## Set the CNN model.\n## My CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out .\n\n## Instantiate Sequential model.\nmodel = Sequential()\n\n## Convolution layer with feature map size 5X5,32 filters,input shape 28X28X1,Relu Activation function.\nmodel.add(Conv2D(filters = 32, ## Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n                 kernel_size = (5,5), ## An integer or tuple\/list of 2 integers, specifying the height and width of the 2D convolution window.Can be a single integer to specify the same value for 1all spatial dimensions.\n                 padding = 'Same', ## one of `\"valid\"` or `\"same\"`.\n                 activation ='relu',## Activation function.If you don't specify anything, no activation is applied.\n                 input_shape = (28,28,3))) ## input shapes(28X28X3).\n\n## Convolution layer with feature map size 5X5,32 filters,Relu Activation function.\nmodel.add(Conv2D(filters = 32,\n                 kernel_size = (5,5),\n                 padding = 'Same', \n                 activation ='relu'))\n\n## Maxpooling layer with kernal size 2X2,default stride (pool_size).\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n## Droput 25% Nodes.\nmodel.add(Dropout(0.25))\n\n## Convolution layer with feature map size 3X3,64 filters,Relu Activation function.\nmodel.add(Conv2D(filters = 64,\n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\n\n## Convolution layer with feature map size 3X3,64 filters,Relu Activation function.\nmodel.add(Conv2D(filters = 64,\n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\n\n## Maxpooling layer with kernal size 2X2,Stride 2X2.\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\n## Droput 25% Nodes.\nmodel.add(Dropout(0.25))\n\n## Convert array data into one dimensional data.\nmodel.add(Flatten())\n\n## Fully connected layer with 256 output shape,Relu Activation function.\nmodel.add(Dense(256, activation = \"relu\"))\n\n## Dropouts 50% Nodes.\nmodel.add(Dropout(0.5))\n\n## Fully connnected layer with 2 output shape,Softmax activation function.\nmodel.add(Dense(2, activation = \"softmax\"))","96063a66":"## Define the RMSprop optimizer with leaning rate 0.001.\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","69902ee1":"## Compile the model\nmodel.compile(optimizer = optimizer ,            ## String (name of optimizer) or optimizer instance.\n              loss = \"categorical_crossentropy\", ## String (name of objective function) or objective function or`Loss` instance. \n              metrics=[\"accuracy\"])              ## List of metrics to be evaluated by the model during training and testing.","032018e8":"## Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', ## Quantity to be monitored.\n                                            patience=3,     ## Number of epochs that produced the monitored quantity with no improvement after which training will be stopped. \n                                            verbose=1,      ## int. 0: quiet, 1: update messages.\n                                            factor=0.5,     ## Factor by which the learning rate will be reduced. new_lr = lr * factor\n                                            min_lr=0.00001) ## Lower bound on the learning rate.","90c970e3":"## Instantiate Data Augmentation\n\ndatagen = ImageDataGenerator(featurewise_center=False,            ## Set input mean to 0 over the dataset\n                             samplewise_center=False,             ## Set each sample mean to 0\n                             featurewise_std_normalization=False, ## Divide inputs by std of the dataset\n                             samplewise_std_normalization=False,  ## Divide each input by its std\n                             zca_whitening=False,                 ## Apply ZCA whitening\n                             rotation_range=10,                   ## Randomly rotate images in the range (degrees, 0 to 180)\n                             zoom_range = 0.1,                    ## Randomly zoom image \n                             width_shift_range=0.1,               ## Randomly shift images horizontally (fraction of total width)\n                             height_shift_range=0.1,              ## Randomly shift images vertically (fraction of total height)\n                             horizontal_flip=False,               ## Randomly flip images horizontally\n                             vertical_flip=False)                 ## Randomly flip images vertically\n\n## Fit data augmentation model\ndatagen.fit(X_train)","bf4f2f35":"epochs = 30      ## Number of epochs to train a model\nbatch_size = 86  ## Number of sample to process at a time","10789751":"## Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,                           ## Input data\n                                           y_train,                           ## Labels\/ Target\/ out put data\n                                           batch_size=batch_size),            ## Batch size (default: 32)\n                              epochs = epochs,                                ## Number of epochs to train the model.\n                              validation_data = (X_test, y_test),             ## On which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data(Validation data).\n                              verbose = 2,                                    ## 0, 1, or 2. Verbosity mode 0 = silent, 1 = progress bar, 2 = one line per epoch.\n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size, ## Total number of steps (batches of samples) to yield from `generator` before declaring one epoch finished and starting the next epoch. It should typically be equal to `ceil(num_samples \/ batch_size)`\n                              callbacks=[learning_rate_reduction])            ## List of callbacks to apply during training.","ecc211a4":"## Plot the loss and accuracy curves for training and validation data\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","71a5d564":"## Get Predictions for test data\nresults = model.predict(test_data)","88b1125a":"## Print first value from predictions data\nresults[0]","a2fa8192":"## Select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)","7597317c":"## Display first 10 values of results\nresults[:10]","9e443200":"## Check length of results\nlen(results)","dcb97b70":"## Copy test data into temp\ntemp = test.copy()","4e590b02":"## Add predictions data to temp data frame with 'emergency_or_not' column name\ntemp ['emergency_or_not'] = results","807878d4":"## Check first 5 records of temp data\ntemp.head()","f642fa9c":"## Copy 'image_names', 'emergency_or_not' columns data from temp to to_submit\nto_submit = temp[['image_names', 'emergency_or_not']]","df5c5ca9":"## Check the data value count for 'emergency_or_not' column\nto_submit.emergency_or_not.value_counts()","cf793446":"## Check first 5 records of to_submit data\nto_submit.head()","9e8f5541":"## Store to_submit data into a csv file with name Keras_Predictions_With_DataAugmentation \nto_submit.to_csv('Keras_Predictions_With_DataAugmentation.csv',index = False)","0abbfa9a":"Approaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more. \n\nBy applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.\n\nThe improvement is important : \n   - Without data augmentation i have obtained an accuracy of 78%\n   - With data augmentation i have achieved 82% of accuracy","996f29b3":"![](https:\/\/datahack-prod.s3.ap-south-1.amazonaws.com\/__sized__\/contest_cover\/cover_FJJYomD-thumbnail-1200x1200-90.jpg)\n\n## Problem Statement\n\nEmergency vs Non-Emergency Vehicle Classification\nFatalities due to traffic delays of emergency vehicles such as ambulance & fire brigade is a huge problem. In daily life, we often see that emergency vehicles face difficulty in passing through traffic. So differentiating a vehicle into an emergency and non emergency category can be an important component in traffic monitoring as well as self drive car systems as reaching on time to their destination is critical for these services.\n\nIn this problem, you will be working on classifying vehicle images as either belonging to the emergency vehicle or non-emergency vehicle category. For the same, you are provided with the train and the test dataset. Emergency vehicles usually includes police cars, ambulance and fire brigades.\n\n![](https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2018\/08\/Emgen.jpg)\n\n**Data Description** \n\n- train.zip: contains 2 csvs and 1 folder containing image data\n\n       train.csv \u2013[\u2018image_names\u2019,\u2018emergency_or_not\u2019] contains the image name and correct class for 1646 (70%) train images\n       images \u2013 contains 2352 images for both train and test sets\n        \n- test.csv: [\u2018image_names\u2019] contains just the image names for the 706 (30%) test images\n\n- sample_submission.csv: [\u2018image_names\u2019,\u2019emergency_or_not\u00ad\u2019] contains the exact format for a valid submission (1 - For Emergency Vehicle, 0 - For Non Emergency Vehicle)\n\n**Evaluation Metric**\n\nThe evaluation metric for this competition is Accuracy.\n\nCompetition Reference Link : https:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-computer-vision-hackathon\/True\/#ProblemStatement\n\nTutorial Reference Link : https:\/\/www.analyticsvidhya.com\/blog\/2019\/01\/build-image-classification-model-10-minutes\/","c22cd6df":"# Introduction\n\n\n## <a>What are Neural Networks <\/a>\n\nNeural networks are a type of machine learning models which are designed to operate similar to biological neurons and human nervous system. These models are used to recognize complex patterns and relationships that exists within a labelled dataset. They have following properties:\n\n1. The core architecture of a Neural Network model is comprised of a large number of simple processing nodes called Neurons which are interconnected and organized in different layers. \n\n2. An individual node in a layer is connected to several other nodes in the previous and the next layer. The inputs form one layer are received and processed to generate the output which is passed to the next layer.\n\n3. The first layer of this architecture is often named as input layer which accepts the inputs, the last layer is named as the output layer which produces the output and every other layer between input and output layer is named is hidden layers. \n\n![](https:\/\/i.imgur.com\/McMOhuQ.png)\n\n### Key concepts in a Neural Network \n\n#### A. Neuron:\n\nA Neuron is a single processing unit of a Neural Network which are connected to different other neurons in the network. These connections repersents inputs and ouputs from a neuron. To each of its connections, the neuron assigns a \u201cweight\u201d (W) which signifies the importance the input and adds a bias (b) term. \n\n![](https:\/\/miro.medium.com\/max\/888\/1*cmg8u0Asyx0RFQQNkRwKMg.png)\n\n#### B. Activation Functions \n\nThe activation functions are used to apply non-linear transformation on input to map it to output. The aim of activation functions is to predict the right class of the target variable based on the input combination of variables. Some of the popular activation functions are Relu, Sigmoid, and TanH. \n\n![](https:\/\/www.researchgate.net\/profile\/Vivienne_Sze\/publication\/315667264\/figure\/fig3\/AS:669951052496900@1536740186369\/Various-forms-of-non-linear-activation-functions-Figure-adopted-from-Caffe-Tutorial.png)\n\n#### C. Forward Propagation \n\nNeural Network model goes through the process called forward propagation in which it passes the computed activation outputs in the forward direction. \n\nZ = W*X + b   \nA = g(Z) \n\n- g is the activation function \n- A is the activation using the input \n- W is the weight associated with the input \n- B is the bias associated with the node \n\n![](https:\/\/www.bogotobogo.com\/python\/scikit-learn\/images\/NeuralNetwork2-Forward-Propagation\/NN-with-components-w11-etc.png)\n\n#### D. Error Computation: \n\nThe neural network learns by improving the values of weights and bias. The model computes the error in the predicted output in the final layer which is then used to make small adjustments the weights and bias. The adjustments are made such that the total error is minimized. Loss function measures the error in the final layer and cost function measures the total error of the network. \n\nLoss = Actual_Value - Predicted_Value   \n\nCost = Summation (Loss)   \n\n#### E. Backward Propagation: \n\nNeural Network model undergoes the process called backpropagation in which the error is passed to backward layers so that those layers can also improve the associated values of weights and bias. It uses the algorithm called Gradient Descent in which the error is minimized and optimal values of weights and bias are obtained. This weights and bias adjustment is done by computing the derivative of error, derivative of weights, bias and subtracting them from the original values. \n\n![](https:\/\/miro.medium.com\/max\/1400\/1*LB10KFg5J7yK1MLxTXcLdQ.jpeg)\n\n<br>\n\n<br>\n\n###  Convolutional Neural Networks \n\nIn Convolutional Neural Networks, every image input is treated as a a matrix of pixel values which represents the amount of darkness at a given pixel in the image. Unlike, tradational neural networks which treats an image as a one dimentional network, CNNs considers the location of pixels and the neighbours for classification.\n\n<br>\n\n![](http:\/\/www.mdpi.com\/information\/information-07-00061\/article_deploy\/html\/images\/information-07-00061-g001.png)\n\n<br>\n\n### Key components of Convolutional Neural Network. \n\n**A. Convolutional layer:** In this layer, a kernel (or weight) matrix is used to extract low level features from the images. The kernel with its weights rotates over the image matrix in a sliding window fashion in order to obtained the convolved output. The kernel matrix behaves like a filter in an image extracting particular information from the original image matrix. During the colvolution process, The weights are learnt such that the loss function is minimized.\n\n![](https:\/\/ds055uzetaobb.cloudfront.net\/brioche\/uploads\/MDyKhb5tXY-1_hbp1vrfewnareprrlnxtqq2x.png?width=500)\n\n**B. Stride:** Stride is defined as the number of steps the kernel or the weight matrix takes while moving across the entire image moving N pixel at a time. If the weight matrix moves N pixel at a time, it is called stride of N.\n\n![](http:\/\/deeplearning.net\/software\/theano\/_images\/numerical_padding_strides.gif) \n\n**C. Pooling Layer:**  Pooling layers are used to extract the most informative features from the generated convolved output.It reduces the size of the data and most commonly used poolings are max pooling,average pooling.\n\nEx: Max Pooling\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/e\/e9\/Max_pooling.png)\n\n**D. Output Layer:** To generate the final output, a dense or a fully connected layer is applied with the softmax activation function. Softmax function is used to generate the probabilities for each class of the target variable. \n\n**E. Dropout:** In machine learning, regularization is way to prevent over-fitting. Regularization reduces over-fitting by adding a penalty to the loss function. By adding this penalty, the model is trained such that it does not learn interdependent set of features weights.Dropout is an approach to regularization in neural networks which helps reducing interdependent learning amongst the neurons.\n\n![](https:\/\/miro.medium.com\/max\/1200\/1*iWQzxhVlvadk6VAJjsgXgg.png)\n\n**F. Flatten:** Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer. In other words, we put all the pixel data in one line and make connections with the final layer.\n\n![](https:\/\/sds-platform-private.s3-us-east-2.amazonaws.com\/uploads\/73_blog_image_1.png)\n\n**G. Optimizer:** Optimization algorithms helps us to minimize (or maximize) an Objective function (another name for Error function).\n\n![](https:\/\/miro.medium.com\/max\/578\/1*65Mxg_Yfq-L7AvaS0K5aGA.png)\n\n**H. Data augmentation:** Data augmentation is the process of increasing the amount and diversity of data. We do not collect new data, rather we transform the already present data. \n\n   **Need for data augmentation:** Data augmentation is an integral process in deep learning, as in deep learning we need large amounts of data and in some cases it is not feasible to collect thousands or millions of images, so data augmentation comes to the rescue.The most commonly used operations are Rotation,Shearing,Zooming,Cropping,Flipping,Changing the brightness level.\n\n**Original Image**   \n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190904224635\/original2.jpg\"><\/img>\n\n**Rotation with 40 degress**\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190904223915\/rotate1.jpeg\"><\/img>\n\n**Zooming**\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190904223919\/zoom1.jpeg\"><\/img>\n\n**Flipping**\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190904223910\/flip1.jpeg\"><\/img>\n\n**Changing Brightness Level**\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190904224635\/original2.jpg\"><\/img>\n\n**I. Call back\/Early stopping:** Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset.\n\n<img src=\"https:\/\/www.mdpi.com\/sensors\/sensors-19-05180\/article_deploy\/html\/images\/sensors-19-05180-g002.png\"><\/img> \n\n**J. Normalization:**  We perform a grayscale normalization to reduce the effect of illumination's differences.Moreover the CNN converg faster on [0..1] data than on [0..255].\n\n**K. Reshape:** In Keras the Convolution layer requirest an additional dimension which will be used for the various filter.Most convolutional neural networks are designed in a way so that they can only accept images of a fixed size. This creates several challenges during data acquisition and model deployment. The common practice to overcome this limitation is to reshape the input images so that they can be fed into the networks. Many standard pre-trained networks and datasets come with a provision of working with square images.\n\nEx: Reshape image in 3 dimensions (height = 28px, width = 28px , chanel = 1).reshaped 784px vectors to 28x28x3 3D matrices.\n![](https:\/\/i.stack.imgur.com\/nfYtQ.jpg)\n\n**L. OneHotEncoding:** Many machine learning algorithms cannot work with categorical data directly. The categories must be converted into numbers. This is required for both input and output variables that are categorical.OneHoorEncoding refers to splitting the column which contains numerical categorical data to many columns depending on the number of categories present in that column. Each column contains \u201c0\u201d or \u201c1\u201d corresponding to which column it has been placed.\n\n![](https:\/\/i.imgur.com\/mtimFxh.png)\n\n**M. Padding:** In order to assist the kernel with processing the image, padding is added to the frame of the image to allow for more space for the kernel to cover the image. Adding padding to an image processed by a CNN allows for more accurate analysis of images.\n\nEx: For an (8 x 8) image and (3 x 3) filter, the output resulting after convolution operation would be of size (6 x 6). Thus, the image shrinks every time a convolution operation is performed. This places an upper limit to the number of times such an operation could be performed before the image reduces to nothing thereby precluding us from building deeper networks.\nAlso, the pixels on the corners and the edges are used much less than those in the middle.\n\n![](https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/20190721011218\/Screenshot-2019-07-16-at-1.35.20-AM.png)\n\nClearly, pixel A is touched in just one convolution operation and pixel B is touched in 3 convolution operations, while pixel C is touched in 9 convolution operations. In general, pixels in the middle are used more often than pixels on corners and edges. Consequently, the information on the borders of images are not preserved as well as the information in the middle.\nTo overcome these problems, we use padding.\n\n![](https:\/\/s3-us-west-2.amazonaws.com\/static.pyimagesearch.com\/keras-conv2d\/keras_conv2d_padding.gif)\n\n**N.Batch Size:** The batch size defines the number of samples that will be propagated through the network.\n\nEx: Let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1st to 100th) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101st to 200th) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network. Problem might happen with the last set of samples. In our example, we've used 1050 which is not divisible by 100 without remainder. The simplest solution is just to get the final 50 samples and train the network.\n\n**Advantages :** It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n\nTypically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. If we used all samples during propagation we would make only 1 update for the network's parameter.\n\n![](https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2018\/11\/Line-Plots-of-Classification-Accuracy-on-Train-and-Test-Datasets-With-Different-Batch-Sizes.png)\n\n**O. Epoch:** An epoch describes the number of times the algorithm sees the entire data set. So, each time the algorithm has seen all samples in the dataset, an epoch has completed.\n\n![](https:\/\/www.researchgate.net\/profile\/Ruimin_Ke\/publication\/323625412\/figure\/fig3\/AS:614088652623879@1523421552170\/CNN-Model-accuracy-curves-train-and-test-during-the-100-epoch-training-process.png)\n\n**P. Iteration:** The number of forward passes (The number of batches that you have created) that your network has to do in order to complete one epoch (i.e., going over all training instances) is called Iteration.\n\n<br>","dc2318ff":"## Set the optimizer and annealer\n\nOnce our layers are added to the model, we need to set up a score function, a loss function and an optimisation algorithm.\n\nWe define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications called the \"categorical_crossentropy\".\n\nThe most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss. \n\nI choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate.\nWe could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop.\n\nThe metric function \"accuracy\" is used is to evaluate the performance our model.\nThis metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation).","82082aee":"## tqdm ----> It is used to print Progress Bars\n\nReference Link : https:\/\/medium.com\/better-programming\/python-progress-bars-with-tqdm-by-example-ce98dbbc9697\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*xwvLepJ3x39UGBXQvQc4jg.gif)","213f74f3":"For the data augmentation, i have choosed to :\n   - Randomly rotate some training images by 10 degrees\n   - Randomly Zoom by 10% some training images\n   - Randomly shift images horizontally by 10% of the width\n   - Randomly shift images vertically by 10% of the height\n   \nI did not apply a vertical_flip nor horizontal_flip since model was giving less performence with these two options.\n\nOnce our model is ready, we fit the training dataset .","112d9937":"## Define a Model\n\nI used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n\nThe first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 32 filters for the two firsts conv2D layers and 64 filters for the two last ones. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\nThe CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n\nThe second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important. \n\nCombining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n\nDropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting. \n\n'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network. \n\nThe Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional\/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\nIn the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(2,activation=\"softmax\")) the net outputs distribution of probability of each class.","df679786":"In order to make the optimizer converge faster and closest to the global minimum of the loss function, i used an annealing method of the learning rate (LR).\n\nThe LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima.\n\nIts better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function. \n\nTo keep the advantage of the fast computation time with a high LR, i decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).\n\nWith the ReduceLROnPlateau function from Keras.callbacks, i choose to reduce the LR by half if the accuracy is not improved after 3 epochs.","a633cdf9":"## Approach : 2 (With Data Augmentation)","f52162bf":"## Approach : 1 (With Out Data Augmentation)"}}