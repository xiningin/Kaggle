{"cell_type":{"5b435599":"code","e2074984":"code","411b78f9":"code","741f244a":"code","d7fa7eb4":"code","d2e30cf5":"code","1157105d":"code","7e777d5d":"code","e4fa92a0":"code","dc453eec":"code","9e0db254":"code","7592ae09":"code","d8d9d206":"markdown","7c0ba17d":"markdown","c631d408":"markdown","9fb23483":"markdown","59279111":"markdown","b482802c":"markdown","8d2d6789":"markdown"},"source":{"5b435599":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e2074984":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization, Add, Input, ZeroPadding2D, AveragePooling2D\nfrom keras.initializers import glorot_uniform\nimport matplotlib.pyplot as plt\nimport cv2\nfrom glob import glob\nfrom numpy import floor\nimport random\nfrom numpy.random import seed\nseed(1)","411b78f9":"def plot_three_samples(letter):\n    print(\"ASL Alphabet for letter: \"+letter)\n    base_path = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/'\n    img_path = base_path + letter + '\/**'\n    path_contents = glob(img_path)\n    \n    plt.figure(figsize=(16,16))\n    imgs = random.sample(path_contents,3)\n    plt.subplot(1,3,1)\n    plt.imshow(cv2.imread(imgs[0]))\n    plt.subplot(1,3,2)\n    plt.imshow(cv2.imread(imgs[1]))\n    plt.subplot(1,3,3)\n    plt.imshow(cv2.imread(imgs[2]))\n    \n    return\n\nplot_three_samples('S')","741f244a":"path = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\npath_test = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\ntarget_size = (64,64)\ntarget_dims = (64,64,3)\nval_frac = 0.1\nn_classes = 29\nbatch_size = 64\n\nimage_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True, validation_split=val_frac)\n\ntrain_gen = image_generator.flow_from_directory(path, target_size=target_size, batch_size=batch_size, shuffle=True, subset='training')\nval_gen = image_generator.flow_from_directory(path, target_size=target_size, subset='validation')","d7fa7eb4":"def identity_block(X,f,filters, stage, block):\n  #defining name basis\n  conv_name_base = 'res' +str(stage)+block+'_branch'\n  bn_name_base = 'bn' +str(stage)+block+'_branch'\n\n  #Retrive Filters\n  F1,F2,F3 = filters\n\n  X_shortcut = X\n\n  X = Conv2D(filters=F1, kernel_size=(1,1), strides = (1,1), padding='valid', name = conv_name_base+'2a',kernel_initializer=glorot_uniform(seed=0))(X)\n  X = BatchNormalization(axis = 3, name = bn_name_base+'2a')(X)\n  X = Activation('relu')(X)\n\n  X = Conv2D(filters=F2, kernel_size=(f,f), strides = (1,1), padding='same', name = conv_name_base+'2b',kernel_initializer=glorot_uniform(seed=0))(X)\n  X = BatchNormalization(axis = 3, name = bn_name_base+'2b')(X)\n  X = Activation('relu')(X)\n\n  X = Conv2D(filters=F3, kernel_size=(1,1), strides = (1,1), padding='valid', name = conv_name_base+'2c',kernel_initializer=glorot_uniform(seed=0))(X)\n  X = BatchNormalization(axis = 3, name = bn_name_base+'2c')(X)\n  X = Add()([X, X_shortcut])\n  X = Activation('relu')(X)\n\n  return X","d2e30cf5":"def convolutional_block(X, f, filters, stage, block, s=2):\n  conv_name_base = 'res' +str(stage)+block+'_branch'\n  bn_name_base = 'bn' +str(stage)+block+'_branch'\n\n  F1,F2,F3 = filters\n\n  X_shortcut = X\n\n  X = Conv2D(filters=F1, kernel_size=(1,1), strides = (s,s), name = conv_name_base+'2a',kernel_initializer=glorot_uniform(seed=0))(X)\n  X = BatchNormalization(axis = 3, name = bn_name_base+'2a')(X)\n  X = Activation('relu')(X)\n\n  X = Conv2D(filters=F2, kernel_size=(f,f), strides = (1,1),padding='same', name = conv_name_base+'2b',kernel_initializer=glorot_uniform(seed=0))(X)\n  X = BatchNormalization(axis = 3, name = bn_name_base+'2b')(X)\n  X = Activation('relu')(X)\n\n  X = Conv2D(filters=F3, kernel_size=(1,1), strides = (1,1),padding='valid', name = conv_name_base+'2c',kernel_initializer=glorot_uniform(seed=0))(X)\n  X = BatchNormalization(axis = 3, name = bn_name_base+'2c')(X)\n\n  X_shortcut = Conv2D(filters=F3, kernel_size=(1,1), strides = (s,s), name = conv_name_base+'1',kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n  X_shortcut = BatchNormalization(axis = 3, name = bn_name_base+'1')(X_shortcut)\n  X = Add() ([X, X_shortcut])\n  X = Activation('relu')(X)\n\n  return X","1157105d":"def ResNet50(input_shape = (64,64,3), classes = 29):\n  X_input = Input(input_shape)\n\n  #Zero padding\n  X = ZeroPadding2D((3,3))(X_input)\n\n  #stage 1\n  X = Conv2D(64,(7,7),strides=(2,2), name = 'conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n  X = BatchNormalization(axis=3, name = 'bn_conv1')(X)\n  X = Activation('relu')(X)\n  X = MaxPooling2D((3,3), strides=(2,2))(X)\n\n  #stage 2\n  X = convolutional_block(X, f=3, filters=[64, 64, 256], stage = 2, block='a', s=1)\n  X = identity_block(X, 3, [64,64,256], stage=2, block='b')\n  X = identity_block(X,3,[64,64,256], stage = 2, block = 'c')\n\n  #stage 3\n  X = convolutional_block(X, f=3, filters=[128, 128, 512], stage = 3, block='a', s=2)\n  X = identity_block(X, 3, filters=[128, 128, 512], stage=3, block='b')\n  X = identity_block(X,3,filters=[128, 128, 512], stage = 3, block = 'c')\n  X = identity_block(X,3,filters=[128, 128, 512], stage = 3, block = 'd')\n\n  #stage 4\n  X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage = 4, block='a', s=2)\n  X = identity_block(X, 3, filters=[256, 256, 1024], stage=4, block='b')\n  X = identity_block(X,3,filters=[256, 256, 1024], stage = 4, block = 'c')\n  X = identity_block(X,3,filters=[256, 256, 1024], stage = 4, block = 'd')\n  X = identity_block(X,3,filters=[256, 256, 1024], stage = 4, block = 'f')\n\n  #stage 5\n  X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage = 5, block='a', s=2)\n  X = identity_block(X, 3, filters=[512, 512, 2048], stage=5, block='b')\n  X = identity_block(X,3,filters=[512, 512, 2048], stage = 5, block = 'c')\n\n  X = AveragePooling2D((2,2), name = 'avg_pool')(X)\n\n  X = Flatten()(X)\n  X = Dense(classes, activation='softmax', name='fc'+str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n\n  model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n  return model","7e777d5d":"model = ResNet50()","e4fa92a0":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","dc453eec":"tf.keras.utils.plot_model(model, show_shapes=True)","9e0db254":"history = model.fit_generator(train_gen,epochs=5, validation_data=val_gen)","7592ae09":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='upper left')\nplt.show()","d8d9d206":"## Data preprocessing","7c0ba17d":"# ASL-Alphabet-Using CNN Keras","c631d408":"## import library","9fb23483":"I'm using Kaggle kernel to make the model for ASL-Alphabet using CNN Keras using resnet50","59279111":"### the architecture","b482802c":"## Resnet50 Architecture","8d2d6789":" ## show sample data\n thank you DanB for the show sample data function"}}