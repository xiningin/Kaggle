{"cell_type":{"baf75b8c":"code","fd69fc84":"code","806a20a6":"code","2e80200a":"code","ab85fefd":"code","e9f56131":"code","c34b8167":"code","45da6ab2":"code","ac1cb020":"code","cb9bd4cd":"code","ce1d454b":"code","d5ac82d1":"code","09b97743":"code","aed40982":"code","db1efb3c":"code","ed15d2e0":"code","36295a59":"code","397b250b":"code","a98059c0":"markdown","382e2fd6":"markdown","1eca0507":"markdown","86b3d64f":"markdown"},"source":{"baf75b8c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fd69fc84":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","806a20a6":"train=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","2e80200a":"print(train.select_dtypes(include=object).columns)","ab85fefd":"train.describe()","e9f56131":"from sklearn.preprocessing import LabelEncoder\n\nfor i in range(train.shape[1]):\n    if train.iloc[:,i].dtypes == object:\n        lbl = LabelEncoder()\n        lbl.fit(list(train.iloc[:,i].values) + list(test.iloc[:,i].values))\n        train.iloc[:,i] = lbl.transform(list(train.iloc[:,i].values))\n        test.iloc[:,i] = lbl.transform(list(test.iloc[:,i].values))","c34b8167":"train.info()","45da6ab2":"train.head()","ac1cb020":"# keep ID for submission\ntrain_ID = train['Id']\ntest_ID = test['Id']\n\n# split data for training\ny_train = train['SalePrice']\nX_train = train.drop(['Id','SalePrice'], axis=1)\nX_test = test.drop('Id', axis=1)\n\n# dealing with missing data\nXmat = pd.concat([X_train, X_test])\nXmat = Xmat.drop(['LotFrontage','MasVnrArea','GarageYrBlt'], axis=1)\nXmat = Xmat.fillna(Xmat.median())","cb9bd4cd":"Xmat['TotalSF']=Xmat['TotalBsmtSF']+Xmat['1stFlrSF']+Xmat['2ndFlrSF']","ce1d454b":"y_train=np.log(y_train)\nax=sns.distplot(y_train)\nplt.show()","d5ac82d1":"X_train.shape","09b97743":"X_train.info()","aed40982":"X_train['LotFrontage']=X_train['LotFrontage'].apply('int64')\nX_train['MasVnrArea']=X_train['MasVnrArea'].apply('int64')\nX_train['GarageYrBlt']=X_train['GarageYrBlt'].apply('int64')","db1efb3c":"X_train.drop(X_train.columns[np.isnan(X_train).any()], axis=1)","ed15d2e0":"X_train.shape","36295a59":"import missingno as msno\nmsno.matrix(df=train, figsize=(20,14), color=(0.5,0,0))","397b250b":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=79, max_features='auto')\nrf.fit(X_train, y_train)\nprint('Training done using Random Forest')\n\nranking = np.argsort(-rf.feature_importances_)\nf, ax = plt.subplots(figsize=(11, 9))\nsns.barplot(x=rf.feature_importances_[ranking], y=X_train.columns.values[ranking], orient='h')\nax.set_xlabel(\"feature importance\")\nplt.tight_layout()\nplt.show()","a98059c0":"# \u65b0\u3057\u3044\u5217 (feature) \u3092\u4f5c\u308b","382e2fd6":"# Label Encoder","1eca0507":"# \u3069\u306efeature\u304c\u5927\u5207\u306a\u306e\u304b\u30c1\u30a7\u30c3\u30af\u3059\u308b","86b3d64f":"'...SF'\u3068\u3044\u3046\u540d\u306eFeature\u304c\u8907\u6570\u767b\u5834\u3059\u308b\u306e\u3067\u3001\u305d\u308c\u3089\u3092\u307e\u3068\u3081\u305fFeature\u3092\u4f5c\u308b"}}