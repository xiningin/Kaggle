{"cell_type":{"cb6856d5":"code","eb9f4be5":"code","746666e3":"code","ed5432cf":"code","f2bd04c7":"code","d83d9e8a":"code","2bd891ac":"code","056a560e":"code","be1ddb3b":"code","9b181daf":"code","547c3205":"code","3df0dc82":"code","b22e1b39":"code","7417b4ee":"code","b836e57d":"markdown","bfe029cb":"markdown","0d5dac79":"markdown","afb30ad4":"markdown","94abc7f2":"markdown","bcac49f4":"markdown"},"source":{"cb6856d5":"!pip install -q tensorflow-gpu==1.15.0 --use-feature=2020-resolver","eb9f4be5":"!git clone https:\/\/github.com\/r9y9\/deepvoice3_pytorch\n%cd deepvoice3_pytorch","746666e3":"!pip install -e '.[bin]'","ed5432cf":"!pip install -q librosa nltk","f2bd04c7":"import torch\nimport numpy as np\nimport nltk\nimport librosa\nimport librosa.display \nimport IPython\nfrom IPython.display import Audio","d83d9e8a":"!python -m nltk.downloader cmudict","2bd891ac":"preset = \"20180505_deepvoice3_ljspeech.json\"\ncheckpoint_path = \"20180505_deepvoice3_checkpoint_step000640000.pth\"","056a560e":"!curl -O -L \"https:\/\/www.dropbox.com\/s\/0ck82unm0bo0rxd\/20180505_deepvoice3_ljspeech.json\"\n!curl -O -L \"https:\/\/www.dropbox.com\/s\/5ucl9remrwy5oeg\/20180505_deepvoice3_checkpoint_step000640000.pth\"","be1ddb3b":"import hparams\nimport json\n\n    \n# Load parameters from preset\nwith open(preset) as f:\n    hparams.hparams.parse_json(f.read())\n\n# Inject frontend text processor\nimport synthesis\nimport train\nfrom deepvoice3_pytorch import frontend\nsynthesis._frontend = getattr(frontend, \"en\")\ntrain._frontend =  getattr(frontend, \"en\")\n\n# alises\nfs = hparams.hparams.sample_rate\nhop_length = hparams.hparams.hop_size","9b181daf":"def tts(model, text, p=0, speaker_id=None, fast=True, figures=True):\n    from synthesis import tts as _tts\n    waveform, alignment, spectrogram, mel = _tts(model, text, p, speaker_id, fast)\n    if figures:\n        visualize(alignment, spectrogram)\n    IPython.display.display(Audio(waveform, rate=fs))","547c3205":"import matplotlib.pyplot as plt\ndef visualize(alignment, spectrogram):\n    label_fontsize = 16\n    plt.figure(figsize=(16,16))\n\n    plt.subplot(2,1,1)\n    plt.imshow(alignment.T, aspect=\"auto\", origin=\"lower\", interpolation=None)\n    plt.xlabel(\"Decoder timestamp\", fontsize=label_fontsize)\n    plt.ylabel(\"Encoder timestamp\", fontsize=label_fontsize)\n    plt.colorbar()\n\n    plt.subplot(2,1,2)\n    librosa.display.specshow(spectrogram.T, sr=fs, \n                           hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\")\n    plt.xlabel(\"Time\", fontsize=label_fontsize)\n    plt.ylabel(\"Hz\", fontsize=label_fontsize)\n    plt.tight_layout()\n    plt.colorbar()","3df0dc82":"from train import build_model\nfrom train import restore_parts, load_checkpoint\n\nmodel = build_model()\nmodel = load_checkpoint(checkpoint_path, model, None, True)","b22e1b39":"# Try your favorite senteneces:)\ntexts = [\n    \"Scientists at the CERN laboratory say they have discovered a new particle.\",\n    \"There's a way to measure the acute emotional intelligence that has never gone out of style.\",\n    \"President Trump met with other leaders at the Group of 20 conference.\",\n    \"The Senate's bill to repeal and replace the Affordable Care Act is now imperiled.\",\n    \"Generative adversarial network or variational auto-encoder.\",\n    \"The buses aren't the problem, they actually provide a solution.\",\n    \"peter piper picked a peck of pickled peppers how many peppers did peter piper pick.\",\n    \"Some have accepted this as a miracle without any physical explanation.\",\n]\n\nfor idx, text in enumerate(texts):\n    print(idx, text)\n    tts(model, text, figures=False)","7417b4ee":"# With attention plot\ntext = \"Generative adversarial network or variational auto-encoder.\"\ntts(model, text, figures=True)","b836e57d":"# DeepVoice3\n## load pre-trained model & Text-To-Speech Synthesis","bfe029cb":"## Synthesis","0d5dac79":"## Generate Speech","afb30ad4":"### Load the model checkpoint","94abc7f2":"## Download a pre-trained model","bcac49f4":"## Repro [Github](https:\/\/github.com\/r9y9\/deepvoice3_pytorch)"}}