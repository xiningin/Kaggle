{"cell_type":{"6b132e9f":"code","865d03da":"code","a7b15791":"code","c249d603":"code","ceb1749b":"code","b49e2bd0":"code","17ac7717":"code","f86e5d45":"code","79596d5c":"code","73d24978":"code","d4ea7dde":"code","e1a4750f":"markdown","6d08202c":"markdown","d509f110":"markdown","f24a84fb":"markdown","ecb5878c":"markdown","b45c0496":"markdown","e8773c40":"markdown","fdf3cc1f":"markdown","b1955dd2":"markdown","9a1db9dc":"markdown"},"source":{"6b132e9f":"import io\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","865d03da":"#Copying current content to new editable directory\n!cp -r \"..\/input\/microsoft-catsvsdogs-dataset\/PetImages\/\" \"\/kaggle\/working\/\"\n\n#Selecting dataset directory\nds_pet_dir = \"\/kaggle\/working\/PetImages\/\"\n\n#Generating a dataset\nds_pet = tf.keras.preprocessing.image_dataset_from_directory(ds_pet_dir)","a7b15791":"#Listing directory. You can find the class names in the class_names attribute on these datasets. These correspond to the directory names in alphabetical order.\n!ls \"\/kaggle\/working\/PetImages\/\"\n#Or\nds_pet.class_names","c249d603":"#Checking images and labels shapes (amount of images, height, width, color channels)\nfor image_batch, labels_batch in ds_pet:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","ceb1749b":"#Displaying image samples (label 0 is \"cat\" and label 1 is \"dog\")\nplt.figure(figsize=(10, 10))\nfor images, labels in ds_pet.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","b49e2bd0":"#Defining parameters for the loader:\nbatch_size = 32\nimg_height = 180\nimg_width = 180\n\n#Filtering out corrupted images\nimport os\nnum_skipped = 0\nfor folder_name in (\"Cat\", \"Dog\"):\n    folder_path = os.path.join(ds_pet_dir, folder_name)\n    for fname in os.listdir(folder_path):\n        fpath = os.path.join(folder_path, fname)\n        try:\n            fobj = open(fpath, \"rb\")\n            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n        finally:\n            fobj.close()\n        if not is_jfif:\n            num_skipped += 1\n            # Delete corrupted image\n            os.remove(fpath)\nprint(\"Deleted %d images\" % num_skipped)\n\n#Data augmentation\ndata_augmentation = keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1)])\n\n#Setting train\/test split\nds_pet_train = tf.keras.preprocessing.image_dataset_from_directory(\n    ds_pet_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)\nds_pet_test = tf.keras.preprocessing.image_dataset_from_directory(\n    ds_pet_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)","17ac7717":"#Displaying a random augmented image sample\nplt.figure(figsize=(10, 10))\nfor images, _ in ds_pet_train.take(1):\n  for i in range(9):\n    augmented_images = data_augmentation(images)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","f86e5d45":"#Checking if the data format i.e the RGB channel is coming first or last so, whatever it may be, model will check first and then input shape will be feeded accordingly.\nfrom keras import backend as K\nif K.image_data_format() == \"channels_first\":\n    input_shape = (3, img_height, img_width)\nelse:\n    input_shape = (img_height, img_width, 3)\n\n#Creating a model\nmodel_dl = Sequential([\n  data_augmentation,\n  layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(input_shape)),\n  layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.5),\n  layers.Flatten(),\n  layers.Dense(128, activation=\"relu\"),\n  layers.Dense(1, activation=\"sigmoid\")\n])","79596d5c":"#Compiling the neural network\nmodel_dl.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\n#Fitting to the model\nmodel_dl.fit(ds_pet_train, validation_data=ds_pet_test, epochs=3)","73d24978":"#Saving the model\nmodel_dl.save(\"model_dl.h5\")\n\n#Loading themodel\nmodel_dl = keras.models.load_model(\"model_dl.h5\") #look for local saved file","d4ea7dde":"#Using a random cat picture found in the web\npicture_url = \"https:\/\/placekitten.com\/g\/200\/300\"\npicture_path = tf.keras.utils.get_file(\"300\", origin=picture_url)\n\nimg = keras.preprocessing.image.load_img(picture_path, target_size=(img_height, img_width))\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model_dl.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\n\nprint(\"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(ds_pet.class_names[np.argmax(score)], 100 * np.max(score)))","e1a4750f":"# 2. Importing Basic Libraries","6d08202c":"# 7. Data Modelling","d509f110":"# 3. Data Collection","f24a84fb":"# 10. Conclusions\n\nWe were able to develop a deep learning model to classify imagens between cats and dogs with 79% accuracy.","ecb5878c":"# 9. Model Deployment","b45c0496":"# 8. Deep Learning Algorithm Implementation & Assessment","e8773c40":"# 4. Data Preliminary Exploration","fdf3cc1f":"# 6. Data Exploration","b1955dd2":"# 1. Introduction: Business Goal & Problem Definition\n\nThis projects goal is developing a model able to identify \"Cats\" and \"Dogs\" photos. I\u00b4m using a Kaggle dataset comtaining 12.5k Cats and 12.5k Dogs pictures.","9a1db9dc":"# 5. Data Preparation"}}