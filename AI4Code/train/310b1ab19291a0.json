{"cell_type":{"1467db51":"code","dbff905f":"code","f8344125":"code","289f89a4":"code","ec8c5eea":"code","952f218c":"code","90050e25":"code","8b1c2992":"code","b29b7baf":"code","88ce451e":"markdown","d45d65b2":"markdown","7df9f8b9":"markdown","440238a6":"markdown","7692d54b":"markdown","bf400c6d":"markdown","7cfc17a5":"markdown","0d01e47f":"markdown","9871e0c0":"markdown","d7ac3825":"markdown","e9e7c544":"markdown","e842f70c":"markdown","d07454b4":"markdown","282e29d3":"markdown"},"source":{"1467db51":"if \"Data Is Gaussian\":\n    \"Use Parametric Statistical Methods\"\nelse:\n    \"Use Nonparametric Statistical Methods\"","dbff905f":"# generate gaussian data\nimport numpy as np\nimport scipy.stats as stats\nimport random\nrandom.seed(42)\n\n# generate univariate observations\ndata =  stats.norm(scale=1, loc=0).rvs(1000)\n\n# summarize\nprint('mean=%.3f stdv=%.3f' % (np.mean(data), np.std(data)))","f8344125":"import plotly.express as px\nfig = px.histogram(data,title='Histogram using Plotly')\nfig.show()","289f89a4":"import seaborn as sns\nsns.histplot(data).set_title('Histogram using Seaborn')","ec8c5eea":"import matplotlib.pyplot as plt\nplt.hist(data)\nplt.title('Histogram using Matplotlib')\nplt.show()","952f218c":"from statsmodels.graphics.gofplots import qqplot\nfrom matplotlib import pyplot\n# q-q plot\nqqplot(data, line='s')\npyplot.show()","90050e25":"# Shapiro-Wilk Test\nfrom scipy.stats import shapiro\n# normality test\nstat, p = shapiro(data)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret results\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","8b1c2992":"# D'Agostino and Pearson's Test\nfrom scipy.stats import normaltest\n# normality test\nstat, p = normaltest(data)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret results\nalpha = 0.05\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')","b29b7baf":"# Anderson-Darling Test\nfrom scipy.stats import anderson\n# normality test\nresult = anderson(data)\nprint('Statistic: %.3f' % result.statistic)\np = 0\n# interpret results\nfor i in range(len(result.critical_values)):\n    slevel, cvalues = result.significance_level[i], result.critical_values[i]\n    if result.statistic < result.critical_values[i]:\n        print('%.3f: %.3f, data looks normal (fail to reject H0)' % (slevel, cvalues))\n    else:\n        print('%.3f: %.3f, data does not look normal (reject H0)' % (slevel, cvalues))","88ce451e":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content:<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#one_\" role=\"tab\" aria-controls=\"profile\">1. Normality Assumption<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#two_\" role=\"tab\" aria-controls=\"messages\">2. Sample Data<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#three_\" role=\"tab\" aria-controls=\"settings\">3. Visual Normality check<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n   <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#four_\" role=\"tab\" aria-controls=\"settings\">4. Statistical Normality Check<span class=\"badge badge-primary badge-pill\">4<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#five_\" role=\"tab\" aria-controls=\"settings\">5. Summary<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>","d45d65b2":"<div class=\"alert alert-block alert-danger\">  \n<h1><strong>5. Summary<\/strong><\/h1>\n    \n<strong> In this notebook we explored the importance of normal distribution and techniques by which we can validate if our data is not deviated from Gaussian Distribution<\/strong><br><br>\n--> How whether a sample is normal speaks about the types of statistical methods to use with a data sample.<br>\n--> Graphical methods for validating the  deviations from standard distributions such as histograms and the Q-Q plot.<br>\n--> Statistical normality test.<br>\n<\/div>\n","7df9f8b9":"<div class=\"alert alert-block alert-danger\">      \n<strong>Also we can assume that data is Gaussian-enough to use parametric methods or that we can use data preparation techniques to transform the data to be sufficiently Gaussian to use the parametric methods .<\/strong>\n    \n<strong>We need this type of evalaution of sample data in our machine learning projects These are -  <\/strong>   \n<ul>\n    <li>Model evaluation results in the case of model selection.<\/li>\n    <li>Residual errors from model predictions in the case of regression..<\/li>\n    <li>Input data to the model in the case of fitting models.<\/li>\n<\/ul>\n    \n<strong> In this Guide we have two type of techniques to check the data sample is in Standard Normal Distribution or not, These are - <\/strong>\n<ul>\n    \n<li>Graphical Methods.<\/li>\n--> These are methods for plotting the data and qualitatively evaluating whether the data looks Gaussian.\n<li>Statistical Tests <\/li>\n--> These are methods that calculate statistics on the data and quantify how likely it is that the data was drawn from a Gaussian distribution.\n<\/ul>\n<\/div>\n\n\n\n","440238a6":"<div class=\"alert alert-block alert-info\">  \n<h1><strong>2. Sample Data<\/strong><\/h1>\n    \n<strong>Let's generate some sample data which we can use for our tutorial. We will generate a small sample of data with Gaussian Distribution.We will the scipy's norm function to generate random Gaussian numbers with a mean of 0 and a standard deviation of 1 hence called Standard Normal variables.  <\/strong>\n    \n<i>Below code example generates the sample and prints the mean and standard deviation of the sample.<\/i>\n    \n\n<\/div>\n","7692d54b":"<div class = \"alert alert-info\"><h1>--> Thumbs Up if you find it Useful \ud83d\udc4d\ud83d\udc4d\ud83d\udc4d\ud83d\udc4d\ud83d\udc4d Cheers \ud83e\udd42!!!!<\/h1> <\/div>","bf400c6d":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>3. Visual Normality Check<\/strong><\/h1>\n    \n<strong>One the cool idea to check the normality in the given sample data is to create the plots or visualize the data whether it is Gaussian or not.However these check are qualitative but they are fast and like the statistical tests, must still be interpreted before you can make a call about your data sample.<\/strong>\n    \n<i>Common Methods forvisually inspecting a dataset to check if it was drawn from a Gaussian distribution.<\/i>\n    \n<h2> <strong>--> Histogram <\/strong> <\/h2>\n    \n    \n<strong>Histogram are basically used to represent data provided in groups.It is one of the popular method for representing  numerical data distribution.It is a type of bar plot where X-axis represents the bin ranges while Y-axis gives us frequency.The Histogram shows us bins across x axis have their ordinal relationship and count in each bin on the y-axis.<\/strong> <br>\n\n<i> Histogram can be created with Plotly,Seaborn,altair or even with  hist() matplotlib function. By default, the number of bins is automatically estimated from the data sample.Complete code for Histogram using Plotly,Seaborn and matplotlib is given below <\/i>\n\n<\/div>\n","7cfc17a5":"<h3><strong>--> References<\/strong><\/h3>\n    \n--> [Normality test](https:\/\/en.wikipedia.org\/wiki\/Normality_test)<br>\n--> [Histogram](https:\/\/en.wikipedia.org\/wiki\/Histogram)<br>\n--> [Q\u2013Q plot](http:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.graphics.gofplots.qqplot.html)<br>\n--> [Introduction to Normality Tests in Python](https:\/\/machinelearningmastery.com\/a-gentle-introduction-to-normality-tests-in-python\/)<br>\n","0d01e47f":"<div class=\"alert alert-block alert-info\">  \n    \n<h2> --> Anderson-Darling Test <\/h2>\n    \n<strong>Anderson-Darling Test is a statistical test that can be used to evaluate whether a data sample is in Standard Gaussian Distribution or not.The test is a improved version of  nonparametric goodness-of-fit statistical test i.e. Kolmogorov-Smirnov test. <br>\n\nIt can be used to check whether a data sample is normal. The test is a modified version of a more sophisticated nonparametric goodness-of-fit statistical test called the Kolmogorov-Smirnov test. <br>\n\nOne of the features of  Anderson-Darling test is that it returns list of critical value other than single p-value hence it provide us more insights on the final result.<\/strong> <br>\n    \n<i>The anderson() SciPy function implements the Anderson-Darling test. It takes as parameters the data sample and the name of the distribution to test it against. By default, the test will check against the Gaussian distribution (dist=\u2019norm\u2019) <\/i>\n\n<\/div>\n","9871e0c0":"<div class=\"alert alert-block alert-info\">  \n<h1><strong>4. Statistical Normality Tests<\/strong><\/h1>\n    \n<strong> There are number of statistical tests which can be performed to check whether data sample falls in Gaussian Distribution or not.Each and every test have different assumption and considers different aspect of sample data. <\/strong>\n<h2> <strong>4.1 Interpretation of Tests <\/strong><\/h2>\n    <strong> Each Tests will return following two metrics that will help us to interpret the results.<\/strong>\n<ul>\n    <li> Statistic<\/li>\n    <p>--> A quantity calculated by the test that can be interpreted in the context of the test via comparing it to critical values from the distribution of the test statistic.<\/p>\n    <li> p-value <\/li>\n    <p>--> p-value used to validate whether data is drawn from Gaussian Distribution.p-value is one of the quick and accurate statistical method to check statistic in real world applications.<\/p>\n\n\n<strong>The Statistical Tests make an assumption that the sample drawn from Gaussian Distribution.This is called null hypothesis or H0.A threshold level known as alpha which is usually 5% that is used to interpret the p-value.  <\/strong> <br> <br>\n    <i>In the SciPy implementation of these tests, you can interpret the p value as follows.<\/i>\n\n* p <= alpha: reject H0, not normal.\n* p > alpha: fail to reject H0, normal.\n \n<i>Broadly speaking , results with a larger p-value to confirm that our sample was likely drawn from a Gaussian distribution. <\/i>\n    \n<h2> --> Shapiro-Wilk Test <\/h2>\n<strong> This test helps us to validate how likely the data is drawn from a Gaussian distribution.Moreover Shapiro-Wilk test is one of the popular test for normality test  although there is some assumptions that the test may be suitable for smaller samples of data, e.g. thousands of observations or fewer.<\/strong> <br> <br>\n    \n<strong>The shapiro scipy() function calculates the Shapiro-Wilk on a given dataset. The function returns both p-value and stats test.Below example p-value indicates that data is drawn from Gaussian Distribtion. <\/strong>\n<\/div>\n","d7ac3825":"<div class=\"alert alert-block alert-info\">  \n        \n<strong>Above code snippets return crtitcal values and statistic values on the sample data. But hold on.... Why we use critical values? <br> <br>\nCritical values are basically  range of pre-defined significance boundaries at which the H0 can be failed to be rejected if the calculated statistic is less than the critical value.So Anderson-Darling Test return critical values for different significance level instead of single p-value. <\/strong><br>\n    \n<i>Results can be interpreted by failed Null Hypothesis if data is in normal distribution and test statistic value is less than the critical value at choosen significance level. <\/i>\n\n<\/div>\n","e9e7c544":"<div class=\"alert alert-block alert-info\">  \n    <h1><strong>-->Beginner's Guide to Normality Tests in Python<\/strong><\/h1>\n    <i><\/i>\n<\/div>\n\n\n<img src = \"https:\/\/miro.medium.com\/max\/350\/1*2vTwIrqdELKJY-tpheO7GA.jpeg\" \/>\n\n<div class=\"alert alert-block alert-info\">  \n    <p><strong>\ud83d\udc68\u200d\ud83d\udcbb In the past we have clear understading for the Statistical Hypothesis tests in python.Please Refer to <a href=\"https:\/\/www.kaggle.com\/shashwatwork\/guide-to-statistical-hypothesis-tests-in-python\" class=\"alert-link\">this link.<\/a> <br> <br>\nThere has been assumption between parametric statistical methods and non-parametric statistical methods.Parametric methods makes an assumption that data has Gaussian distribution on the other hand data sample is not Gaussian,non-parametric statistical methods must be used.   <\/strong><\/p>\n    \n\n<i><strong>Normality Tests are nothing but range to techniques used for checking data samples has Gaussian Distribution or not.<\/strong><\/i>\n\n<strong>In this Notebook, we will discover the importance of checking whether a data sample deviates from the normal distribution and a suite of techniques that you can use to evaluate your data sample.\ud83d\udc68\u200d\ud83d\udcbb<\/strong>\n<\/div>\n\n","e842f70c":"<div class=\"alert alert-block alert-info\">  \n    \n<h2> --> D\u2019Agostino\u2019s K^2 Test <\/h2>\n<strong> DA test basically gives us summary statistics of the data.The summary includes kurtosis and skewness, to determine if the data distribution differs from the normal distribution.<\/strong>\n<ul>\n    <li><strong>Skew <\/strong><\/li>\n    --> Skew is a quantification of how much a distribution is pushed left or right, a measure of asymmetry in the distribution.Skew measures the asymmetry in the distribution.It quantifies how much distribution is pushed to left or right.\n    <li><strong> Kurtosis <\/strong><\/li>\n    --> Kurtosis quantifies how much of the distribution is in the tail. It is a simple and commonly used statistical test for normality.\n    <\/ul>\n    \n<strong>the scipy's normaltest() implements D\u2019Agostino\u2019s K^2 Test and it returns the test statistic and the p-value. <\/strong>\n<\/div>\n","d07454b4":"<div class=\"alert alert-block alert-danger\">      \n<h2> <strong>--> Quantile-Quantile Plot  <\/strong> <\/h2>\n\n    \n    \n<strong>Quantile Quantile plot is yet another popular visualization for validating the distribution of data sample.QQ Plot generates its own sample of distribution that we are comparing with in case of Gaussian Distribution.These samples are divided into groups called Quantiles.Each Data point in the sample is correlated with a similar member from the  distribution at the same cumulative distribution <\/strong>\n <br> <br>\n\n<strong> Hence Resulting Points are plotted in 2D Plain as a scatter plot with the idealized value on the x-axis and the data sample on the y-axis.<\/strong>\n <br><br>\n<strong> The line will run through from bottom left to the top right which indicate the perfect Gaussian Distribution of sample data.However Deviations by the dots from the line shows a deviation from the expected distribution.<strong>\n <br>  <br> \n<i> QQ Plot can be visualized using qqplot() statsmodels function. Function takes data sample as argument as well as line argument assigned to 's' in order to draw the standardized line.<\/i>\n<br><br>\n<i> In the below QQ Plot There are a few small deviations, mainly at  bottom of the plot, which expected as data sample is too small for the plot <\/i>\n\n<\/div>\n","282e29d3":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>1. Normality Assumption<\/strong><\/h1>\n    \n<strong>There has been misconception about the data that is withdrawn from a sample of population must be of Gaussian Distribution.If the data is drawn with different distribution with assumption that methods used as Gaussian Distribution then it may lead to wrong or misleading findings.<\/strong> <br>\n    \n<i>There are number of methods\/techniques by which we can check if our data sample is in Standard Normal Distribution or not.We can decide this based on the pseudocode below--<\/i>\n    \n\n<\/div>\n"}}