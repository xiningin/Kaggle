{"cell_type":{"84fb3620":"code","e03aedc4":"code","a2c1b401":"code","ece385de":"code","5d66010f":"code","ddf97709":"code","253926d4":"code","5ac61d87":"code","009df234":"code","63052425":"code","28efe76d":"code","28b7805b":"code","55c13611":"code","806f4433":"code","38a9f891":"code","9b65b9be":"code","1dc76caa":"code","bf208d44":"code","50a7ba61":"code","b20d468c":"code","70222609":"code","c713e374":"code","c099a8ec":"code","1acb0a8d":"code","5e77188d":"code","236fab08":"code","91173c15":"code","eb05768e":"markdown","a25462b8":"markdown","082b6997":"markdown","346d33c0":"markdown","708de39c":"markdown","a01f75b0":"markdown","60dfeeb3":"markdown","8a6442c2":"markdown","a2dd844e":"markdown","c23379b7":"markdown","4ad6e5df":"markdown","5335664c":"markdown","2fd0172b":"markdown","bca466d5":"markdown","d4d6e50e":"markdown","3a6fbf2c":"markdown","3c1ab6ab":"markdown","f4cf1650":"markdown","50c329e1":"markdown","75617c46":"markdown","e00619ba":"markdown","7d62f06c":"markdown"},"source":{"84fb3620":"#pip install pycaret","e03aedc4":"import pandas as pd","a2c1b401":"regression_df = pd.read_csv(\"..\/input\/insurance\/insurance.csv\")","ece385de":"regression_df.head(10)","5d66010f":"from pycaret.regression import *","ddf97709":"reg_setup = setup(data = regression_df, target = 'charges', session_id=123,\n                  normalize = True, transformation = True,  \n                  combine_rare_levels = True, rare_level_threshold = 0.05,\n                  remove_multicollinearity = True, multicollinearity_threshold = 0.95, \n                  log_experiment = True, experiment_name = 'regression101') ","253926d4":"top5 = compare_models(exclude = ['ransac'], n_select = 5)","5ac61d87":"gbr = create_model('gbr', fold = 5)","009df234":"plot_model(gbr, plot = 'error')","63052425":"predict_model(gbr)","28efe76d":"tuned_gbr = tune_model(gbr, n_iter = 50)","28b7805b":"predict_model(tuned_gbr)","55c13611":"stacker = stack_models(top5)","806f4433":"lasso = create_model('lasso', fold = 5)","38a9f891":"stacked_models = stack_models(top5, meta_model = lasso) #Here meta_model is similar to final_estimator in sklearn.ensemble.StackingRegressor","9b65b9be":"predict_model(stacked_models)","1dc76caa":"classification_df = pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")","bf208d44":"classification_df.head()","50a7ba61":"from pycaret.classification import *","b20d468c":"class_setup = setup(data = classification_df, target = 'HeartDisease', session_id=123,\n                  normalize = True, transformation = True,  \n                  combine_rare_levels = True, rare_level_threshold = 0.05,\n                  log_experiment = True, experiment_name = 'classification101') ","70222609":"top5_class = compare_models(n_select = 5)","c713e374":"catboost = create_model('catboost',fold = 5)","c099a8ec":"plot_model(catboost,plot = 'auc')","1acb0a8d":"plot_model(catboost, plot = 'confusion_matrix')","5e77188d":"predict_model(catboost)","236fab08":"tuned_xgboost = tune_model(catboost, n_iter = 50)","91173c15":"predict_model(tuned_xgboost)","eb05768e":"Predicting the model on test data:","a25462b8":"We should always use **setup()** function before moving ahead with modelling.","082b6997":"# 1. Regression :","346d33c0":"# 2. Classification :","708de39c":"It looks like the R2-score on test data has decreased. Hence the tuning of gbr model with default parameter values seemed to have not worked. We can pass in custom parameter values and observe if it improves further.","a01f75b0":"**Note** : In order to perform the same functions using sci-kit learn, we will need many lines of code, whereas in PyCaret, it is achieved using a single function.","60dfeeb3":"# 2.1 CatBoost Classifier :","8a6442c2":"# Please upvote this notebook if you find it helpful :)","a2dd844e":"# 1.1.1 Tuning the GBR model :","c23379b7":"We were able to achieve a **better R2** score on the train data here after tuning the model with default parameters. We need to now verify if there is any improvement on the test data after tuning with default parameter values:","4ad6e5df":"**Note** : **Normalize** parameter if set to True brings the data range between 0 and 1. **Transformation** is used to make the distribution more normally distributed hence optimal for regression models such as LinearRegression. **Combine_rare_levels** is used to handle any kind of imbalance that exists in the dataset.","5335664c":"# 2.1.1 Tuning the XGBOOST Model:","2fd0172b":"# 1.1 GBR model :","bca466d5":"Creating and Training the model:","d4d6e50e":"**Pycaret** is a low-code machine learning library in python which serves as an alternative to other python libraries such as spaCy and sci-kit learn. It helps the developers in building machine learning pipeline easily and quickly. Feature engineering using traditional libraries is time consuming, whereas in Pycaret it can be accomplished in just a few lines of code.","3a6fbf2c":"**Note** : Here top5 models will act like base estimators in case of sklearn.ensemble.StackingRegressor","3c1ab6ab":"We have achieved a better **R2-score** with Stacking Regression.","f4cf1650":"Please refer to **my other kaggle notebooks** on Regression, Classification and Clustering for more info.","50c329e1":"**Note** : We had used Gradient Boosting Regressor, Random Forest Regressor and Linear Regression models in the notebook : **MedicalCostPrediction_StackingRegression**, where we had also observed that, Gradient Boosting Regressor and Random Forest Regressor performs better than Linear Regression","75617c46":"Here, we can observe that based on **R2 score** and other parameters, the top regression models are Gradient Boosting Regressor, Random Forest Regressor, Cat Boost Regressor, LGBM and AdaBoost.","e00619ba":"# 1.2 Stacking Regression in PyCaret :","7d62f06c":"We need to use the **setup()** function to make the data compatible for the next model building stage."}}