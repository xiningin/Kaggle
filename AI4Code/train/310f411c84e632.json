{"cell_type":{"ac3db547":"code","cc165e26":"code","608bd851":"code","a4de7c0f":"code","1284bb85":"code","ae7dfa69":"code","7dc1b6e0":"code","91aea6db":"code","aa1c1134":"code","34879300":"code","1b2424b0":"code","52471221":"code","6abf7c18":"code","4e1bc1b5":"code","228b7f65":"code","bb3f94a5":"code","5600395a":"code","ba77810c":"code","0b803937":"code","6117b894":"code","30217bca":"code","a8edf544":"code","59dd9dcb":"code","98251159":"code","4c117d15":"code","c4297e22":"code","23d59389":"code","328b2733":"code","fd170f9b":"code","724f115f":"code","632cf82a":"code","462fac07":"code","ad41859a":"code","64d29102":"code","b00a512a":"code","1b13cc49":"code","62f49354":"code","8da8c85c":"code","2ed26bb1":"code","1f9dcc8b":"code","a9acebed":"code","a078fedd":"code","37306907":"code","b2aed8c7":"code","17b8c124":"markdown","63355314":"markdown","9efefdd6":"markdown","f64d23d1":"markdown","08657f63":"markdown","e33b6549":"markdown","5a4b1133":"markdown","aa764bc1":"markdown","9624faca":"markdown","bc7a4ecf":"markdown","83761ea4":"markdown","79869728":"markdown","ea9cecf4":"markdown","01ee70c4":"markdown","f4e3c08f":"markdown","cc13a937":"markdown"},"source":{"ac3db547":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nfrom scipy.interpolate import Rbf, interp2d\nimport datetime\n\n# For import data\nimport os\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Modeling and Prediction\nfrom fbprophet import Prophet\nfrom sklearn.metrics import r2_score\n\nimport warnings\nwarnings.simplefilter('ignore')","cc165e26":"indicator_name = 'PM2.5' # 'PM2.5' or 'PM10'\ntime_interval='H' # 'H' (hour) or D' (day)\ntype_agg='max' # 'mean' or 'max'","608bd851":"#datetime_analysis = '2021-11-16 10:00:00'\ndatetime_analysis = '2021-11-27 09:00:00'  # maximum value after 2021-11-16\n#datetime_analysis = '2021-11-12 18:00:00'\n#datetime_analysis = '2021-01-23 18:00:00'  # maximum value","a4de7c0f":"# Import files with data from Kaggle dataset\ndataset_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        dataset_files.append(os.path.join(dirname, filename))\ndataset_files","1284bb85":"len(dataset_files)","ae7dfa69":"# Data from SaveEcoBot\nstations_about = pd.read_csv('..\/input\/air-quality-monitoring\/saveecobot_city_about_stations.csv', header=0, sep=';')\nstations_about = stations_about[stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\nstations_about","7dc1b6e0":"def get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    # Transform indicator to SaveEcoBot variants\n    if indicator_name=='PM2.5':\n        indicator_name = 'pm25'\n    elif indicator_name=='PM10':\n        indicator_name = 'pm10'\n    \n    # Get codes station\n    id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = stations_about.loc[num,'id_ecocity']\n    if not np.isnan(id_station_ecocity):\n        id_station_ecocity = int(id_station_ecocity)\n        id_station = \"EcoCity_\" + str(id_station_ecocity)\n    else: id_station = \"SaveEcoBot_\" + str(id_station_saveecobot)\n    #print(num, id_station_saveecobot, id_station_ecocity, id_station)\n        \n    df = pd.read_csv(f\"..\/input\/air-quality-monitoring\/data_saveecobot_{id_station_saveecobot}.csv\")\n    #display(df.head())\n    df = df[df['indicator_code']==indicator_name]\n    #display(df.head())\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    #df = df.dropna().reset_index(drop=True)\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    #display(df.head())\n    # Data processing - converting data to average or maximum values per given time_interval\n    #df = df.resample('H').mean()\n    if type_agg == 'mean':\n        df = df.resample(time_interval).mean()\n    else:\n        # type_agg == 'max'\n        df = df.resample(time_interval).max()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n\n    if df.shape[1] > 1:\n        # Resample is successfull\n        #display(df.head())\n        df['network'] = str(stations_about.loc[num,'network'])\n        df['id_station'] = id_station\n        df['lat'] = float(stations_about.loc[num,'lat'])\n        df['lng'] = float(stations_about.loc[num,'lng'])\n        print(f\"Number of data for {num}th station #{id_station} is {len(df)}\")\n        #display(df)\n        #print(df.info())   \n    else:\n        print(f\"Data for {num}th station #{id_station} is bad\")\n        df = pd.DataFrame()\n    return df","91aea6db":"%%time\ndf = pd.DataFrame()\nln = 0\nfor i in range(len(stations_about)):\n    df_i = get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, i)\n    #df_i.info()\n    if len(df) > 0:\n        #ln += len(df_i)\n        #print('\\n',ln)\n        df = pd.concat([df, df_i], ignore_index=True)\n    else: df = df_i\ndf = df.dropna().reset_index(drop=True)\ndf","aa1c1134":"df.info()","34879300":"# Data from SaveEcoBot\necocity_stations_about = pd.read_csv('..\/input\/air-quality-monitoring-from-ecocity\/ecocity_about_stations_2021.csv', header=0, sep=';')\necocity_stations_about","1b2424b0":"ecocity_stations_about_region = ecocity_stations_about[ecocity_stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\necocity_stations_about_region['id_ecocity'] = ecocity_stations_about_region['id_ecocity'].astype('int')\necocity_stations_about_region","52471221":"def get_data_for_indicator_of_station_from_ecocity(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    #id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = int(stations_about.loc[num,'id_ecocity'])\n    \n    # Find file name\n    for i in range(len(dataset_files)):\n        if dataset_files[i].find(str(id_station_ecocity))>0:\n            file_name = dataset_files[i]\n    \n    df = pd.read_csv(file_name)\n    #display(df)\n    df = df[df['indicator_name']==indicator_name]\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    df = df.resample('H').mean()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n    df['network'] = str(stations_about.loc[num,'network'])\n    #df['id_station_ecocity'] = id_station_ecocity\n    df['id_station'] = \"EcoCity_\" + str(id_station_ecocity)\n    df['lat'] = float(stations_about.loc[num,'lat'])\n    df['lng'] = float(stations_about.loc[num,'lng'])\n    #print(f\"Number of data for {num}th station #{id_station_saveecobot} in SaveEcoBot and #{id_station_ecocity} in EcoCity is {len(df)}\")\n    #display(df)\n    return df","6abf7c18":"%%time\ndf2 = pd.DataFrame()\nfor i in range(len(ecocity_stations_about_region)):\n    df_i = get_data_for_indicator_of_station_from_ecocity(ecocity_stations_about_region, indicator_name, i)\n    if len(df2) > 0:\n        df2 = pd.concat([df2, df_i], ignore_index=True)\n    else: df2 = df_i\ndf2","4e1bc1b5":"df2.info()","228b7f65":"# Drop data on stations of the EcoCity network from SaveEcoBot \n# with datetime which equal datetime of data from EcoCity\nif len(df)>0:\n    len_before = len(df)\n    for id_station in df2['id_station'].unique().tolist():\n        print(id_station)\n        ds_list = df2[df2['id_station']==id_station]['ds'].tolist()\n        df = df.drop(df[(df.id_station == id_station) & (df.ds.isin(ds_list))].index)\n    len_after = len(df)\n    print(f\"Number of data before the dropping duplicates - {len_before}, after - {len_after}\")","bb3f94a5":"if len(df)>0:\n    df = pd.concat([df, df2], ignore_index=True)\nelse: df = df2\ndf","5600395a":"df.info()","ba77810c":"df.describe()","0b803937":"print('Download data via API of the Center for Hydrometeorology in Vinnytsia region (http:\/\/meteo.vn.ua\/api\/api.php)....under development')\n# myfile = requests.get('http:\/\/meteo.vn.ua\/api\/api')\n# open('filename', 'wb').write(myfile.content)\n# data_meteo = pd.read_json('filename')\n# data_meteo.tail(5)","6117b894":"# Selection data for interpolation\nif type_agg == 'mean':\n    data = df[df['ds']==datetime.datetime.fromisoformat(datetime_analysis)].reset_index(drop=True)\nelse:\n    # type_agg == 'max':\n    datetime_analysis = 'all time'  \n    data = df[['value', 'id_station']].groupby(by=['id_station']).max()\n    data = data.reset_index(drop=False)\n    data = pd.merge(data, df[['id_station', 'lat', 'lng', 'network']], how = 'left', on = 'id_station').drop_duplicates().reset_index(drop=True)\n    \nx = data.lng.values\ny = data.lat.values\nz = data.value.values\nfig = plt.figure()\nplt.scatter(x, y)\nplt.title(f'Stations in Vinnytsia region with data for {indicator_name} in {datetime_analysis}')\ndisplay(data)\nplt.show()","30217bca":"df[['value']].describe()","a8edf544":"df['value'].hist(bins=50)","59dd9dcb":"# Danger level\nif indicator_name == 'PM2.5':\n    danger_level = 55\nelif indicator_name == 'PM10':\n    danger_level = 254\ndf[df['value'] >= danger_level]['value'].hist(bins=50)","98251159":"# Very danger level\nif indicator_name == 'PM2.5':\n    very_danger_level = 150\nelif indicator_name == 'PM10':\n    very_danger_level = 354\ndf[df['value'] >= very_danger_level]['value'].hist(bins=50)","4c117d15":"# Very danger level\npd.set_option('max_rows',100)\ndf[df['value'] >= very_danger_level]","c4297e22":"df.id_station.unique()","23d59389":"# Very danger level\nprint('Very danger level:')\nvery_danger_station = df[df['value'] >= very_danger_level]['id_station'].unique()\ndf[df['value'] >= very_danger_level]['id_station'].value_counts()","328b2733":"# Maximum value\nprint(f\"The maximum value is:\")\ndisplay(df.iloc[df['value'].argmax(),:])","fd170f9b":"# Maximum values after the starting station \"VNTU\"\nif datetime_analysis != 'all time':\n    print(f\"Maximum values after the starting station 'VNTU' - {df[(df.ds>=datetime.datetime.fromisoformat(datetime_analysis)) & (df.id_station=='EcoCity_1315')].value.max()}\")\nelse: print(f\"Maximum values after the starting station 'VNTU' - {df[df.id_station=='EcoCity_1315'].value.max()}\")","724f115f":"# Data interpolation\nf = interp2d(x, y, z, kind='linear')  # \u2018linear\u2019, \u2018cubic\u2019, \u2018quintic\u2019\nf","632cf82a":"# Calculation of values for a regular network of points\nmarginx = 0.001\nmarginy = 0.0001\nX = np.linspace(data.lng.min()*(1-marginx), data.lng.max()*(1+marginx), 100)\nY = np.linspace(data.lat.min()*(1-marginy), data.lat.max()*(1+marginy), 100)\nZ = f(X, Y)\nZ[0]","462fac07":"X","ad41859a":"Y","64d29102":"data","b00a512a":"# Coordinates of stations - from EcoCity or no\nxseb = data[data['network']!=\"Eco-City\"]['lng'].values\nyseb = data[data['network']!=\"Eco-City\"]['lat'].values\nnumseb = data[data['network']!=\"Eco-City\"]['id_station'].astype('str').values\nxeco = data[data['network']==\"Eco-City\"]['lng'].values\nyeco = data[data['network']==\"Eco-City\"]['lat'].values\nnumeco = data[data['network']==\"Eco-City\"]['id_station'].astype('str').values","1b13cc49":"%%time\n# Visualization\nfig = plt.figure(figsize=(12,10))\nplt.contourf(X, Y, Z)\n\nplt.scatter(xseb, yseb, c='gray', s=100, label='SaveEcoBot')\nfor i in range(len(xseb)):\n    plt.annotate(\"  \"+numseb[i], xy=(xseb[i], yseb[i]), textcoords='data')\n    \nplt.scatter(xeco, yeco, c='white', s=100, label='EcoCity')\nplt.colorbar()\nfor i in range(len(xeco)):\n    plt.annotate(\"  \"+numeco[i], xy=(xeco[i], yeco[i]), textcoords='data')\n\nplt.axis()\ntype_agg_str = 'average' if type_agg=='mean' else 'maximum'\ntime_agg_str = 'hour' if time_interval=='H' else 'D'\nplt.title(f'Stations in Vinnytsia region with {type_agg_str} data per {time_agg_str} for {indicator_name} in {datetime_analysis} (maximum value = {round(data.value.max(),2)})')\nplt.legend(loc='best')\nplt.grid()\nplt.show()","62f49354":"# Thanks to https:\/\/github.com\/serge-m\/pyinterp2\/blob\/master\/interp2.py\n# His example: https:\/\/github.com\/serge-m\/pyinterp2\/blob\/master\/test\/test_interp2.py\n\ndef interp2linear(z, xi, yi, extrapval=0):\n\n    \"\"\"\n    Linear interpolation equivalent to interp2(z, xi, yi,'linear') in MATLAB\n    @param z: function defined on square lattice [0..width(z))X[0..height(z))\n    @param xi: matrix of x coordinates where interpolation is required\n    @param yi: matrix of y coordinates where interpolation is required\n    @param extrapval: value for out of range positions. default is numpy.nan\n    @return: interpolated values in [xi,yi] points\n    @raise Exception:\n    \"\"\"\n\n    x = xi.copy()\n    y = yi.copy()\n    nrows, ncols = z.shape\n\n    if nrows < 2 or ncols < 2:\n        raise Exception(\"z shape is too small\")\n\n    if not x.shape == y.shape:\n        raise Exception(\"sizes of X indexes and Y-indexes must match\")\n\n\n    # find x values out of range\n    x_bad = ( (x < 0) | (x > ncols - 1))\n    if x_bad.any():\n        x[x_bad] = 0\n\n    # find y values out of range\n    y_bad = ((y < 0) | (y > nrows - 1))\n    if y_bad.any():\n        y[y_bad] = 0\n\n    # linear indexing. z must be in 'C' order\n    ndx = np.floor(y) * ncols + np.floor(x)\n    ndx = ndx.astype('int32')\n\n    # fix parameters on x border\n    d = (x == ncols - 1)\n    x = (x - np.floor(x))\n    if d.any():\n        x[d] += 1\n        ndx[d] -= 1\n\n    # fix parameters on y border\n    d = (y == nrows - 1)\n    y = (y - np.floor(y))\n    if d.any():\n        y[d] += 1\n        ndx[d] -= ncols\n\n    # interpolate\n    one_minus_t = 1 - y\n    z = z.ravel()\n    f = (z[ndx] * one_minus_t + z[ndx + ncols] * y ) * (1 - x) + (\n        z[ndx + 1] * one_minus_t + z[ndx + ncols + 1] * y) * x\n\n    # Set out of range positions to extrapval\n    if x_bad.any():\n        f[x_bad] = extrapval\n    if y_bad.any():\n        f[y_bad] = extrapval\n\n    return f","8da8c85c":"def sc(x):\n    return (x-x.min())\/(x.max()-x.min())\n\ndata_int = data[['value', 'lng', 'lat']].copy()\ndata_int['lng'] = sc(data_int['lng'])\ndata_int['lat'] = sc(data_int['lat'])\ndata_interp = data_int.values\ndata_interp","2ed26bb1":"idx, idy = np.meshgrid(np.arange(data_interp.shape[1])\/data_interp.shape[1], np.arange(data_interp.shape[0])\/data_interp.shape[0])\nidx","1f9dcc8b":"X = idx\nY = idy\nZ = interp2linear(data_interp, Y, X)  # \u2018linear\u2019, \u2018cubic\u2019, \u2018quintic\u2019\nZ","a9acebed":"def unsc(x, x0):\n    return x0.min() + x*(x0.max()-x0.min())\n\nX = [unsc(X[i], data['lng']) for i in range(len(X))]\nY = [unsc(Y[i], data['lat']) for i in range(len(Y))]","a078fedd":"X","37306907":"Y","b2aed8c7":"%%time\n# Visualization\nfig = plt.figure(figsize=(12,10))\nplt.contourf(X, Y, Z)\n\nplt.scatter(xseb, yseb, c='gray', s=100, label='SaveEcoBot')\nfor i in range(len(xseb)):\n    plt.annotate(\"  \"+numseb[i], xy=(xseb[i], yseb[i]), textcoords='data')\n    \nplt.scatter(xeco, yeco, c='k', s=100, label='EcoCity')\nplt.colorbar()\nfor i in range(len(xeco)):\n    plt.annotate(\"  \"+numeco[i], xy=(xeco[i], yeco[i]), textcoords='data')\n\nplt.axis()\ntype_agg_str = 'average' if type_agg=='mean' else 'maximum'\ntime_agg_str = 'hour' if time_interval=='H' else 'D'\nplt.title(f'Stations in Vinnytsia region with {type_agg_str} data per {time_agg_str} for {indicator_name} in {datetime_analysis} (maximum value = {round(data.value.max(),2)})')\nplt.legend(loc='best')\nplt.grid()\nplt.show()","17b8c124":"## 6. Interpolation without special libraries<a class=\"anchor\" id=\"6\"><\/a>\n\n[Back to Table of Contents](#0.1)","63355314":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","9efefdd6":"## 2. Download data<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","f64d23d1":"### 2.2 Download data from EcoCity<a class=\"anchor\" id=\"2.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","08657f63":"### 2.3 Download data from the Center for Hydrometeorology in Vinnytsia region (under development)<a class=\"anchor\" id=\"2.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","e33b6549":"### An attempt to repeat interp2d has not yet been successful. The result is still bad. This still needs to be improved.","5a4b1133":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","aa764bc1":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n   - [Download data from SaveEcoBot](#2.1)\n   - [Download data from EcoCity](#2.2)\n   - [Download data from the Center for Hydrometeorology in Vinnytsia region (under development)](#2.3)\n   - [Selection data for interpolation](#2.4)   \n1. [EDA for Vinnytsia region](#3)\n1. [Data interpolation](#4)\n1. [Result visualization](#5)\n1. [Interpolation without special libraries](#6)","9624faca":"## 3. EDA for Vinnytsia region<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","bc7a4ecf":"## 4. Data interpolation<a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","83761ea4":"# Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)","79869728":"### 2.1 Download data from SaveEcoBot<a class=\"anchor\" id=\"2.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","ea9cecf4":"## 5. Result visualization<a class=\"anchor\" id=\"5\"><\/a>\n\n[Back to Table of Contents](#0.1)","01ee70c4":"<a class=\"anchor\" id=\"0\"><\/a>\n# Air Quality Region - 2D Analysis - for Vinnytsia city","f4e3c08f":"## Acknowledgements\n\n### Notebooks:\n* [Air Quality in Region - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-region-2d-analysis)\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/eda-for-tabular-data-advanced-techniques)\n* [COVID in UA: Prophet with 4, Nd seasonality](https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality)\n\n### Kaggle Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)\n\n### Other open data:\n* [Open data of the Vinnytsia City Council](https:\/\/opendata.gov.ua\/dataset\/pibehb-3a6pydhehocti-test)\n* [API of the Center for Hydrometeorology in Vinnytsia region](http:\/\/meteo.vn.ua\/api\/api.php)","cc13a937":"### 2.4 Selection data for interpolation<a class=\"anchor\" id=\"2.4\"><\/a>\n\n[Back to Table of Contents](#0.1)"}}