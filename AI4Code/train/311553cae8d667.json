{"cell_type":{"34ba7296":"code","70900490":"code","fde38483":"code","e2d3e4b5":"code","4179312c":"code","e5d4dd19":"code","420cb350":"code","726d9811":"code","39fe7fe0":"code","7fc3c9ab":"code","bb0ce0b8":"code","727c770f":"code","c63ddc28":"code","17ba0fa1":"code","148b924c":"code","f5d9bdcd":"code","d7acefb2":"code","f93a7e6c":"code","73d9e91b":"code","d49922bb":"code","7dd2a98f":"code","e8025ba6":"code","7877d6ec":"code","710e0497":"code","90ff1daf":"code","0484a3d1":"code","7a5f41fc":"code","159545c4":"code","75fc009c":"code","1746652f":"code","e300c92b":"code","cd4e6793":"code","0c4dfd8f":"code","17f6551f":"code","161c8fcb":"code","0f97d8dc":"markdown","e3b19bd1":"markdown","a0c9c3c9":"markdown","241a8239":"markdown"},"source":{"34ba7296":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","70900490":"adult = pd.read_csv(\"\/kaggle\/input\/adultbase\/adult.data.txt\",\n        names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")","fde38483":"adult.shape","e2d3e4b5":"adult.head()","4179312c":"adult[\"Country\"].value_counts()","e5d4dd19":"import matplotlib.pyplot as plt","420cb350":"adult[\"Age\"].value_counts().plot(kind=\"bar\")","726d9811":"adult[\"Sex\"].value_counts().plot(kind=\"bar\")","39fe7fe0":"adult[\"Education\"].value_counts().plot(kind=\"bar\")","7fc3c9ab":"adult[\"Occupation\"].value_counts().plot(kind=\"bar\")","bb0ce0b8":"nadult = adult.dropna()","727c770f":"nadult.head()","c63ddc28":"print(\"{} - nadult \\n\\r{} - adult\".format(nadult.shape, adult.shape))","17ba0fa1":"testAdult = pd.read_csv(\"\/kaggle\/input\/adultbase\/adult.test.txt\",\n        names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")","148b924c":"nTestAdult = testAdult.dropna()","f5d9bdcd":"Xadult = nadult[[\"Age\",\"Education-Num\",\"Capital Gain\", \"Capital Loss\", \"Hours per week\"]]\nYadult = nadult.Target\n\nXtestAdult = nTestAdult[[\"Age\",\"Education-Num\",\"Capital Gain\", \"Capital Loss\", \"Hours per week\"]]\nYtestAdult = nTestAdult.Target","d7acefb2":"from sklearn.neighbors import KNeighborsClassifier","f93a7e6c":"knn = KNeighborsClassifier(n_neighbors=3)","73d9e91b":"from sklearn.model_selection import cross_val_score","d49922bb":"scores = cross_val_score(knn, Xadult, Yadult, cv=10)","7dd2a98f":"scores","e8025ba6":"knn.fit(Xadult,Yadult)","7877d6ec":"YtestPred = knn.predict(XtestAdult)","710e0497":"YtestPred","90ff1daf":"from sklearn.metrics import accuracy_score","0484a3d1":"accuracy_score(YtestAdult,YtestPred)","7a5f41fc":"knn = KNeighborsClassifier(n_neighbors=30)\nknn.fit(Xadult,Yadult)\nscores = cross_val_score(knn, Xadult, Yadult, cv=10)\nscores","159545c4":"YtestPred = knn.predict(XtestAdult)\naccuracy_score(YtestAdult,YtestPred)","75fc009c":"from sklearn import preprocessing\nnumAdult = nadult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTestAdult = nTestAdult.apply(preprocessing.LabelEncoder().fit_transform)\nXadult = numAdult.iloc[:,0:14]\nYadult = numAdult.Target\nXtestAdult = numTestAdult.iloc[:,0:14]\nYtestAdult = numTestAdult.Target\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(Xadult,Yadult)","1746652f":"YtestPred = knn.predict(XtestAdult)\naccuracy_score(YtestAdult,YtestPred)","e300c92b":"Xadult = numAdult[[\"Age\", \"Workclass\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\"]]\nXtestAdult = numTestAdult[[\"Age\", \"Workclass\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\"]]\nknn = KNeighborsClassifier(n_neighbors=30)\nknn.fit(Xadult,Yadult)","cd4e6793":"YtestPred = knn.predict(XtestAdult)\naccuracy_score(YtestAdult,YtestPred)","0c4dfd8f":"# automation\n\nadult = pd.read_csv(\"\/kaggle\/input\/adultbase\/adult.data.txt\",\n        names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\ntest_adult = pd.read_csv(\"\/kaggle\/input\/adultbase\/adult.test.txt\",\n        names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nnadult = adult.dropna()\nnTestAdult = testAdult.dropna()\n\nfrom sklearn import preprocessing\n\nnumAdult = nadult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTestAdult = nTestAdult.apply(preprocessing.LabelEncoder().fit_transform)\nYadult = numAdult.Target\nYtestAdult = numTestAdult.Target\n\ndef easy_mode(key_columns, n_neighbors,returnPred):\n    Xadult = numAdult[key_columns]\n    XtestAdult = numTestAdult[key_columns]\n    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n    knn.fit(Xadult,Yadult)\n    YtestPred = knn.predict(XtestAdult)\n    if returnPred==True:\n        return YtestPred\n    return (accuracy_score(YtestAdult,YtestPred))\n\n# now a little help from itertools\nfrom itertools import combinations\n#nadult_columns = list(nadult.columns.values)\n#use nadult_columns above for first tests, afterwords you may use the key columns list found,\n#which in my case is the list below\nnadult_columns = [\"Age\", \"Education-Num\", \"Martial Status\",\n                   \"Occupation\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n                   \"Hours per week\"]\nbest_result = {'result':0,'num_knn':0,'col_list':[]}\nfor i in range(6, len(nadult_columns)):\n    key_columns_list = combinations(list(nadult_columns),i)\n    for n_columns in key_columns_list:\n        result = easy_mode(list(n_columns),34, False)\n        if best_result['result']<result:\n            best_result['result']=result\n            best_result['num_knn']=34\n            best_result['col_list']=list(n_columns)\n            print(\"In progress... Best result so far = {}\\t\\n{} (knn num = {})\".format(best_result['result'],best_result['col_list'],best_result['num_knn']))\nprint(\"Best result with key columns {} and knn number = {}:\\t\\nResult = {}\".format(best_result['col_list'],best_result['num_knn'],best_result['result']))\n\nn_columns = best_result['col_list']\nprint(\"Now to confirm the best knn number we use the key columns found with different knn number values.\")\nbest_result = {'result': 0, 'num_knn': 0}\nfor i in range(30, 40):\n    result = easy_mode(n_columns, i, False)\n    if best_result['result'] < result:\n        best_result['result'] = result\n        best_result['num_knn'] = i\n        print(\"In progress... Best result so far = {}; n_knn = {}\".format(best_result['result'], best_result['num_knn']))\nprint(\"With key columns {} and knn_number = {}:\\t\\nAccuracy = {}\".format(n_columns,best_result['num_knn'], best_result['result']))\n\n","17f6551f":"submission = easy_mode(['Age', 'Education-Num', 'Martial Status', 'Occupation', 'Capital Gain', 'Capital Loss'],34,True)\nsubmission","161c8fcb":"final_result = {'Id':[],'Income':[]}\nfor i in range (len(submission)):\n    final_result['Id'].append(i)\n    if submission[i]:\n        final_result['Income'].append(\">50k\")\n    else:\n        final_result['Income'].append(\"<=50k\")\ndf_result = pd.DataFrame(final_result)\ndf_result.to_csv('bestPrediction.csv', index=False, sep=',', line_terminator = '\\r\\n', header = [\"Id\", \"Income\"])","0f97d8dc":"Now, translating submission from binary to string:","e3b19bd1":"accuracy_scores returns 0 (and not 0.0001 for example) because not a single prediction is right due to YtestAdult has been giving values with dot char \"<=50k.\". A simple conversion from non-numerical to numerical values settles this issue as is shown below:","a0c9c3c9":"After several tests, we have obtained with key columns = ['Age', 'Education-Num', 'Martial Status', 'Occupation', 'Capital Gain', 'Capital Loss'] and knn number = 34 the accuracy of 84.18991%.\n","241a8239":"There it go, problem solved."}}