{"cell_type":{"9e7ddb5f":"code","8c08e536":"code","82a3e63a":"code","342a0d62":"code","2add3d3c":"code","4059ac1c":"code","6b251cd4":"code","7970846c":"code","a8e7a743":"code","e6b58da4":"code","454beb18":"code","d6b95cc3":"code","be6ae9e2":"code","0a506da4":"code","0c1dc236":"code","e7dc1986":"code","6bb36802":"markdown","87b65e9e":"markdown","907e6cc7":"markdown","dba6cdac":"markdown","060789ce":"markdown","f2b8f92a":"markdown","a2c58c58":"markdown","2b39ac7b":"markdown","0e7c5efb":"markdown","51bb2261":"markdown","f3ccd2da":"markdown","8c8cfb38":"markdown","dff95692":"markdown"},"source":{"9e7ddb5f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8c08e536":"data = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ndata.head(3)","82a3e63a":"fig = plt.figure(figsize=(15,15))\nfor i in range(1,10):\n    fig.add_subplot(3,3,i)\n    sns.heatmap(np.array(data.iloc[i-1,1:]).reshape(28,28), cbar=False, cmap='Greys');","342a0d62":"import torch\nfrom torch import nn\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image","2add3d3c":"mean = np.array(data.iloc[:,1:]).flatten().mean()\nstd = np.array(data.iloc[:,1:]).flatten().std()\nprint('mean = ', mean)\nprint('std = ', std)","4059ac1c":"class Fashion(Dataset):\n    def __init__(self, data, transform=None):\n        self.transform = transform\n        dataset = data\n        self.labels = dataset.label.values\n        self.images = dataset.iloc[:, 1:].values.astype('uint8').reshape(-1, 28, 28)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        label = self.labels[idx]\n        img = Image.fromarray(self.images[idx])\n        \n        if self.transform:\n            img = self.transform(img)\n\n        return img, label","6b251cd4":"transf = transforms.Compose([transforms.ToTensor(), \n                            transforms.Normalize( (mean\/225,), (std\/225,) )])\n\ndata_train = Fashion(pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv'),transform=transf)\ndata_test = Fashion(pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv'),transform=transf)\n\ntrain_loader = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(data_test, batch_size=64, shuffle=True)","7970846c":"class Net(torch.nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super().__init__()\n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n        self.fc1 = nn.Linear(input_size, hidden_size[0])\n        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n        self.fc3 = nn.Linear(hidden_size[1], hidden_size[2])\n        self.fc4 = nn.Linear(hidden_size[2], num_classes)\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        out = self.tanh(out)\n        out = self.fc3(out)\n        out = self.tanh(out)\n        out = self.fc4(out)\n        return out","a8e7a743":"params = []\nloss_train = []\nloss_test = []\n\ndef test(model):\n    criterion = nn.CrossEntropyLoss()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for batch_id, (image, label) in enumerate(test_loader):\n            image = image.view(image.shape[0],-1)\n            outputs = model(image)\n            \n            # add loss to graph\n            if (batch_id % 100 == 0) & (batch_id > 0):\n                loss = criterion(outputs, label)\n                loss_test.append(loss.item())\n            predicted = torch.argmax(outputs,dim=1)\n            total += label.size(0)\n            correct += (predicted == label).sum().item()\n        print('Test accuracy: {} %'.format(100 * correct \/ total))\n        \ndef train():\n    model = Net(784, [150,150,150], 10)\n    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(1, 20):\n        for batch_id, (image, label) in enumerate(train_loader):\n            image = image.view(image.shape[0],-1)\n            output = model(image)\n            loss = criterion(output, label)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            if batch_id % 1024 == 0:\n                print('Loss :{:.4f} Epoch - {}\/{} '.format(loss.item(), epoch, 20), end=' ')\n                loss_train.append(loss.item())\n        test(model)\n    for i in model.parameters():\n        params.append(i)\n    return model","e6b58da4":"model = train()","454beb18":"plt.plot(np.arange(19),loss_train, label='train')\nplt.scatter(np.arange(19),loss_test, label = 'test')\nplt.legend();","d6b95cc3":"print(\"Classes - T-shirt\/Top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle Boot\")\nfor i in model.parameters():\n        params.append(i)\n        \nfig = plt.figure(figsize=(20,25))\nfor i in range(1,25):\n    fig.add_subplot(7,4,i)\n    sns.heatmap(params[0][i-1,:].reshape(28,28).detach().numpy(), cbar=False);","be6ae9e2":"class Net(torch.nn.Module):\n    def __init__(self, input_size, num_classes):\n        super().__init__()\n        self.fc1 = nn.Linear(input_size, num_classes)\n    def forward(self, x):\n        out = self.fc1(x)\n        return out\nparams = []\nloss_train = []\nloss_test = []\n\ndef test(model):\n    criterion = nn.CrossEntropyLoss()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for batch_id, (image, label) in enumerate(test_loader):\n            image = image.view(image.shape[0],-1)\n            outputs = model(image)\n            \n            # add loss to graph\n            if (batch_id % 100 == 0) & (batch_id > 0):\n                loss = criterion(outputs, label)\n                loss_test.append(loss.item())\n            \n            predicted = torch.argmax(outputs,dim=1)\n            total += label.size(0)\n            correct += (predicted == label).sum().item()\n        print('Test accuracy: {} %'.format(100 * correct \/ total))\n        \ndef train():\n    model = Net(784, 10)\n    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(1, 20):\n        for batch_id, (image, label) in enumerate(train_loader):\n            image = image.view(image.shape[0],-1)\n            output = model(image)\n            loss = criterion(output, label)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            if batch_id % 1024 == 0:\n                print('Loss :{:.4f} Epoch - {}\/{}'.format(loss.item(), epoch, 20), end=' ')\n                loss_train.append(loss.item())\n        test(model)\n    for i in model.parameters():\n        params.append(i)\n    return model\nmodel = train()","0a506da4":"plt.plot(np.arange(19),loss_train, label='train')\nplt.scatter(np.arange(19),loss_test, label = 'test')\nplt.legend();","0c1dc236":"print(\"Classes - T-shirt\/Top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle Boot\")\nfor i in model.parameters():\n        params.append(i) \nfig = plt.figure(figsize=(15,15))\nfor i in range(1,11):\n    fig.add_subplot(5,4,i)\n    sns.heatmap(params[0][i-1,:].reshape(28,28).detach().numpy(), cbar=False);","e7dc1986":"nb_classes = 10\nconfusion_matrix = torch.zeros(nb_classes, nb_classes)\nwith torch.no_grad():\n    for i,  (image, classes) in enumerate(test_loader):\n        image = image.view(image.shape[0],-1)\n        outputs = model(image)\n        _, preds = torch.max(outputs, dim=1)\n        for t, p in zip(classes.view(-1), preds.view(-1)):\n                confusion_matrix[t.long(), p.long()] += 1\ncols = [\"T-shirt\/Top\", \"Trouser\", \"Pullover\",\"Dress\",\"Coat\", \"Sandal\", \"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]\nplt.figure(figsize=(10,8))\nsns.heatmap(pd.DataFrame(np.array(confusion_matrix), columns=cols, index=cols), cmap='Greys', annot=True);","6bb36802":"Thank you for reading! I hope this kernel was helpful for you. <br> \nHere you can see my other kernels: https:\/\/www.kaggle.com\/nikitagrec\/kernels","87b65e9e":"## NN with one linear layer\nLet's repeat the same slightly modified code.","907e6cc7":"Import base libraries - torch and torchvision for image preprocessing.","dba6cdac":"Here I'll plot weights heatmap. Here are the weights from the first layer - 784 * 100. As you can see, most of pictures look like noise. They do not guess a clear structure similar to a picture. But these pictures says us, how NN see an input image. So, let's try to reduce the number of layers and neurons to the minimum - 1 layer with 10 neurons - equal to ten output classes.","060789ce":"Here we can see that model quickly finds a \"plateau\" and further does not improve it's accuracy:","f2b8f92a":"What can we see? Every visualization shows interesting results. I print class names for better understanding. <br>\n- First picture highlighted sleeves in light color, and darkened the fields under the sleeves of the T-shirt. This is important part, because directly short sleeves separate T-shirt from the pullover or Shirt. <br>\n- Second picture, that should recognize trouser, distinguishes the lane between the left and right legs. <br>\n<br>\nSimilar images to every class can be found in each picture. We can see that 85% accuracy for this problem can gives 1 layer with only 10 neurons.","a2c58c58":"Confusion matrix for greater objectivity.","2b39ac7b":"Print some details of learning process:","0e7c5efb":"Create a class, inherited from class Dataset, to download dataset, transfrom, and divided into features and classes","51bb2261":"Now data transform to show examples of dataset:","f3ccd2da":"Now create class Net, which is inherited from class nn.Module. Fistly, try simple architecture, without Conv and Pooling. This architecture has three linear layers. In **init** method we define all unique NN parameters, and in **forward** we define NN architecture.","8c8cfb38":"Usually added **Scale** into Compose container, but in this dataset we have same sized pictures. So, we need **ToTensor** (to transform data to **pytorch.Tensor** format) and Normalize. Neural networks respond poorly to unnormalized data. This is because of the scalar product, that is base of NN.","dff95692":"Here we define Net parameters. It's clear with input\/output parameters - 784 = 28 * 28 and output - 10 (classes). <br>\nThere are no theoretical results to exactly define hidden parameters, which can take best score. In most situations, there is no way to determine the best number of hidden units without training several networks and estimating the generalization error of each. So, only in practice can you get the best result. <br>\nNN learning can be seen as looking for correlations between input and output. And when we add hidden layers, NN find correlations between hidden layers. So, NN find connection not only between input and output, but also between hidden layers."}}