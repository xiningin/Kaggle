{"cell_type":{"69e3e72b":"code","bf17e619":"code","d7a2dd27":"code","12a54fe4":"code","874cb536":"code","79bedf98":"code","05254f92":"code","4f61a096":"code","f967dd77":"code","30259299":"code","cb290d7e":"code","beba2bc7":"code","29f7dce6":"code","99229d6b":"code","d758e3c7":"code","3dece5d5":"code","4719849b":"code","5e3ecce9":"code","526c6bd6":"code","6ae59c41":"code","cf0ea80e":"code","d5fd782c":"code","84855bc2":"code","7a5062bb":"code","ac395d5b":"code","8151c356":"code","2a488327":"code","6feb7b61":"code","e8103363":"code","8034225d":"code","24009ff4":"code","a50febac":"code","db432e8b":"code","b719f993":"code","9c086407":"code","ac2d9d58":"code","d7d45878":"code","82acce0b":"code","42d07a78":"code","5b619495":"code","91ccd3ab":"code","eb84a0cf":"code","40110b70":"code","d169f1a8":"code","ba6147f8":"code","da8c5ac5":"code","546ab1e6":"code","a77959d9":"code","7ef6454d":"code","dffadcd8":"code","f0f0b76b":"code","14bbc222":"code","599d7d0c":"code","e12d77f1":"code","7795125b":"code","1f67cd41":"code","c8f6224d":"code","30645e9b":"code","30b8a24c":"code","bf8d8b9d":"code","910d3f76":"code","27bf8a2c":"code","29f9e27c":"code","078b2f54":"code","91de3a83":"code","0565e3d5":"code","65e8409b":"code","44ed9912":"code","d99d61fe":"code","23fe9007":"code","0e45ba3d":"code","5dd0e1a8":"code","c70cdc91":"code","d66981b2":"code","db903ab9":"code","171f142d":"code","f3d7241f":"code","1ea7b6a7":"code","a1731951":"code","e4149635":"code","e67c1d4b":"code","99177ad6":"code","88ae85a4":"code","20019844":"code","b62ddaef":"code","99e6d726":"code","9a5ef171":"code","4d62e2c0":"code","0cce1ffc":"code","440d5ddd":"code","526cb95d":"code","f1a0b694":"code","5b9eb737":"code","2e4d097c":"code","799da7fc":"markdown","cbf5c20b":"markdown","d267d7b8":"markdown","059bdb81":"markdown","1e9558f0":"markdown","10cf0647":"markdown","99e257c7":"markdown","623fd899":"markdown","acf28c11":"markdown","fccc0ed4":"markdown","2d6d9825":"markdown","c946e4e2":"markdown","c4d0ac1f":"markdown","60c6ae6d":"markdown","98644c79":"markdown","c6dcd42b":"markdown","5bfceaf3":"markdown","5359b43e":"markdown","21b00f9f":"markdown","e8441ae5":"markdown","2b8aad63":"markdown","9f54dfa7":"markdown","fff1f3cd":"markdown","f4452c2a":"markdown","25dd08fa":"markdown","176506a2":"markdown","561c3002":"markdown","16580681":"markdown","60d9e2ca":"markdown","bfb10e49":"markdown","355b5bc0":"markdown","f4023948":"markdown","1fafa653":"markdown","32ae464a":"markdown","c0c82d67":"markdown","9d6e0688":"markdown","4f5a4010":"markdown","5b672faa":"markdown","efc0a098":"markdown","bdfa5e32":"markdown","12d725dc":"markdown","ca970235":"markdown","9ffc7c90":"markdown","abc2e7f2":"markdown","cf021ac0":"markdown","fb43188c":"markdown","879df187":"markdown","87c62772":"markdown","3fdc59b0":"markdown","0ca77fce":"markdown","8b3ed3c4":"markdown","d026142e":"markdown","31932c97":"markdown","b3dddb1a":"markdown","9faec67d":"markdown","03abeaa6":"markdown","aa6b715a":"markdown","beec9e60":"markdown","1cd81487":"markdown","d92fca6d":"markdown","b2a227ab":"markdown","9608c3c6":"markdown","ae61da8e":"markdown","db7b6ea4":"markdown","2b53f01b":"markdown","510b1a18":"markdown","4cb7b2bf":"markdown","06312111":"markdown","531e9d9a":"markdown","89bf37fe":"markdown","a9224b5b":"markdown","66adc0e5":"markdown","40a7ae42":"markdown","c7cf3504":"markdown","9ba6c1eb":"markdown"},"source":{"69e3e72b":"# Load Libraries\nimport pandas as pd \nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport re\nimport string\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report\nfrom nltk.corpus import stopwords\nimport seaborn as sns\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\nfrom gensim.models import Word2Vec\nfrom numpy import asarray\nfrom numpy import zeros\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom nltk.tokenize import RegexpTokenizer\nimport plotly\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud,STOPWORDS\n# general imports\nimport math\nfrom bs4 import BeautifulSoup\nimport tensorflow as tf\nimport numpy as np\nimport skimage\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\nimport missingno as msno\n","bf17e619":"df = pd.read_csv('..\/input\/amazon-alexa-reviews\/amazon_alexa.tsv', sep='\\t')","d7a2dd27":"df.shape","12a54fe4":"\ndf.head()","874cb536":"df.describe()","79bedf98":"#Duplicate Analysis\ncols=df.columns\n#print(list(cols))\ndups_df = df.pivot_table(index=list(cols), aggfunc='size')\nprint (dups_df)","05254f92":"#Explore Categorical Variables\ncat_col = ['rating','feedback']\n\nplt.figure(figsize=(10, 12))\ncount = 1\nfor cols in cat_col:\n    plt.subplot(2, 2, count)\n    df[cols].value_counts().plot.pie(shadow=True,autopct='%1.1f%%')\n    count +=1\n    plt.subplot(2, 2, count)\n    sns.countplot(cols, data=df)\n    count+=1","4f61a096":"# Find missing values\nprint(\"Colums with Null values: \\n\",df.isnull().sum())","f967dd77":"msno.bar(df)","30259299":"#Variable - variation\n#Find unique variation\nlen(df['variation'].unique())","cb290d7e":"#Plotting Variation\nplt.figure(figsize=(18,7))\nsns.countplot(x='variation', data=df, palette=\"hls\")\nplt.xlabel(\"variation\", fontsize=15) #seting the xtitle and size\nplt.ylabel(\"Count\", fontsize=15) # Seting the ytitle and size\nplt.title(\"variation Count\", fontsize=15) \nplt.xticks(fontsize=10)\nplt.yticks(fontsize=12)\nplt.xticks(rotation=45)\nplt.show()","beba2bc7":"#Variable - date\n#Find unique dates \nlen(df['date'].unique())","29f7dce6":"#Plotting date\nplt.figure(figsize=(28,7))\nsns.countplot(x='date', data=df, palette=\"hls\")\nplt.xlabel(\"date\", fontsize=15) #seting the xtitle and size\nplt.ylabel(\"Count\", fontsize=15) # Seting the ytitle and size\nplt.title(\"date Count\", fontsize=15) \nplt.xticks(fontsize=10)\nplt.yticks(fontsize=12)\nplt.xticks(rotation=45)\nplt.show()\n","99229d6b":"df_date_top10 = pd.DataFrame(df['date'].value_counts()[0:11])\ndf_date_top10.date.plot.bar()","d758e3c7":"df['month'] = pd.DatetimeIndex(df['date']).month\ndf['weekday'] = pd.DatetimeIndex(df['date']).weekday\ndf.head()","3dece5d5":"# Lets see how weekday analysis looks like\nplt.rcParams['figure.figsize'] = (14,6)\ndf['weekday'].hist(bins=7,color='orange',range = (-.5,6.5),rwidth=.8)\nplt.xticks(range(7),'Mon Tue Wed Thu Fri Sat Sun'.split());\nplt.ylabel('Counts')\nplt.title('Weekday of review')\nplt.show()","4719849b":"# Lets see how month analysis looks like\nsns.countplot(x = 'month', data = df)","5e3ecce9":"# length of the review\nlens = df['verified_reviews'].str.len()\n\nfig = go.Figure()\nfig.add_trace(\n    go.Histogram(x=lens, xbins=dict(size=200))\n    )\nfig.update_layout(title='Length of reviews', \n                    xaxis_title=\"Length\",\n                    yaxis_title=\"# of reviews\")\nplotly.offline.iplot(fig)","526c6bd6":"#what is the length of the review based upon feedback\nposlens = df[df['feedback']==1]['verified_reviews'].str.len()\nneglens = df[df['feedback']==0]['verified_reviews'].str.len()\nfig = go.Figure()\nfig.add_trace(\n    go.Histogram(x=poslens, xbins=dict(size=200), name='1'),\n    )\nfig.add_trace(\n    go.Histogram(x=neglens, xbins=dict(size=200), name='0'),\n    )\nfig.update_layout(title='Length of reviews', \n                    xaxis_title=\"Length\",\n                    yaxis_title=\"# of reviews\",)\nplotly.offline.iplot(fig)\n","6ae59c41":"#lets check the length of the reviews\ndf['length'] = df['verified_reviews'].apply(len)\ndf['length'].describe()","cf0ea80e":"df.hist(column='length',by='feedback',bins=5,figsize=(12,6))\nplt.show()","d5fd782c":"#what is the length of the reviews per +ve\/-ve review?\nlens1 = df[df['rating']==1]['verified_reviews'].str.len()\nlens2 = df[df['rating']==2]['verified_reviews'].str.len()\nlens3 = df[df['rating']==3]['verified_reviews'].str.len()\nlens4 = df[df['rating']==4]['verified_reviews'].str.len()\nlens5 = df[df['rating']==5]['verified_reviews'].str.len()\n\nfig = go.Figure()\nfig.add_trace(\n    go.Histogram(x=lens1, xbins=dict(size=200), name='1'),\n    )\nfig.add_trace(\n    go.Histogram(x=lens2, xbins=dict(size=200), name='2'),\n    )\nfig.add_trace(\n    go.Histogram(x=lens3, xbins=dict(size=200), name='3'),\n    )\nfig.add_trace(\n    go.Histogram(x=lens4, xbins=dict(size=200), name='4'),\n    )\nfig.add_trace(\n    go.Histogram(x=lens5, xbins=dict(size=200), name='5'),\n    )\n\nfig.update_layout(title='Length of reviews', \n                    xaxis_title=\"Length\",\n                    yaxis_title=\"# of reviews\",)\nplotly.offline.iplot(fig)\n","84855bc2":"df.hist(column='length',by='rating',bins=10,figsize=(15,9))\nplt.show()\n","7a5062bb":"sns.catplot(data=df, x='variation', y='length', hue='feedback', kind='boxen', palette=\"hls\");\nfig=plt.gcf()\nfig.set_size_inches(15,8)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=1)\nplt.xticks(rotation=45)\nplt.show()","ac395d5b":"sns.catplot(data=df, x='variation', y='length', hue='rating', kind='boxen', palette=\"hls\");\nfig=plt.gcf()\nfig.set_size_inches(15,8)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=1)\nplt.xticks(rotation=45)\nplt.show()","8151c356":"sns.catplot(data=df, x='rating', y='length', hue='feedback', kind='bar', palette=\"hls\");\nfig=plt.gcf()\nfig.set_size_inches(8,5)\nplt.xticks(fontsize=8)\nplt.yticks(fontsize=1)\nplt.xticks(rotation=45)\nplt.show()","2a488327":"plt.figure(figsize=(14, 8))\ng = sns.kdeplot(df[\"length\"][(df[\"feedback\"] == 0) & (df[\"length\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(df[\"length\"][(df[\"feedback\"] == 1) & (df[\"length\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"length\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Feedback=0\",\"Feedback=1\"])","6feb7b61":"plt.figure(figsize=(15, 8))\ng = sns.kdeplot(df[\"length\"][(df[\"rating\"] == 1) & (df[\"length\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(df[\"length\"][(df[\"rating\"] == 2) & (df[\"length\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng = sns.kdeplot(df[\"length\"][(df[\"rating\"] == 3) & (df[\"length\"].notnull())], color=\"Green\", shade = True)\ng = sns.kdeplot(df[\"length\"][(df[\"rating\"] == 4) & (df[\"length\"].notnull())], color=\"Orange\", shade = True)\ng = sns.kdeplot(df[\"length\"][(df[\"rating\"] == 5) & (df[\"length\"].notnull())], color=\"Purple\", shade = True)\ng.set_xlabel(\"length\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"rating=1\",\"rating=2\",\"rating=3\",\"rating=4\",\"rating=5\"])","e8103363":"sns.catplot(x='variation',y='feedback',kind='point',data=df)\nfig=plt.gcf()\nfig.set_size_inches(15,8)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=6)\nplt.xticks(rotation=45)\nplt.show()","8034225d":"sns.catplot(x='variation',y='rating',kind='boxen',data=df)\nfig=plt.gcf()\nfig.set_size_inches(15,8)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=6)\nplt.xticks(rotation=45)\nplt.show()\n","24009ff4":"# Lets check the reviews again\ndf['verified_reviews'].head(5)","a50febac":"#Step 1: transform to lowercase\ndf['review_lw'] = df['verified_reviews'].str.lower()\ndf[['verified_reviews','review_lw']].head(10)","db432e8b":"#Step 2: Removing HTML Tags\ndf['review_lw'] = df['review_lw'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text().strip())\n\ndf[['verified_reviews','review_lw']].head(10)","b719f993":"#Step 3: remove stopwords 'n punctuation\nsw = stopwords.words('english')","9c086407":"def transform_text(s):\n    \n    # remove html\n    html=re.compile(r'<.*?>')\n    s = html.sub(r'',s)\n    \n    # remove numbers\n    s = re.sub(r'\\d+', '', s)\n    \n    # remove punctuation\n    # remove stopwords\n    tokens = nltk.word_tokenize(s)\n    \n    new_string = []\n    for w in tokens:\n        # remove words with len = 2 AND stopwords\n        if len(w) > 2 and w not in sw:\n            new_string.append(w)\n \n    s = ' '.join(new_string)\n    s = s.strip()\n\n    exclude = set(string.punctuation)\n    s = ''.join(ch for ch in s if ch not in exclude)\n    \n    return s.strip()\n","ac2d9d58":"df['review_sw'] = df['review_lw'].apply(transform_text)\ndf[['verified_reviews','review_lw', 'review_sw']].head(10)","d7d45878":"#Step 4: lemmatizer\n\nlemmatizer = WordNetLemmatizer() ","82acce0b":"def lemmatizer_text(s):\n    tokens = nltk.word_tokenize(s)\n    \n    new_string = []\n    for w in tokens:\n        lem = lemmatizer.lemmatize(w, pos=\"v\")\n        # exclude if lenght of lemma is smaller than 2\n        if len(lem) > 2:\n            new_string.append(lem)\n    \n    s = ' '.join(new_string)\n    return s.strip()","42d07a78":"df['review_lm'] = df['review_sw'].apply(lemmatizer_text)\ndf[['verified_reviews','review_lw', 'review_sw', 'review_lm']].head(20)","5b619495":"#Step 5: Removing Rare Words\ntext = ' '.join(df['review_lm'])\nlen(text)","91ccd3ab":"# Creating Frequency\ntext_series = pd.Series(text.split())\nfreq_comm = text_series.value_counts()\nfreq_comm\n","eb84a0cf":"rare_words = freq_comm[-1258:-1]\n'rattlecrackle' in rare_words","40110b70":"rare_words","d169f1a8":"# Removing 1258 rare occuring words \ndf['review_lm'] = df['review_lm'].apply(lambda x: ' '.join([word for word in x.split() if word not in rare_words]))\ndf['review_lm'].sample(5)","ba6147f8":"text = ' '.join(df['review_lm'])\nlen(text)","da8c5ac5":"df_pos = df[df['feedback']==1]['review_lm']\n\nwordcloud1 = WordCloud(stopwords=STOPWORDS,\n                      background_color='white',\n                      width=2500,\n                      height=2000\n                      ).generate(\" \".join(df_pos))\n\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud1)\nplt.axis('off')\nplt.show()\n","546ab1e6":"df_neg = df[df['feedback']==0]['review_lm']\n\nwordcloud1 = WordCloud(stopwords=STOPWORDS,\n                      background_color='white',\n                      width=2500,\n                      height=2000\n                      ).generate(\" \".join(df_neg))\n\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud1)\nplt.axis('off')\nplt.show()","a77959d9":"def plot_ngram(sentiment, n):\n    print(\"sentiment\",sentiment)\n    temp_df = df[df['feedback'] == sentiment]\n    \n    word_vectorizer = CountVectorizer(ngram_range=(n, n), analyzer='word')\n    sparse_matrix = word_vectorizer.fit_transform(temp_df['review_lm'])\n    \n    frequencies = sum(sparse_matrix).toarray()[0]\n    \n    return pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\\\n            .sort_values(by='frequency', ascending=False) \\\n            .reset_index() \\\n            .head(10)","7ef6454d":"# For Feedback=1\nplot_ngram(1, 1)","dffadcd8":"# For Feedback=0\nplot_ngram(0, 1)","f0f0b76b":"#Feedback=1 (i.e. +ve)\ndf[df['feedback']== 1]['review_lm'].count()","14bbc222":"#Feedback=0 (i.e. -ve)\ndf[df['feedback']== 0]['review_lm'].count()","599d7d0c":"# Train dataset\npos_train = df[df['feedback']==1][['review_lm', 'feedback']].head(2025)\nneg_train = df[df['feedback']==0][['review_lm', 'feedback']].head(180)\n\n\n# Test dataset\npos_test = df[df['feedback']==1][['review_lm', 'feedback']].tail(868)\nneg_test = df[df['feedback']==0][['review_lm', 'feedback']].tail(77)","e12d77f1":"# put all toghether \ntrain_df = pd.concat([pos_train, neg_train]).sample(frac = 1).reset_index(drop=True)\ntest_df = pd.concat([pos_test, neg_test]).sample(frac = 1).reset_index(drop=True)","7795125b":"train_df.head()","1f67cd41":"test_df.head()","c8f6224d":"X_train = train_df['review_lm']\nX_test  = test_df['review_lm']\ny_train = train_df['feedback']\ny_test  = test_df['feedback']","30645e9b":"vectorizer = CountVectorizer(binary=True)\nvectorizer.fit(X_train)\nX_train_onehot = vectorizer.transform(X_train)\nX_test_onehot = vectorizer.transform(X_test)\n\n#print shape post encoding \nprint(X_train_onehot.shape)\nprint(X_test_onehot.shape)","30b8a24c":"#Let's have a look at 10 words from the word vocabulary \n#with their corresponding indices in the vocabulary.\nword_dict = vectorizer.vocabulary_\nprint({k: word_dict[k] for k in list(word_dict)[:20]})\n","bf8d8b9d":"# Generic function for model building\ndef fit_and_test(classifier, X_train, y_train, X_test, y_test, only_return_accuracy=False):\n  classifier.fit(X_train, y_train)\n  y_hat = classifier.predict(X_test)\n  print('accuracy:', accuracy_score(y_test, y_hat))\n  if not only_return_accuracy:\n    print('f1_score:', f1_score(y_test, y_hat))","910d3f76":"#Logistic Regression\n\n#grid search over regularisation hyperparameter 'c'\nfor c in [0.01, 0.02, 0.05, 0.25, 0.5, 0.75, 1,]:\n  lr = LogisticRegression(C=c, max_iter=1000) # 92.91%\n  print (f'At C = {c}:-', end=' ')\n  fit_and_test(lr, X_train_onehot, y_train, X_test_onehot, y_test, True)","27bf8a2c":"#Make an instance of the model\nlogistic = LogisticRegression(C=1,max_iter=10000)\n#fitting the values for x and y\nlogistic.fit(X_train_onehot,y_train)","29f9e27c":"#predictions from test data\nprediction = logistic.predict(X_test_onehot)","078b2f54":"###### confusion matrix  starts ######\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ncm_lgr1 = confusion_matrix(y_test,prediction) \nnames = np.unique(prediction)\nsns.heatmap(cm_lgr1, square=True, annot=True, cbar=False,xticklabels=names, yticklabels=names, cmap=\"YlGnBu\" ,fmt='g')\nplt.xlabel('Truth')\nplt.ylabel('Predicted')\n\n###### Confusion matrix ends ########","91de3a83":"#calculating the accuracy\naccuracy_score = accuracy_score(y_test,prediction)\nprint(\"Accuracy of  Logistic Regression :\",accuracy_score)","0565e3d5":"################ Print n-grams and frequency starts #################\nvectorizer = CountVectorizer()\nvect_texts = vectorizer.fit_transform(list(df['review_lm']))\n\nall_ngrams = vectorizer.get_feature_names()\n#print(all_ngrams[:5])\nnum_ngrams = min(50, len(all_ngrams))\nall_counts = vect_texts.sum(axis=0).tolist()[0]\n\nall_ngrams, all_counts = zip(*[(n, c) for c, n in sorted(zip(all_counts, all_ngrams), reverse=True)])\nngrams = all_ngrams[:num_ngrams]\ncounts = all_counts[:num_ngrams]\n\nidx = np.arange(num_ngrams)","65e8409b":"# Let's plot a frequency distribution plot for the most seen words\nplt.figure(figsize=(18, 18))\nplt.bar(idx, counts, width=0.8)\nplt.xlabel('N-grams')\nplt.ylabel('Frequencies')\nplt.title('Frequency distribution of ngrams')\nplt.xticks(idx, ngrams, rotation=45)\nplt.show()","44ed9912":"from tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, confusion_matrix","d99d61fe":"# create the tokenizer\ntokenizer = Tokenizer()\n\n# fit the tokenizer on the documents\ntokenizer.fit_on_texts(X_train)\n# encode training data set\nXtrain = tokenizer.texts_to_matrix(X_train, mode='count')\n\n# encode training data set\nXtest = tokenizer.texts_to_matrix(X_test, mode='count')\n\nn_words1 = Xtest.shape[1]\n\nprint(\"n_words1\", n_words1)","23fe9007":"model = tf.keras.models.Sequential([\n       \n    tf.keras.layers.Dense(256, input_shape=(n_words1,), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n\n    \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n          \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","0e45ba3d":"model.compile(loss='binary_crossentropy',\n              optimizer=Adam(0.0001),\n              metrics=['acc'])\n\n#print(model.summary())","5dd0e1a8":"callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n\n\nhistory = model.fit(Xtrain, y_train,\n                    epochs=20,\n                    validation_data=(Xtest, y_test,),\n                    verbose=1,\n                    callbacks=callbacks,\n                   )","c70cdc91":"# Function to make predictions \ndef prediction(X_test, clf_object): \n  \n    y_pred = clf_object.predict(X_test) \n    return y_pred","d66981b2":"predictions_keras = prediction(Xtest, model) ","db903ab9":"pred_ann = [ 1 if y>=0.5 else 0 for y in predictions_keras]","171f142d":"#calculating the accuracy\naccuracy_score = accuracy_score(y_test,pred_ann)\nprint(\"Accuracy score with Keras:\",accuracy_score)","f3d7241f":"def plot_history(history):\n    accuracy = history.history['acc']\n    val_accuracy = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1,len(accuracy) + 1)\n    \n    # Plot accuracy  \n    plt.figure(1)\n    plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n    plt.plot(epochs, val_accuracy, 'g', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Plot loss\n    plt.figure(2)\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\nplot_history(history)","1ea7b6a7":"###### confusion matrix  starts ######\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ncm_ann = confusion_matrix(y_test,pred_ann) \nnames = np.unique(pred_ann)\nsns.heatmap(cm_ann, square=True, annot=True, cbar=False,xticklabels=names, yticklabels=names, cmap=\"YlGnBu\" ,fmt='g')\nplt.xlabel('Truth')\nplt.ylabel('Predicted')\n###### Confusion matrix ends ########","a1731951":"# create the tokenizer\ntokenizer = Tokenizer()\n\n# fit the tokenizer on the train documents\ntokenizer.fit_on_texts(X_train)","e4149635":"# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(X_train)\n# pad sequences\nmax_length = max([len(s.split()) for s in X_train])\nXtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n","e67c1d4b":"# fit the tokenizer on the test documents\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(X_test)\n# pad sequences\nXtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')","99177ad6":"# define vocabulary size (largest integer value)\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"vocab_size = \",vocab_size)","88ae85a4":"# define model\n\nmodel = Sequential()\n\nmodel.add(Embedding(vocab_size, 100, input_length=max_length))\nmodel.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nprint(model.summary())","20019844":"# compile network\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit network\nmodel.fit(Xtrain, y_train, epochs=10, verbose=1)","b62ddaef":"# evaluate\nloss, acc = model.evaluate(Xtest, y_test, verbose=0)\nprint('Test Accuracy: %f' % (acc*100))","99e6d726":"# load embedding as a dict\ndef load_embedding_glove(filename):\n    # load embedding into memory, no need to skip first line\n    file = open(filename,'r', encoding='utf-8')\n    lines = file.readlines()\n    file.close()\n    # create a map of words to vectors\n    embedding = dict()\n    for line in lines:\n        parts = line.split()\n        # key is string word, value is numpy array for vector\n        embedding[parts[0]] = asarray(parts[1:], dtype='float32')\n    return embedding","9a5ef171":"# create a weight matrix for the Embedding layer from a loaded embedding\ndef get_weight_matrix_glove(embedding, vocab):\n    # total vocabulary size plus 0 for unknown words\n    vocab_size = len(vocab) + 1\n    # define weight matrix dimensions with all 0\n    weight_matrix = zeros((vocab_size, 100))\n    # step vocab, store vectors using the Tokenizer's integer mapping\n    for word, i in vocab.items():\n        vector = embedding.get(word)\n        if vector is not None:\n            weight_matrix[i] = vector\n    return weight_matrix","4d62e2c0":"# load embedding from file\nraw_embedding = load_embedding_glove('..\/input\/glove6b100dtxt\/glove.6B.100d.txt')\n","0cce1ffc":"# get vectors in the right order\nembedding_vectors = get_weight_matrix_glove(raw_embedding, tokenizer.word_index)\n","440d5ddd":"# create the embedding layer\nembedding_layer = Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=True)","526cb95d":"# define model\n\nmodel = Sequential()\n\nmodel.add(embedding_layer)\nmodel.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n\nprint(model.summary())","f1a0b694":"# compile network\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","5b9eb737":"# fit network\nmodel.fit(Xtrain, y_train, epochs=10, verbose=2)","2e4d097c":"# evaluate\nloss, acc = model.evaluate(Xtest, y_test, verbose=1)\nprint('Test Accuracy: %f' % (acc*100))","799da7fc":"* In general Length of reviews for feedback=0 is higher than feeback=1\n* For Feedback=0 , length of review is higher for \"black show\", \"Black Plus\" & \"White Plus\"\n* For \"Walnut finish\", \"Oak finish\" - feedback=0 is absent","cbf5c20b":"* verified reviews - Data cleaning & transformation","d267d7b8":"Biveriate Analysis of variation Vs length with hue=feedback","059bdb81":"Lets see top 10 Dates by frequency","1e9558f0":"# Wow !! We got 93% Accuracy with Word embeddigns from GloVe: Global Vectors for Word Representation","10cf0647":"Length of reviews Vs feedback = 0 or 1 : Analysis 2","99e257c7":"Lets see word cloud for feedback=0 (i.e. Negative reviews)","623fd899":"Special thanks to https:\/\/machinelearningmastery.com\/ for the tutorial on Word Embeddings","acf28c11":"Explore length distibution V feedback using kde plots","fccc0ed4":"Print rare words","2d6d9825":"* Total +ve reviews : 2893 and \n* Total -ve reviews : 257 \n* We will split them equally into train and test datasets for model building ","c946e4e2":"Above graphs confirms analysis 1 i.e. feedback=1 have way higher length of reviews(2500+) than feedback=0 (200+)   ","c4d0ac1f":"Lets see word cloud for feedback=1 (i.e. Positive reviews)","60c6ae6d":"Total 16 unique variation","98644c79":"catplot of variation Vs feedback","c6dcd42b":"Analysis 2 confirms analysis 1","5bfceaf3":"Keras with batch normalisation with mode=count","5359b43e":"* Surprisingly, maximum reviews posted on monday, \n* weekends come close to No 2 spot.","21b00f9f":"rating 5 has highest 1955 reviews with length (0-199)","e8441ae5":"Train and test dataset","2b8aad63":"Below are the links to my other Kernel\n\n1. Heart Diesese Prediction (88.52% with simple KNN) - https:\/\/www.kaggle.com\/rahulpednekar\/heart-88-52-accuracy-with-simple-knn \n2. Loan Prediction (85.36% Accuracy) - https:\/\/www.kaggle.com\/rahulpednekar\/loan-prediction-85-36-with-logistic-regression \n3. Heart Failure Prediction (95% Accuracy)-  https:\/\/www.kaggle.com\/rahulpednekar\/heart-failure-prediction-95-accuracy","9f54dfa7":"How about trying Keras ","fff1f3cd":"So we removed 241100 - 230614 = approx 10k characters","f4452c2a":"So we have solved this problem with 4 methods :\n\n1. Simple Logistic regression i.e. classical Method - 92% Accuracy\n1. Artificial Neural Networks - Multiplayer Perceptron - 93% Accuracy\n1. Artificial Neural Networks - Word Embeddings along with CNN (Convolutional Neural Networks)  - 93% Accuracy\n1. Artificial Neural Networks - Word Embeddings along With Glove : Global Vectors for Word Representation - 93% Accuracy\n\n# Isn't it Amazing !!","25dd08fa":"We can see lots of positive words (i.e. good, perfect, easy use, enjoy etc) with feedback=1","176506a2":"Catplot variation+rating","561c3002":"* > **Keras with Tokenizer API produced 93.33% accuracy and only 63 samples were misclassified **","16580681":"Lets plot training\/validation accuracy graphs and loss graphs","60d9e2ca":"Lets try Bag of words Model with binary=True","bfb10e49":"Lets run Logistic Regression with C=1 for which we got highest accuracy","355b5bc0":"* 2500 reviews have a length of (0 to 199)  \n* 416 reviews have a length of (200 to 399)  \n* Few review also have a length > 2500","f4023948":"Lets make the prediction","1fafa653":"Text cleaning completed","32ae464a":"Model Building starts","c0c82d67":"* Length of reviews is highest for \"Black plus \" with rating=2 - indicates some issues with this product\n* Walnut finish and Oak finish have got only rating 5 - Indicates that they might be the best product , also confirmed from variation Vs feedback analysis\n* Maximum review length for rating 1 are for \"Black show\" & \"Black plus\" and \"Black dot\" indicating there may be issues with these products","9d6e0688":"* Data is cleaned and ready for Model Building ...\n* ****so Lets DO It","4f5a4010":"Simple Logistic Regression achieved 93% accuracy for C=1 (Only 67 samples out of 945 were misclassified by the Model)","5b672faa":"Total 77 unique dates","efc0a098":"We can see few negative words (i.e. bad, disappoint, problem, stop,replace, return, repair, never etc) with feedback=0","bdfa5e32":"# We achieved 92.91% accuracy with Embedding layer along with CNN","12d725dc":"30th, 29th & 28th July have maximum frequency","ca970235":"Describe Data","9ffc7c90":"Biveriate Analysis of rating Vs feedback ","abc2e7f2":"* For Feedback=1 : 2369 reviews have length between (0-199) \n* For Feedback=0 : only 163 reviews have length between (0-199) \n* Overall no of reviews are higher for feedback=1 than feedback=0 ","cf021ac0":"Length of reviews Vs feedback = 0 or 1 : Analysis 1","fb43188c":"Length of reviews Vs rating = 1 to 5 : (Analysis 2)","879df187":"July has the maximum review submission ","87c62772":"* Above kde plot confirms that \n* The length of reviews with feedback = 1 are less (0-300) i.e. max frequency\n* The length of reviews with feedback = 0 are more (0-500) i.e. max frequency","3fdc59b0":"Black dot is highest Vs Walnut finish is lowest ","0ca77fce":"Above graph of variation Vs rating confirms our analysis about top and worst products\ni.e. they have only 4 & 5 rating , others rating varies from 1 to 5 ","8b3ed3c4":"# If you have liked my Kernel, PLEASE UPVOTE","d026142e":"* Above graph confirms that -\n* Feedback=1 corresponds to rating 3,4,5 (Good,better, best)\n* Feedback=0 corresponds to rating 1,2 (worst,bad)\n* Average length of feedaback=0 is higher than feedback=1 (Dis-satidfied people are more likely to write more than satusfied people)\n* Highly satisfied people (rating=5) write least as compared to others (rating 1-4)\n* Products with rating = 2 have highest length of reviews","31932c97":"Plot  N-grams ","b3dddb1a":"No duplicates present","9faec67d":"Date , Month and weekday Analysis","03abeaa6":"Lets try Embedding Layer with CNN","aa6b715a":"With the conclusion that\nfeedback=1 (rating 3,4 & 5) i.e. the best products and \nfeedback=0 (rating 1 & 2) i.e. the worst products \n\nLets do some more analysis on the variations Vs feedback and identify which is the best and worst product as per customer sentiments","beec9e60":"Now lets try Deep Learning algorithm with Word embeddigns from GloVe: Global Vectors for Word Representation","1cd81487":"Biveriate Analysis of variation Vs length with hue=rating","d92fca6d":"Print n-grams and frequency","b2a227ab":"Now lets try with Glove embedding i.e. using glove6b100d.txt ","9608c3c6":"Time to print Confusion matrix","ae61da8e":"Explore length distibution V rating using kde plots","db7b6ea4":"Explore Numerical Data","2b53f01b":"* rating : 72.6% (max) belongs to 5 , 3% (lowest) belongs to 2\n  It gives an impression that people are really happy with Alexa  \n\n* feedback : 91.8% gave feedback, 8.2% ddi not give feedback\n","510b1a18":"Load data","4cb7b2bf":"* Above graphs confrms that\n* rating=2 have highest length and rating=1 has minumum length","06312111":"calculate +ve Vs -ve review count","531e9d9a":"Lets identify words which have frequency of 1 and categorize them as rare words for deletion","89bf37fe":"* Feeedback=1 : Total 2893\n* we can use the first 2025(70%) for training and 868(30%) remaining for testing\n* i.e. 2893=2025+868\n* \n* Feeedback=0 : Total 257\n* we can use the first 180(70%) for training and 77(30%) remaining for testing\n* i.e. 257=180+77","a9224b5b":"Lets start cleaning the verified reviews","66adc0e5":"check Shape","40a7ae42":"First Look at data","c7cf3504":"* With respect to customer sentiments as per their feedback 0 or 1 :\n* Walnut finish and oak finish are the top products\n* Heather Grey Fabric comes close at No.2\n* White is the worst product","9ba6c1eb":"Length of reviews Vs rating = 1 to 5 : (Analysis 1)"}}