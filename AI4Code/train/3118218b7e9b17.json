{"cell_type":{"27bb0211":"code","38a511df":"code","9e798e1c":"code","fb79d7d6":"code","701d295d":"code","82663997":"code","5bb027dc":"code","3fc8a882":"code","65a96310":"code","0503a31f":"code","08327c45":"code","39b7000b":"code","097d7598":"code","0f8c946b":"code","c2a515a4":"code","514e2de1":"code","68e5f7ce":"code","92349871":"code","c97aeed9":"code","c9d7b690":"code","2041600d":"code","60fbd931":"code","645e8963":"code","09bb6ba8":"code","d7e91393":"code","83e11216":"code","c3c1235e":"code","c877ac80":"code","f9ee6f0d":"code","b11abdc7":"code","5b9c2edd":"code","92d72e80":"code","601f7fad":"code","7aa433e6":"code","abf8bf27":"markdown","45758a5f":"markdown","b289d776":"markdown","7894013c":"markdown","5bb9aa39":"markdown","55e29bd2":"markdown","cc7097ee":"markdown","63e5934c":"markdown","b425d8ce":"markdown","ca6dcf0f":"markdown","ae4b473c":"markdown","15a8eb80":"markdown","49444e61":"markdown","b6d6cea3":"markdown","d941474a":"markdown","4067bdd5":"markdown","c96d0da9":"markdown"},"source":{"27bb0211":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38a511df":"# Importin Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","9e798e1c":"# Load Data\n# All data set are in Separate format\ntrain_df = pd.read_csv(\"\/kaggle\/input\/loan-prediction-based-on-customer-behavior\/Training Data.csv\",)\ntest_df = pd.read_csv(\"\/kaggle\/input\/loan-prediction-based-on-customer-behavior\/Test Data.csv\")\ntarget_df = pd.read_csv(\"\/kaggle\/input\/loan-prediction-based-on-customer-behavior\/Sample Prediction Dataset.csv\")","fb79d7d6":"train_df.head()","701d295d":"train_df.shape","82663997":"# Checking Null Values\n\nprint(train_df.shape,\ntest_df.shape,\ntarget_df.shape)","5bb027dc":"# Checking Null Values\nprint(train_df.isnull().sum(),\n     test_df.isnull().sum())","3fc8a882":"train_df.info() # Check Data types","65a96310":"# Check Risk Flags\nplt.figure(figsize=(10,8))\nsns.countplot(y=train_df['Risk_Flag'])\nplt.title(\"Risk Flag\")\nprint(train_df['Risk_Flag'].value_counts())","0503a31f":"plt.figure(figsize=(10,6))\ntrain_df['House_Ownership'].value_counts().plot(kind='bar')\nplt.legend(frameon=True)","08327c45":"plt.figure(figsize=(10,6))\ntrain_df['Car_Ownership'].value_counts().plot(kind='pie')\nplt.title(\"Car Owners\")\nplt.legend(loc='upper right')","39b7000b":"plt.figure(figsize=(10,18))\ntrain_df['Profession'].value_counts().plot(kind='barh')\nplt.title('Profession')\nplt.legend()","097d7598":"#Use Label encoding to correlate features\n\nfrom sklearn.preprocessing import LabelEncoder\nenco = LabelEncoder()","0f8c946b":"C_features = ['Married\/Single','House_Ownership','Car_Ownership','Profession','CITY','STATE']\nfor cols in C_features:\n    train_df[cols] = enco.fit_transform(train_df[cols])\n    \ntrain_df.head()","c2a515a4":"train_df.describe()","514e2de1":"# Checking Correlation Between dataset\ncorr = train_df.corr()\ncorr","68e5f7ce":"#Heat Map\nplt.figure(figsize=(15,12))\nsns.heatmap(corr,annot=True)","92349871":"#State wise count\nplt.figure(figsize=(10,16))\ntrain_df['STATE'].value_counts().plot(kind='barh')","c97aeed9":"#Check Defaulters\nDefalters = 100*train_df[\"Risk_Flag\"].value_counts().values[1]\/train_df[\"Risk_Flag\"].value_counts().sum()\nprint(\"Total Defalters in %\",Defalters)\n","c9d7b690":"# Splitting Data set\n\n\nX = train_df.drop(\"Risk_Flag\", axis=1)\ny = train_df[\"Risk_Flag\"]","2041600d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=122)\nprint(X_train.shape,X_test.shape, y_train.shape, y_test.shape)","60fbd931":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state=11)\ntrain_df, test_df = smote.fit_resample(X_train,y_train)","645e8963":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\nclassifier = classifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n","09bb6ba8":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n\n# create heatmap\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix R_Forest', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n\n#Model Evaluation\nfrom sklearn import metrics\nprint(\"Accuracy:  \",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision: \",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:    \",metrics.recall_score(y_test, y_pred))\nprint(\"f1:        \",metrics.f1_score(y_test,y_pred))","d7e91393":"from sklearn.metrics import roc_curve, auc\n\n#---find the predicted probabilities using the test set\nprobs = classifier.predict_proba(X_test)\npreds = probs[:,1]\n\n#---find the FPR, TPR, and threshold---\nfpr, tpr, threshold = roc_curve(y_test, preds)\n#---find the area under the curve---\n\nroc_auc = auc(fpr, tpr)\n\nimport matplotlib.pyplot as plt\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate (TPR)')\nplt.xlabel('False Positive Rate (FPR)')\nplt.title('Receiver Operating Characteristic (ROC)')\nplt.legend(loc = 'lower right')\nplt.show()","83e11216":"from sklearn.neighbors import KNeighborsClassifier\n\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\nclassifier = classifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)","c3c1235e":"cm = confusion_matrix(y_test, y_pred)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass_names=[0,1] # name  of classes\n\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n\n# create heatmap\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix KNN', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n\n# Model Evaluation\n\nprint(\"Accuracy:   \",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:  \",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:     \",metrics.recall_score(y_test, y_pred))\nprint(\"f1:         \",metrics.f1_score(y_test,y_pred))","c877ac80":"probs = classifier.predict_proba(X_test)\npreds = probs[:,1]\n\n#---find the FPR, TPR, and threshold---\nfpr, tpr, threshold = roc_curve(y_test, preds)\n#---find the area under the curve---\n\nroc_auc = auc(fpr, tpr)\n\nimport matplotlib.pyplot as plt\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate (TPR)')\nplt.xlabel('False Positive Rate (FPR)')\nplt.title('Receiver Operating Characteristic (ROC)')\nplt.legend(loc = 'lower right')\nplt.show()\n","f9ee6f0d":"from sklearn.tree import DecisionTreeClassifier\n\nclassifier = DecisionTreeClassifier(random_state = 0)\n#fitting decision tree on data\n\nclassifier = classifier.fit(X_train,y_train)\n#Predicting the Test set results\ny_pred = classifier.predict(X_test)","b11abdc7":"cm = confusion_matrix(y_test, y_pred)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass_names=[0,1] # name  of classes\n\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n\n# create heatmap\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n\n# Model Evaluation\n\nprint(\"Accuracy:   \"  ,metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:  \" ,metrics.precision_score(y_test, y_pred))\nprint(\"Recall:     \",metrics.recall_score(y_test, y_pred))\nprint(\"f1:         \",metrics.f1_score(y_test,y_pred))","5b9c2edd":"#---find the predicted probabilities using the test set\nprobs = classifier.predict_proba(X_test)\npreds = probs[:,1]\n\n#---find the FPR, TPR, and threshold---\nfpr, tpr, threshold = roc_curve(y_test, preds)\n#---find the area under the curve---\n\nroc_auc = auc(fpr, tpr)\n\nimport matplotlib.pyplot as plt\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate (TPR)')\nplt.xlabel('False Positive Rate (FPR)')\nplt.title('Receiver Operating Characteristic (ROC)')\nplt.legend(loc = 'lower right')\nplt.show()","92d72e80":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\nfrom sklearn.svm import SVC\n#classifier = SVC(kernel = 'linear', random_state = 0)\n# classifier = SVC(kernel = 'linear', C = 2, random_state = 0)\n# classifier = SVC(kernel = 'poly', degree = 2, random_state = 0)\nclassifier = SVC(kernel = 'rbf', random_state = 0)\n# classifier = SVC(kernel = 'rbf', gamma = 10, random_state = 0)\n\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)","601f7fad":"cm = confusion_matrix(y_test, y_pred)\nclass_names=[0,1] # name  of classes\n\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n\n# create heatmap\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","7aa433e6":"from sklearn.metrics import plot_roc_curve\n\nsvc_disp = plot_roc_curve(classifier, X_test, y_test)\nplt.show()","abf8bf27":"**The training data(252000, 13)**\n\n**The test data (28000, 12)**","45758a5f":"## ROC Curve Random_Forest Model","b289d776":"## Confusion Matrix Decision Tree","7894013c":"## **Total Defalters 12.3%**","5bb9aa39":"# ROC Curve KNN","55e29bd2":"## Confusion Matrix (Random Forest Model)","cc7097ee":"# SVM(Support Vector Machine)","63e5934c":"# Decision Tree","b425d8ce":"# KNN","ca6dcf0f":"# Confusion Matrix SVM","ae4b473c":"### Total Defalters are 12.3%\n### To improve more accuracy in model \n### Use SMOTE(SMOTE use for Imbalanced Data Distribution)","15a8eb80":"## Confusion Matrix KNN Model","49444e61":"# ROC Curve SVM","b6d6cea3":"**There is no Null Values in whole data set**","d941474a":"# Random Forest","4067bdd5":"train_df.drop('Id',axis=1,inplace=True)","c96d0da9":"# ROC Curve Decision Tree"}}