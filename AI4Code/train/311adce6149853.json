{"cell_type":{"cb0d0a00":"code","15b220cc":"code","8d0b7570":"code","7fa265e4":"code","c807b635":"code","1b25af20":"code","04489496":"code","bb199569":"code","7ec128fc":"code","c938c982":"code","3bd5ae2e":"code","7b00e622":"code","419e67a8":"code","80476bbb":"code","eefec2b8":"code","b39e08fc":"code","c3acc1b1":"code","3fc655dc":"code","a2c88fcd":"code","075af95b":"code","edfb83c0":"markdown","24021952":"markdown","806d3861":"markdown","8e294990":"markdown","9f9c0612":"markdown","8908c958":"markdown","ccc93f84":"markdown","0ab1a9cb":"markdown","3e8e9306":"markdown","3ccb1972":"markdown","7f9a9e91":"markdown","93b8d8be":"markdown","681724b9":"markdown","82d8c334":"markdown","148a5cb2":"markdown","c677bec8":"markdown","c81abf94":"markdown","815a4786":"markdown","81b922af":"markdown","c055a840":"markdown","9b9c38eb":"markdown","78a1d5f3":"markdown","c1c35bf9":"markdown","b67cd62a":"markdown","9c472238":"markdown","668a7780":"markdown","a2a88d37":"markdown","a35a382b":"markdown","b3db4868":"markdown"},"source":{"cb0d0a00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","15b220cc":"dataset = pd.read_csv('..\/input\/train.csv')\nX = dataset.iloc[:, 1:].values\ny = dataset.iloc[:, 0].values","8d0b7570":"import seaborn as sns\nsns.countplot(y)","7fa265e4":"# Check IF some Feature variables are NaN\nnp.unique(np.isnan(X))[0]","c807b635":"# Check IF some Target Variables are NaN\nnp.unique(np.isnan(y))[0]","1b25af20":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)","04489496":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","bb199569":"from keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)","7ec128fc":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout","c938c982":"# Initialising the ANN\nclassifier = Sequential()","3bd5ae2e":"# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 784, activation = 'relu', input_dim = 784))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 128, activation = 'relu'))\nclassifier.add(Dense(units = 128, activation = 'relu'))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Dense(units = 64, activation = 'relu'))\nclassifier.add(Dense(units = 64, activation = 'relu'))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Dense(units = 32, activation = 'relu'))\nclassifier.add(Dense(units = 32, activation = 'relu'))\nclassifier.add(Dropout(0.05))","7b00e622":"# Adding the output layer\nclassifier.add(Dense(units = 10, activation = 'softmax'))","419e67a8":"# Compiling the ANN\nclassifier.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])","80476bbb":"# Fitting the ANN to the Training set\nhistory = classifier.fit(X_train, y_train, \n                         validation_data = (X_test, y_test), \n                         batch_size = 28, \n                         epochs = 25)\n\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n","eefec2b8":"model_acc = classifier.evaluate(X_test, y_test)\nprint(\" Model Accuracy is : {0:.1f}%\".format(model_acc[1]*100))","b39e08fc":"test_dataset = pd.read_csv('..\/input\/test.csv')\ntest = test_dataset.iloc[:,:].values","c3acc1b1":"# Prediction\ntest_pred = classifier.predict(test)\n\n# Mark probability score > 0.5 as Predicted Label, axis = 1 means insert column-wise \nresults = test_pred.argmax(axis=1)","3fc655dc":"for i in range(1,10):\n    index = np.random.randint(1,28001)\n    plt.subplot(3,3,i)\n    plt.imshow(test[index].reshape(28,28))\n    plt.title(\"Predicted Label : {}\".format(results[index]))\nplt.subplots_adjust(hspace = 1.2, wspace = 1.2)\nplt.show()\n    ","a2c88fcd":"results = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","075af95b":"submission.head()","edfb83c0":"### Encoding Categorical Data into Continuous Variable","24021952":"### Adding Input Layer and Hidden Layers","806d3861":"### Let's see the distribution of data","8e294990":"Since no NULL or NaN values are there, we're good to go!","9f9c0612":"### Feature Scaling\nThis step is to transform the data such that its distribution will have a mean value 0 and standard deviation of 1.  \nGiven the distribution of the data, each value in the dataset will have the sample mean value subtracted, and then divided by the standard deviation of the whole dataset.","8908c958":"### Make Predictions for ' test ' data","ccc93f84":"### Splitting Dataset into Training set and Test set","0ab1a9cb":"# 4. Perfomance Evaluation","3e8e9306":"### Import Training data as Numpy array","3ccb1972":"# 2. Building our ANN","7f9a9e91":"### Adding Output Layer","93b8d8be":"### Import Numpy, Pandas and matplotlib libraries","681724b9":"### Initialising the ANN Model","82d8c334":"### Visualize some test results","148a5cb2":"### Fitting the ANN to the Training set","c677bec8":"### Importing the Keras libraries and packages","c81abf94":"**Dataset:**  \n* ..\/input\/  \n       |_ train.csv  \n       |_ test.csv  \n       |_ sample_submission.csv","815a4786":"### Convert Numpy Array format to Pandas Series and then to CSV format","81b922af":"# 5. Prepare for Final Submission","c055a840":"### Compiling our Model","9b9c38eb":"# 3. Training our ANN","78a1d5f3":"### Import the Test Data","c1c35bf9":"### Check for Null Values","b67cd62a":"# Introduction to ANN with Digit Recognizer Challenge  \n\n*5 November 2018*  \n\n#### ***[Soumya Ranjan Behera](https:\/\/www.linkedin.com\/in\/soumya044)***\n\n### In this Kernel I have demonstrated a beginner's approach of implementing an  Artificial Neural Network (ANN) to classify the digits into their respective categories which have scored **96.7 %** Accuracy in the Digit Recognizer Competition.\n\n### Goals of this Kenel:  \n* To provide a basic implementation of Artificial Neural Network (ANN)\n* To show a path for approaching Convolutional Neural Network (CNN)\n* A beginner friendly kernel to show a procedure to compete in Kaggle Digit Recognizer Competition","9c472238":"### Accuracy of Model","668a7780":"Since all our target classes are well-balanced we can move to our next step.","a2a88d37":"### Check Submission file for correct format","a35a382b":"# 1. Prepare our Data ","b3db4868":"# Thank You  \n\nIf you liked this kernel please **Upvote**. Don't forget to drop a comment or suggestion.  \n\n### *Soumya Ranjan Behera*\nLet's stay Connected! [LinkedIn](https:\/\/www.linkedin.com\/in\/soumya044)  \n\n**Happy Coding !**"}}