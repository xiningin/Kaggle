{"cell_type":{"ae66c4e2":"code","f0c5d254":"code","0d8188a9":"code","67952f57":"code","1e4f2efd":"code","d721003f":"code","c0cb6f48":"code","4f7f2fc8":"code","376fd264":"code","179bd49e":"code","dfd767d2":"code","6bd80f38":"code","c7051315":"code","90b3c4cb":"code","5552271d":"code","05119347":"code","3bb985e9":"code","98e33fbb":"code","ba586fc0":"code","c9264bbb":"code","28a3536f":"code","9f47eedc":"code","64b09736":"markdown","fff9ece2":"markdown","370e7fef":"markdown","83ff8f5e":"markdown","398abcf4":"markdown","84a3619c":"markdown","e1eb565e":"markdown"},"source":{"ae66c4e2":"import os\nimport pandas as pd\nimport numpy as np\n\nimport cv2\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport xml.etree.ElementTree as ET\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models","f0c5d254":"images_path = Path('..\/input\/dog-and-cat-detection\/images')\nanno_path = Path('..\/input\/dog-and-cat-detection\/annotations')\n\n\ndef filelist(root, file_type):\n    \"\"\"\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043a\u0432\u0430\u043b\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0441\u043f\u0438\u0441\u043e\u043a \u0444\u0430\u0439\u043b\u043e\u0432 \u0432 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438\"\"\"\n    return [os.path.join(directory_path, f) for directory_path, directory_name, \n            files in os.walk(root) for f in files if f.endswith(file_type)]\n\n\ndef generate_train_df (anno_path):\n    annotations = filelist(anno_path, '.xml')\n    anno_list = []\n    for anno_path in annotations:\n        root = ET.parse(anno_path).getroot()\n        anno = {}\n        anno['filename'] = Path(str(images_path) + '\/'+ root.find(\".\/filename\").text)\n        anno['width'] = root.find(\".\/size\/width\").text\n        anno['height'] = root.find(\".\/size\/height\").text\n        anno['class'] = root.find(\".\/object\/name\").text\n        anno['xmin'] = int(root.find(\".\/object\/bndbox\/xmin\").text)\n        anno['ymin'] = int(root.find(\".\/object\/bndbox\/ymin\").text)\n        anno['xmax'] = int(root.find(\".\/object\/bndbox\/xmax\").text)\n        anno['ymax'] = int(root.find(\".\/object\/bndbox\/ymax\").text)\n        anno_list.append(anno)\n    return pd.DataFrame(anno_list)","0d8188a9":"df_train = generate_train_df(anno_path)\ndf_train","67952f57":"df_train['class'].value_counts()","1e4f2efd":"class_dict = {'cat': 0, 'dog': 1}\ndf_train['class'] = df_train['class'].apply(lambda x:  class_dict[x])\n\nprint(df_train.shape)\ndf_train.head()","d721003f":"def read_image(path):\n    return cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n\ndef create_mask(bb, x):\n    \"\"\"\u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u0430\u0441\u043a\u0443 \u0434\u043b\u044f bounding box'a \u0442\u0430\u043a\u043e\u0433\u043e \u0436\u0435 \u0448\u0435\u0439\u043f\u0430 \u043a\u0430\u043a \u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\"\"\"\n    rows,cols,*_ = x.shape\n    Y = np.zeros((rows, cols))\n    bb = bb.astype(np.int)\n    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n    return Y\n\ndef mask_to_bb(Y):\n    \"\"\"\u041a\u043e\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043c\u0430\u0441\u043a\u0443 Y \u0432 bounding box'a, \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u044f 0 \u043a\u0430\u043a \u0444\u043e\u043d\u043e\u0432\u044b\u0439 \u043d\u0435\u043d\u0443\u043b\u0435\u0432\u043e\u0439 \u043e\u0431\u044a\u0435\u043a\u0442 \"\"\"\n    cols, rows = np.nonzero(Y)\n    if len(cols) == 0: \n        return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef create_bb_array(x):\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c \u043c\u0430\u0441\u0441\u0438\u0432 bounding box'a \u0438\u0437 \u0441\u0442\u043e\u043b\u0431\u0446\u0430 train_df\"\"\"\n    return np.array([x[5],x[4],x[7],x[6]])\n\n\ndef resize_image_bb(read_path, write_path, bb, sz):\n    \"\"\"\u0420\u0435\u0441\u0430\u0439\u0437\u0438\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438 \u0435\u0433\u043e bounding box \u0438 \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0432 \u043d\u043e\u0432\u044b\u0439 \u043f\u0443\u0442\u044c\"\"\"\n    im = read_image(read_path)\n    im_resized = cv2.resize(im, (sz, sz))\n    Y_resized = cv2.resize(create_mask(bb, im), (sz, sz))\n    new_path = str(write_path\/read_path.parts[-1])\n    cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n    return new_path, mask_to_bb(Y_resized)\n\n\n\ndef crop(im, r, c, target_r, target_c): \n    \"\"\"\u0412\u044b\u0440\u0435\u0437\u0430\u0435\u043c \u043a\u0443\u0441\u043e\u043a \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\"\"\"\n    return im[r:r+target_r, c:c+target_c]\n\ndef center_crop(x, r_pix=8):\n    \"\"\"\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u043e\u0435 \u0432\u044b\u0440\u0435\u0437\u0430\u043d\u0438\u0435 \"\"\"\n    r, c,*_ = x.shape\n    c_pix = round(r_pix*c\/r)\n    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n\ndef transformsXY(path, bb, is_transforms):\n    \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u043d\u0430\u0448\u0443 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0443\"\"\"\n    x = cv2.imread(str(path)).astype(np.float32)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) \/ 255\n    Y = create_mask(bb, x)\n    if is_transforms:\n        rdeg = (np.random.random()-.50) * 20\n        x = rotate_cv(x, rdeg)\n        Y = rotate_cv(Y, rdeg, y=True)\n        if np.random.random() > 0.5: \n            x = np.fliplr(x).copy()\n            Y = np.fliplr(Y).copy()\n        x, Y = random_cropXY(x, Y)\n    else:\n        x, Y = center_crop(x), center_crop(Y)\n    return x, mask_to_bb(Y)\n\ndef create_corner_rect(bb, color='red'):\n    bb = np.array(bb, dtype=np.float32)\n    return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n                         fill=False, lw=3)\n\ndef show_corner_bb(im, bb):\n    plt.imshow(im)\n    plt.gca().add_patch(create_corner_rect(bb))","c0cb6f48":"IM_SIZE = 300\n\nnew_paths = []\nnew_bbs = []\ntrain_path_resized = Path('.\/images_resized')\nPath.mkdir(train_path_resized, exist_ok=True)\n\n\nfor index, row in df_train.iterrows():\n    new_path,new_bb = resize_image_bb(row['filename'], train_path_resized, create_bb_array(row.values), IM_SIZE)\n    new_paths.append(new_path)\n    new_bbs.append(new_bb)\n    \n    \ndf_train['new_path'] = new_paths\ndf_train['new_bb'] = new_bbs\n\ndf_train.head()","4f7f2fc8":"im = cv2.imread(str(df_train.values[58][0]))\nbb = create_bb_array(df_train.values[58])\nprint(im.shape)\n\nY = create_mask(bb, im)\nmask_to_bb(Y)\n\nplt.imshow(im)","376fd264":"plt.imshow(Y, cmap='gray')","179bd49e":"df_train = df_train.reset_index()\nX = df_train[['new_path', 'new_bb']]\nY = df_train['class']\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n\ndef normalize(im):\n    \"\"\"\u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0438 ImageNet\"\"\"\n    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n    return (im - imagenet_stats[0]) \/ imagenet_stats[1]\n\n\nclass RoadDataset(Dataset):\n    def __init__(self, paths, bb, y, is_transforms=False):\n        self.is_transforms = is_transforms\n        self.paths = paths.values\n        self.bb = bb.values\n        self.y = y.values\n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, idx):\n        path = self.paths[idx]\n        y_class = self.y[idx]\n        x, y_bb = transformsXY(path, self.bb[idx], self.is_transforms)\n        x = normalize(x)\n        x = np.rollaxis(x, 2)\n        return x, y_class, y_bb\n\n    \ntrain_ds = RoadDataset(X_train['new_path'], X_train['new_bb'], y_train)#, is_transforms=True)\nvalid_ds = RoadDataset(X_val['new_path'], X_val['new_bb'], y_val)","dfd767d2":"batch_size = 16\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size)","6bd80f38":"class BB_model(nn.Module):\n    def __init__(self):\n        super(BB_model, self).__init__()\n        resnet = models.resnet34(pretrained=True)\n        layers = list(resnet.children())[:8]\n        self.features = nn.Sequential(*layers)\n        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = F.relu(x)\n        x = nn.AdaptiveAvgPool2d((1,1))(x)\n        x = x.view(x.shape[0], -1)\n        return self.classifier(x), self.bb(x)","c7051315":"resnet = models.resnet34(pretrained=True)\nlist(resnet.children())[:8]","90b3c4cb":"model = BB_model().cuda()\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.006)\nepochs = 15\nmodel","5552271d":"def train():\n    for i in range(epochs):\n\n        model.train()\n        total = 0\n        sum_loss = 0\n\n        for x, y_class, y_bb in train_dl:\n            len_batch = y_class.shape[0]\n            x = x.cuda().float()\n            y_class = y_class.cuda()\n            y_bb = y_bb.cuda().float()\n            out_class, out_bb = model(x)\n            \n            # losses\n            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"sum\")\n            \n            loss = loss_class + loss_bb\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            total += len_batch\n            sum_loss += loss.item()\n        \n        train_loss = sum_loss \/ total\n\n        # Eval\n        model.eval()\n        val_total = 0\n        val_sum_loss = 0\n        correct = 0\n\n        for x, y_class, y_bb in valid_dl:\n            len_batch = y_class.shape[0]\n            x = x.cuda().float()\n            y_class = y_class.cuda()\n            y_bb = y_bb.cuda().float()\n            \n            out_class, out_bb = model(x)\n            \n            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"sum\")\n            loss = loss_class + loss_bb\n            \n            _, pred = torch.max(out_class, 1)\n            correct += (pred == y_class).sum().item()\n            \n            val_sum_loss += loss.item()\n            val_total += len_batch\n            \n        val_loss = val_sum_loss \/ val_total\n        val_acc = correct \/ val_total\n\n        print(f\"Epoch [{i+1}\/{epochs}]. train_loss {train_loss:.3f} val_loss {val_loss:.3f} val_acc {val_acc:.3f}\")","05119347":"train()","3bb985e9":"# resizing test image\nimage = 'Cats_Test111'\nim = read_image(f'.\/images_resized\/{image}.png')\nPath.mkdir(Path('.\/road_signs_test'), exist_ok=True)\ncv2.imwrite(f'.\/road_signs_test\/{image}.jpg', cv2.cvtColor(im, cv2.COLOR_RGB2BGR))","98e33fbb":"# test Dataset\ntest_ds = RoadDataset(\n    pd.DataFrame([{'path':f'.\/road_signs_test\/{image}.jpg'}])['path'],\n    pd.DataFrame([{'bb':np.array([0,0,0,0])}])['bb'],\n    pd.DataFrame([{'y':[0]}])['y']\n)\nx, y_class, y_bb = test_ds[0]\n\nxx = torch.FloatTensor(x[None,])\nxx.shape","ba586fc0":"# prediction\nout_class, out_bb = model(xx.cuda())\nout_class, out_bb","c9264bbb":"# predicted class\ntorch.max(out_class, 1)","28a3536f":"class_dict","9f47eedc":"# predicted bounding box\nbb_hat = out_bb.detach().cpu().numpy()\nbb_hat = bb_hat.astype(int)\nshow_corner_bb(im, bb_hat[0])","64b09736":"### \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","fff9ece2":"### \u041f\u0440\u0438\u043c\u0435\u0440 \u043f\u043e\u043b\u0443\u0447\u0438\u0432\u0448\u0435\u0433\u043e\u0441\u044f \u0441\u044d\u043c\u043f\u043b\u0430","370e7fef":"### \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435","83ff8f5e":"### \u0418\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u0432 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 bounding box'\u043e\u0432","398abcf4":"### \u0422\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435","84a3619c":"### \u0414\u0430\u0442\u0430\u0441\u0435\u0442","e1eb565e":"### \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445"}}