{"cell_type":{"a1fcd8fa":"code","ca1341d8":"code","f681a219":"code","96b0a691":"code","a5c5e5e4":"code","07cc7563":"code","bd37bf90":"code","6f0b0780":"code","dd61c13b":"code","1d4770d2":"code","47623067":"code","a04ac8c7":"code","29709f72":"code","bf4136bf":"code","c618c93e":"code","57f2224b":"code","e7ba439e":"markdown","8123127d":"markdown","0a9caad7":"markdown"},"source":{"a1fcd8fa":"import numpy as np \nimport pandas as pd \nimport os\nprint(os.listdir(\"..\/input\/leapgestrecog\/leapGestRecog\"))","ca1341d8":"from PIL import Image\nimport matplotlib.image as mpimg \nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport IPython.display\npath='..\/input\/leapgestrecog\/leapGestRecog'\nfolders=os.listdir(path)\nfolders=set(folders)\n\n#import codecs\n#import json\n\n\ndifferent_classes=os.listdir(path+'\/'+'00')\ndifferent_classes=set(different_classes)\n\n\n\n\nprint(\"The different classes that exist in this dataset are:\")\nprint(different_classes)","f681a219":"x=[]\nz=[]\ny=[]#converting the image to black and white\nthreshold=200\nimport cv2\n\n\nfor i in folders:\n    print('***',i,'***')\n    subject=path+'\/'+i\n    subdir=os.listdir(subject)\n    subdir=set(subdir)\n    for j in subdir:\n        #print(j)\n        images=os.listdir(subject+'\/'+j)\n        for k in images:\n            results=dict()\n            results['y']=j.split('_')[0]\n            img = cv2.imread(subject+'\/'+j+'\/'+k,0)\n            img=cv2.resize(img,(int(160),int(60)))\n            \n            ret, imgf = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n            imgD=np.asarray(img,dtype=np.float64)\n            z.append(imgD)\n            imgf=np.asarray(imgf,dtype=np.float64)\n            x.append(imgf)\n            y.append(int(j.split('_')[0]))\n            results['x']=imgf","96b0a691":"l = []\nlist_names = []\nfor i in range(10):\n    l.append(0)\nfor i in range(len(x)):\n    if(l[y[i] - 1] == 0):\n        l[y[i] - 1] = i\n        if(len(np.unique(l)) == 10):\n            break\nfor i in range(len(l)):\n    %matplotlib inline\n    print(\"Class Label: \" + str(i + 1))\n    plt.imshow(np.asarray(z[l[i]]), cmap  =cm.gray)\n    plt.show()\n    plt.imshow(np.asarray(x[l[i]]), cmap = cm.gray)     \n    plt.show()","a5c5e5e4":"x=np.array(x)\ny=np.array(y)\ny = y.reshape(len(x), 1)\nprint(x.shape)\nprint(y.shape)\nprint(max(y),min(y))","07cc7563":"x_data = x.reshape((len(x), 60, 160, 1))\n\nx_data\/=255\nx_data=list(x_data)\nfor i in range(len(x_data)):\n    x_data[i]=x_data[i].flatten()","bd37bf90":"len(x_data)","6f0b0780":"from sklearn.decomposition import PCA\npca = PCA(n_components=20)\nx_data=np.array(x_data)\nprint(\"Before PCA\",x_data.shape)","dd61c13b":"x_data=pca.fit_transform(x_data)\nprint(pca.explained_variance_ratio_)  \nprint(pca.singular_values_)  \n\nprint('___________________')\nprint(\"After PCA\",x_data.shape)","1d4770d2":"from sklearn.model_selection import train_test_split\nx_train,x_further,y_train,y_further = train_test_split(x_data,y,test_size = 0.2)\nx_train,x_valid,y_train, y_valid = train_test_split(x_train,y_train,test_size = 0.5)","47623067":"from sklearn.preprocessing import MinMaxScaler  \nscaler = MinMaxScaler()  \n#We use the MinMaxScaler for Naive Bayes because some of the classifiers require non-negative input.\n#We normalize the values between 0 and 1 in this case\nscaler.fit(x_train)\n\nX_train = scaler.transform(x_train)  \nX_valid = scaler.transform(x_valid)\nX_test = scaler.transform(x_further)  ","a04ac8c7":"from sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\n\nclassifiers = ['bernoulli', 'complement', 'gaussian', 'multinomial']\nerrors = []\n\nbnb = BernoulliNB()\nbnb.fit(X_train, y_train)\nerror = 1. - bnb.score(X_valid, y_valid)\nerrors.append(error)\n\ncompnb = ComplementNB()\ncompnb.fit(X_train, y_train)\nerror = 1. - compnb.score(X_valid, y_valid)\nerrors.append(error)\n\ngnb = GaussianNB() \ngnb.fit(X_train, y_train)\nerror = 1. - gnb.score(X_valid, y_valid)\nerrors.append(error)\n\nmnb = MultinomialNB()\nmnb.fit(X_train, y_train)\nerror = 1. - mnb.score(X_valid, y_valid)\nerrors.append(error)\n\nplt.plot(classifiers, errors)\nplt.title('Classifier vs. Model Error')\nplt.xlabel('classifier')\nplt.ylabel('error')\nplt.xticks(classifiers)\nplt.show()\n\nminError = errors.index(min(errors))\nbestClassifier = classifiers[minError]\n\nprint(\"Optimal Classifier: {}\".format(bestClassifier))","29709f72":"smoothing_values =  [1e-15, 1e-11, 1e-9, 1e-5, 0.001, 0.01, 0.1, 1]\nsmoothing_error = []\n\nfor smoothing in smoothing_values:\n    model = GaussianNB(var_smoothing=smoothing)\n    model = model.fit(X_train, y_train)\n    error = 1. - model.score(X_valid, y_valid)\n    smoothing_error.append(error)\n    \nplt.plot(smoothing_values, smoothing_error)\nplt.title('Smoothing vs. Model Error')\nplt.xlabel('smoothng')\nplt.ylabel('error')\n#plt.xticks(smoothing)\nplt.show()\n\nminError =smoothing_error.index(min(smoothing_error))\nbestSmoothing = smoothing_values[minError]\n\nprint(\"Best Smoothing: {}\".format(bestSmoothing))","bf4136bf":"bestnb = GaussianNB(var_smoothing=bestSmoothing)\nbestnb.fit(X_train, y_train)\ny_pred_nb = bestnb.predict(X_test)\ny_train_score_nb = bestnb.predict(X_train)","c618c93e":"from sklearn.metrics import accuracy_score\nprint(\"accuracy of the model is:\\nTest \", accuracy_score(y_further, y_pred_nb, normalize=True, sample_weight=None))\nprint('Train',accuracy_score(y_train, y_train_score_nb, normalize=True, sample_weight=None))","57f2224b":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nmatrix = confusion_matrix(y_further, y_pred_nb, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nprecision = precision_score(y_further, y_pred_nb, average = None)\naccuracy = accuracy_score(y_further, y_pred_nb, normalize=True, sample_weight=None)\nrecall = recall_score(y_further, y_pred_nb, average=None)\n\nprint(\"Confusion Matrix:\\n\", matrix, \"\\n\")\nprint(\"Accuracy:\", accuracy, \"\\n\")\nprint(\"Recall:\", recall, \"\\n\")\nprint(\"Precision:\", precision)","e7ba439e":"## Run Optimal Model on Test Set","8123127d":"## Naive Bayes","0a9caad7":"## PCA and Pre-Processing the data"}}