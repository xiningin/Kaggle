{"cell_type":{"b489c378":"code","cd575dae":"code","15e67d8f":"code","3e4f0d69":"code","79183625":"code","8f2f4548":"code","596c17df":"code","7aa56702":"code","c3a0f34e":"code","df6b0a8c":"code","3c867160":"code","6968c3bb":"code","4adbe004":"code","8704605b":"code","17acf6f2":"code","92e820a5":"code","1b734f84":"code","ff14f5a4":"code","ae1dc755":"code","3a0ce2e8":"code","e27b73bf":"code","a32e4fe4":"code","8f21d596":"code","af0f8332":"code","fc11e8ab":"code","7ecd2e9b":"code","a6d34b75":"code","015e1154":"code","67aa6365":"code","cc56b4c9":"code","3bd4ea7b":"code","e246c0d6":"code","6a3cef29":"code","edfa755f":"code","f7979f6f":"code","a8e3e2e0":"code","39f1c5da":"code","9b5569d1":"code","e9044fa6":"code","4ab0df99":"code","81afa407":"code","0ced633f":"code","da6219e4":"markdown","a4be3fee":"markdown","c7099b88":"markdown","8f39a54c":"markdown","e8ca8b4c":"markdown","3cc82ba4":"markdown","f40782d0":"markdown","abd432c1":"markdown"},"source":{"b489c378":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","cd575dae":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv')","15e67d8f":"def check(df):\n    col_list = df.columns.values\n    rows = []\n    for col in col_list:\n        tmp = (col,\n              train[col].dtype,\n              train[col].isnull().sum(),\n              train[col].count(),\n              train[col].nunique(),\n              train[col].unique())\n        rows.append(tmp)\n    df = pd.DataFrame(rows) \n    df.columns = ['feature','dtype','nan','count','nunique','unique']\n    return df\n\ncheck(train)","3e4f0d69":"def check(df):\n    col_list = df.columns.values\n    rows = []\n    for col in col_list:\n        tmp = (col,\n              test[col].dtype,\n              test[col].isnull().sum(),\n              test[col].count(),\n              test[col].nunique(),\n              test[col].unique())\n        rows.append(tmp)\n    df = pd.DataFrame(rows) \n    df.columns = ['feature','dtype','nan','count','nunique','unique']\n    return df\n\ncheck(test)\n","79183625":"# GDP\ngdp = pd.read_csv('\/kaggle\/input\/gdp-data-2015-2019finnorswecsv\/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\ngdp.set_index('year', inplace=True)\ngdp","8f2f4548":"# DateTime\nfrom datetime import datetime, date, time\nimport holidays\nimport dateutil.easter as easter","596c17df":"# FI\nprint('**Finland**')\n#fin_holidays = holidays.Finland()\n#for ptr in holidays.Finland(years = 2019).items():\n    #print(ptr)\nfestivities1 = pd.read_csv(\"\/kaggle\/input\/public-holidays-of-nordic-countries-tps-jan-22\/Finlandholidays15_18.csv\")                     \nfestivities1[:60]","7aa56702":"# NO\nprint('**Norway**')\n#nor_holidays = holidays.Norway()\n#for ptr in holidays.Norway(years = 2019).items():\n    #print(ptr)\n    \nfestivities2 = pd.read_csv(\"\/kaggle\/input\/public-holidays-of-nordic-countries-tps-jan-22\/Norwayholidays15_18.csv\")                       \nfestivities2[:48] ","c3a0f34e":"# SE\nprint('**Sweden**s\u00f6ndag = Sunday')\n#swe_holidays = holidays.Sweden()\n#for ptr in holidays.Sweden(years = 2019).items():\n    #print(ptr)\n    \nfestivities3 = pd.read_csv(\"\/kaggle\/input\/public-holidays-of-nordic-countries-tps-jan-22\/Swedenholidays15_18.csv\")\nfestivities3[:60]","df6b0a8c":"festivities3[60:65]","3c867160":"# PLOT\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nimport seaborn as sns\n%matplotlib inline\n\nsns.set('notebook','darkgrid','Accent')\n","6968c3bb":"# Convert date to datetime\ntrain.date=pd.to_datetime(train.date)\ntest.date=pd.to_datetime(test.date)","4adbe004":"\naxs = sns.barplot(data = train, x =\"country\" , y =\"num_sold\")\naxs.bar_label(axs.containers[0])\nplt.legend()\nplt.show()","8704605b":"axs = sns.barplot(data = train,  x =\"country\" , y =\"num_sold\" , hue =\"store\")\naxs.bar_label(axs.containers[0])\naxs.bar_label(axs.containers[1])\nplt.legend()\nplt.show()","17acf6f2":"axs = sns.barplot(data = train, x =\"store\", y =\"num_sold\", hue =\"product\")\naxs.bar_label(axs.containers[0])\naxs.bar_label(axs.containers[1])\naxs.bar_label(axs.containers[2])\nplt.legend()\nplt.show()","92e820a5":"plt.figure(figsize=(12, 8))\nsns.lineplot(data = gdp,)\nplt.title('GDP')\n\nplt.legend()\nplt.show()","1b734f84":"plt.rc(\"figure\", autolayout=True, figsize=(24, 10))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,)\n\nsns.set('notebook','whitegrid','Accent',font_scale = 1.5)","ff14f5a4":"# Num_sold \nstore = train.groupby(['date','store']).agg(num_sold = ('num_sold','sum'))\nsns.lineplot(data = store, x ='date', y ='num_sold', hue ='store')\nplt.title('Num_sold')\n\nplt.legend()\nplt.show()","ae1dc755":"# country\nfig, axes = plt.subplots(2, 1, figsize = (24,18))\n\nKM = train[train.store =='KaggleMart']\nKR = train[train.store =='KaggleRama']\n\ncsm = KM.groupby(['date','country']).agg(num_sold = ('num_sold','sum'))\ncsr = KR.groupby(['date','country']).agg(num_sold = ('num_sold','sum'))\n\nax1 = sns.lineplot(ax = axes[0], data = csm, x ='date', y ='num_sold', hue ='country')\nax2 = sns.lineplot(ax = axes[1], data =csr, x ='date', y ='num_sold', hue ='country')\n\nax1.title.set_text('KaggleMart')\nax2.title.set_text('KaggleRama')\n\nplt.legend()\nplt.show()","3a0ce2e8":"# product \nfig, axes = plt.subplots(6, 1, figsize = (24,52))\n\n# Finland\nf1 = pd.DataFrame(train[(train[\"country\"] == \"Finland\") & (train[\"store\"] == \"KaggleMart\")])\nax1 = sns.lineplot(ax = axes[0], data = f1 , x =\"date\", y =\"num_sold\", hue =\"product\")\nf2 = pd.DataFrame(train[(train[\"country\"] == \"Finland\") & (train[\"store\"] == \"KaggleRama\")])\nax2 = sns.lineplot(ax = axes[1], data = f2 , x =\"date\", y =\"num_sold\", hue =\"product\")\n\n# Norway\nn1 = pd.DataFrame(train[(train[\"country\"] == \"Norway\") & (train[\"store\"] == \"KaggleMart\")])\nax3 = sns.lineplot(ax = axes[2], data = n1, x =\"date\", y =\"num_sold\", hue =\"product\")\nn2 = pd.DataFrame(train[(train[\"country\"] == \"Norway\") & (train[\"store\"] == \"KaggleRama\")])\nax4 = sns.lineplot(ax = axes[3], data = n2, x =\"date\", y =\"num_sold\", hue =\"product\")\n\n# Sweden\ns1 = pd.DataFrame(train[(train[\"country\"] == \"Sweden\") & (train[\"store\"] == \"KaggleMart\")])\nax5 = sns.lineplot(ax = axes[4], data = s1, x =\"date\", y =\"num_sold\", hue =\"product\")\ns2 = pd.DataFrame(train[(train[\"country\"] == \"Sweden\") & (train[\"store\"] == \"KaggleRama\")])\nax6 = sns.lineplot(ax = axes[5], data = s2, x =\"date\", y =\"num_sold\", hue =\"product\")\n\nax1.title.set_text('Finland KaggleMart')\nax2.title.set_text('Finland KaggleRama')\nax3.title.set_text('Norway KaggleMart')\nax4.title.set_text('Norway KaggleRama')\nax5.title.set_text('Sweden KaggleMart')\nax6.title.set_text('Sweden KaggleRama')\n\nplt.legend()\nplt.show()","e27b73bf":"def process_time(df):\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['week'] = df['date'].dt.isocalendar().week\n    df['week'][df['week']>52] = 52\n    df['day'] = df['date'].dt.day\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['dayofyear'] = df['date'].dt.dayofyear\n    return df\n\ntrain = process_time(train)\ntest = process_time(test)","a32e4fe4":"sns.set('notebook','darkgrid',font_scale = 1.5)\n\nfor product in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n    fig = plt.figure(figsize=(24, 14), dpi=100)\n    fig.subplots_adjust(hspace=0.25)\n    for i, store in enumerate(['KaggleMart', 'KaggleRama']):\n        for j, country in enumerate(['Finland', 'Norway', 'Sweden']):\n            ax = fig.add_subplot(2, 3, (i*3+j+1))\n            selection = (train['country']==country)&(train['store']==store)&(train['product']==product)\n            selected = train[selection]\n            for year in [2015, 2016, 2017, 2018]:\n                selected[selected.year==year].set_index('date').groupby('month')['num_sold'].mean().plot(ax=ax, label=year)\n            ax.set_title(f\"{product} | {country}:{store}\")\n            ax.legend()\n    plt.show()","8f21d596":"for product in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n    print(f\"\\n--- {product} ---\\n\")\n    fig = plt.figure(figsize=(24, 14), dpi=100)\n    fig.subplots_adjust(hspace=0.25)\n    for i, store in enumerate(['KaggleMart', 'KaggleRama']):\n        for j, country in enumerate(['Finland', 'Norway', 'Sweden']):\n            ax = fig.add_subplot(2, 3, (i*3+j+1))\n            selection = (train['country']==country)&(train['store']==store)&(train['product']==product)\n            selected = train[selection]\n            for year in [2015, 2016, 2017, 2018]:\n                selected[selected.year==year].set_index('date').groupby('dayofweek')['num_sold'].sum().plot(ax=ax, label=year)\n            ax.set_title(f\"{country}:{store}\")\n            ax.legend()\n    plt.show()","af0f8332":"import math\nimport statistics\nimport pickle\nimport gc\n\nfrom itertools import combinations\nimport itertools\n\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nfrom matplotlib.lines import Line2D\nfrom matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import GroupKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, InputLayer, Add\n","fc11e8ab":"# Plot training history\ndef plot_history(history, *, n_epochs = None, plot_lr = False, plot_acc = True, title = None, bottom = None, top = None):\n    \"\"\"Plot (the last unique n_epochs epochs of) the training history\"\"\"\n    plt.figure(figsize=(15, 8))\n    from_epoch = 0 if n_epochs is None else len(history['loss']) - n_epochs\n    \n    # Plot training and validation losses\n    plt.plot(np.arange(from_epoch, len(history['loss'])), history['loss'][from_epoch:], label ='Training loss')\n    try:\n        plt.plot(np.arange(from_epoch, len(history['loss'])), history['val_loss'][from_epoch:], label ='Validation loss')\n        best_epoch = np.argmin(np.array(history['val_loss']))\n        best_val_loss = history['val_loss'][best_epoch]\n        if best_epoch >= from_epoch:\n            plt.scatter([best_epoch], [best_val_loss], c ='r', label = f'Best val_loss = {best_val_loss:.5f}')\n        if best_epoch > 0:\n            almost_epoch = np.argmin(np.array(history['val_loss'])[:best_epoch])\n            almost_val_loss = history['val_loss'][almost_epoch]\n            if almost_epoch >= from_epoch:\n                plt.scatter([almost_epoch], [almost_val_loss], c ='orange', label ='Second best val_loss')\n    except KeyError:\n        pass\n    if bottom is not None: plt.ylim(bottom = bottom)\n    if top is not None: plt.ylim(top = top)\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer = True))\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='lower left')\n    if title is not None: plt.title(title)\n        \n    # Plot learning rate\n    if plot_lr and 'lr' in history:\n        ax2 = plt.gca().twinx()\n        ax2.plot(np.arange(from_epoch, len(history['lr'])), np.array(history['lr'][from_epoch:]), color ='g', label ='Learning rate')\n        ax2.set_ylabel('Learning rate')\n        ax2.legend(loc='upper right')\n        \n    plt.show()","7ecd2e9b":"def smape_loss(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return tf.abs(y_true - y_pred) \/ (y_true + tf.abs(y_pred)) * 200","a6d34b75":"train_d = train.copy()\ntest_d = test.copy()\n\nfor df in [train_d, test_d]:\n    df['date'] = pd.to_datetime(df.date)","015e1154":"# Feature engineering\ndef feature_e(df):\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp.loc[row.date.year, country]\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis = 1)),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    dayofyear = df.date.dt.dayofyear\n    \n    for k in range(1, 3):\n        new_df[f'sin{k}'] = np.sin(dayofyear \/ 365 * 2 * math.pi * k)\n        new_df[f'cos{k}'] = np.cos(dayofyear \/ 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Hat']\n        \n        \n    # End and new year\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) &\n                                      (df.country == 'Norway')\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & \n                                      (df.country == 'Finland')\n                                      for d in range(1, 14)}),\n                        pd.DataFrame({f\"jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) &\n                                      (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & \n                                      (df.country == 'Sweden')\n                                      for d in range(1, 15)})], axis=1)    \n     \n    # valentain's day & Mother's day(Norway)\n    # new_df = pd.concat([new_df,\n                       # pd.DataFrame({f\"feb{d}\":\n                                      #(df.date.dt.month == 2) & (df.date.dt.day == d) \n                                      #for d in list(range(1, 15))})],axis=1)\n                \n    #  May( mother's day etc.)  \n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\": \n                                     (df.date.dt.month == 5) & (df.date.dt.day == d)\n                                      for d in list(range(1, 10))}),\n    \n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(18, 28))})], axis=1)\n                                     \n    \n    \n    # June and July (mid_summer)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"june{d}\":\n                                     (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 14))}),], axis=1)\n    \n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 6))})], axis=1)\n    \n    \n     # First Sunday of November( second sunday: father's day)\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})], axis=1)\n    \n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 14))})], axis=1)\n             \n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})],axis=1)\n        \n    return new_df.astype(np.float32)","67aa6365":"train = feature_e(train_d)\ntrain['date'] = train_d.date\ntrain['num_sold'] = train_d.num_sold.astype(np.float32)\n\ntest = feature_e(test_d)\n\nfeatures = list(test.columns)\nprint(list(features))","cc56b4c9":"train.head(3)","3bd4ea7b":"EPOCHS = 1000 # increase the number of epochs if the training curve indicates that a better result is possible\nEPOCHS_COSINEDECAY = 120\nVERBOSE = 0 \nRUNS = 1 \nDIAGRAMS = True\nUSE_PLATEAU = True\nINFERENCE = False","e246c0d6":"wd_features = [f for f in features if f.startswith('wd')]\nother_features = [f for f in features if f not in wd_features]","6a3cef29":"def jan_model():\n    \"\"\"Linear model with flexible regularization\n    \n    The model is to be used with a log-transformed target.\n    \"\"\"\n    wd = Input(shape = (len(wd_features), ))\n    other = Input(shape = (len(other_features), ))\n    wd_contribution = Dense(1, use_bias = False)(wd) # no regularization\n    other_contribution = Dense(1, kernel_regularizer = tf.keras.regularizers.l2(1e-10),\n                               use_bias = True,\n                               bias_initializer = tf.keras.initializers.Constant(value = 5.7))(other)\n    output = Add()([wd_contribution, other_contribution])\n    model = Model([wd, other], output)\n    return model","edfa755f":"def fit_model(X_train, X_valid = None):\n    \"\"\"Scale the data, fit a model, plot the training history and validate the model\"\"\"\n\n    # Preprocess the data (select columns and scale)\n    preproc = StandardScaler()\n    X_train_f = pd.DataFrame(preproc.fit_transform(X_train[features]), columns = features, index = X_train.index)\n    y_train = X_train.num_sold.values.reshape(-1, 1)\n\n    if X_valid is not None:\n        # Preprocess the validation data\n        X_valid_f = pd.DataFrame(preproc.transform(X_valid[features]), columns = features, index = X_valid.index)\n        y_valid = X_valid.num_sold.values.reshape(-1, 1)\n        validation_data = ([X_valid_f[wd_features], X_valid_f[other_features]], np.log(y_valid))\n    else:\n        validation_data = None\n        \n    # Define the learning rate schedule and EarlyStopping\n    if USE_PLATEAU and X_valid is not None:\n        epochs = EPOCHS\n        lr = ReduceLROnPlateau(monitor =\"val_loss\", factor = 0.75, \n                               patience = 4, verbose = VERBOSE)\n        es = EarlyStopping(monitor =\"val_loss\",\n                           patience = 25, \n                           verbose = 1,\n                           mode =\"min\", \n                           restore_best_weights = True)\n        callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n\n    else:\n        epochs = EPOCHS_COSINEDECAY\n        lr_start = 0.01\n        lr_end = 0.00001\n        def cosine_decay(epoch):\n            if epochs > 1:\n                w = (1 + math.cos(epoch \/ (epochs - 1) * math.pi)) \/ 2\n            else:\n                w = 1\n            return w * lr_start + (1 - w) * lr_end\n        \n        lr = LearningRateScheduler(cosine_decay, verbose = 0)\n        callbacks = [lr, tf.keras.callbacks.TerminateOnNaN()]\n\n    # Construct and compile the model\n    model = jan_model()\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01), loss ='mse')\n    \n     # Train the model\n    history = model.fit([X_train_f[wd_features], X_train_f[other_features], ], np.log(y_train), \n                        validation_data = validation_data, \n                        epochs = epochs,\n                        verbose = VERBOSE,\n                        batch_size = 512,\n                        shuffle = True,\n                        callbacks = callbacks)\n\n    history_list.append(history.history)\n    callbacks, es, lr, history = None, None, None, None\n    \n    if X_valid is not None:\n        # Inference for validation\n        y_valid_pred = np.exp(model.predict([X_valid_f[wd_features], X_valid_f[other_features]]))\n        oof[run][valid_idx] = y_valid_pred\n        \n        # Evaluation: Execution time and SMAPE\n        smape = np.mean(smape_loss(y_valid, y_valid_pred))\n        score.append(smape)\n        \n        if DIAGRAMS and fold == 0 and run == 0:\n         # Plot training history\n            plot_history(history_list[-1], title=f\"Validation SMAPE = {smape:.5f}\", plot_lr = True)\n\n            # Plot y_true vs. y_pred\n            plt.figure(figsize = (10, 10))\n            plt.scatter(y_valid, y_valid_pred, s=1, color='r')\n            plt.plot([plt.xlim()[0], plt.xlim()[1]], [plt.xlim()[0], plt.xlim()[1]], '--', color = 'k')\n            plt.gca().set_aspect('equal')\n            plt.xlabel('y_true')\n            plt.ylabel('y_pred')\n            plt.title('OOF Predictions')\n            plt.show()\n\n    return preproc, model","f7979f6f":"np.random.seed(2022) # 42 change the seed \n\nhistory_list, score, test_pred = [], [], []\noof = [np.full((len(train), 1), -1.0, dtype='float32') for run in range(RUNS)]\n\nfor run in range(RUNS):\n    preproc, model = None, None\n    kf = GroupKFold(n_splits = 4)\n    \n    for fold, (train_idx, valid_idx) in enumerate(kf.split(train, groups = train.date.dt.year)):\n        X_train = train.iloc[train_idx]\n        X_valid = train.iloc[valid_idx]\n        print(f\"Fold {run}.{fold}\")\n        \n        preproc, model = fit_model(X_train, X_valid)\n        if INFERENCE:\n            test_f = pd.DataFrame(preproc.transform(test[features]), columns = features, index = test.index)\n            test_pred.append(np.exp(model.predict([test_f[wd_features], test_f[other_features]])))\n\n            ","a8e3e2e0":"            \nprint(f\"Average SMAPE: {sum(score) \/ len(score):.5f}\") # Average over all runs and folds\n\nwith open('oof.pickle', 'wb') as handle: pickle.dump(oof, handle) # for further analysis\n    \nif RUNS > 1:\n    y_valid = train.num_sold\n    print(f\"Ensemble SMAPE: {np.mean(smape_loss(y_valid, sum(oof).ravel() \/ len(oof))):.5f}\")","39f1c5da":"# Retrain the network on the full training data several times\nRETRAIN_RUNS = 20\n\nif RETRAIN_RUNS > 0:\n   \n    test_pred = []\n    for run in range(RETRAIN_RUNS):\n        preproc, model = None, None\n        print(f\"Retraining {run}\")\n        \n        preproc, model = fit_model(train)\n        print(f\"Loss:            {history_list[-1]['loss'][-1]:.6f}\")\n        \n        test_f = pd.DataFrame(preproc.transform(test[features]), columns = features, index = test.index)\n        test_pred.append(np.exp(model.predict([test_f[wd_features], test_f[other_features]])))\n","9b5569d1":"from math import ceil, floor, sqrt\n# from https:\/\/www.kaggle.com\/fergusfindley\/ensembling-and-rounding-techniques-comparison\ndef geometric_round(arr):\n    result_array = arr\n    result_array = np.where(result_array < np.sqrt(np.floor(arr)*np.ceil(arr)), np.floor(arr), result_array)\n    result_array = np.where(result_array >= np.sqrt(np.floor(arr)*np.ceil(arr)), np.ceil(arr), result_array)\n\n    return result_array","e9044fa6":"# Create the submission file\nsub = test_d[['row_id']].copy()\nsub['num_sold'] = sum(test_pred) \/ len(test_pred)\n    \nsub['num_sold'] = geometric_round( sub['num_sold']).astype(int) \nsub.to_csv('submission.csv', index = False)\nsub","4ab0df99":"# Plot the distribution of the test predictions\n\nplt.figure(figsize = (16, 8))\nplt.hist(train['num_sold'], bins = np.linspace(0, 3000, 201), density = True, label ='Training')\nplt.hist(sub['num_sold'], bins = np.linspace(0, 3000, 201), density = True, rwidth = 0.5, label= 'Test predictions')\nplt.xlabel('num_sold')\nplt.ylabel('Frequency')\nplt.title(\"the distribution of the test predictions\")\nplt.legend()\nplt.show()\n","81afa407":"def plot_five_years(feature_e, S,P,C, series ):\n\n    demo = pd.DataFrame({'row_id': 0,\n                            'date': pd.date_range('2015-01-01', '2019-12-31', freq='D'),\n                            'country': C,\n                            'store': S,\n                            'product': P})\n    demo.set_index('date', inplace=True, drop=False)\n    demo = feature_e(demo)\n    demo_f = pd.DataFrame(preproc.transform(demo[features]), columns = features, index = demo.index)\n    demo['num_sold'] = np.exp(model.predict([demo_f[wd_features], demo_f[other_features]]))\n    \n    plt.figure(figsize=(20, 8))\n    plt.plot(np.arange(len(demo)), demo.num_sold, label ='prediction')\n    train_subset = train[(train_d.country == C) & (train_d.store == S) & (train_d['product'] == P)]\n    plt.scatter(np.arange(len(train_subset)), train_subset.num_sold, label ='true', alpha = 0.5, color ='red', s = 3)\n    \n    plot_index = test_d[(test_d.store == S) & (test_d.country == C) & (test_d['product'] == P)].index\n    pred_subset = series[series.row_id.isin(plot_index)].reset_index(drop = True)\n   \n    \n    n1 = len(train_subset['num_sold'])\n    n2 = len(pred_subset['num_sold'])\n    \n    plt.plot(np.arange(n1,n1 + n2),pred_subset['num_sold'], label ='Predictions')\n\n    plt.xlabel('Days since 2015-01-01')\n    plt.ylabel('num_sold')\n    \n    plt.legend()\n    plt.title('Predictions and true num_sold for five years by ' + S +' : '+ P + ' : ' + C)\n    plt.show()\n","0ced633f":"trend = pd.DataFrame({'row_id': test_d.index, 'num_sold': sub['num_sold']})\n\nfor S in ['KaggleMart','KaggleRama']:\n    print(f\"\\n--- {S} ---\\n\")\n    for P in ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']:\n        for C in ['Finland', 'Norway', 'Sweden']:\n            plot_five_years(feature_e, S, P, C, series = trend)\n            ","da6219e4":"---------------\n# Occasional events (FI : Finland, NO : Norway, SE : Sweden)\n \n**New year\ud83c\udf89(1\/1)**\n\n**Valentin's Day\ud83d\udc98(2\/14)**\n> *  FI: Friend's Day\n> *  NO: February 14 the same manner as in the Uk\n> *  SE: \"All Hearts'Day\" they are planning to buy presents for somone\n\n**Easter\ud83d\udc23(2015: 4\/5, 2016: 3\/27, 2017: 4\/16, 2018: 4\/1, 2019:4\/21 )**\n> * First Sunday after the first full moon on or after 21 March \n> * Public Holidays  Good Friday, Easter Sunday and Easter Monday :Easter eggs, Easter Bunny,Easter Busket\n\n**Mother's Day\ud83d\udc90**\n> * 2015 FI: 5\/10(Sun), NO: 2\/8(Sun), SE: 5\/31(Sun)\n> * 2016 FI: 5\/8(Sun), NO: 2\/14(Sun), SE: 5\/29(Sun)\n> * 2017 FI: 5\/14(Sun), NO: 2\/12(Sun), SE: 5\/28(Sun)\n> * 2018 FI: 5\/13(Sun), NO: 2\/11(Sun), SE: 5\/27(Sun)\n> * 2019 FI: 5\/10(Sun), NO: 2\/10(Sun), SE: 5\/31(Sun)\n> * FI: The secopmd sunday in May, pick flowers\n> * NO: The second Sunday in februrary.family day, children make card and gifts\n> * SE: The last sunday in May, pick flowers\n\n**Midsummer's Days\ud83c\udf1e**\n> * 2015 FI: 6\/20(Sat), NO: 6\/24(Wed), SE: 6\/20(Sat)\n> * 2016 FI: 6\/25(Sat), NO: 6\/24(Fri), SE: 6\/25(Sat)\n> * 2017 FI: 6\/24(Sat), NO: 6\/24(Sat), SE: 6\/24(Sat)\n> * 2018 FI: 6\/23(Sat), NO: 6\/24(Sun), SE: 6\/23(Sat)\n> * 2019 FI: 6\/22(Sat), NO: 6\/24(Mon), SE: 6\/22(Sat)\n\n**Father's Day\ud83d\ude0e(2015: 11\/8, 2016: 11\/13, 2017: 11\/12, 2018: 11\/11, 2019: 11\/10 )**\n> * The second sunday in November\n\n**Halloween\ud83c\udf83(10\/31)**\n\n**Independence Day\ud83d\udcc5(FI:: 12\/6, NO:: 6\/7, SE:: 6\/6)**\n\n**Christmas\ud83c\udf84(12\/25)**\n\n**Election year\ud83d\udcf0(SE:: 2018: 9\/9)**\n","a4be3fee":"------\n# Holidays(2019)","c7099b88":"# Submission","8f39a54c":"# TPS_Jan_2022(Time series)_EDA & Keras(SMAPE)\ud83d\udcc8\n\n**Reference: Kaggle's Time series course**\n* > I Acknowledge the notebook of AmbrosM, Fergus Findley,Luca Massaron, Samuel Cortinhas, Ruma and Rayan Holbrook.\n* > It was very helpful and useful. I am very grateful for all of you.I have learned a lot fron them!.\n","e8ca8b4c":"* Kaggle hat > Kaggle Mug > Kaggle Sticker\n* Kaggle Rama > Kaggle Mart\n* Norway > Sweden > Finland\n* These Graph shows the waves pattern.\n* December(Holiday season) > April(Easter) > other (The end of October : Halloween,November : Father's day etc.)\n* Weekend > Friday > weekday\n\n----\n\n#  Feature engineering and Modeling\u2699","3cc82ba4":"------------\n# \ud83d\udccaVisualizations\ud83d\udcc8","f40782d0":"**Thank you for reading!**","abd432c1":"**SMAPE(Symmetric mean absolute percentage error) : an accuracy measure based on percentage errors.**"}}