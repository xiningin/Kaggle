{"cell_type":{"3b915feb":"code","69caf793":"code","751db6f6":"code","48e47349":"code","f032c7cf":"code","81aeb8aa":"code","79a5df54":"code","fef3498c":"code","3aa58082":"code","92a8609d":"code","da07bf52":"code","5a7dd784":"code","899fe4f6":"code","5bcf7cea":"code","9980cffa":"code","84a0862c":"code","2707e18c":"code","bccd4322":"code","9514546b":"code","a471e07e":"code","871bebb2":"code","709c8426":"code","ef63ab78":"code","e9ffe389":"code","4d4f2f74":"code","11b59d63":"code","98a1219f":"code","22922f7d":"code","cf2a6fd5":"code","10eb6ba1":"code","9c58caf7":"code","8e411f6d":"code","fbc6b19b":"code","b4cd445f":"code","77ae06f5":"code","6dbc3d10":"code","f95ff908":"code","a62ac931":"code","4dded9b5":"code","de85b69c":"code","9fd5a904":"code","4ba2a38e":"code","be7a4988":"code","e360a480":"code","105e6fe8":"code","da911beb":"code","9698e884":"code","402575fa":"markdown","822b0124":"markdown","8c71d610":"markdown","2026230b":"markdown","f0b6e83f":"markdown","a79a1d78":"markdown","d67cb58f":"markdown","201bffd3":"markdown","6a8259af":"markdown","62da7108":"markdown","2a34c920":"markdown"},"source":{"3b915feb":"import warnings\nwarnings.filterwarnings('ignore')","69caf793":"import os\nprint(os.listdir(\"..\/input\"))","751db6f6":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom collections import Counter","48e47349":"data_train = pd.read_csv('..\/input\/train.csv')\ndata_train.shape","f032c7cf":"data_test = pd.read_csv('..\/input\/test.csv')\ndata_test.shape","81aeb8aa":"x_train = data_train.iloc[:, 1:].values\nprint(\"Number of images in training dataset:\", x_train.shape[0])\nprint(\"Number of pixels in each image in training dataset:\", x_train.shape[1])","79a5df54":"x_test = data_test.iloc[:, :].values\nprint(\"Number of images in test dataset:\", x_test.shape[0])\nprint(\"Number of pixels in each image in test dataset:\", x_test.shape[1])","fef3498c":"x_train = x_train.reshape(42000, 28, 28, 1)\nx_train.shape","3aa58082":"x_test = x_test.reshape(28000, 28, 28, 1)\nx_test.shape","92a8609d":"x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2), (0, 0)), 'constant')\nx_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2), (0, 0)), 'constant')","da07bf52":"x_train.shape, x_test.shape","5a7dd784":"x_train = x_train.reshape(42000, 32 * 32)\nx_test = x_test.reshape(28000, 32 * 32)\nx_train.shape, x_test.shape","899fe4f6":"y_train = data_train.iloc[:, :1].values.flatten()\nprint('Shape of Training Labels:', y_train.shape)","5bcf7cea":"def one_hot_encode(y, n):\n    return np.eye(n)[y]\n\ny_encoded_train = one_hot_encode(y_train, 10)\nprint('Shape of y_train after encoding:', y_encoded_train.shape)","9980cffa":"def next_batch(batch_size, data, labels):\n    idx = np.arange(0, len(data))\n    np.random.shuffle(idx)\n    idx = idx[: batch_size]\n    data_shuffle = [data[i] for i in idx]\n    labels_shuffle = [labels[i] for i in idx]\n    return np.asarray(data_shuffle), np.asarray(labels_shuffle)","84a0862c":"def display_images(data, title, display_label = True):\n    x, y = data\n    fig, axes = plt.subplots(3, 3)\n    fig.subplots_adjust(hspace = 0.5, wspace = 0.5)\n    fig.suptitle(title, fontsize = 18)\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(x[i].reshape(32, 32), cmap = 'binary')\n        if display_label:\n            ax.set_xlabel(y[i])\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","2707e18c":"def display_filters(x, rows, cols, figsize, title, display_label = True):\n    fig, axes = plt.subplots(rows, cols, figsize = figsize)\n    fig.subplots_adjust(hspace = 0.5, wspace = 0.5)\n    fig.suptitle(title, fontsize = 18)\n    c = 1\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(x[i].reshape(x[i].shape[0], x[i].shape[1]), cmap = 'binary')\n        if display_label:\n            ax.set_xlabel(\"Filter \" + str(c))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        c += 1\n    plt.show()","bccd4322":"display_images(next_batch(9, x_train, y_train), 'Training Images')","9514546b":"display_images(next_batch(9, x_test, [None] * len(x_test)), 'Test Images', display_label = False)","a471e07e":"z = dict(Counter(list(y_train)))\nlabels = z.keys()\nfrequencies = [z[i] for i in labels]\nlabels = [str(i) for i in z.keys()]\n\nplt.figure(figsize = (14, 7))\nplt.bar(labels, frequencies)\nplt.title('Frequency Distribution of Alphabets in Training Set', fontsize = 20)\nplt.show()","871bebb2":"# Training Parameters\nlearning_rate = 0.001\nepochs = 10000\nbatch_size = 128\ndisplay_step = 500","709c8426":"# Network Hyperparameters\nn_input = 1024\nn_classes = 10","ef63ab78":"# Placeholders\nX = tf.placeholder(tf.float32, shape = [None, n_input]) # Placeholder for Images\nY = tf.placeholder(tf.float32, shape = [None, n_classes]) # Placeholder for Labels","e9ffe389":"weights = {\n    # Convolutional Layer 1: 5x5 filters, 1 input channels, 6 output channels\n    'w1' : tf.Variable(tf.random_normal([5, 5, 1, 6])), # Image Size becomes 14x14x6\n    # Convolutional Layer 2: 5x5 filters, 6 input channels, 16 output channels\n    'w2' : tf.Variable(tf.random_normal([5, 5, 6, 16])), # Image Size becomes 5x5x16\n    # Fully Connected Layer 1: 5*5*16 = 400 input channels, 120 output channels\n    'w3' : tf.Variable(tf.random_normal([400, 120])),\n    # Fully Connected Layer 2: 120 input channels, 84 output channels\n    'w4' : tf.Variable(tf.random_normal([120, 84])),\n    # Fully Connected Layer 3: 84 input channels, 10 (number of classes) output channels\n    'w5' : tf.Variable(tf.random_normal([84, 10]))\n}","4d4f2f74":"biases = {\n    'b1' : tf.Variable(tf.random_normal([6])),\n    'b2' : tf.Variable(tf.random_normal([16])),\n    'b3' : tf.Variable(tf.random_normal([120])),\n    'b4' : tf.Variable(tf.random_normal([84])),\n    'b5' : tf.Variable(tf.random_normal([10]))\n}","11b59d63":"# Wrapper function for creating a Convolutional Layer\ndef conv2d(x, W, b, strides = 1, padding = 'VALID'):\n    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding = padding)\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)","98a1219f":"# Wrapper function for creating a Pooling Layer\ndef maxpool2d(x, k=2, padding = 'VALID'):\n    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = padding)","22922f7d":"def lenet(x, weight, bias):\n    x = tf.reshape(x, shape = [-1, 32, 32, 1])\n    \n    conv1 = conv2d(x, weight['w1'], bias['b1']) # Convolutional Layer 1\n    conv1 = maxpool2d(conv1) # Pooling Layer 1\n    \n    conv2 = conv2d(conv1, weight['w2'], bias['b2']) # Convolutional Layer 2\n    conv2 = maxpool2d(conv2) # Pooling Layer 2\n    \n    # Fully Connected Layer 1\n    # Reshaping output of previous convolutional layer to fit the fully connected layer\n    fc1 = tf.reshape(conv2, [-1, weights['w3'].get_shape().as_list()[0]])\n    fc1 = tf.add(tf.matmul(fc1, weight['w3']), bias['b3']) # Linear Function\n    fc1 = tf.nn.relu(fc1) # Activation Function\n    \n    # Fully Connected Layer 2\n    fc2 = tf.add(tf.matmul(fc1, weight['w4']), bias['b4']) # Linear Function\n    fc2 = tf.nn.relu(fc2) # Activation Function\n    \n    out = tf.add(tf.matmul(fc2, weight['w5']), bias['b5']) # Output Layer\n    \n    return out","cf2a6fd5":"logits = lenet(X, weights, biases)","10eb6ba1":"loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y))\noptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\ntrain_op = optimizer.minimize(loss_op)","9c58caf7":"correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","8e411f6d":"init = tf.global_variables_initializer()","fbc6b19b":"with tf.Session() as sess:\n    # Running Initializer\n    sess.run(init)\n    cost_hist, acc_hist = [], []\n    for epoch in range(1, epochs + 1):\n        _x, _y = next_batch(batch_size, x_train, y_encoded_train)\n        # Running Optimizer\n        sess.run(train_op, feed_dict = { X : _x, Y : _y })\n        if epoch % display_step == 0:\n            # Calculating Loss and Accuracy on the current Epoch\n            loss, acc = sess.run([loss_op, accuracy], feed_dict = { X : _x, Y : _y })\n            loss = loss\n            cost_hist.append(loss)\n            acc_hist.append(acc)\n            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy: ' + str(acc * 100) + ' %')\n    W = sess.run(weights)\n    B = sess.run(biases)\n    print('-' * 70)\n    print('\\nOptimization Finished\\n')\n    print('Accuracy on Training Data: ' + str(sess.run(accuracy, feed_dict = { X : x_train, Y : y_encoded_train, }) * 100) + ' %')","b4cd445f":"plt.plot(list(range(len(cost_hist))), cost_hist)\nplt.title(\"Change in cost\")\nplt.show()","77ae06f5":"plt.plot(list(range(len(acc_hist))), acc_hist)\nplt.title(\"Change in accuracy\")\nplt.show()","6dbc3d10":"def convert_layer_to_filters(layer):\n    return layer.reshape(layer.shape[-1] * layer.shape[-2], layer.shape[0], layer.shape[1])","f95ff908":"filters_1 = convert_layer_to_filters(W['w1'])\nfilters_2 = convert_layer_to_filters(W['w2'])","a62ac931":"filters_1.shape, filters_2.shape","4dded9b5":"display_filters(filters_1, 1, 6, (14, 3), 'Filters of Layer 1', display_label = True)","de85b69c":"display_filters(filters_2, 16, 6, (14, 18), 'Filters of Layer 2', display_label = True)","9fd5a904":"# KFold cross validation\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits = 10)\n\ncurrent_fold = 1\ntrain_acc_hist = []\ntest_acc_hist = []\n\nfor train_index, test_index in kf.split(y_encoded_train):\n     \n    KFold_X_train = x_train[list(train_index)]\n    KFold_X_test = x_train[test_index]\n    KFold_Y_train = y_encoded_train[train_index]\n    KFold_Y_test = y_encoded_train[test_index]\n\n    # run the graph\n    with tf.Session() as sess:\n    \n        sess.run(init)\n\n        for epoch in range(1, epochs + 1):\n\n            batch_x, batch_y = next_batch(batch_size, KFold_X_train, KFold_Y_train)\n\n            sess.run(train_op, feed_dict = { X : batch_x, Y : batch_y })\n    \n        train_accuracy = sess.run(accuracy, feed_dict = { X : KFold_X_train, Y :KFold_Y_train }) * 100\n        test_accuracy = sess.run(accuracy, feed_dict = { X : KFold_X_test, Y : KFold_Y_test }) * 100\n        \n        train_acc_hist.append(train_accuracy)\n        test_acc_hist.append(test_accuracy)\n\n        print('\\nFOLD-' + str(current_fold) + '\\n')\n        print('Accuracy on train data \\t:  {0:.2f} %'.format(train_accuracy))\n        print('Accuracy on test data  \\t:  {0:.2f} %'.format(test_accuracy))\n\n    current_fold = current_fold +1\n    \ntrain_cross_val_score = np.mean(train_acc_hist)    \ntest_cross_val_score = np.mean(test_acc_hist)\n\n\nprint('\\n\\nFINAL TRAIN SET K-FOLD CROSS VALIDATION ACCURACY \\t:  {0:.2f}'.format(train_cross_val_score))\nprint('\\nFINAL TEST SET K-FOLD CROSS VALIDATION ACCURACY    \\t:  {0:.2f}'.format(test_cross_val_score))","4ba2a38e":"for key in W.keys():\n    np.save(key, W[key])","be7a4988":"for key in B.keys():\n    np.save(key, B[key])","e360a480":"# Converting numpy ndarrays into tensorflow variables \nfor key in weights.keys():\n    weights[key] = tf.Variable(W[key])\nfor key in biases.keys():\n    biases[key] = tf.Variable(B[key])","105e6fe8":"pred = tf.argmax(lenet(X, weights, biases), 1)","da911beb":"with tf.Session() as sess:\n    \n    for key in weights.keys():\n        sess.run(weights[key].initializer)\n    for key in biases.keys():\n        sess.run(biases[key].initializer)\n    y_pred = sess.run(pred, feed_dict= {X : x_test}) ","9698e884":"display_images(next_batch(9, x_test, y_pred), 'Prediction on Test Images')","402575fa":"## 3. Building the Neural Network (Lenet - 5)","822b0124":"# 5. Predictions","8c71d610":"## Visualization","2026230b":"### Visualizing the Images","f0b6e83f":"## K-Fold Cross Validation\u00b6\n","a79a1d78":"### One Hot Encoding","d67cb58f":"### Converting the images to 32x32\nThe images in the dataset have been given in 28x28 resolution. Since Lenet - 5 Architecture requires 32x32 images, we would convert the given images into 32x32. In order to do so, we would apply extra zero padding on the images.","201bffd3":"## 4. Training the Neural Network","6a8259af":"## 2. Data Preprocessing","62da7108":"## 1. Importing Libraries","2a34c920":"### Visualizing the Labels"}}