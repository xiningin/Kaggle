{"cell_type":{"2e03867b":"code","936218d1":"code","69faf584":"code","086e266c":"code","f6b8a05a":"code","c51bdbee":"code","af4799fa":"code","39a841a5":"code","c6e46873":"code","ae3762cf":"code","5b6bc914":"code","032b29b4":"code","3d02ac66":"code","201437c0":"code","796b7f5e":"code","4a88d640":"code","3774bd29":"code","a0f533ac":"code","a77ebfe0":"code","68d496a6":"code","ff1b2eea":"code","c4d52476":"code","7478455d":"code","03e54211":"code","2d764711":"code","171d9222":"code","b0f10132":"code","a3e8d126":"code","967bd91c":"code","d592cead":"code","23d47ce4":"code","c6ce0440":"code","b0b4a629":"code","4443739f":"code","42bdde5d":"code","9f4b39e1":"code","dbf6d306":"code","4a2d8007":"code","0bbf1493":"code","f405461a":"code","45ecd9fe":"code","7fbd6208":"code","dece1097":"code","cee89793":"code","528401ea":"code","9553ac23":"code","333e56a7":"code","a2ef9e5b":"code","479f2069":"code","b5f8a005":"code","3b27a4c8":"code","e5600b90":"code","927ff1aa":"code","d7b305ff":"code","744fd648":"code","333e0e25":"code","19bdc055":"code","6f729ca0":"code","bbc3ff08":"code","e421ad2b":"code","f6a6335e":"code","89e7f0b7":"code","5703cece":"code","491a2bae":"code","5598f79b":"code","5addb4ed":"code","01dc4b17":"code","91ce872d":"code","e06bf908":"code","81cfeccb":"code","49204a75":"code","354c2346":"code","14cbaaf1":"code","fbb9c17a":"code","8f52a8e0":"code","7b3ede9c":"code","152e6ffe":"code","48b52c42":"code","9020c82f":"code","8e714336":"code","551a91f4":"code","bd2e4e86":"code","0a27cdce":"code","1bccfe27":"code","1f054e9e":"code","47287ff9":"code","06bc6164":"code","f82a7026":"code","09832999":"code","109d70f9":"code","222d50a5":"code","eb376dac":"code","4d927ca7":"code","37c1a438":"code","163086f1":"code","387e2856":"code","a3a7d144":"code","45071eb2":"code","9adb1c5e":"code","6cb54890":"code","4f4e6241":"code","ce221775":"code","9bf09f81":"code","ea7c3132":"code","83efdeaa":"code","d8188430":"code","f698bede":"code","f7b7e67a":"code","e86cdbbd":"code","11fecb22":"code","9daf33df":"code","29bb64ba":"code","b42e6c02":"code","6d305122":"code","5a8b2bd5":"code","6063f61d":"code","9e5b36e2":"code","afd6b71b":"code","30728ef7":"code","a87f5946":"code","923a385c":"code","094c9872":"code","f84876ee":"code","8f10ec5a":"code","fb6cd134":"code","83a92dab":"code","c45bd742":"code","9338e71c":"code","288cea99":"code","cc7d4176":"code","1880084c":"code","900b33d9":"code","401130ac":"code","3af7c541":"code","f6a4db68":"code","042058d3":"code","948efef7":"code","55bd3eca":"code","f6e92d31":"code","ff740e45":"code","06ce182a":"code","eaff3d44":"code","972bfc14":"code","8e0c8973":"code","30365ac5":"code","34c51114":"code","669078c7":"code","d41fd219":"code","d53a3630":"code","7c5fd58f":"code","a575fc1d":"code","4c30576d":"code","941496c2":"code","ab76cd9d":"code","25fb4ddb":"markdown","83c9c026":"markdown","1adf6f4d":"markdown","351b65e3":"markdown","b18f429c":"markdown","60f15288":"markdown","a5e19e60":"markdown","5ada9ac4":"markdown","3ca78621":"markdown","27386f7c":"markdown","1c0f6122":"markdown","785a27aa":"markdown","05117550":"markdown","263945bc":"markdown","1deb3d44":"markdown","d639771d":"markdown","455ebe28":"markdown","1d0b2c3c":"markdown","a3923b6e":"markdown","b04ed238":"markdown","87bb8ceb":"markdown","e3b1af05":"markdown","6c7111c6":"markdown","14206864":"markdown","5f328379":"markdown","e3d4bba3":"markdown","c5a679f8":"markdown","d94ec7e7":"markdown","98d6c489":"markdown","1489bfc6":"markdown","7b366058":"markdown","0285eb5e":"markdown","95dbe34d":"markdown","82b00e83":"markdown","995ae909":"markdown","442e336b":"markdown","04dd6808":"markdown","a7f80f88":"markdown","43e89b57":"markdown","b78ba9b1":"markdown","fb8252c6":"markdown","95d380ac":"markdown","0a9e02a1":"markdown","bd10c228":"markdown","1ea5db06":"markdown","2207b169":"markdown","7f9fb8a2":"markdown","6f6ebddd":"markdown","31cb7eb3":"markdown","e0ae5177":"markdown","82dd0d85":"markdown","7764b4a5":"markdown","9b488e7c":"markdown","aea094c1":"markdown","aaab4884":"markdown","a6bb9f8e":"markdown","d6b4ad71":"markdown"},"source":{"2e03867b":"import dask\nimport dask.dataframe as dd\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = [16,9]\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","936218d1":"dtypes = {\n        'ip'            : 'uint32',\n        'app'           : 'object',\n        'device'        : 'object',\n        'os'            : 'object',\n        'channel'       : 'object',\n        'click_time'    : 'object',\n        'is_attributed' : 'uint8',\n        }","69faf584":"#Sample data - (100000, 8)\n#click_data = pd.read_csv('..\/input\/talkingdata-adtracking-fraud-detection\/train_sample.csv', parse_dates=['click_time'])\n\n#Full data - No idea how large it is, this notebook can not handle its size in RAM\n\n#Read only first limit rows\n#limit = 20_000_000\n\n#Read only these columns - skip attributed_time \nusecols = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']","086e266c":"competition_data = dd.read_csv('..\/input\/talkingdata-adtracking-fraud-detection\/train.csv', \n                               dtype=dtypes,\n                               #nrows=limit, #not supported by `dd.read_csv`\n                               usecols=usecols, \n                               parse_dates=['click_time'])","f6b8a05a":"competition_data.info()","c51bdbee":"competition_data_postitive = competition_data[competition_data.is_attributed == 1] ","af4799fa":"start_time = time.time()\ntype(competition_data_postitive)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","39a841a5":"start_time = time.time()\ncompetition_data_postitive = competition_data_postitive.compute()\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","c6e46873":"print(type(competition_data_postitive), competition_data_postitive.shape)","ae3762cf":"competition_data_postitive.sample(10)","5b6bc914":"competition_data_negative = competition_data[competition_data.is_attributed == 0] ","032b29b4":"competition_data_negative = competition_data_negative.sample(frac=0.0025) #number","3d02ac66":"start_time = time.time()\ncompetition_data_negative = competition_data_negative.compute()\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","201437c0":"competition_data_negative.sample(10)","796b7f5e":"train_competition_data = pd.concat([competition_data_postitive, competition_data_negative])","4a88d640":"train_competition_data.is_attributed.value_counts()","3774bd29":"train_competition_data.info()","a0f533ac":"test_dtypes = {\n        'click_id'      : 'uint32',\n        'ip'            : 'uint32',\n        'app'           : 'object',\n        'device'        : 'object',\n        'os'            : 'object',\n        'channel'       : 'object',\n        'click_time'    : 'object'\n        }","a77ebfe0":"usecols","68d496a6":"competition_test_data = dd.read_csv('..\/input\/talkingdata-adtracking-fraud-detection\/test.csv', \n                               dtype=test_dtypes,\n                               #nrows=limit, #not supported by `dd.read_csv`\n                               #usecols=usecols, #no columns needed to be skipped here\n                               parse_dates=['click_time'])","ff1b2eea":"start_time = time.time()\ncompetition_test_data = competition_test_data.compute()\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","c4d52476":"print(competition_test_data.shape)\ncompetition_test_data.head()","7478455d":"# Add new columns for timestamp features day, hour, minute, and second\nclicks = train_competition_data.copy()\nclicks['day'] = clicks['click_time'].dt.day.astype('uint8')\n# Fill in the rest\nclicks['hour'] = clicks['click_time'].dt.hour.astype('uint8')\nclicks['minute'] = clicks['click_time'].dt.minute.astype('uint8')\nclicks['second'] = clicks['click_time'].dt.second.astype('uint8')","03e54211":"clicks.head()","2d764711":"# Add new columns for timestamp features day, hour, minute, and second\ncompetition_test_data = competition_test_data.copy()\ncompetition_test_data['day'] = competition_test_data['click_time'].dt.day.astype('uint8')\n# Fill in the rest\ncompetition_test_data['hour'] = competition_test_data['click_time'].dt.hour.astype('uint8')\ncompetition_test_data['minute'] = competition_test_data['click_time'].dt.minute.astype('uint8')\ncompetition_test_data['second'] = competition_test_data['click_time'].dt.second.astype('uint8')","171d9222":"competition_test_data.head()","b0f10132":"# Not the best solution to ValueError: y contains previously unseen labels: [0, 1, 2,...\nunknown_value = -1 #Make sure this is int (as other labels) or you will not be able to predict in the end \u26a0\ufe0f\n\nfrom sklearn import preprocessing\n\ncat_features = ['ip', 'app', 'device', 'os', 'channel']\n#cat_features = ['ip']\n\n#encoder = preprocessing.LabelEncoder() - Incorrect, we need a label encoder for each feature\n# Create new columns in clicks using preprocessing.LabelEncoder()\n\nfor feature in cat_features:\n    start_time = time.time()\n    print(feature)\n    \n    #New encoder for each feature\n    encoder = preprocessing.LabelEncoder()\n    \n    #Fit on all possible values of this feature\n    encoder.fit(clicks[feature])\n    \n    #Create LabelEncoder of input to output\n    le_dict = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n    \n    #Encode unseen values to the unknown_value label\n    encoded = clicks[feature].apply(lambda x: le_dict.get(x, unknown_value))\n    clicks[feature+'_labels'] = encoded\n    \n    #Competition submission\n    competition_encoded = competition_test_data[feature].apply(lambda x: le_dict.get(x, unknown_value))\n    #ValueError: y contains previously unseen labels: [0, 2, 3, 4, 5,\n    competition_test_data[feature+'_labels'] = competition_encoded\n    \n    print(\"--- %s seconds ---\" % (time.time() - start_time))    ","a3e8d126":"clicks.head()","967bd91c":"competition_test_data.head(20)","d592cead":"#ip\n#--- 96.38041996955872 seconds ---\ndask_ml_preprocessing = \"\"\"\nstart_time = time.time()\n\n# Not the best solution to ValueError: y contains previously unseen labels: [0, 1, 2,...\nunknown_value = -1 #Make sure this is int (as other labels) or you will not be able to predict in the end \u26a0\ufe0f\n\n#from sklearn import preprocessing\nfrom dask_ml import preprocessing #Dask preprocessing\n\n#cat_features = ['ip', 'app', 'device', 'os', 'channel']\ncat_features = ['ip']\n\n#encoder = preprocessing.LabelEncoder() - Incorrect, we need a label encoder for each feature\n# Create new columns in clicks using preprocessing.LabelEncoder()\n\nfor feature in cat_features:\n    print(feature)\n    \n    #New encoder for each feature\n    encoder = preprocessing.LabelEncoder(use_categorical=False) #Dask Specify use_categorical=False to recover the scikit-learn behavior.\n    \n    #Fit on all possible values of this feature\n    encoder.fit(clicks[feature])\n    \n    #Create LabelEncoder of input to output\n    le_dict = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n    \n    #Encode unseen values to the unknown_value label\n    encoded = clicks[feature].apply(lambda x: le_dict.get(x, unknown_value))\n    clicks[feature+'_labels'] = encoded\n    \n    #Competition submission\n    competition_encoded = competition_test_data[feature].apply(lambda x: le_dict.get(x, unknown_value))\n    #ValueError: y contains previously unseen labels: [0, 2, 3, 4, 5,\n    competition_test_data[feature+'_labels'] = competition_encoded\n    \nprint(\"--- %s seconds ---\" % (time.time() - start_time))    \n\"\"\"","23d47ce4":"train_ip_labels_unknowns = sum(clicks['ip_labels'] == unknown_value)\ntrain_ip_labels_unknowns","c6ce0440":"compet_test_ip_labels_unknowns = sum(competition_test_data['ip_labels'] == unknown_value)\ncompet_test_ip_labels_unknowns","b0b4a629":"my_own_metrics={'clicks': clicks.shape[0], #min(limit, clicks.shape[0]),\n                'competition_test_data':competition_test_data.shape[0],\n                'train ip_labels unknowns': train_ip_labels_unknowns,\n                'compet_test ip_labels unknowns':compet_test_ip_labels_unknowns,\n                'compet_test ip_labels unknowns %': round(100*compet_test_ip_labels_unknowns\/competition_test_data.shape[0],2)}\nmy_own_metrics","4443739f":"clicks.shape","42bdde5d":"competition_test_data.shape","9f4b39e1":"import itertools\n\ncat_features = ['ip', 'app', 'device', 'os', 'channel']\ninteractions = pd.DataFrame(index=clicks.index)\n\n# Iterate through each pair of features, combine them into interaction features\nfor interaction_feature_tuple in itertools.combinations(cat_features,2):\n    #New feature name as concatination of 2 categorical features\n    interaction_feature  = '_'.join(list(interaction_feature_tuple))\n    print(interaction_feature_tuple, interaction_feature)\n    \n    #New interaction as concatination of the values of each combination of cateforical features\n    interactions_values = clicks[interaction_feature_tuple[0]].astype(str) + '_' + clicks[interaction_feature_tuple[1]].astype(str)\n    \n    #New label encoder for each interaction_feature \n    label_enc = preprocessing.LabelEncoder()\n    #interactions = interactions.assign(interaction_feature=label_enc.fit_transform(interactions_values)) ??? uses the string interaction_feature as the column name ???\n    #interactions[interaction_feature] = label_enc.fit_transform(interactions_values)                     #??? index values and how do they relate to the full dataset clicks ???\n\n    #Fit on all possible values of this feature\n    label_enc.fit(interactions_values)\n    #Create LabelEncoder of input to output\n    le_dict = dict(zip(label_enc.classes_, label_enc.transform(label_enc.classes_)))\n    #Encode unseen values to the unknown_value label\n    encoded = interactions_values.apply(lambda x: le_dict.get(x, unknown_value))\n    clicks[interaction_feature] = encoded\n    \n    print('clicks.columns')\n    print(clicks.columns)\n\n    #Competition submission\n    # Apply encoding to the competition test dataset\n    comp_interactions_values = competition_test_data[interaction_feature_tuple[0]].astype(str) + '_' + competition_test_data[interaction_feature_tuple[1]].astype(str)\n    #competition_test_data[interaction_feature] = label_enc.transform(comp_interactions_values)  #??? ValueError: y contains previously unseen labels: '119901_9' ???\n    \n    competition_encoded = comp_interactions_values.apply(lambda x: le_dict.get(x, unknown_value))\n    competition_test_data[interaction_feature] = competition_encoded\n    print('competition_test_data.columns')\n    print(competition_test_data.columns)\n    ","dbf6d306":"clicks.columns","4a2d8007":"competition_test_data.columns","0bbf1493":"def count_past_events_6h(series):\n    new_series = pd.Series(index=series, data=series.index, name=\"count_6_hours\").sort_index()\n    #launched = pd.Series(data =ks.index, index=ks.launched, name=\"count_7_days\").sort_index()\n    #print(new_series.head())\n    count_6_hours = new_series.rolling('6h').count() - 1\n    return count_6_hours","f405461a":"series = clicks[:100]['click_time']\nseries","45ecd9fe":"new_series = pd.Series(index=series, data=series.index, name=\"count_6_hours\").sort_index()\nnew_series","7fbd6208":"new_series.rolling('6h').count() - 1","dece1097":"#clicks['count_past_events_6h'] = \nevents_6h = count_past_events_6h(clicks[:100]['click_time'])\nevents_6h","cee89793":"plt.plot(events_6h);","528401ea":"#events_6h.index = events_6h.values\nevents_6h","9553ac23":"events_6h = events_6h.reindex(clicks[:100].index)\nevents_6h","333e56a7":"#competition_test_data['count_past_events_6h'] = competition_test_data['click_time'].apply(count_past_events_6h)","a2ef9e5b":"def time_diff_since_last_event(series):\n    \"\"\"Returns a series with the time since the last timestamp in seconds.\"\"\"\n    time_since_last_event = series.diff().dt.total_seconds()\n    return time_since_last_event","479f2069":"clicks['time_diff_since_last_event'] = clicks['click_time'].apply(time_diff_since_last_event)","b5f8a005":"competition_test_data['time_diff_since_last_event'] = competition_test_data['click_time'].apply(time_diff_since_last_event)","3b27a4c8":"def previous_attributions(series):\n    \"\"\"Returns a series with the number of times an app has been downloaded.\"\"\"\n    #print(series)\n    #print(series.expanding(min_periods=2).sum())\n    sums = series.expanding(min_periods=2).sum() - series\n    return sums","e5600b90":"clicks['time_diff_since_last_event'] = clicks['click_time'].apply(time_diff_since_last_event)","927ff1aa":"clicks.head()","d7b305ff":"feature_cols = ['day', 'hour', 'minute', 'second', \n                'ip_labels', 'app_labels', 'device_labels',\n                'os_labels', 'channel_labels']\n\nvalid_fraction = 0.1\nclicks_srt = clicks.sort_values('click_time')\nvalid_rows = int(len(clicks_srt) * valid_fraction)\ntrain = clicks_srt[:-valid_rows * 2]\n# valid size == test size, last two sections of the data\nvalid = clicks_srt[-valid_rows * 2:-valid_rows]\ntest = clicks_srt[-valid_rows:]","744fd648":"print(clicks.shape,'\\n',train.shape,'\\n',valid.shape,'\\n',test.shape)","333e0e25":"import lightgbm as lgb\n\ndtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\ndvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\ndtest = lgb.Dataset(test[feature_cols], label=test['is_attributed'])\n\nparam = {'num_leaves': 64, 'objective': 'binary'}\nparam['metric'] = 'auc'\nnum_round = 1000\n#bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10)","19bdc055":"#type(bst) #lightgbm.basic.Booster","6f729ca0":"#lgb.plot_metric(bst, metric=metrics.roc_auc_score, dataset_names=[dtrain, dvalid, dtest]) #??? TypeError: booster must be dict or LGBMModel\n#, ax=None, xlim=None, ylim=None, title='Metric during training', xlabel='Iterations', ylabel='auto', figsize=None, dpi=None, grid=True)[source]","bbc3ff08":"#Record eval results for plotting\nvalidation_metrics = {}  \n\nbst = lgb.train(param, \n                dtrain, \n                num_round, \n                valid_sets=[dvalid],\n                valid_names='Baseline Model',\n                early_stopping_rounds=10,\n                evals_result=validation_metrics,\n                verbose_eval=10)","e421ad2b":"validation_metrics","f6a6335e":"ax = lgb.plot_metric(validation_metrics, metric='auc');\n#plt.show();","89e7f0b7":"print('Plot feature importances...')\nax = lgb.plot_importance(bst, max_num_features=15)\nplt.show()","5703cece":"bst.num_trees()","491a2bae":"tree_index = 0\nprint('Plot '+str(tree_index)+'th tree...')  # one tree use categorical feature to split\nax = lgb.plot_tree(bst, tree_index=tree_index, figsize=(64, 36), show_info=['split_gain'])\nplt.show()","5598f79b":"from sklearn import metrics\n\nstart_time = time.time()\n\nypred = bst.predict(test[feature_cols])\nscore = metrics.roc_auc_score(test['is_attributed'], ypred)\nprint(f\"Test score: {score}\")\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","5addb4ed":"my_own_metrics['test score'] = score","01dc4b17":"my_own_metrics","91ce872d":"#plt.bar(my_own_metrics.keys(), my_own_metrics.values())","e06bf908":"feature_cols + ['click_id']","81cfeccb":"competition_test_data = competition_test_data[feature_cols + ['click_id']]","49204a75":"competition_test_data.shape","354c2346":"competition_test_data.head()","14cbaaf1":"test[feature_cols].head()","fbb9c17a":"start_time = time.time()\ncompetition_predictions = bst.predict(competition_test_data[feature_cols])\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","8f52a8e0":"type(competition_predictions)","7b3ede9c":"competition_predictions","152e6ffe":"competition_predictions_df = pd.DataFrame({'click_id': competition_test_data['click_id'],\n                                           'is_attributed': competition_predictions})\ncompetition_predictions_df","48b52c42":"#Takes a long time\n#competition_predictions_df['click_id'] = competition_test_data['click_id']\n#competition_predictions_df = competition_predictions_df[['click_id', 'is_attributed']]\n#competition_predictions_df","9020c82f":"#competition_predictions_df['is_attributed'].value_counts().sort_index()","8e714336":"pd.cut(competition_predictions_df['is_attributed'], bins=10).value_counts().sort_index()","551a91f4":"pd.cut(competition_predictions_df['is_attributed'], bins=10).value_counts().sort_index().plot(kind='bar', rot=45);","bd2e4e86":"#competition_predictions_df['is_attributed'].value_counts().sort_index().plot(kind='bar');","0a27cdce":"#sum(competition_predictions_df['is_attributed'] <= 0.5)\/competition_predictions_df.shape[0]","1bccfe27":"#sum(competition_predictions_df['is_attributed'] > 0.5)\/competition_predictions_df.shape[0]","1f054e9e":"competition_predictions_df.to_csv('submission.csv', index=False)","47287ff9":"my_own_metrics['private score'] = 0\nmy_own_metrics['public score'] = 0\nmy_own_metrics","06bc6164":"clicks.head()","f82a7026":"competition_test_data.head()","09832999":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)\n\nimport random\nseed = 51\ntf.random.set_seed(seed)\nrandom.seed(seed)\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = [16,9]","109d70f9":"clicks.isna().sum()","222d50a5":"clicks.dtypes","eb376dac":"from sklearn.model_selection import train_test_split\n\ntrain_dataset, test_dataset = train_test_split(clicks, stratify=clicks['is_attributed'], test_size=0.2, random_state=seed)\ntrain_dataset, validation_dataset = train_test_split(train_dataset, stratify=train_dataset['is_attributed'], test_size=0.2, random_state=seed)\n\nprint(train_dataset.shape, validation_dataset.shape, test_dataset.shape)\nprint(100*train_dataset.shape[0]\/clicks.shape[0], 100*validation_dataset.shape[0]\/clicks.shape[0], 100*test_dataset.shape[0]\/clicks.shape[0])","4d927ca7":"sns.pairplot(train_dataset[['day', 'hour', 'minute', 'second', 'ip_labels', 'app_labels', 'device_labels', 'os_labels', 'channel_labels', 'is_attributed']], height=3)","37c1a438":"train_labels = train_dataset.pop('is_attributed')\nvalidation_labels = validation_dataset.pop('is_attributed')\ntest_labels = test_dataset.pop('is_attributed')","163086f1":"feature_col = ['day', 'hour', 'minute', 'second', 'ip_labels', 'app_labels', 'device_labels', 'os_labels', 'channel_labels']\n\n#Another way\n#train_dataset.select_dtypes(exclude='object')\n\ntrain_dataset = train_dataset[feature_col]\nvalidation_dataset = validation_dataset[feature_col]\ntest_dataset = test_dataset[feature_col]","387e2856":"def norm_WRONG(df):\n    return (df - df.mean()) \/ df.std()\n\n#AUC is around 0.55 with no normalization\n#normed_train_data = train_dataset\n#normed_validation_data = validation_dataset\n#normed_test_data = test_dataset","a3a7d144":"def norm(df):\n    return (df - train_dataset.mean()) \/ train_dataset.std()","45071eb2":"normed_train_data = norm(train_dataset)\nnormed_validation_data = norm(validation_dataset)\nnormed_test_data = norm(test_dataset)","9adb1c5e":"train_dataset.head()","6cb54890":"normed_train_data.head()","4f4e6241":"train_dataset['day'].hist();","ce221775":"normed_train_data['day'].hist();","9bf09f81":"def compute_metrics(y_true, y_pred):\n    tp = tf.keras.metrics.TruePositives()\n    tp.update_state(y_true, y_pred)\n    tp = int(tp.result().numpy())\n    fp = tf.keras.metrics.FalsePositives()\n    fp.update_state(y_true, y_pred)\n    fp = int(fp.result().numpy())\n    tn = tf.keras.metrics.TrueNegatives()\n    tn.update_state(y_true, y_pred)\n    tn = int(tn.result().numpy())\n    fn = tf.keras.metrics.FalseNegatives()\n    fn.update_state(y_true, y_pred)\n    fn = int(fn.result().numpy())\n    return [tp, fn, fp, tn]","ea7c3132":"def print_metrics(metrics):\n    print('True Positives: ' + str(metrics[0]))\n    print('True Negatives: ' + str(metrics[3]))\n    print('False Positives: ' + str(metrics[2]))\n    print('False Negatives: ' + str(metrics[1]))","83efdeaa":"def plot_results(history):\n    history = history.history\n\n    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex='col', figsize=(20, 14))\n\n    ax1.plot(history['loss'], label='Train loss')\n    ax1.plot(history['val_loss'], label='Validation loss')\n    ax1.legend(loc='best')\n    ax1.set_title('Loss')\n\n    ax2.plot(history['auprc'], label='Train AUPRC')\n    ax2.plot(history['val_auprc'], label='Validation AUPRC')\n    ax2.legend(loc='best')\n    ax2.set_title('AUPRC')\n    \n    \n    ax3.plot(history['auroc'], label='Train AUROC')\n    ax3.plot(history['val_auroc'], label='Validation AUROC')\n    ax3.legend(loc='best')\n    ax3.set_title('AUROC')\n\n    plt.xlabel('Epochs')\n    sns.despine()\n    plt.show()","d8188430":"train_dataset.dtypes","f698bede":"def build_model():\n    model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n    ])\n\n    optimizer = tf.keras.optimizers.RMSprop(0.001)\n\n    model.compile(loss='binary_crossentropy',\n                optimizer=optimizer,\n                metrics=[tf.keras.metrics.AUC(curve='ROC', name='auroc'), \n                          tf.keras.metrics.AUC(curve='PR', name='auprc')])\n    model.summary()\n\n    return model","f7b7e67a":"model = build_model()","e86cdbbd":"example_batch = normed_train_data[:10]\nexample_result = model.predict(example_batch)\nexample_result","11fecb22":"checkpoint_filepath = 'talkingdata-adtracking-dask-ml-dl-v11.h5'\n\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, verbose=0, save_weights_only=True, \n                                                      monitor='val_auprc', mode='max', save_best_only=True)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auprc', patience=10, verbose=1, mode='max')","9daf33df":"EPOCHS = 100\nBATCH_SIZE = 256","29bb64ba":"tf.keras.backend.clear_session()\n\nhistory_v11 = model.fit(\n  normed_train_data, train_labels,\n  epochs=EPOCHS, \n  validation_data = (normed_validation_data, validation_labels), \n  batch_size=BATCH_SIZE,\n  verbose=2, \n  callbacks=[model_checkpoint, early_stopping]\n  )","b42e6c02":"plot_results(history_v11)","6d305122":"y_pred = model.predict(normed_test_data)\nauprc = tf.keras.metrics.AUC(curve='PR')\nauprc.update_state(test_labels, y_pred)\nTF_Model_AUPRC = auprc.result().numpy()\nTF_Model_AUPRC","5a8b2bd5":"TF_Model_metrics = compute_metrics(test_labels, y_pred)\nprint_metrics(TF_Model_metrics)","6063f61d":"#EPOCHS = 100\n#BATCH_SIZE = 256\n#0.90584815\n#True Positives: 73230\n#True Negatives: 362160\n#False Positives: 6734\n#False Negatives: 18139\n\n#Model v12\n#TF_Model_AUPRC 0.9084018 \n#TF_Model_AUROC 0.9549123\n#True Positives: 70773\n#True Negatives: 363975\n#False Positives: 4919\n#False Negatives: 20596\n    \n#EPOCHS = 100\n#BATCH_SIZE = 128\n#0.89784527\n#True Positives: 71936\n#True Negatives: 362700\n#False Positives: 6194\n#False Negatives: 19433","9e5b36e2":"test_labels[:5]","afd6b71b":"y_pred[:5]","30728ef7":"def build_model_v12():\n    tf.keras.backend.clear_session()\n\n    model = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=[len(train_dataset.keys())]),\n    layers.BatchNormalization(),\n    layers.Dropout(0.33), #Remove dropout or lower %\n    layers.Dense(64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.33),\n    layers.Dense(32, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.33),\n    layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(loss='binary_crossentropy',\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[tf.keras.metrics.AUC(curve='ROC', name='auroc'), \n                          tf.keras.metrics.AUC(curve='PR', name='auprc')])\n\n    model.summary()\n\n    return model","a87f5946":"model = build_model_v12()","923a385c":"checkpoint_filepath = 'talkingdata-adtracking-dask-ml-dl-v12.h5'\n\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, verbose=0, save_weights_only=True, \n                                                      monitor='val_auprc', mode='max', save_best_only=True)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auprc', patience=10, verbose=1, mode='max')","094c9872":"EPOCHS = 100\nBATCH_SIZE = 256","f84876ee":"tf.keras.backend.clear_session()\n\nhistory_v12 = model.fit(\n    normed_train_data, train_labels,\n    epochs=EPOCHS, \n    validation_data = (normed_validation_data, validation_labels), \n    batch_size=BATCH_SIZE,\n    verbose=2, \n    callbacks=[model_checkpoint, early_stopping]\n  )","8f10ec5a":"plot_results(history_v12)","fb6cd134":"y_pred = model.predict(normed_test_data)\n\nauprc = tf.keras.metrics.AUC(curve='PR')\nauprc.update_state(test_labels, y_pred)\nTF_Model_AUPRC = auprc.result().numpy()\n\nauroc = tf.keras.metrics.AUC(curve='ROC')\nauroc.update_state(test_labels, y_pred)\nTF_Model_AUROC = auroc.result().numpy()\n\nprint('TF_Model_AUPRC',TF_Model_AUPRC, '\\nTF_Model_AUROC', TF_Model_AUROC)","83a92dab":"TF_Model_metrics = compute_metrics(test_labels, y_pred)\nprint_metrics(TF_Model_metrics)","c45bd742":"feature_cols = ['day', 'hour', 'minute', 'second', \n                'ip_labels', 'app_labels', 'device_labels',\n                'os_labels', 'channel_labels']","9338e71c":"test_dataset.head()","288cea99":"normed_test_data.head()","cc7d4176":"competition_test_data[feature_cols].head()","1880084c":"competition_test_data[feature_cols].dtypes","900b33d9":"competition_test_data[feature_cols].isna().sum()","401130ac":"col = 'day'\nprint(competition_test_data[col].mean(), competition_test_data[col].std())","3af7c541":"competition_test_data['day'].hist();","f6a4db68":"norm_competition_test_data = norm(competition_test_data[feature_cols])","042058d3":"norm_competition_test_data['click_id'] = competition_test_data['click_id']","948efef7":"norm_competition_test_data.head()","55bd3eca":"total = norm_competition_test_data.shape[0]\nh = int(total\/3)\n\ncompetition_test_data_partition1 = norm_competition_test_data.iloc[0:h]\ncompetition_test_data_partition2 = norm_competition_test_data.iloc[h:2*h]\ncompetition_test_data_partition3 = norm_competition_test_data.iloc[2*h:]\n\nprint(competition_test_data.shape, \n      competition_test_data_partition1.shape, \n      competition_test_data_partition2.shape, \n      competition_test_data_partition3.shape)","f6e92d31":"start_time = time.time()\ncompetition_predictions_1 = model.predict(competition_test_data_partition1[feature_cols])\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","ff740e45":"competition_predictions_1_df = pd.DataFrame(competition_predictions_1, columns=['is_attributed'])\npd.cut(competition_predictions_1_df['is_attributed'], bins=10).value_counts().sort_index()","06ce182a":"pd.cut(competition_predictions_1_df['is_attributed'], bins=10).value_counts().sort_index().plot(kind='bar', rot=45);","eaff3d44":"start_time = time.time()\ncompetition_predictions_2 = model.predict(competition_test_data_partition2[feature_cols])\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","972bfc14":"competition_predictions_2_df = pd.DataFrame(competition_predictions_2, columns=['is_attributed'])\npd.cut(competition_predictions_2_df['is_attributed'], bins=10).value_counts().sort_index()","8e0c8973":"pd.cut(competition_predictions_2_df['is_attributed'], bins=10).value_counts().sort_index().plot(kind='bar', rot=45);","30365ac5":"start_time = time.time()\ncompetition_predictions_3 = model.predict(competition_test_data_partition3[feature_cols])\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","34c51114":"competition_predictions_3_df = pd.DataFrame(competition_predictions_3, columns=['is_attributed'])\npd.cut(competition_predictions_3_df['is_attributed'], bins=10).value_counts().sort_index()","669078c7":"pd.cut(competition_predictions_3_df['is_attributed'], bins=10).value_counts().sort_index().plot(kind='bar', rot=45);","d41fd219":"competition_predictions = np.append(competition_predictions_1, competition_predictions_2)\ncompetition_predictions = np.append(competition_predictions, competition_predictions_3)","d53a3630":"submission_df = pd.read_csv('\/kaggle\/input\/talkingdata-adtracking-fraud-detection\/sample_submission.csv')","7c5fd58f":"submission_df['is_attributed'] = competition_predictions","a575fc1d":"submission_df.head()","4c30576d":"pd.cut(submission_df['is_attributed'], bins=10).value_counts().sort_index()","941496c2":"pd.cut(submission_df['is_attributed'], bins=10).value_counts().sort_index().plot(kind='bar', rot=45);","ab76cd9d":"submission_df.to_csv('dl_v11_label_encoding_submission.csv', index=False)","25fb4ddb":"## \u26a0\ufe0f Your notebook tried to allocate more memory than is available. It has restarted. \u26a0\ufe0f","83c9c026":"# Deep Learning Model","1adf6f4d":"## Import TensorFlow libraries","351b65e3":"## \u26a0\ufe0f ValueError: y contains previously unseen labels: [0, 1, 2,... \u26a0\ufe0f","b18f429c":"- validation_metrics inspired by:\nhttps:\/\/github.com\/Microsoft\/LightGBM\/blob\/2e93cdab9eee02d4d7f5cb3b6b31128dec94e25e\/examples\/python-guide\/plot_example.py","60f15288":"## Inspect the data","a5e19e60":"# Machine Learning Model","5ada9ac4":"## Competition data","3ca78621":"## Feature Enginering 5 Numerical Features Time since last event","27386f7c":"## Competition data ","1c0f6122":"## Feature Enginering 4 Numerical Features Number of events in the past 6 hours","785a27aa":"### Question ??? \n\nclass sklearn.preprocessing.LabelEncoder[source]\nEncode target labels with value between 0 and n_classes-1.\n\nThis transformer should be used to encode **target values**, i.e. y, and not the input X.","05117550":"### Competition submission step","263945bc":"## Notes on strategy from 1st place winners\nhttps:\/\/www.kaggle.com\/c\/talkingdata-adtracking-fraud-detection\/discussion\/56475\n![image.png](attachment:image.png)","1deb3d44":"**This notebook is inspired by an exercise in the [Feature Engineering](https:\/\/www.kaggle.com\/learn\/feature-engineering) course**  \n**It is also inspired by David Patton's notebook at [this link ](https:\/\/www.kaggle.com\/dcpatton\/td-fraud-detector-nn)**  \n**You can reference the tutorial at [this link](https:\/\/www.kaggle.com\/matleonard\/baseline-model)**  \n**You can reference my notebook at [this link](https:\/\/www.kaggle.com\/georgezoto\/feature-engineering-baseline-model)**  \n\n---\n","d639771d":"Data fields  \nEach row of the training data contains a click record, with the following features.  \n\n- ip: ip address of click.\n- app: app id for marketing.\n- device: device type id of user mobile phone (e.g., iphone 6 plus, iphone 7, huawei mate 7, etc.)\n- os: os version id of user mobile phone\n- channel: channel id of mobile ad publisher\n- click_time: timestamp of click (UTC)\n- attributed_time: if user download the app for after clicking an ad, this is the time of the app download\n- is_attributed: the target that is to be predicted, indicating the app was downloaded  \n\nNote that ip, app, device, os, and channel are encoded.\n\nThe test data is similar, with the following differences:\n- click_id: reference for making predictions\n- is_attributed: not included","455ebe28":"## Feature Engineering 1 Construct features from timestamps\n\nNotice that the `click_data` DataFrame has a `'click_time'` column with timestamp data.\n\nUse this column to create features for the coresponding day, hour, minute and second. \n\nStore these as new integer columns `day`, `hour`, `minute`, and `second` in a new DataFrame `clicks`.","1d0b2c3c":"## Feature Enginering 3 Add interactions\nSee also: https:\/\/www.kaggle.com\/georgezoto\/talkingdata-adtracking-comp-feature-generation","a3923b6e":"## \u26a0\ufe0f Your notebook tried to allocate more memory than is available. It has restarted. \u26a0\ufe0f","b04ed238":"## Workaround #2 potential data leakage???\n## http:\/\/kagglesolutions.com\/r\/feature-engineering--label-encoding\n## To resolve this issue we will first concatenate X_train and X_test together and then perform label encoding. You can have everything in a loop for all of your categorical features\n\n```\nX_train = pd.DataFrame({'x1': np.random.random(5), 'x2': ['cat', 'cat', 'dog', 'cat', 'dog']})\nX_test = pd.DataFrame({'x1': np.random.random(5), 'x2': ['cat', 'cat', 'dog', 'rat', 'dog']})\n\ncategorical_features = ['x2']\n\n# make an encoder object\nencoder = LabelEncoder()\n\n# fit and transform feature x2\nfor col in categorical_features:\n    encoder.fit(pd.concat([X_train[col], X_test[col]], axis=0, sort=False))\n    X_train[col] = encoder.transform(X_train[col])\n    X_test[col] = encoder.transform(X_test[col])\n    \nprint(X_train.head(), '\\n')\nprint(X_test.head(), '\\n')\n```","87bb8ceb":"This will be our baseline score for the model. When we transform features, add new ones, or perform feature selection, we should be improving on this score. However, since this is the test set, we only want to look at it at the end of all our manipulations. At the very end of this course you'll look at the test score again to see if you improved on the baseline model.\n\n# Keep Going\nNow that you have a baseline model, you are ready to **[use categorical encoding techniques](https:\/\/www.kaggle.com\/matleonard\/categorical-encodings)** to improve it.","e3b1af05":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/161443) to chat with other Learners.*","6c7111c6":"### Plot validation AUC during training","14206864":"## Train, validation, and test sets\nWith our baseline features ready, we need to split our data into training and validation sets. We should also hold out a test set to measure the final accuracy of the model.\n\n### 4) Train\/test splits with time series data\nThis is time series data. Are there any special considerations when creating train\/test splits for time series? If so, what are they?","5f328379":"### Competition submission step","e3d4bba3":"## dask_ml.preprocessing.LabelEncoder\nhttps:\/\/ml.dask.org\/modules\/generated\/dask_ml.preprocessing.LabelEncoder.html","c5a679f8":"## Use smaller storage dtypes","d94ec7e7":"### Train with LightGBM\n\nNow we can create LightGBM dataset objects for each of the smaller datasets and train the baseline model.","98d6c489":"## Keep only numerical features after label encoding above","1489bfc6":"## Split features from labels","7b366058":"## ML Explainability and taking a closer look at feature importance, individual trees\nInspired by: https:\/\/github.com\/Microsoft\/LightGBM\/blob\/2e93cdab9eee02d4d7f5cb3b6b31128dec94e25e\/examples\/python-guide\/plot_example.py\n","0285eb5e":"### Create train\/validation\/test splits\n\nHere we'll create training, validation, and test splits. First, `clicks` DataFrame is sorted in order of increasing time. The first 80% of the rows are the train set, the next 10% are the validation set, and the last 10% are the test set.","95dbe34d":"## Predict on a small portion of the training set a.k.a the test set","82b00e83":"## Feature Engineering 2 Label Encoding\nFor each of the categorical features `['ip', 'app', 'device', 'os', 'channel']`, use scikit-learn's `LabelEncoder` to create new features in the `clicks` DataFrame. The new column names should be the original column name with `'_labels'` appended, like `ip_labels`.","995ae909":"# Submit csv to competition\n<center><a href=\"https:\/\/www.kaggle.com\/c\/talkingdata-adtracking-fraud-detection\"><img src=\"https:\/\/i.imgur.com\/srKxEkD.png\" width=400px><\/a><\/center>","442e336b":"# Introduction\n\nIn the exercise, you will work with data from the TalkingData AdTracking competition.  The goal of the competition is to predict if a user will download an app after clicking through an ad. \n\n<center><a href=\"https:\/\/www.kaggle.com\/c\/talkingdata-adtracking-fraud-detection\"><img src=\"https:\/\/i.imgur.com\/srKxEkD.png\" width=600px><\/a><\/center>\n\nFor this course you will use a small sample of the data, dropping 99% of negative records (where the app wasn't downloaded) to make the target more balanced.\n\nAfter building a baseline model, you'll be able to see how your feature engineering and selection efforts improve the model's performance.","04dd6808":"## Baseline Model\n\nThe first thing you'll do is construct a baseline model. We'll begin by looking at the data.","a7f80f88":"## Data structure","43e89b57":"# Submit test predictions to TalkingData AdTracking Fraud Detection Challenge competition using the ***limited*** train.csv records from this notebook","b78ba9b1":"## Now try out the model. Take a batch of 10 examples from the training data and call model.predict on it.","fb8252c6":"## How many unknown_value did we get in the test dataset?","95d380ac":"### ??? TypeError: booster must be dict or LGBMModel\n\n- booster (dict or LGBMModel) \u2013 Dictionary returned from lightgbm.train() or LGBMModel instance.\nhttps:\/\/lightgbm.readthedocs.io\/en\/latest\/pythonapi\/lightgbm.plot_metric.html","0a9e02a1":"## \ud83d\ude00 Not the best solution to ValueError: y contains previously unseen labels: [0, 1, 2,... \ud83d\ude00\n## unknown_value = -1\n## \u26a0\ufe0f Make sure this is int (as other labels) or you will not be able to predict in the end \u26a0\ufe0f\n## https:\/\/stackoverflow.com\/questions\/21057621\/sklearn-labelencoder-with-never-seen-before-values","bd10c228":"# Submit csv to competition\n<center><a href=\"https:\/\/www.kaggle.com\/c\/talkingdata-adtracking-fraud-detection\"><img src=\"https:\/\/i.imgur.com\/srKxEkD.png\" width=400px><\/a><\/center>","1ea5db06":"## Model v12","2207b169":"## Useful custom methods","7f9fb8a2":"## Evaluate the model\nFinally, with the model trained, we evaluate its performance on the test set. ","6f6ebddd":"# TalkingData AdTracking Fraud Detection Challenge\n# Can you detect fraudulent click traffic for mobile app ads?\n# https:\/\/www.kaggle.com\/c\/talkingdata-adtracking-fraud-detection","31cb7eb3":"- evals_result (dict or None, optional (default=None)) \u2013\n\nThis dictionary used to store all evaluation results of all the items in valid_sets.\n\nhttps:\/\/lightgbm.readthedocs.io\/en\/latest\/pythonapi\/lightgbm.train.html","e0ae5177":"## Feature Enginering 6 Numerical Features Number of previous app downloads","82dd0d85":"## Train the model","7764b4a5":"## Normalize the data \u26a0\ufe0f WRONG \u26a0\ufe0f You get good performance on training** and validation but very bad results on comp test data","9b488e7c":"## \u26a0\ufe0f Partition competition_test_data so it fits in memory \u26a0\ufe0f","aea094c1":"## The model\n## Build the model","aaab4884":"## Split the data","a6bb9f8e":"## Normalize the data","d6b4ad71":"## Check if the dataset contains unknown values"}}