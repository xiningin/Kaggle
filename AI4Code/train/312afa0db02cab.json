{"cell_type":{"e6ab761c":"code","2725e5c1":"code","bc3872bf":"code","8c47fcb3":"code","abdc1f96":"code","ade1c4d0":"code","ed237666":"code","5460c4d1":"code","2cb356e2":"code","6c8d1581":"code","c45e94e8":"code","36298801":"code","94a3a49c":"code","225ef18d":"code","af394992":"code","e1178dd2":"code","4b54f91c":"code","45f58859":"code","95e9d676":"markdown","05d5a0ce":"markdown","bdfc6513":"markdown","fb558b48":"markdown","6e5fb054":"markdown","42081362":"markdown","72e334ff":"markdown","18f8d4ee":"markdown","87d40179":"markdown","40046ff7":"markdown","5a09ac4a":"markdown"},"source":{"e6ab761c":"# importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sklearn\nfrom sklearn.metrics import accuracy_score\nimport nltk\nimport re","2725e5c1":"# loading our dataset\ndf = pd.read_csv(\"..\/input\/spam.csv\", encoding = 'latin-1')","bc3872bf":"# checking the first 5 rows of our data\ndf.head()","8c47fcb3":"# dropping the unnecessary columns Unnamed: 2, Unnamed: 3, Unnamed: 4\ndf = df.drop(labels = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n\n# renaming the existing column v1 as type, v2 as message\ndf = df.rename(columns = {'v1': 'type', 'v2': 'message'})\n\ndf.head()","abdc1f96":"# bar chart\ncount_types = pd.value_counts(df['type'])\ncount_types.plot(kind = 'bar', color = ['blue', 'orange'])\nplt.title('Bar Chart')\nplt.show()","ade1c4d0":"# pie chart\ncount_types.plot(kind = 'pie', autopct='%1.0f%%')\nplt.ylabel('')\nplt.title('Pie Chart')\nplt.show()","ed237666":"# labeling ham as 0 and spam as 1\ndf['type'] = df.type.map({'ham':0, 'spam':1})","5460c4d1":"# splitting the columns\nX = df['message']\ny = df['type']","2cb356e2":"# converting X and y to numpy array\nX = np.array(X)\ny = np.array(y)","6c8d1581":"# coverting the message into lower case, as hello, Hello, HELLO means the same\nfor i in range(len(X)):\n    X[i] = X[i].lower()\n    \n# first 5 messages after converting text into lower case\nprint(X[:5])","c45e94e8":"# removing the extra spaces, digits and non word characters like punctuations, ascii etc.\nfor i in range(len(X)):\n    X[i] = re.sub(r'\\W',' ',X[i])\n    X[i] = re.sub(r'\\d',' ',X[i])\n    X[i] = re.sub(r'\\s+',' ',X[i])\n\n# first 5 messages after removing the extras\nprint(X[:5])","36298801":"# removing the stop words\nfrom nltk.corpus import stopwords\nfor i in range(len(X)):\n    words = nltk.word_tokenize(X[i])\n    new_words = [word for word in words if word not in stopwords.words('english')]\n    X[i] = ' '.join(new_words)\n    \n# first 5 messages after removing the stopwords\nprint(X[:5])","94a3a49c":"# stemming - get the root of each word\nfrom nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\n\nfor i in range(len(X)):\n    words = nltk.word_tokenize(X[i])\n    new_words = [stemmer.stem(word) for word in words]\n    X[i] = ' '.join(new_words)\n\n# first 5 messages after stemming\nprint(X[:5])","225ef18d":"# creating the tf-idf model\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer('english')\nX = vectorizer.fit_transform(X)","af394992":"# splitting the dataset into test and train data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","e1178dd2":"# running multinomial naive bayes classifier\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB(alpha = 0.2)\nclf = clf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\nprint('Accuracy for Multinomial Naive Bayes Classifier: ', accuracy)","4b54f91c":"# running linear support vector machine classifier\nfrom sklearn.svm import SVC\nclf = SVC(kernel = \"linear\")\nclf = clf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\nprint('Accuracy for Linear SVM Classifier: ', accuracy)","45f58859":"# running decision tree classifier\nfrom sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\nprint('Accuracy for Decision Tree Classifier: ', accuracy)","95e9d676":"#### Multinomial Naive Bayes Classifier","05d5a0ce":"## Splitting the Dataset ","bdfc6513":"## Data Preprocessing","fb558b48":"#### Decision Tree Classifier","6e5fb054":"## Loading Dataset","42081362":"## Conclusion\n Among all the classifiers tested here, multinomial naive bayes gives the best accuracy with a score of 0.9802690582959641","72e334ff":"## Text Transformation- TF-IDF model","18f8d4ee":"## Machine Learning Models","87d40179":"#### Linear Support Vector Machine Classifier","40046ff7":"## Data Visualizations","5a09ac4a":"## Importing Libraries"}}