{"cell_type":{"d0c93118":"code","32c86b39":"code","4457c48e":"code","cef0f122":"code","7400cb22":"code","0d34819e":"code","5dbea1b2":"code","a1b0deee":"code","67201d15":"code","8f2f422e":"code","0b0cded0":"code","2f15966c":"code","641412ed":"code","da095c93":"code","b421be14":"code","29f663a8":"code","3876d63f":"code","68412d6f":"code","f3ac44ef":"code","71827003":"code","541a3c35":"code","99bbf01f":"markdown","1757feec":"markdown","1eca7eee":"markdown","843a948d":"markdown","a5d71561":"markdown","afc91a8d":"markdown","e732639e":"markdown"},"source":{"d0c93118":"#Import Required Libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","32c86b39":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv') \ntest  = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","4457c48e":"train.shape","cef0f122":"train.head()","7400cb22":"import pandas_profiling\nprofile_report = pandas_profiling.ProfileReport(train)\nprofile_report","0d34819e":"# Dropping rows where the target is missing\nTarget = 'SalePrice'\ntrain.dropna(axis=0, subset=[Target], inplace=True)","5dbea1b2":"# Combine Test and Training sets to maintain consistancy.\ndata=pd.concat([train.iloc[:,:-1],test],axis=0)\n\nprint('train df has {} rows and {} features'.format(train.shape[0],train.shape[1]))\nprint('test df has {} rows and {} features'.format(test.shape[0],test.shape[1]))\nprint('Combined df has {} rows and {} features'.format(data.shape[0],data.shape[1]))","a1b0deee":"data.head()","67201d15":"# Dropping unwanted columns\ndata = data.drop(columns=['Id'],axis=1)","8f2f422e":"# Looking for Missing Values\n\ndef missingValuesInfo(df):\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100, 2)\n    temp = pd.concat([total, percent], axis = 1,keys= ['Total', 'Percent'])\n    return temp.loc[(temp['Total'] > 0)]\n\nmissingValuesInfo(train)","0b0cded0":"# Missing Value Handling\n\ndef HandleMissingValues(df):\n    # for Object columns fill using 'UNKOWN'\n    # for Numeric columns fill using median\n    num_cols = [cname for cname in df.columns if df[cname].dtype in ['int64', 'float64']]\n    cat_cols = [cname for cname in df.columns if df[cname].dtype == \"object\"]\n    values = {}\n    for a in cat_cols:\n        values[a] = 'UNKOWN'\n\n    for a in num_cols:\n        values[a] = df[a].median()\n        \n    df.fillna(value=values,inplace=True)\n    \n    \nHandleMissingValues(data)\ndata.head()","2f15966c":"# Check for any missing values\ndata.isnull().sum().sum()","641412ed":"#Categorical Feature Encoding\n\ndef getObjectColumnsList(df):\n    return [cname for cname in df.columns if df[cname].dtype == \"object\"]\n\ndef PerformOneHotEncoding(df,columnsToEncode):\n    return pd.get_dummies(df,columns = columnsToEncode)\n\ncat_cols = getObjectColumnsList(data)\ndata = PerformOneHotEncoding(data,cat_cols)\ndata.head()","da095c93":"data.shape","b421be14":"#spliting the data into train and test datasets\ntrain_data=data.iloc[:1460,:]\ntest_data=data.iloc[1460:,:]\nprint(train_data.shape)\ntest_data.shape","29f663a8":"# Get X,y for modelling\nX=train_data\ny=train.loc[:,'SalePrice']","3876d63f":"from sklearn.linear_model import RidgeCV\n\nridge_cv = RidgeCV(alphas=(0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10))\nridge_cv.fit(X, y)\nridge_cv_preds=ridge_cv.predict(test_data)","68412d6f":"import xgboost as xgb\n\nmodel_xgb = xgb.XGBRegressor(n_estimators=340, max_depth=2, learning_rate=0.2)\nmodel_xgb.fit(X, y)\nxgb_preds=model_xgb.predict(test_data)","f3ac44ef":"predictions = ( ridge_cv_preds + xgb_preds )\/2","71827003":"#make the submission data frame\nsubmission = {\n    'Id': test.Id.values,\n    'SalePrice': predictions\n}\nsolution = pd.DataFrame(submission)\nsolution.head()","541a3c35":"#make the submission file\nsolution.to_csv('submission.csv',index=False)","99bbf01f":"## Predictive Modeling","1757feec":"## Credits\n","1eca7eee":"* https:\/\/www.kaggle.com\/redaabdou\/house-prices-solution-data-cleaning-ml\n","843a948d":"## Quick EDA","a5d71561":"## Submission","afc91a8d":"## Data Cleaning","e732639e":"# House Prices Solution \n\nThis competition challenges you to predict the final price of each home with 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa.\n\nIn this notebook : <span style=\"color:ROYALBLUE\">** Quick EDA **<\/span> -> <span style=\"color:BLUE\">** Data cleaning **<\/span> -> <span style=\"color:MEDIUMBLUE\">** Train machine learning regression algorithms to predict **<\/span> -> <span style=\"color:DARKBLUE\">** Submission **<\/span>\n\n\nLet's Start!"}}