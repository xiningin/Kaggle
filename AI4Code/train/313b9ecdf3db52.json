{"cell_type":{"d5893542":"code","91b83382":"code","e175d1ee":"code","f6e68cc0":"code","7ef51ebf":"code","d58c3f4f":"code","3da1d49c":"code","aba15b7a":"code","12233c28":"code","1b9ef5bf":"code","6469bf1f":"code","169b9ca1":"code","d4dd1587":"code","00acc042":"code","8be9ffdf":"markdown","9954003b":"markdown","5e4db3d5":"markdown","42b8c925":"markdown","9841e4f3":"markdown","483db98f":"markdown","e7f358cf":"markdown","5f369d50":"markdown","18afaaeb":"markdown","1587a4e2":"markdown","29f0e505":"markdown","f6bb770e":"markdown","4b407fc2":"markdown","695d1e8a":"markdown"},"source":{"d5893542":"# LIBRARIES\n# general purpose\nimport math\nimport numpy as np\nimport pandas as pd \nimport plotly.graph_objects as go\nimport os\n\n# data processing\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import QuantileTransformer\nfrom scipy.special import boxcox1p\n\n# modelling\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\n\n# parameter tuning\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint \nfrom scipy.stats import gamma","91b83382":"# data\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest  = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain.head()","e175d1ee":"target = ['SalePrice']\nfeat = [var for var in train.columns if var not in ['Id'] + target]\ncatfeat = [var for var in feat\n          if train[var].dtypes == 'object']\nnumfeat = [var for var in feat\n          if train[var].dtypes in ['int64', 'float']]","f6e68cc0":"fig = go.Figure()\nfor var in numfeat+target: \n    fig.add_trace(go.Box(y=train[var], \n                        name=var))\nfig.show(renderer=\"notebook\")","7ef51ebf":"# Correlation Matrix\nfig = go.Figure(data=go.Heatmap(z=train[numfeat+target].corr(),\n                                x=train[numfeat+target].columns, \n                                y=train[numfeat+target].columns,\n                                zmin=-1,\n                                zmax=1,\n                                colorscale=\"RdBu\"))\nfig.show(renderer=\"notebook\")","d58c3f4f":"# Scatter Plots\nif True: \n    xname = numfeat[0]\n    yname = \"SalePrice\"\n    fig = go.Figure()\n    for feat in numfeat: \n        fig.add_trace(go.Scatter(x=train[feat], \n                                 y=train[yname], \n                                 name=feat, \n                                mode=\"markers\"))\n\n    fig.show(renderer=\"notebook\")","3da1d49c":"# set vars\nmissing_catfeat = {var for var in catfeat\n                   if train[var].isnull().sum() !=0}\nmissing_numfeat = {var for var in numfeat\n                  if train[var].isnull().sum() != 0}\nmissing_feat = missing_catfeat | missing_numfeat\n\n# plot\nmissing = train[missing_feat].isnull().sum() \/ len(train) * 100\nmissing = missing.sort_values(ascending=False)\nfig = go.Figure(data=go.Bar(y=missing, x=missing.index), \n               layout=go.Layout(yaxis=go.layout.YAxis(title=go.layout.yaxis.Title(text=\"percentage missing\"))))\nfig.show(renderer=\"notebook\")","aba15b7a":"# Data prep configuration stored in CSV\nconfig = pd.read_csv(\"..\/input\/config-final\/config_final.csv\")\nconfig = config.fillna('None')\nconfig.head()","12233c28":"# Remove outliers detected through visual inspection\ntrain.drop(train[(train['GrLivArea']>4000) & \n                 (train['SalePrice']<300000)].index,\n           inplace = True)","1b9ef5bf":"# config parsing\ntransformers = list()\nfor i in range(0,config.shape[0]): \n    steps = list()\n    \n    for step in ['imputation', 'transformation', 'encoding']: \n        if config[step][i] != 'None': \n            param  = config[step + \"_param\"][i].split(\";\")\n            keys   = list(map(lambda x: x.split(\"=\")[0].strip(), param))\n            values = list(map(lambda x: eval(x.split(\"=\")[1]),   param))\n            kwargs = dict(zip(keys, values))\n            steps.append((step, globals()[config[step][i]](**kwargs)))  \n    \n    transformers.append((config[\"name\"][i], Pipeline(steps=steps), [config[\"name\"][i]]))\n\n# processing wrapper\npreprocessor = ColumnTransformer(transformers=transformers)","6469bf1f":"y = [math.log(x) for x in train['SalePrice']]\nX = np.ones((len(y),1))\nbaseline = Pipeline(steps=[('regression', LinearRegression())])\nscores = -1 * cross_val_score(baseline, X, y, cv=5, scoring='neg_mean_squared_error')\nprint(np.mean([math.sqrt(x) for x in scores]))","169b9ca1":"# parameters\nX =  train.drop(target, axis=1)\ny = [math.log(x) for x in train['SalePrice']]\nbt = Pipeline(steps=[\n    ('dataprep', preprocessor),\n    ('regression', GradientBoostingRegressor(learning_rate=0.1,\n                                             n_estimators=380,\n                                             min_samples_split=23, \n                                             min_samples_leaf=15,\n                                             max_features=40,\n                                             max_depth=3, \n                                             subsample=0.8\n                                             ))])\nparam_dist = {\"regression__n_estimators\": randint(550, 750),\n              \"regression__learning_rate\": gamma(a=4, scale=0.005)}\nn_iter_search = 20\n\n# random search\nrandom_search = RandomizedSearchCV(bt, \n                                   param_distributions=param_dist, \n                                   n_iter=n_iter_search, \n                                   cv=5, \n                                   iid=False)\nrandom_search.fit(X,y)\nrandom_search.best_estimator_","d4dd1587":"# eval\nscores = -1 * cross_val_score(random_search.best_estimator_, X, y, cv=5, scoring='neg_mean_squared_error')\nprint(np.mean([math.sqrt(x) for x in scores]))","00acc042":"\nrandom_search.best_estimator_.fit(train.drop('SalePrice', axis=1),y)\npred = list(map(lambda x: math.exp(x), random_search.best_estimator_.predict(test)))\nsubmission = pd.DataFrame({'Id': test.Id, 'SalePrice': pred})\nsubmission.to_csv('submission2.csv', index=False)\nsubmission.head()","8be9ffdf":"# PREDICTION","9954003b":"# DATA PREPARATION","5e4db3d5":"### Parameter Tuning","42b8c925":"# EXTRACTION","9841e4f3":"## Distribution","483db98f":"## Outliers","e7f358cf":"# VISUALIZATION\n","5f369d50":"## Features","18afaaeb":"## Boosting","1587a4e2":"## Baseline","29f0e505":"## Missingness","f6bb770e":"## Correlation","4b407fc2":"# MODELIZATION","695d1e8a":"## Feature Processing"}}