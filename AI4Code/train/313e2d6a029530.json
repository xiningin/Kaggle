{"cell_type":{"1f257965":"code","88a4224c":"code","fadfc1e4":"code","39600572":"code","8beebdaf":"code","d9c2ae43":"code","b8bd8738":"code","f2b97fc9":"code","68a2a1cf":"code","3364f7c6":"code","39bb3af8":"code","c6a6e96b":"code","89b10aaf":"code","461da873":"code","cc2163dd":"code","ee2ef5e9":"code","3174b2b5":"markdown","08ebf9bc":"markdown","1a45bd0b":"markdown","44b210e0":"markdown","a264687f":"markdown","baf3a235":"markdown","01f10093":"markdown","37aa8560":"markdown","ef10a3be":"markdown"},"source":{"1f257965":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport glob\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\nfrom keras.utils import to_categorical","88a4224c":"file_path = \"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\"\nX_train = []\ny_train = []\npicture_size = (50, 50)\nfor folder_location in glob.glob(file_path+\"\/*\"):\n    i = 0\n    for image_location in glob.glob(folder_location+\"\/*.jpg\"):\n        if i<1500:\n            image = load_img(image_location, target_size=picture_size)\n            converted_image = img_to_array(image)\n            converted_image = converted_image\/255.0\n            X_train.append(converted_image)\n        i=i+1    \nX_train = np.array(X_train)","fadfc1e4":"X_train.shape","39600572":"for folder_location in glob.glob(file_path+\"\/*\"):\n    i = 0\n    for image_location in glob.glob(folder_location+\"\/*.jpg\"):\n        if i<1500:\n            image_name = os.path.basename(image_location)\n            y_train.append(image_name[:1]) #extracting name of classes \n        i=i+1    ","8beebdaf":"y_train[:10]","d9c2ae43":"list_of_labels = list(np.unique(y_train)) #extract the list of unique labels\ndict_of_labels = { i : list_of_labels[i] for i in range(0, len(list_of_labels) ) }\ndict_of_labels = dict([(value, key) for key, value in dict_of_labels.items()]) \n#create a dict with those labels \nfor i in range(len(y_train)):\n    y_train[i] = dict_of_labels[y_train[i]] #turn str into numbers","b8bd8738":"y_train = to_categorical(y_train, dtype =\"uint8\")","f2b97fc9":"y_train.shape","68a2a1cf":"X_train, y_train = shuffle(X_train, y_train, random_state=42)","3364f7c6":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau( monitor='val_accuracy', factor=0.5,   patience=1, min_lr=0.00005)","39bb3af8":"import tensorflow as tf\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=3, \n                                 strides=1, activation='relu', input_shape = (50, 50, 3)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=5, \n                                   strides=2, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=3, \n                                   strides=1, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=5, \n                                   strides=2, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.Conv2D(256, kernel_size=3,  \n                                   strides=1, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Conv2D(256, kernel_size=5,  \n                                   strides=2, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\n    \nmodel.add(tf.keras.layers.Dense(29, activation='softmax'))","c6a6e96b":"model.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","89b10aaf":"train_history = model.fit(X_train, y_train, epochs=10, batch_size = 128,validation_split = 0.2, callbacks = [reduce_lr])","461da873":"accuracy = train_history.history['accuracy']\nval_accuracy = train_history.history['val_accuracy']\nepochs = list(range(1, 11))","cc2163dd":"import plotly.graph_objects as go","ee2ef5e9":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=epochs, y=accuracy, \n                        mode='lines + markers', name='accuracy'))\nfig.add_trace(go.Scatter(x=epochs, y=val_accuracy, \n                        mode='lines + markers', name='val_accuracy'))\nfig.update_layout(title='First Model',\n                   xaxis_title='Epochs', yaxis_title='Accuracy')","3174b2b5":"We need to convert y_train to the right format.","08ebf9bc":"**2.Creating the model**\n\nOur model will have the following structure:","1a45bd0b":"**1.LOAD THE DATA**\n\nFirst, we download the data. In order to reduce memory usage I will be using only the half of the dataset and resizing the pictures.\nIt is also important to note that we will normalize the images at this stage by dividing each one by 255.0. ","44b210e0":"Now we need to use one-hot encoding on order to categorize our data.\n","a264687f":"Extracting the y_train data:","baf3a235":"Let's see an example of what we have got.","01f10093":"To help reduce overfitting we shuffle the data.","37aa8560":"The end result of our X_train data should be a four-dimentional array containing the amount of photos, image width, image height and the amount of channels.","ef10a3be":"Here I used a few technics to better the model:\n* Using a Conv2D layer with stride 2 insted of a MaxPool2D layer\n* Using batch normalization\n\nWhat is batch normalization? This term means that we standartize our data for every batch. Standardization is rescaling the data to have a mean of zero and a standard deviation of one. \n* Using callbacks, specifically ReduceLROnPlateau\n"}}