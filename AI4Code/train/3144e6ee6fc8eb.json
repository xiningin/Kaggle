{"cell_type":{"01c57058":"code","474c5d0f":"code","ce0f89ed":"code","fba57b23":"code","ff01cf21":"code","6cb560b9":"code","a52d81c3":"code","c39c87c9":"code","7afb3b40":"code","3ab7e164":"code","2c8f94fe":"code","35e17e3b":"code","f23280f7":"code","637c0937":"code","50cbca54":"code","5ef34f53":"code","54871325":"code","2c65a117":"code","a20976b3":"code","59cda330":"code","13ca1742":"code","20fec8d0":"code","8a294735":"code","b671dcb8":"code","43a26263":"code","2b0bd2ca":"code","88debfe7":"code","6f01a2fc":"code","a1b7a240":"code","be295e6f":"code","a8f3290c":"code","258767df":"code","20e82f38":"code","1b636452":"code","1759e869":"code","acaa56c5":"code","b5fdb769":"code","03e0c30e":"code","3cbe0fb9":"code","9489c1eb":"code","21a30088":"code","f868b9d1":"code","3cff9815":"code","2c20746d":"code","ea18642a":"code","f211893a":"code","7cd4d282":"markdown","f683a874":"markdown"},"source":{"01c57058":"from collections import Counter\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import SnowballStemmer\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport pandas as pd\nimport numpy as np\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")","474c5d0f":"seed=42","ce0f89ed":"test_label = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test_labels.csv.zip\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip\")\ntrain_data = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip\")\nsample_sub = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/sample_submission.csv.zip\")\n","fba57b23":"train_data_df = train_data.copy()\n","ff01cf21":"test_label.head()","6cb560b9":"train_data.head()","a52d81c3":"test_data.head()","c39c87c9":"sample_sub.head()","7afb3b40":"train_data[\"comment_text\"][0]","3ab7e164":"train_data[\"comment_text\"][2]","2c8f94fe":"train_data.shape","35e17e3b":"targets = [col for col in train_data.columns if col not in [\"id\",\"comment_text\"]]","f23280f7":"for target in targets:\n    print(target)\n    print(train_data[target].value_counts())\n    print(\"=\"*100)","637c0937":"train_data[train_data[\"threat\"] == 1].reset_index(drop=True)[\"comment_text\"][1]","50cbca54":"train_data[train_data[\"insult\"] == 1].reset_index(drop=True)[\"comment_text\"][3]","5ef34f53":"train_data[train_data[\"identity_hate\"] == 1].reset_index(drop=True)[\"comment_text\"][2]","54871325":"train_data[train_data[\"obscene\"] == 1].reset_index(drop=True)[\"comment_text\"][1]","2c65a117":"train_data[train_data[\"severe_toxic\"] == 1].reset_index(drop=True)[\"comment_text\"][38]","a20976b3":"sample = train_data[train_data[\"toxic\"] == 1].reset_index(drop=True)","59cda330":"sample[sample[\"insult\"]==1].reset_index(drop=True).shape","13ca1742":"train_data[\"comment_text\"] = train_data[\"comment_text\"].apply(lambda x: x.lower())\ntrain_data[\"exp_01\"] = train_data[\"comment_text\"].apply(lambda x: word_tokenize(x))\n","20fec8d0":"toxic = train_data[train_data[\"toxic\"] == 1].reset_index(drop=True)\nsevere_toxic = train_data[train_data[\"severe_toxic\"] == 1].reset_index(drop=True)\nobscene = train_data[train_data[\"obscene\"] == 1].reset_index(drop=True)\nthreat = train_data[train_data[\"threat\"] == 1].reset_index(drop=True)\ninsult = train_data[train_data[\"insult\"] == 1].reset_index(drop=True)\nidentity_hate = train_data[train_data[\"identity_hate\"] == 1].reset_index(drop=True)","8a294735":"lemma = WordNetLemmatizer()\nstem = SnowballStemmer(\"english\")\ndef most_common(data,n,col):\n    top = Counter([stem.stem(lemma.lemmatize(item)) for sublist in data[col] for item in sublist if item.lower() not in STOPWORDS])\n    temp = pd.DataFrame(top.most_common(20))\n    temp.columns = [\"common_word\",\"count\"]\n    return temp.style.background_gradient(cmap=\"Blues\")\n\ndef least_common(data,n):\n    top = Counter([item for sublist in data[col] for item in sublist if item not in STOPWORDS])\n    temp = pd.DataFrame(top.most_common()[:-n-1:-1])\n    temp.columns = [\"common_word\",\"count\"]\n    return temp.style.background_gradient(cmap=\"Blues\"),","b671dcb8":"most_common(threat,20,'exp_01')","43a26263":"most_common(toxic,20,\"exp_01\")","2b0bd2ca":"most_common(insult,20,\"exp_01\")","88debfe7":"most_common(severe_toxic,20,\"exp_01\")","6f01a2fc":"most_common(identity_hate,20,\"exp_01\")","a1b7a240":"most_common(obscene,20,\"exp_01\")","be295e6f":"train_data[\"comment_text\"][1]","a8f3290c":"def preprocess(text):\n    text = re.sub(\"\\n\",\" \",text)\n    text = re.sub(\"[0-9]\",\"\",text)\n    text = re.sub(r\"[^\\w\\s]\",\" \",text)\n    text = text.lower()\n    return text","258767df":"train_data[\"new_comment_text\"] = train_data[\"comment_text\"].apply(preprocess)","20e82f38":"train_data[\"exp_02\"] = train_data[\"new_comment_text\"].apply(lambda x: word_tokenize(x))\n","1b636452":"toxic = train_data[train_data[\"toxic\"] == 1].reset_index(drop=True)\nsevere_toxic = train_data[train_data[\"severe_toxic\"] == 1].reset_index(drop=True)\nobscene = train_data[train_data[\"obscene\"] == 1].reset_index(drop=True)\nthreat = train_data[train_data[\"threat\"] == 1].reset_index(drop=True)\ninsult = train_data[train_data[\"insult\"] == 1].reset_index(drop=True)\nidentity_hate = train_data[train_data[\"identity_hate\"] == 1].reset_index(drop=True)","1759e869":"most_common(toxic,20,\"exp_02\")","acaa56c5":"most_common(toxic,20,\"exp_02\")","b5fdb769":"train_data.head()","03e0c30e":"df = train_data_df.copy(deep=True)\n","3cbe0fb9":"df.head()","9489c1eb":"!pip install -q iterative-stratification","21a30088":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold","f868b9d1":"df[\"kfold\"] = -1\ntargets =  [col for col in df.columns if col not in [\"id\",\"comment_text\",\"kfold\"]]\ntarget_feat = df[targets].values\nmskf = MultilabelStratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\nfor fold_, (t_,v_) in enumerate(mskf.split(X=df,y=target_feat)):\n    df.loc[v_,\"kfold\"] = fold_\n","3cff9815":"targets","2c20746d":"df.head()","ea18642a":"def run(data,fold):\n    print(\"making data ready for training\")\n    train_data = data[data[\"kfold\"] != fold].reset_index(drop=True)\n    valid_data = data[data['kfold'] == fold].reset_index(drop=True)\n    \n    targets = [col for col in data.columns if col not in [\"id\",\"comment_text\",\"kfold\"]]\n    \n    ytrain = train_data[targets].values\n    \n    #print(ytrain.shape)\n    yvalid = valid_data[targets].values\n    \n    \n    xtrain = list(np.array(train_data)[:,1]) # selecting new_comment_text and converting it to list\n    xvalid = list(np.array(valid_data)[:,1]) # __x__\n    \n    train_len = len(xtrain)\n    xfull = xtrain + xvalid\n    \n    print(\"fiting tfidf\")\n    tfv = TfidfVectorizer(ngram_range=(1,2),stop_words={\"english\"})\n    tfv.fit(xfull)\n    print(\"transforming tfidf\")\n    xtrain = tfv.transform(xtrain)\n    xvalid = tfv.transform(xvalid)\n    \n    tr_score = []\n    val_score = []\n    \n    print(\"start training\")\n    \n    model_1 = LogisticRegression()\n    model_1.fit(xtrain,ytrain[:,0])\n    \n    train_preds_1 = model_1.predict_proba(xtrain)[:,1]\n    valid_preds_1 = model_1.predict_proba(xvalid)[:,1]\n    \n    train_auc_1 = metrics.roc_auc_score(ytrain[:,0],train_preds_1)\n    valid_auc_1 = metrics.roc_auc_score(yvalid[:,0],valid_preds_1)\n    \n    tr_score.append(train_auc_1)\n    val_score.append(valid_auc_1)\n    \n    print(f\"fold = {fold}, train_auc_1={train_auc_1}, valid_auc-1={valid_auc_1}\")\n    \n    \n    model_2 = LogisticRegression()\n    model_2.fit(xtrain,ytrain[:,1])\n    \n    train_preds_2 = model_2.predict_proba(xtrain)[:,1]\n    valid_preds_2 = model_2.predict_proba(xvalid)[:,1]\n    \n    train_auc_2 = metrics.roc_auc_score(ytrain[:,1],train_preds_2)\n    valid_auc_2 = metrics.roc_auc_score(yvalid[:,1],valid_preds_2)\n    \n    tr_score.append(train_auc_2)\n    val_score.append(valid_auc_2)\n    \n    print(f\"fold = {fold}, train_auc_2={train_auc_2}, valid_auc_2={valid_auc_2}\")\n    \n    model_3 = LogisticRegression()\n    model_3.fit(xtrain,ytrain[:,2])\n    \n    train_preds_3 = model_3.predict_proba(xtrain)[:,1]\n    valid_preds_3 = model_3.predict_proba(xvalid)[:,1]\n    \n    train_auc_3 = metrics.roc_auc_score(ytrain[:,2],train_preds_3)\n    valid_auc_3 = metrics.roc_auc_score(yvalid[:,2],valid_preds_3)\n    \n    tr_score.append(train_auc_3)\n    val_score.append(valid_auc_3)\n    \n    print(f\"fold = {fold}, train_auc_3={train_auc_3}, valid_auc_3={valid_auc_3}\")\n    \n    \n    model_4 = LogisticRegression()\n    model_4.fit(xtrain,ytrain[:,3])\n    \n    train_preds_4 = model_4.predict_proba(xtrain)[:,1]\n    valid_preds_4 = model_4.predict_proba(xvalid)[:,1]\n    \n    train_auc_4 = metrics.roc_auc_score(ytrain[:,3],train_preds_4)\n    valid_auc_4 = metrics.roc_auc_score(yvalid[:,3],valid_preds_4)\n    \n    tr_score.append(train_auc_4)\n    val_score.append(valid_auc_4)\n    \n    print(f\"fold = {fold}, train_auc_4={train_auc_4}, valid_auc_4={valid_auc_4}\")\n    \n    model_5 = LogisticRegression()\n    model_5.fit(xtrain,ytrain[:,4])\n    \n    train_preds_5 = model_5.predict_proba(xtrain)[:,1]\n    valid_preds_5 = model_5.predict_proba(xvalid)[:,1]\n    \n    train_auc_5 = metrics.roc_auc_score(ytrain[:,4],train_preds_5)\n    valid_auc_5 = metrics.roc_auc_score(yvalid[:,4],valid_preds_5)\n    \n    tr_score.append(train_auc_5)\n    val_score.append(valid_auc_5)\n    \n    print(f\"fold = {fold}, train_auc_5={train_auc_5}, valid_auc_5={valid_auc_5}\")\n    \n    model_6 = LogisticRegression()\n    model_6.fit(xtrain,ytrain[:,1])\n    \n    train_preds_6 = model_6.predict_proba(xtrain)[:,1]\n    valid_preds_6 = model_6.predict_proba(xvalid)[:,1]\n    \n    train_auc_6 = metrics.roc_auc_score(ytrain[:,5],train_preds_6)\n    valid_auc_6 = metrics.roc_auc_score(yvalid[:,5],valid_preds_6)\n    \n    tr_score.append(train_auc_6)\n    val_score.append(valid_auc_6)\n    \n    print(f\"fold = {fold}, train_auc_6={train_auc_6}, valid_auc_6={valid_auc_6}\")\n    return tr_score,val_score","f211893a":"tr_score, val_score = run(df,0)","7cd4d282":"# Creating folds","f683a874":"# Training"}}