{"cell_type":{"dc887657":"code","57615618":"code","5480306a":"code","dec6cbca":"code","05cc925d":"code","0c15f16c":"code","ef5ba580":"code","e624ee14":"code","7fe0f6fa":"code","ad40d908":"code","64fcfbf9":"code","239217d5":"code","8980286e":"code","c49d8db8":"code","41507abb":"code","3014a908":"code","c6ddcaae":"code","778f2e8c":"code","cebf863f":"code","b19fd606":"code","b25c2bb8":"code","adc97d3c":"code","88e72802":"code","d8644fc0":"code","7ced6d65":"code","906ecb6c":"code","3eb51cdc":"code","57e7120e":"code","dffc959b":"code","0a000bde":"code","a125bab1":"code","3a86d32d":"code","17b3ae26":"code","5cbc11ec":"code","644ce09c":"code","b6f9a6e8":"code","eb7d52e5":"code","d25b4ee2":"code","00f8c0e3":"code","f4583a1e":"code","14573c4b":"markdown","67c9344e":"markdown","0e2a79c7":"markdown","aa9a2a43":"markdown","32afd5fa":"markdown","ab730167":"markdown","9102a496":"markdown","51e4ad0c":"markdown","07ad29a2":"markdown","1e593dea":"markdown","0c39d22c":"markdown","8ec592f6":"markdown","c69715bd":"markdown","fd31c280":"markdown","35c4d56b":"markdown","a1c11c78":"markdown","bbb7e8ed":"markdown","b872c71d":"markdown","ca9a676e":"markdown","8efe5806":"markdown","c5de6fba":"markdown","f955b990":"markdown","32986f9c":"markdown","8ca0f953":"markdown","7875b648":"markdown","4c532788":"markdown","655f7bba":"markdown","330a95bb":"markdown","1c6841a1":"markdown","ac023592":"markdown","3087c9db":"markdown","9578a62f":"markdown","3e8a2ac5":"markdown","7f10a262":"markdown","1aae8923":"markdown"},"source":{"dc887657":"# Packages for data analysis and linear algebra\nimport numpy as np\nimport pandas as pd\n\n# make http requests and webscrap\nimport requests\n\n# Plotting Libraries\nimport seaborn as sb\nfrom matplotlib import pyplot as plt\n\n# text processing\nimport string\nimport nltk\nfrom nltk.corpus import stopwords","57615618":"!pip install arxiv bs4","5480306a":"from bs4 import BeautifulSoup\nimport arxiv","dec6cbca":"# Function to download randomly created abstracts from the snarxiv\ndef get_snarXiv_abstracts(n_queries = 1):\n    # make a GET request to the snarXiv page\n    abstracts = []\n    for n in range(n_queries):\n        with requests.get('http:\/\/snarxiv.org\/') as response:\n            # Let's scrap the html document of the page\n            soup = BeautifulSoup(response.content)\n            # The abstracts are inside <p> tags which are\n            # inside of <div class = \"meta\"> tags.\n            abstracts.extend( map(lambda x:x.text,soup.select(\"dd > div.meta > p\")) )\n    return abstracts\n\n# Function to create a dataframe with the snarXiv abstracts\ndef make_snarXiv_dataframe(n_queries = 1):\n    summaries = get_snarXiv_abstracts(n_queries = n_queries)\n    summaries_length = len(summaries)\n    labels = ['snarXiv']*summaries_length\n    return pd.DataFrame(\n        data = {\n            'summary':summaries,\n            'label':labels\n        }\n    ).rename_axis('id')    ","05cc925d":"make_snarXiv_dataframe(n_queries = 1)","0c15f16c":"# Function to download the preprints metadata and abstracts from the arXiv\ndef get_arXiv_preprints(n_abstracts = 10):\n    results = arxiv.query(\n        query = 'cat:hep-th',\n        sort_by = 'submittedDate',\n        sort_order = 'descending',\n        max_results = n_abstracts\n    )\n    # Some of the results aren't actually in hep-th, so I will remove them\n    return [result for result in results if result['arxiv_primary_category']['term']=='hep-th']\n\n# Function to create a dataframe with the arXiv abstracts\ndef make_arXiv_dataframe(n_abstracts = 10):\n    results = get_arXiv_preprints(n_abstracts = n_abstracts)\n    arxiv_columns = [\n        'id',\n        'summary'\n    ]\n    arxiv_data = pd.DataFrame({key:result[key] for key in arxiv_columns} for result in results).set_index('id')\n    arxiv_data['label'] = 'arXiv'\n    return arxiv_data","ef5ba580":"make_arXiv_dataframe()","e624ee14":"data = pd.concat(\n    [\n        make_arXiv_dataframe(1000),\n        make_snarXiv_dataframe(100)\n    ]\n)","7fe0f6fa":"data.head()","ad40d908":"sb.countplot(data=data,x='label');","64fcfbf9":"data['summary length'] = data['summary'].apply(len)","239217d5":"data['summary wordcount'] = data['summary'].apply(\n    lambda x: len(\n        ''.join(c for c in x if c not in string.punctuation).split()\n    )\n)","8980286e":"data['avg wordlength'] = data['summary'].apply(\n    lambda x: np.mean(\n        [len(word) for word in x.split()]\n    )\n)","c49d8db8":"data['std wordlength'] = data['summary'].apply(\n    lambda x: np.sqrt(\n        np.var(\n            [len(word) for word in x.split()]\n        )\n    )\n)","41507abb":"data['punctuation'] = data['summary'].apply(\n    lambda x: len(\n        ''.join(c for c in x if c in string.punctuation)\n    )\n)","3014a908":"english_stopwords = stopwords.words('english')\ndata['stopwords'] = data['summary'].apply(\n    lambda x: len(\n        [word for word in x.split() if word.lower() in english_stopwords]\n    )\n)","c6ddcaae":"created_features = ['summary length','summary wordcount','avg wordlength','std wordlength','punctuation','stopwords']\nsb.pairplot(\n    data = data,\n    vars = created_features,\n    hue = 'label'\n);","778f2e8c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","cebf863f":"scaler = StandardScaler().fit(data[created_features])\npca = PCA().fit(\n    scaler.transform(\n        data[created_features]\n    )\n)","b19fd606":"plt.figure(figsize=(12,6))\nsb.barplot(\n    y = pca.explained_variance_ratio_,\n    x = [f'Component {n+1}' for n in range(pca.n_components_) ]\n)\nplt.ylabel('Ratio of explained variance');","b25c2bb8":"data_pca = pca.transform( scaler.transform(data[created_features]) )","adc97d3c":"plt.figure(figsize=(8,6));\nsb.scatterplot(x = data_pca[:,0],y = data_pca[:,1],hue=data['label'],cmap='plasma');\nplt.xlabel('First principal component');\nplt.ylabel('Second Principal Component');\nplt.gca().set_aspect(1)","88e72802":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix, classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline","d8644fc0":"X_train, X_test, y_train, y_test = train_test_split(\n    data['summary'], data['label'], test_size=0.25,random_state = 23)","7ced6d65":"fig,[ax1,ax2] = plt.subplots(ncols=2,figsize = (10,5),sharey=True)\nsb.countplot(x = y_train,ax = ax1)\nax1.set_title('Training')\nsb.countplot(x = y_test,ax = ax2)\nax2.set_title('Test');\nfig.suptitle('Distribution of classes\\n in the train and test sets\\n\\n');","906ecb6c":"def text_process(mess):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in mess if char not in string.punctuation]\n\n    # Join the characters again to form the string.\n    nopunc = ''.join(nopunc)\n    \n    # Now just remove any stopwords\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","3eb51cdc":"pipeline = Pipeline(\n    [\n        ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n        ('tfidf', TfidfTransformer()),                    # integer counts to weighted TF-IDF scores\n        ('classifier', MultinomialNB()),                  # train on TF-IDF vectors w\/ Naive Bayes classifier\n    ]\n).fit(X_train,y_train)","57e7120e":"plot_confusion_matrix(pipeline,X_test,y_test)","dffc959b":"#Make predictions in the test set\ny_predictions = pipeline.predict(X_test)","0a000bde":"import ipywidgets as widgets\nfrom ipywidgets import Layout","a125bab1":"header = widgets.HTML(\n    '<h1 style=\"text-align:center\">arXiv vs snarXiv (a poor man\\'s edition)<\/h1>'\\\n    '<h4 style=\"text-align:center\">Can you beat an AI at distinguishing real science papers from bullshit?<\/h4>'\n)","3a86d32d":"start_button = widgets.Button(\n    description = 'Play !',\n    style = {'button_color':'lightblue'}\n)","17b3ae26":"summary_widget = widgets.HTMLMath('')\nnotification_format_str =\"\"\"\n<div style=\"text-align:center\">\n<h3>You were:<\/h3>\n<h2 style=\"color:{color_user}\": red\">{result_user}!<\/h2>\n<h3>The A.I. was:<\/h3>\n<h2 style=\"color:{color_AI}\": red\">{result_AI}!<\/h2>\n<br><br>\n<a href=\"{paper_URL}\">{paper_URL}<\/a>\n<\/div>\n\"\"\"","5cbc11ec":"choices = {\n    'Real paper':'arXiv',\n    'BullShit!!':'snarXiv'\n}\nchoice_buttons = widgets.HBox(\n    children = [\n        widgets.Button(\n            description = choice,\n            disabled = True,\n            layout = Layout(visibility ='hidden'),\n            style = {'button_color':'lightblue'}\n        ) for choice in choices\n    ]\n)\nlabel_choices = [choices[child.description] for child in choice_buttons.children]","644ce09c":"game = widgets.VBox(\n    children = [\n        header,\n        start_button,\n        summary_widget,\n        choice_buttons\n    ],\n    layout = widgets.Layout(\n        align_items='center'\n    )\n)","b6f9a6e8":"game_data = []","eb7d52e5":"def getPaperFromTestSet():\n    paper_id = np.random.choice(X_test.index)\n    paper = data.loc[paper_id]\n    game_data.append(\n        dict(\n            paper_id = paper_id,\n            AI_answer = y_predictions[ y_test.index.get_loc(paper_id) ],\n            correct_answer = y_test.loc[paper_id],\n        )\n    )\n    return paper_id","d25b4ee2":"import time\n# Callback when the start button is clicked\ndef on_start_button_clicked(b):\n    b.layout.visibility = 'hidden'\n    b.set_trait('disabled',True)\n    paper_id = getPaperFromTestSet()\n    summary_widget.value = '<p>{}<\/p>'.format( data['summary'].loc[paper_id] )\n    for child in choice_buttons.children:\n        child.layout.visibility = 'visible'\n        child.set_trait('disabled',False)\n    return\n\nstart_button.on_click(on_start_button_clicked)\n\n# Callback when a choice is made\ndef on_choice_button_clicked(b):\n    chosen_label = choices.get(b.description)\n    #add answer to game_data\n    if game_data:\n        for child in choice_buttons.children:\n            child.set_trait('disabled',True)\n        # Add the chosen answer to game data\n        game_data[-1].update(user_answer = chosen_label)\n        #Make the background of the right(wrong) answer green(red)\n        correct_button_index = label_choices.index(game_data[-1]['correct_answer'])\n        choice_buttons.children[correct_button_index].style.button_color = 'green'\n        choice_buttons.children[(1+correct_button_index)%2].style.button_color = 'red'\n        results_map_dict = {\n            label_choices[correct_button_index] : ('green','Right'),\n            label_choices[(correct_button_index+1)%2] : ('red','Wrong')\n        }\n        color_user,result_user = results_map_dict[chosen_label]\n        color_AI,result_AI = results_map_dict[game_data[-1]['AI_answer']]\n        summary_widget.value = notification_format_str.format(\n            color_user=color_user,\n            result_user=result_user,\n            color_AI=color_AI,\n            result_AI=result_AI,\n            paper_URL = game_data[-1]['paper_id']\n        )\n        time.sleep(3)\n        #get another paper from the test data set\n        for child in choice_buttons.children:\n            child.style.button_color = 'lightblue'\n        paper_id = getPaperFromTestSet()\n        summary_widget.value = '<p>{}<\/p>'.format( data['summary'].loc[paper_id] )\n        for child in choice_buttons.children:\n            child.set_trait('disabled',False)\n\nfor children in choice_buttons.children:\n    children.on_click(on_choice_button_clicked)","00f8c0e3":"game","f4583a1e":"# # Dataframe with the results from each round\n# game_results = pd.DataFrame(game_data)\n\n# # I drop the last row, which has a NaN value for user_answer, since it is a round that has not been played yet\n# game_results.dropna(inplace=True)\n\n# # make a column with 1 for a right guess and 0 for a wrong one\n# game_results['user_wins'] = (game_results['user_answer'] == game_results['correct_answer']).astype(int)\n# game_results['AI_wins'] = (game_results['AI_answer'] == game_results['correct_answer']).astype(int)\n\n# # Take the average of user_wins and AI_wins\n# cols = ['user_wins','AI_wins']\n# game_summary = game_results[cols].mean() * 100\n\n# #Make the Figure\n# plt.figure(figsize=(10,10))\n# sb.barplot(x=game_summary.index,y = game_summary)\n# plt.title('AI vs human player');\n# plt.ylabel('% of right answers');","14573c4b":"# Bonus: arXiv vs snarXiv game (a poor man's edition)\n\nMake a game with ipywidgets to mimic the arXiv vs snarXiv game. You have to guess if an abstract in the test set comes from the arXiv of the snarXiv","67c9344e":"# Performance of the Naives Bayes classifier","0e2a79c7":"# arXiv vs snarXiv\n\n## Intro\n\nThe [arXiv](https:\/\/arxiv.org\/) (pronunced as archive) is an open-access repository of electronic preprints ran by the university of Cornell. It hosts preprints in diverse fields of physics, mathematics, statistics, computer science...\n\nThe [snarXiv](http:\/\/snarxiv.org\/) is a page that mocks the real [arXiv](https:\/\/arxiv.org\/) and generates a list of random abstracts for fake preprints.\n\nThis notebook is inspired by the game site [arXiv VS snarXiv](http:\/\/snarxiv.org\/vs-arxiv\/), where your objective is to read the titles and distinguish which one of them is for real (believe, it is not easy at all ;) )\n\n## Task\n\nThe task is to train a model that can distinguish real arXiv abstracts from those in the snarXiv. Since the category of the papers that the snarXiv mocks is theoretical high energy physics (hep-th) I will compare only with papers from the arXiv in the same category.\n\nThe contents of the notebook are the following\n\n- Package loading\n- Data adquisition\n- Some Feature engineering\n- Training of a Naive Bayes Multinomial classifier\n- Testing the performance of the classifier\n\nAt the end of the notebook you will find a game made with ipywidgets that mimics the [arXiv VS snarXiv](http:\/\/snarxiv.org\/vs-arxiv\/) site.","aa9a2a43":"Split the data","32afd5fa":"Define an analyzer function for the bag of words. This one is taken from the course of machine learning and data science with python by Jose Portilla (in Udemy). It removes punctuation and stopwords.","ab730167":"### Construct the game widget","9102a496":"# Time to see who wins\n\nRun the following cell only after you have played a few rounds to see how many times you were right and compare with the AI","51e4ad0c":"Check the ratio of snarXiv vs arXiv preprints","07ad29a2":"# Package Loading","1e593dea":"#### Total length of the abstract","0c39d22c":"#### Let's see what the data looks like after being transformed to principal components","8ec592f6":"It looks that it performs really good.","c69715bd":"The dataframes for the arxiv and snarxiv papers have the columns summary and label.\nSummary is the abstract of the preprint and label wether it is arXiv or snarXiv.\n\nThe index of the entries is the 'id', which for the snarXiv papers is just an integer number, but, for\nthe real preprints, is the arXiv uri of the preprint","fd31c280":"#### Average word length","35c4d56b":"## Some exploratory data analysis to see if the new created features are of any help","a1c11c78":"### Data variable to keep the game results","bbb7e8ed":"# Feature engineering\n\nI will add new columns to the dataframe to try and find features that help in classifying the preprints","b872c71d":"It looks that the data from the real arXiv papers has more spread for the values of the features (in fact, to higher values). The average value for the length, wordcount and stopwords count is higher for the real arXiv papers too. However, there is a big overlap between the 2 datasets. I will try to apply principal component analysis to the data to see if it can help in separating the categories","ca9a676e":"# Naive Bayes Classification","8efe5806":"#### Total number of punctuation symbols","c5de6fba":"It doesn't look like the features I introduced are of any help. I will classify with the multinomial Naive Bayes method","f955b990":"#### Plot of the ratio of the components to the explained variance","32986f9c":"I define some functions for downloading the data from the arXiv and creating a dataframe.","8ca0f953":"#### Total word count","7875b648":"I define some functions for downloading the data from the snarXiv and creating a dataframe.","4c532788":"Define a pipeline that combines the bagOfWords, tf-idf, and naive Bayes classifier.","655f7bba":"### Define the component widgets for the game","330a95bb":"## PC Analysis of the created features","1c6841a1":"#### Total number of stopwords","ac023592":"### Components callbacks","3087c9db":"#### word length standard deviation","9578a62f":"Import ipywidgets","3e8a2ac5":"Download many preprints from both repositories and concatenate in a dataframe. The arguments of the function calls are set to obtain fake and real preprints in approximately the same proportion.","7f10a262":"# The game, ready to be played.\n\nPlay as many rounds as you want. Then you can see the results playing against the A.I.","1aae8923":"# Data adquisition\n\nThe real arXiv web page has an API that allows you to make queries\nand download the abstracts and metadata of the preprints. There is a nice\n[python wrapper](https:\/\/github.com\/lukasschwab\/arxiv.py) for this API developed by \n[@lukasschwab](https:\/\/github.com\/lukasschwab) ( I [myself](https:\/\/github.com\/Miguel-ASM) \nalso made a minor contribution ;) ) which makes querying the arXiv far easier.\n\nHowever, to automatically download the abstracts from the snarXiv one has to make some webscrapping. The main page of the [snarxiv]('http:\/\/snarxiv.org\/') lists \n5 randomly generated abstracts every time you click the refresh button. Using the Chrome dev tools I could figure out that the abstracts text are located in the html document like this\n\n```html\n<dd>\n    <div class=\"meta\">\n        .....\n        <p>\n            [abstract text goes here]\n        <\/p>\n    <\/div>\n<\/dd>\n```\n\nWith this knowledge, it is very easy to extract the abstracts with [bs4](https:\/\/www.crummy.com\/software\/BeautifulSoup\/bs4\/doc\/)\n\n```python\nsoup = BeautifulSoup(html_document)\nabstracts = [abstract.text for abstract in soup.select(\"dd > div.meta > p\")]\n```\n\nI start by installing\/importing the arXiv API wrapper for python and bs4"}}