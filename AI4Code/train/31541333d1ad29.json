{"cell_type":{"6947e2d6":"code","bcc53c07":"code","d05fdce5":"code","e36466e4":"code","91f464d4":"code","8532e298":"code","01310277":"code","49dc1ce5":"code","8cc603d5":"code","c6cd6525":"code","4e5eaafc":"code","3d9a9d93":"code","8d9f8a0c":"code","aad18df5":"code","07cedfc1":"code","3c8cf8b9":"code","ece57f36":"code","e425751e":"code","3c921108":"code","71b8293c":"code","3e0e3c8c":"code","9094af41":"code","c40d435b":"code","0dcc7d27":"code","182d4d3a":"code","1336d85c":"code","c7c34acc":"code","152e4243":"code","b850a406":"code","33f731c8":"markdown","189b21ba":"markdown","b4596a0b":"markdown","6deaf7be":"markdown","aa76d83e":"markdown","d3fc446f":"markdown","e9a7a1ad":"markdown","1711f6c2":"markdown","478f54dc":"markdown","e9bea81c":"markdown","91e5f67b":"markdown","c175c206":"markdown","cc06a1f9":"markdown"},"source":{"6947e2d6":"# basics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom os.path import join\nimport sys\nfrom sklearn.model_selection import train_test_split\n# pytorch model\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\n\n# pyTorch Lightning\n\nimport pytorch_lightning as pl\nfrom torchmetrics import Accuracy\n\n# image processing\n\nfrom skimage.io import imread\nfrom scipy.ndimage import zoom # image resizing 3D\nfrom skimage.transform import resize\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n","bcc53c07":"! mkdir my-train-data\nimport zipfile\nwith zipfile.ZipFile('..\/input\/rsnabraintumorclassification-64-256-256\/1MS8S5qFadxAqPCrd0MtKts4ciGH5W1L-', 'r') as zip_ref:\n    zip_ref.extractall('my-train-data')\n    ","d05fdce5":"! rm .\/my-train-data\/00109.pt .\/my-train-data\/00123.pt .\/my-train-data\/00709.pt","e36466e4":"INPUT_FOLDER = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\nINPUT_FOLDER_PNG = '..\/input\/rsna-miccai-png'\n\nlabels_df = pd.read_csv(join(INPUT_FOLDER, 'train_labels.csv'))\nlabels_df = labels_df.sort_values('BraTS21ID')\npatients_train = os.listdir('my-train-data')\npatients_test = os.listdir(join(INPUT_FOLDER, 'test'))\n# removing examples with errors mentioned in discussion\n# erronous examples\nerror_examples = ['00109', '00123', '00709']\n\n# remove from directory list\n# for error in error_examples: patients_train.remove(error)\nlabels_df = labels_df[[ x not in [int(y) for y in error_examples ] for x in labels_df.BraTS21ID ]]\npatients_train.sort()\n\nprint(f'Number of train data : {len(patients_train)}\\nNumber of test data : {len(patients_test)}')","91f464d4":"labels_df['patient_folder'] = patients_train","8532e298":"labels_df.head()","01310277":"train_info = pd.DataFrame({'patient_id': patients_train, 'patient_label': labels_df.MGMT_value})\n\ntrain_info, val_info = train_test_split(train_info, test_size=0.18,\n                                        stratify=train_info.patient_label,\n                                        random_state=42\n                                       )\nprint(train_info.head())\nprint('------')\nprint(val_info.head())","49dc1ce5":"IMAGE_DEPTH = 64\nIMAGE_SIZE = [256, 256]\nIMAGE_DIMS = [IMAGE_DEPTH, *IMAGE_SIZE]\nBATCH_SIZE = 2\nGET_ITEM_ACCESS = 0\nPRETRAINED_PATH = '..\/input\/medicalnet-pretrained-weights\/resnet_34.pth'\nclass MRITypes:\n    flair = 'FLAIR'\n    tw1ce = 'T1wCE'\n    t1w = 'T1w'\n    t2w = 'T2w'\n    \ndef get_types():\n    return [ MRITypes.flair, MRITypes.tw1ce, MRITypes.t1w, MRITypes.t2w]\n    \ndef get_index(mri_type : MRITypes):\n    return get_types().index(mri_type)","8cc603d5":"# load scans in a folder\ndef load_scan(path):\n    slices = [ pydicom.read_file(join(path, slice_file))\n                    for slice_file in os.listdir(path)]\n    \n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n    \n    return slices\n\ndef load_scan_png(path):\n    sorted_filenames = sorted(os.listdir(path), key=lambda x: int(x[:-4][6:]))\n    slices = [ imread(join(path, slice_file), as_gray=True) for slice_file in sorted_filenames]\n    \n    return slices","c6cd6525":"#-------------------------------------------------------------------------------------------------------------------------\n# preprocessing png\ndef preprocess_png_image(image):\n    # resize to IMAGE_SHAPE\n    trans_image = np.array([ resize(x, IMAGE_SIZE) for x in image ])\n    \n    # set image depth to IMAGE_DEPTH\n    current_depth = trans_image.shape[0]\n    trans_image = zoom(trans_image, (IMAGE_DEPTH\/current_depth, 1, 1))\n    \n    # turn image to pytorch tensor\n    trans_image = torch.tensor(trans_image, dtype=torch.float32)\n    \n    # normalize images to values between [0, 1]\n    trans_image \/= 255\n    \n    return trans_image\n#-------------------------------------------------------------------------------------------------------------------------\n# preprocessing function\n\ndef preprocess_dicom_image(image):\n    \n    # remove all black images\n    trans_image = [ x for x in image if np.any(x.pixel_array != 0)]\n    \n    # apply voi lut (which is a filter that makes it easier to spot things)\n    trans_image = [ apply_voi_lut(x.pixel_array, x) for x in trans_image]\n    \n    # reverse image if monochrome (some images are inverted)\n    trans_image = [ np.amax(x) - x if dicom.PhotometricInterpretation == \"MONOCHROME1\" else x\n                       for x, dicom in zip(trans_image, image) ]\n  \n\n    # resize images to IMAGE_SIZE and discard images that are all black\n    trans_image = np.array([ resize(x, IMAGE_SIZE) for x in trans_image ])\n    \n    \n    # set image depth to IMAGE_DEPTH\n    current_depth = trans_image.shape[0]\n    trans_image = zoom(trans_image, (IMAGE_DEPTH\/current_depth, 1, 1))\n    \n    \n    # normalize images using the min max approach to make in range [0, 1]\n    \n    trans_image = [ x - np.min(x) for x in trans_image]\n    trans_image = [ x \/ np.max(x) for x in trans_image]\n    \n    \n    trans_image = torch.tensor(trans_image, dtype=torch.float32)\n    return trans_image\n#-------------------------------------------------------------------------------------------------------------------------\n","4e5eaafc":"# dataset definition\nclass TumorDataset(Dataset):\n    def __init__(self, patient_ids, patient_labels, transform, load_function, input_folder, split):\n        super().__init__()\n        self.patient_ids = patient_ids\n        self.patient_labels = patient_labels if not (split == 'test') else None\n        self.transform = transform\n        self.load_function = load_function\n        self.input_folder = input_folder\n        self.split = split   \n    \n    def __len__(self):\n        return len(self.patient_ids)\n    \n    def __getitem__(self, idx):\n        current_label = self.patient_labels[idx] if self.split == 'train' else None\n        # get folder of patient\n        patient_folder = join(self.input_folder, self.split, self.patient_ids[idx])\n        # read each of T1, Tw1ce, T2w, FLAIR\n        # add them in patient_scans.\n        patient_scans = []\n        \n        for scan_type in get_types():\n            # read image\n            current_scan = self.load_function(join(patient_folder, scan_type))\n            \n            # apply preprocessing\n            current_scan = self.transform(current_scan)\n            \n            # add color channel to 3D image\n            current_scan = current_scan.unsqueeze(0)\n            \n            # add image to array\n            patient_scans.append(current_scan)\n        \n        if self.split == 'train':\n            return (\n                 torch.stack(patient_scans),\n                 torch.tensor(current_label, dtype=torch.float32)\n                )\n        else:\n            return (\n                torch.stack(patient_scans)\n                )\n\n#---------------------------------------------------------------------\nclass PTDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        filename = join('my-train-data', self.x[idx])\n        patient_scans = torch.load(filename)\n        patient_scans = patient_scans.type(torch.FloatTensor)\n        patient_scans \/= 255\n        return (\n            patient_scans,\n            torch.tensor(self.y[idx], dtype=torch.float32)\n        )","3d9a9d93":"def load_dataset(patient_ids, patient_labels, image_type, split):\n    transform, load_fn, input_folder = None, None, None\n    if (image_type.lower() == 'png'):\n        transform = preprocess_png_image\n        load_fn = load_scan_png\n        input_folder = INPUT_FOLDER_PNG\n    if (image_type.lower() == 'dicom' or image_type.lower() == 'dcm'):\n        transform = preprocess_dicom_image\n        load_fn = load_scan\n        input_folder = INPUT_FOLDER\n        \n    return TumorDataset(patient_ids, patient_labels, transform, load_fn, input_folder, split)","8d9f8a0c":"# Train Data\ntrain_dataset = PTDataset(train_info.patient_id.values,\n                             train_info.patient_label.values)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, num_workers=1)\n\n# Validation Data\nval_dataset = PTDataset(val_info.patient_id.values,\n                           val_info.patient_label.values)\n\nval_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=1)\n\n# Test Data\ntest_dataset = load_dataset(patients_test,\n                           None,\n                           image_type='dcm', \n                           split='test')\n\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=1)","aad18df5":"def plot_slices(image):\n    \n    fig, axes = plt.subplots(8, 8, figsize=(50,50))\n    i = 0\n    for row in axes:\n        for col in row:\n            col.imshow(image[i, :, :], cmap='gray')\n            i += 1","07cedfc1":"x = next(iter(test_dataloader))\nprint(f'size of x : {x.size()}')\nprint(f'size of x[:,0] : {x[:,0].size()}')\nx_show = x[:, 1][1].squeeze().numpy()\nt = plot_slices(x_show)","3c8cf8b9":"x, y = next(iter(train_dataloader))\nprint(f'size of x : {x.size()}')\nprint(f'size of x[:,0] : {x[:,0].size()}')\nx_show = x[:, 1][1].squeeze()\nt = plot_slices(x_show.numpy())","ece57f36":"input_monaipath = '\/kaggle\/input\/monai-v060-deep-learning-in-healthcare-imaging\/MONAI-0.7.0'\nmonaipath = '\/kaggle\/monai'\ninput_medicalnet_path = '..\/input\/medicalnet'\nmedicalnet_path = '\/kaggle\/medicalnet'","e425751e":"! mkdir -p {monaipath}\n! cp -r {input_monaipath}\/* {monaipath}\n! mkdir -p {medicalnet_path}\n! cp -r {input_medicalnet_path}\/* {medicalnet_path}","3c921108":"sys.path.append(monaipath)\n# sys.path.append(medicalnet_path)\n\n\nfrom monai.networks.nets.efficientnet import EfficientNetBN\n# from models.resnet import resnet18 , resnet34","71b8293c":"def remove_last_n_layers(model, n):\n    # removes last 2 layer from model and\n    # returns the dimension of last layer\n    \n    components_list = list(model.children())\n    \n    return nn.Sequential(*(components_list[:-n]))\n\ndef remove_last_2_layers(model):\n    return remove_last_n_layers(model, 2)","3e0e3c8c":"def build_model():\n#     model = resnet34(sample_input_D=1, sample_input_H=256,\n#                      sample_input_W=256, num_seg_classes=1)\n#     net_dict = model.state_dict()\n#     pretrained_weights = torch.load(PRETRAINED_PATH)\n#     pretrained_weights = { \n#                             k.replace(\"module.\", \"\"): v \n#                             for k, v in pretrained_weights['state_dict'].items() \n#                             if k.replace(\"module.\", \"\") in net_dict.keys()\n#               }\n#     net_dict.update(pretrained_weights)\n#     model.load_state_dict(net_dict)\n#     model.conv_seg = nn.Sequential(\n#                             nn.AdaptiveAvgPool3d(output_size=1),\n#                             nn.Dropout(p=0.2, inplace=False)\n#                             )\n    model = EfficientNetBN('efficientnet-b2', spatial_dims=3, in_channels=1,\n                           num_classes=1, pretrained=False)\n    \n    model = remove_last_2_layers(model)\n    return model\n\nclass AllTypesNet(pl.LightningModule):\n    def __init__(self, num_features, lr=0.001):\n        super().__init__()\n        \n        self.lr = lr\n        self.train_acc = Accuracy()\n        self.val_acc = Accuracy()\n        \n        self.classifiers = nn.ModuleList([build_model()\n                                                for _ in get_types()])\n        \n        self.fc = nn.Linear(in_features=4*num_features, out_features=1)\n        \n        \n        \n    def forward(self, x):\n#         print(f'size of 1 element of x : {x[:,0].size()}')\n#         print(f'size of x : {x.size()}')\n        pred_list = [ classifier(x[:, i]).squeeze() for i, classifier in enumerate(self.classifiers)]\n#         print(f'size of cat output : {torch.cat(pred_list, -1).size()}')\n#         print(f'pred_list[0] size : {pred_list[0].size()}')\n        pred = self.fc(torch.cat(pred_list, -1))\n        \n        \n        return pred\n    \n    def training_step(self, batch, batch_idx):\n        \n        x, y = batch\n        \n        \n        y_pred = self(x).view(-1)\n        \n        assert not bool(torch.any(torch.isnan(y_pred)).item()), f'Model outputs nan on Epoch {self.current_epoch}, batch {batch_idx}' # assert error msg\n    \n        loss = F.binary_cross_entropy_with_logits(y_pred, y)\n#         print(f'Y : {y}')\n#         print(f'Y pred: {y_pred}')\n        self.train_acc(torch.sigmoid(y_pred), y.type(torch.cuda.LongTensor))\n\n        return {'loss': loss, 'predictions': None }\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        \n        y_pred = self(x).view(-1)\n        \n        loss = F.binary_cross_entropy_with_logits(y_pred, y)\n        \n        self.val_acc(torch.sigmoid(y_pred), y.type(torch.cuda.LongTensor))\n        \n        \n        return {'loss': loss, 'predictions': None }\n    \n    def training_epoch_end(self, training_step_outputs):\n        print(f'Epoch {self.current_epoch} train accuracy : {round(self.train_acc.compute().item() * 100, 2)}%')\n        self.train_acc.reset()\n        \n    \n    def validation_epoch_end(self, validation_step_outputs):\n        print(f'Epoch {self.current_epoch} val accuracy : {round(self.val_acc.compute().item() * 100, 2)}%')\n        self.val_acc.reset()\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n        return optimizer\n","9094af41":"model = build_model()\nmem_params = sum([param.nelement()*param.element_size() for param in model.parameters()])\nmem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\nmem = (mem_params + mem_bufs) \/ 2**20 # in Megabytes\nmem * 4","c40d435b":"from tqdm import tqdm\nfor data in tqdm(train_dataloader):\n    x , y = data\n    \n    assert not bool(torch.any(torch.isnan(x)).item())\n    ","0dcc7d27":"num_features = EfficientNetBN('efficientnet-b2', spatial_dims=3, in_channels=1,\n                           num_classes=1, pretrained=False)._fc.in_features\nnum_features","182d4d3a":"model = AllTypesNet(num_features, 0.025)\n\ntrainer = pl.Trainer(gpus=1, precision=16,\n                     max_epochs=3, log_every_n_steps=150,\n                    gradient_clip_val=0.4, accumulate_grad_batches=2)\ntrainer.fit(model,\n            train_dataloaders=train_dataloader,\n            val_dataloaders=val_dataloader)","1336d85c":"y_pred = trainer.predict(model, test_dataloader)","c7c34acc":"preds = []\nfor pred_list in y_pred:\n    for element in pred_list:\n        preds.append(element.item())","152e4243":"# Applying sigmoid\npreds = 1 \/ ( 1 + np.exp(-1 * np.array(preds)))","b850a406":"submission = pd.DataFrame({'BraTS21ID': patients_test,\n                           'MGMT_value': preds})\nsubmission.to_csv('submission.csv', index=False)","33f731c8":"## **Dataset for my already preprocessed data**","189b21ba":"## **Check Model size to make sure there's enough memory in GPU**","b4596a0b":"# Check that there are no nan in train dataloader","6deaf7be":"The following are my preprocessing for images of different types.\n","aa76d83e":"# Importing Data","d3fc446f":"As preprocessing took a long time, I preprocessed all the data, and uploaded it as a Kaggle Dataset to train faster.","e9a7a1ad":"# **Reading filenames**","1711f6c2":"# **Load image functions**","478f54dc":"# **Split Data to train and validation**","e9bea81c":"# Making the train dataset class","91e5f67b":"# **Constant & Enums**","c175c206":"## **Trying out dataloaders**","cc06a1f9":"# Adding Libraries to download 3D Models"}}