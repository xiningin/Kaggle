{"cell_type":{"18cf9cad":"code","57c3c9ea":"code","993c95a4":"code","5309db60":"code","88c49072":"code","657ad68a":"code","c2bf1596":"code","8a123bd6":"code","285bc61b":"code","60bbc1f2":"code","ebe5988f":"code","6f4fe0c6":"code","22a839d4":"markdown","5f770261":"markdown"},"source":{"18cf9cad":"import cv2\nimport os\nimport glob, random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPClassifier\nfrom keras.preprocessing import image\nfrom sklearn.externals.joblib import dump, load\n\ndef accuracy(confusion_matrix):\n   diagonal_sum = confusion_matrix.trace()\n   sum_of_all_elements = confusion_matrix.sum()\n   return diagonal_sum \/ sum_of_all_elements\n\ndef fd_histogram(image):\n    bins=16\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n    cv2.normalize(hist, hist)\n    return hist.flatten()\n\ndef fd_hu_moments(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n    return feature\n\ndef Get(link):\n    data = []\n    label = []\n    for i in os.listdir(link):\n        label_now=i\n        for j in glob.glob(link + \"\/\" + i + \"\/*.jpg\"):\n            image = cv2.imread(j)\n            fv_hist=fd_histogram(image)\n            fv_hu=fd_hu_moments(image)\n            global_feature=np.hstack([fv_hist, fv_hu])\n            data.append(global_feature)\n            label.append(label_now)\n    return data, label\npathtrain=\"\/kaggle\/input\/data\/data\/train\"\npathtest=\"\/kaggle\/input\/data\/data\/test\"","57c3c9ea":"img_list = glob.glob(os.path.join(pathtrain, '*\/*.jpg'))\n\nfor i, img_path in enumerate(random.sample(img_list, 6)):\n    img = image.load_img(img_path, target_size=(300, 300))\n    img = image.img_to_array(img, dtype=np.uint8)\n\n    plt.subplot(2, 3, i+1),\n    plt.imshow(img.squeeze()),\n    plt.xticks([]),\n    plt.yticks([])\nplt.show()","993c95a4":"x_train, y_train=Get(pathtrain)\nprint(\"Successfully retrieved train data\")\ny_train=np.array(y_train)\nx_train=np.array(x_train)\nprint(\"Training size: \", len(x_train))\nprint(x_train.shape)\nprint(y_train.shape)\n\nx_test, y_test=Get(pathtest)\nprint(\"Successfully retrieved test data\")\ny_test=np.array(y_test)\nx_test=np.array(x_test)\nprint(\"Training size: \", len(x_test))\nprint(x_test.shape)\nprint(y_test.shape)","5309db60":"model = MLPClassifier(hidden_layer_sizes=(16, 8),\n                       learning_rate_init=0.001,\n                       max_iter=10,\n                       activation = 'relu',\n                       solver='adam',\n                       random_state=42,\n                       verbose=0)\n\nN_TRAIN_SAMPLES = x_train.shape[0]\nN_EPOCHS = 10\nN_BATCH = 64\nN_CLASSES = np.unique(y_train)\n\nscores_train = []\nscores_test = []\n\n# EPOCH\nepoch = 1\nwhile epoch <= N_EPOCHS:\n    print('epoch: ', epoch)\n    # SHUFFLING\n    random_perm = np.random.permutation(x_train.shape[0])\n    mini_batch_index = 0\n    while True:\n        # MINI-BATCH\n        indices = random_perm[mini_batch_index:mini_batch_index + N_BATCH]\n        model.partial_fit(x_train[indices], y_train[indices], classes=N_CLASSES)\n        mini_batch_index += N_BATCH\n\n        if mini_batch_index >= N_TRAIN_SAMPLES:\n            break\n\n    # SCORE TRAIN\n    scores_train.append(model.score(x_train, y_train))\n\n    # SCORE TEST\n    scores_test.append(model.score(x_test, y_test))\n\n    epoch += 1\n\n\"\"\" Plot \"\"\"\nfig, ax = plt.subplots(2, sharex=True, sharey=True)\nax[0].plot(scores_train)\nax[0].set_title('Train')\nax[1].plot(scores_test)\nax[1].set_title('Test')\nfig.suptitle(\"Accuracy over epochs\", fontsize=14)\nplt.show()","88c49072":"import matplotlib.pyplot as plt\n\ny_pred = model.predict(x_test)\nprint(y_pred.shape)","657ad68a":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \n\ncm = confusion_matrix(y_pred, y_test)\n\nprint(\"\\nTraining Accuracy: \", model.score(x_train, y_train)*100)\nprint(\"\\nValid Accuracy: \", model.score(x_test, y_test)*100)\nprint('Confusion Matrix:')\nprint (classification_report(y_test, y_pred))","c2bf1596":"dump(model, 'fruit_ANN.joblib')\nprint('Model saved!')","8a123bd6":"loaded_model = load('fruit_ANN.joblib')\nprint('model loaded!')","285bc61b":"print(loaded_model)","60bbc1f2":"link= \"\/kaggle\/input\/dataset\/dataset\"\nfor j in glob.glob(link + \"\/*.jpg\"):\n    image = cv2.imread(j)\n    image = cv2.resize(image, (100, 100))\n    fv_his = fd_histogram(image)\n    fv_hu = fd_hu_moments(image)\n    globals_feature = np.hstack([fv_his, fv_hu])\n    globals_feature = globals_feature.reshape(1, -1)\n    prediction = loaded_model.predict(globals_feature)\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    plt.xlabel(prediction)\n    plt.xticks([])\n    plt.yticks([])\n    plt.show()\n","ebe5988f":"link= \"\/kaggle\/input\/test\/test\"\nfor j in glob.glob(link + \"\/*.jpg\"):\n    image = cv2.imread(j)\n    image = cv2.resize(image, (100, 100))\n    fv_his = fd_histogram(image)\n    fv_hu = fd_hu_moments(image)\n    globals_feature = np.hstack([fv_his, fv_hu])\n    globals_feature = globals_feature.reshape(1, -1)\n    prediction = loaded_model.predict(globals_feature)\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    plt.xlabel(prediction)\n    plt.xticks([])\n    plt.yticks([])\n    plt.show()\n","6f4fe0c6":"# v\u1eady \u0111\u1ed1i v\u1edbi t\u1eadp data t\u1eeb fruit 360 c\u1ee7a kaggle th\u00ec h\u1ea7u nh\u01b0 model predict ch\u00ednh x\u00e1c h\u1ebft \n# c\u00f2n \u0111\u1ed1i v\u1edbi t\u1eadp data l\u1ea5y t\u1eeb gg th\u00ec 1 s\u1ed1 tr\u00e1i model predict sai\n","22a839d4":"## TEST WITH DATASET","5f770261":"# TEST WITH GOOGLE PICTURES"}}