{"cell_type":{"0e3c5926":"code","4910e818":"code","f9e74362":"code","6a6cf2e0":"code","e96cf001":"code","e44f38b8":"code","b7c4d122":"code","0d92f52c":"code","4bfea903":"code","7524ebcf":"code","f23faf4c":"code","e2421003":"code","d28f2caf":"code","3b53bbcf":"code","b07f6655":"code","8585c37f":"code","e8c446a4":"code","72c50d74":"code","ba8672ce":"code","aea2684c":"code","895a20e1":"code","518e9ad9":"code","8a8d9b94":"code","d4d82c23":"markdown","17dfbf28":"markdown","78111b0b":"markdown","c40fde8b":"markdown","baece7b6":"markdown","c4eb5455":"markdown","3a1d0036":"markdown","242cb27e":"markdown","71a62d5d":"markdown","7dae9741":"markdown","c33d0de1":"markdown","6c3d8c70":"markdown","1a5ec6de":"markdown","76859a2d":"markdown","7ad77af5":"markdown","0edbd97f":"markdown","279ee4ed":"markdown","9c789564":"markdown","25fc3c26":"markdown","fb001ba1":"markdown","60be7afb":"markdown"},"source":{"0e3c5926":"import numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport plotly.express as px\npy.offline.init_notebook_mode (connected = True)\n\nimport tqdm\n%matplotlib inline","4910e818":"path = '..\/input\/hpa-single-cell-image-classification\/'","f9e74362":"train_df = pd.read_csv(path + 'train.csv')","6a6cf2e0":"label_to_name = {\n    '0': \"Nucleoplasm\",\n    '1': \"Nuclear membrane\",\n    '2': \"Nucleoli\",\n    '3': \"Nucleoli fibrillar center\",\n    '4': \"Nuclear speckles\",\n    '5': \"Nuclear bodies\",\n    '6': \"Endoplasmic reticulum\",\n    '7': \"Golgi apparatus\",\n    '8': \"Intermediate filaments\",\n    '9': \"Actin filaments\",\n    '10': \"Microtubules\",\n    '11': \"Mitotic spindle\",\n    '12': \"Centrosome\",\n    '13': \"Plasma membrane\",\n    '14': \"Mitochondria\",\n    '15': \"Aggresome\",\n    '16': \"Cytosol\",\n    '17': \"Vesicles and punctate cytosolic patterns\",\n    '18': \"Negative\",\n}","e96cf001":"def view_df(df, idx=0, full=False):\n    '''\n    Helper function to view dataframe in a row or to view just a particular row in the dataframe\n    \n    '''\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n        if full:\n            display(df.head())\n        else:\n            display(pd.DataFrame(df.iloc[idx]).T)","e44f38b8":"train = train_df.copy()\nlab_idx = label_to_name.keys()\n\ntrain['Label'] = train['Label'].map(lambda x: x.split('|'))\n\nfor label in lab_idx:\n    train[label_to_name[label]] = train['Label'].map(lambda result: 1 if label in result else 0)","b7c4d122":"view_df(train, 4)","0d92f52c":"view_df(train, full=True)","4bfea903":"import plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\ndef barplot(x, y, c, x_title, y_title, title):\n    fig = px.bar(x=x, y=y, opacity=0.90, color=c, \\\n            labels={'x': x_title, 'y': y_title})\n    fig.update_layout(title_text=title, title_x=0.5)\n    fig.show()\n\ndef piechart(x, y, c, title):\n    fig = px.pie(names=x, values=y, color=c)\n    fig.update_layout(title_text=title, title_x=0.5)\n    fig.show()\n    \ndef heatmap(x):\n    z = train.drop(['ID', 'Label'], axis=1).corr()\n    z_text = np.around(z, decimals=2)\n    fig = go.Figure(data = go.Heatmap(x = x, y = x, z = z, zmin=-1, zmax=1, colorscale = 'rainbow')) \n  \n    fig.show()","7524ebcf":"values = [train[col].value_counts()[1] for col in train.columns[2:]]\nnames = list(label_to_name.values())\n\nbarplot(values, names, names, 'Number of images', 'Name of labels', 'Number of images per label')\npiechart(names, values, names, 'Number of images per label')","f23faf4c":"from collections import Counter\nnum_labels = Counter([len(n) for n in train['Label']])\nprint(num_labels.keys())\nprint(num_labels.values())\n\nbarplot(num_labels.keys(), num_labels.values(), num_labels.keys(), 'Number of labels', 'Number of images', 'Number of labels per image')\npiechart(num_labels.keys(), num_labels.values(), num_labels.keys(), 'Number of labels per image')","e2421003":"values = [train[col].value_counts()[1] for col in train.columns[2:]]\nnames = list(label_to_name.values())\n\nheatmap(names)","d28f2caf":"def read_image(img_name):\n    \n    green = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_green.png'.format(img_name), cv2.IMREAD_GRAYSCALE )\n    red = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_red.png'.format(img_name), cv2.IMREAD_GRAYSCALE )\n    blue = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_blue.png'.format(img_name), cv2.IMREAD_GRAYSCALE )\n    yellow = cv2.imread('..\/input\/hpa-single-cell-image-classification\/train\/{}_yellow.png'.format(img_name), cv2.IMREAD_GRAYSCALE )\n    \n    return green, red, blue, yellow\n\n\ndef remove_ticks(ax):\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.tick_params(left=False, bottom=False)","3b53bbcf":"from matplotlib.colors import LinearSegmentedColormap\nimg_name = '0060269e-bbbc-11e8-b2ba-ac1f6b6435d0'\nprint(f\"Image name is: {img_name}\")\ngreen, red, blue, yellow = read_image(img_name)\n\n#reset seaborn style\nsns.reset_orig()\n\n# creating custom color map\nc1 = {'red':   ((0.0,  0.0, 0.0),\n                   (1.0,  0.0, 0.0)),\n\n         'green': ((0.0,  0.0, 0.0),\n                   (0.75, 1.0, 1.0),\n                   (1.0,  1.0, 1.0)),\n\n         'blue':  ((0.0,  0.0, 0.0),\n                   (1.0,  0.0, 0.0))}\n\nc2 = {'red':   ((0.0,  0.0, 0.0),\n                   (0.75, 1.0, 1.0),\n                   (1.0,  1.0, 1.0)),\n\n         'green': ((0.0,  0.0, 0.0),\n                   (1.0,  0.0, 0.0)),\n\n         'blue':  ((0.0,  0.0, 0.0),\n                   (1.0,  0.0, 0.0))}\n\nc3 = {'red':   ((0.0,  0.0, 0.0),\n                   (1.0,  0.0, 0.0)),\n\n         'green': ((0.0,  0.0, 0.0),\n                   (1.0,  0.0, 0.0)),\n\n         'blue':  ((0.0,  0.0, 0.0),\n                   (0.75, 1.0, 1.0),\n                   (1.0,  1.0, 1.0))}\n\nc4 = {'red': ((0.0,  0.0, 0.0),\n                   (0.75, 1.0, 1.0),\n                   (1.0,  1.0, 1.0)),\n\n         'green': ((0.0,  0.0, 0.0),\n                   (0.75, 1.0, 1.0),\n                   (1.0,  1.0, 1.0)),\n\n         'blue':  ((0.0,  0.0, 0.0),\n                   (1.0,  0.0, 0.0))}\n\ngreen_map = LinearSegmentedColormap('Green', c1)\nred_map = LinearSegmentedColormap('Red', c2)\nblue_map = LinearSegmentedColormap('Blue', c3)\nyellow_map = LinearSegmentedColormap('Yellow', c4)\n\nf, axarr = plt.subplots(nrows=2, ncols=2, figsize=(14, 14))\naxarr[0,0].imshow(green, cmap=green_map)\naxarr[0,0].set_title('Green: Protein of interest')\nremove_ticks(axarr[0,0])\naxarr[0,1].imshow(red, cmap=red_map)\naxarr[0,1].set_title('Red: Microtubule')\nremove_ticks(axarr[0,1])\naxarr[1,0].imshow(blue, cmap=red_map)\naxarr[1,0].set_title('Blue: Nuclei')\nremove_ticks(axarr[1,0])\naxarr[1,1].imshow(yellow, cmap=yellow_map)\naxarr[1,1].set_title('Yellow: Endoplasmic Reticulum (ER)')\nremove_ticks(axarr[1,1])\nplt.plot()","b07f6655":"def threshold(img, img_name, cmap='Greys'):\n    ret,thresh1 = cv2.threshold(img,40, 255, cv2.THRESH_BINARY)\n    ret,thresh2 = cv2.threshold(img,40, 255, cv2.THRESH_TRUNC)\n    thresh3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n            cv2.THRESH_BINARY,21,4)\n    thresh4 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n            cv2.THRESH_BINARY,21,4)\n    \n    \n    f, ax = plt.subplots(nrows=1, ncols=4, figsize=(23, 23)) \n    ax[0].imshow(thresh1, cmap=cmap)\n    ax[0].set_title(f'Binary Threshold: {img_name}')\n    remove_ticks(ax[0])\n    ax[1].imshow(thresh2, cmap=cmap)\n    ax[1].set_title(f'Trunc Threshold: {img_name}')\n    remove_ticks(ax[1])\n    ax[2].imshow(thresh3, cmap=cmap)\n    ax[2].set_title(f'Adaptive Mean Thresholding: {img_name}')\n    remove_ticks(ax[2])\n    ax[3].imshow(thresh4, cmap=cmap)\n    ax[3].set_title(f'Adaptive Gaussian Thresholding: {img_name}')\n    remove_ticks(ax[3])\n    plt.show()","8585c37f":"print(\"Thresholding with channels\")\nthreshold(green, 'Protein', green_map)\nthreshold(red, 'Microtubules', red_map)\nthreshold(blue, 'Nuclei', blue_map)\nthreshold(yellow, 'Endoplasmic Reticulum', yellow_map)","e8c446a4":"print(\"Thresholding with B\/W\")\nthreshold(green, 'Protein')\nthreshold(red, 'Microtubules')\nthreshold(blue, 'Nuclei')\nthreshold(yellow, 'Endoplasmic Reticulum')","72c50d74":"img_name = '0060269e-bbbc-11e8-b2ba-ac1f6b6435d0'\nprint(f\"Image name is: {img_name}\")\ngreen, red, blue, yellow = read_image(img_name)","ba8672ce":"# taking the picture for endoplasmic reticulum\nimg = yellow\n\n# global thresholding\nret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n\n# Otsu's thresholding\nret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(img,(5,5),0)\nret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\n# plot all the images and their histograms\nimages = [img, 0, th1,\n          img, 0, th2,\n          blur, 0, th3]\n\ntitles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n\nf, ax = plt.subplots(nrows=3, ncols=3, figsize=(20, 20))\n\nfor i in range(3):\n    ax[i, 0].imshow(images[i*3], cmap='Greys')\n    ax[i, 0].set_title(titles[i*3])\n    remove_ticks(ax[i, 0])\n    ax[i, 1].hist(images[i*3].ravel(), 256)\n    ax[i, 1].set_title(titles[i*3+1])\n    remove_ticks(ax[i, 1])\n    ax[i, 2].imshow(images[i*3+2], cmap='Greys')\n    ax[i, 2].set_title(titles[i*3+2])\n    remove_ticks(ax[i, 2])\nplt.show()","aea2684c":"for i, label in enumerate(train.columns[2:]): \n    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n    img_name = train[train[label]==1].iloc[0]['ID']\n    green, red, blue, yellow = read_image(img_name)\n    img = np.dstack((green,red, blue))\n    \n    ax.imshow(img)\n    ax.set_title(label+\" : Image name> \"+img_name)\n    remove_ticks(ax)\n    plt.show()","895a20e1":"import torch\nimport torch.nn as nn\nim = '..\/input\/hpa-single-cell-image-classification\/train\/000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_red.png'\n","518e9ad9":"def double_conv(in_channel, out_channel):\n    conv = nn.Sequential(\n        nn.Conv2d(in_channel, out_channel, kernel_size=3),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(out_channel, out_channel, kernel_size=3),\n        nn.ReLU(inplace=True),\n    )\n    \n    return conv\n    \n    \ndef crop_tensor(original, target):\n    target_size = target.size()[2]\n    original_size = original.size()[2]\n    delta = original_size - target_size\n    \n    delta = delta \/\/ 2\n    return original[:, :, delta: original_size-delta, delta: original_size-delta]\n\n\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        \n        self.max_pool_2x2 = nn.MaxPool2d(\n            kernel_size=2, \n            stride=2\n        )\n        self.down_conv_1 = double_conv(1, 64)\n        self.down_conv_2 = double_conv(64, 128)\n        self.down_conv_3 = double_conv(128, 256)\n        self.down_conv_4 = double_conv(256, 512)\n        self.down_conv_5 = double_conv(512, 1024)\n        \n        \n        self.conv_trans_1 = nn.ConvTranspose2d(\n            1024, \n            512, \n            kernel_size=2, \n            stride=2\n        )\n        \n        self.up_conv_1 = double_conv(1024, 512)\n        \n        self.conv_trans_2 = nn.ConvTranspose2d(\n            512, \n            256, \n            kernel_size=2, \n            stride=2\n        )\n        self.up_conv_2 = double_conv(512, 256)\n        \n        self.conv_trans_3 = nn.ConvTranspose2d(\n            256, \n            128, \n            kernel_size=2, \n            stride=2\n        )\n        self.up_conv_3 = double_conv(256, 128)\n        \n        self.conv_trans_4 = nn.ConvTranspose2d(\n            128, \n            64, \n            kernel_size=2, \n            stride=2\n        )\n        self.up_conv_4 = double_conv(128, 64)\n        \n        self.out = nn.Conv2d(\n            64, \n            2, \n            kernel_size=1\n        )\n        \n    \n    def forward(self, image):\n        # encoder\n        \n        x1 = self.down_conv_1(image)\n        m1 = self.max_pool_2x2(x1)\n        \n        x2 = self.down_conv_2(m1)\n        m2 = self.max_pool_2x2(x2)\n        \n        x3 = self.down_conv_3(m2)\n        m3 = self.max_pool_2x2(x3)\n        \n        x4 = self.down_conv_4(m3)\n        m4 = self.max_pool_2x2(x4)\n        \n        x5 = self.down_conv_5(m4)        \n        \n        # decoder\n        # all the x's are passed in the decoder part too\n        \n        # x4 is 64x64|x is 56x56| we need to crop x4 to same size as x\n        x = self.conv_trans_1(x5)\n        x4 = crop_tensor(x4, x)\n\n        x = torch.cat([x, x4], dim=1)\n        x = self.up_conv_1(x)\n        \n        x = self.conv_trans_2(x)\n        x3 = crop_tensor(x3, x)\n        \n        x = torch.cat([x, x3], dim=1)\n        x = self.up_conv_2(x)\n        \n        x = self.conv_trans_3(x)\n        x2 = crop_tensor(x2, x)\n\n        x = torch.cat([x, x2], dim=1)\n        x = self.up_conv_3(x)\n        \n        x = self.conv_trans_4(x)\n        x1 = crop_tensor(x1, x)\n\n        x = torch.cat([x, x1], dim=1)\n        x = self.up_conv_4(x)\n        \n        out = self.out(x)\n        \n        return out","8a8d9b94":"from torchvision import transforms\n\nwidth = 572\nheight = 572\n\nimage = cv2.imread(im, 0)\nimage = cv2.resize(image, (width, height))\nplt.imshow(image, cmap='magma')\ntran = transforms.ToTensor()\n\nimg_tensor = tran(image).unsqueeze(0)\nprint(img_tensor.shape)\n\nmodel = UNet()\nmodel(img_tensor)","d4d82c23":"### Otsu\u2019s Binarization\n\n- In the above thresholding method, a specific threshold was choosen arbitrary. Otsu's binarization automatically calculates a threshold value from image histogram for a bimodal image. \n","17dfbf28":"### Converting multi labels in one hot encodings","78111b0b":"#### Observation from above\n- About 10412 images have only one label.\n- About 99% of images have at most 3 labels and 88.7% of images have at most 2 labels.","c40fde8b":"### Train Image dataset\n","baece7b6":"### Import Libraries","c4eb5455":"### Correlation between labels ","3a1d0036":"### Vizualize RGB images for each class of the label","242cb27e":"[Cell Segmenation](https:\/\/github.com\/CellProfiling\/HPA-Cell-Segmentation) can be used to extract segment masks for each cell.","71a62d5d":"Below images are images related to specific channels","7dae9741":"#### Observations from above\n- Nucleoplasm and Nuclear speckles are higly correlated.\n- Cytosol and mitochondria are also correlated to some extent.","c33d0de1":"#### Observation from above:\n- Images with Nucleoplasm label are highest in number (8497)\n- Negative labelled images are quite low (34)\n- About 50% of the images consists of 3 labels (Nucleoplasm, Cytosol, Plasma membrane)","6c3d8c70":"The reference for the above is taken from [this](https:\/\/www.kaggle.com\/jschnab\/exploring-the-human-protein-atlas-images) notebook","1a5ec6de":"### U-Net (from scratch)\n\n- The u-net is convolutional network architecture for fast and precise segmentation of images. \n- U-net was used for segmenting biomedical images in the original paper.","76859a2d":"### Number of labels per image","7ad77af5":"To study more about Otsu's Binarization, go to [this link](https:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_thresholding\/py_thresholding.html#otsus-binarization). ","0edbd97f":"## Few important points about the problem.\n- This is a weakly supervised multi-label classification problem. (Weakly supervised learning is a machine learning framework where the model is trained using examples that are only partially annotated or labeled. Here, we are only provided with image level labels.)\n\n- Each sample consists of four files. Each file represents a different filter on the subcellular protein patterns represented by the sample. \n  - The format should be [filename]_[filter color].png for the PNG files. Colors are <span style=\"background-color: #FF0000\">red for microtubule channels<\/span>, <span style=\"background-color: #0000FF\">blue for nuclei channels<\/span>, <span style=\"background-color: #FFFF00\">yellow for Endoplasmic Reticulum (ER) channels<\/span>, and <span style=\"background-color: #00FF00\">green for the protein of interest.<\/span>\n  - The green filter should hence be used to predict the label, and the other filters are used as references.\n- Since this is a multi-label problem, each image is given a set of labels. Following are the index to label mappings used for this problem.\n\n|                     Labels                   |\n|----------------------------------------------|\n| 0. Nucleoplasm                               |\n| 1. Nuclear membrane                          |\n| 2. Nucleoli                                  |\n| 3. Nucleoli fibrillar center                 |\n| 4. Nuclear speckles                          |\n| 5. Nuclear bodies                            |\n| 6. Endoplasmic reticulum                     |\n| 7. Golgi apparatus                           |\n| 8. Intermediate filaments                    |\n| 9. Actin filaments 10. Microtubules          |\n| 11. Mitotic spindle                          |\n| 12. Centrosome                               |\n| 13. Plasma membrane                          |\n| 14. Mitochondria                             |\n| 15. Aggresome                                |\n| 16. Cytosol                                  |\n| 17. Vesicles and punctate cytosolic patterns |\n| 18. Negative                                 |\n","279ee4ed":"#### Thresholding images across all 4 channels with Grey color map","9c789564":"### Number of Images per Label","25fc3c26":"Following are the steps that can be followed here:\n* conv 3x3 applied 2 times, followed by RelU.\n* do a max pooling with filter 2x2 stride of 2 for downsampling\n* Repeat it for 5 steps\n* Then perform up conv\n","fb001ba1":"#### Thresholded images across all the 4 channels","60be7afb":"To be continued .   .  . .. "}}