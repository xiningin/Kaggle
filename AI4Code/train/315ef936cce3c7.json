{"cell_type":{"74726295":"code","4d771a37":"code","2727771f":"code","df57cfc9":"code","8d6c8c63":"code","62121576":"code","75c90184":"code","f5bae870":"code","d9f5fc8e":"code","47391d00":"code","90d97209":"code","f7931e67":"code","7f4bc3e7":"code","b5ef671d":"code","77d97ecb":"code","17da1a69":"code","5f8c237f":"markdown","3635f18e":"markdown","13c264b4":"markdown","89c47342":"markdown","71e63536":"markdown","0be4bcd0":"markdown","2011c309":"markdown","9d52779c":"markdown","30eae6e8":"markdown","8a51221d":"markdown","c7154510":"markdown","f9fb12a9":"markdown","b487d9bf":"markdown","b146a76e":"markdown"},"source":{"74726295":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#      for filename in filenames:\n#          print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4d771a37":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom keras.applications import VGG16 ,ResNet50\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.applications import imagenet_utils\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.layers import Input\nimport seaborn as sns\nimport pandas as pd\nimport itertools\nimport shutil\nimport pickle\nimport random\nimport time\nimport csv\nimport os\n!pip install imutils\nfrom imutils import paths","2727771f":"base_path=\"\/kaggle\/input\"\nwork_path=\"\/kaggle\/working\"","df57cfc9":"print(\"[ALERT]...loading the VGG16 model\")\nmodelVgg=VGG16(weights=\"imagenet\",include_top=False,input_tensor=Input(shape=(128, 128, 3)))\nle=None","8d6c8c63":"modelVgg.summary()","62121576":"datasets=[\"training\"]\nbatch_size=32","75c90184":"# os.remove(\"\/kaggle\/working\/Vgg16.csv\")","f5bae870":"for train_images in (datasets):\n    #we have to grab the images from the training path to extract the features\n    p=os.path.sep.join([base_path,train_images])\n    imagePaths=list(paths.list_images(p))\n    #randomly shuffule the images to make sure all varianta are present randomly \n    random.shuffle(imagePaths)\n    labels=[p.split(os.path.sep)[-2] for p in imagePaths]\n    if le is None:\n        le=LabelEncoder()\n        le.fit(labels)\n    print(set(labels))\n    csvPathVgg=os.path.sep.join([work_path,\"{}.csv\".format(\"Vgg16\")])\n    csvVgg=open(csvPathVgg, \"w\")\n\n    for (b, i) in enumerate(range(0, len(imagePaths), batch_size)):\n        # extract the batch of images and labels, then initialize the\n\t\t# list of actual images that will be passed through the network\n\t\t# for feature extraction\n        print(\"[INFO] processing batch {}\/{}\".format(b + 1,int(np.ceil(len(imagePaths) \/ float(batch_size)))))\n        batchPaths = imagePaths[i:i + batch_size]\n        batchLabels = le.transform(labels[i:i + batch_size])\n        batchImages = []\n        for imagePath in batchPaths:\n            # the image is resized to 128*128 pixels, since the VGG16 model is loaded with same image resolution\n            image = load_img(imagePath, target_size=(128,128))\n            image = img_to_array(image)\n\n            # preprocess the image by  expanding the dimensions and preprocessing using the imagenet utils\n            image = np.expand_dims(image, axis=0)\n            image = imagenet_utils.preprocess_input(image)\n\n            # add the image to the batch\n            batchImages.append(image)\n\n        batchImages = np.vstack(batchImages)\n        featuresVgg = modelVgg.predict(batchImages, batch_size=batch_size)\n        #reshaping the feature array to the output layer shape (4*4*512)\n        featuresVgg = featuresVgg.reshape((featuresVgg.shape[0], 4 * 4 * 512))\n        # loop over the class labels and extracted features\n        for (label, vec) in zip(batchLabels, featuresVgg):\n            # construct a row with \",\" to make sure while writing csv, each value(feature) goes to a sepearte column\n            vec = \",\".join([str(v) for v in vec])\n            csvVgg.write(\"{},{}\\n\".format(label, vec))\nprint(\"extraction completed\")","d9f5fc8e":"csvVgg=os.path.sep.join([work_path,\"Vgg16.csv\"])","47391d00":"def getcsvcount(csvfile):\n    with open(csvVgg, 'r') as csv:\n        first_line = csv.readline()\n    ncol = first_line.count(',') + 1\n    return ncol","90d97209":"csvVggcount=getcsvcount(csvVgg)\ncolsVgg=['feature_'+str(i) for i in range(csvVggcount-1)]","f7931e67":"def load_data_split(splitPath):\n    #data and label varialbles\n    data=[]\n    labels=[]\n    for row in open(splitPath):\n        row=row.strip().split(\",\")\n        label=row[0]\n        features=np.array(row[1:],dtype=\"float\")\n\n        data.append(features)\n        labels.append(label)\n    data=np.array(data)\n    labels=np.array(labels)\n    return(data,labels)","7f4bc3e7":"dataVgg,labelsVgg=load_data_split(csvVgg)\ndf_Vgg=pd.DataFrame(dataVgg,columns=colsVgg)\ndf_Vgg['labels'] = labelsVgg\nprint('Size of the dataframe: {}'.format(df_Vgg.shape))","b5ef671d":"# For reproducability of the results\nnp.random.seed(42)\nrndperm = np.random.permutation(df_Vgg.shape[0])\nN=8000\ndf_subset = df_Vgg.loc[rndperm[:N],:].copy()\ndata_subset = df_subset[colsVgg].values\ny=df_subset['labels'].values","77d97ecb":"#tSNE dimensionality reduction\ntime_start=time.time()\ntsne=TSNE(n_components= 2,verbose=1,perplexity=40,\n          n_iter=600)\ntsne_results=tsne.fit_transform(data_subset)\nprint('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))","17da1a69":"df_subset['tsne-one'] = tsne_results[:,0]\ndf_subset['tsne-two'] = tsne_results[:,1]\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x=\"tsne-one\", y=\"tsne-two\",\n    hue=y,\n    palette=sns.color_palette(\"hls\", 10),\n    data=df_subset,\n    legend=\"full\",\n    alpha=0.9\n)","5f8c237f":"Loading the VGG16 model, without the top layer, since we are only intending to extract the features and not a classification\nThe shape of the Input layer has been changed to 128,128 to keep the memory requirements low","3635f18e":"Setting up the loop to parse the images and extract the features in batch size and then store in the prescribed excel sheet\nWe use label encoder to encode the label strings","13c264b4":"Looking on the model summary to understand the Shape of output layers","89c47342":"Setting up the path for input and working directories","71e63536":"We use VGG16 without the top layer for feature extraction and then use t-SNE algorithm to see how well the features were extracted \nIn another notebook, the results from VGG16 feature extraction will be compared with the results from ResNet50","0be4bcd0":"plotting the t-SNE result in a 2D graph","2011c309":"Setting up the datasets path and batch size","9d52779c":"This brings an insight on how VGG16 did the features extraction and t-SNE algorithm enabled to distinguish the same.","30eae6e8":"Path to the csv file","8a51221d":"Splitting the CSV file into labels and data and storing in seperate lists","c7154510":"Importing all required modules","f9fb12a9":"Evaluating t-SNE algorithm on the subset data","b487d9bf":"Function to read the size (count) of colmns in the csv already saved","b146a76e":"Sizing down the initial dataset to a subset of size 8000 (any random number) to reduce the computational cost"}}