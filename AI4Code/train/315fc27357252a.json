{"cell_type":{"381be303":"code","69f2466d":"code","2c03cd8f":"code","694fbc9e":"code","1cbd90ae":"code","40e06199":"code","8eaa8115":"code","fc8a14b6":"code","6287a100":"code","91ae61bd":"code","bef68537":"code","bdf256ce":"markdown","96aa5dcf":"markdown","11a5261e":"markdown","0d62e828":"markdown","ad4ed984":"markdown","36500de9":"markdown","677c7bcf":"markdown","e5654496":"markdown","1079ffe4":"markdown","854a7379":"markdown","fe930267":"markdown"},"source":{"381be303":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta","69f2466d":"def show_me_the_clock():\n    return (datetime.utcnow() + timedelta(hours=+9)).strftime('%Y-%m-%d %H:%M:%S')\n\ndef load_dataset(train_or_test='train'):\n    file_path = f'..\/input\/tabular-playground-series-nov-2021\/{train_or_test}.csv'\n    df = pd.read_csv(file_path)\n    print(show_me_the_clock(), f'Dataset loaded, shape={df.shape}')\n    df = tame_data(df)\n    print(show_me_the_clock(), f'Dataset tamed, shape={df.shape}')\n    if train_or_test == 'train':\n        y = df['target'].to_numpy()\n        del df['target']\n        X = df.to_numpy()\n        print(show_me_the_clock(), f'Dataset prepared, X.shape={X.shape}, y.shape={y.shape}')\n        return X, y\n    else:\n        X = df.to_numpy()\n        return X\n    return df\n\ndef tame_data(df):\n    df = df.copy()\n    for i in range(100):\n        q1, q2, q3 = df['f%d' % i].quantile([0.25, 0.5, 0.75]).iloc\n        \n        # normalization by median and IQR\n        df['f%d' % i] = (df['f%d' % i] - q2) \/ (q3 - q1) \n        \n        # concentrating data toward median\n        df['f%d' % i] = df['f%d' % i].apply(lambda x: np.sign(x)*np.log1p(np.log1p(np.abs(x))))\n    del df['id']\n    df = df.rename(columns=lambda name: name + '_tamed' if name != 'target' else name)\n    return df","2c03cd8f":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(*load_dataset('train'), test_size=0.2)","694fbc9e":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.linear_model import LogisticRegression\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor C, ax_coef, ax_roc, ax_pr in zip([0.0001, 0.0003, 0.001, 0.003, 0.01], *axs):\n    model = LogisticRegression(penalty='l1', C=C, solver='saga')\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc = roc_auc_score(y_test, y_proba)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    height = model.coef_.ravel()\n    ax_coef.bar(x=list(range(100)), height=height, label='Coefficients')\n    for h_ind in np.argsort(-np.abs(height)):\n        ax_coef.text(h_ind, height[h_ind], f'{h_ind}')\n    ax_coef.set_title(f'Linear model(L1 reg, C={C})', fontsize=16)\n    ax_coef.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n    \n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label='PR curve', color='green')\n    ax_pr.text(0.2, 0.2, f'precision={prec:.3f}\\nrecall={rec:.3f}', fontsize=12)\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","1cbd90ae":"fig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor C, ax_coef, ax_roc, ax_pr in zip([1e-7, 1e-6, 1e-5, 1e-4, 1e-3], *axs):\n    model = LogisticRegression(penalty='l2', C=C)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc = roc_auc_score(y_test, y_proba)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    height = model.coef_.ravel()\n    ax_coef.bar(x=list(range(100)), height=height, label='Coefficients')\n    for h_ind in np.argsort(-np.abs(height)):\n        ax_coef.text(h_ind, height[h_ind], f'{h_ind}')\n    ax_coef.set_title(f'Linear model(L2 reg, C={C})', fontsize=16)\n    ax_coef.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n    \n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label='PR curve', color='green')\n    ax_pr.text(0.2, 0.2, f'precision={prec:.3f}\\nrecall={rec:.3f}', fontsize=12)\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","40e06199":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor max_depth, ax_fi, ax_roc, ax_pr in zip([5, 10, 15, 20, 25], *axs):\n    model = DecisionTreeClassifier(max_depth=max_depth, \n                                   min_samples_split=2, \n                                   min_samples_leaf=1,\n                                   max_features=None)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, max_depth={max_depth}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","8eaa8115":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor min_samples_split, ax_fi, ax_roc, ax_pr in zip([1e-3, 1e-2, 1e-1, 2e-1, 3e-1], *axs):\n    model = DecisionTreeClassifier(max_depth=10, \n                                   min_samples_split=min_samples_split, \n                                   min_samples_leaf=1,\n                                   max_features=None)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, min_samples_split={min_samples_split}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","fc8a14b6":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor min_samples_leaf, ax_fi, ax_roc, ax_pr in zip([1e-5, 1e-4, 1e-3, 1e-2, 1e-1], *axs):\n    model = DecisionTreeClassifier(max_depth=10, \n                                   min_samples_split=1e-3, \n                                   min_samples_leaf=min_samples_leaf,\n                                   max_features=None)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, min_samples_leaf={min_samples_leaf}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","6287a100":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor max_features, ax_fi, ax_roc, ax_pr in zip([8, 16, 32, 64, 82], *axs):\n    model = DecisionTreeClassifier(max_depth=10, \n                                   min_samples_split=1e-3, \n                                   min_samples_leaf=1e-3,\n                                   max_features=max_features)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, max_features={max_features}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","91ae61bd":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor max_features, ax_fi, ax_roc, ax_pr in zip([8, 16, 32, 64, 82], *axs):\n    model = DecisionTreeClassifier(criterion='entropy', \n                                   max_depth=10, \n                                   min_samples_split=1e-3, \n                                   min_samples_leaf=1e-3,\n                                   max_features=max_features)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, max_features={max_features}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","bef68537":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.svm import SVC\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor C, ax_fi, ax_roc, ax_pr in zip([1e-4, 1e-2, 1e0, 1e2, 1e4], *axs):\n    model = SVC(C=C, kernel='rbf', probability=True)\n    model.fit(X_train[::100], y_train[::100])\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n#     fi = model.coef_[1]\n#     ax_fi.bar(list(range(100)), fi, label='feature importances')\n#     for f_num in np.argsort(-fi):\n#         ax_fi.text(f_num, fi[f_num], f'{f_num}')\n#     ax_fi.set_title(f'SVC with rbf, C={C}', fontsize=16)\n#     ax_fi.set_xlabel('features')\n#     ax_fi.set_ylabel('importance')\n#     ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","bdf256ce":"**(2) Logistic Regression - L2 regularized**","96aa5dcf":"**(4) kernel SVM**\n\nThis takes too long, even with much smaller training set .","11a5261e":"d. varying \"max_features\"","0d62e828":"a. varying \"max_depth\"","ad4ed984":"c. varying \"min_samples_leaf\"","36500de9":"# Importing libraries, basic functions","677c7bcf":"**(3) Decision tree**","e5654496":"# Data preparation","1079ffe4":"b. varying \"min_samples_split\"","854a7379":"e. What if criterion is replaced by \"entropy\"?","fe930267":"# Training and testing simple models\n**(1) Logistic Regression - L1 regularized**\n\nAll of these exhibit low performances, and their metrics are similar.\n\nSome features (e.g. f34, f27, f43, etc.) are found influential in each of those models."}}