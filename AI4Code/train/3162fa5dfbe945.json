{"cell_type":{"6e2b1431":"code","58496fbd":"code","7c68e0fd":"code","f9e7db93":"code","c1d9a755":"code","c84339b7":"code","32eb0574":"code","caff55e6":"code","dd16b8db":"code","e3058d07":"code","38b66a5d":"code","fcb7f01d":"code","77877a41":"code","f63ff04f":"code","6ebdd539":"code","54fdaf1a":"code","cf8176c6":"code","9fe08347":"code","c740e663":"code","5e528cfd":"code","f2bd4834":"code","9a714955":"code","291ff62d":"code","8fc3e679":"code","c81078be":"code","43dc4523":"code","40dc2eda":"code","c0724469":"code","02b29890":"code","9f8d2252":"code","7e20e40a":"code","a82baa1e":"code","6ded7569":"code","33a11fe8":"code","eb36a545":"code","73ea0c28":"code","8f1fa040":"code","ae0dd6e8":"code","181041aa":"code","8cb57f72":"code","d2d9e71c":"code","491d10a6":"code","8d9c574c":"code","b55d3ad4":"code","83c93f0b":"code","e543a88f":"code","36af6e65":"code","f3b1a694":"code","aced3176":"code","5e710b88":"code","1249379d":"code","924c78a1":"code","9a1e911d":"code","cc0c4aad":"code","2856ca7c":"code","e1558778":"code","53050a2c":"code","86061ad1":"code","05574e62":"code","647e7a82":"code","13bc061e":"code","5e344d15":"code","68083f8f":"code","6c7e23bc":"code","064ab1b6":"code","404362f7":"code","2f0141f7":"code","cd5c0f99":"code","3a4ff78e":"code","103aae07":"code","94ea4536":"code","866235f0":"code","3170df9a":"code","c1ea9348":"code","cff1466d":"code","5c18325d":"code","ff7ff95a":"code","30af828a":"code","87533051":"code","1b62527e":"code","c1d0fb9c":"code","e07cb11a":"code","43db4e19":"code","bbcbc8a9":"code","379a7928":"code","65fda56e":"code","bc1b9057":"code","1fd29efc":"code","bea16023":"code","c73be041":"code","46cf7bb4":"code","9c432585":"code","98968b04":"markdown","91f92f18":"markdown","96a5e0c6":"markdown","6629bc96":"markdown","a4cf72b0":"markdown","f7cf2b6a":"markdown","60896680":"markdown","29685453":"markdown","4ef8de0c":"markdown","bb49f6fc":"markdown","cb8dc85a":"markdown","3a2b50d9":"markdown","abe3d487":"markdown","b2d34455":"markdown","09cbbf35":"markdown","fc6f32fa":"markdown","6b2bf9c5":"markdown","8a4d46f9":"markdown","1106065e":"markdown","55a50225":"markdown","5d4af40e":"markdown","2b8b5247":"markdown","e4b45930":"markdown","1108e10f":"markdown","710bfaa2":"markdown","109722df":"markdown","3b28830b":"markdown","467a8c56":"markdown","0cd0c8b1":"markdown","1ee937bd":"markdown","ddb3ac39":"markdown","8de2c13b":"markdown","36de84d8":"markdown","e13474d7":"markdown","b254675e":"markdown","6fedbf9f":"markdown","7e3106ab":"markdown","fa6e18be":"markdown","1ef3e391":"markdown","295788b7":"markdown","095705a2":"markdown","e998bf57":"markdown","8257cd41":"markdown","fef3bfba":"markdown","e464785b":"markdown","f796aa42":"markdown","604270c9":"markdown","bd671958":"markdown","84b6bcc8":"markdown","108186e2":"markdown","2df1bf58":"markdown","ef53f3a7":"markdown","5fbdfb23":"markdown","949a9d50":"markdown","50b144a0":"markdown","5e140070":"markdown","06cec185":"markdown","b3821bf3":"markdown","7a361e11":"markdown","0491171f":"markdown","ef678dff":"markdown","8c829cc9":"markdown","da03cd30":"markdown","05c5da24":"markdown","34f8e833":"markdown","704d6396":"markdown","794640f6":"markdown","e1db302f":"markdown","4428b56f":"markdown","65034dfc":"markdown","35471cbf":"markdown","bb55d1c7":"markdown","b28275c1":"markdown","219ba083":"markdown","0f0c677c":"markdown","d8fdb498":"markdown","09b22e88":"markdown","4ea95cf3":"markdown","5073d3a2":"markdown","bd99e044":"markdown","63ee8493":"markdown","023c4674":"markdown"},"source":{"6e2b1431":"#Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport ast\nfrom tqdm import tqdm\nimport time\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression,Lasso\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split,GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.feature_selection import SelectKBest,chi2\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\nfrom xgboost.sklearn import XGBRegressor\nfrom xgboost import plot_importance\nfrom types import FunctionType\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline\nseed = 123","58496fbd":"# Data import\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint('train dataset size:', train.shape)\nprint('test dataset size:', test.shape)","7c68e0fd":"train.info()","f9e7db93":"train.head(3)","c1d9a755":"'''Total rows:3000\nData columns (total 23 columns):\nid  &nbsp;                       3000 non-null int64   unique id given to movie  \nbelongs_to_collection    604 non-null object   title,poster path etc given in jason format  \nbudget                   3000 non-null int64   budget of the movie,assuming in USD  \ngenres                   2993 non-null object  one movie can have multiple genre given in list of dictionaries  \nhomepage                 946 non-null object   homepage of production company,I think  \nimdb_id                  3000 non-null object  unique id given to movie on IMDB website  \noriginal_language        3000 non-null object  original_language of the movie \noriginal_title           3000 non-null object  title of the movie \noverview                 2992 non-null object  short overview about movie story \npopularity               3000 non-null float64 score based on popularity,how this score is calculated is not given to us\nposter_path              2999 non-null object  path to image of movie poster\nproduction_companies     2844 non-null object  one movie can have multiple production companies  \nproduction_countries     2945 non-null object  name of the country where movie production took place \nrelease_date             3000 non-null object  movie release date in mm\/dd\/yy format\nruntime                  2998 non-null float64 movie runtime in minutes\nspoken_languages         2980 non-null object  language spoken in movie given in list of dictionary\nstatus                   3000 non-null object  Status of the movie.Either 'Released' or 'Rumored'\ntagline                  2403 non-null object  Tagline given in String format\ntitle                    3000 non-null object  Title of the movie\nKeywords                 2724 non-null object  List of keywords related to movie plot\ncast                     2987 non-null object  List of cast and its details\ncrew                     2984 non-null object  list of crew and their detail\nrevenue                  3000 non-null int64   revenue earned by the movie,this is our taget variable.'''","c84339b7":"columns_to_keep = set()","32eb0574":"#This method will clean feature with dictionary data.\n#Create new feature with total number of values,onehot encoded feature\ndef clean_dictionary_features(feature_name,train,test):\n    #convert string to dictionary\n    train[feature_name] = train[feature_name].apply(lambda x:{} if pd.isna(x) else ast.literal_eval(x))\n    test[feature_name] = test[feature_name].apply(lambda x:{} if pd.isna(x) else ast.literal_eval(x))\n    \n    #create new feature of total count of values\n    train[feature_name+'_number'] = train[feature_name].apply(lambda x:len(x) if x!={} else 0)\n    test[feature_name+'_number'] = test[feature_name].apply(lambda x:len(x) if x!={} else 0)\n    columns_to_keep.add(feature_name+'_number')\n    \n    #get list of all values\n    list_of_values = list(train[feature_name].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n\n    train[feature_name+'_all'] = train[feature_name].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n    top_values = [m[0] for m in Counter([i for j in list_of_values for i in j]).most_common(10)]\n    \n    #Create one hot encoded feature\n    for val in top_values:\n        train[feature_name +'_'+val] = train[feature_name+'_all'].apply(lambda x: 1 if val in x else 0)\n        columns_to_keep.add(feature_name +'_'+val)\n    \n    test[feature_name+'_all'] = test[feature_name].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n    for val in top_values:\n        test[feature_name +'_'+val] = test[feature_name+'_all'].apply(lambda x: 1 if val in x else 0)\n    \n    #Create Lable encoded feature \n    le = LabelEncoder()\n    le.fit(list(train[feature_name+'_all'].fillna('')) + list(test[feature_name+'_all'].fillna('')))\n    train[feature_name+'_all'] = le.transform(train[feature_name+'_all'].fillna('').astype(str))\n    test[feature_name+'_all'] = le.transform(test[feature_name+'_all'].fillna('').astype(str))\n    columns_to_keep.add(feature_name+'_all')\n    return train,test","caff55e6":"train,test = clean_dictionary_features('genres',train,test)\ntrain,test = clean_dictionary_features('production_companies',train,test)\ntrain,test = clean_dictionary_features('production_countries',train,test)\ntrain,test = clean_dictionary_features('spoken_languages',train,test)\ntrain,test = clean_dictionary_features('Keywords',train,test)\ntrain,test = clean_dictionary_features('cast',train,test)\ntrain,test = clean_dictionary_features('crew',train,test)\n","dd16b8db":"print(\"-\"*40,'\\n',train.isnull().sum())\nprint(\"-\"*40,'\\n',test.isnull().sum())","e3058d07":"train.belongs_to_collection.describe()","38b66a5d":"train['belongs_to_collection'][0]","fcb7f01d":"train['got_collection'] = train['belongs_to_collection'].apply(lambda x:0 if pd.isnull(x) else 1)\ntest['got_collection'] = test['belongs_to_collection'].apply(lambda x:0 if pd.isnull(x) else 1)","77877a41":"sns.catplot(x='got_collection', y='revenue', data=train);","f63ff04f":"columns_to_keep.add('got_collection')","6ebdd539":"train.budget.describe()","54fdaf1a":"sns.distplot(train['budget'])","cf8176c6":"sns.distplot(np.log1p(train['budget']))","9fe08347":"len(train[train['budget']==0])","c740e663":"sns.jointplot(x=np.log1p(train['budget']), y=np.log1p(train['revenue']), data=train, height=8, ratio=4, color=\"b\")","5e528cfd":"train['budget_log'] = np.log1p(train.budget.values)\ntest['budget_log'] = np.log1p(test.budget.values)","f2bd4834":"columns_to_keep.add('budget_log')","9a714955":"train.revenue.corr(train.budget_log,method='pearson')","291ff62d":"train.original_language.describe()","8fc3e679":"sns.catplot('original_language',data=train,kind='count')","c81078be":"train.groupby(['original_language']).mean()[['revenue']].plot(kind='bar')","43dc4523":"train['belongs_to_three_lang'] = train.original_language.apply(lambda x:1 if str(x) in['en','zh','tr'] else 0)\ntest['belongs_to_three_lang'] = test.original_language.apply(lambda x:1 if str(x) in['en','zh','tr'] else 0)","40dc2eda":"columns_to_keep.add('belongs_to_three_lang')","c0724469":"le = LabelEncoder()\nle.fit(list(train['original_language'].fillna('')) + list(test['original_language'].fillna('')))\ntrain['original_language_encoded'] = le.transform(train['original_language'].fillna('').astype(str))\ntest['original_language_encoded'] = le.transform(test['original_language'].fillna('').astype(str))","02b29890":"columns_to_keep.add('original_language_encoded')","9f8d2252":"train.original_title.describe()","7e20e40a":"sns.scatterplot(x=train.original_title.str.len(),y=train.revenue)","a82baa1e":"train['original_title_length'] = train.original_title.str.len()\ntest['original_title_length'] = test.original_title.str.len()","6ded7569":"train.revenue.corr(train.original_title_length)","33a11fe8":"columns_to_keep.add('original_title_length')","eb36a545":"train.overview.describe()","73ea0c28":"train.overview[3]","8f1fa040":"train.popularity.describe()","ae0dd6e8":"sns.distplot(train.popularity)","181041aa":"sns.distplot(np.log1p(train.popularity))","8cb57f72":"plt.boxplot(np.log1p(train.popularity))","d2d9e71c":"sns.scatterplot(x=train.popularity,y=np.log1p(train.revenue))","491d10a6":"train.popularity.corr(train.revenue)","8d9c574c":"columns_to_keep.add('popularity')","b55d3ad4":"train.release_date.describe()","83c93f0b":"#as year is in yy format we have to handle movies after 20xx.So this method will help to add century to year\ndef clean_date(date):\n    year = date.split('\/')[2]\n    if int(year) <= 19:\n        return date[:-2] + '20' + year\n    else:\n        return date[:-2] + '19' + year","e543a88f":"test.loc[test['release_date'].isnull() == True, 'release_date'] = '05\/01\/00'\n","36af6e65":"train['release_date'] = train['release_date'].apply(lambda x:clean_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x:clean_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])","f3b1a694":"#get time period features from date value\ndef date_features(dataset):\n    date_sections = [\"year\", \"weekday\", \"month\", 'weekofyear', 'day']\n    for sec in date_sections:\n        section_col = 'release_date' + \"_\" + sec\n        dataset[section_col] = getattr(dataset['release_date'].dt, sec).astype(int)\n        columns_to_keep.add(section_col)\n    return dataset\n\n","aced3176":"train = date_features(train)\ntest = date_features(test)","5e710b88":"train.runtime.describe()","1249379d":"train.runtime.isnull().sum()","924c78a1":"test.runtime.isnull().sum()","9a1e911d":"train.runtime = train.runtime.fillna(np.mean(train.runtime))\ntest.runtime = test.runtime.fillna(np.mean(test.runtime))","cc0c4aad":"sns.scatterplot(train.runtime,np.log1p(train.revenue))","2856ca7c":"train.revenue.corr(train.runtime)","e1558778":"columns_to_keep.add('runtime')","53050a2c":"train.status.describe()","86061ad1":"train.status.value_counts()","05574e62":"train.tagline.describe()","647e7a82":"train.tagline[:3]","13bc061e":"sns.scatterplot(x=train.tagline.str.len(),y=train.revenue)","5e344d15":"train['tagline_count'] = train['tagline'].apply(lambda x: 0 if pd.isnull(x) else len(x))\ntest['tagline_count'] = test['tagline'].apply(lambda x: 0 if pd.isnull(x) else len(x))","68083f8f":"columns_to_keep.add('tagline_count')","6c7e23bc":"train.title.describe()","064ab1b6":"sns.scatterplot(x=train.title.str.len(),y=train.revenue)","404362f7":"train['title_count'] = train['title'].apply(lambda x: 0 if pd.isnull(x) else len(x))\ntest['title_count'] = test['title'].apply(lambda x: 0 if pd.isnull(x) else len(x))","2f0141f7":"columns_to_keep.add('title_count')","cd5c0f99":"#budget must be high for popular movies\ntrain['budget_popularity'] = train['budget']\/train['popularity']\ntest['budget_popularity'] = test['budget']\/test['popularity']\ncolumns_to_keep.add('budget_popularity')\n\n#budget increased since past\ntrain['budget_release_year'] = train['budget']\/train['release_date_year']\ntest['budget_release_year'] = test['budget']\/test['release_date_year']\ncolumns_to_keep.add('budget_release_year')\n\n#popularity increased since past\ntrain['popularity_release_year'] = train['popularity']\/train['release_date_year']\ntest['popularity_release_year'] = test['popularity']\/test['release_date_year']\ncolumns_to_keep.add('popularity_release_year')\n\n#popularity and day on which movie releases must be related\ntrain['popularity_release_weekday'] = np.sqrt(train['popularity']*train['release_date_weekday'])\ntest['popularity_release_weekday'] = np.sqrt(test['popularity']*test['release_date_weekday'])\ncolumns_to_keep.add('popularity_release_weekday')\n\n#movies with more generes in it are recently being made\ntrain['genres_number_release_year'] = train['genres_number']\/train['release_date_year']\ntest['genres_number_release_year'] = test['genres_number']\/test['release_date_year']\ncolumns_to_keep.add('genres_number_release_year')\n\n\n#movie runtime reduced w.r.t time\ntrain['runtime_release_year'] = np.sqrt(train['runtime']*train['release_date_year'])\ntest['runtime_release_year'] = np.sqrt(test['runtime']*test['release_date_year'])\ncolumns_to_keep.add('runtime_release_year')\n\n#high runtime movies may require high budget\ntrain['budget_runtime'] = np.sqrt(train['budget']*train['runtime'])\ntest['budget_runtime'] = np.sqrt(test['budget']*test['runtime'])\ncolumns_to_keep.add('budget_runtime')\n\ntrain['budget_tagline_count'] = np.sqrt(train['budget']*train['tagline_count'])\ntest['budget_tagline_count'] = np.sqrt(test['budget']*test['tagline_count'])\ncolumns_to_keep.add('budget_tagline_count')","3a4ff78e":"len(columns_to_keep)","103aae07":"columns_to_keep","94ea4536":"numerical_features = ['Keywords_number','runtime','spoken_languages_number','production_countries_number',\n                     'production_companies_number','popularity','genres_number','crew_number','cast_number','budget_log',\n                     'budget_popularity','budget_release_year','popularity_release_year','popularity_release_weekday',\n                     'genres_number_release_year','runtime_release_year','budget_runtime','budget_tagline_count']\ndate_features = ['release_date_day','release_date_month','release_date_weekday','release_date_weekofyear',\n                        'release_date_year']\nfeature_text_length = ['title_count','tagline_count','original_title_length']\ncategorical_features = ['spoken_languages_all','production_companies_all','production_countries_all','original_language',\n                       'got_collection','genres_all','crew_all','cast_all','belongs_to_three_lang','Keywords_all']\nspoken_language_features = ['spoken_languages_','spoken_languages_Deutsch','spoken_languages_English','spoken_languages_Espa\u00f1ol',\n                             'spoken_languages_Fran\u00e7ais','spoken_languages_Italiano', 'spoken_languages_P\u0443\u0441\u0441\u043a\u0438\u0439',\n                            'spoken_languages_\u0939\u093f\u0928\u094d\u0926\u0940','spoken_languages_\u65e5\u672c\u8a9e','spoken_languages_\u666e\u901a\u8bdd']\nproduction_countries_features = ['production_countries_Australia','production_countries_Canada','production_countries_France',\n                                'production_countries_Germany','production_countries_India','production_countries_Italy',\n                                'production_countries_Japan','production_countries_Russia','production_countries_United Kingdom',\n                                'production_countries_United States of America' ]\nproduction_companies_features = ['production_companies_Columbia Pictures','production_companies_Columbia Pictures Corporation',\n                                 'production_companies_Metro-Goldwyn-Mayer (MGM)', 'production_companies_New Line Cinema',\n                                 'production_companies_Paramount Pictures', 'production_companies_Touchstone Pictures',\n                                 'production_companies_Twentieth Century Fox Film Corporation','production_companies_Universal Pictures',\n                                 'production_companies_Walt Disney Pictures', 'production_companies_Warner Bros.']\ngenres_features = ['genres_Action', 'genres_Adventure','genres_Comedy', 'genres_Crime', 'genres_Drama', 'genres_Family',\n                 'genres_Horror', 'genres_Romance', 'genres_Science Fiction', 'genres_Thriller']\ncrew_features = ['crew_Avy Kaufman', 'crew_Deborah Aquila', 'crew_Francine Maisler','crew_James Newton Howard',\n                 'crew_Jerry Goldsmith', 'crew_Luc Besson', 'crew_Mary Vernieu', 'crew_Robert Rodriguez','crew_Steven Spielberg',\n                 'crew_Tricia Wood']\ncast_features = ['cast_Bruce McGill', 'cast_Bruce Willis','cast_J.K. Simmons','cast_John Turturro','cast_Liam Neeson',\n                 'cast_Morgan Freeman','cast_Robert De Niro','cast_Samuel L. Jackson', 'cast_Susan Sarandon','cast_Willem Dafoe']\nkeywords_features = ['Keywords_aftercreditsstinger', 'Keywords_based on novel', 'Keywords_biography',\n                     'Keywords_duringcreditsstinger', 'Keywords_independent film', 'Keywords_murder',\n                     'Keywords_revenge', 'Keywords_sport', 'Keywords_violence', 'Keywords_woman director']\n","866235f0":"print(len(numerical_features)+len(date_features)+len(feature_text_length)+len(categorical_features)+len(spoken_language_features)\n+len(production_countries_features)+len(production_companies_features)+len(genres_features)+len(crew_features)+len(cast_features)\n+len(keywords_features))","3170df9a":"numerical_data = numerical_features\nnumerical_data.append('revenue')","c1ea9348":"plt.figure(figsize=(12,6))\nsns.heatmap(train[numerical_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between Numerical Features')\nplt.show()","cff1466d":"date_data = date_features\ndate_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[date_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between date Features')\nplt.show()","5c18325d":"text_length_data = feature_text_length\ntext_length_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[text_length_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between text length Features')\nplt.show()","ff7ff95a":"categorical_features_data = categorical_features\ncategorical_features_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[categorical_features_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between categorical Features')\nplt.show()","30af828a":"spoken_language_features_data = spoken_language_features\nspoken_language_features_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[spoken_language_features_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between spoken_language Features')\nplt.show()","87533051":"production_countries_features_data = production_countries_features\nproduction_countries_features_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[production_countries_features_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between production_countries Features')\nplt.show()","1b62527e":"production_companies_features_data = production_companies_features\nproduction_companies_features_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[production_companies_features_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between production_companies Features')\nplt.show()","c1d0fb9c":"genres_features_data = genres_features\ngenres_features_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[genres_features_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between genres_features Features')\nplt.show()","e07cb11a":"crew_features_data = crew_features\ncrew_features_data.append('revenue')\nplt.figure(figsize=(12,6))\nsns.heatmap(train[crew_features_data].corr(), annot=True, fmt='.2', center=0.0, cmap='RdBu_r')\nplt.title('Correlation between crew_features Features')\nplt.show()","43db4e19":"corr_features = list(columns_to_keep)\ncorr_features.append('revenue')\ncorrs = abs(train[corr_features].corr()['revenue']).sort_values(ascending=False)\ncorr_selected_features = corrs[:50].index.tolist()\ncorr_selected_features.remove('revenue')\n#corr_selected_features","bbcbc8a9":"def select_model(X_train, X_val, y_train, y_val):\n\n    best_models = {}\n    models = [\n        {\n            'name': 'LinearRegression',\n            'estimator': LinearRegression(),\n            'hyperparameters': {},\n        },\n       \n        {\n            'name': 'GradientBoostingRegressor',\n            'estimator': GradientBoostingRegressor(),\n            'hyperparameters':{\n                'n_estimators': range(100, 200, 10),\n                'criterion': ['friedman_mse'],\n                'max_depth': [3, 5, 7, 9],\n                'max_features': ['log2', 'sqrt'],\n                'min_samples_leaf': [1, 2, 4],\n                'min_samples_split': [3, 5, 7]\n            }\n            \n        },\n\n        {\n            'name': 'XGBoost',\n            'estimator': xgb.XGBRegressor(),\n            'hyperparameters':{\n                'booster': ['gbtree', 'gblinear', 'dart'],\n                'max_depth': range(5, 50, 5),\n                'n_estimators': [200],\n                'nthread': [4],\n                'min_child_weight': range(1, 8, 2),\n                'learning_rate': [.05, .1, .15],\n            }\n        },\n        {\n            'name': 'Light GBM',\n            'estimator': lgb.LGBMRegressor(),\n            'hyperparameters':{\n                'max_depth': range(20, 85, 15),\n                'learning_rate': [.01, .05, .1],\n                'num_leaves': [300, 600, 900, 1200],\n                'n_estimators': [200]\n            }\n        }\n    ]\n    \n    for model in tqdm(models):\n        print('\\n', '-'*25, '\\n', model['name'])\n        start = time.perf_counter()\n        grid = GridSearchCV(model['estimator'], param_grid=model['hyperparameters'], cv=5, scoring = \"neg_mean_squared_error\", verbose=False, n_jobs=-1)\n        grid.fit(X_train, y_train)\n        best_models[model['name']] = {'score': grid.best_score_, 'params': grid.best_params_}\n        mse_val = mean_squared_error(y_val, grid.predict(X_val))\n        mse_train = mean_squared_error(y_train, grid.predict(X_train))\n        print(\"RMSLE train:{}\".format(np.sqrt(mse_train))) \n        print(\"RMSLE validation:{}\".format(np.sqrt(mse_val)))\n        print(\"best_params_:{}\".format(grid.best_params_))\n        run = time.perf_counter() - start\n        \n        \n    return best_models","379a7928":"def get_best_parameters(train,features_list):\n\n    X_train = train[features_list]\n    y_train = np.log1p(train[\"revenue\"]).values\n      \n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1)\n\n    models = select_model(X_train, X_val, y_train, y_val)\n    return models","65fda56e":"# A class that will define all the regression models as methods\n\nclass Models(object):\n    \n    \n    \n    # Initialization \n    def __init__(self, x_train, x_validation, y_train, y_validation):\n        # changing input as dataframe to list\n        self.x_train = [x_train.iloc[i].tolist() for i in range(len(x_train))]\n        self.x_validation = [x_validation.iloc[i].tolist() for i in range(len(x_validation))]\n        self.y_train = y_train.tolist()\n        self.y_validation = y_validation.tolist()\n        \n    \n    \n    @staticmethod\n    def print_info(cross_val_scores, mse_train,mse_val):\n        print(\"Cross Validation Scores: \", cross_val_scores)\n        print(\"RMSLE train:{}\".format(np.sqrt(mse_train))) \n        print(\"RMSLE validation:{}\".format(np.sqrt(mse_val)))\n        #print(\"Mean Squared Error: \", np.sqrt(mse))\n        \n        \n  \n    # Gradient Boosting Regressor\n    def GBR(self, x_train, x_validation,  y_train, y_validation):\n        gbr = GradientBoostingRegressor(n_estimators=120, learning_rate=0.08,max_features='sqrt',criterion='friedman_mse',\n                                        min_samples_leaf=1,min_samples_split=3, max_depth=7, random_state=seed)\n        gbr.fit(self.x_train, self.y_train)\n        kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n        cross_val_scores = cross_val_score(gbr, self.x_train, self.y_train, cv=kfold)\n        mse_val = mean_squared_error(self.y_validation, gbr.predict(self.x_validation))\n        mse_train = mean_squared_error(self.y_train, gbr.predict(self.x_train))\n        print('\\nGradient Boosting Regressor')\n        self.print_info(cross_val_scores, mse_train,mse_val)\n        return cross_val_scores, mse_val, gbr\n    \n    \n    # LGBM Regressor \n    def lgbm(self, x_train, x_validation,  y_train, y_validation):\n        lgbm =lgb.LGBMRegressor(n_estimators=10000,objective=\"regression\", metric=\"rmse\",num_leaves=20, \n                             min_child_samples=100,learning_rate=0.01, bagging_fraction=0.8,feature_fraction=0.8, \n                             bagging_frequency=1,importance_type='gain', bagging_seed=seed,subsample=.9, \n                             colsample_bytree=.9,use_best_model=True)\n                                \n        lgbm.fit(x_train, y_train,eval_set=(x_validation, y_validation),verbose=False)\n    \n        kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n        cross_val_scores = cross_val_score(lgbm, self.x_train, self.y_train, cv=kfold)\n        mse_val = mean_squared_error(self.y_validation, lgbm.predict(self.x_validation))\n        mse_train = mean_squared_error(self.y_train, lgbm.predict(self.x_train))\n        print('\\nLGBM Regressor')\n        self.print_info(cross_val_scores, mse_train,mse_val)\n        return cross_val_scores, mse_val, lgbm\n    \n    \n    # XgBoost Regressor \n    def xgBoost(self, x_train, x_validation,  y_train, y_validation):\n        params = {'objective': 'reg:linear','eta': 0.01,'max_depth': 6,'subsample': 0.6,'colsample_bytree': 0.7,  \n              'eval_metric': 'rmse', 'seed': seed,'silent': True,}\n    \n        record = dict()\n        xg = xgb.train(params, xgb.DMatrix(x_train, y_train), 100000, [(xgb.DMatrix(x_train, y_train), 'train'),\n                                                                      (xgb.DMatrix(x_validation, y_validation), 'valid')]\n                      , verbose_eval=False, early_stopping_rounds=500, callbacks = [xgb.callback.record_evaluation(record)])\n        best_idx = np.argmin(np.array(record['valid']['rmse']))\n    \n        #kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n        #cross_val_scores = cross_val_score(xg, self.x_train, self.y_train, cv=kfold)\n        cross_val_scores= 0\n        mse_val = mean_squared_error(self.y_validation, xg.predict(xgb.DMatrix(x_validation), ntree_limit=xg.best_ntree_limit))\n        mse_train = mean_squared_error(self.y_train, xg.predict(xgb.DMatrix(x_train), ntree_limit=xg.best_ntree_limit))\n        print('\\nXgBoost Regressor')\n        self.print_info(cross_val_scores, mse_train,mse_val)\n        #plot_importance(xg)\n        #plt.show()\n        return cross_val_scores, mse_val, xg","bc1b9057":"def evaluate_models(train, test,features_list):\n\n    X_train = train[features_list]\n    y_train = np.log1p(train[\"revenue\"]).values\n      \n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1)\n\n    methods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\n    methods.remove('__init__')\n    # Now calling the all regression methods\n    cross_scores_list, mse_list = [], []\n    models = {}\n    for model in methods:\n        reg = Models(X_train, X_val, y_train, y_val)\n        cross_val_scores, mse, return_model = getattr(reg, model)(X_train, X_val, y_train, y_val)\n        cross_scores_list.append(cross_val_scores)\n        models[model] = return_model\n        mse_list.append(mse)\n    return models","1fd29efc":"#get_best_parameters(train,list(columns_to_keep))","bea16023":"#Evaluate models with best parameters and top 50 features based on correlation\ncorr_features_models = evaluate_models(train, test,corr_selected_features)","c73be041":"#Evaluate models with best parameters and  all features we created so far\nall_features_models = evaluate_models(train, test,list(columns_to_keep))","46cf7bb4":"def calculate_test_results(models,test,model_names,features_list):\n        \n    X_test = test[features_list]\n    pred = np.empty(shape=len(X_test)).tolist()\n    \n    for model in model_names:\n        mod = models[model]\n        if(model=='xgBoost'):\n            pred = pred + np.expm1(mod.predict(xgb.DMatrix(X_test), ntree_limit=mod.best_ntree_limit))\n        else:   \n            pred = pred + np.expm1(mod.predict(X_test))\n    \n    return pred","9c432585":"xgBoost_results = calculate_test_results(all_features_models,test,['xgBoost'],list(columns_to_keep))\ngbr_results = calculate_test_results(all_features_models,test,['GBR'],list(columns_to_keep))\nlgbm_results = calculate_test_results(all_features_models,test,['lgbm'],list(columns_to_keep))\n\n#final_pred = 0.4*xgBoost_results + 0.4*gbr_results + 0.2*lgbm_results  2.11835\n#final_pred = 0.7*xgBoost_results + 0.3*gbr_results 2.05313\n#final_pred = 0.3*xgBoost_results + 0.7*gbr_results 2.10757\n#final_pred = 0.6*xgBoost_results + 0.2*gbr_results + 0.2*lgbm_results  2.06723\n#final_pred = 0.8*xgBoost_results + 0.2*gbr_results 2.05289\nfinal_pred = 0.8*xgBoost_results + 0.2*lgbm_results \n#final_pred = 0.9*xgBoost_results + 0.1*gbr_results\n#final_pred = xgBoost_results  2.05923\n\nsubmission = pd.DataFrame()\nsubmission['id'] = test['id']\nsubmission['revenue'] = final_pred\nsubmission.to_csv('submission.csv', index=False)","98968b04":"###### inferences","91f92f18":"1.'revenue' is moderately correlated to 'spoken_languages_English'","96a5e0c6":"1.'revenue' is moderately correlated to 'production_countries_United States of America'","6629bc96":"###### inferences","a4cf72b0":"1.'revenue' is moderately correlated to 'original_title_length','title_count'<br>\n2.'original_title_length' and 'title_count' are highly correlated.Either one of them can be dropped.","f7cf2b6a":"## Model and Evaluation","60896680":"<a id='introduction'><\/a>","29685453":"There are null values in belongs_to_collection,homepage, tagline etc columns.But we will handle them when we explore those\nfeatures individually.","4ef8de0c":"We can create new feature if movie belongs to one of these three-English(en),Chinese(zh),Turkish(tr)","bb49f6fc":"There are multiple features with dictionary data stored as String.Let's create common method to process these features","cb8dc85a":"#### Explore:title vs revenue","3a2b50d9":"## Feature Engineering","abe3d487":"So we may have to fill these values.Because making movie with 0 budget is not possible.\nWe will check how to fill these missing values later(After analysing other columns)","b2d34455":"1.'revenue' is moderately correlated to 'Keywords_all','crew_all','cast_all','got_collection','genres_all'","09cbbf35":"## Feature Selection","fc6f32fa":"###### inferences","6b2bf9c5":"There is one null value in test set","8a4d46f9":"#### Explore: original_language vs revenue","1106065e":"#### Explore:overview vs revenue","55a50225":"#### text length features","5d4af40e":"###### inferences","2b8b5247":"We will encode these values(not one hot encoding)","e4b45930":"1.'revenue' is dependant on all numerical features we selected except 'spoken_languages_number','production_countries_number'<br>\n2.'popularity' is highly corelated to 'popularity_release_weekday','popularity_release_year',So keep 1 of 3<br>\n3.'generes_number' is highly corelated to 'generes_number_release_year'.So either one of them can be removed<br>\n4.'runtime' is highly corelated to 'runtime_release_year'.So either one of them can be removed<br>","1108e10f":"There is data for 36 languages but majority(2500+)movies in English","710bfaa2":"#### Explore:tagline vs revenue","109722df":"1.'revenue' is moderately correlated to 'crew_Steven Spielberg'","3b28830b":"#### crew_features ","467a8c56":"I don't think this feature with so many empty values will be useful to determine revenue.However,I see James Bond Collection repeated 16 times.So having collection may mean movie is part of franchise or it is famous one.","0cd0c8b1":"###### inferences","1ee937bd":"###### inferences","ddb3ac39":"Let's get top 50 features out of 106 features depending on correlation with revenue","8de2c13b":"We will find best parameters for models","36de84d8":"Let's summarize meaning of each column","e13474d7":"#### categorical_features","b254675e":"#### Explore:release_date vs revenue","6fedbf9f":"#### Clean Dictionary features","7e3106ab":"1.'revenue' is moderately correlated to 'production_companies_Paramount Pictures','production_companies_Walt Disney Pictures', 'production_companies_Warner Bros.'","fa6e18be":"## Data Preprocessing","1ef3e391":"It looks like positive correlation between title lenght and revenue","295788b7":"So it turns out all features we created so far give less RMSLE","095705a2":"#### spoken_language_features","e998bf57":"###### inferences","8257cd41":"<a id='preprocess'><\/a>","fef3bfba":"<a id='features'><\/a>","e464785b":"Budget data is positively skewed,so to normalise ,we'll take log of it","f796aa42":"This is my first Kaggle kernel.So very excited and looking forward to feedback from kaggle community.","604270c9":"#### Numerical features","bd671958":"## Content\n<a href='#introduction'>Introduction<\/a><br>\n<a href='#preprocess'>Data Preprocessing<\/a><br>\n<a href='#edafeatures'>EDA and Feature Engineering<\/a><br>\n<a href='#model'>Model and Evaluation<\/a><br>\n<a href='#submit'>Submission<\/a>","84b6bcc8":"We can see many values with very less budget,let's confirm with numbers","108186e2":"<a id='edafeatures'><\/a>","2df1bf58":"I am not sure how overview of movie would be helpful in deciding revenue","ef53f3a7":"## EDA and Feature Engineering","5fbdfb23":"#### production_countries_features","949a9d50":"#### Handle missing values","50b144a0":"We have 106 columns as feature,we will select features according to their importance to revenue","5e140070":"All movie buffs had a conversation with friends before movie release:'This movie is going to be hit','This is going to flop'\n.Data enthusiast in me always wondered,How the hell they are predicting it.They all had answers:'it's Avenger movie','Tom Cruise is starring in it' etc.\nWell,now I've got the opportunity to observe it myself,maybe next time I'll try to comment on success of movie and maybe they'll be impressed.","06cec185":"Only 4 movies are not released,so this feature won't add any value","b3821bf3":"1.'revenue' is moderately related to year,day of the week.It makes sense movies usually release on Friday.","7a361e11":"<a id='submit'><\/a>","0491171f":"English(en),Chinese(zh),Turkish(tr) movies have high revenue per movie compared to other languages","ef678dff":"###### inferences","8c829cc9":"#### Explore:status vs revenue","da03cd30":"There is linear relationship between budget and revenue.Let's find strenght of correlation \nbetween these two variables using Pearson\ncorrelation","05c5da24":"## Introduction","34f8e833":"#### Explore:original_title vs revenue","704d6396":"#### production_companies_features features","794640f6":"Thanks for reading through.Please upvote,comment if you liked it","e1db302f":"#### Explore: budget vs revenue","4428b56f":"###### inferences","65034dfc":"## Submission","35471cbf":"let's categorize these features which will simplify further analysis","bb55d1c7":"So let's create categorical feature-if movie belongs to collection.","b28275c1":"<a id='model'><\/a>","219ba083":"#### date features","0f0c677c":"We might need to deal with outliers","d8fdb498":"#### Explore: belongs_to_collection vs revenue","09b22e88":"#### Explore:runtime vs revenue","4ea95cf3":"#### genres_features  ","5073d3a2":"1.'revenue' is moderately correlated to 'genres_Action', 'genres_Adventure','genres_Drama', 'genres_Family',\n                  'genres_Science Fiction'","bd99e044":"Let's create set of columns which we think will be useful for revenue prediction","63ee8493":"Let's create some features based on our intution and domain knowledge","023c4674":"#### Explore:popularity vs revenue"}}