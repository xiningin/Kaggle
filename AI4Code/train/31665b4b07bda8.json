{"cell_type":{"486582e5":"code","7b33dbc5":"code","6a3fc1d7":"code","34eafc48":"code","01525594":"code","af4640dc":"code","168d378d":"code","0ff87469":"code","129333c1":"code","87d9c6ff":"code","a0e386fd":"code","09b3ce32":"code","6ab61901":"code","a151b0f2":"code","42ddb6d0":"code","d5b1d680":"code","428f11fd":"code","825bf314":"code","637e4846":"code","f1425cd6":"code","0376b154":"code","c061b77b":"code","b63e268c":"code","bb205f53":"code","0324edc7":"code","0b406c97":"code","75313a9d":"code","17686a1e":"code","4b76a5f7":"code","0e3c075c":"code","6e839803":"code","35ddef15":"code","2dddbab3":"code","0854942b":"code","4f676962":"code","9d78c1fe":"code","4f8af332":"code","c095cbd2":"code","3252c60d":"code","009061d6":"code","55b709ec":"code","9c7da0cf":"code","356c1ee1":"code","c214cd0a":"code","a8626eeb":"markdown","c5b7275c":"markdown","45e8157d":"markdown","b1a8d250":"markdown","401e95ba":"markdown","f5b4ed95":"markdown","418a9ae7":"markdown","8b0484fa":"markdown","02230a59":"markdown","388a985c":"markdown","9fdc8308":"markdown","6f3f7f23":"markdown","2d34e5d5":"markdown","2e3307c0":"markdown","46265d92":"markdown","da60afae":"markdown","0333ef2e":"markdown","7a24f7ad":"markdown","7823a31b":"markdown","91611411":"markdown","30beba0a":"markdown","dfd66f99":"markdown","b25db448":"markdown","9c84249d":"markdown"},"source":{"486582e5":"from IPython.core.display import display, HTML\ndisplay(HTML('<style>.container {width:98% !important;}<\/style>'))","7b33dbc5":"import numpy as np\nimport pandas as pd\n\nimport random\nrandom.seed(28)\nnp.random.seed(28)\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support)\nimport os\nimport copy\nfrom sklearn.metrics import mean_absolute_error\npd.options.display.precision = 15\nfrom collections import defaultdict\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cat\nimport time\nfrom collections import Counter\nimport datetime\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\nfrom sklearn import metrics\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom bayes_opt import BayesianOptimization\nimport eli5\nimport shap\nfrom IPython.display import HTML\nimport json\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport time\nimport datetime\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\npd.set_option('max_rows', 500)\nimport re\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_columns', 1000)\nnp.random.seed(566)\npd.set_option('display.max_rows', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.float_format', '{:20,.2f}'.format)\npd.set_option('display.max_colwidth', -1)","6a3fc1d7":"train = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/training_v2.csv\")\nsamplesubmission = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/samplesubmission.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/unlabeled.csv\")\ndictionary = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/WiDS Datathon 2020 Dictionary.csv\")\nsolution_template = pd.read_csv(\"\/kaggle\/input\/widsdatathon2020\/solution_template.csv\")\n\nprint('train ' , train.shape)\nprint('test ' , test.shape)\nprint('samplesubmission ' , samplesubmission.shape)\nprint('solution_template ' , solution_template.shape)\nprint('dictionary ' , dictionary.shape)","34eafc48":"dico=pd.DataFrame(dictionary.T.head(6))\ndico.columns=list(dico.loc[dico.index == 'Variable Name'].unstack())\ndico = dico.loc[dico.index != 'Variable Name']\ndico.columns\ntrain_stat = pd.DataFrame(train.describe())\ntrain_stat2 = pd.concat([dico,train_stat],axis=0)\ntrain_stat2.head(20)","01525594":"train_stat2.T.head(200)","af4640dc":"import missingno as msno\n%matplotlib inline","168d378d":"msno.matrix(train.sample(1000),figsize=(35, 60), width_ratios=(10, 1), color=(.0, 0.5, 0.5),           fontsize=16)","0ff87469":"for color, variable in enumerate(dictionary['Category'].unique()) :\n  if variable not in ['GOSSIS example prediction','identifier']  :\n    print(variable)\n    column_list = list(dictionary[dictionary['Category']==variable]['Variable Name'].values)\n    column_list = [f for f in column_list if f in train.columns]\n    if len(column_list) > 0:\n        msno.matrix(train[column_list].sample(1000),figsize=(30, 10), labels=True, color=(color\/10, 1\/(color+1), 0.5),  fontsize=16)\n        msno.heatmap(train[column_list],figsize=(10, 10)     ,  labels=False,    fontsize=14)\n        plt.show()","129333c1":"msno.heatmap(train,figsize=(35, 40)     ,  labels=False,    fontsize=10)","87d9c6ff":"msno.dendrogram(train,fontsize=14)","a0e386fd":"msno.bar(train.sample(10000))","09b3ce32":"# function to evaluate the score of our model\ndef eval_auc(pred,real):\n    false_positive_rate, recall, thresholds = roc_curve(real, pred)\n    roc_auc = auc(false_positive_rate, recall)\n    return roc_auc    ","6ab61901":"# a wrapper class  that we can have the same ouput whatever the model we choose\nclass Base_Model(object):\n    \n    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=10, verbose=True,ps={}):\n        self.train_df = train_df\n        self.test_df = test_df\n        self.features = features\n        self.n_splits = n_splits\n        self.categoricals = categoricals\n        self.target = 'hospital_death'\n        self.cv = self.get_cv()\n        self.verbose = verbose\n#         self.params = self.get_params()\n        self.params = self.set_params(ps)\n        self.y_pred, self.score, self.model , self.oof_pred = self.fit()\n        \n    def train_model(self, train_set, val_set):\n        raise NotImplementedError\n        \n    def get_cv(self):\n        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        return cv.split(self.train_df, self.train_df[self.target])\n    \n    def get_params(self):\n        raise NotImplementedError\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        raise NotImplementedError\n        \n    def convert_x(self, x):\n        return x\n        \n    def fit(self):\n        oof_pred = np.zeros((len(self.train_df), ))\n        y_pred = np.zeros((len(self.test_df), ))\n        for fold, (train_idx, val_idx) in enumerate(self.cv):\n            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n            model = self.train_model(train_set, val_set)\n            conv_x_val = self.convert_x(x_val)\n            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n            x_test = self.convert_x(self.test_df[self.features])\n            y_pred += model.predict(x_test).reshape(y_pred.shape) \/ self.n_splits\n\n            print('Partial score of fold {} is: {}'.format(fold,eval_auc(oof_pred[val_idx],y_val) ))\n        #print(oof_pred, self.train_df[self.target].values)\n        loss_score = eval_auc(oof_pred,self.train_df[self.target].values) \n        if self.verbose:\n            print('Our oof AUC score is: ', loss_score)\n        return y_pred, loss_score, model , oof_pred","a151b0f2":"#we choose to try a LightGbM using the Base_Model class\nclass Lgb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100 if self.verbose else 0\n        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n        val_set   = lgb.Dataset(x_val,    y_val,  categorical_feature=self.categoricals)\n        return train_set, val_set\n        \n    def get_params(self):\n        params = {'n_estimators':50000,\n                    'boosting_type': 'gbdt',\n                    'objective': 'binary',\n                    'metric': 'auc',\n                    'subsample': 0.75,\n                    'subsample_freq': 1,\n                    'learning_rate': 0.1,\n                    'feature_fraction': 0.9,\n                    'max_depth': 15,\n                    'lambda_l1': 1,  \n                    'lambda_l2': 1,\n                    'early_stopping_rounds': 100,\n                    #'is_unbalance' : True ,\n                    'scale_pos_weight' : 3\n                  \n                    }\n        return params\n    def set_params(self,ps={}):\n        params = self.get_params()\n        if 'subsample_freq' in ps:\n            params['subsample_freq']=int(ps['subsample_freq'])\n            params['learning_rate']=ps['learning_rate']\n            params['feature_fraction']=ps['feature_fraction']\n            params['lambda_l1']=ps['lambda_l1']\n            params['lambda_l2']=ps['lambda_l2']\n            params['scale_pos_weight']=ps['scale_pos_weight']\n            params['max_depth']=int(ps['max_depth'])\n        \n        return params  ","42ddb6d0":"train['apache_3j_diagnosis_split0'] = np.where(train['apache_3j_diagnosis'].isna() , np.nan , train['apache_3j_diagnosis'].astype('str').str.split('.',n=1,expand=True)[0]  )\ntest['apache_3j_diagnosis_split0']   = np.where(test['apache_3j_diagnosis'].isna() , np.nan , test['apache_3j_diagnosis'].astype('str').str.split('.',n=1,expand=True)[0]  )\n","d5b1d680":"#we are going to drop these columns because we dont want our ML model to be bias toward these consideration\n#(we also remove the target and the ids.)\nto_drop = ['gender','ethnicity' ,'encounter_id', 'patient_id',  'hospital_death']\n\n# this is a list of features that look like to be categorical\ncategoricals_features = ['hospital_id','ethnicity','gender','hospital_admit_source','icu_admit_source','icu_stay_type','icu_type','apache_3j_bodysystem','apache_2_bodysystem','apache_3j_diagnosis_split0']\ncategoricals_features = [col for col in categoricals_features if col not in to_drop]\n\n# this is the list of all input feature we would like our model to use \nfeatures = [col for col in train.columns if col not in to_drop ]\nprint('numerber of features ' , len(features))\nprint('shape of train \/ test ', train.shape , test.shape)","428f11fd":"# categorical feature need to be transform to numeric for mathematical purpose.\n# different technics of categorical encoding exists here we will rely on our model API to deal with categorical\n# still we need to encode each categorical value to an id , for this purpose we use LabelEncoder\n\nprint('Transform all String features to category.\\n')\nfor usecol in categoricals_features:\n    train[usecol] = train[usecol].astype('str')\n    test[usecol] = test[usecol].astype('str')\n    \n    #Fit LabelEncoder\n    le = LabelEncoder().fit(\n            np.unique(train[usecol].unique().tolist()+\n                      test[usecol].unique().tolist()))\n\n    #At the end 0 will be used for null values so we start at 1 \n    train[usecol] = le.transform(train[usecol])+1\n    test[usecol]  = le.transform(test[usecol])+1\n    \n    train[usecol] = train[usecol].replace(np.nan, 0).astype('int').astype('category')\n    test[usecol]  = test[usecol].replace(np.nan, 0).astype('int').astype('category')","825bf314":"# percentage of death , hopefully it s a bit unbalanced\ntrain['hospital_death'].sum()\/train['hospital_death'].count()","637e4846":"def LGB_Beyes(subsample_freq,\n                    learning_rate,\n                    feature_fraction,\n                    max_depth,\n                    lambda_l1,\n                    lambda_l2,\n                    scale_pos_weight):\n    params={}\n    params['subsample_freq']=subsample_freq\n    params['learning_rate']=learning_rate\n    params['feature_fraction']=feature_fraction\n    params['lambda_l1']=lambda_l1\n    params['lambda_l2']=lambda_l2\n    params['max_depth']=max_depth\n    params['scale_pos_weight']=scale_pos_weight\n    \n    lgb_model= Lgb_Model(train, test, features, categoricals=categoricals_features,ps=params)\n    print('auc: ',lgb_model.score)\n    return lgb_model.score\n\nbounds_LGB = {\n    'subsample_freq': (1, 10),\n    'learning_rate': (0.005, 0.02),\n    'feature_fraction': (0.5, 1),\n    'lambda_l1': (0, 5),\n    'lambda_l2': (0, 5),\n    'max_depth': (13, 17),\n    'scale_pos_weight': (1, 10),\n}\n\n# ACTIVATE it if you want to search for better parameter\nif 0 : \n    LGB_BO = BayesianOptimization(LGB_Beyes, bounds_LGB, random_state=1029)\n    import warnings\n    init_points = 16\n    n_iter = 16\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore')    \n        LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)","f1425cd6":"params = {'feature_fraction': 0.8,\n 'lambda_l1': 1,\n 'lambda_l2': 1,\n 'learning_rate': 0.001,\n 'max_depth': 13,\n 'subsample_freq': 1,\n 'scale_pos_weight':1}","0376b154":"if 0: # ACTIVATE it if you want to search for better parameter\n    lgb_model = Lgb_Model(train,test, features, categoricals=categoricals_features, ps= LGB_BO.max['params']  )\nelse :\n    lgb_model = Lgb_Model(train,test, features, categoricals=categoricals_features, ps=params)","c061b77b":"imp_df = pd.DataFrame()\nimp_df['feature'] = features\nimp_df['gain']  = lgb_model.model.feature_importance(importance_type='gain')\nimp_df['split'] = lgb_model.model.feature_importance(importance_type='split')","b63e268c":"def plot_importances(importances_):\n    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n    plt.figure(figsize=(18, 44))\n    data_imp = importances_.sort_values('mean_gain', ascending=False)\n    sns.barplot(x='gain', y='feature', data=data_imp[:300])\n    plt.tight_layout()\n    plt.savefig('importances.png')\n    plt.show()","bb205f53":"plot_importances(imp_df)","0324edc7":"import shap\nexplainer   =  shap.TreeExplainer(lgb_model.model)\nshap_values = explainer.shap_values(train[features].iloc[:1000,:])\nshap.summary_plot(shap_values, train[features].iloc[:1000,:])","0b406c97":"import warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=UserWarning)\ni=0\nfor index, row in imp_df.sort_values(by=['gain'],ascending=False).iterrows():  \n    column=row['feature']\n    if i< 50:\n            print(column,i,\"gain :\",row['gain'])\n            df1      = train.loc[train['hospital_death']==0]\n            df2      = train.loc[train['hospital_death']==1]\n\n            fig = plt.figure(figsize=(20,4))\n            sns.distplot(df1[column].dropna(),  color='green', label='hospital_death 0', kde=True); \n            sns.distplot(df2[column].dropna(),  color='red', label='hospital_death 1', kde=True); \n            fig=plt.legend(loc='best')\n            plt.xlabel(column, fontsize=12);\n            plt.show()\n            i=i+1\n","75313a9d":"def adversarial_validation(train, test, features):\n    \n    tr_data   = train.copy()\n    tst_data = test.copy()\n    tr_data['target']  = 0 \n    tst_data['target'] = 1\n    av_data = pd.concat([tr_data, tst_data], axis = 0)\n    av_data.reset_index(drop = True)        \n    params = {\n            'learning_rate': 0.1, \n            'seed': 50,\n            'objective':'binary',\n            'boosting_type':'gbdt',\n            'metric': 'auc',\n        }    \n    # define a KFold strategy\n    kf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n    target = 'target'\n    oof_pred = np.zeros(len(av_data))\n    important_features = pd.DataFrame()\n    fold_auc = []    \n    \n    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, av_data[target])) :\n        print('Fold {}'.format(fold + 1))\n        x_train, x_val = av_data[features].iloc[tr_ind], av_data[features].iloc[val_ind]\n        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set   = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(params, train_set, num_boost_round = 1000, early_stopping_rounds = 20, valid_sets = [train_set, val_set], verbose_eval = 100)\n        \n        fold_importance = pd.DataFrame()\n        fold_importance['feature'] = features\n        fold_importance['gain'] = model.feature_importance()\n        important_features = pd.concat([important_features, fold_importance], axis = 0)\n        \n        oof_pred[val_ind] = model.predict(x_val)\n        fold_auc.append(metrics.roc_auc_score(y_train, model.predict(x_train)))\n        \n    print('Our mean train roc auc score is :', np.mean(fold_auc))\n    print('Our oof roc auc score is :', metrics.roc_auc_score(av_data[target], oof_pred))\n    return important_features\n\n","17686a1e":"adversarial_features = adversarial_validation(train, test, features)","4b76a5f7":"adversarial_features = adversarial_features[['gain', 'feature']].groupby('feature').mean().reset_index()\nadversarial_features= adversarial_features.sort_values('gain', ascending=False)\nplot_importances(adversarial_features)","0e3c075c":"import warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=UserWarning)\ni=0\nfor index, row in adversarial_features.sort_values(by=['gain'],ascending=False).iterrows():  \n    column=row['feature']\n    if i< 3:\n            print(column,i,\"gain :\",row['gain'])\n            df1      = train.copy()\n            df2      = test.copy()\n\n            fig = plt.figure(figsize=(20,4))\n            sns.distplot(df1[column].dropna(),  color='yellow', label='train', kde=True); \n            sns.distplot(df2[column].dropna(),  color='violet', label='test', kde=True); \n            fig=plt.legend(loc='best')\n            plt.xlabel(column, fontsize=12);\n            plt.show()\n            i=i+1","6e839803":"adversarial_features2 = adversarial_validation(train, test, [ f for f in features if f not in ['icu_id'] ])","35ddef15":"adversarial_features2 = adversarial_features2[['gain', 'feature']].groupby('feature').mean().reset_index()\nadversarial_features2= adversarial_features2.sort_values('gain', ascending=False)\nplot_importances(adversarial_features2)","2dddbab3":"import warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=UserWarning)\ni=0\nfor index, row in adversarial_features2.sort_values(by=['gain'],ascending=False).iterrows():  \n    column=row['feature']\n    if i< 3:\n            print(column,i,\"gain :\",row['gain'])\n            df1      = train.copy()\n            df2      = test.copy()\n\n            fig = plt.figure(figsize=(20,4))\n            sns.distplot(df1[column].dropna(),  color='yellow', label='train', kde=True); \n            sns.distplot(df2[column].dropna(),  color='violet', label='test', kde=True); \n            fig=plt.legend(loc='best')\n            plt.xlabel(column, fontsize=12);\n            plt.show()\n            i=i+1","0854942b":"common_id  = list([id for id in train['hospital_id'].unique() if id in test['hospital_id'].unique() ])\nid_only_in_train  = [id for id in train['hospital_id'].unique() if id not in test['hospital_id'].unique() ]\nid_only_in_test   = [id for id in test['hospital_id'].unique()  if id not in train['hospital_id'].unique() ]\ncount_common_train = train.loc[train['hospital_id'].isin(common_id)].shape[0]\ncount_common_test  = test.loc[test['hospital_id'].isin(common_id)].shape[0]\n\ncount_train = train.loc[train['hospital_id'].isin(id_only_in_train)].shape[0]\ncount_test  = test.loc[test['hospital_id'].isin(id_only_in_test)].shape[0]\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n \nfig = plt.figure(figsize=(20,6))\nvenn2(subsets = (count_train,  count_test, count_common_train+count_common_test), set_labels = ('Hospital only in train', 'Hospital only in test'),set_colors=('purple', 'yellow'), alpha = 0.7);\nplt.show()","4f676962":"adversarial_features3 = adversarial_validation(train, test, [ f for f in features if f not in ['icu_id','hospital_id'] ])","9d78c1fe":"adversarial_features3 = adversarial_features3[['gain', 'feature']].groupby('feature').mean().reset_index()\nadversarial_features3= adversarial_features3.sort_values('gain', ascending=False)\nplot_importances(adversarial_features3)","4f8af332":"import warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=UserWarning)\ni=0\nfor index, row in adversarial_features3.sort_values(by=['gain'],ascending=False).iterrows():  \n    column=row['feature']\n    if i< 5:\n            print(column,i,\"gain :\",row['gain'])\n            df1      = train.copy()\n            df2      = test.copy()\n\n            fig = plt.figure(figsize=(20,4))\n            sns.distplot(df1[column].dropna(),  color='yellow', label='train', kde=True); \n            sns.distplot(df2[column].dropna(),  color='violet', label='test', kde=True); \n            fig=plt.legend(loc='best')\n            plt.xlabel(column, fontsize=12);\n            plt.show()\n            i=i+1","c095cbd2":"more_drop = ['hospital_id','icu_id','apache4ahospitaldeathprob', 'apache4aicudeath_prob']\nfeatures = [col for col in features if col not in more_drop] \ncategoricals_features = [col for col in categoricals_features if col not in more_drop] \nlgb_model1 = Lgb_Model(train,test, features, categoricals=categoricals_features, ps=params)","3252c60d":"#OHE\nprint('Transform all String features to OHE.\\n')\nfor usecol in categoricals_features:\n    train[usecol] = train[usecol].astype('str')\n    test[usecol] = test[usecol].astype('str')\n    \n    train=pd.concat([train,pd.get_dummies(train[usecol],drop_first=True, prefix=usecol)],axis=1)\n    test =pd.concat([test ,pd.get_dummies(test[usecol],drop_first=True, prefix=usecol)],axis=1)\n    del train[usecol], test[usecol]","009061d6":"features = [col for col in train.columns if col not in to_drop and col in test.columns ]","55b709ec":"lgb_model2 = Lgb_Model(train,test, features, categoricals=[], ps=params)","9c7da0cf":"test[\"hospital_death\"] = lgb_model1.y_pred * 0.7 + lgb_model2.y_pred * 0.3 \ntest[[\"encounter_id\",\"hospital_death\"]].to_csv(\"submission.csv\",index=False)","356c1ee1":"test[\"hospital_death\"] = lgb_model1.y_pred \ntest[[\"encounter_id\",\"hospital_death\"]].to_csv(\"submission1.csv\",index=False)","c214cd0a":"test[\"hospital_death\"] = lgb_model2.y_pred \ntest[[\"encounter_id\",\"hospital_death\"]].to_csv(\"submission2.csv\",index=False)","a8626eeb":"* starter LGB with no feature engering \/\n\n* added some viz about null values\n\n* added adversarial validation ","c5b7275c":"**hospital_id** seems to be also from a different distribution.\nWe can check it directly, obviously only few hospital are common to both dataset ..","45e8157d":"So icu_id columns seems to be the feature that dominate the feature importance for the adversarial validation model, so it is likely to be totally different between train and test, lets check the distribution of the top features :","b1a8d250":"# Some univariate plot of the best feature","401e95ba":"## Heatmap showing the correlation of missingness between every 2 columns\n\nA value near -1 means if one variable appears then the other variable is very likely to be missing.\n\nA value near 0 means there is no dependence between the occurrence of missing values of two variables.\n\nA value near 1 means if one variable appears then the other variable is very likely to be present.\n","f5b4ed95":"# OverView of the dataset","418a9ae7":"# Feature Importance by permutation importance algo","8b0484fa":"# dendrogram visualization \nIt is based on hierachical clustering of missing values, so it shows a tree representing groupings of columns that have strong nullity correlations. so it identifies groups that are correlated, rather than simple pairs (as in the heatmap)","02230a59":"## Due to the amout of features we will split the dataset by category ","388a985c":"Feature Importance from the lightgbm model (gain)","9fdc8308":"run the adversatial model with all the feature we used :","6f3f7f23":"# APACHE III Scoring Card :\nHere is the way apache score (hence the apache probas when rescale to 0-1) is computed :\n\n<img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F273819%2F407c8f1acd66feba1e4ddafb1c8f3a12%2FAPACHEIII_scorecard.png?generation=1579776903551461&alt=media\" alt=\"APACHE III Scoring Card\" \/>","2d34e5d5":"# Read the data","2e3307c0":"# Bar chart\n\nThis bar chart gives you an idea about how many missing values are there in each column. ","46265d92":"AUC is almost perfect so we can expect that **some feature are perfectly different between train \/ test**","da60afae":"it is ....\nLet's remove **icu_id** and see the results ..","0333ef2e":"I leave it to you to see what you can do with other features..","7a24f7ad":"# Adversarial Validation\n\nThe main idea of adversarial validation is to detect shift\/drift in the different features between 2 datasets. \n\nWe usually train a model on past data to forecast future data so it can happened that these futures datas have a distribution that is no longer in line with the data we used for training, or maybe we train on some hospital datas and apply our model on other hospital ?\n\nYou can detect drift by statistical test (like t-test) but here we will do it by training a machine learning model and check if the model can figure out if the data is from the train or test set. If it can, this means that the test data comes from another distribution compare to the train data and then you have to check the distribution of the most important features that are likely to be different between train and test.","7823a31b":"### categorical feature need to be transform to numeric for mathematical purpose.\n\ndifferent technics of categorical encoding exists here we will rely on our model to deal with categorical data,\nstill we need to encode each categorical value to an id , for this purpose we use LabelEncoder\n","91611411":"# Have a look at missing value","30beba0a":"Let's do an ultimate try **without 'icu_id','hospital_id'**","dfd66f99":"# Modele","b25db448":"# Hyper parameter tuning","9c84249d":"## Matrix \n\nUsing this matrix you can very quickly find the pattern of missingness in the dataset.\n\n--> lots of data are missing, for some of them you cannot do anything so just impute with a fixed value , for those that are missing with no specific reason you can try fixex imputation , mean\/median, or to predict it with other value (just try with CV to see what is the best choice for each feature \/ group of feature ) .\n"}}