{"cell_type":{"7ec36f42":"code","04ddf93d":"code","7c3c7314":"code","62aed83b":"code","6bb5a5df":"code","6dafe7fa":"code","5330b8f2":"code","c7e4a18d":"code","63362c23":"code","5dfcd74f":"code","2c08431b":"code","b951d031":"code","22283fcf":"code","23b58f22":"code","28ebaaac":"code","0db5b0da":"code","37e97035":"code","d644df67":"code","a8518628":"markdown","1df7bd24":"markdown","2dc7e74e":"markdown","acb2d477":"markdown","0ff7cdff":"markdown","a6dec042":"markdown"},"source":{"7ec36f42":"!pip install --upgrade scikit-learn scikit-learn-intelex --progress-bar off >> z_pip_installs.log","04ddf93d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearnex import patch_sklearn\npatch_sklearn()","7c3c7314":"DF = pd.read_csv('..\/input\/geocoding-singapore-flats-reusable-output\/flat-prices-geocode-added.csv')\nDF\n\n# A pretty large dataset!","62aed83b":"# There is no missing values\nDF.isnull().sum()","6bb5a5df":"# Variable types\nDF.dtypes","6dafe7fa":"# Visualize price trend over time\n# Blue line represents July 1997 Asian financial crisis\nfrom matplotlib import ticker\n\nfig, ax = plt.subplots(figsize = (15, 8))\nsns.boxplot(data = DF, x = 'month', y = 'resale_price', ax = ax)\nax.xaxis.set_major_locator(ticker.MultipleLocator(12)) # Tick every 12 i.e. per year\nax.axvline(90)\n\nplt.show()","5330b8f2":"# Price w.r.t other features of the flat\n\nfrom matplotlib import gridspec\nfig = plt.figure(figsize = (15, 10))\ngs = gridspec.GridSpec(3, 3, figure = fig)\n\n# Town\nax = fig.add_subplot(gs[0:2, 0:2])\n_order = DF.groupby('town').agg({'resale_price': 'mean'}).sort_values('resale_price', ascending = False).index\nsns.boxenplot(data = DF, x = 'resale_price', y = 'town', order = _order,\n              ax = ax)\n\n# Flat type\n_order = sorted(DF['flat_type'].unique())\nax = fig.add_subplot(gs[0, 2])\nsns.boxenplot(data = DF, x = 'resale_price', y = 'flat_type', order = _order,\n              ax = ax)\n\n# Flat model\nax = fig.add_subplot(gs[1, 2])\nsns.boxenplot(data = DF, x = 'resale_price', y = 'flat_model',\n              ax = ax)\n\n# Storey\n_order = sorted(DF['storey_range'].unique(), reverse = True)\nax = fig.add_subplot(gs[2, 2])\nsns.boxenplot(data = DF, x = 'resale_price', y = 'storey_range', order = _order,\n              ax = ax)\n\n# Lease commence date\nax = fig.add_subplot(gs[2,0:2])\nsns.boxenplot(data = DF, x = 'lease_commence_date', y = 'resale_price',\n              ax = ax)\nax.xaxis.set_major_locator(ticker.MultipleLocator(5))\nplt.tight_layout()\nplt.show()","c7e4a18d":"# Literal \"nearest neighbors\", i.e.\n# correlation between price of a flat with nearest flats\n# according to latitude and longitude.\n\nfrom sklearn.neighbors import KNeighborsRegressor\n\nliteral_neighbors_X = DF[['latitude', 'longitude']]\nprice = DF['resale_price']\n\nKs = [3, 5, 10, 15]\n\nliteral_neighbors_prices_df = pd.DataFrame({\n    k: KNeighborsRegressor(n_neighbors = k).fit(literal_neighbors_X, price).predict(literal_neighbors_X) for k in Ks\n})\n\nliteral_neighbors_prices_df['actual_price'] = price\n\n\nsns.heatmap(literal_neighbors_prices_df.corr(), vmin = -1, vmax = 1, annot = True, cmap = 'RdBu')\nplt.show()\n# Not much of a correlation, eh?","63362c23":"# Nearest neighbors, too, but using kernel trick to approximate\n# neighborhood influence instead\n\nfrom sklearn.svm import SVR\n\nneighbor_svr = SVR(kernel = 'rbf', C = 50, gamma = 1.5)\nneighbor_svr.fit(DF[['longitude', 'latitude']], price)\n\nx_min, x_max = DF['longitude'].min() - 0.1, DF['longitude'].max() + 0.1\ny_min, y_max = DF['latitude'].min() - 0.1, DF['latitude'].max() + 0.1\n\n# The code below is attributed to (with my own modification)\n# https:\/\/github.com\/tirthajyoti\/Machine-Learning-with-Python\/blob\/8f5dfc9b5e98c27ce3e600f655e143c6d91dd0fd\/Utilities\/ML-Python-utils.py\n\nh = 0.05\n\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = neighbor_svr.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nplt.contourf(xx, yy, Z, alpha=0.4)\nplt.scatter(DF['longitude'], DF['latitude'], c=price, alpha=0.8)\nplt.xlabel(\"Longitude\",fontsize=12)\nplt.ylabel(\"Latitude\",fontsize=12)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","5dfcd74f":"# Distance from Changi airport\n\nfrom geopy import geocoders, distance\n\nchangi = geocoders.Nominatim(user_agent = 'kaggle_ds').geocode('Changi Airport')\nchangi_latlon = (changi.latitude, changi.longitude)\n\nflats_latlon = [(flat['latitude'], flat['longitude']) for idx, flat in DF.iterrows()]\n\nchangi_df = pd.DataFrame({\n    'distance': [distance.distance(changi_latlon, x).km for x in flats_latlon]\n})\n\nchangi_df['price'] = price\n\nsns.regplot(data = changi_df, x = 'distance', y = 'price',\n            lowess = True,\n            scatter_kws = {'color': 'black', 'alpha': 0.05})\n\n# Not-so-impressive effect","2c08431b":"# Putting together everything\n\nX = DF.drop('resale_price', axis = 1)\ny = DF['resale_price']\n\n# Use month info to relate to July 1997 crisis\nX[['year', 'month']] = X['month'].str.split('-', expand = True).astype(int)\nX['month_before_crisis'] = 12*(1997 - X['year']) + (6 - X['month'])\n\n# Drop street address and block\nX = X.drop(['street_name', 'block'], axis = 1)\n\n# Display final predictor dataframe\nX","b951d031":"# Make preprocessor for X\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.compose import make_column_transformer\n\nohe_cols = ['town', 'flat_type', 'flat_model']\nohe = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n\nordinal_cols = ['storey_range']\nordinal = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n\npass_cols = [col for col in X.columns if col not in (ohe_cols + ordinal_cols)]\n\npreprocessor = make_column_transformer(\n    (ohe, ohe_cols),\n    (ordinal, ordinal_cols),\n    ('passthrough', pass_cols)\n)","22283fcf":"X = preprocessor.fit_transform(X)\ncolnames = preprocessor.named_transformers_['onehotencoder'].get_feature_names_out().tolist()\ncolnames.extend(ordinal_cols)\ncolnames.extend(pass_cols)\n\nX = pd.DataFrame(X, columns = colnames)\nX","23b58f22":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.1, random_state=2311\n)","28ebaaac":"from sklearn.ensemble import GradientBoostingRegressor\nfrom skopt import BayesSearchCV, space, plots\n\nmodel = GradientBoostingRegressor()\n\nparams = dict(\n    n_estimators = space.Integer(10, 1_000),\n    max_depth = space.Integer(1, 4),\n    subsample = space.Real(0.7, 1)\n)\n\nbs = BayesSearchCV(model, params, n_iter = 30, cv = 3,\n                   scoring = 'neg_mean_absolute_percentage_error',\n                   refit = False, verbose = 3)\n\nbs.fit(X_train, y_train)","0db5b0da":"plots.plot_objective(bs.optimizer_results_[0],\n                     size = 3, levels = 30)\nplt.show()","37e97035":"model.set_params(**bs.best_params_)\nmodel.fit(X_train, y_train)","d644df67":"from sklearn.inspection import permutation_importance\n\nresult = permutation_importance(\n    model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n)\nsorted_idx = result.importances_mean.argsort()\n\nfig, ax = plt.subplots(figsize = (10, 10))\nplt.boxplot(\n    result.importances[sorted_idx].T,\n    vert=False,\n    labels=np.array(colnames)[sorted_idx],\n)\nplt.title(\"Permutation Importance (test set)\")\nfig.tight_layout()\nplt.show()","a8518628":"# Conclusion","1df7bd24":"# Data Partition","2dc7e74e":"# Introduction","acb2d477":"# Modeling","0ff7cdff":"# Feature Exploration, Engineering, Visuals","a6dec042":"This is a work-in-progress."}}