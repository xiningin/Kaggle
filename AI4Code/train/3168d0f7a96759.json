{"cell_type":{"069c3c93":"code","dbfdb2a3":"code","81f6fb36":"code","ea865612":"code","4f73be6d":"code","ce9d0b24":"code","1d89c830":"code","af29a417":"code","7498709c":"code","afdaa5a8":"code","72bc62d4":"code","b0bca877":"code","2682e175":"code","db9556c6":"code","071f4c13":"code","223993f8":"code","6076e604":"code","21c19dcb":"code","b4611201":"code","7b28be46":"code","e9b9066a":"code","fbc8ea0d":"code","bb384dfb":"code","e0db1a99":"code","62409cd1":"code","f7b097e7":"code","1272b977":"code","790f8069":"code","31b87776":"code","69accdbc":"code","265c3b08":"code","a2a42fe1":"code","236abbeb":"code","2330d345":"code","aba34893":"code","ad1091ed":"code","c1bfac8e":"code","9e95f00f":"code","e540d5be":"code","8d5932c3":"code","c5358cef":"code","59c0f462":"code","f45f27c4":"code","2f0f1a90":"code","909967b2":"code","3b4c74a2":"code","cb6c2eb5":"code","7e572829":"code","d9c6dd13":"code","534a9a7a":"code","5b90d2c1":"code","2e67bfa8":"code","2ff4f09c":"code","b2e401d4":"code","70b2e4a4":"code","0c8f334a":"code","a3aeeb06":"code","1882d638":"code","0a2ded99":"code","0d37eb35":"code","46717fe0":"code","81325955":"code","0cd4e400":"code","7c274ed2":"code","d6fb018f":"code","63782dfd":"code","00cd4d7c":"code","3a6b2ad0":"markdown","ccaa8c35":"markdown","e38e9e8a":"markdown","9d86c087":"markdown","e99fe041":"markdown","277ccf56":"markdown","b46e63cc":"markdown","eaed8008":"markdown","41892b1f":"markdown","dc256121":"markdown","e74151e8":"markdown","03206878":"markdown","2229d3af":"markdown","4505ccf8":"markdown","2d678b3d":"markdown","c851273a":"markdown","1e3ad9cf":"markdown","7e2d0ac6":"markdown","a125e562":"markdown","a55c5dc4":"markdown","07d13726":"markdown","53212c08":"markdown","a6e37154":"markdown","98dcbe7d":"markdown","0ec4ba33":"markdown","27c20773":"markdown","a1e56f11":"markdown","47511d53":"markdown","25f832b8":"markdown","c74cac79":"markdown","6aa2397e":"markdown","33206c08":"markdown","459bd108":"markdown","d9516480":"markdown","63afe819":"markdown","0975c69e":"markdown","82588d80":"markdown","db3f09ac":"markdown","581c0e45":"markdown","03fe2935":"markdown","52e683a3":"markdown","536e0a93":"markdown","f1c83e6a":"markdown","ddf37b39":"markdown","dde1c1cd":"markdown","6a451aec":"markdown","022bd422":"markdown","6112521c":"markdown","42e374b5":"markdown","968d9363":"markdown","6b5ad350":"markdown","4f832afb":"markdown","47ec815b":"markdown","a41fe2fa":"markdown"},"source":{"069c3c93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dbfdb2a3":"# import liberaries\nimport pandas as pd\nimport numpy as np  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots","81f6fb36":"df_heart = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","ea865612":"df_heart.head()","4f73be6d":"df_heart.info","ce9d0b24":"df_heart.describe()","1d89c830":"print(df_heart.columns.values)","af29a417":"sns.set()\ncols = ['age', 'anaemia' ,'creatinine_phosphokinase', 'diabetes', 'ejection_fraction',\n 'high_blood_pressure', 'platelets' ,'serum_creatinine' ,'serum_sodium' ,'sex',\n 'smoking', 'time', 'DEATH_EVENT']\nsns.pairplot(df_heart[cols], size = 4)\nplt.show();","7498709c":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df_heart['age'],\n    xbins=dict(\n        start=40,\n        end=95,\n        size=1\n    ),\n    marker_color='black',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='Age Distribution',\n    xaxis_title_text='Age',\n    yaxis_title_text='COUNT', \n    bargap=0.05,\n\n)\n\nfig.show()","afdaa5a8":"sns.FacetGrid(df_heart,hue='DEATH_EVENT',height=8).map(sns.distplot,'age').set_axis_labels('age',\n'DEATH_EVENT').add_legend()\nplt.show()","72bc62d4":"fig = px.box(\n    df_heart, \n    x=\"DEATH_EVENT\", \n    y=\"age\", \n    points='all',\n    title='Age & DEATH_EVENT box plot',\n       \n)\n\nfig.show()","b0bca877":"\nds = df_heart['anaemia'].value_counts().reset_index()\nds.columns = ['anaemia', 'count']\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"anaemia\", \n    title='Anaemia bar chart', \n)\n\nfig.show()","2682e175":"sns.FacetGrid(df_heart,hue='DEATH_EVENT',height=8).map(sns.distplot,'anaemia').set_axis_labels('anaemia',\n'DEATH_EVENT').add_legend()\nplt.show()","db9556c6":"\nd1 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"anaemia\"]==0)]\nd2 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"anaemia\"]==0)]\nd3 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"anaemia\"]==1)]\nd4 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"anaemia\"]==1)]\n\nlabel1 = [\"No Anaemia\",\"Anaemia\"]\nlabel2 = ['No Anaemia - Survived','No Anaemia - Died', \"Anaemia -  Survived\", \"Anaemia  - Died\"]\nvalues1 = [(len(d1)+len(d2)), (len(d3)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"ANAEMIA\"),1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"ANAEMIA VS DEATH_EVENT\"),1, 2)","071f4c13":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df_heart['creatinine_phosphokinase'],\n    xbins=dict(\n        start=23.000000\t,\n        end=7861.000000\t,\n        size=150\n    ),\n    marker_color='black',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='CPK Distribution',\n    xaxis_title_text='CPK',\n    yaxis_title_text='COUNT', \n    bargap=0.05,\n\n)\n\nfig.show()\n","223993f8":"sns.FacetGrid(df_heart,hue='DEATH_EVENT',height=8).map(sns.distplot,'creatinine_phosphokinase').set_axis_labels('creatinine_phosphokinase',\n'DEATH_EVENT').add_legend()\nplt.show()","6076e604":"\nds = df_heart['diabetes'].value_counts().reset_index()\nds.columns = ['diabetes', 'count']\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"diabetes\", \n    title='Diabetes bar chart', \n)\n\nfig.show()","21c19dcb":"\nd1 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"diabetes\"]==0)]\nd2 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"diabetes\"]==1)]\nd3 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"diabetes\"]==0)]\nd4 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"diabetes\"]==1)]\n\nlabel1 = [\"No Diabetes\",\"Diabetes\"]\nlabel2 = ['No Diabetes - Survived','Diabetes - Survived', \"No Diabetes -  Died\", \"Diabetes  - Died\"]\nvalues1 = [(len(d1)+len(d3)), (len(d2)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"DIABETES\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"DIABETES VS DEATH_EVENT\"),\n              1, 2)\n\nfig.show()","b4611201":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df_heart['ejection_fraction'],\n    xbins=dict(\n        start=14.000000\t,\n        end=80.000000\t,\n        size=5\n    ),\n    marker_color='Blue',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='ejection_fraction Distribution',\n    xaxis_title_text='ejection_fraction',\n    yaxis_title_text='COUNT', \n    bargap=.05,\n\n)\n\nfig.show()\n","7b28be46":"# Now lets categorize the above histogram by DEATH_EVENT\nfig = px.histogram(df_heart, x=\"ejection_fraction\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df_heart.columns,\n                   title =\"Distribution of EJECTION FRACTION Vs DEATH_EVENT\", \n                   labels={\"ejection_fraction\": \"EJECTION FRACTION\"},\n                   template=\"plotly_white\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","e9b9066a":"d1 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"high_blood_pressure\"]==0)]\nd2 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"high_blood_pressure\"]==1)]\nd3 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"high_blood_pressure\"]==0)]\nd4 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"high_blood_pressure\"]==1)]\n\nlabel1 = [\"No high_blood_pressure\",\"high_blood_pressure\"]\nlabel2 = ['No high_blood_pressure - Survived','high_blood_pressure - Survived', \"No high_blood_pressure -  Died\", \"high_blood_pressure  - Died\"]\nvalues1 = [(len(d1)+len(d3)), (len(d2)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"high_blood_pressure\"),1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"high_blood_pressure VS DEATH_EVENT\"),1, 2)\nfig.show()","fbc8ea0d":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df_heart['platelets'],\n    xbins=dict(\n        start=25100.000000\t,\n        end=850000.000000\t,\n        size=10000\n    ),\n    marker_color='black',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='platelets Distribution',\n    xaxis_title_text='platelets',\n    yaxis_title_text='COUNT', \n    bargap=0.5,\n\n)\n\nfig.show()","bb384dfb":"fig = px.histogram(df_heart, x=\"platelets\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df_heart.columns)\nfig.show()","e0db1a99":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df_heart['serum_creatinine'],\n    xbins=dict(\n        start=0.50000\t,\n        end=9.40000\t,\n        size=0.1\n    ),\n    marker_color='black',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='serum_creatinine Distribution',\n    xaxis_title_text='serum_creatinine',\n    yaxis_title_text='COUNT', \n    bargap=0.2,\n\n)\n\nfig.show()","62409cd1":"fig = px.histogram(df_heart, x=\"serum_creatinine\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df_heart.columns,\n                   title =\"Distribution of SERUM CREATININE by DEATH_EVENT\", \n                   labels={\"serum_creatinine\": \"SERUM CREATININE\"},\n                   template=\"plotly_white\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","f7b097e7":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df_heart['serum_sodium'],\n    xbins=dict(\n        start=113\t,\n        end=148\t,\n        size=1\n    ),\n    marker_color='black',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='serum_sodium Distribution',\n    xaxis_title_text='serum_sodium',\n    yaxis_title_text='COUNT', \n    bargap=0.01,\n\n)\n\nfig.show()","1272b977":"fig = px.histogram(df_heart, x=\"serum_sodium\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df_heart.columns)\nfig.show()","790f8069":"ds = df_heart['sex'].value_counts().reset_index()\nds.columns = ['sex', 'count']\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"sex\", \n    title='Diabetes bar chart', \n)\n\nfig.show()","31b87776":"\nd1 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"sex\"]==1)]\nd2 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"sex\"]==1)]\nd3 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"sex\"]==0)]\nd4 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"sex\"]==0)]\n\nlabel1 = [\"Male\",\"Female\"]\nlabel2 = ['Male&Survived','Male&Died', \"Female&Survived\", \"Female&Died\"]\nvalues1 = [(len(d1)+len(d2)), (len(d3)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"Sex\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"DEATH_EVENT By Sex\"),\n              1, 2)\n\nfig.show()","69accdbc":"fig = px.histogram(df_heart, x=\"time\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df_heart.columns)\nfig.show()","265c3b08":"d1 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"smoking\"]==0)]\nd2 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"smoking\"]==0)]\nd3 = df_heart[(df_heart[\"DEATH_EVENT\"]==0) & (df_heart[\"smoking\"]==1)]\nd4 = df_heart[(df_heart[\"DEATH_EVENT\"]==1) & (df_heart[\"smoking\"]==1)]\n\nlabel1 = [\"No Smoking\",\"Smoking\"]\nlabel2 = ['No Smoking-Survived','No Smoking-Died', \"Smoking-Survived\", \"Smoking-Died\"]\nvalues1 = [(len(d1)+len(d2)), (len(d3)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"SMOKING\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"SMOKING VS DEATH_EVENT\"),\n              1, 2)\n","a2a42fe1":"ds = df_heart['DEATH_EVENT'].value_counts().reset_index()\nds.columns = ['DEATH_EVENT', 'count']\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"DEATH_EVENT\", \n    title='DEATH_EVENT bar chart', \n)\n\nfig.show()","236abbeb":"df_heart.isnull().sum()","2330d345":"sns.boxplot(x = df_heart.age, color = 'black')\nplt.show()","aba34893":"sns.boxplot(x = df_heart.creatinine_phosphokinase, color = 'black')\nplt.show()","ad1091ed":"sns.boxplot(x = df_heart.ejection_fraction, color = 'black')\nplt.show()","c1bfac8e":"df_heart = df_heart[df_heart['ejection_fraction']<70]\n","9e95f00f":"sns.boxplot(x = df_heart.ejection_fraction, color = 'black')\nplt.show()","e540d5be":"#correlation matrix\ncorrmat = df_heart.corr()\nf, ax = plt.subplots(figsize=(20, 9))\nsns.heatmap(corrmat, vmax=.8, annot=True);","8d5932c3":"x = df_heart.iloc[:, [4,7,11]].values\ny = df_heart.iloc[:,-1].values","c5358cef":"# Splitting the dataset into training set and test set\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state =0)","59c0f462":"# Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","f45f27c4":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(x_train, y_train)\n# Predicting the test set\ny_pred = classifier.predict(x_test)","2f0f1a90":"# Making Confusion Matrix and calculating accuracy score\n\nmylist = []\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm1 = confusion_matrix(y_test, y_pred)\nac1 = accuracy_score(y_test, y_pred)\nmylist.append(ac1)\nprint(cm1)\nprint(ac1)","909967b2":"# Training the Support Vector Classifier on the Training set\n\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor c in [0.5,0.6,0.7,0.8,0.9,1.0]:\n    classifier = SVC(C = c, random_state=0, kernel = 'rbf')\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    list1.append(accuracy_score(y_test,y_pred))\nplt.plot([0.5,0.6,0.7,0.8,0.9,1.0], list1)\nplt.show()","3b4c74a2":"# Predicting the test set results\n\ny_pred = classifier.predict(x_test)\nprint(y_pred)","cb6c2eb5":"# Making the confusion matrix and calculating accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nac = accuracy_score(y_test, y_pred)\nprint(cm)\nprint(ac)\nmylist.append(ac)","7e572829":"# Finding the optimum number of max_leaf_nodes\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor leaves in range(2,10):\n    classifier = DecisionTreeClassifier(max_leaf_nodes = leaves, random_state=0, criterion='entropy')\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    list1.append(accuracy_score(y_test,y_pred))\n#print(mylist)\nplt.plot(list(range(2,10)), list1)\nplt.show()","d9c6dd13":"#Predicting the test set results\n\ny_pred = classifier.predict(x_test)\nprint(y_pred)\n","534a9a7a":"# Making the confusion matrix and calculating accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nac = accuracy_score(y_test, y_pred)\nprint(cm)\nprint(ac)\nmylist.append(ac)","5b90d2c1":"#Finding the optimum number of n_estimators\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor estimators in range(10,30):\n    classifier = RandomForestClassifier(n_estimators = estimators, random_state=0, criterion='entropy')\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    list1.append(accuracy_score(y_test,y_pred))\n#print(mylist)\nplt.plot(list(range(10,30)), list1)\nplt.show()\n","2e67bfa8":"# Training the RandomForest Classifier on the Training set\n\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 11, criterion='entropy', random_state=0)\nclassifier.fit(x_train,y_train)","2ff4f09c":"# Predicting the test set results\n\ny_pred = classifier.predict(x_test)\nprint(y_pred)","b2e401d4":"# Making the confusion matrix and calculating the accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nac = accuracy_score(y_test, y_pred)\nmylist.append(ac)\nprint(cm)\nprint(ac)","70b2e4a4":"# Finding the optimum number of neighbors \n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor neighbors in range(3,10):\n    classifier = KNeighborsClassifier(n_neighbors=neighbors, metric='minkowski')\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    list1.append(accuracy_score(y_test,y_pred))\nplt.plot(list(range(3,10)), list1)\nplt.show()","0c8f334a":"# Training the K Nearest Neighbor Classifier on the Training set\n\nclassifier = KNeighborsClassifier(n_neighbors=6)\nclassifier.fit(x_train, y_train)","a3aeeb06":"# Predicting the Test set results\n\ny_pred = classifier.predict(x_test)\nprint(y_pred)","1882d638":"# Making the confusion matrix and calculating accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nac = accuracy_score(y_test, y_pred)\nmylist.append(ac)\nprint(cm)\nprint(ac)","0a2ded99":"np.random.seed(0)\nimport tensorflow as tf\n\n# Initialising the ANN\n\nann = tf.keras.models.Sequential()\n# Adding the input layer and the first hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n# Adding the second hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n# Adding the third hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n# Adding the fourth hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n #Adding the output layer\n\nann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n# Compiling the ANN\n\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'] )\n# Training the ANN on the training set\n\nann.fit(x_train, y_train, batch_size = 32, epochs = 100)","0d37eb35":"# Predicting the test set results\n\ny_pred = ann.predict(x_test)\ny_pred = (y_pred > 0.5)\nnp.set_printoptions()","46717fe0":"# Making the confusion matrix, calculating accuracy_score \n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# confusion matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint()\n\n# accuracy\nac = accuracy_score(y_test,y_pred)\nprint(\"Accuracy\")\nprint(ac)\nmylist.append(ac)","81325955":"from xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor estimators in range(10,30,1):\n    classifier = XGBClassifier(n_estimators = estimators, max_depth=12, subsample=0.7)\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    list1.append(accuracy_score(y_test,y_pred))\n#print(mylist)\nplt.plot(list(range(10,30,1)), list1)\nplt.show()","0cd4e400":"from xgboost import XGBClassifier\nclassifier = XGBClassifier(n_estimators = 10, max_depth=12, subsample=0.7)\nclassifier.fit(x_train,y_train)","7c274ed2":"y_pred = classifier.predict(x_test)\n","d6fb018f":"# Making the confusion matrix and calculating the accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nac = accuracy_score(y_test, y_pred)\nmylist.append(ac)\nprint(cm)\nprint(ac)","63782dfd":"# Plotting accuracy score of different models\nmylist","00cd4d7c":"mylist2 = [\"Logistic Regression\", \"KNearestNeighbours\",\"SupportVector\",\"DecisionTree\",\"RandomForest\",\"ANN\", \"XGBOOST\"]","3a6b2ad0":"### ANN","ccaa8c35":"## Platelets Distribution","e38e9e8a":"## Data Analysis","9d86c087":"### Knowing who died Considering the diadetes ","e99fe041":"## XGBoost","277ccf56":"## Knowing who died Considering the platelets\n\n","b46e63cc":"## High Blood Pressure Distribution","eaed8008":"### Please upvote for my kernel if you like this","41892b1f":"## Time Distribution","dc256121":"## Missing Values","e74151e8":"## Diabetes Distribution\n","03206878":"### SVC","2229d3af":"## Ejection Fraction Distribution (EF)","4505ccf8":"### Splitting Data","2d678b3d":"# Data Preprocessing","c851273a":"### Knowing who died Considering the Ejection Fraction","1e3ad9cf":"### Random forest\n","7e2d0ac6":"### Knowing who died Considering the age feature ","a125e562":"#### Before starting this work, it is a good idea to explain this data\nThis disease is a serious threat to health at any time without prior warning. Therefore, I advise you not to be exposed to these causes that lead to it, including smoking, eating sweets a lot, and other things that are advised by doctors","a55c5dc4":"### Knowing who died Considering the Serum sodium","07d13726":"## Data Visualization","53212c08":"#### I tried my best to do a comprehensive analysis of this data, but it is not as comprehensive as some expect, but I tried my best, so I want your comment on this work, whether positive or negative\n#### Let's start by making a road map in order to quickly reach the end with the least damage:\n#### first... Understand the problem: We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n#### second...Univariable study. We'll  focus on the dependent variable ('DEATH_EVENT') and try to know a little bit more about it.\n#### Third... multivariate study. We will try to understand the dependent features and do a full feature analysis\n#### Forth...data cleaning. We'll clean the dataset and handle the missing data, outliers and categorical variables.\n#### In the end, we will build a model for this fun work\n","a6e37154":"#### Visualize Outliers For CPK","98dcbe7d":"###### Here we found it detected outliers, so we had to delete them in order not to scatter the data\n","0ec4ba33":"# About Data ","27c20773":"### KNN","a1e56f11":"## Please upvote for my kernel if you like this","47511d53":"## Serum Sodium Distribution","25f832b8":"## Build Model","c74cac79":"## Serum Creatinine Distribution","6aa2397e":"## creatinine_phosphokinase Distribution (CPK)","33206c08":"### Decision Tree\n","459bd108":"### Age Distribution","d9516480":"### If there are any comments on what you have provided then I hope that you will advise me","63afe819":"### Knowing who died Considering the CPK","0975c69e":"## Knowing who died Considering Sex","82588d80":"## Explore outliers","db3f09ac":"Now, it's time to have fun!\nLet's get the party started\n* Let's go","581c0e45":"## Death Event Distrinbtion","03fe2935":"#### Visualize Outliers for age","52e683a3":"###### Get ready for what you're about to see. I must confess that the first time I saw these scatter plots I was totally blown away! So much information in so short space... It's just amazing.","536e0a93":"## Heat Map Correlation","f1c83e6a":"## In the end, I hope you like this humble work, and I wish you all the best in your life.","ddf37b39":"###### When doing a data check, we found that there are no missing values \u200b\u200band therefore we do not need to do a processing for the missing values.","dde1c1cd":"#### Visualize Outliers For Ejection Fraction","6a451aec":"### Feature Scaling","022bd422":"## Smoking Distribution","6112521c":"#### Let's start by analyzing each feature separately","42e374b5":"## Knowing who died Considering the Anaemia","968d9363":"## Sex Distribution\n","6b5ad350":"## Knowing who died Considering the Serum Creatinine","4f832afb":"# Data Modeling","47ec815b":"### Logistic Regression","a41fe2fa":"## Anaemia Distribution"}}