{"cell_type":{"4aa373fa":"code","4af9fa8a":"code","ff5c1e8e":"code","3e3e58e4":"code","4b2c9ba7":"code","79cc3eca":"code","a9d47114":"code","3f6c7f6f":"code","32e4eb94":"code","f18cdf3c":"code","50873ca0":"code","85c220a6":"code","a32fb85d":"code","0509c18c":"code","9f378a86":"code","353eada2":"code","705da52f":"code","1b2afdef":"code","6bfaf16a":"code","1ce40700":"code","bb4ac0f1":"code","8f22d474":"code","3f5ca94e":"code","ba6b067c":"code","28c9d276":"code","e519ff96":"code","bdfe2876":"code","f3c2be76":"code","6c58053b":"code","f6586bb2":"code","9c96463b":"code","973386fe":"code","77307806":"code","35881014":"code","326368d0":"code","b433588a":"code","9000e7cb":"code","caa457f8":"code","c5f81e0b":"code","b23cc922":"code","7366f817":"code","a5de353b":"code","dd79a0f7":"code","10fe948d":"code","880c6333":"code","c145de0a":"code","32b7d68f":"code","eeba7a89":"code","da79c7e0":"code","fd5b2400":"code","e1f71b36":"code","8af3adad":"code","83f9380d":"code","cd7c7ce3":"code","e620cd4a":"code","a4b4895b":"code","c8f4694b":"code","c6bc9df7":"code","ca5e0880":"code","2ad88521":"code","6b516e06":"code","3a23be5a":"code","3cc8c097":"code","e7b788d5":"code","deba553b":"code","156adead":"code","8767a793":"markdown","8f40f979":"markdown","26a138d6":"markdown","3668ca1d":"markdown","47e68c43":"markdown","9addb256":"markdown","bd99d084":"markdown","b50603fc":"markdown","3787ebae":"markdown","d6d44222":"markdown","46df2314":"markdown","ba542d31":"markdown"},"source":{"4aa373fa":"import numpy as np\nimport pandas as pd\nnp.set_printoptions(precision=4)","4af9fa8a":"Data = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex1.csv')    \nprint(type(Data))             \nData.head(4)","ff5c1e8e":"Data_tsv = pd.read_table('..\/input\/pandas-practice-files\/Required files\/test.tsv') \nData_tsv.head()  ","3e3e58e4":"# Reading tsv using read_csv\npd.read_table('..\/input\/pandas-practice-files\/Required files\/ex1.csv', sep=',')\n# If We will not use sep=',' parameter it will read all the data into one column","4b2c9ba7":"pd.read_table('..\/input\/pandas-practice-files\/Required files\/ex1.csv', sep=',',header=None)","79cc3eca":"# If we want our complete data, dont want to include it in header\npd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex2.csv', header=None)","a9d47114":"# If we want to new columns explicitly\ndf =pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex2.csv', names=['asdfdsfs','fsdf', 'b', 'c', 'sudh', 'message'])\n# for those columns which are not present in dataframe it will put Nan values\ndf","3f6c7f6f":"# We can set index by passing column names, Which can be used for multi-level indexing also\nparsed = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/csv_mindex.csv',index_col=['key1', 'key2'])\nparsed","32e4eb94":"# We can Skip the uncessary data to be loaded into our DataFrame by passing the index of rows we want to skip.\n# !cat ex4.csv\npd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex4.csv', skiprows=[0, 2, 3])","f18cdf3c":"result = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex5.csv')\nresult\n# To check is there any NaN Value in our DataFrame\npd.isnull(result)\n# It will Return a DataFrame of True where there is NaN value and False Where there is not a Nan Value.","50873ca0":"# We can Set what Value to be filled in Nan Values\nresult = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex5.csv',na_values='world')\nresult","85c220a6":"# We can read data from Diffrent Sheets within a Single file also.\ndraft3 = pd.read_excel('..\/input\/pandas-practice-files\/Required files\/ex1.xlsx',sheet_name = 0) # Name of sheet to read from\ndraft3.head(6)","a32fb85d":"!pip3 install lxml","0509c18c":"url = \"http:\/\/www.basketball-reference.com\/leagues\/NBA_2015_totals.html\"\nBB_data = pd.read_html(url)         # Read data from the specified url\nBB_data[0].iloc[:, 0:20].head(5)      # Check 5 rows (10 columns only)","9f378a86":"titanic_train = pd.read_csv(\"https:\/\/gist.githubusercontent.com\/michhar\/2dfd2de0d4f8727f873422c5d959fff5\/raw\/ff414a1bcfcba32481e4d4e8db578e55872a2ca1\/titanic.csv\",\n                           sep='\\t')","353eada2":"titanic_train.head(10) # checking 10 rows","705da52f":"titanic_train.columns","1b2afdef":"# we set others string or charater to be treated as Nan values\nresult = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex5.csv',na_values='world')\nresult","6bfaf16a":"# Selecting Column with index ('Name','Pclass')\ntitanic_train[[\"Name\",\"Pclass\"]].head() # by default head read first 5 rows","1ce40700":"# Checking Data type of each column\ntitanic_train.dtypes","bb4ac0f1":"# Python allows us to customise some Settings\npd.options.display.max_rows = 10","8f22d474":"result = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex6.csv')\nresult","3f5ca94e":"# It will only read 5 rows to our dataSet, We can save our resources in this way\npd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex6.csv', nrows=5)","ba6b067c":"chunk = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex6.csv', chunksize=100)\nfor i in chunk:\n    print(i)","28c9d276":"data = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex5.csv')\ndata","e519ff96":"# Saving our DataFrame to file csv\ndata.to_csv('Processed_DataFrame.csv')","bdfe2876":"import sys\ndata.to_csv('out1.csv', sep='@')","f3c2be76":"data.to_csv(sys.stdout, na_rep='Purvansh')","6c58053b":"data.to_csv('out2.csv', index=False, header=False,sep=',')","f6586bb2":"data.to_csv('out3.csv', index=False, columns=['a', 'b', 'c'])","9c96463b":"dates = pd.date_range('1\/1\/2000', periods=7)\nts = pd.Series(np.arange(7), index=dates)\nts.to_csv('tseries.csv')\ndates =pd.DataFrame(dates)\ndates.to_csv('Dates.csv')\n#! tseries.csv","973386fe":"import csv\nf = open('..\/input\/pandas-practice-files\/Required files\/ex7.csv')\nreader = csv.reader(f)\nfor text in reader:\n    print(text)\nreader","77307806":"with open('..\/input\/pandas-practice-files\/Required files\/ex7.csv') as f:\n    lines = list(csv.reader(f))\nprint(lines)","35881014":"header, values = lines[0], lines[1:]","326368d0":"data_dict = {h: v for h, v in zip(header, zip(*values))}\ndata_dict","b433588a":"pd.DataFrame(data_dict,index=['one','two'])","9000e7cb":"obj = \"\"\"\n{\"name\": \"Wes\",\n \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n \"pet\": null,\n \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n              {\"name\": \"Katie\", \"age\": 38,\n               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n}\n\"\"\"","caa457f8":"import json\nresult = json.loads(obj)\nprint(type(result))\nresult","c5f81e0b":"asjson = json.dumps(result)\nprint(type(asjson))\nasjson","b23cc922":"siblings = pd.DataFrame(result['siblings'], columns=['name', 'age','pets'])\nsiblings","7366f817":"data = pd.read_json('..\/input\/pandas-practice-files\/Required files\/example.json')\ndata","a5de353b":"print(data.to_json())\nprint(data.to_json(orient='records'))","dd79a0f7":"tables = pd.read_html('fdic_failed_bank_list.html')\nlen(tables)\nfailures = tables[0]\nfailures.head()","10fe948d":"close_timestamps = pd.to_datetime(failures['Closing Date'])\nclose_timestamps.dt.year.value_counts()\n#close_timestamps","880c6333":"frame = pd.read_csv('..\/input\/pandas-practice-files\/Required files\/ex1.csv')\nframe\nframe.to_pickle('frame_pickle')","c145de0a":"pd.read_pickle('frame_pickle')","32b7d68f":"!pip install tables","eeba7a89":"# HDF5 Hierarchical Data Format (HDF) is an open source file format for storing huge amounts of numerical data.\nframe = pd.DataFrame({'a': np.random.randn(100)})\nstore = pd.HDFStore('mydata.h5')\nstore['obj1'] = frame\nstore['obj1_col'] = frame['a']\nstore","da79c7e0":"store['obj1'].head()","fd5b2400":"store.put('obj2', frame, format='table')\nstore.select('obj2', where=['index >= 10 and index <= 15'])\nstore.close()","e1f71b36":"frame.to_hdf('mydata.h5', 'obj3', format='table')\npd.read_hdf('mydata.h5', 'obj3', where=['index < 5'])","8af3adad":"import requests\nurl = 'https:\/\/api.github.com\/repos\/pandas-dev\/pandas\/issues'\nresp = requests.get(url)\ntype(resp)\nprint(resp)","83f9380d":"data = resp.json()\ndata[2]['user']","cd7c7ce3":"issues = pd.DataFrame(data, columns=['number', 'title',\n                                     'labels', 'state'])\nissues","e620cd4a":"import sqlite3\n#connecting with the database.\ndb = sqlite3.connect(\"my_database4.db\")\n# Drop table if it already exist using execute() method.\ndb.execute(\"drop table if exists test\")\nquery = \"\"\"\nCREATE TABLE test\n(a VARCHAR(20), b VARCHAR(20),\n c REAL,        d INTEGER\n);\"\"\"\ncon = sqlite3.connect('mydata2.sqlite')\ncon.execute(query)\ncon.commit()","a4b4895b":"data = [('Atlanta', 'Georgia', 1.25, 6),\n        ('Tallahassee', 'Florida', 2.6, 3),\n        ('Sacramento', 'California', 1.7, 5)]\nstmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\ncon.executemany(stmt, data)\ncon.commit()","c8f4694b":"cursor = con.execute('select * from test')\nrows = cursor.fetchall()\nrows","c6bc9df7":"print(cursor.description)\npd.DataFrame(rows, columns=[x[0] for x in cursor.description])","ca5e0880":"import sqlite3\n#connecting with the database.\ndb = sqlite3.connect(\"my_database5.db\")\n# Drop table if it already exist using execute() method.\ndb.execute(\"drop table if exists grades1\")\n# Create table as per requirement\ndb.execute(\"create table grades1(id int, name text, score int)\")\n#inserting values inside the created table\ndb.execute(\"insert into grades1(id, name, score) values(101, 'John',99 )\")\ndb.execute(\"insert into grades1(id, name, score) values(102, 'Gary',90 )\")\ndb.execute(\"insert into grades1(id, name, score) values(103, 'James', 80 )\")\ndb.execute(\"insert into grades1(id, name, score) values(104, 'Cathy', 85 )\")\ndb.execute(\"insert into grades1(id, name, score) values(105, 'Kris',95 )\")","2ad88521":"db.commit()","6b516e06":"results = db.execute(\"select * from grades1 order by id\")\nfor row in results:\n    print((row))\nprint(\"-\" * 60 )","3a23be5a":"results = db.execute(\"select * from grades1 where name = 'Gary' \")\nfor row in results: print(row)\nprint(\"-\"* 60 )","3cc8c097":"results = db.execute(\"select * from grades1 where score >= 90 \")\nfor row in results:\n    print(row)\nprint(\"-\" * 60 )","e7b788d5":"results = db.execute(\"select name, score from grades1 order by score desc \")\nfor row in results:\n    print(row)\nprint(\"-\" * 60 )","deba553b":"results = db.execute(\"select name, score from grades1 order by score\")\nfor row in results:\n    print(row)\nprint(\"-\" * 60 )","156adead":"results = db.execute(\"select name, score from grades1 order by score\")\nfor row in results:\n    print(row)","8767a793":"XML and HTML: Web Scraping","8f40f979":"### Writing Data to Text Format","26a138d6":"# Pandas","3668ca1d":"### Reading HTML tables\n#### Note: It will the only data which is present in tabular form on website.","47e68c43":"# Web APIs","9addb256":"## Working With JSON Data","bd99d084":"# Interacting with Databases","b50603fc":"# Binary Data Formats","3787ebae":"Working with Delimited Formats","d6d44222":"### Working with TSV file (Tab Seprated Values)","46df2314":"Using HDF5 Format","ba542d31":"### Working With CSV files"}}