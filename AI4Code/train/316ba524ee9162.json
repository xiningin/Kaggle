{"cell_type":{"5447596d":"code","40b6396f":"code","9caf3e26":"code","0c658920":"code","e935f4eb":"code","6a52aef7":"code","bc64be55":"code","8461c6fa":"code","38582620":"code","5cfa9ccb":"code","a91c5087":"code","67fb827d":"code","e73b7fa6":"code","a33700b5":"code","863049c4":"code","a67da562":"code","396618e5":"code","d1c6ee4b":"code","c9f3c498":"code","a1083895":"code","3fda6d10":"code","58f6b959":"code","7e3b51bf":"code","a53deeaa":"code","ff29bd40":"code","777a393b":"code","6cf4d9fd":"code","341191ad":"code","057aafce":"code","e4c35b96":"code","ae0652bc":"code","5aeff1bd":"code","196763bf":"code","237b9436":"code","ffdc9082":"code","6667e5bf":"code","7639bf99":"code","37c104fb":"code","5d81ae50":"markdown","2356afd4":"markdown","fc468542":"markdown","d57bfadc":"markdown","dd4671f7":"markdown","71025644":"markdown","c61839ea":"markdown","85e14fa1":"markdown","90b569d5":"markdown","f54102ea":"markdown","a0bbd90c":"markdown","ee06f0a2":"markdown","6197d1c8":"markdown","ae6905ae":"markdown","db19ae56":"markdown","23f2b76b":"markdown","b25bff55":"markdown","2893d890":"markdown","227e6bc8":"markdown","bb0fc3e3":"markdown"},"source":{"5447596d":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\nimport folium \nfrom folium import plugins\nfrom tqdm.notebook import tqdm as tqdm\n\n\nfrom pathlib import Path\ndata_dir = Path('..\/input\/pima-indians-diabetes-database')\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.stats import skew   \nimport pylab as p  \n  \nfrom pandas.plotting import scatter_matrix\n\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\n\n\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn import metrics\n","40b6396f":"data = pd.read_csv(data_dir\/'diabetes.csv')\ndata.head()","9caf3e26":"data.info()","0c658920":"data.describe()","e935f4eb":"data1=data.copy(deep=True)\ndata1[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = data1[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\nprint(data1.isnull().sum())","6a52aef7":"fig = make_subplots(rows=3, cols=3, subplot_titles=('Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'))\n\ntrace0= go.Histogram(\n    \n    x=data['Pregnancies'],\n    name=\"Pregnancies\",\n    opacity=0.75\n)\n\ntrace1= go.Histogram(\n    \n    x=data['Glucose'],\n    name=\"Glucose\",\n    opacity=0.75\n)\n\ntrace2= go.Histogram(\n    \n    x=data['BloodPressure'],\n    name=\"BloodPressure\",\n    opacity=0.75\n)\n\ntrace3= go.Histogram(\n    \n    x=data['SkinThickness'],\n    name=\"SkinThickness\",\n    opacity=0.75\n)\n\ntrace4= go.Histogram(\n    \n    x=data['Insulin'],\n    name=\"Insulin\",\n    opacity=0.75\n)\n\ntrace5= go.Histogram(\n    \n    x=data['BMI'],\n    name=\"BMI\",\n    opacity=0.75\n)\n\ntrace6= go.Histogram(\n    \n    x=data['DiabetesPedigreeFunction'],\n    name=\"DiabetesPedigreeFunction\",\n    opacity=0.75\n)\n\ntrace7= go.Histogram(\n    \n    x=data['Age'],\n    name=\"Age\",\n    opacity=0.75\n)\n\ntrace8= go.Histogram(\n    \n    x=data['Outcome'],\n    name=\"Outcome\",\n    opacity=0.75\n)\n\nfig.append_trace(trace0,1,1)\nfig.append_trace(trace1,1,2)\nfig.append_trace(trace2,1,3)\nfig.append_trace(trace3,2,1)\nfig.append_trace(trace4,2,2)\nfig.append_trace(trace5,2,3)\nfig.append_trace(trace6,3,1)\nfig.append_trace(trace7,3,2)\nfig.append_trace(trace8,3,3)\n\nfig.update_layout(template=\"plotly_dark\",title_text='<b>Visualization before dealing Nan values<\/b>',font=dict(family=\"Arial,Balto,Courier new,Droid sans\",color='white'))\nfig.show()","bc64be55":"data1['Glucose'].fillna(data1['Glucose'].mean(), inplace = True)\ndata1['BloodPressure'].fillna(data1['BloodPressure'].mean(), inplace = True)\ndata1['SkinThickness'].fillna(data1['SkinThickness'].median(), inplace = True)\ndata1['Insulin'].fillna(data1['Insulin'].median(), inplace = True)\ndata1['BMI'].fillna(data1['BMI'].median(), inplace = True)","8461c6fa":"fig = make_subplots(rows=3, cols=3, subplot_titles=('Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'))\n\ntrace0= go.Histogram(\n    \n    x=data1['Pregnancies'],\n    name=\"Pregnancies\",\n    opacity=0.75\n)\n\ntrace1= go.Histogram(\n    \n    x=data1['Glucose'],\n    name=\"Glucose\",\n    opacity=0.75\n)\n\ntrace2= go.Histogram(\n    \n    x=data1['BloodPressure'],\n    name=\"BloodPressure\",\n    opacity=0.75\n)\n\ntrace3= go.Histogram(\n    \n    x=data1['SkinThickness'],\n    name=\"SkinThickness\",\n    opacity=0.75\n)\n\ntrace4= go.Histogram(\n    \n    x=data1['Insulin'],\n    name=\"Insulin\",\n    opacity=0.75\n)\n\ntrace5= go.Histogram(\n    \n    x=data1['BMI'],\n    name=\"BMI\",\n    opacity=0.75\n)\n\ntrace6= go.Histogram(\n    \n    x=data1['DiabetesPedigreeFunction'],\n    name=\"DiabetesPedigreeFunction\",\n    opacity=0.75\n)\n\ntrace7= go.Histogram(\n    \n    x=data1['Age'],\n    name=\"Age\",\n    opacity=0.75\n)\n\ntrace8= go.Histogram(\n    \n    x=data1['Outcome'],\n    name=\"Outcome\",\n    opacity=0.75\n)\n\nfig.append_trace(trace0,1,1)\nfig.append_trace(trace1,1,2)\nfig.append_trace(trace2,1,3)\nfig.append_trace(trace3,2,1)\nfig.append_trace(trace4,2,2)\nfig.append_trace(trace5,2,3)\nfig.append_trace(trace6,3,1)\nfig.append_trace(trace7,3,2)\nfig.append_trace(trace8,3,3)\n\nfig.update_layout(template=\"plotly_dark\",title_text='<b>Visualization After NaN removal<\/b>',font=dict(family=\"Arial,Balto,Courier new,Droid sans\",color='white'))\nfig.show()","38582620":"data1.skew(axis=0)","5cfa9ccb":"plot=scatter_matrix(data,figsize=(20, 20))","a91c5087":"plot=sns.pairplot(data, hue = 'Outcome')","67fb827d":"plt.figure(figsize=(10,8))  \nheatmap=sns.heatmap(data.corr(), annot=True,cmap ='RdYlGn') \nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","e73b7fa6":"plt.figure(figsize=(10,8))  \nheatmap=sns.heatmap(data1.corr(), annot=True,cmap ='RdYlGn') \nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","a33700b5":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(data1.drop([\"Outcome\"],axis = 1),),\ncolumns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age'])","863049c4":"X.head()","a67da562":"y = data1.Outcome","396618e5":"data_dmatrix = xgb.DMatrix(data=X,label=y)","d1c6ee4b":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)","c9f3c498":"xg_reg = xgb.XGBRegressor(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)","a1083895":"xg_reg.fit(X_train,y_train)","3fda6d10":"preds = xg_reg.predict(X_test)","58f6b959":"preds","7e3b51bf":"preds1=[]\nn= len(preds)\nfor i in range(n):\n    if(preds[i]>=0.5):\n        preds1.append(1)\n    else:\n        preds1.append(0)","a53deeaa":"preds1","ff29bd40":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, preds1)","777a393b":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,15):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","6cf4d9fd":"max_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))","341191ad":"max_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","057aafce":"plt.figure(figsize=(12,5))\np = sns.lineplot(range(1,15),train_scores,marker='*',label='Train Score')\np = sns.lineplot(range(1,15),test_scores,marker='o',label='Test Score')","e4c35b96":"knn = KNeighborsClassifier(11)\n\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)","ae0652bc":"value = 20000\nwidth = 20000\nplot_decision_regions(X.values, y.values, clf=knn, legend=2, \n                      filler_feature_values={2: value, 3: value, 4: value, 5: value, 6: value, 7: value},\n                      filler_feature_ranges={2: width, 3: width, 4: width, 5: width, 6: width, 7: width},\n                      X_highlight=X_test.values)\n\n\nplt.title('KNN with Diabetes Data')\nplt.show()","5aeff1bd":"y_pred = knn.predict(X_test)\nconfusion_matrix(y_test,y_pred)\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","196763bf":"cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","237b9436":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","ffdc9082":"from sklearn.metrics import roc_curve\ny_pred_proba = knn.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)","6667e5bf":"\n\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=11) ROC curve')\nplt.show()\n\n","7639bf99":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_proba)","37c104fb":"from sklearn.model_selection import GridSearchCV\n#In case of classifier like knn the parameter to be tuned is n_neighbors\nparam_grid = {'n_neighbors':np.arange(1,50)}\nknn = KNeighborsClassifier()\nknn_cv= GridSearchCV(knn,param_grid,cv=5)\nknn_cv.fit(X,y)\n\nprint(\"Best Score:\" + str(knn_cv.best_score_))\nprint(\"Best Parameters: \" + str(knn_cv.best_params_))","5d81ae50":"### Plotting after NaN removal","2356afd4":"The plot between same variables give histogram and beetween two different variables rises scatter plot","fc468542":"\n\nPearson's Correlation Coefficient: helps you find out the relationship between two quantities. It gives you the measure of the strength of association between two variables. The value of Pearson's Correlation Coefficient can be between -1 to +1. 1 means that they are highly correlated and 0 means no correlation.","d57bfadc":"### Filling NaN values in data","dd4671f7":"### Scaling the data\n\ndata Z is rescaled such that \u03bc = 0 and \ud835\uded4 = 1, and is done through this formula: \n\n![image.png](attachment:image.png)\n","71025644":"### Scatter matrix of uncleaned data","c61839ea":"### KNN","85e14fa1":"## Model performance analysis","90b569d5":"### Train , Test data Split","f54102ea":"### XGBOOST","a0bbd90c":"### Pair plot for cleaned data","ee06f0a2":"### Heat Map\nA heat map is a two-dimensional representation of information with the help of colors. Heat maps can help the user visualize simple or complex information.","6197d1c8":"#### Cleaned data","ae6905ae":"Skewness can be shown with a list of numbers as well as on a graph. For example, take the numbers 1,2, and 3. They are evenly spaced, with 2 as the mean (1 + 2 + 3 \/ 3 = 6 \/ 3 = 2). If you add a number to the far left (think in terms of adding a value to the number line), the distribution becomes left skewed:\n-10, 1, 2, 3.\nSimilarly, if you add a value to the far right, the set of numbers becomes right skewed:\n1, 2, 3, 10.","db19ae56":"### Visualization of distribution","23f2b76b":"### Observation from above analysis\n* The columnss  ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']  have their minimum value as Zero. These columns cannot have minimum value as zero.\n* It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values","b25bff55":"## Skewness\n\nA left-skewed distribution has a long left tail. Left-skewed distributions are also called negatively-skewed distributions. That\u2019s because there is a long tail in the negative direction on the number line. The mean is also to the left of the peak.\n\nA right-skewed distribution has a long right tail. Right-skewed distributions are also called positive-skew distributions. That\u2019s because there is a long tail in the positive direction on the number line. The mean is also to the right of the peak.\n\nA perfectly balanced  distribution has equal tails on both sides and skewness value is close to zero.\n\n![Skewness](https:\/\/www.statisticshowto.com\/wp-content\/uploads\/2014\/02\/pearson-mode-skewness.jpg)\n\n![Balances Distribution](https:\/\/www.statisticshowto.com\/wp-content\/uploads\/2013\/09\/normal-distribution-probability.jpg)","2893d890":"#### Uncleaned Data","227e6bc8":"## EDA","bb0fc3e3":"# Modelling using xgboost"}}