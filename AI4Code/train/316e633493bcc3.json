{"cell_type":{"4ec207a0":"code","f47b0b63":"code","d09ebbd0":"code","0372b9cb":"code","e0e759e2":"code","511d3d2e":"code","de054282":"code","e489a80f":"code","8594bdfb":"code","46bf6ef6":"code","9915f67d":"code","dcce6105":"code","aa578cf5":"code","9a529243":"code","70224421":"code","cc2eb1f7":"code","783a542c":"code","f60170b3":"code","6be42598":"code","64d00aee":"code","671b5ca0":"code","14a0e3a7":"code","ef417c0a":"code","530cd4c4":"code","07cc1d36":"markdown","0ac953b6":"markdown","61203724":"markdown","eb069825":"markdown","98f57dea":"markdown","af5aa134":"markdown","21c21e95":"markdown","5ecb0770":"markdown","42b27cce":"markdown","a73cd1d5":"markdown"},"source":{"4ec207a0":"ENV_PRE_MODEL='..\/input\/sartorius-detectors-20211211-1600\/detectors_htc_r50_1x_coco-329b1453.pth'\nENV_PRE_MODEL_PY='\/kaggle\/working\/mmdetection\/configs\/detectors\/detectors_htc_r50_1x_coco.py'\n# ----------------------------------- #\nENV_MY_MODEL='..\/input\/sartorius-801-20211223133157\/801-pseudocheckpointval256-detectors_detectors_htc_r50_1x_coco-\/epoch_5.pth'\n# ENV_IMG_SCALE=[(1333, 800), (1690, 960), (1870, 1120), (2133, 1280), (2399, 1440)]\nENV_IMG_SCALE=[(2133, 1280), (2399, 1440)]\n","f47b0b63":"!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","d09ebbd0":"!pip install '\/kaggle\/input\/mmdetectionv2140\/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmcv_full-1_3_8-cu110-torch1_7_0\/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/pycocotools-2.0.2\/pycocotools-2.0.2' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmpycocotools-12.0.3\/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r ..\/input\/edited-mmdetection \/kaggle\/working\/\n!mv \/kaggle\/working\/edited-mmdetection \/kaggle\/working\/mmdetection\n%cd \/kaggle\/working\/mmdetection\n!pip install -e .","0372b9cb":"!pip install ..\/..\/input\/ensemble-boxes-104\/ensemble_boxes-1.0.4\/ -f .\/ --no-index\n","e0e759e2":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport cupy as cp\nimport gc\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask as maskutils\nimport numpy.random\nimport random\nimport cv2\nimport re\nimport shutil\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed\nfrom ensemble_boxes import *\nfrom tqdm import tqdm","511d3d2e":"%cd ..","de054282":"IMG_WIDTH = 704\nIMG_HEIGHT = 520\nSUBM_PATH='..\/input\/sartorius-cell-instance-segmentation\/test'","e489a80f":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","8594bdfb":"from mmcv import Config\ncfg = Config.fromfile(ENV_PRE_MODEL_PY)","46bf6ef6":"cfg.model.roi_head.pop('semantic_roi_extractor')\ncfg.model.roi_head.pop('semantic_head')\n\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 3\n\nfor head in cfg.model.roi_head.mask_head:\n    head.num_classes=3","9915f67d":"cfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=ENV_IMG_SCALE,\n        flip=True,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip',\n                 flip_ratio=[0.4,0.3,0.3],\n                 #flip_ratio=0.5,\n                 direction= ['horizontal', 'vertical','diagonal' ]),\n                 #direction= 'horizontal' ),\n            dict(\n                type='Normalize',\n#                 mean=[127.96497969, 127.96497969, 127.96497969],\n#                 std=[13.68662336, 13.68662336, 13.68662336],\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n \ncfg.anchor_generator=dict( \n            type='AnchorGenerator',\n            scales=[8], \n            ratios=[0.3, 0.5, 0.65,1,1.25 ,1.3],  # The ratio between height and width.\n            strides=[4, 8, 16, 32, 64])\n \ncfg.data.test.pipeline = cfg.test_pipeline\ncfg.model.test_cfg.rcnn.max_per_img = 1000\ncfg.model.test_cfg.rpn.min_bbox_size=10\ncfg.load_from = ENV_PRE_MODEL\ncfg.work_dir = '\/kaggle\/working\/model_output'\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.img_norm_cfg = dict(  \n#   mean=[127.96497969, 127.96497969, 127.96497969],\n#   std=[13.68662336, 13.68662336, 13.68662336],\n    mean=[128, 128, 128],  \n    std=[11.58, 11.58, 11.58],  \n    to_rgb=True)\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\n# print(f'Config:\\n{cfg.pretty_text}')","dcce6105":"print(f'Config:\\n{cfg.pretty_text}')","aa578cf5":"confidence_thresholds = {0: 0.25, 1: 0.55, 2: 0.35}\n# {0: 0.15, 1: 0.4, 2: 0.5} ## shs5ys astro cort\n# {0: 0.15, 1: 0.55, 2: 0.35} ## shs5ys astro cort\n# {0: 0.25, 1: 0.55, 2: 0.35} ## shs5ys astro cort","9a529243":"segms = []\nfiles = []","70224421":"MIN_PIXELS = [75, 150, 75]\nMODELS = []\n\nmodel = init_detector(cfg, ENV_MY_MODEL)\nMODELS.append(model)","cc2eb1f7":"from scipy.ndimage.morphology import binary_fill_holes\nfrom skimage.morphology import dilation, erosion\n\ndef  postprocess_masks(masks):\n    \n    for mm in range(masks.shape[-1]):\n        # Fill holes inside the mask\n        #mask = binary_fill_holes(masks[..., mm]).astype(np.uint8)\n        # Smoothen edges using dilation and erosion\n        mask = erosion(dilation(mask))\n        # Delete overlaps\n        overlap += mask\n        mask[overlap > 1] = 0\n        out_label = label(mask)\n        # Remove all the pieces if there are more than one pieces\n        if out_label.max() > 1:\n            mask[()] = 0\n\n        result['masks'][..., mm] = mask\n    \n    ","783a542c":"def nms_predictions(classes, scores, bboxes, masks, \n                    iou_th=.35, shape=(520, 704)):\n    he, wd = shape[0], shape[1]\n    boxes_list = [[x[0] \/ wd, x[1] \/ he, x[2] \/ wd, x[3] \/ he]\n                  for x in bboxes]\n    scores_list = [x for x in scores]\n    labels_list = [x for x in classes]\n    nms_bboxes, nms_scores, nms_classes = nms(\n        boxes=[boxes_list], \n        scores=[scores_list], \n        labels=[labels_list], \n        weights=None,\n        iou_thr=iou_th\n    )\n    nms_masks = []\n    for s in nms_scores:\n        nms_masks.append(masks[scores.index(s)])\n    nms_scores, nms_classes, nms_masks = zip(*sorted(zip(nms_scores, nms_classes, nms_masks), reverse=True))\n    return nms_classes, nms_scores, nms_masks\n\n\ndef ensemble_pred_masks(masks, classes, min_pixels=MIN_PIXELS, shape=(520, 704)):\n    result = []\n    pred_class = max(set(classes), key=classes.count)\n    used = np.zeros(shape, dtype=int) \n\n    prev_masks = []\n    for i, mask in enumerate(masks):\n        cont, hier = cv2.findContours(np.array(mask,dtype=np.uint8),cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        if len(cont)>0:\n            for cnt in cont:\n                convex_mask = cv2.fillConvexPoly(np.zeros_like(np.array(mask,dtype=np.uint8)),points=cnt, color=1)\n                fillornot = len(pd.Series((convex_mask==mask).flatten()).value_counts())\n                if fillornot>1: #fill\n                    mask = convex_mask\n                #before= mask.sum()\n                mask = erosion(dilation(mask))  #post processing \n                #if before!=mask.sum():\n                #    print('after',mask.sum(),'before',before)\n                mask = mask * (1-used)\n                if mask.sum() >= min_pixels[pred_class]: # skip predictions with small area\n                    used += mask \n                    result.append(rle_encode(mask))\n        \n    return result","f60170b3":"#np.argwhere(np.array(c)==np.max(c))[0][0]\n\n#classe.shape","6be42598":"subm_ids, subm_masks = [], []\ntest_names = os.listdir(SUBM_PATH)\n\nfor test_name in tqdm(test_names):\n    for i, model in enumerate(MODELS):\n        img = mmcv.imread('..\/input\/sartorius-cell-instance-segmentation\/test\/' + test_name) #file)\n        result = inference_detector(model, img)\n        \n        previous_masks = []\n        classes_nms = []\n        scores_nms = []\n        bboxes_nms = []\n        masks_nms = []\n        \n        #find the max class \n        c = []\n        for i, classe in enumerate(result[0]):\n            #print(classe.shape)\n            c.append(classe.shape[0])\n        \n        maxclass = np.argwhere(np.array(c)==np.max(c))[0][0]\n        #print(c,test_name,classe.shape[0],np.max(c))\n        for i, classe in enumerate(result[0]):\n            if i==maxclass: #classe.shape != (0, 5):\n                bbs = classe\n                sgs = result[1][i]\n\n                for bb, sg in zip(bbs,sgs):\n                    box = bb[:4]\n                    cnf = bb[4]\n\n                    if cnf >= confidence_thresholds[i]:\n                        mask = np.array(sg,dtype=np.uint8)  \n                        previous_masks.append(mask)\n                        scores_nms.extend([cnf])\n                        bboxes_nms.extend([box.tolist()])\n\n        masks_nms = previous_masks\n        classes_nms = [i] * len(previous_masks)\n        classes_nms, scores_nms, masks_nms = nms_predictions(classes_nms, scores_nms, bboxes_nms, masks_nms) \n        encoded_masks = ensemble_pred_masks(masks_nms, classes_nms) \n\n        for enc_mask in encoded_masks:\n            subm_ids.append(test_name[:test_name.find('.')])\n            subm_masks.append(enc_mask)\n","64d00aee":"pd.DataFrame({\n    'id': subm_ids, \n    'predicted': subm_masks\n}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","671b5ca0":"pd.read_csv('submission.csv')","14a0e3a7":"# def visualize_image(image_id,predrle): #,enc_targs, enc_preds,category, iou):\n\n#     image = cv2.imread(f'..\/input\/sartorius-cell-instance-segmentation\/test\/{image_id}.png')\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n#     print(f'{image_id}\\n{\"-\" * len(image_id)}')\n#     print(f'Image Mean: {np.mean(image):.4f}  -  Median: {np.median(image):.4f}  -  Std: {np.std(image):.4f} - Min: {np.min(image):.4f} -  Max: {np.max(image):.4f}')\n\n#     fig, axes = plt.subplots(figsize=(20, 20),ncols=2)\n#     fig.tight_layout(pad=5.0)\n    \n#     axes[0].imshow(image, cmap='gray')\n#     masks = []\n#     for mask in predrle:\n#         masks.append(rle_decode(mask, shape=(IMG_HEIGHT,IMG_WIDTH)))\n\n#     mask = np.stack(masks)\n#     mask = np.any(mask == 1, axis=0)\n#     axes[1].imshow(image, cmap='gray')\n#     axes[1].imshow(mask, alpha=0.4)\n    \n    \n#     plt.show()\n#     plt.close(fig)\n\n# tmp =pd.read_csv('submission.csv')\n# rles = tmp[tmp.id=='d48ec7815252']['predicted'].tolist()\n\n# visualize_image(image_id='d48ec7815252',predrle = rles)","ef417c0a":"# tmp1 =pd.read_csv('..\/input\/inf-mmdetection-detectors-303-v2-scale45\/submission.csv')\n# rles = tmp1[tmp1.id=='d48ec7815252']['predicted'].tolist()\n\n# visualize_image(image_id='d48ec7815252',predrle = rles)","530cd4c4":"shutil.rmtree('\/kaggle\/working\/mmdetection')","07cc1d36":"\n### 801-pseudocheckpointval256-detectors_detectors_htc_r50_1x_coco-\n\n\n\n* Stage2 log\n\n```\n2021-12-23 01:24:15,891 - mmdet - INFO - \nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\nAverage Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.668\nAverage Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.242\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.300\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.092\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.500\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.405\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.405\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.397\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.427\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.500\n\n2021-12-23 01:24:15,907 - mmdet - INFO - Epoch(val) [5][31]\tsegm_mAP: 0.2710, segm_mAP_50: 0.6680, segm_mAP_75: 0.2420, segm_mAP_s: 0.3000, segm_mAP_m: 0.0920, segm_mAP_l: 0.5000, segm_mAP_copypaste: 0.271 0.668 0.242 0.300 0.092 0.500\n```\n","0ac953b6":"<a id=#cbb><\/a>\n<h2 style=\"color: #6cb4e4; background: #dfefff;  box-shadow: 0px 0px 0px 5px #dfefff;  border: dashed 4px white;  padding: 0.2em 0.5em;\">\n<b>Import Libraries\n<\/b><\/h2> ","61203724":"<a id=#cbb><\/a>\n<h2 style=\"color: #6cb4e4; background: #dfefff;  box-shadow: 0px 0px 0px 5px #dfefff;  border: dashed 4px white;  padding: 0.2em 0.5em;\">\n<b>Model\n<\/b><\/h2> ","eb069825":"<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n<b>Info<\/b><\/h1> ","98f57dea":"<a id=#cbb><\/a>\n<h2 style=\"color: #6cb4e4; background: #dfefff;  box-shadow: 0px 0px 0px 5px #dfefff;  border: dashed 4px white;  padding: 0.2em 0.5em;\">\n<b>Helper Functions\n<\/b><\/h2> ","af5aa134":"<a id=#cbb><\/a>\n<h2 style=\"color: #6cb4e4; background: #dfefff;  box-shadow: 0px 0px 0px 5px #dfefff;  border: dashed 4px white;  padding: 0.2em 0.5em;\">\n<b>Inference\n<\/b><\/h2> ","21c21e95":"<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n<b>Main<\/b><\/h1> ","5ecb0770":"<a id=#cbb><\/a>\n<h2 style=\"color: #6cb4e4; background: #dfefff;  box-shadow: 0px 0px 0px 5px #dfefff;  border: dashed 4px white;  padding: 0.2em 0.5em;\">\n<b>Install MMDetection\n<\/b><\/h2> ","42b27cce":"<a id=#cbb><\/a>\n<h2 style=\"color: #6cb4e4; background: #dfefff;  box-shadow: 0px 0px 0px 5px #dfefff;  border: dashed 4px white;  padding: 0.2em 0.5em;\">\n<b>Env\n<\/b><\/h2> ","a73cd1d5":"https:\/\/www.kaggle.com\/hideyukizushi\/inf-mmdetection-detectors-303-v2-scale12345?scriptVersionId=82347401"}}