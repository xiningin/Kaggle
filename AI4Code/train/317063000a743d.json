{"cell_type":{"4fba27ec":"code","99029f80":"code","aa189bfe":"code","a4027387":"code","4c358d99":"code","24aa3626":"code","dc2fbb1d":"code","334fe4e1":"code","3501357f":"code","cce29099":"code","127ed7d3":"code","f528517c":"code","6f7887bd":"code","4b29d5e6":"code","666bc9e0":"code","24d74629":"code","1ed9b93d":"code","fb352ab3":"markdown","becd53d3":"markdown","14596e33":"markdown","73d5e438":"markdown","68bd1d51":"markdown","a3ab65a0":"markdown","a9fc51fd":"markdown"},"source":{"4fba27ec":"import math\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n\n\nprint(tf.__version__)\nprint(tf.version.VERSION)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.2f}'.format","99029f80":"df = pd.read_csv(\"https:\/\/storage.googleapis.com\/ml_universities\/california_housing_train.csv\", sep = \",\")\ndf.info()","aa189bfe":"df.describe()","a4027387":"df.head()","4c358d99":"df.tail()","24aa3626":"df[:30]","dc2fbb1d":"df.iloc[4:7]","334fe4e1":"\ndf['num_rooms'] = df['total_rooms'] \/ df['households']\ndf.describe()","3501357f":"#split the data\nnp.random.seed(seed=1)\nmsk = np.random.rand(len(df)) <0.85\ntraindf = df[msk]\nevaldf = df[~msk]","cce29099":"traindf.describe()","127ed7d3":"evaldf.describe()","f528517c":"OUTDIR =\".\/housing_trained\"","6f7887bd":"def train_and_evaluate(output_dir, num_train_steps):\n    estimator = tf.compat.v1.estimator.LinearRegressor(\n                                                       model_dir=output_dir,\n                                                       feature_columns=[tf.feature_column.numeric_column(\"num_rooms\")])\n    \n    def rmse(labels,predictions):\n        pred_values = tf.cast(predictions[\"predictions\"],tf.float64)\n        return {\"rmse\" : tf.compat.v1.metrics.root_mean_squared_error(labels,pred_values)}\n    estimator = tf.compat.v1.estimator.add_metrics(estimator,rmse)\n    \n    \n    train_spec = tf.estimator.TrainSpec(\n                                       input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\"]],\n                                              y = traindf[\"median_house_value\"],  # note the scaling\n                                              num_epochs = None,\n                                              shuffle = True),\n                       max_steps = num_train_steps)\n    eval_spec=tf.estimator.EvalSpec(\n                   input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\"]],\n                                          y = evaldf[\"median_house_value\"],  # note the scaling\n                                          num_epochs = 1,\n                                          shuffle = False),\n                   steps = None,\n                   start_delay_secs = 1, # start evaluating after N seconds\n                   throttle_secs = 10,  # evaluate every N seconds\n                   )\n    tf.estimator.train_and_evaluate(estimator,train_spec,eval_spec)\n    \n    \n# Run training    \nshutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\ntrain_and_evaluate(OUTDIR, num_train_steps = 100)\n    ","4b29d5e6":"SCALE = 100000\nOUTDIR = '.\/housing_trained'\ndef train_and_evaluate(output_dir, num_train_steps):\n  estimator = tf.compat.v1.estimator.LinearRegressor(\n                       model_dir = output_dir, \n                       feature_columns = [tf.feature_column.numeric_column('num_rooms')])\n  \n  #Add rmse evaluation metric\n  def rmse(labels, predictions):\n    pred_values = tf.cast(predictions['predictions'],tf.float64)\n    return {'rmse': tf.compat.v1.metrics.root_mean_squared_error(labels*SCALE, pred_values*SCALE)}\n  estimator = tf.compat.v1.estimator.add_metrics(estimator,rmse)\n  \n  train_spec=tf.estimator.TrainSpec(\n                       input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\"]],\n                                              y = traindf[\"median_house_value\"] \/ SCALE,  # note the scaling\n                                              num_epochs = None,\n                                              shuffle = True),\n                       max_steps = num_train_steps)\n  eval_spec=tf.estimator.EvalSpec(\n                       input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\"]],\n                                              y = evaldf[\"median_house_value\"] \/ SCALE,  # note the scaling\n                                              num_epochs = 1,\n                                              shuffle = False),\n                       steps = None,\n                       start_delay_secs = 1, # start evaluating after N seconds\n                       throttle_secs = 10,  # evaluate every N seconds\n                       )\n  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n\n# Run training    \nshutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\ntrain_and_evaluate(OUTDIR, num_train_steps = 100)","666bc9e0":"!ls","24d74629":"!ls .\/$OUTDIR *","1ed9b93d":"SCALE = 100000\nOUTDIR = '.\/housing_trained'\ndef train_and_evaluate(output_dir, num_train_steps):\n  myopt = tf.compat.v1.train.FtrlOptimizer(learning_rate = 0.2) # note the learning rate\n  estimator = tf.compat.v1.estimator.LinearRegressor(\n                       model_dir = output_dir, \n                       feature_columns = [tf.feature_column.numeric_column('num_rooms')],\n                       optimizer = myopt)\n  \n  #Add rmse evaluation metric\n  def rmse(labels, predictions):\n    pred_values = tf.cast(predictions['predictions'],tf.float64)\n    return {'rmse': tf.compat.v1.metrics.root_mean_squared_error(labels*SCALE, pred_values*SCALE)}\n  estimator = tf.compat.v1.estimator.add_metrics(estimator,rmse)\n  \n  train_spec=tf.estimator.TrainSpec(\n                       input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\"]],\n                                              y = traindf[\"median_house_value\"] \/ SCALE,  # note the scaling\n                                              num_epochs = None,\n                                              batch_size = 512, # note the batch size\n                                              shuffle = True),\n                       max_steps = num_train_steps)\n  eval_spec=tf.estimator.EvalSpec(\n                       input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\"]],\n                                              y = evaldf[\"median_house_value\"] \/ SCALE,  # note the scaling\n                                              num_epochs = 1,\n                                              shuffle = False),\n                       steps = None,\n                       start_delay_secs = 1, # start evaluating after N seconds\n                       throttle_secs = 10,  # evaluate every N seconds\n                       )\n  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n\n# Run training    \nshutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\ntrain_and_evaluate(OUTDIR, num_train_steps = 100)","fb352ab3":"## Examine the dataset","becd53d3":"# Hand tuning hyperparameters\n\n* use of linearregressor class of tgensorflow to predict median house price.\n* Evaluate the model based on RMSE\n* improve the accuracy of the model by tuning with hand","14596e33":"# Setup ","73d5e438":"## Change learning rate and batch size","68bd1d51":"I am going to take the first feature \"num_room\" to educate my linear model about median value","a3ab65a0":"\nIn this exercise, we'll be trying to predict median_house_value. It will be our label (sometimes also called a target). Can we use total_rooms as our input feature? What's going on with the values for that feature?\n\nThis data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively. Let's create a different, more appropriate feature. Because we are predicing the price of a single house, we should try to make all our features correspond to a single house as well","a9fc51fd":"## scaling the output by 100000"}}