{"cell_type":{"43827d47":"code","423af435":"code","97e5b9bc":"code","9ee739d8":"code","9918a103":"code","0251f9a5":"code","89b826f8":"code","fc4dd35b":"code","0f43141b":"code","b4e6e5a8":"code","415fb3b5":"code","af3cc0a8":"code","9c214b05":"code","b76f787c":"code","a616b0d4":"code","740768a3":"code","7177bf38":"code","88f86f35":"code","67cf64de":"code","6e2d5408":"code","7e555a1c":"code","a89b520e":"code","c5a5c91a":"code","e9107411":"code","5a12cea0":"code","376ca330":"code","d3be51d8":"code","c8b6c903":"code","2d28dd92":"code","65fe0304":"code","b45b2f4a":"code","b771e61b":"code","d2487224":"code","64de7063":"code","6996ce2e":"code","5bd4b52d":"code","070eab22":"code","eb4c163c":"code","56b932f3":"code","5ff4243b":"code","79d5e665":"code","25af0837":"code","2f1cc7ae":"code","1ba3cf21":"code","3d970635":"code","8f5bb261":"code","69d65d1c":"code","a3e844c8":"code","f6e4ef75":"code","babe05ae":"code","434ac97f":"code","d0d25b0c":"code","1f8be3a5":"code","d2e7525e":"code","39c294f0":"code","0a409bec":"code","7ecc8bd2":"code","3e8472b3":"code","e82a5ef2":"code","7edc38b3":"code","f550184f":"code","2d1a7332":"code","020d0012":"code","3d701d83":"code","b15a5e55":"code","d4eb0ff5":"code","24f1fc61":"code","95a4f473":"code","74cc848c":"code","6bfaeda7":"code","0413b963":"markdown","9c8a64d9":"markdown","c68f1bc4":"markdown","e8c913c6":"markdown","5754733b":"markdown","4fe1207a":"markdown","f4665142":"markdown","fb91a789":"markdown","f6c2849b":"markdown","5fb419f9":"markdown","0275310c":"markdown","ca1b9400":"markdown","9e64b969":"markdown","b528d18b":"markdown","e2ca3456":"markdown","01bc533f":"markdown","9e9d79f0":"markdown","7ba44d60":"markdown","12385830":"markdown","ffa0ace7":"markdown","75aa9d86":"markdown","9285993f":"markdown","483e4dfe":"markdown","58a2f280":"markdown","41ce20cb":"markdown","86d53613":"markdown","f522e2c8":"markdown","3b11c5a9":"markdown","3984e2ca":"markdown","bebb0968":"markdown","e58d0217":"markdown","ed45c6ea":"markdown","81298cc2":"markdown","a771047d":"markdown","75dcc8ed":"markdown","0c76994c":"markdown","ef8a17bc":"markdown","a1c57e5d":"markdown","fac52d20":"markdown","e43cce81":"markdown","2804792a":"markdown","2346e829":"markdown","1dfb70d0":"markdown","8fb64da4":"markdown","a349167b":"markdown","0c3bc1eb":"markdown","c0fe8d6c":"markdown","246b6e0c":"markdown","2eebcbba":"markdown","966dcf52":"markdown","066a869c":"markdown","dc255b5a":"markdown","b913e5aa":"markdown","b9a0cee7":"markdown","5bf69b0d":"markdown"},"source":{"43827d47":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","423af435":"data = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\ndata.head(2)","97e5b9bc":"data.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate',\n       'exercise_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']\n\ndata.columns.unique()","9ee739d8":"data.describe().round(2)","9918a103":"data.info()","0251f9a5":"col_class = [\n    len(data.sex.unique()),\n    len(data.chest_pain_type.unique()),\n    len(data.resting_blood_pressure.unique()),\n    len(data.serum_cholesterol.unique()),\n    len(data.fasting_blood_sugar.unique()),\n    len(data.rest_ecg.unique()),\n    len(data.max_heart_rate.unique()),\n    len(data.exercise_angina.unique()),\n    len(data.st_depression.unique()),\n    len(data.st_slope.unique()),\n    len(data.num_major_vessels.unique()),\n    len(data.thalassemia.unique()),\n    len(data.target.unique()),\n]\n\nplt.figure(figsize=(6,6))\nplt.barh(data.columns.unique()[1:], col_class)\nplt.show()","89b826f8":"print('Total people safe = %d' % len(data[data.target == 0]))\nprint('Total people diseased = %d' % len(data[data.target == 1]))\n\nplt.figure(figsize=(5,5))\nsns.countplot(data.target)\nplt.ylim(0,250)\nplt.legend(['Safe', 'Diseased'])\nplt.show()","fc4dd35b":"data['age'].hist(bins=25)","0f43141b":"plt.figure(figsize=(18, 10))\nsns.countplot(x='age', hue='target', data=data)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","b4e6e5a8":"data['age'].mode()","415fb3b5":"young = data[data.age <= 40]\nmiddle = data[(data.age > 40) & (data.age <= 55)]\nold = data[data.age > 55]\n\nprint('Total young people %d' % len(young))\nprint('Total middle-aged people %d' % len(middle))\nprint('Total old people %d' % len(old))\n\nax = plt.figure(figsize=(8,4))\nplt.barh(['young', 'middle', 'old'], [len(young), len(middle), len(old)])\nplt.title('Total people in each group age')\nplt.show()","af3cc0a8":"age_m = [len(young[young.sex==1]), len(middle[middle.sex==1]), len(old[old.sex==1])]\nage_f = [len(young[young.sex==0]), len(middle[middle.sex==0]), len(old[old.sex==0])]\nxpos = np.arange(0,3)\n\nplt.xticks(xpos, ['young', 'middle', 'old'])\nplt.bar(xpos+0.2, age_m, width=0.4, label='Male')\nplt.bar(xpos-0.2, age_f, width=0.4, label='Female')\nplt.title('Total people in each group age by gender')\nplt.ylim(0,130)\nplt.legend()\nplt.show()","9c214b05":"age_m = [len(young[young.target==1]), len(middle[middle.target==1]), len(old[old.target==1])]\nage_f = [len(young[young.target==0]), len(middle[middle.target==0]), len(old[old.target==0])]\nxpos = np.arange(0,3)\n\nplt.xticks(xpos, ['young', 'middle', 'old'])\nplt.bar(xpos+0.2, age_m, width=0.4, label='Diseased')\nplt.bar(xpos-0.2, age_f, width=0.4, label='Safe')\nplt.title('Total diseased and safe people on each group age')\nplt.ylim(0,130)\nplt.legend()\nplt.show()","b76f787c":"plt.figure(figsize=(8,5))\nplt.title('People safe and diseased by sex')\nsns.countplot(y=data.sex, hue=data.target)\nplt.yticks(np.arange(0,2), ['Female', 'Male'])\nplt.show()","a616b0d4":"fig = plt.figure(figsize=(15,6))\nplt.title('People safe and diseased by sex and group age')\nplt.axis('off')\n\nax1 = fig.add_subplot(131)\nsns.countplot(young.sex, hue=young.target, ax=ax1)\nax1.set_xticklabels(['Male', 'Female'])\nax1.set_ylim(0,100)\n\nax2 = fig.add_subplot(132)\nsns.countplot(middle.sex, hue=middle.target, ax=ax2)\nax2.set_xticklabels(['Male', 'Female'])\nax2.set_ylim(0,100)\n\nax3 = fig.add_subplot(133)\nsns.countplot(old.sex, hue=old.target, ax=ax3)\nax3.set_xticklabels(['Male', 'Female'])\nax3.set_ylim(0,100)\n\nplt.show()","740768a3":"sns.countplot(x='chest_pain_type', hue=\"target\", data=data)\nplt.title(\"People safe and diseased grouped by chest pain type\")\nplt.show()","7177bf38":"sns.barplot(x=\"target\", y='resting_blood_pressure',data = data)\nplt.title('People safe and diseased grouped by their blood pressure')\nplt.show()","88f86f35":"sns.barplot(x=\"target\", y='serum_cholesterol',data = data)\nplt.title('People safe and diseased grouped by their cholesterol')\nplt.show()","67cf64de":"sns.countplot(hue='fasting_blood_sugar',x ='target',data = data)\nplt.title('People safe and diseased grouped by their cholesterol their Fasting Blood Sugar')\nplt.show()","6e2d5408":"sns.countplot(x='rest_ecg', hue ='target', data = data)\nplt.title('People safe and diseased grouped by their ECG graph')\nplt.show()","7e555a1c":"sns.barplot(x=\"target\", y='max_heart_rate',data= data)\nplt.title('People safe and diseased grouped by their Maximum Heart Rate')\nplt.show()","a89b520e":"sns.countplot(x='exercise_angina', hue ='target', data = data)\nplt.title('People safe and diseased grouped by their Exercise Induced Angina')\nplt.show()","c5a5c91a":"sns.countplot(hue='st_slope',x ='target',data = data)\nplt.title('People safe and diseased grouped by their depression value')\nplt.show()","e9107411":"sns.countplot(hue='num_major_vessels',x ='target',data = data)\nplt.title('People safe and diseased grouped by their Number Blood Vessel')\nplt.show()","5a12cea0":"sns.countplot(hue='thalassemia',x ='target',data = data)\nplt.title('People safe and diseased grouped by their thalassemia type')\nplt.show()","376ca330":"plt.figure(figsize=(10,8))\nplt.title('Correlation between variable before outlier removal')\nsns.heatmap(data.corr(), annot=True, fmt='.1f')\nplt.show()","d3be51d8":"# sns.scatterplot('age', 'st_depression', data=data)\nplt.figure(figsize=(8,4))\nsns.pairplot(data[['age', 'st_depression', 'serum_cholesterol', 'resting_blood_pressure', 'max_heart_rate']])\nplt.show","c8b6c903":"def assign_col(row):\n    if row >= 29 and row <= 40:\n        return 1\n    elif row > 40 and row <= 55:\n        return 2\n    else:\n        return 3\n\ndata['age_bin'] = data['age'].apply(assign_col)\ndata = data[['age', 'age_bin', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate',\n       'exercise_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']]\ndata.head()","2d28dd92":"plt.figure(figsize=(7,8))\nplt.title('Boxplot Initial Data')\n\nax1 = plt.subplot(221)\nax1.boxplot(data['st_depression'])\nax1.set_xticklabels(['st_depression'])\n\nax2 = plt.subplot(222)\nax2.boxplot(data['serum_cholesterol'])\nax2.set_xticklabels(['serum_cholesterol'])\n\nax3 = plt.subplot(223)\nax3.boxplot(data['resting_blood_pressure'])\nax3.set_xticklabels(['resting_blood_pressure'])\n\nax4 = plt.subplot(224)\nax4.boxplot(data['max_heart_rate'])\nax4.set_xticklabels(['max_heart_rate'])\n\nplt.show()","65fe0304":"def remove_outliers(df, column):\n    upper = df[column].quantile(.90)\n    lower = df[column].quantile(.10)\n    \n    out = df[(df[column] > upper) | (df[column] < lower)]\n    print('Total outlier %s = %d' % (column, len(out)))\n    \n    df = df[(df[column] < upper) & (df[column] > lower)]\n    return df","b45b2f4a":"# before remove outlier\nlen(data)","b771e61b":"columns = ['st_depression', 'serum_cholesterol', 'resting_blood_pressure', 'max_heart_rate']\n\n# remove outlier\ndata_clean = data\nfor i in columns:\n    data_clean = remove_outliers(data_clean, i)\n\ndata_clean = data_clean.reset_index()\n\n# after remove outlier\nprint('=====================')\nprint('After outlier removal = %d ' % len(data_clean))","d2487224":"plt.figure(figsize=(7,8))\n\nax1 = plt.subplot(221)\nax1.boxplot(data_clean['st_depression'])\nax1.set_xticklabels(['st_depression'])\n\nax2 = plt.subplot(222)\nax2.boxplot(data_clean['serum_cholesterol'])\nax2.set_xticklabels(['serum_cholesterol'])\n\nax3 = plt.subplot(223)\nax3.boxplot(data_clean['resting_blood_pressure'])\nax3.set_xticklabels(['resting_blood_pressure'])\n\nax4 = plt.subplot(224)\nax4.boxplot(data_clean['max_heart_rate'])\nax4.set_xticklabels(['max_heart_rate'])\n\nplt.show()","64de7063":"from scipy.stats import chi2_contingency\n\ncat_col = ['age_bin', 'sex', 'chest_pain_type', 'st_slope', 'thalassemia']\nchi2_check = []\nchi_score = []\n\nfor i in cat_col:\n    chi_test = chi2_contingency(pd.crosstab(data['target'], data[i]))[1]\n    chi_score.append(chi_test)\n    if chi_test < 0.05:\n        chi2_check.append('Reject Null Hypothesis')\n    else:\n        chi2_check.append('Fail to Reject Null Hypothesis')\nres = pd.DataFrame(data = [cat_col, chi2_check, chi_score] \n             ).T \nres.columns = ['Column', 'Hypothesis', 'Chi Score']\nres","6996ce2e":"# data without outlier removal\n# convert numbered label to string first\ndata_enc = data\ndata_enc.chest_pain_type = data_enc.chest_pain_type.map({1:'angina pectoris', 2:'atypical angina', 3:'non-anginal pain', 4:'SMI', 0:'absent'})\n\ndata_enc.st_slope = data_enc.st_slope.map({1:'upsloping', 2:'horizontal', 3:'downsloping', 0:'absent'})\n\ndata_enc.thalassemia = data_enc.thalassemia.map({1:'normal', 2:'fixed defect', 3:'reversable defect', 0:'absent'})\n\ndata_enc.age_bin = data_enc.age_bin.map({1:'young', 2:'middle', 3:'old', 0:'absent'})\ndata_enc.head()","5bd4b52d":"X = data_enc.iloc[:, 1:-1]\ny = data_enc.iloc[:, -1]\nX.head(1)","070eab22":"# Categorical columns\ncat_cols = ['age_bin', 'chest_pain_type', 'st_slope', 'thalassemia']\n\nfor column in cat_cols:\n    dummies = pd.get_dummies(X[column], drop_first=True)\n    X[dummies.columns] = dummies\n    X.drop(column, axis=1, inplace=True)\n    \nX.head()","eb4c163c":"from sklearn.model_selection import train_test_split, GridSearchCV\n\n# Splitting the data into test and train \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"X-Train:\",X_train.shape)\nprint(\"X-Test:\",X_test.shape)\nprint(\"Y-Train:\",y_train.shape)\nprint(\"Y-Test:\",y_test.shape)","56b932f3":"from sklearn.preprocessing import StandardScaler\n\nnum_cols = ['st_depression', 'serum_cholesterol', 'resting_blood_pressure', 'max_heart_rate']\nscaler = StandardScaler()\nscaler.fit(X_train[num_cols])\n\nX_train[num_cols] = scaler.transform(X_train[num_cols])\nX_test[num_cols] = scaler.transform(X_test[num_cols])\n\nX_train.head()","5ff4243b":"# data without outlier removal\n# convert numbered label to string first\ndata_enc_clean = data_clean\ndata_enc_clean.chest_pain_type = data_enc_clean.chest_pain_type.map({1:'angina pectoris', 2:'atypical angina', 3:'non-anginal pain', 4:'SMI', 0:'absent'})\n\ndata_enc_clean.st_slope = data_enc_clean.st_slope.map({1:'upsloping', 2:'horizontal', 3:'downsloping', 0:'absent'})\n\ndata_enc_clean.thalassemia = data_enc_clean.thalassemia.map({1:'normal', 2:'fixed defect', 3:'reversable defect', 0:'absent'})\n\ndata_enc_clean.age_bin = data_enc_clean.age_bin.map({1:'young', 2:'middle', 3:'old', 0:'absent'})\ndata_enc_clean.head()","79d5e665":"X_clean = data_enc_clean.iloc[:, 1:-1]\ny_clean = data_enc_clean.iloc[:, -1]\nX_clean.head(1)","25af0837":"# Categorical columns\ncat_cols = ['age_bin', 'chest_pain_type', 'st_slope', 'thalassemia']\n\nfor column in cat_cols:\n    dummies = pd.get_dummies(X_clean[column], drop_first=True)\n    X_clean[dummies.columns] = dummies\n    X_clean.drop(column, axis=1, inplace=True)\n    \nX_clean.head()","2f1cc7ae":"from sklearn.model_selection import train_test_split, GridSearchCV\n\n# Splitting the data into test and train \nX_clean_train, X_clean_test, y_clean_train, y_clean_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n\nprint(\"X-Train:\",X_clean_train.shape)\nprint(\"X-Test:\",X_clean_test.shape)\nprint(\"Y-Train:\",y_clean_train.shape)\nprint(\"Y-Test:\",y_clean_test.shape)","1ba3cf21":"from sklearn.preprocessing import StandardScaler\n\nnum_cols = ['st_depression', 'serum_cholesterol', 'resting_blood_pressure', 'max_heart_rate']\nscaler = StandardScaler()\nscaler.fit(X_clean_train[num_cols])\n\nX_clean_train[num_cols] = scaler.transform(X_clean_train[num_cols])\nX_clean_test[num_cols] = scaler.transform(X_clean_test[num_cols])\n\nX_clean_train.head()","3d970635":"from sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score","8f5bb261":"svm = SVC()\nsvm.fit(X_train, y_train)\ny_pred = svm.predict(X_test)\n\naccuracy_svm = accuracy_score(y_pred, y_test)\nprint(f\"The accuracy on test set using SVM is: {np.round(accuracy_svm, 3)*100.0}%\")\nprint(classification_report(y_test, y_pred))","69d65d1c":"cv_score = cross_val_score(svm, X_train, y_train, cv=10, scoring='accuracy', n_jobs = -1)\nprint(cv_score, end='\\n\\n')\nprint('Mean accuracy cross validation %f ' % np.mean(cv_score))","a3e844c8":"f, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\".0f\", ax=ax)\nplt.xlabel(\"y_head\")\nplt.ylabel(\"y_true\")\nplt.show()","f6e4ef75":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ny_pred = gnb.fit(X_train, y_train).predict(X_test)\naccuracy_nb = accuracy_score(y_pred, y_test)\nprint(f\"The accuracy on test set using Naive Bayes is: {np.round(accuracy_nb, 3)*100.0}%\")\nprint(classification_report(y_test, y_pred))","babe05ae":"cv_score = cross_val_score(gnb, X_train, y_train, cv=10, scoring='accuracy', n_jobs = -1)\nprint(cv_score, end='\\n\\n')\nprint('Mean accuracy cross validation %f ' % np.mean(cv_score))","434ac97f":"f, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\".0f\", ax=ax)\nplt.xlabel(\"y_head\")\nplt.ylabel(\"y_true\")\nplt.show()","d0d25b0c":"\n# creating a list of K's for performing KNN\nmy_list = list(range(0,30))\n\n# filtering out only the odd K values\nneighbors = list(filter(lambda x: x % 2 != 0, my_list))\n\n# list to hold the cv scores\ncv_scores = []\n\n# perform 10-fold cross validation with default weights\nfor k in neighbors:\n  Knn = KNeighborsClassifier(n_neighbors = k, algorithm = 'brute')\n  scores = cross_val_score(Knn, X_train, y_train, cv=10, scoring='accuracy', n_jobs = -1)\n  cv_scores.append(scores.mean())\n\n# finding the optimal k\noptimal_k = neighbors[cv_scores.index(max(cv_scores))]\nprint(\"The optimal K value is with default weight parameter: \", optimal_k)","1f8be3a5":"# plotting accuracy vs K\nplt.plot(neighbors, cv_scores)\nplt.xlabel(\"Number of Neighbors K\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy vs K Plot for normal \")\nplt.grid()\nplt.show()\n\nprint(\"Accuracy scores for each K value is : \", np.round(cv_scores, 3))","d2e7525e":"# Finding the accuracy of KNN with optimal K\n\nfrom sklearn.metrics import accuracy_score\n\n# create instance of classifier\nknn_optimal = KNeighborsClassifier(n_neighbors = optimal_k, algorithm = 'kd_tree', \n                                   n_jobs = -1)\n\n# fit the model\nknn_optimal.fit(X_train, y_train)\n\n# predict on test vector\ny_pred = knn_optimal.predict(X_test)\n\n# evaluate accuracy score\naccuracy_knn = accuracy_score(y_test, y_pred)\nprint(f\"The accuracy on test set using KNN for optimal K = {optimal_k} is {np.round(accuracy_knn, 3)*100}%\")\nprint(classification_report(y_test, y_pred))","39c294f0":"cv_scores = cross_val_score(Knn, X_train, y_train, cv=10, scoring='accuracy', n_jobs = -1)\nprint(cv_score, end='\\n\\n')\nprint('Mean accuracy cross validation %f ' % np.mean(cv_score))","0a409bec":"f, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\".0f\", ax=ax)\nplt.xlabel(\"y_head\")\nplt.ylabel(\"y_true\")\nplt.show()","7ecc8bd2":"from sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score","3e8472b3":"svm = SVC()\nsvm.fit(X_clean_train, y_clean_train)\ny_clean_pred = svm.predict(X_clean_test)\n\naccuracy_svm_clean = accuracy_score(y_clean_pred, y_clean_test)\nprint(f\"The accuracy on test set using SVM is: {np.round(accuracy_svm_clean, 3)*100.0}%\")\nprint(classification_report(y_clean_test, y_clean_pred))","e82a5ef2":"cv_score = cross_val_score(svm, X_clean_train, y_clean_train, cv=10, scoring='accuracy', n_jobs = -1)\nprint(cv_score, end='\\n\\n')\nprint('Mean accuracy cross validation %f ' % np.mean(cv_score))","7edc38b3":"f, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(confusion_matrix(y_clean_test, y_clean_pred), annot=True, fmt=\".0f\", ax=ax)\nplt.xlabel(\"y_head\")\nplt.ylabel(\"y_true\")\nplt.show()","f550184f":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ny_clean_pred = gnb.fit(X_clean_train, y_clean_train).predict(X_clean_test)\naccuracy_nb_clean = accuracy_score(y_clean_pred, y_clean_test)\nprint(f\"The accuracy on test set using Naive Bayes is: {np.round(accuracy_nb_clean, 3)*100.0}%\")\nprint(classification_report(y_clean_test, y_clean_pred))","2d1a7332":"cv_score = cross_val_score(gnb, X_clean_train, y_clean_train, cv=10, scoring='accuracy', n_jobs = -1)\nprint(cv_score, end='\\n\\n')\nprint('Mean accuracy cross validation %f ' % np.mean(cv_score))","020d0012":"f, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(confusion_matrix(y_clean_test, y_clean_pred), annot=True, fmt=\".0f\", ax=ax)\nplt.xlabel(\"y_head\")\nplt.ylabel(\"y_true\")\nplt.show()","3d701d83":"\n# creating a list of K's for performing KNN\nmy_list = list(range(0,30))\n\n# filtering out only the odd K values\nneighbors = list(filter(lambda x: x % 2 != 0, my_list))\n\n# list to hold the cv scores\ncv_scores = []\n\n# perform 10-fold cross validation with default weights\nfor k in neighbors:\n  Knn = KNeighborsClassifier(n_neighbors = k, algorithm = 'brute')\n  scores = cross_val_score(Knn, X_clean_train, y_clean_train, cv=10, scoring='accuracy', n_jobs = -1)\n  cv_scores.append(scores.mean())\n\n# finding the optimal k\noptimal_k = neighbors[cv_scores.index(max(cv_scores))]\nprint(\"The optimal K value is with default weight parameter: \", optimal_k)","b15a5e55":"# plotting accuracy vs K\nplt.plot(neighbors, cv_scores)\nplt.xlabel(\"Number of Neighbors K\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy vs K Plot for normal \")\nplt.grid()\nplt.show()\n\nprint(\"Accuracy scores for each K value is : \", np.round(cv_scores, 3))","d4eb0ff5":"# Finding the accuracy of KNN with optimal K\n\nfrom sklearn.metrics import accuracy_score\n\n# create instance of classifier\nknn_optimal = KNeighborsClassifier(n_neighbors = optimal_k, algorithm = 'kd_tree', \n                                   n_jobs = -1)\n\n# fit the model\nknn_optimal.fit(X_clean_train, y_clean_train)\n\n# predict on test vector\ny_clean_pred = knn_optimal.predict(X_clean_test)\n\n# evaluate accuracy score\naccuracy_knn_clean = accuracy_score(y_clean_test, y_clean_pred)\nprint(f\"The accuracy on test set using KNN for optimal K = {optimal_k} is {np.round(accuracy_knn_clean, 3)*100}%\")\nprint(classification_report(y_clean_test, y_clean_pred))","24f1fc61":"cv_scores = cross_val_score(Knn, X_clean_train, y_clean_train, cv=10, scoring='accuracy', n_jobs = -1)\nprint(cv_score, end='\\n\\n')\nprint('Mean accuracy cross validation %f ' % np.mean(cv_score))","95a4f473":"f, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(confusion_matrix(y_clean_test, y_clean_pred), annot=True, fmt=\".0f\", ax=ax)\nplt.xlabel(\"y_head\")\nplt.ylabel(\"y_true\")\nplt.show()","74cc848c":"model_list = ['SVM (outlier)', 'Naive Bayes (outlier)', 'KNN (outlier)', 'SVM ', 'Naive Bayes', 'KNN']\nacc_list = [accuracy_svm, accuracy_nb, accuracy_knn, accuracy_svm_clean, accuracy_nb_clean, accuracy_knn_clean]\n\ndf_comp = pd.DataFrame({ 'model' : model_list, 'accuracy' : acc_list })\ndf_comp_sort = df_comp.sort_values('accuracy', ascending=False)\ndf_comp_sort","6bfaeda7":"plt.figure(figsize=(8,5))\nplt.title('Accuracy comparison between models.')\nsns.barplot(df_comp_sort['model'], df_comp_sort['accuracy'])\nplt.xticks(rotation=45)\nplt.show()","0413b963":"Note:\n* Value 0: typical angina\n* Value 1: atypical angina\n* Value 2: non-anginal pain\n* Value 3: asymptomatic 0-3.\n\n\nNon-aginal pain become the most common type of chest pain among heart disease patients. Furthermore, there are several patients who dont have chest pain but still have heart disease.","9c8a64d9":"youngest people that have a heart attack is on 29 old.","c68f1bc4":"Cross Validation","e8c913c6":"Cross Validation","5754733b":"Cross Validation","4fe1207a":"Confusion Matrix","f4665142":"### Encoding Phase","fb91a789":"### Now, separating feature and target variables","f6c2849b":"### Naive Bayes","5fb419f9":"## Feature Selection","0275310c":"### KNN","ca1b9400":"As we can see that each of continuous variable having outliers.","9e64b969":"heart disease patients have lower blood pressure but not significant.","b528d18b":"Let's try to grouping them into three groups:\n- young\n- middle-age\n- old","e2ca3456":"# Comparison and Conclusion","01bc533f":"# Modelling\nWithout outlier removal","9e9d79f0":"Confusion Matrix","7ba44d60":"#### Let's try to do Chi-Test\n\nThe hypothesis is:\n\nNull Hypothesis (H0): There is no relationship between the variables\nAlternative Hypothesis (H1): There is a relationship between variables","12385830":"## Standardize Data\nWithout outlier removal","ffa0ace7":"### Encoding Phase","75aa9d86":"Cross Validation","9285993f":"# Preprocessing\n","483e4dfe":"but by sex, female dominating in heart disease","58a2f280":"Confusion Matrix","41ce20cb":"### KNN","86d53613":"## Full Form of the column Headings\n1. **Age**: Age in years\n2. **Sex**: Male (1) or Female(0)\n3. **CP**: pain has values between\n    - Value 0: typical angina\n    - Value 1: atypical angina\n    - Value 2: non-anginal pain\n    - Value 3: asymptomatic 0-3.\n4. **Resting Blood Pressure(trestbps)**: resting blood pressure (in mmHg on admission to the hospital)\n5. **Cholestorol**: serum cholestoral in mg\/dl\n6. **fbs(Fast blood sugar)** : blood sugar while fasting (>120 mg\/dl) (1=true\/0=false)\n7. **Rest ecg** : resting ecg graph\n    - Value 0: normal\n    - Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n8. **thalach**: max heart rate\n9. **exang** : Exercise induced angina is chest pain while exercising or doing any physical activity.(1 = yes; 0 = no)\n10. **Old peak** : ST Depression is the difference between value of ECG at rest and after exercise.\n11. **ST Slope** : is the tangent to the depression value.\n12. **The number of major blood vessels supplying blood to heart blocked.**\n13. **Thal** :The Types of thalassemia. (0=normal ,1= fixed defect ,2=reversable defect)\n14. **Target** : Here 1 denotes heart attack and 0 denotes didn't occur","f522e2c8":"Confusion Matrix","3b11c5a9":"## Load Data","3984e2ca":"Confusion Matrix","bebb0968":"### Naive Bayes","e58d0217":"* Blue: Fasting Blood Sugar < 120 mg\/dl\n* Orange: Fasting Blood Sugar > 120 mg\/dl\n\nHeart disease is mostly found in people who have fasting blood sugar <120 mg\/dl but this cannot be a verdict that a person potentially having a heart disease since the same trend is also found in people who are not have a heart disease.","ed45c6ea":"## Try to visualize data","81298cc2":"# Heart Disease Prediction\nIt's my very first notebook and exploratory. So please if you have any suggestion drop it in comment. Thank you :)","a771047d":"### SVM","75dcc8ed":"As we can see that people have this disease is mostly on 58 years old","0c76994c":"## One Hot Encoding\nWithout outlier removal\n","ef8a17bc":"### Now, separating feature and target variables","a1c57e5d":"## Find Outliers Data","fac52d20":"Confusion Matrix","e43cce81":"each group dominated by male","2804792a":"## One Hot Encoding\nWith outlier removal\n\n","2346e829":"unfortunately for young and middle group is dominted by people having heart disease","1dfb70d0":"Cross Validation","8fb64da4":"Cross Validation","a349167b":"heart disease patients have lower cholesterol but not significant.","0c3bc1eb":"### Binning Age Column","c0fe8d6c":"### SVM","246b6e0c":"So, we can conclude that all categorical variables are important to target variables. We don't need a single one to delete it.","2eebcbba":"#### Let's handle outliers data","966dcf52":"seems the data doesn't have null value","066a869c":"# Modelling\nWith outlier removal","dc255b5a":"## Standardize Data\nWith outlier removal","b913e5aa":"Seems that data isn't correlated each other","b9a0cee7":"# Exploratory Data Analysis","5bf69b0d":"## Find Correlation between Data"}}