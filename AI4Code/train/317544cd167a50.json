{"cell_type":{"de9496ca":"code","7f6666dc":"code","2212fd33":"code","f47c7146":"code","addd4179":"code","f75a5bfb":"code","e1cc4c55":"code","61fadd5a":"code","d87ff3a6":"code","6f51f93a":"code","48f748ac":"code","b9decec8":"code","dc067895":"code","d75e59ab":"code","ff93ba86":"code","2436ccb6":"code","ccda205b":"code","ed5acc81":"markdown","d4992ff4":"markdown","e6a1d434":"markdown","d51f36bc":"markdown","c967f6ef":"markdown","957761b6":"markdown","8da8966f":"markdown","0ebca2f1":"markdown","ecdf6006":"markdown","42e57507":"markdown","aa406d7e":"markdown","5ae33651":"markdown","5f2699c4":"markdown","7da131bf":"markdown","8213b6c1":"markdown","72c549a2":"markdown","2ade7ed5":"markdown"},"source":{"de9496ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport scipy as sc\n        \nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.pipeline import Pipeline\nfrom keras.layers import Dense, Input, Dropout\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom sklearn.impute import SimpleImputer\n\nfrom keras.optimizers import RMSprop, Adam, SGD\nfrom sklearn.feature_selection import SelectKBest, chi2, SelectPercentile\nfrom sklearn.preprocessing import LabelEncoder\nimport keras.backend as K\nfrom sklearn import metrics\nimport tensorflow as tf\n\nimport seaborn as sns\n# Any results you write to the current directory are saved as output.","7f6666dc":"train_transaction = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv\")\ntrain_identity = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv\")\n\ntest_identity = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv\")\ntest_transaction = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv\")","2212fd33":"train_transaction.head()","f47c7146":"train_identity.head()","addd4179":"print(\"train_transaction (Nbr Samples\/Nbr Columns): \", train_transaction.shape) \nprint(\"train_identity (Nbr Samples\/Nbr Columns): \", train_identity.shape)","f75a5bfb":"nans = train_transaction.isnull().mean(axis = 0).sort_values(ascending=False)*100\nnans.reset_index().rename({\"index\": \"column\", 0: \"NaNs rate\"}, axis=1)","e1cc4c55":"nans = train_identity.isnull().mean(axis = 0).sort_values(ascending=False)*100\nnans.reset_index().rename({\"index\": \"column\", 0: \"NaNs rate\"}, axis=1)","61fadd5a":"ax = sns.countplot(x=\"isFraud\", data=train_transaction)","d87ff3a6":"categorical_features = [\n    'ProductCD',\n    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n    'addr1', 'addr2',\n    'P_emaildomain',\n    'R_emaildomain',\n    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9'\n]\n\ndata = train_transaction.merge(train_identity, on=\"TransactionID\", how=\"left\")","6f51f93a":"data = data.loc[:, data.isnull().mean() <= .5]\ncolumns_to_keep = data.columns\ncategorical_cols = [c for c in categorical_features if c in data.columns]","48f748ac":"# Class count\ncount_class_0, count_class_1 = data.isFraud.value_counts()\n\n# Divide by class\ndf_class_0 = data[data['isFraud'] == 0]\ndf_class_1 = data[data['isFraud'] == 1]\n\ndf_class_0_under = df_class_0.sample(int(count_class_1 \/ 2))\nbalenced_df = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nbalenced_df = balenced_df.reset_index(drop=True)","b9decec8":"y = balenced_df.isFraud\nX = balenced_df.drop([\"TransactionID\", \"isFraud\"],axis=1)","dc067895":"def auc(y_true, y_pred):\n    return tf.py_func(metrics.roc_auc_score, (y_true, y_pred), tf.double)","d75e59ab":"def batch_generator(X, y, batch_size=16, shuffle=True):\n    '''\n    Return a random sample from X, y\n    '''\n    y = np.array(y)\n    list_of_index_0 = np.where(y == 0)[0]\n    list_of_index_1 = np.where(y == 1)[0]\n    batch_0 = int(batch_size \/ 2)\n    batch_1 = batch_size - batch_0\n    \n    while True:\n        idx_0 = np.random.choice(list_of_index_0, size=batch_0, replace=False,)\n        idx_1 = np.random.choice(list_of_index_1, size=batch_1, replace=False,)\n        idx = np.concatenate((idx_0, idx_1), axis=None)\n\n        if sc.sparse.issparse(X[idx]): \n            sample = X[idx].toarray()\n        else:\n            sample = X[idx]\n        label = y[idx]\n        \n        yield sample, label","ff93ba86":"def create_model(optimizer=\"adam\", dim=100):\n    model = Sequential()\n    \n    model.add(Dense(50, activation='sigmoid', input_shape=(dim,)))\n    model.add(Dropout(0.5), )\n    \n    model.add(Dense(20, activation='relu'))\n    model.add(Dropout(0.2), )\n \n    model.add(Dense(20, activation='relu'))\n    model.add(Dropout(0.2), )\n    \n    model.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))\n    \n    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[auc])\n    return model","2436ccb6":"kfold_splits = 5\nbatch_size = 512\nepochs = 100\noptimizer = \"NAdam\"\nimputing_strategy = \"mean\"","ccda205b":"results = { \"cv_val\": [], \"cv_train\": [],}\n\n# Instantiate the cross validator\nskf = StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n\n# Loop through the indices the split() method returns\nfor index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n    print (\"Training on fold \" + str(index+1) + \"\/\" + str(kfold_splits) + \"...\")\n  \n    #Split \n    xtrain, xval = X.iloc[train_indices], X.iloc[val_indices]\n    ytrain, yval = y.iloc[train_indices], y.iloc[val_indices]\n    \n    #LabelEncoding categorical columns\n    label_encoders = {c: LabelEncoder() for c in categorical_cols}\n    for c in categorical_cols:\n        xtrain.loc[:,c], xval.loc[:,c] = xtrain[c].map(str), xval[c].map(str)\n        #Handling Unknown Labels\n        label_encoders[c].fit(np.concatenate((xtrain[c].values, np.array([\"other\"])), axis=None))\n        xval.loc[:,c] = xval[c].map(lambda s: 'other' if s not in label_encoders[c].classes_ else s)\n        #LabelEncoding\n        xtrain.loc[:,c]  = label_encoders[c].transform(xtrain[c].values)\n        xval.loc[:,c]  = label_encoders[c].transform(xval[c].values)\n \n    #Imputing Missing Values\n    imp = SimpleImputer(missing_values=np.nan, strategy=imputing_strategy).fit(xtrain)\n    xtrain = imp.transform(xtrain)\n    xval = imp.transform(xval) \n    \n    #Normalize\n    dim = xtrain.shape[1]\n    scaler = StandardScaler(with_mean=False).fit(xtrain)\n    xtrain = scaler.transform(xtrain)\n    xval = scaler.transform(xval)\n  \n    # Create generators for fit_generator method\n    train_gen = batch_generator(xtrain, ytrain, batch_size=batch_size)\n    valid_gen = batch_generator(xval, yval, batch_size=batch_size)\n    \n    model = create_model(optimizer=optimizer, dim=dim)\n   \n    history = model.fit_generator(\n            generator=train_gen,\n            epochs=epochs,\n            verbose=1,\n            steps_per_epoch=xtrain.shape[0] \/\/ batch_size, #xtrain.shape[0] \/\/ batch_size\n            validation_data=valid_gen,\n            validation_steps=xval.shape[0] \/\/ batch_size, #xval.shape[0] \/\/ batch_size\n        )\n    #Evaluate Model\n    val_score, train_score = metrics.roc_auc_score(yval, [x[0] for x in model.predict(xval,verbose=0)]), metrics.roc_auc_score(ytrain, [x[0] for x in model.predict(xtrain,verbose=0)])\n    print(\"RoC AuC:   train %f val %f \" % (train_score, val_score))\n    results[\"cv_val\"].append(val_score)\n    results[\"cv_train\"].append(train_score)\n\nprint(\"Final Score: train %f (+\/- %f) val %f (+\/- %f)\" % (np.mean(results[\"cv_train\"]), np.std(results[\"cv_train\"]), np.mean(results[\"cv_val\"]), np.std(results[\"cv_val\"])))    ","ed5acc81":"# Import some libraries","d4992ff4":"## Check if dataframe is class balanced","e6a1d434":"# Building basic DeepNeural Model","d51f36bc":"### Train Transaction DataSet","c967f6ef":"## Building Keras Model","957761b6":"## Evaluating the Model with stratified k-fold cross validation","8da8966f":"## Class Balancing","0ebca2f1":"# Quick EDA","ecdf6006":"# IEEE-CIS Fraud Detection with Keras\n* Using roc-auc as metric\n* Class Balancing inside batchs with fit_generator so we can compute roc-auc \n* Stratified K-Fold Cross-Validation","42e57507":"### Train identity DataSet","aa406d7e":"# Loading Datasets","5ae33651":"## RoC AuC metric for Keras","5f2699c4":"## Finding the Percentage of Missing Values for each column","7da131bf":"# Preparing Train Data","8213b6c1":"### Parameters","72c549a2":"## Dorp columns with hight NaN numbers","2ade7ed5":"## Batch Generator \nWe make sure that every batch has sample from each class so we can compute RoC AuC score\n\n**TO DO:** BatchGenerator(keras.utils.Sequence) class "}}