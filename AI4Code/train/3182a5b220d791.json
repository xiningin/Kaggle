{"cell_type":{"ac54c2a8":"code","fc89f0c6":"code","43acdc78":"code","95dd3431":"code","67a43702":"code","09cd4728":"code","26397a8f":"code","fc5866d8":"code","09da5ed3":"code","6c00663a":"code","4bd164f8":"code","9b3ffbd8":"code","5f7f1d72":"code","eb87dc27":"code","07529de7":"code","2112fb87":"code","0f3c913f":"code","084a0434":"markdown","28fa1b73":"markdown","fe48ee51":"markdown","74e28625":"markdown","b2913497":"markdown","328ff39d":"markdown","30bf31a9":"markdown","22cee52c":"markdown","98bcd479":"markdown","6d11a576":"markdown","c204c46f":"markdown","14947f32":"markdown","e7085250":"markdown","9000431d":"markdown","da6cba90":"markdown","3b45fa21":"markdown","2160b290":"markdown"},"source":{"ac54c2a8":"# Import basic packages\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Import PyTorch packages\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision.transforms import Compose, ToTensor, Resize\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\n\nTRAIN_PATH = \"..\/input\/intel-image-classification\/seg_train\/seg_train\"\nVALIDATE_PATH = \"..\/input\/intel-image-classification\/seg_test\/seg_test\"\nTEST_PATH = \"..\/input\/intel-image-classification\/seg_pred\/seg_pred\"","fc89f0c6":"# Make sure all images have size [128, 128]\ntransform = Compose([\n    ToTensor(),\n    Resize((128, 128))\n])\n\n# Load train data and test data\ntrain_data = ImageFolder(root=TRAIN_PATH, transform=transform)\nvalidate_data = ImageFolder(root=VALIDATE_PATH, transform=transform)","43acdc78":"# View train dataset size\nprint(\"Train dataset has {0} images\".format(len(train_data)))\n\n# View image size and class\nfst_img, fst_lbl = train_data[0]\nprint(\"First image has size: {0} and class: {1}.\".format(fst_img.shape, fst_lbl))\n\nsc_img, sc_lbl = train_data[5000]\nprint(\"Another random image has size: {0} and class: {1}.\".format(sc_img.shape, sc_lbl))\n\n# View all classes\nclasses = train_data.classes\nprint(\"There are {0} classes in total: \".format(len(classes)))\nprint(classes)","95dd3431":"# Store data in ImageFolder to DataLoader\ntrain_ds = DataLoader(train_data, shuffle=True, pin_memory=True, num_workers=8)\nvalidate_ds = DataLoader(validate_data, shuffle=True, pin_memory=True, num_workers=8)","67a43702":"# Plot a few images\ncount = 0\nfigure, axis = plt.subplots(1, 4, figsize=(16,8))\n\nfor batch in train_ds:\n    img, lbl = batch\n    axis[count].imshow(img[0].permute(1, 2, 0))\n    axis[count].set_title(classes[lbl.item()])\n    axis[count].axis(\"off\")\n    if count == 3:\n        break\n    else:\n        count += 1\nplt.show()","09cd4728":"# Create the CNN\nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Flatten(),\n            nn.Linear(512 * 8 * 8, 512),\n            nn.ReLU(),\n            nn.Linear(512, 64),\n            nn.ReLU(),\n            nn.Linear(64, 6)\n        )\n    \n    def forward(self, img):\n        output = self.model(img)\n        return output","26397a8f":"# Initialize and view model\nmodel = SimpleNet()\nmodel","fc5866d8":"# Perform training and cross validation\n# Calculate accuracy\ndef calcAccuracy(scores, label):\n    _, prediction = torch.max(scores, dim=1)\n    return torch.tensor(torch.sum(prediction == label).item()\/len(scores))\n\n# Cross validate\ndef validate(validate_ds, model,softmax):\n    validate_length = 0\n    accuracy = 0\n    for img, lbl in validate_ds:\n        scores = model(img)\n        loss = softmax(scores, lbl)\n        accuracy += calcAccuracy(scores, lbl)\n        validate_length += 1\n    accuracy \/= validate_length\n    return loss, accuracy\n\n# Run the training and cross validation\ndef fit(train_ds, validate_ds, no_epochs, optimizer, model):\n    history = []\n    softmax = nn.CrossEntropyLoss()\n    for index in range(no_epochs):\n        # Train\n        for img, lbl in train_ds:\n            scores = model(img)\n            loss = softmax(scores, lbl)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        # Validate\n        valid_loss, valid_acr = validate(validate_ds, model, softmax)\n            \n        # Print epoch record\n        print(f\"Epoch [{index + 1}\/{no_epochs}] => loss: {loss}, val_loss: {valid_loss}, val_acc: {valid_acr}\")\n        history.append({\"loss\": loss,\n                       \"valid_loss\": valid_loss,\n                       \"valid_acr\": valid_acr\n                       })\n    return history","09da5ed3":"# Load dataset to GPU\ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass GPUDataLoader():\n    def __init__(self, ds, device):\n        self.ds = ds\n        self.device = device\n    \n    def __iter__(self):\n        for batch in self.ds:\n            yield to_device(batch, self.device)","6c00663a":"# Initialize model and data before training\ndevice = torch.device('cuda:0')\nmodel = model.to(device)\ntrain_ds = GPUDataLoader(train_ds, device)\nvalidate_ds = GPUDataLoader(validate_ds, device)","4bd164f8":"optimizer = torch.optim.Adam(model.parameters(), lr=0.000025)\nno_epochs = 10\nhistory = fit(train_ds, validate_ds, no_epochs, optimizer, model)","9b3ffbd8":"history","5f7f1d72":"train_loss = []\nvalid_loss = []\nvalid_acr = []\nfor x in history:\n    train_loss.append(x[\"loss\"])\n    valid_loss.append(x[\"valid_loss\"])\n    valid_acr.append(x[\"valid_acr\"])\n    \ntrain_loss = [x.item() for x in train_loss]\nvalid_loss = [x.item() for x in valid_loss]\nvalid_acr = [x.item() for x in valid_acr]\nepochs = np.arange(no_epochs)","eb87dc27":"plt.plot(epochs, train_loss)\nplt.plot(epochs, valid_loss)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss of training and validation over iterations\")\nplt.legend([\"training\", \"validation\"])\nplt.show()","07529de7":"plt.plot(epochs, valid_acr)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Cross validation accuracy\")\nplt.show()","2112fb87":"import os\ntest_data = []\nfor i in os.listdir(TEST_PATH):\n    img = plt.imread(TEST_PATH + \"\/\" + i).copy()\n    test_data.append(transform(img))","0f3c913f":"test_ds = DataLoader(test_data, pin_memory=True, num_workers=8)\ntest_ds = GPUDataLoader(test_ds, device)\n\npredictions = []\ncount = 0\nfor img in test_ds:\n    scores = model(img)\n    _, prediction = torch.max(scores, dim=1)\n    predictions.append(prediction.to('cpu').numpy())\n    count += 1\n    if count == 8:\n        break\n    \npredicted_classes = [classes[x.item()] for x in predictions]\n\ncount = 0\nfor img in test_ds:\n    plt.imshow(img[0].to('cpu').permute(1, 2, 0))\n    plt.title(predicted_classes[count])\n    plt.axis(\"off\")\n    plt.show()\n    count += 1\n    if count == 8:\n        break","084a0434":"## Build the CNN model <a id='buildtheCNNmodel'><\/a>","28fa1b73":"The model is applied to test 8 random images of the prediction dataset.","fe48ee51":"## Load the dataset <a id='loadthedataset'><\/a>","74e28625":"## Visualize the images <a id='visualizetheimages'><\/a>","b2913497":"### Table of Contents\n1. [Import dependencies](#importdependencies) <a href = '#importdependencies'><\/a>\n2. [Load the dataset](#loadthedataset) <a href = '#loadthedataset'><\/a>\n3. [Explore the dataset](#explorethedataset) <a href = '#explorethedataset'><\/a>\n4. [Visualize the images](#visualizetheimage) <a href = '#visualizetheimage'><\/a>\n5. [Build the CNN model](#buildtheCNNmodel) <a href = '#buildtheCNNmodel'><\/a>\n    * 5.1. [Construct the model](#constructthemodel) <a href = '#constructthemodel'><\/a>\n    * 5.2. [Fit the model](#fitthemodel) <a href = '#fitthemodel'><\/a>\n6. [Visualize fitting steps](#visualizefittingsteps) <a href = '#visualizefittingsteps'><\/a>\n7. [Test the model](#testthemodel) <a href = '#testthemodel'><\/a>","328ff39d":"## Import dependencies <a id='importdependencies'><\/a>","30bf31a9":"The *history* is used to visualize the steps of the fitting process.","22cee52c":"In the fitting process of the model:\n* **Optimizer**: Adam optimizer.\n* **Loss function**: Cross entropy loss (quite similar to Softmax).\n* **Evaluation metric**: Accuracy suffices. The cross validation dataset is not skewed, so F-score is unnecessary.\n* **Number of epochs**: 10\n* **Fitting history**: After fitting, the *fit* function returns the history of the fitting process as a list of map.","98bcd479":"In this notebook, I have used PyTorch to build an image classification CNN model trained on the image dataset of Natural Scenes around the world.\n\nThis dataset contains around 25k images:\n* 14k images for training.\n* 3k images for cross validation.\n* 7k images for testing.\n\nEach image is 150x150 in size and distributed under 6 categories: **{\"buildings\": 0, \"forest\": 1, \"glacier\": 2, \"mountain\": 3, \"sea\": 4, \"street\": 5}**.","6d11a576":"### Visualize fitting steps <a id='visualizefittingsteps'><\/a>","c204c46f":"As I use SGD, each batch of any DataLoaders contains data of only 1 image.","14947f32":"# A simple Image Classification model with over 80% accuracy","e7085250":"### Fit the model <a id='fitthemodel'><\/a>","9000431d":"### Test the model <a id='testthemodel'><\/a>","da6cba90":"### Construct the model <a id='constructthemodel'><\/a>","3b45fa21":"The model comprises 4 main layers:\n* **Convolution layer**: kernel size = 3x3, padding = 1, stride = 1.\n* **Maxpooling layer**: kernel size = 2x2, stride = 2.\n* **Fully connected layer**: each with different number of neurons.\n* **Softmax layer**: to calculate the loss for minimization.\n\nand 2 supporting layers:\n* **ReLU layer**: an ReLU layer is placed behind any Convolution and FC layers.\n* **Flatten layer**: the Flatten layer is only used once to bridge the Convolution and FC layers.\n\nThe architecture of the model is based on **VGG19 architecture**. However, the depth of the model and the size of the FC layers are reduced.","2160b290":"## Explore the dataset <a id='explorethedataset'><\/a>"}}