{"cell_type":{"5b9a79e6":"code","d1289651":"code","5925f094":"code","9ec65ea4":"code","a421979b":"code","f83000ca":"code","c36d83d9":"code","ecaf4807":"code","5243ceb9":"code","6175e36c":"code","ff2e3898":"code","5e89bf91":"code","b94fa90a":"code","41bdcef0":"code","be351a72":"code","5727c8e0":"code","6da16549":"code","59fc7ba1":"code","288b8241":"code","bb4913cd":"code","65817711":"code","c46a9d72":"code","400c3efc":"code","e28a1f2f":"code","961c50d7":"code","8ede0c14":"code","e3c43a91":"code","305ae1e4":"code","f0a34472":"code","52b23d1f":"code","667ab794":"code","1ce967e7":"code","fc2a7ff6":"code","da843d8e":"code","c4675728":"code","97880fa8":"code","e6805be1":"markdown","d38852d3":"markdown","764f6fd4":"markdown","87ea5515":"markdown","fc63e632":"markdown","baf76e6e":"markdown","51ae4e15":"markdown","e543857f":"markdown","8bb5e946":"markdown","20740260":"markdown"},"source":{"5b9a79e6":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d1289651":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","5925f094":"train = pd.read_csv(\"\/kaggle\/input\/udacity-mlcharity-competition\/census.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/udacity-mlcharity-competition\/test_census.csv\")","9ec65ea4":"print(train.shape,submission.shape)","a421979b":"train.head()","f83000ca":"submission.head()","c36d83d9":"submission.drop(['Unnamed: 0'],axis=1,inplace=True) #Unnamed:0 if of no use. So drop it.","ecaf4807":"train.isna().sum()\/train.shape[0]*100","5243ceb9":"submission.isna().sum()\/submission.shape[0]*100","6175e36c":"submission.fillna(method='bfill',inplace=True) #using backward filling method.","ff2e3898":"train.head()","5e89bf91":"# Frequency of each category of every categorical or object type column.\nfor i in train.select_dtypes(['O']).columns:\n    print(\"*****************{0}****************\".format(i))\n    print(train[i].value_counts())","b94fa90a":"train.workclass = [i.strip() for i in train.workclass]\ntrain.education_level = [i.strip() for i in train.education_level]\ntrain['marital-status'] = [i.strip() for i in train['marital-status']]\ntrain.occupation = [i.strip() for i in train.occupation]\ntrain.relationship = [i.strip() for i in train.relationship]\ntrain.race = [i.strip() for i in train.race]\ntrain.sex = [i.strip() for i in train.sex]\ntrain['native-country'] = [i.strip() for i in train['native-country']]","41bdcef0":"submission.workclass = [i.strip() for i in submission.workclass]\nsubmission.education_level = [i.strip() for i in submission.education_level]\nsubmission['marital-status'] = [i.strip() for i in submission['marital-status']]\nsubmission.occupation = [i.strip() for i in submission.occupation]\nsubmission.relationship = [i.strip() for i in submission.relationship]\nsubmission.race = [i.strip() for i in submission.race]\nsubmission.sex = [i.strip() for i in submission.sex]\nsubmission['native-country'] = [i.strip() for i in submission['native-country']]","be351a72":"def stack_bar(df,x):\n    x_index = df[x].value_counts().index\n    income = []\n    income_label = []\n    for j in df['income'].value_counts().index:\n        income_label.append(j)\n        temp = []\n        for i in x_index:\n            try:\n                temp.append(df.groupby([x]).income.value_counts()[i][j])\n            except KeyError:\n                temp.append(0)\n        income.append(temp)\n    return income,x_index,income_label","5727c8e0":"cat_col = train.drop(['income'],axis=1).select_dtypes(['O']).columns\nfig,ax = plt.subplots(len(cat_col),1,figsize=(14,40),sharex=False,sharey=False)\nfor k,n in enumerate(cat_col):\n    income,x_index,income_label = stack_bar(train,n)\n    z=np.arange(len(income[0]))\n    t=np.array([i for i in range(1,len(income[0])+1)])\n    for i,j in enumerate(income):\n        ax[k-1].bar(height=j,x=z+t,label=income_label[i-1])\n        t=t+0.8\n    t=np.array([i for i in range(1,len(income[0])+1)])    \n    ax[k-1].set_xticks(t*2-0.5)\n    ax[k-1].set_xticklabels(x_index)\n    ax[k-1].legend(income_label)\n    ax[k-1].set_title(\"income Vs \"+n)\n    ax[k-1].tick_params('x',labelrotation=-60)\nfig.tight_layout()","6da16549":"train.head()","59fc7ba1":"#Create a single column.\n\ntrain['capital-net'] = train['capital-gain'] - train['capital-loss']\nsubmission['capital-net'] = submission['capital-gain'] - submission['capital-loss']","288b8241":"train['native-country'] = [i if i == \"United-States\" else \"other\" for i in train['native-country']] \n'''There are around 42K out of 45k observation having United-States in native-country columns. So we will assign rest of the categories as other'''                                                                                                    #United States \ntrain.race = [i if i in ['Black','White'] else \"Other\" for i in train.race] #Same for race column\ntrain.sex = [1 if i == \"Male\" else 0 for i in train.sex] #providing 0-1 to Male and Female","bb4913cd":"# Same on test data\nsubmission['native-country'] = [i if i == \"United-States\" else \"other\" for i in submission['native-country']]\nsubmission.race = [i if i in ['Black','White'] else \"Other\" for i in submission.race]\nsubmission.sex = [1 if i == \"Male\" else 0 for i in submission.sex]","65817711":"train['education_level'].replace({'Preschool':'Below_10th','1st-4th':'Below_10th','5th-6th':'Below_10th','9th':'Below_10th','7th-8th':'Below_10th',\n                                  '10th':'Below_10th','11th':'Above_10th','12th':'Above_10th'},inplace=True)","c46a9d72":"submission['education_level'].replace({'Preschool':'Below_10th','1st-4th':'Below_10th','5th-6th':'Below_10th','9th':'Below_10th','7th-8th':'Below_10th',\n                                '10th':'Below_10th','11th':'Above_10th','12th':'Above_10th'},inplace=True)","400c3efc":"'''As income is our target column and we already created a single column using capital-loss and gain so we are temporarily droping them and droping \nduplicates on the basis of rest of the columns'''\n\ntrain.drop_duplicates(subset=train.drop(['income','capital-gain','capital-loss'],axis=1).columns,inplace=True)","e28a1f2f":"#creating training features and target variable.\n\nfeature = train.drop(['capital-gain','capital-loss'],axis=1).select_dtypes(exclude=['O']).join(pd.get_dummies(train.drop(['income'],axis=1).select_dtypes(['O'])))\ntarget = train.income","961c50d7":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score,accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB","8ede0c14":"X_train, X_test, y_train, y_test = train_test_split(feature,target,test_size=0.2,random_state=42)","e3c43a91":"models = [LGBMClassifier(random_state=42),XGBClassifier(random_state=42),DecisionTreeClassifier(random_state=42),LogisticRegression(random_state=42)]\nmodel_roc_score = []\nfor i in models:\n    dtc=i\n    dtc.fit(X_train,y_train)\n    #print(\"-------------Accuracy Score-----------------\\n\",accuracy_score(y_test,dtc.predict(X_test)))\n    #print(\"-------------AUC-ROC Score-----------------\\n\",roc_auc_score(np.array([0 if i == '<=50K' else 1 for i in y_test]).reshape(-1,1),dtc.predict_proba(X_test)[:,1]))\n    model_roc_score.append(roc_auc_score(np.array([0 if i == '<=50K' else 1 for i in y_test]).reshape(-1,1),dtc.predict_proba(X_test)[:,1]))","305ae1e4":"model_score = pd.DataFrame({'Models':models,'ROC_AUC':model_roc_score})\ncolor_high = ['yellow' if i == model_score.ROC_AUC.max() else \"black\" for i in model_score.ROC_AUC]\ndef highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]\nmodel_score.style.apply(highlight_max,subset=['ROC_AUC'])","f0a34472":"dtc=LGBMClassifier(random_state=42)\ndtc.fit(X_train,y_train)\nprint(\"-------------Accuracy Score-----------------\\n\",accuracy_score(y_test,dtc.predict(X_test)))\nprint(\"-------------AUC-ROC Score-----------------\\n\",roc_auc_score(np.array([0 if i == '<=50K' else 1 for i in y_test]).reshape(-1,1),dtc.predict_proba(X_test)[:,1]))","52b23d1f":"test_feature = submission.drop(['capital-gain','capital-loss'],axis=1).select_dtypes(exclude=['O']).join(pd.get_dummies(submission.select_dtypes(['O'])))","667ab794":"predict_prob = dtc.predict_proba(test_feature)","1ce967e7":"submis = pd.read_csv(\"\/kaggle\/input\/udacity-mlcharity-competition\/example_submission.csv\")","fc2a7ff6":"submis.head()","da843d8e":"submis.income = predict_prob[:,1]","c4675728":"submis.head()","97880fa8":"submis.to_csv(\"udacity_income_lgbm_random.csv\",index=False)","e6805be1":"# Data Pre-Processing and Feature Engineering","d38852d3":"# Thank You!!","764f6fd4":"# Make Submission","87ea5515":"<h2>Bar chart of every categorical columns w.r.t income column<\/h2>","fc63e632":"<h1 style=\"color:skyblue;\">Now Let's Move Towards EDA Part<\/h1>","baf76e6e":"**As LGBM gave the best score so we will create our final model using LGBMClassifier**","51ae4e15":"<h3>There is no NaN value in train while there is very very less percentage of NaN value in test data. So we will going to replace these NaN values in test data.<\/h3>","e543857f":"# Model Building","8bb5e946":"<h1 style=\"text-align:center;color:blue;\">About The Competition<\/h1>\n\n<h2>This notebook is related to Udacity ML Charity Competition.<\/h2>\n\n# Agenda\n\n---> Will do some EDA\n\n---> Feature Engineering \n\n---> Model Building\n\n\n**Evaluation will be done using ROC_AUC_Score on test_census data.**","20740260":"# NaN Values Percentage In Each Train and submission data"}}