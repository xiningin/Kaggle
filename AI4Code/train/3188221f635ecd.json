{"cell_type":{"22d1fc5f":"code","401b4674":"code","311d84ee":"code","3270c11d":"code","39eed947":"code","cb180ed2":"code","16696143":"code","d44f8480":"code","31735d00":"code","9dcd82fe":"code","1bc0ceaa":"code","de19d9c7":"code","c74dd9ae":"code","6863422d":"code","305113e7":"code","33395f65":"code","49e02ab0":"code","bd113ed7":"code","57d40963":"code","44b0cae5":"code","5bc43771":"code","2dc9d7e3":"code","0b16a2e9":"code","90a8762b":"code","db4a8069":"code","2956e8cc":"code","7733e409":"code","d04e24ca":"code","625a1999":"code","009ad82c":"code","53b8f7ef":"code","22ee6aa3":"code","f66fcefd":"code","696a9d6d":"code","7714d217":"code","7f5321f8":"code","bf31bc39":"code","07357f15":"code","e652009e":"code","cf071780":"code","aa4e0816":"code","e4021764":"code","46a2f5ad":"code","d0bf2107":"code","b7d2f68b":"code","57e14492":"markdown","636cd44a":"markdown","919a62e5":"markdown","2bff1a94":"markdown","1da7c911":"markdown","5f433979":"markdown","31deb8b9":"markdown","776df45c":"markdown","710b8253":"markdown","1a3da4bc":"markdown","8382f966":"markdown","fdff14e0":"markdown","8d792d5d":"markdown","c36f92e1":"markdown","f4165bec":"markdown"},"source":{"22d1fc5f":"# importing the libaries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nimport re\nimport string","401b4674":"# importing the dataset\nfake_new = pd.read_csv(r\"..\/input\/fake-news-detection\/Fake.csv\")\ntrue_new = pd.read_csv(r\"..\/input\/fake-news-detection\/True.csv\")\n\n# showing the imported data\nfake_new.head()","311d84ee":"true_new.head()","3270c11d":"fake_new[\"class\"] = 0\ntrue_new[\"class\"] = 1","39eed947":"fake_new.shape, true_new.shape","cb180ed2":"# Removing the last 20 rows for manual testing\nfake_new_manual = fake_new.tail(20)\nfor i in range(23480,23460,-1):\n    fake_new.drop([i], axis=0, inplace=True)\n    \ntrue_new_manual = true_new.tail(20)\nfor i in range(21416,21396,-1):\n    true_new.drop([i], axis=0, inplace=True)","16696143":"fake_new.shape, true_new.shape","d44f8480":"fake_new_manual[\"class\"] = 0\ntrue_new_manual[\"class\"] = 1","31735d00":"true_new_manual.head(10)","9dcd82fe":"fake_new_manual.head(10)","1bc0ceaa":"# merging the two fake_new_manual and true_new_manual\n\nmanual_testing = pd.concat([fake_new_manual, true_new_manual], axis=0)\n\n# saving it as a csv file\nmanual_testing.to_csv(\"manual_testing.csv\")","de19d9c7":"merge_news = pd.concat([fake_new, true_new], axis=0)\n\nmerge_news.head(10)","c74dd9ae":"merge_news.columns","6863422d":"news = merge_news.drop([\"title\",\"subject\",\"date\"], axis=1)","305113e7":"news.isnull().sum()","33395f65":"news = news.sample(frac = 1)","49e02ab0":"news.head()","bd113ed7":"# reseting the indexing and droping the old column\nnews.reset_index(inplace=True)\nnews.drop([\"index\"], axis=1, inplace=True)","57d40963":"news.head()","44b0cae5":"# function to process the text\n\ndef wordopt(text):\n    text = text.lower()\n    text = re.sub(\"\\[.*?\\]\", \"\", text)\n    text = re.sub(\"\\\\W\", \" \", text)\n    text = re.sub(\"https?:\/\/\\S+|www\\.\\S+\", \"\", text)\n    text = re.sub(\"<.*?>+\", \"\", text)\n    text = re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)\n    text = re.sub(\"\\n\", \"\", text)\n    text = re.sub(\"\\w*\\d\\w*\", \"\", text)\n    return text","5bc43771":"# Applying the function \"wordopt\" to \"text\"\n\nnews[\"text\"] = news[\"text\"].apply(wordopt)","2dc9d7e3":"x = news[\"text\"]\ny = news[\"class\"]","0b16a2e9":"x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.25, random_state=100)","90a8762b":"# The variable test is a string - the model needs a feature vector with the same number of dimensions as X. \n# You have to transform the test string to a feature vector using the same vectorizer instance,\n# before you feed it to the model:\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvec = TfidfVectorizer()\nxv_train = vec.fit_transform(x_train)\nxv_test = vec.transform(x_test)","db4a8069":"from sklearn.linear_model import LogisticRegression\n\nLr = LogisticRegression()\n\n# fit \nLr.fit(xv_train,y_train)","2956e8cc":"# predict the model\npred_lr = Lr.predict(xv_test)","7733e409":"Lr.score(xv_test, y_test)","d04e24ca":"print(classification_report(y_test, pred_lr))","625a1999":"from sklearn.tree import DecisionTreeClassifier\n\nDT = DecisionTreeClassifier()\n\n#fit\nDT.fit(xv_train,y_train)","009ad82c":"# predict\npred_DT = DT.predict(xv_test)","53b8f7ef":"DT.score(xv_test, y_test)","22ee6aa3":"print(classification_report(y_test, pred_DT))","f66fcefd":"from sklearn.ensemble import GradientBoostingClassifier\n\nGB = GradientBoostingClassifier(random_state=0)\n\n# fit\nGB.fit(xv_train, y_train)","696a9d6d":"# predict\npred_GB = GB.predict(xv_test)","7714d217":"GB.score(xv_test,y_test)","7f5321f8":"print(classification_report(y_test, pred_GB))","bf31bc39":"from sklearn.ensemble import RandomForestClassifier\n\nRF = RandomForestClassifier()\nRF.fit(xv_train,y_train)","07357f15":"# predict\npred_RF = RF.predict(xv_test)","e652009e":"RF.score(xv_test,y_test)","cf071780":"print(classification_report(y_test,pred_RF))","aa4e0816":"def output_label(n):\n    if n == 0:\n        return \"Fake News\"\n    elif n == 1:\n        return \"Not A Fake News\"\n    \ndef manual_testing(news):\n    testing_news = {\"text\":[news]}\n    new_def_test = pd.DataFrame(testing_news)\n    new_def_test[\"text\"] = new_def_test[\"text\"].apply(wordopt)\n    new_x_test = new_def_test[\"text\"]\n    new_xv_test = vec.transform(new_x_test)\n    pred_LR = Lr.predict(new_xv_test)\n    pred_DT = DT.predict(new_xv_test)\n    pred_GB = GB.predict(new_xv_test)\n    pred_RF = RF.predict(new_xv_test)\n    \n    \n    return print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nGB Prediction: {} \\nRF Prediction: {}\".format(output_label\n                                                                                                            (pred_LR[0]),\n                                                                                                           output_label\n                                                                                                            (pred_DT[0]),\n                                                                                                           output_label\n                                                                                                            (pred_GB[0]),\n                                                                                                           output_label\n                                                                                                            (pred_RF[0])))\n    \n    \n    ","e4021764":"news = str(input())\nmanual_testing(news)","46a2f5ad":"news = str(input())\nmanual_testing(news)","d0bf2107":"news = str(input())\nmanual_testing(news)","b7d2f68b":"news = str(input())\nmanual_testing(news)","57e14492":"### Processing The Text","636cd44a":"#### Random Forest Classifier","919a62e5":"#### Defining independent variable","2bff1a94":"### Merging the True and Fake dataframe","1da7c911":"#### Gradient Booster Classifer","5f433979":"Removing columns that are not required ","31deb8b9":"This Model would be able to determine fake news from real news given the dataset","776df45c":"#### Decision Tree","710b8253":"##### Randomly shuffling the dataframe","1a3da4bc":"##### Logistic Regression","8382f966":"#### Model Testing\n","fdff14e0":"#### splitting Training and Testing","8d792d5d":"### Modelling","c36f92e1":"#### Converting text to Vectors","f4165bec":"#### Inserting another column \"Class\" as true or fake(0 or 1)"}}