{"cell_type":{"37e30726":"code","695048eb":"code","faf4235e":"code","73330bf9":"code","c428dbb3":"code","0e3710f4":"code","eeb18e1f":"code","11d2dd3c":"code","c92372ba":"code","46cfab85":"code","f761bca2":"code","305e90bf":"code","1f548449":"code","c066ec43":"code","60a6df90":"code","67341a74":"code","58ab1905":"code","86c68ee2":"code","7e9c38fe":"code","9ad31db0":"code","42e1faf4":"code","ddd68dc6":"code","ea78211a":"code","41f7a322":"markdown"},"source":{"37e30726":"# Install umap\n!pip install umap\n!pip install umap-learn[plot]","695048eb":"#Call data manipulation libraries\nimport pandas as pd\nimport numpy as np\n\n## Data preprocessing\n# Scaling data in various manner\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom sklearn.pipeline import make_pipeline\n## Manifolds\nfrom sklearn.manifold import TSNE\n#from umap import UMAP\n#import umap.plot\nimport umap\n\nfrom sklearn.ensemble import  RandomForestClassifier\nfrom sklearn.metrics import log_loss\n# Misc\/visualization\nimport os, time, gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns","faf4235e":"#Display multiple commands output from a cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","73330bf9":"#Set datafile path\n#path = \"\/content\/\"\n#os.chdir(path)\n#Read train file\ntrain = pd.read_csv(\"..\/input\/kannadamnistt\/train.csv\/train.csv\")","c428dbb3":"#Look at data\ntrain.shape                        #(60000, 785)\nprint()\ntrain.head()\nprint()\ntrain.dtypes.value_counts()        # All features are integers including target","0e3710f4":"# Target classes--absolute vs normalized\ntrain.label.value_counts()   #data is uniformaly distributed with target\nprint(\"\\n\\n--Normalized data--\\n\")\ntrain.label.value_counts(normalize=True)","eeb18e1f":"# Check if there are Missing\/duplicate values? None\ntrain.isnull().sum()            # None\ntrain.isnull().sum().sum()      # None\ntrain.duplicated().sum()        # None","11d2dd3c":"# Drop 'label' and save label column in another variable called y\ny = train.pop('label')   # Target","c92372ba":"train.shape #finding the shape of train data set after removing target variable.","46cfab85":"# Describing the train data set.\ntrain.describe()","f761bca2":"# Reduce Memory usage\nprint(\"--Current memory usage (MB) --\\n\")\ntrain.memory_usage().sum()\/1000000  # 376MB\n\nprint(\"\\n\\n--Max and min values---\\n\")\ntrain.max().max()               # 255\nprint()\ntrain.min().min()               # 0\n\n#Change dtype\ntrain = train.astype('uint16')\n\nprint(\"\\n\\n--Revised memory usage (MB) --\\n\")\ntrain.memory_usage().sum()\/1000000  # 94MB","305e90bf":"#Encode labels. We have 10 target levels\nle = LabelEncoder()\ny = le.fit_transform(y)","1f548449":"#Standardize dataset\nss = StandardScaler()\nX = ss.fit_transform(train)","c066ec43":"# As t-sne on full dataset may take a longtime,\n# we intend to take a sample of it. But sampling\n# must be stratified. So, for the purpose of taking a \n# stratified sample, we use StratifiedShuffleSplit\n\nsss =  StratifiedShuffleSplit(\n                              n_splits = 1,     # Need only 1-pair of splits\n                              test_size = 30000\n                              )\n\ntype(sss)             # StratifiedShuffleSplit\nprint()\ntype(sss.split(X,y))  # Generator\n\n# Now get indicies of our data points: \nfor train_index, test_index in sss.split(X, y):\n    X_train = X[train_index,:]\n    y_train = y[train_index]","60a6df90":"# Using PCA with 2 components and visualizing the components\n\npca1 = PCA(n_components=2)   # 2 components\npc = pca1.fit_transform(train)\npc.shape","67341a74":"pca_df = pd.DataFrame(data = pc, columns = ['pca1', 'pca2'])","58ab1905":"print('Explained variation per principal component: {}'.format(pca1.explained_variance_ratio_))","86c68ee2":"fig = plt.figure(figsize = (16,10))\nplt.scatter(pc[:, 0], pc[:, 1], s= 5,c= y, cmap='Spectral')\nplt.gca().set_aspect('equal', 'datalim')\nplt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\nplt.title('Kannada MNIST using PCA', fontsize=20);\nplt.xlabel('PCA1')\nplt.ylabel('PCA2')\nplt.figure(figsize=(60,40))","7e9c38fe":"# Use PCA to remove noise and also to slightly reduce data dimensions\n# dimention reduced to 409\npca = PCA(n_components=0.95)   # Explain 95% variance\nXf = pca.fit_transform(X_train)\nXf.shape","9ad31db0":"# Perform t-sne now.\n\nstart = time.time()\ntsne = TSNE(\n            perplexity = 40,  \n            n_jobs = 2,\n            n_iter=500,\n            verbose =1\n            )\n#Fit and transform dataset to 2D\nres = tsne.fit_transform(Xf)\nend = time.time()\n(end - start)\/60","42e1faf4":"#Plot the t-sne results \nres = pd.DataFrame(res, columns= ['x','y'])\nfig = plt.figure(figsize = (16,10))\n_=sns.scatterplot(data=res, x='x', y='y', hue=y_train, palette='tab20')","ddd68dc6":"# We will perform umap on the Xf dataset which is reduced dimentionality on original data using PCA.\nimport umap.umap_ as umap\nstart = time.time()\nmapper = umap.UMAP(\n                    n_epochs = 200,\n                    verbose = True  \n                   ).fit(Xf)       # Instantiation and fitting\nembedding =  mapper.transform(Xf)  # Data transformation\n#mapper = umap.UMAP()\n#embedding = mapper.fit_transform(Xf)\nend = time.time()\n(end-start)\/60   # 3 minutes","ea78211a":"#Plot the UMAP result\n\nembedding = pd.DataFrame(embedding, columns= ['x','y'])\nfig = plt.figure(figsize = (16,10))\n_=sns.scatterplot(\n                   data=embedding,\n                   x='x',\n                   y='y',\n                   hue=y_train,          # Else use y_train\n                   palette='tab20')","41f7a322":"**1. Do tsne and umap display clear structure in the data? \n    \n    Yes both t-sne and UMAP display clear structure in this data set. but, UMAP is more clear and         seperable than t-sne.\n    \n2. Do you think an algorithm intended to predict the digit value should have high performance? or low    performance?\n    \n    Algorithm intended to predict the digits value should have high performance.**"}}