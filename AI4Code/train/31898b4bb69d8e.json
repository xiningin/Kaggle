{"cell_type":{"9fe3b647":"code","4fb2c33f":"code","f9efb0a8":"code","4fc4cbc4":"code","1f772d9b":"code","837cdb0b":"code","ac09a35d":"code","cfd2e1b2":"code","c823c395":"code","cf0654d1":"code","bef85f0c":"code","11c98c10":"code","e5c149c9":"code","73bad076":"code","57ba8240":"code","690dd975":"code","411a13c5":"code","bd898011":"code","e807c7b8":"code","00ba9eb0":"markdown","e5641458":"markdown","22a5badd":"markdown","81cd9493":"markdown","e712152d":"markdown","2c53f8bb":"markdown","a692d2ab":"markdown","920c46af":"markdown","a3fb802f":"markdown"},"source":{"9fe3b647":"lazy_submit = False # set to False to train, set False to use the stored trained weights\nCOLAB = False","4fb2c33f":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.random import set_seed\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nimport os\nimport gc\nimport cv2\nfrom tqdm import tqdm\nimport seaborn as sns\nimport tensorflow_addons as tfa\nimport math\nimport xgboost as xgb\nimport optuna\nfrom optuna.integration import XGBoostPruningCallback\nfrom optuna.samplers import TPESampler\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nimport json\nimport pickle","f9efb0a8":"print(tf. __version__)","4fc4cbc4":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n  tf.config.experimental.set_memory_growth(gpu, True)\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" ","1f772d9b":"SEED = 42\nnp.random.seed(SEED)\nset_seed(SEED)\n\nIMAGE_SIZE = (224, 224)\n\nBATCH_SIZE = 32\nEPOCHS = 10\nFOLDS = 5\nMULTIVARIATE = True\n\nif COLAB:\n  from google.colab import drive\n  drive.mount('\/content\/gdrive')\n  datapath = \"gdrive\/MyDrive\/PAWPULARITY\"\nelse:\n  datapath  = \"..\"\n\nINPUT_DIR = os.path.join(datapath, \"input\")\nOUTPUT_DIR = os.path.join(datapath, \"working\")\nTRAIN_IMAGES_DIR = os.path.join(INPUT_DIR, \"petfinder-pawpularity-score\", 'train')\nTRAIN_DS = os.path.join(INPUT_DIR, \"petfinder-pawpularity-score\", 'train.csv')\nTEST_IMAGES_DIR = os.path.join(INPUT_DIR, \"petfinder-pawpularity-score\", 'test')\nTEST_DS = os.path.join(INPUT_DIR, \"petfinder-pawpularity-score\", 'test.csv')\nSUBMISSION_DS = os.path.join(INPUT_DIR, \"petfinder-pawpularity-score\", 'sample_submission.csv')\n\nif lazy_submit:\n    TRAINED_WEIGHTS_DIR = os.path.join(INPUT_DIR,  'weights-pawpularity')\nelse: \n    TRAINED_WEIGHTS_DIR = OUTPUT_DIR\n    \nweights =  os.path.join(INPUT_DIR, \"efficientnet-noisy-student-b0\", \"efficientnetb0_noisy_student_notop.h5\")","837cdb0b":"!nvidia-smi","ac09a35d":"train_ds = pd.read_csv(TRAIN_DS)\ntrain_ds['Pawpularity'] = train_ds['Pawpularity']\/100.0\ntest_ds = pd.read_csv(TEST_DS)\nsubm_ds = pd.read_csv(SUBMISSION_DS)\nmeta_cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', \n             'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\ntrain_ds.shape","cfd2e1b2":"grouped = train_ds.copy()\ngrouped[\"cuts\"] = pd.cut(train_ds[\"Pawpularity\"], bins = np.arange(0, 1.1, 0.1),labels= np.round(np.arange(0, 1, 0.1), 1))\ngrouped = grouped.drop(\"Id\", axis = 1).groupby(\"cuts\").mean()\nfig,ax = plt.subplots(6, 2, sharex = False, sharey = True, figsize = (14, 16))\ncol = 0\nfor i in range(6):\n    for j in range(2):\n        sns.barplot(ax = ax[i, j], x = meta_cols[col], y = \"cuts\",  data = grouped[meta_cols].reset_index())\n        col += 1\nplt.tight_layout()\nplt.show()","c823c395":"plt.figure(figsize = (10, 8))\nsns.heatmap(grouped.corr())","cf0654d1":"plt.figure(figsize = (10, 8))\nsns.clustermap(grouped.corr())","bef85f0c":"img = keras.preprocessing.image.load_img(\"..\/input\/petfinder-pawpularity-score\/train\/00524dbf2637a80cbc80f70d3ff59616.jpg\")\nimg = keras.preprocessing.image.img_to_array(img) \/ 255.0\nimg.shape","11c98c10":"plt.imshow(img)","e5c149c9":"class CustomDataGen(tf.keras.utils.Sequence):\n    \n    def __init__(self, df, img_dir, \n                 batch_size, tab_columns,\n                 id, target, is_train,\n                 input_size = (224, 224),\n                 shuffle = True):\n        \n        self.df = df.copy()\n        self.img_dir = img_dir\n        self.batch_size = batch_size\n        self.input_size = input_size\n        self.shuffle = shuffle    \n        self.n = len(self.df)\n        self.tab_columns = tab_columns\n        self.target = target\n        self.id = id\n        self.is_train = is_train\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.ceil(len(self.df) \/ float(self.batch_size)))\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n\n    def __getitem__(self, index):\n        this_ds = self.df.iloc[index*self.batch_size:(index+1)*self.batch_size]\n        images = []\n        for img_id in list(this_ds[self.id].values):\n            img = cv2.imread(f\"{self.img_dir}\/{img_id}.jpg\")\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, IMAGE_SIZE, interpolation=cv2.INTER_LINEAR)\n            img = np.array(img, dtype='float32') \n            # .\/ 255.0 EfficientNet models expect their inputs to be float tensors of pixels with values in the [0-255] range\n            images.append(img)\n        if self.is_train:\n            return [np.array(images), this_ds[self.tab_columns].values],this_ds[self.target].values\n        else:\n            return [np.array(images), this_ds[self.tab_columns].values]\n        \n\ndef get_intermediate_layer_output(model, x_train):\n    intermediate_layer_model = keras.Model(inputs=model.input,\n                                 outputs=model.layers[-3].output)\n    intermediate_output = intermediate_layer_model.predict(x_train, verbose = 1) \n    return pd.DataFrame(data=intermediate_output)\n\n\ndef run(trial, xtrain, xval, ytrain, yval):\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n    max_depth = trial.suggest_int(\"max_depth\", 1, 12)\n    \n    pruning_callback = XGBoostPruningCallback(trial, \"validation_0-rmse\")\n\n    model = XGBRegressor(\n        objective =\"reg:logistic\",\n        random_state = SEED,\n        tree_method=\"gpu_hist\",\n        n_estimators= 3000,\n        predictor=\"gpu_predictor\",\n        learning_rate=learning_rate,\n        reg_lambda=reg_lambda,\n        reg_alpha=reg_alpha,\n        subsample=subsample,\n        colsample_bytree=colsample_bytree,\n        max_depth=max_depth)\n\n    model.fit(xtrain,ytrain, \n             early_stopping_rounds= 100, \n             eval_set= [(xval, yval)],\n             callbacks = [pruning_callback],\n             eval_metric='rmse', verbose = True)\n             \n    preds_valid = model.predict(xval)\n    rmse = mean_squared_error(yval, preds_valid, squared=False)\n    return rmse","73bad076":"NCOL = len(meta_cols)\nINPUT_SHAPE = (*IMAGE_SIZE, 3)\n\n\nclass CosineAnnealingStairCase(tf.keras.callbacks.Callback):\n    def __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n        self.epochs = n_epochs\n        self.cycles = n_cycles\n        self.lr_max = lrate_max\n        self.lrates = list()\n        self.best = 1000\n        self.log = -1000\n        self.rate = 1\n\n    def cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max, rate):\n        epochs_per_cycle = math.floor(n_epochs\/n_cycles)\n        cos_inner = (math.pi * (epoch % epochs_per_cycle)) \/ (epochs_per_cycle) \n        return lrate_max\/2 * (math.cos(cos_inner) + 1) \/ rate\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if self.log > self.best:\n            self.rate  *= 1.5\n        lr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max, self.rate)\n        print(f'Learning rate: {lr}')\n        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n        \n    def on_epoch_end(self, epoch, logs = {}):\n        self.log = logs['val_root_mean_squared_error'] \n        if self.log < self.best:\n            self.best = self.log\n\n\ndef create_model():\n\n    CONV_KERNEL_INITIALIZER = {\n    'class_name': 'VarianceScaling',\n    'config': {\n        'scale': 2.0,\n        'mode': 'fan_out',\n        'distribution': 'normal'\n        }\n    }\n\n    conv_base = tf.keras.applications.efficientnet.EfficientNetB0(\n        weights = weights,\n        include_top = False,\n        input_tensor=keras.Input(shape = INPUT_SHAPE))\n\n    conv_base.trainable = False\n\n    data_augmentation = tf.keras.Sequential([\n            tf.keras.layers.experimental.preprocessing.RandomContrast(0.2, seed = SEED),\n            tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", seed = SEED),\n            tf.keras.layers.experimental.preprocessing.RandomRotation(0.2, seed = SEED),\n            tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor = 0.1, width_factor = 0.1, seed = SEED)\n            #tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3),  seed=SEED),\n        ])\n    \n    def conv2d_block(mod, filters):\n        out = layers.Conv2D(filters, kernel_size  = (1, 1),\n                          padding='same',\n                          kernel_initializer = CONV_KERNEL_INITIALIZER)(mod)\n        out = layers.BatchNormalization()(out)\n        out = layers.Activation(\"swish\")(out)\n        return out\n\n    inp = tf.keras.Input(shape=INPUT_SHAPE)\n    out = data_augmentation(inp)\n    out = conv_base(out)\n    out = conv2d_block(out, 640)\n    out = conv2d_block(out, 320)\n    out = conv2d_block(out, 128)\n    out = layers.GlobalAveragePooling2D()(out)\n    out = layers.BatchNormalization()(out)\n    out = layers.Dropout(0.1)(out) \n\n    meta_input = keras.Input(shape = (NCOL,))\n    concat = layers.Concatenate(axis = 1)([out, meta_input])\n    concat = layers.Dense(64)(concat) \n    concat = layers.PReLU()(concat)\n    concat = layers.Dropout(0.1)(concat) \n    concat = layers.Dense(1, activation = \"sigmoid\")(concat)\n    model = tf.keras.Model([inp, meta_input], concat)\n\n    return model","57ba8240":"#check_model = create_model()\n#check_model.compile()\n#check_model.summary()","690dd975":"#tf.keras.utils.plot_model(check_model, show_shapes=True)","411a13c5":"kf = KFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n\ndef train():\n   \n    nn_models = []\n    xgb_models = []\n    histories = []\n    rmse_out = 0\n    for idx, (train_idx, val_idx) in enumerate(kf.split(train_ds)):\n        \n        print(f'\\n----- RUN: {idx} ------')\n        tf.keras.backend.clear_session()\n        gc.collect()\n        \n        params = dict(batch_size=32, tab_columns=meta_cols, id=\"Id\", target=\"Pawpularity\", is_train = True)\n        train_gen = CustomDataGen(img_dir = TRAIN_IMAGES_DIR, df=train_ds.copy().iloc[train_idx], **params)\n        val_gen = CustomDataGen(img_dir = TRAIN_IMAGES_DIR, df=train_ds.copy().iloc[val_idx], **params)\n        \n        optimizer = tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-4)\n\n        es = tf.keras.callbacks.EarlyStopping(\n            monitor='val_root_mean_squared_error', patience=3)\n        \n        ca = CosineAnnealingStairCase(EPOCHS, 1, 1e-3)\n        \n        checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(OUTPUT_DIR, f'efficientnetb0_{idx}.h5'), \n                                                    monitor='val_root_mean_squared_error', verbose = 1, \n                                                    save_best_only=True, mode='min', save_weights_only = True)\n        \n        rmse = tf.keras.metrics.RootMeanSquaredError()\n\n        model = create_model()\n        model.compile(loss = \"binary_crossentropy\", \n            optimizer = optimizer,\n            metrics=[rmse])\n\n        history = model.fit(train_gen,\n                            validation_data = val_gen,\n                            epochs = EPOCHS, \n                            callbacks = [checkpoint, es, ca],\n                            max_queue_size = 3 * BATCH_SIZE)\n               \n        nn_models.append(model)\n        histories.append(history.history)\n        \n        params = dict(batch_size=32, tab_columns=meta_cols, id=\"Id\", target=\"Pawpularity\", is_train = True, shuffle = False)\n        train_gen = CustomDataGen(img_dir = TRAIN_IMAGES_DIR, df=train_ds.iloc[train_idx], **params)\n        val_gen = CustomDataGen(img_dir = TRAIN_IMAGES_DIR, df=train_ds.iloc[val_idx], **params)\n        x_train = get_intermediate_layer_output(nn_models[idx], train_gen)\n        x_val = get_intermediate_layer_output(nn_models[idx], val_gen)\n        \n        sampler = TPESampler(seed=SEED, multivariate=MULTIVARIATE)\n        study = optuna.create_study(direction=\"minimize\", sampler = sampler)\n        study.optimize(lambda trial: run(trial, x_train, x_val, train_ds.iloc[train_idx].loc[:, 'Pawpularity'], train_ds.iloc[val_idx].loc[:, 'Pawpularity']), n_trials=100)\n        best = study.best_params\n        with open(os.path.join(OUTPUT_DIR, f'best_{idx}.json'), 'w') as f:\n            json.dump(best, f)\n        print(best)\n        \n        model = XGBRegressor(\n        objective=\"reg:logistic\",\n        random_state=42,\n        n_estimators= 5000,\n        **best)\n\n        model.fit(x_train,  train_ds.iloc[train_idx].loc[:, 'Pawpularity'], \n                    early_stopping_rounds= 100, \n                    eval_set= [(x_val, train_ds.iloc[val_idx].loc[:, 'Pawpularity'])],\n                    eval_metric='rmse', verbose = True)\n\n        preds_valid = model.predict(x_val)\n        rmse = mean_squared_error(train_ds.iloc[val_idx].loc[:, 'Pawpularity'], preds_valid, squared=False)\n        rmse_out += rmse\n        print('RMSE: ', rmse)\n\n        with open(os.path.join(OUTPUT_DIR, f'model_xgb_{idx}.pkl'), 'wb') as f:\n            pickle.dump(model, f)\n        xgb_models.append(model)\n    \n        gc.collect()\n        \n    return nn_models,xgb_models, histories, rmse_out \/ FOLDS","bd898011":"if not lazy_submit:\n    nn_models,xgb_models, histories, rmse  = train()\n    evals = np.mean([np.min(histories[i]['val_root_mean_squared_error']) for i in range(FOLDS)])\n    \n    fig,ax = plt.subplots(3,2)\n    for i in range(FOLDS):\n        ax = ax.flatten()\n        ax[i].plot(histories[i]['loss'], label= 'loss')\n        ax[i].plot(histories[i]['val_loss'], label = 'val_loss')\n        ax[i].legend()\n    plt.show()\n    \n    evals\n    \nelse:\n    models = []\n    evals = 0\n    for idx, (train_idx, val_idx) in enumerate(kf.split(train_ds)):\n        params = dict(img_dir=TRAIN_IMAGES_DIR, batch_size=BATCH_SIZE, tab_columns=meta_cols, id=\"Id\", target=\"Pawpularity\", is_train = True, shuffle  = False)\n        val_gen = CustomDataGen(df=train_ds.iloc[val_idx], **params)\n        model = get_model()\n        model.load_weights(os.path.join(TRAINED_WEIGHTS_DIR, f'efficientnetb0_{idx}.h5'))\n        models.append(model)\n        evals += model.evaluate(val_gen, \n                                    max_queue_size = 3 * BATCH_SIZE)[1] \n    evals \/= FOLDS\n\nprint(\"AVG RMSE NN: \", evals)\nprint(\"AVG RMSE XGB: \", rmse)","e807c7b8":"predictions = []\nparams = dict(img_dir = TEST_IMAGES_DIR, batch_size = BATCH_SIZE, tab_columns = meta_cols, id = \"Id\", target = \"Pawpularity\", is_train = False, shuffle = False)\ntest_gen = CustomDataGen(df = test_ds, **params)\n\nfor i in tqdm(range(FOLDS)):\n    x_val = get_intermediate_layer_output(nn_models[i], test_gen)\n    predictions.append(xgb_models[i].predict(test_gen))\n    \nsubm_ds[\"Pawpularity\"] =  100 * np.array(predictions).mean(axis = 0)\nsubm_ds.to_csv(\"submission.csv\", index = False)","00ba9eb0":"subm_ds.head()","e5641458":"# Exploratory analysis","22a5badd":"## Build the model","81cd9493":"## Useful functions","e712152d":"# Submission","2c53f8bb":"# [TF] Pawpularity EfficientNetB0 + metadata ensamble \ud83d\ude3a \ud83d\udc36","a692d2ab":"# Description of the notebook:\n\n- The architecture aims to model images and tabular data\n- The base model used for images is EfficientNet b0 with noisy student weights\n- Trained with AdamW + cosine decay \n- Performed an ensamble using 5-fold CV","920c46af":"![](https:\/\/www.petfinder.my\/images\/cuteness_meter.jpg)","a3fb802f":"## Train the model"}}