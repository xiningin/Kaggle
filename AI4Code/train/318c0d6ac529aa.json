{"cell_type":{"4cc30d99":"code","cef28621":"code","de155515":"code","913a586e":"code","9292fa85":"code","9ba7c99f":"code","7ff443ab":"code","b3c082c2":"code","233ce66e":"code","c9f8c7af":"code","273531bb":"code","324e83d4":"code","85d85dfd":"code","c3a07408":"code","294e6bab":"code","3ea56b5f":"code","aa6ce405":"code","a58c8b96":"code","be4b1f67":"code","e888828a":"code","fb3548a1":"code","d5545c61":"code","c7638def":"code","79498dab":"code","82b7c6ff":"code","a1df3608":"markdown","118deb16":"markdown","fe12be25":"markdown","48c9c5e2":"markdown","f81f5ec4":"markdown","d6867f3d":"markdown","4d4a6662":"markdown","dff7ee6b":"markdown","c9147065":"markdown","8000318f":"markdown","fd9e9d21":"markdown","90836169":"markdown","52002dab":"markdown","06e7c15d":"markdown","df052ba9":"markdown","c2ad6693":"markdown","74b6230c":"markdown","47988c39":"markdown","9f23a4cc":"markdown","a15ecdd8":"markdown"},"source":{"4cc30d99":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cef28621":"# !pip install tensorflow-gpu==2.0.0-alpha0\n# !pip install tensorflow-gpu==2.4.1","de155515":"# %tensorflow_version 2.x\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nprint(device_name)\nif device_name != '\/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","913a586e":"tf.__version__","9292fa85":"# from tensorflow.python.client import device_lib\n# device_lib.list_local_devices()","9ba7c99f":"# !cat \/proc\/meminfo","7ff443ab":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom keras_preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import MultiLabelBinarizer","b3c082c2":"df = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\ndf.head()","233ce66e":"df.info()","c9f8c7af":"print(df['labels'].value_counts().plot.bar())","273531bb":"df['labels'] = df['labels'].apply(lambda string: string.split(' '))\ndf.head()","324e83d4":"_labels = list(df['labels'])\nmlb = MultiLabelBinarizer()\ndata = pd.DataFrame(mlb.fit_transform(_labels), columns=mlb.classes_, index=df.index)\nprint(data.sum())\n\nlabels = list(data.sum().keys())\nprint(labels)\nlabel_counts = data.sum().values.tolist()\n\nfig, ax = plt.subplots(1,1, figsize=(20,6))\n\nsns.barplot(x= labels, y= label_counts, ax=ax)\n\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2, p.get_height(), int(p.get_height()), ha='center')\n    \nplt.title('THE AMOUNT OF EACH LABEL')","85d85dfd":"data.insert(0, 'image', df['image'], True)\ndata","c3a07408":"target = []\nfor row in range(len(data)):\n    target.append(list((data.iloc[row])[1:]))\n    \nlen(target), target[:5]","294e6bab":"target = np.array(target)\ntarget[:5]","3ea56b5f":"image_generator = ImageDataGenerator(rescale=1\/255.0, validation_split=0.2)\n#                                      preprocessing_function=tf.keras.applications.vgg16.preprocess_input)","aa6ce405":"HEIGHT = 32 #128 64\nWIDTH = 32 #128 64\nSEED = 42\nBATCH_SIZE = 32","a58c8b96":"type(df), df['labels'].value_counts()","be4b1f67":"with tf.device('\/GPU:0'):\n    train_generator = image_generator.flow_from_dataframe(\n        dataframe=df,\n        directory='..\/input\/plant-pathology-2021-fgvc8\/train_images',\n        x_col='image',\n        y_col='labels',\n        subset='training',\n        batch_size=BATCH_SIZE, \n        seed=SEED,\n        class_mode='categorical',\n        target_size=(HEIGHT, WIDTH),\n        shuffle=True,\n    )\n    validation_generator = image_generator.flow_from_dataframe(\n        dataframe=df,\n        directory='..\/input\/plant-pathology-2021-fgvc8\/train_images',\n        x_col='image',\n        y_col='labels',\n        subset='validation',\n        batch_size=BATCH_SIZE, \n        seed=SEED,\n        class_mode='categorical',\n        target_size=(HEIGHT, WIDTH),\n        shuffle=True,\n    )","e888828a":"# instantiating the model in the strategy scope creates the model on the TPU\n# with tpu_strategy.scope():\n# print(tpu, tpu_strategy)\n# run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\nwith tf.device('\/GPU:0'):\n    model=Sequential()\n    model.add(Conv2D(64,kernel_size=4,activation='relu',input_shape=(HEIGHT,WIDTH,3)))\n    model.add(MaxPooling2D(2,2))\n    model.add(Conv2D(64,(3,3),activation='relu'))\n    model.add(MaxPooling2D(2,2))\n#     model.add(Conv2D(64,(3,3),activation='relu'))\n#     model.add(MaxPooling2D(2,2))\n    model.add(Conv2D(128,(3,3),activation='relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(Flatten())\n    model.add(Dropout(0.5))\n    model.add(Dense(12,activation='softmax'))\n\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy'],\n    #     options=run_opts\n    )\n\n# with tf.device('\/gpu:0'):\n#     model = Sequential()\n#     model.add(Conv2D(64, kernel_size=4, activation='relu', input_shape=(HEIGHT, WIDTH, 3)))\n#     model.add(MaxPooling2D(2,2))\n#     model.add(Conv2D(64, kernel_size=4, activation='relu'))\n#     model.add(MaxPooling2D(2,2))\n#     model.add(Dropout(0.5))\n#     model.add(Conv2D(128, kernel_size=4, activation='relu'))\n#     model.add(MaxPooling2D(2,2))\n#     model.add(Conv2D(128, kernel_size=4, activation='relu'))\n#     model.add(MaxPooling2D(2,2))\n#     model.add(Dropout(0.5))\n#     model.add(Conv2D(256, kernel_size=4, activation='relu'))\n#     model.add(MaxPooling2D(2,2))\n#     model.add(Conv2D(256, kernel_size=4, activation='relu'))\n#     model.add(MaxPooling2D(2,2))\n#     model.add(Flatten())\n#     model.add(Dropout(0.5))\n# #     model.add(Dense(512, activation='relu'))\n#     model.add(Dense(6, activation='softmax'))\n\n#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n\nmodel.summary()\n","fb3548a1":"# model.compile(\n#     optimizer='adam',\n#     loss='categorical_crossentropy',\n#     metrics=['accuracy'])\n# model.summary()","d5545c61":"TRAIN_STEP_SIZE = train_generator.samples\/train_generator.batch_size\nVALIDATION_STEP_SIZE = validation_generator.samples\/validation_generator.batch_size","c7638def":"# tf.test.is_gpu_available(), tf.test.gpu_device_name()","79498dab":"with tf.device('\/gpu:0'):\n    model_history=model.fit_generator(train_generator, validation_data=validation_generator, epochs=5)\n\n#                              steps_per_epoch=TRAIN_STEP_SIZE,\n#                              validation_steps=VALIDATION_STEP_SIZE\n                                \n            ","82b7c6ff":"tf.__version__","a1df3608":"Now we have a table of images' names and their diseases index.  \nLet's get the target of all image in the dataset.","118deb16":"Keep on processing the data, i'm using MultiLabelBinarizer to convert all the labels to the type of a pandas DataFrame named '**data**'.  \nThis '**data**' table represents each disease label as a column and if an image, or leaf, has that disease, the value of it's cell in that column will be 1, otherwise 0.   ","fe12be25":"## **NOTE:**  \n### As we can see here, there are 12 labels but some labels are the combine other labels.  \n### So that, there actually are 5 diseases which are:  \n* rust\n* scab\n* complex\n* frog_eye_leaf_spot\n* powdery_mildew\n\n### And another label is:  \n* healthy","48c9c5e2":"Define important arguments","f81f5ec4":"Reform the type of column 'labels' in the dataset from String to Lists in which all labels of all images are contained. ","d6867f3d":"Define arguments ","4d4a6662":"> # Process the data","dff7ee6b":"## Using Image Data Generator to load the image data from directory","c9147065":"Create a train_generator, validation_generator to get the image from file train_images for training and validating.","8000318f":"## Visualize the data","fd9e9d21":"Create a CNN model","90836169":"> # About the data","52002dab":"In the description of the challenge, it is said that \"**Unhealthy leaves with too many diseases to classify visually will have the complex class, and may also have a subset of the diseases identified.**\"  \nBut in the visualization of data above, there label 'complex' also goes with 'rust', 'frog_eye_leaf_spot', 'powdery_mildew'.  \nSo i suppose the 'complex' label is not the combination of the remaining labels and it's still an independent label, but can combine with other labels. ","06e7c15d":"The data contains 2 columns.  \nThe first column is the *images' names* named '**image**', another column is the '**labels**' of all the images in the dataset.  \nThere are 18632 images and 18632 labels so that there are no null data in this dataset.","df052ba9":"### Because one image (leaf) can have multiple diseases so that this task is a multi-label classification problem!!!","c2ad6693":"> # Include packages and libraries","74b6230c":"Call an ImageDataGenerator","47988c39":"Fit the model","9f23a4cc":"Compile the model","a15ecdd8":"## Read file data "}}