{"cell_type":{"21caad78":"code","d3a91ccd":"code","f7e04834":"code","0ce409bc":"code","0c72e091":"code","ff2b60fd":"code","05050316":"code","cd1f1387":"code","54ad0513":"code","02641f8f":"code","d983f7df":"code","c3883939":"code","4391a0bd":"code","7da0f92c":"code","3642eb77":"code","397974dc":"code","5965e1cb":"code","63d08830":"code","d7ef17af":"code","34ff7100":"code","f3e26251":"code","4a809be0":"code","102e5e12":"code","a43991c7":"code","5a94c07f":"code","3e132605":"code","bdb0f480":"code","921a9eb2":"code","380029b8":"code","0a47a76d":"code","3e45f64e":"code","84bd733a":"code","671d8890":"code","1ecaf8df":"code","34185b4f":"code","82d9e920":"code","3466a797":"code","216d8d44":"code","f41c0aa0":"code","018d7445":"code","44408d7f":"markdown","618a4be5":"markdown","16f69ffe":"markdown","7a8aeb21":"markdown","c5d09293":"markdown","feb0ebc3":"markdown"},"source":{"21caad78":"import datetime\ntime1 = datetime.datetime.now()\nprint(time1)","d3a91ccd":"import random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.metrics import categorical_accuracy\n\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)","f7e04834":"IMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nIMAGE_CHANNELS = 3\nTRAIN_BATCH_SIZE = 8\nVAL_BATCH_SIZE = 5\nEPOCHS = 1\nBALANCE = False #True  False\nAUG = False #True  False\nLR = 0.005#0.001  0.005  0.01\nH5_FILE_NAME = '_'.join(['model',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.h5'\nprint(H5_FILE_NAME)\nTRAINING_LOG_FILE_NAME = '_'.join(['training_log',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(TRAINING_LOG_FILE_NAME)\nSUBMISSION_FILE_NAME = '_'.join(['submission',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(SUBMISSION_FILE_NAME)","0ce409bc":"path = '..\/input\/plant-pathology-2020-fgvc7\/train.csv'\ndf_train_all = pd.read_csv(path)\n\npath = '..\/input\/plant-pathology-2020-fgvc7\/test.csv'\ndf_test = pd.read_csv(path)\n\npath = '..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv'\ndf_sample = pd.read_csv(path)\n\n\nprint(df_train_all.shape)\nprint(df_test.shape)\nprint(df_sample.shape)","0c72e091":"# Identify the target class of each row in the train set\n\ndef get_class(row):\n    \n    if row['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    \n    elif row['rust'] == 1:\n        return 'rust'\n    \n    elif row['scab'] == 1:\n        return 'scab'\n    \n    else:\n        return 'healthy'\n    \ndf_train_all['target'] = df_train_all.apply(get_class, axis=1)\n\ndf_train_all.head()","ff2b60fd":"df_train_all['target'].value_counts()","05050316":"# shuffle\ndf_train_all_shuffle = shuffle(df_train_all, random_state=101)\n# select the column that we will use for stratification\ny = df_train_all_shuffle['target']\n\ndf_train, df_val = train_test_split(df_train_all_shuffle, test_size=0.2, random_state=101, stratify=y)\n\n\nprint(df_train.shape)\nprint(df_val.shape)","cd1f1387":"df_train['target'].value_counts()","54ad0513":"df_val['target'].value_counts()","02641f8f":"def train_balancer(df_train):\n    df_1 = df_train[df_train['target'] != 'multiple_diseases']\n    df_2 = df_train[df_train['target'] == 'multiple_diseases']\n    df_train_up = pd.concat([df_1, df_2,  df_2,  df_2,  df_2,  df_2,  df_2], axis=0).reset_index(drop=True)\n\n    df_train_ret = shuffle(df_train_up, random_state=101)\n    return df_train_ret","d983f7df":"# This is the new class distribution of the train set\nif BALANCE:\n    df_train = train_balancer(df_train)\ndf_train['target'].value_counts()","c3883939":"df_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)\ndf_test.to_csv('df_test.csv.gz', compression='gzip', index=False)\n!ls","4391a0bd":"# Albumentations\n\nimport albumentations as albu\n\n\ndef augment_image(augmentation, image):\n    \n    \"\"\"\n    Uses the Albumentations library.\n    \n    Inputs: \n    1. augmentation - this is the instance of type of augmentation to do \n    e.g. aug_type = HorizontalFlip(p=1) \n    # p=1 is the probability of the transform being executed.\n    \n    2. image - image with shape (h,w)\n    \n    Output:\n    Augmented image as a numpy array.\n    \n    \"\"\"\n    # get the transform as a dict\n    aug_image_dict =  augmentation(image=image)\n    # retrieve the augmented matrix of the image\n    image_matrix = aug_image_dict['image']\n    \n    \n    return image_matrix","7da0f92c":"# Define the transforms\n\n# Modified from --> Pneumothorax - 1st place solution\n# Source: https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/discussion\/107824#latest-620521\n\n\naug_types1 = albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, \n                  interpolation=1, border_mode=4, value=None, mask_value=None, \n                  shift_limit_x=None, shift_limit_y=None, always_apply=False, \n                  p=1)\n\naug_types2 = albu.Flip(p=1)\n\naug_types3 = albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2,\n                                           brightness_by_max=True, always_apply=False,p=1)\n\naug_types4 = albu.Blur(blur_limit=(3,3.5), always_apply=False, p=1)\n\naug_types5 = albu.OneOf([\n                albu.ElasticTransform(alpha=1, sigma=50, alpha_affine=50,\n                                       interpolation=1, border_mode=4, value=None,mask_value=None,\n                                       always_apply=False, approximate=False, p=1),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, \n                                 value=None, mask_value=None, always_apply=False, p=1)\n                        ], p=1)","3642eb77":"def train_generator_aug(batch_size=8,random_seed=None):\n    \n    while True:\n        \n        if random_seed:\n            random.seed(random_seed)\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((6*len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = pd.concat([y_train, y_train, y_train, y_train, y_train, y_train], axis=0).reset_index(drop=True)\n                y_train = np.asarray(y_train) \n\n\n       \n                X_train[i] = image\n                X_train[i+1*len(image_id_list)] = augment_image(aug_types1, image)\n                X_train[i+2*len(image_id_list)] = augment_image(aug_types2, image)\n                X_train[i+3*len(image_id_list)] = augment_image(aug_types3, image)\n                X_train[i+4*len(image_id_list)] = augment_image(aug_types4, image)\n                X_train[i+5*len(image_id_list)] = augment_image(aug_types5, image)\n                \n            # Normalize the images\n            X_train = X_train\/255\n\n            yield X_train, y_train\n            ","397974dc":"def train_generator_no_aug(batch_size=8):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = np.asarray(y_train) \n                \n                # insert the image into X_train\n                X_train[i] = image\n                \n                          \n                \n            # Normalize the images\n            X_train = X_train\/255\n\n            yield X_train, y_train","5965e1cb":"# Test the generator\n\n# initialize\nif AUG:\n    train_gen = train_generator_aug(batch_size=8,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=8)\n\n# run the generator\nX_train, y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(y_train.shape)","63d08830":"def val_generator(batch_size=5):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_val\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_val[i] = image\n                \n                \n            \n            \n            # Create y_val\n            # ===============\n\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_val = df[cols]\n                y_val = np.asarray(y_val) \n\n                       \n                \n            # Normalize the images\n            X_val = X_val\/255\n\n            yield X_val, y_val","d7ef17af":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=5)\n\n# run the generator\nX_val, y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(y_val.shape)","34ff7100":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_test.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_test\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_test[i] = image\n                \n                 \n                \n            # Normalize the images\n            X_test = X_test\/255\n\n            yield X_test","f3e26251":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=1)\n\n# run the generator\nX_test = next(test_gen)\n\nprint(X_test.shape)","4a809be0":"from tensorflow.keras.applications.mobilenet import MobileNet\n\nmodel = MobileNet(weights='imagenet')\n\n# Exclude the last 2 layers of the above model.\nx = model.layers[-2].output\n\n# Create a new dense layer for predictions\n# 3 corresponds to the number of classes\npredictions = Dense(4, activation='softmax')(x)\n\n# inputs=model.input selects the input layer, outputs=predictions refers to the\n# dense layer we created above.\n\nmodel = Model(inputs=model.input, outputs=predictions)\n\nmodel.summary()","102e5e12":"num_train_samples = len(df_train)\nnum_val_samples = len(df_val)\n\n# determine num train steps\ntrain_steps = np.ceil(num_train_samples \/ TRAIN_BATCH_SIZE)\n\n# determine num val steps\nval_steps = np.ceil(num_val_samples \/ VAL_BATCH_SIZE)","a43991c7":"import datetime\ntime3 = datetime.datetime.now()\nprint(time3)","5a94c07f":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\n# Initialize the generators\nif AUG:\n    train_gen = train_generator_aug(batch_size=TRAIN_BATCH_SIZE,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=TRAIN_BATCH_SIZE)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\n\nmodel.compile(\n    Adam(lr=LR),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\n\n\n\nfilepath = H5_FILE_NAME\n\n#earlystopper = EarlyStopping(patience=10, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=3, \n                                   verbose=1, mode='max')\n\n\n\nlog_fname = TRAINING_LOG_FILE_NAME\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, csv_logger, reduce_lr]\n\nhistory = model.fit(train_gen, steps_per_epoch=train_steps, epochs=EPOCHS, \n                    validation_data=val_gen, validation_steps=val_steps,\n                    verbose=2,\n                    callbacks=callbacks_list)\n","3e132605":"time4 = datetime.datetime.now()\nprint(time4)","bdb0f480":"# Training time\nprint(time4-time3)","921a9eb2":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","380029b8":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\nval_loss, val_acc = \\\nmodel.evaluate(val_gen, \n               steps=val_steps)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","0a47a76d":"# Display the training log\n\ntrain_log = pd.read_csv(TRAINING_LOG_FILE_NAME)\n\ntrain_log.head()","3e45f64e":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = train_log['accuracy']\nval_acc = train_log['val_accuracy']\nloss = train_log['loss']\nval_loss = train_log['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()","84bd733a":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)","671d8890":"# get y_pred as index values\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred)","1ecaf8df":"# get y_true as index values\n\ncols = ['healthy', 'multiple_diseases', 'rust', 'scab']\ny_true = df_val[cols]\ny_true = np.asarray(y_true) \n\ny_true = np.argmax(y_true, axis=1)\nprint(y_true)","34185b4f":"model.load_weights(H5_FILE_NAME)\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)\n\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred[:50])","82d9e920":"# Put the preds into a dataframe\n\ndf_preds = pd.DataFrame(preds, columns=['healthy', 'multiple_diseases', 'rust', 'scab'])\n\ndf_preds['image_id'] = df_val['image_id'].copy().values\n\ndf_preds.head()","3466a797":"# Create a submission csv file\n\ndf_results = pd.DataFrame({'image_id': df_preds.image_id,\n                            'healthy': df_preds.healthy,\n                               'multiple_diseases': df_preds.multiple_diseases,\n                               'rust': df_preds.rust,\n                               'scab': df_preds.scab,\n                           'target':df_val['target'].values\n                           }).set_index('image_id')\n\n\n# create a submission csv file\ndf_results.to_csv(SUBMISSION_FILE_NAME) \ndf_results.head()","216d8d44":"time2 = datetime.datetime.now()\nprint(time2)","f41c0aa0":"# Total time\nprint(time2 - time1)","018d7445":"!ls","44408d7f":"Make a test set prediction","618a4be5":"[ 3 ] Test Generator","16f69ffe":"Make a prediction on the val set","7a8aeb21":"Build the Data Generators\n\n\n[ 1 ] Train Generator","c5d09293":"[ 2 ] Val Generator","feb0ebc3":"Classification Report"}}