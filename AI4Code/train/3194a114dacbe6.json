{"cell_type":{"3dc3b62a":"code","de65091a":"code","d4f014e8":"code","f348d0c6":"code","afe78736":"code","5c0a3840":"code","03c88efa":"code","7abac803":"code","e61a29f8":"code","88e614ba":"code","1d3f573e":"code","e0fdc6fd":"code","3c8818be":"code","7f838cb6":"code","1378e054":"code","2985c32b":"code","869254c2":"code","c9436a57":"code","68d96ebc":"code","26dacb69":"code","e02ddb71":"code","4b815a6d":"code","b77f8d52":"code","f9f957c6":"code","1f13e0ae":"code","d629d1f8":"code","281d4eaf":"code","eca89782":"code","7a81a98c":"code","3b8d66a5":"code","b9118a55":"code","add07b91":"code","88911099":"code","4e2bc117":"code","81e762eb":"code","7778809c":"code","ab7582aa":"code","3f390065":"code","3d25593d":"code","509ff322":"code","98f10f29":"code","4348fcc3":"code","a89f0320":"code","691337c1":"code","24460934":"code","a0619672":"markdown","9681f3b1":"markdown","f45337c4":"markdown","8950a32c":"markdown","4e5daeb3":"markdown","de915cce":"markdown","32076b5a":"markdown","cceafbf0":"markdown","638fb21c":"markdown","27627796":"markdown","1c0649d5":"markdown","622131a5":"markdown","82fceb57":"markdown","923379c9":"markdown","0f9586a2":"markdown","fd47d5a9":"markdown","bf37f796":"markdown","c89c5e0e":"markdown","8fff5250":"markdown","cc31f7ba":"markdown","80671141":"markdown","706c1b0b":"markdown","c2339fe2":"markdown","0abcc4af":"markdown","1ae4fdb6":"markdown","89273165":"markdown","586495f6":"markdown","f9648663":"markdown","5822d23b":"markdown","b6b0dd19":"markdown","38673f8d":"markdown","3569c263":"markdown","3f91e84d":"markdown","93caf96a":"markdown","36c3f106":"markdown"},"source":{"3dc3b62a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","de65091a":"df = pd.read_csv(\"..\/input\/avocado-prices\/avocado.csv\", na_values = \"NaN\")","d4f014e8":"df.head() #to have an overview of dataset.","f348d0c6":"df = df.drop(\"Unnamed: 0\", axis = 1)","afe78736":"df = df.rename(columns={\"Date\": \"date\",\"AveragePrice\": \"average_price\",\"Region\":\"region\",\"Total Volume\":\"total_volume\",\"Total Bags\":\"total_bags\",\"Small Bags\":\"small_bags\",\"Large Bags\":\"large_bags\",\"XLarge Bags\":\"xlarge_bags\"})","5c0a3840":"df.dtypes","03c88efa":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size = 0.2, random_state = 42)","7abac803":"categoricals = [\"type\"] # In this notebook, we wont use region variable\nnumericals = ['average_price', 'total_volume', '4046', '4225',\n       '4770', 'total_bags', 'small_bags', 'large_bags', 'xlarge_bags',\n       'year']","e61a29f8":"for i in categoricals:\n    print(train[i].value_counts())\n    print(\"***************************\")","88e614ba":"def plot_histogram(var,df):\n    plt.figure(num=None, figsize=(15,9), dpi=150, facecolor='w', edgecolor='r')\n    sns.histplot(data=df, x= var)\n    plt.title(\"Histogram of '{var_name}'\".format(var_name=str(var)))\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    plt.xticks(rotation=90)\n    plt.show()","1d3f573e":"for i in numericals:\n    plot_histogram(i,train)","e0fdc6fd":"from pandas.plotting import scatter_matrix\nscatter_matrix(train[numericals], figsize = (20,20))","3c8818be":"sns.heatmap(train.corr());","7f838cb6":"X = train.drop([\"average_price\",\"date\",\"year\",\"region\"],axis = 1) # for our analysis we neglect date, year and region variables\ny = train.average_price","1378e054":"train.isnull().sum().sort_values(ascending=False).head()","2985c32b":"for i in categoricals:\n    onehot = pd.get_dummies(X[i], prefix=i, dummy_na=False)\n    X = X.drop(i, axis = 1)\n    X = pd.concat([X, onehot], axis=1)","869254c2":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)","c9436a57":"X_new = scaler.transform(X)","68d96ebc":"from sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(X_new,y)","26dacb69":"from sklearn.metrics import mean_squared_error\nlinreg_preds = linreg.predict(X_new)\nlinreg_mse = mean_squared_error(linreg_preds,y)\nlinreg_rmse = np.sqrt(linreg_mse)","e02ddb71":"linreg_rmse","4b815a6d":"from sklearn.model_selection import cross_val_score\nlinreg_crossval_scores = cross_val_score(linreg, X_new,y,scoring = \"neg_mean_squared_error\", cv = 10)","b77f8d52":"def display_scores(scores):\n    print(\"scores:\"  , scores)\n    print(\"mean:\", scores.mean())","f9f957c6":"display_scores(np.sqrt(-linreg_crossval_scores))","1f13e0ae":"overview_data = X.iloc[40:50]\noverview_labels = y.iloc[40:50]\nscaled = scaler.transform(overview_data)\nprint(\"predicted\", linreg.predict(scaled), \"compare labels\", overview_labels)","d629d1f8":"from sklearn.tree import DecisionTreeRegressor\ndectreereg = DecisionTreeRegressor()\ndectreereg.fit(X_new , y)\ndectreereg_preds = dectreereg.predict(X_new)","281d4eaf":"dectreereg_mse = mean_squared_error(y,dectreereg_preds)\ndectreereg_rmse = np.sqrt(dectreereg_mse)\ndectreereg_rmse","eca89782":"dectreereg_crossval_scores = cross_val_score(dectreereg, X_new,y,scoring = \"neg_mean_squared_error\", cv = 10)\ndisplay_scores(np.sqrt(-dectreereg_crossval_scores))","7a81a98c":"from sklearn.svm import SVR\nsvmreg = SVR()\nsvmreg.fit(X_new,y)\nsvmreg_preds = svmreg.predict(X_new)","3b8d66a5":"svmreg_mse = mean_squared_error(y,svmreg_preds)\nsvmreg_rmse = np.sqrt(svmreg_mse)\nsvmreg_rmse","b9118a55":"svmreg_crossval_scores = cross_val_score(svmreg, X_new,y,scoring = \"neg_mean_squared_error\", cv = 10)\ndisplay_scores(np.sqrt(-svmreg_crossval_scores))","add07b91":"from sklearn.ensemble import RandomForestRegressor\nranforestreg = RandomForestRegressor()\nranforestreg.fit(X_new,y)","88911099":"ranforestreg_preds = ranforestreg.predict(X_new)\nranforestreg_mse = mean_squared_error(y,ranforestreg_preds)\nranforestreg_rmse = np.sqrt(ranforestreg_mse)\nranforestreg_rmse","4e2bc117":"ranforestreg_crossval_scores = cross_val_score(ranforestreg, X_new,y,scoring = \"neg_mean_squared_error\", cv = 10)\ndisplay_scores(np.sqrt(-ranforestreg_crossval_scores))","81e762eb":"from sklearn.model_selection import GridSearchCV\nparam_grid = [\n    {'n_estimators' : [3,10,30], 'max_features' : [2,4,6,8], \"max_depth\" : [10, 20],},\n    {'bootstrap' : [False], 'n_estimators' : [4,8,12], 'max_features' : [2,3,4]}, \n    {'bootstrap' : [True], 'n_estimators' : [2,10,20], 'max_features' : [5,6,7]}\n]","7778809c":"grid_search = GridSearchCV(ranforestreg, param_grid, cv = 10,\n                          scoring = 'neg_mean_squared_error',\n                          return_train_score = True\n                          )","ab7582aa":"grid_search.fit(X_new,y)","3f390065":"grid_search.best_params_","3d25593d":"bestregressor = grid_search.best_estimator_","509ff322":"sorted(zip(bestregressor.feature_importances_, X.columns))","98f10f29":"X_test = test.drop([\"date\",\"average_price\",\"year\",\"region\"],axis = 1)\ny_test = test.average_price","4348fcc3":"for i in categoricals:\n    onehot = pd.get_dummies(X_test[i], prefix=i, dummy_na=False)\n    X_test = X_test.drop(i, axis = 1)\n    X_test = pd.concat([X_test, onehot], axis=1)","a89f0320":"X_test_latest = scaler.transform(X_test)","691337c1":"bestregressor_preds = bestregressor.predict(X_test_latest)\nbestregressor_mse = mean_squared_error(y_test,bestregressor_preds)\nbestregressor_rmse = np.sqrt(bestregressor_mse)\nbestregressor_rmse","24460934":"bestregressor_crossval_scores = cross_val_score(bestregressor, X_test_latest,y_test,scoring = \"neg_mean_squared_error\", cv = 10)\ndisplay_scores(np.sqrt(-bestregressor_crossval_scores))","a0619672":"Is it a safe prediction? Let us see in cross validation.","9681f3b1":"We have the categorical variables \"type\",\"region\"\nWe will not use it for this time.","f45337c4":"#### Decision Tree Regression\n","8950a32c":"#### SVM Regression","4e5daeb3":"Columns are explained in data page https:\/\/www.kaggle.com\/neuromusic\/avocado-prices as follows:\n* Date - The date of the observation\n* AveragePrice - the average price of a single avocado\n* type - conventional or organic\n* year - the year\n* Region - the city or region of the observation\n* Total Volume - Total number of avocados sold\n* 4046 - Total number of avocados with PLU 4046 sold\n* 4225 - Total number of avocados with PLU 4225 sold\n* 4770 - Total number of avocados with PLU 4770 sold","de915cce":"There seem to be no missing data.","32076b5a":"There seem to be some good and bad predictions. For instance 1.65 instead of 1.59 acceptable, also 1.65 instead of 2.73 seems unacceptable. Based on the predictions on these 10 observations, I feel like the model is doing bad, it is not enough to judge for now. Let us compare it with other models.","cceafbf0":"Histograms are useful to distribution of variables, also to see outliers.","638fb21c":"This scores seems more meaningful, obviously decision tree regression is overfitting.","27627796":"* This notebook aims to predict average prices, therefore we will consider different regression algortihms and pick a good one among them. \n* Since we are using regression, we will use mean squared error as a measure of error. More specifically Root Mean Squared Error since it averages the squared errors with relatively high weight to large errors in the computation.","1c0649d5":"## Fine Tuning Random Forest Regressor\n","622131a5":"No strong corellation with average price with any of the variables is apperant in correlation matrix.","82fceb57":"#### Grid Search Method","923379c9":"We will work on train set, until we feel OK with a good model. In this notebook I am planning to go compare regression algortihms and hopefully find a good regression algortihm to predict avocado prices.","0f9586a2":"Two quick fixes shall be made here before go further: \n* The column \"Unnamed: 0\" is obviously an unnecessary column, \n* And I prefer column names lowercase and with underline instead of space.\n","fd47d5a9":"* It seems perfectly balanced. It will not cause an error in our prediction hopefully.","bf37f796":"## Cleaning and Preparing Data  \n","c89c5e0e":"## Evaluate the System on the Test Set","8fff5250":"Seems so good, is it overfitting?","cc31f7ba":"##  Try Different Models to Find an Appropriate One","80671141":"This error is negligible, almost 0. Is it really the case?","706c1b0b":"#### Linear Regression","c2339fe2":"There seem to be no overfitting, but how successful is this value?","0abcc4af":"## Conclusion\n    * In this notebook, linear regression, decision tree regression, svm regression and random forest regression models were compared\n    * To further improve random forest regression model, grid search method applied to find best parameters\n    * type and 4046 seem to be the best parameters to predict average price.","1ae4fdb6":"#### Random Forest Regression","89273165":"It was overfitting obviously, let us see if we can improve this model.","586495f6":"What are most important features?","f9648663":"* Average price seem to have some skewness but can be ignored and assumed it is normally distributed. No obvious outliers apperant in the histogram.\n* Data appears to has has no obvious imbalance in terms of years.","5822d23b":"We need categorical variables in terms of numbers. For instance (not for everyone but) years should also be counted as categorical variable but since it is in increasing order and this increment has a meaning, therefore we treat it as a numerical variable. We apply get_dummies function of pandas to two categorical variables.","b6b0dd19":"Is this prediction an overfitting?","38673f8d":"We are supposed to apply same transformations on the test set","3569c263":"We need to scale the data since all values are scattered among different intervals. Without a proper normalization, ML algorithms does not give meaningful results in general.","3f91e84d":"Before we start an explatory analysis, it is best to seperate test set to avoid an obvious bias. Test set should not effect our analysis.","93caf96a":"## Visualize the data, gain more insights\n","36c3f106":"Lets check if data types are well prepared."}}