{"cell_type":{"f914ac41":"code","91b7e725":"code","e804e5e6":"code","56ea281e":"code","942a1525":"code","2a93b36d":"code","48d802d4":"code","73d8f69a":"code","50539dd8":"code","f88fd5ae":"code","8d5fcc9e":"code","d6e99696":"code","de20649c":"code","74db0cb7":"code","da61504a":"code","22ac89ac":"code","97030ff9":"code","74d04204":"markdown","0775e39c":"markdown","fa337674":"markdown","dc5d1ce7":"markdown","f9960fea":"markdown","cb1eb754":"markdown","d1066100":"markdown","fb367d06":"markdown","dd199168":"markdown","ffac3dca":"markdown","5ee21c0c":"markdown","75e51bbb":"markdown","db269a78":"markdown","212722e2":"markdown","de9f2e03":"markdown","90d53918":"markdown","748949aa":"markdown","a37984df":"markdown","c8598c9e":"markdown","c1bd60fc":"markdown","9b4f40d1":"markdown","c8a84fa4":"markdown","8b3d33c5":"markdown","a90bb2ba":"markdown","ff556bc0":"markdown","be68792f":"markdown"},"source":{"f914ac41":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport zipfile\nimport os\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n%matplotlib inline","91b7e725":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e804e5e6":"# path to zipped & working directories\npath_zip = '\/kaggle\/input\/denoising-dirty-documents\/'\npath = '\/kaggle\/working\/'","56ea281e":"# unzip files first to working directory\n# We could use also unzipped data source, but why not to learn something new?\nwith zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)\n\nwith zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'sampleSubmission.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  ","942a1525":"# store image names in list for later use\ntrain_img = sorted(os.listdir(path + '\/train'))\ntrain_cleaned_img = sorted(os.listdir(path + '\/train_cleaned'))\ntest_img = sorted(os.listdir(path + '\/test'))","2a93b36d":"# prepare function\ndef process_image(path):\n    img = cv2.imread(path)\n    img = np.asarray(img, dtype=\"float32\")\n    img = cv2.resize(img, (540, 420))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img\/255.0\n    img = np.reshape(img, (420, 540, 1))\n    \n    return img","48d802d4":"# preprocess images\ntrain = []\ntrain_cleaned = []\ntest = []\n\nfor f in sorted(os.listdir(path + 'train\/')):\n    train.append(process_image(path + 'train\/' + f))\n\nfor f in sorted(os.listdir(path + 'train_cleaned\/')):\n    train_cleaned.append(process_image(path + 'train_cleaned\/' + f))\n   \nfor f in sorted(os.listdir(path + 'test\/')):\n    test.append(process_image(path + 'test\/' + f))","73d8f69a":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train[i][:,:,0], cmap='gray')\n    plt.title('Noise image: {}'.format(train_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train_cleaned[i][:,:,0], cmap='gray')\n    plt.title('Denoised image: {}'.format(train_img[i]))\n\nplt.show()","50539dd8":"# convert list to numpy array\nX_train = np.asarray(train)\nY_train = np.asarray(train_cleaned)\nX_test = np.asarray(test)\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15)","f88fd5ae":"def model():\n    input_layer = Input(shape=(420, 540, 1))  # we might define (None,None,1) here, but in model summary dims would not be visible\n    \n    # encoding\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    \n    x = Dropout(0.5)(x)\n\n    # decoding\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = UpSampling2D((2, 2))(x)\n\n    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n    model = Model(inputs=[input_layer], outputs=[output_layer])\n    model.compile(optimizer='adam' , loss='mean_squared_error', metrics=['mae'])\n\n    return model\n\n\nmodel = model()\nmodel.summary()","8d5fcc9e":"callback = EarlyStopping(monitor='loss', patience=30)\nhistory = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=600, batch_size=24, verbose=0, callbacks=[callback])","d6e99696":"# Check how loss & mae went down\nepoch_loss = history.history['loss']\nepoch_val_loss = history.history['val_loss']\nepoch_mae = history.history['mae']\nepoch_val_mae = history.history['val_mae']\n\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nplt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\nplt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')\nplt.title('Evolution of loss on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2)\nplt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train MAE')\nplt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val MAE')\nplt.title('Evolution of MAE on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.show()\n","de20649c":"# predict\/clean test images\nY_test = model.predict(X_test, batch_size=16)","74db0cb7":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[i][:,:,0], cmap='gray')\n    plt.title('Noisy image: {}'.format(test_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(Y_test[i][:,:,0], cmap='gray')\n    plt.title('Denoised by autoencoder: {}'.format(test_img[i]))\n\nplt.show()","da61504a":"# it will take a while!\nids = []\nvals = []\nfor i, f in enumerate(test_img):\n    file = path + 'test\/' + f\n    imgid = int(f[:-4])\n    img = cv2.imread(file, 0)\n    img_shape = img.shape\n    # print('Processing image: {} \\tinto size: {}'.format(f, img_shape))    # uncomment to see progress\n    preds_reshaped = cv2.resize(Y_test[i], (img_shape[1], img_shape[0]))\n\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\nsubmission = pd.DataFrame({'id': ids, 'value': vals})\nsubmission.to_csv('submission.csv',index = False)\n\nprint('Results saved to submission.csv!')\n\n# quick check if length of IDs is OK\n# we should get there number 14230080\nprint('Length of IDs: {}'.format(len(ids)))","22ac89ac":"# check first few rows of submission\nmy_submission = pd.read_csv('submission.csv')\nmy_submission.head(5)","97030ff9":"# cleanup working directory\nimport shutil\nshutil.rmtree(path + 'train\/')\nshutil.rmtree(path + 'test\/')\nshutil.rmtree(path + 'train_cleaned\/')","74d04204":"# Import libraries and data\nFirst load libraries we need for our work. We need multiple libraries to be able to unzip files, work with directories, sklearn, tensorflow...","0775e39c":"Now compare noisy (left) and denoised test images (right). Our model has done great job with denoising!","fa337674":"# Conclusion\nWe've created autoencoder using tensorflow v2 and keras that can very successfully remove background and noise from documents. Next step could me create algorithm that will be able to extract words out of cleaned sheets ;-)","dc5d1ce7":"For later use, we will store image names into list, so we can draw them simply.","f9960fea":"# About Autoencoders\nAn autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal \u201cnoise\u201d. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name.","cb1eb754":"## Train model\nVerbose is going to be set to 0 to avoid filling output with hundreds of lines from training. We will run 300 epochs having early stopping set to 20 (if val loss does not drop in 20 epochs, it will stop).","d1066100":"Let's store history of model as well, so we can plot loss (rmse) and mae.","fb367d06":"## If you liked this notebook, please UPVOTE\n## Thanks !","dd199168":"I have tested many different models and this one brought me to best results (val_loss < 0.0004). Increasing filters, adding another convolutional layer, batch normalization or drop out did not helped to get better score.","ffac3dca":"# Submission\nIt's time to contest! Let's submit our data.","5ee21c0c":"I have really enjoyed this task, hope you did as well!","75e51bbb":"# Modeling\nThis is first time I am using functional modeling way in tensorflow. I've tried to go with model.add() and sequential model and it did not worked at all, results were really strange. Maybe you have idea why?","db269a78":"![](https:\/\/osclasspoint.com\/kaggle\/autoencoder.png)","212722e2":"What kind of data\/files we have there?","de9f2e03":"# Split data\nIn this step we convert lists to numpy arrays and split dataset into train and validation in ration 85% train, 15% test.","90d53918":"Model is pretty simple and it's nice to look at model summary how it works in terms of layer sizes.\n420x540 -> 210x270 --> 210x270 -> 420x540","748949aa":"# Remove noisy background from images\/documents using Auto-encoders, Tensorflow v2 and Keras","a37984df":"As we have data zipped, we will have to work in \/kaggle\/working\/ directory to unzip images here.","c8598c9e":"Reshape images and put them into list.","c1bd60fc":"# Exploratory data analysis\nNot too much to look there, but just quickly look on train images and their cleaned version. This is what we put into model to learn how to clean noise from background.","9b4f40d1":"Honestly, this way to submit results was really weird for me :-\/","c8a84fa4":"Adam as optimizer is used (as it worked best out of other optimizers), loss is based on mean squared error and we are looking on mean absolute error as well.","8b3d33c5":"You may notice jump in error after approx. 10 epoch that is pretty important, but enought epochs flatten this to almost 0.","a90bb2ba":"# Data preparation\nNext step is to define function to process images and then store this images in list. As there is not as many data, we do not need to work in batches.","ff556bc0":"# Evaluation\nIn this step we will \"predict\", or better say clean test images and check how well model works.","be68792f":"## Plot error evolution on epochs"}}