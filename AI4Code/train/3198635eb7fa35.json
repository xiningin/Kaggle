{"cell_type":{"a0fa00c9":"code","3a1ae31a":"code","f4685252":"code","64e05057":"code","3f8e1bc8":"code","99630181":"code","499c77db":"code","ef3f57d4":"code","94afca40":"code","f306c4b8":"code","b27312b7":"code","01b1a331":"code","f4438bcc":"code","69aab69f":"code","57fc1cf9":"code","a560c688":"code","541e554d":"code","a750b1d5":"code","ef89a5b0":"code","ff29c58d":"code","65b722c1":"code","c17c56ee":"code","85aa5c5b":"code","2599786f":"code","432f28bb":"code","88d63d47":"code","3498a4b1":"code","c56ed5cf":"markdown","d465066b":"markdown","de415279":"markdown","3c3c17ba":"markdown","1ddcfdfa":"markdown","9cd478a1":"markdown","172bf444":"markdown","70862cef":"markdown","d0bd752f":"markdown","6eb795da":"markdown","93f4d262":"markdown","df9cdec2":"markdown","67bc0dba":"markdown","72fdf7b3":"markdown","9294df2a":"markdown","709f46f2":"markdown","e41e8455":"markdown"},"source":{"a0fa00c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a1ae31a":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing","f4685252":"df = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\ndf.sample(5)","64e05057":"df.describe()","3f8e1bc8":"df.isna().sum()","99630181":"sns.pairplot(df[df.columns.drop('Id')],hue='Species')\ndf.drop(\"Id\", axis=1).boxplot(by=\"Species\", figsize=(12, 10))\nplt.show()","499c77db":"columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','Species']\nfrom pandas.plotting import andrews_curves\nandrews_curves(df[columns], \"Species\")\nplt.show()","ef3f57d4":"sns.countplot(x=df['Species'])\nfig, ax = plt.subplots(nrows=2,ncols=2,figsize=(20,6))\nprint(df['Species'].value_counts(normalize=True))\nsns.distplot(df['SepalLengthCm'],bins=50,ax=ax[0,0])\nsns.distplot(df['SepalWidthCm'],bins=50,ax=ax[0,1])\nsns.distplot(df['PetalLengthCm'],bins=50,ax=ax[1,0])\nsns.distplot(df['PetalWidthCm'],bins=50,ax=ax[1,1])\nplt.show()","94afca40":"fig,ax = plt.subplots(1,2,figsize=(20,3))\nsns.distplot(df['PetalLengthCm'],bins=50,ax=ax[0])\nsns.boxplot(df['PetalLengthCm'],ax=ax[1])\nplt.suptitle('PetalLengthCm',fontsize=20)\nplt.show()","f306c4b8":"quantile_transformer = preprocessing.QuantileTransformer(\n    output_distribution='normal',n_quantiles=len(df), random_state=0)\nX_trans = quantile_transformer.fit_transform(df['PetalLengthCm'].values.reshape((len(df),1)))\nfig,ax = plt.subplots(1,2,figsize=(20,3))\nplt.suptitle('PetalLengthCm',fontsize=20)\nsns.distplot(X_trans,bins=50,ax=ax[0])\nsns.boxplot(X_trans,ax=ax[1])\nplt.show()","b27312b7":"fig,ax = plt.subplots(1,2,figsize=(20,3))\nsns.distplot(df['PetalWidthCm'],bins=50,ax=ax[0])\nsns.boxplot(df['PetalWidthCm'],ax=ax[1])\nplt.suptitle('PetalWidthCm',fontsize=20)\nplt.show()","01b1a331":"X_trans = quantile_transformer.fit_transform(df['PetalWidthCm'].values.reshape((len(df),1)))\nfig,ax = plt.subplots(1,2,figsize=(20,3))\nsns.distplot(X_trans,bins=50,ax=ax[0])\nsns.boxplot(X_trans,ax=ax[1])\nplt.suptitle('PetalWidthCm',fontsize=20)\nplt.show()","f4438bcc":"X = df.drop(['Id','Species'],axis=1)\ny = df['Species']","69aab69f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X.copy(),y.copy(),test_size=0.3,random_state=0)","57fc1cf9":"quantile_transformer = preprocessing.QuantileTransformer(output_distribution='normal',n_quantiles=len(X_train), random_state=0)\nX_train.loc[:,['PetalWidthCm','PetalLengthCm']]=quantile_transformer.fit_transform(X_train[['PetalWidthCm','PetalLengthCm']].values.reshape((len(X_train),2)))\nX_test.loc[:,['PetalWidthCm','PetalLengthCm']]=quantile_transformer.transform(X_test[['PetalWidthCm','PetalLengthCm']].values.reshape((len(X_test),2)))","a560c688":"X_train.describe()","541e554d":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\n\nclass CustomScaler(BaseEstimator):#, TransformerMixin):\n    def __init__(self, columns ):#, copy=True, with_mean=True, with_std=True):\n        self.scaler = StandardScaler()#(copy, with_mean, with_std)\n        self.columns = columns\n        self.mean_ = None\n        self.std_ = None\n    \n    def fit(self, X, y=None):\n        self.scaler.fit(X[self.columns], y)\n        self.mean_ = np.mean(X[self.columns])\n        self.std_ = np.std(X[self.columns])\n        return self\n    \n    def transform(self, X, y=None):#, copy=None):\n        init_col_order = X.columns\n        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns,index=X.index)\n        X_not_scaled = X.loc[:, ~X.columns.isin(self.columns)]\n        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]","a750b1d5":"columns_to_scale = ['SepalLengthCm', 'SepalWidthCm',  'PetalWidthCm', 'PetalLengthCm']\n\nscaler = CustomScaler(columns_to_scale)\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test  = scaler.transform(X_test)","ef89a5b0":"X_train.describe()","ff29c58d":"from sklearn import metrics","65b722c1":"from sklearn import svm\nmodel = svm.SVC()\nmodel.fit(X_train,y_train) \nprediction=model.predict(X_test)\nprint('The accuracy of the SVM is:',metrics.accuracy_score(prediction,y_test))","c17c56ee":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\nprint('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction,y_test))","85aa5c5b":"from sklearn.neighbors import KNeighborsClassifier\nmodel=KNeighborsClassifier(n_neighbors=3)\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\nprint('The accuracy of the KNN is',metrics.accuracy_score(prediction,y_test))","2599786f":"error_rate = []\nx = range(1,40)\nfor i in x:\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\nplt.figure(figsize=(10,6))\nplt.plot(x,error_rate,color='blue', linestyle='dashed', marker='o',\n markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')\nplt.show()","432f28bb":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(X_train,y_train) \nprediction=model.predict(X_test) \nprint('The accuracy of the Decision Tree is ',metrics.accuracy_score(prediction,y_test))","88d63d47":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=20,criterion='entropy',random_state=0)\nmodel.fit(X_train,y_train) \nprediction=model.predict(X_test) \nprint('The accuracy of the Random Forest is ',metrics.accuracy_score(prediction,y_test))","3498a4b1":"error_rate = []\nx = range(1,50,5)\nfor i in x:\n    knn = RandomForestClassifier(n_estimators=i,criterion='entropy',random_state=0)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\nplt.figure(figsize=(10,6))\nplt.plot(x,error_rate,color='blue', linestyle='dashed', marker='o',\n markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. no. of estimators')\nplt.xlabel('K')\nplt.xticks(x)\nplt.ylabel('Error Rate')\nplt.show()","c56ed5cf":"# K-Nearest Neighbours","d465066b":"# Exploratory Data Analysis","de415279":"**Analysis**\n* almost all variabels were able to distinguish the Species except SepalWidth\n* SepalWidth with SepalLength is performing little low in distinguishing species\n* SepalWidth alone is performing bad, it always needs to be used along with other variables","3c3c17ba":"**Analysis**\n* Species are equally distributed\n* SepalLength and SepalWidth are normally distributed\n* PetalLength and PetalWidth are having two bumps","1ddcfdfa":"## Normalizing PetalWidthCm and PetalLengthCm using QuantileTransformer","9cd478a1":"**Analysis**\n* from the above plot it is clear that the data converges only for k=3,6,7,8,9 ","172bf444":"## Normalizing the PetalLengthCm using QuantileTransformer","70862cef":"# Random Fores Classifier","d0bd752f":"# Support Vector Machine (SVM)","6eb795da":"# Logistic Regression","93f4d262":"# Scale the data","df9cdec2":"## Normalizing the PetalWidthCm using QuantileTransformer","67bc0dba":"**Analysis**\n* here we can see that for only values between ~6 to ~16 are unable to classify\n* rest all are able to classify with accuracy of 97% ","72fdf7b3":"# Split the data","9294df2a":"# Decision Tree","709f46f2":"# Univariate Analysis","e41e8455":"# Model"}}