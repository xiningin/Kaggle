{"cell_type":{"0789e856":"code","5520f867":"code","aeec8abe":"code","9c487e4f":"code","b4e6f2e2":"code","7ec3aafe":"code","f6e97048":"code","954bfbd8":"code","5785d996":"code","a23acc0b":"code","b755b7ee":"code","c14ec79f":"code","434eb841":"code","3738490a":"code","d9a9457f":"code","545fae18":"code","d73aa621":"code","ee4e4d96":"code","9504fa41":"code","31c6a693":"code","7551acad":"markdown","00ab4396":"markdown","0315db6d":"markdown","bc103abc":"markdown","612bef40":"markdown","d4c85f5e":"markdown","cdad2ac2":"markdown","dbe6b6fb":"markdown","ef5628fd":"markdown","6aff2a4e":"markdown","efad8bb2":"markdown","1fd9fff1":"markdown","a9becb09":"markdown"},"source":{"0789e856":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5520f867":"!pip install pytrends","aeec8abe":"from pytrends.request import TrendReq\nfrom pylab import rcParams\nfrom ipywidgets import interact, interactive, fixed, interact_manual\n\nimport warnings\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport ipywidgets as widgets\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib\nimport pandas as pd\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport seaborn as sns\n\nplt.rcParams.update({'font.size': 9})\n\nsns.set(style=\"darkgrid\")\n\npytrend = TrendReq()","9c487e4f":"test_samples = {'sample': [\"peanut butter\", \"pizza\", \"cookie\"]}\n\ndef get_google_trends_data(list_product, time_start, time_end, state=None, country='US'):\n    if state:\n        sigla='{}-{}'.format(country, state)\n    else:\n        sigla='{}'.format(country)\n    \n    data_composer = '{} {}'.format(time_start, time_end)\n    pytrend.build_payload(kw_list=list_product, \n                                  geo=sigla, \n                                  cat=0,\n                                  timeframe=data_composer)\n    \n    return pytrend.interest_over_time()\n\nlist_product= test_samples['sample']","b4e6f2e2":"dataset = get_google_trends_data(list_product=list_product, time_start='2014-01-01', time_end='2020-08-01')","7ec3aafe":"def export_data_csv(dataset, save_output):\n    dataset.to_csv(save_output, sep=\",\") \n    \ndel dataset['isPartial']\ndataset.style.background_gradient(cmap='Greens')","f6e97048":"describe = dataset.describe()\ndescribe.style.background_gradient(cmap='Greens')","954bfbd8":"def show_point_compare(df):\n    plt.figure(figsize=(15, 6))\n    for col in df.columns:\n        plt.plot(df.index, df[col], '--')\n\n    plt.title(\"Search\")\n    plt.legend(df.columns)\n    plt.xlabel(\"data\")\n    plt.ylabel(\"frequency\")\n    plt.grid(\"b--\")\n    plt.show()","5785d996":"show_point_compare(dataset)","a23acc0b":"def show_line_compare(df):\n    plt.figure(figsize=(15, 6))\n    for col in df.columns:\n        plt.plot(df.index, df[col])\n\n    plt.title(\"Search\")\n    plt.legend(df.columns)\n    plt.xlabel(\"data\")\n    plt.ylabel(\"frequency\")\n    plt.grid()\n    plt.show() \n    \ndef get_media_year(ano):\n    y_index = dataset[ano]\n    show_line_compare(y_index)","b755b7ee":"get_media_year(\"2018\")","c14ec79f":"get_media_year(\"2019\")","434eb841":"get_media_year(\"2020\")","3738490a":"def frequency_total(ano=None):\n    plt.figure(figsize=(15, 6))\n    if ano:\n        title=f\"Product by search-{ano}\"\n        yi = dataset[ano]\n        produtos_sum = yi.sum()\n        plt.pie(produtos_sum, labels=list_product, \n                 autopct='%1.1f%%', startangle=90, pctdistance=0.85, \n                shadow=True)\n        centre_circle = plt.Circle((0,0),0.65,fc='white')\n        fig = plt.gcf()\n        fig.gca().add_artist(centre_circle)\n        plt.axis('equal') \n        plt.tight_layout()\n\n    else:\n        explode = (0, 0.1, 0)\n        produtos_sum = dataset.sum()\n        title=f\"Product by search\"\n        plt.pie(produtos_sum, labels=list_product, \n        autopct='%1.1f%%', startangle=90, pctdistance=0.85)\n        centre_circle = plt.Circle((0,0),0.65,fc='white')\n        fig = plt.gcf() \n        fig.gca().add_artist(centre_circle)\n        plt.axis('equal')\n        plt.tight_layout()\n    \n    plt.axis('equal')  \n    plt.title(title)\n    plt.show()","d9a9457f":"frequency_total(\"2017\")","545fae18":"frequency_total(\"2018\")","d73aa621":"frequency_total(\"2020\")","ee4e4d96":"for col in dataset.columns:\n    frequencia = 7\n    result = sm.tsa.seasonal_decompose(dataset[col].dropna(),\n                                        period=frequencia)\n    fig = result.plot()\n    fig.set_figheight(9)\n    fig.set_figwidth(14)\n    plt.show()","9504fa41":"y = dataset.resample('MS').mean()\nparametros = {\n                \"order\": (1, 1, 1),\n                \"seas_order\": (1, 1, 0, 12)\n             }\n\npredict_model = []\nfor col in y.columns:\n    print(f\"Training SARIMAX model ... product: {col}\")\n    modelo = sm.tsa.statespace.SARIMAX(y[col],\n                                order=parametros[\"order\"],\n                                seasonal_order=parametros[\"seas_order\"],\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\n\n    results = modelo.fit()\n    print(results.summary().tables[1])\n    results.plot_diagnostics(figsize=(16, 8))\n    predict_model.append(results)","31c6a693":"predict_after = '2020-01-01'\n\ndef bar_graph_porcent(predict_i):\n    np_array = np.array(predict_i['upper'])\n    variation, data_var, colors_var = (list(), list(), list())\n    \n    for index in range(1, len(np_array)):\n        last_month = np_array[index - 1]\n        current_month = np_array[index]\n        \n        data_var.append(predict_i.index[index])\n        \n        porcent_var = (current_month - last_month) * 100 \/ last_month\n        variation.append(porcent_var)\n        \n        if porcent_var < 0:\n            colors_var.append('red')\n        else:\n            colors_var.append('green')\n        \n    ind = np.arange(len(variation))  \n    width = 0.60\n    \n    fig, ax = plt.subplots(figsize=(12, 7))\n    rects1 = ax.bar(ind - width\/2, variation, width)\n    ax.axhline(y=0, color='black', linestyle='-')\n    \n    for i, data in zip(ax.patches, variation):\n        ax.text(i.get_x()-.03, i.get_height()+.5, \"%.2f\" % data + \"%\", fontsize=15,\n                color='black')\n    \n    for k in range(len(colors_var)):\n        rects1[k].set_color(colors_var[k])\n\n    ax.set_ylabel('Porcent predict - comparision by month')\n    ax.set_xticks(ind)\n    ax.set_xticklabels(data_var, rotation=90)\n    ax.legend()\n    \n    \nfor model_i, col in zip(predict_model, list_product):\n    predict_m = model_i.get_prediction(start=pd.to_datetime(predict_after), dynamic=False)\n    predict_i = predict_m.conf_int()\n    \n    test_model = y['2014':][col].plot(label='real', color='green')\n    \n    predict_m.predicted_mean.plot(ax=test_model, color='red', label='predict', alpha=.9, figsize=(20, 7))\n    \n    test_model.fill_between(predict_i.index, predict_i.iloc[:, 0], predict_i.iloc[:, 1], color='k', alpha=.2)\n    \n    predict_i.columns = ['low', 'upper']\n    print(predict_i)\n    bar_graph_porcent(predict_i)\n    test_model.set_xlabel('data')\n    test_model.set_ylabel('frequecy')\n    plt.grid()\n    plt.legend()\n    plt.title(f\"Predict model: {col}\")\n    plt.show()","7551acad":"# Predict Trends using Google Searchs ","00ab4396":"## Tendency using Sarimax Model:\nBy definition, tendency is what makes someone follow a certain path or act in a certain way; predisposition, propensity.\n\nTo predict future falls or increased searches for a product, we use the SARIMAX model. SARIMAX is a statistical model widely used in time series, which is our case. SARIMAX has already been used for several purposes, which is common in the financial market for forecasting inflation.\n\nIf you want to know more about SARIMAX, we have separated a very interesting scientific article on:https:\/\/www.researchgate.net\/publication\/313251716_Modelling_the_demand_for_cement_The_case_of_Poland_and_Spain\n\nAbout the Python statsmodels library:\nstatsmodels is a Python module that provides classes and functions for estimating many different statistical models, as well as for performing statistical tests and exploring statistical data. An extensive list of outcome statistics is available for each estimator. The results are tested against existing statistical packages to ensure they are correct.\n\nhttps:\/\/www.statsmodels.org\/dev\/examples\/notebooks\/generated\/statespace_sarimax_stata.html","0315db6d":"## Libraries used to implement the solution\nList of the resources we use to design this solution:\n\n- pandas: https:\/\/pandas.pydata.org\/\n- pytrends: https:\/\/matplotlib.org\/\n- matplotlib: https:\/\/matplotlib.org\/\n- statsmodels: https:\/\/www.statsmodels.org\/stable\/index.html\n- numpy: https:\/\/numpy.org\/","bc103abc":"## Testing Sarimax Model","612bef40":"## Total search frequency","d4c85f5e":"## Visualizing Google Trends dataset","cdad2ac2":"<img src=\"https:\/\/camo.githubusercontent.com\/f8b517246281add898287d629b4cbda295686248\/68747470733a2f2f676f6f676c65646973636f766572792e636f6d2f77702d636f6e74656e742f75706c6f6164732f676f6f676c652d73686f7070696e672e6a7067\">","dbe6b6fb":"## Comparing search by items","ef5628fd":"## Downloading dataset","6aff2a4e":"## Describe dataset content","efad8bb2":"## Sarimax Model Training\n\nfrequency parameter:\n\n- period = 365, for trends of the year\n- period = 30, for month trends\n- period = 7, for week's trends","1fd9fff1":"#### **My other projects**:\n- Multilayer Perceptron from scratch: https:\/\/www.kaggle.com\/vitorgamalemos\/multilayer-perceptron-from-scratch\n- Probability Theory Explanation: https:\/\/www.kaggle.com\/vitorgamalemos\/probability-theory-exploration\n- Ensemble using Adaboost (XGB + RF): https:\/\/www.kaggle.com\/vitorgamalemos\/ensemble-adaboost-xgb-rf-in-titanic-survived\n- Spam detect using LSTM: https:\/\/www.kaggle.com\/vitorgamalemos\/lstm-sms-spam-detect\n- Benford using real example: https:\/\/www.kaggle.com\/vitorgamalemos\/testing-benfords-law-in-a-real-example","a9becb09":"## Total search frequency by year"}}