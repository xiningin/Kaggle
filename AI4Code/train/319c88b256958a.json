{"cell_type":{"7c6a91e5":"code","568e5089":"code","685654c5":"code","d5ef680d":"code","eb500a30":"code","2ed67948":"code","ed9937b0":"code","a778c58b":"code","c4dcf4e9":"code","78026ea8":"code","5c610aef":"code","9ed666e7":"code","aaf8cdf5":"code","ccd20b57":"code","8f88213a":"code","1082d1ef":"code","9e27a827":"code","c5874d22":"code","300df597":"code","9b2595b3":"code","5b366908":"code","fd7c502f":"code","1489c9b1":"code","e30434b0":"code","51d2cd6f":"code","d22223f1":"code","79254168":"code","b095201b":"code","0627de55":"code","bbea21ac":"code","e56dd6a3":"code","9ac300d2":"code","aa00bfba":"code","f609ad60":"code","e75a63b7":"code","2d0f8b15":"code","0bcfa9ba":"code","7271a66c":"code","5f28a5da":"code","9e3b7d97":"code","bc5a0ddf":"code","43771b69":"code","f8ed504b":"code","91306a15":"code","a7bb8ee1":"code","c911c4c2":"code","b73d37cb":"code","3433e9f7":"code","fc8d7740":"code","e3165d79":"code","7f6623ca":"code","e6359394":"code","0ac7df90":"code","8cd1bb0b":"code","85c78d21":"code","8981659b":"code","7649db6e":"code","a85ac7e5":"code","c1f57594":"code","7fc98358":"code","04b7c5ed":"code","ed4dc0ac":"code","1f2c4a69":"code","d56c1781":"code","9c0ea92a":"code","5262f1f2":"code","f9dda00c":"code","b6e57cc2":"code","87493ff3":"markdown","6fbdd0b2":"markdown","15008a39":"markdown","4cbfde68":"markdown","06a1d994":"markdown","9690f58d":"markdown","c1d944aa":"markdown","a955ced4":"markdown","e4b19fa4":"markdown","1efe51c0":"markdown"},"source":{"7c6a91e5":"# import library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame, Series\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import norm\nfrom scipy import stats\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm.notebook import tqdm as tqdm\n#from tqdm import tqdm_notebook as tqdm\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools, subplots\n\nfrom sklearn.ensemble import GradientBoostingClassifier","568e5089":"# define functions\ndef bar_hor(df, col, title, color, w=None, h=None, lm=0, limit=100, return_trace=False, rev=False, xlb = False):\n    \"\"\"\n    \u6a2a\u5411\u304d\u68d2\u30b0\u30e9\u30d5\u4f5c\u6210\u95a2\u6570\n    df:  \n    col: \n    title: \n    color: \n    w=None: \n    h=None: \n    lm=0: \n    limit=100: \n    return_trace=False: \n    rev=False: \n    xlb = False:\n    \"\"\"\n    cnt_srs = df[col].value_counts()\n    yy = cnt_srs.head(limit).index[::-1] \n    xx = cnt_srs.head(limit).values[::-1] \n    if rev:\n        yy = cnt_srs.tail(limit).index[::-1] \n        xx = cnt_srs.tail(limit).values[::-1] \n    if xlb:\n        trace = go.Bar(y=xlb, x=xx, orientation = 'h', marker=dict(color=color))\n    else:\n        trace = go.Bar(y=yy, x=xx, orientation = 'h', marker=dict(color=color))\n    if return_trace:\n        return trace \n    layout = dict(title=title, margin=dict(l=lm), width=w, height=h)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)\n\ndef bar_hor_noagg(x, y, title, color, w=None, h=None, lm=0, limit=100, rt=False):\n    trace = go.Bar(y=x, x=y, orientation = 'h', marker=dict(color=color))\n    if rt:\n        return trace\n    layout = dict(title=title, margin=dict(l=lm), width=w, height=h)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)\n\n\ndef bar_ver_noagg(x, y, title, color, w=None, h=None, lm=0, rt = False):\n    trace = go.Bar(y=y, x=x, marker=dict(color=color))\n    if rt:\n        return trace\n    layout = dict(title=title, margin=dict(l=lm), width=w, height=h)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)\n    \ndef gp(col, title):\n    \"\"\"\n    \u30b0\u30eb\u30fc\u30d7\u5316\u68d2\u30b0\u30e9\u30d5\u3092\u8868\u793a\n    col: \u8868\u793a\u3059\u308b\u5217\n    title: \u56f3\u306e\u30bf\u30a4\u30c8\u30eb\n    \"\"\"\n    df1 = df_train[df_train[\"loan_condition\"] == 1]\n    df0 = df_train[df_train[\"loan_condition\"] == 0]\n    a1 = df1[col].value_counts()\n    b1 = df0[col].value_counts()\n\n    trace1 = go.Bar(x=a1.index, y=a1.values, name='Target : 1', marker=dict(color=\"#44ff54\"))\n    trace2 = go.Bar(x=b1.index, y=b1.values, name='Target : 0', marker=dict(color=\"#ff4444\"))\n\n    data = [trace1, trace2]\n    layout = go.Layout(barmode='group', height=300, title = title)\n\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig, filename='grouped-bar')\n    \n    #\u6b20\u640d\u5024\u306e\u78ba\u8a8d\ndef null_values(df):\n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        print (\"Dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        return mis_val_table_ren_columns","685654c5":"# Read csv files\n#df_train = pd.read_csv('\/kaggle\/input\/homework-for-students5\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\ndf_train = pd.read_csv('\/kaggle\/input\/homework-for-students5\/train.csv', index_col=0)\ndf_test = pd.read_csv('\/kaggle\/input\/homework-for-students5\/test.csv', index_col=0)","d5ef680d":"train_row, train_column = df_train.shape\ntest_row, test_column = df_test.shape\n\nprint(\"Training Column:\", train_column,\"Test Column:\", test_column, sep='\u3000')\nprint(\"Training Row:\", train_row,\"Test Row:\", test_row, sep='\u3000')","eb500a30":"# Test\u30c7\u30fc\u30bf\u306b\u306f2016\u5e74\u3057\u304b\u306a\u3044\n#issue_d\u3092yyyy\u3092\u62bd\u51fa\n# df_train['issue_d_y'] = pd.to_datetime(df_train['issue_d']).dt.year.astype(str)\n# df_test['issue_d_y'] = pd.to_datetime(df_test['issue_d']).dt.year.astype(str)","2ed67948":"# gp('issue_d_y', # \u8868\u793a\u3059\u308b\u5217\u540d\n#    'Distribution of Target with grade' # \u56f3\u306e\u30bf\u30a4\u30c8\u30eb\n#   ) ","ed9937b0":"# #\u5e74\u3054\u3068\u306bloan_condition\u306e\u5272\u5408\u306b\u9055\u3044\u306f\u306a\u3044\u306e\u3067\u3001\u65e5\u4ed8\u5909\u6570\u3092\u524a\u9664\n# df_train.drop(['issue_d', 'issue_d_y'], axis=1, inplace=True)\n# df_test.drop(['issue_d', 'issue_d_y'], axis=1, inplace=True)","a778c58b":"bar_hor(df_train, # \u8868\u793a\u3059\u308b\u30c7\u30fc\u30bf \n        \"loan_condition\", # \u8868\u793a\u3059\u308b\u5217\u540d\n        \"Distribution of Target Variable\" , # \u56f3\u306e\u30bf\u30a4\u30c8\u30eb\n        [\"#44ff54\", '#ff4444'], # \u68d2\u30b0\u30e9\u30d5\u306e\u8272\n        h=400, # \u56f3\u306e\u9ad8\u3055\n        w=800, # \u56f3\u306e\u5e45\n        lm=100, # ?\n        xlb = ['Target : 1','Target : 0'] # \u5404\u30d0\u30fc\u306e\u8aac\u660e\n       )","c4dcf4e9":"# numerical_feats = df_train.iloc[:, :-1].dtypes[df_train.dtypes != \"object\"].index\n# categorical_feats = df_train.iloc[:, :-1].dtypes[df_train.dtypes == \"object\"].index\n# numerical_feats, categorical_feats","78026ea8":"# for catg in list(categorical_feats) :\n#     print(df_train[catg].value_counts())\n#     print('#'*50)","5c610aef":"# for catg in list(categorical_feats) :\n#     print(df_test[catg].value_counts())\n#     print('#'*50)","9ed666e7":"# tr1 = bar_hor(df_train, \"grade\", \"Distribution of grade Variable\" ,\"#639af2\", w=700, lm=100, return_trace= True) \n# tr2 = bar_hor(df_train, \"sub_grade\", \"Distribution of sub_grade Variable\" ,\"#639af2\", w=700, lm=100, return_trace = True) \n\n# # \u56f3\u306e\u6574\u5f62\u30fb\u8868\u793a\n# fig = tools.make_subplots(rows=1, cols=2, print_grid=False, subplot_titles = ['grade' , 'sub_grade'])\n# fig.append_trace(tr1, 1, 1);\n# fig.append_trace(tr2, 1, 2);\n\n# fig['layout'].update(height=400, showlegend=False, margin=dict(b=100));\n# iplot(fig);","aaf8cdf5":"# gp('grade', # \u8868\u793a\u3059\u308b\u5217\u540d\n#    'Distribution of Target with grade' # \u56f3\u306e\u30bf\u30a4\u30c8\u30eb\n#   ) \n# gp('sub_grade', 'Distribution of Target with sub_grade') # \u5951\u7d04\u30bf\u30a4\u30d7\u30fb\u76ee\u7684\u5909\u6570\u306e\u30b0\u30eb\u30fc\u30d7\u5316\u68d2","ccd20b57":"# tr1 = bar_hor(df_train, \"emp_title\", \"Distribution of emp_title Variable\" ,\"#639af2\", w=700, lm=100, return_trace = True) \n# tr2 = bar_hor(df_train, \"emp_length\", \"Distribution of emp_length Variable\" ,\"#639af2\", w=700, lm=100, return_trace = True) \n\n# fig = subplots.make_subplots(rows=1, cols=2, print_grid=False, subplot_titles = ['emp_title' , 'emp_length'])\n# fig.append_trace(tr1, 1, 1);\n# fig.append_trace(tr2, 1, 2);\n\n# fig['layout'].update(height=400, showlegend=False, margin=dict(b=100));\n# iplot(fig);\n\n# gp('emp_length', 'Distribution of Target with emp_length') # \u5951\u7d04\u30bf\u30a4\u30d7\u30fb\u76ee\u7684\u5909\u6570\u306e\u30b0\u30eb\u30fc\u30d7\u5316\u68d2\u30b0\u30e9\u30d5","8f88213a":"# temp1 = 'purpose'\n# temp2 = 'initial_list_status'\n\n# tr1 = bar_hor(df_train, temp1, \"Distribution of\" + temp1 + \"Variable\" ,\"#639af2\", w=700, lm=100, return_trace = True) \n# tr2 = bar_hor(df_train, temp2, \"Distribution of\" + temp2 + \"Variable\" ,\"#639af2\", w=700, lm=100, return_trace = True) \n\n# fig = subplots.make_subplots(rows=1, cols=2, print_grid=False, subplot_titles = [temp1 , temp2])\n# fig.append_trace(tr1, 1, 1);\n# fig.append_trace(tr2, 1, 2);\n\n# fig['layout'].update(height=400, showlegend=False, margin=dict(b=100));\n# iplot(fig);\n\n# gp(temp1, 'Distribution of Target with' + temp1) # \u5951\u7d04\u30bf\u30a4\u30d7\u30fb\u76ee\u7684\u5909\u6570\u306e\u30b0\u30eb\u30fc\u30d7\u5316\u68d2\u30b0\u30e9\u30d5\n# gp(temp2, 'Distribution of Target with' + temp2) # \u5951\u7d04\u30bf\u30a4\u30d7\u30fb\u76ee\u7684\u5909\u6570\u306e\u30b0\u30eb\u30fc\u30d7\u5316\u68d2\u30b0\u30e9\u30d5","1082d1ef":"#df_train.describe()","9e27a827":"#df_test.describe()","c5874d22":"# temp1 = 'loan_amnt'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","300df597":"# temp1 = 'installment'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","9b2595b3":"# temp1 = 'annual_inc'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","5b366908":"# temp1 = 'dti'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","fd7c502f":"# temp1 = 'mths_since_last_delinq'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","1489c9b1":"# temp1 = 'mths_since_last_record'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","e30434b0":"# temp1 = 'open_acc'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","51d2cd6f":"# temp1 = 'revol_bal'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","d22223f1":"# temp1 = 'revol_util'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","79254168":"# temp1 = 'total_acc'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","b095201b":"# temp1 = 'mths_since_last_major_derog'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","0627de55":"# temp1 = 'tot_cur_bal'\n# plt.figure(figsize=(12,5))\n# plt.title(\"Distribution of \" + temp1)\n# ax = sns.distplot(df_train[temp1])","bbea21ac":"# \u30c7\u30fc\u30bf\u306e\u5206\u5272\nY_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = df_test","e56dd6a3":"#X_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\n#X_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_train.drop(['issue_d', 'emp_title', 'acc_now_delinq', 'home_ownership'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title', 'acc_now_delinq', 'home_ownership'], axis=1, inplace=True)","9ac300d2":"# purpose\u3092\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\ncol='purpose'\n\nsummary = X_train[col].value_counts()\nenc_train = X_train[col].map(summary)\nsummary = X_test[col].value_counts()\nenc_test = X_test[col].map(summary)\nX_train['purpose_c'] = enc_train\nX_test['purpose_c'] = enc_test","aa00bfba":"#emp_length\u3092\u6570\u5024\u306b\u5909\u63db\u3057\u305f\u5909\u6570\u3092\u4f5c\u6210\nX_train.loc[X_train['emp_length'] == '< 1 year',   'emp_length_num'] = 0.8\nX_train.loc[X_train['emp_length'] == '1 years',    'emp_length_num'] = 1\nX_train.loc[X_train['emp_length'] == '2 years',    'emp_length_num'] = 2\nX_train.loc[X_train['emp_length'] == '3 years',    'emp_length_num'] = 3\nX_train.loc[X_train['emp_length'] == '4 years',    'emp_length_num'] = 4\nX_train.loc[X_train['emp_length'] == '5 years',    'emp_length_num'] = 5\nX_train.loc[X_train['emp_length'] == '6 years',    'emp_length_num'] = 6\nX_train.loc[X_train['emp_length'] == '7 years',    'emp_length_num'] = 7\nX_train.loc[X_train['emp_length'] == '8 years',    'emp_length_num'] = 8\nX_train.loc[X_train['emp_length'] == '9 years',    'emp_length_num'] = 9\nX_train.loc[X_train['emp_length'] == '10 years',   'emp_length_num'] = 10\nX_train.loc[X_train['emp_length'] == '10+ years',  'emp_length_num'] = 15\n\nX_test.loc[X_test['emp_length'] == '< 1 year',   'emp_length_num'] = 0.8\nX_test.loc[X_test['emp_length'] == '1 years',    'emp_length_num'] = 1\nX_test.loc[X_test['emp_length'] == '2 years',    'emp_length_num'] = 2\nX_test.loc[X_test['emp_length'] == '3 years',    'emp_length_num'] = 3\nX_test.loc[X_test['emp_length'] == '4 years',    'emp_length_num'] = 4\nX_test.loc[X_test['emp_length'] == '5 years',    'emp_length_num'] = 5\nX_test.loc[X_test['emp_length'] == '6 years',    'emp_length_num'] = 6\nX_test.loc[X_test['emp_length'] == '7 years',    'emp_length_num'] = 7\nX_test.loc[X_test['emp_length'] == '8 years',    'emp_length_num'] = 8\nX_test.loc[X_test['emp_length'] == '9 years',    'emp_length_num'] = 9\nX_test.loc[X_test['emp_length'] == '10 years',   'emp_length_num'] = 10\nX_test.loc[X_test['emp_length'] == '10+ years',  'emp_length_num'] = 15\n\n#\u6b20\u640d\u88dc\u5b8c\nX_train['emp_length_num'] = X_train['emp_length_num'].fillna(-9999)\nX_test['emp_length_num'] = X_test['emp_length_num'].fillna(-9999)","f609ad60":"#sub_grade\u306e\u6570\u5024\u90e8\u5206\u3092\u53d6\u5f97\u3057\u3001\u6570\u5024\u306b\u5909\u63db\nX_train['sub_grade'] = X_train['sub_grade'].replace('A', '', regex=True).replace('B', '', regex=True).replace(\"C\", '', regex=True).replace(\"D\", '', regex=True).replace(\"E\", '', regex=True).replace(\"F\", '', regex=True).replace(\"G\", '', regex=True)\nX_train['sub_grade'] = X_train['sub_grade'].astype(\"float32\")\nX_train['sub_grade'] = X_train['sub_grade'] ** 0.5\n\nX_test['sub_grade'] = X_test['sub_grade'].replace('A', '', regex=True).replace('B', '', regex=True).replace(\"C\", '', regex=True).replace(\"D\", '', regex=True).replace(\"E\", '', regex=True).replace(\"F\", '', regex=True).replace(\"G\", '', regex=True)\nX_test['sub_grade'] = X_test['sub_grade'].astype(\"float32\")\nX_test['sub_grade'] = X_test['sub_grade'] ** 0.5","e75a63b7":"#grade\u3092\u6570\u5024\u306b\u5909\u63db\nX_train.loc[X_train['grade'] == 'A', 'grade'] = 1\nX_train.loc[X_train['grade'] == 'B', 'grade'] = 2\nX_train.loc[X_train['grade'] == 'C', 'grade'] = 3\nX_train.loc[X_train['grade'] == 'D', 'grade'] = 4\nX_train.loc[X_train['grade'] == 'E', 'grade'] = 5\nX_train.loc[X_train['grade'] == 'F', 'grade'] = 6\nX_train.loc[X_train['grade'] == 'G', 'grade'] = 7\nX_train['grade'] = X_train['grade'].astype(\"float32\")\n\nX_test.loc[X_test['grade'] == 'A', 'grade'] = 1\nX_test.loc[X_test['grade'] == 'B', 'grade'] = 2\nX_test.loc[X_test['grade'] == 'C', 'grade'] = 3\nX_test.loc[X_test['grade'] == 'D', 'grade'] = 4\nX_test.loc[X_test['grade'] == 'E', 'grade'] = 5\nX_test.loc[X_test['grade'] == 'F', 'grade'] = 6\nX_test.loc[X_test['grade'] == 'G', 'grade'] = 7\nX_test['grade'] = X_test['grade'].astype(\"float32\")","2d0f8b15":"#grade\u00d7subgrade\u3092\u8a08\u7b97\uff08\u4ea4\u4e92\u4f5c\u7528\u7684\u306a\uff09\nX_train['g_gsub'] = X_train['grade'] * X_train['sub_grade']\nX_test['g_gsub']  = X_test['grade']  * X_test['sub_grade']","0bcfa9ba":"#zip_code\u306f2\u6587\u5b57\u76ee\u307e\u3067\u3092\u62bd\u51fa\nX_train['zip_code']=X_train['zip_code'].str[:2]\nX_test['zip_code']=X_test['zip_code'].str[:2]","7271a66c":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","5f28a5da":"#\u5bfe\u6570\u5909\u63db\nX_train['loan_amnt']   = X_train['loan_amnt'].apply(np.log1p)\nX_train['annual_inc']  = X_train['annual_inc'].apply(np.log1p)\nX_train['open_acc']    = X_train['open_acc'].apply(np.log1p)\nX_train['revol_bal']   = X_train['revol_bal'].apply(np.log1p) \nX_train['tot_coll_amt'] = X_train['tot_coll_amt'].apply(np.log1p)\nX_train['total_acc']   = X_train['total_acc'].apply(np.log1p)\nX_train['tot_cur_bal'] = X_train['tot_cur_bal'].apply(np.log1p)\n#X_train['inq_last_6mths'] = X_train['inq_last_6mths'].apply(np.log1p)\n\nX_test['loan_amnt'] = X_test['loan_amnt'].apply(np.log1p)\nX_test['annual_inc']  = X_test['annual_inc'].apply(np.log1p)\nX_test['open_acc']    = X_test['open_acc'].apply(np.log1p)\nX_test['revol_bal']   = X_test['revol_bal'].apply(np.log1p) \nX_test['tot_coll_amt'] = X_test['tot_coll_amt'].apply(np.log1p)\nX_test['total_acc']   = X_test['total_acc'].apply(np.log1p)\nX_test['tot_cur_bal'] = X_test['tot_cur_bal'].apply(np.log1p)\n#X_test['inq_last_6mths'] = X_test['inq_last_6mths'].apply(np.log1p)","9e3b7d97":"#\u304a\u91d1\u306b\u95a2\u3059\u308b\u3082\u306e\u306f\u4e2d\u592e\u5024\u3067\u88dc\u5b8c\nX_train['loan_amnt']    = X_train['loan_amnt'].fillna(X_train['loan_amnt'].median())\nX_train['installment']  = X_train['installment'].fillna(X_train['installment'].median())\nX_train['annual_inc']   = X_train['annual_inc'].fillna(X_train['annual_inc'].median())\nX_train['dti']          = X_train['dti'].fillna(X_train['dti'].median())\nX_train['revol_bal']    = X_train['revol_bal'].fillna(X_train['revol_bal'].median())\nX_train['total_acc']    = X_train['total_acc'].fillna(X_train['total_acc'].median())\nX_train['tot_coll_amt'] = X_train['tot_coll_amt'].fillna(X_train['tot_coll_amt'].median())\nX_train['tot_cur_bal']  = X_train['tot_cur_bal'].fillna(X_train['tot_cur_bal'].median())\n\nX_test['loan_amnt']    = X_test['loan_amnt'].fillna(X_test['loan_amnt'].median())\nX_test['installment']  = X_test['installment'].fillna(X_test['installment'].median())\nX_test['annual_inc']   = X_test['annual_inc'].fillna(X_test['annual_inc'].median())\nX_test['dti']          = X_test['dti'].fillna(X_test['dti'].median())\nX_test['revol_bal']    = X_test['revol_bal'].fillna(X_test['revol_bal'].median())\nX_test['total_acc']    = X_test['total_acc'].fillna(X_test['total_acc'].median())\nX_test['tot_coll_amt'] = X_test['tot_coll_amt'].fillna(X_test['tot_coll_amt'].median())\nX_test['tot_cur_bal']  = X_test['tot_cur_bal'].fillna(X_test['tot_cur_bal'].median())","bc5a0ddf":"# \u52e4\u52d9\u5e74\u53ce\u304c\u9577\u3044\u306e\u306b\u53ce\u5165\u304c\u5c11\u306a\u3044\uff1f\nX_train['inc_length'] = X_train['annual_inc'] \/ X_train['emp_length']\nX_test['inc_length']  = X_test['annual_inc']  \/ X_test['emp_length']","43771b69":"#\u6b20\u6e2c\u5024\u88dc\u5b8c\nX_train.fillna(-9999, inplace=True)\nX_test.fillna(-9999, inplace=True)","f8ed504b":"#X_train['loan_amnt_c'] = 0\n#X_train.loc[X_train['loan_amnt'] == X_train['loan_amnt'].max(), 'loan_amnt_c'] = 1\n#X_test['loan_amnt_c'] = 0\n#X_test.loc[X_test['loan_amnt'] == X_test['loan_amnt'].max(), 'loan_amnt_c'] = 1","91306a15":"# X_train.drop(['sub_grade', 'emp_length', 'purpose'], axis=1, inplace=True)\n# X_test.drop(['sub_grade', 'emp_length', 'purpose'], axis=1, inplace=True)","a7bb8ee1":"# X_train.drop(['purpose', 'emp_length'], axis=1, inplace=True)\n# X_test.drop(['purpose', 'emp_length'], axis=1, inplace=True)","c911c4c2":"X_train['group_loan_med'] = X_train.groupby(\"grade\")['loan_amnt'].transform(np.median)\nX_train['group_inc_med'] = X_train.groupby(\"grade\")['annual_inc'].transform(np.median)\nX_train['group_inc_max'] = X_train.groupby(\"grade\")['annual_inc'].transform(np.max)\nX_train['group_bal_med'] = X_train.groupby(\"grade\")['tot_cur_bal'].transform(np.median)\nX_train['group_bal_min'] = X_train.groupby(\"grade\")['tot_cur_bal'].transform(np.min)\nX_train['group_bal_max'] = X_train.groupby(\"grade\")['tot_cur_bal'].transform(np.max)\n\nX_test['group_loan_med'] = X_test.groupby(\"grade\")['loan_amnt'].transform(np.median)\nX_test['group_inc_med'] = X_test.groupby(\"grade\")['annual_inc'].transform(np.median)\nX_test['group_inc_max'] = X_test.groupby(\"grade\")['annual_inc'].transform(np.max)\nX_test['group_bal_med'] = X_test.groupby(\"grade\")['tot_cur_bal'].transform(np.median)\nX_test['group_bal_min'] = X_test.groupby(\"grade\")['tot_cur_bal'].transform(np.min)\nX_test['group_bal_max'] = X_test.groupby(\"grade\")['tot_cur_bal'].transform(np.max)","b73d37cb":"#X_test.groupby(\"grade\")['loan_amnt'].describe()","3433e9f7":"# \u6b20\u6e2c\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\nmiss_values = null_values(X_train)\nmiss_values.head(20)","fc8d7740":"miss_values = null_values(X_test)\nmiss_values.head(20)","e3165d79":"from sklearn.model_selection import train_test_split \nimport lightgbm as lgb","7f6623ca":"x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=18)\nlgb_train = lgb.Dataset(data=x_train, label=y_train)\nlgb_eval = lgb.Dataset(data=x_val, label=y_val)","e6359394":"#\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3000\u21d2\u3000\u4f5c\u6210\u4e2d\n\n# from optuna.integration import lightgbm as lgb\n# param = {\n#         'objective': 'binary',\n#         'metric': 'auc',\n#         'boosting_type': 'gbdt',\n#     }\n\n# best = lgb.train(param, \n#                  lgb_train,\n#                  valid_sets=lgb_eval,\n#                  early_stopping_rounds=80)","0ac7df90":"# best.best_score\n\n# defaultdict(collections.OrderedDict,\n#             {'valid_0': OrderedDict([('auc', 0.708205349813691)])})","8cd1bb0b":"# best.best_iteration\n\n# 985","85c78d21":"# best.params\n\n# {'objective': 'binary',\n#  'metric': 'auc',\n#  'boosting_type': 'gbdt',\n#  'feature_pre_filter': False,\n#  'lambda_l1': 1.8249666755267036e-08,\n#  'lambda_l2': 9.034477720637065,\n#  'num_leaves': 7,\n#  'feature_fraction': 0.6,\n#  'bagging_fraction': 0.6849349095352429,\n#  'bagging_freq': 2,\n#  'min_child_samples': 20}","8981659b":"# lightGBM\u306e\u5b9f\u884c\nparams = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n          'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 5000, 'verbose': 0 ,\n          'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n          'min_split_gain':.01, 'min_child_weight':1}\nmodel = lgb.train(params, lgb_train, valid_sets=lgb_eval, early_stopping_rounds=150, verbose_eval=200)","7649db6e":"#lgb.plot_importance(model, figsize=(12, 50));","a85ac7e5":"cols = list(X_train.columns)         # \u7279\u5fb4\u91cf\u540d\u306e\u30ea\u30b9\u30c8\n\n# \u7279\u5fb4\u91cf\u91cd\u8981\u5ea6\u306e\u7b97\u51fa\u65b9\u6cd5 'gain'(\u63a8\u5968) : \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u640d\u5931\u306e\u6e1b\u5c11\u91cf\u3092\u8a55\u4fa1\nf_importance = np.array(model.feature_importance(importance_type='gain')) # \u7279\u5fb4\u91cf\u91cd\u8981\u5ea6\u306e\u7b97\u51fa \/\/\nf_importance = f_importance \/ np.sum(f_importance) # \u6b63\u898f\u5316(\u5fc5\u8981\u306a\u3044\u5834\u5408\u306f\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8)\ndf_importance = pd.DataFrame({'feature':cols, 'importance':f_importance})\ndf_importance = df_importance.sort_values('importance', ascending=False) # \u964d\u9806\u30bd\u30fc\u30c8\ndisplay(df_importance)","c1f57594":"#y_pred = model.predict(X_test.iloc[:, use_col])\ny_pred = model.predict(X_test)\ny_pred ","7fc98358":"# XGBoost\u306e\u5b9f\u884c(max_depth = 4)\nimport xgboost as xgb\n\ndtrain = xgb.DMatrix(x_train, label=y_train)\ndval = xgb.DMatrix(x_val, label=y_val)\n\nxgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'max_depth':4,\n}\n\nevals = [(dtrain, 'train'), (dval, 'eval')]\nevals_result = {}\nbst = xgb.train(xgb_params,\n                dtrain,\n                num_boost_round=1000,\n                early_stopping_rounds=20,\n                evals=evals,\n                evals_result=evals_result,\n               )\n\ny_pred_proba = bst.predict(dval)\n\ntrain_metric = evals_result['train']['auc']\nplt.plot(train_metric, label='train auc')\neval_metric = evals_result['eval']['auc']\nplt.plot(eval_metric, label='eval auc')\nplt.grid()\nplt.legend()\nplt.xlabel('rounds')\nplt.ylabel('auc')\nplt.show()","04b7c5ed":"dtest = xgb.DMatrix(X_test)\ny_pred_proba_4 = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\ny_pred_proba_4","ed4dc0ac":"# XGBoost\u306e\u5b9f\u884c(max_depth = 5)\nimport xgboost as xgb\n\ndtrain = xgb.DMatrix(x_train, label=y_train)\ndval = xgb.DMatrix(x_val, label=y_val)\n\nxgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'max_depth':5,\n}\n\nevals = [(dtrain, 'train'), (dval, 'eval')]\nevals_result = {}\nbst = xgb.train(xgb_params,\n                dtrain,\n                num_boost_round=1000,\n                early_stopping_rounds=20,\n                evals=evals,\n                evals_result=evals_result,\n               )\n\ny_pred_proba = bst.predict(dval)\n\ntrain_metric = evals_result['train']['auc']\nplt.plot(train_metric, label='train auc')\neval_metric = evals_result['eval']['auc']\nplt.plot(eval_metric, label='eval auc')\nplt.grid()\nplt.legend()\nplt.xlabel('rounds')\nplt.ylabel('auc')\nplt.show()","1f2c4a69":"dtest = xgb.DMatrix(X_test)\ny_pred_proba_5 = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\ny_pred_proba_5","d56c1781":"# XGBoost\u306e\u5b9f\u884c(max_depth = 6)\nimport xgboost as xgb\n\ndtrain = xgb.DMatrix(x_train, label=y_train)\ndval = xgb.DMatrix(x_val, label=y_val)\n\nxgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'max_depth':6,\n}\n\nevals = [(dtrain, 'train'), (dval, 'eval')]\nevals_result = {}\nbst = xgb.train(xgb_params,\n                dtrain,\n                num_boost_round=1000,\n                early_stopping_rounds=20,\n                evals=evals,\n                evals_result=evals_result,\n               )\n\ny_pred_proba = bst.predict(dval)\n\ntrain_metric = evals_result['train']['auc']\nplt.plot(train_metric, label='train auc')\neval_metric = evals_result['eval']['auc']\nplt.plot(eval_metric, label='eval auc')\nplt.grid()\nplt.legend()\nplt.xlabel('rounds')\nplt.ylabel('auc')\nplt.show()","9c0ea92a":"dtest = xgb.DMatrix(X_test)\ny_pred_proba_6 = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\ny_pred_proba_6","5262f1f2":"y_pred_proba = (y_pred_proba_4 + y_pred_proba_5 + y_pred_proba_6)\/3","f9dda00c":"y_pred_mix = (y_pred * 0.7) + (y_pred_proba * 0.3)\ny_pred_mix","b6e57cc2":"submission = pd.read_csv('\/kaggle\/input\/homework-for-students5\/sample_submission.csv', index_col=0)\nsubmission.loan_condition = y_pred_mix \nsubmission.to_csv('.\/submission.csv')\nsubmission.head()","87493ff3":"# \u30e2\u30c7\u30eb\u306e\u4f5c\u6210","6fbdd0b2":"# \u95a2\u6570\u306e\u5b9a\u7fa9\u3084\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f","15008a39":"# Library\u306e\u6e96\u5099","4cbfde68":"**XGBoost**","06a1d994":"**Group by \u3067\u7279\u5fb4\u91cf\u3092\u4f5c\u6210**","9690f58d":"# \u30e2\u30c7\u30eb\u4f5c\u6210","c1d944aa":"**\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092\u6570\u5024\u5909\u6570\u306b**","a955ced4":"# EDA\u306e\u5b9f\u65bd","e4b19fa4":"**Count Encoding**","1efe51c0":"**Light GM**"}}