{"cell_type":{"4e567880":"code","470033e5":"code","2c272623":"code","6145338c":"code","018bd9e1":"code","dabc39c8":"code","fb9bed2a":"code","0b412ec1":"markdown","87f387f0":"markdown","5a9f4cb2":"markdown","518e5e4f":"markdown"},"source":{"4e567880":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","470033e5":"from sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline","2c272623":"df_train = pd.read_csv(\"..\/input\/home-data-for-ml-course\/train.csv\")\n\ndf_test = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\n\ny = df_train['SalePrice']\n\ndf_train.drop(['SalePrice','Id'],axis=1,inplace=True)\n\ntest_index = df_test['Id']\ndf_test.drop('Id',axis=1,inplace=True)","6145338c":"numerical_cols= df_train.select_dtypes(exclude='object').columns\n\ncatagorical_cols = df_train.select_dtypes(include='object').columns\n\nnumerical_transfer = SimpleImputer(strategy='median')\n\ncatagorical_transfer = Pipeline(steps=\n                                [\n                                    ('imputer',SimpleImputer(strategy='most_frequent')),\n                                    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n                                ])\n\npreprocessor = ColumnTransformer(transformers=\n                                 [\n                                     ('num',numerical_transfer,numerical_cols),\n                                     ('cat',catagorical_transfer,catagorical_cols)\n                                 ])","018bd9e1":"from xgboost import XGBRegressor","dabc39c8":"# from sklearn.ensemble import RandomForestRegressor\nmodel = XGBRegressor(n_estimators=1000,random_state=0,learning_rate=0.05)\n\nmy_pipeline =Pipeline(steps = \n                     [\n                         ('preprocessor',preprocessor),\n                         ('model',model)\n                     ])","fb9bed2a":"my_pipeline.fit(df_train,y)\n\npred = my_pipeline.predict(df_test)\n\noutput = pd.DataFrame({'Id':test_index,\n                      'SalePrice':pred})\n\noutput.to_csv('using_pipeline_with_xgboost_1.csv',index=False)\n\npd.read_csv('using_pipeline_with_xgboost_1.csv')","0b412ec1":"### Submission","87f387f0":"### Data","5a9f4cb2":"### Define Preprocessing steps","518e5e4f":"### Define the model"}}