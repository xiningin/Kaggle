{"cell_type":{"3786d0bb":"code","616a1d0b":"code","63d8734d":"code","55c4cd39":"code","6df1f3cc":"code","a8453be0":"code","beb13947":"code","35228e65":"code","45794aa7":"code","47ab3b4d":"code","65714f47":"code","8e332afa":"code","a0265b95":"code","8fa747da":"code","55028f97":"code","8da8d468":"code","8f22d866":"code","e09edcff":"code","da50a264":"code","c4a27fe1":"code","507f9e3f":"code","1870608f":"code","22f323dd":"code","4b9c9dea":"code","63d92963":"code","d0d05b04":"code","aa51b992":"code","056b5267":"code","f55b72e7":"code","2a964bfc":"markdown","3eea7381":"markdown","9ddff98f":"markdown","2f252c8d":"markdown","8e7c248b":"markdown","df797f91":"markdown"},"source":{"3786d0bb":"import numpy as np # linear algebra\nimport pandas as pd\nimport random as rd # generating random numbers\nimport datetime # manipulating date formats\n# Viz\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\n# TIME SERIES\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs","616a1d0b":"sales = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nitems = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cat = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nsample_sub = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\n\n\nprint('sales:', sales.shape, 'items:', items.shape, 'item_cats:', item_cat.shape, 'shops:', shops.shape, 'sample submission', sample_sub.shape)","63d8734d":"sales['date'] = pd.to_datetime(sales['date'])\nprint(sales.info())\nsales.head(5)","55c4cd39":"# looking for outliers\nsns.boxplot(x=sales.item_cnt_day)","6df1f3cc":"sns.boxplot(x=sales.item_price)","a8453be0":"# remove it\nsales = sales[(sales.item_price < 100000) & (sales.item_price > 0)]\nsales = sales[(sales.item_cnt_day < 1001) & (sales.item_cnt_day > 0)]","beb13947":"# get shops ID and item ID\ntest_shops = test.shop_id.unique()\nsales = sales[sales.shop_id.isin(test_shops)]\ntest_items = test.item_id.unique()\ntrain = sales[sales.item_id.isin(test_items)]","35228e65":"# aggregation for the monthly sales\ntotal_sales = sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\ntotal_sales.head(20)","45794aa7":"fig = px.line(total_sales, labels={\n    'date_block_num': \"Month\",\n    'value': \"Sales\"\n    })\nfig.show()","47ab3b4d":"res = sm.tsa.seasonal_decompose(total_sales.values, period=12)","65714f47":"fig = make_subplots(specs=[[{\"secondary_y\": True}]])\nfig.add_trace(go.Scatter(y=res.seasonal,\n                    mode='lines',\n                    name='seasonal'))\nfig.add_trace(go.Scatter(y=res.trend,\n                    mode='lines',\n                    name='trend'),\n                    secondary_y=True)\nfig.add_trace(go.Scatter(y=res.resid,\n                    mode='lines',\n                    name='residual'))\nfig.add_trace(go.Scatter(y=res.observed,\n                    mode='lines',\n                    name='observed'),\n                    secondary_y=True)\nfig.update_layout(title={\n                    'text': \"Original\"\n})\n\nfig.show()\n\nadf = sm.tsa.stattools.adfuller(total_sales)\nprint('Dickey-Fuller results:', adf[1:])","8e332afa":"total_sales_no_trend = total_sales - total_sales.shift(1)\n\nres = sm.tsa.seasonal_decompose(total_sales_no_trend[1:], period=12)\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\nfig.add_trace(go.Scatter(y=res.trend,\n                    mode='lines',\n                    name='trend'),\n                    secondary_y=True)\nfig.add_trace(go.Scatter(y=res.observed,\n                    mode='lines',\n                    name='observed'),\n                    secondary_y=True)\nfig.add_trace(go.Scatter(y=res.seasonal,\n                    mode='lines',\n                    name='seasonal'))\nfig.update_layout(title={\n                    'text': \"After removing the trend\"\n                    })\n\nfig.show()\n\nadf = sm.tsa.stattools.adfuller(total_sales_no_trend[1:])\nprint('Dickey-Fuller results:', adf[1:])","a0265b95":"from fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\n\nts = sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head()\nts.columns=['ds','y']","8fa747da":"# build model\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(ts) #fit the model with your dataframe","55028f97":"# make forecast\n# predict for five months in the furure and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nprint(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())\nfig = model.plot(forecast)\na = add_changepoints_to_plot(fig.gca(), model, forecast)","8da8d468":"fig = model.plot_components(forecast)","8f22d866":"test.insert(loc=3, column='date_block_num', value=34)\n# test = pd.merge(test, shops, on=['shop_id'], how='left')\ntest = pd.merge(test, items, on=['item_id'], how='left')\ntest['date_block_num'] = 34\n\ntest = test.drop(['item_name', 'ID'], axis=1)\nprint(f'Shape of test data: {test.shape}')\ntest.head(5)","e09edcff":"# merge with shops and items\ntrain = pd.merge(sales, shops, on=['shop_id'], how='left')\ntrain = pd.merge(train, items, on=['item_id'], how='left')\ntrain = pd.merge(train, item_cat, on=['item_category_id'], how='left')\ntrain = train.groupby(['shop_id', 'item_id', 'date_block_num', 'item_category_id'])['item_cnt_day'].sum().rename('item_cnt_month').reset_index()\ntrain['item_cnt_month'] = (train['item_cnt_month'].fillna(0).clip(0,20))\n\n# add test\ndf = pd.concat([train, test], ignore_index=True, sort=False, keys=['shop_id', 'item_id', 'date_block_num'])\ndf.fillna(0, inplace=True)\n\nprint(f'Shape of training data: {df.shape}')","da50a264":"def generate_lag(train, months, lag_column):\n    for month in months:\n        # Speed up by grabbing only the useful bits\n        train_shift = train[['date_block_num', 'shop_id', 'item_id', lag_column]].copy()\n        train_shift.columns = ['date_block_num', 'shop_id', 'item_id', lag_column+'_lag_'+ str(month)]\n        train_shift['date_block_num'] += month\n        train = pd.merge(train, train_shift, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    return train\n\ndf = generate_lag(df, [1, 2, 3], 'item_cnt_month')\ndf.fillna(0, inplace=True)","c4a27fe1":"X_train = df[df.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = df[df.date_block_num < 33]['item_cnt_month']\nX_valid = df[df.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = df[df.date_block_num == 33]['item_cnt_month']\nX_test = df[df.date_block_num == 34].drop(['item_cnt_month'], axis=1)","507f9e3f":"X_train.head(5)","1870608f":"import lightgbm as lgb\nimport optuna\nimport sklearn.metrics\n\nfrom sklearn.metrics import mean_squared_error as rmse\n\nfeature_name = X_train.columns.tolist()\n\nlgb_train = lgb.Dataset(X_train, Y_train)\nlgb_eval = lgb.Dataset(X_valid, Y_valid, reference=lgb_train)","22f323dd":"def objective(trial):\n        \n    param = {\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        'learning_rate':0.001,\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 50, 150),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.8, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n\n    model = lgb.train(param, \n                      lgb_train,\n                      valid_sets=[lgb_train,lgb_eval],\n                      early_stopping_rounds=15,\n                      verbose_eval=1)\n    \n    y_pred = model.predict(X_valid)\n    accuracy = rmse(Y_valid, y_pred)\n\n    return accuracy","4b9c9dea":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=5)\n \nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","63d92963":"opt_params = study.best_trial.params\nprint(f'optimal trial parameters\\n{opt_params}')","d0d05b04":"x = {\"objective\": \"regression\",\n     \"metric\"   : \"rmse\",\n     \"verbosity\": -1,\n     \"boosting_type\": \"gbdt\"}\n\nopt_params.update(x)\nopt_params","aa51b992":"evals_result = {} \n\nmodel = lgb.train(opt_params,\n                  lgb_train,\n                  valid_sets=[lgb_train,lgb_eval],\n                  evals_result=evals_result,\n                  early_stopping_rounds=100,\n                  verbose_eval=1,\n                  )","056b5267":"lgb.plot_importance(model, max_num_features=10, importance_type='gain')","f55b72e7":"# submission\nY_test = model.predict(X_test[feature_name]).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('submission.csv', index=False)","2a964bfc":"# Competition predictions with LGBM","3eea7381":"# Using prophet for forcast on the overall sales","9ddff98f":"# cleaning","2f252c8d":"# import data","8e7c248b":"## Exploring monthly sales","df797f91":"### EDA"}}