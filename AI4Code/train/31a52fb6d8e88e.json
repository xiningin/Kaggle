{"cell_type":{"43add02e":"code","04246983":"code","a9dfec51":"code","b2f29570":"code","7f38e39a":"code","456e49ab":"code","fa80b48f":"code","37eb57ee":"code","87e1b2a4":"code","8abcf1fc":"code","300bd445":"code","2d36f0d6":"code","0d32828d":"code","c8b77d8e":"code","e4abfc2b":"markdown","a1463d15":"markdown","5bfbba86":"markdown","41c8cb59":"markdown","29aaa5f6":"markdown","b7e6ed69":"markdown","8e02a76d":"markdown","6107e4df":"markdown","eb6b9dc5":"markdown","8da8e440":"markdown","2f1de1f7":"markdown"},"source":{"43add02e":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold","04246983":"dfTitanic = pd.read_csv('..\/input\/lab6_train_no_nulls_no_outliers.csv')\ndfTitanic.head(3)","a9dfec51":"dfTitanic['Sex'] = pd.factorize(dfTitanic['Sex'].values)[0]\ndfTitanic['Pclass'] = pd.factorize(dfTitanic['Pclass'].values)[0]\ndfTitanic['Embarked'] = pd.factorize(dfTitanic['Embarked'].values)[0]\n","b2f29570":"dfTitanic['Ticket'] = pd.factorize(dfTitanic['Ticket'].values)[0]","7f38e39a":"dfTitanic.head()","456e49ab":"y = dfTitanic['Survived'].values\n#X = dfTitanic[['Age', 'SibSp', 'Parch', 'Fare', 'C', 'Q', 'S', '1', '2', '3', 'female', 'male']].values\nX = dfTitanic[['Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked', 'Pclass', 'Sex']].values\n","fa80b48f":"kf = KFold(n_splits=5, shuffle=True)","37eb57ee":"from sklearn.metrics import accuracy_score, roc_auc_score\n\ndef avalia_classificador(clf, kf, X, y, f_metrica):\n    metrica = []\n    for train, valid in kf.split(X,y):\n        x_train = X[train]\n        y_train = y[train]\n        x_valid = X[valid]\n        y_valid = y[valid]\n        clf.fit(x_train, y_train)\n        y_pred = clf.predict(x_valid)\n        metrica.append(f_metrica(y_valid, y_pred))\n    return np.array(metrica).mean()","87e1b2a4":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures","8abcf1fc":"from sklearn.ensemble import RandomForestClassifier\nX_n = StandardScaler().fit_transform(X)\nX_n = PolynomialFeatures(2).fit_transform(X_n)\n\nrf = RandomForestClassifier(n_estimators=200, max_features=8, max_depth=12)\nmedia_acuracia = avalia_classificador(rf, kf, X_n, y, accuracy_score) \nprint('Acur\u00e1cia: ', media_acuracia)\nmedia_auc = avalia_classificador(rf, kf, X, y, roc_auc_score) \nprint('AUC: ', media_auc)","300bd445":"from sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier()","2d36f0d6":"media_acuracia = avalia_classificador(ada, kf, X, y, accuracy_score) \nprint('Acur\u00e1cia: ', media_acuracia)\nmedia_auc = avalia_classificador(ada, kf, X, y, roc_auc_score) \nprint('AUC: ', media_auc)","0d32828d":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier()","c8b77d8e":"media_acuracia = avalia_classificador(gbc, kf, X, y, accuracy_score) \nprint('Acur\u00e1cia: ', media_acuracia)\nmedia_auc = avalia_classificador(gbc, kf, X, y, roc_auc_score) \nprint('AUC: ', media_auc)","e4abfc2b":"Aqui usamos a classe [AdaBoostClassifier](http:\/\/scikit-learn.org\/0.17\/modules\/generated\/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier). Experimente variar os par\u00e2metros do classificador. ","a1463d15":"Assim como no laborat\u00f3rio anterior, aqui temos uma fun\u00e7\u00e3o para avaliar o desempenho dos algoritmos sem termos de ficar repetindo c\u00f3digo. Ele retorna a m\u00e9dia das m\u00e9tricas, acur\u00e1cia no caso.","5bfbba86":"Aqui usamos a classe [RandomForestClassifier](http:\/\/scikit-learn.org\/0.17\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html). Experimente variar os par\u00e2metros do classificador. ","41c8cb59":"Nesse laborat\u00f3rio vamos exercitar o uso do scikit-learn para algoritmos de ensemble para os dados do Titanic que trabalhamos anteriormente, no Laborat\u00f3rio 2. Esse laborat\u00f3rio \u00e9 bem parecido com o anterior, exceto pelos m\u00e9todos que vamos usar.","29aaa5f6":"# Laborat\u00f3rio 6 - Modelos de Ensemble com Scikit-learn","b7e6ed69":"Aqui geramos os K-folds para nossa valida\u00e7\u00e3o cruzada dos algoritmos.","8e02a76d":"### Carregando os dados que trabalhamos anteriormente","6107e4df":"### Ada Boosting","eb6b9dc5":"Aqui usamos a classe [GradientBoostingClassifier](http:\/\/scikit-learn.org\/0.17\/modules\/generated\/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier). Experimente variar os par\u00e2metros do classificador. ","8da8e440":"### Random Forest","2f1de1f7":"### Gradient Boosted Trees"}}