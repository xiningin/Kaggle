{"cell_type":{"8449752f":"code","7fdb451c":"code","5e04068c":"code","4b4786b8":"code","ec85869c":"code","1ec8de49":"code","836f5568":"code","ced86ecf":"code","c5cef941":"code","5e45b626":"code","a7c52f69":"code","4b30d45c":"code","a0275f4c":"code","aa0ad33f":"code","6ce42d87":"code","29a9f193":"code","c3f60387":"code","b9a9b003":"code","6db7f07f":"code","97515639":"code","d9dd87f3":"code","d326b004":"code","2e70d954":"code","2a1ec7d8":"code","9c843a66":"code","51932629":"code","1ad3339d":"code","c4509d77":"code","45ae23bb":"code","f2277355":"code","04e23c64":"code","16973fd1":"code","75fa5c2d":"code","22f5056e":"code","49015ac0":"code","bd7251d3":"code","0596ee4e":"code","877f4686":"code","f80c13c4":"code","2dd152bc":"markdown","70310e71":"markdown","ea17aaf5":"markdown","6a6679b1":"markdown","6653b838":"markdown","ac03ea8b":"markdown"},"source":{"8449752f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7fdb451c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nimport statsmodels.api as sm\ntrain_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain_data.head()","5e04068c":"#duplicated record checking\nprint(any(train_data.duplicated()))\nprint(any(test_data.duplicated()))","4b4786b8":"#look into attributes that missing data\ntrain_miss = train_data.isnull().sum().sort_values(ascending=False)\ntrain_miss = train_miss[train_miss > 0]\nplt.style.use('ggplot')\nplt.figure(figsize=(14,8))\nplt.xticks(rotation=60)\nplt.bar(x = range(train_miss.shape[0]),height = train_miss.values, tick_label = train_miss.index, color = 'steelblue')\nplt.title('Null value records (House price predict train table)')","ec85869c":"#look into attributes that missing data in test data\ntest_miss = test_data.isnull().sum().sort_values(ascending=False)\ntest_miss = test_miss[test_miss > 0]\nplt.style.use('ggplot')\nplt.figure(figsize=(14,8))\nplt.xticks(rotation=60)\nplt.bar(x = range(test_miss.shape[0]),height = test_miss.values, tick_label = test_miss.index, color = 'steelblue')\nplt.title('Null value records (House price predict test table)')","1ec8de49":"plt.style.use('ggplot')\nplt.figure(figsize=(8,6))\n\nsns.distplot(train_data.SalePrice, fit = stats.norm, norm_hist = True,\n             hist_kws ={'color':'Steelblue','edgecolor':'Steelblue'},\n             kde_kws = {'color':'black','linestyle':'-'}, \n             fit_kws ={'color':'red','linestyle':':'})\n\nplt.show()","836f5568":"train_data[\"SalePrice\"] = np.log(train_data[\"SalePrice\"])\nplt.style.use('ggplot')\nplt.figure(figsize=(8,6))\n\nsns.distplot(train_data.SalePrice, fit = stats.norm, norm_hist = True,\n             hist_kws ={'color':'Steelblue','edgecolor':'Steelblue'},\n             kde_kws = {'color':'black','linestyle':'-'}, \n             fit_kws ={'color':'red','linestyle':':'})\n\nplt.show()","ced86ecf":"plt.figure(figsize=(8,6))\nstats.probplot(train_data.SalePrice, plot=plt)","c5cef941":"#see the correlation between them and SalePrice.\ncorr = train_data.drop('SalePrice',axis =1).corrwith(train_data['SalePrice'])\ncorr = corr[corr >0.5].index.tolist()\ncorr.append('SalePrice')\ndata_corr = train_data[corr]\ndt_corr = data_corr.corr(method='pearson')\nplt.figure(figsize=(10,10))\nsns.heatmap(dt_corr,annot=True,vmax=1,square=True, cmap='Oranges')\nplt.show()","5e45b626":"#numerical value's distribution \nnum_col = ['OverallQual','YearBuilt','YearRemodAdd','TotalBsmtSF','GrLivArea','FullBath','GarageArea']\nnum_data = train_data[num_col]\nnum_data_list = pd.melt(num_data,value_vars = num_col,var_name='Attribute', value_name='Values')\nnum_data_list.head()\ng =sns.FacetGrid(num_data_list, col='Attribute', col_wrap =4,sharex = False,sharey = False)\ng.map(sns.histplot, 'Values')","a7c52f69":"num_list_col = np.array(['YearBuilt','YearRemodAdd','TotalBsmtSF','GrLivArea','GarageArea'])\nnum_list_col\n","4b30d45c":"train = pd.DataFrame(train_data.dtypes, columns = ['data_type'])\nobject_list =train[train.data_type== 'object'].index.tolist()\ncat_list1 = ['OverallQual','FullBath','SalePrice']\nfor i in range(0,3):\n    object_list.append(cat_list1[i])\n\ntrain_data[object_list]","a0275f4c":"#category value's distribution \ncat_data = train_data[object_list]\ncat_data_list = pd.melt(cat_data,id_vars =['SalePrice'],value_vars = object_list[:-1],\n                        var_name='Atrributes', value_name='Values')\ndef boxplot(x, y, **kwargs):\n    sns.boxplot(x=x, y=y)\n    x=plt.xticks(rotation=90)\ng =sns.FacetGrid(cat_data_list, col='Atrributes', col_wrap =3,sharex = False,sharey = False,height=5,aspect=1.2)\ng.map(boxplot, 'Values','SalePrice')\n","aa0ad33f":"cat_list_col = np.array(['MSZoning', 'Street', 'Alley',  'LandContour',  'Neighborhood', 'Condition1', 'Condition2',\n'RoofMatl', 'Exterior1st','Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation','BsmtQual', 'BsmtCond', \n'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual','Functional',\n'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual','GarageCond', 'PavedDrive', \n'PoolQC', 'MiscFeature','SaleType', 'SaleCondition', 'OverallQual', 'FullBath'])\nlen(cat_list_col)","6ce42d87":"sp = np.array(['SalePrice'])\nall_col = np.concatenate((num_list_col, cat_list_col,sp))\n\nall_data = train_data.append(test_data)","29a9f193":"all_data","c3f60387":"all_data_final = all_data[all_col].reset_index().drop('index', axis =1)","b9a9b003":"test_data.isnull().sum()","6db7f07f":"all_miss = all_data_final.isnull().sum().sort_values(ascending=False)\n\nall_miss = all_miss[all_miss > 0]\nplt.style.use('ggplot')\nplt.figure(figsize=(14,8))\nplt.xticks(rotation=60)\nplt.bar(x = range(all_miss.shape[0]),height = all_miss.values, tick_label = all_miss.index, color = 'steelblue')\nplt.title('Null value records (House price predict all)')","97515639":"all_miss","d9dd87f3":"#fill null value for all data \nN_list = ['PoolQC','MiscFeature','Alley','FireplaceQu','GarageQual','GarageCond',\n          'GarageFinish','GarageType','BsmtExposure','BsmtCond','BsmtQual','BsmtFinType2','BsmtFinType1','MasVnrType']\nM_list = ['MSZoning','Functional','Exterior1st','Exterior2nd','Electrical','SaleType','KitchenQual']\n\nfor i in N_list:\n    all_data_final[i]=all_data_final[i].fillna('None')\n\nfor i in M_list:\n    all_data_final[i]=all_data_final[i].fillna(all_data_final[i].mode()[0])\n    \nall_data_final['GarageArea']=all_data_final['GarageArea'].fillna(all_data_final['GarageArea'].mean())\nall_data_final['TotalBsmtSF'] = all_data_final['TotalBsmtSF'].fillna(0)   \nall_data_final.isnull().sum().sort_values(ascending=False)\n\n\n","d326b004":"all_data_final.shape","2e70d954":"#delete abnormal values only exist in train dataset\nall_data_final = all_data_final.drop(all_data_final[(all_data_final['RoofMatl'] == 'Roll') | (all_data_final['RoofMatl'] == 'Membran')\n               | (all_data_final['RoofMatl'] == 'Metal')| (all_data_final['RoofMatl'] == 'ClyTile')].index)\nall_data_final = all_data_final.drop(all_data_final[(all_data_final['Condition2'] == 'RRNn') | (all_data_final['Condition2'] == 'RRAe')\n               | (all_data_final['Condition2'] == 'RRAn')].index)\nall_data_final = all_data_final.drop(all_data_final[(all_data_final['Heating'] == 'OthW') | (all_data_final['Heating'] == 'Floor')].index)\nall_data_final = all_data_final.drop(all_data_final[all_data_final['MiscFeature'] == 'TenC'].index)","2a1ec7d8":"#log transfoer to match normal distribution\nall_data_final[\"TotalBsmtSF\"] = all_data_final[\"TotalBsmtSF\"] +1\nall_data_final[\"GarageArea\"] = all_data_final[\"GarageArea\"] +1","9c843a66":"all_data_final[\"TotalBsmtSF\"] = np.log(all_data_final[\"TotalBsmtSF\"])\nall_data_final[\"GrLivArea\"] = np.log(all_data_final[\"GrLivArea\"])\nall_data_final[\"GarageArea\"] = np.log(all_data_final[\"GarageArea\"])\nall_data_final[\"YearAll\"] = (all_data_final[\"YearBuilt\"] + all_data_final[\"YearRemodAdd\"])\/2","51932629":"all_data_final\n","1ad3339d":"all_data_final = all_data_final.drop(['YearRemodAdd','YearBuilt'],axis = 1)\nall_data_final","c4509d77":"num_list_col = ['YearAll', 'TotalBsmtSF', 'GrLivArea','GarageArea']","45ae23bb":"all_dummy = pd.get_dummies(all_data_final[cat_list_col])\nall_data_dummy = pd.concat([all_data_final[num_list_col],all_dummy,all_data_final.SalePrice],axis=1)\nall_data_dummy.head()","f2277355":"#from sklearn import preprocessing\n#lbl = preprocessing.LabelEncoder()\n#all_data_dummy['TotalBsmtSF'] = lbl.fit_transform(all_data_dummy['TotalBsmtSF'].astype(str))#\u5c06\u63d0\u793a\u7684\u5305\u542b\u9519\u8bef\u6570\u636e\u7c7b\u578b\u8fd9\u4e00\u5217\u8fdb\u884c\u8f6c\u6362\ntrain_d = all_data_dummy[~all_data_dummy['SalePrice'].isnull()]\ntest_d = all_data_dummy[all_data_dummy['SalePrice'].isnull()]","04e23c64":"#train, test split from train samples\nfrom sklearn import model_selection\nfrom sklearn.linear_model import Ridge,RidgeCV\nfrom sklearn.linear_model import Lasso,LassoCV\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn import metrics\nfrom sklearn import tree\nfrom sklearn import ensemble\nimport xgboost\nX = train_d.drop('SalePrice',axis =1)\ny = train_d.SalePrice\nX_train,X_test,y_train,y_test = model_selection.train_test_split(X,y, test_size = 0.25,random_state=1234)\ntest_d_X = test_d.drop('SalePrice',axis =1)\n","16973fd1":"#RidgeCV\nLamdas = np.logspace(-5,2,200)\nridge_cv = RidgeCV(alphas = Lamdas, normalize = False, scoring='neg_mean_squared_error',cv =10)\nridge_cv.fit(X_train,y_train)\nridge_best_Lambda = ridge_cv.alpha_\nridge_best_Lambda","75fa5c2d":"#Ridge\nridge = Ridge(alpha=ridge_best_Lambda)\nridge.fit(X_train,y_train)\nridge_predict = ridge.predict(X_test)\nRMSE = np.sqrt(mean_squared_error(y_test, ridge_predict))\nRMSE","22f5056e":"#Lasso, LassoCV\nfrom sklearn.linear_model import Lasso, LassoCV\nLambdas = np.logspace(-5,2,200)\nlasso_cv = LassoCV(alphas = Lambdas, normalize=True, tol =0.0001, max_iter = 10000)\nlasso_cv.fit(X,y)\nlasso_best_Lambdas = lasso_cv.alpha_\nlasso_best_Lambdas","49015ac0":"lasso = Lasso(alpha = lasso_best_Lambdas, normalize = True, max_iter = 10000)\nlasso.fit(X_train,y_train)\nlasso_predict = lasso.predict(X_test)\nRMSE = np.sqrt(mean_squared_error(y_test, lasso_predict))\nRMSE","bd7251d3":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import tree\nmax_depth = [2,3,4,5,6]\nmin_samples_split = [2,4,6,8]\nmin_samples_leaf = [2,4,8,10,12]\nparameters = {'max_depth':max_depth, 'min_samples_split':min_samples_split, 'min_samples_leaf':min_samples_leaf}\ngrid_dtcateg = GridSearchCV(estimator = tree.DecisionTreeRegressor(), param_grid = parameters, cv=10)\ngrid_dtcateg.fit(X_train, y_train)\ngrid_dtcateg.best_params_","0596ee4e":"from sklearn import metrics\nCART_Class = tree.DecisionTreeRegressor(max_depth=6, min_samples_leaf = 12, min_samples_split=4)\ndecision_tree = CART_Class.fit(X_train, y_train)\npred = CART_Class.predict(X_test)\nRMSE = np.sqrt(mean_squared_error(y_test, pred))\nRMSE","877f4686":"from sklearn import ensemble\nRF_class = ensemble.RandomForestRegressor(n_estimators=200, random_state=1234)\nRF_class.fit(X_train, y_train)\nRFclass_pred = RF_class.predict(X_test)\nRMSE = np.sqrt(mean_squared_error(y_test, RFclass_pred))\nRMSE","f80c13c4":"import xgboost\nxgboost2 = xgboost.XGBRegressor()\nxgboost2.fit(X_train,y_train)\npred2 = xgboost2.predict(X_test)\nRMSE = np.sqrt(mean_squared_error(y_test, pred2))\nRMSE","2dd152bc":"Now let's see the performance of all the category attributes.","70310e71":"no duplicated record.","ea17aaf5":"The value for SalePrice in the train dataset doesn't follow normal distrubution, so it need to be transformed.","6a6679b1":"With the ML using several models to compare.","6653b838":"**Data Exploration**","ac03ea8b":"From above attributes, below ones have high correlation between each other, so will remove one from them\n1. TotalBsmtSF (Total square feet of basement area) and 1stFlrSF\uff08First Floor square feet\uff09\n2. GrLivArea (Above grade (ground) living area square feet) & TotRmsAbvGrd(Total rooms above grade (does not include bathrooms))\n3. GarageCars (Size of garage in car capacity) & GarageArea (Size of garage in square feet)\n4. YearBuilt & GarageYrBlt\n\nSo we only leave: OverallQual,YearBuilt,YearRemodAdd,TotalBsmtSF,GrLivArea,FullBath,GarageArea. (will normal distrubution for TotalBsmtSF,GrLivArea,GarageArea). OverallQual and FullBath will be count into category types later."}}