{"cell_type":{"7079104c":"code","a76873a8":"code","3f3a8094":"code","0d670d1b":"code","a8a8f6e9":"code","419f7cfe":"code","1eb3ab1d":"code","6470809b":"code","7214692d":"code","ad82fc9b":"code","0078ff23":"code","cdbe01ca":"code","d2f28705":"code","8d8a2256":"code","7366cad4":"code","3d0818bd":"code","e986c75c":"code","ecfd68d4":"code","9a2daa97":"code","634daed7":"code","ff8c1cad":"code","587c7685":"code","80cad449":"code","648f57af":"code","5d37de5a":"code","29e0640c":"code","25e07883":"code","efad2707":"code","2b9bfb21":"code","97aa35e0":"code","d176c812":"code","016cb55c":"code","9bcaf334":"code","89358218":"code","38e3980d":"code","2c0cdec0":"code","99d345fe":"code","e7f457f6":"code","452b7e67":"code","10300941":"code","75627505":"code","33e1bc26":"code","f0175d1e":"code","d49e9c95":"code","b21c6983":"code","f895a965":"code","d78a50a2":"code","ff08fcd2":"code","935a5e4e":"code","6c36a3a5":"code","aa861842":"code","4e2768e9":"code","cff162fe":"code","56318572":"code","3e0796c0":"code","d6b7c037":"code","16f45649":"code","21544fe2":"code","8b2791da":"code","94c1e28d":"code","1c955c67":"code","03e625b8":"code","590fc493":"code","4190a670":"code","6d811358":"code","39a072ba":"code","43ce99d7":"code","a2ade36d":"code","bd29e081":"code","1f491ae9":"code","69c6cb09":"code","3d804df1":"code","43f28deb":"code","43419f2f":"code","a2f26849":"code","efec1499":"code","530f4cee":"code","e96dccb4":"code","4eaa2d60":"markdown","1a9e0e12":"markdown","9cfb7b57":"markdown","8c3fe0c1":"markdown","15d16917":"markdown","daba4617":"markdown","c625bd20":"markdown","138100a5":"markdown","6817b4a1":"markdown","5af6113c":"markdown","1899fbb9":"markdown","eb506fa6":"markdown","c5f0ee71":"markdown","089b42e6":"markdown","5b0b1ddd":"markdown","b89fda27":"markdown","42d0f652":"markdown","0ec65798":"markdown","f3a1ef26":"markdown","9547f4c2":"markdown","e40aa09b":"markdown","a9082a1f":"markdown","bccec060":"markdown","8a508a92":"markdown","c54fc477":"markdown","9efe32e8":"markdown","cf1f423f":"markdown","6f5f898b":"markdown","2b0e55e3":"markdown","f2ff347b":"markdown","0778e1e1":"markdown","ceb4f0df":"markdown","360de167":"markdown","3842102c":"markdown","43693229":"markdown","b348d293":"markdown","06230ed5":"markdown","a965bbdb":"markdown","a89b7f98":"markdown","63cd1747":"markdown"},"source":{"7079104c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a76873a8":"import random\nrandom.seed(123)\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=FutureWarning)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nimport cv2\nimport datetime\nimport itertools\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\n\nfrom PIL import Image\nimport keras\nfrom keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array\nfrom keras import models\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\nfrom keras import optimizers\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.applications import VGG19\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import auc,roc_curve,roc_auc_score","3f3a8094":"#set Adam optimizer with a learning rate of 1e-4 or 0.0001\noptimizer = keras.optimizers.Adam(learning_rate = 1e-5)\n\n#define the callbacks\nearly_stopping = [EarlyStopping(monitor = 'val_loss', patience = 10),\n                 ModelCheckpoint(filepath = 'best_model.h5', monitor = 'val_loss', save_best_only = True)]","0d670d1b":"#define path to the data directory\nbase_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/'\ntrain_dir = base_dir + 'train\/'\ntest_dir = base_dir + 'test\/'\nval_dir = base_dir + 'val\/'\n\n#train dataset\ntrain_normal = train_dir + 'NORMAL\/'\ntrain_pneu = train_dir + 'PNEUMONIA\/'\n\n#test dataset\ntest_normal = test_dir + 'NORMAL\/'\ntest_pneu = test_dir + 'PNEUMONIA\/'\n\n#validation dataset\nval_normal = val_dir + 'NORMAL\/'\nval_pneu = val_dir + 'PNEUMONIA\/'","a8a8f6e9":"#check for number of images in each dataset\n#normal condition\nprint('Train Normal:', len(os.listdir(train_normal)))\nprint('Test Normal:', len(os.listdir(test_normal)))\nprint('Val Normal:', len(os.listdir(val_normal)))\nprint('\\n')\n\n#pneumonia condition\nprint('Train Pneumonia:', len(os.listdir(train_pneu)))\nprint('Test Pneumonia:', len(os.listdir(test_pneu)))\nprint('Val Pneumonia:', len(os.listdir(val_pneu)))","419f7cfe":"from PIL import Image\nfrom keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt\n\nnormal = Image.open(train_normal + os.listdir(train_normal)[0])\npneu = Image.open(train_pneu + os.listdir(train_pneu)[0])\n\nfig = plt.figure(figsize = (20, 20))\n\nax1 = fig.add_subplot(1, 2, 1)\nax1.set_title('Normal X-ray', fontsize = 15)\nplt.imshow(normal, cmap = 'gray')\n\nax2 = fig.add_subplot(1, 2, 2)\nax2.set_title('Pneumonia X-ray', fontsize = 15)\nplt.imshow(pneu, cmap = 'gray')","1eb3ab1d":"#save\nplt.savefig('X-ray.png')","6470809b":"#visualize each class\nimport seaborn as sns\n\nplt.figure(figsize = (20, 8))\nsns.barplot(x = ['NORMAL', 'PNEUMONIA'], \n            y = [len(os.listdir(train_normal)), len(os.listdir(train_pneu))],\n            palette = 'Spectral')\nplt.xlabel('Condition', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)\nplt.title('X-ray Condition in Training Set', fontsize = 15);","7214692d":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array\n\n#augment train and validation dataset to prevent overfitting by increasing number of images\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   \n                                   #randomly rotate images\n                                   rotation_range = 40,\n                                   \n                                   #randomly shear angles\n                                   shear_range = 0.2,\n                                   \n                                   #randomly zoom images\n                                   zoom_range = 0.2,\n                                   \n                                   #randomly shift images\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   \n                                   # randomly flip images\n                                   horizontal_flip = True,\n                                   \n                                   fill_mode = 'nearest')\n\nval_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                 rotation_range = 40,\n                                 shear_range = 0.2,\n                                 zoom_range = 0.2,\n                                 width_shift_range = 0.2,\n                                 height_shift_range = 0.2,\n                                 horizontal_flip = True,\n                                 fill_mode = 'nearest')\n\n#rescale test dataset without augmentation since real world data is not augmented\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","ad82fc9b":"#get all the data in the directory with specified batch sizes and image dimensions\ntrain_generator = train_datagen.flow_from_directory(\n        #target directory\n        train_dir,\n    \n        #resize to 150x150\n        target_size = (150, 150),\n    \n        #size batches of data\n        batch_size = 32,\n    \n        #since we use binary_crossentropy loss, we need binary labels\n        class_mode = 'binary')\n\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size = (150, 150),\n                                                  batch_size = 32,\n                                                  class_mode = 'binary',\n                                                  shuffle = False)\n\nval_generator = val_datagen.flow_from_directory(val_dir,\n                                                target_size = (150, 150),\n                                                batch_size = 32,\n                                                class_mode = 'binary')","0078ff23":"#code from https:\/\/stackoverflow.com\/questions\/62217528\/how-to-show-results-of-data-augmentation-before-and-after-keras-preprocessing-im\n\ndef getSamplesFromDataGen(resultData):\n    x = resultData.next() #fetch the first batch\n    a = x[0] # train data\n    b = x[1] # train label\n    for i in range(0, 5):\n        plt.imshow(a[i])\n        plt.title(b[i])\n        plt.show() ","cdbe01ca":"#get 5 random images\ngetSamplesFromDataGen(train_generator)","d2f28705":"#code from https:\/\/www.kaggle.com\/rafetcan\/pneumonia-normal-cnn-model\n\nimport cv2\ndef picture_separation(folder):\n    \n    '''divide the mixed pictures into NORMAL and PNEUMONIA & add labels to these'''\n    \n    X = []\n    y = []\n    image_list = []\n\n    for foldername in os.listdir(folder):\n        if not foldername.startswith('.'):\n            if foldername == \"NORMAL\":\n                label = 0\n            elif foldername == \"PNEUMONIA\":\n                label = 1\n            else:\n                label = 2\n                \n            for image_filename in os.listdir(folder + \"\/\"+ foldername):\n                img_file = cv2.imread(folder + \"\/\" + foldername + '\/' + image_filename,0)               \n                \n\n                if img_file is not None:\n                    img = cv2.resize(img_file,(64,64))\n                    img_arr = img_to_array(img) \/ 255\n                    X.append(img_arr)\n                    y.append(label)\n                    image_list.append(foldername + '\/' + image_filename)\n                                        \n    X = np.asarray(X)\n    y = np.asarray(y)\n    \n    return X, y, image_list","8d8a2256":"#get train dataset\nX_train, y_train, img_train = picture_separation(train_dir)\n\ntrain_df = pd.DataFrame(img_train, columns = [\"images\"])\ntrain_df[\"target\"] = y_train\n\n#preview\ntrain_df.head()","7366cad4":"#get validation dataset\nX_val, y_val, img_val = picture_separation(val_dir)\n\nval_df = pd.DataFrame(img_val, columns = [\"images\"])\nval_df[\"target\"] = y_val\n\n#preview\nval_df.head()","3d0818bd":"#get test dataset\nX_test, y_test, img_test = picture_separation(test_dir)\n\ntest_df = pd.DataFrame(img_test, columns = [\"images\"])\ntest_df[\"target\"] = y_test\n\n#preview\ntest_df.head()","e986c75c":"#merge to get full dataset\nfull_data = pd.concat([train_df, test_df, val_df], axis = 0, ignore_index = True)\nfull_data.info()","ecfd68d4":"#save\nfull_data.to_csv('full_data')","9a2daa97":"print('X_train shape:', X_train.shape)\nprint('y_train shape:', y_train.shape)\nprint('\\n')\n\nprint('X_test shape:', X_test.shape)\nprint('y_test shape:', y_test.shape)\nprint('\\n')\n\nprint('X_val shape:', X_val.shape)\nprint('y_val shape:', y_val.shape)","634daed7":"#we need to reshape them from (64, 64), a 64x64 matrix, to (4096,), a 4096-element vector\nX_train = X_train.reshape(5216, 64*64).astype('float32')\nX_test = X_test.reshape(624, 64*64).astype('float32')\nX_val = X_val.reshape(16, 64*64).astype('float32')","ff8c1cad":"#recheck\nprint('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)\nprint('X_val shape:', X_val.shape)","587c7685":"import keras\nfrom keras import models\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n#initiate\nmlp_model = models.Sequential()\n\n#mulilayers with relu activation\nmlp_model.add(Dense(32, activation = 'relu', input_shape = (4096,)))\nmlp_model.add(Dense(32, activation = 'relu'))\nmlp_model.add(Dense(64, activation = 'relu'))\nmlp_model.add(Dense(128, activation = 'relu'))\n\n#one layer with sigmoid activation \nmlp_model.add(Dense(1, activation = 'sigmoid'))","80cad449":"from keras import optimizers\n\nmlp_model.compile(loss = 'binary_crossentropy',\n                  optimizer = keras.optimizers.Adam(0.0001),\n                  metrics = ['acc'])","648f57af":"mlp_model.summary()","5d37de5a":"from keras.utils.vis_utils import plot_model\n\n#plot\nplot_model(mlp_model, to_file = 'mlp_model_plot.png', show_shapes = True, show_layer_names = True)","29e0640c":"import datetime\nstart = datetime.datetime.now()\n\n#fit\nmlp_history = mlp_model.fit(X_train, y_train,\n                            epochs = 30,\n                            batch_size = 32,\n                            validation_data = (X_test, y_test),\n                            validation_steps = 624 \/\/ 32)","25e07883":"end = datetime.datetime.now()\nelapsed = end - start\nprint('Training took a total of {}'.format(elapsed))","efad2707":"#save model\nmlp_model.save('mlp_model.h5')","2b9bfb21":"fig , ax = plt.subplots(1,2)\nfig.set_size_inches(20, 8)\n\nmlp_train_acc = mlp_history.history['acc']\nmlp_train_loss = mlp_history.history['loss']\nmlp_val_acc = mlp_history.history['val_acc']\nmlp_val_loss = mlp_history.history['val_loss']\n\nepochs = range(1, len(mlp_train_acc) + 1)\n\nax[0].plot(epochs , mlp_train_acc , 'g-o' , label = 'Training Accuracy')\nax[0].plot(epochs , mlp_val_acc , 'y-o' , label = 'Validation Accuracy')\nax[0].set_title('MLP Model Training & Validation Accuracy')\nax[0].legend(loc = 'lower right')\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , mlp_train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , mlp_val_loss , 'y-o' , label = 'Validation Loss')\nax[1].set_title('MLP Model Training & Validation Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\n\nplt.show()","97aa35e0":"#save\nplt.savefig('mlp_model.png')","d176c812":"print('Train loss & accuracy:' , mlp_model.evaluate(X_train, y_train))\nprint('\\n')\nprint('Test loss & accuracy:' , mlp_model.evaluate(X_test, y_test))","016cb55c":"from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n\n#make prediction\nyhat_test = mlp_model.predict_classes(X_test)\n\n#get confusion matrix\ncm = confusion_matrix(y_test, yhat_test)\nprint(cm)","9bcaf334":"#code from https:\/\/www.kaggle.com\/basel99\/chest-x-ray-images-cnn-handling-overfitting\n\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion matrix',\n                          cmap = plt.cm.Blues):\n    \n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    plt.grid(b = None)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis = 1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 fontsize = 12,\n                 horizontalalignment = \"center\",\n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","89358218":"#plot confustion matrix\nplot_confusion_matrix(cm, classes = ['NORMAL (Class 0)','PNEUMONIA (Class 1)'], normalize = False)","38e3980d":"#save\nplt.savefig('mlp_model_cm.png')","2c0cdec0":"from sklearn.metrics import classification_report\n\nprint('Model: Multilayer Perceptron', '\\n', classification_report(y_test, yhat_test, target_names = ['NORMAL (Class 0)','PNEUMONIA (Class 1)']))","99d345fe":"from sklearn.metrics import auc,roc_curve,roc_auc_score\n\nfpr, tpr, thresholds = roc_curve(y_test, yhat_test)\nauc = roc_auc_score(y_test, yhat_test)\nprint('AUC:', auc)\n\nplt.figure(figsize = (10, 5))\nplt.plot(fpr, tpr, color = 'yellow', label = 'ROC curve (area = %f)' % auc)\nplt.plot([0, 1], [0, 1], linestyle = '--', color = 'darkgreen')\nplt.xlim([-0.1, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('MLP Model X-ray Pneumonia Classification')\nplt.legend(loc = \"lower right\")\nplt.show()","e7f457f6":"#save\nplt.savefig('mlp_model_roc.png')","452b7e67":"#summary table\nsummary_table = pd.DataFrame({'Model': [],\n                              'Accuracy': [],\n                              'Precision': [], 'Recall': [], 'F1 Score': [],\n                              'AUC': []})","10300941":"summary_table.loc[0] = ['Multilayer Perceptron Model',\n                        round(accuracy_score(y_test, yhat_test), 2),\n                        round(precision_score(y_test, yhat_test, average = 'macro'), 2), round(recall_score(y_test, yhat_test, average = 'macro'), 2), round(f1_score(y_test, yhat_test, average = 'macro'), 2),\n                        round(roc_auc_score(y_test, yhat_test), 2)]\nsummary_table.head()","75627505":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\n#define the callbacks\nearly_stopping = [EarlyStopping(monitor = 'val_loss', patience = 10, verbose = 1),\n                 ModelCheckpoint(filepath = 'cnn_model.h5', monitor = 'val_loss', save_best_only = True)]","33e1bc26":"from keras.layers import Dropout, Flatten\nfrom keras import regularizers\n\n#initialize\ncnn_model = models.Sequential()\n\n#define model architecture\ncnn_model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\ncnn_model.add(MaxPooling2D((2, 2)))\n\ncnn_model.add(Conv2D(32, (3, 3), activation = 'relu'))\ncnn_model.add(MaxPooling2D((2, 2)))\n\n#fully connected layer\ncnn_model.add(Flatten())\ncnn_model.add(Dense(64, activation = 'relu'))\ncnn_model.add(Dense(128, activation = 'relu'))\n\n#one layer with sigmoid activation \ncnn_model.add(Dense(1, activation = 'sigmoid'))","f0175d1e":"#compile\ncnn_model.compile(loss = 'binary_crossentropy',\n                  optimizer = keras.optimizers.Adam(0.0001),\n                  metrics = ['acc'])","d49e9c95":"#get summary\ncnn_model.summary()","b21c6983":"#plot\nplot_model(cnn_model, to_file = 'cnn_model_plot.png', show_shapes = True, show_layer_names = True)","f895a965":"start = datetime.datetime.now()\n\n#fit\ncnn_history = cnn_model.fit(train_generator,\n                            steps_per_epoch = 5216 \/\/ 32,\n                            epochs = 30,\n                            validation_data = test_generator,\n                            validation_steps = 624 \/\/ 32,\n                            callbacks = early_stopping)","d78a50a2":"#time\nend = datetime.datetime.now()\nelapsed = end - start\nprint('Training took a total of {}'.format(elapsed))","ff08fcd2":"#save model\ncnn_model.save('cnn_model.h5')","935a5e4e":"fig , ax = plt.subplots(1,2)\nfig.set_size_inches(20, 8)\n\ncnn_train_acc = cnn_history.history['acc']\ncnn_train_loss = cnn_history.history['loss']\ncnn_val_acc = cnn_history.history['val_acc']\ncnn_val_loss = cnn_history.history['val_loss']\n\nepochs = range(1, len(cnn_train_acc) + 1)\n\nax[0].plot(epochs , cnn_train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , cnn_val_acc , 'yo-' , label = 'Validation Accuracy')\nax[0].set_title('CNN Model Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , cnn_train_loss , 'go-' , label = 'Training Loss')\nax[1].plot(epochs , cnn_val_loss , 'yo-' , label = 'Validation Loss')\nax[1].set_title('CNN Model Training & Validation Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\n\nplt.show()","6c36a3a5":"#save\nplt.savefig('cnn_model.png')","aa861842":"#evaluate\nprint('Train loss & accuracy:' , cnn_model.evaluate(train_generator))\nprint('\\n')\nprint('Test loss & accuracy:' , cnn_model.evaluate(test_generator))","4e2768e9":"#define target for testing\ny_test = test_generator.classes\n\n#make prediction\nyhat_test = cnn_model.predict_classes(test_generator)\n\n#get confusion matrix\ncm = confusion_matrix(y_test, yhat_test)\nprint(cm)\n\n#plot confusion matrix\nplot_confusion_matrix(cm, classes = ['NORMAL (Class 0)','PNEUMONIA (Class 1)'], normalize = False)","cff162fe":"#save\nplt.savefig('cnn_model_cm.png')","56318572":"#get classification report\nprint('Model: CNN', '\\n', classification_report(y_test, yhat_test, target_names = ['NORMAL (Class 0)','PNEUMONIA (Class 1)']))","3e0796c0":"fpr, tpr, thresholds = roc_curve(y_test, yhat_test)\nauc = roc_auc_score(y_test, yhat_test)\nprint('AUC:', auc)\n\nplt.figure(figsize = (10, 5))\nplt.plot(fpr, tpr, color = 'yellow', label = 'ROC curve (area = %f)' % auc)\nplt.plot([0, 1], [0, 1], linestyle = '--', color = 'darkgreen')\nplt.xlim([-0.1, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('CNN Model X-ray Pneumonia Classification')\nplt.legend(loc = \"lower right\")\nplt.show()","d6b7c037":"#save\nplt.savefig('cnn_model_roc.png')","16f45649":"#update summary table\nsummary_table.loc[1] = ['Convolutional Neural Network Model',\n                        round(accuracy_score(y_test, yhat_test), 2),\n                        round(precision_score(y_test, yhat_test, average = 'macro'), 2), round(recall_score(y_test, yhat_test, average = 'macro'), 2), round(f1_score(y_test, yhat_test, average = 'macro'), 2),\n                        round(roc_auc_score(y_test, yhat_test), 2)]\nsummary_table.head()","21544fe2":"#initialize base CNN\nfrom keras.applications import VGG16\n\ncnn_base = VGG16(include_top = False,\n                 weights = 'imagenet',\n                 input_shape = (150, 150, 3),\n                 classes = 2,\n                 classifier_activation = 'sigmoid')","8b2791da":"#leave the pretrained model frozen to prevent the weights in a given layer from being updated during training.\ncnn_base.trainable = False","94c1e28d":"#define model architecture\npretrainedCNN_model = models.Sequential()\n\npretrainedCNN_model.add(cnn_base)\n\n#fully connected layer\npretrainedCNN_model.add(layers.Flatten())\n\npretrainedCNN_model.add(Dense(640, activation = 'relu'))\npretrainedCNN_model.add(Dropout(0.5))\npretrainedCNN_model.add(Dense(128, activation = 'relu'))\npretrainedCNN_model.add(Dropout(0.5))\n\n#output layer\npretrainedCNN_model.add(layers.Dense(1, activation = 'sigmoid'))","1c955c67":"#check whether a layer is trainable (or alter its setting) \nfor layer in pretrainedCNN_model.layers:\n    print(layer.name, layer.trainable)","03e625b8":"#compile\npretrainedCNN_model.compile(loss = 'binary_crossentropy',\n                            optimizer = keras.optimizers.Adam(0.0001),\n                            metrics = ['acc'])","590fc493":"#get summary\npretrainedCNN_model.summary()","4190a670":"#plot\nplot_model(pretrainedCNN_model, to_file = 'pretrainedCNN_model_plot.png', show_shapes = True, show_layer_names = True)","6d811358":"start = datetime.datetime.now()\n\n#fit\npretrainedCNN_history = pretrainedCNN_model.fit(train_generator,\n                                                steps_per_epoch = 5216 \/\/ 32,\n                                                epochs = 30,\n                                                validation_data = test_generator,\n                                                validation_steps = 624 \/\/ 32,\n                                                callbacks = early_stopping)","39a072ba":"#time\nend = datetime.datetime.now()\nelapsed = end - start\nprint('Training took a total of {}'.format(elapsed))","43ce99d7":"#save model\npretrainedCNN_model.save('pretrainedCNN_model.h5')","a2ade36d":"fig , ax = plt.subplots(1,2)\nfig.set_size_inches(20, 8)\n\npretrainedCNN_train_acc = pretrainedCNN_history.history['acc']\npretrainedCNN_train_loss = pretrainedCNN_history.history['loss']\npretrainedCNN_val_acc = pretrainedCNN_history.history['val_acc']\npretrainedCNN_val_loss = pretrainedCNN_history.history['val_loss']\n\nepochs = range(1, len(pretrainedCNN_train_acc) + 1)\n\nax[0].plot(epochs , pretrainedCNN_train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , pretrainedCNN_val_acc , 'yo-' , label = 'Validation Accuracy')\nax[0].set_title('VGG16 Model Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , pretrainedCNN_train_loss , 'go-' , label = 'Training Loss')\nax[1].plot(epochs , pretrainedCNN_val_loss , 'yo-' , label = 'Validation Loss')\nax[1].set_title('VGG16 Training & Validation Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\n\nplt.show()","bd29e081":"#save\nplt.savefig('VGG16_cnn_model.png')","1f491ae9":"print('Train loss & accuracy:' , pretrainedCNN_model.evaluate(train_generator))\nprint('\\n')\nprint('Test loss & accuracy:' , pretrainedCNN_model.evaluate(test_generator))","69c6cb09":"#make prediction\nyhat_test = pretrainedCNN_model.predict_classes(test_generator)\n\n#get confusion matrix\ncm = confusion_matrix(y_test, yhat_test)\nprint(cm)","3d804df1":"#plot confustion matrix\nplot_confusion_matrix(cm, classes = ['NORMAL (Class 0)','PNEUMONIA (Class 1)'], normalize = False)","43f28deb":"#save\nplt.savefig('VGG16_cnn_model_cm.png')","43419f2f":"#get classification report\nprint('Model: VGG16 CNN Model', '\\n', classification_report(y_test, yhat_test, target_names = ['NORMAL (Class 0)','PNEUMONIA (Class 1)']))","a2f26849":"fpr, tpr, thresholds = roc_curve(y_test, yhat_test)\nauc = roc_auc_score(y_test, yhat_test)\nprint('AUC:', auc)\n\nplt.figure(figsize = (10, 5))\nplt.plot(fpr, tpr, color = 'yellow', label = 'ROC curve (area = %f)' % auc)\nplt.plot([0, 1], [0, 1], linestyle = '--', color = 'darkgreen')\nplt.xlim([-0.1, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('VGG16 CNN Model X-ray Pneumonia Classification')\nplt.legend(loc = \"lower right\")\nplt.show()","efec1499":"#save\nplt.savefig('VGG16_cnn_model_roc.png')","530f4cee":"#update summary table\nsummary_table.loc[2] = ['Transfer Learning: VGG16 CNN Model',\n                        round(accuracy_score(y_test, yhat_test), 2),\n                        round(precision_score(y_test, yhat_test, average = 'macro'), 2), round(recall_score(y_test, yhat_test, average = 'macro'), 2), round(f1_score(y_test, yhat_test, average = 'macro'), 2),\n                        round(roc_auc_score(y_test, yhat_test), 2)]\nsummary_table.head()","e96dccb4":"#save\nsummary_table.to_csv('summary_table.csv')","4eaa2d60":"CNN model is a big improvement on the previous MLP model.\u00a0\n\nBoth of TP and TN are higher than FP and FN. FP is also higher than FN.\n\nThis model perform well with both class Pneumonia and class Normal, with class Pneumonia having a higher F1-score.","1a9e0e12":"# Blog\n\nhttps:\/\/baotramduong.medium.com\/x-ray-pneumonia-classification-with-deep-learning-6a81861150a1","9cfb7b57":"# Pretrained CNN Model\n\nSince the dataset used is small, one method of addressing this lack of data in a given domain is to leverage data from a similar domain, a technique known as Transfer Learning (TL) (Kermany et al., 2018). In short, TL means using what is learned from one task and applying that to another task without learning from scratch.\u00a0\n\nI adapted an VGG16 architecture pretrained on the ImageNet dataset. VGG16 model is composed of convolutions layers, max pooling layers, and fully connected layers. The total is 16 layers, including 13 convolutional layers and 3 fully connected layers, with 5 blocks and each block with a max pooling layer.\n\nAdapting a pretrained model will undoubtedly produce better results than a fresh CNN due to the limited size of training data. We will import a pretrained model VGG16 to use as the convolutional base. By doing this, we transform the dataset into a rich feature space and add a few fully connected layers on top of the pretrained layers to build a classification model.","8c3fe0c1":"* I start with initializing the model by specifying that the model is a Sequential model. Sequential model is the simplest Keras model for neural networks that are composed with just one single stack of layers connected sequentially (Geron, 2019, p.299)\n* The input layer needs to have input_shape = (4096,) specified.\n* Three Dense hidden layers with 32, 64, and 128 neurons, are added after that. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). I also add activation = 'relu' (Rectified Linear Unit) to each layers so that all the negative values will not get passed to the next layer.\n* One output layer with activation = 'sigmoid' is added last. Since this is a binary classification problem, only one single output neuron is needed.","15d16917":"Since I use loss = 'binary_crossentropy', I need to set class mode = 'binary'.\n\nI've found that it is important to set shuffle = False for test set or else when making prediction later, function\u00a0.evaluate() and function\u00a0.predict_classes() will yield different accuracy score. When set to False, data is sorted in alphanumeric order while default is set to True, which shuffles the data.","daba4617":"The pre-trained convolutional layers need to be frozen by setting\u00a0.trainable = False. This will prevent the weights, which are initially calculated and stored in order to reduce redundant processes and speed up training,  in the pre-trained layers from being updated while training and later used as fixed feature extractors.","c625bd20":"### Model Evaluation","138100a5":"The data need to be reshaped from (64, 64), a 64x64 matrix, to (4096,), a 4096-element vector, which is required for learning.","6817b4a1":"The presence of white hazy patches known as \"ground-glass opacity\" indicates pneumonia in infected patient which is absent in healthy persons.\n\nThere are 2 sub-categories for Pneumonia: Bacterial and Viral pathogens, which are the two leading causes of pneumonia, but require very different forms of management. Bacterial pneumonia requires urgent referral for immediate antibiotic treatment, while viral pneumonia is treated with supportive care (Kermany, 2018). For this project, we will only look at Normal vs. Pneumonia as a binary classification problem and will further investigate Normal vs. Viral vs. Bacterial as a multi-class classification problem in the future.","5af6113c":"The model perform better on class Pneumonia than class Normal, as reflected through F1-score.\u00a0\nAlthough some Normal are classified as Pneumonia (FP), the MLP Model performs not so bad in classifying Pneumonia as Pneumonia.\u00a0\n\nMisclassification of Pneumonia as Normal (FN) is very low, which is a good thing. However, although tolerated, the FP is higher than TN, which should be corrected to save medical resources.","1899fbb9":"Train and test accuracy are quite different. The model is overfit, as expected due to large amount of parameters trained on small dataset. The model is overtrained and learned well but it did not generalize well with test data. Training curve and Validation curve do not match each other. Validation Accuracy decreases and Validation Loss increases as the training goes on, which is a sign of a bad model.","eb506fa6":"# Data Augmentation\nTo build a powerful image classifier using very little training data, image augmentation is usually required to boost the performance of deep networks. Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc of each training instances (Geron, 2019, p. 465). To achieve this,\u00a0.ImageDataGenerator() is used. The ImageDataGenerator will automatically label all the data inside Pneumonia folder as Pneumonia and Normal for Normal folder. In this way data is easily ready to be passed to the neural network.","c5f0ee71":"# Future Work\n1. Build a multi-class classification deep learning model to distinguish between Normal, Viral Pneumonia, and Bacterial Pneumonia\n\n2. Combine CNN models with other classifiers such as Support Vector Machine (SVM)\u00a0\n\n3. Tune parameters such as learning rate, batch size, try another optimizer, number of layers, different types of layer, number of neurons per layer, and the type of activation functions for each layer. GridSearchCV or RandomizedSearchSV can be used to achieve this.","089b42e6":"During fitting, I specify that my validation_data = test_generator, which uses the test set to validate training. Since there is 624 images in the test set, validation step = 624 \/\/ 32, where 32 is the batch_size.","5b0b1ddd":"Using test set as validation data (X_test and y_test), I fit the model with X_train and y_train.","b89fda27":"# Data Visualization","42d0f652":"I see that validation set only has 16 images, which is significantly smaller than train set of 5216 images. I made the decision to not use this set to validate training but use test set instead.","0ec65798":"There are a lot of parameters for each Dense layer. For example, the first hidden layer has 32 x 4096 connection weights plus 32 bias terms, adds up to 131104 parameters. Since we do not have a large dataset, we run the risk of overfitting our model because of this.","f3a1ef26":"The MLP model performance is not great. For future work, we can tune parameters such as learning rate, batch size, try another optimizer, number of layers, number of neurons per layer, and the type of activation functions for each layer.","9547f4c2":"Next, I compile the model and specify the loss function, the optimizer, and the metrics to use. Since the problem is binary classification and I use 'sigmoid' as activation function in the output layer, I have to use loss = 'binary_crossentropy' here.\n\nThe learning rate indicates at which pace the weights get updated. It can be fixed or adaptively changed. The current most popular optimizer is Adam, which is a method that adapts the learning rate, is used. ","e40aa09b":"Train and test accuracy are similar. The model is not overfit. Train curve and Validation curve are following each other closely. Accuracy improves overtime and Loss decreases overtime.","a9082a1f":"# Github\n\nhttps:\/\/github.com\/baotramduong\/Portfolio_Project_Deep_Learning_Image_Classification","bccec060":".predict() is for predicting target value, predicted from our test data","8a508a92":".flow_from_directory is used to get all of the augmented data into the directory. The function passes the folder which has train data to the object train_generator and similarly passes the folder which has test data to the object test_generator, and val data to the object val_generator.","c54fc477":"I add callbacks to monitor a specific parameter of the model, in this case, val_acc. Since I use a validation set during training, I set save_best_only = True in ModelCheckpoint to specify that the model will only be saved when its performance on the validation set is best.\n\nI also set patience = 10 for EarlyStopping, meaning that the model will stop training if it doesn't see any improvement in val_acc in 10 epochs.","9efe32e8":"# Convolutional Neural Network Model (CNN)","cf1f423f":"Keras measures the loss and accuracy at the end of every epoch. All training acc and val_acc can be found with\u00a0.history. I will use this information to plot accuracy and loss of the model.","6f5f898b":"Right away we can see that there is a class imbalance problem. There are more Pneumonia cases than Normal cases. I see this as an advantage as the model will tend to do better on the major class (Pneumonia) than on the minor class (Normal). The FP (Normal classified as Pneumonia) will be high, but this is significantly less costly than FN (Pneumonia classified as Normal), which can be a fatal mistake. Hence, we will not correct this class imbalance.","2b0e55e3":"A CNN architecture is composed of convolutional layer with ReLU, pooling layer, fully connected layer, and loss layer.\n* Start by initializing a Sequential model.\n* Of course a CNN model needs to have convolutional layers, which is the core block of a CNN model. Convolutional layers apply a filter to input and create a feature map that summarizes the presence of detected features in the input. As observed in the above figure, the input image gets smaller and smaller as it progresses through the network but it also gets deeper and deeper with feature map. I add one Conv2D layer with a filter\/kernel size of 3 x 3, adding ReLU activation function to set negative values to zero, and specify input_shape = (150, 150, 3).\n* Pooling layer is sandwiched between two successive convolutional layers to reduce the spatial size of the convoluted feature\/ parameters in the network. MaxPooling is the most common pooling methods to reduce image size by pooling the most important feature. Here I use MaxPool2D with a pool size of 2, meaning it divides each spatial dimension by a factor of 2.\n* I repeat the above one more time\n* Afterward, a Flatten layer is added to convert each input image into a 1D array: if it receives input data X, it computes X.reshape(-1, 1). The flatten data that comes out of the convolutions and is then fed to the fully connected layers, which consist of two hidden Dense layers and an output hidden Dense layer with one neuron using activation = 'sigmoid'.","f2ff347b":"# Multilayer Perceptron Model (MLP)","0778e1e1":"First, I initialize VGG16 model and use weights = 'imagenet', which is a large visual database designed for use in visual object recognition software research. This database has over 15 million labeled high-resolution images belonging to roughly 22,000 categories.","ceb4f0df":"# Reference\n\nGeron, A. (2019). Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems (2nd ed.). O'Reilly.\n\nKermany, D. S., Goldbaum, M., Cai, W., Valentim, C., Liang, H., Baxter, S. L., McKeown, A., Yang, G., Wu, X., Yan, F., Dong, J., Prasadha, M. K., Pei, J., Ting, M., Zhu, J., Li, C., Hewett, S., Dong, J., Ziyar, I., Shi, A.,\u00a0\u2026 Zhang, K. (2018). Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning. Cell, 172(5), 1122\u20131131.e9. https:\/\/doi.org\/10.1016\/j.cell.2018.02.010\n\nUnicef. (2021, April 07). Pneumonia in children statistics. Retrieved April 13, 2021, from https:\/\/data.unicef.org\/topic\/child-health\/pneumonia\/#:~:text=A%20child%20dies%20of%20pneumonia,of%20these%20deaths%20are%20preventable.","360de167":"Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children's Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients' routine clinical care.","3842102c":"* Sequential model is initialized.\n* VGG16 is added as cnn_base.\n* After the images are trained through the cnn_base, they are retrained through fully connected layers to classify the specific categories of Normal and Pneumonia. Each Dense layer are followed with Dropout layers whose function is to reduce overfitting by reducing the number of neurons.\n* The final fully connected layer is the classification layer with actitvation = 'sigmoid'.","43693229":"# **Introduction**\nAccording to Unicef (2021):\n* Globally, a child dies of pneumonia every 39 seconds.\n* Pneumonia claims the lives of over 800,000 children under five every year, or around 2,200 every day. This includes over 153,000 newborns.\n* Pneumonia is a leading cause of morbidity and mortality in children younger than the age of 5 years, killing more children than HIV\/AIDS, malaria, and measles combined.\n\nChest X-rays are primarily used for the diagnosis of this disease. However, even for a trained radiologist, it is a challenging task to examine chest X-rays.\u00a0\nTo solve this, deep learning (DL), a branch of machine learning (ML), inspired by the make-up of the human brain, are developed to detect hidden features in images which are not apparent or cannot be detected even by medical experts. With AI system aiding medical experts in expediting the diagnosis, earlier treatment can be prescribed, resulting in improved clinical outcomes.","b348d293":".evaluate() is for evaluating our trained model","06230ed5":"### Model Evaluation","a965bbdb":"In terms of DL, convolutional neural network (CNN) is the leading DL tool that is used to analyze visual images. In healthcare, CNN is a powerful tool due to its ability to extract features and learn to distinguish between different classes such as positive and negative, infected and healthy, or in this case, Pneumonia and Normal.","a89b7f98":"Train and test accuracy are similar. The model is not overfit. We can see that the Train curve and Validation curve are closely resemble each other. As training goes on, both Accuracy curves increases while Loss curve decreases, which indicates a well-trained, well-generalized model.","63cd1747":"### Model Evaluation"}}