{"cell_type":{"393357bc":"code","4ad45286":"code","693e9530":"code","e5f6cf3c":"code","2a5c6dbe":"code","8a265e85":"markdown","fdbd427e":"markdown"},"source":{"393357bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ad45286":"\n    \n\ndef load_data():\n    # load data\n    train = pd.read_feather(pathlib.Path(INPUT_TRAIN_DIR + 'train.feather'))\n    tournament = pd.read_feather(pathlib.Path(INPUT_TEST_DIR + 'test.feather'))\n    \n    # split valid and test\n    valid = tournament[tournament[\"data_type\"] == \"validation\"].reset_index(drop = True)\n    \n    # drop data type\n    train.drop(columns=['data_type'], inplace=True)\n    valid.drop(columns=['data_type'], inplace=True)\n    tournament.drop(columns=['data_type'], inplace=True)\n    \n    # era int\n    train[\"era\"] = train[\"era\"].apply(get_int)\n    valid[\"era\"] = valid[\"era\"].apply(get_int)\n    tournament[\"era\"] = tournament[\"era\"].apply(get_int)\n","693e9530":"%%time\n\ndef get_int(x):\n    try:\n        return int(x[3:])\n    except:\n        return 1000\n    \ndef read_data(filepath):\n    # load raw data\n    df = pd.read_csv(filepath)\n    \n    # feature cast to int\n    feature_cols = df.columns[df.columns.str.startswith('feature')]\n    mapping = {0.0 : 0, 0.25 : 1, 0.5 : 2, 0.75 : 3, 1.0 : 4}\n    for c in feature_cols:\n        df[c] = df[c].map(mapping).astype(np.uint8)\n        \n    # era to int\n    df[\"era\"] = df[\"era\"].apply(get_int)\n    \n    print('data shape: ', df.shape)\n    return df","e5f6cf3c":"%%time\n\n# train\ndf = read_data('..\/input\/numerai-tournament-data-updated-weekly\/latest_numerai_training_data.csv.xz')\ndf.drop(columns=['data_type'], inplace=True)\ndf.to_feather('train.feather')\nprint('train saved!')\n\ndel df\ngc.collect()","2a5c6dbe":"%%time\n\n# tournament\ndf = read_data('..\/input\/numerai-tournament-data-updated-weekly\/latest_numerai_tournament_data.csv.xz')\n\n# validation\nvalid = df.loc[df['data_type'] == 'validation', :].reset_index(drop=True)\nvalid.drop(columns=['data_type'], inplace=True)\n\nvalid.to_feather('valid.feather')\nprint('validation saved!')\n\n# tournament\ndf.drop(columns=['data_type'], inplace=True)\ndf.to_feather('tournament.feather')\nprint('train saved!')","8a265e85":"All done!","fdbd427e":"Load raw Numerai Tournament Data and preprocess to reduce the memory demand."}}