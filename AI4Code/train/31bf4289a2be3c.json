{"cell_type":{"ce3d1697":"code","9f6d15a4":"code","b881a661":"code","ed95f9f8":"code","4ea2da9c":"code","1a637494":"code","6a565767":"code","dd172fad":"code","ef09cef9":"code","d56ea55d":"code","9b4959ed":"code","89acff3a":"code","9cc5d206":"code","296076d4":"code","941b2b3b":"code","a6e1033f":"code","f4b95d20":"code","8ab449ca":"code","127dd38c":"code","8fee6c0e":"code","6e46ea1d":"code","05780cb9":"markdown","1e746ac9":"markdown","d5aaa81d":"markdown","354060c0":"markdown","ab9bb469":"markdown","22a148c3":"markdown","83b53bbc":"markdown","0812bd83":"markdown","032c7e97":"markdown"},"source":{"ce3d1697":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom time import time\nimport pickle\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f6d15a4":"df = pd.read_csv('\/kaggle\/input\/scl-2021-ds\/train.csv')\npoi_street_df = df[\"POI\/street\"].str.split(\"\/\", n = 1, expand = True) \ndf[\"POI\"]= poi_street_df[0] \ndf[\"street\"]= poi_street_df[1] \ndf1 = df.drop([\"POI\/street\"], axis=1) \ndf1","b881a661":"def find_first_index(ra_split, st_split):\n    \n    if len(st_split) <= len(ra_split): # new\n    \n        num_iter = len(ra_split) - len(st_split) + 1\n        overlap_list = []\n\n        for i in range(num_iter):\n            window = ra_split[i: i+len(st_split)]\n            overlap = list(set(window) & set(st_split))\n            overlap_list.append(len(overlap))\n\n        max_overlap = [e for e in range(len(overlap_list)) if overlap_list[e] == max(overlap_list)]\n        if len(max_overlap) == 1:\n            return max_overlap[0]\n\n        else:\n            count_list = []\n            for idx in max_overlap:\n                subset_ra = ra_split[idx: idx+len(st_split)]\n                count = 0\n                for e in range(len(subset_ra)):\n                    if subset_ra[e] not in st_split[e]:\n                        count += 0\n                    else:\n                        count += 1\n                count_list.append(count)\n            index = count_list.index(max(count_list))\n            return max_overlap[index]\n    else:\n        return 0","ed95f9f8":"def fix_street_errors(row):\n    \n    raw_add = row['raw_address']\n\n    # If a street name is extracted...\n    if row['street'] != \"\":\n\n        raw_add_split = word_tokenize(raw_add)\n        \n        extr_street = row['street']\n        extr_street_split = word_tokenize(extr_street)\n        \n        # If the extracted street is in the raw address as an entire string, good!\n        if extr_street in raw_add:\n            return raw_add\n        \n        # This is where there are discrepancies!\n        else:\n            index_in_ra = find_first_index(raw_add_split, extr_street_split)\n            raw_add_split[index_in_ra: index_in_ra+len(extr_street_split)] = extr_street_split\n            updated_raw_add = ' '.join(raw_add_split).replace(' ,', ',').replace(' .', '.').replace(' )', ')').replace(' (', '(').replace(' ?', '?')          \n            return updated_raw_add\n      \n    # If a street name is originally an empty string, we just assume there's no error. \n    else:\n        return raw_add","4ea2da9c":"start = time()\n\ndf1['cleaned_raw_add'] = df1.apply(fix_street_errors, axis=1)\n\nprint(\"Executed in {} minutes.\".format(round((time() - start)\/60, 3)))\n\n# Sanity checks\ndf1.loc[[69, 86, 117, 130, 135, 169], :]","1a637494":"def get_street_mapping_dict(row):\n    \n    raw_add = row['raw_address']\n\n    # If a street name is extracted...\n    if row['street'] != \"\":\n\n        raw_add_split = word_tokenize(raw_add)\n        \n        extr_street = row['street']\n        extr_street_split = word_tokenize(extr_street)\n        \n        # If the extracted street is in the raw address as an entire string, good!\n        if extr_street in raw_add:\n            return None\n        \n        # This is where there are discrepancies!\n        else:\n            index_in_ra = find_first_index(raw_add_split, extr_street_split)\n            before = raw_add_split[index_in_ra: index_in_ra+len(extr_street_split)] \n            before = ' '.join(before)\n            return before, extr_street\n      \n    # If a street name is originally an empty string, we just assume there's no error. \n    else:\n        return None","6a565767":"start = time()\n\ndf1['street_mapping'] = df1.apply(get_street_mapping_dict, axis=1)\n\nprint(\"Executed in {} minutes.\".format(round((time() - start)\/60, 3)))\n\n# Sanity checks\ndf1.loc[[69, 86, 117, 130, 135, 169], :]","dd172fad":"# Create a separate dataframe containing only values in `street_mapping` columns, i.e., rows where changes occurred\ndf_with_street_mappings = df1[df1['street_mapping'].notnull()]\n\nstreet_mapping_dict = dict()\n\n# Create a mapping dictionary, where key is the truncated word\/words and the value is the corresponding correct word\/words\nfor row, col in df_with_street_mappings.iterrows():\n    street_mapping_dict[col['street_mapping'][0]] = col['street_mapping'][1]\n    \n# How many street errors are there altogether?\nprint(\"Length of street mapping dictionary:\", len(street_mapping_dict))","ef09cef9":"def fix_poi_errors(row):\n    \n    raw_add = row['cleaned_raw_add']\n\n    # If a POI name is extracted...\n    if row['POI'] != \"\":\n\n        raw_add_split = word_tokenize(raw_add)\n        \n        extr_poi = row['POI']\n        extr_poi_split = word_tokenize(extr_poi)\n        \n        # If the extracted POI is in the raw address as an entire string, good!\n        if extr_poi in raw_add:\n            return raw_add\n        \n        # This is where there are discrepancies!\n        else:\n            index_in_ra = find_first_index(raw_add_split, extr_poi_split)\n            raw_add_split[index_in_ra: index_in_ra+len(extr_poi_split)] = extr_poi_split\n            updated_raw_add = ' '.join(raw_add_split).replace(' ,', ',').replace(' .', '.').replace(' )', ')').replace(' (', '(').replace(' ?', '?')          \n            return updated_raw_add\n      \n    # If a POI name is originally an empty string, we just assume there's no error. \n    else:\n        return raw_add","d56ea55d":"start = time()\n\ndf1['cleaned_raw_add_1'] = df1.apply(fix_poi_errors, axis=1)\n\nprint(\"Executed in {} minutes.\".format(round((time() - start)\/60, 3)))\n\n# Sanity checks\ndf1.loc[[10, 11, 40, 110, 152, 157, 169], :]","9b4959ed":"def get_poi_mapping_dict(row):\n    \n    raw_add = row['cleaned_raw_add']\n\n    # If a POI name is extracted...\n    if row['POI'] != \"\":\n\n        raw_add_split = word_tokenize(raw_add)\n        \n        extr_poi = row['POI']\n        extr_poi_split = word_tokenize(extr_poi)\n        \n        # If the extracted POI is in the raw address as an entire string, good!\n        if extr_poi in raw_add:\n            return None\n        \n        # This is where there are discrepancies!\n        else:\n            index_in_ra = find_first_index(raw_add_split, extr_poi_split)\n            before = raw_add_split[index_in_ra: index_in_ra+len(extr_poi_split)] \n            before = ' '.join(before)\n            return before, extr_poi\n      \n    # If a POI name is originally an empty string, we just assume there's no error. \n    else:\n        return None","89acff3a":"start = time()\n\ndf1['poi_mapping'] = df1.apply(get_poi_mapping_dict, axis=1)\n\nprint(\"Executed in {} minutes.\".format(round((time() - start)\/60, 3)))\n\n# Sanity checks\ndf1.loc[[10, 11, 40, 110, 152, 157, 169], :]","9cc5d206":"# Create a separate dataframe containing only values in `poi_mapping` columns, i.e., rows where changes occurred\ndf_with_poi_mappings = df1[df1['poi_mapping'].notnull()]\n\npoi_mapping_dict = dict()\n\n# Create a mapping dictionary, where key is the truncated word\/words and the value is the corresponding correct word\/words\nfor row, col in df_with_poi_mappings.iterrows():\n    poi_mapping_dict[col['poi_mapping'][0]] = col['poi_mapping'][1]\n    \n# How many POI errors are there altogether?\nprint(\"Length of POI mapping dictionary:\", len(poi_mapping_dict))","296076d4":"# Select required columns\ncleaned_df = df1[['id','cleaned_raw_add_1', 'POI', 'street']]\n\n# Rename columns\ncleaned_df.columns = ['id', 'raw_address', 'POI', 'street']\n\n# Sanity checks\ncleaned_df.loc[[10, 11, 40, 69, 86, 110, 117, 130, 135, 152, 157, 169], :]","941b2b3b":"# Load test dataset\ntest_df = pd.read_csv('\/kaggle\/input\/scl-2021-ds\/test.csv')\n\n# Preview\ntest_df.head()","a6e1033f":"new_street_mapping_dict = {k: v for k, v in street_mapping_dict.items() if len(k.split()) > 1}\nnew_poi_mapping_dict = {k: v for k, v in poi_mapping_dict.items() if len(k.split()) > 1}\n\nprint(\"Length of street mapping dictionary after removing single words:\", len(new_street_mapping_dict))\nprint(\"Length of POI mapping dictionary after removing single words:\", len(new_poi_mapping_dict))","f4b95d20":"start = time()\n\n# Replace truncated words in raw_address of test set with correct street labels\ncount1 = 0\nfor row, col in test_df.iterrows():\n    for k, v in new_street_mapping_dict.items():\n        if k in col['raw_address']:\n            test_df.loc[row, 'raw_address'] = test_df.loc[row, 'raw_address'].replace(k, v)\n            count1 += 1\n            \nprint(\"Number of raw addresses updated due to errors in street labels:\", count1)\n\n# Replace truncated words in raw_address of test set with correct POI labels\ncount2 = 0\nfor row, col in test_df.iterrows():\n    for k, v in new_poi_mapping_dict.items():\n        if k in col['raw_address']:\n            test_df.loc[row, 'raw_address'] = test_df.loc[row, 'raw_address'].replace(k, v)\n            count2 += 1\n\nprint(\"Number of raw addresses updated due to errors in POI labels:\", count2)\n\nprint(\"Executed in {} minutes.\".format(round((time() - start)\/60, 3)))\n\ntest_df","8ab449ca":"# 0\n# s. par 53 sidanegara 4 cilacap tengah to be replaced with s. par\n# Updated:  s. parman 53 sidanegara 4 cilacap tengah\n# 1\n# angg per, baloi indah kel. lubuk baja to be replaced with angg per\n# Updated:  anggrek per, baloi indah kel. lubuk baja\n# 2\n# asma laun, mand imog, to be replaced with , man\n# Updated:  asma laun, mangund imog,\n# 3\n# ud agung rej, raya nga sri wedari karanganyar to be replaced with raya nga\n# Updated:  ud agung rej, raya ngawi- sri wedari karanganyar\n# 5\n# pem dos dapur ala perum gar no a 12 suka jaya sukarami to be replaced with perum gar\n# Updated:  pem dos dapur ala perumahan gar no a 12 suka jaya sukarami\n# 9\n# raya won wonotunggal wonotunggal to be replaced with raya won\n# Updated:  raya wonoso wonotunggal wonotunggal\n# 10\n# tebet timur tebet raya 92 rt 2 1 tebet to be replaced with bet raya\n# Updated:  tebet timur tebetung raya 92 rt 2 1 tebet\n# 14\n# toko teddy raya pan jakat, to be replaced with raya pan\n# Updated:  toko teddy raya pandan jakat,\n# 14\n# toko teddy raya pan jakat, to be replaced with raya pan jakat\n# Updated:  toko teddy raya pandan jakat,\n# 36\n# m. t. haryono, no 11 bank neg indonesia kali rejo ungaran timur to be replaced with bank negara indonesia\n# Updated:  m. t. haryono, no 11 bank negara indonesiaesia kali rejo ungaran timur\n# 36\n# m. t. haryono, no 11 bank neg indonesia kali rejo ungaran timur to be replaced with bank negara indonesia\n# Updated:  m. t. haryono, no 11 bank negara indonesiaesia kali rejo ungaran timur\n# 47\n# rezi, pasar raya to be replaced with pasar campor\n# Updated:  rezi, pasar campor\n# 52\n# mas nurul huda badang ngoro to be replaced with masjid nurul huda\n# Updated:  masjid nurul huda badang ngoro\n# 86\n# kateguhan roti bakar bandung pak budi, jenderal sudirman, to be replaced with roti bakar bandung\n# Updated:  kateguhan roti bakar bandungung pak budi, jenderal sudirman,\n# 92\n# kenc utama ii kembangan selatan 7 kembangan to be replaced with kencana utama\n# Updated:  kencana utama ii kembangan selatan 7 kembangan","127dd38c":"# Save the cleaned train dataset\ncleaned_df.to_csv('cleaned_train.csv', index=False)\n\n# Save the cleaned test dataset\ntest_df.to_csv('cleaned_test.csv', index=False)","8fee6c0e":"# Save the dictionaries\ns_file = open(\"street_mapping_dict.pkl\", \"wb\")\npickle.dump(street_mapping_dict, s_file)\ns_file.close()\n\np_file = open(\"poi_mapping_dict.pkl\", \"wb\")\npickle.dump(street_mapping_dict, p_file)\np_file.close()","6e46ea1d":"# s_file = open(\"street_mapping_dict.pkl\", \"rb\")\n# street_mapping_dict = pickle.load(s_file)\n# print(street_mapping_dict)\n\n# p_file = open(\"poi_mapping_dict.pkl\", \"rb\")\n# poi_mapping_dict = pickle.load(p_file)\n# print(poi_mapping_dict)","05780cb9":"### Note: Run the following codes to load the two dictionaries","1e746ac9":"### 4. Likewise, we also build a dictionary mapping the incorrect\/incomplete POI names in `raw_address` to the correct `POI` labels. ","d5aaa81d":"## Data Cleaning\n\n### 1. Let's fix discrepancies between `street` and `raw_address` labels.","354060c0":"### 6. Now that we have the two mapping dictionaries, let's check whether some of those truncated words exist in the test data, and if so, replace them with the correct labels. ","ab9bb469":"### 3. Next, let's rectify discrepancies between `POI` and `raw_address` labels.","22a148c3":"### 5. We've cleaned the raw address to make sure that it tallies with both the extracted `street` and `POI` labels. Now, let's tidy things up. ","83b53bbc":"### 7. Save the cleaned-up train and test datasets, as well as the two mapping dictionaries.","0812bd83":"It might be risky to replace single words like `par` in the test data as they may form part of a bigger word that is different from the intended word. For example, we should not replace \"par\" in the address \"daya paru 43\" with its value in the `street_mapping_dict`, \"parigi\". This is less likely the case if there are two or more words.\n\nLet's try to filter out single words from the list.","032c7e97":"### 2. We also build a dictionary mapping the incorrect\/incomplete street names in `raw_address` to the correct `street` labels. "}}