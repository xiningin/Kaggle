{"cell_type":{"8fade562":"code","bf98cefd":"code","e43c316e":"code","390a0d5a":"code","57bb5d42":"code","4dbc7fd8":"code","a54170a8":"code","d2ae6374":"code","10413b9a":"code","2be5cd4a":"code","f110edf7":"code","7b47e83b":"code","dc79bf3a":"code","ed1a76bb":"code","f6c05d39":"code","23c3f8b5":"code","1a756277":"code","165b8a6b":"code","3acf34c6":"code","cefc4fa6":"code","a4ebf177":"code","f43a0ad5":"code","a64b6652":"code","924aafed":"code","18f1de11":"code","9fbc7a57":"code","1568b4b2":"code","a338dea1":"code","4a0d3dde":"code","3a30220a":"code","5fb86981":"code","5f229f9b":"code","94c5d48a":"code","a8dc3678":"code","48742d87":"code","61b3b2d6":"code","215853c3":"code","fa64bd73":"code","31509f49":"code","d3dd66a0":"code","89d4892a":"markdown","f8d63af5":"markdown","7770dcbf":"markdown"},"source":{"8fade562":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bf98cefd":"pd.pandas.set_option('display.max_columns',None)\ndf=pd.read_csv('\/kaggle\/input\/weatherww2\/Summary of Weather.csv')","e43c316e":"df.head()","390a0d5a":"df.describe()","57bb5d42":"## 1 -step make the list of features which has missing values\nmissing=[features for features in df.columns if df[features].isnull().sum()>1]\n## 2- step print the feature name and the percentage of missing values\n\nfor feature in missing:\n    print(feature, np.round(df[feature].isnull().mean(), 3)*100,  ' % missing values')","4dbc7fd8":"df.isnull().sum()","a54170a8":"cols=[feature for feature in df.columns  if(df[feature].isnull().sum()\/df.shape[0]*100<70)]\nnew_df=df[cols]\nnew_df=new_df.drop(['STA'],axis=1)\nprint('actual columns after dropping null values are  %s'%new_df.shape[1])","d2ae6374":"new_df.isnull().sum()","10413b9a":"new_df.dtypes","2be5cd4a":"new_df.Date.unique()","f110edf7":"new_df['Date']=pd.to_datetime(new_df['Date'])\nnew_df['Date'].head(300)","7b47e83b":"new_df['Snowfall'].unique()","dc79bf3a":"new_df['SNF'].unique()","ed1a76bb":"new_df['Precip']=pd.to_numeric(new_df['Precip'],errors='coerce')\nnew_df['Snowfall']=pd.to_numeric(new_df['Snowfall'],errors='coerce')\nnew_df['PRCP']=pd.to_numeric(new_df['PRCP'],errors='coerce')\nnew_df['SNF']=pd.to_numeric(new_df['SNF'],errors='coerce')\n","f6c05d39":"new_df.head()","23c3f8b5":"new_df.columns","1a756277":"from sklearn.preprocessing import minmax_scale\n\nnew_df['Precip_scaled'] = minmax_scale(new_df['Precip'])\nnew_df['MaxTemp_scaled'] = minmax_scale(new_df['MaxTemp'])\nnew_df['MinTemp_scaled'] = minmax_scale(new_df['MinTemp'])\nnew_df['YR_scaled'] = minmax_scale(new_df['YR'])\nnew_df['MAX_scaled'] = minmax_scale(new_df['MAX'])\nnew_df['Snowfall_scaled'] = minmax_scale(new_df['Snowfall'])\n\n\n","165b8a6b":"new_df.columns","3acf34c6":"#plot the graphs\nimport matplotlib.pyplot as plt\nimport seaborn as sns","cefc4fa6":"fig,ax=plt.subplots(4,2,figsize=(15,15))\nsns.distplot(new_df['Precip'],ax=ax[0][0])\nsns.distplot(new_df['Precip_scaled'],ax=ax[0][1])\n\nsns.distplot(new_df['MaxTemp'],ax=ax[1][0])\nsns.distplot(new_df['MaxTemp_scaled'],ax=ax[1][1])\n\nsns.distplot(new_df['MinTemp'],ax=ax[2][0])\nsns.distplot(new_df['MinTemp_scaled'],ax=ax[2][1])\n\n\nsns.distplot(new_df['MAX'],ax=ax[3][0])\nsns.distplot(new_df['MAX_scaled'],ax=ax[3][1])\n\n\n\n","a4ebf177":"from scipy.stats import boxcox\n\nPrecip_norm = boxcox(new_df['Precip_scaled'].loc[new_df['Precip_scaled'] > 0])\n#MeanTemp_norm = boxcox(new_df['MeanTemp_scaled'].loc[new_df['MeanTemp_scaled'] > 0])\n\nYR_norm = boxcox(new_df['YR_scaled'].loc[new_df['YR_scaled'] > 0])\nSnowfall_norm = boxcox(new_df['Snowfall_scaled'].loc[new_df['Snowfall_scaled'] > 0])\n\nMAX_norm = boxcox(new_df['MAX_scaled'].loc[new_df['MAX_scaled'] > 0])\n#MIN_norm = boxcox(new_df['MIN_scaled'].loc[new_df['MIN_scaled'] > 0])","f43a0ad5":"new_df.dtypes","a64b6652":"import statsmodels\nfig, ax = plt.subplots(4, 2, figsize=(15, 15))\n\nsns.distplot(new_df['Precip_scaled'], ax=ax[0][0],kde=False)\nsns.distplot(Precip_norm[0], ax=ax[0][1],kde=False)\n\n\nsns.distplot(new_df['Snowfall_scaled'], ax=ax[1][0],kde=False)\nsns.distplot(Snowfall_norm[0], ax=ax[1][1],kde=False)\n\nsns.distplot(new_df['MAX_scaled'], ax=ax[2][0],kde=False)\n#sns.distplot(MAX_norm[0], ax=ax[2][1],kde=False)","924aafed":"from scipy.stats import boxcox\n\nPrecip_norm = boxcox(new_df['Precip_scaled'].loc[new_df['Precip_scaled'] > 0])\n\nYR_norm = boxcox(new_df['YR_scaled'].loc[new_df['YR_scaled'] > 0])\nSnowfall_norm = boxcox(new_df['Snowfall_scaled'].loc[new_df['Snowfall_scaled'] > 0])\nMAX_norm = boxcox(new_df['MAX_scaled'].loc[new_df['MAX_scaled'] > 0])\n","18f1de11":"#hnadle NAN values\nnew_df.interpolate(method='linear',inplace=True)\nnew_df","9fbc7a57":"new_df.isnull().sum()","1568b4b2":"new_df.head()","a338dea1":"new_df.plot(x='MaxTemp_scaled',y='MinTemp_scaled',style='*')\nplt.title('temperature')\nplt.xlabel('min temp')\nplt.ylabel('max temp')\nplt.show()","4a0d3dde":"#because sklearn expects a 2D array as input\nX = new_df['MinTemp_scaled'].values.reshape(-1,1)\ny = new_df['MaxTemp_scaled'].values.reshape(-1,1)","3a30220a":"from sklearn.model_selection import train_test_split","5fb86981":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)","5f229f9b":"X_train.shape","94c5d48a":"y_train.shape","a8dc3678":"from sklearn.linear_model import LinearRegression","48742d87":"reg=LinearRegression()\nreg","61b3b2d6":"reg.fit(X_train,y_train)","215853c3":"#To retrieve the intercept:\nprint(reg.intercept_)\n\n#For retrieving the slope:\nprint(reg.coef_) \n","fa64bd73":"y_pred=reg.predict(X_test)\ny_pred","31509f49":"from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics","d3dd66a0":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","89d4892a":"**Normalization**","f8d63af5":"*from above we can see that root mean squared error is 0.05 which is less than 10% \nso our algo can work fine!! if any query you can suggest*","7770dcbf":"**perfom scaling**"}}