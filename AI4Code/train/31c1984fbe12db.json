{"cell_type":{"cca58ca9":"code","6ae28d3a":"code","6306cc14":"code","a2e79191":"code","f9597756":"code","3c53ce53":"code","17c2c88d":"code","d217fa0d":"code","a4eba022":"code","741da1b0":"code","d53e8c91":"code","f3e56a76":"code","f929e4c0":"markdown"},"source":{"cca58ca9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6ae28d3a":"import csv\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom os import getcwd\nimport pandas as pd","6306cc14":"train_mnist = pd.read_csv(\"..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv\")","a2e79191":"train_mnist.head()","f9597756":"def get_data(filename):\n    with open(filename) as training_file:\n        reader = csv.reader(training_file, delimiter=',')    \n        imgs = []\n        labels = []\n\n        next(reader, None)\n        \n        for row in reader:\n            label = row[0]\n            data = row[1:]\n            img = np.array(data).reshape((28, 28))\n\n            imgs.append(img)\n            labels.append(label)\n\n        images = np.array(imgs).astype(float)\n        labels = np.array(labels).astype(float)\n    return images, labels","3c53ce53":"path_sign_mnist_train = \"..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv\"\npath_sign_mnist_test = \"..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv\"\ntraining_images, training_labels = get_data(path_sign_mnist_train)\ntesting_images, testing_labels = get_data(path_sign_mnist_test)\n\nprint(training_images.shape)\nprint(training_labels.shape)\nprint(testing_images.shape)\nprint(testing_labels.shape)","17c2c88d":"training_images = np.expand_dims(training_images,axis=3)\ntesting_images = np.expand_dims(testing_images,axis=3)","d217fa0d":"# Create an ImageDataGenerator and do Image Augmentation\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n    )\n\nvalidation_datagen = ImageDataGenerator(rescale=1. \/ 255 )\n    \n# Keep These\nprint(training_images.shape)\nprint(testing_images.shape)","a4eba022":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(26, activation='softmax')  # as there are 26 classes (0-25)\n])\n\n# Compile Model. \nmodel.compile(optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'])\n              \n              \ntrain_gen = train_datagen.flow(\n    training_images,\n    training_labels,\n    batch_size=20\n)\n\nval_gen = validation_datagen.flow(\n    testing_images,\n    testing_labels,\n    batch_size=20\n)","741da1b0":"# Train the Model\nhistory = model.fit_generator(train_gen,\n    epochs=20,\n    validation_data=val_gen)\n\nmodel.evaluate(testing_images, testing_labels, verbose=0)","d53e8c91":"import matplotlib.pyplot as plt\nacc =history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","f3e56a76":"plt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","f929e4c0":"### The first line contains the column headers so, ignore it\n###   Each successive line contians 785 comma separated values between 0 and 255\n###   The first value is the label\n###   The rest are the pixel values for that picture\n###   Now created the function, that will return 2 np.array types. \n###   One with all the labels and other with all the images"}}