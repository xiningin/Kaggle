{"cell_type":{"d8758318":"code","02b892d9":"code","cb1a9ba4":"code","df18a0b7":"code","5a8d1c33":"code","6c7f2525":"code","d50ba740":"code","abc57702":"code","1f9db55f":"code","a549b266":"code","be845524":"code","9944bcd2":"code","b4822799":"code","55a88da9":"code","6f868d41":"code","37eb0564":"code","165eeaef":"code","712d0eff":"code","128fa8ef":"code","93ead90d":"code","19616616":"code","5e88822b":"code","9d2f3613":"code","40c3c5ad":"code","358aced6":"code","9ef023c3":"code","13d81956":"code","5f9b1315":"code","03ba23f6":"code","f43199ef":"code","a99a0e4f":"code","3aaea31d":"code","30d5f8c5":"code","b8528101":"code","ebd3e44c":"code","aeeeb0ae":"code","5ca39924":"code","107f42e5":"code","8013535a":"code","7b9c847c":"code","be337121":"code","5bce4e2d":"code","b3d32be1":"code","40b95e27":"code","f969bba2":"code","de7ce9a3":"code","8c022726":"code","0e743c67":"code","781ffa99":"code","d89f9ef1":"code","6427839a":"code","007807fa":"code","19a86c11":"code","2985199f":"code","7762233c":"code","2ceed324":"code","d8465ec1":"code","e8408f59":"code","fab49ebc":"code","88289d0e":"code","61749964":"code","a826f7f0":"code","9da318f5":"code","8650b832":"code","1306e184":"code","66c4a878":"code","089ad6c9":"code","a5d6650f":"code","651c6fd7":"code","466471ba":"code","b0ba2e40":"code","50206f0d":"code","c764e29a":"code","5416414e":"code","edf5ce5e":"code","1c67f873":"code","ed33a8ae":"code","8b64733d":"code","45a0b560":"code","d7e4d7de":"code","851f3e41":"code","7fa407b4":"code","d03ec7f9":"code","52ebc82e":"code","59506da7":"code","9322678b":"code","b3f98c1a":"code","3863f97a":"code","cc68eed5":"code","b3e41f54":"code","db4c88e0":"code","da9a93ff":"code","ff6f5b25":"code","66afc93b":"code","046536cb":"code","34970283":"code","c0408de7":"code","6a0d929a":"code","aede5af0":"code","35cf559c":"code","8a8b473f":"code","4441d002":"code","7049f11f":"code","3468fd99":"code","f667b650":"code","d2ff9178":"code","82d6e956":"code","3fb2cdcc":"code","302814b0":"code","d26c64a7":"code","99efc7fa":"code","e20785c2":"code","a9069935":"code","16cb2fbf":"code","01e051c0":"code","9a1cf8a8":"code","74cd9827":"code","8800eb1c":"code","b644e790":"code","8b86b73d":"code","65ab08fb":"code","60cc44bf":"code","cdac2922":"code","a86640ee":"code","023365ea":"code","8cb13b97":"code","b01953e4":"code","36275cf9":"code","3f9fe841":"code","ce597d62":"markdown","4fc75583":"markdown","1e567738":"markdown","23342d56":"markdown","5637b4b5":"markdown","fa919318":"markdown","792518dc":"markdown","8806a882":"markdown","2514d123":"markdown","17d4a184":"markdown","043b4713":"markdown","0dfe45ee":"markdown","2136ff22":"markdown","b4149352":"markdown","4e8847f3":"markdown","07df6cb5":"markdown","e695bb41":"markdown","0ba638cd":"markdown","776a0677":"markdown","d1e1f1b6":"markdown","1f0d6157":"markdown","9ed687e7":"markdown","d00206ea":"markdown","b514035a":"markdown","634f0074":"markdown","31e34457":"markdown","e7bfbe6a":"markdown","57480fc2":"markdown","916b1d20":"markdown","94309068":"markdown","1f78265b":"markdown","02dab9b2":"markdown","fc00a217":"markdown","4c95a563":"markdown","d407fbd4":"markdown","3cca3fc4":"markdown","1db8c9da":"markdown","078bce61":"markdown","f87dcc27":"markdown","0c0947ad":"markdown","6644844c":"markdown","0f6b1a1d":"markdown","1182471b":"markdown","e08eeb36":"markdown","7ddf6226":"markdown","be65d248":"markdown","1412e0f7":"markdown","f5ae6c93":"markdown","94c11f23":"markdown","2043e68b":"markdown","a4f13ded":"markdown","961c7715":"markdown","11b5904b":"markdown","92b8b7b5":"markdown","2a1b4ffa":"markdown","203eca83":"markdown","61445770":"markdown","78c8e264":"markdown","086b63a3":"markdown","b200c849":"markdown","1c1b0fb7":"markdown","efe6a807":"markdown","b84b58f6":"markdown","a2896343":"markdown","2e210705":"markdown","3608ea89":"markdown","6470abd7":"markdown","2704b995":"markdown","9884a962":"markdown","aca3e53d":"markdown","2e757952":"markdown","1802c2d5":"markdown","e04a862b":"markdown","c620beef":"markdown","72d4007d":"markdown","f0752234":"markdown","57dc52c3":"markdown"},"source":{"d8758318":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02b892d9":"# Importing the libraries\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","cb1a9ba4":"colors= ['#FD151B' ,'#97D2FB' ,'#FFC857' ,'#437F97' ,'#55D6C2']\nsns.palplot(colors, size=3)\nplt.text(-0.5, -0.75, \"Color Palette for Visualizations\", {'fontfamily': 'sans-serif', 'size': 21, 'weight':'semibold'})\nfor idx,values in enumerate(colors):\n    plt.text(idx-0.25,0, colors[idx],{'fontfamily':'Poppins, sans-serif', 'size':16, 'weight':'semibold','color':'#fff'}, alpha =1)","df18a0b7":"# Loading datasets\ndf_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","5a8d1c33":"df_train.head()","6c7f2525":"df_train.describe()","d50ba740":"df_train.isnull().sum()","abc57702":"fig = plt.figure(figsize=(20,12))\ngs = fig.add_gridspec(2,3)\ngs.update(wspace=0.5, hspace=0.25)\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\nax0.set_facecolor(background_color) \nax1.set_facecolor(background_color) \nax2.set_facecolor(background_color) \nax3.set_facecolor(background_color) \nax4.set_facecolor(background_color) \nax5.set_facecolor(background_color)\n\n#Survived Countplot\nax0.text(0.15, 600, 'Survived', fontsize=25, color='#5D576B', weight='bold')\nax0.grid(axis='y', color=\"#333\", linestyle=':')\nax0.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Survived', data=df_train, palette=colors, ax=ax0, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#Pclass Countplot\nax1.text(0.6, 536, 'Pclass', fontsize=25, color='#5D576B', weight='bold')\nax1.grid(axis='y', color=\"#333\", linestyle=':')\nax1.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Pclass', data=df_train, palette=colors, ax=ax1, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#Sex Countplot\nax2.text(0.32, 625, 'Sex', fontsize=25, color='#5D576B', weight='bold')\nax2.grid(axis='y', color=\"#333\", linestyle=':')\nax2.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Sex', data=df_train, palette=colors, ax=ax2, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#SibSp\nax3.text(2, 650, 'Sibsp', fontsize=25, color='#5D576B', weight='bold')\nax3.grid(axis='y', color=\"#333\", linestyle=':')\nax3.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('SibSp', data=df_train, palette=colors, ax=ax3, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#Parch\nax4.text(2.5, 730, 'Parch', fontsize=25, color='#5D576B', weight='bold')\nax4.grid(axis='y', color=\"#333\", linestyle=':')\nax4.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Parch', data=df_train, palette=colors, ax=ax4, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#Embarked\nax5.text(0.5, 690, 'Embarked', fontsize=25, color='#5D576B', weight='bold')\nax5.grid(axis='y', color=\"#333\", linestyle=':')\nax5.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Embarked', data=df_train, palette=colors, ax=ax5, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\nfig.suptitle('Categorical Features in Training Data', fontsize=\"28\", weight=\"bold\", color=\"#F96E46\")\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax3.spines[s].set_visible(False)\n    ax4.spines[s].set_visible(False)\n    ax5.spines[s].set_visible(False)","1f9db55f":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,2)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\naxB = fig.add_subplot(gs[0,1])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(31, 0.035, 'Age', fontsize=25, color='#FD151B', weight='bold')\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=20)\nsns.kdeplot(df_train['Age'], color=colors[0], ax=axA, fill=True, linewidth = 3, ec=\"black\").set(xlabel=\"\", ylabel=\"\")\n\naxB.text(180, 0.0232, 'Fares', fontsize=25, color='#437F97', weight='bold')\naxB.grid(axis='y', color=\"#333\", linestyle=':')\naxB.tick_params(axis='both', which='major', labelsize=20)\nsns.kdeplot(df_train['Fare'], color=colors[3], ax=axB, fill=True, linewidth = 3, ec=\"black\").set(xlabel=\"\", ylabel=\"\")\n\nplt.suptitle(\"Continuous Features in the training data\",fontsize=\"22\", weight=\"bold\", color=\"#5B2A86\", y=1.15, horizontalalignment='center')\n\nfor s in [\"top\",\"right\",\"left\"]:\n    axA.spines[s].set_visible(False)\n    axB.spines[s].set_visible(False)","a549b266":"fig = plt.figure(figsize=(20,12))\ngs = fig.add_gridspec(2,3)\ngs.update(wspace=0.5, hspace=0.25)\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\nax0.set_facecolor(background_color) \nax1.set_facecolor(background_color) \nax2.set_facecolor(background_color) \nax3.set_facecolor(background_color) \nax4.set_facecolor(background_color) \nax5.set_facecolor(background_color)\n\n#Age KDE plot\nax0.text(20, 0.0212, 'Age', fontsize=25, color='#5D576B', weight='bold')\nax0.grid(axis='y', color=\"#333\", linestyle=':')\nax0.tick_params(axis='both', which='major', labelsize=20)\nsns.kdeplot('Age', data=df_train, palette=[\"#FD151B\", \"#01295F\"], ax=ax0, hue=\"Survived\", \n            fill=\"True\",linewidth=3, ec='black').set(xlabel=\"\", ylabel=\"\")\n\n#Pclass Countplot\nax1.text(0.6, 410, 'Pclass', fontsize=25, color='#5D576B', weight='bold')\nax1.grid(axis='y', color=\"#333\", linestyle=':')\nax1.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Pclass', data=df_train, palette=colors, ax=ax1, edgecolor=\"black\",\n              hue=\"Survived\").set(xlabel=\"\", ylabel=\"\")\n\n#Sex Countplot\nax2.text(0.32, 519, 'Sex', fontsize=25, color='#5D576B', weight='bold')\nax2.grid(axis='y', color=\"#333\", linestyle=':')\nax2.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Sex', data=df_train, palette=colors, ax=ax2, edgecolor=\"black\",\n              hue=\"Survived\").set(xlabel=\"\", ylabel=\"\")\n\n#SibSp\nax3.text(2, 430, 'Sibsp', fontsize=25, color='#5D576B', weight='bold')\nax3.grid(axis='y', color=\"#333\", linestyle=':')\nax3.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('SibSp', data=df_train, palette=colors, ax=ax3, edgecolor=\"black\",\n              hue=\"Survived\").set(xlabel=\"\", ylabel=\"\")\n\n#Parch\nax4.text(2.5, 475, 'Parch', fontsize=25, color='#5D576B', weight='bold')\nax4.grid(axis='y', color=\"#333\", linestyle=':')\nax4.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Parch', data=df_train, palette=colors, ax=ax4, edgecolor=\"black\",\n              hue=\"Survived\").set(xlabel=\"\", ylabel=\"\")\n\n#Embarked\nax5.text(0.5, 455, 'Embarked', fontsize=25, color='#5D576B', weight='bold')\nax5.grid(axis='y', color=\"#333\", linestyle=':')\nax5.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Embarked', data=df_train, palette=colors, ax=ax5, edgecolor=\"black\",\n              hue=\"Survived\").set(xlabel=\"\", ylabel=\"\")\n\nfig.suptitle('Categorical Features wrt Target Column(Survived)', fontsize=\"28\", \n             weight=\"bold\", color=\"#0072BB\")\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax3.spines[s].set_visible(False)\n    ax4.spines[s].set_visible(False)\n    ax5.spines[s].set_visible(False)","be845524":"matrix = np.triu(df_train.corr())\nplt.figure(figsize=(15,10))\nsns.heatmap(df_train.corr(), annot=True, mask=matrix, cmap=\"YlOrRd\")","9944bcd2":"fig = plt.figure(figsize=(18,10))\ngs = fig.add_gridspec(2,2)\ngs.update(wspace=0.5, hspace=0.25)\naxC = fig.add_subplot(gs[0,0])\naxD = fig.add_subplot(gs[1,0])\naxA = fig.add_subplot(gs[0,1])\naxB = fig.add_subplot(gs[1,1])\n\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\naxC.set_facecolor(background_color)\naxD.set_facecolor(background_color)\n\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=12)\naxA.set_xlabel('Survived',fontsize=16)\naxA.set_ylabel('Age',fontsize=16)\nsns.boxenplot(x=\"Pclass\",y=\"Age\",data=df_train, palette=['#FD151B' ,'#97D2FB' ,'#F9C846' ,'#437F97'], ax=axA)\n\naxB.grid(axis='y', color=\"#333\", linestyle=':')\naxB.tick_params(axis='both', which='major', labelsize=12)\naxB.set_xlabel('Survived',fontsize=16)\naxB.set_ylabel('Age',fontsize=16)\nsns.boxenplot(x=\"Survived\",y=\"Age\",data=df_train, palette=['#FD151B' ,'#97D2FB' ,'#F9C846' ,'#437F97'], ax=axB)\n\naxC.tick_params(axis='both',left=False, bottom=False)\naxC.set_xticklabels([])\naxC.set_yticklabels([])\naxC.text(0.6,0.4, \"Pclass vs Age\\n____________\",horizontalalignment = 'center',verticalalignment = 'center',\n         fontsize = 28,fontweight='bold',fontfamily='sans-serif', color='#437F97')\n\naxD.tick_params(axis='both',left=False, bottom=False)\naxD.set_xticklabels([])\naxD.set_yticklabels([])\naxD.text(0.6,0.4, \"Survived vs Age\\n_______________\",horizontalalignment = 'center',verticalalignment = 'center',\n         fontsize = 28,fontweight='bold',fontfamily='sans-serif', color='#437F97')\n\nfor s in [\"top\",\"right\",\"left\", \"bottom\"]:\n    axC.spines[s].set_visible(False)\n    axD.spines[s].set_visible(False)\n\nfor s in [\"top\",\"right\",\"left\"]:\n    axA.spines[s].set_visible(False)\n    axB.spines[s].set_visible(False)","b4822799":"df_test.head()","55a88da9":"df_test.describe()","6f868d41":"df_test.isnull().sum()","37eb0564":"fig = plt.figure(figsize=(20,12))\ngs = fig.add_gridspec(2,3)\ngs.update(wspace=0.5, hspace=0.25)\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\nax0.set_facecolor(background_color) \nax1.set_facecolor(background_color) \nax2.set_facecolor(background_color) \nax3.set_facecolor(background_color) \nax4.set_facecolor(background_color) \nax5.set_facecolor(background_color)\n\n#Survived Countplot\nax0.tick_params(axis='both',left=False, bottom=False)\nax0.set_xticklabels([])\nax0.set_yticklabels([])\n\n#Pclass Countplot\nax1.text(0.6, 240, 'Pclass', fontsize=25, color='#5D576B', weight='bold')\nax1.grid(axis='y', color=\"#333\", linestyle=':')\nax1.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Pclass', data=df_test, palette=colors, ax=ax1, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#Sex Countplot\nax2.text(0.32, 290, 'Sex', fontsize=25, color='#5D576B', weight='bold')\nax2.grid(axis='y', color=\"#333\", linestyle=':')\nax2.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Sex', data=df_test, palette=colors, ax=ax2, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#SibSp\nax3.text(2, 305, 'Sibsp', fontsize=25, color='#5D576B', weight='bold')\nax3.grid(axis='y', color=\"#333\", linestyle=':')\nax3.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('SibSp', data=df_test, palette=colors, ax=ax3, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#Parch\nax4.text(2.5, 350, 'Parch', fontsize=25, color='#5D576B', weight='bold')\nax4.grid(axis='y', color=\"#333\", linestyle=':')\nax4.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Parch', data=df_test, palette=colors, ax=ax4, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n#Embarked\nax5.text(0.5, 290, 'Embarked', fontsize=25, color='#5D576B', weight='bold')\nax5.grid(axis='y', color=\"#333\", linestyle=':')\nax5.tick_params(axis='both', which='major', labelsize=20)\nsns.countplot('Embarked', data=df_test, palette=colors, ax=ax5, edgecolor=\"black\").set(xlabel=\"\", ylabel=\"\")\n\nfig.suptitle('Categorical Features in Test Data', fontsize=\"28\", weight=\"bold\", color=\"#437F97\")\n\nfor s in [\"top\",\"right\",\"left\", \"bottom\"]:\n    ax0.spines[s].set_visible(False)\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax3.spines[s].set_visible(False)\n    ax4.spines[s].set_visible(False)\n    ax5.spines[s].set_visible(False)","165eeaef":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,2)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\naxB = fig.add_subplot(gs[0,1])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(31, 0.038, 'Age', fontsize=25, color='#FD151B', weight='bold')\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=20)\nsns.kdeplot(df_test['Age'], color=colors[0], ax=axA, fill=True, linewidth = 3, ec=\"black\").set(xlabel=\"\", ylabel=\"\")\n\naxB.text(180, 0.0185, 'Fares', fontsize=25, color='#437F97', weight='bold')\naxB.grid(axis='y', color=\"#333\", linestyle=':')\naxB.tick_params(axis='both', which='major', labelsize=20)\nsns.kdeplot(df_test['Fare'], color=colors[3], ax=axB, fill=True, linewidth = 3, ec=\"black\").set(xlabel=\"\", ylabel=\"\")\n\nplt.suptitle(\"Continuous Features in the test data\",fontsize=\"22\", weight=\"bold\", color=\"#5B2A86\", y=1.15, horizontalalignment='center')\n\nfor s in [\"top\",\"right\",\"left\"]:\n    axA.spines[s].set_visible(False)\n    axB.spines[s].set_visible(False)","712d0eff":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,2)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\naxB = fig.add_subplot(gs[0,1])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(0.8, -40, 'Missing Values in Training Data', fontsize=18, color='#343f56', weight='bold')\nsns.heatmap(df_train.isnull(), yticklabels=False, cbar=False, cmap=['#437F97','#FFC857'], ax=axA)\n\naxB.text(1.2, -17, 'Missing Values in Test Data', fontsize=18, color='#343f56', weight='bold')\nsns.heatmap(df_test.isnull(), yticklabels=False, cbar=False, cmap=['#437F97','#FFC857'], ax=axB)","128fa8ef":"# Cabin Column has too many missing values to be of any significant use\ndf_train.drop('Cabin', axis=1, inplace=True)\ndf_test.drop('Cabin', axis=1, inplace=True)","93ead90d":"print('Training Data')\nprint('The median age of people in First Class: ',df_train[df_train['Pclass']==1]['Age'].median())\nprint('The median age of people in Second Class: ',df_train[df_train['Pclass']==2]['Age'].median())\nprint('The median age of people in Third Class: ',df_train[df_train['Pclass']==3]['Age'].median())","19616616":"print('Test Data')\nprint('The median age of people in First Class: ',df_test[df_test['Pclass']==1]['Age'].median())\nprint('The median age of people in Second Class: ',df_test[df_test['Pclass']==2]['Age'].median())\nprint('The median age of people in Third Class: ',df_test[df_test['Pclass']==3]['Age'].median())","5e88822b":"# creating a function for imputation in Training Data\ndef impute_age_train(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","9d2f3613":"df_train['Age'] = df_train[['Age', 'Pclass']].apply(impute_age_train, axis=1)","40c3c5ad":"# creating a function for imputation in Test Data\ndef impute_age_test(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 42\n        elif Pclass == 2:\n            return 26\n        else:\n            return 24\n    else:\n        return Age","358aced6":"df_test['Age'] = df_test[['Age', 'Pclass']].apply(impute_age_test, axis=1)","9ef023c3":"df_train[df_train['Embarked'].isnull()]","13d81956":"df_train['Embarked'] = df_train['Embarked'].fillna('S')","5f9b1315":"df_test[df_test['Fare'].isnull()]","03ba23f6":"print('The mean fare of people in Third Class: ',df_train[df_train['Pclass']==3]['Fare'].mean())","f43199ef":"df_test['Fare'] = df_test['Fare'].fillna(13.68)","a99a0e4f":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,2)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\naxB = fig.add_subplot(gs[0,1])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(0.8, -40, 'Missing Values in Training Data', fontsize=18, color='#343f56', weight='bold')\nsns.heatmap(df_train.isnull(), yticklabels=False, cbar=False, cmap=['#437F97','#FFC857'], ax=axA)\n\naxB.text(1.2, -17, 'Missing Values in Test Data', fontsize=18, color='#343f56', weight='bold')\nsns.heatmap(df_test.isnull(), yticklabels=False, cbar=False, cmap=['#437F97','#FFC857'], ax=axB)","3aaea31d":"df_train.drop('PassengerId', axis=1, inplace=True)","30d5f8c5":"df_test.drop('PassengerId', axis=1, inplace=True)","b8528101":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,2)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\naxB = fig.add_subplot(gs[0,1])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(180, 545, 'Fares(Train)', fontsize=25, color='#437F97', weight='bold')\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=20)\nsns.histplot(df_train['Fare'], color=colors[0], ax=axA, linewidth = 1, ec=\"black\", bins=30, kde=True).set(xlabel=\"\", ylabel=\"\")\n\naxB.text(180, 257, 'Fares(Test)', fontsize=25, color='#437F97', weight='bold')\naxB.grid(axis='y', color=\"#333\", linestyle=':')\naxB.tick_params(axis='both', which='major', labelsize=20)\nsns.histplot(df_test['Fare'], color=colors[0], ax=axB, linewidth = 1, ec=\"black\", bins=30, kde=True).set(xlabel=\"\", ylabel=\"\")\n\nfor s in [\"top\",\"right\",\"left\", \"bottom\"]:\n    axA.spines[s].set_visible(False)\n    \nfor s in [\"top\",\"right\",\"left\"]:\n    axB.spines[s].set_visible(False)","ebd3e44c":"df_train[\"Fare\"] = df_train[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test[\"Fare\"] = df_test[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","aeeeb0ae":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,2)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\naxB = fig.add_subplot(gs[0,1])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(1, 250, 'Fares(Train)', fontsize=25, color='#437F97', weight='bold')\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=20)\nsns.histplot(df_train['Fare'], color=colors[0], ax=axA, linewidth = 1, ec=\"black\", bins=30, kde=True).set(xlabel=\"\", ylabel=\"\")\n\naxB.text(1, 130, 'Fares(Test)', fontsize=25, color='#437F97', weight='bold')\naxB.grid(axis='y', color=\"#333\", linestyle=':')\naxB.tick_params(axis='both', which='major', labelsize=20)\nsns.histplot(df_test['Fare'], color=colors[0], ax=axB, linewidth = 1, ec=\"black\", bins=30, kde=True).set(xlabel=\"\", ylabel=\"\")\n\nfor s in [\"top\",\"right\",\"left\", \"bottom\"]:\n    axA.spines[s].set_visible(False)\n    \nfor s in [\"top\",\"right\",\"left\"]:\n    axB.spines[s].set_visible(False)","5ca39924":"df_train['Age'] = pd.qcut(df_train['Age'], 10, duplicates='drop')\ndf_test['Age'] = pd.qcut(df_test['Age'], 10, duplicates='drop')","107f42e5":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,1)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(3, 180, 'Age Bin(Train)', fontsize=25, color='#437F97', weight='bold')\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=10)\nsns.countplot(x=\"Age\",data=df_train, palette=\"magma\",hue=\"Survived\", ax=axA, linewidth = 1, ec=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n    \nfor s in [\"top\",\"right\",\"left\"]:\n    axA.spines[s].set_visible(False)\n    axB.spines[s].set_visible(False)","8013535a":"df_train['FamilyName'] = df_train['Name'].str.split(', ').str[0]","7b9c847c":"df_train['Title'] =  df_train['Name'].str.split(', ').str[1].str.split('.').str[0]","be337121":"df_train['Title'].unique()","5bce4e2d":"df_train['Title'] = df_train['Title'].replace(['Miss', 'Mlle'], 'Ms')\ndf_train['Title'] = df_train['Title'].replace(['Mme', 'Lady','the Countess'], 'Mrs')\ndf_train['Title'] = df_train['Title'].replace(['Don', 'Rev', 'Dr', 'Major', 'Sir', 'Col', 'Capt','Jonkheer'], 'Other Important')","b3d32be1":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,1)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(1.3, 550, 'Titles in Training Data', fontsize=25, color='#437F97', weight='bold')\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=10)\nsns.countplot(x=\"Title\",data=df_train, palette=\"magma\", ax=axA, linewidth = 1, ec=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n    \nfor s in [\"top\",\"right\",\"left\"]:\n    axA.spines[s].set_visible(False)\n    axB.spines[s].set_visible(False)","40b95e27":"df_test['FamilyName'] = df_test['Name'].str.split(', ').str[0]","f969bba2":"df_test['Title'] =  df_test['Name'].str.split(', ').str[1].str.split('.').str[0]","de7ce9a3":"df_test['Title'].unique()","8c022726":"df_test['Title'] = df_test['Title'].replace(['Miss'], 'Ms')\ndf_test['Title'] = df_test['Title'].replace(['Dona'], 'Mrs')\ndf_test['Title'] = df_test['Title'].replace(['Rev', 'Dr', 'Col'], 'Other Important')","0e743c67":"fig = plt.figure(figsize=(16, 5))\ngs = fig.add_gridspec(1,1)\ngs.update(wspace=0.5, hspace=0.25)\naxA = fig.add_subplot(gs[0,0])\n\nbackground_color = \"#FAF0CA\"\nfig.patch.set_facecolor(background_color)\naxA.set_facecolor(background_color) \naxB.set_facecolor(background_color)\n\naxA.text(1.3, 280, 'Titles in Test Data', fontsize=25, color='#437F97', weight='bold')\naxA.grid(axis='y', color=\"#333\", linestyle=':')\naxA.tick_params(axis='both', which='major', labelsize=10)\nsns.countplot(x=\"Title\",data=df_test, palette=\"magma\", ax=axA, linewidth = 1, ec=\"black\").set(xlabel=\"\", ylabel=\"\")\n\n    \nfor s in [\"top\",\"right\",\"left\"]:\n    axA.spines[s].set_visible(False)\n    axB.spines[s].set_visible(False)","781ffa99":"df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch']+1\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch']+1","d89f9ef1":"df_train.loc[ df_train['FamilySize'] == 1, 'FamilySize'] = 0                            \n# Alone\ndf_train.loc[(df_train['FamilySize'] > 1) & (df_train['FamilySize'] <= 4), 'FamilySize'] = 1  \n# Small Family \ndf_train.loc[(df_train['FamilySize'] > 4) & (df_train['FamilySize'] <= 6), 'FamilySize'] = 2  \n# Medium Family\ndf_train.loc[df_train['FamilySize']  > 6, 'FamilySize'] = 3                             \n# Large Family ","6427839a":"df_test.loc[ df_test['FamilySize'] == 1, 'FamilySize'] = 0                            \n# Alone\ndf_test.loc[(df_test['FamilySize'] > 1) & (df_test['FamilySize'] <= 4), 'FamilySize'] = 1  \n# Small Family \ndf_test.loc[(df_test['FamilySize'] > 4) & (df_test['FamilySize'] <= 6), 'FamilySize'] = 2  \n# Medium Family\ndf_test.loc[df_test['FamilySize']  > 6, 'FamilySize'] = 3                             \n# Large Family ","007807fa":"df_train.drop(['SibSp','Parch'], axis = 1, inplace = True)\ndf_test.drop(['SibSp','Parch'], axis = 1, inplace = True)","19a86c11":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler","2985199f":"non_num = ['Sex', 'Embarked', 'Title']\n\nfor feature in non_num:\n    df_train[feature] = LabelEncoder().fit_transform(df_train[feature])\n    df_test[feature] = LabelEncoder().fit_transform(df_test[feature])","7762233c":"cat_feats = ['Sex', 'Embarked', 'Pclass', 'Title', 'FamilySize']\n\nencoded_train_df_feats = []\n\nfor feature in cat_feats:\n    encoded_feats_train = OneHotEncoder().fit_transform(df_train[feature].values.reshape(-1,1)).toarray()\n    n = df_train[feature].nunique()\n    cols = ['{}_{}'.format(feature, n) for n in range(1, n+1)]\n    encoded_df = pd.DataFrame(encoded_feats_train, columns=cols)\n    encoded_df.index = df_train.index\n    encoded_train_df_feats.append(encoded_df)\n    ","2ceed324":"encoded_test_df_feats = []\n\nfor feature in cat_feats:\n    encoded_feats_test = OneHotEncoder().fit_transform(df_test[feature].values.reshape(-1,1)).toarray()\n    n = df_test[feature].nunique()\n    cols = ['{}_{}'.format(feature, n) for n in range(1, n+1)]\n    encoded_dft = pd.DataFrame(encoded_feats_test, columns=cols)\n    encoded_dft.index = df_test.index\n    encoded_test_df_feats.append(encoded_dft)","d8465ec1":"df_train = pd.concat([df_train, *encoded_train_df_feats], axis=1)","e8408f59":"df_test = pd.concat([df_test, *encoded_test_df_feats], axis=1)","fab49ebc":"df_train.info()","88289d0e":"drop_cols = ['Name','Ticket', 'Pclass', 'Sex', 'Title', 'Embarked','FamilyName', 'FamilySize']\ndf_train.drop(columns=drop_cols, inplace=True)","61749964":"df_test.drop(columns=drop_cols, inplace=True)","a826f7f0":"df_train.head()","9da318f5":"df_test.head()","8650b832":"df_train['Age'] = LabelEncoder().fit_transform(df_train['Age'])\ndf_test['Age'] = LabelEncoder().fit_transform(df_test['Age'])","1306e184":"from sklearn.model_selection import train_test_split","66c4a878":"X = df_train.drop('Survived', axis=1)\ny = df_train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","089ad6c9":"# Scaling...\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","a5d6650f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","651c6fd7":"logmodel = LogisticRegression(max_iter=200)\nlogmodel.fit(X_train, y_train)\nprediction1 = logmodel.predict(X_test)","466471ba":"print('Confusion Matrix:\\n', confusion_matrix(y_test, prediction1))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, prediction1))","b0ba2e40":"logmodel2 = LogisticRegression(C= 0.09858667904100823,\n max_iter= 200,\n penalty= 'l2',\n solver= 'liblinear')","50206f0d":"logmodel2.fit(X_train, y_train)","c764e29a":"log_grid_preds = logmodel2.predict(X_test)","5416414e":"print('Confusion Matrix:\\n', confusion_matrix(y_test, log_grid_preds))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, log_grid_preds))","edf5ce5e":"from sklearn.neighbors import KNeighborsClassifier","1c67f873":"knn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\nprediction2 = knn.predict(X_test)","ed33a8ae":"print('Confusion Matrix:\\n', confusion_matrix(y_test, prediction2))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, prediction2))","8b64733d":"error_rate = []\n\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","45a0b560":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40), error_rate, color='blue', linestyle='--', marker='o', markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs K value')\nplt.xlabel = ('K')\nplt.ylabel = ('Error Rate')","d7e4d7de":"knn = KNeighborsClassifier(n_neighbors=33)\nknn.fit(X_train, y_train)\nprediction2 = knn.predict(X_test)","851f3e41":"print('Confusion Matrix:\\n', confusion_matrix(y_test, prediction2))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, prediction2))","7fa407b4":"from sklearn.ensemble import RandomForestClassifier","d03ec7f9":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\nprediction3 = rfc.predict(X_test)","52ebc82e":"print('Confusion Matrix:\\n', confusion_matrix(y_test, prediction3))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, prediction3))","59506da7":"n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num=10)] \nmax_features = ['auto', 'sqrt']\nmax_depth = [2,4]\nmin_samples_split = [2,5]\nmin_samples_leaf = [1,2]\nbootstrap = [True, False]","9322678b":"param_grid = {'n_estimators': n_estimators,\n              'max_features': max_features,\n              'max_depth': max_depth,\n              'min_samples_split': min_samples_split,\n              'min_samples_leaf': min_samples_leaf,\n              'bootstrap': bootstrap}","b3f98c1a":"print(param_grid)","3863f97a":"from sklearn.model_selection import GridSearchCV","cc68eed5":"grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid, verbose=3, cv=10, n_jobs = 4)","b3e41f54":"grid_search.fit(X_train, y_train)","db4c88e0":"grid_search.best_params_","da9a93ff":"grid_predictions = grid_search.predict(X_test)","ff6f5b25":"print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, grid_predictions))\nprint(\"\\n\")\nprint(classification_report(y_test, grid_predictions))","66afc93b":"from sklearn.svm import SVC","046536cb":"svc_model = SVC()\nsvc_model.fit(X_train, y_train)\npredictions4 = svc_model.predict(X_test)","34970283":"print('Confusion Matrix:\\n', confusion_matrix(y_test, predictions4))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, predictions4))","c0408de7":"param_grid_svm = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}","6a0d929a":"from sklearn.model_selection import RandomizedSearchCV","aede5af0":"rndm_cv = RandomizedSearchCV(estimator=svc_model, param_distributions=param_grid_svm, cv=10, verbose=2)","35cf559c":"rndm_cv.fit(X_train, y_train)","8a8b473f":"rndm_preds = rndm_cv.predict(X_test)","4441d002":"print('Confusion Matrix:\\n', confusion_matrix(y_test, rndm_preds))\nprint('\\n')\nprint('Classification Report:\\n', classification_report(y_test, rndm_preds))","7049f11f":"from sklearn.ensemble import GradientBoostingClassifier\nsgb = GradientBoostingClassifier(subsample = 0.90, max_features = 0.70)","3468fd99":"sgb.fit(X_train, y_train)","f667b650":"sgb_preds = sgb.predict(X_test)","d2ff9178":"print(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, sgb_preds)}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, sgb_preds)}\")","82d6e956":"from xgboost import XGBClassifier","3fb2cdcc":"xgb = XGBClassifier(booster = 'gbtree', learning_rate = 0.1, max_depth = 5, n_estimators = 180)\nxgb.fit(X_train, y_train)","302814b0":"xgb_preds = xgb.predict(X_test)","d26c64a7":"print(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, xgb_preds)}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, xgb_preds)}\")","99efc7fa":"params_xgb={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ],\n \"n_estimators\"     : [int(x) for x in np.linspace(start = 10, stop = 80, num=10)] \n}","e20785c2":"xgb_rndm_cv = RandomizedSearchCV(estimator=xgb, param_distributions=params_xgb, cv=10, verbose=2)","a9069935":"xgb_rndm_cv.fit(X_train, y_train)","16cb2fbf":"xgb_rndm_preds = xgb_rndm_cv.predict(X_test)","01e051c0":"print(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, xgb_rndm_preds)}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, xgb_rndm_preds)}\")","9a1cf8a8":"from sklearn.ensemble import VotingClassifier\n\nclassifiers = [('Stochastic Gradient Boosting', sgb), ('XGboost', xgb),\n               ('Random Forest', rfc), ('Logistic', logmodel), ('KNN', knn), ('SVM', grid_search)]","74cd9827":"vc = VotingClassifier(estimators = classifiers)","8800eb1c":"vc.fit(X_train, y_train)","b644e790":"vc_preds = vc.predict(X_test)","8b86b73d":"print(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, vc_preds)}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, vc_preds)}\")","65ab08fb":"print('The accuracy score of Logistic Regression Model is: ', accuracy_score(y_test, prediction1)*100,'%')\nprint('The accuracy score of K Nearest Neighbors Model is: ', accuracy_score(y_test, prediction2)*100,'%')\nprint('The accuracy score of Random Forests Model is: ', accuracy_score(y_test, grid_predictions)*100,'%')\nprint('The accuracy score of SVM Model is: ', accuracy_score(y_test, rndm_preds)*100,'%')\nprint('The accuracy score of Stochastic Gradient Boosting  is: ', accuracy_score(y_test, sgb_preds)*100,'%')\nprint('The accuracy score of XG Boost  is: ', accuracy_score(y_test, xgb_rndm_preds)*100,'%')\nprint('The accuracy score of Voting Classifer  is: ', accuracy_score(y_test, vc_preds)*100,'%')","60cc44bf":"lr_acc = accuracy_score(y_test, prediction1)\nknn_acc = accuracy_score(y_test, prediction2)\nrfc_acc = accuracy_score(y_test, grid_predictions)\nSVM_acc = accuracy_score(y_test, rndm_preds)\nsgb_acc = accuracy_score(y_test, sgb_preds)\nxgb_acc = accuracy_score(y_test, xgb_rndm_preds)\nvc_acc = accuracy_score(y_test, vc_preds)","cdac2922":"model = ['Logistic Regression', 'K Nearest Neighbors', 'Random Forests', 'Support Vector Machines',\n         'Stochastic Gradient Booster', 'XGBoost', 'Voting Classifier']\nscore = [lr_acc, knn_acc, rfc_acc, SVM_acc, sgb_acc, xgb_acc, vc_acc]","a86640ee":"plt.figure(figsize = (15, 10))\nsns.barplot(x = score, y = model)\nplt.show()","023365ea":"passengerdf = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","8cb13b97":"final_preds = logmodel2.predict(df_test)","b01953e4":"final_preds","36275cf9":"submission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\nsubmission_df['PassengerId'] = passengerdf['PassengerId']\nsubmission_df['Survived'] = final_preds","3f9fe841":"submission_df.to_csv('submissions.csv', header=True, index=False)","ce597d62":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">We can't obviously drop the whole age column like we did earlier. Instead I'm going to impute values into the missing and I'll do that by taking median age from each of the passenger class.<\/p>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Check out the relation between Age and Pclass <a href='#boxenplot'>here<\/a><\/p>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">So we replace the missing age of people by the median age of the class they were in.<\/p>\n","4fc75583":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 500;\">Interpretations from the above KDE plots<\/h3>\n<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>A large number of people were between the age of 20 and 50 years of age.<\/li>\n    <li>Fares Column has a skewed distribution. We have to scale it accordingly so that it doesn't interfere with our accuracy.<\/li>\n<\/ul>","1e567738":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 500;\">Interpretations from the above countplots(Test Data)<\/h3>\n<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>Majority of the people were from Passenger Class 3.<\/li>\n    <li>There were more number of males than females.<\/li>\n    <li>There were more number of people without Siblings or Spouses.<\/li>\n    <li>There were more number of people without Parents or Children<\/li>\n    <li>Large number of people who embarked were from Southamptom.<\/li>\n<\/ul>","23342d56":"<a id=\"subsection8\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.1 Preparing Data for Models<\/h3>","5637b4b5":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">After tuning the model now has 83% accuracy approx.<\/p>","fa919318":"<a id=\"subsection7\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">2.5 Creating different columns for Family Names and Titles<\/h3>","792518dc":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Lowest Error Rate observed at K value of 33<\/p>","8806a882":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Cabin Column<\/h3>","2514d123":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; color: #5eaaa8\">Content<\/h3>\n<ol style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li><a href=\"#section1\">Introduction<\/a><\/li>\n    <li><a href=\"#section2\">Exploratory Data Analysis<\/a><\/li>\n    <ul>\n        <li><a href=\"#subsection1\">Training Data<\/a><\/li>\n        <li><a href=\"#subsection2\">Test Data<\/a><\/li>\n    <\/ul>\n    <li><a href=\"#section3\">Data Preprocessing and Cleaning<\/a><\/li>\n    <ul>\n        <li><a href=\"#subsection3\">Handling Missing Values<\/a><\/li>\n        <li><a href=\"#subsection4\">Removing Irrelevant Columns<\/a><\/li>\n        <li><a href=\"#subsection5\">Skewness of Fare Column<\/a><\/li>\n        <li><a href=\"#subsection6\">Binning of Age Column<\/a><\/li>\n        <li><a href=\"#subsection7\">Creating different columns for Family Names and Titles<\/a><\/li>\n    <\/ul>\n    <li><a href=\"#section4\">Encoding Categorical Columns<\/a><\/li>\n    <li><a href=\"#section5\">Classification Models<\/a><\/li>\n    <li><a href=\"#section6\">Result<\/a><\/li>\n<\/ol>","17d4a184":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">There are features like Names, Family Names which are not useful for our models as these are objects, not ints or floats. So we need to drop these columns.<\/p>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Also, since we have hot encoded columns like sex, embarked etc we dont need the original columns again now. So we drop that also.<\/p>","043b4713":"<h1 style=\"font-family: 'Poppins', sans-serif; color: #0061a8; font-size: 36px; text-align: center;\">Titanic Disaster Analysis<\/h1>","0dfe45ee":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 500;\">Interpretations from the above plots<\/h3>\n<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>Large number of people who died were aged between 20 and 50.<\/li>\n    <li>Majority of the people that died were from Passenger Class 3 and more survived in the first class.<\/li>\n    <li>Majority of the people that died were males.<\/li>\n    <li>It was observed that many people who did not have siblings or spuses did not survive.<\/li>\n    <li>Also, people without Parents or Children did not have much chances of survival either.<\/li>\n    <li>Since large number of people embarked from Southampton, the number of deaths of people from Southamptom was more.<\/li>\n<\/ul>","2136ff22":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">As you can see the acuracy is not that good. So I'll plot a graph between error rate and n_neighbors and get the value for n_neighbors where the error rate is lowest!<\/p>","b4149352":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Fare Column in Test Data<\/h3>","4e8847f3":"<a id=\"subsection17\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.7 XG Boost<\/h3>","07df6cb5":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px; font-weight: 600\">PERFECT!!<\/p>","e695bb41":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Final Data Modifications<\/h3>","0ba638cd":"<a id=\"subsection5\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">2.3 Skewnees of Fare Column<\/h3>","776a0677":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 500;\">Interpretations from the above KDE plots<\/h3>\n<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>A large number of people were between the age of 20 and 50 years of age.<\/li>\n    <li>Again Fares Column has a skewed distribution.<\/li>\n<\/ul>","d1e1f1b6":"<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\"><li>Significant amount of data is missing from the Cabin Column. I'll most probably drop this whole column since it has to many values missing to be of any use in modelling.<\/li><li>Age column also has missing values but I'll replace these with mean or median in the data preprocessing section.<\/li><li>Embarked also has missing values.<\/li><\/ul>","1f0d6157":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Since this person was travelling in third class, we can replace it by the mean fare of people from third class.<\/p>","9ed687e7":"<a id=\"section3\"><\/a>\n<h1 style=\"font-family: 'Poppins', sans-serif; color: #ff6701; font-size: 26px; text-align: left; background-color: #fcecdd; padding: 20px; border-radius: 10px; font-weight:600;\">2. Data Preprocessing and Cleaning<\/h1> ","d00206ea":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Hyperparameter Tuning for SVM<\/h3>","b514035a":"<a id=\"subsection9\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.2 Logistic Regression<\/h3>","634f0074":"<a id=\"subsection16\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.6 Stochastic Gradient Boosting<\/h3>","31e34457":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 500;\">What are the problems with this data as of now?<\/h3>\n<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>Passenger Id is irrelevant to the survival of people.<\/li>\n    <li>Both Training Data and Test Data have missing values in Cabin, Age, Embarked, and Fare columns. I'll remove the cabin column as a whole as more than 70% of the data is missing.  <\/li>\n    <li>Fare Column is skewed and model may predict based off the prices for which largest number of data is present. Common transformations to handle skewed variables include square root (sqrt(x)), logarithmic (log(x)), and reciprocal (1\/x). <\/li>\n    <li>The names in this dataset have many titles such as Mr, Mrs, Miss, Duke, etc. We can separate people according to the titles and also I'll try to reduce these titles.<\/li>\n<\/ul>","e7bfbe6a":"<a id=\"subsection4\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">2.2 Removing Irrelevant Columns<\/h3>","57480fc2":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px; font-weight: 600;\">Reference:<\/p>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">I referred some notebooks for understanding feature enginnering. These notebooks have many other features which you also can look into if you are a beginner!<\/p>\n<a href=\"https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\/notebook\">https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\/notebook<\/a>\n<a href=\"https:\/\/www.kaggle.com\/niteshyadav3103\/titanic-eda-prediction-top-8\">https:\/\/www.kaggle.com\/niteshyadav3103\/titanic-eda-prediction-top-8<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/javiervallejos\/titanic-top-3#2.-Feature-Extraction\">https:\/\/www.kaggle.com\/javiervallejos\/titanic-top-3#2.-Feature-Extraction<\/a>","916b1d20":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Label Encoding<\/h3>","94309068":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 600; text-align: center;\">After a lot of feature engineering and fine tuning of several models I made it to the Top 13%. Please do leave an upvote if you find this notebook helpful!<\/p>","1f78265b":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">As you can observe Test Data does not have Target column that is \"Survived\".<\/p> ","02dab9b2":"<a id=\"section6\"><\/a>\n<h1 style=\"font-family: 'Poppins', sans-serif; color: #ff6701; font-size: 26px; text-align: left; background-color: #fcecdd; padding: 20px; border-radius: 10px; font-weight:600;\">5. Results<\/h1> ","fc00a217":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">On reference to other notebooks, I found that the two values missing in Embarked column are of one Mrs. George Nelson and her maid Miss Martha Evelyn. They both embarked from Southampton.<\/p>","4c95a563":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #fff; font-size: 18px; text-align: center; background-color: #004BA8; padding: 10px; border-radius: 5px\">Multivariate Analysis<\/h3>","d407fbd4":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">A significant increase in accuracy is observed.<\/p>","3cca3fc4":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Binning of continuous variable introduces non-linearity and tends to improve the performance of the model. There were also small spikes and bumps in our normal distribution.<\/p>\n","1db8c9da":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #fff; font-size: 18px; text-align: center; background-color: #004BA8; padding: 10px; border-radius: 5px\">Univariate Analysis<\/h3>","078bce61":"<a id=\"section4\"><\/a>\n<h1 style=\"font-family: 'Poppins', sans-serif; color: #ff6701; font-size: 26px; text-align: left; background-color: #fcecdd; padding: 20px; border-radius: 10px; font-weight:600;\">3. Encoding Categorical Features<\/h1> ","f87dcc27":"<a id=\"section5\"><\/a>\n<h1 style=\"font-family: 'Poppins', sans-serif; color: #ff6701; font-size: 26px; text-align: left; background-color: #fcecdd; padding: 20px; border-radius: 10px; font-weight:600;\">4. Classification Models<\/h1> ","0c0947ad":"<a id=\"subsection1\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">1.1 Training Data<\/h3>","6644844c":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">As you can see there are too many titles. I'll just group all the special titles like Major, Col, Capt etc., under 'Other Important'. All other Married Females will be grouped under Mrs. and Unmarried under Ms.<\/p>","0f6b1a1d":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Hyperparameter Tuning for Logistic Regression<\/h3>","1182471b":"<h1 style=\"font-family: 'Poppins', sans-serif; font-size: 30px; color:#fff; background-color: #40476D; padding: 15px; border-radius: 10px; text-align: center;\">If you like this notebook, Please leave an Upvote!<\/h1>","e08eeb36":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 500;\">Interpretations from the above boxenplots<\/h3>\n<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>Pclass 1 had people mostly had people aged between 30 and 50 years. It might be because the more aged people might have better jobs and finances to afford first class.<\/li>\n    <li>Pclass 2 had people aged between 20-40 more.<\/li>\n    <li>Pclass 3 had more people age between 20-30<\/li>\n    <li>Age column has significant outliers as observed from the plots.<\/li>\n<\/ul>","7ddf6226":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Logistic Regression to predict the Test Data<\/h3>","be65d248":"<img src= \"https:\/\/s26162.pcdn.co\/wp-content\/uploads\/sites\/3\/2021\/02\/titanic-feat1.jpg\" alt =\"Titanic\" style=\"height: 300px; width:auto; border-radius: 10px; align: center;\">","1412e0f7":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">One Hot Encoding<\/h3>","f5ae6c93":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Hyperparameter Tuning for XGB<\/h3>","94c11f23":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Embarked Column in Train Data<\/h3>","2043e68b":"<a id=\"subsection10\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.3 K Nearest Neighbours<\/h3>","a4f13ded":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #fff; font-size: 18px; text-align: center; background-color: #004BA8; padding: 10px; border-radius: 5px\">Univariate Analysis with respect to Survived Column(Target)<\/h3>","961c7715":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Final Train and Test Data:<\/p>","11b5904b":"<a id=\"subsection3\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">2.1 Handling Missing Values<\/h3>","92b8b7b5":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px;\">Passenger Id is an irrelevelant column that is not needed for our machine learning purposes.<\/p>","2a1b4ffa":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #fff; font-size: 18px; text-align: center; background-color: #004BA8; padding: 10px; border-radius: 5px\">Univariate Analysis<\/h3>","203eca83":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">We will take a look at both the Training and Test Data separately to get a clear view of the whole data.<\/p>","61445770":"I got a 0.77 score after a trial and error method by using all the models discussed above","78c8e264":"Used basically for creating indicator variables","086b63a3":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; color: #5eaaa8\">Description of Attributes<\/h3>\n\n<ol style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>PassengerId is the unique id of the row and it doesn't have any effect on target<\/li>\n    <li>Survived is the target variable we are trying to predict (0 or 1):\n        <ul>\n            <li>1 = Survived<\/li>\n            <li>0 = Not Survived<\/li>\n        <\/ul>\n    <\/li>\n    <li>Pclass (Passenger Class) is the socio-economic status of the passenger and it is a     \n        categorical ordinal feature which has 3 unique values (1, 2 or 3):\n        <ul>\n            <li>1 = Upper Class<\/li>\n            <li>2 = Middle Class<\/li>\n            <li>3 = Lower Class<\/li>\n        <\/ul>                \n    <\/li>\n    <li>Name, Sex and Age are self-explanatory<\/li>\n    <li>SibSp is the total number of the passengers' siblings and spouse<\/li>\n    <li>Parch is the total number of the passengers' parents and children<\/li>\n    <li>Ticket is the ticket number of the passenger<\/li>\n    <li>Fare is the passenger fare<\/li>\n    <li>Cabin is the cabin number of the passenger<\/li>\n    <li>Embarked is port of embarkation and it is a categorical feature which has 3 unique \n                values (C, Q or S):\n        <ul>\n            <li>C = Cherbourg<\/li>\n            <li>Q = Queenstown<\/li>\n            <li>S = Southampton<\/li>\n        <\/ul>\n<\/ol>","b200c849":"<a id=\"section1\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; color: #5eaaa8\">Introduction<\/h3>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Titanic, in full Royal Mail Ship (RMS) Titanic, British luxury passenger liner that sank on April 14\u201315, 1912, during its maiden voyage, en route to New York City from Southampton, England, killing about 1,500 passengers and ship personnel.<br><br> Titanic Dataset is a great one to begin your data science journey as this dataset needs good data preprocessing and cleaning. This helps you to learn and understand key concepts of data cleaning to make your models perfect!<\/p>","1c1b0fb7":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 20px; font-weight: 500;\">Interpretations from the above countplots<\/h3>\n<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>More than 60% people enlisted in this training data did not survive.<\/li>\n    <li>Majority of the people were from Passenger Class 3.<\/li>\n    <li>There were more number of males than females.<\/li>\n    <li>There were more number of people without Siblings or Spouses.<\/li>\n    <li>There were more number of people without Parents or Children<\/li>\n    <li>Large number of people who embarked were from Southamptom.<\/li>\n<\/ul>","efe6a807":"Forgot to label encode Age column!","b84b58f6":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Age Column<\/h3>","a2896343":"<a id=\"subsection17\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.8 Voting Classifer<\/h3>","2e210705":"<a id=\"subsection11\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.4 Random Forest<\/h3>","3608ea89":"<a id=\"subsection12\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">4.5 Support Vector Machines<\/h3>","6470abd7":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px;\">As you can observe here the graph is quite right skewed. So I'll tranform this distribution to a normal one using log tranformation.<\/p>","2704b995":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Transforming with log doesn't make it perfectly normal but I guess we can work with this.<\/p>","9884a962":"<a id=\"section2\"><\/a>\n<h1 style=\"font-family: 'Poppins', sans-serif; color: #ff6701; font-size: 26px; text-align: left; background-color: #fcecdd; padding: 20px; border-radius: 10px; font-weight:600;\">1. Exploratory Data Analysis<\/h1> ","aca3e53d":"<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>Similar to training data, test data also has lots of values missing in the 'Cabin' Column.<\/li>\n    <li>Age and Fare columns also have missing values but again we can replace these with mean or median accordingly.<\/li>\n<\/ul> ","2e757952":"<h3 style=\"font-family: 'Poppins', sans-serif; color: #343f56; font-size: 18px; text-align: left;\">Hyperparameter Tuning for Random Forest<\/h3>","1802c2d5":"<a id=\"boxenplot\"><\/a>","e04a862b":"<a id=\"subsection6\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">2.4 Binning of Age Column<\/h3>","c620beef":"<a id=\"subsection14\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">2.6 Adding SibSp and Parch to form new column FamilySize<\/h3>","72d4007d":"<ul style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    <li>Pclass has a good negative correlation with Fare. Its kinda obvious that as Pclass increases Fare will decrease(Third Class will cost less than First class).<\/li>\n    <li>Fare also has minor positive correlation with Survived. Again people who paid more had more chances of survival.<\/li>\n    <li>SibSp has good positive correlation with Parch. We can concatenate these together into a single family column later on.<\/li>\n<\/ul>","f0752234":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Now lets check our missing values graph again!<\/p>","57dc52c3":"<a id=\"subsection2\"><\/a>\n<h3 style=\"font-family: 'Poppins', sans-serif; color: #8F2D56; font-size: 18px; text-align: left; background-color: #FFBC42; padding: 15px; border-radius: 5px\">1.2 Test Data<\/h3>"}}