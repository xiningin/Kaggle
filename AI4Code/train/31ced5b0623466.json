{"cell_type":{"87564662":"code","8fc3614a":"code","35331926":"code","4e70377b":"code","8ada572d":"code","8e55d28e":"code","6760adfe":"code","9056c8b4":"code","4a46cfe7":"code","d1f41d21":"code","d68eb8e1":"code","0109049b":"code","ed46a038":"code","303c7d21":"code","79da8997":"code","0bc8c434":"code","1b27046c":"code","e7b77058":"code","39417d4e":"code","bc269f37":"code","02c4f04e":"code","703b57ac":"code","7fd990b7":"code","120c59e6":"code","b14c7d2e":"code","8a883f68":"code","259d70ff":"code","113a3b36":"code","e0b53a43":"code","4601d776":"code","7b67e8f3":"code","603b83c6":"code","b6e151d7":"code","d3151811":"code","fef8cbb1":"code","e6ca15f5":"code","6c0dfe44":"code","89ba2a08":"code","8b85cfae":"code","9bc2aa15":"code","029fec8e":"code","421a89e6":"code","2e24623e":"code","d4776d5f":"code","59b8111b":"code","7bc70ccd":"code","9cd97f9c":"code","2e9754e9":"code","0abcffff":"code","c2d85797":"code","80b93373":"code","b9f872df":"code","d79e53df":"code","15a3c8e5":"code","b3d57414":"code","754eecb3":"code","11655930":"code","bd205d34":"code","1d840a0a":"code","776a51b5":"code","1c0fc743":"code","307947a3":"code","d96e54d7":"code","a642e002":"code","d695c9e8":"code","ccd52335":"code","076d9d80":"markdown","5cfdf6f5":"markdown","5b019769":"markdown","a2b3751d":"markdown","659f2896":"markdown","2143b32f":"markdown","228f1885":"markdown","d93e3dfd":"markdown","1baaa057":"markdown","3ebf51ce":"markdown","8ca69689":"markdown","a5ec0acf":"markdown","f30f6756":"markdown","b8b53f17":"markdown","9d674b3e":"markdown","753e03ba":"markdown","456d3bdc":"markdown","5db35936":"markdown","012897fc":"markdown","8af66ade":"markdown","5978caed":"markdown","f0b492f3":"markdown","5db0fb62":"markdown","cdbd21e2":"markdown","c60bece7":"markdown","b4ba10ee":"markdown","8aaa63f3":"markdown","5f2805eb":"markdown","10137d28":"markdown","05f3613b":"markdown","bc518ce4":"markdown","3782967a":"markdown","5277fef9":"markdown","4622d1a6":"markdown","899cdb5a":"markdown","f741dc49":"markdown","243e4230":"markdown","30970775":"markdown","e6f0bfd8":"markdown","bbe51551":"markdown","1675527a":"markdown","2c436038":"markdown","818b567d":"markdown","f5c15a16":"markdown","69cc3a98":"markdown","71807072":"markdown","a4c8acf0":"markdown","c5d7d119":"markdown","f10dee63":"markdown","38985dd9":"markdown","63acd69d":"markdown","60000c25":"markdown","29a9ea4b":"markdown","6752bd88":"markdown","6eec8049":"markdown"},"source":{"87564662":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_copy = df.copy()\ndf_test_copy = pd.read_csv('..\/input\/titanic\/test.csv')","8fc3614a":"df.head(5)","35331926":"df.describe()","4e70377b":"df.isnull().sum()\n# df_test.isnull().sum()","8ada572d":"def median_age(df, sex):\n    filter_age = (df['Sex'] == sex)\n    age_group = df.loc[filter_age]\n    \n    class_group = df.groupby(['Sex'])\n    median_age = class_group.get_group(sex)['Age'].median()\n    \n    age_group = df['Age'].fillna(median_age, inplace=True)\n\n    \nclasses = [1,2,3]\nsexes = ['male','female']\n\nfor sex in sexes:\n    median_age(df, sex)    \n\nfor sex in sexes:\n    median_age(df_test, sex)","8e55d28e":"df.head(5)","6760adfe":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","9056c8b4":"df_copy = pd.get_dummies(df_copy, columns=['Sex'])","4a46cfe7":"df_copy.corr()","d1f41d21":"sns.heatmap((df_copy.drop(columns=['PassengerId'])).corr(),annot=True,cmap='coolwarm')","d68eb8e1":"def bar_chart(feature):\n    survived = df[df['Survived']==1][feature].value_counts()\n    dead = df[df['Survived']==0][feature].value_counts()\n    bar = pd.DataFrame([survived,dead])\n    bar.index = ['Survived','Dead']\n    bar.plot(kind='bar',stacked=True, figsize=(18,7))","0109049b":"bar_chart('Sex')","ed46a038":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df['Age'].max()))\nfacet.add_legend()\n \nplt.show()","303c7d21":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 18)","79da8997":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df['Age'].max()))\nfacet.add_legend()\nplt.xlim(60, df['Age'].max())","0bc8c434":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 40)","1b27046c":"bar_chart('Pclass')","e7b77058":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, df['Fare'].max()))\nfacet.add_legend()\nplt.show()","39417d4e":"def embark_class(embark):\n    class_embark_group = df.groupby(['Embarked'])\n    class_embark = class_embark_group.get_group((embark))\n    return class_embark['Pclass'].value_counts()\n\n\nbar = pd.DataFrame([embark_class('S'), embark_class('C'), embark_class('Q')])\nbar.index = ['Southampton', 'Cherbourg','Queenstown']\nbar.plot(kind='bar',stacked=False, figsize=(18,7))","bc269f37":"bar_chart('Embarked')","02c4f04e":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'SibSp',shade= True)\nfacet.set(xlim=(0, df['SibSp'].max()))\nfacet.add_legend()\nplt.show()","703b57ac":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Parch',shade= True)\nfacet.set(xlim=(0, df['Parch'].max()))\nfacet.add_legend()\nplt.show()","7fd990b7":"df['TotalFamily'] = df['SibSp'] + df['Parch']","120c59e6":"facet = sns.FacetGrid(df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'TotalFamily',shade= True)\nfacet.set(xlim=(0, df['TotalFamily'].max()))\nfacet.add_legend()\nplt.show()","b14c7d2e":"df['Deck'] = df['Cabin'].str[:1]\ndf['DeckClass'] = df['Deck'] + df['Pclass'].astype(str)","8a883f68":"pd.crosstab(df[\"Deck\"],df[\"Pclass\"])","259d70ff":"pd.crosstab(df[\"Deck\"],df[\"Survived\"])\n# df.pivot(index='Deck', columns='Survived', values='Pclass')","113a3b36":"df['DeckClass'] = df['Deck'] + df['Pclass'].astype(str)\npd.crosstab(df[\"DeckClass\"],df[\"Survived\"])","e0b53a43":"df = pd.get_dummies(df, columns=['Sex', 'Embarked'])","4601d776":"df.head(5)","7b67e8f3":"df.columns","603b83c6":"from sklearn.model_selection import train_test_split\n\ny = df.Survived\nfeatures = ['Pclass', 'Age', 'TotalFamily', 'Sex_female', \n                        'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'SibSp', 'Parch']\n\nX = df[features]\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, random_state = 1)","b6e151d7":"from sklearn.model_selection import cross_val_score","d3151811":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn import metrics\n\nforest_model_test = RandomForestClassifier(random_state=1)\nforest_model_test.fit(train_X, train_y)\nprediction_forest_test = forest_model_test.predict(test_X)\nmean_absolute_error(test_y, prediction_forest_test)","fef8cbb1":"scores = cross_val_score(forest_model_test, X, y, cv=10)\nbase_model_score = scores.mean()\nbase_model_score","e6ca15f5":"forest_model_test.get_params()","6c0dfe44":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrandom_grid","89ba2a08":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n                               n_iter = 10, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X, y)","8b85cfae":"# rfc = RandomForestClassifier()\n# # Random search of parameters, using 3 fold cross validation, \n# # search across 100 different combinations, and use all available cores\n# rfc_grid = GridSearchCV(estimator = rfc, param_grid = random_grid, cv = 3, verbose=2, n_jobs = -1)\n# # Fit the random search model\n# rfc_grid.fit(X, y)\n\n\n# Results:\n\n# Fitting 3 folds for each of 4320 candidates, totalling 12960 fits\n# GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n#              param_grid={'bootstrap': [True, False],\n#                          'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n#                                        110, None],\n#                          'max_features': ['auto', 'sqrt'],\n#                          'min_samples_leaf': [1, 2, 4],\n#                          'min_samples_split': [2, 5, 10],\n#                          'n_estimators': [200, 355, 511, 666, 822, 977, 1133,\n#                                           1288, 1444, 1600]},\n#              verbose=2)","9bc2aa15":"# rfc_grid.best_params_\n\n# Results:\n# {'bootstrap': True,\n#  'max_depth': 10,\n#  'max_features': 'sqrt',\n#  'min_samples_leaf': 4,\n#  'min_samples_split': 5,\n#  'n_estimators': 200}","029fec8e":"tuned_forest = RandomForestClassifier(random_state=1, n_estimators= 200,\n                 min_samples_split = 5,\n                 min_samples_leaf = 4,\n                 max_features = 'sqrt',\n                 max_depth = 10,\n                 bootstrap = True)\n\n\ntuned_forest.fit(train_X, train_y)\ntuned_prediction = tuned_forest.predict(test_X)\nmean_absolute_error(test_y, tuned_prediction)","421a89e6":"scores = cross_val_score(tuned_forest, X, y, cv=5)\nfinal_score = scores.mean()\nfinal_score","2e24623e":"final_score - base_model_score","d4776d5f":"from sklearn.svm import LinearSVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nsvc_model_test = make_pipeline(StandardScaler(),\n                    LinearSVC(random_state=1, max_iter=10000))\nsvc_model_test.fit(train_X, train_y)\n\nprediction_svc_test = svc_model_test.predict(test_X)\nmean_absolute_error(test_y, prediction_svc_test)","59b8111b":"scores = cross_val_score(svc_model_test, X, y, cv=10)\nscores.mean()","7bc70ccd":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score\n\nLR = {'learning_rate': [0.15,0.1,0.10,0.05], 'n_estimators':[100,150,200,250]}\n\ntuning = GridSearchCV(estimator = GradientBoostingRegressor(),\n                     param_grid = LR, scoring='r2')\ntuning.fit(train_X, train_y)\ntuning.best_params_, tuning.best_score_","9cd97f9c":"gradientregressor = GradientBoostingRegressor(max_depth=22, n_estimators=100, learning_rate=0.05)\n\nboost_model_test = gradientregressor.fit(train_X, train_y)\nprediction_boost_test = boost_model_test.predict(test_X)\nmean_absolute_error(test_y, prediction_boost_test)","2e9754e9":"scores = cross_val_score(boost_model_test, X, y, cv=10)\nscores.mean()","0abcffff":"df_test.columns","c2d85797":"df_test.isnull().sum()","80b93373":"df_test['Deck'] = df_test['Cabin'].str[:1]\ndf_test['DeckClass'] = df_test['Deck'] + df_test['Pclass'].astype(str)\ndf_test['TotalFamily'] = df_test['SibSp'] + df_test['Parch']\ndf_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked'])","b9f872df":"df_test[df_test['Fare'].isna()]\n\ngroup_fare = df_test.groupby(['Pclass'])\nfare_average = group_fare.get_group(3)['Fare'].median()","d79e53df":"df_test['Fare'].fillna(fare_average, inplace=True)","15a3c8e5":"df_test.head(4)","b3d57414":"ftrain_y = df.Survived\n\nfeatures = ['Pclass', 'Age', 'TotalFamily', 'Sex_female', \n                        'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n\nftrain_X = df[features]\n\npredict_features = df_test[features]","754eecb3":"df_test.columns","11655930":"df_test.head(3)","bd205d34":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn import metrics\n\nfinalmodel = RandomForestClassifier(random_state=1, n_estimators= 200,\n                 min_samples_split = 5,\n                 min_samples_leaf = 4,\n                 max_features = 'sqrt',\n                 max_depth = 10,\n                 bootstrap = True)\n\nfinalmodel.fit(ftrain_X, ftrain_y)\nprediction = finalmodel.predict(predict_features)","1d840a0a":"df_test['Survived'] = prediction\ndf_test_copy['Survived'] = prediction","776a51b5":"d = {'PassengerId': df_test['PassengerId'], 'Survived': df_test['Survived']}\ndf_prediction = pd.DataFrame(data=d)\ndf_prediction.set_index('PassengerId', inplace=True)","1c0fc743":"sns.heatmap((df_test_copy.drop(columns=['PassengerId'])).corr(),annot=True,cmap='coolwarm')","307947a3":"def results_bar(feature):\n    survived = df_test[df_test['Survived']==1][feature].value_counts()\n    dead = df_test[df_test['Survived']==0][feature].value_counts()\n    bar = pd.DataFrame([survived,dead])\n    bar.index = ['Survived','Dead']\n    bar.plot(kind='bar',stacked=True, figsize=(18,7))","d96e54d7":"results_bar('Sex_female')","a642e002":"results_bar('Pclass')","d695c9e8":"facet = sns.FacetGrid(df_test, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df_test['Age'].max()))\nfacet.add_legend()\n \nplt.show()","ccd52335":"# df_prediction.to_csv(r'data\/predictionsV7.csv', index = True)\n# submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n# submission['Survived'] = prediction\n\ndf_prediction.to_csv('.\/prediction.csv', index=True)","076d9d80":"## Families","5cfdf6f5":"### 2. Linear SVC","5b019769":"The graph shows that people with 1 parent or child had the highest percentage of survival, followed by those with 2 children or parents. Those with no child or parent had a highest percentage of death.","a2b3751d":"### Feature Creation","659f2896":"## Feature Selection","2143b32f":"#### Tune The Model","228f1885":"Gradient Boosting creates multiple decision tree models and constantly aims to improve based on errors of the last tree.\n\nGridSearchCV to Improve the model.","d93e3dfd":"## Cleaning The Data","1baaa057":"## Testing Different Models","3ebf51ce":"Filter cabin numbers to group passengers by deck.","8ca69689":"The Table below fills in some gaps that we had in the previous table: which class the survivors in each deck belonged to.","a5ec0acf":"Measure survival rates based on total family members a passenger had","f30f6756":"## Age","b8b53f17":"### Model Results","9d674b3e":"##### RandomizedSearchCV Parameters","753e03ba":"Both the graphs tell us that the majority of the people on board the Titanic were alone. \n\nThe graph below shows that people with 1 sibling or spouse had the highest percentage of survival, followed by those who had no spouces or siglings.","456d3bdc":"### 1. Random Forest Classifier","5db35936":"The Table below gives us an idea of which deck had the highest survival rate.\n\n - Deck B had the highest survival percentage (All of them were 1st class)\n - The second highest survival percentage was deck D. Followed by deck E","012897fc":"This model scored a: 0.78947","8af66ade":"## Deck & Cabin","5978caed":"We can tell that females had a much larger chance of survival. As we know from history, women and children were prioritized and this data proves that women were indeed prioritized.","f0b492f3":"### 3. Gradient Boosting Regressor","5db0fb62":"Before we begin modeling, we have to clean some of the data and add some one-hot encoding for some of the columns (Sex and Embarked). This will allow us to use those columns in our models since predictive models do not support string\/ object data types.","cdbd21e2":"The graphs below show that the model supports some of the data we have analyzed previously such as:\n\n- The model predicts that a big percentage of females survived and a very small percentage of males survived.\n- The model predicts that 1st class has a higher survival rate, followed by 2nd class.\n- The model predicts that children had a positive survival rate.","c60bece7":"#### Final Step: Tuning The Model","b4ba10ee":"- 21.52% error rate on Random Forest Classifier\n- 19.73% error rate on Linear SVC\n- 25.46% error rate on Gradient Boosting Regressor","8aaa63f3":"##### GridSearchCV Tuning\n\nThe code is commented and results displayed as comments due to the code taking too long to run.","5f2805eb":"The graph below shows us what class people who embarked from each location were in. It tells us that the majority of the people embarked from Southampton, followed by Cherbourg very little came from Queenstown. The graph below combined with the second graph shows us that:\n\n- People who embarked from Cherbourg had a higher survival rate, the majority were in first class.\n- People who embarked from Southampton had the highest death rate, the majority of them were in third class.\n- People who embarked from Queenstown had a slightly better survival rate than Southampton.\n","10137d28":"### Model Creation","05f3613b":"We can see that first class passengers survived at a much higher rate than any other class, followed by 2nd class and then 3rd class having the lowest survival rate. This may be due to their location, which according to the titanic deck plans shows that first class is at the top part of the ship. Another factor that could not be known from the data is that if first class were prioritized rather than survived due to their location on the ship at the time of the impact.","bc518ce4":"### Feature Creation","3782967a":"Find out the total number of family members a passenger has.","5277fef9":"# Titanic - Machine Learning from Disaster\n\nModel Score: 0.78947","4622d1a6":"## Sex","899cdb5a":"Initially I wanted to try and fill the missing data but theres too many missing cabin columns that I felt trying to predict what decks people were in and filling it out would greatly compromise the integrity of the data. So I will just analyze some of the data regarding decks from the information that we currently have.","f741dc49":"Linear SVC aims to split data into multiple factors based on multiple features","243e4230":"The graph below confirms that the majority of the people on board the Titanic were alone.","30970775":"### Clean The Test Data\n\nCleaning the test data to match my train data so that it may fit into the model for predictions","e6f0bfd8":"## Class & Fare","bbe51551":"## Correlation","1675527a":"#### Conclusion","2c436038":"# Predictive Modeling","818b567d":"#### Create The Base Model","f5c15a16":"The models main feature seems to be the sex of individuals on board the titanic. This is not surprising seeing as in the training data, difference in sex had the biggest difference in survival rates. ","69cc3a98":"After tuning the model, it improved by almost 1%","71807072":"### Missing Values","a4c8acf0":"Theres a lot of missing values for the age bracket, I've decided to fill it up by using the median age of their sex. Initially I used the age median of their specific class, but that changed the age median by 6 years which was too great. \n\nThis may not be very accurate in terms of guessing the age of an individual but it will keep the integrity of the known ages data so that we can move forward with predictive modeling.","c5d7d119":"Random forest creates multiple decision tree models that all something to add to improve the overall model. (Bagging)","f10dee63":"## Embarked","38985dd9":"The graph below shows how many people embarked from each location and what class they're in.","63acd69d":"We can now confirm that children up to the age of 15 were indeed prioritized since a higher percentage of them survived. The most common age was around the age of 28, and that age bracket had the most deaths and most survivors. The data also does not support that elderly were prioritized.","60000c25":"The higher the fare, the more likely that they're in first class, so its not a surprise to see that a high percentage of the people who paid over the average amount survived and that there is a high percentage of deaths in the 0-30 range which most of these people were in third class. So the graph below backs up the pervious graph regarding class survival rates.","29a9ea4b":"The table below helps us grasp who occupied which decks. \n\n- We can see that deck A, B, and C were exclusively for 1st class. \n- D and E were for everyone\n- F and G were 2nd and 3rd class\n- T is unknown since we only have 1 entry\n\nObviously all the information above is based on assumptions of the small data we have.\n","6752bd88":"## Final Model: Random Forest Classifier\nI've chosen to go with the Random Forest Classifier model based on the cross validation scores rather than the mean absolute error since cross validation uses K Fold which is more accurate for testing.","6eec8049":"# Data Analysis "}}