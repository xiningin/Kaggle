{"cell_type":{"d70bb8b2":"code","3e1cd00e":"code","ba36b468":"code","bc56a9b5":"code","04f7e458":"code","1c88f4dd":"code","4ae352c6":"code","6a2564f6":"code","c4c1ff2a":"code","9e180381":"code","e5ea5d9b":"code","2b40eb35":"code","a69d8ff8":"code","3c5ada06":"code","1575ebb9":"code","36da8c0e":"code","0f93a8fa":"code","0051b99c":"code","d4408725":"code","e4727786":"code","3a39f133":"code","4289d0ff":"code","e5f69e17":"code","d387f22a":"markdown","fbaa01de":"markdown","f3d65d2d":"markdown","339f08f6":"markdown","d36f7cfe":"markdown","fdb0f569":"markdown","555cfce9":"markdown","3209a297":"markdown","9a907763":"markdown","aee4696e":"markdown","6cf955c8":"markdown","2ec707cf":"markdown","f3593716":"markdown","2feb86d4":"markdown","d4594ca9":"markdown","7fd325a8":"markdown","e6433cd4":"markdown","cdb5ecec":"markdown"},"source":{"d70bb8b2":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nimport random\nimport albumentations as A\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense,Activation,Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping","3e1cd00e":"train_image_path = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\ntest_image_path = '..\/input\/plant-pathology-2021-fgvc8\/test_images'\ntrain_df_path = '..\/input\/plant-pathology-2021-fgvc8\/train.csv'\ntest_df_path = '..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv'","ba36b468":"df_train = pd.read_csv(train_df_path)\ndf_test=pd.read_csv(test_df_path)","bc56a9b5":"df_test","04f7e458":"df_train.labels.value_counts()","1c88f4dd":"plt.figure(figsize=(15,12))\nlabels = sns.barplot(df_train.labels.value_counts().index,df_train.labels.value_counts())\nfor item in labels.get_xticklabels():\n    item.set_rotation(45)","4ae352c6":"def batch_visualize(df,batch_size,path):\n    sample_df = df_train.sample(9)\n    image_names = sample_df[\"image\"].values\n    labels = sample_df[\"labels\"].values\n    plt.figure(figsize=(16, 12))\n    \n    for image_ind, (image_name, label) in enumerate(zip(image_names, labels)):\n        plt.subplot(3, 3, image_ind + 1)\n        image = cv2.imread(os.path.join(path, image_name))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        plt.imshow(image)\n        plt.title(f\"{label}\", fontsize=12)\n        plt.axis(\"off\")\n    plt.show()\n    \nbatch_visualize(df_train,9,train_image_path)","6a2564f6":"def batch_visualize_with_label(df,batch_size,path,label): \n    sample_df = df_train[df_train[\"labels\"]==label].sample(9)\n    image_names = sample_df[\"image\"].values\n    labels = sample_df[\"labels\"].values\n    plt.figure(figsize=(16, 12))\n    \n    for image_ind, (image_name, label) in enumerate(zip(image_names, labels)):\n        plt.subplot(3, 3, image_ind + 1)\n        image = cv2.imread(os.path.join(path, image_name))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        plt.imshow(image)\n        plt.axis(\"off\")\n    plt.show()","c4c1ff2a":"batch_visualize_with_label(df_train,9,train_image_path,'healthy')","9e180381":"batch_visualize_with_label(df_train,9,train_image_path,'scab')","e5ea5d9b":"batch_visualize_with_label(df_train,9,train_image_path,'frog_eye_leaf_spot')","2b40eb35":"batch_visualize_with_label(df_train,9,train_image_path,'rust')","a69d8ff8":"batch_visualize_with_label(df_train,9,train_image_path,'complex')","3c5ada06":"batch_visualize_with_label(df_train,9,train_image_path,'powdery_mildew')","1575ebb9":"HEIGHT = 128\nWIDTH=128\nSEED = 45\nBATCH_SIZE= 64\n\ntrain_datagen = ImageDataGenerator(rescale = 1\/255.,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split = 0.2,\n    zoom_range = 0.2,\n    shear_range = 0.2,\n    vertical_flip = False)\n\ntrain_dataset = train_datagen.flow_from_dataframe(\n    df_train,\n    directory = train_image_path,\n    x_col = \"image\",\n    y_col = \"labels\",\n    target_size = (HEIGHT,WIDTH),\n    class_mode='categorical',\n    batch_size = BATCH_SIZE,\n    subset = \"training\",\n    shuffle = True,\n    seed = SEED,\n    validate_filenames = False\n)\n\n\nvalidation_dataset = train_datagen.flow_from_dataframe(\n    df_train,\n    directory = train_image_path,\n    x_col = \"image\",\n    y_col = \"labels\",\n    target_size = (HEIGHT,WIDTH),\n    class_mode='categorical',\n    batch_size = BATCH_SIZE,\n    subset = \"validation\",\n    shuffle = True,\n    seed = SEED,\n    validate_filenames = False\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale = 1.\/255\n)\nINPUT_SIZE = (HEIGHT,WIDTH,3)\ntest_dataset=test_datagen.flow_from_dataframe(\n    df_test,\n    directory=test_image_path,\n    x_col='image',\n    y_col=None,\n    class_mode=None,\n    target_size=INPUT_SIZE[:2]\n)\n","36da8c0e":"model=Sequential()\nmodel.add(Conv2D(32,(3,3),activation='relu',padding='same',input_shape=(HEIGHT,WIDTH,3)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Flatten())\nmodel.add(Dense(12,activation='softmax'))","0f93a8fa":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\nmodel.summary()","0051b99c":"checkpoint_path = \"training_1\/cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)","d4408725":"model_history=model.fit_generator(train_dataset,\n                                  validation_data=validation_dataset,\n                                  epochs=5,\n                                  steps_per_epoch=train_dataset.samples\/\/128,\n                                 validation_steps=validation_dataset.samples\/\/128,\n                                 callbacks=[cp_callback]\n                                 )","e4727786":"train_dataset.class_indices.items()","3a39f133":"preds = model.predict(test_dataset)\nprint(preds)","4289d0ff":"preds_disease_ind=np.argmax(preds, axis=-1)","e5f69e17":"preds_disease_ind","d387f22a":"# 2. About Dataset","fbaa01de":"# 1. Problem Statement \uff1f\n\nApples are one of the most important temperate fruit crops in the world. Foliar (leaf) diseases pose a major threat to the overall productivity and quality of apple orchards. The current process for disease diagnosis in apple orchards is based on manual scouting by humans, which is time-consuming and expensive.\n\nThe main objective of the competition is to develop machine learning-based models to accurately classify a given leaf image from the test dataset to a particular disease category, and to identify an individual disease from multiple disease symptoms on a single leaf image.\n","f3d65d2d":"## libraries ","339f08f6":"# 3. Tensorflow Dataset Generation","d36f7cfe":"### Visualise rust leaves ","fdb0f569":"> \ud83d\udccc**Note**:\n* `train.csv` contains information about the image files available in `train_images`. It contains 18632 rows(images) with 2 columns i.e (image , labels )\n* `test.csv` The test set images. This competition has a hidden test set: only three images are provided here as samples while the remaining 5,000 images will be available to your notebook once it is submitted.","555cfce9":"### Visualise powdery_mildew leaves","3209a297":"## Batch Visualisation of Images ","9a907763":"> \ud83d\udccc**Note**:\n* We have multiple labels for eg. label can be **scab** or **scab and rust**\n* Main labels are - **scab** , **healthy** , **frog_eye_leaf_spot** , **rust** , **complex** and **powdery_mildew**","aee4696e":"## Batch visualisation with labels","6cf955c8":"### Visualise healthy leaves","2ec707cf":"### Visualise complex leaves","f3593716":"### Visualise frog_eye_leaf_spot  leaves","2feb86d4":"# 4. Convolutional Neural Networks ","d4594ca9":"### Visualise scab leaves ","7fd325a8":"> Refer Tensorflow docs for more information [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator)","e6433cd4":"# Prediction","cdb5ecec":"<h1><center> \ud83c\udf4e Classify foliar diseases in apple trees<\/center><\/h1>"}}