{"cell_type":{"6e444099":"code","fcf6c98e":"code","fbb89df4":"code","9275b5f8":"code","18316de2":"code","22c3cab4":"code","ee514477":"code","5f2ff598":"code","99aa8516":"code","f01ac06e":"code","65011bf9":"code","36779ca5":"code","8d36eeee":"code","48ba9c36":"code","5c46fba0":"code","7ef0bd79":"code","2ba14fb7":"code","b089746a":"code","17ab4be1":"code","071a3126":"code","6f059fac":"code","c928d0d2":"code","8cd658fb":"code","8a37ca6e":"code","c06202e2":"code","814fbf97":"markdown","91ff9b53":"markdown","de695d34":"markdown","daea54e8":"markdown","f679a892":"markdown","b412a4d4":"markdown","d11e0144":"markdown"},"source":{"6e444099":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom PIL import Image\nimport tensorflow as tf\nfrom IPython.display import Image \n\nfrom sklearn.model_selection import train_test_split\nfrom skimage.transform import resize\nfrom sklearn.metrics import accuracy_score\n\nfrom keras.applications import ResNet50\nfrom keras.applications.nasnet import NASNetLarge\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping,ModelCheckpoint\nfrom keras.utils import plot_model\nimport keras.backend as K\n","fcf6c98e":"# Count the images in test file\ntest = {}\ncount = 0\nfor folder in os.listdir('..\/input\/fer2013\/test'):\n    temp = []\n    for files in os.listdir(f\"..\/input\/fer2013\/test\/{folder}\"):\n        temp.append(files)\n    count += len(temp)\n    test[folder] = temp\n    print(f\"{folder} has {len(temp)} images\")\nprint(f\"Total images in all folders are {count}\")","fbb89df4":"# Count the images in train file\ntrain = {}\ncount = 0\nfor folder in os.listdir('..\/input\/fer2013\/train'):\n    temp = []\n    for files in os.listdir(f\"..\/input\/fer2013\/train\/{folder}\"):\n        temp.append(files)\n    count += len(temp)\n    train[folder] = temp\n    print(f\"{folder} has {len(temp)} images\")\nprint(f\"Total images in all folders are {count}\")","9275b5f8":"# training dataframe with folder name as index\ntrain_df = pd.DataFrame.from_dict(train.values())\ntrain_df.index = train.keys()\ntrain_df","18316de2":"# list of all the emotions to classify in the output\nemotions = [k for k in train.keys()]","22c3cab4":"base_dir = '..\/input\/fer2013\/'","ee514477":"# lets see one image from each category from training data\nplt.figure(figsize = (20, 8))\nfor i in range(7):\n    ax = plt.subplot(2,4, i+1)\n    img = cv2.imread(f\"{base_dir}train\/{emotions[i]}\/{train_df.loc[emotions[i], i+7]}\")\n    ax.imshow(img, cmap = 'gray')\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(emotions[i])","5f2ff598":"# To know the shape of image\none_img = cv2.imread('..\/input\/fer2013\/train\/surprise\/Training_10013223.jpg')\none_img.shape","99aa8516":"# Data augmentation\ntrain_dir = f\"{base_dir}\/train\"\ntest_dir = f\"{base_dir}\/test\"\ntrain_datagen = ImageDataGenerator(width_shift_range = 0.1,\n                                    height_shift_range = 0.1,\n                                    horizontal_flip = True,\n                                    rescale = 1.\/255,\n                                    #zoom_range = 0.2,\n                                    rotation_range= 5, \n                                    shear_range= 0.2,\n                                   fill_mode = 'nearest'\n                                    )\ntest_datagen = ImageDataGenerator(rescale= 1.0\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                        train_dir,\n                        target_size=(48,48),\n                        batch_size=64,\n                        class_mode='categorical',\n                        subset = \"training\")\ntest_generator = test_datagen.flow_from_directory(\n                        test_dir,\n                        target_size=(48,48),\n                        batch_size=64,\n                        class_mode='categorical')","f01ac06e":"# model = Sequential()\n\n# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n# model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Flatten())\n# model.add(Dense(1024, activation='relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(7, activation='softmax'))\n\n# # model compilation\n# model.compile(loss = 'categorical_crossentropy', optimizer =Adam(lr=0.0001, decay=1e-6), metrics =['accuracy'])","65011bf9":"# model.summary()","36779ca5":"base_model = ResNet50(input_shape=(48,48,3),include_top = False, weights = 'imagenet')\n\nlen(base_model.layers)","8d36eeee":"# Freezing layers \nfor layer in base_model.layers[:-4]:\n    layer.trainable = False","48ba9c36":"# Build model on the top of base model\nmodel = Sequential()\n\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\n\n# fully connected layer-1\nmodel.add(Dense(128, kernel_initializer = 'he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\n# fully connected layer-2\nmodel.add(Dense(64, kernel_initializer = 'he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\n# fully connected layer-3\nmodel.add(Dense(32, kernel_initializer = 'he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n# output layer\nmodel.add(Dense(7, activation = 'softmax'))\n\n# model Summary\nmodel.summary()","5c46fba0":"plot_model(model, to_file= 'convnet.png', show_shapes= True)\nImage(filename='convnet.png')","7ef0bd79":"# function to calculate f1_score\ndef f1_score(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val","2ba14fb7":"# evaluation metrics\nfrom keras.metrics import AUC, BinaryAccuracy, Precision, Recall\nmetric = [BinaryAccuracy(name = 'accuracy'), \n           Precision(name = 'precision'), \n           Recall(name = 'recall'), \n           AUC(name = 'AUC'),\n           ]","b089746a":"# callbacks\n# checkpoint = ModelCheckpoint('model.h5')\n\nearlystop = EarlyStopping(patience=20, \n                          verbose=1)\n#                           restore_best_weights=True)\n                        \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.5, \n                              patience=20, \n                              verbose=1,\n                              min_lr=1e-10)\n#                               min_delta=0.0001)\ncallbacks = [checkpoint,earlystop,reduce_lr]","17ab4be1":"# compile model\nmodel.compile(optimizer= 'Adam', loss='categorical_crossentropy', metrics=metric)","071a3126":"# model fitting\nhistory = model.fit_generator(train_generator, validation_data=test_generator,epochs=60,verbose = 1,callbacks=callbacks)","6f059fac":"model.save('model_optimal.h5')\nmodel.save_weights('model_weights.h5')","c928d0d2":"plt.figure(0)\nplt.plot(history.history['accuracy'], label= 'train accuracy')\nplt.plot(history.history['val_accuracy'], label= 'test accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('Accuracy')\nplt.legend()","8cd658fb":"plt.figure(0)\nplt.plot(history.history['loss'], label= 'train loss')\nplt.plot(history.history['val_loss'], label= 'test loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('Loss')\nplt.legend()","8a37ca6e":"plt.figure(0)\nplt.plot(history.history['AUC'], label= 'train auc')\nplt.plot(history.history['val_AUC'], label= 'test auc')\nplt.title('auc')\nplt.xlabel('epochs')\nplt.ylabel('auc')\nplt.legend()","c06202e2":"plt.figure(0)\nplt.plot(history.history['precision'], label= 'train precision')\nplt.plot(history.history['val_precision'], label= 'test precision')\nplt.title('precision')\nplt.xlabel('epochs')\nplt.ylabel('precision')\nplt.legend()","814fbf97":"The difference between Keras.fit and Keras.fit_generator functions used to train a deep learning neural network:    \n* `model.fit` is used when the entire training dataset can fit into the memory and no data augmentation is applied.    \n* `model.fit_generator` is used when either we have a huge dataset to fit into our memory or when data augmentation needs to be applied.","91ff9b53":"We can design the architecture of the CNN model by adding Convolution layers and pooling layers, but here I am using the weights of already trained model `ResNet50`","de695d34":"## About the Dataset\nThe data consists of 48*48 pixel grayscale face images. The images are centered and occupy an equal amount of space. This dataset consist of facial emotions of following categories:\n\n0:angry        \n1:disgust     \n2:feat     \n3:happy     \n4:sad     \n5:surprise     \n6:natural   \n\nThe training set consists of 28,709 examples and the public test set consists of 3,589 examples.","daea54e8":"## ResNet50\n\nSteps:\n1. make a instance of ResNet50\n2. freezing the layers\n3. build model\n4. compile the model\n5. fit the model\n6. make predictions","f679a892":"Keras `ImageDataGenerator` is a gem! It lets you augment your images in real-time while your model is still training! You can apply any random transformations on each training image as it is passed to the model. This will not only make your model robust but will also save up on the overhead memory!     \n\nThe ImageDataGenerator class has three methods `flow(), flow_from_directory()` and `flow_from_dataframe()` to read the images from a big numpy array and folders containing images. \n\nIn this the `flow_from_directory()` is used because it expects at least one directory under the given directory path","b412a4d4":"## Import libraries","d11e0144":"## Explore dataset"}}