{"cell_type":{"720a5dc9":"code","bfe84e14":"code","f444f718":"code","772e7abe":"code","7cf737a4":"code","41838f31":"code","5c9cf3f6":"code","68e7bb61":"code","6b66fc27":"code","3692dc29":"code","8aeeeae1":"code","47097863":"code","cb5a13c8":"code","35b4d7cd":"code","f6e9c449":"code","a59bf6e2":"code","3816d2a8":"code","cb54df6e":"code","6bc85d70":"code","93ed75b4":"code","672361de":"code","cf68d927":"code","3ba4818b":"code","c41ba4e5":"code","a15fe920":"code","6428ac75":"code","1b5d9979":"code","4800ce58":"code","b1f1802c":"code","2e0523ba":"code","424886b9":"code","2770b544":"markdown","b692071c":"markdown","9c7ac6db":"markdown","ee42e2fe":"markdown","f2824f18":"markdown","52f00449":"markdown","2d4d5833":"markdown","dd81f232":"markdown","da652432":"markdown","c8da36ae":"markdown","d5162bbe":"markdown","b2c58d16":"markdown"},"source":{"720a5dc9":"import warnings\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\n#plt.style.use('fivethirtyeight')\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib\nimport datetime\nfrom IPython.display import clear_output\nimport time\nimport seaborn as sns\nsns.set_style('darkgrid')\ncolor = sns.color_palette()","bfe84e14":"train = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')","f444f718":"train['Date'] = pd.to_datetime(train['Date'])\ntest['Date'] = pd.to_datetime(test['Date'])","772e7abe":"display(train.head())\ndisplay(test.head())","7cf737a4":"test = test.sort_values(by=['Store','Date'])\ntrain = train.sort_values(by=['Store','Date'])","41838f31":"train['Date'].unique().max(), train['Date'].unique().min() \n\n","5c9cf3f6":"test['Date'].unique().max(), test['Date'].unique().min() ","68e7bb61":"test[test['Store'] == 1].head()","6b66fc27":"store_list = test['Store'].unique()","3692dc29":"train.head()","8aeeeae1":"store = 21\n\ndate_from = '2013-06-02'\ndate_to = ''\nrsmpl_opt = '3d'\nspqd_period = 24\nprogram_starts = time.time()\niters = 0\n\nsales = train[train['Store'] == store]\nsales = sales.set_index('Date')\nsales = sales[date_from:]\n\nsales_exog = sales[['Open','Promo','StateHoliday','SchoolHoliday']]\nsales_exog['Open'] = pd.to_numeric(sales_exog['Open'], errors='coerce').fillna(0)\nsales_exog['Promo'] = pd.to_numeric(sales_exog['Promo'], errors='coerce').fillna(0)\nsales_exog['StateHoliday'] = pd.to_numeric(sales_exog['StateHoliday'], errors='coerce').fillna(0)\nsales_exog['SchoolHoliday'] = pd.to_numeric(sales_exog['SchoolHoliday'], errors='coerce').fillna(0)\n\nsales_exog = sales_exog[date_from:]\n\nsales_exog = sales_exog.resample(rsmpl_opt).mean()\n#sales_exog = sales_exog\nsales_exog = sales_exog.fillna({'Open':0, 'Promo':0, 'StateHoliday':0, 'SchoolHoliday':0})\n#print(sales_exog)\n\n\n\nsales = sales['Sales'].resample(rsmpl_opt).mean()    \n\n\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(sales, lags=len(sales)\/2-1, ax=ax1) # \nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(sales, lags=len(sales)\/2-1, ax=ax2)# , lags=40\n\n\n\n\n\n\n\n\n","47097863":"fig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(sales, lags=len(sales)\/2-1, ax=ax1) # \nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(sales, lags=len(sales)\/2-1, ax=ax2)# , lags=40","cb5a13c8":"from statsmodels.tsa.stattools import adfuller\ndef test_stationarity(timeseries, window = 12, cutoff = 0.01):\n\n    #Determing rolling statistics\n    rolmean = timeseries.rolling(window).mean()\n    rolstd = timeseries.rolling(window).std()\n\n    #Plot rolling statistics:\n    fig = plt.figure(figsize=(12, 8))\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show()\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC', maxlag = 20 )\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    pvalue = dftest[1]\n    if pvalue < cutoff:\n        print('p-value = %.4f. The series is likely stationary.' % pvalue)\n    else:\n        print('p-value = %.4f. The series is likely non-stationary.' % pvalue)\n    \n    print(dfoutput)","35b4d7cd":"test_stationarity(sales)","f6e9c449":"first_diff = sales - sales.shift(1)\nfirst_diff = first_diff.dropna(inplace = False)\ntest_stationarity(first_diff, window = 12)","a59bf6e2":"fig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(first_diff, lags=len(first_diff)-2,ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(first_diff, lags=len(first_diff)\/2-1, ax=ax2)","3816d2a8":"hasil = pd.DataFrame()\n\n# Change the rsmpl_opt and also spqd_period for different smoothing of data \ndate_from = '2013-06-02'\ndate_to = ''\nrsmpl_opt = 'M'\nspqd_period = 12\nprogram_starts = time.time()\niters = 0\n\nfor store in store_list:\n    \n   \n    sales = train[train['Store'] == store]\n    sales = sales.set_index('Date')\n    sales = sales[date_from:]\n    \n    sales_exog = sales[['Open','Promo','StateHoliday','SchoolHoliday']]\n    sales_exog['Open'] = pd.to_numeric(sales_exog['Open'], errors='coerce').fillna(0)\n    sales_exog['Promo'] = pd.to_numeric(sales_exog['Promo'], errors='coerce').fillna(0)\n    sales_exog['StateHoliday'] = pd.to_numeric(sales_exog['StateHoliday'], errors='coerce').fillna(0)\n    sales_exog['SchoolHoliday'] = pd.to_numeric(sales_exog['SchoolHoliday'], errors='coerce').fillna(0)\n    \n    sales_exog = sales_exog[date_from:]\n    \n    sales_exog = sales_exog.resample(rsmpl_opt).mean()\n    #sales_exog = sales_exog\n    sales_exog = sales_exog.fillna({'Open':0, 'Promo':0, 'StateHoliday':0, 'SchoolHoliday':0})\n    #print(sales_exog)\n    \n    \n    \n    sales = sales['Sales'].resample(rsmpl_opt).mean()    \n    #y = pd.DataFrame(sales['Sales'])\n    \n    \n    \n    #params\n    p = d = q = range(0, 2)\n    pdq = list(itertools.product(p, [1], q))\n    seasonal_pdq = [(x[0], 1, x[2], spqd_period) for x in pdq]\n    #seasonal_pdq = [(0, 1, 1, spqd_period)]\n    # IMPORTANTTTTT\n    \n    #p = q = range(0, 6) \n    #pdq = list(itertools.product([0], [1], q)) \n    #sp = sq = range(1,8)#range(0,1) <- ARIMAX \n    #seasonal_pdq = list(itertools.product(sp, [0,1], sq,[1]))#rlist(itertools.product(sp, [0], sq,[0]))<- ARIMAX\n    \n    \n    #p = d = q = range(0, 6)\n    #pdq = list(itertools.product(p, [1], q))\n    #seasonal_pdq = [(x[0], x[1], x[2], spqd_period) for x in pdq]\n    #seasonal_pdq = [(0, 1, 1, spqd_period)]\n    \n    \n    \n    #search for the best params\n    aic = 9999999999999999999\n    for param in pdq:\n        for param_seasonal in seasonal_pdq:\n            try:\n                mod2 = sm.tsa.statespace.SARIMAX(sales,\n                                                exog=sales_exog,\n                                                order=param,\n                                                seasonal_order=param_seasonal,\n                                                enforce_stationarity=False,\n                                                enforce_invertibility=False,\n                                                error_action='ignore',\n                                                suppress_warnings=True)\n                results = mod.fit()\n\n                if ((results.aic < 50) && ) :\n                    aic = results.aic\n                    st = f'ARIMA{param}x{param_seasonal}12 - AIC:{results.aic}'\n                    pl = param  #param with lowest aic\n                    pls = param_seasonal #param_seasonal with lowest aic\n                    mod = mod2\n                    return\n            except:\n                continue\n            \n\n    #print('=========LOWEST AIC===========')\n    \n    #print(f'ARIMA{pl}x{pls}12 - AIC:{results.aic}')\n    #print([pl[0], pl[1], pl[2]])\n    #print([pls[0], pls[1], pls[2]])\n\n    #mod = sm.tsa.statespace.SARIMAX(sales,\n    #                                exog=sales_exog,\n    #                                order=(pl[0], pl[1], pl[2]),\n     #                               seasonal_order=(pls[0], pls[1], pls[2], spqd_period), # IMPORTANTTTTT\n    #                                enforce_stationarity=False,\n    #                                enforce_invertibility=False,\n    #                              error_action='ignore',\n     #                               suppress_warnings=True)\n    results = mod.fit()\n    #print(results.summary().tables[1])\n    #print(results.summary().tables[1])\n\n    \n    #get the prediction for this store\n    test_sales = test[test['Store'] == store]\n    test_sales = test_sales.set_index('Date')\n    test_sales_exog = test_sales[['Open','Promo','StateHoliday','SchoolHoliday']]\n    \n    test_sales_exog['Open'] = pd.to_numeric(test_sales_exog['Open'], errors='coerce').fillna(0)\n    test_sales_exog['Promo'] = pd.to_numeric(test_sales_exog['Promo'], errors='coerce').fillna(0)\n    test_sales_exog['StateHoliday'] = pd.to_numeric(test_sales_exog['StateHoliday'], errors='coerce').fillna(0)\n    test_sales_exog['SchoolHoliday'] = pd.to_numeric(test_sales_exog['SchoolHoliday'], errors='coerce').fillna(0)\n\n    test_sales_exog = test_sales_exog.resample(rsmpl_opt).mean()\n    test_sales_exog = test_sales_exog.fillna({'Open':0, 'Promo':0, 'StateHoliday':0, 'SchoolHoliday':0})\n    #print(test_sales_exog)\n    \n    \n    pred_uc = results.get_forecast(steps=len(test_sales_exog),exog=test_sales_exog)\n    pred_ci = pred_uc.conf_int()\n    pred_ci = pd.DataFrame(pred_ci[['lower Sales','upper Sales']].mean(axis=1))\n    pred_ci['Store'] = store\n    pred_ci = pred_ci.sort_index()\n    #pred_ci.sort_values(by=['Index'])\n    hasil = hasil.append(pred_ci)\n    \n    \n    \n    \n    \n    #print(f'{sales_exog.index}')\n    #print(f'{y.index} ')\n    clear_output()\n    print(st)\n    iters = iters + 1\n    print(f'done: {iters}\/{len(store_list)}')\n    now = time.time()\n    print(\"It has been {0} seconds since the loop started\".format(now - program_starts))\n\nprint('done')\n\n\n    \n    \n","cb54df6e":"hasil2 = hasil","6bc85d70":"date = str(sales_exog.last('10M').first('1d').index.item())\n#pred = results.get_prediction(start=pd.to_datetime(date), exog=sales_exog[sales_exog.index >= pd.to_datetime(date)] , dynamic=False)\npred = results.get_prediction(start=pd.to_datetime(date), exog=sales_exog[sales_exog.index >= date] , dynamic=False)\npred_cix = pred.conf_int()\nax = sales[date_from:].plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n\nax.fill_between(pred_cix.index,\n                pred_cix.iloc[:, 0],\n                pred_cix.iloc[:, 1], color='k', alpha=.2)\nplt.legend()\nplt.show()\npred.dist()","93ed75b4":"y_forecasted = pred.predicted_mean\ny_truth = sales[date:]\nmse = ((y_forecasted - y_truth) ** 2).mean()\nprint(f'The Mean Squared Error is {round(mse, 2)}')\nprint(f'The Root Mean Squared Error of our forecasts is {round(np.sqrt(mse))}')","672361de":"pd.concat([pd.DataFrame(sales), sales_exog],axis=1, join='inner')","cf68d927":"hasil","3ba4818b":"store_list[1:25]","c41ba4e5":"wak = pd.DataFrame()\nm = max(store_list)\nfor store in store_list:\n    wak = wak.append(test[test['Store'] == store][['Id','Store','Date']])\n    clear_output()\n    print(f'{store}\/{m}')\n    \n#wak\nwkwk = pd.DataFrame([], columns=['Id','Date','Sales'])\niters = 0;\nn = len(wak)\nfor index, row in wak.iterrows():\n    wkwk = wkwk.append({'Id': row['Id'],'Date': row['Date'], 'Sales': hasil[hasil['Store'] == row['Store']].iloc[hasil[hasil['Store']== row['Store']].index.get_loc(row['Date'], method='nearest')][0]},ignore_index=True)\n    iters = iters +1\n    clear_output()\n    print(f'matching = {iters}\/{n}')\n    \n","a15fe920":"wkwk2['Sales'][wkwk2['Sales'] > 10**3]","6428ac75":"wkwk2.describe()","1b5d9979":"wkwk2 = wkwk[['Id', 'Sales']].sort_values(['Id'])\nwkwk2\nlen(wkwk2['Sales'].unique())","4800ce58":"len(wkwk2['Sales'][np.isnan(wkwk2['Sales'])])\nlen(wkwk2['Sales'][wkwk2['Sales'] < 0])\nwkwk2['Sales'][np.isnan(wkwk2['Sales'])] = wkwk2['Sales'].notnull().mean()\nwkwk2['Sales'][wkwk2['Sales'] < 0] = wkwk2['Sales'].notnull().mean()\nwkwk2['Sales'][wkwk2['Sales'] > 10**4] = wkwk2['Sales'].notnull().mean()\n","b1f1802c":"wkwk2[np.isnan(wkwk2['Sales'])]","2e0523ba":"wkwk2['Sales'][wkwk2['Sales'] < 0]","424886b9":"wkwk2.to_csv('weekly3.csv',index=False)","2770b544":"# Checking result and cleaning just before exporting the result into csv.","b692071c":"# Sort test & train data by store then date","9c7ac6db":"## MAIN SARIMAX LOOP FOR ALL STORE LIST","ee42e2fe":"Get store list from needed for test data","f2824f18":"# Read the csv data ","52f00449":"#  Import stuff","2d4d5833":"Stasionary test and acf, pacf graph","dd81f232":"# Analyzing data","da652432":"# Matching result and id, also turning the smoothed data to daily data","c8da36ae":"## Checking model","d5162bbe":"## Convert date column to datetime type","b2c58d16":"# OUTPUT to csv"}}