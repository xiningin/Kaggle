{"cell_type":{"96412f3f":"code","528e1f53":"code","81e60f5b":"code","2cbd291e":"code","54ecb83b":"code","7563257d":"code","b62463ba":"code","9eaeda25":"code","395ff922":"code","ea4fe97e":"code","439368a4":"code","083a2c93":"markdown","ffb0f7a0":"markdown","2696223c":"markdown","328b517c":"markdown","c025f5e5":"markdown","b2c45656":"markdown","677f07d8":"markdown","02efc1ee":"markdown"},"source":{"96412f3f":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import applications\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.losses import BinaryCrossentropy, binary_crossentropy\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, Conv2DTranspose, MaxPooling2D, Input, RepeatVector, Reshape, concatenate, UpSampling2D\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os","528e1f53":"!pip install googledrivedownloader\nfrom google_drive_downloader import GoogleDriveDownloader as gdd\ngdd.download_file_from_google_drive(file_id='1KVfrTao_0XzUWLI4-JgGZJOLE0ddjwto', dest_path='.\/data\/file.zip', unzip=True)","81e60f5b":"lst   = os.listdir('\/kaggle\/working\/data\/images\/')\nmask = []\nimg = []\nfor filename in lst:\n    if filename.endswith('.jpg'):\n        img.append('\/kaggle\/working\/data\/images\/' + filename)\n    if filename.endswith('.png'):\n        mask.append('\/kaggle\/working\/data\/images\/' + filename)\n\nimg.sort()\nmask.sort()\n#img = img[:1000]\n#masks = mask[:1000]\n\ndf = pd.DataFrame({'Filepath_Image':img, 'Filepath_Mask':mask})","2cbd291e":"img = img[:1000]\nmask = mask[:1000]","54ecb83b":"x = np.zeros((1000, 256, 256, 1), dtype=np.float32)\ny = np.zeros((1000, 256, 256, 1), dtype=np.int8)\n\nfor i in tqdm(range(len(img))):\n    imx = cv2.imread(img[i], 0)\n    imx = cv2.resize(imx, (256, 256))\n    imx = imx \/ 255.0\n    x[i,:,:, 0] = imx\n    \nfor i in tqdm(range(len(mask))):\n    msk = cv2.imread(mask[i], 0)\n    msk = (msk!=2)*1.0\n    msk = cv2.resize(msk, (256, 256))\n    msk = 1.0*(msk[:,:]>0.2)\n    #msk = msk \/ 3.0\n    y[i,:,:,0] = msk","7563257d":"fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10,12))\n\nax[0, 0].imshow(x[0, :, :, 0], cmap='gray', vmin=0, vmax=1)\nax[0, 0].set_xticks([]), ax[0, 0].set_yticks([])\nax[0, 1].imshow(y[0, :, :, 0], cmap='gray', vmin=0, vmax=1)\nax[0, 1].set_xticks([]), ax[0, 1].set_yticks([])\nax[1, 0].imshow(x[100, :, :, 0], cmap='gray', vmin=0, vmax=1)\nax[1, 0].set_xticks([]), ax[1, 0].set_yticks([])\nax[1, 1].imshow(y[100, :, :, 0], cmap='gray', vmin=0, vmax=1)\nax[1, 1].set_xticks([]), ax[1, 1].set_yticks([])\nax[2, 0].imshow(x[800, :, :, 0], cmap='gray', vmin=0, vmax=1)\nax[2, 0].set_xticks([]), ax[2, 0].set_yticks([])\nax[2, 1].imshow(y[800, :, :, 0], cmap='gray', vmin=0, vmax=1)\nax[2, 1].set_xticks([]), ax[2, 1].set_yticks([])\nplt.show()","b62463ba":"def iou_score(x, y, smooth = 1e-6):\n    intersection = tf.reduce_sum(x * y)\n    union = tf.reduce_sum(x + y) - intersection\n    return (intersection + smooth) \/ (union + smooth)\ndef iou_loss(x,y, smooth = 1e-6):\n    intersection = tf.reduce_sum(x * y)\n    union = tf.reduce_sum(x + y) - intersection\n    return 1 - ((intersection + smooth) \/ (union + smooth))\n\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    Dice = (2*|X & Y|)\/ (|X|+ |Y|)\n         =  2*sum(|A*B|)\/(sum(A^2)+sum(B^2))\n    ref: https:\/\/arxiv.org\/pdf\/1606.04797v1.pdf\n    \"\"\"\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)\n\ndef jaccard_distance_loss(y_true, y_pred, smooth=100):\n    \"\"\"\n    Jaccard = (|X & Y|)\/ (|X|+ |Y| - |X & Y|)\n            = sum(|A*B|)\/(sum(|A|)+sum(|B|)-sum(|A*B|))\n    \n    The jaccard distance loss is usefull for unbalanced datasets. This has been\n    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n    gradient.\n    \n    Ref: https:\/\/en.wikipedia.org\/wiki\/Jaccard_index\n    \n    @url: https:\/\/gist.github.com\/wassname\/f1452b748efcbeb4cb9b1d059dce6f96\n    @author: wassname\n    \"\"\"\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return (1 - jac) * smooth\n\ndef DiceBCELoss(targets, inputs, smooth=1e-6):    \n       \n    #flatten label and prediction tensors\n    inputs = K.flatten(inputs)\n    targets = K.flatten(targets)\n    \n    BCE = 0.5# binary_crossentropy(targets, inputs)\n    #intersection = K.sum((targets * inputs))\n    intersection = K.sum(K.abs(targets * inputs), axis=-1)\n    dice_loss = 1 - (2*intersection + smooth) \/ (K.sum(targets) + K.sum(inputs) + smooth)\n    Dice_BCE = BCE + dice_loss\n    \n    return Dice_BCE","9eaeda25":"def unet(pretrained_weights = None, input_size = (256,256,1)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n    \n    model = Model(inputs = inputs, outputs = conv10)\n\n    model.compile(optimizer = optimizers.SGD(lr=1e-4, momentum=0.9), loss = jaccard_distance_loss, metrics = [iou_score, dice_coef])\n    \n    model.summary()\n\n    if(pretrained_weights):\n        model.load_weights(pretrained_weights)\n\n    return model\nmodel = unet()","395ff922":"#model_checkpoint = ModelCheckpoint('unet_m.hdf5', monitor='loss', verbose=1, save_best_only=True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 1, verbose = 1, min_delta=0.05, min_lr = 1e-8)\nmodel.fit(x, y, batch_size = 16 , epochs = 30, callbacks=[ModelCheckpoint('modelx.model', monitor='acc'), reduce_lr])","ea4fe97e":"to_predict = np.asarray([x[0], x[100], x[700]])\nout = model.predict(to_predict)","439368a4":"fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10,10))\n\nax[0, 0].imshow(to_predict[0,:,:,0], cmap='gray', vmin=0, vmax=1)\nax[0, 0].set_xticks([]), ax[0, 0].set_yticks([])\nax[0, 1].imshow(out[0,:,:,0], cmap='gray', vmin=0, vmax=1)\nax[0, 1].set_xticks([]), ax[0, 1].set_yticks([])\n\nax[1, 0].imshow(to_predict[1,:,:,0], cmap='gray', vmin=0, vmax=1)\nax[1, 0].set_xticks([]), ax[1, 0].set_yticks([])\nax[1, 1].imshow(out[1,:,:,0], cmap='gray', vmin=0, vmax=1)\nax[1, 1].set_xticks([]), ax[1, 1].set_yticks([])\n\nax[2, 0].imshow(to_predict[2,:,:,0], cmap='gray', vmin=0, vmax=1)\nax[2, 0].set_xticks([]), ax[2, 0].set_yticks([])\nax[2, 1].imshow(out[2,:,:,0], cmap='gray', vmin=0, vmax=1)\nax[2, 1].set_xticks([]), ax[2, 1].set_yticks([])\nplt.show()","083a2c93":"# Prediction","ffb0f7a0":"# Fit model","2696223c":"# Resizing images and masks to 256*256","328b517c":"# Limiting to 1000 images of cats only","c025f5e5":"# Reading Images and their Masks","b2c45656":"# Viewing images and their masks","677f07d8":"# Importing Animals Dataset","02efc1ee":"# Defining UNet"}}