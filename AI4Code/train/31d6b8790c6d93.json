{"cell_type":{"6e395bf5":"code","c4005d4d":"code","7024d0bb":"code","eb8011bf":"code","3227c65c":"code","65c2dc34":"code","6015358f":"code","f06985ff":"code","9b77f106":"code","3402fd7e":"code","f8318e59":"code","5b47143e":"code","e85b0a15":"code","979ddcf0":"code","b3706514":"code","d36e5180":"code","ec781eac":"code","792b4010":"code","8f50ecd1":"markdown","86775e9d":"markdown","545b9c5e":"markdown","1e4459b6":"markdown","38dd1238":"markdown","1ad01f5b":"markdown","1357d22f":"markdown","4fa1cc2e":"markdown","2c4b32d8":"markdown","d806c08d":"markdown","65455d8f":"markdown"},"source":{"6e395bf5":"import pandas as pd\nimport numpy as np\n\nimport lightgbm as lgb\nimport catboost as cbt\n\nimport random, os\nimport math\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom math import pi\n\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nfrom sklearn.model_selection import cross_val_score\nfrom pylab import rcParams\nrcParams['figure.figsize']=15,4\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nRANDOM_SEED = 42\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(RANDOM_SEED)","c4005d4d":"train=pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv')\ntest=pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')\nsample=pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\n\ntrain['date_time']=pd.to_datetime(train['date_time'])\ntest['date_time']=pd.to_datetime(test['date_time'])\n\ntrain=train.set_index('date_time')\ntest=test.set_index('date_time')\n\ntargets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\ntrain[targets] = np.log1p(train[targets])\n\ndf=pd.concat([train,test.iloc[1:]],axis=0,sort=False)","7024d0bb":"df['month']=df.index.month\ndf['weekday']=df.index.dayofweek\ndf['year']=df.index.year\ndf['hour']=df.index.hour","eb8011bf":"plt.figure(figsize=(16,20))\n\nplt.subplot(3,1,1)\ndf['sensor_4'].asfreq('H').plot()\nplt.minorticks_on()\nplt.grid(which='minor')\nplt.grid(which='major',linewidth=2)\nplt.title('sensor_4')\n\nplt.subplot(3,1,2)\ndf['sensor_2'].asfreq('H').plot()\nplt.minorticks_on()\nplt.grid(which='minor')\nplt.grid(which='major',linewidth=2)\nplt.title('sensor_2')\n\nplt.subplot(3,1,3)\ndf['absolute_humidity'].asfreq('H').plot()\nplt.minorticks_on()\nplt.grid(which='minor')\nplt.grid(which='major',linewidth=2)\nplt.title('absolute_humidity')","3227c65c":"scale=MinMaxScaler()\n\nplt.figure(figsize=(10,7))\nfor i in range(3):\n    a=df.groupby(['hour']).median()[targets[i]]\n    plt.plot(a.index,scale.fit_transform(a.values.reshape(-1,1)),label=targets[i])\nplt.legend(loc='lower right',prop={'size':15})\nplt.xlabel('hours')\nplt.show()","65c2dc34":"scale=MinMaxScaler()\n\nplt.figure(figsize=(10,7))\nfor i in range(3):\n    a=df.groupby(['weekday']).median()[targets[i]]\n    plt.plot(a.index,scale.fit_transform(a.values.reshape(-1,1)),label=targets[i])\nplt.legend(loc='lower left',prop={'size':15})\nplt.xlabel('Week Days')\nplt.show()","6015358f":"df['working_hour']=df['hour'].isin(np.arange(8,21,1)).astype('i')\ndf['is_weekend']=(df['weekday']>=5).astype('i')\ndf['sat']=(df.weekday==5).astype('i')\ndf['saturation_point']=df['absolute_humidity']*100\/df['relative_humidity']\ndf['is_odd']=((df['sensor_4']<646)&(df['absolute_humidity']<0.238)&(df['sensor_2']<426)).astype('i')\n\nq=np.arange(0,len(df),1)\n\ndf['sin']=np.sin(2*pi*q\/24)\ndf['sin1']=np.sin(2*pi*q\/(24*7))\ndf['sin2']=np.sin(2*pi*q\/(24*365))","f06985ff":"for i in train.drop(targets,axis=1).columns:\n        add=seasonal_decompose(df[i], model='additive', period = 24,two_sided=False)\n        add1=seasonal_decompose(df[i], model='additive', period = 24*7,two_sided=False)\n        data=pd.concat([add.resid,add.seasonal,add.trend],axis=1).fillna(0)\n        data.columns=[f'{i}_resid',f'{i}_seas',f'{i}_trend']\n        data1=pd.concat([add1.resid,add1.seasonal,add1.trend],axis=1).fillna(0)\n        data1.columns=[f'{i}_resid1',f'{i}_seas1',f'{i}_trend1']\n        df=pd.concat([df,data,data1],axis=1)\n#df.dropna(inplace=True,subset=df.columns.drop(targets))","9b77f106":"for i in targets:\n    ad=seasonal_decompose(train[i], model='additive', period = 24,two_sided=False)\n    df=pd.concat([df,ad.seasonal],axis=1)\n    dic=dict(df.groupby([df.hour]).mean()['seasonal'])\n    df[f'decompose_{i}']=df.hour.map(dic)\n    df.drop('seasonal',axis=1,inplace=True)\n    \n    ad=seasonal_decompose(train[i], model='additive', period = 24*7,two_sided=False)\n    df=pd.concat([df,ad.seasonal],axis=1)\n    plt.plot(train.index.dayofyear[:-1],ad.trend[:-1])\n    plt.minorticks_on()\n    plt.grid(which='minor')\n    plt.grid(which='major',linewidth=2)\n    plt.title(i)\n    plt.show()\n    \n    df[f'decompose1_{i}']=df[['weekday','hour']].apply(lambda x:df.groupby([df.weekday,df.hour]).mean()['seasonal'][x[0]][x[1]],axis=1)\n    df.drop('seasonal',axis=1,inplace=True)\ndf.drop('hour',axis=1,inplace=True)","3402fd7e":"df['range1']=((df.index.dayofyear>=90)&(df.index.dayofyear<200)).astype('i')\ndf['range2']=((df.index.dayofyear>=200)&(df.index.dayofyear<250)).astype('i')\ndf['range3']=((df.index.dayofyear>=250)&(df.index.dayofyear<290)).astype('i')\ndf['range4']=((df.index.dayofyear>=290)&(df.index.dayofyear<320)).astype('i')\ndf['range5']=((df.index.dayofyear>=320)&(df.index.dayofyear<345)).astype('i')\ndf['range6']=((df.index.dayofyear>=345)&(df.index.dayofyear<365)).astype('i')","f8318e59":"df_train= df.loc[train.index]\ndf_test=df.loc[test.index]","5b47143e":"rand_states = [2021, 1998, 42, 123]","e85b0a15":"print(f\"\\nTraining regressors for carbon monoxide\")\n\ntarget = 'target_carbon_monoxide'\n\ntargets.remove(target)\ndrop=[i for i in df_train.columns if ((targets[0] in i)|(targets[1] in i))]\ntargets.append(target)\n\ntrain=df_train.drop(drop,axis=1)\ntest=df_test.drop(drop,axis=1)\n    \nyhat = np.zeros((sample.shape[0],1))\n    \nfor rand in rand_states:\n    print(f\"\\nRandom state {rand} \")\n    seed_everything(rand)\n    \n    m_lgb = lgb.LGBMRegressor(seed = rand)\n    m_ctb = cbt.CatBoostRegressor(random_seed = rand, verbose=False)\n\n    stack = StackingCVRegressor(regressors=(m_lgb, m_ctb), meta_regressor = BayesianRidge(normalize = True))\n\n    regressors = ['LightGBM', 'CatBoost', 'StackingCVRegressor']\n\n    for clf, label in zip([m_lgb, m_ctb, stack], regressors):\n        \n        scores = cross_val_score(clf, train.drop(target, axis = 1), train[target], cv = 3, scoring='neg_mean_squared_error')\n        print(\"  - Neg. MSE Score: %0.4f (+\/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))\n\n    stack.fit(train.drop(target, axis = 1), train[target])\n        \n    yhat += np.expm1(stack.predict(test.drop(target, axis = 1))).reshape(-1, 1)\n        \nsample[target] = yhat \/ len(rand_states)","979ddcf0":"print(f\"\\nTraining regressors for Benzene\")\n\ntarget = 'target_benzene'\n\ntargets.remove(target)\ndrop=[i for i in df_train.columns if ((targets[0] in i)|(targets[1] in i))]\ntargets.append(target)\n\ntrain=df_train.drop(drop,axis=1)\ntest=df_test.drop(drop,axis=1)\n    \nyhat = np.zeros((sample.shape[0],1))\n    \nfor rand in rand_states:\n    print(f\"\\nRandom state {rand} \")\n    seed_everything(rand)\n    \n    m_lgb = lgb.LGBMRegressor(seed = rand)\n    m_ctb = cbt.CatBoostRegressor(random_seed = rand, verbose=False)\n\n    stack = StackingCVRegressor(regressors=(m_lgb, m_ctb), meta_regressor = BayesianRidge(normalize = True))\n\n    regressors = ['LightGBM', 'CatBoost', 'StackingCVRegressor']\n\n    for clf, label in zip([m_lgb, m_ctb, stack], regressors):\n        \n        scores = cross_val_score(clf, train.drop(target, axis = 1), train[target], cv = 3, scoring='neg_mean_squared_error')\n        print(\"  - Neg. MSE Score: %0.4f (+\/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))\n\n    stack.fit(train.drop(target, axis = 1), train[target])\n        \n    yhat += np.expm1(stack.predict(test.drop(target, axis = 1))).reshape(-1, 1)\n        \nsample[target] = yhat \/ len(rand_states)","b3706514":"print(f\"\\nTraining regressors for Nitrogen Oxide\")\n\ntarget = 'target_nitrogen_oxides'\n\ntargets.remove(target)\ndrop=[i for i in df_train.columns if ((targets[0] in i)|(targets[1] in i))]\ntargets.append(target)\n\ntrain=df_train.drop(drop,axis=1)[df_train.index.month>8]\ntest=df_test.drop(drop,axis=1)\n    \nyhat = np.zeros((sample.shape[0],1))\n    \nfor rand in rand_states:\n    print(f\"\\nRandom state {rand} \")\n    seed_everything(rand)\n    \n    m_lgb = lgb.LGBMRegressor(seed = rand)\n    m_ctb = cbt.CatBoostRegressor(random_seed = rand, verbose=False)\n\n    stack = StackingCVRegressor(regressors=(m_lgb, m_ctb), meta_regressor = BayesianRidge(normalize = True))\n\n    regressors = ['LightGBM', 'CatBoost', 'StackingCVRegressor']\n\n    for clf, label in zip([m_lgb, m_ctb, stack], regressors):\n        \n        scores = cross_val_score(clf, train.drop(target, axis = 1), train[target], cv = 3, scoring='neg_mean_squared_error')\n        print(\"  - Neg. MSE Score: %0.4f (+\/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))\n\n    stack.fit(train.drop(target, axis = 1), train[target])\n        \n    yhat += np.expm1(stack.predict(test.drop(target, axis = 1))).reshape(-1, 1)\n        \nsample[target] = yhat \/ len(rand_states)","d36e5180":"sample.iloc[0,1:]=np.expm1(df_train[targets].iloc[-1])","ec781eac":"sample.head()","792b4010":"sample.to_csv('submission.csv',index=False)","8f50ecd1":"## Benzene","86775e9d":"## Data Split","545b9c5e":"### Carbon Monoxide","1e4459b6":"- **From the above plots, some new features can be added as trend is different for different range of days**","38dd1238":"## Model Learning","1ad01f5b":"### Seasonal decomposition","1357d22f":"## Tabular Playground Series July 21\n**Objective** : Predicting the pollution level(benzene, nitrous oxide and carbon monoxide)\n\n**Dependent Variables** : target_carbon_monoxide, target_benzene, target_nitrogen_oxides\n\n**Independent Variables** : date_time, deg_C, relative_humidity, absolute_humidity,sensor_1, sensor_2, sensor_3, sensor_4, sensor_5","4fa1cc2e":"- **It is evident from the above plot that pollution levl is high during working hours, specially during office hours**","2c4b32d8":"## Nitrogen Oxide","d806c08d":"- **It is evident from the above plot that pollution level is high from monday(0) to friday(4) and lower in weekends**","65455d8f":"- **Abnormalities can be seen in the above 3 features as their are some sudden fall and rise of readings at some points which are almost same in value**"}}