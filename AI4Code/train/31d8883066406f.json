{"cell_type":{"43768c90":"code","8f9534a7":"code","35fa1d84":"code","d10dec8a":"code","1ba305f1":"code","f1dfbb46":"code","bd712c13":"code","e072910f":"code","970deab0":"code","88a9de03":"code","862dddd8":"code","87807842":"code","cfb82f55":"code","6c6a535d":"code","628d0818":"code","5e8b1f8f":"code","22c7e164":"code","232a8a68":"code","9c5eb3fe":"code","72afb46c":"code","11db0527":"code","a73c3e28":"code","45e93c96":"code","4c271726":"code","70679db0":"code","2b1a588a":"code","9976cab8":"code","5d4dcfed":"code","a62a93d5":"code","0bc280f5":"code","4e40ab5e":"code","bb855feb":"code","fc6a2f30":"code","c7665e5b":"code","5b4a205f":"code","05c8fc24":"code","e4d1a3f7":"code","91688d66":"code","95033e38":"code","1529e2f7":"code","9003802b":"code","b3d61ca1":"code","020db7da":"code","76f5ee6e":"code","81b922aa":"code","db4942ea":"code","b2151cf8":"code","5735fa28":"code","c119987a":"code","ea2b4682":"code","c967cb50":"code","f5dea0c7":"code","3d853a30":"code","45fb0366":"code","6a71871f":"code","5235f28f":"code","dd13b71f":"code","bf2ab7f7":"code","39bf1b0c":"markdown","cca8efb2":"markdown","55ad4af4":"markdown","993f527d":"markdown","914dd88d":"markdown","0332a88d":"markdown","020d6775":"markdown","2376282a":"markdown","5d2baa75":"markdown","45370ab4":"markdown","93dd64f6":"markdown","35589243":"markdown","777b6484":"markdown","3f71f70c":"markdown","c17452f5":"markdown","3d069003":"markdown","557d55f8":"markdown","aa551514":"markdown","6e95401a":"markdown","2d3fe9ce":"markdown","aeb64142":"markdown","7f11eb0f":"markdown","74b935bf":"markdown","5d365109":"markdown","2cb814d7":"markdown","1663554a":"markdown","3d815108":"markdown","365b9426":"markdown","0a278be1":"markdown","3231de0e":"markdown","0a728cdf":"markdown","d9e86c3d":"markdown","f42a5ab4":"markdown","1cebb2fb":"markdown","4e5bdda9":"markdown","106d711c":"markdown","0b0afbbb":"markdown"},"source":{"43768c90":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\npd.set_option('max_columns', 150)\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nkf = StratifiedKFold(n_splits=10)","8f9534a7":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')","35fa1d84":"train.shape, test.shape","d10dec8a":"train.head(10)","1ba305f1":"for col in train.columns[:-1]:\n    if train[col].isnull().any():\n        print('Column {0} has {1:.2f}% null values in train set.'.format(col, np.sum(train[col].isnull()) * 100 \/ train.shape[0]))\n    if test[col].isnull().any():\n        print('Column {0} has {1:.2f}% null values in test set.'.format(col, np.sum(test[col].isnull()) * 100 \/ test.shape[0]))","f1dfbb46":"one_value_column = [i for i in train.columns if train[i].nunique() == 1][0]\nprint(f'Column \"{one_value_column}\" has only one unique value in train set.')","bd712c13":"print('{0} columns in train set are binary.'.format(sum([1 for i in train.columns if train[i].nunique() == 2])))","e072910f":"idhogars = train.groupby(['idhogar']).agg({'Target': ['count', 'min', 'max']}).reset_index()\nidhogars[idhogars['Target']['min'] != idhogars['Target']['max']].head(20)","970deab0":"for i in idhogars[idhogars['Target']['min'] != idhogars['Target']['max']]['idhogar'].unique():\n    correct_value = train.loc[(train['idhogar'] == i) & (train['parentesco1'] == 1), 'Target'].values[0]\n    train.loc[train['idhogar'] == i, 'Target'] = correct_value","88a9de03":"sns.countplot(x=\"Target\", data=train);","862dddd8":"# Let's create a short train set which contains only one line per household for correct analysis and visualization of household features.\ntrain_short = train.drop_duplicates('idhogar')","87807842":"train_short.groupby('Target')['v2a1'].mean()","cfb82f55":"sns.boxplot(x=\"Target\", y=\"v2a1\", data=train_short);","6c6a535d":"print('Mean monthly rate for households with different sizes of household separately by poverty level.')\nsns.factorplot(x=\"tamhog\", y=\"v2a1\", col=\"Target\", data=train_short, kind=\"bar\");","628d0818":"print('Counts of households with different sizes of household separately by poverty level.')\nsns.factorplot(x=\"tamhog\", col=\"Target\", data=train_short, kind=\"count\");","5e8b1f8f":"print('Overcrowding rate by bedrooms and rooms.')\ntrain_short.groupby('tamhog').agg({'hacdor': 'mean', 'hacapo': 'mean'}).style.background_gradient(cmap='bwr', low=.5, high=0)","22c7e164":"train_short.groupby('tamhog').agg({'v14a': 'mean', 'refrig': 'mean', 'v18q': 'mean'})","232a8a68":"sns.boxplot(x='Target', y='escolari', data = train);\nplt.title('Years of schooling per household poverty level.')","9c5eb3fe":"def combine_features(data, cols=[], name=''):\n    df = data.copy()\n    for i, col in enumerate(cols):\n        print(i + 1, col)\n    df[cols] = df[cols].multiply([i for i in range(1, len(cols) + 1)], axis=1)\n    df[name] = df[cols].sum(axis=1)\n    df.drop(cols, axis=1, inplace=True)\n    return df","72afb46c":"train_new = combine_features(train, cols=[col for col in train.columns if col.startswith('pared')], name='wall')","11db0527":"print('Wall type count by target.');\nsns.factorplot(\"wall\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","a73c3e28":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('piso')], name='floor')\nprint('Floor type count by target.');\nsns.factorplot(\"floor\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","45e93c96":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('techo')], name='roof')\nprint('Roof type count by target.');\nsns.factorplot(\"roof\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","4c271726":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('abasta')], name='water')\nprint('Water provision type count by target.');\nsns.factorplot(\"water\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","70679db0":"train_new = combine_features(train_new, cols=['public', 'planpri', 'noelec', 'coopele'], name='electricity')\nprint('Electricity source type count by target.');\nsns.factorplot(\"electricity\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","2b1a588a":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('sanitario')], name='toilet')\nprint('Toilet connection type count by target.');\nsns.factorplot(\"toilet\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","9976cab8":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('energcocinar')], name='cooking')\nprint('Cooking sourse energy type count by target.');\nsns.factorplot(\"cooking\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","5d4dcfed":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('elimbasu')], name='rubbish')\nprint('Rubbish disposal type count by target.');\nsns.factorplot(\"rubbish\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","a62a93d5":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('epared')], name='wall_quality')\nprint('Wall quality type count by target.');\nsns.factorplot(\"wall_quality\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","0bc280f5":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('etecho')], name='roof_quality')\nprint('Roof quality type count by target.');\nsns.factorplot(\"roof_quality\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","4e40ab5e":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('eviv')], name='floor_quality')\nprint('Floor quality type count by target.');\nsns.factorplot(\"floor_quality\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","bb855feb":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('estadocivil')], name='family')\nprint('Family status count by target.');\nsns.factorplot(\"family\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","fc6a2f30":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('parentesco')], name='family_status')\ntrain_new['family_status'].value_counts().plot(kind='bar');\nplt.title('Family status count.');","c7665e5b":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('instlevel')], name='education')\nprint('Education level count by target.');\nsns.factorplot(\"education\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","5b4a205f":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('tipovivi')], name='home_own')\nprint('Home ownership type count by target.');\nsns.factorplot(\"home_own\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","05c8fc24":"train_new = combine_features(train_new, cols=[col for col in train_new.columns if col.startswith('lugar')], name='region')\nprint('Region count by target.');\nsns.factorplot(\"region\", col=\"Target\", col_wrap=4, data=train_new, kind=\"count\");","e4d1a3f7":"train['edjefe'].unique(),train['SQBedjefe'].unique()","91688d66":"print(train.loc[train.edjefe == 'yes', 'SQBedjefe'].unique())\nprint(train.loc[train.edjefe == 'no', 'SQBedjefe'].unique())","95033e38":"train['edjefe'] = train['edjefe'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))\ntrain_new['edjefe'] = train_new['edjefe'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))\n\n# fixing edjefa as well\ntrain['edjefa'] = train['edjefa'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))\ntrain_new['edjefa'] = train_new['edjefa'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))","1529e2f7":"train['dependency'].unique(),train['SQBdependency'].unique()","9003802b":"print(train.loc[train.dependency == 'yes', 'SQBdependency'].unique())\nprint(train.loc[train.dependency == 'no', 'SQBdependency'].unique())","b3d61ca1":"train['dependency'] = train['dependency'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else float(x)))\ntrain_new['dependency'] = train_new['dependency'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else float(x)))","020db7da":"for col in ['v2a1', 'v18q1', 'rez_esc', 'meaneduc', 'SQBmeaned']:\n    train[col] = train[col].fillna(0)\n    train_new[col] = train_new[col].fillna(0)","76f5ee6e":"def create_new_features(data, new=False):\n    data['v2a1'] = np.log1p(data['v2a1'])\n    data['rent_per_room'] = data['v2a1'] \/ data['rooms']\n    data['males_to_females'] = data['r4h3'] \/ data['r4m3']\n    data['persons_per_room'] = data['tamviv'] \/ data['rooms']\n    \n    data['bedrooms_to_rooms'] = data['bedrooms']\/data['rooms']\n    data['r4t3_to_tamhog'] = data['r4t3']\/data['tamhog']\n    data['r4t3_to_rooms'] = data['r4t3']\/data['rooms']\n    data['v2a1_to_r4t3'] = data['v2a1']\/data['r4t3']\n    data['v2a1_to_r4t3'] = data['v2a1']\/(data['r4t3'] - data['r4t1'])\n    data['hhsize_to_rooms'] = data['hhsize']\/data['rooms']\n    data['rent_to_hhsize'] = data['v2a1']\/data['hhsize']\n    \n    for col in ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin',\n       'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq', 'v2a1', 'meaneduc']:\n        data['idhogar_mean_' + col] = data.groupby('idhogar')[col].transform('mean')\n        data['idhogar_std_' + col] = data.groupby('idhogar')[col].transform('std')\n        data['idhogar_sum_' + col] = data.groupby('idhogar')[col].transform('sum')\n    \n    if new:\n        for col in ['wall', 'floor', 'roof', 'water', 'electricity', 'toilet', 'cooking', 'rubbish', 'wall_quality', 'roof_quality', 'floor_quality', 'family', 'family_status',\n                    'education', 'home_own', 'region']:\n            data[col + '_rent_mean'] = data.groupby(col)['v2a1'].transform('mean')\n    return data","81b922aa":"train = create_new_features(train)\ntrain_new = create_new_features(train_new, new=True)","db4942ea":"test_new = combine_features(test, cols=[col for col in test.columns if col.startswith('pared')], name='wall')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('piso')], name='floor')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('techo')], name='roof')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('abasta')], name='water')\ntest_new = combine_features(test_new, cols=['public', 'planpri', 'noelec', 'coopele'], name='electricity')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('sanitario')], name='toilet')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('energcocinar')], name='cooking')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('elimbasu')], name='rubbish')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('epared')], name='wall_quality')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('etecho')], name='roof_quality')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('eviv')], name='floor_quality')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('estadocivil')], name='family')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('parentesco')], name='family_status')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('instlevel')], name='education')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('tipovivi')], name='home_own')\ntest_new = combine_features(test_new, cols=[col for col in test_new.columns if col.startswith('lugar')], name='region')\ntest['edjefe'] = test['edjefe'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))\ntest_new['edjefe'] = test_new['edjefe'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))\ntest['dependency'] = test['dependency'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else float(x)))\ntest_new['dependency'] = test_new['dependency'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else float(x)))\n# fixing edjefa as well\ntest['edjefa'] = test['edjefa'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))\ntest_new['edjefa'] = test_new['edjefa'].apply(lambda x: 0 if x == 'no' else (1 if x == 'yes' else int(x)))\nfor col in ['v2a1', 'v18q1', 'rez_esc', 'meaneduc', 'SQBmeaned']:\n    test[col] = test[col].fillna(0)\n    test_new[col] = test_new[col].fillna(0)","b2151cf8":"test = create_new_features(test)\ntest_new = create_new_features(test_new, new=True)","5735fa28":"le.fit(list(train_new['idhogar'].values) + list(test_new['idhogar'].values))\ntrain['idhogar'] = le.transform(train['idhogar'])\ntrain_new['idhogar'] = le.transform(train_new['idhogar'])\ntest['idhogar'] = le.transform(test['idhogar'])\ntest_new['idhogar'] = le.transform(test_new['idhogar'])","c119987a":"X = train.drop(['Id', 'Target'], axis=1)\ny = train['Target']\nX_new = train_new.drop(['Id', 'Target'], axis=1)\ny_new = train_new['Target']","ea2b4682":"X_test = test.drop(['Id'], axis=1)\nX_test_new = test_new.drop(['Id'], axis=1)","c967cb50":"X_train, X_valid, y_train, y_valid = train_test_split(X, y - 1, test_size=0.10, random_state=42, stratify=y)\nparams = {\n    \n    'boosting_type': 'gbdt',\n    'objective': 'multiclass',\n    'metric': 'multi_logloss',\n    'max_depth': 5,\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 5,\n    'num_threads': 6,\n    'lambda_l2': 1.0,\n    'num_class': 4,}\nmodel = lgb.train(params, lgb.Dataset(X_train, y_train), 5000, [lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)], verbose_eval=500, early_stopping_rounds=50)","f5dea0c7":"lgb.plot_importance(model, max_num_features=30, figsize=(24, 18));","3d853a30":"X_train, X_valid, y_train, y_valid = train_test_split(X_new, y_new - 1, test_size=0.10, random_state=42, stratify=y_new)\nparams = {\n    'boosting': 'gbdt',\n    'application': 'multiclass',\n    'metric': 'multi_logloss',\n    'num_class': 4,\n    'learning_rate': 0.05,\n    'num_leaves': 7,\n    'max_depth': 3,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'scale_pos_weight': 2,\n    'reg_alpha': 1,\n    'reg_lambda': 1,\n    'num_threads': 6}\nmodel1 = lgb.train(params, lgb.Dataset(X_train, y_train), 5000, [lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)], verbose_eval=500, early_stopping_rounds=50)","45fb0366":"lgb.plot_importance(model1, max_num_features=30, figsize=(24, 18));","6a71871f":"%%time\n## predicting on folds\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'multiclass',\n    'metric': 'multi_logloss',\n    'max_depth': 5,\n    'num_leaves': 31,\n    'learning_rate': 0.01,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 5,\n    'verbose': -1,\n    'num_threads': 6,\n    'lambda_l2': 1.0,\n    'min_gain_to_split': 0,\n    'num_class': 4,}\nprediction = np.zeros((X_test.shape[0], 4))\nfor i, (train_i, test_i) in enumerate(kf.split(X, y)):\n    print(f'Fold {i}.')\n    X_train = X.values[train_i]\n    y_train = y.values[train_i] - 1\n    X_valid = X.values[test_i]\n    y_valid = y.values[test_i] - 1\n    model = lgb.train(params, lgb.Dataset(X_train, y_train), 5000, [lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)], verbose_eval=500, early_stopping_rounds=50)\n    pred = model.predict(X_test)\n    prediction += pred\n","5235f28f":"%%time\n## predicting on folds\nparams = {\n    'boosting': 'gbdt',\n    'application': 'multiclass',\n    'metric': 'multi_logloss',\n    'num_class': 4,\n    'learning_rate': 0.01,\n    'num_leaves': 9,\n    'max_depth': 128,\n    'feature_fraction': 0.7,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 5,\n    'scale_pos_weight': 2,\n    'reg_alpha': 1,\n    'reg_lambda': 1,\n    'num_threads': 6}\nprediction1 = np.zeros((X_test.shape[0], 4))\nfor i, (train_i, test_i) in enumerate(kf.split(X_new, y_new)):\n    print(f'Fold {i}.')\n    X_train = X_new.values[train_i]\n    y_train = y_new.values[train_i] - 1\n    X_valid = X_new.values[test_i]\n    y_valid = y_new.values[test_i] - 1\n    model = lgb.train(params, lgb.Dataset(X_train, y_train), 5000, [lgb.Dataset(X_train, y_train), lgb.Dataset(X_valid, y_valid)], verbose_eval=500, early_stopping_rounds=50)\n    pred = model.predict(X_test_new)\n    prediction1 += pred\n","dd13b71f":"full_prediction = np.argmax(prediction + prediction1, axis=1)","bf2ab7f7":"submission['Target'] = full_prediction + 1\nsubmission.to_csv('blend.csv', index=False)","39bf1b0c":"## Modelling","cca8efb2":"Almost all houses have toilets and refrigerators, but sadly most don't have tablets.","55ad4af4":"A lot of columns are binary, in fact you could say that there were several categorical features and they were one-hot encoded.","993f527d":"## Feature analysis\n\nLet's work with features. It is important to remember that some features show data for each individual and others show data for the whole household, so they have the same value for each individual in the household.","914dd88d":"Most of the rubbish is disposed using tanker truck.","0332a88d":"### Basic lgb","020d6775":"### v2a1\nMonthly rent payment.\n\nI suppose that empty values mean that family owns the house and therfore doesn't pay rent.","2376282a":"We can see that poor households indeed can only afford lower rents than non vulnerable households.","5d2baa75":"And most of people live in Central region.","45370ab4":"# Costa Rican Household Poverty Level Prediction\n## General information\n\nThis kernel is dedicated to extensive EDA of Costa Rican Household Poverty Level Prediction competition as well as feature engineering and modelling.","93dd64f6":"## Data overview","35589243":"Test dataset is several times bigger than train dataset.","777b6484":"edjefe -  years of education of male head of household;\n\nSQBedjefe, edjefe squared","3f71f70c":"### Feature engineering","c17452f5":"## Combining ohe-hot enoded columns\nSeveral columns were one-hot encoded and separated into separate columns. While some machine learning models will enjoy it, some others won't. And it is easier to visualize a single column. ","3d069003":"ddddTo be continued","557d55f8":"This is quite interesting:\n- Usually there is no more than 8 people in families, which rent. There are a couple of exceptions though;\n- Non vulnerable households usually pay a comparable amount of rent and it almost doesn't depent of household size. But there are several families of 8 people with vastly different rent;\n- On average households with poverty pay twice less rent, as they can't afford better places;","aa551514":"Now all households have a single value for target. We can see that most of the rows in train set have target 4, so this is imbalanced classification problem.","6e95401a":"## Floor material","2d3fe9ce":"It seems that 'no' in edjefe is 0 in SQBedjefe and 'yes' is 1.","aeb64142":"Most walls are made from bricks\/blocks or cement. But poor households sometimes leave in wooden houses.","7f11eb0f":"Most of the households own houses, as we could saw from rent payment amount.","74b935bf":"### Fixing target\nYou can see in [this](https:\/\/www.kaggle.com\/c\/costa-rican-household-poverty-prediction\/discussion\/61403#358941) discussion that some targets of individual rows could be wrong, let's correct them.","5d365109":"### Filling missing values\n\nThere are five columns with missing values and in all of them missing value can mean absence of the feature, so filling them with zeroes.","2cb814d7":"We can see that people in non vulnerable households have better education. It is a question which comes the first: is it more difficult to get better education for poor people or does lower education cause poverty?","1663554a":"Overfitting is huge, so let's try averaging.","3d815108":"Wow, most households have electricity from private plants!","365b9426":"### Calculated columns\nThere are some calculated columns and they can be useful in cases when original columns don't have all values. Let's see.","0a278be1":"There are 5 columns with missing values and three of them lack 70%+ data","3231de0e":"## Household quality","0a728cdf":"It is quite reasonable that the bigger the household size, the higher is the overcrowding rate.","d9e86c3d":"Now I have two paired sets of data - I'll use both of them and see which is better. Let's prepare data for prediction.","f42a5ab4":"The same for dependency.","1cebb2fb":"Most of non vulnurable households have good houses, but more than a third have regular quality. Poor houselds tend to have houses with problems.","4e5bdda9":"Most of the toilets are connected to septic tanks.","106d711c":"Most households have water provision inside their dwellings.","0b0afbbb":"Most use electricity or gas."}}