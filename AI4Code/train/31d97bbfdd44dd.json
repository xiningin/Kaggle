{"cell_type":{"df3cadb5":"code","2303a030":"code","21c9d9cd":"code","547576c7":"code","09dbbedd":"code","af2ae181":"code","ed3403f5":"markdown","e7edc503":"markdown","c3a02ff1":"markdown","0e7539c7":"markdown","4ff7e6f4":"markdown","9f34af4b":"markdown","cc8e1562":"markdown","44a0d0f3":"markdown","f308b0df":"markdown","df7d9d74":"markdown"},"source":{"df3cadb5":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom keras.utils.np_utils import to_categorical \nfrom keras.preprocessing.image import ImageDataGenerator","2303a030":"#Training data\ntrain_data = pd.read_csv('..\/input\/train.csv') # Import the dataset\ntrain_y = train_data[\"label\"] # Create label vector\ntrain_data.drop([\"label\"], axis=1, inplace=True) # Remove the label vector from the pixel column matrix\ntrain_X = train_data\ntrain_X = train_X.values.reshape(-1, 28, 28, 1)\ntrain_y = train_y.values\ntrain_y = to_categorical(train_y)\ntrain_X = train_X\/255.00 # Normalization\n#Test data\ntest_X = pd.read_csv('..\/input\/test.csv')\ntest_X = test_X.values.reshape(-1,28,28,1)\ntest_X = test_X \/ 255.0 # Normalization","21c9d9cd":"model = tf.keras.Sequential([\ntf.keras.layers.Conv2D(32, kernel_size = (5,5), padding = 'same', activation ='relu', input_shape = (28,28,1)),\ntf.keras.layers.Conv2D(32, kernel_size = (5,5), padding = 'same', activation ='relu'),\ntf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2), \ntf.keras.layers.Dropout(0.2),\ntf.keras.layers.Flatten(),\ntf.keras.layers.Dense(512, activation = \"relu\"),\ntf.keras.layers.Dense(10, activation = \"softmax\")\n])","547576c7":"model.summary()\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])","09dbbedd":"datagen = ImageDataGenerator(rotation_range=5, zoom_range=0.09) # try  \ndatagen.fit(train_X)\nbatch =512\nmodel.fit_generator(datagen.flow(train_X, train_y, batch_size=batch), epochs=45)","af2ae181":"predictions = model.predict(test_X)\npredictions[354]\npred = np.argmax(predictions, axis=1)\n\nplt.imshow(test_X[354][:,:,0],cmap='gray')\nplt.show()\n\npred[354]\n\npred_digits = pd.DataFrame({'ImageId': range(1,len(test_X)+1) ,'Label':pred })\npred_digits.to_csv(\"pre_digits.csv\",index=False)\npred_digits.head()","ed3403f5":"TABLE OF CONTENTS\n0. OVERVIEW\n1. IMPORT LIBRARIES\n2. DATA PRE-PROCESSING\n3. CNN MODEL\n4. PREDICTING RESULTS\n5. CONCLUSIONS","e7edc503":"# 0. OVERVIEW\nThe training dataset is a csv-file with 785 columns: 1 label column and 784 pixel columns. The csv file is made of images, which are 28 pixels x 28 pixels, so each image includes in total 784 different pixels. Each column represents the individual pixel value. The pixel value contain data on the exact intensity of the gray scale color between 0 to 255.  Each row on the csv-file represents a single image. The testing dataset is similar to the training, but without the label of correct digit. \n\nThe objective is to correctly classify labels of the testing dataset. To achieve our objective, we will create Convolutional Neural Network with the Tensorflow - to classify images of digits into specific class. Prior to creating the Tensorflow CNN, we will import libraries required and the dataset. The star of this notebook is the Convolutional Neural Network, which you can read details in [my Medium profile.](https:\/\/medium.com\/@tmmtt) The conclusions section will discuss in detail, the potential further improvements, based the metrics applied.\n\n**Data augmentation**\nIn this notebook, we turned into data augmentation. There is a useful information, which offers details of further ways to apply data augmentation with [Keras ImageDataGenerator class.](https:\/\/keras.io\/preprocessing\/image\/)","c3a02ff1":"# 4. PREDICTING RESULTS\nNow, we will print the model summary, compile the model with Adam-optimizer.\nFinally, let's apply augmented data and fit the data.","0e7539c7":"# 3. CNN MODEL\nOur tensorflow model consist:\n* Two CNN layers, Maxpooling, dropout, Flatten, Dense, Output layer","4ff7e6f4":"# Tensorflow Convolutional Neural Network: Digit Recognizer\n> According to [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Handwriting), the handwriting is characterized by factors such as: shape of letters, spacing between letters, slope of letters, arrhythmia, pressure applied and size\/thickness of the letters.","9f34af4b":"# 5. CONCLUSIONS\n\nThere is massive amount of Kagglers with super accurately performing classifiers. If we look at the leaderboard: there are hundreds of users, who are capable of reaching close to human level performance. So, there arises the question, if we are able to classify 100% accurately in the future?\n\nThere appears certainly lot of research papers, which Kagglers are familiar. Further, the transfer learning is a great example, how we can improve our model performance. Within time, we will as well be able to put even more computer resources, to calculate even more complex networks.\n\nHowever, it seems still early to say, that we are certainly going to reach the 100% accuracy. To efficiently overcome this challenge, we will need to share more about best practices, which help objectively to tune any model, to a better one. \n\nFor example, it is interesting to read - lot of notebooks offer really high accuracy, but relatively less offer ideas: How their models could be further improved? Here, it is obvious - the importance of a good metric. We see lot of notebooks, where the analysis of wrong results is left out completely. There needs to be a clear metric, which allows us to know: are we moving to right direction. But beside knowing what was right or wrong: the next step is to analyze the concrete errors made by the model. \n\nThe data augmentation is a great point of analysis. The possibility of adding data is great: few lines of extra code for data augmentation gives significant boost to our model accuracy. However, it leaves us to wonder: Is there still major room for further improvements by adding further data augmentation methods? Is there a greater chance to improve our model by making our CNN more complex or making our dataset more complex? \n\n\n\n\n\n\n","cc8e1562":"# 1. IMPORT LIBRARIES\nLet's start by importing the required Python libraries. We will use general purpose data handling libraries: numpy, pandas and matplotplip for plotting. The Tensorflow and Keras libraries are used for building the CNN-moodel and data augmentation.","44a0d0f3":"Data augmentation\nA useful site, where we can learn more about Data augmentation using Keras [ImageDataGenerator().](https:\/\/blog.keras.io\/building-powerful-image-classification-models-using-very-little-data.html)","f308b0df":"Our results","df7d9d74":"# 2. DATA PRE-PROCESSING\nTo apply the Convolutional Neural Network, we wil import the csv-data using pandas read_csv. We will split the correct labels"}}