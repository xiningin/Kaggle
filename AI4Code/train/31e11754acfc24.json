{"cell_type":{"bc450af7":"code","7264f584":"code","f35c5785":"code","db696bf8":"code","e290ae0a":"code","0dfdca93":"code","13f8c5f5":"code","81f083c3":"code","2536f44d":"code","93287c29":"code","20a40e31":"code","2b827c55":"code","237f11a2":"code","6935d76f":"code","f8408d05":"code","f1da42e3":"code","1b298cac":"code","731fb524":"code","5d9c5ad1":"code","b5e974de":"code","d1339662":"code","e062c679":"code","306c3695":"code","eeb43a61":"code","b4970a01":"code","219ab529":"code","03556543":"code","11fa4798":"code","5daa2834":"code","cbb91c7e":"code","650211b8":"code","d75512d0":"code","8a8b17fe":"code","489ffeac":"code","78fafc29":"code","35af82f9":"code","69385297":"code","d75c3f2e":"code","093ea35f":"code","978801b2":"code","0ceb41bf":"markdown","2aadd001":"markdown","68ac544e":"markdown","b85ff9f1":"markdown","1711400e":"markdown","04b78d20":"markdown"},"source":{"bc450af7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7264f584":"df=pd.read_csv('..\/input\/fake-news\/train.csv')\ndf.head()","f35c5785":"###Drop Nan Values\ndf=df.dropna()","db696bf8":"## Get the Independent Features\nX=df.drop('label',axis=1)\n\n## Get the Dependent features\ny=df['label']\n\nprint(X.shape)\nprint(y.shape)","e290ae0a":"import tensorflow as tf\ntf.__version__","0dfdca93":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","13f8c5f5":"### Vocabulary size\nvoc_size=5000","81f083c3":"messages=X.copy()\n\nprint(messages.head(1))","2536f44d":"print(messages['title'][1])","93287c29":"#as we have droped the nan values so we have deleted the index sequence\nmessages.reset_index(inplace=True)","20a40e31":"import nltk\nimport re  #Regular expressions\nfrom nltk.corpus import stopwords","2b827c55":"nltk.download('stopwords')","237f11a2":"### Dataset Preprocessing\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []","6935d76f":"for i in range(0, len(messages)):\n    #print('\\n', messages['title'][i])\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])# ^ means except #remove all things except [^a-zA-Z]\n    #print('\\n', review)\n    review = review.lower() # make all words in lower case\n    #print('\\n', review)\n    review = review.split() # split all words\n    #print('\\n', review)\n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')] # looking each word and remove stopWords\n    #print('\\n', review)\n    review = ' '.join(review) # join all words with space\n    #print('\\n', review)\n    corpus.append(review) # append the whole line one by one\n    #break","f8408d05":"corpus[4]","f1da42e3":"#converting the all words into oneHot\nonehot_repr=[one_hot(words,voc_size)for words in corpus] \nprint(onehot_repr[0])\nprint('\\n',len(onehot_repr))","1b298cac":"sent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","731fb524":"embedded_docs[0]","5d9c5ad1":"## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","b5e974de":"len(embedded_docs),y.shape","d1339662":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","e062c679":"X_final.shape,y_final.shape","306c3695":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","eeb43a61":"### Finally Training\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","b4970a01":"from tensorflow.keras.layers import Dropout\n## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(500))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","219ab529":"### Finally Training again\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=64)","03556543":"### Finally Training again\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","11fa4798":"# test_data = pd.read_csv('..\/input\/fake-news\/test.csv')","5daa2834":"# test_data.head()","cbb91c7e":"# test_data.isnull().sum()","650211b8":"# test_data.dropna(axis=0, inplace=True)","d75512d0":"# test_data.reset_index(inplace=True)","8a8b17fe":"# test_data['title'].head(15)","489ffeac":"# #test data preprocessing\n# corpus = []\n# for i in range(0, len(test_data)):\n#     review = re.sub('[^a-zA-Z]', ' ', test_data['title'][i])\n#     review = review.lower()\n#     review = review.split()\n    \n#     review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n#     review = ' '.join(review)\n#     corpus.append(review)","78fafc29":"# corpus[0]","35af82f9":"# onehot_repr=[one_hot(words,voc_size)for words in corpus] \n# onehot_repr[0]","69385297":"# sent_length=20\n# test=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n# print(embedded_docs)","d75c3f2e":"# y_pred=model.predict_classes(test)","093ea35f":"from sklearn.metrics import confusion_matrix","978801b2":"y_pred","0ceb41bf":"### Performance Metrics And Accuracy","2aadd001":"### Model Training","68ac544e":"** Tensorflow version is greater than 2.0 ** keras in inbuit in this version of tensorflow ","b85ff9f1":"### Onehot Representation","1711400e":"### Embedding Representation","04b78d20":"### Adding Dropout "}}