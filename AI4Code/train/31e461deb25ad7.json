{"cell_type":{"11070b4f":"code","590ad502":"code","83c2d996":"code","29ff6ae4":"code","7d321f4a":"code","7ec426bf":"code","e95506a8":"code","add22231":"code","e6ac3750":"markdown","f52ed208":"markdown","583c0150":"markdown","3d41581f":"markdown","2b2fd464":"markdown","23b5d9c5":"markdown","082dbc9f":"markdown","8490d6dc":"markdown","c5993f60":"markdown","480d882b":"markdown","53f4bb13":"markdown","ded252aa":"markdown","1a5900c4":"markdown","798c088b":"markdown","bee30fc5":"markdown"},"source":{"11070b4f":"import json\nimport pandas as pd\nimport numpy as np","590ad502":"#Read Line Delimited JSON files\ncontents = open('data.ldjson', \"r\").read()\ncontents = contents.encode('utf-8')\ncontents = contents.decode('ascii','replace').replace('\ufffd',\"\")\ncontents = contents.replace('}{\"uniq_id\"','}\\n{\"uniq_id\"')\ncontents = contents.strip().split(\"}\\n\")\nkeys = [\"uniq_id\",\"crawl_timestamp\",\"url\",\"job_title\",\"company_name\",\"city\",\"state\",\"country\",\"post_date\",\"job_description\",\"job_requirements\",\"job_type\",\"job_board\",\"geo\",\"site_name\",\"domain\",\"postdate_yyyymmdd\",\"has_expired\",\"last_expiry_check_date\",\"postdate_in_indexname_format\",\"inferred_city\",\"inferred_state\",\"inferred_country\",\"fitness_score\",\"category\",\"company_description\",\"salary_offered\",\"contact_person\",\"contact_email\",\"contact_phone_number\"]\ndata = dict()\nfor i in range(len(contents)):\n  line = contents[i]\n  line = line.replace('}','')\n  line = line.replace('{','')\n  line = line.strip()\n  line = '{'+line+'}'\n  content = json.loads(line)\n  for key in keys:\n\t  if key in data.keys():\n\t\t  if key in content.keys():\n\t\t\t    data[key].append(content[key])\n\t\t  else:\n\t\t\t    data[key].append(None)\n\t  else:\n\t\t    if key in content.keys():\n\t\t\t\t   data[key] = [content[key]]\n\t\t    else:\n\t\t\t\t   data[key] = [None]\n\ndf = pd.DataFrame(data)","83c2d996":"#Defining a unique function to get a unique list\ndef unique(list1):\n  unique_list = []\n  for x in list1:\n    if x not in unique_list:\n      unique_list.append(x)\n  return unique_list","29ff6ae4":"#Fixing Locations\npd.set_option('mode.chained_assignment', None)\ncities = pd.read_csv('list_of_cities_and_towns_in_india-834j.csv')\nfor index2 in cities.index:\n\tcity = cities.iloc[index2,1]\n\tstate = cities.iloc[index2,2]\n\tcountry = \"IN\"\n\tif not str(city) == 'nan' and not str(state) == 'nan':\n\t\tdf['city'].loc[df['city'].str.contains(city,case=False,regex=False,na=False)] = city\n\t\tdf['state'].loc[df['city'].str.contains(city,case=False,regex=False,na=False)] = state\n\t\tdf['country'].loc[df['city'].str.contains(city,case=False,regex=False,na=False)] = country\n\t\tdf['city'].loc[df['country'].str.contains(city,case=False,regex=False,na=False)] = city\n\t\tdf['state'].loc[df['country'].str.contains(city,case=False,regex=False,na=False)] = state\n\t\tdf['country'].loc[df['country'].str.contains(city,case=False,regex=False,na=False)] = country\ndf['country'].loc[df['country']=='India'] = \"IN\"","7d321f4a":"#Finding out the right data points for filter\nmatch1 = df['job_description'].str.contains('Customer Care', case = False, regex = False, na = False)\nmatch2 = df['job_description'].str.contains('Voice Process', case = False, regex = False, na = False)\nmatch3 = df['job_description'].str.contains('Customer Service', case = False, regex = False, na = False)\nmatch4 = df['job_description'].str.contains('Tech Support', case = False, regex = False, na = False)\nmatch_final = []\nfor i in range(len(match1)):\n  if match1[i] == True or match2[i] == True or match3[i] == True or match4[i] == True:\n    match_final.append(True)\n  else:\n    match_final.append(False)","7ec426bf":"#Filtering the Data Frame\nmatch_final = pd.Series(match_final, index = range(len(match_final)))\ndf2 = df.loc[match_final,:]\ndf2.index = range(len(df2))","e95506a8":"#Fixing Eperience Range and finding out unqiue set of skills\ndf2['Min_Year_Req'] = None\ndf2['Max_Year_Req'] = None\nskills = []\nfor index1, row  in df2.iterrows():\n skill = ''\n if not str(row['job_requirements']) == 'nan' and not str(row['job_requirements']) == 'None':\n  req_split = (row['job_requirements'].split(\"|\"))\n  if len(req_split) > 1:\n    exp_split = req_split[0]\n    skill_split = req_split[1]\n    if len(exp_split) < 30:\n      exp_split = exp_split.replace(\" years\", \"\")\n      exp_split = exp_split.split(\"-\")\n      df2.iloc[index1,30] = int(exp_split[0].strip())\n      df2.iloc[index1,31] = int(exp_split[1].strip())\n    if len(skill_split) < 3000:\n      skill_split = skill_split.lower().strip().replace(\"keywords \/ skills : \",\"\")\n      skill_split = skill_split.split(',')\n      if isinstance(skill_split,list):\n        if len(skill_split) > 1:\n          for k in range(len(skill_split)):\n            if len(skill_split[k]) < 50:\n              skill = skill_split[k].strip().replace('\"','').replace(\"'\",'')\n              skills.append(skill)\n        else:\n            if len(skill_split[0]) < 50:\n              skill = skill_split[0].strip().replace('\"','').replace(\"'\",'')\n              skills.append(skill)\n      elif isintance(skills_split,str):\n        if len(skill_split) < 50:\n          skill = skill_split.strip().replace('\"','').replace(\"'\",'')\n          skills.append(skill)\n  else:\n    req_split = req_split[0]\n    exp_check = False\n    if len(req_split) < 30:\n       exp_split = req_split\n       if exp_split.find('years') > -1:\n        exp_check = True\n       else:\n        exp_check = False\n    else:\n      exp_check = False\n\n    if exp_check:  \n      exp_split = exp_split.replace(\" years\", \"\")\n      exp_split = exp_split.split(\"-\")\n      df2.iloc[index1,30] = int(exp_split[0].strip())\n      df2.iloc[index1,31] = int(exp_split[1].strip())\n    else:\n       skill_split = req_split[0]\n       skill_split = skill_split.lower().strip().replace(\"keywords \/ skills : \",\"\")\n       skill_split = skill_split.split(',')\n       if isinstance(skill_split,list):\n        if len(skill_split) > 1:\n          for k in range(len(skill_split)):\n            if len(skill_split[k]) < 50:\n              skill = skill_split[k].strip().replace('\"','').replace(\"'\",'')\n              skills.append(skill)\n        else:\n          if len(skill_split[0]) < 50:\n            skill = skill_split[0].strip().replace('\"','').replace(\"'\",'')\n            skills.append(skill)\n       elif isinstance(skill_split,str):\n         if len(skill_split) < 50:\n            skill = skill_split.strip().replace('\"','').replace(\"'\",'')\n            skills.append(skill)\nskills = unique(skills)","add22231":"for skill in skills:\n  df2[skill] = 0\n  df2[skill].loc[df2['job_requirements'].str.contains(skill,case=False,regex=False,na=False)] = 1\n    \n#This will take a lot of time in case the Skills list is not cleaned properly.","e6ac3750":"* I am planning on making a predictive model taking Experience years requirement, Location, and Employer, and Job Type(Sales, Non sales, Tech support etc.) to predict the skills required for that particular job. (For HR orgs or Employees to easily create better JDs in the future).\n* Again predicting skills for people searching for a particular Job. Based on this person's experience, and job type saught after, we can predict the skills required for this particular Job.\n* Compensation Offered details are not mentioned too well in the data, so in case that ever gets better, a new model can be created for Emplyers to provide better compensation based on experience and skills of an aspirant. Also, similar model for aspirants to check out what is the current compensation being offered for the role that they aspire for in the market. ","f52ed208":"# Imports","583c0150":"# Future Plans\n","3d41581f":"And this is where I give up on this current data. The skills cleaning part was taking too much time doing it on my own, and it is an important part for what I was planning. \nI will be listing down the ideas that I had for this data. ","2b2fd464":"Now, creating a binary variable for all skills and the corresponding Job listings","23b5d9c5":"# Data Cleaning","082dbc9f":"# Json to Data Frame conversion","8490d6dc":"I will be creating a list of the keys that are present in the json outputs. I had to go through it multiple times and finally got the below mentioned Keys list.","c5993f60":"I will be focusing the analysis on Customer Support or Tech Support Jobs","480d882b":"I couldn't find a unique function in lists similar to Pandas Series, so created one (Not the best approach. Meh! it'll work)","53f4bb13":"I might not be requiring the Country column in the data as a major part of the data is from India. \nI am just cleaning it for good measure.","ded252aa":"I took only 4 filters for convenience sake. We can draw out many more. ","1a5900c4":"When I read the Data, I saw the country column is not that well defined. Hence, it will also require some cleaning. I have downloaded a third party database with the names of the cities\/towns in India with their corresponding states. I will be using this to clean up the location columns.","798c088b":"If the length of the skills list is too large, you might want to print out the list and try to remove a few values. I saw a few comapny names also popping up as skils (-__-)' . This data might require a lot more cleaning before it can be made AI\/ML friendly.","bee30fc5":"I tried appending a large data frames with small data frames being created dynamically but that method was too slow. So now, I am creating a big dictionary with all data items as list inputs, and using this to create our Data Frame."}}