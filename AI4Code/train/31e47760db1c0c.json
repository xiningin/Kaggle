{"cell_type":{"306d1d94":"code","e6cec8f9":"code","f963e4cf":"code","2498ef27":"code","3dc35079":"code","577cae89":"code","71ca8c04":"code","fba8fa4b":"code","b9781085":"code","5d129b29":"code","abbb0f86":"code","b214704e":"code","50adf596":"code","f09de6e4":"code","0f19fee0":"code","bfe96bcd":"code","4fa626ec":"code","4f4c2073":"code","81aa750f":"code","2f2aa107":"code","b9984f79":"code","7c460e6c":"code","67e06d10":"code","258a4d35":"code","cc793e45":"code","ce70325e":"code","76b04187":"code","f63bceca":"code","6573d034":"code","ee14ab95":"code","dadae36d":"code","21ccadba":"code","f7f55749":"code","af7336e6":"code","31d3adf9":"code","d3708de0":"code","b12b5de8":"code","dd0be9de":"code","d138acbd":"code","31d87d7d":"code","103f4765":"code","c59363ad":"code","ae6d67e1":"code","338a8868":"code","ac8cc6cb":"code","e449eb80":"code","e30c7932":"code","1cd00e9d":"code","83d91176":"code","6e45fb38":"code","cc805854":"code","51f9e5e8":"code","fb44daee":"code","8f4e3396":"code","a0021eff":"code","ba86742c":"code","fcd145ca":"code","a23ed4da":"code","549da39a":"markdown","abf68163":"markdown","75d3bc5d":"markdown","20094df5":"markdown","be90c163":"markdown","897099c7":"markdown","fd376606":"markdown","b9c657c3":"markdown","e9fb6b5e":"markdown","30f2c5df":"markdown","cd3d743d":"markdown","8e2d634b":"markdown","eb4bf68b":"markdown","a9b437f1":"markdown","9b8b5070":"markdown","72d893a8":"markdown","171a7908":"markdown","39e18530":"markdown","acd2ff2b":"markdown","a57bab46":"markdown","7ee3c616":"markdown","3fae1b11":"markdown","8f07a32a":"markdown","dc6ef42f":"markdown","c97389d5":"markdown","78faaf6f":"markdown","ec7c16c5":"markdown","89a07ae7":"markdown"},"source":{"306d1d94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e6cec8f9":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","f963e4cf":"aisles = pd.read_csv('..\/input\/instacart-market-basket-analysis\/aisles.csv')\ndepartments = pd.read_csv('..\/input\/instacart-market-basket-analysis\/departments.csv')\norder_prd_p = pd.read_csv('..\/input\/instacart-market-basket-analysis\/order_products__prior.csv')\norder_prd_t = pd.read_csv('..\/input\/instacart-market-basket-analysis\/order_products__train.csv')\norders = pd.read_csv('..\/input\/instacart-market-basket-analysis\/orders.csv')\nproducts = pd.read_csv('..\/input\/instacart-market-basket-analysis\/products.csv')","2498ef27":"orders","3dc35079":"orders.info(), orders.describe()","577cae89":"order_prd_p","71ca8c04":"order_prd_p.info(), order_prd_p.describe()","fba8fa4b":"order_prd_t","b9781085":"order_prd_t.info(), order_prd_t.describe()","5d129b29":"products","abbb0f86":"aisles","b214704e":"departments","50adf596":"cnt_srs = orders.eval_set.value_counts()\n\nplt.figure(figsize = (12,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize =12)\nplt.xlabel('Eval set type', fontsize=12)\nplt.title('count of Rows in eval set type', fontsize =15)\nplt.show()","f09de6e4":"def get_unique_count(x):\n    return len(np.unique(x))\n\ncnt_srs = orders.groupby('eval_set')['user_id'].aggregate(get_unique_count)\ncnt_srs","0f19fee0":"cnt_srs = orders.groupby('user_id')['order_number'].aggregate(np.max).reset_index()\ncnt_srs = cnt_srs.order_number.value_counts()\n\nplt.figure(figsize = (12,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha = 0.8)\nplt.ylabel('Number of Occurrences', fontsize =12)\nplt.xlabel('Maximum order number', fontsize=12)\nplt.title('count of Rows in order number', fontsize =15)\nplt.xticks(rotation = 'vertical')\nplt.show()","bfe96bcd":"plt.figure(figsize = (12,8))\nsns.countplot(x = 'order_dow', data = orders)\nplt.ylabel('Count', fontsize =12)\nplt.xlabel('Day of week', fontsize=12)\nplt.title('Frequency of order by week day', fontsize =15)\nplt.show()","4fa626ec":"plt.figure(figsize = (12,8))\nsns.countplot(x = 'order_hour_of_day', data = orders)\nplt.ylabel('Count', fontsize =12)\nplt.xlabel('Hour of day', fontsize=12)\nplt.title('Frequency of order by hour of day', fontsize =15)\nplt.show()","4f4c2073":"grouped = orders.groupby(['order_dow', 'order_hour_of_day'])['order_number'].aggregate('count').reset_index()\ngrouped = grouped.pivot('order_dow','order_hour_of_day', 'order_number' )\n\nplt.figure(figsize = (12,8))\nsns.heatmap(grouped)\nplt.ylabel('oder_dow', fontsize =12)\nplt.xlabel('Hour of day', fontsize=12)\nplt.title('Frequency of Day of week AND Hour of day', fontsize =15)\nplt.show()","81aa750f":"plt.figure(figsize = (12,8))\nsns.countplot(x = 'days_since_prior_order', data = orders)\nplt.ylabel('Count', fontsize =12)\nplt.xlabel('Days since prior order', fontsize=12)\nplt.title('Frequency distribution by days since prior order', fontsize =15)\nplt.show()","2f2aa107":"# percentage of re-orders in prior set\n\norder_prd_p.reordered.sum() \/ order_prd_p.shape[0]","b9984f79":"# percentage of re-orders in prior set\n\norder_prd_t.reordered.sum() \/ order_prd_t.shape[0]","7c460e6c":"## It takes too much RAM\n# total = pd.merge(orders, order_prd_p, on = 'order_id', how='left')\n# total = pd.merge(total, order_prd_t, on = 'order_id', how='left')\n\n# total.fillna(0)  # there are NAN values where prior table has no values of train table. And vise versa.","67e06d10":"order_prd_p = pd.merge(order_prd_p, products, on = 'product_id', how='left')\norder_prd_p = pd.merge(order_prd_p, aisles, on = 'aisle_id', how='left')\norder_prd_p = pd.merge(order_prd_p, departments, on = 'department_id', how='left')\norder_prd_p = pd.merge(order_prd_p, orders, on = 'order_id', how='left')\n\norder_prd_p","258a4d35":"order_prd_t = pd.merge(order_prd_t, products, on = 'product_id', how='left')\norder_prd_t = pd.merge(order_prd_t, aisles, on = 'aisle_id', how='left')\norder_prd_t = pd.merge(order_prd_t, departments, on = 'department_id', how='left')\norder_prd_t = pd.merge(order_prd_t, orders, on = 'order_id', how='left')\n\norder_prd_t","cc793e45":"print(order_prd_p.eval_set.unique(), order_prd_p.reordered.unique())","ce70325e":"print(order_prd_t.eval_set.unique(), order_prd_t.reordered.unique())","76b04187":"grouped = order_prd_t.groupby('order_id')['add_to_cart_order'].aggregate('max').reset_index()\ncnt_srs = grouped.add_to_cart_order.value_counts()\n\nplt.figure(figsize = (12,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha = 0.8)\nplt.ylabel('Number of Occurrences', fontsize =12)\nplt.xlabel('Number of products in the given order', fontsize=12)\nplt.title('Products in the given order', fontsize =15)\nplt.show()","f63bceca":"cnt_srs = order_prd_p['product_name'].value_counts().reset_index().head(20)\ncnt_srs.columns = ['product_name', 'frequency_count']\ncnt_srs","6573d034":"cnt_srs = order_prd_p['aisle'].value_counts().head(20)\nplt.figure(figsize = (12,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number od Occurences', fontsize= 12)\nplt.xlabel('Aisle', fontsize=12)\nplt.xticks(rotation = 'vertical')\nplt.show()","ee14ab95":"plt.figure(figsize = (10,10))\ntemp_series = order_prd_p['department'].value_counts()\nlabels = (np.array(temp_series.index))\nsizes = (np.array((temp_series \/ temp_series.sum())* 100))\nplt.pie(sizes, labels = labels, autopct = '%1.1f%%', startangle=200)\nplt.show()","dadae36d":"grouped = order_prd_p.groupby(['department'])['reordered'].aggregate('mean').reset_index()\n\nplt.figure(figsize = (12,8))\nsns.pointplot(grouped['department'].values, grouped['reordered'].values, alpha=0.8)\nplt.ylabel('Reorder ratio', fontsize= 12)\nplt.xlabel('Department', fontsize=12)\nplt.title('Department wise reorder ratio', fontsize = 15)\nplt.xticks(rotation = 'vertical')\nplt.show()","21ccadba":"grouped = order_prd_p.groupby(['department_id', 'aisle'])['reordered'].aggregate('mean').reset_index()\n\nfig, ax = plt.subplots(figsize = (12,20))\nax.scatter(grouped.reordered.values, grouped.department_id.values)\nfor i, txt in enumerate(grouped.aisle.values):\n    ax.annotate(txt, (grouped.reordered.values[i], grouped.department_id.values[i]), rotation = 45,\n                     ha = 'center', va = 'center')\nplt.ylabel('Department Id', fontsize= 12)\nplt.xlabel('Reordered Ratio', fontsize=12)\nplt.title('Reorder ratio of different aisles', fontsize = 15)\nplt.show()","f7f55749":"order_prd_p['add_to_cart_order_mod'] = order_prd_p['add_to_cart_order'].copy()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \nAddToCart = order_prd_p['add_to_cart_order_mod']\n\n# order_prd_p['add_to_cart_order_mod'].ix[order_prd_p['add_to_cart_order_mod']>70] = 70 ## 'ix' method doesn't work\nAddToCart[AddToCart>70] = 70\ngrouped = order_prd_p.groupby(['add_to_cart_order_mod'])['reordered'].aggregate('mean').reset_index()\n\nplt.figure(figsize = (12,8))\nsns.pointplot(grouped['add_to_cart_order_mod'].values, grouped['reordered'].values, alpha=0.8)\nplt.ylabel('Reorder ratio', fontsize= 12)\nplt.xlabel('Add to cart order', fontsize=12)\nplt.title('Add to cart order & Reorder ratio', fontsize = 15)\nplt.xticks(rotation = 'vertical')\nplt.show()","af7336e6":"grouped = order_prd_t.groupby(['order_dow'])['reordered'].aggregate('mean').reset_index()\n\nplt.figure(figsize = (12,8))\nsns.barplot(grouped['order_dow'].values, grouped['reordered'].values, alpha=0.8)\nplt.ylabel('Reorder Ratio', fontsize=12)\nplt.xlabel('Day of Week', fontsize=12)\nplt.title('Reorder ratio across day of week', fontsize=15)\nplt.xticks(rotation='vertical')\nplt.ylim(0.5, 0.7) # fix y axis height\nplt.show()","31d3adf9":"grouped = order_prd_t.groupby(['order_hour_of_day'])['reordered'].aggregate('mean').reset_index()\n\nplt.figure(figsize=(12,8))\nsns.barplot(grouped['order_hour_of_day'].values, grouped['reordered'].values, alpha=0.8)\nplt.ylabel('Reorder Ratio', fontsize=12)\nplt.xlabel('hour of Day', fontsize=12)\nplt.title('Reorder ratio across hour of day', fontsize=15)\nplt.xticks(rotation='vertical')\nplt.ylim(0.5, 0.7)\nplt.show()","d3708de0":"len(products.product_id.unique())","b12b5de8":"# order_prd_p.product_name.value_counts()[0:10]","dd0be9de":"# order_prd_p.aisle.value_counts()[0:10]","d138acbd":"clst_prd = pd.crosstab(order_prd_p['user_id'], order_prd_p['aisle'])\nclst_prd","31d87d7d":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 6)\npca.fit(clst_prd)\npca_samples = pca.transform(clst_prd)","103f4765":"ps = pd.DataFrame(pca_samples)\nps.head()","c59363ad":"ps.describe()","ae6d67e1":"from mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d\ntocluster = pd.DataFrame(ps[[4,1]])  # pick 2 pca columns\nprint(tocluster.shape)\nprint(tocluster.head())\n\nfig = plt.figure(figsize=(8,8))\nplt.plot(tocluster[4], tocluster[1], 'o', markersize=2, color='blue', alpha=0.5, label='class1')\n\nplt.xlabel('x_values')\nplt.ylabel('y_values')\nplt.legend()\nplt.show()","338a8868":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nclusterer = KMeans(n_clusters = 4, random_state = 42).fit(tocluster)\ncenters = clusterer.cluster_centers_\nc_preds = clusterer.predict(tocluster)\n\nprint(centers)","ac8cc6cb":"print(c_preds[0:100])","e449eb80":"import matplotlib\n\nfig = plt.figure(figsize = (8,8))\ncolors = ['orange', 'blue', 'purple', 'green']\ncolored = [colors[k] for k in c_preds]\n\nprint(colored[0:10])\n\n\nplt.scatter(tocluster[4], tocluster[1], color = colored)\n\nfor ci,c in enumerate(centers):\n    plt.plot(c[0], c[1], 'o', markersize = 8, color = 'red', alpha=0.9, label=''+str(ci))\n\nplt.xlabel('x_values')\nplt.ylabel('y_values')\nplt.legend()\nplt.show()","e30c7932":"clst_prd_mod = clst_prd.copy()\nclst_prd_mod['cluster'] =  c_preds\n\nclst_prd_mod.head(10)","1cd00e9d":"print(clst_prd_mod.shape)\n\nf,arr = plt.subplots(2,2, sharex = True, figsize=(15,15))\n\nc1_count = len(clst_prd_mod[clst_prd_mod['cluster']==0])\n\nc0 = clst_prd_mod[clst_prd_mod['cluster']==0].drop('cluster', axis=1).mean()\narr[0,0].bar(range(len(clst_prd_mod.drop('cluster', axis=1).columns)), c0)\nc1 = clst_prd_mod[clst_prd_mod['cluster']==1].drop('cluster', axis=1).mean()\narr[0,1].bar(range(len(clst_prd_mod.drop('cluster', axis=1).columns)), c1)\nc2 = clst_prd_mod[clst_prd_mod['cluster']==2].drop('cluster', axis=1).mean()\narr[1,0].bar(range(len(clst_prd_mod.drop('cluster', axis=1).columns)), c2)\nc3 = clst_prd_mod[clst_prd_mod['cluster']==3].drop('cluster', axis=1).mean()\narr[1,1].bar(range(len(clst_prd_mod.drop('cluster', axis=1).columns)), c3)\n\nplt.show()","83d91176":"c0.sort_values(ascending=False)[0:10]","6e45fb38":"c1.sort_values(ascending=False)[0:10]","cc805854":"c2.sort_values(ascending=False)[0:10]","51f9e5e8":"c3.sort_values(ascending=False)[0:10]","fb44daee":"print(len(orders), len(order_prd_p),len(order_prd_t))","8f4e3396":"order_prd_p.columns","a0021eff":"X = total[['order_id', 'user_id', 'order_number', 'order_dow',\n       'order_hour_of_day', 'product_id_x',\n       'add_to_cart_order_x', 'reordered_x']]\nY = total['product_id_y']","ba86742c":"x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size = 0.3)","fcd145ca":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport numpy as np","a23ed4da":"model = tf.keras.Sequential()\n\nmodel.add(layers.Input(shape=8))\nmodel.add(layers.Dense(4, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='mean_squared_error',\n              optimizer = 'SGD',\n              metrics = ['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=10, verbose=1)","549da39a":"### Hypothesis\n\\\nWith variables of order product prior, we could predict products of train data sets.\\","abf68163":"The sum of order_product_prior and order_product_train is not same volume with orders data.\\\nBecause the order product prior\/train carry 'products' data.\\\nIn one order, users could buy plural products.\\\nThat's why the sum of the order product data doesn't have same record with orders.","75d3bc5d":"## Perceptron","20094df5":"\n# My Modeling","be90c163":"# Clustering Customers\n\n- following beneth notebook\n    - [Customer Segments with PCA](https:\/\/www.kaggle.com\/asindico\/customer-segments-with-pca)","897099c7":"We can see people order in 30 days cycle the most and then 7 days cycle.","fd376606":"**Train Orders**","b9c657c3":"There are 49688 products in the lists.","e9fb6b5e":"### Products in Order","30f2c5df":"Prior set means the total customer number.\\\n131209 users already have the result, and 75000 users need to be predicted.","cd3d743d":"### How long does it take to reorder after prior order","8e2d634b":"**Details of products**","eb4bf68b":"This competetion aims to predic the products which will be user's future order.\\\nThe given data is 'prior order', 'train order', 'orders' and the details of the products.","a9b437f1":"### Order number (including Frequency)","9b8b5070":"**Prior Orders**","72d893a8":"**Merge Data**\n\n- orders, order product prior, order product train","171a7908":"Banana is the most sold products.\\\nAnd top 20 products are almost fruits and vegies.","39e18530":"59% of users reordered in both evaluation datasets.","acd2ff2b":"### Eval set comparison","a57bab46":"**Libraries**","7ee3c616":"# Data\n\n- following beneth notebook\n    - [Simple Exploration Notebook - Instacart](https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-notebook-instacart)","3fae1b11":"**Orders**","8f07a32a":"3 types of Evaluation set type : prior, train, test.\\\nAnd the prior set has most of the records.","dc6ef42f":"## Data Exploration","c97389d5":"Also the aisles of most sold products are fresh fruits and fresh vegies.","78faaf6f":"ERROR Message : Your notebook tried to allocate more memory than is available. It has restarted.\n\n- I guess kaggle notebook doesn't have enough memory for this data..","ec7c16c5":"## PCA : Principall components Analysis\n\n- For calulating KMeans","89a07ae7":"## Basic"}}