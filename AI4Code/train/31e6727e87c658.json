{"cell_type":{"5b7d2289":"code","a35ac0d7":"code","75f3fe95":"code","04ede7c0":"code","253f09d8":"code","fa71d6ac":"code","71bd9dd8":"code","e4faa1d6":"code","ec347948":"code","0cc02658":"code","0723c78e":"code","3b433a0b":"code","07f8c64f":"code","87edd1d8":"code","cfbe4205":"code","f15993f1":"code","8c95dc2b":"code","16335f8b":"markdown","d1b68ea1":"markdown","9f57902e":"markdown","3dc92faa":"markdown","f850b90d":"markdown","5fe0a356":"markdown","0fcdca5e":"markdown","efd80dd4":"markdown","acb7e8fa":"markdown","b9f25892":"markdown","eabb3935":"markdown","0c2b777c":"markdown","4b4ec743":"markdown","cf75725a":"markdown","b6f0366d":"markdown","978b8ceb":"markdown","33fdfe5a":"markdown","ace1ab36":"markdown","e758c492":"markdown","df0f8b37":"markdown","28645738":"markdown"},"source":{"5b7d2289":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sb\nfrom sklearn import metrics \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix","a35ac0d7":"kfoldmean = np.array([0.0,0.0,0.0,0.0,0.0,0.0,0.0])\nkfoldstd = np.array([0.0,0.0,0.0,0.0,0.0,0.0,0.0])\ncmval=np.array([0,0,0,0,0,0,0])\npositions=np.array([0,1,2,3,4,5,6])\nnames=[\"Logistic Regression\",\"KNN\",\"SVM Linear\",\"SVM rbf\",\"Naive Bayes\",\"Decision Tree\",\"Random Forest\"]","75f3fe95":"dataset = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, 8].values","04ede7c0":"from sklearn.impute import SimpleImputer\nimputer= SimpleImputer(missing_values=0, strategy=\"mean\")\nimputer=imputer.fit(X[:,1:8])\nX[:,1:8]=imputer.transform(X[:,1:8])","253f09d8":"corr = dataset.corr()\nplt.figure(figsize=(12, 12))\nsb.heatmap(corr, annot=True)","fa71d6ac":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2, random_state=0)","71bd9dd8":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","e4faa1d6":"from sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression(random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nsb.heatmap(cm, annot=True, fmt='g')\n\ncmval[0]=cm[0][0]+cm[1][1]\n\naccuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\nprint(\"Mean using K-fold:\",accuracies.mean())\nprint(\"Standard Deviation using K-fold:\",accuracies.std())\n\nkfoldmean[0]=accuracies.mean()\nkfoldstd[0]=accuracies.std()","ec347948":"from sklearn.neighbors import KNeighborsClassifier\nclassifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nsb.heatmap(cm, annot=True, fmt='g')\n\ncmval[1]=cm[0][0]+cm[1][1]\n\naccuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\nprint(\"Mean using K-fold:\",accuracies.mean())\nprint(\"Standard Deviation using K-fold:\",accuracies.std())\n\nkfoldmean[1]=accuracies.mean()\nkfoldstd[1]=accuracies.std()\n","0cc02658":"from sklearn.svm import SVC\nclassifier=SVC(kernel='linear',random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nsb.heatmap(cm, annot=True, fmt='g')\n\ncmval[2]=cm[0][0]+cm[1][1]\n\naccuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\nprint(\"Mean using K-fold:\",accuracies.mean())\nprint(\"Standard Deviation using K-fold:\",accuracies.std())\n\nkfoldmean[2]=accuracies.mean()\nkfoldstd[2]=accuracies.std()","0723c78e":"classifier=SVC(kernel='rbf',random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nsb.heatmap(cm, annot=True, fmt='g')\n\ncmval[3]=cm[0][0]+cm[1][1]\n\naccuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\nprint(\"Mean using K-fold:\",accuracies.mean())\nprint(\"Standard Deviation using K-fold:\",accuracies.std())\n\nkfoldmean[3]=accuracies.mean()\nkfoldstd[3]=accuracies.std()","3b433a0b":"from sklearn.naive_bayes import GaussianNB\nclassifier=GaussianNB()\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nsb.heatmap(cm, annot=True, fmt='g')\n\ncmval[4]=cm[0][0]+cm[1][1]\n\naccuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\nprint(\"Mean using K-fold:\",accuracies.mean())\nprint(\"Standard Deviation using K-fold:\",accuracies.std())\n\nkfoldmean[4]=accuracies.mean()\nkfoldstd[4]=accuracies.std()","07f8c64f":"from sklearn.tree import DecisionTreeClassifier\nclassifier=DecisionTreeClassifier(criterion='entropy',random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nsb.heatmap(cm, annot=True, fmt='g')\n\ncmval[5]=cm[0][0]+cm[1][1]\n\naccuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\nprint(\"Mean using K-fold:\",accuracies.mean())\nprint(\"Standard Deviation using K-fold:\",accuracies.std())\n\nkfoldmean[5]=accuracies.mean()\nkfoldstd[5]=accuracies.std()","87edd1d8":"from sklearn.ensemble import RandomForestClassifier\nclassifier=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nsb.heatmap(cm, annot=True, fmt='g')\n\ncmval[6]=cm[0][0]+cm[1][1]\n\naccuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\nprint(\"Mean using K-fold:\",accuracies.mean())\nprint(\"Standard Deviation using K-fold:\",accuracies.std())\n\nkfoldmean[6]=accuracies.mean()\nkfoldstd[6]=accuracies.std()","cfbe4205":"fig=plt.figure(figsize=(12,12))\nplt.barh(names,cmval)\nplt.ylabel('Models Used')\nplt.xlabel('Correct CM Values')\nfor index, value in enumerate(cmval):\n    plt.text(value, index, str(value))\nplt.show()","f15993f1":"fig=plt.figure(figsize=(12,12))\nplt.barh(names,kfoldmean)\nplt.ylabel('Models Used')\nplt.xlabel('Kfold Mean Values')\nfor index, value in enumerate(kfoldmean):\n    plt.text(value, index, str(value))\nplt.show()","8c95dc2b":"fig=plt.figure(figsize=(12,12))\nplt.barh(names,kfoldmean)\nplt.ylabel('Models Used')\nplt.xlabel('Kfold Standard Deviation Values')\nfor index, value in enumerate(kfoldstd):\n    plt.text(value, index, str(value))\nplt.show()","16335f8b":"# **Importing Libraries**","d1b68ea1":"Dataset is ready for processing","9f57902e":"# **Defining arrays**","3dc92faa":"# **Feature Scaling**","f850b90d":"# Summary","5fe0a356":"# **Decision Tree, Confusion Matrix, K-Fold**","0fcdca5e":"# **KNN, Confusion Matrix, K-Fold**","efd80dd4":"# **Logistic Regression, Confusion Matrix, K-Fold**","acb7e8fa":"Best Model found was Logistic Regression with the highest K-Fold Score and Least Incorrect Predicted Values using CM.","b9f25892":"# **Handling missing values** and replacing it with mean","eabb3935":"# **Plotting K-Fold Standard Deviation Values of Each Model **","0c2b777c":"# **Importing dataset**","4b4ec743":"# **SVM RBF Gaussian Kernel, Confusion Matrix, K-Fold**","cf75725a":"# **Splitting dataset**","b6f0366d":"No serious Multicollinearity found","978b8ceb":"# **SVM Linear, Confusion Matrix, K-Fold**","33fdfe5a":"# **Plotting K-Fold Mean Values of Each Model**","ace1ab36":"# **Naive Bayes, Confusion Matrix, K-Fold**","e758c492":"# **Finding Multicollinearity**","df0f8b37":"# **Plotting Correct values by Each Model using Confusion Matrix**","28645738":"# **Random Forest, Confusion Matrix, K-Fold**"}}