{"cell_type":{"7bb55e77":"code","d4f15b08":"code","d99b3d59":"code","630b11bf":"code","40c59b8d":"code","847aecf1":"code","d813bcfe":"code","0425b99b":"code","2c4c9366":"code","7c14ef09":"code","63864bea":"code","7bd883a9":"code","f39d4659":"markdown","56c7efed":"markdown","8fde6936":"markdown","484bd494":"markdown","5c548940":"markdown","477ddd86":"markdown","f989ce9f":"markdown","edcc35cb":"markdown","8e76e0ce":"markdown","718a1991":"markdown","93576975":"markdown","84e63d99":"markdown","3dced092":"markdown","afa227b8":"markdown","69d7ba21":"markdown","29be28c5":"markdown","d82a2411":"markdown","57f6b5f1":"markdown","4eaa39a9":"markdown","7cb0d3e0":"markdown","02d4ae3e":"markdown","57e2b8fd":"markdown"},"source":{"7bb55e77":"from IPython.display import Image\nImage(\"..\/input\/cvresults\/cv-resultsv02.png\")","d4f15b08":"%matplotlib inline\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\nimport plotly.plotly as py\nimport cufflinks as cf\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom wordcloud import WordCloud","d99b3d59":"input_dir = r'..\/input\/data-science-for-good-careervillage'\n#print(os.listdir(input_dir))\n#input_dir = '' \n\nprofessionals = pd.read_csv(os.path.join(input_dir, 'professionals.csv'))\nstudents = pd.read_csv(os.path.join(input_dir, 'students.csv'))\ntag_users = pd.read_csv(os.path.join(input_dir, 'tag_users.csv'))\n\nanswers = pd.read_csv(os.path.join(input_dir, 'answers.csv'))\nquestions = pd.read_csv(os.path.join(input_dir, 'questions.csv'))\ntag_questions = pd.read_csv(os.path.join(input_dir, 'tag_questions.csv'))\n\ntags = pd.read_csv(os.path.join(input_dir, 'tags.csv'))\nemails = pd.read_csv(os.path.join(input_dir, 'emails.csv'))\nmatches = pd.read_csv(os.path.join(input_dir, 'matches.csv'))\n\n# Dropped:\n# groups = pd.read_csv(os.path.join(input_dir, 'groups.csv'))\n# group_memberships = pd.read_csv(os.path.join(input_dir, 'group_memberships.csv'))\n# school_memberships = pd.read_csv(os.path.join(input_dir, 'school_memberships.csv'))\n# comments = pd.read_csv(os.path.join(input_dir, 'comments.csv'))\n# question_scores = pd.read_csv(os.path.join(input_dir, 'question_scores.csv'))\nanswer_scores = pd.read_csv(os.path.join(input_dir, 'answer_scores.csv'))\n\n\n## Cleaning & Prejoining tables\n\n#dtype to datetime\nprofessionals['professionals_date_joined'] = pd.to_datetime(professionals['professionals_date_joined'])\nstudents['students_date_joined'] = pd.to_datetime(students['students_date_joined'])\nquestions['questions_date_added'] = pd.to_datetime(questions['questions_date_added'])\nanswers['answers_date_added'] = pd.to_datetime(answers['answers_date_added'])\n\ntag_users = tag_users.merge(tags, left_on='tag_users_tag_id',right_on='tags_tag_id', how='outer')\ntag_questions = tag_questions.merge(tags, left_on ='tag_questions_tag_id',right_on='tags_tag_id', how='outer')\n\n\n#tag_users.describe(include='all')\n#tag_users.set_index(['tag_users_tag_id']);\n#tags.set_index(['tags_tag_id']);\n#tag_users.join(tags, on=['tag_users_tag_id', 'tags_tag_id'], how='inner')\n#result = pd.merge(left.reset_index(), right.reset_index(), on=['key'], how='inner').set_index(['key','Y'])","630b11bf":"#professionals.describe()\nprofessionals['professionals_date_joined'].dt.month\n\nplt_profjoined = (professionals.groupby([professionals['professionals_date_joined'].map(lambda x: 100*x.year + x.quarter)]).size())#\/len(professionals.professionals_date_joined))\nplt_studjoined = (students.groupby([students['students_date_joined'].map(lambda x: 100*x.year + x.quarter)]).size())#\/len(students.students_date_joined))\n\nplt_data = pd.DataFrame({'professionals': plt_profjoined,\n                        'students':plt_studjoined })\n\nplt_data.cumsum().plot(kind='bar', figsize=(13, 6))\nplt.xlabel('Year - Quarter')\nplt.ylabel('Number of users.')\nplt.title('Professionals joined over time')\nplt.show()","40c59b8d":"#professionals.describe()\n\nplt_questions = (questions.groupby([questions['questions_date_added'].map(lambda x: 100*x.year + x.quarter)]).size())#\/len(students.students_date_joined))\nplt_answers = (answers.groupby([answers['answers_date_added'].map(lambda x: 100*x.year + x.quarter)]).size())#\/len(students.students_date_joined))\n\n\nplt_data = pd.DataFrame({'questions': plt_questions,\n                        'answers': plt_answers})\n\n\nplt_data.cumsum().plot(kind='bar', figsize=(13, 6))\nplt.xlabel('Year - Quarter')\nplt.ylabel('Number of Prof.')\nplt.title('Activity on the site')\nplt.show()","847aecf1":"cf.set_config_file(offline=True, world_readable=True, theme='pearl')\n\n# get the number of users & questions for each tag.\nplt_tag_users = tag_users.groupby([tag_users['tags_tag_name']]).size()\nplt_tag_questions = tag_questions.groupby([tag_questions['tags_tag_name']]).size()\n\nplt_data = pd.DataFrame({'user_tags': plt_tag_users,\n                        'question_tags': plt_tag_questions}).reset_index()\n\n# filter out the tags with little use (just for the visualisation)\nplt_data = plt_data[(plt_data>20).all(axis=1)]\n\nplt_data.iplot(kind='bubble', x='user_tags', y='question_tags', size='question_tags', text='tags_tag_name', color = 'blue',\n             xTitle='User w Tag', yTitle='Question w Tag',title='Popular tags for users & professionals')\nplt.show()\n","d813bcfe":"tag_questions['dummy'] = 1\nq_tags = tag_questions.pivot_table(index='tag_questions_question_id', columns = \"tags_tag_name\", values='dummy',fill_value=0)\n\nimport scipy as sp\nfrom scipy.sparse import csr_matrix\n\n#sparse matrix from tag matrix\nsp_tags=csr_matrix(q_tags)\nsp_tags = sp_tags.T.dot(sp_tags)\n\n#print(sp_tags[:,-5])\n\n#get the indices for the rows\/cols & values:\nKnz = sp_tags.nonzero()\nsparserows = Knz[0]\nsparsecols = Knz[1]\nvals = np.empty(sparserows.shape).astype(np.float)\nfor i in range(len(sparserows)):\n    vals[i] = sp_tags[sparserows[i],sparsecols[i]]\n\n# Dataframe: Tag 1  \/ Tag 2 \/ nuumber of times both tags appear in the same question.\ntags_NN = pd.DataFrame({'tag1': sparserows,\n                        'tag2': sparsecols,\n                        'n_occurances' :vals})\n\n# Remove relations where tag1 = tag2 (connection with itself).\ntags_NN= tags_NN[tags_NN.tag1 != tags_NN.tag2]\n# Correct for double counts: All connections  counted twice (A-> B and B-> A)\ntags_NN.drop(tags_NN.loc[tags_NN[\"tag2\"]<tags_NN[\"tag1\"]].index.tolist(), inplace=True)\n\n\n# - - - - -\n# Test with Head\n# - - - - -\ntags_NN = tags_NN.head(200)\n\n#Create a network:\nimport networkx as nx\n\nG_tags = nx.from_pandas_edgelist(df=tags_NN, source='tag1', target='tag2', edge_attr='n_occurances')\n#G_tags.add_nodes_from(nodes_for_adding=tags_NN.tag2.tolist())\n\ntags_NN.head();\npos = nx.spring_layout(G_tags)\n\nplt.figure(1,figsize=(12,12))\nnx.draw_networkx_nodes(G_tags, pos, alpha=0.1)\nnx.draw_networkx_edges(G_tags, pos, alpha=0.1)\n","0425b99b":"#Convert dates to datetime64 format\nemails['emails_date_sent'] = emails['emails_date_sent'].map(lambda x: str(x)[:-9])\nemails['emails_date_sent'] = pd.to_datetime(emails['emails_date_sent'],infer_datetime_format=True)\n\nemail_matches = emails.merge(matches, left_on='emails_id',right_on='matches_email_id', \n                             how='right').drop('matches_email_id',axis=1);\n\nq_and_a =questions.merge(answers, left_on='questions_id',right_on='answers_question_id', \n                             how='outer').drop('answers_question_id',axis=1).sort_values('questions_id');\n\n### Amount of e-mails send per question ###\nemails_send = email_matches.groupby('matches_question_id').count().sort_values('emails_id',ascending=False)['emails_id']\n\nemails_send.iplot('histogram', title = 'Number of e-mails send per question',xTitle = 'E-mails send', \n                  yTitle = 'Counts (log)',logy=True,bins=50)\n\n### Number of answers per question ###\nN_answers = q_and_a.groupby('questions_id').count()['answers_id']\nN_answers=N_answers[N_answers<20]\nN_answers.iplot('histogram', title = 'Answers per question',xTitle = '# Answers')\n\n\n### Time between question and answer\ntime_qa = q_and_a['answers_date_added'] - q_and_a['questions_date_added']\ntime_qa.dt.days.iplot('histogram',title = 'Average time until a question is answered',xTitle = 'Days', yTitle ='Counts', logy=True, bins=50)\n#time_qa.iplot(kind='histogram')","2c4c9366":"# Merge [matches_question_id & email_recipient_id]  with [question_id & answer_author id] from q_and_a\n# Merge: the questions for which e-mails have been send to users, with the answer table to find how many answers the e-mails have generated.\nemail_QA = pd.merge(email_matches, q_and_a,  how='left', left_on=['matches_question_id','emails_recipient_id'], \n                               right_on = ['questions_id','answers_author_id'])\nemail_QA = email_QA.drop(['emails_frequency_level','questions_date_added','questions_body','answers_body','questions_id'], \n                                               axis=1)\n\n# Converting dates to datetime type takes a long time, quick and dirty method to get the months:\nemail_QA['emails_ym_sent'] = email_QA['emails_date_sent'].map(lambda x: str(x)[:-12])\nmails_send = email_QA.groupby(email_QA['emails_ym_sent']).count(); #.dropna())\/len(email_QA).groupby('emails_date_sent')\nmails_send = mails_send['emails_id']\nmails_answered = email_QA.dropna()\nmails_answered = mails_answered.groupby('emails_ym_sent').count();\nmails_answered = mails_answered['emails_id']\n\n#Bar plot - howmany people actually responded after receiving an an e-mail:\nplot_mail_response = pd.DataFrame({'send': mails_send,\n                        'answered': mails_answered})\nplot_mail_response.iplot(kind='bar',bins=10,barmode='stack',title='Numer of e-mails over time: send out and resulting in a reply',yTitle='e-mail count')\n\n#Bar plot - ratio of the people that answered a question after receiving an e-mail.\nplt_ratio = mails_answered\/mails_send\nplt_ratio.iplot(kind='bar',title='Effectiveness of mails being send out',xTitle='Time',yTitle='% of mails that trigger a response')\nprint('Effectiveness of e-mails', plt_ratio.mean())","7c14ef09":"# Reconstruct the ranking that was used by carreervillage\n# Create a ranking for each question: #e.g. 50th person to be send an e-mail answered --> ranking = 50.\ncv_communication = email_QA[['matches_question_id','emails_recipient_id','emails_date_sent','answers_date_added']];\n\n# 1. Sort by question and by date\ncv_communication = cv_communication.sort_values(by=['matches_question_id','emails_date_sent'])\n# hardcode the index counter, we will use this column to calculate the ranking of the professional that replied.\ncv_communication['row_counter'] = range(len(cv_communication))\n\n# 2. Get the index of the first answer:\ncv_rank_index = cv_communication.groupby([\"matches_question_id\"], sort=False)['answers_date_added'].min();\ncv_rank_index = cv_rank_index.dropna().to_frame()\n#merge back to get the row index\ncv_rank_index = pd.merge(cv_rank_index, cv_communication,  how='left', left_on=['matches_question_id','answers_date_added'], \n                               right_on = ['matches_question_id','answers_date_added'])\n\n\n# 3. Index of the first mail that was send for this Q:\ncv_ref_index = pd.DataFrame(cv_communication.groupby([\"matches_question_id\"], sort=False)['emails_date_sent'].min());\n\n #merge back to get the row index\ncv_ref_index = pd.merge(cv_ref_index, cv_communication,  how='left', left_on=['matches_question_id','emails_date_sent'], \n                               right_on =['matches_question_id','emails_date_sent'])\ncv_ref_index = pd.DataFrame(cv_ref_index.groupby([\"matches_question_id\"], sort=False)['row_counter'].min());\n\n\n# 4. Take the difference in index between the row with question id & and the answer.\ncv_ranking = cv_rank_index.merge(cv_ref_index, how='left', left_on=['matches_question_id'], right_on=['matches_question_id'])\n\n\n#merge the two dataframes:\ncv_ranking[\"Ranking\"] = cv_ranking['row_counter_x'] - cv_ranking['row_counter_y']\ncv_ranking = cv_ranking.drop(['row_counter_x','row_counter_y','emails_recipient_id'],axis=1);\n\n# 5. Add the total number of e-mails send to cv_ranking\ncv_nmails = cv_communication.drop(['emails_date_sent','answers_date_added','row_counter'],axis=1).groupby([\"matches_question_id\"]).count()\ncv_nmails.rename(columns={'emails_recipient_id': 'Total mails sent'}, inplace=True)\ncv_ranking = cv_ranking.merge(cv_nmails, how='left', left_on=['matches_question_id'], right_on = ['matches_question_id'])\n\n#plot\ncv_ranking['rank_frac_cv'] = cv_ranking['Ranking']\/cv_ranking['Total mails sent']\ncv_ranking['rank_frac_cv'].iplot(kind='histogram',title='Ranking vs chance to answer to an e-mail for the CVs matching algorithm',yTitle='answered to question',\n                                 xTitle='Ranking of user \/ total mails send')","63864bea":"input_dir2 = '..\/input\/cvresultslarge'\n\ndf_output = pd.read_csv(os.path.join(input_dir2, 'df_output_large.csv'))\ndf_output = df_output.dropna()\nrank_comparisson = pd.merge(df_output, cv_ranking,  how='inner', left_on='Question_ID', \n                               right_on = 'matches_question_id')\n\nrank_comparisson['model_vs_cv'] = rank_comparisson['Ranking model']\/rank_comparisson['Ranking']\nrank_comparisson['model_vs_cv'] = rank_comparisson['model_vs_cv'][(rank_comparisson['model_vs_cv']<12)]\nrank_comparisson['model_vs_cv'].iplot(kind='histogram',title='Model vs CV (smaller[<1] is better)',bins=60, xTitle='Rank tag-based recommender \/ Rank CV', yTitle='# questions')\n\nrank_comparisson['rank_frac_cv'] = rank_comparisson['Ranking']\/rank_comparisson['Total mails sent']\nrank_comparisson['rank_frac_model'] = rank_comparisson['Ranking model']\/rank_comparisson['Total mails sent']\n\nplt_ranks =  pd.DataFrame({'currently used system': rank_comparisson['rank_frac_cv'],\n                        'Tag-based recommender': rank_comparisson['rank_frac_model']})\n\nplt_ranks.iplot(kind='histogram', bins=20,xTitle = 'User ranking', yTitle='Matches by mail',title='Comparison between current situation and tag-based recommendations')","7bd883a9":"'''\n\n# Exploring the data\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy import sparse\nimport time\nimport sys\n\npd.set_option('display.max_columns', 20)\npd.set_option('display.max_rows', 200)\ndatadir = r'..\/input'\n\nread_data = True  # Always true\npreprocess_data = True\nrecalculate_professionals_profiles = True  # True: Run only once and save the data. Slow. False: The second time you can put this to false and just load the data.\n\n# Reading csv files\nif read_data:\n    # Persons\n    professionals = pd.read_csv(os.path.join(datadir, 'professionals.csv'))\n    students = pd.read_csv(os.path.join(datadir, 'students.csv'))\n    tag_users = pd.read_csv(os.path.join(datadir, 'tag_users.csv'))\n    # Questions\n    questions = pd.read_csv(os.path.join(datadir, 'questions.csv'))\n    answers = pd.read_csv(os.path.join(datadir, 'answers.csv'))\n    tag_questions = pd.read_csv(os.path.join(datadir, 'tag_questions.csv'))\n    question_scores = pd.read_csv(os.path.join(datadir, 'question_scores.csv'))\n    answer_scores = pd.read_csv(os.path.join(datadir, 'answer_scores.csv'))\n    emails = pd.read_csv(os.path.join(datadir, 'emails.csv'))\n    matches = pd.read_csv(os.path.join(datadir, 'matches.csv'))\n    tags = pd.read_csv(os.path.join(datadir, 'tags.csv'))\n    print('Number of professionals: ' + str(len(professionals)))\n    print('Number of students: ' + str(len(students)))\n    print('Number of tag_users: ' + str(len(tag_users)))\n    print('Number of questions: ' + str(len(questions)))\n    print('Number of answers: ' + str(len(answers)))\n    print('Number of tag_questions: ' + str(len(tag_questions)))\n    print('Number of question_scores: ' + str(len(question_scores)))\n    print('Number of answer_scores: ' + str(len(answer_scores)))\n    print('Number of emails: ' + str(len(emails)))\n    print('Number of matches: ' + str(len(matches)))\n\ndef append_question_tags_to_professionals(questions, answers, tag_questions, tag_users, tags):\n    # Assign the tags to professionals which belong to questions they replied to in the past\n    tag_users = tag_users.merge(tags, left_on='tag_users_tag_id', right_on='tags_tag_id', how='outer')\n    tag_questions = tag_questions.merge(tags, left_on='tag_questions_tag_id', right_on='tags_tag_id', how='outer')\n    q_and_a = questions.merge(answers, left_on='questions_id', right_on='answers_question_id',\n                              how='outer').drop('answers_question_id', axis=1).sort_values('questions_id');\n    q_and_a = q_and_a.drop(\n        columns=['questions_author_id', 'questions_date_added', 'questions_title', 'questions_body', 'answers_body',\n                 'answers_date_added'])\n    prof_c_tags = pd.merge(tag_questions, q_and_a, how='left', left_on='tag_questions_question_id',\n                           right_on='questions_id')\n    prof_c_tags = prof_c_tags.drop(columns=['tag_questions_question_id', 'answers_id', 'questions_id'])\n    prof_c_tags = pd.DataFrame({'tag_users_tag_id': prof_c_tags['tag_questions_tag_id'],\n                                'tag_users_user_id': prof_c_tags['answers_author_id'],\n                                'tags_tag_id': prof_c_tags['tags_tag_id'],\n                                'tags_tag_name': prof_c_tags['tags_tag_name']\n                                })\n    tag_users = tag_users.append(prof_c_tags)\n    return tag_users\n\nif preprocess_data:\n    professionals = professionals.drop(['professionals_headline', 'professionals_industry'], axis=1)\n    professionals = professionals.fillna('')\n\n    #Print most frequent tags\n    most_frequent_tags = tags.set_index('tags_tag_id')\n    most_frequent_tags['counts'] = tag_questions['tag_questions_tag_id'].value_counts()\n    most_frequent_tags.sort_values(by='counts', ascending=False)\n    #The most frequent tags '27490' and '129' correspond to 'college' and 'career'. These are not too relevant\n    # and can better be removed for improved model performance\n    tag_users = append_question_tags_to_professionals(questions, answers, tag_questions, tag_users, tags)\n    tags = tags[(tags.tags_tag_id != '27490') & (tags.tags_tag_id != '129')]\n    tag_users = tag_users[(tag_users.tag_users_tag_id != '27490') & (tag_users.tag_users_tag_id != '129')]\n    tag_questions = tag_questions[(tag_questions.tag_questions_tag_id != '27490') & (tag_questions.tag_questions_tag_id != '129')]\n    unique_questions = list(set(tag_questions['tag_questions_question_id'].values))\n    matches = matches.set_index('matches_question_id').loc[unique_questions].reset_index()\n\n    # Filter tags_users so that it only contains professionals which have tags: tag_users_professionals_only\n    tag_users_professionals_only = \\\n    pd.merge(tag_users, professionals, how='left', left_on='tag_users_user_id', right_on='professionals_id').dropna(\n        axis=0)[['tag_users_tag_id', 'tag_users_user_id']]\n    tag_questions = tag_questions.set_index('tag_questions_question_id')\n\ndef create_tagMatrix(df_tags, content='', n_rows=[]):\n    if content == 'questions':\n        dfindex = \"tag_questions_question_id\"\n        dfcolumns = \"tag_questions_tag_id\"\n    elif content == 'users':\n        dfindex = \"tag_users_user_id\"\n        dfcolumns = \"tag_users_tag_id\"\n\n    df_tags['dummy'] = 1\n    df_QT = df_tags.pivot_table(index=dfindex, columns=dfcolumns, values='dummy').fillna(0)\n    if n_rows == []:\n        n_rows = len(df_QT)\n    QT = df_QT.head(n_rows)\n    tag_list = list(QT.columns)\n\n    # Count co-occurrence of the tags from questions\n    print('... Create co-occurence matrix ...')\n    QT_sparse = sparse.csr_matrix(QT)\n    TT_sparse = QT_sparse.transpose().dot(QT_sparse).tocsr()\n    TT_sparse.setdiag(0)\n    TT_sparse.eliminate_zeros()\n    TT_sparse = sparse.csr_matrix(\n        (TT_sparse.transpose() \/ TT_sparse.sum(axis=0)).transpose())  # Now the sum of every row equals 1\n\n    # Make a matrix with ones on the diagonal and reduce the influence of neighbors.\n    print('... Combining sparse matrices ...')\n    TT_sparse = tune_TT(TT_sparse)\n\n    # Check matrix with excel (don't do for 16000 columns!!)\n    if content == 'users':\n        print('... Write quality check to excel ...')\n        df = pd.DataFrame(TT_sparse.todense())\n        filepath = 'my_excel_file.xlsx'\n        df.iloc[:100, :100].to_excel(filepath, index=False)\n\n    df_TT = pd.DataFrame(TT_sparse.todense(), index=tag_list, columns=tag_list).fillna(0)\n    return df_TT  # A matrix with in the rows the tags, and in the columns the co-occurrence of the tags. The sum of values in a row equals 1.\n\ndef tune_TT(TT_sparse, neighbor_reduction_factor=0.5):\n    # First order neighbor implementation: divide influence of the neighbors by 2 and add ones to the diagonal of the matrix\n    TT_sparse = TT_sparse * neighbor_reduction_factor\n    # To take into account also the second order neighbors, you can add  \"  + TT_sparse.multiply(TT_sparse) * neighbor_reduction_factor**2  \"\n    TT_sparse.setdiag(1)\n    return TT_sparse\n\ndef get_tagvals(df, row):\n    # Returns a list of tags that is associated with a row from the TT_professionals dataframe\n    rownr = row['rownumber'].astype(int)\n    tagvals = list(pd.Series(df.columns[:-1]).values[df.iloc[rownr, :-1].values.astype(bool)])\n    return tagvals\n\ndef get_profile(df_TT, tags):\n    # Returns the profile of a question, given a question with several tags\n    profile = df_TT.loc[tags, :].sum()\n    profile = profile \/ max(\n        profile)  # Now the strongest tags will be (nearly) equal to one, which makes them comparable with users\n    return profile\n\ndef create_TT_matrices(tag_list, tag_questions, tag_users_professionals_only):\n    # Create a dataframe with co-occurrence of tags\n    print('Start questions')\n    df_TT_questions = create_tagMatrix(tag_questions, content='questions')\n    df_TT_questions = df_TT_questions.reindex(columns=tag_list,\n                                              fill_value=0)  # Add all tags to the columns, not just questions or users\n    print('Start professionals')\n    df_TT_professionals = create_tagMatrix(tag_users_professionals_only, content='users')\n    df_TT_professionals = df_TT_professionals.reindex(columns=tag_list, fill_value=0)\n    return df_TT_questions, df_TT_professionals\n\ntag_list = sorted(list(tags['tags_tag_id'].values))\ndf_TT_questions, df_TT_professionals = create_TT_matrices(tag_list, tag_questions, tag_users_professionals_only)\n\ndef create_professionals_profiles(tag_users_professionals_only, df_TT_professionals):\n    # Create a dataframe with the tagprofiles of all professionals\n    df_tags_professionals = tag_users_professionals_only.pivot_table(index='tag_users_user_id',\n                                                                     columns='tag_users_tag_id', values='dummy').fillna(\n        0)\n    df_tags_professionals = df_tags_professionals.reindex(columns=tag_list,\n                                                          fill_value=0)  # Add all tags (empty columns)\n    df_tags_professionals['rownumber'] = range(\n        len(df_tags_professionals))  # Add a column with row numbers for allowing lambda function usage\n    #df_tags_professionals = df_tags_professionals.head(5000)  # For testing: use only n professionals from the database\n    professionals_profiles = df_tags_professionals.apply(\n        lambda row: get_profile(df_TT_professionals, get_tagvals(df_tags_professionals, row)), axis=1)\n    professionals_profiles_sparse = scipy.sparse.csr.csr_matrix(professionals_profiles)\n    df_tags_professionals = df_tags_professionals.drop(['rownumber'], axis=1)\n    return professionals_profiles_sparse, df_tags_professionals\n\nif recalculate_professionals_profiles:\n    print(\n        ' ... Recalculating professionals profiles, this can take about 10 minutes for the complete dataset ... ')\n    professionals_profiles_sparse, df_tags_professionals = create_professionals_profiles(tag_users_professionals_only,\n                                                                                         df_TT_professionals)\n    print(' ... Saving the professionals profiles ... ')\n    sparse.save_npz(\"professionals_profiles.npz\", professionals_profiles_sparse)\nelse:\n    print(' ... Loading the professionals profiles ... ')\n    professionals_profiles_sparse = sparse.load_npz(\"professionals_profiles.npz\")\n    df_tags_professionals = tag_users_professionals_only.pivot_table(index='tag_users_user_id',\n                                                                     columns='tag_users_tag_id', values='dummy').fillna(\n        0)\n    df_tags_professionals = df_tags_professionals.reindex(columns=tag_list,\n                                                          fill_value=0)  # Add all tags (empty columns)\n\ndef costfunction(professionals_profiles_sparse, question_profile_sparse, profs_list):\n    question_profile_sparse = scipy.sparse.vstack([question_profile_sparse] * professionals_profiles_sparse.shape[0])\n    minmatrix = scipy.sparse.csr_matrix.minimum(professionals_profiles_sparse,\n                                                question_profile_sparse) - question_profile_sparse\n    minmatrix.data **= 2  # Square all elements of matrix\n    cost = pd.Series(index=profs_list, data=np.squeeze(np.asarray(np.sum(minmatrix, axis=1))))\n    return cost\n\n\n#recommended_profs = get_best_profs(question_tags, professionals_profiles_reduced, profs_list)\n\ndef get_best_profs(testquestion_tags, professionals_profiles_sparse, profs_list):\n    # Test a question and return the best matching professionals sorted from best to worst\n    question_profile_sparse = scipy.sparse.csr.csr_matrix(get_profile(df_TT_questions, testquestion_tags))\n    profranking = costfunction(professionals_profiles_sparse, question_profile_sparse, profs_list)\n    recommended_profs=profranking.sort_values()\n    return recommended_profs\n\ndf_TT_professionals = None  # Clear for memory\n\ndef merge_question_matrices(emails, matches, questions, answers):\n    email_matches = emails.merge(matches, left_on='emails_id', right_on='matches_email_id',\n                                 how='right').drop('matches_email_id', axis=1)\n    q_and_a = questions.merge(answers, left_on='questions_id', right_on='answers_question_id',\n                              how='outer').drop('answers_question_id', axis=1).sort_values('questions_id')\n    email_QA = pd.merge(email_matches, q_and_a, how='left', left_on=['matches_question_id', 'emails_recipient_id'],\n                        right_on=['questions_id', 'answers_author_id'])\n    email_QA = email_QA.drop(\n        ['emails_id', 'emails_date_sent', 'questions_author_id', 'questions_title', 'answers_id', 'answers_date_added',\n         'emails_frequency_level', 'questions_date_added', 'questions_body', 'answers_body'], axis=1)\n    email_QA['answers_author_id'] = email_QA['answers_author_id'].notna()\n    email_QA = email_QA.set_index('matches_question_id')\n    return email_QA\nemail_QA = merge_question_matrices(emails, matches, questions, answers)\nunique_questions = list(set(email_QA.index))\n\nanswers_reduced = answers.drop(['answers_id', 'answers_date_added', 'answers_body'], axis=1)\nanswers_reduced = answers_reduced.set_index(['answers_question_id'])\n\ndef best_ranking(recommended_profs, profs_list, question, answers_further_reduced):\n    #Returns the value of the best ranked professional of the professionals that replied to the question\n    profs_who_replied = pd.Series(answers_further_reduced['answers_author_id'][question])\n    ranking = pd.DataFrame(recommended_profs).reindex(index=profs_list, columns=['ranking'])\n    ranking['ranking']=range(len(ranking))\n    ranking=ranking.loc[list(profs_who_replied.values),:].dropna()\n    return min(ranking.ranking.values)\n\nprint('... Starting for loop ...')\ndf_output = pd.DataFrame(index = unique_questions, columns=['Ranking model', 'Total sent'])\ndf_tags_professionals['rownumber'] = range(len(df_tags_professionals))  # Add a column with row numbers for allowing lambda function usage\nfor rownr, question in enumerate(unique_questions):\n    question_tags = pd.Series(tag_questions.loc[question,'tag_questions_tag_id']).values\n    if email_QA.loc[question,'answers_author_id'].sum() > 0:\n        execute_ranking = True\n    else:\n        execute_ranking = False\n\n    profs_list = list(email_QA.loc[email_QA.index == question, 'emails_recipient_id'].values)  # The list of professionals who received this question\n    profs_list = list(set(profs_list)) #remove duplicates\n    profs_list = list(np.intersect1d(np.array(profs_list), answers_reduced['answers_author_id'].values)) #Contains only profs who actually answered a question\n    df_output['Total sent'][question] = len(profs_list)\n    if execute_ranking:\n        profindices = df_tags_professionals.reindex(index=profs_list, columns=['rownumber'])[\n            'rownumber'].values  # The row indices of these professionals in the prof lookup table\n        profs_list = list(np.array(profs_list)[~np.isnan(profindices)])\n        answers_further_reduced = answers_reduced.reset_index().set_index('answers_author_id').loc[profs_list,\n                                  :].reset_index().set_index('answers_question_id') #Contains only answers from profs in the prof_list\n        profindices = profindices[~np.isnan(profindices)]\n        professionals_profiles_reduced = professionals_profiles_sparse[profindices]\n        recommended_profs = get_best_profs(question_tags, professionals_profiles_reduced, profs_list)\n\n        df_output['Ranking model'][question] = best_ranking(recommended_profs, profs_list, question, answers_further_reduced)\n    else:\n        '' #A question without answers was encountered\n\ndf_output.to_csv('df_output.csv')\n\n'''\n","f39d4659":"### Graph network for Tags","56c7efed":"#### Activity:\n","8fde6936":"### E-mails & Matches\n","484bd494":"## General outline of the model:\n\n1. Graph network of tags in order to find related tags. Tags are related to each other if they appear in the same question. (this matrix can be recalculated every x-days\/weeks\/months).\n\n2. Calculate a 'fingerprint' for each professional. This list contains the tags that user added to his\/her profile, the ones of the questions he\/she answered, including neighbouring tagss (although they contribute to a lesses extend).\n\n3. For each question: tags that are added by the student are compared to the fingerprints of the professionals.\n* Professionals who have the most tags in common with the question are selected by the algorithm.  ","5c548940":"In the image above, who show the relation between 200 tags. We find that these appear to be clustered. A central topic can have many sub-topics. And these tags will appear together in the questions of students.\n\nOur professionals will not assign all the different 'sub' tags to their profile. To increase our chances of matching a professional with a question we will add two things to our model: \n\n - we will take into account 'neighbouring tags' when matching questions with users.\n - if a professional responds to a certain question, he will 'inherit' the corresponding tags from that question to his profile. In this way we can increase the details of our users knowledge, without the user themselves adding the related sub-tags to his\/her profile.","477ddd86":"We see that after re-ranking the users with our model, the professionals that answered to e-mails are ranked significantly higher. This already cuts back about 50% of the mails that are currently send out. This gives reason to believe that using this model on the full set of professionals, a larger user-response rate can be achieved.","f989ce9f":"### Scoring the model\n\nScoring models in the challenge has proven to be difficult.\nOur approach for having some kind of scoring is to:\n\n* create a ranking for currently used model by cv: mails are send to users in a certain order, we assume that this is the ranking that is constructed by the model careervillage is currently using.\n\n* Re-rank the CV order using our model. If the user that actually replied to a question ranks higher with our model, we can have some confidence that this model is usefull to test in production.\n","edcc35cb":"# Feature Exploration, Engineering and Cleaning\n## General metrics for CV: \n#### Userbase Growth:\n","8e76e0ce":"Below you can find the complete script that:\n* Enriches the profile of professionals with the tags of questions they responded to.\n* Creates a tag-tag relational matrix to take into account neighbours.\n* Creates a 'fingerprint' for each professional\n* Creates a ranking of professionals for a certain question\n* Tests the model by re-ranking the professionals that have been e-mailed by cv.org.","718a1991":"#### Use of Tags","93576975":"For each question, professionals that were e-mailed by cv are re-ranked according to our tag-based recommender system. If users that answered are higher ranked, we can conclude that the model is effective.\n\nNote: \n* this is not a 'real scoring' of the model, as running the model in production will e-mail users that have not been considered before. \n* We import df_output.csv here, this is the file created by the script (complete model) at the end of this notebook.","84e63d99":"## Importing CSV files\n\nFor our initial model, we will keep things simple and focus on the datasets that appear to be revelant for our recommender system.\n\nInformation on the users. Users consist of professionals & students\n- **professionals**.csv: We call our volunteers \"Professionals\", but we might as well call them Superheroes. They're the grown ups who volunteer their time to answer questions on the site.\n- **students**.csv: Students are the most important people on CareerVillage.org. They tend to range in age from about 14 to 24. They're all over the world, and they're the reason we exist!\n- **tag_users**.csv: Users of any type can follow a hashtag. This shows you which hashtags each user follows.\n\n\nCore of our recommendation engine: the Q&A information:\n\n- **questions**.csv: Questions get posted by students. Sometimes they're very advanced. Sometimes they're just getting started. It's all fair game, as long as it's relevant to the student's future professional success.\n\n- **tag_questions**.csv: Every question can be hashtagged. We track the hashtag-to-question pairings, and put them into this file.\n\n- **answers**.csv: Answers are what this is all about! Answers get posted in response to questions. Answers can only be posted by users who are registered as Professionals. However, if someone has changed their registration type after joining, they may show up as the author of an Answer even if they are no longer a Professional.\n\nInformation on the platform: \n\n- **emails**.csv: Each email corresponds to one specific email to one specific recipient. The frequency_level refers to the type of email template which includes immediate emails sent right after a question is asked, daily digests, and weekly digests.\n\n- **matches**.csv: Each row tells you which questions were included in emails. If an email contains only one question, that email's ID will show up here only once. If an email contains 10 questions, that email's ID would show up here 10 times.\n\n- **tags**.csv: Each tag gets a name.\n\n#### Dropped tables:\n\n- group_memberships.csv: Any type of user can join any group. There are only a handful of groups so far.\n- group.csv:  Each group has a \"type\"\n- school_memberships.csv: Just like group_memberships, but for schools instead.\n- comments.csv: Comments can be made on Answers or Questions. We refer to whichever the comment is posted to as the \"parent\" of that comment. Comments can be posted by any type of user. Our favorite comments tend to have \"Thank you\" in them :)\n- question_scores.csv: \"Hearts\" scores for each question.\n- answer_scores.csv: \"Hearts\" scores for each answer.\n\n**","3dced092":"### Scoring of tag-Based recommender system","afa227b8":"## Packages","69d7ba21":"- Symmetric usergrow in professionals and students.\n- On average, 2 answers per question.\n- The tag 'college' is overly used in users, and questions. \n- The effectiveness of sending an email is currently around 1%.","29be28c5":"## Recommender system for CareerVillage\n\n<img src=\"https:\/\/www.ffwd.org\/wp-content\/uploads\/CareerVillage-logo.png\" alt=\"Drawing\" style=\"width: 400px;\"\/>\n\n### Problem Statement\nThe U.S. has almost 500 students for every guidance counselor. Underserved youth lack the network to find their career role models, making CareerVillage.org the only option for millions of young people in America and around the globe with nowhere else to turn.\n\nTo date, 25,000 volunteers have created profiles and opted in to receive emails when a career question is a good fit for them. This is where your skills come in. To help students get the advice they need, the team at CareerVillage.org needs to be able to send the right questions to the right volunteers. The notifications sent to volunteers seem to have the greatest impact on how many questions are answered.\n\n#### Objective: \nDevelop a method to recommend relevant questions to the professionals who are most likely to answer them.","d82a2411":"# Careervillage ranking of professionals\n\n\nWe assume that the ranking that is currently used by careervillage corresponds to time the e-mail was send to a specific professional.\ne.g. 50th person to receive an e-mail from carreervillage about a certain question is ranked '50'.","57f6b5f1":"#### Takeaway from the plots:","4eaa39a9":"# A Tag-based recommender for cv - complete code:","7cb0d3e0":"#### Recommendations for further improving the model:\n\n* Question\/answer scores are not included in our model. If a professional receives a *heart* he should be higher up in the ranking for questions with related tags. \n* Weight of related tags: some tags are more related to each other then others. This can be used to enhance the 'fingerprint' of the professionals.\n* Questions and replies can be scanned for tags.\n\n#### Remarks\n\n* We have removed the tags 'College' and 'Career' from the model. We felt that they were overly used, and can not be used to specify a certain professional.\n\n","02d4ae3e":"Our goal is to use related tags to enrich the profiles of our professionals. This method is only usefull if we can cluster tags around a 'central' topic. The plot below shows that is the case for cv.org: ","57e2b8fd":"## Approach: \n\nThe approach is to develop a model that only takes into account the tags used by professionals and questions.\n\nAfter browsing careervillage.org it became clear that the questions are often very short, which can be hard to process with NLP. Our claim is that e.g. a bag-of-words TFIDF would include a lot of overhead, with minimal improvement over using an efficient tag-matching system.\n\nFurthermore users are free to add new tags in their questions, which make many questions to have very specific tags. Although professionals will be less inclined to add a lot sub-categories to their profile, we including some extra features to our model:\n* For each professional the tags of the questions that he\/she answered are added to his\/her profile when setting up the model.\n* Tags that are closely related to ones in this profile will be added as well, and contribute to a lesser extend when predicting matches.\n"}}