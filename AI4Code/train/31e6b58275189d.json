{"cell_type":{"430df7c3":"code","0be48399":"code","3685d003":"code","1005aceb":"code","9dfac004":"code","f5f59364":"code","3b9fea0c":"code","0cffb165":"code","02bf70a3":"code","d276ffe9":"code","6404fd9e":"code","a057084b":"code","39e01beb":"code","bf72d689":"code","f8591053":"code","110d72fd":"code","6fb779f2":"code","978871aa":"markdown","bc563b85":"markdown"},"source":{"430df7c3":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns\nimport pandas_profiling as pp\nfrom sklearn.metrics import mean_squared_error as mse\nfrom math import sqrt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0be48399":"df = pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')","3685d003":"df.head()","1005aceb":"df.info()","9dfac004":"df = pd.get_dummies(df)\ndf.info()","f5f59364":"df.describe()","3b9fea0c":"pp.ProfileReport(df)","0cffb165":"sns.pairplot(df)","02bf70a3":"#Defining X, y\ny = df.iloc[:, 3].values\ndf = df.drop(['charges'], axis = 1)\nX = df.iloc[:, :].values","d276ffe9":"#Splitting Dataset for training and testing the model\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) ","6404fd9e":"print(\"Shape of X_train:\", X_train.shape)\nprint(\"Shape of X_test:\", X_test.shape)\nprint(\"Shape of Y_train:\", y_train.shape)\nprint(\"Shape of Y_test:\", y_test.shape)","a057084b":"#Multi-Linear Regression\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test) ","39e01beb":"#SVR\nfrom sklearn.svm import SVR\nsvr = SVR(kernel = 'rbf')\nsvr.fit(X_train, y_train)\nsvr_pred = svr.predict(X_test)","bf72d689":"#Decision Tree Regression\nfrom sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(random_state = 0)\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test) ","f8591053":"#Random Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 200, random_state = 0)\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test) ","110d72fd":"#XGB Regression\nfrom xgboost import XGBRegressor\nxgb = XGBRegressor()\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test) ","6fb779f2":"print(\"RMSE valuse for MultiLinear Regression:\", sqrt(mse(y_test, lr_pred)))\nprint(\"RMSE valuse for SVR:\", sqrt(mse(y_test, svr_pred)))\nprint(\"RMSE valuse for Decision Tree Regression:\", sqrt(mse(y_test, dt_pred)))\nprint(\"RMSE valuse for Random Forest Regression:\", sqrt(mse(y_test, rf_pred)))\nprint(\"RMSE valuse for XGB Regression:\", sqrt(mse(y_test, xgb_pred)))","978871aa":"**Regression Model Applied:**\n1. MultiLinear Regression\n2. SVR\n3. Decision Tree Regression\n4. Random Forest Regression\n5. XGB Regression","bc563b85":"**From the above applied regression models we can see clearly that Random Forest Regression gives us the lowest RMSE thus being the most accurate model for this Dataset.\nThus to finally predict a value we will use Random Forest Regression**"}}