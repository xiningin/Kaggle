{"cell_type":{"ff04fff0":"code","2444119f":"code","2427f443":"code","d8ce3c97":"code","4955c5a6":"code","b82bddc1":"code","70707912":"code","11241b32":"code","91086e5d":"code","2a0a399e":"code","ebb8f9d7":"code","c08cb6b7":"code","fd99f0f8":"code","79e8a106":"code","49b86f42":"code","aa601b94":"code","b6067abc":"code","d8f75c73":"code","334742f1":"code","c29ed551":"code","08048604":"code","06626f5f":"code","ac6305d5":"code","0436818c":"code","0d0ec461":"code","d765877a":"markdown","307d14e7":"markdown","ed7fe4b7":"markdown","e104d703":"markdown","f671523a":"markdown","8b0d8581":"markdown","7f2006c7":"markdown","2683b5d8":"markdown","21acc3a3":"markdown","2bbc6f95":"markdown"},"source":{"ff04fff0":"\"\"\" Step 1\nEnvironmental setting before starting.\nInstall the python package 'white-box-layer' with version 0.1.8 via pip command.\"\"\"\n\n!pip install whiteboxlayer==0.1.8","2444119f":"\"\"\" Step 2\nImport the python packages.\nThe purpose of each package is to:\n - os: access to the operating system command \n - glob: access to the file system \n - random: for some random functions such as random shuffling\n - numpy: handing array-like data easily\n - pandas: handling tabular data easily\n - matplotlib: for visualizing the data\n - whiteboxlayer: for constructing the neural network\n - tensorflow: tensorflow is... TensorFlow\n \nThe last line will be used to calculating the computational requirement for using a neural network as FLOPS.\n\n- FLOPS: https:\/\/en.wikipedia.org\/wiki\/FLOPS\"\"\"\n\nimport os, glob, random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport whiteboxlayer.layers as wbl\n\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph","2427f443":"\"\"\" Step 3\nDefine custom python functions.\n\n - sorted_list: for getting list of file system\n - read_csv: for loading the tabular data\n - min_max_norm: for normalizing the data\n \nIt is all for you, take these to your own project. \n:) \"\"\"\n\ndef sorted_list(path):\n    \n    tmplist = glob.glob(path)\n    tmplist.sort()\n    \n    return tmplist\n\ndef read_csv(path):\n    \n    return pd.read_csv(path)\n\ndef min_max_norm(data):\n    \n    return (data - data.min()) \/ (data.max() - data.min())","d8ce3c97":"\"\"\" Step 1\nWe already define the function for file listing.\nNow, we will use that function.\nTake a look! \"\"\"\n\nsorted_list(path=os.path.join('..\/input\/digit-recognizer', '*'))","4955c5a6":"\"\"\" Step 2\nWe have confirmed the list of given data in the above code block.\nThen, we will allocate them as the following three path variables. \"\"\"\n\npath_tr = '..\/input\/digit-recognizer\/train.csv'\npath_te = '..\/input\/digit-recognizer\/test.csv'\npath_sb = '..\/input\/digit-recognizer\/sample_submission.csv'","b82bddc1":"\"\"\" Step 1\nFor confirming the training set, we can use the training path 'path_tr'. \nAlso, we can use the pre-defined function 'read_csv' to load the training set. \"\"\"\n\ndf_tr = read_csv(path=path_tr)\nprint(\"Shape of Training Set:\", df_tr.shape, type(df_tr))","70707912":"\"\"\" Step 2\nThen, we will confirm which contents are contained in the training set. \nDataset is given as tabular style and it has loaded as pandas 'dataframe'. \nThe pandas 'dataframe' supports confirming method for first N samples easily via 'head' command. \"\"\"\n\nN = 10 # Change this value and confirming once more. (this is up-to-you)\ndf_tr.head(N)","11241b32":"\"\"\" Step 3\nThe first column, referring to the above confirmation, contains label information.\nLooking only at that table, we don't know what is the pixel{k} meaning. \nHowever, we can confirm how much information, including label and pixel, are contained in the above table. \nAlso, we can confirm the unique labels via 'set' and 'list' commands. \"\"\"\n\nx_tr = df_tr.drop(columns=['label'], axis=0)\ny_tr = df_tr['label']\nprint(\"Training Data  : \", x_tr.shape)\nprint(\"Training Label : \", y_tr.shape)\n\ny_unique = list(set(list(y_tr)))\nprint(\"Unique Labels  : \", y_unique)","91086e5d":"\"\"\" Step 4\nAlso, we can confirm the quantity for each label and the ratio to the total quantity.\nThe aggregated information can be printed out as text basically.\nFor better and easier confirmation, we can adopt the visualization technique using 'matplotlib'. \"\"\"\n\ndict_subset = {}\nfor label in range(10):\n    df_subset = df_tr[df_tr['label'] == label]\n    num_subset = df_subset.shape[0]\n    dict_subset['%d' %(label)] = num_subset\n    print(\"Label: %d | %d samples (%.3f%% of total)\" %(label, num_subset, num_subset\/x_tr.shape[0]*100))\n\nplt.figure(figsize=(8, 5))\nplt.bar(range(len(dict_subset)), list(dict_subset.values()), align='center')\nplt.xticks(range(len(dict_subset)), list(dict_subset.keys()))\nplt.ylabel('Number of samples')\nplt.xlabel('Class Label')\nplt.grid()\nplt.tight_layout()\nplt.show()","2a0a399e":"\"\"\" Step 5\nThe information for interpreting the meaning of pixel is provided on the following page and we will use them actively. \nwe can transform the 784-pixel information to the 28 x 28 image information.\nhttps:\/\/www.kaggle.com\/c\/digit-recognizer\/data \"\"\"\n\nx_tr = np.asarray(x_tr).reshape((-1, 28, 28, 1))\nprint(\"Training Data (Transformed) : \", x_tr.shape)","ebb8f9d7":"\"\"\" Step 6\nNow, we can visualize the transformed information.\nWe have known the number of the label is 10.\nThus, we will visualize the 10 images that one image to each class. \"\"\"\n\nplt.figure(figsize=(15, 6))\nfor label in range(10):\n    idx = 0\n    while(True):\n        if(y_tr[idx] == label): \n            plt.subplot(2, 5, label+1)\n            plt.imshow(x_tr[idx][:, :, 0], cmap='gray')\n            break\n        idx += 1\nplt.tight_layout()\nplt.show()","c08cb6b7":"\"\"\" Step 7\nSometimes someone may wonder about the whole data.\nHowever, the number of the training set is too large to visualize.\nSo, we will calculate the average image for each class and visualize them. \"\"\"\n\nx_avg = np.zeros((10, 28, 28, 1))\nfor idx, x in enumerate(x_tr):\n    x_avg[y_tr[idx], :, :, :] += x\n\nplt.figure(figsize=(15, 6))\nfor label in range(10):\n    plt.subplot(2, 5, label+1)\n    plt.imshow(x_avg[label, :, :, 0], cmap='gray')\nplt.tight_layout()\nplt.show()","fd99f0f8":"\"\"\" Step 1\nSame process as above but applying to test set. \"\"\"\n\ndf_te = read_csv(path=path_te)\nprint(\"Shape of Test Set:\", df_te.shape)","79e8a106":"\"\"\" Step 2\nFirst N samples of the test set. \"\"\"\n\ndf_te.head(N)","49b86f42":"\"\"\" Step 3\nFor referring to the above confirmation the test set does not contain label information. \nThat is the part we need to fill in by estimating through the training set. \"\"\"\n\nx_te = np.asarray(df_te).reshape((-1, 28, 28, 1))\nprint(\"Test Data (Transformed) : \", x_te.shape)","aa601b94":"\"\"\" Step 4\nWe can't visualize the test set for each label like a process with a training set.\nThus, we simply visualize the first 10 samples as following. \"\"\"\n\nplt.figure(figsize=(15, 6))\nfor idx, x in enumerate(x_te):\n    if(idx >= 10): break\n    plt.subplot(2, 5, idx+1)\n    plt.imshow(x[:, :, 0], cmap='gray')\nplt.tight_layout()\nplt.show()","b6067abc":"\"\"\" Step 1\nCheck the shape of the submission form.\"\"\"\n\ndf_sb = read_csv(path=path_sb)\nprint(\"Shape of Submission:\", df_sb.shape)","d8f75c73":"\"\"\" Step 2\nThen, confirm the first N contents.\nWe will fill the 'Label' column via pixel information of the test set after the training process. \"\"\"\n\ndf_sb.head(N)","334742f1":"\"\"\" Step 1\nWe will construct a training agent including a simple convolutional neural network.\nTraining agent has the function of inference essentially.\nThe agent can calculate loss between the target (label) and the inference result, \nand update the parameters via the backpropagation mechanism.\nPlease check the comments for each function for details. \"\"\"\n\nclass Agent(object):\n\n    def __init__(self, **kwargs):\n        \n        \"\"\" Agent initializer \n         - dim_h: height of the input image \n         - dim_w: width of the input image \n         - dim_c: channel of the input image \n         - num_class: number of the class for inference \n         - learning_rate: learning rate to update parameter \n         - path_ckpt: path for saving the checkpoint \"\"\"\n\n        print(\"\\nInitializing Neural Network...\")\n\n        self.dim_h = kwargs['dim_h']\n        self.dim_w = kwargs['dim_w']\n        self.dim_c = kwargs['dim_c']\n        self.num_class = kwargs['num_class']\n        self.learning_rate = kwargs['learning_rate']\n        self.path_ckpt = kwargs['path_ckpt']\n\n        self.variables = {}\n\n        dummy = tf.zeros((1, self.dim_h, self.dim_w, self.dim_c), dtype=tf.float32)\n        self.__model = Neuralnet(**kwargs) # CNN is here!\n        self.__model.forward(x=dummy, verbose=True)\n        print(\"\\nNum Parameter: %d\" %(self.__model.layer.num_params))\n\n        self.__init_propagation(path=self.path_ckpt)\n\n    def __init_propagation(self, path):\n        \n        \"\"\" Propagation test function\n        Test the propagation and saving the list of learnable parameters.\n        Also, calculating the FLOPs of constructed CNN architecture. \"\"\"\n        \n        self.summary_writer = tf.summary.create_file_writer(self.path_ckpt)\n\n        self.variables['trainable'] = []\n        ftxt = open(\"list_parameters.txt\", \"w\")\n        for key in list(self.__model.layer.parameters.keys()):\n            trainable = self.__model.layer.parameters[key].trainable\n            text = \"T: \" + str(key) + str(self.__model.layer.parameters[key].shape)\n            if(trainable):\n                self.variables['trainable'].append(self.__model.layer.parameters[key])\n            ftxt.write(\"%s\\n\" %(text))\n        ftxt.close()\n\n        self.optimizer = tf.optimizers.Adam(learning_rate=self.learning_rate)\n        self.save_params()\n\n        conc_func = self.__model.__call__.get_concrete_function(\\\n            tf.TensorSpec(shape=(1, self.dim_h, self.dim_w, self.dim_c), dtype=tf.float32))\n        self.__get_flops(conc_func)\n\n    def __loss(self, y, y_hat):\n        \n        \"\"\" Loss function to optimize the neural network \"\"\"\n        \n        entropy_b = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_hat)\n        entropy = tf.math.reduce_mean(entropy_b)\n\n        return {'entropy_b': entropy_b, 'entropy': entropy}\n\n    @tf.autograph.experimental.do_not_convert\n    def step(self, minibatch, iteration=0, training=False):\n        \n        \"\"\" Function for inference and optimization step \n        When the 'training' states 'True', optimization is conducted.\n        In the opposite case, the inference is only conducted.\"\"\"\n        \n        x = minibatch['x']\n        y = minibatch['y']\n\n        with tf.GradientTape() as tape: \n            logit, y_hat = self.__model.forward(x=x, verbose=False)\n            losses = self.__loss(y=y, y_hat=logit)\n\n        if(training): # apply gradient for backpropagation\n            gradients = tape.gradient(losses['entropy'], self.variables['trainable'])\n            self.optimizer.apply_gradients(zip(gradients, self.variables['trainable']))\n\n            with self.summary_writer.as_default():\n                tf.summary.scalar('%s\/entropy' %(self.__model.who_am_i), losses['entropy'], step=iteration)\n\n        return {'y_hat':y_hat, 'losses':losses}\n\n    def __get_flops(self, conc_func):\n    \n        \"\"\" Function for calculating the FLOPs \"\"\"\n        \n        frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(conc_func)\n\n        with tf.Graph().as_default() as graph:\n            tf.compat.v1.graph_util.import_graph_def(graph_def, name='')\n\n            run_meta = tf.compat.v1.RunMetadata()\n            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n            flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n\n            flop_tot = flops.total_float_ops\n            ftxt = open(\"flops.txt\", \"w\")\n            for idx, name in enumerate(['', 'K', 'M', 'G', 'T']):\n                text = '%.3f [%sFLOPS]' %(flop_tot\/10**(3*idx), name)\n                print(text)\n                ftxt.write(\"%s\\n\" %(text))\n            ftxt.close()\n\n    def save_params(self, model='base', tflite=False):\n        \n        \"\"\" Function for saving the checkpoint\n        This function also supprots to save the model as 'TF-Lite' format. \"\"\"\n        \n        if(tflite):\n            # https:\/\/github.com\/tensorflow\/tensorflow\/issues\/42818\n            conc_func = self.__model.__call__.get_concrete_function(\\\n                tf.TensorSpec(shape=(1, self.dim_h, self.dim_w, self.dim_c), dtype=tf.float32))\n            converter = tf.lite.TFLiteConverter.from_concrete_functions([conc_func])\n\n            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n            converter.experimental_new_converter = True\n            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n\n            tflite_model = converter.convert()\n\n            with open('model.tflite', 'wb') as f:\n                f.write(tflite_model)\n        else:\n            vars_to_save = self.__model.layer.parameters.copy()\n            vars_to_save[\"optimizer\"] = self.optimizer\n\n            ckpt = tf.train.Checkpoint(**vars_to_save)\n            ckptman = tf.train.CheckpointManager(ckpt, directory=os.path.join(self.path_ckpt, model), max_to_keep=1)\n            ckptman.save()\n\n    def load_params(self, model):\n        \n        \"\"\" Function for loading the model via checkpoint \"\"\"\n        \n        vars_to_load = self.__model.layer.parameters.copy()\n        vars_to_load[\"optimizer\"] = self.optimizer\n\n        ckpt = tf.train.Checkpoint(**vars_to_load)\n        latest_ckpt = tf.train.latest_checkpoint(os.path.join(self.path_ckpt, model))\n        status = ckpt.restore(latest_ckpt)\n        status.expect_partial()\n\nclass Neuralnet(tf.Module):\n\n    def __init__(self, **kwargs):\n        super(Neuralnet, self).__init__()\n        \n        \"\"\" Neural network initializer \n         - who_am_i: indicating who I am \n         - dim_h: height of the input image \n         - dim_w: width of the input image \n         - dim_c: channel of the input image \n         - num_class: number of the class for inference \n         - filters: to construct the feature map for each layer \"\"\"\n        \n        self.who_am_i = \"CNN\"\n        self.dim_h = kwargs['dim_h']\n        self.dim_w = kwargs['dim_w']\n        self.dim_c = kwargs['dim_c']\n        self.num_class = kwargs['num_class']\n        self.filters = [1, 32, 64, 128]\n\n        self.layer = wbl.Layers() # initializing the white-box-layer object\n\n        self.forward = tf.function(self.__call__)\n\n    @tf.function\n    def __call__(self, x, verbose=False):\n\n        logit = self.__nn(x=x, name=self.who_am_i, verbose=verbose)\n        y_hat = tf.nn.softmax(logit, name=\"y_hat\")\n\n        return logit, y_hat\n\n    def __nn(self, x, name='neuralnet', verbose=True):\n\n        for idx, _ in enumerate(self.filters[:-1]): # Covolutional layers\n            if(idx == 0): continue\n            x = self.layer.conv2d(x=x, stride=1, \\\n                filter_size=[3, 3, self.filters[idx-1], self.filters[idx]], batch_norm=True, \\\n                activation='relu', name='%s-%dconv' %(name, idx), verbose=verbose)\n            x = self.layer.maxpool(x=x, ksize=2, strides=2, \\\n                name='%s-%dmp' %(name, idx), verbose=verbose)\n\n        x = tf.reshape(x, shape=[x.shape[0], -1], name=\"flat\") # Fully-connected layers\n        x = self.layer.fully_connected(x=x, c_out=self.filters[-1], \\\n                activation='relu', name=\"%s-clf0\" %(name), verbose=verbose)\n        x = self.layer.fully_connected(x=x, c_out=self.num_class, \\\n                activation=None, name=\"%s-clf1\" %(name), verbose=verbose)\n\n        return x","c29ed551":"\"\"\" Step 2\nSet the gpu environment \"\"\"\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)","08048604":"\"\"\" Step 3\nInitialize the agent.\"\"\"\n\nagent = Agent(\\\n    dim_h=28, \\\n    dim_w=28, \\\n    dim_c=1, \\\n    num_class=10, \\\n    learning_rate=5e-4, \\\n    path_ckpt='Checkpoint')","06626f5f":"\"\"\" Step 4\nWe need to define the function for parsing the given dataset.\nThe essential requirements are the following.\n - split (or extract) some of the samples from the whole set \n - parsing each sample into pixel data and label (in the test set only use pixel data)\n - transform the pixel vector to image (matrix) \n - flag and variable for checking that all data is used up \"\"\"\n\ndef next_batch(df, idx, batch_size):\n    \n    batch_x, batch_y, batch_id, terminate = [], [], [], False\n    while(True):\n        \n        try: tmp_row = df.iloc[idx]\n        except: \n            idx = 0\n            terminate = True\n            break\n        else:\n            try: \n                batch_y.append(np.diag(np.ones(10))[tmp_row['label']])\n                tmp_x = tmp_row[1:]\n            except: \n                batch_y.append(np.diag(np.ones(10))[0])\n                tmp_x  = tmp_row\n            tmp_x = np.asarray(tmp_x).reshape((28, 28, 1))\n            batch_x.append(tmp_x)\n            batch_id.append(idx)\n            \n            idx += 1\n            if(len(batch_x) == batch_size): break\n    \n    batch_x = np.asarray(batch_x)\n    batch_y = np.asarray(batch_y)\n    \n    return {'x':batch_x.astype(np.float32), 'y':batch_y.astype(np.float32), 'id':batch_id, 'terminate':terminate, 'idx':idx}","ac6305d5":"\"\"\" Step 5\nNow, we can start learning.\nNote that, This example does not fully complete finding the best hyperparameters.\nFine-tuning is up to you. \nAlways good luck to you! \"\"\"\n\nepochs, batch_size = 10, 32\niteration = 0\nfor epoch in range(epochs):\n    \n    idx, list_loss = 0, []\n    while(True):\n        minibatch = next_batch(df=df_tr, idx=idx, batch_size=batch_size)\n        idx, terminate = minibatch['idx'], minibatch['terminate']\n        \n        step_dict = agent.step(minibatch=minibatch, iteration=iteration, training=True)\n        list_loss.append(step_dict['losses']['entropy'])\n        if(iteration % 100 == 0): print(\" Iteration %10d | Loss: %.5f\" %(iteration, step_dict['losses']['entropy']))\n        iteration += 1\n        \n        del minibatch\n        if(terminate): break\n        \n    loss = np.average(np.asarray(list_loss))\n    print(\"Epoch [%d \/ %d] | Loss: %.5f\" %(epoch+1, epochs, loss))\n    \n    agent.save_params(model='model_0')\nagent.save_params(tflite=True)","0436818c":"idx = 0\nwhile(True):\n    minibatch = next_batch(df=df_te, idx=idx, batch_size=batch_size)\n    idx = minibatch['idx']\n    if(len(minibatch['x']) == 0): break\n    if(idx % (batch_size*20) == 0): print(\"Progress [%d\/%d] (%.2f%%)\" %(idx, df_sb.shape[0], idx\/df_sb.shape[0]))\n\n    step_dict = agent.step(minibatch=minibatch, training=False)\n\n    for idx_id, tmp_id in enumerate(minibatch['id']): # fill the answer to the submission sheet\n        df_sb.loc[df_sb['ImageId'] == tmp_id, 'Label'] = np.argmax(step_dict['y_hat'][idx_id])\n\n    if(minibatch['terminate']): break","0d0ec461":"df_sb.to_csv('submission.csv', index=False)","d765877a":"# 2. Exploratory data analysis (EDA)\nFor solving the main task, we will check how the data constructed with.  \nIn this source code, we will simply check where the data is and what it looks like.  \nWe support and believe that in the future you will be able to reflect your own style to the EDA process, such as statistical analysis of data.  ","307d14e7":"# 3. Training the neural network\nIn this section, we will define the neural network and training them.  \nThe convolutional neural network is widely used in the image recognition process because of:  \n* State-of-the-art performance\n* Easily data-driven training.  ","ed7fe4b7":"## 2.1 Confirm list of given data","e104d703":"# 4. Test using the neural network\nFinally we are almost at the end.  \nThe test is performed through a trained neural network, CNN.","f671523a":"## 2.3 Confirm the test set","8b0d8581":"# 1. Preparation\nWe will call some python packages, and define some custom functions in this section.  \nAlso, we will use an additional package called <a href=\"https:\/\/github.com\/YeongHyeon\/white-box-layer\">white-box-layer<\/a> that helps us configure our TensorFlow models a little easier.","7f2006c7":"# 5. Save the answer!\n","2683b5d8":"## 2.2 Confirm the training set","21acc3a3":"# 0. Introduction\nWelcome back kagglers and also welcome to join the competition'<a href=\"https:\/\/www.kaggle.com\/c\/digit-recognizer\">Digit-Recognizer<\/a>'!\n\n\nThe essential goal of this competition is to achieve state-of-the-art classification performance at the digit recognizing task.  \nHowever, the goal of this source code is to help beginners getting involve to this competition and encouraging for their efforts.  \nThis source code provides the full package including exploratory data analysis (EDA) and example solution for solving the digit recognizing task as following.  \n\n* Exploratory data analysis (EDA)\n* Deep neural network for recognizing 10 kinds of digits.\n* Function to parse dataset as mini-batch\n* Training and Test procedure\n* Submission making\n\nTry this source code and upvote if you like it! Have a nice day and good luck to you.","2bbc6f95":"## 2.4 Confirm the submission sheet\nWe are required to fill out and submit a submission sheet form as an assignment for this task.  \nWe will check the above sheet in this section."}}