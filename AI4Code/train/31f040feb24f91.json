{"cell_type":{"fef6bd01":"code","f93febd4":"code","9feec59f":"code","64d80320":"code","6be5c348":"code","ad7f84a6":"code","a680a618":"code","f6c88552":"code","24d09466":"code","ed2ebc92":"code","d33963f9":"code","50f66f1c":"code","9081e396":"code","777cda3e":"code","995e61d4":"code","a712aa8f":"code","49a20b92":"code","1bdb0ba7":"code","a3c4448c":"code","e587f107":"code","36d59932":"code","75bd5b53":"code","829b79b3":"code","928ee886":"code","6303d2b0":"code","2412abc7":"code","b953946c":"code","a0b451a2":"code","54be2d96":"code","5d6528c7":"code","a6bb3448":"code","c13c3b31":"markdown","a4a34c53":"markdown","ef3f2130":"markdown","da09146b":"markdown","128180da":"markdown","d3969962":"markdown","fd2d3a59":"markdown","596da908":"markdown","276e13ac":"markdown","dc71e152":"markdown","4d815436":"markdown","eea48349":"markdown","4d0e22b4":"markdown","204f1ca3":"markdown","a747b081":"markdown","3377728e":"markdown"},"source":{"fef6bd01":"!conda update --all -y","f93febd4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom scipy import stats\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom scipy.stats.mstats import winsorize\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import set_config\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, MaxAbsScaler\nfrom sklearn.metrics import mean_squared_error, explained_variance_score\nfrom sklearn.linear_model import RidgeCV, Ridge, LassoCV\nfrom sklearn.ensemble import VotingRegressor, GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor, StackingRegressor\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom xgboost import XGBRegressor","9feec59f":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (25, 15)\nset_config(display='diagram')","64d80320":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndata.drop(columns=['Id'], inplace=True)\ndata.head()","6be5c348":"data.columns[data.isna().any()].tolist()","ad7f84a6":"data.info()","a680a618":"data['MasVnrType'] = data['MasVnrType'].replace(np.nan, data.MasVnrType.value_counts().index[0])\ndata['Electrical'] = data['Electrical'].replace(np.nan, data.Electrical.value_counts().index[0])","f6c88552":"columns = data.drop(['SalePrice'], axis=1).columns\nnonObjCols = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object']).columns\ntoScale1 = [key for key, val in (data[nonObjCols].quantile(0.75) == 0.0).to_dict().items() if val == True] \ntoScale2 = [val for val in nonObjCols if val not in toScale1]\nObjCols = data.select_dtypes(include=['object']).columns","24d09466":"numeric_features2 = toScale2\nnumeric_transformer2 = Pipeline(steps=[\n    ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')), \n    ('scaler', RobustScaler())])\n\nnumeric_features1 = toScale1\nnumeric_transformer1 = Pipeline(steps=[\n    ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')), \n    ('scaler', MaxAbsScaler())]) \ncategorical_features = ObjCols\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('numerical1', numeric_transformer1, numeric_features1),\n        ('numerical2', numeric_transformer2, numeric_features2),\n        ('categorical', categorical_transformer, categorical_features)],\n        remainder='drop')","ed2ebc92":"X = data.loc[:, data.columns != 'SalePrice']\ny = data.SalePrice","d33963f9":"ScaleTarget = RobustScaler()","50f66f1c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=18)\ny_train = ScaleTarget.fit_transform(y_train.values.reshape(-1,1))\ny_test = ScaleTarget.transform(y_test.values.reshape(-1,1))","9081e396":"def prediction(X_train, y_train, X_test, y_test, estimator):\n        \n    print (\": Metrics of estimator: \", estimator, \"\\n\")\n    \n    pipe = Pipeline([('preprocessor', preprocessor), ('estimator', estimator)], verbose=True)\n    pipe.fit(X_train, y_train.ravel())\n    pred = pipe.predict(X_test)\n    \n    rmse = mean_squared_error(y_test, pred, squared = False)\n    print(\"RMSE: %.4f\" % rmse)\n    evs = explained_variance_score(y_test, pred)\n    print(\"EVS: %.4f\" % evs)\n    score = pipe.score(X_test, y_test)\n    print(\"Score: %.4f\" % score)\n\n    MAX = 200\n    x = range(len(pred))[0:MAX]\n    plt.scatter(x,y_test[0:MAX],color='g', linewidths=5, label='Actual')\n    plt.scatter(x,pred[0:MAX],color='r', linewidths=3, label='Predicted')\n    plt.plot(pred[0:MAX], color = 'r', linewidth=2)\n    plt.ylabel('Sale Price', fontsize=15)\n    plt.title(estimator, fontsize=20)\n    plt.legend(loc =\"upper right\", fontsize=20)\n    plt.show()\n        \n    return pipe","777cda3e":"ridge = prediction(X_train, y_train, X_test, y_test, Ridge(alpha=16))","995e61d4":"ridgecv = prediction(X_train, y_train, X_test, y_test, RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10]))","a712aa8f":"randomforest = prediction(X_train, y_train, X_test, y_test, RandomForestRegressor(n_estimators=800, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=50, bootstrap=False, random_state=2, n_jobs=-1))","49a20b92":"xgb = prediction(X_train, y_train, X_test, y_test, XGBRegressor(n_jobs=-1))","1bdb0ba7":"gradientboost = prediction(X_train, y_train, X_test, y_test, GradientBoostingRegressor(n_estimators=400,learning_rate=0.1,max_depth=2,subsample=1,random_state=1))","a3c4448c":"lassocv = prediction(X_train, y_train, X_test, y_test, LassoCV(cv=10, n_jobs=-1))","e587f107":"estimators = [('ridge', ridge), ('ridgecv', ridgecv), ('lassocv', lassocv), ('randomforest', randomforest), ('xgb', xgb), ('gradientboost', gradientboost)]\nsr = StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=800, random_state=42, n_jobs=-1), n_jobs=-1, cv = 10)\n\nsr.fit(X_train, y_train.ravel())\npred = sr.predict(X_test)\n\nrmse = mean_squared_error(y_test, pred, squared = False)\nprint(\"RMSE: %.4f\" % rmse)\nevs = explained_variance_score(y_test, pred)\nprint(\"EVS: %.4f\" % evs)\nscore = sr.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)\n\nMAX = 200\nx = range(len(pred))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5, label='Actual')\nplt.scatter(x,pred[0:MAX],color='r', linewidths=3, label='Predicted')\nplt.plot(pred[0:MAX], color = 'r', linewidth=2)\nplt.ylabel('Sale Price', fontsize=15)\nplt.title(sr, fontsize=20)\nplt.legend(loc =\"upper right\", fontsize=20)\nplt.show()","36d59932":"sr","75bd5b53":"estimators = [('ridge', ridge), ('ridgecv', ridgecv), ('lassocv', lassocv), ('stacked', sr), ('randomforest', randomforest), ('xgboost', xgb), ('gradientboost', gradientboost)]\n# vr = VotingRegressor(estimators=estimators, weights=[Weights['ridge'], Weights['ridgecv'], Weights['stacked'], Weights['randomforest'], Weights['xgboost'], Weights['gradientboost']], n_jobs=-1)\nvr = VotingRegressor(estimators=estimators, n_jobs=-1) # Gave better result than above\n\nvr.fit(X_train, y_train.ravel())\npred = vr.predict(X_test)\nrmse = mean_squared_error(y_test, pred, squared = False)\nprint(\"RMSE: %.4f\" % rmse)\nevs = explained_variance_score(y_test, pred)\nprint(\"EVS: %.4f\" % evs)\nscore = vr.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)\n\nMAX = 200\nx = range(len(pred))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5, label='Actual')\nplt.scatter(x,pred[0:MAX],color='r', linewidths=3, label='Predicted')\nplt.plot(pred[0:MAX], color = 'r', linewidth=2)\nplt.ylabel('Sale Price', fontsize=15)\nplt.title(vr, fontsize=20)\nplt.legend(loc =\"upper right\", fontsize=20)\nplt.show()","829b79b3":"vr","928ee886":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","6303d2b0":"id_values = data.Id.values","2412abc7":"data['MasVnrType'] = data['MasVnrType'].replace(np.nan, data.MasVnrType.value_counts().index[0])\ndata['Electrical'] = data['Electrical'].replace(np.nan, data.Electrical.value_counts().index[0])","b953946c":"pred = vr.predict(data.drop(['Id'], axis=1))\npred = ScaleTarget.inverse_transform(pred.reshape(-1,1))","a0b451a2":"result = pd.DataFrame(id_values, columns=['Id'])","54be2d96":"result['SalePrice'] = pred","5d6528c7":"result","a6bb3448":"result.to_csv(\"Result_p.csv\", index=False)","c13c3b31":"**List out all the features in the data that have undefined values**","a4a34c53":"**Gradient Boost**","ef3f2130":"**Ridge**","da09146b":"**Ridge CV**","128180da":"**XGBoost**","d3969962":"**VotingRegressor**","fd2d3a59":"**StackingRegressor**","596da908":"**Pipelining**","276e13ac":"**Lasso CV**","dc71e152":"**Replace the NaN values  (Note: Not all NA are invalid)**","4d815436":"**Splitting data into Train and Test sets**","eea48349":"**Libraries used**","4d0e22b4":"**RandomForest**","204f1ca3":"**Read the input file nd display contents**","a747b081":"**Prediction**","3377728e":"# House Price Prediction-(Pipeline Method) "}}