{"cell_type":{"bec516ba":"code","167b30b5":"code","833d98f8":"code","05190eec":"code","1da32421":"code","96f7dfd7":"code","49bb433d":"code","f6eefb1b":"code","99d5a003":"code","a8d17495":"code","8f10c3a2":"code","763a970e":"code","583f0955":"code","2098ac12":"code","10933d3b":"code","631b0e06":"code","25063134":"code","f3f6507d":"code","672629f0":"code","d64288e5":"code","b2d9d337":"code","85cc93ba":"code","5c7d9cc0":"code","fd8224a3":"code","17369ec3":"code","5270b53c":"code","456c0d63":"code","659c257d":"code","74a06303":"code","c15e4725":"code","dbdf9ea4":"code","a26fcbdc":"code","7a392898":"code","cb0780ed":"code","55985666":"code","85f39209":"code","9644ec50":"code","550c26a7":"code","28b36402":"code","18c2a6e3":"code","113bff0c":"code","e13582fb":"code","af5052a2":"code","7fb596b1":"code","30e57aa9":"code","392d9158":"code","601872f3":"code","ed0dee42":"code","5ca44d00":"code","e8b6a5fc":"code","65118558":"code","bbaccb53":"code","95a9af9e":"code","8dbd0410":"code","464cf518":"code","042e8d54":"markdown","9e01bb50":"markdown","2d2eb909":"markdown","e840818e":"markdown","9c88e38b":"markdown","bb4bfec0":"markdown","146c2664":"markdown","141f6569":"markdown","40e1bfb4":"markdown","49bf7257":"markdown","bf90b534":"markdown","42bfc8b9":"markdown","8b4a7814":"markdown","adc245dd":"markdown","a032a63f":"markdown","8a63281d":"markdown","9aa95e3d":"markdown","097d38ad":"markdown","1ca4acf7":"markdown","75cc09ec":"markdown","d7735f95":"markdown","822f0f73":"markdown","6ca81379":"markdown","599b348b":"markdown","dbc141af":"markdown"},"source":{"bec516ba":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\n# Warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","167b30b5":"column_name = [\"MPG\", \"Cylinders\", \"Displacement\", \"Horsepower\",\"Weight\",\"Acceleration\",\"Model Year\",\"Origin\"]","833d98f8":"df_raw = pd.read_csv(\"..\/input\/autompg-data\/auto-mpg.data\", names = column_name, na_values = \"?\", comment = \"\\t\",sep = \" \", skipinitialspace = True)","05190eec":"data = df_raw.copy()","1da32421":"data.head()","96f7dfd7":"data = data.rename(columns = {\"MPG\":\"target\"})","49bb433d":"data.head()","f6eefb1b":"data.shape","99d5a003":"data.info()","a8d17495":"#Horsepower i\u00e7erisinde 6 tane missing value var \n#Kategorik veri yok, daha sonra origin kategorik olmal\u0131","8f10c3a2":"data.describe()","763a970e":"# in acceleration little bit skewness\n\n#model year no skewness\n\n#displacement, horsepower, target, cylinder have skewness\n\n","583f0955":"data.isna().sum()","2098ac12":"sns.distplot(data.Horsepower);","10933d3b":"data.isna().sum()","631b0e06":"data[\"Horsepower\"] = data[\"Horsepower\"].fillna(data[\"Horsepower\"].mean())","25063134":"data.isna().sum()","f3f6507d":"sns.distplot(data.Horsepower);","672629f0":"for feature in data.select_dtypes(\"number\").columns:\n    if feature == \"model_year\":\n        continue\n    plt.figure(figsize=(16,5))\n    sns.distplot(data[feature], hist_kws={\"rwidth\": 0.9})\n    plt.xlim(data[feature].min(), data[feature].max())\n    data[feature].plot(kind=\"hist\", rwidth=0.9, bins=50)\n    plt.title(f\"{feature.capitalize()}\")\n    plt.tight_layout()\n    plt.show()","d64288e5":"corr_matrix = data.corr()\nsns.clustermap(corr_matrix, annot = True, fmt = \".2f\")\nplt.title(\"Correlation Between Features\")\nplt.show()","b2d9d337":"threshold = 0.75\nfiltre = np.abs(corr_matrix[\"target\"])>threshold\ncorr_features = corr_matrix.columns[filtre].tolist()\nsns.clustermap(data[corr_features].corr(), annot = True, fmt = \".2f\")\nplt.show()","85cc93ba":"sns.pairplot(data, diag_kind = \"kde\", markers = \"+\")\nplt.show()","5c7d9cc0":"sns.countplot(data[\"Cylinders\"]);\nprint(data[\"Cylinders\"].value_counts())","fd8224a3":"sns.countplot(data[\"Origin\"]);\nprint(data[\"Origin\"].value_counts())","17369ec3":"#boxplot\nfor c in data.columns:\n    plt.figure()\n    sns.boxplot( x = c, data = data, orient = \"v\")\n","5270b53c":"## BoxPlot\n\nth = 2\n\nQ1_acc = data[\"Acceleration\"].quantile(0.25)\nQ3_acc = data[\"Acceleration\"].quantile(0.75)\nIQR_acc = Q3_acc - Q1_acc \n\nlower_bound_acc = Q1_acc - th * IQR_acc\nupper_bound_acc = Q3_acc + th * IQR_acc\n\noutliers_lower_vector_acc = (data[\"Acceleration\"] < (lower_bound_acc))\noutliers_upper_vector_acc = (data[\"Acceleration\"] > (upper_bound_acc))\noutliers_vector_acc = (outliers_lower_vector_acc) | (outliers_upper_vector_acc)\n#outliers_vector_acc = (data[\"Acceleration\"] < lower_bound_acc) | (data[\"Acceleration\"] > upper_bound_acc)\n\nprint(\"Total Sample Size : \", data[\"Acceleration\"].shape[0])\nprint(\"Lower Bound : \", \"%.2f\" %(lower_bound_acc))\nprint(\"Upper Bound : \", \"%.2f\" %(upper_bound_acc))\nprint(\"Total Outlier for Threshold {} * IQR : \".format(th), data[\"Acceleration\"][outliers_vector_acc].shape[0])","456c0d63":"#Boxplot \n\nth = 2\n\nQ1_hp = data[\"Horsepower\"].quantile(0.25)\nQ3_hp = data[\"Horsepower\"].quantile(0.75)\nIQR_hp = Q3_hp - Q1_hp\n\nlower_bound_hp = Q1_hp - th * IQR_hp\nupper_bound_hp = Q3_hp + th * IQR_hp\n\noutliers_lower_vector_hp = ( data[\"Horsepower\"] < (lower_bound_hp))\noutliers_upper_vector_hp = ( data[\"Horsepower\"] > (upper_bound_hp))\noutliers_vector_hp = (outliers_lower_vector_hp) | (outliers_upper_vector_hp)\n\n\nprint(\"Total Sample Size :\", data[\"Horsepower\"].shape[0])\nprint(\"Lower Bound : \", \"%.2f\" % (lower_bound_hp))\nprint(\"Upper Bound : \", \"%.2f\" % (upper_bound_hp))\nprint(\"Total Outlier for Threshold {} * IQR :\".format(th), data[\"Horsepower\"][outliers_vector_hp].shape[0])","659c257d":"data = data[~outliers_vector_acc]","74a06303":"data = data[~outliers_vector_hp]","c15e4725":"data.shape","dbdf9ea4":"#target dependent variable\n\nsns.distplot(data.target, fit = norm);","a26fcbdc":"(mu, sigma) = norm.fit(data[\"target\"])\nprint(\"mu : {} | sigma : {}\".format(mu,sigma))","7a392898":"plt.figure()\nstats.probplot(data[\"target\"], plot = plt)\nplt.show()","cb0780ed":"data[\"target\"] = np.log1p(data[\"target\"])","55985666":"sns.distplot(data.target, fit = norm);","85f39209":"plt.figure()\nstats.probplot(data[\"target\"], plot = plt)\nplt.show()","9644ec50":"# Independent Variables\n\nskewed_feats = data.apply(lambda x: skew(x.dropna())).sort_values(ascending = False )\n\nskewness = pd.DataFrame(skewed_feats, columns=[\"skewed_feats\"])","550c26a7":"skewness","28b36402":"data[\"Cylinders\"] = data[\"Cylinders\"].astype(str)  \ndata[\"Origin\"] = data[\"Origin\"].astype(str)\n\ndata = pd.get_dummies(data)","18c2a6e3":"data.head()","113bff0c":"x = data.drop([\"target\"], axis = 1)\ny = data.target","e13582fb":"test_size = 0.2\nX_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size = test_size, random_state = 42)","af5052a2":"print(\"X train shape : {} | X test shape : {} \\nY train shape : {} | Y test shape : {} \".format(X_train.shape[0],X_test.shape[0],Y_train.shape[0],Y_test.shape[0]))","7fb596b1":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","30e57aa9":"lr = LinearRegression()\nlr.fit(X_train, Y_train)\nprint(\"LR Coef: \",lr.coef_)\ny_predicted_dummy = lr.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"Linear Regression MSE: \",mse)\n","392d9158":"ridge = Ridge(random_state =42, max_iter = 10000)","601872f3":"alphas = np.logspace(-4,-0.5,30)\ntuned_parameters = [{\"alpha\":alphas}]\nn_folds = 5\n\nclf = GridSearchCV(ridge, tuned_parameters, cv = n_folds, scoring = \"neg_mean_squared_error\", refit = True)\nclf.fit(X_train, Y_train)\nscores = clf.cv_results_[\"mean_test_score\"]\nscores_std = clf.cv_results_[\"std_test_score\"]\n\nprint(\"Ridge Coef : \",clf.best_estimator_.coef_)\n\nridge = clf.best_estimator_\n\nprint(\"Ridge Best Estimator : \", ridge)\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\n\nprint(\"Ridge MSE : \",mse)\nprint(\"-------------------------\")\n\nplt.figure()\nplt.semilogx(alphas, scores)\nplt.xlabel(\"alpha\")\nplt.ylabel(\"score\")\nplt.title(\"Ridge\")","ed0dee42":"lasso = Lasso(random_state=42, max_iter=10000)\nalphas = np.logspace(-4, -0.5, 30)\n\ntuned_parameters = [{'alpha': alphas}]\nn_folds = 5\n\nclf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, scoring='neg_mean_squared_error',refit=True)\nclf.fit(X_train,Y_train)\nscores = clf.cv_results_['mean_test_score']\nscores_std = clf.cv_results_['std_test_score']\n\nprint(\"Lasso Coef: \",clf.best_estimator_.coef_)\nlasso = clf.best_estimator_\nprint(\"Lasso Best Estimator: \",lasso)\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test,y_predicted_dummy)\nprint(\"Lasso MSE: \",mse)\nprint(\"---------------------------------------------------------------\")\n\nplt.figure()\nplt.semilogx(alphas, scores)\nplt.xlabel(\"alpha\")\nplt.ylabel(\"score\")\nplt.title(\"Lasso\")","5ca44d00":"parametersGrid = {\"alpha\": alphas,\n                  \"l1_ratio\": np.arange(0.0, 1.0, 0.05)}\n\neNet = ElasticNet(random_state=42, max_iter=10000)\nclf = GridSearchCV(eNet, parametersGrid, cv=n_folds, scoring='neg_mean_squared_error', refit=True)\nclf.fit(X_train, Y_train)\n\n\nprint(\"ElasticNet Coef: \",clf.best_estimator_.coef_)\nprint(\"ElasticNet Best Estimator: \",clf.best_estimator_)\n\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test,y_predicted_dummy)\nprint(\"ElasticNet MSE: \",mse)","e8b6a5fc":"scaler = RobustScaler() \nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","65118558":"lr = LinearRegression()\nlr.fit(X_train, Y_train)\nprint(\"LR Coef: \",lr.coef_)\ny_predicted_dummy = lr.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"Linear Regression MSE: \",mse)\n","bbaccb53":"ridge = Ridge(random_state =42, max_iter = 10000)","95a9af9e":"alphas = np.logspace(-4,-0.5,30)\ntuned_parameters = [{\"alpha\":alphas}]\nn_folds = 5\n\nclf = GridSearchCV(ridge, tuned_parameters, cv = n_folds, scoring = \"neg_mean_squared_error\", refit = True)\nclf.fit(X_train, Y_train)\nscores = clf.cv_results_[\"mean_test_score\"]\nscores_std = clf.cv_results_[\"std_test_score\"]\n\nprint(\"Ridge Coef : \",clf.best_estimator_.coef_)\n\nridge = clf.best_estimator_\n\nprint(\"Ridge Best Estimator : \", ridge)\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\n\nprint(\"Ridge MSE : \",mse)\nprint(\"-------------------------\")\n\nplt.figure()\nplt.semilogx(alphas, scores)\nplt.xlabel(\"alpha\")\nplt.ylabel(\"score\")\nplt.title(\"Ridge\")","8dbd0410":"lasso = Lasso(random_state=42, max_iter=10000)\nalphas = np.logspace(-4, -0.5, 30)\n\ntuned_parameters = [{'alpha': alphas}]\nn_folds = 5\n\nclf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, scoring='neg_mean_squared_error',refit=True)\nclf.fit(X_train,Y_train)\nscores = clf.cv_results_['mean_test_score']\nscores_std = clf.cv_results_['std_test_score']\n\nprint(\"Lasso Coef: \",clf.best_estimator_.coef_)\nlasso = clf.best_estimator_\nprint(\"Lasso Best Estimator: \",lasso)\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test,y_predicted_dummy)\nprint(\"Lasso MSE: \",mse)\nprint(\"---------------------------------------------------------------\")\n\nplt.figure()\nplt.semilogx(alphas, scores)\nplt.xlabel(\"alpha\")\nplt.ylabel(\"score\")\nplt.title(\"Lasso\")","464cf518":"parametersGrid = {\"alpha\": alphas,\n                  \"l1_ratio\": np.arange(0.0, 1.0, 0.05)}\n\neNet = ElasticNet(random_state=42, max_iter=10000)\nclf = GridSearchCV(eNet, parametersGrid, cv=n_folds, scoring='neg_mean_squared_error', refit=True)\nclf.fit(X_train, Y_train)\n\n\nprint(\"ElasticNet Coef: \",clf.best_estimator_.coef_)\nprint(\"ElasticNet Best Estimator: \",clf.best_estimator_)\n\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test,y_predicted_dummy)\nprint(\"ElasticNet MSE: \",mse)","042e8d54":"### Q-Q Plot","9e01bb50":"**Models**\n* Linear Regression\n* Ridge Regression\n* Lasso Regression\n* ElasticNet","2d2eb909":"#NOTES : \n- Target : Right skewed, Pozitive skewness\n- Cylinders : can be considered categorically\n- Displacement, horsepower, weight negative correlation between dependent variable \"target\"  \n- Origin : can be considered categorically.\n- Horsepower - weight graph might be outliers","e840818e":"## Feature Engineering","9c88e38b":"## Lasso Regression Model","bb4bfec0":"# Split - Standardization","146c2664":"## IQR ","141f6569":"## Lasso Regression Model","40e1bfb4":"# Regression Models\n## Linear Regression Model","49bf7257":"## Standardization StandardScaler","bf90b534":"<a href=\"https:\/\/archive.ics.uci.edu\/ml\/datasets\/Auto+MPG\">\n    <img src=\"https:\/\/i.ibb.co\/2jGk0YW\/autompg.png\" align=\"center\">\n<\/a>","42bfc8b9":"# Missing Values","8b4a7814":"## Ridge Regression Model","adc245dd":"## One Hot Encoding","a032a63f":"### Skewness","8a63281d":"- if  > 1 positive skewness\n- if  < -1 negative skewness\n- horsepower is 1.05 but its OK, I won't change it.\n---","9aa95e3d":"# Exploratory Data Analyze","097d38ad":"## RobustScaler","1ca4acf7":"## ElasticNet","75cc09ec":"## Ridge Regression Model","d7735f95":"<a href=\"https:\/\/www.oguzerdogan.com\/\">\n    <img src=\"https:\/\/www.oguzerdogan.com\/wp-content\/uploads\/2020\/08\/logo_.png\" width=\"200\" align=\"center\">\n<\/a>","822f0f73":"**Source:**\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The dataset was used in the 1983 American Statistical Association Exposition.\n\n\n**Data Set Information:**\n\nThis dataset is a slightly modified version of the dataset provided in the StatLib library. In line with the use by Ross Quinlan (1993) in predicting the attribute \"mpg\", 8 of the original instances were removed because they had unknown values for the \"mpg\" attribute. The original dataset is available in the file \"auto-mpg.data-original\".\n\n\"The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of 3 multivalued discrete and 5 continuous attributes.\" (Quinlan, 1993)\n\n\n**Attribute Information:**\n\n1. mpg: continuous\n2. cylinders: multi-valued discrete\n3. displacement: continuous\n4. horsepower: continuous\n5. weight: continuous\n6. acceleration: continuous\n7. model year: multi-valued discrete\n8. origin: multi-valued discrete\n9. car name: string (unique for each instance)\n\n****","6ca81379":"## Log Transform","599b348b":"## ElasticNet","dbc141af":"## Delete Outliers"}}