{"cell_type":{"3850f388":"code","300c72fe":"code","bf55c1ef":"code","bb9bc21a":"code","6e9d8b3b":"code","cd654929":"code","a4fb5d7a":"code","b337281e":"code","c3c53438":"code","4c8d4f5b":"code","c1812d7f":"code","8f5530ec":"code","09dcd499":"code","1b5328fa":"code","8f0bfc9b":"code","a4039f4f":"code","b92470da":"code","65dccc10":"code","1fdb9186":"code","df3178d6":"code","ef0b7fae":"code","e0345732":"markdown","c4c4382f":"markdown","d4af1174":"markdown","dd940c9b":"markdown","d2ff9f2e":"markdown","f65423a8":"markdown","2f1c6a8e":"markdown","1bc63917":"markdown","f43eb2f6":"markdown","a2428b65":"markdown","ba8a9a39":"markdown","1782b494":"markdown","6bd1492d":"markdown"},"source":{"3850f388":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npaths= []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","300c72fe":"paths","bf55c1ef":"train = pd.read_csv(paths[0])  #0 for the training dataset","bb9bc21a":"train.head() #printing the training dataset","6e9d8b3b":"test = pd.read_csv(paths[1]) # 1 FOR THE TEST DATASET","cd654929":"test #printing the testing dataset","a4fb5d7a":"train.info() # PRINTS THE INFORMATION ABOUT THE DATA","b337281e":"train.describe() #DESCRIBE ABOUT THE DATA ABOUT THE MEAN, COUNT, STANDARD DEVIATION AND COUNT","c3c53438":"import seaborn as sbn\n\nsbn.pairplot(train)   # Gives the pair plot for using the seaborn library ","4c8d4f5b":"sbn.heatmap(train.corr(),annot=True)  # Plots the heat map for the corelation matrix","c1812d7f":"train['Survived'].value_counts()","8f5530ec":"print(train['Sex'].describe())\ntrain['Sex'].unique()\n","09dcd499":"train['Embarked'].unique()  #Printing the unique values present the in embarked coloumn in the training dataset","1b5328fa":"train = train.dropna(subset=['Embarked']) ## DELETES THE NULL VALUES PRODUCED BY THE EMBARKED ONLY\n","8f0bfc9b":"train['Embarked'].unique()","a4039f4f":"splited = train[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",'Survived']]\ntest_splited = test[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]]\nsplited=splited.dropna()","b92470da":"x_train = splited[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]]\ny_train = splited['Survived']\nx_test = test_splited[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]]","65dccc10":"x_train = pd.get_dummies(x_train)\nx_test = pd.get_dummies(x_test)","1fdb9186":"from sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression()\nmodel = LR.fit(x_train,y_train)\n","df3178d6":"predictions = model.predict(x_test)","ef0b7fae":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","e0345732":"# Importing Data","c4c4382f":"**Files in this directory.....**","d4af1174":"**Pair plot**:\n    Which compare each and every data in the dataset and it will give us all the plot in the matrix form","dd940c9b":"Now the **Nan** value gone....","d2ff9f2e":"# Exploring Dataset","f65423a8":"Clearing the **NULL** Values produced by Embarked","2f1c6a8e":"# Visualising the data","1bc63917":"**Corelation Matrix:**\n    Corelation matrix shows the corelation between the each and every data in the dataset","f43eb2f6":"Reading the training data and saving it to the train variable","a2428b65":"Splitting for the training and testing data","ba8a9a39":"Want to clear that nan value","1782b494":"# Data Processing\n\nIn this we are cleaning the NULL values produced by the **Embarked** coloumn and making the categorical coloumn into the integer representation\n<br>\nCheck [here](https:\/\/machinelearningmastery.com\/why-one-hot-encode-data-in-machine-learning\/) for the information about the integer representation\n","6bd1492d":"# Model training\n\nTraining the model using the Logistic regression and finding the accuracy score using the sklearn library"}}