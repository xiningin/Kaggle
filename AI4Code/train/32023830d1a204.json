{"cell_type":{"b5da0a02":"code","9009d5cd":"code","91633ddb":"code","80af47e9":"code","e8793b4a":"code","61ffd8f5":"code","57de030a":"code","6f7f290c":"code","a663862d":"code","33391bfd":"code","a07c5fd7":"code","7924cdbd":"code","07af2f6c":"code","7beead91":"code","3e4e6bd5":"code","029184c2":"code","12858d9e":"code","da55f146":"code","8af84f8d":"code","8572f512":"code","123f22d2":"code","80815ed3":"code","b0385f3f":"code","ea616697":"code","443ceec2":"code","52b481df":"code","f2ab7f9d":"code","2ff20e01":"markdown","61416058":"markdown","deb6b234":"markdown","3020457d":"markdown","cafe6f77":"markdown","e71b4470":"markdown","ac5f8c8b":"markdown","aebe61db":"markdown","249a1ee5":"markdown","f427215b":"markdown","fe447758":"markdown"},"source":{"b5da0a02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9009d5cd":"#Libraries\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","91633ddb":"data = pd.read_csv('\/kaggle\/input\/airlines-customer-satisfaction\/Invistico_Airline.csv')\ndata.head()","80af47e9":"data.isna().sum()","e8793b4a":"data['Arrival Delay in Minutes'] = data['Arrival Delay in Minutes'].fillna(data['Arrival Delay in Minutes'].median())\ndata.isna().sum()","61ffd8f5":"def object_cols(df):\n    return list(df.select_dtypes(include='object').columns)\n\ndef numerical_cols(df):\n    return list(df.select_dtypes(exclude='object').columns)","57de030a":"obj_col = object_cols(data)\nnum_col = numerical_cols(data)","6f7f290c":"obj_col","a663862d":"num_col","33391bfd":"le = LabelEncoder()\nnorm = Normalizer()","a07c5fd7":"for col in obj_col:\n    data[col] = le.fit_transform(data[col])","7924cdbd":"data.isna().sum()","07af2f6c":"data[num_col] = norm.fit_transform(data[num_col])","7beead91":"data.head()","3e4e6bd5":"X_data = data.drop(['satisfaction'], axis = 1)\ny_data = data['satisfaction']","029184c2":"X_train, X_test, y_train, y_test = train_test_split(\n    X_data, y_data, test_size=0.33, random_state=42)","12858d9e":"log_reg = LogisticRegression()","da55f146":"fit_model = log_reg.fit(X_train, y_train)","8af84f8d":"preds = fit_model.predict(X_test)","8572f512":"preds","123f22d2":"probs = fit_model.predict_proba(X_test)","80815ed3":"probs","b0385f3f":"model_results = pd.DataFrame([preds, y_test, [elem[0] for elem in probs], [elem[1] for elem in probs]])\nmodel_results = model_results.T\nmodel_results.rename(columns = {0 : 'PredictedClass', 1 : 'TrueClass', 2 : 'ClassProb:0', 3 : 'ClassProb:1'}, inplace = True)","ea616697":"model_results","443ceec2":"true_count = 0\nfor pred, real in zip(model_results['PredictedClass'], model_results['TrueClass']):\n    if pred == real:\n        true_count = true_count + 1\nprint(\"Number of True Classifications = {0} \".format(true_count))\nprint(\"Accurate Classification Ratio = {0} \".format(true_count \/ len(y_test)))","52b481df":"second_model = LogisticRegression(penalty = 'l2',solver = 'newton-cg' ,C = 10, class_weight = 'balanced')\nsecond_fit = second_model.fit(X_train, y_train)","f2ab7f9d":"second_fit.score(X_test, y_test)","2ff20e01":"* We have 129880 customer experience data. In this data, we have some information about customers (age, gender, etc.) and flight (departure time, seat comfort, etc.). We will use these data to set a logistic regression algorithm and to classify customer satisfaction. But before we do this we need to learn more about our data. Let's start by checking the empty values.\n* 129880 m\u00fc\u015fteri deneyimi verisine sahibiz. Bu verilerde m\u00fc\u015fteri (ya\u015f, cinsiyet vb.) ve u\u00e7u\u015f (kalk\u0131\u015f saati, koltuk konforu vb.) ile ilgili baz\u0131 bilgilere sahibiz. Bu verileri bir lojistik regresyon algoritmas\u0131 olu\u015fturmak ve m\u00fc\u015fteri memnuniyetini s\u0131n\u0131fland\u0131rmak i\u00e7in kullanaca\u011f\u0131z. Ancak bunu yapmadan \u00f6nce verilerimiz hakk\u0131nda daha fazla \u015fey \u00f6\u011frenmemiz gerekiyor. Bo\u015f de\u011ferleri kontrol ederek ba\u015flayal\u0131m.","61416058":"* The ratio which you can see as \"Accurate Classification Ratio\" is also known as accuracy score. This ratio simply shows you success ratio of your classification algorithm. We now have only one algorithm hence we can not say this algorithm with these parameters (default parameters) is the best one. Let's create another logistic regression algorithm and let's check the accuracy score again to choose one of them as the best one. \n* \"Accurate Classification Ratio\" olarak g\u00f6rebilece\u011finiz oran, accuracy score olarak da bilinir. Bu oran basit\u00e7e size s\u0131n\u0131fland\u0131rma algoritman\u0131z\u0131n ba\u015far\u0131 oran\u0131n\u0131 g\u00f6sterir. \u015eu anda tek bir algoritmam\u0131z var, bu nedenle bu parametrelerle (dafault parametreler) bu algoritman\u0131n en iyisi oldu\u011funu s\u00f6yleyemeyiz. Ba\u015fka bir lojistik regresyon algoritmas\u0131 olu\u015ftural\u0131m ve bunlardan birini en iyi olarak se\u00e7mek i\u00e7in do\u011fruluk puan\u0131n\u0131 tekrar kontrol edelim.","deb6b234":"* Hello everyone. This is Burak. Your instructor data scientist at the ML 101 Series. Today we are at the second stop of our learning journey. We will cover and learn about logistic regression with an example. Imagine that you are a data scientist in an airline company. The company wants you to develop an algorithm to classify the flight experience of a customer as 'Satisfied' or 'Dissatisfied'. To do this we need data. Let's read our data and start our journey. \n* Herkese merhaba. Ben Burak. ML 101 Serisindeki e\u011fitmen veri bilimciniz. Bug\u00fcn \u00f6\u011frenme yolculu\u011fumuzun ikinci dura\u011f\u0131nday\u0131z. Bir \u00f6rnekle lojistik regresyonu ele al\u0131p \u00f6\u011frenece\u011fiz. Bir havayolu \u015firketinde veri bilimcisi oldu\u011funuzu hayal edin. \u015eirket, bir m\u00fc\u015fterinin u\u00e7u\u015f deneyimini 'Memnun' veya 'Memnun De\u011fil' olarak s\u0131n\u0131fland\u0131rmak i\u00e7in bir algoritma geli\u015ftirmenizi istiyor. Bunu yapmak i\u00e7in verilere ihtiyac\u0131m\u0131z var. Verilerimizi okuyal\u0131m ve yolculu\u011fumuza ba\u015flayal\u0131m.","3020457d":"* If you check our data, some of our columns have numeric values and some of them have categorical values. We have to apply some other data preprocessing methods to prepare this data for our logistic regression algorithm. But to do this, we need to learn the data type of all of our columns. Let's create 2 methods for this and run them to see the outputs of these methods. \n* Verilerimizi kontrol ederseniz, baz\u0131 s\u00fctunlar\u0131m\u0131z\u0131n say\u0131sal de\u011ferleri, baz\u0131lar\u0131n\u0131n da kategorik de\u011ferleri vard\u0131r. Bu verileri lojistik regresyon algoritmam\u0131za haz\u0131rlamak i\u00e7in baz\u0131 di\u011fer veri \u00f6n i\u015fleme y\u00f6ntemlerini uygulamam\u0131z gerekiyor. Ancak bunu yapmak i\u00e7in t\u00fcm s\u00fctunlar\u0131m\u0131z\u0131n veri t\u00fcr\u00fcn\u00fc \u00f6\u011frenmemiz gerekiyor. Bunun i\u00e7in 2 metot olu\u015ftural\u0131m ve bu metotlar\u0131n \u00e7\u0131kt\u0131lar\u0131n\u0131 g\u00f6rmek i\u00e7in \u00e7al\u0131\u015ft\u0131ral\u0131m.","cafe6f77":"* As you can see our model made some classifications as 1 or 0. To classify any point as 1 or 0 the model is using the probabilities and set the output by choosing the high probability. To see the probability values of any data point we can call the predict_proba method of our logistic regression model. Once we have both classified values and related probabilities let's create a dataframe to see everything combined.\n* G\u00f6rd\u00fc\u011f\u00fcn\u00fcz gibi modelimiz 1 veya 0 olarak baz\u0131 s\u0131n\u0131fland\u0131rmalar yapt\u0131. Herhangi bir noktay\u0131 1 veya 0 olarak s\u0131n\u0131fland\u0131rmak i\u00e7in model olas\u0131l\u0131klar\u0131 kullan\u0131yor ve y\u00fcksek olas\u0131l\u0131\u011f\u0131 se\u00e7erek \u00e7\u0131kt\u0131y\u0131 ayarl\u0131yor. Herhangi bir veri noktas\u0131n\u0131n olas\u0131l\u0131k de\u011ferlerini g\u00f6rmek i\u00e7in lojistik regresyon modelimizin predict_proba metodunu \u00e7a\u011f\u0131rabiliriz. Hem s\u0131n\u0131fland\u0131r\u0131lm\u0131\u015f de\u011ferlere hem de ilgili olas\u0131l\u0131klara sahip oldu\u011fumuzda, her \u015feyi bir arada g\u00f6rmek i\u00e7in bir veri \u00e7er\u00e7evesi olu\u015ftural\u0131m.","e71b4470":"* Now we have two different lists. One of them has the names of categorical columns. The name of this list is obj_col. To work with categorical variables we need to encode them. To encode categorical values let's call the LabelEncoder method of sklearn. The second list which is num_col has the names of columns that include numerical values. We can normalize these values by using Normalize method of sklearn. Once we apply these two preprocessing methods to our data, we will be ready for Logistic Regression. \n* \u015eimdi iki farkl\u0131 listemiz var. Bunlardan biri kategorik s\u00fctunlar\u0131n adlar\u0131n\u0131 i\u00e7erir. Bu listenin ad\u0131 obj_col. Kategorik de\u011fi\u015fkenlerle \u00e7al\u0131\u015fmak i\u00e7in onlar\u0131 encode etmek gerekir. Kategorik de\u011ferleri encode edebilmek i\u00e7in sklearn'in LabelEncoder y\u00f6ntemini \u00e7a\u011f\u0131ral\u0131m. num_col olan ikinci liste, say\u0131sal de\u011ferler i\u00e7eren s\u00fctunlar\u0131n adlar\u0131na sahiptir. Sklearn'in Normalize y\u00f6ntemini kullanarak bu de\u011ferleri normalize edebiliriz. Bu iki \u00f6n i\u015fleme y\u00f6ntemini verilerimize uygulad\u0131\u011f\u0131m\u0131zda Lojistik Regresyon i\u00e7in haz\u0131r olaca\u011f\u0131z.","ac5f8c8b":"* We all are set. So far we have read data about customer's flight experience. After then we applied some preprocessing steps to these data to make our data ready for logistic regression. Now we are ready to create a logistic regression model. Let's split our data into two data frames such as train and test by using train_test_split method of sklearn. \n* Hepimiz haz\u0131r\u0131z. \u015eimdiye kadar m\u00fc\u015fterinin u\u00e7u\u015f deneyimiyle ilgili verileri okuduk. Daha sonra verilerimizi lojistik regresyona haz\u0131r hale getirmek i\u00e7in bu verilere baz\u0131 \u00f6n i\u015fleme ad\u0131mlar\u0131 uygulad\u0131k. Art\u0131k bir lojistik regresyon modeli olu\u015fturmaya haz\u0131r\u0131z. Sklearn'in train_test_split y\u00f6ntemini kullanarak verilerimizi train ve test gibi iki dataframe olarak ay\u0131ral\u0131m.","aebe61db":"* In the pandas library, there is a method named isna. This method allows you to check the data has any null values or not. If you combine this method with another method which is sum, you can see the total number of null values in a column. If you check the results of this code you can see that we have 393 null values in the 'Arrival Delay in Minutes' column. There are too many methods to handle null values and don't worry we will cover them in the future also. In this example, we will use the median of the column to fill null values, and let's check null values again.  \n* Pandas k\u00fct\u00fcphanesinde isna ad\u0131nda bir metot var. Bu metot, verilerin bo\u015f de\u011ferlere sahip olup olmad\u0131\u011f\u0131n\u0131 kontrol etmenizi sa\u011flar. Bu metodu, ad\u0131 sum olan ba\u015fka bir y\u00f6ntemle birle\u015ftirirseniz, bir s\u00fctundaki toplam bo\u015f de\u011fer say\u0131s\u0131n\u0131 g\u00f6rebilirsiniz. Bu kodun sonu\u00e7lar\u0131n\u0131 kontrol ederseniz, 'Arrival Delay in Minutes' s\u00fctununda 393 bo\u015f de\u011ferimiz oldu\u011funu g\u00f6rebilirsiniz. Bo\u015f de\u011ferleri i\u015flemek i\u00e7in \u00e7ok fazla y\u00f6ntem var ve onlar\u0131 gelecekte de ele alaca\u011f\u0131z merak etmeyin. Bu \u00f6rnekte, bo\u015f de\u011ferleri doldurmak i\u00e7in s\u00fctunun ortancas\u0131n\u0131 kullanaca\u011f\u0131z ve tekrar bo\u015f de\u011ferleri kontrol edelim.","249a1ee5":"* We now have prediction results for all of the data points in our X_test dataframe. Any classification algorithm can make any classification by using any data that you use as input. But how can you evaluate the success rate of this algorithm? Let's check the dataframe which we have created. In the first two columns of this dataframe we have predicted and true class values. For any data point, if the predicted class value and true class value are the same, we can call this classification a true classification. If we divide the count of true classifications by the number of all test values, we can find \"accurate classification ratio\". Let's do it!\n* Art\u0131k X_test veri setimizdeki t\u00fcm veri noktalar\u0131 i\u00e7in tahmin sonu\u00e7lar\u0131m\u0131z var. Herhangi bir s\u0131n\u0131fland\u0131rma algoritmas\u0131, girdi olarak kulland\u0131\u011f\u0131n\u0131z herhangi bir veriyi kullanarak herhangi bir s\u0131n\u0131fland\u0131rma yapabilir. Ancak bu algoritman\u0131n ba\u015far\u0131 oran\u0131n\u0131 nas\u0131l de\u011ferlendirebilirsiniz? Olu\u015fturdu\u011fumuz dataframe'i kontrol edelim. Bu dataframe'deki ilk iki s\u00fctununda tahmin ve ger\u00e7ek s\u0131n\u0131f de\u011ferlerini ald\u0131k. Herhangi bir veri noktas\u0131 i\u00e7in tahmin edilen s\u0131n\u0131f de\u011feri ile ger\u00e7ek s\u0131n\u0131f de\u011feri ayn\u0131 ise bu s\u0131n\u0131fland\u0131rmaya do\u011fru bir s\u0131n\u0131fland\u0131rma diyebiliriz. Do\u011fru s\u0131n\u0131fland\u0131rma say\u0131s\u0131n\u0131 t\u00fcm test de\u011ferlerinin say\u0131s\u0131na b\u00f6lersek \"do\u011fru s\u0131n\u0131fland\u0131rma oran\u0131\"n\u0131 bulabiliriz. Haydi Yapal\u0131m!","f427215b":"* We did everything to make classifications by using logistic regression. Let's create a logistic regression instance firstly. Then fit it by using the split data. Once our model is ready, call the predict method to make classifications and check some of the results. \n* Lojistik regresyon kullanarak s\u0131n\u0131fland\u0131rma yapmak i\u00e7in her \u015feyi yapt\u0131k. \u00d6ncelikle bir lojistik regresyon instance olu\u015ftural\u0131m. Ard\u0131ndan, ay\u0131r\u0131lm\u0131\u015f verileri kullanarak fit edelim. Modelimiz haz\u0131r oldu\u011funda, s\u0131n\u0131fland\u0131rma yapmak ve baz\u0131 sonu\u00e7lar\u0131 kontrol etmek i\u00e7in predict metodunu \u00e7a\u011f\u0131ral\u0131m.","fe447758":"* We have changed many things in our model. To learn more about logistic regression model parameters you can check https:\/\/medium.com\/@bcelalakyuz. I have explained all of the parameters, attributes, and methods deeply. Once our model is fitted we called the score method of logistic regression. This method uses X_test data to make classifications and evaluate classification results by doing the same things which we did by using our model_results dataframe. Now our model is pretty better than the first one. But of course there are better models than these two models. I suggest you try other models by yourself. I have tried to do my best to teach you what is logistic regression and how to use it. I hope you learned some things from me. Next Saturday we will learn about k-NN at the third stop of our ML101 journey. If you have any questions about logistic regression, do not hesitate to communicate with me via comments or Kaggle mail. See you next week.\n* Modelimizde bir\u00e7ok \u015feyi de\u011fi\u015ftirdik. Lojistik regresyon model parametreleri hakk\u0131nda daha fazla bilgi edinmek i\u00e7in https:\/\/medium.com\/@bcelalakyuz sayfas\u0131n\u0131 inceleyebilirsiniz. T\u00fcm parametreleri, nitelikleri ve y\u00f6ntemleri derinlemesine a\u00e7\u0131klad\u0131m. Modelimiz e\u011fitiltikten sonra, lojistik regresyonun score metodunu \u00e7a\u011f\u0131rd\u0131k. Bu metot, model_results veri setimizi kullanarak yapt\u0131\u011f\u0131m\u0131z ayn\u0131 \u015feyleri yaparak s\u0131n\u0131fland\u0131rma yapmak ve s\u0131n\u0131fland\u0131rma sonu\u00e7lar\u0131n\u0131 de\u011ferlendirmek i\u00e7in X_test verilerini kullan\u0131r. \u015eimdi modelimiz ilkinden olduk\u00e7a iyi. Ama elbette bu iki modelden daha iyi modeller var. Di\u011fer modelleri kendi ba\u015f\u0131n\u0131za denemenizi \u00f6neririm. Size lojistik regresyonun ne oldu\u011funu ve nas\u0131l kullan\u0131laca\u011f\u0131n\u0131 \u00f6\u011fretmek i\u00e7in elimden gelenin en iyisini yapmaya \u00e7al\u0131\u015ft\u0131m. Umar\u0131m benden bir \u015feyler \u00f6\u011frenmi\u015fsinizdir. \u00d6n\u00fcm\u00fczdeki Cumartesi ML101 yolculu\u011fumuzun \u00fc\u00e7\u00fcnc\u00fc dura\u011f\u0131nda k-NN \u00f6\u011frenece\u011fiz. Lojistik regresyon hakk\u0131nda herhangi bir sorunuz varsa, yorumlar veya Kaggle mail yoluyla benimle ileti\u015fime ge\u00e7mekten \u00e7ekinmeyin. Haftaya g\u00f6r\u00fc\u015f\u00fcr\u00fcz."}}