{"cell_type":{"96fb831f":"code","2c8acd5d":"code","f17229f3":"code","bc702f5a":"code","b993022a":"code","05eea21b":"code","9b196011":"code","5b583768":"code","86d628c4":"code","1838e923":"code","4a1fd5e0":"code","d5122474":"code","2da19cdf":"code","cbe7694f":"code","47b97271":"code","9d661e2f":"code","112bcf64":"code","9b7d3837":"code","1a1f7b93":"code","62e06213":"code","0c4d2664":"code","77c00bbc":"code","5dc90b08":"code","fbb9e34f":"markdown","b4e7b840":"markdown","ce5be185":"markdown","076c40db":"markdown","3bb8e314":"markdown","cf69c078":"markdown","ea99e679":"markdown","8a872c04":"markdown","5f979e47":"markdown","71330b11":"markdown","7949105b":"markdown","b93efca4":"markdown","811a2905":"markdown"},"source":{"96fb831f":"from tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nimport pandas as pd","2c8acd5d":"image_size = [224, 224]","f17229f3":"vgg = VGG16(input_shape = image_size + [3], weights = 'imagenet', include_top =  False)","bc702f5a":"for layer in vgg.layers:\n    layer.trainable = False","b993022a":"from glob import glob\nfolders = glob('\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/*')","05eea21b":"folders","9b196011":"x = Flatten()(vgg.output)","5b583768":"prediction = Dense(len(folders), activation = 'softmax')(x)","86d628c4":"model = Model(inputs = vgg.input, outputs = prediction)","1838e923":"model.summary()","4a1fd5e0":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","d5122474":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","2da19cdf":"train_data_gen = ImageDataGenerator(rescale = 1.\/255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)","cbe7694f":"test_data_gen = ImageDataGenerator(rescale = 1.\/255)","47b97271":"train_set = train_data_gen.flow_from_directory('\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/', target_size = (224,224), batch_size = 32, class_mode = 'categorical')","9d661e2f":"test_set = test_data_gen.flow_from_directory('\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/', target_size = (224,224), batch_size = 32, class_mode = 'categorical')","112bcf64":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Bacterial_spot\/00416648-be6e-4bd4-bc8d-82f43f8a7240___GCREC_Bact.Sp 3110.JPG\"))\nplt.title(\"Bacterial Spot\")","9b7d3837":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Early_blight\/0034a551-9512-44e5-ba6c-827f85ecc688___RS_Erly.B 9432.JPG\"))\nplt.title(\"Early Blight\")","1a1f7b93":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Late_blight\/0003faa8-4b27-4c65-bf42-6d9e352ca1a5___RS_Late.B 4946.JPG\"))\nplt.title(\"Late Blight\")","62e06213":"mod = model.fit_generator(\n  train_set,\n  validation_data=test_set,\n  epochs=20,\n  steps_per_epoch=len(train_set),\n  validation_steps=len(test_set)\n)","0c4d2664":"import matplotlib.pyplot as plt\nplt.plot(mod.history['loss'], label='train loss')\nplt.plot(mod.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()","77c00bbc":"plt.plot(mod.history['accuracy'], label='train accuracy')\nplt.plot(mod.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.show()","5dc90b08":"# save it as a h5 file\nfrom tensorflow.keras.models import load_model\nmodel.save('model.h5')","fbb9e34f":"- Importing library","b4e7b840":"Flattening the output layer","ce5be185":"![](https:\/\/neurohive.io\/wp-content\/uploads\/2018\/11\/vgg16.png)","076c40db":"Plotting few images ","3bb8e314":"Some of the layers of VGG16 are already trained. To train them again is not a good practice. Thereby making it False","cf69c078":"# VGG16 \u2013 Convolutional Network for Classification and Detection","ea99e679":"Fitting the model","8a872c04":"- VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. It was one of the famous model submitted to ILSVRC-2014. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3\u00d73 kernel-sized filters one after another. VGG16 was trained for weeks and was using NVIDIA Titan Black GPU\u2019s.","5f979e47":"Compiling the model","71330b11":"Generating more images","7949105b":"![](https:\/\/neurohive.io\/wp-content\/uploads\/2018\/11\/vgg16-1-e1542731207177.png)","b93efca4":"As we are using VGG16 architecture, it expects the size of 224 by 224. We will set image size.","811a2905":"The first argument is the shape of input image plus **3**(as image is colured[RBG], for black_and_white add **1**).\nThe second one is the weights eqaul to imagenet. And,\nas we know it gives 1000 outputs. Third one excludes the top layer."}}