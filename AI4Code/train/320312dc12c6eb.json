{"cell_type":{"a58fc12b":"code","6cb64833":"code","66991dd6":"code","a0fca459":"code","2c36b955":"code","921893ef":"code","e478f81f":"code","ec05bb21":"code","be419d99":"code","cc3560df":"code","c55ab5d6":"code","b9f941a7":"code","a7e0b7d3":"code","00f76c05":"code","08ceddf5":"code","881422f6":"code","727f7bb5":"code","b8ab4323":"code","ecf6832c":"code","1cf925af":"code","23d6d28a":"code","748370b6":"code","aa04ed04":"code","80df6bf2":"code","b49b109a":"code","ee056617":"code","1e8c146c":"code","1f0a5251":"code","ddaf18e5":"code","91a506ca":"code","dd25e6c9":"code","a918d1e5":"code","351c1f21":"code","772ee7ea":"code","cfa44da1":"markdown","e9346837":"markdown","dcf8af4e":"markdown","b4a49892":"markdown","849749ce":"markdown","c415bd6f":"markdown","c31beecc":"markdown","9a062c38":"markdown","302d1290":"markdown","bd1e9018":"markdown","c2e25459":"markdown","dd4c8079":"markdown","1f4ec29b":"markdown","58ffbba2":"markdown","4ffcfab9":"markdown"},"source":{"a58fc12b":"import PIL\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom matplotlib import pyplot\n\nfrom sklearn import preprocessing","6cb64833":"# control loop\nrun_model1 = False\nrun_model2 = False\nrun_model3 = False\nrun_model_adv = True","66991dd6":"#input data\ntrain = pd.read_csv('..\/input\/train.csv', delimiter=',')\ntest = pd.read_csv('..\/input\/test.csv', delimiter=',') ","a0fca459":"train.head()","2c36b955":"train_size = train.shape[0]\ntest_size = test.shape[0]\n\nX_train = train.iloc[:, 1:].values.astype('uint8')  #iloc[row, column]\nY_train = train.iloc[:, 0]\nX_test = test.iloc[:, :].values.astype('uint8')\n\nimg_dimension = np.int32(np.sqrt(X_train.shape[1]))\nimg_rows, img_cols = img_dimension, img_dimension #28*28\nnb_of_color_channels = 1\n\n# Check Keras backend\nif(keras.backend.image_dim_ordering()==\"th\"):\n    # Reshape the data to be used by a Theano CNN. Shape is\n    # (nb_of_samples, nb_of_color_channels, img_width, img_heigh)\n    X_train = X_train.reshape(train.shape[0], nb_of_color_channels, img_rows, img_cols)\n    X_test = X_test.reshape(test.shape[0], nb_of_color_channels, img_rows, img_cols)\n    in_shape = (nb_of_color_channels, img_rows, img_cols)\nelse:\n    # Reshape the data to be used by a Tensorflow CNN. Shape is\n    # (nb_of_samples, img_width, img_heigh, nb_of_color_channels)\n    X_train = X_train.reshape(train.shape[0], img_rows, img_cols, nb_of_color_channels)\n    X_test = X_test.reshape(test.shape[0], img_rows, img_cols, nb_of_color_channels)\n    in_shape = (img_rows, img_cols, nb_of_color_channels)\n\n\n#X_train = X_train.reshape(train_size, img_dimension, -1)\n#X_test = X_test.reshape(test_size, img_dimension, -1)\n\nprint('Data Information\\n')\nprint('Training set size: {}\\nTesting set size: {}'.format(train_size, test_size))\nprint('Image dimension: {0}*{0}'.format(img_dimension))\n\n\n#free some memory space\n#del train, test\n","921893ef":"# display some image\ndef display_digits(dim, X, Y_true, pred=None, random_seed=None):\n    \"\"\" This function shows n images choiced randomly with their predicted(optional) and real labels\n    dim: plots parameter, tuple with (nrows, ncols)\n    \n    \"\"\"\n    if random_seed is not None:\n        np.random.seed(random_seed)\n        \n    nrows, ncols = dim\n    indices = np.random.randint(Y_true.shape[0], size=dim)\n    \n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    plt.subplots_adjust(wspace=0.1, hspace=0.8)\n    \n    for row in range(nrows):\n        for col in range(ncols):\n            i = indices[row,col]\n            ax[row,col].imshow(X[i,:,:,0], cmap='gray')\n            if pred is not None:\n                ax[row,col].set_title(\"id:{0}\\nPredicted label:{1}\\nTrue label:{2}\".\n                                      format(i,pred[i],Y_true[i]))\n            else:\n                ax[row,col].set_title(\"id:{0}\\nTrue label:{1}\".format(i,Y_true[i]))\n\n                \ndisplay_digits(dim=(2,3), X=X_train, Y_true=Y_train)\n#display_random_digits(dim=(2,3))","e478f81f":"# display the distribution of labels\nsns.countplot(Y_train)\nhist_Y_train = Y_train.groupby(Y_train.values).count()\nprint(hist_Y_train)","ec05bb21":"# Normalization: Make the value floats in [0,1] instead of int in [0,255]\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train_nor = X_train \/ 255\nX_test_nor= X_test \/ 255","be419d99":"oh_encoder = preprocessing.OneHotEncoder(categories='auto')\noh_encoder.fit(Y_train.values.reshape(-1,1))\nY_train_oh = oh_encoder.transform(Y_train.values.reshape(-1,1)).toarray()","cc3560df":"print('One-hot:')\nprint(Y_train_oh[:5])\nprint('\\nLabel:')\nprint(Y_train[:5])","c55ab5d6":"# Just for record~ Another way for one-hot encoding (by keras)\nfrom keras.utils.np_utils import to_categorical \nto_categorical(Y_train, Y_train.unique().shape[0])[:5]\n","b9f941a7":"# Final check for dimensions before training\nprint('X_train shape:', X_train.shape)\nprint('Y_train shape:', Y_train.shape)\nprint('X_test shape:', X_test.shape)","a7e0b7d3":"from keras.layers import Activation,Dropout,Dense,Conv2D,AveragePooling2D,Flatten,ZeroPadding2D,MaxPooling2D\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.callbacks import ReduceLROnPlateau","00f76c05":"def build_lenet5(model, input_shape=X_train.shape[1:], dropout=0):\n    # N' = (N+2P-F)\/S + 1\n    S = [1,2,1,2,1]\n    N_input = [28,28,14,10,5]\n    P = [2,0,0,0,0]\n    N = [28,14,10,5,1]\n    F = [i[0] + 2*i[1] - i[3]*(i[2] - 1) for i in zip(N_input, P, N, S)] #[5,2,5,2]\n    \n    #Input: (28*28*1)\n    #C1: (28*28*6)\n    model.add(Conv2D(filters=6, kernel_size=(F[0],F[0]), padding='same', strides=S[0],\n                     activation='relu', input_shape=input_shape))\n    #S2: (14*14*6)\n    model.add(MaxPooling2D(pool_size=F[1], strides=S[1]))\n    #C3: (10*10*16)\n    model.add(Conv2D(filters=16, kernel_size=(F[2],F[2]), padding='valid', strides=S[2],\n                     activation='relu'))\n    #S4: (5*5*16)\n    model.add(MaxPooling2D(pool_size=F[3], strides=S[3]))\n    #C5: (1*1*120)\n    model.add(Conv2D(filters=120, kernel_size=(F[4],F[4]), padding='valid', strides=S[4],\n                     activation='relu'))\n    #New add: Dropout\n    model.add(Dropout(dropout))\n    model.add(Flatten()) #Same work as C5 the input image size is unchanged.\n    \n    #F6: (84)\n    model.add(Dense(84, activation='relu'))\n    #Output: (10)\n    model.add(Dense(10, activation='softmax'))\n    \n\nif __name__ == '__main__' and run_model1:\n    model = Sequential()\n    build_lenet5(model, input_shape=X_train.shape[1:], dropout=0)\n    model.summary()\n\n","08ceddf5":"hist_dict = {}\n\nif __name__ == '__main__' and run_model1:\n    adam = optimizers.Adam()\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n    hist_dict['run_model1'] = model.fit(X_train, Y_train_oh, batch_size=64, epochs=20,\n                                    shuffle=True, validation_split=0.2, verbose=2)\n    ","881422f6":"def model_predict(model):\n    print(\"Generating test predictions...\")\n    predictions = model.predict_classes(X_test, verbose=1)\n    print(\"OK.\")\n    return predictions\n\ndef model_predict_val(model, set_check):\n    print(\"Generating set predictions...\")\n    predictions = model.predict_classes(set_check, verbose=1)\n    print(\"OK.\")\n    return predictions\n\ndef write_preds(preds, filename):\n    pd.DataFrame({\"ImageId\": list(range(1,len(preds)+1)), \"Label\": preds}).to_csv(filename, index=False, header=True)\n\nif __name__ == '__main__' and run_model1:    \n    predictions = model_predict(model)\n    print(predictions[:5])\n    write_preds(predictions, \"keras-lenet5-basic.csv\")\n\n\n","727f7bb5":"if __name__ == '__main__' and run_model2:\n    model = Sequential()\n    build_lenet5(model, input_shape=X_train.shape[1:], dropout=0.3)\n    model.summary()\n    \n    adam = optimizers.Adam()\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n    hist_dict['run_model2'] = model.fit(X_train, Y_train_oh, batch_size=64, epochs=20, shuffle=True, validation_split=0.2, verbose=2)","b8ab4323":"if __name__ == '__main__' and run_model2:\n    predictions = model_predict(model)\n    print(predictions[:5])\n    write_preds(predictions, \"keras-lenet5-basic-droupout.csv\")","ecf6832c":"# Ref: https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n# augmentation \u5404\u9805\u5177\u9ad4\u6548\u679c : https:\/\/zhuanlan.zhihu.com\/p\/30197320\n\"\"\"\nAugmentation:\n\nRandomly rotate some training images by 10 degrees\nRandomly Zoom by 10% some training images\nRandomly shift images horizontally by 10% of the width\nRandomly shift images vertically by 10% of the height\n\n\nvertical_flip , horizontal_flip are not appropriate to apply here\nsince it could have lead to misclassify symetrical numbers such as 6 and 9.\n\"\"\"\nfrom keras.preprocessing.image import ImageDataGenerator \n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","1cf925af":"for x_batch, y_batch in datagen.flow(X_train, Y_train_oh, batch_size=9, shuffle = False):\n    print(x_batch.shape)\n    print(y_batch.shape)\n    break","23d6d28a":"for x_batch, y_batch in datagen.flow(X_train, Y_train_oh, batch_size=9, shuffle = False):\n    # create a grid of 4x4 images\n    fig, axes = plt.subplots(3, 3, figsize=(5,5))\n    axes = axes.flatten()\n    for i in range(0, 9):\n        axes[i].imshow(x_batch[i].reshape(28,28), cmap=pyplot.get_cmap('gray'))\n        axes[i].set_xticks(())\n        axes[i].set_yticks(())\n    plt.tight_layout()\n    break","748370b6":"# Set a learning rate annealeras the callback function\n\"\"\"\nref: https:\/\/www.twblogs.net\/a\/5c114f3ebd9eee5e40bb299e\/\n\u7576\u8a55\u50f9\u6307\u6a19\u4e0d\u518d\u63d0\u5347\u6642\uff0c\u6e1b\u5c11\u5b78\u7fd2\u7387\u3002\n\u7576\u5b78\u7fd2\u505c\u6eef\u6642\uff0c\u6e1b\u5c112\u500d\u621610\u500d\u7684\u5b78\u7fd2\u7387\u5e38\u5e38\u80fd\u7372\u5f97\u8f03\u597d\u7684\u6548\u679c\u3002\n\u8a72\u56de\u8abf\u51fd\u6578\u6aa2\u6e2c\u6307\u6a19\u7684\u60c5\u6cc1\uff0c\u5982\u679c\u5728patience\u500bepoch\u4e2d\u770b\u4e0d\u5230\u6a21\u578b\u6027\u80fd\u63d0\u5347\uff0c\u5247\u6e1b\u5c11\u5b78\u7fd2\u7387\n\n\u53c3\u6578\n\nmonitor\uff1a\u88ab\u76e3\u6e2c\u7684\u91cf\nfactor\uff1a\u6bcf\u6b21\u6e1b\u5c11\u5b78\u7fd2\u7387\u7684\u56e0\u5b50\uff0c\u5b78\u7fd2\u7387\u5c07\u4ee5lr=lr*factor\u7684\u5f62\u5f0f\u6e1b\u5c11\npatience\uff1a\u7576patience\u500bepoch\u904e\u53bb\u800c\u6a21\u578b\u6027\u80fd\u4e0d\u63d0\u5347\u6642\uff0c\u5b78\u7fd2\u7387\u6e1b\u5c11\u7684\u52d5\u4f5c\u6703\u88ab\u89f8\u767c\nmode\uff1a\u2018auto\u2019\uff0c\u2018min\u2019\uff0c\u2018max\u2019\u4e4b\u4e00\uff0c\u5728min\u6a21\u5f0f\u4e0b\uff0c\u5982\u679c\u6aa2\u6e2c\u503c\u4e0d\u518d\u964d\u4f4e\uff0c\u5247\u89f8\u767c\u5b78\u7fd2\u7387\u6e1b\u5c11\u3002\n        \u5728max\u6a21\u5f0f\u4e0b\uff0c\u7576\u6aa2\u6e2c\u503c\u4e0d\u518d\u4e0a\u5347\u5247\u89f8\u767c\u5b78\u7fd2\u7387\u6e1b\u5c11\u3002\nepsilon\uff1a\u95be\u503c\uff0c\u7528\u4f86\u78ba\u5b9a\u662f\u5426\u9032\u5165\u6aa2\u6e2c\u503c\u7684\u201c\u5e73\u539f\u5340\u201c\ncooldown\uff1a\u5b78\u7fd2\u7387\u6e1b\u5c11\u5f8c\uff0c\u6703\u7d93\u904ecooldown\u500bepoch\u624d\u91cd\u65b0\u9032\u884c\u6b63\u5e38\u64cd\u4f5c\nmin_lr\uff1a\u5b78\u7fd2\u7387\u7684\u4e0b\u9650\n\"\"\"\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","aa04ed04":"# Build the net\nfrom sklearn.model_selection import train_test_split \n\nif __name__ == '__main__' and run_model3:\n    X_train_s, X_val, Y_train_s, Y_val = train_test_split(X_train, Y_train_oh, test_size=0.13, random_state=42)\n    model = Sequential()\n    build_lenet5(model, input_shape=X_train_s.shape[1:], dropout=0.15)\n    model.summary()\n    \n    adam = optimizers.Adam()\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n    \n# Fit the model\n# About fit_generator vs fit: https:\/\/blog.csdn.net\/learning_tortosie\/article\/details\/85243310\n#X_val\n#Y_val\n# Use original image to validate\n    epochs = 45\n    batch_size = 72\n    Train_gen_batch = datagen.flow(X_train_s, Y_train_s, batch_size=batch_size)\n    #Val_gen_batch = datagen.flow(X_val, Y_val, batch_size=batch_size)\n    datagen_no_aug = ImageDataGenerator()\n    Val_gen_batch = datagen_no_aug.flow(X_val, Y_val, batch_size=batch_size)\n    hist_dict['run_model3'] = model.fit_generator(Train_gen_batch, epochs = epochs, verbose = 2,\n                                      steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n                                      validation_data = Val_gen_batch,\n                                      validation_steps = X_val.shape[0] \/\/ batch_size,\n                                     callbacks=[learning_rate_reduction])\n\n#history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size), epochs = epochs,\n#                              validation_data = (X_val,Y_val), verbose = 2,\n#                              steps_per_epoch=X_train.shape[0] \/\/ batch_size)\n                              \n                              #, callbacks=[learning_rate_reduction])","80df6bf2":"if __name__ == '__main__' and run_model3:\n    predictions = model_predict(model)\n    print(predictions[:5])\n    write_preds(predictions, \"keras-lenet5-aug.csv\")\n","b49b109a":"# Save prediction in file for Kaggle submission\n#np.savetxt('mnist-pred.csv', np.c_[range(1,len(yPred)+1),yPred], delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')\n\n\n#submission_rf.to_csv('titanic_sk_rf.csv', index=False)","ee056617":"def build_net_advanced(model, input_shape=X_train.shape[1:], dropout=0.25):\n    # N' = (N+2P-F)\/S + 1\n    #S = [1,2,1,2,1]\n    #N_input = [28,28,14,10,5]\n    #P = [2,0,0,0,0]\n    #N = [28,14,10,5,1]\n    #F = [i[0] + 2*i[1] - i[3]*(i[2] - 1) for i in zip(N_input, P, N, S)] #[5,2,5,2]\n    \n\n    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', strides=1,\n                     activation='relu', input_shape=input_shape))\n    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='valid', strides=2,\n                     activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3,3), strides=1))\n    model.add(Dropout(dropout))\n    \n    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', strides=1,\n                     activation='relu'))\n    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='valid', strides=2,\n                     activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2), strides=1))\n    model.add(Dropout(dropout))\n              \n    model.add(Flatten()) \n\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(dropout))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(dropout))\n    #Output: (10)\n    model.add(Dense(10, activation='softmax'))","1e8c146c":"if __name__ == '__main__' and run_model_adv:\n    X_train_s, X_val, Y_train_s, Y_val = train_test_split(X_train, Y_train_oh, test_size=0.15, random_state=42)\n    model = Sequential()\n    build_net_advanced(model, input_shape=X_train_s.shape[1:], dropout=0.3)\n    model.summary()\n    \n    adam = optimizers.Adam()\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n    \n# Fit the model\n# About fit_generator vs fit: https:\/\/blog.csdn.net\/learning_tortosie\/article\/details\/85243310\n# Use original image to validate\n#X_val\n#Y_val\n#history_adv_net\n    epochs = 35\n    batch_size = 84\n    Train_gen_batch = datagen.flow(X_train_s, Y_train_s, batch_size=batch_size)\n    #Val_gen_batch = datagen.flow(X_val, Y_val, batch_size=batch_size)\n    datagen_no_aug = ImageDataGenerator()\n    Val_gen_batch = datagen_no_aug.flow(X_val, Y_val, batch_size=batch_size)\n    hist_dict['run_model_adv'] = model.fit_generator(Train_gen_batch, epochs = epochs, verbose = 2,\n                                      steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n                                      validation_data = Val_gen_batch,\n                                      validation_steps = X_val.shape[0] \/\/ batch_size,\n                                     callbacks=[learning_rate_reduction])","1f0a5251":"if __name__ == '__main__' and run_model_adv:\n    predictions = model_predict(model)\n    print(predictions[:5])\n    write_preds(predictions, \"keras-adv-net.csv\")\n","ddaf18e5":"# Plot the loss and accuracy curves for training and validation \ndef loss_acc_plt(history):\n    fig, ax = plt.subplots(2,1)\n    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n\n    ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n    ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n    \n#if __name__ == '__main__' and run_model_adv:\n#    loss_acc_plt(history_adv_net)\n\nif run_model1:\n    loss_acc_plt(hist_dict['run_model1'])\nif run_model2:\n    loss_acc_plt(hist_dict['run_model2'])\nif run_model3:\n    loss_acc_plt(hist_dict['run_model3'])\nif run_model_adv:\n    loss_acc_plt(hist_dict['run_model_adv'])","91a506ca":"from sklearn.metrics import confusion_matrix\n\n_, X_val_check, _, Y_val_check = train_test_split(X_train, Y_train, test_size=0.1, random_state=1)\nYpred_val_check = model_predict_val(model, set_check=X_val_check)\n","dd25e6c9":"\ncm = confusion_matrix(Y_val_check.values, Ypred_val_check)\ncm","a918d1e5":"plt.figure(figsize = (10,8))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n\nplt.title('Confusion Matrix', fontsize=14)\nplt.colorbar()\nn_classes = cm.shape[0]\nrange_class = range(n_classes)\ntick_marks = np.arange(len(range_class))\nplt.xticks(tick_marks, range_class, rotation=-45, fontsize=14)\nplt.yticks(tick_marks, range_class, fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.ylabel('True label', fontsize=14)\n\nfor i in range_class:\n    for j in range_class:        \n        plt.text(j, i, cm[i,j], horizontalalignment=\"center\", fontsize=14, \n                color=\"white\" if i==j else \"black\")\nplt.plot","351c1f21":"X_val_check[Ypred_val_check != Y_val_check.values].shape[0] \/ X_val_check.shape[0]","772ee7ea":"display_digits(dim = (2,3),\n               X = X_val_check[Ypred_val_check != Y_val_check.values],\n               Y_true = Y_val_check.values[Ypred_val_check != Y_val_check.values],\n               pred = Ypred_val_check[Ypred_val_check != Y_val_check.values])","cfa44da1":"### Showing the image with wrong label","e9346837":"### Basic Model w\/o Augmentation & droupout","dcf8af4e":"### LeNet5 Arch:\n![LeNet5 Arch](https:\/\/cdn-images-1.medium.com\/max\/2400\/1*1TI1aGBZ4dybR6__DI9dzA.png)","b4a49892":"### Basic Model w\/o Augmentation; with droupout=0.2","849749ce":"## Part2: Regularization & Normalization","c415bd6f":"# MNIST & LeNet implementation ","c31beecc":"**Data Visulization**","9a062c38":"### Plotting Training History","302d1290":"## Part1: Data Information and Distribution","bd1e9018":"### Take a look about the augmented images ","c2e25459":"### Basic Model w\/i Augmentation; with droupout setting (acc~99.3%)","dd4c8079":"### Confusion Matrix","1f4ec29b":"## Part3: Model Training\n\nLeNet-5\u5171\u67097\u5c64\uff08\u4e0d\u5305\u542b\u8f38\u5165\uff09\uff0c\u6bcf\u5c64\u90fd\u5305\u542b\u53ef\u8a13\u7df4\u53c3\u6578\u3002\n\u8f38\u5165\u5716\u50cf\u5927\u5c0f\u70ba32x32\uff0c\u6bd4MNIST\u6578\u64da\u96c6\u7684\u5716\u7247\u8981\u5927\u4e00\u4e9b\uff0c\u9019\u9ebc\u505a\u7684\u539f\u56e0\u662f\u5e0c\u671b\u6f5b\u5728\u7684\u660e\u986f\u7279\u5fb5\u5982\u7b46\u5283\u65b7\u9ede\u6216\u89d2\u80fd\u5920\u51fa\u73fe\u5728\u6700\u9ad8\u5c64\u7279\u5fb5\u6aa2\u6e2c\u5b50\u611f\u53d7\u91ce\uff08receptive field\uff09\u7684\u4e2d\u5fc3\u3002\u56e0\u6b64\u5728\u8a13\u7df4\u6574\u500b\u7db2\u7d61\u4e4b\u524d\uff0c\u9700\u8981\u5c0d28x28\u7684\u5716\u50cf\u52a0\u4e0azero paddings.\n\nC1\u5c64\uff1a\u8a72\u5c64\u662f\u4e00\u500b\u5377\u7a4d\u5c64\u3002\u4f7f\u75286\u500b\u5927\u5c0f\u70ba5x5\u7684\u6372\u7a4d\u6838\u5c0d\u8f38\u5165\u5c64\u9032\u884c\u5377\u7a4d\u904b\u7b97\uff0c\u7279\u5fb5\u5716\u5c3a\u5bf8\u70ba32-5+1=28\uff0c\u56e0\u6b64\u7522\u751f6\u500b\u5927\u5c0f\u70ba28x28\u7684\u7279\u5fb5\u5716\u3002\u9019\u9ebc\u505a\u5920\u9632\u6b62\u539f\u5716\u50cf\u8f38\u5165\u7684\u4fe1\u606f\u6389\u5230\u5377\u7a4d\u6838\u908a\u754c\u4e4b\u5916\u3002\n\nS2\u5c64\uff1a\u8a72\u5c64\u662f\u4e00\u500b\u6c60\u5316\u5c64\uff08pooling\uff0c\u4e5f\u7a31\u70ba\u4e0b\u63a1\u6a23\u5c64\uff09\u3002\u9019\u88e1\u63a1\u7528max_pool\uff08\u6700\u5927\u6c60\u5316\uff09\uff0c\u6c60\u5316\u7684size\u5b9a\u70ba2x2\uff0c\u6c60\u5316\u5f8c\u5f97\u52306\u500b14x14\u7684\u7279\u5fb5\u5716\uff0c\u4f5c\u70ba\u4e0b\u4e00\u5c64\u795e\u7d93\u5143\u7684\u8f38\u5165\u3002\n\nC3\u5c64\uff1a\u8a72\u5c64\u4ecd\u70ba\u4e00\u500b\u5377\u7a4d\u5c64\uff0c\u6211\u5011\u9078\u7528\u5927\u5c0f\u70ba5x5\u768416\u7a2e\u4e0d\u540c\u7684\u6372\u7a4d\u6838\u3002\u9019\u88e1\u9700\u8981\u6ce8\u610f\uff1aC3\u4e2d\u7684\u6bcf\u500b\u7279\u5fb5\u5716\uff0c\u90fd\u662fS2\u4e2d\u7684\u6240\u67096\u500b\u6216\u5176\u4e2d\u5e7e\u500b\u7279\u5fb5\u5716\u9032\u884c\u52a0\u6b0a\u7d44\u5408\u5f97\u5230\u7684\u3002\u8f38\u51fa\u70ba16\u500b10x10\u7684\u7279\u5fb5\u5716\u3002\n\nS4\u5c64\uff1a\u8a72\u5c64\u4ecd\u70ba\u4e00\u500b\u6c60\u5316\u5c64\uff0csize\u70ba2x2\uff0c\u4ecd\u63a1\u7528max_pool\u3002\u6700\u5f8c\u8f38\u51fa16\u500b5x5\u7684\u7279\u5fb5\u5716\uff0c\u795e\u7d93\u5143\u500b\u6578\u4e5f\u6e1b\u5c11\u81f316x5x5=400\u3002\n\nC5\u5c64\uff1a\u8a72\u5c64\u6211\u5011\u7e7c\u7e8c\u75285x5\u7684\u6372\u7a4d\u6838\u5c0dS4\u5c64\u7684\u8f38\u51fa\u9032\u884c\u5377\u7a4d\uff0c\u7531120\u500b1x1\u7684\u7279\u5fb5\u5716\u7d44\u6210\u3002\u9019\u6a23C5\u5c64\u7684\u8f38\u51fa\u5716\u7247\u5927\u5c0f\u70ba5-5+1=1\u3002\u6700\u7d42\u8f38\u51fa120\u500b1x1\u7684\u7279\u5fb5\u5716\u3002\u9019\u88e1\u5be6\u969b\u4e0a\u662f\u8207S4\u5168\u9023\u63a5\u4e86\uff0c\u4f46\u4ecd\u5c07\u5176\u6a19\u70ba\u5377\u7a4d\u5c64\uff0c\u539f\u56e0\u662f\u5982\u679cLeNet-5\u7684\u8f38\u5165\u5716\u7247\u5c3a\u5bf8\u8b8a\u5927\uff0c\u5176\u4ed6\u4fdd\u6301\u4e0d\u8b8a\uff0c\u90a3\u8a72\u5c64\u7279\u5fb5\u5716\u7684\u7dad\u6578\u4e5f\u6703\u5927\u65bc1x1 \u3002\n\nF6\u5c64\uff1a\u8a72\u5c64\u8207C5\u5c64\u5168\u9023\u63a5\uff0c\u8f38\u51fa84\u5f35\u7279\u5fb5\u5716\u3002\u70ba\u4ec0\u9ebc\u662f84\uff1f\u4e0b\u9762\u6709\u8ad6\u6587\u7684\u89e3\u91cb\uff08\u611f\u8b1d\u7ffb\u8b6f\uff09\u3002\n\n\u8f38\u51fa\u5c64\uff1a\u8a72\u5c64\u8207F6\u5c64\u5168\u9023\u63a5\uff0c\u8f38\u51fa\u9577\u5ea6\u70ba10\u7684\u5f35\u91cf\uff0c\u4ee3\u8868\u6240\u62bd\u53d6\u7684\u7279\u5fb5\u5c6c\u65bc\u54ea\u500b\u985e\u5225\u3002\uff08\u4f8b\u5982[0,0,0,1,0,0,0,0,0,0]\u7684\u5f35\u91cf\uff0c1\u5728index=3\u7684\u4f4d\u7f6e\uff0c\u6545\u8a72\u5f35\u91cf\u4ee3\u8868\u7684\u5716\u7247\u5c6c\u65bc\u7b2c\u4e09\u985e\uff09\n\n\n> \u6b64\u8655\u70ba\u8ad6\u6587\u5c0dF6\u5c64\u548c\u8f38\u51fa\u5c64\u7684\u89e3\u91cb\uff1a\n> \n> \u8f38\u51fa\u5c64\u7531\u6b50\u5f0f\u5f91\u5411\u57fa\u51fd\u6578\uff08Euclidean Radial Basis Function\uff09\u55ae\u5143\u7d44\u6210\uff0c\u6bcf\u985e\u4e00\u500b\u55ae\u5143\uff0c\u6bcf\u500b\u670984\u500b\u8f38\u5165\u3002\u63db\u53e5\u8a71\u8aaa\uff0c\u6bcf\u500b\u8f38\u51faRBF\u55ae\u5143\u8a08\u7b97\u8f38\u5165\u5411\u91cf\u548c\u53c3\u6578\u5411\u91cf\u4e4b\u9593\u7684\u6b50\u5f0f\u8ddd\u96e2\u3002\u8f38\u5165\u96e2\u53c3\u6578\u5411\u91cf\u8d8a\u9060\uff0cRBF\u8f38\u51fa\u7684\u8d8a\u5927\u3002\u4e00\u500bRBF\u8f38\u51fa\u53ef\u4ee5\u88ab\u7406\u89e3\u70ba\u8861\u91cf\u8f38\u5165\u6a21\u5f0f\u548c\u8207RBF\u76f8\u95dc\u806f\u985e\u7684\u4e00\u500b\u6a21\u578b\u7684\u5339\u914d\u7a0b\u5ea6\u7684\u61f2\u7f70\u9805\u3002\u7528\u6982\u7387\u8853\u8a9e\u4f86\u8aaa\uff0cRBF\u8f38\u51fa\u53ef\u4ee5\u88ab\u7406\u89e3\u70baF6\u5c64\u914d\u7f6e\u7a7a\u9593\u7684\u9ad8\u65af\u5206\u4f48\u7684\u8ca0log-likelihood\u3002\u7d66\u5b9a\u4e00\u500b\u8f38\u5165\u6a21\u5f0f\uff0c\u640d\u5931\u51fd\u6578\u61c9\u80fd\u4f7f\u5f97F6\u7684\u914d\u7f6e\u8207RBF\u53c3\u6578\u5411\u91cf\uff08\u5373\u6a21\u5f0f\u7684\u671f\u671b\u5206\u985e\uff09\u8db3\u5920\u63a5\u8fd1\u3002\u9019\u4e9b\u55ae\u5143\u7684\u53c3\u6578\u662f\u4eba\u5de5\u9078\u53d6\u4e26\u4fdd\u6301\u56fa\u5b9a\u7684\uff08\u81f3\u5c11\u521d\u59cb\u6642\u5019\u5982\u6b64\uff09\u3002\u9019\u4e9b\u53c3\u6578\u5411\u91cf\u7684\u6210\u5206\u88ab\u8a2d\u70ba-1\u62161\u3002\u96d6\u7136\u9019\u4e9b\u53c3\u6578\u53ef\u4ee5\u4ee5-1\u548c1\u7b49\u6982\u7387\u7684\u65b9\u5f0f\u4efb\u9078\uff0c\u6216\u8005\u69cb\u6210\u4e00\u500b\u7cfe\u932f\u78bc\uff0c\u4f46\u662f\u88ab\u8a2d\u8a08\u6210\u4e00\u500b\u76f8\u61c9\u5b57\u7b26\u985e\u76847*12\u5927\u5c0f\uff08\u537384\uff09\u7684\u683c\u5f0f\u5316\u5716\u7247\u3002\u9019\u7a2e\u8868\u793a\u5c0d\u8b58\u5225\u55ae\u7368\u7684\u6578\u5b57\u4e0d\u662f\u5f88\u6709\u7528\uff0c\u4f46\u662f\u5c0d\u8b58\u5225\u53ef\u6253\u5370ASCII\u96c6\u4e2d\u7684\u5b57\u7b26\u4e32\u5f88\u6709\u7528\u3002\u4f7f\u7528\u9019\u7a2e\u5206\u4f48\u7de8\u78bc\u800c\u975e\u66f4\u5e38\u7528\u7684\u201c1 of N\u201d\u7de8\u78bc\u7528\u65bc\u7522\u751f\u8f38\u51fa\u7684\u53e6\u4e00\u500b\u539f\u56e0\u662f\uff0c\u7576\u985e\u5225\u6bd4\u8f03\u5927\u7684\u6642\u5019\uff0c\u975e\u5206\u4f48\u7de8\u78bc\u7684\u6548\u679c\u6bd4\u8f03\u5dee\u3002\u539f\u56e0\u662f\u5927\u591a\u6578\u6642\u9593\u975e\u5206\u4f48\u7de8\u78bc\u7684\u8f38\u51fa\u5fc5\u9808\u70ba0\u3002\u9019\u4f7f\u5f97\u7528sigmoid\u55ae\u5143\u5f88\u96e3\u5be6\u73fe\u3002\u53e6\u4e00\u500b\u539f\u56e0\u662f\u5206\u985e\u5668\u4e0d\u50c5\u7528\u65bc\u8b58\u5225\u5b57\u6bcd\uff0c\u4e5f\u7528\u65bc\u62d2\u7d55\u975e\u5b57\u6bcd\u3002\u4f7f\u7528\u5206\u4f48\u7de8\u78bc\u7684RBF\u66f4\u9069\u5408\u8a72\u76ee\u6a19\u3002\u56e0\u70ba\u8207sigmoid\u4e0d\u540c\uff0c\u4ed6\u5011\u5728\u8f38\u5165\u7a7a\u9593\u7684\u8f03\u597d\u9650\u5236\u7684\u5340\u57df\u5167\u8208\u596e\uff0c\u800c\u975e\u5178\u578b\u6a21\u5f0f\u66f4\u5bb9\u6613\u843d\u5230\u5916\u908a\u3002\n> RBF\u53c3\u6578\u5411\u91cf\u8d77\u8457F6\u5c64\u76ee\u6a19\u5411\u91cf\u7684\u89d2\u8272\u3002\u9700\u8981\u6307\u51fa\u9019\u4e9b\u5411\u91cf\u7684\u6210\u5206\u662f+1\u6216-1\uff0c\u9019\u6b63\u597d\u5728F6 sigmoid\u7684\u7bc4\u570d\u5167\uff0c\u56e0\u6b64\u53ef\u4ee5\u9632\u6b62sigmoid\u51fd\u6578\u98fd\u548c\u3002\u5be6\u969b\u4e0a\uff0c+1\u548c-1\u662fsigmoid\u51fd\u6578\u7684\u6700\u5927\u5f4e\u66f2\u7684\u9ede\u8655\u3002\u9019\u4f7f\u5f97F6\u55ae\u5143\u904b\u884c\u5728\u6700\u5927\u975e\u7dda\u6027\u7bc4\u570d\u5167\u3002\u5fc5\u9808\u907f\u514dsigmoid\u51fd\u6578\u7684\u98fd\u548c\uff0c\u56e0\u70ba\u9019\u5c07\u6703\u5c0e\u81f4\u640d\u5931\u51fd\u6578\u8f03\u6162\u7684\u6536\u6582\u548c\u75c5\u614b\u554f\u984c\u3002\n\n> \u4f5c\u8005\uff1aLowesYang\n> \u94fe\u63a5\uff1ahttps:\/\/juejin.im\/post\/5935771ffe88c20061d6beb4\n> \u6765\u6e90\uff1a\u6398\u91d1\n> \u8457\u4f5c\u6743\u5f52\u4f5c\u8005\u6240\u6709\u3002\u5546\u4e1a\u8f6c\u8f7d\u8bf7\u8054\u7cfb\u4f5c\u8005\u83b7\u5f97\u6388\u6743\uff0c\u975e\u5546\u4e1a\u8f6c\u8f7d\u8bf7\u6ce8\u660e\u51fa\u5904\u3002\n> ","58ffbba2":"**The distribution of labels training examples seems quite balance.**","4ffcfab9":"### Advanced Net Building"}}