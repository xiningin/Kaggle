{"cell_type":{"6ffccfde":"code","c1598314":"code","8e841402":"code","d9a80383":"code","6cff8958":"code","2e652c05":"code","f73b71bb":"code","b3f626d2":"code","1b36307d":"code","f4b1e3c5":"code","d8dbeace":"code","98aeb2d0":"code","f16f3418":"code","534375aa":"code","a7666054":"code","515002f6":"code","f7d201ba":"code","3dcc9852":"code","1165b69f":"code","22a74df7":"code","5c303118":"code","97641a38":"code","39458b12":"code","d4095577":"code","12279cc1":"code","bfaa8311":"code","98734076":"code","e21b8d3c":"code","8a9292ba":"code","d3331b16":"code","f8c9c24c":"code","66ea1d3d":"code","dc02ea1d":"markdown","73c196d0":"markdown","6b795d22":"markdown","b7469ad3":"markdown","c09ab2bf":"markdown","66369859":"markdown","769dfdc8":"markdown"},"source":{"6ffccfde":"from google.colab import drive\ndrive.mount('\/content\/drive')","c1598314":"## Can be used for removing \u0627\u0644\u062a\u0634\u0643\u064a\u0644 \n!pip install pyarabic","8e841402":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport time\nimport glob\nfrom random import shuffle\nfrom pyarabic import araby\nfrom tensorflow.keras.layers import GRU, Embedding, Dense, Input, Dropout, Bidirectional, BatchNormalization, Flatten, Reshape\nfrom tensorflow.keras.models import Sequential\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","d9a80383":"!pip install --upgrade --force-reinstall --no-deps kaggle\n!mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\/\n!chmod 600 ~\/.kaggle\/kaggle.json\n!kaggle competitions download -c machathon2-qualifications","6cff8958":"import zipfile\nfilename = \"machathon2-qualifications.zip\"\nwith zipfile.ZipFile(filename, 'r') as zipf:\n  zipf.extractall()\n  print(\"Done\")","2e652c05":"with open('labels.txt', 'r') as f:\n  label2name = f.readlines()\n  label2name = [name.replace('\\n', '') for name in label2name]","f73b71bb":"import pandas as pd\n## It was enough to test the data with 100 examples as the data was convenient\ndata = pd.read_csv('train.csv')\ntrain_data = data[:19900]  \ntest_data = data[19900:]","b3f626d2":"x_train = np.array(train_data['data'])\ny_train  = np.array(train_data['labels'])\n\nx_test = np.array(test_data['data'])\ny_test = np.array(test_data['labels'])","1b36307d":"## To exclude any useless parts in the \"\u0634\u0637\u0631\" or \"\u0627\u0644\u0628\u064a\u062a\"\nexecluded = '!()*-\u0640.:=o[]\u00ab\u00bb;\u061b,\u060c~?\u061f\\u200f\\ufeff\u0640'\n\nfor i in tqdm(range(len(x_train))):\n  out = \"\"\n  #x_train[i] = araby.strip_tashkeel(x_train[i])\n  for c in x_train[i]:\n    if c not in execluded:\n      out += c\n  x_train[i] = out\n\nfor i in tqdm(range(len(x_test))):\n  out = \"\"\n  #x_test[i] = araby.strip_tashkeel(x_test[i])\n  for c in x_test[i]:\n    if c not in execluded:\n      out += c\n  x_test[i] = out","f4b1e3c5":"## Almost 1900 examples are taken to validate the model to make sure the model generalizes well\nX_train, X_valid , y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.1, random_state = 41)","d8dbeace":"# Creating a mapping from unique characters to indices\nvocab = set(' '.join(x_train))\nchar2idx = {u:i+1 for i, u in enumerate(vocab)}\n\ndef to_sequences(X):\n  X = [[char2idx[char] for char in line] for line in X]\n  X = pad_sequences(X, padding='post', value=0, maxlen = 100)\n  return X\n \nX_train = to_sequences(X_train)\nX_valid = to_sequences(X_valid)\n\ny_train = np.array(y_train)\ny_valid = np.array(y_valid)","98aeb2d0":"## Steps taken to get the 95% accuracy:\n\n### Training 40 epochs on the first Model, then realoading the same weights \n### following up with 20 epochs on the second model which only differs from\n### the first in the dropout layers\n\nfrom tensorflow import keras\n\n\n############### 70 epochs #########\n\nmodel = Sequential()\nmodel.add(Input((100,)))\nmodel.add(Embedding(len(char2idx)+1,256))\nmodel.add(Bidirectional(tf.keras.layers.LSTM(units = 256, return_sequences=True)))\nmodel.add(Dropout(0.7))\nmodel.add(Bidirectional(tf.keras.layers.LSTM(units = 1024)))\nmodel.add(Dropout(0.75)) \nmodel.add(Dense((512), activation = 'relu'))\nmodel.add(Dropout(0.75)) \nmodel.add(Dense(len(label2name), activation = 'softmax'))\nmodel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","f16f3418":"model.summary()","534375aa":"## Creating a callback to recall best accuracy achieved on the validation set\n\ncallbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001)]\ncallbacks += [tf.keras.callbacks.ModelCheckpoint('full_verse.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')]","a7666054":"## Train the model for than 60 epochs at least\nmodel.fit(X_train, y_train, validation_data= (X_valid, y_valid), epochs = 70, batch_size= 32, shuffle = True, callbacks=callbacks)","515002f6":"## Loading best weights that achieved best accuracy\n\nmodel = tf.keras.models.load_model('full_verse.h5')","f7d201ba":"def classify(sentence):\n\n  sequence = [char2idx[char] for char in sentence]\n  sequence = pad_sequences([sequence], maxlen = X_train.shape[1], padding='post', value=0)\n\n  pred = model.predict(sequence)[0]\n  pred = np.argmax(pred, 0)\n  return pred","3dcc9852":"prediction = []\nfor i in tqdm(range(len(x_test))):\n    prediction.append(classify(x_test[i]))","1165b69f":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, prediction))","22a74df7":"submission = pd.read_csv('test.csv')\nsubmission","5c303118":"test = np.array(submission['data'])\ntest","97641a38":"for i in tqdm(range(len(test))):\n  out = \"\"\n  #test[i] = araby.strip_tashkeel(test[i])\n  for c in test[i]:\n    if c not in execluded:\n      out += c\n  test[i] = out","39458b12":"preds = []\nfor i in tqdm(range(len(test))):\n    preds.append(classify(test[i]))","d4095577":"ids = [str(id_val) for id_val in range(submission.shape[0])]\nsample_submission = pd.DataFrame(np.array([ids,preds]).T,columns=['id','labels'])\nsample_submission.to_csv(\"sample_submission13_95xxx.csv\",index=False)","12279cc1":"sample_submission","bfaa8311":"submission_final = pd.read_csv('\/content\/final_round_test.csv')\nsubmission_final","98734076":"final_test = np.array(submission_final['data'])\nfinal_test","e21b8d3c":"for i in tqdm(range(len(final_test))):\n  out = \"\"\n  #test[i] = araby.strip_tashkeel(test[i])\n  for c in final_test[i]:\n    if c not in execluded:\n      out += c\n  final_test[i] = out","8a9292ba":"final_preds = []\nfor i in tqdm(range(len(final_test))):\n    final_preds.append(classify(final_test[i]))","d3331b16":"ids = [str(id_val) for id_val in range(submission_final.shape[0])]\nsample_submission = pd.DataFrame(np.array([ids,final_preds]).T,columns=['id','labels'])\nsample_submission.to_csv(\"final_submission_v9530.csv\",index=False)","f8c9c24c":"sample_submission","66ea1d3d":"## Concatenate  to get ' High results '\n## Concatenate the training data with the predictions made in order to get a higher generalization of the process\nX_test = to_sequences(x_test)\nTEST = to_sequences(test)\nPreds = np.array(preds)\nY_test = np.array(y_test)\nX_total = np.concatenate((X_train,X_test,TEST),axis=0)\ny_total = np.concatenate((y_train,Y_test,Preds),axis=0)\n\ncallbacks2 = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001)]\ncallbacks2 += [tf.keras.callbacks.ModelCheckpoint('full_verse2.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')]\n## setting 6 to 10 epochs is enough\nmodel.fit(X_total, y_total, validation_data= (X_valid, y_valid), epochs =8 , batch_size= 32, shuffle = True,callbacks= callbacks2)\nmodel = tf.keras.models.load_model('full_verse2.h5')\n\n## After that you can re-create your submission results in order to get a better score on the leaderboard","dc02ea1d":"## My model","73c196d0":"## Classify on the test set splitted from the dataset ","6b795d22":"## Final submission\nSubmit the predictions on the final qualifying leaderboard","b7469ad3":"## after modelig","c09ab2bf":"## Training process","66369859":"## Submission\nSubmit the predictions on the qualifying leaderboard","769dfdc8":"## Model summary"}}