{"cell_type":{"529266f2":"code","82dcacfb":"code","f4fd12b5":"code","5c44e7d6":"code","a4e3a7d2":"code","2d7cb827":"markdown","628967ee":"markdown","b6a0c486":"markdown","4996a3fc":"markdown","27d7f0d8":"markdown","e0461385":"markdown","80eda813":"markdown","eb253e3c":"markdown","634b937f":"markdown"},"source":{"529266f2":"DATA_DIR = \"..\/input\/applications-of-deep-learningwustl-spring-2020\/\"\n\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tensorflow.keras.utils import to_categorical\n\nprint(\"Loading original data...\")\ndf = pd.read_csv(DATA_DIR+\"train.csv\")\nX = np.array(df.drop(['id','glasses'], axis=1))\ny = np.array(to_categorical(df['glasses']))\nprint(\"Done!\")","82dcacfb":"print(X.shape, y.shape)","f4fd12b5":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization\n\nprint(\"Creating model...\")\n\nmodel = Sequential([\n    Dense(512, input_shape=X.shape[1:]), BatchNormalization(), LeakyReLU(0.1), Dropout(0.1),\n    Dense(512), BatchNormalization(), LeakyReLU(0.1), Dropout(0.3),\n    Dense(512), BatchNormalization(), LeakyReLU(0.1), Dropout(0.3),\n    Dense(512), BatchNormalization(), LeakyReLU(0.1), Dropout(0.3), \n    Dense(256), BatchNormalization(), LeakyReLU(0.1), \n    Dense(y.shape[:][1], activation='softmax')    \n])\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])\nprint(\"Model created.\")","5c44e7d6":"from tensorflow.keras.callbacks import ModelCheckpoint\n\nmc = ModelCheckpoint('best_model.h5', monitor='loss', mode='min', verbose=1, save_best_only=True)\n\nmodel.fit(X, y, \n          epochs=1000, \n          validation_split=0.2, \n          callbacks=[mc])\n\nprint(\"Model trained.\")","a4e3a7d2":"print(\"Loading best model...\")\nmodel.load_weights(\"best_model.h5\")\n\nprint(\"Loading test data...\")\ndf = pd.read_csv(DATA_DIR+\"test.csv\")\nX = np.array(df.drop(['id'], axis=1))\ny = model.predict_proba(X)\ndf['glasses'] = y[:,1]\ndf['glasses'] = df['glasses']\ndf[['id','glasses']].to_csv(\"submission.csv\", index=False)\n\nprint(df[['id','glasses']].head(20))\nprint(\"Done!\")","2d7cb827":"# Step 6: Post-Mortem Analysis\nClearly some of the results are erroneous, but that was expected due to the erroneous labeling.  The only thing to do at this point is to play around with the model structure to try to move up the leaderboard.","628967ee":"If I did it right, *X* should have 4500 rows of 512 elements each while *y* should have 4500 rows of 2 elements which represent category 0 (no glasses) and category 1 (glasses)","b6a0c486":"# Step 2: Process the Input \nAlthough I could have used a binary classification scheme, I chose to use a multi-class classification to allow for expanded categorization in the future.  This required a one-hot-encoding of the labels which I chose to implement via Keras to_categorical() method.","4996a3fc":"# Introduction:\nY'know that moment when you realize that you have probably had the optimal answer for weeks, but your unfamiliarity with the programming tools being used has hampered your progress...?\n\nThat was today.  I had not explored Keras callbacks, and my ignorance of the ModelCheckpoint callback probably cost me dozens of hours of frustration.  Lo and behold!  Once the callback was added, my results improved by an order of magnitude.\n\nAh well... welcome to learning Python, Pandas, Numpy, Tensorflow and Keras.\n\nAnd more frustration before finally figuring out the automatic submission process which attaches the relevant notebook to the submission.  DOH!\n\nWelcome to learning Kaggle!","27d7f0d8":"# Step 3: Build your Model\nThe little trick of letting the label set the length of the final output was not one I had found; but, it made sense.  Let the training label data set the output size automatically!","e0461385":"# Step 1: Exploratory Data Analysis\nDoing a visual exploratory data analysis of the training images, we see that there are a number of images that are mislabeled.  Faces 30 and 31 are both identified in the training data as having glasses, yet visual inspection shows they do not.  \n\nColor me masochistic, but I did a visual review of the training images and found ~540 or the 4,500 images to be improperly labeled for a base error rate of 12% over the training data.  \n\nSince this project was supposed to properly detect glasses in StyleGAN2-generated images, I knew I needed to correct the labels to avoid a garbage-in\/garbage-out effect.\n\nYeah... that'll be in a different notebook.  This notebook is about moving towards an optimal score on the leaderboard.","80eda813":"# Step 4: Train your Model\n![](http:\/\/)I dunno about you, but as I wrote that I flashed on \"How to Train your Dragon.\"  Meh.\nHere's where we add the code for the ModelCheckpoint callback.","eb253e3c":"OK.  So the basic data is ready to go... erroneous labels and all.  Do I sound salty?  Naaaaahhhhhh!  Well... a bit perhaps.  I absolutely loathe generating incorrect outcomes just to try to climb the leaderboard.  ","634b937f":"# Step 5: Load the Best, and Test the Rest\nCheesy... but accurate!  Load the best weights saved via the checkpoint callback, and run predictions against the test data."}}