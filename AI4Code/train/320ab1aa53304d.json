{"cell_type":{"fb3fea41":"code","963d453b":"code","67bc8a83":"code","e44faf88":"code","41c1df8c":"code","eae7b218":"code","e4e411cc":"code","3652ca9e":"code","1e50f22d":"code","7ed0b7ac":"code","a018fe15":"code","cca5ecec":"code","8813dde5":"code","c68c70cd":"code","b31d24ee":"code","ecc2d1af":"code","dc2be8d3":"code","51b2a9ae":"code","ea4fbf0f":"code","d5b47c61":"code","db56f5b5":"code","7c728d70":"code","f1efe850":"code","df073667":"code","84bd4f47":"markdown"},"source":{"fb3fea41":"# !nvidia-smi","963d453b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\n# from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model, load_model\n# from tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom keras import backend\nfrom keras.utils import plot_model\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport os","67bc8a83":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.5\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","e44faf88":"# Declarations\ntrain_path = '..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train'\ntest_path = '..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid'\n\n# re-size all the images to this\nIMAGE_SIZE = [224, 224]\nBATCH_SIZE = 32\nEPOCHS = 8\nRANDOM_SEED = 42\n\nif backend.image_data_format() == 'channels_first':\n    INPUT_SHAPE = (3, IMAGE_SIZE[0], IMAGE_SIZE[1])\nelse:\n    INPUT_SHAPE = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n\nprint(f'input_shape: {INPUT_SHAPE}')\n\n# useful for getting number of output classes\ncount_of_classes = len(glob(train_path+'\/*'))\nprint(count_of_classes)","41c1df8c":"# Prepare train\/test using ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   validation_split=0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","eae7b218":"#### conventional read\n\n# labels = {\n#     'healthy': 0,\n#     'Late_blight': 1,\n#     'Early_blight': 2,\n#     'Septoria_leaf_spot': 3,\n#     'Tomato_Yellow_Leaf_Curl_Virus': 4,\n#     'Bacterial_spot': 5,\n#     'Target_Spot': 6,\n#     'Tomato_mosaic_virus': 7,\n#     'Leaf_Mold': 8,\n#     'Spider_mites Two-spotted_spider_mite': 9\n# }\n# labels_inv = dict((y,x) for x,y in labels.items())\n\n# X_train = []\n# y_train = []\n# X_test = []\n# y_test = []\n\n# # read train data\n# for train_class_path in glob(train_path+'\/*'):\n#     class_label = labels[train_class_path.split('___')[1]]\n#     print(f': Reading {train_class_path} images')\n#     for img in glob(train_class_path+'\/*'):\n#         img = load_img(img, color_mode='rgb', target_size=IMAGE_SIZE)\n#         X_train.append(np.array(img))\n#         y_train.append(class_label)\n\n# # read test data\n# for test_class_path in glob(test_path+'\/*'):\n#     class_label = labels[test_class_path.split('___')[1]]\n#     print(f': Reading {test_class_path} images')\n#     for img in glob(test_class_path+'\/*'):\n#         img = load_img(img, color_mode='rgb', target_size=IMAGE_SIZE)\n#         X_test.append(np.array(img))\n#         y_test.append(class_label)\n\n# X_train = np.array(X_train)\n# y_train = np.array(y_train)\n# X_test = np.array(X_test)\n# y_test = np.array(y_test)\n# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n\n# training_set = train_datagen.flow(x=X_train,\n#                    y=y_train,\n#                    batch_size=BATCH_SIZE, seed=RANDOM_SEED)\n\n# test_set = test_datagen.flow(x=X_test,\n#                    y=y_test,\n#                    batch_size=BATCH_SIZE, seed=RANDOM_SEED)","e4e411cc":"#### read directly from directories\n\ntraining_set = train_datagen.flow_from_directory(train_path,\n                                                 target_size = tuple(IMAGE_SIZE),\n                                                 batch_size = BATCH_SIZE,\n                                                 subset='training',\n                                                 class_mode = 'categorical')\n\ntraining_set2 = train_datagen.flow_from_directory(train_path,\n                                                 target_size = tuple(IMAGE_SIZE),\n                                                 batch_size = BATCH_SIZE,\n                                                 subset='validation',\n                                                 class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory(test_path,\n                                            target_size = tuple(IMAGE_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = 'categorical')","3652ca9e":"# Target class labels\nlabels_inv = dict((y,x) for x,y in training_set.class_indices.items())\nlabels_inv","1e50f22d":"data, label = training_set.next()\n\nplt.figure(figsize=(6, 6))\nplt.imshow(data[4])\nplt.title(label[2])\nplt.show()","7ed0b7ac":"# Here we will be using imagenet weights\n\nvgg16 = VGG16(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)","a018fe15":"# don't train existing weights\nfor layer in vgg16.layers:\n    layer.trainable = False","cca5ecec":"# our layers - you can add more if you want\nx = Flatten()(vgg16.output)\n\nprediction = Dense(count_of_classes, activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=vgg16.input, outputs=prediction)\n\nmodel.compile(loss='categorical_crossentropy',\n              metrics=['accuracy'],\n              optimizer='adam')\nplot_model(model, show_shapes=True)","8813dde5":"model.summary()","c68c70cd":"# fit the model\n\n### using generator\nhistory = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=EPOCHS,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","b31d24ee":"# plot the loss\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='test loss')\nplt.legend()\nplt.show()\nplt.savefig('Loss over Epochs')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='test accuracy')\nplt.legend()\nplt.show()\nplt.savefig('Accuracy over Epochs')","ecc2d1af":"# Save models\nmodel.save('model_vgg16_complete')\nmodel.save('model_vgg16_tf', save_format='tf')\nmodel.save('model_vgg16.h5')\n\n# del model","dc2be8d3":"# 1. Load saved models\nmodel_tf = load_model(\"model_vgg16_tf\")\nmodel_h5 = load_model(\"model_vgg16.h5\")\nmodel_complete_pb = load_model(\"model_vgg16_complete\")","51b2a9ae":"# a. Using only validation data for further learning\nhistory = model_tf.fit_generator(\n  training_set2,\n  validation_data=test_set,\n  epochs=EPOCHS,\n  steps_per_epoch=len(training_set2),\n  validation_steps=len(test_set)\n)\n\n# plot the loss\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='test loss')\nplt.legend()\nplt.show()\nplt.savefig('Loss over Epochs')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='test accuracy')\nplt.legend()\nplt.show()\nplt.savefig('Accuracy over Epochs')","ea4fbf0f":"# a. Using only validation data for further learning\nhistory = model_h5.fit_generator(\n  training_set2,\n  validation_data=test_set,\n  epochs=EPOCHS,\n  steps_per_epoch=len(training_set2),\n  validation_steps=len(test_set)\n)\n\n# plot the loss\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='test loss')\nplt.legend()\nplt.show()\nplt.savefig('Loss over Epochs')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='test accuracy')\nplt.legend()\nplt.show()\nplt.savefig('Accuracy over Epochs')","d5b47c61":"# a. Using only validation data for further learning\nhistory = model_complete_pb.fit_generator(\n  training_set2,\n  validation_data=test_set,\n  epochs=EPOCHS,\n  steps_per_epoch=len(training_set2),\n  validation_steps=len(test_set)\n)\n\n# plot the loss\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='test loss')\nplt.legend()\nplt.show()\nplt.savefig('Loss over Epochs')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='test accuracy')\nplt.legend()\nplt.show()\nplt.savefig('Accuracy over Epochs')","db56f5b5":"# # b. Using Training + Validation data for further learning\n# complete_train_datagen = ImageDataGenerator(rescale = 1.\/255,\n#                                    shear_range = 0.2,\n#                                    zoom_range = 0.2,\n#                                    horizontal_flip = True)\n\n# complete_train = complete_train_datagen.flow_from_directory(train_path,\n#                                                  target_size = tuple(IMAGE_SIZE),\n#                                                  batch_size = BATCH_SIZE,\n#                                                  class_mode = 'categorical')\n\n# history = complete_model.fit_generator(\n#   complete_train,\n#   validation_data=test_set,\n#   epochs=EPOCHS,\n#   steps_per_epoch=len(complete_train),\n#   validation_steps=len(test_set)\n# )\n\n# # plot the loss\n# plt.plot(history.history['loss'], label='train loss')\n# plt.plot(history.history['val_loss'], label='test loss')\n# plt.legend()\n# plt.show()\n# plt.savefig('Loss over Epochs')\n\n# # plot the accuracy\n# plt.plot(history.history['accuracy'], label='train accuracy')\n# plt.plot(history.history['val_accuracy'], label='test accuracy')\n# plt.legend()\n# plt.show()\n# plt.savefig('Accuracy over Epochs')","7c728d70":"# # 2. Load H5 format:\n# h5_model = load_model(\"model_vgg16.h5\")","f1efe850":"# # a. Using only validation data for further learning\n\n# history = h5_model.fit_generator(\n#   training_set2,\n#   validation_data=test_set,\n#   epochs=EPOCHS,\n#   steps_per_epoch=len(training_set2),\n#   validation_steps=len(test_set)\n# )\n\n# # plot the loss\n# plt.plot(history.history['loss'], label='train loss')\n# plt.plot(history.history['val_loss'], label='test loss')\n# plt.legend()\n# plt.show()\n# plt.savefig('Loss over Epochs')\n\n# # plot the accuracy\n# plt.plot(history.history['accuracy'], label='train accuracy')\n# plt.plot(history.history['val_accuracy'], label='test accuracy')\n# plt.legend()\n# plt.show()\n# plt.savefig('Accuracy over Epochs')","df073667":"# # b. Using Training + Validation data for further learning\n\n\n# history = h5_model.fit_generator(\n#   complete_train,\n#   validation_data=test_set,\n#   epochs=EPOCHS,\n#   steps_per_epoch=len(complete_train),\n#   validation_steps=len(test_set)\n# )\n\n# # plot the loss\n# plt.plot(history.history['loss'], label='train loss')\n# plt.plot(history.history['val_loss'], label='test loss')\n# plt.legend()\n# plt.show()\n# plt.savefig('Loss over Epochs')\n\n# # plot the accuracy\n# plt.plot(history.history['accuracy'], label='train accuracy')\n# plt.plot(history.history['val_accuracy'], label='test accuracy')\n# plt.legend()\n# plt.show()\n# plt.savefig('Accuracy over Epochs')","84bd4f47":"## Let's test incremental learning\n\nPlease note, previously we only trained on the training set1 and evaluated on test set, training_set2 was untouched. Here, we'll load models, which were saved in various formats, train them on training_set2, and evaluate them on test set. Expectation is to observe the improved validation frequency from the beginning itself, and by end see an overall improvement over training 1."}}