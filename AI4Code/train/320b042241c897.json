{"cell_type":{"e9a8880d":"code","6c467b98":"code","ef2f20c3":"code","e1e35c43":"code","cb2afb36":"code","280b6c2e":"code","ddc1511a":"code","7aa1478a":"code","6a9dbf01":"code","e3c582f4":"code","0c9334f8":"code","a962ffcd":"code","dc72d699":"code","5b3aaa20":"code","0b6ec97a":"code","9a091756":"code","39a04339":"code","a1cde49b":"code","469d3066":"markdown","ce5f8797":"markdown","5711f06a":"markdown","b9e4ab6c":"markdown","4bf12372":"markdown","368f13ef":"markdown","a69ff0c6":"markdown","2310596e":"markdown","7f995dce":"markdown"},"source":{"e9a8880d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c467b98":"# Load the libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.utils import shuffle","ef2f20c3":"def load_images_from_folder(folder,only_path = False, label = \"\"):\n# Load the paths to the images in a directory\n# or load the images\n    if only_path == False:\n        images = []\n        for filename in os.listdir(folder):\n            img = cv2.imread(os.path.join(folder,filename))\n            if img is not None:\n                images.append(img)\n        return images\n    else:\n        path = []\n        for filename in os.listdir(folder):\n            img_path = os.path.join(folder,filename)\n            if img_path is not None:\n                path.append([label,img_path])\n        return path","e1e35c43":"# Load the paths on the images\nimages = []\ndirp = \"\/kaggle\/input\/fruit-recognition\/\"\nfor f in os.listdir(dirp):\n    if \"png\" in os.listdir(dirp+f)[0]:\n        images += load_images_from_folder(dirp+f,True,label = f)\n    else:\n        for d in os.listdir(dirp+f):\n            images += load_images_from_folder(dirp+f+\"\/\"+d,True,label = f)","cb2afb36":"df = pd.DataFrame(images, columns = [\"fruit\", \"path\"])","280b6c2e":"df.head()","ddc1511a":"# shuffle dataset\ndf = shuffle(df, random_state = 0)\ndf = df.reset_index(drop=True)\n\n# Assign to each fruit a specific number\nfruit_names = sorted(df.fruit.unique())\nmapper_fruit_names = dict(zip(fruit_names, [t for t in range(len(fruit_names))]))\ndf[\"label\"] = df[\"fruit\"].map(mapper_fruit_names)\nprint(mapper_fruit_names)","7aa1478a":"df.head(15)","6a9dbf01":"plt.figure(figsize=(15,10))\np = df[\"fruit\"].value_counts().plot(kind='bar',color='r')\nplt.title(\"Distribution of the fruit types\", fontsize = 20)\np.tick_params(labelsize=16)\nplt.show()","e3c582f4":"# Display 20 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.path[i]))\n    ax.set_title(df.fruit[i])\nplt.tight_layout()\nplt.show()\n","0c9334f8":"def load_img(df):\n# Load the images using their contained in the dataframe df\n# Return a list of images and a list with the labels of the images\n    img_paths = df[\"path\"].values\n    img_labels = df[\"label\"].values\n    X = []\n    y = []\n    \n    for i,path in enumerate(img_paths):\n        img =  cv2.imread(path)\n        img = cv2.resize(img, (150,150))\n        label = img_labels[i]\n        X.append(img)\n        y.append(label)\n    return np.array(X),np.array(y)\n\n\ndef from_categorical(lst):\n    \"\"\"\n    Inverse of to_categorical\n    Example: [[0,0,0,1,0], [1,0,0,0,0]] => [3,0]\n    \"\"\"\n    \n    lst = lst.tolist()\n    lst2 = []\n    for x in lst:\n        lst2.append(x.index(max(x)))\n    return lst2\n\n\ndef display_stats(y_test, pred):\n# Display prediction statistics\n    print(f\"### Result of the predictions using {len(y_test)} test data ###\\n\")\n    y_test_class = from_categorical(y_test)\n    print(\"Classification Report:\\n\")\n    print(classification_report(y_test_class, pred))\n    print(\"\\nConfusion Matrix:\\n\\n\")\n    print(confusion_matrix(y_test_class, pred))\n    print(\"\\nAccuracy:\", round(accuracy_score(y_test_class, pred),5))\n    \ndef plot_training(model):\n    history = pd.DataFrame(model.history.history)\n    history[[\"accuracy\",\"val_accuracy\"]].plot()\n    plt.title(\"Training results\")\n    plt.xlabel(\"# epoch\")\n    plt.show()\n    \ndef cut_df(df, number_of_parts, part):\n# Return a part of the dataframe\n# For example, if a dataframe has 10 rows and we want to return a part of them\n# if it is cut in two, it will return the first 5 rows or the last 5 rows depending the part wanted\n\n# Args:\n#     df (pandas.DataFrame): The dataframe to cut a part of\n#     number_of_parts (int): In how many parts should the dataframe be cut\n#     part (int): The part of the dataframe to return\n\n    if part < 1:\n        print(\"Error, the part should be at least 1\")\n    elif part > number_of_parts:\n        print(\"Error, the part cannot be higher than the number_of_parts\")\n        \n    number_imgs_each_part = int(df.shape[0]\/number_of_parts)\n    idx1 = (part-1) * number_imgs_each_part\n    idx2 = part * number_imgs_each_part\n    return df.iloc[idx1:idx2]","a962ffcd":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(150,150,3), activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(len(mapper_fruit_names)))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","dc72d699":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","5b3aaa20":"X_train, y_train = load_img(cut_df(df,3,2))\ny_train = to_categorical(y_train)","0b6ec97a":"hists = []\ncallbacks = [EarlyStopping(monitor='val_loss', patience=10),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n    \nmodel.fit(X_train, y_train, batch_size=128, epochs=80, callbacks=callbacks, validation_split = 0.1, verbose = 1)\nhists.append(model.history.history)\n    \n# Delete X_train and y_train to avoid using too much RAM\ndel X_train\ndel y_train","9a091756":"acc = []\nval_acc = []\nfor i in range(len(hists)):\n    acc += hists[i][\"accuracy\"]\n    val_acc += hists[i][\"val_accuracy\"]\nhist_df = pd.DataFrame({\"# Epoch\": [e for e in range(1,len(acc)+1)],\"Accuracy\": acc, \"Val_accuracy\": val_acc})\nhist_df.plot(x = \"# Epoch\", y = [\"Accuracy\",\"Val_accuracy\"])\nplt.title(\"Accuracy vs Validation Accuracy\")\nplt.show()","39a04339":"# Make predictions with the model using the last 1\/20 part of the dataset\nX, y = load_img(cut_df(df, 20, 17))\npred = model.predict_classes(X)\ny_test = to_categorical(y)\n\n# Display statistics\ndisplay_stats(y_test, pred)","a1cde49b":"fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(X[-i])\n    ax.set_title(f\"True label: {fruit_names[y[-i]]}\\nPredicted label: {fruit_names[pred[-i]]}\")\n\nplt.tight_layout()\nplt.show()","469d3066":"**Encoding the fruit categories and shuffling the dataset**","ce5f8797":"**Distribution of different fruits in the dataset**","5711f06a":"98% validation accuracy is as good as it gets! ","b9e4ab6c":"# MDELLING AND TRAINING","4bf12372":"**Predictions**","368f13ef":"**Creating a dataframe of fruits and their respective image paths**","a69ff0c6":"Let's look at some of the images.","2310596e":"**Training**","7f995dce":"# LOADING AND PREPROCESSING THE IMAGES"}}