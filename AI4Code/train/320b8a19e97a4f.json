{"cell_type":{"757f9d29":"code","fda9b0bb":"code","5b4b8ee2":"code","e8bae573":"code","490d669e":"code","e2714bfc":"code","4141292e":"markdown","64ae4d73":"markdown","61cad27c":"markdown","e2fe53f5":"markdown","bb20f33f":"markdown","07131d92":"markdown","246892ee":"markdown","fbd627ad":"markdown","b6449d7e":"markdown","7559a1c9":"markdown","a4f6b703":"markdown"},"source":{"757f9d29":"import pandas as pd\ntrain =pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\ntrain = train.drop('id',axis=1)\ntest = test.drop('id',axis=1)\n\nprint(\"train data : \",len(train))\nprint(\"test data : \",len(test))","fda9b0bb":"train.isna().sum()","5b4b8ee2":"test.isna().sum()","e8bae573":"y_train = train['claim']\nX_train = train.drop('claim',axis=1)\n\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\nX_train = imp_mean.fit_transform(X_train)\ntest = imp_mean.transform(test)","490d669e":"from lightgbm import LGBMRegressor\n\nmodel = LGBMRegressor(n_estimators=1000)\nmodel.fit(X_train,y_train)\npredict = model.predict(test)","e2714bfc":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\nsample['claim'] = predict\nsample.to_csv(\"test.csv\",index=None)\nsample","4141292e":"### Hello Kaggler !\n### This time, I prepare the LightGBM tutorial.","64ae4d73":"### When you visit the LightGBM document site, You can see that first.\n### I think LightGBM is faster than other M\/L models, and show high accuracy !\n### Just use it !","61cad27c":"### If you see the dataset, It has so many rows ! \n### When i saw this dataset. I surprised.. So I think that, I will prepare the fast ML model.\n### That is LightGBM!","e2fe53f5":"### You should fill the NaN data first !","bb20f33f":"### If you want more accuracy, try adjsut parameters !","07131d92":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:skyblue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nLightGBM\n<\/h1>\n<\/div>","246892ee":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:skyblue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nCheck the dataset!\n<\/h1>\n<\/div>","fbd627ad":"### I just use SimpleImputer ","b6449d7e":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:skyblue;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n<h1 style=\"text-align: center;\n           padding: 10px;\n              color:white\">\nTabular Playground Series - Sep 2021\n<\/h1>\n<\/div>\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/25226\/logos\/header.png?t=2021-01-27-17-34-31)\n\n","7559a1c9":"![](https:\/\/lightgbm.readthedocs.io\/en\/latest\/_images\/LightGBM_logo_black_text.svg)","a4f6b703":"### Welcome to LightGBM\u2019s documentation!\n#### LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\n* Faster training speed and higher efficiency.\n* Lower memory usage.\n* Better accuracy.\n* Support of parallel, distributed, and GPU learning.\n* Capable of handling large-scale data."}}