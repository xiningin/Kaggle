{"cell_type":{"c53077e9":"code","4bff2aa1":"code","70a796be":"code","1eec99e5":"code","c9ea5c9d":"code","18eced50":"code","917e7a97":"code","a31844dd":"code","305d8acd":"code","06b31788":"code","a647a557":"code","36dfd999":"code","574ec816":"code","73e20df6":"code","5567f057":"code","ede0705c":"code","bfe47548":"markdown","7d7c0e21":"markdown","9ab52bc4":"markdown","ab848aff":"markdown","e5d8fced":"markdown","8d567eb0":"markdown","0c7e72ca":"markdown","7425e7dd":"markdown","ac994e6e":"markdown","d964f61d":"markdown"},"source":{"c53077e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport nltk\nimport nltk.corpus\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4bff2aa1":"#List the classes in corpus\n\nprint(os.listdir(nltk.data.find(\"corpora\")))","70a796be":"# Sample of a list of words in 'brown'\nnltk.corpus.brown.words()","1eec99e5":"# Tokenizing string into individual words in a list\n\nfrom nltk.tokenize import word_tokenize\n\ntext = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science,\nand artificial intelligence concerned with the interactions between computers and human language,\nin particular how to program computers to process and analyze large amounts of natural language data.\nThe goal is a computer capable of \"understanding\" the contents of documents, including the contextual\nnuances of the language within them. The technology can then accurately extract information and insights\ncontained in the documents as well as categorize and organize the documents themselves.\n\nNatural language processing has its roots in the 1950s. Already in 1950, Alan Turing\npublished an article titled \"Computing Machinery and Intelligence\" which proposed what\nis now called the Turing test as a criterion of intelligence, though at the time that\nwas not articulated as a problem separate from artificial intelligence. The proposed\ntest includes a task that involves the automated interpretation and generation of natural language.\n\"\"\"\n\ntokens = word_tokenize(text) # Resulting list of individual words\ntokens[:15] # The list is very long so only the first 15 words are being printed","c9ea5c9d":"# Tokenizing the paragraphs into list\n\nfrom nltk.tokenize import blankline_tokenize\n\nbl_tokens = blankline_tokenize(text) # Resulting list of individual paragraphs\nbl_tokens","18eced50":"# Frequency distribution for number of repeating words in an object FreqDist (like a dictionary)\n\nfrom nltk.probability import FreqDist\nfd = FreqDist()\n\nfor stri in tokens:\n    fd[stri.lower()] += 1\n\n# Top 10 most common words in the text\nfd_ten = fd.most_common(10)","917e7a97":"from nltk.util import bigrams, trigrams, ngrams\n\n# Creates a list of two consecutive words in a tuple\nt_bi = list(nltk.bigrams(tokens))\n\n# Creates a list of three consecutive words in a tuple\nt_tri = list(nltk.trigrams(tokens))\n\n# Creates a list of N consecutive words in a tuple\nt_ngr = list(nltk.ngrams(tokens, 4))\n\n\nprint(str(t_bi[:5]) + \"\\n\" + str(t_tri[:5]) + \"\\n\" + str(t_ngr[:5]))","a31844dd":"from nltk.stem import PorterStemmer\np = PorterStemmer()\n\nwords = [\"affection\", \"having\", \"chooses\", \"loses\", \"given\", \"gave\"]\nporterstem = {}\n\nfor w in words:\n    porterstem[w] = p.stem(w)\n\nporterstem","305d8acd":"from nltk.stem import LancasterStemmer\nl = LancasterStemmer()\n\nlanstem = {}\n\nfor w in words:\n    lanstem[w] = l.stem(w)\n    \nlanstem","06b31788":"from nltk.stem import SnowballStemmer\ns = SnowballStemmer('english')\n\nsnowstem = {}\n\nfor w in words:\n    snowstem[w] = s.stem(w)\n    \nsnowstem","a647a557":"# Converts variations of a word into the proper word\nfrom nltk.stem import wordnet\nfrom nltk.stem import WordNetLemmatizer\nlem = WordNetLemmatizer()\n\nlemstem = {}\n\nfor w in words:\n    lemstem[w] = lem.lemmatize(w)\n\n# The output is as is because it's missing POS (pards of speech)\nlemstem","36dfd999":"# Stopwords are redundant words that are not that important for nlp\nfrom nltk.corpus import stopwords\n\nlen(stopwords.words('english'))\nfd_ten","574ec816":"import re\npunctuation = re.compile(r'[-.?!,;:()|0-9]')\n\n# A list of all the punctuations and numbers removed\npunc_removed = []\n\nfor w in tokens:\n    word = punctuation.sub(\"\", w)\n    if len(word) > 0:\n        punc_removed.append(word)\n        \npunc_removed[:15]","73e20df6":"sample_str = \"This is a very short sentence and my name is John White House\"\ntoken_sample = word_tokenize(sample_str)\n\nfor t in token_sample:\n    print(nltk.pos_tag([t]))","5567f057":"# For identification of a named entity, such as 'John' in the example above\n\nfrom nltk import ne_chunk\n\nne_tags = nltk.pos_tag(token_sample)\nner = ne_chunk(ne_tags)\nprint(ner)","ede0705c":"# Chunking - grouping of individual pieces (here, tokens or strings) into a larger structure (a sentence or paragraph)\ngrammar = r\"NP: {<DT>?<JJ>*<NN>}\"\n\nchunk_parse = nltk.RegexpParser(grammar)\n\nchunk_result = chunk_parse.parse(ne_tags)\nprint(chunk_result)","bfe47548":"Acknowledgement & Credit: https:\/\/www.youtube.com\/watch?v=X2vAabgKiuM&t=715s","7d7c0e21":"# Tokenization\n\nThe concept of converting a string into individual words or tokens","9ab52bc4":"As you can see the way these functions work is by grouping immediate consecutive words, in every possible, sequential manner","ab848aff":"### Named Entity Recognition\n\nDiscerning a name from a string of words or tokens","e5d8fced":"# Parts of Speech","8d567eb0":"### Just a quick overview of the concepts of Natural Language Processing done through the great library, nltk of python.\n\n# Inspecting some specific data contained in nltk:","0c7e72ca":"### Bigrams, Trigrams, and Ngrams","7425e7dd":"# Stemming\n\nThe concept of finding the stem word from its variations in English","ac994e6e":"### Chunking\n\nGrouping together of the words after identification","d964f61d":"# Lemmatization\n\nThe process of grouping inflected forms of a word"}}