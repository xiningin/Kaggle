{"cell_type":{"38074a6c":"code","f2e2ec6e":"code","5a12fcca":"code","4a0ccadf":"code","79ffb10b":"code","a2d9e1a1":"code","8f18e845":"code","b80b6646":"code","659af925":"code","839e5a72":"code","a8cb87bd":"code","9c5f37b1":"code","3c934377":"code","c10c69cb":"code","85db4f8e":"code","7c34bade":"markdown","ded4afc8":"markdown"},"source":{"38074a6c":"import pandas as pd\n\ndfs= pd.read_html('https:\/\/www.cdc.gov\/niosh\/npptl\/respirators\/testing\/NonNIOSHresults.html')\nimport matplotlib.pyplot as plt\n\nplaces = pd.read_csv(\"..\/input\/china-city-names-with-province\/city_names_lat_long.csv\")\n","f2e2ec6e":"places.head() ","5a12fcca":"prov_names= places.Province.value_counts().index\nplaces.set_index('Province', inplace=True)","4a0ccadf":"df= dfs[0] \ndf[df.columns[3]].median\n\ndf.columns=['Manufacturer', 'Model', 'Standard',\n       'max_fe', 'min_fe',\n       'Test Report']\ndf['name_len'] =  df.Manufacturer.str.split().str.len()\ndf['name1'] = df.Manufacturer.str.split().str.get(0)\ndf['name2'] =  df.Manufacturer.str.split().str.get(1)\ndf['name3'] =  df.Manufacturer.str.split().str.get(2)\ndf['ispname'] = df.name1.isin(prov_names)\ndf['mod_len'] = df.Model.str.split().str.len()      #model number of words\ndf.drop(index=df.index[(df.Manufacturer == '3M')])  #no prejudice\n\n\ndf['pass'] = df.min_fe >= 95 \ndf['mfg_ntests']=  df[['Manufacturer','Test Report']].groupby('Manufacturer')['Test Report'].transform(pd.Series.count)\n#df[['Manufacturer','Test Report']].groupby(by='Manufacturer').count().sort_values(by='Test Report', ascending=False)\ntarget='pass'","79ffb10b":"means = df[['Manufacturer','name1','max_fe','min_fe']].groupby(by='name1').mean().sort_values(by='min_fe', ascending=False)\nax = means.plot(figsize=(10,5))\nax.set_title('Min, Max FE ranges')\nax.hlines(y=95, xmin=df.name1[0], xmax='Yufing', color='red')","a2d9e1a1":"df = df.join(places, on='name1', how='left')\n\ndf.Latitude.fillna(value=df.Latitude.mean(),inplace=True)\ndf.Longitude.fillna(value=df.Longitude.mean(),inplace=True)","8f18e845":"features = [ 'mod_len','ispname',\n         'name_len', 'name1', 'name2',\n       'name3', 'mfg_ntests','Latitude','Longitude','city']","b80b6646":"import matplotlib.colors\ncmap = 'RdPu'\nc= df.min_fe\n\nax= df.plot.scatter(x='Latitude',y='Longitude', c=c,cmap='RdBu', alpha= .6,figsize=(6,6))\nax.set_xlabel('latitude')","659af925":"import seaborn as sns\nax = sns.heatmap(\n    df.corr(), \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)","839e5a72":"fi_feat = ['mfg_ntests','ispname','mod_len'] # by feature importance lr\n#features = fi_feat","a8cb87bd":"from sklearn.model_selection import train_test_val_split\n\ntrain,test,val = train_test_val_split(df,val_size=.2,test_size= .2,random_state =3)\ntrain.shape,test.shape,val.shape\n\nX_train= train[features]\ny_train= train[target]\nX_val=   val[features]\ny_val  = val[target]\nX_test = test[features]\ny_test = test[target]\n\nbaseline= df[target].value_counts(normalize=True).values[0] #baseline\nprint( df[target].value_counts(normalize=True)) #predict false= FAIL  \n","9c5f37b1":"import category_encoders as ce\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom xgboost import XGBClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.feature_selection import SelectKBest\n\nmodels = [RidgeClassifierCV(),LogisticRegression(),XGBClassifier() , RandomForestClassifier(),DecisionTreeClassifier() ]\n\nfor model in models:\n    pipe = make_pipeline( ce.OrdinalEncoder(),SimpleImputer(), model)\n    pipe.fit(X_train,y_train)\n    print(list(pipe.named_steps.keys())[-1])\n    print('Training Accuracy:', pipe.score(X_train, y_train))\n    print('Validation Accuracy:', pipe.score(X_val, y_val))\n    print('Test Accuracy:', pipe.score(X_test, y_test))\n    print('baseline Accuracy:', baseline,'\\n')","3c934377":"pipe.named_steps['simpleimputer']","c10c69cb":"import eli5\nfrom eli5.sklearn  import PermutationImportance\nprint('logreg')\nperm = PermutationImportance(pipe, random_state=887).fit(pipe.named_steps['ordinalencoder'].transform(X_test),y_test)\neli5.show_weights(perm, feature_names = pipe.named_steps['ordinalencoder'].get_feature_names())\n\n","85db4f8e":"from pdpbox import pdp, get_dataset, info_plots\n\nfeature  = 'Latitude'\nmfg_name_length=  pdp.pdp_isolate(model=pipe, dataset=X_test,\n                              model_features= pipe.named_steps['ordinalencoder'].get_feature_names(),\n                                  feature =feature)\npdp.pdp_plot(mfg_name_length, feature)\nplt.show()\n#so we conclude the more words the manufacturer name contains, the more likely they are to fail","7c34bade":"This is just a fun exploration of a tiny set of test results performed by the National PPE Testing Lab. The tests are being conducted on non-NIOSH approved facemask type respirators, most commonly, the KN95. Iniitally the FDA issued an emergency blanket approval allowing the import of non-approved models. Unfortunately there are many outright fake or low quality versions of this PPE being produced and sold. As can be seen if you follow along, some of the worst test results show a complete lack of efficacy. \n\nSince the information provided by the dataset was very sparse, and the initial models were barely beating baseline, I pulled a few tricks out of the feature engineer's magic hat. \n\nFirst, after realizing that many of the manufacturer names contained a city and or province name, I crudely parsed these out by extracting the first 3 terms in the name. You can probably guess that I suspected that some places might be better than others. This was not initially the case, but it as interesting to note that the longer factory names were associated more strongly with a minimum filtration efficiency below the 95% standard.\n\n","ded4afc8":"grabbed a list of city and province names from the web, minimally processed to separate province\nthis is clearly a subset of all chinese cities."}}