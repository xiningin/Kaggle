{"cell_type":{"bd77561d":"code","f09849b6":"code","bca4a02d":"code","fc69e779":"code","0ab5ce0c":"code","b30514b4":"code","9946bbae":"code","b479d399":"code","6655b0e6":"code","a432c1f8":"code","df9ba57d":"code","28caae16":"code","9ca04459":"code","e9325d95":"code","a1912561":"code","33d7f690":"code","8089af84":"code","f8f4acd0":"code","65512fca":"code","44284170":"code","a0761710":"code","58bfbd3a":"code","440bf7e7":"code","7cfada6e":"code","7e0bf8e6":"code","34204c23":"code","4a708e2b":"code","4e4b4904":"code","f53f61dd":"code","0fa68327":"code","10fc8801":"code","562c00c6":"code","d75900cc":"code","c65eb541":"code","c6d9ef1b":"code","410a4203":"code","7c8f9260":"code","d869b0e9":"code","1fcb3b32":"code","c8b90928":"code","6780327a":"code","db8e6f05":"code","5523c12f":"code","61f1ff30":"code","be6587f0":"code","6fbe25b3":"code","c45ed2c2":"code","99421b19":"markdown","fe79f34a":"markdown","1f1ba840":"markdown","c9466f82":"markdown","1ea02fb5":"markdown","dfee5dce":"markdown","b4d724b6":"markdown","c0b7b98a":"markdown","d10be46e":"markdown","975e0ccc":"markdown","9935f9bc":"markdown","451542be":"markdown","bcd7c27f":"markdown","1da4a0f0":"markdown","85cbd9bc":"markdown","c1d42320":"markdown","6cbc8200":"markdown","e341a97d":"markdown","7f570b51":"markdown","085fe0bd":"markdown","6ac40401":"markdown","0e4a818f":"markdown","66e6797e":"markdown","409e14a2":"markdown"},"source":{"bd77561d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.svm import SVC","f09849b6":"data=pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","bca4a02d":"data.head()","fc69e779":"data.shape","0ab5ce0c":"data.isnull().sum()","b30514b4":"data.describe()","9946bbae":"data['quality'].unique()","b479d399":"data.info()","6655b0e6":"sns.countplot(data['quality'])","a432c1f8":"data.corr()","df9ba57d":"data_columns=data.columns","28caae16":"for ele in data_columns:\n    fig = plt.figure(figsize = (10,6))\n    sns.barplot(x = 'quality', y = ele, data = data)","9ca04459":"for i in range(1599):\n    if(data['quality'][i]<=6.5):\n        data['quality'][i]=0\n    else:\n        data['quality'][i]=1","e9325d95":"data['quality'].unique()","a1912561":"sns.countplot(data['quality'])","33d7f690":"model=LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=1000)","8089af84":"y=data['quality']\nX=data.drop(['quality'],axis=1)","f8f4acd0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","65512fca":"model.fit(X_train,y_train)","44284170":"model.score(X_test,y_test)","a0761710":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","58bfbd3a":"print(classification_report(y_test, pred_rfc))","440bf7e7":"print(confusion_matrix(y_test, pred_rfc))","7cfada6e":"clf = SVC() ","7e0bf8e6":"clf.fit(X_train, y_train) ","34204c23":"pred_svc=clf.predict(X_test)","4a708e2b":"print(classification_report(y_test, pred_svc))","4e4b4904":"print(confusion_matrix(y_test, pred_svc))","f53f61dd":"data_1=data[data.quality == 1]","0fa68327":"data_0=data[data.quality == 0]","10fc8801":"data_1.info()","562c00c6":"data_0.info()","d75900cc":"data_1_new = pd.concat([data_1, data_1],ignore_index=True, sort =False)","c65eb541":"data_1_new.info()","c6d9ef1b":"data_new = pd.concat([data_1_new,data_0],ignore_index=True, sort =False)","410a4203":"data_new.info()","7c8f9260":"y_new=data_new['quality']\nX_new=data_new.drop(['quality'],axis=1)","d869b0e9":"X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.20)","1fcb3b32":"model=LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=1000)","c8b90928":"model.fit(X_train,y_train)","6780327a":"model.score(X_test,y_test)","db8e6f05":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","5523c12f":"print(classification_report(y_test, pred_rfc))","61f1ff30":"clf = SVC() ","be6587f0":"clf.fit(X_train, y_train) ","6fbe25b3":"pred_svc_new=clf.predict(X_test)","c45ed2c2":"print(classification_report(y_test, pred_svc_new))","99421b19":"## Looks like resampling the data worked.","fe79f34a":"###### In this notebook, First I have done some exploration on the data using matplotlib and seaborn. Then, I use different classifier models to predict the quality of the wine.\n\n1. Logistic regression\n\n2. Random Forest Classifier\n \n3. Support Vector Classifier(SVC)\n\n###### then i did some resampling in the given data as the data is imbalanced which gave me some different results.","1f1ba840":"###### converting the quality to 0 and 1 depending on their score.","c9466f82":"###### as per the problem statement we have to classify the wine type in two varities good or bad.\n\n###### 1 for good and 0 for bad.\n\n###### the criteria to decide whether it is good or bad is that if the quality score is less than 6.5 it is a bad wine and if it is greater than 6.5 it is considered as good.","1ea02fb5":"###### Accuracy from logistic regression is 85.9\n###### Accuracy from Random Forest classifier is 91\n###### Accuracy from support vector machine is 85","dfee5dce":"###### this data is also imbalanced but lets continue with this data and see what we can do.","b4d724b6":"###### Collecting all the rows of quality 1 and all the rows of quality 0.","c0b7b98a":"###### importing required packages","d10be46e":"###### using support vector machine\nsvc documentation https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html","975e0ccc":"###### running the above cell will replicate the data_1 dataframe and thus it will create a dataframe with more rows with the same data.","9935f9bc":"Over-Sampling increases the number of instances in the minority class by randomly replicating them in order to present a higher representation of the minority class in the sample.","451542be":"###### Accuracy from logistic regression is 85.9\n###### Accuracy from Random Forest classifier is 95\n###### Accuracy from support vector machine is 89","bcd7c27f":"###### some basic observation of the dataset.","1da4a0f0":"###### using all the above models one by one again on this resampled data.","85cbd9bc":"as we can see the data is imbalanced .\n\nthe quality 5 and 6 of the wine are in large number compared to other qualities.\n\n","c1d42320":"###### some visualisation between the various features and the quality of the wine.","6cbc8200":"# If you like my work give it a thumps UP.","e341a97d":"### Resampling\nData imbalance can be treated with resampling the data. data resampling can be of two types.\nundersampling and oversampling.\n\nhere i am using oversampling.\n","7f570b51":"###### using random forest\n\nrandom forest documentation https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html","085fe0bd":"###### no null values great!!","6ac40401":"###### now we have two varities in our quality column either 0 or 1 and the count of each variety is shown in the countplot .","0e4a818f":"###### Concatenating the two dataframes data_1_new and data_0 to create a training dataset for further use","66e6797e":"###### using logistic regression model .","409e14a2":"so thats a very good accuracy with a logistic regression model.\n\nlet's try some other methods in the data."}}