{"cell_type":{"a6ef65bf":"code","83dfadf8":"code","ee2addbc":"code","08f267a1":"code","78f546b4":"code","461a24bb":"code","a6d76157":"code","0c9c0fb3":"code","a3a764d3":"code","446bdc62":"code","8d46eea3":"code","874991f9":"code","91f94f8b":"code","193cfa79":"code","21933ac6":"code","2033e1fc":"code","4484e0f5":"code","2c88c1dc":"code","718f4851":"code","c92e2045":"code","49a76f86":"code","c83cec94":"markdown"},"source":{"a6ef65bf":"!pip install lungs-segmentation","83dfadf8":"import torch\nimport albumentations as A\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom sklearn.preprocessing import MinMaxScaler\n\n# last import\nfrom lungs_segmentation.pre_trained_models import create_model","ee2addbc":"import lungs_segmentation.inference as inference","08f267a1":"## Start the process\nmodel = create_model(\"resnet34\")\n\n\n## Make sure you have activated the GPU from colab\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)","78f546b4":"torch.cuda.is_available()","461a24bb":"# create the directories\ndirs = ['train','test','val']\nsub_dirs = ['NORMAL','PNEUMONIA']\n\nfor dir in dirs:\n    try:\n        os.mkdir('\/kaggle\/working\/' + dir)\n\n        for sub_dir in sub_dirs:\n            os.mkdir('\/kaggle\/working\/' + dir + '\/' + sub_dir + '\/')\n    except Exception:\n        pass","a6d76157":"pneumonia_img_filenames = []\nnormal_img_filenames = []\n\nfor folder in ['train','test','val']:\n\n    print('-' * 20, '[ P N E U M O N I A ]', '-' * 20)\n    for i,item in enumerate(os.scandir(f'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/{folder}\/PNEUMONIA')):\n        if i < 10:\n            print(f'--> {item.name}')\n\n        pneumonia_img_filenames.append(item.path)\n\n    print('-' * 20, '[ N O R M A L ]', '-' * 20)\n    for i,item in enumerate(os.scandir(f'\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/{folder}\/NORMAL')):\n        if i < 10:\n            print(f'--> {item.name}')\n\n        normal_img_filenames.append(item.path)   ","0c9c0fb3":"len(normal_img_filenames), len(pneumonia_img_filenames)","a3a764d3":"## Experiment with the code below. Once confortable loop over all the images and supply to the \"inference\" function to get the mask\n\nplt.figure(figsize=(5,5))\n\nplt.subplot(1,1,1)\nimage, mask = inference.inference(model, normal_img_filenames[0], 0.2)\nplt.imshow(inference.img_with_masks( image, [mask[0], mask[1]], alpha = 0.1))","446bdc62":"image_bw = image.mean(axis=2)    # convert to grayscale\nimage_segmented = (image_bw * mask[0]) + (image_bw * mask[1])\n\nplt.imshow(image_segmented, cmap='gray')\nplt.colorbar();","8d46eea3":"mask.shape","874991f9":"def preprocess_image(fn, img_shape=(150,150), scale=True):\n\n    img, mask = inference.inference(model, fn, 0.2)\n    img_bw = img.mean(axis=2)                                    # convert to grayscale\n    img_segmented = (img_bw * mask[0]) + (img_bw * mask[1])\n\n    # resize to specified image shape\n    resized_img = cv2.resize(img_segmented, dsize=(150,150), interpolation=cv2.INTER_CUBIC)\n\n    min_, max_ = np.min(resized_img), np.max(resized_img)\n    resized_img = ((resized_img - min_) \/ (max_ - min_) * 255).astype(int)\n\n    new_fn = '\/kaggle\/working\/' + fn.split('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/')[1]\n    cv2.imwrite(new_fn, resized_img)\n\n    return resized_img","91f94f8b":"def preprocess_image_no_compress(fn, scale=True):\n\n    img, mask = inference.inference(model, fn, 0.2)\n    img_bw = img.mean(axis=2)                                    # convert to grayscale\n    img_segmented = (img_bw * mask[0]) + (img_bw * mask[1])\n\n    # resize to specified image shape\n    #resized_img = cv2.resize(img_segmented, dsize=(150,150), interpolation=cv2.INTER_CUBIC)\n    resized_img = img_segmented\n\n    min_, max_ = np.min(resized_img), np.max(resized_img)\n    resized_img = ((resized_img - min_) \/ (max_ - min_) * 255).astype(int)\n\n    new_fn = '\/kaggle\/working\/' + fn.split('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/')[1]\n    cv2.imwrite(new_fn, resized_img)\n\n    return resized_img","193cfa79":"for i,fn in enumerate(pneumonia_img_filenames):\n            \n    if (i+1) % 200 == 0:\n        print(f'Processed {i+1}th file...')\n    try:\n#         preprocess_image(fn)\n        preprocess_image_no_compress(fn)\n    except Exception:\n        print(f'Error occurred at index {i}, file name: {fn}')","21933ac6":"for i,fn in enumerate(normal_img_filenames):\n    if (i+1) % 200 == 0:\n        print(f'Processed {i+1}th file...')\n    try:\n#         preprocess_image(fn)\n        preprocess_image_no_compress(fn)\n    except Exception:\n        print(f'Error occurred at index {i}, file name: {fn}')","2033e1fc":"train_filenames = [item.path for item in os.scandir('.\/train\/PNEUMONIA')]     # get all file names of train data, pneumonia \ntrain_filenames.extend([item.path for item in os.scandir('.\/train\/NORMAL')])  # ... and normal folder\n\nN_samples = int(len(train_filenames) * 0.2)      # number of samples to augment = 20% of training set\nnp.random.seed(8888)                             # for consistency\nrandom_sample_ix = np.random.randint(0,high=len(train_filenames),size=N_samples)\n\nprint(f'Number of samples to be augmented: {N_samples}')","4484e0f5":"files_to_augment = list(np.array(train_filenames)[random_sample_ix])\nfiles_to_augment[:10]","2c88c1dc":"def augment_image(img, flip_horiz=False, blur=False, blur_size=0, rotate = False, rotate_angle=0):\n    '''\n    Utility function to augment the images... Parameters are self explanatory\n    '''\n    if flip_horiz:    # if flip horizontal\n        img = cv2.flip(img,1)\n    \n    if blur and blur_size > 0:\n        img = cv2.GaussianBlur(img,(blur_size,blur_size),0)\n        \n    if rotate and rotate_angle != 0:\n        width, height, _ = img.shape\n        matrix = cv2.getRotationMatrix2D((width\/2,height\/2),rotate_angle,1)\n        img = cv2.warpAffine(img,matrix,(width,height))\n        \n    return img","718f4851":"img = cv2.imread(files_to_augment[-1])\n\nplt.imshow(augment_image(img, flip_horiz=True, blur=True, blur_size=3, rotate=True, rotate_angle=10))\nplt.title('Flipped Horizontally, Blur = 3 x 3 Gaussian Blur, Rotated 10 degress')","c92e2045":"np.random.seed(8888)    # for consistency\naugmented_images_filenames = []\nfor i,fn in enumerate(files_to_augment):\n    \n    if (i+1) % 100 == 0:\n        print(f'Processing {i+1}th file')\n    \n    try:\n        img = cv2.imread(fn)\n        flip_horiz = np.random.choice([True,False])\n        blur = np.random.choice([True,False])\n        if blur:\n            blur_size = np.random.choice([1,3,5])\n        rotate = np.random.choice([True,False])\n        if rotate:\n            rotate_angle = np.random.randn() * 15     # rotate up to 15 degrees\n        else:\n            rotate_angle = 0\n\n        augmented = augment_image(img,flip_horiz,blur,blur_size,rotate,rotate_angle)\n\n        new_fn = fn.split('.jpeg')[0] + 'augmented.jpeg'\n        augmented_images_filenames.append(new_fn)\n        cv2.imwrite(new_fn, augmented)   \n    except Exception as e:\n        print(f'Error occurred at file index {i}, filename: {fn}')","49a76f86":"augmented_images_filenames[:25]   # sample of augmented file names","c83cec94":"# Image augmentations\nOnly use samples from Train folder"}}