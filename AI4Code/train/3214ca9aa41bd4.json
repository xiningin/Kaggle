{"cell_type":{"b2b5172d":"code","c7e37a05":"code","0f281768":"code","edfd3d95":"code","cb87d4a5":"code","9a583268":"code","b04baa45":"code","d1c2f422":"code","8e8b036c":"code","9ed4e927":"code","2fe1e96d":"code","f9f1495d":"code","02d4a4a8":"code","f058aef0":"code","21646068":"code","f314b393":"code","fc755dec":"code","85b26dbe":"code","bda12ebb":"code","d6766191":"code","4cf9a361":"code","7077f4e6":"code","c26a7366":"code","878f71a3":"code","76acdca0":"code","edc1cba3":"code","1b2a9162":"code","e93bb976":"code","64019924":"code","f6613bc0":"code","4ee25f60":"code","548f08c9":"code","b36a0f50":"code","50e4b91b":"code","1ad638dc":"code","0d567fb3":"code","581673c0":"code","d96a76fc":"code","b684ac2b":"code","dee5e9db":"code","fbe25670":"code","e1ff3af5":"markdown","3d5afa2f":"markdown","2c91da29":"markdown","91f34dd6":"markdown","4579ef38":"markdown","e43a6732":"markdown","06d252d5":"markdown","c30a4697":"markdown","67eff001":"markdown","b18074bd":"markdown","3bc9f3a1":"markdown","9cdc10d4":"markdown","88c4bb7e":"markdown","e6975dc8":"markdown","241e0a0b":"markdown"},"source":{"b2b5172d":"import tensorflow as tf","c7e37a05":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.losses import categorical_crossentropy\nfrom sklearn.metrics import accuracy_score\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"..\/input\"))","0f281768":"data = pd.read_csv('..\/input\/fer2013\/fer2013.csv')\n#check data shape\ndata.shape","edfd3d95":"#preview first 5 row of data\ndata.head(5)","cb87d4a5":"#check usage values\n#80% training, 10% validation and 10% test\ndata.Usage.value_counts()","9a583268":"#check target labels\nemotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\nemotion_counts = data['emotion'].value_counts(sort=False).reset_index()\nemotion_counts.columns = ['emotion', 'number']\nemotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\nemotion_counts","b04baa45":"# Plotting a bar graph of the class distributions\nplt.figure(figsize=(6,4))\nsns.barplot(emotion_counts.emotion, emotion_counts.number)\nplt.title('Class distribution')\nplt.ylabel('Number', fontsize=12)\nplt.xlabel('Emotions', fontsize=12)\nplt.show()","d1c2f422":"def row2image(row):\n    pixels, emotion = row['pixels'], emotion_map[row['emotion']]\n    img = np.array(pixels.split())\n    img = img.reshape(48,48)\n    image = np.zeros((48,48,3))\n    image[:,:,0] = img\n    image[:,:,1] = img\n    image[:,:,2] = img\n    return np.array([image.astype(np.uint8), emotion])\n\nplt.figure(0, figsize=(16,10))\nfor i in range(1,8):\n    face = data[data['emotion'] == i-1].iloc[0]\n    img = row2image(face)\n    plt.subplot(2,4,i)\n    plt.imshow(img[0])\n    plt.title(img[1])\n\nplt.show()  ","8e8b036c":"#split data into training, validation and test set\ndata_train = data[data['Usage']=='Training'].copy()\ndata_val   = data[data['Usage']=='PublicTest'].copy()\ndata_test  = data[data['Usage']=='PrivateTest'].copy()\n#data_train = data_train[data_train['emotion']!=1]\n#data_val = data_val[data_val['emotion']!=1]\n##data_test = data_test[data_test['emotion']!=1]\n#data_train['emotion'] = data_train['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n#data_test['emotion'] = data_test['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n#data_val['emotion'] = data_val['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\nprint(\"train shape: {}, \\nvalidation shape: {}, \\ntest shape: {}\".format(data_train.shape, data_val.shape, data_test.shape))","9ed4e927":"# barplot class distribution of train, val and test\nemotion_labels = ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndef setup_axe(axe,df,title):\n    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)\n    axe.set_xticklabels(emotion_labels)\n    axe.set_xlabel(\"Emotions\")\n    axe.set_ylabel(\"Number\")\n    axe.set_title(title)\n    \n    # set individual bar lables using above list\n    for i in axe.patches:\n        # get_x pulls left or right; get_height pushes up or down\n        axe.text(i.get_x()-.05, i.get_height()+120, \\\n                str(round((i.get_height()), 2)), fontsize=14, color='dimgrey',\n                    rotation=0)\n\n   \nfig, axes = plt.subplots(1,3, figsize=(20,8), sharey=True)\nsetup_axe(axes[0],data_train,'train')\nsetup_axe(axes[1],data_val,'validation')\nsetup_axe(axes[2],data_test,'test')\nplt.show()","2fe1e96d":"#initilize parameters\nnum_classes = 7\nwidth, height = 48, 48\nnum_epochs = 50\nbatch_size = 64\nnum_features = 64","f9f1495d":"# CRNO stands for Convert, Reshape, Normalize, One-hot encoding\n# (i) convert strings to lists of integers\n# (ii) reshape and normalise grayscale image with 255.0\n# (iii) one-hot encoding label, e.g. class 3 to [0,0,0,1,0,0,0]\n\ndef CRNO(df, dataName):\n    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n    data_X = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1,width, height,1)\/255.0   \n    data_Y = to_categorical(df['emotion'], num_classes)  \n    print(dataName, \"_X shape: {}, \", dataName, \"_Y shape: {}\".format(data_X.shape, data_Y.shape))\n    return data_X, data_Y\n\n    \ntrain_X, train_Y = CRNO(data_train, \"train\") #training data\nval_X, val_Y     = CRNO(data_val, \"val\") #validation data\ntest_X, test_Y   = CRNO(data_test, \"test\") #test data","02d4a4a8":"import os\nimport cv2\n\ndata_path = '..\/input\/ckplus\/CK+48'\ndata_dir_list = os.listdir(data_path)\n\nimg_data_list=[]\n\nnumbers = []\nc=0\n\nfor dataset in data_dir_list:\n    img_list=os.listdir(data_path+'\/'+ dataset)\n    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n    for img in img_list:\n        input_img=cv2.imread(data_path + '\/'+ dataset + '\/'+ img )\n        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n        input_img_resize=cv2.resize(input_img,(48,48))\n        input_img_resize = np.reshape(input_img_resize,(48,48,1))\n        img_data_list.append(input_img_resize)\n        c += 1\n    numbers.append(c)\n    c = 0\n        \nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data = img_data\/255\nimg_data.shape","f058aef0":"pl = img_data\nnp.reshape(pl[0],(48,48,1))\npl[0].shape","21646068":"\n\nnum_classes = 7\n\nnum_of_samples = img_data.shape[0]\nlabels = np.ones((num_of_samples,),dtype='int64')\n\nlabels[0:134]=0 #135\nlabels[135:188]=6 #54\nlabels[189:365]=1 #177\nlabels[366:440]=2 #75\nlabels[441:647]=3 #207\nlabels[648:731]=4 #84\nlabels[732:980]=5 #249\n\nnames = ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndef getLabel(id):\n    return ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'][id]","f314b393":"from keras.utils import np_utils, to_categorical\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nY = np_utils.to_categorical(labels, num_classes)\n\n#Shuffle the dataset\nx,y = shuffle(img_data,Y, random_state=2)\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)","fc755dec":"from tensorflow import Tensor\nfrom tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,Add, AveragePooling2D, Flatten, Dense\nfrom tensorflow.keras.models import Model\n\ndef relu_bn(inputs: Tensor) -> Tensor:\n    relu = ReLU()(inputs)\n    bn = BatchNormalization()(relu)\n    return bn\n\ndef residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n    y = Conv2D(kernel_size=kernel_size,\n               strides= (1 if not downsample else 2),\n               filters=filters,\n               padding=\"same\")(x)\n    y = relu_bn(y)\n    y = Conv2D(kernel_size=kernel_size,\n               strides=1,\n               filters=filters,\n               padding=\"same\")(y)\n\n    if downsample:\n        x = Conv2D(kernel_size=1,\n                   strides=2,\n                   filters=filters,\n                   padding=\"same\")(x)\n    out = Add()([x, y])\n    out = relu_bn(out)\n    return out\n\ndef create_res_net():\n    \n    inputs = Input(shape=(48, 48, 1))\n    num_filters = 32\n    \n    t = BatchNormalization()(inputs)\n    t = Conv2D(kernel_size=3,\n               strides=1,\n               filters=num_filters,\n               padding=\"same\")(t)\n    t = relu_bn(t)\n    \n    num_blocks_list = [2,3, 2]\n    for i in range(len(num_blocks_list)):\n        num_blocks = num_blocks_list[i]\n        for j in range(num_blocks):\n            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n        num_filters *= 2\n    \n    t = AveragePooling2D(4)(t)\n    t = Flatten()(t)\n    #outputs = Dense(10, activation='softmax')(t)\n    \n    model = Model(inputs, t)\n\n    return model\n\n#output layer\n#model.add(Dense(6,activation='softmax'))","85b26dbe":"pip install stn","bda12ebb":"from tensorflow import keras\nfrom keras import layers\nfrom stn import spatial_transformer_network as transformer\n\nimg_inputs = keras.Input(shape=(48,48,1))\n\nlocnet = layers.Conv2D(32,3, padding='same')(img_inputs)\nlocnet = layers.MaxPooling2D(3, padding='same')(locnet)\nlocnet = layers.Activation('relu')(locnet)\nlocnet = layers.BatchNormalization()(locnet)\nlocnet = layers.Conv2D(64,3, padding='same')(locnet)\nlocnet = layers.MaxPooling2D(3, padding='same')(locnet)\nlocnet = layers.Activation('relu')(locnet)\nlocnet = layers.BatchNormalization()(locnet)\nlocnet = layers.Conv2D(96,3, padding='same')(locnet)\nfeat_map = layers.Activation('relu')(locnet)\nlocnet = layers.BatchNormalization()(locnet)\nlocnet = layers.Flatten()(feat_map)\nlocnet = layers.Dense(90, activation='relu',kernel_regularizer='l2')(locnet)\nlocnet = layers.Dropout(0.2)(locnet)\nlocnet = layers.Dense(32, activation='relu', kernel_regularizer='l2')(locnet)\ntheta = layers.Dense(6, activation='linear')(locnet)\n\nlocnet = keras.Model(img_inputs, theta, name=\"locnet\")\n#locnet.summary()\n\n#spatial transformer network\noutstn = transformer(feat_map,theta)\n\n\n\n#feature extraction network\nfe = layers.Conv2D(32,3, padding='same')(img_inputs)\nfe = layers.BatchNormalization()(fe)\nfe = layers.Activation('relu')(fe)\nfe = layers.MaxPooling2D(3,padding='same')(fe)\nfe = layers.Conv2D(64,3, padding='same')(fe)\nfe = layers.BatchNormalization()(fe)\nfe = layers.Activation('relu')(fe)\nfe = layers.MaxPooling2D(3,padding='same')(fe)\nfe = layers.Conv2D(96,3, padding='same')(fe)\nfe = layers.Activation('relu')(fe)\ndo = layers.BatchNormalization()(fe)\n\nfe = keras.Model(img_inputs, do, name=\"feature extractor\")\n#fe.summary()\n\nadd = layers.Add()([outstn, do])\n\nflats = layers.Flatten()(add)\nflats = layers.Dense(64, activation='relu',  kernel_regularizer='l2')(flats)\nflats = layers.Dropout(0.4)(flats)\nflats = layers.Dense(32, activation='relu',  kernel_regularizer='l2')(flats)\nflats = layers.Dropout(0.4)(flats)\n#output = layers.Dense(6, activation='softmax')(flats)\n\nx1 = layers.Dense(7, activation='linear')(flats)\nx2 = layers.Dense(7,activation='linear')(flats)\nx3 = layers.Dense(7,activation='linear')(flats)\nx4 = layers.Dense(7,activation='linear')(flats)\navg = layers.Average()([x1, x2, x3, x4])\nout = layers.Dense(7, activation='softmax')(avg)\n\nmodel = keras.Model(inputs=img_inputs, outputs=out, name=\"FEMSTN\")\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    0.1,\n    decay_steps=1000,\n    decay_rate=0.96,\n    staircase=True)\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=keras.optimizers.SGD(learning_rate=lr_schedule), \n              metrics=['accuracy'])\n\nmodel.summary()","d6766191":"from keras.callbacks import ReduceLROnPlateau\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)","4cf9a361":"from keras.layers import LeakyReLU\n\nmodel = Sequential()\n\n#module 1\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), input_shape=(48, 48, 1), data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n#module 2\nmodel.add(Conv2D(4*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(4*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n#module 3\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#flatten\nmodel.add(Flatten())\n\n#dense 2\nmodel.add(Dense(2*2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dropout(0.3))\n\n\n#dense 4\nmodel.add(Dense(2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(7, activation='softmax'))\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    0.01,\n    decay_steps=100,\n    decay_rate=0.5,\n    staircase=False)\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=keras.optimizers.Adam(0.01), \n              metrics=['accuracy'])\n\nmodel.summary()","7077f4e6":"batch_size = 128\nepochs = 100","c26a7366":"# data generator\ndata_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True\n)\n\n\nes = EarlyStopping(monitor='val_loss', patience = 10, mode = 'min', restore_best_weights=True)\n\ncp_path = '.\/model_bacc.h5'\ncpl_path = '.\/model_fer_bloss.h5'\ncp = tf.keras.callbacks.ModelCheckpoint(filepath=cp_path,save_best_only=True, save_weights_only=False, verbose=0, monitor='val_accuracy')\ncpl = tf.keras.callbacks.ModelCheckpoint(filepath=cpl_path,save_best_only=True, save_weights_only=False, verbose=2, monitor='val_loss')\nhistory = model.fit(data_generator.flow(train_X, train_Y, 256),\n                                epochs=100,\n                                verbose=1, \n                                callbacks = [cp, cpl, es],\n                                validation_data=(val_X, val_Y))","878f71a3":"model.save('.\/model_c.h5')","76acdca0":"from keras import models","edc1cba3":"model = models.load_model('.\/model_bacc.h5')","1b2a9162":"import matplotlib.pyplot as plt","e93bb976":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(history.history['accuracy'])\naxes[0].plot(history.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(history.history['loss'])\naxes[1].plot(history.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","64019924":"test_true = np.argmax(test_Y, axis=1)\ntest_pred = np.argmax(model.predict(test_X), axis=1)\nprint(\"CNN Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))","f6613bc0":"emotion_labels = ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    #else:\n        #print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    fig, ax = plt.subplots(figsize=(12,6))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","4ee25f60":"# Plot normalized confusion matrix\nplot_confusion_matrix(test_true, test_pred, classes=emotion_labels, normalize=True, title='Normalized confusion matrix')\nplt.show()","548f08c9":"['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']","b36a0f50":"exp_map = {0 : 'anger', 1:'disgust' , 6 : 'contempt', 2 : 'fear', 3 : 'happy',4 :'sadness',5 :'surprise'}","50e4b91b":"import math","1ad638dc":"def anger(p):\n    \n    t = 0.343* p + 1.003\n    return 2.332 * math.log(t)\n\ndef fear(p):\n    \n    t = 1.356* p + 1\n    return 1.763 * math.log(t)\n\ndef contempt(p):\n    t = 0.01229* p + 1.036\n    return 5.03 * math.log(t)\n\ndef disgust(p):\n    t = 0.0123* p + 1.019\n    return 7.351 * math.log(t)\n\ndef happy(p):\n    t = 5.221e-5* p + 0.9997\n    return 532.2 * math.log(t)\n\ndef sad(p):\n    t = 0.1328* p + 1.009\n    return 2.851 * math.log(t)\n\ndef surprise(p):\n    t = 0.2825* p + 1.003\n    return 2.478 * math.log(t)","0d567fb3":"samp = test_X[1236]\nsamp = np.reshape(samp,(1,48,48,1))\nsamp.shape","581673c0":"ex_p = model.predict(samp)\nex_p.shape","d96a76fc":"correct = []\ncorrecty = []\nres = model.predict(X_test)\nfor i in range(len(test_Y)):\n    if np.argmax(res[i]) == np.argmax(test_Y[i]):\n        correct.append(res[i])\n        correcty.append(test_Y[i])\ncorrect = np.array(correct)\ncorrecty = np.array(correcty)\ncorrect.shape","b684ac2b":"func = [anger,disgust, fear, happy, sad, surprise,contempt]","dee5e9db":"exp_stress = {}\nfor i,face in enumerate(correct):\n    f = np.argmax(face)\n    x = np.max(face)*100\n    \n    s = func[f](x)\n    sp = s\/9*100\n    \n    if f not in exp_stress.keys():\n        exp_stress[f] = []\n        exp_stress[f].append([sp, f, face, correcty[i]])\n    else:\n        exp_stress[f].append([sp, f, face, correcty[i]])\n        ","fbe25670":"for i in range(7):\n    for j in range(len(exp_stress)):\n        print(exp_stress[i][j])","e1ff3af5":"## Introduction\nFrom Kaggle open resource, we had **training** dataset, **public test** dataset (which is then used as validation dataset for our project), and further a **private test** dataset (same size with public test dataset and will be used as data for evaluating the prediction performance).\n\nImage set of 35,887 examples, with training-set : **80%** validation-set : **10%** test-set : **10%**.\n\n## Objectives\n(i) To apply Convolutional neural networks (CNN) for facial expression recognition.\n \n(ii) To correctly classify each facial image into one of the seven facial emotion categories: **anger**, **disgust**, **fear**, **happiness**, **sadness**, **surprise**, and **neutral**.\n","3d5afa2f":"---------------------------------------------------------------------------------------\n## Import libraries","2c91da29":"## FER Dataset Overview ","91f34dd6":"## Evaluate Test Performance","4579ef38":"# **CK+ OVERVIEW**","e43a6732":"----------------------------------------------------------------------------------\n## Pre-processing data\n#### Summary:\n1. Splitting dataset into 3 parts: train, validation, test\n1. Convert strings to lists of integers\n1. Reshape to 48x48 and normalise grayscale image with 255.0\n1. Perform one-hot encoding label, e.g. class 3 to [0,0,0,1,0,0,0]","06d252d5":"## Visualize Training Performance","c30a4697":"## More Analysis using Confusion Matrix\n\nConfusion Matrix is applied and plotted to find out which emotion usually get confused with each other.","67eff001":"from keras.layers import Average, Add\nfrom keras.models import Model\n\nmodel = create_res_net()\n\nx1 = Dense(6)(model.output)\nx2 = Dense(6)(model.output)\nx3 = Dense(6)(model.output)\nx4 = Dense(6)(model.output)\navg = Average()([x1, x2, x3, x4])\nout = Dense(6, activation='softmax')(avg)\nmodel = Model(inputs=model.input, outputs=out)\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    0.1,\n    decay_steps=1000,\n    decay_rate=0.46,\n    staircase=True)\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule), \n              metrics=['accuracy'])\n\nmodel.summary()","b18074bd":"#### Let's look at some images...","3bc9f3a1":"\n> ### Great! :) \n> ### This is an exciting result because the [model that won the competition had 71.1% accuracy](https:\/\/www.kaggle.com\/c\/challenges-in-representation-learning-facial-expression-recognition-challenge\/leaderboard?source=post_page), which means this result puts us into 5th place!\n        \n   ![KaggleRanking](https:\/\/i.imgur.com\/l8LnPfe.png)","9cdc10d4":"---------------------------------------------------------------------------------------------------\n### Extra:\n\n### Batch Normalization\n\n#### (i) Apply Batch-Normalization before or after activation function?\n*Regarding this issue, it is still occasionally a topic of debate. However, in this project, we applied BN before ReLu as we are trying to follow the original BatchNorm paper. The following is the exact text from the paper...*\n    \n> We add the BN transform immediately before the nonlinearity, by normalizing x = Wu+ b. \nWe could have also normalized the layer inputs u, but since u is likely the output of another nonlinearity, \nthe shape of its distribution is likely to change during training, and constraining its first and second \nmoments would not eliminate the covariate shift. In contrast, Wu + b is more likely to have a symmetric, \nnon-sparse distribution, that is \u201cmore Gaussian\u201d (Hyv\u00a8arinen & Oja, 2000); normalizing it is likely to \nproduce activations with a stable distribution.\n\n\n#### (ii) Is it better to use DropOut together with Batch-Normalization?\n*Again, it is another common debate topic in DL community. In this project, we totally eliminate the use of dropout and focusing batch-normalization technique only. This is because, Batch normalization already offers some regularization effect, reducing generalization error, perhaps no longer requiring the use of dropout for regularization.* \n\n> Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout\n\nMore details -> [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https:\/\/arxiv.org\/abs\/1502.03167).\n\n\n\n\n---------------------------------------------------------------------------------------------------\n","88c4bb7e":"*It was a fun project, Happy Kaggling :) *\n-----------------------------------","e6975dc8":"-------------------------------------------------------------------\n\n**Future Work:**\n\n    (i) To further fine tuning model using grid_search, specifically:\n        a. Different optimizer such as Adam, RMSprop, Adagrad.\n        b. experimenting dropout with batch-normalization.\n        c. experimenting different dropout rates. \n\n    (ii) To collect more data and train the model with balance dataset.\n\n","241e0a0b":"Notice that the later two subplots share the same y-axis with the first subplot. \n\nThe size of **train**, **validation**, **test** are **80%**, **10%** and **10%**, respectively. \n\nThe exact number of each class of these datasets are written on top of their x-axis bar. "}}