{"cell_type":{"9ca8fa57":"code","869fc2ae":"code","d4f0f9d8":"code","fa041de4":"code","be852320":"code","d716a7db":"code","97192ae5":"code","19e0e53d":"code","ff459aff":"code","591e0f23":"code","61d8db83":"code","31a99f92":"code","94a5ff34":"code","6bfeb175":"code","1966d1de":"markdown","84bde03b":"markdown","60885c31":"markdown","68abd9ec":"markdown","64dcc38c":"markdown","3e5d96c5":"markdown","909b6922":"markdown","225a4357":"markdown","335db757":"markdown","bc9fbefd":"markdown","d4508864":"markdown","dfde97a9":"markdown","142e6d93":"markdown","d1d82545":"markdown","29a7848c":"markdown","c9881e67":"markdown","e523e198":"markdown","f2aad081":"markdown","5a52bec6":"markdown","8893aa2a":"markdown","6affb416":"markdown","2da235be":"markdown","f25b96d5":"markdown","7dcd18c1":"markdown","cbf65b7b":"markdown","da73a253":"markdown","36f6060a":"markdown","10421cb7":"markdown","20bdf50f":"markdown","5d7ca11d":"markdown","b3bfcf7a":"markdown","bb8f3ca4":"markdown","d0282deb":"markdown","83ebc9f7":"markdown"},"source":{"9ca8fa57":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import dates\n\nfrom pylab import rcParams\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)","869fc2ae":"df = pd.read_csv(\"..\/input\/amazon-stock-data\/AMZN.csv\", parse_dates=True, index_col = \"Date\")\ndf.head()","d4f0f9d8":"df['Volume'].plot(figsize=(10,6))","fa041de4":"df.plot(subplots=True, figsize=(10,12))\n","be852320":"df_month = df.resample(\"M\").mean()\nfig, ax = plt.subplots(figsize=(12, 6))\nax.xaxis.set_major_formatter(dates.DateFormatter('%Y-%m'))\nax.bar(df_month['2020':].index, df_month.loc['2020':, \"Volume\"], width=25, align='center')","d716a7db":"start, end = '2017-01', '2017-06'\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(df.loc[start:end, 'Volume'],\nmarker='.', linestyle='-', linewidth=0.5, label='Daily')\nax.plot(df_month.loc[start:end, 'Volume'],\nmarker='o', markersize=8, linestyle='-', label='Monthly Mean Resample')\nax.set_ylabel('Volume')\nax.legend();","97192ae5":"df_week = df.resample(\"W\").mean()","19e0e53d":"start, end = '2020-01', '2020-08'\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(df.loc[start:end, 'Volume'], marker='.', linestyle='-', linewidth = 0.5, label='Daily', color='black')\nax.plot(df_week.loc[start:end, 'Volume'], marker='o', markersize=8, linestyle='-', label='Weekly', color='coral')\nax.set_ylabel(\"Open\")\nax.legend()","ff459aff":"df_7d_rolling = df.rolling(7, center=True).mean()\nstart, end = '2016-06', '2017-05'\nfig, ax = plt.subplots(figsize=(12, 6))\nax.plot(df.loc[start:end, 'Volume'], marker='.', linestyle='-', \n        linewidth=0.5, label='Daily')\nax.plot(df_week.loc[start:end, 'Volume'], marker='o', markersize=5, \n        linestyle='-', label = 'Weekly mean volume')\nax.plot(df_7d_rolling.loc[start:end, 'Volume'], marker='.', linestyle='-', label='7d Rolling Average')\nax.set_ylabel('Stock Volume')\nax.legend()","591e0f23":"df['Change'] = df.Close.div(df.Close.shift())\ndf['Change'].plot(figsize=(20, 8), fontsize = 16)","61d8db83":"df['2001']['Change'].plot(figsize=(10, 6))","31a99f92":"df_month.loc[:, 'pct_change'] = df.Close.pct_change()*100\nfig, ax = plt.subplots(figsize=(20, 8))\ndf_month['pct_change' ].head(100).plot(kind='bar', color='violet', ax=ax)\nax.xaxis.set_major_locator(dates.WeekdayLocator())\nax.xaxis.set_major_formatter(dates.DateFormatter('%b %d'))\nplt.xticks(rotation=45)\nax.legend()","94a5ff34":"fig, ax = plt.subplots(figsize=(20, 8))\nax = df.High.plot(label='High')\nax = df.High.expanding().mean().plot(label='High expanding mean')\nax = df.High.expanding().std().plot(label='High expanding std')\nax.legend()","6bfeb175":"rcParams['figure.figsize'] = 11, 9\ndecomposition = sm.tsa.seasonal_decompose(df_month['Volume'], model='Additive')\nfig = decomposition.plot()\nplt.show()\n","1966d1de":"We can clearly see the percentage change in the data.","84bde03b":"We are doing it on the above plot","60885c31":"I've used expanding window,an another way of transformation. It keeps adding the cumulative. For example, if you add an expanding function to the \u2018High\u2019 column first element remains the same. The second element becomes cumulative of the first and second element, the third element becomes cumulative of the first, second, and third element, and so on. You can use aggregate functions like mean, median, standard deviation, etc. on it too","68abd9ec":"**WEEKLY RESAMPLE**","64dcc38c":" 7-d rolling average is a bit smoother than the weekly average.","3e5d96c5":"# SHIFT:","909b6922":"**We can see alot of peaks and density between 2000 and 2010**","225a4357":"The shift function shifts the data before or after the specified amount of time. It will shift the data by one day by default. That means you will get the previous day's data. In financial data like this one, it is helpful to see previous day data and today's data side by side.","335db757":"I've chose only the first 100 data entries.","bc9fbefd":"Lets look at how the other features are distributed","d4508864":"* Open = Price from the first transaction of a trading day\n* High = Maximum price in a trading day\n* Low = Minimum price in a trading day\n* Close = Price from the last transaction of a trading day\n* Adj Close = Closing price adjusted to reflect the value after accounting for any corporate actions\n* Volume = Number of units traded in a day**","dfde97a9":"**The shape of the curve for \u2018Open\u2019, \u2018Close\u2019, \u2018High\u2019 and \u2018Low\u2019 data have the same shape. Only the \u2018Volume\u2019 has a different shape.**","142e6d93":"# ROLLING:","d1d82545":"> BASIC PLOT FOR CHECKING THE TRENDS OF VOLUME:","29a7848c":"Differencing takes the difference in values of a specified distance.It is a popular method to remove the trend in the data. The trend is not good for forecasting or modeling.","c9881e67":"Here the trend is the moving average. To give you a high-level idea of residuals, here is the general formula:\n**Original observations = Trend + Seasonality + Residuals**","e523e198":"Each bar represents a month. A huge spike in April 2020. Otherwise, there is monthly seasonality after 2020 ended.","f2aad081":"In the code above, .div() helps to fill up the missing data. Actually, div() means division. df. div(6) will divide each element in df by 6. But here I used \u2018df.Close.shift()\u2019. So, Each element of df will be divided by each element of \u2018df.Close.shift()\u2019. We do this to avoid the null values that are created by the \u2018shift()\u2019 operation.","5a52bec6":"# FEATURE DESCRIPTION:","8893aa2a":"# PLOTTING THE CHANGE:","6affb416":"There is a percent change function available to get the percent_change data.","2da235be":"# REFERENCE:\n[https:\/\/towardsdatascience.com\/a-complete-guide-to-time-series-data-visualization-in-python-da0ddd2cfb01](http:\/\/)","f25b96d5":"Decomposition will show the observations and these three elements in the same plot:\n* Trend: Consistent upward or downward slope of a time series.\n* Seasonality: Clear periodic pattern of a time series\n* Noise: Outliers or missing values","7dcd18c1":"This is the plot of 2001 only.","cbf65b7b":"Rolling is another very helpful way of smoothing out the curve. It takes the average of a specified amount of data. If I want a 7-day rolling, it gives us the 7-day average data.","da73a253":"# DECOMPOSITION:","36f6060a":"Resampling is very common in time-series data. Most of the time resampling is done to a lower frequency.Though resampling of higher frequency is also necessary especially for modeling purposes. Not so much in data analysis purpose.\nIn the \u2018Volume\u2019 data we are working on right now, we can observe some big spikes here and there. These types of spikes are not helpful for data analysis or for modeling. normally to smooth out the spikes, resampling to a lower frequency and rolling is very helpful.","10421cb7":"# AMAZON STOCKS TREND","20bdf50f":"Resampling for months or weeks and making bar plots is another very simple and widely used method of finding seasonality. Here I am making a bar plot of month data in 2020","5d7ca11d":"# SEASONALITY:","b3bfcf7a":"# RESAMPLING AND ROLLING:","bb8f3ca4":"# PERCENTAGE CHANGE:","d0282deb":"I used the \u2018parse_dates\u2019 parameter in the read_csv function to convert the \u2018Date\u2019 column to the DatetimeIndex format.","83ebc9f7":"# DIFFERENCING:"}}