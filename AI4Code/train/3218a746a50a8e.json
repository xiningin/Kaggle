{"cell_type":{"09f0ca7d":"code","0e21a74d":"code","9b4937ce":"code","cabfb7f0":"code","f75cd6f3":"code","62a956f1":"code","0c13e2aa":"code","1ff7452c":"code","d589c7a2":"code","2a358f4f":"code","6d0e9cd0":"code","81ec7a07":"code","3963c443":"code","e2a09649":"code","89448818":"code","a038a1aa":"code","93b4e340":"code","a643bba9":"code","5080d757":"code","582143ad":"code","e1908bbc":"markdown","6b75d82d":"markdown","4e863e8e":"markdown","4ba4d637":"markdown","c494fb0c":"markdown","94f29ba0":"markdown","b2de3b22":"markdown","72b27382":"markdown","35106144":"markdown","76d908a0":"markdown","893a607a":"markdown","a86d113b":"markdown","b3ccfcd8":"markdown","3c5412a4":"markdown","df992fdc":"markdown","a7d90b9a":"markdown"},"source":{"09f0ca7d":"# file system\nimport os\n\n# data manipulation\nimport pandas as pd\nimport numpy as np\n\n# dataviz\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0e21a74d":"import warnings\nwarnings.filterwarnings('ignore')","9b4937ce":"!pip install pycaret","cabfb7f0":"# auto machine-learning regression\nfrom pycaret.regression import *\n\n# auto eda\nfrom pandas_profiling import ProfileReport","f75cd6f3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","62a956f1":"# import datasets\nsample_submission = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\", low_memory = False)\ntrain = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\", low_memory = False)\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\", low_memory = False)\n\n# overview\ntrain.sample(10)","0c13e2aa":"# generate Auto EDA Reports\nprofile = ProfileReport(train, title=\"AutoEDA_HousePrice\", pool_size=-1, progress_bar=True, explorative=True)\nprofile.to_file(\"house_price_auto_eda.html\")","1ff7452c":"# Calculate few metrics in supplement\ntrain[\"TotalSF\"] = train[\"GrLivArea\"] + train[\"TotalBsmtSF\"]\ntrain[\"TotalPorchSF\"] = train[\"OpenPorchSF\"] + train[\"EnclosedPorch\"] + train[\"3SsnPorch\"] + train[\"ScreenPorch\"]\ntrain[\"TotalBath\"] = train[\"FullBath\"] + train[\"BsmtFullBath\"] + 0.5 * (train[\"BsmtHalfBath\"] + train[\"HalfBath\"])\ntrain[[\"MSSubClass\", \"YrSold\"]]= train[[\"MSSubClass\", \"YrSold\"]].astype(\"category\")","d589c7a2":"# variable to predict\nsns.distplot(train['SalePrice'])","2a358f4f":"# quick overview of dispersion\nfig, ax = plt.subplots(figsize=(10, 6))\nax.grid()\nax.scatter(train[\"GrLivArea\"], train[\"SalePrice\"], c=\"#3f72af\", zorder=3, alpha=0.9)\nax.axvline(4500, c=\"#112d4e\", ls=\"--\", zorder=2)\nax.set_xlabel(\"Ground living area (sq. ft)\", labelpad=10)\nax.set_ylabel(\"Sale price ($)\", labelpad=10)\nplt.show()","6d0e9cd0":"# filter\ntrain = train[train[\"GrLivArea\"] < 4000]","81ec7a07":"# setup experiment\nexperiment_regression = setup(\n    data = train.drop(columns=['Id'], axis=1),\n    target = 'SalePrice',\n    train_size = .8,\n    use_gpu = False,\n    normalize = True, \n    normalize_method = 'zscore',\n    remove_outliers= True,\n    outliers_threshold = 0.05,\n    remove_multicollinearity = True,\n    polynomial_features = True, \n    trigonometry_features = True,\n    transformation_method = 'yeo-johnson',\n    transform_target = True,\n    numeric_features = [\n        'OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath',\n        'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n        'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'PoolArea',\n        'TotalSF', 'TotalPorchSF', 'TotalBath'\n    ],\n    ordinal_features = {\n        'ExterQual': ['Fa', 'TA', 'Gd', 'Ex'],\n        'ExterCond' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'BsmtQual' : ['Fa', 'TA', 'Gd', 'Ex'], \n        'BsmtCond' : ['Po', 'Fa', 'TA', 'Gd'],\n        'BsmtExposure' : ['No', 'Mn', 'Av', 'Gd'],\n        'HeatingQC' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'KitchenQual' : ['Fa', 'TA', 'Gd', 'Ex'],\n        'FireplaceQu' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'GarageQual' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'GarageCond' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'PoolQC' : ['Fa', 'Gd', 'Ex']\n    }\n)","3963c443":"best = compare_models(\n    sort = 'RMSE', # optimise metrics\n    turbo = False, # don't exclude model not fast to train\n    exclude = ['dummy', 'en', 'lasso', 'llar', 'par', 'tr', 'kr', 'ridge']\n)","e2a09649":"tuned_br = tune_model(best, n_iter = 40, optimize = 'RMSE')","89448818":"plot_model(tuned_br)","a038a1aa":"plot_model(tuned_br, plot = 'error')","93b4e340":"plot_model(tuned_br, plot = 'vc')","a643bba9":"plot_model(tuned_br, plot = 'feature')","5080d757":"# recalcul metrics \ntest[\"TotalSF\"] = test[\"GrLivArea\"] + test[\"TotalBsmtSF\"]\ntest[\"TotalPorchSF\"] = test[\"OpenPorchSF\"] + test[\"EnclosedPorch\"] + test[\"3SsnPorch\"] + test[\"ScreenPorch\"]\ntest[\"TotalBath\"] = test[\"FullBath\"] + test[\"BsmtFullBath\"] + 0.5 * (test[\"BsmtHalfBath\"] + test[\"HalfBath\"])\ntest[[\"MSSubClass\", \"YrSold\"]] = test[[\"MSSubClass\", \"YrSold\"]].astype(\"category\")\n\n# predict\ndf_to_predict = test.drop(columns=['Id'], axis=1)\npred_sale_price = predict_model(tuned_br, data=df_to_predict)\n\npredictions = pd.DataFrame(pred_sale_price, columns=['Label'])\ndf_submission = pd.concat([test, predictions], axis =1)","582143ad":"df_submission_formating = df_submission[[\"Id\", \"Label\"]]\ndf_submission_formating.rename(columns={\"Label\": \"SalePrice\"}, inplace=True)\n\ndf_submission_formating.to_csv('.\/submission.csv', index=False)\ndf_submission_formating.head()","e1908bbc":"### PART 5 - Inference","6b75d82d":"**Tips :**\n\n- You can include or exclude model on the run with :\n    - include = ['name_model_to_keep_1', 'name_model_to_keep_2', ...]\n    - exclude = ['name_model_to_exclude_1', 'name_to_exclude_2', ...]","4e863e8e":"### PART 3 - Features Engineering","4ba4d637":"#### Compare Models","c494fb0c":"#### Plot Evaluation\n\n- Residual Plot","94f29ba0":"### PART 2 - Auto EDA","b2de3b22":"# House Prices\n\n**Disclaimer**: The purpose of this Notebook is only to experiment Open-Source AutoML Library, PyCaret.\n\n## Context\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence. <br>\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\n#### Import Libraries","72b27382":"### PART 4 - Setup Experiment AutoML","35106144":"- Prediction Error Plot","76d908a0":"- Validation Curves","893a607a":"## Conclusion\n\n1. PyCaret seems nice to iterate quickly over models with all these build-in functionalities which reduce time spend to code.\n2. PyCaret is still a tool for Data Science, so if you don't do some analyse and feature engineering you won't improve your model. Moreover, before select Model X, understand model engine behind each models choose may help you to understand how improve these models scores.","a86d113b":"- Feature Importance","b3ccfcd8":"---\n\n## Code\n### PART 1 - Data Gathering","3c5412a4":"#### Fine Tuning best model","df992fdc":"- Formating DataFrame to submit","a7d90b9a":"Installation of PyCaret"}}