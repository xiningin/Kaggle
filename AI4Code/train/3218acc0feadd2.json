{"cell_type":{"0c685717":"code","a067530f":"code","496f358c":"code","4635def2":"code","0123ed7c":"code","b6cd72e4":"code","48ba1a05":"code","c8d5e8cd":"code","ae9a3593":"code","e871df93":"code","40148f7d":"code","8a9780d3":"code","619ca704":"code","154b27b3":"code","c1f60989":"code","c6a8dad4":"code","c0cf29f2":"code","3c42a863":"code","77156633":"code","4eb31e55":"code","7d6deccb":"code","336cfc99":"code","a63074b1":"code","fc284387":"markdown","2c8bfadc":"markdown","9693279a":"markdown","1dc5c562":"markdown","076b0963":"markdown","36185fc7":"markdown","967d7fe0":"markdown","f9d389ef":"markdown","fdd4a71b":"markdown","aeb7c421":"markdown","fdaaed17":"markdown","587514b2":"markdown","d703aa85":"markdown","e936bd89":"markdown"},"source":{"0c685717":"import os\nimport cv2\nimport time\nimport pandas as pd\nimport numpy as np\n\nfrom PIL import Image\n\nimport torch\nimport torchvision\nimport torchvision.transforms as T\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torch.utils.data import DataLoader, Dataset\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nDIR_INPUT = \"\/kaggle\/input\/face-mask-detection-dataset\/\"\nDIR_IMAGES = DIR_INPUT + \"Medical mask\/Medical mask\/Medical Mask\/images\/\"","a067530f":"### Loading Dataset\n\ndf = pd.read_csv(DIR_INPUT + \"train.csv\")\ndf.head()","496f358c":"### Null Values, Unique Values\n\nunq_values = df[\"name\"].unique()\nprint(\"Total Records: \", len(df))\nprint(\"Unique Images: \",len(unq_values))\n\nnull_values = df.isnull().sum(axis = 0)\nprint(\"\\n> Null Values in each column <\")\nprint(null_values)","4635def2":"### Total Classes\n\nclasses = df[\"classname\"].unique()\nprint(\"Total Classes: \",len(classes))\nprint(\"\\n> Classes <\\n\",classes)","0123ed7c":"### Visualizing Class Distribution\n\nplt.figure(figsize=(14,8))\nplt.title('Class Distribution', fontsize= 20)\nsns.countplot(x = \"classname\", data = df)","b6cd72e4":"### Function to plot image\n\ndef plot_img(image_name):\n    \n    fig, ax = plt.subplots(1, 2, figsize = (14, 14))\n    ax = ax.flatten()\n    \n    bbox = df[df['name'] == image_name]\n    img_path = os.path.join(DIR_IMAGES, image_name)\n    \n    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n    image \/= 255.0\n    image2 = image\n    \n    ax[0].set_title('Original Image')\n    ax[0].imshow(image)\n    \n    for idx, row in bbox.iterrows():\n        x1 = row['x1']\n        y1 = row['y1']\n        x2 = row['x2']\n        y2 = row['y2']\n        label = row['classname']\n        \n        cv2.rectangle(image2, (int(x1),int(y1)), (int(x2),int(y2)), (255,0,0), 3)\n        font = cv2.FONT_HERSHEY_SIMPLEX\n        cv2.putText(image2, label, (int(x1),int(y1-10)), font, 1, (255,0,0), 2)\n    \n    ax[1].set_title('Image with Bondary Box')\n    ax[1].imshow(image2)\n\n    plt.show()","48ba1a05":"### Pass any image name as parameter\n\nplot_img(\"3845.png\")","c8d5e8cd":"### Cleaning Column Headers - x2 <-> y1 (mismatched)\ndf.rename(columns = {'x2' : 'y1', 'y1' : 'x2'}, inplace = True)\ndf.head()","ae9a3593":"### Re-plot same image\n\nplot_img(\"3845.png\")","e871df93":"### Class <-> Int\n\n_classes = np.insert(classes, 0, \"background\", axis=0)        # adding a background class for Faster R-CNN\nclass_to_int = {_classes[i] : i for i in range(len(_classes))}\nint_to_class = {i : _classes[i] for i in range(len(_classes))}\nprint(\"class_to_int : \\n\",class_to_int)\nprint(\"\\nint_to_class : \\n\",int_to_class)","40148f7d":"### Creating Data (Labels & Targets) for Faster R-CNN\n\nclass FaceMaskDetectionDataset(Dataset):\n    \n    def __init__(self, dataframe, image_dir, mode = 'train', transforms = None):\n        \n        super().__init__()\n        \n        self.image_names = dataframe[\"name\"].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n        self.mode = mode\n        \n    def __getitem__(self, index: int):\n        \n        #Retrive Image name and its records (x1, y1, x2, y2, classname) from df\n        image_name = self.image_names[index]\n        records = self.df[self.df[\"name\"] == image_name]\n        \n        #Loading Image\n        image = cv2.imread(self.image_dir + image_name, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        \n        if self.mode == 'train':\n            \n            #Get bounding box co-ordinates for each box\n            boxes = records[['x1', 'y1', 'x2', 'y2']].values\n\n            #Getting labels for each box\n            temp_labels = records[['classname']].values\n            labels = []\n            for label in temp_labels:\n                label = class_to_int[label[0]]\n                labels.append(label)\n\n            #Converting boxes & labels into torch tensor\n            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n            labels = torch.as_tensor(labels, dtype=torch.int64)\n\n            #Creating target\n            target = {}\n            target['boxes'] = boxes\n            target['labels'] = labels\n\n            #Transforms\n            if self.transforms:\n                image = self.transforms(image)\n\n\n            return image, target, image_name\n        \n        elif self.mode == 'test':\n\n            if self.transforms:\n                image = self.transforms(image)\n\n            return image, image_name\n    \n    def __len__(self):\n        return len(self.image_names)\n    \n    ","8a9780d3":"### Transform for Train & Valid\n\n## Using Albumentations\n#def get_transform():\n    #return A.Compose([\n        #ToTensorV2(p=1.0)\n    #], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\n## Using torchvision.transforms - without Augmentation!\ndef get_transform():\n    return T.Compose([T.ToTensor()])","619ca704":"### Preparing data for Train & Validation\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n\n#Dataset object\ndataset = FaceMaskDetectionDataset(df, DIR_IMAGES, transforms = get_transform())\n\n\n# split the dataset in train and test set - using 80% for training, 20% for validation\nindices = torch.randperm(len(dataset)).tolist()\ntrain_dataset = torch.utils.data.Subset(dataset, indices[:-866])\nvalid_dataset = torch.utils.data.Subset(dataset, indices[-866:])\n\n\n#Preparing data loaders\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size = 4,\n    shuffle = True,\n    num_workers = 4,\n    collate_fn = collate_fn\n)\n\n\nvalid_data_loader = DataLoader(\n    valid_dataset,\n    batch_size = 4,\n    shuffle = True,\n    num_workers = 4,\n    collate_fn = collate_fn\n)\n","154b27b3":"### Utilize GPU if available\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ntorch.cuda.empty_cache()","c1f60989":"### Create \/ load model\n\n#Faster - RCNN Model - pretrained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\nnum_classes = len(class_to_int)\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","c6a8dad4":"### Preparing model for training\n\n#Retriving all trainable parameters from model (for optimizer)\nparams = [p for p in model.parameters() if p.requires_grad]\n\n#Defininig Optimizer\n#optimizer = torch.optim.Adam(params, lr = 0.0001)\noptimizer = torch.optim.SGD(params, lr = 0.005, momentum = 0.9)\n\n#LR\n#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n#Load pre-trained model\ncheckpoint = torch.load(\"..\/input\/face-mask-detection-trained-weights\/fmd_frcnn_e23.pth\")\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nmodel.to(device)\n\n#No of epochs\nepochs = 1","c0cf29f2":"### Training model xD\n\n# Training code is commented for submission, as it takes 11 mins for 1 epoch '-'\n\n\"\"\"\nitr = 1\ntotal_train_loss = []\n\nfor epoch in range(epochs):\n    \n    start_time = time.time()\n    train_loss = []\n    \n    #Retriving Mini-batch\n    for images, targets, image_names in train_data_loader:\n        \n        #Loading images & targets on device\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        #Forward propagation\n        out = model(images, targets)\n        losses = sum(loss for loss in out.values())\n        \n        #Reseting Gradients\n        optimizer.zero_grad()\n        \n        #Back propagation\n        losses.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n        optimizer.step()\n        \n        #Average loss\n        loss_value = losses.item()\n        train_loss.append(loss_value)\n        \n        if itr % 25 == 0:\n            print(f\"\\n Iteration #{itr} loss: {out} \\n\")\n\n        itr += 1\n    \n    #lr_scheduler.step()    \n    \n    epoch_train_loss = np.mean(train_loss)\n    total_train_loss.append(epoch_train_loss)\n    print(f'Epoch train loss is {epoch_train_loss:.4f}')\n\n    \n    time_elapsed = time.time() - start_time\n    print(\"Time elapsed: \",time_elapsed)\n    \n    torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': epoch_train_loss\n            }, \"checkpoint.pth\")\n\"\"\"","3c42a863":"### This code may take upto 3 mins (on GPU) to execute, commented purposely!\n\n\"\"\"\nitr = 1\nv_loss = []\n\nstart_time = time.time()\n\nfor images, targets, image_names in valid_data_loader:\n        \n    #Loading images & targets on device\n    images = list(image.to(device) for image in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n    #Forward propagation\n    out = model(images, targets)\n    losses = sum(loss for loss in out.values())\n        \n    #Average loss\n    loss_value = losses.item()\n    v_loss.append(loss_value)\n\nval_loss = np.mean(v_loss)\nprint(f'Val loss is {val_loss:.4f}')\n \ntime_elapsed = time.time() - start_time\nprint(\"Time elapsed: \",time_elapsed)\n\"\"\"","77156633":"### Creating submission df\n\nsubmission = pd.DataFrame(columns = [\"name\", \"x1\", \"x2\", \"y1\", \"y2\", \"classname\"])\nsubmission.head()","4eb31e55":"### 0 - 1800 (Test Images)\n\nimages = sorted(os.listdir(DIR_IMAGES))\ntest_images = images[ : 1698]\n\n#Use submission.csv (from dataset) as temp\ntest_df = pd.read_csv(DIR_INPUT + \"submission.csv\")\ntest_df = test_df.drop_duplicates(subset='name', keep=\"first\")","7d6deccb":"### Preparing Training Data\n\n#Test Dataset\ntest_dataset = FaceMaskDetectionDataset(test_df, DIR_IMAGES, mode = 'test', transforms = get_transform())\n\n#Test data loader\ntest_data_loader = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=1,\n    drop_last=False,\n    collate_fn=collate_fn\n)\n","336cfc99":"### Results - may take few mins, please wait!\n\nthreshold = 0.5\nmodel.eval()\n\nfor images, image_names in test_data_loader:\n\n    #Forward ->\n    images = list(image.to(device) for image in images)\n    output = model(images)\n    \n    #Converting tensors to array\n    boxes = output[0]['boxes'].data.cpu().numpy()\n    scores = output[0]['scores'].data.cpu().numpy()\n    labels = output[0]['labels'].data.cpu().numpy()\n    \n    #Thresholding\n    boxes_th = boxes[scores >= threshold].astype(np.int32)\n    scores_th = scores[scores >= threshold]\n    \n    # int_to_class - labels\n    labels_th = []\n    for x in range(len(labels)):\n        if scores[x] > threshold:\n            labels_th.append(int_to_class[labels[x]])\n    \n    #Appending results to csv\n    for y in range(len(boxes_th)):\n        \n        #Bboxes, classname & image name\n        x1 = boxes_th[y][0]\n        y1 = boxes_th[y][1]\n        x2 = boxes_th[y][2]\n        y2 = boxes_th[y][3]\n        class_name = labels_th[y]\n        \n        #Creating row for df\n        row = {\"name\" : image_names[0], \"x1\" : x1, \"x2\" : x2, \"y1\" : y1, \"y2\" : y2, \"classname\" : class_name}\n        \n        #Appending to df\n        submission = submission.append(row, ignore_index = True)\n    ","a63074b1":"submission.to_csv('submission.csv', index = False)","fc284387":"# Submission \ud83d\udcc4","2c8bfadc":"# Exploring Dataset \ud83d\udcca","9693279a":"# Create Model - Resnet50 (Faster R-CNN) \ud83d\udd28","1dc5c562":"**Training Details**\n\n* Architecture = ResNet50\n* Method = Faster R-CNN\n* Pretrained Weights = MS_COCO\n* Learning Rate = 0.05\n* Optimizer = SGD with momentum 0.9\n* Epochs = 25\n* Avg Time per Epoch (80% Train Data) = 690 sec\n\n","076b0963":"# Preparing Dataset for Training \ud83d\udcc2","36185fc7":"# Face-Mask Detection using Faster R-CNN (PyTorch) \u0f3c \u3064 \u25d5_\u25d5 \u0f3d\u3064","967d7fe0":"**As we can see, column headers (bbox co-ordinates) in 'train.csv' are messed up \ud83d\ude0f, lets clean it! \ud83d\ude0b**","f9d389ef":"**Looks good! \ud83d\ude09**","fdd4a71b":"**Loss Details (After 30 Epochs of Training)**\n\n* cls_loss     =  0.0466\n* reg_loss     =  0.0125\n* obj_loss     =  0.0040\n* rpn_reg_loss =  0.0120\n* Overall      =  0.0546","aeb7c421":"# Generating Results, appending it to submission df \ud83d\udcdd","fdaaed17":"# Preparing Model for Training - Define learning parameters \ud83d\udcdd","587514b2":"# Now comes everbody's favorite part \ud83d\ude0b, let's train it!","d703aa85":"# Visualise Random Images with BBox \ud83d\udd75\ufe0f\u200d","e936bd89":"# Evaluate Model on Validation Data \ud83d\udd27"}}