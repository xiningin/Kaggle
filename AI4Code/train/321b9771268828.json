{"cell_type":{"c8a33aee":"code","f5e54ea1":"code","03fe4403":"code","1ae1dfaf":"code","4ec2e408":"code","b017667c":"code","3551e595":"code","cd6ecfac":"code","12f12e6f":"code","c8d883bb":"code","7f665004":"code","817693c1":"code","9a225892":"code","e8575481":"code","0c8d09bd":"code","22cb65c5":"code","80327c7d":"code","2bd07c58":"code","2f269747":"code","856a7743":"code","a1a9cc29":"code","bc9c66d5":"code","abdf0b87":"code","b84d40f2":"code","e6337e29":"code","1fcc84fb":"code","14134b06":"code","10121821":"code","82fd8685":"code","3be12bfa":"code","8569193b":"code","28ef4e7d":"code","56779491":"code","d3254bf1":"code","50761dfa":"code","45363fe4":"code","0fa31558":"code","b00c8d9f":"code","1ab56ab8":"code","fa7a505c":"code","a335475c":"code","43dea020":"code","6d92347f":"code","6e6450e5":"markdown","a293c9fe":"markdown","2857423b":"markdown","39a10c3c":"markdown","87282097":"markdown","30ca4bfa":"markdown","862355ff":"markdown","2ac2b432":"markdown","9db7a54a":"markdown","8ce528bf":"markdown","d3cc8b40":"markdown","a5c04c46":"markdown","59e536ef":"markdown","69dd7afd":"markdown","58b92136":"markdown","0e9d871c":"markdown"},"source":{"c8a33aee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5e54ea1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install xlrd\n!pip install autoviz","03fe4403":"#importing Autoviz class\nfrom autoviz.AutoViz_Class import AutoViz_Class\n#Instantiate the AutoViz class\nAV = AutoViz_Class()","1ae1dfaf":"data_train = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv', sep = ',')\ndata_test = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv', sep = ',')\nsub = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/sample_submission.csv')","4ec2e408":"sub.head()","b017667c":"train = pd.DataFrame(data_train)\ntrain.head()","3551e595":"df = AV.AutoViz('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')","cd6ecfac":"test = pd.DataFrame(data_test)\ntest.head()","12f12e6f":"print('Train_Shape:', train.shape, '\\n', \"Test_Shape:\", test.shape)","c8d883bb":"train.columns","7f665004":"test.columns","817693c1":"train.isnull().sum()","9a225892":"test.isnull().sum()","e8575481":"train.info()","0c8d09bd":"train[['CITY', 'City_code']] = train['city'].str.split('_', expand = True)\ntest[['CITY', 'City_code']] = test['city'].str.split('_', expand = True)\n#df[['First','Last']] = df.Name.str.split(\"_\",expand=True)","22cb65c5":"train = train.drop(['city', 'CITY'], axis = 1)\ntest = test.drop(['city', 'CITY'], axis = 1)","80327c7d":"train.head()","2bd07c58":"cateogry_columns=train.select_dtypes(include=['object']).columns.tolist()\ninteger_columns=train.select_dtypes(include=['int64','float64']).columns.tolist()\n\nfor column in train:\n    if train[column].isnull().any():\n        if(column in cateogry_columns):\n            train[column]=train[column].fillna(train[column].mode()[0])\n        else:\n            train[column]=train[column].fillna(train[column].mean)\n","2f269747":"cateogry_columns=test.select_dtypes(include=['object']).columns.tolist()\ninteger_columns=test.select_dtypes(include=['int64','float64']).columns.tolist()\n\nfor column in test:\n    if test[column].isnull().any():\n        if(column in cateogry_columns):\n            test[column]=test[column].fillna(test[column].mode()[0])\n        else:\n            test[column]=test[column].fillna(test[column].mean)\n","856a7743":"train.head()","a1a9cc29":"test.head()","bc9c66d5":"column = ['gender', 'relevent_experience', 'enrolled_university', 'education_level',\n       'major_discipline', 'experience',  'company_type','last_new_job']\nfor col in column:\n    print('TRain_Set:','\\n',col, '\\n', train[col].unique(),'\\n')\n    print('Test_SET:', '\\n',col, '\\n', test[col].unique(),'\\n')","abdf0b87":"train['company_size'].unique()","b84d40f2":"train['company_size'] = train['company_size'].map({'50-99': 'fifty to ninetynine', '<10':'less than ten', '10000+':'ten thousand plus',\n                                                   '5000-9999': 'five to ten thousan', '1000-4999':'one to five thousand', '10\/49':'ten to fifty',\n                                                   '100-500': 'one to five hundred', '500-999':'five to nine hundred'})\ntest['company_size'] = test['company_size'].map({'50-99': 'fifty to ninetynine', '<10':'less than ten', '10000+':'ten thousand plus',\n                                                   '5000-9999': 'five to ten thousan', '1000-4999':'one to five thousand', '10\/49':'ten to fifty',\n                                                   '100-500': 'one to five hundred', '500-999':'five to nine hundred'})","e6337e29":"train['last_new_job'] = train['last_new_job'].map({'never':'zero', '1':'one', '>4': 'four_plus','4':'four', '3':'three', '2':'two'})\ntest['last_new_job'] = test['last_new_job'].map({'never':'zero', '1':'one', '>4': 'four_plus','4':'four', '3':'three', '2':'two'})","1fcc84fb":"train['experience'] = train['experience'].map({'9':'nine', '5':'five', '<1':'less than one', '11': 'eleven', '>20':'more than twenty', \n                                             '10':'ten', '14':'fourteen', '3':'three', '20': 'twenty', '8':'eight', '4':'four',\n                                             '13':'thirteen', '2':'two', '6':'six', '7':'seven', '1':'one', '19':'nineteen',\n                                             '15':'fifteen', '16':'sixteen','17': 'seventeen', '18':'eighteen', '12':'twelve'})\ntest['experience'] = test['experience'].map({'9':'nine', '5':'five', '<1':'less than one', '11': 'eleven', '>20':'more than twenty', \n                                             '10':'ten', '14':'fourteen', '3':'three', '20': 'twenty', '8':'eight', '4':'four',\n                                             '13':'thirteen', '2':'two', '6':'six', '7':'seven', '1':'one', '19':'nineteen',\n                                             '15':'fifteen', '16':'sixteen','17': 'seventeen', '18':'eighteen', '12':'twelve'})","14134b06":"train.head()","10121821":"train.columns.isna()","82fd8685":"from sklearn.preprocessing import LabelEncoder, StandardScaler\nle = LabelEncoder()\nsc = StandardScaler()","3be12bfa":"column = ['gender', 'relevent_experience', 'enrolled_university', 'education_level',\n       'major_discipline', 'company_type','last_new_job','experience', 'company_size']\nfor col in column:\n    train[col]= le.fit_transform(train[col])\n    test[col]= le.fit_transform(test[col])\n    ","8569193b":"train.head()","28ef4e7d":"test.head(2)","56779491":"train['City_code'] = train['City_code'].astype(int)","d3254bf1":"#train = train.fillna(train.mean, inplace = True)","50761dfa":"test.isna().any()","45363fe4":"X = train.drop(['target'], axis = 1)\ny = train.target\nfrom sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(X, y, random_state = 43, test_size = 0.2)","0fa31558":"sc.fit(X_train, y_train)\nX_train = sc.transform(X_train)\nX_test = sc.transform(X_test)","b00c8d9f":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score , plot_roc_curve\n\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nrf = RandomForestClassifier()\nad = AdaBoostClassifier(base_estimator =rf)\ndt = DecisionTreeClassifier()\nkn = KNeighborsClassifier()\n#gnb = GaussianProcessClassifier()\nsvc = SVC()\n\nmodels = [rf,ad, dt, kn, svc]\nfor model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mod = model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    scores = cross_val_score(model, X, y, cv=5).mean().round(3)\n    accuracy = metrics.classification_report(y_test, y_pred)\n    print(model, '\\n', accuracy,'\\n', 'mean_score:',scores, '\\n' )\n   \n    ","1ab56ab8":"fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","fa7a505c":"test1 = test.copy()\ntest = sc.transform(test)","a335475c":"model = ad.fit(X_train, y_train)\ny_pred_test = model.predict(test).round(3)\nprint(y_pred_test)","43dea020":"test_prediction_rf = pd.DataFrame(y_pred_test, columns= ['Predicted_test'])\ntest_prediction_rf['enroll ID'] = test1['enrollee_id']\ntest_prediction_rf.head()","6d92347f":"test_prediction_rf['Predicted_test'].value_counts()","6e6450e5":"# Fitting the test data into Standard Scaler","a293c9fe":"# ROC_AUC curve","2857423b":"# Splitting the 'city' column into two","39a10c3c":"# Please do not forget to vote","87282097":"# Unique values from train & test data set\n","30ca4bfa":"# Missing Values\n# Imputing the missing values with mode in train & test data set","862355ff":"# Label Encoding to the train & test data columns","2ac2b432":"# Checking for data types\n1. Most of the data types are objects","9db7a54a":"# Total 366 Data Scientist will move to new job","8ce528bf":"# Checking for null values in train & test data set","d3cc8b40":"# Converting the values in to Standard Scaler","a5c04c46":"# Running multiple classification models","59e536ef":"# fitting the best model i.e. AdaBoostClassifier on the test data","69dd7afd":"# TRain test & Split","58b92136":"# Replacing values in train & test data columns","0e9d871c":"# Predicted values in DataFrame"}}