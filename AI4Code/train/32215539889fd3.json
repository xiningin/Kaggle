{"cell_type":{"2c207a76":"code","21623d83":"code","3dd4de5c":"code","177bfafc":"code","d399d0c2":"code","bd079b74":"code","35fdfdac":"code","18739b11":"code","73f0d396":"code","f0c7655e":"code","9b79a170":"code","b90877a8":"code","507bb850":"code","4f662b1d":"code","a88b80b0":"code","c90172a6":"code","91467984":"code","f3c546ae":"code","9c28eae8":"code","d65eae80":"code","381a2f58":"code","9d7bf96e":"code","4ad14543":"code","bd64e20b":"code","a8b47737":"code","71790a58":"code","a6bc8da4":"code","55d63d4f":"code","cd4ec2c3":"code","b20191bc":"code","951d1da7":"code","e951295e":"code","bf933cf4":"code","eacb61f5":"code","f0fdbde7":"code","8d5cdd19":"code","29f9e1b6":"code","25d21ade":"code","31351993":"code","cfc088db":"code","aa08cb5a":"code","15a303f3":"code","ece3032f":"code","fc7f2013":"code","bda56bfb":"code","ab6bc39d":"code","6be96faf":"code","5f7c3c2c":"code","0ac9ac38":"code","bb3f4eac":"code","35db5b96":"code","4ee513e5":"code","7beb9fed":"code","130a4f82":"code","e5c3e69a":"code","08075298":"code","57faa1fe":"code","a758e2af":"code","14f59025":"code","917da982":"code","901c8d34":"code","a13d0270":"code","d7ebe979":"markdown","dd0b739f":"markdown","042b7577":"markdown","f06d5b53":"markdown","616ed758":"markdown","84a578cf":"markdown","20544c52":"markdown","aae96612":"markdown","906d3d98":"markdown","aaebdbfc":"markdown","fe807f59":"markdown","28bc390e":"markdown","6e6a1341":"markdown","4988a816":"markdown","85753c37":"markdown","bc2914ac":"markdown","c1f00a41":"markdown","127892e8":"markdown","20374731":"markdown","60db06c6":"markdown","2ce716e7":"markdown","b2eff027":"markdown","9c839c2d":"markdown","6ec36ac4":"markdown","206b0b68":"markdown","5dcf9c75":"markdown","7e0e806c":"markdown","144f0947":"markdown","11384b7e":"markdown","b692375d":"markdown","d844da49":"markdown","d1d63e98":"markdown","bc629c20":"markdown","ab26edd6":"markdown","bb369be9":"markdown","6e196d05":"markdown","61764f5c":"markdown","7948ebb0":"markdown","f29aadd3":"markdown","79a10e44":"markdown","f2e8d1ea":"markdown","df585348":"markdown","c6d12844":"markdown","0f2c1e30":"markdown","5ca74c1e":"markdown","77647344":"markdown","1f3084be":"markdown","7d4ce150":"markdown","596538a4":"markdown","73dcb87d":"markdown","b45a2417":"markdown","17be4570":"markdown","ae4d7dc4":"markdown","89187f19":"markdown","2f2129a0":"markdown","b401ae5f":"markdown","2d44992d":"markdown","8aa6d607":"markdown","ebd2bbe7":"markdown"},"source":{"2c207a76":"# Third party\nfrom keras.applications import VGG16\nfrom keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Local application\nimport miner_a_de_datos_redes_neuronales_utilidad as utils","21623d83":"device_type = \"GPU\"\n\nutils.check_physical_devices(device_type)","3dd4de5c":"seed = 27912","177bfafc":"rescale = 1 \/ 255","d399d0c2":"validation_split = 0.2\n\ntrain_generator = ImageDataGenerator(rescale=rescale,\n                                     validation_split=validation_split)","bd079b74":"test_generator = ImageDataGenerator(rescale=rescale)","35fdfdac":"batch_size = 64\ntarget_size = (128, 128)","18739b11":"directory = \"..\/input\/recognition-2020\/train\"\nsubset = \"training\"\n\ntrain_iterator = train_generator.flow_from_directory(seed=seed,\n                                                     subset=subset,\n                                                     directory=directory,\n                                                     batch_size=batch_size,\n                                                     target_size=target_size)","73f0d396":"subset = \"validation\"\n\nvalidation_iterator = train_generator.flow_from_directory(seed=seed,\n                                                          subset=subset,\n                                                          directory=directory,\n                                                          batch_size=batch_size,\n                                                          target_size=target_size)","f0c7655e":"directory = \"..\/input\/recognition-2020\/test\"\nshuffle = False\n\ntest_iterator = test_generator.flow_from_directory(seed=seed,\n                                                   shuffle=shuffle,\n                                                   directory=directory,\n                                                   batch_size=batch_size,\n                                                   target_size=target_size)","9b79a170":"data_format = \"channels_last\"\ninput_shape = (*target_size, 3)","b90877a8":"flatten_layer = Flatten(data_format=data_format, input_shape=input_shape)","507bb850":"activation = \"relu\"\n\nhidden_layer_1 = Dense(64, activation=activation)\nhidden_layer_2 = Dense(64, activation=activation)","4f662b1d":"activation = \"softmax\"\n\noutput_layer = Dense(10, activation=activation)","a88b80b0":"neural_network_model = utils.group_layers(flatten_layer,\n                                          hidden_layer_1,\n                                          hidden_layer_2,\n                                          output_layer)","c90172a6":"line_length = 79","91467984":"neural_network_model.summary(line_length)","f3c546ae":"lr = 1e-3","9c28eae8":"model = neural_network_model\n\nutils.compile_model(model, lr)","d65eae80":"activation = \"relu\"\n\nconvolutional_layer_1 = Conv2D(32, 3, activation=activation, input_shape=input_shape)","381a2f58":"convolutional_layer_2 = Conv2D(32, 3, activation=activation)\nconvolutional_layer_3 = Conv2D(64, 3, activation=activation)\nconvolutional_layer_4 = Conv2D(64, 3, activation=activation)","9d7bf96e":"max_pooling_layer_1 = MaxPooling2D(3)\nmax_pooling_layer_2 = MaxPooling2D(2)","4ad14543":"flatten_layer = Flatten(data_format=data_format)","bd64e20b":"hidden_layer = Dense(512, activation=activation)","a8b47737":"activation = \"softmax\"\n\noutput_layer = Dense(10, activation=activation)","71790a58":"convolutional_neural_network_model = utils.group_layers(convolutional_layer_1,\n                                                        convolutional_layer_2,\n                                                        max_pooling_layer_1,\n                                                        convolutional_layer_3,\n                                                        convolutional_layer_4,\n                                                        max_pooling_layer_2,\n                                                        flatten_layer,\n                                                        hidden_layer,\n                                                        output_layer)","a6bc8da4":"convolutional_neural_network_model.summary(line_length)","55d63d4f":"model = convolutional_neural_network_model\n\nutils.compile_model(model, lr)","cd4ec2c3":"weights = \"imagenet\"\ninclude_top = False\n\nvgg16_model = VGG16(weights=weights, include_top=include_top, input_shape=input_shape)","b20191bc":"model = vgg16_model\n\nutils.freeze_layers(model)","951d1da7":"last_layer = vgg16_model.output","e951295e":"flatten_layer = Flatten(data_format=data_format)(last_layer)","bf933cf4":"activation = \"relu\"\n\nhidden_layer = Dense(128, activation=activation)(flatten_layer)","eacb61f5":"activation = \"softmax\"\n\noutput_layer = Dense(10, activation=activation)(hidden_layer)","f0fdbde7":"input_layer = vgg16_model.input","8d5cdd19":"transfer_learning_model = Model(inputs=input_layer, outputs=output_layer)","29f9e1b6":"transfer_learning_model.summary(line_length)","25d21ade":"model = transfer_learning_model\n\nutils.compile_model(model, lr)","31351993":"epochs = 5\ngenerator = train_iterator\nvalidation_data = validation_iterator","cfc088db":"model = neural_network_model\n\nneural_network_history = model.fit_generator(epochs=epochs,\n                                             generator=generator,\n                                             validation_data=validation_data)","aa08cb5a":"model = convolutional_neural_network_model\n\nconvolutional_neural_network_history = model.fit_generator(epochs=epochs,\n                                                           generator=generator,\n                                                           validation_data=validation_data)","15a303f3":"model = transfer_learning_model\n\ntransfer_learning_history = model.fit_generator(epochs=epochs,\n                                                generator=generator,\n                                                validation_data=validation_data)","ece3032f":"history = neural_network_history\n\nutils.plot_history(history)","fc7f2013":"history = convolutional_neural_network_history\n\nutils.plot_history(history)","bda56bfb":"history = transfer_learning_history\n\nutils.plot_history(history)","ab6bc39d":"generator = test_iterator","6be96faf":"model = neural_network_model\n\nneural_network_predictions = utils.predict(model, generator)","5f7c3c2c":"model = convolutional_neural_network_model\n\nconvolutional_neural_network_predictions = utils.predict(model, generator)","0ac9ac38":"model = transfer_learning_model\n\ntransfer_learning_predictions = utils.predict(model, generator)","bb3f4eac":"predictions = neural_network_predictions\n\nneural_network_submission = utils.create_submission(predictions)","35db5b96":"predictions = convolutional_neural_network_predictions\n\nconvolutional_neural_network_submission = utils.create_submission(predictions)","4ee513e5":"predictions = transfer_learning_predictions\n\ntransfer_learning_submission = utils.create_submission(predictions)","7beb9fed":"random_state = seed","130a4f82":"neural_network_submission.sample(5, random_state=random_state)","e5c3e69a":"convolutional_neural_network_submission.sample(5, random_state=random_state)","08075298":"transfer_learning_submission.sample(5, random_state=random_state)","57faa1fe":"path_or_buf = \"neural_network_submission.csv\"\n\nneural_network_submission.to_csv(path_or_buf)","a758e2af":"path_or_buf = \"convolutional_neural_network_submission.csv\"\n\nconvolutional_neural_network_submission.to_csv(path_or_buf)","14f59025":"path_or_buf = \"transfer_learning_submission.csv\"\n\ntransfer_learning_submission.to_csv(path_or_buf)","917da982":"filepath = \"neural_network_model.h5\"\n\nneural_network_model.save(filepath)","901c8d34":"filepath = \"convolutional_neural_network_model.h5\"\n\nconvolutional_neural_network_model.save(filepath)","a13d0270":"filepath = \"transfer_learning_model.h5\"\n\ntransfer_learning_model.save(filepath)","d7ebe979":"Por \u00faltimo, fijamos una semilla para lograr que los experimentos sean reproducibles:\n\n---\n\n**Nota**: La reproducibilidad de los experimentos no est\u00e1 garantizada en `Keras` (`Tensorflow`) si se utilizan *GPUs* (debido a la ejecuci\u00f3n en paralelo de determinadas operaciones matem\u00e1ticas). No obstante, sigue siendo necesario fijar una semilla para que las particiones de entrenamiento y prueba se obtengan de manera determinista y as\u00ed se puedan comparar los resultados obtenidos en diferentes ejecuciones. Para conocer m\u00e1s informaci\u00f3n al respecto, se recomienda visitar este [enlace](https:\/\/keras.io\/getting_started\/faq\/#how-can-i-obtain-reproducible-results-using-keras-during-development).\n\n---","dd0b739f":"Como se puede observar, la red neuronal tiene que aprender un total de 3150602 par\u00e1metros. Por \u00faltimo, configuramos el modelo con respecto a los hiperpar\u00e1metros:\n\n---\n\n**Nota**: Si bien no es necesario comprender el funcionamiento del optimizador (`optimizer`), si que es importante que trat\u00e9is de ajustar la tasa de aprendizaje (`learning_rate`).\n\n**Nota**: Se ha decidido evaluar \u00fanicamente la tasa de acierto (`scoring=\"accuracy\"`) puesto que se trata de la m\u00e9trica de rendimiento con la que se evaluan los modelos en la competici\u00f3n. No obstante, en este [enlace](https:\/\/keras.io\/api\/metrics) se ofrece una lista exhaustiva.\n\n---","042b7577":"Adem\u00e1s es importante fijar todas las capas de `VGG16` como no entrenables para evitar modificar los pesos ya entrenados:","f06d5b53":"## 3.2. Redes neuronales convolucionales","616ed758":"#### 1. Lectura y estudio\n\nEn esta pr\u00e1ctica deber\u00e9is estudiar cuidadosamente la documentaci\u00f3n de esta libreta y leer las p\u00e1ginas de ejemplo y teor\u00eda de `Keras` proporcionadas.","84a578cf":"Con el objetivo de garantizar la reproducibilidad de los experimentos, vamos a serializar y almacenar los modelos. De esta manera, cualquiera puede recrear los mismos modelos y resultados:","20544c52":"Las *redes neuronales convolucionales* (*CNNs*) son una arquitectura especial de redes neuronales principalmente utilizadas en problemas de visi\u00f3n artificial. Este tipo de arquitectura se suele organizar mediante la siguiente secuencia de capas:\n\n* Capa convolucional.\n* Capa *ReLU*.\n* Capa de *pooling*.\n* Capa completamente conectada.\n\nSi bien no existe una \"*regla de oro*\" para definir la arquitectura de una red neuronal convolucional, se puede seguir el siguiente patr\u00f3n como recomendaci\u00f3n:\n\n1. `M` secuencias de una capa convolucional + *ReLU* + *pooling* (opcional).\n2. `K` secuencias de una capa completamente conectada + *ReLU*.\n3. Capa completamente conectada.\n\nCon `M > 0` y `K >= 0 & K < 3`.","aae96612":"Vamos a cargar el conjunto de datos `MNIST` y crear tres iteradores de *batches* de im\u00e1genes para el conjunto de datos de entrenamiento (`train_iterator`), validaci\u00f3n (`validation_iterator`) y prueba (`test_iterator`).\n\n---\n\n**Palabra clave**: Se entiende por *batch* a un conjunto de muestras (im\u00e1genes) que se propagan a trav\u00e9s de una red neuronal en una iteraci\u00f3n.\n\n---","906d3d98":"# Pr\u00e1ctica 3: Redes neuronales (*Deep Learning*)\n\n####\u00a0Miner\u00eda de Datos: Curso acad\u00e9mico 2020-2021\n\n### Profesorado:\n\n* Juan Carlos Alfaro Jim\u00e9nez\n* Jos\u00e9 Antonio G\u00e1mez Mart\u00edn\n\nEn esta pr\u00e1ctica trabajaremos con redes neuronales a trav\u00e9s de la *API* (*Advanced Programming Interface*) de `Keras`. Esta se trata de una de las librer\u00edas m\u00e1s populares actualmente debido a su facilidad de uso y versatilidad.","aaebdbfc":"Estas capas se encuentran implementadas en:\n\n* **Capa convolucional**: Se implementa en la clase `Conv2D` y sus hiperpar\u00e1metros m\u00e1s importantes son el n\u00famero de filtros (`filters`) y tama\u00f1o del filtro (`kernel_size`). La lista exhaustiva de capas convolucionales se encuentra en este [enlace](https:\/\/keras.io\/layers\/convolutional\/).\n\n* **Capa *ReLU***: La capa *ReLU* se especifica directamente en las capas correspondientes fijando el hiperpar\u00e1metro `activation=\"relu\"`.\n\n* **Capa de *pooling***: Existen multitud de clases que pueden ser utilizadas en la capa de *pooling*, siendo las m\u00e1s utilizadas `MaxPooling2D` y `AveragePooling2D`, que aplican como funci\u00f3n de agrupaci\u00f3n el m\u00e1ximo y la media (respectivamente). El hiperpar\u00e1metro m\u00e1s importante es el tama\u00f1o de la ventana (`pool_size`). La lista exhaustiva de capas de *pooling* se ofrece en este [enlace](https:\/\/keras.io\/layers\/pooling\/).","fe807f59":"Finalmente solo nos queda especificar la capa de entrada y salida:","28bc390e":"Una vez tenemos las redes neuronales entrenadas, simplemente nos queda obtener las predicciones sobre el conjunto de datos de prueba:","6e6a1341":"#\u00a01. Preliminares","4988a816":"Y comprobamos que los ficheros se han creado correctamente:","85753c37":"N\u00f3tese que se ha especificado un tama\u00f1o de *batch* de 64, esto es, se van a propagar 64 muestras del conjunto de datos a lo largo de las redes neuronales en cada iteraci\u00f3n. En particular:\n\n* En aprendizaje se van a actualizar los par\u00e1metros de las redes neuronales tras procesar 64 muestras del conjunto de datos de entrenamiento.\n\n* En inferencia se obtienen las predicciones de 64 muestras del conjunto de datos de validaci\u00f3n (o prueba) en paralelo.\n\nLa principal ventaja de utilizar un tama\u00f1o de *batch* menor al n\u00famero de instancias del conjunto de datos de entrenamiento (validaci\u00f3n o prueba) es que solo se tienen que cargar en memoria (simult\u00e1neamente) tantas im\u00e1genes como tama\u00f1o de *batch* se haya especificado. Esto va a permitir optimizar los recursos de memoria para as\u00ed poder trabajar con grandes conjuntos de datos.\n\nPor otro lado, el escalado de las im\u00e1genes va a permitir (entre otros) acelerar el proceso de entrenamiento dado que la convergencia en la optimizaci\u00f3n de los par\u00e1metros mediante gradiente descendiente se va a realizar m\u00e1s r\u00e1pidamente.\n\n---\n\n**Lectura recomendada**: En este [enlace](https:\/\/stats.stackexchange.com\/questions\/153531\/what-is-batch-size-in-neural-network) pod\u00e9is encontrar algunas de las ventajas (y desventajas) que presenta utilizar un tama\u00f1o de *batch* menor que el n\u00famero de muestras del conjunto de entrenamiento (validaci\u00f3n o prueba).\n\n**Palabra clave**: Se entiende por *epoch* al procesamiento completo de todas las instancias de un conjunto de datos.\n\n---","bc2914ac":"Una alternativa a crear redes neuronales convolucionales y entrenarlas desde cero es utilizar modelos pre-entrenados con grandes conjuntos de datos (`ImageNet`). Esta t\u00e9cnica se conoce como *transfer learning* y permite que las caracter\u00edsticas (profundas) aprendidas por una red neuronal convolucional sean extra\u00eddas para abordar otros problemas. Lo que se hace para tratar problemas mediante *transfer learning* es mantener los par\u00e1metros de la red neuronal convolucional original y a\u00f1adir capas completamente conectadas (despu\u00e9s del vector de car\u00e1cteristicas profundas) para que estas se centren en aprender los par\u00e1metros de acuerdo con el problema a resolver.\n\nVamos a comenzar cargando el modelo pre-entrenado `VGG16`:\n\n---\n\n**Lectura recomendada**: La lista exhaustiva de los modelos pre-entrenados disponibles en `Keras` se ofrecen en este [enlace](https:\/\/keras.io\/applications\/).\n\n---","c1f00a41":"Y finalizamos con la capa de salida:","127892e8":"#### 2. Arquitecturas de redes neuronales\n\nCada grupo deber\u00e1 proponer e implementar (al menos) tres arquitecturas diferentes de redes neuronales. Para ello, se recomiendan seguir los siguientes pasos:\n\n* Preparar el conjunto de datos de entrenamiento, validaci\u00f3n y prueba.\n* Definir una red neuronal convolucional manualmente o utilizar *transfer learning* (con *fine-tuning* de par\u00e1metros).\n* Utilizar t\u00e9cnicas para evitar el sobreajuste (*dropout*, *early stopping*, *data augmentation*, etc.).\n* Utilizar t\u00e9cnicas para acelerar el entrenamiento (inicializaci\u00f3n de pesos, *learning rate*, tama\u00f1o de *batch*, n\u00famero de *epochs*, etc.).","20374731":"Ahora solo nos queda crear el modelo que contenga dichas capas:","60db06c6":"Tras verificar que los ficheros se han creado correctamente, vamos a guardarlos. Para realizar las subidas a `Kaggle` simplemente debemos hacer `Commit` de la libreta y extraer los ficheros `.csv` del apartado `Output` (que contiene las predicciones realizadas por cada uno de los modelos).","2ce716e7":"# Trabajo aut\u00f3nomo","b2eff027":"##\u00a0Extras","9c839c2d":"En esta pr\u00e1ctica vamos a emplear el conjunto de datos `MNIST` (`Modified National Institute of Standards and Technology`). Desde su creaci\u00f3n en 1999, este conjunto de datos se ha utilizado como *benchmark* para probar el rendimiento de diferentes algoritmos de clasificaci\u00f3n supervisada en problemas de visi\u00f3n artificial.\n\nEl objetivo ser\u00eda identificar un d\u00edgito escrito a mano (del 0 al 9) en una imagen.","6ec36ac4":"Antes de a\u00f1adir la capa completamente conectada a `VGG16`, tenemos que extraer el vector de caracter\u00edsticas profundas (aplanar la salida de `VGG16`):","206b0b68":"Lo primero de todo es asegurarnos de que las librer\u00edas que vamos a utilizar est\u00e1n disponibles desde el principio:","5dcf9c75":"Un aspecto muy interesante es visualizar la evoluci\u00f3n del valor de la funci\u00f3n de p\u00e9rdida y de la tasa de acierto con respecto al n\u00famero de *epochs*: ","7e0e806c":"Una vez realizado este proceso, podemos a\u00f1adir la capa completamente conectada (con 128 neuronas):","144f0947":"Una vez hemos obtenido las predicciones, solo nos queda crear los ficheros de subida para la competici\u00f3n:","11384b7e":"Finalmente solo nos queda subirlas a la plataforma de la competici\u00f3n y ver el resultado obtenido.","b692375d":"En este caso, la red neuronal convolucional tiene que aprender 10688042 par\u00e1metros. Vamos a configurarla de acuerdo con los hiperpar\u00e1metros:","d844da49":"## 3.3. *Transfer Learning*","d1d63e98":"####\u00a04. Entregable\n\nDeber\u00e9is entregar un enlace a un *kernel* de `Kaggle` con el estudio sobre el conjunto de datos `MNIST`. En la evaluaci\u00f3n se valorar\u00e1 el estudio que hag\u00e1is tanto de las t\u00e9cnicas aplicadas como su justificaci\u00f3n.\n\n**Recordar que asociada a esta pr\u00e1ctica habr\u00e1 una entrevista para completar la evaluaci\u00f3n de la pr\u00e1ctica.**","bc629c20":"Antes de comenzar con la pr\u00e1ctica es necesario comprobar que se est\u00e9 utilizando una *GPU*. De esta manera se incrementar\u00e1 la capacidad computacional reduciendo as\u00ed el tiempo de aprendizaje e inferencia de las redes neuronales:","ab26edd6":"Y usando los generadores de im\u00e1genes, creamos los iteradores correspondientes:","bb369be9":"Las *redes neuronales* (*NNs*) son un tipo de modelo de aprendizaje autom\u00e1tico que tratan de emular el compartamiento del cerebro humano. Aunque existe una amplia gama de arquitecturas de redes neuronales, la m\u00e1s utilizada es el perceptr\u00f3n multicapa. Este tipo de arquitectura est\u00e1 formada por una capa de entrada y otra capa de salida, variando el n\u00famero de capas ocultas y el n\u00famero de neuronas en estas. Para definir las capas del perceptr\u00f3n multicapa en `Keras` utilizaremos:\n\n* **Capa de entrada**: Se integra en la primera capa oculta, especificando mediante el hiperpar\u00e1metro `input_shape` el tama\u00f1o de las im\u00e1genes.\n\n* **Capas ocultas**: Se implementan en la clase `Dense` y los hiperpar\u00e1metros m\u00e1s importantes son el n\u00famero de neuronas (`units`) y la funci\u00f3n de activaci\u00f3n (`activation`).\n\n* **Capa de salida**: Al igual que las capas ocultas se implementa en la clase `Dense` fijando el n\u00famero de neuronas al n\u00famero de etiquetas de la variable clase del problema a resolver (`units=n_classes`) y como funci\u00f3n de activaci\u00f3n *softmax* (`activation=\"softmax\"`).\n\nVamos a crear un perceptr\u00f3n multicapa con 2 capas ocultas, 64 unidades en cada una de estas y funci\u00f3n de activaci\u00f3n *ReLU* (*Rectified Linear Units*).\n\n---\n\n**Lectura recomendada**: En este [enlace](https:\/\/keras.io\/layers\/core\/) se proporcionan los diferentes tipos de capas que se pueden utilizar en `Keras` para definir la arquitectura de redes neuronales.\n\n---","6e196d05":"La primera capa que vamos a crear va a aplanar la imagen de entrada para poder procesarla en las capas completamente conectadas (indicando que la imagen de entrada est\u00e1 en modo de color RGB):","61764f5c":"Vamos a entrenar nuestras redes neuronales un total de 5 *epochs* (cada una):","7948ebb0":"## 3.1. Redes neuronales","f29aadd3":"Continuamos con las capas de *pooling*:","79a10e44":"Una vez tenemos preparados los iteradores correspondientes a los conjuntos de datos de entrenamiento, validaci\u00f3n y prueba, podemos pasar a la fase de modelado.","f2e8d1ea":"Comenzamos con la primera capa convolucional en la que debemos especificar el tama\u00f1o de la imagen de entrada:","df585348":"## Un peque\u00f1o par\u00e9ntesis: Garantizado la reproducibilidad de los experimentos","c6d12844":"Y finalizamos con la capa de salida:","0f2c1e30":"# 2. Carga de datos","5ca74c1e":"Continuamos con las capas ocultas:","77647344":"Ahora solo nos queda crear el modelo:","1f3084be":"#\u00a05. Predicci\u00f3n","7d4ce150":"####\u00a03. Competici\u00f3n\n\nLos grupos deber\u00e1n evaluar el rendimiento de los diferentes modelos que vayan obteniendo sobre el conjunto de datos de prueba en la [competici\u00f3n](https:\/\/www.kaggle.com\/t\/7db407a7d76e45f3bd42d0a0d5619183) creada con tal prop\u00f3sito.\n\n**Los grupos con los tres mejores modelos tendr\u00e1n una bonificaci\u00f3n en la nota de la asignatura.**","596538a4":"Como se puede observar, las tres arquitecturas obtienen buenas tasas de acierto sobre el conjunto de datos de validaci\u00f3n. En este caso concreto, la red neuronal convolucional definida manualmente es la que mejores resultados obtiene. No obstante, n\u00f3tese que sus par\u00e1metros est\u00e1n sobreajustados al conjunto de datos de entrenamiento.","73dcb87d":"Como se puede observar, la red neuronal convolucional \u00fanicamente tiene que aprender 1049994 par\u00e1metros (en lugar de los 15764682 par\u00e1metros totales). Por \u00faltimo, vamos a configurarla con respecto a los hiperpar\u00e1metros:","b45a2417":"# 3. Modelos basados en redes neuronales","17be4570":"Como se ha podido observar, las redes neuronales sobreajustan al conjunto de datos de entrenamiento. Para evitarlo, podemos recurrir a t\u00e9cnicas como *dropout* que permiten obtener modelos m\u00e1s robustos contra el ruido. Esta se encuentra en la clase `Dropout` y pod\u00e9is encontrar m\u00e1s informaci\u00f3n en este [enlace](https:\/\/keras.io\/layers\/core\/).\n\nAdem\u00e1s, la clase `ImageDataGenerator` permite aplicar diferentes t\u00e9cnicas de *data augmentation* para incrementar el n\u00famero de im\u00e1genes en conjunto de datos de entrenamiento con t\u00e9cnicas como rotaci\u00f3n, cambio de canales de color, etc.\n\nPor \u00faltimo, es importante que tener en cuenta que, durante el entrenamiento, no hemos seleccionado el mejor modelo sobre el conjunto de validaci\u00f3n (ni tampoco hemos usado el conjunto de validaci\u00f3n para realizar un ajuste de hiperpar\u00e1metros), pues simplemente nos hemos quedado con el modelo obtenido despu\u00e9s de finalizar el n\u00famero de *epochs* establecido. La clase `CallBack` nos permite monitorizar diferentes resultados sobre el conjunto de datos de validaci\u00f3n y actuar en consecuencia. Encontrar\u00e9is toda la documentaci\u00f3n necesaria en este [enlace](https:\/\/keras.io\/callbacks\/).\n\n---\n\n**Nota**: Si se particiona el conjunto de datos usando el hiperpar\u00e1metro `subset` de la clase `ImageDataGenerator`, el aumento de datos se aplica tanto al conjunto de datos de entrenamiento como validaci\u00f3n, lo cu\u00e1l es incorrecto. La validaci\u00f3n de los modelos siempre debe realizarse sobre las im\u00e1genes originales (sin modificar).\n\n---","ae4d7dc4":"Lo primero de todo es crear los generadores de im\u00e1genes para el conjunto de datos de entrenamiento (`train_generator`) y prueba (`test_generator`): ","89187f19":"Y la capa de salida:","2f2129a0":"Procedemos con la capa de aplanamiento y la capa completamente conectada:","b401ae5f":"Seguimos con el resto de capas convolucionales:","2d44992d":"# 4. Modelado y evaluaci\u00f3n","8aa6d607":"##\u00a0Entrega","ebd2bbe7":"Vamos a dise\u00f1ar una red neuronal convolucional con la siguiente secuencia de capas:\n\n* Capa convolucional (con 32 filtros y un tama\u00f1o de filtro de 3) + *ReLU* + *pooling* (con un tama\u00f1o de ventana de 2 y agrupando por la m\u00e1ximo).\n* Capa convolucional (con 64 filtros y un tama\u00f1o de filtro de 3) + *ReLU* + *pooling* (con un tama\u00f1o de ventana de 3 y agrupando por el m\u00e1ximo).\n* Capa complementamente conectada (con 512 neuronas)."}}