{"cell_type":{"75ad4d21":"code","5e37b6fa":"code","68e004ae":"code","380bec5a":"code","8681e15b":"code","b27513f6":"code","c4a28f6f":"code","efdf985e":"code","4997485d":"code","18eaf30e":"code","028d8e96":"code","11bf65d3":"code","830a79c4":"code","baa397b1":"code","6de1df8c":"markdown","0bf67813":"markdown"},"source":{"75ad4d21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5e37b6fa":"# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","68e004ae":"dataset = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [dataset, test_data]\ndataset.head()","380bec5a":"ax = sns.countplot(x='Sex', hue='Survived', data=dataset)\n#plt.show()\n\ncol = ['Survived', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked']\nno_of_rows = 2\nno_of_col = 3\nfig, axs = plt.subplots(no_of_rows, no_of_col, figsize=(no_of_col * 3.5, no_of_rows * 3))\n\nfor r in range(0, no_of_rows):\n    for c in range(0, no_of_col):\n        i = r * no_of_col + c\n        ax = axs[r][c]\n        sns.countplot(dataset[col[i]], hue=dataset[\"Survived\"], ax=ax)\n        ax.set_title(col[i], fontsize=14, fontweight='bold')\n        ax.legend(title=\"survived\", loc='upper center')\n\nplt.tight_layout()\n#use plt.show() if you are using an IDE like Pycharm","8681e15b":"g = sns.FacetGrid(dataset, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","b27513f6":"# grid = sns.FacetGrid(dataset, col='Pclass', hue='Survived')\ngrid = sns.FacetGrid(dataset, col='Survived', row='Pclass', height=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","c4a28f6f":"for dat in combine:\n    dat['Title'] = dat.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nfor dat in combine:\n    dat['Title'] = dat['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dat['Title'] = dat['Title'].replace('Mlle', 'Miss')\n    dat['Title'] = dat['Title'].replace('Ms', 'Miss')\n    dat['Title'] = dat['Title'].replace('Mme', 'Mrs')\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}","efdf985e":"for dat in combine:\n    dat['Title'] = dat['Title'].map(title_mapping)\n    dat['Title'] = dat['Title'].fillna(0)\n\ndataset = dataset.drop(['Name', 'PassengerId', 'Cabin', 'Embarked', 'Ticket','Fare'], axis=1)\n\ntest_data = test_data.drop(['Name', 'PassengerId', 'Cabin', 'Embarked', 'Ticket', 'Fare'], axis=1)\ncombine = [dataset, test_data]\ndataset.head()\n","4997485d":"test_data.head()","18eaf30e":"X = dataset.iloc[:, 1:].values\nX_test = test_data.iloc[:, :].values\ny = dataset.iloc[:, 0].values","028d8e96":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 2:3])\nX[:, 2:3] = imputer.transform(X[:, 2:3])\nimputer.fit(X_test[:, 2:3])\nX_test[:, 2:3] = imputer.transform(X_test[:, 2:3])","11bf65d3":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n# Encoding the test set\nc_t = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\nX_test = np.array(c_t.fit_transform(X_test))\n# print(X)","830a79c4":"# Training the SVM model on the Training set\nfrom sklearn.svm import SVC\n\nclassifier = SVC(kernel='linear', random_state=0)\nclassifier.fit(X, y)","baa397b1":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\nprint(y_pred.reshape(len(y_pred), 1))","6de1df8c":"importing dataset","0bf67813":"The data can be categorized into two category: \n1)Numerical - Pclass, Age, SibSp, Parch, Fare, Survived\n2)Object - Name, Sex, Cabin, Embarked, Ticket\n\nLet's do some Visualization of Training set data, i.e dataset"}}