{"cell_type":{"92b4e2c1":"code","7f29ecde":"code","315c0ab5":"code","3c065742":"code","84e49847":"code","9d8d6eb2":"code","e32cb27d":"code","cfccdd88":"code","0dcb5156":"code","0ccab7db":"code","945433c2":"code","8311da6b":"code","c9744144":"code","d5f8dc8d":"code","bcad811c":"code","08964363":"code","7d9ae5cb":"code","0947194d":"code","72b4a7ba":"code","319a90fe":"code","e4a1d794":"code","a6912fc4":"code","6d3c3dd0":"code","e85e76e1":"markdown","6689b410":"markdown","ba8af953":"markdown","0afe4b19":"markdown","8a2d883b":"markdown","0efc9c31":"markdown","c6565680":"markdown","49e4a4b4":"markdown","d1bc7ebb":"markdown","8cba5234":"markdown","8b419207":"markdown","c0dc8ab5":"markdown","7241c010":"markdown","5ce6099e":"markdown","6a751e0c":"markdown","c4e13510":"markdown"},"source":{"92b4e2c1":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport pathlib\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Layer, BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\n\nimport matplotlib.gridspec as gridspec\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings('ignore')","7f29ecde":"classes = {\"cat\": \"0\", \"dog\": \"1\", \"wild\": \"2\"}\nallFilenames = []\nallCategories = []\nfor classElement in classes:\n    filenames = os.listdir(\"..\/input\/animal-faces\/afhq\/train\/\"+classElement)\n    allFilenames += [classElement + \"\/\" + file for file in filenames]\n    allCategories += [classes[classElement]] * len(filenames)\n\n\ndf = pd.DataFrame({\n    'filename': allFilenames,\n    'class': allCategories\n})","315c0ab5":"allFilenames_test = []\nallCategories_test = []\nfor classElement in classes:\n    filenames = os.listdir(\"..\/input\/animal-faces\/afhq\/val\/\" + classElement)\n    allFilenames_test += [classElement + \"\/\" + file for file in filenames]\n    allCategories_test += [classes[classElement]] * len(filenames)\n\n\ndf_test = pd.DataFrame({\n    'filename': allFilenames_test,\n    'class': allCategories_test\n})","3c065742":"df.head()","84e49847":"x = ['Cat', 'Dog', 'Wild']\ny = [len(df[df[\"class\"] == \"0\"]), len(df[df[\"class\"] == \"1\"]), len(df[df[\"class\"] == \"2\"])]\n\nfig = go.Figure(data=[go.Bar(x = x, y = y)])\nfig.update_layout(title_text = 'Distribution of classes')\nfig.show()","9d8d6eb2":"df_training, df_validation = train_test_split(df, test_size = 0.20)\ndf_training = df_training.reset_index(drop = True)\ndf_validation = df_validation.reset_index(drop = True)","e32cb27d":"df_training","cfccdd88":"train_datagen = ImageDataGenerator(\n    rotation_range = 45,\n    width_shift_range = 0.2,  \n    height_shift_range = 0.2,    \n    zoom_range = 0.2,        \n    horizontal_flip = True, \n    rescale = 1.\/255,\n    fill_mode = 'reflect'\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    df_training, \n    \"..\/input\/animal-faces\/afhq\/train\", \n    x_col = 'filename',\n    y_col = 'class',\n    target_size = (150, 150),\n    class_mode = 'categorical',\n    batch_size = 64\n)","0dcb5156":"df_example = df_training.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    df_example, \n    \"..\/input\/animal-faces\/afhq\/train\", \n    x_col='filename',\n    y_col='class',\n    target_size = (150, 150),\n    class_mode='categorical'\n)","0ccab7db":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","945433c2":"validation_datagen = ImageDataGenerator(rescale = 1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    df_validation, \n    \"..\/input\/animal-faces\/afhq\/train\", \n    x_col = 'filename',\n    y_col = 'class',\n    target_size = (150, 150),\n    class_mode = 'categorical',\n    batch_size = 64\n)","8311da6b":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","c9744144":"early_stopping = EarlyStopping(patience=10)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_acc', patience = 3, factor = 0.5, min_lr = 0.00001)\n\ncallbacks = [early_stopping, reduce_lr]","d5f8dc8d":"history = model.fit_generator(\n    train_generator, \n    epochs = 25,\n    validation_data = validation_generator,\n    callbacks = callbacks\n)","bcad811c":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(y = history.history['loss'],\n                    mode='lines+markers',\n                    name='Training loss'))\nfig.add_trace(go.Scatter(y = history.history['val_loss'],\n                    mode='lines+markers',\n                    name='Validation loss'))\n\nfig.update_layout(title_text = 'Loss of model')\nfig.show()","08964363":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(y = history.history['accuracy'],\n                    mode='lines+markers',\n                    name='Training accuracy'))\nfig.add_trace(go.Scatter(y = history.history['val_accuracy'],\n                    mode='lines+markers',\n                    name='Validation accuracy'))\n\nfig.update_layout(title_text = 'Accuracy of model')\nfig.show()","7d9ae5cb":"test_gen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    df_test, \n    \"..\/input\/animal-faces\/afhq\/val\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode= None,\n    target_size = (150, 150),\n    batch_size = 64,\n    shuffle = False\n)","0947194d":"predict = model.predict_generator(test_generator, steps = np.ceil(df_test.shape[0] \/ 64))","72b4a7ba":"df_test['prediction'] = np.argmax(predict, axis=-1)\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\ndf_test['prediction'] = df_test['prediction'].replace(label_map)\ndf_test['prediction'] = df_test['prediction'].replace({ '1': 1, '0': 0 })","319a90fe":"fig = go.Figure(data=[go.Bar(x = ['Cat', 'Dog', 'Wild'], y = df_test['prediction'].value_counts())])\nfig.update_layout(title_text = 'Distribution of predicted classes')\nfig.show()","e4a1d794":"df_test['correctPred'] = df_test.apply(lambda x: str(x['class']) == str(x['prediction']), axis=1)","a6912fc4":"fig = go.Figure(data=[go.Bar(x = ['Correct prediction', 'False prediction'], y = df_test.correctPred.value_counts())])\nfig.update_layout(title_text = 'Correct prediction vs False prediction')\nfig.show()","6d3c3dd0":"import random\nrandomlist = []\nfor i in range(0,9):\n    n = random.randint(0,len(df_test))\n    randomlist.append(n)\n\nfig = plt.figure(figsize=(15,8))\ngs1 = gridspec.GridSpec(3, 3)\naxs = []\nfor num in range(len(randomlist)):\n    row = df_test.iloc[[randomlist[num]]]\n    filename = row['filename'][randomlist[num]]\n    img = load_img(\"..\/input\/animal-faces\/afhq\/val\/\"+filename, target_size= (150, 150))\n    axs.append(fig.add_subplot(gs1[num - 1]))\n    axs[-1].imshow(img)\n    axs[-1].set_title(\"Actual: \" + df_test[df_test[\"filename\"] == filename][\"class\"].iloc[0] + \" Prediction: \" + str(row['prediction'][randomlist[num]]) )\nfig.subplots_adjust(hspace=0.3)\nplt.show()","e85e76e1":"<a id=\"2\"><\/a>\n# Preprocess data","6689b410":"<a id=\"4\"><\/a>\n# Results","ba8af953":"I just want to give a little information about what I did in this kernel related to data.\n\nAs you know, we have two folders: train and val\n\nI split the train set into two parts: 80% for training 20% validation\n\nAnd I used the dataset inside the val folder as test data. With this dataset, I can get information on my model's accuracy on the new unseen dataset.","0afe4b19":"The result of data augmentation:","8a2d883b":"**Thank You!** If you have any suggestion, advice or feedback, I will be very appreciated to hear them.","0efc9c31":"Here I used ImageDataGenerator for data augmentation. I used several properties for creating lots of samples.","c6565680":"I am using **val** folder as test data set for getting information accuracy on new dataset.","49e4a4b4":"Here I tried to show you images of 9 estimates and the actual classes of their from test data.","d1bc7ebb":"# **Animal Face Detection with Keras**\n\n### In this kernel, I will use Keras for identifying animals from images. If you have any suggestions, advice or correction please don't hesitate to write them.\n\n    \n<center><img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F793761%2Fafb6d1aa3be4c82e17a0d0b802436e82%2Fafhq_dataset.jpg?generation=1590130743209322&alt=media\"><\/center>","8cba5234":"As you can see, we have quite lots of correct predictions in our test data prediction.","8b419207":"I splited the train set into two parts: 80% for training 20% validation","c0dc8ab5":"<a id=\"1\"><\/a>\n# Import libraries","7241c010":"I used two callbacks: Early stopping and Reduce learning rate\n\n**Early stopping**\nStop training when a monitored metric has stopped improving. Once it's found no longer decreasing, model.stop_training is marked True and the training terminates.\n\n\n**Reduce learning rate**\n\nReduce learning rate when a metric has stopped improving.\n\nModels often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.","5ce6099e":"# Table of contents:\n\n* [1. Import libraries](#1)\n* [2. Preprocess data](#2)\n* [3. Create model](#3)\n* [4. Results](#4)","6a751e0c":"# Introduction\n\nThis dataset, also known as Animal Faces-HQ (AFHQ), consists of 16,130 high-quality images at 512\u00d7512 resolution.\nThere are three domains of classes, each providing about 5000 images. By having multiple (three) domains and diverse images of various breeds per each domain, AFHQ sets a challenging image-to-image translation problem. The classes are:\n\n* Cat\n* Dog\n* Wildlife","c4e13510":"<a id=\"3\"><\/a>\n# Create model"}}