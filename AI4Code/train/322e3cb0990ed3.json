{"cell_type":{"e8f6e0f5":"code","41e729ce":"code","576dca6e":"code","74c17fa8":"code","12538b40":"code","d80f4aec":"code","5d59fe33":"code","ab23c615":"code","18d3cc70":"code","cd1d1b1a":"code","c7a11190":"code","dc31f914":"code","b3b9d24b":"code","014e55d0":"code","c37a881f":"code","a53a2292":"code","1a72e135":"code","77b3b10f":"code","57ad7b4f":"code","5cd3e37c":"code","8eb1255b":"code","c8e2b021":"code","88c86d56":"code","087d5b8d":"code","8e663066":"code","0c44c8c5":"code","db609bdf":"code","7fd69713":"code","33b7a813":"code","c670f722":"code","8901361a":"code","f38f11e1":"code","7cacb380":"code","42c26c86":"code","dc4a2559":"code","68e0a7a1":"code","966b9ef7":"markdown","3560e076":"markdown","bfa37f83":"markdown","eeebe5d1":"markdown","7cf1e736":"markdown","1dac3029":"markdown","07e7bc90":"markdown","39f7c47b":"markdown","038626d6":"markdown","c12da6e7":"markdown","725cd1f7":"markdown","e0a4e991":"markdown","86662e95":"markdown","ea1137f8":"markdown","9a09a35a":"markdown","83890423":"markdown"},"source":{"e8f6e0f5":"# Importing Packages\n\n# Setting Random seed\nfrom numpy.random import seed\nseed(101)\nfrom tensorflow import set_random_seed\nset_random_seed(101)\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nimport os\nimport cv2\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","41e729ce":"# Setting Parameters before loading data\nIMAGE_SIZE = 96\nIMAGE_CHANNELS = 3\nSAMPLE_SIZE = 80000 # the number of images we use from each of the two classes\n","576dca6e":"print(len(os.listdir('..\/input\/train')))\nprint(len(os.listdir('..\/input\/test')))","74c17fa8":"df_data = pd.read_csv('..\/input\/train_labels.csv')\n\n# removing this image because it caused a training error previously\ndf_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n\n# removing this image because it's black\ndf_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n\n\nprint(df_data.shape)","12538b40":"df_data['label'].value_counts()","d80f4aec":"# Function for Showing images with both classes randomly\ndef draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n    \n    \"\"\"\n    Give a column in a dataframe,\n    this function takes a sample of each class and displays that\n    sample on one row. The sample size is the same as figure_cols which\n    is the number of columns in the figure.\n    Because this function takes a random sample, each time the function is run it\n    displays different images.\n    \"\"\"\n    \n\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n            im=cv2.imread(file)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=16)  \n    plt.tight_layout()\n    plt.show()\n    ","5d59fe33":"IMAGE_PATH = '..\/input\/train\/' \n# Displaying 4 images in each class \ndraw_category_images('label',4, df_data, IMAGE_PATH)","ab23c615":"# take a random sample of class 0 with size equal to num samples in class 1\ndf_0 = df_data[df_data['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n# filter out class 1\ndf_1 = df_data[df_data['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n\n# concat the dataframes\ndf_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n# shuffle\ndf_data = shuffle(df_data)\n\ndf_data['label'].value_counts()","18d3cc70":"# DF Overview\ndf_data.head()","cd1d1b1a":"# train_test_split\n\n# stratify=y creates a balanced validation set.\ny = df_data['label']\n\ndf_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","c7a11190":"# Both classes have equal weightage in train subset\ndf_train['label'].value_counts()","dc31f914":"# Both classes have equal weightage in Val subset\ndf_val['label'].value_counts()","b3b9d24b":"# Create a new directory\nbase_dir = 'base_dir'\nos.mkdir(base_dir)\n\n# create a path to 'base_dir' to which we will join the names of the new folders\n# train_dir\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n# val_dir\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\n# Inside each folder we create seperate folders for each class\n# create new folders inside train_dir\nno_tumor_tissue = os.path.join(train_dir, 'a_no_tumor_tissue')\nos.mkdir(no_tumor_tissue)\nhas_tumor_tissue = os.path.join(train_dir, 'b_has_tumor_tissue')\nos.mkdir(has_tumor_tissue)\n\n\n# create new folders inside val_dir\nno_tumor_tissue = os.path.join(val_dir, 'a_no_tumor_tissue')\nos.mkdir(no_tumor_tissue)\nhas_tumor_tissue = os.path.join(val_dir, 'b_has_tumor_tissue')\nos.mkdir(has_tumor_tissue)\n","014e55d0":"# check that the folders have been created\nos.listdir('base_dir\/train_dir')","c37a881f":"# Set the id as the index in df_data\ndf_data.set_index('id', inplace=True)","a53a2292":"# Get a list of train and val images\ntrain_list = list(df_train['id'])\nval_list = list(df_val['id'])\n\n\n# Transfer the train images\nfor image in train_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image + '.tif'\n    # get the label for a certain image\n    target = df_data.loc[image,'label']\n    \n    # these must match the folder names\n    if target == 0:\n        label = 'a_no_tumor_tissue'\n    if target == 1:\n        label = 'b_has_tumor_tissue'\n    \n    # source path to image\n    src = os.path.join('..\/input\/train', fname)\n    # destination path to image\n    dst = os.path.join(train_dir, label, fname)\n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)\n\n\n# Transfer the val images\n\nfor image in val_list:\n    \n    # the id in the csv file does not have the .tif extension therefore we add it here\n    fname = image + '.tif'\n    # get the label for a certain image\n    target = df_data.loc[image,'label']\n    \n    # these must match the folder names\n    if target == 0:\n        label = 'a_no_tumor_tissue'\n    if target == 1:\n        label = 'b_has_tumor_tissue'\n    \n\n    # source path to image\n    src = os.path.join('..\/input\/train', fname)\n    # destination path to image\n    dst = os.path.join(val_dir, label, fname)\n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)\n    \n\n\n   ","1a72e135":"# checking for how many train images we have in each folder\n\nprint(len(os.listdir('base_dir\/train_dir\/a_no_tumor_tissue')))\nprint(len(os.listdir('base_dir\/train_dir\/b_has_tumor_tissue')))","77b3b10f":"# checking how many val images we have in each folder\n\nprint(len(os.listdir('base_dir\/val_dir\/a_no_tumor_tissue')))\nprint(len(os.listdir('base_dir\/val_dir\/b_has_tumor_tissue')))\n","57ad7b4f":"# Setting up new created directories as path\ntrain_path = 'base_dir\/train_dir'\nvalid_path = 'base_dir\/val_dir'\ntest_path = '..\/input\/test'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\n# Defining steps with batch size and samples\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\nval_steps = np.ceil(num_val_samples \/ val_batch_size)","5cd3e37c":"# Using ImageDataGenerator for loading images\ndatagen = ImageDataGenerator(rescale=1.0\/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)","8eb1255b":"# Model Params\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n# Model Structure\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()\n","c8e2b021":"# Compliling the model\nmodel.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n              metrics=['accuracy'])","88c86d56":"# Get the labels that are associated with each index\nprint(val_gen.class_indices)","087d5b8d":"filepath = \"model.h5\"\n\n# Checkpoint to save weights after every epoch\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\n# It alters the learning rate based on metrics in each epoch\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                                                  \ncallbacks_list = [checkpoint, reduce_lr]\n\n# Fitting the model\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=20, verbose=1,\n                   callbacks=callbacks_list)","8e663066":"# Here the best epoch will be used.\n\n# Loading Weights file\nmodel.load_weights('model.h5')\n\nval_loss, val_acc = \\\nmodel.evaluate_generator(test_gen, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","0c44c8c5":"# Display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()","db609bdf":"predictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)","7fd69713":"# To check what index keras has internally assigned to each class. \ntest_gen.class_indices","33b7a813":"# The columns need to be ordered to match the output of the previous cell\n# Appending predictions to  a dataframe object\ndf_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\ndf_preds.head()","c670f722":"# Get the true labels\ny_true = test_gen.classes\n\n# Get the predicted labels as probabilities\ny_pred = df_preds['has_tumor_tissue']","8901361a":"# AUC Score\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_true, y_pred)","f38f11e1":"# Confusion Matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","7cacb380":"# labels of the test images.\ntest_labels = test_gen.classes","42c26c86":"# argmax returns the index of the max value in a row\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))","dc4a2559":"# Define the labels of the class indices. These need to match the order shown above.\ncm_plot_labels = ['no_tumor_tissue', 'has_tumor_tissue']\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","68e0a7a1":"# Classification Report\nfrom sklearn.metrics import classification_report\n\n# Generate a classification report\n\n# For this to work we need y_pred as binary labels not as probabilities\ny_pred_binary = predictions.argmax(axis=1)\n\nreport = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n\nprint(report)\n","966b9ef7":"### Model Architecture\u00b6","3560e076":"### Train the Model","bfa37f83":"### Labels as per csv file\n\n0 = no tumor tissue<br>\n1 =   has tumor tissue. <br>\n","eeebe5d1":"## Metrics","7cf1e736":"### Transfer the images into the folders","1dac3029":"<center><h1 class=\"list-group-item list-group-item-success\">HISTOPATHOLOGIC CANCER DETECTION<\/h1><\/center><br>\n\n<img src = \"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/11848\/logos\/header.png?t=2018-11-15-01-52-19\">\n","07e7bc90":"### Check the class distribution","39f7c47b":"### Create a Dataframe containing all images","038626d6":"### Evaluate the model using the val set","c12da6e7":"### Display a random sample of train images  by class","725cd1f7":"### Create a Directory Structure","e0a4e991":"#### Balance the target distribution\nWe will reduce the number of samples in class 0.","86662e95":"### Set Up the Generators","ea1137f8":"### Checking for  Count of Train & Test Images","9a09a35a":"### Plot the Training Curves","83890423":"### Predictions"}}