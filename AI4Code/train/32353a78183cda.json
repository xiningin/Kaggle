{"cell_type":{"1c705ca7":"code","43c08345":"code","036dc8de":"code","076cd3a6":"code","116d7d64":"code","b00024ed":"code","4e02d9b7":"code","d5bf28e1":"code","309431f9":"code","627fd752":"code","9bb18ed6":"code","129b615a":"code","f1696c73":"code","18d960b8":"code","ac7ec4b8":"code","880ac4f4":"code","22ffab66":"code","f887e9b6":"code","4b00376c":"markdown","7a18f9da":"markdown","f8ef4bba":"markdown","7e3c3e8c":"markdown","a7a410b0":"markdown","c72aaca8":"markdown","9bd62919":"markdown","ebaae66f":"markdown","ebb69398":"markdown","444552d6":"markdown","1343ef0e":"markdown","1458eb00":"markdown","9820a7f9":"markdown","7f9965ee":"markdown","179264db":"markdown","77cd9bba":"markdown","9abbed9b":"markdown","7f6f87fd":"markdown","23b16ec3":"markdown","76e53f49":"markdown","746f0faa":"markdown","833256eb":"markdown"},"source":{"1c705ca7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot # plotly offline mode\ninit_notebook_mode(connected=True) \n\nimport seaborn as sns\nimport cv2\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D,MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","43c08345":"# plotting a random image\nimg = plt.imread(\"..\/input\/flowers\/flowers\/daisy\/100080576_f52e8ee070_n.jpg\")\nimg = cv2.resize(img,(124,124))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","036dc8de":"x_ = list()\ny = list()\nIMG_SIZE = 128\nfor i in os.listdir(\"..\/input\/flowers\/flowers\/daisy\"):\n    try:\n        path = \"..\/input\/flowers\/flowers\/daisy\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(0)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers\/flowers\/dandelion\"):\n    try:\n        path = \"..\/input\/flowers\/flowers\/dandelion\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(1)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers\/flowers\/rose\"):\n    try:\n        path = \"..\/input\/flowers\/flowers\/rose\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(2)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers\/flowers\/sunflower\"):\n    try:\n        path = \"..\/input\/flowers\/flowers\/sunflower\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(3)\n    except:\n        None\nfor i in os.listdir(\"..\/input\/flowers\/flowers\/tulip\"):\n    try:\n        path = \"..\/input\/flowers\/flowers\/tulip\/\"+i\n        img = plt.imread(path)\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        x_.append(img)\n        y.append(4)\n    except:\n        None\nx_ = np.array(x_)","076cd3a6":"#plottin one of all flower types in data\nplt.figure(figsize = (20,20))\nfor i in range(5):\n    img = x_[950*i]\n    plt.subplot(1,5,i+1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title(y[950*i])","116d7d64":"# for replacement process i'll use keras.to_categorical \nfrom keras.utils.np_utils import to_categorical\ny = to_categorical(y,num_classes = 5)","b00024ed":"# test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x_,y,test_size = 0.15,random_state = 42)","4e02d9b7":"# validation and trains split\nx_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.15,random_state = 42)","d5bf28e1":"plt.figure(figsize = (20,20))\nfor i in range(5):\n    img = x_train[600*i]\n    plt.subplot(1,5,i+1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title(y_train[600*i])\nplt.show()","309431f9":"x_train.shape # look traing shape","627fd752":"model = Sequential()\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),padding=\"Same\",activation=\"relu\" , input_shape = (IMG_SIZE,IMG_SIZE,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=256,kernel_size = (3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=512,kernel_size = (3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\n# 1st Fully Connected Layer\nmodel.add(Dense(1024,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n# Add output layer\nmodel.add(Dense(5,activation=\"softmax\"))\n\nmodel.summary() # print summary my model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy']) #compile model","9bb18ed6":"model.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=0.001),\n              metrics=['accuracy'])","129b615a":"epoch = 50 \nbatch_size = 64","f1696c73":"datagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    rotation_range=60,  # randomly rotate images in the range (60, 0 to 180)\n    zoom_range = 0.1, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,\n    shear_range=0.1,\n    fill_mode = \"reflect\"\n    ) \ndatagen.fit(x_train)","18d960b8":"history = model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                              epochs= epoch,validation_data=(x_val,y_val),\n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size\n                              )","ac7ec4b8":"print(\"Test Accuracy: {0:.2f}%\".format(model.evaluate(x_test,y_test)[1]*100)) #get score acording to test datas","880ac4f4":"x_ = np.array(range(len(history.history['loss']))) # get loss values from the history\ntrace1 = go.Scatter(\n        x = x_,\n        y = history.history['loss'], # get loss values from the history\n        mode = \"lines\",\n        marker = dict(color = \"rgba(0,255,0,0.9)\"),\n        text = \"Loss\"\n)\ntrace2 = go.Scatter(\n        x = x_,\n        y = history.history['acc'],# get accuracy values from the history\n        mode = \"lines\",\n        marker = dict(color = \"rgba(0,0,255,0.9)\"),\n        text = \"Accuracy\"\n)\ndata = [trace1,trace2]\nlayout = dict(title = \"Training Accuracy and Loss\")\nfig = dict(data = data,layout=layout)\niplot(fig)","22ffab66":"x_ = np.array(range(len(history.history['val_loss'])))# get validation loss values from the history\ntrace1 = go.Scatter(\n        x = x_,\n        y = history.history['val_loss'], # get validation loss values from the history\n        mode = \"lines\",\n        marker = dict(color = \"rgba(0,0,0,0.9)\"),\n        text = \"Validation Loss\"\n)\ntrace2 = go.Scatter(\n        x = x_,\n        y = history.history['val_acc'],# get validation accuracy values from the history\n        mode = \"lines\",\n        marker = dict(color = \"rgba(255,0,0,0.9)\"),\n        text = \"Validation Accuracy\"\n)\ndata = [trace1,trace2]\nlayout = dict(title = \"Validation Accuracy and Loss\")\nfig = dict(data = data,layout=layout)\niplot(fig)","f887e9b6":"from sklearn.metrics import confusion_matrix\nY_pred = model.predict(x_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1)\nY_true = np.argmax(y_val,axis = 1)\nconfusion_mtx = confusion_matrix(Y_true,Y_pred_classes)\nf,ax = plt.subplots(figsize = (8,8))\nsns.heatmap(confusion_mtx,annot=True,linewidths = 0.01,cmap=\"Reds\",\n            linecolor = \"gray\",fmt = \".2f\",ax=ax\n            )\nplt.xlabel(\"predicted label\")\nplt.ylabel(\"True Label\")\nplt.title(\"confusion matrix\")\nplt.show()","4b00376c":"compile model","7a18f9da":"Firsly split test data then split train and validation datas","f8ef4bba":"Plotting random 5 image in train data","7e3c3e8c":"Test accuracy a little bit lower than validation accuracy","a7a410b0":"Create Sequential model with using Keras ","c72aaca8":"# 1. Introduction \nI'll try the flower recognition with custom CNN(convolutional neural network) model in this kernel. This data have 5 different kind flower. These flowers are daisy, dandelion, rose, sunflower and tuilp. I will try recognition them. Firstly i'll the data read then i'll prepare the data. Secondly i'll create my cnn model and train them. 'e'll see what happens at the end \u263b","9bd62919":"# 7. Conclusion\n* Accuracy rate exceeded 80% limit while in the training phase. In the same way validation accuracy return the 80%. I think this is not a bad result for this datasets.\n* According to the confusion matrix of the most difficult to detect the type of flower is rose. \n* According to the confusion matrix of the easiest to detect the type of flower is sunflower.\n* Most false prediction between rose and tuilps.\n* Thank you for your interest \u263b","ebaae66f":"Not bad for first time in my opinion. Let's look test result","ebb69398":"Train our model according to the data and the values we have prepared in the previous stages","444552d6":"# 2. Read and Overview Data ","1343ef0e":"# Content\n1. Introduction\n2. Read and Overview Data\n3. Data Preparation\n4. Create CNN Model\n5. Train and Test the Model\n6. Plotting Results\n7. Conclusion","1458eb00":"**import all necessary modules**","9820a7f9":"Create a data augmentation and apply them x_train data ","7f9965ee":"# 6. Plotting Results","179264db":"Set epoch and batch size values","77cd9bba":"# 4. Create CNN Model ","9abbed9b":"**Read all datas then create x and y datas **","7f6f87fd":"I will plotting confusion matrix according to test datas. \n**0,1,2,3,4 values in this matrix means daisies, dandelions, roses, sunflowers, tuilps respectively**","23b16ec3":"I'll replace flower types for the computer to understand.","76e53f49":"let's see how the images look.","746f0faa":"# 3. Data Preparation","833256eb":"# 5. Train and Test the Model"}}