{"cell_type":{"8ea49134":"code","1b0b5fd8":"code","bfc2fe36":"code","66201f86":"code","728fafe5":"code","7ec676c0":"code","0be93df1":"code","94ace4c8":"code","0b16b08d":"code","d6bceb00":"code","57b479fa":"code","2c6583de":"code","ee07d275":"code","8203fb96":"code","959e44bd":"code","830726a3":"code","10e62ea6":"markdown","69fdad85":"markdown","8090894f":"markdown","5b655991":"markdown","7f471039":"markdown","0d0deecb":"markdown","8a4b540c":"markdown","e61bac3f":"markdown","b51b6e10":"markdown","a83db158":"markdown","f1d30097":"markdown","0f35b418":"markdown","035d4d86":"markdown","57df48f8":"markdown","69fe4e34":"markdown"},"source":{"8ea49134":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Import required functions\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n#Supress warnings\nimport warnings \nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","1b0b5fd8":"# Whole dataset on Iris Species\ndataset_w = pd.read_csv('..\/input\/Iris.csv')\n#Prints out the size of out dataset and also first 5 rows\nprint('Data shape: ', dataset_w.shape)\ndataset_w.head()","bfc2fe36":"#Examine the number of flowers in each category\ndataset_w['Species'].value_counts()","66201f86":"#Display the Species names\ndataset_w['Species'].unique()","728fafe5":"#Summary of Irist dataset\ndataset_w.describe()","7ec676c0":"columns=dataset_w.columns\nprint(columns)","0be93df1":"# box and whisker plots of 4 features\ndataset_w[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\nimport matplotlib\nmatplotlib.pyplot.show()","94ace4c8":"# histograms\ndataset_w[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].hist()\nmatplotlib.pyplot.show()","0b16b08d":"import seaborn as sns","d6bceb00":"# A seaborn jointplot shows bivariate scatterplots and univariate histograms in the same figure\nsns.jointplot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", data=dataset_w)","57b479fa":"sns.FacetGrid(dataset_w, hue=\"Species\", size=5) \\\n   .map(matplotlib.pyplot.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n   .add_legend()","2c6583de":"sns.FacetGrid(dataset_w, hue=\"Species\", size=5) \\\n   .map(matplotlib.pyplot.scatter, \"PetalLengthCm\", \"PetalWidthCm\") \\\n   .add_legend()","ee07d275":"sns.pairplot(dataset_w.drop(\"Id\", axis=1), hue=\"Species\", size=3)","8203fb96":"# Split data randomly into training and validation subsets\narray = dataset_w.values\nX = array[:,1:5]\nY = array[:,5]\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)","959e44bd":"# Training and cross-validation a selection of algorithms\nscoring=\"accuracy\"\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n kfold = model_selection.KFold(n_splits=10, random_state=seed)\n cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n results.append(cv_results)\n names.append(name)\n msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n print(msg)\n","830726a3":"# Make predictions on validation dataset\nsvc = SVC()\nsvc.fit(X_train, Y_train)\npredictions = svc.predict(X_validation)\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","10e62ea6":"The accuracy on the validation set is 0.933. From confusion matrix we can see that\n2 versicolor flowers were classified as virginica. ","69fdad85":"Imported really useful and neat library for data visualisation. [https:\/\/seaborn.pydata.org\/](http:\/\/)","8090894f":"We can see that Irist-setosa is separated from the other species","5b655991":"Turned out the best model was support vector machine. Please keep in mind that we used all default pararamters in our models.","7f471039":"Firstly, we will split the data into training and validation subsets. We will use the model_selection.train_test_split function from sklearn library. We reserved 80% of the data for training and 20% for validation. ","0d0deecb":"**Viola. We found out that we have a balanced dataset!!**","8a4b540c":"Let's now do some predictions of the Species based on the 4 features - petal and sepal attributes.","e61bac3f":"In the next step, we will use 10-fold cross-validation to evaluate accuracy of 6 different classification models.  We will choose the best model in terms of accuracy.","b51b6e10":"**Firstly let's do some exploratory analysis**","a83db158":"More separation with regards to Petal features.","f1d30097":"Please refer to sklearn documentaion for the default settings. For example, Logistic Regression classifier support multiclass and has L2 regularization. \nFor SVM: \nclass sklearn.svm.SVC(C=1.0, kernel=\u2019rbf\u2019, degree=3, gamma=\u2019auto\u2019, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=\u2019ovr\u2019, random_state=None)[source]","0f35b418":"Everything is neatly together!","035d4d86":"OK. Looks like we have 4 features describing species of Iris.  Let's investigate further. ","57df48f8":"Let's look at some graphs!","69fe4e34":"See above. We looked  what are the unique species names we have.  These are: Setosa, Versicolor and Virginica.\nLet's look at some stats."}}