{"cell_type":{"738b14be":"code","67ff9771":"code","603930e2":"code","8ce335f8":"code","fcf17f00":"code","dd1bd910":"code","ed3d489e":"code","48afb928":"code","af315949":"code","d004af57":"code","d789f282":"code","c58a49ab":"markdown","ef82499b":"markdown","1a09f0d4":"markdown","f69304bc":"markdown"},"source":{"738b14be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","67ff9771":"df_train = pd.read_csv('..\/input\/30-days-of-ml\/train.csv') # train-set\nX_test = pd.read_csv('..\/input\/30-days-of-ml\/test.csv') # test-set\nsubmission = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv')","603930e2":"df_train.info() # we can see object columns here","8ce335f8":"import pandas_profiling as pp\n\npp.ProfileReport(df_train)","fcf17f00":"X_train = df_train.copy().drop('target',axis = 1)\ny_train = df_train.target.copy()","dd1bd910":"# We will try to list the categorical data\ncat_col = list(X_train.select_dtypes([\"object\"]))\nprint (cat_col)","ed3d489e":"from sklearn.preprocessing import OrdinalEncoder\nord_encoder = OrdinalEncoder()\n\nX_train[cat_col] = ord_encoder.fit_transform(X_train[cat_col])\nX_test[cat_col] = ord_encoder.transform(X_test[cat_col])","48afb928":"X_train.head() # All are encoded\nX_test.head()","af315949":"# I am going to define cross_validation function\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBRegressor\n\n# Define Model\n\n# tweak learning rate and n_estimators as we learnt in course\nXGBoost_model = XGBRegressor(n_estimators = 2000,learning_rate = 0.03,random_state = 22, tree_method = 'gpu_hist', reg_alpha = 10)\n\n# Define K-Fold\nkfold_size =  KFold(n_splits = 10)  # this mean we are doing 10 experiment (Krish Nash Video haha)\ncross_validation_score = cross_val_score(XGBoost_model,X_train,y_train,cv = kfold_size , scoring = 'neg_root_mean_squared_error' )\nprint (cross_validation_score.mean() * (-1))","d004af57":"# model fitting\n\nXGBoost_model.fit(X_train,y_train)\npred = XGBoost_model.predict(X_test)\n\n# Submission\n\nsubmit = pd.DataFrame()\nsubmit[\"id\"] = X_test[\"id\"]\nsubmit[\"target\"] = pred\n\nsubmit.to_csv('submission.csv', index=False, header= submit.columns)","d789f282":"submit","c58a49ab":"# Encode all the categorical data","ef82499b":"# Model Training with XGBoost","1a09f0d4":"# Auto EDA","f69304bc":"# Data Preparation"}}