{"cell_type":{"1f2ffd91":"code","3cfad6b7":"code","ace8116d":"code","79133c4b":"code","52d912a3":"code","cb5e0c44":"code","65c2cefa":"code","f3fe6c03":"code","ad4392b8":"code","00162dd0":"code","120be129":"code","1c117cf5":"code","996df34e":"code","e300532e":"code","a527464a":"code","af7be2c7":"code","2d6e696f":"code","90811ab6":"code","4a625a6b":"code","124477c0":"code","61d6fe58":"code","c290b593":"code","a3ad2402":"code","154c1c8a":"code","7cd08a1c":"code","41028e9b":"code","24df05a5":"code","419606e1":"markdown","2157114f":"markdown","52ae9cbd":"markdown","497e55a4":"markdown","3e9b0204":"markdown","e445d52d":"markdown","2cd4eddb":"markdown","0e28a671":"markdown","0c8f2e83":"markdown","fc6e75dd":"markdown","4aca8bee":"markdown"},"source":{"1f2ffd91":"# importando as bibliotecas para EDA\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# ignorar warnings\nimport warnings\nwarnings.filterwarnings('ignore')","3cfad6b7":"# carregando os datasets\ndf_calendar = pd.read_csv('..\/input\/eda-airbnb-santiago-chile\/calendar.csv')\ndf_listings = pd.read_csv('..\/input\/eda-airbnb-santiago-chile\/listings.csv')\ndf_reviews = pd.read_csv('..\/input\/eda-airbnb-santiago-chile\/reviews.csv')","ace8116d":"# quantidade de linhas e colunas de cada dataset\nprint(df_calendar.shape)\nprint(df_listings.shape)\nprint(df_reviews.shape)","79133c4b":"df_listings.head()","52d912a3":"# An\u00e1lise geral dos dados\n\n#pd.set_option('display.max_columns', None) -> mostra todas as colunas sem truncar\n#pd.set_option('display.max_rows', None) -> mostra todas as linhas sem truncar\n\ndf_pivot = pd.DataFrame({'types': df_listings.dtypes,\n                         'nulls': df_listings.isna().sum(),\n                          '% nulls': df_listings.isna().sum() \/ df_listings.shape[0],\n                          'size': df_listings.shape[0],\n                          'uniques': df_listings.nunique()})\ndf_pivot","cb5e0c44":"# verificando quantidade de dados ausentes\ndf_listings['host_is_superhost'].isnull().sum()","65c2cefa":"# substituindo pelo valor mais frequente\ndf_listings['host_is_superhost'].fillna('f', inplace = True)\ndf_listings['host_is_superhost'].isnull().sum()","f3fe6c03":"# convertendo o dado categ\u00f3rico para num\u00e9rico\ndf_listings['host_is_superhost'].replace(['f','t'],[0,1],inplace=True)","ad4392b8":"# plotando o gr\u00e1fico de pizza e barra\nf,ax=plt.subplots(1,2,figsize=(18,8))\ndf_listings['host_is_superhost'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Super Host')\nax[0].set_ylabel('')\nsns.countplot('host_is_superhost',data=df_listings,ax=ax[1])\nax[1].set_title('Super Host')\nplt.show()","00162dd0":"# a coluna host_since n\u00e3o foi reconhecida com o tipo datetime, e sim como object\n# nesse caso, teremos que transform\u00e1-la para o tipo datetime antes de seguir com a an\u00e1lise.\ndf_listings['host_since'] = pd.to_datetime(df_listings['host_since'])\ndf_listings['host_since'].dtype","120be129":"mais_antigo = df_listings['host_since'].min()\nmais_novo = df_listings['host_since'].max()\nprint(f'O anfitri\u00e3o mais antigo se registrou em: {mais_antigo} no AirBnb')\nprint(f'O anfitri\u00e3o mais novo se registrou em: {mais_novo} no AirBnb') ","1c117cf5":"# gr\u00e1fico de bloxplot para avaliar a dispers\u00e3o da capacidade m\u00e1xima de h\u00f3spedes com rela\u00e7\u00e3o ao tipo de acomoda\u00e7\u00e3o\nplt.figure(figsize=(12,10))\nsns.boxplot(x = df_listings.room_type, y = df_listings.accommodates)\nplt.xlabel(\"Tipo de acomoda\u00e7\u00e3o\")\nplt.ylabel(\"Capacidade m\u00e1xima de h\u00f3spedes\")\nplt.show()","996df34e":"# chute inicial para verificar as features com potencial de correla\u00e7\u00e3o\ndf_listings.corr()['beds'].sort_values(ascending=False).head()","e300532e":"# criando um dataframe com somente algumas vari\u00e1veis num\u00e9ricas consideradas importantes para esta an\u00e1lise\nfeatures_correlacao = df_listings[['bedrooms','beds','accommodates', 'longitude', 'latitude']]\n\n# plotando a matrix de correla\u00e7\u00e3o somente com estas features\naxis = plt.subplots(figsize = (12,8))\nsns.heatmap(features_correlacao.corr(), annot=True, annot_kws = {\"size\":12})\nplt.show()","a527464a":"# exemplo de correla\u00e7\u00e3o fortemente positiva\nplt.xlabel('beds')\nplt.ylabel('accommodates')\nplt.scatter(df_listings['beds'], df_listings['accommodates'])\nplt.show()","af7be2c7":"sns.factorplot('accommodates','beds',data=df_listings,col='room_type')\nplt.show()","2d6e696f":"#!pip install folium\nimport folium\nfrom folium.plugins import MarkerCluster\n\nmapa = folium.Map(\n    width=1000, height=600,\n    location=[-33.4513,-70.6653], # mapa renderizado na latidude e longitude de Santiago, Chile.\n    tiles='Cartodb Positron',\n    zoom_start=5)\n\nmc = MarkerCluster()\n    \nfor index, df_listings in df_listings.iterrows():\n  mc.add_child(folium.Marker([df_listings['latitude'], df_listings['longitude']], \n              popup=str(df_listings['host_url']),\n              tooltip=df_listings['price'],\n              icon=folium.Icon(icon='book'))).add_to(mapa)\n  \nmapa","90811ab6":"# importando as bibliotecas para tratar e avaliar a frequ\u00eancia de palavras\nimport nltk\nimport re\nimport string\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator ","4a625a6b":"df_reviews.head()","124477c0":"# utilizaremos as informa\u00e7\u00f5es armazenadas na coluna comments\ndf_comments = df_reviews['comments'].loc[0:20000] # usando somente alguns registros para n\u00e3o prejudicar a performance\ndf_comments.shape","61d6fe58":"# removendo os dados ausentes\nprint(df_comments.isnull().sum())\ndf_comments = df_comments.dropna()\n\nprint(df_comments.isnull().sum())","c290b593":"# removendo todas as palavras com n\u00fameros e colocando as palavras em min\u00fasculo\nlower_alpha = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x.lower())\ndf_comments = df_comments.map(lower_alpha)\n\ndf_comments.head()","a3ad2402":"# removendo toda a pontua\u00e7\u00e3o\npunc_re = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\ndf_comments = df_comments.map(punc_re)\n\ndf_comments.head()","154c1c8a":"# tokeniza\u00e7\u00e3o dos coment\u00e1rios\nfrom nltk.tokenize import word_tokenize\n\ndf_comments = df_comments.map(word_tokenize)\ndf_comments.head()","7cd08a1c":"# removendo stop words dos coment\u00e1rios\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\n\nstop_words_en = stopwords.words('english')\nstop_words_pt = stopwords.words('portuguese')\nstop_words_sp = stopwords.words('spanish')\n\nstop_words_all = stop_words_en + stop_words_pt + stop_words_sp\nstop_words_all.append('br') # apareceu com bastante frequ\u00eancia e foi decidido retirar tamb\u00e9m\n\nstop_lambda = lambda x: [y for y in x if y not in stop_words_all]\ndf_comments = df_comments.apply(stop_lambda)\n\ndf_comments.head()","41028e9b":"from collections import Counter\n\n# converte a lista em um dicion\u00e1rio com contagem de valores\nword_list = sum(df_comments.tolist(), [])\nword_counts_clean = Counter(word_list)\na = word_counts_clean\n\n# inverta a chave \/ valores no dicion\u00e1rio para classificar\nword_counts_clean = list(zip(word_counts_clean.values(), word_counts_clean.keys()))\n\n# classifique a lista por contagem\nword_counts_clean = sorted(word_counts_clean, reverse=True)\n\n# imprime as 10 palavras mais comuns\nword_counts_clean[:10]","24df05a5":"wordcloud_comments = WordCloud(width=1600, \n                      height=800, \n                      max_font_size=200,\n                      max_words=400\n                      ).fit_words(a)\n\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud_comments, interpolation='bilinear')\nplt.axis(\"off\")\nplt.savefig(\"comments_reviews_santiago.png\")\nplt.show()","419606e1":"#### Localiza\u00e7\u00e3o das acomoda\u00e7\u00f5es no mapa. \u00c9 poss\u00edvel identificar a regi\u00e3o, pre\u00e7o da di\u00e1ria e o link do airbnb para avaliar no detalhe a acomoda\u00e7\u00e3o. ","2157114f":"#### Vamos analisar quantos destes usu\u00e1rios s\u00e3o considerados SuperHost no airbnb.  \n#### Os anfitri\u00f5es de mais alto desempenho s\u00e3o chamados de Superhosts. Seus an\u00fancios t\u00eam um selo especial que permite que todos saibam que s\u00e3o incr\u00edveis.","52ae9cbd":"#### Vamos agora analisar se existe algum tipo de correla\u00e7\u00e3o entre as vari\u00e1veis","497e55a4":"#### Verificando a data do primeiro e \u00faltimo registro da lista de anfitri\u00f5es na plataforma AirBnb","3e9b0204":"## Trabalho pr\u00e1tico de EDA  \n\n\u2022 Escolher uma das cidades e realizar an\u00e1lise explorat\u00f3ria de dados do [AirBnb](http:\/\/insideairbnb.com\/get-the-data.html)   \n\u2022 Usar os conjuntos de dados completos para a an\u00e1lise:  \u2013 Listings.csv.gz, calendar.csv.gz, reviews.csv.gz  \n\u2022 N\u00e3o h\u00e1 um objetivo de aprendizado supervisionado  \n\u2022 Exercitar os diversos m\u00e9todos de visualiza\u00e7\u00e3o apresentados nessa aula   \n\u2022 Revis\u00e3o em pares: cada participante vai revisar o trabalho de ao menos dois outros colegas   \n\u2022 Utilizar a plataforma Kaggle   \n\u2022 Pesquisar sintaxe no Stackoverflow \/ Google :-)  ","e445d52d":"#### \u00c9 poss\u00edvel identificar que as acomoda\u00e7\u00f5es que disponibilizam a casa\/apartamento por inteiro possuem um limite maior na capacidade de h\u00f3spedes.","2cd4eddb":"#### Percebe-se que as vari\u00e1veis accommodates e beds possuem uma correla\u00e7\u00e3o fortemente positiva ~0.82","0e28a671":"#### Aplica\u00e7\u00e3o da Tokeniza\u00e7\u00e3o e StopWords","0c8f2e83":"#### Pouco mais de 16% dos anfitri\u00f5es s\u00e3o classificados como SuperHosts","fc6e75dd":"## (Parte 2) A partir daqui iremos construir uma nuvem de palavras (wordcloud) das reviews realizadas pelos h\u00f3spedes. Vamos utilizar as t\u00e9cnicas de tokeniza\u00e7\u00e3o e stopwords.","4aca8bee":"## (Parte 1) Vamos iniciar explorando a lista de anfitri\u00f5es e acomoda\u00e7\u00f5es dispon\u00edveis para loca\u00e7\u00e3o"}}