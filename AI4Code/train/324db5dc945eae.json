{"cell_type":{"1b0e45fc":"code","511818be":"code","8dd97ec1":"code","00088e2b":"code","4ebf017e":"code","88aa2ba2":"code","78ef7fa9":"markdown"},"source":{"1b0e45fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nfrom datetime import datetime\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set seed for reproducibility. I chose '1337' for good luck. See details about 1337-speak on KnowYourMeme.\n\nmyseed = 42\nnp.random.seed(myseed)","511818be":"# Load in data\ntrain = pd.read_csv('..\/input\/mldub-comp1\/train_data.csv')\ntest = pd.read_csv('..\/input\/mldub-comp1\/test_data.csv')\nsample_sub = pd.read_csv('\/kaggle\/input\/mldub-comp1\/sample_sub.csv')","8dd97ec1":"# Join training and testing features\ntrain_features = train.drop(['target_variable'], axis=1)\ntest_features = test\nfeatures = pd.concat([train_features, test_features]).reset_index(drop=True)","00088e2b":"# Create features from tags\nfrom sklearn.feature_extraction.text import CountVectorizer\ncorpus = features['tags'].astype('U').values\n\nvectorizer = CountVectorizer(min_df = 0.05) # Setting a minumum % of \"documents\" to contain each \"tag\"\ntags = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names())\n\ntags = pd.DataFrame(tags.toarray(),index=features.index)\ntags.columns = vectorizer.get_feature_names()\ntags = tags.add_prefix('tags_')\n# tags","4ebf017e":"# Add tags to our dataframe with features\nfeatures = pd.concat([features, tags], ignore_index=False, axis=1, sort=False).reset_index(drop=True)","88aa2ba2":"# Enjoy new features\nquantitative = [f for f in features.columns if features.dtypes[f] != 'object']\nqualitative = [f for f in features.columns if features.dtypes[f] == 'object']\nprint(\"quantitative \\n\", quantitative)\nprint(\"qualitative \\n\", qualitative)","78ef7fa9":"### With this kernel you can see how to extract the most popular tags from the `tags` variable.\n\nYou are welcome :) "}}