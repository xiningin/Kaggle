{"cell_type":{"f9ff7581":"code","d076e0db":"code","890a2c8a":"code","30c7d34a":"code","20db110a":"code","5ffa99ed":"code","0372d052":"code","2dda1f4b":"code","f70af341":"code","365a179e":"code","78fadc77":"code","34dc2850":"code","45cf12f3":"code","2633683a":"code","f9be2e63":"code","a4f1dec0":"code","8be289d4":"code","33cdf700":"code","361655b1":"code","4fc2669f":"code","62be8557":"code","c46da8dd":"markdown","204175fa":"markdown","ac3689c2":"markdown","8a425919":"markdown","03715b1d":"markdown","da567972":"markdown","3da2e9a5":"markdown","3c5c134b":"markdown","90c117fe":"markdown","d33c23a8":"markdown","85b8e099":"markdown","05bb98b8":"markdown","39b697ab":"markdown","ca8834bf":"markdown","279436ba":"markdown","ddd47ddb":"markdown","ae5f50d0":"markdown","7550dc4a":"markdown","f2a5cca7":"markdown"},"source":{"f9ff7581":"import numpy as np\nimport pandas as pd\nimport os \nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization\nfrom keras.applications import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import plot_model\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom keras.regularizers import l2\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport pathlib\nimport random","d076e0db":"dataset_path = pathlib.Path('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset')\nTest_path = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\nTrain_path = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\nVal_path = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'\n\nimages=os.listdir(Train_path)\nimages","890a2c8a":"Mask_img =  mpimg.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\/272.png')\nplt.imshow(Mask_img)\nplt.title(\"person with mask\")","30c7d34a":"Mask_img =  mpimg.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithoutMask\/14.png')\nplt.imshow(Mask_img)\nplt.title(\"person without mask\")","20db110a":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   rotation_range=0.2)\n\nval_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)  #Image normalization.\n\ntraining_set = train_datagen.flow_from_directory(Train_path,\n                                                 target_size = (128, 128),\n                                                 interpolation=\"nearest\",\n                                                 class_mode='binary',\n                                                 classes=[\"WithoutMask\",\"WithMask\"])\n\nvalidation_set = val_datagen.flow_from_directory(Val_path,\n                                                 target_size=(128, 128),\n                                                 interpolation=\"nearest\",\n                                                 class_mode='binary',\n                                                 classes=[\"WithoutMask\",\"WithMask\"])\n\ntest_set = test_datagen.flow_from_directory(Test_path,\n                                            target_size = (128, 128),\n                                            interpolation=\"nearest\",\n                                            class_mode='binary',\n                                            classes=[\"WithoutMask\",\"WithMask\"])\n\n#interpolation=\"nearest\",\n#classes=[\"without_mask\",\"with_mask\"]","5ffa99ed":"def GetXY(gen):\n    listX = []\n    listY = []\n    for i in range(gen.__len__()):\n        gennext = gen.next()\n        listX.append(gennext[0])\n        listY.append(gennext[1])\n    x=np.concatenate(listX)\n    y=np.concatenate(listY)\n    return (x,y)","0372d052":"trainX,trainY = GetXY(training_set)\nvalX,valY = GetXY(validation_set)\ntestX,testY = GetXY(test_set)","2dda1f4b":"input_data = Input(shape=(128, 128, 3))\n\n#Convolution\nx = Conv2D(32, (3, 3), activation=\"relu\")(input_data)\n\n#Pooling\nx = MaxPooling2D(pool_size = (4, 4), strides=(4, 4))(x)\n\n#Dropout\nx = Dropout(0.25)(x)\n\n# 2nd Convolution\nx = Conv2D(32, (3, 3), activation=\"relu\")(x)\n\n# 2nd Pooling layer\nx = MaxPooling2D(pool_size = (2, 2))(x)\n\n#Dropout\nx = Dropout(0.3)(x)\n\n#3rd Convolution\nx = Conv2D(32, (3, 3), activation='relu')(x)\n\n#3rd Pooling Layer\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n#Dropout\nx = Dropout(0.3)(x)\n\n# Flatten the layer\nx = Flatten()(x)\n\n# Fully Connected Layers\nx = Dense(128, activation = 'relu')(x)\noutput = Dense(1, activation = 'sigmoid')(x)\n\ncnn = Model(inputs=input_data, outputs=output)\n\n# Compile the Neural network\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","f70af341":"cnn.summary()","365a179e":"callbacks = [ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=0.00001)]\nhistory = cnn.fit(trainX, trainY,\n                         epochs = 15,\n                         verbose = 1,\n                         batch_size=32,\n                         validation_data = (valX, valY),\n                         callbacks=callbacks)","78fadc77":"cnn.evaluate(testX, testY, verbose=2)\npredict = (cnn.predict(testX) > 0.5).astype(\"int32\")\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","34dc2850":"print('Accuracy:', accuracy_score(testY, predict))","45cf12f3":"plt.figure(figsize=(20,20))\nfor i in range(0, 20):\n    plt.subplot(6, 10, i+1)\n    number = np.random.randint(testX[testY == predict.ravel()].shape[0])\n    plt.imshow(testX[testY == predict.ravel()][number])\n    plt.axis(\"off\")\nplt.subplots_adjust(wspace=-0.5, hspace=1)\nplt.show()","2633683a":"plt.figure(figsize=(20,20))\nfor i in range(0, 20):\n    plt.subplot(6, 10, i+1)\n    number = np.random.randint(testX[testY != predict.ravel()].shape[0])\n    plt.imshow(testX[testY != predict.ravel()][number])\n    plt.axis(\"off\")\nplt.subplots_adjust(wspace=-0.5, hspace=1)\nplt.show()","f9be2e63":"def build_model(resnet):\n    input_data = Input(shape=(128, 128, 3))\n    x = resnet(input_data)\n    x = GlobalMaxPooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(128,activation='relu')(x) \n    output = Dense(1, activation='sigmoid')(x)\n    \n    resnet_model = Model(inputs=input_data, outputs=output)\n    \n    resnet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return resnet_model","a4f1dec0":"#weights_path = \"..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nresnet = ResNet50(weights='imagenet', \n                      include_top=False, \n                      input_shape = (128, 128, 3))\nresnet.trainable = False\nmodel = build_model(resnet)\nmodel.summary()","8be289d4":"callbacks = [ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=0.00001)]\nhistory = model.fit(trainX, trainY,\n                         epochs = 15,\n                         verbose = 1,\n                         batch_size=32,\n                         validation_data = (valX, valY),\n                         callbacks=callbacks)","33cdf700":"model.evaluate(testX, testY, verbose=2)\npredict = (model.predict(testX) > 0.5).astype(\"int32\")\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","361655b1":"print('Accuracy:', accuracy_score(testY, predict))","4fc2669f":"plt.figure(figsize=(20,20))\nfor i in range(0, 20):\n    plt.subplot(6, 10, i+1)\n    number = np.random.randint(testX[testY == predict.ravel()].shape[0])\n    plt.imshow(testX[testY == predict.ravel()][number])\n    plt.axis(\"off\")\nplt.subplots_adjust(wspace=-0.5, hspace=1)\nplt.show()","62be8557":"plt.figure(figsize=(20,20))\nfor i in range(0, 20):\n    plt.subplot(6, 10, i+1)\n    number = np.random.randint(testX[testY != predict.ravel()].shape[0])\n    plt.imshow(testX[testY != predict.ravel()][number])\n    plt.axis(\"off\")\nplt.subplots_adjust(wspace=-0.5, hspace=1)\nplt.show()","c46da8dd":"Evaluating the model, getting report","204175fa":"Bulding CNN and ResNet50 for Face Mask Detection","ac3689c2":"Preparing image data, splitting into train, cross validation, test sets ","8a425919":"Incorrectly predicted images:","03715b1d":"Evaluating the model, getting report","da567972":"Setting CNN","3da2e9a5":"Importing libraries","3c5c134b":"## Model: ResNet50 (Residual neural network)","90c117fe":"\u0421orrectly predicted images:","d33c23a8":"Incorrectly predicted images:","85b8e099":"Showing image with mask","05bb98b8":"Training the model","39b697ab":"\u0421orrectly predicted images:","ca8834bf":"Transforming to numpy array and getting labeled array","279436ba":"Setting model","ddd47ddb":"Showing image without mask","ae5f50d0":"# Face Mask Detection (CNN, ResNet50)","7550dc4a":"Training the model","f2a5cca7":"## CNN"}}