{"cell_type":{"349cb8ce":"code","991e19c6":"code","2faaf3b9":"code","c7e33e01":"code","41a85b41":"code","17dba1c4":"code","8099cc32":"code","b9212669":"code","b39d0f6a":"code","27609aa5":"code","b214f6cb":"code","4ccf7a33":"code","5d04793d":"code","0ce69191":"code","2dc9371c":"code","579343a0":"code","6b2646d0":"code","7914801d":"code","d3e1d092":"code","e0ef43f0":"code","2bb8d512":"code","27110f12":"code","fcb2b4ad":"code","4f12dd44":"code","42902804":"code","82630320":"code","3768b91b":"code","972ddc51":"code","16b1f683":"code","29af8411":"code","c6eca46a":"code","f8e14347":"code","1e9829da":"code","237e07fd":"code","7a23388a":"code","3741ead8":"code","2738b486":"code","adc981d0":"code","2d22be56":"code","5837aaf1":"code","42ce27ca":"code","e7c91749":"code","a543b781":"code","f3db3a10":"code","1d812177":"code","aab4a428":"code","32f44fe8":"code","a7d0a636":"code","7022ce1a":"code","ae947822":"code","2f28d9ff":"code","b54669f8":"code","ffe577d2":"code","e9f3e485":"code","32d1e71e":"markdown","70dd3d37":"markdown","200ff5c1":"markdown","26c4df44":"markdown","6788d8dc":"markdown","b05dff7b":"markdown","f724d484":"markdown","8aaa1698":"markdown","57314bb7":"markdown","1da96ba8":"markdown","bd1a06e7":"markdown","5586f1cf":"markdown","6f87ce57":"markdown","6df4708a":"markdown","7f9714b0":"markdown","bf49f17b":"markdown","4fc6fadd":"markdown","a88a1e4a":"markdown","a4d1d71d":"markdown","eb039042":"markdown","b1dbe789":"markdown","fbea8ad0":"markdown","9c9dbf5e":"markdown","10b76c77":"markdown","9779b315":"markdown","cd932b9b":"markdown","db75120f":"markdown","69162e1e":"markdown","bd48647a":"markdown","0812258a":"markdown","9b45557e":"markdown","25fe2fbc":"markdown","11429802":"markdown","a8457a89":"markdown","e1296c60":"markdown","2463e2f9":"markdown","54ce189c":"markdown","d3dfce98":"markdown","b54d14ef":"markdown","59f0fc56":"markdown","2cd7d9b7":"markdown","148d2cb2":"markdown","4f149877":"markdown","9a301547":"markdown"},"source":{"349cb8ce":"#import the Libraries\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport random\nimport h5py\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","991e19c6":"os.listdir('..\/input\/trends-assessment-prediction\/')","2faaf3b9":"features = pd.read_csv('..\/input\/trends-assessment-prediction\/train_scores.csv')\nloading = pd.read_csv('..\/input\/trends-assessment-prediction\/loading.csv')\nsubmission = pd.read_csv('..\/input\/trends-assessment-prediction\/sample_submission.csv')\nfnc = pd.read_csv('..\/input\/trends-assessment-prediction\/fnc.csv')\nreveal = pd.read_csv('..\/input\/trends-assessment-prediction\/reveal_ID_site2.csv')\nnumbers = pd.read_csv('..\/input\/trends-assessment-prediction\/ICN_numbers.csv')\nfmri_mask = '..\/input\/trends-assessment-prediction\/fMRI_mask.nii'","c7e33e01":"# Installing the nilearn\n!wget https:\/\/github.com\/Chaogan-Yan\/DPABI\/raw\/master\/Templates\/ch2better.nii","41a85b41":"import nilearn as nl\nimport nilearn.plotting as nlplt\nimport nibabel as nib\nfrom nilearn import image\nfrom nilearn import plotting\nfrom nilearn import datasets\nfrom nilearn import surface","17dba1c4":"smri = 'ch2better.nii'\nmask_img = nl.image.load_img(fmri_mask)\n\ndef load_subject(filename, mask_img):\n    subject_data = None\n    with h5py.File(filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_img = nl.image.new_img_like(mask_img, subject_data, affine=mask_img.affine, copy_header=True)\n\n    return subject_img","8099cc32":"files = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    nlplt.plot_prob_atlas(subject_img, bg_img=smri, view_type='filled_contours',\n                          draw_cross=False, title='All %d spatial maps' % num_components, threshold='auto')\n    print(\"-\"*50)","b9212669":"files = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)\n    plotting.plot_stat_map(first_rsn)\n    print(\"-\"*50)","b39d0f6a":"files = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)\n    for img in image.iter_img(rsn):\n        # img is now an in-memory 3D img\n        plotting.plot_stat_map(img, threshold=3)\n    print(\"-\"*50)","27609aa5":"files = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)     \n    plotting.plot_glass_brain(first_rsn,display_mode='lyrz')\n    print(\"-\"*50)","b214f6cb":"files = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)\n    plotting.plot_epi(first_rsn)\n    print(\"-\"*50)","4ccf7a33":"files = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)\n    plotting.plot_anat(first_rsn)\n    print(\"-\"*50)","5d04793d":"files = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)\n    plotting.plot_roi(first_rsn)\n    print(\"-\"*50)","0ce69191":"motor_images = datasets.fetch_neurovault_motor_task()\nstat_img = motor_images.images[0]\nview = plotting.view_img_on_surf(stat_img, threshold='90%')\nview.open_in_browser()\nview","2dc9371c":"features.head()","579343a0":"features.info()","6b2646d0":"from sklearn.impute import KNNImputer\nimpute = KNNImputer(n_neighbors=40)\nfeatures = impute.fit_transform(features)","7914801d":"features = pd.DataFrame(features,columns = ['Id','age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2'])","d3e1d092":"features","e0ef43f0":"loading.head()","2bb8d512":"loading.info()","27110f12":"fnc.head()","fcb2b4ad":"fnc.info()","4f12dd44":"reveal.head()","42902804":"reveal.info()","82630320":"numbers.head()","3768b91b":"numbers.info()","972ddc51":"sns.heatmap(features.corr(),annot=True,linewidths=0.2) \nfig=plt.gcf()\nfig.set_size_inches(20,12)\nplt.show()","16b1f683":"sns.heatmap(loading.corr(),annot=True,linewidths=0.2) \nfig=plt.gcf()\nfig.set_size_inches(20,12)\nplt.show()","29af8411":"#main or, target element in problem\ntarget_col = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']","c6eca46a":"fig, ax = plt.subplots(1, 5, figsize=(20, 5))\nsns.distplot(features['age'], ax=ax[0],rug=True, rug_kws={\"color\": \"coral\"},\n                  kde_kws={\"color\": \"royalblue\", \"lw\": 1.5},\n                  hist_kws={\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"coral\"}).set_title('Age')\n\nsns.distplot(features['domain1_var1'], ax=ax[1],rug=True, rug_kws={\"color\": \"coral\"},\n                  kde_kws={\"color\": \"royalblue\", \"lw\": 1.5},\n                  hist_kws={\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"coral\"}).set_title('domain1_var1')\n\nsns.distplot(features['domain1_var2'], ax=ax[2],rug=True, rug_kws={\"color\": \"coral\"},\n                  kde_kws={\"color\": \"royalblue\", \"lw\": 1.5},\n                  hist_kws={\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"coral\"}).set_title('domain1_var2')\n\nsns.distplot(features['domain2_var1'], ax=ax[3],rug=True, rug_kws={\"color\": \"coral\"},\n                  kde_kws={\"color\": \"royalblue\", \"lw\": 1.5},\n                  hist_kws={\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"coral\"}).set_title('domain2_var1')\n\nsns.distplot(features['domain2_var2'], ax=ax[4],rug=True, rug_kws={\"color\": \"coral\"},\n                  kde_kws={\"color\": \"royalblue\", \"lw\": 1.5},\n                  hist_kws={\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"coral\"}).set_title('domain2_var2')\n\nfig.suptitle('Target Visualization', fontsize=10)","f8e14347":"train = features.merge(loading, on='Id', how='left')\ntrain = train.merge(fnc, on='Id', how='left')\ntrain.head()","1e9829da":"X = train.drop(target_col, axis=1)\nX.head()","237e07fd":"X","7a23388a":"y = features\ny.head()","3741ead8":"y","2738b486":"y.info()","adc981d0":"submission['ID_num'] = submission['Id'].apply(lambda x: int(x.split('_')[0]))\ntest = pd.DataFrame({'Id': submission['ID_num'].unique()})\ndel submission['ID_num'];\ntest.head()","2d22be56":"test = test.merge(loading, on='Id', how='left')\ntest = test.merge(fnc, on='Id', how='left')\ntest.head()","5837aaf1":"test","42ce27ca":"test.info()","e7c91749":"import autokeras as ak\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.model_selection import KFold,cross_val_score\nfrom tensorflow.keras.layers import Dropout\nfrom keras.callbacks import History, ModelCheckpoint, EarlyStopping\n\nregressor  = ak.StructuredDataRegressor(max_trials=100,loss='mean_absolute_error',metrics='accuracy', seed=42,output_dim=5)\nregressor.fit(x=X.iloc[:,1:], y=y.iloc[:,1:],validation_split=0.25,\n                               callbacks=[History(),\n                               EarlyStopping(monitor='val_loss', \n                               patience=30, \n                               restore_best_weights=True, \n                               verbose=1)])\n","a543b781":"from tensorflow.keras.models import load_model,save_model\nmodel = regressor.export_model()\nprint(type(model))\nfrom tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes=True, expand_nested=True)","f3db3a10":"import tensorflow as tf\ntf.keras.models.save_model(model,'C:\/OpenClassRooms\/projet 8\/',include_optimizer=True,save_format='tf',)","1d812177":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.model_selection import KFold,cross_val_score\nfrom tensorflow.keras.layers import Dropout\nfrom keras.callbacks import History, ModelCheckpoint, EarlyStopping\n\nmodel = Sequential()\nmodel.add(Dense(1404,input_dim=1404,kernel_initializer='normal',activation='relu'))\nmodel.add(Dense(702,kernel_initializer='normal',activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(702,kernel_initializer='normal',activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(702,kernel_initializer='normal',activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,kernel_initializer='normal'))\n\nmodel.compile(loss='mean_absolute_error',optimizer='adam', metrics = ['accuracy'])\n\nmodel.summary()","aab4a428":"loaded_model = load_model('C:\/OpenClassRooms\/projet 8', custom_objects=ak.CUSTOM_OBJECTS)","32f44fe8":"history=model.fit(X.iloc[:,1:],y.iloc[:,1:],epochs=1000,batch_size=32,validation_split=0.25,verbose=2,\n                  callbacks=[History(),\n                             EarlyStopping(monitor='val_loss', \n                             patience=30, \n                             restore_best_weights=True, \n                             verbose=1)])","a7d0a636":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","7022ce1a":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplt.plot(epochs, acc, 'y', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","ae947822":"prediction = regressor.predict(test.iloc[:,1:])\nprediction = pd.DataFrame(prediction)\nprediction.columns = y.iloc[:,1:].columns\nprediction.head(10)","2f28d9ff":"pred = pd.DataFrame()\n\nfor target in target_col:\n    value = pd.DataFrame()\n    value['Id'] = [f'{c}_{target}' for c in test['Id'].values]\n    value['Predicted'] = prediction[target]\n    pred = pd.concat([pred, value])\n\npred.head()","b54669f8":"submission","ffe577d2":"submission = pd.merge(submission, pred, on = 'Id')\nsubmission = submission[['Id', 'Predicted_y']]\nsubmission.columns = ['Id', 'Predicted']\nsubmission.to_csv('submission_deeplearning_knnimputer.csv', index=False)\nsubmission.head()\n","e9f3e485":"submission['Predicted'].hist()","32d1e71e":"# End Note...\n\nThis notebook is work in progress.And I try my level best to explain each and every thing as I learn in this competition. And I try to update this kernal as i learn new thing in this. \n\n\n## <span style=\"color:blue\"> I hope you find this kernel useful and enjoyable, If so Please upvote it. And Your comments and feedback are most welcome. ;-)<\/span>\n\n#### <span style=\"color:red\">STAY TUNED!<\/span>","70dd3d37":"## Visualize the Target Columns...","200ff5c1":"## Let understand the Problem statment!!!","26c4df44":"## References\n\n* Convolutional Neural Networks with Intermediate Loss for 3D Super-Resolution of CT and MRI Scans: [click here](https:\/\/arxiv.org\/pdf\/2001.01330)\n* Multi-Resolution 3D CNN for MRI Brain Tumor Segmentation and Survival Prediction: [click here](https:\/\/arxiv.org\/abs\/1911.08388)\n* Automatic Post-Stroke Lesion Segmentation on MR Images using 3D Residual Convolutional Neural Network: [click here](https:\/\/arxiv.org\/pdf\/1911.11209)\n* You can also check out the previuos competition occur on kaggle regard to this. [click here](https:\/\/www.kaggle.com\/c\/mlsp-2014-mri\/overview)\n* You can plot brain visualization using nilearn: [click here](https:\/\/nilearn.github.io\/plotting\/index.html)\n* Check out the various library in python for visulization of Brain MRI.[click here](https:\/\/www.kaggle.com\/c\/trends-assessment-prediction\/discussion\/148175)\n* Thanks to soham for their great kernal help and giving Idea of visualization. [click here](https:\/\/www.kaggle.com\/soham1024\/visualization-using-nilearn)","6788d8dc":"Interpreting The Heatmap The first thing to note is that only the numeric features are compared as it is obvious that we cannot correlate between alphabets or strings. Before understanding the plot, let us see what exactly correlation is.\n\nPOSITIVE CORRELATION: If an increase in feature A leads to increase in feature B, then they are positively correlated. A value 1 means perfect positive correlation.\n\nNEGATIVE CORRELATION: If an increase in feature A leads to decrease in feature B, then they are negatively correlated. A value -1 means perfect negative correlation.\n\nNow lets say that two features are highly or perfectly correlated, so the increase in one leads to increase in the other. This means that both the features are containing highly similar information and there is very little or no variance in information. This is known as MultiColinearity as both of them contains almost the same information.\n\nSo do you think we should use both of them as one of them is redundant. While making or training models, we should try to eliminate redundant features as it reduces training time and many such advantages.","b05dff7b":"## Preparing the test data...","f724d484":"## Plotting a statistical map...\n\nStatistical parametric mapping or SPM is a statistical technique for examining differences in brain activity recorded during functional neuroimaging experiments.The measurement technique depends on the imaging technology (e.g., fMRI and PET). The scanner produces a 'map' of the area that is represented as voxels. Each voxel represents the activity of a specific volume in three-dimensional space. The exact size of a voxel varies depending on the technology. fMRI voxels typically represent a volume of 27 mm3 (a cube with 3mm length sides).\n\nParametric statistical models are assumed at each voxel, using the general linear model to describe the data variability in terms of experimental and confounding effects, with residual variability. Hypotheses expressed in terms of the model parameters are assessed at each voxel with univariate statistics.\n\nAnalyses may examine differences over time (i.e. correlations between a task variable and brain activity in a certain area) using linear convolution models of how the measured signal is caused by underlying changes in neural activity.\n\nBecause many statistical tests are conducted, adjustments have to be made to control for type I errors (false positives) potentially caused by the comparison of levels of activity over many voxels. A type I error would result in falsely assessing background brain activity as related to the task. Adjustments are made based on the number of resels in the image and the theory of continuous random fields in order to set a new criterion for statistical significance that adjusts for the problem of multiple comparisons.","8aaa1698":"## Prepare the Train dataset...","57314bb7":"### Taking any 3 random images and visualize the plot.","1da96ba8":"from trains import Task\nimport autokeras as ak\nfrom keras.callbacks import callbacks\nfrom tensorflow import keras\n\ntask = Task.init(project_name=\"autokeras\", task_name=\"autokeras TreNds kaggle competition\",output_uri=\"http:\/\/localhost:8081\/\")\n\ntensorboard_callback_train = keras.callbacks.TensorBoard(log_dir='log')","bd1a06e7":"## Creating the Models...","5586f1cf":"## 3D Plots of statistical maps or atlases on the cortical surface...","6f87ce57":"## Let understand the Dataset.\n\n* fMRI_train - a folder containing 53 3D spatial maps for train samples in [.mat] format.\n* fMRI_test - a folder containing 53 3D spatial maps for test samples in [.mat] format.\n* fnc.csv - static FNC correlation features for both train and test samples.\n* loading.csv - sMRI SBM loadings for both train and test samples.\n* train_scores.csv - age and assessment values for train samples.\n* reveal_ID_site2.csv - a list of subject IDs whose data was collected with a different scanner than the train samples.\n* fMRI_mask.nii - a 3D binary spatial map.\n* ICN_numbers.txt - intrinsic connectivity network numbers for each fMRI spatial map; matches FNC names.\n\n[Note] - The [.mat] files in this can be read in python using h5py,and the [.nii] file can be read in python using nilearn.","6df4708a":"## About this notebook...\n\nA\/c to me, this is one of the best competition on kaggle. It give you a chance to learn some cool new things on kaggle and broad you knowledge in Datascience.\n\nAs already written in Introduction, Human brain research is among the most complex areas of study for scientists. We know that age and other factors can affect its function and structure, but more research is needed into what specifically occurs within the brain. With much of the research using MRI scans, data scientists are well positioned to support future insights. In particular, neuroimaging specialists look for measurable markers of behavior, health, or disorder to help identify relevant brain regions and their contribution to typical or symptomatic effects.\n\nI try my level best to give all things as simple as possible.","7f9714b0":"## Creating the Models with CNN and Auto Keras... DEPRECATED","bf49f17b":"## Glass brain visualization...\n\nGlass Brain is a tool that maps the electrical activity of your brain in realtime.The anatomically realistic 3D brain will show realtime data from electroencephalographic (EEG) signals taken from a specially-designed EEG cap.This data is mapped to the source of that electrical activity, i.e. the specific part of the brain. The underlying brain model is generated through MRI scans so that the EEG data is accurately mapped to an individual's brain model.\n\nDifferent colours are given to the different signal frequency bands to create a beautiful interactive artwork that seems to crackle with energy, showing how information is transferred (or at least estimated to do so) between different regions of the brain.","4fc6fadd":"## Let Create the Submission...","a88a1e4a":"### There lot more in visualization,and I try to explain all possible visualization in a simple way. you can also check out the above links for more details.","a4d1d71d":"## Plotting an EPI...\n\nIn Echo-Planar Imaging (EPI)-based Magnetic Resonance Imaging (MRI), inter-subject registration typically uses the subject's T1-weighted (T1w) anatomical image to learn deformations of the subject's brain onto a template. The estimated deformation fields are then applied to the subject's EPI scans (functional or diffusion-weighted images) to warp the latter to a template space.\n\nFor further details you visit.[click here](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC5819565\/)","eb039042":"#from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nimp_mean = IterativeImputer(random_state=0,max_iter=100)\nfeatures = imp_mean.fit_transform(features)","b1dbe789":"#### I strongly recommend to change the plot from \"Inflated\" to \"Pial\" for analyze the 3D view of Brain.","fbea8ad0":"import autokeras\nprint(dir(autokeras))","9c9dbf5e":"features.fillna(features.mean(),inplace=True)","10b76c77":"## How Features Were Obtained\n\nAn unbiased strategy was utilized to obtain the provided features. This means that a separate, unrelated large imaging dataset was utilized to learn feature templates. Then, these templates were \"projected\" onto the original imaging data of each subject used for this competition using spatially constrained independent component analysis (scICA) via group information guided ICA (GIG-ICA).\n\nThe first set of features are source-based morphometry (SBM) loadings. These are subject-level weights from a group-level ICA decomposition of gray matter concentration maps from structural MRI (sMRI) scans.\n\nThe second set are static functional network connectivity (FNC) matrices. These are the subject-level cross-correlation values among 53 component timecourses estimated from GIG-ICA of resting state functional MRI (fMRI).\n\nThe third set of features are the component spatial maps (SM). These are the subject-level 3D images of 53 spatial networks estimated from GIG-ICA of resting state functional MRI (fMRI).","9779b315":"# What next...\n\n* Try to improve the model performance.\n    * Try to use pre-trained model.\n    * may also try some machine learning model.\n    * Try Gridsearchcv\n    * use ensembales of models.\n    * use of ensembales weights of correlations.  \n* More explanition through visualization.\n* And What all I  learn in this competition.","cd932b9b":"## Plotting a statistical map...\n\nStatistical parametric mapping or SPM is a statistical technique for examining differences in brain activity recorded during functional neuroimaging experiments.The measurement technique depends on the imaging technology (e.g., fMRI and PET). The scanner produces a 'map' of the area that is represented as voxels. Each voxel represents the activity of a specific volume in three-dimensional space. The exact size of a voxel varies depending on the technology. fMRI voxels typically represent a volume of 27 mm3 (a cube with 3mm length sides).\n\nParametric statistical models are assumed at each voxel, using the general linear model to describe the data variability in terms of experimental and confounding effects, with residual variability. Hypotheses expressed in terms of the model parameters are assessed at each voxel with univariate statistics.\n\nAnalyses may examine differences over time (i.e. correlations between a task variable and brain activity in a certain area) using linear convolution models of how the measured signal is caused by underlying changes in neural activity.\n\nBecause many statistical tests are conducted, adjustments have to be made to control for type I errors (false positives) potentially caused by the comparison of levels of activity over many voxels. A type I error would result in falsely assessing background brain activity as related to the task. Adjustments are made based on the number of resels in the image and the theory of continuous random fields in order to set a new criterion for statistical significance that adjusts for the problem of multiple comparisons.","db75120f":"### Handling the missing Value...\n\nHandling missing values is an essential part of data cleaning and preparation process because almost all data in real life comes with some missing values.\n\nMissing values need to be handled because they reduce the quality for any of our performance metric. It can also lead to wrong prediction or classification and can also cause a high bias for any given model being used.\n\n### WHAT DO WE DO TO MISSING VALUES?\nThere are several options for handling missing values each with its own PROS and CONS. However, the choice of what should be done is largely dependent on the nature of our data and the missing values. Below is a summary highlight of several options we have for handling missing values.\n\n* DROP MISSING VALUES\n* FILL MISSING VALUES WITH TEST STATISTIC(mean, median, mode).\n* PREDICT MISSING VALUE WITH A MACHINE LEARNING ALGORITHM(knn).","69162e1e":"## Little more about \"Nilearn\"\nNilearn is a Python module for fast and easy statistical learning on NeuroImaging data. It leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.\n\nNilearn can operate on either file names or NiftiImage objects. The later represent the data loaded in memory. In the example above, the function smooth_img returns a Nifti1Image object, which can then be readily passed to other nilearn functions.\n\nIn nilearn, we often use the term \u201cniimg\u201d as abbreviation that denotes either a file name or a NiftiImage object.\nNiimgs can be 3D or 4D. A 4D niimg may for instance represent a time series of 3D images.\n\n### The NifTi data structure (also used in Analyze files) is the standard way of sharing data in neuroimaging research. \n\nThree main components are:\n* data :- raw scans in form of a numpy array: data = nilearn.image.get_data(img)\n\n* affine :- returns the transformation matrix that maps from voxel indices of the numpy array to actual real-world locations of the brain: affine = img.affine\n\n* header:- low-level informations about the data (slice duration, etc.): header = img.header\n\n### Nilearn functions take as input argument what we call \u201cNiimg-like objects\u201d:\n\nNiimg: A Niimg-like object can be one of the following:\n\n* A string with a file path to a Nifti or Analyse image\n\n* An SpatialImage from nibabel, ie an object exposing get_fdata() method and affine attribute, typically a Nifti1Image from nibabel.\n\nNiimg-4D: Similarly, some functions require 4D Nifti-like data, which we call Niimgs or Niimg-4D. Accepted input arguments are:\n\n* A path to a 4D Nifti image\n\n* List of paths to 3D Nifti images\n\n* 4D Nifti-like object\n\n* List of 3D Nifti-like objects\n","bd48647a":"\n## What is NeuroImaging?\n\nNeuroimaging or brain imaging is the use of various techniques to either directly or indirectly image the structure, function, or pharmacology of the nervous system.It is a relatively new discipline within medicine, neuroscience, and psychology.Physicians who specialize in the performance and interpretation of neuroimaging in the clinical setting are neuroradiologists.\n\nNeuroimaging falls into two broad categories:\n* Structural imaging, which deals with the structure of the nervous system and the diagnosis of gross (large scale) intracranial disease (such as a tumor) and injury.\n* Functional imaging, which is used to diagnose metabolic diseases and lesions on a finer scale (such as Alzheimer's disease) and also for neurological and cognitive psychology research and building brain-computer interfaces.\n\nHuman brain research is among the most complex areas of study for scientists. We know that age and other factors can affect its function and structure, but more research is needed into what specifically occurs within the brain. With much of the research using MRI scans, data scientists are well positioned to support future insights. In particular, neuroimaging specialists look for measurable markers of behavior, health, or disorder to help identify relevant brain regions and their contribution to typical or symptomatic effects.\n\n### In this challenge, we have to predict age and assessment values from two domains using features derived from brain MRI images as inputs.","0812258a":"## Now move to the Data EDA...\n\n* Analyze the data\n* check for missing values.\n* Analyze the correlation.","9b45557e":"![nilearn_candy.png](attachment:nilearn_candy.png)","25fe2fbc":"from autokeras.cnn_module import CnnModule\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import Tensor\n\ntrain_dataset = TensorDataset(Tensor(X.iloc[:,1:].values),Tensor(y.iloc[:,1:].values))\ntest_dataset = TensorDataset(Tensor(test.iloc[:,1:].values), Tensor(y.iloc[:,1:].values))\ntrain_loader = DataLoader(train_dataset,shuffle=True,batch_size=32)\ntest_loader = DataLoader(train_dataset,shuffle=True,batch_size=32)\n\ncnnModule= CnnModule(loss='mean_absolute_error',metrics='accuracy',verbose=True)\ncnnModule.fit(n_output_node=5,\n              input_shape=1404,\n              train_data=train_loader,\n              test_data=test_loader,\n              time_limit=20*60)","11429802":"## Creating the Models with Auto Keras...","a8457a89":"## Now first visualize the data, and see what it conatin...","e1296c60":"## Start Diving into it...","2463e2f9":"## Plotting an anatomical image...\n\nMain Idea of this visualization technique is to provide the anatomical picture of the brain. Due to the measurement procedures, BOLD images usually have a realtively low resolution, as you want to squeeze in as many data-points along time as possible.","54ce189c":"## Checking the correlation between features...","d3dfce98":"## Plotting ROIs, or a mask...\n\nwhen mapping brain connectivities, ROIs provide the structural substrates for measuring connectivities within individual brains and for pooling data across populations. Thus, identification of reliable, reproducible and accurate ROIs is critically important for the success of brain connectivity mapping.\n\nFor more details you may visit.[click here](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3927780\/)","b54d14ef":"## How Brain MRI is done?\n\nMagnetic resonance imaging (MRI) of the head is a painless, noninvasive test that produces detailed images of your brain and brain stem. An MRI machine creates the images using a magnetic field and radio waves. This test is also known as a brain MRI or a cranial MRI. You will go to a hospital or radiology center to take a head MRI.\n\nAn MRI scan is different from a CT scan or an X-ray in that it doesn\u2019t use radiation to produce images. An MRI scan combines images to create a 3-D picture of your internal structures, so it\u2019s more effective than other scans at detecting abnormalities in small structures of the brain such as the pituitary gland and brain stem. Sometimes a contrast agent, or dye, can be given through an intravenous (IV) line to better visualize certain structures or abnormalities.\n\nA functional MRI (fMRI) of the brain is useful for people who might have to undergo brain surgery. An fMRI can pinpoint areas of the brain responsible for speech and language, and body movement. It does this by measuring metabolic changes that take place in your brain when you perform certain tasks. During this test, you may need to carry out small tasks, such as answering basic questions or tapping your thumb with your fingertips.\n","59f0fc56":"### This kernel will be a work in Progress,and I will keep on updating it as the competition progresses.\n\n### <span style=\"color:blue\">This Kernel is derived from this one : https:\/\/www.kaggle.com\/saife245\/neuroimaging-in-depth-understanding-eda-model If you find this kernel useful, Please Upvote it.<\/span> ","2cd7d9b7":"## Plotting 4D probabilistic atlas maps...\n\nProbabilistic atlasing is a research strategy whose goal is to generate anatomical templates that retain quantitative information on inter-subject variations in brain architecture (Mazziotta et al., 1995). A digital probabilistic atlas of the human brain, incorporating precise statistical information on positional variability of important functional and anatomic interfaces, may rectify many current atlasing problems, since it specifically stores information on the population variability.\n\nFor further reading you may visit.[click here](http:\/\/users.loni.usc.edu\/~thompson\/prob_atlas.html)","148d2cb2":"### Importing Libraries for Brain image visualization.","4f149877":"### Before moving to the visalization first understand the file format\n\n## What is .nii file format?\nThe [.nii] file type is primarily associated with NIfTI-1 Data Format by Neuroimaging Informatics Technology Initiative. NIfTI-1 is adapted from the widely used ANALYZE 7.5 file format. NIfTI-1 uses the empty space in the ANALYZE 7.5 header to add several new features.\n\n#### You can open the [.nii] file [here](https:\/\/filext.com\/file-extension\/NII)\n\n### How to read in Python?\nFor Python, you will need the nilearn in your system.Nilearn is a Python module for fast and easy statistical learning on NeuroImaging data. It leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.\n\n## What is .mat file format?\nFiles with the [.mat] extension are files that are in the binary data container format that the MATLAB program uses.MAT files are categorized as data files that include variables, functions, arrays and other information. There are the so called level 4 MAT files wherein two-dimensional matrices and character strings are supported and there is also the level 5 MAT files wherein several things are included like the cell arrays, objects, multidimensional numeric arrays, structures and character arrays. MAT files are also useful when it comes to representing audio in various formats such as 16-bit signed integer, 8-bit unsigned integer and 64-bit floating point. Mathworks MATLAB is the software used to open MAT files. It is an application used to develop algorithm, visualize and analyze data as well as to compute numbers.\n\n### How to read it in Python?\nFor Python, you will need the h5py extension, which requires HDF5 on your system. The function loadmat loads all variables stored in the MAT-file into a simple Python data structure, using only Python's dict and list objects.","9a301547":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#About-this-notebook...\" data-toc-modified-id=\"About-this-notebook...-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;<\/span>About this notebook...<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#This-kernel-will-be-a-work-in-Progress,and-I-will-keep-on-updating-it-as-the-competition-progresses.\" data-toc-modified-id=\"This-kernel-will-be-a-work-in-Progress,and-I-will-keep-on-updating-it-as-the-competition-progresses.-0.1.1\"><span class=\"toc-item-num\">0.1.1&nbsp;&nbsp;<\/span>This kernel will be a work in Progress,and I will keep on updating it as the competition progresses.<\/a><\/span><\/li><li><span><a href=\"#This-Kernel-is-derived-from-this-one-:-https:\/\/www.kaggle.com\/saife245\/neuroimaging-in-depth-understanding-eda-model-If-you-find-this-kernel-useful,-Please-Upvote-it.\" data-toc-modified-id=\"This-Kernel-is-derived-from-this-one-:-https:\/\/www.kaggle.com\/saife245\/neuroimaging-in-depth-understanding-eda-model-If-you-find-this-kernel-useful,-Please-Upvote-it.-0.1.2\"><span class=\"toc-item-num\">0.1.2&nbsp;&nbsp;<\/span><span style=\"color: blue\">This Kernel is derived from this one : <a href=\"https:\/\/www.kaggle.com\/saife245\/neuroimaging-in-depth-understanding-eda-model\" target=\"_blank\">https:\/\/www.kaggle.com\/saife245\/neuroimaging-in-depth-understanding-eda-model<\/a> If you find this kernel useful, Please Upvote it.<\/span><\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#References\" data-toc-modified-id=\"References-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;<\/span>References<\/a><\/span><\/li><li><span><a href=\"#Let-understand-the-Problem-statment!!!\" data-toc-modified-id=\"Let-understand-the-Problem-statment!!!-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;<\/span>Let understand the Problem statment!!!<\/a><\/span><\/li><li><span><a href=\"#What-is-NeuroImaging?\" data-toc-modified-id=\"What-is-NeuroImaging?-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;<\/span>What is NeuroImaging?<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#In-this-challenge,-we-have-to-predict-age-and-assessment-values-from-two-domains-using-features-derived-from-brain-MRI-images-as-inputs.\" data-toc-modified-id=\"In-this-challenge,-we-have-to-predict-age-and-assessment-values-from-two-domains-using-features-derived-from-brain-MRI-images-as-inputs.-0.4.1\"><span class=\"toc-item-num\">0.4.1&nbsp;&nbsp;<\/span>In this challenge, we have to predict age and assessment values from two domains using features derived from brain MRI images as inputs.<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#How-Brain-MRI-is-done?\" data-toc-modified-id=\"How-Brain-MRI-is-done?-0.5\"><span class=\"toc-item-num\">0.5&nbsp;&nbsp;<\/span>How Brain MRI is done?<\/a><\/span><\/li><li><span><a href=\"#Let-understand-the-Dataset.\" data-toc-modified-id=\"Let-understand-the-Dataset.-0.6\"><span class=\"toc-item-num\">0.6&nbsp;&nbsp;<\/span>Let understand the Dataset.<\/a><\/span><\/li><li><span><a href=\"#How-Features-Were-Obtained\" data-toc-modified-id=\"How-Features-Were-Obtained-0.7\"><span class=\"toc-item-num\">0.7&nbsp;&nbsp;<\/span>How Features Were Obtained<\/a><\/span><\/li><li><span><a href=\"#Start-Diving-into-it...\" data-toc-modified-id=\"Start-Diving-into-it...-0.8\"><span class=\"toc-item-num\">0.8&nbsp;&nbsp;<\/span>Start Diving into it...<\/a><\/span><\/li><li><span><a href=\"#Now-first-visualize-the-data,-and-see-what-it-conatin...\" data-toc-modified-id=\"Now-first-visualize-the-data,-and-see-what-it-conatin...-0.9\"><span class=\"toc-item-num\">0.9&nbsp;&nbsp;<\/span>Now first visualize the data, and see what it conatin...<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Before-moving-to-the-visalization-first-understand-the-file-format\" data-toc-modified-id=\"Before-moving-to-the-visalization-first-understand-the-file-format-0.9.1\"><span class=\"toc-item-num\">0.9.1&nbsp;&nbsp;<\/span>Before moving to the visalization first understand the file format<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#What-is-.nii-file-format?\" data-toc-modified-id=\"What-is-.nii-file-format?-0.10\"><span class=\"toc-item-num\">0.10&nbsp;&nbsp;<\/span>What is .nii file format?<\/a><\/span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#You-can-open-the-[.nii]-file-here\" data-toc-modified-id=\"You-can-open-the-[.nii]-file-here-0.10.0.1\"><span class=\"toc-item-num\">0.10.0.1&nbsp;&nbsp;<\/span>You can open the [.nii] file <a href=\"https:\/\/filext.com\/file-extension\/NII\" target=\"_blank\">here<\/a><\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#How-to-read-in-Python?\" data-toc-modified-id=\"How-to-read-in-Python?-0.10.1\"><span class=\"toc-item-num\">0.10.1&nbsp;&nbsp;<\/span>How to read in Python?<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#What-is-.mat-file-format?\" data-toc-modified-id=\"What-is-.mat-file-format?-0.11\"><span class=\"toc-item-num\">0.11&nbsp;&nbsp;<\/span>What is .mat file format?<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#How-to-read-it-in-Python?\" data-toc-modified-id=\"How-to-read-it-in-Python?-0.11.1\"><span class=\"toc-item-num\">0.11.1&nbsp;&nbsp;<\/span>How to read it in Python?<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Little-more-about-&quot;Nilearn&quot;\" data-toc-modified-id=\"Little-more-about-&quot;Nilearn&quot;-0.12\"><span class=\"toc-item-num\">0.12&nbsp;&nbsp;<\/span>Little more about \"Nilearn\"<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#The-NifTi-data-structure-(also-used-in-Analyze-files)-is-the-standard-way-of-sharing-data-in-neuroimaging-research.\" data-toc-modified-id=\"The-NifTi-data-structure-(also-used-in-Analyze-files)-is-the-standard-way-of-sharing-data-in-neuroimaging-research.-0.12.1\"><span class=\"toc-item-num\">0.12.1&nbsp;&nbsp;<\/span>The NifTi data structure (also used in Analyze files) is the standard way of sharing data in neuroimaging research.<\/a><\/span><\/li><li><span><a href=\"#Nilearn-functions-take-as-input-argument-what-we-call-\u201cNiimg-like-objects\u201d:\" data-toc-modified-id=\"Nilearn-functions-take-as-input-argument-what-we-call-\u201cNiimg-like-objects\u201d:-0.12.2\"><span class=\"toc-item-num\">0.12.2&nbsp;&nbsp;<\/span>Nilearn functions take as input argument what we call \u201cNiimg-like objects\u201d:<\/a><\/span><\/li><li><span><a href=\"#Importing-Libraries-for-Brain-image-visualization.\" data-toc-modified-id=\"Importing-Libraries-for-Brain-image-visualization.-0.12.3\"><span class=\"toc-item-num\">0.12.3&nbsp;&nbsp;<\/span>Importing Libraries for Brain image visualization.<\/a><\/span><\/li><li><span><a href=\"#Taking-any-3-random-images-and-visualize-the-plot.\" data-toc-modified-id=\"Taking-any-3-random-images-and-visualize-the-plot.-0.12.4\"><span class=\"toc-item-num\">0.12.4&nbsp;&nbsp;<\/span>Taking any 3 random images and visualize the plot.<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Plotting-4D-probabilistic-atlas-maps...\" data-toc-modified-id=\"Plotting-4D-probabilistic-atlas-maps...-0.13\"><span class=\"toc-item-num\">0.13&nbsp;&nbsp;<\/span>Plotting 4D probabilistic atlas maps...<\/a><\/span><\/li><li><span><a href=\"#Plotting-a-statistical-map...\" data-toc-modified-id=\"Plotting-a-statistical-map...-0.14\"><span class=\"toc-item-num\">0.14&nbsp;&nbsp;<\/span>Plotting a statistical map...<\/a><\/span><\/li><li><span><a href=\"#Plotting-a-statistical-map...\" data-toc-modified-id=\"Plotting-a-statistical-map...-0.15\"><span class=\"toc-item-num\">0.15&nbsp;&nbsp;<\/span>Plotting a statistical map...<\/a><\/span><\/li><li><span><a href=\"#Glass-brain-visualization...\" data-toc-modified-id=\"Glass-brain-visualization...-0.16\"><span class=\"toc-item-num\">0.16&nbsp;&nbsp;<\/span>Glass brain visualization...<\/a><\/span><\/li><li><span><a href=\"#Plotting-an-EPI...\" data-toc-modified-id=\"Plotting-an-EPI...-0.17\"><span class=\"toc-item-num\">0.17&nbsp;&nbsp;<\/span>Plotting an EPI...<\/a><\/span><\/li><li><span><a href=\"#Plotting-an-anatomical-image...\" data-toc-modified-id=\"Plotting-an-anatomical-image...-0.18\"><span class=\"toc-item-num\">0.18&nbsp;&nbsp;<\/span>Plotting an anatomical image...<\/a><\/span><\/li><li><span><a href=\"#Plotting-ROIs,-or-a-mask...\" data-toc-modified-id=\"Plotting-ROIs,-or-a-mask...-0.19\"><span class=\"toc-item-num\">0.19&nbsp;&nbsp;<\/span>Plotting ROIs, or a mask...<\/a><\/span><\/li><li><span><a href=\"#3D-Plots-of-statistical-maps-or-atlases-on-the-cortical-surface...\" data-toc-modified-id=\"3D-Plots-of-statistical-maps-or-atlases-on-the-cortical-surface...-0.20\"><span class=\"toc-item-num\">0.20&nbsp;&nbsp;<\/span>3D Plots of statistical maps or atlases on the cortical surface...<\/a><\/span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#I-strongly-recommend-to-change-the-plot-from-&quot;Inflated&quot;-to-&quot;Pial&quot;-for-analyze-the-3D-view-of-Brain.\" data-toc-modified-id=\"I-strongly-recommend-to-change-the-plot-from-&quot;Inflated&quot;-to-&quot;Pial&quot;-for-analyze-the-3D-view-of-Brain.-0.20.0.1\"><span class=\"toc-item-num\">0.20.0.1&nbsp;&nbsp;<\/span>I strongly recommend to change the plot from \"Inflated\" to \"Pial\" for analyze the 3D view of Brain.<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#There-lot-more-in-visualization,and-I-try-to-explain-all-possible-visualization-in-a-simple-way.-you-can-also-check-out-the-above-links-for-more-details.\" data-toc-modified-id=\"There-lot-more-in-visualization,and-I-try-to-explain-all-possible-visualization-in-a-simple-way.-you-can-also-check-out-the-above-links-for-more-details.-0.20.1\"><span class=\"toc-item-num\">0.20.1&nbsp;&nbsp;<\/span>There lot more in visualization,and I try to explain all possible visualization in a simple way. you can also check out the above links for more details.<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Now-move-to-the-Data-EDA...\" data-toc-modified-id=\"Now-move-to-the-Data-EDA...-0.21\"><span class=\"toc-item-num\">0.21&nbsp;&nbsp;<\/span>Now move to the Data EDA...<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Handling-the-missing-Value...\" data-toc-modified-id=\"Handling-the-missing-Value...-0.21.1\"><span class=\"toc-item-num\">0.21.1&nbsp;&nbsp;<\/span>Handling the missing Value...<\/a><\/span><\/li><li><span><a href=\"#WHAT-DO-WE-DO-TO-MISSING-VALUES?\" data-toc-modified-id=\"WHAT-DO-WE-DO-TO-MISSING-VALUES?-0.21.2\"><span class=\"toc-item-num\">0.21.2&nbsp;&nbsp;<\/span>WHAT DO WE DO TO MISSING VALUES?<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Checking-the-correlation-between-features...\" data-toc-modified-id=\"Checking-the-correlation-between-features...-0.22\"><span class=\"toc-item-num\">0.22&nbsp;&nbsp;<\/span>Checking the correlation between features...<\/a><\/span><\/li><li><span><a href=\"#Visualize-the-Target-Columns...\" data-toc-modified-id=\"Visualize-the-Target-Columns...-0.23\"><span class=\"toc-item-num\">0.23&nbsp;&nbsp;<\/span>Visualize the Target Columns...<\/a><\/span><\/li><li><span><a href=\"#Prepare-the-Train-dataset...\" data-toc-modified-id=\"Prepare-the-Train-dataset...-0.24\"><span class=\"toc-item-num\">0.24&nbsp;&nbsp;<\/span>Prepare the Train dataset...<\/a><\/span><\/li><li><span><a href=\"#Preparing-the-test-data...\" data-toc-modified-id=\"Preparing-the-test-data...-0.25\"><span class=\"toc-item-num\">0.25&nbsp;&nbsp;<\/span>Preparing the test data...<\/a><\/span><\/li><li><span><a href=\"#Creating-the-Models-with-CNN-and-Auto-Keras...-DEPRECATED\" data-toc-modified-id=\"Creating-the-Models-with-CNN-and-Auto-Keras...-DEPRECATED-0.26\"><span class=\"toc-item-num\">0.26&nbsp;&nbsp;<\/span>Creating the Models with CNN and Auto Keras... DEPRECATED<\/a><\/span><\/li><li><span><a href=\"#Creating-the-Models-with-Auto-Keras...\" data-toc-modified-id=\"Creating-the-Models-with-Auto-Keras...-0.27\"><span class=\"toc-item-num\">0.27&nbsp;&nbsp;<\/span>Creating the Models with Auto Keras...<\/a><\/span><\/li><li><span><a href=\"#Creating-the-Models...\" data-toc-modified-id=\"Creating-the-Models...-0.28\"><span class=\"toc-item-num\">0.28&nbsp;&nbsp;<\/span>Creating the Models...<\/a><\/span><\/li><li><span><a href=\"#Let-Create-the-Submission...\" data-toc-modified-id=\"Let-Create-the-Submission...-0.29\"><span class=\"toc-item-num\">0.29&nbsp;&nbsp;<\/span>Let Create the Submission...<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#What-next...\" data-toc-modified-id=\"What-next...-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>What next...<\/a><\/span><\/li><li><span><a href=\"#End-Note...\" data-toc-modified-id=\"End-Note...-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>End Note...<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#-I-hope-you-find-this-kernel-useful-and-enjoyable,-If-so-Please-upvote-it.-And-Your-comments-and-feedback-are-most-welcome.-;-)\" data-toc-modified-id=\"-I-hope-you-find-this-kernel-useful-and-enjoyable,-If-so-Please-upvote-it.-And-Your-comments-and-feedback-are-most-welcome.-;-)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span><span style=\"color: blue\"> I hope you find this kernel useful and enjoyable, If so Please upvote it. And Your comments and feedback are most welcome. ;-)<\/span><\/a><\/span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#STAY-TUNED!\" data-toc-modified-id=\"STAY-TUNED!-2.1.0.1\"><span class=\"toc-item-num\">2.1.0.1&nbsp;&nbsp;<\/span><span style=\"color: red\">STAY TUNED!<\/span><\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/div>"}}