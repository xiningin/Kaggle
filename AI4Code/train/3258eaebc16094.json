{"cell_type":{"793c0c1e":"code","7b59e7f2":"code","b1390ac8":"code","12763c3d":"code","dba86f82":"code","0c9dff1c":"code","e71c43f2":"code","a63a602a":"code","6eb4892e":"code","97da7731":"code","998e8927":"code","b79a37f4":"code","5b533d85":"code","3455dae0":"code","fa49529d":"code","eb70cf11":"code","9f927d7b":"code","076917e9":"code","9dbd6567":"code","ce29fb76":"code","1d9d98de":"code","99dd06bb":"code","51731c6e":"code","67a34cb3":"code","f9e163d8":"code","7a068c2f":"code","d74d3649":"code","e6fc21be":"code","4ba85d2c":"code","b47c8041":"code","a36686da":"code","f3de5ffe":"code","e149aefe":"code","de7e03c7":"code","5988145f":"code","8cd0972f":"code","670dc864":"code","e35e0404":"code","689c04d7":"code","8fe0a2c3":"code","f110537a":"code","0dcbd30f":"code","3f5ee815":"code","a2cd768b":"code","5b07f25d":"code","c5b1d6ef":"code","f43ab147":"code","c77bcf6f":"code","2298d5ae":"code","135449da":"code","e1346f06":"code","a2c6b986":"code","9e7d73ee":"code","93df0e18":"code","d6e80f33":"code","575938e0":"code","da665443":"code","2fb0080a":"code","3939aca6":"code","b6770772":"code","cdafb8ef":"code","9bbc552a":"code","4ea7f15c":"code","0c1a5082":"code","cc0b85f5":"code","7351ac01":"code","c6529b33":"code","62529137":"code","78320f83":"code","4d824bbd":"code","847ce950":"code","28c7abdc":"code","018b3b26":"code","d0dfec0e":"code","ab2ca84e":"code","3260ae38":"code","a0047fb9":"code","5d8144c8":"code","b854cd1a":"code","e2bf4010":"code","c1e61d63":"code","0f700c16":"code","ff3fc161":"code","1ad5143a":"code","ac9dc2b7":"code","b9fae212":"code","48a24315":"code","137f7f12":"code","47753929":"code","53af97d2":"code","e152ce2d":"code","28ee4702":"code","cd036192":"code","86d0f3cc":"code","ecab9783":"code","5678c354":"code","cf572d78":"code","2aeedeae":"code","72f85b1c":"code","e226297e":"code","90df98bc":"code","686f08e0":"code","eec565b5":"code","592f7c7d":"code","d3f8d6b1":"code","1f2a8157":"code","80714d2a":"code","97aecad0":"code","5c748614":"code","030339b4":"code","46a1ed9e":"code","79538ee5":"code","5be6330b":"code","eacbc698":"code","b9a6c820":"code","d20bb06c":"code","c8ee5994":"code","856d7966":"code","e50ad9b0":"code","82db275a":"code","0780b560":"code","99b5518d":"code","427d37f2":"code","344da421":"code","5a9348b9":"code","14c91fc9":"code","1b4af0c4":"code","ed69274f":"code","e2f1d883":"code","1339d8ac":"code","90734168":"code","3a3668b3":"code","0a317f43":"code","ce5669ce":"code","291e4399":"code","f2f76a00":"code","21d9181d":"code","ffa50054":"code","dec71030":"code","782f7093":"code","9feed011":"code","53f191fa":"code","3fb72d36":"code","52b9e9dd":"code","dd51fa2e":"code","d611d2c5":"code","01f52d4d":"code","0e1f3651":"code","4101738c":"code","50e0b04d":"code","e0dfb17a":"code","6b11a446":"code","860bc9db":"code","8664dcd7":"code","bc563c90":"code","2020a2cf":"code","d342e192":"code","d9eaf7d0":"code","f7ce7928":"code","8fa35427":"code","8a8dde13":"code","a57930c9":"code","a73e49c0":"code","b2a1a781":"code","b8a4b86b":"code","a8f36ae9":"code","e4dbc27d":"code","97457122":"code","6e4e4831":"code","dd860bdb":"code","52e0ce4c":"code","441a43df":"code","8c655e17":"code","acb78608":"code","8b1c7c13":"code","ca34412c":"code","2df4df21":"code","c7a15d93":"code","f56d08a4":"code","ba5a74ae":"code","1b03a022":"code","37ca0aa2":"code","519e86fb":"code","b8fafbed":"code","03e39617":"code","db7c8a3c":"code","85e3fdbd":"code","db016b85":"code","b124c468":"code","f4183bdb":"code","344f3944":"code","ec28aa74":"code","cd269388":"markdown","e41185df":"markdown","36932046":"markdown","3c741d64":"markdown","d6ef6551":"markdown","f8020a6e":"markdown","75d1e4a8":"markdown","7b1943f1":"markdown","904bcbcc":"markdown","bac2c804":"markdown","fc19dde7":"markdown","8ff27ab4":"markdown","18f38305":"markdown","561b8be0":"markdown","abb025d1":"markdown","bea9625a":"markdown","f384cc27":"markdown","b711c967":"markdown","604b5e93":"markdown","836ad464":"markdown","20f47143":"markdown","0e2605ce":"markdown","c2f3c699":"markdown","5e83a0bd":"markdown","29011004":"markdown","8b907154":"markdown","cf50d3cb":"markdown","5ab3094d":"markdown","b30a0207":"markdown","2eb867ff":"markdown","87d92781":"markdown","abacaef6":"markdown","28ea16bf":"markdown","9ce2c9dc":"markdown","0da37283":"markdown","d523a06d":"markdown","a19e26cc":"markdown","a9c9e8e9":"markdown","092ab568":"markdown","3c8fe548":"markdown","1a60aa84":"markdown","223798a7":"markdown","f4c2032c":"markdown","76573a91":"markdown","61743ed3":"markdown","d4acc003":"markdown","c6631520":"markdown","98431601":"markdown","b86fea7e":"markdown","afa60512":"markdown","cb48d196":"markdown","35347d67":"markdown","57b13e64":"markdown","8be7d3ed":"markdown","f13724c8":"markdown","ec258729":"markdown","82c58ffa":"markdown","24f1c7b3":"markdown","488dc664":"markdown","68242c4d":"markdown","2dd726c9":"markdown","a10b330c":"markdown","adaac512":"markdown","0e625ecd":"markdown","ef4817ca":"markdown","2e7a4de2":"markdown","ce02e59a":"markdown","43800e67":"markdown","de78380a":"markdown","25fde1f4":"markdown","48057d29":"markdown"},"source":{"793c0c1e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import recall_score\n\n\nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz","7b59e7f2":"traindf = pd.read_csv('..\/input\/novartis-data\/Train.csv')\ntraindf.head()","b1390ac8":"testdf = pd.read_csv('..\/input\/novartis-data\/Test.csv')\ntestdf.head()","12763c3d":"ss = pd.read_csv('..\/input\/novartis-data\/sample_submission.csv')\nss.head()","dba86f82":"traindf.dtypes","0c9dff1c":"testdf.dtypes","e71c43f2":"traindf['DATE'] =pd.to_datetime(traindf.DATE, format = '%d-%b-%y')\ntestdf['DATE'] = pd.to_datetime(testdf.DATE, format = '%d-%b-%y')\nprint('train set ' , traindf.DATE.dtypes)\nprint('test set ',testdf.DATE.dtypes)","a63a602a":"# traindf['MULTIPLE_OFFENSE'] = pd.Categorical(traindf.MULTIPLE_OFFENSE)\n# traindf['MULTIPLE_OFFENSE'].dtypes","6eb4892e":"# traindf.dtypes","97da7731":"NA_col = pd.DataFrame(traindf.isna().sum(), columns = ['NA_Count'])\nNA_col['%_of_NA'] = (NA_col.NA_Count\/len(traindf))*100\nNA_col.sort_values(by = ['%_of_NA'], ascending = False, na_position = 'first')","998e8927":"NA_row = pd.DataFrame(traindf.isna().sum(axis=1), columns = ['NA_rw_count'])\nNA_row['%_of_rw_NA'] = (NA_row.NA_rw_count\/len(traindf))*100\nNA_row.sort_values(by = ['%_of_rw_NA'], ascending = False, na_position = 'first').head(10)","b79a37f4":"NA_col = pd.DataFrame(testdf.isna().sum(), columns = ['NA_Count'])\nNA_col['%_of_NA'] = (NA_col.NA_Count\/len(testdf))*100\nNA_col.sort_values(by = ['%_of_NA'], ascending = False, na_position = 'first')","5b533d85":"NA_row = pd.DataFrame(testdf.isna().sum(axis=1), columns = ['NA_rw_count'])\nNA_row['%_of_rw_NA'] = (NA_row.NA_rw_count\/len(testdf))*100\nNA_row.sort_values(by = ['%_of_rw_NA'], ascending = False, na_position = 'first').head()","3455dae0":"cor = traindf[['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7',\n       'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15']]","fa49529d":"plt.figure(figsize = (18,14))\nsns.heatmap(cor.corr(), vmin=cor.values.min(), vmax=1, annot=True, annot_kws={\"size\":14}, square = False)\nplt.show()","eb70cf11":"sns.catplot('MULTIPLE_OFFENSE', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['MULTIPLE_OFFENSE'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of MULTIPLE_OFFENSE', fontsize = 14, color = 'black')\nplt.show()","9f927d7b":"sns.catplot('X_1', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_1'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_1', fontsize = 14, color = 'black')\nplt.show()","076917e9":"sns.catplot('X_2', data= traindf, kind='count', alpha=0.7, height=4, aspect= 4)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_2'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_2', fontsize = 14, color = 'black')\nplt.show()","9dbd6567":"sns.catplot('X_3', data= traindf, kind='count', alpha=0.7, height=4, aspect= 4)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_3'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_3', fontsize = 14, color = 'black')\nplt.show()","ce29fb76":"sns.catplot('X_4', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_4'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_4', fontsize = 14, color = 'black')\nplt.show()","1d9d98de":"sns.catplot('X_5', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_5'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_5', fontsize = 14, color = 'black')\nplt.show()","99dd06bb":"sns.catplot('X_6', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_6'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_6', fontsize = 14, color = 'black')\nplt.show()","51731c6e":"sns.catplot('X_7', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_7'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_7', fontsize = 14, color = 'black')\nplt.show()","67a34cb3":"sns.catplot('X_8', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_8'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_8', fontsize = 14, color = 'black')\nplt.show()","f9e163d8":"sns.catplot('X_9', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_9'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_9', fontsize = 14, color = 'black')\nplt.show()","7a068c2f":"sns.catplot('X_10', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_10'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_10', fontsize = 14, color = 'black')\nplt.show()","d74d3649":"sns.catplot('X_11', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3.8)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_11'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=10, color='blue',ha='center',  va='bottom', rotation = 90)\nplt.title('Frequency plot of X_11', fontsize = 14, color = 'black')\n\nplt.tick_params(axis='x', rotation = 90,  labelsize = 8)\nplt.show()","e6fc21be":"sns.catplot('X_12', data= traindf, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_12'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_12', fontsize = 14, color = 'black')\nplt.show()","4ba85d2c":"sns.catplot('X_13', data= traindf, kind='count', alpha=0.7, height=4, aspect= 4)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_13'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_13', fontsize = 14, color = 'black')\nplt.show()","b47c8041":"sns.catplot('X_14', data= traindf, kind='count', alpha=0.7, height=4, aspect= 4)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_14'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_14', fontsize = 14, color = 'black')\nplt.show()","a36686da":"sns.catplot('X_15', data= traindf, kind='count', alpha=0.7, height=4, aspect= 4)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = traindf['X_15'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of X_15', fontsize = 14, color = 'black')\nplt.show()","f3de5ffe":"train_X_10_12 = traindf[[\"DATE\", \"X_10\",\"X_12\",\"MULTIPLE_OFFENSE\"]]\ntrain_X_10_12.head()","e149aefe":"null = train_X_10_12[train_X_10_12['X_12'].isna()]\nnull.DATE.min()","de7e03c7":"train_X_10_12 = train_X_10_12[train_X_10_12[\"DATE\"].isin(pd.date_range(\"2016-07-01\", \"2030-01-01\"))]\ntrain_X_10_12 = train_X_10_12.set_index('DATE')\ntrain_X_10_12.head()","5988145f":"train_X_10_12 = train_X_10_12 .assign(missing= np.nan)\ntrain_X_10_12.missing[train_X_10_12['X_12'].isna()] = train_X_10_12.X_10\ntrain_X_10_12.info()","8cd0972f":"train_X_10_12.plot(style=['k--', 'bo-', 'r*'], figsize=(20, 10))","670dc864":"train_X_10_12.X_12.value_counts()","e35e0404":"test_X_10_12 = testdf[[\"DATE\", \"X_10\",\"X_12\"]]\ntest_X_10_12.head()","689c04d7":"null = test_X_10_12[test_X_10_12['X_12'].isna()]\nnull.DATE.min()","8fe0a2c3":"test_X_10_12 = test_X_10_12[test_X_10_12[\"DATE\"].isin(pd.date_range(\"2016-07-01\", \"2030-01-01\"))]\ntest_X_10_12 = test_X_10_12.set_index('DATE')\ntest_X_10_12.head()","f110537a":"test_X_10_12 = test_X_10_12 .assign(missing= np.nan)\ntest_X_10_12.missing[test_X_10_12['X_12'].isna()] = test_X_10_12.X_10\ntest_X_10_12.info()","0dcbd30f":"test_X_10_12.plot(style=['k--', 'bo-', 'r*'], figsize=(20, 10))","3f5ee815":"test_X_10_12.X_12.value_counts()","a2cd768b":"traindf['X_12'] = traindf['X_12'].fillna(1)\ntraindf.isna().sum()","5b07f25d":"testdf['X_12'] = testdf['X_12'].fillna(1)\ntestdf.isna().sum()","c5b1d6ef":"for i in traindf.columns:\n    if traindf[i].nunique() == 1:\n        print('Train: With only 1 unique value: ', i)\n    if traindf[i].nunique() == traindf.shape[0]:\n        print('Train: With all unique value: ', i)\n\nfor i in testdf.columns:\n    if testdf[i].nunique() == 1:\n        print('Test: With only 1 unique value: ', i)\n    if testdf[i].nunique() == testdf.shape[0]:\n        print('Test: With all unique value: ', i)","f43ab147":"train = traindf.copy().drop('INCIDENT_ID', axis = 1)\ntest = testdf.copy().drop('INCIDENT_ID', axis = 1)","c77bcf6f":"train['Year'] = train['DATE'].dt.year\ntrain['Month'] = train['DATE'].dt.month\ntrain['Day'] = train['DATE'].dt.day_name()\ntrain.head()","2298d5ae":"test['Year'] = test['DATE'].dt.year\ntest['Month'] = test['DATE'].dt.month\ntest['Day'] = test['DATE'].dt.day_name()\ntest.head()","135449da":"train = train.drop('DATE', axis = 1)\ntest = test.drop('DATE', axis = 1)","e1346f06":"col_train = train.columns\ncol_test = test.columns","a2c6b986":"# Changing variables with 10 or less unique values\nl1 = []\nfor i in col_train:\n    if train[i].nunique() <= 10:\n        l1.append(i)\n               \nl1.remove('MULTIPLE_OFFENSE')","9e7d73ee":"l2 = []\nfor i in col_test:\n    if test[i].nunique() <= 10:\n        l2.append(i)","93df0e18":"# Checking the columns in train and test are same or not\ndf = pd.DataFrame(l1, columns = ['train'])\ndf['test'] = pd.DataFrame(l2)\ndf","d6e80f33":"train[l1] = train[l1].apply(lambda x: x.astype('category'), axis=0)\ntest[l2] = test[l2].apply(lambda x: x.astype('category'), axis=0)\nprint('train dtypes:')\nprint(train[l1].dtypes)\nprint('======================================')\nprint('test dtypes:')\nprint(test[l1].dtypes)","575938e0":"cols = train.drop('MULTIPLE_OFFENSE', axis=1).columns\nnum_cols = train._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))\ncat_cols","da665443":"for usecol in cat_cols:\n    train[usecol] = train[usecol].astype('str')\n    test[usecol] = test[usecol].astype('str')\n    \n    #Fit LabelEncoder\n    le = LabelEncoder().fit(\n            np.unique(train[usecol].unique().tolist()+ test[usecol].unique().tolist()))\n\n    #At the end 0 will be used for dropped values\n    train[usecol] = le.transform(train[usecol])+1\n    test[usecol]  = le.transform(test[usecol])+1\n    \n    train[usecol] = train[usecol].replace(np.nan, '').astype('int').astype('category')\n    test[usecol]  = test[usecol].replace(np.nan, '').astype('int').astype('category')","2fb0080a":"train.MULTIPLE_OFFENSE.value_counts()","3939aca6":"# Separating majority and minority classes\ntrain_majority = train[train.MULTIPLE_OFFENSE==1]\ntrain_minority = train[train.MULTIPLE_OFFENSE==0]","b6770772":"# Resampling the minority levels to match the majority level\n# Upsample minority class\nfrom sklearn.utils import resample\ntrain_minority_upsampled = resample(train_minority, \n                                 replace=True,       # sample with replacement\n                                 n_samples=22788,    # to match majority class\n                                 random_state= 303)  # reproducible results\n \n# Combine majority class with upsampled minority class\ntrain_upsampled = pd.concat([train_majority, train_minority_upsampled])\n \n# Display new class counts\ntrain_upsampled.MULTIPLE_OFFENSE.value_counts()","cdafb8ef":"# Resampling the majority levels to match the minority level\n# Downsample majority class\nfrom sklearn.utils import resample\ntrain_majority_downsampled = resample(train_majority, \n                                 replace=True,       # sample with replacement\n                                 n_samples=1068,    # to match minority class\n                                 random_state= 303)  # reproducible results\n \n# Combine majority class with upsampled minority class\ntrain_downsampled = pd.concat([train_majority_downsampled, train_minority])\n \n# Display new class counts\ntrain_downsampled.MULTIPLE_OFFENSE.value_counts()","9bbc552a":"X = train.drop('MULTIPLE_OFFENSE', axis = 1)\ny = train['MULTIPLE_OFFENSE']","4ea7f15c":"Xs = train_upsampled.drop('MULTIPLE_OFFENSE', axis = 1)\nys = train_upsampled['MULTIPLE_OFFENSE']","0c1a5082":"Xsd = train_downsampled.drop('MULTIPLE_OFFENSE', axis = 1)\nysd = train_downsampled['MULTIPLE_OFFENSE']","cc0b85f5":"X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3, random_state = 42)","7351ac01":"Xs_train, Xs_val, ys_train, ys_val = train_test_split(Xs, ys, test_size=0.3, random_state = 42)","c6529b33":"Xsd_train, Xsd_val, ysd_train, ysd_val = train_test_split(Xsd, ysd, test_size=0.3, random_state = 42)","62529137":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()","78320f83":"logreg.fit(X_train, y_train)","4d824bbd":"predictions = logreg.predict(X_val)","847ce950":"confusion_matrix(y_val, predictions)","28c7abdc":"recall_score(y_val, predictions)","018b3b26":"test['MULTIPLE_OFFENSE'] = logreg.predict(test)","d0dfec0e":"test.head()","ab2ca84e":"test['INCIDENT_ID'] = testdf['INCIDENT_ID']","3260ae38":"submission = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission.head()","a0047fb9":"# submission.to_csv(\"submission_logreg.csv\",index=False)","5d8144c8":"from sklearn.ensemble import RandomForestClassifier\nrfc0 = RandomForestClassifier()\nrfc0.fit(X = X_train,y = y_train)","b854cd1a":"pred_rf = rfc0.predict(X_val)","e2bf4010":"confusion_matrix(y_val, pred_rf)","c1e61d63":"recall_score(y_val, pred_rf)","0f700c16":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)","ff3fc161":"test['MULTIPLE_OFFENSE'] = rfc0.predict(test)","1ad5143a":"test['INCIDENT_ID'] = testdf['INCIDENT_ID']","ac9dc2b7":"submission_rf = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_rf.head()","b9fae212":"# submission_rf.to_csv(\"submission_rf.csv\",index=False)","48a24315":"rfc0_up = RandomForestClassifier()\nrfc0_up.fit(X = Xs_train,y = ys_train)","137f7f12":"pred_rf_up = rfc0_up.predict(Xs_val)\nconfusion_matrix(ys_val, pred_rf_up)","47753929":"recall_score(ys_val, pred_rf_up)","53af97d2":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)\ntest['MULTIPLE_OFFENSE'] = rfc0_up.predict(test)","e152ce2d":"test['INCIDENT_ID'] = testdf['INCIDENT_ID']\nsubmission_rf_up = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_rf_up.head()","28ee4702":"# submission_rf_up.to_csv(\"submission_rf_up.csv\",index=False)","cd036192":"rfcv0 = RandomForestClassifier(random_state=42)","86d0f3cc":"param_grid = { \n    'n_estimators': [100, 150, 200, 250],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [4,5,6,7,8,9,10],\n    'criterion' :['gini', 'entropy']\n}","ecab9783":"cv_rfc = GridSearchCV(estimator=rfcv0, param_grid=param_grid, cv= 5)\ncv_rfc.fit(X_train, y_train)","5678c354":"cv_rfc.best_params_","cf572d78":"rfc1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 100, max_depth=10, criterion='entropy')","2aeedeae":"rfc1.fit(X_train, y_train)","72f85b1c":"pred_rfgs = rfc1.predict(X_val)","e226297e":"confusion_matrix(y_val, pred_rfgs)","90df98bc":"recall_score(y_val, pred_rfgs)","686f08e0":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)","eec565b5":"test['MULTIPLE_OFFENSE'] = rfc1.predict(test)","592f7c7d":"test['INCIDENT_ID'] = testdf['INCIDENT_ID']","d3f8d6b1":"submission_rfgs1 = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_rfgs1.head()","1f2a8157":"# submission_rfgs1.to_csv(\"submission_rfgs.csv\",index=False)","80714d2a":"param_grid_2 = { \n    'n_estimators': [80,100,110,120,130],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [10,12,14,16],\n    'criterion' :['gini']\n}","97aecad0":"cv_rfc2 = GridSearchCV(estimator=rfcv0, param_grid=param_grid_2, cv= 5)\ncv_rfc2.fit(X_train, y_train)","5c748614":"cv_rfc2.best_params_","030339b4":"rfc2=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 80, max_depth=16, criterion='gini')","46a1ed9e":"rfc2.fit(X_train, y_train)","79538ee5":"pred_rfgs2 = rfc2.predict(X_val)","5be6330b":"confusion_matrix(y_val, pred_rfgs2)","eacbc698":"recall_score(y_val, pred_rfgs2)","b9a6c820":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)","d20bb06c":"test['MULTIPLE_OFFENSE'] = rfc2.predict(test)","c8ee5994":"test['INCIDENT_ID'] = testdf['INCIDENT_ID']","856d7966":"submission_rfgs2 = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_rfgs2.head()","e50ad9b0":"# submission_rfgs2.to_csv(\"submission_rfgs2.csv\",index=False)","82db275a":"cv_rfc_up = GridSearchCV(estimator=rfcv0, param_grid=param_grid, cv= 5)\ncv_rfc_up.fit(Xs_train, ys_train)","0780b560":"cv_rfc_up.best_params_","99b5518d":"rfc_up1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 100, max_depth=10, criterion='entropy')\nrfc_up1.fit(Xs_train, ys_train)","427d37f2":"pred_rfgs_up1 = rfc_up1.predict(Xs_val)\nconfusion_matrix(ys_val, pred_rfgs_up1)","344da421":"recall_score(ys_val, pred_rfgs_up1)","5a9348b9":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)\ntest['MULTIPLE_OFFENSE'] = rfc_up1.predict(test)\ntest['INCIDENT_ID'] = testdf['INCIDENT_ID']","14c91fc9":"submission_rfgs_up1 = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_rfgs_up1.head()","1b4af0c4":"# submission_rfgs_up1.to_csv(\"submission_rfgs_up1.csv\",index=False)","ed69274f":"cv_rfc_up2 = GridSearchCV(estimator=rfcv0, param_grid=param_grid_2, cv= 5)\ncv_rfc_up2.fit(Xs_train, ys_train)","e2f1d883":"cv_rfc_up2.best_params_","1339d8ac":"rfc_up2=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 120, max_depth=16, criterion='gini')\nrfc_up2.fit(Xs_train, ys_train)","90734168":"pred_rfgs_up2_train = rfc_up2.predict(Xs_train)\npred_rfgs_up2 = rfc_up2.predict(Xs_val)\nconfusion_matrix(ys_val, pred_rfgs_up2)","3a3668b3":"recall_score(ys_val, pred_rfgs_up2)","0a317f43":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)\ntest['MULTIPLE_OFFENSE'] = rfc_up2.predict(test)\ntest['INCIDENT_ID'] = testdf['INCIDENT_ID']","ce5669ce":"submission_rfgs_up2 = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_rfgs_up2.head()","291e4399":"# submission_rfgs_up2.to_csv(\"submission_rfgs_up2.csv\",index=False)","f2f76a00":"param_grid_3 = { \n    'n_estimators': [80,100,110,120,130,140,150,180],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [8,10,12,14,16],\n    'criterion' :['gini', 'entropy']\n}","21d9181d":"cv_rfc_down = GridSearchCV(estimator=rfcv0, param_grid=param_grid_3, cv= 5)\ncv_rfc_down.fit(Xsd_train, ysd_train)","ffa50054":"cv_rfc_down.best_params_","dec71030":"rfc_down=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 130, max_depth=12, criterion='gini')\nrfc_down.fit(Xsd_train, ysd_train)","782f7093":"pred_rfgs_down = rfc_down.predict(Xsd_val)\nconfusion_matrix(ysd_val, pred_rfgs_down)","9feed011":"recall_score(ysd_val, pred_rfgs_down)","53f191fa":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)\ntest['MULTIPLE_OFFENSE'] = rfc_down.predict(test)\ntest['INCIDENT_ID'] = testdf['INCIDENT_ID']","3fb72d36":"submission_rfgs_down = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_rfgs_down.head()","52b9e9dd":"# submission_rfgs_down.to_csv(\"submission_rfgs_down.csv\",index=False)","dd51fa2e":"from sklearn.ensemble import VotingClassifier","d611d2c5":"model = VotingClassifier(estimators = [('rf1', rfc_up2), ('rf2', rfc_down)], voting = 'hard')","01f52d4d":"model.fit(X_train, y_train)","0e1f3651":"ensemble_pred = model.predict(X_val)\nconfusion_matrix(y_val, ensemble_pred)","4101738c":"recall_score(y_val, ensemble_pred)","50e0b04d":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)\ntest['MULTIPLE_OFFENSE'] = model.predict(test)\ntest['INCIDENT_ID'] = testdf['INCIDENT_ID']","e0dfb17a":"submission_ensemble = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_ensemble.head()","6b11a446":"# submission_ensemble.to_csv(\"submission_ensemble.csv\",index=False)","860bc9db":"!pip install lightgbm","8664dcd7":"import lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV\nclf = lgb.LGBMClassifier(silent=True, random_state = 333, metric='recall', n_jobs=4)","bc563c90":"params ={'cat_smooth' : sp_randint(1, 100), 'min_data_per_group': sp_randint(1,1000), 'max_cat_threshold': sp_randint(1,100)}","2020a2cf":"fit_params={\"eval_metric\" : 'recall', \n            \"eval_set\" : [(Xs_train, ys_train),(Xs_val,ys_val)],\n            'eval_names': ['train','valid'],\n            'verbose': 200,\n            'categorical_feature': 'auto'}","d342e192":"gs = RandomizedSearchCV( estimator=clf, param_distributions=params, scoring='recall',\n                        cv=5, refit=True,random_state=333,verbose=True)","d9eaf7d0":"gs.fit(Xs_train, ys_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))","f7ce7928":"gs.best_params_, gs.best_score_","8fa35427":"clf2 = lgb.LGBMClassifier(**clf.get_params())\nclf2.set_params(**gs.best_params_)","8a8dde13":"params_2 = {'learning_rate': [0.08, 0.09, 0.5, 0.85, 0.9],   \n            'num_iterations': sp_randint(500,3000)}","a57930c9":"gs2 = RandomizedSearchCV( estimator=clf2, param_distributions=params_2, scoring='recall',\n                        cv=5, refit=True,random_state=333,verbose=True)","a73e49c0":"gs2.fit(Xs_train, ys_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs2.best_score_, gs2.best_params_))","b2a1a781":"gs2.best_params_, gs2.best_score_","b8a4b86b":"clf3 = lgb.LGBMClassifier(**clf2.get_params())\nclf3.set_params(**gs2.best_params_)","a8f36ae9":"params_3 = {'colsample_bytree': sp_uniform(loc=0.4, scale=0.6), 'num_leaves': sp_randint(500, 5000), \n            'min_child_samples': sp_randint(100,500), 'min_child_weight': [1e-2, 1e-1, 1, 1e1]}","e4dbc27d":"gs3 = RandomizedSearchCV(estimator=clf3, param_distributions=params_3, scoring='recall',\n                        cv=5, refit=True,random_state=333,verbose=True)","97457122":"gs3.fit(Xs_train, ys_train, **fit_params)\nprint('Best score reached: {} with params: {}'.format(gs3.best_score_, gs3.best_params_))","6e4e4831":"gs3.best_params_, gs3.best_score_","dd860bdb":"clf4 = lgb.LGBMClassifier(**clf3.get_params())\nclf4.set_params(**gs3.best_params_)","52e0ce4c":"params_4 = {'max_bin': sp_randint(100, 1500), 'max_depth': sp_randint(1, 15), \n            'min_data_in_leaf': sp_randint(500,3500)}","441a43df":"gs4 = RandomizedSearchCV(estimator=clf4, param_distributions=params_4, scoring='recall',\n                        cv=5, refit=True,random_state=333,verbose=True)","8c655e17":"gs4.fit(Xs_train, ys_train, **fit_params)\nprint('Best score reached: {} with params: {}'.format(gs4.best_score_, gs4.best_params_))","acb78608":"gs4.best_params_, gs4.best_score_","8b1c7c13":"clf5 = lgb.LGBMClassifier(**clf4.get_params())\nclf5.set_params(**gs4.best_params_)","ca34412c":"params_5 = {'reg_lambda': sp_randint(1, 30), 'boosting': ['goss', 'dart']}","2df4df21":"gs5 = RandomizedSearchCV(estimator=clf5, param_distributions=params_5, scoring='recall',\n                        cv=5, refit=True,random_state=333,verbose=True)","c7a15d93":"gs5.fit(Xs_train, ys_train, **fit_params)\nprint('Best score reached: {} with params: {}'.format(gs5.best_score_, gs5.best_params_))","f56d08a4":"gs5.best_params_, gs5.best_score_","ba5a74ae":"clf6 = lgb.LGBMClassifier(**clf5.get_params())\nclf6.set_params(**gs5.best_params_)","1b03a022":"params_6 = {'bagging_fraction': [0.2, 0.4, 0.6, 0.8, 1], 'feature_fraction': [0.2, 0.4, 0.6, 0.8, 1]}","37ca0aa2":"gs6 = RandomizedSearchCV(estimator=clf6, param_distributions=params_6, scoring='recall',\n                        cv=5, refit=True,random_state=333,verbose=True)","519e86fb":"gs6.fit(Xs_train, ys_train, **fit_params)\nprint('Best score reached: {} with params: {}'.format(gs6.best_score_, gs6.best_params_))","b8fafbed":"gs6.best_params_, gs6.best_score_","03e39617":"clf_final = lgb.LGBMClassifier(**clf6.get_params())\n\nclf_final.fit(Xs_train, ys_train, **fit_params)","db7c8a3c":"feat_imp = pd.Series(clf_final.feature_importances_, index=train_upsampled.drop(['MULTIPLE_OFFENSE'], \n                                                                                axis=1).columns)\nfeat_imp.nlargest(20).plot(kind='barh', figsize=(8,10))","85e3fdbd":"lgbm_pred = clf_final.predict(Xs_val, pred_contrib=False)\nconfusion_matrix(ys_val, lgbm_pred)","db016b85":"final_params = {**gs.best_params_, **gs2.best_params_, **gs3.best_params_, **gs4.best_params_, **gs5.best_params_, \n               **gs6.best_params_, 'scoring':'recall', 'metric':'recall', 'objective': 'binary'}\nfinal_params","b124c468":"recall_score(ys_val, lgbm_pred)","f4183bdb":"test = test.drop(['MULTIPLE_OFFENSE', 'INCIDENT_ID'], axis = 1)\ntest['MULTIPLE_OFFENSE'] = clf_final.predict(test, pred_contrib=False)\ntest['INCIDENT_ID'] = testdf['INCIDENT_ID']","344f3944":"submission_lgbm = test[['INCIDENT_ID', 'MULTIPLE_OFFENSE']]\nsubmission_lgbm.head()","ec28aa74":"# submission_lgbm.to_csv(\"submission_lgbm2.csv\",index=False)","cd269388":"[Home](#home) <a href = '#home'><\/a>","e41185df":"<a id = 'home' ><\/a>","36932046":"1. [**Libraries and Analyzing the Data**](#Libraries) <a href = '#Libraries'><\/a>\n2. [**Converting Data and Analyzing Null Values**](#convert) <a href = '#convert'><\/a>\n3. [**Initial Plots and Observations**](#plot) <a href = '#plot'><\/a>\n    - **Correlation Plot**\n        - Two pairs with high correlation appear: (X_6 & X_7) and (X_10 & X_12)\n        - X_6 & X_7 relation to be used later in the analysis by either FE or elimination\n        - X_10 & X_12 relation to be used for one of the methods of imputation for X_12\n    - [**Checking Target Variable Frequencies**](#target) <a href = '#target'><\/a>\n        - MULTIPLE_OFFENSE = 0 is <5% of the total observations\n        - Noted for treatment for Class Imbalance\n    - [**Frequencies of X_ variables**](#xvar) <a href = '#xvar'><\/a>\n        - X_2 & X_3 have same set of counts but a part of the set belonging to different values\n        - X_6 & X_7 have same set of counts but a part of the set belonging to different values\n        - Spikes observed maybe in line with the X_ variables indicating logging parameters\n4. [**Imputation**](#impute) <a href = '#impute'><\/a>\n    - [**Imputing X_12 with value 1**](#impute1) <a href = '#impute1'><\/a>\n        -  Analyzing this imputation in line with X_10 and most occuring value\n5. [**Data Preparation**](#prep) <a href = '#prep'><\/a>\n    - [**Resampling - Upsample minority class**](#upmin) <a href = '#upmin'><\/a>\n    - [**Resampling - Downsample majority class**](#downmaj) <a href = '#downmaj'><\/a>\n6. [**Model Building**](#model) <a href = '#model'><\/a>\n    - [**A. Logistic Regression**](#logreg) <a href = '#logreg'><\/a>\n    - [**B. Random Forest**](#rf) <a href = '#rf'><\/a>\n        -  [**RF with Grid Search and CV**](#rfgs) <a href = '#rfgs'><\/a>\n        -  [**RF with Grid Search and CV on Upsampled Data**](#rfgs_up) <a href = '#rfgs_up'><\/a>\n        -  [**RF with Grid Search and CV on Downsampled Data**](#rfgs_down) <a href = '#rfgs_down'><\/a>\n        -  [**Ensemble of RFs on Up and Down - sampled Data**](#ens) <a href = '#ens'><\/a>       \n    - [**C. LGBM**](#lgbm) <a href = '#lgbm'><\/a>  \n        -  [**Final Params**](#fp) <a href = '#fp'><\/a>   ","3c741d64":"### RF with Grid Search and CV on Upsampled Data <a id = 'rfgs_up' ><\/a>","d6ef6551":"#### Grid Search for 'reg_lambda', 'boosting' ","f8020a6e":"### C. LGBM on Upsampled data <a id = 'lgbm' ><\/a>","75d1e4a8":"[Home](#home) <a href = '#home'><\/a>","7b1943f1":"[Home](#home) <a href = '#home'><\/a>","904bcbcc":"[Home](#home) <a href = '#home'><\/a>","bac2c804":"#### On upsampled data","fc19dde7":"[Home](#home) <a href = '#home'><\/a>","8ff27ab4":"### RF with Grid Search and CV on Downsampled Data <a id = 'rfgs_down' ><\/a>","18f38305":"#### Grid Search for 'cat_smooth', 'min_data_per_group', and 'max_cat_threshold'","561b8be0":"[Home](#home) <a href = '#home'><\/a>","abb025d1":"#### For the downsampled data","bea9625a":"### Resampling - Upsample minority class <a id = 'upmin' ><\/a>","f384cc27":"#### Dropping INCIDENT_ID","b711c967":"### [**Submission Summary**](#ss) <a href = '#ss'><\/a>","604b5e93":"#### Correlation Plot\n- Two pairs with high correlation appear: (X_6 & X_7) and (X_10 & X_12)\n- X_6 & X_7 relation to be used later in the analysis by either FE or elimination\n- X_10 & X_12 relation to be used for one of the methods of imputation for X_12","836ad464":"[Home](#home) <a href = '#home'><\/a>","20f47143":"## 5. Data Preparation <a id = 'prep' ><\/a>","0e2605ce":"#### Converting target variable to Categorical","c2f3c699":"## Content","5e83a0bd":"[Home](#home) <a href = '#home'><\/a>","29011004":"## 4. Imputation <a id = 'impute' ><\/a>","8b907154":"[Home](#home) <a href = '#home'><\/a>","cf50d3cb":"[Home](#home) <a href = '#home'><\/a>","5ab3094d":"### Ensemble of RFs on Up and Down - sampled Data <a id = 'ens' ><\/a>","b30a0207":"#### Checking for Columns with either single value or all unique values","2eb867ff":"#### Checking row wise NAs for test","87d92781":"## 2. Converting Data and Analyzing Null Values <a id = 'convert' ><\/a>\n- No need to drop column\/s based on existing null values","abacaef6":"[Home](#home) <a href = '#home'><\/a>","28ea16bf":"#### Analyzing X_10 and X_12 for Train data","9ce2c9dc":"#### Second combo","0da37283":"#### Checking row wise NAs for traindf","d523a06d":"[Home](#home) <a href = '#home'><\/a>","a19e26cc":"#### Grid Search for 'max_bin', 'max_depth', 'min_data_in_leaf'","a9c9e8e9":"#### Analyzing X_10 and X_12 for Test data","092ab568":"#### Second combo","3c8fe548":"## 1. Libraries and Analyzing the Data <a id = 'Libraries' ><\/a>","1a60aa84":"### Resampling - Downsample majority class <a id = 'downmaj' ><\/a>","223798a7":"### Imputing X_12 with value 1 <a id = 'impute1' ><\/a>","f4c2032c":"[Home](#home) <a href = '#home'><\/a>","76573a91":"#### Frequency Plots of X_ variables <a id = 'xvar' ><\/a>","61743ed3":"## Submission Summary <a id = 'ss' ><\/a>\n- Submission 1: Logistic Regression       - **56.07**\n- Submission 2: Random Forest             - **88.85**\n- Submission 3: Random Forest Grid Search - **77.99**\n    - criterion': 'entropy',  'max_depth': 10,  'max_features': 'auto',  'n_estimators': 100\n- Submission 4: Random Forest Grid Search - **84.29**\n    - 'criterion': 'gini',  'max_depth': 16,  'max_features': 'auto', 'n_estimators': 80\n- Submission 5: Random Forest on Upsampled data - **92.95**\n    - criterion='gini', max_depth=16, max_features='auto', n_estimators= 80\n- Submission 6: Random Forest with GS & CV on Upsampled data - **97.46**  \n    - criterion='entropy', max_depth=10, max_features='auto', n_estimators= 150\n- Submission 7: Random Forest with GS & CV on Upsampled data - **97.46**  \n    - criterion='gini', max_depth=16, max_features='auto', n_estimators= 130\n- Submission 8: Random Forest with GS & CV on Downsampled data - **94.67**  \n    - criterion='gini', max_depth=12, max_features='auto', n_estimators= 130   \n- Submission 9: Ensemble of RFs on Up and Down - sampled data - **84.91**    \n- Submission 10: Random Forest on Upsampled data with new set of Car var defined - **95.14**   \n- Submission 11: Random Forest Grid Search with new set of Car var defined - **93.83**\n    - 'criterion': 'gini',  'max_depth': 16,  'max_features': 'auto', 'n_estimators': 80\n- Submission 12: Random Forest with GS & CV on Upsampled data with new set of Car var defined - **98.35**  \n    - criterion='entropy', max_depth=10, max_features='auto', n_estimators= 100\n- Submission 13: Random Forest with GS & CV on Upsampled data with new set of Car var defined - **97.86**  \n    - criterion='entropy', max_depth=10, max_features='auto', n_estimators= 120\n- Submission 14: LGBM Randomized Search on Upsampled data with new set of Car var defined - **99.41**  \n    - hard coded bagging_fraction and feature_fraction\n- Submission 15: LGBM Randomized Search on Upsampled data with new set of Car var defined - **99.56**  \n    - with GS on bagging_fraction and feature_fraction\n    - for the set of hyperparameters please refer to [final_params](#fp) <a href = '#fp'><\/a> ","d4acc003":"#### Checking Target Variable Frequencies <a id = 'target' ><\/a>\n- MULTIPLE_OFFENSE = 0 is <5% of the total observations\n- Noted for treatment for Class Imbalance","c6631520":"#### Converting DATE to Date","98431601":"[Home](#home) <a href = '#home'><\/a>","b86fea7e":"[Home](#home) <a href = '#home'><\/a>","afa60512":"#### Grid Search for 'colsample_bytree', 'num_leaves', 'min_child_samples', 'min_child_weight'","cb48d196":"[Home](#home) <a href = '#home'><\/a>","35347d67":"#### Checking column wise NAs for traindf","57b13e64":"### A. Logistic Regression <a id = 'logreg' ><\/a>","8be7d3ed":"#### Grid Search for 'learning_rate' & 'num_iterations'","f13724c8":"#### Extracting information from DATE column before dropping","ec258729":"#### Final Params <a id = 'fp' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","82c58ffa":"[Home](#home) <a href = '#home'><\/a>","24f1c7b3":"### B. Random Forest <a id = 'rf' ><\/a>","488dc664":"## 3. Initial Plots and Observations <a id = 'plot' ><\/a>","68242c4d":"#### Checking column wise NAs for test","2dd726c9":"#### Final Build","a10b330c":"### RF with Grid Search and CV <a id = 'rfgs' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","adaac512":"# Multiple Offense Analysis - Updated","0e625ecd":"[Home](#home) <a href = '#home'><\/a>","ef4817ca":"[Home](#home) <a href = '#home'><\/a>","2e7a4de2":"## 6. Model Building <a id = 'model' ><\/a>","ce02e59a":"[Home](#home) <a href = '#home'><\/a>","43800e67":"#### Defining Categorical Variables for Label Encoding","de78380a":"#### Grid Search for 'bagging_fraction' and 'feature_fraction'","25fde1f4":"#### For the upsampled data","48057d29":"[Home](#home) <a href = '#home'><\/a>"}}