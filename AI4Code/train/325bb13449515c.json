{"cell_type":{"4119e338":"code","f011172e":"code","ff1cc8d9":"code","9156ae8d":"code","f5c89e1d":"code","8b266717":"code","e23ff4d1":"code","7532c218":"code","be1c2dc9":"code","c0c83b1f":"code","e8020c11":"code","fe96a8ea":"code","d6362e04":"code","37b7d1d3":"code","d8331861":"markdown","bcfae60a":"markdown","12a858ee":"markdown","582a1d4a":"markdown","7efeb9f8":"markdown","3dd5f37c":"markdown"},"source":{"4119e338":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\/gulvslimon\/\"))","f011172e":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu',\n                       input_shape = (150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))","ff1cc8d9":"model.summary()","9156ae8d":"from keras import optimizers\n\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics = ['acc'])\n","f5c89e1d":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain=\"..\/input\/gulvslimon\/train\"\nvalidation=\"..\/input\/gulvslimon\/validation\"\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                    train,\n                    target_size = (150, 150),\n                    batch_size = 20,\n                    class_mode = 'binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                        validation,\n                        target_size = (150, 150),\n                        batch_size = 20,\n                        class_mode = 'binary')","8b266717":"for data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break","e23ff4d1":"history = model.fit_generator(\n                train_generator,\n                steps_per_epoch = 20,\n                epochs = 12,\n                validation_data = validation_generator,\n                validation_steps = 10)","7532c218":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label = 'Training acc')\nplt.plot(epochs, val_acc, 'b', label = 'Validation acc')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","be1c2dc9":"train_datagen = ImageDataGenerator(\n                rescale = 1.\/255,\n                rotation_range=40,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                train,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                                validation,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode = 'binary')\n\nhistory = model.fit_generator(\n                            train_generator,\n                            steps_per_epoch = 20,\n                            epochs = 12,\n                            validation_data = validation_generator,\n                            validation_steps = 10)","c0c83b1f":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()","e8020c11":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])\n\ntrain_datagen = ImageDataGenerator(\n                rescale = 1.\/255,\n                rotation_range=40,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                train,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                                validation,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode = 'binary')\n\nhistory = model.fit_generator(\n                            train_generator,\n                            steps_per_epoch = 20,\n                            epochs = 12,\n                            validation_data = validation_generator,\n                            validation_steps = 10)","fe96a8ea":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()","d6362e04":"train_datagen = ImageDataGenerator(\n                rescale = 1.\/255,\n                rotation_range=40,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                train,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                                validation,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode = 'binary')\n\nhistory = model.fit_generator(\n                            train_generator,\n                            steps_per_epoch = 20,\n                            epochs = 8,\n                            validation_data = validation_generator,\n                            validation_steps = 10)","37b7d1d3":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()","d8331861":"# **A\u015f\u015fa\u011f\u0131da dropout + augmantation uygulanm\u0131\u015ft\u0131r**","bcfae60a":"# **A\u015f\u015fa\u011f\u0131da Augmentetaion i\u015flemi uygulanm\u0131\u015ft\u0131r**","12a858ee":"# **Birazdan a\u015f\u015fa\u011f\u0131da CNN-maxpool olay\u0131 ger\u00e7ekle\u015fecektir**","582a1d4a":"# **A\u015f\u015fa\u011f\u0131da ise overfit olan noktada epoch kesme uygulanmaktad\u0131r.**","7efeb9f8":"# \u0130SMA\u0130L TALHA \u00c7AVU\u015e -- 162803022 -- II. \u00d6\u011eRET\u0130M\n","3dd5f37c":"# DATASET DROPBOX L\u0130NK\u0130\n# https:\/\/www.dropbox.com\/sh\/72gbwjojeh8448x\/AAAG-FKHVyiMWXhosvABsKjpa?dl=0"}}