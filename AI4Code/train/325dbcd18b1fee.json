{"cell_type":{"9c5cec3e":"code","dfeb2946":"code","724d2b17":"code","93afa8f2":"code","a212b056":"code","d77de5a1":"code","937a261b":"code","b892493c":"code","cc46648c":"code","cdef916f":"code","1f791cf3":"code","baf31892":"code","34fadf05":"code","6a232bce":"code","e32099af":"code","74f140e5":"code","d0f877da":"code","f10eb884":"code","ecbfd637":"code","9c93a78f":"code","8a91d8d3":"code","4bedefb6":"code","7819461a":"code","5ecf28bd":"code","8fbb95fd":"code","1c7d2596":"markdown","fcaab557":"markdown","40fb9d76":"markdown","01ae2727":"markdown","778798be":"markdown","10635342":"markdown","ef633779":"markdown","27d3782f":"markdown","9704a798":"markdown","ccd940b6":"markdown","575eae42":"markdown","543e8382":"markdown"},"source":{"9c5cec3e":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec \nimport seaborn as sns\nfrom PIL import ImageDraw\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')\n\nimport ast","dfeb2946":"train = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/train.csv')\ntest = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/test.csv')\nsample = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/example_sample_submission.csv')","724d2b17":"train.shape","93afa8f2":"train.head()","a212b056":"train.tail()","d77de5a1":"train.info()","937a261b":"train.duplicated().sum()","b892493c":"train['video_id'].nunique()","cc46648c":"train['video_id'].value_counts()","cdef916f":"sns.set_theme(style=\"whitegrid\")\nax = sns.countplot(x='video_id', data=train)","1f791cf3":"for i in range(3):\n    print(\"Video \" + str(i))\n    print(\"Frames with Annotations : \" + str((train[train['video_id'] == i]['annotations'] != '[]').sum()) )\n    print(\"Frames without Annotations : \" + str((train[train['video_id'] == i]['annotations'] == '[]').sum()) )\n    print(\"---------\")","baf31892":"train.iloc[16].annotations\n# Note the below result is string. We need to convert it to list","34fadf05":"# Convert String to List Type\ntrain['annotations'] = train['annotations'].apply(ast.literal_eval)","6a232bce":"train.iloc[16].annotations\n","e32099af":"train['num_bboxes'] = train['annotations'].apply(lambda x: len(x))","74f140e5":"train['num_bboxes'].value_counts()","d0f877da":"print('Total rows without annotations : {}'.format(train[train['num_bboxes'] == 0]['num_bboxes'].count()))","f10eb884":"plt.figure(figsize = (15,8))\nsns.countplot(x=train[train['num_bboxes'] > 0].num_bboxes,data=train)","ecbfd637":"train[train['annotations'].str.len() > 2]","9c93a78f":"from os import listdir\nfrom PIL import Image\n\ndef validate_images(video_id):\n    path = '\/kaggle\/input\/tensorflow-great-barrier-reef\/train_images\/video_{}\/'.format(video_id)\n    \n    print(\"Verifying that video {} frames are valid...\".format(video_id))\n    for filename in listdir(path):\n        if filename.endswith('.jpg'):\n            try:\n                img = Image.open(path+filename)\n                img.verify() # Verify it is in fact an image\n            except (IOError, SyntaxError) as e:\n                print('Bad file:', filename) # Print out the names of corrupt files\n    print(\"Verified! Video {} has all valid images\".format(video_id))\n\n# for video_id in range(3):\n#     validate_images(video_id)","8a91d8d3":"def fetch_image(df, video_id, frame_id):\n    # get frame\n    frame = df[(df['video_id'] == video_id) & (df['video_frame'] == frame_id)].iloc[0]\n    # get bounding_boxes\n    bounding_boxes = frame['annotations']\n    # open image\n    img = Image.open('\/kaggle\/input\/tensorflow-great-barrier-reef\/' + f'train_images\/video_{video_id}\/{frame_id}.jpg')\n\n    for box in bounding_boxes:\n        x0, y0, x1, y1 = (box['x'], box['y'], box['x']+box['width'], box['y']+box['height'])\n        draw = ImageDraw.Draw(img)\n        draw.rectangle( (x0, y0, x1, y1), outline=180, width=5)\n    return img\n\ndef fetch_image_list(df, video_id, num_images, start_frame_idx):\n    image_list = [np.array(fetch_image(df, video_id, start_frame_idx + index)) for index in range(num_images)]\n\n    return image_list","4bedefb6":"# images = fetch_image_list(train, video_id=2, num_images=5000, start_frame_idx=100)\nimages = fetch_image_list(train, video_id=0, num_images=200, start_frame_idx=100)\n\n\nprint(f'Number of images: {len(images)}')","7819461a":"grid = gridspec.GridSpec(4, 2) \nplt.figure(figsize=(18, 20))\n\nidx_list = [0, 5, 10, 15, 20, 25, 30, 35] \n\nfor i, idx in enumerate(idx_list): \n    ax = plt.subplot(grid[i])\n    plt.imshow(images[idx], interpolation='nearest')\n    ax.set_title(f'frame index {idx}')\n    plt.axis('off')","5ecf28bd":"def create_animation(imgs, frame_interval=130):\n    fig = plt.figure(figsize=(7, 4))\n    plt.axis('off')\n    img = plt.imshow(imgs[0])\n\n    def animate(i):\n        img.set_array(imgs[i])\n        return [img]\n\n    return animation.FuncAnimation(fig, animate, frames=len(imgs), interval=frame_interval)","8fbb95fd":"frame_interval = 190 # set smaller number if you want to play fast, otherwise set bigger\n\ncreate_animation(images, frame_interval=frame_interval)","1c7d2596":"# Analyze","fcaab557":"# References\n* Thanks to DIEGO GOMEZ & BAEK KYUN SHIN\n* https:\/\/www.kaggle.com\/diegoalejogm\/great-barrier-reefs-eda-with-animations\n* https:\/\/www.kaggle.com\/werooring\/basic-eda-starter-for-everyone","40fb9d76":"### Lets create a feature which have info about number of annotations per image","01ae2727":"### Not all the images have Crown-Of-Thorns Starfish (COTS) for which we have annotations as []","778798be":"# Visualize COTS Annimation","10635342":"# Load data","ef633779":"### As you can see, we have totally 3 videos in the training dataset. Now lets see row count for each videos","27d3782f":"# Imports","9704a798":"### Lets see the distribution of number of COTS per image","ccd940b6":"# Validate Images","575eae42":"### Checking Duplicates","543e8382":"# Feature Engineering"}}