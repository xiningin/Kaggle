{"cell_type":{"8e6c2698":"code","7100752e":"code","8654afff":"code","190cb964":"code","5888082b":"code","a1839e44":"code","3b429b04":"code","8f27eb4d":"code","b1108e56":"code","b21900cb":"code","1976849a":"code","a70c1fd7":"code","412a7f16":"code","fad885c3":"code","1e12d421":"code","1cfeadcb":"code","8f21201b":"code","7270d13a":"code","71643f25":"code","884c8831":"code","fe71f23d":"code","a9fad5fe":"code","bf635da7":"code","f74a81b9":"code","151d2cde":"code","71610159":"code","0bde3110":"code","4cf73a28":"code","97298d3c":"code","c56970d9":"code","63b945ca":"code","04b10e0e":"code","f5567965":"code","33f4e03c":"code","363f1cfa":"code","96d05ddf":"code","6100e5b5":"code","742bfdee":"code","bc4acf08":"code","9e89c4b2":"code","ef151c1b":"code","fb4abf75":"markdown","7a884182":"markdown","39196f7c":"markdown","05e5356c":"markdown","24c74c10":"markdown","e4189848":"markdown","f8b6b753":"markdown","cd97707a":"markdown","731c211b":"markdown","d60cf3e4":"markdown","c4e36022":"markdown","3b1c3f86":"markdown","64cd8896":"markdown","af4c270f":"markdown","1a58ed4b":"markdown","67e3c7a4":"markdown","7dd1b8f8":"markdown","59d3abcf":"markdown","4cbeb276":"markdown","9f961b14":"markdown","a94685d1":"markdown","1eb3d47a":"markdown","4cbec782":"markdown","e35092fb":"markdown","d64427e7":"markdown","1346e0c5":"markdown","947fc4c9":"markdown","3e335100":"markdown","27e2c404":"markdown","f79d2033":"markdown","61a66200":"markdown","0fb09c7d":"markdown","91d9e5b5":"markdown","d33b8615":"markdown","e4824baa":"markdown","8d1fcba3":"markdown","c4a26138":"markdown","4bb09329":"markdown","13b4c5e9":"markdown","377ab407":"markdown","3534fb43":"markdown","3cefd0cc":"markdown","38458c16":"markdown","a805a8ff":"markdown","8fa56aa0":"markdown","05059b15":"markdown","81c0aadd":"markdown","81e1dc28":"markdown","a32b273c":"markdown","bcd3e82e":"markdown","ca444e0c":"markdown","ae748d59":"markdown"},"source":{"8e6c2698":"import pandas as pd\nimport keras\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, GlobalAveragePooling2D\nfrom keras import backend as K\nimport os\nimport numpy as np\nfrom numpy.random import seed\nimport json\nfrom collections import Counter\nfrom keras.optimizers import SGD\nfrom PIL import Image\nfrom PIL import ImageEnhance\nfrom PIL import ImageFilter\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image as Image2\nfrom IPython.display import display\nfrom matplotlib.pyplot import imshow\nimport urllib\nfrom tensorflow import set_random_seed\nimport tensorflow as tf\nfrom scipy.spatial import distance_matrix","7100752e":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","8654afff":"working_path = 'd:\/projects\/python\/dupe_image_pred\/'\nos.chdir(working_path)\n\nseed(1)\nset_random_seed(2)","190cb964":"# change working directory\nos.chdir(working_path+'\/Images\/Sample_Goose')\n\n# get list of images (.jpg only)\nsample_images = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n\n# initialize\nlabels = []\ndupe = []\nidx_to_labels = []\nlabel_to_idx = {}\n\n# iterate\nfor fn in sample_images:\n    if not fn in label_to_idx:\n        label_to_idx[fn] = len(idx_to_labels)\n        idx_to_labels.append(fn)\n    labels.append(label_to_idx[fn])\n    dupe.append(int(fn.replace('.jpg','').rsplit('_', 2)[2]))\nlen(idx_to_labels)\n\nprint('')\nprint('Number of images: ')\nprint(len(sample_images))\nprint('')\nprint('Sample images used: ')\nprint([i for i in idx_to_labels])\nprint('')","5888082b":"for pic in sample_images:\n    display(Image2(pic, width = 150))\n    print(pic)","a1839e44":"dupe","3b429b04":"for i in range(0,len(sample_images)): \n    os.chdir(working_path+'\/Images\/Sample_Goose')\n    image_name = sample_images[i]\n    temp_load = Image.open(image_name,'r')\n    temp_load = temp_load.resize( (299,299), Image.ANTIALIAS )\n    temp_load = temp_load.convert('L') # converts to monochrome\n    temp_load = temp_load.convert('1') # converts to black and white\n    os.chdir(working_path+'\/Images\/Sample_Goose\/Norm')\n    temp_load.save(image_name, temp_load.format)\n    temp_load.close()\n    \nos.chdir(working_path+'\/Images\/Sample_Goose\/Norm')\n         \nsample_images_rs = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n         \norg_img_count = len(sample_images)\nrs_img_count = len(sample_images_rs)\n\nprint('\\n Original Images: ' + str(org_img_count) + '\\n Resized Images: ' + str(rs_img_count))","8f27eb4d":"for pic in sample_images_rs:\n    display(Image2(pic, width = 150))\n    print(pic)","b1108e56":"os.chdir(working_path+'\/Images\/Sample_Goose\/Norm')\n\nw_min = 1000\nh_min = 1000\nfor i in range(1,len(sample_images_rs)):\n    temp_img = Image.open(sample_images_rs[i])\n    w, h = temp_img.size\n    if w < w_min:\n        w_min = w\n    if h < h_min:\n        h_min = h\n    \nprint('\\n Minimum image width: ' + str(w_min))\nprint('\\n Minimum image height: ' + str(h_min) + '\\n' )\n\nfor pic in sample_images_rs: \n    temp_img = Image.open(pic)\n    print(pic + ' ' + str(temp_img.size))\n\nprint('\\n')","b21900cb":"# trainable = False is import because we'll be using this system for features but not output\n\nbase_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\nfor layer in base_model.layers:\n    layer.trainable = False","1976849a":"pool_2d = GlobalAveragePooling2D(name='pool_2d')(base_model.output)\ndense = Dense(1024, name='dense', activation='relu')(pool_2d)\npredictions = Dense(1000, activation='relu')(dense)\nmodel = Model(inputs=base_model.input, outputs=predictions)","a70c1fd7":"os.chdir(working_path+'\/Images\/Sample_Goose\/Norm')\n\nuse_images = [image.load_img(c, target_size=(299,299))\n         for c in sample_images]\n\nuse_tensor = np.array([image.img_to_array(img) for img in use_images])","412a7f16":"model_output = model.predict(use_tensor, batch_size=32, verbose=1)","fad885c3":"model_output.shape","1e12d421":"df = pd.DataFrame(model_output, index = sample_images)","1cfeadcb":"dist_mat = pd.DataFrame(distance_matrix(df.values,df.values),index=df.index,columns=df.index)","8f21201b":"dist_mat","7270d13a":"# change working directory\nos.chdir(working_path+'\/Images\/Sample_Sadie')\n\n# get list of images (.jpg only)\nsadie_images = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n\n# initialize\nsadie_labels = []\nsadie_dupe = []\nsadie_idx_to_labels = []\nsadie_label_to_idx = {}\n\n# iterate\nfor fn in sadie_images:\n    if not fn in sadie_label_to_idx:\n        sadie_label_to_idx[fn] = len(sadie_idx_to_labels)\n        sadie_idx_to_labels.append(fn)\n    sadie_labels.append(sadie_label_to_idx[fn])\n    sadie_dupe.append(int(fn.replace('.jpg','').rsplit('_', 2)[2]))\nlen(sadie_idx_to_labels)\n\nprint('')\nprint('Number of images: ')\nprint(len(sadie_images))\nprint('')\nprint('Sample images used: ')\nprint([i for i in sadie_idx_to_labels])\nprint('')","71643f25":"for pic in sadie_images:\n    display(Image2(pic, width = 150))\n    print(pic)","884c8831":"# change working directory\nos.chdir(working_path+'\/Images\/Sample_Goose2')\n\n# get list of images (.jpg only)\ngoose2_images = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n\n# initialize\ngoose2_labels = []\ngoose2_dupe = []\ngoose2_idx_to_labels = []\ngoose2_label_to_idx = {}\n\n# iterate\nfor fn in goose2_images:\n    if not fn in goose2_label_to_idx:\n        goose2_label_to_idx[fn] = len(goose2_idx_to_labels)\n        goose2_idx_to_labels.append(fn)\n    goose2_labels.append(goose2_label_to_idx[fn])\n    goose2_dupe.append(int(fn.replace('.jpg','').rsplit('_', 2)[2]))\nlen(goose2_idx_to_labels)\n\nprint('')\nprint('Number of images: ')\nprint(len(goose2_images))\nprint('')\nprint('Sample images used: ')\nprint([i for i in goose2_idx_to_labels])\nprint('')","fe71f23d":"for pic in goose2_images:\n    display(Image2(pic, width = 150))\n    print(pic)","a9fad5fe":"for i in range(0,len(sadie_images)): \n    os.chdir(working_path+'\/Images\/Sample_Sadie')\n    image_name = sadie_images[i]\n    temp_load = Image.open(image_name,'r')\n    temp_load = temp_load.resize( (299,299), Image.ANTIALIAS )\n    temp_load = temp_load.convert('L') # converts to monochrome\n    temp_load = temp_load.convert('1') # converts to black and white\n    os.chdir(working_path+'\/Images\/Sample_Sadie\/Norm')\n    temp_load.save(image_name, temp_load.format)\n    temp_load.close()\n    \nos.chdir(working_path+'\/Images\/Sample_Sadie\/Norm')\n         \nsadie_images_rs = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n         \norg_img_count = len(sadie_images)\nrs_img_count = len(sadie_images_rs)\n\nprint('\\n Original Images: ' + str(org_img_count) + '\\n Resized Images: ' + str(rs_img_count))","bf635da7":"for i in range(0,len(goose2_images)): \n    os.chdir(working_path+'\/Images\/Sample_Goose2')\n    image_name = goose2_images[i]\n    temp_load = Image.open(image_name,'r')\n    temp_load = temp_load.resize( (299,299), Image.ANTIALIAS )\n    temp_load = temp_load.convert('L') # converts to monochrome\n    temp_load = temp_load.convert('1') # converts to black and white\n    os.chdir(working_path+'\/Images\/Sample_Goose2\/Norm')\n    temp_load.save(image_name, temp_load.format)\n    temp_load.close()\n    \nos.chdir(working_path+'\/Images\/Sample_Goose2\/Norm')\n         \ngoose2_images_rs = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n         \norg_img_count = len(goose2_images)\nrs_img_count = len(goose2_images_rs)\n\nprint('\\n Original Images: ' + str(org_img_count) + '\\n Resized Images: ' + str(rs_img_count))","f74a81b9":"os.chdir(working_path+'\/Images\/Sample_Sadie\/Norm')\n\nuse_images_sadie = [image.load_img(c, target_size=(299,299))\n         for c in sadie_images]\n\nuse_tensor_sadie = np.array([image.img_to_array(img) for img in use_images_sadie])\n\nmodel_output_sadie = model.predict(use_tensor_sadie, batch_size=32, verbose=1)\n\ndf_sadie = pd.DataFrame(model_output_sadie, index = sadie_images)\n\ndist_mat_sadie = pd.DataFrame(distance_matrix(df_sadie.values,df_sadie.values),index=df_sadie.index,columns=df_sadie.index)\n\ndist_mat_sadie","151d2cde":"os.chdir(working_path+'\/Images\/Sample_Goose2\/Norm')\n\nuse_images_goose2 = [image.load_img(c, target_size=(299,299))\n         for c in goose2_images]\n\nuse_tensor_goose2 = np.array([image.img_to_array(img) for img in use_images_goose2])\n\nmodel_output_goose2 = model.predict(use_tensor_goose2, batch_size=32, verbose=1)\n\ndf_goose2 = pd.DataFrame(model_output_goose2, index = goose2_images)\n\ndist_mat_goose2 = pd.DataFrame(distance_matrix(df_goose2.values,df_goose2.values),index=df_goose2.index,columns=df_goose2.index)\n\ndist_mat_goose2","71610159":"# create a temp dataframe\nstg_sadie = dist_mat_sadie\n\n# add a column for file name equal to the index, which enables the melt\nstg_sadie['File1']=stg_sadie.index\n\n# grab column names\nstg_cols = dist_mat_sadie.columns\n\n# complete the melt\nstg1 = pd.melt(stg_sadie, id_vars='File1',value_vars=stg_cols[stg_cols != 'File1'])\n\n# clean up column names\nstg1.columns = ['File1','File2','Distance']\n\n# remove rows where files are the same, which removes self duplicates\nstg2 = stg1[stg1.File1 != stg1.File2]\n\nfnl_sadie = stg2.groupby('File1')['Distance'].min()\n\nfnl_sadie","0bde3110":"vehicle_path = 'd:\/projects\/python\/TL_logos\/Vehicles\/'\nos.chdir(vehicle_path)\n\nvehicle_list = [n for n in os.listdir() if n.upper().endswith('.JPG')]\n\nfor i in range(0,len(vehicle_list)):\n    new_name = working_path + 'Images\/Sample_Vehicles\/' + 'Vehicle_' + str(i) + '_0.JPG'\n    old_name = vehicle_path + vehicle_list[i]\n    os.rename(old_name, new_name)","4cf73a28":"# change working directory\nos.chdir(working_path+'\/Images\/Sample_Vehicles')\n\n# get list of images (.jpg only)\nvehicles_images = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n\n# initialize\nvehicles_labels = []\nvehicles_dupe = []\nvehicles_idx_to_labels = []\nvehicles_label_to_idx = {}\n\n# iterate\nfor fn in vehicles_images:\n    if not fn in vehicles_label_to_idx:\n        vehicles_label_to_idx[fn] = len(vehicles_idx_to_labels)\n        vehicles_idx_to_labels.append(fn)\n    vehicles_labels.append(vehicles_label_to_idx[fn])\n    vehicles_dupe.append(int(fn.replace('.jpg','').replace('.JPG','').rsplit('_', 2)[2]))\nlen(vehicles_idx_to_labels)\n\nprint('')\nprint('Number of images: ')\nprint(len(vehicles_images))\n","97298d3c":"dupes_in_folder = 0 \n\nfor i in vehicles_images: \n    if i.endswith('1.JPG'):\n        print(i)\n        dupes_in_folder += 1\n\nprint('\\n Duplicates in the folder: ' + str(dupes_in_folder))\nprint('\\n We should see ' + str(dupes_in_folder * 2) + ' duplicates in the resulting list. ')","c56970d9":"for i in range(0,len(vehicles_images)): \n    os.chdir(working_path+'\/Images\/Sample_Vehicles')\n    image_name = vehicles_images[i]\n    temp_load = Image.open(image_name,'r')\n    temp_load = temp_load.resize( (299,299), Image.ANTIALIAS )\n    temp_load = temp_load.convert('L') # converts to monochrome\n    temp_load = temp_load.convert('1') # converts to black and white\n    os.chdir(working_path+'\/Images\/Sample_Vehicles\/Norm')\n    temp_load.save(image_name, temp_load.format)\n    temp_load.close()\n    \nos.chdir(working_path+'\/Images\/Sample_Vehicles\/Norm')\n         \nvehicles_images_rs = [fn for fn in os.listdir() if fn.upper().endswith('.JPG')]\n         \norg_img_count = len(vehicles_images)\nrs_img_count = len(vehicles_images_rs)\n\nprint('\\n Original Images: ' + str(org_img_count) + '\\n Resized Images: ' + str(rs_img_count))","63b945ca":"os.chdir(working_path+'\/Images\/Sample_Vehicles\/Norm')\n\nuse_images_vehicles = [image.load_img(c, target_size=(299,299))\n         for c in vehicles_images]\n\nuse_tensor_vehicles = np.array([image.img_to_array(img) for img in use_images_vehicles])\n\nmodel_output_vehicles = model.predict(use_tensor_vehicles, batch_size=32, verbose=1)\n\ndf_vehicles = pd.DataFrame(model_output_vehicles, index = vehicles_images)\n\ndist_mat_vehicles = pd.DataFrame(distance_matrix(df_vehicles.values,df_vehicles.values),index=df_vehicles.index,columns=df_vehicles.index)\n","04b10e0e":"# create a temp dataframe\nstg_vehicles = dist_mat_vehicles\n\n# add a column for file name equal to the index, which enables the melt\nstg_vehicles['File1']=stg_vehicles.index\n\n# grab column names\nstg_cols = dist_mat_vehicles.columns\n\n# complete the melt\nstg1 = pd.melt(stg_vehicles, id_vars='File1',value_vars=stg_cols[stg_cols != 'File1'])\n\n# clean up column names\nstg1.columns = ['File1','File2','Distance']\n\n# remove rows where files are the same, which removes self duplicates\nstg2 = stg1[stg1.File1 != stg1.File2]\n\nfnl_vehicles = stg2.groupby('File1')['Distance'].min()\n\nfnl_vehicles","f5567965":"vehicle_dupes = fnl_vehicles[fnl_vehicles<1]","33f4e03c":"len(vehicle_dupes)","363f1cfa":"vehicle_dupes","96d05ddf":"vehicles_similar = fnl_vehicles[fnl_vehicles<26] # 26 was derived based on results examination","6100e5b5":"vehicles_similar_not_same = vehicles_similar[vehicles_similar>=1]","742bfdee":"vehicles_similar_not_same","bc4acf08":"similar_df = pd.DataFrame(vehicles_similar_not_same)\njoined_results = pd.merge(similar_df,stg2,how='left',on=['File1','Distance'])","9e89c4b2":"joined_results","ef151c1b":"os.chdir(working_path+'\/Images\/Sample_Vehicles')\n\nfor i in range(0,len(joined_results)):\n    print('Similar group ' + str(i+1))\n    pic = joined_results.File1[i]\n    display(Image2(pic, width = 150))\n    pic = joined_results.File2[i]\n    display(Image2(pic, width = 150))\n    print(pic)\n    print('\\n')","fb4abf75":"We can see these are basically the same picture, but from a slightly different closeness. What I'd expect to see is smaller distance as compared to that of the Grumpy Cat compared to Goose. Additionally, I'd think that Sadie_3 is very similar to Sadie_5. ","7a884182":"With the results, put it into a dataframe and create a distance matrix from it. ","39196f7c":"<a name='Development'><\/a>\n# Development\n* Load sample images\n* Import pre-trained deep learning model\n* Edit deep learning model\n* Get model output for each image\n* Check distances between them\n* Show how duplicates would present\n","05e5356c":"With those, I chose 30 images to duplicate. For these files, I changed the naming convention to Vehicle_D#_1 to indicate it is a duplicate.","24c74c10":"Looking at the results, it makes sense that Goose2_2 and Goose2_3 are the most similar, given the composition of the pictures. ","e4189848":"Get list of files for Sadie","f8b6b753":"### Checking the GPU is running\nGiven the type of model I'll be using, I want to make sure the environment can take advantage of my computer's GPUs. \nIf I've configured correctly, I should see a device_type called 'GPU'","cd97707a":"These are the steps to grab the smallest distance across all other files.","731c211b":"<a name='Results'><\/a>\n# Results\n* Identified duplicate images\n* Show near-duplicate images","d60cf3e4":"See the pictures of Sadie.","c4e36022":"See the duplicates. ","3b1c3f86":"For pictures of vehicles used in the prior project, add them to another folder and standardize naming conventions. ","64cd8896":"<a name='Prep'><\/a>\n# Prep\n* Import the necessary packages\n* Set working directory\n* Set random seed to make reproducable","af4c270f":"Load images","1a58ed4b":"Now, I need to normalize the images of Sadie","67e3c7a4":"If we had the training data, we would be able to set up a logistic regression to predict duplicate and near-duplicate images. At this time, I'm not interested in creating that training data :)","7dd1b8f8":"The interesting thing about this technique isn't finding perfect duplicates, which could be accomplished other ways. If we select distances greater than 0 and less than a threshold, we can find similar images. ","59d3abcf":"Get sample image to work. I'm using a naming convention that should make this easy to work with. The beginning is some name, like 'Goose' or 'NotGoose'. This is followed by an underscore and number. The number is simply a sequential number for the file, which creates a file ID. Later, I'll apply this method as an iterator for a larger number of images in a folder, as I did with the prior project. Lastly, for the development piece, I'm adding an underscore 1\/0 to distinguish duplicates, where both duplicate images would have a 1. This makes it easy, as for the training set, I'm manually creating the duplicates. ","4cbeb276":"<a name='Enhancements'><\/a>\n# Enhancements\n* Transform the resulting distance matrix to be a list of the closest neighbor (not including itself)\n* Run technique against a much larger data set of vehicles that were used in the previous project","9f961b14":"As you can see, the first two images are duplicates of my dog, Goose. Grumpy cat is used for the last image, which is clearly not Goose. Here you can see the list of dupe tags derived from the file name: ","a94685d1":"Let's see the pictures of Goose. ","1eb3d47a":"Read in the new data set. ","4cbec782":"Run the model for each image. ","e35092fb":"I'm now going to run the model output and distance matrix of Sadie. I'm combining the steps into one code section and removing the display of the shape.","d64427e7":"Similarly, I need to do this for Goose2. ","1346e0c5":"For the list of vehicle pictures that are similar, but not the same, get the file name that it most closely matches to. ","947fc4c9":"This will iterate over my images, normalize them, and create a new image file in a new folder. ","3e335100":"See the resulting distance matrix to view the results.","27e2c404":"The 58 length shows that it correctly identified the 29 duplicates and 29 original images that had a duplicate made. ","f79d2033":"Get the minimum distance per image. ","61a66200":"For a different set of images of my other dog, Sadie, I'd like to see how to distances look for pictures that are slightly different from one another. ","0fb09c7d":"I want to do the same thing for a new set of images of Goose. ","91d9e5b5":"Let's see the normalized images","d33b8615":"# Duplicate Image Prediction\n\nPlease visit the articile on my website for full write up. \n* https:\/\/www.jocampo.com\/projects\/2019\/3\/3\/finding-duplicate-images-using-transfer-learning-on-deep-neural-networks\n\nConcept: \nA discussion with a co-worker after a meeting generated this idea. He mentioned it would be nice if there was an easy way to identify duplicate images with a folder containing many image files. Seemed like a greate idea for a project. I think of this in 2 ways: \n1. Identifying similar\/duplicate images \n2. The user interface to execute this application. \nI'm going to primarily focus on the former for now, and maybe circle back for the latter at some point. \n\nI'm re-using some of the code that I used for my previous project that explored deep learning on images using a transfer learning approach. Check that out if you haven't already. \n* https:\/\/www.jocampo.com\/projects\/2018\/11\/4\/image-recognition-and-transfer-learning\n\n### Sections \n* <a href='#Prep'>Prep<\/a>\n* <a href='#Development'>Development<\/a>\n* <a href='#Further Testing'>Further Testing<\/a>\n* <a href='#Enhancements'>Enhancements<\/a>\n* <a href='#Results'>Results<\/a>","e4824baa":"Normalize the vehicle images.","8d1fcba3":"See the images that I entered into the folder as duplicates. ","c4a26138":"I now want to normalize my images into the same size and black & white coloring. ","4bb09329":"Similarly for the series of Sadie, I'd expect Goos2_1 and Goose2_5 to have close distance values. ","13b4c5e9":"I'm going to skip displaying the output of the normalizing. I've already shown what that looks like and I quickly looked at the results in the \/norm folder. ","377ab407":"Check the shape of the output. For each image, there should be a row. The model's last layer that I added was 1000 nodes, so the resulting columns should be output of those 1000 nodes.","3534fb43":"With the pre-trained model that I edited before, capture the final layer for each image. ","3cefd0cc":"<a name='Further Testing'><\/a>\n# Further Testing\n* Run distance matrices for two more sets of images that are created to be slightly different for the other pictures in the set","38458c16":"Now, let's import pre-trained model that I'll use for feature engineering","a805a8ff":"Display the groupings of similar, but not exact duplicate, vehicles. ","8fa56aa0":"These results show what I'd expect. Sadie_1 (most zoomed out) is most different from Sadie_6 (most zoomed in). Additionally, the middle images (Sadie_2 through Sadie_5) had similar distances. ","05059b15":"### Variable declaration","81c0aadd":"We can see that using a low distance metric was successful in finding some similar images. Further review results also shows that background of the image impacts results. That is to say that humans focus on the foreground, while the models look at the entire image. ","81e1dc28":"From this, we can see that NotGoose (aka Grumpy Cat) has a non-zero value, indicating it is not a duplicate. The two Goose files have a distance of zero, meaning they are duplicates. ","a32b273c":"Specify an additional layer that will be the output from the model","bcd3e82e":"Check that the images have been resized","ca444e0c":"Display images being used","ae748d59":"Run the same thing for Goose2. "}}