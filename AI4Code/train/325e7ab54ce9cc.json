{"cell_type":{"cf1affc4":"code","34381483":"code","063526ae":"code","b80126ce":"code","b94a2577":"code","95b80314":"code","89745438":"code","f145decc":"code","8342ec5e":"code","0841e0e7":"code","7c3e49d2":"code","ad713a08":"code","a6be2d15":"code","10abc877":"code","caf24fdc":"code","d26d42b6":"code","c394d40d":"code","94bb8852":"code","6b3a9750":"code","68b9ce9b":"code","3f93e260":"code","101e14fa":"code","44758615":"markdown","21996c99":"markdown","5b03b0cc":"markdown","a551ecdc":"markdown","39d5bda3":"markdown","c33a8bae":"markdown","4d9ea5cb":"markdown","c4aef3ea":"markdown","839aa2d4":"markdown","cadbff7b":"markdown","dd6a36cb":"markdown","283b2477":"markdown"},"source":{"cf1affc4":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport missingno as msno\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.offline import iplot, init_notebook_mode\nimport matplotlib.pyplot as plt\ninit_notebook_mode(connected=True)","34381483":"train_df = pd.read_csv(\"\/kaggle\/input\/song-popularity-prediction\/train.csv\")","063526ae":"train_df.head()","b80126ce":"train_df.iloc[:, :].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='GnBu')\\\n                     .bar(subset=[\"max\"], color='#BB0000')\\\n                     .bar(subset=[\"mean\",], color='green')","b94a2577":"for col in train_df.columns:\n    print(f'{col} has range from {train_df[col].min()} to {train_df[col].max()}')","95b80314":"msno.matrix(train_df)","89745438":"missing_df = pd.concat([train_df.notnull().sum(), train_df.isnull().sum()], axis=1)\nmissing_df = missing_df.rename(columns={0:\"#Non_Missing\", 1:\"#Missing\"})","f145decc":"missing_df[\"columns\"] = missing_df.index\nmissing_df.reset_index(drop=True, inplace=True)\ncols = list(missing_df.columns)\ncols = [cols[-1]] + cols[:-1]\nmissing_df = missing_df[cols]\nmissing_df[\"#Non_Missing\"] = round(missing_df[\"#Non_Missing\"]*100\/train_df.shape[0], 2)\nmissing_df[\"#Missing\"] = round(missing_df[\"#Missing\"]*100\/train_df.shape[0], 2)","8342ec5e":"missing_df","0841e0e7":"fig = px.bar(missing_df, x=\"columns\", y=[\"#Non_Missing\", \"#Missing\"], title=\"Missing\/Non_Missing\")\nfig.show()","7c3e49d2":"train_df[\"nul_vals\"] = train_df.isnull().sum(axis=1)\nprint(f'A row can have maximum {train_df[\"nul_vals\"].max()} null values')\nprint(f'{train_df[train_df[\"nul_vals\"]>0].shape[0]} rows has null values which is {train_df[train_df[\"nul_vals\"]>0].shape[0]*100\/train_df.shape[0]}%')\ntrain_df.drop(columns=[\"nul_vals\"], inplace=True)","ad713a08":"fig, axes = plt.subplots(nrows=3, ncols=3,figsize=(24, 10))\npalette_ = [\"#9b59b6\", \"#ff0000\", \"#00f0f0\", \"#00ff00\"]\nsns.kdeplot(train_df[\"song_duration_ms\"], fill=True, color=\"blue\", alpha=1, ax = axes[0,0])\nsns.kdeplot(train_df[\"acousticness\"], fill=True, color=\"red\", alpha=1,  ax = axes[0,1])\nsns.kdeplot(train_df[\"danceability\"], fill=True, color=\"violet\", alpha=1,  ax = axes[0,2])\nsns.kdeplot(train_df[\"instrumentalness\"], fill=True, color=\"orange\", alpha=1,  ax = axes[1,0])\nsns.kdeplot(train_df[\"liveness\"], fill=True, color=\"yellow\", alpha=1,  ax = axes[1,1])\nsns.kdeplot(train_df[\"loudness\"], fill=True, color=\"green\", alpha=1, ax = axes[1,2])\nsns.kdeplot(train_df[\"speechiness\"], fill=True, color=\"pink\", alpha=1,  ax = axes[2,0])\nsns.kdeplot(train_df[\"tempo\"], fill=True, color=\"lightblue\", alpha=1,  ax = axes[2,1])\nsns.kdeplot(train_df[\"audio_valence\"], fill=True, color=\"lightgreen\", alpha=1,  ax = axes[2,2])\nfig.tight_layout()\nfig.show()","a6be2d15":"fig, axes = plt.subplots(nrows=3, ncols=1,figsize=(15, 20))\n# plt.figure(figsize=(12,6))\n\ntmp_df = pd.DataFrame(train_df[\"time_signature\"].value_counts())\ntmp_df = tmp_df.rename(columns={\"time_signature\":\"count\"})\ntmp_df[\"time_signature\"] = tmp_df.index\ntmp_df.reset_index(drop=True, inplace=True)\nsns.barplot(tmp_df[\"time_signature\"], tmp_df[\"count\"], alpha=1, ax=axes[0])\n\ny = train_df['audio_mode'].value_counts()\nx = [i for i in range(train_df[\"audio_mode\"].nunique())]\nsns.barplot(x, y[x], alpha=1, ax = axes[1])\n\n\ny = train_df['key'].value_counts()\nx = [i for i in range(train_df[\"key\"].nunique())]\nsns.barplot(x, y[x], alpha=1, ax=axes[2])\n\n\n\nfig.show()","10abc877":"uniq_val = {}\nfor idx,col in enumerate(train_df.columns):\n    print(f'{idx+1}.{col} has unique: {train_df[col].nunique()}')\n    uniq_val[col] = train_df[col].nunique()*100\/train_df.shape[0]\n\nuniq_val_df = pd.DataFrame.from_dict(uniq_val, orient ='index')\nuniq_val_df[\"columns\"] = uniq_val_df.index\nuniq_val_df.reset_index(drop=True, inplace=True)\nuniq_val_df = uniq_val_df.rename(columns={0:\"%uniq\"})\ncols = list(uniq_val_df.columns)\ncols = [cols[-1]] + cols[:-1]\nuniq_val_df = uniq_val_df[cols]","caf24fdc":"uniq_val_df = uniq_val_df.sort_values('%uniq', ascending=True)\n# fig = plt.figure(figsize=(15,6))\nfig = px.bar(uniq_val_df, x=\"columns\", y=[\"%uniq\"], title=\"Unique Values\", \\\n            text=[f'{round(i,2)}%' for i in uniq_val_df['%uniq']])\nfig.show()","d26d42b6":"fig, axes = plt.subplots(nrows=3, ncols=3,figsize=(24, 10))\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"song_duration_ms\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[0,0])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"song_duration_ms\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[0,0])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"acousticness\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[0,1])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"acousticness\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[0,1])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"danceability\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[0,2])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"danceability\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[0,2])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"instrumentalness\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[1,0])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"instrumentalness\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[1,0])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"liveness\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[1,1])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"liveness\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[1,1])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"loudness\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[1,2])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"loudness\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[1,2])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"speechiness\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[2,0])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"speechiness\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[2,0])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"tempo\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[2,1])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"tempo\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[2,1])\n\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==0], x=\"audio_valence\", fill=True, \\\n            color=\"blue\", alpha=0.5,linewidth = 2, shade = True, ax = axes[2,2])\nsns.kdeplot(data = train_df[train_df[\"song_popularity\"]==1], x=\"audio_valence\", fill=True, \\\n            color=\"violet\", alpha=0.5,linewidth = 2, shade = True, ax = axes[2,2])\n\nfig.tight_layout()\nfig.show()","c394d40d":"def genSankey(df,cat_cols=[],value_cols='',title='Sankey Diagram'):\n    # maximum of 6 value cols -> 6 colors\n    colorPalette = ['#4B8BBE','#306998','#FFE873','#FFD43B','#646464']\n    labelList = []\n    colorNumList = []\n    for catCol in cat_cols:\n#         print(catCol)\n        labelListTemp =  list(set(df[catCol].values))\n        colorNumList.append(len(labelListTemp))\n        labelList = labelList + labelListTemp\n        \n    # remove duplicates from labelList\n    labelList = list(dict.fromkeys(labelList))\n    \n    # define colors based on number of levels\n    colorList = []\n    for idx, colorNum in enumerate(colorNumList):\n        colorList = colorList + [colorPalette[idx]]*colorNum\n        \n    # transform df into a source-target pair\n    sourceTargetDf = pd.DataFrame()\n    for i in range(len(cat_cols)-1):\n        if i==0:\n            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n            sourceTargetDf.columns = ['source','target','count']\n        else:\n            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n            tempDf.columns = ['source','target','count']\n            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n        sourceDf = sourceTargetDf.groupby(['source']).agg({'count':'sum'}).reset_index()\n        sourceDf = sourceDf.rename(columns={\"count\":\"source_sum\"})\n        sourceTargetDf = sourceTargetDf.groupby(['source','target']).agg({'count':'sum'}).reset_index()\n        \n        sourceTargetDf = pd.merge(sourceTargetDf, sourceDf, on=[\"source\"], how=\"left\")\n#         print(sourceTargetDf)\n        sourceTargetDf[\"%age\"] = sourceTargetDf[\"count\"]*100\/sourceTargetDf[\"source_sum\"]\n    sank_df_chk = sourceTargetDf\n#     print(sourceTargetDf)    \n    # add index for source-target pair\n#     sourceTargetDf.to_csv(\"sourceTargetDf.csv\")\n    sourceTargetDf['sourceID'] = sourceTargetDf['source'].apply(lambda x: labelList.index(x))\n    sourceTargetDf['targetID'] = sourceTargetDf['target'].apply(lambda x: labelList.index(x))\n    # creating the sankey diagram\n    data = dict(\n        type='sankey',\n        valueformat = \".0f\",\n        node = dict(\n          pad = 15,\n          thickness = 20,\n          line = dict(\n            color = \"black\",\n            width = 0.5\n          ),\n          label = labelList,\n          color = colorList\n        ),\n        link = dict(\n          source = sourceTargetDf['sourceID'],\n          target = sourceTargetDf['targetID'],\n          value = sourceTargetDf['%age']\n        )\n      )\n    \n    layout =  dict(\n        title = title,\n        font = dict(\n          size = 10\n        )\n    )\n       \n    fig = dict(data=[data], layout=layout)\n    return fig","94bb8852":"tmp_train_df = train_df[[\"key\",\"time_signature\",\"audio_mode\",\"song_popularity\"]].copy()\ntmp_train_df = tmp_train_df[tmp_train_df[\"key\"].notnull()]\ntmp_train_df_grp = tmp_train_df.groupby([\"key\",\"time_signature\",\"audio_mode\",\"song_popularity\"]).size().reset_index()\ntmp_train_df_grp = tmp_train_df_grp.rename(columns={0:\"count\"})\ntmp_train_df_grp[[\"key\",\"time_signature\",\"audio_mode\",\"song_popularity\"]]= tmp_train_df_grp[[\"key\",\"time_signature\",\"audio_mode\",\"song_popularity\"]].astype(str).apply(lambda x : x+'_'+x.name)","6b3a9750":"sank = genSankey(tmp_train_df_grp,cat_cols=[\"song_popularity\",\"audio_mode\"],value_cols='count',title='Merchant Transactions')\nfig = go.Figure(sank)\niplot(fig)","68b9ce9b":"sank = genSankey(tmp_train_df_grp,cat_cols=[\"song_popularity\",\"key\"],value_cols='count',title='Merchant Transactions')\nfig = go.Figure(sank)\niplot(fig)","3f93e260":"sank = genSankey(tmp_train_df_grp,cat_cols=[\"song_popularity\",\"time_signature\"],value_cols='count',title='Merchant Transactions')\nfig = go.Figure(sank)\niplot(fig)","101e14fa":"\ncorr = train_df.corr()\n\nmask = np.zeros_like(corr)\n\nmask[np.triu_indices_from(mask)] = True\ncolormap = sns.color_palette(\"magma\")\nwith sns.axes_style(\"darkgrid\"):\n\n    f, ax = plt.subplots(figsize=(20, 15))\n\n    ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True, cmap=colormap, annot=True)","44758615":" ### Variable Description\n Ref: https:\/\/towardsdatascience.com\/what-makes-a-song-likeable-dbfdb7abe404\n - <b>Danceability<\/b>: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n - <b>Valence<\/b>: Describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n - <b>Energy<\/b>: Represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n - <b>Tempo<\/b>: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n - <b>Loudness<\/b>: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n - <b>Speechiness<\/b>: This detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\n - <b>Instrumentalness<\/b>: Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d.\n - <b>Liveness<\/b>: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n - <b>Acousticness<\/b>: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n - Key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n - <b>Mode<\/b>: Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n - <b>Duration<\/b>: The duration of the track in milliseconds.\n - <b>Time Signature<\/b>: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).","21996c99":"### Observations: \n- Most of the numerical columns has high cardinality, higher than 90% apart from song_duration_ms.\n- tempo, audio_valence and speechines have 100% cardinality which means their values are unique for every observation.","5b03b0cc":"# Target Impact on the Distribution of Variables between Popular and Un-Popular Songs ","a551ecdc":"### Observations:\n- <b>Target Column<\/b>: song_popularity\n- <b>Categorical Column<\/b>: key, time_signature, audio_mode\n- <b>Numerical Column<\/b>: song_duration_ms, tempo, loudness, acousticness, audio_valence, energy, danceability, liveness, instrumentalness, speechiness\n- Numerical Variables are scaled on different range. This needs to re-scale for better model performance.","39d5bda3":"# Introduction\nPredict the song popularity using set of features provided in the dataset.","c33a8bae":"### Observations:\n- song_duration_ms, accousticness, danceability, instumentalness, key, liveness and loudness has missing values of 10%.\n- 22,741 rows consist of null values which is around 56.85%\n- A row can have maximum 6 null values.","4d9ea5cb":"# Correlation and Interaction among Variables","c4aef3ea":"# Analysis of Missing Values","839aa2d4":"### Observations:\n- intrumentalness, speechiness and accousticness are right-skew whereas loudness is left-skew. There is some transformation required before training the model.","cadbff7b":"# Dependent Variable Distributions","dd6a36cb":"This noteboook is created by taking reference of https:\/\/www.kaggle.com\/headsortails\/song-popularity-eda-live-coding-fun","283b2477":"# Dataset"}}