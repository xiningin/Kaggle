{"cell_type":{"2d18350f":"code","51ac1b05":"code","a2752bee":"code","f33ac5f1":"code","f87f808a":"code","84ad47ce":"code","fb0078c0":"code","41a45b1c":"code","f9744760":"code","21c02635":"code","9c6e9d03":"code","497bb6ad":"code","566b573e":"code","df60b4e0":"code","a6643e43":"code","8f1694fa":"code","e0b3b089":"code","0410d408":"code","1ebec56c":"code","d886f0a3":"code","18445524":"code","78b3ad04":"code","28232f17":"code","83d4b806":"code","b189c907":"code","7011a614":"code","7798b4bd":"code","4d577ecc":"code","5c3cb288":"code","6db56221":"code","5f1a9b6f":"code","cf6d49bc":"code","d9c27a79":"code","7f9eb096":"code","c3d12f01":"code","3c8835d9":"code","fd46cfc0":"code","ad7ef2cd":"code","d8e68753":"code","deb40849":"code","432cbb71":"code","60be7b43":"code","1ed161c9":"code","df034833":"code","fe0dd1b7":"code","489a171e":"code","40410b6f":"code","d4109c9f":"code","87fe54e6":"code","515cba4e":"code","8ef246ba":"code","943e2156":"code","b1048c5e":"code","c8872f54":"code","842f7ce4":"code","b4d2921e":"markdown","591310bc":"markdown","a45456c1":"markdown","d547c35a":"markdown","9700719d":"markdown","6cdfd1a1":"markdown","9ae40026":"markdown","ba881052":"markdown","a78b0a07":"markdown","4c596a31":"markdown","b88e8600":"markdown","979ed182":"markdown","98e58520":"markdown","bc173707":"markdown","a17f8705":"markdown","f80293a2":"markdown","e1914205":"markdown","ce527468":"markdown","05a09436":"markdown","43c3f8b0":"markdown","d087dade":"markdown","d45283dc":"markdown","5fb70df5":"markdown","72b234da":"markdown","2199827c":"markdown","00284f0c":"markdown","38e46eed":"markdown","df074726":"markdown","efa04608":"markdown","333b2f89":"markdown","7d28fd18":"markdown","fde5b35a":"markdown","5e2ad16e":"markdown","f4c3068a":"markdown","7d67b094":"markdown","82f6afae":"markdown","3ffe6ac4":"markdown","842e7297":"markdown","977e81a4":"markdown","cb55571a":"markdown","569599ee":"markdown","2a2562d5":"markdown","0a7587e2":"markdown"},"source":{"2d18350f":"#Generate Map with RMS Titanic previous route and crash location \nimport folium\nloc = [41.726931,-49.948253]\n# create a plain world map\nworld_map = folium.Map(location=loc, zoom_start=3,tiles = \"Stamen Terrain\")\n\nfolium.Marker([41.726931, -49.948253],\n              popup='Crash location RMS Titanic',\n              icon=folium.Icon(color='green')\n             ).add_to(world_map)\n\n# display map\nworld_map","51ac1b05":"import pandas as pd\nimport matplotlib.pylab as plt\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn import utils\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","a2752bee":"#Import Dataset\ndb = \"..\/input\/titanic\/train.csv\"\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf = pd.read_csv(db)\ndf.head()","f33ac5f1":"df.describe(include=\"all\")","f87f808a":"print(pd.isnull(df).sum())","84ad47ce":"print(pd.isnull(test).sum())","fb0078c0":"# create new column with the travelers alone\ndef alone(df):\n    if (df['Parch'] == 0) and (df['SibSp'] == 0):\n        return 1\n    else:\n        return 0\n    \ndf['Alone'] = df.apply(alone, axis=1)\ntest['Alone'] = test.apply(alone, axis=1)\nsns.barplot(x=\"Alone\", y=\"Survived\", data=df)\n\n#print percentage of people that was traveling alone\nprint(\"Percentage alone travelers who survived:\", df[\"Survived\"][df[\"Alone\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage not alone travelers who survived:\", df[\"Survived\"][df[\"Alone\"] == 0].value_counts(normalize = True)[1]*100)","41a45b1c":"sns.countplot(x='Survived', hue='Sex', data = df)","f9744760":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=df)","21c02635":"df[\"Age\"] = df[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ndf['AgeGroup'] = pd.cut(df[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=df)\nplt.show","9c6e9d03":"# create new column with the Family Size\ndf['FamilySize'] = df['Parch'] + df['SibSp']\ntest['FamilySize'] = test['Parch'] + test['SibSp']\nsns.barplot(x=\"FamilySize\", y=\"Survived\", data=df)\nplt.show","497bb6ad":"combine = [df, test]\n\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    \npd.crosstab(df['Title'], df['Sex'])","566b573e":"#replace various titles with more common names\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\ndf[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","df60b4e0":"#map each of the title groups to a numerical value\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    \ndf.head()","a6643e43":"#create an Age Group\ndf[\"Age\"] = df[\"Age\"].fillna(-0.5)\ntest[\"Age\"] = test[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ndf['AgeGroup'] = pd.cut(df[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n# Fill the missing values\nmr_age = df[df[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\nmiss_age = df[df[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\nmrs_age = df[df[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\nmaster_age = df[df[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\nroyal_age = df[df[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\nrare_age = df[df[\"Title\"] == 6][\"AgeGroup\"].mode() #Adult\n\nage_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n\nfor x in range(len(df[\"AgeGroup\"])):\n    if df[\"AgeGroup\"][x] == \"Unknown\":\n        df[\"AgeGroup\"][x] = age_title_mapping[df[\"Title\"][x]]\n        \nfor x in range(len(test[\"AgeGroup\"])):\n    if test[\"AgeGroup\"][x] == \"Unknown\":\n        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]","8f1694fa":"#Transform each Age Group into numerical\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ndf['AgeGroup'] = df['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n# Drop the age that not be usefull for now\ndf = df.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","e0b3b089":"sex_mapping = {\"female\": 1, \"male\": 0 }\ndf['Sex'] = df['Sex'].map(sex_mapping).astype(int)\ntest['Sex'] = test['Sex'].map(sex_mapping).astype(int)","0410d408":"df.head()","1ebec56c":"df['Embarked'].value_counts().idxmax()","d886f0a3":"df[\"Embarked\"].replace(np.nan, \"S\", inplace=True)\ntest[\"Embarked\"].replace(np.nan, \"S\", inplace=True)","18445524":"embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ndf['Embarked'] = df['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)\ndf.head()","78b3ad04":"test[\"Fare\"].replace(np.nan, test[\"Fare\"].mean(), inplace=True)","28232f17":"plt.figure(figsize=(16,8))\nsns.heatmap(df.corr(),annot=True,linewidths=1,linecolor='w')\nplt.xlabel('Columns')\nplt.ylabel('Columns')\nplt.title('Heatmap')\nplt.savefig('Heatmap.png')","83d4b806":"df = df.drop([\"SibSp\"], axis = 1)\ndf = df.drop([\"Parch\"], axis = 1)\ndf = df.drop(['Cabin'], axis = 1)\ndf = df.drop([\"Ticket\"], axis = 1)\ndf = df.drop([\"Name\"], axis = 1)","b189c907":"test = test.drop([\"SibSp\"], axis = 1)\ntest = test.drop([\"Parch\"], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\ntest = test.drop([\"Ticket\"], axis = 1)\ntest = test.drop([\"Name\"], axis = 1)","7011a614":"print(pd.isnull(df).sum())\nprint(pd.isnull(test).sum())","7798b4bd":"plt.figure(figsize=(16,8))\nsns.heatmap(df.corr(),annot=True,linewidths=1,linecolor='w')\nplt.xlabel('Columns')\nplt.ylabel('Columns')\nplt.title('Heatmap')\nplt.savefig('Heatmap.png')","4d577ecc":"y = df['Survived']\nx = df.drop(['Survived','PassengerId'],axis=1)","5c3cb288":"x = preprocessing.StandardScaler().fit(x).transform(x)","6db56221":"LRlib = LogisticRegression(C=0.01, solver='liblinear').fit(x,y)\nLRnew = LogisticRegression(C=0.01, solver='newton-cg').fit(x,y)\nLRsag = LogisticRegression(C=0.01, solver='sag').fit(x,y)\nLRsaga = LogisticRegression(C=0.01, solver='saga').fit(x,y)\nLRlbf = LogisticRegression(C=0.01, solver='lbfgs').fit(x,y)","5f1a9b6f":"yLIB = cross_val_predict(LRlib, x, y, cv=5)\nyNEW = cross_val_predict(LRnew, x, y, cv=5)\nySAG = cross_val_predict(LRsag, x, y, cv=5)\nySAGA = cross_val_predict(LRsaga, x, y, cv=5)\nyLBFGS = cross_val_predict(LRlbf, x, y, cv=5)","cf6d49bc":"lr_cross_val = []\nlr_cross_val.append(cross_val_score(LRlib, x, y, cv=5).mean())\nlr_cross_val.append(cross_val_score(LRnew, x, y, cv=5).mean())\nlr_cross_val.append(cross_val_score(LRsag, x, y, cv=5).mean())\nlr_cross_val.append(cross_val_score(LRsaga, x, y, cv=5).mean())\nlr_cross_val.append(cross_val_score(LRlbf, x, y, cv=5).mean())","d9c27a79":"lr_f1_score = []\nlr_f1_score.append(f1_score(y, yLIB, average='weighted'))\nlr_f1_score.append(f1_score(y, yNEW, average='weighted'))\nlr_f1_score.append(f1_score(y, ySAG, average='weighted'))\nlr_f1_score.append(f1_score(y, ySAGA, average='weighted'))\nlr_f1_score.append(f1_score(y, yLBFGS, average='weighted'))","7f9eb096":"lr_jaccard = []\nlr_jaccard.append(jaccard_score(y, yLIB,average='weighted'))\nlr_jaccard.append(jaccard_score(y, yNEW,average='weighted'))\nlr_jaccard.append(jaccard_score(y, ySAG,average='weighted'))\nlr_jaccard.append(jaccard_score(y, ySAGA,average='weighted'))\nlr_jaccard.append(jaccard_score(y, yLBFGS,average='weighted'))","c3d12f01":"dataLR = {'Solver': ['Liblinear','Newton-cg','Sag','Saga','LBFGS'],'Cross Validation': lr_cross_val, 'F1_Score': lr_f1_score, 'Jaccard': lr_jaccard}\nSVM_Results = pd.DataFrame(dataLR) \nSVM_Results.set_index('Solver', inplace = True)\nSVM_Results","3c8835d9":"best_fit_cv = []\nbest_fit_f1 = []\nbest_fit_jaccard = []\n\nbest_LR = LogisticRegression(C=0.01, solver='lbfgs').fit(x,y)\ny_best_LR = cross_val_predict(best_LR, x, y, cv=5)\nbest_fit_cv.append(cross_val_score(best_LR, x, y, cv=5).mean())\nbest_fit_f1.append(f1_score(y, y_best_LR, average='weighted'))\nbest_fit_jaccard.append(jaccard_score(y, y_best_LR,average='weighted'))","fd46cfc0":"bestTree = DecisionTreeClassifier(criterion=\"entropy\",max_depth = 4).fit(x,y)\nyhat_cross_predictDT = bestTree.predict(x)","ad7ef2cd":"#Check f1 score, jaccard, and cross validation score\n\nyhatScoreDT = cross_val_score(bestTree, x, y, cv = 5)\nTree_jaccard = jaccard_score(y, yhat_cross_predictDT,average='weighted')\nTree_f1_score = f1_score(y, yhat_cross_predictDT, average='weighted')\n\nTree_Scores = []\nTree_Scores.append(yhatScoreDT.mean())\nTree_Scores.append(Tree_f1_score)\nTree_Scores.append(Tree_jaccard)","d8e68753":"dataTree = {'Validation': ['Cross Validation','Jaccard','F1_Score'],'Results': Tree_Scores}\nTree_Results = pd.DataFrame(dataTree) \nTree_Results.set_index('Validation', inplace = True)\nTree_Results","deb40849":"best_fit_cv.append(cross_val_score(bestTree, x, y, cv = 5).mean())\nbest_fit_f1.append(f1_score(y, yhat_cross_predictDT, average='weighted'))\nbest_fit_jaccard.append(jaccard_score(y, yhat_cross_predictDT,average='weighted'))","432cbb71":"neighBestCross = KNeighborsClassifier(n_neighbors = 5).fit(x,y)\nKNN_cross_predict = neighBestCross.predict(x)","60be7b43":"Knn_f1_score = f1_score(y, KNN_cross_predict, average='weighted')\nKnn_jaccard_score = jaccard_score(y, KNN_cross_predict, average='weighted')\nyhat_cross_score = cross_val_score(neighBestCross, x, y, cv= 5)\n\nKNN_Scores = []\nKNN_Scores.append(yhat_cross_score.mean())\nKNN_Scores.append(Knn_jaccard_score)\nKNN_Scores.append(Knn_f1_score)","1ed161c9":"dataKNN = {'Validation': ['Cross Validation','Jaccard','F1_Score'],'Results': KNN_Scores}\nKNN_Results = pd.DataFrame(dataKNN) \nKNN_Results.set_index('Validation', inplace = True)\nKNN_Results","df034833":"best_fit_cv.append(cross_val_score(neighBestCross, x, y, cv= 5).mean())\nbest_fit_f1.append(f1_score(y, KNN_cross_predict, average='weighted'))\nbest_fit_jaccard.append(jaccard_score(y, KNN_cross_predict,average='weighted'))","fe0dd1b7":"rbf = svm.SVC(kernel='rbf',gamma='scale').fit(x,y)\nlin = svm.SVC(kernel='linear',gamma='scale').fit(x,y)\npoly = svm.SVC(kernel='poly',gamma='scale').fit(x,y)\nsig = svm.SVC(kernel='sigmoid',gamma='scale').fit(x,y)","489a171e":"svm_rbf_cross_predict = rbf.predict(x)\nsvm_lin_cross_predict = rbf.predict(x)\nsvm_poly_cross_predict = rbf.predict(x)\nsvm_sig_cross_predict = rbf.predict(x)","40410b6f":"svm_cross_val = []\nsvm_cross_val.append(cross_val_score(rbf, x, y, cv = 5).mean())\nsvm_cross_val.append(cross_val_score(lin, x, y, cv = 5).mean())\nsvm_cross_val.append(cross_val_score(poly, x, y, cv = 5).mean())\nsvm_cross_val.append(cross_val_score(sig, x, y, cv = 5).mean())","d4109c9f":"svm_f1_score = []\nsvm_f1_score.append(f1_score(y, svm_rbf_cross_predict, average='weighted'))\nsvm_f1_score.append(f1_score(y, svm_lin_cross_predict, average='weighted'))\nsvm_f1_score.append(f1_score(y, svm_poly_cross_predict, average='weighted'))\nsvm_f1_score.append(f1_score(y, svm_sig_cross_predict, average='weighted'))","87fe54e6":"svm_jaccard = []\nsvm_jaccard.append(jaccard_score(y, svm_rbf_cross_predict,average='weighted'))\nsvm_jaccard.append(jaccard_score(y, svm_lin_cross_predict,average='weighted'))\nsvm_jaccard.append(jaccard_score(y, svm_poly_cross_predict,average='weighted'))\nsvm_jaccard.append(jaccard_score(y, svm_sig_cross_predict,average='weighted'))","515cba4e":"data = {'Kernel': ['RBF','Linear','Polynomial','Sigmoid'],'Cross Validation': svm_cross_val, 'F1_Score': svm_f1_score, 'Jaccard': svm_jaccard}\nSVM_Results = pd.DataFrame(data) \nSVM_Results.set_index('Kernel', inplace = True)\nSVM_Results","8ef246ba":"best_SVM = svm.SVC(kernel='rbf',gamma='scale').fit(x,y)\ny_best_SVM = rbf.predict(x)\nbest_fit_cv.append(cross_val_score(rbf, x, y, cv = 5).mean())\nbest_fit_f1.append(f1_score(y, svm_rbf_cross_predict, average='weighted'))\nbest_fit_jaccard.append(jaccard_score(y, svm_rbf_cross_predict,average='weighted'))\n","943e2156":"BestFit = {'Algorithm': ['Logistic Regression','Decision Tree','K-Nearest Neighbors','SVM (Support Vector Machines)'],'Cross Validation': best_fit_cv, 'F1_Score': best_fit_f1, 'Jaccard': best_fit_jaccard}\nResults = pd.DataFrame(BestFit) \nResults.set_index('Algorithm', inplace = True)\nResults","b1048c5e":"x_test = test.drop(['PassengerId'],axis=1)\nx_test = preprocessing.StandardScaler().fit(x_test).transform(x_test)","c8872f54":"DT_test = bestTree.predict(x_test)","842f7ce4":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = DT_test\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","b4d2921e":"<div id=\"Introduction\">\n    <h2>Introduction<\/h2>\n    Titanic, in full Royal Mail Ship (RMS) Titanic, British luxury passenger liner that sank on April 14\u201315, 1912, during its maiden voyage, en route to New York City from Southampton, England, killing about 1,500 passengers and ship personnel. One of the most famous tragedies in modern history, it inspired numerous stories, several films, and a musical and has been the subject of much scholarship and scientific speculation. \n    <br>\n    <br>\n    The RMS Titanic was under the command of Capt. Edward Smith, who also went down with the ship. The ocean liner carried some of the wealthiest people in the world, as well as hundreds of emigrants from Great Britain and Ireland, Scandinavia and elsewhere throughout Europe who were seeking a new life in the United States.\n    <br>\n<\/div>","591310bc":"<h4>Missing Ages<\/h4>","a45456c1":"<h3>Logistic Regression<\/h3>","d547c35a":"As we can see, the age have an impact on survivors","9700719d":"<h3> SVM (Support Vector Machines)<\/h3>","6cdfd1a1":"<hr>","9ae40026":"Let's see if the Age has any impact","ba881052":"<div id=\"Introduction\">\n   After leaving Southampton on 10 April 1912, Titanic called at Cherbourg in France and Queenstown (now Cobh) in Ireland before heading west to New York. On 14 April, four days into the crossing and about 375 miles (600 km) south of Newfoundland, she hit an iceberg at 11:40 p.m. ship's time. The collision caused the hull plates to buckle inwards along her starboard (right) side and opened five of her sixteen watertight compartments to the sea; she could only survive four flooding. Meanwhile, passengers and some crew members were evacuated in lifeboats, many of which were launched only partially loaded. A disproportionate number of men were left aboard because of a \"women and children first\" protocol for loading lifeboats. At 2:20 a.m., she broke apart and foundered with well over one thousand people still aboard. Just under two hours after Titanic sank, the Cunard liner RMS Carpathia arrived and brought aboard an estimated 705 survivors.\n    <br>\n    <br>\n    The purpose of this project is, based on the information given, to develop a solution that is able to predict the accident survivors, using the most diverse algorithms available and selecting the one that best solves the problem.\n<\/div>\n<hr>","a78b0a07":"Now, let's see how the features impacts in survive probability","4c596a31":"Here we can see some useful informations:\n - There some missing values in Age, Cabin and Embarked Columns\n - The amount of missing values in Cabin are high, so we will drop this column\n - The Embarked column have only 2 missing values\n - The Fare column have only 1 missing values","b88e8600":"<div id=\"data-visualization\">\n    <h2>Data Visualization<\/h2>\n<\/div>","979ed182":"Let's drop the columns that have insignificant correlation with \"Survived\"","98e58520":"<hr>","bc173707":"<h1>Table of contents<\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#Introduction\">Introduction<\/a><\/li>\n        <li><a href=\"#import-data\">Import Data<\/a><\/li>\n        <li><a href=\"#data-visualization\">Data Visualization<\/a><\/li>\n        <li><a href=\"#pre-processing\">Pre-processing<\/a><\/li>\n        <li><a href=\"#modeling-evaluation\">Modeling and Evaluation<\/a><\/li>\n        <li><a href=\"#prediction-submission\">Prediction abd Submission<\/a><\/li>\n    <\/ol>\n<\/div>\n<br>\n<hr>","a17f8705":"### Explore the Data","f80293a2":"<div id=\"Libraries\">\n    <h2>Import libraries<\/h2>\n<\/div>\n","e1914205":"<center><a href=\"https:\/\/en.wikipedia.org\/wiki\/RMS_Titanic\"><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/f\/fd\/RMS_Titanic_3.jpg\/1024px-RMS_Titanic_3.jpg\" width=\"400\" align=\"center\"><\/a><\/center>\n<hr>","ce527468":"As we could see, some of data in dataset are missing, now we need to deal with them.","05a09436":"<hr>","43c3f8b0":"<h3>Decision Tree<\/h3>","d087dade":"I decided to use the Decistion Tree model for the testing data.","d45283dc":"<h3>K-Nearest Neighbors<\/h3>","5fb70df5":"<div id=\"pre-processing\">\n    <h2>Pre-processing<\/h2>\n<\/div>","72b234da":"As we can see, the passengers that traveled with family survived more than the passengers that traveled alone","2199827c":"<hr>","00284f0c":"Female are more likely to survive than male","38e46eed":"### Danilo Packer\n<hr>","df074726":"First, let's create a new column called \"Alone\", to compare the passengers that traveled with family and the passengers that traveled alone","efa04608":"<div id=\"prediction-submission\">\n    <h2>Prediction and Submission<\/h2>\n<\/div>","333b2f89":"Let's check if family size","7d28fd18":"First, we need to deal with Age missing values, to do this we could try to classificate the missing values for Age. For that we can observe that in the column \"Name\" the title is included with the passenger Name, so we will create a new column called \"Title\".\n\nObs: for do this part i used the kernel from the link as inspiration: https:\/\/www.kaggle.com\/nadintamer\/titanic-survival-predictions-beginner","fde5b35a":"Replace Embarked with frequency and transform into numerical","5e2ad16e":"Passengers with highest class are more likely to survive","f4c3068a":"<div id=\"import-data\">\n    <h2>Import Data<\/h2>\n<\/div>","7d67b094":"<div id=\"modeling-evaluation\">\n    <h2>Modeling and Evaluation <\/h2>\n<\/div>","82f6afae":"Let's compare the sex","3ffe6ac4":"<h1><center>Titanic supervised Survivor Prediction<\/center><\/h1>","842e7297":"Now, let's try differents model and evaluete the more accurate","977e81a4":"Let's see if there is a correlation between ticket class and survivors","cb55571a":"**<h4> Drop Columns <\/h4>","569599ee":"<h4>Missing Embarked Datas<\/h4>","2a2562d5":"<hr>","0a7587e2":"Family size has no clearly correlation with survivors"}}