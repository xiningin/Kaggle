{"cell_type":{"140b5acb":"code","307b6b06":"code","2e2c9158":"code","c09d60c7":"code","90734eb1":"code","80e87fda":"code","d88bae9e":"code","de21542f":"code","02e18148":"code","6fdeefe8":"code","1fc38cfb":"code","98517610":"code","877beebb":"code","354c32e8":"code","f557db5e":"code","4e26f576":"code","dcac94cd":"code","7333705c":"code","5a826f96":"code","58ee5c43":"code","0d9760fd":"code","4b1ba0ed":"code","affb9166":"code","2b130e2f":"code","a1256782":"code","391384cd":"code","de8aa526":"code","5dc2ca46":"code","6ded57ca":"code","57e9a1c5":"code","1123dae6":"code","0b3f26f7":"code","962aa2f5":"code","a2f24fca":"code","691a847a":"code","5a06aac3":"code","bf95762d":"code","571d5e19":"code","12cdf1f2":"code","b2e993d1":"code","693bcdbf":"code","5340e62b":"code","c5117f9d":"code","359abfa4":"code","75cf9e3c":"code","e2dfd36b":"code","7ef2bb20":"code","dfabedd2":"code","74b2ab9e":"code","dfae9904":"code","824645b9":"code","3d47b0ed":"code","23843d6e":"code","d5af37ed":"code","b34f8da4":"code","f246d189":"markdown","cd91f17a":"markdown","335c7986":"markdown","6a5febb5":"markdown","7c2860aa":"markdown","93ca449e":"markdown","823858e8":"markdown"},"source":{"140b5acb":"import pandas as pd\nimport random\nimport numpy as np\n\n","307b6b06":"!conda install -y gdown","2e2c9158":"!gdown --id 1s-8A8sF7b23Tb9Myoc_3DTl6YXLpL17L  # train data\n!gdown --id 1YtAHCzeZUXGZQ9cimdkkUq4lUk3ZH-I_  # evaluate.py\n!gdown --id 1EacvwnOHfwa4FiZy2K8mFpFjmpb4Mt-t\n","c09d60c7":"data = pd.read_csv('lab4_train.csv') \ntest = pd.read_csv('lab4_test.csv')","90734eb1":"\ndef split_by_bar(string_text):\n    return string_text.split(' ') #split data (=tokenize)\n\ndata['tokens'] = data['text'].apply(split_by_bar)","80e87fda":"\ndata['tokens']\ndata['tokens'][10]","d88bae9e":"data['tokens']","de21542f":"data.head()","02e18148":"data['aspectCategory']","6fdeefe8":" \ntrain, dev = np.split(data, [int(len(data)*0.8)])","1fc38cfb":"dev.shape","98517610":"train.shape","877beebb":"train.to_csv('aspect-train.csv')\ndev.to_csv('aspect-dev.csv')\n","354c32e8":"train","f557db5e":"dev.head","4e26f576":"from collections import Counter\nfrom nltk.util import ngrams\nn_gram = 1","dcac94cd":"def unigram(lst):\n  unigram = Counter(ngrams(lst, n_gram))\n  return unigram","7333705c":"train['ug'] = (train['tokens']).apply(unigram)","5a826f96":"train['ug']","58ee5c43":"\ndef featurize(token_list): \n  features = {} # add output into dict = dict of features = list of feature dict\n  for i in token_list:\n    features[i] = 1 \n  return features","0d9760fd":"feature_dict_list = [featurize(x) for x in train['ug']]","4b1ba0ed":"feature_dict_list","affb9166":"train","2b130e2f":"from sklearn.feature_extraction import DictVectorizer\ndv = DictVectorizer(sparse=True)\ntrain_sparse_matrix = dv.fit_transform(feature_dict_list)","a1256782":"train_sparse_matrix","391384cd":"from sklearn.linear_model import LogisticRegression\nlm = LogisticRegression()\nlm.fit(train_sparse_matrix, train['aspectCategory'])","de8aa526":"test['tokens'] = test['text'].apply(split_by_bar)\ntest['ug'] = test['tokens'].apply(unigram)","5dc2ca46":"dev_feature_dict_list = [featurize(x) for x in test['ug']]\ndev_sparse_matrix = dv.transform(dev_feature_dict_list)\n","6ded57ca":"dev_sparse_matrix","57e9a1c5":"predictions = lm.predict(dev_sparse_matrix)","1123dae6":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","0b3f26f7":"dev.columns","962aa2f5":"from sklearn.metrics import classification_report","a2f24fca":"dev['ug'] = (dev['tokens']).apply(unigram)","691a847a":"dev","5a06aac3":"# instance of vectorizer\nvectorizer1 = DictVectorizer(sparse=True)\n\n# make binary feature dictionary of train\/dev data\nfeature_dic_train1 = train['ug'].apply(featurize)\nfeature_dic_dev1 = dev['ug'].apply(featurize)\n\n# convert to feature vectors (use .fit_transform\/.transform)\nfeature_vec_train1 = vectorizer1.fit_transform(feature_dic_train1)\nfeature_vec_dev1 = vectorizer1.transform(feature_dic_dev1)\n\n# instance of Logistic Regression Model\nclassifier1 = LogisticRegression()\n\n# train model with train data\nclassifier1.fit(feature_vec_train1, train['aspectCategory'])","bf95762d":"predict_result_aspect = classifier1.predict(feature_vec_dev1)\nprint(classification_report(dev['aspectCategory'], predict_result_aspect))","571d5e19":"train['predicted_category'] = classifier1.predict(feature_vec_train1)","12cdf1f2":"train['predicted_category']","b2e993d1":"train.head()","693bcdbf":"from sklearn.linear_model import LogisticRegression\nlm = LogisticRegression()\nlm.fit(train_sparse_matrix, train['polarity'])","5340e62b":"dev_sparse_matrix","c5117f9d":"predictions = lm.predict(dev_sparse_matrix)","359abfa4":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","75cf9e3c":"# instance of vectorizer\nvectorizer1 = DictVectorizer(sparse=True)\n\n# make binary feature dictionary of train\/dev data\nfeature_dic_train1 = train['ug'].apply(featurize)\nfeature_dic_dev1 = dev['ug'].apply(featurize)\n\n# convert to feature vectors (use .fit_transform\/.transform)\nfeature_vec_train1 = vectorizer1.fit_transform(feature_dic_train1)\nfeature_vec_dev1 = vectorizer1.transform(feature_dic_dev1)\n\n# instance of Logistic Regression Model\nclassifier1 = LogisticRegression()\n\n# train model with train data\nclassifier1.fit(feature_vec_train1, train['polarity'])","e2dfd36b":"predict_result_polarity = classifier1.predict(feature_vec_dev1)\nprint(classification_report(dev['polarity'], predict_result_polarity))\n","7ef2bb20":" predict_result_aspect.shape","dfabedd2":" predict_result_polarity.shape","74b2ab9e":"# result\nnewdf = pd.DataFrame()\nnewdf['id'] = dev['id']\nnewdf['aspectCategory'] = predict_result_aspect\nnewdf['polarity'] = predict_result_polarity\nnewdf","dfae9904":"# export to csv\nnewdf.to_csv('pred.csv', index=None)","824645b9":"\n!python3 evaluate.py lab4_train.csv pred.csv","3d47b0ed":"train['aspectCategory'].value_counts()","23843d6e":"train['polarity'].value_counts()\n","d5af37ed":"print(classification_report(dev['polarity'], newdf['polarity']))","b34f8da4":"print(classification_report(dev['aspectCategory'], newdf['aspectCategory']))","f246d189":"from sklearn.metrics import accuracy_score\naccuracy_score(dev['aspectCategory'], predictions)","cd91f17a":"## Train to predict polarity","335c7986":"# predict & create new df","6a5febb5":"# evaluate\n!python3 evaluate.py test_set.csv pred.csv","7c2860aa":"from sklearn.metrics import accuracy_score\naccuracy_score(test['polarity'], predictions)","93ca449e":"## Train to predict category","823858e8":"# Restaurant Reviews Aspect-based Sentiment Analysis\n> My First Contest Assignment in Introduction to Computational Linguistics Course 2020 <br>Chulalongkorn University<\/br>****"}}