{"cell_type":{"a97091b3":"code","ec4ac469":"code","5a47c1a1":"code","677fce6a":"code","a1aedcf5":"code","21d8e4c2":"code","606a70f4":"code","fc3e7bed":"code","32e4f39c":"code","6028d746":"code","04ff89ad":"code","35441778":"code","09f900fd":"code","4cf8ef4e":"code","bd49aedb":"code","077ff855":"code","e37fd38e":"code","bd2534a2":"code","bd286e55":"code","947a371a":"code","20db854e":"code","d66c5f5e":"markdown","5f28d5b5":"markdown","ff66e150":"markdown","2e0508e7":"markdown","40afacfe":"markdown","8cdb0603":"markdown","9d4b9955":"markdown","aeac2eee":"markdown","4b3bd139":"markdown","623f84dc":"markdown","53dc72e2":"markdown","dc272935":"markdown"},"source":{"a97091b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ec4ac469":"import matplotlib.pyplot as plt\nimport re\nimport numpy as np\nimport seaborn as sns\nfrom scipy import stats as stat","5a47c1a1":"df_path = \"..\/input\/bitcoin-tweets\/Bitcoin_tweets.csv\"\ndf = pd.read_csv(df_path)","677fce6a":"df.drop([\"user_name\",\"user_description\", \"user_created\",\"user_location\"], axis=1, inplace=True)\ndf.drop(df.loc[df.user_verified.isna()].index, axis=0, inplace=True)","a1aedcf5":"df[\"hashtags\"]=df[\"hashtags\"].apply(lambda s : s[1:-1].split(',') if isinstance(s,str) else [])\ndf[\"hashtags_len\"]=df[\"hashtags\"].apply(len)","21d8e4c2":"def conv_to_int(val):\n    if isinstance(val, str):\n        return 0\n    else:\n        return float(val)\ndf[\"user_followers\"]=df[\"user_followers\"].apply(lambda x : conv_to_int(x))\ndf[\"user_friends\"]=df[\"user_friends\"].apply(lambda x : conv_to_int(x))\ndf[\"user_favourites\"]=df[\"user_favourites\"].apply(lambda x : conv_to_int(x))","606a70f4":"def clean_text(text):\n    if(isinstance(text, str)):\n        text = text.replace(\"#\",\"\")\n        text = re.sub('\\\\n', '', text)\n        text = re.sub('https:\\\/\\\/\\S+', '', text)\n        return text\n    else:\n        return \"\"\n\ndf[\"clean_text\"]=df[\"text\"].apply(clean_text)\ndf.drop(\"text\", axis=1, inplace=True)","fc3e7bed":"df[\"date\"]=pd.to_datetime(df[\"date\"],errors='coerce')\ndf[\"date\"]=df[\"date\"].apply(lambda x: x.date() )","32e4f39c":"def generate_impact_score(tweet):\n    coef_verified = 1.1 if tweet.user_verified else 1\n    coef_hashtags = 1+(tweet.hashtags_len\/20)\n    return ((tweet.user_followers + (tweet.user_friends\/4))*coef_verified*coef_hashtags)\/100","6028d746":"df[\"impact_score\"]=df.apply(generate_impact_score, axis=1)","04ff89ad":"!pip install yfinance","35441778":"import yfinance as yf\nbtc_stock=yf.Ticker(\"BTC-USD\")","09f900fd":"start = min(df['date'])\nend = max(df['date'])\nbtc_stock = btc_stock.history(start=start, end=end)","4cf8ef4e":"tweet_shift1 = df.groupby('date').size().shift(-1).dropna() \ntweet_shift1_impact = df.groupby('date')[\"impact_score\"].sum().shift(-1).dropna() \n\nstocks_data = btc_stock['Volume'].dropna()\n\ncorr, pval = stat.spearmanr(tweet_shift1.reindex(stocks_data.index), stocks_data,nan_policy='omit')\ncorr_i, pval_i = stat.spearmanr(tweet_shift1_impact.reindex(stocks_data.index), stocks_data,nan_policy='omit')\n\ntweets_vol = df.groupby('date').size().rolling(10).mean().dropna()\ntweets_vol_impact= df.groupby('date')[\"impact_score\"].sum().rolling(10).mean().dropna()\n\nfig, ax = plt.subplots(figsize=(16,8))\n\nax.plot(stocks_data.index,stocks_data,color='orange',label='Trade Volume')\nax.tick_params(axis='y')\n\nax2 = ax.twinx()\nax2.plot(tweets_vol.index,tweets_vol,label='Tweet Volume')\nax2.set_yscale('log')\nax2.tick_params(axis='y')\n\nax3=ax.twinx()\nax3.plot(tweets_vol_impact.index,tweets_vol_impact,label='Tweet Volume and Impact', color='red')\n\nlines, labels = ax.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nlines3, labels3 = ax3.get_legend_handles_labels()\nax2.legend(lines + lines2 + lines3, labels + labels2 + labels3, loc=0)\n\nplt.show()\n\nprint(\"Spearman correlation - tweets: corr={} pval={}\".format(corr,pval))\nprint(\"Spearman correlation - impact tweets: corr={} pval={}\".format(corr_i,pval_i))\n","bd49aedb":"from nltk.sentiment import SentimentIntensityAnalyzer\n\ndef get_polarity_score(tweet):\n    sia = SentimentIntensityAnalyzer()\n    return sia.polarity_scores(tweet)[\"compound\"]\n    \ndef get_polarity_cat(score):\n    if score >=0.05 : \n        return \"positive\"\n    elif score <=-0.05:\n        return \"negative\"\n    else:\n        return \"neutral\"\n\ndf[\"polarity_score\"]=df[\"clean_text\"].apply(get_polarity_score)\ndf[\"polarity_cat\"]=df[\"polarity_score\"].apply(get_polarity_cat)","077ff855":"df.head()","e37fd38e":"df['polarity_cat'].value_counts().plot(kind=\"bar\")\nplt.title(\"Tweets sentiment plot\")\nplt.xlabel(\"Polarity\")\nplt.ylabel(\"Count\")\nplt.show()","bd2534a2":"df.polarity_score.plot(kind='hist',range=(-1,1),bins=40,edgecolor='black');","bd286e55":"df_positive=df.loc[df.polarity_cat==\"positive\"]\ndf_negative=df.loc[df.polarity_cat==\"negative\"]\ndf_neutral=df.loc[df.polarity_cat==\"neutral\"]","947a371a":"tweet_shift_positive = df_positive.groupby('date').size().shift(-1) \ntweet_shift_negative = df_negative.groupby('date').size().shift(-1) \ntweet_shift_neutral = df_neutral.groupby('date').size().shift(-1)\n\nstocks_data = btc_stock['Volume'].dropna()\n\ncorr_positive, pval_positive = stat.spearmanr(tweet_shift_positive.reindex(stocks_data.index), stocks_data,nan_policy='omit')\ncorr_negative, pval_negative = stat.spearmanr(tweet_shift_negative.reindex(stocks_data.index), stocks_data,nan_policy='omit')\ncorr_neutral, pval_neutral = stat.spearmanr(tweet_shift_neutral.reindex(stocks_data.index), stocks_data,nan_policy='omit')\n\ntweets_vol_positive = df_positive.groupby('date').size().rolling(10).mean()\ntweets_vol_negative = df_negative.groupby('date').size().rolling(10).mean()\ntweets_vol_neutral = df_neutral.groupby('date').size().rolling(10).mean()\n\nfig, ax = plt.subplots(figsize=(16,8))\n\nax.plot(stocks_data.index,stocks_data,color='orange',label='Trade Volume')\nax3.set_yscale('log')\n\nax2 = ax.twinx()\nax2.plot(tweets_vol_positive.index,tweets_vol_positive,label='Positive Tweet Volume', color=\"green\")\nax2.set_yscale('log')\nax2.tick_params(axis='y')\n\nax3 = ax.twinx()\nax3.plot(tweets_vol_negative.index,tweets_vol_negative,label='Negative Tweet Volume', color=\"red\")\nax3.set_yscale('log')\n\nax4 = ax.twinx()\nax4.plot(tweets_vol_neutral.index,tweets_vol_neutral,label='Neutral Tweet Volume')\nax4.tick_params(axis='y')\nax3.set_yscale('log')\n\nlines, labels = ax.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nlines3, labels3 = ax3.get_legend_handles_labels()\nlines4, labels4 = ax4.get_legend_handles_labels()\nax2.legend(lines + lines2 + lines3 + lines4, labels + labels2 + labels3 + labels4, loc=0)\n\nplt.show()\n\nprint(\"Spearman correlation - tweets: corr={} pval={}\".format(corr_positive,pval_positive))\nprint(\"Spearman correlation - tweets: corr={} pval={}\".format(corr_negative,pval_negative))\nprint(\"Spearman correlation - tweets: corr={} pval={}\".format(corr_neutral,pval_neutral))\n","20db854e":"sentiment= df.groupby('date')['polarity_score'].mean().shift(-1).rolling(10).mean()\ncorr_test = df.groupby('date')['polarity_score'].mean().shift(-1)\ncorr, pval = stat.spearmanr(corr_test.reindex(btc_stock.index), btc_stock['Open'],nan_policy='omit')\n\nfig, ax = plt.subplots(figsize=(16,8))\n\nax.plot(sentiment.index,sentiment,label='Tweets Sentiment score')\nax2 = ax.twinx()\nax2.plot(btc_stock.index,btc_stock['Close'],color='orange',label='share price')\nax2.set_title(\"Effects of tweets on prices\")\n\nlines, labels = ax.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax2.legend(lines + lines2, labels + labels2, loc=0)\nplt.show()\n\nprint(\"Spearman correlation: corr={} pval={}\".format(corr,pval))","d66c5f5e":"Importing BTC stocks info from yahoo finance :","5f28d5b5":"We transform the Hashtags column to have clean arrays we can work with :","ff66e150":"We transform dates too :","2e0508e7":"We remove all \"#\" from our text : ","40afacfe":"We convert columns to float to be able to work with them :","8cdb0603":"# Does tweets volume affects BTC traded volume ?","9d4b9955":"We want to run our analysis again, this time taking into account the tweets' sentiments.\n\n**Reminder :**\n* positive sentiment : (compound score >= 0.05) \n* neutral sentiment : (compound score > -0.05) and (compound score < 0.05) \n* negative sentiment : (compound score <= -0.05)","aeac2eee":"# Sentiment analysis ","4b3bd139":"# Data preparation","623f84dc":"dropping columns we won't use :","53dc72e2":"Just for fun, we can guess an impact score for each tweet based on the information we have :","dc272935":"Hypothesis : tweets amount affects the volume traded of the particular company. \nTo verify that, we shift the entire timeseries back by 1 period, to compare the effects of tweets from day before on the btc  traded volume the following day.\n\nSpearman correlation statistic test was used (it does not assume that the dataset is normally distributed).\n\nIf the p-value of the spearman correlation, falls below the pre-determined threshold of 0.05, we will reject the null hypothesis and we will have enough evidence to conclude that there is a correlation between the btc traded volume and the amount of tweets.\n"}}