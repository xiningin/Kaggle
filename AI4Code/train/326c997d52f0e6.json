{"cell_type":{"3a2b465b":"code","68c64012":"code","6c5b363c":"code","0ce62e2c":"code","eafa8578":"code","a83b91a8":"code","8cb139e1":"code","05505786":"code","e4a349ad":"markdown","b6ee8ad6":"markdown","a249e2d6":"markdown","35e0203c":"markdown","e66c76d2":"markdown","493c5834":"markdown","b196d384":"markdown"},"source":{"3a2b465b":"import os\nimport sys\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport time\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import auc, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, KFold\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\n\n# set pandas preview to use full width of browser to see more of the column data\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)\n","68c64012":"show_files = False\n\nif show_files is True:\n    # helper method to quickly see the file paths of your imported data\n    for dirname, _, filenames in os.walk('\/kaggle\/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))","6c5b363c":"# uncomment these lines to try different types of preprocessed data\n\n#train_file_path = '..\/input\/nlp-getting-started\/train.csv'\n#train_file_path = '..\/input\/tweet-cleaner\/train_df_clean.csv'\ntrain_file_path = '..\/input\/gpt-2-fake-real-disasters-data-augmentation\/train_df_combined.csv'\n\n#test_file_path = '..\/input\/nlp-getting-started\/test.csv'\ntest_file_path = '..\/input\/tweet-cleaner\/test_df_clean.csv'\n\ntrain_full = pd.read_csv(train_file_path)\ntrain = train_full[['text']]\ntarget = train_full[['target']]\ntest = pd.read_csv(test_file_path)\ntest = test[['id', 'text']]","0ce62e2c":"# from https:\/\/www.kaggle.com\/denychaen\/tweets-simple-baseline-tfembed-lgb\nembed = hub.load(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/3\")\nX_train_embeddings = embed(train['text'].values)\nX_test_embeddings = embed(test['text'].values)","eafa8578":"do_grid_search = False\n\nif do_grid_search is True:\n    X_train, X_test, y_train, y_test = train_test_split(\n        np.array(X_train_embeddings['outputs']),\n        target,\n        test_size=0.2,\n        random_state=20)\n\n    estimator = lgb.LGBMClassifier()\n\n    # Try your own ranges here, you may find better ones than me!\n    param_grid = {\n        'n_estimators': [64, 200],\n        'num_leaves': [31, 64],\n        'learning_rate': [0.05, 0.1],\n        'feature_fraction': [0.8, 1.0],\n        'max_depth': [-1],\n        'lambda_l1': [0, 1],\n        'lambda_l2': [0, 1],\n    }\n\n    gridsearch = GridSearchCV(\n        estimator, param_grid, refit=True, verbose=0, cv=5)\n\n    gridsearch.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_test, y_test)],\n        eval_metric=['auc', 'binary_logloss'],\n        early_stopping_rounds=10,\n        verbose=0)\n\n    print('Best parameters found by grid search are:', gridsearch.best_params_)\n\n    Y_pred = gridsearch.best_estimator_.predict(X_test)\n\n    print(metrics.classification_report(y_test, Y_pred, digits=3),)\n    print(metrics.confusion_matrix(y_test, Y_pred))\n\n    # if we just guessed the most common class (0) for every prediction\n    print('The null acccuracy is:',\n          max(y_test['target'].mean(), 1 - y_test['target'].mean()))","a83b91a8":"params = {\n    'objective': 'binary',\n    'feature_fraction': 0.9,\n    'lambda_l1': 1.0,\n    'lambda_l2': 0.001,\n    'learning_rate': 0.05,\n    'max_depth': -1,\n    'n_estimators': 128,\n    'num_leaves': 64,\n    'metric': 'binary_logloss',\n    'random_seed': 42\n}\n\nkf = KFold(n_splits=5, random_state=42)\nmodels = []\n\nX_train = pd.DataFrame(data=np.array(X_train_embeddings['outputs']))\ny_train = target\n\nfor train_index, test_index in kf.split(X_train):\n    train_features = X_train.loc[train_index]\n    train_target = y_train.loc[train_index]\n\n    test_features = X_train.loc[test_index]\n    test_target = y_train.loc[test_index]\n\n    d_training = lgb.Dataset(\n        train_features, label=train_target, free_raw_data=False)\n    d_test = lgb.Dataset(test_features, label=test_target, free_raw_data=False)\n\n    evals_result = {}  # to record eval results for plotting\n\n    model = lgb.train(\n        params,\n        train_set=d_training,\n        num_boost_round=200,\n        valid_sets=[d_training, d_test],\n        verbose_eval=50,\n        early_stopping_rounds=5,\n        evals_result=evals_result)\n\n    # https:\/\/machinelearningmastery.com\/learning-curves-for-diagnosing-machine-learning-model-performance\/\n    print('Plotting metrics recorded during training...')\n    ax = lgb.plot_metric(evals_result, metric='binary_logloss')\n    plt.show()\n\n    models.append(model)","8cb139e1":"# https:\/\/www.kaggle.com\/rohanrao\/ashrae-half-and-half\n# averages the votes of each model, then returns the majority vote\ndef get_predictions(data):\n\n    results = []\n    for model in models:\n        if results == []:\n            results = model.predict(\n                data, num_iteration=model.best_iteration) \/ len(models)\n        else:\n            results += model.predict(\n                data, num_iteration=model.best_iteration) \/ len(models)\n\n    # if the average value is less than .5, then the majority vote was 0, otherwise it was 1\n    results = [int(round(x)) for x in results]\n\n    return results","05505786":"preds = get_predictions(X_test_embeddings['outputs'])\n\nssub = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\n\nssub[\"target\"] = preds\nssub.to_csv(\"submission.csv\", index=False)","e4a349ad":"# Create embeddings","b6ee8ad6":"My methodology is as follows:\n 1. Clean the text using my [Tweet Cleaner](https:\/\/www.kaggle.com\/jdparsons\/tweet-cleaner) notebook\n 2. Send the clean text to GPT-2 using my [GPT-2: fake real disasters](https:\/\/www.kaggle.com\/jdparsons\/gpt-2-fake-real-disasters-data-augmentation) notebook. This generates similar tweets with the same label, which doubles the size of my training data.\n 3. In this notebook:\n  * I, um, use USE (Universal Sentence Encoder) to convert the tweets into 512 dimensional vectors\n  * Perform a grid search on many Light GBM parameters to find the best ones\n  * Use K-Fold Cross Validation to train multiple LGB models on different random splits of the data. The prediction function averages the votes into a final answer.\n\nMy best score was 0.82413 with the previously mentioned preprocessing notebooks and the following Light GBM parameters:\n * K-fold DV=5\n * 'feature_fraction': 0.9, 'lambda_l1': 1.0, 'lambda_l2': 0.001, 'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 128, 'num_leaves': 64,\n\nMy next experiment will be to send my GPT-2 augmented data to Google's AutoML and see how it scores compared to this hand-crafted approach. I'll publish that notebook and update this description when I have the results. **If you have any ideas for improving this notebook, please let me know in the comments!**\n\nCode linted via http:\/\/pep8online.com\/ and https:\/\/yapf.now.sh\/ to follow the Google python style guide (mostly).","a249e2d6":"# Generate submission","35e0203c":"# Grid Search","e66c76d2":"# Load data","493c5834":"# Prediction method","b196d384":"# Train final model"}}