{"cell_type":{"8b433576":"code","68d25933":"code","140fe9f9":"code","7825719a":"code","84c5501a":"code","3c1a6bc9":"code","a2700cc5":"code","fb5a8920":"code","4ea4e8a1":"code","ed2494e4":"code","779d7200":"code","dc2841d0":"code","c9463a2f":"code","f55985e0":"code","fe009aed":"code","9347e73c":"code","b3c077ff":"code","0b1aaa71":"code","e72600c8":"code","317816d4":"code","2c349e2b":"code","c38207c5":"code","c53cc4ca":"code","4e4b74ea":"code","701985a7":"code","b82a0bad":"code","890f9de9":"markdown","76478658":"markdown","010ffe05":"markdown","2ec5f1e6":"markdown","933c7c61":"markdown","201a44fa":"markdown","42e307c5":"markdown","306b06ab":"markdown","00f3471f":"markdown","9a2c24c4":"markdown","9b979034":"markdown","b47de6cc":"markdown","c966bf7d":"markdown","89a484bd":"markdown","98b5ada3":"markdown","d4e77963":"markdown","d6b06a4d":"markdown","6272ac7a":"markdown","444d3271":"markdown","d1a10098":"markdown"},"source":{"8b433576":"import os\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\nfrom keras.optimizers import Adam","68d25933":"train = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_train_v2.csv')\nvalid = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_validation_v2.csv')","140fe9f9":"plt.figure(figsize=(15, 10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/train_v2\/train\/'+train.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(train.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","7825719a":"print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\nprint(\"Number of NaNs in validation set : \", valid['IDENTITY'].isnull().sum())","84c5501a":"train.dropna(axis=0, inplace=True)\nvalid.dropna(axis=0, inplace=True)","3c1a6bc9":"unreadable = train[train['IDENTITY'] == 'UNREADABLE']\nunreadable.reset_index(inplace = True, drop=True)\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/train_v2\/train\/'+unreadable.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","a2700cc5":"train = train[train['IDENTITY'] != 'UNREADABLE']\nvalid = valid[valid['IDENTITY'] != 'UNREADABLE']","fb5a8920":"train['IDENTITY'] = train['IDENTITY'].str.upper()\nvalid['IDENTITY'] = valid['IDENTITY'].str.upper()","4ea4e8a1":"train.reset_index(inplace = True, drop=True) \nvalid.reset_index(inplace = True, drop=True)","ed2494e4":"def preprocess(img):\n    (h, w) = img.shape\n    \n    final_img = np.ones([64, 256])*255 # blank white image\n    \n    # crop\n    if w > 256:\n        img = img[:, :256]\n        \n    if h > 64:\n        img = img[:64, :]\n    \n    \n    final_img[:h, :w] = img\n    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)","779d7200":"train_size = 30000\nvalid_size= 3000","dc2841d0":"train_x = []\n\nfor i in range(train_size):\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/train_v2\/train\/'+train.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image\/255.\n    train_x.append(image)","c9463a2f":"valid_x = []\n\nfor i in range(valid_size):\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/validation_v2\/validation\/'+valid.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image\/255.\n    valid_x.append(image)","f55985e0":"train_x = np.array(train_x).reshape(-1, 256, 64, 1)\nvalid_x = np.array(valid_x).reshape(-1, 256, 64, 1)","fe009aed":"alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\nmax_str_len = 24 # max length of input labels\nnum_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\nnum_of_timestamps = 64 # max length of predicted labels\n\n\ndef label_to_num(label):\n    label_num = []\n    for ch in label:\n        label_num.append(alphabets.find(ch))\n        \n    return np.array(label_num)\n\ndef num_to_label(num):\n    ret = \"\"\n    for ch in num:\n        if ch == -1:  # CTC Blank\n            break\n        else:\n            ret+=alphabets[ch]\n    return ret","9347e73c":"name = 'JEBASTIN'\nprint(name, '\\n',label_to_num(name))","b3c077ff":"train_y = np.ones([train_size, max_str_len]) * -1\ntrain_label_len = np.zeros([train_size, 1])\ntrain_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([train_size])\n\nfor i in range(train_size):\n    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])    ","0b1aaa71":"valid_y = np.ones([valid_size, max_str_len]) * -1\nvalid_label_len = np.zeros([valid_size, 1])\nvalid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\nvalid_output = np.zeros([valid_size])\n\nfor i in range(valid_size):\n    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])    ","e72600c8":"print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n      '\\ntrain_input_len : ', train_input_len[100])","317816d4":"input_data = Input(shape=(256, 64, 1), name='input')\n\ninner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n\ninner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\ninner = Dropout(0.3)(inner)\n\ninner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\ninner = Dropout(0.3)(inner)\n\n# CNN to RNN\ninner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\ninner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n## RNN\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n\n## OUTPUT\ninner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\ny_pred = Activation('softmax', name='softmax')(inner)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\nmodel.summary()","2c349e2b":"# the ctc loss function\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)","c38207c5":"labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)","c53cc4ca":"# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\nmodel_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n\nmodel_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n                epochs=60, batch_size=128)","4e4b74ea":"preds = model.predict(valid_x)\ndecoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n                                   greedy=True)[0][0])\n\nprediction = []\nfor i in range(valid_size):\n    prediction.append(num_to_label(decoded[i]))","701985a7":"y_true = valid.loc[0:valid_size, 'IDENTITY']\ncorrect_char = 0\ntotal_char = 0\ncorrect = 0\n\nfor i in range(valid_size):\n    pr = prediction[i]\n    tr = y_true[i]\n    total_char += len(tr)\n    \n    for j in range(min(len(tr), len(pr))):\n        if tr[j] == pr[j]:\n            correct_char += 1\n            \n    if pr == tr :\n        correct += 1 \n    \nprint('Correct characters predicted : %.2f%%' %(correct_char*100\/total_char))\nprint('Correct words predicted      : %.2f%%' %(correct*100\/valid_size))","b82a0bad":"test = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_test_v2.csv')\n\nplt.figure(figsize=(15, 10))\nfor i in range(6):\n    ax = plt.subplot(2, 3, i+1)\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/test_v2\/test\/'+test.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap='gray')\n    \n    image = preprocess(image)\n    image = image\/255.\n    pred = model.predict(image.reshape(1, 256, 64, 1))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    plt.title(num_to_label(decoded[0]), fontsize=12)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","890f9de9":"Reset the index and we are done with cleaning. ","76478658":"## Cleaning Data","010ffe05":"## Load and view data","2ec5f1e6":"The model will be trained on 30000 images and validate on 3000 images","933c7c61":"Lets start by importing the necessary libraries. I'll be using Keras for building our CRNN model.","201a44fa":"## Some predictions on test set","42e307c5":"Let's check for NaNs in our label.","306b06ab":"## Check model performance on validation set","00f3471f":"* The images are loaded as grayscale and reshaped to width 256 and height 64.  \n* The width and height are cropped if they are greater than 256 and 64 respectively. If they are smaller, then the image is padded with white pixels. Finally the image is rotated clockwise to bring the image shape to (x, y). \n* The image is then normalized to range [0, 1]","9a2c24c4":"* **train_y** contains the true labels converted to numbers and padded with -1. The length of each label is equal to max_str_len. \n* **train_label_len** contains the length of each true label (without padding) \n* **train_input_len** contains the length of each predicted label. The length of all the predicted labels is constant i.e number of timestamps - 2.  \n* **train_output** is a dummy output for ctc loss. \n","9b979034":"## Ways to improve the model \n\n* Use more training samples. This will help the model to learn and generalise better. I have used only 10% of the images as the entire training set cannot be loaded into kaggle's memory. \n* There are multiple images in the training set which are not at all legible to the human eye. Removing such images will help in model's learning. ","b47de6cc":"There are some labels which are in lowercase. To maintain uniformity in the labels, I convert all the labels to uppercase.","c966bf7d":"## Building our model\n","89a484bd":"Also, there are some images in our data with the label 'UNREADABLE'. Lets check those images and remove them.","98b5ada3":"In this notebook, we'll go through the steps to train a CRNN (CNN+RNN) model for handwriting recognition. The model will be trained using the CTC(Connectionist Temporal Classification) loss.\n\n\n![Webp.net-resizeimage.jpg](attachment:Webp.net-resizeimage.jpg)","d4e77963":"The output shape of the predictions is (64, 30). The model predicts words of 64 characters and each character contains the probability of the 30 alphabets which we defined earlier.  ","d6b06a4d":"## Preparing the labels for CTC Loss\n\nLearn more about CTC loss and why its amazing for text recognition from [here](https:\/\/theailearner.com\/2019\/05\/29\/connectionist-temporal-classificationctc\/).\n\nThe labels have to be converted to numbers which represent each character in the training set. The 'alphabets' consist of A-Z and three special characters (-  '  and space). ","6272ac7a":"## Preprocessing and preparing the images for training","444d3271":"*P.S : This is my first Kaggle notebook. Any feedback would be highly appreciated*","d1a10098":"## Train our model"}}