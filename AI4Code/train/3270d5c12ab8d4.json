{"cell_type":{"c9a5c8ee":"code","a55b05e2":"code","b2bd4d01":"code","41acc8a6":"code","2fa958bd":"code","5c173d81":"code","5014e73f":"code","01b89d20":"markdown","6ae880ba":"markdown","12e46dbd":"markdown"},"source":{"c9a5c8ee":"# importing all required modules or libraries\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn import linear_model","a55b05e2":"# Define sample input data\nX = np.array([[3.1, 7.2],[4, 6.7],[2.9, 8],\n              [5.1, 4.5], [6, 5], [5.6, 5], \n              [3.3, 0.4], [3.9, 0.9], [2.8, 1],\n              [0.5, 3.4], [1, 4], [0.6, 4.9]])\n\n# This are our 4 classes {0 to 3} \ny = np.array([0, 0, 0, \n              1, 1, 1,\n              2, 2, 2,\n              3, 3, 3])","b2bd4d01":"# Put your Enrollment number:-\na = input('Put you enrollment number here:')","41acc8a6":"# Put your Value of C:\nb = input('Put the value of C:')\nb = int(b)","2fa958bd":"# Defining the visulaizer for plotting\ndef visualize_classifier(classifier, X, y):\n    # Define the minimum and maximum values for X and Y\n    # that will be used in the mesh grid\n    min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0\n    min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0\n\n    # Define the step size to use in plotting the mesh grid \n    mesh_step_size = 0.01\n\n    # Define the mesh grid of X and Y values\n    x_vals, y_vals = np.meshgrid(np.arange(min_x, max_x, mesh_step_size), np.arange(min_y, max_y, mesh_step_size))\n\n    # Run the classifier on the mesh grid\n    output = classifier.predict(np.c_[x_vals.ravel(), y_vals.ravel()])\n\n    # Reshape the output array\n    output = output.reshape(x_vals.shape)\n\n    # Create a plot\n    plt.figure()\n\n    # Choose a color scheme for the plot \n    plt.pcolormesh(x_vals, y_vals, output, cmap=plt.cm.gray)\n\n    # Overlay the training points on the plot \n    plt.scatter(X[:, 0], X[:, 1], c=y, s=75, edgecolors='black', linewidth=1, cmap=plt.cm.Paired)\n\n    # Specify the boundaries of the plot\n    plt.xlim(x_vals.min(), x_vals.max())\n    plt.ylim(y_vals.min(), y_vals.max())\n\n    # Specify the ticks on the X and Y axes\n    plt.xticks((np.arange(int(X[:, 0].min() - 1), int(X[:, 0].max() + 1), 1.0)))\n    plt.yticks((np.arange(int(X[:, 1].min() - 1), int(X[:, 1].max() + 1), 1.0)))\n    \n    plt.title(f'{a}, value of C ={b}')\n              \n    plt.show()","5c173d81":"#Create the logistic regression classifier\n# Here we can change the value of C and max_iter for better classification\nclassifier = linear_model.LogisticRegression(solver = 'liblinear',C = b, max_iter = 1000) \n\n# train the classifier\nclassifier.fit(X,y)","5014e73f":"# Visulaizing the  output \nvisualize_classifier(classifier, X, y)\n\n# Prediction \npr = classifier.predict(X)\nprint(pr)","01b89d20":"### Information about Modules\n\n**1). `numpy` :- It is used for mathematical operation and also for the scientific Calculations.(Full form :- numerical python)**\n\n**2). `matplotlib` :- It is used for the visualization and plottting the data**\n\n**3). `sklearn` :- It is used for machine learning, because it has all the algorithms that we are going to use.(Full form :- Scikit-learn)**","6ae880ba":"### Logistic regression: regression and a sigmoid\n\nLogistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n\nRegression:\n$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\nNote that the $\\theta$ values are \"weights\". If you took the Deep Learning, we referred to the weights with the `w` vector.  In this  we're using a different variable $\\theta$ to refer to the weights.\n\nLogistic regression\n$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\nWe will refer to 'z' as the 'logits'.","12e46dbd":"## Logistic Regression \n\nLogistic regression is a fundamental classification technique. It belongs to the group of linear classifiers and is somewhat similar to polynomial and linear regression. Logistic regression is fast and relatively uncomplicated, and it\u2019s convenient for you to interpret the results. Although it\u2019s essentially a method for binary classification, it can also be applied to multiclass problems.\n\n### Math Prerequisites:\n\n#### The sigmoid function\n\nEquation of Sigmoid:\n\n$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n\nThis image shows the sigmoid function (or S-shaped curve):\n\n<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https:\/\/github.com\/ibrahimjelliti\/Deeplearning.ai-Natural-Language-Processing-Specialization\/blob\/master\/1%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces\/Labs\/tmp2\/sigmoid_plot.jpg?raw=1' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" \/>  <\/div>\n\nThe sigmoid function has values very close to either 0 or 1 across most of its domain. This fact makes it suitable for application in classification methods."}}