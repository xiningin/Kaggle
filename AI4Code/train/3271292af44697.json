{"cell_type":{"46196338":"code","e28da50b":"code","67a16cdc":"code","8bbb7075":"code","7247a7cf":"code","76097a4b":"code","d3a60ccb":"code","b557faa5":"code","a31b3ba4":"code","a5036980":"code","eb4a8a62":"code","fc4e9efa":"code","3a801e67":"code","5c2f92fc":"code","645ce93e":"code","d6bba12d":"code","dda23ba8":"code","0e5860b5":"code","ca1604a7":"code","332dc84a":"code","ba1223bb":"code","da5a470c":"code","d1bbf128":"code","be52abda":"markdown","853ed7e9":"markdown","82a0f2cc":"markdown","f4d8c554":"markdown","c2c06c2c":"markdown","82a581f6":"markdown","ff5d33ed":"markdown","32a350fc":"markdown","59de6675":"markdown","5df88ca7":"markdown","80749629":"markdown","ff9e747d":"markdown","0da1107c":"markdown","5cd94cf2":"markdown","1e2c4a3c":"markdown","7a6249b2":"markdown","37e1d15b":"markdown","c349aceb":"markdown","61ac95d6":"markdown","38575dad":"markdown","752a6a35":"markdown","d75ff986":"markdown","28294624":"markdown","f901ac3f":"markdown","1dd66038":"markdown"},"source":{"46196338":"#imports\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt","e28da50b":"rating = pd.read_csv('\/kaggle\/input\/anime-recommendations-database\/rating.csv')\nrating.head(1)","67a16cdc":"anime0 = pd.read_csv('\/kaggle\/input\/anime-recommendations-database\/anime.csv')\nanime0.head(1)","8bbb7075":"anime = anime0.drop(columns=['name', 'members', 'rating'])","7247a7cf":"# spand genre in columns, one for each genre\ndef func(x):\n    if x['genre'] is np.nan:\n        return x\n    else:\n        genres = list(map(lambda y: y.strip(), x['genre'].split(',')))\n        for g in genres:\n            x[g] = 1\n        return x\n\n\nanime2 = anime.apply(func, axis=1)\nanime2.head(1)","76097a4b":"# expand type in columns, one for each type\none_hot = pd.get_dummies(anime2['type'])\none_hot[one_hot == 0] = np.nan\nanime3 = (anime2\n          .drop(columns=['type', 'episodes', 'genre'])\n          .join(one_hot, rsuffix='-type'))\nanime3.head(1)","d3a60ccb":"rating_anime = rating.join(anime3.set_index('anime_id'), on='anime_id')\nrating_anime.head(1)","b557faa5":"rating_anime.loc[rating_anime['rating'] == -1, 'rating'] = 5\nrating_anime.head()","a31b3ba4":"# anime3 is the dataframe joined before.\n# All columns are anime properties, except anime_id.\nattr = anime3.columns.tolist()\nattr.remove('anime_id')\n\nrating_anime[attr] = rating_anime[attr].mul(rating_anime['rating'], axis=0)\nrating_anime.head(10)","a5036980":"users = (rating_anime\n         .drop(columns=['anime_id', 'rating'])\n         .groupby(by='user_id')\n         .mean())\nusers.head()","eb4a8a62":"users = users.fillna(value=0)\nusers.head()","fc4e9efa":"%matplotlib inline\n\npca = PCA()\npca.fit(users)\nacc_var = np.cumsum(pca.explained_variance_ratio_) \n\nplt.style.use('seaborn')\nplt.plot(range(1, len(acc_var)+1), acc_var)\nplt.title('PCA explained variance')\nplt.xlabel('Number of Variables')\n_ = plt.ylabel('Variance Explained')","3a801e67":"number_of_components = 20\npca.set_params(n_components=number_of_components)\npca.fit(users)\nusers_pca = pca.transform(users)\nusers_pos_pca = pd.DataFrame(users_pca)\nusers_pos_pca['user_id'] = users.index\nusers_pos_pca = users_pos_pca.set_index('user_id')\nusers_pos_pca.head(1)","5c2f92fc":"inertia = []\nscores = []\nfor n_clusters in range(2, 12):\n    kmeans = KMeans(n_clusters=n_clusters, n_jobs=-1)\n    kmeans.fit(users_pos_pca)\n    inertia.append(kmeans.inertia_)\nplt.plot(range(2, 12), inertia)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Quadratic Error')\n_ = plt.title('K-means error vs number of Clusters')","645ce93e":"#project the users feature vector in 3 dimensions\nusers_with_label = pd.DataFrame(PCA(n_components=3).fit_transform(users))\nusers_with_label['user_id'] = users.index\nusers_with_label = users_with_label.set_index('user_id')\n\n#find each user's cluster\nkmeans = KMeans(n_clusters=6, n_init=30, n_jobs=-1)\nusers_with_label['label'] = kmeans.fit_predict(users_pos_pca)\nusers_with_label.head()","d6bba12d":"fig = plt.figure()\nax = Axes3D(fig)\n\nax.scatter(users_with_label[0], users_with_label[1], users_with_label[2], c=users_with_label['label'].to_numpy(), cmap='viridis', s=10)\n_ = plt.title('Clusters')","dda23ba8":"print('Cluster ID     Number of users in cluster')\nfor idx, val in (pd.get_dummies(users_with_label['label'])).sum().iteritems():\n    print(f'{idx}              {val}')","0e5860b5":"rating_user = rating.join(users_with_label[['label']], on='user_id')\nrating_user.loc[rating_user['rating'] == -1, 'rating'] = np.nan\nrating_user.head(1)","ca1604a7":"groups = (rating_user[['anime_id', 'rating', 'label']]\n          .groupby(by=['label', 'anime_id'])\n          .rating.agg(['mean', 'count']))\ngroups.head(2)","332dc84a":"groups['obj'] = groups['mean']*groups['count']\ngroups.head()","ba1223bb":"groups_obj = groups[['obj']].dropna()\ngroups_obj.head(2)","da5a470c":"cats = groups_obj.index.get_level_values(0).unique().tolist()\nrec = []\nfor cat in cats:\n    rec.append(\n        groups_obj\n        .loc[cat]\n        .sort_values(by='obj', ascending=False)\n        .reset_index()\n        .join(\n            anime0[['name', 'anime_id']].set_index('anime_id'),\n            on='anime_id')\n        ['name']\n        .rename(cat)\n    )\nrec = pd.concat(rec, axis=1)\nrec.head(10)","d1bbf128":"for i in range(2, 20, 2):\n    print('First {} recomendations: {} animes in total'\n          .format(\n              i,\n              np.unique(\n                  rec\n                  .head(i)\n                  .to_numpy())\n              .shape[0]))\n","be52abda":"Next we will extract a feature vector for each anime\n","853ed7e9":"The nan values in dataframe refers to categories that the user has never watched an anime in. So, its a good hypotesis to assign a 0 grade to then\n","82a0f2cc":"Based on the plot above, we choose the number of variables. About 80% of variance explained seems good. ","f4d8c554":"## Data preparation\nFirst, lets import the datafiles","c2c06c2c":"I guess that is a good split\n","82a581f6":"Now we can calculate user preference as the mean values for its gradings in each category\n","ff5d33ed":"Great, is not clear at all, but between 4 and 8 seems a good choice. We chose 6.\n","32a350fc":"Next, the rating becomes a weight in the anime properties","59de6675":"A lot (really lot) of animes repeat between clusters. Well, that is reasonable, since the most popular animes can be liked by everyone. But, if all recomendations are the same, this is the most useless code of all times. Lets measure how much variability exists between the lists. I find that a good measure is to count unique values overall. If we have more unique values on a fixed lenght list, we have more differences between clusters, as some anime are suggested for one cluster and not for another\n","5df88ca7":"if some anime has received no evaluation for some user cluster, obj will be nan. We have so much anime to recomend... just drop those that are nan and we should be fine\n","80749629":"# Anime Recomendation based on user clustering\n\n![image.png](attachment:image.png)\n(Image: Spoiler from our projected clusters)\n","ff9e747d":"Awesome, we can see the clusters. It is worth to remember the clustering is done in a higher dimensional space than the plot. If you can project a 20-dimensional space in your head, you can probably see them better than that.\n\nIs the clusters well split, though?\n","0da1107c":"We have to deal with the -1 rating, which indicates that the user has watched the anime but not rated. Well, we can assume that the user hasn't rated because s\/he did not have a good reason to do so (the anime was neither great, nor bad). So we assign a rating of 5 to this animes. It also help us diferenciate between the animes he has watched and not rated (which is preferable) and the ones he has not watched.\n","5cd94cf2":"We find that we do have a good variability, so the recomendation system works\n","1e2c4a3c":"# Cheers!\nIf you like this notebook, don't forget to leave an upvote :)","7a6249b2":"Reorganize this information sorting, for each user cluster, the animes by obj. Replace anime_id by their names and organize everything on a dataframe\n","37e1d15b":"Group the data so we can get the mean rating and the view count for each anime in each user cluster","c349aceb":"## Clustering visualization\n\nNow lets plot the clusters (who doesn't love 3d plots?).\n\nTo do so we need two things:\n* project the users feature vector in 3 dimensions\n* find each user's cluster","61ac95d6":"## Create the recomendations. \n\nWe need to evaluate what is a good anime chosen by the group. There are two important factor, average rating and views (Spoiler: I will multiply then together to build a single score). \n\n\n","38575dad":"Our goodness evaluation (obj - stands for objective) is the mean rating multiplied by the view count.\n","752a6a35":"## K-means clustering\nNow we are ready to clusterize. Kmeans is great, but you have to tell the number of nodes. We try for several number of nodes and choose based on the plot of the quadratic error. The ideia is choosing a value when the curve begins to decrease more slowly. Of course, this is not always very clear, so it is a bit subjective.\n","d75ff986":"Now we can merge each anime features in the rating table\n","28294624":"First, we join to the rating table the user's cluster.\n\nDifferently from before, when the rating assinged is -1, we will ignore it, since we already know the groups and we have a lot of good, non-guessed, ratings.","f901ac3f":"## Introduction\n\nHi! On this notebook we build a anime recomendation system based on user clustering. \n\nWe have the following available data\n* User ratings on animes\n* Information about the anime, like genre and type\n\nWe leverage both these informations to build our recommendation system. So lets get started!","1dd66038":"Lets evaluate how to reduce dimensionality before applying kmeans\n"}}