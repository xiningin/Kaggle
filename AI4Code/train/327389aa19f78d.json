{"cell_type":{"aca8a122":"code","99e54ffb":"code","66f84719":"code","0b39dee5":"code","9cf30c90":"code","70c17acd":"code","5e2ac864":"code","889c2fbd":"code","63825d59":"code","684f9749":"code","bbb7bfe3":"code","98f0356d":"code","3af97e9e":"code","a082274b":"code","4e2788a4":"code","43866add":"code","dd415228":"code","a2423b7e":"code","2423cf26":"code","4b4e4b79":"code","ef795604":"code","0d6de7b9":"code","5c58b84e":"code","226d6638":"code","245a82d6":"code","31ccb5a0":"code","e973e5e1":"code","e7fd2b20":"code","dc639d86":"code","ee34c565":"code","becfc889":"code","87629507":"code","a5b2a747":"code","ed674f68":"code","e399754c":"code","2fdc0fc9":"code","c75211fb":"code","452527d6":"code","b3825d11":"code","ac952be1":"code","b72b93cd":"code","6d655a5c":"code","dafa09e2":"code","427598d2":"code","6e2e4570":"markdown","857d21df":"markdown","d1202e03":"markdown","3332082c":"markdown","61a87e99":"markdown","6c7b25ab":"markdown","782f767f":"markdown","00875fbb":"markdown","44e47c4a":"markdown","6d750c70":"markdown","dc4cad0f":"markdown","f930610b":"markdown","7269d5f7":"markdown","cfcb0785":"markdown","62dadac9":"markdown","41a09536":"markdown","d7989316":"markdown","cc8fb5b1":"markdown","a2ea79b9":"markdown","f8b48c7e":"markdown","938abbe6":"markdown","3cc0d8d2":"markdown"},"source":{"aca8a122":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, plot_confusion_matrix, classification_report\nfrom scipy import stats\n\nimport warnings\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","99e54ffb":"directory = \"\/kaggle\/input\/airline-passenger-satisfaction\/\"\nfeature_tables = ['train.csv', 'test.csv']\n\ndf_train = directory + feature_tables[0]\ndf_test = directory + feature_tables[1]\n\n# Create dataframes\nprint(f'Reading csv from {df_train}...')\ntrain = pd.read_csv(df_train)\nprint('...Complete')\n\nprint(f'Reading csv from {df_train}...')\ntest = pd.read_csv(df_test)\nprint('...Complete')","66f84719":"train.drop(['Unnamed: 0'], axis=1, inplace=True)","0b39dee5":"df_bad = pd.DataFrame([[129881,np.nan,\"Loyal Customer\" ,23,\"Personal Travel\",\"Eco Plus\",275,1,1,1,3,3,1,5,5,1,4,3,2,1,2,2,5,\"satisfied\"]\n,[129882,\"Male\",\"Loyal Customer\" ,23,\"Personal Travel\",\"Eco Plus\",270,1,3,1,4,5,5,2,4,2,5,4,1,4,1,2,1,\"satisfied\"]\n,[129883,\"Female\",\"Loyal Customer\" ,27,\"Personal Travel\",np.nan,281,3,2,2,3,3,1,4,1,4,4,2,2,2,1,2,3,\"satisfied\"]\n,[129884,\"Male\",\"Loyal Customer\" ,66,\"Personal Travel\",\"Eco Plus\",125,5,4,3,2,4,1,4,5,2,1,1,3,2,2,2,4,\"neutral or dissatisfied\"]\n,[129885,\"Female\",\"Loyal Customer\" ,14,\"Personal Travel\",\"Eco Plus\",151,4,2,2,2,4,np.nan,1,3,4,2,4,np.nan,4,3,1,3,\"satisfied\"]\n,[129886,\"Mal\",np.nan,23,\"Personal Travel\",\"Eco Plus\",177,5,5,3,1,3,4,2,4,3,1,1,5,1,2,1,2,\"satisfied\"]\n,[129887,np.nan,\"Loyal Customer\" ,200,\"Personal Travel\",\"Eco Plus\",216,3,2,1,3,1,5,1,3,5,4,5,3,2,1,2,4,\"satisfied\"]\n,[129888,\"Male\",\"Loyal Customer\" ,28,\"Personal Travel\",np.nan,162,5,4,1,4,4,1,4,1,1,3,2,5,1,5,1,2,\"neutral or dissatisfied\"]\n,[129889,\"Female\",\"Loyal Customer\" ,34,np.nan,\"Eco Plus\",159,4,5,1,4,5,2,4,5,np.nan,2,1,2,3,5,4,1,\"satisfied\"]\n,[129890,\"Male\",\"Loyal Customer\" ,51,\"Personal Travel\",\"Eco Plus\",242,3,3,5,4,3,4,3,4,2,1,2,2,3,3,2,5,\"satisfied\"]\n,[129891,\"Female\",\"Loyal Customer\" ,44,\"Personal Travel\",\"Eco Plus\",207,2,5,2,5,4,1,4,5,5,5,1,2,4,3,4,1,\"neutral or dissatisfied\"]\n,[129892,\"Male\",np.nan,1,\"Personal Travel\",\"Eco Plus\",-220,1,4,5,np.nan,3,5,5,5,5,5,4,3,2,4,4,2,\"satisfied\"]\n,[129893,np.nan,\"Loyal Customer\" ,14,np.nan,\"Eco Plus\",113,1,5,4,3,3,5,5,2,3,3,2,1,3,3,3,3,\"neutral or dissatisfied\"]\n,[129894,\"Male\",\"Loyal Customer\" ,61,\"Personal Travel\",\"Eco Plus\",184,3,4,2,5,2,3,2,1,5,3,1,5,2,1,3,1,\"satisfied\"]\n,[129895,\"Female\",\"Loyal Customer\" ,48,\"Personal Travel\",\"Eco Plus\",155,5,4,4,1,5,3,5,4,2,2,5,3,2,np.nan,1,3,\"satisfied\"]\n,[129896,\"Male\",\"Loyal Customer\" ,199,\"Personal Travel\",\"Eco Plus\",171,5,2,3,2,5,3,4,3,3,1,4,1,2,5,3,4,\"neutral or dissatisfied\"]\n])\n#pd.DataFrame()\n\ndf_bad.columns = train.columns\ntrain = train.append(df_bad)","9cf30c90":"train.head()","70c17acd":"train.describe()","5e2ac864":"train.isnull().any()","889c2fbd":"for col in train.columns:\n    if train[col].isnull().any():\n        print(col, train[col].dtype, )","63825d59":"train[train['Customer Type'].isna()]","684f9749":"train['Customer Type'].value_counts()","bbb7bfe3":"train['Customer Type'] = train['Customer Type'].fillna(\"Loyaly Customer\")\ntrain['Customer Type'].isnull().any()","98f0356d":"train['Type of Travel'] = train['Type of Travel'].fillna(\"Business travel\")\n\ntrain['Gender'] = train['Gender'].fillna(\"Female\")\n\ntrain['Class'] = train['Class'].fillna(\"Business\")\n\ntrain['Gate location'] = train['Gate location'].fillna(train['Gate location'].median())\n\ntrain['Online boarding'] = train['Online boarding'].fillna(train['Online boarding'].median())\n\ntrain['On-board service'] = train['On-board service'].fillna(train['On-board service'].median())\n\ntrain['Checkin service'] = train['Checkin service'].fillna(train['Checkin service'].median())\n\ntrain['Cleanliness'] = train['Cleanliness'].fillna(train['Cleanliness'].median())\n'''\nArrival Delay in Minutes float64'''","3af97e9e":"sns.distplot(np.log1p(train['Arrival Delay in Minutes']), bins=5)\n","a082274b":"#Should I fill with 0 or median value?\n\n#Vote in: https:\/\/www.strawpoll.me\/33402615\n\n#train['Arrival Delay in Minutes'] = train['Arrival Delay in Minutes'].fillna(train['Arrival Delay in Minutes'].median())\ntrain['Arrival Delay in Minutes'] = train['Arrival Delay in Minutes'].fillna(0)\n","4e2788a4":"train.isnull().any()","43866add":"train.describe()","dd415228":"sns.boxplot(train['Age'])","a2423b7e":"\n\nsns.scatterplot(data=train, x=\"id\", y=\"Flight Distance\")\n\n#which ones are the outliers?\n#https:\/\/www.strawpoll.me\/33402725","2423cf26":"train = train[train['Age']<=120]\n\ntrain = train[train['Flight Distance']>0]","4b4e4b79":"fig = plt.figure(figsize=(15, 12))\n\nsubset = train[[\"id\", \"Age\",\"Flight Distance\", \"Inflight wifi service\",\"Departure\/Arrival time convenient\",\"Ease of Online booking\",\"Gate location\",\"Food and drink\",\"Online boarding\",\"Seat comfort\",\"Inflight entertainment\",\"On-board service\",\"Leg room service\",\"Baggage handling\",\"Checkin service\",\"Inflight service\",\"Cleanliness\",\"Departure Delay in Minutes\",\"Arrival Delay in Minutes\",]]\nfor i in range(1, subset.shape[1]):\n    plt.subplot(7, 7, i)\n    f = plt.gca()\n    f.axes.get_yaxis().set_visible(False)\n    # f.axes.set_ylim([0, train.shape[0]])\n\n    vals = np.size(subset.iloc[:, i].unique())\n    if vals < 10:\n        bins = vals\n    else:\n        vals = 10\n\n    plt.hist(subset.iloc[:, i], bins=10)\n\nplt.tight_layout()\n","ef795604":"train.satisfaction.value_counts()","0d6de7b9":"str_cols = [\"Gender\", \"Customer Type\", \"Type of Travel\", \"Class\", \"satisfaction\"]\n\n\nfor col in str_cols:\n    print(col)\n    print(train[col].value_counts())\n    print(\"+---------------------------------+\")\n","5c58b84e":"train['Gender'] = np.where(train['Gender'] == 'Mal', 'Male', train['Gender'])\ntrain['Customer Type'] = np.where(train['Customer Type'] == 'Loyaly Customer', 'Loyal Customer', train['Customer Type'])","226d6638":"cat_cols = [\"Gender\", \"Customer Type\", \"Type of Travel\", \"Class\"]\n\n","245a82d6":"pd.get_dummies(train['Gender'], columns=[\"Gender\"])","31ccb5a0":"train[cat_cols].head()","e973e5e1":"df_cat = pd.get_dummies(train[cat_cols], columns=cat_cols)\ndf_cat.head()","e7fd2b20":"train.info()","dc639d86":"num_cols = [\"Age\",\"Flight Distance\",\"Inflight wifi service\",\"Departure\/Arrival time convenient\",\"Ease of Online booking\",\"Gate location\",\"Food and drink\",\"Online boarding\",\"Seat comfort\",\"Inflight entertainment\",\"On-board service\",\"Leg room service\",\"Baggage handling\",\"Checkin service\",\"Inflight service\",\"Cleanliness\",\"Departure Delay in Minutes\",\"Arrival Delay in Minutes\", \"satisfaction\"]\ndf_num = train[num_cols]\ndf_num[\"satisfaction\"] = np.where(df_num[\"satisfaction\"] == \"satisfied\", 1, 0)\ndf_num.head()","ee34c565":"df = pd.concat([df_num, df_cat], axis=1)","becfc889":"df.columns","87629507":"df = df[['Age','Flight Distance','Inflight wifi service','Departure\/Arrival time convenient','Ease of Online booking','Gate location','Food and drink','Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service','Inflight service','Cleanliness','Departure Delay in Minutes','Arrival Delay in Minutes','Gender_Female','Gender_Male','Customer Type_Loyal Customer','Customer Type_disloyal Customer','Type of Travel_Business travel','Type of Travel_Personal Travel','Class_Business','Class_Eco','Class_Eco Plus','satisfaction']]\ndf.head()","a5b2a747":"fig_dims = (80, 100)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.set(font_scale=2)\nsns.heatmap(df.corr(), annot=True, ax = ax)\n\n","ed674f68":"df[['Gate location', 'satisfaction']]\n\n\nsns.jointplot(data=df[['Gate location', 'satisfaction']], x=\"Gate location\", y=\"satisfaction\")\n","e399754c":"\nsns.jointplot(data=df[['Departure\/Arrival time convenient', 'satisfaction']], x=\"Departure\/Arrival time convenient\", y=\"satisfaction\")\n","2fdc0fc9":"df.columns","c75211fb":"#'Departure\/Arrival time convenient' is removed\n\n#Define our features and target (this is helpful in case you would like to drop any features that harm model performance)\nfeatures = ['Age','Flight Distance','Inflight wifi service','Departure\/Arrival time convenient','Ease of Online booking','Gate location','Food and drink','Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service','Inflight service','Cleanliness','Departure Delay in Minutes','Arrival Delay in Minutes','Gender_Female','Gender_Male','Customer Type_Loyal Customer','Customer Type_disloyal Customer','Type of Travel_Business travel','Type of Travel_Personal Travel','Class_Business','Class_Eco','Class_Eco Plus']\ntarget = ['satisfaction']\n\nfrom sklearn.model_selection import train_test_split\n\nX = df[features]\ny = df[target].to_numpy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n\n# Normalize Features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","452527d6":"def run_model(model, X_train, y_train, X_test, y_test, verbose=True):\n    if verbose == False:\n        model.fit(X_train,y_train, verbose=0)\n    else:\n        model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    roc_auc = roc_auc_score(y_test, y_pred.round())\n    print(\"ROC_AUC = {}\".format(roc_auc))\n    print(classification_report(y_test,y_pred.round(),digits=5))\n    plot_confusion_matrix(model, X_test, y_test.round(),cmap=plt.cm.Blues, normalize = 'all')\n    \n    return model, roc_auc","b3825d11":"from sklearn.linear_model import LogisticRegression\n\n\n\nmodel_lr = LogisticRegression()\nmodel_lr, roc_auc_lr = run_model(model_lr, X_train, y_train, X_test, y_test)","ac952be1":"for i in range(len(X.columns)):\n    print (X.columns[i] , 'x ',model_lr.coef_[0][i],  ' + ')\n\nprint(model_lr.intercept_[0])","b72b93cd":"model_lr.coef_","6d655a5c":"params_rf = {'max_depth': 25,\n         'min_samples_leaf': 1,\n         'min_samples_split': 2,\n         'n_estimators': 200,\n         'random_state': 42}\n\nmodel_rf = RandomForestClassifier(**params_rf)\nmodel_rf, roc_auc_rf = run_model(model_rf, X_train, y_train, X_test, y_test)","dafa09e2":"params_xgb ={}\n\nmodel_xgb = xgb.XGBClassifier(**params_xgb)\nmodel_xgb, roc_auc_xgb = run_model(model_xgb, X_train, y_train, X_test, y_test)","427598d2":"auc_scores = [roc_auc_lr, roc_auc_rf, roc_auc_xgb]\nmodel_scores = pd.DataFrame(auc_scores, index=['Linear Regression','Random Forest','XGBoost'], columns=['AUC'])\nmodel_scores.head()","6e2e4570":"### Linear Models\n\n![](https:\/\/i0.wp.com\/cmdlinetips.com\/wp-content\/uploads\/2020\/03\/Linear_Regression_Beta_Hat_Matrix_Multiplication.png?resize=561%2C136&ssl=1)\n\n\n&nbsp;\n&nbsp;\n&nbsp;\n\nor more simply:\n\n&nbsp;\n&nbsp;\n&nbsp;\n\n\n<img src=\"https:\/\/static.packt-cdn.com\/products\/9781789537123\/graphics\/78c4af48-3b33-4cbd-bc15-45aeb0f8833e.png\" width=\"200\">\n\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n\nWe aim to find the best function to fit for our parameters a and b.\n\n<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSLOy-ZBkyQ11sPq0URHUrWwJvhpZNGNsWDA1Un19rmCyTnaE6V\">\n\n&nbsp;\n&nbsp;\n&nbsp;\n\n### Tree Based Algorithms\n![](https:\/\/cdn-images-1.medium.com\/max\/824\/0*J2l5dvJ2jqRwGDfG.png)\n\n### Ensemble Models\nCombining multiple models and voting the best average results.\n![](https:\/\/miro.medium.com\/max\/600\/1*sSSHJeUE2WHp3xD35NoJ9w.png)\n\n### Neural Networks\nSingle Neuron\n![](https:\/\/miro.medium.com\/max\/1826\/1*L9xLcwKhuZ2cuS8fF0ZjwA.png)\n\nMore Complex Architectures\n![](https:\/\/www.asimovinstitute.org\/wp-content\/uploads\/2019\/04\/NeuralNetworkZoo20042019.png)\n","857d21df":"### Now a Sample Application\nLet's put in use, what we have learnt.\n\nThe task is to estimate the passenger satisfaction in a flight.","d1202e03":"#### What is the value with this approach?","3332082c":"### Exploratory Data Analysis: Understanding the data","61a87e99":"### Building the Model\nNow we have our data in shape, now time to build our model and investigate the results.","6c7b25ab":"What could go wrong?\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/1\/19\/Overfitting.svg\/1200px-Overfitting.svg.png\" width=\"600\">","782f767f":"### Linear Regression\n\n","00875fbb":"### Data Characteristics","44e47c4a":"### Random Forest \n\nA great place to start! We are seeing an accuracy of 96.30%. Lets see if the other models can compare.","6d750c70":"## Model Evaluation\n\nNow let's create our model\n\n#### how do we measure our models' performance\nPrecision & Recall\n![](https:\/\/cdn-images-1.medium.com\/fit\/t\/1600\/480\/1*Ub0nZTXYT8MxLzrz0P7jPA.png)\n\nF1-score\n![](https:\/\/miro.medium.com\/max\/1624\/0*DaA9fG5env3JGp2k)\n","dc4cad0f":"We have some non-numerical columns. How do we process them?\nhttps:\/\/www.strawpoll.me\/33402755","f930610b":"Gate Location, Departure\/Arrical time convenient,  seems to be irrelevant. \n\nFood and Drink seem to be multicollinear with Cleanliness, Inflight entertainment and Seat comfort\n\nCategorical dummy variables seem to be highly multicollinear. Shouldn't it be?","7269d5f7":"Features' relation with our target","cfcb0785":"### XGBoost\n\nNotorious XGBoost","62dadac9":"Let's check if we have null values","41a09536":"### Loss Function\n\n![](https:\/\/miro.medium.com\/max\/500\/0*gglavDlTUWKn4Loe)\n\nFor tree based methods, Gini index and Entrophy Loss are calculated. \n&nbsp;\nFor K-NN, distance between data points are calculated. \n\n#### Gradient Descent\nWhile finding out our optimum function parameters we need to minimize our error  ei . To reduce computational complexity, we use Gradient Descent.\n\nGradient Descent is a method to find the local minimum for the cost function that is defined by function parameter and errors.\n\n![](https:\/\/pbs.twimg.com\/media\/EK2QGHyW4AAooxn?format=png&name=small)\n\n#### Activation Functions & Back Propagation\nNeural networks require activation functions to transmit their output over their Axons.\n\nAccording to the loss function at the output neuron, we can rearrange the weights on the previous paths in the network. \n\n![](https:\/\/missinglink.ai\/wp-content\/uploads\/2018\/11\/activationfunction-1.png)\n\n","d7989316":"What about passenger grades? Are they numerical or categorical?\nhttps:\/\/www.strawpoll.me\/33402823","cc8fb5b1":"Let's check our data distribution","a2ea79b9":"## Introduction to Machine Learning: Basic Concepts\n\n### Supervised Learning\n\n\n<img src=\"https:\/\/miro.medium.com\/max\/2494\/1*nJCYz0UIJNtRF7Et2Pi_aQ.png\" width=\"600\">\n\n\n### Unsupervised Learning\n\n<img src=\"https:\/\/static.packt-cdn.com\/products\/9781788393485\/graphics\/f8315f3f-703d-4929-bd7b-cd40db553fc5.png\" width=\"600\">\n\n### Reinforcement Learning\n\n<img src=\"https:\/\/miro.medium.com\/max\/3084\/0*WC4l7u90TsKs_eXj.png\" width=\"600\">\n","f8b48c7e":"## Main Components\n\n* Data\n* Loss Function\n* Algorithm\n\n### Data\n\nData should be in a tabular format in which each datapoint corresponds to the atomic information in the set. ML algorithms can only process numeric data.\n\n**Time series**\n![](https:\/\/i.ibb.co\/jLKD1c8\/timeseries.png)\n&nbsp;\n&nbsp;\n&nbsp;\n![](https:\/\/i.ibb.co\/RPhdN96\/timeseries2.png)\n\n\n\n**Numeric data**\n![](https:\/\/miro.medium.com\/max\/1048\/1*k7ZifUD4IFuiN06TVnVIVw.png)\n\n\n\n**Images**\n\n![](https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/02\/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png)\n\n![](https:\/\/jamesmccaffrey.files.wordpress.com\/2014\/06\/mnist_viewer_demo.jpg)\n\n\n\n\n**Text**\n![](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2020\/02\/BoWBag-of-Words-model-2.png)\n","938abbe6":"### Algorithm\n\n* Linear \n* Tree Based \n* Ensemble Models\n* Neural Networks","3cc0d8d2":"Let's add some anomalies"}}