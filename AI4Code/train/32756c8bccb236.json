{"cell_type":{"37c9987c":"code","ffbe609c":"code","b4a28735":"code","7aace649":"code","79060b94":"code","613e8121":"code","6e52605e":"code","d3ad3dbb":"code","84f33485":"code","ae59d36d":"markdown"},"source":{"37c9987c":"# =======================================================\n# TPS Nov 2021 - Simple Reg Log\n# =======================================================\n# Name: B\u00e1rbara Sulpis\n# Date: 1-nov-2021\n# Description: I will run an XGBoost with Hyperparameter Tuning\n# Python 3 - kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nfrom sklearn.model_selection import train_test_split\n\n#Lgbm\nimport lightgbm as lgb\n\n# roc\nimport sklearn.metrics as metrics   # Para la curva ROC\nimport matplotlib.pyplot as plt     # Para la curva ROC\n\n\n# ---------------------------\n# Input data:\n# Go to file -> add or upload data -> \"Competition\" data tab and select the commpetition which you want to add the csv data data \"\n# files are available in the read-only \"..\/input\/\" directory\n# ---------------------------\n\ndata = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")        \nsubm = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ffbe609c":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix","b4a28735":"def Draw_ROC(y_test, preds, base_name):\n    fpr, tpr, threshold = metrics.roc_curve(y_test , preds)\n    roc_auc = metrics.auc(fpr, tpr)\n\n    plt.title('Receiver Operating Characteristic ('+ base_name+ ')')\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.6f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n","7aace649":"# --------------------------------------------------------------------\n#     TARGET\n# --------------------------------------------------------------------\ny = data['target']\nX = data.drop(['target', 'id'], axis=1)","79060b94":"# --------------------------------------------------------------------\n#     SPLIT TRAIN - TEST - VALIDATION\n# --------------------------------------------------------------------\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)","613e8121":"model = LogisticRegression(solver='liblinear', random_state=0)","6e52605e":"model.fit(X_train, y_train)","d3ad3dbb":"# ---------------------------------------\n#  ROC : VALIDATION\n# ---------------------------------------\n\n# calculate the fpr and tpr for all thresholds of the classification\ny_predict = model.predict_proba(X_test)\npreds = y_predict  [:,1]   # CLF_pred es la variable con las predicciones de probabilidad\nbase_name = 'VALIDATION'\nDraw_ROC(y_test, preds, base_name)","84f33485":"# ---------------------------------------\n#  SUBMISSION FILE \n# ---------------------------------------\nX_subm = subm.drop(['id'], axis=1)\ny_preds_subm = model.predict_proba(X_subm)\n\nsubmit = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\nsubmit['target'] = y_preds_subm  [:,1]\n#submit.to_csv(\"LGBM_Baseline.csv\", index=False)\nsubmit.to_csv(\"TPS_nov21_RegLog.csv\", index=False)\nsubmit.head()","ae59d36d":"optional parameters that define the behavior of the model and approach:\n\n**penalty** is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n\n**dual** is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).\n\n**tol** is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n\n**C** is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n\n**fit_intercept** is a Boolean (True by default) that decides whether to calculate the intercept \ud835\udc4f\u2080 (when True) or consider it equal to zero (when False).\n\n**intercept_scaling** is a floating-point number (1.0 by default) that defines the scaling of the intercept \ud835\udc4f\u2080.\n\n**class_weight** is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n\n**random_state** is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n\n**solver** is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n\n**max_iter** is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.\n\n**multi_class** is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n\n**verbose** is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.\n\n**warm_start** is a Boolean (False by default) that decides whether to reuse the previously obtained solution.\n\n**n_jobs** is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.\n\n**l1_ratio** is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.\n\nYou should carefully match the solver and regularization method for several reasons:\n\n'liblinear' solver doesn\u2019t work without regularization.\n'newton-cg', 'sag', 'saga', and 'lbfgs' don\u2019t support L1 regularization.\n'saga' is the only solver that supports elastic-net regularization."}}