{"cell_type":{"11e0e205":"code","72acb2e7":"code","35d9e490":"code","e08af6bb":"code","548e6153":"code","9d71a9a9":"code","26f635bc":"code","29fb3407":"code","18164eba":"code","d222e046":"code","29230510":"code","5147b6be":"code","9cf8596a":"code","55cf87b9":"code","5a46eccc":"code","2f3b2e7c":"code","ec225189":"code","7332f0c2":"code","f512c389":"code","f478d822":"code","4bd46519":"code","eaa9af57":"code","9cefea76":"code","168656e7":"code","92b6676d":"code","0f87504c":"code","3f0809b1":"code","4219dc7b":"code","32732035":"code","ac3bed2a":"code","8fc0748c":"code","9f42095b":"markdown","c3acd8c3":"markdown","6bc6665c":"markdown","754dc552":"markdown","8fcefcea":"markdown","25692e09":"markdown","82df8836":"markdown","cd0cab20":"markdown","92d7bd87":"markdown","ee46ac2e":"markdown"},"source":{"11e0e205":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n\nsns.set_style('dark')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","72acb2e7":"df = pd.read_csv(r'\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv', sep = '\\t')\ndf.head()","35d9e490":"df.isna().sum()","e08af6bb":"df = df.dropna()\ndf = df.drop(columns =['ID'])","548e6153":"df['Expenditure'] = df['MntMeatProducts'] + df['MntWines'] + df['MntFruits'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']\ndf['Purchases'] = df['NumDealsPurchases'] + df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases']\ndf['Average Spending'] = df['Expenditure'] \/ df['Purchases']\ndf['Children'] = df['Kidhome'] + df['Teenhome']\ndf['Coupons Accepted'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + df['AcceptedCmp4'] + df['AcceptedCmp5']\ndf['Age'] = (pd.to_datetime(2021, format =  '%Y') - pd.to_datetime(df['Year_Birth'], format = '%Y'))\/np.timedelta64(1, 'Y')\ndf['Tenure'] = (pd.to_datetime(2021, format = '%Y')- pd.to_datetime(df['Dt_Customer']))\/np.timedelta64(1,'Y')\ndf = df.drop(columns = ['Year_Birth', 'Dt_Customer'])","9d71a9a9":"def plt_columns(df, df_columns, hue = 'Coupons Accepted', cluster_column = 'Clusters_2p', plt_type = 'scatter'):\n    df = df.copy()\n    \n    rows = len(df_columns) \/\/ 3\n    columns = len(df_columns) \/\/ rows + 1\n    \n    fig, axes = plt.subplots(rows, columns, figsize = (30, 30))\n    axes = axes.flatten()\n    for axe in axes:\n        axe.set_axis_off()\n       \n    color = ['blue', 'orange', 'green', 'black']\n    \n    for idx, col in enumerate(df_columns):\n        if plt_type == 'scatter':\n            sns.scatterplot(x = col, y = 'Average Spending', data = df, hue = hue, ax = axes[idx])\n        elif plt_type == 'hist':\n            cluster_means = df.groupby(by = cluster_column)['Income'].mean().sort_values().index.to_list()\n            bins = np.histogram_bin_edges(df[col], bins = 15)\n            for mdx in cluster_means:\n                sns.histplot(x = col, stat = 'percent', data = df.loc[df[hue] == cluster_means[mdx]],\\\n                             color = color[mdx], bins = bins, ax = axes[idx])\n        elif plt_type == 'box':\n            cluster_means = df.groupby(by = cluster_column)['Income'].mean().sort_values().index.to_list()\n            for mdx in cluster_means:\n                sns.boxplot(x = col, y = 'Average Spending', data = df.loc[df[hue] == cluster_means[mdx]], color = color[mdx])\n        axes[idx].set_axis_on()\n    plt.tight_layout()","26f635bc":"numerical_columns = df.select_dtypes(np.number).drop(columns = ['Kidhome', 'Teenhome', 'Average Spending']).columns\ncategorical_columns = df.select_dtypes(exclude = np.number).columns\n\n\nplt_columns(df, numerical_columns, hue = 'Coupons Accepted', plt_type = 'scatter')\n#rows = len(numerical_columns) \/\/ 3\n#columns = (len(numerical_columns) \/\/ rows) + 1\n\n#fig, axes = plt.subplots(rows, columns, figsize = (20, 20))\n#axes = axes.flatten()\n#for axe in axes:\n#    axe.set_axis_off()\n\n#for idx, col in enumerate(numerical_columns):\n#    sns.scatterplot(x = col, y = 'Average Spending', data = df, hue = 'Coupons Accepted', ax = axes[idx])\n#    axes[idx].set_axis_on()\n#plt.tight_layout()","29fb3407":"df = df.drop(columns = ['Z_CostContact', 'Z_Revenue'])","18164eba":"def remove_outliers(df, outlier):\n    '''\n    Removes data points that are 1.5 * IQR\n    Away from the 25%\/75% Quantile\n    '''\n    q25 = df[outlier].quantile(0.25)\n    q75 = df[outlier].quantile(0.75)\n    iqr = q75 - q25\n    df = df.loc[(df[outlier] >= q25 - (1.5 * iqr)) &\n               (df[outlier] <= q75 + (1.5 * iqr))]\n    return df","d222e046":"outlier_columns = ['Age', 'NumWebPurchases', 'MntSweetProducts', 'NumCatalogPurchases', 'NumWebVisitsMonth', 'Income']\nfor outlier in outlier_columns:\n    df = remove_outliers(df, outlier)\n    \nsns.scatterplot(x = 'Income', y = 'Average Spending', hue = 'Coupons Accepted', data = df)","29230510":"df['Education'].value_counts()\neducation_dict = {'Graduation' : 'Undergrad', 'PhD' : 'Post-grad', 'Master' : 'Post-grad', '2n Cycle' : 'Undergrad', 'Basic' : 'No College'}\ndf['Education'] = df.loc[:, 'Education'].map(lambda x: education_dict[x])","5147b6be":"df['Marital_Status'].value_counts()\nmartial_dict = {'Married' : 'Married', 'Together' : 'Married', 'Single' : 'Single', 'Divorced' : 'Single', 'Widow' : 'Married', 'Alone' : 'Single', 'YOLO' : 'Single', 'Absurd' : 'Married'}\n#Widowed = Married since I consider widowed people since they were married and are no longer due to death\n#Divorced = Single, because they broke up\n#Absurd = Married because they are married, it's apparenlty a las-vegas styled marriage\ndf['Marital_Status'] = df.loc[:, 'Marital_Status'].map(lambda x: martial_dict[x])","9cf8596a":"rows = 1\ncolumns = 2\nfig, axes = plt.subplots(rows, columns, figsize = (15, 7))\naxes = axes.flatten()\n\nfor idx, col in enumerate(categorical_columns):\n    sns.boxplot(x = col, y = 'Average Spending', hue = 'Coupons Accepted', data = df, ax = axes[idx])","55cf87b9":"df_no_outliers = df.groupby(by = ['Education', 'Coupons Accepted'], as_index = False).apply(remove_outliers, outlier = 'Average Spending')#.drop(columns = 'Education').reset_index()\ndf_no_outliers = df_no_outliers.groupby(by = ['Marital_Status', 'Coupons Accepted']).apply(remove_outliers, outlier = 'Average Spending')","5a46eccc":"rows = 2\ncolumns = 2\norder = [['No College', 'Undergrad', 'Post-grad'], ['Single', 'Married']]\nfig, axes = plt.subplots(rows, columns, figsize = (15, 7))\naxes = axes.flatten()\nfor idx, col in enumerate(categorical_columns):\n    sns.boxplot(x = col, y = 'Average Spending', hue = 'Coupons Accepted', order = order[idx], data = df_no_outliers, ax = axes[2 * idx])\n    sns.countplot(x = col, hue = 'Coupons Accepted', order = order[idx], data = df_no_outliers, ax = axes[2 * idx + 1])","2f3b2e7c":"def make_mean_col(df, col = 'Average Spending'):\n    df[f'Mean_{col}'] = df[col].mean()\n    return df\n\ndef make_std_col(df, col = 'Average Spending'):\n    df[f'Std_{col}'] = df[col].std()\n    return df\n\ndf2 = df[['Education', 'Marital_Status', 'Coupons Accepted', 'Average Spending']].copy()\ndf2 = df2.groupby(by = 'Coupons Accepted').apply(make_mean_col, col = 'Average Spending')\ndf2 = df2.groupby(by = 'Coupons Accepted').apply(make_std_col, col = 'Average Spending')\ndf2.head()\n\n#df2.groupby(by = 'Coupons Accepted')['Average Spending'].mean()","ec225189":"sns.pointplot(x = 'Coupons Accepted', y = 'Average Spending', data = df2)","7332f0c2":"df.columns","f512c389":"X = df.drop(columns = ['Kidhome', 'Teenhome', 'Coupons Accepted'])\nX_numerical_columns = X.drop(columns = ['AcceptedCmp5', 'AcceptedCmp4', 'AcceptedCmp3', 'AcceptedCmp2', 'AcceptedCmp2', 'AcceptedCmp1']).select_dtypes(np.number).columns\nct = ColumnTransformer([('OHE', OneHotEncoder(), categorical_columns), ('Standard Scaler', StandardScaler(), X_numerical_columns)], remainder = 'passthrough')\ncomponents = []\nss = []\nfor i in range(2, 11):\n    X_transformed = ct.fit_transform(X)\n    pipe = Pipeline(steps = [('CT', ct), ('Gaussian Mixture', GaussianMixture(n_components = i))])\n    pipe.fit(X)\n    preds = pipe.predict(X)\n    components.append(i)\n    ss.append(silhouette_score(X_transformed, preds))\nsns.scatterplot(x = components, y = ss)\n    ","f478d822":"pipe = Pipeline(steps = [('CT', ct), ('Gaussian Mixture', GaussianMixture(n_components = 2))])\npipe.fit(X)\ndf['Clusters_2p'] = pipe.predict(X)\npipe_3cp = Pipeline(steps = [('CT', ct), ('Gaussian Mixture', GaussianMixture(n_components = 3))])\npipe_3cp.fit(X)\ndf['Clusters_3p'] = pipe_3cp.predict(X)\npipe_4cp = Pipeline(steps = [('CT', ct), ('Gaussian Mixture', GaussianMixture(n_components = 4))])\npipe_4cp.fit(X)\ndf['Clusters_4p'] = pipe_4cp.predict(X)","4bd46519":"numerical_columns = df.drop(columns = ['Kidhome', 'Teenhome', 'Clusters_2p', 'Clusters_3p', 'Clusters_4p', 'Average Spending']).select_dtypes(np.number).columns\nnumerical_columns","eaa9af57":"plt_columns(df, numerical_columns, hue = 'Clusters_2p', plt_type = 'hist')","9cefea76":"#df['Clusters_2p'] = df['Clusters_2p'].map(lambda x: 'High Income' if x == 1 else 'Low Income')\nplt_columns(df, numerical_columns, hue = 'Clusters_2p', plt_type = 'scatter')","168656e7":"plt_columns(df, numerical_columns, hue = 'Clusters_3p', cluster_column = 'Clusters_3p', plt_type = 'hist')","92b6676d":"plt_columns(df, numerical_columns, hue = 'Clusters_4p', cluster_column = 'Clusters_4p', plt_type = 'hist')","0f87504c":"rows = 1\ncolumns = 2\nfig, axes = plt.subplots(rows, columns, figsize = (15, 7))\naxes = axes.flatten()\n\nfor idx, col in enumerate(categorical_columns):\n    sns.histplot(x = col, color = 'orange', stat = 'percent', data = df[df['Clusters_2p'] == 0], ax = axes[idx])\n    sns.histplot(x = col, color = 'blue', stat = 'percent', data = df[df['Clusters_2p'] == 1], ax = axes[idx])","3f0809b1":"rows = 1\ncolumns = 2\nfig, axes = plt.subplots(rows, columns, figsize = (15, 7))\naxes = axes.flatten()\n\nfor idx, col in enumerate(categorical_columns):\n    sns.histplot(x = col, color = 'orange', stat = 'percent', data = df[df['Clusters_3p'] == 0], ax = axes[idx])\n    sns.histplot(x = col, color = 'blue', stat = 'percent', data = df[df['Clusters_3p'] == 1], ax = axes[idx])\n    sns.histplot(x = col, color = 'green', stat = 'percent', data = df[df['Clusters_3p'] == 2], ax = axes[idx])","4219dc7b":"def get_ratio(df, column_type, cluster_name):\n    '''\n    Gets the ratio of the the column type\n    For example, it will sum the amount of\n    Wine, Gold, etc purchases, and give\n    the ratio of the wine to the total\n    bought\n    Inputs:\n        df - The data df\n        column_type - Mnt, Purchases\n            gives the columns to\n            filter by\n    '''\n    df2 = df.filter(regex = f'({column_type}.*)').copy()\n    df2['Clusters'] = df[cluster_name]\n    a = df2.groupby(by = 'Clusters').sum()\n    b = df2.groupby(by = 'Clusters').sum().sum(axis = 1)\n    df2 = a.divide(b, axis = 0)\n    df2 = df2.melt(ignore_index = False).reset_index()\n    df2.head()\n    return df2\n    ","32732035":"df.groupby(by = 'Clusters_2p')['Income'].mean().sort_values().index.to_list()","ac3bed2a":"fig, axes = plt.subplots(1, 2, figsize = (20, 10))\naxes = axes.flatten()\nX = get_ratio(df, 'Mnt', cluster_name = 'Clusters_2p')\nY = get_ratio(df.drop(columns = 'Purchases'), 'Purchase', cluster_name = 'Clusters_2p')\nsns.barplot(x = 'variable', y = 'value', hue = 'Clusters', data = X, ax = axes[0])\nsns.barplot(x = 'variable', y = 'value', hue = 'Clusters', data = Y, ax = axes[1])\n","8fc0748c":"fig, axes = plt.subplots(1, 2, figsize = (20, 10))\naxes = axes.flatten()\nX = get_ratio(df, 'Mnt', cluster_name = 'Clusters_3p')\nY = get_ratio(df.drop(columns = 'Purchases'), 'Purchase', cluster_name = 'Clusters_3p')\nsns.barplot(x = 'variable', y = 'value', hue = 'Clusters', hue_order = [1, 2, 0], data = X, ax = axes[0])\nsns.barplot(x = 'variable', y = 'value', hue = 'Clusters', hue_order = [1, 2, 0], data = Y, ax = axes[1])\n","9f42095b":"The higher income(cluster 1, orange), and lower income (cluster 0, blue) customers have each item in the same rank, ie wine is their most purchased item, followed by meat, etc. However, the higher income customers thend to buy more gold (as a percentage), than the lower income, while the lower income buy more meat products (as a percentage), so running more sales on gold would probably be something to consider, however, wine accounts for around 6x the sales of gold for this group and attracts half of the lower income group, so wine sales and offers would almost certainly be better.\n\nThe only real difference in the purchase behaviors of the two income groups is that the higher incomes are more likely to purchase deals, and less likely to purchase from catalogs, by a ratio of about 2 in either way. Store purchases, however, makes about twice the number of sales compared to either method for both income groups.","c3acd8c3":"The two clusters here divide the customers into high income (blue) and low income (orange). Some of the information isn't too surprising, people with higher income spend more, and have more purchases. People with higher income are less likely to have children, and are more likely to accepted coupons (the above graphs are a percentage of the total of each group).\n\nHowever, we have some interesting trends. The lower income group visists the website more often, however the higher income group has more web purchases (the second part isn't surprising). This could be that the lower income group spends more time considering their purchases, or has problems finding what they want. Let's see the advantages of three clusters:","6bc6665c":"Things to note: <br>\n    1. Z_CostContact adn Z_Revenue are pointless features for our task <br>\n    2. There's an outlier in the income, anda couple in the age <br>\n    3. The average tenure seems to be 7.5yrs, which is interesting. <br>\n           Perhaps coupons are only given to people who were customers<br>\n           for more than six years?<br>\n    4. Coupon users are mostly people with higher average spending \/ transaction <br>\n           The only categories where they seem to differ are:\n               MntWines, they buy more than average\n               MnFruis, they rarely buy any\n               Income, they are above average\n    5. Nobody accepted all the coupons","754dc552":"Three clusters doesn't really show anything new. The new highest spending grup is the one with teh highest income. The new highest income cluster is even less likely to visit, and has roughly the same number of purchases as the middle income group (which was largely part of the highest income group when there are only two clusters). Finally, a lot of people are using four clusters assuming they correspond to low income young people, high income young people, low income elderly people and high income elderly people.","8fcefcea":"There's no real significance in the education\/marital status between the two groups.","25692e09":"Since two components have a significantly higher silhouette score than any other components, I'll start off with two components. Three components might be interesting as well, however, the ss is basically 0 for higher components.","82df8836":"Sticking two the two clusters, let's see how they like buying items, and what kind of items they like to buy","cd0cab20":"If we split the high income group into a medium income, and high income group, the highest income group shows much of the same pattern. However, the sales of wine is significanlty reduced, for the higher income group (as a percentage), while gold makes up 20% of their sales. ","92d7bd87":"The vast majority of customers dont' use any coupons, with people with most people having at least some college.\n\nThe count graphs give a good perspective to what the values acutally mean. For example the post-grad cohorts have higher median spending for people who use 3\/4 coupons than there is for people who use fewer coupons. However, the people who use more coupons is a highly skewed sample in comparison, with people who use only 2 coupons having about 10x the number of the people using three or four. For such a small number, a few superspenders could severely effect the median. Let's see this skew effects things.","ee46ac2e":"The fourth cluster doesn't really make too much sense. It seems to only consist of people who complain, which might be interesting if complaints are mertitous and make sense to consider for marketing. Ie a customer complaining about a sale not being applied whether the item is still on sale, would be better suited for another branch. We can see that the complainers don't use coupons and visit the web the most. "}}