{"cell_type":{"2d821512":"code","be1f5634":"code","67db7e3b":"code","829f927f":"code","8a3759ea":"code","ba5fe614":"code","703adf61":"code","7f0929ba":"code","ab77aa6e":"code","4497c0c4":"code","375f6229":"code","cf9f9f69":"code","73c91f3b":"code","d63b13f4":"code","fc6bdf4c":"code","aebc2a05":"code","74c210cd":"code","e381c690":"code","6943d7c6":"code","3441e742":"code","28716213":"code","d518ff11":"code","582fe6ef":"code","a367440d":"code","4d6b008b":"code","3c663cee":"code","cd833a2d":"code","ff8cd5bc":"code","86a49682":"code","3c24be0e":"code","102bf5f9":"code","5f271c8f":"code","676736c1":"code","fa8a5502":"code","d70bbe12":"code","3bc9dad8":"markdown","436d75b1":"markdown","dcc1fd6c":"markdown","f8806562":"markdown","2054f187":"markdown","60cdd6e9":"markdown","ec80ed74":"markdown","26a0b63d":"markdown","05ea276b":"markdown","8539aa8d":"markdown","c80a4a97":"markdown","1b7ad704":"markdown","2b3abf97":"markdown","e609dfc9":"markdown","f2967bad":"markdown","d66056b8":"markdown","f72f0535":"markdown","578f998a":"markdown","bbadbfbc":"markdown","df427568":"markdown","6b7998f7":"markdown","328f4f3b":"markdown","9b313445":"markdown","acbb2723":"markdown","50d888b6":"markdown","026e8922":"markdown","c29d649b":"markdown","c19b1a1f":"markdown","a976ae58":"markdown","774c513e":"markdown","f07d71ca":"markdown","034e2934":"markdown"},"source":{"2d821512":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization, MaxPooling2D, Activation\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport cv2\nfrom PIL import Image\nimport itertools\nimport random as rn\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n","be1f5634":"train_dir='..\/input\/boat-types-recognition\/boats'\nbuoy_dir='..\/input\/boat-types-recognition\/buoy'\ncruise_ship_dir='..\/input\/boat-types-recognition\/cruise ship'\nferry_boat_dir='..\/input\/boat-types-recognition\/ferry boat'\nfreight_boat_dir='..\/input\/boat-types-recognition\/freight boat'\ngondola_dir='..\/input\/boat-types-recognition\/gondola'\ninflatable_boat_dir='..\/input\/boat-types-recognition\/inflatable boat'\nkayak_dir='..\/input\/boat-types-recognition\/kayak'\npaper_boat_dir='..\/input\/boat-types-recognition\/paper boat'\nsailboat_dir='..\/input\/boat-types-recognition\/sailboat'","67db7e3b":"def fetchfiles(directory):\n    file_list = []\n    for image_name in os.listdir(directory):\n        filename,extension = os.path.splitext(image_name)\n        file_list.append(image_name)\n    return file_list\n#file_list = fetchfiles(buoy_dir)","829f927f":"labels = {\"buoy\" : 0,\n             \"cruise\" : 1,\n             \"ferry\" : 2,\n             \"freight\": 3,\n             \"gondola\" : 4,\n             \"inflatable\" : 5,\n             \"kayak\" : 6,\n             \"paper\" : 7,\n             \"sail\" : 8}\nlabels_list = list(labels)\ndef fetchlabels(file_list, boat_type):\n    label_list = []\n    for image_name in file_list:\n        label_list.append(boat_type)\n    return label_list\n#fetchlabels(file_list,'buoy')\n#print(\"the length of files is:\", len(file_list))\n#print(\"the length of labels is:\", len(label_list))","8a3759ea":"allfiles =[]\nalllabels = []\nimages_all =[]\nx=[]\n\nfiledirectories = [buoy_dir,cruise_ship_dir,ferry_boat_dir,freight_boat_dir,gondola_dir,inflatable_boat_dir,kayak_dir, paper_boat_dir, sailboat_dir]\n#filedirectories = [cruise_ship_dir,ferry_boat_dir,freight_boat_dir,gondola_dir,inflatable_boat_dir,kayak_dir, paper_boat_dir, sailboat_dir]\n\nfor directory, key in zip(filedirectories,labels):\n    newfiles = fetchfiles(directory)   \n    newlabels = fetchlabels(newfiles,key)\n\n    for i, j in tqdm(zip(newfiles,newlabels)):\n        allfiles.append(i)\n        alllabels.append(j)\n        path = os.path.join(directory,i)\n        img = cv2.imread(path,cv2.IMREAD_COLOR) \n        img = cv2.resize(img, (150,150))\n        x.append(np.array(img))\n        images_all.append(str(j))\n    \n    print(\"The length of the current image array is:\")\n    print(len(x))\n","ba5fe614":"print(\"the length of final files are:\", len(allfiles))\nprint(\"the length of final labels are:\", len(alllabels))\n\nalldata = {\"image\" : allfiles, \"label\" : alllabels}\ndf_alldata = pd.DataFrame(alldata)\nprint(\"the last 5 entries are: \") \nprint(df_alldata.tail())\nprint(\"The columns are:\")\nprint(df_alldata.columns)\nprint(\"The summary\")\ndf_alldata.describe(include=\"all\")","703adf61":"df_alldata.label.value_counts()\ndf_alldata['label'].unique()\ndf_alldata['label'] = df_alldata['label'].astype(str)\n\nplt.figure(figsize=(8,5))\nsns.countplot(data=df_alldata,y=\"label\")","7f0929ba":"fig,ax=plt.subplots(5,5)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (5):\n        index=rn.randint(0,len(alllabels))\n        ax[i,j].imshow(x[index])\n        ax[i,j].set_title(alllabels[index])\nplt.tight_layout()","ab77aa6e":"le=LabelEncoder()\nprint(\"original all_labels \")\nprint(alllabels[100])\ny=le.fit_transform(alllabels)\nprint(\"after transforming to 0-8\")\nprint(y[100])\ny=to_categorical(y,len(labels_list))\nprint(\"after converting to binary vectors\")\nprint(y[100])\nx=np.array(x)\n#x=x\/255\n","4497c0c4":"train_ratio = 0.80\nvalidation_ratio = 0.10\ntest_ratio = 0.10\n\n# train is now 75% of the entire data set\n# the _junk suffix means that we drop that variable completely\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=(1 - train_ratio),stratify=y,random_state=42)\n# test is now 10% of the initial data set\n# validation is now 15% of the initial data set\nx_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio\/(test_ratio + validation_ratio),stratify=y_test,random_state=42) \n#print(x_train, x_val, x_test)\n\n#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42,stratify=y)\n\nprint(len(x_train))\nprint(len(x_test))\nprint(len(x_val))\n\nx_test = x_test\/255.0\nx_val = x_val\/255.0","375f6229":"def count_classes(y_set):\n    class_count =[]\n    image_count = []\n    for i in range(len(y_set)):\n        class_count.append(np.argmax(y_set[i]))\n        image_count.append(i)\n    count_dict = {\"image\" : image_count, \"label\" : class_count}\n    return count_dict\n\ndef count_label_sets(y_set):\n    set_dict = count_classes(y_set)\n    set_df = pd.DataFrame(set_dict)\n    label_counts = pd.DataFrame((set_df.label.value_counts()))\n    label_counts = label_counts.sort_index()\n    #print(label_counts)\n    return label_counts\n\ndef proportions(set_counts,y_set,x_set):\n    set_prop = []\n    for i in range(len(labels_list)): \n        proportion = ((set_counts.iloc[i]['label'])\/len(y_set))*100\n        set_prop.append(proportion)\n    #print(set_prop)\n    return set_prop\n\n#train check\ntrain_counts = count_label_sets(y_train)\n#test check\ntest_counts = count_label_sets(y_test)\n#validation check\nval_counts = count_label_sets(y_val)\n\ntrain_prop = proportions(train_counts,y_train,x_train)\ntrain_counts['Proportion full set %'] = train_prop\nprint(train_counts)\n\ntest_prop = proportions(test_counts,y_test,x_test)\ntest_counts['Proportion full set %'] = test_prop\nprint(test_counts)\n\nval_prop = proportions(val_counts,y_val,x_val)\nval_counts['Proportion full set %'] = val_prop\nprint(val_counts)","cf9f9f69":"#from imblearn.over_sampling import SMOTE \n\n#sm = SMOTE(random_state = 42) \n\n#x_train, y_train = sm.fit_resample(x_train.reshape((-1, 150 * 150 * 3)), y_train)\n#x_train = x_train.reshape((-1, 150, 150, 3))\n#x_train.shape, y_train.sum(axis=0)","73c91f3b":"from sklearn.utils import class_weight\n\ny_ints = [y.argmax() for y in y_train]\n\ny_list = list(np.unique(y_ints))\n\nclass_weights = class_weight.compute_class_weight('balanced',np.unique(y_ints),y_ints)\n\nfor i in range(len(class_weights)):\n    weights = {y_list[i]:class_weights[i] for i in range(len(y_list))}\n\nprint(weights)","d63b13f4":"batch_size=20\nepochs=50\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nred_lr= ReduceLROnPlateau(monitor='val_accuracy',patience=5,verbose=1,factor=0.5,min_lr=.000001)\nES_monitor=EarlyStopping(monitor='val_loss',\n                          patience=20,verbose=1)\n\nfilepath = 'my_best_model.hd5'\ncheckpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy',verbose=1, save_best_only=True,save_weights_only=True,mode='max')","fc6bdf4c":"np.random.seed(42)\nrn.seed(42)\ntf.random.set_seed(42)","aebc2a05":"from tensorflow.keras.layers import GlobalAveragePooling2D\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n                                include_top = False, # Leave out the last fully connected layer\n                                weights = 'imagenet')\n\nx = pre_trained_model.output\n# Adding a global spatial average pooling layer\nx = GlobalAveragePooling2D()(x)\n# Adding a fully-connected dense layer\nx = Dense(1024, activation='relu')(x)\n# Adding a batch normalisation layer\n#x = BatchNormalization(axis=-1,center=True,scale=False)(x)\n# Adding a dropout layer\nx = Dropout(0.25)(x)\n# Adding a final output layer with num of nodes = number of classes\npredictions = Dense(len(labels_list), activation='softmax')(x)\n\n# Combined, these give a final model to train:\nmodel = Model(inputs=pre_trained_model.input, outputs=predictions)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False","74c210cd":"model.compile(optimizer = Adam(lr=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])\n#model.summary()","e381c690":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.01, # Randomly zoom image \n        width_shift_range=0.05,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.05,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,\n        fill_mode='nearest',\n        brightness_range=[1.0,1.0],\n        rescale=1\/255.0\n        #shear_range=0.25,\n        )  # randomly flip images\n\ndatagen.fit(x_train)","6943d7c6":"print(\"Some sample images after image augmentation:\")\nprint(\"\")\n\nfig,ax=plt.subplots(10,2)\nfig.set_size_inches(10,10)\n\nfor x_batch in datagen.flow(x_train):\n  for i in range(0, 9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(x_batch[i]) #cmap=('gray'))\n  plt.show()\n  break","3441e742":"History = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] \/\/ batch_size, \n                    epochs=30, validation_data = (x_test,y_test), verbose = 1,callbacks=[red_lr,ES_monitor,checkpoint], class_weight=weights)","28716213":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","d518ff11":"plt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","582fe6ef":"#for i, layer in enumerate(pre_trained_model.layers):\n   #print(i, layer.name)","a367440d":"for layer in model.layers[:249]:\n   layer.trainable = False\nfor layer in model.layers[249:]:\n   layer.trainable = True","4d6b008b":"model.compile(optimizer = Adam(lr=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","3c663cee":"History = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] \/\/ batch_size, \n                    epochs=50, validation_data = (x_test,y_test), verbose = 1,callbacks=[red_lr,ES_monitor,checkpoint],class_weight=weights)","cd833a2d":"model_dir = 'my_best_model.hd5'\nmodel.load_weights(model_dir)","ff8cd5bc":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","86a49682":"plt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","3c24be0e":"model.evaluate(x_test,y_test)","102bf5f9":"model.evaluate(x_val,y_val)","5f271c8f":"model.save(\"boat_classification_model.h5\")\nprint(\"Saved model to disk\")","676736c1":"pred=model.predict(x_val)\npred_digits=np.argmax(pred,axis=1)\nprint(len(pred_digits))\nprint(\"\")\n\ni=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(y_val)):\n    if(np.argmax(y_val[i])==pred_digits[i]):\n        prop_class.append(i)\nprint(len(prop_class))\n    #if(len(prop_class)==20):\n        #break\n\ni=0\nfor i in range(len(y_val)):\n    if(not np.argmax(y_val[i])==pred_digits[i]): #if y_val == predcited value, then append to mis_class\n        mis_class.append(i)\nprint(len(mis_class))\n    #if(len(mis_class)==20):\n        #break\n\nprint(len(prop_class)\/len(y_val))\nprint(len(mis_class)\/len(y_val))","fa8a5502":"warnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ncount=0\nfig,ax=plt.subplots(10,2)\nfig.set_size_inches(30,30)\nfor i in range (10):\n    for j in range (2):\n        ax[i,j].imshow(x_val[prop_class[count]])\n        ax[i,j].set_title(\"Predicted boat : \"+str(le.inverse_transform([pred_digits[prop_class[count]]])))\n        plt.tight_layout()\n        count+=1","d70bbe12":"warnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ncount=0\nfig,ax=plt.subplots(10,2)\nfig.set_size_inches(30,30)\nfor i in range (10):\n    for j in range (2):\n        ax[i,j].imshow(x_val[mis_class[count]])\n        ax[i,j].set_title(\"Predicted : \"+str(le.inverse_transform([pred_digits[mis_class[count]]])))\n        plt.tight_layout()\n        count+=1","3bc9dad8":"**Plotting the correctly classified images**","436d75b1":"**Defining the ratio of train, validation and test. Splitting datasets with stratify set to enure an equal proportion of classes is generated between each set.\nNormalising the test and validation sets. The train will be normalised in the data generator.**","dcc1fd6c":"*There are various techniques that can be employed to deal with unequal distributions of classes. These include under and oversampling techniques, including SMOTE, or balancing out class weights in the model.fit() step.*","f8806562":"**Fitting the first portion of the model, with our new additional layers.**","2054f187":"**Preparing directory paths**","60cdd6e9":"**Counting proportion of classes in each set.**","ec80ed74":"**Re-fitting the pre-trained model**","26a0b63d":"**Compiling the model with Adam optimiser with the loss as categorical crossentropy for a multi-class problem.**","05ea276b":"**Recompiling the model with additional layers**","8539aa8d":"**Preparing the prediction results into a correct and incorrect class**","c80a4a97":"**Fetch the files for a particular directory**","1b7ad704":"**Calculating a balanced distribution of class weights to help with unequal distribution of class images**","2b3abf97":"**Inspecting the data using a pandas DataFrame**","e609dfc9":"**Encoding string variables to 0-1 then \nOne hot encoding y into binary vector**","f2967bad":"**Importing the InceptionV3 pre-trained model, adding additional lower layers and freezing all other layers in the InceptionV3 model.**","d66056b8":"**Plotting the train and test model loss**","f72f0535":"**Fetch the labels for a particular boat type**","578f998a":"**Generate a list of all files in all classes**","bbadbfbc":"**Plotting the train and test model loss and accuracy**","df427568":"**Saving the full model to disk for easy reloading**","6b7998f7":"**Evaluating final loss and accuracy on the test set**","328f4f3b":"**Unfreezing a portion of the lowest layers from InceptionV3**","9b313445":"**Plotting the train and test model accuracy**","acbb2723":"**Carrying out image augmentation and fitting the data generator to the training image data.**","50d888b6":"**Printing some sample images after image augmentation**","026e8922":"**Plotting the incorrectly classified images**","c29d649b":"**Plotting 25 random images from the dataset for inspection**","c19b1a1f":"**Plotting the counts of images with each unique label**","a976ae58":"**Evaluating final loss and accuracy on the validation set**","774c513e":"**Conducting Synthetic Minority Oversampling Technique (SMOTE) to even out the unequal distribution of images in each class. Conducted on training dataset only.**","f07d71ca":"**Loading the weights from the best performing model\/epoch**","034e2934":"**Implementing callbacks for overfitting and for saving the model at the epoch with the highest val_accuracy. Setting the batch size and number of epochs.**"}}