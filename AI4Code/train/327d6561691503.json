{"cell_type":{"2c41e013":"code","fdeb5a7e":"code","0a887ace":"code","ba4205c6":"code","1c05dd28":"code","86700274":"code","93557265":"code","b3908b50":"code","f6252dd3":"code","63fc0fa0":"code","104ba46c":"code","e1044913":"code","1497c17b":"code","a685117f":"code","ed451b58":"code","c718367a":"code","c50f300c":"code","e8af2e4e":"code","871eddf6":"code","9de303a0":"code","2b7a4627":"code","3553bed6":"code","afbfa219":"code","655a5390":"code","9392f1d6":"code","bd5351a7":"code","36e436a7":"code","3656847e":"code","e8a676ab":"code","9f3ca453":"code","5e73c195":"code","23b3c4d7":"code","bba24661":"code","6dcf8f9e":"code","49fcf457":"markdown","64f6fbb6":"markdown","67bf3505":"markdown","9400a18d":"markdown","4ddfe22f":"markdown","cad2f8a5":"markdown","1f7dbc57":"markdown","bba032b0":"markdown","d897cdb3":"markdown","bdd3a232":"markdown"},"source":{"2c41e013":"!pip install skorch","fdeb5a7e":"import os\nimport random\nimport numpy as np\nimport pandas as pd\n\n#PyTorch libraries\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n#Skorch\nfrom skorch import NeuralNetBinaryClassifier\n\n#Sklearn\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')","0a887ace":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed = 1234\nseed_everything(seed)","ba4205c6":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","1c05dd28":"train.head()","86700274":"def title_extract(df):\n    df['Title'] = df['Name'].str.extract('([a-zA-Z]+)\\.')\n    df['Title'] = df['Title'].apply(lambda x: 'Unknown' if x not in ['Miss','Master','Mr','Mrs', 'Dr', 'Rev'] else x)\n    return df","93557265":"train = title_extract(train)\ntest = title_extract(test)","b3908b50":"def fill_nan_age(df):\n    df['group_mean_age'] = round(df.groupby(['Sex', 'Title'])['Age'].transform('mean'))\n    df['Age'].fillna(df['group_mean_age'], inplace=True)\n    del df['group_mean_age']\n    return df","f6252dd3":"train = fill_nan_age(train)\ntest = fill_nan_age(test)","63fc0fa0":"def cat_age(df):\n    age_bins = [0, 10, 18, 30, 55, 100]\n    group_names = ['child', 'teenager', 'young adult', 'adult', 'elderly']\n    df['age_cat'] = pd.cut(df['Age'], age_bins, right=False, labels=group_names)\n    del df['Age']\n    return df","104ba46c":"train = cat_age(train)\ntest = cat_age(test)","e1044913":"def alone_family(df):\n    df['Family'] = train['SibSp'] + train['Parch']\n    df['Alone'] = pd.Series(np.where(df['Family'] == 0, 1, 0))\n    return df","1497c17b":"train = alone_family(train)\ntest = alone_family(test)","a685117f":"train.head()","ed451b58":"def fare_cat(df):\n    fare_labels = ['very cheap', 'cheap', 'moderate', 'exp', 'very exp']\n    df['Fare_cat'] = pd.qcut(df['Fare'], [0, 0.1, 0.25, 0.5, 0.9, 1], precision=0, labels=fare_labels)\n    del df['Fare']\n    return df","c718367a":"train = fare_cat(train)\ntest = fare_cat(test)","c50f300c":"train.head()","e8af2e4e":"train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)\ntest['Embarked'].fillna(test['Embarked'].mode()[0], inplace=True)\ntrain.head()","871eddf6":"def data_clean(drop_col, dummies, df):\n    df = df.drop(drop_col, axis=1)\n    df = pd.get_dummies(data=df, columns=dummies)\n    return df","9de303a0":"col_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ncol_dummies = ['Sex', 'Embarked', 'age_cat', 'Fare_cat', 'Pclass', 'Title']","2b7a4627":"train_clean = data_clean(col_drop, col_dummies, train)\ntrain_clean.head()","3553bed6":"test_clean = data_clean(col_drop, col_dummies, test)\ntest_clean.head()","afbfa219":"X = train_clean.drop('Survived', axis=1)\ny = train_clean['Survived']","655a5390":"X = np.array(X, dtype='float32')\ny = np.array(y, dtype='float32')","9392f1d6":"class TitanicModel(nn.Module):\n    def __init__(self, neurons=10, dropout=0.2):\n        super(TitanicModel, self).__init__()\n        \n        self.dense0 = nn.Linear(X.shape[1], neurons)\n        self.activation0 = nn.ReLU()\n        self.dropout0 = nn.Dropout(dropout)\n        self.dense1 = nn.Linear(neurons, neurons)\n        self.activation1 = nn.ReLU()\n        self.dropout1 = nn.Dropout(dropout)\n        self.dense2 = nn.Linear(neurons, 1)\n        self.output = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.dense0(x)\n        x = self.activation0(x)\n        x = self.dropout0(x)\n        x = self.dense1(x)\n        x = self.activation1(x)\n        x = self.dropout1(x)\n        x = self.dense2(x)\n        x = self.output(x)\n        return x","bd5351a7":"model = NeuralNetBinaryClassifier(module=TitanicModel,\n                                          lr = 0.001, \n                                          optimizer__weight_decay = 0.001,\n                                          verbose=0,\n                                          train_split=False,\n                                          device='cuda')","36e436a7":"params = {'batch_size': [10],\n          'max_epochs': [25],\n          'optimizer': [torch.optim.Adam],\n          'lr': [0.01, 0.001],\n          'criterion': [nn.BCELoss],\n          'module__neurons': [10, 15, 20, 25],\n          'module__dropout': [0, 0.2]}\n        ","3656847e":"params","e8a676ab":"%%time\nmodel_grid = GridSearchCV(estimator=model, param_grid=params,\n                          scoring = 'accuracy', cv=3, verbose=0)\n\nmodel_grid = model_grid.fit(X, y)","9f3ca453":"print(f'Accuracy: {model_grid.best_score_ * 100 :.2f}%')\nprint(model_grid.best_params_)","5e73c195":"test_clean = np.array(test_clean, dtype='float32')","23b3c4d7":"pred = model_grid.predict(test_clean)","bba24661":"submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred})\nsubmission.head()","6dcf8f9e":"submission.to_csv('submission.csv', index=False)","49fcf457":"## Seed\nCreating our seed.\n","64f6fbb6":"# Titanic with PyTorch and Skorch!\n\n\n[![Build Status](https:\/\/miro.medium.com\/max\/830\/1*JaF7d0hECZed9A_iDNy4hQ.png)](https:\/\/skorch.readthedocs.io\/en\/stable\/r)\n\n## About Skorch\nSkorch is a scikit-learn compatible neural network library that wraps PyTorch.\nFor more information about skorch visit: https:\/\/skorch.readthedocs.io\/\n\n\n# What are we going to do?\n\n  - Clean the data\n  - Create the model\n  - Fit our model to skorch\n\nWe can achieve accuracy approximately 83% with the train data and 78% with our test data.\n\n\n### References\n\nIf you want to go deep:\n\n* [PyTorch for Deep Learning](https:\/\/www.youtube.com\/watch?v=GIsg-ZUy0MY) - freeCodeCamp PyTorch for Deep Learning - Full Course \/ Tutorial\n\n\n* [Venelin Valkov Youtube Channel](https:\/\/www.youtube.com\/user\/VulkovVenelin\/videos) - Great youtube channel for projects with PyTorch\n\n* [Deep Learning de A \u00e0 Z com PyTorch e Python](https:\/\/www.udemy.com\/course\/formacao-deep-learning-pytorch-python\/) - For those who speak portuguese amazing course about PyTorch, with some parts about skorch\n* [Skorch documentation](https:\/\/skorch.readthedocs.io\/en\/stable\/) - Learn more about Skorch with advanced tutorials.\n\n* [The Complete Pandas Bootcamp 2020: Data Science with Python](https:\/\/www.udemy.com\/course\/the-pandas-bootcamp\/) - A good Pandas course","67bf3505":"## Create GridSearchCV\nFit our model and parameters to GridSearchCV.","9400a18d":"## Creating our model\n\nNow the fun part, create our PyTorch model.","4ddfe22f":"## Predict with test data","cad2f8a5":"## Importing libraries","1f7dbc57":"## Installing skorch!","bba032b0":"## Skorch Classifier\nNow we feed our model to the skorch classifier, with some parameters.","d897cdb3":"## Clean and some Features extration\nNow we do some clean in our data, not complex or advanced features extraction just the basics.","bdd3a232":"Create our dictionary with parameters names and the list of values for our model to try, just remember with more parameters it does not mean that the model will improve that much, but the time to process sure will be long."}}