{"cell_type":{"25411805":"code","26517730":"code","8fb895f6":"code","3bbdb136":"code","1cde6722":"code","bc6b56a3":"code","7b71e19e":"code","15e9b506":"code","bf146f94":"code","8d05cd0d":"code","876105f9":"code","3bd62694":"code","7801d069":"code","0d4b9ac5":"code","2fc5c03d":"code","7c79b107":"code","743092f8":"code","3f61352c":"code","c45560b9":"code","611cb999":"code","60f6d27b":"code","bd7258da":"code","dc112aee":"code","9f7db591":"code","4e6285ec":"code","17e44b6c":"code","00b1d51c":"code","83a97dac":"code","77dae94f":"code","413b0a09":"code","9f28cb00":"code","4a8fd880":"code","e1fa5596":"code","bffbdf3a":"code","54fdb823":"code","249e2f48":"code","bcfa2465":"code","309d49f1":"code","c33383b0":"code","03f71495":"code","45b35504":"code","9a407fbe":"code","7fd5ff9b":"markdown","937fc3a4":"markdown","522d4146":"markdown","76bf1b37":"markdown","8132c871":"markdown","4632cfd1":"markdown","d9f97479":"markdown","6b4cddf2":"markdown","280cb3bc":"markdown","b5ae0bda":"markdown","337f4a07":"markdown","b219cab0":"markdown","a3f77113":"markdown","bfa143d6":"markdown","169d4685":"markdown","7e76a2f2":"markdown","02393bc5":"markdown","58bc1622":"markdown","1baf7017":"markdown","9b85907e":"markdown","25a0de01":"markdown","6917cb72":"markdown","88717454":"markdown","c5c66de2":"markdown","3e4e36e1":"markdown"},"source":{"25411805":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\n%matplotlib inline","26517730":"path = '..\/input\/'\nreviews = pd.read_csv(os.path.join(path, 'olist_order_reviews_dataset.csv'))\nreviews.head()","8fb895f6":"orders = pd.read_csv(os.path.join(path, 'olist_orders_dataset.csv'))\norders.head()","3bbdb136":"columns_to_stay = ['order_id','order_delivered_carrier_date', 'order_delivered_customer_date']\norders = orders[columns_to_stay]\norders.head()","1cde6722":"columns_to_remove = ['review_id']\nreviews = reviews.drop(columns_to_remove, axis=1)\nreviews.head()","bc6b56a3":"reviews.dtypes","7b71e19e":"reviews['review_creation_date'] = reviews['review_creation_date'].apply(pd.to_datetime)\nreviews['review_answer_timestamp'] = reviews['review_answer_timestamp'].apply(pd.to_datetime)","15e9b506":"reviews['review_score'].value_counts()","bf146f94":"print(\n    reviews['review_comment_title'].isna().sum(),\n    reviews['review_comment_message'].isna().sum()\n)","8d05cd0d":"def nan_to_empty_string(row):\n    if row is np.NaN:\n        row = ''.strip()\n    else:\n        pass\n    return row\n\nreviews['review_comment_title'] = reviews['review_comment_title'].apply(nan_to_empty_string)\nreviews['review_comment_message'] = reviews['review_comment_message'].apply(nan_to_empty_string)","876105f9":"orders.dtypes","3bd62694":"orders['order_delivered_carrier_date'] = orders['order_delivered_carrier_date'].apply(pd.to_datetime)\norders['order_delivered_customer_date'] = orders['order_delivered_customer_date'].apply(pd.to_datetime)","7801d069":"orders['Time waiting'] = orders['order_delivered_customer_date'] - orders['order_delivered_carrier_date']\norders['Time waiting'] = orders['Time waiting'].apply(lambda x: x.total_seconds())\n\norders = orders.drop(['order_delivered_customer_date', 'order_delivered_carrier_date'], axis=1)","0d4b9ac5":"orders['Time waiting'].isna().sum()","2fc5c03d":"reviews['review timestamp'] = reviews['review_answer_timestamp'] - reviews['review_creation_date']\nreviews['review timestamp'] = reviews['review timestamp'].apply(lambda x: x.total_seconds())\n\nreviews = reviews.drop(['review_answer_timestamp', 'review_creation_date'], axis=1)","7c79b107":"reviews['review timestamp'].isna().sum()","743092f8":"def join_text(row):\n    return '{} {}'.format(\n        row['review_comment_title'],\n        row['review_comment_message'])\n\nreviews['review'] = reviews[['review_comment_title','review_comment_message']].apply(join_text, axis=1)\nreviews = reviews.drop(['review_comment_title','review_comment_message'], axis=1)","3f61352c":"orders.head()","c45560b9":"print(\n    orders.shape,\n    reviews.shape\n)","611cb999":"review_merge = reviews.merge(\n    orders,\n    how='inner',\n    on='order_id'\n)\n\nreview_merge.head()","60f6d27b":"sem_data_entrega = review_merge[review_merge['Time waiting'].isna()]\nsem_data_entrega.head()","bd7258da":"sns.countplot(sem_data_entrega['review_score'])","dc112aee":"media_time_waiting = review_merge['Time waiting'].mean()\nreview_merge['Time waiting'].fillna(media_time_waiting, inplace=True)","9f7db591":"review_merge['Time waiting'].isna().sum()","4e6285ec":"review_merge.head()","17e44b6c":"review_merge['review len'] = review_merge['review'].apply(lambda x: len(x.strip()))\nreview_merge.head()","00b1d51c":"review_merge.drop('order_id', axis=1, inplace=True)","83a97dac":"review_merge['review len'].max()","77dae94f":"sns.lineplot(y='review len',x='review_score', data=review_merge)","413b0a09":"review_merge.corr()","9f28cb00":"sns.countplot(review_merge['review_score'])","4a8fd880":"sns.distplot(review_merge['Time waiting'])","e1fa5596":"sns.lmplot(x='Time waiting', y='review_score',data= review_merge)","bffbdf3a":"from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import FunctionTransformer, Normalizer\nfrom nltk.corpus import stopwords","54fdb823":"review_merge.head()","249e2f48":"def _get_numeric(data):\n    return data[['Time waiting', 'review len']]\n    \ndef _get_text(data):\n    return data[['review']].apply(lambda x: ''.join(x), axis=1)\n\n\nget_numeric = FunctionTransformer(_get_numeric, validate=False)\nget_text = FunctionTransformer(_get_text, validate=False)","bcfa2465":"get_numeric.transform(review_merge.head())","309d49f1":"get_text.transform(review_merge.head())","c33383b0":"from sklearn.naive_bayes import MultinomialNB","03f71495":"TOKEN_PATTERN = r'\\w+'\n\nnumeric_pipeline = Pipeline([\n    ('selector', get_numeric),\n    ('scaler', Normalizer())\n])\n\ntext_pipeline = Pipeline([\n    ('selector', get_text),\n    ('tfidf', TfidfVectorizer(\n        lowercase=True,\n        ngram_range=(1,2),\n        token_pattern=TOKEN_PATTERN,\n        stop_words=stopwords.words('portuguese'))),\n    ('dim_reduction', SelectKBest(chi2, k=300))\n])\n\nfinal_pipe = Pipeline([\n    ('feature_union', FeatureUnion(transformer_list=[\n        ('numeric', numeric_pipeline),\n        ('text', text_pipeline)\n    ])),\n    ('sgd', SGDClassifier(max_iter=100, tol=0.001))\n])","45b35504":"NUMERO_OBS = 100000\nX = review_merge.drop('review_score', axis=1)[:NUMERO_OBS]\ny = review_merge['review_score'].tolist()[:NUMERO_OBS]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    stratify=y,\n    shuffle=True,\n    test_size=0.3\n)\nfinal_pipe.fit(X_train, y_train)\npredicted = final_pipe.predict(X_test)\nprint(classification_report(y_test, predicted))","9a407fbe":"print(\"Acur\u00e1cia de treino: \", final_pipe.score(X_train, y_train))\nprint(\"Acur\u00e1cia de teste: \", final_pipe.score(X_test, y_test))","7fd5ff9b":"## Mesmo processo para orders","937fc3a4":"# Agora vamos partir para o ML","522d4146":"Com base no resultado da Acur\u00e1cia de treino e teste, printado acima, podemos ver que o classificador n\u00e3o sofre de **Overfitting** e nem de **Underfitting**. ","76bf1b37":"# Avalia\u00e7\u00e3o das m\u00e9tricas\n\n\nCom o uso de 100mil dados, foi poss\u00edvel atingir um total de 54% de *precision*, e 65% de *recall*. O que parece ser bom no geral. Mas deve-se observar que para as categorias **2, 3 e 4** o classificador n\u00e3o se saiu muito bem. \u00c9 interessante ver que os dois extremos, **1 e 5** o modelo parece conseguir identificar com mais facilidade. ","8132c871":"## olist_orders_dataset apresenta se um produto foi enviado e quanto tempo demorou para ser entregue. Essa informa\u00e7ao pode ser importante","4632cfd1":"# Pr\u00e9-processamento\n\nUma vez que eu tenho um dataset que mistura dados textuais com num\u00e9ricos, eu preciso trat\u00e1-los para que o algoritmo selecionado possa recebe-los.\n\n\nPara isso, definirei dois m\u00e9todos que retornam as features num\u00e9ricas e a textual, respectivamente. Depois, utilizarei o `FunctionTransformer` para transformar as minhas fun\u00e7\u00f5es em um `Transformer` do Scikit","d9f97479":"## Criando uma coluna com as features textuais\n\ncom uma coluna que ja une duas outras, n\u00e3o preciso mais dessas duas","6b4cddf2":"## Correla\u00e7\u00e3o entre as features","280cb3bc":"## Seria interessante ver a rela\u00e7\u00e3o entre o tamanho do review com a nota atribuida","b5ae0bda":"# Intro\n\nEsse notebook visa explorar os dados dispon\u00edveis pelo dataset [Brazilian E-Commerce Public Dataset by Olist](https:\/\/www.kaggle.com\/olistbr\/brazilian-ecommerce)\n\nAl\u00e9m de explorar, houve um *experimento* para tentar identificar qual foi a Nota de satisfa\u00e7\u00e3o, dada pelo usu\u00e1rio ap\u00f3s uma compra, com base no que o usu\u00e1rio escreveu. ","337f4a07":"## Gr\u00e1fico acima mostra que, geralmente, quanto maior o review, menor \u00e9 a nota","b219cab0":"## Quantos NaN existem nessas colunas","a3f77113":"## H\u00e1 produtos que n\u00e3o possuem registros da entrega para o cliente. Vamos analisar como reagem os usu\u00e1rios","bfa143d6":"# Warnings\n\n[UndefinedMetricWarning](https:\/\/stackoverflow.com\/questions\/43162506\/undefinedmetricwarning-f-score-is-ill-defined-and-being-set-to-0-0-in-labels-wi)\n\n# Considera\u00e7\u00f5es\n\nPoderia utilizar o m\u00e9todo `parcial_fit` para melhorar o algortimo SGDClassifier, caso existissem dados demais.\n\nAntes de utilizar o [SGDClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier), utilizei o [KNN](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html). N\u00e3o recomendo, KNN consumiu muita mem\u00f3ria, ao ponto de ser invi\u00e1vel utilizar mais de 15mil observa\u00e7\u00f5es, enquanto ao utilizar o SGD, foi poss\u00edvel utilizar todo o dataset\n\n\n\n# Poss\u00edveis A\u00e7\u00f5es para Melhorar o Resultado do Classificador\n\n\n* Aplica\u00e7\u00e3o de **Stemming** nas palavras. Isto \u00e9, a redu\u00e7\u00e3o das palavras a sua forma mais simples. \n* Considerar outra forma de Tokeniza\u00e7\u00e3o das palavras. No meu caso, utilizei apenas a regex definida por **TOKEN_PATTERN = r'\\w+'**. \n* Utilizar uma t\u00e9cnica de **Part-of-speech tagging**. ","169d4685":"## Para tratar os dados faltantes nessa coluna, utilizarei a m\u00e9dia do dataset como valor. ","7e76a2f2":"# Data Treatment and Visualization\n\n\ntimestamp e creation_date s\u00e3o do tipo datetime, vamos transforma-los para tal","02393bc5":"# Gr\u00e1ficos","58bc1622":"### Como \u00e9 mostrado acima, h\u00e1 mais informa\u00e7\u00f5es de reviews que h\u00e1 de orders. Eu quero somente os registros que possuem informa\u00e7\u00f5es de order. ","1baf7017":"## Gr\u00e1fico acima mostra que o review tende a ser menor quanto maior o tempo de espera pelo produto","9b85907e":"## Criando uma coluna com o timestamp entre o pedido de review e a realiza\u00e7\u00e3o do review pelo usuario","25a0de01":"# Um pouco de Feature Engineering\n\nCriando outras colunas para poder relacionar com o dataset de reviews e conseguir plotar um gr\u00e1fico com as informa\u00e7\u00f5es","6917cb72":"**Agora que essas fun\u00e7\u00f5es s\u00e3o um `transformer` do scikit, posso utiliz\u00e1-las no Pipeline e no FeatureUnion**\n\n\nNas funcionalidades num\u00e9ricas, realizarei a normaliza\u00e7\u00e3o dos dados. Essa pr\u00e1tica j\u00e1 seria boa em diversas situa\u00e7\u00f5es, uma vez que essas `features` possuem um range muito diverso. Na aplica\u00e7\u00e3o do algoritmo de KNN, a normaliza\u00e7\u00e3o \u00e9 um passo bem aceito, uma vez que o algoritmo pode ficar enviesado com `features` que tenham valores num\u00e9ricos mais altos","88717454":"# Por enquanto, n\u00e3o me interessa quem comprou. Aqui, estou curioso sobre quanto tempo demorou para ser entregue","c5c66de2":"# Outras informa\u00e7\u00f5es\n\n\nH\u00e1 mais arquivos com algumas outras informa\u00e7\u00f5es que podem ser de grande valor para um futuro `Feature Engineering`. Vejamos a rela\u00e7\u00e3o dos bancos\n\n![Rela\u00e7\u00e3o dos Bancos](https:\/\/i.imgur.com\/HRhd2Y0.png)","3e4e36e1":"# J\u00e1 que a inten\u00e7\u00e3o \u00e9 identificar o valor de review_score atrav\u00e9s do texto, remover algumas colunas"}}