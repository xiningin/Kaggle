{"cell_type":{"c9ff8094":"code","dd740707":"code","43e645b8":"code","166df57f":"code","a7510898":"code","10627fc0":"code","14ea373d":"code","2130487e":"code","9f8b7a11":"code","d13e297e":"code","9e0f5819":"code","535118fe":"code","24c4761e":"code","59ccf76a":"code","ed6902b5":"code","cf95b954":"code","09fef181":"code","86d027a8":"code","ffc06b93":"code","0980a3c0":"code","278e1a07":"code","c735041b":"code","1addc76f":"code","e894485d":"markdown","fe0ab440":"markdown","1259228c":"markdown"},"source":{"c9ff8094":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport skimage.io\nimport os \nimport tqdm\nimport glob\nimport tensorflow \n\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nfrom skimage.color import grey2rgb\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import optimizers\n\nfrom keras.callbacks import Callback,ModelCheckpoint\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimport keras.backend as K\n\n#import tensorflow_addons as tfa\n#from tensorflow.keras.metrics import Metric\n#from tensorflow_addons.utils.types import AcceptableDTypes, FloatTensorLike\nfrom typeguard import typechecked\nfrom typing import Optional","dd740707":"AUTOTUNE = tf.data.experimental.AUTOTUNE","43e645b8":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   validation_split = 0.2,\n                                  \n        rotation_range=5,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        #zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  validation_split = 0.2)\n\ntest_datagen  = ImageDataGenerator(rescale = 1.\/255\n                                  )","166df57f":"#train_dataset = tf.keras.preprocessing.image_dataset_from_directory('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n#                                                                        validation_split=0.2,\n#                                                                        subset=\"training\",\n#                                                                        shuffle=False,\n#                                                                        image_size=(224,224),\n#                                                                        batch_size=32,\n#                                                                        )\n\ntrain_dataset  = train_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n                                                   target_size = (224,224),\n                                                   class_mode = 'categorical',\n                                                   subset = 'training',\n                                                   batch_size = 32)","a7510898":"#valid_dataset = tf.keras.preprocessing.image_dataset_from_directory('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n#                                                                        validation_split=0.2,\n#                                                                        subset=\"validation\",\n#                                                                        shuffle=False,\n#                                                                        image_size=(224,224),\n#                                                                        batch_size=32,\n#                                                                        )\nvalid_dataset = valid_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n                                                  target_size = (224,224),\n                                                  class_mode = 'categorical',\n                                                  subset = 'validation',\n                                                  batch_size = 32)","10627fc0":"#test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\",\n##                                                            shuffle=False,\n#                                                            image_size=(224,224),\n#                                                            batch_size=32,\n#)\n\ntest_dataset = test_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test',\n                                                  target_size = (224,224),\n                                                  class_mode = 'categorical',\n                                                  batch_size = 32)","14ea373d":"base_model = ResNet50(input_shape=(224,224,3), \n                   include_top=False,\n                   weights=\"imagenet\")","2130487e":"# Freezing Layers\n\nfor layer in base_model.layers:\n    layer.trainable=False","9f8b7a11":"# Building Model\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dense(4,activation='softmax'))","d13e297e":"# Model Summary\n\nmodel.summary()","9e0f5819":"def f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val","535118fe":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        f1_score,\n]","24c4761e":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 5) # when i run it for 50 epochs\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)","59ccf76a":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=METRICS)","ed6902b5":"history=model.fit(train_dataset,\n                        validation_data=valid_dataset,\n                        epochs = 20,\n                        verbose = 1,\n                         callbacks=lr_scheduler)","cf95b954":"#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n\ndef Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n    \n    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    \n    ax3.plot(range(1, len(auc) + 1), auc)\n    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n    ax3.set_title('History of AUC')\n    ax3.set_xlabel('Epochs')\n    ax3.set_ylabel('AUC')\n    ax3.legend(['training', 'validation'])\n    \n    ax4.plot(range(1, len(precision) + 1), precision)\n    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n    ax4.set_title('History of Precision')\n    ax4.set_xlabel('Epochs')\n    ax4.set_ylabel('Precision')\n    ax4.legend(['training', 'validation'])\n    \n    ax5.plot(range(1, len(f1) + 1), f1)\n    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n    ax5.set_title('History of F1-score')\n    ax5.set_xlabel('Epochs')\n    ax5.set_ylabel('F1 score')\n    ax5.legend(['training', 'validation'])\n\n\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'],\n               history.history['auc'],history.history['val_auc'],\n               history.history['precision'],history.history['val_precision'],\n               history.history['f1_score'],history.history['val_f1_score']\n              )","09fef181":"scores = model.evaluate_generator(test_dataset)","86d027a8":"print(\"Accuracy = \", scores[1])\nprint(\"Precision = \", scores[2])\nprint(\"Recall = \", scores[3])\nprint(\"AUC = \", scores[4])\nprint(\"F1_score = \", scores[5])","ffc06b93":"kpred = model.predict(test_dataset)","0980a3c0":"pred = kpred.tolist()\npredictions = []\nfor i in pred:\n  predictions.append(i.index(max(i)))","278e1a07":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix","c735041b":"print(classification_report(test_dataset.classes,predictions))","1addc76f":"cf_matrix=confusion_matrix(test_dataset.classes,predictions)\ncf_matrix","e894485d":"### MODEL BUILDING","fe0ab440":"## feature preprocessing and label encoding.","1259228c":"### IMPORT LIBRARIES"}}