{"cell_type":{"5eb6283c":"code","5eb4730a":"code","13f3ff47":"code","3e1c0d68":"code","a38a5924":"code","10f5fb96":"code","815b05ef":"code","27b95347":"code","5d5c3f8e":"code","91c7e537":"code","eb256d6c":"code","bf928714":"code","716c5240":"code","0b89b429":"code","baa7f60b":"code","380a07f6":"code","89dd8458":"code","e02a74ef":"code","731b850e":"code","19ceee21":"code","53b7d43a":"code","23cf3ce4":"code","b8b81378":"code","eb500d60":"code","3b2982c6":"code","2b82a391":"code","6f17fdca":"code","f86c2616":"code","e9444f90":"code","bac06e1a":"code","fe7bdc94":"code","9c9697d4":"code","ae55361c":"code","08773611":"code","d54735ae":"code","95ffb4b0":"markdown","bb96e9ee":"markdown","728b1e9b":"markdown","8401dc1c":"markdown","da836432":"markdown","622a7e0c":"markdown","dda5656c":"markdown","5e67bfb8":"markdown","c429db6a":"markdown","27e04f7f":"markdown","30d64c15":"markdown","962103a5":"markdown","c1bd2b77":"markdown","66a0a487":"markdown"},"source":{"5eb6283c":"# library for Data manipulation and analysi\nimport pandas as pd\n\n# library for mathematical work\nimport numpy as np\n\n#library for missing data visualization\nimport missingno as mn\n\n#libraries for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#librarie for ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","5eb4730a":"# import dataset\ntrain_data = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/train.csv')\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/test.csv')","13f3ff47":"train_data.head()","3e1c0d68":"test_data.head()","a38a5924":"train_data.isnull().mean()","10f5fb96":"test_data.isnull().mean()","815b05ef":"mn.matrix(train_data,color=(0.05,0.15,0.30))\nplt.xlabel(\"Feature of training data\",fontsize=25)\nplt.ylabel(\"Number of Entry\",fontsize=25)\nplt.title(\"Checking Missing values in Training data\",fontsize=30,color='red')","27b95347":"mn.matrix(test_data,color=(0.05,0.15,0.30))\nplt.xlabel(\"Feature of testing data\",fontsize=25)\nplt.ylabel(\"Number of Entry\",fontsize=25)\nplt.title(\"Checking Missing values in Testing data\",fontsize=30,color='red')","5d5c3f8e":"train_data.head()","91c7e537":"for i,col in enumerate(train_data.columns[1:11],1):\n    print(train_data[col].value_counts(),\"\\n=============\")","eb256d6c":"plt.figure(figsize=(12,18))\nfor i,col in enumerate(train_data.columns[1:11],1):\n    plt.subplot(5,2,i)\n    sns.countplot(train_data[col])","bf928714":"for i in train_data.columns[1:11]:\n    print(i,'having',+len(train_data[i].unique()),'unique values')","716c5240":"for i in train_data.columns[1:4]:\n    train_data[i] = pd.get_dummies(train_data[i],drop_first=True,columns=[i])\n    train_data.rename(columns={'B':i},inplace=True)\n    train_data.head()","0b89b429":"for i,col in enumerate(train_data.columns[4:11],1):\n    print(col,\"=\",list(train_data[col].value_counts().index),\"\\n=============\")","baa7f60b":"cat3_dict = {'C':1, 'A':2, 'D':3, 'B':4}\ncat4_dict = {'B':1, 'A':2, 'C':3, 'D':4}\ncat5_dict = {'B':1, 'D':2, 'C':3, 'A':4}\ncat6_dict = {'A':1, 'B':2, 'C':3, 'D':4, 'I':5, 'E':6, 'H':7, 'G':8}\ncat7_dict = {'E':1 ,'D':2, 'B':3, 'G':4, 'F':5, 'A':6, 'C':7, 'I':8}\ncat8_dict = {'C':1, 'E':2, 'G':3, 'A':4, 'D':5, 'F':6, 'B':7}\ncat9_dict = {'F':1, 'I':2, 'L':3, 'H':4, 'K':5, 'A':6, 'G':7, 'M':8, 'J':9, 'O':10, 'N':11, 'B':12, 'C':13, 'D':14, 'E':15}\ncat_dict = [cat3_dict,cat4_dict,cat5_dict,cat6_dict,cat7_dict,cat8_dict,cat9_dict]\ncat_dict","380a07f6":"cat_dict = [cat3_dict,cat4_dict,cat5_dict,cat6_dict,cat7_dict,cat8_dict,cat9_dict]\nfor i,j in zip(train_data.columns[4:11],cat_dict):\n        train_data[i]=(train_data[i].map(j))     ","89dd8458":"train_data","e02a74ef":"test_data.head()","731b850e":"for i,col in enumerate(test_data.columns[1:11],1):\n    print(test_data[col].value_counts(),\"\\n=============\")","19ceee21":"plt.figure(figsize=(12,18))\nfor i,col in enumerate(test_data.columns[1:11],1):\n    plt.subplot(5,2,i)\n    sns.countplot(test_data[col])","53b7d43a":"for i in test_data.columns[1:11]:\n    print(i,'having',+len(test_data[i].unique()),'unique values')","23cf3ce4":"for i in test_data.columns[1:4]:\n    test_data[i] = pd.get_dummies(test_data[i],drop_first=True,columns=[i])\n    test_data.rename(columns={'B':i},inplace=True)\n    test_data.head()","b8b81378":"for i,col in enumerate(test_data.columns[4:11],1):\n    print(col,\"=\",list(test_data[col].value_counts().index),\"\\n=============\")","eb500d60":"cat3_dict = {'C':1, 'A':2, 'D':3, 'B':4}\ncat4_dict = {'B':1, 'A':2, 'C':3, 'D':4}\ncat5_dict = {'B':1, 'D':2, 'C':3, 'A':4}\ncat6_dict = {'A':1, 'B':2, 'C':3, 'D':4, 'I':5, 'E':6, 'H':7}\ncat7_dict = {'E':1 ,'D':2, 'B':3, 'G':4, 'F':5, 'A':6, 'I':7, 'C':8}\ncat8_dict = {'C':1, 'E':2, 'G':3, 'A':4, 'D':5, 'F':6, 'B':7}\ncat9_dict = {'F':1, 'I':2, 'L':3, 'H':4, 'K':5, 'A':6, 'G':7, 'M':8, 'J':9, 'O':10, 'N':11, 'B':12, 'C':13, 'D':14, 'E':15}\ncat_dict1 = [cat3_dict,cat4_dict,cat5_dict,cat6_dict,cat7_dict,cat8_dict,cat9_dict]\ncat_dict1","3b2982c6":"for i,j in zip(test_data.columns[4:11],cat_dict1):\n        test_data[i]=(test_data[i].map(j))","2b82a391":"test_data.head()","6f17fdca":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb","f86c2616":"x = train_data.drop(['id','target'],axis=1)\ny=  train_data['target']\n","e9444f90":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=18)\nClassifier  = xgb.XGBRegressor()\nClassifier.fit(x_train,y_train)","bac06e1a":"demo = test_data.drop('id',axis=1)","fe7bdc94":"y_pred = Classifier.predict(demo)\ny_pred","9c9697d4":"submition = pd.DataFrame({\n    'id':test_data['id'],\n    'target':y_pred\n})","ae55361c":"submition","08773611":"submition.to_csv('submission_1.csv',index=False)","d54735ae":"pd.read_csv('submission_1.csv')","95ffb4b0":"- There are many techniques for handling obvious features,\n\n\n        - Here I prefer to use a one hot and label encoding technique","bb96e9ee":"<h3 style=\"color:#7F525D\"> - Building model","728b1e9b":"<h3 style=\"color:#504A4B\"> Index <\/h3> \n\n<h6 style=\"color:#848482\"> \n\n- Importing required libraries\n    \n    \n- Data Collection\n    \n    \n- Data Cleaning\n    \n    \n- Data Transformation","8401dc1c":"<h3 style=\"color:#7F525D\"> - Import required libraries <\/h1> ","da836432":"<h1 align='center' style='color:nevyblue'> Thank you !","622a7e0c":"<h3 style=\"color:#7F525D\"> - Data Cleaning <\/h3>\n    \n- After collecting the data we need to check the missing values present in it, if there are any missing values it needs to be handled properly.","dda5656c":"<h3 style=\"color:#7F525D\"> - Data Transformation","5e67bfb8":"- There is no vertical line here so no missing values exist in the given data","c429db6a":"<h1 align=center style=\"color:#6495ED\"> Tabular Playground Series - Feb 2021 <\/h1> ","27e04f7f":"<h3 style=\"color:orange\"> - Testing Dataset","30d64c15":"- ['cat0','cat1','cat2'] having only two feature so we performe one hot encoding technique on it,\n- If you want to explore One Hot encoding please take of my [notebook](https:\/\/www.kaggle.com\/rushikeshlavate\/check-how-to-perform-onehot-encoding-technique)","962103a5":"<h3 style=\"color:#7F525D\"> - Data Collection <\/h3>\n\n- Here I am using the data provided in the contest","c1bd2b77":"<h3 style=\"color:orange\"> - Training Dataset","66a0a487":"- No missing values exist in the given data"}}