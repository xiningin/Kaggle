{"cell_type":{"5be00d87":"code","f56c3e0c":"code","984eccff":"code","0273cd7a":"code","bb56950d":"code","37434983":"code","b18c61ab":"code","d5547689":"code","78a35234":"code","7b90fc7b":"code","6f434bc2":"code","cd1388a1":"code","3a41d794":"code","b7acb990":"code","3e228ceb":"code","6be22d7c":"code","77f0b055":"code","06fb3efa":"code","4b5b67c3":"markdown","e98641b1":"markdown","7830ac8c":"markdown","a7da6365":"markdown","190101a9":"markdown","8a93fa7c":"markdown","52d832ee":"markdown","76bbd9d0":"markdown","92c41220":"markdown","5ce30df9":"markdown","eefb4394":"markdown","86885874":"markdown","d01649b4":"markdown","9c4779ca":"markdown","81ef1dcb":"markdown"},"source":{"5be00d87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f56c3e0c":"data= pd.read_csv(\"..\/input\/CC GENERAL.csv\")\nprint(data.shape)\ndata.head()","984eccff":"data.describe()","0273cd7a":"data.isnull().sum().sort_values(ascending=False).head()","bb56950d":"data.loc[(data['MINIMUM_PAYMENTS'].isnull()==True),'MINIMUM_PAYMENTS']=data['MINIMUM_PAYMENTS'].mean()\ndata.loc[(data['CREDIT_LIMIT'].isnull()==True),'CREDIT_LIMIT']=data['CREDIT_LIMIT'].mean()","37434983":"data.isnull().sum().sort_values(ascending=False).head()","b18c61ab":"columns=['BALANCE', 'PURCHASES', 'ONEOFF_PURCHASES', 'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT',\n        'PAYMENTS', 'MINIMUM_PAYMENTS']\n\nfor c in columns:\n    \n    Range=c+'_RANGE'\n    data[Range]=0        \n    data.loc[((data[c]>0)&(data[c]<=500)),Range]=1\n    data.loc[((data[c]>500)&(data[c]<=1000)),Range]=2\n    data.loc[((data[c]>1000)&(data[c]<=3000)),Range]=3\n    data.loc[((data[c]>3000)&(data[c]<=5000)),Range]=4\n    data.loc[((data[c]>5000)&(data[c]<=10000)),Range]=5\n    data.loc[((data[c]>10000)),Range]=6\n ","d5547689":"columns=['BALANCE_FREQUENCY', 'PURCHASES_FREQUENCY', 'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY', \n         'CASH_ADVANCE_FREQUENCY', 'PRC_FULL_PAYMENT']\n\nfor c in columns:\n    \n    Range=c+'_RANGE'\n    data[Range]=0\n    data.loc[((data[c]>0)&(data[c]<=0.1)),Range]=1\n    data.loc[((data[c]>0.1)&(data[c]<=0.2)),Range]=2\n    data.loc[((data[c]>0.2)&(data[c]<=0.3)),Range]=3\n    data.loc[((data[c]>0.3)&(data[c]<=0.4)),Range]=4\n    data.loc[((data[c]>0.4)&(data[c]<=0.5)),Range]=5\n    data.loc[((data[c]>0.5)&(data[c]<=0.6)),Range]=6\n    data.loc[((data[c]>0.6)&(data[c]<=0.7)),Range]=7\n    data.loc[((data[c]>0.7)&(data[c]<=0.8)),Range]=8\n    data.loc[((data[c]>0.8)&(data[c]<=0.9)),Range]=9\n    data.loc[((data[c]>0.9)&(data[c]<=1.0)),Range]=10\n    ","78a35234":"columns=['PURCHASES_TRX', 'CASH_ADVANCE_TRX']  \n\nfor c in columns:\n    \n    Range=c+'_RANGE'\n    data[Range]=0\n    data.loc[((data[c]>0)&(data[c]<=5)),Range]=1\n    data.loc[((data[c]>5)&(data[c]<=10)),Range]=2\n    data.loc[((data[c]>10)&(data[c]<=15)),Range]=3\n    data.loc[((data[c]>15)&(data[c]<=20)),Range]=4\n    data.loc[((data[c]>20)&(data[c]<=30)),Range]=5\n    data.loc[((data[c]>30)&(data[c]<=50)),Range]=6\n    data.loc[((data[c]>50)&(data[c]<=100)),Range]=7\n    data.loc[((data[c]>100)),Range]=8","7b90fc7b":"data.drop(['CUST_ID', 'BALANCE', 'BALANCE_FREQUENCY', 'PURCHASES',\n       'ONEOFF_PURCHASES', 'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE',\n       'PURCHASES_FREQUENCY',  'ONEOFF_PURCHASES_FREQUENCY',\n       'PURCHASES_INSTALLMENTS_FREQUENCY', 'CASH_ADVANCE_FREQUENCY',\n       'CASH_ADVANCE_TRX', 'PURCHASES_TRX', 'CREDIT_LIMIT', 'PAYMENTS',\n       'MINIMUM_PAYMENTS', 'PRC_FULL_PAYMENT' ], axis=1, inplace=True)\n\nX= np.asarray(data)","6f434bc2":"scale = StandardScaler()\nX = scale.fit_transform(X)\nX.shape","cd1388a1":"n_clusters=30\ncost=[]\nfor i in range(1,n_clusters):\n    kmean= KMeans(i)\n    kmean.fit(X)\n    cost.append(kmean.inertia_)  ","3a41d794":"plt.plot(cost, 'bx-')","b7acb990":"kmean= KMeans(6)\nkmean.fit(X)\nlabels=kmean.labels_","3e228ceb":"clusters=pd.concat([data, pd.DataFrame({'cluster':labels})], axis=1)\nclusters.head()","6be22d7c":"for c in clusters:\n    grid= sns.FacetGrid(clusters, col='cluster')\n    grid.map(plt.hist, c)","77f0b055":"dist = 1 - cosine_similarity(X)\n\npca = PCA(2)\npca.fit(dist)\nX_PCA = pca.transform(dist)\nX_PCA.shape","06fb3efa":"x, y = X_PCA[:, 0], X_PCA[:, 1]\n\ncolors = {0: 'red',\n          1: 'blue',\n          2: 'green', \n          3: 'yellow', \n          4: 'orange',  \n          5:'purple'}\n\nnames = {0: 'who make all type of purchases', \n         1: 'more people with due payments', \n         2: 'who purchases mostly in installments', \n         3: 'who take more cash in advance', \n         4: 'who make expensive purchases',\n         5:'who don\\'t spend much money'}\n  \ndf = pd.DataFrame({'x': x, 'y':y, 'label':labels}) \ngroups = df.groupby('label')\n\nfig, ax = plt.subplots(figsize=(20, 13)) \n\nfor name, group in groups:\n    ax.plot(group.x, group.y, marker='o', linestyle='', ms=5,\n            color=colors[name],label=names[name], mec='none')\n    ax.set_aspect('auto')\n    ax.tick_params(axis='x',which='both',bottom='off',top='off',labelbottom='off')\n    ax.tick_params(axis= 'y',which='both',left='off',top='off',labelleft='off')\n    \nax.legend()\nax.set_title(\"Customers Segmentation based on their Credit Card usage bhaviour.\")\nplt.show()","4b5b67c3":"Imputing these missing values with mean","e98641b1":"Normalizing input values.","7830ac8c":"* **Cluster0** People with average to high credit limit who make all type of purchases\n\n* **Cluster1** This group has more people with due payments who take advance cash more often\n\n* **Cluster2** Less money spenders with average to high credit limits who purchases mostly in installments \n\n* **Cluster3** People with high credit limit who take more cash in advance \n\n* **Cluster4** High spenders with high credit limit who make expensive purchases\n\n* **Cluster5** People who don't spend much money and who have average to high credit limit\n\n(Clsuter number changes when re run)","a7da6365":"And it's done! ","190101a9":"## MODELING\n\n#### Clustering using Kmeans","8a93fa7c":"## Data Preprocessing","52d832ee":"## Interpretation of Clusters","76bbd9d0":"\n#### Dealing with Outliers\n\nBy dropping outliers we can lose many rows as there are too many outliers in dataset. So making ranges to deal with extreme values.","92c41220":"Kindly Upvote this kernel if you found it helpful!","5ce30df9":"## Visualization of Clusters\n\n#### Using PCA to transform data to 2 dimensions for visualization","eefb4394":"#### Dealing with Missing Values","86885874":"Seems like data have many outliers!","d01649b4":"#### Choosing 6 no of clusters ","9c4779ca":"## Customers Segmentation based on their Credit Card usage bhaviour\n\nDataset for this notebook consists of credit card usage behavior of customers with 18 behavioral features. Segmentation of customers can be used to define marketing strategies.\n\n\n**Content of this Kernel:**\n* Data Preprocessing\n* Clustering using KMeans\n* Interpretation of Clusters\n* Visualization of Clusters using PCA","81ef1dcb":"#### Descriptive Statistics of Data"}}