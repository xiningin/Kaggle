{"cell_type":{"eb816a88":"code","d69207b7":"code","b6458d12":"code","8fd08640":"code","df0e84e1":"code","2be78b33":"code","655dad15":"code","72e1969a":"code","9e07939c":"code","4322e85c":"code","bc48d5f8":"code","7e380d06":"code","ad88aabb":"code","2b4ee12b":"code","59e9bd41":"code","9286c052":"code","6871aa62":"code","6ce12369":"code","775de0fe":"code","66e2830c":"code","94a13d37":"code","95244aae":"code","a715a68c":"code","8dce48f9":"code","2f6c95aa":"code","4f660578":"markdown","f97ea258":"markdown","491688e0":"markdown","4281a6c7":"markdown","b1576d3d":"markdown","ad6fee61":"markdown","fde1d0ba":"markdown","124e6ae7":"markdown","30ba1d30":"markdown","4eac0309":"markdown","621bcb25":"markdown","59beb196":"markdown","d82109df":"markdown","1924daea":"markdown","c6544e23":"markdown","f10a0566":"markdown","b163f536":"markdown","0baf045b":"markdown","928f3fb7":"markdown","ae6e06fb":"markdown","fc51f8d7":"markdown","ab9b8113":"markdown","307638bd":"markdown","e1b6c27a":"markdown","e10fa70c":"markdown","f85407de":"markdown","89a1cdf8":"markdown","75b898fa":"markdown","4252dcca":"markdown","194b5eb5":"markdown","13526aff":"markdown","881df4ba":"markdown","9a1ae83b":"markdown","114cf138":"markdown"},"source":{"eb816a88":"#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","d69207b7":"!pip install tf-nightly-gpu\n!pip install \"tensorflow_hub==0.4.0\"\n!pip install -U tensorflow_datasets","b6458d12":"from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport matplotlib.pylab as plt\n\nimport tensorflow as tf\ntf.enable_eager_execution()\n\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\n\nfrom tensorflow.keras import layers","8fd08640":"import logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)","df0e84e1":"CLASSIFIER_URL =\"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/classification\/2\" #\u7531tensorflow hub\u8f09\u5165\nIMAGE_RES = 224 #mobilenet\u7576\u521d\u8a13\u7df4\u6642\u5716\u7247\u8f38\u5165\u5927\u5c0f\u662f224*224, \u56e0\u6b64\u4e4b\u5f8c\u4e5f\u8981\u4e00\u6a23\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(CLASSIFIER_URL, input_shape=(IMAGE_RES, IMAGE_RES, 3))\n])","2be78b33":"import numpy as np\nimport PIL.Image as Image\n\ngrace_hopper = tf.keras.utils.get_file('image.jpg','https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/grace_hopper.jpg')\ngrace_hopper = Image.open(grace_hopper).resize((IMAGE_RES, IMAGE_RES))\ngrace_hopper ","655dad15":"grace_hopper = np.array(grace_hopper)\/255.0\ngrace_hopper.shape","72e1969a":"result = model.predict(grace_hopper[np.newaxis, ...])\nresult.shape","9e07939c":"predicted_class = np.argmax(result[0], axis=-1)\npredicted_class","4322e85c":"labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https:\/\/storage.googleapis.com\/download.tensorflow.org\/data\/ImageNetLabels.txt')\nimagenet_labels = np.array(open(labels_path).read().splitlines())\n\nplt.imshow(grace_hopper)\nplt.axis('off')\npredicted_class_name = imagenet_labels[predicted_class]\n_ = plt.title(\"Prediction: \" + predicted_class_name.title())","bc48d5f8":"splits = tfds.Split.ALL.subsplit(weighted=(80, 20))\n\nsplits, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True, split = splits)\n\n(train_examples, validation_examples) = splits\n\nnum_examples = info.splits['train'].num_examples\nnum_classes = info.features['label'].num_classes","7e380d06":"for i, example_image in enumerate(train_examples.take(3)):\n  print(\"Image {} shape: {}\".format(i+1, example_image[0].shape))","ad88aabb":"def format_image(image, label):\n  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))\/255.0\n  return  image, label\n\nBATCH_SIZE = 32\n\ntrain_batches      = train_examples.shuffle(num_examples\/\/4).map(format_image).batch(BATCH_SIZE).prefetch(1)\nvalidation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)","2b4ee12b":"image_batch, label_batch = next(iter(train_batches.take(1)))\nimage_batch = image_batch.numpy()\nlabel_batch = label_batch.numpy()\n\nresult_batch = model.predict(image_batch)\n\npredicted_class_names = imagenet_labels[np.argmax(result_batch, axis=-1)]\npredicted_class_names","59e9bd41":"plt.figure(figsize=(10,9))\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(image_batch[n])\n  plt.title(predicted_class_names[n])\n  plt.axis('off')\n_ = plt.suptitle(\"ImageNet predictions\")","9286c052":"URL = \"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/2\"\nfeature_extractor = hub.KerasLayer(URL,\n                                   input_shape=(IMAGE_RES, IMAGE_RES,3))","6871aa62":"feature_batch = feature_extractor(image_batch)\nprint(feature_batch.shape)","6ce12369":"feature_extractor.trainable = False","775de0fe":"model = tf.keras.Sequential([\n  feature_extractor,\n  layers.Dense(2, activation='softmax')\n])\n\nmodel.summary()","66e2830c":"model.compile(\n  optimizer='adam', \n  loss='sparse_categorical_crossentropy',\n  metrics=['accuracy'])\n\nEPOCHS = 6\nhistory = model.fit(train_batches,\n                    epochs=EPOCHS,\n                    validation_data=validation_batches)","94a13d37":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(EPOCHS)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","95244aae":"class_names = np.array(info.features['label'].names)\nclass_names","a715a68c":"predicted_batch = model.predict(image_batch)\npredicted_batch = tf.squeeze(predicted_batch).numpy()\npredicted_ids = np.argmax(predicted_batch, axis=-1)\npredicted_class_names = class_names[predicted_ids]\npredicted_class_names","8dce48f9":"print(\"Labels: \", label_batch)\nprint(\"Predicted labels: \", predicted_ids)","2f6c95aa":"plt.figure(figsize=(10,9))\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(image_batch[n])\n  color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n  plt.title(predicted_class_names[n].title(), color=color)\n  plt.axis('off')\n_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")","4f660578":"## Run it on a single image","f97ea258":"# TensorFlow Hub and Transfer Learning","491688e0":"# Part 2: Use a TensorFlow Hub models for the Cats vs. Dogs dataset","4281a6c7":"# Imports\n\n","b1576d3d":"The labels seem to match names of Dogs and Cats. Let's now plot the images from our Dogs vs Cats dataset and put the ImageNet label next to them.","ad6fee61":"## Dataset\n\nWe can use TensorFlow Datasets to load the Dogs vs Cats dataset. ","fde1d0ba":"<table class=\"tfo-notebook-buttons\" align=\"left\">\n  <td>\n    <a target=\"_blank\" href=\"https:\/\/colab.research.google.com\/github\/tensorflow\/examples\/blob\/master\/courses\/udacity_intro_to_tensorflow_for_deep_learning\/l06c01_tensorflow_hub_and_transfer_learning.ipynb\"><img src=\"https:\/\/www.tensorflow.org\/images\/colab_logo_32px.png\" \/>Run in Google Colab<\/a>\n  <\/td>\n  <td>\n    <a target=\"_blank\" href=\"https:\/\/colab.research.google.com\/github\/tensorflow\/examples\/blob\/master\/courses\/udacity_intro_to_tensorflow_for_deep_learning\/l06c01_tensorflow_hub_and_transfer_learning.ipynb\"><img src=\"https:\/\/www.tensorflow.org\/images\/GitHub-Mark-32px.png\" \/>View source on GitHub<\/a>\n  <\/td>\n<\/table>","124e6ae7":"Remember, models always want a batch of images to process. So here, we add a batch dimension, and pass the image to the model for prediction.","30ba1d30":"Freeze the variables in the feature extractor layer, so that the training only modifies the final classifier layer.","4eac0309":"## Check the predictions\n\nTo redo the plot from before, first get the ordered list of class names.","621bcb25":"What is a bit curious here is that validation performance is better than training performance, right from the start to the end of execution.\n\nOne reason for this is that validation performance is measured at the end of the epoch, but training performance is the average values across the epoch.\n\nThe bigger reason though is that we're reusing a large part of MobileNet which is already trained on Dogs and Cats images. While doing training, the network is still performing image augmentation on the training images, but not on the validation dataset. This means the training images may be harder to classify compared to the normal images in the validation dataset.","59beb196":"Let's look at the true labels and predicted ones.","d82109df":"Let's run a batch of images through this, and see the final shape. 32 is the number of images, and 1280 is the number of neurons in the last layer of the partial model from TensorFlow Hub.","1924daea":"Remember our `model` object is still the full MobileNet model trained on ImageNet, so it has 1000 possible output classes.\nImageNet has a lot of dogs and cats in it, so let's see if it can predict the images in our Dogs vs. Cats dataset.\n","c6544e23":"##### Copyright 2019 The TensorFlow Authors.","f10a0566":"## Train the model\n\nWe now train this model like any other, by first calling `compile` followed by `fit`.","b163f536":"Bingo. Our model correctly predicted miliatry uniform!","0baf045b":"# Part 3: Do simple transfer learning with TensorFlow Hub\n\nLet's now use TensorFlow Hub to do Transfer Learning.\n\nWith transfer learning we reuse parts of an already trained model and change the final layer, or several layers, of the model, and then retrain those layers on our own dataset.\n\nIn addition to complete models, TensorFlow Hub also distributes models without the last classification layer. These can be used to easily do transfer learning. We will continue using MobileNet v2 because in later parts of this course, we will take this model and deploy on a mobile device using [TensorFlow Lite](https:\/\/www.tensorflow.org\/lite). Any [image feature vector url from tfhub.dev](https:\/\/tfhub.dev\/s?module-type=image-feature-vector&q=tf2) would work here. \n\nWe'll also continue to use the Dogs vs Cats dataset, so we will be able to compare the performance of this model against the ones we created from scratch earlier.\n\nNote that we're calling the partial model from TensorFlow Hub (without the final classification layer) a `feature_extractor`. The reasoning for this term is that it will take the input all the way to a layer containing a number of features. So it has done the bulk of the work in identifying the content of an image, except for creating the final probability distribution. That is, it has extracted the features of the image.","928f3fb7":"The images in the Dogs vs. Cats dataset are not all the same size.","ae6e06fb":"MobileNet has been trained on the ImageNet dataset. ImageNet has 1000 different output classes, and one of them is military uniforms.\nLet's get an image containing a military uniform that is not part of ImageNet, and see if our model can predict that it is a military uniform.","fc51f8d7":"# Part 1: Use a TensorFlow Hub MobileNet for prediction","ab9b8113":"This Colab will require us to use some things which are not yet in official releases of TensorFlow. So below, we're first installing a nightly version of TensorFlow as well as TensorFlow Hub.\n\nThis will switch your installation of TensorFlow in Colab to this TensorFlow version. Once you are finished with this Colab, you should  switch batch to the latest stable release of TensorFlow by doing selecting `Runtime -> Reset all runtimes...` in the menus above. This will reset the Colab environment to its original state.","307638bd":"Some normal imports we've seen before. The new one is importing tensorflow_hub which was installed above, and which this Colab will make heavy use of.","e1b6c27a":"## Attach a classification head\n\nNow wrap the hub layer in a `tf.keras.Sequential` model, and add a new classification layer.","e10fa70c":"[TensorFlow Hub](http:\/\/tensorflow.org\/hub) is an online repository of already trained TensorFlow models that you can use.\nThese models can either be used as is, or they can be used for Transfer Learning.\n\nTransfer learning is a process where you take an existing trained model, and extend it to do additional work. This involves leaving the bulk of the model unchanged, while adding and retraining the final layers, in order to get a different set of possible outputs.\n\nIn this Colab we will do both.\n\nHere, you can see all the models available in [TensorFlow Module Hub](https:\/\/tfhub.dev\/).\n\n## Concepts that will be covered in this Colab\n\n1. Use a TensorFlow Hub model for prediction.\n2. Use a TensorFlow Hub model for Dogs vs. Cats dataset.\n3. Do simple transfer learning with TensorFlow Hub.\n\nBefore starting this Colab, you should reset the Colab environment by selecting `Runtime -> Reset all runtimes...` from menu above.","f85407de":"## Decode the predictions\n\nTo see what our predicted_class is in the ImageNet dataset, download the ImageNet labels and fetch the row that the model predicted.","89a1cdf8":"You can see we get ~97% validation accuracy, which is absolutely awesome. This is a huge improvement over the model we created in the previous lesson, where we were able to get ~83% accuracy. The reason for this difference is that MobileNet was carefully designed over a long time by experts, then trained on a massive dataset (ImageNet).\n\nAlthough not equivalent to TensorFlow Hub, you can check out how to create MobileNet in Keras [here](https:\/\/github.com\/keras-team\/keras-applications\/blob\/master\/keras_applications\/mobilenet.py).\n\nLet's plot the training and validation accuracy\/loss graphs.","75b898fa":"In this part of the Colab, we'll take a trained model, load it into to Keras, and try it out.\n\nThe model that we'll use is MobileNet v2 (but any model from [tf2 compatible image classifier url from tfhub.dev](https:\/\/tfhub.dev\/s?q=tf2&module-type=image-classification) would work).","4252dcca":"Now we'll use the full MobileNet model and see how it can perform on the Dogs vs. Cats dataset. ","194b5eb5":"## Run the classifier on a batch of images","13526aff":"So we need to reformat all images to the resolution expected by MobileNet (224, 224)\n\nThe `.repeat()` and `steps_per_epoch` here is not required, but saves ~15s per epoch, since the shuffle-buffer only has to cold-start once.","881df4ba":"The result is a 1001 element vector of logits, rating the probability of each class for the image.\n\nSo the top class ID can be found with argmax. But how can we know what class this actually is and in particular if that class ID in the ImageNet dataset denotes a military uniform or something else?","9a1ae83b":"## Download the classifier\n\nDownload the MobileNet model and create a Keras model from it.\nMobileNet is expecting images of 224 $\\times$ 224 pixels, in 3 color channels (RGB).","114cf138":"Run the image batch through the model and comvert the indices to class names."}}