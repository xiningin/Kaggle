{"cell_type":{"593ae059":"code","aa809867":"code","6a1b79de":"code","de5b714f":"code","da1e0217":"code","8b4abc66":"code","3a8e74aa":"code","024ceb70":"code","6622ba04":"code","020d241c":"code","a0583ed4":"code","c5cfa28d":"markdown","d580b4fd":"markdown","14806282":"markdown","4faa7a55":"markdown","58289924":"markdown","7af4ef76":"markdown","ca069939":"markdown","48705596":"markdown","d961e393":"markdown"},"source":{"593ae059":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Input, Embedding, LSTM, Dense, Dropout\nfrom keras import Model","aa809867":"df = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv', encoding = 'latin-1')\ndf = df[['v2', 'v1']]\ndf = df.rename(columns = {'v2': 'text', 'v1': 'label'})\n\nprint('Number of instances :', df.shape[0])\ndf.head()","6a1b79de":"s = df['label'].value_counts()\n\nplt.figure()\nplt.bar(x = s.index, height = s.values, color = ['purple', 'brown'], alpha = .6)\nplt.show()","de5b714f":"df['label'] = df['label'].replace({'ham': 0, 'spam': 1})","da1e0217":"X = df['text'].values\ny = df['label'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)","8b4abc66":"max_words = 1000              # Only consider top 1000 most common words when tokenizing\nmax_len = 150                # Set the maximum length of a sequence to 150\n\ntokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(X_train)\nsequences = tokenizer.texts_to_sequences(X_train)\nsequences = pad_sequences(sequences, maxlen = max_len)","3a8e74aa":"X_input = Input(name = 'Input', shape = (max_len,))\nX = Embedding(max_words, 50, input_length = max_len, name = 'Embedding')(X_input)\nX = LSTM(units = 64, activation = 'tanh', name = 'LSTM')(X)\nX = Dense(256, activation = 'relu', name = 'Dense1')(X)\nX = Dropout(.4)(X)\nX = Dense(1, activation = 'sigmoid', name = 'Output')(X)\n\nmodel = Model(inputs = X_input, outputs = X, name = 'Spam_Detector')\nprint(model.summary())","024ceb70":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","6622ba04":"_ = model.fit(sequences, y_train, batch_size = 128, epochs = 10, validation_split = 0.2)","020d241c":"tokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(X_test)\ntest_sequences = tokenizer.texts_to_sequences(X_test)\ntest_sequences = pad_sequences(test_sequences, maxlen = max_len)","a0583ed4":"score = model.evaluate(test_sequences, y_test, verbose = 0)\nprint('Accuracy : {:0.2f}'.format(score[1]))\nprint('Loss : {:0.2f}'.format(score[0]))","c5cfa28d":"## Data preparation\n\n- Encoding labels","d580b4fd":"## Import libraries","14806282":"- Tokenizing texts to fit an RNN","4faa7a55":"- Slitting dataset for training and testing","58289924":"## Quick data analysis","7af4ef76":"## RNN architecture","ca069939":"## Loading dataset","48705596":"98% accuracy on validation data and 99% accuracy on training data is good enough","d961e393":"## Testing model"}}