{"cell_type":{"4a5e3002":"code","f905bef2":"code","203c7744":"code","8bb5e6a3":"code","373bc26a":"code","241986a7":"code","142cf228":"code","0cb52670":"code","ccd66a5f":"code","2f463d51":"code","d38514e1":"code","87797370":"code","f0cbf57a":"code","2e3c0f79":"code","4f94a2f2":"markdown","b27cf7ef":"markdown","f36a2d25":"markdown","557e48a4":"markdown","0e3a4d5e":"markdown","36b51484":"markdown","6341ff81":"markdown","43a0a9d4":"markdown","91239bfb":"markdown"},"source":{"4a5e3002":"import pandas as pd\n# show images inline\n%matplotlib inline\n\nimport keras\nimport tensorflow\n\n# import miscellaneous modules\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport numpy as np\nimport time\n\nimport tensorflow as tf\n\n\n\n\n#Clone Git Repository\n!git clone https:\/\/github.com\/fizyr\/keras-retinanet.git\n%cd keras-retinanet\/\n!python setup.py build_ext --inplace\n\n# import keras_retinanet\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\nfrom keras_retinanet import models","f905bef2":"df_train = pd.read_csv(\"\/kaggle\/input\/tensorflow-great-barrier-reef\/train.csv\")\n\ndf_train=df_train.loc[df_train[\"annotations\"].astype(str) != \"[]\"]\ndf_train['annotations'] = df_train['annotations'].apply(eval)\n\ndf_train['image_path'] = \"\/kaggle\/input\/tensorflow-great-barrier-reef\/train_images\/video_\" + df_train['video_id'].astype(str) + \"\/\" + df_train['video_frame'].astype(str) + \".jpg\"\ndf_extrain=df_train.explode('annotations') # Single annotation per row\ndf_extrain.reset_index(inplace=True)\ndf_extrain.head()","203c7744":"df_extrain_main=pd.DataFrame(pd.json_normalize(df_extrain['annotations']), columns=['x', 'y', 'width', 'height']).join(df_extrain)\ndf_extrain_main['class']='Fish'\ndf_extrain_main=df_extrain_main[['image_path','x','y','width','height','class','video_id','video_frame']]\ndf_extrain_main.head(10)","8bb5e6a3":"!pip install --upgrade git+https:\/\/github.com\/broadinstitute\/keras-resnet\nimport keras\nimport keras_resnet\nimport urllib.request\nPRETRAINED_MODEL = '.\/snapshots\/_pretrained_model.h5'\n#### OPTION 1: DOWNLOAD INITIAL PRETRAINED MODEL FROM FIZYR ####\nURL_MODEL = 'https:\/\/github.com\/fizyr\/keras-retinanet\/releases\/download\/0.5.1\/resnet50_coco_best_v2.1.0.h5'\nurllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\nprint('Downloaded pretrained model to ' + PRETRAINED_MODEL)","373bc26a":"\ndef create_tf_example(rowss,data_df):\n    \"\"\"Create a tf.Example entry for a given training image.\"\"\"\n    full_path = os.path.join(rowss.image_path)\n    with tf.io.gfile.GFile(full_path, 'rb') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    if image.format != 'JPEG':\n        raise ValueError('Image format not JPEG')\n\n    height = image.size[1] # Image height\n    width = image.size[0] # Image width\n    #print(width,height)\n    filename = f'{rowss.video_id}:{rowss.video_frame}'.encode('utf8') # Unique id of the image.\n    encoded_image_data = None # Encoded image bytes\n    image_format = 'jpeg'.encode('utf8') # b'jpeg' or b'png'\n\n    xmins = [] \n    xmaxs = [] \n    ymins = [] \n    ymaxs = [] \n    \n    # Convert ---> [xmin,ymin,width,height] to [xmins,xmaxs,ymins,ymaxs]\n    xmin = rowss['x']\n    xmax = rowss['x']+rowss['width']\n    ymin = rowss['y']\n    ymax = rowss['y']+rowss['height']\n    \n\n    #main_data.append((rowss['image_path'],xmins,xmaxs,ymins,ymaxs))\n    return rowss['image_path'],xmin,ymin,xmax,ymax","241986a7":"import tensorflow as tf\nimport contextlib2\nimport io\nimport IPython\nimport json\nimport numpy as np\nimport os\nimport pathlib\nimport pandas as pd\nimport sys\nimport tensorflow as tf\nimport time\n\ntf_example1=[]\n\nfrom PIL import Image, ImageDraw\nfor index, row in df_extrain_main.iterrows():\n            if index % 500 == 0:\n                print('Processed {0} images.'.format(index))\n            image_path,xmins,ymins,xmaxs,ymaxs=create_tf_example(row,df_extrain_main)\n            #print(image_path,xmins,xmaxs,ymins,ymaxs)\n            df_extrain_main.loc[index,'image_path']=image_path\n            df_extrain_main.loc[index,'x']=xmins\n            df_extrain_main.loc[index,'y']=ymins\n            df_extrain_main.loc[index,'width']=xmaxs\n            df_extrain_main.loc[index,'height']=ymaxs\n","142cf228":"classes=pd.DataFrame([{'class':'Fish','label':0}])\nclasses.to_csv(\"classes.csv\",index=False,header=False)  # This CSV will be use in training\n\ndf_extrain_main['class']='Fish'\ndf_extrain_main[['image_path','x','y','width','height','class']].to_csv(\"annotation.csv\",index=False,header=False)","0cb52670":"!keras_retinanet\/bin\/train.py --freeze-backbone --random-transform --no-resize --weights {PRETRAINED_MODEL} --batch-size 1 --steps 550 --epochs 40 csv annotation.csv classes.csv","ccd66a5f":"model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\nprint(model_path)\n\n# load retinanet model\nmodel = models.load_model(model_path, backbone_name='resnet50')  ## Use backbone as resnet50\nmodel = models.convert_model(model)\n\n# load label to names mapping for visualization purposes\nlabels_to_names = pd.read_csv('classes.csv',header=None).T.loc[0].to_dict()","2f463d51":"THRES_SCORE = 0.25  # Set Score Threshold Value\n\ndef df_plot_orinal(drawOG,img_path,df):\n    df=df[df['image_path']==img_path]\n    for i,r in df.iterrows():\n        cv2.rectangle(drawOG, (r['x'], r['y']), (r['width'], r['height']), (255,0,0),2)\n    \n\ndef img_inference(img_path):\n  image = read_image_bgr(img_path)\n\n  # copy to draw on\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n  drawOG = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  # preprocess image for network\n  image = preprocess_image(image)\n  image, scale = resize_image(image)\n\n  # process image\n  start = time.time()\n  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n  df_plot_orinal(drawOG,img_path,df_extrain_main)\n  # correct for image scale\n  boxes \/= scale\n  # visualize detections\n  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n      # scores are sorted so we can break\n      if score < THRES_SCORE:\n          break\n      color = label_color(label)\n      b = box.astype(int)\n      draw_box(draw, b, color=color)\n      caption = \"{} {:.3f}%\".format(labels_to_names[label], score*100)\n    \n  fig = plt.figure(figsize=(20, 20))\n  ax1=fig.add_subplot(1, 2, 1)\n  plt.imshow(draw)\n  ax2=fig.add_subplot(1, 2, 2)\n  plt.imshow(drawOG)\n\n  ax1.title.set_text('Predicted')\n  ax2.title.set_text('Actual')\n  plt.show()","d38514e1":"data=df_extrain_main.sample(n=5)  #Predict on Random 5 Image\nfor i,r in data.iterrows():\n    img_inference(r['image_path'])","87797370":"# Import the library that is used to submit the prediction result.\nimport sys\nINPUT_DIR = '\/kaggle\/input\/tensorflow-great-barrier-reef\/greatbarrierreef\/'\nsys.path.insert(0, INPUT_DIR)\nimport greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()","f0cbf57a":"THRES_SCORE = 0.8\n\nsubmission_dict = {\n    'id': [],\n    'prediction_string': [],\n}\n\nfor (image, sample_prediction_df) in iter_test:\n  print(image.shape,sample_prediction_df)\n\n  image = preprocess_image(image)\n  image, scale = resize_image(image)\n\n  # process image\n  start = time.time()\n  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n  predictions=[]\n  # correct for image scale\n  boxes \/= scale\n  # visualize detections\n  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n      # scores are sorted so we can break\n      if score < 0.0:\n          break\n      predictions = []\n      x_min = int(box[0])  \n      y_min = int(box[1])\n      x_max = int(box[2])\n      y_max = int(box[3])\n\n      bbox_width = x_max - x_min\n      bbox_height = y_max - y_min\n      predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n\n  prediction_str = ' '.join(predictions)\n  sample_prediction_df['annotations'] = prediction_str\n  env.predict(sample_prediction_df)\n  print('Prediction:', prediction_str)\n\nmy_submission = pd.DataFrame(sample_prediction_df)\n# you could use any filename. We choose submission here\nsample_prediction_df.to_csv('submission.csv', index=False)","2e3c0f79":"#!ls\n#!mv 'submission.csv' '\/kaggle\/working\/'","4f94a2f2":"# \u52a0\u8f7d\u8bad\u7ec3\u6a21\u578b","b27cf7ef":"# \u521b\u5efa\u8bad\u7ec3\u6570\u636e","f36a2d25":"# \u8f6c\u6362\u6570\u636e\u683c\u5f0f","557e48a4":"# \u52a0\u8f7d\u6570\u636e","0e3a4d5e":"\n# \u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd","36b51484":"# \u8bad\u7ec3Training RetinaNe","6341ff81":"\n# \u5bfc\u5165\u5e93","43a0a9d4":"# Reef API","91239bfb":"# \u9884\u6d4b\u4e0e\u5b9e\u9645"}}