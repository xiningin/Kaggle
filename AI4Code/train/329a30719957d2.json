{"cell_type":{"7077128f":"code","173f1e7e":"code","3ca2c33b":"code","f829a940":"code","81356804":"code","b431dcb2":"code","452d66f5":"code","989daf2a":"code","04f0c436":"code","3dcb021b":"code","a7028290":"code","2197f1e7":"code","655d385b":"code","ddff20d0":"code","018b94b9":"code","2cb3a7f4":"code","4c9e94be":"code","23b6bb4a":"code","5af1f1bc":"code","048f665d":"code","28dfa6ff":"code","096e2eb6":"code","87e96e13":"code","bb05bbc1":"code","385cbc57":"code","7d7d5b2b":"code","8758b564":"code","33232edb":"code","9adf0097":"code","91b898ed":"code","fcc090de":"code","333fb1c6":"code","5b8dceae":"code","de1917a2":"code","b268c389":"code","675625ab":"code","0f5993d3":"code","ce3c19e1":"code","eddd66bd":"markdown","07a21336":"markdown","8e2cefc5":"markdown","5b038ae3":"markdown","a5447e94":"markdown"},"source":{"7077128f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","173f1e7e":"train=pd.read_csv(\"\/kaggle\/input\/landmark-retrieval-2020\/train.csv\")\ntrain.head()","3ca2c33b":"train[\"landmark_id\"].nunique(),train[\"id\"].nunique(),train.shape","f829a940":"t=train.groupby(\"landmark_id\")[\"id\"].count().to_frame().sort_values(\"id\",ascending=False)\nt=t[t[\"id\"]>100]\ntrain=train[train[\"landmark_id\"].isin(list(t.index))]\ntrain[\"landmark_id\"].nunique(),train[\"id\"].nunique(),train.shape","81356804":"from glob import glob\ntrain_files=glob(\"..\/input\/landmark-retrieval-2020\/train\/*\/*\/*\/*\")\nindex_files=glob(\"..\/input\/landmark-retrieval-2020\/index\/*\/*\/*\/*\")\ntest_files=glob(\"..\/input\/landmark-retrieval-2020\/test\/*\/*\/*\/*\")\nlen(train_files),len(index_files),len(test_files)","b431dcb2":"t=pd.DataFrame({\"train_path\":train_files})\nt[\"id\"]=t[\"train_path\"].apply(lambda x: x.split(\"\/\")[-1][:-4])\ntrain=train.merge(t,how='inner',on=[\"id\"])\nprint(train.shape)\ntrain.head()","452d66f5":"import matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\nid=27\ndfsample = train[train['landmark_id' ]== id]\n\nfor i,row in dfsample.reset_index().iterrows():\n    \n    path=row[\"train_path\"]\n    example = cv2.imread(path)\n    print(example.shape)\n\n    plt.imshow(example)\n    plt.show()\n    if (i>4):\n        break","989daf2a":"train.head()","04f0c436":"import tensorflow as tf\nfrom tensorflow.keras import layers,models\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self,train):\n        self.batch_size=BATCH_SIZE\n        self.landmark_ids=train[\"landmark_id\"].unique()\n        self.ids=train[\"id\"].unique()\n        \n        self.dict_image_to_landmark_mapping=train.set_index(\"id\")[\"landmark_id\"].to_dict()\n        self.dict_landmark_to_images_mapping=train.groupby(\"landmark_id\")[\"id\"].apply(list).to_dict()\n        self.path_dict=train.set_index(\"id\")[\"train_path\"].to_dict()\n        \n        self.on_epoch_end()\n        pass\n    def __len__(self,):\n#         return int(np.floor(len(self.ids) \/ self.batch_size))\n        return 20#*20\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.ids))\n        np.random.shuffle(self.indexes)\n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        anchors = [self.ids[k] for k in indexes]\n        positives=[self.get_positives(anchor) for anchor in anchors]\n        negatives=[self.get_negatives(anchor) for anchor in anchors]\n        \n        X=[anchors,positives,negatives]\n        X= self.get_images(X)\n        y=np.zeros((len(X),))\n        return X,y\n    def get_positives(self,anchor):\n        landmarkid=self.dict_image_to_landmark_mapping[anchor]\n        all_positive_images=self.dict_landmark_to_images_mapping[landmarkid]\n        all_positive_images=[t for t in all_positive_images if t != anchor]\n        return np.random.choice(all_positive_images)\n    \n    def get_negatives(self,anchor):\n        landmarkid=self.dict_image_to_landmark_mapping[anchor]\n        random_negative_landmarkid=np.random.choice([t for t in self.landmark_ids if t!=landmarkid])\n        random_negative_image=self.dict_landmark_to_images_mapping[random_negative_landmarkid]\n        return np.random.choice(random_negative_image)\n    def get_images(self,X):\n        X_=[]\n        \n        anchors=X[0]\n        positives=X[1]\n        negatives=X[2]\n        anchors_=[]\n        positives_=[]\n        negatives_=[]\n        for a in anchors:\n            a=self.path_dict[a]\n            a=cv2.imread(a)\n            a=cv2.resize(a,(128,128))*1\/255\n            anchors_.append(a)\n        for p in positives:\n            p=self.path_dict[p]\n            p=cv2.imread(p)\n            p=cv2.resize(p,(128,128))*1\/255\n            positives_.append(p)\n        for n in negatives:\n            n=self.path_dict[n]\n            n=cv2.imread(n)\n            n=cv2.resize(n,(128,128))*1\/255\n            negatives_.append(n)\n        \n        X_=[np.array(anchors_),np.array(positives_),np.array(negatives_)]\n        return X_","3dcb021b":"BATCH_SIZE=1\ntraining_generator = DataGenerator(train)","a7028290":"for batch in training_generator:\n    break\nlen(batch)","2197f1e7":"X=batch[0]\nanchor=X[0]\nanchor.shape","655d385b":"d={0:\"Anchor\",1:\"Positive\",2:\"Negative\"}\nfor i,a in enumerate(batch[0]):\n    print(d[i])\n    plt.imshow(a[0])\n    plt.show()\n    \ndel training_generator","ddff20d0":"# https:\/\/github.com\/KinWaiCheuk\/Triplet-net-keras\/blob\/master\/Triplet%20NN%20Test%20on%20MNIST.ipynb\nfrom tensorflow.keras import backend as K\ndef triplet_loss(y_true, y_pred, alpha = 0.4):\n    \"\"\"\n    Implementation of the triplet loss function\n    Arguments:\n    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n    y_pred -- python list containing three objects:\n            anchor -- the encodings for the anchor data\n            positive -- the encodings for the positive data (similar to anchor)\n            negative -- the encodings for the negative data (different from anchor)\n    Returns:\n    loss -- real number, value of the loss\n    \"\"\"\n    print('y_pred.shape = ',y_pred)\n    \n    total_lenght = y_pred.shape.as_list()[-1]\n#     print('total_lenght=',  total_lenght)\n#     total_lenght =12\n    \n    anchor = y_pred[:,0:int(total_lenght*1\/3)]\n    positive = y_pred[:,int(total_lenght*1\/3):int(total_lenght*2\/3)]\n    negative = y_pred[:,int(total_lenght*2\/3):int(total_lenght*3\/3)]\n\n    # distance between the anchor and the positive\n    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n\n    # distance between the anchor and the negative\n    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n\n    # compute loss\n    basic_loss = pos_dist-neg_dist+alpha\n    loss = K.maximum(basic_loss,0.0)\n \n    return loss\ndef base_model():\n    inp=layers.Input(shape=(128,128,3))\n    x=layers.Conv2D(128,(7,7),padding='same',activation='relu',name='conv1')(inp)\n    x=layers.MaxPooling2D((2,2),(2,2),padding='same',name='pool1')(x)\n#     x=layers.Conv2D(256,(5,5),padding='same',activation='relu',name='conv2')(x)\n#     x=layers.MaxPooling2D((2,2),(2,2),padding='same',name='pool2')(x)\n    x=layers.Flatten(name='flatten')(x)\n    x=layers.Dense(4,name='embeddings')(x)\n    model=models.Model(inputs=inp,outputs=x)\n    return model\n\ndef build_model():\n    anchor_input=layers.Input(shape=(128,128,3))\n    positive_input=layers.Input(shape=(128,128,3))\n    negative_input=layers.Input(shape=(128,128,3))\n    \n    base=base_model()\n    encoded_anchor = base(anchor_input)\n    encoded_positive = base(positive_input)\n    encoded_negative = base(negative_input)\n    merged_vector = layers.concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n    model = models.Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n    model.compile(loss=triplet_loss, optimizer=tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999))\n    \n    embedding_model = models.Model(inputs=anchor_input, outputs=encoded_anchor)\n    \n    return model,embedding_model\n  \nmodel,embedding_model=build_model()\nmodel.summary()","018b94b9":"train.head()\nval_lid=np.random.choice(train[\"landmark_id\"].unique(),int(len(train[\"landmark_id\"].unique())*0.3))\nlen(val_lid),len(train[\"landmark_id\"].unique())\nval_=train[train[\"landmark_id\"].isin(val_lid)]\ntrain_=train[(train[\"landmark_id\"].isin(val_lid))==False]\nprint(train_.shape,val_.shape)","2cb3a7f4":"BATCH_SIZE=32\nEPOCHS=2\ntraining_generator=DataGenerator(train_)\nvalidation_data=DataGenerator(val_)","4c9e94be":"model.fit(training_generator,\n                    validation_data=validation_data,\n                     batch_size=BATCH_SIZE, epochs=EPOCHS)","23b6bb4a":"print(len(index_files),len(test_files))\ndfindex=pd.DataFrame({\"index_path\":index_files})\ndfindex[\"index\"]=dfindex[\"index_path\"].apply(lambda x: x.split(\"\/\")[-1][:-4])\ndftest=pd.DataFrame({\"test_path\":test_files})\ndftest[\"test\"]=dftest[\"test_path\"].apply(lambda x: x.split(\"\/\")[-1][:-4])\ndftest.head()","5af1f1bc":"del train,training_generator,validation_data\nimport gc\ngc.collect()","048f665d":"class predictDataset(tf.keras.utils.Sequence):\n    def __init__(self,path):\n        self.paths=path\n        self.batch_size=BATCH_SIZE\n        self.on_epoch_end()\n    def __len__(self,):\n        return int(np.floor(len(self.paths) \/ self.batch_size))\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.paths))\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        images=[self.paths[t] for t in indexes]\n        images=[cv2.imread(t) for t in images]\n        images=[cv2.resize(t,(128,128))*1\/255 for t in images]\n        return np.array(images)\n","28dfa6ff":"BATCH_SIZE=102\n\nquery_dataset=predictDataset(dftest[\"test_path\"].values)","096e2eb6":"%%time\nquery_embeddings=embedding_model.predict(query_dataset)\nquery_embeddings.shape","87e96e13":"import joblib\n# joblib.dump(query_embeddings,\"query_embeddings.pkl\")\n","bb05bbc1":"del query_dataset\ngc.collect()","385cbc57":"%%time\nindex_dataset=predictDataset(dfindex[\"index_path\"].values)\nindex_embeddings=embedding_model.predict(index_dataset)\nindex_embeddings.shape","7d7d5b2b":"import joblib\n# joblib.dump(index_embeddings,\"index_embeddings.pkl\")\ndel index_dataset\ngc.collect()","8758b564":"# del model, embedding_model\ngc.collect()","33232edb":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(100)\ny=np.arange(index_embeddings.shape[0])","9adf0097":"knn.fit(index_embeddings,y)","91b898ed":"preds=knn.predict(query_embeddings)\npreds","fcc090de":"random_query=np.random.choice(range(len(dftest)))\nprint(\"query image\")\nplt.imshow(cv2.imread(dftest[\"test_path\"].values[random_query]))\nplt.show()\nprint(\"match index\")\nplt.imshow(cv2.imread(dfindex[\"index_path\"].values[random_query]))\nplt.show()","333fb1c6":"random_query=np.random.choice(range(len(dftest)))\nprint(\"query image\")\nplt.imshow(cv2.imread(dftest[\"test_path\"].values[random_query]))\nplt.show()\nprint(\"match index\")\nplt.imshow(cv2.imread(dfindex[\"index_path\"].values[random_query]))\nplt.show()","5b8dceae":"random_query=np.random.choice(range(len(dftest)))\nprint(\"query image\")\nplt.imshow(cv2.imread(dftest[\"test_path\"].values[random_query]))\nplt.show()\nprint(\"match index\")\nplt.imshow(cv2.imread(dfindex[\"index_path\"].values[random_query]))\nplt.show()","de1917a2":"random_query=np.random.choice(range(len(dftest)))\nprint(\"query image\")\nplt.imshow(cv2.imread(dftest[\"test_path\"].values[random_query]))\nplt.show()\nprint(\"match index\")\nplt.imshow(cv2.imread(dfindex[\"index_path\"].values[random_query]))\nplt.show()","b268c389":"random_query=np.random.choice(range(len(dftest)))\nprint(\"query image\")\nplt.imshow(cv2.imread(dftest[\"test_path\"].values[random_query]))\nplt.show()\nprint(\"match index\")\nplt.imshow(cv2.imread(dfindex[\"index_path\"].values[random_query]))\nplt.show()","675625ab":"tf.saved_model.save(embedding_model, \"sub\/final_model\")","0f5993d3":"import shutil\nshutil.make_archive(\"submission\", 'zip', \"sub\/final_model\")","ce3c19e1":"!ls sub","eddd66bd":"**Steps:**\n1. Train model on anchor,positive,negative image sets to minimize triplet loss\n2. Use trained model layers to generate embeddings of test images and index images\n3. Train KNN classifier on index image embeddings (n=100)\n4. Predict on test image embeddings (i.e. find test image embeddings' closest index image embedding) \n5. Save Model","07a21336":"First draft...\n\nNeed to be improved\n\n**Upvotes appreciated :)**","8e2cefc5":"First draft...\n\nNeed to be improved\n\n\n\n**Comments\/suggestions\/feedback & Upvotes appreciated :)**","5b038ae3":"**Selecting only high occurrence landmarks for training**","a5447e94":"https:\/\/towardsdatascience.com\/image-similarity-using-triplet-loss-3744c0f67973\n\nTrying Triplet Loss\n![image.png](attachment:image.png)\n\nInspired by: https:\/\/www.kaggle.com\/c\/landmark-retrieval-challenge\/discussion\/58155"}}