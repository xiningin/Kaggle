{"cell_type":{"395c9c83":"code","7587ec88":"code","0705cd9d":"code","c86b28c0":"code","9656f20c":"code","f0ac2973":"code","422610c1":"code","3f235f92":"code","fd874863":"code","114dcbd7":"code","74d853ec":"code","d2ea0e32":"code","44dd49c6":"code","0b5a8f69":"code","c3b1a47d":"code","d9797e38":"code","c1be530f":"code","315ac4f4":"code","2fef415b":"code","abe3625a":"code","7a851271":"code","c2a83c59":"code","f4f189a0":"code","2484ee52":"code","418dcd2d":"code","bf4d9897":"markdown","e7a231c8":"markdown","adb10e03":"markdown","0dca7c62":"markdown","38e6236d":"markdown","72280237":"markdown","39c45329":"markdown","b8517857":"markdown","6009fd0c":"markdown","1943f59b":"markdown","81403a0c":"markdown","020cafa6":"markdown","2e5a0a79":"markdown","9cd96a70":"markdown","bb91b6fd":"markdown","fc0c3eda":"markdown","e2651e9c":"markdown","65e2baf4":"markdown","5536d602":"markdown","03f049b2":"markdown","78266170":"markdown","96d50f2b":"markdown","96984cbb":"markdown","fa6f10c8":"markdown","51848021":"markdown","021cd86c":"markdown","ecb87b4c":"markdown"},"source":{"395c9c83":"import os\n\npath = '\/kaggle\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'\n\nlabels = [something for something in os.listdir(path) if os.path.isdir(path + '\/' + something)]\ndata = [path + ('\/' + label) * 2 + '\/' + f for label in labels for f in sorted(os.listdir(path + ('\/' + label) * 2))]\nlabels = [d[len(path) + 1:].split('\/')[0] for d in data] # update\n\ndata[:5], labels[:5]","7587ec88":"import pandas as pd\n\ndf = pd.DataFrame({'data_path': [d[len(path):] for d in data], 'label': labels})\ndf.head()","0705cd9d":"df.info()","c86b28c0":"df['label'].value_counts()","9656f20c":"import random\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# choose each one fish\nfishes = list(df['label'].value_counts().index)\nfishes_example = [random.sample(list(df[df['label'] == fish]['data_path']), 1) for fish in fishes]\n\nrow = col = 3\nfigure = plt.figure(figsize = (15, 13))\n\nfor r in range(row):\n    for c in range(col):\n        ax = figure.add_subplot(row, col, r * col + c + 1)\n        ax.imshow(mpimg.imread(path + fishes_example[r * col + c][0]))\n        ax.set_title(fishes[r * col + c], fontsize = 20)\n        ax.axis(\"off\")\nplt.show()","f0ac2973":"label_to_int = {}\nint_to_label = {}\nfor i, label in enumerate(df['label'].value_counts().index):\n    label_to_int[label] = i\n    int_to_label[i] = label\nlabel_to_int","422610c1":"from PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import transforms\n\nclass FishDataset(Dataset):\n    def __init__(self, file_name, labels, path, transform = transforms.ToTensor()):\n        self.file_name = file_name.tolist()\n        self.labels = [label_to_int[label] for label in labels]\n        self.path = path\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return (self.transform(Image.open(self.path + self.file_name[idx])), self.labels[idx])","3f235f92":"batch_size = 32\nshuffle = True\n\ndata_set = FishDataset(df['data_path'], df['label'], path)\ntotal_loader = DataLoader(dataset = data_set, batch_size = batch_size, shuffle = shuffle)","fd874863":"import torch\nfrom tqdm.auto import tqdm\n\ntotal_sum, total_square_root_sum, batch_count = 0.0, 0.0, 0\nfor data, _ in tqdm(total_loader, position = 0):\n    total_sum += torch.mean(data, dim = [0, 2, 3])\n    total_square_root_sum += torch.mean(data ** 2, dim = [0, 2, 3])\n    batch_count += 1\ntotal_mean = total_sum \/ batch_count\ntotal_std = (total_square_root_sum \/ batch_count - total_mean ** 2) ** 0.5\ntotal_mean, total_std","114dcbd7":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = total_mean, std = total_std)\n])\ntransform","74d853ec":"from sklearn.model_selection import train_test_split\nimport numpy as np\n\ntrain_data, test_data, train_answer, test_answer = train_test_split(df['data_path'], df['label'], test_size = 0.4, stratify = df['label'])\n\ntrain_set = FishDataset(train_data, train_answer, path, transform)\ntest_set = FishDataset(test_data, test_answer, path, transform)\n\nprint('Train data count =', np.unique(train_answer, return_counts = True)[1])\nprint('Test data count =', np.unique(test_answer, return_counts = True)[1])","d2ea0e32":"train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = shuffle)\ntest_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = shuffle)\nnext(iter(train_loader))[0].shape","44dd49c6":"one_image, one_label = next(iter(train_loader))\none_image = one_image[0]\none_label = int_to_label[one_label[0].item()]\n\nplt.figure(figsize = (7, 5))\nplt.imshow(one_image.permute(1, 2, 0)) # torch(channel, height, width) -> plt(width, height, channel)\nplt.title(one_label, fontsize = 20)\nplt.axis('off')\nplt.show()","0b5a8f69":"!pip install timm","c3b1a47d":"import timm\n\nprint('Number of models available =', len(timm.list_models(pretrained = True)))","d9797e38":"num_classes = len(label_to_int)\nmodel_names = ['efficientnet_b0', 'efficientnet_b4', 'nfnet_l0']\nmodels = []\nfor model_name in model_names:\n    models.append(timm.create_model(model_name, pretrained = True, num_classes = num_classes))\n[model.__class__ for model in models]","c1be530f":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nlearning_rate = 0.0001\n\ncriterion = torch.nn.CrossEntropyLoss().to(device)\noptimizers = []\nfor model in models:\n    optimizers.append(torch.optim.Adam(model.parameters(), lr = learning_rate))\ndevice","315ac4f4":"epochs = 3\ntrain_lastest_accuracy = []\nfor name, model, optimizer in zip(model_names, models, optimizers):\n    model = model.to(device)\n    model.train()\n    for epoch in tqdm(range(1, epochs + 1), position = 0):\n        train_loss = 0\n        train_accuracy = 0\n        for data, targets in train_loader:\n            data = data.to(device)\n            targets = targets.to(device)\n\n            output = model(data)\n            loss = criterion(output, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            predict = output.max(1)[1]\n            train_accuracy += predict.eq(targets).sum().item()\n        else:\n            train_loss \/= len(train_loader)\n            train_accuracy *= (100 \/ len(train_loader.dataset))\n            print(\"Train Result of {} : Epoch = {} -> Loss = {:.4f}, Accuracy = {:.4f}%\".format(name, epoch, train_loss, train_accuracy))\n    else:\n        train_lastest_accuracy.append(train_accuracy)\ntrain_lastest_accuracy","2fef415b":"class AccuracyEnsemble(torch.nn.Module):\n    def __init__(self, models, train_accuracy = [1 \/ len(models)] * len(models)):\n        super(AccuracyEnsemble, self).__init__()\n        self.models = models\n        self.weights = torch.tensor(train_accuracy)\n        \n    def forward(self, x):\n        total_output = 0\n        for weight, model in zip(self.weights, self.models):\n            total_output += weight * model(x)\n        return total_output","abe3625a":"ensemble = AccuracyEnsemble(models, train_lastest_accuracy).to(device)\nensemble.weights.tolist()","7a851271":"ensemble = ensemble.to(device)\nfor model in models:\n    model.eval()\nensemble.eval()\n\ntest_predict_list = []\ntest_answer_list = []\nwith torch.no_grad():\n    test_loss = 0\n    test_accuracy = 0\n    for data, targets in tqdm(test_loader, position = 0):\n        data = data.to(device)\n        targets = targets.to(device)\n\n        output = ensemble(data)\n\n        test_loss += criterion(output, targets).item()\n        predict = output.max(1)[1]\n        test_accuracy += predict.eq(targets).sum().item()\n        \n        test_predict_list.extend(predict.tolist())\n        test_answer_list.extend(targets.tolist())\n    else:\n        test_loss \/= len(test_loader)\n        test_accuracy *= (100 \/ len(test_loader.dataset))\n        print(\"Test Result of ensemble : Loss -> {:.4f}, Accuracy = {:.4f}%\".format(test_loss, test_accuracy))","c2a83c59":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(test_answer_list, test_predict_list, normalize = 'true')\nplt.figure(figsize = (15, 13))\nsns.heatmap(cf_matrix, annot = True, fmt = '.2%', cmap = 'Blues', xticklabels = [p + '(p)' for p in label_to_int], yticklabels = [a + '(a)' for a in label_to_int])\nplt.show()","f4f189a0":"ensemble_model_name = 'fish_ensemble_model.pt'\ntorch.save(ensemble.state_dict(), ensemble_model_name)","2484ee52":"ensemble = AccuracyEnsemble(models, train_lastest_accuracy)\nensemble.load_state_dict(torch.load(ensemble_model_name), strict = False)","418dcd2d":"ensemble = ensemble.to(device)\nensemble.eval()\ndata, target = next(iter(test_loader))\nsample_predict_list = ensemble(data.to(device)).max(1)[1].tolist()\nsample_answer_list = target.to(device).tolist()\nprint('Predict =', [int_to_label[p] for p in sample_predict_list])\nprint()\nprint('Answer  =', [int_to_label[a] for a in sample_answer_list])","bf4d9897":"#### Make DataFrame for data verification.","e7a231c8":"# 3. Sample images","adb10e03":"#### Save model","0dca7c62":"# 4. Dataset","38e6236d":"#### Split dataset","72280237":"#### Make custom dataset.","39c45329":"#### Install timm package","b8517857":"#### Test cell\n\nCheck **accuracy**. **F1-score**.","6009fd0c":"#### Confusion matrix","1943f59b":"# 8. Save & Load model ","81403a0c":"# 7. Test","020cafa6":"# 2. DataFrame","2e5a0a79":"#### Check null data","9cd96a70":"#### Set models","bb91b6fd":"# 5. Model","fc0c3eda":"#### Set transforms","e2651e9c":"#### Show image with transform applied","65e2baf4":"#### Load model","5536d602":"#### Sample test","03f049b2":"# 1. Data preprocessing","78266170":"# 6. Train","96d50f2b":"#### Each data count","96984cbb":"#### Show each fish images.","fa6f10c8":"# Fish Classification using timm","51848021":"#### Calculate mean & standard","021cd86c":"#### Create ensemble models proportional to accuracy","ecb87b4c":"#### train cell\n\ncheck **accuracy**."}}