{"cell_type":{"fc740459":"code","95ee1719":"code","9ce82a74":"code","95df1cb6":"code","51eb095f":"code","684e44ed":"code","cb1c02e3":"code","afe81e2c":"code","ab96a77e":"code","ab69aabc":"code","c745dd69":"code","2b151949":"code","95fe2bed":"code","d36e8d5b":"code","d353cab9":"code","78bc707a":"code","351a0e46":"code","56759b74":"code","1d6da8ac":"code","3be7abb3":"code","8aa1e1c4":"code","38d57ad0":"code","fdaa46ee":"code","02fd16d3":"code","bb2b1806":"code","2f4bba70":"code","a895c6c7":"code","43e430d7":"code","90bfa023":"code","289b2b0c":"code","68e884fe":"code","73c2a4a6":"code","23333b0f":"code","8a7004a9":"code","82b252c9":"code","eec5be60":"code","7739bbd4":"code","a4a7e0ce":"code","1d45c56e":"code","2814be66":"code","21c3aaf3":"code","ad0d1012":"code","d5b089f4":"code","2a931e87":"code","cf5ec941":"code","9cd00071":"code","7f84020f":"code","d30aaac1":"code","d8c902fe":"code","d79b4d82":"code","38e8abac":"code","4ebc29f1":"code","550a15ef":"code","f2fffbc4":"code","9919b608":"code","d79d7e0c":"code","b4fb8190":"code","036e1739":"code","630644c4":"code","c83e090a":"code","c5561e44":"code","17d01d90":"code","450d30f5":"code","c1b6809e":"code","5b790082":"code","1d52eed2":"code","2ed72b3c":"code","eca5709c":"code","3208754e":"code","0947df66":"code","bb04ab81":"code","792b7b16":"code","9c3f7314":"code","159463df":"code","5b9f7fda":"code","156efe29":"code","b6d2ec95":"code","f93207a5":"code","b69ae687":"code","5f9ea65a":"markdown","a6828fb6":"markdown","19cc97f9":"markdown","7343fe2e":"markdown","2b108b83":"markdown","2da9569d":"markdown","7b88832f":"markdown","21ec4258":"markdown","1b7b2129":"markdown","f150be1a":"markdown","21058a9d":"markdown","308c25c7":"markdown","66837da0":"markdown","668623fd":"markdown","6d9e32a8":"markdown","81171fc4":"markdown","9c4d4ed2":"markdown","1a665379":"markdown","d98dbeea":"markdown","1be4775e":"markdown"},"source":{"fc740459":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\n\n\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score,accuracy_score,log_loss\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\n#optimizer \n\nfrom functools import partial\nimport optuna\n\n","95ee1719":"train_df= pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv',index_col='row_id')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv',index_col ='row_id')","9ce82a74":"train_df.head()","95df1cb6":"# change date datatype to datatime \ntrain_df['date'] = pd.to_datetime(train_df.date, format = \"%Y-%m-%d\")\ntest_df['date'] = pd.to_datetime(test_df.date, format = \"%Y-%m-%d\")","51eb095f":"#As many people discussing about GDP per capita, I am going to use the data.\n#https:\/\/www.macrotrends.net\/countries\/NOR\/norway\/gdp-per-capita\n#USD per capita and growth rate\n\nSweden_ec = {2015:[51545,-.1412],2016:[51965,.0081],2017:[53792,.0351],2018:[54589,.0148],2019:[51687,-.0532]}\n\nFinland_ec = {2015:[42802,-.1495],2016:[43814,.0236],2017:[46412,.0593],2018:[50038,.0781],2019:[48712,-.0265]}\n\nNorway_ec = {2015:[74356,-.2336],2016:[70461,-.0524],2017:[75497,0.0715],2018:[82268,.0897],2019:[75826,-.0783]}\n","684e44ed":"train_df['GDPperCapita'] = [Sweden_ec[a.year][0] if b =='Sweden' else(Finland_ec[a.year][0] if b =='Finland' else Norway_ec[a.year][0]) for a,b in zip(train_df.date,train_df.country)]\ntrain_df['GrowthRate']  = [Sweden_ec[a.year][1] if b =='Sweden' else(Finland_ec[a.year][1] if b =='Finland' else Norway_ec[a.year][1]) for a,b in zip(train_df.date,train_df.country)]","cb1c02e3":"test_df['GDPperCapita'] = [Sweden_ec[a.year][0] if b =='Sweden' else(Finland_ec[a.year][0] if b =='Finland' else Norway_ec[a.year][0]) for a,b in zip(test_df.date,test_df.country)]\ntest_df['GrowthRate']  = [Sweden_ec[a.year][1] if b =='Sweden' else(Finland_ec[a.year][1] if b =='Finland' else Norway_ec[a.year][1]) for a,b in zip(test_df.date,test_df.country)]","afe81e2c":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\n\ntrain_df[['GDPperCapita','GrowthRate']] = scaler.fit_transform(train_df[['GDPperCapita','GrowthRate']])\ntest_df[['GDPperCapita','GrowthRate']] = scaler.transform(test_df[['GDPperCapita','GrowthRate']])","ab96a77e":"#Add day of week Monday:0 Sunday:6\n\ndayOfWeek={'Monday':0, 'Tuesday':1, 'Wednesday':2, 'Thursday':3, 'Friday':4, 'Saturday':5, 'Sunday':6}\ntrain_df['day_of_week'] = train_df['date'].dt.day_name().map(dayOfWeek)\ntest_df['day_of_week'] = test_df['date'].dt.day_name().map(dayOfWeek)","ab69aabc":"train_df['weekend'] = [1 if a in [5,6] else 0 for a in train_df['day_of_week']]\ntest_df['weekend'] = [1 if a in [5,6] else 0 for a in test_df['day_of_week']]\n","c745dd69":"daily_average_sale = train_df.groupby(by='date').num_sold.mean()","2b151949":"fig = plt.figure(figsize=(50,10))\nplt.bar(daily_average_sale.index,daily_average_sale.values,color=(0.1,0.1,0.1,0.1),edgecolor='blue')\n\n\nplt.title('Daily Average Sales')\nplt.ylabel('Number of Sales')","95fe2bed":"objects =['country','store','product']\n\nfor i in objects:\n     print(train_df[i].unique())\nprint('\\n')\nfor i in objects:\n    print(test_df[i].unique())\n","d36e8d5b":"Finland_KaggleMart = train_df[(train_df.country=='Finland') & (train_df.store =='KaggleMart')]","d353cab9":"Finland_KaggleMart","78bc707a":"def make_sales_graphs(country,store,product):\n    df1 = train_df[(train_df.country== country) & (train_df.store == store)]\n    \n    df2 = df1[df1['product'] == product]   \n    fig = plt.figure(figsize=(50,10))\n    plt.bar(df2.date,df2.num_sold)\n    fig.suptitle( product + ' Sales - ' + country +' ' + store + ' (2015-2018)',fontsize=20) \n    plt.show()\n    \n    ","351a0e46":"make_sales_graphs('Finland','KaggleMart','Kaggle Mug')","56759b74":"countries = ['Finland', 'Norway', 'Sweden']\nstores = ['KaggleMart', 'KaggleRama']\nproducts = ['Kaggle Mug' ,'Kaggle Hat', 'Kaggle Sticker']","1d6da8ac":"for i in stores:\n    for j in products:\n        make_sales_graphs('Finland',i,j)","3be7abb3":"for i in stores:\n    for j in products:\n        make_sales_graphs('Norway',i,j)","8aa1e1c4":"for i in stores:\n    for j in products:\n        make_sales_graphs('Sweden',i,j)","38d57ad0":"daily_sale = train_df.groupby(by='day_of_week').mean()\nplt.bar(np.arange(len(daily_sale)),daily_sale['num_sold'].to_list(),color=(0.1,0.1,0.1,0.1),edgecolor='blue')\n\nplt.xticks(np.arange(len(daily_sale)),['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])\n\nplt.title('Sales by Day of Week')\nplt.ylabel('Number of Sales')\n","fdaa46ee":"train_df['day'] = pd.DatetimeIndex(train_df.date).day\ntest_df['day'] = pd.DatetimeIndex(test_df.date).day\n\ntrain_df['month'] = pd.DatetimeIndex(train_df.date).month\ntest_df['month'] = pd.DatetimeIndex(test_df.date).month\n\ntrain_df['year'] = pd.DatetimeIndex(train_df.date).year\ntest_df['year'] = pd.DatetimeIndex(test_df.date).year","02fd16d3":"monthly_sale = train_df.groupby(by='month').mean()\nplt.bar(np.arange(len(monthly_sale)),monthly_sale['num_sold'].to_list(),color=(0.1,0.1,0.1,0.1),edgecolor='blue')\n\nplt.xticks(np.arange(len(monthly_sale)),range(1,13))\n\nplt.title('Sales by Month')\nplt.ylabel('Number of Sales')","bb2b1806":"#\nprint(train_df.groupby(by=['month','day']).sum()['num_sold'].sort_values(ascending=False)[:10])\nprint(train_df.query('year==2015').groupby(by='date').sum()['num_sold'].sort_values(ascending=False)[:10])\nprint(train_df.query('year==2016').groupby(by='date').sum()['num_sold'].sort_values(ascending=False)[:10])\nprint(train_df.query('year==2017').groupby(by='date').sum()['num_sold'].sort_values(ascending=False)[:10])\nprint(train_df.query('year==2018').groupby(by='date').sum()['num_sold'].sort_values(ascending=False)[:10])","2f4bba70":"# for each item\nprint('Hat Top Ten Sales Day')\nprint(train_df.query('product==\"Kaggle Hat\"').groupby(by=['month','day']).sum()['num_sold'].sort_values(ascending=False)[:10])\nprint(\"\\n\")\nprint(\"Mug Top Ten Sales Day\")\nprint(train_df.query('product==\"Kaggle Mug\"').groupby(by=['month','day']).sum()['num_sold'].sort_values(ascending=False)[:10])\nprint(\"\\n\")\nprint(print(\"Mug Top Ten Sales Day\"))\nprint(train_df.query('product==\"Kaggle Sticker\"').groupby(by=['month','day']).sum()['num_sold'].sort_values(ascending=False)[:10])\n\n","a895c6c7":"train_df.date[0].strftime('%m-%d') <\"01-02\"","43e430d7":"train_df['busiest'] =[1 if a.strftime('%m-%d')>='12-27' or a.strftime('%m-%d')<='1-3' else 0 for a in train_df.date]\ntest_df['busiest'] =[1 if a.strftime('%m-%d')>='12-27' or a.strftime('%m-%d')<='1-3' else 0 for a in test_df.date]","90bfa023":"#Add steps\n#https:\/\/stackoverflow.com\/questions\/60252983\/adding-new-step-value-column-for-timeseries-data-with-multiple-records-per-tim\ntrain_df['step'] = train_df['date']-train_df['date'].shift(1)     #shift index and find difference\nzero = np.timedelta64(0, 's')       \ntrain_df['step'][0] = np.timedelta64(0, 's')          #change first var from naT to zero\ntrain_df['step'] = train_df['step'].apply(lambda x: x>zero).cumsum()","289b2b0c":"test_df['step'] = test_df['date']-test_df['date'].shift(1)     #shift index and find difference\nzero = np.timedelta64(0, 's')       \ntest_df['step'][0] = np.timedelta64(0, 's')          #change first var from naT to zero\ntest_df['step'] = test_df['step'].apply(lambda x: x>zero).cumsum()","68e884fe":"\n\ntrain_df['year'] = pd.DatetimeIndex(train_df.date).year\ntest_df['year'] = pd.DatetimeIndex(test_df.date).year\n\ntrain_df['day'] = pd.DatetimeIndex(train_df.date).day\ntest_df['day'] = pd.DatetimeIndex(test_df.date).day\n\ntrain_df['dayofyear'] = pd.DatetimeIndex(train_df.date).dayofyear\ntest_df['dayofyear'] = pd.DatetimeIndex(test_df.date).dayofyear\n\ntrain_df['Quarter'] = pd.DatetimeIndex(train_df.date).quarter\ntest_df['Quarter'] = pd.DatetimeIndex(test_df.date).quarter\n\ntrain_df['week'] = pd.DatetimeIndex(train_df.date).weekofyear\ntest_df['week'] = pd.DatetimeIndex(test_df.date).weekofyear","73c2a4a6":"import datetime\nimport holidays\n\n# Country List:['Finland' 'Norway' 'Sweden']\nholiday_FI = holidays.CountryHoliday('FI', years=[2015, 2016, 2017, 2018, 2019])\nholiday_NO = holidays.CountryHoliday('NO', years=[2015, 2016, 2017, 2018, 2019])\nholiday_SE = holidays.CountryHoliday('SE', years=[2015, 2016, 2017, 2018, 2019])\ndictionaries ={'Finland':holiday_FI,'Norway':holiday_NO,'Sweden':holiday_SE}\n\n#add some more celebration days\nholiday_FI.update({datetime.date(2015,5,10):'Mothers Day',datetime.date(2016,5,8):'Mothers Day',datetime.date(2017,5,14):'Mothers Day',datetime.date(2018,5,13):'Mothers Day',datetime.date(2019,5,12):'Mothers Day'})\nholiday_SE.update({datetime.date(2015,5,31):'Mothers Day',datetime.date(2016,5,29):'Mothers Day',datetime.date(2017,5,28):'Mothers Day',datetime.date(2018,5,27):'Mothers Day',datetime.date(2019,5,26):'Mothers Day'})\nholiday_NO.update({datetime.date(2015,5,10):'Mothers Day',datetime.date(2016,2,8):'Mothers Day',datetime.date(2017,2,14):'Mothers Day',datetime.date(2018,2,11):'Mothers Day',datetime.date(2019,2,10):'Mothers Day'})","23333b0f":"def add_dic(df):\n    ls = []\n    for a,b in zip(df.date,df.country):\n        if a.date() in list(dictionaries[b].keys()):\n            ls.append(dictionaries[b][a])\n        else:\n            ls.append('Not Holidays')\n    df['holiday_name'] = ls\n    return df\n    \n    ","8a7004a9":"train_df = add_dic(train_df)\ntest_df = add_dic(test_df)","82b252c9":"#https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\/discussion\/298990\n#As discuessed, adding some other celebration day.\n\n#Valentine's Day\n#New Year's Eve\n#Father's Day\n\ntrain_df['holiday_name'] = ['Valentine' if a.strftime('%m-%d')=='02-14' else b for a,b in zip(train_df.date,train_df.holiday_name)]\ntest_df['holiday_name'] = ['Valentine' if a.strftime('%m-%d')=='02-14' else b for a,b in zip(test_df.date,test_df.holiday_name)]\n\n\ntrain_df['holiday_name'] = ['New Year Eve' if a.strftime('%m-%d')=='12-31' else b for a,b in zip(train_df.date,train_df.holiday_name)]\ntest_df['holiday_name'] = ['New Year Eve' if a.strftime('%m-%d')=='12-31' else b for a,b in zip(test_df.date,test_df.holiday_name)]","eec5be60":"Fathers = ['2015-11-8','2016-11-13','2017-11-12','2018-11-11','2019-11-10']","7739bbd4":"train_df['holiday_name'] = ['Fathers Day' if a.strftime('%y-%m-%d') in Fathers else b for a,b in zip(train_df.date,train_df.holiday_name)]\n","a4a7e0ce":"train_df['is_holiday'] = [0 if a == 'Not Holidays' else 1 for a in train_df.holiday_name]\ntest_df['is_holiday'] = [0 if a == 'Not Holidays' else 1 for a in test_df.holiday_name]","1d45c56e":"test_df = test_df.replace(\"Trettondedag jul, S\u00f6ndag\" , \"Trettondedag jul\")","2814be66":"train_df['holiday_month'] = [1 if a in[1,4,12] else 0 for a in train_df.month]\ntest_df['holiday_month'] = [1 if a in[1,4,12] else 0 for a in test_df.month]","21c3aaf3":"# count week from each new year day\ntrain_df['week2'] = [int(a\/7) +1 for a in train_df['dayofyear']]\ntest_df['week2'] = [int(a\/7) +1 for a in test_df['dayofyear']]","ad0d1012":"categories = ['country','store','product','holiday_name']\nfor i in categories:\n    encoder = preprocessing.LabelEncoder()\n    train_df[i] = encoder.fit_transform(train_df[i])\n    test_df[i] =  encoder.transform(test_df[i])","d5b089f4":"def smape(a, f):\n    return 1\/len(a) * np.sum(2 * np.abs(f-a) \/ (np.abs(a) + np.abs(f))*100)","2a931e87":"train_df['step^2'] = train_df['step']**2\ntest_df['step^2']  = test_df['step']**2","cf5ec941":"features = train_df[['country','store','product','step','step^2']]\ntargets = train_df['num_sold'] ","9cd00071":"# split data\nX_train,X_val,y_train,y_val = train_test_split(features,targets,test_size=0.05,shuffle=False)\n","7f84020f":"model2 = LinearRegression()\nmodel2.fit(X_train, y_train)","d30aaac1":"smape(y_val,model2.predict(X_val))","d8c902fe":"Finland_0_1 = train_df[(train_df['country'] ==0) & (train_df['store']==0) & (train_df['product']==0)]","d79b4d82":"Finland_0_1.columns","38e8abac":"plt.plot(Finland_0_1.step,Finland_0_1.num_sold)\n","4ebc29f1":"features = Finland_0_1[['day_of_week',\n       'weekend', 'step', 'year', 'day', 'dayofyear', 'Quarter', 'week','week2',\n       'month', 'holiday_month','step^2','busiest' ]]\n                       \ntargets = Finland_0_1['num_sold']","550a15ef":"# split data\nX_train,X_val,y_train,y_val = train_test_split(features,targets,test_size=0.05,shuffle=False)","f2fffbc4":"model1 = LinearRegression()\nmodel1.fit(X_train, y_train)\npredictions = model1.predict(X_val)\nsmape(y_val,predictions)","9919b608":"plt.plot(X_val.index,y_val)\nplt.plot(X_val.index,predictions)\n","d79d7e0c":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\n\nxgb = xgb.XGBRegressor(n_estimators=1000)\nxgb.fit(X_train, y_train,\n        eval_set=[(X_train,y_train),(X_val, y_val)],\n        early_stopping_rounds=25,\n       verbose=False)","b4fb8190":"predictions = xgb.predict(X_val)\nplt.plot(X_val.index,predictions)\nplt.plot(X_val.index,y_val)\n","036e1739":"smape(y_val,predictions)","630644c4":"from matplotlib import pyplot\n# plot learning curves\nresults = xgb.evals_result()\nplt.figure(figsize=(10, 8))\npyplot.plot(results['validation_0']['rmse'], label='train')\npyplot.plot(results['validation_1']['rmse'], label='test')\n# show the legend\npyplot.legend()\nplt.xlabel('iterations')\nplt.ylabel('rmse')\n# show the plot\npyplot.show()","c83e090a":"train_df.columns","c5561e44":"#https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\/discussion\/302270\n# idea using log comes from this discussion.\n\nfeatures = train_df[['country','store','product','Quarter','day','month','year','week2','dayofyear','busiest','day_of_week','step','is_holiday','holiday_name','GDPperCapita','GrowthRate']]\n#holiday_month,step^2 \n\ntargets = train_df['num_sold']\n#targets = np.log(train_df['num_sold'])\n\n","17d01d90":"targets_log = np.log(targets)","450d30f5":"# split data\nX_train,X_val,y_train_log,y_val_log = train_test_split(features,targets_log,test_size=0.05,shuffle=False)\nX_train,X_val,y_train,y_val = train_test_split(features,targets,test_size=0.05,shuffle=False)","c1b6809e":"model1 = LinearRegression()\nmodel1.fit(X_train, y_train)\nsmape(y_val,model1.predict(X_val))","5b790082":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\n\nxgb = xgb.XGBRegressor(learning_rate=0.17)\nxgb.fit(X_train, y_train,\n        eval_set=[(X_train,y_train),(X_val, y_val)],\n        early_stopping_rounds=25,\n       verbose=False)\npredictions = xgb.predict(X_val)\nsmape(y_val,predictions)","1d52eed2":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\n\nxgb = xgb.XGBRegressor(learning_rate=0.17)\nxgb.fit(X_train, y_train_log,\n        eval_set=[(X_train,y_train_log),(X_val, y_val_log)],\n        early_stopping_rounds=25,\n       verbose=False)\npredictions = xgb.predict(X_val)\nsmape(np.exp(y_val_log),np.exp(predictions))","2ed72b3c":"plot_importance(xgb)","eca5709c":"results = xgb.evals_result()","3208754e":"from matplotlib import pyplot\n# plot learning curves\nplt.figure(figsize=(10, 8))\npyplot.plot(results['validation_0']['rmse'], label='train')\npyplot.plot(results['validation_1']['rmse'], label='test')\n# show the legend\npyplot.legend()\nplt.xlabel('iterations')\nplt.ylabel('rmse')\n# show the plot\npyplot.show()","0947df66":"from catboost import CatBoostRegressor\ncat = CatBoostRegressor(n_estimators=600)\ncat.fit(X_train,y_train_log,eval_set=(X_val,y_val_log),early_stopping_rounds=500,verbose=False)\nsmape(np.exp(y_val_log),np.exp(cat.predict(X_val)))","bb04ab81":"import lightgbm as lgb\nlgb = lgb.LGBMRegressor(n_estimators=1000,boosting_type='dart',learning_rate=0.2)\nlgb.fit(X_train, y_train)\nsmape(y_val,lgb.predict(X_val))","792b7b16":"import lightgbm as lgb\nlgb = lgb.LGBMRegressor(n_estimators=1000,boosting_type='dart',learning_rate=0.2)\nlgb.fit(X_train, y_train_log)\nsmape(np.exp(y_val_log),np.exp(lgb.predict(X_val)))","9c3f7314":"import xgboost as xgb\nxgb = xgb.XGBRegressor(learning_rate=0.17)\nxgb.fit(features,targets, verbose=False)","159463df":"import lightgbm as lgb\nlgb = lgb.LGBMRegressor(n_estimators=1000,boosting_type='dart',learning_rate=0.2)\nlgb.fit(features, targets)","5b9f7fda":"from catboost import CatBoostRegressor\ncat = CatBoostRegressor(n_estimators=600,verbose=False)\ncat.fit(features,targets_log)","156efe29":"predictions1 = xgb.predict(test_df[['country','store','product','day','month','year','week2','busiest','Quarter','dayofyear','day_of_week','step','is_holiday','holiday_name','GDPperCapita','GrowthRate']])\npredictions2 = cat.predict(test_df[['country','store','product','day','month','year','week2','busiest','Quarter','dayofyear','day_of_week','step','is_holiday','holiday_name','GDPperCapita','GrowthRate']])\npredictions3= lgb.predict(test_df[['country','store','product','day','month','year','week2','busiest','Quarter','dayofyear','day_of_week','step','is_holiday','holiday_name','GDPperCapita','GrowthRate']])","b6d2ec95":"predictions = (predictions1*0.33)+np.exp((predictions2*0.34))+(predictions3*0.33)","f93207a5":"predictions","b69ae687":"output = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\noutput['num_sold']= predictions\n\n#idea comes from https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022\/discussion\/299162\noutput['num_sold'] = output['num_sold'].apply(np.ceil)\noutput.to_csv('submission.csv',index =False)\n","5f9ea65a":"# Finland Graphs","a6828fb6":"# Insights from Finland\n\n* There are sales peaks every end of year for the three items. \n* Seasons affect Hat sales signigicantly and mug sales slightly. Sticker sales seems stable over the year.  \n* Three item sales seemed to be affected by the day of week.\n\n****************************************************************************************************","19cc97f9":"**********************************************************************","7343fe2e":"# Train on Full Train Data","2b108b83":"# Insight from Sweden\n\nSweden market has the same tendency of Finland.\n*****************************************************************","2da9569d":"# Top Sales Day","7b88832f":"* <font size =4>\n For each item, they sells well on the peak time. Hat also sells well in Spring time(August and May)    \n<\/font>","21ec4258":"# Load libraries","1b7b2129":"# Making Model and Predict","f150be1a":"# Making Submission file","21058a9d":"# Month affects the Sales?","308c25c7":"# Insight from Norway\n\nNorway market has the same tendency of Finland\n*****************************************************************","66837da0":"# Load Data","668623fd":"# Day of Week affects the Sales?","6d9e32a8":"* <font size =4>\n From 12\/27 to 1\/3 is the busiest season for the shops  \n<\/font>","81171fc4":"# Sweden Graphs","9c4d4ed2":"# Norway Graphs","1a665379":"# Explanatory Data Analysis and Preprocess","d98dbeea":"<font size =5 >More customers comes to the stores weekends. <\/font>\n************************************************************************","1be4775e":"# Three countires have the same tendency on their sales\n* There are sales peaks every end of year for the three items. \n* Seasons affect Hat sales signigicantly and mug sales slightly. Sticker sales seems stable over the year.  \n* Three item sales seemed to be affected by the day of week.\n\n****************************************************************************************************"}}