{"cell_type":{"87f38b94":"code","5d03b1fa":"code","3d88cba7":"code","23df9a20":"code","04ad72f8":"code","45e0ab66":"code","cd7afed3":"code","7b78918e":"code","059df934":"code","b0deea13":"code","7b2e3af5":"code","3d70f217":"code","a0c25675":"code","ca486dee":"code","c5b4fc2e":"code","bf634930":"code","b61290f7":"code","cc606902":"code","7bed7f00":"code","c0c605b3":"code","9c7c77c3":"code","5108051d":"code","a9ae0c88":"code","df55d439":"code","27ba0992":"code","5fc2e2d0":"code","93a536ba":"code","e59a4ec9":"code","2b96958e":"code","1bf84889":"code","43e15ba6":"code","7aec5994":"code","c2c62a5a":"code","8d320085":"code","426ecf29":"code","236fa3fc":"code","f902a458":"code","02132d56":"markdown"},"source":{"87f38b94":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV ,KFold, cross_val_score, train_test_split\nfrom sklearn.linear_model import ElasticNet, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MultiLabelBinarizer ,LabelEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nimport xgboost\nimport math\nimport ast\nfrom datetime import datetime\nimport calendar\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom scipy.special import boxcox1p\n","5d03b1fa":"train_data = pd.read_csv('\/kaggle\/input\/tmdb-box-office-prediction\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/tmdb-box-office-prediction\/test.csv')","3d88cba7":"train_data.head()","23df9a20":"test_data.head()","04ad72f8":"def nullColumns(train_data):\n    list_of_nullcolumns =[]\n    for column in train_data.columns:\n        total= train_data[column].isna().sum()\n        try:\n            if total !=0:\n                print('Total Na values is {0} for column {1}' .format(total, column))\n                list_of_nullcolumns.append(column)\n        except:\n            print(column,\"-----\",total)\n    print('\\n')\n    return list_of_nullcolumns\n\n\ndef percentMissingFeature(data):\n    data_na = (data.isnull().sum() \/ len(data)) * 100\n    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n    print(missing_data.head(20))\n    return data_na\n\n\ndef plotMissingFeature(data_na):\n    f, ax = plt.subplots(figsize=(15, 12))\n    plt.xticks(rotation='90')\n    if(data_na.empty ==False):\n        sns.barplot(x=data_na.index, y=data_na)\n        plt.xlabel('Features', fontsize=15)\n        plt.ylabel('Percent of missing values', fontsize=15)\n        plt.title('Percent missing data by feature', fontsize=15)\n\ndef extract_key_val(df,colname):\n    \n    for idx, row in df.iterrows():\n        \n        try:\n            y =ast.literal_eval(row[colname])  \n            z= []\n            for i in y:\n                z.append(i['name'])\n            df[colname][idx] = z\n        \n        except Exception as e:\n            print(idx ,e)\n    \n    return df\n","45e0ab66":"listOfNullColumns = nullColumns(train_data)","cd7afed3":"listOfNullColumns = nullColumns(test_data)","7b78918e":"test_data['revenue'] = 0\ncombined_data = pd.concat([train_data,test_data],axis =0)\ncombined_data = combined_data.reset_index(drop = True)\ncombined_data.head()","059df934":"target_column =combined_data.pop('revenue')[:3000]","b0deea13":"combined_data =combined_data.drop(columns=['belongs_to_collection','homepage','poster_path','id'],axis =1)","7b2e3af5":"def correct_year(df,colname):\n    \n    df[colname] = df[colname].apply(lambda x : (x-100) if x>2017 else x)\n    \n    return df","3d70f217":"def generate_date_features(calendar,colname):\n    \n    df = pd.DataFrame()\n    \n    df['Year'] = pd.to_datetime(calendar[colname]).dt.year\n\n    df['Month'] = pd.to_datetime(calendar[colname]).dt.month\n\n    df['Day'] = pd.to_datetime(calendar[colname]).dt.day\n\n    df['Dayofweek'] = pd.to_datetime(calendar[colname]).dt.dayofweek\n\n    df['DayOfyear'] = pd.to_datetime(calendar[colname]).dt.dayofyear\n\n    df['Week'] = pd.to_datetime(calendar[colname]).dt.week\n\n    df['Quarter'] = pd.to_datetime(calendar[colname]).dt.quarter \n\n    df['Is_month_start'] = pd.to_datetime(calendar[colname]).dt.is_month_start\n\n    df['Is_month_end'] = pd.to_datetime(calendar[colname]).dt.is_month_end\n\n    df['Is_quarter_start'] = pd.to_datetime(calendar[colname]).dt.is_quarter_start\n\n    df['Is_quarter_end'] = pd.to_datetime(calendar[colname]).dt.is_quarter_end\n\n    df['Is_year_start'] = pd.to_datetime(calendar[colname]).dt.is_year_start\n\n    #df['Is_year_end'] = pd.to_datetime(calendar[colname]).dt.is_year_end\n\n    df['Semester'] = np.where(df['Quarter'].isin([1,2]),1,2)\n\n    df['Is_weekend'] = np.where(df['Dayofweek'].isin([5,6]),1,0)\n\n    df['Is_weekday'] = np.where(df['Dayofweek'].isin([0,1,2,3,4]),1,0)\n\n    return df","a0c25675":"date_features = generate_date_features(combined_data,'release_date')\ndate_features = correct_year(date_features,'Year')","ca486dee":"date_features.head()","c5b4fc2e":"combined_data = pd.concat([date_features,combined_data],axis =1)","bf634930":"plt.figure(figsize =(20,20))\nplt.xticks(rotation='90')\nsns.pointplot(combined_data.loc[:3000,'Year'],target_column)","b61290f7":"plt.figure(figsize = (20,20))\nsns.barplot(combined_data.loc[:3000,'original_language'],target_column)","cc606902":"combined_data['genres'] = combined_data['genres'].fillna('[{\"id\": 9999, \"name\": \"unknown1\"}]')\n#train_data['production_companies'] = train_data['production_companies'].fillna('[{\"id\": 9999, \"name\": \"unknown2\"}]')\n#train_data['production_countries'] = train_data['production_countries'].fillna('[{\"iso_3166_1\": \"unknown3\", \"name\": \"unknown4\"}]')\n#train_data['spoken_languages'] = train_data['spoken_languages'].fillna('[{\"iso_639_1\": \"unknown5\", \"name\": \"unknown6\"}]')\n#train_data['Keywords'] = train_data['Keywords'].fillna('[{\"id\": \"unknown7\", \"name\": \"unknown8\"}]')\n#train_data['cast'] = train_data['cast'].fillna('[{\"cast_id\": \"unknown9\", \"name\": \"unknown10\"}]')\n#train_data['runtime'] =train_data['runtime'].fillna(train_data['runtime'].mean())","7bed7f00":"df = extract_key_val(combined_data,'genres')\n#extract_vals(train_data,'production_companies')\n#extract_vals(train_data,'production_countries')\n#extract_vals(train_data,'spoken_languages')\n#extract_vals(train_data,'Keywords')\n#extract_vals(train_data,'cast')","c0c605b3":"df.head(5)","9c7c77c3":"plt.figure(figsize = (20,20))\nsns.distplot(target_column)","5108051d":"target_column = np.log1p(target_column[:3000])","a9ae0c88":"plt.figure(figsize = (20,20))\nsns.distplot(target_column)","df55d439":"#lb = LabelEncoder()\n#df['original_language'] = lb.fit_transform(df['original_language'])\nmlb = MultiLabelBinarizer()\n#df['original_language'] = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"original_language\"]),columns=mlb.classes_, index=df.index)],axis =1)\ndf = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"genres\"]),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"production_companies\"]),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"production_countries\"]),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"Keywords\"].apply(lambda x :x[0:1])),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"cast\"].apply(lambda x : x[0:2])),columns=mlb.classes_, index=df.index)],axis =1)","27ba0992":"df['count_genres'] = df['genres'].apply(lambda x : len(x))\n#df['noofPrCom'] = df[\"production_companies\"].apply(lambda x : len(x))\n#df['noofPrCou'] = df[\"production_countries\"].apply(lambda x : len(x))\n#df['noofkey'] = df[\"Keywords\"].apply(lambda x : len(x))\n#df['noofcast'] = df[\"cast\"].apply(lambda x : len(x))\n#df['noofspokenlang'] =df[\"spoken_languages\"].apply(lambda x : len(x))\n#df['sequel'] = mlb.fit_transform(df[\"Keywords\"])[:,5869]","5fc2e2d0":"for col in df.columns:\n    if df.dtypes[col] != 'O':\n        #print(col)\n        df[col] =boxcox1p(df[col],0.15)","93a536ba":"df = df.drop(columns = ['release_date'\n                                ,'imdb_id'\n                                ,'title'\n                                ,'overview'\n                                ,'production_companies'\n                                ,'production_countries'\n                                ,'spoken_languages'\n                                ,'status'\n                                ,'tagline'\n                                ,'title'\n                                ,'cast'\n                                ,'crew'\n                                ,'Keywords'\n                                ,'original_language'\n                                ,'genres'\n                                ,'original_title'\n                                ,'TV Movie'\n                                ,'unknown1'\n                               ])","e59a4ec9":"df.head()","2b96958e":"X_train,X_val,y_train,y_val = train_test_split(df.iloc[:3000,:],target_column,test_size =0.2,random_state = 1001)","1bf84889":"def RMSLE(y, y_pred):     \n    assert len(y) == len(y_pred)\n    terms_to_sum = []\n    for p , a in zip(y_pred,y):\n        terms_to_sum.append((math.log(p + 1) - math.log(a + 1)) ** 2.0)\n    \n    return 'RMSLE',(sum(terms_to_sum) * (1.0\/len(y))) ** 0.5, False","43e15ba6":"def feature_importance(model, X_train=X_train):\n\n    print(model.feature_importances_)\n    names = X_train.columns.values\n    ticks = [i for i in range(len(names))]\n    plt.bar(ticks, model.feature_importances_)\n    plt.xticks(ticks, names,rotation =90)\n    plt.show()","7aec5994":"def create_submission_file(model_list):\n    preds = 0\n    submission = pd.read_csv('..\/input\/tmdb-box-office-prediction\/sample_submission.csv')\n    for model in model_list:\n        preds = preds + np.expm1(model.predict(df.iloc[3000:,:]))\n    submission.loc[:,'revenue'] = preds\/len(model_list)\n    !rm '.\/submission.csv'\n    submission.to_csv('submission.csv', index = False, header = True)\n    print(submission.head())\n        ","c2c62a5a":"model_xgb = xgboost.XGBRegressor(colsample_bytree=0.4, gamma=0.045, \n                             learning_rate=0.1, max_depth=6, \n                             min_child_weight=1.7817, n_estimators=1000,\n                             reg_alpha=0.45, reg_lambda=0.8,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1,seed=42)\n\nmodel_xgb.fit(X_train,y_train,eval_set=[(X_train, y_train), (X_val, y_val)],\n        eval_metric='rmsle',\n        early_stopping_rounds = 50,\n        verbose=2)\n","8d320085":"plt.figure(figsize =(20,20))\nfeature_importance(model_xgb)","426ecf29":"model_lgb = lgb.LGBMRegressor(bagging_fraction=0.8, bagging_frequency=4, boosting_type='gbdt',\n              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n              importance_type='split', learning_rate=0.1, max_depth=3,\n              min_child_samples=20, min_child_weight=30, min_data_in_leaf=70,\n              min_split_gain=0.0001, n_estimators=200, n_jobs=-1,\n              num_leaves=1200, objective='regression' ,random_state=101, reg_alpha=0.2,\n              reg_lambda=0.6, silent=True, subsample=1.0,\n              subsample_for_bin=200000, subsample_freq=0)\n\nmodel_lgb.fit(X_train, y_train,eval_set=[(X_train, y_train), (X_val, y_val)],\n        eval_metric=RMSLE,\n        early_stopping_rounds = 100,\n        verbose=2)","236fa3fc":"plt.figure(figsize =(20,20))\nfeature_importance(model_xgb)","f902a458":"create_submission_file([model_lgb,model_xgb])","02132d56":"# LightGBM Model"}}