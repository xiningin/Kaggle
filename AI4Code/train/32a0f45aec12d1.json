{"cell_type":{"aa163a53":"code","a4a32101":"code","3256a416":"code","da7cf047":"code","f3d92909":"code","e8ad4893":"code","38f9d205":"code","0fb9b4df":"code","097b722e":"code","673bec06":"code","b1416b16":"code","15f22ab8":"code","5809d350":"code","d49a21bd":"code","91aa57d1":"code","57750195":"code","7257859e":"code","9f6b5d59":"code","d145835f":"markdown","73a307fc":"markdown"},"source":{"aa163a53":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a4a32101":"import numpy\nimport pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, BatchNormalization\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n","3256a416":"# load train dataset\ntrainDataFrame = pandas.read_csv(\"..\/input\/trainSimple.csv\")\ntrainDataFrame.describe()\n\n\n","da7cf047":"# split into input (X) and output (Y) variables\nX = trainDataFrame.iloc[:,0:6]\ny = trainDataFrame.iloc[:,6:8]\n\nprint(X.head())\nprint(y.head())\nX=X.values\ny=y.values","f3d92909":"# create training and validation sets\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.1, random_state=1)\nprint (X_train.shape, y_train.shape)\nprint (X_validation.shape, y_validation.shape)","e8ad4893":"# load test dataset\ntestDataFrame = pandas.read_csv(\"..\/input\/testSimple.csv\")\ntestDataFrame.describe()\n","38f9d205":"# remove ID column for converting to input (X)\nXtest = testDataFrame.iloc[:,1:8]\n\n\nprint(Xtest.head())\n\nXtest= Xtest.values","0fb9b4df":"def showHistory(history):\n    # list all data in history\n    print(history.history.keys())\n    # summarize history for accuracy\n    plt.plot(history.history['mean_absolute_error'])\n    plt.plot(history.history['val_mean_absolute_error'])\n    plt.title('model accuracy')\n    plt.ylabel('mae')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    ","097b722e":"def transformData ( X_train, X_validation, y_train, y_validation, Xtest):\n    #Normalize data\n    global scalarX, scalarY \n    scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n    #scalarX, scalarY = RobustScaler(), RobustScaler()\n    #scalarX, scalarY = StandardScaler(), StandardScaler()\n    \n    \n    X_train, X_validation, y_train, y_validation\n    \n    scalarX.fit(X_train)\n    scalarY.fit(y_train)\n    X_train = scalarX.transform(X_train)\n    y_train = scalarY.transform(y_train)\n    \n    X_validation = scalarX.transform(X_validation)\n    y_validation = scalarY.transform(y_validation)\n        \n    Xtest = scalarX.transform(Xtest)\n    \n    return X_train, X_validation, y_train, y_validation,Xtest","673bec06":"def inverseTransformData (ytest):\n    ytest= scalarY.inverse_transform(ytest)\n    return ytest\n    ","b1416b16":"def createModel(input,output):\n    # define and fit the final model\n    model = Sequential()\n    model.add(Dense(input.shape[1], input_dim=6, activation='relu'))\n    model.add(Dense(1024, use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Dense(512, use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(8, activation='relu'))\n    model.add(Dense(output.shape[1], activation='linear'))\n    model.compile(loss='MSE', optimizer='adam', metrics=['mae'])\n\n    model.summary()\n    return model\n\n","15f22ab8":"def fitPredict(model, X_train, X_validation, y_train, y_validation,Xtest):\n    \n    #history = model.fit(X_train, y_train, epochs=100, verbose=1, validation_split=0.10, batch_size=25)\n    history = model.fit(X_train, y_train, epochs=100, verbose=1, validation_data=(X_validation,y_validation), batch_size=25)\n    \n     \n    \n    # make a prediction\n    ytest = model.predict(Xtest)\n    \n    \n    \n    \n        \n    return ytest , history","5809d350":"a=[[0.0002,0.0000004],\n   [4.9,-2000],\n   [5,50000000]]\n\n\nscalarA= RobustScaler()\n#RobustScaler() StandardScaler() MinMaxScaler\n    \nscalarA.fit(a)\naNew = scalarA.transform(a)\nprint(a)\nprint( aNew)\n\nv= pd.DataFrame(aNew)\nprint(v.describe())\nv.head()\n\naInv = scalarA.inverse_transform(aNew)\nprint( aInv)","d49a21bd":"\n\nX_train, X_validation, y_train, y_validation,Xtest = transformData(X_train, X_validation, y_train, y_validation,Xtest)\n\n\nmodel = createModel(X_train,y_train)\npredictions, trainingHistory = fitPredict(model,X_train, X_validation, y_train, y_validation,Xtest)\npredictions = inverseTransformData(predictions)\n","91aa57d1":"showHistory(trainingHistory)\n","57750195":"predictions","7257859e":"a= predictions[:,0]\nb = predictions[:,1]\n","9f6b5d59":"my_submission = pd.DataFrame({ 'ID': testDataFrame.ID,'A': a, 'B': b})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\nmy_submission.head()","d145835f":"The below code is modified version of the  below link:\nhttps:\/\/machinelearningmastery.com\/regression-tutorial-keras-deep-learning-library-python\/\n[](https:\/\/machinelearningmastery.com\/regression-tutorial-keras-deep-learning-library-python\/\/)","73a307fc":"Everything runs smoothly, but the problem is you can't see your file anywhere in this page, nor in your Profile, Kernels tab, nowhere! This is because you haven't commited your notebook yet. To do that, click the **Commit **button - as I write it, this is a light-blue button in the top-right corner of my notebook page, in the main pane. (There is also a right pane with Sessions, Versions etc. You can ignore it for now). It may take a minute for the Kaggle server to publish your notebook.\n\nWhen this operation is done, you can go back by clicking '<<' button in the top-left corner. Then you should see your notebook with **a menu  bar on the left**  that has a few tabs: Notebook, Code, Data, **Output**, Comments, Log ... Edit Notebook. Click the **Output** tab. You should see your output csv file there, ready to download! **R\u0130ght Upper corne**r you will see \"**Submit to competiton**\" button. Click it!"}}