{"cell_type":{"4a0516fc":"code","0c8f6e8d":"code","51b79da6":"code","96e11243":"code","80fa94b6":"code","cdfe96be":"code","c8732677":"code","df067e68":"code","f724b2c4":"code","ce4c3800":"code","3f41da41":"code","f78019a7":"code","34771b8a":"code","868d0506":"code","4fd84ac7":"code","2b2326e0":"code","2cb53e48":"markdown","5786807a":"markdown","3652f8d6":"markdown","35345647":"markdown","32a3e268":"markdown","a3a616c2":"markdown","6effcca3":"markdown","3bd585b7":"markdown","30283301":"markdown","d9ac00c4":"markdown","e27c90fb":"markdown","38aee7ec":"markdown","e69c24f0":"markdown","55f48db2":"markdown"},"source":{"4a0516fc":"import numpy as np #For linear algebra maths\nimport pandas as pd #For data manipulation\nfrom keras.models import Sequential #For DL\nfrom keras.layers import LSTM, Dense, Dropout #For DL\nimport matplotlib.pyplot as plt #For plotting","0c8f6e8d":"hist_len = 10","51b79da6":"data = pd.read_csv(\"..\/input\/avocado.csv\")\ndata.head()","96e11243":"data = data.drop(['Unnamed: 0','Date','Total Volume','4046','4225','4770','Total Bags','Small Bags','Large Bags','XLarge Bags','type','year','region'],1)","80fa94b6":"data = data.T\ndata = data.values","cdfe96be":"data = data[0]\nscale_min = min(data)\nscale_range = max(data) - scale_min\ndata = (data-scale_min)\/(scale_range)","c8732677":"def make_feed_dicts(data,hist_len):\n    xs,ys = [],[]\n    for i in range(len(data)-hist_len-1):\n        ys.append(data[i+hist_len])\n        xs.append(data[i:i+hist_len])\n    j = int(len(data)*0.9)\n    return np.array(xs[:j]),np.array(xs[j:]),np.array(ys[:j]),np.array(ys[j:])","df067e68":"x_train, x_test, y_train, y_test = make_feed_dicts(data,hist_len)\nx_test.shape","f724b2c4":"x_train = x_train.reshape((x_train.shape[0],x_train.shape[1],1))\nx_test = x_test.reshape((x_test.shape[0],x_test.shape[1],1))","ce4c3800":"x_test.shape","3f41da41":"model = Sequential()\nmodel.add(LSTM(256,input_shape=(hist_len,1)))\nmodel.add(Dense(5))\n#model.add(Dropout(0.1))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')","f78019a7":"model.summary()","34771b8a":"history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test),shuffle=False)","868d0506":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","4fd84ac7":"predicted_x = model.predict(x_test[:250])\nplt.plot(predicted_x*scale_range+scale_min)\nplt.plot(y_test[:250].reshape(-1,1)*scale_range+scale_min)","2b2326e0":"step = np.array([x_test[0]])\n\n\n\ndef take_step(step):\n    next_step = model.predict(step)\n    next_step = next_step.reshape(1,1,1)\n    next_step = np.concatenate(([step[0][1:]],next_step),axis=1)\n    return next_step, next_step[0][0][0]\n    \n    \ntrendline = []\nfor _ in range(100):\n    step, value = take_step(step)\n    trendline.append(value)\n    \nplt.plot(trendline)\nplt.plot(y_test[7:100])","2cb53e48":"## Loss and Validation Loss Graphs","5786807a":" Load data from file, then show the beginning to get a feel for the layout of the data.","3652f8d6":"Change the matrix structure slightly, Ex.: [[1,2,3,4....]] to [1,2,3,4....].\n\nNormalise data.","35345647":"Function that constructs each x vector. Then creates lists of each x input and the corresponding y output.\nEx.:      a_list = [1,2,3,4,5,6,7,8,9,10,11,12,13] with a hist_len of 3, the lists created are as:\n\n   xs = [[1,2,3],   and ys = [4,\n           [2,3,4],                    5,\n           [3,4,5],                    6,\n               .....]                     ...]\n               \n so for [1,2,3] the network needs to predict 4. \n \n Then split both lists into training and validation sets. With the last ~10% being used as validation data.","32a3e268":"## Settings","a3a616c2":" Drop all of the unneeded columns, we will only use Average Price","6effcca3":"## Building Model","3bd585b7":"Turn single column to single row with .T\nSo:\n    1        \n    2             =====>         1    2    3   4\n    3           becomes\n    4\n    \n Then turn pandas dataFrame into array.","30283301":"## Preprocessing","d9ac00c4":"Now lets predict forward:","e27c90fb":"## Training","38aee7ec":"## Importing necessary modules","e69c24f0":"Reshape data for the last time.","55f48db2":"Lets see how well the trained model agrees with the actual validation data."}}