{"cell_type":{"43ba18c0":"code","fc9af661":"code","fbadbe15":"code","d6209bd0":"code","8a2fc426":"code","0fdf9a33":"code","817bf46d":"code","93341f1d":"code","92a82da1":"code","9a807077":"code","8bfd411a":"code","17e674a6":"code","d413ae9f":"code","1c436f13":"code","ce93341a":"code","cf8bb690":"code","293e00a2":"code","275030df":"code","479cb051":"code","fce9dc88":"code","6f55d16f":"code","5b4f73ea":"code","89920899":"code","1af84c29":"code","92e70817":"code","4501a3a5":"code","a69e8c6a":"code","6d5f3798":"code","ed937231":"code","7a40a391":"code","2d7c82c0":"markdown","ba9490ba":"markdown","56d37e77":"markdown","bb72bee1":"markdown","e7438ece":"markdown","5aa92c6c":"markdown","3564aeb4":"markdown","e287ca28":"markdown","12bbd86a":"markdown","85341adc":"markdown","648e2111":"markdown","4a7d4ea9":"markdown","18410de2":"markdown","1ef3c5cb":"markdown","3554c853":"markdown","fdba64ab":"markdown","5480868b":"markdown","eb7beb51":"markdown","9fd5c776":"markdown","1c91e77f":"markdown"},"source":{"43ba18c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc9af661":"whole_dataset = pd.read_csv(\"\/kaggle\/input\/twitter-user-gender-classification\/gender-classifier-DFE-791531.csv\", encoding = \"latin1\")","fbadbe15":"dataset = pd.concat([whole_dataset.gender, whole_dataset.description], axis = 1)","d6209bd0":"dataset.head(20)","8a2fc426":"dataset = dataset.dropna()","0fdf9a33":"dataset.head(20)","817bf46d":"dataset.gender = [1 if person == \"female\" else 0 for person in dataset.gender]","93341f1d":"dataset.head(10)","92a82da1":"import re","9a807077":"first_description = dataset.description[4]\nfirst_description","8bfd411a":"first_description = re.sub(\"[^a-zA-z]\", \" \",first_description)\nfirst_description","17e674a6":"first_description = first_description.lower()\nfirst_description","d413ae9f":"import nltk # natural language took kit\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords","1c436f13":"first_description = nltk.word_tokenize(first_description)\nfirst_description","ce93341a":"first_description = [word for word in first_description if not word in set(stopwords.words(\"english\"))]","cf8bb690":"first_description","293e00a2":"import nltk as nlp\n\nlemma = nlp.WordNetLemmatizer()\nfirst_description = [lemma.lemmatize(i) for i in first_description]","275030df":"first_description","479cb051":"first_description = \" \".join(first_description)","fce9dc88":"first_description","6f55d16f":"description_list = []\nfor description in dataset.description:\n    description = re.sub(\"[^a-zA-z]\", \" \",description)\n    description = description.lower()\n    description = nltk.word_tokenize(description)\n    description = [word for word in description if not word in set(stopwords.words(\"english\"))]\n    lemma = nlp.WordNetLemmatizer()\n    description = [lemma.lemmatize(i) for i in description]\n    description = \" \".join(description)\n    description_list.append(description)","5b4f73ea":"from sklearn.feature_extraction.text import CountVectorizer\n\nmax_features = 5000\ncount_vectorizer = CountVectorizer(max_features = max_features, stop_words = \"english\")","89920899":"sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()","1af84c29":"print(\"5000 most common words: \", count_vectorizer.get_feature_names())","92e70817":"x = sparce_matrix","4501a3a5":"x","a69e8c6a":"y = dataset.iloc[:,0].values\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)","6d5f3798":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x_train, y_train)","ed937231":"predictions = nb.predict(x_test)","7a40a391":"print(\"Accuracy: \", nb.score(predictions.reshape(-1,1), y_test))","2d7c82c0":"Using Regular Expression Library, I deleted \":)\" symbol.","ba9490ba":"Also, in computer language, \"BAND\" and \"band\" words are understood differently. So I am going to convert all letters into lowercase. ","56d37e77":"I am going to split my descriptions one by one then check them if it is a stop word or not.","bb72bee1":"Some words have changed: chiefs -> chief, memories -> memory","e7438ece":"Now, I am going to make a sentence using these words.","5aa92c6c":"Natural language processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.\n\nIn this tutorial, I am going to implement Natural Language Process to understand whether the post written on Twitter is written by a man or woman.","3564aeb4":"We are going to use gender and description columns. Let's concat them.","e287ca28":"I have showed you how to claen dataset with using only one sentence. But we should implement this method for whole dataset. Let'S do it together. We need only a for loop:","12bbd86a":"The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.","85341adc":"# Natural Language Processing for Twitter User Gender Classification","648e2111":"Now, I am going to clean my data with using Regular Expression library.(Regular Expression Library is using for searching a pattern)","4a7d4ea9":"Let's import dataset:","18410de2":"![](https:\/\/enterprisetalk.com\/wp-content\/uploads\/2020\/05\/IBM-Integrates-Watson-Platform-in-Project-Debater-NLP-Technology.jpg)","1ef3c5cb":"In order to classify our data, we need to get rid of string values.\n\nfemale -> 1   male -> 0","3554c853":"Let's implement Naive Bayes Method for the Machine Learning part to make predictions.","fdba64ab":"As you can see, we have some missing values (NaN). Let's delete this missing rows.","5480868b":"CountVectoizer:\n\n![](https:\/\/iksinc.files.wordpress.com\/2019\/12\/screen-shot-2019-12-11-at-9.47.32-pm.png?w=1100)","eb7beb51":"This part, I am going to find root of letters (lemmatization) in order to do classification.","9fd5c776":"Using word_tokenize method instead of split is more beneficial. Because, for example if you have a word like \"shouldn't\". split method cannot divide it into two parts but word_tokenize divide it into two parts : should and n't. ","1c91e77f":"In this part, I am going to clean all irrelavent words. For example, if we have a sentence like: \"I go to the school every day.\" we don't need some words (\"the\", \"to\" etc.) while classifying if a sentence was written by a male or female. I am going to get rid of them."}}