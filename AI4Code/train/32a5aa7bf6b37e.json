{"cell_type":{"8f9ac287":"code","e891351a":"code","63a1ccd7":"code","6f7e2db6":"code","3d360761":"code","46e0b079":"code","1bbf6933":"code","3eac792e":"code","02091ac3":"code","d4c52876":"code","46beea66":"code","e31c2f0d":"code","e8c4185f":"code","bda4c2e8":"code","443edf73":"code","e43cc231":"code","23eb7cda":"code","7f8c4c46":"code","57159ea1":"code","f375bd40":"code","1b1bd8c2":"code","ab20ccc6":"code","f01f73f8":"code","d0ddaeab":"code","673113da":"code","1a7598c1":"code","16c0ef92":"code","3ab5ca0e":"code","e8ccff50":"code","36e0e3f1":"code","8ffcc731":"code","4994510c":"code","6e908d36":"code","8351fcdf":"code","40083a2f":"code","37512da2":"code","de44ebd5":"code","f2a98f83":"code","a1f56768":"code","429fd4ed":"code","5bf56a1e":"code","98fd7550":"code","affde3f6":"code","27ff9e3a":"code","93f46c7e":"code","6f5b5d3a":"code","b1560cf1":"code","e00d9eeb":"code","154acfe0":"code","30b60ee4":"code","5510b2aa":"code","f5692c09":"code","98f1d874":"code","4d781676":"code","6cfdd132":"markdown","d6c24588":"markdown","82b9a837":"markdown","f11c49e0":"markdown","1cc77eef":"markdown","68270594":"markdown","2dfcfa46":"markdown","3c420aae":"markdown","b5c2ae25":"markdown","5f93d26b":"markdown","fc88e9db":"markdown","de57d1a4":"markdown","4ad0d7bb":"markdown","8e07bedf":"markdown","b81892bf":"markdown","1aba6211":"markdown","60d6ed0a":"markdown","2cc181ba":"markdown","44bc97e3":"markdown","9cffb053":"markdown"},"source":{"8f9ac287":"import numpy as np\nimport pandas as pd\nimport datetime as dt\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e891351a":"item_categories=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\n\nitems=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\n\ndateparse = lambda x: pd.datetime.strptime(x, '%d.%m.%Y')\nsales_train=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv', \\\n                        parse_dates=['date'],date_parser=dateparse)\n\nsample_submission=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\n\nshops=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\n\ntest=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv').set_index('ID')","63a1ccd7":"train=sales_train.join(items, on='item_id', rsuffix='_') \\\n                 .join(item_categories, on='item_category_id', rsuffix='_') \\\n                 .drop(['item_id_','item_category_id_','item_name', 'item_category_name'], axis=1)","6f7e2db6":"train.head(2)","3d360761":"train.shape","46e0b079":"test.head(2)","1bbf6933":"shops","3eac792e":"train.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id==0, 'shop_id']=57\ntrain.loc[train.shop_id==1, 'shop_id']=58\ntest.loc[test.shop_id==1, 'shop_id']=58\ntrain.loc[train.shop_id==10, 'shop_id']=11\ntest.loc[test.shop_id==10, 'shop_id']=11","02091ac3":"train.describe()","d4c52876":"train=train[train.item_price>0]","46beea66":"train['year']=pd.DatetimeIndex(train.date).year\ntrain['month']=pd.DatetimeIndex(train.date).month","e31c2f0d":"train.isnull().sum()","e8c4185f":"train.dtypes","bda4c2e8":"plt.figure(figsize=(12,5))\nsns.boxplot(train.item_price.values)\nplt.title('Item Price', fontsize=15)","443edf73":"train=train[train.item_price<100000]","e43cc231":"plt.figure(figsize=(12,5))\nsns.boxplot(train.item_price.values)\nplt.title('Item Price after outliers cut', fontsize=15)","23eb7cda":"plt.figure(figsize=(12,5))\nsns.boxplot(train.item_cnt_day.values)\nplt.title('Number of products sold', fontsize=15)\nplt.xlabel('Products', fontsize=10)","7f8c4c46":"train=train[train.item_cnt_day<999]","57159ea1":"plt.figure(figsize=(12,5))\nsns.boxplot(train.item_cnt_day.values)\nplt.title('Number of products sold', fontsize=15)\nplt.xlabel('Products after outliers cut', fontsize=10)","f375bd40":"plt.figure(figsize=(15,5))\nsns.lineplot(data=train, x='month', y='item_cnt_day', style='year')\nplt.title('Number of products sold in month', fontsize=15)","1b1bd8c2":"train_calendar=train[['date','item_cnt_day']]\ntrain_calendar.set_index('date', inplace=True)\ntrain_calendar=train_calendar.resample('W')['item_cnt_day'].sum()","ab20ccc6":"plt.figure(figsize=(10,5))\nsns.lineplot(data=train_calendar)\nplt.title('Weekly sales',fontsize=15 )\nplt.xlabel('Year',fontsize=10)\nplt.ylabel('Sales per day', fontsize=10)","f01f73f8":"train_sold=train.groupby('shop_id',as_index=False).agg({'item_cnt_day':'sum','item_price':'sum'}) \\\n                .rename(columns={'item_cnt_day':'total_items_sold', 'item_price': 'total_money' }) \\\n                .sort_values('total_items_sold', ascending=False).reset_index(drop=True)","d0ddaeab":"plt.figure(figsize=(15,5))\nsns.barplot(x=train_sold.shop_id, y=train_sold.total_items_sold ,data= train_sold, order= train_sold.shop_id)\nplt.title('Most popular shop', fontsize=15)\nplt.ylabel('Items sold', fontsize=10)\nplt.xlabel('Shop ID', fontsize=10)","673113da":"train_sold=train_sold.sort_values('total_money', ascending=False).reset_index(drop=True)\nplt.figure(figsize=(15,5))\nsns.barplot(x=train_sold.shop_id, y=train_sold.total_money, order= train_sold.shop_id)\nplt.title('Sales proceeds', fontsize=15)\nplt.ylabel('Money', fontsize=10)\nplt.xlabel('Shop ID', fontsize=10)","1a7598c1":"train_items_sold=train.groupby('shop_id',as_index=False) \\\n                      .agg({'item_id':'count'}) \\\n                      .rename(columns={'item_id':'items_sold'})\\\n                      .sort_values('items_sold', ascending=False).reset_index(drop=True)","16c0ef92":"plt.figure(figsize=(15,5))\nsns.barplot(x=train_items_sold.shop_id, y=train_items_sold.items_sold, order= train_items_sold.shop_id)\nplt.title('Items sold ', fontsize=15)\nplt.ylabel('Items', fontsize=10)\nplt.xlabel('Shop ID', fontsize=10)","3ab5ca0e":"train_categ=train.groupby('item_category_id', as_index=False) \\\n                 .agg({'item_cnt_day':'count', 'item_id':'nunique'}) \\\n                 .rename(columns={'item_cnt_day':'items_sold', 'item_id':'assortment_items'}) \\\n                 .sort_values('items_sold',ascending=False) \\\n                 .reset_index(drop=True)","e8ccff50":"plt.figure(figsize=(18,5))\nsns.barplot(x='item_category_id', y='items_sold', data=train_categ, palette=\"pastel\", order=train_categ.item_category_id)\nplt.title('most popular category ', fontsize=15)\nplt.ylabel('Items sold', fontsize=10)\nplt.xlabel('Category', fontsize=10)","36e0e3f1":"train_df=train.drop(['date', 'item_price','item_category_id'], axis=1)","8ffcc731":"feature= [c for c in train_df.columns if c not in ['item_cnt_day']]","4994510c":"train_df = train_df.groupby(feature, as_index=False) \\\n                   .agg({'item_cnt_day':'sum'}) \\\n                   .rename(columns={'item_cnt_day':'item_cnt_month'})","6e908d36":"shop_item_monthly_mean = train_df[['shop_id', 'item_id', 'item_cnt_month']] \\\n                        .groupby(['shop_id', 'item_id'], as_index=False) \\\n                        .agg({'item_cnt_month': 'mean'}) \\\n                        .rename(columns={'item_cnt_month':'item_cnt_month_mean'})","8351fcdf":"train_df = pd.merge(train_df, shop_item_monthly_mean, how='left', on=['shop_id', 'item_id'])\ntrain_df.head()","40083a2f":"shop_item_prev_month = train_df[train_df['date_block_num'] == 33][['shop_id', 'item_id', 'item_cnt_month']] \\\n                        .rename(columns={'item_cnt_month':'item_cnt_prev_month'})\nshop_item_prev_month.head()","37512da2":"train_df = pd.merge(train_df, shop_item_prev_month, how='left', on=['shop_id', 'item_id'])\ntrain_df.head()","de44ebd5":"train_df = train_df.fillna(0.)\ntrain_df.head()","f2a98f83":"test['month'] = 11\ntest['year'] = 2015\ntest['date_block_num'] = 34\ntest.head()","a1f56768":"test_df = pd.merge(test, shop_item_monthly_mean, how='left', on=['shop_id', 'item_id'])\n","429fd4ed":"test_df = pd.merge(test_df, shop_item_prev_month, how='left', on=['shop_id', 'item_id'])\ntest_df.head()","5bf56a1e":"test_df = test_df.fillna(0.)\ntest_df.head()","98fd7550":"feature_list = [c for c in train_df.columns if c not in 'item_cnt_month']\nX_train = train_df[train_df['date_block_num'] < 33]\ny_train = np.log1p(X_train['item_cnt_month'].clip(0., 20.))\nX_train = X_train[feature_list]\nX_val = train_df[train_df['date_block_num'] == 33]\ny_val = np.log1p(X_val['item_cnt_month'].clip(0., 20.))\nX_val = X_val[feature_list]\nX_test=test_df[feature_list]","affde3f6":"# rf_model=RandomForestRegressor(random_state=42, n_jobs=-1, verbose=1)\n# params={'n_estimators':np.arange(100,500,50), 'max_depth':np.arange(10,50,10), \\\n#         'min_samples_s,1plit': np.arange(2,8)}\n# rand_cv=RandomizedSearchCV(rf_model, params, n_iter=3, scoring= 'neg_mean_squared_error')\n# rand_cv.fit(X_train,y_train)\n# best_model=rand_cv.best_estimator_\n# score=best_model.score(X_val, y_val)\n# rmse=np.sqrt(score)\n# y_test=best_model.predict(X_test).clip(0., 20.)\n# print('best params', rand_cv.best_params_)\n","27ff9e3a":"# params={'n_estimators':[20,30,50,100, 400], 'max_depth':[ 20, 30, 50, 100], \\\n#         'min_samples_split': [2, 4, 6] }\n# grid_model=GridSearchCV(rf_reg, params, cv= 3, shuffle= True)\n\n# grid_model.fit(X_train, y_train)\n\n# grid_model.best_params_","93f46c7e":"# rnd=RandomForestRegressor(n_estimators=400, max_depth= 20, min_samples_split=6, \\\n#                           random_state=42, n_jobs=-1, verbose=1)","6f5b5d3a":"# t=dt.datetime.now()\n# rnd.fit(X_train, y_train)\n# print(dt.datetime.now() - t)","b1560cf1":"# rnd.score(X_val, y_val)","e00d9eeb":"# y_pred=rnd.predict(X_val)\n# MSE=mean_squared_error(y_val, y_pred)\n# rmse=np.sqrt(MSE)\n# print('MSE:', MSE)\n# print('RMSE:',rmse)","154acfe0":"model=XGBRegressor()\nparams={'learning_rate':[0.05, 0.1, 0.16],\n       'max_depth':[10,30,50],\n       'min_child_weight':[1,3,6],\n       'n_estimators':[200, 300, 400]}\nxgb_grid=GridSearchCV(model, params, n_jobs=1, verbose=1, cv=3)","30b60ee4":"%time\nxgb_grid.fit(X_train, y_train)","5510b2aa":"xgb_grid.best_estimator_","f5692c09":"xgb_grid.best_params_","98f1d874":"y_test=rnd.predict(X_test).clip(0., 20.)","4d781676":"submission=pd.DataFrame({'ID': X_test.index,'item_cnt_month':y_test})\nsubmission.to_csv('rnd_submission.csv', index=False)","6cfdd132":"## Data fields\n\nID - an Id that represents a (Shop, Item) tuple within the test set\n\nshop_id - unique identifier of a shop\n\nitem_id - unique identifier of a product\n\nitem_category_id - unique identifier of item category\n\nitem_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n\nitem_price - current price of an item\n\ndate - date in format dd\/mm\/yyyy\n\ndate_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n\nitem_name - name of item\n\nshop_name - name of shop\n\nitem_category_name - name of item category","d6c24588":"Missing values","82b9a837":"What category sales more?","f11c49e0":"Minimal item price is negative number. We need to remove all negative and zero values in price","1cc77eef":"## Data cleaning","68270594":"\nsales proceeds","2dfcfa46":"## Modelling","3c420aae":"## Preprocessing","b5c2ae25":"Let's year, month and consecutive month number to test data frame","5f93d26b":"sold products","fc88e9db":"We can see that several shops duplicates of each other. I need to get rid of duplicate values in the data.","de57d1a4":"\ntarget variable - price","4ad0d7bb":"## Loading data","8e07bedf":"most popular shop \/ item \/ sales","b81892bf":"let's add year and month colomn","1aba6211":"## File descriptions\n\nsales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n\ntest.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n\nsample_submission.csv - a sample submission file in the correct format.\n\nitems.csv - supplemental information about the items\/products.\n\nitem_categories.csv - supplemental information about the items categories.\n\nshops.csv- supplemental information about the shops.","60d6ed0a":"## Data analys","2cc181ba":"Validation hold out month is 33","44bc97e3":"## Imports","9cffb053":"\nlet's see which month had the most sales"}}