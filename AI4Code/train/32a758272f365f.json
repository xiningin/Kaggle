{"cell_type":{"4a0801f8":"code","0ae0967d":"code","e0230d19":"code","5703db2a":"code","5711ef4e":"code","ec76d6cc":"code","4f72591f":"code","b0f68ff3":"code","81801945":"code","03dcee3e":"code","a8dca9a1":"code","5c9f4149":"code","9ce27399":"code","451e1c4a":"code","84dd008a":"code","d8eadbdc":"code","8f218b99":"code","ebc6d4a3":"code","958519f6":"code","3fcd388d":"code","dba2ac8d":"code","0bec22f6":"code","6872c01e":"code","43022b81":"code","b32b4063":"code","226ed5d7":"code","dac26486":"code","465e735e":"markdown","a908b206":"markdown","3944b55e":"markdown","51c9c9c8":"markdown","10148729":"markdown","8f371b3f":"markdown","e40b43ec":"markdown","4bdc4282":"markdown","12276dda":"markdown"},"source":{"4a0801f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ae0967d":"# Load the Dataset\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mlxtend.preprocessing import TransactionEncoder\n\n# Load transactions from pandas.\ndf = pd.read_csv(\"\/kaggle\/input\/groceries-dataset\/Groceries_dataset.csv\")\n\n# Print the header\nprint(df.head(10))","e0230d19":"# Grouping each observation by customer\ndf_grouped=df.groupby(['Member_number','Date'])['itemDescription'].apply(sum)\ndf_grouped","5703db2a":"# Create a list of transaction\ntransactions = [a[1]['itemDescription'].tolist() for a in list(df.groupby(['Member_number','Date']))]\ntransactions","5711ef4e":"# Encoding transactions\nte = TransactionEncoder()\nte_ary = te.fit(transactions).transform(transactions)\nte.columns_","ec76d6cc":"\ntransactions = pd.DataFrame(te_ary, columns=te.columns_)\npf = transactions.describe()\npf","4f72591f":"pf.iloc[0]-pf.iloc[3]","b0f68ff3":"f = pf.iloc[0]-pf.iloc[3]\na = f.tolist()\nb = list(f.index)\nitem = pd.DataFrame([[a[r],b[r]]for r in range(len(a))], columns=['Count','Item'])\nitem = item.sort_values(['Count'], ascending=False).head(50)\ntransactions","81801945":"# Computing Support for Single Items\nprint(transactions.mean().sort_values(ascending=False))","03dcee3e":"# Print first five items\nprint(transactions.head())","a8dca9a1":"# Computing support.\nsupportWmOv = np.logical_and(transactions['whole milk'], transactions['other vegetables']).mean()\nsupportWm = transactions['whole milk'].mean()\nsupportOv = transactions['other vegetables'].mean()\n\n# Compute and print confidence and lift.\nconfidence = supportWmOv \/ supportWm\nlift = supportWmOv \/ (supportWm * supportOv)\n\n# Print results.\nprint(supportOv, confidence, lift)","5c9f4149":"# Compute and print leverage\nleverage = supportWmOv - supportWm * supportOv\nprint(leverage)","9ce27399":"# Compute support for NOT \"almonds\"\nsupport_n_Ov = 1.0 - onehot['other vegetables'].mean()\n\n# Compute support for \"asparagus\" and NOT \"almonds\"\nsupportWm_n_Ov = supportWm - supportWmOv\n\n# Compute conviction\nconviction = supportWm*support_n_Ov \/ supportWmOv\nprint(conviction)","451e1c4a":"# Let's define the functions to calculate the metrics from the original data.\nfrom itertools import permutations\n\ndef supportA(itemA, df):\n    return float(df[itemA].mean())    \n\ndef supportB(itemB, df):\n    return float(df[itemB].mean())\n\ndef confidence(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() \/(df[itemA].mean()))\n\ndef lift(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() \/(df[itemA].mean() * df[itemB].mean()))\n\ndef leverage(itemA,itemB,df):\n    return np.logical_and(df[itemA],df[itemB]).mean() - (df[itemA].mean()*df[itemB].mean())\n\ndef conviction(itemA, itemB, df):\n    # Compute support for A and B\n    supportAB = np.logical_and(df[itemA], df[itemB]).mean()\n    # Compute support for A\n    supportA = df[itemA].mean()\n    # Compute support for not B\n    supportnB = 1.0 - df[itemB].mean()\n    # Compute support for A not B\n    supportAnB = supportA - supportAB\n    # Compute conviction\n    return float(supportA*supportnB \/ supportAnB)","84dd008a":"item_pairs = list()\nfor itemA,itemB in permutations(onehot,2):\n    item_pairs.append(list((itemA,itemB, #names\n                            onehot[itemA].sum(),onehot[itemB].sum(), #individual count\n                            np.logical_and(onehot[itemA],onehot[itemB]).sum(), #pair count\n                            supportA(itemA, onehot),\n                            supportB(itemB, onehot),\n                            confidence(itemA,itemB,onehot), #confidence\n                            lift(itemA,itemB,onehot), #lift\n                            leverage(itemA,itemB,onehot), # leverage\n                            conviction(itemA, itemB, onehot)\n                            ))) # ","d8eadbdc":"item_pairs = pd.DataFrame(item_pairs,columns = ['itemA','itemB',\n                                                'countItemA','countItemB',\n                                                'countItemA&B',\n                                                'Antecedent Support',\n                                                'Consequent Support',\n                                                'Confidence',\n                                                'Lift',\n                                                'Leverage',\n                                                'Conviction'])\n\nitem_pairs.sample(5)","8f218b99":"# Select subset of rules with low consequent support.\n#rules = item_pairs[item_pairs['Consequent Support'] < 0.05]\n#print(len(rules))\n#rules","ebc6d4a3":"# Select subset of rules with lift > 1.5.\n#rules_2 = rules[rules['Lift'] > 1.5]\n#print(len(rules_2))\n#rules_2","958519f6":"# Import Apriori algorithm\nfrom mlxtend.frequent_patterns import apriori","3fcd388d":"# Compute frequent itemsets\nfrequent_itemsets = apriori(transactions, min_support = 0.0005,max_len = 4, use_colnames = True)\n\n# Print number of itemsets\nprint(len(frequent_itemsets))","dba2ac8d":"# Print frequent itemsets\nprint(frequent_itemsets.head())","0bec22f6":"# Import Apriori algorithm\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\n# Compute association rules\nArules = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.001)","6872c01e":"Arules","43022b81":"# Raise the threshold\n# Compute association rules\nArules_2 = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.010)\n\nArules_2","b32b4063":"# Raise the threshold\n# Compute association rules\nArules_3 = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.050)\n\nArules_3","226ed5d7":"fig, ax = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(10,5))\nsns.boxenplot(x='antecedent support', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[0])\nsns.boxenplot(x='support', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[1])\nsns.boxenplot(x='confidence', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[2])\nplt.tight_layout()\nplt.show()","dac26486":"filtered_rules = Arules[(Arules['antecedent support'] > 0.06) &\n                        (Arules['support'] > 0.002) &\n                        (Arules['confidence'] > 0.04) &\n                        (Arules['lift'] > 1.00)]\n\nfiltered_rules","465e735e":"# Data Preparation","a908b206":"## Computing Leverage","3944b55e":"## Apriori and Computing Association Rule ","51c9c9c8":"## Computing Conviction","10148729":"## Apriori Algorithm","8f371b3f":"## Condifence & Lift","e40b43ec":"## Calculating Metrics","4bdc4282":"## Performing Multi-Metric Filtering","12276dda":"## Simplest Metric"}}