{"cell_type":{"bae03a03":"code","f7d3aad2":"code","c75ae0ee":"code","50aa0b44":"code","14cfde06":"code","300832ea":"code","a0a3d96f":"code","cb6ba21a":"code","5173f338":"code","f3a79848":"code","3e582b3b":"code","21288774":"code","e9d6a4e1":"code","80e18a94":"code","4567889c":"code","d1dd8a9f":"markdown","db7f496f":"markdown","6aaafd05":"markdown","81a99c78":"markdown","ced5887b":"markdown","7baaff20":"markdown","3f3aa677":"markdown","37836c99":"markdown","0993198f":"markdown"},"source":{"bae03a03":"import pandas as pd\nimport numpy as np\nfrom zipfile import ZipFile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom pathlib import Path\nimport matplotlib.pyplot as plt","f7d3aad2":"movielens_data_file_url = (\n    \"http:\/\/files.grouplens.org\/datasets\/movielens\/ml-latest-small.zip\"\n)\n\nmovielens_zipped_file = keras.utils.get_file(\n    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n)\n\nkeras_datasets_path = Path(movielens_zipped_file).parents[0]\nmovielens_dir = keras_datasets_path \/ \"ml-latest-small\"\n\n# Only extract the data the first time the script is run.\nif not movielens_dir.exists():\n    with ZipFile(movielens_zipped_file, \"r\") as zip:\n        # Extract files\n        print(\"Extracting all the files now...\")\n        zip.extractall(path=keras_datasets_path)\n        print(\"Done!\")\n        \nratings_file = movielens_dir \/ \"ratings.csv\"\ntags_file = movielens_dir \/ \"tags.csv\"\nmovies_file = movielens_dir \/ \"movies.csv\"\n\ndf = pd.read_csv(ratings_file)\ntags = pd.read_csv(tags_file)\nmovies = pd.read_csv(movies_file)","c75ae0ee":"df.head()","50aa0b44":"df.describe()","14cfde06":"df.info()","300832ea":"# Map user ID to a \"user vector\" via an embedding matrix\nuser_ids = df[\"userId\"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuserencoded2user = {i: x for i, x in enumerate(user_ids)}\n\n# Map movies ID to a \"movies vector\" via an embedding matrix\nmovie_ids = df[\"movieId\"].unique().tolist()\nmovie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\nmovie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n\ndf[\"user\"] = df[\"userId\"].map(user2user_encoded)\ndf[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n\nnum_users = len(user2user_encoded)\nnum_movies = len(movie_encoded2movie)\ndf['rating'] = df['rating'].values.astype(np.float32)\n\n# min and max ratings will be used to normalize the ratings later\nmin_rating = min(df[\"rating\"])\nmax_rating = max(df[\"rating\"])\n\nprint(f\"Number of users: {num_users}, Number of Movies: {num_movies}, Min Rating: {min_rating}, Max Rating: {max_rating}\")","a0a3d96f":"df = df.sample(frac=1, random_state=42)\nx = df[[\"user\", \"movie\"]].values\n\n# Normalizing the targets between 0 and 1. Makes it easy to train.\ny = df[\"rating\"].apply(lambda x: (x - min_rating) \/ (max_rating - min_rating)).values\n\n# Assuming training on 90% of the data and validating on 100%\ntrain_indices = int(0.9 * df.shape[0])\nx_train, x_val, y_train, y_val = (\n    x[:train_indices],\n    x[train_indices:],\n    y[:train_indices],\n    y[train_indices:],\n)","cb6ba21a":"EMBEDDING_SIZE = 50\n\nclass RecommenderNet(keras.Model):\n    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n        super(RecommenderNet, self).__init__(**kwargs)\n        self.num_users = num_users\n        self.num_movies = num_movies\n        self.embedding_size = embedding_size\n        self.user_embedding = layers.Embedding(\n            num_users,\n            embedding_size,\n            embeddings_initializer=\"he_normal\",\n            embeddings_regularizer=keras.regularizers.l2(1e-6),\n        )\n        self.user_bias = layers.Embedding(num_users, 1)\n        self.movie_embedding = layers.Embedding(\n            num_movies,\n            embedding_size,\n            embeddings_initializer=\"he_normal\",\n            embeddings_regularizer=keras.regularizers.l2(1e-6)\n        )\n        self.movie_bias = layers.Embedding(num_movies, 1)\n        \n    def call(self, inputs):\n        user_vector = self.user_embedding(inputs[:, 0])\n        user_bias = self.user_bias(inputs[:, 0])\n        movie_vector = self.movie_embedding(inputs[:, 1])\n        movie_bias = self.movie_bias(inputs[:, 1])\n        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n        # Add all the components (including bias)\n        x = dot_user_movie + user_bias + movie_bias\n        # The sigmoid activation forces the rating to be between 0 and 11\n        return tf.nn.sigmoid(x)\n    \nmodel = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\nmodel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n)","5173f338":"history = model.fit(\n    x=x_train,\n    y=y_train,\n    batch_size=64,\n    epochs=5,\n#     verbose=1,\n    validation_data=(x_val, y_val)\n)","f3a79848":"plt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.title('model_loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend()","3e582b3b":"movie_df = pd.read_csv(movielens_dir \/ 'movies.csv')\n\nuser_id = df.userId.sample(1).iloc[0]\nmovies_watched_by_user = df[df.userId == user_id]\nmovies_not_watched = movie_df[~movie_df['movieId'].isin(movies_watched_by_user.movieId.values)]['movieId']\n\nmovies_not_watched = list(set(movies_not_watched).intersection(set(movie2movie_encoded.keys())))\n\nmovies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n\nuser_encoder = user2user_encoded.get(user_id)\n\nuser_movie_array = np.hstack(\n    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n)\n\nratings = model.predict(user_movie_array).flatten()\ntop_ratings_indices = ratings.argsort()[-10:][::-1]\nrecommended_movie_ids = [\n    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n]","21288774":"print(\"Showing recommendations for user: {}\".format(user_id))\nprint(\"====\" * 9)\nprint(\"Movies with high ratings from user\")\nprint(\"----\" * 8)\ntop_movies_user = (\n    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n    .head(5)\n    .movieId.values\n)\nmovie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\nfor row in movie_df_rows.itertuples():\n    print(row.title, \":\", row.genres)\n\nprint(\"----\" * 8)\nprint(\"Top 10 movie recommendations\")\nprint(\"----\" * 8)\nrecommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\nfor row in recommended_movies.itertuples():\n    print(row.title, \":\", row.genres)\n","e9d6a4e1":"!\/opt\/conda\/bin\/python3.7 -m pip install --upgrade pip","80e18a94":"!pip install -q tensorflow-recommenders\n!pip install -q --upgrade tensorflow-datasets","4567889c":"import tensorflow_datasets as tfds\nimport tensorflow_recommenders as tfrs\n\n# Load data on movie ratings.\nratings = tfds.load(\"movielens\/100k-ratings\", split=\"train\")\nmovies = tfds.load(\"movielens\/100k-movies\", split=\"train\")\n\n# Build flexible representation models.\nuser_model = tf.keras.Sequential([...])\nmovie_model = tf.keras.Sequential([...])\n\n# Define your objectives.\ntask = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n    movies.batch(128).map(movie_model)\n  )\n)\n\n# Create a retrieval model.\nmodel = MovielensModel(user_model, movie_model, task)\nmodel.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n\n# Train.\nmodel.fit(ratings.batch(4096), epochs=3)\n\n# Set up retrieval using trained representations.\nindex = tfrs.layers.ann.BruteForce(model.user_model)\nindex.index(movies.batch(100).map(model.movie_model), movies)\n\n# Get recommendations.\n_, titles = index(np.array([\"42\"]))\nprint(f\"Recommendations for user 42: {titles[0, :3]}\") ","d1dd8a9f":"# 4. Create the model\n\nWe embed both users and movies in to `50-dimentional` vectors. \nThe model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias. The match score is scalled to the`[0, 1]` interval via a sigmoid (since our ratings are normalized to this range).","db7f496f":"# 7. TensorFlow Recommenders\n\nTensorFlow Recommenders (TFRS) is a library for building recommender system models. It helps with the full workflow of building a recommender system: data preparation, model formulation, training, evaluation, and deployment.\n\nIt's built on Keras and aims to have a gentile learning curve while still giving you the flexibility to build complex models.\n\nTFRS makes it possible to:\n- Build and evaluate flexible recommendation retrieval models.\n- Freely incorporate item, user and context information into recommendation models.\n- Train multi-task models that jointly optimize multiple recommendation objectives.","6aaafd05":"# Collaborative Filtering for Movie Recommendations\n\nIn this notebook we demonstrate Collaborative filtering using the Movielens datasets to recommend movies to users. The MovieLens retings dataset lists the ratings given by a set of users to a set of movies. Our goal is to be able to predict reatings for movies a user has not yet watched. The movies with the highest predicted ratings can then be recommended to the user.\n\nThe steps in the model are as follows:\n\n1. Map user ID to a \"user vector\" via an embedding matrix\n2. Map movie ID to a \"movie vector\" via an embedding matrix\n3. Compute the dot product between the user vector and movie vector, to obtain the a match score between the user and the movie (predicted rating).\n4. Train the embeddings via gradient descent using all known user-movie pairs.","81a99c78":"This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity. It contains `100836` ratings and `3683` tag applications across `9742` movies. These data were created by `610` users between `March 29, 1996` and `September 24, 2018`.\n\nUsers were selected at random for inclusion. All selected users had rated at least `20` movies. No demographic information is included. Each user is represented by an id, and no other information is provided.","ced5887b":"# 1. Load the data and apply preprocessing","7baaff20":"# 3. Preparing the Data","3f3aa677":"# 6. Show top 10 movie recommendations to a user","37836c99":"# 2. Exploratory Data Analysis","0993198f":"# 5. Train the Model on the Data Split"}}