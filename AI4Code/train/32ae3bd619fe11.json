{"cell_type":{"30026fab":"code","8952e792":"code","9b165ada":"code","cbbd0f1c":"code","818a0b9f":"code","4d3b6bf2":"code","b6addc7e":"code","a57c1fd4":"code","14e18b3b":"code","c8a930a3":"code","059160d6":"code","7d930c70":"markdown"},"source":{"30026fab":"import pandas  as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier","8952e792":"train = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")","9b165ada":"train[\"missing\"] = train.isnull().sum(axis = 1)\ntest[\"missing\"] = test.isnull().sum(axis = 1)","cbbd0f1c":"target = \"claim\"\npredictors = [x for x in train.columns if x not in [\"id\", target]]\n\nkf = KFold(n_splits = 5, shuffle = True, random_state = 666)\nskf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 666)","818a0b9f":"train[predictors] = train[predictors].fillna(train.groupby(\"missing\")[predictors].transform(\"median\"))\ntest[predictors] = test[predictors].fillna(train.groupby(\"missing\")[predictors].transform(\"median\"))","4d3b6bf2":"scaler = StandardScaler()\n\ntrain[predictors] = scaler.fit_transform(train[predictors])\ntest[predictors] = scaler.transform(test[predictors])","b6addc7e":"X = train[predictors]\ny = train[target]\ntest = test[predictors]","a57c1fd4":"params = {\n    'max_depth': 12, \n    'max_leaf_nodes': 175, \n    'min_samples_leaf': 13646, \n    'l2_regularization': 0.4559366258442665\n}","14e18b3b":"oof_hist = np.zeros(len(X))\npredictions_hist = np.zeros(len(test))\ni = 1\n\nfor train_ix, test_ix in skf.split(X.values, y.values):\n        \n    print(\"\\033[1m\" + \"Out of fold predictions generating for fold \\033[94m {} \\033[0m \\n\".format(i))\n        \n    train_X, train_y = X.values[train_ix], y.values[train_ix]\n    test_X, test_y = X.values[test_ix], y.values[test_ix]\n    \n    model_hist = HistGradientBoostingClassifier(\n        random_state = 666,\n        max_iter = 40000,\n        learning_rate = 0.025,\n        validation_fraction = 0.1,\n        early_stopping = True,\n        n_iter_no_change = 200,\n        scoring = \"roc_auc\",\n        verbose = 0,\n        **params\n    )   \n    \n    model_hist.fit(\n        train_X, \n        train_y,\n    )\n    \n    oof_hist[test_ix] = oof_hist[test_ix] + model_hist.predict_proba(test_X)[:, 1]\n    predictions_hist = predictions_hist + model_hist.predict_proba(test)[:, 1]\n    \n    print(\"\\033[1mAUC for fold \\033[91m{} \\t\\t\\t \\033[92m {} \\033[0m \\n\".format(i, round(roc_auc_score(test_y, oof_hist[test_ix]), 5)))\n    \n    i = i + 1\n    \nprint(\"\\033[1mAUC for Training Set: \\t\\t \\033[92m {} \\033[0m \\n\".format(round(roc_auc_score(y, oof_hist), 5)))","c8a930a3":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\nsubmission[target] = predictions_hist \/ 5\nsubmission.to_csv(\"submission.csv\", index = False)\nsubmission","059160d6":"np.save(\"oof_hist.npy\", oof_hist)\nnp.save(\"preds_hist.npy\", predictions_hist)","7d930c70":"For my other works in this TPS;\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/tps-09-21-eda\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/tps-09-21-xgboost-0-81785\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/tps-09-21-lightgbm-0-81772"}}