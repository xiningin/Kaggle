{"cell_type":{"26f3e66a":"code","3377353b":"code","bbfa40b4":"code","dfad434a":"code","6c44d95c":"code","44d71f88":"code","7529d814":"code","2b7f6aaf":"code","696fcb36":"code","a5b4914d":"code","3a381ddc":"code","2ddcc40c":"markdown","8f3e508c":"markdown","b74587c9":"markdown","f0f23fe5":"markdown"},"source":{"26f3e66a":"import os,cv2,re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf","3377353b":"TFREC = '..\/input\/melanoma-256x256'\n\nfiles_train = np.sort(np.array(tf.io.gfile.glob(TFREC + '\/train*.tfrec')))\nfiles_test  = np.sort(np.array(tf.io.gfile.glob(TFREC + '\/test*.tfrec')))","bbfa40b4":"ds = tf.data.TFRecordDataset(files_train).shuffle(42)","dfad434a":"def read_tfrecord(example):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['image'], example['target']","6c44d95c":"def image_decode(img):\n    img,label = read_tfrecord(img)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img,label","44d71f88":"def image_preprocessing(img):\n    \n    plt.imshow(img)\n    plt.show()\n    \n    #removing hairs\n    img = dullrazor(img)\n    #denoising\n    img = cv2.medianBlur(img, 3)\n    #filters\n    #CALL A FILTER METHOD HERE: BENGRAHAM for example\n \n    return img","7529d814":"def dullrazor(img, lowbound=15, showimgs=True, filterstruc=3, inpaintmat=3):\n    #grayscale\n    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n\n    #applying a blackhat\n    filterSize =(filterstruc, filterstruc)\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n\n    #0=skin and 255=hair\n    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n    \n    #inpainting\n    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n    \n    if showimgs:\n        print(\"_____DULLRAZOR_____\")\n        plt.imshow(imgtmp1, cmap=\"gray\")\n        plt.show()\n        plt.imshow(imgtmp2, cmap='gray')\n        plt.show()\n        plt.imshow(mask, cmap='gray')\n        plt.show()\n        plt.imshow(img_final)\n        plt.show()\n        print(\"___________________\")\n\n    return img_final","2b7f6aaf":"def view_images_bengraham(image):\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n        image = cv2.resize(image, (256, 256))\n        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 256\/10) ,-4 ,128)\n        plt.imshow(image, cmap=plt.cm.bone)\n        plt.show()","696fcb36":"def view_images_neuronengineer(image):\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (256, 256))\n        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 10) ,-4 ,128)\n        plt.imshow(image, cmap=plt.cm.bone)\n        plt.show()","a5b4914d":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n    \ndef circle_crop(img, sigmaX=10):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width\/2)\n    y = int(height\/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    return img \n\ndef view_images_crop(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (256, 256))\n    image= circle_crop(image)\n    plt.imshow(image, cmap=plt.cm.bone)\n    plt.show()","3a381ddc":"tmp = ds.take(1)\ntmp = tmp.map(lambda img: image_decode(img))\n\nfor img,label in tmp.as_numpy_iterator():\n    img = image_preprocessing(img)\n    view_images_bengraham(img)\n    view_images_neuronengineer(img)\n    view_images_crop(img)","2ddcc40c":"# Image preprocessing\n\n>>> Dataset TFRECORDS 256x256 with DULLRAZOR available here: [dataset](https:\/\/www.kaggle.com\/antocad\/melanoma-256x-dullrazor)\n\n* 1st step: remove hairs with Dull Razor filter (it works but need an improvement) ([ref](https:\/\/www.sciencedirect.com\/science\/article\/abs\/pii\/S0010482597000206?via%3Dihub))\n* 2nd step: remove the noise with Median Filtering\n* 3rd step: Discovering filters, Applying Neuron Engineer's method    ([Notebook](https:\/\/www.kaggle.com\/nxrprime\/siim-d3-eda-augmentations-and-resnext))\n\n* Next step: Lesion segmentation","8f3e508c":"def my_test(img):\n    def test_fn(img):\n        return image_preprocessing(img.numpy())\n    def call_test(img):\n        return tf.py_function(test_fn, [img], tf.uint8)\n    return call_test(img)","b74587c9":"ds = ds.map(lambda img: image_decode(img))\nds = ds.map(lambda img, label: (tf.py_function(my_test, [img], tf.uint8),label))","f0f23fe5":"### (useless part)"}}