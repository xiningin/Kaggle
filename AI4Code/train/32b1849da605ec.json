{"cell_type":{"a38d3d50":"code","72d29c50":"code","bed3ecca":"code","140324d1":"code","ec6400d0":"code","3a0952af":"code","8e10efed":"code","ade4afe1":"code","9b95f08f":"code","d0b502a3":"code","2e961d27":"code","8e027aa2":"code","48d8818b":"code","251d4c5c":"code","73513a31":"code","324c8428":"code","2f3c1af4":"code","856a5a0b":"code","a4202f03":"code","cacbde56":"code","cfb0c8d7":"code","53f2ee70":"code","e3949c65":"code","e9137c89":"code","4b26fbd8":"code","5a34fd79":"code","9e0f36f2":"code","45803c93":"code","fd1250d0":"markdown","21cdb9a6":"markdown","74bd6b49":"markdown"},"source":{"a38d3d50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","72d29c50":"import torch\nimport torchvision\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport pickle\n\nprint(torch.__version__)","bed3ecca":"# \u5b9a\u4e49transform\ntransform = torchvision.transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,),)\n])","140324d1":"# \u8bfb\u53d6\u6570\u636e\ntrain_set = datasets.FashionMNIST('.\/', download=True, train=True, transform=transform)\ntest_set = datasets.FashionMNIST('.\/', download=True, train=False, transform=transform)","ec6400d0":"# \u9a8c\u8bc1\u96c6\u5927\u5c0f\nval_size = int(len(train_set) * 0.2)\nval_size","3a0952af":"train_set, val_set = torch.utils.data.random_split(train_set, [len(train_set)-val_size, val_size])\nlen(train_set), len(val_set)","8e10efed":"# \u8bbe\u7f6ebatch_size\u5927\u5c0f\nBATCH_SIZE = 64\ntrain_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE)\nval_loader = torch.utils.data.DataLoader(val_set, shuffle=True, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=BATCH_SIZE)","ade4afe1":"data_iter = iter(train_loader)\nimages, labels = data_iter.next()\nimages.size(), labels.size(), labels[:5]","9b95f08f":"img, _ = next(iter(train_set))\nplt.imshow(img.squeeze(), cmap='gray')","d0b502a3":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","2e961d27":"\n# \u5b9a\u4e49\u7f51\u7edc\nclass LRNet(nn.Module):\n    def __init__(self):\n        super(LRNet, self).__init__();\n        self.fc1 = nn.Linear(28 * 28, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 64)\n        self.fc4 = nn.Linear(64, 10)\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)\n        x = self.dropout(F.leaky_relu(self.fc1(x)))\n        x = self.dropout(F.leaky_relu(self.fc2(x)))\n        x = self.dropout(F.leaky_relu(self.fc3(x)))\n        x = self.fc4(x)\n        return x","8e027aa2":"class BestAcc:\n    def __init__(self, epoch, loss, acc):\n        self.epoch = epoch\n        self.loss = loss\n        self.acc = acc\n    \n    def update(self, epoch, loss, acc):\n        if acc > self.acc:\n            self.epoch = epoch\n            self.loss = loss\n            self.acc = acc\n            ","48d8818b":"class MyModel:\n\n    def __init__(self, train_loader, val_loader, test_loader, model, criterion, optimizer, batch_size, device):\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.batch_size = batch_size\n        self.device = device\n\n        self.train_loss_arr = []\n        self.val_loss_arr = []\n        self.train_acc_arr = []\n        self.val_acc_arr = []\n        self.train_log = \"\"\n        self.val_log = \"\"\n        self.test_log = \"\"\n        self.train_best = BestAcc(-1, 0, -float('inf'))\n        self.val_best = BestAcc(-1, 0, -float('inf'))\n        self.epochs = 0\n        self.model = model\n        self.is_model_loaded = False\n\n    def train_and_val(self, epochs, force_train=False):\n        self.epochs = epochs\n\n        if self.is_model_loaded and not force_train:\n            return False\n\n        for epoch in range(epochs):\n            train_loss = 0.0\n            val_loss = 0.0\n            train_correct = 0\n            val_correct = 0\n            for i, (images, labels) in enumerate(self.train_loader, 0):\n                images, labels = images.to(self.device), labels.to(self.device)\n\n                pred = self.model(images)\n                loss = self.criterion(pred, labels)\n\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                train_loss += loss\n                label_pred = pred.max(1)[1]\n                train_correct += label_pred.eq(labels.data).sum()\n                if i % 100 == 0:\n                    log = 'Train epoch #{} {}\/{} {:.0f}%\\tLoss: {:.6f}\\n' \\\n                        .format(epoch, i * self.batch_size, len(self.train_loader.dataset),\n                                100.0 * i \/ len(self.train_loader), loss.item())\n                    print(log)\n                    self.train_log += log\n\n            train_loss_ave = train_loss \/ len(self.train_loader)\n            self.train_loss_arr.append(train_loss_ave)\n            train_acc = 1.0 * train_correct \/ len(self.train_loader.dataset)\n            self.train_acc_arr.append(train_acc)\n            self.train_best.update(epoch, train_loss_ave, train_acc)\n\n            #\n            for i, (images, labels) in enumerate(self.val_loader, 0):\n                images, labels = images.to(self.device), labels.to(self.device)\n                pred = self.model(images)\n\n                loss = self.criterion(pred, labels)\n                val_loss += loss\n\n                label_pred = pred.max(1)[1]\n                val_correct += label_pred.eq(labels.data).sum()\n\n            val_loss_ave = val_loss \/ len(self.val_loader)\n            self.val_loss_arr.append(val_loss_ave)\n            val_acc = 1.0 * val_correct \/ len(self.val_loader.dataset)\n            self.val_acc_arr.append(val_acc)\n            self.val_best.update(epoch, val_loss_ave, val_acc)\n            log = 'Validation epoch #{} Average loss: {:.4f}\\tAccuracy: {}\/{} {:.2f}%\\n' \\\n                .format(epoch, val_loss_ave, val_correct, len(self.val_loader.dataset), 100.0 * val_acc)\n            print(log)\n            self.val_log += log\n        return True\n\n    def test(self):\n        test_loss = 0.0\n        test_correct = 0\n        for i, (images, labels) in enumerate(self.test_loader, 0):\n            images, labels = images.to(self.device), labels.to(self.device)\n            pred = self.model(images)\n\n            loss = self.criterion(pred, labels)\n            test_loss += loss\n\n            label_pred = pred.max(1)[1]\n            test_correct += label_pred.eq(labels.data).sum()\n\n        test_loss_ave = test_loss \/ len(self.test_loader)\n\n        test_acc = 1.0 * test_correct \/ len(self.test_loader.dataset)\n\n        log = 'Test Average loss: {:.4f}\\tAccuracy: {}\/{} {:.2f}%\\n' \\\n            .format(test_loss_ave, test_correct, len(self.test_loader.dataset), 100.0 * test_acc)\n        print(log)\n        self.test_log += log\n\n    def get_loss_data(self):\n        return self.train_loss_arr, self.val_loss_arr\n\n    def get_acc_data(self):\n        return self.train_acc_arr, self.val_acc_arr\n\n    def get_log(self):\n        return self.train_log, self.val_log, self.test_log\n\n    def get_best_acc(self):\n        return self.train_best, self.val_best\n\n    def draw_acc(self):\n        x_axis = np.arange(self.epochs)\n        plt.figure()\n        plt.title('Accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.plot(x_axis, self.train_acc_arr, label='train')\n        plt.plot(x_axis, self.val_acc_arr, label='val')\n        plt.legend()\n        plt.show()\n\n    def draw_loss(self):\n        x_axis = np.arange(self.epochs)\n        plt.figure()\n        plt.title('Loss')\n        plt.xlabel('epochs')\n        plt.ylabel('loss')\n        plt.plot(x_axis, self.train_loss_arr, label='train')\n        plt.plot(x_axis, self.val_loss_arr, label='val')\n        plt.legend()\n        plt.show()\n\n    def load_model(self, path_model):\n        self.model.load_state_dict(torch.load(path_model))\n        self.model.eval()\n        self.is_model_loaded = True\n        return True\n\n    def save_model(self, path_model):\n        torch.save(self.model.state_dict(), path_model)\n\n","251d4c5c":"LEARNING_RATE = 0.0001\n\nnet = LRNet().to(device)\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n\nEPOCHS = 45","73513a31":"%%time\nLRModel = MyModel(train_loader, val_loader, test_loader, net, criterion, optimizer, BATCH_SIZE, device)\n# LRModel.load_model('\/kaggle\/working\/linear_model.pkl')\nLRModel.train_and_val(EPOCHS)","324c8428":"LRModel.save_model('\/kaggle\/working\/linear_model.pkl')","2f3c1af4":"LRModel.test()","856a5a0b":"train_best, val_best = LRModel.get_best_acc()\nprint('Train best epoch: {}, loss: {:.4f}, accuracy: {:.4f}'.format(train_best.epoch, train_best.loss, train_best.acc))\nprint('Val best epoch: {}, loss: {:.4f}, accuracy: {:.4f}'.format(val_best.epoch, val_best.loss, val_best.acc))","a4202f03":"LRModel.draw_loss()","cacbde56":"LRModel.draw_acc()","cfb0c8d7":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc1 = nn.Linear(64*6*6, 600)\n        self.drop = nn.Dropout2d(0.25)\n        self.fc2 = nn.Linear(600, 120)\n        self.fc3 = nn.Linear(120, 10)\n        \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = x.view(x.shape[0], -1)\n        x = self.fc1(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        \n        return x","53f2ee70":"# \u8bbe\u7f6ebatch_size\u5927\u5c0f\nBATCH_SIZE = 32\ntrain_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE)\nval_loader = torch.utils.data.DataLoader(val_set, shuffle=True, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=BATCH_SIZE)","e3949c65":"LEARNING_RATE = 0.001\ncnn = CNN().to(device)\nEPOCHS = 5\n\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\nprint(cnn)","e9137c89":"%%time\nCNNModel = MyModel(train_loader, val_loader, test_loader, cnn, criterion, optimizer, BATCH_SIZE, device)\n# CNNModel.load_model('\/kaggle\/working\/cnn_model.pkl', '\/kaggle\/working\/cnn_model_data.pkl')\nCNNModel.train_and_val(EPOCHS)\nCNNModel.save_model('\/kaggle\/working\/cnn_model.pkl', '\/kaggle\/working\/cnn_model_data.pkl')","4b26fbd8":"CNNModel.test()","5a34fd79":"train_best, val_best = CNNModel.get_best_acc()\nprint('Train best epoch: {}, loss: {:.4f}, accuracy: {:.4f}'.format(train_best.epoch, train_best.loss, train_best.acc))\nprint('Val best epoch: {}, loss: {:.4f}, accuracy: {:.4f}'.format(val_best.epoch, val_best.loss, val_best.acc))","9e0f36f2":"CNNModel.draw_loss()","45803c93":"CNNModel.draw_acc()","fd1250d0":"## Linear Model","21cdb9a6":"### After modularity","74bd6b49":"## CNN Model"}}