{"cell_type":{"764f9b1d":"code","8ec1e9e2":"code","426870b3":"code","cf29157e":"code","a0faf7f4":"code","ac6e21ba":"code","cea8c1cc":"code","42069de1":"code","21679e77":"code","3cdadc4e":"code","a80c142c":"code","b4800eea":"code","65d9e575":"markdown","ae4b4d41":"markdown","fef08411":"markdown","67dba982":"markdown","d4331da0":"markdown","259a942c":"markdown","ff0183d1":"markdown","9a7dc25f":"markdown","762e0c8a":"markdown","9eb74b29":"markdown","065805c9":"markdown"},"source":{"764f9b1d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\npyo.init_notebook_mode()\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ec1e9e2":"data = pd.read_csv('\/kaggle\/input\/pakistans-largest-ecommerce-dataset\/Pakistan Largest Ecommerce Dataset.csv');\ndata","426870b3":"sub_columns = ['status', 'created_at', 'price', 'qty_ordered', 'category_name_1', 'grand_total', 'discount_amount', 'Working Date', 'BI Status', 'Year', 'Month']\ndata_sub = data[sub_columns]\ndata_sub","cf29157e":"# there are some rows in which all columns are null need to drop all those rows\ndata_sub.dropna(how='all', inplace=True)\n\n#null_status_rows = pd.isnull(data_sub.status)\ndata_sub.sort_index(ascending=False)","a0faf7f4":"\n\ndata_sub.status.fillna(data_sub.status.mode()[0], inplace=True)\n\n","ac6e21ba":"\n\ndata_sub.isnull().sum()\n\n","cea8c1cc":"data_sub.category_name_1.fillna(data_sub.category_name_1.mode()[0], inplace=True)","42069de1":"\n\ndata_sub\n\n","21679e77":"\n\nlist_of_categories = data_sub['category_name_1'].unique()\ntotal_categories = len(list_of_categories)\nprint(f'Total categories {total_categories}')\n\n","3cdadc4e":"\n\ncategories_by_order_count = data_sub.groupby('category_name_1').size().reset_index(name='Number of Orders').sort_values('Number of Orders',ascending=False)\n\nbar = px.bar(categories_by_order_count, y='Number of Orders', x='category_name_1',\n             title='Number of orders by Category',\n             hover_data=['category_name_1'], labels={'category_name_1':'Category name'})\nbar.show()\n\n","a80c142c":"data_sub['status'].unique()","b4800eea":"completed_orders = data_sub[(data_sub['status'] == 'complete') | (data_sub['status'] == 'paid') | (data_sub['status'] == 'received')]\ncompleted_orders_by_category_count = completed_orders.groupby('category_name_1').size().reset_index(name='Number of Orders').sort_values('Number of Orders', ascending=False)\n\npie = px.bar(completed_orders_by_category_count, y='Number of Orders', x='category_name_1',\n             title='Number of completed orders by Category',\n             hover_data=['category_name_1'], labels={'category_name_1':'Category name'})\npie.show()","65d9e575":"**\n# Subset of data needed for Best selling category analysis**","ae4b4d41":"**\n\nGet all unique categories\n**","fef08411":"**Category_name_1 null treatment**","67dba982":"\n**Exploratory Data Analysis**","d4331da0":"# \nBest Category by completion of order","259a942c":"\n#  Treatment of Null or NaN\n\n*     Treament of rows having all columns as NaN\n\n ","ff0183d1":"\nTable of Content\n* \n* 1.     Importing the library\n* 2.     Loading the Dataset\n* 3.     Null\/NaN values Treatment\n* 4.     Exploratory Data Analysis.\n     \n         Best category by total numebr of Orders\n        Best Category by completion of order\n        Worst category by not completed order\n        Compare the completed and not completed orders by category\n        Categories by number of order Per Year\n        Number of orders by category by month\n\nInteresting Facts (outcome of EDA):\n\n    Men Fashion has more number of orders than women Fashion :-)\n    Spike in orders in November for each category, resaon might be Black Friday and 11.11 Sales.\n    Spike in May for each category is not I understand. In May we donot have any sales or promotions.\n    2017 is busiest year for most of categories sales.\n\n","9a7dc25f":"**Category name 1 has 164 null, for time begin, we fill all NaN with mode value**\n\nMode value is 'Mobiles & Tablets'","762e0c8a":"**Considering order statuses 'complete', 'paid', 'received' as completed**","9eb74b29":"# Best category by total numebr of Orders","065805c9":"\n\n# *     Status null treatment\n\n    *         After removing all rows having nan in all column,only 15 are rows in which status is nullwe use mode to all 15 nulls. Mode value is completed.\n"}}