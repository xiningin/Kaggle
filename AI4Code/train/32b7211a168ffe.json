{"cell_type":{"acf010b4":"code","289493ce":"code","e4c0be40":"code","815b5653":"code","794788a0":"code","1a443ab8":"code","0f23cd51":"code","2bd25f4a":"code","80235b6b":"code","e657419d":"code","e0009971":"code","afe1ae52":"code","facc05c6":"code","88b91d99":"code","b0fd0346":"code","2a604369":"code","55d13ba9":"code","625d4a5e":"code","737be871":"code","9c4e0e0e":"code","868ccb85":"code","23940a20":"code","91e0c00a":"code","74024a78":"code","f839add3":"markdown","07bad457":"markdown","0de10e64":"markdown","93b87b1e":"markdown","d2218f65":"markdown"},"source":{"acf010b4":"!pip install -U scikit-learn\n\nimport os\nimport time\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\nRANDOM_SEED = 111\n\nnp.random.seed(RANDOM_SEED)\n\nfrom datetime import datetime\nfrom numpy.random import default_rng\nrng = default_rng(RANDOM_SEED)\n\nimport matplotlib.pyplot as plt\n\nimport sklearn\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_squared_log_error\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, make_scorer\nfrom sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, StandardScaler, OneHotEncoder, Binarizer, KBinsDiscretizer, QuantileTransformer, PolynomialFeatures, LabelEncoder\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold, StratifiedKFold, StratifiedShuffleSplit, ShuffleSplit\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import LinearRegression, Ridge, RidgeCV\nfrom sklearn.ensemble import StackingRegressor\n\nDS_DIR = '\/kaggle\/input\/aug21-ds'\nINPUT_DIR = '\/kaggle\/input\/tabular-playground-series-aug-2021'\nOUTPUT_DIR = '.\/'","289493ce":"sklearn.__version__","e4c0be40":"!pip install -q h2o\n\nimport h2o\nfrom h2o.automl import H2OAutoML\nfrom h2o.sklearn import H2OAutoMLRegressor\nh2o.init()","815b5653":"train_df = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'), index_col='id')\ntest_df = pd.read_csv(os.path.join(INPUT_DIR,'test.csv'), index_col='id')\n\ntrain_df = train_df.sample(frac=1, random_state=RANDOM_SEED)\nholdout_size = train_df.shape[0]\/\/5\nholdout_df = train_df.iloc[:holdout_size]\ntrain_df = train_df.iloc[holdout_size:]\nholdout_labels_df = holdout_df['loss']\nholdout_df.drop(columns='loss', inplace=True)\n\nlabels = train_df['loss']\ntrain_df.drop(columns='loss', inplace=True)\ntotal_df = train_df.append(holdout_df).append(test_df) \n\nprint('validate sample seed: ', holdout_df.iloc[100, :5])","794788a0":"pd.concat((total_df.min(), total_df.max(), total_df.mean(), total_df.std(), total_df.nunique()), axis=1)","1a443ab8":"class LiteAutoMLWrapper(BaseEstimator):\n  def __init__(self, all_cols, timeout=3600):\n    self.all_cols = all_cols\n    self.roles = {\n        #lama.dataset.roles.CategoryRole(dtype=np.float): all_cols,\n        lama.dataset.roles.NumericRole(dtype=np.float): all_cols\n    }\n    \n    task = Task('reg', loss='mse', metric='mse')\n    self.automl = TabularAutoML(task=task, timeout=timeout, \n                           reader_params  = {'cv': 5, 'random_state': RANDOM_SEED},\n                           general_params = {'use_algos': [['lgb', 'lgb_tuned', 'cb', 'cb_tuned']]})\n\n  def fit(self, X, y, **kwargs):\n    self.automl.fit_predict({'data': X, 'target': y}, train_features=self.all_cols, roles=self.roles)\n    \n  def predict(self, X):\n    y_pred = self.automl.predict({'data': X}, features_names=self.all_cols)\n    y_pred = y_pred.data[:, 0]\n    return y_pred\n\n\nclass FLAMLWrapper(BaseEstimator):\n  def __init__(self, **kwargs):\n    self.settings = kwargs\n    self.automl = flaml.AutoML()\n\n  def fit(self, X, y, **kwargs):\n    self.automl.fit(X, y, **self.settings)\n    \n  def predict(self, X):\n    y_pred = self.automl.predict(X)\n    return y_pred\n\n\ndef RMSE(y_true, y_pred, **kwargs):\n    return np.sqrt(mean_squared_error(y_true, y_pred, **kwargs))","0f23cd51":"train_frame = h2o.H2OFrame(train_df)\nholdout_frame = h2o.H2OFrame(holdout_df)\ntest_frame = h2o.H2OFrame(test_df)\n\nmodel = H2OAutoMLRegressor(seed=RANDOM_SEED, max_runtime_secs=600, nfolds=5, stopping_metric='RMSE', sort_metric='RMSE', \n                           stopping_rounds=10, verbosity='warn')\n\nmodel.fit(train_frame, labels.values)\ntest_pred = np.squeeze(model.predict(test_frame).as_data_frame().values)\ntrain_pred = np.squeeze(model.predict(train_frame).as_data_frame().values)\nholdout_pred = np.squeeze(model.predict(holdout_frame).as_data_frame().values)","2bd25f4a":"score_train = RMSE(train_pred, labels.values)\nscore_holdout = RMSE(holdout_pred, holdout_labels_df.values)\nprint(score_train, score_holdout)","80235b6b":"model.estimator.leaderboard.as_data_frame().iloc[:12]","e657419d":"#h2o.get_model(model.estimator.get_best_model().metalearner().model_id)\n\nleaderbrd = model.estimator.leaderboard.as_data_frame().iloc[2:12]\nleaderbrd = leaderbrd['model_id'].values\n\ntest_ds_pred, train_ds_pred, holdout_ds_pred = [], [], []\nfor mdl in leaderbrd:\n  mdl = h2o.get_model(mdl)\n  test_ds_pred.append(np.squeeze(mdl.predict(test_frame).as_data_frame().values))\n  train_ds_pred.append(np.squeeze(mdl.predict(train_frame).as_data_frame().values))\n  holdout_ds_pred.append(np.squeeze(mdl.predict(holdout_frame).as_data_frame().values))\n\ntest_ds_pred = np.vstack(test_ds_pred).T\ntrain_ds_pred = np.vstack(train_ds_pred).T\nholdout_ds_pred = np.vstack(holdout_ds_pred).T","e0009971":"output_res = pd.DataFrame(data=test_ds_pred)\noutput_res.to_csv('test_pred.csv', index=False)\n\noutput_res = pd.DataFrame(data=train_ds_pred)\noutput_res.to_csv('train_pred.csv', index=False)\n\noutput_res = pd.DataFrame(data=holdout_ds_pred)\noutput_res.to_csv('holdout_pred.csv', index=False)","afe1ae52":"test_ds_pred = pd.read_csv(os.path.join(DS_DIR,'test_pred.csv')).values\ntrain_ds_pred = pd.read_csv(os.path.join(DS_DIR, 'train_pred.csv')).values\nholdout_ds_pred = pd.read_csv(os.path.join(DS_DIR, 'holdout_pred.csv')).values\n\ntrain_labels = labels.values\nholdout_labels = holdout_labels_df.values","facc05c6":"#1) Take the best fold in holdout dataset (no stacking)\n#Private Score: 7.89102\n\nbest_holdout_score, scores, best_idx = 10, [], -1\nfor i in range(train_ds_pred.shape[1]):\n  score_train = RMSE(train_ds_pred.T[i], labels.values)\n  score_holdout = RMSE(holdout_ds_pred.T[i], holdout_labels_df.values)\n  print(score_train, score_holdout)\n  scores.append(score_holdout)\n  if best_holdout_score > score_holdout:\n    best_holdout_score = score_holdout\n    best_idx = i\n\nscores = np.argsort(scores)\n\nprint('\\n', 'index with best score:', best_idx, ', score ranks:', scores)","88b91d99":"#2) Mean\/median among numeric float label values\n#Private Score: 7.89707 (mean)\n\nscore_train = RMSE(np.mean(train_ds_pred, 1), labels.values)\nscore_holdout = RMSE(np.mean(holdout_ds_pred, 1), holdout_labels_df.values)\nprint(score_train, score_holdout)\n\nscore_train = RMSE(np.median(train_ds_pred, 1), labels.values)\nscore_holdout = RMSE(np.median(holdout_ds_pred, 1), holdout_labels_df.values)\nprint(score_train, score_holdout)","b0fd0346":"#3) Voting among discreet label values\n#Private Score: 7.92492\n\nscore_train = RMSE(np.squeeze(stats.mode(np.round(train_ds_pred), 1).mode), labels.values)\nscore_holdout = RMSE(np.squeeze(stats.mode(np.round(holdout_ds_pred), 1).mode), holdout_labels_df.values)\nprint(score_train, score_holdout)","2a604369":"#4) Best weighted average against holdout labels\n#7.877126121980474 (0.075, 0.8, 0.125) - Private Score: 7.87690\n#7.885931889115389 (0.0875, 0.8, 0.1125) - Private Score: 7.87679\n\n\nimport itertools\n\ndef minimize_weights(cols, n, maxv):\n  size = len(cols)\n  best_score = 100\n  best_weights = []\n  perf = np.array([0]*size)\n\n  linspace = np.round(np.linspace(0, maxv, round(n*maxv*10)+1).tolist(), 8)\n  print(linspace[:50])\n  print(cols)\n\n  for x in itertools.product(linspace, repeat=size): \n    if sum(x) == 1:\n      score = mean_squared_error(np.average(holdout_ds_pred.T[cols], 0, x), holdout_labels_df.values)\n      if score < best_score:\n        best_score = score\n        best_weights = x\n        perf = perf + x\n        #print(np.sqrt(score), x)\n\n  cols = cols[perf.argsort()]\n  print(np.sqrt(best_score), best_weights, cols)\n  return cols, best_weights\n\n#full flow for selecting best features:\n#cols = scores\n#cols, best_weights = minimize_weights(cols[:12], 0.5, 0.8)\n#cols, best_weights = minimize_weights(cols[-6:], 2, 0.8)\n#cols, best_weights = minimize_weights(cols[-4:], 4, 0.8)\n#cols, best_weights = minimize_weights(cols[-3:], 8, 0.8)\n\n#quick flow:\ncols, best_weights = minimize_weights(np.array([9,0,8]), 16, 0.8)","55d13ba9":"cols = np.array([9,0,8])\nscore_train = RMSE(np.average(train_ds_pred.T[cols], 0, best_weights), labels.values)\nscore_holdout = RMSE(np.average(holdout_ds_pred.T[cols], 0, best_weights), holdout_labels_df.values)\nprint(score_train, score_holdout)","625d4a5e":"#5) Add a normally-distributed noise to existing predictions\n#Private Score: 7.86517\n\ntrain_pred_noise = [x + np.random.normal(0, 0.03) for x in train_pred]\ntest_pred_noise = [x + np.random.normal(0, 0.03) for x in test_pred]\nholdout_pred_noise = [x + np.random.normal(0, 0.03) for x in holdout_pred]\n\nscore_train = RMSE(train_pred_noise, labels.values)\nscore_holdout = RMSE(holdout_pred_noise, holdout_labels_df.values)\nprint(score_train, score_holdout)","737be871":"#6) H2O stacking with predicted values from holdout dataset\n#Private Score: 7.87028\n\nholdout_stack_frame = h2o.H2OFrame(holdout_ds_pred)\ntrain_stack_frame = h2o.H2OFrame(train_ds_pred)\ntest_stack_frame = h2o.H2OFrame(test_ds_pred)\n\nmodel = H2OAutoMLRegressor(seed=RANDOM_SEED, max_runtime_secs=600, nfolds=5, stopping_metric='RMSE', sort_metric='RMSE', \n                           stopping_rounds=10, verbosity='warn')\n\nmodel.fit(holdout_stack_frame, holdout_labels_df.values)\ntest_stack_pred = np.squeeze(model.predict(test_stack_frame).as_data_frame().values)\ntrain_stack_pred = np.squeeze(model.predict(train_stack_frame).as_data_frame().values)\nholdout_stack_pred = np.squeeze(model.predict(holdout_stack_frame).as_data_frame().values)","9c4e0e0e":"score_train = RMSE(train_stack_pred, labels.values)\nscore_holdout = RMSE(holdout_stack_pred, holdout_labels_df.values)\nprint(score_train, score_holdout)","868ccb85":"#7) H2O default stacking with 20% test pseudolabels\n#Private Score: 7.86660\n\ntest_pseudo_df = test_df.copy()\ntest_pseudo_df['loss'] = test_pred\ntest_pseudo_df = test_pseudo_df.sample(frac=1, random_state=RANDOM_SEED)\ntest_pseudo_df = test_pseudo_df.iloc[:test_pseudo_df.shape[0]\/\/5]\n\ntrain_pseudo_df = train_df.copy()\ntrain_pseudo_df['loss'] = labels\ntrain_pseudo_df = train_pseudo_df.append(test_pseudo_df)\ntrain_pseudo_labels = train_pseudo_df['loss']\ntrain_pseudo_df.drop(columns='loss', inplace=True)\n\nmodel = H2OAutoMLRegressor(seed=RANDOM_SEED, max_runtime_secs=600, nfolds=5, stopping_metric='RMSE', sort_metric='RMSE', \n                           stopping_rounds=10, verbosity='warn')\n\nmodel.fit(train_pseudo_df.values, train_pseudo_labels.values)\ntest_pred2 = model.predict(test_df.values)\ntrain_pred2 = model.predict(train_df.values)\nholdout_pred2 = model.predict(holdout_df.values)","23940a20":"score_train = RMSE(train_pred2, labels.values)\nscore_holdout = RMSE(holdout_pred2, holdout_labels_df.values)\nprint(score_train, score_holdout)","91e0c00a":"#8) H2O recursive chaining with pseudolabels\n#The algorithm is taken from:\n#https:\/\/www.kaggle.com\/c\/tabular-playground-series-aug-2021\/discussion\/270051\n#Private Score: 7.84977\n\nmodel = H2OAutoMLRegressor(seed=RANDOM_SEED, max_runtime_secs=600, nfolds=5, stopping_metric='RMSE', sort_metric='RMSE', \n                           stopping_rounds=10, verbosity='warn')\n\ndef recursive_train(test_pred, learning_rate = 0.2, output_res=None):\n  model.fit(test_frame, test_pred)\n  train_pred = np.squeeze(model.predict(train_frame).as_data_frame().values)\n  new_pred = labels.values - train_pred\n  print('train loss:', RMSE(train_pred, labels.values))\n\n  model.fit(train_frame, new_pred)\n  error_prediction = np.squeeze(model.predict(test_frame).as_data_frame().values)\n\n  test_pred = test_pred + (error_prediction * learning_rate)\n  if output_res:\n    output_res['loss'] = test_pred\n    output_res.to_csv('submission.csv', index=False)\n\n  return test_pred\n\nmodel.fit(train_frame, labels.values)\ntest_pred = np.squeeze(model.predict(test_frame).as_data_frame().values)\ntrain_pred = np.squeeze(model.predict(train_frame).as_data_frame().values)\nprint('train loss:', RMSE(train_pred, labels.values))\n\ntest_pred_new = test_pred\n\nfor x in range(10):\n  test_pred_new = recursive_train(test_pred_new)","74024a78":"output_res = pd.DataFrame(index=test_df.index, data={'id':test_df.index})\noutput_res['loss'] = test_pred_new\noutput_res.to_csv('submission.csv', index=False)","f839add3":"### Load source data\n\nWe will split train dataset into the train (80%) and holdout (20%) to validate train results and stacking.","07bad457":"### Save new or load existing predicted data","0de10e64":"### Build H2O model\n\nThe built-in H2O stacking algorithm reach as much as **7.87097** in private score.<br\/>\nTo improve the scores, increase the `max_runtime_secs` to 1h.","93b87b1e":"### Do manual stacking and blending\nWe will do and compare stacking among the best 10 sub-models from the same H2O model\n\n|stacking type|private score\n|---|---\n|Take the best fold in holdout dataset (no stacking)|7.89102\n|Mean\/median among numeric float label values|7.89707\n|Voting among discreet label values|7.92492\n|Best weighted average against holdout labels|7.87679\n|Add a normally-distributed noise to existing predictions|7.86517\n|H2O stacking with predicted values from holdout dataset|7.87028\n|H2O default stacking with 20% test pseudolabels|7.86660\n|H2O recursive chaining with pseudolabels|7.84977","d2218f65":"### Save submission data"}}