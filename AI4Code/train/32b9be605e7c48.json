{"cell_type":{"9b9d3804":"code","6f3059ac":"code","38382c74":"code","8b239a87":"code","8f8265dc":"code","f51ba606":"code","bc5e08c2":"code","37ba5fb6":"code","49a9a6cf":"code","96a0b492":"code","1190007c":"code","a67ea1d4":"code","8e2e5698":"code","bec434f3":"code","c1b57565":"code","689c68d0":"code","90f0e654":"code","5279e7af":"code","74de281c":"code","a58ff922":"code","bbc9552d":"code","3258e096":"code","28b50ca0":"code","47638a98":"code","0865cc57":"code","7fb4603d":"code","79bb676e":"code","d85972ed":"code","d4e9033c":"code","3990e939":"code","852069ab":"code","960ba1fb":"code","4ee85d57":"code","4a8d12d0":"code","cdd8e5b1":"code","e81e4b67":"code","c1ea41ff":"code","5298d884":"code","27ed8ed2":"code","d6ceea9c":"code","52e5b6a3":"code","a8f62d67":"markdown","20c28012":"markdown","2456fe42":"markdown","628694ac":"markdown","a11fb01a":"markdown","fd871063":"markdown","72324be0":"markdown","f84d0c66":"markdown","24de240f":"markdown","e4d485ba":"markdown","06315c83":"markdown","37104cf0":"markdown","7c795a8f":"markdown","69cfac51":"markdown","3a2f46bd":"markdown","29c0e119":"markdown","29606b40":"markdown","86205355":"markdown","34f5f860":"markdown","19b36f14":"markdown","eb01f3ab":"markdown","df2b99de":"markdown","5f595636":"markdown","08581fab":"markdown","b9a1fe1c":"markdown","5544271a":"markdown","c12b67eb":"markdown","d41b5d94":"markdown","c4e18b7a":"markdown","13432176":"markdown","82c9ab8f":"markdown","790e3a45":"markdown","f44a6ad4":"markdown","ed558726":"markdown","7b4ff9e6":"markdown","b0994ad5":"markdown","7d62c881":"markdown","11ef187a":"markdown","d9354302":"markdown","aefcdea7":"markdown","ee57c1d7":"markdown","9bb77451":"markdown","b2271def":"markdown","11a720f8":"markdown","25082b66":"markdown","3037b881":"markdown","902300cd":"markdown","cafac82a":"markdown","d5c54a6a":"markdown","ae53141a":"markdown","a034f463":"markdown","7ed55f10":"markdown","7ed89772":"markdown","3dec1b1f":"markdown","3b8b2875":"markdown","aba47455":"markdown","904a07bf":"markdown","1d25ad17":"markdown","dbd1589f":"markdown","d3fcfb71":"markdown","cccb7b68":"markdown","12991218":"markdown","cc87176b":"markdown","b5666e68":"markdown","5338cb5a":"markdown","6bf139ae":"markdown","86f72d98":"markdown","f29884a5":"markdown","0b891aef":"markdown","8015183e":"markdown","387c579a":"markdown","beda115e":"markdown","5d88bd16":"markdown","0f7685a1":"markdown"},"source":{"9b9d3804":"import gensim\nfrom gensim import corpora, models\nfrom gensim.models import Word2Vec\nfrom multiprocessing import freeze_support\n\nimport pyLDAvis.gensim\n\nimport nltk\nfrom nltk import stem\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\n\nfrom IPython.display import IFrame\nimport matplotlib\nfrom matplotlib import pyplot\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport os","6f3059ac":"#read metadata function\ndef readMetaData(path):\n    metadataDf = pd.read_csv(path, encoding = 'utf-8')\n    metadataDf = metadataDf.loc[metadataDf.abstract.str.len() < 1500]\n    metadataDf[\"text\"] = metadataDf[\"title\"] + ' ' + metadataDf[\"abstract\"]\n    return metadataDf","38382c74":"dataDf = readMetaData('..\/input\/CORD-19-research-challenge\/metadata.csv')","8b239a87":"for col in dataDf.columns:\n    print(col)","8f8265dc":"dataDf.source_x.value_counts()\\\n    .plot(kind = 'pie', title = 'distribution of publlication sources', figsize = (6,6));","f51ba606":"pd.to_datetime(dataDf.publish_time, errors='coerce', format = '%Y\/%m\/%d')\\\n    .dt.year.value_counts().plot.bar(x = 'year', rot=45, figsize = (10,8));","bc5e08c2":"dataDf.has_pmc_xml_parse.value_counts().plot(kind = 'bar', figsize = (6,5));","37ba5fb6":"dataDf.title.str.split().str.len().value_counts()\\\n    .plot(kind = 'hist', bins = 50, figsize = (10,8));","49a9a6cf":"dataDf.title.iloc[0]","96a0b492":"dataDf.abstract.str.split().str.len().value_counts()\\\n    .plot(kind = 'hist', bins = 50, figsize = (10,8), xlim=(0,600));","1190007c":"dataDf.abstract.iloc[0]","a67ea1d4":"dataDf.text.str.split().str.len().value_counts()\\\n    .plot(kind = 'hist', bins = 50, figsize = (10,8), xlim=(0,600));","8e2e5698":"dataDf.text.iloc[0]","bec434f3":"custom_stop_words = ['abstract', 'preprint', 'fig', 'doi', 'equilibrium', 'spatial', 'eq', 'time' \\\n                     ,'rainfall', 'hsa', 'susceptible','number', 'biorxiv', 'ape', 'mir', 'bifurcation',\\\n                     'forecasts', 'parameter', 'using', 'peer', 'reviewed', 'fia', 'lf','medrxiv', 'reuse',\\\n                     'reserved', 'holder', 'copyright', 'funder', 'author','reviewed', 'peer', 'allowed',\\\n                     'granted', 'sia','license', 'https', 'org', 'display', 'appendicitis', 'biorxiv',\\\n                     'respondents', 'nanoparticles', 'filmarray','probnp', 'btv', 'january', 'medrxiv',\\\n                     'preprint', 'license', 'number', 'granted', 'display', 'estimated', 'doi','days', 'confirmed',\\\n                     'available', 'cc', 'nd', 'nc', 'author', 'reuse', 'reserved', 'allowed', 'peer', 'reviewed',\\\n                     'copyright', 'holder','author', 'funder', 'org', 'https', 'et', 'al', 'using', 'fig', 'figure',\\\n                     'used', 'onset', 'preprint','days', 'time', 'granted', 'mean', 'display', 'number', 'screening',\\\n                     'exposure', 'ci', 'available', 'travellers', 'estimated','intervals', 'uveitis', 'ii', 'predicted',\\\n                     'biorxiv', 'jia', 'dr', 'org', 'using', 'selected', 'lamp', 'osd', 'xf', 'medrxiv','sets', 'peer',\\\n                     'reviewed', 'inactivation', 'preprint', 'prf', 'doi', 'mngs', 'r503', 'https', 'org', 'valent',\\\n                     'tilorone', 'prepared','inactivated', 'preprint', 'number', 'doi', 'perpetuity', 'available', 'estimated',\\\n                     'display', 'reported', 'time', 'cc', 'onset', 'days','copyright', 'ax', 'file','preprint', 'perceived',\\\n                     'bat', 'pangolin', 'ratg13', 'doi', 'preprint', 'org', 'hdl', 'funder', 'reuse', 'allowed','nanopore',\\\n                     'coverage','datasets', 'reference', 'ont', 'supplementary', 'annotation', 'vadr', 'parhyale', 'abundance',\\\n                     'mapped', 'expression','cell', 'il', 'data', 'ifitm3', 'perpetuity','display', 'nd', 'nc', 'group',\\\n                     'admission', 'chickens', 'tree', 'preprint', 'infected', 'time', \\\n                     'confirmed', 'days', 'pro', 'residues', 'kcal', 'org', 'mol', 'hydrogen', 'reuse']\n\n#lemmatize: change tense to present\n#stem: reduce words to their roots\ndef lemmatize_stemming(text):\n    stemmer = stem.PorterStemmer()\n    return stemmer.stem(stem.WordNetLemmatizer().lemmatize(text, pos='v'))\n\n#tokenization: split the string into list of words\n#remove stop words\ndef preprocess(text):\n    result = []\n    if isinstance(text, float) == False:\n        for token in gensim.utils.simple_preprocess(text):\n            if (token not in gensim.parsing.preprocessing.STOPWORDS) and (token not in custom_stop_words):\n                result.append(lemmatize_stemming(token))\n    return result\n","c1b57565":"corpus = dataDf['norm_text'] = dataDf['text'].map(preprocess)","689c68d0":"dictionary = gensim.corpora.Dictionary(corpus)\ndictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)","90f0e654":"bow_corpus = [dictionary.doc2bow(doc) for doc in corpus]","5279e7af":"tfidf = models.TfidfModel(bow_corpus)\ncorpus_tfidf = tfidf[bow_corpus]","74de281c":"lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf,\n                                             id2word=dictionary,\n                                             num_topics=4,\n                                             passes=5,\n                                             workers=4,\n                                             random_state=4)","a58ff922":"vaccinTopic = -1\nfor idx, topic in lda_model_tfidf.print_topics(-1, 20):\n    print('\\nTopic: {} keywords: {}'.format(idx, topic))\n    if 'vaccin' in topic:\n        vaccinTopic = idx\nprint(\"\\n\\nindex of topic related to vaccin is {}\".format(vaccinTopic))","bbc9552d":"vis = pyLDAvis.gensim.prepare(lda_model_tfidf, bow_corpus, dictionary=dictionary)\npyLDAvis.display(vis)","3258e096":"new_columns = ['lda_dominant']\ntopics = [('topic_' + str(i)) for i in range(lda_model_tfidf.num_topics)]\nnew_columns.extend(topics)\ndataDf = pd.concat([dataDf, pd.DataFrame(columns=new_columns)], axis=1);","28b50ca0":"for idx, row in dataDf.iterrows():\n\n    doc = dataDf.loc[idx].norm_text\n    bow = dictionary.doc2bow(doc)\n    res = lda_model_tfidf.get_document_topics(bow)\n\n    for topic_num, val in res:\n        dataDf.loc[idx, topics[topic_num]] = val\n    dataDf.loc[idx, 'lda_dominant'] = np.nanargmax(dataDf.loc[idx, topics].values)","47638a98":"vaccinLdaDf = dataDf.loc[dataDf['lda_dominant'] == vaccinTopic]","0865cc57":"print('number of articles after lda filtering: {}'.format(len(vaccinLdaDf)))","7fb4603d":"np.random.seed(0)\n\n#remove empty text\nvaccinLdaDf = vaccinLdaDf.loc[vaccinLdaDf['norm_text']!=np.nan]\n                \n#re-create Tf-Idf vector for sklearn library                    \nvectorizer = TfidfVectorizer(stop_words='english')\nX = vectorizer.fit_transform(vaccinLdaDf['norm_text'].str.join(' '))\n\n#true_k -> number of clusters\ntrue_k = 10\nkmodel = KMeans(n_clusters=true_k, init='k-means++', max_iter=500, n_init=5)\nkmodel.fit(X)\n       \nprint(\"Top terms per cluster:\")\norder_centroids = kmodel.cluster_centers_.argsort()[:, ::-1]\nterms = vectorizer.get_feature_names()\n\nkMeansDict = {}\nfor i in range(true_k):\n    kMeansDict[i] = []\n    for ind in order_centroids[i, :50]:\n        kMeansDict[i].append(terms[ind])\n        \nkClustersDf =pd.DataFrame.from_records(kMeansDict).add_prefix('cluster_')\nkClustersDf","79bb676e":"# train model\npcamodel = Word2Vec(kMeansDict.values(), min_count=1)\n# fit a 2d PCA model to the vectors\nXvec = pcamodel[pcamodel.wv.vocab]\npca = PCA(n_components=2)\nresult = pca.fit_transform(Xvec)\n# create a scatter plot of the projection\nfig = pyplot.figure(figsize=(10,8))\npyplot.scatter(result[:, 0], result[:, 1])\nwords = list(pcamodel.wv.vocab)\nfor i, word in enumerate(words):\n    pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\npyplot.show()","d85972ed":"cluster = []\nfor i in range(len(kClustersDf.columns)):\n    if kClustersDf.iloc[0,i] in ['vaccin', 'antibodi']:\n        cluster.append(i)\nprint(\"we should keep cluster {} as it relates to vaccin\".format(cluster))","d4e9033c":"vaccinLdaDf['cluster'] = kmodel.predict(X)\nvaccinLdaKnnDf = vaccinLdaDf[vaccinLdaDf['cluster'].isin(cluster)]","3990e939":"print('number of articles after lda and knn filtering: {}'.format(len(vaccinLdaKnnDf)))","852069ab":"workWithDb = False","960ba1fb":"if workWithDb == True:\n    graphdb = Graph(uri=\"http:\/\/192.168.0.103:7687\", auth=(\"neo4j\", \"roche\"))","4ee85d57":"if workWithDb == True:\n    #from py2neo import Graph, Node, Relationship\n    populateDb = False\n\n    # For data insertion\n    INSERT_QUERY = '''\n\n        CREATE (d:Doc {title:$document[3], sha:$document[0], doi:$document[1], pubmed_id:$document[2]})\n        WITH d\n\n        UNWIND range(0,size($array)-3) AS i \n            MERGE (w1:Word {name: $array[i]})\n            ON CREATE SET w1.count = 1 ON MATCH SET w1.count = w1.count + 1\n            MERGE (w2:Word {name: $array[i+1]})\n            ON CREATE SET w2.count = 1 ON MATCH SET w2.count = w2.count + 1\n            MERGE (w3:Word {name: $array[i+2]})\n            ON CREATE SET w3.count = 1 ON MATCH SET w3.count = w3.count + 1\n\n            MERGE (w1)-[r1:NEXT]->(w2)\n              ON CREATE SET r1.count = 1\n              ON MATCH SET r1.count = r1.count + 1\n            MERGE (w1)-[r2:NEXT]->(w3)\n              ON CREATE SET r2.count = 1\n              ON MATCH SET r2.count = r2.count + 1\n            MERGE (w2)-[r3:NEXT]->(w3)\n              ON CREATE SET r3.count = 1\n              ON MATCH SET r3.count = r3.count + 1\n\n            MERGE (d)-[rb1:BELONGS_TO]->(w1)\n                    ON CREATE SET rb1.count = 1\n                    ON MATCH SET rb1.count = rb1.count+1\n            MERGE (d)-[rb2:BELONGS_TO]->(w2)\n                    ON CREATE SET rb2.count = 1\n                    ON MATCH SET rb2.count = rb2.count+1\n            MERGE (d)-[rb3:BELONGS_TO]->(w3)\n                    ON CREATE SET rb3.count = 1\n                    ON MATCH SET rb3.count = rb3.count+1\n    '''\n\n    if workWithDb == True and populateDb == True:\n\n        for idx, row in vaccinLdaKnnDf.iterrows():\n\n            text = vaccinLdaKnnDf.loc[idx].norm_text\n            title = vaccinLdaKnnDf.loc[idx].title\n            doc = vaccinLdaKnnDf.loc[idx, ['sha', 'doi', 'pubmed_id', 'title']].tolist()\n            graphdb.run(INSERT_QUERY, parameters={'array': text, 'document': doc})","4a8d12d0":" if workWithDb == True:\n    try:\n        graphdb.run(\"CALL gds.graph.drop('gow') YIELD graphName\")\n    except:\n        pass\n\n    GOW_QUERY = '''\n    CALL gds.graph.create(\n        'gow',\n        'Word',\n        'NEXT',\n        {\n            relationshipProperties: 'count'\n        }\n    )\n    '''\n    try:\n        graphdb.run(GOW_QUERY)\n    except:\n        pass","cdd8e5b1":"if workWithDb == True:\n    # pagerank algo from gds library\n    PAGERANK_QUERY = '''\n    CALL gds.pageRank.write('gow', {\n      maxIterations: 30,\n      dampingFactor: 0.85,\n      writeProperty: 'pagerank',\n      relationshipWeightProperty: 'count'\n    })\n    '''\n    graphdb.run(PAGERANK_QUERY);","e81e4b67":"if workWithDb == True:\n    regex = re.compile(r'(\\'\\w+\\').*(\\d+.\\d+)')\n    pagerank_results = graphdb.run('MATCH (w:Word) RETURN w.name, w.pagerank ORDER BY w.pagerank DESC LIMIT 300')\n\n    keywords = []\n    for x in pagerank_results:\n        name = x.values(0)[0]\n        num = x.values(1)[0]\n        print(name +\"\\t\\t\\t\"+ str(num))\n        keywords.append(name)","c1ea41ff":"if workWithDb == True:\n    # train model\n    pcamodel = Word2Vec([keywords[:100]], min_count=1)\n    # fit a 2d PCA model to the vectors\n    Xvec = pcamodel[pcamodel.wv.vocab];\n    pca = PCA(n_components=2)\n    result = pca.fit_transform(Xvec)\n    # create a scatter plot of the projection\n    fig = pyplot.figure(figsize=(10,8))\n    pyplot.scatter(result[:, 0], result[:, 1])\n    words = list(pcamodel.wv.vocab)\n    for i, word in enumerate(words):\n        pyplot.annotate(word, xy=(result[i, 0], result[i, 1]));\n    pyplot.show();","5298d884":"if workWithDb == True:\n    # pagerank algo from gds library\n    PAGERANK_QUERY = '''\n    CALL gds.louvain.write('gow', { writeProperty: 'group' })\n    '''\n    graphdb.run(PAGERANK_QUERY);","27ed8ed2":"if workWithDb == True:\n    IFrame(src='..\/input\/neovis-graph\/index_global.html', width=1000, height=700)","d6ceea9c":"if workWithDb == True:\n    IFrame(src='..\/input\/neovis-graph\/index_vaccin.html', width=1000, height=700)","52e5b6a3":"if workWithDb == True:\n    IFrame(src='..\/input\/neovis-graph\/index_antibodi.html', width=1000, height=700)","a8f62d67":"check the repartition of publications between sources","20c28012":"import libraries","2456fe42":"add new columns to data frame to place the topic related probability for each article","628694ac":"all these words are very generic. Most of them are actually the key words of the selected clusters.","a11fb01a":"from now, we will keep only the documents related to vaccine","fd871063":"### most influencial connections among vaccin community","72324be0":"each article comes with a title. Below is the overall distribution of the length of the titles:","f84d0c66":"html for:   most influencial connections among all nodes","24de240f":"# Preprocessing","e4d485ba":"connect to graph DB on neo4j","06315c83":"we reduced the number of articles from 22000 to :","37104cf0":"run pagerank algorithm in order to find the most important words \n> The PageRank algorithm 5 measures the transitive influence or connectivity of nodes. This is the most famous graph algorithm, and was named after Google co-founder Larry Page. We can use this algorithm to find important words based not only on whether they\u2019re followed by lots of other words, but whether those words are themselves important.","7c795a8f":"display the most influencial (connections) across the whole graph. Nodes with the same color belong to the same community. The following query is defined in html file for visualization that relies on neovis.js (ref:appendix).\n> MATCH (p1:Word)-[r:NEXT]->(p2:Word) RETURN *, r.count AS rank ORDER BY rank DESC LIMIT 300","69cfac51":"create dictionary and remove words that are not frequent at all","3a2f46bd":"Show a subset of the community where the word vaccine is located (all the nodes are blue because they belong to many community). We display nodes with the strongest relationships. The following query is defined in html file for visualization that relies on neovis.js (ref:appendix).\n> MATCH (w1:Word{name:'vaccin'}) WITH w1 AS word_interest, w1.group as group_interest MATCH (w2:Word)-[r:NEXT]-(w3:Word) WHERE w2.group = group_interest AND w3.group = group_interest RETURN word_interest,w2,w3,r, r.count AS rank ORDER BY rank DESC LIMIT 300","29c0e119":"### most influencial connections among antibodi community","29606b40":"the visualization of the data base is done via neovis.js library. It is a java script module that have to be installed locally. As Kaggle does not provide this tool, we will plot the screenshots instead. html are presented in the appendix chapter.","86205355":"<!doctype html>\n<html>\n    <head>\n        <title>vaccin_community_strong_relationships<\/title>\n        <style type=\"text\/css\">\n            #viz {\n                width: 900px;\n                height: 700px;\n            }\n        <\/style>\n\t\t<script src=\"https:\/\/rawgit.com\/neo4j-contrib\/neovis.js\/master\/dist\/neovis.js\"><\/script>\n    <\/head>\n\t<script>\n\t\tfunction draw() {\n\t\t\t\tvar config = {\n\t\t\t\t\tcontainer_id: \"viz\",\n\t\t\t\t\tserver_url: \"bolt:\/\/localhost:7687\",\n\t\t\t\t\tserver_user: \"neo4j\",\n\t\t\t\t\tserver_password: \"roche\",\n\t\t\t\t\tlabels: {\n\t\t\t\t\t\t\"Word\": {\n\t\t\t\t\t\t\t\"caption\": \"name\",\n\t\t\t\t\t\t\t\"size\": \"pagerank\",\n\t\t\t\t\t\t\t\"community\": \"group\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\trelationships: {\n\t\t\t\t\t\t\"NEXT\": {\n\t\t\t\t\t\t\t\"thickness\": \"count\",\n\t\t\t\t\t\t\t\"caption\": false\n\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\tinitial_cypher: \"MATCH (w1:Word{name:'vaccin'}) WITH w1 AS word_interest, w1.group as group_interest MATCH (w2:Word)-[r:NEXT]-(w3:Word) WHERE w2.group = group_interest AND w3.group = group_interest RETURN word_interest,w2,w3,r, r.count AS rank ORDER BY rank DESC LIMIT 300\"\n\t\t\t\t\t\n\t\t\t\t};\n\n\t\t\t\tviz = new NeoVis.default(config);\n\t\t\t\tviz.render();\n\t\t\t}\n\t<\/script>\n    <body onload=\"draw()\">\n        <div id=\"viz\"><\/div>\n \n\t\tCypher query: <textarea rows=\"4\" cols=50 id=\"cypher\"><\/textarea><br>\n\t\t<input type=\"submit\" value=\"Submit\" id=\"reload\">\n\t\t<input type=\"submit\" value=\"Stabilize\" id=\"stabilize\">\n\n\n\t<\/body>\n\n\t<script>\n\t\t$(\"#reload\").click(function() {\n\n\t\t\tvar cypher = $(\"#cypher\").val();\n\n\t\t\tif (cypher.length > 3) {\n\t\t\t\tviz.renderWithCypher(cypher);\n\t\t\t} else {\n\t\t\t\tconsole.log(\"reload\");\n\t\t\t\tviz.reload();\n\n\t\t\t}\n\n\t\t});\n\n\t\t$(\"#stabilize\").click(function() {\n\t\t\tviz.stabilize();\n\t\t})\n\n\t<\/script>\n<\/html>","34f5f860":"## populate graph data base","19b36f14":"Here are all important topics that satellite around vaccine. The model seems to return valid information as corona is identified as causing respiratory disease.\nThe virus spike protein and the virus envelop protein seem to be the preferred way to develop a new vaccin. It seems that scientists are already investigating this approach according to recent news...","eb01f3ab":"Show a subset of the community where the word antibodies is located (all the nodes are blue because they belong to many communities). We display nodes with the strongest relationships. The following query is defined in html file for visualization that relies on neovis.js (ref:appendix).\n> MATCH (w1:Word{name:'antibodi'}) WITH w1 AS word_interest, w1.group as group_interest MATCH (w2:Word)-[r:NEXT]-(w3:Word) WHERE w2.group = group_interest AND w3.group = group_interest RETURN word_interest,w2,w3,r, r.count AS rank ORDER BY rank DESC LIMIT 300","df2b99de":"<!doctype html>\n<html>\n    <head>\n        <title>antibodi_community_strong_relationships<\/title>\n        <style type=\"text\/css\">\n            #viz {\n                width: 900px;\n                height: 700px;\n            }\n        <\/style>\n\t\t<script src=\"https:\/\/rawgit.com\/neo4j-contrib\/neovis.js\/master\/dist\/neovis.js\"><\/script>\n    <\/head>\n\t<script>\n\t\tfunction draw() {\n\t\t\t\tvar config = {\n\t\t\t\t\tcontainer_id: \"viz\",\n\t\t\t\t\tserver_url: \"bolt:\/\/localhost:7687\",\n\t\t\t\t\tserver_user: \"neo4j\",\n\t\t\t\t\tserver_password: \"roche\",\n\t\t\t\t\tlabels: {\n\t\t\t\t\t\t\"Word\": {\n\t\t\t\t\t\t\t\"caption\": \"name\",\n\t\t\t\t\t\t\t\"size\": \"pagerank\",\n\t\t\t\t\t\t\t\"community\": \"group\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\trelationships: {\n\t\t\t\t\t\t\"NEXT\": {\n\t\t\t\t\t\t\t\"thickness\": \"count\",\n\t\t\t\t\t\t\t\"caption\": false\n\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\tinitial_cypher: \"MATCH (w1:Word{name:'antibodi'}) WITH w1 AS word_interest, w1.group as group_interest MATCH (w2:Word)-[r:NEXT]-(w3:Word) WHERE w2.group = group_interest AND w3.group = group_interest RETURN word_interest,w2,w3,r, r.count AS rank ORDER BY rank DESC LIMIT 300\"\n\t\t\t\t\t\n\t\t\t\t};\n\n\t\t\t\tviz = new NeoVis.default(config);\n\t\t\t\tviz.render();\n\t\t\t}\n\t<\/script>\n    <body onload=\"draw()\">\n        <div id=\"viz\"><\/div>\n \n\t\tCypher query: <textarea rows=\"4\" cols=50 id=\"cypher\"><\/textarea><br>\n\t\t<input type=\"submit\" value=\"Submit\" id=\"reload\">\n\t\t<input type=\"submit\" value=\"Stabilize\" id=\"stabilize\">\n\n\n\t<\/body>\n\n\t<script>\n\t\t$(\"#reload\").click(function() {\n\n\t\t\tvar cypher = $(\"#cypher\").val();\n\n\t\t\tif (cypher.length > 3) {\n\t\t\t\tviz.renderWithCypher(cypher);\n\t\t\t} else {\n\t\t\t\tconsole.log(\"reload\");\n\t\t\t\tviz.reload();\n\n\t\t\t}\n\n\t\t});\n\n\t\t$(\"#stabilize\").click(function() {\n\t\t\tviz.stabilize();\n\t\t})\n\n\t<\/script>\n<\/html>","5f595636":"filter documents related to vaccine and antibodies","08581fab":"## PageRank algorithms","b9a1fe1c":"# Topic modelling","5544271a":"check what topic is dominant in each article","c12b67eb":"identify the clusters related to vaccine and antibodies","d41b5d94":"text cleaning steps:\n- remove stop words\n- remove custom words\n- lemmatization: return the base or dictionary form of a word\n- stemming: heuristic process that chops off the ends of words","c4e18b7a":"![image.png](attachment:image.png)","13432176":"![image.png](attachment:image.png)","82c9ab8f":"we reduced the number of articles from 22000 to :","790e3a45":"We will now split the words into 10 clusters thanks to  k-means algorithm:\n> k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells.","f44a6ad4":"# LDA filtering: keep documents related to vaccine","ed558726":"check the distribution of publications per year","7b4ff9e6":"# Outlook","b0994ad5":"for example:","7d62c881":"The vaccine group is also very generic. It doesnt give us relevant information. The word most related to vaccine is develop... That means  there is still work to be done. no answers yet.","11ef187a":"load pre-processed words and link them to eachother as long as they come in the same window of 3 words","d9354302":"Participants:\n* Stephane Grandjean - 4772330 - <stephane.grandjean@roche.com>\n* Ioanna Birmpa - 3228119 - <io.birmpa@gmail.com>\n* Romain Guerre - 4891576 - <guerre_romain38@hotmail.com>\n* Said Bouseida - 4894299 - <said.bouseida@roche.com>\n* Robert Mueller - 1147191 - <r.mueller89@gmx.de>\n* Juraj Sibik -  4893774  - <jurkos1@gmail.com>","aefcdea7":"![image.png](attachment:image.png)","ee57c1d7":"The PCA algorithm below shows 2D representation of the keywords","9bb77451":"the metadata present the following features","b2271def":"we populate an external database managed via neo4j community. The display is compromised because kaggle do not have access to neo4j. We will plot screenshots of our work instead.","11a720f8":"We could continue the work by adding the body text to the graph. We could also increase the size of convolution window (3 in our case) connecting the words to each others. Also, we could have explore the data with the same techniques for therapeutics.","25082b66":"for example:","3037b881":"visualize model","902300cd":"html for:   most influencial connections among antibodi community","cafac82a":"the community algorithm is useful for the display below. Nodes with the same color belong to the same community.","d5c54a6a":"for example:","ae53141a":"html for:   most influencial connections among vaccin community","a034f463":"create a projected graph (gow) to be able to run the neo4j algos","7ed55f10":"We import meta data as given for the challenge. Title and Abstract are concatenated in column 'text'. Abstracts with length bigger than 1500 words are removed. That actually concerned one huge article. The article is removed as we try to keep a balanced distribution.","7ed89772":"each article comes wth an abstract. Below is the overall distribution of the length of the title","3dec1b1f":"The result shows the most influencial words in the corpus.","3b8b2875":"<!doctype html>\n<html>\n    <head>\n        <title>global_strong_relatioships<\/title>\n        <style type=\"text\/css\">\n            #viz {\n                width: 900px;\n                height: 700px;\n            }\n        <\/style>\n\t\t<script src=\"https:\/\/rawgit.com\/neo4j-contrib\/neovis.js\/master\/dist\/neovis.js\"><\/script>\n    <\/head>\n\t<script>\n\t\tfunction draw() {\n\t\t\t\tvar config = {\n\t\t\t\t\tcontainer_id: \"viz\",\n\t\t\t\t\tserver_url: \"bolt:\/\/localhost:7687\",\n\t\t\t\t\tserver_user: \"neo4j\",\n\t\t\t\t\tserver_password: \"roche\",\n\t\t\t\t\tlabels: {\n\t\t\t\t\t\t\"Word\": {\n\t\t\t\t\t\t\t\"caption\": \"name\",\n\t\t\t\t\t\t\t\"size\": \"pagerank\",\n\t\t\t\t\t\t\t\"community\": \"group\"\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\trelationships: {\n\t\t\t\t\t\t\"NEXT\": {\n\t\t\t\t\t\t\t\"thickness\": \"count\",\n\t\t\t\t\t\t\t\"caption\": false\n\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\tinitial_cypher: \"MATCH (p1:Word)-[r:NEXT]-(p2:Word) RETURN *, r.count AS rank ORDER BY rank DESC LIMIT 300\"\n\t\t\t\t\t\n\t\t\t\t};\n\n\t\t\t\tviz = new NeoVis.default(config);\n\t\t\t\tviz.render();\n\t\t\t}\n\t<\/script>\n    <body onload=\"draw()\">\n        <div id=\"viz\"><\/div>\n \n\t\tCypher query: <textarea rows=\"4\" cols=50 id=\"cypher\"><\/textarea><br>\n\t\t<input type=\"submit\" value=\"Submit\" id=\"reload\">\n\t\t<input type=\"submit\" value=\"Stabilize\" id=\"stabilize\">\n\n\n\t<\/body>\n\n\t<script>\n\t\t$(\"#reload\").click(function() {\n\n\t\t\tvar cypher = $(\"#cypher\").val();\n\n\t\t\tif (cypher.length > 3) {\n\t\t\t\tviz.renderWithCypher(cypher);\n\t\t\t} else {\n\t\t\t\tconsole.log(\"reload\");\n\t\t\t\tviz.reload();\n\n\t\t\t}\n\n\t\t});\n\n\t\t$(\"#stabilize\").click(function() {\n\t\t\tviz.stabilize();\n\t\t})\n\n\t<\/script>\n<\/html>","aba47455":"# Presentation","904a07bf":"In the rest of the notebook, we are going to work with a concatenation of both title and abstract. Distribution of the size of text to be processed [title, abstract]:","1d25ad17":"# Data exploration","dbd1589f":"## Display graph content","d3fcfb71":"# Graph Database","cccb7b68":"# KNN filtering","12991218":"transform corpus into bag of words array\n> representation of text that describes the occurrence of words within a document. It involves two things: A vocabulary of known words. A measure of the presence of known words.","cc87176b":"We print topics and take care of storing what is the index of vaccine related topic.","b5666e68":"check how much articles have their full text available (True)","5338cb5a":"# Appendix - html scripts for graph visualization","6bf139ae":"# Set up","86f72d98":"# Import meta data","f29884a5":"run LDA algoritm\n> generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics. LDA is an example of a topic model and belongs to the machine learning toolbox and in wider sense to the artificial intelligence toolbox.","0b891aef":"Abstract:\n\nWe focused on the metadata exclusively. We applied NLP techniques on the title and the abstract of each article to find out information about vaccins and therapeutics. We built LDA and KNN models in order to target articles about vaccine exclusively. Thanks to these 2 models we managed to reduce the number of articles from 22000 to 1000 roughly. Then we uploaded this subset of articles and words into a neo4j graph database in order to take advantage of built in algorithm and collect any relevant information. The techniques is original and interesting but not conclusive. The main work is left over to domain scientists to decode and understand connections. ","8015183e":"run community algorithm to identify separated groups of words\n> The Louvain method is a simple, efficient and easy-to-implement method for identifying communities in large networks. The method is a greedy optimization method that attempts to optimize the \"modularity\" of a partition of the network (modularity is defined here). The optimization is performed in two steps. First, the method looks for \"small\" communities by optimizing modularity locally. Second, it aggregates nodes belonging to the same community and builds a new network whose nodes are the communities. These steps are repeated iteratively until a maximum of modularity is attained and a hierarchy of communities is produced.","387c579a":"## Community algorithm (louvain)","beda115e":"### most influencial connections among all nodes","5d88bd16":"transform bag of words into tf-idf array\n> short for term frequency\u2013inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.","0f7685a1":"here we can see that the strongest connection to antibodies is monoclonal... it could be a lead towards the research of antibodies. We see that canin\/dogs, bovin, or murin\/mouse can be the best animal model for testing a vaccine prior to human."}}