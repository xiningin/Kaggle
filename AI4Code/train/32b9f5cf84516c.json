{"cell_type":{"b7fbd29d":"code","f3a7c157":"code","827e0aa6":"code","2669bffd":"code","98881d35":"code","4fd94e09":"code","001d453b":"code","c8a279c7":"code","909b93f5":"code","dccc8ce3":"code","ddedf28d":"markdown"},"source":{"b7fbd29d":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy\nfrom scipy.special import entr\nfrom statsmodels.tsa.ar_model import AutoReg, ar_select_order","f3a7c157":"dataset_path_1st = '..\/input\/bearing-dataset\/1st_test\/1st_test'\ndataset_path_2nd = '..\/input\/bearing-dataset\/2nd_test\/2nd_test'\ndataset_path_3rd = '..\/input\/bearing-dataset\/3rd_test\/4th_test\/txt'","827e0aa6":"# Test for the first file\ndataset = pd.read_csv('..\/input\/bearing-dataset\/2nd_test\/2nd_test\/2004.02.12.10.32.39', sep='\\t')\ndataset.columns = ['Bearing 1','Bearing 2','Bearing 3','Bearing 4']\ndataset.head()","2669bffd":"# raw signal\ndataset[['Bearing 1']].plot(figsize=(18,6));","98881d35":"# old extract function\ndef merge_data(dataset_path, id_set=None):\n    data = pd.DataFrame()\n    for filename in os.listdir(dataset_path):\n        dataset=pd.read_csv(os.path.join(dataset_path, filename), sep='\\t')\n        dataset_mean_abs = np.array(dataset.abs().mean())\n        if id_set == 1:\n            dataset_mean_abs = pd.DataFrame(dataset_mean_abs.reshape(1,8))\n        else:\n            dataset_mean_abs = pd.DataFrame(dataset_mean_abs.reshape(1,4))\n        dataset_mean_abs.index = [filename]\n        data = data.append(dataset_mean_abs)\n    \n    if id_set == 1:\n        data.columns = ['B1_a','B1_b','B2_a','B2_b','B3_a','B3_b','B4_a','B4_b']\n    else:\n        data.columns = ['B1','B2','B3','B4']\n        \n    data.index = pd.to_datetime(data.index, format='%Y.%m.%d.%H.%M.%S')\n    data = data.sort_index()\n    return data","4fd94e09":"def calculate_rms(df):\n    result = []\n    for col in df:\n        r = np.sqrt((df[col]**2).sum() \/ len(df[col]))\n        result.append(r)\n    return result\n\n# extract peak-to-peak features\ndef calculate_p2p(df):\n    return np.array(df.max().abs() + df.min().abs())\n\n# extract shannon entropy (cut signals to 500 bins)\ndef calculate_entropy(df):\n    entropy = []\n    for col in df:\n        entropy.append(scipy.stats.entropy(pd.cut(df[col], 500).value_counts()))\n    return np.array(entropy)\n\ndef time_features(dataset_path, id_set=None):\n    time_features = ['mean','std','skew','kurtosis','entropy','rms','max','p2p']\n    cols1 = ['B1_a','B1_b','B2_a','B2_b','B3_a','B3_b','B4_a','B4_b']\n    cols2 = ['B1','B2','B3','B4']\n    \n    # initialize\n    if id_set == 1:\n        columns = [c+'_'+tf for c in cols1 for tf in time_features]\n        data = pd.DataFrame(columns=columns)\n    else:\n        columns = [c+'_'+tf for c in cols2 for tf in time_features]\n        data = pd.DataFrame(columns=columns)\n    \n    for filename in os.listdir(dataset_path):\n        # read dataset\n        raw_data = pd.read_csv(os.path.join(dataset_path, filename), sep='\\t')\n        \n        # time features\n        mean_abs = np.array(raw_data.abs().mean())\n        std = np.array(raw_data.std())\n        skew = np.array(raw_data.skew())\n        kurtosis = np.array(raw_data.kurtosis())\n        entropy = calculate_entropy(raw_data)\n        rms = np.array(calculate_rms(raw_data))\n        max_abs = np.array(raw_data.abs().max())\n        p2p = calculate_p2p(raw_data)\n        \n        if id_set == 1:\n            mean_abs = pd.DataFrame(mean_abs.reshape(1,8), columns=[c+'_mean' for c in cols1])\n            std = pd.DataFrame(std.reshape(1,8), columns=[c+'_std' for c in cols1])\n            skew = pd.DataFrame(skew.reshape(1,8), columns=[c+'_skew' for c in cols1])\n            kurtosis = pd.DataFrame(kurtosis.reshape(1,8), columns=[c+'_kurtosis' for c in cols1])\n            entropy = pd.DataFrame(entropy.reshape(1,8), columns=[c+'_entropy' for c in cols1])\n            rms = pd.DataFrame(rms.reshape(1,8), columns=[c+'_rms' for c in cols1])\n            max_abs = pd.DataFrame(max_abs.reshape(1,8), columns=[c+'_max' for c in cols1])\n            p2p = pd.DataFrame(p2p.reshape(1,8), columns=[c+'_p2p' for c in cols1])\n        else:\n            mean_abs = pd.DataFrame(mean_abs.reshape(1,4), columns=[c+'_mean' for c in cols2])\n            std = pd.DataFrame(std.reshape(1,4), columns=[c+'_std' for c in cols2])\n            skew = pd.DataFrame(skew.reshape(1,4), columns=[c+'_skew' for c in cols2])\n            kurtosis = pd.DataFrame(kurtosis.reshape(1,4), columns=[c+'_kurtosis' for c in cols2])\n            entropy = pd.DataFrame(entropy.reshape(1,4), columns=[c+'_entropy' for c in cols2])\n            rms = pd.DataFrame(rms.reshape(1,4), columns=[c+'_rms' for c in cols2])\n            max_abs = pd.DataFrame(max_abs.reshape(1,4), columns=[c+'_max' for c in cols2])\n            p2p = pd.DataFrame(p2p.reshape(1,4), columns=[c+'_p2p' for c in cols2])\n            \n        mean_abs.index = [filename]\n        std.index = [filename]\n        skew.index = [filename]\n        kurtosis.index = [filename]\n        entropy.index = [filename]\n        rms.index = [filename]\n        max_abs.index = [filename]\n        p2p.index = [filename]\n        \n        # concat\n        merge = pd.concat([mean_abs, std, skew, kurtosis, entropy, rms, max_abs, p2p], axis=1)\n        data = data.append(merge)\n        \n    if id_set == 1:\n        cols = [c+'_'+tf for c in cols1 for tf in time_features]\n        data = data[cols]\n    else:\n        cols = [c+'_'+tf for c in cols2 for tf in time_features]\n        data = data[cols]\n        \n    data.index = pd.to_datetime(data.index, format='%Y.%m.%d.%H.%M.%S')\n    data = data.sort_index()\n    return data","001d453b":"%%time\nset1 = time_features(dataset_path_1st, id_set=1)\nset2 = time_features(dataset_path_2nd, id_set=2)\nset3 = time_features(dataset_path_3rd, id_set=3)","c8a279c7":"set2.isnull().sum().sum()","909b93f5":"set1.to_csv('set1_timefeatures.csv')\nset2.to_csv('set2_timefeatures.csv')\nset3.to_csv('set3_timefeatures.csv')","dccc8ce3":"set2 = pd.read_csv(\".\/set2_timefeatures.csv\")\nset2.describe().T","ddedf28d":"# Extract Time Features\nReferences:\nhttp:\/\/mkalikatzarakis.eu\/wp-content\/uploads\/2018\/12\/IMS_dset.html"}}