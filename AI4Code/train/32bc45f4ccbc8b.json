{"cell_type":{"808e48fe":"code","61ca4dd3":"code","1abcf08c":"code","9917d4e5":"code","2e62dcd6":"code","5c827ef4":"code","1a233aac":"code","1afb8e3f":"code","40e4ee97":"code","4025a010":"code","895088ff":"code","a667f30a":"code","87987247":"code","3f51ef51":"code","83af0226":"code","dee678c4":"code","1ed3880c":"code","7ed9f754":"markdown","0830f59e":"markdown","408517b1":"markdown","fa919bda":"markdown","8b2f6a72":"markdown","af93d0e7":"markdown","dc81d237":"markdown","c5156b2e":"markdown","5fde0085":"markdown","44fbd518":"markdown"},"source":{"808e48fe":"#Imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\nimport string\n\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nimport re\n\n# from sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.metrics import f1_score","61ca4dd3":"#Take a peak at the data\ntrain = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntrain.head()","1abcf08c":"train.info()","9917d4e5":"#Lets answer our first question... whats the distribution of real to fake look like?\ntmp = train.groupby('target').count()\nsns.barplot(tmp.index, tmp.id)\n\nprint(\"Number of real disasters: {}\".format(tmp[tmp.index == 1].id.values[0]))\nprint(\"Number of fake disasters: {}\".format(tmp[tmp.index == 0].id.values[0]))","2e62dcd6":"def find_num_hashtags(s):\n    arr = s.split()\n    ans = len([word for word in arr if word[0] == '#'])\n    return ans","5c827ef4":"#Create some new columns I think would be useful: num_words, num_hashtags, num_characters\ntrain['num_words'] = train.text.apply(lambda s: len(s.split()))\ntrain['num_hashtags'] = train.text.apply(find_num_hashtags)\ntrain['num_characters'] = train.text.apply(lambda s: len(s))","1a233aac":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.distplot(train[train.target == 1].num_words)\nplt.title('Distribution of num_words in case of real disaster.')\n\nplt.subplot(1,2,2)\nsns.distplot(train[train.target == 0].num_words)\nplt.title('Distribution of num_words in case of fake disaster.')","1afb8e3f":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.distplot(train[train.target == 1].num_hashtags)\nplt.title('Distribution of num_hashtags in case of real disaster.')\n\nplt.subplot(1,2,2)\nsns.distplot(train[train.target == 0].num_hashtags)\nplt.title('Distribution of num_hashtags in case of fake disaster.')","40e4ee97":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.distplot(train[train.target == 1].num_characters)\nplt.title('Distribution of num_characters in case of real disaster.')\n\nplt.subplot(1,2,2)\nsns.distplot(train[train.target == 0].num_characters)\nplt.title('Distribution of num_characters in case of fake disaster.')","4025a010":"# Count keywords\nkeywords = []\ni = 0\nfor word in train.keyword:\n    if word is not np.nan:\n        keywords.append(word)\n\nkeyword_freq = Counter(keywords)","895088ff":"print(\"For the top 10 most occuring keywords:\")\nprint('________________________')\nfor i in range(10):\n    word = keyword_freq.most_common(10)[i][0]\n    print(\"Keyword: {}\".format(word))\n    print(\">>>> Num of occurences in REAL disasters = {}\".format(len(train[(train.keyword == word) & (train.target == 1)])))\n    print(\">>>> Num of occurences in FAKE disasters = {}\".format(len(train[(train.keyword == word) & (train.target == 0)])))\n    print(\"__________________________________\")","a667f30a":"# how many tweets containing a specific keyword are real vs fake?\nfor word in keyword_freq:\n    ratio = len(train[(train.keyword == word) & (train.target == 1)]) \/ len(train[train.keyword == word])\n    train.loc[train.keyword == word, 'keyword_ratio'] = ratio\n    \nkeyword_ratio = train[['keyword','keyword_ratio']].drop_duplicates()","87987247":"# Top ten keywords with the highest ratio\nkeyword_ratio.sort_values('keyword_ratio', ascending=False).head(10)","3f51ef51":"def remove_url(s):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',s)\n\ndef remove_punctuation(s):\n    table = str.maketrans(\"\",\"\",string.punctuation)\n    return s.translate(table)\n\ndef remove_emoji(s):\n    return s.encode('ascii', 'ignore').decode('ascii')\n\ntrain['text_cleaned'] = train.text.apply(remove_url)\ntrain['text_cleaned'] = train.text_cleaned.apply(remove_punctuation)\ntrain['text_cleaned'] = train.text_cleaned.apply(remove_emoji)","83af0226":"tf_idf_vectorizer = TfidfVectorizer()\nX = tf_idf_vectorizer.fit_transform(train['text_cleaned'])\nX_train, X_val, y_train, y_val = train_test_split(X, train['target'], test_size=0.25)","dee678c4":"clf = RidgeClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_val)\nscore = f1_score(predictions, y_val)\nprint(score)","1ed3880c":"scores = cross_val_score(clf, X, train[\"target\"], cv=5, scoring=\"f1\")\nscores","7ed9f754":"### Hashtag Analysis","0830f59e":"## Text Analysis","408517b1":"## TF-IDF","fa919bda":"So it seems that certain words are very useful when determining whether a disaster is real or fake. This seems like a prime candidate for **TF-IDF** which measures the relative importance of words.","8b2f6a72":"## Notes to Myself\nThis is a work in progress so I will be using this section write down any thoughts I have in my head while I explore the data a little bit. I am also going to be including the steps I took to make my analysis.\n\n1. Exploratory Data Analysis:\n    - We want to answer a couple of questions:\n        - What is the distribution of the target variable? (real or fake)\n        - Deep dive into text data\n            - Average length of tweet?\n            - Any correlation between typos and realness\/fakeness?\n            - All caps must mean realness right?...RIGHT?","af93d0e7":"## Data Cleaning\n\n1. Remove stop words (didn't do this because model performance actually dropped)\n2. Remove URLs\n3. Remove punctuation\n4. Remove emojis","dc81d237":"## Keyword Analysis","c5156b2e":"Seems like number of words, characters or hashtags don't really give useful information for differentiating real from fake.","5fde0085":"# Real or Not? NLP with Disaster Tweets\nThe purpose of this notebook is to determine if a person is tweeting about a real disaster or not!","44fbd518":"Seems like some keywords can distinguish between realness and fakeness better than others. Let's continue investigating the keywords feature... I want to know the ratio of real vs fake per keyword."}}