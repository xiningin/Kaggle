{"cell_type":{"80591c3c":"code","82bb174f":"code","6f560be8":"code","39f1bab7":"code","164f4bec":"code","793f7502":"code","8569bb5a":"code","b4e9bcf9":"code","0467ab36":"code","ad1c66d0":"code","a53c4e24":"code","af353dfb":"code","5453df79":"code","f38e6593":"code","253eb05d":"code","e3c5b0b2":"code","159bb64d":"code","59efbca7":"code","273cf737":"code","4f220c4f":"code","c290eafa":"code","4fd2130b":"code","2a3e90e3":"code","c1a8ed4a":"code","de117f46":"code","59bedfef":"code","9a3d06d0":"code","c46b148f":"code","4c5322b8":"code","37196582":"code","6365741a":"code","0b089285":"code","0f09cc90":"code","237b4ce1":"code","fbe7281f":"code","6876b3a6":"code","4234b961":"code","93cd7821":"code","000bf14f":"code","7f39d92b":"code","5b7c8dde":"code","e4765263":"code","2cb43914":"code","ade9892c":"code","d35db5ea":"code","1bd6149e":"code","2354b271":"code","c636f6e2":"code","6703ffa1":"code","9b436309":"markdown","9a24bc4b":"markdown","08f8d8c9":"markdown","8bcbc8b0":"markdown","fad49f10":"markdown","5864061e":"markdown","0d683cca":"markdown","e341a1df":"markdown","e8a72794":"markdown","90b19528":"markdown","c9ba2ca3":"markdown","29e6bc1a":"markdown","d95abc78":"markdown","103fad31":"markdown","e0beead0":"markdown","4b5496c0":"markdown","2ff3917e":"markdown","8b995854":"markdown","c09fe5b9":"markdown","58c28860":"markdown","32cd9e57":"markdown","fa298f08":"markdown"},"source":{"80591c3c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","82bb174f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score,classification_report,plot_confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","6f560be8":"df=pd.read_csv('\/kaggle\/input\/breast-cancer-dataset\/breast-cancer.csv')\ndf.shape","39f1bab7":"df.head()","164f4bec":"df.info()","793f7502":"df['diagnosis']=df['diagnosis'].astype('category')","8569bb5a":"df.duplicated().sum()","b4e9bcf9":"plt.figure(figsize=(16,5))\nsns.heatmap(df.isnull())","0467ab36":"plt.figure(figsize=(18,10\n                   \n                   ))\nsns.heatmap(df.corr())","ad1c66d0":"def correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","a53c4e24":"corr_features = correlation(df, 0.75)\nlen(set(corr_features))","af353dfb":"corr_features","5453df79":"df.drop(columns={'id','area_mean',\n 'area_se',\n 'area_worst',\n 'compactness_worst',\n 'concave points_mean',\n 'concave points_se',\n 'concave points_worst',\n 'concavity_mean',\n 'concavity_se',\n 'concavity_worst',\n 'fractal_dimension_se',\n 'fractal_dimension_worst',\n 'perimeter_mean',\n 'perimeter_se',\n 'perimeter_worst',\n 'radius_worst',\n 'smoothness_worst',\n 'texture_worst'},inplace=True)","f38e6593":"df.head()","253eb05d":"plt.figure(figsize=(10,4))\nsns.countplot(df['diagnosis'],label='count')","e3c5b0b2":"plt.figure(figsize=(16,8))\nsns.countplot(df['radius_mean'],hue=df['diagnosis'],palette='dark')","159bb64d":"plt.figure(figsize=(10,4))\nsns.distplot(df['radius_mean'])\nprint(df['radius_mean'].skew())\nprint(df['radius_mean'].kurt())","59efbca7":"plt.figure(figsize=(10,4))\nsns.histplot(df['radius_mean'])","273cf737":"sns.boxplot(df['radius_mean'])","4f220c4f":"plt.figure(figsize=(10,4))\nsns.distplot(df['compactness_mean'])\nprint(df['compactness_mean'].skew())\nprint(df['compactness_mean'].kurt())","c290eafa":"sns.boxplot(df['compactness_mean'])","4fd2130b":"plt.figure(figsize=(16,8))\nsns.countplot(df['symmetry_worst'],hue=df['diagnosis'],palette='dark')","2a3e90e3":"#Multivariate Analysis\nplt.figure(figsize=(13,5))\nsns.scatterplot(df['radius_mean'],df['texture_mean'],hue=df['diagnosis'])","c1a8ed4a":"plt.figure(figsize=(14,5),)\nsns.scatterplot(df['compactness_mean'],df['smoothness_mean'],hue=df['diagnosis'])","de117f46":"# y includes diagnosis column with M or B values\ny = df.diagnosis\n# drop diagnosis since we are separating labels and features\n# X includes our features\nX = df.drop(columns={'diagnosis'})\n# get the first ten features\ndata_dia = y\ndata = X\ndata_std = (data-data.mean()) \/ (data.std()) # standardization\n# get the first 10 features\ndata = pd.concat([y,data_std.iloc[:,0:12]],axis=1)\ndata = pd.melt(data,id_vars='diagnosis',\n var_name='features',\n value_name='value')\n# make a violin plot\nplt.figure(figsize=(14,8))\nsns.violinplot(x='features', y='value', hue='diagnosis', data=data,split=True, inner='quart')\nplt.xticks(rotation=90)","59bedfef":"plt.figure(figsize=(12,6))\nplot = sns.boxplot(x=df['diagnosis'], y=df['symmetry_worst'], showfliers=False)\nplot.set_title('Graph of texture mean vs diagnosis of tumor')","9a3d06d0":"plt.figure(figsize=(12,6))\nplot = sns.boxplot(x=df['diagnosis'], y=df['radius_se'], showfliers=False)\nplot.set_title('Graph of radius_se vs diagnosis of tumor')","c46b148f":"plt.figure(figsize=(12,6))\nplot = sns.boxplot(x=df['diagnosis'], y=df['compactness_se'], showfliers=False)\nplot.set_title('Graph of radius_se vs diagnosis of tumor')","4c5322b8":"plt.figure(figsize=(12,6))\nplot = sns.boxplot(x=df['diagnosis'], y=df['symmetry_mean'], showfliers=False)\nplot.set_title('Graph of radius_se vs diagnosis of tumor')","37196582":"sns.jointplot(x = df['smoothness_mean'], y = df['smoothness_se'],\n              kind = \"reg\",color='g')\nplt.show()","6365741a":"sns.jointplot(x = df['symmetry_mean'], y = df['symmetry_se'],\n              kind = \"reg\",color='r')\nplt.show()","0b089285":"df.drop(columns={'fractal_dimension_mean','smoothness_se','texture_se','symmetry_se'},inplace=True)","0f09cc90":"sns.pairplot(df,kind='reg',hue='diagnosis')","237b4ce1":"label_encoding=LabelEncoder()\ndf['diagnosis']=label_encoding.fit_transform(df['diagnosis'])","fbe7281f":"df.head()","6876b3a6":"def Remove_outliers(df,col):\n    \n    percentile_25=df[col].quantile(0.25)\n    percentile_75=df[col].quantile(0.75)\n\n    IQR = percentile_75-percentile_25\n    Upper_limit=percentile_75+1.5*IQR\n    Lower_limit=percentile_25-1.5*IQR\n    df[col]=np.where(df[col]>Upper_limit,Upper_limit,\n                           np.where(df[col]<Lower_limit,Lower_limit,df[col]))\n    return df[col]","4234b961":"df['radius_mean']=Remove_outliers(df,'radius_mean')\ndf['texture_mean']=Remove_outliers(df,'texture_mean')\ndf['smoothness_mean']=Remove_outliers(df,'smoothness_mean')\ndf['compactness_mean']=Remove_outliers(df,'compactness_mean')\ndf['symmetry_mean']=Remove_outliers(df,'symmetry_mean')\ndf['radius_se']=Remove_outliers(df,'radius_se')\ndf['compactness_se']=Remove_outliers(df,'compactness_se')\ndf['symmetry_worst']=Remove_outliers(df,'symmetry_worst')","93cd7821":"df.describe()","000bf14f":"X=df.iloc[:,1:]\ny=df.iloc[:,0]","7f39d92b":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=20)","5b7c8dde":"scale=StandardScaler()\nX_train=scale.fit_transform(X_train)\nX_test=scale.fit_transform(X_test)","e4765263":"LC=LogisticRegression()\nLC.fit(X_train,y_train)\ny_pred=LC.predict(X_test)\naccuracy_score(y_test,y_pred)","2cb43914":"RFC=RandomForestClassifier()\nRFC.fit(X_train,y_train)\ny_pred=RFC.predict(X_test)\naccuracy_score(y_test,y_pred)","ade9892c":"ADC=AdaBoostClassifier()\nADC.fit(X_train,y_train)\ny_pred=ADC.predict(X_test)\naccuracy_score(y_test,y_pred)","d35db5ea":"GBC=GradientBoostingClassifier()\nGBC.fit(X_train,y_train)\ny_pred=GBC.predict(X_test)\naccuracy_score(y_test,y_pred)","1bd6149e":"Kn=KNeighborsClassifier()\nKn.fit(X_train,y_train)\ny_pred=Kn.predict(X_test)\naccuracy_score(y_test,y_pred)","2354b271":"def Clf(X,y):\n    \n    target_names=['class_0','class_1']\n    \n    LC=LogisticRegression()\n    LC.fit(X_train,y_train)\n    y_pred=LC.predict(X_test)\n    LC_acc=round(accuracy_score(y_test,y_pred),2)\n    print('Logistic_Regression acc_score: '+ str(LC_acc))\n    print('LC Class_report:'+str(classification_report(y_test,y_pred,target_names=target_names)))\n    print('*'*50)\n    \n    RFC=RandomForestClassifier()\n    RFC.fit(X_train,y_train)\n    y_pred=RFC.predict(X_test)\n    RFC_acc= round(accuracy_score(y_test,y_pred),2)\n    print('RFC acc_score: '+ str(RFC_acc))\n    print('RFC Class_report: '+ str(classification_report(y_test,y_pred,target_names=target_names)))\n    print('*'*50)\n    \n    ADC=AdaBoostClassifier()\n    ADC.fit(X_train,y_train)\n    y_pred=ADC.predict(X_test)\n    ADC_acc=round(accuracy_score(y_test,y_pred),2)\n    print('Adaboost clf acc_score: ' +str(ADC_acc))\n    print('ADC Class_report: '+ str(classification_report(y_test,y_pred,target_names=target_names)))\n    print('*'*50)\n    \n    GBC=GradientBoostingClassifier()\n    GBC.fit(X_train,y_train)\n    y_pred=GBC.predict(X_test)\n    GBC_acc=round(accuracy_score(y_test,y_pred),2)\n    print('GradBoost acc_score: '+ str(GBC_acc))\n    print('GBC Class_report: '+ str(classification_report(y_test,y_pred,target_names=target_names)))\n    print('*'*50)\n    \n    Kn=KNeighborsClassifier()\n    Kn.fit(X_train,y_train)\n    y_pred=Kn.predict(X_test)\n    Kn_acc=round(accuracy_score(y_test,y_pred),2)\n    print('Knn acc_score: ' +str(Kn_acc))\n    print('KNN Class_report: '+ str(classification_report(y_test,y_pred,target_names=target_names)))\n    ","c636f6e2":"Clf(X,y)","6703ffa1":"plot_confusion_matrix(RFC,X_test,y_test)","9b436309":"- **change dtype of diagnose to category**","9a24bc4b":"# 1-Importing Libraries","08f8d8c9":"**Label Encoding**","8bcbc8b0":"- **Most of the tumors lies in size range of (12,15)**","fad49f10":"# 3- EDA\n- **Univariate Analysis**\n- **Biavariate Analysis**\n","5864061e":"**Scaling**","0d683cca":"**Treament of Outliers by using IQR method and capping them.**","e341a1df":"# `Read_Csv File`","e8a72794":"****Selecting Random forests classifier with high accuracy and recall score.****","90b19528":"- **The median for fractal_dimension_mean ,smoothness_se,texture_se symmetry_se are very close to each other.It means,these features does'nt create too much impact on the target variable.**","c9ba2ca3":"- **Analysis of accuracy_score and classification report for different classifiers.**","29e6bc1a":"# 4- Model Building","d95abc78":"- **Dropping fractal_dimension_mean,smoothness_se,texture_se,symmetry_se as they does'nt impact the target very much.**","103fad31":"- **Most of the tumors are beningn and have low mean_radius.**","e0beead0":"- **Radius_mean and texture mean for malignant tumor is higher than for beningn tumor.**","4b5496c0":"- **Smoothness_mean and smoothness_se does'nt have highly linear relationship.**","2ff3917e":"- **Interqurtile range for malignannt tumor is higher and its median level is also on the higher side than beningn tumor.**","8b995854":"- **compactness_mean and smoothness_mean both are higher for Beningn tumor.** ","c09fe5b9":"- **No missing values present in the dataset**","58c28860":"- **All the features represents above,have almost similar impact on the target including,id col will also not creating any impact on target.**\n\n- **So dropping all the cols**","32cd9e57":"- Segregation of features and target","fa298f08":"# 2-Data_Wrangling\n- **Assessment of Data**\n- **Data Cleaning**"}}