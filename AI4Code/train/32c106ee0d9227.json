{"cell_type":{"55252ab2":"code","76017369":"code","b7338874":"code","946c5b6d":"code","4580bee9":"code","828c0a68":"code","7f8333c1":"code","c758d14e":"markdown","687c44f0":"markdown","71717b74":"markdown"},"source":{"55252ab2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76017369":"import sys\n!cp ..\/input\/rapids\/rapids.21.06 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","b7338874":"import io, requests\n\n# download CSV file from GitHub\nurl=\"https:\/\/github.com\/plotly\/datasets\/raw\/master\/tips.csv\"\ncontent = requests.get(url).content.decode('utf-8')\n\n# read CSV from memory\ntips_df = cudf.read_csv(io.StringIO(content))\ntips_df['tip_percentage'] = tips_df['tip']\/tips_df['total_bill']*100\n\n# display average tip by dining party size\nprint(tips_df.groupby('size').tip_percentage.mean())","946c5b6d":"from cuml.ensemble import RandomForestClassifier as cumlRandomForestClassifier\nfrom sklearn.datasets import load_iris\nimport numpy as np\n\nX, y = load_iris(return_X_y=True)\nX, y = X.astype(np.float32), y.astype(np.int32)\nclf = cumlRandomForestClassifier(max_depth=300, random_state=0, n_estimators=10)\nclf.fit(X, y)\n\ncheckpoint_path = '.\/checkpoint.tl'\n# Export cuML RF model as Treelite checkpoint\nclf.convert_to_treelite_model().to_treelite_checkpoint(checkpoint_path)","4580bee9":"\n# \u9884\u6d4b\nclf.predict(X)","828c0a68":"import treelite\n\n# The checkpoint file has been copied over\ncheckpoint_path = '.\/checkpoint.tl'\ntl_model = treelite.Model.deserialize(checkpoint_path)\nout_prob = treelite.gtil.predict(tl_model, X, pred_margin=True)\nprint(out_prob)","7f8333c1":"dir(clf)","c758d14e":"# \u975egpu\u63a8\u7406","687c44f0":"# Gpu\u8fd0\u884c\u968f\u673a\u68ee\u6797","71717b74":"# \u6587\u6863\n\nhttps:\/\/docs.rapids.ai\/"}}