{"cell_type":{"67ac10fa":"code","ef7c8de6":"code","c5da995a":"code","7caf6cdc":"code","856f92a3":"code","a9955862":"code","032ffb27":"code","65219b79":"code","bbe55118":"code","4b175784":"code","0a0282e4":"code","b1e06356":"code","d037efb3":"code","90d7cca6":"code","9be73583":"code","e97a29f7":"code","a388facc":"code","916a25ae":"code","e858ac3c":"code","58cf7ec7":"code","62091286":"code","b8110fe2":"code","c9ea4bb5":"code","5030eeec":"code","67f4fbb8":"code","6514ef45":"code","bbfba785":"code","d3e051e7":"code","319448a1":"code","f34ac7d9":"code","1c9599c3":"code","417960e8":"code","cee2ea30":"code","6dc6fcc0":"markdown","390aec09":"markdown"},"source":{"67ac10fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ef7c8de6":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_main=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","c5da995a":"test=test_main","7caf6cdc":"train.head()","856f92a3":"test.isnull().sum()","a9955862":"train.isnull().sum()","032ffb27":"train['Age']=train['Age'].fillna(train['Age'].median())\ntrain['Fare']=train['Fare'].fillna(train['Fare'].median())\n\ntest['Age']=test['Age'].fillna(test['Age'].median())\ntest['Fare']=test['Fare'].fillna(test['Fare'].median())","65219b79":"\n\ntrain[['Pclass','Survived','SibSp','Parch']]=train[['Pclass','Survived','SibSp','Parch']].astype('str')\n\ntest[['Pclass','SibSp','Parch']]=test[['Pclass','SibSp','Parch']].astype('str')\n\n\n\ntrain=train.drop(['Cabin','Name','Embarked','PassengerId','Ticket'],axis=1)\n\n\ntest=test.drop(['Cabin','Name','Embarked','PassengerId','Ticket'],axis=1)\n#train=train.dropna()\n\n#test=test.dropna()\n\n\ntrain.Sex=train.Sex.replace({'male':1,'female':0})\n\ntest.Sex=test.Sex.replace({'male':1,'female':0})\n\nfrom sklearn.utils import resample\n\n\n\n\ndf_Parch_0 = resample(train[train['Parch']=='0'],n_samples=500,replace=True,random_state=1)\ndf_Parch_1 = resample(train[train['Parch']=='1'],n_samples=500,replace=True,random_state=1)\n\ndf_Parch_2 = resample(train[train['Parch']=='2'],n_samples=500,replace=True,random_state=1)\n\ndf_Parch_3 = resample(train[train['Parch']=='3'],n_samples=500,replace=True,random_state=1)\n\ndf_Parch_4 = resample(train[train['Parch']=='4'],n_samples=500,replace=True,random_state=1)\n\ndf_Parch_5 = resample(train[train['Parch']=='5'],n_samples=500,replace=True,random_state=1)\ndf_Parch_6 = resample(train[train['Parch']=='6'],n_samples=500,replace=True,random_state=1)\n#df_survived_1=resample(tita[tita['Survived']=='1'],n_samples=500,replace=True,random_state=1)\n#df_survived_1=resample(tita[tita['Survived']=='0'],n_samples=500,replace=True,random_state=1)\n\n\n\n\ntrain=pd.concat([df_Parch_0,df_Parch_1,df_Parch_2,df_Parch_3,df_Parch_4,df_Parch_5,df_Parch_6])","bbe55118":"train.head()","4b175784":"test.head()","0a0282e4":"x=train.drop('Survived',axis=1)\ny=train['Survived']\n","b1e06356":"test=pd.get_dummies(test)","d037efb3":"x=pd.get_dummies(x)","90d7cca6":"x=x.drop(['SibSp_0','Parch_0'],axis=1)\n\nx.shape","9be73583":"test=test.drop(['SibSp_0','Parch_0','Parch_9'],axis=1)\n\ntest.shape","e97a29f7":"from sklearn.preprocessing import StandardScaler","a388facc":"features=['Age','Fare']\nsc=StandardScaler()\n\nsc.fit(x[features].values)\nx[features]=sc.transform(x[features].values)\ntest[features]=sc.transform(test[features].values)\n\nx.head()\n","916a25ae":"test.head()","e858ac3c":"test.shape","58cf7ec7":"x.shape","62091286":"from sklearn.model_selection import train_test_split","b8110fe2":"xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=12)","c9ea4bb5":"#importing the requried libraries for model designing.\nfrom  keras.models import Sequential\nfrom keras.layers import Dense","5030eeec":"# Initialising the NN\nmodel = Sequential()\n\n# layers\nmodel.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu', input_dim = 18))\nmodel.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n","67f4fbb8":"model.summary()","6514ef45":"# Train the ANN\nhistory=model.fit(xtrain,ytrain, batch_size = 32, epochs = 200,validation_data=(xtest,ytest))","bbfba785":"from matplotlib import pyplot\nimport seaborn as sns","d3e051e7":"# plot loss during training\npyplot.subplot(211)\npyplot.title('Loss')\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\n# plot accuracy during training\npyplot.subplot(212)\npyplot.title('Accuracy')\npyplot.plot(history.history['acc'], label='train')\npyplot.plot(history.history['val_acc'], label='test')\npyplot.legend()\npyplot.show()","319448a1":"ypred=model.predict(test)","f34ac7d9":"y_final = (ypred > 0.5).astype(int).reshape(test.shape[0])","1c9599c3":"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_main[\"PassengerId\"],\n        \"Survived\": y_final\n    })","417960e8":"submission.head()","cee2ea30":"submission.to_csv('tita_nn_sub.csv',index=False)","6dc6fcc0":"Keras is used as backend and Neural networks is used for Model archtecture.","390aec09":"Importing the datasets"}}