{"cell_type":{"d45e8059":"code","8570e4e4":"code","39687696":"code","5cbce6b7":"code","bfb5f289":"code","bebc8265":"code","d5366024":"code","e9296bd7":"code","2f3bae51":"code","2901c331":"code","2afa8638":"code","0c9a60ec":"code","5d72eeab":"code","6f1877c8":"code","4c57689b":"code","c1ca759f":"code","9f7677c1":"code","4e277f10":"code","a62742c3":"code","c473b0e0":"code","772391f4":"code","8e5ef1cd":"code","ca0c701b":"code","8fc4bf6f":"code","544a41b8":"code","4d93f224":"code","c285a809":"code","d82857b1":"code","c9904f3a":"code","86e937b7":"code","30083ef6":"code","c9b29b9a":"code","633dff92":"code","333d505f":"code","936bc79d":"code","a3f62deb":"code","3586ad47":"code","dee6f95a":"code","7ff2c842":"code","9c2706c7":"code","0dfe9d25":"code","4bae412f":"code","97d5843c":"code","8270a962":"code","5fd9e45a":"code","fa03894f":"code","1bbde2bc":"code","79009982":"code","d5dffa9d":"code","67bc529c":"code","dbb7aa3c":"code","863f5650":"code","b6af04b5":"code","85a81eb0":"code","a699d0a4":"code","f786465d":"code","4d6cfe00":"code","db39bf08":"code","c3e5d3a1":"code","c864765e":"code","45dea82a":"code","f9e52429":"code","8da55002":"code","6dbe31b6":"code","26e11f48":"code","7338d42f":"code","5a8e8ca4":"code","0e9e83e9":"code","4d41f694":"code","de84ca73":"code","22babe0c":"code","ed9b8413":"code","f12ea1d0":"code","dae5b2e9":"code","02ff140c":"markdown","6d6a9fde":"markdown","051b393f":"markdown","3c3be8b9":"markdown","3e975305":"markdown","72535143":"markdown","4f407873":"markdown","aeb2e75e":"markdown","e5844ea3":"markdown","58836ce4":"markdown","4a5ecadf":"markdown","ca99870b":"markdown","0fa9ca0c":"markdown","99994c60":"markdown","ebf0d7f7":"markdown","67a3de18":"markdown","271c7e41":"markdown","92546281":"markdown","2ab3027f":"markdown","81d7e925":"markdown","4e04c579":"markdown","9c9dd71f":"markdown","3a070bee":"markdown","a084b412":"markdown","9a636dbe":"markdown","415a7975":"markdown","491a8e02":"markdown","2c284c97":"markdown","e8156646":"markdown","8c3f4ffc":"markdown","b7740e0c":"markdown","c9a38600":"markdown","7bc95012":"markdown","bee982cd":"markdown","0c359f1b":"markdown","031fbff7":"markdown","93f7b93c":"markdown"},"source":{"d45e8059":"!pip install -U missingno","8570e4e4":"!pip install fuzzywuzzy","39687696":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numexpr\nimport math\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport missingno as msno\n\nimport gc\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\", font_scale=1.75)\n\n# prettify plots\nplt.rcParams['figure.figsize'] = [20.0, 5.0]\nsns.set_palette(sns.color_palette(\"muted\"))\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cbce6b7":"def strip_spaces_from_all_columns(dataframe: pd.DataFrame) -> pd.DataFrame:\n    string_type_cols = dataframe.columns[\n        (dataframe.dtypes == 'object') | \n        (dataframe.dtypes == 'str')\n    ]\n    \n    for each_column in string_type_cols:\n        dataframe[each_column] = dataframe[each_column].apply(lambda x: x.strip() if type(x) == 'str' else x)\n\n    category_type_cols = dataframe.columns[dataframe.dtypes == 'category']\n    for each_column in category_type_cols:\n        dataframe[each_column] = dataframe[each_column].astype('str')\n        dataframe[each_column] = dataframe[each_column].apply(lambda x: x.strip())\n        dataframe[each_column] = dataframe[each_column].astype('category')\n    \n    if (len(string_type_cols) > 0) or (len(category_type_cols) > 0):\n        print(f'Stripped leading and trailing spaces from these columns: {string_type_cols}, {category_type_cols}')\n\n    return dataframe","bfb5f289":"### Reference: https:\/\/hackersandslackers.com\/compare-rows-pandas-dataframes\/\ndef dataframe_difference(first: pd.DataFrame, other: pd.DataFrame, which=None):\n    \"\"\"Find rows which are different between two DataFrames.\"\"\"\n    comparison_df = first.merge(\n        other,\n        indicator=True,\n        how='inner'\n    )\n    if which is None:\n        diff_df = comparison_df[comparison_df['_merge'] != 'both']\n    else:\n        diff_df = comparison_df[comparison_df['_merge'] == which]\n    return diff_df","bebc8265":"DATASET_UPLOAD_FOLDER='\/kaggle\/working\/upload'\nPREPROCESSED_DATASET_UPLOAD_FOLDER='\/kaggle\/working\/upload\/preprocessed-kaggle-2017-to-2020'\nNOT_AVAILABLE = \"Unknown \/ Not Specified\"","d5366024":"%%bash\nUPLOAD_FOLDER=\"\/kaggle\/working\/upload\"\nPREPROCESSED_UPLOAD_FOLDER='\/kaggle\/working\/upload\/preprocessed-kaggle-2017-to-2020'\nmkdir -p ${UPLOAD_FOLDER} ${PREPROCESSED_UPLOAD_FOLDER}\ncp -fr \/kaggle\/input\/stack-overflow-developer-survey-2020\/* ${UPLOAD_FOLDER} || true\n\nfolders=( \"kaggle-survey-2020\" \"kaggle-survey-2019\" \"kaggle-survey-2018\" \"kaggle-survey-2017\" \"so-survey-2017\" \"stack-overflow-developer-survey-2020\" \n\"cleaned-mcr-kaggle-survey-2019\" \"stack-overflow-2018-developer-survey\" \"stack-overflow-developer-survey-results-2019\"\n\"kaggle-survey-20172020-merged-data\" \"world-development-indicators\" )\n\nfor each_folder in \"${folders[@]}\"\ndo\n    echo \"~~~ Zipping files in ${each_folder}\"\n    cd \"\/kaggle\/input\/${each_folder}\"\n    zip -r9 ${UPLOAD_FOLDER}\/${each_folder}.zip *\n    echo \"~~~ ${each_folder}.zip ready to be used\/copied.\"\n    echo \"\"\n    cd ..\ndone","e9296bd7":"def check_missing_values(dataframe):\n    missing_values_data = []\n    for column in list(dataframe.columns):\n        values = (dataframe[column].isna()).value_counts()\n        value = 0\n        if len(values) > 1:\n            value = values[1]\n\n        missing_values_data.append({'column_name': column, 'missing_values_count': value})\n        \n    df_missing_values = pd.DataFrame(missing_values_data)\n    return df_missing_values.sort_values(by='missing_values_count', ascending=False)","2f3bae51":"kaggle_questions_and_responses_ref_df = pd.read_csv('..\/input\/kaggle-survey-20172020-merged-data\/kaggle_survey_17_20_v2.csv')\nprint(f\"Before kaggle_questions_and_responses_ref_df: {kaggle_questions_and_responses_ref_df.shape[0]}\")\nkaggle_questions_and_responses_ref_df = kaggle_questions_and_responses_ref_df.fillna(NOT_AVAILABLE)\nif 'index' in kaggle_questions_and_responses_ref_df.columns:\n    kaggle_questions_and_responses_ref_df = kaggle_questions_and_responses_ref_df.drop('index', axis=1)\nfinal_rows_count = kaggle_questions_and_responses_ref_df.shape[0]\nprint(f\"After kaggle_questions_and_responses_ref_df: {final_rows_count}\")\nrows_count_after_dropping_duplicates = kaggle_questions_and_responses_ref_df.drop_duplicates(keep='first').shape[0]\nprint('if duplicates dropped in kaggle_questions_and_responses_ref_df: ' \\\n      f\"{rows_count_after_dropping_duplicates} (difference: {final_rows_count - rows_count_after_dropping_duplicates})\")\nkaggle_questions_and_responses_ref_df.head()","2901c331":"def load_dataset(filepath: str, column_mappings: dict, encoding='utf-8') -> pd.DataFrame:\n    dataset = pd.read_csv(filepath, encoding=encoding)\n    dataset = dataset.rename(columns=column_mappings)\n    dataset = dataset.drop([0], errors='ignore')\n    columns_found = list(set(column_mappings.values()) & set(dataset.columns))\n    columns_missing = list(set(column_mappings.values()) - set(columns_found))\n    if columns_missing:\n        dataset[columns_missing] = NOT_AVAILABLE\n        print(f'columns missing (replaced with \"{NOT_AVAILABLE}\" values):', columns_missing)\n    return dataset[list(column_mappings.values())]","2afa8638":"question_id_to_human_readable_2017 = {\n    'Age':'Age',\n    'GenderSelect':'Gender',\n    'Country':'Country',\n    'FormalEducation':'Degree',\n    'CurrentJobTitleSelect':'Job Title',\n    'EmployerSize':'Company Size',\n    #'EmployerSizeChange':'Team Size',\n    #'EmployerMLTime':'ML Status in Company',\n    'CompensationAmount':'Compensation Status',\n    'N\/A1' : 'Current role experience (in years)',\n    'N\/A2': 'Role Important at work',\n    'N\/A11': 'Programming language choice',\n    'LanguageRecommendationSelect': 'Recommend Programming language', \n    'N\/A12': 'Coding experience (in years)', ## CodeWriter field does not have the right data for this year\n    'N\/A3': 'Notebook product', \n    'N\/A4': 'Computing platform', \n    'N\/A5': '% of current ML\/DS training categories',\n    'HardwarePersonalProjectsSelect': 'Specialised HW',\n    'N\/A6': 'TPU Usage',      # not available in 2018\n    'N\/A7': 'ML Methods experience (in years)',\n    'N\/A8': 'Tools to manage ML experiments', # not available  in 2018\n    'N\/A9': 'Completed DS courses', # also check CoursePlatformSelect\n    'N\/A10':'Favourite media sources'\n}\nkaggle_2017 = load_dataset('..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv', question_id_to_human_readable_2017, encoding='latin-1')\nkaggle_2017['Year'] = 2017\nkaggle_2017.head()","0c9a60ec":"question_id_to_human_readable_2018 = {\n    'Time from Start to Finish (seconds)':'Time',\n    'Q2':'Age',\n    'Q1':'Gender',\n    'Q3':'Country',\n    'Q4':'Degree',\n    'Q6':'Job Title',\n    # 'Q8':'Team Size', ## wrong\n    # 'Q9':'Company Size', ## wrong                       \n    'Q10':'ML Status in Company', \n    'Q9':'Compensation Status',\n    # 'Q11':'Money Spent' ## wrong    \n    'Q8' : 'Current role experience (in years)',\n    'Q11_Part_1': 'Role Important at work 1',\n    'Q11_Part_2': 'Role Important at work 2',\n    'Q11_Part_3': 'Role Important at work 3',\n    'Q11_Part_4': 'Role Important at work 4',\n    'Q11_Part_5': 'Role Important at work 5',\n    'Q11_Part_6': 'Role Important at work 6',\n    'Q11_Part_7': 'Role Important at work 7',\n    'Q11_OTHER_TEXT': 'Role Important at work 8',\n    'Q17': 'Programming language choice', \n#     'N\/A1': 'Recommend Programming language', \n    'Q14_Part_1': 'Notebook product 1', \n    'Q14_Part_2': 'Notebook product 2', \n    'Q14_Part_3': 'Notebook product 3',     \n    'Q14_Part_4': 'Notebook product 4', \n    'Q14_Part_5': 'Notebook product 5', \n    'Q14_Part_6': 'Notebook product 6',     \n    'Q14_Part_7': 'Notebook product 7', \n    'Q14_Part_8': 'Notebook product 8', \n    'Q14_Part_9': 'Notebook product 9',     \n    'Q14_Part_10': 'Notebook product 10', \n    'Q14_Part_11': 'Notebook product 11',     \n    'Q14_OTHER_TEXT': 'Notebook product 12',\n    'Q15_Part_1': 'Cloud Computing platform 1', \n    'Q15_Part_2': 'Cloud Computing platform 2', \n    'Q15_Part_3': 'Cloud Computing platform 3', \n    'Q15_Part_4': 'Cloud Computing platform 4', \n    'Q15_Part_5': 'Cloud Computing platform 5', \n    'Q15_Part_6': 'Cloud Computing platform 6', \n    'Q15_Part_7': 'Cloud Computing platform 7',     \n    'Q15_OTHER_TEXT': 'Computing platform 8',  \n    'Q35_Part_1': '% of current ML\/DS training categories 1',\n    'Q35_Part_2': '% of current ML\/DS training categories 2',\n    'Q35_Part_3': '% of current ML\/DS training categories 3',    \n    'Q35_Part_4': '% of current ML\/DS training categories 4',\n    'Q35_Part_5': '% of current ML\/DS training categories 5',\n    'Q35_Part_6': '% of current ML\/DS training categories 6',    \n    'Q35_OTHER_TEXT': '% of current ML\/DS training categories 7',\n#     'N\/A1': 'Specialised HW', # not available in 2018\n#     'N\/A2': 'TPU Usage',      # not available in 2018\n#     'N\/A3': 'ML Methods experience (in years)',  # not available in 2018\n#     'N\/A4': 'Tools to manage ML experiments', # not available  in 2018\n    'Q36_Part_1': 'Completed DS courses 1',\n    'Q36_Part_2': 'Completed DS courses 2',\n    'Q36_Part_3': 'Completed DS courses 3',    \n    'Q36_Part_4': 'Completed DS courses 4',\n    'Q36_Part_5': 'Completed DS courses 5',\n    'Q36_Part_6': 'Completed DS courses 6',    \n    'Q36_Part_7': 'Completed DS courses 7',\n    'Q36_Part_8': 'Completed DS courses 8',\n    'Q36_Part_9': 'Completed DS courses 9',    \n    'Q36_Part_10': 'Completed DS courses 10',\n    'Q36_Part_11': 'Completed DS courses 11',\n    'Q36_Part_12': 'Completed DS courses 12',    \n    'Q36_Part_13': 'Completed DS courses 13',  \n    'Q36_OTHER_TEXT': 'Completed DS courses 14',\n    'Q38_Part_1':'Favourite media sources 1',\n    'Q38_Part_2':'Favourite media sources 2',\n    'Q38_Part_3':'Favourite media sources 3',\n    'Q38_Part_4':'Favourite media sources 4',\n    'Q38_Part_5':'Favourite media sources 5',    \n    'Q38_Part_6':'Favourite media sources 6',\n    'Q38_Part_7':'Favourite media sources 7',\n    'Q38_Part_8':'Favourite media sources 8',\n    'Q38_Part_9':'Favourite media sources 9',\n    'Q38_Part_10':'Favourite media sources 10',\n    'Q38_Part_11':'Favourite media sources 11',\n    'Q38_Part_12':'Favourite media sources 12',\n    'Q38_Part_13':'Favourite media sources 13',\n    'Q38_Part_14':'Favourite media sources 14',\n    'Q38_Part_15':'Favourite media sources 15',\n    'Q38_Part_16':'Favourite media sources 16',\n    'Q38_Part_17':'Favourite media sources 17',\n    'Q38_Part_18':'Favourite media sources 18',    \n    'Q38_Part_19':'Favourite media sources 19',        \n    'Q38_Part_20':'Favourite media sources 20',        \n    'Q38_Part_21':'Favourite media sources 21',\n    'Q38_Part_22':'Favourite media sources 22',\n    'Q38_OTHER_TEXT': 'Favourite media sources 23'\n}\nkaggle_2018 = load_dataset('..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv', question_id_to_human_readable_2018)\nkaggle_2018['Year'] = 2018\nkaggle_2018.head()","5d72eeab":"question_id_to_human_readable_2019 = {\n    'Time from Start to Finish (seconds)':'Time',\n    'Q1':'Age',\n    'Q2':'Gender',\n    'Q3':'Country',\n    'Q4':'Degree',\n    'Q5':'Job Title',\n    'Q6':'Team Size', ## wrong\n#     'Q9':'Company Size', ## wrong                       \n    'Q10':'Compensation Status',\n    'Q8':'ML Status in Company',     \n    # 'Q11':'Money Spent' ## wrong        \n#     'N\/A1' : 'Current role experience (in years)',\n    'Q9_Part_1': 'Role Important at work 1',\n    'Q9_Part_2': 'Role Important at work 2',\n    'Q9_Part_3': 'Role Important at work 3',\n    'Q9_Part_4': 'Role Important at work 4',\n    'Q9_Part_5': 'Role Important at work 5',\n    'Q9_Part_6': 'Role Important at work 6',\n    'Q9_Part_7': 'Role Important at work 7',\n    'Q9_OTHER_TEXT': 'Role Important at work 8',\n    'Q18_Part_1': 'Programming language choice 1', \n    'Q18_Part_2': 'Programming language choice 2',     \n    'Q18_Part_3': 'Programming language choice 3', \n    'Q18_Part_4': 'Programming language choice 4', \n    'Q18_Part_5': 'Programming language choice 5', \n    'Q18_Part_6': 'Programming language choice 6', \n    'Q18_Part_7': 'Programming language choice 7', \n    'Q18_Part_8': 'Programming language choice 8',   \n    'Q18_Part_9': 'Programming language choice 9',   \n    'Q18_Part_10': 'Programming language choice 10',   \n    'Q18_Part_11': 'Programming language choice 11',   \n    'Q18_Part_12': 'Programming language choice 12',       \n    'Q19_OTHER_TEXT': 'Programming language choice 13',\n    'Q19': 'Recommend Programming language', \n    'Q17_Part_1': 'Notebook product 1', \n    'Q17_Part_2': 'Notebook product 2', \n    'Q17_Part_3': 'Notebook product 3',     \n    'Q17_Part_4': 'Notebook product 4', \n    'Q17_Part_5': 'Notebook product 5', \n    'Q17_Part_6': 'Notebook product 6',     \n    'Q17_Part_7': 'Notebook product 7', \n    'Q17_Part_8': 'Notebook product 8', \n    'Q17_Part_9': 'Notebook product 9',     \n    'Q17_Part_10': 'Notebook product 10', \n    'Q17_Part_11': 'Notebook product 11',    \n    'Q17_Part_12': 'Notebook product 12',    \n    'Q17_OTHER_TEXT': 'Notebook product 13',\n    'Q29_Part_1': 'Cloud Computing platform 1', \n    'Q29_Part_2': 'Cloud Computing platform 2', \n    'Q29_Part_3': 'Cloud Computing platform 3', \n    'Q29_Part_4': 'Cloud Computing platform 4', \n    'Q29_Part_5': 'Cloud Computing platform 5', \n    'Q29_Part_6': 'Cloud Computing platform 6', \n    'Q29_Part_7': 'Cloud Computing platform 7',   \n    'Q29_Part_7': 'Cloud Computing platform 8',   \n    'Q29_Part_7': 'Cloud Computing platform 9',   \n    'Q29_Part_7': 'Cloud Computing platform 10',   \n    'Q29_Part_7': 'Cloud Computing platform 11',  \n    'Q29_Part_7': 'Cloud Computing platform 12',    \n    'Q29_OTHER_TEXT': 'Computing platform 13',  \n#     'N\/A2': '% of current ML\/DS training categories 1',\n#     'N\/A3': '% of current ML\/DS training categories 2',\n#     'N\/A4': '% of current ML\/DS training categories 3',    \n#     'N\/A5': '% of current ML\/DS training categories 4',\n#     'N\/A6': '% of current ML\/DS training categories 5',\n#     'N\/A7': '% of current ML\/DS training categories 6',    \n#     'N\/A8': '% of current ML\/DS training categories 7',\n    'Q21_Part_1': 'Specialised HW 1',\n    'Q21_Part_2': 'Specialised HW 2',\n    'Q21_Part_3': 'Specialised HW 3',\n    'Q21_Part_4': 'Specialised HW 4',\n    'Q21_Part_5': 'Specialised HW 5',\n    'Q21_Part_6': 'Specialised HW 6',\n    'Q21_OTHER_TEXT': 'Specialised HW 7',    \n    'Q22': 'TPU Usage',      \n    'Q23': 'ML Methods experience (in years)', \n#     'N\/A9': 'Tools to manage ML experiments', \n    'Q13_Part_1': 'Completed DS courses 1',\n    'Q13_Part_2': 'Completed DS courses 2',\n    'Q13_Part_3': 'Completed DS courses 3',    \n    'Q13_Part_4': 'Completed DS courses 4',\n    'Q13_Part_5': 'Completed DS courses 5',\n    'Q13_Part_6': 'Completed DS courses 6',    \n    'Q13_Part_7': 'Completed DS courses 7',\n    'Q13_Part_8': 'Completed DS courses 8',\n    'Q13_Part_9': 'Completed DS courses 9',    \n    'Q13_Part_10': 'Completed DS courses 10',\n    'Q13_Part_11': 'Completed DS courses 11',\n    'Q13_Part_12': 'Completed DS courses 12',    \n    'Q13_Part_13': 'Completed DS courses 13',  \n    'Q13_OTHER_TEXT': 'Completed DS courses 14',\n    'Q12_Part_1':'Favourite media sources 1',\n    'Q12_Part_2':'Favourite media sources 2',\n    'Q12_Part_3':'Favourite media sources 3',\n    'Q12_Part_4':'Favourite media sources 4',\n    'Q12_Part_5':'Favourite media sources 5',    \n    'Q12_Part_6':'Favourite media sources 6',\n    'Q12_Part_7':'Favourite media sources 7',\n    'Q12_Part_8':'Favourite media sources 8',\n    'Q12_Part_9':'Favourite media sources 9',\n    'Q12_Part_10':'Favourite media sources 10',\n    'Q12_Part_11':'Favourite media sources 11',\n    'Q12_Part_12':'Favourite media sources 12',\n    'Q12_OTHER_TEXT': 'Favourite media sources 13'\n}\nkaggle_2019 = load_dataset('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv', question_id_to_human_readable_2019)\nkaggle_2019['Year'] = 2019\nkaggle_2019.head()","6f1877c8":"question_id_to_human_readable_2020 = {\n    'Time from Start to Finish (seconds)':'Time',\n    'Q1':'Age',\n    'Q2':'Gender',\n    'Q3':'Country',\n    'Q4':'Degree',\n    'Q5':'Job Title',\n    'Q20':'Company Size',\n    'Q21':'Team Size',\n    'Q22':'ML Status in Company',\n    'Q24':'Compensation Status',\n    'Q25':'Money Spent',\n    'Q6': 'Coding experience (in years)', \n    'Q7_Part_1': 'Programming language choice 1', \n    'Q7_Part_2': 'Programming language choice 2', \n    'Q7_Part_3': 'Programming language choice 3', \n    'Q7_Part_4': 'Programming language choice 4', \n    'Q7_Part_5': 'Programming language choice 5', \n    'Q7_Part_6': 'Programming language choice 6',     \n    'Q7_Part_7': 'Programming language choice 7',     \n    'Q7_Part_8': 'Programming language choice 8',    \n    'Q7_Part_9': 'Programming language choice 9', \n    'Q7_Part_10': 'Programming language choice 10', \n    'Q7_Part_11': 'Programming language choice 11', \n    'Q7_Part_12': 'Programming language choice 12',     \n    'Q7_OTHER': 'Programming language choice 13', \n    'Q8': 'Recommend Programming language', \n    'Q10_Part_1': 'Notebook product 1', \n    'Q10_Part_2': 'Notebook product 2', \n    'Q10_Part_3': 'Notebook product 3',     \n    'Q10_Part_4': 'Notebook product 4', \n    'Q10_Part_5': 'Notebook product 5', \n    'Q10_Part_6': 'Notebook product 6',     \n    'Q10_Part_7': 'Notebook product 7', \n    'Q10_Part_8': 'Notebook product 8', \n    'Q10_Part_9': 'Notebook product 9',     \n    'Q10_Part_10': 'Notebook product 10', \n    'Q10_Part_11': 'Notebook product 11',    \n    'Q10_Part_12': 'Notebook product 12',    \n    'Q10_Part_13': 'Notebook product 13',        \n    'Q10_OTHER': 'Notebook product 14',\n    'Q26_A_Part_1': 'Cloud Computing platform 1', \n    'Q26_A_Part_2': 'Cloud Computing platform 2', \n    'Q26_A_Part_3': 'Cloud Computing platform 3',     \n    'Q26_A_Part_4': 'Cloud Computing platform 4',    \n    'Q26_A_Part_5': 'Cloud Computing platform 5',    \n    'Q26_A_Part_6': 'Cloud Computing platform 6',    \n    'Q26_A_Part_7': 'Cloud Computing platform 7',\n    'Q26_A_Part_8': 'Cloud Computing platform 8',    \n    'Q26_A_Part_9': 'Cloud Computing platform 9',    \n    'Q26_A_Part_10': 'Cloud Computing platform 10',    \n    'Q26_A_Part_11': 'Cloud Computing platform 11',\n    'Q26_A_OTHER': 'Cloud Computing platform 12',\n    'Q12_Part_1': 'Specialised HW 1', \n    'Q12_Part_2': 'Specialised HW 2', \n    'Q12_Part_3': 'Specialised HW 3', \n    'Q12_OTHER': 'Specialised HW 4',     \n    'Q13': 'TPU Usage', \n    'Q15': 'ML Methods experience (in years)', \n    'Q23_Part_1': 'Role Important at work 1', \n    'Q23_Part_2': 'Role Important at work 2', \n    'Q23_Part_3': 'Role Important at work 3', \n    'Q23_Part_4': 'Role Important at work 4',\n    'Q23_Part_5': 'Role Important at work 5',\n    'Q23_Part_6': 'Role Important at work 6',\n    'Q23_Part_7': 'Role Important at work 7',\n    'Q23_OTHER': 'Role Important at work 8',\n    'Q35_A_Part_1': 'Tools to manage ML experiments 1',\n    'Q35_A_Part_2': 'Tools to manage ML experiments 2',  \n    'Q35_A_Part_3': 'Tools to manage ML experiments 3',   \n    'Q35_A_Part_4': 'Tools to manage ML experiments 4',  \n    'Q35_A_Part_5': 'Tools to manage ML experiments 5',  \n    'Q35_A_Part_6': 'Tools to manage ML experiments 6',  \n    'Q35_A_Part_7': 'Tools to manage ML experiments 7',  \n    'Q35_A_Part_8': 'Tools to manage ML experiments 8',\n    'Q35_A_Part_9': 'Tools to manage ML experiments 9',  \n    'Q35_A_Part_10': 'Tools to manage ML experiments 10',      \n    'Q35_A_OTHER': 'Tools to manage ML experiments 11',  \n    'Q37_Part_1': 'Completed DS courses 1',\n    'Q37_Part_2': 'Completed DS courses 2',\n    'Q37_Part_3': 'Completed DS courses 3',    \n    'Q37_Part_4': 'Completed DS courses 4',\n    'Q37_Part_5': 'Completed DS courses 5',\n    'Q37_Part_6': 'Completed DS courses 6',    \n    'Q37_Part_7': 'Completed DS courses 7',\n    'Q37_Part_8': 'Completed DS courses 8',\n    'Q37_Part_9': 'Completed DS courses 9',    \n    'Q37_Part_10': 'Completed DS courses 10',\n    'Q37_Part_11': 'Completed DS courses 11',\n    'Q37_OTHER': 'Completed DS courses 12', \n    'Q39_Part_1':'Favourite media sources 1',\n    'Q39_Part_2':'Favourite media sources 2',\n    'Q39_Part_3':'Favourite media sources 3',\n    'Q39_Part_4':'Favourite media sources 4',\n    'Q39_Part_5':'Favourite media sources 5',    \n    'Q39_Part_6':'Favourite media sources 6',\n    'Q39_Part_7':'Favourite media sources 7',\n    'Q39_Part_8':'Favourite media sources 8',\n    'Q39_Part_9':'Favourite media sources 9',\n    'Q39_Part_10':'Favourite media sources 10',\n    'Q39_Part_11':'Favourite media sources 11',\n    'Q39_OTHER': 'Favourite media sources 12'\n}\n\nkaggle_2020 = load_dataset('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv', question_id_to_human_readable_2020)\nkaggle_2020['Year'] = 2020\nkaggle_2020.head()","4c57689b":"columns = ['Time', 'Year', 'Age', 'Gender', 'Country', 'Degree', 'Job Title', 'Company Size', 'Team Size', \n           'ML Status in Company','Compensation Status','Money Spent', 'Current role experience (in years)',\n           'Programming language choice', 'Recommend Programming language', 'Coding experience (in years)', \n           'Specialised HW', 'TPU Usage', 'ML Methods experience (in years)']\n\nkaggle_combined = pd.concat([kaggle_2017, kaggle_2018, kaggle_2019, kaggle_2020])\nkaggle_combined = kaggle_combined[columns]\nkaggle_combined = kaggle_combined.fillna(NOT_AVAILABLE)\nprint(f'Count before dropping duplicates: {kaggle_combined.shape}')\nkaggle_combined = kaggle_combined.sort_values(['Year', 'Country'])\nkaggle_combined = kaggle_combined.reset_index(drop=True)\n# kaggle_combined = kaggle_combined.drop_duplicates(keep='first')\nkaggle_combined.insert(0, 'Unique_Id', kaggle_combined.index.to_list())\nprint(f'Count after dropping duplicates: {kaggle_combined.shape}')\nprint(f'Dataset shape: {kaggle_combined.shape}')\nkaggle_combined.head()","c1ca759f":"# del kaggle_2017, kaggle_2018, kaggle_2019, kaggle_2020\n# gc.collect()","9f7677c1":"def combine_age_2018(row):\n    if type(row) == float:\n        if (float(row) >= 70.0):\n            return '70+'\n        if (float(row) < 18.0):\n            return '18-21'\n        \n    if row == '80+':\n        return '70+'\n    elif row == '70-79':\n        return '70+'\n    else:\n        return row\n    \nkaggle_combined['Age'] = kaggle_combined['Age'].apply(combine_age_2018)","4e277f10":"age_ranges = kaggle_combined['Age'].unique()\n\ndef combine_age_2017(row):\n    if row.Year == 2017:\n        for local_age in age_ranges:\n            if type(local_age) != float:\n                if (local_age[-1] == '+'):\n                    if row.Age >= 70:\n                        return '70+'\n                else:\n                    ranges = local_age.split('-')\n                    try:\n                        if int(row.Age) >= int(ranges[0]) and int(row.Age) <= int(ranges[1]):\n                            return local_age\n                    except:\n                        return row.Age\n    else:\n        return row.Age\n    \nkaggle_combined['Age'] = kaggle_combined.apply(combine_age_2017, axis=1)","a62742c3":"kaggle_combined['Age'].value_counts()","c473b0e0":"def change_gender(row):\n    if row['Gender'] == 'Man':\n        return 'Male'\n    elif row['Gender'] == 'Woman':\n        return 'Female'\n    elif row['Gender'].strip() == 'A different identity':\n        return 'Prefer not to say'\n    elif row['Gender'].strip() == 'Non-binary, genderqueer, or gender non-conforming':\n        return 'Nonbinary'\n    else:\n        return row['Gender']\n    \nkaggle_combined['Gender'] = kaggle_combined.apply(change_gender, axis=1)","772391f4":"kaggle_combined['Gender'].value_counts()","8e5ef1cd":"def degree_change(row):\n    if row.Degree == 'I did not complete any formal education past high school':\n        return 'No formal education past high school'\n    elif row.Degree == 'Master\\'s degree':\n        return 'Master\u2019s degree'\n    elif row.Degree == 'Bachelor\\'s degree':\n        return 'Bachelor\u2019s degree'\n    elif row.Degree == 'Some college\/university study without earning a bachelor\\'s degree':\n        return 'Some college\/university study without earning a bachelor\u2019s degree'\n    else:\n        return row.Degree\n    \nkaggle_combined['Degree'] = kaggle_combined.apply(degree_change, axis=1)\nkaggle_combined['Degree'].value_counts()","ca0c701b":"def change_company_size(row):\n    if row.Year == 2019:\n        if row['Company Size'] == '> 10,000 employees':\n            return '10,000 or more employees'   \n        else:\n            return row['Company Size']\n\n    if row['Company Size'] == '10 to 19 employees' or row['Company Size'] == 'Fewer than 10 employees':\n        return '0-49 employees'\n    elif row['Company Size'] == '20 to 99 employees' or row['Company Size'] == '100 to 499 employees':\n        return '50-249 employees'\n    elif row['Company Size'] == '500 to 999 employees':\n        return '250-999 employees'\n    elif row['Company Size'] == '1,000 to 4,999 employees' or row['Company Size'] == '5,000 to 9,999 employees':\n        return '1000-9,999 employees'\n    elif row['Company Size'] == '10,000 or more employees':\n        return '10,000 or more employees'\n    else:\n        return row['Company Size']\n    \nkaggle_combined['Company Size'] = kaggle_combined.apply(change_company_size, axis=1)\nkaggle_combined['Company Size'].value_counts()","8fc4bf6f":"dict_salary_2018_mapping = {'0-10,000':'0-10,000','10-20,000': '10,001-20,000', '20-30,000': '20,001-30,000', '30-40,000':'30,000-39,999',\n                           '40-50,000':'40,000-49,999', '50-60,000':'50,000-59,999', '60-70,000':'60,000-69,999',\n                           '70-80,000':'70,000-79,999', '80-90,000':'80,000-89,999', '90-100,000':'90,000-99,999',\n                           '100-125,000':'100,000-124,999', '125-150,000':'125,000-149,999', '150-200,000': '150,000-199,999',\n                           '200-250,000':'200,000-249,999', '250-300,000': '250,000-299,999', '300-400,000':'300,000-500,000',\n                           '400-500,000':'300,000-500,000','500,000+':'> $500,000', 'I do not wish to disclose my approximate yearly compensation':'Cant Disclose',\n                           NOT_AVAILABLE: NOT_AVAILABLE, np.nan:np.nan}\n\ndef change_salary(row):\n    if row.Year == 2019 or row.Year == 2020:\n        if row['Compensation Status']=='$0-999' or row['Compensation Status'] == '1,000-1,999' or row['Compensation Status'] == '2,000-2,999' \\\n            or row['Compensation Status']=='3,000-3,999' or row['Compensation Status']=='4,000-4,999' or row['Compensation Status']=='5,000-7,499' or row['Compensation Status']=='7,500-9,999':\n            return '0-10,000'\n        elif row['Compensation Status'] == '10,000-14,999' or row['Compensation Status'] == '15,000-19,999':\n            return '10,001-20,000'\n        elif row['Compensation Status'] == '20,000-24,999' or row['Compensation Status'] == '25,000-29,999':\n            return '20,001-30,000'\n        else:\n            return row['Compensation Status']\n\n    elif row.Year == 2018:\n        #if not row['Compensation Status'].isna():\n        value_to_return = dict_salary_2018_mapping[row['Compensation Status']]\n        return value_to_return\n    else:\n        return row['Compensation Status']\n    \nkaggle_combined['Compensation Status'] = kaggle_combined.apply(change_salary, axis=1)\n\nlist_values = list(dict_salary_2018_mapping.values())\nlist_values.remove(np.nan)\n\ndef change_salary_2017(row):\n    if row['Year'] == 2017:\n        for i in list_values:\n            ranges = i.split('-')\n            if len(ranges)==2:\n                try:\n                    if int(row['Compensation Status'].replace(',',''))>=int(ranges[0].replace(',','')) and int(row['Compensation Status'].replace(',','')) <= int(ranges[1].replace(',','')):\n                        return i\n                except:\n                    return 'Cant Disclose'\n            else:\n                try:\n                    if int(row['Compensation Status'].replace(',',''))>500000:\n                        return '> $500,000'\n                    else:\n                        return 'Cant Disclose'\n                except:\n                    return 'Cant Disclose'\n                #> 5,000,000, can't disclose\n                \n    else:\n        return row['Compensation Status']","544a41b8":"kaggle_combined['Compensation Status'] = kaggle_combined.apply(change_salary_2017, axis=1)\nkaggle_combined['Compensation Status'].unique()","4d93f224":"consistent_country_name = {\n    'United States of America': 'United States', \n    'Republic of China': 'China',\n    'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n    \"People 's Republic of China\": 'China', \n    'Republic of Korea': 'South Korea',\n    'Hong Kong (S.A.R.)': 'Hong Kong',\n    'Iran, Islamic Republic of...': 'Iran',\n    'Viet Nam': 'Vietnam'\n}\nkaggle_combined['Country'] = kaggle_combined['Country'].apply(lambda x: x.strip())\nkaggle_combined = kaggle_combined.replace({'Country': consistent_country_name})\nkaggle_combined = kaggle_combined.replace({'Country': {'I do not wish to disclose my location': NOT_AVAILABLE}})\nkaggle_combined = kaggle_combined.replace({'Country': {'I do not wish to disclose my location': NOT_AVAILABLE}})\nkaggle_combined = strip_spaces_from_all_columns(kaggle_combined)","c285a809":"countries = [country[0] for country in dict(kaggle_combined[['Country']].value_counts()).keys()]\ncountries","d82857b1":"print(f'Dataset shape: {kaggle_combined.shape}')\nkaggle_combined.to_csv(f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}\/kaggle_2017_to_2020.csv', index=False)","c9904f3a":"missing_countries_in_2020 = ['New Zealand', 'Denmark', 'Finland', 'Norway', 'UK', 'Czech Republic', 'Hungary',\n                            'Austria', 'Norway', 'Algeria']","86e937b7":"total_rows = kaggle_2017.shape[0] + kaggle_2018.shape[0] + kaggle_2019.shape[0] + kaggle_2020.shape[0] \nprint(f\"Individual tables: total: {total_rows}, \\n  kaggle_2017: {kaggle_2017.shape[0]},   \\n  kaggle_2018: {kaggle_2018.shape[0]}, \" \\\n      f\"\\n  kaggle_2019: {kaggle_2019.shape[0]},  \\n  kaggle_2020: {kaggle_2020.shape[0]}\")\nprint(f\"Combined table: kaggle_combined: {kaggle_combined.shape[0]}\")","30083ef6":"total_rows = kaggle_2017.shape[0] + kaggle_2018.shape[0] + kaggle_2019.shape[0] + kaggle_2020.shape[0] \nprint(f\"Individual tables: total: {total_rows}, \\n  kaggle_2017: {kaggle_2017.shape[0]},   \\n  kaggle_2018: {kaggle_2018.shape[0]}, \" \\\n      f\"\\n  kaggle_2019: {kaggle_2019.shape[0]},  \\n  kaggle_2020: {kaggle_2020.shape[0]}\")\nprint(f\"Combined table: kaggle_combined: {kaggle_combined.shape[0]}\")\nprint(f\"Reference table: kaggle_questions_and_responses_ref_df: {kaggle_questions_and_responses_ref_df.shape[0]}\")","c9b29b9a":"print(kaggle_questions_and_responses_ref_df.columns)\nprint(kaggle_combined.columns)","633dff92":"diff_df = dataframe_difference(\n    kaggle_questions_and_responses_ref_df,\n    kaggle_combined[kaggle_questions_and_responses_ref_df.columns]\n)","333d505f":"print(f\"Combined table: kaggle_combined: {kaggle_combined.shape[0]}\\n\")\nprint(diff_df['_merge'].value_counts(), \"\\n\")\nprint(f\"Differences table: diff_df: {diff_df.shape[0]}\\n\")\nprint(\"Total of merged table differences:\", sum(diff_df['_merge'].value_counts()))","936bc79d":"filter_missing_countries = (kaggle_combined['Country'].isin(missing_countries_in_2020)) & (kaggle_combined['Year'] != 2020)\nkaggle_combined[filter_missing_countries]","a3f62deb":"filter_missing_countries = (kaggle_combined['Country'].isin(missing_countries_in_2020)) & (kaggle_combined['Year'] == 2020)\nkaggle_combined[filter_missing_countries]","3586ad47":"print(f'Before combining kaggle_combined.shape: {kaggle_combined.shape}')\ncountry_and_continent_info = pd.read_csv('..\/input\/world-bank-data-1960-to-2016-extended\/Countries_and_continents_of_the_world.csv')\nprint(f'   Before dropping duplicates from country_and_continent_info: {country_and_continent_info.shape}')\ncountry_and_continent_info = country_and_continent_info.rename(columns={'Country Name': 'Country'})\ncountry_and_continent_info = country_and_continent_info.drop_duplicates(subset = ['Country'], keep='first')\nprint(f'   After dropping duplicates from country_and_continent_info: {country_and_continent_info.shape}')\ncountry_and_continent_info[['Region', 'Continent', 'Country']] = \\\n                                    country_and_continent_info[['Region', 'Continent', 'Country']].fillna(NOT_AVAILABLE)\ncountry_and_continent_info = country_and_continent_info.reset_index(drop=True)\ncountry_and_continent_info = strip_spaces_from_all_columns(country_and_continent_info)\n\nprint()\nprint('    --- country_and_continent_info combined with kaggle_combined into kaggle_combined_country_and_continents ---')\nprint()\n\nkaggle_combined_country_and_continents = kaggle_combined.merge(country_and_continent_info, how='left', on='Country', indicator=True)\nprint(\"We won't be removing duplicates for the reason that they end up\\n\")\n# print(f'   Before dropping duplicates from kaggle_combined_country_and_continents: {kaggle_combined_country_and_continents.shape}')\n# kaggle_combined_country_and_continents = kaggle_combined_country_and_continents.drop_duplicates(keep='first')\n# print(f'   After dropping duplicates from kaggle_combined_country_and_continents: {kaggle_combined_country_and_continents.shape}')\nkaggle_combined_country_and_continents[['Region', 'Continent', 'Country']] = \\\n                                    kaggle_combined_country_and_continents[['Region', 'Continent', 'Country']].fillna(NOT_AVAILABLE)\nkaggle_combined_country_and_continents = strip_spaces_from_all_columns(kaggle_combined_country_and_continents)\nkaggle_combined_country_and_continents = kaggle_combined_country_and_continents.reset_index(drop=True)\nkaggle_combined_country_and_continents = strip_spaces_from_all_columns(kaggle_combined_country_and_continents)\nprint(f'After combining kaggle_combined.shape: {kaggle_combined_country_and_continents.shape}')","dee6f95a":"country_and_continent_info['Region'] = country_and_continent_info['Region'].apply(lambda x: x.strip())","7ff2c842":"country_and_continent_info['Region'].value_counts()","9c2706c7":"country_and_continent_info['Continent'].value_counts()","0dfe9d25":"def exclude_columns_in_df(dataframe: pd.DataFrame, columns_to_exclude: list = []) -> pd.DataFrame:\n    current_columns = dataframe.columns\n    excluded_columns = list(set(current_columns) - set(columns_to_exclude))\n    return dataframe[excluded_columns]","4bae412f":"sorted_df1 = exclude_columns_in_df(kaggle_combined, ['_merge']).sort_values(by=['Year', 'Country']) \nsorted_df2 = exclude_columns_in_df(kaggle_combined_country_and_continents[kaggle_combined.columns], ['_merge']).sort_values(by=['Year', 'Country'])\ndiff_df1 = dataframe_difference(sorted_df1, sorted_df2[sorted_df1.columns])\ndiff_df2 = dataframe_difference(sorted_df2[sorted_df1.columns], sorted_df1)","97d5843c":"print(f'diff_df1: {diff_df1.shape[0]} diff_df2: {diff_df2.shape[0]}')\nprint(f'kaggle_combined: {kaggle_combined.shape[0]}, ' \\\n      f'kaggle_combined_country_and_continents: {kaggle_combined_country_and_continents.shape[0]}')","8270a962":"diff_indices = set(kaggle_combined.index) - set(kaggle_combined_country_and_continents.index)\nlen(diff_indices)","5fd9e45a":"from pandas.testing import assert_frame_equal\n\ntry:\n    assert_frame_equal(kaggle_combined, kaggle_combined_country_and_continents[kaggle_combined.columns])\nexcept Exception as ex:\n    print(ex)","fa03894f":"import os\n!mkdir -p \/kaggle\/working\/tmp\nos.environ['sorted_df1_filename'] = '\/kaggle\/working\/tmp\/kaggle_combined.csv'\nos.environ['sorted_df2_filename'] = '\/kaggle\/working\/tmp\/kaggle_combined_country_and_continents.csv'\nsorted_df1_filename = os.environ['sorted_df1_filename']\nsorted_df2_filename = os.environ['sorted_df2_filename']\nsorted_df1.to_csv(sorted_df1_filename, index=False)\nsorted_df2[sorted_df1.columns].to_csv(sorted_df2_filename, index=False)\n!head -n 1 $sorted_df1_filename\n! echo \"\"\n!head -n 1 $sorted_df2_filename\n! echo \"\"\n!diff --suppress-common-lines -y $sorted_df1_filename $sorted_df2_filename\nprint(\"Download the two .csv files and compare them using diff (just like the above command)\")","1bbde2bc":"original_index = sorted(kaggle_combined.index.to_list())\nindex_after_merge = sorted(kaggle_combined_country_and_continents.index.to_list())\nprint(kaggle_combined.shape[0], kaggle_combined_country_and_continents.shape[0], \n      kaggle_combined.shape[0] - kaggle_combined_country_and_continents.shape[0], \n      len(set(original_index) - set(index_after_merge)))","79009982":"from fuzzywuzzy import fuzz\nFILTER_COLUMN = 'Country'\n\ncentral_countries_list = list(set(country_and_continent_info[FILTER_COLUMN].values))\nprint(f'No of countries in the \"country_and_continent_info\" table: {len(central_countries_list)}')\n\ncountries_active_on_kaggle = list(set(kaggle_combined_country_and_continents[FILTER_COLUMN].values))\nprint(f'No of countries active on Kaggle (\"kaggle_combined_country_and_continents\" table): {len(countries_active_on_kaggle)}')\n\ncountries_active_on_kaggle = list(set(kaggle_combined[FILTER_COLUMN].values))\nprint(f'No of countries active on Kaggle (\"kaggle_combined\" table): {len(countries_active_on_kaggle)}')\n\nprint()\nfilter_not_active_on_kaggle = ~country_and_continent_info[FILTER_COLUMN].isin(countries_active_on_kaggle)\ncountries_not_active_on_kaggle = list(set(country_and_continent_info[filter_not_active_on_kaggle][FILTER_COLUMN].values))\nprint(f'No of countries NOT active on Kaggle: {len(countries_not_active_on_kaggle)}')\n\nfound_pairs = {}\nfor not_an_active_country in countries_not_active_on_kaggle:\n    for active_country in countries_active_on_kaggle:\n        ratio = fuzz.token_sort_ratio(not_an_active_country, active_country)\n        if ratio >= 70:\n            found_pairs.update({not_an_active_country: active_country})\n\nprint(f'No of countries that match (between countries_active_on_kaggle and countries_not_active_on_kaggle) due to fuzzy similarity: {len(found_pairs)}')\n\ncountry_and_continent_info['active_on_kaggle'] = 1\ncountry_and_continent_info.loc[filter_not_active_on_kaggle, 'active_on_kaggle'] = 0\nactive_filter = country_and_continent_info['active_on_kaggle'] == 1\nprint()\nprint(f'No of countries NOT active on Kaggle: {country_and_continent_info[~active_filter].shape[0]}')\nprint(f'No of countries active on Kaggle: {country_and_continent_info[active_filter].shape[0]}')","d5dffa9d":"country_and_continent_info['Region'].value_counts()","67bc529c":"country_and_continent_info['Continent'].value_counts()","dbb7aa3c":"display(country_and_continent_info[country_and_continent_info['Country Code'].isna()])\ndisplay(country_and_continent_info[['Country', 'Country Code']])","863f5650":"country_and_continent_info.to_csv(f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}\/country_and_continent_info.csv', index=False)","b6af04b5":"countries_check_df = pd.concat([kaggle_combined['Country'].value_counts(), \n                                kaggle_combined_country_and_continents['Country'].value_counts()], axis=1)\ncountries_check_df.columns=['Before merging count', 'After merging count']\ncountries_check_df['Difference'] = countries_check_df['After merging count'] - countries_check_df['Before merging count']\nfilter_differences = countries_check_df['Difference'] != 0\nprint(f\"Sum of all the differences: {abs(countries_check_df['Difference'].sum())}\")\ncountries_check_df[filter_differences]","85a81eb0":"filter_turkey_kc = (kaggle_combined['Country'] == 'Turkey')\nfilter_turkey_kccc = (kaggle_combined_country_and_continents['Country'] == 'Turkey')","a699d0a4":"print(\n    \"kaggle_combined row count:\", kaggle_combined[filter_turkey_kc].shape[0], \n    \"\\nkaggle_combined_country_and_continents row count:\", kaggle_combined_country_and_continents[filter_turkey_kccc][kaggle_combined.columns].shape[0]\n)\nprint()\nprint(\"With limited (as that of kaggle_combined) columns (after dropping duplicates):\", kaggle_combined_country_and_continents.loc[filter_turkey_kccc, kaggle_combined.columns].drop_duplicates(keep='first').shape)\nprint(\"With all columns (after dropping duplicates):\", kaggle_combined_country_and_continents.loc[filter_turkey_kccc].drop_duplicates(keep='first').shape)","f786465d":"filter_extra_HK_2020_data = (kaggle_combined['Country'] == 'Hong Kong') & (kaggle_combined['Year'] != 2020) \nprint('Before merging countries')\nprint('   - Original count:', kaggle_combined[filter_extra_HK_2020_data].shape)\nprint('   - Duplicates dropped count:', kaggle_combined[filter_extra_HK_2020_data].drop_duplicates().shape)\nprint('After merging countries')\nfilter_extra_HK_2020_data = (kaggle_combined_country_and_continents['Country'] == 'Hong Kong') & (kaggle_combined_country_and_continents['Year'] != 2020) \nprint('   - Duplicates dropped count:', kaggle_combined_country_and_continents[filter_extra_HK_2020_data].shape)","4d6cfe00":"filter_HK_2020_data = (kaggle_combined['Country'] == 'Hong Kong') & (kaggle_combined['Year'] == 2020) \nkaggle_combined[filter_HK_2020_data]","db39bf08":"country_to_check = 'Finland'\nfilter_country_c = kaggle_combined['Country'] == country_to_check\nfilter_country_cc = kaggle_combined_country_and_continents['Country'] == country_to_check","c3e5d3a1":"a = kaggle_combined[filter_country_c].sort_index().reset_index(drop=True)\nb = kaggle_combined_country_and_continents[filter_country_cc][kaggle_combined.columns].sort_index().reset_index(drop=True)\ndataframe_difference(a, b, 'both')\nprint(a['Year'].value_counts(), b['Year'].value_counts())","c864765e":"kaggle_combined_country_and_continents.to_csv(\n    f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}\/kaggle_2017_to_2020_and_countries.csv', index=False\n)","45dea82a":"def get_users_count_upto_end_of(year: int) -> int:\n    filter_year = (kaggle_users['RegisterDate'] <= f'12\/31\/{year}') ## MM\/DD\/YYYY date format (US format)\n    return kaggle_users[filter_year]['RegisterDate'].shape[0]","f9e52429":"%%time\nforce_generate = True\nif force_generate:\n    kaggle_users = pd.read_csv('..\/input\/meta-kaggle\/Users.csv')","8da55002":"%%time\nkaggle_members_count_stats = {\n    'Year': ['2020', '2019', '2018', '2017'], \n    'Total_members_count': [get_users_count_upto_end_of(2020), get_users_count_upto_end_of(2019), \n              get_users_count_upto_end_of(2018), get_users_count_upto_end_of(2017)]\n}\n\nkaggle_members_count_stats","6dbe31b6":"del kaggle_users\ngc.collect()","26e11f48":"def get_response_count_for(year: int) -> int:\n    filter_year = preprocessed_kaggle_combined['Year'] == year\n    return preprocessed_kaggle_combined[filter_year].shape[0]","7338d42f":"preprocessed_kaggle_combined = pd.read_csv('..\/input\/kaggle-machine-learning-data-science-survey-ext\/preprocessed-kaggle-2017-to-2020\/kaggle_2017_to_2020.csv')\nkaggle_response_count_stats = {\n    'Year': ['2020', '2019', '2018', '2017'], \n    'Total_responses_count': [get_response_count_for(2020), get_response_count_for(2019), \n              get_response_count_for(2018), get_response_count_for(2017)]\n}\n\nkaggle_response_count_stats","5a8e8ca4":"survey_response_stats_df = pd.DataFrame(kaggle_response_count_stats).merge(\n    pd.DataFrame(kaggle_members_count_stats), \n    how ='inner', on='Year'\n)\nsurvey_response_stats_df = survey_response_stats_df.sort_values(by='Year').reset_index(drop=True)\nsurvey_response_stats_df['Members_to_response_ratio'] = survey_response_stats_df['Total_responses_count'] \/ survey_response_stats_df['Total_members_count']\n\ncolumns = list(set(survey_response_stats_df.columns) - set(['Year']))\n\nfor each_column in columns:\n    if 'pct_change' not in each_column:\n        new_column = f'{each_column}_pct_change'\n        survey_response_stats_df[new_column] = survey_response_stats_df[each_column].pct_change()\nsurvey_response_stats_df","0e9e83e9":"survey_response_stats_df.to_csv(f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}\/survey_response_stats.csv', index=False)","4d41f694":"%%bash\nUPLOAD_FOLDER=\"\/kaggle\/working\/upload\"\nPREPROCESSED_UPLOAD_FOLDER='\/kaggle\/working\/upload\/preprocessed-kaggle-2017-to-2020'\n\necho \"~~~ Zipping folder: ${PREPROCESSED_UPLOAD_FOLDER}\"\ncd \"${PREPROCESSED_UPLOAD_FOLDER}\"\nzip -r9 ${PREPROCESSED_UPLOAD_FOLDER}.zip *\necho \"~~~ ${PREPROCESSED_UPLOAD_FOLDER}.zip ready to be used\/copied.\"\ncd ${UPLOAD_FOLDER}\nls -lash *.zip \necho \"\"","de84ca73":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nimport os\nos.environ['KAGGLE_KEY'] = user_secrets.get_secret(\"KAGGLE_KEY\")\nos.environ['KAGGLE_USERNAME'] = user_secrets.get_secret(\"KAGGLE_USERNAME\")","22babe0c":"import kaggle\nkaggle.api.authenticate()","ed9b8413":"OWNER_SLUG='neomatrix369'\nDATASET_SLUG='kaggle-machine-learning-data-science-survey-ext'\ndataset_metadata = kaggle.api.metadata_get(OWNER_SLUG, DATASET_SLUG)\ndataset_metadata['id'] = dataset_metadata[\"ownerUser\"] + \"\/\" + dataset_metadata['datasetSlug']\ndataset_metadata['id_no'] = dataset_metadata['datasetId']\nimport json\nwith open(f'{DATASET_UPLOAD_FOLDER}\/dataset-metadata.json', 'w') as file:\n    json.dump(dataset_metadata, file, indent=4)","f12ea1d0":"%%time\n# !kaggle datasets version -m \"Updating datasets\" -p \/kaggle\/working\/upload\nkaggle.api.dataset_create_version(DATASET_UPLOAD_FOLDER, 'Updating datasets')","dae5b2e9":"!rm -fr \/kaggle\/working\/upload","02ff140c":"From the above we can say more or less that all the new data seems to be good, the mismatch in row counts arise when we try to drop duplicates (especially when we scope the columns to only that of the `kaggle_combined` dataset.","6d6a9fde":"## Loading datasets","051b393f":"## Uploading newly created\/updated csv to your Kaggle Dataset\n\nSetup your local environment with your Kaggle login details (`KAGGLE_KEY` and `KAGGLE_USERNAME`).","3c3be8b9":"### Degree \/ qualification","3e975305":"### Prequels\/sequels\n\n- **Kaggle Machine Learning & Data Science (data-prep)** | [Extended Dataset](https:\/\/www.kaggle.com\/neomatrix369\/kaggle-machine-learning-data-science-survey-ext) | [Additional Dataset](https:\/\/www.kaggle.com\/neomatrix369\/world-bank-data-1960-to-2016-extended)\n- [Kaggle Global Outreach (analysis)](https:\/\/www.kaggle.com\/neomatrix369\/kaggle-global-outreach-analysis\/)","72535143":"### Prequels\/sequels\n\n- **Kaggle Machine Learning & Data Science (data-prep)** | [Extended Dataset](https:\/\/www.kaggle.com\/neomatrix369\/kaggle-machine-learning-data-science-survey-ext) | [Additional Dataset](https:\/\/www.kaggle.com\/neomatrix369\/world-bank-data-1960-to-2016-extended)\n- [Kaggle Global Outreach (analysis)](https:\/\/www.kaggle.com\/neomatrix369\/kaggle-global-outreach-analysis\/)","4f407873":"### Company Size","aeb2e75e":"### Checking for missing data (by country and\/or year)","e5844ea3":"### Comparing combined dataset with individual tables and combined counts from them","58836ce4":"Using the `kaggle` Python client login, into your account from within the kernel.","4a5ecadf":"### Let's check Denmark, Canada, HK or another country","ca99870b":"###\u00a0Kaggle Survey 2018","0fa9ca0c":"###\u00a0Kaggle Survey 2020","99994c60":"Get the metadata for the dataset you have already created manually - it's best to manually create it and upload the initial csv file(s) into it, to avoid subsequent issues with updating the dataset (as seen during my own end-to-end cycle).\n\nSave the metadata file as a json file but before that, add\/update two keys id and id_no with the respective details as shown below and then save it.","ebf0d7f7":"### Age","67a3de18":"###\u00a0Kaggle Survey 2019","271c7e41":"### Cleanup ","92546281":"### Preprocessing merged dataset from @harveenchadha (from 2017 to 2020)","2ab3027f":"Finally call the dataset_create_version() api and pass it the folder where the metadata file exists and also where your .csv and .fth file(s) - those file(s) that you would like to upload into your existing Dataset (as a new version).","81d7e925":"### Compensation Status","4e04c579":"### Country","9c9dd71f":"All the shape (row count) functions return a mismatch although the `merge()` and `concat()` (after dropping duplicates) do not seem to find","3a070bee":"###\u00a0Kaggle Survey 2017","a084b412":"### Comparing combined dataset with a reference dataset for differences and discrepancies","9a636dbe":"## Survey response v\/s total Kaggle members stats","415a7975":"#### Checks on Hong Kong data","491a8e02":"### Gender","2c284c97":"### Thanks \/ Credits\n\n- [sahilmaheshwari](https:\/\/www.kaggle.com\/sahilmaheshwari\/) (https:\/\/www.kaggle.com\/thedatabeast\/cleaned-mcr-kaggle-survey-2019)\n- [rblcoder](https:\/\/www.kaggle.com\/rblcoder\/) (https:\/\/www.kaggle.com\/aitzaz\/stack-overflow-developer-survey-2020)\n- [harveenchadha](https:\/\/www.kaggle.com\/harveenchadha) (https:\/\/www.kaggle.com\/harveenchadha\/kaggle-survey-20172020-merged-data) - special thanks for your data preparatory kernel (https:\/\/www.kaggle.com\/harveenchadha\/merging-all-historical-survey-data-2017-2020), I have reused a number of things from it\n\nFor sharing a number of additional survey\/country\/region\/world related datasets.","e8156646":"## Combining Kaggle dataset with Countries and Continents dataset","8c3f4ffc":"It is possible the reference table and the newly combined tables differ for good reasons, and could be checked later on, why.","b7740e0c":"### Zipping the respective directories","c9a38600":"## Installing and importing libraries and packages","7bc95012":"### Check for correctness after merging the datasets","bee982cd":"#### We can confirm that there is no data for **Hong Kong** in **2020**. Also there are no duplicates present.","0c359f1b":"Doing the above, seems like an old-school way to compare datasets but it gives a better idea why there is a difference between the datasets, so far it seems semantically the datasets are different but if we have to look at it literally they differ a bit. Comparisons and analysis further on will show the differences.","031fbff7":"### Picking a handful more columns missed in the above merge process","93f7b93c":"#### Checks on Turkey data"}}