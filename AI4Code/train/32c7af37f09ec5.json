{"cell_type":{"2ddac18d":"code","b7b3044f":"code","344e0d72":"code","7b26b2f3":"code","a9b136c5":"code","f7ef49f9":"code","ef59011d":"code","e0471012":"code","9a7f5282":"code","364d28d8":"code","589a8168":"code","73530f5d":"code","80c2c4eb":"code","931c160c":"code","be4d95d2":"code","1e0d6d6b":"code","152cb28d":"code","fadc0218":"code","5f779d2f":"code","38c43002":"code","4cd94ff7":"code","0a78cfbf":"code","a68b5130":"code","1135a5b7":"code","f21231e5":"code","927846d3":"code","16b5c63f":"code","1ddf19b8":"code","6ed0b7b6":"code","11fd2092":"code","e6addcf6":"code","19f53ab8":"code","59517d99":"code","7960c24a":"code","e9b8f29b":"code","2e0028dd":"code","238090ee":"code","857a231e":"code","f4926aff":"code","77244059":"code","1e0a6ccf":"code","fe697735":"code","93c31edb":"code","d807fdfb":"markdown","940b1017":"markdown","1eec30dd":"markdown"},"source":{"2ddac18d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b7b3044f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport nltk","344e0d72":"sms = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\",encoding='latin')","7b26b2f3":"sms.head()","a9b136c5":"sms.columns[2]","f7ef49f9":"# Most of the 2,3,4 columns have null values\nprint(sms.iloc[:,2].isna().sum(),\n      sms.iloc[:,3].isna().sum(),\n      sms.iloc[:,4].isna().sum())","ef59011d":"sms = sms.drop([sms.columns[2],sms.columns[3],sms.columns[4]],axis=1)","e0471012":"sms.head()","9a7f5282":"sms.v1.value_counts()","364d28d8":"sns.countplot(sms[\"v1\"])","589a8168":"sms.describe()","73530f5d":"sms.groupby('v1').describe().T","80c2c4eb":"sms['length'] = sms['v2'].apply(len)","931c160c":"sms.head()","be4d95d2":"sns.set()","1e0d6d6b":"sms['length'].plot(bins=50,kind=\"hist\")","152cb28d":"sms.length.describe()","fadc0218":"sms.hist(column='length',by='v1',bins=50,figsize=(12,3))","5f779d2f":"# The spam messages are longer","38c43002":"import string\n\ntest = \"We can turn, the world to go !\"\n\npuncless = [c for c in test if c not in string.punctuation]\n\npuncless = \"\".join(puncless)","4cd94ff7":"puncless","0a78cfbf":"from nltk.corpus import stopwords\nstopwords.words('english')[:20]","a68b5130":"list(puncless.split())","1135a5b7":"stopless = [w for w in list(puncless.split()) if w not in stopwords.words('english')]","f21231e5":"stopless","927846d3":"from nltk.corpus import stopwords\ndef text_process(msg):\n    puncless = [c for c in msg if c not in string.punctuation]\n    \n    puncless = \"\".join(puncless)\n    \n    return [w for w in list(puncless.split()) if w.lower() not in stopwords.words('english')]","16b5c63f":"sms['v2'].head(5).apply(text_process)","1ddf19b8":"#Vectorization","6ed0b7b6":"from sklearn.feature_extraction.text import CountVectorizer","11fd2092":"bow_transformer = CountVectorizer(analyzer = text_process).fit(sms['v2'])","e6addcf6":"print(len(bow_transformer.vocabulary_))","19f53ab8":"sms_bow = bow_transformer.transform(sms['v2'])\nprint(\"Sparse shape\",sms_bow.shape)\nprint(\"Non zero\",sms_bow.nnz)","59517d99":"sparsity = (100.0 * sms_bow.nnz \/ (sms_bow.shape[0] * sms_bow.shape[1]))\nprint('sparsity: {}'.format(round(sparsity,4)))","7960c24a":"from sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer().fit(sms_bow)\nsms_tfidf = tfidf_transformer.transform(sms_bow)","e9b8f29b":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB().fit(sms_tfidf,sms['v1'])","2e0028dd":"#Testing\nprint(\"Predicted:\",model.predict(sms_tfidf)[0])\nprint(\"expected:\",sms.v1[3])","238090ee":"pred = model.predict(sms_tfidf)","857a231e":"from sklearn.metrics import classification_report\nprint(classification_report(sms['v1'],pred))","f4926aff":"from sklearn.metrics import accuracy_score","77244059":"print(accuracy_score(pred,sms['v1']))","1e0a6ccf":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nmodel2 = neigh.fit(sms_tfidf,sms['v1'])\npred2 = model2.predict(sms_tfidf)\n\nprint(\"KNeighbors Classifier accuracy : \",accuracy_score(pred2,sms['v1']))","fe697735":"from sklearn.svm import LinearSVC\nmodel3 = LinearSVC(random_state=0).fit(sms_tfidf,sms['v1'])\npred3 = model3.predict(sms_tfidf)\nprint(\"SVC accuracy : \",accuracy_score(pred3,sms['v1']))\n","93c31edb":"from sklearn.model_selection import train_test_split\n","d807fdfb":"Now we only have 2 columns in sms","940b1017":"Now we process all the entries","1eec30dd":"Pre Processing"}}