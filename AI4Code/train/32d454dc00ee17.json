{"cell_type":{"d7f2a82b":"code","4afa5e6e":"code","3b0e2cba":"code","214d3b2f":"code","4002c3f9":"code","bb61bbd5":"code","7614c0bc":"code","3ecd1ea8":"code","ac881c0c":"code","4674f73a":"code","a67c3133":"code","ca85ddfd":"code","d57b7fe8":"code","050082bf":"code","b6949a0d":"code","363ffa94":"markdown","553d5968":"markdown","3006478d":"markdown","7a451bc6":"markdown","73c4f1bd":"markdown","cadcc4f6":"markdown","b5bab549":"markdown","b6c6e179":"markdown","eafb30f5":"markdown","8d4e17a8":"markdown","db5c8407":"markdown","582b629c":"markdown","06bffa3d":"markdown","f64ffa8e":"markdown","0a9bc7fa":"markdown","30afbaaf":"markdown","e0c5058b":"markdown"},"source":{"d7f2a82b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os # reading data\nimport cv2 # reading images\nimport matplotlib.pyplot as plt\n# \/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/\n","4afa5e6e":"datadir=\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/\"\ncategories = [\"NORMAL\",\"PNEUMONIA\"]\ntraining_data =[]\nnum=0\nfor category in categories:\n    path = os.path.join(datadir, category)\n    class_num = categories.index(category)\n    for img in os.listdir(path):\n        try:\n            img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n            new_array = cv2.resize(img_array,(200,200))\n            if(num<=2642): # i have more than i need pneumonia data so i added an if condition\n                training_data.append([new_array,class_num])\n                num+=1\n            else:\n                break\n        except Exception:\n            pass","3b0e2cba":"plt.imshow(new_array,cmap=\"gray\")\nplt.show()","214d3b2f":"datadir=\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\/\"\ncategories = [\"NORMAL\",\"PNEUMONIA\"]\ntest_data =[]\nnum=0\nfor category in categories:\n    path = os.path.join(datadir, category)\n    class_num = categories.index(category)\n    for img in os.listdir(path):\n        try:\n            img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n            new_array = cv2.resize(img_array,(200,200))\n            if(num<=2642): # i have more than i need pneumonia data so i added an if condition\n                test_data.append([new_array,class_num])\n                num+=1\n            else:\n                break\n        except Exception:\n            pass","4002c3f9":"plt.imshow(new_array,cmap=\"gray\")\nplt.show()","bb61bbd5":"len(training_data)\nimport random\nrandom.shuffle(training_data)\nx_train=[]\ny_train=[]\nx_test=[]\ny_test=[]","7614c0bc":"for features, label in training_data:\n    x_train.append(features)\n    y_train.append(label)\nx_train = np.array(x_train).reshape(-1,200,200,1)\n#I convert numpy and then i added 1 at the end because keras need 3 \nx_train.shape\nx_train = x_train\/255.0 # normalization","3ecd1ea8":"for features, label in test_data:\n    x_test.append(features)\n    y_test.append(label)\nx_test = np.array(x_test).reshape(-1,200,200,1)\n#I convert numpy and then i added 1 at the end because keras need 3 \nx_test.shape\nx_test = x_test\/255.0 # normalization","ac881c0c":"from keras.utils.np_utils import to_categorical \ny_train = to_categorical(y_train, num_classes = 2)\ny_test = to_categorical(y_test, num_classes = 2)","4674f73a":"for a in y_train[10:20]:\n    print(a)","a67c3133":"from sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=8, kernel_size=(20,20), padding='Same', activation='relu', input_shape=(200,200,1)))\nmodel.add(MaxPool2D((10,10),strides=(1,1)))\nmodel.add(Conv2D(filters=6, kernel_size=(7,7), padding='Same', activation='relu'))\nmodel.add(MaxPool2D((10,10),strides=(1,1)))\n#model.add(MaxPool2D((2,2),strides=(1,1)))\n#model.add(Conv2D(filters=8, kernel_size=(3,3), padding='Same', activation='relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(2, activation='sigmoid'))","ca85ddfd":"optimizer = Adam(lr=0.0000008)\nmodel.compile(optimizer = optimizer , loss =\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nepochs = 20\nhistory = model.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=5,batch_size=16)","d57b7fe8":"plt.plot(history.history[\"val_loss\"], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","050082bf":"import seaborn as sns\ny_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred,axis = 1) \ny_true = np.argmax(y_test,axis = 1) \nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \nf,ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","b6949a0d":"predictions = model.predict(x_test)\nscore = model.evaluate(x_test,y_test,verbose=0)\nprint(\"Test loss :\",score[0])\nprint(\"Test Accuracy : \",score[1])","363ffa94":"I need to save my labels and features in diferrent arrays and then reshape my train and validation datas.","553d5968":"My datas are almost ready.Now i need to convert my y_train and y_test to one hot vector.","3006478d":"Now i need to shuffle my data to learn better.","7a451bc6":"First of all i need to get my jpeg files to arrays but i have 3875 pneumonia and 1341 normal data.I need to delete some of pneumonia data.","73c4f1bd":"<a id=\"1\"><\/a>\n# 1.Data Loading with OpenCV","cadcc4f6":"As you can see my data is shuffled.","b5bab549":"Time for plot our test loss and confusion matrix.","b6c6e179":"<a id=\"6\"><\/a>\n# 6.Accuracy","eafb30f5":"**As you can see my model is not so good but you can work on hyperparameters and see how it works !**","8d4e17a8":"<a id=\"5\"><\/a>\n# 5.Training","db5c8407":"I am going to use Adam optimizer.","582b629c":"<a id=\"3\"><\/a>\n# 3.Creating Model with Keras","06bffa3d":"Now i need to import my validation data too.","f64ffa8e":"I added all my jpeg files into training_data above as you can see.But i still got my last image in new_array variable.Let's see what is it look like.","0a9bc7fa":"Now I am going to create my model.For this I will follow this structure :\n\nConv -> MaxPool -> Dropout -> Conv -> MaxPool -> Dropout -> Conv -> MaxPool -> Dropout -> Fully Connected Layer","30afbaaf":"<a id=\"2\"><\/a>\n# 2.Data Preprocessing","e0c5058b":"# CNN with OpenCV\n**In this kernel I am going to classify x-ray images in order to understand whether the person has Pneumonia or not.Firstly , i will going to read my images with openCV.Then I will preprocesses my data, create my model.At last, I will feed my images to my Convolutional Neural Network, and calculate my accuracy.*\n\nLet's start with importing our libraries.\n\n**Content:**\n1. [Data Loading with OpenCV](#1)\n1. [Data Preprocessing](#2)\n1. [Creating Model with Keras](#3)\n1. [Data Augmentation](#4)\n1. [Training](#5)\n1. [Prediction and Accuracy](#6)\n"}}