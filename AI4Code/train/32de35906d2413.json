{"cell_type":{"982d4824":"code","8a70f454":"code","5a470348":"code","0a61ccf1":"code","5b150585":"code","539eb357":"code","f593ac0a":"code","d4652a2d":"code","9e433875":"code","c903a551":"markdown"},"source":{"982d4824":"import os\nimport glob\nimport random\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tqdm.notebook as tqdm\n\nfrom skimage.measure import shannon_entropy\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report as cr, confusion_matrix as cm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier","8a70f454":"random.seed(0)\nfiles = glob.glob('\/kaggle\/input\/diast-vitveid\/DIAST Variability Illuminated Thermal and Visible Ear Images Datasets\/*\/* Visible\/*.jpg')\nfiles = sorted(files)\nrandom.shuffle(files)\n\nrandom.seed()\nk = 5\nfig, axs = plt.subplots(1, k, figsize=(20, int(20 \/ k)))\nfor ax, file_ in zip(axs, random.choices(files, k=k)):\n    ax.imshow(cv2.imread(file_, cv2.IMREAD_GRAYSCALE), cmap='gray')\nplt.show()\n\nrandom.seed(0)","5a470348":"def get_lux(file_):\n    \"\"\"Extract the lux value that was used to take the image.\"\"\"\n    base = os.path.basename(file_)\n    base, _ = os.path.splitext(base)\n    lux = int(base.split('x')[-1].split('v')[0])\n    return lux\n\nlux_values = list(map(get_lux, files))\nassert min(lux_values) >=1\nassert max(lux_values) <= 9999\nassert len(lux_values) == len(files)\n\nfig = plt.figure()\nplt.hist(lux_values, bins='auto', histtype='bar', ec='white')\nplt.xlabel('lux value')\nplt.ylabel('Freq')\nplt.title(\"Histogram of lux values across DIAST visible dataset\")\nplt.show()","0a61ccf1":"# Extract the class labels from the lux values\nCLASS_NAMES = ['Dark', 'Average', 'Bright']\nbins = [20, 100, max(lux_values)]  # Dark, Average, Bright - from the dataset.\nf = lambda lux: next(bins.index(b) for b in bins if lux <= b)\ny = np.array(list(map(f, lux_values)))  # 0=Dark, 1=Average, 2=Bright\nassert min(y) == 0\nassert max(y) == 2\nassert len(y) == len(files)\n\nunq, unq_cnts = np.unique(y, return_counts=True)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\nax1.pie(unq_cnts, rotatelabels=True, labels=np.array(CLASS_NAMES)[unq], autopct='%1.1f%%', pctdistance=0.85)\nax1.legend()\nax1.set_title('Diast Class Split')\n\nax2.scatter(lux_values, y, s=5, c=y)\nax2.set(xlabel='lux_values', ylabel='bins')\nax2.set_title('Binning function on lux values.')\nplt.show()","5b150585":"# Extract the features that we want to use\n\ndef nric(img):\n    \"\"\"Extract the no reference features from image.\n    \n    Parameters\n    ----------\n    img: np.ndarray or path-like\n        Grayscale image or path to image.\n    \n    Returns\n    -------\n    float\n        The shannon entropy of the grayscale image.\n    float\n        The standard deviation of the grayscale image.\n    float\n        The mean of the grayscale image.\n        \n    \"\"\"\n    if isinstance(img, str):\n        img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n        \n    sd = np.std(img)\n    me = np.mean(img)\n    se = shannon_entropy(img)\n    return se, sd, me\n\nx = np.array(list(map(nric, tqdm.tqdm(files))))\nassert len(x) == len(y)","539eb357":"FEATURE_NAMES = ['SE', 'STD', 'MEAN']\nk = len(FEATURE_NAMES)\n\nfig, ax = plt.subplots(1, k, figsize=(18, 18\/k))\nfor i, q in enumerate(FEATURE_NAMES):\n    ax[i].hist(x[:, i], bins='auto', histtype='bar', ec='white')\n    ax[i].set(xlabel=q, ylabel=\"freq\")\n    ax[i].set_title(q + ' DIAST')\nplt.show()\n\nprint('Metric Avg | Dark=0 | Average=1 | Bright=2')\nfig, ax = plt.subplots(1, k, figsize=(18, 18\/k))\nfor i, q in enumerate(['SE', 'STD', 'MEAN']):\n    scatter = ax[i].scatter(np.arange(0, len(y)), x[:, i], c=y)\n    legend = ax[i].legend(*scatter.legend_elements(), loc=\"lower left\", title=\"Classes\")\n    ax[i].add_artist(legend)\n    ax[i].set(xlabel='item', ylabel=q)\n    ax[i].set_title(q + ' DIAST')\n    print(q, *[x[y == c][:, i].mean() for c in unq])\nplt.show()","f593ac0a":"# Data split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)","d4652a2d":"# Train RF\nclf = RandomForestClassifier(random_state=0, class_weight='balanced')\nclf.fit(x_train, y_train)\n\ny_pred = clf.predict(x_test)\n\nprint(cr(y_true=y_test, y_pred=y_pred))\nprint(cm(y_true=y_test, y_pred=y_pred))","9e433875":"# Train kNN\nk = 5\nknn = KNeighborsClassifier(k)\nknn.fit(x_train, y_train)\n\ny_pred = knn.predict(x_test)\n\nprint(cr(y_true=y_test, y_pred=y_pred))\nprint(cm(y_true=y_test, y_pred=y_pred))","c903a551":"# Illumination Classification Based on No-Reference Image Quality Assessment (NR-IQA)\n\nThis work is my own implementation of the method described in. \n\nhttps:\/\/dl.acm.org\/doi\/abs\/10.1145\/3314527.3314529\nhttps:\/\/www.researchgate.net\/publication\/332538419_Illumination_Classification_based_on_No-Reference_Image_Quality_Assessment_NR-IQA"}}