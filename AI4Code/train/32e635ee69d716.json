{"cell_type":{"57f50961":"code","794b1de5":"code","2f0a98c7":"code","341e2fd5":"code","a704aef9":"code","0ed1a8da":"code","65fbd2c5":"code","987e2dfc":"code","0159156d":"code","8ae5cf9b":"code","34354b21":"code","5b720552":"code","25e31984":"code","da9acbef":"code","f4441b94":"code","6005a37b":"code","6ddb2df2":"code","967bae35":"code","6bbd35b6":"markdown","7e4ddc8f":"markdown","08e8fbcd":"markdown","b0da7e56":"markdown"},"source":{"57f50961":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","794b1de5":"# Importing the data set\ndf = pd.read_csv(\"\/kaggle\/input\/automobile-dataset\/Automobile_data.csv\")\ndf.head()","2f0a98c7":"# Since pandas does not understands '?' values we must replace it with 'NAN' values to perfom pandas operation.\ndf.replace(\"?\",np.nan,inplace = True)\n\n# Loading dataset\ndf.head()","341e2fd5":"# Before dealing with missing values we must check for the data type\nprint(df.dtypes)","a704aef9":"# Calculate number of nan values and percentage of nan values in 'normalized-losses'\n# Number of missing values of 'normalized-losses' columns.\nmissing_values = df['normalized-losses'].isnull().sum()\nprint(\"The number of missing value is normalized-losses: \",missing_values)\n# Percentage of nan values.\ntotal_num_cells = np.product(df['normalized-losses'].shape)\npercent_of_nan = (missing_values\/total_num_cells)*100\nprint(\"The percentage of missing value is normalized-losses: \",percent_of_nan,\"%\")","0ed1a8da":"# Since percentage of mising values in normalized losses is less we can replace it with either mean or '0'.\n# Replace nan values of 'normalised losses' with mean values of the column\n# But to find mean we need to change datatype of the 'normalised losses'\nmean = df['normalized-losses'].astype(float).mean()\ndf['normalized-losses'].replace(np.nan,mean,inplace = True)\ndf.head()","65fbd2c5":"# Similarly we shall replace for other numerical columns\n\n# For 'bore' column\nm_1 = df['bore'].astype('float').mean(axis=0)\ndf['bore'].replace(np.nan,m_1,inplace = True)\n\n# For 'horsepower' column\nm_2 = df['horsepower'].astype('float').mean(axis=0)\ndf['horsepower'].replace(np.nan,m_2,inplace = True)\n\n# For 'Peak-rpm' column\nm_3 = df['peak-rpm'].astype('float').mean(axis=0)\ndf['peak-rpm'].replace(np.nan,m_3,inplace = True)\n\n# For 'Stroke' column\nm_4 = df['stroke'].astype('float').mean(axis = 0)\ndf['stroke'].replace(np.nan,m_4,inplace = True)\n\n# Checking for null value\nmissing_data = df.isnull()\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")    ","987e2dfc":"# For categorical values we replace missing values with most occurred values\nprint(df['num-of-doors'].value_counts())\nprint()\nprint(\"Most occurred value\",df['num-of-doors'].value_counts().idxmax())\n\n# Replace missing values with 'four'\ndf['num-of-doors'].replace(np.nan,'four',inplace = True)","0159156d":"# Delete the nan values from price column as  price is what we want to predict. \n# Any data entry without price data cannot be used for prediction\ndf.dropna(subset=[\"price\"],axis=0,inplace = True)\n\n# Check for nan \nprint(\"The number of missing values in price:\",df['price'].isnull().sum())","8ae5cf9b":"# Checking for more columns with null values\nprint(df.isnull().sum())","34354b21":"# Check for data format and make correction\ndf.dtypes","5b720552":"# Convert data format\ndf[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\ndf[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\ndf[[\"price\"]] = df[[\"price\"]].astype(\"float\")\ndf[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")\ndf[[\"horsepower\"]] = df[[\"horsepower\"]].astype(\"int\")","25e31984":"# Check \ndf.dtypes","da9acbef":"# Define important variables for prediction\n# Select variables with correlation close to either -1 or 1 with price\ndf.corr()","f4441b94":"# Since more than one variable has impact on price column\n# We must use Multipe Linear regression and here we selected variables most close to -1 or 1\n# The equation is given by \n# yhat = a + b1\ud835\udc4b1 + b2\ud835\udc4b2 + b3\ud835\udc4b3 + b4\ud835\udc4b4\n\n# Training and Testing Data\n# X has data of all the important variables\/ Predictor variable\/ Independent variables\nx = df[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']]\n\n# Y has data of dependent variable\/ target variable\ny = df['price']","6005a37b":"# For predictive analysis, We first split data into two groups training data and testing data(For this case train_data = 80% and test_data=20%)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression\n\n# Here, the variables:\n# x_train = 80% data of independent variables.\n# y_train = 80% data from price column w.r.t x_train data.\n# x_test  = 20% data of independent variables for prediction of price.\n# y_test  = The price predicted from above 'x_test' data is checked with original y_test data to get the accuracy of the model.\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state=0,test_size=0.3)","6ddb2df2":"reg = LinearRegression()\n\n# Training the model\nreg.fit(x_train,y_train)\n\n# Price prediction based on x_test data\nprice_predict = reg.predict(x_test)\nprice_pred = np.round(price_predict,2)\nprice_pred_df = pd.DataFrame({'Predicted_price':price_pred})\n\n# Printing first 10 values of price prediction dataframe\nprint(price_pred_df.head(10))\n\n# Accuracy percentage using y_test data\n# Here R^2 method is used to evaluate the model\naccuracy = r2_score(y_test,price_predict)\nprint()\nprint(\"The accuracy of the model based on current test data: \",accuracy*100,\"%\")","967bae35":"# Model evaluation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint(\"Here is comparision between predicted values from train_data and test_data\")\n\n# Distribution plot for Training data\ntrain_data_plot = reg.predict(x_train)\nplt.figure(figsize=(7,7))\n\n\nax1 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual price\")\nsns.distplot(train_data_plot, hist=False, color=\"b\", label=\"Predicted price\" , ax=ax1)\n\n# Note here:\n# t_data --> train data\n# a_price --> actual price\n# p_price --> pridected price\nplt.title('A_price of t_data   vs   p_price of t_data')\nplt.xlabel('Price (in dollars)')\nplt.ylabel('Proportion of Cars')\n\nplt.show()\nplt.close()\n\n\n# Distribution plot for Test data\n# Using 'price_predict' variable from above\nplt.figure(figsize=(7,7))\n\nax2 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual price\")\nsns.distplot(price_predict, hist=False, color=\"b\", label=\"Predicted price\" , ax=ax2)\n\n# Note here:\n# t_data --> test data\n# a_price --> actual price\n# p_price --> pridected price\nplt.title('A_price of t_data   vs   p_price of t_data')\nplt.xlabel('Price (in dollars)')\nplt.ylabel('Proportion of Cars')\n\nplt.show()\nplt.close()\n\nprint(\"Here see that the predicted values are close to the actual values, since the two distributions overlap a bit\",\".\"\n      ,\"Thus the model is reasonably correct.\")","6bbd35b6":"## Prediction model developement","7e4ddc8f":"## Data-wrangling","08e8fbcd":"### Important numerical variables for prediction\n- Length\n- Width\n- Curb-weight\n- Engine-size\n- Horsepower\n- City-mpg\n- Highway-mpg\n- Wheel-base\n- Bore","b0da7e56":"## Now we have no missing data in the data set"}}