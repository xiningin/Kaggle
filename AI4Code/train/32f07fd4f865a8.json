{"cell_type":{"34be4db4":"code","b018f35e":"code","fb18cd61":"code","59c3e076":"code","99ec0d8d":"code","d825a903":"code","32504853":"code","28fe9af4":"code","77c947a9":"code","31bd5ed1":"code","478c6e03":"code","a0ed923e":"code","0533c32b":"code","7c9c091f":"code","dd67d9f5":"code","55531739":"code","fec32e4b":"code","4eb11c6f":"code","96d1aaa1":"code","d0d67acd":"code","cdd34275":"code","d9026573":"code","5c374623":"code","fd1c75da":"code","73cdbc5c":"code","d7571beb":"code","4abe66ed":"markdown","f4c396c0":"markdown","ff9a03e2":"markdown","08b69052":"markdown","04366148":"markdown","8c14dff0":"markdown","7f06f767":"markdown","11bf4746":"markdown","b70e161a":"markdown"},"source":{"34be4db4":"!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/pytorch-170-cuda-toolkit-110221\/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","b018f35e":"!pip install '\/kaggle\/input\/mmdetectionv2140\/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmcv_full-1_3_8-cu110-torch1_7_0\/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/pycocotools-2.0.2\/pycocotools-2.0.2' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmpycocotools-12.0.3\/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r ..\/input\/edited-mmdetection \/kaggle\/working\/\n!mv \/kaggle\/working\/edited-mmdetection \/kaggle\/working\/mmdetection\n%cd \/kaggle\/working\/mmdetection","fb18cd61":"# %%writefile \/kaggle\/working\/mmdetection\/mmdet\/core\/post_processing\/bbox_nms.py\n\n# import torch\n# from mmcv.ops.nms import batched_nms\n\n# from mmdet.core.bbox.iou_calculators import bbox_overlaps\n\n# def intersect(box_a, box_b):\n\n#     n = box_a.size(0)\n#     A = box_a.size(1)\n#     B = box_b.size(1)\n#     max_xy = torch.min(box_a[:, :, 2:].unsqueeze(2).expand(n, A, B, 2),\n#                        box_b[:, :, 2:].unsqueeze(1).expand(n, A, B, 2))\n#     min_xy = torch.max(box_a[:, :, :2].unsqueeze(2).expand(n, A, B, 2),\n#                        box_b[:, :, :2].unsqueeze(1).expand(n, A, B, 2))\n#     inter = torch.clamp((max_xy - min_xy), min=0)\n#     return inter[:, :, :, 0] * inter[:, :, :, 1]\n\n# def diou(box_a, box_b, beta=1.0, iscrowd:bool=False):\n#     use_batch = True\n#     if box_a.dim() == 2:\n#         use_batch = False\n#         box_a = box_a[None, ...]\n#         box_b = box_b[None, ...]\n\n#     inter = intersect(box_a, box_b)\n#     area_a = ((box_a[:, :, 2]-box_a[:, :, 0]) *\n#               (box_a[:, :, 3]-box_a[:, :, 1])).unsqueeze(2).expand_as(inter)  # [A,B]\n#     area_b = ((box_b[:, :, 2]-box_b[:, :, 0]) *\n#               (box_b[:, :, 3]-box_b[:, :, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n#     union = area_a + area_b - inter\n#     x1 = ((box_a[:, :, 2]+box_a[:, :, 0]) \/ 2).unsqueeze(2).expand_as(inter)\n#     y1 = ((box_a[:, :, 3]+box_a[:, :, 1]) \/ 2).unsqueeze(2).expand_as(inter)\n#     x2 = ((box_b[:, :, 2]+box_b[:, :, 0]) \/ 2).unsqueeze(1).expand_as(inter)\n#     y2 = ((box_b[:, :, 3]+box_b[:, :, 1]) \/ 2).unsqueeze(1).expand_as(inter)\n\n#     t1 = box_a[:, :, 1].unsqueeze(2).expand_as(inter)\n#     b1 = box_a[:, :, 3].unsqueeze(2).expand_as(inter)\n#     l1 = box_a[:, :, 0].unsqueeze(2).expand_as(inter)\n#     r1 = box_a[:, :, 2].unsqueeze(2).expand_as(inter)\n\n#     t2 = box_b[:, :, 1].unsqueeze(1).expand_as(inter)\n#     b2 = box_b[:, :, 3].unsqueeze(1).expand_as(inter)\n#     l2 = box_b[:, :, 0].unsqueeze(1).expand_as(inter)\n#     r2 = box_b[:, :, 2].unsqueeze(1).expand_as(inter)\n#     cr = torch.max(r1, r2)\n#     cl = torch.min(l1, l2)\n#     ct = torch.min(t1, t2)\n#     cb = torch.max(b1, b2)\n#     D = (((x2 - x1)**2 + (y2 - y1)**2) \/ ((cr-cl)**2 + (cb-ct)**2 + 1e-7))\n#     out = inter \/ area_a if iscrowd else inter \/ union - D ** beta\n#     return out if use_batch else out.squeeze(0)\n\n# def multiclass_nms(multi_bboxes,\n#                    multi_scores,\n#                    score_thr,\n#                    nms_cfg,\n#                    max_num=-1,\n#                    score_factors=None,\n#                    return_inds=False):\n#     \"\"\"NMS for multi-class bboxes.\n\n#     Args:\n#         multi_bboxes (Tensor): shape (n, #class*4) or (n, 4)\n#         multi_scores (Tensor): shape (n, #class), where the last column\n#             contains scores of the background class, but this will be ignored.\n#         score_thr (float): bbox threshold, bboxes with scores lower than it\n#             will not be considered.\n#         nms_thr (float): NMS IoU threshold\n#         max_num (int, optional): if there are more than max_num bboxes after\n#             NMS, only top max_num will be kept. Default to -1.\n#         score_factors (Tensor, optional): The factors multiplied to scores\n#             before applying NMS. Default to None.\n#         return_inds (bool, optional): Whether return the indices of kept\n#             bboxes. Default to False.\n\n#     Returns:\n#         tuple: (dets, labels, indices (optional)), tensors of shape (k, 5),\n#             (k), and (k). Dets are boxes with scores. Labels are 0-based.\n#     \"\"\"\n#     iou_thr = nms_cfg['iou_threshold']\n#     num_classes = multi_scores.size(1) - 1\n#     # exclude background category\n#     if multi_bboxes.shape[1] > 4:\n#         bboxes = multi_bboxes.view(multi_scores.size(0), -1, 4)\n#     else:\n#         bboxes = multi_bboxes[:, None].expand(\n#             multi_scores.size(0), num_classes, 4)\n\n#     scores = multi_scores[:, :-1]\n\n#     labels = torch.arange(num_classes, dtype=torch.long).cuda()\n#     labels = labels.view(1, -1).expand_as(scores)\n\n#     bboxes = bboxes.reshape(-1, 4)\n#     scores = scores.reshape(-1)\n#     labels = labels.reshape(-1)\n\n#     if not torch.onnx.is_in_onnx_export():\n#         # NonZero not supported  in TensorRT\n#         # remove low scoring boxes\n#         valid_mask = scores > score_thr\n#     # multiply score_factor after threshold to preserve more bboxes, improve\n#     # mAP by 1% for YOLOv3\n#     if score_factors is not None:\n#         # expand the shape to match original shape of score\n#         score_factors = score_factors.view(-1, 1).expand(\n#             multi_scores.size(0), num_classes)\n#         score_factors = score_factors.reshape(-1)\n#         scores = scores * score_factors\n\n#     if not torch.onnx.is_in_onnx_export():\n#         # NonZero not supported  in TensorRT\n#         inds = valid_mask.nonzero(as_tuple=False).squeeze(1)\n#         bboxes, scores, labels = bboxes[inds], scores[inds], labels[inds]\n#     else:\n#         # TensorRT NMS plugin has invalid output filled with -1\n#         # add dummy data to make detection output correct.\n#         bboxes = torch.cat([bboxes, bboxes.new_zeros(1, 4)], dim=0)\n#         scores = torch.cat([scores, scores.new_zeros(1)], dim=0)\n#         labels = torch.cat([labels, labels.new_zeros(1)], dim=0)\n\n#     if bboxes.numel() == 0:\n#         if torch.onnx.is_in_onnx_export():\n#             raise RuntimeError('[ONNX Error] Can not record NMS '\n#                                'as it has not been executed this time')\n#         dets = torch.cat([bboxes, scores[:, None]], -1)\n#         if return_inds:\n#             return dets, labels, inds\n#         else:\n#             return dets, labels\n    \n#     # Weighted Cluster-DIoU-NMS\n#     scores, idx = scores.sort(0, descending=True)\n#     bboxes = bboxes[idx]\n#     labels = labels[idx]\n#     inds = inds[idx]\n#     box = bboxes + labels.unsqueeze(1).expand_as(bboxes)*4000\n\n#     diou_matrix = diou(box, box, 0.8)    # DIoU matrix\n#     iou = (diou_matrix+0).triu_(diagonal=1) \n#     B = iou\n#     for i in range(999):\n#         A=B\n#         maxA = A.max(dim=0)[0]\n#         E = (maxA <= iou_thr).float().unsqueeze(1).expand_as(A)\n#         B=iou.mul(E)\n#         if A.equal(B)==True:\n#             break\n#     B=torch.triu(diou_matrix).mul(E)\n#     keep = (maxA <= iou_thr)\n#     weights = (torch.exp(-(1-(B*(B>0.7).float()))**2 \/ 0.025)) * (scores.reshape((1,len(scores))))\n#     #weights = (B*(B>0.7).float()) * (scores.reshape((1,len(scores))))\n#     bboxes = torch.mm(weights, bboxes).float() \/ weights.sum(1, keepdim=True)\n\n#         # Only keep the top max_num highest scores across all classes\n#     if max_num > 0:\n#         scores = scores[keep][:max_num]\n#         labels = labels[keep][:max_num]\n#         bboxes = bboxes[keep][:max_num]\n#     dets = torch.cat([bboxes, scores[:, None]], dim=1)\n    \n#     if return_inds:\n#         return dets, labels, inds[keep]\n#     else:\n#         return dets, labels","59c3e076":"!pip install -e .","99ec0d8d":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport cupy as cp\nimport gc\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport cv2\nimport re\nimport shutil\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","d825a903":"%cd ..","32504853":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","28fe9af4":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","77c947a9":"def rle_encoding(x):\n    dots = np.where(x.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return ' '.join(map(str, run_lengths))","31bd5ed1":"def get_mask_from_result(result):\n    d = {True : 1, False : 0}\n    u,inv = np.unique(result,return_inverse = True)\n    mk = cp.array([d[x] for x in u])[inv].reshape(result.shape)\n#     print(mk.shape)\n    return mk","478c6e03":"def does_overlap(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            return True\n    return False\n\n\ndef remove_overlapping_pixels(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            print(\"Overlap detected\")\n            mask[np.logical_and(mask, other_mask)] = 0\n    return mask","a0ed923e":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w\/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","0533c32b":"from mmcv import Config\ncfg = Config.fromfile('\/kaggle\/working\/mmdetection\/configs\/cascade_rcnn\/cascade_mask_rcnn_x101_64x4d_fpn_20e_coco.py')\n# cfg = Config.fromfile('\/kaggle\/working\/mmdetection\/configs\/cascade_rcnn\/cascade_mask_rcnn_r50_fpn_20e_coco.py')","7c9c091f":"for head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 3\n    \ncfg.model.roi_head.mask_head.num_classes=3\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\n# cfg.data.test.pipeline[1].transforms[2] = dict(\n#                                             type='Normalize',\n#                                             mean=[128, 128, 128],\n#                                             std=[11.58, 11.58, 11.58],\n#                                             to_rgb=True)\n\ncfg.data.test.pipeline = cfg.test_pipeline\n\ncfg.model.test_cfg.rcnn.max_per_img = 3000\n\n# cfg.load_from = '..\/input\/cascade-mask-rcnn-mmdet\/cascade_mask_rcnn_x101_64x4d_fpn_20e_coco_20200512_161033-bdb5126a.pth'\n\ncfg.model.test_cfg.rpn.nms_pre = 3000\ncfg.model.test_cfg.rpn.nms_post = 3000\n\ncfg.work_dir = '\/kaggle\/working\/model_output'\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.img_norm_cfg = dict(  \n    mean=[128, 128, 128],  \n    std=[11.58, 11.58, 11.58],  \n    to_rgb=True)\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\nprint(f'Config:\\n{cfg.pretty_text}')","dd67d9f5":"confidence_thresholds = {0: 0.25, 1: 0.55, 2: 0.35}","55531739":"pixel_thresholds = {0: 75, 1: 150, 2: 75}","fec32e4b":"segms = []\nfiles = []","4eb11c6f":"model = init_detector(cfg, '..\/input\/mmdetection-neuron-training\/model_output\/epoch_7.pth')\nfor file in sorted(os.listdir('..\/input\/sartorius-cell-instance-segmentation\/test')):\n    img = mmcv.imread('..\/input\/sartorius-cell-instance-segmentation\/test\/' + file)\n    result = inference_detector(model, img)\n    show_result_pyplot(model, img, result)\n    previous_masks = []\n    for i, classe in enumerate(result[0]):\n        if classe.shape != (0, 5):\n            bbs = classe\n            sgs = result[1][i]\n            for bb, sg in zip(bbs,sgs):\n#                 print(sg)\n                box = bb[:4]\n                cnf = bb[4]\n                count = np.count_nonzero(sg)\n                if cnf >= confidence_thresholds[i] and count >= pixel_thresholds[i]:\n#                 if cnf >= confidence_thresholds[i]:\n                    mask = get_mask_from_result(sg)\n                    mask = remove_overlapping_pixels(mask, previous_masks)\n                    previous_masks.append(mask)\n\n    for mk in previous_masks:\n            rle_mask = rle_encoding(mk)\n            segms.append(rle_mask)\n            files.append(str(file.split('.')[0]))","96d1aaa1":"indexes = []\nfor i, segm in enumerate(segms):\n    if segm == '':\n        indexes.append(i)","d0d67acd":"for element in sorted(indexes, reverse = True):\n    del segms[element]\n    del files[element]","cdd34275":"files = pd.Series(files, name='id')\npreds = pd.Series(segms, name='predicted')","d9026573":"preds","5c374623":"submission_df = pd.concat([files, preds], axis=1)","fd1c75da":"submission_df.to_csv('submission.csv', index=False)","73cdbc5c":"submission_df","d7571beb":"shutil.rmtree('\/kaggle\/working\/mmdetection')","4abe66ed":"# **Helper Functions**","f4c396c0":"# **References**","ff9a03e2":"# **Import Libraries**","08b69052":"# **Model**","04366148":"# **Install MMDetection**","8c14dff0":"https:\/\/www.kaggle.com\/vexxingbanana\/sartorius-coco-dataset-notebook\n\nhttps:\/\/www.kaggle.com\/vexxingbanana\/sartorius-mmdetection-training","7f06f767":"# **Inference**","11bf4746":"# **Previous Notebooks**","b70e161a":"https:\/\/www.kaggle.com\/dschettler8845\/sartorius-segmentation-eda-and-baseline\n\nhttps:\/\/www.kaggle.com\/ihelon\/cell-segmentation-run-length-decoding\n\nhttps:\/\/www.kaggle.com\/stainsby\/fast-tested-rle\n\nhttps:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\n\nhttps:\/\/www.kaggle.com\/awsaf49\/sartorius-mmdetection-infer\n\nhttps:\/\/www.kaggle.com\/awsaf49\/sartorius-mmdetection-train\n\nhttps:\/\/www.kaggle.com\/evancofsky\/sartorius-torch-lightning-mask-r-cnn\/notebook"}}