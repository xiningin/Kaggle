{"cell_type":{"aa7e9aeb":"code","c1034687":"code","f67e7c78":"code","117dc4ae":"code","d3f65c6b":"code","9c585e97":"code","18a305b6":"code","11cd1268":"code","f118cf97":"code","949b4743":"code","3ddbdbc1":"code","ea4e3689":"code","88225023":"code","22062a86":"code","08f35de0":"code","da31ec93":"code","b461f7b1":"code","98b36e9e":"code","9b24d975":"code","c2111ff9":"code","1ba0c3ad":"code","cfe91984":"code","22ef453e":"code","b94555d2":"code","33b3ec68":"code","575428b8":"code","1202e202":"code","f74285bf":"code","1135273b":"code","c5e5a71c":"code","5c83f126":"code","c57c71e1":"code","f7ef633b":"code","d944c994":"code","5ef30261":"code","d868a7aa":"code","a79d2f69":"code","c7894263":"code","9d803dc1":"markdown","efeef73f":"markdown","6963473c":"markdown","31ab3d6f":"markdown","90cc4d3d":"markdown","e67ba741":"markdown","1110b45d":"markdown","534d6f1a":"markdown","29057497":"markdown","52d35f50":"markdown","7748713e":"markdown","bd5d5bd3":"markdown","e820ceef":"markdown","3f5727e6":"markdown","09160477":"markdown","f6533de0":"markdown","0efb84de":"markdown","a71cacc6":"markdown","a52e68ff":"markdown","1399fcde":"markdown","d340ef08":"markdown","3b4c0bdb":"markdown","8eb9ffe8":"markdown"},"source":{"aa7e9aeb":"!pip install pycaret -q","c1034687":"from pycaret.regression import *\n\nmodels()","f67e7c78":"from pycaret.classification import *\n\nmodels()","117dc4ae":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pycaret.classification import *","d3f65c6b":"data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')","9c585e97":"data.head()","18a305b6":"data.info()","11cd1268":"sns.countplot(data['Survived'])","f118cf97":"test_data.head()","949b4743":"test_data.info()","3ddbdbc1":"clf = setup(data, target = 'Survived', \n            train_size = 0.8,\n            numeric_imputation = 'median',\n            categorical_imputation = 'mode',\n            ignore_features = ['PassengerId','Name','Ticket'],\n            feature_selection = True,\n            remove_multicollinearity = True,\n            folds_shuffle = True,\n            session_id = 211, # Pseudo random number\n            html = False, silent = True)","ea4e3689":"top5_model = compare_models(sort = 'Accuracy', fold = 5, n_select = 5)","88225023":"for model in top5_model:\n    print(model)","22062a86":"predict_model(top5_model[2]); # Predict on validation set","08f35de0":"tuned_model = tune_model(top5_model[2], optimize = 'Accuracy', n_iter = 30, fold = 5)","da31ec93":"print('After Tune:')\nprint(tuned_model)","b461f7b1":"predict_model(tuned_model); # Predict on validation set","98b36e9e":"plot_model(tuned_model, plot = 'confusion_matrix')","9b24d975":"plot_model(tuned_model, plot='feature')","c2111ff9":"plot_model(tuned_model, plot = 'auc')","1ba0c3ad":"plot_model(tuned_model, plot = 'pr')","cfe91984":"# All in one but slow\n\n# evaluate_model(tuned_model)","22ef453e":"interpret_model(tuned_model)","b94555d2":"interpret_model(tuned_model, plot = 'reason', observation = 10)","33b3ec68":"final_model = finalize_model(tuned_model)","575428b8":"plot_model(final_model, plot = 'confusion_matrix')","1202e202":"predict_model(final_model); # Predict on validation set","f74285bf":"predictions = predict_model(final_model, data=test_data)\n\npredictions.head()","1135273b":"predictions.rename({'Label':'Survived'}, axis='columns', inplace = True)\n\npredictions.head()","c5e5a71c":"sns.countplot(predictions['Survived'])","5c83f126":"predictions[['PassengerId','Survived']].to_csv('.\/result.csv', index = False)","c57c71e1":"# tuned_model_0 = tune_model(top5_model[0], optimize = 'Accuracy', n_iter = 30, fold = 5)\n# tuned_model_1 = tune_model(top5_model[1], optimize = 'Accuracy', n_iter = 30, fold = 5)\n\n# fin_0 = finalize_model(tuned_model_0)\n# fin_1 = finalize_model(tuned_model_1)\n\n# print(fin_0)\n# print(fin_1)","f7ef633b":"# blender = blend_models(estimator_list = [final_model, fin_0, fin_1], method = 'hard')","d944c994":"# print(blender)","5ef30261":"# predictions_blend = predict_model(blender, data=test_data)\n\n# predictions_blend.rename({'Label':'Survived'}, axis='columns', inplace = True)","d868a7aa":"# sns.countplot(predictions_blend['Survived'])\n\n# predictions_blend[['PassengerId','Survived']].to_csv('.\/result_blend.csv', index = False)","a79d2f69":"# save_model(final_rf,'<path_of_file>')","c7894263":"# load_model('<path_of_file>')","9d803dc1":"# Let's Start\n\nCredit: https:\/\/towardsdatascience.com\/announcing-pycaret-2-0-39c11014540e","efeef73f":"## Prediction","6963473c":"Please note that ***plot_model*** cannot use in all model here. ***interpret_model*** can be used instead in that case.","31ab3d6f":"## Train Set","90cc4d3d":"## Test Set","e67ba741":"# Note","1110b45d":"## Classification Model","534d6f1a":"Can also setup this way\n\n**Compare only the specified model**\n\n> *best_specific = compare_models(include = ['dt','rf','xgboost'])*\n\n**Ignore the specified model**\n\n> *best_specific = compare_models(exclude = ['catboost','svm'])*\n\n**Or build model on your own**\n\n> *model = create_model('lightgbm', fold = 5)*\n\n**Note:**\n\nFirst thing you should know, Should keep all model at top 5 in for your decision because the result be will change after hyperparameter tuning.\n\nand also use the domain knowledge about data and machine learning model to choose the best one.\n\nOne last thing to keep in mind, \n**random seed** also effect to our model (to be precise, portion of data that split to be train set). Please be careful.","29057497":"Or you can set your **custom** hyperparameters tuning like this\n\n> params = {\"max_depth\": np.random.randint(1, (len(data.columns)*.85),20),\n>           \"max_features\": np.random.randint(1, len(data.columns),20),\n>           \"min_samples_leaf\": [2,3,4,5,6],\n>           \"criterion\": [\"gini\", \"entropy\"]\n>           }\n> \n> tuned_dt_custom = tune_model(dt, custom_grid = params)","52d35f50":"## Setup","7748713e":"# Import Data and Library","bd5d5bd3":"## Finalize","e820ceef":"Various type of machine learning model included in Pycaret","3f5727e6":"## Tuning","09160477":"## Model Selection","f6533de0":"---","0efb84de":"---","a71cacc6":"There are more ensemble method in **Pycaret** [website](https:\/\/pycaret.org\/ensemble-model\/).","a52e68ff":"## Regression Model","1399fcde":"# Install Pycaret","d340ef08":"## Model Ensembling","3b4c0bdb":"Some model cannot use ***plot_model***. So, please use ***interpret_model*** instead as follow","8eb9ffe8":"In Pycaret, you can easily use ***save_model*** for saving your model and ***load_model*** for loading."}}