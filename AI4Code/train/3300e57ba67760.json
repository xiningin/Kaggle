{"cell_type":{"8983d4c5":"code","1796679c":"code","f9b0b14b":"code","a82368c2":"code","9cd93df7":"code","33627f02":"code","621662cd":"code","4c5efe11":"code","ae83c705":"code","6230b772":"code","30f86600":"code","e920dc44":"code","f24cbf78":"code","1de78fe8":"markdown","2f1cf09a":"markdown","530dc9eb":"markdown","9b40e9e3":"markdown","c8d6bfa3":"markdown","c1387e2b":"markdown","b6ed7f65":"markdown","12d71116":"markdown"},"source":{"8983d4c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom sklearn import decomposition # used for PCA (Principal Components Analysis)\n\nfrom sklearn.linear_model import RidgeCV # for Ridge regression with Cross-Validation\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.RidgeCV.html\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport time\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output.","1796679c":"# load data set\nx_load = np.load('..\/input\/Sign-language-digits-dataset\/X.npy')\ny_load = np.load('..\/input\/Sign-language-digits-dataset\/Y.npy')\nimg_size = 64\n\n# one sample from each digits\nimage_index_list = [260,900,1800,1600,1400,2061,700,500,1111,100]\nfor each in range(10):\n    plt.figure(figsize=(8,5))\n    plt.imshow(x_load[image_index_list[each]].reshape(img_size, img_size))\n    plt.axis('off')\n    title = \"Sign \" + str(each) \n    plt.title(title)\nplt.show()","f9b0b14b":"X = x_load.reshape((len(x_load), -1)) #reshape(-1) : It simply means that it is an unknown dimension and we want numpy to figure it out\n\ntrain = X\ntest = X[image_index_list]\nn_pixels = X.shape[1]\n\n# Upper half of the faces\nX_train = train[:, :(n_pixels + 1) \/\/ 2]\nX_test = test[:, :(n_pixels + 1) \/\/ 2]\n\n# Lower half of the faces\ny_train = train[:, n_pixels \/\/ 2:]\ny_test = test[:, n_pixels \/\/ 2:]\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","a82368c2":"print(x_load.shape)\nprint(y_load.shape)\nprint(len(x_load))\nprint(X.shape)\nprint(train.shape)\nprint(test.shape)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n","9cd93df7":"# Fit estimators\nestimator = RidgeCV()\n\nstart = time.time()   # returns in second\nestimator.fit(X_train, y_train)\nend = time.time()\nprint(\"Training time is \"+ str(end - start) + \" second.\")\n\nstart = time.time()   # returns in second\ny_test_predict = estimator.predict(X_test)\nend = time.time()\nprint(\"Prediction time is \"+ str(end - start) + \" second.\")","33627f02":"# Plot the completed faces\nimage_shape = (64, 64)\nn_faces = 10\nn_cols = 1","621662cd":"X_test[0].shape","4c5efe11":"# Plot the completed faces\nimage_shape = (64, 64)\nplt.figure(figsize=(8, 24))\nfor i in range(10):\n    true_digits = np.hstack((X_test[i], y_test[i])) #numpy.hstack() function is used to stack the sequence  \n                                                    #of input arrays horizontally (i.e. row wise) to make a single array.\n    if i:\n        sub = plt.subplot(10, 2, i * 2 + 1)\n    else:\n        sub = plt.subplot(10, 2, i * 2 + 1, title=\"true digits\")\n    \n    sub.imshow(true_digits.reshape(image_shape),interpolation=\"nearest\")\n    sub.axis(\"off\")\n    completed_digits = np.hstack((X_test[i], y_test_predict[i]))\n\n    if i:\n        sub = plt.subplot(10, 2, i * 2 + 2 )\n\n    else:\n        sub = plt.subplot(10, 2, i * 2 + 2,title=\"RidgeCV\")\n\n    sub.imshow(completed_digits.reshape(image_shape),interpolation=\"nearest\")\n    sub.axis(\"off\")\n\nplt.show()","ae83c705":"n_components = 5\n(n_samples, n_features) = X.shape\nestimator = decomposition.PCA(n_components=n_components, svd_solver='randomized', whiten=True)\nestimator.fit(X)\ncomponents_ = estimator.components_\nimages = components_[:n_components]\nplt.figure(figsize=(6, 5))\nfor i, comp in enumerate(images):\n    vmax = max(comp.max(), -comp.min())  # ??\n    plt.imshow(comp.reshape((64, 64)),interpolation='nearest',vmin=-vmax, vmax=vmax)\n    plt.xticks(())\n    plt.yticks(())\nplt.savefig('graph.png')\nplt.show()","6230b772":"estimator","30f86600":"components_","e920dc44":"components_.shape","f24cbf78":"images\nprint(images.shape)","1de78fe8":"* Now lets visualize how we complete our images.","2f1cf09a":"* In sign language digits, most important things are fingers\n* After PCA, as you can see fingers are emphasized.\n* Try other images and play with n_components","530dc9eb":"* As a training set we will use all images.\n* As a test set we will choose ten images and use them.\n* **reshape(-1) :  It simply means that it is an unknown dimension and we want numpy to figure it out**\n* Difference between \"\/\/\" and \"\/\": for example 4097\/2 = 2048.5 (division) and 4097\/\/2 = 2048\n ","9b40e9e3":"## Principle Componenet Analysis (PCA)\n* I think it is very cool and good understanding way of PCA. \n* Fundemental dimension reduction technique\n* It is real life example. I hope it makes more sense for you.\n* Now lets try one more thing. \n* As you remember training time is almost 45 second. I think it is too much time. The reason of this time is number of sample(2062) and number of feature(4096). \n* There is two way to decrease time spend.\n    1. Decrease number of samples that I do no recommend.\n    1. Decrease number of features. As you see from images all signs are in the middle of the frames. Therefore, around signs are same for all signs. <a href=\"http:\/\/imgbb.com\/\"><img src=\"http:\/\/image.ibb.co\/nAu55x\/20.jpg\" alt=\"20\" border=\"0\"><\/a>\n    * Think that all of the pixels are features. Features which are out of the red frame is useless but pixels in red frame take part in  training and prediction steps.  Therefore, we need to make dimension reduction. \n    * PCA: Principle Component Analysis\n        * One of the most popular dimension reduction technique.\n        * PCA  uses high variances. It means that it likes diversity. For example compare two images above. Out of red frame there is no diversity (high variance). On the other hand, in red frames there is diversity.\n            * first step is decorrelation:\n                * rotates data samples to be aligned with axes\n                * shifts data Samples so they have mean zero\n                * no information lost\n                * **fit() : learn how to shift samples**\n                * **transform(): apply the learned transformation. It can also be applies test data( We do not use here but it is  good to know it.)**\n                * Resulting PCA features are **not** linearly correlated\n                * Principle components: directions of variance\n            * Second step: intrinsic dimension: number of features needed to approximate the data essential idea behind dimension reduction\n                * PCA identifies intrinsic dimension when samples have any number of features\n                * intrinsic dimension = number of PCA features with significant variance\n* Lets apply PCA and visualize what PCA says to us.","c8d6bfa3":"# Conclusion\n* If you like it, thank you for you upvotes.\n* **If you have any question, I will happy to hear it**\n","c1387e2b":"# Sign Language Digits completion with a multi-output estimators\n* While searching on the internet and I saw **completion with multi - output estimators**.\n> https:\/\/scikit-learn.org\/stable\/auto_examples\/miscellaneous\/plot_multioutput_face_completion.html\n* It looks like very cool to me and I want to share with you :)\n* In this kernel use of multi-output estimator to complete images. The goal is to predict the lower half of a sign language digits given its upper half. For example, we will train our model with first part and it will predict the second part. \n<a href=\"http:\/\/ibb.co\/jp0aNc\"><img src=\"http:\/\/preview.ibb.co\/i3hphc\/17.jpg\" alt=\"17\" border=\"0\"><\/a><br \/>\n* We will use **ridge regression with cross validation.**\n    * **What is ridge regression:** Linear least squares with l2 regularization\n        * **What is linear least square:** it is basically line fitting.<a href=\"http:\/\/ibb.co\/ibwJ8H\"><img src=\"http:\/\/preview.ibb.co\/eWkBTH\/18.jpg\" alt=\"18\" border=\"0\"><\/a><br \/>\n        * **What is l2 regularization:** Shortly, regularization is penalty term. When our model learn too much (over fit), we need to avoid it with regularization(penalty). Because, if we do not use regularization data will memorize the training set and cannot predict test set very well. For further information check my machine learning tutorial. For this kernel do not worry how to implement it, we will use sklearn. https:\/\/www.kaggle.com\/kanncaa1\/machine-learning-tutorial-for-beginners\n    * **What is cross validation:** Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it.  \n    <a href=\"http:\/\/imgbb.com\/\"><img src=\"http:\/\/image.ibb.co\/mHSdax\/19.jpg\" alt=\"19\" border=\"0\"><\/a>","b6ed7f65":"* As I mentioned, we will use ridgeCV.\n* Also lets print the training and prediction time\n","12d71116":"* Our data is sign language digits dataset.\n* Shape of our data is (2062,64,64). \n    * 2062 is number of images.\n    * There are 64x64 pixels.\n* Lets load the data. We will use all images that are from zero to nine.\n* There are totally 2062 images.\n* I will plot one sample from each digits."}}