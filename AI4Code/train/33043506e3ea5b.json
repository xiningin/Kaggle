{"cell_type":{"7f262d90":"code","7bd654b2":"code","8391f9d0":"code","07e4d1a6":"code","88aad8f7":"code","f98d167e":"code","312f7058":"code","a85ae991":"code","353e088f":"code","9db77bf6":"code","68956a74":"code","826e4468":"code","b14efc9d":"code","f68a614a":"code","d1d7f5f5":"code","53c397a2":"code","3829c40d":"code","dd43b487":"code","d50331d7":"code","c30c2fa0":"code","deeeb5ab":"code","ecbe3ce0":"code","50f4d5d0":"code","d72b659f":"code","47a17038":"code","cf9b533f":"code","fb2cee90":"code","7de3c5f2":"code","3b2eeb9e":"code","87146186":"code","f5db66b4":"code","5bc1db22":"code","a2a79f0c":"code","a29058e1":"code","c67ce934":"code","f06a74da":"code","12545b9e":"code","e90a0972":"code","00ea70e5":"code","fce0fbb2":"code","3545b339":"code","3b053bee":"code","64085e40":"code","78477c40":"code","f14638ce":"code","ce1dd8c6":"code","b19ea3e0":"code","7123561d":"code","d953e2a8":"code","5516d6d6":"markdown","00357051":"markdown","279d35c4":"markdown"},"source":{"7f262d90":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport scipy\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split , GridSearchCV\nfrom wordcloud import WordCloud,STOPWORDS\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.metrics import classification_report\n\nimport re, string\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import wordnet","7bd654b2":"import nltk; nltk.download('wordnet')","8391f9d0":"train_df = pd.read_csv('..\/input\/iba-ml1-final-project\/train.csv')\ntest_df = pd.read_csv('..\/input\/iba-ml1-final-project\/test.csv')","07e4d1a6":"# train_df = train_df.drop(\"Id\",axis=1)\ndf = pd.concat([train_df, test_df], 0)\nnrow_train = train_df.shape[0]\ny_train_1 = train_df[\"Rating\"]\ny_train_2 = train_df[\"Recommended\"]","88aad8f7":"df[\"Review\"] = df[\"Review\"].fillna(\"None\")\ndf[\"Review_Title\"] = df[\"Review_Title\"].fillna(\"None\")","f98d167e":"df['Review']","312f7058":"df['Review'] = df['Review'].apply(lambda x: re.split(r'\\W+', x))  # saving only words","a85ae991":"def remove_punctuations(words):\n  table = str.maketrans('', '', string.punctuation)\n  stripped = [w.translate(table) for w in words]\n  return stripped","353e088f":"df['Review']","9db77bf6":"df['Review'] = df['Review'].apply(remove_punctuations)  # removing punctuations","68956a74":"df['Review']","826e4468":"df['Review'] = df['Review'].apply(lambda x: [y.lower() for y in x]) # converting to lower case","b14efc9d":"df['processed'] = df['Review'].apply(lambda x: [WordNetLemmatizer().lemmatize(y) for y in x]) # Lemmatize every word.","f68a614a":"df['processed']","d1d7f5f5":"df['processed_review'] = df['processed'].apply(lambda x: [PorterStemmer().stem(y) for y in x]).apply(lambda x: ' '.join(x)) # Stem every word and concatinate them.","53c397a2":"df['processed_review']","3829c40d":"data = df[['processed_review','Rating']]","dd43b487":"tfidf = TfidfVectorizer(max_features=20000,ngram_range=(1,3),analyzer='char')","d50331d7":"X = tfidf.fit_transform(data['processed_review'])","c30c2fa0":"y = data['Rating']","deeeb5ab":"X_train,X_test,y_train,y_test = train_test_split(X[:nrow_train],y[:nrow_train],test_size=0.2)","ecbe3ce0":"param_space = {\n    'C': np.arange(0.01,30,3)\n}","50f4d5d0":"clf = LinearSVC()","d72b659f":"gridsearch = GridSearchCV(clf,param_space,cv=5)","47a17038":"gridsearch.fit(X_train,y_train)","cf9b533f":"gridsearch.best_params_","fb2cee90":"gridsearch.best_score_","7de3c5f2":"y_pred = gridsearch.best_estimator_.predict(X_test)","3b2eeb9e":"pd.Series(y_pred).hist()","87146186":"print(classification_report(y_test,y_pred))","f5db66b4":"X_train = X[:nrow_train]\ny_train = y[:nrow_train]","5bc1db22":"model = LinearSVC(C=3)","a2a79f0c":"model.fit(X_train,y_train)","a29058e1":"X_test = X[nrow_train:]","c67ce934":"preds = model.predict(X_test)","f06a74da":"preds","12545b9e":"pd.Series(preds).hist()","e90a0972":"prev_sub = pd.read_csv(\"submission2.csv\")","00ea70e5":"submission = pd.DataFrame({\n        \"Id\": test_df[\"Id\"],\n        \"Rating\": preds,\n        \"Recommended\" : prev_sub[\"Recommended\"],\n    })","fce0fbb2":"submission","3545b339":"submission.to_csv('.\/submission.csv', index=False)","3b053bee":"y2 = df['Recommended']","64085e40":"clf = SVC(C=10)","78477c40":"clf.fit(X_train,y2[:nrow_train])","f14638ce":"recommended_preds = clf.predict(X_test)","ce1dd8c6":"recommended_preds","b19ea3e0":"pd.Series(recommended_pred).hist()","7123561d":"submission = pd.DataFrame({\n        \"Id\": test_df[\"Id\"],\n        \"Rating\": preds,\n        \"Recommended\" : recommended_preds,\n    })","d953e2a8":"submission.to_csv('.\/submission3.csv', index=False)","5516d6d6":"# Creating final model for Rating","00357051":"Distribution of ratings seem close to original distribution","279d35c4":"# Unimportant"}}