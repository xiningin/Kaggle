{"cell_type":{"35830206":"code","7e17dbd0":"code","7e072988":"code","739e9add":"code","d2e3143b":"code","d4206842":"code","c5b0e705":"code","f1a073d4":"code","a0631011":"code","5940f2aa":"code","719b458c":"code","fcec0ca4":"code","bec5eb34":"code","8f619002":"code","75eafd6e":"code","95999f3a":"code","3eab87cd":"code","cfb3214c":"code","7e5e302c":"code","60d65bf8":"code","2e1c79a7":"code","a8c164df":"markdown","78a0d87b":"markdown","08ba4431":"markdown","52f8d633":"markdown","f9031b25":"markdown","6f146837":"markdown","d98d2bb9":"markdown","03d1d2de":"markdown","4f6b23dc":"markdown","d0916370":"markdown","4b5c4385":"markdown","80245bb8":"markdown","de7f254d":"markdown","2d49aeeb":"markdown","7e93b162":"markdown","4fabc9b9":"markdown","8bf551a2":"markdown","089a494a":"markdown","e3db71fd":"markdown","6fbcbc92":"markdown"},"source":{"35830206":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7e17dbd0":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\n\n# Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Splitting test data\nfrom sklearn.model_selection import train_test_split\n\n#Accuracy scores\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","7e072988":"train_data = pd.read_csv('..\/input\/assignment2\/train.csv', low_memory=False)\ntest_data = pd.read_csv('..\/input\/assignment2\/eval.csv', low_memory=False)","739e9add":"train_data.isnull().sum()","d2e3143b":"train_data['esrb_rating'].unique()","d4206842":"train_data['esrb'] = train_data['esrb_rating'].map({'E':0, 'ET':1, 'T':2, 'M':3})","c5b0e705":"features = ['alcohol_reference', 'animated_blood', 'blood', 'blood_and_gore', 'cartoon_violence', 'crude_humor', 'drug_reference', 'fantasy_violence', 'intense_violence', 'language', 'mature_humor', 'mild_blood', 'mild_cartoon_violence', 'mild_fantasy_violence', 'mild_language', 'mild_lyrics', 'mild_suggestive_themes', 'mild_violence', 'nudity', 'partial_nudity', 'sexual_content', 'sexual_themes', 'simulated_gambling', 'strong_janguage', 'strong_sexual_content', 'suggestive_themes', 'use_of_alcohol', 'use_of_drugs_and_alcohol', 'violence']\nX = train_data[features]\ny = train_data['esrb']\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=7)","f1a073d4":"model_lr = LinearRegression()\nmodel_lr.fit(train_X, train_y)\npredict1 = np.around(model_lr.predict(test_X)).astype(int)\noutput1 = pd.DataFrame({'id': test_X.index, 'esrb':predict1})\nprint(mean_squared_error(test_y, predict1, squared=False))\nprint(cross_val_score(model_lr, test_X, test_y, cv=3))\noutput1['esrb'].describe()","a0631011":"param_grid = {'C': [0.1, 1, 10, 100, 1000],\n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']}\n\ngrid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3)\ngrid.fit(train_X, train_y)","5940f2aa":"print(grid.best_params_)","719b458c":"model_svm = svm.SVC(kernel='rbf', C=100, gamma=0.01)\nmodel_svm.fit(train_X, train_y)\npredict2 = model_svm.predict(test_X)\noutput2 = pd.DataFrame({'id': test_X.index, 'esrb':predict2})\nprint(accuracy_score(test_y, model_svm.predict(test_X)))\nprint(cross_val_score(model_svm, test_X, test_y, cv=3))\noutput2['esrb'].describe()","fcec0ca4":"param_grid = {'max_depth': range(1,10),\n              'min_samples_split': range(1,10),\n              'min_samples_leaf': range(1,5)}\n\ngrid = GridSearchCV(DecisionTreeClassifier(), param_grid, refit = True, verbose = 3)\ngrid.fit(train_X, train_y)","bec5eb34":"print(grid.best_params_)","8f619002":"model_dt = DecisionTreeClassifier(max_depth=9, min_samples_leaf=1, min_samples_split=2)\nmodel_dt.fit(train_X, train_y)\npredict3 = model_dt.predict(test_X)\noutput3 = pd.DataFrame({'id': test_X.index, 'esrb':predict3})\nprint(accuracy_score(test_y, model_dt.predict(test_X)))\nprint(cross_val_score(model_dt, test_X, test_y, cv=3))\noutput3['esrb'].describe()","75eafd6e":"param_grid={'max_depth': range(1, 10),\n            'min_samples_leaf': range(1, 5),\n            'min_samples_split': range(1, 10)}\ngrid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3)\ngrid.fit(train_X, train_y)","95999f3a":"print(grid.best_params_)","3eab87cd":"model_rf = RandomForestClassifier(max_depth=7, min_samples_leaf=2, min_samples_split=6)\nmodel_rf.fit(train_X, train_y)\npredict4 = model_rf.predict(test_X)\noutput4 = pd.DataFrame({'id': test_X.index, 'esrb':predict4})\nprint(accuracy_score(test_y, model_rf.predict(test_X)))\nprint(cross_val_score(model_rf, test_X, test_y, cv=3))\noutput4['esrb'].describe()","cfb3214c":"param_grid = {'n_neighbors': range(1,10),\n              'leaf_size': range(1,10),\n              'p': [1,2]}\n\ngrid = GridSearchCV(KNeighborsClassifier(), param_grid, refit = True, verbose = 3)\ngrid.fit(train_X, train_y)","7e5e302c":"print(grid.best_params_)","60d65bf8":"model_kn = KNeighborsClassifier(leaf_size=4, n_neighbors=1, p=1)\nmodel_kn.fit(train_X, train_y)\npredict5 = model_kn.predict(test_X)\noutput5 = pd.DataFrame({'id': test_X.index, 'esrb':predict5})\nprint(accuracy_score(test_y, model_kn.predict(test_X)))\nprint(cross_val_score(model_kn, test_X, test_y, cv=3))\noutput5['esrb'].describe()","2e1c79a7":"predict_f = model_svm.predict(test_data[features])\n\npredict_final = []\nfor rating in predict_f:\n    if rating == 0:\n        predict_final.append('E')\n    if rating == 1:\n        predict_final.append('ET')\n    if rating == 2:\n        predict_final.append('T')\n    if rating == 3:\n        predict_final.append('M')\n\noutput = pd.DataFrame({'id': test_data.id, 'esrb_rating':predict_final})\noutput.to_csv('submission.csv', index=False)\nprint(output)","a8c164df":"# Making sure all ratings are either E, ET, T, or M\nAll ratings accounted for \/ every game has a rating.","78a0d87b":"# Creating the testing and training data","08ba4431":"# Random Forest Model","52f8d633":"- Finding the best paramaters for the KNN Model","f9031b25":"- Best parameters for the Decision Tree Model","6f146837":"# Importing the testing and training data","d98d2bb9":"- Best parameters for the Random Forest Model","03d1d2de":"# Linear Regression Model","4f6b23dc":"# Checking for null \/ empty data\nNo null or empty data was found.","d0916370":"- Finding the best parameters for the Decision Tree Model","4b5c4385":"- Best Parameters for KNN Model","80245bb8":"- Finding the best parmaters for the SVM","de7f254d":"- Best paramaters for SVM","2d49aeeb":"- Finding the best paramaters for the Random Forest Model","7e93b162":"# Import Statements","4fabc9b9":"# K-Nearest Neighbors Model","8bf551a2":"# Final model prediction and submission\nSVM model chosen for the best accuracy. Converting numerical ESRB ratings back into E, ET, T, and M for the final submission.","089a494a":"# Mapping ESRB ratings to 0-3\nThis way my models can predict the ratings numerically.","e3db71fd":"# Support Vector Model","6fbcbc92":"# Decision Tree Model"}}