{"cell_type":{"18d4e3b3":"code","13b220f1":"code","4cb8d4fb":"code","989b5b76":"code","ab849dd3":"code","7fb51fb9":"code","7582a7cc":"code","d3d3b564":"code","f38d4034":"code","6fc7c36f":"code","bf370617":"code","17c5cfb3":"code","f9d05a78":"code","6d997572":"code","a0cbfb8f":"code","91274643":"code","f23c8974":"code","079bec27":"code","8cfcfcbe":"code","fd598f70":"code","29f21ea3":"code","090d2deb":"code","22647be8":"code","fa222ac7":"code","b2f88c8f":"code","750f0e15":"code","835fe6e7":"code","b0003f19":"code","dae93314":"code","0c1145f2":"code","daa92ec0":"code","08548e15":"code","21330518":"code","d5639756":"code","66fd5fdf":"code","be14f682":"code","65d74791":"code","e57adc33":"code","2945ffbb":"code","46b024ff":"code","de3e7ac1":"code","3337ef0b":"code","f6379950":"code","3aa4cb5f":"code","aa7a4561":"code","f74d4651":"markdown","e944c626":"markdown","874eb7ae":"markdown","5fb00214":"markdown","55716765":"markdown","24a24dfe":"markdown","f172f59a":"markdown","da1b71c0":"markdown","f305acde":"markdown","62ef7720":"markdown","0eaa7792":"markdown","cdb89c20":"markdown","2d593111":"markdown","b696babe":"markdown","262fda8f":"markdown","05ad622f":"markdown","276c5253":"markdown","9804c896":"markdown","187ea892":"markdown","6945abd5":"markdown"},"source":{"18d4e3b3":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Subset\nimport torch.nn as nn\nimport torch.optim as optim\nfrom copy import deepcopy\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport seaborn as sns","13b220f1":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","4cb8d4fb":"labels = pd.read_csv('..\/input\/traffic-signs-classification\/labels.csv')\nlabels.head(10)","989b5b76":"def getLabel(id):\n    if(type(id) == type([])):\n        return labels.iloc[id]['Name'].values\n    else:\n        return labels.iloc[id]['Name']","ab849dd3":"transform = transforms.Compose([\n      transforms.ToTensor(),\n      transforms.Normalize((0.5,0.5,0.5), (0.5, 0.5, 0.5)),\n])","7fb51fb9":"dataset = ImageFolder('..\/input\/traffic-signs-classification\/myData', transform = transform)","7582a7cc":"print(len(dataset))","d3d3b564":"def train_val_test_split(dataset, val_split = 0.1, test_split = 0.1):\n    train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size = 0.1, random_state = 1)\n    datasets = {}\n    train_idx, val_idx = train_test_split(train_idx,test_size = 1\/9, random_state = 1)\n    datasets['train'] = Subset(dataset, train_idx)\n    datasets['val'] = Subset(dataset, val_idx)\n    datasets['test'] = Subset(dataset, test_idx)\n    return datasets","f38d4034":"datasets = train_val_test_split(dataset)","6fc7c36f":"traindata = datasets['train']\ntestdata = datasets['test']\nvaldata = datasets['val']","bf370617":"print(len(traindata), len(valdata), len(testdata))","17c5cfb3":"def getCount(dataloader):\n    cnt = []\n    for _ in range(num_classes):\n        cnt.append(0)\n    for data in dataloader:\n        _, labels = data\n        for x in labels:\n            cnt[x]+=1\n    return cnt","f9d05a78":"num_classes = 43\nbatch_size = 32","6d997572":"trainloader = torch.utils.data.DataLoader(traindata, batch_size = batch_size, shuffle = True)\ntestloader = torch.utils.data.DataLoader(testdata, batch_size = batch_size, shuffle = True)\nvalloader = torch.utils.data.DataLoader(valdata, batch_size = batch_size, shuffle = True)","a0cbfb8f":"traincount = getCount(trainloader)\nvalcount = getCount(valloader)\ntestcount = getCount(testloader)","91274643":"ids = list(range(0,num_classes))\nclasses = getLabel(ids)\n\nf, ax = plt.subplots(figsize=(20, 15))\n\nplt.bar(classes, traincount, color = 'g')\nplt.bar(classes, valcount, bottom = traincount, color = 'b')\nplt.bar(classes, testcount, bottom = [traincount[i]+valcount[i] for i in range(num_classes)], color = 'orange')\nplt.xlabel('Class name', fontsize = 20)\nplt.ylabel('No. of samples from each class', fontsize = 20)\nplt.title('Distribution of samples for each class', fontsize = 30)\nplt.legend(['Train distribution', 'Validation distribution', 'Test distribution'], prop = {\"size\":20})\nplt.xticks(rotation = 90)\nplt.show()","f23c8974":"def getImageFromEachClass(dataloader):\n    img = []\n    for i in range(num_classes):\n        img.append(0)\n    for data in dataloader:\n        images, labels = data\n        for i in range(len(images)):\n            img[labels[i]] = images[i]\n    return img","079bec27":"images = getImageFromEachClass(testloader)","8cfcfcbe":"def imshow(img, title):\n    npimg = img.numpy() \/ 2 + 0.5\n    plt.figure(figsize=(15, 15))\n    plt.axis('off')\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(title)\n    plt.show()","fd598f70":"img = torchvision.utils.make_grid(images)\nimshow(img, title='Random images from each class')","29f21ea3":"!pip install efficientnet_pytorch","090d2deb":"from efficientnet_pytorch import EfficientNet","22647be8":"def evaluation(dataloader, model):\n    total, correct = 0, 0\n    for data in dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n    return 100 * correct \/ total","fa222ac7":"iterations = []\naccuracies = []\nlosses = []\n\nmodel = EfficientNet.from_pretrained('efficientnet-b7')\n\nfor param in model.parameters():\n    param.required_grad = False\n\nin_features = model._fc.in_features\nmodel._fc = nn.Linear(in_features, num_classes)\n\nmodel = model.to(device)\nloss_fn = nn.CrossEntropyLoss()\nopt = optim.Adam(model.parameters(), lr = 0.0001)\n\nloss_epoch_arr = []\nmax_epochs = 3\n\nmin_loss = 1000000\n\nn_iters = np.ceil(58511\/batch_size)*max_epochs\niters = 0\n\nfor epoch in range(max_epochs):\n\n    for i, data in enumerate(trainloader, 0):\n        iters += 1\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        opt.zero_grad()\n\n        outputs = model(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        opt.step()\n        \n        if iters % 100 == 0:\n            curAccuracy =  evaluation(valloader, model)\n            curLoss = loss.item()\n            iterations.append(iters)\n            accuracies.append(curAccuracy)\n            losses.append(curLoss)\n            print('Iteration: %d\/%d, Loss: %0.2f, Validation acc: %0.2f'%(iters,n_iters, curLoss, curAccuracy))\n        \n        del inputs, labels, outputs\n        torch.cuda.empty_cache()\n    loss_epoch_arr.append(loss.item())\n    print('Epoch: %d\/%d ended. Validation acc: %0.2f, Train acc: %0.2f' % (\n      epoch+1, max_epochs, \n      evaluation(valloader, model), \n      evaluation(trainloader, model)))\n    \nprint('\\n\\nTest Accuarcy on final model: %0.4f' % evaluation(testloader, model))","b2f88c8f":"plt.figure(figsize = (10,6), facecolor = (0.900, 0.900, 0.900))\nplt.style.use('seaborn-darkgrid')\npalette = ['magenta','blue','green','red',\n'black','indigo','teal']\nplt.rcParams.update({'font.size': 10})\nplt.plot(iterations,accuracies, marker = '', color = 'teal', linewidth = 1, alpha = 1)\nplt.title('Validation accuracy graph',fontsize = 18)\nplt.xlabel('Iterations', fontsize = 14)\nplt.ylabel('Accuracy', fontsize = 14)","750f0e15":"plt.figure(figsize = (10,6), facecolor = (0.900, 0.900, 0.900))\nplt.style.use('seaborn-darkgrid')\npalette = ['magenta','blue','green','red',\n'black','indigo','teal']\nplt.rcParams.update({'font.size': 10})\nplt.plot(iterations,losses, marker = '', color = 'teal', linewidth = 1, alpha = 1)\nplt.title('Validation loss graph',fontsize = 18)\nplt.xlabel('Iterations', fontsize = 14)\nplt.ylabel('Loss', fontsize = 14)","835fe6e7":"device1 = torch.device(\"cpu\")","b0003f19":"images = []\nactual = []\npredicted = []\n\n\nfor data in testloader:\n    inputs, labels = data\n    inp = deepcopy(inputs)\n    lbl = deepcopy(labels)\n    inputs, labels = inputs.to(device), labels.to(device)\n    outputs = model(inputs)\n    _, pred = torch.max(outputs.data, 1)\n    pred.to(device1)\n    for i in range(pred.shape[0]):\n        images.append(inp[i])\n        predicted.append(pred[i].to(device1))\n        actual.append(lbl[i])","dae93314":"for i in range(len(actual)):\n    actual[i] = actual[i].numpy()\n    predicted[i] = predicted[i].numpy()","0c1145f2":"missclassifiedCount = 0\nfor i in range(len(actual)):\n    if(actual[i]!=predicted[i]):\n        missclassifiedCount+=1\nprint(missclassifiedCount)","daa92ec0":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n        \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize = 20)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label',fontsize = 18)\n    plt.xlabel('Predicted label', fontsize = 18)\n\ncm = confusion_matrix(actual, predicted)","08548e15":"plt.figure(figsize=(24,24))\nplot_confusion_matrix(cm,classes)","21330518":"csvdata = pd.read_csv('..\/input\/traffic-signs-classification\/labels.csv')","d5639756":"def getLabel(id):\n    if(type(id) == type([])):\n        return csvdata.iloc[id]['Name'].values\n    else:\n        return csvdata.iloc[id]['Name']","66fd5fdf":"def imshow(img, title):\n    npimg = img.numpy() \/ 2 + 0.5\n    plt.axis('off')\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(title)","be14f682":"print('Missclassified Images: ')\nfig = plt.figure(figsize=(30,100))\ncur = 0\nfor i in range(len(images)):\n    if(predicted[i] != actual[i]):\n        cur += 1\n        fig.add_subplot(20, 8, cur)\n        imshow(images[i], title = ('Predicted sign: ' + getLabel(predicted[i])) + '\\nActual sign: ' + getLabel(actual[i]))","65d74791":"correct = []\nmiss = []\nsum = 0\nfor i in range(num_classes):\n    correct.append(0)\n    miss.append(0)\nfor i in range(len(actual)):\n    if(actual[i] == predicted[i]):\n        correct[actual[i]]+=1\n    else:\n        miss[actual[i]]+=1\n        sum+=1\n\ntitles = []\nfor i in range(num_classes):\n    titles.append(classes[i] + \"    {:.2%}\".format(miss[i]\/sum))","e57adc33":"plt.figure(figsize = (24,24), facecolor = (0.900, 0.900, 0.900))\nplt.style.use('seaborn-darkgrid')\nfig, ax = plt.subplots()\nax.axis('equal')\npie = ax.pie(miss, radius=5,  labeldistance=0.7, labels=titles, rotatelabels = 270,startangle=180,counterclock=False)\nplt.title('Misclassification distribution', fontsize = 30)\nplt.show()","2945ffbb":"plt.figure(figsize = (24,24), facecolor = (0.900, 0.900, 0.900))\nplt.style.use('seaborn-darkgrid')\nimport matplotlib.pyplot as plt\nmissedpercentages = []\nfor i in range(num_classes):\n    missedpercentages.append(miss[i]\/(correct[i]+miss[i]))\n\nplt.barh(classes, missedpercentages)\n\nplt.ylabel(\"Traffic sign\", fontsize = 14)\n\nplt.xlabel(\"Percentage of misclassified samples\", fontsize = 14)\nplt.title(\"Misclassification rates\", fontsize = 24)\nplt.show()","46b024ff":"for i in range(len(classes)):\n    print(\"Traffic Sign -\", classes[i],': Misclassification rate -', missedpercentages[i])","de3e7ac1":"wronglyclassified = []\nfor i in range(num_classes):\n    wronglyclassified.append(0)\nfor i in range(len(actual)):\n    if(actual[i]!=predicted[i]):\n        wronglyclassified[predicted[i]]+=1","3337ef0b":"_labels = []\n_missed = []\n_wronglyclassified = []\n\nfor i in range(num_classes):\n    if(miss[i]!=0 and wronglyclassified[i]!=0):\n        _labels.append(classes[i])\n        _missed.append(miss[i])\n        _wronglyclassified.append(wronglyclassified[i])\n\n        \ndf = pd.DataFrame([ [_labels[i],_missed[i],_wronglyclassified[i]] for i in range(len(_labels)) ],\n                  columns=['Traffic Sign','Number of misclassified samples given that the actual class label is X', 'Number of samples misclassified as class X'])\n\ndf.plot(x='Traffic Sign',\n        kind='bar',\n        stacked=False,\n        title='False Positive vs True Negative comparision', figsize = (30,7))","f6379950":"matrix = []\nfor i in range(num_classes):\n    matrix.append([])\n    for j in range(num_classes):\n        matrix[i].append(0)\n\nfor i in range(len(actual)):\n    if(actual[i]!=predicted[i]):\n        matrix[actual[i]][predicted[i]]+=1\n\nsortedorder = []\nfor i in range(num_classes):\n    for j in range(0,i):\n        sortedorder.append([matrix[i][j]+matrix[j][i],i,j])\n\nsortedorder.sort(reverse = True)\n\nwhile(len(sortedorder)>20):\n    sortedorder.pop()","3aa4cb5f":"font_color = '#525252'\nhfont = {'fontname':'Calibri'}\nfacecolor = '#eaeaf2'\ncolor_red = '#fd625e'\ncolor_blue = '#01b8aa'\nindex = [classes[x[1]] + ' x ' + classes[x[2]] for x in sortedorder]\ncolumn0 = [matrix[x[1]][x[2]] for x in sortedorder]\ncolumn1 = [matrix[x[2]][x[1]] for x in sortedorder]\ntitle0 = 'Left class samples classified \\n as right class'\ntitle1 = 'Right class samples classified \\n as left class'","aa7a4561":"fig, axes = plt.subplots(figsize=(20,15), facecolor=facecolor, ncols=2, sharey=True)\nfig.tight_layout()\n\naxes[0].barh(index, column0, align='center', color=color_red, zorder=10)\naxes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\naxes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\naxes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n\naxes[0].invert_xaxis() \n\nplt.gca().invert_yaxis()\naxes[0].set(yticks=index, yticklabels=index)\naxes[0].yaxis.tick_left()\naxes[0].tick_params(axis='y', colors='white')\n\n\nfor label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n    label.set(fontsize=13, color=font_color, **hfont)\nfor label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n    label.set(fontsize=13, color=font_color, **hfont)\n\nplt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)","f74d4651":"### Reading class names from the csv file provided as a dictionary","e944c626":"## Contributors\n### K. Yaswanth Phani\n### Giwansh Aryan\n### P. Chetan Sai Kumar\n### B. Sai Pavan Kumar","874eb7ae":"#### Creating function to get class label for the given class id","5fb00214":"### Splitting the main dataset into test, train and validation","55716765":"## Validation loss and accuracy graphs","24a24dfe":"## Model training and testing","f172f59a":"## Visualizing top interrelated class pairs ","da1b71c0":"## Pie chart for the distribution of misclassified samples for each class","f305acde":"### Plotting an image from each class","62ef7720":"### Importing required packages","0eaa7792":"## Comparing False Negative and True Positive values","cdb89c20":"### Downloading EfficientNet model","2d593111":"#### Defining function for evaluation","b696babe":"## Horizontal barplot for misclassification rates for each class","262fda8f":"## Misclassified images visualization","05ad622f":"## Stacked barplot for the distribution data between train, validation and test splits for each class","276c5253":"### Making use of GPU provided by kaggle","9804c896":"##### Dataset size: 73139","187ea892":"## Confusion Matrix","6945abd5":"### Reading the image dataset"}}