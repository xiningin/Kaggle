{"cell_type":{"460f30b7":"code","f10a3318":"code","04e680d6":"code","d7bdb8fd":"code","a88d4da4":"code","1fb9c3b7":"code","6f928d5b":"code","f94a2965":"code","ca7a4077":"markdown","96e3ff79":"markdown","696f516e":"markdown","734f2524":"markdown"},"source":{"460f30b7":"print(\"\\n... PIP\/APT INSTALLS AND DOWNLOADS\/ZIP STARTING ...\")\n!pip install pandarallel\n!pip install -q tensorflow_model_optimization\n!pip install -q --upgrade tensorflow_datasets\nprint(\"... PIP\/APT INSTALLS COMPLETE ...\\n\")\n\n\nprint(\"\\n... IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t\u2013 TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_datasets as tfds; print(f\"\\t\\t\u2013 TENSORFLOW DATASETSVERSION: {tfds.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t\u2013 TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None; pd.set_option('max_columns', 100);\nimport numpy as np; print(f\"\\t\\t\u2013 NUMPY VERSION: {np.__version__}\");\n\n# Other\/Competition Related Imports\nfrom pandarallel import pandarallel; pandarallel.initialize();\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport scipy\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport matplotlib.patches as patches\n\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t\u2013 MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n    \n\nprint(\"\\n... SEEDING FOR DETERMINISTIC BEHAVIOUR ...\")\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_it_all()\nprint(\"... SEEDING COMPLETE ...\\n\")\n\nROOT_DIR = \"\/kaggle\"\nINPUT_DIR = os.path.join(ROOT_DIR, \"input\")\nLIB_DIR = os.path.join(INPUT_DIR, \"automl-efficientdet-efficientnetv2\")\n\nprint(\"\\n... SETUP EFFICIENTDET REPO STARTING ...\")\n# To give access to automl files\nsys.path.insert(0, os.path.join(LIB_DIR, \"automl\"))\nsys.path.insert(0, os.path.join(LIB_DIR, \"automl\", \"brain_automl\"))\nsys.path.insert(0, os.path.join(LIB_DIR, \"automl\", \"brain_automl\", \"efficientdet\"))\n    \n# EfficientNet Module Imports\nimport brain_automl\nfrom brain_automl import efficientdet\nfrom efficientdet.keras import efficientdet_keras\nimport hparams_config\n\nprint(\"... SETUP EFFICIENTDET REPO COMPLETE ...\\n\\n\")","f10a3318":"IMAGE_SIZE = (512,512)\nSEG_SIZE = (128,128)\n\ndef create_mask(pred_mask):\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]\n\n\ndef normalize(input_image, input_mask):\n    input_image = tf.cast(input_image, tf.float32) \/ 255.0\n    input_mask -= 1\n    return input_image, input_mask\n\n\ndef load_image_train(datapoint):\n    \"\"\"Load images for training.\"\"\"\n    input_image = tf.image.resize(datapoint['image'], IMAGE_SIZE)\n    input_mask = tf.image.resize(datapoint['segmentation_mask'], SEG_SIZE)\n\n    if tf.random.uniform(()) > 0.5:\n        input_image = tf.image.flip_left_right(input_image)\n        input_mask = tf.image.flip_left_right(input_mask)\n    input_image, input_mask = normalize(input_image, input_mask)\n\n    return input_image, input_mask\n\n\ndef load_image_test(datapoint):\n    input_image = tf.image.resize(datapoint['image'], IMAGE_SIZE)\n    input_mask = tf.image.resize(datapoint['segmentation_mask'], SEG_SIZE)\n    input_image, input_mask = normalize(input_image, input_mask)\n\n    return input_image, input_mask","04e680d6":"DS_DIR = os.path.join(INPUT_DIR, \"the-oxfordiiit-pet-dataset\")\nIMAGE_DIR = os.path.join(DS_DIR, \"images\", \"images\")\nLABEL_DIR = os.path.join(DS_DIR, \"annotations\", \"annotations\", \"trimaps\")\n\ndef plot_image_and_mask(name=None):\n    \"\"\" TODO \n    \n    Args:\n        name (str, optional): Name of file to plot w\/ mask.\n            If no name is passed than the image will be picked randomly\n     \n    Returns:\n        todo\n        \n    \"\"\"\n    if name is None:\n        name=os.listdir(IMAGE_DIR)[int(random.random()*len(IMAGE_DIR))][:-4]\n    \n    ############################    \n    # PLOTTING\n    ############################\n    plt.figure(figsize=(18,8))\n\n    plt.subplot(1,3,1)\n    original = np.asarray(Image.open(os.path.join(IMAGE_DIR, f'{name}.jpg')))\/255\n    plt.axis(False)\n    plt.title(\"Original Image\", fontweight=\"bold\")\n    plt.imshow(original)\n\n    plt.subplot(1,3,2)\n    mask = np.tile(np.expand_dims(np.asarray(Image.open(os.path.join(LABEL_DIR, f'{name}.png')))-1, axis=-1), 3)\n    mask = 1-mask\/np.max(mask)\n    \n    plt.axis(False)\n    plt.title(\"Segmentation Mask\", fontweight=\"bold\")\n    plt.imshow(mask)\n\n    plt.subplot(1,3,3)\n    combo = cv2.addWeighted(original,0.55,mask,0.5,0)\n    plt.axis(False)\n    plt.title(\"Original Image w\/ Mask Overlay\", fontweight=\"bold\")\n    plt.imshow(combo)\n\n    plt.tight_layout()\n    plt.show()\n    ############################\n    \nplot_image_and_mask()\nplot_image_and_mask()\nplot_image_and_mask()\nplot_image_and_mask()\nplot_image_and_mask()","d7bdb8fd":"BATCH_SIZE = 8\ntfds_ds, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n\nn_train = info.splits['train'].num_examples\nn_train_steps_per_epoch = n_train\/\/BATCH_SIZE\ntest_subsplits = 5\nn_test_steps_per_epoch = info.splits['test'].num_examples \/\/ BATCH_SIZE \/\/ test_subsplits\n\ntrain_ds = tfds_ds['train'].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\ntest_ds = tfds_ds['test'].map(load_image_test)\n\ntrain_ds = train_ds.shuffle(BATCH_SIZE*10)\\\n                   .batch(BATCH_SIZE)\\\n                   .prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)","a88d4da4":"# Get the configuration parameters (for segmentation)\nconfig = hparams_config.get_efficientdet_config('efficientdet-d0')\nconfig.heads = ['segmentation']\n\n# Make the d0-model\nmodel = efficientdet_keras.EfficientDetNet(config=config)\nmodel.build((1, 256, 256, 3))\nmodel.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\nmodel.summary()","1fb9c3b7":" model.fit(\n      train_ds,\n      epochs=10,\n      validation_data=test_ds,\n      callbacks=[]\n )","6f928d5b":"for img_batch, seg_batch in test_ds.take(1):\n    pred_batch = create_mask(model.predict(img_batch))\n    \nplt.figure(figsize=(18,40))\nfor i, (img, seg, pred) in enumerate(zip(img_batch, seg_batch, pred_batch)):\n    plt.subplot(BATCH_SIZE, 5, i*5+1)\n    plt.imshow(img)\n    plt.axis(False)\n    plt.title(\"Original Image\", fontweight=\"bold\")\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+2)\n    plt.imshow(seg.numpy(), cmap=\"gray\")\n    plt.axis(False)\n    plt.title(\"GT Segmentation Map\", fontweight=\"bold\")\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+3)\n    plt.imshow(pred, cmap=\"gray\")\n    plt.axis(False)\n    plt.title(\"Pred Segmentation Map\", fontweight=\"bold\")\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+4)\n    plt.axis(False)\n    plt.title(\"Image w\/ GT Overlay\", fontweight=\"bold\")\n    plt.imshow(img)\n    plt.imshow(cv2.resize(1-np.tile(seg.numpy(), 3), IMAGE_SIZE), cmap=\"jet\", alpha=0.55)\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+5)\n    plt.axis(False)\n    plt.title(\"Image w\/ Pred Overlay\", fontweight=\"bold\")\n    plt.imshow(img)\n    plt.imshow(cv2.resize(1-np.tile(pred.numpy().astype(np.float32), 3), IMAGE_SIZE), cmap=\"jet\", alpha=0.55)\n    \nplt.tight_layout()\nplt.show()","f94a2965":"for img_batch, seg_batch in test_ds.skip(1).take(1):\n    pred_batch = create_mask(model.predict(img_batch))\n    \nplt.figure(figsize=(18,40))\nfor i, (img, seg, pred) in enumerate(zip(img_batch, seg_batch, pred_batch)):\n    plt.subplot(BATCH_SIZE, 5, i*5+1)\n    plt.imshow(img)\n    plt.axis(False)\n    plt.title(\"Original Image\", fontweight=\"bold\")\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+2)\n    plt.imshow(seg.numpy(), cmap=\"gray\")\n    plt.axis(False)\n    plt.title(\"GT Segmentation Map\", fontweight=\"bold\")\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+3)\n    plt.imshow(pred, cmap=\"gray\")\n    plt.axis(False)\n    plt.title(\"Pred Segmentation Map\", fontweight=\"bold\")\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+4)\n    plt.axis(False)\n    plt.title(\"Image w\/ GT Overlay\", fontweight=\"bold\")\n    plt.imshow(img)\n    plt.imshow(cv2.resize(1-np.tile(seg.numpy(), 3), IMAGE_SIZE), cmap=\"jet\", alpha=0.55)\n    \n    plt.subplot(BATCH_SIZE, 5, i*5+5)\n    plt.axis(False)\n    plt.title(\"Image w\/ Pred Overlay\", fontweight=\"bold\")\n    plt.imshow(img)\n    plt.imshow(cv2.resize(1-np.tile(pred.numpy().astype(np.float32), 3), IMAGE_SIZE), cmap=\"jet\", alpha=0.55)\n    \nplt.tight_layout()\nplt.show()","ca7a4077":"## Setup EfficientDet","96e3ff79":"## Utility Functions","696f516e":"## Imports & Basic Setup","734f2524":"## Setup Paths to On-Disk Dataset And Plot Examples"}}