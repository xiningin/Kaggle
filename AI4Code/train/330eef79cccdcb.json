{"cell_type":{"a745c43a":"code","45a86fdd":"code","79492cd0":"code","f3bc9f20":"code","8a96550f":"code","d7f81f20":"code","5811e727":"code","d4ea6320":"code","c9377c39":"code","cf238189":"code","3292e34a":"code","8b736fb4":"code","f2a812dc":"code","48a1be8d":"code","dd58a5ed":"code","59e37042":"code","e2a44dcd":"code","c5e1254c":"code","4595a96a":"code","4d39ca4c":"code","b97fbf81":"code","cb476b56":"code","bd50dfb6":"code","34a197ca":"code","6bf2d647":"code","78396f27":"code","ce3333a6":"code","0a18ec50":"code","75d42523":"code","af1913df":"code","f2c095cc":"markdown","cbc9ced1":"markdown","1e88f237":"markdown","8723cca3":"markdown","2710b3de":"markdown","79c8cbc5":"markdown","93c10cb9":"markdown","4f560db2":"markdown","82f3c75c":"markdown","b0ede476":"markdown","69430bb7":"markdown","c571cb68":"markdown","78ee1f69":"markdown","4d502c40":"markdown","f09a1b68":"markdown","ba784762":"markdown","ef8a3bdb":"markdown","bc21cf5a":"markdown","8030b964":"markdown","edd480d2":"markdown","e84bee92":"markdown","b60f8f37":"markdown"},"source":{"a745c43a":"# Import libraries necessary for this project\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Import the supervised learning models form sklearn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import fbeta_score, accuracy_score, roc_auc_score, make_scorer\n\n\n# Load the Census dataset\ndata = pd.read_csv(\"..\/input\/udacity-mlcharity-competition\/census.csv\")\n\n# Display the first five records\ndata.head()","45a86fdd":"# gain statistics insight\ndata.describe()","79492cd0":"# TODO: Total number of records\nn_records = data.shape[0]\n\n# TODO: Number of records where individual's income is more than $50,000\nn_greater_50k = len(data[data['income']=='>50K'])\n\n# TODO: Number of records where individual's income is at most $50,000\nn_at_most_50k = len(data[data['income']=='<=50K'])\n\n# TODO: Percentage of individuals whose income is more than $50,000\ngreater_percent = n_greater_50k\/n_records\n\n# Print the results\nprint(\"Total number of records: {}\".format(n_records))\nprint(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\nprint(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\nprint(\"Percentage of individuals making more than $50,000: {:.2f}%\".format(greater_percent*100))","f3bc9f20":"# split features and target\nincome_raw = data['income']\nfeature_raw = data.drop('income', axis=1)","8a96550f":"# continues features\ncontinues = list(feature_raw.describe().columns)\nprint(continues)","d7f81f20":"for col in feature_raw.columns:\n    if col not in continues:\n        values = list(data[col].value_counts().index)\n        print('{}: {}'.format(col, ', '.join(values)))\n        print('\\n')","5811e727":"# check the distributions of those continues features\nfor col in continues:\n    a = sns.FacetGrid(feature_raw, height=8, aspect=2)\n    a.map(sns.distplot, col, kde_kws={'bw': 25})\n    a.add_legend\n    print('{} skew: {}'.format(col, feature_raw[col].skew()))","d4ea6320":"# Log-transform the skewed features\nskewed = ['capital-gain', 'capital-loss']\nfeatures_log_transformed = pd.DataFrame(data = feature_raw)\nfeatures_log_transformed[skewed] = feature_raw[skewed].apply(lambda x: np.log(x + 1))","c9377c39":"for col in skewed:\n    print('{} skew: {}'.format(col, features_log_transformed[col].skew()))","cf238189":"# show the distributions after log-transform\nsns.set()\nfig = plt.figure(figsize=(11,5))\nfig.suptitle(\"Log-transformed Distributions of Continuous Census Data Features\", fontsize=16)\n\nfor i, feature in enumerate(skewed):\n    ax = fig.add_subplot(1, 2, i+1)\n    ax.hist(features_log_transformed[feature], bins=25)\n    ax.set_title(\"{} Feature Distribution\".format(feature), fontsize=14)\n    ax.set_xlabel(\"Value\")\n    ax.set_ylabel(\"Number of Records\")\n    ax.set_ylim((0,2000))\n    ax.set_yticks([0, 500, 1000, 1500, 2000])\n    ax.set_yticklabels([0, 500, 1000, 1500, \">2000\"])","3292e34a":"# Import sklearn.preprocessing.StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Initialize a scaler, then apply it to the features\nscaler = MinMaxScaler()\n\nfeatures_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\nfeatures_log_minmax_transform[continues] = scaler.fit_transform(features_log_transformed[continues])\n\n# Show an example of a record with scaling applied\nfeatures_log_minmax_transform.head()","8b736fb4":"# One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\nfeatures_final = pd.get_dummies(features_log_minmax_transform)\n\n# Encode the 'income_raw' data to numerical values\nincome = income_raw.map({\"<=50K\":0, \">50K\":1})\n\n# Print the number of features after one-hot encoding\nencoded = list(features_final.columns)\nprint(\"{} total features after one-hot encoding.\".format(len(encoded)))\n","f2a812dc":"features_final.head()","48a1be8d":"# Split the 'features' and 'income' data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features_final, \n                                                    income, \n                                                    test_size = 0.2, \n                                                    random_state = 0)\n\n# Show the results of the split\nprint(\"Training set has {} samples.\".format(X_train.shape[0]))\nprint(\"Testing set has {} samples.\".format(X_test.shape[0]))","dd58a5ed":"# create a training and predicting pipeline\n\ndef train_predict(learner, X_train, y_train, X_test, y_test): \n    '''\n    inputs:\n       - learner: the learning algorithm to be trained and predicted on\n       - X_train: features training set\n       - y_train: income training set\n       - X_test: features testing set\n       - y_test: income testing set\n    '''\n    \n    results = {}\n    \n    # Fit the learner to the training data \n    start = time() # Get start time\n    learner = learner.fit(X_train, y_train)\n    end = time() # Get end time\n    \n    # Calculate the training time\n    results['train_time'] = end - start\n        \n    # Get the predictions on the test set(X_test),\n    # then get predictions on the first 300 training samples\n    start = time() # Get start time\n    predictions_test = learner.predict(X_test)\n    predictions_train = learner.predict(X_train[:300])\n    end = time() # Get end time\n    \n    # Calculate the total prediction time\n    results['pred_time'] = end - start\n            \n    # Compute accuracy on the first 300 training samples which is y_train[:300]\n    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n        \n    # Compute accuracy on test set using accuracy_score()\n    results['acc_test'] = accuracy_score(y_test, predictions_test)\n    \n    # Compute F-score on the the first 300 training samples using fbeta_score()\n    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta=0.5)\n        \n    # Compute F-score on the test set which is y_test\n    results['f_test'] = fbeta_score(y_test, predictions_test, beta=0.5)\n    \n    # Compute roc_auc_score on the first 300 training samples which is y_train[:300]\n    results['roc_auc_score_train'] = roc_auc_score(y_train[:300], learner.predict_proba(X_train[:300])[:, 1])\n    \n    # Compute roc_auc_score on the test set which is y_test\n    results['roc_auc_score_test'] = roc_auc_score(y_test, learner.predict_proba(X_test)[:, 1])\n    \n    print('{} trained on {} samples'.format(learner.__class__.__name__, len(X_train)))\n    print('\\n'+'-'*10)\n    # Return the results\n    return results","59e37042":"# TODO: Initialize the four models\nclf_A = MultinomialNB()\nclf_B = RandomForestClassifier()\nclf_C = AdaBoostClassifier()\nclf_D = GradientBoostingClassifier()\n\n\n# Collect results on the learners\nresults = {}\nfor clf in [clf_A, clf_B, clf_C, clf_D]:\n    clf_name = clf.__class__.__name__\n    results[clf_name] = train_predict(clf, X_train, y_train, X_test, y_test)\n    ","e2a44dcd":"# create a dataframe for those metrics\nmetrics_frame = pd.DataFrame(data=results).transpose().reset_index()\nmetrics_frame = metrics_frame.rename(columns={'index': 'models'})\nmetrics_frame","c5e1254c":"# show the visulization\n# create shape(4,2) grouped bar plots, it displays metrics of both train and test on each row.\nfig, ax = plt.subplots(4,2, figsize=(20, 30))\n    \n# column list for metrics\nmetrics_col = list(metrics_frame.columns[1:])\ni=0\nj=0\nfor col in range(int(len(metrics_col)\/2)):\n    \n    sns.barplot(x='models', y=metrics_col[2*col], data=metrics_frame, ax=ax[i, j])\n    j+=1\n    sns.barplot(x='models', y=metrics_col[2*col+1], data=metrics_frame, ax=ax[i, j])\n    i+=1\n    j-=1\n    if i==4 and j==0:\n        break\n        \n    # set ylim(0,1) for the three metrics(accuracy, fbeta_score, roc_au_score)\n    ax[i,j].set_ylim((0, 1))\n    ax[i, j+1].set_ylim((0,1))\n\nplt.suptitle(\"Performance Metrics for Supervised Learning Models\", fontsize = 25, y = 1.10)\nplt.tight_layout()\n","4595a96a":"# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\n\n# TODO: Initialize the classifier\nclf = AdaBoostClassifier()\n\n# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\nparameters = {'n_estimators':[50, 200, 400, 1000], 'learning_rate':[0.01, 0.1, 0.5, 1]}\n\n# TODO: Make an fbeta_score scoring object using make_scorer()\nscorer = make_scorer(roc_auc_score)\n\n# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\ngrid_obj = GridSearchCV(clf, parameters, scoring=scorer, n_jobs=-1)\n\n# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train, y_train)\n\n# Get the estimator\nbest_clf = grid_fit.best_estimator_\n\n# Make predictions using the unoptimized and model\npredictions = (clf.fit(X_train, y_train)).predict(X_test)\nbest_predictions = best_clf.predict(X_test)\n","4d39ca4c":"# Report the before-and-afterscores\nprint(\"Unoptimized model\\n------\")\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\nprint(\"Roc_au_score on testing data: {:.4f}\".format(roc_auc_score(y_test, clf.fit(X_train, y_train).predict_proba(X_test)[:,1])))\nprint(\"\\nOptimized Model\\n------\")\nprint(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\nprint(\"Roc_au_score on testing data: {:.4f}\".format(roc_auc_score(y_test, best_clf.predict_proba(X_test)[:,1])))","b97fbf81":"submission = pd.read_csv('..\/input\/udacity-mlcharity-competition\/test_census.csv')\nsubmission.head()","cb476b56":"submission.info()","bd50dfb6":"# fill missing values with mean for continues features\nfor col in ['age', 'education-num', 'hours-per-week']:\n    submission[col] = submission[col].fillna(submission[col].mean())\n    \n# fill missing values with median for skewed features\nfor col in skewed:\n    submission[col] = submission[col].fillna(submission[col].median())\n    \n# fill missing values with most frequent values for categorical features\nfor col in submission.columns:\n    if col not in continues:\n        most_frequent_values = submission[col].value_counts().sort_values().index[-1]\n        submission[col] = submission[col].fillna(most_frequent_values)        ","34a197ca":"# check again\nsubmission.info()","6bf2d647":"# log transform skewed features\nfor col in skewed:\n    submission[col] = submission[col].apply(lambda x: np.log(x+1))","78396f27":"# normalize numerical features\nscaler = MinMaxScaler()\nsubmission[continues] = scaler.fit_transform(submission[continues])","ce3333a6":"# one-hot encoding for categorical features\nsubmission = pd.get_dummies(submission)\nprint('{} total features after one_hot encoding.'.format(len(submission.columns)))","0a18ec50":"# drop first columns\nsubmission_final = submission.drop('Unnamed: 0', 1)","75d42523":"# predict the results using the tuned model and output the file\nsubmission['id'] = np.arange(len(submission))\nsubmission['income'] = (best_clf.predict_proba(submission_final))[:, 1]\nsubmission[['id', 'income']].to_csv('submission.csv', index=False)","af1913df":"!!jupyter nbconvert *.ipynb","f2c095cc":"**summary**\n- **Metrics**:\nAs expected, ensembel models are good preditors.As for the four models, all of them performed well in regards to the metrics of accuracy, fbeta_score and rou_auc_score. Especially, the random forest performed the best in tranining data while no better than the ensembel models in the test data.\n- **Computation complexity**:\nObviously, the MultinomialNB is the fastest model both on training and predicting data which is way better than other models. Random forest is the second lowest model on training data, but the slowest on prediction. As for ensemble models, AdaBoost is better than GradientBoosting on both training and prediction.\n\nTherefore, I choose AdaBoost classifier over GradientBoosting classifier. Although GradientBoosting performed slightly better than AdaBoost on the three metrics, AdaBoost has much lower training time, manageable prediction time and less parameters than GradientBoosting, which makes it easier for tuning.","cbc9ced1":"### Implementation: Data Preprocessing\n\nFrom the table in **Data Exploration** above, we can see there are several features for each record that are non-numeric(categorical values). Typically, learning algorithms expect input to be numeric, which requires that non-numeric features be converted. One popular way to convert categorical variables is by using the **one-hot encoding** scheme, which creates a _\"dummy\"_ variable for each possible category of each non-numeric feature.\n\nAdditionally, as with the non-numeric features, we need to convert the non-numeric target label, `'income'` to numerical values for the learning algorithm to work. Since there are only two possible categories for this label (\"<=50K\" and \">50K\"), we can avoid using one-hot encoding and simply encode these two categories as `0` and `1`, respectively. ","1e88f237":"For highly-skewed feature distributions such as `'capital-gain'` and `'capital-loss'`, it is common practice to apply a <a href=\"https:\/\/en.wikipedia.org\/wiki\/Data_transformation_(statistics)\">logarithmic transformation<\/a> on the data so that the very large and very small values do not negatively affect the performance of a learning algorithm. Using a logarithmic transformation significantly reduces the range of values caused by outliers. Care must be taken when applying this transformation however: The logarithm of `0` is undefined, so we must translate the values by a small amount above `0` to apply the the logarithm successfully.","8723cca3":"### Implementation - Creating a Training and Predicting Pipeline\nTo properly evaluate the performance of each chosen model, it's important to create a training and predicting pipeline to quickly and effectively train models using various sizes of training data and perform predictions on the testing data. My implementation here will be used in the following section.\n\n\n - Fit the learner to the sampled training data and record the training time.\n - Perform predictions on the test data `X_test`, and also on the first 300 training points `X_train[:300]`.\n   - Record the total prediction time.\n - Calculate the accuracy_score for both the training subset and testing set.\n - Calculate the fbeta_score for both the training subset and testing set (here, beta will be set to 0.5, for precision rate is more important regarding this situation, cause we dont want to send email to people whose income is lower than 50k. Therefore, it's better to have a lower number of false positive).\n - Calculate the roc_auc_score for both the training subset and testing set.\n","2710b3de":"## Getting Started\n\nIn this project, I will employ several supervised algorithms to accurately model individuals' income using data collected from the 1994 U.S. Census. I will then choose the best candidate algorithm from preliminary results and further optimize this algorithm to best model the data. My goal with this implementation is to construct a model that accurately predicts whether an individual makes more than $50,000. This sort of task can arise in a non-profit setting, where organizations survive on donations.  Understanding an individual's income can help a non-profit better understand how large of a donation to request, or whether or not they should reach out to begin with.\n\nThe dataset for this project originates from the [UCI Machine Learning Repository](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Census+Income). The datset was donated by Ron Kohavi and Barry Becker, after being published in the article _\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_. You can find the article by Ron Kohavi [online](https:\/\/www.aaai.org\/Papers\/KDD\/1996\/KDD96-033.pdf). The data we investigate here consists of small changes to the original dataset, such as removing the `'fnlwgt'` feature and records with missing or ill-formatted entries.","79c8cbc5":"1. Data Exploration\n2. Data Preprocessing\n3. Exploring different supervised algorithms to find the best one\n4. Tune the best model to get a better metric","93c10cb9":"----\n## Evaluating Model Performance\nIn this section, I will investigate five different algorithms, and determine which is best at modeling the data. My assumption is that the ensemble models will outperform other models.It runs efficiently on large datasets. Naive Bayes model performs well with categorical variables, but the cons lie in that correlated features may influence performance. As for KNN, it can often gives reasonable performance without a lot of adjustments, however it will be incapable of many features(hundreds or more), it does particularly badly with datasets where most features are 0 most of the time (so-called sparse datasets). Therefore, I will not choose KNN for this condition.","4f560db2":"### Implementation: Model Tuning\n\n- Initialize the classifier and store it in `clf`.\n- Create a dictionary of parameters for the chosen model.\n- Use `make_scorer` to create an `roc_au_score` scoring object.\n- Perform grid search on the classifier `clf` using the `'scorer'`, and store it in `grid_obj`.\n- Fit the grid search object to the training data (`X_train`, `y_train`), and store it in `grid_fit`.","82f3c75c":"----\n## Preprocessing the Data\nBefore data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured \u2014 this is typically known as **preprocessing**. Fortunately, for this dataset, there are no invalid or missing entries we must deal with, however, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms.","b0ede476":"**Featureset Exploration Summary**\n\n* **age**: continuous. \n* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n* **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n* **education-num**: continuous. \n* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n* **sex**: Female, Male. \n* **capital-gain**: continuous. \n* **capital-loss**: continuous. \n* **hours-per-week**: continuous. \n* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.","69430bb7":"### Normalizing Numerical Features\nIn addition to performing transformations on features that are highly skewed, it is often good practice to perform some type of scaling on numerical features. Applying a scaling to the data does not change the shape of each feature's distribution (such as `'capital-gain'` or `'capital-loss'` above); however, normalization ensures that each feature is treated equally when applying supervised learners. We will use [`sklearn.preprocessing.MinMaxScaler`](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.MinMaxScaler.html) for this.","c571cb68":"## Apply on Submission Set","78ee1f69":"### Implementation: Initial Model Evaluation\nIn the code cell, I will implement the following:\n- Initialize the three models and store them in `'clf_A'`, `'clf_B'`, `'clf_C'` and `'clf_D'`.\n- Collect different metrics results on the learners, and store them in a dict.","4d502c40":"## Supervised Learning\n## Project: Finding Donors for *CharityML*","f09a1b68":"----\n## Data Exploration\n","ba784762":"#### Results:\n\n|     Metric     | Unoptimized Model | Optimized Model |\n| :------------: | :---------------: | :-------------: | \n| Accuracy Score |  0.8576           |  0.8676         |\n| F-score        |  0.7246           |  0.7448         |\n| Roc_au_score   |  0.9148           |  0.9268         |    \n","ef8a3bdb":"### Final Model Evaluation\n","bc21cf5a":"### Preprocessing the submission set","8030b964":"### Shuffle and Split Data\nNow all _categorical variables_ have been converted into numerical features, and all numerical features have been normalized. As always, we will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing.","edd480d2":"### Transforming Skewed Continuous Features\nA dataset may sometimes contain at least one feature whose values tend to lie near a single number, but will also have a non-trivial number of vastly larger or smaller values than that single number.  Algorithms can be sensitive to such distributions of values and can underperform if the range is not properly normalized. With the census dataset two features fit this description: '`capital-gain'` and `'capital-loss'`. ","e84bee92":"----\n## Improving Results\nIn this final section, I will then perform a grid search optimization for the AdaBoost classifier over the entire training set (`X_train` and `y_train`) by tuning at least one parameter to improve upon the untuned model's roc_au_score. ","b60f8f37":"###  Supervised Learning Models\n**The following are the supervised learning models I will choose to check in regards of performance**\n- Gaussian Naive Bayes (GaussianNB)\n- Ensemble Methods (AdaBoost, Random Forest, Gradient Boosting)"}}