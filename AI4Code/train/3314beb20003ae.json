{"cell_type":{"3036bacf":"code","44642f46":"code","18209425":"code","878b89c6":"code","f19fe9ed":"code","019ceeff":"code","862e92e7":"code","25f22f65":"code","faf84a13":"code","40938ac6":"code","50bf87a0":"code","b3126599":"code","2121f41d":"code","efc772c2":"code","1823a11b":"code","5f2563e8":"code","68c0f05d":"code","eaddbbb2":"code","51e2f3fa":"code","31b94ee5":"code","2be26905":"code","b5329cbf":"markdown","e26cd30c":"markdown","3a6c3061":"markdown","a72e2946":"markdown","6511cfb4":"markdown","99517601":"markdown","16f0c281":"markdown","24296afa":"markdown","e97d27a1":"markdown","f7e50104":"markdown"},"source":{"3036bacf":"import numpy as np \nimport pandas as pd \n\nimport os\nprint(os.listdir(\"..\/input\"))","44642f46":"from sklearn.model_selection import train_test_split\n\ndef read_data():\n    df = pd.read_csv(\"..\/input\/train.csv\")\n    print (\"Shape of base training File = \", df.shape)\n    # Remove missing values and duplicates from training data\n    df.drop_duplicates(inplace=True)\n    df.dropna(inplace=True)\n    print(\"Shape of base training data after cleaning = \", df.shape)\n    return df\n\ndf = read_data()\ndf_train, df_test = train_test_split(df, test_size = 0.02)\nprint (\"\\n\\n\", df_train.head(10))\nprint (\"\\nTrain Shape : \", df_train.shape)\nprint (\"Test Shape : \", df_test.shape)","18209425":"import matplotlib.pyplot as plt\n\ndef eda(data):\n    dup_check = data['is_duplicate'].value_counts()\n    plt.bar(dup_check.index, dup_check.values)\n    plt.ylabel('Number of Queries')\n    plt.xlabel('Is Duplicate')\n    plt.title('Data Distribution', fontsize = 18)\n    plt.show()\n    \n    print(\"\\nAbove Graph Features :  [Is Not Duplicate | Is Duplicate]\\n\")\n    print(\"Above Graph Indices  : \", dup_check.index)\n    print(\"\\nAbove Graph Values   : \", dup_check.values)\n\neda(df_train)\n","878b89c6":"import re\nimport gensim\nfrom gensim import corpora\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import *","f19fe9ed":"words = re.compile(r\"\\w+\",re.I)\nstopword = stopwords.words('english')\nstemmer = PorterStemmer()\n\n# Cleaning and tokenizing the queries.\ndef tokenize_questions(df):\n    question_1_tokenized = []\n    question_2_tokenized = []\n\n    for q in df.question1.tolist():\n        question_1_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) \n                                     if i not in stopword])\n\n    for q in df.question2.tolist():\n        question_2_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) \n                                     if i not in stopword])\n\n    df[\"Question_1_tok\"] = question_1_tokenized\n    df[\"Question_2_tok\"] = question_2_tokenized\n    \n    return df","019ceeff":"df_train = tokenize_questions(df_train)\ndf_test = tokenize_questions(df_test)","862e92e7":"df_train","25f22f65":"df_test","faf84a13":"def train_dictionary(df):\n    \n    questions_tokenized = df.Question_1_tok.tolist() + df.Question_2_tok.tolist()\n    \n    dictionary = corpora.Dictionary(questions_tokenized)\n    dictionary.filter_extremes(no_below=5)\n    dictionary.compactify()\n    \n    return dictionary","40938ac6":"dictionary = train_dictionary(df_train)\nprint (\"No of words in the dictionary = %s\" %len(dictionary.token2id))","50bf87a0":"print(dictionary)","b3126599":"def get_vectors(df, dictionary):\n    \n    question1_vec = [dictionary.doc2bow(text) for text in df.Question_1_tok.tolist()]\n    question2_vec = [dictionary.doc2bow(text) for text in df.Question_2_tok.tolist()]\n    \n    question1_csc = gensim.matutils.corpus2csc(question1_vec, num_terms=len(dictionary.token2id))\n    question2_csc = gensim.matutils.corpus2csc(question2_vec, num_terms=len(dictionary.token2id))\n    \n    return question1_csc.transpose(),question2_csc.transpose()\n\n\nq1_csc, q2_csc = get_vectors(df_train, dictionary)\n\nprint (q1_csc.shape)\nprint (q2_csc.shape)","2121f41d":"q1_csc_test, q2_csc_test = get_vectors(df_test, dictionary)","efc772c2":"'''\nSimilarity Measures:\n    Cosine Similarity\n    Manhattan Distance\n    Euclidean Distance\n'''\n\nfrom sklearn.metrics.pairwise import cosine_similarity as cs\nfrom sklearn.metrics.pairwise import manhattan_distances as md\nfrom sklearn.metrics.pairwise import euclidean_distances as ed\n\n\ndef get_similarity_values(q1_csc, q2_csc):\n    cosine_sim = []\n    manhattan_dis = []\n    eucledian_dis = []\n        \n    for i,j in zip(q1_csc, q2_csc):\n        sim = cs(i,j)\n        cosine_sim.append(sim[0][0])\n        sim = md(i,j)\n        manhattan_dis.append(sim[0][0])\n        sim = ed(i,j)\n        eucledian_dis.append(sim[0][0])\n        \n    return cosine_sim, manhattan_dis, eucledian_dis","1823a11b":"cosine_sim, manhattan_dis, eucledian_dis = get_similarity_values(q1_csc, q2_csc)\ny_pred_cos, y_pred_man, y_pred_euc = get_similarity_values(q1_csc_test, q2_csc_test)\n\nprint (\"cosine_sim sample= \\n\", cosine_sim[0:5])\nprint (\"\\nmanhattan_dis sample = \\n\", manhattan_dis[0:5])\nprint (\"\\neucledian_dis sample = \\n\", eucledian_dis[0:5])","5f2563e8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nxtrain = pd.DataFrame({\"cosine\" : cosine_sim, \"manhattan\" : manhattan_dis,\n                        \"eucledian\" : eucledian_dis})\nytrain = df_train.is_duplicate\n\nxtest = pd.DataFrame({\"cosine\" : y_pred_cos, \"manhattan\" : y_pred_man,\n                       \"eucledian\" : y_pred_euc})\nytest = df_test.is_duplicate\n","68c0f05d":"rf = RandomForestClassifier()\nrf.fit(xtrain, ytrain)\nrf_predicted = rf.predict(xtest)","eaddbbb2":"logist = LogisticRegression(random_state=0)\nlogist.fit(xtrain, ytrain)\nlogist_predicted = logist.predict(xtest)","51e2f3fa":"from sklearn.metrics import log_loss\n\ndef calculate_logloss(y_true, y_pred):\n    loss_cal = log_loss(y_true, y_pred)\n    return loss_cal","31b94ee5":"logloss_rf = calculate_logloss(ytest, rf_predicted)\nlog_loss_logist = calculate_logloss(ytest, logist_predicted)\nprint (\"Log loss value using Random Forest is = %f\" %logloss_rf)\nprint (\"Log loss value using Logistic Regression is = %f\" %log_loss_logist)","2be26905":"from sklearn.metrics import accuracy_score\ntest_acc_rf = accuracy_score(ytest, rf_predicted) * 100\ntest_acc_logist = accuracy_score(ytest, logist_predicted) * 100\nprint (\"Accuracy of Random Forest Model : \", test_acc_rf)\nprint (\"Accuracy of Logistic Regression Model : \", test_acc_logist)","b5329cbf":"### Tokenize","e26cd30c":"## A Liitle bit - **EDA**","3a6c3061":"### Preparing Dictionary","a72e2946":"# **DATA**","6511cfb4":"### ML Model","99517601":"# Result Time","16f0c281":"# **Preparing Bag of Words**","24296afa":"### Preparing vectors and BOW","e97d27a1":"# **Preparing ML Model using Similarity Measures**","f7e50104":"### Similarity Measure"}}