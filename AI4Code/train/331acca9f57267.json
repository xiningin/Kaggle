{"cell_type":{"0c83fed4":"code","2aae2729":"code","b5e830fe":"code","9e6cfab8":"code","84a1d8e6":"code","13b1c4df":"code","ca9e4c13":"code","4aeb8921":"code","f7433d54":"code","35f93f13":"code","9d3a04b1":"code","e34053e5":"code","afdfd563":"code","6c02f029":"code","94f81270":"code","84f8b52c":"code","28207ce7":"code","1cbfb5b3":"markdown","75ba0737":"markdown","5f4172e6":"markdown","c4b0e7f8":"markdown","47e9c80e":"markdown","1b6c8195":"markdown","91b46c1d":"markdown","75a9f07d":"markdown","73fb7cd3":"markdown","137677fd":"markdown","2d85c009":"markdown","2d89b565":"markdown","0a7d5e95":"markdown","118f82d3":"markdown","7a4ed469":"markdown"},"source":{"0c83fed4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sb # Data visualization\nimport matplotlib.pyplot as plt\nimport scipy as stats\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2aae2729":"train = pd.read_csv(\"..\/input\/inputd\/train.csv\")\ntest = pd.read_csv(\"..\/input\/inputd\/eval.csv\")\nsubmission = pd.read_csv(\"..\/input\/inputd\/sample_submission.csv\")","b5e830fe":"train.head()","9e6cfab8":"train = train.drop(['title'], axis = 1)","84a1d8e6":"train.head()","13b1c4df":"train.describe()","ca9e4c13":"def ESRBTOINT(x):\n    if x == 'E': return 0\n    elif x == 'ET': return 1\n    elif x == 'LL': return 2\n    elif x == 'M': return 3\n    elif x == 'T': return 4\n    else: return -1\n    \ntrain['esrb_rating'] = train['esrb_rating'].apply(ESRBTOINT)\ntrain['esrb_rating'].head()","4aeb8921":"train.isnull().sum().sort_values()","f7433d54":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score","35f93f13":"predictors = train.drop(['esrb_rating'], axis = 1)\ntarget = train[\"esrb_rating\"]\nX, X_val, y, y_val = train_test_split(predictors, target, test_size = 0.45, shuffle = True)\n\nx_test = test.copy()\n","9d3a04b1":"from sklearn.linear_model import LinearRegression\n\nmodel1 = LinearRegression()\nmodel1.fit(X,y)\nmodel1Score = (model1.score(X, y) * 100)\nprint('Ordinary Least Squares:',model1Score,'%')","e34053e5":"from sklearn.svm import SVR\n\nmodel2 = SVR()\nmodel2.fit(X,y)\nmodel2Score = (model2.score(X, y) * 100)\nprint('Ordinary Least Squares:',model2Score,'%')","afdfd563":"from sklearn.tree import DecisionTreeClassifier\nmodel3 = DecisionTreeClassifier()\nmodel3.fit(X, y)\nmodel3Score = (model3.score(X, y) * 100)\nprint('Ordinary Least Squares:',model3Score,'%')","6c02f029":"from sklearn.ensemble import RandomForestClassifier\n\nmodel4 = RandomForestClassifier( max_features = \"auto\", min_samples_leaf = 1)\nmodel4.fit(X, y)\nmodel4Score = (model4.score(X, y) * 100)\nprint('Ordinary Least Squares:',model4Score,'%')","94f81270":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel5 = KNeighborsClassifier()\nmodel5.fit(X, y)\nmodel5Score = (model5.score(X, y) * 100)\nprint('Ordinary Least Squares:',model5Score,'%')","84f8b52c":"d = {'Name': ['Linear Regression', 'SVR', 'Decision Tree', 'Random Forest', 'KNeighbors'], 'Validation Score': [model1Score, model2Score, model3Score, model4Score, model5Score]}\n\nValidationDF = pd.DataFrame(data = d)\n\n#ValidationDF.head()\n\nsb.barplot(ValidationDF['Name'], ValidationDF['Validation Score'] )","28207ce7":"Y_pred = model4.predict(x_test)\n\nsubmit = pd.DataFrame({'id': test['id'], 'esrb_rating': Y_pred})\n\n\ndef inToESRB(x):\n    if x == 0: return 'E'\n    elif x == 1: return 'ET'\n    elif x == 2: return 'LL'\n    elif x == 3: return 'M'\n    elif x == 4: return 'T'\n    else: return -1\n    \nsubmit['esrb_rating'] = submit['esrb_rating'].apply(inToESRB)\n\n\nsubmit.to_csv('submission.csv', index = False)\nprint(\"Submission GOOD\")\n\nprint(submit)\n","1cbfb5b3":"# [2 point] You must build and train a Decision Tree model on the training data and evaluate its performance on a set of validation data\nYou must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)","75ba0737":"# [2 point] You must describe any data transformations or feature engineering that are required and provide an explanation as to \"why\" each is being done.","5f4172e6":"Because this contains binary information, there aren't outliers in the data.\n\n-If I wanted a better score I could identify which groups don't have much information and treat those as outliers.","c4b0e7f8":"# [2 point] You must build and train an Support Vector Machine on the training data and evaluate its performance on a set of validation data\nYou must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)","47e9c80e":"# [2 point] You must build and train a K Nearest Neighbors model on the training data and evaluate its performance on a set of validation data\nYou must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)","1b6c8195":"# [2 point] You must load the data from the provided CSV files.\n","91b46c1d":"There is no missing data therefore we don't need to do anything. ","75a9f07d":"Clearly, Decision tree and Random Forest are the best models. However after submitting Random Forest edges out Decision Tree so we are going to use Random Forest for our submission (model 4)","73fb7cd3":"# [2 point] You must check for missing values within the training data and, if required, describe and implement an approach to handle those missing values.","137677fd":"First there is a lot of data here that is useless to us and some that is redudant.\n\nLet's remove that data.","2d85c009":"# [2 point] You must check for outliers within the training data and, if required, describe and implement an approach to handle those outliers.","2d89b565":"The ESRB ratings are currently strings, let's set them to integers based on this chart.\n\n0-E\n\n1-ET\n\n2-LL\n\n3-M\n\n4-T\n","0a7d5e95":"# [2 point] You must build and train a Random Forest model on the training data and evaluate its performance on a set of validation data\nYou must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)","118f82d3":"# [2 point] You must build and train a Logistic Regression model on the training data and evaluate its performance on a set of validation data\nYou must generate a distribution of validation scores, as well as summary statistics for this distribution (using the pandas describe() method)","7a4ed469":"# [2 points] You must select the best model that you have generated and use that model to predict the target vector for the test data.\nYou must save this this target vector to your submission.csv file and print the contents of your submission.csv file within the notebook"}}