{"cell_type":{"9e668d2e":"code","1f8c4bac":"code","988e1bcd":"code","a24dd430":"code","e2162124":"code","fc9549ea":"code","2a04d135":"code","61b2657f":"code","8388e0db":"code","358f66e6":"code","cbd89ea2":"code","c08d69ab":"code","c8c719c7":"code","9d4e1179":"code","d9b5552e":"code","f50d8bf9":"code","ffff9776":"code","398afb3f":"code","54a110fe":"code","866a7046":"code","03068f45":"code","766a4016":"code","2be9b47f":"code","af4190a0":"code","633113b5":"code","1190bcc3":"code","05ad4f49":"code","fe0a3570":"code","6387f237":"code","ec329451":"code","178356a9":"code","cbdeaca9":"code","0023ab06":"code","276efbe7":"code","326d036e":"code","4e431a05":"code","e0d6a525":"code","204e05eb":"code","c7114975":"code","cb0afa8a":"code","8941f65e":"code","6567d554":"code","56fa8320":"code","83bf29fd":"code","6b177b58":"code","3ca1a973":"code","83630408":"code","b5111d36":"code","e248a0cb":"code","e0e66c87":"code","d4560772":"code","c4dfc6f5":"markdown","66580510":"markdown","f2be44dd":"markdown","292e58b2":"markdown","525670e8":"markdown","74bbcc66":"markdown","121f02d1":"markdown","acc8da7e":"markdown","7b439e9a":"markdown","20abb6f8":"markdown","5e8818b6":"markdown","7a59d998":"markdown","afe5c753":"markdown"},"source":{"9e668d2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f8c4bac":"df = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","988e1bcd":"df.head()","a24dd430":"df.info()","e2162124":"def CheckMissingData(sourceDataframe):\n# handling missing values in train data\n    missing_df=pd.DataFrame({\"type\": sourceDataframe.dtypes, \"total\": sourceDataframe.isnull().sum(), \"Percentage\" : sourceDataframe.isnull().sum()\/len(sourceDataframe)})\n    missing_df = missing_df.loc[missing_df.Percentage > 0]\n    return missing_df","fc9549ea":"CheckMissingData(df)","2a04d135":"#removing the columns having missing value more than 90% and unwanted ones\ndf.drop(['Alley','PoolQC','MiscFeature','Id','Fence'], axis=1, inplace = True)","61b2657f":"#for number variables lets create heatmap diaplying the correlation with sales price\nsns.heatmap(df.corr())","8388e0db":"sns.barplot(df['MasVnrType'], df[\"SalePrice\"])","358f66e6":"sns.barplot(df['SaleCondition'], df[\"SalePrice\"])","cbd89ea2":"sns.barplot(df['OverallCond'], df[\"SalePrice\"])","c08d69ab":"sns.scatterplot(df['YearBuilt'],df['SalePrice'])","c8c719c7":"sns.distplot(df[\"SalePrice\"])","9d4e1179":"#imputing missing values - mode for categorical and mean for numbers\n\ndf['MasVnrType'] = df['MasVnrType'].fillna( value = df['MasVnrType'].mode()[0])\ndf['BsmtQual'] = df['BsmtQual'].fillna( value = df['BsmtQual'].mode()[0])\ndf['BsmtCond'] = df['BsmtCond'].fillna( value = df['BsmtCond'].mode()[0])\ndf['BsmtExposure'] = df['BsmtExposure'].fillna( value = df['BsmtExposure'].mode()[0])\ndf['BsmtFinType1'] = df['BsmtFinType1'].fillna( value = df['BsmtFinType1'].mode()[0])\ndf['BsmtFinType2'] = df['BsmtFinType2'].fillna( value = df['BsmtFinType2'].mode()[0])\ndf['Electrical'] = df['Electrical'].fillna( value = df['Electrical'].mode()[0])\ndf['FireplaceQu'] = df['FireplaceQu'].fillna( value = df['FireplaceQu'].mode()[0])\ndf['GarageType'] = df['GarageType'] .fillna( value = df['GarageType'].mode()[0])\ndf['GarageFinish'] = df['GarageFinish'].fillna( value = df['GarageFinish'].mode()[0])\ndf['GarageQual'] = df['GarageQual'].fillna( value = df['GarageQual'].mode()[0])\ndf['GarageCond'] = df['GarageCond'].fillna( value = df['GarageCond'].mode()[0])\n\ndf['LotFrontage'] = df['LotFrontage'].fillna( value = df['LotFrontage'].mean())\ndf['MasVnrArea'] = df['MasVnrArea'].fillna( value = df['MasVnrArea'].mean())\ndf['GarageYrBlt'] = df['GarageYrBlt'].fillna( value = df['GarageYrBlt'].mean())","d9b5552e":"CheckMissingData(df)","f50d8bf9":"CheckMissingData(df_test)","ffff9776":"#removing the columns having missing value more than 90% and unwanted ones\ndf_test.drop(['Alley','PoolQC','MiscFeature','Id','Fence'], axis=1, inplace = True)","398afb3f":"df_test['MSZoning'] = df_test['MSZoning'].fillna( value = df_test['MSZoning'].mode()[0])\ndf_test['Utilities'] = df_test['Utilities'].fillna( value = df_test['Utilities'].mode()[0])\ndf_test['Exterior1st'] = df_test['Exterior1st'].fillna( value = df_test['Exterior1st'].mode()[0])\ndf_test['Exterior2nd'] = df_test['Exterior2nd'].fillna( value = df_test['Exterior2nd'].mode()[0])\ndf_test['MasVnrType'] = df_test['MasVnrType'].fillna( value = df_test['MasVnrType'].mode()[0])\ndf_test['BsmtQual'] = df_test['BsmtQual'].fillna( value = df_test['BsmtQual'].mode()[0])\ndf_test['BsmtCond'] = df_test['BsmtCond'].fillna( value = df_test['BsmtCond'].mode()[0])\ndf_test['BsmtExposure'] = df_test['BsmtExposure'].fillna( value = df_test['BsmtExposure'].mode()[0])\ndf_test['BsmtFinType1'] = df_test['BsmtFinType1'].fillna( value = df_test['BsmtFinType1'].mode()[0])\ndf_test['BsmtFinType2'] = df_test['BsmtFinType2'].fillna( value = df_test['BsmtFinType2'].mode()[0])\ndf_test['KitchenQual'] = df_test['KitchenQual'].fillna( value = df_test['KitchenQual'].mode()[0])\ndf_test['Functional'] = df_test['Functional'].fillna( value = df_test['Functional'].mode()[0])\ndf_test['FireplaceQu'] = df_test['FireplaceQu'].fillna( value = df_test['FireplaceQu'].mode()[0])\ndf_test['GarageType'] = df_test['GarageType'].fillna( value = df_test['GarageType'].mode()[0])\ndf_test['GarageFinish'] = df_test['GarageFinish'].fillna( value = df_test['GarageFinish'].mode()[0])\ndf_test['GarageQual'] = df_test['GarageQual'] .fillna( value = df_test['GarageQual'].mode()[0])\ndf_test['GarageCond'] = df_test['GarageCond'].fillna( value = df_test['GarageCond'].mode()[0])\ndf_test['SaleType'] = df_test['SaleType'].fillna( value = df_test['SaleType'].mode()[0])\n\ndf_test['LotFrontage'] = df_test['LotFrontage'].fillna( value = df_test['LotFrontage'].mean())\ndf_test['MasVnrArea'] = df_test['MasVnrArea'].fillna( value = df_test['MasVnrArea'].mean())\ndf_test['BsmtFinSF1'] = df_test['BsmtFinSF1'].fillna( value = df_test['BsmtFinSF1'].mean())\ndf_test['BsmtFinSF2'] = df_test['BsmtFinSF2'].fillna( value = df_test['BsmtFinSF2'].mean())\ndf_test['TotalBsmtSF'] = df_test['TotalBsmtSF'].fillna( value = df_test['TotalBsmtSF'].mean())\ndf_test['BsmtUnfSF'] = df_test['BsmtUnfSF'].fillna( value = df_test['BsmtUnfSF'].mean())\ndf_test['BsmtFullBath'] = df_test['BsmtFullBath'].fillna( value = df_test['BsmtFullBath'].mean())\ndf_test['BsmtHalfBath'] = df_test['BsmtHalfBath'].fillna( value = df_test['BsmtHalfBath'].mean())\ndf_test['GarageYrBlt'] = df_test['GarageYrBlt'].fillna( value = df_test['GarageYrBlt'].mean())\ndf_test['GarageCars'] = df_test['GarageCars'].fillna( value = df_test['GarageCars'].mean())\ndf_test['GarageArea'] = df_test['GarageArea'].fillna( value = df_test['GarageArea'].mean())","54a110fe":"CheckMissingData(df_test)","866a7046":"# missign value handling is done for train and test \ndata_train = df\ndata_test = df_test","03068f45":"#categories in test data is more than that of train data, so we will concat them both\ndf_final = pd.concat([df, df_test], axis=0)","766a4016":"CATEGORICAL_COLUMNS =[]\nNUMERIC_COLUMNS =[]\n\n\ni = 0\nfor a in df_final.dtypes:\n    if a ==float or a==int:\n        NUMERIC_COLUMNS.append(df_final.columns[i])\n    elif a ==object:\n        CATEGORICAL_COLUMNS.append(df_final.columns[i])\n    i= i+1","2be9b47f":"df_final_dummies = pd.get_dummies(df_final, columns = CATEGORICAL_COLUMNS, drop_first=True)","af4190a0":"df_final_dummies.reset_index(drop=True,inplace=True)","633113b5":"# dropping the duplicates from df\ndf_final_dummies =df_final_dummies.loc[:,~df_final_dummies.columns.duplicated()]","1190bcc3":"df_final_dummies_train = df_final_dummies.loc[df_final_dummies['SalePrice'] >= 0]","05ad4f49":"df_final_dummies_train.shape","fe0a3570":"df_final_dummies_test = df_final_dummies.loc[df_final_dummies['SalePrice'].isnull()]","6387f237":"df_final_dummies_test.shape","ec329451":"from sklearn.model_selection import train_test_split,RandomizedSearchCV\n\nY = np.log(df_final_dummies_train['SalePrice']) #applying log for standardising the target\nX = df_final_dummies_train.drop(['SalePrice'], axis = 1, inplace=False)","178356a9":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.3, random_state = 42)","cbdeaca9":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()","0023ab06":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","276efbe7":"import xgboost as xgb\n\nxgb_r = xgb.XGBRegressor()\nn_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\nbase_score=[0.25,0.5,0.75,1]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }","326d036e":"random_cv = RandomizedSearchCV(estimator=xgb_r,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)","4e431a05":"random_cv.fit(X_train,Y_train)","e0d6a525":"xgb_r = xgb.XGBRegressor(base_score=0.5, booster='gbtree',\n                                          colsample_bylevel=1,\n                                          colsample_bynode=1,\n                                          colsample_bytree=1, gamma=0,\n                                          gpu_id=-1, importance_type='gain',\n                                          interaction_constraints='',\n                                          learning_rate=0.300000012,\n                                          max_delta_step=0, max_depth=6,\n                                          min_child_weight=1, missing=None,\n                                          monotone_constraints='()',\n                                          n_estimators=100)","204e05eb":"xgb_r.fit(X_train,Y_train)","c7114975":"pred = xgb_r.predict(X_test)","cb0afa8a":"from sklearn.metrics import mean_squared_error,accuracy_score,r2_score\nimport math\nprint(mean_squared_error(Y_test, pred))","8941f65e":"sns.scatterplot(pred, Y_test)","6567d554":"r2_score(Y_test, pred,\n...          multioutput='variance_weighted')","56fa8320":"df_final_dummies_test.drop(['SalePrice'], axis =1, inplace=True)","83bf29fd":"X_test_final = scaler.transform(df_final_dummies_test)\npredictionsForTest = np.exp(xgb_r.predict(X_test_final))","6b177b58":"sub_df=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","3ca1a973":"sub_df","83630408":"prediction_df = pd.DataFrame(predictionsForTest)","b5111d36":"dataset_Submit=pd.concat([sub_df['Id'],prediction_df],axis=1)\n","e248a0cb":"dataset_Submit.columns = ['Id','SalePrice']","e0e66c87":"dataset_Submit","d4560772":"dataset_Submit.to_csv('sample_submission.csv',index=False)","c4dfc6f5":"**Normalising the train data**","66580510":"not much impact based on overall condition","f2be44dd":"**Handling Missing values**","292e58b2":"> **Data splitting**","525670e8":"Encoding Categorical features","74bbcc66":"target variable is rightly skewed","121f02d1":"**Hyper parameter Tuning**","acc8da7e":"with years the prices are increasing which is assumed but in 2000 the price has been increased much","7b439e9a":"***Model Building***","20abb6f8":"the sale consition of partial is increasing the sale price","5e8818b6":"prediction score with validation set is not bad with RMSE of 0.019 and r2 score of 0.88","7a59d998":"**Predicting on Test data**","afe5c753":"***Basic EDA***"}}