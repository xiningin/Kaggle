{"cell_type":{"e168dee2":"code","553d9582":"code","c2ae1413":"code","d7599f54":"code","a268e3b2":"code","5c726289":"code","a4c0c1a5":"code","77d7eafc":"code","3edc61cf":"code","2e972db1":"code","d0d09902":"code","89bde0f1":"code","11d1d763":"code","e502000a":"code","263f5127":"code","a059f68a":"code","a1efdd86":"code","1b9f2859":"code","2e4ec0ad":"code","e9d83b93":"code","1dcb0c33":"code","4682fb2f":"code","72a59663":"code","1bb37314":"code","2fd71f37":"code","1b3ddd28":"code","80851d4c":"markdown","459b6ceb":"markdown"},"source":{"e168dee2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","553d9582":"!pip install dash","c2ae1413":"import pandas as pd","d7599f54":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain.head()","a268e3b2":"train.describe()","5c726289":"#find the missing data\ntrain.isnull().sum()","a4c0c1a5":"#find the missing data\ntest.isnull().sum()","77d7eafc":"train.info()","3edc61cf":"import matplotlib.pyplot as plt \nimport seaborn as sns","2e972db1":"#Now we calculate the survival rate by sex\nprint(train.groupby('Sex').mean()['Survived'])\n#set the width and height of the figure \nplt.figure(figsize= (10,6))\n\n#Add title\nplt.title=('Relationship between Sex and Survival Rate')\n\n#Bar chart showing survived rate and sex relationship\nsns.barplot(x='Sex', y='Survived', data=train, palette='Set2')\n# Add label for vertical axis\nplt.ylabel(\"survived rate\")\nplt.show()","d0d09902":"#Now we calculate the survival rate by sex\nprint(train.groupby('Pclass').mean()['Survived'])\n#set the width and height of the figure \nplt.figure(figsize= (10,6))\n\n#Add title\nplt.title=('Relationship between Sex and Survival Rate')\n\n#Bar chart showing survived rate and Pclass relationship\nsns.barplot(x='Pclass', y='Survived', data=train, palette='Set2')\n# Add label for vertical axis\nplt.ylabel(\"survived rate\")\nplt.show()","89bde0f1":"#Now we calculate the survival rate by sex\nprint(train.groupby('SibSp').mean()['Survived'])\n#set the width and height of the figure \nplt.figure(figsize= (10,6))\n\n\n#Bar chart showing survived rate and Pclass relationship\nsns.barplot(x='SibSp', y='Survived', data=train, palette='Set2')\n# Add label for vertical axis\nplt.ylabel(\"survived rate\")\nplt.show()\n","11d1d763":"#I'm thinking that the Age feature is pretty important to survival, so we try to fill NAs. Transform  them to another mean.\ntrain['Age']= train['Age'].fillna(-0.5)\n\n# 0~5:baby\u30015~12:child\u300112~18:teenager\u300118~35:young adult\u300135~65:adult\u300165>:elder \u3001-5:unknown\n\ntrain['Age_group']= train['Age'].apply(lambda x: 'unknown' if x < 0\n                                                else   'baby' if x>=0 and x < 5\n                                                else   'child' if x>=5 and x < 12\n                                                else   'teenager' if x>=12 and x < 18\n                                                else   'young adult' if x>=18 and x < 35 \n                                                else   'adult' if x>=35 and x < 65\n                                                else   'elder'\n                                              )\n#replacing the missing values in the Embarked feature with S \ntrain['Embarked']=train['Embarked'].fillna('S')\ntrain","e502000a":"#I'm thinking that the Age feature is pretty important to survival, so we try to fill NAs. Transform  them to another mean.\ntest['Age']= test['Age'].fillna(-0.5)\n\n# 0~5:baby\u30015~12:child\u300112~18:teenager\u300118~35:young adult\u300135~65:adult\u300165>:elder \u3001-5:unknown\n\ntest['Age_group']= test['Age'].apply(lambda x: 'unknown' if x < 0\n                                                else   'baby' if x>=0 and x < 5\n                                                else   'child' if x>=5 and x < 12\n                                                else   'teenager' if x>=12 and x < 18\n                                                else   'young adult' if x>=18 and x < 35 \n                                                else   'adult' if x>=35 and x < 65\n                                                else   'elder'\n                                              )\ntest","263f5127":"#Now we calculate the survival rate by sex\nprint(train.groupby('Age_group').mean()['Survived'])\n#set the width and height of the figure \nplt.figure(figsize= (10,6))\n\n\n#Bar chart showing survived rate and Pclass relationship\nsns.set(font_scale = 1)\nsns.barplot(x='Age_group', y='Survived', data=train, palette='Set2')\n# Add label for vertical axis\nplt.ylabel(\"survived rate\")\nplt.show()","a059f68a":"#we'll drop the Cabin feature because it is not an useful imformation.\ntrain.drop(['Name','Age','Ticket','Fare','Cabin'],inplace=True,axis=1)\ntest.drop(['Name','Age','Ticket','Fare','Cabin'],inplace=True,axis=1)\n","a1efdd86":"#map each Age value to a numerical value\nage_mapping = {'unknown': 0, 'baby': 1, 'child': 2, 'teenager': 3, 'young adult': 4, 'adult': 5, 'elder': 6}\ntrain['Age_group'] = train['Age_group'].map(age_mapping)\ntest['Age_group'] = test['Age_group'].map(age_mapping)","1b9f2859":"#map each Embarked value to a numerical value\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)\n","2e4ec0ad":"#map each Sex value to a numerical value\nsex_mapping = {\"male\": 0, \"female\": 1}\ntrain['Sex'] = train['Sex'].map(sex_mapping)\ntest['Sex'] = test['Sex'].map(sex_mapping)","e9d83b93":"train.head()","1dcb0c33":"from sklearn.model_selection import train_test_split\nx = train.drop(['PassengerId', 'Survived'], axis=1)\ny = train['Survived']\nx_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.30, random_state=21)","4682fb2f":"#Dicision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\ndecisiontree = DecisionTreeClassifier()\ndecisiontree.fit(x_train, y_train)\ny_pred = decisiontree.predict(x_test)\nacc_decisiontree = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_decisiontree,'%')","72a59663":"#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrfc= RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=10, min_samples_leaf=5)\nrfc.fit(x_train, y_train)\ny_predict= rfc.predict(x_test)\nacc_randomforest = round(rfc.score(x_test,y_test) *100, 2)\nprint(acc_randomforest,'%')","1bb37314":"#Naive Bayes\nfrom sklearn.naive_bayes import MultinomialNB\nmodelm = MultinomialNB()\nmodelm.fit(x_train, y_train)\ny_predict = modelm.predict(x_test)\nacc_Naive_Bayes = round(modelm.score(x_test,y_test) *100, 2)\nprint(acc_Naive_Bayes,'%')","2fd71f37":"#Logistic Regression\nfrom sklearn import linear_model\nmodel=linear_model.LogisticRegression()\nmodel.fit(x_train, y_train)\ny_predict = model.predict(x_test)\nacc_Naive_Bayes = round(model.score(x_test,y_test) *100, 2)\nprint(acc_Naive_Bayes,'%')","1b3ddd28":"decisiontree = DecisionTreeClassifier()\ndecisiontree.fit(x_train, y_train)\ny_pred = decisiontree.predict(x_test)\nacc_decisiontree = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_decisiontree,'%')\nids = test['PassengerId']\npredictions = decisiontree.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)\nprint(\"your submission was succesfull\")","80851d4c":"> Clean data","459b6ceb":"* ***Machine Learnig Choose the best model***"}}