{"cell_type":{"dcfc929b":"code","848758eb":"code","24124d70":"code","d9422a24":"code","4eedffac":"code","7d6c00a3":"code","43c4a9d5":"code","a9da71e7":"code","66013031":"code","b3ca383d":"code","10911a73":"code","f03233c5":"code","9e337a11":"code","f4118f36":"code","7603003b":"code","a49fce7f":"code","f347a221":"code","8ed5048f":"code","646ae6a7":"code","9ba78568":"code","ea0769a7":"code","bec02458":"code","a242b982":"code","b6e1a51a":"code","015c1388":"code","ba125c94":"code","03085027":"code","30c74fd7":"code","b49a6454":"code","9a759a50":"code","82d1b445":"code","591b229a":"code","0a9aad9c":"code","a094395f":"code","96e57197":"code","7fbd47b9":"code","68a8eabb":"code","c0f787e5":"code","7ba7b7f1":"code","f0c048d4":"code","816bd196":"code","8220edfa":"code","e220d62a":"code","91318772":"code","5fed6f5e":"code","b9fe02b5":"code","cbc12e01":"code","69f6a0a7":"code","30fb0c41":"code","6fb804c4":"code","e0f2c9ad":"code","a1e4c499":"code","13c0cf05":"code","fa40b4f2":"code","ccfd32f9":"code","c11ea75d":"code","f2138e53":"code","415efc92":"code","352773d9":"code","249df433":"code","3a984add":"code","99e616b3":"code","0ce4eca3":"code","9dfe1e72":"code","dd17cc24":"code","543aaa14":"code","7d4883ac":"markdown","681f48e6":"markdown","b46ed9f7":"markdown","53e8207b":"markdown","4d84f2ac":"markdown","16fe6a11":"markdown","8d81f2f7":"markdown","6cccf578":"markdown"},"source":{"dcfc929b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","848758eb":"import warnings\nwarnings.filterwarnings(\"ignore\")","24124d70":"df = pd.read_csv('\/kaggle\/input\/insights\/Insights.csv')\ndf.columns","d9422a24":"df.dropna(inplace = True)","4eedffac":"df.isna().sum()","7d6c00a3":"df_Aggregate = df.groupby('Port of Destination').sum()","43c4a9d5":"df_Aggregate = df_Aggregate[df_Aggregate['Qty']>=100]","a9da71e7":"df_Aggregate['Good Dest'] = 0","66013031":"for i in range(len(df_Aggregate)):\n    if df_Aggregate['Qty'].iloc[i]>100:\n        df_Aggregate['Good Dest'].iloc[i] = 1.0 if (df_Aggregate['Value In FC'].iloc[i]\/df_Aggregate['Qty'].iloc[i])>=(3.0) else 0.0","b3ca383d":"df_Aggregate['Good Dest'].value_counts()","10911a73":"df_Aggregate","f03233c5":"X=df_Aggregate.index.tolist()\nX=pd.DataFrame(X,columns=['Ports'])\nX","9e337a11":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","f4118f36":"y=df_Aggregate['Good Dest']","7603003b":"from sklearn.preprocessing import LabelEncoder","a49fce7f":"labelencoder = LabelEncoder()","f347a221":"X['Ports_encoded'] = labelencoder.fit_transform(X['Ports'])\n#X.drop('Bridge_Types_Cat',axis=1)\nlabelencoder.transform(['Hamburg'])\n#39\n\n","8ed5048f":"x=X.Ports_encoded\n#x=pd.DataFrame(x)","646ae6a7":"x=np.array(x)\ny=np.array(y)\nprint(x)\nprint(y)","9ba78568":"x=x.reshape(-1,1)\nprint(x)","ea0769a7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","bec02458":"y_pred = logreg.predict([labelencoder.transform(['Hamburg'])])\nprint(y_pred)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n","a242b982":"df_most_performing = df.groupby('Product').sum()","b6e1a51a":"df_most_performing['Profit'] = df_most_performing['Value(INR)']\/df_most_performing['Qty']","015c1388":"threshold_profit = df_most_performing['Profit'].mean()\nthreshold_profit","ba125c94":"df_most_performing['Profitable_Product'] = 0\nfor i in range(len(df_most_performing)):\n    df_most_performing['Profitable_Product'].iloc[i] = 1 if (df_most_performing['Profit'].iloc[i]>=threshold_profit) else 0","03085027":"df_most_performing","30c74fd7":"df_most_performing['Profitable_Product'].value_counts()","b49a6454":"X=df_most_performing.index.tolist()\nX=pd.DataFrame(X,columns=['Products'])\nX","9a759a50":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","82d1b445":"y=df_most_performing['Profitable_Product']\n","591b229a":"from sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()","0a9aad9c":"X['Products'] = labelencoder.fit_transform(X['Products'])\n#labelencoder.transform(['Hamburg'])","a094395f":"x=X.Products","96e57197":"x=np.array(x)\ny=np.array(y)\nprint(x)\nprint(y)","7fbd47b9":"x=x.reshape(-1,1)\nprint(x)","68a8eabb":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\nlogreg = DecisionTreeClassifier(max_depth=2)\nlogreg.fit(X_train, y_train)","c0f787e5":"y_pred = logreg.predict(X_test)\nprint(y_pred)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n","7ba7b7f1":"top_profitable_products = df_most_performing.sort_values('Profit',ascending=False).index[:10].tolist()\ntop_profitable_products","f0c048d4":"df.head(2)","816bd196":"df_quest3=df[['Qty','Unit Rate In FC']]\ndf_quest3","8220edfa":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\ndf_quest3 = pd.DataFrame(scaler.fit_transform(df_quest3),columns=df_quest3.columns)\ndf_quest3.describe()","e220d62a":"X=df_quest3['Qty']\nX=np.array(X)\nX=X.reshape(-1,1)\ny=df_quest3['Unit Rate In FC']\ny=np.array(y)","91318772":"print(X)\nprint(y)","5fed6f5e":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","b9fe02b5":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\n\nregressor.fit(X_train, y_train)","cbc12e01":"y_pred = regressor.predict(X_test)\nprint(y_pred)","69f6a0a7":"import sklearn.metrics as sm\nprint(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test, y_pred), 2)) \nprint(\"Mean squared error =\", round(sm.mean_squared_error(y_test, y_pred), 2)) \nprint(\"Median absolute error =\", round(sm.median_absolute_error(y_test, y_pred), 2)) \nprint(\"Explain variance score =\", round(sm.explained_variance_score(y_test, y_pred), 2)) \nprint(\"R2 score =\", round(sm.r2_score(y_test, y_pred), 2))","30fb0c41":"import matplotlib.pyplot as plt\nplt.scatter(X_test,y_test)\nplt.xlabel(\"Quantity\")\nplt.ylabel(\"Unit Rate in FC\")\nplt.title(\"Quantity vs Unit Rate in FC\")","6fb804c4":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV","e0f2c9ad":"ridge = Ridge()\nparameters = {'alpha':[1e-15,1e-10,1e-8,1e-4,1e-3,1e-2,1,5,10,20]}\nridge_processor = GridSearchCV(ridge,parameters,scoring = 'neg_mean_absolute_error',cv = 5)\nridge_processor.fit(X,y)","a1e4c499":"print(ridge_processor.best_params_)\nprint(ridge_processor.best_score_)","13c0cf05":"ridge_model = Ridge(alpha = ridge_processor.best_params_['alpha'])\nridge_model.fit(X_train,y_train)","fa40b4f2":"y_pred = ridge_model.predict(X_test)","ccfd32f9":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split","c11ea75d":"print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test, y_pred), 2)) \nprint(\"Mean squared error =\", round(sm.mean_squared_error(y_test, y_pred), 2)) \nprint(\"Median absolute error =\", round(sm.median_absolute_error(y_test, y_pred), 2)) \nprint(\"Explain variance score =\", round(sm.explained_variance_score(y_test, y_pred), 2)) \nprint(\"R2 score =\", round(sm.r2_score(y_test, y_pred), 2))\nprint(\"Cross val score =\",np.mean(cross_val_score(regressor,X_test,y_test,scoring = 'neg_mean_squared_error',cv=5)))","f2138e53":"df","415efc92":"import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans","352773d9":"x1=df[['Country of Destination','Specific Product','Port of Origin','Port of Destination','Shipment Mode']]\nx1","249df433":"from sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\nfor col in x1.columns:\n    x1[col]=labelencoder.fit_transform(x1[[col]])\n    \nx1\n                                        \n","3a984add":"kmean=KMeans(n_clusters=5)\nkmean.fit(x1)","99e616b3":"kmean.cluster_centers_","0ce4eca3":"kmean.labels_","9dfe1e72":"x1.describe()","dd17cc24":"kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)\npred_y = kmeans.fit(x1)\nplt.scatter(x1.iloc[:,0],x1.iloc[:,4])\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\nplt.show()","543aaa14":"wcss = []\nfor i in range(1,20):\n    kmeans = KMeans(n_clusters=i,max_iter=300,n_init=10,random_state=0)\n    kmeans.fit(x1)\n    wcss.append(kmeans.inertia_)\n    #print(\u201cCluster\u201d, i, \u201cInertia\u201d, kmeans.inertia_)\nplt.plot(range(1,20),wcss)\nplt.title('The Elbow Curve')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS') ##WCSS stands for total within-cluster sum of square\nplt.show()","7d4883ac":"## Overlapping","681f48e6":"## 3rd Question","b46ed9f7":"## First Question","53e8207b":"## Threshold for Profit","4d84f2ac":"## Second Question","16fe6a11":"## part2","8d81f2f7":"## quest 4","6cccf578":"## DF Cleaning"}}