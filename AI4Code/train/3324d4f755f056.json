{"cell_type":{"096a93c8":"code","f851e1d1":"code","e43fad9a":"code","9e919365":"code","9823cd5c":"code","8ef97423":"code","20631eb7":"code","107cff6b":"code","9ef0a072":"code","c75a3ade":"code","937a7571":"code","385ec5db":"code","6ff70b3c":"code","b7720253":"code","4441c91a":"code","712a9d66":"code","cbd39113":"code","f51b1db3":"code","aeb19160":"code","dd03727b":"code","ae668755":"code","b687d667":"code","0a8b9fd7":"code","03af2215":"code","bce821b1":"code","f7ca4f3a":"code","a646d4ae":"markdown","1aa86085":"markdown","bae4f37d":"markdown","63a01d28":"markdown","150e2886":"markdown","e45b0e5e":"markdown","d3b81c04":"markdown","2b13eda7":"markdown","f8a027ee":"markdown","b5e49e87":"markdown","37b12b45":"markdown"},"source":{"096a93c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f851e1d1":"# This is not drawn by me but its so impressive that I cant control my fingures to upload it.","e43fad9a":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models       \nimport numpy as np                                # numerical Python\nimport matplotlib.pyplot as plt                   # for visualisation\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","9e919365":"df_train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ndf_test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\n\n# Loading the files from the dataset given on right corner of screen","9823cd5c":"df_train.sample(5)\n\n# lets see the data \n# label is our target class and the images are 784 i.e (28*28 pixels)","8ef97423":"df_train['label'].value_counts()\n# so we have 10 classes with 6000 images","20631eb7":"# Shape \/Dimensions of Dataset\nprint(' Shape of Train Data',df_train.shape,'\\n','Shape of Train Data',df_test.shape)","107cff6b":"train_images=df_train.iloc[0:1,1:]   # taking 1st row except label\nplt.figure()  \nplt.imshow(np.squeeze(train_images.values.reshape(28,28,1)))\n\n# imshow() is used to display data as an image, i.e. on a 2D regular raster.\n# A Raster graphic is a dot matrix data structure that represents a generally rectangular grid of pixels.\n# np.squeeze() function is used when we want to remove single-dimensional entries from the shape of an array.\n","9ef0a072":"# lets have a look on dataset, what eaxctly it is talking about\n\nrows = 10\ncolumns = 10\nfig,ax = plt.subplots(rows,columns,figsize = (16,16))\nax = ax.ravel()\nn_train = len(df_train)\nfor i in range(0,10*10):\n    index = np.random.randint(0, n_train)\n    img = df_train.iloc[index,1:]\n    img = np.array(img)\n    ax[i].imshow(np.squeeze(img.reshape(28,28,1)),cmap=plt.cm.binary)  # converted into grayscale i.e. black and white\n#cmap - parameter used for color \n# imshow() to display the data as image","c75a3ade":"train_data = np.array(df_train, dtype = 'float32')\ntest_data = np.array(df_test, dtype='float32')","937a7571":"X_train = train_data[:,1:]\/255\n\ny_train = train_data[:,0]   # this is our target, thats why we are not dividing it\n\nX_test= test_data[:,1:]\/255\n\ny_test=test_data[:,0]       #this is our target, thats why we are not dividing it","385ec5db":"# test_size means 20 % data will be considered for testing the model\n# random state is just for freezing .i.e we can take any number\nX_train,X_validate,y_train,y_validate = train_test_split(X_train,y_train,test_size = 0.2,random_state = 12345)","6ff70b3c":"batch_size = 2000\nimage_shape = (28,28,1)","b7720253":"X_train = X_train.reshape(X_train.shape[0],*image_shape)\nX_test = X_test.reshape(X_test.shape[0],*image_shape)\nX_validate = X_validate.reshape(X_validate.shape[0],*image_shape)","4441c91a":"# First convolutional layer. \n# Number of filters = 32\n# filter(kernel) size = 3x3\n# Activation function = Relu\n# input data (images) size (height, width, channels) = (28, 28, 1)\n# Channels is 'colors' here. Since fashion MNIST images are grayscale, number of colors = 1, hence, channels = 1\n\n\nconv1 = layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1), padding='same' )\n\n#    padding: one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the\n#    left\/right or up\/down of the input such that output has the same height\/width dimension as the input.","712a9d66":"# Second convolutional layer. \n# Number of filters = 64\n# filter(kernel) size = 3x3\n# Activation function = Relu\n# No separate input data for this layer, input to this layer are the 'weights' of the conv1 layer featureMaps\n# no need to specify explicitly the input to the other convolutional layers (except for the first layer, as above)\n\nconv2 = layers.Conv2D(64, (3,3), activation='relu')","cbd39113":"# Third convolutional layer. \n# Number of filters = 128\n# filter(kernel) size = 3x3\n# Activation function = Relu\n# No separate input data for this layer, input to this layer are the 'weights' of the conv2 layer featureMaps\n# no need to specify explicitly the input to the other convolutional layers (except for the first layer, as above)\n\nconv3 = layers.Conv2D(128, (3,3), activation='relu')","f51b1db3":"# Max Pool Layer \n# Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. \n# Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous\n# feature map.\n\n\n# Since input to CNN is a 2-D image and ouput from last convolutional layer (featuerMap) is also 2-D array \n# (except the third dimension i.e. channels), we will use 2D version of Max Pooling function of TensorFlow Keras\n# to create a Max Pooling Layer, as shown below filter (kernel) size for Pooling Layer = 2x2\n\n#Creating first Max. Pooling Layer\nmax_pool_1 = layers.MaxPooling2D((2,2))\n\n#Creating second Max. Pooling Layer\nmax_pool_2 = layers.MaxPooling2D((2,2))\n\n#Creating third Max. Pooling Layer\nmax_pool_3 = layers.MaxPooling2D((2,2))","aeb19160":"# Fully Connected (FC) Layer i.e. hidden layer expects input in 1-D format (1-D array), hence, we need to convert\n# 2-D output (2-D array) of last convolutional layer (conv3) to 1-D array i.e. we need to flatten the 2-D array\n# to 1-D array\n\nflat_layer = layers.Flatten()","dd03727b":"# Fully Connected (FC) Layer - Hidden(Dense) Layer\n# Normally, the number of neurons that we keep in FC layer should be equal to the number of neurons in just\n# immediate previous convolutional layer\n\nfc = layers.Dense(128, activation='relu')","ae668755":"# Output Layer - with 10 neurons (as we have 10 output classes) and using 'softmax' function\n\noutput = layers.Dense(10, 'softmax')","b687d667":"# TensorFlow Keras uses Keras Sequential API\n\nmodel = models.Sequential()\n\nmodel.add(conv1)\nmodel.add(conv2)\nmodel.add(conv3)\nmodel.add(max_pool_1)\nmodel.add(flat_layer)\nmodel.add(fc)\nmodel.add(output)","0a8b9fd7":"# Let us see what all layers our model has\n\nmodel.summary()\n","03af2215":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","bce821b1":"# we are using the normalized input data\n\n# Let us perform 20 epochs with batch_size as 512, and with shuffling = true \n\n# shuffle=true will shuffle the indexes of the instances in order to allocate different sets of instances \n# in validation dataset each time cross-validation runs\n\n# validation split=0.1 means a validation dataset of size of 10% is created from the training dataset for cross validation = 50\n\nmodel.fit(X_train, y_train, epochs=15, batch_size=50, shuffle=True, validation_split=0.1) ","f7ca4f3a":"score = model.evaluate(X_test, y_test)\n# checking the test loss and test accuracy\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","a646d4ae":"Fashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.","1aa86085":"Each row is a separate image\nColumn 1 is the class label.\nRemaining columns are **pixel numbers (784 total).**\nEach value is the darkness of the **pixel (1 to 255)**","bae4f37d":"# **Importing Libraries**","63a01d28":"Let us create a Fully Connected Layer (Hidden Layer) and an Output Layer to perform Classification","150e2886":"Training and Validation Datasets\nWhile building real world machine learning models, it is quite common to split the dataset into 3 parts:\n\nTraining set - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\nValidation set - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\nTest set - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.\nSince there's no predefined validation set, we can set aside a small portion (20%) of the training set to be used as the validation set.","e45b0e5e":"![image.png](attachment:image.png)","d3b81c04":"The pixel values for the images lie between 0 to 255 now, which is a large range. \n\nLet us normalize these values to a range from 0 to 1. To do this, we can simply divide each pixel value with 255","2b13eda7":"Let us now specify the optimizer(adam), loss function(crossentropy) and metrics(accuracy) for this model\n\nNOTE: Use sparse categorical crossentropy when your classes are mutually exclusive (e.g. when each sample belongs exactly to one class) and categorical crossentropy when one sample can have multiple classes or labels are soft probabilities (like [0.5, 0.3, 0.2]).","f8a027ee":"Each training and test example is assigned to one of the following labels:\n\n0 T-shirt\/top\n\n1 Trouser\n\n2 Pullover\n\n3 Dress\n\n4 Coat\n\n5 Sandal\n\n6 Shirt\n\n7 Sneaker\n\n8 Bag\n\n9 Ankle boot","b5e49e87":"Now let us train the model and also perform the cross validation and hyperparameter tuning. Passing validation_split parameter to fit() method ensures that cross validation and hyperparameter tuning also happens during the training.","37b12b45":"Let us now create the model (CNN model) structure using the above defined layers"}}