{"cell_type":{"ccc309a7":"code","44b83c26":"markdown","ab832870":"markdown","5febd36b":"markdown"},"source":{"ccc309a7":"def calculate_metrics(self, outputs, targets, **kwargs):\n    outputs = (outputs>0).float()\n    targets = targets.view(-1,128,128)\n    # This is different from the Dice logic\n    # calculating intersection and union for a batch\n    intersect = (outputs*targets).sum(2).sum(1)\n    union = (outputs+targets).sum(2).sum(1)\n    # Calculates the IOU, 0.001 makes sure the iou is 1 in case intersect\n    # and union are both zero (where mask is zero and predicted mask is zero) -\n    # this is a case of perfect match as well.\n    iou = (intersect+0.001)\/(union-intersect+0.001)\n    # This simple logic here will give the correct result for precision\n    # without going thru each threshold\n    classification_precision = ((iou-0.451)*2*10).floor()\/10\n    # makes any ious less than 0.451 zero as well\n    classification_precision[classification_precision<0] = 0\n    # If you don't want the mean for the batch, you can return a list\n    # of the classification_precision as well.  \n    classification_precision = classification_precision.mean()\n    return classification_precision","44b83c26":"A few examples:\nfor IOU of 0.6464, you should get an average precision value of 0.3 (as shown in the https:\/\/www.kaggle.com\/pestipeti\/explanation-of-scoring-metric)\n\n(0.6464-0.451)x2x10 = 3.908,  floor(3.908) = 3,  3\/10 = 0.3 - average precision value\n\nIOU of 0.5:\n(0.5-0.451)x2x10 = 0.98,  floor(0.98) = 0,  0\/10 = 0 - average precision value\n\nIOU of 0.51:\n(0.51-0.451)x2x10 = 1.18,  floor(1.18) = 1,  1\/10 = 0.1 - average precision value\n\nIOU of 0.94:\n(0.94-0.451)x2x10 = 9.78,  floor(9.78) = 9,  9\/10 = 0.9 - average precision value\n\nIOU of 0.98:\n(0.98-0.451)x2x10 = 10.58,  floor(10.58) = 10,  10\/10 = 1.0 - average precision value\n","ab832870":"Let me know if you find any error in my logic by posting comments.  Do upvote if you find it useful.","5febd36b":"Showing here a way to calculate the competition metric in a straightforward manner without going thru separate threshold calculation code.  I have used this metric code in my DL model and every submission result has come very close to what I came up for my validation data using this code.  This metric code is based on my understanding of the metric from the discussion here:\n\nhttps:\/\/www.kaggle.com\/c\/tgs-salt-identification-challenge\/discussion\/62717\n\nand the notebook here:\n\nhttps:\/\/www.kaggle.com\/pestipeti\/explanation-of-scoring-metric\n\nNote: The script assumes that your ground truth and predicted masks have values 0 to 1. Not 0 to 255."}}