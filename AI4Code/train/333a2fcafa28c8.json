{"cell_type":{"f5a29f2c":"code","89548a42":"code","81f26085":"code","d382a518":"code","5ec06d1a":"code","abe61f6c":"code","9a7a8eb7":"code","e7d07520":"code","aaf751d4":"code","9f75f136":"code","365dde5c":"code","223ea6cb":"code","8544ddba":"code","b233b5b2":"code","6fad070f":"code","00323640":"code","e565e361":"code","3d7c2d34":"code","2b2c8405":"code","2bf499a0":"code","f184d123":"code","236cbb45":"code","62cc3c63":"code","a1074177":"code","546ae611":"code","0c6bb4b8":"code","a5d7bcdd":"code","7d12c9fc":"code","5bb8b28a":"code","33056c38":"code","80a967e7":"code","a81644ed":"code","b9bb436b":"code","6b25cebe":"code","e0b1e35d":"code","05b601c1":"code","4693707b":"code","b7952ffa":"code","ffdd8b37":"code","bbca1509":"markdown","3ea021d5":"markdown","eb978cd6":"markdown","c97162a5":"markdown","84cdc27d":"markdown","cf71c77e":"markdown","499a3e7b":"markdown","f7e7661e":"markdown","2ba8bbaa":"markdown","8411f5e4":"markdown","924363b0":"markdown","d0fe9062":"markdown","bb5705e0":"markdown","822e7951":"markdown","08d3047c":"markdown","cdc32fa5":"markdown","f96e6160":"markdown","c163a18e":"markdown","b1e6ff9e":"markdown","a743b761":"markdown","010e6d4a":"markdown","d6a50ee6":"markdown","2c680290":"markdown","40dbacfb":"markdown","156e7929":"markdown","13c1683f":"markdown","7ba206d9":"markdown","62e87bb5":"markdown","660dfc23":"markdown","274ae8ca":"markdown","19a52ca7":"markdown","5c375849":"markdown"},"source":{"f5a29f2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89548a42":"#general music data from various genres, gathered from official spotify playlists available in my region\nblues_df = pd.read_csv(\"..\/input\/spotify-multigenre-playlists-data\/blues_music_data.csv\")\nrock_df = pd.read_csv(\"..\/input\/spotify-multigenre-playlists-data\/rock_music_data.csv\")\nmetal_df = pd.read_csv(\"..\/input\/spotify-multigenre-playlists-data\/metal_music_data.csv\")\npop_df = pd.read_csv(\"..\/input\/spotify-multigenre-playlists-data\/pop_music_data.csv\")\nindie_df = pd.read_csv(\"..\/input\/spotify-multigenre-playlists-data\/indie_alt_music_data.csv\")\nalt_df = pd.read_csv(\"..\/input\/spotify-multigenre-playlists-data\/alternative_music_data.csv\")\nhiphop_df = pd.read_csv(\"..\/input\/spotify-multigenre-playlists-data\/hiphop_music_data.csv\")\n\n#personal data gathered from my music library\nmy_df = pd.read_csv(\"..\/input\/my-spotify-music-library\/train_music_data.csv\").drop('type',axis=1)","81f26085":"#useful imports\nfrom matplotlib import pyplot as plt\nimport seaborn as sns; sns.set()","d382a518":"pd.DataFrame(pd.DataFrame(my_df.groupby(my_df['Artist Name']).filter(lambda x: len(x)>10)).groupby(\"Artist Name\").energy.mean()).sort_values(by='energy',ascending=False)[:20]\n#There must be a better way of finding the top 20 loudest\/most energetic bands in my library... too bad I didn't find it though so enjoy this monstrosity\n#(Do note I didn't include any artist with less than 10 songs (1 LP-worth of songs) saved, due to the possible high variance (and low sample size) between audio features). ","5ec06d1a":"plt.rcParams[\"figure.figsize\"] = (12,10)","abe61f6c":"average_noise = pop_df['energy'].mean()\naverage_danceability = pop_df['danceability'].mean()\nplt.scatter(my_df['danceability'],my_df['energy'],alpha=0.75)\nplt.axhline(y=average_noise, color='r')\nplt.axvline(x=average_danceability, color='r')\nplt.title(\"Energy as a function of Danceability - from my music library\")\nplt.xlabel(\"Danceability\")\nplt.ylabel(\"Energy\")\nplt.show()","9a7a8eb7":"'''#reset default fig size\nplt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']'''","e7d07520":"my_df.columns","aaf751d4":"pop_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nrock_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nalt_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nindie_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nhiphop_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nmetal_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nmy_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nplt.legend([\"pop\",\"rock\",\"alternative\",\"indie\",\"hiphop\",\"metal\",\"my library\"])\nplt.title(\"Different genres across different audio features\")\n","9f75f136":"metal_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nmy_df[['danceability','energy','loudness','speechiness','acousticness','valence']].mean().plot(legend=True)\nplt.legend([\"metal\",\"my library\"])\nplt.title(\"Different genres across different audio features\")","365dde5c":"plt.figure(figsize = (16, 6))\nfull_dataset = pd.concat([blues_df,pd.concat([rock_df,pd.concat([metal_df,pd.concat([indie_df,pd.concat([alt_df,pd.concat([pop_df,pd.concat([hiphop_df,my_df])])])])])])]).drop_duplicates()\nsns.heatmap(full_dataset[['Popularity','danceability',\n       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n       'instrumentalness', 'liveness', 'valence', 'tempo']].corr(),annot=True)","223ea6cb":"def del_common_rows(df1,df2,decider):\n    \"\"\"\n    :returns a DataFrame that is identical to df1 without any rows it has in common with df2\n    \"\"\"\n    intersection = pd.merge(df2, df1, how ='inner')\n    intersection_list_dec = intersection[decider].tolist()\n    df = df1.loc[~df1[decider].isin(intersection_list_dec)]\n    return df","8544ddba":"pop_dis_df = del_common_rows(pop_df,my_df,\"Track Name\")  # Deleting any pop\/hiphop tracks I like from the supposed \"dislike pile\" \nhiphop_dis_df = del_common_rows(hiphop_df,my_df,\"Track Name\")\ndislikes = pd.concat([pop_dis_df,hiphop_dis_df])\nlikes = pd.concat([blues_df,pd.concat([rock_df,pd.concat([metal_df,pd.concat([indie_df,alt_df])])])])\nlikes = del_common_rows(likes,my_df,\"Track Name\")\nlikes['like'] = 1\nmy_df['like'] = 1\ndislikes['like'] = 0","b233b5b2":"likes = likes.drop('Playlist',axis=1)\ndislikes = dislikes.drop('Playlist',axis=1) # Won't use the playlist feature with this approach","6fad070f":"from sklearn.model_selection import train_test_split\ndislikes_train,dislikes_test = train_test_split(dislikes)","00323640":"train = pd.concat([my_df,dislikes_train]).drop_duplicates()","e565e361":"\ntest = pd.concat([likes,dislikes_test]).drop_duplicates()\ntrue_labels = test['like']\ntest = test.drop('like',axis=1)","3d7c2d34":"#Importing some ML packages\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate,GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n#Tried using keras NN, but the results were not impressive enough overall","2b2c8405":"to_drop=['Artist Name','Track Name','Genres','key','mode','id','uri','track_href','analysis_url','duration_ms','time_signature']\ny = train['like']\nX = train.drop(to_drop,axis=1).copy()\nX= X.drop(['like'],axis=1)\nX_test = test.drop(to_drop,axis=1).copy()","2bf499a0":"#using grid CV to determine best randomforest parameters\n'''param_grid = {\n    'criterion': ['gini','entropy'],\n    'max_depth': [1,2,3,4,10,15],\n     'min_samples_leaf': [3, 5,10,20,30],\n     'min_samples_split': [4, 8, 10, 12],\n     'n_estimators': [3,5,10,15]\n}\n\nrf = RandomForestClassifier(random_state=1)\n\ngrid_search_forest = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 5, n_jobs = -1, verbose = 2)\n\ngrid_search_forest.fit(X,y)\ngrid_search_forest.best_params_'''","f184d123":"# Applying same logic for gboost hyperparameters.\n'''param_grid = {\n    'loss': ['deviance','exponential'],\n    'learning_rate': [0.05,0.1,0.15,0.175,0.2],\n     'min_samples_leaf': [3, 5,10,20,30],\n     'min_samples_split': [4, 8, 10, 12],\n     'n_estimators': [10,50,100]\n}\n\ngb = GradientBoostingClassifier(random_state=1)\n\ngrid_search_gboost = GridSearchCV(estimator = gb, param_grid = param_grid, \n                          cv = 5, n_jobs = -1, verbose = 2)\ngrid_search_gboost.fit(X,y)\ngrid_search_gboost.best_params_'''","236cbb45":"log_model = LogisticRegression(max_iter=10000)\n\n#Parameters found using Grid-CV\n\nforest_model = RandomForestClassifier(criterion = 'entropy',\n max_depth =  15,\n min_samples_leaf =  3,\n min_samples_split =  12,\n n_estimators = 15,random_state=1)\n\ngboost_model = GradientBoostingClassifier(learning_rate= 0.1,\n loss= 'deviance',\n min_samples_leaf= 30,\n min_samples_split= 4,\n n_estimators= 100,\n random_state=1)\n","62cc3c63":"cv_Err_forest = cross_validate(forest_model,X,y,cv=10)\nprint(\"Average Cross Validation score on the training set with Random Forests is \" +str(cv_Err_forest[\"test_score\"].mean()))","a1074177":"cv_Err_gboost = cross_validate(gboost_model,X,y,cv=10)\nprint(\"Average Cross Validation score on the training set with Gradient Boosting is \" +str(cv_Err_gboost[\"test_score\"].mean()))","546ae611":"cv_Err_log = cross_validate(log_model,X,y,cv=10)\nprint(\"Average Cross Validation score on the training set with Logistic Regression is \" +str(cv_Err_log[\"test_score\"].mean()))","0c6bb4b8":"log_model.fit(X,y)\nforest_model.fit(X,y)\ngboost_model.fit(X,y)","a5d7bcdd":"predictions_forest = forest_model.predict_proba(X_test)\npredictions_gboost = gboost_model.predict_proba(X_test)\npredictions_log = log_model.predict_proba(X_test)","7d12c9fc":"def get_top_k_results(predictions,model,k):\n    prob_df = pd.DataFrame(predictions, columns=model.classes_)\n    indices = np.argsort(prob_df.values[:,1],)\n    indices= np.flip(indices)\n    top_k_df = pd.DataFrame([test.iloc[indx] for indx in indices[:k]])\n    return top_k_df\n","5bb8b28a":"log_top_k = get_top_k_results(predictions_log,log_model,15)\nforest_top_k = get_top_k_results(predictions_forest,forest_model,15)\ngboost_top_k = get_top_k_results(predictions_gboost,gboost_model,15)","33056c38":"log_top_k ","80a967e7":"forest_top_k","a81644ed":"gboost_top_k","b9bb436b":"pop_dis_df = del_common_rows(pop_df,my_df,\"Track Name\")  # Deleting any pop\/hiphop tracks I like from the supposed \"dislike pile\" \nhiphop_dis_df = del_common_rows(hiphop_df,my_df,\"Track Name\")\ndislikes = pd.concat([pop_dis_df,pd.concat([metal_df,hiphop_dis_df])])\nlikes = pd.concat([blues_df,pd.concat([rock_df,pd.concat([indie_df,alt_df])])])\nlikes = del_common_rows(likes,my_df,\"Track Name\")\nlikes['like'] = 1\nmy_df['like'] = 1\ndislikes['like'] = 0\nlikes = likes.drop('Playlist',axis=1)\ndislikes = dislikes.drop('Playlist',axis=1)\ntrain = pd.concat([my_df,dislikes_train]).drop_duplicates()\ntest = pd.concat([likes,dislikes_test]).drop_duplicates()\ntrue_labels = test['like']\ntest = test.drop('like',axis=1)\nto_drop=['Artist Name','Track Name','Genres','key','mode','id','uri','track_href','analysis_url','duration_ms','time_signature']\ny = train['like']\nX = train.drop(to_drop,axis=1).copy()\nX= X.drop(['like'],axis=1)\nX_test = test.drop(to_drop,axis=1).copy()\n                      \nlog_model = LogisticRegression(max_iter=10000)\n\n#Parameters found using Grid-CV\n\nforest_model = RandomForestClassifier(criterion = 'entropy',\n max_depth =  15,\n min_samples_leaf =  3,\n min_samples_split =  12,\n n_estimators = 15,random_state=1)\n\ngboost_model = GradientBoostingClassifier(learning_rate= 0.1,\n loss= 'deviance',\n min_samples_leaf= 30,\n min_samples_split= 4,\n n_estimators= 100,\n random_state=1)\n\nlog_model.fit(X,y)\nforest_model.fit(X,y)\ngboost_model.fit(X,y)\n\npredictions_forest = forest_model.predict_proba(X_test)\npredictions_gboost = gboost_model.predict_proba(X_test)\npredictions_log = log_model.predict_proba(X_test)\n\nlog_top_k = get_top_k_results(predictions_log,log_model,15)\nforest_top_k = get_top_k_results(predictions_forest,forest_model,15)\ngboost_top_k = get_top_k_results(predictions_gboost,gboost_model,15)","6b25cebe":"log_top_k","e0b1e35d":"forest_top_k","05b601c1":"gboost_top_k","4693707b":"#Saving the final recommendations:\nlog_top_k.to_csv(\"log_recommendations_v1.csv\",index =False)\nforest_top_k.to_csv(\"forest_recommendations_v1.csv\",index =False)\ngboost_top_k.to_csv(\"gboost_recommendations_v1.csv\",index =False)","b7952ffa":"'''def create_music_dataset(playlists, sp,k):\n    \"\"\"\n    Helper function\n    :param playlists- playlists to draw tracks from\n    :param sp - spotipy object to manage stuff\n    :k - constant to determine how many songs I want to scrape from each playlist.\n    100 songs per k\n    :returns a song list along with their audio features\n    \"\"\"\n    track_art_names = []\n    while playlists:\n        for i, playlist in enumerate(playlists['items']):\n            print(\"%4d %s\" % (i + 1 + playlists['offset'], playlist['name']))\n            for j in range(k):\n                playlist_tracks = sp.playlist_items(playlist['id'], offset=j * 100)\n                items = playlist_tracks['items']\n                for item in items:\n                    track = item['track']\n                    try:\n                        artist_name = track['artists'][0]['name']\n                        artist_id = track['artists'][0]['id']\n                        track_name = track['name']\n                        orig_playlist = playlist['name']\n                        track_art_names.append((artist_name, track_name, artist_id,orig_playlist))\n                    except:\n                        print(\"Playlist Error\")\n                        continue\n        if playlists['next']:\n            playlists = sp.next(playlists)['playlists']\n        else:\n            playlists = None\n\n    ids = []\n    song_list = []\n    cols = []\n    unique_tracks = list(set(track_art_names))\n    for j, data_tup in enumerate(unique_tracks):\n        try:  # Avoid stoppin\n            track_feats = sp.search(q='artist:' + data_tup[0] + ' track:' + data_tup[1], type='track')\n            track_id = track_feats['tracks']['items'][0]['id']\n            track_pop = sp.track(track_id)['popularity']\n            artist = sp.artist(data_tup[2])\n            features = sp.audio_features(track_id)\n            del features[0]['type']\n        except:  # The track_feats search query returns an empty statement sometimes\n            print(\"err\")\n            continue\n        ids.append(track_id)\n        artist_genre = artist['genres']\n        if not cols:  # First iteration\n            cols = ['Artist Name', 'Track Name', 'Popularity', 'Genres','Playlist']\n            cols.extend(features[0].keys())\n        song_row = [data_tup[0], data_tup[1], track_pop, artist_genre,data_tup[3]]\n        try:  # somehow, some songs have no features\n            song_row.extend(features[0].values())\n        except:\n            continue\n        print(\"Artist = \", data_tup[0], \" Song = \", data_tup[1], \" Id = \", track_id, \" Iter = \", j)\n        song_list.append(song_row)\n\n    return song_list, cols'''","ffdd8b37":"'''import spotipy\nfrom spotipy.oauth2 import SpotifyOAuth\nimport pandas as pd\n\ndef main():\n    SPOTIPY_CLIENT_ID = '<YOUR CLIENT ID HERE>'\n    SPOTIPY_CLIENT_SECRET = '<YOUR CLIENT SECRET HERE>'\n    SPOTIPY_REDIRECT_URI = '<YOUR REDIRECT ID HERE>'\n    SCOPE = \"user-library-read\"\n\n    sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=SCOPE, client_id=SPOTIPY_CLIENT_ID,\n                                                   client_secret=SPOTIPY_CLIENT_SECRET,\n                                                   redirect_uri=SPOTIPY_REDIRECT_URI))\n    playlists = sp.current_user_playlists()\n    song_list, cols = create_music_dataset(playlists, sp,2)\n    df = pd.DataFrame(song_list, columns=cols)\n    df.to_csv(\"train_music_data.csv\", header=cols)'''","bbca1509":"### ","3ea021d5":"We can see from this visualization that I usually favor tracks with very high energy and pretty low danceability (compared to your average \"popular song\"). \nWe can use this insight later on to draw some conclusions about my general music taste...","eb978cd6":"Now, lets visualize my libraries' tendencies using some audio features - specifically the \"energy\" and \"danceability\" features, to create a neat 2-D scatter plot. The red cross represents the \"average popular song\"'s audio features, as a frame of reference:","c97162a5":"To make things simpler the first time around, and considering my general taste revolves around rock music, I automatically marked that I love all \"rocky\" music (tracks from rock\/blues\/metal\/alt\/indie and automatically disliked every pop\/hiphop track thats in my dataset.","84cdc27d":"While discerning minute differences between the genres might be difficult, what we CAN clearly see is that songs from my library tend to be much louder than its' peers, while also topping the energy ranks and coming in last at danceability. Furthermore, we can clearly see my songs' features are very **very** similar to the metal genre - and that very much surprised me, as I barely listen to any metal at all.\n\nSome other cute stuff I've noticed:\n - the hiphop genre leads the pack in terms of speechiness, which makes sense overall.\n - metal (and rock, to some extent) tend to have lower danceability and acousticness- not surprising considering the abundance of electric guitars and that sweet distortion.\n- indie seems to be the 'chillest' genre overall, with the lowest loudness score and with low energy score, as well.","cf71c77e":"# **Introduction**","499a3e7b":"(Seems like Gboost gives us the best result so far, however the differences between the models are relatively small, so I decided to use the 3 of them and check which model gives the best predictions overall).","f7e7661e":"The base script - **for scraping data from your library** ","2ba8bbaa":"Now that we got our results, let us see how did the models do:","8411f5e4":"The two clearest dependencies are valence-danceability and loudness-energy, the former makes sense to me since happy songs are more fun to dance to, and the latter further supports the phenomena we witnessed when comparing the cross-genre audio features- and noticed that the loudest genres (and my library) tend to be more energetic as well.\n\nSimiliary, we detect a clear anti-correlation between acousticness and both energy and loudness.","924363b0":"Now let's try to check for some audio features dependencies using a heatmap correlation matrix: ","d0fe9062":"...And now we can see differences more cleary, including the changes in energy,danceability,acousticness and valence (\"Hapiness measure\") across the two groups. \n\nHowever, it is a bit forboding how my musical taste is feature-similar to a genre I generally do not like all that much...","bb5705e0":"# **Appendix- code to get your own music data, playlist-wise**","822e7951":"Lets remove the \"noise\" and focus solely on my library and the metal library: ","08d3047c":"**Take 2 - dropping the metal dataframe from the 'liked' group**","cdc32fa5":"Well, if you know any of these bands, you are probably not surprised, as all of these artists usually play pretty [energetic](https:\/\/www.youtube.com\/watch?v=tuK6n2Lkza0&ab_channel=Jet) stuff.","f96e6160":"# Importing the dataset(s)","c163a18e":"# **Approach 1 - Binary Classification**\nAssuming I have my own library AND a list of songs I don't like, I can use regular ML\/NN algorithms to try and predict which songs from the remainder of Spotify's featured tracks I may like the most:","b1e6ff9e":"One of the very first stuff that I wanted to do with my data was to try and check which bands that I like were the loudest\/hypest\/most energetic, because that's my most listened to \"genre\" of music.","a743b761":"Helper function:","010e6d4a":"So, I started this little project with a pretty obvious goal - design a track recommender system, using my music library as a train set.\nBeing a data science student the first thing that came to mind was to build a binary classifcation model - using a train set filled with songs I like **and** dislike. While this approach may require more data than other, more realistic\/feasible approaches (that may operate more smoothly without a list of disliked songs), its also relatively simple and intiutive to anyone who tried basic ML before. Will update this notebook when I have the time to try out some other approaches I had in mind.","d6a50ee6":"Far less metal thats for sure!","2c680290":"Hello there, this is a (semi)-quick look of how one can use [this Spotify audio features dataset I created](https:\/\/www.kaggle.com\/siropo\/spotify-multigenre-playlists-data) to train a basic recommender system for your own music library! \nWhile I won't provide access to my private music library (for now...), I'll be leaving the code I used to scrape my personal music data (and the global playlist data) in the appendix section at the end of this notebook, so be sure to give it a look if you'd like to try this with your own track list!","40dbacfb":"So, this model is pretty basic overall, since it relied solely on numeric variables and didn't include any feature engineering beforehand, thus we can probably improve it by doing stuff like:\n- Encoding the 'Genres' feature to a group of binary variables, to help our model diffrentiate genres\n- Introducing a \"score\" metric to boost tracks that come from the same Spotify playlist as one of your liked songs from the train set\n- Using more complex models, such as neural networks using keras and TF.\n\nHowever, this seems like a good starting point.\nDo check if you can improve your own recommendations with more complex models though.\n\nThats it for me,thanks for sticking around! would love to answer any questions that pop up (and accept any criticisms)!","156e7929":"Well, seems like the audio features' similarity between my library and the metal track list proved itself, because apparently I'm a metalhead now, with most of the top-15 recommended songs being from the metal genre. While there are some offerings from other genres such as alt,blues and funk rock most of it is the usual deathcore stuff I apparently enjoy so much...","13c1683f":"# **Summing up, and closing thoughts (for now)**","7ba206d9":"Before we dive in to the code, heres a couple of things you should know:\n- This code is written in python, which uses the spotipy library to access Spotify's data through an **App** that uses your own Spotify user credentials. \n- Here's a [good tutorial](https:\/\/towardsdatascience.com\/get-your-spotify-streaming-history-with-python-d5a208bbcbd3#:~:text=Getting%20the%20data,but%20it's%20usually%20much%20faster) to get you started with creating your app at the Spotify developers website. Didn't follow all of it, since some of the spotipy code is deprecated, but this guide was great at helping me set up my Spotify developers account and app.\n- Once you have an app running, you should plug you client secret and user to this code and be good to go! Be sure to check [Spotipy's documentation](https:\/\/spotipy.readthedocs.io\/en\/2.18.0\/) if there's something unclear.\n- This code accesses your music library **Playlist wise**, so be sure any song you want to actually access is in one of your playlists.\n- Would recommend running this with a debugger if confused, as the Json structure of this is quite trippy, but your mileage may vary.","62e87bb5":"# **Some insights** - Data Analysis","660dfc23":"Lesson learned - Quickly running the same exact code as take 1, but putting the entirety of the metal database in the dislike pile this time- not only I do not like metal all that much, its' similiarities to what I **do** like seemed to confuse the models a whole lot. \nLets see how well do we fare now","274ae8ca":"# **Building some models**","19a52ca7":"Next, I'm gonna take my data and compare the \"average song\" from my library to those from different genres:","5c375849":"# Evaluating results"}}