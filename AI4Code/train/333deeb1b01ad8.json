{"cell_type":{"65ee3744":"code","eaee37fc":"code","8465c2ab":"code","214c82ba":"code","11eecf0b":"code","4f2c8593":"code","fe19c5f8":"code","ce754990":"code","f707cfa0":"code","76ddc3f4":"code","e767ebd2":"code","aa11aafd":"code","f6edd0cc":"code","a08d362a":"code","afa45001":"code","2db5f611":"code","47d142d1":"code","40eae906":"code","414f643d":"code","87eabdd3":"code","f68d3fa6":"code","f59c7fc6":"markdown","84f41f3a":"markdown","9d296d1a":"markdown","c5ca84a8":"markdown","da183d06":"markdown","b9443fe1":"markdown","70697fe2":"markdown","11b3cb84":"markdown","bafd8c67":"markdown","ffec7501":"markdown","03bdd0ce":"markdown","dc5b74a3":"markdown","46570f70":"markdown","cecd35e6":"markdown","582848a8":"markdown","009feb87":"markdown","89b71acd":"markdown","98495f25":"markdown"},"source":{"65ee3744":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.preprocessing import LabelEncoder\nfrom wordcloud import WordCloud\nimport tensorflow\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer","eaee37fc":"imdb_df = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\nimdb_df.head()","8465c2ab":"imdb_df.describe()","214c82ba":"sns.set(style = \"darkgrid\" , font_scale = 1.2)\nsns.countplot(x='sentiment',data=imdb_df)\nplt.show()","11eecf0b":"imdb_df.isna().sum()   #checking for missing values","4f2c8593":"def strip_html(text):\n    soup = BeautifulSoup(text,\"html.parser\")\n    return soup.get_text()\n\n#function to remove punctuations\ndef remove_punctuations(text):\n    punctuations = re.compile(r'[^\\w\\s]')\n    text = punctuations.sub(r'',text)\n    return text\n    ","fe19c5f8":"stopwrds = stopwords.words('english')\n\ndef remove_stopwords(text):\n    final_text =[]\n    for i in text.split():\n        #print(i.strip().lower())\n        if i.strip().lower() not in stopwrds and i.strip().lower().isalpha():\n            final_text.append(i.strip().lower())\n            \n    return \" \".join(final_text)\n\n            ","ce754990":"# applying the functions to the review column\n\nimdb_df['review'] = imdb_df['review'].apply(strip_html)\nimdb_df['review'] = imdb_df['review'].apply(remove_punctuations)\nimdb_df['review'] = imdb_df['review'].apply(remove_stopwords)","f707cfa0":"le = LabelEncoder()\nimdb_df['sentiment'] = le.fit_transform(imdb_df['sentiment'])\nimdb_df.head()","76ddc3f4":"plt.figure(figsize = (20,20))\nwrdcld = WordCloud(max_words=2000,width=1600, height =800,\n                   stopwords = stopwrds,background_color='white').generate(\"\".join(imdb_df[imdb_df['sentiment']==1].review))\nplt.imshow(wrdcld,interpolation = 'bilinear')","e767ebd2":"plt.figure(figsize = (20,20))\nwrdcld = WordCloud(max_words=2000,width=1600, height =800,\n                   stopwords = stopwrds,background_color='white').generate(\"\".join(imdb_df[imdb_df['sentiment']==0].review))\nplt.imshow(wrdcld,interpolation = 'bilinear')","aa11aafd":"X = imdb_df['review']\ny = imdb_df['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)","f6edd0cc":"from sklearn.feature_extraction.text import CountVectorizer\n\ncount_vec = CountVectorizer()\ncountvec_train = count_vec.fit_transform(X_train)\ncountvec_test = count_vec.transform(X_test)\n\ncountvec_train.toarray()","a08d362a":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vec = TfidfVectorizer()\ntfidfvec_train = tfidf_vec.fit_transform(X_train)\ntfidfvec_test = tfidf_vec.transform(X_test)\n\ntfidfvec_train.toarray()","afa45001":"from sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC(C=0.5, random_state=42)\nlinear_svc.fit(tfidfvec_train, y_train)\n\npredict = linear_svc.predict(tfidfvec_test)","2db5f611":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(\"Classification Report: \\n\", classification_report(y_test, predict,target_names=['Negative','Positive']))\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predict))\nprint(\"Accuracy: \\n\", accuracy_score(y_test, predict))","47d142d1":"linear_svc_count = LinearSVC(C=0.5, random_state=42, max_iter=5000)\nlinear_svc_count.fit(countvec_train, y_train)\n\npredict_count = linear_svc_count.predict(countvec_test)\n","40eae906":"print(\"Classification Report: \\n\", classification_report(y_test, predict_count,target_names=['Negative','Positive']))\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predict_count))\nprint(\"Accuracy: \\n\", accuracy_score(y_test, predict_count))","414f643d":"bcount_vec = CountVectorizer()\nbcountvec_train = bcount_vec.fit_transform(X_train)\nbcountvec_test = bcount_vec.transform(X_test)\n\nbcountvec_train.toarray()","87eabdd3":"linear_svc_bcount = LinearSVC(C=0.5, random_state=42)\nlinear_svc_bcount.fit(bcountvec_train, y_train)\n\npredict_bcount = linear_svc_bcount.predict(bcountvec_test)","f68d3fa6":"print(\"Classification Report: \\n\", classification_report(y_test, predict_bcount,target_names=['Negative','Positive']))\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predict_bcount))\nprint(\"Accuracy: \\n\", accuracy_score(y_test, predict_bcount))","f59c7fc6":"#### Splitting data into Train and Test Sets","84f41f3a":"Now, applying the techniques to test the performance of the model","9d296d1a":"#### Wordcloud for negative text - label 0","c5ca84a8":"### TF-IDF Vectorizer\nTF stands for Text Frequency which means how many times a word (term) appears in a text (document). IDF means Inverse Document Frequency and is calculated as log(# of documents in corpus\/# of documents containing the term).\n<br> <br>\nFinally TF-IDF score is calculated as TF * IDF. <br> <br>\nIDF acts as a balancing factor and diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely.","da183d06":"<b> binary=True in count vectorizer","b9443fe1":"#### Removing stopwords\nStopwords are those words that do not provide any useful information to decide in which category a text should be classified. This may be either because they don't have any meaning (prepositions, conjunctions, etc.) or because they are too frequent in the classification context.\nWe remove these words as they do not provide much weight to the overall sentiment of the sentence","70697fe2":"### Basic Data Cleaning \n\n<ol>\n<li>The review section consists of text alongwith some html code. To remove the html code, we will use the python webscraping library Beautiful Soup<\/li>\n\n<li>To remove the urls and punctuations, we will use regular expressions in python<\/li>\n    \n<\/ol>","11b3cb84":"<b> So we can see the data has become numeric with 1,2 and 3s based on the number of times they appear in the text.\n<\/b>","bafd8c67":"# The whole notebook does not run on Kaggle due to memory constraints. Please download and run it on your local PC in order to obtain the results","ffec7501":"#### Wordcloud for positive text - label 1","03bdd0ce":"#### Reading the data\nRead the csv into a pandas dataframe and then display the first few rows of data to understand the values.","dc5b74a3":"#### Label encoding\nWe will perform label encoding on our dataset on the column sentiment, to replace the categorical variable with an integer variable so that it is more machine readable. ","46570f70":"From the above plot, we can see that the dataset is balanced.","cecd35e6":"Linear Support Vector classifier with count vectorizer\n\n<br> <br>\n<b>binary=False in count vectorizer","582848a8":"### Count Vectorizer\nThe count of a word in a particular sample or review becomes the value of the corresponding word vector","009feb87":"<b> Thus, as observed from the above results, our linear svc model gives the best accuracy when combined with tfidf vectorizer","89b71acd":"#### Visualizing and preprocessing the data\nUnderstanding the distribution of values in the data by visualizing it and performing some necessary preprocessing steps on it","98495f25":"### LinearSVC \nLinear Support Vector Classification with tfidf"}}