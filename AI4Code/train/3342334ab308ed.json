{"cell_type":{"e1ad3ba1":"code","b3adc887":"code","42d95cff":"code","19df6d0f":"code","fb7ce9ce":"code","fcc139bc":"code","1fa149dd":"code","56662c5b":"code","555c3603":"code","eec33571":"code","71290815":"code","150c8ed2":"code","af6be10e":"code","6df36e85":"code","92223b44":"code","684b2ddd":"code","5d1296b6":"code","eba64ca2":"code","9f5fa6fe":"code","77b9434f":"code","3ea4abbf":"code","9b0a7a03":"code","e433d900":"code","216c3f6f":"code","2d93f26a":"code","ffe69486":"code","cb30f1b0":"code","d7d11168":"code","f079afef":"code","f950c836":"code","5a10151e":"code","e41d5f78":"markdown","f02208df":"markdown","ef6de847":"markdown","2ddad335":"markdown"},"source":{"e1ad3ba1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b3adc887":"import time\nimport os\nimport sys\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.nn import functional as F\nimport torch.utils.data as data\n\n\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\n","42d95cff":"torch.cuda.is_available()","19df6d0f":"train = pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')","fb7ce9ce":"class SignLanguageDataset(data.Dataset):\n    \n    def __init__(self, df, transform=None):\n        \n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        \n        label = self.df.iloc[index, 0]\n        \n        img = self.df.iloc[index, 1:].values.reshape(28, 28)\n        img = torch.Tensor(img).unsqueeze(0)\n        if self.transform is not None:\n            img =self.transform(img)\n        \n        return img, label\n        ","fcc139bc":"def show_img(img, label):\n    img = img.squeeze()\n    img = img*40. + 159.\n    imgnp = img.detach().numpy()\n    plt.imshow(img, interpolation='bicubic')\n    print(label)","1fa149dd":"transforms4train = transforms.Compose([\n        #transforms.Normalize(159, 40),\n        transforms.RandomHorizontalFlip(p=0.1),\n        transforms.RandomApply([transforms.RandomRotation(degrees=(-180, 180))], p=0.2),\n]) ","56662c5b":"train_dataset = SignLanguageDataset(train, transform=transforms4train)\ntest_dataset = SignLanguageDataset(test)","555c3603":"len(train_dataset), len(test_dataset)","eec33571":"train_loader = data.DataLoader(train_dataset, batch_size=200, shuffle=True, num_workers=2)\ntest_loader = data.DataLoader(test_dataset, batch_size=200, shuffle=True, num_workers=2)","71290815":"trainiter = iter(train_loader)\nimg, label = next(trainiter)\nprint(img.shape)","150c8ed2":"show_img(img[10], label[10])","af6be10e":"def calc_out_size(img_size, kernel_size, stride=1, padding=1, dilation=1 ):\n    out_size = ((img_size + 2*padding - (dilation*(kernel_size-1) +1 )) \/ stride) + 1\n    return int(out_size)","6df36e85":"calc_out_size(28, 3)","92223b44":"class MyConvNet(nn.Module):\n    \n    def __init__(self, stride=1, dilation=1, n_classes=25):\n        \n        super(MyConvNet, self).__init__()\n        \n        self.stride = stride\n        self.dilation = dilation\n        self.n_classes = n_classes\n        \n        self.block1 = nn.Sequential(\n            #input=(batch, 1, 28, 28)\n            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1, stride=self.stride, dilation=self.dilation),\n            nn.BatchNorm2d(8),\n            # (batch, 8, 28, 28)\n            nn.AvgPool2d(2),\n            # (batch, 8, 14, 14)\n            nn.ReLU()\n            )\n        \n        self.block2 = nn.Sequential(\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1, stride=self.stride, dilation=self.dilation),\n            nn.BatchNorm2d(16),\n            # (batch, 16, 14, 14)\n            nn.AvgPool2d(2),\n            # (batch, 16, 7, 7)\n            nn.ReLU()\n        )\n        \n        self.lin1 = nn.Linear(in_features=16*7*7, out_features=100)\n        # (batch, 100)\n        self.act1 = nn.LeakyReLU()\n        self.drop1 = nn.Dropout(p=0.3)\n        self.lin2 = nn.Linear(100, self.n_classes)\n        # (batch, 25)\n    \n    def forward(self, x):\n        \n        x = self.block1(x)\n        x = self.block2(x)\n        x = x.view((x.shape[0], -1))\n        x = self.lin1(x)\n        x = self.act1(x)\n        x = self.drop1(x)\n        x = self.lin2(x)\n        \n        return x","684b2ddd":"model = MyConvNet()\nmodel","5d1296b6":"sample_batch = torch.ones(20, 1, 28, 28)\nprint(model.block1(sample_batch).shape)\nprint(model.block2(model.block1(sample_batch)).shape)\nprint(model(sample_batch).shape)","eba64ca2":"def eval_model(model, criterion, test_loader, cuda=True):\n    \n    if cuda:\n        model = model.cuda()\n    \n    model = model.eval()\n    \n    running_loss = 0.\n    num_correct = 0.\n    num_total = 0.\n    \n    for batch, labels in test_loader:\n        \n        if cuda:\n            batch = batch.cuda()\n            labels = labels.cuda()\n        \n        out = model(batch)\n        pred_labels = out.argmax(dim=1)\n        num_correct += float((pred_labels == labels).sum())\n        \n        loss = criterion(out, labels)\n        running_loss += loss.data.cpu()\n        \n        num_total += labels.shape[0]\n    \n    mean_loss = running_loss \/ num_total\n    accuracy = num_correct \/ num_total\n    \n    return mean_loss, accuracy\n        \n        ","9f5fa6fe":"def train_model(n_epochs, model, optimizer, criterion, train_loader, test_loader, cuda=True):\n    \n    if cuda:\n        model = model.cuda()\n    \n    model = model.train()\n    \n    train_loss, train_acc = [], []\n    test_loss, test_acc = [], []\n    \n    for epoch in range(n_epochs):\n        t0 = time.perf_counter()\n        \n        running_loss = 0.\n        num_correct = 0.\n        num_total = 0.\n        \n        for batch, labels in train_loader:\n            if cuda:\n                batch = batch.cuda()\n                labels = labels.cuda()\n            \n            optimizer.zero_grad()\n            \n            out = model(batch)\n            pred_labels = out.argmax(dim=1)\n            num_correct += float((pred_labels == labels).sum())\n            num_total += labels.shape[0]\n            \n            \n            \n            loss = criterion(out, labels)\n            running_loss += loss\n            loss.backward()\n            optimizer.step()\n        \n        epoch_loss = running_loss \/ num_total\n        epoch_acc = num_correct \/ num_total\n        \n        train_loss.append(epoch_loss.data.cpu())\n        train_acc.append(epoch_acc)\n        \n        t_loss, t_acc = eval_model(model, criterion, test_loader, cuda=True)\n        \n        test_loss.append(t_loss.data.cpu())\n        test_acc.append(t_acc)\n        \n        t1 = time.perf_counter()\n        \n        delta_t = t1 - t0\n        print(f\"EPOCH {epoch} ({round(delta_t, 4)} s.): train loss - {epoch_loss}, train accuracy - {epoch_acc}; test loss - {t_loss}, test accuracy - {t_acc}\")\n        \n    \n    return model, train_loss, train_acc, test_loss, test_acc        \n        \n        ","77b9434f":"optimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()","3ea4abbf":"model, train_loss, train_acc, test_loss, test_acc = train_model(20, model, optimizer, criterion, train_loader, test_loader, cuda=True)","9b0a7a03":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\nax1.plot(train_loss)\nax1.plot(test_loss)\nax1.legend(['train', 'test'])\nax1.set_title('Loss')\nax2.plot(train_acc)\nax2.plot(test_acc)\nax2.legend(['train', 'test'])\nax2.set_title('Accuracy')","e433d900":"state = {'model': model.state_dict(),\n        'epoch': 20}\ntorch.save(state, '.\/myconvnet_sign_lang.pth')","216c3f6f":"testiter = iter(test_loader)\nimg, label = next(testiter)\nmodel = model.cpu()","2d93f26a":"idx=12\npred = model(img)\nprint(f'Fact: {label[idx]}, Prediction: {(torch.argmax(pred[idx], dim=0))}')\nshow_img(img[idx], label[idx])","ffe69486":"resnet18 = models.resnet18(pretrained=False)\nresnet18","cb30f1b0":"resnet18.fc = nn.Linear(in_features=512, out_features=25) ","d7d11168":"resnet18_1channel = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding=1), \n                                resnet18)","f079afef":"smpl = torch.ones((10, 1, 28, 28))\nresnet18_1channel(smpl).shape","f950c836":"optimizer = optim.Adam(resnet18_1channel.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()","5a10151e":"model, train_loss, train_acc, test_loss, test_acc = train_model(30, resnet18_1channel, optimizer, criterion, train_loader, test_loader, cuda=True)","e41d5f78":"## Making simple custom convolution net:","f02208df":"## Defining our training and evaluation pipeline:","ef6de847":"## Defining Pytorch Dataset and Dataloader:","2ddad335":"## Using ready ResNet18 architecture (with additional layers to match desired input and output sizes)"}}