{"cell_type":{"78161846":"code","30afbe46":"code","b4a37d6f":"code","bf45587a":"code","28225aad":"code","78740ac5":"code","4bba0b14":"code","afb7e819":"code","9db8f05d":"code","da0ad3c2":"code","dcce3526":"code","bd36561e":"code","25e9128f":"code","15927ec0":"code","2ed5acc6":"code","a49003cd":"code","9bcb9f42":"code","9baf9659":"code","4af5609e":"code","b3e4815b":"code","05965b08":"code","6f89584c":"code","3c6da16e":"code","4e7c5353":"code","12f83bd8":"code","0147a96a":"code","559fa65d":"code","99641205":"code","a87149cc":"markdown"},"source":{"78161846":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","30afbe46":"import seaborn as sns\nimport matplotlib.pyplot as plt","b4a37d6f":"heart_df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","bf45587a":"heart_df.head()","28225aad":"heart_df.info()","78740ac5":"heart_df.isna().sum()","4bba0b14":"heart_df['target'].value_counts()","afb7e819":"sns.countplot(heart_df['target'])","9db8f05d":"cat_feats = [col for col in heart_df.columns if heart_df[col].nunique() <10]\ncont_feats = [col for col in heart_df.columns if col not in cat_feats]","da0ad3c2":"print('Categorical features', end=\": \"),\nprint(cat_feats)\nprint('Continuous features',end=\": \"),\nprint(cont_feats)\n","dcce3526":"for col in cat_feats:\n    print(heart_df[col].value_counts())","bd36561e":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(cont_feats, 1):\n    plt.subplot(3, 2, i)\n    heart_df[heart_df[\"target\"] == 0][column].hist(bins=35, color='blue', label='Heart Disease = NO', alpha=0.6)\n    heart_df[heart_df[\"target\"] == 1][column].hist(bins=35, color='green', label='Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","25e9128f":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(cat_feats, 1):\n    plt.subplot(3, 3, i)\n    heart_df[heart_df[\"target\"] == 0][column].hist(bins=35, color='blue', label='Heart Disease = NO', alpha=0.6)\n    heart_df[heart_df[\"target\"] == 1][column].hist(bins=35, color='green', label='Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","15927ec0":"df = heart_df\nfor col in cat_feats:\n    df[col] = df[col].apply(str)\n#check\ndf.info()","2ed5acc6":"# Converting categorical features into dummies\ndf = pd.get_dummies(df, columns = cat_feats)","a49003cd":"#Using standard scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\ndf[cont_feats] = sc.fit_transform(df[cont_feats])","9bcb9f42":"df.head()","9baf9659":"X = df.drop(['target_0','target_1'], axis = 1)\ny = heart_df['target']","4af5609e":"from sklearn.model_selection import train_test_split\n\nX_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)","b3e4815b":"from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier()\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\n","05965b08":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","6f89584c":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n","3c6da16e":"print(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","4e7c5353":"len(X.columns)","12f83bd8":"# Deep learning\ny_train = y_train.astype(int)\ny_test = y_test.astype(int)\n\n# Create a model with one hidden layer\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\n#input layer consists of 29 inputs\nmodel.add(Dense(32, activation='relu', input_shape=(30,))) \nmodel.add(Dense(16, activation='relu'))\n\n# Add an output layer with one output and sigmoid activation\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n                   \nmodel.fit(X_train, y_train, epochs=20, batch_size=1, verbose=1)\ny_nn_pred = model.predict(X_test)","0147a96a":"y_train","559fa65d":"print(confusion_matrix(y_test, y_nn_pred.round()))\nprint(classification_report(y_test, y_nn_pred.round()))","99641205":"submission = pd.DataFrame({'Id':y_test.index,'predict':y_pred})\nsubmission.to_csv('submission.csv')","a87149cc":"There are no null values"}}