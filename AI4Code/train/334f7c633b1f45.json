{"cell_type":{"d057e3b9":"code","af8f8df9":"code","fbac16e1":"code","b0711ca4":"code","7430e2cb":"code","72505b3d":"code","8a2c7de3":"code","232826b7":"code","4d132a28":"code","9985db5d":"code","4cd7a869":"code","fca1d27b":"code","33ab48aa":"code","c57cbd6e":"code","eb030890":"code","be097ee0":"markdown","4cc45b98":"markdown","429d4308":"markdown","37c3ac49":"markdown","1f4a7b44":"markdown","409d228a":"markdown","06820dc5":"markdown","0a915b4f":"markdown","f3fcd102":"markdown","a68c91ed":"markdown","62af2dd5":"markdown","b7ba35cc":"markdown","46b27caf":"markdown"},"source":{"d057e3b9":"import numpy as np\nimport torch\nfrom torchvision import datasets, transforms\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport pandas as pd\nfrom torch import nn, optim\n\nimport torch.nn.functional as F","af8f8df9":"labelsCSV = pd.read_csv('..\/input\/kuzushiji\/kmnist_classmap.csv', delimiter=',', nrows = 100)\nlabelsCSV.dataframeName = '..\/input\/kuzushiji\/kmnist_classmap.csv'\nnRow, nCol = labelsCSV.shape\nprint(labelsCSV)\nprint('\\nHay', nRow, 'filas y', nCol, 'columnas')","fbac16e1":"X_train = np.load('..\/input\/kuzushiji\/kmnist-train-imgs.npz')['arr_0'] #IMAGENES DE ENTRENAMIENTO\nY_train = np.load('..\/input\/kuzushiji\/kmnist-train-labels.npz')['arr_0'] #ETIQUETAS DE LAS IMAGENES\n\nX_test = np.load('..\/input\/kuzushiji\/kmnist-test-imgs.npz')['arr_0'] #IMAGENES PARA PROBAR EL MODELO\nY_test = np.load('..\/input\/kuzushiji\/kmnist-test-labels.npz')['arr_0'] #ETIQUETAS DE LAS IMAGENES DE PRUEBA","b0711ca4":"train_labels, train_counts = np.unique(Y_train, return_counts=True)\ntest_labels, test_counts = np.unique(Y_test, return_counts=True)\n\nfig, (ax1, ax2) = plt.subplots(figsize=(15,5), ncols=2)\nax1.bar(train_labels, train_counts, 2\/4, color=\"green\"); \nax1.set(xticks=train_labels)\nax1.set(xlabel='Etiquetas', ylabel='Numero de Imagenes')\nax1.set_title('TRAIN DATASET')\n\nax2.bar(test_labels, test_counts, 2\/4, color=\"blue\"); \nax2.set(xticks=test_labels)\nax2.set(xlabel='Etiquetas', ylabel='Numero de Imagenes')\nax2.set_title('TEST DATASET')","7430e2cb":"def normalizar(img, respu):\n    img = img.astype(np.float32)\n    img = img\/255.0 #normalizacion\n    img = np.reshape(img, (len(img), 1, 28, 28))\n    img = torch.Tensor(img)\n    respu = respu.astype('int64')\n    respu = torch.Tensor(respu).type(torch.LongTensor)\n    \n    return img, respu\n\nX_train, Y_train = normalizar(X_train, Y_train) #NORMALIZACION DE LAS IMAGENES TRAIN\nX_test, Y_test = normalizar(X_test, Y_test) #NORMALIZACION DE LAS IMAGENES TEST","72505b3d":"torch.manual_seed(0)\nX_train, X_dev, Y_train, Y_dev = train_test_split(X_train, Y_train, test_size = 0.05,  random_state=1) #Se crea el conjunto de validacion, 10% del conjunto de entrenamiento\n\ndataset_train = torch.utils.data.TensorDataset(X_train, Y_train) #DATASET DE ENTRENAMEINTO IMAGENES + ETIQUETAS\ntrainloader = torch.utils.data.DataLoader(dataset_train, batch_size = 128, shuffle = False) #DIVICION DEL DATASET EN BATCH DE 128=2^7\n\ndataset_test = torch.utils.data.TensorDataset(X_test, Y_test) #DATASET DE PRUEBAS IMAGENES + ETIQUETAS\ntestloader = torch.utils.data.DataLoader(dataset_test, batch_size = 128, shuffle = False)\n\ndataset_dev = torch.utils.data.TensorDataset(X_dev, Y_dev) #DATASET DE PRUEBAS IMAGENES + ETIQUETAS\ndevloader = torch.utils.data.DataLoader(dataset_dev, batch_size = 128, shuffle = False)\n\nprint (\"Numero de imagenes de ENTRENAMIENTO: \" + str(X_train.shape[0]))\nprint (\"Numero de imagenes de VALIDACI\u00d3N: \" + str(X_dev.shape[0]))\nprint (\"Numero de imagenes de PRUEBA: \" + str(X_test.shape[0]))\nprint (\"Tama\u00f1o de las imagenes: \" + str(X_train.shape[2]) + \"px , \" + str(X_train.shape[2]) + \"px, 1 capa\")\nprint (\"Dimenciones de X_train: \" + str(X_train.shape))\nprint (\"Dimenciones de Y_train: \" + str(Y_train.shape))\nprint (\"Dimenciones de X_dev: \" + str(X_dev.shape))\nprint (\"Dimenciones de Y_dev: \" + str(Y_dev.shape))\nprint (\"Dimenciones de X_test: \" + str(X_test.shape))\nprint (\"Dimenciones de Y_test: \" + str(Y_test.shape))","8a2c7de3":"imagen, etiqueta = next(iter(trainloader))\nindex=11\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(figsize=(15,5), ncols=4)\n\nax1.imshow(imagen[index][0])\nax1.set_title(\"Imagen de ejemplo =\" + str(index) +\"\\n Etiqueta = \"+ str((int(etiqueta[index]))))\nax2.imshow(imagen[index+1][0])\nax2.set_title(\"Imagen de ejemplo =\" + str(index+1) +\"\\n Etiqueta = \"+ str((int(etiqueta[index+1]))))\nax3.imshow(imagen[index+2][0])\nax3.set_title(\"Imagen de ejemplo =\" + str(index+2) +\"\\n Etiqueta = \"+ str((int(etiqueta[index+2]))))\nax4.imshow(imagen[index+3][0])\nax4.set_title(\"Imagen de ejemplo =\" + str(index+3) +\"\\n Etiqueta = \"+ str((int(etiqueta[index+3]))))","232826b7":"class Classifier(nn.Module):\n    def __init__(self, modelo):\n        super().__init__()\n        self.modelo = modelo\n        torch.manual_seed(2)\n        \n        if self.modelo == 1: #MODELO DE R.N.A.\n            self.fc1 = nn.Linear(784, 128) #Capa Entrada 784=(28px*28px*1) CONECTADA 1era Capa Oculta 128 neuronas\n            self.fc2 = nn.Linear(128, 64)  #1era Capa Oculta 128 CONECTADA 2da Capa Oculta 64 neuronas\n            self.fc3 = nn.Linear(64, 10)   #2da Capa Oculta 64 CONECTADA Capa de salida de 10 neuronas (10 tipos de letras)\n        \n        if self.modelo == 2: # 1er MODELO R.N.C\n            self.layer1 = nn.Sequential( # input=(128*1*28*28)\n            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0), # output = (128*6*24*24)\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2), # output = (128*6*12*12)\n            nn.Dropout(p=0.2))\n        \n            self.fc1 = nn.Linear(864, 512)\n            self.fc2 = nn.Linear(512, 64)\n            self.fc3 = nn.Linear(64, 10)\n            \n        if self.modelo == 3: # 2do MODELO R.N.C\n            self.layer1 = nn.Sequential( # input=(128*1*28*28)\n            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2), # output = (128*6*28*28)\n            nn.BatchNorm2d(6),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2), # output = (32*6*14*14)\n            nn.Dropout(p=0.1)) #nn.Dropout(p=0.2) \n            \n            self.layer2 = nn.Sequential(\n            nn.Conv2d(6, 12, kernel_size=4, stride=1, padding=0), # output = (128*12*11*11) \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2), # output = (128*12*5*5)\n            nn.Dropout(p=0.1))\n            \n            self.fc1 = nn.Linear(300, 512) #pading 0 (192,512)\n            self.fc2 = nn.Linear(512, 64)\n            self.fc3 = nn.Linear(64, 10)\n        \n        if self.modelo == 4: # 3do MODELO R.N.C\n            self.layer1 = nn.Sequential( # input=(128*1*28*28)\n            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2), # output = (128*6*28*28)\n            nn.BatchNorm2d(6),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2), # output = (128*6*14*14)\n            nn.Dropout(p=0.1)) \n            \n            self.layer2 = nn.Sequential(\n            nn.Conv2d(6, 12, kernel_size=3, stride=1, padding=1), # output = (128*12*14*14) \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), # output = (128*12*7*7)\n            nn.Dropout(p=0.1)) \n            \n            self.layer3 = nn.Sequential(\n            nn.Conv2d(12, 24, kernel_size=2, stride=1, padding=0), # output = (128*24*6*6) \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), # output = (128*24*3*3)\n            nn.Dropout(p=0.1))\n            \n            self.fc1 = nn.Linear(216, 512)\n            self.fc2 = nn.Linear(512, 64)\n            self.fc3 = nn.Linear(64, 10)\n            \n    def forward(self, x):\n        if self.modelo == 1:\n            x = x.view(x.shape[0], -1) # aplanar las imagenes en vectores\n            \n            l1 = F.relu(self.fc1(x)) #relu para la primera capa oculta\n            #l1 = F.dropout(l1, p=0.2)\n            l2 = F.relu(self.fc2(l1)) #relu para la segunda capa oculta\n            #l2 = F.dropout(l2, p=0.2)\n            predic = F.log_softmax(self.fc3(l2), dim=1) #softmax porque necesitamos que sean multiclase la salida\n            \n            return predic\n        \n        if self.modelo == 2:\n            l1 = self.layer1(x)\n        \n            x = l1.view(l1.shape[0], -1)\n        \n            l1fc = F.relu(self.fc1(x))\n            l2fc = F.relu(self.fc2(l1fc))\n            predic = F.softmax(self.fc3(l2fc), dim=1)\n        \n            return predic\n        \n        if self.modelo == 3:\n            l1 = self.layer1(x)\n            l2 = self.layer2(l1)\n            \n            x = l2.view(l2.shape[0], -1)\n            \n            l1fc = F.relu(self.fc1(x))\n            l2fc = F.relu(self.fc2(l1fc))\n            predic = F.softmax(self.fc3(l2fc), dim=1)\n            \n            return predic\n        \n        if self.modelo == 4:\n            l1 = self.layer1(x)\n            l2 = self.layer2(l1)\n            l3 = self.layer3(l2)\n            \n            x = l3.view(l3.shape[0], -1)\n            \n            l1fc = F.relu(self.fc1(x))\n            l2fc = F.relu(self.fc2(l1fc))\n            predic = F.softmax(self.fc3(l2fc), dim=1)\n            \n            return predic","4d132a28":"def entrenamiento(model, criterion, optimizer, epocas, tloader, dloader, lentrainds, lentestds):\n    \n    train_lost_array = []\n    train_accuracy_array = []\n    dev_lost_array = []\n    dev_accuracy_array = []\n    \n    for e in range(epocas):\n        model.train() #Cambiar a modo entrenamiento\n        train_loss = 0\n        accuracy = 0\n        steps = 0\n        \n        for i, (image, label) in enumerate(tloader):\n            y_techo = model(image)\n            loss = criterion(y_techo, label)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = torch.max(y_techo, 1)\n            accuracy += (predicted == label).sum()\n            steps += 1\n            \n        train_lost_array.append(train_loss\/steps)\n        train_accuracy_array.append(100 * accuracy\/\/lentrainds)\n        \n        model.eval()\n        with torch.no_grad():\n            iter_loss = 0\n            accuracy = 0\n            steps = 0\n            \n            for i, (images, labels) in enumerate(devloader):\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                iter_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                accuracy += (predicted == labels).sum()\n                steps += 1\n            \n            dev_lost_array.append(iter_loss\/steps)\n            dev_accuracy_array.append(100 * accuracy\/lentestds)\n            \n        print ('Epocas {}\/{}, Training Loss: {:.3f}, Training Accuracy: {:.2f}%, Validation Loss: {:.3f}, Validation Acc: {:.2f}%'.format(e+1, epocas, train_lost_array[-1], train_accuracy_array[-1], dev_lost_array[-1], dev_accuracy_array[-1]))\n                \n    return train_lost_array, train_accuracy_array, dev_lost_array, dev_accuracy_array","9985db5d":"#PARAMETROS DEL MODELO\nchoseModelo = 3 # Ek modelo 3 resulto tener el mejor rendimiento\nmodel = Classifier(choseModelo)\ncriterion = nn.CrossEntropyLoss() #nn.NLLLoss() nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001) #optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nepocas = 24\n\ntrain_lost_array, train_accuracy_array, dev_lost_array, dev_accuracy_array= entrenamiento(model, criterion, optimizer, epocas, trainloader, devloader, len(dataset_train), len(dataset_dev))\n\nfig, (ax1, ax2) = plt.subplots(figsize=(15,5), ncols=2)\nax1.plot(train_lost_array, label='Train Cost')\nax1.plot(dev_lost_array, label='Dev Cost')\nax1.set_title('Train\/Dev Cost')\nax1.set(xlabel='Epocas', ylabel='Costo')\nax1.legend()\n\nax2.plot(train_accuracy_array, label='Train Accuracy')\nax2.plot(dev_accuracy_array, label='Dev Accuracy')\nax2.set_title('Train\/Dev Accuracy')\nax2.set(xlabel='Epocas', ylabel='Aaccuracy')\nax2.legend()","4cd7a869":"#MODELO UTILIZADO\nprint(model)","fca1d27b":"def pintar(img, ps, lab):\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(8,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.set_title(\"Imagen de ejemplo =\" + str(index) +\"\\n Etiqueta = \"+ str((int(lab))))\n    ax1.axis('on')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(np.arange(10))\n    ax2.set_title('Probabilidad')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n    \n    print(labelsCSV)","33ab48aa":"%matplotlib inline\n\nindex=12\n\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\nimg = images[index]\nlab = labels[index]\n\nimg = img.resize_(1, 1, 28, 28) # Aplanado de la imagen\n\nmodel.eval()\nif choseModelo == 1 :\n    ps = torch.exp(model(img))\nelse:\n    ps=model(img)\n\n# Plot the image and probabilities\npintar(img.resize_(1, 28, 28), ps, lab)\n\nif (torch.argmax(ps) == lab):\n    print(\"\\nPrediccion Correcta! el verdadero valor es \" +str(int(lab))+\" y la prediccion fue \"+str(int(torch.argmax(ps))) +\"\\n\")\nelse:\n    print(\"\\nPrediccion Incorrecta!! el verdadero valor es \" +str(int(lab))+\" y la prediccion fue \"+str(int(torch.argmax(ps))) +\"\\n\")","c57cbd6e":"model.eval() #Cambiar a modo evaluacion\n\ntest_lost_array=[]\ntest_accuracy_array=[]\n\nwith torch.no_grad():\n    accuracy = 0\n    total = 0\n    test_loss = 0\n\n    for images, labels in testloader:\n        y_techo = model(images)\n        loss = criterion(y_techo, labels)\n\n        test_loss += loss.item()\n        test_loss = test_loss\/len(testloader)\n        _, predicted = torch.max(y_techo, 1)\n        total += labels.size(0)\n        accuracy += (predicted == labels).sum().item()\n        test_accuracy = (100*accuracy)\/total\n\n    test_lost_array.append(test_loss)\n    test_accuracy_array.append(test_accuracy)\n    print(f'test loss: {test_loss:.3f}, test accuracy: {(100*accuracy)\/total:.2f}%')","eb030890":"%matplotlib inline\n  \nindex=14\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[index]\nlab = labels[index]\n\nimg = img.resize_(1, 1, 28, 28) # Aplanado de la imagen\n\nmodel.eval()\nif choseModelo == 1 :\n    ps = torch.exp(model(img))\nelse:\n    ps=model(img)\n\npintar(img.resize_(1, 28, 28), ps, lab)\n\nif (torch.argmax(ps) == lab):\n    print(\"\\nPrediccion Correcta! el verdadero valor es \" +str(int(lab))+\" y la prediccion fue \"+str(int(torch.argmax(ps))) +\"\\n\")\nelse:\n    print(\"\\nPrediccion Incorrecta!! el verdadero valor es \" +str(int(lab))+\" y la prediccion fue \"+str(int(torch.argmax(ps))) +\"\\n\")","be097ee0":"**ALGUNAS IMAGENES DE ENTRENAMIENT0**","4cc45b98":"El **TRAIN DATASET** contiene 60.000 imagenes, 10.000 imagenes por cada una de los 10 tipos de letras.   El **TEST DATASET** contiene 10.000 imagenes, 1.000 imagenes por cada una de los 10 tipos de letras. ","429d4308":"## DATASET DE ENTRENAMIENTO TRAIN Y PRUEBA TEST\nLos archivos kmist-train-img.npz y kmnist-train-labels.npz contienen las imagenes y etiquetas de entrenamiento. Los archivos kmist-test-img.npz y kmnist-test-labels.npz contienen las imagenes y etiquetas de prueba ","37c3ac49":"## PREDICCIONES DEL MODELO CON EL TESTSET","1f4a7b44":"## LIBRERIAS","409d228a":"## TIPOS DE LETRAS Y ETIQUETAS EN EL DATASET\n\nUn archivo CSV contiene los 10 tipos de letras Kuzushiji que conforman el dataset, junto con el indice que le corresponde a cada una.","06820dc5":"## ENTRENAMIENTO DEL MODELO ","0a915b4f":"**PROBANDO EL MODELO CON UNA IMAGEN DEL SET DE ENTRENAMIENTO**\n","f3fcd102":"## CREACI\u00d3N DE LA RED","a68c91ed":"**PROBANDO EL MODELO CON UNA IMAGEN DEL SET DE PRUEBA**","62af2dd5":"**Conociendo las distribuciones de los datos:**","b7ba35cc":"**RESULTADOS DEL ENTRENAMIENTO**","46b27caf":"**RESUMEN DEL MODELO UTILIZADO**"}}