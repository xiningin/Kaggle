{"cell_type":{"a77bd18b":"code","e79483eb":"code","9a758e52":"code","76b19e1c":"code","958a1f43":"code","d4559fef":"code","563a8db3":"code","ef368741":"code","5f37089b":"code","34a08ae2":"code","268c3c25":"code","a111cdaf":"code","eeef3b28":"code","1125627a":"code","06b745d3":"code","d44bba27":"code","134ac50e":"code","4600720d":"code","e8c13ccc":"code","d6c6ee5e":"code","c392fb93":"code","8c3e03fa":"code","8ff107a8":"code","bae10c91":"code","2c23590c":"code","1a9ec5e2":"code","90995f12":"code","1470a942":"code","8dcef7a7":"code","e90f0e40":"code","7c6f4f0f":"code","3ad68e32":"code","19876534":"code","92a9b1eb":"code","fcb319c8":"code","8853a3d1":"code","5abb009f":"code","abf79e50":"markdown"},"source":{"a77bd18b":"import pandas as pd\nimport numpy as np\n\n#Load Training Dataset\ntitanic_train_data = pd.read_csv('..\/input\/titanic\/train.csv',na_values=['?'])\ntitanic_train_data.describe()","e79483eb":"#Load Testing Dataset\ntitanic_test_data = pd.read_csv('..\/input\/titanic\/test.csv',na_values=['?'])\ntitanic_test_data.describe()","9a758e52":"print(\"Missing data in the train set:\")\ndisplay(titanic_train_data.isnull().sum())\nprint(\"Missing data in the test set:\")\ndisplay(titanic_test_data.isnull().sum())","76b19e1c":"print('Age Stats for the Training Set')\n\nprint(\"Mean for Age seperated by Pclass:\")\ndisplay(titanic_train_data.groupby('Pclass')['Age'].mean())\n\nprint(\"Mean for Age seperated by Pclass and Sex:\")\ndisplay(titanic_train_data.groupby(['Pclass','Sex'])['Age'].mean())\n\nprint(\"Mean for Age seperated by Pclass, Sex and Survived:\")\ndisplay(titanic_train_data.groupby(['Survived','Pclass','Sex'])['Age'].mean())\n\nprint(\"Median for Age seperated by Pclass:\")\ndisplay(titanic_train_data.groupby('Pclass')['Age'].median())\n\nprint(\"Median for Age seperated by Pclass and Sex:\")\ndisplay(titanic_train_data.groupby(['Pclass','Sex'])['Age'].median())\n\nprint(\"Median for Age seperated by Pclass, Sex and Survived:\")\ndisplay(titanic_train_data.groupby(['Survived','Pclass','Sex'])['Age'].median())","958a1f43":"print('Age Stats for the Test Set')\n\nprint(\"Mean for Age seperated by Pclass:\")\ndisplay(titanic_test_data.groupby('Pclass')['Age'].mean())\n\nprint(\"Mean for Age seperated by Pclass and Sex:\")\ndisplay(titanic_test_data.groupby(['Pclass','Sex'])['Age'].mean())\n\nprint(\"Median for Age seperated by Pclass:\")\ndisplay(titanic_test_data.groupby('Pclass')['Age'].median())\n\nprint(\"Median for Age seperated by Pclass and Sex:\")\ndisplay(titanic_test_data.groupby(['Pclass','Sex'])['Age'].median())","d4559fef":"#Group the Train Dataset according to Survival\ntrain_data_survived = titanic_train_data[titanic_train_data['Survived'] == 1]\ntrain_data_nosurvived = titanic_train_data[titanic_train_data['Survived'] == 0]","563a8db3":"train_data_survived.describe()","ef368741":"train_data_nosurvived.describe()","5f37089b":"#Apply Median Age of the Survived Passengers after grouping them according to Pclass and Sex to the missing values in Age\ntrain_data_survived['Age'] = train_data_survived.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median()))","34a08ae2":"#Apply Median Age of the Dead Passengers after grouping them according to Pclass and Sex to the missing values in Age\ntrain_data_nosurvived['Age'] = train_data_nosurvived.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median()))","268c3c25":"train_data_survived.describe()","a111cdaf":"train_data_nosurvived.describe()","eeef3b28":"#Join the two sets again\ntitanic_train_data_2 = pd.concat([train_data_survived, train_data_nosurvived], sort=True).reset_index(drop=True)\ntitanic_train_data_2.describe()","1125627a":"#Shuffle the Set to avoid similar items kept together\ntitanic_train_data_2 = titanic_train_data_2.sample(frac=1).reset_index(drop=True)\ntitanic_train_data_2.describe()","06b745d3":"#Apply Median Age after grouping according to Pclass and Sex to the missing values \ntitanic_test_data['Age'] = titanic_test_data.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median()))","d44bba27":"titanic_test_data.describe()","134ac50e":"print(\"Missing data in the train set 2:\")\ndisplay(titanic_train_data_2.isnull().sum())\nprint(\"Missing data in the test set 2:\")\ndisplay(titanic_test_data.isnull().sum())","4600720d":"#Look for the passenger with missing fare\ntitanic_test_data.loc[titanic_test_data['Fare'].isnull()]","e8c13ccc":"#Apply median fare to the missing value after looking for similar passengers\ntitanic_test_data.loc[titanic_test_data['Fare'].isnull(),'Fare'] = titanic_test_data.loc[(titanic_test_data['Pclass']==3)&(titanic_test_data['Embarked']=='S')&(titanic_test_data['SibSp']==0)&(titanic_test_data['Parch']==0)]['Fare'].median()","d6c6ee5e":"#Look for the passengers with missing embarked\ntitanic_train_data_2.loc[titanic_train_data_2['Embarked'].isnull()]","c392fb93":"#Count How many people embarked at what given stations\ntitanic_train_data_2.loc[(titanic_train_data_2['Fare']<=80)&(titanic_train_data_2['Parch']==0)&(titanic_train_data_2['Pclass']==1)&(titanic_train_data_2['SibSp']==0)]['Embarked'].value_counts()","8c3e03fa":"#Assign embarked to the passengers missing it\ntitanic_train_data_2.loc[titanic_train_data_2['Embarked'].isnull(),'Embarked']='S'","8ff107a8":"print(\"Missing data in the train set 2:\")\ndisplay(titanic_train_data_2.isnull().sum())\nprint(\"Missing data in the test set 2:\")\ndisplay(titanic_test_data.isnull().sum())","bae10c91":"#Replace male and females with 1 and 0 for calculations\ntitanic_train_data_2['Sex'].replace(('male','female'),(1,0),inplace=True)\ntitanic_test_data['Sex'].replace(('male','female'),(1,0),inplace=True)","2c23590c":"#Replace Embarking Stations with numbers for calculations\ntitanic_train_data_2['Embarked'].replace(('C','Q','S'),(0,1,2),inplace=True)\ntitanic_test_data['Embarked'].replace(('C','Q','S'),(0,1,2),inplace=True)","1a9ec5e2":"print(\"Mean for Pclass seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Survived'])['Pclass'].mean())\n\nprint(\"Mean for Age seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Survived'])['Age'].mean())\n\nprint(\"Mean for Sex seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Survived'])['Sex'].mean())\n\nprint(\"Mean for SibSp seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Survived'])['SibSp'].mean())\n\nprint(\"Mean for Parch seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Survived'])['Parch'].mean())\n\nprint(\"Mean for Fare seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Survived'])['Fare'].mean())\n\nprint(\"Mean for Embarked seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Survived'])['Embarked'].mean())","90995f12":"print(\"Mean for SibSp seperated by Survived, Pclass, Sex, Age:\")\ndisplay(titanic_train_data_2.groupby(['Pclass','Sex'])['SibSp'].mean())\n\nprint(\"Mean for Parch seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Pclass','Sex'])['Parch'].mean())\n\nprint(\"Mean for Embarked seperated by Survived:\")\ndisplay(titanic_train_data_2.groupby(['Pclass','Sex'])['Embarked'].mean())","1470a942":"#Split set to features and classes\/labels\nall_features = titanic_train_data_2.drop(['PassengerId','Survived','Name','Ticket','Cabin','Embarked'], axis=1).values\nall_classes = titanic_train_data_2['Survived'].values\n\nsur = 0\nfor i in all_classes:\n    if i ==1:\n        sur = sur+1\nprint(len(all_classes))\nprint(sur\/len(all_classes))","8dcef7a7":"#Scale the features for model fitting\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nscaler.fit(all_features)\nscaler.transform(all_features)","e90f0e40":"#Split the features and labels\/classes to train and test\ntrain_features = all_features[:711]\ntrain_classes = all_classes[:711]\n\ntest_features = all_features[711:]\ntest_classes = all_classes[711:]","7c6f4f0f":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\n\n#Stop the model once certain requirements are met\n#callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20,restore_best_weights=True)\n\n#Create Model\nmodel = Sequential()\nmodel.add(Dense(16, activation='relu', input_shape=(6,))) #dense layer with 512 neurones, taking 784 pixels in \nmodel.add(Dropout(0.2))\nmodel.add(Dense(16, activation ='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid')) #final output layer with 1 neurone","3ad68e32":"#Compile model using Adam Optimizer\nmodel.compile(loss='binary_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","19876534":"#Fit the features and test using batches of 8 over 60 iterations\nhistory = model.fit(train_features, train_classes,\n                    batch_size=32,\n                    epochs=100,\n                    verbose=2,\n                   # callbacks=[callback],\n                    validation_data=(test_features, test_classes))","92a9b1eb":"test_features_2 = titanic_test_data.drop(['PassengerId','Name','Ticket','Cabin','Embarked'], axis=1).values\n\nscaler2 = MinMaxScaler()\nscaler2.fit(test_features_2)\nscaler2.transform(test_features_2)","fcb319c8":"pred3 = model.predict(test_features_2)\n\n#Convert back from One-Hot Encoding to 0-1\nclass_labels = np.argmax(pred3, axis=1)\nprint(class_labels)\n\nfor i in range (len(pred3)):\n    if pred3[i] <= 0.5:\n        pred3[i]=0\n    else:\n        pred3[i]=1\nprint(pred3)","8853a3d1":"submission = pd.DataFrame({'PassengerId':titanic_test_data.index+892, 'Survived': class_labels})\nsubmission.to_csv('Titanic_Submission.csv', index=False)","5abb009f":"count = 0\nfor i in pred3:\n    if i==1:\n        count=count+1\nprint(count\/len(class_labels))","abf79e50":"Please Note that the following Code and Model is slightly different from my original Submission. This is only to give an idea on how I approached the problem. \nMy Original Submission Score was 77.751%\nEnjoy"}}