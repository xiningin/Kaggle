{"cell_type":{"5d885ced":"code","bd0c4290":"code","c84ddbef":"code","30088ce0":"code","be061c2c":"code","18039292":"code","35d22a46":"code","f818d8e0":"code","02e28e02":"code","1dcef9f5":"code","ab205c80":"code","cfafb704":"code","bd811483":"code","a34df02c":"code","2c3083a5":"code","4b45d771":"code","c6795b32":"code","1fe1f6a0":"code","dfc0bddb":"code","e3072100":"code","1530e403":"code","75d985a4":"code","4b6f3e96":"markdown","bded274c":"markdown","d0bf3767":"markdown"},"source":{"5d885ced":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers\nfrom keras import Sequential\nfrom keras import models\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split # split the data into train and test set\nimport seaborn as sns\nimport cv2\nimport numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport random\nimport gc\nimport matplotlib.image as mpimg\nimport csv\nfrom tqdm import tqdm\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bd0c4290":"train_dir = \"\/kaggle\/input\/ieeeensiai\/train\/train\"\ntest_dir = \"\/kaggle\/input\/ieeeensiai\/test\/test\"\n\ntrain_set = [\"\/kaggle\/input\/ieeeensiai\/train\/train\/{}\".format(i) for i in os.listdir(train_dir)] # get the image training set\ntest_set = [\"\/kaggle\/input\/ieeeensiai\/test\/test\/{}\".format(i) for i in os.listdir(test_dir)] # get the image test set\ntrain_set= train_set[:11000]\ntest_set= test_set[:5000]\ndict_labels = {'10':0,'20':1,'50':2,'100':3,'200':4,'500':5,'1000':6,'2000':7,'5000':8}\nrandom.shuffle(train_set)","c84ddbef":"# displaying image data\ndef display_data(image):\n    img=mpimg.imread(image)\n    imgplot = plt.imshow(img)\n    plt.show()\ndisplay_data(train_set[8])","30088ce0":"labels = {}\nwith open('\/kaggle\/input\/ieeeensiai\/train.csv') as csv_file:\n    csv_reader = csv.reader(csv_file, delimiter=',')\n    for row in csv_reader:\n        if row[0]!= 'img':\n            labels[row[0]] = row[1]","be061c2c":"def process_images(list_of_images, labels):\n    X = []\n    Y = []\n#     vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n    for path in tqdm(list_of_images):\n        im = cv2.imread(path)\n        im = im[:,::-1]\n        X.append(im)\n#         im = im - vgg_mean\n        if labels:\n            label = path.split('\/')\n            label = label[-1]\n            label = label.split('.')[0]\n            categ = [0.]*9\n            categ[dict_labels[labels[label]]] = 1.\n            Y.append(categ)\n    return X, Y","18039292":"# processing data and making labels\nX, Y = process_images(train_set, labels)","35d22a46":"# delete unnecessary data\ndel train_set\ngc.collect()","f818d8e0":"# convert to array\nX = np.array(X)\nY = np.array(Y)","02e28e02":"# test image with corresponding label\ndef print_label(y):\n    for key, value in dict_labels.items():\n        index = list(y).index(1.)\n        if index == value:\n            return(key)\n# testing the labeled data\nplt.imshow(X[6])\nplt.title(print_label(Y[6]))","1dcef9f5":"print('image data shape', X.shape)\nprint('label shape', Y.shape)","ab205c80":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20)\n\nprint(\"shape of train images is :\",X_train.shape)\nprint(\"shape of validation images is :\",X_val.shape)\nprint(\"shape of train labels is :\",y_train.shape)\nprint(\"shape of validation labels is :\",y_train.shape)","cfafb704":"# clear memory\ndel X\ndel Y\ngc.collect()\n\n# get the lenght of train and validation data\nntrain = len(X_train)\nnval = len(X_val)\n\n# bach_size\nbatch_size = 64","bd811483":"model = models.Sequential()\n# Conv Block 1\n\nmodel.add(layers.Conv2D(64, (3, 3), input_shape=(224,224,3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 2\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 3\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 4\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# Conv Block 5\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n\n# FC layers\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(4096, activation='relu'))\n\nmodel.add(layers.Dense(4096, activation='relu'))\n\nmodel.add(layers.Dense(9, activation='softmax'))","a34df02c":"model.summary()","2c3083a5":"# compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['accuracy'])","4b45d771":"# create the augmentation configuration\n# this helps prevent overfitting, since we use a small dataset\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                    rotation_range=40,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    shear_range = 0.2,\n                                    horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale=1.\/255) # for validation dataset","c6795b32":"# creat the image generators\ntrain_generator = train_datagen.flow(X_train, y_train , batch_size=batch_size)\nval_generator = val_datagen.flow(X_val, y_val , batch_size=batch_size)","1fe1f6a0":"# the training part\n# we train for 64 epochs\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch=ntrain \/\/ batch_size,\n                             epochs=32,\n                             validation_data=val_generator,\n                             validation_steps=nval \/\/ batch_size)","dfc0bddb":"#Save the model\n# model.save('model_keras.h5')","e3072100":"# process the test set \nX_test,_ = process_images(test_set[:1000], labels=[])\nx = np.array(X_test)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\nx_test = test_datagen.flow(x, batch_size=1)\npredected = model.predict_generator(x_test,steps=len(x_test))\nprint(len(predected))","1530e403":"# make predection\npredect = []\nfor pre in predected:\n    index = list(pre).index(max(list(pre)))\n    for key,value in dict_labels.items():\n        if value ==index:\n            predect.append(key)","75d985a4":"# print some predection\nind = 40\npred = model.predict(x_test[ind])\nlist_label = list(pred[0,])\nprint(list_label)\nmaximum = max(list_label)\nindex = list_label.index(maximum)\ntext_label = ''\nfor key,val in dict_labels.items():\n    if val ==index:\n        text_label=key\nplt.title('it is a '+ text_label +\" coin\")\nimgplot = plt.imshow(x_test[ind][0])\nplt.show()","4b6f3e96":"## Load Dataset","bded274c":"### Test data","d0bf3767":"### Get labels from CSV file"}}