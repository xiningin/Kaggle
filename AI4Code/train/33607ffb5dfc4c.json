{"cell_type":{"22b2e524":"code","8b418690":"code","1a963916":"code","5445835b":"code","965b48e9":"code","7eb98a9a":"code","38034edd":"code","29f9d144":"code","86cbc510":"code","d6e165d5":"code","1a9a67d9":"code","e2b733bd":"code","ec8259b1":"code","0ca77dd0":"code","52375c09":"code","77dd8fe5":"code","85f803aa":"code","bdf82e6e":"code","ab9ab863":"code","923c6d4d":"code","204b8507":"code","c43abef8":"code","5985b22c":"code","049981cd":"code","2b7e4328":"code","de1e23b2":"code","f5794eb4":"code","da3d53e4":"code","bdc0e9d2":"code","bbe1152a":"code","d152e396":"markdown","cc6a1916":"markdown","d9737541":"markdown","98af66f4":"markdown","1446b39d":"markdown","bd9b536b":"markdown","5b967995":"markdown"},"source":{"22b2e524":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn","8b418690":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a963916":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_train.head()","5445835b":"df_train.info()","965b48e9":"df_train.describe()","7eb98a9a":"np.round(df_train.isna().sum() \/ df_train.shape[0], 1)","38034edd":"sns.heatmap(df_train.corr())\nplt.show()","29f9d144":"print(df_train['Survived'].value_counts())\nprint(df_train['Pclass'].value_counts())\nprint(df_train['Sex'].value_counts())\nprint(df_train['SibSp'].value_counts())\nprint(df_train['Parch'].value_counts())\nprint(df_train['Embarked'].value_counts())","86cbc510":"plt.subplots(figsize=(4, 4))\nsns.countplot(x='Sex', hue='Survived', data=df_train)\nplt.show()","d6e165d5":"plt.subplots(figsize=(4, 4))\nsns.countplot(x='Embarked', hue='Survived', data=df_train)\nplt.show()","1a9a67d9":"plt.subplots(figsize=(4, 4))\nsns.countplot(x='Pclass', hue='Survived', data=df_train)\nplt.show()","e2b733bd":"plt.subplots(figsize=(4, 4))\nsns.countplot(x='Parch', hue='Survived', data=df_train)\nplt.show()","ec8259b1":"f, ax = plt.subplots(figsize=(4, 4))\nax = sns.kdeplot(df_train[df_train['Survived'] == 0]['Age'])\nax = sns.kdeplot(df_train[df_train['Survived'] == 1]['Age'])","0ca77dd0":"df_train = df_train.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\ndf_train.head()","52375c09":"df_train['Sex'] = df_train['Sex'].replace('male', 0)\ndf_train['Sex'] = df_train['Sex'].replace('female', 1)\ndf_train['Sex'].value_counts()","77dd8fe5":"df_train['Embarked'] = df_train['Embarked'].replace('S', 0)\ndf_train['Embarked'] = df_train['Embarked'].replace('C', 1)\ndf_train['Embarked'] = df_train['Embarked'].replace('Q', 2)\ndf_train['Embarked'].value_counts()","85f803aa":"df_train = df_train.dropna()","bdf82e6e":"df_train.count()","ab9ab863":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import classification_report","923c6d4d":"X = df_train[[c for c in df_train.columns if c != \"Survived\"]]\ny = df_train[\"Survived\"]\nX.head()","204b8507":"y.head()","c43abef8":"model_dt = DecisionTreeClassifier()","5985b22c":"print(\"Decision Tree: \")\nkf = KFold(n_splits=5, random_state=32, shuffle=True)\ndt_score_list = list()\ncnt = 0\n\nfor train_index, test_index in kf.split(X):\n    \n    print(\"Fold {}:\".format(cnt + 1))\n    cnt += 1\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    model_dt.fit(X_train, y_train)\n    y_hat = model_dt.predict(X_test)\n    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_hat)\n    \n    df_temp = pd.DataFrame()\n    df_temp[\"Precision\"] = [prec[0], prec[1]]\n    df_temp[\"Recall\"] = [rec[0], rec[1]]\n    df_temp[\"F1-score\"] = [f1[0], f1[1]]\n    df_temp.index.name = 'Class'\n    print(df_temp)\n    \n    score = {'precision' : df_temp['Precision'].tolist(), \n             'recall' : df_temp['Recall'].tolist(),\n             'f1': df_temp['F1-score'].tolist()}\n    dt_score_list.append(score)","049981cd":"average_f1 = np.mean([np.mean(ele['f1']) for ele in dt_score_list])\nprint(\"Average f-score of Decision Tree: {:.2f}\".format(average_f1))","2b7e4328":"model_mlp = MLPClassifier(hidden_layer_sizes=(150,100,50),\n                          max_iter=300,\n                          activation = 'relu',\n                          solver='sgd',\n                          random_state=1)","de1e23b2":"print(\"Multi-layer Perceptron: \")\nkf = KFold(n_splits=5, random_state=32, shuffle=True)\nmlp_score_list = list()\ncnt = 0\n\nfor train_index, test_index in kf.split(X):\n    \n    print(\"Fold {}:\".format(cnt + 1))\n    cnt += 1\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    model_mlp.fit(X_train, y_train)\n    y_hat = model_mlp.predict(X_test)\n    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_hat)\n    \n    df_temp = pd.DataFrame()\n    df_temp[\"Precision\"] = [prec[0], prec[1]]\n    df_temp[\"Recall\"] = [rec[0], rec[1]]\n    df_temp[\"F1-score\"] = [f1[0], f1[1]]\n    df_temp.index.name = 'Class'\n    print(df_temp)\n    \n    score = {'precision' : df_temp['Precision'].tolist(), \n             'recall' : df_temp['Recall'].tolist(),\n             'f1': df_temp['F1-score'].tolist()}\n    mlp_score_list.append(score)","f5794eb4":"average_f1 = np.mean([np.mean(ele['f1']) for ele in mlp_score_list])\nprint(\"Average f-score of Multi-layer Perceptron: {:.2f}\".format(average_f1))","da3d53e4":"model_gnb = GaussianNB()","bdc0e9d2":"print(\"Decision Tree: \")\nkf = KFold(n_splits=5, random_state=32, shuffle=True)\ngnb_score_list = list()\ncnt = 0\n\nfor train_index, test_index in kf.split(X):\n    \n    print(\"Fold {}:\".format(cnt + 1))\n    cnt += 1\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    model_gnb.fit(X_train, y_train)\n    y_hat = model_gnb.predict(X_test)\n    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_hat)\n    \n    df_temp = pd.DataFrame()\n    df_temp[\"Precision\"] = [prec[0], prec[1]]\n    df_temp[\"Recall\"] = [rec[0], rec[1]]\n    df_temp[\"F1-score\"] = [f1[0], f1[1]]\n    df_temp.index.name = 'Class'\n    print(df_temp)\n    \n    score = {'precision' : df_temp['Precision'].tolist(), \n             'recall' : df_temp['Recall'].tolist(),\n             'f1': df_temp['F1-score'].tolist()}\n    gnb_score_list.append(score)","bbe1152a":"average_f1 = np.mean([np.mean(ele['f1']) for ele in gnb_score_list])\nprint(\"Average f-score of Gaussian Naive Bayes: {:.2f}\".format(average_f1))","d152e396":"## 2. Gaussian Naive Bayes","cc6a1916":"# Preprocessing","d9737541":"## 2. Multi-layer Perceptron","98af66f4":"# Train models","1446b39d":"## 1. Decision Tree","bd9b536b":"# Load dataset","5b967995":"# EDA"}}