{"cell_type":{"16955ec4":"code","e8475123":"code","5eab1910":"code","3a14c72a":"code","dbdf37ee":"code","18935a0d":"code","025d9755":"code","2ad93006":"code","62df3d7f":"code","2e6e4f35":"code","f5a71e86":"code","bdfc0504":"code","8f900adb":"code","ac46ecb3":"code","23f9e2d4":"code","0ec66cef":"code","3d2bf49e":"code","eabf03ce":"code","bd9d9704":"code","55b4fff6":"code","663eeceb":"code","8f9765dd":"code","933c632d":"code","616e4749":"code","3ecab2fa":"markdown","f4bbe588":"markdown","2c0bbe3f":"markdown","bef4266f":"markdown","f60eb7a9":"markdown","15f04535":"markdown","720e1321":"markdown","e9f8ecc4":"markdown","f5283d40":"markdown","2f579f52":"markdown","7bb5e3eb":"markdown","530bcb8e":"markdown","8f02349b":"markdown","26c6bf80":"markdown","9028e785":"markdown"},"source":{"16955ec4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objects as go","e8475123":"data = pd.read_excel(\"\/kaggle\/input\/covid19\/dataset.xlsx\")","5eab1910":"data","3a14c72a":"data.describe(include=\"all\")","dbdf37ee":"# Columns with no missing values: the first 6\ndata.columns[(data.isna().any() == False).values].values","18935a0d":"(data.iloc[:, 6:].isna().sum() \/ len(data)).sort_values()[:20]","025d9755":"# No positive case when Influenza A is detected\ndata.groupby([\"Influenza A\", \"SARS-Cov-2 exam result\"])[\"Patient ID\"].count()","2ad93006":"# Records with NaN in all feature columns (i.e. no lab exams)\ndata.iloc[:, 6:].isna().all(axis=1).value_counts()","62df3d7f":"# Number of positive to negative cases among those with lab exams\ndata[data.iloc[:, 6:].isna().all(axis=1)][\"SARS-Cov-2 exam result\"].value_counts()","2e6e4f35":"df = (data[data.iloc[:, 6:].isna().all(axis=1) == False] # Only patients that have at least one lab exam\n                  .groupby([\"Patient age quantile\", \"SARS-Cov-2 exam result\"])[\"Patient ID\"]\n                  .count()\n                  .reset_index()\n                  .rename(columns={\"Patient ID\":\"count\"})\n                  .sort_values(\"Patient age quantile\")\n     )\n\nfig = go.Figure(data=[\n    go.Bar(name='Positive', x=np.array(range(20)), y=df[df[\"SARS-Cov-2 exam result\"] == \"positive\"][\"count\"]),\n    go.Bar(name='Negative', x=np.array(range(20)), y=df[df[\"SARS-Cov-2 exam result\"] == \"negative\"][\"count\"])\n])\n# Change the bar mode\nfig.update_layout(barmode='group', \n                  xaxis_title=\"Age percentile\", \n                  yaxis_title=\"Count\",\n                  title=\"Histogram: age distribution of patients with at least one lab exam, with and without COVID-19\")","f5a71e86":"df = (data[data.iloc[:, 6:].isna().all(axis=1) == True] # Only patients that had no lab exams\n                  .groupby([\"Patient age quantile\", \"SARS-Cov-2 exam result\"])[\"Patient ID\"]\n                  .count()\n                  .reset_index()\n                  .rename(columns={\"Patient ID\":\"count\"})\n                  .sort_values(\"Patient age quantile\")\n     )\n\nfig = go.Figure(data=[\n    go.Bar(name='Positive', x=np.array(range(20)), y=df[df[\"SARS-Cov-2 exam result\"] == \"positive\"][\"count\"]),\n    go.Bar(name='Negative', x=np.array(range(20)), y=df[df[\"SARS-Cov-2 exam result\"] == \"negative\"][\"count\"])\n])\n# Change the bar mode\nfig.update_layout(barmode='group', \n                  xaxis_title=\"Age percentile\", \n                  yaxis_title=\"Count\",\n                  title=\"Histogram: age distribution of patients with at least one lab exam, with and without COVID-19\")","bdfc0504":"import xgboost as xgb\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder","8f900adb":"# Remove records that have null values for all exams \ndata_w_exams = data[~data.iloc[:, 6:].isna().all(axis=1)]\ny = data_w_exams[\"SARS-Cov-2 exam result\"]\nX = data_w_exams.iloc[:, 6:]\nX[\"Patient age quantile\"] = data_w_exams[\"Patient age quantile\"]","ac46ecb3":"X.loc[177, \"Urine - pH\"] = np.nan  # Substitute 'N\u00e3o Realizado' for NaN\nskip = {\"Urine - pH\":\"\"} # No need to transform this feature into categorical\n\n# Encode categorical features\nles = []\nfor field in list(X.dtypes[X.dtypes == \"object\"].index.values):\n#     print(field)\n    if field in skip:\n        X[field] = pd.to_numeric(X[field])\n        continue\n    le = LabelEncoder()\n    idx = X[field].notnull()\n    X.loc[idx, field] = pd.Series(le.fit_transform(X[idx][field]))\n    X[field] = pd.to_numeric(X[field], errors=\"raise\")\n    les.append(le)\n    \n# Encode target field\nley = LabelEncoder()\ny = ley.fit_transform(y)","23f9e2d4":"dm_w_exams = xgb.DMatrix(data=X, label=y)","0ec66cef":"####################\n##  Use cross-validation to evaluate different hyperparams of XGBoost models\n####################\n\ncolsamples = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3]\ndepths = [3, 4, 5, 7, 9, 11]\nalphas = [0, 0.1, 0.3, 1]\nlrs = [0.1, 0.01]\n\nbest = None\nfor colsample in colsamples:\n    for depth in depths:\n        for alpha in alphas:\n            for lr in lrs:\n                params = {\"objective\":\"binary:logistic\",'colsample_bytree': colsample,'learning_rate': lr,\n                                'max_depth': depth, 'alpha': alpha} # no improvement by changing scale_pos_weight here, needs more work\n\n                cv_results = xgb.cv(dtrain=dm_w_exams, params=params, nfold=3,\n                                    num_boost_round=500, early_stopping_rounds=10, \n                                    metrics=\"logloss\", \n#                                     metrics=\"auc\",\n                                    as_pandas=True, seed=123)\n                res = cv_results[\"test-logloss-mean\"].iloc[-1]\n#                 res = cv_results[\"test-auc-mean\"].iloc[-1]\n                if best is None:\n                    best = (colsample, depth, alpha, lr, res)\n                elif res < best[4]:\n                    best = (colsample, depth, alpha, lr, res)\nprint(\"Best:\\n\", best)","3d2bf49e":"params = {\"objective\":\"binary:logistic\",'colsample_bytree': best[0], 'learning_rate': best[3],\n                                'max_depth': best[1], 'alpha': best[2]}\n\ncv_results = xgb.cv(dtrain=dm_w_exams, params=params, nfold=3,\n                    num_boost_round=700, early_stopping_rounds=10, \n                    metrics=[\"logloss\"], as_pandas=True, seed=123)\nnum_rounds = len(cv_results)\ncv_results","eabf03ce":"params = {\"objective\":\"binary:logistic\",'colsample_bytree': best[0], 'learning_rate': best[3],\n                                'max_depth': best[1], 'alpha': best[2]}\n\nmodel =  xgb.train(dtrain=dm_w_exams, params=params,\n                    num_boost_round=num_rounds, \n                    )","bd9d9704":"# Top 20 most important features\nres = list(model.get_score(importance_type=\"gain\").items())\nres.sort(key=lambda x: x[1])\nres[::-1][:20]","55b4fff6":"from sklearn.metrics import precision_recall_curve, auc, roc_auc_score, accuracy_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","663eeceb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)\n\nprint(f\"Number of samples in train set: {len(X_train)}\\nNumber of samples in test set: {len(X_test)}\")\n\nparams = {\"objective\":\"binary:logistic\",'colsample_bytree': best[0], 'learning_rate': best[3],\n                                'max_depth': best[1], 'alpha': best[2]}\n\nmodel =  xgb.train(dtrain=xgb.DMatrix(data=X_train, label=y_train), params=params,\n                    num_boost_round=num_rounds)\n","8f9765dd":"preds = model.predict(xgb.DMatrix(data=X_test))\n\nprecision, recall, thresholds = precision_recall_curve(y_test, preds)\nplt.figure(figsize=(10, 7))\nplt.plot(precision, recall)\nplt.ylabel(\"Precision\")\nplt.xlabel(\"Recall\")\nplt.title(f\"Precision-Recall curve - PR-AUC: {auc(recall, precision):.3f}\")\n\nprint(\"For comparison: AUC:\", roc_auc_score(y_test, preds))\nprint(\"Accuracy: \", accuracy_score(y_test, np.around(preds)))\nprint(\"Precision: \", precision_score(y_test, np.around(preds)))\nprint(\"Recall: \", recall_score(y_test, np.around(preds)))","933c632d":"data_wo_exams = data[data.iloc[:, 6:].isna().all(axis=1)]\ndata_wo_exams","616e4749":"cols = [\"Patient ID\", \"Patient age quantile\", \"SARS-Cov-2 exam result\"]\ndata_wo_exams[cols].groupby(cols[1:]).count().groupby(level=0).apply(lambda x:\n                                                 100 * x \/ float(x.sum()))","3ecab2fa":"This can be used as a comparison with other models. But please note that since the dataset is imbalanced, metrics such as accuracy and AUC should be avoided and the 89% AUC is only listed here for illustration purposes. The actual threshold depends on the risk assessment and choice from the hospital.\n\n### 2.2 Statistical model - samples without lab exams\n\nFor many data samples we have no other information apart from the age.\n\nHere we assume the following:\n1. The physicians chose to perform lab exams on those that were symptomatic and were medium to severe cases.\n2. Those who did not have lab exams probably were asymptomatic or showed mild symptoms.\n3. Our data represents well enough the behavior of new patients that come in the future to this hospital with no to mild symptoms.\n\n\n- **[2.2.1] Frequentist approach:**","f4bbe588":"This notebook presents the solution to Task #1: \"Predict confirmed COVID-19 cases among suspected cases\".\nIt studies some models that hopefully will be useful in understanding and coordinating action against the COVID-19 pandemic.\n\nSome highlights are:\n1. Explore the data:\n    - Features are very sparse\n    - Many samples have no lab tests, only age information\n2. Modeling:\n    - The data is divided between those that: have lab tests vs. those that don't\n    - An XGBoost model is used for the cases with lab tests, where precision and recall are analyzed\n    - A simple frequentist model is used to estimate results in samples without lab tests\n\n-- For new patients, given the assumptions in this notebook:\n    - i. If presenting symptoms as to prompt lab testing, use the XGBoost model;\n    - ii. If not presenting symptoms and not requiring lab tests, use the frequentist model.\n\n## 1. Data Exploration","2c0bbe3f":"- **[2.1.2] Selecting the best hyperparameters:**","bef4266f":"- **[2.1.1] Preparing the data:**","f60eb7a9":"The above is a frequentist representation of what happens at the hospital. It is the proportion of positive to negative cases in each age quantile.\n\nIf a new patient comes and she has not strong enough symptoms to require additional lab tests, we could use the above probabilities to estimate the result of the SARS-Cov-2 exam, with a grain of salt of course.\n\nThe more appropriate method would be using bayesian inference, using as prior an aproximation of the distributions of those infected (e.g., using a Beta distribution with the estimated infection rate of those that visit the hospital) and adjusting it by the positive cases seen at each age quantile. But this is left as future work due to time contraints.","15f04535":"- **[1.6] Age distribution - patients with no lab exams:**","720e1321":"Another interesting observation is how widespread (relative to age) the positive cases are, instead of concentrating only in a small age range. \n\nWe need to be careful here to not assume this is a random sample of patients from the population, because:\n1. The hostpital's testing strategy was not made clear (e.g., based on symptoms, or widespread testing?)\n2. The hospital is private and present in a single city in Brazil and only those with access to it could be examined and only a few of these may have been tested.\n\nSo, in reality, the real prevalence of the disease might look different than what we observe here.\n\nOne important factor to consider is that COVID-19 seems to remain asymptomatic in many of those that contract it, but in most hospitals, due to the lack of sufficient testing kits, only symptomatic patients are tested. This opens the way for the real distribution, from which the cases above were drawn, to look different than what we see.","e9f8ecc4":"**This is a very interesting result, because the most important exams for the model are not the most commonly requested, so we can exclude the hypothesis of bias by being the most present in the data. **\n\n**The only feature that is present in all samples is the Age Quantile and we can see it is the 10th most important feature.**\n\n**Also, as expected by characteristics of COVID-19, features related to CO2 in the blood are among the top 6 most important.**\n\n- **[2.1.4] Estimation of Precision and Recall:**\n\nHere we divide the data between train (2\/3) and test (1\/3) sets to estimate precision and recall in an unseen part of the dataset.","f5283d40":"- **[1.4] Among these, we only have ~12% of positive cases, so the dataset is imbalanced, as one would expect.**","2f579f52":"- **[2.1.3] Feature importances:**","7bb5e3eb":"- ** [1.3] Interestingly, 2101 records have no exam results. For these cases, we can only hope to use the age to better predict the SARS-Cov-2. And it is important that we separate them so that our models are not biased towards samples without exams. **","530bcb8e":"- **[1.5] Age distribution - patients with at least one lab exam:**","8f02349b":"## 2. Modeling\n\n### 2.1 XGBoost - samples with lab exams","26c6bf80":"- ** [1.2] Probably doctors think these most used tests are most important in the COVID-19 diagnostics. The interesting note is that in all COVID-19 cases, no patient had a positive Influenza A result (as seen below) and probably this happens with other features too.**","9028e785":"- **[1.1]  The data is very sparse: the most populated field is still missing in 76% of the records:**"}}