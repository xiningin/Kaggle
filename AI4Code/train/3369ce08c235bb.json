{"cell_type":{"084b264e":"code","0090d91f":"code","35a58115":"code","fe3a8f29":"code","2db87327":"code","f47cd4f8":"code","657527d1":"code","53241fbd":"code","9a0f524f":"code","168e4322":"code","ce62bd9b":"code","65820a39":"code","a3430d24":"code","6203f7e1":"code","c95fc6eb":"code","98f7c94b":"code","c7531793":"code","042bddd4":"code","9d321971":"code","f5a67c26":"code","746bb0c0":"markdown","031802ef":"markdown","32574b59":"markdown","05062521":"markdown","828ac6de":"markdown","d5583c55":"markdown","6e115c92":"markdown","07b99b21":"markdown","7e8b8608":"markdown","32458a5f":"markdown","436e6645":"markdown","b584eb3a":"markdown"},"source":{"084b264e":"pip install mlxtend","0090d91f":"import pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\npd.set_option('display.expand_frame_repr', False)\nfrom mlxtend.frequent_patterns import apriori, association_rules\n","35a58115":"# We use these functions to ignore outliers.\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","fe3a8f29":"# We use these functions for data preprocessing\ndef retail_data_prep(dataframe):\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe","2db87327":"# The function we will use to bring the dataframe to the ARL form\n\ndef create_invoice_product_df(dataframe, id=False):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)","f47cd4f8":"# This function is used to find the name of the product whose StockCode is given.\ndef check_id(dataframe, stock_code):\n    if type(stock_code)==list:\n        return([dataframe[dataframe[\"StockCode\"] == code][[\"Description\"]].values[0].tolist() for code in stock_code])\n    else:\n        product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0][0]\n        return(product_name)","657527d1":"# This function is used to learn the rules for arl_recommender\ndef create_rules(dataframe, id=True, country=\"France\"):\n    dataframe = dataframe[dataframe['Country'] == country]\n    dataframe = create_invoice_product_df(dataframe, id)\n    frequent_itemsets = apriori(dataframe, min_support=0.01, use_colnames=True)\n    rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\n    return rules","53241fbd":"# this function is used to recommend for the product the basket\ndef arl_recommender(rules_df, product_id, rec_count=1):\n    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n    recommendation_list = []\n    for i, product in sorted_rules[\"antecedents\"].items():\n        for j in list(product):\n            if j == product_id:\n                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"]))\n    recommendation_list = list({item for item_list in recommendation_list for item in item_list})\n    return recommendation_list[:rec_count]","9a0f524f":"# Let's import the data we will use.\ndf_= pd.read_csv('..\/input\/online-retail\/online_retail_II.csv')\ndf= df_[df_[\"InvoiceDate\"] >= '2010-12-01']\ndf.head()","168e4322":"# The Unnamed column has been deleted.\ndf.columns.str.match(\"Unnamed\")\ndf=df.loc[:,~df.columns.str.match(\"Unnamed\")]\ndf.head()\n","ce62bd9b":"df.describe().T\n# As can be seen in the description of the data, the standard deviations are very high.\n# When you look at the max and min values, contradictory observations are seen. \n# At the same time, there are negative observations that should not be present in our data. \n# These cause our results to be inaccurate.","65820a39":"# so we need to clear our data from these values.\ndf= retail_data_prep(df)","a3430d24":"df.describe().T","6203f7e1":"## **The form we want our data to come in for the ARL data structure.**\n\n# Description   NINE DRAWER OFFICE TIDY   SET 2 TEA TOWELS I LOVE LONDON    SPACEBOY BABY GIFT SET\n# Invoice\n# 536370                              0                                 1                       0\n# 536852                              1                                 0                       1\n# 536974                              0                                 0                       0\n# 537065                              1                                 0                       0\n# 537463                              0                                 0                       1","c95fc6eb":"# Let's choose Germany as the country in our data.\ndf_germany= df[df['Country']== 'Germany']\ndf_germany.head()","98f7c94b":"# In order to bring our data to the form we want, let's arrange it so that the invoices in the rows, the product name \n# in the columns, and the sum of the quantity in the intersections. At the same time, let's fill the na values and the \n# values less than 0 with 0. Let's fill values greater than 0 with 1.\ndf_germany_inv_pro=create_invoice_product_df(df_germany)\ndf_germany_inv_pro.head()","c7531793":"rules= create_rules(df, country=\"Germany\")\nrules.head()","042bddd4":"# Let's get the names of the three products with the following StockCodes using the check_id function.\ncheck_lists=['21987','23235','22747']\nprint(check_id(df_germany, check_lists))","9d321971":"# Removal of Association Rules","f5a67c26":"check_lists=['21987','23235','22747']\n# Recommending the 3 closest products to the above products for which the stock code is given.\nrecommends = {check_id(df_germany, stock_no):\n              check_id(df_germany, arl_recommender(rules_df=rules, product_id=stock_no, rec_count=3)) for stock_no in check_lists}\nprint(recommends)","746bb0c0":"***The cart information of 3 different users is given below. Make the most appropriate product recommendation for this basket information.\nNote: Product recommendations can be 1 or more than 1. Derive the decision rules from the 2010-2011 Germany customers.***\n\n> \u25aa **User 1 product id: 21987**\n\n> \u25aa **User 2 product id: 23235**\n\n> \u25aa **User 3 product id: 22747**","031802ef":"# **Dataset Story**\n> *The dataset named Online Retail II shows the sales of a UK-based online store between 01\/12\/2009 - 09\/12\/2011.\ncontains.\nThe product catalog of this company includes souvenirs. promotion\ncan be considered as products. There is also information that most of its customers are wholesalers.*","32574b59":"# VARIABLES\n> * **InvoiceNo**: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter \u2018c\u2019, it indicates a cancellation.\n> * **StockCode**: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n> * **Description**: Product (item) name. Nominal.\n> * **Quantity**: The quantities of each product (item) per transaction. Numeric.\n> * **InvoiceDate**: Invoice Date and time. Numeric, the day and time when each transaction was generated.\n> * **UnitPrice**: Unit price. Numeric, Product price per unit in sterling.\n> * **CustomerID**: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n> * **Country**: Country name. Nominal, the name of the country where each customer resides.","05062521":"# **DIAPER - BEER RELATIONSHIP**\n\n![image.png](attachment:d2214776-3590-4445-94a9-0ac5185250ca.png) \n\nWhen we consider diapers and beer one by one, you may think that they are two unrelated products, but if we look at the analyzes made by the American retail giant Walmart, we can see that they are not so irrelevant. According to the analysis, 4,000 of the 200,000 purchase data handled include diapers. 5,500 of them contain beer. In addition, 3,500 transactions include both diapers and beer products. When this review is interpreted, it is observed that parents who have new children spend their evenings at home instead of going out to have fun, buying beer. Based on these observations, Walmart manages to make a profit by putting diapers and beer in close aisles.","828ac6de":">    **The recommends for the product of 'PACK OF 6 SKULL PAPER CUPS'**  ","d5583c55":"# **Business Problem**\n> *Suggesting products to users at the basket stage.*","6e115c92":"# **APRIORY ALGORITHM**\n\nThe Apriori algorithm is a widely used algorithm for association analysis. This algorithm has certain metrics. \n\n* **Support**: Indicates the rate at which a relationship is repeated across all purchases.\n\n* **Confidence**: Indicates the probability that customers who buy product X will buy product Y.\n\n* **Lift**: If the first product is purchased, the probability of purchasing the second product increases.\n\n![1_3eQ7CesIRbMiZ2JePUdpjA.jpeg](attachment:c808da33-db46-49a1-9be4-0762b7aa7850.jpeg)","07b99b21":"* antecedents :first product\n* consequents :second product\n* antecedent support : the possibility of purchasing the first product alone\n* consequent support:the possibility of purchasing the second product alone\n* support confidence:Possibility of purchasing together\n* lift: If the first product is purchased, the probability of purchasing the second product increases.","7e8b8608":"# **Data Preprocessing**","32458a5f":"# **Association Rules Analysis**\n\n![sepet.png](attachment:be6ced0c-f52c-4411-a987-8a188c6d76a7.png)\n\nAssociation Rules are one of the first techniques used in data mining and it is one of the first analyzes that comes to mind when data mining is mentioned. Association analysis; It is the analysis made to reveal the connection between the data we have. One of the first examples that comes to mind when it comes to association analysis is diapers and beer!","436e6645":"# ***Now let's generate the rules of association through Germany customers.***","b584eb3a":"![2.png](attachment:bba0d36f-84ff-4463-a70e-1f59aaf6d9e1.png)"}}