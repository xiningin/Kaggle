{"cell_type":{"5c1adb48":"code","1fb6ce3b":"code","05175e19":"code","63b8b2dc":"code","2154f15e":"code","eff43308":"code","2e2cc381":"code","ed2a9f5b":"code","ada972a4":"code","c21d616f":"code","2e51d136":"code","93b53615":"code","e541102a":"code","8810bb5c":"code","b2fec38d":"code","7051812f":"code","1ef7260d":"code","0faeb5ac":"code","10999f70":"code","2e9dafff":"code","9b0b9359":"code","fb033e28":"code","b53161f0":"code","3de2320a":"code","5d1b8023":"code","090b4c31":"code","95dcf22b":"code","0ce52cb1":"code","8339ea4c":"code","ca6f6495":"code","55ddb9f0":"code","b68ea279":"code","a3093085":"code","cb6cac72":"code","aa02958c":"code","f8387581":"code","8470412a":"code","37f55e43":"code","2be1c4e7":"code","b0f0f5a1":"code","d57aaa02":"code","594cd3ba":"code","317079be":"code","948e996d":"code","2fece758":"code","6d936d83":"code","8a8af448":"code","e255efe9":"code","0983a8ec":"code","d67f6f76":"code","3b0b9a9d":"code","d81f3259":"code","af6d7533":"code","6b2d727a":"code","75468230":"code","a0104f32":"code","ac23bd33":"code","b2582a9f":"code","b795eacd":"code","8b20f2df":"code","faa82120":"code","4eeb93bd":"code","2c516d13":"code","96874e48":"code","db210e88":"markdown","6ba2b0bf":"markdown","0c8b32b2":"markdown","bbbdc002":"markdown","53a4bfff":"markdown","bad9f7fa":"markdown","62fadcdd":"markdown","a3744226":"markdown","4565dedc":"markdown","fe4f34fe":"markdown","d03df03a":"markdown","f1562ede":"markdown","6e25411a":"markdown","c57e6812":"markdown","515bf540":"markdown","dbe1d2c7":"markdown","7e1502b6":"markdown","ae1531ad":"markdown"},"source":{"5c1adb48":"# Important Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Preprocessing modules\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Model\nfrom sklearn.ensemble import RandomForestClassifier\n# Metrics\nfrom sklearn.metrics import plot_confusion_matrix, classification_report, plot_roc_curve\n\n# Saving the model\nimport pickle","1fb6ce3b":"data = pd.read_csv('..\/input\/shipping\/shipping_data.csv')\ndata.head()","05175e19":"df = data.copy()\ndf.shape","63b8b2dc":"df.info()","2154f15e":"# Checking for presence of null values specifically in O\/P as well as in the I\/P features\ndf.isnull().sum()","eff43308":"# The output values are well distributed (balanced)\ndf['Reached.on.Time_Y.N'].value_counts()","2e2cc381":"# Changing the 'F' values into 'E'\ndf['Warehouse_block'].unique()","ed2a9f5b":"whb_map = {\n    'A':'A',\n    'B':'B',\n    'C':'C',\n    'D':'D',\n    'F':'E',\n}","ada972a4":"df['Warehouse_block'] = df['Warehouse_block'].map(whb_map)","c21d616f":"df.head()","2e51d136":"# Successfully mapped 'E' with 'F'\ndf['Warehouse_block'].unique()","93b53615":"corr = df.corr()","e541102a":"plt.figure(figsize=(10,8))\nsns.heatmap(corr, annot=True, cmap='RdYlGn')\nplt.show()","8810bb5c":"df.drop(['ID'],axis=1,inplace=True)","b2fec38d":"X = df.drop(['Reached.on.Time_Y.N'],axis=1)\nX.head()","7051812f":"y = df['Reached.on.Time_Y.N']\ny.head()","1ef7260d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","0faeb5ac":"plt.figure(figsize=(15,10))\nX_train.boxplot()\nplt.show()","10999f70":"outliers_features = ['Discount_offered', 'Prior_purchases']\noutliers_features","2e9dafff":"# My custom Transformer to handle the Outliers\n\nfrom sklearn.base import TransformerMixin\nimport pandas as pd\npd.options.mode.chained_assignment = None  # To ignore the warning for not returning a copied DataFrame\n\nclass HandleOutliers(TransformerMixin):\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n\n        from scipy.stats import shapiro\n\n        for col in X.columns : # Looping through all columns within the given DataFrame\n            \n            # If p-value < 0.05 == Skewed Distribution, else Normal Distribution\n            \n            if shapiro(X[col]).pvalue < 0.05 :\n\n                # IQR method to handle outliers with Skewed Distribution\n                q1 = X[col].quantile(0.25)\n                q3 = X[col].quantile(0.75)\n\n                iqr = q3 - q1\n\n                lower_boundary = q1 - 1.5 * q1\n                upper_boundary = q3 + 1.5 * q3\n\n                X.loc[X[col] <= lower_boundary, col] = lower_boundary\n                X.loc[X[col] >= upper_boundary, col] = upper_boundary\n\n                \n            else :\n\n                # 3-Sigma method to handle outliers with Normal Distribution\n                lower_boundary = X[col].mean() - 3 * X[col].std()\n                upper_boundary = X[col].mean() + 3 * X[col].std()\n\n                X.loc[X[col] <= lower_boundary, col] = lower_boundary\n                X.loc[X[col] >= upper_boundary, col] = upper_boundary\n                \n        return X","9b0b9359":"outliers = HandleOutliers()","fb033e28":"# X_train before handling the outliers\nX_train[outliers_features].hist(bins=50)\nplt.show()","b53161f0":"outliers_df = outliers.fit_transform(X_train[outliers_features])","3de2320a":"outliers_df.hist(bins=50)\nplt.show()","5d1b8023":"X_train.drop(outliers_features, axis=1, inplace=True)","090b4c31":"X_train = pd.concat([X_train, outliers_df], axis=1)","95dcf22b":"X_train.head()","0ce52cb1":"# X_train after handling the outliers\nX_train[outliers_features].hist(bins=50)\nplt.show()","8339ea4c":"# Appending all the features with dtype == 'object' (Categorical Features) in a list\ncat_features = []\n\nfor col in X_train.columns :\n    if X_train[col].dtype == 'object' :\n        cat_features.append(col)\n        \ncat_features","ca6f6495":"dummies_WH_Block = pd.get_dummies(X_train['Warehouse_block'], prefix='WH_Block', drop_first=True)\ndummies_Mode_of_S = pd.get_dummies(X_train['Mode_of_Shipment'], prefix='Mode_of_S', drop_first=True)\ndummies_Gender = pd.get_dummies(X_train['Gender'], prefix='Gender', drop_first=True)","55ddb9f0":"encode_df = pd.concat([dummies_WH_Block, dummies_Mode_of_S, dummies_Gender], axis=1)","b68ea279":"encode_df.head()\n","a3093085":"X_train = pd.concat([X_train, encode_df], axis=1)","cb6cac72":"X_train.drop(['Warehouse_block', 'Mode_of_Shipment', 'Gender'], axis=1, inplace=True)","aa02958c":"# New X_train with OneHot Encoded features\nX_train.head()","f8387581":"X_train['Product_importance'].unique()","8470412a":"Product_imp = {\n    'low' : 0,\n    'medium' : 1,\n    'high' : 2\n}","37f55e43":"X_train['Product_Importance'] = X_train['Product_importance'].map(Product_imp)","2be1c4e7":"X_train.head()","b0f0f5a1":"X_train['Product_Importance'].unique()","d57aaa02":"X_train.drop(['Product_importance'], axis=1, inplace=True)","594cd3ba":"# New X_train with Ordinal values of the feature 'Product_Importance'\nX_train.head()","317079be":"# 1. Handling the outliers (Using transform method for Test data)\noutliers_df = outliers.transform(X_test[outliers_features])\n\nX_test.drop(outliers_features, axis=1, inplace=True)\n\nX_test = pd.concat([X_test, outliers_df], axis=1)\n\n# 2. OneHotEncoding\n\ndummies_WH_Block = pd.get_dummies(X_test['Warehouse_block'], prefix='WH_Block', drop_first=True)\ndummies_Mode_of_S = pd.get_dummies(X_test['Mode_of_Shipment'], prefix='Mode_of_S', drop_first=True)\ndummies_Gender = pd.get_dummies(X_test['Gender'], prefix='Gender', drop_first=True)\n\nencode_df = pd.concat([dummies_WH_Block, dummies_Mode_of_S, dummies_Gender], axis=1)\n\nX_test = pd.concat([X_test, encode_df], axis=1)\n\nX_test.drop(['Warehouse_block', 'Mode_of_Shipment', 'Gender'], axis=1, inplace=True)\n\n# 3. Ordinal Encoding (using map method)\nX_test['Product_Importance'] = X_test['Product_importance'].map(Product_imp)\n\nX_test.drop(['Product_importance'], axis=1, inplace=True)","948e996d":"X_test.head()","2fece758":"X_train.columns == X_test.columns","6d936d83":"rf = RandomForestClassifier()","8a8af448":"rf_model = rf.fit(X_train, y_train)","e255efe9":"rf_model.score(X_test, y_test)","0983a8ec":"rf_params = {\n    'n_estimators' : [50,100,130,150],\n    'max_depth' : [4,5,10,20,None],\n    'min_samples_split' : [2,3,4,5],\n    'min_samples_leaf' : [1,4,10,20],\n    'max_leaf_nodes' : [2,5,10,None]\n}","d67f6f76":"rf_rs = RandomizedSearchCV(rf, rf_params, cv=5, n_iter=10)","3b0b9a9d":"rf_best_model = rf_rs.fit(X_train, y_train)","d81f3259":"rf_best_model.score(X_test, y_test)","af6d7533":"rf_best_model.best_params_","6b2d727a":"rf_best_model.best_estimator_","75468230":"y_pred = rf_best_model.predict(X_test)","a0104f32":"plot_confusion_matrix(rf_best_model, X_test, y_test)\nplt.title('Confusion Matrix\\n')\nplt.show()","ac23bd33":"print(\"Classification Report:\\n\\n\", classification_report(y_test, y_pred))","b2582a9f":"plot_roc_curve(rf_best_model, X_test, y_test)\nplt.title('ROC-AUC\\n')\nplt.show()","b795eacd":"# open a file, where you want to store the data\nfile = open('e_commerce_rf.pkl', 'wb')\n\n# dump information to that file\npickle.dump(rf_best_model, file)","8b20f2df":"model = open('e_commerce_rf.pkl', 'rb')","faa82120":"test_data = X_test.head()\ntest_data","4eeb93bd":"y_test.head()","2c516d13":"rf_best_model.predict(test_data)","96874e48":"rf_best_model.predict([[4, 5, 216, 2053, 25.0, 3.0, 0, 0, 0, 1, 0, 1, 1, 2]])","db210e88":"### Saving the Model","6ba2b0bf":"### Tuning the Hyperparameters of RandomForest Model","0c8b32b2":"#### There isn't enough correlation among the input features in order to drop any\n#### Dropping the uniquely identifying feature : ID","bbbdc002":"### Correlation Heatmap","53a4bfff":"### No Null values present in the dataset","bad9f7fa":"### Preprocessing\n* Preprocessing the Train & Test Data separately to avoid Data Leakage\n#### 1.) Handling Continuous Features (Checking for the outliers)","62fadcdd":"#### 2.) Handling Categorical Features (Encoding)","a3744226":"### Creating a Custom Transformer to Handle Outliers","4565dedc":"### Train the Model","fe4f34fe":"##### b) Ordinal Encoding (using map method)","d03df03a":"### Preprocessing Test Data Seperately","f1562ede":"##### Nominal Features (To OneHot Encode)\n* 1) Warehouse_block\n\n* 2) Mode_of_Shipment\n\n* 3) Gender\n\n##### Ordinal Features (I will use the map method for this)\n* 4) Product_importance\n##### a) OneHotEncoding","6e25411a":"#### Features with OUTLIERS\n* A) Prior_purchases\n* B) Discount_offered","c57e6812":"### Model Performance","515bf540":"### Predictions","dbe1d2c7":"## Problem Statement\n\nAn international E-commerce Company wants to discover key insights from their customer database, and depending upon various parameters, wants to predict whether their future order will reach on time or not.","7e1502b6":"### Mapping the values in the Warehouse_block feature for convenience","ae1531ad":"### Model Building"}}