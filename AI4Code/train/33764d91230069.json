{"cell_type":{"3ee3c769":"code","4a16c5f7":"code","52d1649a":"code","95ed7c13":"code","32542c86":"code","e776ec14":"code","9d8268a4":"code","ec3b358a":"code","7a4687b0":"code","ed22f810":"code","018c089e":"code","54c18950":"code","4ed0405c":"code","37fc6155":"code","20a3b5fc":"code","7ac68837":"code","c1692c44":"markdown","2be0b787":"markdown"},"source":{"3ee3c769":"!pip install segmentation_models_pytorch","4a16c5f7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport albumentations as albu\nimport segmentation_models_pytorch as smp\nfrom albumentations.pytorch import ToTensor\nimport torch\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt","52d1649a":"DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')","95ed7c13":"!mkdir data\n!mkdir data\/images\n!unzip ..\/input\/256x256-images\/train.zip -d data\/images","32542c86":"!mkdir data\/masks\n!unzip ..\/input\/256x256-images\/masks.zip -d data\/masks","e776ec14":"class config:\n    images_path = '.\/data\/images'\n    masks_path = '.\/data\/masks'\n    backbone = 'resnet34'\n    ACTIVATION = 'sigmoid'\n    ENCODER_WEIGHTS = 'imagenet'\n    lr=1e-3\n    epochs=10\n    batch_size=8\n    T_max=500\n    im_size=256\n    num_workers=4","9d8268a4":"train_augmentation = albu.Compose([\n                        albu.HorizontalFlip(),\n                        albu.OneOf([\n                            albu.RandomContrast(),\n                            albu.RandomGamma(),\n                            albu.RandomBrightness(),\n                            ], p=0.3),\n                        albu.OneOf([\n                            albu.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n                            albu.GridDistortion(),\n                            albu.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n                            ], p=0.3),\n                        albu.ShiftScaleRotate(),\n                        albu.Resize(config.im_size, config.im_size),\n                        ToTensor()\n\n                    ])\n\nvalid_augmentation = albu.Compose([\n                        albu.Resize(config.im_size, config.im_size),\n                        ToTensor()\n                    ])\n\n\nclass HuBMAPDataset(Dataset):\n    def __init__(self, ids, transforms=None):\n        self.ids = ids\n        self.transforms = transforms\n        \n    def __getitem__(self, idx):\n        name = self.ids[idx]\n        img = cv2.imread(f\"{config.images_path}\/{name}\")\n        mask = cv2.imread(f\"{config.masks_path}\/{name}\", 0)\n        \n        if self.transforms:\n            augmented = self.transforms(image=img, mask=mask)\n            img = augmented['image']\n            mask = augmented['mask']\n\n        return img, mask\n\n    def __len__(self):\n        return len(self.ids)","ec3b358a":"data = os.listdir(config.images_path)#[:100]\ntrain_lsit = list(set([row.split(\"_\")[0] for row in data]))\ntrain_idx = [row for row in data if row.split(\"_\")[0] in train_lsit[:-2]]\nvalid_idx = [row for row in data if row.split(\"_\")[0] not in train_lsit[:-2]]\nlen(train_idx), len(valid_idx)","7a4687b0":"train_datasets = HuBMAPDataset(train_idx, transforms=train_augmentation)\nvalid_datasets = HuBMAPDataset(valid_idx, transforms=valid_augmentation)\ntrain_loader = DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\nvalid_loader = DataLoader(valid_datasets, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)","ed22f810":"x,y = train_datasets[1]\nx.shape,y.shape","018c089e":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()\n\n# same image with different random transforms\n\nimage, mask = train_datasets[5]\nvisualize(image=image.permute(1,2,0), mask=mask.squeeze(0))","54c18950":"model = smp.Unet(\n    config.backbone, \n    encoder_weights=config.ENCODER_WEIGHTS, \n    in_channels=3, \n    classes=1, \n    activation=config.ACTIVATION,\n    decoder_use_batchnorm=False\n)\noptimizer = torch.optim.AdamW(model.parameters(),lr=config.lr)\n\nloss_fn = smp.utils.losses.DiceLoss() # smp.utils.losses.BCEWithLogitsLoss()\n\n#metric = [smp.utils.losses.DiceLoss()]\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]","4ed0405c":"train_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss_fn, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=DEVICE,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss_fn, \n    metrics=metrics, \n    device=DEVICE,\n    verbose=True,\n)","37fc6155":"def savelogs(logs, name):\n    with open(f'{name}.txt', 'a') as f:\n        for k, v in logs.items():\n            f.write(f'{k} {v}')\n        f.write('\\n')","20a3b5fc":"max_score = 1e5\nlosses = {}\nious = {}\nlosses['train'] = []\nlosses['valid'] = []\nious['train'] = []\nious['valid'] = []\n\nfor i in range(0, config.epochs):\n    \n    print('\\nEpoch: {}'.format(i))\n    train_logs = train_epoch.run(train_loader)\n    valid_logs = valid_epoch.run(valid_loader)\n    \n    savelogs(train_logs, f'train_logs.txt')\n    savelogs(valid_logs, f'valid_logs.txt')\n    \n    losses['train'].append(train_logs['dice_loss'])\n    losses['valid'].append(valid_logs['dice_loss'])\n    ious['train'].append(train_logs['iou_score'])\n    ious['valid'].append(valid_logs['iou_score'])\n    #break\n    # do something (save model, change lr, etc.)\n    # val loss\n    if max_score > valid_logs['dice_loss']:\n        max_score = valid_logs['dice_loss']\n        torch.save(model, 'best.pth')\n        print('Model saved!')\n        \n    if i == 15:\n        optimizer.param_groups[0]['lr'] = 1e-5\n        print('Decrease decoder learning rate to 1e-5!')","7ac68837":"# PLOT\ndef plot(scores, name):\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n    plt.plot(range(len(scores[\"train\"])), scores[\"valid\"], label=f'val {name}')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n    plt.legend(); \n    plt.show()\n\nplot(losses, \"loss\")\nplot(ious, \"iou\")","c1692c44":"### reference:  \n\nhttps:\/\/www.kaggle.com\/c\/hubmap-kidney-segmentation\/notebooks   \nhttps:\/\/github.com\/qubvel\/segmentation_models.pytorch\/blob\/master\/examples\/cars%20segmentation%20(camvid).ipynb  \n","2be0b787":"#### data preprocessing:  \n\nhttps:\/\/www.kaggle.com\/iafoss\/256x256-images"}}