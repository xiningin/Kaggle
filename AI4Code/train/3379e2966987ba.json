{"cell_type":{"91753cc6":"code","865ea8b4":"code","0ccb2f85":"code","612c0ec5":"code","55e7ac7c":"code","ffa42ff1":"code","8e9ed361":"code","bf6892b7":"code","6a6993dc":"code","552f89b4":"code","b2d7be7d":"code","4c8a0b38":"code","fb7f830e":"code","234590cd":"code","49de0c4f":"code","dd862aef":"code","fdffaf13":"code","8fcc8333":"code","83c221fa":"code","54ddb3ff":"code","80c89aca":"code","b00523a9":"code","b1138034":"code","b41e67a5":"code","a8f0e0b1":"code","21e01313":"code","b2536438":"code","adc7c393":"code","f881275e":"markdown","49b511c6":"markdown","ad23be33":"markdown","dff8cc65":"markdown","9b9c35f0":"markdown","24732fc1":"markdown","13122d67":"markdown","0963e55e":"markdown","9dfe87d4":"markdown"},"source":{"91753cc6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","865ea8b4":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","0ccb2f85":"x_train = train.drop('label', axis=1)\/255.0\ny_label = train['label'].values\n\nx_test = test\/255.0","612c0ec5":"X_train = x_train.values.reshape(-1,28,28,1)\nX_test = x_test.values.reshape(-1,28,28,1)","55e7ac7c":"# datagen will randomly generate rotated, zoomed, shifted image\ndatagen = ImageDataGenerator(\n        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n)","ffa42ff1":"# a example to augmentation pic\nX_train3 = X_train[9,].reshape((1,28,28,1))\nY_train3 = [y_label[9]]\nplt.figure(figsize=(15,4.5))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    X_train2, Y_train2 = datagen.flow(X_train3,Y_train3).next()\n    plt.imshow(X_train2[0].reshape((28,28)),cmap=plt.cm.binary)\n    plt.axis('off')\n    if i==9: X_train3 = X_train[11,].reshape((1,28,28,1))\n    if i==19: X_train3 = X_train[18,].reshape((1,28,28,1))\nplt.subplots_adjust(wspace=-0.1, hspace=-0.1)\nplt.show()","8e9ed361":"import tensorflow as tf","bf6892b7":"class ResidualUnit(tf.keras.layers.Layer):\n    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n        super().__init__(**kwargs)\n        self.activation = tf.keras.activations.get(activation)\n        self.main_layers = [\n            tf.keras.layers.Conv2D(filters, 3, strides=strides, padding='SAME', use_bias=False),\n            tf.keras.layers.BatchNormalization(),\n            self.activation,\n            tf.keras.layers.Conv2D(filters, 3, strides=1, padding='SAME', use_bias=False),\n            tf.keras.layers.BatchNormalization(),\n            self.activation,\n            tf.keras.layers.Conv2D(filters, 3, strides=1, padding='SAME', use_bias=False),\n            tf.keras.layers.BatchNormalization(),\n        ]\n        self.skip_layers = []\n        \n        if strides > 1:\n            self.skip_layers = [\n                tf.keras.layers.Conv2D(filters, 1, strides=strides, padding='SAME', use_bias=False),\n                tf.keras.layers.BatchNormalization(),\n            ]\n            \n    def call(self, inputs):\n        Z = inputs\n        for layer in self.main_layers:\n            Z=layer(Z)\n        skip_Z = inputs\n        \n        for layer in self.skip_layers:\n            skip_Z = layer(skip_Z)\n        \n        return self.activation(Z +skip_Z)","6a6993dc":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(64, (7,7), input_shape=(28, 28, 1), padding='SAME'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2, 2))\nprev_filters = 64\nfor filters in [64]*2 + [128]*2 + [256]*2:    \n    print(filters)\n    strides = 1 if filters == prev_filters else 2\n    model.add(ResidualUnit(filters, strides=strides))\n    prev_filters = filters\nmodel.add(tf.keras.layers.GlobalAvgPool2D())\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dropout(0.5*0.5))\nmodel.add(tf.keras.layers.Dense(int(filters\/2), activation='relu'))\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))","552f89b4":"from keras.utils import plot_model\n\nresnet_architecture = plot_model(model, show_shapes=True, show_layer_names=False)\nresnet_architecture.width = 600\nresnet_architecture","b2d7be7d":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\nimport time\n\n## \u4f7f\u7528adam\uff0c\u4f18\u5316\u6307\u6807\u4e3aaccuracy\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer='adam',\n              metrics=['acc'])\n\ncheckpoint = ModelCheckpoint(\n    filepath=f'resnet-{int(time.time())}.dhf5',\n    monitor='loss',\n    save_best_only=True\n)\n\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8**x)\n\ncallbacks = [checkpoint, annealer]","4c8a0b38":"batch_size = 64\nhistory = model.fit(datagen.flow(X_train, y_label, batch_size=batch_size),\n                              epochs = 50,\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=callbacks,) ","fb7f830e":"model.evaluate(X_train, y_label)","234590cd":"def predict_proba(X, model, num_samples):\n    preds = [model(X, training=True) for _ in range(num_samples)]\n    return np.stack(preds).mean(axis=0)\n\ndef predict_class(X, model, num_samples):\n    proba_preds = predict_proba(X, model, num_samples)\n    return np.argmax(proba_preds, axis=1)","49de0c4f":"y_pred = predict_class(X_test, model, 20)","dd862aef":"res = pd.DataFrame(y_pred, columns=['Label'])\nres.index = res.index + 1\nres.index.rename('ImageId', inplace=True)\nres.to_csv('res.csv')","fdffaf13":"import numpy as np\nimport random\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# \u8ba9\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u8f93\u51fa\u5148\u524d\u6a21\u578b\u4e2d\u6240\u6709\u5c42\u7684\u4e2d\u95f4\u8868\u793a\u3002\nsuccessive_outputs = [layer.output for layer in model.layers[0:]]\n# \u8fdb\u884c\u53ef\u89c6\u5316\u6a21\u578b\u642d\u5efa\uff0c\u8bbe\u7f6e\u8f93\u5165\u548c\u8f93\u51fa\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n# \u9009\u53d6\u4e00\u5f20\u968f\u673a\u7684\u56fe\u7247\nimg = random.choice(X_train)  # \u968f\u673a\u9009\u53d6\u4e00\u4e2a\n\nplt.imshow(img, cmap=plt.cm.binary)\nplt.show()","8fcc8333":"img = img.reshape((1,) + img.shape)","83c221fa":"# \u8fd0\u884c\u6211\u4eec\u7684\u6a21\u578b\uff0c\u5f97\u5230\u6211\u4eec\u8981\u753b\u7684\u56fe\u3002\nsuccessive_feature_maps = visualization_model.predict(img)\n\n# \u9009\u53d6\u6bcf\u4e00\u5c42\u7684\u540d\u5b57\nlayer_names = [layer.name for layer in model.layers]\n\n# \u5f00\u59cb\u753b\u56fe\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  if len(feature_map.shape) == 4:\n    # \u53ea\u7ed8\u5236\u5377\u79ef\u5c42\uff0c\u6c60\u5316\u5c42\uff0c\u4e0d\u753b\u5168\u8fde\u63a5\u5c42\u3002\n    n_features = feature_map.shape[-1]  # \u6700\u540e\u4e00\u7ef4\u7684\u5927\u5c0f\uff0c\u4e5f\u5c31\u662f\u901a\u9053\u6570\uff0c\u4e5f\u662f\u6211\u4eec\u63d0\u53d6\u7684\u7279\u5f81\u6570\n    # feature_map\u7684\u5f62\u72b6\u4e3a (1, size, size, n_features)\n    size = feature_map.shape[1]\n    # \u6bcf8\u4e2a\u4e00\u884c\n    pic_num_per_row = n_features \/\/ 8 + 1\n    display_grid_arr = []\n    \n    # \u6211\u4eec\u5c06\u5728\u6b64\u77e9\u9635\u4e2d\u5e73\u94fa\u56fe\u50cf\n    display_grid = np.zeros((size, size * pic_num_per_row))\n    \n    for i in range(n_features):\n      if i>0 and (i % pic_num_per_row == 0 or i == n_features):\n        display_grid_arr.append(display_grid)\n        display_grid = np.zeros((size, size * pic_num_per_row))\n    \n      index = i % pic_num_per_row\n      # \u540e\u671f\u5904\u7406\u6211\u4eec\u7684\u7279\u5f81\uff0c\u4f7f\u5176\u770b\u8d77\u6765\u66f4\u7f8e\u89c2\u3002\n      x = feature_map[0, :, :, i]\n      x -= x.mean()\n      x \/= x.std()\n      x *= 64\n      x += 128\n      x = np.clip(x, 0, 255).astype('uint8')\n      # \u6211\u4eec\u628a\u56fe\u7247\u5e73\u94fa\u5230\u8fd9\u4e2a\u5927\u77e9\u9635\u4e2d\n      display_grid[:, index * size : (index + 1) * size] = x\n    # \u7ed8\u5236\u8fd9\u4e2a\u77e9\u9635\n    row_num = len(display_grid_arr)\n    scale = 200. \/ n_features\n    \n    fig, axes = plt.subplots(row_num, 1, figsize=(scale * pic_num_per_row, scale * row_num))  # \u8bbe\u7f6e\u56fe\u7247\u5927\u5c0f\n    fig.suptitle(layer_name, fontsize=40)  # \u8bbe\u7f6e\u9898\u76ee\n    # aspect='auto'\u81ea\u52a8\u63a7\u5236\u8f74\u7684\u957f\u5bbd\u6bd4\u3002 \u8fd9\u65b9\u9762\u5bf9\u4e8e\u56fe\u50cf\u7279\u522b\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u53ef\u80fd\u4f1a\u626d\u66f2\u56fe\u50cf\uff0c\u5373\u50cf\u7d20\u4e0d\u4f1a\u662f\u6b63\u65b9\u5f62\u7684\u3002\n    # cmap='viridis'\u8bbe\u7f6e\u56fe\u50cf\u7684\u989c\u8272\u53d8\u5316\n    \n    for i in range(row_num):\n      axes[i].imshow(display_grid_arr[i], aspect='auto', cmap='viridis')","54ddb3ff":"# y_pred = predict_class(X_train, model, 1)\ny_pred = model.predict_classes(X_train)","80c89aca":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score","b00523a9":"conf_max = confusion_matrix(y_label, y_pred)\nconf_max","b1138034":"plt.matshow(conf_max, cmap=plt.cm.gray)\nplt.show()","b41e67a5":"rows_num = conf_max.sum(axis=1, keepdims=True)\nnorm_conf_max = conf_max \/ rows_num\n\nnp.fill_diagonal(norm_conf_max, 0)\nplt.matshow(norm_conf_max, cmap=plt.cm.gray)\nplt.show()","a8f0e0b1":"diff_num = 10","21e01313":"# Convert it into a 1D array\na_1d = norm_conf_max.flatten()\n\n# Find the indices in the 1D array\nidx_1d = a_1d.argsort()[-diff_num:]\n\n# convert the idx_1d back into indices arrays for each dimension\nx_idx, y_idx = np.unravel_index(idx_1d, norm_conf_max.shape)\n\nprint(x_idx, y_idx)","b2536438":"import math\n\ndef plot_digits(img_arr, images_per_row):\n    img_arr = [x.reshape(28, 28) for x in img_arr]\n    row_num = math.ceil(len(img_arr)\/images_per_row)\n    row_arr = []\n    \n#     print(np.hstack(img_arr[0:5]))\n#     print(np.c_[np.array(img_arr[0:5]).flatten()])\n#     print(img_arr[0])\n    \n    for i in np.arange(row_num):\n        if i != row_num-1:\n            row_arr.append(np.hstack(img_arr[i*images_per_row: (i+1)*images_per_row]))\n        else:\n            row_arr.append(np.hstack(img_arr[i*images_per_row:]))\n    try:\n        image = np.vstack(row_arr)\n    except:\n        print(row_arr)\n        print(row_arr.shape)\n    \n    plt.imshow(image, cmap='binary')\n    plt.axis('off')","adc7c393":"for i in range(diff_num):\n    # 4 & 9\n    cl_4, cl_9 = x_idx[i], y_idx[i]\n    X_44 = X_train[(y_label == cl_4) & (y_pred == cl_4) ]\n    X_49 = X_train[(y_label == cl_4) & (y_pred == cl_9) ]\n    X_94 = X_train[(y_label == cl_9) & (y_pred == cl_4) ]\n    X_99 = X_train[(y_label == cl_9) & (y_pred == cl_9) ]\n\n    fig = plt.figure(figsize=(8,8))\n    fig.suptitle('{}_{}'.format(cl_4, cl_9), fontsize=20)\n    if len(X_44) != 0:\n        plt.subplot(221)\n        plot_digits(X_44[:25], images_per_row=5)\n\n    if len(X_49) != 0:    \n        plt.subplot(222)\n        plot_digits(X_49[:25], images_per_row=5)\n\n    if len(X_94) != 0:\n        plt.subplot(223)\n        plot_digits(X_94[:25], images_per_row=5)\n\n    if len(X_99) != 0:\n        plt.subplot(224)\n        plot_digits(X_99[:25], images_per_row=5)\n    plt.show()","f881275e":"# 5. predict (mc dropout)","49b511c6":"# 2. reshape data","ad23be33":"# 1. Load data","dff8cc65":"# 3. Data augmentation visualization","9b9c35f0":"# 6. Show rnn change","24732fc1":"# 4. train","13122d67":"# 7. Show Error prediction","0963e55e":"# 3. Build Resnet","9dfe87d4":"a great describe of augmentation\n\n[Does ImageDataGenerator add more images to my dataset?](https:\/\/stackoverflow.com\/questions\/51748514\/does-imagedatagenerator-add-more-images-to-my-dataset)"}}