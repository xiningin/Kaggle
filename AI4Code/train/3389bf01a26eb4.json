{"cell_type":{"889de4b9":"code","753abbca":"code","3b917e77":"code","a3ed52c9":"code","4a951e98":"code","bdb87c23":"code","e4714600":"code","cffb13a8":"code","c0dec0ab":"code","673d965d":"code","8b7c3312":"code","5e7aba02":"code","c5182887":"code","068a843d":"code","b5cc3583":"code","4d624bd4":"code","6a4f4a04":"code","3ae7a66a":"code","5edf3827":"code","7dc7eb64":"code","d98030e9":"code","ceac626a":"code","b5ba9b8d":"code","8da97d45":"code","cb41839b":"code","1b586864":"code","c6a4cbc5":"code","c6cc6d66":"code","b4af0a74":"code","07698ff5":"code","efd13eec":"code","005d9867":"code","74da2854":"code","bd6d6073":"markdown","08a4c050":"markdown","1385afa0":"markdown","1082eae5":"markdown","eadd2a71":"markdown","6e7bf406":"markdown","4b37355e":"markdown","913e6b6c":"markdown","f74e75ca":"markdown","ef67835b":"markdown","18f0ad51":"markdown","b0c1fa8b":"markdown"},"source":{"889de4b9":"#import library\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport nltk\nnltk.download('stopwords')\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport re\nimport string\nstring.punctuation\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nfrom sklearn.model_selection import train_test_split\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, SimpleRNN, Dense, Dropout\nfrom sklearn import metrics","753abbca":"df = pd.read_json('..\/input\/is-this-sentence-completed\/finished_sentences.json')","3b917e77":"df.shape","a3ed52c9":"df.head()","4a951e98":"df.info()","bdb87c23":"#selection data\ntext = df[['sentence']]\ntext.head()","e4714600":"#defining to remove punctuation\ndef remove_punctuation(text):\n    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree\n\ntext['sentence_clean'] = text['sentence'].apply(lambda text: remove_punctuation(text))\ntext.head()","cffb13a8":"#setting lower case\ntext['sentence_lower'] = text['sentence_clean'].str.lower()\ntext.head()","c0dec0ab":"#defining function for tokenization\ndef tokenization(text):\n    tokens = re.split('W+', text)\n    return tokens\n\n#applying function to the column\ntext['sentence_tokenied'] = text['sentence_lower'].apply(lambda x: tokenization(x))\ntext.head()","673d965d":"#stop words present in the library\nstopwords = nltk.corpus.stopwords.words('english')\n\n#defining the function to remove stopwords from tokenized text\ndef remove_stopwords(text):\n    output= [i for i in text if i not in stopwords]\n    return output\n\n#applying the function\ntext['no_stopword'] = text['sentence_tokenied'].apply(lambda x:remove_stopwords(x))\ntext.head()","8b7c3312":"#defining the object for stemming\nporter_stemmer = PorterStemmer()\n\n#defining a function for stemming\ndef stemming(text):\n    stem_text = [porter_stemmer.stem(word) for word in text]\n    return stem_text\n\n#applying the function\ntext['sentence_stemmend'] = text['no_stopword'].apply(lambda x: stemming(x))\ntext.head()","5e7aba02":"#defining the object for lemmatizing\nlemmatizer = WordNetLemmatizer()\n\n#defining a function for lemmatizing\ndef lemmatize_words(text):\n    lemma_text = [lemmatizer.lemmatize(word) for word in text]\n    return lemma_text\n                \n#applying the function\ntext['sentence_lemmatized'] = text['sentence_stemmend'].apply(lambda text: lemmatize_words(text))\ntext.head()","c5182887":"df_new = text[['sentence_clean']]\ndf_new.head()","068a843d":"#create function to get subjectivity\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\n#create function to get polarity\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\n\n#apply function to data \ndf_new['subjectivity'] = df_new['sentence_clean'].apply(getSubjectivity)\ndf_new['polarity'] = df_new['sentence_clean'].apply(getPolarity)\ndf_new.head()","b5cc3583":"#create function to get sentiment data\ndef getSentiment(score):\n    if score < 0:\n        return 'Negative'\n    elif score == 0:\n        return 'Neutral'\n    else:\n        return 'Positive'\n\n#apply function to data\ndf_new['sentiment'] = df_new['polarity'].apply(getSentiment)\ndf_new.head()","4d624bd4":"#selection data\njoin = (df['is_finished'], df_new['sentiment'])\nsentiment = pd.concat(join, axis = True)\nsentiment.head()","6a4f4a04":"#visualize track title\nplt.figure(figsize = (8,6))\nsns.countplot(df['is_finished'])\nplt.title(\"Finished Status of the Sentence\")\nplt.xlabel(\"Count\")\nplt.ylabel(\"Finished Status\")\nplt.show()","3ae7a66a":"#group finished status & sentiment\nstatus_sentiment = sentiment.groupby(['is_finished', 'sentiment']).size().reset_index(name = 'Count')\n\n#visualize finished status ~ sentiment\nplt.figure(figsize = (8,6))\nsns.barplot(data = status_sentiment, x = 'is_finished', y = 'Count', hue = 'sentiment', palette = 'Set1')\nplt.title(\"Finished Status ~ Sentiment\")\nplt.xlabel(\"Finished Status\")\nplt.ylabel(\"Count\")\nplt.show()","5edf3827":"#visualize positive sentiment of sentence\npositive = \" \".join(df_new[df_new.sentiment == 'Positive']['sentence_clean'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100).generate(positive)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Positive Sentence\")\nplt.axis('off')\nplt.show()","7dc7eb64":"#visualize neutral sentiment of sentence\nneutral = \" \".join(df_new[df_new.sentiment == 'Neutral']['sentence_clean'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, colormap = 'Set1').generate(neutral)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Neutral Sentence\")\nplt.axis('off')\nplt.show()","d98030e9":"#visualize negative sentiment of sentence\nnegative = \" \".join(df_new[df_new.sentiment == 'Negative']['sentence_clean'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, colormap = 'Set2').generate(negative)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Negative Sentence\")\nplt.axis('off')\nplt.show()","ceac626a":"#visualize sentiment\nplt.figure(figsize = (8,6))\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nchart = df_new['sentiment'].value_counts().plot(kind = 'bar', color = 'indigo')\nchart.set_xticklabels(chart.get_xticklabels(), rotation = 1)\nplt.title(\"Sentiment Analysis of Sentence\")\nplt.show()","b5ba9b8d":"#handling categorical data\ndf['is_finished'] = df['is_finished'].astype('category').cat.codes\ndf.head()","8da97d45":"#data preprocessing\nX, y = (df['sentence'].values, df['is_finished'].values)\n\n#feature scaling\ntk = Tokenizer(lower = True)\ntk.fit_on_texts(X)\nX_seq = tk.texts_to_sequences(X)\nX_pad = pad_sequences(X_seq, maxlen = 100, padding = 'post')\nX_pad","cb41839b":"#split data\nX_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size = 0.3, random_state = 0)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","1b586864":"#check validation\nbatch_size = 64\nX_train1 = X_train[batch_size:]\ny_train1 = y_train[batch_size:]\n\nX_test = X_train[:batch_size]\ny_test = y_train[:batch_size]","c6a4cbc5":"#build model\nvocabulary_size = len(tk.word_counts.keys()) + 1\nmax_words = 100\n\nembedding_size = 32\nregressor = Sequential()\nregressor.add(Embedding(vocabulary_size, embedding_size, input_length = max_words))\nregressor.add(SimpleRNN(200))\nregressor.add(Dense(1, activation = 'sigmoid'))\nregressor.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","c6cc6d66":"#fitting model\nregressor.fit(X_train1, y_train1, validation_data = (X_test, y_test), batch_size = 128, epochs = 5)","b4af0a74":"#result of summary model\nregressor.summary()","07698ff5":"#accuracy score\nscore = regressor.evaluate(X_test, y_test, verbose = 0)\nprint('Accuracy Score : ', score[1])","efd13eec":"#prediction\ny_pred = regressor.predict(X_test, verbose = 0)\ny_pred = (y_pred > 0.5)\nprint(y_pred)","005d9867":"#confusion matrix\nmatrix = metrics.confusion_matrix(y_test, y_pred)\nprint(matrix)\n\n#heatmap matrix\nplt.figure(figsize = (8,6))\nsns.heatmap(matrix, annot = True, cmap = 'viridis')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Actual\")\nplt.show()","74da2854":"#classification report\nreport = metrics.classification_report(y_test, y_pred)\nprint(report)","bd6d6073":"# \u2705 Reccurent Neural Network Model","08a4c050":"## Stemming","1385afa0":"## Removal Punctuation","1082eae5":"# \u2705 Data Extraction","eadd2a71":"# \ud83c\udd8e Classify whether a Sentence has been Finished or Not","6e7bf406":"## Lemmatizing","4b37355e":"# \u2705 Sentiment Analysis","913e6b6c":"## Tokenization","f74e75ca":"## Removal Stopwords","ef67835b":"#\u2705 Natural Language Processing","18f0ad51":"# \u2705 Visualization","b0c1fa8b":"## Lower Casing"}}