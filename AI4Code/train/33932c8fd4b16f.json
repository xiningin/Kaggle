{"cell_type":{"cb011b6d":"code","c2771e49":"code","026095ec":"code","b4140f6a":"code","766be025":"code","95963f7c":"code","341e2f59":"code","d67d047c":"code","b48e8ebe":"code","e28f28a9":"code","cc5f79ac":"code","1ef25adb":"code","7ab615e5":"code","9f269132":"markdown","64708c25":"markdown"},"source":{"cb011b6d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2771e49":"import tensorflow\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.optimizers import RMSprop","026095ec":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nvalidation = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsubmission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","b4140f6a":"X = train.drop([\"label\"],axis=1)\ny = train[\"label\"]","766be025":"from sklearn.model_selection import train_test_split\n\nraw_train_images, raw_test_images, raw_train_labels, raw_test_labels = train_test_split(X, y, test_size=0.3, \n                                                    random_state=101)","95963f7c":"#reshape, normalize\ntrain_images = np.array(raw_train_images).reshape((len(raw_train_images),28,28,1)).astype('float32')\/255\ntest_images = np.array(raw_test_images).reshape((len(raw_test_images),28,28,1)).astype('float32')\/255\nval_images = np.array(validation).reshape((len(validation),28,28,1)).astype('float32')\/255","341e2f59":"#one hot encode labels\ntrain_labels = tensorflow.keras.utils.to_categorical(raw_train_labels, 10)\ntest_labels = tensorflow.keras.utils.to_categorical(raw_test_labels, 10)","d67d047c":"input_shape=(28,28,1)\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n# 64 3x3 kernels\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n# Reduce by taking the max of each 2x2 block\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Dropout to avoid overfitting\nmodel.add(Dropout(0.25))\n# Flatten the results to one dimension for passing into our final layer\nmodel.add(Flatten())\n# A hidden layer to learn with\nmodel.add(Dense(128, activation='relu'))\n# Another dropout\nmodel.add(Dropout(0.5))\n# Final categorization from 0-9 with softmax\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","b48e8ebe":"model.summary()","e28f28a9":"history = model.fit(train_images, train_labels,\n                    batch_size=32,\n                    epochs=200,\n                    verbose=2,\n                    validation_data=(test_images, test_labels))","cc5f79ac":"score = model.evaluate(test_images, test_labels, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","1ef25adb":"pred = model.predict(val_images)","7ab615e5":"submission['Label'] = [int(np.argmax(val)) for val in pred]\nsubmission.to_csv('submission.csv', index=False)","9f269132":"# Model","64708c25":"# Evaluation"}}