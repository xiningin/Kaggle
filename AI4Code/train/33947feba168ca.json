{"cell_type":{"a172d202":"code","027345d7":"code","f864fe0b":"code","594ebf50":"code","3d3127c4":"code","9756ef1f":"code","7c7e0361":"code","bac4ee40":"code","52f6ba8e":"code","ac4b5a9c":"code","d98ab9c7":"code","6327d4fd":"code","ec862ac2":"code","95433333":"code","ad338605":"code","dc8860f6":"code","4a2c6869":"code","1cd32e25":"code","76a54010":"code","66ee7852":"code","19e80c14":"code","dfab2360":"code","6c97680d":"code","420f0f9d":"code","a4c3b836":"code","9c7735e7":"code","9874f646":"code","f79318ae":"code","2e2b0492":"code","e16ba0f3":"markdown","9a5e617d":"markdown","2b77f73e":"markdown","6b38cbd2":"markdown","07339980":"markdown","c02671da":"markdown","56236fa1":"markdown","ff4a549a":"markdown","3fea9fd4":"markdown","09fe3678":"markdown","3e8a9e98":"markdown"},"source":{"a172d202":"import os\nimport regex as re\nimport subprocess\nimport urllib\nimport numpy as np\nimport tensorflow as tf\n\nfrom IPython.display import Audio\n\nimport matplotlib.pyplot as plt\nimport time\n\nfrom IPython import display as ipythondisplay\nfrom string import Formatter\n\n# Import all remaining packages\n\nimport functools\nfrom tqdm import tqdm\n!apt-get install abcmidi","027345d7":"!apt-get install --yes timidity","f864fe0b":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint(dirname)","594ebf50":"def load_training_data():\n    with open('\/kaggle\/input\/abc-notation-of-tunes\/input.txt', \"r\") as f:\n        text = f.read()\n    songs = extract_song_snippet(text)\n    return songs\n\nsongs = load_training_data()\n\n# Print one of the songs\nexample_song = songs[0]\nprint(\"\\nSample song: \")\nprint(example_song)","3d3127c4":"def save_song_to_abc(song, filename=\"tmp\"):\n    save_name = \"{}.abc\".format(filename)\n    with open(save_name, \"w\") as f:\n        f.write(song)\n    return filename\n\ndef abc2wav(abc_file):\n    path_to_tool = os.path.join(dirname, 'abc2wav.sh')\n    cmd = \"{} {}\".format(path_to_tool, abc_file)\n    return os.system(cmd)\n\ndef play_wav(wav_file):\n    return Audio(wav_file)\n\ndef play_song(song):\n    basename = save_song_to_abc(song)\n    ret = abc2wav(basename+'.abc')\n    if ret == 0: #did not suceed\n        return play_wav(basename+'.wav')\n    return None\n\n\n# Convert the ABC notation to audio file and listen to it\nplay_song(example_song)","9756ef1f":"# Join our list of song strings into a single string containing all songs\nsongs_joined = \"\\n\\n\".join(songs) \n\n# Find all unique characters in the joined string\nvocab = sorted(set(songs_joined))\nprint(\"There are\", len(vocab), \"unique characters in the dataset\")\n","7c7e0361":"### Define numerical representation of text ###\n\n# Create a mapping from character to unique index. \nchar2idx = {u:i for i, u in enumerate(vocab)}\n\n# Create a mapping from indices to characters. \nidx2char = np.array(vocab)","bac4ee40":"print('{')\nfor char,_ in zip(char2idx, range(20)):\n    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\nprint('  ...\\n}')","52f6ba8e":"### Vectorize the songs string ###\n\ndef vectorize_string(string):\n  vectorized_output = np.array([char2idx[char] for char in string])\n  return vectorized_output\n\n\nvectorized_songs = vectorize_string(songs_joined)","ac4b5a9c":"print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n# check that vectorized_songs is a numpy array\nassert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\"","d98ab9c7":"### Batch definition to create training examples ###\n\ndef get_batch(vectorized_songs, seq_length, batch_size):\n  # the length of the vectorized songs string\n  n = vectorized_songs.shape[0] - 1\n  # randomly choose the starting indices for the examples in the training batch\n  idx = np.random.choice(n-seq_length, batch_size)\n\n  \n  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n    \n  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n  \n  # x_batch, y_batch provide the true inputs and targets for network training\n  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n  return x_batch, y_batch\n\ndef test_batch_func_types(func, args):\n    ret = func(*args)\n    assert len(ret) == 2, \"[FAIL] get_batch must return two arguments (input and label)\"\n    assert type(ret[0]) == np.ndarray, \"[FAIL] test_batch_func_types: x is not np.array\"\n    assert type(ret[1]) == np.ndarray, \"[FAIL] test_batch_func_types: y is not np.array\"\n    print(\"[PASS] test_batch_func_types\")\n    return True\n\ndef test_batch_func_shapes(func, args):\n    dataset, seq_length, batch_size = args\n    x, y = func(*args)\n    correct = (batch_size, seq_length)\n    assert x.shape == correct, \"[FAIL] test_batch_func_shapes: x {} is not correct shape {}\".format(x.shape, correct)\n    assert y.shape == correct, \"[FAIL] test_batch_func_shapes: y {} is not correct shape {}\".format(y.shape, correct)\n    print(\"[PASS] test_batch_func_shapes\")\n    return True\n\ndef test_batch_func_next_step(func, args):\n    x, y = func(*args)\n    assert (x[:,1:] == y[:,:-1]).all(), \"[FAIL] test_batch_func_next_step: x_{t} must equal y_{t-1} for all t\"\n    print(\"[PASS] test_batch_func_next_step\")\n    return True\n\ndef test_custom_dense_layer_output(y):\n    true_y = np.array([[0.2697859,  0.45750418, 0.66536945]],dtype='float32')\n    assert tf.shape(y).numpy().tolist() == list(true_y.shape), \"[FAIL] output is of incorrect shape. expected {} but got {}\".format(true_y.shape, y.numpy().shape)\n    np.testing.assert_almost_equal(y.numpy(), true_y, decimal=7, err_msg=\"[FAIL] output is of incorrect value. expected {} but got {}\".format(y.numpy(), true_y), verbose=True)\n    print(\"[PASS] test_custom_dense_layer_output\")\n    return True\n\n# Perform some simple tests to make sure your batch function is working properly! \ntest_args = (vectorized_songs, 10, 2)\nif not test_batch_func_types(get_batch, test_args) or \\\n   not test_batch_func_shapes(get_batch, test_args) or \\\n   not test_batch_func_next_step(get_batch, test_args): \n   print(\"======\\n[FAIL] could not pass tests\")\nelse: \n   print(\"======\\n[PASS] passed all tests!\")","6327d4fd":"x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n\nfor i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n    print(\"Step {:3d}\".format(i))\n    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))","ec862ac2":"def LSTM(rnn_units): \n  return tf.keras.layers.LSTM(\n    rnn_units, \n    return_sequences=True, \n    recurrent_initializer='glorot_uniform',\n    recurrent_activation='sigmoid',\n    stateful=True,\n  )","95433333":"def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n  model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n    LSTM(rnn_units), \n    tf.keras.layers.Dense(vocab_size)\n  ])\n\n  return model\n\nmodel = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)","ad338605":"model.summary()","dc8860f6":"x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\npred = model(x)\nprint(\"Input shape:      \", x.shape)\nprint(\"Prediction shape: \", pred.shape)","4a2c6869":"sampled_indices = tf.random.categorical(pred[0], num_samples=1)\nsampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\nsampled_indices","1cd32e25":"print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\nprint()\nprint(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))","76a54010":"### Defining the loss function ###\n\ndef compute_loss(labels, logits):\n  loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n  return loss\n\nexample_batch_loss = compute_loss(y, pred)\n\n\nprint(\"Prediction shape: \", pred.shape) \nprint(\"scalar_loss:      \", example_batch_loss.numpy().mean())","66ee7852":"### Hyperparameter setting and optimization ###\n\n# Optimization parameters:\nnum_training_iterations = 2000  \nbatch_size = 4 \nseq_length = 100  \nlearning_rate = 5e-3 \n\n# Model parameters: \nvocab_size = len(vocab)\nembedding_dim = 256 \nrnn_units = 1024  \n\n# Checkpoint location: \nimport os\n#os.mkdir(\"\/kaggle\/working\/checkpoint\")\ncheckpoint_prefix = os.path.join(\"\/kaggle\/working\/checkpoint\", \"my_ckpt\")","19e80c14":"def display_model(model):\n  tf.keras.utils.plot_model(model,\n             to_file='tmp.png',\n             show_shapes=True)\n  return ipythondisplay.Image('tmp.png')\n\n\ndef plot_sample(x,y,vae):\n    plt.figure(figsize=(2,1))\n    plt.subplot(1, 2, 1)\n\n    idx = np.where(y==1)[0][0]\n    plt.imshow(x[idx])\n    plt.grid(False)\n\n    plt.subplot(1, 2, 2)\n    _, _, _, recon = vae(x)\n    recon = np.clip(recon, 0, 1)\n    plt.imshow(recon[idx])\n    plt.grid(False)\n\n    plt.show()\n\n\n\nclass LossHistory:\n  def __init__(self, smoothing_factor=0.0):\n    self.alpha = smoothing_factor\n    self.loss = []\n  def append(self, value):\n    self.loss.append( self.alpha*self.loss[-1] + (1-self.alpha)*value if len(self.loss)>0 else value )\n  def get(self):\n    return self.loss\n\nclass PeriodicPlotter:\n  def __init__(self, sec, xlabel='', ylabel='', scale=None):\n\n    self.xlabel = xlabel\n    self.ylabel = ylabel\n    self.sec = sec\n    self.scale = scale\n\n    self.tic = time.time()\n\n  def plot(self, data):\n    if time.time() - self.tic > self.sec:\n      plt.cla()\n\n      if self.scale is None:\n        plt.plot(data)\n      elif self.scale == 'semilogx':\n        plt.semilogx(data)\n      elif self.scale == 'semilogy':\n        plt.semilogy(data)\n      elif self.scale == 'loglog':\n        plt.loglog(data)\n      else:\n        raise ValueError(\"unrecognized parameter scale {}\".format(self.scale))\n\n      plt.xlabel(self.xlabel); plt.ylabel(self.ylabel)\n      ipythondisplay.clear_output(wait=True)\n      ipythondisplay.display(plt.gcf())\n\n      self.tic = time.time()\n","dfab2360":"### Define optimizer and training operation ###\n\nmodel = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate)\n\n@tf.function\ndef train_step(x, y): \n  with tf.GradientTape() as tape:\n  \n    \n    y_hat = model(x) \n      \n    \n    loss = compute_loss(y, y_hat) \n  grads = tape.gradient(loss, model.trainable_variables) \n  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n  return loss\n\nhistory = []\nplotter = PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\nif hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n\nfor iter in tqdm(range(num_training_iterations)):\n\n  # Grab a batch and propagate it through the network\n  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n  loss = train_step(x_batch, y_batch)\n\n  # Update the progress bar\n  history.append(loss.numpy().mean())\n  plotter.plot(history)","6c97680d":"  # Update the model with the changed weights!\n  if iter % 100 == 0:     \n    model.save_weights(checkpoint_prefix)\n    \n# Save the trained model and the weights\nmodel.save_weights(checkpoint_prefix)","420f0f9d":"### Prediction of a generated song ###\n\ndef generate_text(model, start_string, generation_length=1000):\n  # Evaluation step (generating ABC text using the learned RNN model)\n\n  input_eval = [char2idx[s] for s in start_string]\n  input_eval = tf.expand_dims(input_eval, 0)\n\n  # Empty string to store our results\n  text_generated = []\n\n  # Here batch size == 1\n  model.reset_states()\n  tqdm._instances.clear()\n\n  for i in tqdm(range(generation_length)):\n      \n      predictions = model(input_eval)\n      \n      predictions = tf.squeeze(predictions, 0)\n      \n      \n      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n      \n      input_eval = tf.expand_dims([predicted_id], 0)\n      \n      \n      text_generated.append(idx2char[predicted_id]) \n    \n  return (start_string + ''.join(text_generated))","a4c3b836":"model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1) \n# Restore the model weights for the last checkpoint after training\nmodel.load_weights(checkpoint_prefix)\nmodel.build(tf.TensorShape([1, None]))\n\nmodel.summary()","9c7735e7":"generated_text = generate_text(model, start_string=\"X\", generation_length=1000) ","9874f646":"def extract_song_snippet(text):\n    pattern = '(^|\\n\\n)(.*?)\\n\\n'\n    search_results = re.findall(pattern, text, overlapped=True, flags=re.DOTALL)\n    songs = [song[1] for song in search_results]\n    print(\"Found {} songs in text\".format(len(songs)))\n    return songs","f79318ae":"generated_songs = extract_song_snippet(generated_text)","2e2b0492":"### Play back generated songs ###\n\ndef play_generated_song(generated_text):\n    songs = extract_song_snippet(generated_text)\n    if len(songs) == 0:\n        print(\"No valid songs found in generated text. Try training the \\\n            model longer or increasing the amount of generated music to \\\n            ensure complete songs are generated!\")\n\n    for song in songs:\n        play_song(song)\n    print(\"None of the songs were valid, try training longer to improve \\\n        syntax.\")\n\nfor i, song in enumerate(generated_songs): \n  # Synthesize the waveform from a song\n  waveform = play_song(song)\n\n  if waveform:\n    print(\"Generated song\", i)\n    ipythondisplay.display(waveform)","e16ba0f3":"### Predictions from the untrained model","9a5e617d":"\n## Importing dependencies\n\nFirst let us install and import all the modules and packages that will be required.\n","2b77f73e":"## Loading Dataset\n\nThe dataset of thousands of 8207 songs, represented in the ABC notation.","6b38cbd2":"## Training the model","07339980":"### Create training examples and targets\n\nDivide the text into example sequences that we'll use during training. Also, define a target sequence for each input sequence, which will be used in training the RNN to predict the next character. For each input, the corresponding target will contain the same length of text, except shifted one character to the right.\nThe batch method is used to convert the stream of character indices to sequences of the desired size.","c02671da":"One important thing to think about is that this notation of music does not simply contain information on the notes being played, but additionally there is meta information such as the song title, key, and tempo. ","56236fa1":"## Generate song","ff4a549a":"## Define the RNN model\n","3fea9fd4":"## Overview\n\nThis script uses the dataset containing music in anc notation, preprocesses it and uses it to train a RNN-LSTM model ","09fe3678":"## Preprocess the dataset \n\n### Vectorize the text\n\nCreate a numerical representation of this text-based dataset by mapping characters to numbers, and mapping numbers back to characters. ","3e8a9e98":"The generated song `tmp.abc` can be converted into wav format and played."}}