{"cell_type":{"3e160aa4":"code","16d9f8e9":"code","a8d5c0dc":"code","d966ef01":"code","14217b07":"code","0a71bfaa":"code","8f94eb08":"code","b85f285e":"code","1aeab268":"code","870a12b3":"code","af61c2dd":"code","c70e1ffc":"code","e1b97c49":"code","234f8278":"markdown","5a0e4ecb":"markdown","eb12fff4":"markdown"},"source":{"3e160aa4":"!pip install -U tensorflow-addons","16d9f8e9":"import pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nimport os\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import callbacks","a8d5c0dc":"#Trying to get reproducible results\nfrom numpy.random import seed\nseed(42)\nfrom tensorflow.random import set_seed\nset_seed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)","d966ef01":"df_train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv').drop('id', axis = 1)\ndf_train['target'] = df_train['target'].str.slice(start=6).astype(int) - 1\n\ny_train = df_train['target'].copy()\nX_train = df_train.copy().drop('target', axis = 1)\n\nX_test = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv').drop('id', axis = 1)","14217b07":"#Converting target series to matrix for multiclass classification on Keras\n\nY_train = to_categorical(y_train)\nY_train","0a71bfaa":"def get_model(X_train, n_classes = 9):\n    inputs = layers.Input(shape = (X_train.shape[1],))\n    \n    embed = layers.Embedding(360, 8)(inputs)\n    embed = layers.Flatten()(embed)\n    \n    hidden = layers.Dropout(0.2)(embed)\n    hidden = tfa.layers.WeightNormalization(layers.Dense(units=128, activation='selu', kernel_initializer=\"lecun_normal\"))(hidden)\n    \n    output = layers.Dropout(0.2)(layers.Concatenate()([embed, hidden]))\n    output = tfa.layers.WeightNormalization(layers.Dense(units=64, activation='relu'))(output) \n    \n    output = layers.Dropout(0.3)(layers.Concatenate()([embed, hidden, output]))\n    output = tfa.layers.WeightNormalization(layers.Dense(units=32, activation='elu'))(output) \n    output = layers.Dense(n_classes, activation = 'softmax')(output)\n    \n    model = keras.Model(inputs=inputs, outputs=output, name=\"res_nn_model\")\n    \n    return model","8f94eb08":"K.clear_session()\ncce = keras.losses.CategoricalCrossentropy(name = 'cat_crossentr')\n\ndef custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = cce(y_true, y_pred)\n    return loss","b85f285e":"OOF_PRED = np.zeros((X_train.shape[0], 9))\nTEST_PRED = np.zeros((X_test.shape[0], 9))\nN_starts = 10\nfor i in range(N_starts):\n    N = 10\n    kf = StratifiedKFold(n_splits=N, shuffle=True, random_state=13 + i)\n\n    for FOLD, (trn_idx, val_idx) in enumerate(kf.split(y_train, y_train)):\n        X_tr, y_tr = X_train.iloc[trn_idx, :], Y_train[trn_idx, :]\n        X_val, y_val = X_train.iloc[val_idx, :], Y_train[val_idx, :]\n\n        K.clear_session()\n        model = get_model(X_tr)\n        model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=2e-4), metrics=custom_metric)\n\n        early_stopping = callbacks.EarlyStopping(patience=10, min_delta=1e-5, restore_best_weights=True)\n        plateau = callbacks.ReduceLROnPlateau(factor = 0.7, patience = 2, verbose = 0) \n\n        model.fit(X_tr, y_tr,\n              batch_size = 256, epochs = 100,\n              validation_data=(X_val, y_val),\n              callbacks=[early_stopping, plateau],\n              verbose = 0)\n\n        pred = model.predict(X_val)\n        OOF_PRED[val_idx, :] += pred \/ N_starts\n        TEST_PRED += model.predict(X_test) \/ N \/ N_starts\n\n        nn_logloss = log_loss(y_train[val_idx], pred)\n\n        print(f\"START {i:d} FOLD {FOLD:d}: logloss score {nn_logloss:.6f}\")\n\n        del model\n        _ = gc.collect()\n\nnn_logloss = log_loss(y_train, OOF_PRED)\nprint(f\"full logloss score {nn_logloss}\")","1aeab268":"ss = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\nss","870a12b3":"ss.iloc[:, 1:] = TEST_PRED\nss","af61c2dd":"ss.to_csv('nn_predict.csv', index = False)","c70e1ffc":"oof_preds_df = pd.DataFrame(OOF_PRED, columns = ['Class_' + str(i) for i in range(1, 10)])\noof_preds_df.insert(0, 'id', list(range(oof_preds_df.shape[0])))\noof_preds_df","e1b97c49":"oof_preds_df.to_csv('OOF_nn_predict.csv', index = False)","234f8278":"## Creating and Evaluating the NN","5a0e4ecb":"## Making Predictions","eb12fff4":"### This notebook is a modified python version of [this R notebook](https:\/\/www.kaggle.com\/oxzplvifi\/tabular-residual-network) from @oxzplvifi"}}