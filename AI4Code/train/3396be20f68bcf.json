{"cell_type":{"8d5c7172":"code","b1bc1ec6":"code","222f3c7d":"code","c1dc4ab7":"code","057397a7":"code","1ae5033b":"code","51d9f97b":"code","13792b7a":"code","422c2f29":"code","92f99990":"code","4d39c896":"code","572e62ff":"code","127bad98":"code","8cacfb31":"code","4a4bdc4b":"code","8454a68a":"code","4b16625b":"code","f6ef5f78":"code","80a1d84d":"code","18e05911":"code","2a4cfe4b":"code","eaf88238":"code","3ae9f42c":"code","f1d1f216":"code","8db06818":"code","2b25cb6c":"code","03dc80e2":"code","6f42a44e":"code","97957597":"code","46a02fb3":"code","a34b6593":"code","19ca56af":"code","3d168329":"code","6b7aa73b":"code","4f988bf7":"code","95b2ad3d":"code","4df9afb0":"code","31a6b6a0":"code","a93b45cc":"code","e8005941":"code","9a982394":"code","4982a222":"code","4744f646":"code","13ffa981":"code","39c352f0":"code","30f14b0a":"code","16dd30a7":"code","4c0ba8e4":"code","6170e27c":"code","4897fdc3":"code","e1c281ba":"code","c62dd65d":"code","d15c6f4a":"code","5e2a4f8f":"code","8fc88c59":"code","3929eb15":"markdown","7512552a":"markdown","ec7a28ac":"markdown","409bb206":"markdown","0bd777e7":"markdown","21641b11":"markdown","a0aa61fc":"markdown","efb36f76":"markdown","5bb43f3c":"markdown","32dfc14c":"markdown","a41799ad":"markdown","b4c12931":"markdown","13df5bb3":"markdown","b5ca1819":"markdown","aff062c1":"markdown"},"source":{"8d5c7172":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b1bc1ec6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","222f3c7d":"raw_data = pd.read_csv('\/kaggle\/input\/fang-stocks-15-year-data\/SPY_ALL_15years.csv')","c1dc4ab7":"raw_data.head()","057397a7":"raw_data.describe(include = 'all')","1ae5033b":"raw_data.isnull().sum()","51d9f97b":"data_cleaned = raw_data.drop(['symbol','date'], axis = 1)","13792b7a":"pd.set_option('display.float_format', lambda x: '%.3f' % x)","422c2f29":"data_cleaned.describe(include = 'all')","92f99990":"data_cleaned.columns","4d39c896":"sns.distplot(data_cleaned['close'])","572e62ff":"q = data_cleaned['close'].quantile(0.01)\ndata_1 = data_cleaned[data_cleaned['close']>q]\ndata_1.describe(include = 'all')","127bad98":"sns.distplot(data_1['BB'])","8cacfb31":"q = data_1['BB'].quantile(0.01)\ndata_2 = data_1[data_1['BB']>q]\ndata_2.describe(include = 'all')","4a4bdc4b":"sns.distplot(data_2['OBV'])","8454a68a":"q = data_2['OBV'].quantile(0.01)\ndata_3 = data_2[data_2['OBV']>q]\ndata_3.describe(include = 'all')","4b16625b":"sns.distplot(data_3['OBV'])","f6ef5f78":"sns.distplot(data_3['exponentialmovingaverage'])","80a1d84d":"q = data_3['OBV'].quantile(0.01)\ndata_4 = data_3[data_3['OBV']>q]\ndata_4.describe(include = 'all')","18e05911":"sns.distplot(data_4['exponentialmovingaverage'])","2a4cfe4b":"sns.distplot(data_4['MACD'])","eaf88238":"q = data_4['MACD'].quantile(0.01)\ndata_5 = data_4[data_4['MACD']>q]\ndata_5.describe(include = 'all')","3ae9f42c":"sns.distplot(data_5['MACD'])","f1d1f216":"sns.distplot(data_5['RSI'])","8db06818":"q = data_5['RSI'].quantile(0.01)\ndata_6 = data_5[data_5['RSI']>q]\ndata_6.describe(include = 'all')","2b25cb6c":"sns.distplot(data_6['RSI'])","03dc80e2":"sns.distplot(data_6['AD'])","6f42a44e":"q = data_6['RSI'].quantile(0.01)\ndata_7 = data_6[data_6['RSI']>q]\ndata_7.describe(include = 'all')","97957597":"sns.distplot(data_7['AD'])","46a02fb3":"sns.distplot(data_7['ADX'])","a34b6593":"q = data_7['ADX'].quantile(0.01)\ndata_8 = data_7[data_7['ADX']>q]\ndata_8.describe(include = 'all')","19ca56af":"sns.distplot(data_8['ADX'])","3d168329":"sns.distplot(data_8['aroonoscillator'])","6b7aa73b":"q = data_8['aroonoscillator'].quantile(0.01)\ndata_9 = data_8[data_8['aroonoscillator']>q]\ndata_9.describe(include = 'all')","4f988bf7":"sns.distplot(data_9['aroonoscillator'])","95b2ad3d":"sns.distplot(data_9['SMA'])","4df9afb0":"q = data_9['SMA'].quantile(0.01)\ndata_10 = data_9[data_9['SMA']>q]\ndata_10.describe(include = 'all')","31a6b6a0":"sns.distplot(data_10['SMA'])","a93b45cc":"sns.distplot(data_10['MFI'])","e8005941":"q = data_10['MFI'].quantile(0.01)\ndata_11 = data_10[data_10['aroonoscillator']>q]\ndata_11.describe(include = 'all')","9a982394":"sns.distplot(data_11['MFI'])","4982a222":"data_cleaned = data_11.reset_index(drop = True)","4744f646":"data_cleaned.describe(include = 'all')","13ffa981":"data_cleaned = data_cleaned.reset_index(drop = True)","39c352f0":"data_cleaned.describe(include = 'all')","30f14b0a":"data_cleaned.columns","16dd30a7":"data_cleaned = data_cleaned.astype(np.int64)","4c0ba8e4":"data_cleaned.dtypes","6170e27c":"import statsmodels.formula.api as smf\n\ndf = data_cleaned.astype('float64')\n\ndf.drop(['open','high','low'], axis = 1)\n\nprint(df.columns)\n\nsns.pairplot(df, x_vars=['OBV', 'averagegain', 'averageloss'], y_vars='close', height=7, aspect=0.7)\n\nsns.pairplot(df, x_vars=['BB','lowerband', 'middleband', 'upperband','standarddeviation'], y_vars='close', height=7, aspect=0.7)\n\nsns.pairplot(df, x_vars=['RSI','AD', 'MFI'], y_vars='close', height=7, aspect=0.7)\n\nsns.pairplot(df, x_vars=['ADX','negativedirectionalindex', 'positivedirectionalindex', 'aroonoscillator'], y_vars='close', height=7, aspect=0.7)\n\nsns.pairplot(df, x_vars=['exponentialmovingaverage','SMA', 'rollingsum'], y_vars='close', height=7, aspect=0.7)\n\nsns.pairplot(df, x_vars=['MACD','fast', 'slow', 'histogram','signal'], y_vars='close', height=7, aspect=0.7)\n\n\n\n'BB','lowerband','middleband',''\n### STATSMODELS ###\n\n# create a fitted model\nlm1 = smf.ols(formula='volume ~ standarddeviation', data=df).fit()\n\n# print the coefficients\nlm1.params","4897fdc3":"\n#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['MACD']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs volume Targets', size = 10)\nplt.ylabel('close vs volume Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()\n\n#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['RSI']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs volume Targets', size = 10)\nplt.ylabel('close vs volume Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()\n\n#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['ADX']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs volume Targets', size = 10)\nplt.ylabel('close vs volume Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()\n\n#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['MFI']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs MFI Targets', size = 10)\nplt.ylabel('close vs MFI Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()\n\n#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['aroonoscillator']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs volume Targets', size = 10)\nplt.ylabel('close vs volume Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()","e1c281ba":"#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['OBV']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs OBV Targets', size = 10)\nplt.ylabel('close vs OBV Predictions', size = 10)\n\nprint('Model Score:', regressor.score(X,y))\nplt.show()","c62dd65d":"#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['OBV', 'AD']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs OBV ~ AD Targets', size = 10)\nplt.ylabel('close vs OBV ~ AD Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()","d15c6f4a":"#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['OBV', 'AD', 'BB']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs OBV ~ AD ~ BB Targets', size = 10)\nplt.ylabel('close vs OBV ~ AD ~ BB Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()","5e2a4f8f":"#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['OBV', 'AD', 'BB', 'SMA']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs OBV ~ AD ~ BB ~ SMA Targets', size = 10)\nplt.ylabel('close vs OBV ~ AD ~ BB ~ SMA Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()","8fc88c59":"#Creating the independent vector\nX = df[['close']]\n#Creating the dependent vector\ny = df[['OBV', 'AD', 'BB', 'SMA', 'exponentialmovingaverage']]\n#Printing the two vectors\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n\n#Splitting the dataset into training and testing dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.9, random_state = 50)\n\nregressor = LinearRegression()\nregressor.fit(X,y)\n\ny_hat_test = regressor.predict(X_test)\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('close vs OBV ~ AD ~ BB ~ SMA ~ EMA Targets', size = 10)\nplt.ylabel('close vs OBV ~ AD ~ BB ~ SMA ~ EMA Predictions', size = 10)\n\nprint(regressor.score(X,y))\nplt.show()","3929eb15":"# Linear Regression Model","7512552a":"# Now we can easily see which Indicators have heavy correlation to close price and those that dont.\n\n# Usefull Indicators: \n\n# - Bollinger Bands (BB) \n# - Accumulation\/Distribution (AD)\n# - Exponential Moving Average (EMA)\n# - Simple Moving Average (SMA)\n# - On Balance Volume (OBV)\n\n# Useless Indicators: \n\n# - Moving Average Convergance (MACD)\n# - Average Directional Movement Index (ADX)\n# - Money Flow Index (MFI)\n# - Relative Strength Index (RSI)\n# - Aroon Oscillator (AO)","ec7a28ac":"# Exploring the PDFs and trying to achieve a Normal Distribution","409bb206":"__________________________________________________________________","0bd777e7":"__________________________________________________________________","21641b11":"__________________________________________________________________","a0aa61fc":"# - On Balance Volume (OBV)\n\n# - Accumulation\/Distribution (AD)\n\n# - Bollinger Bands (BB)\n\n# - Simple Moving Average (SMA)\n\n# - Exponential Moving Average (EMA)","efb36f76":"# Using 'usefull' indicators as inputs into the regression model","5bb43f3c":"__________________________________________________________________","32dfc14c":"# Using 'useless' Indicators within a linear Regression Model","a41799ad":"# - On Balance Volume (OBV)\n\n# - Accumulation\/Distribution (AD)\n\n# - Bollinger Bands (BB)","b4c12931":"\n# - On Balance Volume (OBV)\n\n# - Accumulation\/Distribution (AD)\n\n# - Bollinger Bands (BB)\n\n# - Simple Moving Average (SMA)","13df5bb3":"\n# - On Balance Volume (OBV)","b5ca1819":"# - On Balance Volume (OBV)\n\n# - Accumulation\/Distribution (AD)","aff062c1":"# Understanding the indicator linear correlation to price"}}