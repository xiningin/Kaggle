{"cell_type":{"7f9f395d":"code","7d61e44b":"code","97509d40":"code","bf914740":"code","0b189a1e":"code","02f2aac2":"code","715a1b49":"code","108bddcc":"code","421e6f05":"code","34c3e780":"code","98874e94":"code","b58b3620":"code","b8c11ab9":"code","5226c7bb":"code","ec8f1bf4":"code","39632739":"code","1fab51db":"markdown","bdb95296":"markdown","2bf73dd1":"markdown","bff42422":"markdown","1e4ae23b":"markdown","bd17cd43":"markdown","a1997e56":"markdown","5b3b55c5":"markdown","a9e5a554":"markdown"},"source":{"7f9f395d":"!pip install '\/kaggle\/input\/pytorch-lightning142\/pytorch_lightning-1.4.2-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/pytorchimagemodels\/pytorch-image-models-master' --no-deps","7d61e44b":"import os\nfrom os import walk\nimport cv2\nimport pickle\nimport shutil\nimport torchmetrics\nimport timm\nimport pandas as pd\n\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy","97509d40":"class ICPModel(pl.LightningModule):\n    def __init__(self,\n                 model_type,\n                 num_classes,\n                 classes_weights,\n                 learning_rate=0.0001):\n        super().__init__()\n\n        # log hyperparameters\n        self.save_hyperparameters()\n\n        self.learning_rate = learning_rate\n        self.num_classes = num_classes\n        self.model_type = model_type\n\n        # load network\n        if self.model_type in ['densenet121',  # classifier\n                               'densenet161',\n                               'densenet169',\n                               'densenet201',\n                               'densenetblur121d',\n                               'efficientnet_b0',\n                               'efficientnet_b1',\n                               'efficientnet_b1_pruned',\n                               'efficientnet_b2',\n                               'efficientnet_b2a',\n                               'efficientnet_b3',\n                               'efficientnet_b3_pruned',\n                               'efficientnet_b3a',\n                               'efficientnet_em',\n                               'efficientnet_es',\n                               'efficientnet_lite0',\n                               'fbnetc_100',\n                               'hrnet_w18',\n                               'hrnet_w18_small',\n                               'hrnet_w18_small_v2',\n                               'hrnet_w30',\n                               'hrnet_w32',\n                               'hrnet_w40',\n                               'hrnet_w44',\n                               'hrnet_w48',\n                               'hrnet_w64',\n                               'mixnet_l',\n                               'mixnet_m',\n                               'mixnet_s',\n                               'mixnet_xl',\n                               'mnasnet_100',\n                               'mobilenetv2_100',\n                               'mobilenetv2_110d',\n                               'mobilenetv2_120d',\n                               'mobilenetv2_140',\n                               'mobilenetv3_large_100',\n                               'mobilenetv3_rw',\n                               'semnasnet_100',\n                               'spnasnet_100',\n                               'tf_efficientnet_b0',\n                               'tf_efficientnet_b0_ap',\n                               'tf_efficientnet_b0_ns',\n                               'tf_efficientnet_b1',\n                               'tf_efficientnet_b1_ap',\n                               'tf_efficientnet_b1_ns',\n                               'tf_efficientnet_b2',\n                               'tf_efficientnet_b2_ap',\n                               'tf_efficientnet_b2_ns',\n                               'tf_efficientnet_b3',\n                               'tf_efficientnet_b3_ap',\n                               'tf_efficientnet_b3_ns',\n                               'tf_efficientnet_b4',\n                               'tf_efficientnet_b4_ap',\n                               'tf_efficientnet_b4_ns',\n                               'tf_efficientnet_b5',\n                               'tf_efficientnet_b5_ap',\n                               'tf_efficientnet_b5_ns',\n                               'tf_efficientnet_b6',\n                               'tf_efficientnet_b6_ap',\n                               'tf_efficientnet_b6_ns',\n                               'tf_efficientnet_b7',\n                               'tf_efficientnet_b7_ap',\n                               'tf_efficientnet_b7_ns',\n                               'tf_efficientnet_b8',\n                               'tf_efficientnet_b8_ap',\n                               'tf_efficientnet_cc_b0_4e',\n                               'tf_efficientnet_cc_b0_8e',\n                               'tf_efficientnet_cc_b1_8e',\n                               'tf_efficientnet_el',\n                               'tf_efficientnet_em',\n                               'tf_efficientnet_es',\n                               'tf_efficientnet_l2_ns',\n                               'tf_efficientnet_l2_ns_475',\n                               'tf_efficientnet_lite0',\n                               'tf_efficientnet_lite1',\n                               'tf_efficientnet_lite2',\n                               'tf_efficientnet_lite3',\n                               'tf_efficientnet_lite4',\n                               'tf_mixnet_l',\n                               'tf_mixnet_m',\n                               'tf_mixnet_s',\n                               'tf_mobilenetv3_large_075',\n                               'tf_mobilenetv3_large_100',\n                               'tf_mobilenetv3_large_minimal_100',\n                               'tf_mobilenetv3_small_075',\n                               'tf_mobilenetv3_small_100',\n                               'tf_mobilenetv3_small_minimal_100',\n                               'tv_densenet121',\n                               'tf_efficientnetv2_b0',\n                               'tf_efficientnetv2_l',\n                               'eca_efficientnet_b0',\n                               'efficientnet_b2_pruned',\n                               'efficientnet_b4',\n                               'efficientnet_b5',\n                               'efficientnet_b6',\n                               'efficientnet_b7',\n                               'efficientnet_b8',\n                               'efficientnet_cc_b0_4e',\n                               'efficientnet_cc_b0_8e',\n                               'efficientnet_cc_b1_8e',\n                               'efficientnet_el',\n                               'efficientnet_el_pruned',\n                               'efficientnet_es_pruned',\n                               'efficientnet_l2',\n                               'efficientnet_lite1',\n                               'efficientnet_lite2',\n                               'efficientnet_lite3',\n                               'efficientnet_lite4',\n                               'efficientnetv2_l',\n                               'efficientnetv2_m',\n                               'efficientnetv2_rw_m',\n                               'efficientnetv2_rw_s',\n                               'efficientnetv2_s',\n                               'gc_efficientnet_b0',]:\n            model = timm.create_model(model_type, pretrained=True)\n            in_features = model.classifier.in_features\n            model.classifier = nn.Linear(in_features, self.num_classes)\n            self.model = model\n        elif self.model_type in ['adv_inception_v3',  # fc\n                                 'ecaresnet26t',\n                                 'ecaresnet50d',\n                                 'ecaresnet50d_pruned',\n                                 'ecaresnet50t',\n                                 'ecaresnet101d',\n                                 'ecaresnet101d_pruned',\n                                 'ecaresnet269d',\n                                 'ecaresnetlight',\n                                 'gluon_inception_v3',\n                                 'gluon_resnet18_v1b',\n                                 'gluon_resnet34_v1b',\n                                 'gluon_resnet50_v1b',\n                                 'gluon_resnet50_v1c',\n                                 'gluon_resnet50_v1d',\n                                 'gluon_resnet50_v1s',\n                                 'gluon_resnet101_v1b',\n                                 'gluon_resnet101_v1c',\n                                 'gluon_resnet101_v1d',\n                                 'gluon_resnet101_v1s',\n                                 'gluon_resnet152_v1b',\n                                 'gluon_resnet152_v1c',\n                                 'gluon_resnet152_v1d',\n                                 'gluon_resnet152_v1s',\n                                 'gluon_resnext50_32x4d',\n                                 'gluon_resnext101_32x4d',\n                                 'gluon_resnext101_64x4d',\n                                 'gluon_senet154',\n                                 'gluon_seresnext50_32x4d',\n                                 'gluon_seresnext101_32x4d',\n                                 'gluon_seresnext101_64x4d',\n                                 'gluon_xception65',\n                                 'ig_resnext101_32x8d',\n                                 'ig_resnext101_32x16d',\n                                 'ig_resnext101_32x32d',\n                                 'ig_resnext101_32x48d',\n                                 'inception_v3',\n                                 'res2net50_14w_8s',\n                                 'res2net50_26w_4s',\n                                 'res2net50_26w_6s',\n                                 'res2net50_26w_8s',\n                                 'res2net50_48w_2s',\n                                 'res2net101_26w_4s',\n                                 'res2next50',\n                                 'resnest14d',\n                                 'resnest26d',\n                                 'resnest50d',\n                                 'resnest50d_1s4x24d',\n                                 'resnest50d_4s2x40d',\n                                 'resnest101e',\n                                 'resnest200e',\n                                 'resnest269e',\n                                 'resnet18',\n                                 'resnet18d',\n                                 'resnet26',\n                                 'resnet26d',\n                                 'resnet34',\n                                 'resnet34d',\n                                 'resnet50',\n                                 'resnet50d',\n                                 'resnet101d',\n                                 'resnet152d',\n                                 'resnet200d',\n                                 'resnetblur50',\n                                 'resnext50_32x4d',\n                                 'resnext50d_32x4d',\n                                 'resnext101_32x8d',\n                                 'selecsls42b',\n                                 'selecsls60',\n                                 'selecsls60b',\n                                 'seresnet50',\n                                 'seresnet152d',\n                                 'seresnext26d_32x4d',\n                                 'seresnext26t_32x4d',\n                                 'seresnext50_32x4d',\n                                 'skresnet18',\n                                 'skresnet34',\n                                 'skresnext50_32x4d',\n                                 'ssl_resnet18',\n                                 'ssl_resnet50',\n                                 'ssl_resnext50_32x4d',\n                                 'ssl_resnext101_32x4d',\n                                 'ssl_resnext101_32x8d',\n                                 'ssl_resnext101_32x16d',\n                                 'swsl_resnet18',\n                                 'swsl_resnet50',\n                                 'swsl_resnext50_32x4d',\n                                 'swsl_resnext101_32x4d',\n                                 'swsl_resnext101_32x8d',\n                                 'swsl_resnext101_32x16d',\n                                 'tf_inception_v3',\n                                 'tv_resnet34',\n                                 'tv_resnet50',\n                                 'tv_resnet101',\n                                 'tv_resnet152',\n                                 'tv_resnext50_32x4d',\n                                 'wide_resnet50_2',\n                                 'wide_resnet101_2',\n                                 'xception', ]:\n            model = timm.create_model(model_type, pretrained=True)\n            in_features = model.fc.in_features\n            model.classifier = nn.Linear(in_features, self.num_classes)\n            self.model = model\n        elif self.model_type in ['dla34',\n                                 'dla46_c',\n                                 'dla46x_c',\n                                 'dla60',\n                                 'dla60_res2net',\n                                 'dla60_res2next',\n                                 'dla60x',\n                                 'dla60x_c',\n                                 'dla102',\n                                 'dla102x',\n                                 'dla102x2',\n                                 'dla169',\n                                 'dpn68',\n                                 'dpn68b',\n                                 'dpn92',\n                                 'dpn98',\n                                 'dpn107',\n                                 'dpn131',\n                                 ]:\n            model = timm.create_model(model_type, pretrained=True)\n            if self.model_type == 'dla34':\n                model.fc = nn.Conv2d(512, self.num_classes, kernel_size=(1, 1), stride=(1, 1))\n            elif self.model_type in ['dla46_c',\n                                     'dla46x_c',\n                                     'dla60x_c', ]:\n                model.fc = nn.Conv2d(256, self.num_classes, kernel_size=(1, 1), stride=(1, 1))\n            elif self.model_type in ['dla60',\n                                     'dla60_res2net',\n                                     'dla60_res2next',\n                                     'dla60x',\n                                     'dla102',\n                                     'dla102x',\n                                     'dla102x2',\n                                     'dla169']:\n                model.fc = nn.Conv2d(1024, self.num_classes, kernel_size=(1, 1), stride=(1, 1))\n            elif self.model_type in ['dpn68', 'dpn68b', ]:\n                model.fc = nn.Conv2d(832, self.num_classes, kernel_size=(1, 1), stride=(1, 1))\n            elif self.model_type in ['dpn92', 'dpn98', 'dpn107', 'dpn131', ]:\n                model.fc = nn.Conv2d(2688, self.num_classes, kernel_size=(1, 1), stride=(1, 1))\n            self.model = model\n        elif self.model_type in ['cspdarknet53',  # head.fc\n                                 'cspresnet50',\n                                 'cspresnext50',\n                                 'dm_nfnet_f0',\n                                 'dm_nfnet_f1',\n                                 'dm_nfnet_f2',\n                                 'dm_nfnet_f3',\n                                 'dm_nfnet_f4',\n                                 'dm_nfnet_f5',\n                                 'dm_nfnet_f6',\n                                 'ese_vovnet19b_dw',\n                                 'ese_vovnet39b',\n                                 'gernet_l',\n                                 'gernet_m',\n                                 'gernet_s',\n                                 'nf_regnet_b1',\n                                 'nf_resnet50',\n                                 'nfnet_l0c',\n                                 'regnetx_002',\n                                 'regnetx_004',\n                                 'regnetx_006',\n                                 'regnetx_008',\n                                 'regnetx_016',\n                                 'regnetx_032',\n                                 'regnetx_040',\n                                 'regnetx_064',\n                                 'regnetx_080',\n                                 'regnetx_120',\n                                 'regnetx_160',\n                                 'regnetx_320',\n                                 'regnety_002',\n                                 'regnety_004',\n                                 'regnety_006',\n                                 'regnety_008',\n                                 'regnety_016',\n                                 'regnety_032',\n                                 'regnety_040',\n                                 'regnety_064',\n                                 'regnety_080',\n                                 'regnety_120',\n                                 'regnety_160',\n                                 'regnety_320',\n                                 'repvgg_a2',\n                                 'repvgg_b0',\n                                 'repvgg_b1',\n                                 'repvgg_b1g4',\n                                 'repvgg_b2',\n                                 'repvgg_b2g4',\n                                 'repvgg_b3',\n                                 'repvgg_b3g4',\n                                 'resnetv2_50x1_bitm',\n                                 'resnetv2_50x1_bitm_in21k',\n                                 'resnetv2_50x3_bitm',\n                                 'resnetv2_50x3_bitm_in21k',\n                                 'resnetv2_101x1_bitm',\n                                 'resnetv2_101x1_bitm_in21k',\n                                 'resnetv2_101x3_bitm',\n                                 'resnetv2_101x3_bitm_in21k',\n                                 'resnetv2_152x2_bitm',\n                                 'resnetv2_152x2_bitm_in21k',\n                                 'resnetv2_152x4_bitm',\n                                 'resnetv2_152x4_bitm_in21k',\n                                 'rexnet_100',\n                                 'rexnet_130',\n                                 'rexnet_150',\n                                 'rexnet_200',\n                                 'tresnet_l',\n                                 'tresnet_l_448',\n                                 'tresnet_m',\n                                 'tresnet_m_448',\n                                 'tresnet_xl',\n                                 'tresnet_xl_448',\n                                 'vgg11',\n                                 'vgg11_bn',\n                                 'vgg13',\n                                 'vgg13_bn',\n                                 'vgg16',\n                                 'vgg16_bn',\n                                 'vgg19',\n                                 'vgg19_bn',\n                                 'xception41',\n                                 'xception65',\n                                 'xception71', ]:\n            model = timm.create_model(model_type, pretrained=True)\n            in_features = model.head.fc.in_features\n            model.classifier = nn.Linear(in_features, self.num_classes)\n            self.model = model\n        elif self.model_type in ['deit_base_distilled_patch16_224']:\n            model = timm.create_model(model_type, pretrained=True)\n            in_features_head = model.head.in_features\n            in_features_head_dist = model.head_dist.in_features\n            model.head = nn.Linear(in_features_head, self.num_classes)\n            model.head_dist = nn.Linear(in_features_head_dist, self.num_classes)\n            print(model)\n            self.model = model\n        elif self.model_type in ['ens_adv_inception_resnet_v2',  # classif\n                                 'inception_resnet_v2', ]:\n            model = timm.create_model(model_type, pretrained=True)\n            in_features = model.classif.in_features\n            model.classifier = nn.Linear(in_features, self.num_classes)\n            self.model = model\n        elif self.model_type in ['inception_v4',  # last_linear\n                                 'legacy_senet154',\n                                 'legacy_seresnet18',\n                                 'legacy_seresnet34',\n                                 'legacy_seresnet50',\n                                 'legacy_seresnet101',\n                                 'legacy_seresnet152',\n                                 'legacy_seresnext26_32x4d',\n                                 'legacy_seresnext50_32x4d',\n                                 'legacy_seresnext101_32x4d',\n                                 'nasnetalarge',\n                                 'pnasnet5large', ]:\n            model = timm.create_model(model_type, pretrained=True)\n            in_features = model.last_linear.in_features\n            model.last_linear = nn.Linear(in_features, self.num_classes)\n            self.model = model\n        elif self.model_type in ['vit_base_patch16_224',  # head\n                                 'vit_base_patch16_224_in21k',\n                                 'vit_base_patch16_384',\n                                 'vit_base_patch32_224_in21k',\n                                 'vit_base_patch32_384',\n                                 'vit_base_resnet50_224_in21k',\n                                 'vit_base_resnet50_384',\n                                 'vit_deit_base_distilled_patch16_224',\n                                 'vit_deit_base_distilled_patch16_384',\n                                 'vit_deit_base_patch16_224',\n                                 'vit_deit_base_patch16_384',\n                                 'vit_deit_small_distilled_patch16_224',\n                                 'vit_deit_small_patch16_224',\n                                 'vit_deit_tiny_distilled_patch16_224',\n                                 'vit_deit_tiny_patch16_224',\n                                 'vit_large_patch16_224',\n                                 'vit_large_patch16_224_in21k',\n                                 'vit_large_patch16_384',\n                                 'vit_large_patch32_224_in21k',\n                                 'vit_large_patch32_384',\n                                 'vit_small_patch16_224',\n                                 'cait_m36_384',\n                                 'cait_m48_448',\n                                 'cait_s24_224',\n                                 'cait_s24_384',\n                                 'cait_s36_384',\n                                 'cait_xs24_384',\n                                 'cait_xxs24_224',\n                                 'cait_xxs24_384',\n                                 'cait_xxs36_224',\n                                 'cait_xxs36_384',\n                                 'coat_lite_mini',\n                                 'coat_lite_small',\n                                 'coat_lite_tiny',\n                                 'coat_mini',\n                                 'coat_tiny',\n                                 'convit_base',\n                                 'convit_small',\n                                 'convit_tiny', ]:\n            model = timm.create_model(model_type, pretrained=True)\n            in_features = model.head.in_features\n            model.classifier = nn.Linear(in_features, self.num_classes)\n            self.model = model\n        else:\n            assert (\n                False\n            ), f\"model_type '{self.model_type}' not implemented. Please, choose from {MODELS}\"\n\n        if classes_weights:\n            self.classes_weights = torch.FloatTensor(classes_weights).cuda()\n            self.loss_func = nn.CrossEntropyLoss(weight=self.classes_weights)\n        else:\n            self.loss_func = nn.CrossEntropyLoss()\n\n#         self.f1 = torchmetrics.F1(num_classes=self.num_classes)\n\n    def loss(self, logits, labels):\n        return self.loss_func(input=logits, target=labels)\n\n    # will be used during inference\n    def forward(self, x):\n        return self.model(x)\n\n    # Using custom or multiple metrics (default_hp_metric=False)\n    def on_train_start(self):\n        self.logger.log_hyperparams(self.hparams)\n\n    # logic for a single training step\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        output = self.forward(x)\n        train_loss = self.loss(output, y)\n\n        # training metrics\n        output = torch.argmax(output, dim=1)\n        acc = accuracy(output, y)\n\n        self.log('train_loss', train_loss, prog_bar=True)\n        self.log('train_acc', acc, prog_bar=True)\n\n        return train_loss\n\n    # logic for a single validation step\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        output = self.forward(x)\n        val_loss = self.loss(output, y)\n\n        # validation metrics\n        output = torch.argmax(output, dim=1)\n        acc = accuracy(output, y)\n\n        self.log('val_loss', val_loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n\n        return val_loss\n\n    # logic for a single testing step\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        output = self(x)\n        test_loss = self.loss(output, y)\n\n        # validation metrics\n        output = torch.argmax(output, dim=1)\n        acc = accuracy(output, y)\n\n        self.log('test_loss', test_loss, prog_bar=True)\n        self.log('test_acc', acc, prog_bar=True)\n\n        return test_loss\n\n    # def training_epoch_end(self, outputs):\n    #     self.log('train_f1_epoch', self.f1.compute())\n    #     self.f1.reset()\n    #\n    # def validation_epoch_end(self, outputs):\n    #     self.log('val_f1_epoch', self.f1.compute(), prog_bar=True)\n    #     self.f1.reset()\n    #\n    # def test_epoch_end(self, outputs):\n    #     self.log('test_f1_epoch', self.f1.compute())\n    #     self.f1.reset()\n\n    def configure_optimizers(self):\n        gen_opt = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n\n        gen_sched = {'scheduler': torch.optim.lr_scheduler.ExponentialLR(gen_opt, gamma=0.999, verbose=False),\n                     'interval': 'epoch'}\n\n        return [gen_opt], [gen_sched]","bf914740":"class InferenceDataset(Dataset):\n    def __init__(self,\n                 image_ids,\n                 img_size,\n                 mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]):\n        super().__init__()\n        self.image_ids = image_ids\n        self.mean = mean\n        self.std = std\n        self.img_size = img_size\n        self.transform = A.Compose([\n            A.Normalize(mean=self.mean, std=self.std), ToTensorV2(transpose_mask=True)])\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def __getitem__(self, item):\n        image_id = str(self.image_ids[item]).split('\/')[-1].split('.')[0]\n        image = cv2.imread(self.image_ids[item], cv2.IMREAD_COLOR)\n        image = cv2.resize(image, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)\n        image = self.transform(image=image)\n        \n        return image, image_id","0b189a1e":"# import timm\n# from pprint import pprint\n\n# model = 'inception_v4'\n# m = timm.create_model(model, pretrained=True)\n# print(model)\n# pprint(m.default_cfg)","02f2aac2":"!mkdir -p \/root\/.cache\/torch\/hub\/checkpoints\/","715a1b49":"%cd \/root\/.cache\/torch\/hub\/checkpoints\/","108bddcc":"!cp \/kaggle\/input\/timm-pretrained-models-weights\/inceptionv4-8e4777a0.pth .","421e6f05":"%cd \/kaggle\/working","34c3e780":"checkpoint = '\/kaggle\/input\/inception-v4-weights\/inception_v4__epoch4_val_loss2.132_val_acc0.587.ckpt'\n# mean = [0.485, 0.456, 0.406]\n# std = [0.229, 0.224, 0.225]\nmean = [0.5, 0.5, 0.5]\nstd = [0.5, 0.5, 0.5]\nimg_size = 299\n\nmodel = ICPModel.load_from_checkpoint(checkpoint_path=checkpoint)\nmodel = model.to(\"cuda\")\nmodel.eval()\nmodel.freeze()\n\nsm = torch.nn.Softmax()","98874e94":"# get mapping from labels to landmarks\n# we created label_encoder_0_5000.pkl during training\nlabel_encoder = pickle.load(open(\"\/kaggle\/input\/inception-v4-weights\/label_encoder_0_5000.pkl\", 'rb'))","b58b3620":"# get all images paths\nimages = []\nfor dirpath, dirnames, filenames in os.walk(\"\/kaggle\/input\/landmark-recognition-2021\/test\"):\n    for filename in [f for f in filenames if f.endswith(\".jpg\")]:\n        images.append(os.path.join(dirpath, filename))","b8c11ab9":"# create dataset and dataloader\ntest_dataset = InferenceDataset(image_ids=images, img_size=img_size, mean=mean, std=std)\ntest_loader = DataLoader(test_dataset, batch_size=1)","5226c7bb":"images = [] \nresults = []\n    \nfor i, data in enumerate(tqdm(test_loader)):\n    file = data[1][0]\n    images.append(file)\n    \n    y_hat = model(data[0].get('image').to(\"cuda\"))\n    probabilities = sm(y_hat)\n    \n \n    predicted_class = torch.argmax(probabilities, dim=1)\n\n    y_hat = predicted_class.cpu().detach().numpy()[0]\n    probabilities = probabilities.cpu().detach().numpy()[0]\n\n\n    class1 = label_encoder.classes_[y_hat]\n\n    results.append(str(class1) + ' ' + str(probabilities[y_hat]))","ec8f1bf4":"df = pd.DataFrame(list(zip(images, results)), columns=['id', 'landmarks'])\ndf.to_csv('\/kaggle\/working\/submission.csv', index=None)","39632739":"df.head()","1fab51db":"<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.9em; font-weight: 350;\">Model<\/span><br>\n\nThis is a module where we define our model, loss function, optimizer, scheduler, train\/val\/test steps.<br><br>\nBelow you will see a big \"if-elif-else\" construction with models names. It's because the models have different name for their last fully-connected layer where we should change default count of classes to our.<br>\nIn some models it is called \"fc\" or \"head\" or \"classifier\". When we create model for training we will only pass  it's name and count of classes and this \"if-elif-else\" construction creates valid model for us.<br>","bdb95296":"<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.9em; font-weight: 350;\">Set parameters of our model<\/span>","2bf73dd1":"<p style='text-align: center;'><span style=\"color: #000508; font-family: Roboto; font-size: 2.2em; font-weight: 350;\"> [Inference] Inception_v4 and PyTorchn Lightning<\/span><\/p>","bff42422":"<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.9em; font-weight: 350;\">Dataset<\/span><br>\nThis is how you process a pair \"image - label\" of your dataset. ","1e4ae23b":"<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.9em; font-weight: 350;\">Predict and save results<\/span>","bd17cd43":"<br>\nIt's an example of inference Inception_v4.<br>\n\nYou can train any model using [this notebook](https:\/\/www.kaggle.com\/denispotapov\/train-inception-v4-pytorch-lightning).<br>","a1997e56":"<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.9em; font-weight: 350;\">Upload initial weights<\/span><br>","5b3b55c5":"<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.7em; font-weight: 350;\">Thank you for attention!<\/span>\n<br>\n\u200b\nIf you have some questions or suggestions you can write comments \ud83d\udcac<br>\n\u200b\n<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.3em; font-weight: 350;\">Don't give up, keep trying! \ud83d\udcaa<\/span>","a9e5a554":"<span style=\"color: #027fc1; font-family: Segoe UI; font-size: 1.7em; font-weight: 350;\">Install and Import Libraries<\/span>\n\nThere is nothing special. Install PyTorch Lightning and PyTorch Image Models.<br>"}}