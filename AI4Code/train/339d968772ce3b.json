{"cell_type":{"5f91caf2":"code","5d37c651":"code","38d5749c":"code","a1977d4f":"code","6a791628":"code","4107973f":"code","0d2c9a4f":"code","3a93e4da":"code","c4a055dd":"code","6097cab6":"code","8be8ac66":"code","caef19ae":"code","1686ab11":"code","b8014cbf":"code","ea4bc4e9":"code","9603e118":"code","d4145337":"code","d3924315":"code","8848c3ae":"code","c9f78091":"markdown","a6ff8d12":"markdown","6882b79f":"markdown","52a34c7c":"markdown","41f32d02":"markdown","bc4fb2f6":"markdown","7426ae8b":"markdown","7b99970e":"markdown","b28446e4":"markdown","c52ee019":"markdown","0e06d53d":"markdown","a0b6eab3":"markdown","a6145c96":"markdown"},"source":{"5f91caf2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d37c651":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","38d5749c":"train = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\ntest = pd.read_csv('..\/input\/mobile-price-classification\/test.csv')","a1977d4f":"train.head()","6a791628":"test.head()","4107973f":"train.shape","0d2c9a4f":"test.shape","3a93e4da":"x_train = train.iloc[:,0:-1]\nx_train.shape","c4a055dd":"y_train = train.iloc[:,-1]\ny_train.shape","6097cab6":"x_test = test.iloc[:,0:-1]\nx_test.shape","8be8ac66":"y_test = test.iloc[:,-1]\ny_test.shape","caef19ae":"from sklearn.model_selection import train_test_split\n\nx_train_1, x_test_1, y_train_1, y_test_1 =  train_test_split(x_train,y_train , random_state=1)","1686ab11":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nknn = KNeighborsClassifier(n_neighbors = 5)\n\nknn.fit(x_train_1, y_train_1)\n\nkfold = KFold(n_splits = 10)\n\nscores_1 = cross_val_score(knn, x_test_1, y_test_1, cv=kfold, scoring='accuracy');scores_1\n","b8014cbf":"scores_1.mean()","ea4bc4e9":"knn.fit(x_train, y_train)","9603e118":"kfold = KFold(n_splits = 10)\n\nscores = cross_val_score(knn, x_test, y_test, cv=kfold, scoring='accuracy');scores\n","d4145337":"scores.mean()","d3924315":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nn_esti = list(range(5,16))\nmax_dep = list(range(5,16))\n\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\nrf_param_grid = {'n_estimators' : n_esti, 'max_depth' : max_dep}\nrf_grid = GridSearchCV(estimator=rf,\n                      param_grid=rf_param_grid,\n                      scoring='accuracy',\n                      cv=4,\n                      return_train_score=True)\n\nrf_grid.fit(x_test, y_test)","8848c3ae":"rf_grid_df = pd.DataFrame(rf_grid.cv_results_)\nrf_grid_df.loc[rf_grid_df['rank_test_score'] == 1, ]","c9f78091":"# Conclusion: We can see that our this model is also giving 53% accuracy for testing data which makes it a bad model.","a6ff8d12":"# Checking Head of our Dataset","6882b79f":"# Dividing Testing data into x and y","52a34c7c":"# Based on our predictions we can see that on training data we are getting 89% accuracy while on testing data we are getting 49% and 53% as accuracy rates from two different models. This states that our model is not working great on testing data. Hence, it is a bad model.","41f32d02":"# Dividing Training data into x and y","bc4fb2f6":"# Using KNN model with CV to check Accuracy on Test Data (Model 1)","7426ae8b":"# Importing required libraries","7b99970e":"# Conclusion : We can see that our model is giving 49% accuracy for testing data which makes it a bad model.","b28446e4":"# Conclusion: Training data is giving 89% accuracy","c52ee019":"# Importing Dataset","0e06d53d":"# Checking Shape of our Data","a0b6eab3":"# Using RandomForest model with CV to check Accuracy on Test data(Model 2)","a6145c96":"# Checking accuracy for Training data"}}