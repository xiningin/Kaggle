{"cell_type":{"36c5fb2e":"code","6cff7f06":"code","eee8ca91":"code","80d31158":"code","bb8f66b2":"code","5220a822":"code","f276f534":"code","0dab8d09":"code","58930618":"code","0f36f76e":"code","cdca8c04":"code","9df439ae":"code","be3e766e":"code","ebde7573":"code","6e467310":"code","bf0b5c9c":"code","81aacdc2":"code","1aa81ca9":"markdown","88756f7d":"markdown","29dc6e92":"markdown","dcd48598":"markdown","4c792fb1":"markdown","e12f3ff7":"markdown","d13d8bb4":"markdown","699e1a7d":"markdown"},"source":{"36c5fb2e":"from IPython.display import Image\nimport os\nImage('..\/input\/cvcvcv\/CV.jpeg')","6cff7f06":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","eee8ca91":"train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsample=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","80d31158":"x_train=train.iloc[:,1:]\ny_train=train['label']\nprint(x_train.shape)","bb8f66b2":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2)","5220a822":"x_train=x_train\/255\nx_test=x_test\/255\ntest=test\/255","f276f534":"x_train=x_train.astype('float32')\nx_test=x_test.astype('float32')\ntest=test.astype('float32')","0dab8d09":"x_train=x_train.values.reshape(-1,28,28,1)\nx_test=x_test.values.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)","58930618":"import matplotlib.pyplot as plt\nfor i in range(8):\n    plt.subplot(3,3,i+1)\n    plt.imshow(x_train[i],cmap=plt.cm.binary)\n    plt.axis('off')","0f36f76e":"from tensorflow import keras\nfrom keras import layers\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping","cdca8c04":"callbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath=\"checkpoint_path.keras\",\n        monitor=\"val_loss\",\n        save_best_only=True,\n    )\n]","9df439ae":"datagen = ImageDataGenerator(\n        featurewise_center=False, \n        samplewise_center=False, \n        featurewise_std_normalization=False, \n        samplewise_std_normalization=False, \n        zca_whitening=False, \n        rotation_range=10, \n        zoom_range = 0.1, \n        width_shift_range=0.1, \n        height_shift_range=0.1,\n        horizontal_flip=False,\n        vertical_flip=False)\ndatagen.fit(x_train)","be3e766e":"inputs=keras.Input(shape=(28,28,1))\nx=inputs\nx=keras.layers.Conv2D(filters=64,kernel_size=3,strides=2,padding='same',activation='relu')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Dropout(0.2)(x)\nx=keras.layers.MaxPool2D(pool_size=2)(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Dropout(0.2)(x)\nx=keras.layers.Conv2D(filters=64,kernel_size=4,strides=2,padding='same',activation='relu')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.MaxPool2D(pool_size=2)(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Conv2D(filters=128,kernel_size=5,strides=2,padding='same',activation='relu')(x)\nx=keras.layers.Flatten()(x)\nx=keras.layers.Dense(256, activation = \"relu\")(x)\nx=keras.layers.Dropout(0.5)(x)\noutputs=keras.layers.Dense(10,activation='softmax')(x)\nmodel=keras.Model(inputs=inputs,outputs=outputs)\n\n","ebde7573":"model.compile(optimizer='rmsprop',loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","6e467310":"history=model.fit(x_train,y_train,epochs=5,batch_size=86,validation_data = (x_test,y_test),callbacks=callbacks_list)","bf0b5c9c":"result=model.predict(test)\nresult=np.argmax(result,axis=1)\nresult=pd.Series(result,name='Label')","81aacdc2":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),result],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist.csv\",index=False)","1aa81ca9":"# **Introduction to convnets**\n\u5bc6\u96c6\u9023\u63a5\u5c64\u548c\u5377\u7a4d\u5c64\u4e4b\u9593\u7684\u6839\u672c\u5340\u5225\u5728\u65bc\uff1aDense\u5c64\u5728\u5176\u8f38\u5165\u7279\u5fb5\u7a7a\u9593\u4e2d\u5b78\u7fd2\u5168\u5c40\u6a21\u5f0f\uff08\u4f8b\u5982\uff0c\u5c0d\u65bc MNIST \u6578\u5b57\uff0c\u6a21\u5f0f\u6d89\u53ca\u6240\u6709\u50cf\u7d20\uff09\uff0c\u800c\u5377\u7a4d\u5c64\u5b78\u7fd2\u5c40\u90e8\u6a21\u5f0f\uff0c\u5728\u5716\u50cf\u7684\u60c5\u6cc1\u4e0b\uff0c\u5728\u8f38\u5165\u7684\u5c0f 2D \u7a97\u53e3\u4e2d\u767c\u73fe\u7684\u6a21\u5f0f\u3002\n\n**convnets \u63d0\u4f9b\u4e86\u5169\u500b\u6709\u8da3\u7684\u7279\u6027\uff1a**\n\n1.\u4ed6\u5011\u5b78\u7fd2\u7684\u6a21\u5f0f\u662f\u5e73\u79fb\u4e0d\u8b8a\u7684\uff1a\u5728\u5b78\u7fd2\u5716\u7247\u53f3\u4e0b\u89d2\u7684\u67d0\u500b\u6a21\u5f0f\u5f8c\uff0c\u5377\u7a4d\u795e\u7d93\u7db2\u7d61\u53ef\u4ee5\u5728\u4efb\u4f55\u5730\u65b9\u8b58\u5225\u5b83\uff1a\u4f8b\u5982\uff0c\u5728\u5de6\u4e0a\u89d2\u3002\u5982\u679c\u4e00\u500b\u5bc6\u96c6\u9023\u63a5\u7684\u6a21\u578b\u51fa\u73fe\u5728\u4e00\u500b\u65b0\u7684\u4f4d\u7f6e\uff0c\u5b83\u5c31\u5fc5\u9808\u91cd\u65b0\u5b78\u7fd2\u8a72\u6a21\u5f0f\u3002\u9019\u4f7f\u5f97 convnets \u6578\u64da\u5728\u8655\u7406\u5716\u50cf\u6642\u66f4\u52a0\u9ad8\u6548\uff08\u56e0\u70ba\u8996\u89ba\u4e16\u754c\u57fa\u672c\u4e0a\u662f\u5e73\u79fb\u4e0d\u8b8a\u7684\uff09\uff1a\u5b83\u5011\u9700\u8981\u66f4\u5c11\u7684\u8a13\u7df4\u6a23\u672c\u4f86\u5b78\u7fd2\u5177\u6709\u6cdb\u5316\u80fd\u529b\u7684\u8868\u793a\u3002\n\n2.\u4ed6\u5011\u53ef\u4ee5\u5b78\u7fd2\u6a21\u5f0f\u7684\u7a7a\u9593\u5c64\u6b21\u7d50\u69cb\u3002\u7b2c\u4e00\u500b\u5377\u7a4d\u5c64\u5c07\u5b78\u7fd2\u5c0f\u7684\u5c40\u90e8\u6a21\u5f0f\uff0c\u4f8b\u5982\u908a\u7de3\uff0c\u7b2c\u4e8c\u500b\u5377\u7a4d\u5c64\u5c07\u5b78\u7fd2\u7531\u7b2c\u4e00\u5c64\u7684\u7279\u5fb5\u7d44\u6210\u7684\u66f4\u5927\u7684\u6a21\u5f0f\uff0c\u4f9d\u6b64\u985e\u63a8\u3002\u9019\u5141\u8a31 convnets \u6709\u6548\u5730\u5b78\u7fd2\u8d8a\u4f86\u8d8a\u8907\u96dc\u548c\u62bd\u8c61\u7684\u8996\u89ba\u6982\u5ff5\u2014\u2014\u56e0\u70ba\u8996\u89ba\u4e16\u754c\u57fa\u672c\u4e0a\u662f\u7a7a\u9593\u5c64\u6b21\u7684\u3002","88756f7d":"# **MNIST-Digit Recognizer-Deep learning for computer vision**","29dc6e92":"* \u8b93\u6211\u5011\u4f86\u770b\u770b\u524d8\u7b46DATA\u8f49\u63db\u6210\u5716\u7247\u5f8c\u6703\u9577\u600e\u9ebc\u6a23","dcd48598":"# **MNIST_Data**","4c792fb1":"# **Ready to train**","e12f3ff7":"# **Data_augmentation**","d13d8bb4":"# **What we use**\n* **Convolution strides**:Using stride 2 means the width and height of the feature map are downsampled by a factor of 2 (in addition to any changes induced by border effects). \n\n* **The max-pooling operation**: That\u2019s the role of max pooling: to aggressively downsample feature maps, much like strided convolutions.\n\n* **BatchNormalization**:Normalization is a broad category of methods that seek to make different samples seen by a machine-learning model more similar to each other, which helps the model learn and generalize well to new data. ","699e1a7d":"* \u5728\u8a13\u7df4\u4e4b\u524d\uff0c\u6211\u5011\u5c07\u901a\u904e\u5c07\u6578\u64da\u91cd\u5851\u70ba\u6a21\u578b\u671f\u671b\u7684\u5f62\u72c0\u4e26\u5c0d\u5176\u9032\u884c\u7e2e\u653e\u4f86\u9810\u8655\u7406\u6578\u64da\uff0c\u4ee5\u4fbf\u6240\u6709\u503c\u90fd\u5728[0, 1]\u5340\u9593\u5167\u3002\u4ee5\u524d\uff0c\u6211\u5011\u7684\u8a13\u7df4\u5716\u50cf\u5b58\u5132\u5728(60000, 28, 28)\u985e\u578buint8\u70ba[0, 255]\u5340\u9593\u7684\u5f62\u72c0\u6578\u7d44\u4e2d\u3002\u6211\u5011\u5c07\u5176\u8f49\u63db\u70ba\u4e00\u500b\u503c\u5728 0 \u5230 1 \u4e4b\u9593float32\u7684\u5f62\u72c0\u6578\u7d44(60000, 28 * 28)\u3002"}}