{"cell_type":{"7cd5c70e":"code","fcdfe64a":"code","beb86958":"code","1aae3679":"code","24faf7a1":"code","b40f13b4":"code","f91bfa5f":"code","6942ae17":"code","53704b1d":"code","08258fa5":"code","a437d50c":"code","766b64c3":"code","f9db7f4f":"code","7b05f1bb":"code","710dcee1":"code","a1105d47":"markdown","a1282259":"markdown","683925e9":"markdown","e3365bd7":"markdown","e68b0b1f":"markdown","b7fb5d58":"markdown","b0e8771f":"markdown","b8e9f1bd":"markdown","c25082ec":"markdown","d21af940":"markdown","261cfc5b":"markdown","2a1a6253":"markdown","19e4dab3":"markdown","b7a96678":"markdown","3e62735c":"markdown","ec6347f0":"markdown","61d3884f":"markdown","5a2e2fe8":"markdown","7d5c8acb":"markdown","8e9c7493":"markdown","ec781bc2":"markdown","89f54880":"markdown","7833d1a4":"markdown","a511445c":"markdown","088a1fa8":"markdown","345745ed":"markdown","a6af2b3a":"markdown","06a950a8":"markdown"},"source":{"7cd5c70e":"import warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nwarnings.filterwarnings(\"ignore\")\nplt.style.use(\"ggplot\")","fcdfe64a":"import seaborn as sns\nfrom statsmodels.tsa.stattools import adfuller\n\ndiamonds = sns.load_dataset(\"diamonds\")\n\ntest_results = adfuller(diamonds[\"price\"])\n\nprint(f\"ADF test statistic: {test_results[0]}\")\nprint(f\"p-value: {test_results[1]}\")\nprint(\"Critical thresholds:\")\nfor key, value in test_results[4].items():\n    print(f\"\\t{key}: {value}\")","beb86958":"tps_july = pd.read_csv(\n    \"..\/input\/tabular-playground-series-jul-2021\/train.csv\", parse_dates=[\"date_time\"], index_col=\"date_time\"\n)\n\ntest_results = adfuller(tps_july[\"target_carbon_monoxide\"])\n\ntest_results[1]","1aae3679":"amzn = pd.read_csv(\n    \"https:\/\/raw.githubusercontent.com\/BexTuychiev\/medium_stories\/master\/2021\/july\/6_stationarity_ts\/data\/AMZN.csv\",\n    parse_dates=[\"Date\"],\n    index_col=\"Date\",\n)\n\namzn.plot(figsize=(14, 4));","24faf7a1":"amzn_results = adfuller(amzn[\"Close\"])\n\namzn_results[1]","b40f13b4":"msft = pd.read_csv(\n    \"https:\/\/raw.githubusercontent.com\/BexTuychiev\/medium_stories\/master\/2021\/july\/6_stationarity_ts\/data\/MSFT.csv\",\n    parse_dates=[\"Date\"],\n    index_col=\"Date\",\n).dropna()\n\nmsft.plot(figsize=(14, 4));","f91bfa5f":"msft_results = adfuller(msft[\"Close\"])\n\nmsft_results[1]","6942ae17":"msft[\"diff_1\"] = msft[\"Close\"].diff(periods=1)\nmsft[\"diff_2\"] = msft[\"Close\"].diff(periods=2)\nmsft[\"diff_3\"] = msft[\"Close\"].diff(periods=3)\n\nmsft.head(6)","53704b1d":"results = adfuller(msft[\"diff_1\"].dropna())\n\nresults[1]","08258fa5":"amzn.plot(figsize=(14, 4));","a437d50c":"transformed_amzn = pd.Series(np.log(amzn[\"Close\"])).diff().dropna()\n\ntransformed_amzn.plot(figsize=(14, 4));","766b64c3":"results = adfuller(transformed_amzn)\n\nresults[1]","f9db7f4f":"drugs = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/BexTuychiev\/medium_stories\/master\/2021\/july\/6_stationarity_ts\/data\/australia_drug_sales.csv\", index_col=0)\n\ndrugs.plot(\"time\", \"value\", figsize=(20, 5))\nplt.xlabel(\"Year\")\nplt.ylabel(\"Anibiotics Sold (mln)\");","7b05f1bb":"fig, ax = plt.subplots(3, 1, figsize=(20, 15))\n\nax[0].plot(drugs[\"time\"], drugs[\"value\"], label=\"Original series\")\nax[1].plot(drugs[\"time\"], np.log(drugs[\"value\"]), label=\"After log transform\")\n\ndrugs[\"transformed\"] = pd.Series(np.log(drugs[\"value\"])).diff(periods=12)  # 12 months\ndrugs.dropna(inplace=True)\nax[2].plot(drugs[\"time\"], drugs[\"transformed\"], label=\"After differencing\");","710dcee1":"results = adfuller(drugs[\"transformed\"])\n\nresults[1]","a1105d47":"\n> Spoiler: Surprisingly, all the target variables turned out to be stationary. I made this notebook anyway as a tutorial on detecting and transforming non-stationary time series data. It may not be useful in this competition but this topic is extremely important in other forecasting problems since almost all real-world time-series data is non-stationary.","a1282259":"The p-value is close to 1. No interpretation is necessary.","683925e9":"## Setup","e3365bd7":"## Why is stationarity important? <small id='1'><\/small>","e68b0b1f":"## Detecting non-stationarity statistically <small id='3'><\/small>","b7fb5d58":"## Introduction <small id='intro'><\/small>\n\nUnlike ordinary machine learning problems, time series forecasting requires *extra* preprocessing steps.\n\nOn top of the normality assumptions, most ML algorithms expect a *static relationship* between the input features and the output.\n\nA static relationship requires inputs and outputs with constant parameters such as mean, median, and variance. In other words, algorithms perform best when the inputs and outputs are **stationary**.\n\nThis is not the case in time series forecasting. Distributions that change over time can have unique properties such as seasonality and trend. These, in turn, cause the mean and variance of the series to fluctuate, making it hard to model their behavior.\n\nSo, making a distribution stationary is a strict requirement in time series forecasting. In this article, we will explore several techniques to detect non-stationary distributions and convert them into stationary data.","b0e8771f":"The output above shows the results of first, second, and third-order differencing.\n\nFor simple distributions, taking the first-order difference is enough to make it stationary. Let's check this by using the `adfuller` function on the `diff_1` (first-order difference of Microsoft stocks):","b8e9f1bd":"When we run `adfuller` on the original distribution of Microsoft stocks, the p-value was close to 1. After differencing, the p-value is flat 0, suggesting we reject the null and conclude the series is now stationary.\n\nHowever, some distributions may not be so easy to deal with. Going back to Amazon stocks:","c25082ec":"## Transforming non-stationary series to make it stationary <small id='4'><\/small>\n\n<a href='#toc'>Back to Top \ud83d\udd1d<\/a>","d21af940":"## Summary <small id='5'><\/small>","261cfc5b":"We can confirm the stationarity with `adfuller`:","2a1a6253":"Since stationary series have constant variance, we can rule out **a, c, e, f**, and **i**. These plots show a clear upward or downward trend or changing levels like in f.\n\nSimilarly, as **d** and **h** show seasonal patterns, we can rule them out too.\u00a0\n\nBut how about **g**\u200a-\u200athe pattern does look it is seasonal.\n\n**g** is the plot of the [lynx](https:\/\/en.wikipedia.org\/wiki\/Lynx) population growth. When food becomes scarce, they stop breeding, causing the population numbers to plummet. When the food sources replenish, they start reproducing again, making the population grow.\n\nThis cyclic behavior is not the same as seasonality. When seasonality exists, you know exactly what will happen after a certain period of time. In contrast, the cyclic behavior of lynx population growth is unpredictable. You can't guess the timing of the food cycles and this makes the series stationary.\nSo, the only stationary series are b and g.\n\nTricky distributions like **d, f**, and **h** can make you question whether identifying non-stationary data visually is the best option. As you observed, it is pretty easy to confuse seasonality with random cycles or trends with white noise.\n\nFor this reason, the next section will be about statistical methods of detecting non-stationary time series.","19e4dab3":"We look at the p-value, which is almost 0. This means we can easily reject the null and consider the distribution as stationary.\n\nNow, let's load the TPS July Playground dataset from Kaggle and check if the target carbon monoxide is stationary:","b7a96678":"Another topic is done and dusted in this Time Series forecasting series!\n\nWe have already covered a lot, even though we haven't gotten around to the actual forecasting part. By now, you should be able to:\n\n- Manipulate time-series data like a pro using pandas ([link](https:\/\/www.kaggle.com\/bextuychiev\/every-pandas-function-to-manipulate-time-series)).\n- Dissect any time series into core components such as seasonality and trend ([link](https:\/\/www.kaggle.com\/bextuychiev\/advanced-time-series-analysis-decomposition)).\n- Analyze time-series signals using autocorrelation ([link](https:\/\/www.kaggle.com\/bextuychiev\/advanced-time-series-analysis-decomposition)).\n- Identify if the target you want to predict is white noise or follows a random walk ([link](https:\/\/www.kaggle.com\/bextuychiev\/how-to-detect-white-noise-and-random-walks-in-ts)).\n\nAnd finally, you learned how to remove the effect of non-stationary from any time series. All of these are must-know topics and important building blocks to forecasting. The next post is on **time-series feature engineering**. Don't miss it!","3e62735c":"Surprisingly, carbon monoxide is found to be stationary. This might be because the data is recorded over a short period of time, which diminishes the effect of the time component. In fact, all other variables in the data are completely stationary.\n\nNow, let's load some stocks data that is more likely to be non-stationary:","ec6347f0":"The p-value is extremely small, proving that the transformation steps have shown their effect.\n\nIn general, every distribution is different, and to achieve stationarity, you might end up chaining multiple operations. Most of these involve taking logarithms, first\/second-order, or seasonal differencing.","61d3884f":"If a distribution is not stationary, then it becomes tough to model. Algorithms build relationships between inputs and outputs by estimating the core parameters of the underlying distributions.\n\nWhen these parameters are all time-dependent, algorithms will face different values at each point in time. And if the time series is granular enough (such as minutes or seconds frequencies), models may even end up with more parameters than actual data.\n\nThis type of variable relationship between inputs and outputs will seriously compromise the decision function of any model. If the relationship keeps changing through time, models end up using an outdated relationship or one that does not contribute to its predictive power.\n\nTherefore, you must dedicate a certain amount of time to detecting non-stationarity and removing its effects during your workflow.\n\nWe will see an example of this in the coming sections.","5a2e2fe8":"As you can see, the series shows both an upward trend and a strong seasonality. We will again apply a log transform and, this time, take a yearly difference (12 months) to remove the seasonality.\n\nHere is what each step looks like:","7d5c8acb":"As you can see, the distribution that returned a perfect p-value before transformation is now completely stationary.\n\nLet's look at another example. Below is the plot of monthly antibiotics sales in Australia:","8e9c7493":"# How to Remove Non-Stationarity in Time Series Forecasting\n## Algorithms can't handle non-stationary. They need static relationships.\n![](https:\/\/cdn-images-1.medium.com\/max\/1200\/1*qhSTGmSC69HxBM8V3Jh7bA.jpeg)\n<figcaption style=\"text-align: center;\">\n    <strong>\n        Photo by \n        <a href='https:\/\/unsplash.com\/@jonathanpielmayer?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText'>Jonathan Pielmayer<\/a>\n        on \n        <a href='https:\/\/unsplash.com\/s\/photos\/still?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText'>Unsplash.<\/a> All images are by author unless specified otherwise.\n    <\/strong>\n<\/figcaption>","ec781bc2":"Before taking the difference, we have to account for that obvious non-linear trend. Otherwise, the series will still be non-stationary.\n\nTo remove non-linearity, we will use the logarithmic function `np.log` and then, take the first-order difference:","89f54880":"<a href='#toc'>Back to Top \ud83d\udd1d<\/a>\n\nTake a look at these plots and try to guess which of the lines represent a stationary series:\n\n![](https:\/\/otexts.com\/fpp2\/fpp_files\/figure-html\/stationary-1.png)\n<figcaption style=\"text-align: center;\">\n    <strong>\n        Image by <a href='https:\/\/otexts.com\/fpp2\/'>otexts.com<\/a> [1]\n    <\/strong>\n<\/figcaption>","7833d1a4":"As you can see, Amazon stocks show a clear upward trend. Let's perform the Dickey-Fuller test:","a511445c":"## Examples of non-stationary series <small id='2'><\/small>","088a1fa8":"We get a perfect p-value of 1\u200a-\u200athis is 100% non-stationary time series data. Let's perform a final test on Microsoft stocks, and we will move on to different techniques you can deal with this type of data:","345745ed":"<a href='#toc'>Back to Top \ud83d\udd1d<\/a>\n\nIn the statistics world, there are several tests under the label of [unit root tests](https:\/\/medium.com\/r\/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FUnit_root_test%23%3A~%3Atext%3DIn%2520statistics%252C%2520a%2520unit%2520root%2Cdepending%2520on%2520the%2520test%2520used.). The augmented Dickey-Fuller test may be the most popular one, and we have already seen how to use it to detect random walks in [my last kernel](https:\/\/www.kaggle.com\/bextuychiev\/how-to-detect-white-noise-and-random-walks-in-ts).\n\nHere, we will see how to use it to check if a series is stationary or not.\n\nSimply put, here are the null and alternative hypotheses of this test:\n- **The null hypothesis**: the distribution is non-stationary, time-dependent (it has a unit root)\n- **The alternative hypothesis**: the distribution is stationary, not time-dependent (can't be represented by a unit root).\n\nThe p-value determines the result of the test. If it is smaller than a critical threshold of 0.05 or 0.01, we **reject** the null hypothesis and conclude that the series is stationary. Otherwise, we **fail to reject** the null and conclude the series is non-stationary.\n\nThe full test is conveniently implemented as `adfuller` function under `statsmodels`. First, let's use it on a distribution we know is stationary and get familiarized with its output:","a6af2b3a":"One method for transforming the simplest non-stationary data is differencing. This process involves taking the differences of consecutive observations. Pandas has a `diff` function to do this:","06a950a8":"## Table of Contents <small id='toc'><\/small>\n#### [1. Why is stationarity important?](#1)\n#### [2. Examples of non-stationary series](#2)\n#### [3. Detecting non-stationarity statistically](#3)\n#### [4. Transforming non-stationary series to make it stationary](#4)\n#### [5. Summary](#5)\n\n"}}