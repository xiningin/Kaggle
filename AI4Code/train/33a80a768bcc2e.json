{"cell_type":{"75dd4527":"code","1a040868":"code","196a2d78":"code","07a2d964":"code","cc521089":"code","59cac130":"code","8ba289a0":"code","078b034c":"code","609fa2de":"code","9b76a43d":"code","ed9fcced":"code","2fcf0e74":"code","6e85dccd":"code","3b29c135":"code","c03645ec":"code","648b3ac9":"code","137fd61a":"code","97002cce":"code","1d65edf6":"code","ee92d29c":"code","c064a8ed":"code","6f6f3165":"code","3f16195c":"code","e4ac1d63":"code","cc13918d":"code","92c5b9db":"code","738617f0":"code","ba4b1d17":"code","a548012e":"code","b257fd4b":"code","ba0a0e29":"code","dc8d5540":"code","ec4c2347":"code","c07d8915":"markdown","b13a6e13":"markdown"},"source":{"75dd4527":"import os\nimport cv2\nimport shutil\nimport random\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D,BatchNormalization,AvgPool2D,Flatten,Dense,Concatenate,Input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix","1a040868":"input_train_path='\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train'\ninput_test_path='\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test'\nlabels=os.listdir(input_train_path)\nprint(labels)","196a2d78":"def get_images(path):\n    name_list,path_list=[],[]\n    for folder in os.listdir(path):\n        folder_path=os.path.join(path,folder)\n        name_list.append(folder)\n        image_set=random.sample(os.listdir(folder_path),1)\n        for file in image_set:\n            file_path=os.path.join(folder_path,file)\n            path_list.append(file_path)\n    return path_list,name_list","07a2d964":"path_list,name_list=get_images(input_train_path)","cc521089":"def show_labels(path_list,name_list):\n    fig=plt.figure(figsize=(16,16))\n    row=2\n    col=3\n    for i in range(len(name_list)):\n        fig.add_subplot(row,col,i+1)\n        plt.axis('off')\n        plt.title(name_list[i])\n        plt.imshow(cv2.imread(path_list[i]))\n    plt.show()","59cac130":"show_labels(path_list,name_list)","8ba289a0":"data_dir='\/kaggle\/data'\ntrain_path=os.path.join(data_dir,'train')\nvalid_path=os.path.join(data_dir,'valid')\ntest_path=os.path.join(data_dir,'test')","078b034c":"def make_dir():\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n        os.mkdir(train_path)\n        os.mkdir(valid_path)\n        os.mkdir(test_path)\n        for label in labels:\n            os.mkdir(os.path.join(train_path,label))\n            os.mkdir(os.path.join(valid_path,label))\n            os.mkdir(os.path.join(test_path,label))\ndef check_dir():\n    print(f'{data_dir}: {os.path.isdir(data_dir)}')\n    print(f'{train_path}: {os.path.isdir(train_path)}')\n    print(f'{valid_path}: {os.path.isdir(valid_path)}')\n    print(f'{test_path}: {os.path.isdir(test_path)}')\n    for label in labels:\n        print(f'{os.path.join(train_path,label)}: {os.path.isdir(os.path.join(train_path,label))}')\n        print(f'{os.path.join(valid_path,label)}: {os.path.isdir(os.path.join(valid_path,label))}')\n        print(f'{os.path.join(test_path,label)}: {os.path.isdir(os.path.join(test_path,label))}')","609fa2de":"make_dir()","9b76a43d":"check_dir()","ed9fcced":"def load_train_images(n=1800):\n    for folder in os.listdir(input_train_path):\n        folder_path=os.path.join(input_train_path,folder)\n        dest_path=os.path.join(train_path,folder)\n        print(f'Loading the training images for {folder} from {folder_path} to {dest_path}')\n        image_set=random.sample(os.listdir(folder_path),n)\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)\ndef load_valid_images(n=300):\n    for folder in os.listdir(input_train_path):\n        folder_path=os.path.join(input_train_path,folder)\n        dest_path=os.path.join(valid_path,folder)\n        print(f'Loading the validation images for {folder} from {folder_path} to {dest_path}')\n        image_set=random.sample(os.listdir(folder_path),n)\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)\ndef load_test_images(n=100):\n    for folder in os.listdir(input_test_path):\n        folder_path=os.path.join(input_test_path,folder)\n        dest_path=os.path.join(test_path,folder)\n        print(f'Loading the test images for {folder} from {folder_path} to {dest_path}')\n        image_set=random.sample(os.listdir(folder_path),n)\n        for file in tqdm(image_set):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest_path)","2fcf0e74":"load_train_images()","6e85dccd":"load_valid_images()","3b29c135":"load_test_images()","c03645ec":"batch_size=32\nepochs=35\ntarget_size=(96,96)","648b3ac9":"datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1.\/255)\ntrain_data=ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1.\/255,horizontal_flip=True).flow_from_directory(directory=train_path,target_size=target_size,classes=labels,batch_size=batch_size)\nvalid_data=datagen.flow_from_directory(directory=valid_path,target_size=target_size,classes=labels,batch_size=batch_size)\ntest_data=datagen.flow_from_directory(directory=test_path,target_size=target_size,classes=labels,batch_size=batch_size,shuffle=False)","137fd61a":"class Resnet(tf.keras.models.Model):\n    def __init__(self,filters,n_conv=3,kernel_size=3,strides=1):\n        super().__init__()\n        self.model=[]\n        for i in range(n_conv):\n            self.model.append(Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same',activation='relu'))\n            self.model.append(BatchNormalization())\n        self.model=Sequential(self.model)\n    def call(self,inputs):\n        out=self.model(inputs)\n        out=Concatenate()([out,inputs])\n        return tf.keras.activations.relu(out)","97002cce":"class BottleNeckResnet(tf.keras.models.Model):\n    def __init__(self,filters,n_conv=3,kernel_size=3,strides=1,ratio=4):\n        super().__init__()\n        input_filters=int(filters\/ratio)\n        self.model=[]\n        self.model.append(Conv2D(filters=input_filters,kernel_size=1,strides=strides,padding='same',activation='relu'))\n        for i in range(n_conv):\n            self.model.append(Conv2D(filters=input_filters,kernel_size=kernel_size,strides=strides,padding='same',activation='relu'))\n            self.model.append(BatchNormalization())\n        self.model.append(Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same',activation='relu'))\n        self.model=Sequential(self.model)\n    def call(self,inputs):\n        out=self.model(inputs)\n        out=Concatenate()([out,inputs])\n        return tf.keras.activations.relu(out)","1d65edf6":"def build_resnet(input_shape,n_conv=3):\n    model=[]\n    steps=int(np.log2(input_shape[0]))\n    model.append(Input(shape=input_shape))\n    filters=8\n    for i in range(steps):\n        model.append(Resnet(filters=filters,n_conv=n_conv))\n        model.append(AvgPool2D(pool_size=2,strides=2))\n        filters=filters*2\n    return Sequential(model)","ee92d29c":"def build_bottleneck_resnet(input_shape,n_conv=3,ratio=4):\n    model=[]\n    steps=int(np.log2(input_shape[0]))\n    model.append(Input(shape=input_shape))\n    filters=8\n    model.append(Conv2D(filters=filters,kernel_size=1,strides=1,padding='same',activation='relu'))\n    for i in range(steps):\n        model.append(BottleNeckResnet(filters=filters,ratio=ratio,n_conv=n_conv))\n        model.append(AvgPool2D(pool_size=2,strides=2))\n        filters=filters*2\n    return Sequential(model)","c064a8ed":"class ParallelModel(tf.keras.models.Model):\n    def __init__(self,resnet_builder,bottleneck_resnet_builder,input_shape=(96,96,3),n_conv=3,ratio=4):\n        super().__init__()\n        self.preprocess=Conv2D(filters=8,kernel_size=1,strides=1,padding='same',activation='relu')\n        self.resnet=resnet_builder(input_shape=(*input_shape[0:2],4),n_conv=n_conv)\n        self.bottleneck_resnet=bottleneck_resnet_builder(input_shape=(*input_shape[0:2],4),n_conv=n_conv,ratio=ratio)\n        self.remaining_model=[\n            Flatten(),\n            Dense(units=4096,activation='relu'),\n            Dense(units=4096,activation='relu'),\n            Dense(units=len(labels),activation='softmax')\n        ]\n        self.remaining_model=Sequential(self.remaining_model)\n    def call(self,inputs):\n        x=self.preprocess(inputs)\n        input1=x[:,:,:,0:4]\n        input2=x[:,:,:,4:]\n        out1=self.resnet(input1)\n        out2=self.bottleneck_resnet(input2)\n        out=Concatenate()([out1,out2])\n        out=tf.keras.activations.relu(out)\n        return self.remaining_model(out)","6f6f3165":"model=ParallelModel(resnet_builder=build_resnet,bottleneck_resnet_builder=build_bottleneck_resnet,n_conv=5)","3f16195c":"data,target=train_data.next()\nprint(model(data).shape)","e4ac1d63":"model.summary()","cc13918d":"ckpt_path='\/kaggle\/ckpt'\nos.mkdir(ckpt_path)","92c5b9db":"model_callback=ModelCheckpoint(filepath=ckpt_path,save_weights_only=True,monitor='val_accuracy',save_best_only=True)","738617f0":"model.compile(optimizer=Adam(lr=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])","ba4b1d17":"history=model.fit(x=train_data,batch_size=batch_size,epochs=epochs,verbose=2,validation_data=valid_data,callbacks=[model_callback])","a548012e":"model.load_weights(ckpt_path)","b257fd4b":"def print_accuracy(data):\n    p=model.predict(data)\n    cm=confusion_matrix(y_true=data.classes,y_pred=np.argmax(p,axis=-1))\n    acc=cm.trace()\/cm.sum()\n    print(f'The accuracy is {acc*100}%')","ba0a0e29":"print_accuracy(test_data)","dc8d5540":"val_loss=history.history['val_loss']\ntrain_loss=history.history['loss']","ec4c2347":"plt.figure()\nplt.plot(train_loss,'ro-')\nplt.plot(val_loss,'bo-')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss vs Epoch')\nplt.legend(['Train','Valid'])\nplt.show()","c07d8915":"# Model structure","b13a6e13":"![model.png](attachment:dcd6889f-5a20-4b3e-ace0-a6fcab17efc9.png)"}}