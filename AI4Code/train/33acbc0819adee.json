{"cell_type":{"f1d0267a":"code","23f27438":"code","72b00fc2":"code","15e34cc2":"code","84cd3f44":"code","1497393d":"code","88f8c841":"code","f23591ba":"code","2d703322":"code","56bd0731":"code","ec6a325a":"code","fc43841c":"code","3cfd022b":"code","69a94216":"code","6748f50e":"code","e50ab092":"code","fd5a938d":"code","46f088db":"code","99e30a1a":"code","f38c06dc":"code","ca5e2184":"code","af3f65c9":"code","5422d120":"code","801b7a6b":"code","fbd0bb89":"code","887464f3":"code","aa8defa1":"code","9e96d01e":"code","c390e711":"code","be438a5e":"code","235317a5":"code","87b1c1b0":"code","ee1c653f":"code","4ecbe62d":"code","262290be":"code","b3e24950":"code","4bf0e34d":"code","61818914":"code","c6c429d4":"code","255b6425":"code","e312ac8f":"code","d9eab4e4":"code","c6ff8511":"code","24a81a2a":"code","622ad997":"code","812f18a0":"code","305eeb32":"markdown","117915af":"markdown","b15039dc":"markdown","83fe833e":"markdown","39a5781a":"markdown","e039c050":"markdown","d9b58c51":"markdown","c25f642e":"markdown","e8bfddac":"markdown","0102cc14":"markdown"},"source":{"f1d0267a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","23f27438":"import matplotlib.pyplot as plt\nimport seaborn as sns","72b00fc2":"data = pd.read_csv('\/\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndata.head()","15e34cc2":"data.shape","84cd3f44":"data.describe(include = 'all')","1497393d":"data.info()","88f8c841":"data['quality'].unique()","f23591ba":"data['quality'] = data['quality'] - 3","2d703322":"data['quality'].unique()","56bd0731":"data.hist(figsize=(20,20))\nplt.show()","ec6a325a":"sns.pairplot(data, diag_kind = 'kde', hue = 'quality')\nplt.show()","fc43841c":"sns.distplot(data['total sulfur dioxide'])\nplt.show()","3cfd022b":"data.groupby(['quality']).count()","69a94216":"df = data.copy()\nX = df.iloc[:,:].values\nfrom scipy.stats import zscore\nzscore(X)\nX.shape\n","6748f50e":"plt.figure(figsize=(20,20))\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.grid(True)\nplt.show()\n","e50ab092":"# Fitting K-Means to the dataset\nkmeans = KMeans(n_clusters = 6, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X[:,[0,11]])\n","fd5a938d":"plt.figure(figsize=(20,14))\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 20, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 20, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 20, c = 'orange', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 20, c = 'black', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 20, c = 'green', label = 'Cluster 5')\nplt.scatter(X[y_kmeans == 5, 0], X[y_kmeans == 5, 1], s = 20, c = 'yellow', label = 'Cluster 6')\n\n\n\nplt.title('Clusters of wine quality')\nplt.xlabel('quality of wine in catageory')\nplt.ylabel('fixed acidity')\nplt.legend()\nplt.show()","46f088db":"def replace(group):\n    median, std = group.median(), group.std()\n    outliers = (group - median).abs() > 2 * std\n    group[outliers] = group.median()\n    return group","99e30a1a":"data['total sulfur dioxide'].max()","f38c06dc":"data['total sulfur dioxide'] = replace(data['total sulfur dioxide'])\ndata['sulphates'] = replace(data['sulphates'])","ca5e2184":"sns.distplot(data['total sulfur dioxide'])\n","af3f65c9":"sns.distplot(data['sulphates'])","5422d120":"corr_matrix = data.corr()\nplt.figure(figsize = (10,20))\nax = sns.heatmap(corr_matrix[['quality']].sort_values(by=['quality'],ascending=False),annot = True)","801b7a6b":"plt.figure(figsize = (15,15))\nsns.heatmap(data.corr(),annot = True)","fbd0bb89":"data['fixed acidity_per_volatiles acidity'] = data['fixed acidity']\/data['volatile acidity']\ndata['residual sugar_per_volatiles acidity'] = data['residual sugar']\/data['volatile acidity']\ndata['fixed acidity_per_residual sugar'] = data['fixed acidity']\/data['residual sugar']\ndata['free sulfur dioxide_per_volatiles acidity'] = data['free sulfur dioxide']\/data['volatile acidity']\ndata['total sulfur dioxide_per_PH'] = data['total sulfur dioxide']\/data['pH']\ndata['pH_per_density'] = data['pH']\/data['density']\ndata['sulphates_per_alcohol'] = data['sulphates']\/data['alcohol']\ndata['alchol_per_residual sugar'] = data['alcohol']\/data['residual sugar']\ndata['alcohol_per_chlorides'] = data['alcohol']\/data['chlorides']\ndata['alcohol_per_density'] = data['alcohol']\/data['density']\ndata['alcohol_per_fixed acidity'] = data['alcohol']\/data['fixed acidity']\ndata['alcohol_per_volatile acidity'] = data['alcohol']\/data['volatile acidity']\ndata['fixed acidity_per_density'] = data['fixed acidity']\/data['density']\ndata['volatile acidity_per_density'] = data['volatile acidity']\/data['density']\ndata['sulphates_per_density'] = data['sulphates']\/data['density']\ndata['total sulfur dioxide_per_density'] = data['total sulfur dioxide']\/data['density']\ndata['citric acid_per_density'] = data['citric acid']\/data['density']\n","887464f3":"data.head()","aa8defa1":"#sns.pairplot(data,hue = 'quality')\nplt.show()","9e96d01e":"X = data.drop('quality',axis = 1).copy()\nY = data['quality'].copy()\ndf = X.copy()\nX.shape[1]\n\nX = pd.DataFrame(X)\nY = pd.DataFrame(Y)","c390e711":"df = X\nY.head()\nimport time\nfrom sklearn.manifold import TSNE","be438a5e":"import time\nfrom sklearn.manifold import TSNE\n\nn_sne = 7000\ntime_start = time.time()\ntsne = TSNE(n_iter = 1000,random_state=13)\ntsne_result = tsne.fit_transform(df.values)\nprint('tsne done! Time elapsed {} seconds'.format(time.time()-time_start))","235317a5":"df['label'] = Y\n%matplotlib inline\nfig = plt.figure(figsize=(20,8))\nplt.scatter(tsne_result[:,0],tsne_result[:,1],c = df['label'], cmap = plt.cm.get_cmap('Dark2',20),alpha = 0.9,linewidths = 5)\nplt.clim(-0.5,9.5)\nplt.colorbar(ticks = range(0,6))\nplt.show()","87b1c1b0":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data[\"quality\"]):\n    strat_train_set = data.loc[train_index]\n    strat_test_set = data.loc[test_index]","ee1c653f":"strat_train_set=strat_train_set.reset_index(drop=True)\nstrat_train_set.head()","4ecbe62d":"strat_test_set = strat_test_set.reset_index(drop=True)\nstrat_test_set.head()","262290be":"X_train, y_train, X_test, y_test = heart = strat_train_set.drop(\"quality\", axis=1),strat_train_set[\"quality\"].copy(),strat_test_set.drop('quality',axis = 1),strat_test_set['quality'].copy()","b3e24950":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(C = 1.0,solver = 'newton-cg', multi_class =  'multinomial')\nclassifier.fit(X_train, y_train)","4bf0e34d":"y_pred = classifier.predict(X_test)\nfrom sklearn import metrics\nmetrics.accuracy_score(y_pred, y_test)","61818914":"print(metrics.classification_report( y_test, y_pred))","c6c429d4":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm,annot = True)","255b6425":"x = range(len(X_test[:20]))\nplt.plot(x,classifier.predict(X_test[:20]),color = 'green', label = 'predicted values' )\nplt.scatter(x,y_test[:20] , color = 'red', label = 'original values')\nplt.grid(True)\nplt.legend()","e312ac8f":"cat_features = list(range(0, X.shape[1]))\nprint(cat_features)\n\nfrom catboost import CatBoostClassifier\n\nclf = CatBoostClassifier(\n    iterations=5, \n    learning_rate=0.1, \n    #loss_function='CrossEntropy'\n)\n\n\nclf.fit(X_train, y_train, \n        eval_set=(X_train, y_train), \n        verbose=False\n)\n\nprint('CatBoost model is fitted: ' + str(clf.is_fitted()))\nprint('CatBoost model parameters:')\nprint(clf.get_params())\n","d9eab4e4":"from catboost import CatBoostClassifier\nclf = CatBoostClassifier(\n    iterations=10,\n#     verbose=5,\n)\n\nclf.fit(\n    X_train, y_train,\n    eval_set=(X_train, y_train),\n)","c6ff8511":"y_pred = clf.predict(X_test)\nfrom sklearn import metrics\nmetrics.accuracy_score(y_pred, y_test)","24a81a2a":"x = range(len(X_test[:20]))\nplt.plot(x,clf.predict(X_test[:20]),color = 'green', label = 'predicted values' )\nplt.scatter(x,y_test[:20] , color = 'red', label = 'original values')\nplt.grid(True)\nplt.legend()","622ad997":"import time\nstart_time = time.time()\nfrom tpot import TPOTClassifier\ntpot_clf = TPOTClassifier(verbosity=1,cv = 2,max_eval_time_mins=1)\ntpot_clf.fit(X_train.values,y_train.values)\nprint(f'Time Elasped to done the whole process is {time.time()-start_time}')","812f18a0":"automl.fit(X_train,y_train)\ny_pred = automl.predict(X_test)\n# Making the Confusion Matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_pred,y_test)\nsns.heatmap(cm,annot = True)\naccuracy_score(y_pred,y_test)","305eeb32":"# Feature Engineering","117915af":"# Removing the Outliers form the some of the column in data\n","b15039dc":"# EDA on the classification of red wine data","83fe833e":"## As we can clearly see from clustering there are some attribute which are clearly seperate all the categeory of red wine\n","39a5781a":"# Making the diffrent cluster on data for better understanding of the data","e039c050":"# Logistic Regression classifier","d9b58c51":"# predictive analysis","c25f642e":"# Visualising the data\n","e8bfddac":"# Catboost","0102cc14":"# Don't Forget To UpVote :)"}}