{"cell_type":{"f349f3ea":"code","0cc529e3":"code","63af2660":"code","692abb1b":"code","16e103e5":"code","13c917f1":"code","bfa81dd1":"code","1206106b":"code","6d0bc195":"code","5cbc40a2":"code","59cb9c2b":"code","ed9c2632":"code","60a20ab8":"code","c9cc1ba1":"code","3c006c66":"code","2abf090f":"code","abf53c15":"code","66e3fcf3":"code","b0f4ad65":"code","ae59516f":"code","c3b7b900":"code","7a444a66":"code","7f81a134":"markdown","9dd87544":"markdown","666b4879":"markdown","ad8af75a":"markdown","c22fb1e9":"markdown","1485dafe":"markdown","09fc04a2":"markdown","f5dbe03d":"markdown","2ca1f038":"markdown","62e505d6":"markdown","870cbdd2":"markdown","b9fcad2a":"markdown","24cc5fe1":"markdown","2abc8538":"markdown","311d0284":"markdown","4ecd0243":"markdown","2d4d090f":"markdown"},"source":{"f349f3ea":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import minmax_scale\nimport random\nimport cv2\nfrom imgaug import augmenters as iaa\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.experimental import CosineDecay\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation","0cc529e3":"img_folder = '..\/input\/cassava-leaf-disease-classification\/train_images\/'","63af2660":"samples_data = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\nsamples_data = shuffle(samples_data, random_state=42)\nsamples_data[\"filepath\"] = img_folder+samples_data[\"image_id\"]\nsamples_data.head()\n","692abb1b":"batch_size = 8\nimg_size = 512\ninput_shape = (img_size,img_size, 3)\ndropout = 0.4\ntraining_percen = 0.8\ntraining_length = int(len(samples_data)*training_percen)\nvalidation_item_count = len(samples_data)-int(len(samples_data)*training_percen)\ntraining_df = samples_data[:training_length]\nvalidation_df = samples_data[training_length:]\n","16e103e5":"training_data = tf.data.Dataset.from_tensor_slices((training_df.filepath.values, training_df.label.values))\nvalidation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))","13c917f1":"def load_image_and_label_from_path(image_path, label):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntraining_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\nvalidation_data = validation_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n\n\ntraining_data_batches = training_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)\nvalidation_data_batches = validation_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)","bfa81dd1":"adapt_data = tf.data.Dataset.from_tensor_slices(training_df.filepath.values)\ndef adapt_mode(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(img)\n    return img\n\nadapt_data = adapt_data.map(adapt_mode, num_parallel_calls=AUTOTUNE)\nadapt_data_batches = adapt_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)","1206106b":"augmentation = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomCrop(height=img_size, width=img_size),\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        layers.experimental.preprocessing.RandomRotation(0.25),\n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n    ]\n)","6d0bc195":"efficientnet = EfficientNetB3(weights=\"..\/input\/keras-efficientnetb3-no-top-weights\/efficientnetb3_notop.h5\", \n                              include_top=False, \n                              input_shape=input_shape, \n                              drop_connect_rate=dropout)\n\ninputs = Input(shape=input_shape)\naugmented = augmentation(inputs)\nefficientnet = efficientnet(augmented)\npooling = layers.GlobalAveragePooling2D()(efficientnet)\ndropout = layers.Dropout(dropout)(pooling)\noutputs = Dense(5, activation=\"softmax\")(dropout)\nmodel = Model(inputs=inputs, outputs=outputs)\n    \nmodel.summary()","5cbc40a2":"epochs = 3","59cb9c2b":"\ndecay_steps = int(round(len(training_df)\/batch_size))*epochs\ncosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3)\n\ncallbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(cosine_decay), metrics=[\"accuracy\"])","ed9c2632":"\nhistory = model.fit(training_data_batches,\n                  epochs = epochs, \n                  validation_data=validation_data_batches,\n                  callbacks=callbacks)","60a20ab8":"history.history","c9cc1ba1":"history_dict = history.history\n\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(acc) + 1)\nline1 = plt.plot(epochs, acc, label='train_Accuracy', color='red')\nline2 = plt.plot(epochs, val_acc, label='Val_acuuracy',color='green')\n\nplt.title('Accuracy ~ Epochs graph', fontsize=20)\nplt.xlabel('Epochs') \nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","3c006c66":"history_dict = history.history\n\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\nepochs = range(1, len(acc) + 1)\nline1 = plt.plot(epochs, loss, label='train_Accuracy', color='red')\nline2 = plt.plot(epochs, val_loss, label='Val_acuuracy',color='green')\n\nplt.title('Loss ~ Epochs graph', fontsize=20)\nplt.xlabel('Epochs') \nplt.ylabel('Loss')\nplt.legend()\nplt.show()","2abf090f":"model.load_weights(\"best_model.h5\")","abf53c15":"def scan_img(img_path, crop_size=512):\n   \n    \n    img = Image.open(img_path)\n    img_height, img_width = img.size\n    img = np.array(img)\n    \n    y = random.randint(0,img_height-crop_size)\n    x = random.randint(0,img_width-crop_size)\n\n    x_img_origins = [0,img_width-crop_size]\n    y_img_origins = [0,img_height-crop_size]\n    img_list = []\n    for x in x_img_origins:\n        for y in y_img_origins:\n            img_list.append(img[x:x+crop_size , y:y+crop_size,:])\n  \n    return np.array(img_list)\n\n\n\ntest_augmentation = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n    ]\n)","66e3fcf3":"def predict(image_filename, folder, TTA_runs=4):\n\n    \n    localised_predictions = []\n    local_image_list = scan_img(folder+image_filename)\n    for local_image in local_image_list:\n        duplicated_local_image = tf.convert_to_tensor(np.array([local_image for i in range(TTA_runs)]))\n        augmented_images = test_augmentation(duplicated_local_image)\n        \n        predictions = model.predict(augmented_images)\n        localised_predictions.append(np.sum(predictions, axis=0))\n    \n    global_predictions = np.sum(np.array(localised_predictions),axis=0)\n    final_prediction = np.argmax(global_predictions)\n    \n    return final_prediction\n\n\n\ndef predictions(image_list, folder):\n    predictions = []\n    with tqdm(total=len(image_list)) as pbar:\n        for image_filename in image_list:\n            pbar.update(1)\n            predictions.append(predict(image_filename, folder))\n    return predictions\n","b0f4ad65":"from PIL import Image\ntest_dir = '..\/input\/cassava-leaf-disease-classification\/test_images\/'\ntest_imgs = os.listdir(test_dir)\n\npredictions = predictions(test_imgs, test_dir)","ae59516f":"submission = pd.DataFrame({'image_id': test_imgs, 'label': predictions})","c3b7b900":"submission","7a444a66":"submission.to_csv('submission.csv', index = False)","7f81a134":"# Data Augmentation \n\n","9dd87544":"## Loss graph","666b4879":"# Training Model","ad8af75a":"# load model","c22fb1e9":"# Plotting","1485dafe":"# Submission file making","09fc04a2":"# callbacks","f5dbe03d":"# Import libs","2ca1f038":"## Accuracy graph","62e505d6":"## predict","870cbdd2":"# import images ","b9fcad2a":"# Cassava disease classification (keras)","24cc5fe1":"## scan and augmentation","2abc8538":"# Load images from path","311d0284":"# Build model-transfer learning(EfficientNetB3)","4ecd0243":"# Rescaling images","2d4d090f":"# csv file"}}