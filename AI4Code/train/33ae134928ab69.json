{"cell_type":{"20a6d2c8":"code","8339e6d5":"code","efe99663":"code","e7fb2855":"code","d4d92688":"code","be768d54":"code","bb25087e":"code","27c7ecd3":"code","0d85f431":"code","acf08e24":"code","7f6913e6":"code","6ae6a138":"code","21fc48a5":"code","88240523":"code","ff345086":"code","c518b4ae":"code","92fdd145":"code","13fba61b":"code","834724b4":"code","498bf387":"code","4bcae01b":"code","d5403dec":"code","bf99374e":"code","158cad07":"code","85fc9394":"code","a362792d":"code","6384d88d":"code","a29ba680":"code","b394e5ef":"code","7b44ccae":"markdown","c3ccfdf1":"markdown","5bbfa980":"markdown","9b386c24":"markdown","65dbc2d3":"markdown","2dcfa24e":"markdown","cc378131":"markdown","a1a1eb80":"markdown","bba6ba82":"markdown","cb8d3641":"markdown","e07c022f":"markdown","c33a65f9":"markdown","5e5f67d9":"markdown","68411b58":"markdown","aee8ff8b":"markdown","e0d15e3c":"markdown","fac74f4d":"markdown","b028b4b0":"markdown","781dcfa2":"markdown","2309a0ca":"markdown","d2b6acf6":"markdown","53a77122":"markdown","4dd0a305":"markdown","a2207f79":"markdown","30851300":"markdown","1e505fad":"markdown","650c6063":"markdown","8f873cf1":"markdown","e1feac26":"markdown","684e86ba":"markdown","7d393039":"markdown","c0ca2231":"markdown","bed288d2":"markdown","b62bfa44":"markdown","b97c00d3":"markdown","c6e83758":"markdown","a5bf84a8":"markdown","faf67a05":"markdown","2503b0f6":"markdown","8624993e":"markdown","cccfaba7":"markdown","e2d27cad":"markdown","84143c06":"markdown","8a2d1da9":"markdown","eb94358c":"markdown","9d04a9fe":"markdown","9e80272a":"markdown","99053db6":"markdown","ea751a77":"markdown","4f128311":"markdown","ce797a8f":"markdown","9e3d1eec":"markdown","6318eb13":"markdown","dcf3de46":"markdown","53092724":"markdown","fed3944c":"markdown","04856d2c":"markdown","d9c69bff":"markdown","9ee85cd6":"markdown","a057f34c":"markdown","f90efab7":"markdown","26556e29":"markdown","d3cc706f":"markdown","75c7287b":"markdown","6369c376":"markdown","587c3f16":"markdown","547920cd":"markdown","03443643":"markdown","ca759b12":"markdown","f164b24f":"markdown","e4688e8f":"markdown","65e61f39":"markdown","09cadd8f":"markdown","79ea34fa":"markdown","b7607a2e":"markdown"},"source":{"20a6d2c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode, iplot, download_plotlyjs\nimport plotly.graph_objs as go\nimport cufflinks as cf\ninit_notebook_mode(connected=True)\ncf.go_offline()\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8339e6d5":"# Reading dataset in this form, so that I can use it on my laptop also.\ntry:\n    df_mcr = pd.read_csv('..\/input\/multipleChoiceResponses.csv')\n    df_schema = pd.read_csv('..\/input\/SurveySchema.csv')\nexcept Exception as e:\n    pass","efe99663":"# Basic information about Dataset.\nprint(df_mcr.shape)\nprint(\"As one can see there are 395 columns.\")","e7fb2855":"# Let's see the details about the null values.\nnull = df_mcr.isnull().sum()\nprint(null[:30])\n","d4d92688":"df_mcr.head()","be768d54":"gender = df_mcr['Q1'].value_counts().reset_index()\ngender.iplot(kind='pie', labels='index', values='Q1',title='Ration of Gender', pull=0.2, hole=0.2 )","bb25087e":"age = df_mcr['Q2'].value_counts().reset_index()\nage.iplot(kind='bar', x='index', y='Q2', title='Age of respondants', xTitle='Age',\n          yTitle='Number of responses', colors='deepskyblue')","27c7ecd3":"country = df_mcr['Q3'].value_counts().reset_index()[:10]\ncountry.iplot(kind='bar', x='index', y='Q3', \n              title='Top 10 Countries participated in survey', xTitle='Country', yTitle='Number of Respondants')\ncountry.drop([3], axis=0, inplace=True)\ncountry\nvalues = country['Q3'].values\n#print(values)\nname = country['index'].values\n#print(name)\ncode = ['USA','IND','CHN','RUS','BRA','DEU','GBR','CAN','FRA']\ndata = dict(\n        type = 'choropleth',\n        locations = code,\n        z = values,\n        text = name,\n        colorbar = {'title' : 'Number of Participants'},\n      ) \nlayout = dict(\n    title = 'Country Wise Users',\n    geo = dict(\n        showframe = False,\n        projection = {'type':'natural earth'}\n    )\n)\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","0d85f431":"degree = df_mcr['Q4'].value_counts().reset_index()\ndegree.iplot(kind='bar',x='index', y='Q4', title='Top formal educations', xTitle='Degree', \n             yTitle='Frequency', colors='deepskyblue')","acf08e24":"titles = df_mcr['Q6'].value_counts().reset_index()[:10]\ntitles.iplot(kind='bar',x='index', y='Q6', title='Top Current Titles', \n             xTitle='Title', yTitle='Frequency',colors='green')","7f6913e6":"industry = df_mcr['Q7'].value_counts().reset_index()[:10]\nindustry.iplot(kind='bar',x='index', y='Q7', title='Top 10 Current industry', \n             xTitle='Industry', yTitle='Frequency',colors='indigo')","6ae6a138":"experience = df_mcr['Q8'].value_counts().reset_index()[:10]\nexperience.iplot(kind='bar',x='index', y='Q8', title='Average Years of experience', \n             xTitle='Years', yTitle='Frequency',colors='indianred')","21fc48a5":"compensation = df_mcr['Q9'].value_counts().reset_index()[:10]\ncompensation.iplot(kind='bar',x='index', y='Q9', title='Average compensation', \n             xTitle='Amount of compensation', yTitle='Frequency',colors='indianred')\n","88240523":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q11_Part_1'],temp_df.loc[:,'Q11_Part_2'],temp_df.loc[:,'Q11_Part_3'],\np4,p5  = temp_df.loc[:,'Q11_Part_4'],temp_df.loc[:,'Q11_Part_5'],\np6,p7 = temp_df.loc[:,'Q11_Part_6'],temp_df.loc[:,'Q11_Part_7']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7]).reset_index()      # Concating 7 columns of Q7.\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()\nnew_df.columns = ['a','b']\nnew_df.iplot(kind='bar', x='a', y='b', title='Important Activities', xTitle='Activity', colors='brown')    \n","ff345086":"ml = df_mcr['Q10'].value_counts().reset_index()[:10]\nml.iplot(kind='bar',x='index', y='Q10', title='Use of ML ', \n             xTitle='Whether Ml is used or not', yTitle='Frequency',colors='indigo')\n","c518b4ae":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q13_Part_1'],temp_df.loc[:,'Q13_Part_2'],temp_df.loc[:,'Q13_Part_3'],\np4,p5  = temp_df.loc[:,'Q13_Part_4'],temp_df.loc[:,'Q13_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q13_Part_6'],temp_df.loc[:,'Q13_Part_7'],temp_df.loc[:,'Q13_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q13_Part_9'],temp_df.loc[:,'Q13_Part_10'],temp_df.loc[:,'Q13_Part_11']\np12,p13,p14 = temp_df.loc[:,'Q13_Part_12'],temp_df.loc[:,'Q13_Part_13'],temp_df.loc[:,'Q13_Part_14']\np15 = temp_df.loc[:,'Q13_Part_15']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15]).reset_index()      # Concating 7 columns of Q7.\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()\nnew_df.columns = ['a','b']\nnew_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \n","92fdd145":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q14_Part_1'],temp_df.loc[:,'Q14_Part_2'],temp_df.loc[:,'Q14_Part_3'],\np4,p5  = temp_df.loc[:,'Q14_Part_4'],temp_df.loc[:,'Q14_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q14_Part_6'],temp_df.loc[:,'Q14_Part_7'],temp_df.loc[:,'Q14_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q14_Part_9'],temp_df.loc[:,'Q14_Part_10'],temp_df.loc[:,'Q14_Part_11']\n#p12,p13,p14 = temp_df.loc[:,'Q13_Part_12'],temp_df.loc[:,'Q13_Part_13'],temp_df.loc[:,'Q13_Part_14']\n#p15 = temp_df.loc[:,'Q13_Part_15']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11]).reset_index()      # Concating 7 columns of Q7.\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top ONLINE NOTEBOOKS', pull=0.2, hole=0.2)","13fba61b":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q16_Part_1'],temp_df.loc[:,'Q16_Part_2'],temp_df.loc[:,'Q16_Part_3'],\np4,p5  = temp_df.loc[:,'Q16_Part_4'],temp_df.loc[:,'Q16_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q16_Part_6'],temp_df.loc[:,'Q16_Part_7'],temp_df.loc[:,'Q16_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q16_Part_9'],temp_df.loc[:,'Q16_Part_10'],temp_df.loc[:,'Q16_Part_11']\np12,p13,p14 = temp_df.loc[:,'Q16_Part_12'],temp_df.loc[:,'Q16_Part_13'],temp_df.loc[:,'Q16_Part_14']\np15,p16,p17 = temp_df.loc[:,'Q16_Part_15'], temp_df.loc[:,'Q16_Part_16'], temp_df.loc[:,'Q16_Part_17']\np18 = temp_df.loc[:,'Q16_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Programming Languages', pull=0.2, hole=0.2)","834724b4":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q19_Part_1'],temp_df.loc[:,'Q19_Part_2'],temp_df.loc[:,'Q19_Part_3'],\np4,p5  = temp_df.loc[:,'Q19_Part_4'],temp_df.loc[:,'Q19_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q19_Part_6'],temp_df.loc[:,'Q19_Part_7'],temp_df.loc[:,'Q19_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q19_Part_9'],temp_df.loc[:,'Q19_Part_10'],temp_df.loc[:,'Q19_Part_11']\np12,p13,p14 = temp_df.loc[:,'Q19_Part_12'],temp_df.loc[:,'Q19_Part_13'],temp_df.loc[:,'Q19_Part_14']\np15,p16,p17 = temp_df.loc[:,'Q19_Part_15'], temp_df.loc[:,'Q19_Part_16'], temp_df.loc[:,'Q19_Part_17']\np18 = temp_df.loc[:,'Q19_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Machine Learning Libraries', pull=0.2, hole=0.2)","498bf387":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q21_Part_1'],temp_df.loc[:,'Q21_Part_2'],temp_df.loc[:,'Q21_Part_3'],\np4,p5  = temp_df.loc[:,'Q21_Part_4'],temp_df.loc[:,'Q21_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q21_Part_6'],temp_df.loc[:,'Q21_Part_7'],temp_df.loc[:,'Q21_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q21_Part_9'],temp_df.loc[:,'Q21_Part_10'],temp_df.loc[:,'Q21_Part_11']\np12,p13 = temp_df.loc[:,'Q21_Part_12'],temp_df.loc[:,'Q21_Part_13']\n#p15,p16,p17 = temp_df.loc[:,'Q16_Part_15'], temp_df.loc[:,'Q16_Part_16'], temp_df.loc[:,'Q16_Part_17']\n#p18 = temp_df.loc[:,'Q16_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Libraries for Visualization', pull=0.2, hole=0.2)","4bcae01b":"time = df_mcr['Q24'].value_counts().reset_index()\ntime.iplot(kind='pie', labels='index', values='Q24',title='Time in Year ', pull=0.2, hole=0.2 )","d5403dec":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q28_Part_1'],temp_df.loc[:,'Q28_Part_2'],temp_df.loc[:,'Q28_Part_3'],\np4,p5  = temp_df.loc[:,'Q28_Part_4'],temp_df.loc[:,'Q28_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q28_Part_6'],temp_df.loc[:,'Q28_Part_7'],temp_df.loc[:,'Q28_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q28_Part_9'],temp_df.loc[:,'Q28_Part_10'],temp_df.loc[:,'Q28_Part_11']\np12,p13,p14 = temp_df.loc[:,'Q28_Part_12'],temp_df.loc[:,'Q28_Part_13'],temp_df.loc[:,'Q28_Part_14']\np15,p16,p17 = temp_df.loc[:,'Q28_Part_15'], temp_df.loc[:,'Q28_Part_16'], temp_df.loc[:,'Q28_Part_17']\np18 = temp_df.loc[:,'Q28_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Machine Learning Products', pull=0.2, hole=0.2)","bf99374e":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q30_Part_1'],temp_df.loc[:,'Q30_Part_2'],temp_df.loc[:,'Q30_Part_3'],\np4,p5  = temp_df.loc[:,'Q30_Part_4'],temp_df.loc[:,'Q30_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q30_Part_6'],temp_df.loc[:,'Q30_Part_7'],temp_df.loc[:,'Q30_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q30_Part_9'],temp_df.loc[:,'Q30_Part_10'],temp_df.loc[:,'Q30_Part_11']\np12,p13,p14 = temp_df.loc[:,'Q30_Part_12'],temp_df.loc[:,'Q30_Part_13'],temp_df.loc[:,'Q30_Part_14']\np15,p16,p17 = temp_df.loc[:,'Q30_Part_15'], temp_df.loc[:,'Q30_Part_16'], temp_df.loc[:,'Q30_Part_17']\np18 = temp_df.loc[:,'Q30_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Big Data and Analytic Products', pull=0.2, hole=0.2)","158cad07":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q31_Part_1'],temp_df.loc[:,'Q31_Part_2'],temp_df.loc[:,'Q31_Part_3'],\np4,p5  = temp_df.loc[:,'Q31_Part_4'],temp_df.loc[:,'Q31_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q31_Part_6'],temp_df.loc[:,'Q31_Part_7'],temp_df.loc[:,'Q31_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q31_Part_9'],temp_df.loc[:,'Q31_Part_10'],temp_df.loc[:,'Q31_Part_11']\np12 = temp_df.loc[:,'Q31_Part_12']\n#p15,p16,p17 = temp_df.loc[:,'Q30_Part_15'], temp_df.loc[:,'Q30_Part_16'], temp_df.loc[:,'Q30_Part_17']\n#p18 = temp_df.loc[:,'Q30_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Type of Data', pull=0.2, hole=0.2)","85fc9394":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q33_Part_1'],temp_df.loc[:,'Q33_Part_2'],temp_df.loc[:,'Q33_Part_3'],\np4,p5  = temp_df.loc[:,'Q33_Part_4'],temp_df.loc[:,'Q33_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q33_Part_6'],temp_df.loc[:,'Q33_Part_7'],temp_df.loc[:,'Q33_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q33_Part_9'],temp_df.loc[:,'Q33_Part_10'],temp_df.loc[:,'Q33_Part_11']\n#p12 = temp_df.loc[:,'Q31_Part_12']\n#p15,p16,p17 = temp_df.loc[:,'Q30_Part_15'], temp_df.loc[:,'Q30_Part_16'], temp_df.loc[:,'Q30_Part_17']\n#p18 = temp_df.loc[:,'Q30_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\nnew_df.iplot(kind='bar', x='a', y='b', title='TOP Places for Dataset', xTitle='Place', colors='deepskyblue')    \n#new_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Type of Data', pull=0.2, hole=0.2)","a362792d":"online = df_mcr['Q37'].value_counts().reset_index()[:10]\nonline.iplot(kind='pie', labels='index', values='Q37',title='Top 10 Online Platforms to learn Data Science ',\n             pull=0.2, hole=0.2 )","6384d88d":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2,p3 = temp_df.loc[:,'Q38_Part_1'],temp_df.loc[:,'Q38_Part_2'],temp_df.loc[:,'Q38_Part_3'],\np4,p5  = temp_df.loc[:,'Q38_Part_4'],temp_df.loc[:,'Q38_Part_5'],\np6,p7,p8 = temp_df.loc[:,'Q38_Part_6'],temp_df.loc[:,'Q38_Part_7'],temp_df.loc[:,'Q38_Part_8']\np9,p10,p11 = temp_df.loc[:,'Q38_Part_9'],temp_df.loc[:,'Q38_Part_10'],temp_df.loc[:,'Q38_Part_11']\np12,p13,p14 = temp_df.loc[:,'Q38_Part_12'],temp_df.loc[:,'Q38_Part_13'],temp_df.loc[:,'Q38_Part_14']\np15,p16,p17 = temp_df.loc[:,'Q38_Part_15'], temp_df.loc[:,'Q38_Part_16'], temp_df.loc[:,'Q38_Part_17']\np18 = temp_df.loc[:,'Q38_Part_18']\n\nnew_df = pd.concat([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14,p15,p16,p17,p18]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='Top 10 Websites for Data Science News', pull=0.2, hole=0.2)","a29ba680":"temp_df = df_mcr.drop([0],axis=0)\ntemp_df.head()\n\np1,p2 = temp_df.loc[:,'Q39_Part_1'],temp_df.loc[:,'Q39_Part_2']\n\n\nnew_df = pd.concat([p1,p2]).reset_index()      \n\nnew_df.dropna(inplace=True)\nnew_df = new_df[0].value_counts().reset_index()[:10]\nnew_df.columns = ['a','b']\n#new_df.iplot(kind='bar', x='a', y='b', title='TOP IDE', xTitle='IDE', colors='deepskyblue')    \nnew_df.iplot(kind='pie', labels='a', values='b', title='View on quality of OnlineLearning and Bootcamp',\n             pull=0.2, hole=0.2)","b394e5ef":"online = df_mcr['Q40'].value_counts().reset_index()[:10]\nonline.iplot(kind='bar', x='index', y='Q40',title='Academic Achievement VS Independent projects for Data Science ',\n             xTitle='Comparision', colors='deepskyblue' )","7b44ccae":"#### ====================================================================================================","c3ccfdf1":"### Q6). Top 10 Industries of respondants.","5bbfa980":"### Q17). Top 10 Machine Learning products that are used at work.","9b386c24":"### Q20). Top 10 places to find Pubic Datasets.","65dbc2d3":"### Q4). Top 5 formal educations of respondants.","2dcfa24e":"* ML is highly used in industries.\n* Maximum are exploring ML, means they are new to ML and they want to use ML.","cc378131":"#### ==================================================================================================","a1a1eb80":"#### =====================================================================================================","bba6ba82":"### Q12). Online Notebooks which are highly used people.","cb8d3641":"#### Observations:-\n* Maximum number of responses are from USA and India.\n* It indicates that maximum number of people who know Kaggle platforms are from USA and India.\n* Maximum number of people who are learning Data Science are from USA and India.\n* It's good to see India at this place.","e07c022f":"* More than 80% of respondences are male.","c33a65f9":"#### ====================================================================================================","5e5f67d9":"#### ====================================================================================================","68411b58":"#### Observations:-\n* Maximum number of people are new in this field with experience of 1 to 3 years.\n* I think I choose data science at a correct time.","aee8ff8b":"#### =====================================================================================================","e0d15e3c":"<img src='https:\/\/drive.google.com\/uc?id=1jLLEThALBvFGa01gvpQkNnbvlJUml1g2' width=800 >","fac74f4d":"#### ====================================================================================================","b028b4b0":"* Mainly people interact with numerical data then by text data and then by categorical data.\n* So practice on these type of data will help.\n","781dcfa2":"#### ===================================================================================================","2309a0ca":"#### Observations:- \n* 40% people are learning from Coursera.\n* Datacamp, udemy are at 2nd and 3rd places with 12% each.\n* Mainly people are learning Data Science from online courses.\n* Online courses are very flexible, so they are in high demnad.","d2b6acf6":"### Q24). Academic Achievement VS Independent projects for Data Science.","53a77122":"### Q15). Top 10 Libraries for Visualization.","4dd0a305":"#### ====================================================================================================","a2207f79":"## All the graphs are interactive","30851300":"#### ===================================================================================================","1e505fad":"#### Observations:-\n* 50% people love to learn from online sources or from bootcamp.\n* This is a new type of education revolution.\n","650c6063":"* Maximum number of people are in age group of 25 to 35.\n* As this is our demographic dividents.","8f873cf1":"#### =====================================================================================================","e1feac26":"#### Observations:-\n* Kaggle kernels, they are highly used Data science people.\n* Followed by Jupyter Hub.\n* This is the reason I choose Kaggle + Data Science.\n* 28% people use no online notebook as they prefer to work on thier own machine.\n\n","684e86ba":" ### Q23). People view on the quality of Online learning and  bootcamp.","7d393039":"### Q7). Average years of experience of people who know about data science.","c0ca2231":"# BASIC ANALYSIS","bed288d2":"### Q11). Top 10 IDE.","b62bfa44":"#### ==================================================================================================","b97c00d3":"### Q5). Top 10 Current Job Title.","c6e83758":"### Q14). Top 10 machine Learning libraries.","a5bf84a8":"#### ====================================================================================================","faf67a05":"### Q21). Top 10  Online Platforms to learn Data Science.","2503b0f6":"### Q9). Important Activities.","8624993e":"#### ====================================================================================================","cccfaba7":"### Q16). How long have people been writing code to analysis the data.","e2d27cad":"<img src='https:\/\/drive.google.com\/uc?id=1rUzGRQ__HvXBUGK1CH4DuxCCH-NxXXuf' width=800>","84143c06":"#### ===================================================================================================\n#### ===================================================================================================\n#### ===================================================================================================","8a2d1da9":"#### ===================================================================================================","eb94358c":"#### ===================================================================================================","9d04a9fe":"### Q13). Top 10 Programming Languages.","9e80272a":"* Maximum people get their dataset from kaggle.\n* As expected kaggle lead the race.\n* The reason I choose kaggle.\n","99053db6":"### Observations:-\n* Scikit-learn topped the list followed by tensorflow and by keras.\n* 22% people use Scikit-learn.\n* 18% people use Tensorflow.\n* 14% people use Keras.","ea751a77":"### Q19). Top 10 types of Data people currently interact.","4f128311":"### Q3). Top 10 countries participating in survey.","ce797a8f":"#### Observations:-\n* Matplotlib,the basic of visualization library, topped the list.\n* Seaborn,more advance than matplotlib and it is based on maplotlib, is at 2nd rank.\n* Plotly, which I am using right now, is at 4th place.\n* Feeling happy to see this list.","9e3d1eec":"#### ==================================================================================================","6318eb13":"### Q2). Ages of maximum of respondants.\n","dcf3de46":"#### ===================================================================================================","53092724":"#### Observations:-\n* Kaggleform is at top place with 18%.\n* It is followed by mediumblog post.\n* Kaggle is again at the top.\n* Many things I am learning from kaggle platform.\n","fed3944c":"### Q18). Top 10 Big Data and Analytics Products.","04856d2c":"### Q8). Current Yearly compensation of respondants.","d9c69bff":"* Independent projects are more important than academic achievement.","9ee85cd6":"* As one can see there are so many null values in columns but we do not have to remove them, as they  are \n* part of multiple choice questions.","a057f34c":"# DATA SCIENCE ANALYSIS","f90efab7":"#### =====================================================================================================","26556e29":"### Q22). Top 10 Websites for Data Science News.","d3cc706f":"#### =================================================================================================","75c7287b":"\n#### ================================================================================================","6369c376":"#### Observations:-\n* Jupyter notebook is highly used by people follwed by RStudio.\n* Notebook++ is also in list.\n* PyCharm is mainly used backhand programmers. ","587c3f16":"#### Observations:-\n* Mainly people are using it for 1 to 5 year.\n* Totaly new field and expanding at a high pace.\n* Maybe my step to choose Data Science is correct, let's see in future.\n","547920cd":"#### =====================================================================================================","03443643":"## ABOUT NOTEBOOK:-\n* After survey conducted by kaggle and I am as an enthusiat to learn Data Science, started thinking to do analysis on their dataset.\n* This thing encouraged me to make this notebook.\n* In this notebook I am analysing kaggle survey dataset by forming questions and then answering them.\n* The questions which I am analysing are given below:-\n#### Basic analysis:-\n* Q1). Ratio of gender in survey.\n* Q2). Ages of maximum of respondants.\n* Q3). Top 10 countries participating in survey.\n* Q4). Top 5 formal educations of respondants.\n* Q5). Top 10 Current Job Title.\n* Q6). Top 10 Industries of respondants.\n* Q7). Average years of experience of people who know about data science.\n* Q8). Current Yearly compensation of respondants.\n* Q9). Important Activities.\n## Data Science Analysis:-\n* Q10). Current Employers incorporate Machine Learning or not.\n* Q11). Top 10 IDE.\n* Q12). Online Notebooks which are highly used people.\n*  Q13). Top 10 Programming Languages.\n*  Q14). Top 10 machine Learning libraries.\n* Q15). Top 10 Libraries for Visualization.\n* Q16). How long have people been writing code to analysis the data.\n* Q17). Top 10 Machine Learning products that are used at work.\n* Q18). Top 10 Big Data and Analytics Products.\n* Q19). Top 10 types of Data people currently interact.\n* Q20). Top 10 places to find Pubic Datasets. \n* Q21). Top 10  Online Platforms to learn Data Science.\n* Q22). Top 10 Websites for Data Science News.\n* Q23). People view on the quality of Online learning and  bootcamp.\n* Q24). Academic Achievement VS Independent projects for Data Science.\n","ca759b12":"#### ====================================================================================================","f164b24f":"# IF YOU LIKE THIS KERNEL,THEN PLEASE UPVOTE.\n<img src='https:\/\/drive.google.com\/uc?id=1snfO_T6LnQAgj4ps3whAvcfkipEOEORj' width=600>","e4688e8f":"### Q1). Ratio of gender in survey.","65e61f39":"#### Observations:-\n* Many respondants from students are also there.\n* Till now data science is widely used by computer, education, or finanace industries.\n* Government Sectors are far away from using data science, they should start to use data science otherwise they will lack behind from other Industries.****","09cadd8f":"### Q10). Current Employers incorporate Machine Learning or not.","79ea34fa":"#### Observations:-\n* As aspected python, sql and R at the top.\n<img src='https:\/\/drive.google.com\/uc?id=1iObz8QN2D3OS83tXeJQQ51VV3d2vXFUx' width=500>\n* In future python will eat maximum languages.\n* 31% data science people use python.\n* SQL is also neccesary to connect with data base, which is at 16%.","b7607a2e":"# I CHOOSE KAGGLE + DATA SCIENCE."}}