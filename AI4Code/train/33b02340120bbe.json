{"cell_type":{"cbfd915e":"code","768415d3":"code","71dd4948":"code","cfacbfd1":"code","2021a5d6":"code","46b720b0":"code","bc691b5b":"code","1373867a":"code","b247732c":"code","afc504ea":"code","78af61dc":"code","96676dd7":"code","9b518b51":"code","58afe938":"code","7eaf95cf":"code","ebeadfe6":"code","89ee504d":"markdown","d94d7373":"markdown","bb80f2f5":"markdown","cabd3105":"markdown","f318c93c":"markdown","e5364309":"markdown","15f24f72":"markdown","57c0681a":"markdown","5b327f24":"markdown","10d7bc3c":"markdown","4e009a91":"markdown","a1234a0c":"markdown","ce325efd":"markdown","0896b775":"markdown"},"source":{"cbfd915e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","768415d3":"pd.read_csv('\/kaggle\/input\/bank-customers\/Churn Modeling.csv')","71dd4948":"dataset = pd.read_csv('\/kaggle\/input\/bank-customers\/Churn Modeling.csv')\nX = dataset.iloc[:, 3:13].values\ny = dataset.iloc[:, 13].values","cfacbfd1":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder\nle_1 = LabelEncoder()\nX[:,1] = le_1.fit_transform(X[:,1])\nle_2 = LabelEncoder()\nX[:,2] = le_2.fit_transform(X[:,2])\nohe = OneHotEncoder(categorical_features = [1])\nX = ohe.fit_transform(X).toarray()\nX = X[:, 1:]","2021a5d6":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 0)","46b720b0":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","bc691b5b":"import keras\nkeras.__version__","1373867a":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","b247732c":"classifier = Sequential()","afc504ea":"#Adding the input layer and first layer\nclassifier.add(Dense(activation = 'selu', input_dim = 11, units = 6, kernel_initializer = 'lecun_normal'))\nclassifier.add(Dropout(rate = 0.1))\n#Adding the second hidden layer\nclassifier.add(Dense(activation='selu', units = 6, kernel_initializer=\"lecun_normal\"))\nclassifier.add(Dropout(rate = 0.1))\n#Adding the third hidden layer\nclassifier.add(Dense(activation = 'selu', units = 6, kernel_initializer = 'lecun_normal'))\nclassifier.add(Dropout(rate  =0.1))\n#Adding the fourth hidden layer\nclassifier.add(Dense(activation = 'selu', units = 6, kernel_initializer = 'lecun_normal'))\nclassifier.add(Dropout(rate  =0.1))\n#Adding the output layer\nclassifier.add(Dense(activation = 'sigmoid', units = 1, kernel_initializer = 'uniform'))","78af61dc":"classifier.compile(optimizer = 'nadam', loss = 'binary_crossentropy', metrics = ['accuracy'])","96676dd7":"classifier.fit(X_train,y_train,batch_size = 32, epochs = 100)","9b518b51":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred>0.5)","58afe938":"y_pred","7eaf95cf":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\ncm","ebeadfe6":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test,y_pred)\naccuracy","89ee504d":"**MAKING ANN**","d94d7373":"86.55% accuracy!","bb80f2f5":"Making preditions on the test set","cabd3105":"One-hot-encoding the categorical variable \"Geography\" and Label-Encoding the categorical variable \"Gender\"","f318c93c":"Using accuracy_score to analyse the accuracy on the test set.","e5364309":"Initialising the ANN","15f24f72":"***MAKING PREDICTIONS AND ANALYSING THE MODEL***","57c0681a":"Reading the dataset and setting the values for dependent and independent variables.","5b327f24":"Compiling the model using nadam optimiser","10d7bc3c":"***BUILDING A 4 HIDDEN-LAYERED ANN USING SELU ACTIVATION FUNCTION***","4e009a91":"Feature Scaling","a1234a0c":"Training the model with a batch size of 32 for 100 epochs.","ce325efd":"Splitting the training and testing dataset","0896b775":"Using Confusion matrix to see the number of correct and incorrect predictions"}}