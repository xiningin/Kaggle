{"cell_type":{"e49c459d":"code","53e7238a":"code","3b246fe7":"code","aa984e83":"code","04c05754":"code","4f5c709f":"code","a03e494f":"code","a7bdc90a":"code","ad616ac0":"code","19406875":"code","7ec8bcaa":"code","57e5abc6":"code","99c7e4bf":"code","be8b48f3":"code","c5e2b424":"code","1cd5e4e0":"code","3888cd80":"code","a8806992":"code","e504d079":"code","772b2f60":"code","a94c8953":"code","4b3993cc":"code","4685198b":"code","a97615fd":"code","4b024c9f":"code","97470b2b":"code","49162659":"code","103c2181":"code","64576245":"code","7d3512e2":"markdown","2feab570":"markdown","07d0a24b":"markdown","345e296e":"markdown","d19d90eb":"markdown","fcbafe7a":"markdown","644acd31":"markdown","2a3bd22e":"markdown"},"source":{"e49c459d":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import f1_score, accuracy_score\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","53e7238a":"train = pd.read_csv('\/kaggle\/input\/intercampusai2019\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/intercampusai2019\/test.csv')\nsample_submission2 = pd.read_csv('\/kaggle\/input\/intercampusai2019\/sample_submission2.csv')","3b246fe7":"test.shape, train.shape","aa984e83":"print ('Ratio of Test to Train ',(16496 \/(train.shape[0] +test.shape[0]), 38312 \/(train.shape[0] +test.shape[0])))","04c05754":"def encode(df):\n    df['Gender'] = df.Gender.replace({\n        'Female': 0,\n        'Male': 1,\n        })\n    df['Foreign_schooled'] = df.Foreign_schooled.replace({\n    'No': 0,\n    'Yes': 1,\n    })\n    df['Past_Disciplinary_Action'] = df.Past_Disciplinary_Action.replace({\n    'No': 0,\n    'Yes': 1,\n    })\n    df['Previous_IntraDepartmental_Movement'] = df.Previous_IntraDepartmental_Movement.replace({\n    'No': 0,\n    'Yes': 1,\n    })\n    df['No_of_previous_employers'] = df.No_of_previous_employers.replace({\n    '0': 0,\n    '1': 1,\n    '2': 2,\n    '3': 3,\n    '4': 4,\n    '5': 5,\n    'More than 5': 6\n    })\n    df['Division'] = df.Division.replace({\n    'Commercial Sales and Marketing': 0,\n    'Customer Support and Field Operations': 1,\n    'Sourcing and Purchasing': 2,\n    'Information Technology and Solution Support': 3,\n    'Information and Strategy': 4,\n    'Business Finance Operations': 5,\n    'People\/HR Management': 6,\n    'Regulatory and Legal services': 7,\n    'Research and Innovation': 8,\n    })\n    df['Qualification'] = df.Qualification.replace({\n    'First Degree or HND': 1,\n    'MSc, MBA and PhD': 2,\n    'Non-University Education': 0\n    })\n    df['Channel_of_Recruitment'] = df.Channel_of_Recruitment.replace({\n    'Agency and others': 1,\n    'Direct Internal process': 0,\n    'Referral and Special candidates': 2\n    })\n    df['Marital_Status'] = df.Marital_Status.replace({\n    'Married': 2,\n    'Single': 1,\n    'Not_Sure': 0\n    })\n    df['Last_performance_score'] = df.Last_performance_score.replace({\n     0.0: 0,\n     2.5: 1,\n     5.0: 2,\n     7.5: 3,\n     10.0: 4,\n     12.5: 5\n    })\n    ","4f5c709f":"encode(train)\nencode(test)","a03e494f":"test.info()","a7bdc90a":"all_data = pd.concat([train, test])\nall_data.Qualification.fillna(0, inplace = True)\nall_data['emplo_year'] = all_data.Year_of_recruitment - all_data.Year_of_birth\nall_data['age'] = 2019 - all_data.Year_of_birth","ad616ac0":"# all_data['Training_score_average'][all_data['Training_score_average'] < 34]=34\n# all_data['Training_score_average'][all_data['Training_score_average'] > 86]=86 \n# # lgb best","19406875":"all_data['score_2'] = (all_data.Training_score_average)**2\nall_data['score_3'] = (all_data.Training_score_average)**3\nall_data['score_perf'] = (all_data.Training_score_average)\/(all_data.Last_performance_score)\nall_data['score_perf2'] = (all_data.Training_score_average)+(all_data.Last_performance_score)\nall_data['score_perf4'] = ((all_data.Training_score_average)+(all_data.Targets_met))\/all_data.Trainings_Attended\n\nall_data['score_perf3'] = ((all_data.Training_score_average)+(all_data.Last_performance_score))\/all_data.Trainings_Attended\nall_data['Targets_met_Previos'] = (all_data.Targets_met) + (all_data.Previous_Award)","7ec8bcaa":"all_data.columns","57e5abc6":"all_data['Division_Score'] = all_data['Division'] + np.digitize(all_data['Training_score_average'], [30, 40, 50, 60, 70, 80, 90, 100])\nall_data['Targets_met_Score'] = all_data['Targets_met'] + np.digitize(all_data['Training_score_average'], [30, 40, 50, 60, 70, 80, 90, 100])\nall_data['LPS_Score'] = all_data['Last_performance_score'] + np.digitize(all_data['Training_score_average'], [30, 40, 50, 60, 70, 80, 90, 100])\nall_data['Division_Targets_met'] = all_data['Division'] + all_data['Targets_met']\nall_data['Division_LPS'] = all_data['Last_performance_score'] + all_data['Targets_met']","99c7e4bf":"all_data['max_training_by_Division'] = all_data['Division'].map(all_data.groupby('Division')['Training_score_average'].max())\nall_data['Division_training_max_ratio'] = all_data['Training_score_average'] \/ all_data['max_training_by_Division']\nall_data['min_training_by_Division'] = all_data['Division'].map(all_data.groupby('Division')['Training_score_average'].min())\nall_data['Division_training_min_ratio'] = all_data['Training_score_average'] \/ all_data['min_training_by_Division']\nall_data['std_training_by_Division'] = all_data['Division'].map(all_data.groupby('Division')['Training_score_average'].std())\nall_data['Division_training_std_ratio'] = all_data['Training_score_average'] \/ all_data['std_training_by_Division']","be8b48f3":"all_data['mean_training_by_Division'] = all_data['Division'].map(all_data.groupby('Division')['Training_score_average'].mean())\nall_data['Division_training_mean_Divider'] = all_data['Training_score_average'] \/ all_data['mean_training_by_Division']\n\nall_data['mean_rating_by_Division'] = all_data['Division'].map(all_data.groupby(['Division','State_Of_Origin'])['Training_score_average'].mean())\nall_data['Division_rating_mean_Divider'] = all_data['Training_score_average'] \/ all_data['mean_rating_by_Division']\nall_data['mean_Targets_met_by_Division'] = all_data['Division'].map(all_data.groupby('Division')['Targets_met'].mean())\n","c5e2b424":"all_data.head()","1cd5e4e0":"all_data.columns","3888cd80":"feat = ['Channel_of_Recruitment', 'Division', 'EmployeeNo',\n        'Last_performance_score', \n       'Previous_Award',\n       'Promoted_or_Not', 'Qualification','Targets_met',\n       'Training_score_average', 'Trainings_Attended',\n       'emplo_year', 'age','score_perf3',\n       'score_perf', 'score_perf2', 'score_perf4', \n        'Division_Score','LPS_Score', 'Division_LPS',\n       'Targets_met_Score', 'Division_Targets_met', \n       'mean_training_by_Division',\n       'Division_training_mean_Divider', 'mean_Targets_met_by_Division','mean_rating_by_Division', 'Division_rating_mean_Divider']","a8806992":"# Label encode region\nall_data.State_Of_Origin = all_data.State_Of_Origin.astype('category').cat.codes\nall_data[['Qualification','Last_performance_score']] = all_data[['Qualification','Last_performance_score']].astype('int32')","e504d079":"train.shape","772b2f60":"new_train = all_data[feat][:38312]\nnew_test = all_data[feat][38312:]\n\n# new_train = all_data[:38312]\n# new_test = all_data[38312:]","a94c8953":"Target_name=\"Promoted_or_Not\"\nnot_used_cols=[Target_name, 'EmployeeNo'\n       ]\nfeatures_name=[ f for f in new_train.columns if f not in not_used_cols]","4b3993cc":"new_train.head()","4685198b":"params = {\"objective\": \"binary\",\n          \"booster\": \"gbtree\",\n          \"eta\": 0.01,\n#           \"max_depth\":6,\n#           'min_child_weight':2,\n#           \"categorical_feature\":cat_feat,\n#           'is_unbalance': True\n          \"subsample\": 0.9,\n#           \"colsample_bytree\": 0.7,\n#           \"gamma\": 0.5,\n#           \"alpha\": 0.04,\n#           \"min_child_weight\": 10,\n          'colsample_bytree': 0.8,     \n          'eval_metric':'binary_logloss',\n          'metric':'binary_logloss'\n          }","a97615fd":"model = []\nimport numpy as np, pandas as pd, lightgbm as lgb, warnings\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')\nval_score =[]\ntrain_score = []\nbest_boost = []\n\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1996)\noof =  np.zeros(len(new_train))\npredictions = np.zeros(len(new_test))\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(new_train.values, new_train.Promoted_or_Not.values)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(new_train.iloc[trn_idx][features_name], label=new_train['Promoted_or_Not'].iloc[trn_idx])\n    val_data = lgb.Dataset(new_train.iloc[val_idx][features_name], label=new_train['Promoted_or_Not'].iloc[val_idx],reference=trn_data)\n    \n    clf = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=50, early_stopping_rounds = 100)\n    model.append(clf)\n    \n    oof[val_idx] = clf.predict(new_train.iloc[val_idx][features_name], num_iteration=clf.best_iteration)\n    predictions += clf.predict(new_test[features_name], num_iteration=clf.best_iteration) \/ folds.n_splits\n    \n    \n    val_score.append(clf.best_score['valid_1']['binary_logloss'])\n    train_score.append(clf.best_score['training']['binary_logloss'])\n    best_boost.append(clf.best_iteration)","4b024c9f":"i=1\nfor mod in model:\n    lgb.plot_importance(mod,xlabel='Feature importance' + str(i)) \n    i=i+1","97470b2b":"print('Xgb cv_mean', np.asarray(val_score, dtype=np.float32).mean())\nprint('Xgb cv_std', np.asarray(val_score, dtype=np.float32).std())","49162659":"print(\"micro F1 CV score: {:<8.5f}\".format(f1_score(new_train['Promoted_or_Not']  , (oof>= 0.5).astype(int), average='micro')))  # present Best","103c2181":"print(\"F1 CV score: {:<8.5f}\".format(f1_score(new_train['Promoted_or_Not'] , (oof>= 0.5).astype(int))))  # present Best","64576245":"pd.DataFrame({\"EmployeeNo\": new_test.EmployeeNo.values, 'Promoted_or_Not':(predictions >= 0.5).astype(int)}).to_csv('output_submission.csv', index=False)","7d3512e2":"## Data Preprocessing","2feab570":"### LGB","07d0a24b":"## Split data","345e296e":"Past_Disciplinary_action is bad for all_fold , \nafter confirming from 2  seed value and 2 importance type i might drop this value down","d19d90eb":"## Feature Importance","fcbafe7a":"### Add new features","644acd31":"## Evaluation","2a3bd22e":"## Categorical Encoding"}}