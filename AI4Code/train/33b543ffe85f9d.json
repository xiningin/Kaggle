{"cell_type":{"8c2502bd":"code","bac5aaad":"code","6a6cb4f6":"code","d1a9407e":"code","6922efc8":"code","83be5789":"code","a866c8df":"code","ff9fe208":"code","d3eb42a9":"code","c72f899e":"code","91c42a45":"code","86c84a8c":"code","2d4eb57c":"code","d6ebcf2c":"code","eaca7822":"code","f813f2e3":"code","cc6f6f16":"code","54c356db":"code","2f6fcd7d":"code","7404eae3":"code","e33c2dc3":"code","d43ec3a9":"code","b5ed3c9e":"code","922e374b":"code","05331bb9":"code","5a0f3006":"code","90f4a07f":"code","70865ac7":"code","bc649449":"code","3daea613":"code","d4f647f3":"code","32ad0124":"code","0d6d4a61":"code","fdec1b38":"code","13873ef9":"code","f2f9cb1d":"code","24944038":"code","18d2dac9":"markdown","cf7d6ff0":"markdown","6c52e329":"markdown","c65b6ac4":"markdown","44c14970":"markdown","40d08be5":"markdown","365534a2":"markdown","e18bb2b4":"markdown","493564c4":"markdown","0dbc061c":"markdown","d18565a4":"markdown","85f9c01e":"markdown","4ce6a0a6":"markdown","d7b4ef24":"markdown","7957a496":"markdown","f10dc17c":"markdown","62e30678":"markdown","6a48f672":"markdown","128c0714":"markdown","87b7f4b2":"markdown","109b33d5":"markdown"},"source":{"8c2502bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bac5aaad":"df = pd.read_csv(\"\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")\ndf.head()","6a6cb4f6":"df.shape","d1a9407e":"import matplotlib.pyplot as plt\ndef plot_figure(index,column):\n    plt.subplot(6,2,index)\n    plt.title(column)\n    plt.plot(df[column])\n    \nplt.figure(figsize=(10,10))\n\nfor index , column in enumerate(df.columns):\n    if index+1<=len(df.columns):\n        plot_figure(index+1, column)\n\nplt.tight_layout()","6922efc8":"df.dtypes","83be5789":"df.isnull().any()","a866c8df":"import seaborn as sns\n#correlation matrix\ncorrmat = df.corr()\nk = 12 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'quality')['quality'].index\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1)\nplt.figure(figsize=(8,8))\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","ff9fe208":"input_cols = list(df.columns)[:-1]\ninput_cols","d3eb42a9":"output_cols = ['quality']","c72f899e":"def dataframe_to_arrays(df):\n    # Make a copy of the original dataframe\n    df1 = df.copy(deep=True)\n    # Extract input & outupts as numpy arrays\n    inputs_array = df1[input_cols].to_numpy()\n    targets_array = df1[output_cols].to_numpy()\n    return inputs_array, targets_array","91c42a45":"inputs_array, targets_array = dataframe_to_arrays(df)\ninputs_array, targets_array","86c84a8c":"inputs_array.shape,targets_array.shape","2d4eb57c":"import torch\ninputs = torch.Tensor(inputs_array)\ntargets = torch.Tensor(targets_array)","d6ebcf2c":"from torch.utils.data import DataLoader, TensorDataset, random_split\ndataset = TensorDataset(inputs, targets)","eaca7822":"df.shape","f813f2e3":"num_rows = len(df)\nval_percent = 0.01 # between 0.1 and 0.2\nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size\n\n\ntrain_df, val_df = random_split(dataset, [train_size, val_size]) ","cc6f6f16":"batch_size = 50","54c356db":"train_loader = DataLoader(train_df, batch_size, shuffle=True)\nval_loader = DataLoader(val_df, batch_size)","2f6fcd7d":"input_cols","7404eae3":"output_cols","e33c2dc3":"input_size = len(input_cols)\noutput_size = len(output_cols)","d43ec3a9":"import torch.nn as nn\nclass WineModel(nn.Module):\n    def __init__(self):\n        super().__init__()     \n        self.linear = nn.Linear(input_size, output_size) # fill this (hint: use input_size & output_size defined above)\n        #model initialized with random weight\n        \n    def forward(self, xb):\n        out = self.linear(xb)             # batch wise forwarding\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)         \n        # Calcuate loss\n        loss = F.l1_loss(out, targets)  # batch wise training step and loss\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss =F.l1_loss(out, targets)       # batch wise validation and loss    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine val losses of all batches as average\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","b5ed3c9e":"model =  WineModel()","922e374b":"list(model.parameters())","05331bb9":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)  #appends total validation loss of whole validation set epoch wise\n    return history","5a0f3006":"import torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\n","90f4a07f":"result = evaluate(model,val_loader) # Use the the evaluate function\nprint(result)","70865ac7":"epochs = 1000\nlr = 1e-2\nhistory1 = fit(epochs, lr, model, train_loader, val_loader)","bc649449":"epochs = 1000\nlr = 1e-3\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","3daea613":"epochs = 1000\nlr = 1e-4\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","d4f647f3":"epochs = 1000\nlr = 1e-5\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","32ad0124":"epochs = 1000\nlr = 1e-6\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","0d6d4a61":"val_loss = evaluate(model,val_loader)\nval_loss","fdec1b38":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0) \n    predictions = model(inputs)\n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","13873ef9":"input, target = val_df[0]\npredict_single(input, target, model)","f2f9cb1d":"input, target = val_df[10]\npredict_single(input, target, model)","24944038":"input, target = val_df[5]\npredict_single(input, target, model)","18d2dac9":"**Make predictions using the trained model**","cf7d6ff0":"**Find number of columns and rows**","6c52e329":"**Read the csv file**","c65b6ac4":"**Convert numpy array to torch tensor**","44c14970":"**Create Model skeleton**","40d08be5":"**Checking if there is any missing value exists**","365534a2":"It means there are 1599 rows and 12 columns","e18bb2b4":"**Train the model 4-5 times with different learning rates & for different number of epochs to see what works**","493564c4":"**Note: I am doing predictions for validation set. But ideally you should seperate some of datasaets for test. **\n\nHere it has been done for learning purpose only.","0dbc061c":"**Now calculate final validation loss **","d18565a4":"**Now plot graph to see it's distribution and property**","85f9c01e":"** Use the evaluate function to calculate the loss on the validation set before training.**","4ce6a0a6":"I have considered highly correlated if correaltion value is >0.7 ","d7b4ef24":"Hoorrah..... It's performing well .<br>\nAnd this is how we trained our first pytorch model with linear regression on **Wine quality dataset.**","7957a496":"**Split the datasets into train ,validation and test datasets**","f10dc17c":"**check correlation between features**","62e30678":"**Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a TensorDataset. **","6a48f672":"**As every column name returned false it means that there is not any null value.**","128c0714":"**Check datatypes of dataframe's columns**","87b7f4b2":"**Convert dataframe to numpy arrays**","109b33d5":"**Pick a batch size for data loader**"}}