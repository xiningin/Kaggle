{"cell_type":{"d6abd95d":"code","a6a8afdb":"code","42a5e544":"code","0944fe2d":"code","90efae56":"code","d5ebb88d":"code","91684079":"code","5140beda":"code","6807882b":"code","72e4d561":"code","029d8b01":"code","c1a523c5":"code","9b42df51":"code","f2d7ac4d":"code","5c9bb33a":"code","8ac52609":"code","2e8e62aa":"code","5a26d561":"code","e7868350":"code","05231efb":"code","e720e270":"code","9e40c06e":"code","27a46b64":"code","907d7f81":"code","f4b9cca3":"code","828acb20":"code","bfa8f7b7":"code","79773056":"code","2b0d826b":"code","663e14b2":"code","f0deb544":"code","e2db17d3":"code","7846fafc":"code","808629a1":"code","8e034f04":"code","3585ec06":"code","a27e81a4":"code","ba10785b":"code","60d7b4ed":"code","99f56c51":"code","e5bb7859":"code","7b15881e":"code","15847c7b":"code","38b202d5":"code","f9ab4cd2":"code","7db64dab":"code","164b39c6":"code","b3c0a613":"code","5c72f20c":"code","7d04093d":"code","807be5fe":"code","c2825fc2":"code","f0c93ab4":"code","a86fddfb":"code","f5ea7ef2":"code","07133903":"code","a5890dd9":"code","00edbd92":"code","b0285ea6":"code","5dcb2670":"code","80d7017d":"code","890d86da":"code","743fc883":"code","62e5f2f5":"code","ccf8e25f":"code","e0579ba8":"code","283e86ca":"code","e59b1125":"code","f31a0a11":"code","461a794f":"code","28b2c647":"code","9efc93fa":"code","48fa8005":"code","ffbfe044":"code","bea67b95":"code","f39fa7f3":"code","39a6d921":"code","36d8d07d":"code","a5607466":"code","1ec6cc4d":"code","e36e18df":"code","a8605a86":"code","cf79a7d1":"code","24d13e5a":"code","c27be21a":"code","efe19307":"code","e1e496b9":"code","3403e3a6":"code","072965eb":"code","fef05d7f":"code","cf288ee7":"code","96e21b88":"code","f8f9ba46":"code","3c82028f":"code","529fd525":"code","b06b7709":"code","a199f52d":"code","8f0a625a":"code","071f9dea":"code","b9acd989":"code","4663dd47":"code","bfc137f1":"code","cb38dd1e":"code","0ed5986b":"code","0cfdae74":"code","0822222e":"code","16ad3f99":"code","fe18e76e":"code","44c3af53":"markdown","85340c18":"markdown","4ce364f8":"markdown","62f6fa26":"markdown","5423cdae":"markdown","471c1868":"markdown","d34328b4":"markdown","5942ded7":"markdown","d3494776":"markdown","9593a30f":"markdown","2676e29a":"markdown","6a130f4c":"markdown","0e3b204d":"markdown","0ff27cc7":"markdown","c8c2e788":"markdown","2a5c5519":"markdown","a7da030c":"markdown","04199cfc":"markdown","4f6913f1":"markdown","301bc2d3":"markdown","f24703c9":"markdown","f321a168":"markdown","63e5fb01":"markdown","33507518":"markdown","cdf91590":"markdown","6e6637b8":"markdown","c6b4790f":"markdown","ec536225":"markdown","e262f729":"markdown","a5c470e9":"markdown","498265ba":"markdown","9757f17c":"markdown","f5d87a56":"markdown","601d4bc4":"markdown","d8ab6e66":"markdown","1b534546":"markdown","dd7ed3f1":"markdown","f7a4ed59":"markdown","05016e68":"markdown","548e682a":"markdown","ef38028e":"markdown","6ac851c5":"markdown","1255858e":"markdown","f8702b09":"markdown","30fc80c9":"markdown","38c8f925":"markdown","bf86be05":"markdown","33fb551c":"markdown","feb87561":"markdown","f23e25e6":"markdown","5acb2fd8":"markdown","7e91726f":"markdown","15d9c6a1":"markdown","662315d9":"markdown","531f2390":"markdown","fc46eb46":"markdown","2dee646f":"markdown","56115f4f":"markdown","5608ca65":"markdown","d3961831":"markdown","12eef388":"markdown"},"source":{"d6abd95d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('always')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6a8afdb":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_ID = test['PassengerId'] ## Saving the IDs to be used while submitting the notebook ","42a5e544":"train.head()","0944fe2d":"print(\"The number of rows in the dataset are: \", train.shape[0])\nprint(\"The number of columns which can be used to predict wheteher a person survived is: \", train.shape[1] - 1)","90efae56":"train.info()","d5ebb88d":"# Outlier detection \nfrom collections import Counter\n\ndef detect_outliers_using_Tukey_Method(table, n, features):\n    \"\"\"\n    Takes a dataframe table of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over each column\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(table[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(table[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = table[(table[col] < Q1 - outlier_step) | (table[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare as these are the continuous variables\nOutliers_to_drop = detect_outliers_using_Tukey_Method(train ,2, [\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","91684079":"train.loc[Outliers_to_drop]","5140beda":"train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True, inplace = True)","6807882b":"train.isnull().sum()","72e4d561":"from math import pi\n\nfrom bokeh.io import output_notebook\nfrom bokeh.io import show\nfrom bokeh.plotting import figure\nfrom bokeh.transform import cumsum\nfrom bokeh.palettes import Spectral6\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.layouts import gridplot","029d8b01":"train['Survived'].value_counts()\nsurvived_and_not_survived = {'Survived' : train['Survived'].value_counts()[1], 'Not Survived' : train['Survived'].value_counts()[0]}","c1a523c5":"data = pd.Series(survived_and_not_survived).reset_index(name = 'value').rename(columns = {'index':'Survived'})\ndata['angle'] = data['value']\/data['value'].sum() * 2 * pi\ndata['color'] = ['skyblue', 'salmon']","9b42df51":"output_notebook()","f2d7ac4d":"p = figure(plot_height=300, plot_width = 300, title=\"Pie Chart\", toolbar_location=None,\n           tools=\"hover\", tooltips=\"@Survived: @value\", x_range=(-0.5, 1.0))\n\np.wedge(x=0, y=1, radius=0.4,\n        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n        line_color=\"white\", fill_color = 'color', legend_field='Survived', source=data)\np.legend.location = \"top_right\"\np.legend.label_text_font_size = '5pt'","5c9bb33a":"unique = ['Survived', 'Not Survived']\ntop = [train['Survived'].value_counts()[1], train['Survived'].value_counts()[0]]\nsource = ColumnDataSource(data=dict(Survived = unique, counts = top, color = Spectral6))","8ac52609":"p1 = figure(\n    x_range = unique,\n    plot_height=300,\n    plot_width = 300,\n    x_axis_label = 'Survived',\n    y_axis_label = 'Count(Survived)',\n    title = 'Count of Survived and Not Survived',\n    tools=\"hover\", tooltips=\"@Survived: @counts\"\n)\n\np1.vbar(\n    x = 'Survived',\n    top = 'counts',\n    bottom = 0,\n    width = 0.9,\n    source = source,\n    color = 'color'\n)","2e8e62aa":"show(gridplot([[p,p1]]))","5a26d561":"types = {}\nfor i in train.columns:\n    types[i] = train[i].unique()\nprint(types)","e7868350":"train.groupby(['Sex', 'Survived'])['Survived'].count()","05231efb":"sex_vs_survived = train.groupby(['Sex', 'Survived'])['Survived'].count().to_list()","e720e270":"unique = ['Female', 'Male']\ntop = [sex_vs_survived[1], sex_vs_survived[3]]\nsource = ColumnDataSource(data = dict(Survived = unique, counts = top, color = Spectral6))\n       \np2 = figure(\n    x_range = unique,\n    plot_height = 400,\n    plot_width = 400,\n    x_axis_label = 'Sex',\n    y_axis_label = 'Count(Survived)',\n    title = 'Sex vs Survived',\n    tools=\"hover\", tooltips=\"@Survived: @counts\"\n)\n\np2.vbar(\n    x = 'Survived',\n    top = 'counts',\n    bottom = 0,\n    width = 0.9,\n    source = source,\n    color = 'color'\n)","9e40c06e":"unique = ['Female', 'Male']\ncondition = ['Survived', 'Died']\ncolors = [\"#c9d9d3\", \"#718dbf\"]\n\ndata = {'Sex' : unique,\n        'Survived' : [sex_vs_survived[1], sex_vs_survived[3]],\n        'Died'   : [sex_vs_survived[0], sex_vs_survived[2]],\n        }\n\np3 = figure(x_range = unique, plot_height = 400, plot_width = 400, title = \"Sex vs Survival\",\n           toolbar_location=None, tools=\"\")\n\np3.vbar_stack(condition, x ='Sex', width = 0.9, color = colors, source = data,\n             legend_label = condition)","27a46b64":"show(gridplot([[p3, p2]]))","907d7f81":"pd.crosstab(train.Pclass, train.Survived, margins = True)","f4b9cca3":"Pclass_Values = {}\nfor i in train['Pclass'].value_counts().index:\n    Pclass_Values[i] = train['Pclass'].value_counts()[i]\nprint(Pclass_Values)","828acb20":"PClass = list(Pclass_Values.keys())\ntop = list(Pclass_Values.values())\nsource = ColumnDataSource(data = dict(Classes = PClass, counts = top, color = Spectral6))\n       \np4 = figure(\n    plot_height = 400,\n    plot_width = 400,\n    x_axis_label = 'Classes',\n    y_axis_label = 'Count(Classes)',\n    title = 'No of passengers in each class',\n    tools=\"hover\", tooltips=\"@Classes: @counts\"\n)\n\np4.vbar(\n    x = 'Classes',\n    top = 'counts',\n    bottom = 0,\n    width = 0.9,\n    source = source,\n    color = 'color'\n)","bfa8f7b7":"pclass_vs_survived = train.groupby(['Pclass', 'Survived'])['Survived'].count().to_list()","79773056":"pclass_vs_survived","2b0d826b":"unique = [1, 2, 3]\ncondition = ['Survived', 'Died']\ncolors = [\"#718dbf\", \"#c9d9d3\"]\n\ndata = {'Classes' : unique,\n        'Survived' : [pclass_vs_survived[1], pclass_vs_survived[3], pclass_vs_survived[5]],\n        'Died'   : [pclass_vs_survived[0], pclass_vs_survived[2], pclass_vs_survived[4]],\n        }\n\np5 = figure(plot_height = 400, plot_width = 400, title = \"Pclass vs Survival\",\n           )\n\np5.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data,\n             legend_label = condition)","663e14b2":"show(gridplot([[p4, p5]]))","f0deb544":"pd.crosstab([train.Sex, train.Survived], train.Pclass, margins=True)","e2db17d3":"sns.factorplot('Pclass', 'Survived', hue = 'Sex', data = train)\nplt.show()","7846fafc":"train.Fare.isnull().sum()","808629a1":"hist, edges = np.histogram(train['Fare'], density=True, bins = 70)\np6 = figure(\n    x_axis_label = 'Fare',\n    title = 'Distplot'\n)\n\np6.quad(\n    bottom = 0,\n    top = hist,\n    left = edges[:-1],\n    right = edges[1:],\n    line_color = 'white'\n)\n\n\nshow(p6)\nprint(\"The skewness of the feature is: \", train['Fare'].skew())","8e034f04":"train[\"Fare\"] = train[\"Fare\"].map(lambda i: np.log(i + 1))","3585ec06":"hist, edges = np.histogram(train['Fare'], density=True, bins = 70)\np7 = figure(\n    x_axis_label = 'Fare',\n    title = 'Distplot'\n)\n\np7.quad(\n    bottom = 0,\n    top = hist,\n    left = edges[:-1],\n    right = edges[1:],\n    line_color = 'white'\n)\n\n\nshow(p7)\nprint(\"The skewness of the feature is: \", train['Fare'].skew())","a27e81a4":"train['Embarked'].value_counts()","ba10785b":"train.groupby(['Embarked', 'Survived'])['Survived'].count()","60d7b4ed":"embarked_vs_survived = train.groupby(['Embarked', 'Survived'])['Survived'].count().to_list()","99f56c51":"unique = [1, 2, 3]\ncondition = ['Survived', 'Died']\ncolors = [\"green\", \"red\"]\n\ndata = {'Classes' : unique,\n        'Survived' : [embarked_vs_survived[1], embarked_vs_survived[3], embarked_vs_survived[5]],\n        'Died'   : [embarked_vs_survived[0], embarked_vs_survived[2], embarked_vs_survived[4]],\n        }\n\np8 = figure(plot_height = 400, plot_width = 400, title = \"Embarked vs Survival\",)\n\np8.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data,\n             legend_label = condition)\nshow(p8)","e5bb7859":"train['Age'].isnull().sum()","7b15881e":"train_copy = train\ntrain_copy.Age.dropna(inplace = True)","15847c7b":"train_copy.Age.isnull().sum()","38b202d5":"train\nhist, edges = np.histogram(train_copy['Age'], density = True, bins = 30)\np8 = figure(\n    plot_height = 500,\n    plot_width = 500,\n    x_axis_label = 'Age',\n    title = 'Distplot'\n)\n\np8.quad(\n    bottom = 0,\n    top = hist,\n    left = edges[:-1],\n    right = edges[1:],\n    line_color = 'white'\n)\n\n\nshow(p8)","f9ab4cd2":"g = sns.FacetGrid(train_copy, col='Survived')\ng = g.map(sns.distplot, \"Age\")","7db64dab":"print(\"The skewness for the first graph above is\", train_copy[\"Age\"][(train_copy[\"Survived\"] == 0)].skew())\nprint(\"The skewness for the second graph above is\", train_copy[\"Age\"][(train_copy[\"Survived\"] == 1)].skew())","164b39c6":"dataset = pd.concat([train, test], axis = 0)","b3c0a613":"print(\"Train dataset shape: \", train.shape)\nprint(\"Test dataset shape: \", test.shape)\nprint(\"Combined dataset shape\", dataset.shape)","5c72f20c":"dataset.isnull().sum()","7d04093d":"sns.factorplot(x = \"Sex\", y = \"Age\", data = dataset, kind = \"box\")","807be5fe":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\", data = dataset, kind = \"box\")","c2825fc2":"sns.factorplot(x = \"Parch\", y = \"Age\", data = dataset, kind = \"box\")","f0c93ab4":"sns.factorplot(y = \"Age\", x = \"SibSp\", data = dataset, kind=\"box\")","a86fddfb":"dataset['Sex'] = dataset['Sex'].map({'male' : 0, 'female' : 1})","f5ea7ef2":"sns.heatmap(dataset[[\"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Pclass\"]].corr(),cmap = \"BrBG\",annot = True)","07133903":"null_index = dataset['Age'][dataset['Age'].isnull()].index","a5890dd9":"null_index","00edbd92":"for i in null_index:\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    dataset['Age'].iloc[i] = age_pred\n    ","b0285ea6":"dataset[\"Name\"].head()","5dcb2670":"dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset[\"Title\"] = pd.Series(dataset_title)\ndataset[\"Title\"].head()","80d7017d":"dataset['Title']","890d86da":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45)","743fc883":"dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n# First replace the 5 uncommon titles with rare.\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n# Map each of the titles to a number.\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)","62e5f2f5":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss\/Ms\/Mme\/Mlle\/Mrs\",\"Mr\",\"Rare\"])","ccf8e25f":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","e0579ba8":"dataset.drop('Name', axis = 1, inplace = True)","283e86ca":"dataset['FamSize'] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1","e59b1125":"g = sns.factorplot(x = \"FamSize\",y = \"Survived\",data = dataset)\ng = g.set_ylabels(\"Survival Probability\")","f31a0a11":"dataset['Single'] = dataset['FamSize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallFam'] = dataset['FamSize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedFam'] = dataset['FamSize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeFam'] = dataset['FamSize'].map(lambda s: 1 if s >= 5 else 0)","461a794f":"g = sns.factorplot(x = \"Single\", y = \"Survived\", data = dataset, kind = \"bar\")\ng = sns.factorplot(x = \"SmallFam\", y = \"Survived\", data = dataset, kind = \"bar\")\ng = sns.factorplot(x = \"MedFam\", y = \"Survived\", data = dataset, kind = \"bar\")\ng = sns.factorplot(x = \"LargeFam\", y = \"Survived\", data = dataset, kind = \"bar\")","28b2c647":"dataset = pd.get_dummies(dataset, columns = [\"Title\"])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")","9efc93fa":"dataset.head()","48fa8005":"dataset.columns","ffbfe044":"dataset.drop([\"PassengerId\", \"Ticket\", \"Fare\", \"Cabin\"], axis = 1, inplace = True)","bea67b95":"dataset.columns","f39fa7f3":"dataset","39a6d921":"dataset.shape","36d8d07d":"dataset.isnull().sum()","a5607466":"dataset['Age'].fillna(dataset['Age'].mean(), inplace = True)","1ec6cc4d":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","e36e18df":"len_train = train.shape[0]\ntrain = dataset[:len_train]\ntest = dataset[len_train:]","a8605a86":"X = train.drop('Survived', axis = 1)\ny = train['Survived']","cf79a7d1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","24d13e5a":"ss = StandardScaler()\nX_train = ss.fit_transform(X_train)\nX_test = ss.transform(X_test)","c27be21a":"X_train.shape","efe19307":"X_test.shape","e1e496b9":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","3403e3a6":"kfold = StratifiedKFold(n_splits=10)\nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\n\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\n\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state = random_state),random_state = random_state,learning_rate = 0.1))\nclassifiers.append(RandomForestClassifier(random_state = random_state))\nclassifiers.append(ExtraTreesClassifier(random_state = random_state))\nclassifiers.append(GradientBoostingClassifier(random_state = random_state))\nclassifiers.append(MLPClassifier(random_state = random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs = 4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","072965eb":"LR = LogisticRegression()\nLR.fit(X_train, y_train)\npredictions = LR.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test, predictions))","fef05d7f":"from sklearn import svm, datasets\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'kernel' : ('linear', 'rbf'), 'C' : [1, 10], 'gamma' : [0.001, 0.01, 0.1]}\nsvc = svm.SVC()\nclf = GridSearchCV(svc, parameters)\nclf.fit(X_train, y_train)","cf288ee7":"best_parameters = clf.best_params_","96e21b88":"best_parameters","f8f9ba46":"svc = SVC(kernel = best_parameters['kernel'], C = best_parameters['C'], gamma = best_parameters['gamma'] )","3c82028f":"svc.fit(X_train, y_train)","529fd525":"predictions = svc.predict(X_test)","b06b7709":"print(accuracy_score(y_test, predictions))","a199f52d":"ABC = AdaBoostClassifier(DecisionTreeClassifier(random_state = 2), random_state = 2, learning_rate=0.1)","8f0a625a":"ABC.fit(X_train, y_train)","071f9dea":"prediction_using_ABC = ABC.predict(X_test)","b9acd989":"print(accuracy_score(y_test, prediction_using_ABC))","4663dd47":"LDA = LinearDiscriminantAnalysis()\nLDA.fit(X_train, y_train)","bfc137f1":"prediction_using_LDA = LDA.predict(X_test)","cb38dd1e":"print(accuracy_score(y_test, prediction_using_LDA))","0ed5986b":"test.drop('Survived', axis = 1, inplace = True)","0cfdae74":"test.head()","0822222e":"test = ss.transform(test)","16ad3f99":"predictions = svc.predict(test)","fe18e76e":"test_Survived = pd.Series(predictions, name = \"Survived\")\n\nresults = pd.concat([test_ID, test_Survived],axis=1).astype(int)\n\nresults.to_csv(\"submission1.csv\", index = False)","44c3af53":"In the above graph we can see that maximum number of passengers belonged to class 3 and the maximum number of people who died were also of class 3, whereas the people belonging to class 1 were saved, giving advantage to them being rich.\n\nLets take into consideration both Sex and the Pclass.","85340c18":"We can see that the people belonging to Class 1 are older than those belonging to Class 2, which are in turn older than the people belonging to Class 3, which is obvious.","4ce364f8":"After performing manipulation we will drop the name column.","62f6fa26":"Maximum number of women were saved amongst all the members or \"Women or child first\"","5423cdae":"We can observe that maximum number of people were between 20 and 50 years of age.","471c1868":"## Submission","d34328b4":"We can see that Age distribution seems to be the same in Male and Female subpopulations, so Sex can not be used to calculate the null values of Age.","5942ded7":"## Feature Engineering","d3494776":"No null value is present for the Fare column.","9593a30f":"## Exploring Different Features","2676e29a":"For plotting purposes I have mapped 'C' to 1, 'Q' to 2, and 'S' to 3.","6a130f4c":"From the graph and the the value of the skewness we can see that the 'Fare' feature is skewed. Hence we will take the log transform of the values in order to reduce the skewness.","0e3b204d":"We use FactorPlot in this case, because they make the seperation of categorical values easy.\n\nLooking at the CrossTab and the FactorPlot, we can easily infer that survival for Women from Pclass1 is about 95-96%, as only 3 out of 94 Women from Pclass1 died.\n\nIt is evident that irrespective of Pclass, Women were given first priority while rescue. Even Men from Pclass1 have a very low survival rate.\n\nLooks like Pclass is also an important feature. Lets analyse other features.\n\n","0ff27cc7":"## Exploratory Data Analysis Using Bokeh","c8c2e788":"Checking for NULL values","2a5c5519":"There are 17 different titles in the datatset, we will group all the titles into 4 different categories.","a7da030c":"### Logistic Regression","04199cfc":"### Fare","4f6913f1":"We can see there are 10 outliers present in the dataset, some of them are outliers either due to large number of SibSp or due to high fare. \n\nLets drop these outliers","301bc2d3":"### SVM using GridSearchCV","f24703c9":"### AdaBoosting","f321a168":"These feature take continuous values or it takes values between any two points in the column. For example, the Price of the house can be a continous feature.","63e5fb01":"### Overall","33507518":"There are three unique values for Embarked feature, let's visualise this feature.","cdf91590":"### Age","6e6637b8":"We can see that not many people survived the crash, 549 people died whereas only 342 people survived. This is pretty sad. \n\nNow we will look at other features and try to see the effect of those features on the survival rate.\n\nFirst let us understand the different type of features.","c6b4790f":"### Outlier Detection","ec536225":"These are the features whose values are divided into certain categories like gender is a categorical feature whose value can be Male or Female or PClass is also a categorical feature which can take the values like 1 2 or 3.","e262f729":"### Categorical Features","a5c470e9":"We can think that as the family size increases, it would be more difficult to evacuate those people. So I created a feature called 'FamSize' which represents the total size of the family, i.e sum of Parch, SibSp, and self.","498265ba":"We can say that Age is not correlated with Sex but is negatively correlated with SibSp, Parch and Pclass.\n\nIn the plot of Age in function of Parch, Age is growing with the number of parents \/ children. But the general correlation is negative.\n\nSo we will be using SibSp, Parch, Pclass to calculate the missing values of Age. \n\nWe will fill the missing values of Age with the median age of similar rows based on Parch, SibSp and Pclass","9757f17c":"As it's visible in the graphs as well as indicated by the above calculated values of skewness, the graphs are almost symmetrical. \n\nWe notice that age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to young passengers, that have survived. We also see that passengers between 60-80 have less survived.","f5d87a56":"### Survived","601d4bc4":"Ordinal Features are similar to Categorical Features but the difference between them is that we can have relative ordering between the values. For example, PClass is an Ordinal Feature as it has values 1,2 and 3 as there is a relative sort in the feature.","d8ab6e66":"So you can see that as the family size increases the survival probability decreases.","1b534546":"We can see that there are 418 null values for the 'Survived' columns, these are for the test dataset whose rows were added to the train dataset. We don't need to worry about these values.\n\nNow we have to deal with the Age column as there are 263 NULL values.\n\nFirst, let us see the effect of each feature on the Age column.","dd7ed3f1":"Above are the final Columns which will be used.","f7a4ed59":"## Loading and Checking the data","05016e68":"## Types of Features","548e682a":"Now we can see that the skewness of the data dropped significantly.","ef38028e":"### Family Size","6ac851c5":"### Embarked","1255858e":"You might wonder why the number of columns in the combined dataset is 12, even though the number of columns in the train is 12 and test is 11, it's because we have to predict the 'Survived' column in the test dataset, and if we combine the two datasets, the values of the 'Survived' column for the rows which were present in the test dataset will be set as NAN.","f8702b09":"Let's fill the missing values with the mean values of the age.","30fc80c9":"More a passenger has siblings\/spouses the younger he is.","38c8f925":"There are various ways to detect outliers in a given dataset, one of them is known as Tukey Method which takes into consideration the first quartile (Q1), the third quartile values (Q3) and the interquartile range (IQR). In order to understand this method better just imagine a box plot, which also indicates these values. This method states that the maximum value can be equal to the Q3 + 1.5 * IQR and that the minimum value can be Q1 - 1.5 * Q1, any values greater or less than the maximum and minimum is said to be an outlier. \n\nFor better understanding of outlier detection, refer to this amazing blog https:\/\/towardsdatascience.com\/practical-guide-to-outlier-detection-methods-6b9f947a161e","bf86be05":"As there are 177 null values, lets make a copy of the train dataset which contains no null values for Age. We are doing this because it's not possible to plot the null values.","33fb551c":"Let's group the Famsize into four different categories.","feb87561":"We can observe that the maximum number of people who survived embarked from station 'S', although maximum number of people who died were also from 'S'.","f23e25e6":"## Model Training","5acb2fd8":"### Linear Discriminant Analyses","7e91726f":"We can classify the features as follows:\n\nCategorical -- Sex, Embarked\n\nOrdinal -- PClass\n\nContinuous -- Age","15d9c6a1":"### Filling the missing values\n\nFirst let us combine the training set and the testing set as one table called dataset.","662315d9":"Let's see which column belongs to which type of feature.\n\nWe can use the command 'unique' to check the different unique values in the column.","531f2390":"Moreover, the more a passenger has parents\/children the older he is.","fc46eb46":"### PClass","2dee646f":"With the help of stacked vertical bar we can see that more number of female passenger survived as compared to the number of male passengers. The survival rate for women on ship is approximately 75% whereas it is 18% for men.","56115f4f":"### Sex","5608ca65":"Name","d3961831":"### Continuous Features","12eef388":"### Ordinal Features"}}