{"cell_type":{"048bf1a0":"code","341d78a4":"code","6f12dc58":"code","4d7ab72c":"code","fab5ca8e":"code","5c9e30dd":"code","43dbaf00":"code","0d7f9db7":"code","79de8b37":"code","ee0306b9":"code","dac6ad93":"code","e5b37d1e":"code","4266f0ae":"code","50f2493e":"code","a84d34bb":"code","c24493b6":"code","986ed185":"code","5db2c6ae":"code","71cd84e0":"code","a5e536ed":"code","30285fad":"code","0d430292":"code","62f286ca":"code","96028fe5":"code","eed4249c":"code","9de72218":"code","218b40a3":"code","e0bfaec4":"code","ef2b3693":"code","3e03b331":"code","c9ce4d2c":"code","f2b0f6dd":"markdown"},"source":{"048bf1a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","341d78a4":"!unzip -q ..\/input\/dogs-vs-cats\/test1.zip\n!unzip -q ..\/input\/dogs-vs-cats\/train.zip","6f12dc58":"!mkdir Train\n!mkdir Validation\n!mkdir Train\/cat\n!mkdir Train\/dog\n!mkdir Validation\/cat\n!mkdir Validation\/dog","4d7ab72c":"import numpy as np\nimport tensorflow\nimport tensorflow.keras\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Dropout, GlobalMaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport shutil\nfrom random import shuffle\nimport matplotlib.pyplot as plt\n# from google.colab.patches import cv2_imshow\n%matplotlib inline","fab5ca8e":"files = os.listdir('train')\nshuffle(files)","5c9e30dd":"os.path.isdir('train\/')","43dbaf00":"# cv2.imshow(cv2.imread('train\/' + files[4]))","0d7f9db7":"base_path = 'train'\ndest_path1 = 'Train'\ndest_path2 = 'Validation'","79de8b37":"cat_split = int(len(files) * 0.1)\ndog_split = int(len(files) * 0.1)\ncat_counter = 0\ndog_counter = 0\n\nfor i in tqdm(range(len(files))):\n    img = files[i]\n    pet = img.split('.')[0]\n    \n    if pet == 'dog':\n        if dog_counter < dog_split:\n            shutil.copyfile(\n                os.path.join(base_path, img),\n                os.path.join(dest_path2, pet, img))\n            dog_counter += 1\n        else:\n            shutil.copyfile(\n                os.path.join(base_path, img),\n                os.path.join(dest_path1, pet, img))\n    \n    elif pet == 'cat':\n        if cat_counter < cat_split:\n            shutil.copyfile(\n                os.path.join(base_path, img),\n                os.path.join(dest_path2, pet, img))\n            cat_counter += 1\n        else:\n            shutil.copyfile(\n                os.path.join(base_path, img),\n                os.path.join(dest_path1, pet, img))","ee0306b9":"datagen = ImageDataGenerator(rescale=1.\/255 ,preprocessing_function=preprocess_input)\n\ntrain_datagen = datagen.flow_from_directory('Train',\n                                            batch_size=32,\n                                            shuffle=True,\n                                            target_size=(224, 224),\n                                            class_mode='binary')\n\nval_datagen = datagen.flow_from_directory('Validation',\n                                            batch_size=32,\n                                            shuffle=True,\n                                            target_size=(224, 224),\n                                            class_mode='binary')","dac6ad93":"print(int(20000 \/ 32) * 32)\nprint(int(5000 \/ 32) * 32)","e5b37d1e":"data, label = next(train_datagen)\ni = 0\nplt.imshow(data[i])\nprint(label[i])","4266f0ae":"model = VGG16(weights='imagenet', include_top=False)\n\ninp = Input(shape=(224, 224, 3), batch_size=32)\n\nx = model(inp)\nx = GlobalMaxPooling2D()(x)\n\nmodel_feature_extractor = Model(inputs=[inp], outputs=[x])","50f2493e":"X_train = np.zeros((20000, 512), dtype=np.float32)\ny_train = np.zeros((20000))\n\nX_val = np.zeros((4992, 512), dtype=np.float32)\ny_val = np.zeros((4992))","a84d34bb":"for i in tqdm(range(0, 20000, 32)):\n    batch = train_datagen.next()\n    X_train[i:i + 32] = model_feature_extractor.predict(batch[0])\n    y_train[i:i + 32] = batch[1]\n\nfor i in tqdm(range(0, 4992, 32)):\n    batch = val_datagen.next()\n    X_val[i:i + 32] = model_feature_extractor.predict(batch[0])\n    y_val[i:i + 32] = batch[1]","c24493b6":"print(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)","986ed185":"def plot_history(history):\n    fig, axs = plt.subplots(2)\n    # Plot both Loss & Accuracy in Subplot\n  # creat accuracy plot\n    axs[0].plot(history.history['acc'], label='train accuracy')\n    axs[0].plot(history.history['val_acc'], label='test accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].legend(loc='best')\n    axs[0].set_title('Accuracy eval')\n\n  # creat loss plot\n    axs[1].plot(history.history['loss'], label='train loss')\n    axs[1].plot(history.history['val_loss'], label='test loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(loc='best')\n    axs[1].set_title('Loss eval')\n\n    plt.show()","5db2c6ae":"import tensorflow as tf\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nimport datetime","71cd84e0":"clf_model =  Sequential()\n\nclf_model.add(Dense(128, activation='relu', input_dim=512,\n                    kernel_regularizer=l2(0.001)))\nclf_model.add(Dropout(0.3))\n\n# clf_model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n# clf_model.add(Dropout(0.3))\n\nclf_model.add(Dense(1, activation='sigmoid'))\n\nclf_model.summary()\n\nclf_model.compile(optimizer=Adam(learning_rate=0.0001), \n                  loss='binary_crossentropy', metrics=['acc'])","a5e536ed":"res = clf_model.fit(X_train, y_train.reshape(-1, 1), epochs=50, batch_size=32,\n              validation_data=(X_val, y_val.reshape(-1, 1)), verbose=2)\n\nplot_history(res)","30285fad":"test_filenames = os.listdir(\"\/kaggle\/working\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","0d430292":"test_df.head()","62f286ca":"test_datagen = datagen.flow_from_dataframe(\n    test_df, \n    \"\/kaggle\/working\/test1\/\",\n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=False\n)","96028fe5":"print(int(12500 \/ 32) * 32)","eed4249c":"X_test = np.zeros((12480, 512), dtype=np.float32)","9de72218":"for i in tqdm(range(0, 12480, 32)):\n    batch = test_datagen.next()\n    X_test[i:i + 32] = model_feature_extractor.predict(batch)\n#     y_train[i:i + 32] = batch[1]","218b40a3":"X_test.shape","e0bfaec4":"preds = clf_model.predict(X_test)","ef2b3693":"for i in range(len(preds)):\n    if preds[i] >= 0.5:\n        preds[i] = 1\n    else:\n        preds[i] = 0","3e03b331":"predictions = pd.DataFrame()\npredictions[\"id\"] = np.arange(1, 12481)\npredictions[\"target\"] = preds\n\npredictions.to_csv('Pejman_submission.csv', index=False, header=predictions.columns)\npredictions.head(10)","c9ce4d2c":"predictions['target'].value_counts()","f2b0f6dd":"Cat label = 0.0\n\nDog label = 1.0"}}