{"cell_type":{"7b2d24da":"code","daea1098":"code","f46d0293":"code","0ff19d2e":"code","6bdb3bf2":"code","2801c238":"code","68c57b42":"code","01ba7beb":"code","8d0fe14a":"code","3be6be4a":"code","3c0d2ddd":"code","657521e6":"code","c89ec7e1":"code","c8078088":"code","e4b7bdc3":"code","61255c26":"code","4d4f62aa":"code","2c962446":"code","beca8cc9":"code","86a8ed14":"code","912cf3df":"code","114f2845":"code","82a90750":"code","468e30f0":"code","2778b210":"code","0f087bab":"code","93a55b8d":"code","10aaeb90":"code","7630b00f":"code","d6cc9ac3":"code","3497fecb":"code","4678a8e9":"code","00d28133":"code","5cedf754":"code","f171486b":"code","34e62d03":"code","f6c323cd":"code","7dab6167":"code","3dcacfa4":"markdown","741e6103":"markdown","bac781ea":"markdown","5dc1b5b0":"markdown","1e6bdaf1":"markdown","30ef5598":"markdown","3060e912":"markdown","c5ff3aa7":"markdown","ef9467e5":"markdown","260e6cf1":"markdown","64947c40":"markdown","547d43a4":"markdown","02f9d6f0":"markdown","33099307":"markdown","4ed67cef":"markdown","3bbd2ca1":"markdown","47031257":"markdown","6d9d999f":"markdown","27643e23":"markdown","fe94b383":"markdown"},"source":{"7b2d24da":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","daea1098":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nperfect = pd.read_csv('\/kaggle\/input\/perfecttitanic\/PerfectScoreTitanic.csv')","f46d0293":"# credit: https:\/\/www.kaggle.com\/willkoehrsen\/start-here-a-gentle-introduction. \n# One of the best notebooks on getting started with a ML problem.\n\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns\n\n","0ff19d2e":"train_missing= missing_values_table(train)\ntrain_missing","6bdb3bf2":"test_missing= missing_values_table(test)\ntest_missing","2801c238":"def combine(train,test):\n    merged = pd.concat([train,test])\n    merged.drop('Survived',axis=1,inplace=True)\n    return merged\nmerged = combine(train,test)","68c57b42":"def encoding_label(merged, baseline= True):\n    from sklearn.preprocessing import LabelEncoder\n    encoder = LabelEncoder()\n    \n    if baseline == True:\n        merged['Sex'] = encoder.fit_transform(merged['Sex'])\n    else:\n        merged['Sex'] = encoder.fit_transform(merged['Sex'])\n        merged['Cabin'] = [0 if 'Cabin' in i else 1 for i in merged['Cabin']]\n        merged['Embarked'] = encoder.fit_transform(merged['Embarked'])\n    return merged","01ba7beb":"def scoring(merged):\n    trained = merged.iloc[:len(train)]\n    tested = merged.iloc[len(train):]\n    y = train.Survived\n    y_perfect = perfect.Survived\n    \n    from sklearn.linear_model import LogisticRegression\n    logreg = LogisticRegression()\n    \n    logreg.fit(trained,y)\n    return logreg.score(tested,y_perfect)","8d0fe14a":"name = list()\nscores = list()","3be6be4a":"merged = combine(train,test)\nmerged.drop(columns = ['PassengerId','Name','Cabin','Ticket','Fare','Embarked','Age'], inplace=True)","3c0d2ddd":"merged = encoding_label(merged)\nscores.append(scoring(merged))\nname.append('Base_Model')","657521e6":"merged = combine(train,test)\nmerged = merged[['Sex','Pclass','Age','SibSp','Parch','Fare','Cabin','Embarked']]","c89ec7e1":"# Replacing the null values in the Age column with Mean\nfrom sklearn.impute import SimpleImputer\nfrom array import array\n\n# Imputers for Cabin\nimputer = SimpleImputer(missing_values= np.nan, strategy='constant', fill_value='No_Cabin')\n\n# Fit and transform to the parameters\nmerged['Cabin'] = imputer.fit_transform(np.array(merged['Cabin']).reshape(-1,1))\n\n# Imputers for Embarked\nimputer = SimpleImputer(missing_values= np.nan, strategy='most_frequent')\n\n# Fit and transform to the parameters\nmerged['Embarked'] = imputer.fit_transform(np.array(merged['Embarked']).reshape(-1,1))\n\n# Checking for any null values\nmerged.head()","c8078088":"merged = encoding_label(merged, baseline=False)","e4b7bdc3":"merged_simple = merged.copy()\nmerged_simple['Fare'] = merged.Fare.fillna(merged.Fare.mean())\nmerged_simple['Age'] = merged_simple.Age.fillna(merged.Age.mean())","61255c26":"scores.append(scoring(merged_simple))\nname.append('Simple_Mean')","4d4f62aa":"merged_pclass = merged.copy()\nmerged_pclass['Age'] = merged.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.mean()))\nmerged_pclass['Fare'] = merged.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.mean()))","2c962446":"scores.append(scoring(merged_pclass))\nname.append('Mean_Based_on_Pclass')","beca8cc9":"merged_simple = merged.copy()\nmerged_simple['Fare'] = merged.Fare.fillna(merged.Fare.median())\nmerged_simple['Age'] = merged_simple.Age.fillna(merged.Age.median())","86a8ed14":"scores.append(scoring(merged_simple))\nname.append('Simple_Median')","912cf3df":"merged_pclass = merged.copy()\nmerged_pclass['Age'] = merged.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))\nmerged_pclass['Fare'] = merged.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))","114f2845":"scores.append(scoring(merged_simple))\nname.append('Median_Based_on_Pclass')","82a90750":"merged_ffill = merged.copy()\nmerged_ffill['Age'].fillna(method='ffill',inplace=True)\nmerged_ffill['Fare'].fillna(method='ffill',inplace=True)","468e30f0":"scores.append(scoring(merged_ffill))\nname.append('FFILL_Method')","2778b210":"merged_bfill = merged.copy()\nmerged_bfill['Age'].fillna(method='bfill',inplace=True)\nmerged_bfill['Fare'].fillna(method='bfill',inplace=True)\n\n# Because it still leaves 2 missing values using bfill, I use ffill to mask it\nmerged_bfill['Age'].fillna(method='ffill',inplace=True)\n","0f087bab":"scores.append(scoring(merged_bfill))\nname.append('BFILL_Method')","93a55b8d":"from sklearn.impute import KNNImputer\nmerged_knn = merged.copy(deep=True)\n\nknn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n\nmerged_knn['Age'] = knn_imputer.fit_transform(merged_knn[['Age']])\nmerged_knn['Fare'] = knn_imputer.fit_transform(merged_knn[['Fare']])","10aaeb90":"scores.append(scoring(merged_knn))\nname.append('KNN_Imputation')","7630b00f":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nmerged_mice = merged.copy(deep=True)\n\nmice_imputer = IterativeImputer()\nmerged_mice['Age'] = mice_imputer.fit_transform(merged_mice[['Age']])\n\nmice_imputer = IterativeImputer()\nmerged_mice['Fare'] = mice_imputer.fit_transform(merged_mice[['Fare']])","d6cc9ac3":"scores.append(scoring(merged_mice))\nname.append('MICE_Imputation')","3497fecb":"merged_regression = merged.copy()\nmerged_regression_train = merged_regression.iloc[:len(train)]\nmerged_regression_test = merged_regression.iloc[:len(test)]","4678a8e9":"from sklearn.linear_model import LinearRegression\nmerged_regression_train_age = merged_regression_train[merged_regression_train[\"Age\"].isna() == False]\nmerged_regression_test_age = merged_regression_test[merged_regression_test[\"Age\"].isna() == False]\n\nmerged_regression_new = merged_regression_train_age.append(merged_regression_test_age)\n\nmerged_regression_age_X = merged_regression_new.drop([\"Age\"], axis = 1)\nmerged_regression_age_y = merged_regression_new[\"Age\"]\n\nmerged_regression_age_X[\"Fare\"].fillna(merged_regression_age_X[\"Fare\"].median(), inplace = True)\n\nlinear_reg_model = LinearRegression().fit(merged_regression_age_X, merged_regression_age_y)","00d28133":"# get indexes of rows that have NaN value\n\ndef get_age_indexes_to_replace(df):\n    age_temp_list = df[\"Age\"].values.tolist()\n    indexes_age_replace = []\n    age_temp_list = [str(x) for x in age_temp_list]\n    for i, item in enumerate(age_temp_list):\n        if item == \"nan\":\n            indexes_age_replace.append(i)\n    return indexes_age_replace\n\nindexes_to_replace_main = get_age_indexes_to_replace(merged_regression_train)\nindexes_to_replace_test = get_age_indexes_to_replace(merged_regression_test)","5cedf754":"# make predictions on the missing values\ndef linear_age_predictions(reg_df, indexes_age_replace):\n    reg_df_temp = reg_df.drop([\"Age\"], axis = 1)\n    age_predictions = []\n    for i in indexes_age_replace:\n        x = reg_df_temp.iloc[i]\n        x = np.array(x).reshape(1,-1)\n        pred = linear_reg_model.predict(x)\n        age_predictions.append(pred)\n    return age_predictions\n\nage_predictions_main = linear_age_predictions(merged_regression_train, indexes_to_replace_main)\nage_predictions_test = linear_age_predictions(merged_regression_test, indexes_to_replace_test)","f171486b":"# fill the missing values with predictions\ndef fill_age_nan(merged_regression, indexes_age_replace, age_predictions):\n\n    for i, item in enumerate(indexes_age_replace):\n        merged_regression[\"Age\"][item] =  age_predictions[i]\n\n    return merged_regression\n\nmerged_regression_train = fill_age_nan(merged_regression_train, indexes_to_replace_main, age_predictions_main)\nmerged_regression_test = fill_age_nan(merged_regression_test, indexes_to_replace_test, age_predictions_test)","34e62d03":"merged_regression = pd.concat([merged_regression_train, merged_regression_test])","f6c323cd":"scores.append(scoring(merged_regression))\nname.append('LinearRegression_Imputation')","7dab6167":"comparison = pd.DataFrame([scores],columns=name)\ncomparison","3dcacfa4":"### Fillna using Regression","741e6103":"## Mean and Median Missing Value","bac781ea":"### Fillna using KNN Imputation","5dc1b5b0":"### Simple Fillna using Mean","1e6bdaf1":"You can see base_model (drop all the missing values \u200b\u200bcolumns) has the highest score, I don't know why, definitely Age is an important factor to survive, but feel free to change the model maybe you get different results! \n\n<t> **Remember: Don't always believe your model results without comparing it with the domain knowledge**","30ef5598":"### Fillna using MICE","3060e912":"## Base Model (drop missing values columns)","c5ff3aa7":"## CABIN AND EMBARKED IMPUTATION\nIn this section we impute Cabin and Embarked columns with constant and most_frequent values.","ef9467e5":"## FILLNA USING MODEL","260e6cf1":"### Fillna using median based on Pclass","64947c40":"### Fillna using FFILL method","547d43a4":"### Fillna using mean based on Pclass","02f9d6f0":"In this notebook, I try various imputation techniques for numerical variables to see which is the best imputation technique to get the best score. And for the categorical variable I didn't try to variate it, I just impute the Constant values and Most frequent values for Cabin and Embarked columns.","33099307":"I use LogisticRegression to see the score, but different models can get different scores, feel free to change the model.","4ed67cef":"### Fillna using BFILL method","3bbd2ca1":"## FFILL AND BFILL METHOD\nI know FFILL_Method and BFILL_Method is use for Time_Series, but it doesn't hurt to try","47031257":"perfect is the actual prediction of titanic problem, I use it because it saves me more time without doing submitting it again and again.","6d9d999f":"### Simple fillna using Median","27643e23":"## References\n* [A guide to Handling missing values](https:\/\/www.kaggle.com\/parulpandey\/a-guide-to-handling-missing-values)\n* [Handling missing values for beginner](https:\/\/www.kaggle.com\/mojtylor\/handling-missing-values-for-beginner)\n* [EDA, Handling missing values using Regression](https:\/\/www.kaggle.com\/modojj\/eda-handling-missing-values-using-regression)","fe94b383":"## IMPUTATION TECHNIQUE COMPARISON"}}