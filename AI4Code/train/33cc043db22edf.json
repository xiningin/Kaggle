{"cell_type":{"e84383a1":"code","026b7341":"code","e355ba9b":"code","52010d0a":"code","1d30d9c8":"code","79a0b681":"code","1c19f09e":"code","ca46f6c3":"code","28c9b0a0":"code","c9dce8e9":"code","0f25203f":"code","3bcfd320":"code","b11bbc57":"code","52d74cb4":"code","8d1acddb":"code","75cac3c2":"code","af47272f":"code","061c3b8b":"code","69f873ae":"markdown","c456ce2d":"markdown","c7dec5a2":"markdown","7f471e7a":"markdown","59c5627d":"markdown","5ca1dafc":"markdown","49cec471":"markdown","e2c60485":"markdown","65fa9ec3":"markdown","c7fb7b12":"markdown"},"source":{"e84383a1":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport warnings\n\nfrom sklearn import linear_model\nfrom sklearn import neighbors\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\n\nwarnings.filterwarnings(\"ignore\")","026b7341":"data = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')\ndata.head()","e355ba9b":"data.drop(\"Serial No.\", axis=1, inplace=True)\ndata.head()","52010d0a":"print(\"Average GRE Score:\", int(data['GRE Score'].mean()))\nplt.title(\"DISTRIBUTION OF GRE SCORES\")\nsns.distplot(data['GRE Score'])\nplt.show()\n\nprint(\"\\nAverage TOEFL Score:\", int(data['TOEFL Score'].mean()))\nplt.title(\"DISTRIBUTION OF TOEFL SCORES\")\nsns.distplot(data['TOEFL Score'],color = 'r')\nplt.show()\n\nprint(\"\\nAverage CGPA:\", int(data['CGPA'].mean()))\nplt.title(\"DISTRIBUTION OF CGPA\")\nsns.distplot(data['CGPA'],color = 'g')\nplt.show()\n\nprint(\"Distribution Of University Ratings\")\nplt.title(\"Countplot of University Rating\")\nsns.countplot(x=\"University Rating\", data=data, palette=\"Set3\")\nplt.show()\n\nprint(\"Distribution Of SOP vs LOR\")\nplt.title(\"SOP vs LOR distribution\")\nsns.distplot(data[['SOP']], hist=False, rug=True,label ='SOP')\nsns.distplot(data[['LOR ']], hist=False, rug=True,label ='LOR')\nplt.show()","1d30d9c8":"g = sns.FacetGrid(data, col=\"Research\")\ng.map(plt.hist, \"University Rating\");\nplt.show()\n\n\ntarget_0 = data.loc[data['Research'] == 0]\ntarget_1 = data.loc[data['Research'] == 1]\nplt.title(\"GRE Score wrt Research\")\nsns.distplot(target_0[['GRE Score']], hist=False, rug=True,label ='No Research')\nsns.distplot(target_1[['GRE Score']], hist=False, rug=True,label ='Research')\nplt.show()\n\nplt.title(\"TOEFL Score wrt Research\")\nsns.distplot(target_0[['TOEFL Score']], hist=False, rug=True,label ='No Research')\nsns.distplot(target_1[['TOEFL Score']], hist=False, rug=True,label ='Research')\nplt.show()","79a0b681":"fig,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(data.corr(), ax=ax, annot=True, linewidths=0.05, fmt= '.2f',cmap=\"cubehelix\")\nplt.show()","1c19f09e":"fig=plt.figure()\n \nplt.subplots(figsize=(10, 10))\n# Do a 2x2 chart\nplt.subplot(221)\nplt.plot( 'TOEFL Score','CGPA', data=data, linestyle='none', marker='D', color=\"green\", alpha=0.3)\nplt.title('TOEFL vs CGPA', fontsize=20, color='grey', loc='left', style='italic')\n\nplt.subplot(222)\nplt.plot( 'GRE Score', 'CGPA', data=data, linestyle='none', marker='o', color=\"orange\", alpha=0.3)\nplt.title('GRE vs CGPA', fontsize=20, color='grey', loc='left', style='italic')\n\nplt.subplot(223)\nplt.plot('University Rating', 'CGPA', data=data, linestyle='none',marker='o', alpha=0.4)\nplt.title('CGPA vs University Rating:', fontsize=20, color='grey', loc='left', style='italic')\n\nplt.subplot(224)\nplt.plot('CGPA', 'Chance of Admit ', data=data,linestyle='none', marker='o', color=\"grey\", alpha=0.3)\nplt.title('CGPA vs Chance of Admit', fontsize=20, color='grey', loc='left', style='italic')\n \n# Add a title:\nplt.suptitle('The CGPA effect',fontsize = 30)\nplt.show()","ca46f6c3":"X_train, X_test, y_train, y_test = train_test_split(data.drop('Chance of Admit ',axis=1), \n                 data['Chance of Admit '], test_size=0.33, random_state=42)","28c9b0a0":"### Ridge Regression\nreg = linear_model.Ridge(alpha=.5)\nreg.fit(X_train,y_train)\npred_ridge=reg.predict(X_test)\nprint(\"Mean Squared Error for Ridge Regression: \",mean_squared_error(y_test,pred_ridge))\n\nplt.figure(figsize=(15,5))\nx = np.arange(1,50)\nplt.plot(x,y_test[:49], '-g', label='Actual',color ='r')\nplt.plot(x, pred_ridge[:49], ':b', label='Predicted')\nplt.legend();","c9dce8e9":"#### Ridge regression with built-in cross-validation of the alpha parameter\nreg =linear_model.RidgeCV(alphas=[0.001,0.01,0.1,1.0,10.0], cv=5)\nreg.fit(X_train,y_train)\npred1=reg.predict(X_test)\nprint(\"Mean Squared Error for Bayesian Regression: \",mean_squared_error(y_test,pred1))","0f25203f":"### Bayesian ridge, Lasso Model and ARDRegression\n\nreg = linear_model.BayesianRidge()\nreg.fit(X_train,y_train)\npred1=reg.predict(X_test)\nprint(\"Mean Squared Error for Bayesian Regression: \",mean_squared_error(y_test,pred1))\n\nreg = linear_model.Lasso(alpha=0.001)\nreg.fit(X_train,y_train)\npred1=reg.predict(X_test)\nprint(\"Mean Squared Error for Lasso Regression: \",mean_squared_error(y_test,pred1))\n\nreg = linear_model.ARDRegression()\nreg.fit(X_train,y_train)\npred1=reg.predict(X_test)\nprint(\"Mean Squared Error for ADRRegression: \",mean_squared_error(y_test,pred1))","3bcfd320":"## KNN Regression\nn_neighbors= 15 #Decided After lil Gridsearch of different N values\nreg=neighbors.KNeighborsRegressor(n_neighbors,weights='uniform')\nreg.fit(X_train,y_train)\npred_knn=reg.predict(X_test)\nprint(\"Mean Squared Error for KNN\", mean_squared_error(y_test,pred_knn))\n\nplt.figure(figsize=(15,5))\nx = np.arange(1,50)\nplt.plot(x,y_test[:49], '-g', label='Actual',color ='g')\nplt.plot(x, pred_knn[:49], ':b', label='Predicted')\nplt.legend();","b11bbc57":"## Decision Tree Regression\nall_mse = []\nfor i in range(1,100):\n    reg = tree.DecisionTreeRegressor(max_depth=i)\n    reg.fit(X_train,y_train)\n    pred1=reg.predict(X_test)\n    all_mse.append(mean_squared_error(y_test,pred1))\n    \nbest_max_depth = all_mse.index(min(all_mse))\nreg = tree.DecisionTreeRegressor(max_depth=best_max_depth)\nreg.fit(X_train,y_train)\npred_tree=reg.predict(X_test)\nprint(\"Mean Squared Error for Decision Trees: \",mean_squared_error(y_test,pred_tree))\n\nplt.figure(figsize=(15,5))\nx = np.arange(1,50)\nplt.plot(x,y_test[:49], '-g', label='Actual',color ='brown')\nplt.plot(x, pred_tree[:49], ':b', label='Predicted')\nplt.legend();","52d74cb4":"reg=svm.SVR(kernel='rbf', C=1e3, gamma=0.1)\nreg.fit(X_train,y_train)\npred_svm=reg.predict(X_test)\nprint(\"Mean Squared Error for SVM\", mean_squared_error(y_test,pred_svm))","8d1acddb":"lw = 2\nplt.figure(figsize=(17,7))\nplt.scatter(x, y_test[:49], color='darkorange', label='data')\nplt.plot(x, pred_ridge[:49], color='navy', lw=lw, label='Ridge model')\nplt.plot(x, pred_knn[:49], color='cornflowerblue', lw=lw, label='KNN model')\nplt.plot(x, pred_svm[:49], color='c', lw=lw, label='SVM model')\nplt.plot(x, pred_tree[:49], color='g', lw=lw, label='Tree model')\nplt.title('Comparison of Regression Models')\nplt.legend()\nplt.show()","75cac3c2":"data['admission'] = data['Chance of Admit '] \ndata.admission[data.admission >=0.8] = 1 \ndata.admission[data.admission <0.8 ] = 0","af47272f":"df = data.drop('Chance of Admit ',axis=1)","061c3b8b":"X_train, X_test, y_train, y_test = train_test_split(data.drop('admission',axis=1), \n                 data['admission'], test_size=0.33, random_state=42)\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nprediction=nb.predict(X_test)\nprint(\"F1 SCORE for Naive Bayes:\",metrics.f1_score(y_test, prediction, average='weighted'))\n\nclf = LogisticRegression(random_state=0, multi_class='ovr')\nmodel = clf.fit(X_train, y_train)\nprediction=model.predict(X_test)\nprint(\"F1 SCORE for Logistic Regression:\",metrics.f1_score(y_test, prediction, average='weighted'))\n\ndecisiontree=DecisionTreeClassifier()\ndecisiontree.fit(X_train, y_train)\nprediction=decisiontree.predict(X_test)\nprint(\"F1 SCORE For Decision Trees:\",metrics.f1_score(y_test, prediction, average='weighted'))\n\nneigh = KNeighborsClassifier(n_neighbors=5)\nneigh.fit(X_train, y_train)\nprediction=neigh.predict(X_test)\nprint(\"F1 SCORE for KNN:\",metrics.f1_score(y_test, prediction, average='weighted'))\n\nrandomforest=RandomForestClassifier(n_estimators =100)\nrandomforest.fit(X_train, y_train)\nprediction=randomforest.predict(X_test)\nprint(\"F1 SCORE for Random Forest:\",metrics.f1_score(y_test, prediction, average='weighted'))","69f873ae":"### Comparing the different used Models","c456ce2d":"### The Factors that affect your Admissions (According to the data)\n\n- GRE and TOEFL Score\n\n- University Rating \n\n- Your CGPA (ughh)\n\n- Reccomendation Letter and Statement of Purpose\n\n- Research\n\nLets see how much each of them affect your chances\n\n\n### Order of Feature correlation with chance of admission\n\n1. CGPA\n2. GRE\n3. TOEFL \n4. Rating \n5. SOP\n6. LOR\n7. Research","c7dec5a2":"# Basic EDA Regression and Classification Models","7f471e7a":"### Exploring the distribution of features","59c5627d":"### Impact of Research on University Ratings and Test scores \n\nStudents with research history tend to get higher scores in tests and get into high rated universities (as expected)","5ca1dafc":"### Does CGPA matter that much tho ?\n\nLooks like it does matter...very much so","49cec471":"### Lets Convert this into a classification Problem \n\nLet 80% be the threshold for Admission","e2c60485":"## WOAH WOAH HOLD UP AND CHECK THIS OUT !!!!!!!!!!\n\n## WE ARE GETTING 100% Accuracy in the test set ","65fa9ec3":"### Building Regression Models","c7fb7b12":"### Lets just drop the Serial number column as it's unnecessary"}}