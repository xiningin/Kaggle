{"cell_type":{"f34855a3":"code","6794e209":"code","b779a20b":"code","e9d9a068":"code","6c60223d":"code","73ffb589":"code","64c27f84":"code","47a428af":"code","d78f208e":"markdown","7575d04c":"markdown","43de59e3":"markdown","7c776181":"markdown","15afd0fb":"markdown","91e6a0bd":"markdown","849d250d":"markdown","814aa009":"markdown"},"source":{"f34855a3":"import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(r\"\/kaggle\/input\/digit-recognizer\/train.csv\")","6794e209":"class image_data_set(Dataset):\n    def __init__(self, df, flg=\"train\"):\n        self.flg = flg\n        if self.flg == \"train\":\n            self.images = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.labels = torch.from_numpy(df.iloc[:,0].values)\n            self.transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.RandomAffine(\n                    degrees=45,\n                    translate=(0.1, 0.1),\n                    scale=(0.8, 1.2),\n                    fillcolor=0\n                ),\n                transforms.ToTensor(),\n            ])\n        else:\n            self.images = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.ToTensor(),\n            ])\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        if self.flg == \"train\":\n            return self.transform(self.images[idx]), self.labels[idx]\n        else:\n            return self.transform(self.images[idx])","b779a20b":"train_set = image_data_set(train)\ntrain_loader = DataLoader(train_set, batch_size = 100, shuffle = False)","e9d9a068":"def conv_layer(\n    channel_in,\n    channel_out,\n    kernel_size=3,\n    stride=1,\n    padding=0,\n    activation=nn.ReLU(True),\n    use_norm=True\n):\n    sequence = []\n    sequence += [nn.Conv2d(channel_in, channel_out, kernel_size=kernel_size, padding=padding, stride=stride, padding_mode=\"replicate\", bias=False)]\n    sequence += [activation]\n    sequence += [nn.BatchNorm2d(channel_out)]\n\n    return nn.Sequential(*sequence)\n\n# \u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\nclass ImprovedLeNet5(nn.Module):\n    def __init__(self):\n        super(ImprovedLeNet5, self).__init__()\n        \n        # conv block\n        sequence = []\n        sequence += [conv_layer(1, 32)]\n        sequence += [conv_layer(32, 32)]\n        sequence += [conv_layer(32, 32, kernel_size=5, padding=2, stride=2)]\n        sequence += [nn.Dropout(0.4)]\n        sequence += [conv_layer(32, 64)]\n        sequence += [conv_layer(64, 64)]\n        sequence += [conv_layer(64, 64, kernel_size=5, padding=2, stride=2)]\n        sequence += [nn.Dropout(0.4)]\n        sequence += [conv_layer(64, 128, kernel_size=4)]\n        self.conv_block = nn.Sequential(*sequence)\n        \n        # dense block\n        sequence = []\n        sequence += [nn.Linear(128, 10)]\n        sequence += [nn.Dropout(0.1)]\n        sequence += [nn.Softmax(dim=1)]\n        self.dense_block = nn.Sequential(*sequence)\n        \n    def forward(self, input_image):\n        feature_map = self.conv_block(input_image)\n        output = self.dense_block(feature_map.flatten(1))\n        return output","6c60223d":"device = torch.device(\"cuda\")\nmodel = ImprovedLeNet5().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","73ffb589":"model.train()\nfor epoch in range(45):\n    train_loss = 0\n    correct = 0\n    for images, labels in train_loader:\n        #GPU\u306e\u5229\u7528\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # \u52fe\u914d\u306e\u521d\u671f\u5316\n        optimizer.zero_grad()\n\n        # \u9806\u4f1d\u64ad\n        outputs = model(images)\n        \n        # \u30ed\u30b9\u306e\u8a08\u7b97\u3068\u9006\u4f1d\u64ad\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n\n        # \u6b63\u7b54\u6570\u3092\u8a08\u7b97\n        predicted = outputs.data.max(1, keepdim=True)[1] \n        correct += predicted.eq(labels.data.view_as(predicted)).cpu().sum()\n        \n        train_loss += loss.item()\n        \n    print(f\"Epoch: {epoch+1}\/{45}.. \",\n          f\"Training Loss: {train_loss\/len(train_loader):.3f}.. \",\n          f\"Training Accu: {correct\/len(train_loader):.3f}.. \")","64c27f84":"test = pd.read_csv(r\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntest_set = image_data_set(test, flg='test')\ntest_loader = DataLoader(test_set, batch_size = 100, shuffle = False)\n\nmodel.eval()\ntest_predicted = torch.LongTensor()\nfor i, data in enumerate(test_loader):\n    data = data.cuda()\n    output = model(data)\n    predicted = output.cpu().data.max(1, keepdim=True)[1]\n    test_predicted = torch.cat((test_predicted, predicted), dim=0)","47a428af":"submission_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission_df['Label'] = test_predicted.numpy().squeeze()\nsubmission_df.to_csv(\"my_submission.csv\", index=False, header=True)","d78f208e":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u63a8\u8ad6","7575d04c":"# \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2","43de59e3":"# \u53c2\u8003 Discussion\nhttps:\/\/www.kaggle.com\/c\/digit-recognizer\/discussion\/61480\n\n# \u53c2\u8003 Notebook\nhttps:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist","7c776181":"# \u6539\u5584\u4e8b\u9805\n\n* Validation set \u306b\u3088\u308b Early Stopping\n* \u30e2\u30c7\u30eb\u306e\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\n","15afd0fb":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport","91e6a0bd":"# Dataset\u30af\u30e9\u30b9\u306e\u5b9a\u7fa9\n## \u3053\u306e\u4e2d\u3067\u30c7\u30fc\u30bf\u306e\u52a0\u5de5\u3092\u5168\u90e8\u3067\u304d\u308b\u3068\u7dba\u9e97","849d250d":"# \u63d0\u51fa\u30c7\u30fc\u30bf\u306e\u4f5c\u6210","814aa009":"# \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5b9a\u7fa9\n## \u4eca\u56de\u306f\u4ee5\u4e0b\u306eNotebook\u3067\u7d39\u4ecb\u3055\u308c\u3066\u3044\u308bLeNet5\u306e\u6539\u826f\u7248\u3092Pytorch\u3067\u66f8\u304f\n### https:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist"}}