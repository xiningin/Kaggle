{"cell_type":{"21df33c9":"code","884e0f1e":"code","6a449b84":"code","7f7c48fe":"code","904b2abc":"code","4cfdb217":"code","96deb31f":"code","df6a1d17":"code","d2c2fda5":"code","90c258af":"code","4b37145b":"code","e4cb5e69":"code","946829c4":"code","11261752":"code","e1551b5f":"code","5fc3ba35":"code","ac29a7a7":"code","71ca2c93":"code","e62b174d":"code","3586a8a5":"code","28d0c79d":"code","42b7539f":"code","fcbde641":"code","a7967eaf":"code","95ecd749":"code","c876837f":"code","a4d3d137":"code","dcc5a7f1":"code","6112ad60":"code","ec2c4d2d":"code","985fc187":"code","8c08711a":"code","4b44f73e":"code","3f72d251":"code","7554de6e":"code","b167a870":"code","d5c3d84a":"code","145dcc41":"code","9106b209":"code","56c544e5":"code","a2344675":"code","0f3d4ede":"code","1a485989":"code","346715ab":"code","7020d864":"code","8318e591":"code","333a7320":"code","d0bbe417":"code","74ae5df5":"code","a111063f":"code","60809e85":"code","9192b7c4":"code","3e7b09b4":"code","5ffc5651":"code","71f65861":"code","bbb14f54":"code","c8485b80":"code","eda84f6a":"code","a8a81af3":"code","f9730403":"markdown","14f3fa16":"markdown","5fd1d172":"markdown","a3641223":"markdown","cb7cb403":"markdown","0b5fce8a":"markdown","484329f5":"markdown","cd1ca29f":"markdown","dd6b394a":"markdown","32b31043":"markdown","3f46fe85":"markdown","ab8d4b9a":"markdown","9600f0fe":"markdown","102b4c32":"markdown","aac714e3":"markdown","e1af44e8":"markdown","9d13fbc8":"markdown","b6f346aa":"markdown","5aa23d90":"markdown","2d54f007":"markdown","de673dbb":"markdown","afd9c372":"markdown","474c8d8a":"markdown","a6325313":"markdown","415d45ce":"markdown","4408e151":"markdown","a5b791bb":"markdown","c8bba959":"markdown","240cea21":"markdown"},"source":{"21df33c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","884e0f1e":"df = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","6a449b84":"len(df)","7f7c48fe":"df.head()","904b2abc":"df.describe()","4cfdb217":"df.info()","96deb31f":"df.select_dtypes('object').columns","df6a1d17":"df.select_dtypes('float64').columns","d2c2fda5":"import plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt","90c258af":"df['Date']=pd.to_datetime(df['Date'],format='%Y-%m-%d')","4b37145b":"df['Year']=df['Date'].dt.year\ndf['Month']=df['Date'].dt.month\ndf['day']=df['Date'].dt.day","e4cb5e69":"cat_columns = df.select_dtypes('object').columns.to_list()","946829c4":"cat_columns","11261752":"#lets get the list of Nuemrical feature column list\nnum_cols = df.select_dtypes('number').columns.to_list()","e1551b5f":"num_cols","5fc3ba35":"num_cols.remove('Year')\nnum_cols.remove('Month')\nnum_cols.remove('day')","ac29a7a7":"plt.figure(figsize=(10,8))\nsns.heatmap(df[num_cols].corr(), annot=True)","71ca2c93":"df[['MinTemp','Temp3pm']].corr()['MinTemp'][1]","e62b174d":"treshold=0.68\ncorr_cols=[]\nfor i in num_cols:\n    \n    for j in num_cols:\n        if i == j:\n            continue\n        #print(df[[i,j]].corr()[j])\n        if df[[i,j]].corr()[i][1] >= treshold:\n            print(\"{} is highly coorelated with {} at {:.2f}\".format(i,j,df[[i,j]].corr()[i][1] ))\n            corr_cols.append(j)\n        ","3586a8a5":"corr_cols=list(set(corr_cols))","28d0c79d":"sns.pairplot(df[corr_cols], diag_kind='hist', kind='scatter')","42b7539f":"df[num_cols].describe()","fcbde641":"px.box(df, x=['Rainfall', 'Evaporation', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm'])","a7967eaf":"#Rainfall Feature\nfor i in ['Rainfall', 'Evaporation', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm']:\n    IQR = df[i].quantile(0.75)-df[i].quantile(0.25)\n    lower_fence=df[i].quantile(0.25)-(IQR*1.5)\n    upper_fence=df[i].quantile(0.75)+(IQR*1.5)\n    print(\"{} has the upper fence : {:0.2f} & lower fence : {:0.2f}\".format(i,upper_fence,lower_fence))\n","95ecd749":"df[num_cols].isnull().sum()","c876837f":"#percentate of null values in the data set\ndf[num_cols].isnull().sum()\/len(df)","a4d3d137":"df['MinTemp'].mode()[0]","dcc5a7f1":"df['MinTemp'].median()","6112ad60":"for i in num_cols:\n    df[i].fillna(df[i].median(), inplace=True)","ec2c4d2d":"df[num_cols].isnull().sum()","985fc187":"#lets work on the Categorical features\ndf[cat_columns].isnull().sum()\/len(df)","8c08711a":"df[cat_columns].isnull().sum()\/len(df)","4b44f73e":"for i in cat_columns:\n    df[i].fillna(df[i].mode()[0], inplace=True)","3f72d251":"df[cat_columns].isnull().sum()","7554de6e":"df.isnull().sum()","b167a870":"df1=df.copy()","d5c3d84a":"df1['Rainfall']=df1['Rainfall'].apply(lambda x: np.where(x>2.00,2.00,x))\ndf1['Evaporation']=df1['Evaporation'].apply(lambda x: np.where(x>14.60,14.60,x))\ndf1['WindGustSpeed']=df1['WindGustSpeed'].apply(lambda x: np.where(x>73.50,73.50,x))\ndf1['WindSpeed9am']=df1['WindSpeed9am'].apply(lambda x: np.where(x>37.00,37.00,x))\ndf1['WindSpeed3pm']=df1['WindSpeed3pm'].apply(lambda x: np.where(x>40.50,40.50,x))","145dcc41":"df1.describe()","9106b209":"df.boxplot(column=['Rainfall','Evaporation','WindGustSpeed','WindSpeed9am','WindSpeed3pm'])","56c544e5":"df1.boxplot(column=['Rainfall','Evaporation','WindGustSpeed','WindSpeed9am','WindSpeed3pm'])","a2344675":"y=df1['RainTomorrow']\nX=df1.drop(labels=['RainTomorrow','Date'], axis=1)","0f3d4ede":"from sklearn.preprocessing import label_binarize, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)","1a485989":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler","346715ab":"encode=OneHotEncoder()\nscaler = MinMaxScaler()\nfrom sklearn.compose import make_column_transformer, ColumnTransformer\n#encode.fit_transform(X_train[['Location']])","7020d864":"X_train.select_dtypes('float').columns","8318e591":"num_cols=['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n       'Temp9am', 'Temp3pm']","333a7320":"cat_cols=['Location','WindGustDir','WindDir9am','WindDir3pm','RainToday']","d0bbe417":"#column_transformer = make_column_transformer(\n#(encode,['Location','WindGustDir','WindDir9am','WindDir3pm','RainToday']),\n#remainder='passthrough')\ncolumn_transformer1 = ColumnTransformer(\n[('cat_feat',encode,cat_cols),\n('num_feat',scaler,num_cols)\n],\nremainder='passthrough')","74ae5df5":"X_train=column_transformer1.fit_transform(X_train)","a111063f":"X_test =column_transformer1.transform(X_test)","60809e85":"y_train=y_train.map({'Yes':1,'No':0})\ny_test=y_test.map({'Yes':1,'No':0})","9192b7c4":"from sklearn.linear_model import LogisticRegression","3e7b09b4":"model=LogisticRegression()","5ffc5651":"model.fit(X_train,y_train)","71f65861":"y_pred = model.predict(X_test)","bbb14f54":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","c8485b80":"accuracy_score(y_test, y_pred)","eda84f6a":"print(classification_report(y_test,y_pred))","a8a81af3":"sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)","f9730403":"# Explore Categorical Datatype","14f3fa16":"Before and after handling Outliers","5fd1d172":"1. Rainfall has the upper fence : 2.00 & lower fence : -1.20\n2. Evaporation has the upper fence : 14.60 & lower fence : -4.60\n3. WindGustSpeed has the upper fence : 73.50 & lower fence : 5.50\n4. WindSpeed9am has the upper fence : 37.00 & lower fence : -11.00\n5. WindSpeed3pm has the upper fence : 40.50 & lower fence : -3.50","a3641223":"Null Values in Numerical features","cb7cb403":"# Reports to test the model accuracy","0b5fce8a":"# Identify Target vairable","484329f5":"# Target Variable\n\nLets encode the Target variable","cd1ca29f":"null values in the numerical columns has been removed. ","dd6b394a":"Identify outliers","32b31043":"All Null values in the Dataset has been handled.","3f46fe85":"There are 7 Categorical data, and i belive Date columns must be data object for our detailed analysis","ab8d4b9a":"# Read Data","9600f0fe":"# Result\nModel can predict the Rain with 83% accuracy Score","102b4c32":"in this case the numerical values has outliers which we need to deal with. so, let us fill the null values in numerical features with Median values.","aac714e3":"# Ploting","e1af44e8":"# Analysing Numerical features","9d13fbc8":"Initial level analysis to understand the data and data type.","b6f346aa":"From the above table we can see that the features like Rainfall, Evaporation, WindGustSpeed, WindSpeed9am, WindSpeed3pm has high outliers","5aa23d90":"There are 16 columns with Integer values. ","2d54f007":"# Feature Engineering\n1. Remove outliers\n2. Handel null values","de673dbb":"# Create & Train Model","afd9c372":"It is clear that the above said features has the outliers. lets us use Interquaritle Range method to remove the Outliers","474c8d8a":"# Problem Statement\ndataset is provided with data to predict the rain in Australia. our aim in this notebook to do the EDA with the data set provided. do feature engnineering, feature analysis and create a machinlearning model to predict the Rain.","a6325313":"['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday','RainTomorrow']  are the categorical values. we need to convert the categorical features with Onehot encoder or binary encoding techinque to convert it as numerical variables.","415d45ce":"Set of highly coorelated features","4408e151":"lets find the linearity between the highly coorelated Variables","a5b791bb":"# Exploratory Data Analysis","c8bba959":"![Rain In Australia](https:\/\/res-3.cloudinary.com\/the-university-of-melbourne\/image\/upload\/s---y185jhN--\/c_limit,f_auto,q_75,w_1784\/v1\/pursuit-uploads\/4be\/f69\/882\/4bef6988217e9f3be436803052345f9b7fc2752087fa9e4d56c3dc600c07.jpg)","240cea21":"# Pipeline & Column Transformer\nCreate pipeline & Column Transforment to Transform the Categorical & Numerical Features"}}