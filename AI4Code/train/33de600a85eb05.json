{"cell_type":{"f0ed0adc":"code","8622e82c":"code","62a1639b":"code","a2e39e56":"code","53545a2b":"code","140053de":"code","e2aef7b9":"code","bf65fbd5":"code","24c1453b":"code","dde699a6":"markdown","651fa683":"markdown","ec0cc7bc":"markdown","6fc22c75":"markdown","ae592894":"markdown","423a41b2":"markdown","ceef10dd":"markdown"},"source":{"f0ed0adc":"# Chargement des librairies n\u00e9cessaires pour le code.\nimport pandas as p # pour read_csv(), etc.\nimport numpy as np # pour random.seed(), where(), etc.\nimport time # pour time(), afin de mesurer le temps d'ex\u00e9cution du programme.\nfrom sklearn.model_selection import train_test_split # pour train_test_split().\nfrom keras.models import Sequential # pour add(), Sequential(), compile(), etc. \nfrom keras.layers import Dense # pour Dense(), compile(), etc.\n\n# On initialise la graine du G\u00e9n\u00e9rateur de Nombre Al\u00e9atoire (RNG) afin de rendre le r\u00e9sultat reproductible.\nnp.random.seed(7)","8622e82c":"# Cr\u00e9ation et initialisation d'une fonction, qui prend une variable de type liste\/tableau.\n# Cette fonction a pour but d'obtenir chaque moyenne des valeurs de chaque colonne, comme par exemple la colonne Glucose,\n# Tout en \u00e9liminant toute valeur nulle.\ndef moyColonne(table):\n    # Cr\u00e9ation d'une liste contenant les noms de chaque colonne qui nous int\u00e9resse dans le tableau \"table\".\n    colonesAmoyenner = table.columns\n    colonesAmoyenner = colonesAmoyenner.drop('Outcome')\n    \n    # Parcours des noms pr\u00e9sent dans la liste colonesAmoyenner d\u00e9clarer au-dessus. \n    for c in colonesAmoyenner:\n        #Calcul de la moyenne de la colonne \"c\" du tableau \"table\", dont les valeurs sont sup\u00e9rieurs \u00e0 0.\n        moyColonnes = table[table[c] > 0][c].mean()\n        \n        # np.where(condition, valeur si vrai, valeur si fausse)\n        # Ajout d'une colone portant le nom actuel de la colone + '_imputed'.\n        # Cette nouvelle colone prend la valeur d'origine si elle est diff\u00e9rente de 0, ou la valeur moyenne de cette colone sinon.\n        table[c + '_imputed'] = np.where(table[c] != 0, table[c], moyColonnes)\n\n\n# Lecture du fichier \"diabetes.csv\"\ndf = p.read_csv(\"..\/input\/diabetes.csv\")\n# Divise notre ensemble de donn\u00e9es en 2 parties \"Train\" et \"Test\". Ici, train contiendra 70% de l'ensemble de donn\u00e9es et test seulement 30%\ntrain, test = train_test_split(df, test_size = 0.3, random_state = 0)\n\n# Les donn\u00e9es de test peuvent parfois \u00eatre fauss\u00e9, c'est pour cela que l'on remplace les 0 par la valeur moyenn\u00e9 de la colonne.\nmoyColonne(test)\n#moyColonne(train)\n\n# On retire la colonne Outcome.\nX_train = train.drop('Outcome', axis = 1, inplace = False)\n\n# On retire les colonnes non-imput\u00e9s.\n#X_train = train.drop(df.columns, axis = 1, inplace = False)\nX_test = test.drop(df.columns, axis = 1, inplace = False)\n\n# On r\u00e9cup\u00e8re l'Outcome de chaque tableau train et test.\nY_train = train[['Outcome']]\nY_test = test[['Outcome']]","62a1639b":"# Initialisation du mod\u00e8le.\n# Sequential permet la cr\u00e9ation d'une pile de couche lin\u00e9aire vide.\nmodel = Sequential()\n\n# Ajout de types de couches de r\u00e9seau de neuronnes gr\u00e2ce \u00e0 \"add\" au mod\u00e8le.\n# Dense permet de cr\u00e9er un r\u00e9seau de neuronnes fully-connected. On ajoute donc des couches de r\u00e9seaux de neuronnes fully-connected.\n# Les param\u00e8tres de Dense, ici, sont:\n#    - La dimension de l'espace de sortie.\n#    - La dimension de l'espace entrant ('input_dim').\n#    - La fonction d'activation, c-\u00e0-d une fonction math\u00e9matique appliqu\u00e9 \u00e0 un signal\n#       (cf https:\/\/fr.wikipedia.org\/wiki\/Fonction_d%27activation).\n#        o La fonction \"relu\", ou \"ReLU\", signifie Rectification Linear Unit (Unit\u00e9 de Rectification Lin\u00e9aire).\n#              En d'autres termes: y = 0 si x <= 0, y = x si x > 0.\n#        o La fonction \"sigmoid\", ou \"marche douce\", est une exponentielle invers\u00e9e \u00e0 puissance n\u00e9gative.\n#              En d'autres termes: y = 1 \/ (1 + exp(-x)).\nmodel.add(Dense(12, input_dim=8, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compillation du mod\u00e8le, c-\u00e0-d que le mod\u00e8le est configur\u00e9 pour l'entra\u00eenement.\n# Les param\u00e8tres de compile, ici, sont:\n#    - Un String ou une fonction loss, ou d'optimisation du score. (REQUIS)\n#    - L'optimisateur, ou instance de la classe optimizer. (REQUIS)\n#    - La mesure du r\u00e9sultat (ici, une probabilit\u00e9).\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","a2e39e56":"#R\u00e9cup\u00e9ration du temps pour chronom\u00e8trer le temps d'entra\u00eenement\nstart_time = time.time()\n# Entra\u00eenement du mod\u00e8le sur les donn\u00e9es X et Y \"_train\".\n# Le mod\u00e8le lira \"epochs fois\" les donn\u00e9es X et Y train, qui sont divis\u00e9 par 10 pour chaque pente de la courbe d'entra\u00eenement.\n# Les param\u00e8tres de fit, ici, sont:\n#    - Les donn\u00e9es d'entr\u00e9es.\n#    - Les donn\u00e9es de sortie.\n#    - Le nombre d'it\u00e9ration sur toutes les donn\u00e9es d'entr\u00e9e et de sortie pour entra\u00eener le r\u00e9seau de neuronnes.\n#    - Le nombres de donn\u00e9es par pente mis-\u00e0-jour.\n#    - L'affichage de l'entra\u00eenement \u00e0 chaque \"epoch\". Ici, aucun affichage.\nmodel.fit(X_train, Y_train, epochs=1500, batch_size=32, verbose = 0)\n\n# Affichage du temps d'ex\u00e9cution du programme.\ntemps_exec = time.time() - start_time\nprint(\"\\nNombre de secondes mis par le programme: %.3f secondes\" % temps_exec)","53545a2b":"# Test du mod\u00e8le sur les donn\u00e9es X et Y \"_test\".\n# Le mod\u00e8le sera test\u00e9 sur la cr\u00e9ation du courbe dont chaque pente contient 10 donn\u00e9es de test.\n# Les r\u00e9sultats sont renvoy\u00e9s dans les tableaux model.metrics_names et scores.\n# La premi\u00e8re colonne concerne le loss, la deuxi\u00e8me la pr\u00e9cision (accuracy).\nscores = model.evaluate(X_test, Y_test, batch_size = 10, verbose = 0)\n\n# Affichage du score obtenu.\n# On affiche ici la pr\u00e9cision du mod\u00e8le sur le test \u00e9valu\u00e9 pr\u00e9c\u00e9demment,\n# l'affichage \u00e9tant en poucentage avec 2 chiffres apr\u00e8s la virgule.\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))\n","140053de":"#ici le code dans son int\u00e9gralit\u00e9 avec plusieurs essais sur le nombre d'\u00e9poques\nimport pandas as p\nimport numpy as np\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\np.options.mode.chained_assignment = None  # default='warn'\nbatch_size = 32\n\ndef moyColonne(table):\n    colonesAmoyenner = table.columns\n    colonesAmoyenner = colonesAmoyenner.drop('Outcome')\n    for c in colonesAmoyenner:\n        moyColonnes = table[table[c] > 0][c].mean()\n        table[c + '_imputed'] = np.where(table[c] != 0, table[c], moyColonnes)\n        \nnp.random.seed(7)\ndf = p.read_csv(\"..\/input\/diabetes.csv\")\n\ntrain, test = train_test_split(df, test_size = 0.3, random_state = 0)\nmoyColonne(test)\nX_train = train.drop('Outcome', axis = 1, inplace = False)\nX_test = test.drop(df.columns, axis = 1, inplace = False)\nY_train = train[['Outcome']]\nY_test = test[['Outcome']]\n\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=8, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nstart_time = time.time()\nmodel.fit(X_train, Y_train, epochs=500, batch_size=batch_size, verbose = 0)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le pour 500 \u00e9poques : %.3f secondes\" % temps_exec)\n\nscores = model.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 0)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))\n\nstart_time = time.time()\nmodel.fit(X_train, Y_train, epochs=1000, batch_size=batch_size, verbose = 0)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le pour 1000 \u00e9poques : %.3f secondes\" % temps_exec)\n\nscores = model.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 0)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))\n\nstart_time = time.time()\nmodel.fit(X_train, Y_train, epochs=1500, batch_size=batch_size, verbose = 0)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le pour 1500 \u00e9poques : %.3f secondes\" % temps_exec)\n\nscores = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose = 0)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))","e2aef7b9":"#ici le code dans son int\u00e9gralit\u00e9 avec plusieurs essais sur la d\u00e9finition du r\u00e9seau de neurones\nimport pandas as p\nimport numpy as np\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\np.options.mode.chained_assignment = None  # default='warn'\nbatch_size = 32\n\ndef moyColonne(table):\n    colonesAmoyenner = table.columns\n    colonesAmoyenner = colonesAmoyenner.drop('Outcome')\n    for c in colonesAmoyenner:\n        moyColonnes = table[table[c] > 0][c].mean()\n        table[c + '_imputed'] = np.where(table[c] != 0, table[c], moyColonnes)\n        \nnp.random.seed(7)\ndf = p.read_csv(\"..\/input\/diabetes.csv\")\n\ntrain, test = train_test_split(df, test_size = 0.3, random_state = 0)\nmoyColonne(test)\nX_train = train.drop('Outcome', axis = 1, inplace = False)\nX_test = test.drop(df.columns, axis = 1, inplace = False)\nY_train = train[['Outcome']]\nY_test = test[['Outcome']]\n\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nstart_time = time.time()\nmodel.fit(X_train, Y_train, epochs=1000, batch_size=batch_size, verbose = 0)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le pour 1000 \u00e9poques : %.3f secondes\" % temps_exec)\n\nscores = model.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 0)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))\n\nmodel2 = Sequential()\nmodel2.add(Dense(12, input_dim=8, activation='relu'))\nmodel2.add(Dense(8, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))\nmodel2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nstart_time = time.time()\nmodel2.fit(X_train, Y_train, epochs=1000, batch_size=batch_size, verbose = 0)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le pour 1000 \u00e9poques : %.3f secondes\" % temps_exec)\n\nscores = model2.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 0)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))\n\nmodel3 = Sequential()\nmodel3.add(Dense(32, input_dim=8, activation='relu'))\nmodel3.add(Dense(16, input_dim=8, activation='relu'))\nmodel3.add(Dense(8, activation='relu'))\nmodel3.add(Dense(1, activation='sigmoid'))\nmodel3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nstart_time = time.time()\nmodel3.fit(X_train, Y_train, epochs=1000, batch_size=batch_size, verbose = 0)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le pour 1000 \u00e9poques : %.3f secondes\" % temps_exec)\n\nscores = model3.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 0)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))","bf65fbd5":"#ici l'entra\u00eenement compar\u00e9 au K Nearest Neighbors\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn_uni = KNeighborsClassifier(n_neighbors=11, weights = 'uniform')\nstart_time=time.time()\nknn_uni.fit(X_train, Y_train.values.ravel())\nY_pred = knn_uni.predict(X_test)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le : %.3f secondes\" % temps_exec)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (accuracy_score(Y_test, Y_pred) * 100))","24c1453b":"#ici le code dans son int\u00e9gralit\u00e9\nimport pandas as p\nimport numpy as np\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\np.options.mode.chained_assignment = None  # default='warn'\nbatch_size = 32\n\ndef moyColonne(table):\n    colonesAmoyenner = table.columns\n    colonesAmoyenner = colonesAmoyenner.drop('Outcome')\n    for c in colonesAmoyenner:\n        moyColonnes = table[table[c] > 0][c].mean()\n        table[c + '_imputed'] = np.where(table[c] != 0, table[c], moyColonnes)\n        \nnp.random.seed(7)\ndf = p.read_csv(\"..\/input\/diabetes.csv\")\n\ntrain, test = train_test_split(df, test_size = 0.3, random_state = 0)\nmoyColonne(test)\nX_train = train.drop('Outcome', axis = 1, inplace = False)\nX_test = test.drop(df.columns, axis = 1, inplace = False)\nY_train = train[['Outcome']]\nY_test = test[['Outcome']]\n\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nstart_time = time.time()\nmodel.fit(X_train, Y_train, epochs=1000, batch_size=batch_size, verbose = 0)\ntemps_exec = time.time() - start_time\nprint(\"\\nTemps pass\u00e9 \u00e0 entra\u00eener le mod\u00e8le pour 1000 \u00e9poques : %.3f secondes\" % temps_exec)\n\nscores = model.evaluate(X_test, Y_test, batch_size = batch_size, verbose = 0)\nprint(\"Le taux de r\u00e9ussite est de : %.2f%%\" % (scores[1] * 100))","dde699a6":"## 3.\tPr\u00e9paration des donn\u00e9es\n\nLors de cette \u00e9tape, il est n\u00e9cessaire d'ouvrir notre ensemble de donn\u00e9es et de le diviser en 2 parties (notre ensemble d'apprentissage et notre jeu de test) et d'effectuer un pr\u00e9traitement pour \u00eatre sur que notre ensemble de donn\u00e9es et pr\u00eat \u00e0 \u00eatre utilis\u00e9s.","651fa683":"\n## Mini projet 1\n# PR\u00c9DICTION DE DIAB\u00c8TE \u00c0 L'AIDE DE KERAS\n## 1.\t\u00c9tude r\u00e9alis\u00e9e \nDans le cadre de ce mini projet, nous avons \u00e9t\u00e9 amen\u00e9 \u00e0 \u00e9tudier la biblioth\u00e8que Keras. Pour se faire, nous avons souhait\u00e9 mettre en place un programme python en utilisant cette biblioth\u00e8que. Nous avons souhait\u00e9 compar\u00e9 les r\u00e9sultats obtenus. \nIci, nous avons utilis\u00e9 les donn\u00e9es fournies lors du TD de deep learning (Diabete.csv). Les r\u00e9sultats attendues ne sont donc pas d'une grande pr\u00e9cision car nous n'avons \u00e0 disposition qu'un petit ensemble d'apprentissage (environ 700 donn\u00e9es).\n\nLe mini projet avait pour objectif principal est de pr\u00e9dire si oui ou non un patient est atteint du diab\u00e8te \u00e0 partir de certains attributs : \u00e2ge, nombre de grossesses, taux d\u2019insuline, etc.  \n\nVoici une liste des documentations que nous avons \u00e9t\u00e9 amen\u00e9 \u00e0 utilis\u00e9 pour mettre en place ce mini projet:\n>1. [Documentation officielle de python](https:\/\/www.python.org\/ ) \n>2. [Le site officiel de Keras](https:\/\/keras.io\/optimizers\/)\n>3. [Le Machine learning selon Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Machine_learning)\n>4. [Une introduction a Keras](https:\/\/www.youtube.com\/watch?v=J6Ok8p463C4&ab_channel=GoogleCloudPlatform)\n>5. [Un ensemble de projet Github](https:\/\/github.com\/keras-team\/keras\/blob\/master\/examples\/README.md)\n\n\n\n_Mis en place par Kevin Lobjois et Enzo Pasqualini_","ec0cc7bc":"## 4.\tMise en place de notre r\u00e9seau de neurones\n\nIci, nous allons mettre en place notre r\u00e9seau de neurones. Pour notre exemple, nous avons d\u00e9cider de faire un r\u00e9seau de neurones convolutifs ce que l'on appelle plus commun\u00e9ment du deep learning.","6fc22c75":"## 5.\tEntra\u00eenement du mod\u00e8le\n\nUne fois que notre mod\u00e8le est en place et que nos donn\u00e9es sont pr\u00eates \u00e0 \u00eatre utilis\u00e9s. Nous pouvons commencer \u00e0 entra\u00eener notre mod\u00e8le.","ae592894":"## 2.\tL'importation des biblioth\u00e8ques \nPour bien comprendre ce que l'on a fait dans ce projet, il est important de conna\u00eetre les biblioth\u00e8ques que nous avons utilis\u00e9es :\n1. Pandas\n\n    Biblioth\u00e8que open source permetttant la manipulation des donn\u00e9es pour notre ensemble d'apprentissage.\n![](https:\/\/pandas.pydata.org\/_static\/pandas_logo.png)\n2. Numpy\n\n    Biblioth\u00e8que open source permettant d'utiliser des tableaux ou des matrices.\n![](http:\/\/www.numpy.org\/_static\/numpy_logo.png)\n    \n3. sklearn (Scikit learn)\n\n     Biblioth\u00e8que open source permettant de mettre en place notre ensemble d'apprentissage.\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/05\/Scikit_learn_logo_small.svg\/260px-Scikit_learn_logo_small.svg.png)\n\n4. Keras\n\n    Bilbioth\u00e8que open source permettant la mise en place de reseaux de neurones. \n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/c\/c9\/Keras_Logo.jpg)    ","423a41b2":"6. Test du mod\u00e8le\n\nIci, notre mod\u00e8le est entrain\u00e9. Nous avons donc mesurer sa performance \u00e0 l'aide du taux d'accuracy de celui-ci.","ceef10dd":"Lors de cette \u00e9tape, la mise en place de notre r\u00e9seau de neurones a \u00e9t\u00e9 faites.\nOn peut retrouver :\n1. Dense\n1. Optimizer\n\nDense repr\u00e9sente un r\u00e9seau de neurones fully-connected.\n\nCependant, il en existe plein d'autre que l'on peut retrouver sur : [le site officiel de Keras](https:\/\/keras.io\/layers\/about-keras-layers\/)\n\nOptimizer repr\u00e9sente l'optimisation que va faire Keras pour compiler le mod\u00e8le.\n\nDe plus ample renseignement peuvent-\u00eatre retrouv\u00e9 sur : [le site officiel de Keras](https:\/\/keras.io\/optimizers\/)\n\n\n"}}