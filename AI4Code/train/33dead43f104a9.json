{"cell_type":{"d0d8d480":"code","68fc66c8":"code","c489db1d":"code","28602f58":"code","cfefcce9":"code","680f934b":"code","bf68bdaa":"code","66158313":"code","d3344c38":"code","2fc0f1b1":"code","d5d8db7b":"code","c2491904":"code","d8db0ebf":"code","c49cf732":"markdown","f74ccddb":"markdown","cbc671e1":"markdown","452f8243":"markdown","d3f33c9a":"markdown","624caa3e":"markdown","a99bd747":"markdown","0db361eb":"markdown","5f5531e8":"markdown","407739dc":"markdown"},"source":{"d0d8d480":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n!pip install arch\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input\/ntt-data-global-ai-challenge-06-2020\/Crude_oil_trend.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","68fc66c8":"import warnings\nwarnings.simplefilter('ignore')\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn\n\nseaborn.set_style('darkgrid')\nplt.rc(\"figure\", figsize=(16, 6))\nplt.rc(\"savefig\", dpi=90)\nplt.rc(\"font\",family=\"sans-serif\")\nplt.rc(\"font\",size=14)\nfrom arch import arch_model\nfrom sklearn import datasets, linear_model\nfrom sklearn.linear_model import LinearRegression","c489db1d":"data = pd.read_csv(r'..\/input\/ntt-data-global-ai-challenge-06-2020\/Crude_oil_trend.csv',index_col=\"Date\",parse_dates=True)\ncrd_inflation = 100 * data.pct_change().dropna()\nfig = crd_inflation.plot()","28602f58":"from arch import arch_model\n\nam = arch_model(crd_inflation)\nres = am.fit(update_freq=5)\nprint(res.summary())","cfefcce9":"am = arch_model(crd_inflation,p=1,o=1,q=1,power=1.0)\nres = am.fit(update_freq=5)\nprint(res.summary)","680f934b":"fig = res.plot(annualize = 'M')","bf68bdaa":"am = arch_model(crd_inflation,p=1,o=0,q=1,power=1.0,dist='StudentsT')\nres = am.fit(update_freq=5)\nprint(res.summary())","66158313":"from collections import OrderedDict\ncrude_ret = 100 * data.dropna().pct_change().dropna()\nres_normal = arch_model(crude_ret).fit(disp='off')\nres_t = arch_model(crude_ret, dist='t').fit(disp='off')\nres_skewt = arch_model(crude_ret, dist='skewt').fit(disp='off')\nlls = pd.Series(\n    OrderedDict((('normal', res_normal.loglikelihood),\n                 ('t', res_t.loglikelihood), ('skewt',\n                                              res_skewt.loglikelihood))))\nprint(lls)\nparams = pd.DataFrame(\n    OrderedDict((('normal', res_normal.params), ('t', res_t.params),\n                 ('skewt', res_skewt.params))))\nparams","d3344c38":"std_resid = res_normal.resid \/ res_normal.conditional_volatility\nunit_var_resid = res_normal.resid \/ res_normal.resid.std()\ndf = pd.concat([std_resid, unit_var_resid], 1)\ndf.columns = ['Std Resids', 'Unit Variance Resids']\nsubplot = df.plot(kind='kde', xlim=(-4, 4))","2fc0f1b1":"res = arch_model(crude_ret, p=1, o=1, q=1, dist='skewt').fit(disp='off')\npd.DataFrame(res.params)","d5d8db7b":"sim_mod = arch_model(None, p=1, o=1, q=1, dist=\"skewt\")\n\nsim_data = sim_mod.simulate(res.params, 1000)\nsim_data.head()","c2491904":"from arch.univariate import ConstantMean, GARCH, SkewStudent\nimport numpy as np\n\nrs = np.random.RandomState([892380934, 189201902, 129129894, 9890437])\n# Save the initial state to reset later\nstate = rs.get_state()\n\ndist = SkewStudent(random_state=rs)\nvol = GARCH(p=1, o=1, q=1)\nrepro_mod = ConstantMean(None, volatility=vol, distribution=dist)\n\nrepro_mod.simulate(res.params, 1000).head()","d8db0ebf":"# Reset the state to the initial state\nrs.set_state(state)\nrepro_mod.simulate(res.params, 1000).head()","c49cf732":"## Volatility Processes","f74ccddb":"Resetting the state using *set_state* shows that calling simulate using the same underlying state in the\n*RandomState* produces the same objects","cbc671e1":"## Distributions\n> Standardized Student\u2019s T using the distribution property of a mean model","452f8243":"> Plotting the standardized residuals and the conditional volatility shows some large (in magnitude) errors, even when standardized. (Month)","d3f33c9a":"* Simulations is reproduced using a NumPy *RandomState*\n* *RandomState* instance is passed into to the distribution when the model is created\n* Code builds a model with a constant mean, GJR-GARCH volatility and Skew t errors initialized with *RandomState*","624caa3e":"* > The below model is based on involving the components\n* > Three models are fit using alternative distributional assumptions.\n* > The results are printed, where we can see that the normal has a much lower log-likelihood \n    than either the Standard Student\u2019s T or the Standardized Skew Student\u2019s T (neither parallel nor intersecting)\n    The closeness of the T and the Skew T indicate that returns are not heavily misleading.\n","a99bd747":"* The standardized residuals can be computed by dividing the residuals by the conditional volatility\n* The below graph is plotted along with the residuals, the center indicating that the standardized residuals \n  distribution has more varicance than the non-standardized residuals\n","0db361eb":"# ARCH Modeling\n\nARCH models are a popular class of volatility models that use observed values of returns or residuals as volatility shocks.\n\nA complete ARCH model is divided into three components:\n\n* Mean model\n* Volatility process\n* Distribution for the standardized residuals\n\n\n\n\n","5f5531e8":"# Building a Model From Components\n\n## Mean Models\n\nInflation chart","407739dc":"# Simulation \n\n* All mean models show a method to simulate returns from assuming the model is correctly specified.\n* Below is the simulation from a GJR-GARCH(1,1) with Skew-t errors using parameters estimated on the series\n* The simulations returns a DataFrame with 3 columns:\n    1. **data**: The simulated data, which includes any mean dynamics.\n\n    2. **volatility**: The conditional volatility series\n\n    3. **errors**: The simulated errors generated to produce the model. The errors are the difference between the data and its conditional mean, and can be transformed into the standardized errors by dividing by the volatility."}}