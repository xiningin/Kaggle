{"cell_type":{"69155c0e":"code","819ef788":"code","08faa03f":"code","51d2bc22":"code","d11fe09a":"code","5718b09d":"markdown","14053900":"markdown","1e2f0a39":"markdown","8338f56a":"markdown","ad86942b":"markdown","3b94f0a7":"markdown"},"source":{"69155c0e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\nimport os\n# %load_ext tensorboard.notebook\n# %tensorboard --logdir logs\n\nimage_dim = 128\ndef read_label_filepath(path):\n    data = pd.read_csv(path)\n    labels = data.iloc[:,[1]].values\n    zeros = np.zeros((len(labels),5))\n    for i in range(len(labels)): \n        zeros[i,labels[i]]=1 \n    labels = zeros    \n    filename = data.iloc[:,[0]].values\n    trian_path ='..\/input\/diabetic-retinopathy-resized\/resized_train\/resized_train\/' + filename + '.jpeg'\n    return labels , trian_path\n\n\ndef read_images_from_disk(path):\n    file_contents = tf.read_file(path)\n    img_tensor = tf.image.decode_jpeg(file_contents, channels=3)\n    img_final = tf.image.resize_images(img_tensor, (image_dim, image_dim))\n    img_final = tf.cast(img_final, tf.uint8)\n    img_final = tf.image.rgb_to_grayscale(img_final)\n    return img_final\n\n\ntrain_labels,train_filepath = read_label_filepath('..\/input\/diabetic-retinopathy-resized\/trainLabels.csv')\ntrain_filepath=train_filepath.flatten()\n\n\n\n\nlabel_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_labels, tf.int16))\npath_ds = tf.data.Dataset.from_tensor_slices(train_filepath)\nimage_ds = path_ds.map(read_images_from_disk, num_parallel_calls=10)\nimage_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n\n\nlabels_count = np.zeros(shape = 5)\nlabels_iterator = label_ds.make_one_shot_iterator()\nnext_element = labels_iterator.get_next()\nwith tf.Session() as sess:\n    while True:\n        try:\n            lbl = sess.run(next_element)\n            labels_count += lbl\n#             print(labels_count)\n        except tf.errors.OutOfRangeError:\n            break\n\nplt.bar(range(5),height = labels_count)\nplt.ylabel(\"number of labels in each category\")\nplt.xlabel(\"labels\")\nplt.show()\n# Any results you write to the current directory are saved as output.","819ef788":"def init_weight_dist(shape):\n    weights = tf.truncated_normal(shape,stddev=0.1)\n    return tf.Variable(weights)\n\ndef init_bias_vals(shape):\n    biases = tf.constant(1.0,shape=shape)\n    return tf.Variable(biases)\ndef conv2d(x,W):\n    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n\ndef pooling(x):\n    return tf.nn.max_pool(x,ksize=[1,4,4,1],strides=[1,4,4,1],padding='SAME')\n\ndef convolutional_layer(input_x,shape):\n    w = init_weight_dist(shape)\n    b = init_bias_vals([shape[3]])\n    return tf.nn.relu(conv2d(input_x,w)+b)\n\ndef normal_full_layer(input_layer,size):\n    input_size = int(input_layer.get_shape()[1])\n    W = init_weight_dist([input_size,size])\n    b = init_bias_vals([size])\n    return tf.matmul(input_layer,W) + b","08faa03f":"image_dim = 128\nx = tf.placeholder(tf.float32,shape=[None,image_dim,image_dim,1])\ny_true = tf.placeholder(tf.int32,shape=[None,5])\nhold_prob = tf.placeholder(tf.float32)\n\nx_image = tf.reshape(x,[-1,image_dim,image_dim,1])\nprint(x_image.shape)\nconv1 = convolutional_layer(x_image,shape=[50,50,1,32])\nconv1_pool = pooling(conv1)\n\nconv2 = convolutional_layer(conv1_pool,shape=[25,25,32,8])\nconv2_pool = pooling(conv2)\nconv2_flat = tf.reshape(conv2_pool,[-1,51200])\n\nfull_layer_one = tf.nn.relu(normal_full_layer(conv2_flat,128))\nfull_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)\ny_pred = normal_full_layer(full_one_dropout,5)\n\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_true,logits = y_pred))\noptimizer = tf.train.AdamOptimizer(learning_rate=0.01)\ntrain = optimizer.minimize(cross_entropy)\n\ninit = tf.global_variables_initializer()\n\nbatch_data = image_label_ds.batch(100)\niterator = batch_data.make_initializable_iterator()\nnext_element = iterator.get_next()\n","51d2bc22":"# import matplotlib.image as mpimg\nfrom PIL import Image\nimport matplotlib.pyplot as plt\ntrue_wm=Image.open('..\/input\/true-false-img\/true.png').resize((128,128), Image.ANTIALIAS)\nfalse_wm=Image.open('..\/input\/true-false-img\/false.png').resize((128,128), Image.ANTIALIAS)\ndef show_images(batch,matches):\n    plt.rcParams[\"figure.figsize\"]=20,20\n    count = len(batch)\n    sq = int(np.sqrt(count))\n    fig, ax = plt.subplots(sq, sq)\n    \n    for i in range(sq):\n        for j in range(sq):\n            ax[i,j].imshow(np.asarray(batch[i*sq + j]).reshape((128,128)),cmap='gray')\n            if matches[i*sq + j] == True:\n               ax[i,j].imshow(true_wm, aspect='auto', zorder=1, alpha=0.7)\n            else:\n               ax[i,j].imshow(false_wm, aspect='auto', zorder=1, alpha=0.7)  \n    plt.show()","d11fe09a":"num_epoch = 3\nshow_best = False\nwith tf.Session() as sess:\n    sess.run(init)\n    for i in range(num_epoch):\n        sess.run(iterator.initializer)\n        acc_sum = 0\n        j = 0\n        while True:\n            try:\n                batch_x , batch_y  = sess.run(next_element)\n#                 print(\"epoch {}, batch {}: \".format(i+1,j+1) +  str(batch_x.shape))\n                sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob: 0.5})\n                matches = tf.equal(tf.arg_max(y_pred,1),tf.argmax(y_true,1))\n                acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n                \n                \n                acc_res,matches = sess.run([acc,matches],feed_dict={x:batch_x,y_true : batch_y,hold_prob: 1.0})\n                acc_sum += acc_res\n                \n#                 print(\"acc: \" + str(acc_res))\n                if acc_res > 0.9 and show_best == False:\n                    show_best = True\n                    print(\"just for good visualization:\")\n                    print(\"the best batch detection with accuracy {}\".format(str(acc_res)))\n                    show_images(batch_x[0:100],matches[0:100])\n                j += 1\n            except tf.errors.OutOfRangeError:   \n                break\n            except tf.errors.InvalidArgumentError:\n                break\n        print(\"epoch accuracy :\" + str(acc_sum\/j))\n    writer = tf.summary.FileWriter('..\/output\/graphs', sess.graph)","5718b09d":"<h1>design the structure of convolutional neural network:<\/h1>\n<h3>\nfirst of all set the image dim to 128x128.\ndefine place holders:\nin this stucture there are 3 placeholder:\n<\/h3>\n<ul>\n<li>x: placeholder for batch images.<\/li>\n<li>y_true: the corresponding true class label of batch images<\/li>\n<li>hold_prob: a tuning parameter for pruning the CNN<\/li>\n<\/ul>\n","14053900":"<h1>Results:<\/h1>\n<h3>after run 3 epoch it reach to avg accuracy: 0.7346723646859498<\/h3>","1e2f0a39":"<h1>trianing part:<\/h1>\n<h3>until now the strcture of neural network is completely defined so we continue with optimization task for training the weights of convolutional neural network<\/h3>","8338f56a":"<h1> visualization part <\/h1>\n<h4> in this section we define a function that recieve a batch of images and their corresponding matches labels and draw a plot of them<\/h4>","ad86942b":"<h1>functions for creating convolutional neural networks<\/h1>\n<h3>in this part we define some function like initializers and layer makers to facilitate making our neural network.<\/h3>","3b94f0a7":"<h1>load dataset:<\/h1>\n<h3>first we defined some function to load path and label of training images then we have to create a tensorflow dataset <\/h3>"}}