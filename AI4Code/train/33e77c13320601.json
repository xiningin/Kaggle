{"cell_type":{"f755bfd1":"code","7814e048":"code","81cfb18b":"code","1ba6ca39":"code","b21e1a6f":"code","55c54a88":"code","95eb7f80":"code","52bec7e3":"code","7ee8a44b":"code","0b3c7ab7":"code","cd2ccc83":"markdown","cffa1745":"markdown","71e35f99":"markdown","c5025c22":"markdown","5e8bc7a3":"markdown","81989e90":"markdown","c8f2373a":"markdown","03c0d1a5":"markdown"},"source":{"f755bfd1":"from pathlib import Path\nimport pandas as pd\nimport numpy as np\n\n# Data scraping tools\nfrom bs4 import BeautifulSoup\n\n# Display tools\nfrom IPython.core.display import display, Markdown\nimport plotly.express as px","7814e048":"PUB = Path('..\/input\/30dmlleaderboards\/public_lb.html')\nPRIV = Path('..\/input\/30dmlleaderboards\/private_lb.html')\nCSV_PUB = Path('..\/input\/30dmlleaderboards\/30-days-of-ml-publicleaderboard\/30-days-of-ml-publicleaderboard.csv')","81cfb18b":"def _strip_all_spaces(series):\n    # clean up internal and external spaces from a pandas series\n    return series.replace(r\"\\s+\", \" \", regex=True).str.strip()\n\ndef _extract_kernel(element):\n    # scrape title and href attributes from a single BeautifulSoup anchor element\n    try:\n        anchor = element.find('a')\n        title = anchor.get('title')\n        href = anchor.get('href')\n    except AttributeError:\n        title, href = \"\", \"\"\n    return title, href\n\ndef _load_pub_dataframe(pathname=PUB):\n    \"\"\"\n    Scrape the key data items from the HTML version of the public leaderboard.\n    \n    Return a pandas DataFrame\n    \"\"\"\n    with pathname.open() as f:\n        soup = BeautifulSoup(f,'lxml-xml')\n\n    recs = soup.find_all('tr', class_=[\"competition-leaderboard__row\",\n                                       \"competition-leaderboard__row competition-leaderboard__row--user-scored\"\n                                      ])\n    rows = []\n    for rec in recs:\n        record = dict()\n\n        keys = [\"Rank\", \"Team Name\", \"Kernel\", \"Score\", \"Number of Entries\"]\n        for key in keys:\n            if key != \"Kernel\":\n                record[key] = rec.find('td', {\"data-th\" : key}).text\n            else:\n                element = rec.find('td', {\"data-th\" : key})\n                record['KernelTitle'], record['KernelHref'] = _extract_kernel(element)\n\n        record[\"Last Entry\"] = rec.find_all('span')[-1]['title']\n        rows.append(record)\n\n    df = pd.DataFrame(rows)\n    df[\"Last Entry\"] = pd.to_datetime(df[\"Last Entry\"].str.split().str[0:6].str.join(\" \"))\n    df[\"Team Name\"] = _strip_all_spaces( df[\"Team Name\"] )\n    df = df[df[\"Team Name\"].notna()]\n    df.columns = ['Rank', 'TeamName', 'KernelTitle', 'KernelHref', 'Score', 'Entries', 'Latest']\n    df = df.drop(['Score', 'Latest'], axis='columns')    \n    return df\n\ndef _load_priv_dataframe(pathname=PRIV):\n    \"\"\"\n    Scrape the key data items from the HTML version of the private leaderboard.\n    \n    Return a pandas DataFrame\n    \"\"\"\n    with pathname.open() as f:\n        soup = BeautifulSoup(f,'lxml-xml')\n\n    recs = soup.find_all('tr', class_=[\"competition-leaderboard__row\",\n                                       \"competition-leaderboard__row competition-leaderboard__row--user-scored\"\n                                      ])\n    rows = []\n    for rec in recs:\n        record = dict()\n        keys = [\"Rank\", \"Team Name\", \"Score\"]\n        for key in keys:\n            record[key] = rec.find('td', {\"data-th\" : key}).text\n            \n        change_span = rec.find('td', {\"data-th\" : \"Change\"}).find('span')\n        if change_span.find('span', class_=\"position-change__none\"):\n            change = (0, 0)\n        elif change_span.find('span', class_=\"position-change__risen\"):\n            change = (1, int(change_span.find('span', class_=\"position-change__risen\").text))\n        else:\n            change = (-1, int(change_span.find('span', class_=\"position-change__fallen\").text))\n            \n        record[\"ChangeDirection\"], record[\"ChangeNo\"] = change\n        rows.append(record)\n        \n    df = pd.DataFrame(rows)\n    df[\"Team Name\"] = _strip_all_spaces( df[\"Team Name\"] )\n    df.columns = ['PrivRank', 'TeamName', 'PrivScore', 'ChangeDirection', 'ChangeNo']\n    return df\n\ndef _load_csv_dataframe(pathname=CSV_PUB):\n    \"\"\"\n    Read the CSV version of the public leaderboard as downloaded from Kaggle.\n    (This will be merged with the scraped version).\n    \n    Return a pandas DataFrame\n    \"\"\"\n    df = pd.read_csv(pathname)\n    df.TeamName = df.TeamName.replace(r\"\\s+\", \" \", regex=True).str.strip()\n    \n    return df\n\ndef _load_dataframe(pathname):\n    # entry function to loading the two versions of the public leaderboard\n    if pathname == PUB:\n        df = _load_pub_dataframe()\n    elif pathname == CSV_PUB:\n        df = _load_csv_dataframe()\n    return df\n\ndef _load_and_merge_public_lb():\n    \"\"\"\n    Load and clean the two versions (HTML and CSV) of the public leaderboard.\n    Then merge the two on TeamName.\n    \n    Return a merged pandas DataFrame.\n    \"\"\"\n    df = _load_dataframe(PUB)\n    df_pub = _load_dataframe(CSV_PUB)\n    \n    df = df[df[\"TeamName\"].isin(df_pub[\"TeamName\"])]\n    df_pub = df_pub[df_pub[\"TeamName\"].isin(df[\"TeamName\"])]\n    \n    final = df.merge(df_pub, on=\"TeamName\", how=\"left\")\n    final.columns = ['PubRank', 'TeamName', 'KernelTitle', 'KernelHref', \n                     'Entries', 'TeamId', 'SubmissionDate', 'PubScore']\n    return final\n\ndef load_data():\n    \"\"\"\n    Load all data (two versions of public and scraped version of private leaderboard).\n    Merge into one DataFrame and set dtypes correctly.\n    \n    Return a pandas DataFrame\n    \"\"\"\n    pub_df = _load_and_merge_public_lb()\n    priv_df = _load_priv_dataframe()\n    df = pub_df.merge(priv_df, on=\"TeamName\", how=\"left\")\n    \n    # set dtypes\n    type_dict = {\n    'PubRank': 'int32',\n    'Entries': 'int32',\n    'SubmissionDate': 'datetime64',\n    'PubScore': 'float64',\n    'PrivRank': 'int32',\n    'PrivScore': 'float64',\n    'ChangeDirection': 'category',\n    'ChangeNo': 'int32',\n    }\n    for key, value in type_dict.items():\n        df[key] = df[key].astype(value)\n    \n    # reorder columns\n    new_order = ['TeamId', 'TeamName', 'PubRank', 'PubScore', 'PrivRank', \n                 'PrivScore', 'ChangeDirection', 'ChangeNo', 'SubmissionDate', \n                 'Entries', 'KernelTitle', 'KernelHref'\n                ]\n    df = df[new_order]\n    return df","1ba6ca39":"DF = load_data()\nDF.sample(5)","b21e1a6f":"RANK = 500  # This refers to the highest PRIVATE rank included in the graphics below\n\n# Build plots on a subset of the DataFrame, defined by the value of RANK\nSOURCE = DF[DF['PrivRank'] <= RANK].copy()","55c54a88":"x_data = SOURCE[\"Entries\"]\ny_data = SOURCE[\"PrivRank\"]\ncolor_data = SOURCE[\"ChangeDirection\"]\nsize_data = SOURCE[\"Entries\"]\n\n\nfig = px.scatter(SOURCE, x=x_data, y=y_data, color=color_data, \n                 size=size_data, opacity=0.75, hover_data=['TeamName'])\nfig.show()","95eb7f80":"x_data = SOURCE[\"SubmissionDate\"]\ny_data = SOURCE[\"Entries\"]\ncolor_data = SOURCE[\"PrivRank\"]\nsize_data = SOURCE[\"Entries\"]\n\n\nfig = px.scatter(SOURCE, x=x_data, y=y_data, color=color_data, size=size_data, opacity=0.75, hover_data=['TeamName'])\nfig.show()","52bec7e3":"x_data = SOURCE[\"PrivRank\"]\ny_data = SOURCE[\"PrivScore\"]\ncolor_data = SOURCE[\"ChangeDirection\"]\nsize_data = SOURCE[\"Entries\"]\n\n\nfig = px.scatter(SOURCE, x=x_data, y=y_data, color=color_data, size=size_data, opacity=0.75, hover_data=['TeamName'])\nfig.show()","7ee8a44b":"x_data = SOURCE[\"PubRank\"]\ny_data = SOURCE[\"PubScore\"]\ncolor_data = SOURCE[\"ChangeDirection\"]\nsize_data = SOURCE[\"Entries\"]\n\n\nfig = px.scatter(SOURCE, x=x_data, y=y_data, color=color_data, size=size_data, opacity=0.75, hover_data=['TeamName'])\nfig.show()","0b3c7ab7":"kernels = DF[DF.KernelHref.str.len() > 0].sort_values(by=\"PrivRank\")\nkernels = kernels[['PrivRank', 'PrivScore', 'KernelTitle', 'KernelHref']]\n\nmarkdown = \"\"\"\n| Private Rank | Private Score | Notebook |\n|--------------|--------------:|---------:|\n\"\"\"\nfor row in kernels.iterrows():\n    rec = row[1]\n    priv_rank = rec['PrivRank']\n    priv_score = rec['PrivScore']\n    title = \" \".join(rec['KernelTitle'].split())\n    title = title.replace(\"|\", \"\/\")\n    url = rec['KernelHref']\n    anchor = f\"[{ title }](https:\/\/kaggle.com{ url })\"\n    line = f\"| {priv_rank} | {priv_score}  | {anchor} |\\n\"\n    markdown += line\n    \ndisplay(Markdown(markdown))","cd2ccc83":"# List of Ranked Notebooks","cffa1745":"# Scatterplot: Number of Entries by Submission Date","71e35f99":"# Script: Scrape both Leaderboards into a single DataFrame\n\nThe scraping script is lengthy and hidden in the cell below. Feel free to use it if interested in this dataset. I decided to give the raw data and the script rather than the final dataframe since this seemed to me more in the spirit of the challenge and respects Kaggle's ownership. (Someone please tell me in the comments if this is not the done thing).","c5025c22":"# Scatterplot: Private Rank by Number of Entries","5e8bc7a3":"# Scatterplot: Public Rank by Public Score","81989e90":"# Limit the number of teams to include in the plots\n\nChange the value of `RANK` to taste.","c8f2373a":"# From Dabbler to Kaggler\n\n## Reflections on the first \"30 Days of Machine Learning Challenge\"\n\nThe [first \"30 Days of Machine Learning Challenge\"](https:\/\/www.kaggle.com\/c\/30-days-of-ml) was a tremendous learning experience. I learned a lot from all the participants but especially from [Alexis Cook](https:\/\/www.kaggle.com\/alexisbcook), [Abhishek Thakur](https:\/\/www.kaggle.com\/abhishek) (I highly commend his [videos](https:\/\/www.youtube.com\/watch?v=_55G24aghPY&list=PL98nY_tJQXZnP-k3qCDd1hljVSciDV9_N), [notebooks](https:\/\/www.kaggle.com\/abhishek\/competition-part-1-baseline), and [his book](https:\/\/www.amazon.com\/Approaching-Almost-Machine-Learning-Problem-ebook\/dp\/B089P13QHT) which is essential reading for all Kagglers), and [Luca Massaron](https:\/\/www.kaggle.com\/lucamassaron) (himself [a prolific writer on data science](https:\/\/www.amazon.com\/Luca-Massaron\/e\/B00RW7GV02%3Fref=dbs_a_mng_rwt_scns_share)).\n\n## Top 2%: Ranking #139\n\nI managed to earn a satisfactory private ranking of #139 on the private LB. My final notebook is [Experiment 11B: Blending to Stacking](https:\/\/www.kaggle.com\/gauden\/experiment-11b-blending-to-stacking). There is no major insight in the notebook -- I just accumulated experience from the community and built my own version of the common ensemble. Thanks to all!\n\n## Souvenir: Leaderboard Dataset\n\nAs a souvenir of the event, I downloaded the leaderboards in [both HTML and CSV](https:\/\/www.kaggle.com\/gauden\/30dmlleaderboards) formats. In [this notebook](https:\/\/www.kaggle.com\/gauden\/top-2-30dml-dabbler-to-kaggler), I provide a script to scrape the data into a dataset and add some Plotly graphics, in the hope that the participants in the challenge will enjoy hovering over the plots and seeking their own Team.\n\nThe Dataset is open for exploration either by interacting with the plots below or by using the dataset and script below to use the data in their own graphics.\n\n---\n\n## Would you consider upvoting?\n\n#### Do you have ideas for more plots? Do comment below...\n\n##### And now, on to the [next challenge](https:\/\/www.kaggle.com\/c\/tabular-playground-series-sep-2021)!\n\n\n## `:-)`\n\n","03c0d1a5":"# Scatterplot: Private Rank by Private Score"}}