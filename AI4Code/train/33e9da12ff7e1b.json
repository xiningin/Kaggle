{"cell_type":{"9b125f68":"code","6682efd2":"code","8195dbad":"code","f20d3094":"code","61f43932":"code","a78b45c0":"code","a0712ae0":"code","c6af5ea9":"code","f234c27e":"code","b703bd1d":"code","6b832a01":"code","06dea71d":"code","a0a0ce9f":"code","b1c69185":"code","844c563e":"code","6b0ce93c":"code","5da3a617":"code","1798b70b":"code","8f21edfa":"code","2d308b2d":"code","e0585a38":"code","7947cf94":"code","09b15536":"code","4a28c81f":"code","b4ef5f3b":"code","29410089":"code","8a07e0d5":"code","984c1a5b":"code","c1a032a4":"code","090b3f29":"code","a0d31739":"code","95f31bf8":"code","9ae71c78":"code","79ccefe5":"code","8e46a7a9":"code","c0bd710f":"code","833edeed":"code","8e0cd6b9":"code","20d92e5e":"code","5cfa36e5":"code","cb642bd5":"code","88a0a4c3":"code","34e29115":"code","cd075a1c":"code","138c1ae3":"markdown","ff2adc16":"markdown","9ae21fb8":"markdown","039fb27d":"markdown","e9f058e7":"markdown","b4f4f1d7":"markdown","86c3aab8":"markdown","e3bd62b2":"markdown","b0546d53":"markdown","e4c716ff":"markdown","dae5809f":"markdown","edd70f94":"markdown","c8838e67":"markdown","48105d75":"markdown","6b4a473a":"markdown","f3a4f9d5":"markdown"},"source":{"9b125f68":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6682efd2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom datetime import datetime\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","8195dbad":"train = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv')","f20d3094":"train.head(3)","61f43932":"train.info()","a78b45c0":"train.describe().T","a0712ae0":"# countplot in categorical variable\nfig, axes = plt.subplots(nrows=2, ncols=2)\nfig.set_size_inches(16,8)\n\nsns.countplot(train['season'], ax=axes[0][0])\nsns.countplot(train['holiday'], ax=axes[0][1])\nsns.countplot(train['workingday'], ax=axes[1][0])\nsns.countplot(train['weather'], ax=axes[1][1])","c6af5ea9":"# pointplot in categorical variable\nfig, axes = plt.subplots(nrows=2, ncols=2)\nfig.set_size_inches(16,8)\n\nsns.pointplot(data=train, x='season', y='count', ax=axes[0][0])\nsns.pointplot(data=train, x='holiday',y='count', ax=axes[0][1])\nsns.pointplot(data=train, x='workingday',y='count', ax=axes[1][0])\nsns.pointplot(data=train, x='weather',y='count', ax=axes[1][1])","f234c27e":"# count in the worst weather \ntrain[train['weather']==4]","b703bd1d":"# boxplot in continuous variable\nfig, axes = plt.subplots(nrows=2, ncols=3)\nfig.set_size_inches(18,8)\n\nsns.boxplot(train['temp'], ax=axes[0][0])\nsns.boxplot(train['atemp'], ax=axes[0][1])\nsns.boxplot(train['humidity'], ax=axes[0][2])\nsns.boxplot(train['windspeed'], ax=axes[1][0])\nsns.boxplot(train['count'], ax=axes[1][1])","6b832a01":"# distplot in continuous variable\nfig, axes = plt.subplots(nrows=2,ncols=3)\nfig.set_size_inches(18,8)\n\nsns.distplot(train['temp'],ax=axes[0][0])\nsns.distplot(train['atemp'],ax=axes[0][1])\nsns.distplot(train['humidity'],ax=axes[0][2])\nsns.distplot(train['windspeed'],ax=axes[1][0])\nsns.distplot(train['count'],ax=axes[1][1])","06dea71d":"corr = train.corr()\nmask = np.array(corr)\nmask[np.tril_indices_from(mask)] = False\nfig=plt.gcf()\nfig.set_size_inches(10,10)\nsns.heatmap(data=corr,\n            mask=mask,\n            cmap='Oranges',\n            square=True,\n            annot=True,\n            cbar=True)","a0a0ce9f":"# delect the outliers\nprint('before delect train outlier: ', train.shape)\ntrain = train[np.abs(train['count']-train['count'].mean()) <= 3*train['count'].std()]\nprint('before delect train outlier: ', train.shape)","b1c69185":"weekday={'Sunday':0,\n        'Monday':1,\n        'Tuesday':2,\n        'Wednesday':3,\n        'Thursday':4,\n        'Friday':5,\n        'Saturday':6}","844c563e":"# train dataset\ntrain['datetime'] = pd.to_datetime(train['datetime'], format='%Y-%m-%d %H:%M:%S')\ntrain['year']=train['datetime'].dt.year\ntrain['year']=train['year'].map({2011:0, 2012:1})\ntrain['month']=train['datetime'].dt.month\ntrain['weekday']=pd.DatetimeIndex(train['datetime']).day_name()\ntrain['weekday']=train['weekday'].map(weekday)\ntrain['hour']=train['datetime'].dt.hour","6b0ce93c":"# test dataset\ntest['datetime'] = pd.to_datetime(test['datetime'], format='%Y-%m-%d %H:%M:%S')\ntest['year']=test['datetime'].dt.year\ntest['year']=test['year'].map({2011:0, 2012:1})\ntest['month']=test['datetime'].dt.month\ntest['weekday']=pd.DatetimeIndex(test['datetime']).day_name()\ntest['weekday']=test['weekday'].map(weekday)\ntest['hour']=test['datetime'].dt.hour","5da3a617":"train.head(3)","1798b70b":"fig=plt.gcf()\nfig.set_size_inches(12,6)\nsns.pointplot(x = 'hour', y = 'count', data = train, \n              estimator=np.average, hue = 'weekday', palette='coolwarm')","8f21edfa":"fig=plt.gcf()\nfig.set_size_inches(12,6)\nsns.pointplot(x = 'month', y = 'count', data = train, \n              estimator=np.average, hue = 'weekday', palette='coolwarm')","2d308b2d":"# Leave-One-Out Encoding\n\n# pip install category_encoders\n# import category_encoders as ce\n\n# def LOO_Encoding(feature):\n#   global train, test\n#   for i in feature:\n#     encoder = ce.LeaveOneOutEncoder(cols=[i], sigma=0.05)\n#     train[i] = encoder.fit_transform(train[i], train['count'])\n#     test[i] = encoder.transform(test[i])\n#   return print('Finishing LOO_Encoding in categorical variable:\\n', feature)\n\n# feature_LOO = ['season','holiday','workingday','weather',\n#                'year','month','weekday','hour']\n# LOO_Encoding(feature_LOO)","e0585a38":"# Astype to category\ncategory_feature = ['season','holiday','workingday','weather',\n                    'year','month','weekday','hour']\n\nfor i in category_feature:\n  train[i] = train[i].astype('category')\n  test[i] = test[i].astype('category')","7947cf94":"train.info()","09b15536":"# Combine train & test\ndata = train.append(test, ignore_index=True)","4a28c81f":"# plot windspeed\nsns.distplot(data['windspeed'])","b4ef5f3b":"windFeatures = ['season', 'weather', 'temp', 'atemp', 'humidity', 'year', 'month', 'weekday', 'hour']\n\nwindspeedIs0 = data[data['windspeed']==0]\nwindspeedIsNot0  = data[data['windspeed']!=0]\n\nX = windspeedIsNot0[windFeatures]\ny = windspeedIsNot0['windspeed']","29410089":"# use train_test data to evaluate model effectiveness\nfrom sklearn.model_selection import train_test_split\nx_train1, x_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n\nrfModel = RandomForestRegressor(n_estimators=1000, random_state=42)\nrfModel.fit(x_train1, y_train1)\ny_pred1 = rfModel.predict(x_test1)","8a07e0d5":"# evaluate randomforest model effectiveness\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nwind_RMSE = np.sqrt(mean_squared_error(y_test1, y_pred1))\nwind_RMSLE = np.sqrt(mean_squared_log_error(y_test1, y_pred1))\n\nprint('wind_RMSE: ', wind_RMSE)\nprint('wind_RMSLE: ', wind_RMSLE)","984c1a5b":"# fill up wind_zero_values in data\nrfModel = RandomForestRegressor(n_estimators=1000, random_state=42)\nrfModel.fit(X,y)\nwind0Values = rfModel.predict(windspeedIs0[windFeatures])\nwindspeedIs0.loc[:,'windspeed'] = wind0Values\n\ndata = pd.concat((windspeedIs0, windspeedIsNot0), axis=0)","c1a032a4":"# plot windspeed after filling up 0 value\nsns.distplot(data['windspeed'])","090b3f29":"dataTrain = data[pd.notnull(data['count'])].sort_values(by='datetime')\ndataTest = data[~pd.notnull(data['count'])].sort_values(by='datetime')\n\ndataTrain_Y = dataTrain['count']\ndatetimeCol = dataTest['datetime']","a0d31739":"# dataTrain_Y\nsns.distplot(dataTrain_Y)","95f31bf8":"# log Y\ndataTrain_Y_log = np.log(dataTrain_Y)","9ae71c78":"# dataTrain_Y_log\nsns.distplot(dataTrain_Y_log)","79ccefe5":"dropFeatures = ['datetime','casual','registered','count']\ndataTrain = dataTrain.drop(dropFeatures, axis=1)\ndataTest = dataTest.drop(dropFeatures, axis=1)","8e46a7a9":"dataTrain.head(3)","c0bd710f":"# evaluate model effectiveness function\ndef evaluate_model_RMSE(modelName, y_test, y_pred):\n  train_RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n  train_RMSLE = np.sqrt(mean_squared_log_error(y_test, y_pred))\n\n  print(modelName, ' train_RMSE : ', train_RMSE)\n  print(modelName, ' train_RMSLE : ', train_RMSLE)","833edeed":"x_train, x_test, y_train, y_test = train_test_split(dataTrain.values,\n                                                    dataTrain_Y_log.values,\n                                                    test_size=0.2, random_state=42, shuffle=True)","8e0cd6b9":"# Linear Regression\nLR = LinearRegression()\nLR.fit(x_train, y_train)\ny_pred = LR.predict(x_test)\n\nevaluate_model_RMSE('LinearRegression',y_test,y_pred)","20d92e5e":"# Polynomial regression\ndeg = 3\nregressor_poly = PolynomialFeatures(degree=deg)\nx_train_poly = regressor_poly.fit_transform(x_train)\nx_test_poly = regressor_poly.fit_transform(x_test)\n\nLR = LinearRegression()\nLR.fit(x_train_poly, y_train)\ny_pred_poly = LR.predict(x_test_poly)\ny_pred_poly = [max(0,x) for x in y_pred_poly]\n\nevaluate_model_RMSE('LinearRegression Poly',y_test,y_pred_poly)","5cfa36e5":"# RandomForestRegressor\nrfModel = RandomForestRegressor(n_estimators=1000, random_state=42)\nrfModel.fit(x_train, y_train)\ny_pred_rf = rfModel.predict(x_test)\n\nevaluate_model_RMSE('RandomForest', y_test, y_pred_rf)","cb642bd5":"rfModel = RandomForestRegressor(n_estimators=1000, random_state=42)\nrfModel.fit(dataTrain, dataTrain_Y_log)\ndataTest_Y_log = rfModel.predict(dataTest)","88a0a4c3":"dataTest_Y = [max(0,x) for x in np.exp(dataTest_Y_log)]","34e29115":"result = pd.DataFrame({\n    'datetime' : datetimeCol,\n    'count' : dataTest_Y\n})","cd075a1c":"result.to_csv('bike_prediction.csv',index=False)","138c1ae3":"**Insight\uff1a**\n\n*   count : There are lots of outlier in count.\n*   windspeed : According to the common sense that windspeed is continuous variable, but actually no. Maybe someone filled the missing values up with 0. I will use randomfores model to refill the missing values up with reasonable value.\n\n---\n","ff2adc16":"# Exploratory Data Analysis (EDA)","9ae21fb8":"**Delete unnecessary columns**","039fb27d":"**Plot in categorical variable**","e9f058e7":"**Insight:**\n*   season: There are high rental demand in summer and fall.\n*   holiday\/working: Rental count in workingday is much more than that in holiday.\n*   weather: Rental count is large in good weather.\n\n\n---","b4f4f1d7":"**Outliers Detection**","86c3aab8":"**Split train and test dataset**","e3bd62b2":"**Correlation matrix**","b0546d53":"**A short description of the features**\n\n* datetime - hourly date + timestamp\n* season - 1 = spring, 2 = summer, 3 = fall, 4 = winter\n* holiday - whether the day is considered a holiday\n* workingday - whether the day is neither a weekend nor holiday\n* weather -\n  \n  1: Clear, Few clouds, Partly cloudy, Partly cloudy\n  \n  2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n\n  3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n\n  4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\n* temp - temperature in Celsius\n* atemp - \"feels like\" temperature in Celsius\n* humidity - relative humidity\n* windspeed - wind speed\n* casual - number of non-registered user rentals initiated\n* registered - number of registered user rentals initiated\n* count - number of total rentals","e4c716ff":"# Feature Engineering ","dae5809f":"**Feature Transformation in datetime**","edd70f94":"**Feature Transformation in categorical variable**\n\nTry two methon:\n* Leave-One-Out Encoding\n* Astype to category\n\nThe method 'Leave-One-Out Encoding' isn't more effective than the method 'Astype to category', so use the second way in feature transformation.","c8838e67":"**Missing Value Imputation in windspeed**","48105d75":"# Build machine learning models\n* Linear regression\n* Polynomial regression\n* RandomForest regressor","6b4a473a":"**Plot continuous variable**","f3a4f9d5":"# Choose model : RandomForest Regressor"}}