{"cell_type":{"729bbe87":"code","74a129fa":"code","f687f09d":"code","f158b175":"code","2e6989c1":"code","c5bdd830":"code","5fda9949":"code","89f37d9a":"code","1277a250":"code","bfebec52":"code","667c0e08":"code","9baebb40":"code","50ba0f99":"code","db78b4fc":"code","c5095d56":"code","3a9c53c8":"code","f842ff2a":"code","d6999853":"code","66a252f4":"code","20d9f42a":"code","158e8a15":"code","e69e1b96":"code","dec6687a":"code","92cbea48":"code","dc57281d":"code","919061ed":"code","b1cacac5":"code","c9341e2b":"code","07cd231d":"code","f7b988e4":"code","1971e232":"code","fe74af92":"code","b4784d80":"code","f5c228b0":"code","1004dfb2":"code","787e6e34":"code","1d1670fa":"code","37dc81af":"code","134cee55":"code","9eda045c":"code","f325f967":"code","2a78d09d":"code","772d77b0":"code","afd8cc94":"code","8ae00971":"code","e1065412":"code","57251760":"code","be383ee7":"code","a10203af":"code","78acaf8a":"code","c12f7b8f":"code","de34ef67":"code","cc591e06":"code","6a8ed881":"code","63ad6d84":"code","81e75e1f":"code","bd49ac69":"code","111ec5ef":"code","d0b49a34":"code","128db9e7":"code","5282a689":"markdown","ab0b782a":"markdown","f68fcfa2":"markdown","537efb26":"markdown","d5b1d98b":"markdown","d6bebd37":"markdown","700807b5":"markdown","b078bf88":"markdown","9212bcde":"markdown","cd5362d5":"markdown","5c3bfc5b":"markdown","b08a0eaf":"markdown","65649e76":"markdown","b571d114":"markdown","74aec1d9":"markdown","af056f93":"markdown","1c8dbd5e":"markdown","20068420":"markdown","9cca5e81":"markdown","454b17b7":"markdown","46fb1e2a":"markdown","49471d18":"markdown","46e7221e":"markdown","70f11757":"markdown","b26066e9":"markdown","733f2115":"markdown","1985f9c9":"markdown","e456459a":"markdown","282ecd51":"markdown","fc7be6aa":"markdown","eef320e1":"markdown","6c65e308":"markdown","4cf784f0":"markdown","bc1a69fa":"markdown","e03438c3":"markdown","cc280e7a":"markdown","2101d159":"markdown","6ef189ca":"markdown","65837431":"markdown","35bf66fa":"markdown","0b37827d":"markdown","b18cbfb9":"markdown","89d3b3a3":"markdown","eca0780a":"markdown"},"source":{"729bbe87":"#Import the neccessary library for the task\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom warnings import simplefilter # ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","74a129fa":"#Read the dataset from the kaggle\ndataset = pd.read_csv('\/kaggle\/input\/spotifyclassification\/data.csv', index_col = 0)","f687f09d":"dataset.head()","f158b175":"dataset.tail()","2e6989c1":"print('Dataset: ', dataset.shape[0], 'Rows', dataset.shape[1], 'Features')","c5bdd830":"dataset['target'].value_counts()","5fda9949":"dataset.columns.values","89f37d9a":"SpeechinessMusic = dataset[['instrumentalness','speechiness']]\nEnergetic = dataset[['danceability','energy']]\nMusicAttribute = dataset[['tempo','mode','key','time_signature']]\nEnvironment = dataset[['acousticness','liveness','loudness']]\n\nprint(SpeechinessMusic.head(2))\nprint(Energetic.head(2))\nprint(MusicAttribute.head(2))\nprint(Environment.head(2))","1277a250":"dataset.describe()","bfebec52":"dataset.describe(include = 'O')","667c0e08":"#Check the null value for the string variable\nprint('song_title:' ,dataset['song_title'].isnull().sum())\nprint('artist:' ,dataset['artist'].isnull().sum())","9baebb40":"#Check how many of duplicate values in song_title & artist features\n\ndef DuplicatedFunction(data,column):\n    result = data[column].duplicated().sum()\n    return result\n\nprint('Duplicate Values:' ,DuplicatedFunction(dataset,'song_title'))\nprint('Duplicate Values:' ,DuplicatedFunction(dataset,'artist'))","50ba0f99":"print(dataset[['mode','target']].groupby(['mode']).mean().sort_values(by = 'target', ascending = False))","db78b4fc":"sns.factorplot('mode','target', data = dataset)\nplt.show()","c5095d56":"dataset[['key','target']].groupby('key').mean().sort_values(by = 'target', ascending = False)","3a9c53c8":"Explode = [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1,.1,.1]\n\nf, ax = plt.subplots(figsize = (7,10))\ndataset[['key','target']].groupby('key').mean().plot.pie(subplots = True, explode = Explode, autopct = '%.2f%%',ax = ax)\nplt.legend(loc = 'lower left') \nplt.show()","f842ff2a":"sns.factorplot('key','target', data = dataset)\nplt.show()","d6999853":"dataset[['time_signature','target']].groupby(['time_signature']).mean().sort_values(by = 'target', ascending = False)","66a252f4":"sns.factorplot('time_signature','target', data = dataset)\nplt.show()","20d9f42a":"f, ax = plt.subplots(2,2, figsize = (10,10))\ndataset[dataset['target'] == 0].instrumentalness.plot.hist(bins = 10, ax = ax[0,0])\nax[0,0].set_title('target = 0 | instrumentalness')\ndataset[dataset['target'] == 1].instrumentalness.plot.hist(bins = 10, ax = ax[0,1])\nax[0,1].set_title('target = 1 | instrumentalness')\ndataset[dataset['target'] == 0].speechiness.plot.hist(bins = 10, ax = ax[1,0])\nax[1,0].set_title('target = 0 | speechiness')\ndataset[dataset['target'] == 1].speechiness.plot.hist(bins = 10, ax = ax[1,1])\nax[1,1].set_title('target = 1 | speechiness')\nplt.show()","158e8a15":"f, ax = plt.subplots(2,2,figsize = (10,10))\ndataset[dataset['target'] == 0].danceability.plot.hist(bins = 10, ax = ax[0,0])\nax[0,0].set_title('target = 0 | danceability')\ndataset[dataset['target'] == 1].danceability.plot.hist(bins = 10, ax = ax[0,1])\nax[0,1].set_title('target = 1 | danceability')\ndataset[dataset['target'] == 0].energy.plot.hist(bins = 10, ax = ax[1,0])\nax[1,0].set_title('target = 0 | energy')\ndataset[dataset['target'] == 1].energy.plot.hist(bins = 10, ax = ax[1,1])\nax[1,1].set_title('target = 1 | energy')\n\nplt.show()","e69e1b96":"f,ax = plt.subplots(1,2,figsize = (10,5))\ndataset[dataset['target'] == 0].tempo.plot.hist(bins = 10, ax = ax[0])\nax[0].set_title('target = 0 | tempo')\ndataset[dataset['target'] == 1].tempo.plot.hist(bins = 10, ax = ax[1])\nax[1].set_title('target = 1 | tempo')\n\nplt.show()","dec6687a":"f,ax = plt.subplots(2,2,figsize = (10,10))\ndataset[dataset['target'] == 0].acousticness.plot.hist(bins = 10, ax = ax[0,0])\nax[0,0].set_title('target = 0 | acousticness')\ndataset[dataset['target'] == 1].acousticness.plot.hist(bins = 10, ax = ax[0,1])\nax[0,1].set_title('target = 1 | acousticness')\ndataset[dataset['target'] == 0].liveness.plot.hist(bins = 10, ax = ax[1,0])\nax[1,0].set_title('target = 0 | liveness')\ndataset[dataset['target'] == 1].liveness.plot.hist(bins = 10, ax = ax[1,1])\nax[1,1].set_title('target = 1 | liveness')\n\nplt.show()","92cbea48":"f,ax = plt.subplots(1,2,figsize = (10,5))\ndataset[dataset['target'] == 0].loudness.plot.hist(bins = 10, ax = ax[0])\nax[0].set_title('target = 0 | loudness')\ndataset[dataset['target'] == 1].loudness.plot.hist(bins = 10, ax = ax[1])\nax[1].set_title('target = 1 | loudness')\n\nplt.show()","dc57281d":"f,ax = plt.subplots(figsize = (10,10)) #the size of the heat map\nsns.heatmap(dataset.corr(), annot = True, fmt = '.2g', cmap = 'RdYlGn', ax= ax) #annot: values, fmt: decimal points of values\nsns.set(font_scale = 0.75) #the font size of the value in the heat map\nplt.xlabel('Features')\nplt.show()","919061ed":"print('The Dimension of the dataset before drop the features:', dataset.shape)\ndataset = dataset.drop(['song_title','artist','duration_ms'], axis = 1)\nprint('The Dimension of the dataset after drop the features:', dataset.shape)","b1cacac5":"#1. instrumentalness\ndataset['InstrumentalnessBand'] = pd.cut(dataset['instrumentalness'],4)\ndataset[['InstrumentalnessBand','target']].groupby('InstrumentalnessBand',as_index = False).mean().sort_values(by = 'InstrumentalnessBand', ascending = True)","c9341e2b":"dataset['instrumentalness2'] = 0\ndataset.loc[dataset['instrumentalness'] <= 0.244,'instrumentalness2'] = 0\ndataset.loc[(dataset['instrumentalness'] > 0.244) & (dataset['instrumentalness'] <= 0.488), 'instrumentalness2'] = 1\ndataset.loc[(dataset['instrumentalness'] > 0.488) & (dataset['instrumentalness'] <= 0.732), 'instrumentalness2'] = 2\ndataset.loc[dataset['instrumentalness'] > 0.732, 'instrumentalness2'] = 3","07cd231d":"#2. speechiness\ndataset['SpeechinessBand'] = pd.cut(dataset['speechiness'],4)\ndataset[['SpeechinessBand','target']].groupby('SpeechinessBand',as_index = False).mean().sort_values(by = 'SpeechinessBand', ascending = True)","f7b988e4":"dataset['speechiness2'] = 0\ndataset.loc[dataset['speechiness'] <= 0.221, 'speechiness2'] = 0\ndataset.loc[(dataset['speechiness'] > 0.221) & (dataset['speechiness'] <= 0.42), 'speechiness2'] = 1\ndataset.loc[(dataset['speechiness'] > 0.42) & (dataset['speechiness'] <= 0.618), 'speechiness2'] = 2\ndataset.loc[dataset['speechiness'] > 0.618, 'speechiness2'] = 3","1971e232":"#3. danceability\ndataset['DanceabilityBand'] = pd.cut(dataset['danceability'],4)\ndataset[['DanceabilityBand','target']].groupby('DanceabilityBand',as_index = False).mean().sort_values(by = 'DanceabilityBand', ascending = True)","fe74af92":"dataset['danceability2'] = 0\ndataset.loc[dataset['danceability'] <= 0.338, 'danceability2'] = 0\ndataset.loc[(dataset['danceability'] > 0.338) & (dataset['danceability'] <= 0.553), 'danceability2'] = 1\ndataset.loc[(dataset['danceability'] > 0.553) & (dataset['danceability'] <= 0.769), 'danceability2'] = 2\ndataset.loc[dataset['danceability'] > 0.769, 'danceability2'] = 3","b4784d80":"#4. energy\ndataset['EnergyBand'] = pd.cut(dataset['energy'],4)\ndataset[['EnergyBand','target']].groupby('EnergyBand',as_index = False).mean().sort_values(by = 'EnergyBand', ascending = True)","f5c228b0":"dataset['energy2'] = 0\ndataset.loc[dataset['energy'] <= 0.261, 'energy2'] = 0\ndataset.loc[(dataset['energy'] > 0.261) & (dataset['energy'] <= 0.506), 'energy2'] = 1\ndataset.loc[(dataset['energy'] > 0.506) & (dataset['energy'] <= 0.752), 'energy2'] = 2\ndataset.loc[dataset['energy'] > 0.752, 'energy2'] = 3","1004dfb2":"#5. acousticness\ndataset['AcousticnessBand'] = pd.cut(dataset['acousticness'],4)\ndataset[['AcousticnessBand','target']].groupby('AcousticnessBand',as_index = False).mean().sort_values(by = 'AcousticnessBand', ascending = True)","787e6e34":"dataset['acousticness2'] = 0\ndataset.loc[dataset['acousticness'] <= 0.249, 'acousticness2'] = 0\ndataset.loc[(dataset['acousticness'] > 0.249) & (dataset['acousticness'] <= 0.498), 'acousticness2'] = 1\ndataset.loc[(dataset['acousticness'] > 0.498) & (dataset['acousticness'] <= 0.746), 'acousticness2'] = 2\ndataset.loc[dataset['acousticness'] > 0.746, 'acousticness2'] = 3","1d1670fa":"#6. liveness\ndataset['LivenessBand'] = pd.cut(dataset['liveness'],4)\ndataset[['LivenessBand','target']].groupby('LivenessBand', as_index = False).mean().sort_values(by = 'LivenessBand', ascending = True)","37dc81af":"dataset['liveness2'] = 0\ndataset.loc[dataset['liveness'] <= 0.256,'liveness2'] = 0\ndataset.loc[(dataset['liveness'] > 0.256) & (dataset['liveness'] <= 0.494),'liveness2'] = 1\ndataset.loc[(dataset['liveness'] > 0.494) & (dataset['liveness'] <= 0.731),'liveness2'] = 2\ndataset.loc[dataset['liveness'] > 0.731, 'liveness2'] = 3","134cee55":"#7. loudness\ndataset['LoudnessBand'] = pd.cut(dataset['loudness'], 4)\ndataset[['LoudnessBand','target']].groupby('LoudnessBand').mean()","9eda045c":"dataset['loudness2'] = 0\ndataset.loc[dataset['loudness'] <= -24.9, 'loudness2'] = 0\ndataset.loc[(dataset['loudness'] > -24.9) & (dataset['loudness'] <= -16.702), 'loudness2'] = 1\ndataset.loc[(dataset['loudness'] > -16.702) & (dataset['loudness'] <= -8.504), 'loudness2'] = 2\ndataset.loc[dataset['loudness'] > -8.504, 'loudness2'] = 3","f325f967":"#8. tempo\n\ndataset['TempoBand'] = pd.cut(dataset['tempo'],4)\ndataset[['TempoBand','target']].groupby('TempoBand',as_index = False).mean().sort_values(by = 'TempoBand', ascending = True)","2a78d09d":"dataset['tempo2'] = 0\ndataset.loc[dataset['tempo'] <= 90.727, 'tempo2'] = 0\ndataset.loc[(dataset['tempo'] > 90.727) & (dataset['tempo'] <= 133.595), 'tempo2'] = 1\ndataset.loc[(dataset['tempo'] > 133.595) & (dataset['tempo'] <= 176.463), 'tempo2'] = 2\ndataset.loc[ dataset['tempo'] > 176.463, 'tempo2'] = 3","772d77b0":"#9. valence\ndataset['valenceband'] = pd.cut(dataset['valence'], 4)\ndataset[['valenceband','target']].groupby('valenceband').mean().sort_values(by = 'valenceband')","afd8cc94":"dataset['valence2'] = 0\ndataset.loc[dataset['valence'] <= 0.274, 'valence2'] = 0\ndataset.loc[(dataset['valence'] > 0.274) & (dataset['valence'] <= 0.513), 'valence2'] = 1\ndataset.loc[(dataset['valence']> 0.513) & (dataset['valence'] <= 0.753), 'valence2'] = 2\ndataset.loc[dataset['valence'] > 0.753, 'valence2'] = 3","8ae00971":"dataset.head()","e1065412":"#Drop the range features\ndataset = dataset.drop(['InstrumentalnessBand','SpeechinessBand','DanceabilityBand','EnergyBand',\n                        'AcousticnessBand','LivenessBand','LoudnessBand','TempoBand','valenceband'], axis = 1)\n\ndataset.columns","57251760":"#Drop all the numerical features without process through binning method\n\ndataset = dataset.drop(['acousticness','danceability','energy','instrumentalness',\n                        'liveness','loudness','speechiness','tempo','valence'],axis = 1)\n\ndataset.columns","be383ee7":"#Rename the binning features\ndataset = dataset.rename(columns = {'instrumentalness2':'instrumentalness','speechiness2': 'speechiness', 'danceability2': 'danceability',\n                                   'energy2': 'energy','acousticness2':'acousticness', 'liveness2':'liveness', 'loudness2':'loudness',\n                                   'tempo2': 'tempo', 'valence2': 'valence'})\ndataset.columns","a10203af":"#Change the time_signature features from numerical type features to Int type features\n\ndataset['time_signature'] = dataset['time_signature'].astype(int)\ndataset.head()","78acaf8a":"dataset.describe()","c12f7b8f":"#drop the features which doesn't have the good result in average mean\ndataset = dataset.drop(['instrumentalness','speechiness','acousticness','liveness'], axis = 1)\nprint('The dimension of the dataset after drop the features: ', dataset.shape)","de34ef67":"df_key = pd.get_dummies(dataset['key'])\ndf_time_signature = pd.get_dummies(dataset['time_signature'])\ndf_danceability = pd.get_dummies(dataset['danceability'])\ndf_energy = pd.get_dummies(dataset['energy'])\ndf_loudness = pd.get_dummies(dataset['loudness'])\ndf_tempo = pd.get_dummies(dataset['tempo'])\ndf_valence = pd.get_dummies(dataset['valence'])\n\ndummy_variables = pd.concat([df_key,df_time_signature,df_danceability,df_energy,df_loudness,df_tempo,df_valence], axis = 1)\ndataset = pd.concat([dataset,dummy_variables], axis = 1)\nprint('The dimension of the dataset after create the dummy variables: ', dataset.shape)","cc591e06":"#Replace the numerical features by dummy variables, but the target class labels\ndataset = dataset.drop(['key','time_signature','danceability','energy','loudness','tempo','valence'], axis = 1)\nprint('The dimension of the dataset after drop the numerical features: ', dataset.shape)","6a8ed881":"#Import the library we need to use for the following step\n\nfrom sklearn.linear_model import LogisticRegression #Logistic Regression\nfrom sklearn.naive_bayes import GaussianNB #Naive Bayes\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\n\n","63ad6d84":"#1. Create the X_train without the target class label & Y_train (target)\nX_train = dataset.drop('target', axis = 1)\nY_train = dataset['target']\n\n#2. Split the X_Train & Y_train into training set & testing set by train_test_split function\nx_train,x_test,y_train,y_test = train_test_split(X_train,Y_train,test_size = 0.2, random_state = 0)","81e75e1f":"print('the dimension of the x_train: ', x_train.shape)\nprint('the dimension of the x_test: ', x_test.shape)","bd49ac69":"#3. Fit the model into the training set\n\n#i. Logistic Regression\nlog = LogisticRegression()\nlog.fit(x_train,y_train)\nlog_y_pred = log.predict(x_test)\nlog_result_train = round(log.score(x_train,y_train)*100,2)\n\n#ii. Gaussian Naive Bayes\nNB = GaussianNB()\nNB.fit(x_train,y_train)\nNB_y_pred = NB.predict(x_test)\nNB_result_train = round(NB.score(x_train,y_train)*100,2)\n\n#iii. Decision Tree\nDT = DecisionTreeClassifier()\nDT.fit(x_train,y_train)\nDT_y_pred = DT.predict(x_test)\nDT_result_train = round(DT.score(x_train,y_train)*100, 2)\n\n#iv. K-Nearest Neighbors (K-NN)\nKNN = KNeighborsClassifier()\nKNN.fit(x_train,y_train)\nKNN_y_pred = KNN.predict(x_test)\nKNN_result_train = round(KNN.score(x_train,y_train)*100,2)\n\nprint('1. Logistic Regression: ', log_result_train)\nprint('2. Gaussian Naive Bayes: ', NB_result_train)\nprint('3. Decision Tree Classifier: ', DT_result_train)\nprint('4. K-NN: ', KNN_result_train)","111ec5ef":"#4. Fit the model into the testing dataset\n\n\n#i. Logistic Regression\nlog_result_test = round(log.score(x_test,y_test)*100,2)\n\n#ii. Gaussian Naive Bayes\nNB_result_test = round(NB.score(x_test,y_test)*100,2)\n\n#iii. Decision Tree\nDT_result_test = round(DT.score(x_test,y_test)*100,2)\n\n#iv. K-Nearest Neighbors\nKNN_result_test = round(KNN.score(x_test,y_test)*100,2)\n\nprint('1. Logistic Regression: {}'.format(log_result_test))\nprint('2. Gaussian Naive Bayes: {}'.format(NB_result_test))\nprint('3. Decision Tree: {}'.format(DT_result_test))\nprint('4. K-NN: {}'.format(KNN_result_test))","d0b49a34":"#5. Apply K-fold Cross Validation method into the model (testing data)\n\n#1. Logistic Regression\nKfold = KFold(n_splits = 10)\nlogregScore = cross_val_score(log,x_test,y_test, cv = Kfold)\navglogregScore = np.mean(logregScore)\n\n#2. Gaussien Naive Bayes\nNBScore = cross_val_score(NB,x_test,y_test, cv = Kfold)\navgNBScore = np.mean(NBScore)\n\n#3. Decision Tree Classifier\nDTScore = cross_val_score(DT, x_test,y_test, cv =Kfold)\navgDTScore = np.mean(DTScore)\n\n#4. K-NN\nKNNScore = cross_val_score(KNN, x_test,y_test, cv = Kfold)\navgKNNScore = np.mean(KNNScore)\n#for i in range(len(logregScore)): \n  #  print(i+1, 'Logistic Regression:',logregScore[i])\n    \nprint('1. Logistic Regression: ', round(avglogregScore*100,2))\nprint('2. Gaussian Naive Bayes:  ', round(avgNBScore*100,2))\nprint('3. Decision Tree Classifier: ', round(avgDTScore*100,2))\nprint('4. K-NN: ', round(avgKNNScore*100,2))\n","128db9e7":"#6. Create the confusion matrix table for the performance of model\n\nf, (ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize = (12,3))\n#1. Logistic Regression\nLogregCM = confusion_matrix(y_test,log_y_pred)\nsns.heatmap(LogregCM, annot = True, fmt = 'd', vmin = 0, vmax = 150,cmap = 'viridis', ax = ax1)\n#Annot: the value of the heatmap\n#fmt: the decimal point of value of heatmap\n#vmin, vmax: the limits of the colorbar\nax1.set_title('Logistic Regression')\nax1.set_xlabel('Features')\n\n#2. Gaussian Naive Bayes\nNBCM = confusion_matrix(y_test,NB_y_pred)\nsns.heatmap(NBCM, annot = True, fmt = 'd', vmin = 0, vmax = 150, cmap = 'YlGnBu', ax = ax2)\nax2.set_title('Gaussian Naive Bayes')\nax2.set_xlabel('Features')\n\n\n#3. Decision Tree\nDTCM = confusion_matrix(y_test, DT_y_pred)\nsns.heatmap(DTCM, annot = True, fmt = 'd', vmin = 0, vmax = 150, cmap = 'viridis', ax = ax3)\nax3.set_title('Decision Tree')\nax3.set_xlabel('Features')\n\n\n#4. KNN\nKNNCM = confusion_matrix(y_test, KNN_y_pred)\nsns.heatmap(KNNCM, annot = True, fmt = 'd', vmin = 0 , vmax = 150, cmap = 'YlGnBu', ax = ax4)\nax4.set_title('KNN')\nax4.set_xlabel('Features')\n\n\nplt.show()","5282a689":"# Analyse the features by visualization","ab0b782a":"We use the **describe** function to define the summary of the dataset.<br\/>","f68fcfa2":"#### 1. instrumentalness  2. speechiness","537efb26":"Wow there's a lot of different type of features in the dataset. But **how many features and rows** in this dataset?","d5b1d98b":"#### 8. loudness","d6bebd37":"At the last, we will create a heat map to find out the correalation between the features & class labels.","700807b5":"1. We can know that there are 61 song title is duplicated in the dataset.<br\/>\n2. Artist feature is different with song_title. Although the duplicated values is huge, but we can assumed that 1 artist may have different music in the dataset.<br\/><br\/>\n\n#### **We are not going to check the duplicated values from the numeric variable. Because every value of the music attribute might be same as other music as well.**","b078bf88":"Good to know that there is none of null values exist in the dataset.","9212bcde":"**Observation:**\n\nConfusion Matrix table is the table that we used to take a look the numbers of feature predicted correctly by model.<br\/>\nIn this time, we apply the confusion matrix table into the heat map graph. It's easier to read the result.<br\/>\nThere's 404 observations in the testing dataset. We can know that **Logistic Regression** is the best performance of predective model.<br\/>\nIt predict 241 observations corretcly from TP columns & FP columns.<br\/>\n\n","cd5362d5":"In this stage, we will apply the K-fold cross validation method to evaluate the performance of model. K-fold cross validation splits the dataset into **K** random number of subsets to let the model fit into. We set the K number : 38 as we have the 38 features in the both dataset.","5c3bfc5b":"# Model, predict & evaluation","b08a0eaf":"#### 6. acousticness 7. liveness","65649e76":"#### 3. Time Signature","b571d114":"Hi All, welcome to my first notebook in Kaggle. <br\/>\nThis model is about predict the music whether the user like or not within the playist. <br\/>\nI am very apperiacted that everyone could comment this notebook. This is the way to make the rookie improve. <br\/><br\/>\n### **I am Still Learning - MICHELANGELO**","74aec1d9":"#### 1. Mode","af056f93":"#### Assumption: \n\n1. According to the SpeechinessMusic group description, There is only 13% and 9 % for the average mean among the datasets. <br\/>\n   It seems like it dont so contribute so much for the modeling. Therefore, we will consider to drop this group of features.<br\/><br\/>\n2. Energetic group has the different result with the SpeechinessMusic. Both features have more than half average mean values. Which are 61 % for danceability & 68% for energy features. So that we decided these 2 features into the modeling. <br\/> <br\/>\n3. We can see that the average mean of tempo is 120, which means that most of the music are in allegro speed music. After that, key feature indicate that the overall key of the music. Most of the music are in concert F major, 5 based on the standard pitch notation.<br\/><br\/>\n4. Mode, this feature indicates that whether the music is in major key or minor key. Major Key means that the music based on major scale.<br\/>According to the description result, there are nearly 61% that the music is on major key.<br\/><br\/>\n5. Time_siganture, the features used to indicate how many beats in a measure. We can see that the average mean of the feature is 3.968.It's almost near to 4. <br\/>We are able to know half of the music are in 4\/4 time signature.<br\/><br\/>\n6. The environment factor is the important to adjust the user preference in the music.<br\/>Morever,acousticness and loudness both feature have the not so good performance. Only have 17% and 19% of the average mean value. But there's 25% music which have the 92% that is in live recording,<br\/> <br\/>\n7. According to the documentation user provide, loudness is the feature for the quality of the music. Range from -60db to 0. It seems like the distrubution looks equally.<br\/><br\/>\n","1c8dbd5e":"#### Assumption: \n1. There are only 1956 unique value for song title feature, which means there's possible null\/duplicate song title in the dataset.\n2. Same as song title feature, there are only 1343 unique artist, possible that there are repeated artist in the dataset.\n3. River has appeared 3 times as song title.\n4. From the description, we know that Drake is the most favor artist of the user.There is total 16 music in the dataset.","20068420":"We can see that there is 1020 music the user favor music from the dataset. After that, we might need to know the features name.","9cca5e81":"####  * **Drop the features**\n\nWe decided drop the song_tile,artist & duration_ms features from the dataset, As we thought that these features doesn't contribute so much for the modeling.<br\/>","454b17b7":"This dataset is provided by kaggle user GeorgeMcIntire.<br\/>\nI am impreseed that he is the pioneer that who changes his professional from journalism to data science. <br\/>\nHis story gives me the encouragement to improve through data science journey.<br\/> <br\/>\n\nAt first, he writes the code to access the Spotify API to obtain the music.<br\/>\nThere is a lot of music attributes from the API result. For example, tempo & time_signature.<br\/>\nSo that, he selected the music from his playlist in order to create the dataset.\n","46fb1e2a":"There are total 2017 rows and 16 features include the class label in this dataset. Which means that there are 2017 pieces of music in the playist.<br\/>\nLet's take a look that how many music that the user like.\n","49471d18":"There are few steps we need to do in this part. First of all, we will drop the features which is not contribute so much for the modeling. <br\/>\nSecondly, most of the features are in numerical type, and the predective model only accept the binary data type. <br\/>\nTherefore, we may use the binning method to create the new feature which is binary\/ordinal data type. After that, we will replace the numerical features to binary features.<br\/>","46e7221e":"# Predective Model on Spotify Classification","70f11757":"**Result:**\n\nAccording to the performance of model from training dataset, we know that the performance are looks great. Especially the Decision Tree and K-NN.<br\/>\nBut we suprised that the performance of model from testing dataset have the big contrast with training dataset.<br\/>","b26066e9":"At first, we start to analyse the MusicAttribute group. Which are **mode**, **key** and **time_signature**.<br\/>\nWe are not going to analyse the tempo at this moment. Due to tempo is the numeric feature, and other features are ordinal\/binary.","733f2115":"#### 5. tempo","1985f9c9":"**Duplicated values**","e456459a":"### **2. Categorical Features**","282ecd51":"# Feature Engineering","fc7be6aa":"As we can see that, we extract 404 observations (20%) from the dataset to create the testing set.","eef320e1":"#### Create the Dummy Variables from the features, except the target class labels.","6c65e308":"**Null Values**","4cf784f0":"# To be Continued...\n\ncommit v24: Model, predict & evaluation\n\n1. Import the Classification_report class from the sklearn.metrics to evaluate the performance of model.","bc1a69fa":"Let's take a look the first 5 rows and last 5 rows of the dataset.","e03438c3":"### **1. Numerical Features**","cc280e7a":"### Categorizing","2101d159":"### Data Summary: ","6ef189ca":"#### 3. danceability 4. energy","65837431":"**Result:**\n<br\/> We can see that the performance of model have slightly increased. Logistic Regression & KNN model have the bigger contrast performance with the previous result. It proves that K-fold cross validation method is useful to enhance the performance of model.","35bf66fa":"#### 2. Key","0b37827d":"We need to know whether the null values \/ duplicate values in the dataset.","b18cbfb9":"* Class Labels: target\n* Interval: acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness,valence \n* Time: duration_ms\n* Numerical: tempo\n* Ordinal: key, time_signature\n* Binary: mode\n* String: song_title & artist\n\n\nI realzied that there are many features have the similarity.<br\/>\nFor example, instrumentalness is the measure to define the music is instrumental music or not. And, speechiness used to measure the music is vocable. Both features are used to define the music type. Therefore, these 2 features have the similarity.Besides, danceability and energy both features are used to define the music is energetic or not.<br\/> <br\/>\n\nMeanwhile, we grouping these features into 4 groups. Which are \n1. SpeechinessMusic\n2. Energetic\n3. MusicAttribute\n4. Environment\n\n\n","89d3b3a3":"## Analyse the numeric features by visualization","eca0780a":"#### * **Create the new features by binning method**\n\nAt first, we start to create the **range features** based on the group we created before. <br\/><br\/>\n\n* SpeechinessMusic: instrumentalness & speechiness<br\/>\n* Energetic: danceability & energy<br\/>\n* MusicAttribute: tempo, mode, key, time_signature<br\/>\n* Environment: acousticness, liveness, loudness<br\/>\n* Valence\n\nIt used to define the range of the value of the features.<br\/>\nAfter that, we are binning the data to the new feature based on the range features.<br\/>\nP\/S. We are not going to conver the **mode**, **key**,**time_siganature** and **target** to ordinal features. Because there are already the binary\/ordinal features.<br\/>"}}