{"cell_type":{"cb7aea5d":"code","7bfc6a2a":"code","e5feb46e":"code","97863271":"code","708b2ba1":"code","75131af3":"code","742fac32":"code","25cec3df":"code","3162afbd":"code","79952ac8":"code","89ab035a":"code","89bb8c59":"code","df750bd9":"code","4d5611e2":"code","06066579":"code","012fcbc5":"code","fdd90df1":"code","d6f92e56":"code","629d684b":"code","24757044":"code","e0136de8":"code","816cf7a8":"code","564287e3":"code","db639b64":"code","367dcc4c":"code","24f7d32d":"markdown","d7546d32":"markdown","83cdab2c":"markdown","717fbce4":"markdown"},"source":{"cb7aea5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n# , cross_val_score\nfrom lightgbm import LGBMRegressor\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7bfc6a2a":"df = pd.read_csv(os.path.join(dirname, filename))","e5feb46e":"print(\"Initial dataframe len = \",len(df))\ndf.head()","97863271":"#calculating CPM\ndef weird_division(n, d):\n    return n \/ d if d else 0","708b2ba1":"df['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)","75131af3":"df.head()","742fac32":"df.hist(column=\"CPM\", grid=True)","25cec3df":"df.CPM[df.CPM >= 50000]","3162afbd":"df = df[df.CPM >= 0].reset_index(drop=True)\n# df.drop(['total_revenue'], axis = 1, inplace=True)\ndf = df.loc[df['CPM'] < df['CPM'].quantile(.95)].reset_index(drop=True)\nprint(\"Dataframe len after deleting negative CMP vals and 0.95 cut-off = \",len(df))","79952ac8":"df.hist(column=\"CPM\", grid=True)","89ab035a":"import datetime\ndef convert_date_to_feature(df):\n    df['date'] = pd.to_datetime(df['date'])\n    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n    df['day'] = pd.DatetimeIndex(df['date']).day\n    df['weekday'] = pd.DatetimeIndex(df['date']).weekday\n    return df","89bb8c59":"df = convert_date_to_feature(df)","df750bd9":"df.columns","4d5611e2":"for col in df.columns:\n    print(col)\n    print(\"   null vals: \",df[col].isnull().values.sum(),\"; unique vals:\", len(df[col].unique()),)\n    print()","06066579":"# integration_type, revenue_share_percent -- only 1 val","012fcbc5":"# selected features\ncat_cols = ['geo_id', 'monetization_channel_id','day','weekday','site_id','device_category_id','advertiser_id','ad_unit_id', 'os_id', 'line_item_type_id','order_id',]\nnum_cols = ['CPM','total_impressions', 'viewable_impressions',]\nfeatures = cat_cols + num_cols","fdd90df1":"for col in cat_cols:\n    df[col] = df[col].astype('category')","d6f92e56":"split_date ='2019-06-22 00:00:00'\ntrain_df = df.loc[df['date'] < split_date].reset_index(drop=True)\ntest_df = df.loc[df['date'] >= split_date].reset_index(drop=True)","629d684b":"print(\"Train df len = \",len(train_df))\ntrain_df.tail(1)","24757044":"print(\"Test df len = \",len(test_df))\ntest_df.head(1)","e0136de8":"train_df = train_df[features]\ntest_df = test_df[features]","816cf7a8":"def train_and_test(transformed_df, model, cat_cols, test_size=0.2):\n    target = transformed_df['CPM']\n    features = transformed_df.copy().drop('CPM', axis=1)\n\n    X_train, X_val, y_train, y_val = train_test_split(\n        features, target, test_size=test_size, shuffle = False, random_state=42)\n\n    model.fit(X_train, y_train, categorical_feature=cat_cols)  \n    y_pred = model.predict(X_val) \n    print('MSE val: %.3f' % (mean_squared_error(y_val, y_pred)))\n    plt.scatter(y_val, y_pred)\n    plt.title('Predicted vs. Actual CMP', fontsize=18, fontweight='bold')\n    plt.xlabel('Actual CMP')\n    plt.ylabel('Predicted CMP')\n    plt.show()\n\n    return model","564287e3":"params ={\n    \"n_estimators\": 600,\n    \"max_depth\": 6,\n    \"learning_rate\":0.1,\n    \"criterion\": \"mse\",\n}","db639b64":"model = LGBMRegressor(**params) \ntrained_model = train_and_test(train_df, model, cat_cols)","367dcc4c":"y_pred = trained_model.predict(test_df.drop('CPM', axis=1))\npred = abs(np.round(y_pred,0))\nactual = np.array(test_df['CPM'])\nmean_squared_error(actual, pred)","24f7d32d":"### MSE on test data","d7546d32":"### Train model","83cdab2c":"### Filter values","717fbce4":"### Select features"}}