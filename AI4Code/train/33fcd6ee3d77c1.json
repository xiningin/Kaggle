{"cell_type":{"9711a5e6":"code","92e8b393":"code","e268886a":"code","dbd23d9f":"code","31ce4514":"code","62ad7b35":"code","081f11a9":"code","35fd6a1d":"code","bd327c3d":"code","0b44c877":"code","b953b723":"code","2022025d":"code","ccbde7e7":"code","8ccd4922":"code","87aa3f31":"code","61452d18":"code","f00e556f":"code","e659e0f8":"code","f4384eca":"code","87f555f8":"code","051a92cd":"code","543f674d":"code","fdb560e9":"code","beada798":"code","7342d5b8":"code","f9ab4f96":"code","e4f7bf23":"code","1b0045fd":"code","7526c47e":"code","f86ac1a7":"code","3cc92a16":"code","979fe1e0":"code","fc3f57fd":"code","88d5c6a2":"code","b78e0fb2":"code","6dcee5cf":"code","045fccd1":"code","a0ef4a6d":"code","d0629a29":"code","aac376d2":"code","89be55bd":"code","1adffb6d":"code","b7a710bb":"code","00ffe246":"code","14a3dcbf":"code","7a761ae0":"code","2bbdbf5a":"code","5aef1968":"code","efd6ecd4":"code","ae97ac74":"code","c85c53fc":"code","0cd58624":"code","51e7a210":"code","3cdbc111":"code","180d6c59":"code","c601e9f7":"code","107a4065":"code","d24d7626":"code","bd78870b":"code","4886ff48":"code","9ad423bf":"code","788d8d16":"markdown","f369ee0e":"markdown","7a7da170":"markdown","ff9cf124":"markdown","cd12a87f":"markdown","8304a15b":"markdown","159a71a2":"markdown","7b846edb":"markdown","0d31b340":"markdown","150f5e4b":"markdown","ebe773df":"markdown","c2c9f7b7":"markdown","5ac4fc96":"markdown","a0d5ca6e":"markdown","83579e86":"markdown","041d1fd9":"markdown","95741f07":"markdown","20a79d82":"markdown","73f43384":"markdown","8d1bc205":"markdown","4a8808d9":"markdown","7c74687f":"markdown","37821554":"markdown","52435f66":"markdown","32f60416":"markdown"},"source":{"9711a5e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nplt.style.use('seaborn-pastel')\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92e8b393":"data = pd.read_csv('\/kaggle\/input\/loandata\/Loan payments data.csv')","e268886a":"print(data.shape)\ndata.head()","dbd23d9f":"data['loan_status'].unique()","31ce4514":"import missingno as msno\nmsno.bar(data)","62ad7b35":"data[['paid_off_time','past_due_days']].isnull().sum()","081f11a9":"data[(data['paid_off_time'].isnull()) & (data['loan_status'] != 'COLLECTION')]","35fd6a1d":"data[data['past_due_days'].isnull() & (data['loan_status'] != 'PAIDOFF')]","bd327c3d":"fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,5))\nsns.countplot(data['Gender'],ax=ax1)\nsns.countplot(data['Gender'],hue=data['loan_status'],ax=ax2)\n\nfor p in ax1.patches:   \n    height = p.get_height()\n    ax1.text(p.get_x()+p.get_width()\/2., height + 0.1,height ,ha=\"center\",fontsize=10)\nfor p in ax2.patches:   \n    height = p.get_height()\n    ax2.text(p.get_x()+p.get_width()\/2., height + 0.1,height ,ha=\"center\",fontsize=10) ","0b44c877":"fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\nsns.countplot(data['education'],ax=ax1)\nsns.countplot(data['education'],hue= data['loan_status'],ax=ax2)\nax1.tick_params(labelrotation=30)\nax2.tick_params(labelrotation=30)\nplt.legend(loc='best')\nfor p in ax1.patches:   \n    height = p.get_height()\n    ax1.text(p.get_x()+p.get_width()\/2., height + 0.1,height ,ha=\"center\",fontsize=10)\nfor p in ax2.patches:   \n    height = p.get_height()\n    ax2.text(p.get_x()+p.get_width()\/2., height + 0.1,height ,ha=\"center\",fontsize=10) ","b953b723":"data[['loan_status', 'education', 'Loan_ID']].groupby(['loan_status', 'education']).agg(['count'])","2022025d":"plt.figure(figsize=(12,8))\nsns.catplot(data=data,x='loan_status',y='Principal',col='Gender',hue='education',kind='bar',ci=False)","ccbde7e7":"data['age'].describe()","8ccd4922":"data['age_range'] = pd.cut(data['age'],[10,20,30,40,50,60],labels=['10s','20s','30s','40s','50s'])","87aa3f31":"plt.figure(figsize=(12,8))\nax=sns.countplot(data['age_range'],hue=data['loan_status'])\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 0.1,height ,ha=\"center\",fontsize=10)","61452d18":"data[['loan_status', 'age_range', 'Loan_ID']].groupby(['loan_status', 'age_range']).agg(['count'])","f00e556f":"sns.boxplot(x=data['loan_status'],y=data['Principal'])","e659e0f8":"data[['loan_status', 'Principal', 'Loan_ID']].groupby(['loan_status', 'Principal']).agg(['count'])","f4384eca":"import datetime\ndata['effective_date']=data['effective_date'].apply(lambda x:datetime.datetime.strptime(x,'%m\/%d\/%Y'))\ndata['due_date']=data['due_date'].apply(lambda x:datetime.datetime.strptime(x,'%m\/%d\/%Y'))","87f555f8":"data['paid_off_time'] = data['paid_off_time'].apply(lambda x: datetime.datetime.strptime(x,'%m\/%d\/%Y %H:%M') if type(x) == str else x)","051a92cd":"data.head()","543f674d":"# proof\nfrom datetime import timedelta\nprint(data['due_date'][300] + timedelta(days = data['past_due_days'][300]))\nprint(data['due_date'][301] + timedelta(days = data['past_due_days'][301]))","fdb560e9":"na_idx = data[data['paid_off_time'].isnull()].index\nfor i in na_idx:\n    data['paid_off_time'].iloc[i] = data['due_date'][i] + timedelta(days = data['past_due_days'][i])","beada798":"data.head()","7342d5b8":"data['paid_off_time'] = data['paid_off_time'].apply(lambda x: '{}-{}-{}'.format(x.year,x.month,x.day))","f9ab4f96":"data['paid_off_time'] = data['paid_off_time'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d'))","e4f7bf23":"idx = data[data['past_due_days'].isnull()].index\ndata['past_due_days'][idx] = data['paid_off_time'][idx] - data['due_date'][idx]","1b0045fd":"msno.bar(data)","7526c47e":"try:\n    for i in range(len(data['past_due_days'])):\n        data['past_due_days'][i] = data['past_due_days'][i].days\nexcept:\n    pass","f86ac1a7":"data['loan_status'].unique()","3cc92a16":"data[data['loan_status'] == 'COLLECTION']","979fe1e0":"data['tmp']=data['due_date'] - data['effective_date'] + timedelta(days=1)\ndata['tmp'] = data['tmp'].dt.days","fc3f57fd":"extension_idx = []\nfor i in range(data.shape[0]):\n    if data['terms'][i] < data['tmp'][i]:\n        extension_idx.append(i)\n    else:\n        continue\ndata.iloc[extension_idx]","88d5c6a2":"extension_idx = []\nfor i in range(data.shape[0]):\n    if data['terms'][i] < data['tmp'][i]:\n        data['tmp'][i] = 'Y'\n    else:\n        data['tmp'][i] = 'N'","b78e0fb2":"data.rename(columns={'tmp':'extension'},inplace=True)","6dcee5cf":"data.head()","045fccd1":"data['loan_status'].unique()","a0ef4a6d":"loan_dic = {'PAIDOFF':0,'COLLECTION_PAIDOFF':1,'COLLECTION':2}\ndata['loan_status'] = data['loan_status'].map(loan_dic)","d0629a29":"data.drop(['effective_date','due_date','paid_off_time','age'],axis=1,inplace=True)","aac376d2":"data.info()","89be55bd":"data['past_due_days'] = data['past_due_days'].astype(float)","1adffb6d":"category_features = ['education','Gender','age_range','extension']\nfor i in category_features:\n    data[i] = data[i].astype('category')","b7a710bb":"id_ = data['Loan_ID']\ndata = pd.get_dummies(data.drop(['Loan_ID'],axis=1))","00ffe246":"data","14a3dcbf":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(data,test_size=.2)\nprint(\"train shape:{}\\ntest shape:{}\".format(train.shape,test.shape))","7a761ae0":"train = train.reset_index(drop=True)\ntrain_x = train.drop('loan_status',axis=1)\ntrain_y = train['loan_status']\ntest = test.reset_index(drop=True)\ntest_x = test.drop('loan_status',axis=1)\ntest_y = test['loan_status']","2bbdbf5a":"from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom xgboost import XGBClassifier","5aef1968":"rf=RandomForestClassifier()\nada=AdaBoostClassifier()\ngra = GradientBoostingClassifier()\nxgb = XGBClassifier()","efd6ecd4":"rf.fit(train_x,train_y)\npred = rf.predict(test_x)","ae97ac74":"from sklearn.metrics import accuracy_score\naccuracy_score(test_y.values,pred)","c85c53fc":"score_df=pd.DataFrame(columns=['model','score'])\nidx=0\nfor i in [rf,ada,gra,xgb]:\n    i.fit(train_x,train_y)\n    pred = i.predict(test_x)\n    score_df.loc[idx,'model'] = i.__class__.__name__\n    score_df.loc[idx,'score'] = accuracy_score(test_y.values,pred)\n    idx+=1\nscore_df","0cd58624":"plt.figure(figsize=(12,8))\nax= sns.barplot(data=score_df,x='model',y='score')\nplt.ylim(0,1.1)\nfor p in ax.patches:   \n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height,height ,ha=\"center\",fontsize=13)\nplt.title('score by model')","51e7a210":"fig,axes = plt.subplots(4,1,figsize=(10,8))\nnum=0\nfor i in [rf,ada,gra,xgb]:\n    \n    feat_importances = pd.Series(i.feature_importances_, index=train_x.columns)\n    feat_importances.nlargest(5).plot(kind='barh',ax=axes[num])\n\n    \n    axes[num].set(title='{} featrue importances'.format(i.__class__.__name__))\n    plt.tight_layout()\n    num+=1\n","3cdbc111":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.init as init","180d6c59":"from sklearn.preprocessing import MinMaxScaler\nminmax = MinMaxScaler()\ntrain_x_scale = minmax.fit_transform(train_x)\ntest_x_scale = minmax.fit_transform(test_x)","c601e9f7":"trainx_tensor = torch.tensor(train_x_scale,dtype=torch.float)\ntrainy_tensor = torch.tensor(train_y.values,dtype = torch.float)\n\ntestx_tensor = torch.tensor(test_x_scale,dtype = torch.float)\ntesty_tensor = torch.tensor(test_y.values,dtype = torch.float)\n\ntrainx_tensor = trainx_tensor.type(torch.FloatTensor)\ntrainy_tensor = trainy_tensor.type(torch.LongTensor)\n\ntestx_tensor = testx_tensor.type(torch.FloatTensor)\ntesty_tensor = testy_tensor.type(torch.LongTensor)","107a4065":"num_epoch = 10000\nlearning_rate = 0.0002\nloss_func = nn.CrossEntropyLoss()\nw = data.shape[1]-1  # number of input's values","d24d7626":"def model_RRRLR():\n    model = nn.Sequential(\n          nn.Linear(1*w,6*w), nn.ReLU(),\n          nn.Linear(6*w,10*w), nn.ReLU(),\n          nn.Linear(10*w,6*w), nn.ReLU(),\n          nn.Linear(6*w,1*w), nn.LeakyReLU(),\n          nn.Linear(w,3) )\n    return model","bd78870b":"\nloss_array = []\nmodel = model_RRRLR()\noptimizer = optim.Adam(model.parameters(),learning_rate)\n\nfor i in range(num_epoch):\n    optimizer.zero_grad()\n    output = model(trainx_tensor)\n    loss = loss_func(output,trainy_tensor)\n    if i%5000==0:\n        print(loss)\n    loss.backward()\n    optimizer.step()\n    loss_array.append(loss)\nplt.plot(loss_array)\nplt.title('RRRLR loss array')","4886ff48":"output = model(testx_tensor)\nresult = []\nfor i in output:\n    if i.argmax() == 2:\n        result.append(2)\n    elif i.argmax() == 1:\n        result.append(1)\n    else:\n        result.append(0)\n","9ad423bf":"accuracy_score(test_y.values,result)","788d8d16":"- The characteristic of delinquent borrowers is that they borrow a lot of money.\n- Among them, the man with the highest level of education, Master or Above, borrowed the most money and delayed the payment. However, we must be careful not to make the fallacy of hasty generalization as it is a minority.\n","f369ee0e":"'past_due_days' most affected the accuracy of the model.","7a7da170":"####  replace missing values","ff9cf124":"- nerual network by pytorch","cd12a87f":"- Most of the defaulters borrowed high loans.","8304a15b":"Missing values of paid_off_time are replaced by 2016-12-08.","159a71a2":"- Ensemble and xgboost","7b846edb":"The category type is converted to OneHotEncoding.","0d31b340":"# improvement point","150f5e4b":"Delete variables of type datetime.\n\nThis is because the datetime format is not only applicable to the model, but has already obtained a new derived variable that can be obtained from this variable.\n\nAnd the age variable is deleted because there is an age_range variable.","ebe773df":"# limitation","c2c9f7b7":"We have dealt with all the missing values.","5ac4fc96":"Use cross-validation to test your predictive power.","a0d5ca6e":"- 'Paidoff' = \uae30\ud55c \ub0b4 \ub300\ucd9c\uae08 \ubaa8\ub450 \uc0c1\ud658\n- 'collection' = \uc5f0\uccb4\n- 'collection paidoff' = \uae30\ud55c \uc9c0\ub098\uc11c \ubaa8\ub450 \uc0c1\ud658","83579e86":"Overall, it can be seen that the man had a lot of loans.","041d1fd9":"# data description\n\n![image.png](attachment:image.png)","95741f07":"Variable conversion is easy to model","20a79d82":"Range (range) between '0 to 1'manually with minimum (minimum) and maximum (maximum) values","73f43384":"Therefore, I will create a new column called 'extension'.","8d1bc205":"- The column in past_due_days is treated as missing because it is not overdue.\n- Therefore, the missing values are replaced by the due date paid minus the date of data creation.\n- The data creation date is the date past_due_days is added to the value of missing values by due_days.","4a8808d9":"I found something strange while looking at the data.\n\nIn some cases, it was against the formula 'due_date'-'effective_date' = term.\n\nLet's see the index number 398.\n\nAccording to the formula, it should be 60 but 'term' is 30.\n\nSo I assumed that there were times when the period was extended.\n\nHowever, if there is only one case, it will be judged as a data error.","7c74687f":"# EDA","37821554":"# Preprocessing","52435f66":"The small size of the sample increased the risk of overfit.","32f60416":"# Modeling"}}