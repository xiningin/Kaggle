{"cell_type":{"e070e39f":"code","c95e95da":"code","5ad19218":"code","516df8fe":"code","279da59d":"code","c416ab77":"code","70d9d032":"code","345429ec":"code","377a1631":"code","9e38361d":"code","2d0ae962":"code","1cf80d19":"code","cce2eb31":"code","c1e53c15":"code","2015d89f":"code","acbf5724":"code","ba54bd3c":"code","a8c61279":"code","29c6d60d":"code","380c425a":"markdown","2e2b3d34":"markdown","b0b90d72":"markdown","54a1d12d":"markdown","0a41108f":"markdown","ea9f2c28":"markdown","204cbc75":"markdown","f26a78a8":"markdown","4917cd45":"markdown","2c276f38":"markdown","27087c00":"markdown","e151640f":"markdown","d85a2571":"markdown","20af9258":"markdown","b0db61b4":"markdown","764bf07d":"markdown","804deb44":"markdown"},"source":{"e070e39f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c95e95da":"import torch\nfrom torchvision import datasets, transforms, models\nfrom torch.autograd import Variable\nimport numpy as np\nfrom matplotlib import pyplot as plt","5ad19218":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ndata_dir = \"..\/input\/flowers_\/flowers_\/\"\n\ntrain_transform = transforms.Compose([\n                                transforms.Resize(150),\n                                transforms.RandomResizedCrop(150),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ColorJitter(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntest_transform = transforms.Compose([\n                                transforms.Resize(150),\n                                transforms.CenterCrop(150),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntrain_data  = datasets.ImageFolder(data_dir + '\/train', train_transform)\ntest_data = datasets.ImageFolder(data_dir + '\/test', test_transform)","516df8fe":"classes = train_data.classes\nclass_idx = train_data.class_to_idx\nclass_idx","279da59d":"train_loader = torch.utils.data.DataLoader(train_data,\n                                           batch_size=100,\n                                           shuffle=True,\n                                           num_workers=1)\n\ntest_loader = torch.utils.data.DataLoader(test_data,\n                                          batch_size=100,\n                                          shuffle=False,\n                                          num_workers=1)\n\nprint(len(train_loader))","c416ab77":"images , labels = next(iter(train_loader))\nimages.shape, len(labels)","70d9d032":"# visualize data\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata_iter = iter(test_loader)\nimages, labels = data_iter.next()\n\nfig = plt.figure(figsize=(25, 5))\nfor idx in range(2):\n    ax = fig.add_subplot(1, 5, idx + 1, xticks=[], yticks=[])\n    # unnormolaize first\n    img = images[idx] \/ 2 + 0.5\n    npimg = img.numpy()\n    img = np.transpose(npimg, (1, 2, 0)) #transpose\n    ax.imshow(img, cmap='gray')\n    ax.set_title(classes[labels[idx]])","345429ec":"model = models.resnet50(pretrained=True)\nmodel.fc","377a1631":"for param in model.parameters():\n    param.required_grad = False","9e38361d":"import torch.nn as nn\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2048, out_features=1024),\n  nn.LeakyReLU(),\n  nn.Dropout(p=0.2),\n  nn.Linear(in_features=1024, out_features=512),\n  nn.LeakyReLU(),\n  nn.Dropout(p=0.3),\n  nn.Linear(in_features=512, out_features=5),\n  nn.LogSoftmax(dim=1)  \n)\n    \nmodel.fc = classifier\nmodel.fc","2d0ae962":"import torch.optim as optim\nimport torch\n\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n#gpu\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","1cf80d19":"n_epochs = 5\n\n# compare overfited\ntrain_loss_data,valid_loss_data = [],[]\n\n# initialize tracker for minimum validation loss\nvalid_loss_min = np.Inf # set initial \"min\" to infinity\n\nclass_correct = list(0. for i in range(5))\nclass_total = list(0. for i in range(5))\n\nfor epoch in range(n_epochs):\n    # monitor training loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train() # prep model for training\n    for data, target in train_loader:\n        # Move input and label tensors to the default device\n        data, target = data.to(device), target.to(device)\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item() #*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval() # prep model for evaluation\n    for data, target in test_loader:\n        # Move input and label tensors to the default device\n        data, target = data.to(device), target.to(device)\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update running validation loss \n        valid_loss += loss.item() #*data.size(0)\n        # convert output probabilities to predicted class\n        _, pred = torch.max(output, 1)\n        # compare predictions to true label\n        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n        # calculate test accuracy for each object class\n        for i in range(16):\n          label = target.data[i]\n          class_correct[label] += correct[i].item()\n          class_total[label] += 1\n        \n        \n    # print training\/validation statistics \n    # calculate average loss over an epoch\n    train_loss = train_loss\/len(train_loader.dataset)\n    valid_loss = valid_loss\/len(test_loader.dataset)\n    \n    #clculate train loss and running loss\n    train_loss_data.append(train_loss)\n    valid_loss_data.append(valid_loss)\n    \n    print('Epoch: {}\/{} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch+1,\n        n_epochs,\n        train_loss,\n        valid_loss\n        ))\n    print('\\t\\tTest Accuracy: %4d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('\\t\\tValidation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = valid_loss","cce2eb31":"# load the saved model\nmodel.load_state_dict(torch.load('model83.pt'))","c1e53c15":"# save model\ntorch.save(model.state_dict(), 'model83.pt')","2015d89f":"# check for overfitting\nplt.plot(train_loss_data, label = \"taining loss\")\nplt.plot(valid_loss_data, label = \"validation loss\")\nplt.legend(frameon = False)","acbf5724":"# track test loss\n\ntotal_class = 5\n\ntest_loss = 0.0\nclass_correct = list(0. for i in range(total_class))\nclass_total = list(0. for i in range(total_class))\n\nwith torch.no_grad():\n  model.eval()\n  # iterate over test data\n  for data, target in test_loader:\n      # move tensors to GPU if CUDA is available\n      data, target = data.to(device), target.to(device)\n      # forward pass: compute predicted outputs by passing inputs to the model\n      output = model(data)\n      # calculate the batch loss\n      loss = criterion(output, target)\n      # update test loss \n      test_loss += loss.item()*data.size(0)\n      # convert output probabilities to predicted class\n      _, pred = torch.max(output, 1)    \n      # compare predictions to true label\n      correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n      # calculate test accuracy for each object class\n      for i in range(16):\n          label = target.data[i]\n          class_correct[label] += correct[i].item()\n          class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss\/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(total_class):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            classes[i], 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","ba54bd3c":"import os\nfrom glob import glob\nimport numpy as np  # linear algebra\nimport torch\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\ndef showPred(path):\n    classes = train_loader.dataset.class_to_idx\n\n    file = glob(os.path.join(path, '*.jpg'))[0]\n\n    with Image.open(file) as f:\n        img = test_transform(f).unsqueeze(0)\n        with torch.no_grad():\n            out = model(img.to(device)).cpu().numpy()\n            for key, value in classes.items():\n                if value == np.argmax(out):\n                    print(key)\n        plt.imshow(np.array(f))\n        plt.show()","a8c61279":"rose = data_dir + \"test\/rose\/\"\nshowPred(rose)","29c6d60d":"sun = data_dir + \"test\/sunflower\/\"\nshowPred(sun)","380c425a":"Freeze Parameters","2e2b3d34":"## Save Model","b0b90d72":"# Test per class","54a1d12d":"# Helper method \nto show individual Picture","0a41108f":"## Load Saved best model","ea9f2c28":"Prepare Data loader","204cbc75":"### Change the last linear Layer","f26a78a8":"## Check Overfitting","4917cd45":"# Test Rose","2c276f38":"Load Class and ids","27087c00":"# Training","e151640f":"# Visualize \ndata from data loder","d85a2571":"## Load ResNet50 model","20af9258":"Check shape of Image","b0db61b4":"Import libraries","764bf07d":"# Prepare Data","804deb44":"# Test Sunflower"}}