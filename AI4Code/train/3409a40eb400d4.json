{"cell_type":{"555486ee":"code","e85a4e41":"code","c67a6538":"code","89998272":"code","0ff7ee4b":"code","e0b9fb6a":"code","820603ed":"code","115a2768":"code","ae707d7b":"code","8ea05a34":"code","0912c4fb":"code","c73b697e":"code","1536fc45":"code","f09c10d5":"code","2c57df05":"code","5a49f0be":"code","5e99fc38":"code","22a043f0":"code","de6af615":"code","5fd3d6a0":"code","79863676":"code","9316296f":"code","047bc6ab":"code","db39742f":"code","17bcb92a":"code","a6099d5c":"code","cb3c6982":"code","96936cd6":"code","c26df2d8":"code","fb10ba41":"code","e23502d0":"markdown","712a5f97":"markdown","3e4d8e6b":"markdown","81a5160d":"markdown","0264ff7b":"markdown","3f59250c":"markdown","ebaa4d0e":"markdown","b3efb7d1":"markdown","5671f8ac":"markdown","c3c08bc0":"markdown","e0cd6f7d":"markdown","f8147126":"markdown","6627635f":"markdown","055480ad":"markdown","b2ba58ba":"markdown","c6083c69":"markdown","b9a0e6bb":"markdown","9a488bc0":"markdown","897047db":"markdown","5fffc317":"markdown","97a33bce":"markdown","fdf4c5c7":"markdown","defd2e4d":"markdown","2bf18418":"markdown","922c344a":"markdown","f07a8a3f":"markdown","a9119962":"markdown","fd515d04":"markdown","3fe1827d":"markdown","d114bb0d":"markdown","855b24b6":"markdown","da37cc61":"markdown","bc99de7f":"markdown"},"source":{"555486ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e85a4e41":"import pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nprint(\"Libraries Imported\")","c67a6538":"file_path = \"..\/input\/iris\/Iris.csv\"\n\niris_data = pd.read_csv(file_path, index_col=\"Id\")\n\nprint(\"Data Imported\")","89998272":"iris_data.head()","0ff7ee4b":"iris_data.shape","e0b9fb6a":"iris_data.info()","820603ed":"iris_data.describe()","115a2768":"iris_data.Species.unique()","ae707d7b":"data_setosa = iris_data.loc[iris_data.Species == \"Iris-setosa\"]\ndata_versicolor = iris_data.loc[iris_data.Species == \"Iris-versicolor\"]\ndata_virginica = iris_data.loc[iris_data.Species == \"Iris-virginica\"]","8ea05a34":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 3, figsize=(15, 5), sharex=True)\nsns.despine(left=True)\n\n#Plot the boxplot\nsns.boxplot(x = iris_data['SepalLengthCm'], ax=axes[0])\n\n# Plot the histogram\nsns.distplot(a=iris_data['SepalLengthCm'], kde=False, ax=axes[1])\n\n# Plot the density plot\nsns.kdeplot(data=iris_data['SepalLengthCm'], shade=True, ax=axes[2])\n\nplt.tight_layout()","0912c4fb":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 3, figsize=(15, 5), sharex=True)\nsns.despine(left=True)\n\n#Plot the boxplot\nsns.boxplot(x = iris_data['SepalWidthCm'], ax=axes[0])\n\n# Plot the histogram\nsns.distplot(a=iris_data['SepalWidthCm'], kde=False, ax=axes[1])\n\n# Plot the density plot\nsns.kdeplot(data=iris_data['SepalWidthCm'], shade=True, ax=axes[2])\n\nplt.tight_layout()","c73b697e":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 3, figsize=(15, 5), sharex=True)\nsns.despine(left=True)\n\n#Plot the boxplot\nsns.boxplot(x = iris_data['PetalLengthCm'], ax=axes[0])\n\n# Plot the histogram\nsns.distplot(a=iris_data['PetalLengthCm'], kde=False, ax=axes[1])\n\n# Plot the density plot\nsns.kdeplot(data=iris_data['PetalLengthCm'], shade=True, ax=axes[2])\n\nplt.tight_layout()","1536fc45":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 3, figsize=(15, 5), sharex=True)\nsns.despine(left=True)\n\n#Plot the boxplot\nsns.boxplot(x = iris_data['PetalWidthCm'], ax=axes[0])\n\n# Plot the histogram\nsns.distplot(a=iris_data['PetalWidthCm'], kde=False, ax=axes[1])\n\n# Plot the density plot\nsns.kdeplot(data=iris_data['PetalWidthCm'], shade=True, ax=axes[2])\n\nplt.tight_layout()","f09c10d5":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n\n# Histograms for each species\nsns.distplot(a=data_setosa['SepalLengthCm'], label=\"Iris-setosa\", kde=False, ax=axes[0])\nsns.distplot(a=data_versicolor['SepalLengthCm'], label=\"Iris-versicolor\", kde=False, ax=axes[0])\nsns.distplot(a=data_virginica['SepalLengthCm'], label=\"Iris-virginica\", kde=False, ax=axes[0])\n\n# KDE plots for each species\nsns.kdeplot(data=data_setosa['SepalLengthCm'], label=\"Iris-setosa\", shade=True, ax=axes[1])\nsns.kdeplot(data_versicolor['SepalLengthCm'], label=\"Iris-versicolor\", shade=True, ax=axes[1])\nsns.kdeplot(data=data_virginica['SepalLengthCm'], label=\"Iris-virginica\", shade=True, ax=axes[1])\n\n\nplt.tight_layout()","2c57df05":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n# Plot the Swarmplot\nsns.swarmplot(x=iris_data['Species'], y=iris_data['SepalLengthCm'], ax=axes[0])\n\n# Plot the Boxplot\nsns.boxplot(x=iris_data['Species'], y=iris_data['SepalLengthCm'], ax=axes[1])\n\nplt.tight_layout()","5a49f0be":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n# Histograms for each species\nsns.distplot(a=data_setosa['SepalWidthCm'], label=\"Iris-setosa\", kde=False, ax=axes[0])\nsns.distplot(a=data_versicolor['SepalWidthCm'], label=\"Iris-versicolor\", kde=False, ax=axes[0])\nsns.distplot(a=data_virginica['SepalWidthCm'], label=\"Iris-virginica\", kde=False, ax=axes[0])\n\n# KDE plots for each species\nsns.kdeplot(data=data_setosa['SepalWidthCm'], label=\"Iris-setosa\", shade=True, ax=axes[1])\nsns.kdeplot(data_versicolor['SepalWidthCm'], label=\"Iris-versicolor\", shade=True, ax=axes[1])\nsns.kdeplot(data=data_virginica['SepalWidthCm'], label=\"Iris-virginica\", shade=True, ax=axes[1])\n\n\nplt.tight_layout()","5e99fc38":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n# Plot the Swarmplot\nsns.swarmplot(x=iris_data['Species'], y=iris_data['SepalWidthCm'], ax=axes[0])\n\n# Plot the Boxplot\nsns.boxplot(x=iris_data['Species'], y=iris_data['SepalWidthCm'], ax=axes[1])\n\nplt.tight_layout()","22a043f0":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n# Histograms for each species\nsns.distplot(a=data_setosa['PetalLengthCm'], label=\"Iris-setosa\", kde=False, ax=axes[0])\nsns.distplot(a=data_versicolor['PetalLengthCm'], label=\"Iris-versicolor\", kde=False, ax=axes[0])\nsns.distplot(a=data_virginica['PetalLengthCm'], label=\"Iris-virginica\", kde=False, ax=axes[0])\n\n# KDE plots for each species\nsns.kdeplot(data=data_setosa['PetalLengthCm'], label=\"Iris-setosa\", shade=True, ax=axes[1])\nsns.kdeplot(data_versicolor['PetalLengthCm'], label=\"Iris-versicolor\", shade=True, ax=axes[1])\nsns.kdeplot(data=data_virginica['PetalLengthCm'], label=\"Iris-virginica\", shade=True, ax=axes[1])\n\n\nplt.tight_layout()","de6af615":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n# Plot the Swarmplot\nsns.swarmplot(x=iris_data['Species'], y=iris_data['PetalLengthCm'], ax=axes[0])\n\n# Plot the Boxplot\nsns.boxplot(x=iris_data['Species'], y=iris_data['PetalLengthCm'], ax=axes[1])\n\nplt.tight_layout()","5fd3d6a0":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n# Histograms for each species\nsns.distplot(a=data_setosa['PetalWidthCm'], label=\"Iris-setosa\", kde=False, ax=axes[0])\nsns.distplot(a=data_versicolor['PetalWidthCm'], label=\"Iris-versicolor\", kde=False, ax=axes[0])\nsns.distplot(a=data_virginica['PetalWidthCm'], label=\"Iris-virginica\", kde=False, ax=axes[0])\n\n# KDE plots for each species\nsns.kdeplot(data=data_setosa['PetalWidthCm'], label=\"Iris-setosa\", shade=True, ax=axes[1])\nsns.kdeplot(data_versicolor['PetalWidthCm'], label=\"Iris-versicolor\", shade=True, ax=axes[1])\nsns.kdeplot(data=data_virginica['PetalWidthCm'], label=\"Iris-virginica\", shade=True, ax=axes[1])\n\n\nplt.tight_layout()","79863676":"# Set up the matplotlib figure\nf, axes = plt.subplots(ncols = 2, figsize=(10, 5), sharex=True)\nsns.despine(left=True)\n\n# Plot the Swarmplot\nsns.swarmplot(x=iris_data['Species'], y=iris_data['PetalWidthCm'], ax=axes[0])\n\n# Plot the Boxplot\nsns.boxplot(x=iris_data['Species'], y=iris_data['PetalWidthCm'], ax=axes[1])\n\nplt.tight_layout()","9316296f":"sns.pairplot(iris_data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']], hue=\"Species\", diag_kind=\"hist\")","047bc6ab":"from sklearn.model_selection import train_test_split\n\ny = iris_data.Species\nfeatures = ['SepalLengthCm','SepalWidthCm','PetalLengthCm', 'PetalWidthCm']\nX = iris_data[features]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)","db39742f":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","17bcb92a":"data = pd.DataFrame(X_train)\ndata.columns = X.columns\ndata['label'] = y\n\nf, axes = plt.subplots(ncols = 4, figsize=(20, 5), sharex=True)\nsns.despine(left=True)\n\nsns.kdeplot(data=data['SepalLengthCm'], shade=True, ax=axes[0])\nsns.kdeplot(data=data['SepalWidthCm'], shade=True, ax=axes[1])\nsns.kdeplot(data=data['PetalLengthCm'], shade=True, ax=axes[2])\nsns.kdeplot(data=data['PetalWidthCm'], shade=True, ax=axes[3])\n","a6099d5c":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n\nprint('Confusion matrix : \\n' + str(confusion_matrix(y_test, y_pred)))\nprint('Accuracy score : \\n' + str(accuracy_score(y_test, y_pred)))","cb3c6982":"# Train \/ Test Split\ny_2 = iris_data.Species\nfeatures = ['SepalLengthCm', 'PetalLengthCm', 'PetalWidthCm']\nX_2 = iris_data[features]\n\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.1, random_state=0)\n\n# Standardization\nsc = StandardScaler()\nX_train_2 = sc.fit_transform(X_train_2)\nX_test_2 = sc.transform(X_test_2)\n\n# Model Development\nclassifier_2 = RandomForestClassifier(max_depth=2, random_state=0)\n\nclassifier_2.fit(X_train_2, y_train_2)\ny_pred_2 = classifier_2.predict(X_test_2)\n\nprint('Confusion matrix : \\n' + str(confusion_matrix(y_test, y_pred_2)))\nprint('Accuracy score : \\n' + str(accuracy_score(y_test, y_pred_2)))","96936cd6":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nlda = LinearDiscriminantAnalysis(n_components=2)\n\nX_train_lda = lda.fit_transform(X_train, y_train)\nX_test_lda = lda.transform(X_test)\n\nexplained_variance = lda.explained_variance_ratio_\n\nprint(explained_variance)","c26df2d8":"n_component_1 = 0.99099846\nn_component_2 = 0.00900154\npercentage_of_variance_explained = n_component_1 + n_component_2\nprint(\"Percentage of variance explained = \" + str(percentage_of_variance_explained*100))","fb10ba41":"classifier_lda = RandomForestClassifier(max_depth=2, random_state=0)\n\nclassifier_lda.fit(X_train_lda, y_train)\ny_pred_lda = classifier_lda.predict(X_test_lda)\n\nprint('Confusion matrix : \\n' + str(confusion_matrix(y_test, y_pred_lda)))\nprint('Accuracy score : \\n' + str(accuracy_score(y_test, y_pred_lda)))","e23502d0":"# 3) Data Preprocessing","712a5f97":"### 3.2) Standardization","3e4d8e6b":"### 3.1) Traint \/ Test Split","81a5160d":"The Iris Dataset includes **3 Iris Species** with **50 samples** each (**150 rows**) and is composed of **6 columns** :\n\n* the **ID** column\n* 4 columns of measures on Sepal and Petal : **SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm**\n* the column containing the labels : **Iris-setosa, Iris-versicolor, Iris-virginica**\n\nThe objective is to build a model that uses the features to  **classify the flowers** with a maximum of accuracy. In order to reach this goal, we are going to perform an **exploratory data analysis** to understand the data and choose the best features. Then we will build a **random forest model** and try to improve its performance firstly by **dropping out the less interesting feature** and secondly by using the **linear discriminant analysis** technic which allows to optimize class separability.","0264ff7b":"**Comments:**\n\nAccording to these different plots, the petal width seems to be an interesting feature to use in order to classify the different species. Indeed : \n* the petal width of Iris-setosa flowers is clearly smaller than the petal width of the two other species\n* even if the difference of petal width is less clear between Iris-versicolor and Iris-virginica, the petal width of Iris-versicolor flowers is mainly smaller than the petal width of Iris-virginica flowers","3f59250c":"**Comments:**\n\nAccording to these different plots, the sepal length seems to be quite an interesting feature to use in order to classify the different species. Indeed : \n* the sepal length of Iris-setosa flowers is mainly smaller than the petal length of the two other species\n* even if the difference of sepal length is less clear between Iris-versicolor and Iris-virginica, the sepal length of Iris-versicolor flowers is mainly smaller than the sepal length of Iris-virginica flowers","ebaa4d0e":"**Comments:**\n\nAccording to these different plots, the sepal width seems to be the less interesting feature to use in order to classify the different species. Indeed : \n* the sepal width of the Iris-setosa flowers seems to be larger than the sepal width of Iris-versicolor and Iris-virginica but for many samples this difference of size is not true\n* the sepal width of the Iris-virginica flowers seems to be larger than the sepal width of Iris-versicolor but for many samples this difference of size is not true","b3efb7d1":"* **PetalLengthCm vs Species**","5671f8ac":"### 4.2) Random Forest Model without the SepalWidthCm Feature","c3c08bc0":"**Comments:**\n\nThe two components of the linear discriminant analysis explains 100% of the variance between classes (Iris-setosa, Iris-versicolor, Iris-virginica).","e0cd6f7d":"**Comments:**\n\nThe random forest model has the same accuracy score with or without the SepalWidthCm feature.\n\nAs we could predict, thanks to the different plots of the data, the random forest model (with all or three features) makes good predictions concerning the Iris-setosa species but has more difficulties with the Iris-versicolor and Iris-virginica species.\n\nIn order to solve this problem we will implement a Linear Discrimant Analysis which allows to optimize both class separability and dimensionality reduction (less important in our case given the small number of features of the dataset).","f8147126":"### 2.3) Multivariate Data Analysis","6627635f":"**Comments:**\n\nThe model accuracy using all the features is 93.33%. We will first try to improve it by dropping out the SepalWidthCM feature because it seems to be the less interesting to achieve the classification.\n","055480ad":"### 2.1) General information on the dataset","b2ba58ba":"* **SepalWidthCm vs Species**","c6083c69":"**Comments:**\n\nAs we see on the KDE plots, standardscaler allows to scale the features such that their distribution is now centred around 0 and has a standard deviation of 1. This allows to achieve better performance in classification problems.","b9a0e6bb":"* **SepalWidthCm**","9a488bc0":"# 0) The Iris Dataset","897047db":"* **PetalLengthCm**","5fffc317":"* **SepalLengthCm vs Species**","97a33bce":"# 1) Importing Iris Dataset and Libraries","fdf4c5c7":"**Comments:**\n\nUsing the LDA projection of the dataset, the random forest model is able to class the different samples with an accuracy score of 100%. With the original data, the accuray score was 93.33%.","defd2e4d":"### 4.1) Random Forest Model with all the Features","2bf18418":"### 2.2) Univariate Analysis","922c344a":"### 4.3) Linear Discriminant Analysis","f07a8a3f":"* **PetalWidthCm**","a9119962":"* **All features vs All features vs Species**","fd515d04":"# 2) Exploratory Data Analysis","3fe1827d":"* **PetalWidthCm vs Species**","d114bb0d":"**Comments:**\n\nAccording to these different plots, the petal length seems to be an interesting feature to use in order to classify the different species. Indeed : \n* the petal length of Iris-setosa flowers is clearly smaller than the petal length of the two other species\n* even if the difference of petal length is less clear between Iris-versicolor and Iris-virginica, the petal length of Iris-versicolor flowers is mainly smaller than the petal length of Iris-virginica flowers","855b24b6":"# 4) Model development + Linear Discriminant Analysis","da37cc61":"* **SepalLengthCm**","bc99de7f":"### 4.4) Random Forest + Linear Discriminant Analysis"}}