{"cell_type":{"d0d9ceb3":"code","09ceec2e":"code","0c825391":"code","c1192014":"code","1ed77125":"code","c14de59b":"code","488a7f5b":"code","66d4a4a9":"code","32662817":"code","1fba58e3":"code","8868e5b6":"code","3887b805":"code","10a547d1":"code","91e1b2e1":"code","c049d117":"markdown","ace3e8d8":"markdown","8d0c9ec2":"markdown","d1d9a729":"markdown","9c1063ee":"markdown","9a7b0023":"markdown","8016c8c5":"markdown","9feb93f4":"markdown","d9a7a727":"markdown","cb2ee6e0":"markdown","c9721dbe":"markdown","d3153f50":"markdown","7a9ac9cd":"markdown","bfdbd54f":"markdown","5d091c2d":"markdown","b2ce4eb5":"markdown","12648172":"markdown","1be6315a":"markdown","d5b65e6d":"markdown","b28480f7":"markdown","8df28117":"markdown","56054ba6":"markdown","a2caafca":"markdown","aa904b1d":"markdown"},"source":{"d0d9ceb3":"import pandas as pd\n\nbooks = pd.read_csv('\/kaggle\/input\/market-basket-analysis-dataset\/bookstore_transactions.csv')\nprint(books.head(2))","09ceec2e":"transactions = books['Transaction'].apply(lambda t: t.split(','))\ntransactions = list(transactions)\ntransactions","0c825391":"history = transactions.count(['History', 'Bookmark'])\nbiography = transactions.count(['Biography', 'Bookmark'])\nfiction = transactions.count(['Fiction', 'Bookmark'])\n\nprint('history:', history)\nprint('biography:', biography)\nprint('fiction:', fiction)","c1192014":"from itertools import permutations\n\nflattened = [item for transaction in transactions for item in transaction]\nitems = list(set(flattened))","1ed77125":"rules = list(permutations(items,2))\nprint(rules)","c14de59b":"print(len(rules))","488a7f5b":"from mlxtend.preprocessing import TransactionEncoder\nencoder = TransactionEncoder().fit(transactions)\nonehot = encoder.transform(transactions)","66d4a4a9":"onehot = pd.DataFrame(onehot, columns=encoder.columns_)\nprint(onehot)","32662817":"print(onehot.mean())","1fba58e3":"import numpy as np\n\nonehot['Fiction+Poetry'] = np.logical_and(onehot['Fiction'],onehot['Poetry'])\n\nprint(onehot.mean())","8868e5b6":"supportBF = np.logical_and(onehot['Biography'], onehot['Fiction']).mean()\nsupportBF","3887b805":"supportBP = np.logical_and(onehot['Biography'], onehot['Poetry']).mean()\nsupportBP","10a547d1":"supportBH = np.logical_and(onehot['Biography'], onehot['History']).mean()\nsupportBH","91e1b2e1":"supportPH = np.logical_and(onehot['Poetry'], onehot['History']).mean()\nsupportPH","c049d117":"## Identifying association rules\n\n### Association rules\n    - Association rule \n        - Contains antecedent and consequent\n            - {health} -> {cooking}\n    - Multi-antecedent rule\n        - {humor,travel} -> {language}\n    - Multi-consequent rule\n        - {biography} -> {histroy,language}\n","ace3e8d8":"##### Compute support for Potter and Twilight\nsupportPT = np.logical_and(books['Potter'], books['Twilight']).mean()\n\n##### Compute support for Potter\nsupportP = books['Potter'].mean()\n\n##### Compute support for Twilight\nsupportT = books['Twilight'].mean()\n\n##### Compute confidence for both rules\n\n##### Compute the confidence of {Potter} \u2192 {Twilight} and {Twilight} \u2192 {Potter}.\nconfidencePT = supportPT \/ supportP\nconfidenceTP = supportPT \/ supportT\n\n##### Print results\nprint('{0:.2f}, {1:.2f}'.format(confidencePT, confidenceTP))","8d0c9ec2":"### Computing the support metric\n\nYou one-hot encoded transactions as the DataFrame onehot. Here you'll make use of that DataFrame and the support metric to help the owner. First, she has asked you to identify frequently purchased items, which you'll do by computing support at the item-level. And second, she asked you to check whether the rule {Fiction} \u2192 {Poetry} has a support of over 0.05. Note that onehot has been defined and is available. ","d1d9a729":"### Computing support for single items\n\nNote that for calculating support for items we use `mean()` method","9c1063ee":"# Market Basket Analysis\n\nThe basics of Market Basket Analysis: association rules, metrics, and pruning. You\u2019ll then apply these concepts to help a small grocery store improve its promotional and product placement efforts.","9a7b0023":"## What is market basket analysis?\n\n1. Identify products frequently purchased together\n    - Biography and history\n2. Construct recommendations based on these findings\n    - place biography and history sections together \n\n## Use cases\n    - Construct association rules\n        - {antecedent} -> {consequent}\n    - identify items frequently purchased\n    ","8016c8c5":"## One-hot encoding transaction data\n\nWe will use a common pipeline for preprocessing data for use in market basket analysis. The first step is to import a pandas DataFrame and select the column that contains transactions. Each transaction in the column will be a string that consists of a number of items, each separated by a comma. The next step is to use a lambda function to split each transaction string into a list, thereby transforming the column into a list of lists.\n\nHere the list of lists, which is available as transactions. You will then transform transactions into a one-hot encoded DataFrame, where each column consists of TRUE and FALSE values that indicate whether an item was included in a transaction.","9feb93f4":"# Aggregation and Pruning\n\n\nThe fundamental problem of Market Basket Analysis is determining how to translate vast amounts of customer decisions into a small number of useful rules. This process typically starts with the application of the Apriori algorithm and involves the use of additional strategies, such as pruning and aggregation. Learn how to use these methods and will ultimately apply them in exercises where you assist a retailer in selecting a physical store layout and performing product cross-promotions.\n","d9a7a727":"\n## Multiple antecedents and consequents\n\nMarket basket analysis revolves around the use of association rules, which are if-then statements about the relationship between two sets of items. The rule {coffee} \u2192 {milk}, for instance, is read as \"if coffee then milk,\" where coffee is the antecedent and milk is the consequent. Many rules have multiple antecedents and consequents.\n\n    - Multiple Antecedent `{sugar, flower} -> {sweet puff}`\n    - Multiple Consequent `{tea} -> {milk,biscuit}`\n    - Multiple Antecedent and Consequent `{biscuit,jam} -> {milk,cereal}`","cb2ee6e0":"## Cross-selling products\n\nThe small grocery store has decided to cross-sell chewing gum with either `coffee, cereal, or bread`. To determine which of the three items is best to use, the store owner has performed an experiment. For one week, she sold chewing gum next to the register and recorded all transactions where it was purchased with either `coffee, cereal, or bread`. The transactions from that day are available as a list of lists named transactions. Each transaction is either `['coffee','gum']`, `['cereal','gum']`, or `['bread','gum']`","c9721dbe":"### Recommending books with support\n\nA library wants to get members to read more and has decided to use market basket analysis to figure out how. They approach you to do the analysis. You are given the data in one-hot encoded format in a pandas DataFrame called books.\n\nEach column in the DataFrame corresponds to a book and has the value TRUE if the book is contained in a reader's library and is rated highly. To make things simpler, we'll work with shortened book names: Hunger, Potter, and Twilight.","d3153f50":"> Even though the support is identical for the two association rules, the confidence is much higher for Twilight -> Harry Potter, since Harry Potter has a higher support than Twilight.","7a9ac9cd":"## The simplest metric\n\n### Metrics and Pruning\n\n    - A metric is a measure of performance for rules\n        - {humor} -> {poetry} - .81\n    - pruning is the use of metrics to discard the rules\n        - Retain {humor} -> {poetry}\n        \n- The support metric measures the share of transactions that contain the itemset\n    - number of transactions with item(s) \/ number of transactions \n    - number of transactions with milk \/ total transactions \n","bfdbd54f":"### Generating rules with itertools","5d091c2d":"> <script.py> output:\n- Hunger Games and Harry Potter: 0.12\n- Hunger Games and Twilight: 0.09\n- Harry Potter and Twilight: 0.14\n\nBased on the support metric, Harry Potter and Twilight appear to be the best options for cross-promotion. In the next problem, we'll consider whether we should use Harry Potter to promote Twilight or Twilight to promote Harry Potter.","b2ce4eb5":"### MLxtend package\n\n```python\nfrom mlxtend.frequent_patterns import association_rules\nfrom mlxtend.frequent_patterns import apriori\n\nfrequent_itemsets = apriori(transactions, min_support = .001, max_len = 2, use_colnames = True)\n\nrules = association_rules(frequent_itemsets, metric = 'lift', min_threshold = 1.0)\n```","12648172":"### Confidence and lift\n\n> Confidence = support(Milk & Coffee)\/ support(Milk) = 0.20\/1.0 = 0.20\n\nAs support for milk and coffee and the confidence is same, this means purchasing milk doesn't assure purchasing coffee.\n\n**Lift**: Lifts provide another metric for evaluating the relationship between items\n    - Numerator: proportion of transactions that contain X and Y\n    - Denominator: Proportion if X and Y assigned randomly and independently\n","1be6315a":"### Refining support with confidence\n\nAfter reporting your findings, the library asks you about the direction of the relationship. Should they use Harry Potter to promote Twilight or Twilight to promote Harry Potter?\n\nAfter thinking about this, you decide to compute the confidence metric, which has a direction, unlike support. You'll compute it for both {Potter} \u2192 {Twilight} and {Twilight} \u2192 {Potter}","d5b65e6d":"## The basics of market basket analysis\n\nMarket basket analysis uses lists of transactions to identify useful associations between items. Such associations can be written in the form of a rule that has an antecedent and a consequent. Let's assume a small grocery store has asked you to look at their transaction data. After some analysis, you find the rule given below.\n\n`{cereal} \u2192 {milk}`\n\nWhich statement about this rule is correct?\n\n`{cereal} is the antecedent, {milk} is the consequent, and both are items.`","b28480f7":"**Important links:**\n    - [Instacart Market Basket Analysis](https:\/\/medium.com\/kaggle-blog\/instacart-market-basket-analysis-feda2700cded)\n    - [Food Discovery with Uber Eats: Recommending for the Marketplace](https:\/\/eng.uber.com\/uber-eats-recommending-marketplace\/)","8df28117":"# Visualizing Rules\n\nLearn how visualizations are used to guide the pruning process and summarize final results, which will typically take the form of itemsets or rules. You\u2019ll master the three most useful visualizations -- heatmaps, scatterplots, and parallel coordinates plots \u2013 and will apply them to assist a movie streaming service.","56054ba6":"# Association Rules\n\nAssociation rules tell us that two or more items are related. Metrics allow us to quantify the usefulness of those relationships. Learning six metrics to evaluate association rules: supply, confidence, lift, conviction, leverage, and Zhang's metric. You\u2019ll then use association rules and metrics to assist a library and an e-book seller.\n","a2caafca":"# Objective\n\n\nMarket Basket Analysis, which is a powerful tool for translating vast amounts of customer transaction and viewing data into simple rules for product promotion and recommendation. Purpose of this notebook is to learn how to perform Market Basket Analysis using the Apriori algorithm, standard and custom metrics, association rules, aggregation and pruning, and visualization. Also to reinforce new skills through building recommendations for a small grocery store, a library, an e-book seller, a novelty gift retailer, and a movie streaming service.","aa904b1d":"## Generating association rules\n\nAs you saw, the function `permutations` from the module `itertools` can be used to quickly generate the set of all one-antecedent, one-consequent rules. You do not, of course, know which of these rules are useful. You simply know that each is a valid way to combine two items.\n\nLet's practice generating and counting the set of all rules for a subset of the grocery dataset: coffee, tea, milk, and sugar."}}