{"cell_type":{"adfec206":"code","6f2e4aaa":"code","3cd6dda7":"code","e03bb619":"code","5aee6fad":"code","df0c2643":"code","deb9da32":"code","2cab583d":"code","26457eb5":"code","bfeeec8e":"markdown","15a4e97e":"markdown","719d3763":"markdown","85705235":"markdown","035c07f0":"markdown","a0c1517e":"markdown","ea1e6a95":"markdown","26865d65":"markdown","a59f2f96":"markdown"},"source":{"adfec206":"%matplotlib inline\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt","6f2e4aaa":"(x_train, y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()","3cd6dda7":"plt.figure(figsize = (10,20))\n\nfor i in range(0,10):\n    plt.subplot(4,4,i+1)\n    plt.imshow(x_train[i],cmap = \"binary\")\n    plt.xlabel(str(y_train[i]))\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","e03bb619":"# size of data\nprint(\"x_train\",x_train.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_test\",y_test.shape)\n\n# In the training set we have 60000 examples and in the test set we have 10000 examples\n# Each example is an array of 28 x 28 which is the size of the image\n\n# reshape the data to feature vector of size (28 x 28,1) for each example\nx_train = np.reshape(x_train,(x_train.shape[0], x_train.shape[1]*x_train.shape[2]))\nx_test = np.reshape(x_test,(x_test.shape[0], x_test.shape[1]*x_test.shape[2]))\n\nprint(x_train.shape)\nprint(x_test.shape)\n\n# normalisation\n# each value in the array is between 0 to 255\n# we divide each value by 255 to get a value between 0 and 1\n\nx_train = x_train \/ 255\nx_test = x_test \/ 255","5aee6fad":"# two hidden layers with 32 units each and sigmoid as activation function\n# softmax is used for output layer\n# 10 units are present in output layer\nmodel  = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(32, activation = 'tanh' , input_shape =(784,)),\n    tf.keras.layers.Dense(32, activation = 'tanh'),\n    tf.keras.layers.Dense(10, activation = 'softmax')\n])\n\nmodel.compile(\n    loss = 'sparse_categorical_crossentropy',\n    optimizer = 'adam',\n    metrics = ['accuracy']\n)","df0c2643":"_ = model.fit(\n    x_train,y_train,\n    validation_data = (x_test,y_test),\n    epochs = 20, batch_size = 1024,\n    verbose = 2\n)","deb9da32":"model.save('model.h5')","2cab583d":"%%writefile ml_server.py\n\n# creating a basic flask server\n\nimport json\nimport tensorflow as tf\nimport numpy as np\nimport random\n\nfrom flask import flask, request\n\napp = Flask(__name__)\n\nmodel = tf.keras.models.load_model('model.h5')\n\n# feature model will take the input same as 'model' but give the output of all layers\nmodel = tf.keras.modesls.load.model('model.h5')\nfeature_model = tf.keras.models.Model(\n    model.inputs,\n    [layer.output for layer in model.layers]\n)\n\n_ , (x_test, _) = tf.keras.datasets.mnist.load_data()\nx_test = x_test\/ 255\n\ndef get_prediction():\n    index = np.random.choice(x_test.shape[0])\n    image = x_test[index, :,:]\n    image_arr = np.reshape(image,(1,x_test.shape[1]*x_test.shape[2]))\n    return feature_model.predict((image_arr)), image\n\n\n@app.route('\/', methods = ['GET','POST'])\n\ndef index():\n    if request.method == 'POST':\n        preds, image = get_prediction()\n        final_preds = [p.tolist() for p in preds]\n        return json.dumps[(\n            'prediction': final_preds,\n            'image': image.tolist()\n        )]\n    return \"Welcome to ML server\"\n\nif __name__ == '__main__':\n    app.run()\n\n","26457eb5":"%%writefile app.py\n\nimport streamlit as st\nimport json\nimport requests\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# use streamlit run app.py to run the app\n\nURI = 'http:\/\/127.0.0.1:5000'\n\nst.title('Neural Network Visualiser')\nst.sidebar.markdown(\"## Input Image\")\n\nif st.button('Get random prediction'):\n    response = requests.post(URI, data=())\n    response = json.loads(response.text())\n    preds = response.get('prediction')\n    image = respnse.get('image')\n    image = np.reshape(image,(28,28))\n    \n    st.sidebar.image(image,width = 150)\n    \n    for layer, p in enumerate(preds):\n        numbers = np.squeeze(np.array(p))\n        plt.figure(figsize = (32,4))\n        \n        # output layer\n        if layer == 2:\n            row = 1\n            col = 10\n        \n        # hidden layers\n        else: \n            row = 2\n            col = 16\n        \n        for i, number in enumerate(numbers):\n            plt.subplot(row,col, i+1)\n            plt.imshow(number*np.ones((8,8,3).astype('float32'))\n            plt.xticks([])\n            plt.yticks([])\n            \n            if layer == 2:\n                plt.xlabel(str(i), fontsize  = 40)\n        \n        plt.subplots_adjust(wspace = 0.05, hspace = 0.05)\n        plt.tight_layout()\n        st.text('Layer {}'.format(layer+1))\n        st.pyplot()","bfeeec8e":"## Streamlit web application","15a4e97e":"## Datasets from mnist","719d3763":"## Creating a NN model ","85705235":"## Importing Libraries","035c07f0":"## Plot the first 10 examples from training set","a0c1517e":"## ML server","ea1e6a95":"## Training the model","26865d65":"## Save the NN model","a59f2f96":"## Normalising the data"}}