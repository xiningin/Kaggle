{"cell_type":{"9716ea01":"code","b953ce64":"code","7952f9f6":"code","2eb05263":"code","c3bc1d89":"code","bdacd0df":"code","70f60810":"code","8923a5b4":"code","4acea0cd":"code","a3b52131":"code","e2657b24":"code","ef0120d7":"code","59ce446b":"code","6d34a22a":"code","ff588492":"code","2db69cca":"code","6ff96016":"code","4409db23":"code","89781f93":"code","a2e4913f":"code","1052e313":"code","9780c79b":"code","015fe489":"code","25f9c002":"code","410b4185":"code","900c7f04":"code","1536772e":"code","896e5f24":"code","94286114":"code","21e50030":"code","e346bc0e":"code","92edab8f":"code","4686c57b":"code","935ed99f":"code","aebcd9ca":"code","31441167":"code","aa6c404f":"code","cffcc08f":"code","b39aa4eb":"code","405eec1c":"code","1d45e09c":"code","2e71e9ab":"code","c2fcddba":"code","ddadc322":"code","2c893eb4":"code","fbe54cb1":"code","b14e2424":"code","a132caa1":"code","bb52926b":"markdown"},"source":{"9716ea01":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b953ce64":"import pandas_profiling as pdp\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_colwidth', 5000)\npd.options.display.float_format = '{:.3f}'.format\n%matplotlib inline\nplt.style.use('fivethirtyeight')","7952f9f6":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, RepeatedKFold, GridSearchCV\nfrom sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n\nimport xgboost as xgb","2eb05263":"train_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv')\ntest_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv')\n\ntrain_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv')\ntest_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/test_identity.csv')\n\nsample_submission = pd.read_csv('..\/input\/ieee-fraud-detection\/sample_submission.csv')","c3bc1d89":"pd.set_option('display.max_columns', 500)\ntrain_transaction.head(5)","bdacd0df":"test_transaction.head(5)","70f60810":"train_identity.head(5)","8923a5b4":"test_identity.head(5)","4acea0cd":"train = train_transaction.merge(train_identity , how = 'left' , on = 'TransactionID')\ntest = test_transaction.merge(test_identity , how = 'left' , on = 'TransactionID')\n","a3b52131":"print('Train dataset has {} rows and {} columns.'.format(train.shape[0], train.shape[1]))\nprint('Test dataset has {} rows and {} columns.'.format(test.shape[0], test.shape[1]))","e2657b24":"del train_transaction, train_identity, test_transaction, test_identity","ef0120d7":"def is_integer_num(n):\n    if isinstance(n, int):\n        return True\n    if isinstance(n, float):\n        return n.is_integer()\n    return False\n\ndef missing_values_table_specified_value(df, value=0.5): \n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum()\/len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n    \n    if is_integer_num(value):\n        mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns['Missing Values'] >= value]\n        print('The number of columns with {} counts missing values is {}.'.format(value, len(mis_val_table_ren_columns)))\n    else:\n        value = value * 100\n        mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns['% of Total Values'] >= value]\n        print('The number of columns with {}% missing values is {}.'.format(value, len(mis_val_table_ren_columns)))\n    return mis_val_table_ren_columns \n\ndef missing_values_table(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","59ce446b":"missing_values_table_specified_value(train, 0.5).head()","6d34a22a":"missing_values_table_specified_value(test, 0.5).head()","ff588492":"display(missing_values_table(train), missing_values_table(test))\n","2db69cca":"train['isFraud'].value_counts()","6ff96016":"sns.countplot(train['isFraud'])","4409db23":"f,ax=plt.subplots(1,2,figsize=(18,8))\ntrain['isFraud'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('isFraud')\nax[0].set_ylabel('')\nsns.countplot('isFraud',data=train,ax=ax[1])\nax[1].set_title('isFraud')\nplt.show()","89781f93":"train=train[train.columns[train.isnull().mean() <= 0.70]] \ntest=test[test.columns[test.isnull().mean() <= 0.70]] ","a2e4913f":"quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\nprint(quantitative)\nprint('Counts: {}'.format(len(quantitative)))","1052e313":"qualitative = [f for f in train.columns if train.dtypes[f] == 'object']\nprint(qualitative)\nprint('Counts: {}'.format(len(qualitative)))","9780c79b":"for column in qualitative:\n    train[column].fillna(train[column].mode()[0], inplace=True)","015fe489":"qualitative_test = [f for f in test.columns if train.dtypes[f] == 'object']\nprint(qualitative_test)\nprint('Counts: {}'.format(len(qualitative_test)))","25f9c002":"for column in qualitative_test:\n    test[column].fillna(test[column].mode()[0], inplace=True)","410b4185":"for column in quantitative:\n    train[column].fillna(train[column].mean(), inplace=True)","900c7f04":"quantitative_test = [f for f in train.columns if train.dtypes[f] != 'object']\nprint(quantitative_test)\nprint('Counts: {}'.format(len(quantitative_test)))","1536772e":"del quantitative_test[1]","896e5f24":"quantitative_test[1]","94286114":"\nfor column in quantitative_test:\n    test[column].fillna(test[column].mean(), inplace=True)","21e50030":"print(train.shape)\nprint(test.shape)","e346bc0e":"X_train = train.drop('isFraud', axis=1)\ny_train = train['isFraud'].copy()\nX_test = test.copy()","92edab8f":"X_train.shape, X_test.shape","4686c57b":"# Label Encoding\nfor f in qualitative:\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n    X_train[f] = lbl.transform(list(X_train[f].values))\n    X_test[f] = lbl.transform(list(X_test[f].values)) ","935ed99f":"# Check if it is encoded\nprint(len(X_train.select_dtypes(include='object').columns))\nprint(len(X_test.select_dtypes(include='object').columns))\n","aebcd9ca":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","31441167":"X_train = reduce_mem_usage(X_train)\n","aa6c404f":"X_test = reduce_mem_usage(X_test)","cffcc08f":"import warnings\nwarnings.filterwarnings(\"ignore\")","b39aa4eb":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nscore = cross_val_score(LogisticRegression(),X_train,y_train).mean()","405eec1c":"print(score)","1d45e09c":"#decisiontree\nfrom sklearn.tree import DecisionTreeClassifier\ndecision_score = cross_val_score(DecisionTreeClassifier(),X_train,y_train).mean()\nprint(decision_score)","2e71e9ab":"#randomforest\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_score = cross_val_score(RandomForestClassifier(),X_train,y_train).mean()\nprint(random_score)\n","c2fcddba":"rand_model=RandomForestClassifier()\nrand_model.fit(X_train,y_train)\nrand_pred=rand_model.predict(X_test)","ddadc322":"sample_submission['isFraud'] = rand_pred\nsample_submission.to_csv('IEEE_SUBMISSION.csv',index=False)\n","2c893eb4":"sample_submission.columns","fbe54cb1":"sample_submission['isFraud'].value_counts()","b14e2424":"sample_submission['isFraud'].value_counts()","a132caa1":"sample_submission.head()","bb52926b":"Model Building"}}