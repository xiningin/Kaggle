{"cell_type":{"cb9f5dd1":"code","e011be90":"code","ccd9e9e4":"code","9ec717bf":"code","d045d2c1":"markdown"},"source":{"cb9f5dd1":"# General imports\nimport pandas as pd\nimport os, sys, gc, warnings\n\nwarnings.filterwarnings('ignore')","e011be90":"########################### DATA LOAD\/MIX\/EXPORT\n#################################################################################\n# Simple lgbm (0.0948)\nsub_1 = pd.read_csv('..\/input\/ieee-simple-lgbm\/submission.csv')\n\n# Blend of two kernels with old features (0.9468)\nsub_2 = pd.read_csv('..\/input\/ieee-cv-options\/submission.csv')\n\n# Add new features lgbm with CV (0.09485)\nsub_3 = pd.read_csv('..\/input\/ieee-lgbm-with-groupkfold-cv\/submission.csv')\n\n# Add catboost (0.09407)\nsub_4 = pd.read_csv('..\/input\/ieee-catboost-baseline-with-groupkfold-cv\/submission.csv')\n\n# Add catboost (0.09523)\nsub_5 = pd.read_csv('..\/input\/mysub18\/simple_ensemble30.csv', index_col='TransactionID')\nsub_5.to_csv('submission_old.csv')\nsub_6 = pd.read_csv('..\/input\/mysub18\/IEEE_add_917_9547.csv', index_col='TransactionID')\nsub_7 = pd.read_csv('..\/input\/mysub18\/IEEE_add_918_9548.csv', index_col='TransactionID')\nsub_7 = pd.read_csv('..\/input\/mysub18\/IEEE_version1_version2_kernel_fix.csv', index_col='TransactionID')\n# sub_7['isFraud'] += sub_6['isFraud']\nsub_7['isFraud'] += sub_5['isFraud'] * 1.5\nprint(sub_7)\nsub_7.to_csv('submission.csv')\n\nsf1 = pd.read_csv('..\/input\/mysub18\/fe_test2.csv', index_col='TransactionID')\nsub_7 = sub_7.merge(sf1,on='TransactionID',how='left')\nsub_7['isFraud'] = sub_7.groupby('ukey')['isFraud'].transform('mean')\nsub_7[['isFraud']].to_csv('submission_proc.csv')","ccd9e9e4":"import numpy as np\n\ntrain_transaction = pd.read_csv('..\/input\/\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID')\n\n\n\ntrain_f5 = pd.read_csv('..\/input\/mysub18\/fi_train4.csv', index_col='TransactionID')\ntrain_transaction = train_transaction.merge(train_f5, how='left', left_index=True, right_index=True)\n#\ndebug = False\nif not debug:\n    test_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv', index_col='TransactionID')\n    test_f5 = pd.read_csv('..\/input\/mysub18\/fi_test4.csv', index_col='TransactionID')\n    test_transaction = test_transaction.merge(test_f5, how='left', left_index=True, right_index=True)\n    test_transaction['isFruad'] = 0.0\n\nsub = pd.read_csv('.\/submission.csv', index_col='TransactionID')\ntrain_transaction['pred'] = 0.0\ntest_transaction['pred'] = sub['isFraud']\n\n\nkey = 'card123456_add1_D15_series'\nkey2 = 'card123456_add1_D2_series'\nkey3 = 'card123456_add1_D11_series'\n\n\n\n\nif debug:\n    cache = train_transaction[[key,key2,key3,'isFraud','pred']].values\n    cache2 = train_transaction['pred'].values\nelse:\n    cache = train_transaction.append(test_transaction)[[key, key2,key3, 'isFraud','pred']].values\n    cache2 = train_transaction.append(test_transaction)['pred'].values\n","9ec717bf":"count00 = 0\ncount01 = 0\ncount10 = 0\ncount11 = 0\n\nukey_dict = {}\nukey2_dict = {}\nukey3_dict = {}\nif debug:\n    train_len = train_transaction.shape[0] * 4\/\/5\nelse:\n    train_len = train_transaction.shape[0]\n\npred_np = []\nfor i in range(cache.shape[0]):\n    ukey = cache[i,0]\n    ukey2 = cache[i, 1]\n    ukey3 = cache[i, 2]\n    isFraud = cache[i,3]\n    pred = cache[i,4]\n    ukey_dict[ukey] = ukey_dict.get(ukey,[])\n    ukey2_dict[ukey2] = ukey2_dict.get(ukey2, [])\n    ukey3_dict[ukey3] = ukey3_dict.get(ukey3, [])\n\n\n    res = cache2[i]\n\n    if i >= train_len and i < train_len + 800000:\n        pred = 0.5\n\n        offset = i - train_len\n\n        if int(np.sum(ukey_dict[ukey]) > 0.5 * len(ukey_dict[ukey])) + int(np.sum(ukey2_dict[ukey2]) > 0.5 * len(ukey2_dict[ukey2])) + int(np.sum(ukey3_dict[ukey3]) > 0.5 * len(ukey3_dict[ukey3])) >= 2:\n            # pred = 1\n            count01 +=1\n            res += 0.25\n        elif int(np.sum(ukey_dict[ukey]) > 0.5 * len(ukey_dict[ukey])) + int(np.sum(ukey2_dict[ukey2]) > 0.5 * len(ukey2_dict[ukey2])) + int(np.sum(ukey3_dict[ukey3]) > 0.5 * len(ukey3_dict[ukey3])) >= 1:\n            pred = 1\n            count10 += 1\n            res += 0.10\n\n        elif int(np.sum(ukey_dict[ukey]) < max(0,0.2 * len(ukey_dict[ukey]))) + int(np.sum(ukey2_dict[ukey2]) < 0.2 * max(0,len(ukey2_dict[ukey2]))) + int(np.sum(ukey3_dict[ukey3]) < 0.2 * max(0,len(ukey3_dict[ukey3]))) > 2:\n            pred = 0\n            count11 += 1\n            res *= 0.2\n\n        if debug:\n            if pred == 0 and isFraud == 0:\n                count00 +=1\n            elif pred == 0 and isFraud == 1:\n                count01 +=1\n            elif pred == 1 and isFraud == 0:\n                count10 +=1\n            elif pred == 1 and isFraud == 1:\n                count11 +=1\n\n    if debug:\n        pred_np.append(res)\n    elif i >= train_len:\n        pred_np.append(res)\n    if i >= train_len:\n        continue\n\n    ukey_dict[ukey].append(isFraud)\n    ukey2_dict[ukey2].append(isFraud)\n    ukey3_dict[ukey3].append(isFraud)\n\nprint(count00,count01,count10,count11)\nif debug:\n    train_transaction['pred'] = np.array(pred_np)\n    from sklearn.metrics import roc_auc_score\n    split_pos = train_transaction.shape[0]*4\/\/5\n    df = train_transaction.iloc[split_pos:,:].copy()\n    y_test = df['isFraud']\n    y_pred = df['pred']\n    print(roc_auc_score(y_test,y_pred))\nelse:\n    print(sub['isFraud'])\n    print( np.array(pred_np))\n    sub['isFraud'] = np.array(pred_np)\n    sub.to_csv('.\/sub_group_d2d15d11.csv')\n    ","d045d2c1":"# Summary\n\nI'll try to make a small summary for this blend baseline:\n\nStep: 0. EDA (missing kernel here, I'll post later)\n\n\nStep: 1. Minify Data \n> https:\/\/www.kaggle.com\/kyakovlev\/ieee-data-minification\n\n\nStep: 2. Make ground baseline with no fe:\n> https:\/\/www.kaggle.com\/kyakovlev\/ieee-ground-baseline and \n> https:\/\/www.kaggle.com\/kyakovlev\/ieee-ground-baseline-deeper-learning\n\n\nStep: 3. Make a small FE and see I you can understand data you have\n>  https:\/\/www.kaggle.com\/kyakovlev\/ieee-ground-baseline-make-amount-useful-again and\n>  https:\/\/www.kaggle.com\/kyakovlev\/ieee-gb-2-make-amount-useful-again\n\n\nStep: 4. Find good CV strategy \n>  https:\/\/www.kaggle.com\/kyakovlev\/ieee-cv-options\nand same with gap to compare results (gap in values is what we have in test set)\nhttps:\/\/www.kaggle.com\/kyakovlev\/ieee-cv-options-with-gap\n\nStep: 4(1). Groupkfold (by timeblocks) application\n> https:\/\/www.kaggle.com\/kyakovlev\/ieee-lgbm-with-groupkfold-cv\n\n\nStep: 5. Try different set of features\n>  https:\/\/www.kaggle.com\/kyakovlev\/ieee-experimental\n\n\nStep: 6. Make deeper FE (brute force option)\n> https:\/\/www.kaggle.com\/kyakovlev\/ieee-fe-with-some-eda\n\n\nStep: 7. Features selection (missing kernel here, I'll post later)\n\n\nStep: 8. Hyperopt (missing kernel here, I'll post later)\n\n\nStep: 9. Try other models (XGBoost, CatBoost, NN - missing kernel here, I'll post later)\n> CatBoost (with categorical transformations)  https:\/\/www.kaggle.com\/kyakovlev\/ieee-catboost-baseline-with-groupkfold-cv\n\nStep: 10. Try blending and stacking (missing kernel here, I'll post later)\n\n---\n\n(Utils)\n\nSome tricks that where used in fe kernel\n> https:\/\/www.kaggle.com\/kyakovlev\/ieee-small-tricks\n\nPart of EDA (Just few things)\n> https:\/\/www.kaggle.com\/kyakovlev\/ieee-check-noise and https:\/\/www.kaggle.com\/kyakovlev\/ieee-simple-eda\n\n---\n\nhttps:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/104142"}}