{"cell_type":{"4db55f73":"code","d06a5f78":"code","488009b4":"code","e6e83107":"code","3645a4a6":"code","f98cc62e":"code","f8e2be44":"code","a2818d89":"code","172e1b65":"code","777e87df":"code","bd5d1906":"code","dfb3ef39":"code","a363a968":"markdown","e49a2a80":"markdown","1876ef8d":"markdown","84c82112":"markdown","17c803c2":"markdown","0bfe27ee":"markdown","39b891bb":"markdown","5b5c127c":"markdown","baa208a7":"markdown"},"source":{"4db55f73":"import numpy as np\nimport pandas as pd\nimport gc\nimport tqdm\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport pickle\nimport random\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\n\nLOCAL = False","d06a5f78":"if LOCAL:\n    train_df = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/train.csv')\n    test_df = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/test.csv')\n    building = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/building_metadata.csv')\n    train_weather = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/weather_train.csv')\n    train_df = train_df.merge(building, on='building_id', how='left')\n    train_df = train_df.merge(train_weather, on=['site_id', 'timestamp'], how='left')\n    del train_weather\n    test_weather = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/weather_test.csv')\n    test_df = test_df.merge(building, on='building_id', how='left')\n    del building\n    test_df = test_df.merge(test_weather, on=['site_id', 'timestamp'], how='left')\n    del test_weather\n    gc.collect()\n\n    train_df[\"primary_use_cate\"]=float(np.nan)\n    test_df[\"primary_use_cate\"]=float(np.nan)\n    train_df[\"time_year\"]=float(np.nan)\n    train_df[\"time_month\"]=float(np.nan)\n    train_df[\"time_day\"]=float(np.nan)\n    train_df[\"time_hour\"]=float(np.nan)\n    test_df[\"time_year\"]=float(np.nan)\n    test_df[\"time_month\"]=float(np.nan)\n    test_df[\"time_day\"]=float(np.nan)\n    test_df[\"time_hour\"]=float(np.nan)\n\n    primary_use_cate = list(set(train_df[\"primary_use\"].values)|set(test_df[\"primary_use\"].values))\n    primary_use_label2int = {c:i for i,c in enumerate(primary_use_cate)}\n\n    for i in tqdm.tqdm(range(len(train_df))):\n        s = train_df.at[i,\"timestamp\"]\n        train_df.at[i,\"primary_use_cate\"] = primary_use_label2int[train_df.at[i,\"primary_use\"]]\n        train_df.at[i,\"time_year\"] = int(s[0:4])\n        train_df.at[i,\"time_month\"] = int(s[5:7])\n        train_df.at[i,\"time_day\"] = int(s[8:10])\n        train_df.at[i,\"time_hour\"] = int(s[11:13])\n    \n    for i in tqdm.tqdm(range(len(test_df))):\n        s = test_df.at[i,\"timestamp\"]\n        test_df.at[i,\"primary_use_cate\"] = primary_use_label2int[test_df.at[i,\"primary_use\"]]\n        test_df.at[i,\"time_year\"] = int(s[0:4])\n        test_df.at[i,\"time_month\"] = int(s[5:7])\n        test_df.at[i,\"time_day\"] = int(s[8:10])\n        test_df.at[i,\"time_hour\"] = int(s[11:13])","488009b4":"if not LOCAL:\n    train_df = pickle.load(open(\"\/kaggle\/input\/ashrae-preprocessed-data\/train.pickle\",\"rb\"))\n    test_df = pickle.load(open(\"\/kaggle\/input\/ashrae-preprocessed-data\/test.pickle\",\"rb\"))","e6e83107":"# from https:\/\/www.kaggle.com\/divrikwicky\/ashrae-lofo-feature-importance\n\ny_train = np.array(train_df[\"meter_reading\"])\ndel train_df['primary_use']\ndel train_df['meter_reading']\ndel train_df['year_built']\ndel train_df['floor_count']\ndel train_df['precip_depth_1_hr']\ndel train_df['wind_direction']\ndel train_df['sea_level_pressure']\ndel train_df['time_hour']\ndel train_df['timestamp']\n\ndel test_df['primary_use']\ndel test_df['row_id']\ndel test_df['year_built']\ndel test_df['floor_count']\ndel test_df['precip_depth_1_hr']\ndel test_df['wind_direction']\ndel test_df['sea_level_pressure']\ndel test_df['time_hour']\ndel test_df['timestamp']\n\nX_train = train_df\nX_test = test_df","3645a4a6":"data=[0 for i in range(200)]\ndata_ori=[0 for i in range(21904701)]\nfor p in tqdm.tqdm(y_train):\n    data[int(np.log(p+1)*10)]+=1\n    data_ori[int(p)]+=1","f98cc62e":"plt.plot([i for i in range(21904701)],data_ori)","f8e2be44":"plt.plot([i for i in range(200)],data)","a2818d89":"y_train = np.log(y_train+1)","172e1b65":"gc.collect()\nfolds = 3\nseed = 222\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_valid_pred = np.zeros(X_train.shape[0])\nmodels = []\n\nfor tr_idx, val_idx in kf.split(X_train, y_train):\n    tr_x, tr_y = X_train.iloc[tr_idx,:], y_train[tr_idx]\n    vl_x, vl_y = X_train.iloc[val_idx,:], y_train[val_idx]\n            \n    print(len(tr_x),len(vl_x))\n    tr_data = lgb.Dataset(tr_x, label=tr_y)\n    vl_data = lgb.Dataset(vl_x, label=vl_y)  \n    clf = lgb.LGBMRegressor(n_estimators=200,learning_rate=0.5,feature_fraction=0.9,\n            bagging_fraction=0.9,early_stopping_rounds=50)\n    clf.fit(tr_x, tr_y,\n        eval_set=[(vl_x, vl_y)],\n        verbose=True)\n    y_valid_pred[val_idx] += clf.predict(vl_x, num_iteration=clf.best_iteration_)\n    models.append(clf)\n    gc.collect()","777e87df":"print(\"valid score is\",np.sqrt(sum(np.power(y_train-np.clip(y_valid_pred,0,None),2))\/y_train.shape[0]))","bd5d1906":"res=np.zeros(41697600,dtype=float)\nfor i in tqdm.tqdm(range(0,41697600,27200)):\n    res[i:i+27200] = sum([np.clip(np.exp(model.predict(X_test.iloc[i:i+27200]))-1,0,None) for model in models])\/folds","dfb3ef39":"submission = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/sample_submission.csv')\nsubmission['meter_reading'] = res\nsubmission.to_csv('submission.csv', index=False)\nsubmission","a363a968":"# make submission\nI need to do the opposite of what was done in preprocessing.","e49a2a80":"# evaluation\nSince the minimum value is 0, it was clipped to do so.","1876ef8d":"There is a way to reduce memory, and using it does not seem to require this effort to save memory for https:\/\/www.kaggle.com\/hamditarek\/reducing-memory-size-for-great-energy-predictor.<br>\nPlease let me know if you have any opinions or advice.","84c82112":"As you can see, it is difficult to predict because of the wide distribution range.","17c803c2":"# preprocessing\nI created the data to be used this time with the following code, but this time it is running in a local environment because it takes more than 2 hours.","0bfe27ee":"So I decided to take the logarithm.","39b891bb":"# train\nI think it's intuitive to use a regression algorithm in this competition.","5b5c127c":"The elements that seem to contribute little was removed due to memory constraints.","baa208a7":"# import"}}