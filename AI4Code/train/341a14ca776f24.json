{"cell_type":{"8e3ee6af":"code","d50cf592":"code","e6f09637":"code","aed4097e":"code","5f53442d":"code","65b3873c":"code","0344ae6c":"code","71baeb51":"code","7b20f58e":"code","fd571069":"code","6b9aa558":"code","3ab717c8":"markdown","e9b6bc5f":"markdown","da95e6a7":"markdown","a9494923":"markdown","3b29e78a":"markdown","86e37b40":"markdown"},"source":{"8e3ee6af":"%%time\n# INSTALL RAPIDS OFFLINE (FROM KAGGLE DATASET). TAKES 1 MINUTE :-)\nimport sys\n!cp ..\/input\/rapids\/rapids.0.11.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","d50cf592":"# INSTALL RAPIDS ONLINE (WITH CONDA). TAKES 6 MINUTES :-(\n#import sys\n#!conda create -n rapids -c rapidsai\/label\/xgboost -c rapidsai -c nvidia -c conda-forge rapids=0.11 python=3.6 cudatoolkit=10.1 --yes\n#sys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\n#!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","e6f09637":"# LOAD LIBRARIES\nimport cudf, cuml\nimport pandas as pd, numpy as np, os\nfrom cuml.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nprint('cuML version',cuml.__version__)","aed4097e":"# LOAD TRAIN DATA\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv').values\n#train = np.array( cudf.read_csv('..\/input\/digit-recognizer\/train.csv').to_gpu_matrix() )\nprint('Original train shape =', train.shape )","5f53442d":"stderr = sys.stderr; sys.stderr = open(os.devnull, 'w')\nfrom keras.preprocessing.image import ImageDataGenerator; sys.stderr = stderr\n# PREVIEW AUGMENTED IMAGES\ndatagen = ImageDataGenerator(rotation_range=10, zoom_range = 0.10, width_shift_range=0.1, height_shift_range=0.1)\ndigit = train[21,1:].reshape((1,28,28,1))\nplt.figure(figsize=(15,5.5))\nfor i in range(24):  \n    plt.subplot(3, 8, i+1)\n    new_digit = datagen.flow(digit).next()\n    plt.imshow(new_digit[0].reshape((28,28)),cmap=plt.cm.binary)\n    if i==0: plt.title('Original')\n    elif i<8: plt.title('Augmented')\n    plt.xticks([], []); plt.yticks([], [])\n    if i==7: digit = train[22,1:].reshape((1,28,28,1))\n    if i==15: digit = train[25,1:].reshape((1,28,28,1))\nplt.subplots_adjust(wspace=-0.1, hspace=0.1)\nplt.show()","65b3873c":"%%time\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rotation_range=10, zoom_range = 0.10, width_shift_range=0.1, height_shift_range=0.1)\nda = 50; bs=4200\ntrain2 = np.zeros((train.shape[0]*da,train.shape[1]),dtype=np.float32)\nfor k,(X,Y) in enumerate( datagen.flow( train[:,1:].reshape((-1,28,28,1)), train[:,0].reshape((-1,1)) ,batch_size=bs ) ):\n    train2[bs*k:bs*(k+1),1:] = X.reshape((-1,784))\n    train2[bs*k:bs*(k+1),0] = Y.reshape((-1))\n    if k%10==0: print(k\/\/10,', ',end='')\n    if k==train2.shape[0]\/\/bs-1: break\nprint(); print('New train shape =', train2.shape )","0344ae6c":"# LOAD TEST DATA\ntest = cudf.read_csv('..\/input\/digit-recognizer\/test.csv')\nprint('test shape =', test.shape )","71baeb51":"%%time\n# CONVERT NumPy array to cuDF array\ntrain3 = cudf.from_pandas( pd.DataFrame(train2) )\n# train3 = cudf.DataFrame.from_gpu_matrix(cupy.asarray(train2))","7b20f58e":"%%time\n# FIT KNN MODEL\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit( train3.iloc[:,1:], train3.iloc[:,0] )\n# We can train directly from NumPy array but cuML v0.11.0 has bug\n# knn.fit(train2[:,1:], train2[:,0])","fd571069":"%%time\n# PREDICT TEST DATA\ny_hat_p = knn.predict_proba(test)\ny_hat = y_hat_p.to_pandas().values.argmax(axis=1)\n# We could use knn.predict() but cuML v0.11.0 has bug\n# y_hat = knn.predict(test)","6b9aa558":"# SAVE PREDICTIONS TO CSV\nsub = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsub.Label = y_hat\nsub.to_csv('submission_cuML_DAx50.csv',index=False)\nsub.head()","3ab717c8":"# Install Nvidia RAPIDS in 1 minute\nNvidia RAPIDS is described [here][1]. The RAPIDS library allows us to perform all our data science on GPUs. The library cuDF provides Pandas functionality on GPU, and cuML provides Scikit-learn functionality on GPU. \n\nIn Kaggle notebooks, we can either install RAPIDS from a local Kaggle dataset [here][2], or install RAPIDS from its online source using Conda. Local takes 1 minute and Conda takes 6 minutes. If the local install doesn't work or we want a more recent version of RAPIDS, we should install with Conda, otherwise local is the fast choice.\n\n[1]: https:\/\/rapids.ai\/\n[2]: https:\/\/www.kaggle.com\/cdeotte\/rapids","e9b6bc5f":"# Data Augmentation - 2 Million Images!\nIf we rotate the image of a digit, it is still the same digit. Likewise if we shift or scale an image, it is the same digit. We would like our model to learn this, so will will create 2 million additional training data images where we randomly rotate, shift, and scale the original training images.\n  \nWe will use [`keras.preprocessing.image.ImageDataGenerator()`][1] to augment our data. This function uses CPU and isn't very fast. If we want more speed, we could write our own augmentation function on GPU or use an existing GPU augmentation package. Since rotation, shift, and scaling are all matrix computations we would see a huge speed increase on GPU (600x or more). \n  \n[1]: https:\/\/keras.io\/preprocessing\/image\/","da95e6a7":"# RESULT without Data Augmentation\nIn our last notebook without data augmentation, we achieved an accuracy of 96.9%:\n  \n![1-24-20-cuML.png](attachment:1-24-20-cuML.png)","a9494923":"# Predict Test\nIn our previous notebook we witnessed GPU RAPIDS kNN infer the entire Kaggle test dataset of 28,000 images against a training set of 48,000 images in an incredible 2.5 seconds. Below we witness GPU RAPIDS kNN infer the entire Kaggle test dataset of 28,000 images against an augmented training set of 2,400,000 images in an incredible 14.5 seconds. That's an amazing 131.7 trillion multiplies, additions, and subtractions in only 14.5 seconds! Unbelieveable!","3b29e78a":"# RESULT with Data Augmentation\nIn this notebook with data augmentation, we achieve an accuracy of 98.5%. If we create more augmented data and\/or create non-linear augmentations, we can achieve accuracy over 99%. Additionally, one can scale columns of the dataset to prioritize certain regions of pixels and increase accuracy further! Or one can ensemble multiple models created with bagging. Because RAPIDS cuML is so fast, we can do kNN plus additional tasks and achieve state of the art accuracies!\n\n![cuML_DAx50.png](attachment:cuML_DAx50.png)","86e37b40":"# RAPIDS - Do More in Less Time - kNN - MNIST - [0.985]\nIn our previous kernel [here][1], we saw that RAPIDS cuML's kNN algorithm could predict all the test images in Kaggle's Digit-Recognizer competition in an incredible 2.5 seconds (compared to Scikit-learn's 25 minutes). Since RAPIDS cuML is so fast, we can use this speed advantage to increase our model's accuracy by doing additional tasks. Some ways to increase model accuracy are:\n* Feature Engineering and Selection\n* Hyperparameter Search\n* Data Augmentation\n* Ensembling with Bagging and Boosting\n  \nIn this kernel, we will apply Data Augmentation to generate more training data and increase model accuracy.\n\n[1]: https:\/\/www.kaggle.com\/cdeotte\/rapids-gpu-knn-mnist-0-97"}}