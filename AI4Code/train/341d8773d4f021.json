{"cell_type":{"822187ad":"code","2d5854e2":"code","515086aa":"code","31cdd7af":"code","9cf857d9":"code","29034f99":"code","fd7fa6ac":"code","43ebbbdf":"code","16be8fbe":"code","1635d74d":"code","399d6298":"code","7e0cfdbd":"markdown","a377857e":"markdown","d1782499":"markdown","4239cca7":"markdown"},"source":{"822187ad":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF","2d5854e2":"ROOT = '..\/input\/aclimdb-v1\/aclImdb\/train\/pos'","515086aa":"reviews = []\n\nfor file in os.listdir(ROOT):\n    path = os.path.join(ROOT, file)\n    if os.path.isfile(path):\n        with open(path, 'r') as fin:\n            reviews.append(fin.read())","31cdd7af":"len(reviews)","9cf857d9":"for i in range(3):\n    print(reviews[i])\n    print(\"=\" * 150)","29034f99":"vect = TfidfVectorizer(stop_words=\"english\")\nX = vect.fit_transform(reviews)\n\npd.DataFrame(X.toarray(), columns=vect.get_feature_names())","fd7fa6ac":"N_TOPICS = 15\nnmf = NMF(n_components=N_TOPICS)\nW = nmf.fit_transform(X) # Document-topic matrix\nH = nmf.components_      # Topic-term matrix","43ebbbdf":"# Top 10 words per topic\nwords = np.array(vect.get_feature_names())\ntopic_words = pd.DataFrame(np.zeros((N_TOPICS, 10)), index = [f'Topic {i + 1}' for i in range(N_TOPICS)], \n                           columns = [f'Word {i + 1}' for i in range(10)]).astype(str)\n\nfor i in range(N_TOPICS):\n    ix = H[i].argsort()[::-1][:10]\n    topic_words.iloc[i] = words[ix]\n    \ntopic_words","16be8fbe":"# Create a topic mapping\ntopic_mapping = {\n    'Topic 4': 'TV',\n    'Topic 7': 'War',\n    'Topic 8': 'Comedy',\n    'Topic 12': 'Book Adaptation',\n    'Topic 13': 'Horror'\n}","1635d74d":"# Recall the document-topic matrix, W\nW = pd.DataFrame(W, columns=[f'Topic {i + 1}' for i in range(N_TOPICS)])\nW['max_topic'] = W.apply(lambda x: topic_mapping.get(x.idxmax()), axis=1)\nW[pd.notnull(W['max_topic'])].head(10)","399d6298":"reviews[33]","7e0cfdbd":"## Exploring the Dataset","a377857e":"## Feature Extraction","d1782499":"## Importing Libraries","4239cca7":"## NMF Decomposition"}}