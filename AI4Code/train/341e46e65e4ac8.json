{"cell_type":{"395c88e3":"code","438e0b42":"code","581c6970":"code","528f7f7e":"code","d62be4bf":"code","0f91985d":"code","63364e3a":"code","5c6be67a":"code","95266456":"code","442c76de":"code","e7bca405":"code","0a3ca0e1":"code","e32aa7fa":"code","e04cca1b":"code","f2332032":"code","1e050474":"code","50b3889f":"markdown","f800bdc6":"markdown","c12aaeaa":"markdown","80a77117":"markdown","26c0082c":"markdown","d362de5f":"markdown","a8bfc5fe":"markdown","8eefdb42":"markdown","71fe08de":"markdown"},"source":{"395c88e3":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom collections import Counter\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nfrom spacy.lang.hi import Hindi, STOP_WORDS as hindi_stopwords\nfrom spacy.lang.ta import Tamil, STOP_WORDS as tamil_stopwords","438e0b42":"train_df = pd.read_csv('..\/input\/chaii-hindi-and-tamil-question-answering\/train.csv')","581c6970":"train_df.head()","528f7f7e":"train_df.info()","d62be4bf":"sns.displot(data=train_df,x='language', color='orange')","0f91985d":"chars_per_ques = train_df['question'].str.len()\nchars_per_ques.describe()","63364e3a":"chars_per_ans = train_df['answer_text'].str.len()\nchars_per_ans.describe()","5c6be67a":"sns.displot(data=train_df,x=train_df['question'].str.len())","95266456":"sns.displot(data=train_df,x=chars_per_ans, color='green')","442c76de":"sns.boxplot(data=chars_per_ans)","e7bca405":"# Download and extract the fonts\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Devanagari.zip\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Tamil.zip\n\n!unzip -qq Devanagari.zip\n!unzip -qq Tamil.zip","0a3ca0e1":"# Get the text for both the languages\ntamil_text = \" \".join(train_df[train_df[\"language\"]==\"tamil\"][\"question\"])\nhindi_text = \" \".join(train_df[train_df[\"language\"]==\"hindi\"][\"question\"])","e32aa7fa":"# Get the tokens and frequencies for Hindi language\n\nhindi_nlp = Hindi()\nhindi_doc = hindi_nlp(hindi_text)\nhindi_tokens = set([token.text for token in hindi_doc])\nhindi_tokens_counter = Counter(hindi_tokens)\n\n\n# Get the tokens and frequencies for Tamil language\ntamil_nlp = Tamil()\ntamil_doc = hindi_nlp(tamil_text)\ntamil_tokens = set([token.text for token in tamil_doc])\ntamil_tokens_counter = Counter(tamil_tokens)","e04cca1b":"def plot_wordcloud(\n    font_path,\n    frequencies,\n    stopwords,\n    background_color=\"white\",\n    collocations=True,\n    min_font_size=8,\n):\n    \"\"\"Generates wordcloud from word frequencies.\"\"\"\n    \n    wordcloud = WordCloud(font_path=font_path,\n                      width=400,\n                      height=400,\n                      background_color=background_color,\n                      stopwords=stopwords,\n                      collocations=collocations,\n                      min_font_size=min_font_size).generate_from_frequencies(frequencies)\n\n    \n    plt.figure(figsize=(10, 10))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.show()","f2332032":"# Plot the wordcloud for hindi langauge\nplot_wordcloud(font_path=\"Devanagari\/Lohit-Devanagari.ttf\",\n               frequencies=hindi_tokens_counter,\n               stopwords=hindi_stopwords\n              )","1e050474":"# Plot the wordcloud for tamil language\nplot_wordcloud(font_path=\"Tamil\/Lohit-Tamil.ttf\",\n               frequencies=tamil_tokens_counter,\n               stopwords=tamil_stopwords\n              )","50b3889f":"# Length of Questions & Answers","f800bdc6":"## Some Issues\n* As pointed out by some members in [this discussion thread](https:\/\/www.kaggle.com\/c\/chaii-hindi-and-tamil-question-answering\/discussion\/264395) , there are some noisy labels in the training data. Although the competition host has assured that in the test set each instance is 3-way annotated (unlike the 1-way annotated train data) so that is very unlikely to have such issues.","c12aaeaa":"## Contents:\n* [Competition Objective](#Competition-Objective)\n* [Length of Questions & Answers](#Length-of-Questions-&-Answers)\n* [Wordcloud](#Wordcloud)\n* [Additional Public Datasets](#Additional-Public-datasets)\n* [Other Useful Resources](#Good-Additional-Resources)","80a77117":"# Good Additional Resources\n* Official Starter Notebook: https:\/\/www.kaggle.com\/deeplearning10\/chaii-1-starter-notebook\n* AI4Bharat IndicNLP [homepage](https:\/\/indicnlp.ai4bharat.org\/home\/) , project led by volunteers from IIT Madras and other organizations\n* pre-trained language models - [IndicBERT](https:\/\/indicnlp.ai4bharat.org\/indic-bert\/)\n* [Multilingual Transfer Learning for QA Using Translation as Data Augmentation](https:\/\/arxiv.org\/pdf\/2012.05958.pdf)","26c0082c":"# Wordcloud\nThanks to [NAIN's notebook](https:\/\/www.kaggle.com\/aakashnain\/chaii-explore-the-data) for these good wordclouds","d362de5f":"Box Plot of answer length (in number of characters)","a8bfc5fe":"As we can see, the average length of the answers is much shorter- less than one third of the average question length. Although there are a few very long answers with the longest answer being 286 characters long.","8eefdb42":"# Competition Objective\nPopular Natural Language Understanding (NLU) models perform worse with Indian languages compared to English, the effects of which lead to subpar experiences in downstream web applications for Indian users. \nWe are given questions in Tamil & Hindi about some Wikipedia articles, and we have to get the answers for those questions from the articles.\n\n## Important Points\n* The answers are drawn directly from a limited context. So no rephrasing etc. is to be done.\n* **context** is the text (the Wikipedia article) of the Hindi\/Tamil sample from which answers should be derived\n* The evaluation metric in this competition is the word-level **Jaccard score** (As described in the [evaluation tab](https:\/\/www.kaggle.com\/c\/chaii-hindi-and-tamil-question-answering\/overview\/evaluation) )","71fe08de":"# Additional Public datasets\nAs the training data size in the given dataset is quite small, we are encouraged by the hosts to share and use more public data sources. Following are some of the data sources that have been shared by other members so far:\n* [Samanantar](https:\/\/indicnlp.ai4bharat.org\/samanantar\/#en-indic)\n* [Facebook Multilingual QA datasets](https:\/\/github.com\/facebookresearch\/MLQA)\n* [Hindi Wikipedia Articles - 172k](https:\/\/www.kaggle.com\/disisbig\/hindi-wikipedia-articles-172k)\n\nThe main discussion thread for sharing datasets is:\nhttps:\/\/www.kaggle.com\/c\/chaii-hindi-and-tamil-question-answering\/discussion\/264581"}}