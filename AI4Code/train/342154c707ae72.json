{"cell_type":{"36e00104":"code","8c8811e6":"code","c2d0b857":"code","38164174":"code","0b865854":"code","ee261be9":"code","f226ef66":"code","61262f10":"code","fcd0bfe2":"code","b7dcaeb0":"code","037c6346":"code","5d0d263c":"code","dd7ebaf9":"code","476b5dbc":"code","eb8dbc64":"code","0d586719":"code","13f62fc8":"code","bce26925":"code","ea004596":"code","4b5588cb":"code","c0a0b4f2":"code","b832fad5":"code","cdd0b004":"code","485ccf44":"code","5769768f":"code","e7dd57b5":"code","3dbd70a8":"code","fb58a543":"code","a51549ef":"code","6a637175":"code","e72fa36e":"code","c281f18e":"code","371ee8b0":"code","70fc7356":"code","0739b12a":"code","dfa000d3":"code","8bb593d1":"code","1653eb1b":"code","4d5fa532":"code","e1ee7ac7":"code","c188dcdc":"code","63ae0099":"code","6e62bee8":"code","4e6c7253":"code","d4ddf1e1":"code","569d7d49":"code","a8c2f3b7":"code","9653fd79":"code","802add02":"markdown","e262e45c":"markdown","a8912e2f":"markdown","6af554e3":"markdown","684f53e7":"markdown","05652b5c":"markdown","22bf348d":"markdown","04c8a624":"markdown","ca294cc7":"markdown","5263d3f2":"markdown","f50876c3":"markdown","c6821bb6":"markdown","f0d85756":"markdown","7b0afea4":"markdown","be1ab989":"markdown","72ae123d":"markdown","3595e0e7":"markdown","9dea0ec4":"markdown","7f341f58":"markdown","40907bfa":"markdown","d8a58dd7":"markdown","1791c736":"markdown","a20f7222":"markdown","d15622f8":"markdown","c79af505":"markdown","9cb04940":"markdown","cbce7096":"markdown","14485994":"markdown","fde106ac":"markdown","34d2fbb3":"markdown","efd528af":"markdown","f83be62d":"markdown","60cb415c":"markdown","29e5b990":"markdown","86bbcc64":"markdown","27d724f3":"markdown","d1d09dc8":"markdown","659d783a":"markdown","cc4a5e8b":"markdown","75b446c6":"markdown","5024bdc3":"markdown","1011d85b":"markdown","1e24338b":"markdown","c6638f35":"markdown","ce28f804":"markdown"},"source":{"36e00104":"# from google.colab import drive\n# drive.mount('\/content\/drive')","8c8811e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    print(dirname)\n    #for filename in filenames:\n    #   print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2d0b857":"#Reading the training images from the path and labelling them into the given categories\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport seaborn as sns # for data visualization \nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.models import Sequential #sequential api for sequential model \nfrom tensorflow.keras.layers import Dense, Dropout, Flatten #importing different layers \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Input, LeakyReLU,Activation\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical #to perform one-hot encoding \nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam,RMSprop #optimiers for optimizing the model\n#from keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping  #regularization method to prevent the overfitting\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import losses, optimizers\n","38164174":"DATADIR = r\"\/kaggle\/input\/greatlearning-aimlmaycohort\/Data Set Brain Tumor\/Data Set Brain Tumor\/Training\"\nCATEGORIES = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]\n\n#Storing all the training images\ntraining_data = []\n\ndef create_training_data():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR,category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)# Converting image to greyscale to reduce the complexity and computation \n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n                training_data.append([new_array,class_num])\n            except Exception as e:\n                pass","0b865854":"create_training_data()","ee261be9":"\nDATADIR = r\"\/kaggle\/input\/greatlearning-aimlmaycohort\/Data Set Brain Tumor\/Data Set Brain Tumor\/Testing\"\nCATEGORIES = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]\n\n#Storing all the training images\ntesting_data = []\n\ndef create_testing_data():\n    for category in CATEGORIES:\n        path = os.path.join(DATADIR,category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)# Converting image to greyscale to reduce the complexity and computation \n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n                testing_data.append([new_array,class_num])\n            except Exception as e:\n                pass","f226ef66":"create_testing_data()","61262f10":"# Separating the images and labels\nX_train = []\ny_train = []\nnp.random.shuffle(training_data)\nfor features,label in training_data:\n    X_train.append(features)\n    y_train.append(label)\nX_train= np.array(X_train)\nprint(X_train.shape)\n\n# Normalizing pixel values  \nX_train = X_train\/255.0  \n# image reshaping \nX_train = X_train.reshape(-1,150,150,1)","fcd0bfe2":"X_test = []\ny_test = []\n\nnp.random.shuffle(testing_data)\nIMG_SIZE = 150\nfor features,label in testing_data:\n    X_test.append(features)\n    y_test.append(label)\nX_test = np.array(X_test).reshape(-1,IMG_SIZE,IMG_SIZE)\nprint(X_test.shape)\nX_test = X_test\/255.0  \nX_test = X_test.reshape(-1,150,150,1)","b7dcaeb0":"#creating the dataframe to plot the pie chart\ndf=pd.DataFrame(y_train,columns=['Suffering'])","037c6346":"#plotting the pie chart \nlabels = 'Tumor', 'Non_Tumor'\nsizes = [df.Suffering[df['Suffering']!=0].count(), df.Suffering[df['Suffering']==0].count()]\nexplode = (0, 0.1)\nfig1, ax1 = plt.subplots(figsize=(10, 8))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',normalize=None,\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Proportion of tumor and non tumor patients \", size = 20)\nplt.show()","5d0d263c":"#train_dir = 'DATA\/train' # image folder\nimport os\n# get the list of jpegs from sub image class folders\nglioma_tumor_imgs = [fn for fn in os.listdir(f'{DATADIR}\/{CATEGORIES[0]}') ]\nmeningioma_tumor_imgs = [fn for fn in os.listdir(f'{DATADIR}\/{CATEGORIES[1]}') ]\nno_tumor_imgs = [fn for fn in os.listdir(f'{DATADIR}\/{CATEGORIES[2]}') ]\npituitary_tumor_imgs = [fn for fn in os.listdir(f'{DATADIR}\/{CATEGORIES[3]}') ]\n\n# randomly select 3 of each\nselect_gal = np.random.choice(glioma_tumor_imgs, 3, replace = False)\nselect_menin = np.random.choice(meningioma_tumor_imgs, 3, replace = False)\nselect_no_t = np.random.choice(no_tumor_imgs, 3, replace = False)\nselect_pit = np.random.choice(pituitary_tumor_imgs, 3, replace = False)\n","dd7ebaf9":"from keras.preprocessing import image\n# plotting 2 x 3 image matrix\nfig = plt.figure(figsize = (10,10))\nfor i in range(12):\n    if i < 3:\n        fp = f'{DATADIR}\/{CATEGORIES[0]}\/{select_gal[i]}'\n        label = 'Galioma Tumor'\n    if i>=3 and i<6:\n        fp = f'{DATADIR}\/{CATEGORIES[1]}\/{select_menin[i-3]}'\n        label = 'Meningioma Tumor' \n    if i>=6 and i<9:\n        fp = f'{DATADIR}\/{CATEGORIES[2]}\/{select_no_t[i-6]}'\n        label = 'No Tumor'\n    if i>=9 and i<12:\n        fp = f'{DATADIR}\/{CATEGORIES[3]}\/{select_pit[i-9]}'\n        label = 'Pituitary Tumor'\n    ax = fig.add_subplot(4, 3, i+1)\n    \n    # to plot without rescaling, remove target_size\n    fn = image.load_img(fp, target_size = (150,150), color_mode='grayscale')\n    plt.imshow(fn, cmap='Greys_r')\n    plt.title(label)\n    plt.axis('off')\nplt.show()\n\n# also check the number of files here","476b5dbc":"def find_mean_img(full_mat, title):\n    # calculate the average\n    mean_img = np.mean(full_mat, axis = 0)\n    # reshape it back to a matrix\n    mean_img = mean_img.reshape((150,150))\n    plt.imshow(mean_img, vmin=0, vmax=255, cmap='Greys_r')\n    plt.title(f'Average {title}')\n    plt.axis('off')\n    plt.show()\n    return mean_img\n\ngalioma_data=[]\nmenin_data=[]\n               \nno_tumor_data=[]\n               \npitu_data=[]\n\nfor cat in CATEGORIES:\n        path = os.path.join(DATADIR,cat)\n        for img in os.listdir(path):\n                \n                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)# Converting image to greyscale to reduce the complexity and computation \n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n                if cat==CATEGORIES[0]:\n                      galioma_data.append([new_array])\n                if cat==CATEGORIES[1]:\n                      menin_data.append([new_array])\n                if cat==CATEGORIES[2]:\n                      no_tumor_data.append([new_array])\n                if cat==CATEGORIES[3]:\n                      pitu_data.append([new_array])\n\n                \n\nnorm_mean = find_mean_img(np.array(no_tumor_data), 'No Tumor')\ngali_mean = find_mean_img(np.array(galioma_data), 'Galioma Tumor')\nmenin_mean = find_mean_img(np.array(menin_data), 'Meningioma Tumor')\nPitu_mean = find_mean_img(np.array(pitu_data), 'Pituitary Tumor')\n","eb8dbc64":"fig = plt.figure(figsize = (8,6))\n\nfor i in enumerate([gali_mean,menin_mean,Pitu_mean]):\n       \n    contrast_mean = norm_mean - i[1]\n    plt.imshow(contrast_mean, cmap='bwr')\n    if i[0]==0:\n        plt.title(f'Difference Between Non Tumor & Galioma Average')\n    if i[0]==1:\n        plt.title(f'Difference Between Non Tumor & Meningioma Average')\n    if i[0]==2:\n        plt.title(f'Difference Between Non Tumor & Pituitary Average')\n    plt.axis('off')\n    plt.show()","0d586719":"encoded = to_categorical(np.array(y_train))\ny_train_e=encoded\nencoded_test = to_categorical(np.array(y_test))\ny_test_e=encoded_test","13f62fc8":"print(y_train_e.shape)\nprint(y_test_e.shape)","bce26925":"#Build the model\n# 3 layers, 1 layer to flatten the image to a 28 x 28 = 784 vector\n#           1 layer with 128 neurons and relu function\n#           1 layer with 10 neurons and softmax function\n#Create the neural network model\ndef create_model(): \n        model_ann = keras.Sequential([\n            keras.layers.Flatten(input_shape=(150,150)),\n            keras.layers.Dense(500,kernel_initializer='he_uniform', activation=tf.nn.relu),\n            keras.layers.Dense(700,kernel_initializer='he_uniform', activation=tf.nn.relu),\n            keras.layers.Dense(4, kernel_initializer='random_uniform',activation=tf.nn.softmax)\n        ])\n        #Compile the model\n        #The loss function measures how well the model did on training , and then tries \n        #to improve on it using the optimizer\n        model_ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n        return model_ann","ea004596":"model_ann=create_model()\nmodel_ann.summary()","4b5588cb":"#Train the model\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\nhistory=model_ann.fit(X_train, \n          y_train_e,  #It expects integers because of the sparse_categorical_crossentropy loss function\n          epochs=200, #number of iterations over the entire dataset to train on\n          batch_size=64,validation_split=0.20,callbacks=[es, mc],use_multiprocessing=True)#number of samples per gradient update for training","c0a0b4f2":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","b832fad5":"import numpy\nmodel_ann.evaluate(X_test,y_test_e)","cdd0b004":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\nmodel = Sequential()\n#\ny_train=np.array(y_train)\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (150,150,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n#\nmodel.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n\n#\nmodel.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n\n# \nmodel.add(Flatten())\nmodel.add(Dense(1024, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4, activation = \"softmax\"))\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nepochs = 200  \nbatch_size = 64\n\n\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n\nhistory=model.fit(X_train, \n          y_train_e,  #It expects integers because of the sparse_categorical_crossentropy loss function\n          epochs=30, #number of iterations over the entire dataset to train on\n          batch_size=64,validation_split=0.20,callbacks=[es, mc],use_multiprocessing=True)#number of samples per gradient update for training  \n\n","485ccf44":"model.evaluate(X_test,np.array(y_test_e))","5769768f":"class conv_Layers:\n\n  def __init__(self, nfilters, kernel_size, stride=1, \n               pool_size=2, leakyrelu_slope=0.1, dropc=0.0, bnorm=False):\n    self.nfilters = nfilters\n    self.kernel_size = kernel_size\n    self.stride = stride\n    self.pool_size = pool_size\n    self.leakyrelu_slope = leakyrelu_slope\n    self.dropfrac = dropc\n    self.bnorm = bnorm\n  \n  def __call__(self, x):\n    x = Conv2D(self.nfilters, kernel_size=self.kernel_size, \n               strides=self.stride, padding='same')(x)\n    x = LeakyReLU(self.leakyrelu_slope)(x)\n    if (self.dropfrac > 0.0): \n      x = Dropout(self.dropfrac)(x)\n    if (self.bnorm):\n      x = BatchNormalization()(x)\n    x = MaxPool2D(self.pool_size)(x)\n    return x\n\nclass dense_Layers:\n\n  def __init__(self, nunits, leakyrelu_slope=0.1, dropd=0.0, bnorm=False):\n    self.nunits = nunits\n    self.leakyrelu_slope = leakyrelu_slope \n    self.dropfrac = dropd\n    self.bnorm = bnorm\n\n  def __call__(self, x):\n    x = Dense(self.nunits)(x)\n    x = LeakyReLU(self.leakyrelu_slope)(x)\n    if (self.dropfrac > 0.0):\n      x = Dropout(self.dropfrac)(x)\n    if (self.bnorm):\n      x = BatchNormalization()(x)\n    return x\n\ndef LNmodel(in_shape, conv_filters, dense_filters, kernel_size, num_classes, lr,\n            stride=1, pool_size=2, leakyrelu_slope=0.1, dropc=0.0, dropd=0.0, bnorm=False):\n\n  in_shape = X_train.shape[1:]\n  i = Input(shape=in_shape)\n  for ncl, nconvfilters in enumerate(conv_filters):\n    if (ncl==0):\n      x = conv_Layers(nconvfilters, kernel_size,\n                      stride, pool_size, leakyrelu_slope, dropc, bnorm)(i)\n    else:\n      x = conv_Layers(nconvfilters, kernel_size,\n                      stride, pool_size, leakyrelu_slope, dropc, bnorm)(x)\n\n  x = Flatten()(x)\n\n  for ndl, ndunits in enumerate(dense_filters):\n    x = dense_Layers(ndunits, leakyrelu_slope, dropd, bnorm)(x)\n\n  x = Dense(num_classes, activation='softmax')(x)\n\n  ln_model  = Model(inputs=i, outputs=x)\n  adam = optimizers.Adam(lr=lr)\n  ln_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n  return ln_model","e7dd57b5":"lr = 0.001\nkernelsize = 5\nin_shape= X_train.shape[1:]\nmodel_ln3 = LNmodel(in_shape, [8,16], [16,8], kernelsize, 4, lr,\n                    stride=1, pool_size=2, leakyrelu_slope=0.1, dropc=0.25,\n                    dropd=0.5, bnorm=False)\nmodel_ln3.summary()\n","3dbd70a8":"\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n\nhistory_model_ln3 = model_ln3.fit(X_train, y_train_e, \n                                  validation_split=0.1,\n                                  verbose=1, batch_size=256,\n                                  shuffle=True, epochs=60,callbacks=[es,mc])","fb58a543":"lr = 0.001\nkernelsize = 5\nmodel_ln4 = LNmodel(in_shape, [8,16], [512,256], kernelsize, 4, lr,\n                    stride=1, pool_size=2, leakyrelu_slope=0.1, dropc=0.25,\n                    dropd=0.5, bnorm=False)\nmodel_ln4.summary()","a51549ef":"\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n\nhistory_model_ln4 = model_ln4.fit(X_train, y_train_e, \n                                  validation_split=0.1,\n                                  verbose=1, batch_size=512, \n                                  shuffle=True, epochs=40,callbacks=[es,mc])","6a637175":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","e72fa36e":"print(history_model_ln3.history.keys())\n# summarize history for accuracy\nplt.plot(history_model_ln3.history['accuracy'])\nplt.plot(history_model_ln3.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","c281f18e":"print(history_model_ln4.history.keys())\n# summarize history for accuracy\nplt.plot(history_model_ln4.history['accuracy'])\nplt.plot(history_model_ln4.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","371ee8b0":"model.evaluate(X_test,y_test_e)","70fc7356":"model_ln3.evaluate(X_test,y_test_e)","0739b12a":"model_ln4.evaluate(X_test,y_test_e)","dfa000d3":"# Test Prediction \ny_test_pred_ln3 = model_ln3.predict(X_test)\ny_test_pred_classes_ln3 = np.argmax(y_test_pred_ln3, axis=1)\ny_test_pred_prob_ln3 = np.max(y_test_pred_ln3, axis=1)\n","8bb593d1":"# Test Accuracy \nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, confusion_matrix\naccuracy_score(np.array(y_test), y_test_pred_classes_ln3)\n\n","1653eb1b":"cf_matrix = confusion_matrix(np.array(y_test), y_test_pred_classes_ln3)\n\n# Confusion matrix normalized per category true value\ncf_matrix_n1 = cf_matrix\/np.sum(cf_matrix, axis=1)\nplt.figure(figsize=(8,6))\nsns.heatmap(cf_matrix_n1, xticklabels=CATEGORIES, yticklabels=CATEGORIES, annot=True)","4d5fa532":"#Test Prediction \n\ny_test_pred_ln4 = model_ln4.predict(X_test)\ny_test_pred_classes_ln4 = np.argmax(y_test_pred_ln4, axis=1)\ny_test_pred_prob_ln4 = np.max(y_test_pred_ln4, axis=1)\n","e1ee7ac7":"import seaborn as sns\nfrom sklearn.metrics import accuracy_score, confusion_matrix\naccuracy_score(np.array(y_test), y_test_pred_classes_ln4)\n\n","c188dcdc":"cf_matrix = confusion_matrix(np.array(y_test), y_test_pred_classes_ln4)\n\n# Confusion matrix normalized per category true value\ncf_matrix_n1 = cf_matrix\/np.sum(cf_matrix, axis=1)\nplt.figure(figsize=(8,6))\nsns.heatmap(cf_matrix_n1, xticklabels=CATEGORIES, yticklabels=CATEGORIES, annot=True)","63ae0099":"\nfrom sklearn.metrics import precision_recall_fscore_support  \n\np=precision_recall_fscore_support(np.array(y_test), y_test_pred_classes_ln3, average=None,labels=list(np.unique(y_test)))\n\nprint(\" Precision is {}\\n Recall is {} \\n f_beta Score is {}\".format(p[0],p[1],p[2]))","6e62bee8":"\nfrom sklearn.metrics import precision_recall_fscore_support  \n\np=precision_recall_fscore_support(np.array(y_test), y_test_pred_classes_ln4, average=None,labels=list(np.unique(y_test)))\n\n\nprint(\" Precision is {}\\n Recall is {} \\n f_beta Score is {}\".format(p[0],p[1],p[2]))","4e6c7253":"\nfrom sklearn.metrics import f1_score\n\nf1_score(np.array(y_test), y_test_pred_classes_ln3, average='weighted')","d4ddf1e1":"\nfrom sklearn.metrics import f1_score\n\nf1_score(np.array(y_test), y_test_pred_classes_ln4, average='weighted')","569d7d49":"#fn = image.load_img(fp, target_size = (150,150), color_mode='grayscale')\nplt.imshow(X_test[1].reshape(150,150), cmap='Greys_r')\ni=y_test[1]\ni=np.argmax(i)\nif(i == 0):\n    plt.title(\"glioma_tumor\")\nif(i==1):\n    plt.title(\"meningioma_tumor\")\nif(i==2):\n    plt.title(\"no_tumor\")\nif(i==3):\n    plt.title(\"pituitary_tumor\")\n\nplt.axis('off')\nplt.show()","a8c2f3b7":"res=model_ln4.predict(X_test[1].reshape(1,150,150,1))","9653fd79":"i=np.argmax(res)\n\n\nif(i == 0):\n    print(\"glioma_tumor\")\nif(i==1):\n    print(\"meningioma_tumor\")\nif(i==2):\n    print(\"no_tumor\")\nif(i==3):\n    print(\"pituitary_tumor\")\n","802add02":"### **Plotting the Train & Test Accuracy**","e262e45c":"#### **Convolutional Neural Network (CNN)** \n\n**Model 3:** CNN with Dropout after Convolution and having two Dense layers with 512 & 256 Units respectively ","a8912e2f":"**CNN Model 2**","6af554e3":"# **Brain Tumor Classification**\n\n","684f53e7":"### **Plotting the confusion matrix for the two best models** ","05652b5c":"**CNN Model 3**","22bf348d":"### **Reading the Training Data**","04c8a624":"Unfortunately, **we cannot decide the best model based on test accuracy here** because we are dealing with an imbalanced dataset, so we are more concerned with **Precision and Recall**. Since these two metrics are both quite important in this scenario, we will also check the **F1 score** to try to achieve a good balance between Precision and Recall. ","ca294cc7":"### **Model Evaluation**","5263d3f2":"**Model 2**","f50876c3":"### **Model Building** \n\nWe will be using two types of Deep Neural Networks:\n\n- **ANN** (Artificial Neural Network - fully connected)\n- **CNN** (Convolutional Neural Network)","c6821bb6":"**Model 3**","f0d85756":"**Finding the mean images** for each class of tumor: ","7b0afea4":"As we can see from the contrast difference between the No tumor image and the tumor image, the blue area represents the negative values, meaning the size of the tumorous brain is more than  non-tumourous brain.","be1ab989":"### **Prediction**\n\nLet us predict with best model with is model_ln4","72ae123d":"Model 3 with 2 Dense layer and more  number of units having better F1 score.","3595e0e7":"**CNN Model 1**","9dea0ec4":"### **Importing the libraries**","7f341f58":"The above two confusion matrices show that the models seem to be working well. **Let's calculate the F1 score** (the harmonic mean of precision and recall), which is used as an evaluation metric for imbalanced datasets.","40907bfa":"**CNN Model 2**","d8a58dd7":"As we have seen, **ANNs do not work well with image data**, because ANNs do not take 2-D images as input. They flatten the image and make it lose its spatial struture, whereas CNNs take the full 2D-image as input in order to perform feature extraction. So **CNNs do not lose the image's spatial structure, which makes them more suitable for working with image datasets.**\n\n**There is still scope for improvement in the test accuracy and F1 score of the CNN model** chosen here. **Different architectures** can be built and **hyperparamter tuning** can be performed to obtain a better brain tumor classifier. \n\nWe can visualize the filters  and understand why the model does not do well in the identification of the glioma tumor.\n","1791c736":"**CNN Model 3**","a20f7222":"This model unfortunately **does not have a good test accuracy,** and it appears to be **underfitting on the training dataset.** That means we need to increase the complexity of the model in our next attempt.","d15622f8":"**CNN Model 2**","c79af505":"**CNN Model 2**","9cb04940":"### **Conclusion**","cbce7096":"As we can see, **Model 2 and Model 3 seem to be generalizing well** because they both have a good Holdout set Accuracy. **Let us compute the confusion matrix** for these two models to understand the distribution of True Positives, False Positives, False Negatives and True Negatives.","14485994":"**Classification Report for each class** \n\n- **Precision:** precision is the fraction of relevant instances among the retrieved instances.\n\n- **Recall:** recall is the fraction of relevant instances that were retrieved.\n\n- **F-beta score:** The F-beta score is the weighted harmonic mean of precision and recall, reaching its optimal value at 1 and its worst value at 0. The beta parameter determines the weight of recall in the combined score.\n\n\n\nThe order of printing the above metrices for each class is as follows:\n\n- **Glioma Tumor**\n- **Meningioma Tumor**\n- **Non Tumor**\n- **Pituitary Tumor**\n\n","fde106ac":"**CNN Model 3**","34d2fbb3":"### **Reading the Testing Dataset**\n","efd528af":"**CNN Model 3**","f83be62d":"## **Context**\n\nBrain tumor is known to be one of the most aggressive diseases that affect both children and adults. Of all primary Central Nervous System (CNS) tumors, brain tumors account for 85 to 90 percent. **Around 11,700 individuals are diagnosed with a brain tumor every year.** For individuals with a cancerous brain or CNS tumor, **the 5-year survival rate is around 34 percent for men and 36 percent for women.** Brain tumors are classified into Benign Tumors, Pituitary Tumors, Malignant Tumors etc. In order to increase the life expectancy of patients, adequate care, preparation and reliable diagnostics are required in the treatment process.\n\n**Magnetic Resonance Imaging (MRI)** is the best way to identify brain tumors. A huge amount of image data is produced through MRI Scans. However, there are several anomalies in the tumor size and location (s). This makes it very difficult to completely comprehend the nature of the tumor. **A trained neurosurgeon is usually needed for MRI image analysis.** **The lack of qualified doctors and the lack of knowledge about tumors makes it very difficult and time-consuming for clinical facilities in developing countries to perform MRI studies.** Due to the level of difficulty involved in comprehending the nature of brain tumors and their properties, manual analyses can be highly error-prone. That makes an automated MRI analysis system crucial to solve this problem. \n\n**Applications of automated classification techniques using Machine Learning (ML) and Artificial Intelligence (AI) algorithms have consistently shown better performance than manual classification.** It would therefore be highly beneficial to write an algorithm that performs **detection and classification of brain tumors using Deep Learning Algorithms.**\n\n## **Dataset**\n\nThe dataset folder contains MRI data. The images are already split into Training and Testing folders.\nEach folder has more four subfolders named **`\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\"`** and **`\"pituitary_tumor\"`**. These folders have MRI images of the respective tumor classes.\n\n**Instructions** to access the data through Google Colab:\n\nFollow the below steps: \n\n1) Download the zip file from Olympus and extract it in your local system. \n\n2) Upload the extracted folder into your drive.\n\n3) Mount your Google Drive using the code below.\n\n\n```\nfrom google.colab import drive\ndrive.mount('\/content\/drive')\n```\n\n\n4) Now, you can read the dataset as mentioned in the code below.\n\n## **Problem Statement**\n\nTo build a classification model that can take images of MRI scans as input and can classify them into one of the following types of tumor:\n\n**`glioma_tumor`**, **`meningioma_tumor`**, **`pituitary_tumor`** and **`no_tumor`**.\n\n","60cb415c":"#### **Convolutional Neural Network (CNN)**\n\n**Model 2:** CNN with Dropout after Convolution and having two Dense layers with 16 & 8 units respectively \n\nSince CNN Model 1 does not appear to have good test accuracy and appears to be overfitting on the training dataset, let's use CNN Model 2, which has a different architecture that should generalize well and not overfit.","29e5b990":"#### **ANN**","86bbcc64":"### **Exploratory Data Analysis**","27d724f3":"### **Data Preprocessing** ","d1d09dc8":"The above plot shows that **this dataset is imbalanced**, because **71.2% of the images are those of tumors** - Majority class: glioma, meningioma and pituitary tumors, while approx. **28.8% of the images** belong to the **non-tumor category** (Minority class).","659d783a":"#### **Convolutional Neural Network (CNN)**\n\n**Model 1:** CNN with Dropout","cc4a5e8b":"As we see here, the **ANN does not show a good test accuracy**, since ANNs are unable to capture spatial correlation characteristics of the image. \n\n**Let's try Convolutional Neural Networks, which take in the whole image as a 2D matrix instead.** ","75b446c6":"**CNN Model 1**","5024bdc3":"### **One-Hot Encoding**","1011d85b":"**Let's visualize MRI images randomly from each of the three classes.** The Image matrix is plotted and each row represents three single channel images corresponding to one class. We have read single channel images in order to reduce complexity. \n\n\n","1e24338b":"### **Weighted F-Score**","c6638f35":"**Model 3 (Best) Observation**\n\nAs we see from the precision for each class, the Pituitary tumor classifier has the highest precision. But here, **we are more concerned about the case where a person who has a tumor is wrongly classified as belonging to the non-tumor category (False Negative).** \n\n**33% of the persons belonging to Glioma tumour and 8.6% belonging to Meningioma tumor are not identified correctly, and the model predicts that they don't have a tumor at all** - which shows that our model does not do well in identifying glioma and meningioma tumors. But it is works well for the other scenario, where the model is able to correctly identify those scans that do not not show a tumor. \n\n---\n\n","ce28f804":"### **Contrast Difference**"}}