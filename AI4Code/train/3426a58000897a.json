{"cell_type":{"ff0d6e51":"code","6678cdbd":"code","d1d2874c":"code","d22adc86":"code","f198017c":"code","67ae9f71":"code","02ea87c3":"code","4526b487":"code","63e1257d":"code","314e0d19":"code","7ff1f2fe":"code","9c206db8":"code","deccb7c3":"code","a9835a06":"code","779ab64d":"code","0f27f9cc":"code","3cc3a577":"code","be70f6b6":"code","dd375c5b":"code","59d4c09c":"code","42316c7b":"code","a4ae0ccb":"code","79e1271d":"code","b4ac2902":"code","65215edb":"code","82cd0cb1":"code","8199d9f9":"code","95c3f000":"code","3f6efd6c":"markdown","cc0899cb":"markdown","001814dd":"markdown","ff9d2c6c":"markdown","5f2f56d5":"markdown","6daa415c":"markdown","9b42663e":"markdown","057fe3a8":"markdown","8ab9fd52":"markdown","b1348207":"markdown","e7c75e11":"markdown","71390d28":"markdown","9446af43":"markdown","df6331f2":"markdown","740e84fc":"markdown","61876bec":"markdown","ee39bae8":"markdown","935baca4":"markdown","150f3919":"markdown","58b0339b":"markdown","33525cdd":"markdown","f11e76bc":"markdown","9614f7d7":"markdown","2fca6488":"markdown","f7fece8e":"markdown","6c5854d3":"markdown","56903586":"markdown"},"source":{"ff0d6e51":"import numpy as np \nimport pandas as pd ","6678cdbd":"import pandas as pd\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\n\nprint(train.shape, test.shape, submission.shape)\nprint(train.columns)                             #printing the column names\nprint(set(train.columns)-set(test.columns))      #printing the target column","d1d2874c":"train.head()","d22adc86":"_1 = train.isnull().sum()\/len(train)*100\n_2 = test.isnull().sum()\/len(train)*100\n\ndf = pd.concat([_1,_2], axis = 1)\ndf.columns = ['train', 'test']\ndf","f198017c":"test['Survived'] = -1\nall_data = pd.concat([train, test])\nprint(all_data.head())\nall_data.tail()","67ae9f71":"for col in ['Age', 'Fare']:\n    all_data[col] = all_data[col].fillna(all_data[col].mean())\n    print(all_data[col].isnull().sum())","02ea87c3":"for col in ['Embarked', 'Ticket']:\n    all_data[col] = all_data[col].fillna(all_data[col].mode()[0]) \n    print(all_data[col].isnull().sum())","4526b487":"col = 'Cabin'\nall_data[col] = all_data[col].notnull().astype(int)\nprint(all_data[col].isnull().sum())","63e1257d":"all_data.isnull().sum()\/len(train)*100","314e0d19":"# Taking only categorical columns\ncols = [col for col in all_data.columns if all_data[col].dtype == 'object']\ncols\n\nfor col in cols:\n    print(f\"{col} : {all_data[col].nunique()\/len(all_data)*100}\")","7ff1f2fe":"all_data.drop(['Name', 'Ticket'], axis = 1, inplace = True)","9c206db8":"df = pd.concat([all_data.iloc[0], all_data.dtypes], axis = 1)\ndf.columns = ['sample', 'dtype']\ndf","deccb7c3":"# Check which categorical columns are left\ncols = [col for col in all_data.columns if all_data[col].dtype == 'object']\ncols","a9835a06":"all_data = pd.get_dummies(all_data, drop_first = True)\nall_data.head()","779ab64d":"n_train = len(train)\ntrain_modified = all_data.iloc[:n_train].copy()   # This will create copy of the df. Done to avoid future warnings\ntest_modified = all_data.iloc[n_train:].copy()\n\nprint(len(train_modified), len(test_modified))","0f27f9cc":"train_modified.head()","3cc3a577":"# Removing 'PassengerId' column\ntrain_modified.drop('PassengerId', axis = 1, inplace = True)","be70f6b6":"test_modified.head()","dd375c5b":"# Remove 'Survived' column from test data\ntest_modified.drop('Survived', axis = 1,inplace = True)","59d4c09c":"from sklearn.model_selection import train_test_split\n\nX = train_modified.drop('Survived', axis = 1)\ny = train_modified['Survived'].copy()\n\nx_train, x_test, y_train, y_test = train_test_split(X, y.values, test_size = 0.25, random_state = 42)\n\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","42316c7b":"x_test","a4ae0ccb":"from sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression(solver='liblinear', random_state = 42)\n\nclassifier.fit(x_train.values, y_train)","79e1271d":"y_pred = classifier.predict(x_test.values)\naccuracy = (y_pred == y_test).astype(int).sum()\/len(y_test)*100\nprint(f\"Model accuracy is : {accuracy: .3f} %\")","b4ac2902":"# Saving 'PassengerId' of test data and deleting it\ntest_idx = test_modified['PassengerId'].copy()\n\ntest_modified.drop('PassengerId', axis = 1, inplace = True)\n\nprint(test_modified.shape)","65215edb":"y_pred = classifier.predict(test_modified.values)\nsubmission.loc[:, 'Survived'] = y_pred","82cd0cb1":"submission","8199d9f9":"submission.to_csv('submission.csv', index = False)   # index = False is important ","95c3f000":"# Recheck if the file is in correct format\npd.read_csv(\"submission.csv\")","3f6efd6c":"An accuracy of 76.612% is a good starting point. From here on we can improve","cc0899cb":"<a id='tag9'><\/a>\n## [Step - 9 : Making your first submission](#content-table)","001814dd":"<a id='load'><\/a>\n## [Step - 1 : Loading data](#content-table)","ff9d2c6c":"<a id='tag6'><\/a>\n## [Step - 6 : Splitting into train\/test set](#content-table)","5f2f56d5":"### Fill 'Age' and 'Fare' value with their mean value","6daa415c":"Here we see that the data type of sample matches with the datatype of the column. Hence no need to change column datatype","9b42663e":"<a id='tag3'><\/a>\n## [Step - 3 : Filling missing values](#content-table)","057fe3a8":"<a id='tag8'><\/a>\n## [Step - 8 : Making predicitions on Test set](#content-table)","8ab9fd52":"### Split into train-test set","b1348207":"## Print first 5 rows","e7c75e11":"___________\n# Summary\n#### The aim of this notebook is to make first submission and get a baseline score from where improvement can be made. For this I would just be filling the null values, correcting the datatypes which includes one-hot-encoding categorical columns. All this is required as ML models need data which are numerical and void of null values. \n#### There is no additional EDA\/Feature Engineering\/Model optimization etc as our aim is first submission.\n\n<a id='content-table'><\/a>\n## Table of Contents\n1. [Loading data](#load)\n2. [Combine Train and Test data](#tag2)\n3. [Filling missing values](#tag3)\n4. [Remove unncessary columns](#tag4)\n5. [Change datatypes if required](#tag5)\n6. [Splitting into train\/test set](#tag6)\n7. [Training a simple model](#tag7)\n8. [Making predicitions on Test set](#tag8)\n9. [Making your first submission](#tag9)","71390d28":"`'Name'` and `'Ticket'` columns have more than 87% & 66% unique values respectively. They don't give any information to the model just as is. EDA\/Feature Engineering might give us some insight, but we are not doing that here.","9446af43":"**Now you have made your first submssion. From here on you can do many things to improve your accuracy. You can do EDA to get better insights in your data. Furthur you can also do feature engineering, hyperparameter optimization, ensembling of models.**","df6331f2":"<a id='tag5'><\/a>\n## [Step - 5 : Change datatypes if required](#content-table)","740e84fc":"We see that columns that have null values are same in both the dataset and the % missing values is around the same","61876bec":"<a id='tag2'><\/a>\n## [Step - 2 : Combine Train and Test data](#content-table)","ee39bae8":"### Create a train-test split on training data","935baca4":"### Fill 'Embarked' and 'Ticket' values with their mode value","150f3919":"### Filling Cabin values\nHere 67% values are missing. Hence I will fill it with 1 if value is present and 0 if missing value","58b0339b":"_______________","33525cdd":"Now our data is ready to be fed into model. So we will split into train\/validation\/test set and train a basic model","f11e76bc":"<a id='tag7'><\/a>\n## [Step - 7 : Training a simple model](#content-table)","9614f7d7":"### Verify there are no null values","2fca6488":"### Check column datatype with a sample datatype","f7fece8e":"<a id='tag4'><\/a>\n## [Step - 4 : Remove unncessary columns](#content-table)\n\nWe will check %unique values in column","6c5854d3":"### One-hot-encode categorical columns","56903586":"## Check the %null values in  Train and Test data"}}