{"cell_type":{"5ea5362a":"code","2a717841":"code","367697e3":"code","206f4109":"code","176f462c":"code","81ba8109":"code","6714ed32":"code","c6d763c7":"code","cc7cd2d5":"code","b10d980a":"code","fdc9da2d":"code","bdc569b9":"markdown","5b4f49d9":"markdown","410cdcc7":"markdown","7bd41bda":"markdown"},"source":{"5ea5362a":"import numpy as np\nimport pandas as pd\nfrom category_encoders import TargetEncoder\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils import estimator_html_repr\nfrom IPython.core.display import HTML\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn import linear_model\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import LabelEncoder\nfrom category_encoders import TargetEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler, MinMaxScaler, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport optuna\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import SMOTE\nfrom matplotlib import pyplot\nfrom numpy import where\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import roc_auc_score","2a717841":"df = pd.read_csv('train1.csv')\ndf['credit_line_utilization']=df['credit_line_utilization'].replace(',', '.', regex=True).astype(float)\ndf['credit_line_utilization']=pd.to_numeric(df['credit_line_utilization'])","367697e3":"from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import SMOTE\nfrom matplotlib import pyplot\nfrom numpy import where","206f4109":"X = df[['age', 'number_dependent_family_members', 'monthly_income',\n       'number_of_credit_lines', 'real_estate_loans',\n       'ratio_debt_payment_to_income', 'credit_line_utilization',\n       'number_of_previous_late_payments_up_to_59_days',\n       'number_of_previous_late_payments_up_to_89_days',\n       'number_of_previous_late_payments_90_days_or_more']]\n\ny = df['defaulted_on_loan']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.35)","176f462c":"over = RandomOverSampler(sampling_strategy=0.6)\nunder = RandomUnderSampler(sampling_strategy=0.9)\nX_over, y_over = over.fit_resample(X_train, y_train)\nprint(f\"Oversampled: {Counter(y_over)}\")\nX_combined_sampling, y_combined_sampling = under.fit_resample(X_over, y_over)\nprint(f\"Combined Random Sampling: {Counter(y_combined_sampling)}\")","81ba8109":"def make_clf(max_depth, numeric_imputation, scaling_strategy,n_estimators,min_samples_leaf):\n    categorical_preprocessing = Pipeline(steps=[\n        ('imputation', SimpleImputer(strategy='most_frequent')),\n        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\n    if scaling_strategy == 'robust':\n        scaling = RobustScaler()\n    elif scaling_strategy == 'minmax':\n        scaling = MinMaxScaler()\n    elif scaling_strategy == 'standard':\n        scaling = StandardScaler()\n        \n    numeric_preprocessing = Pipeline(steps=[\n        ('imputation', SimpleImputer(strategy=numeric_imputation)),\n        ('scaling', scaling)\n    ])\n\n    preprocessing = ColumnTransformer(transformers=[\n        ('categorical', categorical_preprocessing, ['number_dependent_family_members',\n                                                   'number_of_credit_lines','real_estate_loans','number_of_previous_late_payments_up_to_59_days',\n                                                   'number_of_previous_late_payments_up_to_89_days',\n                                                   'number_of_previous_late_payments_90_days_or_more']),\n        ('numeric', numeric_preprocessing, ['age','monthly_income',\n                  'ratio_debt_payment_to_income','credit_line_utilization'])])\n\n    clf = Pipeline(steps=[\n        ('preprocessing', preprocessing),\n        ('clf', RandomForestClassifier(max_depth=max_depth,n_estimators=n_estimators,min_samples_leaf=min_samples_leaf,class_weight='balanced'))\n    ])\n    \n    return clf\n","6714ed32":"test1 = pd.read_csv('test11.csv')","c6d763c7":"X = ['age', 'number_dependent_family_members', 'monthly_income',\n       'number_of_credit_lines', 'real_estate_loans',\n       'ratio_debt_payment_to_income', 'credit_line_utilization',\n       'number_of_previous_late_payments_up_to_59_days',\n       'number_of_previous_late_payments_up_to_89_days',\n       'number_of_previous_late_payments_90_days_or_more']\n\ntest1['credit_line_utilization']=test1['credit_line_utilization'].replace(',', '.', regex=True).astype(float)\ntest1['credit_line_utilization']=pd.to_numeric(test1['credit_line_utilization'])\nclf.predict(test1[X])","cc7cd2d5":"print(f\"Oversampled: {Counter(clf.predict(test1[X]))}\")","b10d980a":"probability = clf.predict_proba(test1[X])[:,1]\nsubmission = pd.DataFrame({'Id':test1['Id'],'Predicted':probability})","fdc9da2d":"filename = 'Loan_Default_Prediction_xx.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","bdc569b9":"# Next line of code is for replacing the commas in the data with dots to read data correctly","5b4f49d9":"# Because of having small number of defaulted loans, I have decided to over sample it. To reduce the processing time, I have undersampled the overall data, to work with closer number of defaulted and non-defaulted loan values.","410cdcc7":"# \"test11.csv\" is the target file that need to be evaluated with our model","7bd41bda":"# Random Forest Classifier with balanced"}}