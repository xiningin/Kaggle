{"cell_type":{"e499d0bf":"code","8d3adc07":"code","d669ce04":"code","17f4a637":"code","63343dd6":"code","28f746cd":"code","a8139c76":"code","7c448fde":"code","086cfcbf":"code","35f3691b":"code","7e886a02":"code","06317c7b":"code","b53bfbbd":"code","107aca28":"code","0be5e1f1":"code","ca323b00":"code","84905ca8":"code","836f204c":"code","3e256318":"code","454cdeb0":"code","bc54758f":"code","9ef8f26b":"code","7bf4d80e":"code","ae934493":"code","3412f347":"markdown","432892e1":"markdown","14f7d603":"markdown","539f756d":"markdown","9d59995e":"markdown","1cd7a381":"markdown","35c6ac98":"markdown","beed3930":"markdown"},"source":{"e499d0bf":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\n\nimport joblib\nimport imageio\nimport cv2\nimport os\nimport glob","8d3adc07":"# Download CSV containing the id and landmark-id of the images\n!wget -cq 'https:\/\/s3.amazonaws.com\/google-landmark\/ground_truth\/recognition_solution_v2.1.csv'","d669ce04":"# Read downloaded CSV file into pandas DataFrame\nrecognition_solution = pd.read_csv('recognition_solution_v2.1.csv')","17f4a637":"# Convert usage to category for efficient storage\nrecognition_solution['Usage'] = recognition_solution['Usage'].astype('category')","63343dd6":"# Converts space seperated landmark-ids to integer tuples\ndef landmarks2tuple(s):\n    if type(s) is float:\n        return tuple([])\n    else:\n        return tuple([int(e) for e in s.split(' ')])\n    \n# Add landmarks as integer tuples\nrecognition_solution['landmarks_tuple'] = recognition_solution['landmarks'].apply(landmarks2tuple)\n# Add landmarks length\nrecognition_solution['landmarks_len'] = recognition_solution['landmarks_tuple'].apply(len).astype(np.uint8)","28f746cd":"# Set first landmark as label, -1 for non-landmarks\ndef get_label(t):\n    if len(t) == 0:\n        return -1\n    else:\n        return t[0]\n\nrecognition_solution['label'] = recognition_solution['landmarks_tuple'].apply(get_label)","a8139c76":"# Add file path\ndef to_file_path(i):\n    return f'\/kaggle\/working\/test\/{i[0]}\/{i[1]}\/{i[2]}\/{i}.jpg'\n\nrecognition_solution['file_path'] = recognition_solution['id'].apply(to_file_path).astype('string')","7c448fde":"display(recognition_solution.head())","086cfcbf":"# The test set contains of 117K images\ndisplay(recognition_solution.info())","35f3691b":"# Distribution of number of landmarks in image, 98.3% is non-landmark\ndisplay(recognition_solution['landmarks_len'].value_counts(normalize=True).to_frame() * 100)","7e886a02":"# Save DataFrame\nrecognition_solution.to_pickle('.\/recognition_solution.pkl.xz')","06317c7b":"# Make test directory\n!mkdir test","b53bfbbd":"# Download all 19 test parts, takes several minutes\nfor i in tqdm(range(0, 20)):\n    idx = str(i).rjust(2, '0')\n    file = f'images_0{idx}.tar'\n    # Download tar file\n    !wget -cq \"https:\/\/s3.amazonaws.com\/google-landmark\/test\/$file\" -P test\n    # Extract tar file\n    !tar -xf \"\/kaggle\/working\/test\/$file\" -C \"\/kaggle\/working\/test\"\n    # Remove tar file\n    !rm -f \"\/kaggle\/working\/test\/$file\"","107aca28":"# Image size for TFRecords\nIMG_SIZE = 384","0be5e1f1":"# Processes an image for the TFRecords\ndef process_image(file_path):\n    # Read image\n    img = imageio.imread(file_path)\n    h, w, _ = img.shape\n\n    # Downsize ratio in case image is larger than desired IMG_SIZE\n    r = IMG_SIZE \/ min(w, h)\n    if min(h,w) > IMG_SIZE:\n        w_resize = int(w * r)\n        h_resize = int(h * r)\n        # Resize image using LANCZOS algorithm for best result\n        img = cv2.resize(img, (w_resize, h_resize), interpolation=cv2.INTER_LANCZOS4)\n        # Decode image as JPEG\n        img_jpeg = tf.io.encode_jpeg(img, quality=70, optimize_size=True).numpy()\n        return img_jpeg, h_resize, w_resize\n    else:\n        with open(file_path, 'rb') as f:\n            img_jpeg = f.read()\n        return img_jpeg, h, w","ca323b00":"# Splits array into equally sized chunks\ndef split_in_chunks(data, chunk_size):\n    return [data[:, i:i + CHUNK_SIZE] for i in range(0, len(data[1]), CHUNK_SIZE)]","84905ca8":"# Each TFRecord will contain 3000 images to get TFRecords of roughly 100MB\nCHUNK_SIZE = int(3e3)\n\n# Splits images into chunks\ndata_split = split_in_chunks(np.array((recognition_solution['file_path'], recognition_solution['label'])), CHUNK_SIZE)\n\nprint(f'data_split chunks: {len(data_split)}')","836f204c":"def to_tf_records(data_split):\n    # Make directory\n    if not os.path.exists('test_tfrecords'):\n        os.mkdir('test_tfrecords')\n    \n    for idx, (fps, lbls) in enumerate(tqdm(data_split)):\n\n        # Process images in parallel\n        jobs = [joblib.delayed(process_image)(fp) for fp in fps]\n        imgs_resized = joblib.Parallel(\n            n_jobs=cpu_count(),\n            verbose=0,\n            batch_size=64,\n            pre_dispatch=64*cpu_count(),\n            require='sharedmem'\n        )(jobs)\n        tfrecord_name = f'test_tfrecords\/test_batch_{idx}.tfrecords'\n\n        # Write processed images to TFRecord file\n        with tf.io.TFRecordWriter(tfrecord_name) as file_writer:\n            for (img, h, w), lbl in zip(imgs_resized, lbls):\n                record_bytes = tf.train.Example(features=tf.train.Features(feature={\n                    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img])),\n                    'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(lbl)])),\n                    'height': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(h)])),\n                    'width': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(w)])),\n                })).SerializeToString()\n                file_writer.write(record_bytes)\n\n# Create TFRecords\nto_tf_records(data_split)","3e256318":"# Zip image folders, otherwise all images are written to the output notebook HTML which will crash\nfor source in tqdm(glob.glob('\/kaggle\/working\/test\/*')):\n    if '.' not in source:\n        folder = source.split('\/')[-1]\n        target = f'{folder}.zip'\n        # Zip\n        !cd \"\/kaggle\/working\/test\" ; zip -qr \"$target\" \"$folder\"\n        # Remove original folder\n        !rm -rf \"$source\"","454cdeb0":"# ImageNet mean and standard deviations for image normalization\nIMAGENET_MEAN = tf.constant([0.485, 0.456, 0.406], dtype=tf.float32)\nIMAGENET_STD = tf.constant([0.229, 0.224, 0.225], dtype=tf.float32)\n\nN_CHANNELS = tf.constant(3, dtype=tf.int64)","bc54758f":"# Decodes the images\ndef decode_tfrecord(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n        'width': tf.io.FixedLenFeature([], tf.int64),\n        'height': tf.io.FixedLenFeature([], tf.int64),\n    })\n\n    image = tf.io.decode_jpeg(features['image'])\n    label = features['label']\n    height = features['height']\n    width = features['width']\n    \n    # Cutout Random Square\n    if height != width:\n        if height > width:\n            offset = tf.random.uniform(shape=(), minval=0, maxval=height-width, dtype=tf.int64)\n            image = tf.slice(image, [offset, 0, 0], [width, width, N_CHANNELS])\n        else:\n            offset = tf.random.uniform(shape=(), minval=0, maxval=width-height, dtype=tf.int64)\n            image = tf.slice(image, [0, offset, 0], [height, height, N_CHANNELS])\n    \n    # Reshape and Normalize\n    size = tf.math.reduce_min([height, width])\n    image = tf.reshape(image, [size, size, N_CHANNELS])\n    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n    image = tf.cast(image, tf.float32)  \/ 255.0\n    image = (image - IMAGENET_MEAN) \/ IMAGENET_STD\n    \n    return image, label","9ef8f26b":"# Shows a batch of images given a dataset\ndef show_batch(dataset, rows=4, cols=3):\n    imgs, lbls = next(iter(dataset))\n    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*4, rows*4))\n    for r in range(rows):\n        for c in range(cols):\n            img = imgs[r*cols+c].numpy().astype(np.float32)\n            img += abs(img.min())\n            img \/= img.max()\n            axes[r, c].imshow(img)\n            axes[r, c].set_title(f'Label: {lbls[r*cols+c]}')","7bf4d80e":"# The TFRecord dataset\ndef get_test_dataset():\n    FNAMES_TEST_TFRECORDS = tf.io.gfile.glob('.\/test_tfrecords\/*.tfrecords')\n    test_dataset = tf.data.TFRecordDataset(FNAMES_TEST_TFRECORDS, num_parallel_reads=1)\n    test_dataset = test_dataset.map(decode_tfrecord, num_parallel_calls=1)\n    test_dataset = test_dataset.batch(32)\n    \n    return test_dataset","ae934493":"# Get dataset and show batch\ntest_dataset = get_test_dataset()\nshow_batch(test_dataset)","3412f347":"# Check TFRecords","432892e1":"# Zip Image Folder for Dataset","14f7d603":"# Split in Chunks","539f756d":"# Make TFRecords","9d59995e":"# Download Label File","1cd7a381":"Hello fellow Kagglers,\n\nThis noteboook demonstrates the creation of the Google Landmark Recgonition 2019 Test dataset, publicly available [here](https:\/\/www.kaggle.com\/markwijkhuizen\/google-landmark-recognition-2019-test).\n\nBoth the public and private test dataset are included. The dataset in contain the images and resized TFRecords. These images can be used for validation or to have examples of non-landmark images.\n\nAn important remark is the occurance of images with multiple landmark-ids assigned, this would indicate images could belong to multiple classes, which is not the case in the Google Landmark Recognition 2021 competition. For simplicitly purposes the first landmark-id is used as label for the TFRecords.","35c6ac98":"# Process Image","beed3930":"# Download Dataset"}}