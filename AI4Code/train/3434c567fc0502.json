{"cell_type":{"46d04e2d":"code","f4010fea":"code","f6f2b696":"code","00fe7983":"code","0d3dc0bf":"code","64dc1276":"code","b544d67c":"code","eae63d0d":"code","ab197121":"code","dbe36f8f":"code","0f90944f":"code","101eb4ec":"code","6a21e138":"code","18024df2":"code","b91f0e38":"code","a0833485":"code","ac4d4ce2":"code","592c8424":"code","718e808b":"code","6d8a1c40":"code","780c2663":"code","02ef43e8":"code","1ad4e927":"code","ca3bfc7b":"code","d9319c3e":"code","9fb5b520":"markdown","88c8d39b":"markdown","f8e01bc9":"markdown","1e58b5da":"markdown","36e3bce8":"markdown","d6af1a8e":"markdown","9c4aecf0":"markdown","586acf2a":"markdown","3730e758":"markdown","5e9711d3":"markdown"},"source":{"46d04e2d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4010fea":"import pandas as pd\nimport pylab\nimport matplotlib.pyplot as plt\nimport numpy as np","f6f2b696":"dataset = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","00fe7983":"death_events = dataset['DEATH_EVENT']\ndeath_events = death_events.value_counts().tolist()                             #taking count of unique values in death events\ndeath_events_labels = ['Surivival','Death']\n\nplt.pie(x = death_events,labels = death_events_labels, autopct = '%.2f%%')","0d3dc0bf":"correlation = dataset.corr()\nplt.imshow(correlation, aspect='auto')\nax = pylab.subplot()\ndataset.columns","64dc1276":"X = dataset.iloc[ : , :-1].values\nY = dataset.iloc[ : ,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX,X_test,Y,Y_test = train_test_split(X, Y, test_size= 0.20, random_state = 4)\nX_train,X_validate,Y_train,Y_validate = train_test_split(X, Y, test_size=0.125, random_state = 2)\n\nmodel_results = []           #The models with the best accuracy will be stored in this list","b544d67c":"logistic_regression_C_values = [1, 0.1, 0.01, 0.001, 0.0001]\nlogistic_regression_results = []\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport statistics\n\nfor c in logistic_regression_C_values :\n    logistic_regression_classifier = LogisticRegression(C=c, max_iter = 10000)\n    logistic_regression_classifier.fit(X_train, Y_train)\n    \n    Y_pred_test = logistic_regression_classifier.predict(X_test)\n    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n\n    Y_pred_validate = logistic_regression_classifier.predict(X_validate)\n    validation_accuracy = accuracy_score(Y_validate, Y_pred_validate)\n\n    #storing accuracy score for each value of C in a list\n    logistic_regression_results.append({'test_accuracy':test_accuracy, \n                                        'validation_accuracy': validation_accuracy, \n                                        'total_accuracy':statistics.mean([test_accuracy,validation_accuracy])\n                                        })","eae63d0d":"print('C','\\t','Test accuracy','\\t','Validation accuracy','\\t','Total accuracy')\ni = 0\nfor i in range(len(logistic_regression_C_values)) :\n    print(logistic_regression_C_values[i],'\\t',\n          \"{:.2f}%\".format(logistic_regression_results[i]['test_accuracy']*100),'\\t',\n          \"{:.2f}%\".format(logistic_regression_results[i]['validation_accuracy']*100),'\\t\\t',\n          \"{:.2f}%\".format(logistic_regression_results[i]['total_accuracy']*100),'\\n')","ab197121":"#Adding the result with best accuracy to algorithm_results\nmodel_results.append({'model_name':'Logistic regression',\n                      'accuracy':logistic_regression_results[3]['total_accuracy']\n                          })","dbe36f8f":"knn_neighbors = [8 , 9, 10, 11, 12, 13]\nknn_results = []\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfor n in knn_neighbors :\n    k_neighbor_classifier = KNeighborsClassifier(n_neighbors = n, metric = 'minkowski', p = 1)\n    k_neighbor_classifier.fit(X_train, Y_train)\n\n    Y_pred_test = k_neighbor_classifier.predict(X_test)\n    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n\n    Y_pred_validate = k_neighbor_classifier.predict(X_validate)\n    validation_accuracy = accuracy_score(Y_validate, Y_pred_validate)\n\n    #storing accuracy score for each value of neighbors in a list\n    knn_results.append({'test_accuracy':test_accuracy, \n                        'validation_accuracy': validation_accuracy, \n                        'total_accuracy':statistics.mean([test_accuracy,validation_accuracy])\n                        })","0f90944f":"print('Neighbors','\\t','Test accuracy','\\t','Validation accuracy','\\t','Total accuracy')\nfor i in range(len(knn_neighbors)) :\n    print(knn_neighbors[i],'\\t\\t',\n          \"{:.2f}%\".format(knn_results[i]['test_accuracy']*100),'\\t\\t',\n          \"{:.2f}%\".format(knn_results[i]['validation_accuracy']*100),'\\t',\n          \"{:.2f}%\".format(knn_results[i]['total_accuracy']*100),'\\n')","101eb4ec":"#Adding the result with best accuracy to algorithm_results\nmodel_results.append({'model_name':'KNN',\n                     'accuracy':knn_results[2]['total_accuracy']\n                          })","6a21e138":"svm_C_values = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\nsvm_results = []\n\nfrom sklearn.svm import SVC\nfor c in svm_C_values :\n    svc_classifier = SVC(kernel = 'linear', C = c)\n    svc_classifier.fit(X_train, Y_train)\n\n    Y_pred_test = svc_classifier.predict(X_test)\n    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n\n    Y_pred_validate = svc_classifier.predict(X_validate)\n    validation_accuracy = accuracy_score(Y_validate, Y_pred_validate)\n\n    #storing accuracy score for each value of neighbors in a list\n    svm_results.append({'test_accuracy':test_accuracy, \n                        'validation_accuracy': validation_accuracy, \n                        'total_accuracy':statistics.mean([test_accuracy,validation_accuracy])\n                        })","18024df2":"print('C','\\t','Test accuracy','\\t','Validation accuracy','\\t','Total accuracy')\nfor i in range(len(svm_C_values)) :\n    print(svm_C_values[i],'\\t\\t',\n          \"{:.2f}%\".format(svm_results[i]['test_accuracy']*100),'\\t\\t',\n          \"{:.2f}%\".format(svm_results[i]['validation_accuracy']*100),'\\t',\n          \"{:.2f}%\".format(svm_results[i]['total_accuracy']*100),'\\n')","b91f0e38":"#Adding the result with best accuracy to algorithm_results\nmodel_results.append({'model_name':'Linear SVM',\n                     'accuracy':svm_results[2]['total_accuracy']\n                          })","a0833485":"from sklearn.naive_bayes import GaussianNB\n\nnaive_bayes_classifier = GaussianNB()\nnaive_bayes_classifier.fit(X_train, Y_train)\n\nY_pred_test = naive_bayes_classifier.predict(X_test)\ntest_accuracy = accuracy_score(Y_test, Y_pred_test)\n\nY_pred_validate = naive_bayes_classifier.predict(X_validate)\nvalidation_accuracy = accuracy_score(Y_validate, Y_pred_validate)\n\ntotal_accuracy = statistics.mean([test_accuracy,validation_accuracy])","ac4d4ce2":"print('Test set accuracy : ',\"{:.2f}%\".format(100*test_accuracy))\nprint('\\nValidation set accuracy : ',\"{:.2f}%\".format(100*accuracy_score(Y_validate, Y_pred_validate)))\nprint('\\nTotal accuracy : ',\"{:.2f}%\".format(100*total_accuracy))","592c8424":"#Adding the result with best accuracy to algorithm_results\nmodel_results.append({'model_name':'Naive Bayes',\n                      'accuracy':total_accuracy\n                      })","718e808b":"decision_tree_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\ndecision_tree_results = []\n\nfrom sklearn.tree import DecisionTreeClassifier\nfor d in decision_tree_depth :\n    decision_tree_classifier = DecisionTreeClassifier(criterion = 'gini', random_state = 0, max_depth = d)\n    decision_tree_classifier.fit(X_train, Y_train)\n\n    Y_pred_test = decision_tree_classifier.predict(X_test)\n    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n\n    Y_pred_validate = decision_tree_classifier.predict(X_validate)\n    validation_accuracy = accuracy_score(Y_validate, Y_pred_validate)\n\n    #storing accuracy score for each value of neighbors in a list\n    decision_tree_results.append({'test_accuracy':test_accuracy, \n                                  'validation_accuracy': validation_accuracy, \n                                  'total_accuracy':statistics.mean([test_accuracy,validation_accuracy])\n                                  })","6d8a1c40":"print('Max depth','\\t','Test accuracy','\\t','Validation accuracy','\\t','Total accuracy')\nfor i in range(len(decision_tree_depth)) :\n    print(decision_tree_depth[i],'\\t\\t',\n          \"{:.2f}%\".format(decision_tree_results[i]['test_accuracy']*100),'\\t\\t',\n          \"{:.2f}%\".format(decision_tree_results[i]['validation_accuracy']*100),'\\t',\n          \"{:.2f}%\".format(decision_tree_results[i]['total_accuracy']*100),'\\n')","780c2663":"#Adding the result with best accuracy to algorithm_results\nmodel_results.append({'model_name':'Decision tree',\n                      'accuracy':decision_tree_results[4]['total_accuracy']\n                     })","02ef43e8":"random_forest_estimators = [5, 7, 10, 12, 15, 18, 20, 22]\nrandom_forest_results = []\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfor n in random_forest_estimators :\n    random_forest_classifier = RandomForestClassifier(n_estimators = n, criterion = 'entropy', random_state = 5, max_depth = 4)\n    random_forest_classifier.fit(X_train, Y_train)\n\n    Y_pred_test = random_forest_classifier.predict(X_test)\n    test_accuracy = accuracy_score(Y_test, Y_pred_test)\n\n    Y_pred_validate = random_forest_classifier.predict(X_validate)\n    validation_accuracy = accuracy_score(Y_validate, Y_pred_validate)\n\n    #storing accuracy score for each value of neighbors in a list\n    random_forest_results.append({'test_accuracy':test_accuracy, \n                                  'validation_accuracy': validation_accuracy, \n                                  'total_accuracy':statistics.mean([test_accuracy,validation_accuracy])\n                                  })","1ad4e927":"print('Estimators','\\t','Test accuracy','\\t','Validation accuracy','\\t','Total accuracy')\nfor i in range(len(random_forest_estimators)) :\n    print(random_forest_estimators[i],'\\t\\t',\n          \"{:.2f}\".format(random_forest_results[i]['test_accuracy']*100),'\\t\\t',\n          \"{:.2f}%\".format(random_forest_results[i]['validation_accuracy']*100),'\\t\\t',\n          \"{:.2f}%\".format(random_forest_results[i]['total_accuracy']*100),'\\n')","ca3bfc7b":"#Adding the result with best accuracy to algorithm_results\nmodel_results.append({'model_name':'Random forest',\n                      'accuracy':random_forest_results[5]['total_accuracy']\n                      })","d9319c3e":"print(\"{:<25}\".format('Model'),'Accuracy')\nfor model in model_results :\n    print(\"{:<25}\".format(model['model_name']),\n          \"{:.2f}%\".format(model['accuracy']*100))","9fb5b520":"<h3><b>Linear SVM<\/h3><\/b>","88c8d39b":"<h2><b>Apply learning<\/h2><\/b>\n<h3><b>Split the data into training, test and validation set<\/h3><\/b>","f8e01bc9":"<h3><b>Logistic Regression<\/h3><\/b>","1e58b5da":"<h3><b>KNN<\/h3><\/b>","36e3bce8":"<h3><b>Decision tree<\/h3><\/b>","d6af1a8e":"<h3><b>Random forest<\/h3><\/b>","9c4aecf0":"<h3><b>Accuracy of each model<\/h3><\/b>","586acf2a":"<h3><b>Correlation matrix<\/h3><\/b>","3730e758":"<h3><b>The ratio of Dead to Survived in the dependent column<\/b><\/h3>","5e9711d3":"<h3><b>Naive Bayes<\/h3><\/b>"}}