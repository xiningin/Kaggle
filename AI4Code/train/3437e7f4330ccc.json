{"cell_type":{"4b2549fa":"code","24e30769":"code","64b1c944":"code","cd6a3fc5":"code","9572f718":"code","fabfc2ab":"code","5bec2d3e":"code","229320dd":"code","b9ec17f4":"code","9b56d936":"code","7f58066a":"code","eb8c9b4b":"code","e6c807db":"code","34971515":"code","453e37a2":"code","9b434979":"code","a3cfad89":"code","b56ada11":"markdown","895aff99":"markdown","80f0eed4":"markdown","216a8d97":"markdown","dd05c6a0":"markdown","ae5773b3":"markdown","9db581a3":"markdown"},"source":{"4b2549fa":"import os\nprint(os.listdir(\"..\/input\"))","24e30769":"from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm_notebook","64b1c944":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\nplt.figure(figsize=(15,10))\nimg = cv2.imread(\"..\/input\/coco2017\/train2017\/train2017\/000000281563.jpg\")\nlabel = cv2.imread(\"..\/input\/coco2017\/stuffthingmaps_trainval2017\/train2017\/000000281563.png\")\n# changing to the BGR format of OpenCV to RGB format for matplotlib\nplt.subplot(1,3, 1)\nplt.imshow(img[:,:,::-1])\nplt.title(\"Image\")\nplt.subplot(1,3, 2)\nplt.imshow(label)\nplt.title(\"Label\")\ndst = cv2.addWeighted(img,0.3,label,0.8,0)\nplt.subplot(1,3, 3)\nplt.imshow(dst[:,:,::-1])\nplt.title(\"Blending\")\nplt.show()","cd6a3fc5":"!pip install keras_maskrcnn","9572f718":"!pip install keras_retinanet==0.5.1","fabfc2ab":"# \u0421\u043a\u0430\u0447\u0430\u0435\u043c \u0432\u0435\u0441\u0430 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\n!wget https:\/\/github.com\/fizyr\/keras-maskrcnn\/releases\/download\/0.2.2\/resnet50_coco_v0.2.0.h5","5bec2d3e":"!pip freeze > requirements.txt","229320dd":"# show images inline\n%matplotlib inline\n\n# automatically reload modules when they have changed\n%load_ext autoreload\n%autoreload 2\n\n# import keras\nimport keras\n\n# import keras_retinanet\nfrom keras_maskrcnn import models\nfrom keras_maskrcnn.utils.visualization import draw_mask\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption, draw_annotations\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.colors import label_color\n\n# import miscellaneous modules\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport numpy as np\nimport time\n\n# set tf backend to allow memory to grow, instead of claiming everything\nimport tensorflow as tf\n\ndef get_session():\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    return tf.Session(config=config)\n\n# use this environment flag to change which GPU to use\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\n# set the modified tf session as backend in keras\nkeras.backend.tensorflow_backend.set_session(get_session())","b9ec17f4":"ls","9b56d936":"# adjust this to point to your downloaded\/trained model\nmodel_path = os.path.join('.\/','resnet50_coco_v0.2.0.h5')\n\n# load retinanet model\nmodel = models.load_model(model_path, backbone_name='resnet50')\n#print(model.summary())\n\n# load label to names mapping for visualization purposes\nlabels_to_names = {0: 'person',}","7f58066a":"# load image\nimage = read_image_bgr('..\/input\/coco2017\/train2017\/train2017\/000000281563.jpg')\n\n# copy to draw on\ndraw = image.copy()\ndraw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n# preprocess image for network\nimage = preprocess_image(image)\nimage, scale = resize_image(image)\n\n# process image\nstart = time.time()\noutputs = model.predict_on_batch(np.expand_dims(image, axis=0))\nprint(\"processing time: \", time.time() - start)\n\nboxes  = outputs[-4][0]\nscores = outputs[-3][0]\nlabels = outputs[-2][0]\nmasks  = outputs[-1][0]\n\n# correct for image scale\nboxes \/= scale\n\n# visualize detections\nfor box, score, label, mask in zip(boxes, scores, labels, masks):\n    if score < 0.5:\n        break\n\n    color = label_color(label)\n    \n    b = box.astype(int)\n    draw_box(draw, b, color=color)\n    \n    mask = mask[:, :, label]\n    draw_mask(draw, b, mask, color=label_color(label))\n    \n    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n    #draw_caption(draw, b, caption)\n    \nplt.figure(figsize=(15, 15))\nplt.axis('off')\nplt.imshow(draw)\nplt.show()","eb8c9b4b":"def mask_get (image, model, THRESHOLD=0.5):\n    \n    #image = read_image_bgr(image)\n    # copy to draw on\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    # preprocess image for network\n    image = preprocess_image(image)\n    image, scale = resize_image(image)\n\n    # process image\n    start = time.time()\n    outputs = model.predict_on_batch(np.expand_dims(image, axis=0))\n    #print(\"processing time: \", time.time() - start)\n    draw = np.zeros((draw.shape[0], draw.shape[1], 3), np.uint8)\n\n    boxes  = outputs[-4][0]\n    scores = outputs[-3][0]\n    labels = outputs[-2][0]\n    masks  = outputs[-1][0]\n\n    # correct for image scale\n    boxes \/= scale\n\n    # visualize detections\n    #draw = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n    for box, score, label, mask in zip(boxes, scores, labels, masks):\n        if score < THRESHOLD:\n            break\n        b = box.astype(int)\n        #draw_box(draw, b, color=color)\n        if label == 0:\n            mask = mask[:, :, label]\n            #draw = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n            draw_mask(draw, b, mask, color=label_color(label))\n\n        #caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n        #draw_caption(draw, b, caption)\n\n    mask_out = (draw[:, :, 0] > THRESHOLD).astype(np.uint8)\n    return(mask_out)","e6c807db":"print('\u0421\u0440\u0430\u0437\u0443 \u0441\u0440\u0430\u0432\u043d\u0438\u043c \u0441 \u044d\u0442\u0430\u043b\u043e\u043d\u043e\u043c')\nimage = read_image_bgr('..\/input\/coco2017\/train2017\/train2017\/000000281563.jpg')\nmask_out = mask_get(image, model, THRESHOLD=0.5)\nplt.figure(figsize=(15, 15))\nlabel = cv2.imread(\"..\/input\/coco2017\/stuffthingmaps_trainval2017\/train2017\/000000281563.png\")\nplt.subplot(1,2, 1)\nplt.imshow(mask_out)\nplt.title(\"Predict\")\nplt.subplot(1,2, 2)\nplt.imshow(label[:, :, 0] < 0.5)\nplt.title(\"Label\")\nplt.show()","34971515":"# \u0418\u0437 sample-submission \u0447\u0438\u0442\u0430\u0435\u043c \u043f\u043e \u043a\u0430\u043a\u0438\u043c \u0438\u043c\u0435\u043d\u043d\u043e \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435\nsample_submission = pd.read_csv('..\/input\/sf-dl-person-segmentation\/sample-submission.csv')\nsample_submission.info()\nsample_submission.head()","453e37a2":"# \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043c\u0430\u0441\u043a\u0438 \u0432 EncodedPixels\ndef mask_to_rle(mask):\n    mask_flat = mask.flatten('F')\n    flag = 0\n    rle_list = list()\n    for i in range(mask_flat.shape[0]):\n        if flag == 0:\n            if mask_flat[i] == 1:\n                flag = 1\n                starts = i+1\n                rle_list.append(starts)\n        else:\n            if mask_flat[i] == 0:\n                flag = 0\n                ends = i\n                rle_list.append(ends-starts+1)\n    if flag == 1:\n        ends = mask_flat.shape[0]\n        rle_list.append(ends-starts+1)\n    #sanity check\n    if len(rle_list) % 2 != 0:\n        print('NG')\n    if len(rle_list) == 0:\n        rle = np.nan\n    else:\n        rle = ' '.join(map(str,rle_list))\n    return rle","9b434979":"%%time\n# \u041e\u0441\u0442\u0430\u043b\u043e\u0441\u044c \u0434\u0435\u043b\u043e \u0437\u0430 \u043c\u0430\u043b\u044b\u043c, \n# \u043f\u0440\u043e\u0439\u0442\u0438\u0441\u044c \u043f\u043e \u0441\u043f\u0438\u0441\u043a\u0443 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u044b \u0441 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0438\u043c \u0438\u0445 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0432 EncodedPixels\n# \u042d\u0442\u043e \u0437\u0430\u0439\u043c\u0435\u0442 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0435 \u0432\u0440\u0435\u043c\u044f (\u043e\u043a\u043e\u043b\u043e 8 \u0447\u0430\u0441\u043e\u0432)...\n\nTHRESHOLD=0.5  # \u0441 \u0443\u0440\u043e\u0432\u043d\u0435\u043c \u043e\u0442 \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0441\u0447\u0438\u0442\u0430\u0435\u0442\u044c\u0441\u044f \u043c\u0430\u0441\u043a\u0430 - \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0438\u0433\u0440\u0430\u0442\u044c\u0441\u044f\n\nsubmit_rle_arr = []\n\nfor img_id in tqdm_notebook(sample_submission.ImageId.values):\n    image = read_image_bgr(f'..\/input\/coco2017\/val2017\/{img_id}')\n    mask_out = mask_get(image, model, THRESHOLD=THRESHOLD)\n    rle = mask_to_rle(mask_out)\n    submit_rle_arr.append(rle)","a3cfad89":"sample_submission['EncodedPixels'] = submit_rle_arr\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head()","b56ada11":"### \u041a\u043e\u043f\u0438\u043f\u0430\u0441\u0442\u0438\u043c \u043f\u0440\u0438\u043c\u0435\u0440\n\u0443 keras_maskrcnn \u0435\u0441\u0442\u044c \u043e\u0442\u043b\u0438\u0447\u043d\u044b\u0439 [\u041f\u0440\u0438\u043c\u0435\u0440](https:\/\/github.com\/fizyr\/keras-maskrcnn\/blob\/master\/examples\/ResNet50MaskRCNN.ipynb)  \n\u041f\u0440\u043e\u0441\u0442\u043e \u043a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u043a\u043e\u0434 \u0438\u0437 \u043f\u0440\u0438\u043c\u0435\u0440\u0430, \u0447\u0442\u043e\u0431 \u043f\u043e\u043d\u044f\u0442\u044c \u043a\u0430\u043a \u0432\u0441\u0435 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0441 \u043d\u0430\u0448\u0435\u0439 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u043e\u0439...","895aff99":"# Person Segmentation\n![Person Segmentation](https:\/\/cdn-images-1.medium.com\/max\/1200\/1*UicBY4HeqWEl4l70fTtc6w.png)\n\n\u0412 \u044d\u0442\u043e\u043c \u0440\u0435\u0448\u0435\u043d\u0438\u0438 \u044f \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u044e \u043d\u0435 \u0438\u0437\u043e\u0431\u0440\u0435\u0442\u0430\u0442\u044c \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434...\n\n\u041d\u0435\u043c\u043d\u043e\u0433\u043e \u043f\u043e\u0433\u0443\u0433\u043b\u0438\u0432 \u043c\u043e\u0436\u043d\u043e \u043d\u0430\u0439\u0442\u0438 \u0433\u043e\u0442\u043e\u0432\u044b\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u043d\u0430 \u0411\u0430\u0437\u0435 [Mask-RCNN](https:\/\/github.com\/fizyr\/keras-maskrcnn) \u0438\u043b\u0438 [DeepLab v3+](https:\/\/github.com\/bonlime\/keras-deeplab-v3-plus) \u0441 \u0443\u0436\u0435 **\u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u044b\u043c\u0438 \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438!**\n\u041a\u043e\u0442\u043e\u0440\u044b\u0435 \u043e\u0442\u043b\u0438\u0447\u043d\u043e \u0441\u043f\u0440\u0430\u0432\u043b\u044f\u044e\u0442\u044c\u0441\u044f \u0441 \u0437\u0430\u0434\u0430\u0447\u0435\u0439 \u0421\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u043b\u044e\u0434\u0438\u0435\u0439 (\u0438 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e) \u043f\u0440\u044f\u043c\u043e \"\u0438\u0437 \u043a\u043e\u0440\u043e\u0431\u043a\u0438\". \u041d\u0430\u043c \u043e\u0441\u0442\u0430\u0435\u0442\u044c\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0430\u0434\u0430\u043f\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0440\u0435\u0448\u0435\u043d\u0438\u0435 \u0438\u043c\u0435\u043d\u043d\u043e \u043f\u043e\u0434 \u043d\u0430\u0448\u0443 \u0437\u0430\u0434\u0430\u0447\u0443.\n\n\u0427\u0442\u043e \u0431\u0443\u0434\u0435\u043c \u0434\u0435\u043b\u0430\u0442\u044c:\n> ### \u0411\u0435\u0440\u0435\u043c \u0441\u0435\u0442\u044c Mask-RCNN \u0443\u0436\u0435 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u043d\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 COCO \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u043c\u0430\u0441\u043a\u0443 \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0430 Person \n\n\u042d\u0442\u043e \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u0442 \u0441\u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0442\u044c \u043d\u0430\u043c \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u0441\u0435\u0442\u0438 \u0438 \u0441\u0440\u0430\u0437\u0443 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0445\u043e\u0440\u043e\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442. \u0417\u0432\u0443\u0447\u0438\u0442 \u043d\u0435 \u043f\u043b\u043e\u0445\u043e...\n\n![smart](http:\/\/memesmix.net\/media\/created\/7ncr3w.jpg)","80f0eed4":"### \u0421\u043c\u043e\u0442\u0440\u0438\u0442\u044c\u0441\u044f \u043d\u0435 \u043f\u043b\u043e\u0445\u043e, \u0434\u0430\u0432\u0430\u0439 \u0442\u0435\u043f\u0435\u0440\u044c \u0432\u044b\u043d\u0435\u0441\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u043c\u0430\u0441\u043a\u0443 \u0438 \u0441\u0440\u0430\u0432\u043d\u0438\u043c \u0441 \u044d\u0442\u0430\u043b\u043e\u043d\u043e\u043c.\n\u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0447\u0443\u0442\u044c \u043c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u0443\u0435\u043c \u043a\u043e\u0434 \u0438\u0437 \u043f\u0440\u0438\u043c\u0435\u0440\u0430 (\u0443\u0431\u0435\u0440\u0435\u043c \u0431\u043e\u043a\u0441\u044b \u0438 \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u043c\u0430\u0441\u043a\u0443) \u0438 \u0437\u0430\u0432\u0435\u0440\u043d\u0435\u043c \u0432\u0441\u0435 \u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0447\u0442\u043e\u0431 \u0431\u044b\u043b\u043e \u0443\u0434\u043e\u0431\u043d\u043e \u0441 \u044d\u0442\u0438\u043c \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c","216a8d97":"### \u0422\u0435\u043f\u0435\u0440\u044c \u041f\u043e\u0441\u0442\u0430\u0432\u0438\u043c keras_maskrcnn","dd05c6a0":"### \u0414\u0430\u0436\u0435 \u043d\u0430 \u0442\u0430\u043a\u043e\u043c \u0441\u043b\u043e\u0436\u043d\u043e\u043c \u043f\u0440\u0438\u043c\u0435\u0440\u0435 \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043d\u0435\u043f\u043b\u043e\u0445\u043e\u0439 \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442! \n> \u041a\u0441\u0442\u0430\u0442\u0438, \u0442\u044b \u0437\u0430\u043c\u0435\u0442\u0438\u043b \u0447\u0442\u043e \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0430 \u0441\u0430\u043c\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 COCO \u0434\u0430\u043b\u0435\u043a\u0430 \u043e\u0442 \u0438\u0434\u0435\u0430\u043b\u0430, \u0438 \u0432 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043c\u0435\u0441\u0442\u0430\u0445 \u043c\u043e\u0434\u0435\u043b\u044c \u044d\u0442\u043e \u0434\u0435\u043b\u0430\u0435\u0442 \u0434\u0430\u0436\u0435 \u043b\u0443\u0447\u0448\u0435!  \n> \u042d\u0442\u043e \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u0430\u044f \u043f\u043b\u043e\u0431\u043b\u0435\u043c\u0430 \u044d\u0442\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430, \u043f\u043e \u044d\u0442\u043e\u043c\u0443 \u0434\u043b\u044f \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u043b\u044e\u0434\u0435\u0439 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u044b (\u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 [Supervisely Person Dataset](https:\/\/hackernoon.com\/releasing-supervisely-person-dataset-for-teaching-machines-to-segment-humans-1f1fc1f28469)), \u043d\u043e \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043d\u0430\u043c \u0438 COCO \u0441\u043e\u0439\u0434\u0435\u0442\n\n\u041d\u0430\u043c \u043e\u0441\u0442\u0430\u043b\u043e\u0441\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043f\u0440\u0435\u0434\u0438\u043a\u0442 \u043d\u0430 \u043a\u0430\u0436\u0434\u0443\u044e \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0443 \u0438 \u0437\u0430\u043f\u0438\u0441\u0430\u0442\u044c \u0432 submission \u0432 \u043d\u0443\u0436\u043d\u043e\u043c \u0444\u043e\u0440\u043c\u0430\u0442\u0435.","ae5773b3":"**\u0412\u043e\u0442 \u0438 \u0432\u0441\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u0435!**\n\n### \u041a\u0430\u043a \u043c\u043e\u0436\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442:\n1. \u041f\u043e\u0434\u043e\u0431\u0440\u0430\u0442\u044c THRESHOLD\n2. \u0414\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u0431\u043e\u043b\u0435\u0435 \u0442\u043e\u0447\u043d\u043e\u0439 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u043a\u043b\u0430\u0441\u0441\u0430 Person\n3. \u0421\u0434\u0435\u043b\u0430\u0442\u044c \u0442\u043e\u0436\u0435 \u0441\u0430\u043c\u043e\u0435 \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u043d\u0430 [DeepLab v3+](https:\/\/github.com\/bonlime\/keras-deeplab-v3-plus) \u0438 \u0443\u0441\u0440\u0435\u0434\u043d\u0438\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b (\u0442\u0435 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u044c \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u044d\u0442\u043e\u0436 kaggle, \u043a\u0443\u0434\u0430 \u0442\u0443\u0442 \u0431\u0435\u0437 \u044d\u0442\u043e\u0433\u043e ;) )","9db581a3":"## \u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0432\u0433\u043b\u044f\u043d\u0435\u043c \u043d\u0430 \u0441\u0430\u043c\u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 COCO"}}