{"cell_type":{"5240c3b0":"code","bbf9ea36":"code","6e58a115":"code","3fce8e7e":"code","19374dc2":"code","8ad4d615":"code","9a5efd74":"code","faf0a17f":"code","2a903394":"code","dae4f6c4":"code","2d8ed9bd":"code","831dffe5":"code","486282cc":"markdown","20b92f21":"markdown","3f123455":"markdown","dc752c0a":"markdown","60bc312e":"markdown","e2a3420e":"markdown","161f8c85":"markdown","d1f68fb6":"markdown","c99607aa":"markdown","2e58ad2c":"markdown"},"source":{"5240c3b0":"#Necessary Imports for importing the required modules to be used\nimport pandas as pd\nimport numpy  as np\nimport matplotlib.pyplot as plt\n%matplotlib inline   \n# this makes sure that the graphs are printed in the jupyter notebook itself","bbf9ea36":"#importing the dataset\ndataset= pd.read_csv('..\/input\/polynomial-regression-salaries\/Position_Salaries.csv') \ndataset.head()","6e58a115":"x=dataset.iloc[:,1:2].values\nx","3fce8e7e":"y=dataset.iloc[:,2].values\ny","19374dc2":"# Fitting Linear Regression to the dataset\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(x, y)","8ad4d615":"plt.scatter(x, y, color = 'red')\nplt.plot(x, lin_reg.predict(x), color = 'blue')\nplt.title('Linear Regression')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","9a5efd74":"# Fitting Polynomial Regression to the dataset\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 2)  #trying to create a 2 degree polynomial equation. It simply squares the x as shown in the output\nX_poly = poly_reg.fit_transform(x)\nprint(X_poly)\npoly_reg.fit(X_poly, y)","faf0a17f":"# doing the actual polynomial Regression\nlin_reg_2 = LinearRegression()\nlin_reg_2.fit(X_poly, y)","2a903394":"# Visualising the Polynomial Regression results\nplt.scatter(x, y, color = 'red')\nplt.plot(x, lin_reg_2.predict(poly_reg.fit_transform(x)), color = 'blue')\nplt.title('Polynomial Regression')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","dae4f6c4":"# Fitting Polynomial Regression to the dataset\npoly_reg1 = PolynomialFeatures(degree = 4)\nX_poly1 = poly_reg1.fit_transform(x)\npoly_reg1.fit(X_poly, y)\nlin_reg_3 = LinearRegression()\nlin_reg_3.fit(X_poly1, y)","2d8ed9bd":"# Visualising the Polynomial Regression results\nplt.scatter(x, y, color = 'red')\nplt.plot(x, lin_reg_3.predict(poly_reg1.fit_transform(x)), color = 'blue')\nplt.title('Polynomial Regression of Degree 4')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()","831dffe5":"# Now the question, did you find anything odd in our model????","486282cc":"# <a>When to use Polynomial Regression?<a>\nMany times we may face a requirement where we have to do a regression, but when we plot a graph between a dependent and independent variables, the graph doesn't turn out to be a linear one.\nA linear graph typically looks like:\n<img src=\"https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets%2F888192%2F1510176%2FLinearGraph.jpeg?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1601111443&Signature=BMGD%2BBLhc93ER%2BL%2Fyk8HuxSLkEAsTYK4N1M%2FqEGTrwkSRmJnw2k7NeEAkUu%2FAudxP54k09Ov9ogNgVNqqOsqjL9nRqlWY%2F%2BNrEB5I0cd6Oa0HHmwZafRf9tAp5u4GIPjEDaaibJlMTzIZDdh9Ar8p8%2FO8RX%2FvosewIGWNtZqnR3WCL1Aa0grznAdmCNaMP1sMPgpDP8b9i6nSu6H%2BFe3%2BH8oEUUceY6lJlDWyfH7N1kydgawH3DMfGLF%2BA%2BPc3tJqmguwu%2FYyJoThlQqSJTikyuroGKQTdjSdfdnGSXQgBcm2fu69ZMZ8tBKOxVhyZVDgxyOCl1gpz9LoUWWe%2Fi0%2BQ%3D%3D\" width=\"300\">\n\nBut what if the relationship looks like:\n<img src=\"https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets%2F888192%2F1510176%2FPolynomialGraph.jpeg?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1601111471&Signature=lZsung%2Bfpqyc5PMxIxWelO21Vqb8Dl%2BKUJ%2FCxD5Nt0%2F4v1tsow8eP6hj82yZ%2B5gX2xBKHh5KcHvjV5xtqbtWOYjrFrBaI8z3RDFqCgD5ez7r7jofcTaSzG3ZDfM1Ou6hh45HcNu355pGqSIuB4oyNr27c3H2sSsTB%2BzmNvU%2FKndE5uwQihMaPj5on0JFo8%2FEfxJ8%2FnUh7F0GfLy0iAhiuie1HYkzT%2F530EpasSy4%2F0zkyqdk1CVQiZEoTJ%2FwsOwvaJNcDIsbvdW4G862SopkoNf%2B4lEcpWZ%2BnifF3CK%2FjtbSjq2lAJZYx4aAW1veHTaAHos7epDvClLRdU7sT3q0%2Fw%3D%3D\" width=\"300\">\n\nIt means that the relationship between X and Y can't be described Linearly.\nThen comes the time to use the Polynomial Regression.","20b92f21":"<a>Now our data fits perfectly<\/a>","3f123455":"Here, the red dots are the actual data points and, the blue straight line is what our model has created.\nIt is evident from the diagram above that a Linear model does not fit our dataset well. So, let's try with a Polynomial Model.","dc752c0a":"Generally, we divide our dataset into two parts\n1) The training dataset to train our model. \n2) The test dataset to test our prepared model.\nHere, as the dataset has a limited number of entries, we won't do a split.\nInstead of that, we'd use direct numerical values to test the model.\nHence, the code above is kept commented.\nBut, train test split can also be done, if you desire so:)\n    \nTo learn Polynomial Regression, we'd follow a comparative approach.\nFirst, we'll try to create a Linear Model using Linear Regression and then we'd prepare a Polynomial Regression Model and see how do they compare to each other","60bc312e":"We can generalize the matrix obtained above (for Linear Regression) for an equation of n coefficients(in y=mx+b, m and b are the coefficients) as follows: \n![image.jpeg](https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets%2F888192%2F1511964%2FgeneralEquation.jpeg?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1601111673&Signature=Yqo7LIyDyWe%2B%2BG6wDn%2Bj82TPjv7nHZxnRUdC%2Fo2fA0XLonBUZBRqSYfcxShBsj9UaS8WvOEJVLqJUURKZJ96S7U28Lpa2q1YtAfCjQ4B81qK75qnAbQX%2B97BrU4%2FZQsdJuouB9%2BRPj9cCAO677Mw8VIFKadUFkx9qVguzZU%2FqbO21wXbPEQF9Idh%2FEi9aPVgu%2Foy4t17e3KR4onMkNu%2BSXwaqEM4QeZ%2F3rWQG3AdGox9b1Mwl7k4eT0D7tTEdI%2FDa%2FcBph7A%2BevV3W0KPUurwhhCMSl3bxn7a9RiScyH3d4Zk5mN1NrFhVLKNXlvwm9hip1UJZZBidJ%2Fic6umDlwaQ%3D%3D)\nWhere m is the _degree_(maximum power of x) of the polynomial and n is the number of observation points.\nThe above matrix results in the general formula for Polynomial Regression.\nEarlier, we were able to visualize the calculation of minima because the graph was in three dimensions. But as there are n number of coefficients, it's not possible to create an (n+1)  dimension graph here. ","e2a3420e":"For Linear reg : https:\/\/www.kaggle.com\/farsanas\/linear-regression-e2e","161f8c85":"It can be noted here that for Polynomial Regression also, we are using the Linear Regression Object.\n###### Why is it so?\nIt is because the Linear in Linear Regression does not talk about the degree of the Polynomial equation in terms of the dependent variable(x). Instead, it talks about the degree of the coefficients. Mathematically,\n$$y = {a+bx + cx^2+...+nx^n+...}$$\nIt's not talking about the power of x, but the powers of a,b,c etc.\nAnd as the  coefficients are only of degree 1, hence the name Linear Regression.","d1f68fb6":"Still, a two degree equation is also not a good fit. \nNow, we'll try to increase the degree of the equation i.e. we'll try to see that whether we get a good fit at a higher degree or not.\nAfter some hit and trial, we see that the model get's the best fit for a 4th degree polynomial equation.","c99607aa":"# Polynomial Regression\n\nFor understanding Polynomial Regression, let's first understand a polynomial.\nMerriam-webster defines a polynomial as:\n\"_A mathematical expression of one or more algebraic terms each of which consists of a constant multiplied by one or more variables raised to a non-negative integral power (such as a + bx + cx^2)\"._\nSimply said, poly means many. So, a polynomial is an aggregation of many monomials(or Variables).\nA simple polynomial equation can be written as:\n$$y = {a+bx + cx^2+...+nx^n+...}$$\n\nSo, Polynomial Regression can be defined as a mechanism to predict a _dependent variable_ based on the polynomial relationship with the _independent variable_.\n\n In the equation, _$$y= {a+bx + cx^2+...+nx^n+...}$$_ the maximum power of 'x' is called the degree of the polynomial equation.\n For example, if the degree is 1, the equation becomes $$y={a+bx}$$ which is a simple linear equation.\n              if the degree is 2, the equation becomes $$y = {a+bx + cx^2}$$ which is a quadratic equation and so on.","2e58ad2c":"Here, it can be seen that there are 3 columns in the dataset. The problem statement here is to predict the salary based on the\nPosition and Level of the employee.\nBut we may observe that the Position and the level are related or level is one other way of conveying the position of the employee in the company. So, essentially Position and Level are conveying the same kind of information. As Level is a numeric column, let's use that in our Machine Learning Model.\nHence, Level is our feature or X variable.\nAnd, Salary is Label or the Y variable"}}