{"cell_type":{"725ff165":"code","73e35058":"code","51ab4187":"code","e9de0a22":"code","f2b06f7c":"markdown","9a728014":"markdown"},"source":{"725ff165":"from IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#8F003C','#eb3446','Tourney','Smokum',45,10\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h4 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h4>\"\"\"%string))\n    \nfrom IPython.display import HTML\nHTML(\"\"\"\n<style>\nh1,h2,h3 {\n    margin: 1em 0 0.5em 0;\n    font-weight: 600;\n    font-family: 'Titillium Web', sans-serif;\n    position: relative;  \n    font-size: 25px;\n    line-height: 40px;\n    padding: 10px 10px 10px 2.5%;\n    color: #00018D;\n    box-shadow: \n        inset 0 0 0 1px rgba(97,0,45, 1), \n        inset 0 0 5px rgba(53,86,129, 1),\n        inset -285px 0 35px #F2D8FF;\n    border-radius: 0 10px 0 15px;\n    background: #FFD8B2\n    \n},\n\u200b\nh4 {\n    margin: 1em 0 0.5em 0;\n    font-weight: 600;\n    font-family: 'Titillium Web', sans-serif;\n    position: relative;  \n    font-size: 36px;\n    line-height: 40px;\n    padding: 15px 15px 15px 2.5%;\n    color: #00018D;\n\u200b\n    border-radius: 0 10px 0 15px;\n    background: #FFD8B2\n    \n}\n<\/style>\n\"\"\")","73e35058":"from PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ntrain=pd.read_csv(\"..\/input\/sartorius-cell-instance-segmentation\/train.csv\")\n\ntrain.head(1)\n","51ab4187":"def rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n\n# to visualize a single cell in image\n\n_, axs = plt.subplots(1,2, figsize=(40,15))\n\nenc=train['annotation'][0]\ndec = rle_decode(enc)\n#axs[0].title(\"single cell\")\n\naxs[0].imshow(np.ma.masked_where(dec==0, dec))\n\n#for multiple cells \n\ndf=train[train['id']=='0030fd0e6378']\ndec1=np.zeros((520,704))\nfor j in range(395):\n    dec1+=rle_decode(df['annotation'][j])\n\naxs[1].imshow(np.ma.masked_where(dec1==1,dec1))  \n\naxs[0].set_title(\"single cell\",fontsize=50)\naxs[1].set_title(\"multiple cell\",fontsize=50)\n","e9de0a22":"dec","f2b06f7c":"<h1 style=\"background-color:grey;font-size:20px;color:#00033E;font-weight : bold\"> \ud83d\udc4d   1. Image segmentation:<\/h1>\n\n* differencing objects on pixcel level is **image segmentation** \n\n* image segmentation is of two type Semantic Segmentation and Instance \nSegmentation\n* different objects(sheeps) of same type Instance Segmentation\n\n* In this competition need to identify all neuronal cells in a image. \nthe identified cells must be encoded and put for submission,\n\n* check this discussion what is RLE(encoding)[@revathiprakash](https:\/\/www.kaggle.com\/c\/sartorius-cell-instance-segmentation\/discussion\/278936)\n\n\n![asd](https:\/\/valueml.com\/wp-content\/uploads\/2020\/11\/DV8TLgkWsAEGsEs-1024x485.jpg)\n","9a728014":"<h1 style=\"background-color:grey;font-size:20px;color:#00033E;font-weight : bold\"> \ud83d\udc4d   2. understanding Data:<\/h1>\n\n**in each row the annotation column here is pixels that represents a individual cell in image with id**\n\n**there can be multiple cells in an image**\n"}}