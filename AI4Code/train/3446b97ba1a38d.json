{"cell_type":{"a7434b9b":"code","31c9e2ee":"code","87536ee1":"code","6aa0f09f":"code","a5341371":"code","eb739a3f":"code","d0af9315":"code","bf0a2c1d":"code","42fc0f94":"code","34844d11":"code","f3d2ee40":"code","e59c04b6":"code","2f24b328":"code","5ad16a54":"code","f5106a4c":"code","7afdfd89":"code","ea284d4a":"code","a8ed15e0":"code","e9a84638":"code","f449740b":"code","e813e1a3":"code","bdcfe005":"code","c9f356f9":"code","94c78620":"code","2197f456":"code","20fd207b":"code","0238c015":"code","b910058b":"code","1071600b":"code","fc04ebcf":"code","807d9028":"code","97a62830":"code","03b4bbae":"code","63f64857":"code","120d7f07":"code","4b2ff742":"code","bfb213bd":"code","bbc1064a":"code","66e6942a":"code","4246cf02":"code","0e1e9c5a":"code","9e8f9cc8":"code","bd827342":"code","ccb969ad":"code","0681cab8":"code","b661d39c":"code","aed3fc86":"code","936f0b15":"code","38a98d48":"code","45cafeb1":"code","87b900d8":"code","e2ad56ba":"code","3bb29d3c":"code","4cbcfbc6":"code","ff7895dd":"code","ef62f0db":"code","4c9c0741":"markdown","1f8c9a2f":"markdown","1125ea7e":"markdown","732946f2":"markdown","ce48b303":"markdown","5c8eb940":"markdown","9b9bbddb":"markdown","a6acad5a":"markdown","cd07cc1c":"markdown","15f378f4":"markdown","e588fa1e":"markdown","51de878f":"markdown","3ac452d6":"markdown","864db6db":"markdown","0ef3679d":"markdown","392c187c":"markdown","8f1bd91b":"markdown","eb0e0210":"markdown","c33bb559":"markdown","df320110":"markdown","ffe2b2c6":"markdown","2f25ccd2":"markdown","7a523d75":"markdown","afe819e0":"markdown","592e2c65":"markdown","c9743a06":"markdown","a284f824":"markdown","e59b84d6":"markdown","6961bfe6":"markdown","fd1d62ac":"markdown","042fcee5":"markdown","07653ebb":"markdown","000a0d30":"markdown","f7e67804":"markdown","1d61707b":"markdown","a24d469d":"markdown","d69e21d2":"markdown","41ab8384":"markdown","a9d7515d":"markdown","49cfd395":"markdown","10e46d92":"markdown","7cbdd14c":"markdown","6ba3d840":"markdown","829d3091":"markdown","71dee5f8":"markdown","db0695ec":"markdown","fb491c2f":"markdown","bced80bf":"markdown","6d963b26":"markdown","ec0c7e69":"markdown","d99e8164":"markdown","50f6a0f4":"markdown","485ceca9":"markdown","34eb438a":"markdown","a8529ef1":"markdown","f92e3c37":"markdown"},"source":{"a7434b9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","31c9e2ee":"#Read in 'User' dataset containing information about users\nusers = pd.read_csv('..\/input\/users.csv')\n#Read in 'tweets' dataset containing actual tweets\ntweets = pd.read_csv('..\/input\/tweets.csv')","87536ee1":"#First five rows of users dataset\nusers.head()","6aa0f09f":"#create a simplified users dataset\nusers = users.iloc[:,[0,3,7,8,10,12]]\nusers.head()","a5341371":"#Let's look at the first 5 rows of the tweets dataset\ntweets.head()","eb739a3f":"#create a simplified tweets df\ntweets = tweets.iloc[:,[0,1,2,3,7,8,10]]\ntweets.head()","d0af9315":"#Plot the relationship between the number of a user's \"friends\" and \"followers\"\nsns.scatterplot(x=users['friends_count'], y=users['followers_count'])\nplt.xlabel('Number of Friends')\nplt.ylabel('Number of Followers')\nplt.show()","bf0a2c1d":"#subset and copy users df to include only users with 'friend_count' > 0\nclean_users = users[users['friends_count'] > 0].copy()\n#create new column containing the ratio for follower to friends\nclean_users['f_f_ratio'] = clean_users['followers_count'] \/ clean_users['friends_count']\nclean_users['f_f_ratio'].describe(percentiles = [0.5,0.6,0.7,0.8,0.9])","42fc0f94":"#subset users data based on the f_f_ratio, using a threshold of 2 followers to friends\npopular = clean_users[clean_users['f_f_ratio'] > 2].copy()\nunpopular = clean_users[clean_users['f_f_ratio'] < 2].copy()\nper_popular = popular.shape[0] \/ clean_users.shape[0] *100\nprint(per_popular)","34844d11":"popular.sort_values(['f_f_ratio'],ascending=False).head(10)","f3d2ee40":"#Plot 'friends' vs. 'followers' with points colored by language\nsns.scatterplot(x='friends_count',y='followers_count',hue='lang',data=clean_users)\nplt.xlim(-10000,40000)\nplt.show()","e59c04b6":"print('Fraction of popular accounts that are Russian language users')\nprint(popular[popular['lang']=='ru'].shape[0]\/popular.shape[0])","2f24b328":"#subset popular df by english language users\nen_pop = popular.loc[popular['lang'] == 'en','screen_name'].str.lower().values\nprint(en_pop)\n    ","5ad16a54":"#convert popular users' screen names to 'user_key' format\npop_peeps = popular['screen_name'].str.lower().values\n#convert unpopular users' screen names to 'user_key' format\nunpop_peeps = unpopular['screen_name'].str.lower().values\n#no_friends 'user_keys'\nno_friends = users.loc[users['friends_count'] == 0,'screen_name'].str.lower().values\n#all 'user_keys'\nall_users = users['screen_name'].str.lower().values","f5106a4c":"#count total number of tweets in tweets df for popular vs unpopular vs all users\nname_list = ['popular','unpopular','all']\nlist_list = [pop_peeps,unpop_peeps,all_users]\ncount_list = []\nfor el in list_list:\n    count = 0\n    for peep in el:\n        pop = tweets[tweets['user_key'] == peep]\n        count += pop.shape[0]\n    count_list.append(count)\nfor i in range(0,3):\n    print('percent of tweets from {} people: {}'.format(name_list[i],count_list[i]\/tweets.shape[0]*100))\n        ","7afdfd89":"#calculate the percent of tweet influence (among those users included in the popular and unpopular dataframes)\n#accounted for by 'popular' vs 'unpopular' users\n\n\ndf_list = [popular,unpopular]\nname_list = ['popular','unpopular']\ndf_count = []\n#iterate through screen_name col\nfor df in df_list:\n    count = 0\n    for peep in df['screen_name'].values:\n        #count number of followers for a given user in users df\n        followers = int(users.loc[users['screen_name']==peep,'followers_count'])\n        #convert screen_name to user_key\n        uk = peep.lower()\n        #count tweets from a given user in tweets df\n        pop = tweets[tweets['user_key'] == uk]\n        tweet_count = pop.shape[0]\n        #scale tweets by number of followers\n        mag = followers * tweet_count\n        count += mag\n    df_count.append(count)    \n#print(df_count)\nfor i in range(0,2):\n    print('Percent of tweet influence attributable to {} people: {}'.format(name_list[i],(df_count[i]\/sum(df_count)*100)))\n\n","ea284d4a":"#convert created_at column to datetime objects and plot a histogram of creation years\nusers['created_at'] = pd.to_datetime(users['created_at'])\nyears = users['created_at'].dt.year\nyears.plot(kind='hist')\nplt.xlabel('Account Created (Year)')\nplt.show()","a8ed15e0":"#Convert created_at to datetime and plot histograms of creation years for popular and unpopular users\npopular['created_at'] = pd.to_datetime(popular['created_at'])\npop_years = popular['created_at'].dt.year\nunpopular['created_at'] = pd.to_datetime(unpopular['created_at'])\nunpop_years = unpopular['created_at'].dt.year\nplt.hist([pop_years,unpop_years], alpha=0.5,label = ['Popular','Unpopular'])\nplt.xlabel('Account Created (Year)')\nplt.ylabel('Frequency')\nplt.legend(loc='upper left')\nplt.show()","e9a84638":"#Plot histogram of creation date by month in the year 2014\npop_year = popular[popular['created_at'].dt.year == 2014]\nplt.hist(pop_year['created_at'].dt.month,bins=12)\nplt.xlabel('Month (1-12)')\nplt.ylabel('Frequency')\nplt.show()","f449740b":"#Plot histograms of creation dates by month over the years 2013-2016 for unpopular accounts\nmonths_list = []\nyr_list = [2013,2014,2015,2016]\nfor el in yr_list:\n    df = unpopular[unpopular['created_at'].dt.year == el]\n    months = df['created_at'].dt.month\n    months_list.append(months)\n\nplt.hist(months_list,alpha = 0.5, label = ['2013','2014','2015','2016'])\nplt.xlabel('Month (1-12)')\nplt.ylabel('Frequency')\nplt.legend(loc='upper left')         \nplt.show()","e813e1a3":"#create a dictionary to replace 'user_key' values in tweets df with 'screen_name' values\nusers['lower'] = users['screen_name'].str.lower()\ns_name = users.screen_name.values\nlower = users.lower.values\nconversion = dict(zip(lower,s_name))","bdcfe005":"#replace 'user_keys' with 'screen_names' in tweets dataframe\ntweets['user_key'].replace(conversion,inplace=True)\ntweets.head()","c9f356f9":"#create a new True\/False column indicating whether the tweet is a retweet\ntweets['is_retweet'] = tweets['text'].str.contains('RT @')\ntweets['is_retweet'].mean()","94c78620":"#create a new row in tweets containing the screen_name of the user who is being retweeted if applicable\ntweets['RT_source'] = tweets['text'].str.extract(r'@(\\S+):')\ntweets['RT_source'].fillna('None',inplace=True)\n                      \ntweets['RT_source'].head()","2197f456":"#create a list of the unique screen_names\nuser_list = tweets['user_key'].unique()\n\n#Define a function to test whether a value is part of the user_list (for apply function below)\ndef test_in(el):\n    return (el in user_list)\n\n#create a new column in tweets indicating whether the source of a retweeted tweet was in our list of Russian screen_names\ntweets['RT_from_user_list'] = tweets['RT_source'].apply(test_in)\n#find fraction of all tweets that were retweeting tweets from a Russian troll\ntweets['RT_from_user_list'].mean()","20fd207b":"#Create a new column in tweets indicating T\/F of whether a RT was originally composed by the same user\ntweets['RT_self'] = tweets['user_key'] == tweets['RT_source']\ntweets['RT_self'].mean()","0238c015":"tweets.loc[tweets['RT_from_user_list'] == True, 'RT_source'].value_counts().head(10)\ntop_retweeted = tweets.loc[tweets['RT_from_user_list'] == True, 'RT_source'].value_counts().head(10).index\nprint(top_retweeted)","b910058b":"top_retweeted = tweets.loc[tweets['RT_from_user_list'] == True, 'RT_source'].value_counts().head(20).index\nfrac_RT = []\nfor user in top_retweeted:\n    is_rt = round(tweets.loc[tweets['user_key'] == user,'is_retweet'].mean(),2)\n    frac_RT.append(is_rt)\n    per_rt = is_rt *100\n    print('{}% of {}\\'s tweets were retweets'.format(per_rt,user))\nprint(frac_RT)    ","1071600b":"tweets.loc[tweets['RT_from_user_list'] == False,'RT_source'].value_counts().head(10)","fc04ebcf":"tweets['user_key'].value_counts().head(10)","807d9028":"top_tweeter = tweets['user_key'].value_counts().head(20).index\ntop_frac_RT = []\nfor user in top_tweeter:\n    is_rt = round(tweets.loc[tweets['user_key'] == user,'is_retweet'].mean(),2)\n    top_frac_RT.append(is_rt)\n    per_rt = is_rt *100\n    print('{}% of {}\\'s tweets were retweets'.format(per_rt,user))\nprint(top_frac_RT) ","97a62830":"#Create a simplified df containing only 'user_key','created_str','RT_source' and dropna rows\nsimple = tweets.iloc[:,[1,3,8]].dropna().copy()\n#convert 'created_str' to datetime object\nsimple['created_str'] = pd.to_datetime(simple['created_str'])\n#collect hour attribute in a new column\nsimple['hour'] = simple['created_str'].dt.hour.astype(float)\n#print(simple.head())\n\n\n#Function that accepts a list of users and the 'user_key' or 'source' column names as input\n#Generates a count of a users tweets for each hour of the day\n#Returns a dictionary mapping a 'user_key' or a 'source' to a list containing the hourly tweet count\ndef hour_hist(user_list,column,RT_col = False):\n    time_dict = {}\n    for user in user_list:\n        #print(user)\n        if user in simple[column].tolist():\n            #print(user)\n            time_list = simple.loc[simple[column]==user,'hour'].tolist()\n            #print(time_list)\n            count_list = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n            for el in time_list:\n                int_el = int(el)\n                count_list[int_el] += 1\n            #print(count_list)    \n            sum_count = sum(count_list)\n            #print(sum_count)\n            new_list = [el\/sum_count for el in count_list]\n            if RT_col == True:\n                rt_frac = round(tweets.loc[tweets['user_key'] == user,'is_retweet'].mean(),2)\n                new_list.append(rt_frac)\n                time_dict[user] = new_list\n                data_frame = pd.DataFrame.from_dict(time_dict,orient='index')\n                data_frame.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,'RT']\n            else:\n                time_dict[user] = new_list\n                data_frame = pd.DataFrame.from_dict(time_dict,orient='index')\n                #print(data_frame.head())\n                data_frame.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n    return data_frame \n","03b4bbae":"#Tweet pattern all tweets\nall_users = tweets['user_key'].unique().tolist()\n#print(all_users)\n#all_user_dict = hour_hist(all_users, 'user_key')\nall_heat = hour_hist(all_users,'user_key',RT_col=True)\n   \nsns.clustermap(all_heat,metric='minkowski',col_cluster=False,robust=True)","63f64857":"\n#Tweet pattern for users with >90% original tweets\noriginals = all_heat.loc[all_heat['RT'] < 0.1].index\n#Create heatmap dataframe\noriginal_heat = hour_hist(originals,'user_key')\n#display clustermap   \nsns.clustermap(original_heat,metric='minkowski',col_cluster=False,robust=True)","120d7f07":"#create a list of the top 20 tweeters in the tweets dataset\ntop_twenty = simple['user_key'].value_counts().head(20).index\n#create heatmap dataframe.\ntwenty_time_heat = hour_hist(top_twenty, 'user_key',RT_col=True)\n#Plot a clustered heatmap to show tweeting patterns over a 24 hour period for the top 20 tweeters\nsns.clustermap(twenty_time_heat,metric='minkowski',col_cluster=False,robust=True)\n","4b2ff742":"#Tweet pattern of top 20 most retweeted users\nretweet_top_twenty = tweets.loc[tweets['RT_from_user_list'] == True, 'RT_source'].value_counts().head(20).index\n#Create heatmap dataframe\nRT_heat = hour_hist(retweet_top_twenty,'user_key',RT_col=True)\n#Plot clustered heatmap\nsns.clustermap(RT_heat,metric='minkowski',col_cluster=False,robust=True)","bfb213bd":"#Pattern of tweets that are retweeting the most commonly retweeted users OUTSIDE of Russian user set\nout_rt_top_twenty = tweets.loc[tweets['RT_from_user_list'] == False, 'RT_source'].value_counts().head(20).index\n\n#Create heatmap dataframe, RT column is omitted because it obscures tweet pattern data\nout_rt_heat = hour_hist(out_rt_top_twenty,'RT_source')\n#Show clustermap\nsns.clustermap(out_rt_heat,metric='minkowski',col_cluster=False,robust=True)","bbc1064a":"#What is the tweet time distribution for users pretending to be news outlets?\n\n#List of words commonly associated with news outlets\nnews_word_list = ['today','post','online','new','voice']\njoined_news = '|'.join(news_word_list)\n#lower case all users\nlower_users = tweets['user_key'].str.lower()\n#create array of unique 'news' users\nnews_users = tweets.loc[lower_users.str.contains(joined_news),'user_key'].unique()\n#Create heatmap dataframe \nnews_heat = hour_hist(news_users,'user_key',RT_col=True) \n#display clustermap                       \nsns.clustermap(news_heat,metric='minkowski',col_cluster=False,robust=True)\n","66e6942a":"#Copy tweets dataframe, removing rows that have na values for text\nnew_tweets = tweets.loc[tweets['text'].notna()].copy() \n#Remove the RT @xyz: part of a tweet by splitting text at : that is NOT preceded by https\nsplit = new_tweets['text'].str.split(r'(?<!https):',n=1,expand=True)\n#Take the column containing the RT-free text, fill Na values with the left column for those tweets that were not retweets\nsplit[1].fillna(split[0],inplace=True)\n#Add this new 'clean_text' column to the new_tweets data frame\nnew_tweets['clean_text'] = split[1]\n#Clean up the 'clean_text' column further, by removing hashtags, mentions, #, @, and other various symbols\nnew_tweets['clean_text'] = (new_tweets['clean_text']\n                                .str.replace('7yrs','')\n                                #remove hashtags\n                                .str.replace(r'(?<=#)[A-Za-z0-9]+','')\n                                #remove mentions\n                                .str.replace(r'(?<=@)[A-Za-z0-9]+','')\n                                #.str.lstrip('#')\n                                .str.strip('[# ]+')\n                                .str.strip('[@ ]+')\n                                .str.strip(')')\n                                .str.strip('(')\n                                .str.strip('lol')\n                                .str.strip('\"')\n                                .str.strip(u'\\u2026')\n                                .str.strip('#')\n                                .str.lstrip(':')\n                                .str.strip(' ')\n                            \n                           )\nnew_tweets.head()","4246cf02":"#Create a list of strings containing the 200 most retweeted 'core' tweets\nstring_list = new_tweets['clean_text'].value_counts(dropna=True).head(200).index\n\ndef time_diff(df):\n    #This function takes a dataframe as input, which should be structured like the new_tweets df\n    #creates a subsetted df with a selection of the columns, converts tweet time to datetime, subtracts\n    #datetime object from the original tweet time, and returns a dataframe with a new column 'time_diff'\n    #with the time difference from the original tweet presented in hours. This is a helper function for time_df_list (below)\n    \n    s_df = df.iloc[:,[1,3,4,7,8,9,10,11]].copy()\n    s_df['created_str'] = pd.to_datetime(s_df['created_str'])\n    s_df.sort_values(by='created_str',ascending=True,inplace=True)\n    #initialize a list of time differences; the first element is the first tweet minus itself, so 0\n    time_diff_list = [0]\n    #subtract the time of each tweet from the time of the first tweet\n    for i in range (1, len(s_df['created_str'])):\n        time_diff = s_df.iloc[i,1] - s_df.iloc[0,1]\n        #represent time differences in hours \n        time_diff_list.append(time_diff.total_seconds()\/3600)\n    #add a column to the subsetted data frame with the time difference values\n    s_df['time_diff'] = time_diff_list\n    #sort time_diff column\n    s_df.sort_values(by='time_diff',ascending=True, inplace=True)\n    return s_df\n    \ndef time_df_list(tweet_list,chain_plots=False):\n    #initialize a list to contain dataframes for each tweet\n    df_list = []\n    #iterate over 'core' tweet list\n    for el in tweet_list:\n        #subset dataframe to include only tweets with a given 'clean_text'\n        df = new_tweets[new_tweets['clean_text'] == el]\n        if chain_plots == False:\n            #size variable counts the number of times this text has been retweeted\n            size = df.shape[0]\n            #If the text is not an empty string, and it has been retweeted more than 10 times, create a small\n            #dataframe with select columns, convert the 'created_str' column to datetimes, and sort from first to last\n            if (el != '') & (size > 10):\n                s_df = time_diff(df)\n                #append sorted data frame to list of dataframes\n                df_list.append(s_df)\n        else:\n            #this definition of size selects for those retweet patterns where there is a chain of single retweets\n            size = df.shape[0] \/ len(df['user_key'].unique())\n            if (el != '') & (size < 2):\n                s_df = time_diff(df)\n                #append sorted data frame to list of dataframes\n                df_list.append(s_df)\n    return df_list\n\ntext_df_list = time_df_list(string_list[:20])\n\n#plot catplots one at a time (this was the cleanest way I found to do this, otherwise there were issues with facets in the figure)\nfor i in range(0,len(text_df_list)-1):\n    p = sns.catplot(data=text_df_list[i],x='time_diff',y='user_key',col='clean_text',aspect=2)\n    p.set_titles('{col_name}')\n    p.set_xlabels('Time From First Tweet (Hours)')\n    \n","0e1e9c5a":"#create dataframe list for chain retweets\nchain_df_list = time_df_list(string_list,chain_plots=True)\n#plot chains\nfor i in range(0,10):\n    p = sns.catplot(data=chain_df_list[i],x='time_diff',y='user_key',col='clean_text',hue='RT_source',aspect=2)\n    p.set_titles('{col_name}')\n    p.set_xlabels('Time From First Tweet (Hours)')\n","9e8f9cc8":"#Create a list of the top 40 users retweeting other Russian users\nin_rt_top_forty = tweets.loc[tweets['RT_from_user_list'] == True, 'user_key'].value_counts().head(40).index\n\n#This effectively creates a heatmap of a user's typical position in the retweet chain\nuser_position_dict = {}\nfor user in in_rt_top_forty:\n    #print(user)\n    position_dict = {}\n    #iterate through chain tweet dataframes\n    for i in range(0,len(chain_df_list)):\n        now_df = chain_df_list[i].copy()\n        #reset index to be able to access index as integers\n        now_df.reset_index(inplace=True)\n        #test if user is in the 'user_key' column of people who retweeted a given tweet\n        if user in now_df['user_key'].tolist():\n            #capture the position of that user in the sequence of retweets as a list (sometimes a person tweets twice)\n            positions = now_df.index[now_df['user_key']==user].tolist()\n            #Pick the first occasion that the person tweeted (if multiple tweets)\n            first_position = positions[0]\n            #Count the number of times that person tweets at a given position in the sequence of retweets\n            if first_position in position_dict:\n                position_dict[first_position] += 1\n            else:\n                position_dict[first_position] = 1\n        \n        else:\n            pass\n    #map the position_dict to the user_key\n    user_position_dict[user] = position_dict\n#create a dataframe from the dictionary        \nsequence = pd.DataFrame.from_dict(user_position_dict,orient='index')   \n#sequence","bd827342":"#get columns names\ncols = sequence.columns\n#sort columns numerically and take only the first 12\ncols = sorted(cols)[:12]\n#sort columns and create a new dataframe n_sequence\nn_sequence = sequence[cols].copy()\n#replace na values with 0\nn_sequence.fillna(0,inplace=True)\n#Display clustermap\nsns.clustermap(n_sequence,metric='minkowski',col_cluster=False)","ccb969ad":"edge_list = []\n#iterate over the first 10 users in the top_retweeted list\nfor user in top_retweeted[:10]:\n    #initialize a dataframe to consolidate 'edges' - connections between a source and a retweeter\n    edge_df = pd.DataFrame()\n    #collect all retweets from a given source, and present the 'RT_source' column\n    edge_df['source'] = tweets.loc[(tweets['is_retweet']==True) & (tweets['RT_source']==user),'RT_source']\n    #collect all retweets from a given source, and present the 'user_key' column\n    edge_df['user'] = tweets.loc[(tweets['is_retweet']==True) & (tweets['RT_source']==user),'user_key']\n    #create an array of the top twenty users who retweeted the source \n    top_retweeters = edge_df['user'].value_counts().head(20).index\n    #Create a list of (source,retweeter) tuples\n    top_list = list(zip([user]*len(top_retweeters),top_retweeters))\n    for el in top_list:\n        #add each edge for each top_retweeted source to the edge_list\n        edge_list.append(el)\n","0681cab8":"import networkx as nx\n#Create a directional graph object\nB = nx.DiGraph()\n#Populate the graph with connections in edge_list\nB.add_edges_from(edge_list)\n#calculate in_degree_centrality for each person in the graph\n#this is the number of edges that end at a given user divided by the total number of users\n#in this case it reflects how many people a given person retweets\nin_deg_dict = nx.in_degree_centrality(B)\n#create the 'central' dataframe from the in_deg_dict dictionary\ncentral = pd.DataFrame.from_dict(in_deg_dict,orient='index')\n#sort dataframe by in-degree values\ncentral = central.sort_values(by=0,ascending=False)\n#assign top 20 retweeters to the top_retweeter variable\ntop_retweeter = central.head(20).index\n\nprint(top_retweeter)","b661d39c":"#This code was modified from code found here: https:\/\/bokeh.pydata.org\/en\/latest\/docs\/user_guide\/graph.html\nfrom bokeh.io import show, output_notebook\nfrom bokeh.models import Plot, Range1d, MultiLine, Circle, HoverTool, BoxZoomTool, ResetTool\nfrom bokeh.models.graphs import from_networkx\n\n\n#top 20 most retweeted users\ntop_retweeted = tweets.loc[tweets['RT_from_user_list'] == True, 'RT_source'].value_counts().head(20).index\n#list of 10 colors for the top 10 most retweeted users\ncolors = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2','#7f7f7f','#bcbd22','#17becf']\n#Create a dict mapping a user to a color\ntop_rt_map = dict(zip(top_retweeted,colors))\n\n#SET EDGE COLORS\n#initialize the edge_attr dictionary\nedge_attr = {}\n#iterate over edges list for the graph\nfor start_node,end_node, _ in B.edges(data=True):\n    #define color based on the start node (retweeted user) in the user:color dictionary above\n    color = top_rt_map[start_node]\n    #map the edge to the color selected above\n    edge_attr[(start_node, end_node)] = color\n#create a new attribute of the edges in B called edge color, using the edge_attr dictionary  \nnx.set_edge_attributes(B, edge_attr, \"edge_color\")\n\n#SET NODE COLOR AND SIZE\n#initialize dicts to map a user's node to a color and size\ncolor_map = {}\nsize_map = {}\n#iterate through nodes in the B graph (this is a tuple ('user_key',{}), so we need to access the first element)\nfor node in B.nodes(data=True):\n    #Test if user is in the top 10 retweeted set\n    if node[0] in top_rt_map:\n        #if yes, assign the color using the dictionary above, and the size = 15\n        color_map[node[0]] = top_rt_map[node[0]]\n        size_map[node[0]] = 15\n    #Test if the user is one of the top 20 retweeters in the top_retweeter list (above)\n    elif node[0] in top_retweeter:\n        #if so color the user's node black and set size at 8\n        color_map[node[0]] = 'black'\n        size_map[node[0]] = 8\n    #if not either of these things, set users color grey and size 4\n    else:\n        color_map[node[0]] = 'grey'\n        size_map[node[0]] = 4\n\n#create and set node attibutes 'color' and 'size' using the dictionaries created above       \nnx.set_node_attributes(B, color_map, 'color')\nnx.set_node_attributes(B, size_map,'size')\n\n#Show with Bokeh\n#Initialize a plot object with the given size and title\nplot = Plot(plot_width=500, plot_height=500,\n            x_range=Range1d(-1.1, 1.1), y_range=Range1d(-1.1, 1.1))\nplot.title.text = \"Linkage Between Top 10 retweeted users and their Top 20 retweeters\"\n#Initialize this cool node_hover_tool, which allows users to inspect node identity\nnode_hover_tool = HoverTool(tooltips=[(\"index\", \"@index\")])\n#add the hover_tool, zoomtool, and resettool to the plot\nplot.add_tools(node_hover_tool, BoxZoomTool(), ResetTool())\n\n#create a graph renderer using the data in B, applying a circular layout\ngraph_renderer = from_networkx(B, nx.circular_layout, scale=1, center=(0, 0))\n#render the nodes using circles, with the size and color defined according to the node attributes set above\ngraph_renderer.node_renderer.glyph = Circle(size='size', fill_color='color',fill_alpha=1,line_color='color')\n#render the edges with the edge_color defined in the edge attributes\ngraph_renderer.edge_renderer.glyph = MultiLine(line_color='edge_color', line_alpha=0.8, line_width=1)\n#add the rendered data to the plot\nplot.renderers.append(graph_renderer)\n#display plot in notebook setting\noutput_notebook()\nshow(plot)","aed3fc86":"#Create array of top 50 retweeters\ntop_fifty_rt = tweets.loc[tweets['is_retweet'] == True, 'user_key'].value_counts().head(50).index\n\n#Create an edge list mapping each of the top 50 retweeters to their top source, and collect their number of\n#retweetes in the size_df_dict\nin_edge_list = []\nsource_list = []\nsize_df_dict = {}\nfor user in top_fifty_rt:\n    #create data frame mapping sources to retweeters \n    edge_df = pd.DataFrame()\n    edge_df['source'] = tweets.loc[(tweets['is_retweet']==True) & (tweets['user_key']==user),'RT_source']\n    edge_df['user'] = tweets.loc[(tweets['is_retweet']==True) & (tweets['user_key']==user),'user_key']\n    #count number of retweets for a given retweeter\n    rt_count = edge_df.shape[0]\n    #map user_key to number of tweets\n    size_df_dict[user]=rt_count\n    #find the most common source for a given retweeter\n    top_source = edge_df['source'].value_counts().head(1).index[0]\n    source_list.append(top_source)\n    in_edge_list.append((top_source,user))  ","936f0b15":"#The purpose of this block of code is to make it possible to visualize tweet number in the graph below\n#This is a way of binning the number of tweets into discrete bins in the range (fewest_retweets to most_retweets)\nmost_tweets = max(size_df_dict.values())\nfewest_tweets = min(size_df_dict.values())\n#Create a list of numbers linearly spaced from fewest to most tweeets, with a length = to the number of values\ntweet_range = np.linspace(fewest_tweets,most_tweets,len(size_df_dict.values()))\n#Iterate over the users in the size_df_dict\nfor user in size_df_dict:\n    #iterate over each bin of the tweet_range list\n    for i in range(len(tweet_range)-1):\n        tweet_bin_lo = tweet_range[i]\n        tweet_bin_hi = tweet_range[i+1]\n        #if the number of tweets falls within a given bin, remap the user to the bin number in the size_df_dict\n        if (size_df_dict[user] >= tweet_bin_lo) & (size_df_dict[user]<=tweet_bin_hi):\n            size_df_dict[user] = i      ","38a98d48":"#Create a directional graph object\nG = nx.DiGraph()\n#Populate graph using in_edge_list data\nG.add_edges_from(in_edge_list)\n#set size of nodes based on the size_df_dict created above\nnx.set_node_attributes(G,size_df_dict,'df_size')","45cafeb1":"#create a dictionary mapping the unique top sources to colors\nimport bokeh.palettes as bp\nunique_source = set(source_list)\nunique_list = list(unique_source)\n#create a list of colors from the viridis palette with a length equal to the number of unique sources\ncolors = bp.viridis(len(unique_source))\nsource_color = [(unique_list[i],colors[i]) for i in range(len(unique_source))]\n#map each source to a color\nsource_map = dict(source_color)   ","87b900d8":"#COLOR EDGES BASED ON SOURCE COLOR\nedge_attr = {}\nfor start_node,end_node, _ in G.edges(data=True):\n    color = source_map[start_node]\n    edge_attr[(start_node, end_node)] = color\nnx.set_edge_attributes(G, edge_attr, \"edge_color\")\n\n#COLOR NODES IF IN SOURCE:COLOR Dictionary, else grey\ncolor_map = {}\nfor node in G.nodes(data=True):\n    #print(node[1])\n    if node[0] in source_map:\n        color_map[node[0]] = source_map[node[0]]\n    else:\n        color_map[node[0]] = 'grey'\n\n#SCALE NODES in proportion to a given user's number of retweets (if in the top retweeter list), else size=4\nsize_map = {}\nfor node in G.nodes(data=True):\n    if node[0] in size_df_dict:\n        size_map[node[0]] = size_df_dict[node[0]]\n    else:\n        size_map[node[0]] = 4\n        \n#set node color and size attributes using the dictionaries created above        \nnx.set_node_attributes(G, color_map, 'color')\nnx.set_node_attributes(G, size_map,'size')\n\n#Create a large bokeh plot object and title\nplot = Plot(plot_width=800, plot_height=800,\n            x_range=Range1d(-2, 2), y_range=Range1d(-2, 2))\nplot.title.text = \"Linkage Between Top 50 retweeters and their Respective Top Sources\"\n#initialize and add plot tools\nnode_hover_tool = HoverTool(tooltips=[(\"index\", \"@index\")])\nplot.add_tools(node_hover_tool, BoxZoomTool(), ResetTool())\n#initialize renderer using data from G, render nodes and edges using the attributes set above\ngraph_renderer = from_networkx(G, nx.circular_layout, scale=1.8, center=(0, 0))\ngraph_renderer.node_renderer.glyph = Circle(size='size', fill_color='color',fill_alpha=0.7,line_color='color')\ngraph_renderer.edge_renderer.glyph = MultiLine(line_color='edge_color', line_alpha=0.8, line_width=2)\nplot.renderers.append(graph_renderer)\n\noutput_notebook()\nshow(plot)","e2ad56ba":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import wordpunct_tokenize\n\n#create a set of words to ignore in the text\nstop = set(stopwords.words('english'))\n#add some additional tweet specific characters and words\nstop.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', '@', '#', 'rt', 'amp','https','co','http','u'])\n\n#create separate word compilations for RT_from_user_list == True and RT_from_user_list == False\nfor el in [True,False]:\n    series_tweets = new_tweets.loc[new_tweets['RT_from_user_list'] == el,'clean_text']\n    #concatenate clean text column into a single string separated by spaces\n    tweet_str = series_tweets.str.cat(sep = ' ')\n    #create a lower case word list if the word is not in the stop lists and is alphanumeric\n    word_list = [i.lower() for i in wordpunct_tokenize(tweet_str) if i.lower() not in stop and i.isalpha()]\n    #create a frequency distribution of bigrams in the current word list\n    wordfreqdist = nltk.FreqDist(list(nltk.bigrams(word_list)))\n    #find 30 most common bigrams\n    mostcommon = wordfreqdist.most_common(30)\n    #if RT_from_user_list == True\n    if el:\n        print('Top 30 Bigrams In Retweeted Tweets Originating from Russian User List:')\n        print(mostcommon)\n        print('\\n')\n    else:\n        print('Top 30 Bigrams In Retweeted Tweets Originating from Outside of Russian User List:')\n        print(mostcommon)","3bb29d3c":"#add a column of the tweet's year to the new_tweets dataframe\ndates = pd.to_datetime(new_tweets['created_str'])\nnew_tweets['years'] = dates.dt.year\n\nyear_list = [2014,2015,2016,2017]\nfor year in year_list:\n    #get clean_text for tweets for each year\n    year_tweets = new_tweets.loc[new_tweets['years'] == year,'clean_text']\n    #print(year_tweets.head())\n    tweet_str = year_tweets.str.cat(sep = ' ')\n    #create a lower case word list if the word is not in the stop lists and is alphanumeric\n    word_list = [i.lower() for i in wordpunct_tokenize(tweet_str) if i.lower() not in stop and i.isalpha()]\n    #create a frequency distribution of bigrams in the current word list\n    wordfreqdist = nltk.FreqDist(list(nltk.bigrams(word_list)))\n    #find 30 most common bigrams\n    mostcommon = wordfreqdist.most_common(30)\n    print('The most common words for {} are:'.format(str(year)))\n    print(mostcommon)\n","4cbcfbc6":"#Collect tweets containing 'Donald Trump' from 2015, and print the first 10\nDJT_2015 = new_tweets.loc[(new_tweets['text'].str.contains('Donald Trump')) & (new_tweets['years']==2015), 'text']\nfor el in DJT_2015.head(10).values:\n    print(el)","ff7895dd":"#Collect tweets containing 'Jeb Bush' from 2015 and print first 10\nJB_2015 = new_tweets.loc[(new_tweets['text'].str.contains('Jeb Bush')) & (new_tweets['years']==2015), 'text']\nfor el in JB_2015.head(10).values:\n    print(el)","ef62f0db":"#collect and print tweets containing 'Rand Paul' from 2015\nRP_2015 = new_tweets.loc[(new_tweets['text'].str.contains('Rand Paul')) & (new_tweets['years']==2015), 'text']\nfor el in RP_2015.head(10).values:\n    print(el)","4c9c0741":"#### From this analysis we can see a number of interesting aspects of how tweets are retweeted within the Russian user set. 1) There are different patterns (\"chain\" vs. \"burst\") 2) most of the retweets are retweeting content that was generated outside of the user list, 3) There are some users who are more likely to initiate retweet chains, possibly reflecting their connectedness to the outside twitter community, and possibly as a way to sample external content, then load it into the twitter retweeting machines to amplify the message among lots of less popular users. This is a good way to popularize messages.\n\n## Now that we have studied these connections on the level of individual tweets, let's explore how users are connected into a network, by first focusing on the top 10 retweeted users and their top 20 retweeters.","1f8c9a2f":"# Overall Summary of the Results\n### All of this information taken together supports a strategy in which Russian users sought to influence the 2016 election by amplifying the voices of real people. This amplification, normalization, and popularization of ideas was achieved through the sheer number of fake users and their high level of twitter activity. In most cases, the users took the time to gather followers by making an approximately equal number of friend requests. After gathering followers, they could then spread primarily retweeted content to a wider audience through semi-structured networks of fake and real users. I am surprised by how simple this strategy appears to be. It also makes me realize how difficult it would be to intervene to prevent such influence in the future. These Russian users were not, in most cases, putting new ideas into the population, they were merely giving a wider platform for ideas that already exist among the population of real users. It is relatively more difficult to prevent the spread of ideas that have already taken root in the population.","1125ea7e":"Interestingly, it looks like nearly all of the popular accounts were created in 2014, were they created at the same time in 2014?","732946f2":"From the RT column on the right, we can see that ~2 out of 3 users has a high proportion of tweets that are retweets (over 60%). Is there a noticeably different pattern of tweeting if we focus on the users who are primarily tweeting original content? ","ce48b303":"What is the tweeting pattern over a 24 hour period for the top 20 tweeters?","5c8eb940":"## Let's try to study the linkage between users in more detail\n\nThe analysis above is based on a lot of inference and a qualitative examination of the typical tweet times. Let's try to look at how specific tweets are retweeted through the Russian user population. To do this, we have to clean up the text to remove mentions and hashtags, as these may be added to the text of a tweet by a retweeter. We want to look for the core text.","9b9bbddb":"From this sample of plots, we can see what appears to be two tweeting patterns:\n1) A few users retweeting each other or themselves many times in parallel\n2) Chains of retweets in which one user is retweeted by a different user, who in turn is retweeted by a different user.\nThere is also a significant range in the time between retweets for a given tweet, from 20 tweets in ~ 1 min, to a similar number over the course of about a year.\n\nInterestingly the chains of retweets (option 2, above) typically occur in a smaller timeframe 20 min-\n5hrs. \n\nLet's take a closer look at those chains of retweets to see if certain users typically come before other users in the sequence.","a6acad5a":"Who are the users who were most frequently retweeted outside of the Russian troll list?","cd07cc1c":"By comparing distribution of tweets over a 24 hour period for the top 20 tweeters with that of the 20 most-retweeted users, we can see that there is a bit more order in the users who are retweeted (i.e. there is a typical tweeting schedule)\n\nThere are clearly different tweeting patterns. For example, WorldOfHashtags, DanaGeezus, ChrixMorgan, and GiselleEvns have a similar schedule (one burst around 1-3PM), while Pamela_Moore13, Crystal1Johnson, TodayPittsburgh, TEN_GOP, and tpartynews have a different schedule (more steady tweets between 6PM-2AM)\n\nTweet pattern also appears to correlate with tweet content. Those users who have a single burst of tweets mid-day are more likely to retweet other users' content (See RT column in the bottom plot, which indicates proportion of tweets that are retweets)","15f378f4":"#### From this graph we can see that there are a number of users who play a more important role in retweeting these top 10 retweeted users. These include some of the users identified above who typically fall in the middle of the tweet chains (e.g. MelvinSRoberts is a medium sized black dot, indicating a high in-degree-centrality score). We can also see that there are some users who are only connected with a single source (e.g. lower right of the graph, mr_clampin, Jasper_Fly, etc) are uniquely associated with DominicValent, as are melanymelanin and BleepThePolice uniquely associated with gloed_up.\n\n#### Thus there are users who are frequently used to retweet other russian users, and some that are more specific to a given source.","e588fa1e":"#### Using the top 200 retweeted tweets, with the 40 top retweeters, we can begin to see a pattern where there are a few instigators (WorldOfHashtags, GiselleEvns, traceyhappymom) who are more likely to tweet early on in a sequence, then there are others who more commonly come next (MelvinSRoberts), then DaileyJadon and mr_clampin, then pureDavie. It is probably significant that there is not a single person who typically is the last in the tweeting sequence. This would reflect that 1) the original tweet has been amplified (diluted among the large population of retweeters) and 2) there is no fixed sequence of retweeting. It is also significant that in most cases the three instigators are not the source of the original tweet. They may come early in the sequence more commonly because they are some of the most active users with more followers, and who follow more people.","51de878f":"In this enormous graph, we can see the connections between the top 20 retweeters and their most commonly retweeted source. The sources are presented in color, and the retweeters are typically presented in gray (unless they are a source of another user). The size of the circle represents the activity of the user (larger circles indicate that the user had more retweets in the dataset).\n\n9 out of 50 of the top retweeters had Conservatexian as their most common source.\nGiselleEvns, one of the most active tweeters, was the primary source of MelvinSRoberts.\nChrixMorgan was the primary source of GiselleEvns and pureDavie\n\nInterestingly, the most active retweeter (based on circle size), AmelieBaldwin, used RealDonaldTrump as her most common source of retweets.","3ac452d6":"Interestingly the vast majority of tweets in the tweets dataset are from 'unpopular' people. It is also worth noting that it appears as though ~10% of the tweets are not accounted for in the `popular` and `unpopular` subsets.  This is probably due to `NaN` values in the `friend_counts` column.\n\nHowever, what if we create a new statistic that is the product of tweets * followers to scale the \"power\" of a tweet based on the number of users who will see it, let's call this statistic 'tweet influence'","864db6db":"Interestingly many of these English language users with a high follower to friend ratio appear to be posing as news sites\n\nLet's now look to see how active these popular vs unpopular accounts were in the `tweets` df.","0ef3679d":"Qualitatively, it appears as though the users posting original content have a greater tweet time preference (i.e. more users have a typical tweet time)","392c187c":"19% of accounts have 2-fold more followers than friends. Who are these accounts that are so popular?","8f1bd91b":"This plot confirms what we saw above that many of the most popular accounts are russian language accounts","eb0e0210":"There is a substantial difference between the most prolific tweeters and the most frequently retweeted users in terms of the amount of original content. The most retweeted users have more original content, whereas the most prolific tweeters are almost exclusively retweeting other users.","c33bb559":"This plot shows a pretty clear linear relationship for most users where the number of followers is ~ equal to the the number of friends, but there are a few outliers in the top left of the scatter plot. Let's take a closer look at those users.","df320110":"Over 60% of the most popular accounts are Russian language users. Who are the users that speak english and are popular?","ffe2b2c6":"## First let's just take a look at the two dataframes...starting with the `users` dataframe","2f25ccd2":"From these tweets there is not an obvious preference for Trump in 2015, but there does seem to be some bias against Jeb Bush (at least there are more negative tweets about him e.g. 'Jeb Bush vs the second amendment...')\n\nFor Rand Paul, there are some race issues that are being discussed, possibly to negatively impact people's perception of him, but those may have been actual things he said.","7a523d75":"From the `user_key`s of the most retweeted users, it appears as though many of them were marketing themselves as news outlets. Is there any pattern in the tweets for these users?","afe819e0":"#### Now that we have a feel for how these users are connected to each other by their retweets, let's finally try to get a sense of what they are actually saying. I am especially curious to know how original content from Russian users differs from the content that originates outside of the user set. Let's take a look:","592e2c65":"Apparently not - only GiselleEvns. This suggests that the likelihood of a Russian user retweeting another Russian user was not simply due to chance, otherwise the most prolific Russian tweeters would also be the most retweeted. This points to the possibility that there may be some structure in who is retweeting whom.","c9743a06":"From This we can see that there are probably relatively few tweets for 2014, and there is little discussion of politics in those tweets - although there was some popular discussion of the Ebola outbreak.\n\nIn 2015 the tweets jump into the presidential race, with signs of the primaries, mentioning people like Jeb Bush, Rand Paul, Ben Carson, and others.\n\nIn 2016, the tweets are fully polarized between Hillary Clinton and Donald Trump.\n\nIn 2017, there are mentions of the trump inauguration and the women's march...the post-election excitement.","a284f824":"Interestingly the majority of the accounts were created in 2013 and 2014. When were the popular accounts created relative to the unpopular accounts?","e59b84d6":"One notable feature of these chains is that they are typically all retweeting the same original user, so it is not so much a chain of tweets as a ripple from a single source propagating outward.","6961bfe6":"## Let's begin by looking at relationship between the number of friends and followers for each user to see if there are some users that are more 'popular'","fd1d62ac":"#### I wonder if there is any clear preference for Donald Trump over the other Republicans in the tweets from 2015. Let's take a look at that.","042fcee5":"The `tweets` dataset likewise has a number of columns that will be interesting to explore, including:\n* `user_key`\n* `created_str`\n* `text`\n\nThe `user_key` column may be used to link the `tweets` dataset to the `users['screen_name']` column.\n\nThe `created_str` column will allow us to ask the questions: \nWhen are these tweets generated over the course of a 24 hour period? Is there a common pattern?\nand\nIs there a typical retweeting pattern?\n\nThe `text` column can be used to extract the source of a retweet and study the fraction of retweets vs original content.","07653ebb":"Most of the popular accounts were created in May and June of 2014.\n\nWhen were the unpopular accounts created?","000a0d30":"# What Twitter Tactics Were Used To Try To Influence The 2016 US Election?\n\nThis is my first foray into analyzing data publicly, so bear with me. There are a number of interesting, basic questions that might be asked of this collection of tweets from Russian bots\/humans intending to influence Americans before and after the 2016 Presidential Election, for example:\n\n* Who are the users doing the tweeting - are they 'popular' accounts?\n* What fraction of the tweets are original content (not retweeted content)?\n* Among the retweets, what fraction are retweeting other Russian users? What fraction are retweeting outside users?\n* Who are the most retweeted Russian users? The most retweeted outside users? The most prolific tweeters? And what fraction of their content is original?\n* Is there a typical tweeting time over the course of a 24 hour period? For users posting mostly original content? For the top tweeters? Top retweeted? For users posing as news sites?\n* Is there a typical pattern of retweets from one user to another? How does a tweet move between users?\n* How are users connected to each other through their retweeting patterns?\n* Are there any differences in language usage between tweets that originate from the Russian user set as compared to content that is retweeted from outside of the user set? Were there differences in language usage over time? Were other Republicans from the primary treated similarly to Donald Trump in the early days of the campaign?\n\nSome thoughts about the dataset itself:\nIt is probable that this dataset is not comprehensive, so there may be Russian trolls that will be falsely identified as 'real' people, only because they were not included in this dataset. I am also unsure of the timezone that the tweets were created in, so there may be an issue with analyzing the patterns of tweets over a 24 hour period. I have made the assumption that the tweet time stamps are all presented in the same time zone (although which time zone, I am not sure).\n","f7e67804":"With the exception of the top 4 rows, this plot shows that there is no real time preference in the tweets for the most prolific tweeters. We can also see (as we had seen previously) that most of the content \n\nWhat is the tweeting pattern over a 24 hour period for the top 20 most retweeted users?","1d61707b":"## Next, let's try to study the hourly distribution of tweets over a 24 hour period\n\n## We will look at the distribution of tweets for all users, the top 20 Russian tweeters and the top twenty retweeted Russian users","a24d469d":"The above users were retweeted more frequently than other users. Was their content original?","d69e21d2":"The `users` dataset has a number of columns that might be interesting to explore further, including the `created_at` column and the `followers_count` vs `friends_count` columns. \n* the `created_at` column might help us understand how far in advance these accounts were created prior to the election and might shed some light on the degree of planning that went into this.\n* a comparison of the `followers_count` vs `friends_count` might help us understand how 'popular' these accounts were. For example, I imagine most celebrities would have a high follower-to-friend ratio. A low ratio, or a ratio close to one, would indicate that influence on twitter was cultivated by making lots of friend requests to 'real' people.","41ab8384":"Only 0.1% of tweets were a user retweeting him or herself.","a9d7515d":"Let's look to see which users from within the list of Russian trolls were most commonly retweeted","49cfd395":"## ...Now let's look at the `tweets` dataframe","10e46d92":"It appears that although popular users account for only 3% of tweets in the `tweets` dataset, these tweets have a disproportionate influence of 22% because they will be viewed by many more followers. Regardless, it remains true that the majority of tweets (87%) and the majority of influence (77%) came from Russian users who were categorized as 'unpopular' above (i.e. have < 2 followers \/ friend)\n\n## Let's now look to see when the accounts were created.","7cbdd14c":"It is an interesting array of users who are getting retweeted: \nblicqer, which has the tag line on twitter: The latest Tweets from blicqer\u2122 (@blicqer). Black News...And More!. Harlem, NY #Unfiltered #Followback.\nconservatexian -> Overeducated conservative cowboy. Thinker, Sailor, Soldier, Spy\u00a9. Retired\/disabled Paratrooper; Professor; Coastie; Private Detective. I don't suffer fools well\n...and Donald Trump.","6ba3d840":"Only about 2% of the retweeted tweets were originally composed by a Russian troll. In other words, a very small fraction of the retweets were amplifying an original idea composed by a Russian troll. How many of the retweets were attributable to a user retweeting him\/herself?","829d3091":"#### I am also curious to see how the tweets changed over the four years that are available in the tweets dataset. Let's take a look!","71dee5f8":"Are the most commonly retweeted russian users also the most prolific?","db0695ec":"## Is there any apparent preference in the time for retweeting users outside of the user set?","fb491c2f":"It looks like the majority of these popular users are Russian.","bced80bf":"For the 'unpopular' accounts, there is a spike of account creation in August of 2013, and another spike of account creation in May and June of 2014, as was seen for the popular accounts.","6d963b26":"There are some clear patterns for the tweets of those users who market themselves as news sites. A number of users have a wave-like pattern, while other users work at night (this may be a time-zone difference), and other users work more consistently, with a common gap between 3AM-11AM.","ec0c7e69":"Let's now look to see the tweets are original content or if they are retweets. Skimming the first few rows, it appears as though many of them are retweets. Let's take a closer look to see what fraction of the collected tweets were retweets.","d99e8164":"## Given that most of the tweets in the dataset are retweets from non-Russian users, who is the top source for the top 50 retweeters, and how are they connected? Let's take a look.","50f6a0f4":"It appears as though the retweets originating from Russian users are a bit more polarizing on their surface compared to retweets originating outside of the user list. The former's bigrams appear more focused on issues of race and (relatedly) police violence.","485ceca9":"# Now that we have a better understanding of the timeline and influence of the accounts in the twitter dataset, let's take a closer look at the tweets themselves","34eb438a":"Almost 73% of the tweets are retweets. Who are the accounts that are getting retweeted? Are they Russian users or 'Real' users?","a8529ef1":"From this we can see that there is great variety in the typical tweeting pattern over a 24 hour period among the users. Some users tweet selectively in a small window each day (top rows), some users tweet consistently over the 24 hour period.","f92e3c37":"From looking at these tweet patterns over a 24 hour period, and thinking about the most resource efficient way of amplifying messages on twitter, I would hypothesize that:\n\n1) There are a limited number of real humans generating original content, and these users would likely follow a tweeting schedule similar to that of the \"news\" outlets above and some of the most retweeted users above - natural peaks and troughs, with a 5-10 hour downtime.\n\n2) There are vastly more bots, who are amplifying the content of other Russian users and outside users who express views consistent with the goals of those hoping to influence the election. These users are likely to have a more \"unnatural\" tweeting schedule (e.g. tweeting at a very specific time of day almost exclusively, or tweeting all the time, with no downtime). \n\n3) There are layers of amplification: A) an original tweet is probably retweeted by B) a select few users, who are very active, aggregating and capturing content to be retweeted by a much larger population (e.g. GiselleEvns, one of the most prolific tweeters and retweeters), and C) The less active, but large number of users who amplify and spread the content to their respective friends and followers. "}}