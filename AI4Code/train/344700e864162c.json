{"cell_type":{"a04786b3":"code","a5ffd3f3":"code","e405f4e6":"code","fe8f06fb":"code","ac4eb98a":"code","116d261c":"code","f1d586f2":"code","8dc16b3c":"code","c54c89ef":"code","2f384177":"code","224dd393":"code","23c82727":"code","b1a7bc71":"code","de47094d":"code","4aba4a88":"code","3fd0e217":"code","ff67a3fa":"code","2738392b":"code","4ddf26a8":"code","5bf74b1e":"code","7ce7a768":"code","d94b55b6":"code","f0bfdb23":"code","f948bcc2":"code","6585ba18":"code","100cfab9":"code","99882c18":"code","e6cd2d54":"code","19466cb7":"code","37e49fa2":"code","c78cdca0":"code","8a5aa7b6":"code","7049f6bd":"code","e41167f7":"code","70103995":"code","e78378f5":"code","a17c14b3":"code","e00837ba":"code","80469967":"code","05ee9782":"code","770de18b":"code","0eccac0d":"code","1c487fdc":"code","d8b08f3a":"code","a7238780":"code","6f4ba315":"code","99a82d67":"code","b6c7f305":"code","f355756a":"code","cf4a7f89":"code","18987372":"code","10a22378":"code","cbf3d603":"code","ec214e63":"code","16bcd3c0":"code","4cd598d6":"code","c584937a":"code","c8bbdf27":"code","72567083":"code","8462710c":"code","9fbaba2d":"code","840dbbc4":"code","16b7883f":"code","1373d1d5":"code","06efdb5b":"code","d50bd1b7":"code","709ce0ea":"code","63d058c9":"code","f8edce42":"code","b1ce5d9a":"code","a6ebed8e":"code","abe26de2":"code","6358c3ef":"code","22d4365c":"code","6058afc0":"code","70535f42":"code","5f19ea20":"code","d2eec026":"code","3ba1d430":"code","3c472e0b":"code","8c031567":"code","4a47b936":"code","f1b003b7":"code","36ec075e":"code","1b85f7f0":"code","4a78cdd0":"code","1b129680":"code","b5ebd103":"code","38a7126b":"code","ad547976":"code","e194f68c":"code","f734a1ab":"code","27058041":"code","c747facd":"code","3a4e66d0":"code","f35f1dd9":"code","76ca2d10":"code","43537e3f":"code","62ed2a10":"code","a89cbecf":"code","7f0ccd73":"code","ab1e93e6":"code","7baf0a0a":"code","2eb4c7d6":"code","ba895310":"code","b6652c59":"code","de2ac23a":"code","9d1e6e93":"code","61839bd1":"code","b577ccd7":"code","72f1e83d":"code","189f67e8":"code","43cdb056":"code","7b8084d3":"code","cf3fcb22":"markdown","6bfd65b9":"markdown","0101b0a6":"markdown","e067e334":"markdown","55224aac":"markdown","b630a7db":"markdown","d80d254c":"markdown","e65b8503":"markdown","20a2f54c":"markdown","42c4f75f":"markdown","b7b439e1":"markdown","db6387a6":"markdown","c685a51e":"markdown","81db09a1":"markdown","d3302a6b":"markdown","bb0f7e48":"markdown","a72b100a":"markdown","01d7f354":"markdown","4e4f5f65":"markdown","17047d56":"markdown","55b7eea7":"markdown","0dda292f":"markdown","3b4ed918":"markdown","68837308":"markdown","f084d23f":"markdown","38af3af1":"markdown","397635cd":"markdown","4beed10e":"markdown","57e39b5f":"markdown","a59f019c":"markdown","1cd34c99":"markdown","7d36a4fa":"markdown","d9b27cd8":"markdown","fd77dfe5":"markdown","234793fb":"markdown","55b1fcc2":"markdown","e40875c9":"markdown","e0d212ab":"markdown","519308c1":"markdown","e99a6158":"markdown","7f8ae6f3":"markdown","3438e04b":"markdown","03f9b9e3":"markdown","0355fcb0":"markdown","ea62bf90":"markdown","97998b13":"markdown","77bafb72":"markdown","562f3c90":"markdown","14288393":"markdown","eba636b3":"markdown","8531d705":"markdown","fb354251":"markdown","c7d50f5a":"markdown","83c0962a":"markdown","609ea37c":"markdown"},"source":{"a04786b3":"import pandas as pd\nimport io\ndf = pd.read_csv('..\/input\/google-play-store-apps\/googleplaystore.csv')\ndf2 = pd.read_csv('..\/input\/google-play-store-apps\/googleplaystore_user_reviews.csv')","a5ffd3f3":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e405f4e6":"df[df['Size'] == '1,000+']\n# Some values are not in right columns","fe8f06fb":"NUM_ROW = 10472\nTOTAL_ROWS = df.shape[1] -1\n\nnew_line = [df.iloc[NUM_ROW, 0], None]\n\nfor i in df.iloc[NUM_ROW, 1:TOTAL_ROWS]:\n  new_line.append(i)\n\ndf.loc[NUM_ROW] = new_line\n\n#or you can use .shift()","ac4eb98a":"df.iloc[10472]","116d261c":"df[df['Size']== 'Varies with device']","f1d586f2":"df = df.drop_duplicates(subset=['App', 'Category'])","8dc16b3c":"df['Size'].replace('Varies with device', np.nan, inplace = True ) ","c54c89ef":"df.Size = (df.Size.replace(r'[kM]+$', '', regex=True).astype(float) * \\\n             df.Size.str.extract(r'[\\d\\.]+([KM]+)', expand=False)\n            .fillna(1)\n            .replace(['k','M'], [10**3, 10**6]).astype(int))\n#plain copy-paste. Stackoverflow for more infomation. link below","2f384177":"# replace nan with median value in each category \ndf['Size'].fillna(df.groupby('Category')['Size'].transform('median'), inplace = True)","224dd393":"df.head(2)","23c82727":"df['Installs'].unique()","b1a7bc71":"#remove '+' and change type to int","de47094d":"df['Installs'] = df['Installs'].map(lambda x: x.rstrip('+'))\ndf['Installs'] = df['Installs'].apply(lambda x: x.replace(',', ''))","4aba4a88":"df['Installs'] =df['Installs'].astype('int')\ndf['Installs'].unique()","3fd0e217":"df['Rating'].unique()","ff67a3fa":"# change type to float","2738392b":"df['Rating'] = df['Rating'].astype('float')","4ddf26a8":"df['Rating'].unique()","5bf74b1e":"df['Price'].unique()","7ce7a768":"df['Price'] = df['Price'].apply(lambda x: x.replace('$', ''))\ndf['Price'] =  df['Price'].astype('float')","d94b55b6":"df['Last Updated'] = df['Last Updated'].apply(pd.to_datetime)\n","f0bfdb23":"df['Last Update'] = (df['Last Updated'] -  df['Last Updated'].max()).dt.days","f948bcc2":"df['Last Update'] = -df['Last Update']","6585ba18":"df = df.dropna(how='any')\ndf.isnull().sum()","100cfab9":"def comma_sep(df):\n    s = df[\"Genres\"].str.split(';', expand=True).stack()\n    i = s.index.get_level_values(0)\n    df2 = df.loc[i].copy()\n    df2[\"Genres\"] = s.values\n    return df2\n#split Genres bu the semicolon.","99882c18":"df_diff_genres = comma_sep(df)\n#we only use this df when we explore something related to Genres","e6cd2d54":"df.dtypes","19466cb7":"df.isnull().sum()","37e49fa2":"df.sample(2)","c78cdca0":"df.Category.value_counts()","8a5aa7b6":"sns.set(rc = {'figure.figsize':(15,10)})\ncagplot = sns.barplot(y=df.Category.value_counts().index, x=df.Category.value_counts(), orient='h')","7049f6bd":"cag = df['Category'].value_counts().reset_index()\ncag = cag.rename(columns={'index': 'Category', 'Category': 'Count'})\ncag['Percentage'] = 100 * cag['Count']  \/ cag['Count'].sum()\ncag = cag.sort_values('Percentage', ascending = False)\ncag.head()","e41167f7":"#sns.set(rc = {'figure.figsize':(15,10)})\nfig, ax = plt.subplots(figsize =(15, 10))\n\ncol1 = cag.head(3)\ncol2 = cag.head(10)\n\n\nax.barh(col2.Category, col2.Percentage, color ='grey')\nax.barh(col1.Category, col1.Percentage, color = '#d4728c')\nax.patch.set_facecolor('#e4f2f7')\n\nax.invert_yaxis()\n\n\nplt.grid(b=None)\n\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax.spines[i].set_visible(False)\n\nplt.xlabel('Percentage', fontsize =13)\nplt.ylabel('Category', fontsize = 13)\n\nplt.text(4.1, -1, \"Category\", size =22, color = '#d4728c')\nplt.text(6.8, -1, \"by Percentage\", size=22, color='grey')\n\nplt.show()\n\n#sns.barplot(x='Percentage', y='Category', data=cag.head(10), orient='h')","70103995":"sns.set(rc = {'figure.figsize':(15,10)})\nsns.barplot(x='Percentage', y='Category', data=cag.head(10), orient='h')","e78378f5":"gen = df_diff_genres['Genres'].value_counts().reset_index()\ngen = gen.rename(columns={'index':'Genres', 'Genres': 'Count'})\ngen['Percentage'] = 100 * gen['Count']\/gen['Count'].sum()\ngen.head()","a17c14b3":"cag_gen = df_diff_genres.pivot_table(index=['Category', 'Genres'], aggfunc='count')\ncag_gen = cag_gen[cag_gen.columns[cag_gen.columns.isin(['App'])]].reset_index().sort_values('App', ascending = False)\ncag_gen.head(10)","e00837ba":"sns.barplot(y='Genres', x='Percentage', orient='h', data=gen.head(10))","80469967":"sns.barplot(y='Category', x='App', orient='h', data=cag_gen.head(10))","05ee9782":"cag_install = df.groupby('Category')['Installs'].agg('sum').reset_index().sort_values('Installs', ascending=False)\ncag_rate = df.groupby('Category')['Rating'].agg('mean').reset_index().sort_values('Rating', ascending=False)\n\n","770de18b":"sns.set(rc = {'figure.figsize':(15,10)})\nfig, ax =plt.subplots(1,2 ,constrained_layout=True)\n#fig.tight_layout()\n#sns.barplot(x='Percentage', y='Category', data=cag, orient='h').set_title('Percentage Category')\nsns.barplot(x='Installs', y = 'Category', data=cag_install.head(10), ax=ax[0]).set_title('Installs by Category')\nsns.barplot(x='Rating', y = 'Category', data=cag_rate, ax=ax[1]).set_title('Rating by Category')\nfig.show()","0eccac0d":"df[df['Category']=='COMMUNICATION'].sort_values('Installs', ascending = False).head()","1c487fdc":"cag_gen = df_diff_genres.pivot_table(index=['Category', 'Genres'], values = 'Installs', aggfunc='sum')\ncag_gen2 = df_diff_genres.pivot_table(index=['Category', 'Genres'], values=['Rating'], aggfunc='mean')\npd.concat((cag_gen, cag_gen2), axis=1).sort_values('Installs', ascending = False).head(5)\n#Installs and Rating for each Genres","d8b08f3a":"df['Reviews'] = df['Reviews'].astype('int')","a7238780":"sns.set(rc = {'figure.figsize':(18,5)})\nfig, ax =plt.subplots(1, 2,constrained_layout=True)\n#ax = ax.flatten()\n#fig.tight_layout()\nsns.countplot(x='Type', data=df, orient='h', ax=ax[1]).set_title('Type')\nsns.barplot(x='Type', y = 'Installs', data=df, ax=ax[0]).set_title('Installs by Type')\nfig.show()","6f4ba315":"sns.set(rc = {'figure.figsize':(10,5)})\nsns.barplot(x='Type', y = 'Reviews', data=df).set_title('Reviews by Type')","99a82d67":"df['Content Rating'].value_counts()","b6c7f305":"order = df.groupby('Content Rating')['Rating'].mean().sort_values(ascending=False).index","f355756a":"sns.set(rc = {'figure.figsize':(15,5)})\nfig, ax = plt.subplots(1, 2,constrained_layout=True)\nsns.barplot(x='Rating', y='Content Rating', data=df, order = order, ax=ax[1])\nsns.barplot(x='Installs', y='Content Rating', data=df,order = order,ax=ax[0])","cf4a7f89":"df[df['Content Rating']=='Adults only 18+']","18987372":"df.sample(5)","10a22378":"fig, ax = plt.subplots(1, 4, constrained_layout=True)\nplt.figure(figsize=(20,10))\nsns.regplot(x='Reviews', y= 'Rating', data=df[df['Reviews']<800000],line_kws={\"color\": \"lightpink\"}, ax = ax[0])\nsns.regplot(x='Size', y= 'Rating', data=df,line_kws={\"color\": \"lightpink\"}, ax = ax[1])\nsns.regplot(x='Installs', y= 'Rating',line_kws={\"color\": \"lightpink\"}, data=df, ax = ax[2])\nsns.regplot(x='Last Update', y= 'Rating',line_kws={\"color\": \"lightpink\"}, data=df, ax = ax[3])","cbf3d603":"plt.figure(figsize=(10,10))\nsns.boxplot(x='Type', y= 'Rating', data=df)","ec214e63":"#merge 2 csv files. similar to LEFT JOIN in SQL\nnew_df = df.merge(df2, how = 'left', on = 'App')\nnew_diff_genres = df_diff_genres.merge(df2,  how = 'left', on = 'App') ","16bcd3c0":"new_df.head(1)","4cd598d6":"new_df['Sentiment_Subjectivity'].unique()","c584937a":"print(new_df['Sentiment'].value_counts())\nprint('NaN:', new_df['Sentiment'].isnull().sum())","c8bbdf27":"new_df['Sentiment'] = new_df['Sentiment'].fillna('No sentiment')","72567083":"plt.figure(figsize=(10,10))\nfig, ax = plt.subplots(1,2, constrained_layout=True)\nsns.barplot(x='Sentiment', y='Size', data=new_df, ax=ax[0])\nsns.regplot(x='Size', y='Sentiment_Polarity', data=new_df, ax=ax[1], line_kws={\"color\": \"lightpink\"})\n","8462710c":"plt.figure(figsize=(10,10))\nfig, ax = plt.subplots(1,2, constrained_layout=True)\nsns.boxplot(x='Type', y='Sentiment_Polarity', data=new_df, ax=ax[0])\nsns.regplot(x='Price', y='Sentiment_Polarity', data=new_df, ax=ax[1], line_kws={\"color\": \"lightpink\"})","9fbaba2d":"sns.regplot(x='Installs', y='Sentiment_Polarity', data=new_df, line_kws={\"color\": \"lightpink\"})","840dbbc4":"contentrate = new_df.groupby('Content Rating')['Sentiment_Polarity'].agg('mean').reset_index().dropna()\ncontentrate","16b7883f":"sns.barplot(x='Sentiment_Polarity', y='Content Rating', data=contentrate)","1373d1d5":"gen_plot = new_diff_genres.groupby('Genres')['Sentiment_Polarity'].mean().reset_index().dropna().sort_values('Sentiment_Polarity', ascending=False)\nprint(gen_plot.head(5))\nprint(gen_plot.tail(5))","06efdb5b":"plt.figure(figsize=(20,10))\nsns.barplot(x='Sentiment_Polarity', y='Genres',data=gen_plot.head(10))","d50bd1b7":"from  wordcloud  import WordCloud\n#wordcloud = WordCloud().generate(' '.join(df2['']))\nwords = ' '.join([Text for Text in df2[df2['Sentiment']=='Negative']['Translated_Review']])\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', colormap='Set2', collocations=False).generate(words)\nplt.grid(False)\nplt.axis(\"off\")\nplt.imshow(wordcloud)","709ce0ea":"words = ' '.join([Text for Text in df2[df2['Sentiment']=='Positive']['Translated_Review']])\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', colormap='Set2', collocations=False).generate(words)\nplt.grid(False)\nplt.axis(\"off\")\nplt.imshow(wordcloud)","63d058c9":"corr = new_df.corr()\nplt.figure(figsize=(9,5))\nsns.heatmap(data=corr, annot=True, linewidths= 0.2, cmap='Blues')","f8edce42":"df.isnull().sum()","b1ce5d9a":"df.info()","a6ebed8e":"data = df.drop(['App', 'Last Updated', 'Current Ver', 'Android Ver'], axis = 1)\ndata.sample(3)","abe26de2":"data = df.drop(['App', 'Last Updated', 'Current Ver', 'Android Ver','Reviews', 'Installs', 'Last Update'], axis = 1)","6358c3ef":"data","22d4365c":"data['Genres'].nunique()","6058afc0":"data['Genres'] = data['Genres'].apply(lambda x: x.split(';')[0])","70535f42":"print(data['Genres'].unique())\nprint(data['Genres'].nunique())","5f19ea20":"data = pd.get_dummies(data, columns=['Category', 'Type', 'Content Rating', 'Genres'], drop_first=True)","d2eec026":"print(data.shape)\nprint(df.shape)","3ba1d430":"data.columns","3c472e0b":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\nfrom xgboost import XGBRegressor\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler \n","8c031567":"X_train, X_test, y_train, y_test = train_test_split(data.drop('Rating', axis = 1), data['Rating'], random_state = 101)","4a47b936":"sc = MinMaxScaler()\n\nsc.fit(X_train)\n\nX_train_sc =sc.transform(X_train)\nX_test_sc = sc.transform(X_test)\nX_train_sc_df = pd.DataFrame(X_train_sc, columns = X_train.columns)\nX_test_sc_df = pd.DataFrame(X_test_sc, columns = X_test.columns)","f1b003b7":"stc = StandardScaler()\nstc.fit(X_train)\nX_train_stc =stc.transform(X_train)\nX_test_stc = stc.transform(X_test)\nX_train_stc_df = pd.DataFrame(X_train_stc, columns = X_train.columns)\nX_test_stc_df = pd.DataFrame(X_test_stc, columns = X_test.columns)","36ec075e":"X_train_sc_df","1b85f7f0":"linear_reg = LinearRegression()\nlinear_reg.fit(X_train, y_train)\ny_pred = linear_reg.predict(X_test)\nmean_squared_error(y_test, y_pred)","4a78cdd0":"linear_reg.fit(X_train_stc_df, y_train)\ny_pred = linear_reg.predict(X_test_stc_df)\nlinear_error = mean_squared_error(y_test, y_pred)\nlinear_error","1b129680":"model = XGBRegressor()\nmodel.fit(X_train, y_train, \n             early_stopping_rounds=10, \n             eval_set=[(X_test, y_test)],\n             verbose=False)\ny_pred = model.predict(X_test)\nmean_squared_error(y_pred, y_test)","b5ebd103":"model","38a7126b":"from sklearn.model_selection import GridSearchCV ","ad547976":"param_grid = {\n    'max_depth': [3,4,5],\n    'learning_rate': [0.1, 0.15],\n    'gamma': [0,0.25, 0.5],\n    'reg_lambda': [0,1,2],\n    'scale_pos_weight': [0,1, 2]}\n\"\"\"\nparam_grid = {\n    'max_depth': [3],\n    'learning_rate': [0.1],\n    'gamma': [0, 0.25],\n    'reg_lambda': [1, 1.5],\n    'scale_pos_weight': [0.5, 1]} \"\"\"\n\"\"\"    \nparam_grid = {\n    'max_depth': [7,8],\n    'learning_rate': [0.01, 0.05, 0.1 ],\n    'gamma': [0.25, 0.5, 1],\n    'reg_lambda': [5, 6, 7],\n    'scale_pos_weight': [3]} \"\"\"","e194f68c":"\"\"\"optimal_params = GridSearchCV(\n    estimator=xgb.XGBRegressor(seed=40, subsample = 0.9, colsample_bytree=0.5),\n    param_grid=param_grid,\n    scoring = 'neg_mean_squared_error',\n    verbose = 0,\n    n_jobs = 10,\n    cv=3\n)\n\noptimal_params.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds= 10, verbose = 0)\nprint(optimal_params.best_params_)\"\"\"","f734a1ab":"xgb_reg = XGBRegressor(learning_rate=0.1, gamma= 0.25, max_depth= 3, scale_pos_weight=1, reg_lambda= 1)\nxgb_reg.fit(X_train, y_train, \n             early_stopping_rounds=10, \n             eval_set=[(X_test, y_test)],\n             verbose=False)\ny_pred = xgb_reg.predict(X_test)\nxgb_error = mean_squared_error(y_test,y_pred)\nxgb_error","27058041":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train, y_train)\nrf_y_pred = rf_reg.predict(X_test)\nmean_squared_error(y_test, rf_y_pred)\n","c747facd":"RandomForestRegressor()","3a4e66d0":"param_grid = {\n\n    'max_depth': [7,8],\n    'min_samples_leaf': [3, 4],\n    'min_samples_split': [3],\n    'n_estimators': [300,400]\n}\n# Create a based model\nrf = RandomForestRegressor()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 0)\ngrid_search.fit(X_train, y_train)\nprint(grid_search.best_params_)","f35f1dd9":"rf_reg = RandomForestRegressor(max_depth= 7, min_samples_leaf= 3, min_samples_split= 3, n_estimators= 300)\nrf_reg.fit(X_train, y_train)\nrf_y_pred = rf_reg.predict(X_test)\nrf_error = mean_squared_error(y_test, rf_y_pred)\nrf_error","76ca2d10":"from sklearn import svm\nsvm_reg = svm.SVR()\nsvm_reg.fit(X_train, y_train)\nsvm_y_pred = svm_reg.predict(X_test)\nmean_squared_error(y_test, svm_y_pred)","43537e3f":"svm_reg.fit(X_train_sc_df, y_train)\nsvm_y_pred = svm_reg.predict(X_test_sc_df)\nmean_squared_error(y_test, svm_y_pred)","62ed2a10":"svm_reg","a89cbecf":"param_grid = {'C': [0.1,1, 10, 100], \n              'gamma': [1,0.1,0.01,0.001],\n              'kernel': ['rbf', 'poly', 'sigmoid']}\n\ngrid = GridSearchCV(svm_reg, param_grid=param_grid, cv=3, n_jobs = -1)\ngrid.fit(X_train_sc_df, y_train)\nprint(grid.best_params_)\n","7f0ccd73":"\nsvm_b = grid.predict(X_test_sc_df)\nsvm_error = mean_squared_error(y_test, svm_b)\nsvm_error","ab1e93e6":"from sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor(n_neighbors=20)\nknn.fit(X_train, y_train)\nknn_y_pred = knn.predict(X_test)\nmean_squared_error(y_test, knn_y_pred)","7baf0a0a":"from sklearn.neighbors import KNeighborsRegressor\n#k_range = range(1, 50)\n\nk =50\n\nk_range = np.arange(1,k+1,1)\n# We can create Python dictionary using [] or dict()\nscores = []\nacc_array=np.zeros(k)\n# We use a loop through the range 1 to 26\n\nfor k in k_range:\n    knn = KNeighborsRegressor(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    svm_y_pred = knn.predict(X_test)\n    # We append the scores in the dictionary for plot\n    scores.append(mean_squared_error(y_test, svm_y_pred))\n    acc = mean_squared_error(y_test, svm_y_pred)\n    acc = -acc\n    acc_array[k-1]=acc # store correctly the results\n\nprint(min(scores))\n\n","2eb4c7d6":"max_acc=np.amax(acc_array)\nacc_list=list(acc_array)\nk=acc_list.index(max_acc)\nprint(\"The best accuracy was with\", abs(max_acc), \"with k=\", k+1)","ba895310":"acc_list_for_plt = abs(acc_array)","b6652c59":"plt.plot(k_range, acc_list_for_plt)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Testing error')\nplt.show()","de2ac23a":"k =50\n\nk_range = np.arange(1,k+1,1)\n# We can create Python dictionary using [] or dict()\nscores = []\nacc_array=np.zeros(k)\n# We use a loop through the range 1 to 26\n\nfor k in k_range:\n    knn = KNeighborsRegressor(n_neighbors=k)\n    knn.fit(X_train_sc_df, y_train)\n    svm_y_pred = knn.predict(X_test_sc_df)\n    # We append the scores in the dictionary for plot\n    scores.append(mean_squared_error(y_test, svm_y_pred))\n    acc = mean_squared_error(y_test, svm_y_pred)\n    acc = -acc\n    acc_array[k-1]=acc # store correctly the results\n\nprint(min(scores))\nknn_error = min(scores)\n\nmax_acc=np.amax(acc_array)\nacc_list=list(acc_array)\nk=acc_list.index(max_acc)\nprint(\"The best accuracy was with\", abs(max_acc), \"with k=\", k+1)","9d1e6e93":"import lightgbm as lgb\nlgb_reg = lgb.LGBMRegressor()\nlgb_reg.fit(X_train, y_train)\nlgb_pred_y = lgb_reg.predict(X_test)\nmean_squared_error(y_test, lgb_pred_y)\n","61839bd1":"lgb_reg","b577ccd7":"param_grid = {\n    'num_leaves': [40, 50],\n    'min_data_in_leaf': [100],\n    'max_depth':[2,3],\n    \"learning_rate\" : [0.1, 0.12],\n    \"n_estimators\": [125,150]}\n\ngrid_search = GridSearchCV(lgb_reg, param_grid=param_grid, cv=3, n_jobs = -1)\ngrid_search.fit(X_train, y_train)\nprint(grid_search.best_params_)","72f1e83d":"lgb_pred = grid_search.predict(X_test)\nmean_squared_error(y_test, lgb_pred)","189f67e8":"lgb_reg = lgb.LGBMRegressor(num_leaves=40,\n   min_data_in_leaf= 100,\n    max_depth=2,\n    learning_rate= 0.1,\n    n_estimators= 200)\nlgb_reg.fit(X_train, y_train)\nlgb_pred_y = lgb_reg.predict(X_test)\nlgb_reg_error = mean_squared_error(y_test, lgb_pred_y)\nlgb_reg_error","43cdb056":"\"\"\"print(\"LightGBM error\", round(lgb_reg_error, 4))\nprint(\"KNeighbors error\", round(knn_error, 4))\nprint(\"Random forest error\", round(rf_error, 4))\nprint(\"XGBoost error\", round(xgb_error, 4)) \nprint(\"linear error\", round(linear_error, 4)) \nprint(\"svm error\", round(svm_error, 4))\"\"\"","7b8084d3":"error = [lgb_reg_error, knn_error, rf_error, xgb_error, linear_error, svm_error]\ndict = {'model': ['LightGBM', 'KNeighbors', 'Random forest', 'XGBoost', 'Linear', 'Svm'],\n                          'error': error}\nData_frame = pd.DataFrame(dict)\nData_frame.sort_values(by='error')","cf3fcb22":"**Type**","6bfd65b9":"### Python for basic cleaning data, EDA, ML","0101b0a6":"# Preprocess (cleaning)","e067e334":"**Linear Regression**\n\n","55224aac":"[Hyperparameter Tuning the Random Forest to improve accuracy in Python](https:\/\/towardsdatascience.com\/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)","b630a7db":"**XGBoost**","d80d254c":"Ratings are not too different between categories except DATING, which is below 4.0. Maybe it is hard to use an app to successfully date someone?  ","e65b8503":"Basically in this ML section, I am going to fit the default model and try to tune the Hyperparameters to get better results\nWatch this video would be definitely helpful \n\n[(Youtube at 36:43) How to build XGBoost model and Optimize Parameters with Cross Validation (GridSearchCV)](https:\/\/youtu.be\/GrJP9FLV3FE?t=2202)\n","20a2f54c":"[Normalization vs. Standardization](https:\/\/www.analyticsvidhya.com\/blog\/2020\/04\/feature-scaling-machine-learning-normalization-standardization\/)","42c4f75f":"Quicker Visualization","b7b439e1":"Better Visualization","db6387a6":"\n*   Adults only 18+ has the highest rating and the lowest Intalls because users **dont have too many options** (*in this dataset*) and they have **less free time** than people who are younger. More than that, these app have **particular contents** and most likely are not everyone's cup of tea. \n*   The Ratings of the Content Rating are not too different \n\n","c685a51e":"You can drop this column and keep going. But there is an approach on kaggle, so i decide to use it in my notebook. Original link below","81db09a1":"Overall, Paid Apps have slightly higher ratings than Free ones.","d3302a6b":"**Random forest**","bb0f7e48":"More than 20 percent of total app on android market are in Family cagetory. The following are Game, Tools","a72b100a":"**Type**","01d7f354":"Process Last Update","4e4f5f65":"![Google play](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/7\/78\/Google_Play_Store_badge_EN.svg\/1024px-Google_Play_Store_badge_EN.svg.png)","17047d56":"Process Size","55b7eea7":"*   Reviews and Size and Installs are **directly** correlated with Rating. The more popular an app has, the higher rating it gets?\n*   An app constantly updates more content, fixes errors, improves performance through patches would have higher rating.\n\n","0dda292f":"**Rating vs Reviews, Size, Installs**","3b4ed918":"prerequisite: Basic Pandas, Seaborn, Basic Machine Learning concepts","68837308":"Top ten Genres have positive reviews","f084d23f":"Process Price","38af3af1":"More Installs usually comes with more Reviews","397635cd":"\n\n\n*   `df['Last Updated'].max()` is the day that has the lastest update. Assume that today is that day\n*   So basically, we calculate how long an app have not been updated.\n\n","4beed10e":"\n\n*   Free apps tend to receive more rude comments\n*  \n\n","57e39b5f":"**LightGBM**","a59f019c":"[How to use LightGBM Classifier and Regressor in Python?](https:\/\/www.dezyre.com\/recipes\/use-lightgbm-classifier-and-regressor-in-python)","1cd34c99":"Who wouldn't love free stuff? That's why Free apps overwhelm Paid ones in the number of Installs and app","7d36a4fa":"{'gamma': 0.25, 'learning_rate': 0.1, 'max_depth': 3, 'reg_lambda': 2, 'scale_pos_weight': 0}\nthis is what I got. \n\nBut seems like the model with these parameters is overfitted.\n\nSo I decide to manually change them to get a better result on test set","d9b27cd8":"We should normalize after split to avoid data leakage","fd77dfe5":"18+ App have a lot of polite and positive comments. Just like my explanation above, Adults apps aim at specific users with particular contents. So these apps would easily satisfy their users","234793fb":"The code above is just to see the Category of Genres","55b1fcc2":"**Support Vector Machine**","e40875c9":"[Parameters Tuning](https:\/\/lightgbm.readthedocs.io\/en\/latest\/Parameters-Tuning.html) and [Example](https:\/\/www.kaggle.com\/dejavu23\/titanic-survival-seaborn-and-ensembles?scriptVersionId=17964757&cellId=172)","e0d212ab":"# EDA","519308c1":"# pre ML","e99a6158":"**KNeighbors**","7f8ae6f3":"We will predict a new app's rating based on its Category, Size, Type, Price, Content Rating, Genres. Some features like Installs, Reviews, Last Update cannot be used because these data only can be collected after the app is on the martket. That means at the time we predict, we dont have those data. This problem is also known as data leakage.","3438e04b":"Process Genres\n","03f9b9e3":"**Category and Genres**","0355fcb0":"# Conclusion","ea62bf90":"Popular apps have more neutral comment","97998b13":"# ML","77bafb72":"Process Rating","562f3c90":"Before we start, I recommend a youtube channel that clearly explains every basic concepts (what it is, how it works, with examples) in machine learning.\n\n[StatQuest with Josh Starmer ](https:\/\/www.youtube.com\/channel\/UCtYLUTtgS3k1Fg4y5tAhLbw)","14288393":"[M to million, k to thousand](https:\/\/stackoverflow.com\/questions\/39684548\/convert-the-string-2-90k-to-2900-or-5-2m-to-5200000-in-pandas-dataframe)","eba636b3":"[Last updated](https:\/\/www.kaggle.com\/tanetboss\/how-to-get-high-rating-on-play-store?select=googleplaystore.csv&scriptVersionId=6076775&cellId=108)\n\n","8531d705":"**Sentiment**","fb354251":"A large app would come with high expectation. Therefore, it easily gets negative comment","c7d50f5a":"Process Installs","83c0962a":"\n[Hyperparameter Tuning for Support Vector Machines \u2014 C and Gamma Parameters](https:\/\/towardsdatascience.com\/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167)\n\n[With example](https:\/\/medium.com\/@hritishak\/support-vector-machine-and-hyper-parameter-tuning-in-svm-d0f85017a69e)","609ea37c":"[How to select K in sklearn's KNeighborsClassifier based on the highest accuracy](https:\/\/stackoverflow.com\/questions\/57347217\/how-to-select-k-in-sklearns-kneighborsclassifier-based-on-the-highest-accuracy)"}}