{"cell_type":{"67d6bcda":"code","df4818f9":"code","4ecee929":"code","c0ab3e2f":"code","a6c6d7bc":"code","0b261e02":"code","c7989f9f":"code","42711efd":"code","59a65658":"code","b6a315c3":"code","a442e560":"code","b2661c7a":"code","632e079d":"code","ada44e5d":"code","bdcd503e":"code","7a97c3ff":"code","fab7a45a":"code","e6763afe":"code","258aca75":"code","8dbb8744":"code","403e5f66":"code","7c016b31":"code","9946e62b":"code","a199ad45":"code","5d185921":"code","eaf0ecaa":"code","1f1c84bf":"code","65f75784":"code","aabc1195":"code","77476fae":"code","be23b757":"code","b0c6e03e":"code","f30538cf":"code","146fc531":"code","a829f828":"code","8fa505d0":"code","a3fa1da4":"code","84b7a58f":"code","577fcbfa":"code","4d29ac9e":"code","28e5cd3b":"code","ae788212":"code","451e8be5":"code","e238565c":"code","e102cf48":"code","1eccc06e":"code","b3f4d40c":"code","38363661":"code","53c9f84c":"code","9e631892":"code","4b5c019b":"code","27f3be6f":"code","d3bcfbec":"code","6c878c96":"code","969fbd0d":"code","acaadc98":"code","d209ca64":"code","e0008a8c":"code","5e9ebe5a":"code","db06142b":"code","b621da7c":"code","df758f70":"code","0e69aa18":"markdown","b9311639":"markdown","22142a61":"markdown","ba102865":"markdown","6dc55252":"markdown","eaf6a621":"markdown","dd9a8117":"markdown","36974b54":"markdown","d41874d1":"markdown","d53ff688":"markdown","12454fbf":"markdown","72861ad0":"markdown","e15bee16":"markdown","a6512783":"markdown","547f144e":"markdown","362d3842":"markdown","980e1573":"markdown","ae84f4d4":"markdown","166e0dd5":"markdown","e3728385":"markdown","d1cbb893":"markdown","580b846c":"markdown","f0246e9f":"markdown"},"source":{"67d6bcda":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(color_codes=True)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows',None)","df4818f9":"plt.rcParams['xtick.labelsize'] = 15.\nplt.rcParams['ytick.labelsize'] = 15.\nplt.rcParams['figure.figsize'] = [15.,8.]\nplt.rcParams['legend.fontsize'] = 13.\nplt.rcParams['axes.labelsize'] = 15.","4ecee929":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain.head()","c0ab3e2f":"train.shape","a6c6d7bc":"train.duplicated().sum()","0b261e02":"train.info()","c7989f9f":"def missing(train):\n    missing_value = train.isnull().sum().sort_values(ascending=False)\n    missing_percentage= (train.isnull().sum()*100\/train.isnull().count()).sort_values(ascending=False)\n    missing_total = pd.concat([missing_value,missing_percentage], axis=1, keys=['missing_value','missing_percentage'])\n    return missing_total\nmissing(train)","42711efd":"plt.figure(figsize=(15,10))\nsns.heatmap(train.isnull(),yticklabels=False)","59a65658":"train.describe()","b6a315c3":"null_feature = [feature for feature in train.columns if train[feature].isnull().sum()>1]\ntrain[null_feature].head()","a442e560":"for feature in null_feature:\n    data=train.copy()\n    \n    data[feature]=np.where(data[feature].isnull(),1,0)\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.xlabel('0= Not Null, 1= Null')\n    plt.ylabel('Sales Price')\n    plt.show()","b2661c7a":"numerical_features = [features for features in train.columns if train[features].dtypes !='O']\ntrain[numerical_features].head()","632e079d":"year_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\ntrain[year_feature].head()","ada44e5d":"train.groupby('YrSold')['SalePrice'].median().plot()\nplt.show()","bdcd503e":"for feature in year_feature:\n    if feature != 'YrSold':\n        data=train.copy()\n        data[feature] = data['YrSold']-data[feature]\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","7a97c3ff":"train[numerical_features].isnull().sum()","fab7a45a":"discreate_feature = [feature for feature in numerical_features if len(train[feature].unique())<25 and feature not in year_feature+['Id']] \nprint(f'Number of Discreate Features: {len(discreate_feature)}')\ntrain[discreate_feature].head() ","e6763afe":"for feature in discreate_feature:\n    data = train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.ylabel('Sale Price')\n    plt.xticks(rotation=0)\n    plt.show()","258aca75":"contineous_feature = [feature for feature in numerical_features if feature not in discreate_feature+year_feature+['Id']]\nprint(f'Number of Contineous Feature:{len(contineous_feature)}')\ntrain[contineous_feature].head()","8dbb8744":"for feature in contineous_feature:\n    data= train.copy()\n    sns.histplot(data=data, x=feature, bins=15, palette=\"magma\", kde=True)\n    plt.show()","403e5f66":"# logrithmic transformation\nfor feature in contineous_feature:\n    data = train.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data['SalePrice'] = np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('Sale Price')\n        plt.show()","7c016b31":"for feature in numerical_features:\n    data=train.copy()\n    sns.boxplot(data=data, x=feature)\n    plt.show()","9946e62b":"for i in numerical_features:\n    IQR = train[i].quantile(0.75)-train[i].quantile(0.25)\n    lower_bridge = train[i].quantile(0.25)-(IQR*1.5)\n    upper_bridge = train[i].quantile(0.75)+(IQR*1.5)\n    print(f'{i}: Lower Bridge: {lower_bridge}, Upper Bridge: {upper_bridge}')","a199ad45":"train.loc[train['MSSubClass']>=145.0, 'MSSubClass'] = 145.0\ntrain.loc[train['MSSubClass']<=-55.0, 'MSSubClass'] = -55.0\n\ntrain.loc[train['LotFrontage']>=111.5, 'LotFrontage'] = 111.5\ntrain.loc[train['LotFrontage']<=27.5, 'LotFrontage'] = 27.5\n\ntrain.loc[train['LotArea']>=17673.5, 'LotArea'] = 17673.5\ntrain.loc[train['LotArea']<=1481.5, 'LotArea'] = 1481.5\n\ntrain.loc[train['OverallQual']>=10.0, 'OverallQual'] = 10.0\ntrain.loc[train['OverallQual']<=2.0, 'OverallQual'] = 2.0\n\ntrain.loc[train['OverallCond']>=7.5, 'OverallCond'] = 7.5\ntrain.loc[train['OverallCond']<=3.5, 'OverallCond'] = 3.5\n\ntrain.loc[train['YearBuilt']>=2069.0, 'YearBuilt'] = 2069.0\ntrain.loc[train['YearBuilt']<=1885.0, 'YearBuilt'] = 1885.0\n\ntrain.loc[train['YearRemodAdd']>=2069.0, 'YearRemodAdd'] = 2069.0\ntrain.loc[train['YearRemodAdd']<=1911.5, 'YearRemodAdd'] = 1911.5\n\ntrain.loc[train['MasVnrArea']>=415.0, 'MasVnrArea'] = 415.0\ntrain.loc[train['MasVnrArea']<=-249.0, 'MasVnrArea'] = -249.0\n\ntrain.loc[train['BsmtFinSF1']>=1780.625, 'BsmtFinSF1'] =1780.625\ntrain.loc[train['BsmtFinSF1']<=-1068.375, 'BsmtFinSF1'] = -1068.375\n\ntrain.loc[train['BsmtFinSF2']>=0.0, 'BsmtFinSF2'] = 0.0\ntrain.loc[train['BsmtFinSF2']<=0.0, 'BsmtFinSF2'] = 0.0\n\ntrain.loc[train['BsmtUnfSF']>=1685.5, 'BsmtUnfSF'] = 1685.5\ntrain.loc[train['BsmtUnfSF']<=-654.5, 'BsmtUnfSF'] = -654.5\n\ntrain.loc[train['TotalBsmtSF']>=2052.0, 'TotalBsmtSF'] = 2052.0\ntrain.loc[train['TotalBsmtSF']<=42.0, 'TotalBsmtSF'] = 42.0\n\ntrain.loc[train['1stFlrSF']>=2155.125, '1stFlrSF'] =2155.125\ntrain.loc[train['1stFlrSF']<=118.125, '1stFlrSF'] = 118.125         \n\ntrain.loc[train['2ndFlrSF']>=1820.0, '2ndFlrSF'] = 1820.0\ntrain.loc[train['2ndFlrSF']<=-1092.0, '2ndFlrSF'] = -1092.0\n\ntrain.loc[train['LowQualFinSF']>=0.0, 'LowQualFinSF'] = 145.0\ntrain.loc[train['LowQualFinSF']<=0.0, 'LowQualFinSF'] = 0.0\n\ntrain.loc[train['GrLivArea']>=2747.625, 'GrLivArea'] = 2747.625\ntrain.loc[train['GrLivArea']<=158.625, 'GrLivArea'] =158.625\n\ntrain.loc[train['BsmtFullBath']>=2.5, 'BsmtFullBath'] = 2.5\ntrain.loc[train['BsmtFullBath']<=-1.5, 'BsmtFullBath'] = -1.5\n\ntrain.loc[train['BsmtHalfBath']>=0.0, 'BsmtHalfBath'] = 0.0\ntrain.loc[train['BsmtHalfBath']<=0.0, 'BsmtHalfBath'] = 0.0\n\ntrain.loc[train['FullBath']>=3.5, 'FullBath'] = 3.5\ntrain.loc[train['FullBath']<=-0.5, 'FullBath'] =-0.5\n\ntrain.loc[train['HalfBath']>=2.5, 'HalfBath'] = 2.5\ntrain.loc[train['HalfBath']<=-1.5, 'HalfBath'] = -1.5\n\ntrain.loc[train['BedroomAbvGr']>=4.5, 'BedroomAbvGr'] = 4.5\ntrain.loc[train['BedroomAbvGr']<= 0.5, 'BedroomAbvGr'] =  0.5\n\ntrain.loc[train['KitchenAbvGr']>=1.0, 'KitchenAbvGr'] = 1.0\ntrain.loc[train['KitchenAbvGr']<=1.0, 'KitchenAbvGr'] = 1.0\n\ntrain.loc[train['TotRmsAbvGrd']>=10.0, 'TotRmsAbvGrd'] = 10.0\ntrain.loc[train['TotRmsAbvGrd']<=2.0, 'TotRmsAbvGrd'] = 2.0\n\ntrain.loc[train['Fireplaces']>=2.5, 'Fireplaces'] = 2.5\ntrain.loc[train['Fireplaces']<=-1.5, 'Fireplaces'] = -1.5\n\ntrain.loc[train['GarageYrBlt']>=2063.5, 'GarageYrBlt'] = 2063.5\ntrain.loc[train['GarageYrBlt']<=1899.5, 'GarageYrBlt'] = 1899.5\n\ntrain.loc[train['GarageCars']>=3.5, 'GarageCars'] = 3.5\ntrain.loc[train['GarageCars']<=-0.5, 'GarageCars'] = -0.5\n\ntrain.loc[train['GarageArea']>=938.25, 'GarageArea'] = 938.25\ntrain.loc[train['GarageArea']<=-27.75, 'GarageArea'] =-27.75\n\ntrain.loc[train['WoodDeckSF']>=420.0, 'WoodDeckSF'] = 420.0\ntrain.loc[train['WoodDeckSF']<=-252.0, 'WoodDeckSF'] = -252.0\n\ntrain.loc[train['OpenPorchSF']>=170.0, 'OpenPorchSF'] = 170.0\ntrain.loc[train['OpenPorchSF']<=-102.0, 'OpenPorchSF'] = -102.0\n\ntrain.loc[train['EnclosedPorch']>=0.0, 'EnclosedPorch'] = 0.0\ntrain.loc[train['EnclosedPorch']<=0.0, 'EnclosedPorch'] = 0.0\n\ntrain.loc[train['3SsnPorch']>=0.0, '3SsnPorch'] = 170.0\ntrain.loc[train['3SsnPorch']<=0.0, '3SsnPorch'] = 0.0\n\ntrain.loc[train['ScreenPorch']>=0.0, 'ScreenPorch'] =0.0\ntrain.loc[train['ScreenPorch']<=0.0, 'ScreenPorch'] = 0.0\n\ntrain.loc[train['PoolArea']>=0.0, 'PoolArea'] = 170.0\ntrain.loc[train['PoolArea']<=0.0, 'PoolArea'] = 0.0\n\ntrain.loc[train['MiscVal']>0.0, 'MiscVal'] = 0.0\ntrain.loc[train['MiscVal']<=0.0, 'MiscVal'] = -102.0\n\ntrain.loc[train['MoSold']>=12.5, 'MoSold'] = 12.5\ntrain.loc[train['MoSold']<=0.5, 'MoSold'] = 0.5\n\ntrain.loc[train['YrSold']>=2012.0, 'YrSold'] = 2012.0\ntrain.loc[train['YrSold']<=2004.0, 'YrSold'] = 2004.0\n","5d185921":"for feature in numerical_features:\n    data=train.copy()\n    sns.boxplot(data=data, x=feature)\n    plt.show()","eaf0ecaa":"categorical_feature = [feature for feature in train.columns if train[feature].dtypes =='O']\ntrain[categorical_feature].head()","1f1c84bf":"for feature in categorical_feature:\n    print(f'The Feature is :{feature} and number of categories is {len(train[feature].unique())}')","65f75784":"for feature in categorical_feature:\n    data = train.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('Sale Price')\n    plt.show()","aabc1195":"cat_nan = [feature for feature in train.columns if train[feature].isnull().sum()>1 and train[feature].dtypes=='O']\ntrain[cat_nan].head()","77476fae":"def fill_cat_nan(train, cat_nan):\n    data= train.copy()\n    data[cat_nan] = train[cat_nan].fillna('Missing')\n    return data\ntrain = fill_cat_nan(train, cat_nan)\ntrain[cat_nan].isna().sum()","be23b757":"numerical_nan = [feature for feature in numerical_features if train[feature].isnull().sum()>1 and train[feature].dtypes !='O']\n\nfor feature in numerical_nan:\n    print(f'{feature}: {np.round(train[feature].isnull().mean(),4)} % missing value')","b0c6e03e":"# replacing numerical missing value\nfor feature in numerical_nan:\n    # as we have outliers in the numerical data we replace nan with median\n    median_value = train[feature].median()\n    \n   # make a new column in which 1 represent nan value and 0 represent not had nan value\n    train[feature+'nan'] = np.where(train[feature].isnull(),1,0)\n    train[feature].fillna(median_value, inplace=True)\n    \ntrain[numerical_nan].isna().sum()","f30538cf":"train['Electrical'] = train['Electrical'].fillna('Missing')","146fc531":"train['Electrical'].value_counts()","a829f828":"train.isna().sum()","8fa505d0":"train.head(20)","a3fa1da4":"for feature in year_feature:\n    if feature!='YrSold':\n        train[feature] = train['YrSold'] - train[feature]","84b7a58f":"train[year_feature].head()","577fcbfa":"numerical_feat = ['LotFrontage','LotArea','1stFlrSF','GrLivArea','SalePrice']\n\nfor feature in numerical_feat:\n    train[feature] = np.log(train[feature])","4d29ac9e":"train.head()","28e5cd3b":"for feature in categorical_feature:\n    temp_cat = train.groupby(feature)['SalePrice'].count()\/len(train)\n    temp_df = temp_cat[temp_cat>0.01].index\n    train[feature] = np.where(train[feature].isin(temp_df), train[feature], 'rare_category')","ae788212":"from sklearn.preprocessing import LabelEncoder\n\nfor feature in categorical_feature:\n    le = LabelEncoder()\n    train[feature] = le.fit_transform(train[feature])","451e8be5":"train.head()","e238565c":"from sklearn.preprocessing import MinMaxScaler\n\nfeature_scale  = [feature for feature in train.columns if feature not in ['Id','SalePrice']]\nscaler = MinMaxScaler()\ntrain[feature_scale] = scaler.fit_transform(train[feature_scale])","e102cf48":"train.head()","1eccc06e":"train_new = train.copy()\ntrain_new.to_csv('train_new.csv', index=False)","b3f4d40c":"x  = train.drop(['Id','SalePrice'], axis=1)\ny = train['SalePrice']","38363661":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=0)","53c9f84c":"len(x_train), len(y_train)","9e631892":"from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge","4b5c019b":"!pip install xgboost","27f3be6f":"from xgboost import XGBRegressor","d3bcfbec":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, plot_roc_curve\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV","6c878c96":"models ={'RandomForestRegressor': RandomForestRegressor(),\n        'AdaBoostRegressor': AdaBoostRegressor(),\n        'GradientBoostingRegressor': GradientBoostingRegressor(),\n        'LinearRegression': LinearRegression(),\n        'Lasso':Lasso(),\n        'Ridge':Ridge()\n        }","969fbd0d":"def fit_and_score(models, x_train,x_test,y_train,y_test):\n    \n    model_score= {}\n    np.random.seed(42)\n    \n    for name, model in models.items():\n        model.fit(x_train,y_train)\n        model_score[name]= model.score(x_test,y_test)\n    return model_score","acaadc98":"scores = fit_and_score(models= models,\n                     x_train=x_train,\n                     x_test=x_test,\n                     y_train=y_train,\n                     y_test=y_test)\nscores","d209ca64":"search_grid={'n_estimators':[500,1000,2000],\n             'learning_rate':[.001,0.01,.1],\n                 'max_depth':[1,2,4],\n             'subsample':[.5,.75,1],\n             'random_state':[1]\n            }","e0008a8c":"gbm = GradientBoostingRegressor()\ngbm_random=RandomizedSearchCV(estimator=gbm,\n                        param_distributions=search_grid,\n                        n_jobs=1,\n                        cv=5,\n                       verbose=2,\n                        n_iter=100)\ngbm_random.fit(x_train,y_train)","5e9ebe5a":"best_random = gbm_random.best_estimator_\nbest_random","db06142b":"y_preds = best_random.predict(x_test)","b621da7c":"best_random.score(x_test,y_test)","df758f70":"print(mean_absolute_error(y_test,y_preds))\nprint(mean_squared_error(y_test,y_preds))\nprint(np.sqrt(mean_squared_error(y_test,y_preds)))","0e69aa18":"## Numerical Nan Value ","b9311639":"### Null values of LotFrontage, Alley, MasVnrType, MasVnrArea, Fence and MiscFeature are related to the Sales Price, hence connot drop the nan values for these coluns","22142a61":"## Finding relation between categorical features and target feature SalePrice","ba102865":"### Handling Outliers","6dc55252":"### White line represents the amount of misisng values in the columns","eaf6a621":"### Model Tuning: GradientBoostingRegressor","dd9a8117":"### Number of categiries in a feature","36974b54":"### No Null\/nan values","d41874d1":"## Train Test Split","d53ff688":"## Importing Models","12454fbf":"### Feature scaling","72861ad0":"### RandomForest Regressor","e15bee16":"### GridSearchCV","a6512783":"### Checking Outliers","547f144e":"### Year Feature","362d3842":"## Categorical feature","980e1573":"### Import Metrics","ae84f4d4":"## Numerical Features","166e0dd5":"### Changing categoral feature in numerical dtype","e3728385":"### Categorical Feature nan value","d1cbb893":"### All Outliers are removed using IQR except SalesPrice as it is our taget feature","580b846c":"### Neighborhood, Exterior1st, Exterior2nd are having more than 15 categories","f0246e9f":"### Sales Price is decreasing as year increases"}}