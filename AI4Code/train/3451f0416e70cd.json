{"cell_type":{"6b052475":"code","f48ad10f":"code","d33d4db7":"code","265ca339":"code","0b2d167f":"code","a32975c6":"code","3a59ebb3":"code","ca0ad998":"code","89fd3682":"code","8a9e8b60":"code","4907ec58":"code","59e4a367":"code","629fe514":"code","17e89d90":"code","bf8918d5":"code","20d5647a":"code","9b6e135e":"code","f3d8d001":"code","9d75b0b3":"code","bdbae4e5":"code","798dc800":"code","ab504a50":"code","06b5d9c2":"code","a8ea905b":"code","edbd88e4":"code","b73e1950":"code","49b8e35d":"code","7bc283c2":"code","db8c0c3a":"code","b380ac39":"code","61c0e49c":"code","c74233a7":"code","9bd74684":"code","29911c5e":"code","591b09db":"code","6d3621cc":"code","5f05a1e7":"markdown","f4ba4474":"markdown","9bbfc43a":"markdown","ffac5292":"markdown","bdb601cd":"markdown","3afbf3f2":"markdown","b9c58702":"markdown","6ff11262":"markdown","44b9ad8c":"markdown","2b7c1e88":"markdown","b8921172":"markdown","7551b82f":"markdown","03889786":"markdown","32b93a6b":"markdown","2bead5b3":"markdown","c2f67315":"markdown","556cb435":"markdown","f0ff5ed3":"markdown","22b7a6ba":"markdown","4a5d1963":"markdown","279f1eac":"markdown","8df696a6":"markdown","2fa7a1f9":"markdown","22f13695":"markdown","65528f06":"markdown"},"source":{"6b052475":"import numpy as np\nimport pandas as pd","f48ad10f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d33d4db7":"train = pd.read_csv('\/kaggle\/input\/porto-seguro-data-challenge\/train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/porto-seguro-data-challenge\/test.csv')\n\nprint('Treino - linhas: %d colunas: %d' % train.shape)\nprint('Teste  - linhas: %d colunas: %d' % test.shape)","265ca339":"metadata = pd.read_csv('\/kaggle\/input\/porto-seguro-data-challenge\/metadata.csv')\nmetadata['Variavel tipo'].value_counts()","0b2d167f":"train.sample(3)","a32975c6":"train.dtypes.value_counts()","3a59ebb3":"train['y'].value_counts()","ca0ad998":"# recupera os valores (X), e as classes (Y)\nX = train.drop(['id', 'y'], axis=1)\nY = train['y']","89fd3682":"# treinamento, test split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=26)","8a9e8b60":"# m\u00e9tricas\nfrom sklearn.metrics import f1_score, recall_score","4907ec58":"# classificadores\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier","59e4a367":"random_seed = 26\nmodels = [\n    RandomForestClassifier(random_state=random_seed),\n    RandomForestClassifier(n_estimators=500, random_state=random_seed),\n    MLPClassifier(hidden_layer_sizes=(500), max_iter=1_000, random_state=random_seed),\n    MLPClassifier(hidden_layer_sizes=(500, 200), max_iter=1_000, random_state=random_seed)\n]","629fe514":"# fun\u00e7\u00e3o para avaliar classificadores\ndef evaluate(model, X_train, y_train, X_val, y_val):\n    # treina\n    model.fit(X_train, y_train)\n    # avalia o modelo\n    y_pred = model.predict(X_val)\n    rec = recall_score(y_pred, y_val)\n    f1  = f1_score(y_pred, y_val)\n    return str(model), {'f1':f1, 'rec':rec}","17e89d90":"from tqdm.notebook import tqdm\n\nexperiment = {}\nfor model in tqdm(models):\n    name, results = evaluate(model, X_train, y_train, X_val, y_val)\n    experiment[name] = results","bf8918d5":"pd.DataFrame(experiment).T.style.highlight_max(axis=0)","20d5647a":"def generate_submission(prediction, test, file_name):\n    # recupera os dados e os ids\n    X = test.drop('id', axis=1)\n    ids = test['id']\n    target = prediction(X)\n    # gera o arquivo de submiss\u00e3o\n    submission = {'id':ids, 'predicted':target}\n    df_submission = pd.DataFrame(submission)\n    df_submission.to_csv(file_name, index=False)","9b6e135e":"model = RandomForestClassifier(n_estimators=500, random_state=random_seed)\nmodel.fit(X, Y)","f3d8d001":"generate_submission(model.predict, test, 'submission-randomforest.csv')","9d75b0b3":"import tensorflow as tf\nimport tensorflow_hub as hub","bdbae4e5":"# Model layers\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=X_train.shape[1]),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(300, activation='relu'),\n    tf.keras.layers.Dense(300, activation='relu'),\n    tf.keras.layers.Dense(2, activation='softmax')\n])","798dc800":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc')])","ab504a50":"model.fit(X_train, y_train, epochs=50)","06b5d9c2":"y_pred = model.predict(X_val)\ny_pred = np.argmax(y_pred, axis=1)","a8ea905b":"rec = recall_score(y_pred, y_val)\nf1  = f1_score(y_pred, y_val)\nexperiment['Deep Learning (keras)'] = {'f1':f1, 'rec':rec}","edbd88e4":"pd.DataFrame(experiment).T.style.highlight_max(axis=0)","b73e1950":"def prediction(X):\n    y_pred = model.predict(X)\n    y_pred = np.argmax(y_pred, axis=1)\n    return y_pred","49b8e35d":"generate_submission(prediction, test, 'submission-deeplearning.csv')","7bc283c2":"!pip install flaml[notebook]==0.5.11\n!pip install delayed==0.11.0b1","db8c0c3a":"!pip freeze | grep delayed","b380ac39":"from flaml import AutoML\n\nautoml = AutoML()","61c0e49c":"settings = {\n    \"time_budget\":300, # total em segundos\n    \"metric\":'f1', # ['accuracy','roc_auc','f1','log_loss','mae','mse','r2']\n    \"task\":'classification',\n    \"log_file_name\":'flaml.log', # flaml log file\n}","c74233a7":"automl.fit(X_train=X, y_train=Y, **settings)","9bd74684":"print('Melhor ML:', automl.best_estimator)\nprint('Hyperparmeter config:', automl.best_config)\nprint('Melhor f1 na valida\u00e7\u00e3o: {0:.4g}'.format(1-automl.best_loss))","29911c5e":"y_pred = automl.predict(X_val)\nrec = recall_score(y_pred, y_val)\nf1  = f1_score(y_pred, y_val)\nexperiment['AutoML (flaml)'] = {'f1':f1, 'rec':rec}","591b09db":"pd.DataFrame(experiment).T.style.highlight_max(axis=0)","6d3621cc":"generate_submission(prediction, test, 'submission-automl-flaml.csv')","5f05a1e7":"### Avalia\u00e7\u00e3o\n\nVamos treinar e avaliar cada um dos modelos. Para isto, vamos utilizar a fun\u00e7\u00e3o `evaluate`.\n\n- `evaluate(model, X_train, y_train, X_val, y_val)`\n- Seu c\u00f3digo esta ocultado, clique em expandir para visualiz\u00e1-lo.","f4ba4474":"Os dados est\u00e3o desbalanceados?\n- Ideia - explorar t\u00e9cnicas de oversampling na classe minorit\u00e1ria.","9bbfc43a":"Carregando algumas bibliot\u00e9cas b\u00e1sicas.","ffac5292":"### Submiss\u00e3o","bdb601cd":"Qual a quantidade de dados?","3afbf3f2":"-----\n<a id=\"auto\"><\/a>\n# AutoML","b9c58702":"Olhando os tipos dos dados, reparamos que todos s\u00e3o num\u00e9ricos - independentemente se \u00e9 quantiativo ou qualitativo.","6ff11262":"### Avalia\u00e7\u00e3o","44b9ad8c":"-----\n<a id=\"clas\"><\/a>\n# Machine Learning Tradicional","2b7c1e88":"Vamos criar um conjunto de treino e valida\u00e7\u00e3o do experimento.","b8921172":"Vamos ver alguns exemplos desses dados...","7551b82f":"### Submiss\u00e3o","03889786":"### Avalia\u00e7\u00e3o","32b93a6b":"Vejamos as m\u00e9tricas dos nossos experimentos.","2bead5b3":"# Classifica\u00e7\u00e3o - Porto Seguro Data Challenge\n\nEste notebook aplica a tarefa de classifica\u00e7\u00e3o em clientes do Porto Seguro com a inten\u00e7\u00e3o de identificar a probabilidade de contrata\u00e7\u00e3o de um servi\u00e7o ou n\u00e3o. Leia mais sobre a competi\u00e7\u00e3o no [Porto Seguro Data Challenge - Estime a propens\u00e3o de aquisi\u00e7\u00e3o a novos produtos](https:\/\/www.kaggle.com\/c\/porto-seguro-data-challenge)\n\n> **Resumidamente**. Tarefa de classifica\u00e7\u00e3o bin\u00e1ria utilizando os dados providos pelo Porto Seguro.\nConte\u00fado voltado para n\u00edvel intermedi\u00e1rio da \u00e1rea de Aprendizado de M\u00e1quina e Ci\u00eancia de Dados!\n\n# Conte\u00fado\n> **Nota**. Alguns c\u00f3digos e outputs ser\u00e3o ocultados, a fim de facilitar a visualiza\u00e7\u00e3o dos dados e dar destaque para o conte\u00fado mais importante.\n\nO notebook est\u00e1 organizado como segue:\n\n- [Dados](#data) - An\u00e1lise dos dados.\n- [Machine Learning](#clas) - Explora\u00e7\u00e3o de diversos algoritmos cl\u00e1ssicos.\n- [Deep Learning](#deep) - Cria\u00e7\u00e3o de um modelo de Deep Learning.\n- [AutoML](#auto) - Explora\u00e7\u00e3o de modelos usando AutoML.","c2f67315":"-----\n<a id=\"deep\"><\/a>\n# Deep Learning","556cb435":"Com isso, minha primeira suposi\u00e7\u00e3o \u00e9 simplesmente fornecer esses dados para um algoritmo de classifica\u00e7\u00e3o qualquer e analisar seu resultado.","f0ff5ed3":"Quais s\u00e3o os tipos de dados dispon\u00edveis?","22b7a6ba":"## Conjunto de Dados","4a5d1963":"## Experimentos","279f1eac":"Explorando os dados providos.","8df696a6":"-----\n<a id=\"data\"><\/a>\n# Dados","2fa7a1f9":"## FLAML - Fast and Lightweight AutoML\n\n\"[FLAML](https:\/\/github.com\/microsoft\/FLAML) is a lightweight Python library that finds accurate machine learning models automatically, efficiently and economically\" (Microsoft).","22f13695":"Qual foi o melhor modelo encontrado?","65528f06":"### Submiss\u00e3o"}}