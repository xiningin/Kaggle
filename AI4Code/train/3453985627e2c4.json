{"cell_type":{"ebcb2b26":"code","254639f7":"code","46a39b8e":"code","057d64bd":"code","ae8e7116":"code","4363ea63":"code","34c0f582":"code","52913191":"code","f28646cb":"code","521eab22":"code","e17ee187":"code","99c4442a":"code","2bc41cd9":"markdown","e67adfed":"markdown","3fb14573":"markdown","1e6128a8":"markdown","a1885bf5":"markdown","e4cbd1db":"markdown","c3ff6365":"markdown","3b47b079":"markdown","6e023c8d":"markdown"},"source":{"ebcb2b26":"import torch\nimport numpy as np\nfrom torch import optim","254639f7":"from torchvision import datasets\nimport torchvision.transforms as transfroms\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n#number of subprocess to use for data loading\nnum_workers = 0\n\n#how many samples per batch to load\nbatch_size = 20\n\n#percentage of training set to use as validation\nvalid_size = 0.2\n\n#convert data to torch_FloatTensor\ntransform = transfroms.ToTensor()\n\n#choose the training and test datasets\ntrain_data = datasets.MNIST(root='data', train=True,download=True,transform=transform)\ntest_data = datasets.MNIST(root='data', train=False,download=True,transform=transform)\n","46a39b8e":"#obtain training indices that will be used for validation\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\n\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n#define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n#prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           sampler=train_sampler,\n                                           num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           sampler=valid_sampler,\n                                           num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                          num_workers=num_workers)\n","057d64bd":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n#obtain one batch of training images\ndataiter = iter(train_loader)\nimages,labels = dataiter.next()\nimages = images.numpy()\n\n#plot images in the batch , along with the corresponding labels\nfig = plt.figure(figsize=(25,4))\nfor idx in np.arange(20):\n  #fig.add_subplot(num_column,row,idx+1,xticks=[],yticks=[])\n  ax = fig.add_subplot(2,20\/2,idx+1,xticks=[],yticks=[])\n  ax.imshow(np.squeeze(images[idx]),cmap='gray')\n  ax.set_title(str(labels[idx].item()))\n","ae8e7116":"import torch.nn as nn\nimport torch.nn.functional as F","4363ea63":"class Net(nn.Module):\n  def __init__(self):\n    super(Net, self).__init__()\n    #linear layer (784->1 hidden node)\n    self.fc1 = nn.Linear(28*28,512)\n    self.fc2 = nn.Linear(512,256)\n    self.fc3 = nn.Linear(256,10)\n\n    #Dropout module with 0.2 drop probability\n    self.dropout = nn.Dropout(p=0.2)\n  \n  def forward(self,x):\n    #flatten image input\n    x = x.view(-1,28*28)\n    #add hidden layer,with activation function\n    x = self.dropout(F.relu(self.fc1(x)))\n    x = self.dropout(F.relu(self.fc2(x)))\n    x = self.fc3(x)\n    return(x)\n  \n#initialize the NN\nmodel = Net()\nprint(model)","34c0f582":"#specify loss and optimization function\n\n#specify loss function\ncriterion = nn.CrossEntropyLoss()\n\n#Specify optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.003)","52913191":"#number of epochs to train the model\nn_epochs = 50\n\n#initialize tracker for minimum validation loss\n#set initial \"min\" to infinity\nvalid_loss_min = np.Inf \n\n#prep model for training\nmodel.train()\n\nfor epoch in range(n_epochs):\n  #monitor training loss\n  train_loss = 0.0\n  valid_loss = 0.0\n\n  #train the model\n  for data,target in train_loader:\n    #clear the gradients of all optimized variables\n    optimizer.zero_grad()\n    \n    #forward pass\n    output = model(data)\n\n    #calculate the loss\n    loss = criterion(output,target)\n\n    #backward pass\n    loss.backward()\n\n    #paramter update(optimization step)\n    optimizer.step()\n\n    #update runnning training loss\n    train_loss += loss.item() * data.size(0)\n\n  #validate the model\n  model.eval()\n  for data,target in valid_loader:\n    #forward pass\n    output = model(data)\n    #calculate the loss\n    loss = criterion(output,target)\n    #update running validation loss\n    valid_loss += loss.item()*data.size(0)\n  \n  #Avergare loss over an epoch\n  train_loss = train_loss\/len(train_loader.sampler)\n  valid_loss = valid_loss\/len(valid_loader.sampler)\n\n  #print training statistics\n  print('EPOCH: {} \\tTraining loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch+1,\n                                                                             train_loss,\n                                                                             valid_loss))\n  #save model if validation loss has decreased \n  if(valid_loss <= valid_loss_min):\n    print('validation loss decreased ({:.6f})-->{:.6f}, Saving model...'.format(\n        valid_loss_min,valid_loss))\n    torch.save(model.state_dict(),'model.pt')\n    valid_loss_min = valid_loss\n","f28646cb":"model.load_state_dict(torch.load('model.pt'))","521eab22":"#initialize lists to monitor test loss and accuracy\ntest_loss = 0.0\nclass_correct = list(0. for i in range(10)) \nclass_total = list(0. for i in range(10))\n\n#prepare model for evaluation\nmodel.eval()\n\nfor data,target in test_loader:\n  #forward pass\n  output = model(data)\n\n  #calculate the loss\n  loss = criterion(output,target)\n\n  #update test loss\n  test_loss += loss.item()*data.size(0)\n\n  #convert output probabilities to predicted class\n  _,pred = torch.max(output,1)\n\n  #compare predictions to true label\n  correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n\n  #calculate test accuracy for each object class\n  for i in range(batch_size):\n    label = target.data[i]\n    class_correct[label] += correct[i].item()\n    class_total[label] += 1\n\n#calculate and print avg test loss\ntest_loss = test_loss\/len(test_loader.dataset)\nprint('test loss: {:.6f}\\n'.format(test_loss))\n","e17ee187":"\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            str(i), 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","99c4442a":"#obtain one batch of test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\n\n#get sample outputs\noutput = model(images)\n\n#convert output probabilities to predicted class\n_,preds = torch.max(output,1)\n\n#prep images to display\nimages = images.numpy()\n\n#plot images in the batch , along with the predicted and true labels\nfig = plt.figure(figsize=(25,4))\nfor idx in np.arange(20):\n  #fig.add_subplot(num_column,row,idx+1,xticks=[],yticks=[])\n  ax = fig.add_subplot(2,20\/2,idx+1,xticks=[],yticks=[])\n  ax.imshow(np.squeeze(images[idx]),cmap='gray')\n  ax.set_title(\"{} ({})\".format(str(preds[idx].item()),str(labels[idx].item()),color=(\"green\" if preds[idx]==labels[idx] else \"red\")))","2bc41cd9":"Specify Loss Function and Optimizer\n\nIt's recommended that you use cross-entropy loss for classification. If you look at the documentation (linked above), you can see that PyTorch's cross entropy function applies a softmax funtion to the output layer and then calculates the log loss.","e67adfed":"Visualize batch of training data","3fb14573":"### Visualize Sample Test Results\n\nThis cell displays test images and their labels in this format: `predicted (ground-truth)`. The text will be green for accurately classified examples and red for incorrect predictions.","1e6128a8":"----------------------------------------------\nAn Overview of Python\u2019s super() Function\n\nIf you have experience with object-oriented languages, you may already be familiar with the functionality of super().\n\nIf not, don\u2019t fear! While the official documentation is fairly technical, at a high level super() gives you access to methods in a superclass from the subclass that inherits from it.\n\nsuper() alone returns a temporary object of the superclass that then allows you to call that superclass\u2019s methods.\n\nWhy would you want to do any of this? While the possibilities are limited by your imagination, a common use case is building classes that extend the functionality of previously built classes.\n\nCalling the previously built methods with super() saves you from needing to rewrite those methods in your subclass, and allows you to swap out superclasses with minimal code changes. ","a1885bf5":"---\n## Train the Network\n\nThe steps for training\/learning from a batch of data are described in the comments below:\n1. Clear the gradients of all optimized variables\n2. Forward pass: compute predicted outputs by passing inputs to the model\n3. Calculate the loss\n4. Backward pass: compute gradient of the loss with respect to model parameters\n5. Perform a single optimization step (parameter update)\n6. Update average training loss\n\nThe following loop trains for 30 epochs; feel free to change this number. For now, we suggest somewhere between 20-50 epochs. As you train, take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data. ","e4cbd1db":"Load the Model with the lowest validation loss","c3ff6365":"# Multi-Layer Perceptron, MNIST\n---\nIn this notebook, we will train an MLP to classify images from the [MNIST database](http:\/\/yann.lecun.com\/exdb\/mnist\/) hand-written digit database.\n\nThe process will be broken down into the following steps:\n>1. Load and visualize the data\n2. Define a neural network\n3. Train the model\n4. Evaluate the performance of our trained model on a test dataset!\n\nBefore we begin, we have to import the necessary libraries for working with data and PyTorch.","3b47b079":"The architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting","6e023c8d":"---\n## Test the Trained Network\n\nFinally, we test our best model on previously unseen **test data** and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy.\n\n#### `model.eval()`\n\n`model.eval(`) will set all the layers in your model to evaluation mode. This affects layers like dropout layers that turn \"off\" nodes during training with some probability, but should allow every node to be \"on\" for evaluation!"}}