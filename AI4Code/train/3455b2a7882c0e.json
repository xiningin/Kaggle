{"cell_type":{"31a1ad21":"code","0b275b75":"code","9a87fd64":"code","5abe89d3":"code","52ca393b":"code","7d45450b":"code","5d783ece":"code","5b08e080":"code","9d4e9935":"code","361c5460":"code","45a4d3e8":"code","1fdca5fd":"code","cb2684cb":"code","2d5d954a":"code","91eec9ab":"markdown","153ca6dc":"markdown","7cbc5eb6":"markdown","17fcaaad":"markdown","c1f19286":"markdown"},"source":{"31a1ad21":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection  # Stratified KFold\nfrom sklearn import metrics  # for metrics on Regression Data\n\nimport xgboost as xgb","0b275b75":"train = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntrain.head()","9a87fd64":"train.info()","5abe89d3":"test = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\ntest.head()","52ca393b":"test.info()","7d45450b":"def create_folds(data):\n    \n    # We create a new column called kfold and fill it with -1\n    data[\"kfold\"] = -1.0\n    \n    # randomize the rows of the data\n    data = data.sample(frac=1).reset_index(drop=True)\n    \n    # Calculate the number of bins using Sturges's law\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"loss\"], bins=num_bins, labels=False\n    )\n    \n    kf = model_selection.StratifiedKFold(n_splits=5)\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins\n    for fold, (train_, val_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[val_, 'kfold'] = fold\n        \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n    \n    return data\n\ndf = create_folds(train)\ndf.to_csv(\"kfold_train.csv\", index=False)","5d783ece":"def runLR(df, fold):\n    \"\"\"\n    Calculates R2 score for Linear Regression model\n    \n    :param df: the training data frame\n    :param fold: fold on which evaluation will be performed\n    \"\"\"\n    \n    # Training and Validation data frames\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    \n    # Training data\n    x_train = df_train.drop([\"loss\", \"kfold\", \"id\"], axis=1).values\n    y_train = df_train[\"loss\"].values\n    \n    # Validation data\n    x_valid = df_valid.drop([\"loss\", \"kfold\", \"id\"], axis=1).values\n    y_valid = df_valid[\"loss\"].values\n    \n    model = xgb.XGBRegressor(n_estimators = 300, max_depth=5)\n    model.fit(x_train,y_train)\n    \n    y_pred_train = model.predict(x_train)\n    y_pred_valid = model.predict(x_valid)\n    \n    mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n    mse_valid = metrics.mean_squared_error(y_valid, y_pred_valid)\n    \n    print(f\"RMSE Score (Fold : {fold}) :: Train : {mse_train**0.5} and Valid : {mse_valid**0.5}\")","5b08e080":"data = pd.read_csv(\".\/kfold_train.csv\")\nfor f_ in range(5):\n    runLR(data, f_)","9d4e9935":"X = data.drop([\"loss\", \"kfold\", \"id\"], axis=1).values\nY = data[\"loss\"].values\n\nmodel = xgb.XGBRegressor(n_estimators = 300, max_depth=5)\nmodel.fit(X, Y)","361c5460":"XTest = test.drop([\"id\"], axis=1).values\nXTest.shape, X.shape","45a4d3e8":"YPred = model.predict(XTest)","1fdca5fd":"sub = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\nsub.head()","cb2684cb":"sub[\"loss\"] = YPred\nsub.to_csv(\"submission.csv\", index=False)","2d5d954a":"sub.head()","91eec9ab":"## Training","153ca6dc":"## Create Folds","7cbc5eb6":"### The dataset has __No Null Values!!__","17fcaaad":"## Models","c1f19286":"## Submission"}}