{"cell_type":{"05bbb2b6":"code","73528d8a":"code","9fd72d92":"code","e2798727":"code","b27d87d2":"code","2e494c74":"code","a62f8b6f":"code","822ba51c":"code","dc978e38":"code","21acaeea":"code","914dac55":"code","d54c895c":"code","880cb190":"code","5364cdec":"code","e4cf45fa":"code","edfa60db":"code","29659719":"code","4171e99e":"code","3afe5f92":"code","d641b68a":"code","0a9254d9":"code","fb5635e0":"code","aec71ee6":"code","6fa84055":"code","51d8373e":"code","1f9a1fe7":"code","d6f85505":"code","c415304f":"code","78191f71":"code","79ad29cc":"markdown","9637a7f9":"markdown","9b08a281":"markdown","e2adc40f":"markdown","db8df182":"markdown","e1349efa":"markdown"},"source":{"05bbb2b6":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport optuna\n\nfrom warnings import simplefilter\nimport gc\n\nsimplefilter('ignore')\nrs = 69420\ntrain_path = r'..\/input\/tabular-playground-series-aug-2021\/train.csv'\ntest_path = r'..\/input\/tabular-playground-series-aug-2021\/test.csv'\nsubmission_path = r'..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv'\nbudget = 3600*2","73528d8a":"train = pd.read_csv(train_path, index_col=0)\ntest = pd.read_csv(test_path, index_col=0)","9fd72d92":"train.head()","e2798727":"test.head()","b27d87d2":"y = train.loss.values\nX = train.drop([\"loss\"], axis = 1).values\n\nX.shape, y.shape","2e494c74":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\n\ndef objective(trial,data=X,target=y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=rs, stratify=target)\n    \n    sc = RobustScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n    \n    params = {\n        'iterations':trial.suggest_int(\"iterations\", 1000, 20000),\n        'od_wait':trial.suggest_int('od_wait', 500, 2000),\n        'loss_function':'RMSE',\n        'task_type':\"GPU\",\n        'eval_metric':'RMSE',\n        'leaf_estimation_method':'Newton',\n        'bootstrap_type': 'Bernoulli',\n        'learning_rate' : trial.suggest_uniform('learning_rate',0.02,1),\n        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n        'subsample': trial.suggest_uniform('subsample',0,1),\n        'random_strength': trial.suggest_uniform('random_strength',10,50),\n        'depth': trial.suggest_int('depth',1,15),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n    }\n    \n    model = CatBoostRegressor(**params)  \n    \n    model.fit(X_train, y_train, eval_set=[(X_test,y_test)], early_stopping_rounds=100, verbose=False)\n        \n    y_preds = model.predict(X_test)\n    loss = np.sqrt(mean_squared_error(y_test, y_preds))\n    \n    return loss","a62f8b6f":"%%time\nstudy = optuna.create_study(\n    direction='minimize',\n    sampler=optuna.samplers.TPESampler()\n)\n\nstudy.optimize(\n    objective,\n    timeout=budget,\n    gc_after_trial=True\n)","822ba51c":"print('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","dc978e38":"optuna.visualization.plot_optimization_history(study)","21acaeea":"cat_params = study.best_trial.params\ncat_params['loss_function'] = 'RMSE'\ncat_params['eval_metric'] = 'RMSE'\ncat_params['bootstrap_type']= 'Bernoulli'\ncat_params['leaf_estimation_method'] = 'Newton'\ncat_params['random_state'] = rs\ncat_params['task_type']='GPU'","914dac55":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor\n\ndef objective2(trial,data=X,target=y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=rs, stratify=target)\n    \n    sc = RobustScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n    \n    params = {\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha', 0.19, 0.5),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda', 0.31, 0.34),\n        'num_leaves' : trial.suggest_int('num_leaves', 50, 91),\n        'learning_rate' : trial.suggest_uniform('learning_rate', 0.01, 0.07),\n        'max_depth' : trial.suggest_int('max_depth', 3 , 67),\n        'n_estimators' : trial.suggest_int('n_estimators', 5555, 7000),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight', 0.012, 0.04),\n        'subsample' : trial.suggest_uniform('subsample', 0.789, 1.0),\n        'colsample_bytree' : trial.suggest_loguniform('colsample_bytree', 0.52, 1),\n        'min_child_samples' : trial.suggest_int('min_child_samples', 76, 80),\n        'metric' : 'rmse',\n        'device_type' : 'gpu',\n        'boosting_type':'gbdt'\n    }\n    \n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'rmse', valid_name = 'valid_0')\n    \n    model = LGBMRegressor(**params, random_state=rs)\n    model.fit(X_train, y_train, eval_set=[(X_test,y_test)], verbose=False, early_stopping_rounds=50, callbacks=[pruning_callback])\n        \n    y_preds = model.predict(X_test)\n    loss = np.sqrt(mean_squared_error(y_test, y_preds))\n    \n    return loss","d54c895c":"%%time\nstudy = optuna.create_study(\n    direction='minimize',\n    sampler=optuna.samplers.TPESampler(),\n    pruner = optuna.pruners.HyperbandPruner()\n)\n\nstudy.optimize(\n    objective2,\n    timeout=budget,\n    gc_after_trial=True\n)","880cb190":"print('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","5364cdec":"optuna.visualization.plot_optimization_history(study)","e4cf45fa":"lgbm_params = study.best_trial.params\nlgbm_params['metric'] = 'RMSE'\nlgbm_params['boosting_type']= 'gbdt'\nlgbm_params['random_state'] = rs\nlgbm_params['device'] = 'gpu'","edfa60db":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\n\ndef objective3(trial,data=X,target=y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=rs, stratify=target)\n    \n    sc = RobustScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n    \n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\",200,2000,100),\n        \"subsample\": trial.suggest_discrete_uniform(\"subsample\",0.6,1,0.1),\n        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\",0.6,1,0.1),\n        \"eta\": trial.suggest_loguniform(\"eta\",1e-3,0.1),\n        \"reg_alpha\": trial.suggest_int(\"reg_alpha\",1,50),\n        \"reg_lambda\": trial.suggest_int(\"reg_lambda\",5,100),\n        \"max_depth\": trial.suggest_int(\"max_depth\",5,20),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\",5,20),\n    }\n    \n    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation_0-rmse\")\n    model = XGBRegressor(**params, tree_method='gpu_hist', random_state=rs)\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_test,y_test)],\n        verbose=False,\n        eval_metric='rmse',\n        early_stopping_rounds=50,\n        callbacks=[pruning_callback]\n    )\n\n    y_preds = model.predict(X_test)\n    loss = np.sqrt(mean_squared_error(y_test, y_preds))\n    \n    return loss","29659719":"%%time\nstudy = optuna.create_study(\n    direction='minimize',\n    sampler=optuna.samplers.TPESampler(),\n    pruner = optuna.pruners.HyperbandPruner()\n)\n\nstudy.optimize(\n    objective3,\n    timeout=budget,\n    gc_after_trial=True\n)","4171e99e":"print('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","3afe5f92":"optuna.visualization.plot_optimization_history(study)","d641b68a":"xgb_params = study.best_trial.params\nxgb_params['tree_method'] = 'gpu_hist'\nxgb_params['random_state'] = rs","0a9254d9":"from sklearn.ensemble import VotingRegressor\n\ncat = CatBoostRegressor(**cat_params, verbose=0)\nlgbm = LGBMRegressor(**lgbm_params, verbose=0)\nxgb = XGBRegressor(**xgb_params, verbosity=0)\n\nestimators = [\n    ('Catboost', cat),\n    ('LightGBM', lgbm),\n    ('XGBoost', xgb),\n]\n\nclf = VotingRegressor(estimators=estimators)","fb5635e0":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=rs, stratify=y)\n    \nsc = RobustScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","aec71ee6":"%%time\nclf.fit(X_train, y_train)","6fa84055":"y_pred = clf.predict(X_test)","51d8373e":"print(\"Blend RMSE: \", round(np.sqrt(mean_squared_error(y_test, y_pred)), 5))","1f9a1fe7":"test_sub = sc.transform(test)","d6f85505":"submission = pd.read_csv(submission_path)\nsubmission.head()","c415304f":"submission['loss'] = clf.predict(test_sub)\nsubmission.head()","78191f71":"submission.to_csv(\"sub_stack.csv\", index=False)","79ad29cc":"# Data Prep","9637a7f9":"# LGBM Optuna Tuning","9b08a281":"# Catboost Optuna Tuning","e2adc40f":"# Optuna XGBoost","db8df182":"# Imports","e1349efa":"# Blend Models"}}