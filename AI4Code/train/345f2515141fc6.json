{"cell_type":{"5001587d":"code","a18bcbe2":"code","d02de141":"code","fcff063c":"code","70957053":"code","f8a5c2be":"markdown"},"source":{"5001587d":"\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n","a18bcbe2":"# 0) Prepare data\nbc = datasets.load_breast_cancer()\nX, y = bc.data, bc.target\n\nn_samples, n_features = X.shape\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n\n# scale. Always use SC  for logisticragression. it will be useful for zero mean and unit variance\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n#original data is in numpy array. we need to convert it to tensors before we run model,otherwise we will get errors\n\nX_train = torch.from_numpy(X_train.astype(np.float32))\nX_test = torch.from_numpy(X_test.astype(np.float32))\ny_train = torch.from_numpy(y_train.astype(np.float32))\ny_test = torch.from_numpy(y_test.astype(np.float32))\n\n# view is pytorch function that is used to reshape tensor in given size\ny_train = y_train.view(y_train.shape[0], 1)\ny_test = y_test.view(y_test.shape[0], 1)","d02de141":"\n\n# 1) Model\n# Linear model f = wx + b , sigmoid at the end\nclass Model(nn.Module):\n    def __init__(self, n_input_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(n_input_features, 1)\n\n    def forward(self, x):\n        y_pred = torch.sigmoid(self.linear(x))\n        return y_pred\n\nmodel = Model(n_features)","fcff063c":"\n\n# 2) Loss and optimizer\nnum_epochs = 200\nlearning_rate = 0.01\ncriterion = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","70957053":"\n# 3) Training loop\nfor epoch in range(num_epochs):\n    # Forward pass and loss\n    y_pred = model(X_train)\n    loss = criterion(y_pred, y_train)\n\n    # Backward pass and update\n    loss.backward()\n    optimizer.step()\n\n    # zero grad before new step\n    optimizer.zero_grad()\n\n    if (epoch+1) % 10 == 0:\n        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n\n\nwith torch.no_grad():\n    y_predicted = model(X_test)\n    y_predicted_cls = y_predicted.round()\n    acc = y_predicted_cls.eq(y_test).sum() \/ float(y_test.shape[0])\n    print(f'accuracy: {acc.item():.4f}')\n","f8a5c2be":"Credits: Python Engineer\n\nDon't hesitate to watch YouTube video. It has clear explanation\n\nhttps:\/\/youtu.be\/OGpQxIkR4ao\n\nIf you like my notebook Please upvote\n\nI will going to create more notebooks on pytorch"}}