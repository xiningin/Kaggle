{"cell_type":{"65c53ba6":"code","a15f7110":"code","6d4b761e":"code","9e99fd20":"code","5a0f977c":"code","b1b4498e":"code","5c064eba":"code","fc373eea":"code","b2f3020c":"code","6202d061":"code","5040ba15":"code","d8c58b28":"code","95f42b72":"code","b40b66d1":"code","01944d85":"code","0580ec75":"code","0fadb2d2":"code","da9e8529":"code","dc00fe88":"code","84f79687":"code","644d7229":"code","54c79d3f":"code","84dd7544":"code","54e7e064":"code","b177d98b":"code","ea0da843":"code","41025aaf":"code","fac88272":"code","84fddf09":"code","95188ab3":"code","1d81b1f8":"code","4bb15c09":"code","fe10276e":"code","b75f2d3a":"code","cb87ff42":"code","104c8040":"code","ef8266dc":"code","bf6ac362":"code","ec79490f":"code","e805cb62":"code","eae75771":"code","29a632ee":"code","1ca29c38":"code","d76ea201":"code","1c9e5deb":"code","b409ee44":"code","fd2dcb13":"code","c1a63ce1":"code","80b99ef3":"code","f3d1d565":"code","94ddd986":"code","2cfd982a":"code","b6cf5030":"code","49051ecf":"code","b60c566f":"code","911bc7b0":"code","2c6e3830":"code","7e42d418":"code","412bd8bf":"code","42232d53":"code","37e9acd1":"code","64bc5383":"code","54c7240b":"markdown","e750cbea":"markdown","eab7145d":"markdown","2a023de5":"markdown","d397ea0d":"markdown","80d38440":"markdown","1169a4eb":"markdown","755376cf":"markdown","20b0a891":"markdown","4aa78646":"markdown","81196468":"markdown","c7f13ede":"markdown","61059b6d":"markdown","8306522f":"markdown","ee213658":"markdown","b0237d28":"markdown","2f24fb88":"markdown","0c33bdce":"markdown","c06fc660":"markdown","0566a8e8":"markdown","a9070c59":"markdown","08348510":"markdown","74fc8ea8":"markdown","a3f64c69":"markdown","a9fde6c7":"markdown","09e8013f":"markdown","8fef907d":"markdown","3708fff7":"markdown","97323d2c":"markdown","4176d163":"markdown","36746565":"markdown","c15c458c":"markdown","5f99b485":"markdown","d5164e4f":"markdown","57bea070":"markdown","723d139e":"markdown","8527fb37":"markdown","856f2c44":"markdown","296736bd":"markdown","dcf169ed":"markdown","f10f24bd":"markdown","9c5a7578":"markdown","69da736e":"markdown","86927f42":"markdown","8e9b62f8":"markdown","2c70f55f":"markdown","df9e1a5e":"markdown","05cc432b":"markdown","f15b38a4":"markdown","f8211927":"markdown","ba4ef45e":"markdown","c4bc302c":"markdown","2c3dc7e0":"markdown","99d520b6":"markdown"},"source":{"65c53ba6":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nprint('numpy version : ',np.__version__)\nprint('pandas version : ',pd.__version__)\nprint('seaborn version : ',sns.__version__)\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier","a15f7110":"aadasd = pd.DataFrame()","6d4b761e":"sns.set(rc={'figure.figsize':(20.7,8.27)})\nsns.set_style(\"whitegrid\")\nsns.color_palette(\"dark\")\nplt.style.use(\"fivethirtyeight\")","9e99fd20":"from matplotlib import rcParams\nrcParams['figure.figsize'] = 12, 4\nrcParams['lines.linewidth'] = 3\nrcParams['xtick.labelsize'] = 'x-large'\nrcParams['ytick.labelsize'] = 'x-large'","5a0f977c":"df = pd.read_csv('..\/input\/all-products-available-on-sephora-website\/sephora_website_dataset.csv')\ndf.head()","b1b4498e":"df.info()","5c064eba":"df.columns","fc373eea":"numeric=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_num=df.select_dtypes(include=numeric)\ndf_num.head(3)","b2f3020c":"df_cat=df.select_dtypes(include='object')\ndf_cat.head(3)","6202d061":"describeNum = df.describe(include =['float64', 'int64', 'float', 'int'])\ndescribeNum.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","5040ba15":"describeNumCat = df.describe(include=[\"O\"])\ndescribeNumCat.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","d8c58b28":"cats = ['brand','category', 'name', 'size'] \nfor col in cats:\n    print(f'''Value count kolom {col}:''')\n    print(df[col].value_counts())\n    print()","95f42b72":"df.corr()","b40b66d1":"features = ['rating', 'number_of_reviews', 'love', 'price', 'value_price', 'online_only', 'exclusive', 'limited_edition', 'limited_time_offer']\n\nplt.figure(figsize=(30,20))\nax = sns.heatmap(data = df[features].corr(),cmap='YlGnBu',annot=True)\n\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5,top - 0.5)","01944d85":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['price'], y=df['value_price'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"price\", ylabel=\"value_price\")","0580ec75":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['love'], y=df['number_of_reviews'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"love\", ylabel=\"number_of_reviews\")","0fadb2d2":"features = ['number_of_reviews', 'love', 'price', 'value_price']\nplt.figure(figsize=(20, 8))\nfor i in range(0, len(features)):\n    plt.subplot(1, 7, i+1)\n    sns.boxplot(y=df[features[i]],color='green',orient='v')","da9e8529":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Sale Price Distribution Plot')\nsns.distplot(df.value_price)\n\nplt.subplot(1,2,2)\nplt.title('Sale Price Spread')\nsns.boxplot(y=df.value_price)\n\nplt.show()","dc00fe88":"print(df.value_price.describe(percentiles = [0.25,0.50,0.75,0.85,0.90,1]))","84f79687":"# GET SKEWNESS \nprint(f\"Skewness Co-efficient: {round(df.value_price.skew(), 3)}\")\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), dpi=300)\n\n# HISTOGRAM \nfrom scipy import stats\nsns.distplot(df['value_price'] , fit=stats.norm, ax=ax1)\nax1.set_title('Histogram')\n\n# PROBABILITY \/ QQ PLOT\nstats.probplot(df['value_price'], plot=ax2)\n\nplt.show()","644d7229":"df[\"value_price\"] = np.log1p(df[\"value_price\"])\n\n# GET SKEWNESS \nprint(f\"Skewness Co-efficient: {round(df.value_price.skew(), 3)}\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), dpi=300)\n\n# HISTOGRAM \nfrom scipy import stats\nsns.distplot(df['value_price'] , fit=stats.norm, ax=ax1)\nax1.set_title('Histogram')\n# PROBABILITY \/ QQ PLOT\nstats.probplot(df['value_price'], plot=ax2)\n\nplt.show()","54c79d3f":"for index, row in df.iterrows():\n    if row['price']!=row['value_price']:\n        print(index, row['price'], row['value_price'])","84dd7544":"bestBrandReviews = df.groupby([\"brand\"]).head()\nbestBrandReviews = bestBrandReviews.sort_values('number_of_reviews', ascending=False)\nbestBrandReviews.head(10)","54e7e064":"rating_products = pd.DataFrame(round(df.groupby('brand')['rating'].mean(),2))\nmost_rating = rating_products.sort_values('rating', ascending=False)\nmost_rating.head(10)","b177d98b":"popular_products = pd.DataFrame(df.groupby('brand')['rating'].sum())\nmost_popular = popular_products.sort_values('rating', ascending=False)\nmost_popular.head(10)","ea0da843":"price_products = pd.DataFrame(df.groupby('brand')['price'].mean())\nmost_price = price_products.sort_values('price', ascending=False)\nmost_price.head(10)","41025aaf":"love_products = pd.DataFrame(df.groupby('brand')['love'].mean())\nmost_love = love_products.sort_values('love', ascending=False)\nmost_love.head(10)","fac88272":"reviews_products = pd.DataFrame(df.groupby('brand')['number_of_reviews'].mean())\nmost_reviews = reviews_products.sort_values('number_of_reviews', ascending=False)\nmost_reviews.head(10)","84fddf09":"xbrand = df[df['brand']=='Buxom']\nxbrand.head(45)","95188ab3":"ybrand = df[df['brand']=='stila']\nybrand.head(10)","1d81b1f8":"zbrand = df[df['brand']=='NARS']\nzbrand.head(45)","4bb15c09":"price_category = pd.DataFrame(df.groupby('category')['rating'].mean())\nmost_price = price_category.sort_values('rating', ascending=False)\nmost_price.head()","fe10276e":"price_sorted_category = pd.pivot_table(df,\n              index=['category'],\n              values=['price'],\n              aggfunc=['sum']\n              ).reset_index()\nprice_sorted_category.columns = ['category', 'price']\nprice_sorted_category = price_sorted_category.sort_values(['price'], ascending = False)\nprice_sorted_category = price_sorted_category.head(10)\nprice_sorted_category","b75f2d3a":"fig, ax = plt.subplots(figsize=(15,7))\n_ = sns.barplot(x=\"category\", y=\"price\", data=price_sorted_category,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Total Price\")","cb87ff42":"price_sorted_category = pd.pivot_table(df,\n              index=['brand'],\n              values=['price'],\n              aggfunc=['sum']\n              ).reset_index()\nprice_sorted_category.columns = ['brand', 'price']\nprice_sorted_category = price_sorted_category.sort_values(['price'], ascending = False)\nprice_sorted_category = price_sorted_category.head(10)\nprice_sorted_category","104c8040":"brandHighestPrice = df[(df[\"brand\"] == 'TOM FORD')]\nbrandHighestPrice.head()","ef8266dc":"fig, ax = plt.subplots(figsize=(15,7))\n_ = sns.barplot(x=\"category\", y=\"price\", data=brandHighestPrice,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Total Price\")","bf6ac362":"price_sorted_category = pd.pivot_table(df,\n              index=['name'],\n              values=['price'],\n              aggfunc=['sum']\n              ).reset_index()\nprice_sorted_category.columns = ['name', 'price']\nprice_sorted_category = price_sorted_category.sort_values(['price'], ascending = False)\nprice_sorted_category = price_sorted_category.head(10)\nprice_sorted_category","ec79490f":"plt.figure(figsize=(30,100),dpi=100)\nplt.xticks(rotation=90)\nplt.title('Brand Counts')\nsns.countplot(y=df['brand'], palette=\"nipy_spectral\");","e805cb62":"brandbig10 = df.groupby(['brand'])['exclusive'].count().sort_values(ascending=False).reset_index().head(10)\n\nplt.figure(figsize=(18,6), dpi=100)\nplt.subplot(2,2,1)\nplt.ylabel('')\nplt.xlabel('')\nsns.barplot(y=brandbig10['brand'],x=brandbig10['exclusive'], palette='nipy_spectral')","eae75771":"plt.figure(figsize=(25,40),dpi=100)\nplt.xticks(rotation=90)\nplt.title('Category Counts')\nsns.countplot(y=df['category'], palette=\"nipy_spectral\");","29a632ee":"categorybig10 = df.groupby(['category'])['exclusive'].count().sort_values(ascending=False).reset_index().head(10)\n\nplt.figure(figsize=(18,6), dpi=100)\nplt.subplot(2,2,1)\nplt.ylabel('')\nplt.xlabel('')\nsns.barplot(y=categorybig10['category'],x=categorybig10['exclusive'], palette='nipy_spectral')","1ca29c38":"sns.countplot(df['rating'],palette='nipy_spectral',orient='v')","d76ea201":"features = ['number_of_reviews','love','price','value_price']\nplt.figure(figsize=(15, 10))\nfor i in range(0, len(features)):\n    plt.subplot(1, 4, i+1)\n    sns.boxplot(y=df[features[i]],color='green',orient='v')\n    plt.tight_layout()","1c9e5deb":"df['number_of_reviews'] = np.log1p(df['number_of_reviews'])\ndf['love'] = np.log1p(df['love'])\ndf['price'] = np.log1p(df['price'])\ndf['value_price'] = np.log1p(df['value_price'])","b409ee44":"plt.figure(figsize=(15, 7))\nfor i in range(0, len(features)):\n    plt.subplot(1, 4, i+1)\n    sns.boxplot(y=df[features[i]],color='green',orient='v')\n    plt.tight_layout()","fd2dcb13":"df.info()","c1a63ce1":"df['MarketingFlags'] = df.MarketingFlags.map({False:0, True:1})","80b99ef3":"df = df.drop(['id'],axis=1)\ndf = df.drop(['name'],axis=1)\ndf = df.drop(['URL'],axis=1)\ndf = df.drop(['options'],axis=1)\ndf = df.drop(['details'],axis=1)\ndf = df.drop(['how_to_use'],axis=1)\ndf = df.drop(['ingredients'],axis=1)\ndf = df.drop(['price'],axis=1)","f3d1d565":"df.head()","94ddd986":" df['rating']=df['rating'].astype(str)","2cfd982a":"# Get all the categorical columns\ncat_cols = df.select_dtypes(\"object\").columns\n\n## One-Hot Encoding all the categorical variables but dropping one of the features among them.\ndrop_categ = []\nfor i in cat_cols:\n    drop_categ += [ i+'_'+str(df[i].unique()[-1]) ]\n\n## Create dummy variables (One-Hot Encoding)\ndf = pd.get_dummies(df, columns=cat_cols) \n\n## Drop the last column generated from each categorical feature\ndf.drop(drop_categ, axis=1, inplace=True)","b6cf5030":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics\n\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet","49051ecf":"X = df.drop('value_price', axis = 1) \ny = df['value_price']","b60c566f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","911bc7b0":"# scaler = RobustScaler() #RobustScaler - StandardScaler\n# X_train = scaler.fit_transform(X_train)\n# X_test = scaler.transform(X_test)","2c6e3830":"# lets print the shapes again \nprint(\"Shape of the X Train :\", X_train.shape)\nprint(\"Shape of the y Train :\", y_train.shape)\nprint(\"Shape of the X test :\", X_test.shape)\nprint(\"Shape of the y test :\", y_test.shape)","7e42d418":"# Model Build\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve, auc, precision_recall_curve, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')","412bd8bf":"xgb = XGBRegressor()\n\nxgb.fit(X_train, y_train)\ndf_imp = pd.DataFrame(xgb.feature_importances_ , columns = ['Importance'], index=X_train.columns)\ndf_imp = df_imp.sort_values(['Importance'], ascending = False)\n\ndf_imp.head()","42232d53":"XGB_model = XGBRegressor()\n\nXGB_model.fit(X_train, y_train)\ny_pred= XGB_model.predict(X_test)\n\nprint(\"Accuracy on Traing set   : \",XGB_model.score(X_train,y_train))\nprint(\"Accuracy on Testing set  : \",XGB_model.score(X_test,y_test))\nprint(\"__________________________________________\")\nprint(\"\\t\\tError Table\")\nprint('Mean Absolute Error      : ', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared  Error      : ', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error  : ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('R Squared Error          : ', metrics.r2_score(y_test, y_pred))","37e9acd1":"RandomForest = RandomForestRegressor()\nRandomForest.fit(X_train, y_train)\ny_pred= RandomForest.predict(X_test)\n\nprint(\"Accuracy on Traing set   : \",RandomForest.score(X_train,y_train))\nprint(\"Accuracy on Testing set  : \",RandomForest.score(X_test,y_test))\nprint(\"__________________________________________\")\nprint(\"\\t\\tError Table\")\nprint('Mean Absolute Error      : ', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error       : ', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error  : ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('R Squared Error          : ', metrics.r2_score(y_test, y_pred))","64bc5383":"ridge = Ridge()\nridge.fit(X_train, y_train)\ny_pred= ridge.predict(X_test)\n\nprint(\"Accuracy on Traing set   : \",ridge.score(X_train,y_train))\nprint(\"Accuracy on Testing set  : \",ridge.score(X_test,y_test))\nprint(\"__________________________________________\")\nprint(\"\\t\\tError Table\")\nprint('Mean Absolute Error      : ', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared  Error      : ', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error  : ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('R Squared Error          : ', metrics.r2_score(y_test, y_pred))","54c7240b":"### What Category With The Highest sales from Highest Income Value Brands","e750cbea":"# Data Preparation","eab7145d":"## Ridge Regression","2a023de5":"### Analysis Variable Dependent \"value_price\"","d397ea0d":"### Categorical Value Counting","80d38440":"### What Product With The Highest Price","1169a4eb":"## Graphic Approach","755376cf":"# Data Exploration","20b0a891":"# Sephora Website\n","4aa78646":"## Data numeric","81196468":"As for some brands that have the most love in the previous category can be seen also fall into the category of number_of_reviews the top 10. some of them are **Buxom, stila, NARS, Anastasia Beverly Hills, Makeup Eraser, and Urban Decay**. here it can also be seen that these two variables have correlations that can later be seen at the time of correlation analysis before.","c7f13ede":"The analysis obtained by SEPHORA COLLECTION brand managed to become the most popular product with a total number of ratings given by consumers, namely 1893.5 rating. but this could be because this brand has a lot of sales.","61059b6d":"Based on the analysis of the above 3 variables can be seen clearly from the brand **'NARS'** which has good data from the side of **love and number_of_reviews** but does not show any correlation with exclusive whether or not a product. so it can be concluded that the two columns **love and number_of_reviews** do not really affect the value of an item is exclusive what not.","8306522f":"### What is the Rating With the Most Sales? ","ee213658":"## Standardization","b0237d28":"The next step is to analyze the column 'value_price', because the target variable is numeric then look at the histogram whether distributed normally or not. in the column, in the 'value_price' column, we can see a positive skewed because the tail of the distribution is to the right of the most value. That is, most distributions are in low value. So, the target variable is right skewed. As (linear) models love normally distributed data , we need to transform this variable and make it more normally distributed. We will apply log transformation to the feature to make the distribution close to gaussian. We will apply log(1+x) transformation to avoid 0 values (if present)","2f24fb88":"### Scatter plot","0c33bdce":"### What is the Brand With the Most Sales?","c06fc660":"- Brand **Four Sigmatic** which is the most popular brand is not the brand that is the highest rated brand, it shows that this brand is only a popular brand but not the most effective brand for buyers. \n- However, **Fable & Mane\t, Aether Beauty, and Montblanc** brands are the highest rated brands with maximum scores, and this shows many who like these brands with all the qualities they have given.\n","0566a8e8":"### Analysis Variable Brand Buxom, stila, and NARS","a9070c59":"**Analysis results From Correlation Heatmap**\n- based on the picture above can be seen that the 'price' and 'value_price' features have a correlation of 0.99, then it is necessary to check further whether these two features have the same actual value but different column names only? \n- 'love' and 'number_of_review' features can also be seen to have a fairly high correlation value of 0.74.","08348510":"### What are the Most Expensive Brands","74fc8ea8":"### What Brand With The Highest Income Value","a3f64c69":"## Data categorical","a9fde6c7":"# Exploratory Data Analysis","09e8013f":"### Statistical Summary","8fef907d":"## Feature Engineering","3708fff7":"### What Product got a lot of Love From Customer","97323d2c":"## Load Dataset","4176d163":"## Outliers","36746565":"After transformation the skewness has reduced from 3.143 to 0.31, and the plot now looks close to the normal distribution and the probability plot can confirm the same.","c15c458c":"### Price and Value_price Check Similarity ","5f99b485":"### What is the Category With the Most Sales?","d5164e4f":"From the information above, it shows us: \n* Dataframe has a total of 9268 rows and 21 columns \n* Target Regression is the column 'value_price' with data type 'float64' ","57bea070":"We can be seen that indeed these two tables have many different values therefore it is then decided to keep these two features.","723d139e":"### What Brand Got the Highest Number of Reviews","8527fb37":"### Correlation heatmap","856f2c44":"# Modeling","296736bd":"## Dataset\nThe dataset was collected by **Raghad Alharbi** using web scraping methods like selenium and beautiful soup to collect more than 1,000 useful records from Sephora website.\n\n## Goals\nPredict the price of product based on the features available\n\n## Objective\nThe objective is to analyze product based on several variables, determine what variables affect product price the most, then build a model that can predict the price of a Product.","dcf169ed":"### What Product got a lot of Reviews From Customer","f10f24bd":"## Description","9c5a7578":"### Boxplot","69da736e":"- Brand **Four Sigmatic, Montblanc, and Aether Beauty** which are the highest rated brands can be seen not including brands with an average price of expensive products.  \n- Brands such as **dyson, ReFa, and LightStim** which are the brands with the average price of the most expensive products. brand **ReFa** itself is a brand that falls into the top 10 category with the best rating with a score of 4.83.\n","86927f42":"## Numerical Approach","8e9b62f8":"### What Most Popular Product Based on Rating","2c70f55f":"### Analysis Variable Brand = 'TOM FORD'","df9e1a5e":"### What Product got the most total Rating","05cc432b":"## Feature encoding (one hot encoding)","f15b38a4":"### What Most Popular Category Based on Rating","f8211927":"## Random Forest","ba4ef45e":"Based on the table above can be seen some columns that have abnormal data distribution among them because it has mean values and medians that are far linked.","c4bc302c":"## XGBoost","2c3dc7e0":"## Import Libraries","99d520b6":"### What Category With The Highest Income Value"}}