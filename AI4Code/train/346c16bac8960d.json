{"cell_type":{"d2f0402e":"code","500022d4":"code","809a72dc":"code","3f77818f":"code","e684f2b0":"code","61185ae0":"code","21034e38":"code","5c48493a":"code","7c464d87":"code","a6bf89ad":"code","533a7500":"code","1794b8c1":"code","289d20f6":"code","59039056":"code","5ab435ad":"code","c8321590":"code","60087742":"code","09a5cca3":"code","bf939190":"code","013d95a0":"code","c830a69a":"code","ac0c412b":"code","96dd45aa":"code","78ed3d34":"code","dcd0ba3e":"code","f784c96a":"code","83c8d7b2":"code","11bbd058":"code","90bcadf9":"code","28f6dae1":"code","72bc297a":"code","5de52da9":"code","49f19723":"code","02c26c1a":"code","d2a4920d":"code","9eac5a0e":"code","73dcf654":"code","67925346":"code","f62ca532":"markdown","aea6003f":"markdown","08b3a601":"markdown","6385cee1":"markdown","a326c97e":"markdown","b5189eb9":"markdown","c5542583":"markdown","f869aafb":"markdown","bae8d6e5":"markdown","2b78aba8":"markdown","9164f2b8":"markdown","fc6b5fe2":"markdown","cc9f1125":"markdown","c1cd417a":"markdown","b9e26c29":"markdown","880e452b":"markdown","1c354872":"markdown","23ce21af":"markdown"},"source":{"d2f0402e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# v1\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom PIL import Image\n\n# v3\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.utils import shuffle\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.metrics import *\n# v4\n\nACCURACY_LIST = []\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.models import Model\n\n# v5\n!pip install efficientnet\nfrom efficientnet.keras import EfficientNetB4\nfrom keras import backend as K\n\n# v6\n# Get reproducible results\nfrom numpy.random import seed\nseed(1)\nimport tensorflow as tf\ntf.random.set_seed(1)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","500022d4":"metadata = pd.read_csv('\/kaggle\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv')\nsummary = pd.read_csv('\/kaggle\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_dataset_Summary.csv')\n\nmetadata.sample(10)","809a72dc":"train_data = metadata[metadata['Dataset_type'] == 'TRAIN']\ntest_data = metadata[metadata['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == metadata.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")\ntest_data.sample(10)","3f77818f":"# Null value calculation\nprint(f\"Count of null values in train :\\n{train_data.isnull().sum()}\")\nprint(f\"Count of null values in test :\\n{test_data.isnull().sum()}\")","e684f2b0":"# Substitute null values with string unknown\ntrain_fill = train_data.fillna('unknown')\ntest_fill = test_data.fillna('unknown')\n\ntrain_fill.sample(10)","61185ae0":"# Count plot for 3 attributes with unknown variable addition\ntargets = ['Label', 'Label_2_Virus_category', 'Label_1_Virus_category']\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\nsns.countplot(x=targets[0], data=train_fill, ax=ax[0, 0])\nsns.countplot(x=targets[1], data=train_fill, ax=ax[0, 1])\nsns.countplot(x=targets[2], data=train_fill, ax=ax[1, 0])\nplt.show()","21034e38":"# Pie chart representation of Label_2_Virus_category values\n\ncolors = ['#ff5733', '#33ff57']\nexplode = [0.02, 0.02]\n\nvalues = ['unknown', 'other']\npercentages = [100 * (train_fill[train_fill[targets[1]] == 'unknown'].shape[0]) \/ train_fill.shape[0],\n              100 * (train_fill[train_fill[targets[1]] != 'unknown'].shape[0]) \/ train_fill.shape[0]]\n\nfig1, ax1 = plt.subplots(figsize=(7, 7))\n\nplt.pie(percentages, colors=colors, labels=values,\n        autopct='%1.1f%%', startangle=0, explode=explode)\nfig = plt.gcf()\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\nfig.gca().add_artist(centre_circle)\n\nax1.axis('equal')\nplt.tight_layout()\nplt.title('Percentage of \"unknown\" values present in Label_2_Virus_category')\nplt.show()","5c48493a":"# Count plot for 3 target variables without filling unknown variable\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\nsns.countplot(x=targets[0], data=train_data, ax=ax[0, 0])\nsns.countplot(x=targets[1], data=train_data, ax=ax[0, 1])\nsns.countplot(x=targets[2], data=train_data, ax=ax[1, 0])\nplt.show()","7c464d87":"print(f\"Label = Normal Cases : {train_data[train_data['Label'] == 'Normal'].shape[0]}\")\nprint(f\"\"\"Label = Pnemonia + Label_2_Virus_category = COVID-19 cases : {train_data[(train_data['Label'] == 'Pnemonia')\n      & (train_data['Label_2_Virus_category'] == 'COVID-19')].shape[0]}\"\"\")\nprint(f\"\"\"Label = Normal + Label_2_Virus_category = COVID-19 cases : {train_data[(train_data['Label'] == 'Normal')\n      & (train_data['Label_2_Virus_category'] == 'COVID-19')].shape[0]}\"\"\")","a6bf89ad":"TEST_FOLDER = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test'\nTRAIN_FOLDER = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'\n\nassert os.path.isdir(TEST_FOLDER) == True\nassert os.path.isdir(TRAIN_FOLDER) == True","533a7500":"sample_train_images = list(os.walk(TRAIN_FOLDER))[0][2][:8]\nsample_train_images = list(map(lambda x: os.path.join(TRAIN_FOLDER, x), sample_train_images))\n\nsample_test_images = list(os.walk(TEST_FOLDER))[0][2][:8]\nsample_test_images = list(map(lambda x: os.path.join(TEST_FOLDER, x), sample_test_images))","1794b8c1":"# Plot sample training images\nplt.figure(figsize=(20, 20))\n\nfor iterator, filename in enumerate(sample_train_images):\n    image = Image.open(filename)\n    plt.subplot(4, 2, iterator+1)\n    plt.axis('off')\n    plt.imshow(image)\n\n\nplt.tight_layout()","289d20f6":"# Plot sample testing images\nplt.figure(figsize=(20, 20))\n\nfor iterator, filename in enumerate(sample_test_images):\n    image = Image.open(filename)\n    plt.subplot(4, 2, iterator+1)\n    plt.axis('off')\n    plt.imshow(image)\n\n\nplt.tight_layout()","59039056":"# Plot b\/w image histograms of Label_2_Virus_category type \"COVID-19\" patients \nfig, ax = plt.subplots(4, 2, figsize=(20, 20))\n\ncovid19_type_file_paths = train_data[train_data['Label_2_Virus_category'] == 'COVID-19']['X_ray_image_name'].values\nsample_covid19_file_paths = covid19_type_file_paths[:4]\nsample_covid19_file_paths = list(map(lambda x: os.path.join(TRAIN_FOLDER, x), sample_covid19_file_paths))\n\nfor row, file_path in enumerate(sample_covid19_file_paths):\n    image = plt.imread(file_path)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label 2 Virus Category = COVID-19', size=16)\nplt.show()","5ab435ad":"# Plot b\/w image histograms of Label type \"Normal\" patients \nfig, ax = plt.subplots(4, 2, figsize=(20, 20))\n\nother_type_file_paths = train_data[train_data['Label'] == 'Normal']['X_ray_image_name'].values\nsample_other_file_paths = other_type_file_paths[:4]\nsample_other_file_paths = list(map(lambda x: os.path.join(TRAIN_FOLDER, x), sample_other_file_paths))\n\nfor row, file_path in enumerate(sample_other_file_paths):\n    image = plt.imread(file_path)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label = Normal', size=16)\nplt.show()","c8321590":"# Generate the final train data from original train data with conditions refered from EDA inference\nfinal_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n\n# Create a target attribute where value = positive if 'Pnemonia + COVID-19' or value = negative if 'Normal'\nfinal_train_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in final_train_data['Label']]\n\nfinal_train_data = shuffle(final_train_data, random_state=1)\n\nfinal_validation_data = final_train_data.iloc[1000:, :]\nfinal_train_data = final_train_data.iloc[:1000, :]\n\nprint(f\"Final train data shape : {final_train_data.shape}\")\nfinal_train_data.sample(10)","60087742":"train_image_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=90,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    horizontal_flip=True,\n    zoom_range=[0.9, 1.25],\n    brightness_range=[0.5, 1.5]\n)\n\ntest_image_generator = ImageDataGenerator(\n    rescale=1.\/255\n)\n\ntrain_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_train_data,\n    directory=TRAIN_FOLDER,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=8,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\nvalidation_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_validation_data,\n    directory=TRAIN_FOLDER,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=8,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\ntest_generator = test_image_generator.flow_from_dataframe(\n    dataframe=test_data,\n    directory=TEST_FOLDER,\n    x_col='X_ray_image_name',\n    target_size=(224, 224),\n    shuffle=False,\n    batch_size=16,\n    class_mode=None\n)","09a5cca3":"def scheduler(epoch):\n    if epoch < 5:\n        return 0.0001\n    else:\n        print(f\"Learning rate reduced to {0.0001 * np.exp(0.5 * (5 - epoch))}\")\n        return 0.0001 * np.exp(0.5 * (5 - epoch))\n    \ncustom_callback = LearningRateScheduler(scheduler)\n\nMETRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'), \n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]","bf939190":"model = Sequential([\n    Conv2D(64, (3, 3), input_shape=(224, 224, 3), activation='relu'),\n    MaxPooling2D((3, 3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((3, 3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((3, 3)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.4),\n    Dense(32, activation='relu'),\n    Dropout(0.4),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=Adam(), loss=binary_crossentropy,\n             metrics=METRICS)","013d95a0":"history = model.fit_generator(train_generator,\n                   validation_data=validation_generator,\n                   epochs=20,\n                   callbacks=[custom_callback])","c830a69a":"model.save('covid19_xray_base_cnn_model.h5')\nACCURACY_LIST.append(['Base CNN Model', history])","ac0c412b":"fig, ax = plt.subplots(2, 2, figsize=(10, 10))\nsns.lineplot(x=np.arange(1, 21), y=history.history.get('loss'), ax=ax[0, 0])\nsns.lineplot(x=np.arange(1, 21), y=history.history.get('auc'), ax=ax[0, 1])\nsns.lineplot(x=np.arange(1, 21), y=history.history.get('val_loss'), ax=ax[1, 0])\nsns.lineplot(x=np.arange(1, 21), y=history.history.get('val_auc'), ax=ax[1, 1])\nax[0, 0].set_title('Training Loss vs Epochs')\nax[0, 1].set_title('Training AUC vs Epochs')\nax[1, 0].set_title('Validation Loss vs Epochs')\nax[1, 1].set_title('Validation AUC vs Epochs')\nfig.suptitle('Base CNN model', size=16)\nplt.show()","96dd45aa":"balanced_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\nbalanced_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in balanced_data['Label']]\n\nbalanced_data_subset_normal = balanced_data[balanced_data['target'] == 'negative']\nbalanced_data_subset_covid = balanced_data[balanced_data['target'] == 'positive']\nbalanced_data_frac_normal = balanced_data_subset_normal.sample(frac=(1\/5))\n\nbalanced_data_concat = pd.concat([balanced_data_frac_normal, balanced_data_subset_covid], axis=0)\nbalanced_data_concat = shuffle(balanced_data_concat, random_state=0)\nbalanced_data_train = balanced_data_concat[:240]\nbalanced_data_validation = balanced_data_concat[240:]\n\nprint(f\"Balanced train data shape {balanced_data_train.shape}\")\nprint(f\"Balanced validation data shape {balanced_data_validation.shape}\")","78ed3d34":"balanced_train_generator = train_image_generator.flow_from_dataframe(\n    dataframe=balanced_data_train,\n    directory=TRAIN_FOLDER,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=64,\n    class_mode='binary'\n)\n\nbalanced_validation_generator = train_image_generator.flow_from_dataframe(\n    dataframe=balanced_data_validation,\n    directory=TRAIN_FOLDER,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=64,\n    class_mode='binary'\n)","dcd0ba3e":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'), \n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]\n\nbalanced_model = Sequential([\n    Conv2D(64, (3, 3), input_shape=(224, 224, 3), activation='relu'),\n    MaxPooling2D((3, 3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((3, 3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((3, 3)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.4),\n    Dense(32, activation='relu'),\n    Dropout(0.4),\n    Dense(1, activation='sigmoid')\n])\n\nbalanced_model.compile(optimizer=Adam(), loss=binary_crossentropy,\n             metrics=METRICS)","f784c96a":"balanced_model.summary()","83c8d7b2":"balanced_history = balanced_model.fit_generator(balanced_train_generator,\n                                               epochs=30,\n                                               validation_data=balanced_validation_generator,\n                                               callbacks=[custom_callback])","11bbd058":"balanced_model.save('covid19_xray_base_cnn_model_balanced.h5')\nACCURACY_LIST.append(['Balanced Base Model', balanced_history])","90bcadf9":"fig, ax = plt.subplots(2, 2, figsize=(10, 10))\nsns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('loss'), ax=ax[0, 0])\nsns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('auc'), ax=ax[0, 1])\nsns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('val_loss'), ax=ax[1, 0])\nsns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('val_auc'), ax=ax[1, 1])\nax[0, 0].set_title('Training Loss vs Epochs')\nax[0, 1].set_title('Training AUC vs Epochs')\nax[1, 0].set_title('Validation Loss vs Epochs')\nax[1, 1].set_title('Validation AUC vs Epochs')\nfig.suptitle('Balanced base CNN model', size=16)\nplt.show()","28f6dae1":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'), \n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]\n\ndef output_custom_model(prebuilt_model):\n    print(f\"Processing {prebuilt_model}\")\n    prebuilt = prebuilt_model(include_top=False,\n                            input_shape=(224, 224, 3),\n                            weights='imagenet')\n    output = prebuilt.output\n    output = GlobalMaxPooling2D()(output)\n    output = Dense(128, activation='relu')(output)\n    output = Dropout(0.2)(output)\n    output = Dense(1, activation='sigmoid')(output)\n\n    model = Model(inputs=prebuilt.input, outputs=output)\n    model.compile(optimizer='sgd', loss=binary_crossentropy,\n              metrics=METRICS)\n    return model","72bc297a":"resnet_custom_model = output_custom_model(ResNet50)\nresnet_history = resnet_custom_model.fit_generator(train_generator,\n                                 epochs=20,\n                                 validation_data=validation_generator,\n                                 callbacks=[custom_callback])","5de52da9":"resnet_custom_model.save('covid19_xray_resnet_50.h5')\nACCURACY_LIST.append(['ResNet 50', resnet_history])","49f19723":"fig, ax = plt.subplots(2, 2, figsize=(10, 10))\nsns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('loss'), ax=ax[0, 0])\nsns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('auc'), ax=ax[0, 1])\nsns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('val_loss'), ax=ax[1, 0])\nsns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('val_auc'), ax=ax[1, 1])\nax[0, 0].set_title('Training Loss vs Epochs')\nax[0, 1].set_title('Training AUC vs Epochs')\nax[1, 0].set_title('Validation Loss vs Epochs')\nax[1, 1].set_title('Validation AUC vs Epochs')\nfig.suptitle('ResNet 50 model', size=16)\nplt.show()","02c26c1a":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'), \n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]\n\nefficient_net_custom_model = output_custom_model(EfficientNetB4)\nefficient_net_history = efficient_net_custom_model.fit_generator(train_generator,\n                                 epochs=20,\n                                 validation_data=validation_generator,\n                                 callbacks=[custom_callback])","d2a4920d":"efficient_net_custom_model.save('covid19_xray_efficient_net_B4.h5')\nACCURACY_LIST.append(['EfficientNet B4', efficient_net_history])","9eac5a0e":"fig, ax = plt.subplots(2, 2, figsize=(10, 10))\nsns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('loss'), ax=ax[0, 0])\nsns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('auc'), ax=ax[0, 1])\nsns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('val_loss'), ax=ax[1, 0])\nsns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('val_auc'), ax=ax[1, 1])\nax[0, 0].set_title('Training Loss vs Epochs')\nax[0, 1].set_title('Training AUC vs Epochs')\nax[1, 0].set_title('Validation Loss vs Epochs')\nax[1, 1].set_title('Validation AUC vs Epochs')\nfig.suptitle('EfficientNet B4 model', size=16)\nplt.show()","73dcf654":"ACCURACY_LIST = np.array(ACCURACY_LIST)\nmodel_names = ACCURACY_LIST[:, 0]\nhistories = ACCURACY_LIST[:, 1]\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 20))\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('auc')[-1], histories)), ax=ax[0, 0], palette='Spectral')\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('val_auc')[-1], histories)), ax=ax[0, 1], palette='gist_yarg')\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('accuracy')[-1], histories)), ax=ax[1, 0], palette='rocket')\nsns.barplot(x=model_names, y=list(map(lambda x: x.history.get('val_accuracy')[-1], histories)), ax=ax[1, 1], palette='ocean_r')\nax[0, 0].set_title('Model Training AUC scores')\nax[0, 1].set_title('Model Validation AUC scores')\nax[1, 0].set_title('Model Training Accuracies')\nax[1, 1].set_title('Model Validation Accuracies')\nfig.suptitle('Model Comparisions')\nplt.show()","67925346":"metric_dataframe = pd.DataFrame({\n    'Model Names': model_names,\n    'True Positives': list(map(lambda x: x.history.get('tp')[-1], histories)),\n    'False Positives': list(map(lambda x: x.history.get('fp')[-1], histories)),\n    'True Negatives': list(map(lambda x: x.history.get('tn')[-1], histories)),\n    'False Negatives': list(map(lambda x: x.history.get('fn')[-1], histories))\n})\nfig, ax = plt.subplots(2, 2, figsize=(20, 20))\nsns.barplot(x='Model Names', y='True Positives', data=metric_dataframe, ax=ax[0, 0], palette='BrBG')\nsns.barplot(x='Model Names', y='False Positives', data=metric_dataframe, ax=ax[0, 1], palette='icefire_r')\nsns.barplot(x='Model Names', y='True Negatives', data=metric_dataframe, ax=ax[1, 0], palette='PuBu_r')\nsns.barplot(x='Model Names', y='False Negatives', data=metric_dataframe, ax=ax[1, 1], palette='YlOrBr')\nax[0, 0].set_title('True Positives of Models')\nax[0, 1].set_title('False Positives of Models')\nax[1, 0].set_title('True Negatives of Models')\nax[1, 1].set_title('False Negatives of Models')\nfig.suptitle('Confusion Matrix comparision of Models', size=16)\nplt.show()","f62ca532":"### Inferences\n\n- Reducing imbalances results in reduced training images\n- Accuracy reduced because of reduced training images\n- Validation accuracy still remains stale even on reducing number of \"Normal\" labelled images\n- V5 changes:\n    - A good measure for imbalanced dataset is Area Under the Curve(AUC)\n    - The metrics for the model changed to AUC in version 5\n    - Comparision of models will be done based on AUC score","aea6003f":"## Base CNN model with lower imbalance in data\n\n- In this subsection, we try to remove 95.86 % imbalance present in the data\n- We will remove 4 \/ 5 th of the Normal labelled images while keeping the count of COVID-19 labelled images same\n- `1342 \/ 5 ~ 269; 269 \/ (269 + 58) ~ 82.26 % `\n- To compensate for less number of training images, we increase the number of epochs","08b3a601":"### Analysis of Image files","6385cee1":"## Binary Accuracy and AUC score comparision\n\n- As the data is imbalanced, more concentration will be given on AUC score comparision","a326c97e":"## Training EfficientNet B4 on data\n\n[EfficientNet Arxiv Paper](https:\/\/arxiv.org\/abs\/1905.11946)\n\n- Reduced batch-size of data generators due to ResourceExhaustionError()","b5189eb9":"### Image Histograms\n\n> An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value. By looking at the histogram for a specific image a viewer will be able to judge the entire tonal distribution at a glance.\n\nSource : [Image histogram](https:\/\/en.wikipedia.org\/wiki\/Image_histogram)","c5542583":"### Inference from metric comparisions\n\n- ResNet 50 has the most AUC score out of all the models\n- In our experiment, it is higly important for a model to correctly predict COVID-19 patient, thus it should have high True Positive score and low False Negative score\n- ResNet 50 has the highest True Positive score and lowest False Negative score\n- From the metric comparisions, ResNet 50 model performs better than other models in the experiment","f869aafb":"### Inference\n\n- The effect of data imbalance is visible in validation accuracy measures\n- Training accuracy of ResNet 50 is almost equal to base CNN model\n- V5 Changes:\n    - A good measure for imbalanced dataset is Area Under the Curve(AUC)\n    - The metrics for the model changed to AUC in version 5\n    - Comparision of models will be done based on AUC score","bae8d6e5":"## Training ResNet 50 on data\n\n[ResNet Introduction and Architecture](https:\/\/neurohive.io\/en\/popular-networks\/resnet\/)","2b78aba8":"## Exploratory Data Analysis\n\n> Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n\nSource : [Exploratory Data Analysis](https:\/\/towardsdatascience.com\/exploratory-data-analysis-8fc1cb20fd15)","9164f2b8":"## Base CNN model accuracy calculation\n\n- The given 69 images divided into 4 classes will be trained on a simple 3 convolution layers CNN","fc6b5fe2":"## TP, FP, TN, FN model comparisions","cc9f1125":"### Inference from count plots and Pie chart\n\n- All COVID-19 patients are classified with attribute Label as Pnemonia. None of them is classified as normal. \n- In target \"Label_2_Virus_category\", \"unknown\" value is associated with majority of images\n- Unknown values consist of 98.7 % of total cases while COVID-19 value consist of less than 1.3 % of total cases.\n- Even if we train a model to classify Label_2_virus_category with 98.7 % accuracy, it will be highly inefficient in detecting true positive COVID-19 cases.\n- Thus we are going to construct a model which differentiates between (Normal) and (Pnemonia + COVID-19) Cases","c1cd417a":"### Inference\n\n- From the sample images, seperated according to Label 2 Virus Category into COVID-19 and Other, we can infer the difference in image histograms\n- The sample histograms of images having target as COVID-19 are mostly left-skewed histograms.\n- The sample histograms of images which have Label value as Normal are mostly right skewed histograms (with exception of image 4).","b9e26c29":"### Inference from base CNN model accuracy and AUC\n- Base CNN model\n    - Train data accuracy = 95.4 %\n    - Validation data accuracy = 97 %\n\n\n- Possible reasons for stale accuracy on 20 epochs\n    - Highly imbalance target variables\n        - COVID-19 target value = positive rows have count as 58\n        - Normal target value = negative rows have count as 1342\n        - `100 * (1342 \/ 1400) ~ 95.86 %`\n        - Even if model classifies all the images as \"Normal\" label, it would achieve 95.86 % accuracy\n        \n- V5 Changes:\n    - A good measure for imbalanced dataset is Area Under the Curve(AUC)\n    - The metrics for the model changed to AUC in version 5\n    - Comparision of models will be done based on AUC score","880e452b":"## COVID-19 Classifier from X-Ray Images\n\n#### Tasks\n\n- [\u2714\ufe0f] Exploratory Data Analysis\n- [\u2714\ufe0f] Image augumentation\n- [\u2714\ufe0f] Base CNN model accuracy calculation\n- [\u2714\ufe0f] Base CNN model with lower imbalance data\n- [\u2714\ufe0f] RESNET 50 model accuracy calculation\n- [\u2714\ufe0f] EfficientNet B4 accuracy calculation\n- [\u2714\ufe0f] AUC Score comparision\n- [\u26ab] Results\n\n#### Version Information\n\n- v1 :\n    - Completed exploratory data analysis of given metadata\n    - Completed exploratory data analysis of provided images\n    - Inferences of both EDA explained\n\n- v2 :\n    - Code cleaning\n    - Output cleaning\n\n- v3 :\n    - Completed Image Augumentation using Keras ImageDataGenerator\n    - Completed training of base CNN model on data\n    - Accuracy inference of base CNN model completed\n    \n- v4 :\n    - Trained base CNN model on balanced data\n    - Inferenced accuracy of base CNN model on balanced data\n    - Trained ResNet 50 model on data\n    - Inferenced accuracy of ResNet 50 model\n    \n- v5 :\n    - Because of severe class imbalance, metric for model training and validation is changed from accuracy -> AUC ROC\n    - [Really Good Article on choosing evaluation metrics](https:\/\/machinelearningmastery.com\/tour-of-evaluation-metrics-for-imbalanced-classification\/)\n    - Trained EfficientNet B4 model on data\n    - Inferenced accuracy of EfficientNet B4 model\n    - AUC score comparisions of all trained models\n    \n- v6 :\n    - Added multiple metrics for better view of model comparison\n    - Added numpy and tensorflow seeding for reproducible results\n\n- v7 :\n    - Code cleaning, debugging","1c354872":"### Sort out the file names to be worked on\n\n- From EDA, we decided to remove files with Label_2_Virus_category as NaN","23ce21af":"## Image Augumentation\n\n> Deep networks need large amount of training data to achieve good performance. To build a powerful image classifier using very little training data, image augmentation is usually required to boost the performance of deep networks. Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc\n\nSource : [Image Augumentation for Deep Learning](https:\/\/towardsdatascience.com\/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2)\n\n- We will be using keras ImageDataGenerator's inbuilt image augumentation functionality for the process of image augumentation."}}