{"cell_type":{"a7198eb6":"code","2c41a5ff":"code","ab15510d":"code","1347f774":"code","01b1b4f7":"code","b0aded68":"code","5a874b13":"code","ecf06a74":"code","d9026ccc":"code","b131401b":"code","6ee369dd":"code","d7635803":"code","85536e2d":"code","e3570887":"code","21fe7abe":"markdown","1bc232e7":"markdown","9335a271":"markdown","2ccd0fa6":"markdown","d99209d0":"markdown"},"source":{"a7198eb6":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","2c41a5ff":"# List files\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ab15510d":"# Importing data and naming columns\nraw_data = pd.read_csv(\"\/kaggle\/input\/ciri422\/training.csv\", header=None)\ntest_data = pd.read_csv(\"\/kaggle\/input\/ciri422\/test.csv\", header=None)\noutput = pd.read_csv(\"\/kaggle\/input\/ciri422\/sample.csv\", header=0)\n\nraw_data.columns = [\"Id\", \"U\", \"G\", \"R\", \"I\", \"Z\", \"Y\", \"Redshift\"]\ntest_data.columns = [\"Id\", \"U\", \"G\", \"R\", \"I\", \"Z\", \"Y\"]\noutput.columns = [\"Id\", \"Redshift\"]\nred_shift_features = [\"U\", \"G\", \"R\", \"I\", \"Z\", \"Y\"]","1347f774":"print(\"Raw data:\")\ndisplay(raw_data.head())\n\nprint(\"Test data:\")\ndisplay(test_data.head())\n\nprint(\"Output data:\")\ndisplay(output.head())","01b1b4f7":"raw_data.describe()","b0aded68":"raw_data[red_shift_features].hist(bins=30, figsize=(20, 15))","5a874b13":"# Select our prediction target\ny = raw_data.Redshift\ndisplay(y.head())\n\n# Choosing the features\nX = raw_data[red_shift_features]\ndisplay(X.describe())","ecf06a74":"train_data = pd.concat([X, y], axis=1)\ncorr_matrix = train_data.corr()\ndisplay(corr_matrix)\n\nplt.figure(figsize=(18, 8))\nfor i, x in enumerate(red_shift_features):\n    plt.subplot(2, 3, i + 1)\n    plt.scatter(train_data[x], train_data[\"Redshift\"], alpha=0.1)\n    plt.xlabel(x)\n    plt.ylabel(\"Redshift\")","d9026ccc":"import keras as ks","b131401b":"def rmse(y_true, y_pred):\n\treturn ks.backend.sqrt(ks.backend.mean(ks.backend.square(y_pred - y_true), axis=-1))\n\nnn_model = ks.Sequential()\nnn_model.add(ks.layers.Dense(200, activation=\"selu\", input_shape=X.shape[1:]))\nnn_model.add(ks.layers.Dropout(0.05))\nnn_model.add(ks.layers.Dense(50, activation=\"selu\"))\nnn_model.add(ks.layers.Dropout(0.1))\nnn_model.add(ks.layers.Dense(50, activation=\"selu\"))\nnn_model.add(ks.layers.Dropout(0.1))\nnn_model.add(ks.layers.Dense(50, activation=\"selu\"))\nnn_model.add(ks.layers.Dense(1, activation=None, name=\"Output\"))\n\nopt = ks.optimizers.Adam(lr=0.002, decay=1e-4)\nnn_model.compile(optimizer=opt, loss=\"mse\", metrics=[rmse])\n\ntrain_nn_X = np.asarray(X)\ntrain_nn_y = np.asarray(y)\n\n# early_stop = ks.callbacks.EarlyStopping(monitor='loss', patience=500)\n# history = nn_model.fit(train_nn_X, train_nn_y, epochs=5000, batch_size=32, callbacks=[early_stop])\nhistory = nn_model.fit(train_nn_X, train_nn_y, epochs=10000, batch_size=32)","6ee369dd":"nn_model.summary()","d7635803":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 0.1)\nplt.show()","85536e2d":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\ndef baseline_model():\n    model = Sequential()\n    model.add(Dense(200, input_dim=6, kernel_initializer='normal', activation='selu'))\n    model.add(Dropout(0.05))\n    model.add(Dense(50, kernel_initializer='normal', activation=\"selu\"))\n    model.add(Dense(50, kernel_initializer='normal', activation=\"selu\"))\n    model.add(Dense(1, kernel_initializer='normal', activation=None))\n\n    model.compile(loss='mse', optimizer=Adam(lr=0.002, decay=1e-4))\n    \n    return model\n\nestimators = []\nscaler = StandardScaler()\nestimators.append(('standardize', scaler.fit(X)))\nestimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=10000, batch_size=50)))\npipeline = Pipeline(estimators)\npipeline.fit(X, y)","e3570887":"def write_output(values, filename):\n    output[\"Redshift\"] = values\n    formated_output = np.empty_like(output, dtype='O')\n\n    for index, row in output.iterrows():\n        formated_output[index] = (\"{:.18e}\".format(row['Id']), \"{:.18e}\".format(row['Redshift']))\n\n    formated_output = pd.DataFrame(formated_output)\n    formated_output.columns = [\"Id\", \"Redshift\"]\n    formated_output.to_csv('\\kaggle\\output\\{}'.format(filename), index=False)\n    \n# ANN\ntest_X = test_data.drop(columns=[\"Id\"])\n\npredict_redshift = pipeline.predict(test_X)\ndisplay(predict_redshift)\nwrite_output(predict_redshift, 'ANN.csv')","21fe7abe":"## 1.a. Explaining the data\nThe `raw_data` dataframe has 8 columns:\n- `Id` which is the galaxy identifier\n- `U`, `G`,`R`, `I`, `Z`, `Y` which are magnitudes of galaxies measured with different color filters. \n- `Redshift` which is the mesured red-shift of the galaxy\n\nThe `test_data` dataframe has only the first 7 columns of `raw_data`, the last one is missing. `Redshift` is our *prediction target*, we have to predict it from the given data.\n\nThe `output` dataframe is a placeholder for our final data.","1bc232e7":"# 2. Artificial Neural Network\n\nUsing a neural network:","9335a271":"# 1. Data exploration","2ccd0fa6":"Now we try to predict the red-shift value of the `test_data`dataframe.","d99209d0":"# Try 2 with ANN"}}