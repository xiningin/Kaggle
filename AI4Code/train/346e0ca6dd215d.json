{"cell_type":{"321c324b":"code","adc2a944":"code","eea087b8":"code","b29408d7":"code","f6c0704b":"code","52fadb05":"code","1563d590":"code","168ef1ce":"code","c07d16fd":"code","48de772f":"code","7d46ed45":"code","8d97a394":"code","d7d9fcd2":"code","578012d3":"code","923c9c83":"markdown","0b9483c0":"markdown","be0a248a":"markdown","404d1961":"markdown","497d37da":"markdown","1d1e7c1c":"markdown","0293154f":"markdown","08c315da":"markdown","565603fd":"markdown","e40d489d":"markdown","b40be15a":"markdown","87db4cfc":"markdown"},"source":{"321c324b":"import featuretools as ft\nimport pandas as pd \nimport numpy as np\nimport sqlite3","adc2a944":"path = \"..\/input\/\"  #Insert path here\ndatabase = path + 'database.sqlite'\nconn = sqlite3.connect(database)","eea087b8":"matches_df = pd.read_sql(\"\"\"SELECT * from MATCH\"\"\", conn)\nteams_df = pd.read_sql(\"\"\"SELECT * from TEAM\"\"\", conn)\nplayer_attributes_df = pd.read_sql(\"\"\"SELECT * from PLAYER_ATTRIBUTES\"\"\", conn)\n\nmatches_df['date'] = pd.to_datetime(matches_df['date'], format='%Y-%m-%d 00:00:00')","b29408d7":"home_players = [\"home_player_\" + str(x) for x in range(1, 12)]\naway_players = [\"away_player_\" + str(x) for x in range(1, 12)]\n\nbetting_columns = [\"B365H\", \"B365D\", \"B365A\"]\n\nmatches_kept_columns = [\"id\", \"date\", \"home_team_api_id\", \"away_team_api_id\", \"home_team_goal\", \"away_team_goal\"]\nmatches_kept_columns = matches_kept_columns + home_players\nmatches_kept_columns = matches_kept_columns + away_players\nmatches_kept_columns = matches_kept_columns + betting_columns\n\nmatches_df = matches_df[matches_kept_columns]","f6c0704b":"matches_df['goal_difference'] = matches_df['home_team_goal'] - matches_df['away_team_goal']\nmatches_df['home_status'] = 'D'\nmatches_df['home_status'] = np.where(matches_df['goal_difference'] > 0, 'W', matches_df['home_status'])\nmatches_df['home_status'] = np.where(matches_df['goal_difference'] < 0, 'L', matches_df['home_status'])\n\nfor player in home_players:\n    matches_df = pd.merge(matches_df, player_attributes_df[[\"id\", \"overall_rating\"]], left_on=[player], right_on=[\"id\"], suffixes=[\"\", \"_\" + player])\nfor player in away_players:\n    matches_df = pd.merge(matches_df, player_attributes_df[[\"id\", \"overall_rating\"]], left_on=[player], right_on=[\"id\"], suffixes=[\"\", \"_\" + player])\n    \nmatches_df = matches_df.rename(columns={\"overall_rating\": \"overall_rating_home_player_1\"})\n\nmatches_df = matches_df[ matches_df[['overall_rating_' + p for p in home_players]].isnull().sum(axis = 1) <= 0]\nmatches_df = matches_df[ matches_df[['overall_rating_' + p for p in away_players]].isnull().sum(axis = 1) <= 0]\n\nmatches_df['overall_rating_home'] = matches_df[['overall_rating_' + p for p in home_players]].sum(axis=1)\nmatches_df['overall_rating_away'] = matches_df[['overall_rating_' + p for p in away_players]].sum(axis=1)\nmatches_df['overall_rating_difference'] = matches_df['overall_rating_home'] - matches_df['overall_rating_away']\n\nmatches_df['min_overall_rating_home'] = matches_df[['overall_rating_' + p for p in home_players]].min(axis=1)\nmatches_df['min_overall_rating_away'] = matches_df[['overall_rating_' + p for p in away_players]].min(axis=1)\n\nmatches_df['max_overall_rating_home'] = matches_df[['overall_rating_' + p for p in home_players]].max(axis=1)\nmatches_df['max_overall_rating_away'] = matches_df[['overall_rating_' + p for p in away_players]].max(axis=1)\n\nmatches_df['mean_overall_rating_home'] = matches_df[['overall_rating_' + p for p in home_players]].mean(axis=1)\nmatches_df['mean_overall_rating_away'] = matches_df[['overall_rating_' + p for p in away_players]].mean(axis=1)\n\nmatches_df['std_overall_rating_home'] = matches_df[['overall_rating_' + p for p in home_players]].std(axis=1)\nmatches_df['std_overall_rating_away'] = matches_df[['overall_rating_' + p for p in away_players]].std(axis=1)","52fadb05":"for c in matches_df.columns:\n    if '_player_' in c:\n        matches_df = matches_df.drop(c, axis=1)","1563d590":"ct_home_matches = pd.DataFrame()\nct_away_matches = pd.DataFrame()\n\nct_matches = pd.DataFrame()\n\n# Trick to exclude current match from statistics and do not biais predictions\nct_home_matches['time'] = matches_df['date'] - pd.Timedelta(hours=1)\nct_home_matches['instance_id'] = matches_df['home_team_api_id']\nct_home_matches['label'] = (ct_home_matches['instance_id'] == ct_home_matches['instance_id'])\n\n# Trick to exclude current match from statistics and do not biais predictions\nct_away_matches['time'] = matches_df['date'] - pd.Timedelta(hours=1)\nct_away_matches['instance_id'] = matches_df['away_team_api_id']\nct_away_matches['label'] = (ct_away_matches['instance_id'] == ct_away_matches['instance_id'])\n\nct_matches = ct_home_matches.append(ct_away_matches)","168ef1ce":"es = ft.EntitySet(\"entityset\")\n\nes.entity_from_dataframe(entity_id=\"home_matches\",\n                        index=\"id\",\n                        time_index=\"date\",\n                        dataframe=matches_df,\n                        variable_types={\"home_team_api_id\": ft.variable_types.Categorical,\n                                              \"away_team_api_id\": ft.variable_types.Categorical,\n                                              \"home_status\": ft.variable_types.Categorical,\n                                              \"home_team_goal\":     ft.variable_types.Numeric,\n                                              \"away_team_goal\":     ft.variable_types.Numeric})\n\nes.entity_from_dataframe(entity_id=\"away_matches\",\n                        index=\"id\",\n                        time_index=\"date\",\n                        dataframe=matches_df,\n                        variable_types={\"home_team_api_id\": ft.variable_types.Categorical,\n                                              \"away_team_api_id\": ft.variable_types.Categorical,\n                                              \"home_status\": ft.variable_types.Categorical,\n                                              \"home_team_goal\":     ft.variable_types.Numeric,\n                                              \"away_team_goal\":     ft.variable_types.Numeric})\n\nes.entity_from_dataframe(entity_id=\"teams\",\n                         index=\"team_api_id\",\n                         dataframe=teams_df)\n\nes.add_last_time_indexes()\n\nnew_relationship = ft.Relationship(es[\"teams\"][\"team_api_id\"],\n                                   es[\"home_matches\"][\"home_team_api_id\"])\nes = es.add_relationship(new_relationship)\n\nnew_relationship = ft.Relationship(es[\"teams\"][\"team_api_id\"],\n                                   es[\"away_matches\"][\"away_team_api_id\"])\nes = es.add_relationship(new_relationship)\n\nfeature_matrix, features_defs = ft.dfs(entities=es,\n                                       entityset=es,\n                                       cutoff_time=ct_matches,\n                                       cutoff_time_in_index=True,\n                                       training_window='60 days',\n                                       max_depth=3,\n                                       target_entity=\"teams\",\n                                       verbose=True\n                                      )\n\nprint(feature_matrix)","c07d16fd":"# Recover the true datetime \nfeature_matrix = feature_matrix.reset_index()\nfeature_matrix['time'] = feature_matrix['time'] + pd.Timedelta(hours=1)\n\nprint(feature_matrix['time'])\n\ndf_final = pd.merge(matches_df, feature_matrix, left_on=['date', 'home_team_api_id'], right_on=['time','team_api_id'], suffixes=('', '_HOME'))\ndf_final = pd.merge(df_final, feature_matrix, left_on=['date', 'away_team_api_id'], right_on=['time','team_api_id'], suffixes=('', '_AWAY'))","48de772f":"columns_to_drop = [\"id\", \"team_fifa_api_id\", \"date\", \"team_long_name\",\"team_long_name_AWAY\", \"team_short_name\",\"team_short_name_AWAY\", \"home_status\", \"home_team_goal\", \"away_team_goal\", \"home_team_api_id\", \"away_team_api_id\", \"label_AWAY\", \"label\", \"goal_difference\", 'team_api_id', 'time', 'team_api_id_AWAY', 'time_AWAY']\n\nfor c in df_final.columns:\n    if 'MODE' in c:\n        columns_to_drop.append(c)\n\ny = df_final[\"home_status\"]\ndf = df_final.drop(columns_to_drop, axis=1)\ndf = df.fillna(0)\n\nprint(df)","7d46ed45":"from sklearn.model_selection import TimeSeriesSplit, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_selection import RFE\n\n# 1. Split X and y into a train and test set\nX_train, X_test, y_train, y_test = train_test_split(df, y, shuffle=True, random_state=42)\n\n# 2. Select features using RFE\nclf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\nestimator = clf\nselector = RFE(estimator, 10, step=1)\nselector = selector.fit(X_train, y_train)\nX_train.iloc[:, selector.support_].tail()","8d97a394":"clf.fit(selector.transform(X_train), y_train)\n\nscore = clf.score(selector.transform(X_test), y_test)\ny_pred = clf.predict(selector.transform(X_test))\n\nprint(score)","d7d9fcd2":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\nclass_names = y.unique()\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","578012d3":"bet = 10\nearnings = 0\n\nearnings = earnings + X_test[(y_pred == y_test) & (y_pred == 'W')]['B365H'].sum() * bet\nearnings = earnings + X_test[(y_pred == y_test) & (y_pred == 'L')]['B365A'].sum() * bet\nearnings = earnings + X_test[(y_pred == y_test) & (y_pred == 'D')]['B365D'].sum() * bet\n\nearnings = earnings - len(X_test) * bet\n\nprint(\"You lose \" + str(earnings) + \"\u20ac !\")","923c9c83":"# Prediction phase\n\nFinally! Here we are in the prediction phase. First, we will keep the 10 most useful features to predict our output.\nIt's pretty logical, the best features are linked with goal differences and ratings of teams. :)\n\nAnd then let's magic happen with Random Forest algorithm :) ","0b9483c0":"# Load required data \n\nLoading matches data  from from SQLite database that will give us the scores and opposing teams.  I use also player attributes from FIFA video game in order to capture player's ratings and compare overall team ratings.","be0a248a":"We create all required entities for featuretools. An entity set can store every dataframe (here time-series) as entity, handle relationships between these entities. I have chosen to generate new features on a 60 days rolling-period.\n\n### Amazing ! After featuretools' work, the new dataset holds 200+ features. \nIt only remains to identify the most relevant.","404d1961":"# 48% of good predictions on test dataset","497d37da":"# Feature engineering with Featuretools\n\nHere, we have built a new dataframe that lists an element for every match per team. This dataframe holds time and instance_id columns to be handled by featuretools and generate teams' statistics over time. ","1d1e7c1c":"I drop player's rating, I'm just interested in agregation values at team level.","0293154f":"# If I bet \u20ac 10 on each match from test dataset, I will have lose 1673 \u20ac","08c315da":"# Plotting results for each categorical output\n\nI have very nice results when victory or defeat happen (approx. 88% accuracy) but my model is not able to predict draws (only 63%)","565603fd":"Here I add some new features:\n* **goal_difference** -> it is the difference of number of goals between home and away teams\n* **home_status** -> it stores L if home team loses, W if it wins else it stores D. It will be used as **output to predict**. \n* **overall_rating_home** -> total rating of each player in the home team\n* **overall_rating_away** -> total rating of each player in the away team\n* **min_overall_rating_home** -> minimum rating of each player in the home team\n* **min_overall_rating_away** -> minimum rating of each player in the away team\n* **max_overall_rating_home** -> maximum rating of each player in the home team\n* **max_overall_rating_away** -> maximum rating of each player in the away team\n* **mean_overall_rating_home** -> mean rating of each player in the home team\n* **mean_overall_rating_away** -> mean rating of each player in the away team\n* **std_overall_rating_home** -> standard deviation rating of each player in the home team\n* **std_overall_rating_away** -> standard deviation rating of each player in the away team\n* **overall_rating_difference** -> difference of total rating between the two teams ","e40d489d":"# Motivation\n\nEveryone dreams to earn money easily and more if they can do it thanks to its favourite sport. I love soccer since my childhood and I am passionate about data for some years ago. Here, I will show you how I can predict the matches' outcome for more than 80% of them.\n\nTwo of most important things I used are Feature Tools and Scikit-Learn. I won't talk about Scikit-Learn but Feature Tools is very young and I think a lot of words are worth it. \n\nFeaturetools ([https:\/\/www.featuretools.com](https:\/\/www.featuretools.com\/)) is an open source python framework for automated feature engineering.  Feature engineering is really painfull when you have to generate new features from raw ones, and you have to be very lucky to find the most reliable for your final prediction. Featuretools helps you to automate new features' generation even by handling  time, datasets relationships and the depth of complexity.","b40be15a":"# Raw data preparation\nHere I filter useless columns in order to not flood Featuretools with meaningless informations. I have decided to keep id of player who have played, id for each team, the date  of the match and number of goals scored by each team. I have also kept betting columns to calculate the sum of the gains after prediction.","87db4cfc":"Then, we are merging new features with the initial dataframe and removing useless columns to process classification."}}