{"cell_type":{"34dc60a2":"code","888e7e58":"code","94d914e4":"code","a765f13d":"code","3fd22bae":"code","8cc6812e":"code","81f76d1d":"code","e60019b4":"code","8b4ed601":"code","c63a24b3":"code","467444f1":"code","392515b8":"code","b59644b6":"code","e8130947":"code","01123262":"code","2b854b19":"code","4a7197b3":"code","a19951d9":"code","dea591ee":"code","7a5afee3":"code","9ffa6636":"code","523535f9":"code","d9722503":"code","65175f80":"code","b0410bcf":"code","a86ce1ba":"code","7be38974":"code","2d6942d8":"code","860a133a":"code","d029cc9f":"code","2c35551b":"code","4a9e6a58":"code","b494a04a":"code","c941a5d7":"code","582c67ec":"code","87f10d6c":"code","3e64c304":"markdown","fe7901e5":"markdown","f3619d8e":"markdown","fe14f2d7":"markdown"},"source":{"34dc60a2":"#importing sklearn\nimport sklearn\n\n# Common imports\nimport numpy as np\nimport pandas as pd\nimport os\n\n# To plot pretty figures in jupyter notebooks\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)","888e7e58":"#getting data from csv\nhouse = pd.read_csv('..\/input\/california-housing-prices\/housing.csv')\nhouse.head()","94d914e4":"house.info()","a765f13d":"house[\"ocean_proximity\"].value_counts()","3fd22bae":"house.describe().T","8cc6812e":"#plotting histogram\nhouse.hist(bins=50, figsize=(20,15))\nplt.show();","81f76d1d":"fig = plt.figure(dpi = 80, figsize = (6,4))\nax = fig.add_axes([1,1,1,1])\nax.set(xlabel = 'Median Income Class',ylabel = 'Frequency',title = 'Distribution of Median Income')\nhouse[\"median_income\"].hist(color='black',ax = ax)\nplt.show()","e60019b4":"house[\"income_cat\"] = pd.cut(house[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n                               labels=[1, 2, 3, 4, 5])","8b4ed601":"house[\"income_cat\"].value_counts()","c63a24b3":"fig = plt.figure(dpi = 80, figsize = (6,4))\nax = fig.add_axes([1,1,1,1])\nax.set(xlabel = 'Median Income Category',ylabel = 'Frequency',title = 'Distribution of Median Income Category')\nhouse[\"income_cat\"].hist(color = 'orange',ax=ax)\nplt.show()","467444f1":"# Importing and Using Stratified shuffle split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(house, house[\"income_cat\"]):\n    strat_train_set = house.loc[train_index]\n    strat_test_set = house.loc[test_index]","392515b8":"house = strat_train_set.copy()","b59644b6":"house.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\ns=house[\"population\"]\/100, label=\"population\", figsize=(10,7),\nc=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n)\nplt.legend()","e8130947":"corr = house.corr()\nmask = np.triu(np.ones_like(corr,dtype = bool))\n\nplt.figure(dpi=100)\nplt.title('Correlation Analysis')\nsns.heatmap(corr,mask=mask,annot=False,lw=0,linecolor='white',cmap='viridis',fmt = \"0.2f\")\nplt.xticks(rotation=90)\nplt.yticks(rotation = 0)\nplt.show()","01123262":"# from pandas.tools.plotting import scatter_matrix\nfrom pandas.plotting import scatter_matrix\n\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_matrix(house[attributes], figsize=(12, 10))\nplt.show()","2b854b19":"#The most promising attribute to predict the median house value is the median income, so let\u2019s zoom in on their correlation scatterplot\nfig = plt.figure(dpi = 80, figsize = (6,4))\nax = fig.add_axes([1,1,1,1])\n\nhouse.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n             alpha=0.1,color = 'black',ax=ax)\nplt.axis([0, 16, 0, 550000])\nplt.show()","4a7197b3":"house[\"rooms_per_household\"] = house[\"total_rooms\"]\/house[\"households\"]\nhouse[\"bedrooms_per_room\"] = house[\"total_bedrooms\"]\/house[\"total_rooms\"]\nhouse[\"population_per_household\"]=house[\"population\"]\/house[\"households\"]","a19951d9":"corr = house.corr()\nmask = np.triu(np.ones_like(corr,dtype = bool))\n\nplt.figure(dpi=100)\nplt.title('Correlation Analysis')\nsns.heatmap(corr,mask=mask,annot=False,lw=0,linecolor='white',cmap='cividis',fmt = \"0.2f\")\nplt.xticks(rotation=90)\nplt.yticks(rotation = 0)\nplt.show()","dea591ee":"# droping labels for training set\nhouse = strat_train_set.drop(\"median_house_value\", axis=1) \nhouse_labels = strat_train_set[\"median_house_value\"].copy()","7a5afee3":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder","9ffa6636":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# column index\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X):\n        rooms_per_household = X[:, rooms_ix] \/ X[:, households_ix]\n        population_per_household = X[:, population_ix] \/ X[:, households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]","523535f9":"#importing pipeline and standardScaler \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('attribs_adder', CombinedAttributesAdder()),\n        ('std_scaler', StandardScaler()),\n    ])","d9722503":"from sklearn.compose import ColumnTransformer\n\nhouse_num = house.drop(\"ocean_proximity\", axis=1)\n\nnum_attribs = list(house_num)\ncat_attribs = [\"ocean_proximity\"]\n\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])","65175f80":"house_prepared = full_pipeline.fit_transform(house)\nhouse_prepared","b0410bcf":"#importing random forest regressor to predict the value of house\nfrom sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor()\nforest_reg.fit(house_prepared, house_labels)","a86ce1ba":"#to know the MSE and MAE of the model used \nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nhouse_predicted = forest_reg.predict(house_prepared)\nforest_mse = mean_squared_error(house_labels, house_predicted)\nforest_rmse = np.sqrt(forest_mse)\nprint(\"RMSE ==> \", forest_rmse)","7be38974":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","2d6942d8":"#impoting cross val score to cross validaton about the performance of the model tained\nfrom sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, house_prepared, house_labels,\n                                scoring=\"neg_mean_squared_error\", cv=5)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","860a133a":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3\u00d74) combinations of hyperparameters\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    # then try 6 (2\u00d73) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error',\n                           return_train_score=True)\ngrid_search.fit(house_prepared, house_labels)","d029cc9f":"grid_search.best_params_","2c35551b":"grid_search.best_estimator_","4a9e6a58":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","b494a04a":"final_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)","c941a5d7":"final_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","582c67ec":"print(\"RMSE on Test ==> \",final_rmse)","87f10d6c":"from scipy import stats\n\nconfidence = 0.95\nsquared_errors = (final_predictions - y_test) ** 2\nnp.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n                         loc=squared_errors.mean(),\n                         scale=stats.sem(squared_errors)))","3e64c304":"# Model Training","fe7901e5":"> This image tells that the housing price is very much related to the location and to the population density.","f3619d8e":"# Data Pipeline","fe14f2d7":"# Evaluate Model"}}