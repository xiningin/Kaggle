{"cell_type":{"6c8259bd":"code","3ff200af":"code","3fd9c143":"code","2dd3118d":"code","96d69e6f":"code","8db7066b":"code","9a102392":"code","442541f7":"code","ab33de6a":"code","6058db3f":"code","fa960532":"code","98a73be6":"code","ee4f402d":"code","c222c393":"code","eb27dfc9":"code","1994b8a2":"code","4d0bad53":"code","3a5abd09":"code","a940ee77":"code","b182d989":"code","3132f7b0":"code","33629f36":"code","75146480":"code","2cc352e4":"code","fd6fc1f4":"code","4044caeb":"code","2c2917e6":"code","79d38a35":"code","d15f2dab":"code","35da0402":"code","0f9edcf7":"code","5b41f0d3":"code","e47605bd":"code","e4a7e419":"code","39bd4f92":"code","7a798ff4":"code","ad13c436":"code","75aef156":"code","a33590cb":"code","72a66332":"code","3cf0abd9":"code","80d248e9":"code","83c87171":"code","6633eb1f":"code","1d432037":"code","4d67b3a6":"code","c5ed90c0":"code","e2fed501":"code","8e3e5d00":"code","c9e7cc38":"code","444ff373":"code","c395d087":"code","23eca305":"code","83f82662":"code","a6cacc59":"code","4788b17d":"code","b35ef163":"code","5e3a71ba":"code","21393531":"code","a4b0b622":"code","9751c4a3":"code","ae325578":"code","bfba0169":"code","e92a8058":"code","742c7ee5":"code","df9b88e3":"code","45f974cc":"code","775b09c5":"code","2700a984":"code","e7cb4ff7":"code","a0ac7e23":"code","79b75e53":"code","71d69663":"code","331cd6d1":"code","4a31db2a":"markdown","3cb6dfb1":"markdown","a207e242":"markdown","ee000347":"markdown","f66314e1":"markdown","1eed58bc":"markdown","323affe5":"markdown","75ac74ab":"markdown","d2fdc66a":"markdown","9776262f":"markdown","5d75babf":"markdown","1e5d86a5":"markdown","ed57cf0e":"markdown","bf58df36":"markdown","63418bb7":"markdown","d1e41890":"markdown","422ebe74":"markdown","22d2e702":"markdown","f84b2f72":"markdown","9f2b09fa":"markdown","0de768f1":"markdown","8468fcfb":"markdown","01cc1c98":"markdown","2563aeae":"markdown","74ae97dc":"markdown","180e20f7":"markdown","9740b3d4":"markdown","b5f7d677":"markdown","54470c3d":"markdown","eeacfe0b":"markdown","470938d1":"markdown","b0336c20":"markdown","b43f72e8":"markdown","0b4109f3":"markdown","54e3f198":"markdown","b716a684":"markdown","33e7b9c3":"markdown","8c62a29f":"markdown","0f6fd9e5":"markdown","c80ac151":"markdown","25a4af3c":"markdown","748c8894":"markdown","eb128682":"markdown","be66a4af":"markdown","efa18484":"markdown","0e365ab0":"markdown","82df8c98":"markdown","bc7672c8":"markdown","72cfbe18":"markdown","03fe4ff0":"markdown","32ab5493":"markdown","f5e62232":"markdown","a380182b":"markdown","86123e7d":"markdown"},"source":{"6c8259bd":"import numpy as np\nimport pandas as pd\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# machine learning\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn import preprocessing\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# setting color for all graphs\ncolors = ['#e79c2a','#d54062', '#ebdc87', '#ffa36c']\nsns.set_palette(sns.color_palette(colors))","3ff200af":"data = pd.read_csv(\"\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\")","3fd9c143":"data.head()","2dd3118d":"print('='*50)\nprint(\"Columns in data\")\nprint('='*50)\nprint(data.columns.values)","96d69e6f":"print('='*20)\nprint(\"Data shape\")\nprint('='*20)\nprint(data.shape)","8db7066b":"print('='*50)\nprint(\"\\nDescribe data\\n\")\nprint('='*50) \nprint(data.describe())","9a102392":"print('='*50)\nprint(\"\\nData Information\\n\")\nprint('='*50) \nprint(data.info())","442541f7":"data = data.drop(['sl_no'], axis=1)","ab33de6a":"sns.countplot('status', data=data)","6058db3f":"data['gender'].value_counts()","fa960532":"df = pd.DataFrame(data.groupby(['gender','status'])['status'].count())\ndf","98a73be6":"sns.countplot(x='gender', hue='status', data=data)","ee4f402d":"sns.distplot(data['ssc_p'], kde=False)\nplt.title('Distribution of SSC Percentage')\nplt.xlabel('SSC %')","c222c393":"sns.catplot(y='ssc_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('SSC %')","eb27dfc9":"data['ssc_b'].value_counts()","1994b8a2":"df = pd.DataFrame(data.groupby(['ssc_b','status'])['status'].count())\ndf","4d0bad53":"sns.countplot(x='ssc_b', hue='status', data=data)","3a5abd09":"sns.distplot(data['hsc_p'], kde=False)\nplt.title('Distribution of SSC Percentage')\nplt.xlabel('HSC %')","a940ee77":"sns.catplot(y='hsc_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('HSC %')","b182d989":"data['hsc_b'].value_counts()","3132f7b0":"df = pd.DataFrame(data.groupby(['hsc_b','status'])['status'].count())\ndf","33629f36":"sns.countplot(x='hsc_b', hue='status', data=data)","75146480":"data['hsc_s'].value_counts()","2cc352e4":"df = pd.DataFrame(data.groupby(['hsc_s','status'])['status'].count())\ndf","fd6fc1f4":"sns.countplot(x='hsc_s', hue='status', data=data)","4044caeb":"sns.distplot(data['degree_p'], kde=False)\nplt.title('Distribution of Degree Percentage')\nplt.xlabel('Degree %')","2c2917e6":"sns.catplot(y='degree_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('Degree %')","79d38a35":"data['degree_t'].value_counts()","d15f2dab":"df = pd.DataFrame(data.groupby(['degree_t','status'])['status'].count())\ndf","35da0402":"sns.countplot(x='degree_t', hue='status', data=data)","0f9edcf7":"data['workex'].value_counts()","5b41f0d3":"df = pd.DataFrame(data.groupby(['workex','status'])['status'].count())\ndf","e47605bd":"sns.countplot(x='workex', hue='status', data=data)","e4a7e419":"sns.distplot(data['etest_p'], kde=False)\nplt.title('Distribution of MBA Percentage')\nplt.xlabel('Employment Test %')","39bd4f92":"sns.catplot(y='etest_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('Employment Test %')","7a798ff4":"data['specialisation'].value_counts()","ad13c436":"df = pd.DataFrame(data.groupby(['specialisation','status'])['status'].count())\ndf","75aef156":"sns.countplot(x='specialisation', hue='status', data=data)\nplt.xlabel('MBA Specialization')","a33590cb":"sns.distplot(data['mba_p'], kde=False)\nplt.title('Distribution of MBA Percentage')\nplt.xlabel('MBA %')","72a66332":"sns.catplot(y='mba_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('MBA %')","3cf0abd9":"sns.distplot(data['salary'], kde=False)\nplt.title('Distribution of Salary')\nplt.xlabel('Salary')","80d248e9":"sns.catplot(y='salary', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('Salary')","83c87171":"sns.pairplot(data=data[['ssc_p','hsc_p','degree_p', 'etest_p','mba_p','salary', 'status']], hue=\"status\", diag_kind='hist')","6633eb1f":"data.drop(['ssc_b','hsc_b', 'hsc_s', 'degree_t', 'salary'], axis=1, inplace=True)","1d432037":"data[\"gender\"] = data.gender.map({\"M\":0,\"F\":1})\ndata[\"workex\"] = data.workex.map({\"No\":0, \"Yes\":1})\ndata[\"status\"] = data.status.map({\"Not Placed\":0, \"Placed\":1})\ndata[\"specialisation\"] = data.specialisation.map({\"Mkt&HR\":0, \"Mkt&Fin\":1})","4d67b3a6":"data.columns","c5ed90c0":"data.head()","e2fed501":"def new_features(df):\n    df['hsc_to_ssc'] = df['hsc_p'] \/ df['ssc_p']\n    df['degree_to_hsc'] = df['degree_p'] \/ df['hsc_p']\n    df['degree_to_ssc'] = df['degree_p'] \/ df['ssc_p']\n    df['mba_to_degree'] = df['mba_p'] \/ df['degree_p']\n    df['mba_to_etest'] = df['mba_p'] \/ df['etest_p']\n        \n    return df","8e3e5d00":"data = new_features(data)","c9e7cc38":"# Seperating Features and Target\nX = data.copy().drop('status', axis=1)\ny = data['status']","444ff373":"# scale each features\nX_scaled = preprocessing.scale(X)","c395d087":"#Train Test Split\nX_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.3)\nX_train.shape, Y_train.shape, X_test.shape","23eca305":"# k-nearest neighbor\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nknn_Y_pred = knn.predict(X_test)\nknn_accuracy = knn.score(X_test, Y_test)\nknn_accuracy","83f82662":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, knn_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","a6cacc59":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, knn_Y_pred))","4788b17d":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\ndecision_tree_Y_pred = decision_tree.predict(X_test)\ndecision_tree_accuracy = decision_tree.score(X_test, Y_test)\ndecision_tree_accuracy","b35ef163":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, decision_tree_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","5e3a71ba":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, decision_tree_Y_pred))","21393531":"# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nsvm_Y_pred = svc.predict(X_test)\nsvc_accuracy = svc.score(X_test, Y_test)\nsvc_accuracy","a4b0b622":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, svm_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","9751c4a3":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, svm_Y_pred))","ae325578":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=1000)\nrandom_forest.fit(X_train, Y_train)\nrandom_forest_Y_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nrandom_forest_accuracy = random_forest.score(X_test, Y_test)\nrandom_forest_accuracy","bfba0169":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, random_forest_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","e92a8058":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, random_forest_Y_pred))","742c7ee5":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\ngaussian_Y_pred = gaussian.predict(X_test)\ngaussian_accuracy = gaussian.score(X_test, Y_test)\ngaussian_accuracy","df9b88e3":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, gaussian_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","45f974cc":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, gaussian_Y_pred))","775b09c5":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nsgd_Y_pred = sgd.predict(X_test)\nsgd_accuracy = sgd.score(X_test, Y_test)\nsgd_accuracy","2700a984":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, sgd_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","e7cb4ff7":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, sgd_Y_pred))","a0ac7e23":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nlinear_svc_Y_pred = linear_svc.predict(X_test)\nlinear_svc_accuracy = linear_svc.score(X_test, Y_test)\nlinear_svc_accuracy","79b75e53":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, linear_svc_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","71d69663":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, linear_svc_Y_pred))","331cd6d1":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Linear SVC', 'Decision Tree','Random Forest', 'Stochastic Gradient Descent', 'Gaussian Naive Bayes'],\n    'Score': [svc_accuracy, knn_accuracy, linear_svc_accuracy, decision_tree_accuracy, random_forest_accuracy, sgd_accuracy, gaussian_accuracy]})\nmodels.sort_values(by='Score', ascending=False)","4a31db2a":"Students who are place have higer percentage in SSC.","3cb6dfb1":"<a id='#4.6'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.6. HSC Board<\/b><\/font>","a207e242":"<a id='#4.2'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.2. Gender<\/b><\/font>\n\nLet's check whethere gender affect on placement.\n- Out of 215 candidates, 139 are male and 76 are female.","ee000347":"<a id='#2.2'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>2.2. Data size and Structure<\/b><\/font>","f66314e1":"Let's map categorical feature to numeric one.\nCategorical features:\n- Gender : Gender feature have male and female values. I am going to map 0 for male and 1 for female.\n- Work Experience : Work Experience feature have Yes and No values. I am going to map 0 for No and 1 for Yes.\n- Status : Status feature have Not Placed and Placed values. Again for this features I am mapping 0 for not placed and 1 for placed values.\n- Specialisation : Specialisation feature have two values Mkt&HR and Mkt&Fin. I am going to map 0 to Mkt&HR and 1 to Mkt&Fin.","1eed58bc":"<a id='#4.3'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.3. SSC Percentage<\/b><\/font>","323affe5":"Now our data is ready to prepare model to predict solution. There is plenty of predictive algorithm out there to try. In this project, I am going to use classification and regression algorithms.","75ac74ab":"<a id='#6.5'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.5. Random Forest<\/b><\/font>","d2fdc66a":"<a id='#4'><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>3. Exploring important features<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","9776262f":"<a id='#4.4'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.4. SSC Board<\/b><\/font>","5d75babf":"<a id='#6.9'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.9. Best Performing Model<\/b><\/font>","1e5d86a5":"<a id='#5'><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>4. Feature mapping and generation<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","ed57cf0e":"<a id='#4.12'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.12. MBA Specialization<\/b><\/font>","bf58df36":"<a id='#1'><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>1. Summary<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","63418bb7":"<a id='#4.13'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.13. MBA Percentage<\/b><\/font>","d1e41890":"As it is clear that we don't need sl_no in training model or in EDA. Thus I am dropping sl_no column. Rest of them I will keep as it is. After performing EDA I will drop other if needed.","422ebe74":"From the above analysis I can say that, SSC board is not important to recruiters when it come to hiring candidates.\nSo I am not going to use this feature while training model.","22d2e702":"<a id='#4.5'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.5. HSC Percentage <\/b><\/font>","f84b2f72":"<a id='#4.14'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.14. Most Important Factor; Salary<\/b><\/font>","9f2b09fa":"Like SSC and HSC percentages, Degree Percentages are also impotant factor to get placed.","0de768f1":"<a id='#4.7'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.7. HSC Specialisation<\/b><\/font>","8468fcfb":"<a id='#4.1'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.1. The Class Variable; Status<\/b><\/font>","01cc1c98":"<a id='#4.11'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.11. Employment Test Percentage<\/b><\/font>","2563aeae":"<font color='red' size=5>\n    <center>\n        I hope you enjoyed this kernel, Please don't forget to appreciate me with an Upvote. :)\n    <\/center>\n<\/font>","74ae97dc":"It is obvious, we dont have salary details of Un-Placed candidate. Salary feature alone is enough to classify the placement status of candidate (if salary > 0 then placed else not placed). However, if we want to use only salary feature then we dont need machine learning for that, by looking only we can do that. So I am going to drop this column while performing classification model training.","180e20f7":"From the above analysis I can say that, SSC board is not important to recruiters when it come to hiring candidates.\nSo I am not going to use this feature while training model.","9740b3d4":"### Features in data.","b5f7d677":"<a id='#6.6'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.6. Gaussian Naive Bayes<\/b><\/font>","54470c3d":"### Let's have look at each column information.\n\n* sl_no : Serial Number\n\n* gender : Candidate gender --> Male='M',Female='F'\n\n* ssc_p : SSC (10th) Percentage\n\n* ssc_b : SSC Board of Education --> Central (or) Others\n\n* hsc_p : HSC (12th) percentage\n\n* hsc_b : HSC Board of Education --> Central\/ Others\n\n* hsc_s : Specialization in HSC\n\n* degree_p : Degree Percentage\n\n* degree_t : Under Graduation (Degree type)- Field of degree education\n\n* workex : Work Experience\n\n* etest_p : Employability test percentage ( conducted by college)\n\n* specialisation : Post Graduation(MBA)- Specialization\n\n* mba_p : MBA percentage\n\n* status : Status of placement- Placed\/Not placed\n\n* salary : Salary offered by corporate to candidates","eeacfe0b":"<a id='#4.8'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.8. Degree Percentage<\/b><\/font>","470938d1":"<a id='#6.2'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.2. KNN Classification<\/b><\/font>","b0336c20":"It is clear that candidate with work experience have higher chance of getting placed.","b43f72e8":"<a id='#2.1'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>2.1. Loading libraries required and reading the data into Python DataFrame<\/b><\/font>","0b4109f3":"We have only 215 samples in our dataset. I hope this is enough to train models.","54e3f198":"![]()\n<center>\n    <img src='https:\/\/d8it4huxumps7.cloudfront.net\/bites\/wp-content\/banners\/2020\/7\/5f02f3ca4efab_campus_recruitment_process_heres_everything_you_need_to_know.png?d=700x400'>\n    <font size='1'> Source: https:\/\/d8it4huxumps7.cloudfront.net\/bites\/wp-content\/banners\/2020\/7\/5f02f3ca4efab_campus_recruitment_process_heres_everything_you_need_to_know.png?d=700x400 <\/font>\n<\/center>\n","b716a684":"<font color='blue' size='9.5'><b><i>\n    Campus Recruitment: EDA and Classification<\/b><\/i>\n<\/font>\n\n<font size='2'>Durgesh Samariya | The ML PhD Student<\/font>","33e7b9c3":"<a id='#4.9'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.9. Degree Type<\/b><\/font>","8c62a29f":"<a id='#4.10'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.10. Work Experience<\/b><\/font>","0f6fd9e5":"<a id='#5.1'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>4.1. Additional feature generation<\/b><\/font>","c80ac151":"<a id='#4.15'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>3.15. Correlation between features<\/b><\/font>","25a4af3c":"Let's have look at example samples.","748c8894":"<a id='#6.3'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.3. Decision Tree Classification<\/b><\/font>","eb128682":"<a id=\"top\"><\/a>\n## Table of Content\n\n* [1. Summary](#1)\n* [2. Loading and Exploring Data](#2)\n    - [2.1 Loading libraries required and reading the data into Python DataFrame](#2.1)\n    - [2.2 Data size and structure](#2.2)\n* [3. Exploring features and relation with target class](#4)\n    - [3.1. Target Class; Status](#4.1)\n    - [3.2. Gender](#4.2)\n    - [3.3. SSC Percentage](#4.3)\n    - [3.4. SSC Board](#4.4)\n    - [3.5. HSC Percentage](#4.5)\n    - [3.6. HSC Board](#4.6)\n    - [3.7. HSC Specialization](#4.7)\n    - [3.8. Degree Percentage](#4.8)\n    - [3.9. Degree Type](#4.9)\n    - [3.10. Work Experience](#4.10)\n    - [3.11. Employment Test Percentage](#4.11)\n    - [3.12. MBA Specialization](#4.12)\n    - [3.13. MBA Percentage](#4.13)\n    - [3.14. Most Important Factor; Salary](#4.14)\n    - [3.15. Correlation between features](#4.15)\n* [4. Feature mapping and generation](#5)\n    - [4.1. Additional feature generation](#5.1)\n* [5. Model Prediction](#6)\n    - [5.1. Train and Test Split](#6.1)\n    - [5.2. KNN Classification](#6.2)\n    - [5.3. Decision Tree Classification](#6.3)\n    - [5.4. Support Vector Machine](#6.4)\n    - [5.5. Random Forest](#6.5)\n    - [5.6. Gaussian Naive Bayes](#6.6)\n    - [5.7. Stochastic Gradient Descent](#6.7)\n    - [5.8. Linear SVC](#6.8)\n    - [5.9. Best Performing Model](#6.9)","be66a4af":"<font color='red' size='5'>\n    <center>\n        Please Upvote my kernel if you like my work.\n    <\/center>\n<\/font>","efa18484":"<a id='#2'><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>2. Loading and Exploring Data<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","0e365ab0":"<a id='#6.8'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.8. Linear SVC<\/b><\/font>","82df8c98":"<a id='#6.7'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.7. Stochastic Gradient Descent<\/b><\/font>","bc7672c8":"Male have high chances of getting placed compared to females.","72cfbe18":"Let's drop all unwanted columns as menstioned in above section.\n- SSC Board\n- HSC Board\n- HSC Specialisation\n- Degree Type\n- Salart","03fe4ff0":"<font size=3>Campus placement or campus recruiting is a program conducted within universities or other educational institutions to provide jobs to students nearing completion of their studies. <\/font>\n<center>\n    <img src='https:\/\/annamacharyagroup.org\/wp-content\/uploads\/2018\/05\/Tip-for-campus-placements-2-05-2018.jpg'>\n    <text size=2> Source: https:\/\/annamacharyagroup.org\/wp-content\/uploads\/2018\/05\/Tip-for-campus-placements-2-05-2018.jpg<\/text>\n<\/center>\n<hr>\n\n<font size=5>Problem Statement:<\/font>\n\nXYZ University wants to build machine learning model to know whethere student will get placed or not. So that they can provide special attention and help them to get job. Given dataset can be trated as classification or regression problem. In this project, I am going to focus on classification problem, where task is to find whethere candidate will placed or not. This is binary classification problem.\n\nIn this project, I used following classification algorithms.\n- KNN Classification\n- Decision Tree Classification\n- Support Vector Machine\n- Random Forest\n- Gaussian Naive Bayes\n- Stochastic Gradient Descent\n- Linear SVC","32ab5493":"<a id='#6'><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>5. Model Prediction<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","f5e62232":"<a id='#6.4'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.4. Support Vector Machine<\/b><\/font>","a380182b":"HSC percentage are important features. As all placed students have higher percentages.","86123e7d":"<a id='#6.1'><\/a>\n<font color=\"darkslateblue\" size=3.5><b>5.1. Train and Test Split<\/b><\/font>"}}