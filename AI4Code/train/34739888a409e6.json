{"cell_type":{"f968654f":"code","51a2995e":"code","0b5f1926":"code","d128d845":"markdown","4617d83f":"markdown","2e4772ad":"markdown","e78f2cf3":"markdown"},"source":{"f968654f":"# Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"talk\")\n\nfrom scipy.stats import beta","51a2995e":"# figure and axes\nfig, ax = plt.subplots(5, 5, figsize=(20, 20))\n\n# parameters\nparams = np.array([0.5, 1, 2, 3, 5])\ncolors = sns.cubehelix_palette(25)\n\n# range\ncounts = 0\nfor r, a in enumerate(params):\n    for c, b in enumerate(params):\n        # probability densitiy function\n        x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), 100)\n        ax[r, c].plot(x, beta.pdf(x, a, b), 'r-', color=colors[counts], lw=10, alpha=0.9)\n        ax[r, c].set_title(\"a = \" + str(a) + \", b = \" + str(b))\n        counts += 1\n        if c == 0:\n            ax[r, c].set_ylabel(\"PDF\")\n        if r == 0:\n            ax[r, c].set_xlabel(\"x\")\nplt.tight_layout()","0b5f1926":"# figure and axes\nfig, ax = plt.subplots(5, 5, figsize=(20, 20))\n\n# parameters\nparams = np.array([0.5, 1, 2, 3, 5])\n\n# range\ncounts = 0\nfor r, a in enumerate(params):\n    for c, b in enumerate(params):\n        # probability densitiy function\n        x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), 100)\n        ax[r, c].plot(x, beta.cdf(x, a, b), 'r-', color=colors[counts], lw=10, alpha=0.9)\n        ax[r, c].set_title(\"a = \" + str(a) + \", b = \" + str(b))\n        counts += 1\n        if c == 0:\n            ax[r, c].set_ylabel(\"CDF\")\n        if r == 0:\n            ax[r, c].set_xlabel(\"x\")\nplt.tight_layout()","d128d845":"# Beta distribution (Probability Density Function)","4617d83f":"Apparently the Beta distribution can take many forms:D Which is your favorite?:)","2e4772ad":"# Beta distribution (cumulative density function)","e78f2cf3":"Once you learn the Bayesian statistics, you should come across **the Beta distribution**.\n\nBeta distribution is something you might have not used at all when you were dealing with a frequentist statistics and a conventional machine learning. However, when it comes to **the Bayesian inference**, which is to estimate the posterior probability distribution given the prior and observations, the Beta distribution is extremely useful.\n\nWhat is good with the Beta distribution?\n\nWell, using the Beta distribution, **you can model the probability itself, just by two positive shape parameters**.\n\nAs the Bayesian inference is all about estimating the probability, this feature of Beta distribution is very helpful to model probabilistic behaviors.\n\nFurthermore, **the Beta distribution is the conjugate prior probability distribution for the Bernoulli, binomial, negative binomial and geometric distributions**. That means, you can easily compute the posterior distribution by modeling the prior distribution with the Beta distribution.\n\nLet's have a look at how the Beta distribution looks like as a function of the shape parameters, a and b!"}}