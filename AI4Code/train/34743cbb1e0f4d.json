{"cell_type":{"6c7445df":"code","288f54ac":"code","f36d00d5":"code","bdefcdfe":"code","5cab95eb":"code","7c17b70a":"code","4341192a":"code","a2f56832":"code","34354547":"code","62094701":"code","98d6d168":"code","26d41fba":"code","5bda397e":"code","b3f57577":"code","5494d4c0":"code","c2563c52":"code","41d01e33":"code","f2874215":"code","52f98f33":"code","4d0ec096":"code","e1d4ab80":"code","eaaa7488":"code","9b948926":"code","0235be74":"code","0f360fcd":"code","7f2856d6":"code","5a8c8e62":"code","154801fe":"code","1fd66445":"code","56b96b4e":"code","6471dc80":"code","d34025a8":"code","2a1a3c4c":"code","b9a5d988":"code","a6851e2d":"code","f1c080e0":"code","bc3eded2":"code","99e4cdb4":"code","985921fc":"code","c5fbd9e7":"code","3a878d84":"code","f181f654":"markdown","7a7361e1":"markdown","f40542e4":"markdown","f1befb9f":"markdown","9a2a113f":"markdown","df347748":"markdown","c2a14720":"markdown","59918aab":"markdown","3ceb4aa3":"markdown","abf2f8f1":"markdown","53ef19b1":"markdown","27f444f8":"markdown","ccdafeb1":"markdown","dbcea008":"markdown","aba2c4cd":"markdown","73b2b1fe":"markdown"},"source":{"6c7445df":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","288f54ac":"data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndata.head()","f36d00d5":"data.shape","bdefcdfe":"data.info()","5cab95eb":"data.describe()","7c17b70a":"sns.countplot(x='Class', data=data)\nprint(\"Fraud: \",data.Class.sum()\/data.Class.count())","4341192a":"Fraud_class = pd.DataFrame({'Fraud': data['Class']})\nFraud_class.apply(pd.value_counts).plot(kind='pie',subplots=True)","a2f56832":"fraud = data[data['Class'] == 1] \nvalid = data[data['Class'] == 0] ","34354547":"fraud.Amount.describe() ","62094701":"valid.Amount.describe()","98d6d168":"plt.figure(figsize=(20,20))\nplt.title('Correlation Matrix', y=1.05, size=15)\nsns.heatmap(data.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, linecolor='white', annot=True)","26d41fba":"from sklearn.preprocessing import RobustScaler\nrs = RobustScaler()\n\ndata['Amount'] = rs.fit_transform(data['Amount'].values.reshape(-1, 1))\ndata['Time'] = rs.fit_transform(data['Time'].values.reshape(-1, 1))","5bda397e":"X = data.drop(['Class'], axis = 1) \nY = data[\"Class\"] ","b3f57577":"from sklearn.model_selection import train_test_split \n# Split the data into training and testing sets \nX_train, X_test, Y_train, Y_test = train_test_split( \n        X, Y, test_size = 0.2, random_state = 1) ","5494d4c0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score","c2563c52":"def evaluate(Y_pred, Y_pred_prob):\n    print(\"Accuracy: \",accuracy_score(Y_test, Y_pred)) \n    print(\"Precision: \",precision_score(Y_test, Y_pred))\n    print(\"Recall: \",recall_score(Y_test, Y_pred))\n    print(\"F1-Score: \",f1_score(Y_test, Y_pred))\n    print(\"AUC score: \",roc_auc_score(Y_test, Y_pred))\n    \n    print(classification_report(Y_test, Y_pred, target_names = ['Normal', 'Fraud']))\n     \n    conf_matrix = confusion_matrix(Y_test, Y_pred) \n    plt.figure(figsize =(6, 6)) \n    sns.heatmap(conf_matrix, xticklabels = ['Normal', 'Fraud'],  \n            yticklabels = ['Normal', 'Fraud'], annot = True, fmt =\"d\"); \n    plt.title(\"Confusion matrix\") \n    plt.ylabel('True class') \n    plt.xlabel('Predicted class') \n    plt.show() \n    \n    \n    p, r, t = precision_recall_curve(Y_test, Y_pred_prob)\n    plt.plot(p, r)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve')\n    \n    ","41d01e33":"lr = LogisticRegression()\nlr.fit(X_train, Y_train)\nY_pred_lr_i = lr.predict(X_test)","f2874215":"Y_pred_prob_lr_i = lr.predict_proba(X_test)[:,1]","52f98f33":"evaluate(Y_pred_lr_i, Y_pred_prob_lr_i)","4d0ec096":"# random forest model creation \nrfc = RandomForestClassifier() \nrfc.fit(X_train, Y_train) \n# predictions \nY_pred_rf_i = rfc.predict(X_test) ","e1d4ab80":"Y_pred_prob_rf_i = rfc.predict_proba(X_test)[:,1]","eaaa7488":"evaluate(Y_pred_rf_i, Y_pred_prob_rf_i)","9b948926":"from sklearn.ensemble import RandomForestClassifier \n# random forest model creation \nrfb = RandomForestClassifier(class_weight='balanced') \nrfb.fit(X_train, Y_train) \n# predictions \nY_pred_rf_b = rfb.predict(X_test) ","0235be74":"Y_pred_prob_rf_b = rfb.predict_proba(X_test)[:,1]","0f360fcd":"evaluate(Y_pred_rf_b, Y_pred_prob_rf_b)","7f2856d6":"from imblearn.over_sampling import SMOTE","5a8c8e62":"smote = SMOTE(random_state=56)\nsmote_X, smote_Y = smote.fit_resample(X, Y)","154801fe":"sns.countplot(smote_Y)","1fd66445":"X_train, X_test, Y_train, Y_test = train_test_split(smote_X, smote_Y, test_size=0.2, random_state=1)","56b96b4e":"lr_smote = LogisticRegression()\nlr_smote.fit(X_train, Y_train)\nY_pred_lr_smote = lr_smote.predict(X_test)","6471dc80":"Y_pred_prob_lr_smote = lr_smote.predict_proba(X_test)[:,1]","d34025a8":"evaluate(Y_pred_lr_smote, Y_pred_prob_lr_smote)","2a1a3c4c":"rf_smote = RandomForestClassifier() \nrf_smote.fit(X_train, Y_train)  \nY_pred_rf_smote = rf_smote.predict(X_test) ","b9a5d988":"Y_pred_prob_rf_smote = rf_smote.predict_proba(X_test)[:,1]","a6851e2d":"evaluate(Y_pred_rf_smote, Y_pred_prob_rf_smote)","f1c080e0":"spw = 1\/0.00172","bc3eded2":"xgbc = XGBClassifier(n_estimators = 1000, verbosity = 1, scale_pos_weight = spw)\nxgbc.fit(X_train, Y_train)\n\nY_pred_xgb = xgbc.predict(X_test)","99e4cdb4":"Y_pred_xgb_prob = xgbc.predict_proba(X_test)[:,1]","985921fc":"evaluate(Y_pred_xgb, Y_pred_xgb_prob)","c5fbd9e7":"importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(rf_smote.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.plot.bar()","3a878d84":"importances.sort_values('importance')","f181f654":"### Observations:\n- No high correlation between features seen.","7a7361e1":"# Loading Data","f40542e4":"## Logistic Regression - initial","f1befb9f":"# Using SMOTE","9a2a113f":"## Scale data\n","df347748":"# Models","c2a14720":"## Random Forest","59918aab":"### Obervation:\n- High Class imbalance \n- 0.17% of data consists class Fraud","3ceb4aa3":"# Loading Libraries","abf2f8f1":"## Random forest with balanced class weights","53ef19b1":"## XGBoost","27f444f8":"## Logistic Regression","ccdafeb1":"## Feature Importance","dbcea008":"# Exploring Data","aba2c4cd":"## Random Forest - Initial","73b2b1fe":"The argument value of \u2018balanced\u2018 here can be provided to automatically use the inverse weighting from the training dataset, giving focus to the minority class."}}