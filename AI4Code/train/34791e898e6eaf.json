{"cell_type":{"e784accf":"code","4d16a217":"code","869a053f":"code","39533a7f":"code","0c5db65b":"code","e161c6a8":"code","d41f03a7":"code","cd807d0d":"code","33b18acc":"code","05b8dece":"code","57b3c1bb":"code","1dccdb39":"code","ec0fd0ba":"code","290acff7":"code","e2d11a6d":"code","deb157e0":"code","0fd74274":"code","2b6665c1":"code","7978ab90":"code","8269baba":"code","198e2c24":"code","e5224b8e":"code","ff6cfeb1":"code","4fc4b2ef":"code","0f1c5abf":"code","3d5cc8fb":"code","2ed821ae":"code","b31857b9":"code","37c30386":"code","01b924cc":"code","3449271c":"code","58627f99":"code","e7bff350":"code","66c180c3":"code","5d0043f7":"code","66571e22":"markdown","a1188160":"markdown","2cc619b3":"markdown","f4ba8db0":"markdown","e3cf067f":"markdown","8f25cbe0":"markdown","483d2d3f":"markdown","0885bc11":"markdown","1ea30808":"markdown","9757000e":"markdown","ade16958":"markdown","3eb8e0a7":"markdown","a3167c6b":"markdown","35ed8cc3":"markdown","43af0244":"markdown","0e354dfe":"markdown","33e1a1e1":"markdown","f55fd8dc":"markdown","1352bb21":"markdown","e48040db":"markdown","dffb02f0":"markdown","a4eac0e1":"markdown","3ff4602d":"markdown","1529c1d4":"markdown","a7d08e6e":"markdown","10217c5b":"markdown","97e43462":"markdown","8d3e2e6c":"markdown","76ff2313":"markdown","541f12a5":"markdown","3560651a":"markdown","02b46fa0":"markdown","fe0f5952":"markdown","a6527017":"markdown","005d8934":"markdown","62ff8f6b":"markdown","8063884c":"markdown","b95fd0ce":"markdown","9073e013":"markdown","ba5a8b44":"markdown","2130398f":"markdown","82ad28bc":"markdown","cc9f1fd9":"markdown"},"source":{"e784accf":"import pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\n\nimport gc\nfrom datetime import datetime \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn import svm\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nimport xgboost as xgb\n\npd.set_option('display.max_columns', 100)\nMAX_ROUNDS = 1000 #lgb iterations\nEARLY_STOP = 50 #lgb early stop \nOPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\nVERBOSE_EVAL = 50 #Print out metric result\n\nIS_LOCAL = False\n\nimport os\n\nif(IS_LOCAL):\n    PATH=\"..\/input\/credit-card-fraud-detection\"\nelse:\n    PATH=\"..\/input\"\nprint(os.listdir(PATH))","4d16a217":"data_df=pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","869a053f":"data_df.head(20)","39533a7f":"data_df.shape","0c5db65b":"data_df.describe()","e161c6a8":"data_df.isnull().sum().max()","d41f03a7":"sns.countplot(x='Class',data=data_df)\nplt.ylabel('Transaction')\nplt.title('Credit Card Fraud - Class unbalance')\nplt.legend()\n","cd807d0d":"sns.kdeplot(data=data_df.loc[data_df['Class']==0]['Time'],label='No Fraud')\nsns.kdeplot(data=data_df.loc[data_df['Class']==1]['Time'],label='Fraud')\nplt.xlabel('Time')\n","33b18acc":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\ns = sns.boxplot(ax = ax1, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data_df, palette=\"PRGn\",showfliers=True)\ns = sns.boxplot(ax = ax2, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data_df, palette=\"PRGn\",showfliers=False)","05b8dece":"sns.scatterplot(x='Time',y='Amount',data=data_df.loc[data_df['Class']==1])","57b3c1bb":"plt.figure(figsize=(13,13))\nsns.heatmap(data_df.corr(),linewidths=.1,cmap='Reds')\nplt.title('Credit Card Transactions Correlation Matrix')","1dccdb39":"s = sns.lmplot(x='V20', y='Amount',data=data_df, hue='Class', fit_reg=True,scatter_kws={'s':2})\ns = sns.lmplot(x='V7', y='Amount',data=data_df, hue='Class', fit_reg=True,scatter_kws={'s':2})\nplt.show()","ec0fd0ba":"s = sns.lmplot(x='V2', y='Amount',data=data_df, hue='Class', fit_reg=True,scatter_kws={'s':2})\ns = sns.lmplot(x='V5', y='Amount',data=data_df, hue='Class', fit_reg=True,scatter_kws={'s':2})\nplt.show()","290acff7":"var = data_df.columns.values\n\ni = 0\nt0 = data_df.loc[data_df['Class'] == 0]\nt1 = data_df.loc[data_df['Class'] == 1]\n\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(8,4,figsize=(16,28))\n\nfor feature in var:\n    i += 1\n    plt.subplot(8,4,i)\n    sns.kdeplot(t0[feature], bw=0.5,label=\"Class = 0\")\n    sns.kdeplot(t1[feature], bw=0.5,label=\"Class = 1\")\n    plt.xlabel(feature, fontsize=12)\n    locs, labels = plt.xticks()\n    plt.tick_params(axis='both', which='major', labelsize=12)\nplt.show()","e2d11a6d":"target = 'Class'\npredictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n       'Amount']","deb157e0":"train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=2, shuffle=True)\ntrain_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=2, shuffle=True)","0fd74274":"clf = RandomForestClassifier(n_jobs=4, \n                             random_state=2,\n                             criterion='gini',\n                             n_estimators=100,\n                             verbose=False)","2b6665c1":"clf.fit(train_df[predictors], train_df[target].values)\n","7978ab90":"preds = clf.predict(valid_df[predictors])\n","8269baba":"tmp=pd.DataFrame({'Features':predictors,'Importance':clf.feature_importances_})\ntmp.sort_values(by='Importance',ascending=False,inplace=True)\nsns.barplot(x='Features',y='Importance',data=tmp)\nplt.xticks(rotation=90)","198e2c24":"cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm,xticklabels=['Not Fraud', 'Fraud'],yticklabels=['Not Fraud', 'Fraud'],annot=True,ax=ax1,linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\nplt.title('Confusion Matrix', fontsize=14)\nplt.show()","e5224b8e":"roc_auc_score(valid_df[target].values, preds)\n","ff6cfeb1":"clf = AdaBoostClassifier(random_state=2,\n                         algorithm='SAMME.R',\n                         learning_rate=0.8,\n                             n_estimators=100)","4fc4b2ef":"clf.fit(train_df[predictors], train_df[target].values)\n","0f1c5abf":"preds = clf.predict(valid_df[predictors])\n","3d5cc8fb":"tmp=pd.DataFrame({'Features':predictors,'Importance':clf.feature_importances_})\ntmp.sort_values(by='Importance',ascending=False,inplace=True)\nsns.barplot(x='Features',y='Importance',data=tmp)\nplt.xticks(rotation=90)","2ed821ae":"cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm, \n            xticklabels=['Not Fraud', 'Fraud'],\n            yticklabels=['Not Fraud', 'Fraud'],\n            annot=True,ax=ax1,\n            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\nplt.title('Confusion Matrix', fontsize=14)\nplt.show()","b31857b9":"roc_auc_score(valid_df[target].values, preds)","37c30386":"clf = CatBoostClassifier(iterations=500,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='AUC',\n                             random_seed = 2,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 50,\n                             od_wait=100)\n","01b924cc":"clf.fit(train_df[predictors], train_df[target].values,verbose=True)\n","3449271c":"preds = clf.predict(valid_df[predictors])\n","58627f99":"tmp=pd.DataFrame({'Features':predictors,'Importance':clf.feature_importances_})\ntmp.sort_values(by='Importance',ascending=False,inplace=True)\nsns.barplot(x='Features',y='Importance',data=tmp)\nplt.xticks(rotation=90)","e7bff350":"cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm, \n            xticklabels=['Not Fraud', 'Fraud'],\n            yticklabels=['Not Fraud', 'Fraud'],\n            annot=True,ax=ax1,\n            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\nplt.title('Confusion Matrix', fontsize=14)\nplt.show()","66c180c3":"roc_auc_score(valid_df[target].values, preds)","5d0043f7":"kf = KFold(n_splits = 5, random_state = 2, shuffle = True)\n\n# Create arrays and dataframes to store results\noof_preds = np.zeros(train_df.shape[0])\ntest_preds = np.zeros(test_df.shape[0])\nfeature_importance_df = pd.DataFrame()\nn_fold = 0\nfor train_idx, valid_idx in kf.split(train_df):\n    train_x, train_y = train_df[predictors].iloc[train_idx],train_df[target].iloc[train_idx]\n    valid_x, valid_y = train_df[predictors].iloc[valid_idx],train_df[target].iloc[valid_idx]\n    \n    evals_results = {}\n    model =  LGBMClassifier(\n                  nthread=-1,\n                  n_estimators=2000,\n                  learning_rate=0.01,\n                  num_leaves=80,\n                  colsample_bytree=0.98,\n                  subsample=0.78,\n                  reg_alpha=0.04,\n                  reg_lambda=0.073,\n                  subsample_for_bin=50,\n                  boosting_type='gbdt',\n                  is_unbalance=False,\n                  min_split_gain=0.025,\n                  min_child_weight=40,\n                  min_child_samples=510,\n                  objective='binary',\n                  metric='auc',\n                  silent=-1,\n                  verbose=-1,\n                  feval=None)\n    model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n                eval_metric= 'auc', verbose= VERBOSE_EVAL, early_stopping_rounds= EARLY_STOP)\n    \n    oof_preds[valid_idx] = model.predict_proba(valid_x, num_iteration=model.best_iteration_)[:, 1]\n    test_preds += model.predict_proba(test_df[predictors], num_iteration=model.best_iteration_)[:, 1] \/ kf.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = predictors\n    fold_importance_df[\"importance\"] = clf.feature_importances_\n    fold_importance_df[\"fold\"] = n_fold + 1\n    \n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n    del model, train_x, train_y, valid_x, valid_y\n    gc.collect()\n    n_fold = n_fold + 1\ntrain_auc_score = roc_auc_score(train_df[target], oof_preds)\nprint('Full AUC score %.6f' % train_auc_score)","66571e22":"**Confusion matrix**","a1188160":"**Defining predictors and targets features.**","2cc619b3":"Look into more details of it.","f4ba8db0":"# Predicting Models","e3cf067f":"I hope that this notebook would be helpful to you .\n\n**Please do upvote !!!\nThanks in advance**","8f25cbe0":"# Checking the data Unbalance","483d2d3f":"**Confusion Matrix**","0885bc11":"**Prepare the model.**","1ea30808":"# AdaBoostClassifier","9757000e":"# Feature Importance","ade16958":"The ROC-AUC score obtained with AdaBoostClassifier is 0.86.\n\n","3eb8e0a7":"Plot the importance of each feature on a bargraph.","a3167c6b":"The AUC score for the prediction from the test data was 0.96.\n\nWe prepare the test prediction, from the averaged predictions for test over the 5 folds.","35ed8cc3":"# Check missing data","43af0244":"Defining Model Parameters and initializing the model.","0e354dfe":"**Correlation Matrix of the data**","33e1a1e1":"For some of the features we can observe a good selectivity in terms of distribution for the two values of Class: V4, V11 have clearly separated distributions for Class values 0 and 1, V12, V14, V18 are partially separated, V1, V2, V3, V10 have a quite distinct profile, whilst V25, V26, V28 have similar profiles for the two values of Class.\n\nIn general, with just few exceptions (Time and Amount), the features distribution for legitimate transactions (values of Class = 0) is centered around 0, sometime with a long queue at one of the extremities. In the same time, the fraudulent transactions (values of Class = 1) have a skewed (asymmetric) distribution.","f55fd8dc":"**Fit the model**","1352bb21":"Variation with transaction amount.","e48040db":"**Plotting the relations between different correlation features**","dffb02f0":"Train the model.","a4eac0e1":"# Read data","3ff4602d":"**Predict the target features**","1529c1d4":"**Feature Importance**","a7d08e6e":"**Initialize the model**","10217c5b":"**Predicting the target featrues.**","97e43462":"Amount of fraudlent transaction over time.","8d3e2e6c":"**Feature importance**","76ff2313":"# Random Forest Classifier","541f12a5":"**Variation with time**","3560651a":"**Fit the model.**","02b46fa0":"# Features Density plot","fe0f5952":"# Load Packages","a6527017":"Predict the target Values using the predict method.","005d8934":"**Test Train and Split between the dataset.**","62ff8f6b":"The ROC-AUC score obtained with CatBoostClassifier is 0.88.\n\n","8063884c":"# CatBoost Classifier","b95fd0ce":"The ROC-AUC score obtained with RandomForrestClassifier is 0.86.\n\n","9073e013":"# Data Analysis","ba5a8b44":"As expected, there is no notable correlation between features V1-V28. There are certain correlations between some of these features and Time (inverse correlation with V3) and Amount (direct correlation with V7 and V20, inverse correlation with V1 and V5).","2130398f":"# A glimpse of the data","82ad28bc":"**Training and validation using cross-validation**\n\nLet's use now cross-validation. We will use cross-validation (KFolds) with 5 folds. Data is divided in 5 folds and, by rotation, we are training using 4 folds (n-1) and validate using the 5th (nth) fold.\n\nTest set is calculated as an average of the predictions","cc9f1fd9":"# **The Confusion matrix**"}}