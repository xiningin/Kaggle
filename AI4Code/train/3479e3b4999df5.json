{"cell_type":{"8c76d384":"code","6562c77d":"code","ebb5a099":"code","b1dbe2f6":"code","3cc8f642":"code","4b571ca8":"code","c1143ba1":"code","3b8fd810":"code","3eb33a90":"code","4245ad64":"code","083a5a72":"code","dda4c851":"code","b51c22c7":"code","1af7cbe9":"code","d2fe2d8e":"code","bc34a4ed":"markdown","043164ee":"markdown","2a491c1d":"markdown","01fc9bf9":"markdown","2d7e5ee4":"markdown","1eb4f177":"markdown","bd5648dd":"markdown","50d96aba":"markdown","98937af5":"markdown","d7a1cd82":"markdown","7f119ae4":"markdown","4a900b1d":"markdown","361fb92f":"markdown"},"source":{"8c76d384":"from tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","6562c77d":"!unzip ..\/input\/aerial-cactus-identification\/train.zip\n!unzip ..\/input\/aerial-cactus-identification\/test.zip","ebb5a099":"# [ train data ]\n\n# train image paths\nfile_path = '\/kaggle\/working\/'\ntrain_dir = '\/kaggle\/working\/train\/'\ntrain_fnames = os.listdir(train_dir)\ntrain_fpaths = [os.path.join(train_dir,fname) for fname in train_fnames]\n\n# train labels\ncsv_path ='..\/input\/aerial-cactus-identification\/train.csv'\ndf = pd.read_csv(csv_path)\ndf.head()\n\n# merge train image paths with labels\ntrain_df = pd.DataFrame(data={'id':train_fpaths,'has_cactus':df['has_cactus']})\ntrain_df = train_df.astype(str) # must replace label dtype to strings\n\nprint('classes : ',set(train_df['has_cactus']))\nprint('total train images : ',len(train_df))\nprint(train_df.head())\n\n# sample image\nsample = train_df['id'][0]\nimg_sample = Image.open(sample)\nimage = np.array(img_sample)\n\nprint(image.shape)\nplt.imshow(image)\n","b1dbe2f6":"sub_sample = '..\/input\/aerial-cactus-identification\/sample_submission.csv'\nsample_df = pd.read_csv(sub_sample)\nprint('submission sample \uc218 : ',len(sample_df))\n\ntest_dir = '\/kaggle\/working\/test\/'\ntest_names = os.listdir(test_dir)\ntest_paths = [os.path.join(test_dir,fname) for fname in test_names]\nprint('\ud14c\uc2a4\ud2b8\uc14b \uc218 : ',len(test_paths))\nsample_df.head()","3cc8f642":"test_df = train_df[-500:]\ntrain_df = train_df[:-500]","4b571ca8":"input_shape = (32,32,3)\nbatch_size = 32\nnum_classes =2\nnum_epochs = 5\nlearning_rate = 0.01","c1143ba1":"train_datagen = ImageDataGenerator(rescale=1.\/255.,\n                                  width_shift_range=0.3,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1.\/255.)","3b8fd810":"train_generator = train_datagen.flow_from_dataframe(train_df,\n                                                   x_col='id',\n                                                   y_col='has_cactus',\n                                                   target_size=input_shape[:2],\n                                                   batch_size=batch_size,\n                                                   class_mode='sparse')\n\ntest_generator = test_datagen.flow_from_dataframe(test_df,\n                                                 x_col='id',\n                                                 y_col='has_cactus',\n                                                 target_size=input_shape[:2],\n                                                 batch_size=batch_size,\n                                                 class_mode='sparse')","3eb33a90":"# model = tf.keras.applications.ResNet101(\n#     include_top=True, weights='imagenet', input_tensor=None,\n#     input_shape=None, pooling=None, classes=1000\n# )\n\n# model = tf.keras.applications.VGG16(\n#     include_top=True, weights='imagenet', input_tensor=None,\n#     input_shape=None, pooling=None, classes=1000,\n#     classifier_activation='softmax'\n# )\n\ninputs = layers.Input(input_shape)\nnet = layers.Conv2D(64, (3, 3), padding='same')(inputs)\nnet = layers.Conv2D(64, (3, 3), padding='same')(net)\nnet = layers.Conv2D(64, (3, 3), padding='same')(net)\nnet = layers.BatchNormalization()(net)\nnet = layers.Activation('relu')(net)\nnet = layers.MaxPooling2D(pool_size=(2, 2))(net)\n\nnet = layers.Conv2D(128, (3, 3), padding='same')(net)\nnet = layers.Conv2D(128, (3, 3), padding='same')(net)\nnet = layers.Conv2D(128, (3, 3), padding='same')(net)\nnet = layers.BatchNormalization()(net)\nnet = layers.Activation('relu')(net)\nnet = layers.MaxPooling2D(pool_size=(2, 2))(net)\nnet = layers.Dropout(0.25)(net)\n\nnet = layers.Conv2D(256, (3, 3), padding='same')(net)\nnet = layers.Conv2D(256, (3, 3), padding='same')(net)\nnet = layers.Conv2D(256, (3, 3), padding='same')(net)\nnet = layers.BatchNormalization()(net)\nnet = layers.Activation('relu')(net)\nnet = layers.MaxPooling2D(pool_size=(2, 2))(net)\nnet = layers.Dropout(0.25)(net)\n\nnet = layers.Conv2D(512, (3, 3), padding='same')(net)\nnet = layers.Conv2D(512, (3, 3), padding='same')(net)\nnet = layers.Conv2D(512, (3, 3), padding='same')(net)\nnet = layers.BatchNormalization()(net)\nnet = layers.Activation('relu')(net)\nnet = layers.MaxPooling2D(pool_size=(2, 2))(net)\nnet = layers.Dropout(0.25)(net)\n\nnet = layers.Conv2D(512, (3, 3), padding='same')(net)\nnet = layers.Conv2D(512, (3, 3), padding='same')(net)\nnet = layers.Conv2D(512, (3, 3), padding='same')(net)\nnet = layers.BatchNormalization()(net)\nnet = layers.Activation('relu')(net)\nnet = layers.MaxPooling2D(pool_size=(2, 2))(net)\nnet = layers.Dropout(0.25)(net)\n\nnet = layers.Flatten()(net)\nnet = layers.Dense(512)(net)\nnet = layers.Activation('relu')(net)\nnet = layers.Dropout(0.5)(net)\nnet = layers.Dense(num_classes)(net)\nnet = layers.Activation('softmax')(net)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=net)\n\nmodel.summary()","4245ad64":"model.compile(loss='sparse_categorical_crossentropy',\n             optimizer=tf.keras.optimizers.Adam(learning_rate),\n             metrics=['accuracy'])","083a5a72":"model.fit_generator(train_generator,\n                    steps_per_epoch=len(train_generator),\n                    epochs=num_epochs,\n                    validation_data = test_generator,\n                    validation_steps=len(test_generator))","dda4c851":"model_dir = '.\/model_cactus'\nmodel.save(model_dir)\n\nmodel = keras.models.load_model(model_dir)","b51c22c7":"# !rm -r train\n# !rm -r test","1af7cbe9":"test_dir = '\/kaggle\/working\/test\/'\ntest_names = os.listdir(test_dir)\ntest_paths = [os.path.join(test_dir,fname) for fname in test_names]\n\npreds = []\n\nfor test_path in tqdm_notebook(test_paths):\n    img_pil = Image.open(test_path)\n    image = np.array(img_pil)\n    \n    pred = model.predict(image[tf.newaxis, ...])\n    pred = np.argmax(pred)\n    preds.append(pred)\n    \n\nplt.imshow(image)\nprint('sample pred : ', pred)","d2fe2d8e":"submission_df = pd.DataFrame(data={'id':sample_df['id'],'has_cactus':preds})\nsubmission_df.to_csv('submission.csv',index=False)\nsubmission_df.head()","bc34a4ed":"# Contents\n 1. [Load Packages](#1.-Load-Packages)\n 2. [Check Dataset](#2.-Check-Datasets)\n 3. [Hyperparameter](#3.-Hyperparameter)\n 4. [Data Preprocessing](#4.-Data-Preprocessing) \n 5. [Model](#5.-Model)\n 6. [Train](#6.-Train)\n 7. [Evaluate](#7.-Evaluate)\n 8. [Save Submission](#8.-Save-Submission)\n ---","043164ee":"> ---\n> ## 2-4. train test split","2a491c1d":"---\n# 4. Data Preprocessing","01fc9bf9":"---\n# 3. Hyperparameter","2d7e5ee4":"> ---\n> ## 2-2. train dataframe merge","1eb4f177":"---\n# 6. Train","bd5648dd":"---\n# 7. Evaluate","50d96aba":"---\n# 2. Check Datasets","98937af5":"---\n# 8. Save Submission","d7a1cd82":"# 1. Load Packages","7f119ae4":"> ---\n> ## 2-3. check sample submission","4a900b1d":"---\n# 5. Model","361fb92f":"> ---\n> ## 2-1. Dataset unzip"}}