{"cell_type":{"896a7537":"code","63a20c32":"code","9c451304":"code","1bc019d4":"code","0c90935e":"code","c0eabdd4":"code","07540f01":"code","ffd7c32f":"code","76235390":"code","62f70ad9":"code","8611f65c":"code","a0e272cc":"code","f4e010e9":"code","2592d10d":"code","2e61c3f6":"code","5b0a391e":"code","c666a257":"code","3aae1e48":"code","ff8d9483":"code","be1daca0":"code","5fd50aae":"code","e74e5da0":"code","e65b716c":"code","628f7168":"code","7d0976d1":"code","70ba9be0":"code","9491f8d8":"code","9c5015ee":"code","d08abf6f":"code","ce511230":"markdown","d572bb68":"markdown","aa005445":"markdown","9bc8fdd2":"markdown","00bbc1fa":"markdown","7435ffea":"markdown","173e0e4a":"markdown","89bc23f0":"markdown"},"source":{"896a7537":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport glob\nimport cv2\nimport torch\nimport torchvision\nfrom PIL import Image\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import transforms\nfrom torchvision.utils import save_image\nfrom sklearn.model_selection import train_test_split\nfrom skimage import metrics\nfrom torch.autograd import Variable\n","63a20c32":"os.makedirs('motion_blurred', exist_ok=True)\nsrc_dir = '..\/input\/natural-images\/natural_images\/person'\nimages = os.listdir(src_dir)\ndst_dir = 'motion_blurred'\nsize=11\nkernel_motion_blur = np.zeros((size, size))\nkernel_motion_blur[int((size-1)\/2), :] = np.ones(size)\nkernel_motion_blur = kernel_motion_blur\/size\nfor i, img in tqdm(enumerate(images), total=len(images)):\n    img = cv2.imread(f\"{src_dir}\/{images[i]}\")\n    # add motion blur\n    blur=cv2.filter2D(img,-1,kernel_motion_blur)\n    cv2.imwrite(f\"{dst_dir}\/{images[i]}\", blur)\nprint('DONE')\n\n","9c451304":"image_dir = 'saved_images_motion'\nos.makedirs(image_dir, exist_ok=True)\n    \ndef save_decoded_image(img, name):\n    img = img.view(img.size(0), 3,224, 224)\n    save_image(img, name)","1bc019d4":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)\n\nbatch_size = 5\n\nmotion_blur = os.listdir('motion_blurred')\nmotion_blur.sort()\nsharp = os.listdir('..\/input\/natural-images\/natural_images\/person')\nsharp.sort()\n\nx_blur = []\nfor i in range(len(motion_blur)):\n    x_blur.append(motion_blur[i])\n\ny_sharp = []\nfor i in range(len(sharp)):\n    y_sharp.append(sharp[i])\n    \nprint(x_blur[10])\nprint(y_sharp[10])\n\n(x_train, x_val, y_train, y_val) = train_test_split(x_blur[:900], y_sharp[:900], test_size=0.25)\n\nprint(len(x_train))\nprint(len(x_val))\n","0c90935e":"# define transforms\ntransform = transforms.Compose([\n    \n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])","c0eabdd4":"class DeblurDataset(Dataset):\n    def __init__(self, blur_paths, sharp_paths=None, transforms=None):\n        self.X = blur_paths\n        self.y = sharp_paths\n        self.transforms = transforms\n         \n    def __len__(self):\n        return (len(self.X))\n    \n    def __getitem__(self, i):\n        blur_image = Image.open(f\"motion_blurred\/{self.X[i]}\")\n        \n        if self.transforms:\n            blur_image = self.transforms(blur_image)\n            \n        if self.y is not None:\n            sharp_image = Image.open(f\"..\/input\/natural-images\/natural_images\/person\/{self.y[i]}\")\n            sharp_image = self.transforms(sharp_image)\n            return (blur_image, sharp_image)\n        else:\n            return blur_image\n","07540f01":"train_data = DeblurDataset(x_train, y_train, transform)\nval_data = DeblurDataset(x_val, y_val, transform)\n \ntrainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)","ffd7c32f":"class DeblurCNN(nn.Module):\n    def __init__(self):\n        super(DeblurCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=2)\n        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=2)\n        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        #x = F.relu(self.conv3(x))\n        x = self.conv3(x)\n        return x\n\nmodel = DeblurCNN().to(device)\nprint(model)\n\n","76235390":"criterion = nn.MSELoss()\n# the optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n        optimizer,\n        mode='min',\n        patience=5,\n        factor=0.1,\n        verbose=True\n    )\n","62f70ad9":"def fit(model, dataloader, epoch):\n    model.train()\n    running_loss = 0.0\n    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)\/dataloader.batch_size)):\n        blur_image = data[0]\n        sharp_image = data[1]\n        blur_image = blur_image.to(device)\n        sharp_image = sharp_image.to(device)\n        optimizer.zero_grad()\n        outputs = model(blur_image)\n        loss = criterion(outputs, sharp_image)\n        # backpropagation\n        loss.backward()\n        # update the parameters\n        optimizer.step()\n        running_loss += loss.item()\n    train_loss = running_loss\/len(dataloader.dataset)\n    print(f\"Train Loss: {train_loss:.5f}\")\n    \n    return train_loss\n","8611f65c":"# the vakidation function\ndef validate(model, dataloader, epoch):\n    model.eval()\n    running_loss = 0.0\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)\/dataloader.batch_size)):\n            blur_image = data[0]\n            sharp_image = data[1]\n            blur_image = blur_image.to(device)\n            sharp_image = sharp_image.to(device)\n            outputs = model(blur_image)\n            loss = criterion(outputs, sharp_image)\n            running_loss += loss.item()\n\n            if epoch == 0 and i == (len(val_data)\/dataloader.batch_size)-1:\n                save_decoded_image(sharp_image.cpu().data, name=f\"saved_images_motion\/sharp{epoch}.jpg\")\n                save_decoded_image(blur_image.cpu().data, name=f\"saved_images_motion\/blur{epoch}.jpg\")\n\n        val_loss = running_loss\/len(dataloader.dataset)\n        print(f\"Val Loss: {val_loss:.5f}\")\n\n        save_decoded_image(outputs.cpu().data, name=f\"saved_images_motion\/val_deblurred{epoch}.jpg\")\n        \n        return val_loss\n","a0e272cc":"train_loss  = []\nval_loss = []\n\nfor epoch in range(60):\n    \n    print(f\"Epoch {epoch+1} of 60\")\n    train_epoch_loss = fit(model, trainloader, epoch)\n    val_epoch_loss = validate(model, valloader, epoch)\n    train_loss.append(train_epoch_loss)\n    val_loss.append(val_epoch_loss)\n    scheduler.step(val_epoch_loss)\n\n# loss plots\nplt.figure(figsize=(10, 7))\nplt.plot(train_loss, color='orange', label='train loss')\nplt.plot(val_loss, color='red', label='validataion loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('loss.png')\nplt.show()\n\n# save the model to disk\nprint('Saving model...')\ntorch.save(model.state_dict(), 'modelmotion.pth')","f4e010e9":"model.load_state_dict(torch.load('..\/input\/models\/motionblurmodel.pth'))","2592d10d":"\ndef predict_image(image):\n    image_tensor = transform(image)\n    image_tensor = image_tensor.unsqueeze_(0)\n    input = Variable(image_tensor)\n    input = input.to(device)\n    output = model(input)\n    save_decoded_image(output.cpu().data, name=\"deblurred.jpg\")\n\n    ","2e61c3f6":"psnrsandt=[]\npsnrsandb=[]\nssimsandt=[]\nfor i in range(900,910):\n    predict_image(Image.open(f\"motion_blurred\/{x_blur[i]}\"))\n    Image.open(f\"..\/input\/natural-images\/natural_images\/person\/{y_sharp[i]}\").resize((224,224)).save(\"sharp.jpg\")\n    Image.open(f\"motion_blurred\/{x_blur[i]}\").resize((224,224)).save(\"blur.jpg\")\n    psnrsandb.append(cv2.PSNR(cv2.imread(\"blur.jpg\"),cv2.imread(\"sharp.jpg\")))\n    psnrsandt.append(cv2.PSNR(cv2.imread(\"deblurred.jpg\"),cv2.imread(\"sharp.jpg\")))\n    ssimsandt.append(metrics.structural_similarity(cv2.imread(\"deblurred.jpg\"),cv2.imread(\"sharp.jpg\"),multichannel=True))","5b0a391e":"print(\"Psnr between sharp and deblurred images\")\nfor i in range(10):\n    print(\"Image{0}: {1}\".format(i+1,psnrsandt[i]))","c666a257":"print(\"Psnr between sharp and blur images\")\nfor i in range(10):\n    print(\"Image{0}: {1}\".format(i+1,psnrsandb[i]))","3aae1e48":"print(\"SSIM between sharp and deblurred images\")\nfor i in range(10):\n    print(\"Image{0}: {1}\".format(i+1,ssimsandt[i]))","ff8d9483":"os.makedirs('guassian_blurred', exist_ok=True)\nsrc_dir = '..\/input\/blur-dataset\/sharp'\nimages = os.listdir(src_dir)\ndst_dir = 'guassian_blurred'\n\nfor i, img in tqdm(enumerate(images), total=len(images)):\n    img = cv2.imread(f\"{src_dir}\/{images[i]}\")\n    # add gaussian blurring\n    blur = cv2.GaussianBlur(img, (51, 51), 0)\n   # blur=cv2.filter2D(img,-1,kernel_motion_blur)\n\n    cv2.imwrite(f\"{dst_dir}\/{images[i]}\", blur)\nprint('DONE')\n\n","be1daca0":"image_dir = 'saved_images_guassian'\nos.makedirs(image_dir, exist_ok=True)\n    \ndef save_decoded_image(img, name):\n    img = img.view(img.size(0), 3,224, 224)\n    save_image(img, name)","5fd50aae":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)\n\nbatch_size = 2\n\nmotion_blur = os.listdir('guassian_blurred')\nmotion_blur.sort()\nsharp = os.listdir('..\/input\/blur-dataset\/sharp')\nsharp.sort()\n\nx_blur = []\nfor i in range(len(motion_blur)):\n    x_blur.append(motion_blur[i])\n\ny_sharp = []\nfor i in range(len(sharp)):\n    y_sharp.append(sharp[i])\n    \nprint(x_blur[10])\nprint(y_sharp[10])\n\n(x_train, x_val, y_train, y_val) = train_test_split(x_blur[:900], y_sharp[:900], test_size=0.25)\n\nprint(len(x_train))\nprint(len(x_val))\n\n# define transforms\ntransform = transforms.Compose([\n    \n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])\n\nclass DeblurDataset(Dataset):\n    def __init__(self, blur_paths, sharp_paths=None, transforms=None):\n        self.X = blur_paths\n        self.y = sharp_paths\n        self.transforms = transforms\n         \n    def __len__(self):\n        return (len(self.X))\n    \n    def __getitem__(self, i):\n        blur_image = Image.open(f\"guassian_blurred\/{self.X[i]}\")\n        \n        if self.transforms:\n            blur_image = self.transforms(blur_image)\n            \n        if self.y is not None:\n            sharp_image = Image.open(f\"..\/input\/blur-dataset\/sharp\/{self.y[i]}\")\n            sharp_image = self.transforms(sharp_image)\n            return (blur_image, sharp_image)\n        else:\n            return blur_image\n\ntrain_data = DeblurDataset(x_train, y_train, transform)\nval_data = DeblurDataset(x_val, y_val, transform)\nprint(train_data)\n \ntrainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)","e74e5da0":"class DeblurCNN(nn.Module):\n    def __init__(self):\n        super(DeblurCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=2)\n        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=2)\n        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        #x = F.relu(self.conv3(x))\n\n        x = self.conv3(x)\n        return x\n\nmodel = DeblurCNN().to(device)\nprint(model)\n\ncriterion = nn.MSELoss()\n# the optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n        optimizer,\n        mode='min',\n        patience=5,\n        factor=0.1,\n        verbose=True\n    )\n","e65b716c":"def fit(model, dataloader, epoch):\n    model.train()\n    running_loss = 0.0\n    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)\/dataloader.batch_size)):\n        blur_image = data[0]\n        sharp_image = data[1]\n        blur_image = blur_image.to(device)\n        sharp_image = sharp_image.to(device)\n        optimizer.zero_grad()\n        outputs = model(blur_image)\n        loss = criterion(outputs, sharp_image)\n        # backpropagation\n        loss.backward()\n        # update the parameters\n        optimizer.step()\n        running_loss += loss.item()\n    \n    train_loss = running_loss\/len(dataloader.dataset)\n    print(f\"Train Loss: {train_loss:.5f}\")\n    \n    return train_loss\n# the loss function\n","628f7168":"# the training function\ndef validate(model, dataloader, epoch):\n    model.eval()\n    running_loss = 0.0\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)\/dataloader.batch_size)):\n            blur_image = data[0]\n            sharp_image = data[1]\n            blur_image = blur_image.to(device)\n            sharp_image = sharp_image.to(device)\n            outputs = model(blur_image)\n            loss = criterion(outputs, sharp_image)\n            running_loss += loss.item()\n\n            if epoch == 0 and i == (len(val_data)\/dataloader.batch_size)-1:\n                save_decoded_image(sharp_image.cpu().data, name=f\"saved_images_guassian\/sharp{epoch}.jpg\")\n                save_decoded_image(blur_image.cpu().data, name=f\"saved_images_guassian\/blur{epoch}.jpg\")\n\n        val_loss = running_loss\/len(dataloader.dataset)\n        print(f\"Val Loss: {val_loss:.5f}\")\n\n        save_decoded_image(outputs.cpu().data, name=f\"saved_images_guassian\/val_deblurred{epoch}.jpg\")\n        \n        return val_loss\n","7d0976d1":"train_loss  = []\nval_loss = []\n\nfor epoch in range(50):\n    \n    print(f\"Epoch {epoch+1} of 50\")\n    train_epoch_loss = fit(model, trainloader, epoch)\n    val_epoch_loss = validate(model, valloader, epoch)\n    train_loss.append(train_epoch_loss)\n    val_loss.append(val_epoch_loss)\n    scheduler.step(val_epoch_loss)\n\n# loss plots\nplt.figure(figsize=(10, 7))\nplt.plot(train_loss, color='orange', label='train loss')\nplt.plot(val_loss, color='red', label='validataion loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('loss.png')\nplt.show()\n\n# save the model to disk\nprint('Saving model...')\ntorch.save(model.state_dict(), 'modelguassian.pth')\n#a=model(DeblurDataset(x_blur[0]))","70ba9be0":"\ndef predict_image(image):\n    image_tensor = transform(image)\n    image_tensor = image_tensor.unsqueeze_(0)\n    input = Variable(image_tensor)\n    input = input.to(device)\n    output = model(input)\n    save_decoded_image(output.cpu().data, name=\"deblurred.jpg\")\n","9491f8d8":"psnrsandt=[]\npsnrsandb=[]\nfor i in range(10,20):\n    predict_image(Image.open(f\"guassian_blurred\/{x_val[i]}\"))\n    Image.open(f\"..\/input\/blur-dataset\/sharp\/{y_val[i]}\").resize((224,224)).save(\"sharp.jpg\")\n    Image.open(f\"guassian_blurred\/{x_val[i]}\").resize((224,224)).save(\"blur.jpg\")\n    psnrsandb.append(cv2.PSNR(cv2.imread(\"blur.jpg\"),cv2.imread(\"sharp.jpg\")))\n    psnrsandt.append(cv2.PSNR(cv2.imread(\"test.jpg\"),cv2.imread(\"sharp.jpg\")))\n    \n    ","9c5015ee":"psnrsandt","d08abf6f":"psnrsandb","ce511230":"# **For Guassian Blur**","d572bb68":"Model Code","aa005445":"Applying blur","9bc8fdd2":"Validate function","00bbc1fa":"Fitting the model","7435ffea":"Function for saving images","173e0e4a":"# **For Motion Blur**","89bc23f0":"Preparation of Dataset"}}