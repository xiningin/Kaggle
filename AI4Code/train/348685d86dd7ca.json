{"cell_type":{"dbdac3bb":"code","ffc25d39":"code","2aabb194":"code","06075e35":"code","d36d6382":"code","c2a6cfb5":"code","3b0191a4":"code","807ec468":"code","cd097c61":"code","eda0f31d":"code","fbacebdb":"code","dd31d741":"code","d5de62b2":"code","bafcc29d":"code","7b9c65dc":"code","acc471d8":"code","dd6ed468":"code","e8f67b80":"code","2f769bf7":"code","9dc6b196":"code","896c61dc":"code","b3871883":"code","3a536da5":"code","924d2b17":"code","066cbc65":"code","2f3291d1":"code","fd4dcdcc":"code","e04f84c2":"code","9f005c97":"code","e892fcd3":"code","af6ae20b":"code","b8e068dc":"code","ff88dd30":"code","bb685d23":"code","754e3ea3":"code","6be64721":"code","ad990d9f":"code","a270ec1c":"code","5226a405":"markdown","8a208875":"markdown","fa80aaef":"markdown"},"source":{"dbdac3bb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","ffc25d39":"sms = pd.read_csv(\"..\/input\/spam-filter\/SMSSpamCollection\",sep = \"\\t\",header = None,names = [\"Label\",\"Messages\"])","2aabb194":"sms.head()","06075e35":"sms.shape","d36d6382":"sms[\"Label\"].value_counts(normalize = True) * 100","c2a6cfb5":"shuffled_sms = sms.sample(frac = 1, random_state = 123, replace = True )","3b0191a4":"int(len(shuffled_sms)*.8)","807ec468":"train = shuffled_sms[:4457]\ntest = shuffled_sms[4457:]","cd097c61":"train.shape","eda0f31d":"test.shape","fbacebdb":"train.reset_index(inplace = True,drop = True)\ntest.reset_index(inplace = True,drop = True)","dd31d741":"train[\"Label\"].value_counts(normalize = True)","d5de62b2":"p_ham = train[\"Label\"].value_counts(normalize = True)[0]\np_spam = train[\"Label\"].value_counts(normalize = True)[1]","bafcc29d":"p_ham,p_spam","7b9c65dc":"train.head()","acc471d8":"train[\"Messages\"] = train[\"Messages\"].str.replace(\"\\W\",\" \").str.lower().str.split()","dd6ed468":"train.head()","e8f67b80":"vocab = []\nfor lst in train[\"Messages\"]:\n    for word in lst:\n        vocab.append(word)\n","2f769bf7":"vocab = list(set(vocab))","9dc6b196":"len(vocab)","896c61dc":"dict = {}\nfor i in vocab:\n    dict[i] = [0] * len(train)","b3871883":"train.shape","3a536da5":"train[\"Messages\"].head()","924d2b17":"for i, lst in enumerate(train[\"Messages\"]):\n    for word in lst:\n        dict[word][i] += 1","066cbc65":"pd.options.display.max_rows = None","2f3291d1":"df = pd.DataFrame(dict)","fd4dcdcc":"df.head()","e04f84c2":"df.loc[0,[\"ard\",\"4\",\"lor\"]]","9f005c97":"train_set = pd.concat([train[\"Label\"],df],axis = 1)","e892fcd3":"n_sp = train[train[\"Label\"] == \"spam\"].sum(axis = 1).sum()","af6ae20b":"n_hm = train[train[\"Label\"] == \"spam\"].sum(axis = 1).sum()","b8e068dc":"spam = train_set[train_set[\"Label\"] == \"spam\"]\nham = train_set[train_set[\"Label\"] == \"ham\"]","ff88dd30":"spam.head()","bb685d23":"spam_par = {i:0 for i in vocab}\nham_par = {i:0 for i in vocab}","754e3ea3":"for i in vocab:\n    n_wo_sp = spam[i].sum()\n    p_word_sp = (n_wo_sp + 1)\/n_sp+1*len(vocab)\n    spam_par[i] = p_word_sp","6be64721":"for i in vocab:\n    n_wo_hm = ham[i].sum()\n    p_word_hm = (n_wo_hm + 1)\/n_hm+1*len(vocab)\n    spam_par[i] = p_word_hm","ad990d9f":"import re\ndef classify(new_ms):\n    msg = re.sub(r\"\\W\",\" \",new_ms).lower().split()\n    p_msg = p_spam\n    h_msg = p_ham\n    \n    for word in msg:\n        if word in spam_par:\n            p_msg *= spam_par[word]\n            h_msg *= ham_par[word]\n        else:\n            return \"human will classify\"\n    if p_msg > h_msg:\n        return \"spam\"\n    else:\n        return \"ham\"\n    ","a270ec1c":"message = \"ador 4\"\nclassify(message)","5226a405":"training = \"80%\"\ntesting = \"20%\"","8a208875":"# Naive Bayes Algorithm Manually","fa80aaef":"P(Spam | new_msg) \u221d P(spam) * P(new_msg | spam)  \nP(Spamc | new_msg) \u221d P(spamc) * P(new_msg | Spams) "}}