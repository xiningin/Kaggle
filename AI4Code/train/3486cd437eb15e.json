{"cell_type":{"6a2d84eb":"code","31df8542":"code","232ee6ac":"code","99a6f983":"code","c20cd7b6":"code","c3a0f6b8":"code","c72895b4":"code","e5dc961a":"code","1c64e1d8":"code","a9456d03":"code","30cc6197":"code","8db290ac":"code","ed39a0dc":"code","72f25c4b":"code","b7b9a29e":"code","b4e545a6":"code","1a590616":"code","f1f60c98":"code","27b05ade":"code","adbe44cd":"code","30298be7":"code","6e6d9a4c":"markdown","fb0bac0d":"markdown","66ff14d3":"markdown","e2a13b8a":"markdown","6773fcb4":"markdown","97e3e469":"markdown","b63e1dcb":"markdown","4b1dd129":"markdown","357696c2":"markdown","167d7ebb":"markdown","c0996071":"markdown","d3ccd4db":"markdown","cb83077d":"markdown","dfb7a56e":"markdown"},"source":{"6a2d84eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","31df8542":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport shutil\nfrom shutil import copyfile\nimport random\nimport os\nimport zipfile\nprint(\"What we've Got\",os.listdir(\"..\/input\/dogs-vs-cats\"))\ninput = \"..\/input\/dogs-vs-cats\/train\"\n\n### ADDING TPU's\n# detect and init the TPU\ntpu=\"TPU v3-8\"\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","232ee6ac":"## Unzip All\nDataset = \"train\"\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/\"+Dataset+\".zip\",\"r\") as z:\n    z.extractall(\".\")","99a6f983":"def mk_categories(df,dtype):\n    os.makedirs(dtype+\"\/dogs\", exist_ok=True)\n    os.makedirs(dtype+\"\/cats\", exist_ok=True)\n    for index, row in df.iterrows():\n        filename= row['filename']\n        category = row['filename'].split('.')[0]\n        if category == 'dog':\n            copyfile(\"train\/\"+filename, dtype+\"\/dogs\/\"+filename)\n        else:\n            copyfile(\"train\/\"+filename, dtype+\"\/cats\/\"+filename)\n\nfilenames = os.listdir(\"train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\n## Make some test data out of training data\ntrain_df, test_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True) \nmk_categories(train_df,\"training\")\nmk_categories(test_df,\"test\")","c20cd7b6":"train_df['category'].value_counts().plot.bar()","c3a0f6b8":"test_df['category'].value_counts().plot.bar()","c72895b4":"sample = random.choice(filenames)\nimage = load_img(\"train\/\"+sample)\nplt.imshow(image)","e5dc961a":"def plotSnap(who,folder=\"train\/\"): \n    # plot first few images\n    for i in range(9):\n         # define subplot\n        plt.subplot(330 + 1 + i)\n        # define filename\n        filename = folder + who +'.' + str(i) + '.jpg'\n        # load image pixels\n        image = load_img(filename)\n        # plot raw pixel data\n        plt.imshow(image)","1c64e1d8":"plotSnap(\"dog\")\n    \n# show the figure\nplt.show()","a9456d03":"plotSnap(\"cat\")\n    \n# show the figure\nplt.show()","30cc6197":"def plotPreview(who,folder=\"preview\/\"): \n    i=1\n    # plot first few images\n    for file in os.listdir(folder):\n         # define subplot\n        plt.subplot(8,8,i)\n        i=i+1\n        filename = folder + file\n        image = load_img(filename)\n        plt.imshow(image)\n        if i>20:\n            break\n\nif not os.path.exists(\"preview\"):\n    os.mkdir(\"preview\")\n    \ndatagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\nimg = load_img('train\/cat.0.jpg')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\nx = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview\/` directory\ni = 0\nfor batch in datagen.flow(x, batch_size=1,save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n    i += 1\n    if i > 20:\n        break  # otherwise the generator would loop indefinitely\n        \nplotPreview(\"cat\")\nplt.show()","8db290ac":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n# create convnet model\ndef build_model(type=\"covnet\"):\n    with strategy.scope():\n        if type == \"covnet\":\n            model = Sequential()\n            model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Dropout(0.2))\n            model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Dropout(0.2))\n            model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Dropout(0.2))\n            model.add(Flatten())\n            model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n            model.add(Dropout(0.5))\n            model.add(Dense(1, activation='sigmoid'))\n            opt = SGD(lr=0.001, momentum=0.9)\n            model.compile(loss='binary_crossentropy',\n                          optimizer='rmsprop',\n                          metrics=['accuracy'])\n        if type == \"VGG16\":\n            model = VGG16(include_top=False, input_shape=(224, 224, 3))\n            for layer in model.layers:\n                layer.trainable = False\n            flat1 = Flatten()(model.layers[-1].output)\n            class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n            output = Dense(1, activation='sigmoid')(class1)\n            model = Model(inputs=model.inputs, outputs=output)\n            opt = SGD(lr=0.001, momentum=0.9)\n            model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n\nimport tensorflow as tf\nimport keras.backend.tensorflow_backend as tfback\nprint(\"tf.__version__ is\", tf.__version__)\nprint(\"tf.keras.__version__ is:\", tf.keras.__version__)\n\ndef _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    #global _LOCAL_DEVICES\n    if tfback._LOCAL_DEVICES is None:\n        devices = tf.config.list_logical_devices()\n        tfback._LOCAL_DEVICES = [x.name for x in devices]\n    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n\ntfback._get_available_gpus = _get_available_gpus","ed39a0dc":"## Unzip All test\nDataset = \"test1\"\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/\"+Dataset+\".zip\",\"r\") as z:\n    z.extractall(\".\")\n","72f25c4b":"def plot_summaries(model):\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(model.history['loss'], color='blue', label='train')\n    plt.plot(model.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    plt.subplot(212)\n    plt.title('Classification Accuracy')\n    plt.plot(model.history['accuracy'], color='blue', label='train')\n    plt.plot(model.history['val_accuracy'], color='orange', label='test')\n    plt.show()\n \n# Run Train and eval Model \ndef run_train_eval(savepoint=\"savepoint.h5\",type=\"covnet\"):\n    batch_size=16 * strategy.num_replicas_in_sync\n    if type==\"covnet\":\n        size = 200\n    else:\n        size = 224\n    # this is the augmentation configuration we will use for training\n    train_datagen = ImageDataGenerator(\n            rescale=1.\/255,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True)\n\n    # this is the augmentation configuration we will use for testing:\n    # only rescaling\n    test_datagen = ImageDataGenerator(rescale=1.\/255)\n\n    # this is a generator that will read pictures found in\n    # subfolers of 'data\/train', and indefinitely generate\n    # batches of augmented image data\n    train_generator = train_datagen.flow_from_directory(\n            '\/kaggle\/working\/training\/',  # this is the target directory\n            target_size=(size, size),  # all images will be resized to 150x150\n            batch_size=batch_size,\n            class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n\n    # this is a similar generator, for validation data\n    validation_generator = test_datagen.flow_from_directory(\n            '\/kaggle\/working\/test\/',\n            target_size=(size, size),\n            batch_size=batch_size,\n            class_mode='binary')\n    model = build_model(type=type)\n    fit = model.fit_generator(\n            train_generator,\n            steps_per_epoch=2000\/\/ batch_size,\n            epochs=50,\n            validation_data=validation_generator,\n            validation_steps=800 \/\/ batch_size\n    )\n    model.save_weights(savepoint)\n    # evaluate model\n    _, acc = model.evaluate_generator(validation_generator, steps=len(validation_generator), verbose=0)\n    display('> %.3f' % (acc * 100.0))\n    plot_summaries(fit)\n    return (model,fit)","b7b9a29e":"#model = run_train_eval()","b4e545a6":"modelVGG = run_train_eval(savepoint=\"vgg.h5\",type=\"VGG16\")","1a590616":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import load_model\n \n# load and prepare the image\ndef load_image(filename,imgSize =224):\n    img = load_img(filename, target_size=(imgSize, imgSize))\n    img = img_to_array(img)\n    img = img.reshape(1, imgSize, imgSize, 3)\n    img = img.astype('float32')\n    img = img - [123.68, 116.779, 103.939]\n    return img\n \n# load an image and predict the class\ndef predict_img(img):\n    # load the image\n    img = load_image(img)\n    # load model\n    model = build_model(type=\"VGG16\")\n    model.load_weights('vgg.h5')\n    # predict the class\n    result = model.predict(img)\n    return result[0]\n\ndef predict_img(img):\n    # load the image\n    img = load_image(img)\n    # load model\n    model = build_model(type=\"VGG16\")\n    model.load_weights('vgg.h5')\n    # predict the class\n    result = model.predict(img)\n    return result[0]","f1f60c98":"load_img(\"test1\/5853.jpg\") ","27b05ade":"val = predict_img(\"test1\/5853.jpg\") \nprint(val[0])\nif val[0]== 1:\n    print(\"Found A Dog !\")\nelse:\n    print(\"Found A Cat ! \")","adbe44cd":"filenames = os.listdir(\"test1\") \nids =[]\nlabels =[]\ni =1 \nplt.figure(figsize=(12, 24))\nmodel = build_model(type=\"VGG16\")\nmodel.load_weights('vgg.h5')\nfor filename in filenames:\n    id = filename.split('.')[0]\n    ids.append(id)\n    img=\"test1\/\"+filename\n    truncImg = load_image(img)\n    lbl = model.predict(truncImg) \n    labels.append(int(round(lbl[0][0])))\n    # Plot few samples\n    if i <= 5:\n        plt.subplot(6, 3, i+1)\n        plt.imshow(load_img(\"test1\/\"+filename))\n        plt.xlabel('%s > %f' % (id,int(round(lbl[0][0]))))\n        plt.show()\n        #display('%s > %f' % (id,lbl))\n    i = i+1\n\n  ","30298be7":"## remode dirs\ndef deldir(dirPath):\n    try:\n        print(\"Removing Directory\",dirPath) \n        shutil.rmtree(dirPath)\n    except:\n        print('Error while deleting directory')\ndeldir(\"train\")\ndeldir(\"training\")\ndeldir(\"test1\")\ndeldir(\"test\")\ndeldir(\"preview\")\n\n## create submission file\nsubmission_df = pd.DataFrame({\n    'id': ids,\n    'label': labels\n})\ndisplay(submission_df.head())\nsubmission_df.to_csv('submission.csv', index=False)  ","6e6d9a4c":"# Data prep","fb0bac0d":"# Import Stuff and TPU's","66ff14d3":"# PLot a snapshot ","e2a13b8a":"# The Model","6773fcb4":"# Lets let the dogs out","97e3e469":"# Data Preprocessing","b63e1dcb":"check augmenting existing data to generate scenarios","4b1dd129":"# Test with covnet","357696c2":"folder = 'train\/'\nphotos, labels = list(), list()\n# enumerate files in the directory\nfor file in os.listdir(folder):\n    # determine class\n    output = 0.0\n    if file.startswith('cat'):\n        output = 1.0\n    # load image\n    photo = load_img(folder + file, target_size=(200, 200))\n    # convert to numpy array\n    photo = img_to_array(photo)\n    # store\n    photos.append(photo)\n    labels.append(output)\n# convert to a numpy arrays\nphotos = np.asarray(photos)\nlabels = np.asarray(labels)\nprint(photos.shape, labels.shape)\n# save the reshaped photos\nsave('dogs_vs_cats_photos.npy', photos)\nsave('dogs_vs_cats_labels.npy', labels)","167d7ebb":"# Create Submission","c0996071":"# Hmm so many different pictures :|","d3ccd4db":"# See if predictions work","cb83077d":"# Check with VGG :)","dfb7a56e":"# Lets see some cat pics"}}