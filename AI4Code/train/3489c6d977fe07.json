{"cell_type":{"bd7e8f22":"code","87f158f0":"code","91ea81b6":"code","6e7e0b1a":"code","fae84060":"code","d9cb461b":"code","6fba4312":"code","fda7fda7":"code","269ee2b9":"code","550fe436":"code","fbc835b0":"code","485edf83":"code","66243457":"code","f2f28d77":"code","2b08fd81":"code","58801b0c":"code","88eb9546":"code","846335ed":"code","7987d10d":"markdown","985b1b66":"markdown","d5ae462c":"markdown","d96041ab":"markdown","a3161fbe":"markdown","01f9b9dc":"markdown"},"source":{"bd7e8f22":"import torch\nimport torchvision\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader\nimport torchvision.models as models\n\n\nimport numpy as np\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom pathlib import Path\nimport os\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","87f158f0":"LEARNING_RATE = 1e-4\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 32\nNUM_EPOCHS = 20\nNUM_WORKERS = 2\nIMAGE_HEIGHT = 160 \nIMAGE_WIDTH = 240 \nPIN_MEMORY = True\nLOAD_MODEL = False\nroot_dir = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'","91ea81b6":"path = Path(root_dir)\npath_images = list(path.glob('**\/*'))\nextensions = set()\nfor name in path_images:\n    if len(os.path.split(name)[1].split('.')) > 1:\n        extensions.add(os.path.split(name)[1].split('.')[1])\nprint(f'Extensions in root directory : {extensions}')","6e7e0b1a":"path = Path(root_dir)\npath_images = list(path.glob('**\/*.png'))\n\nimages_paths = [str(path_image) for path_image in path_images if 'GT' not in str(path_image)]\nprint(f'Number of training images :{len(images_paths)}')\n\nlabels = [os.path.split(os.path.split(name)[0])[1] for name in images_paths]\nprint(f'Number of labels :{len(labels)}')\n\nclasses = list(set(labels))\nlabels_str_to_int = {label : i for i,label in enumerate(classes)}\nlabels_int = [labels_str_to_int[str_label] for str_label in labels]# Convert string labels to int format","fae84060":"data , test_data, labels, test_labels = train_test_split(images_paths, labels_int, test_size=0.1, shuffle=True)#Split data for train and for test\ntrain_data , val_data, train_labels, val_labels = train_test_split(data, labels, test_size=0.1, shuffle=True)#Split train data for train and validation","d9cb461b":"class FishDataset(torch.utils.data.Dataset):\n    def __init__(self, images : list, labels : list, transform=None):\n        super().__init__() \n        self.images = images\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__(self, ):\n        return len(self.labels)\n        \n    def __getitem__(self, index):\n        input_image = self.images[index]\n        label = self.labels[index]\n\n        image = np.array(Image.open(input_image).convert(\"RGB\"))\n\n        if self.transform is not None:\n            augmentations = self.transform(image=image)\n            image = augmentations[\"image\"]\n\n        return image, label    ","6fba4312":"train_transform = A.Compose(\n    [\n        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n        A.Rotate(limit=35, p=1.0),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.1),\n        A.Normalize(\n            mean=[0.0, 0.0, 0.0],\n            std=[1.0, 1.0, 1.0],\n            max_pixel_value=255.0,\n        ),\n        ToTensorV2(),\n    ],\n)\n\nval_transforms = A.Compose(\n    [\n        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n        A.Normalize(\n            mean=[0.0, 0.0, 0.0],\n            std=[1.0, 1.0, 1.0],\n            max_pixel_value=255.0,\n        ),\n        ToTensorV2(),\n    ],\n)","fda7fda7":"def get_loaders(\n    train_data , \n    val_data, \n    train_labels, \n    val_labels,\n    test_data,\n    test_labels,\n    batch_size,\n    train_transform,\n    test_transform,\n    num_workers=4,\n    pin_memory=True,\n):\n    train_ds = FishDataset(\n        images=train_data,\n        labels=train_labels,\n        transform=train_transform,\n    )\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=True,\n    )\n\n    val_ds = FishDataset(\n        images=val_data,\n        labels=val_labels,\n        transform=test_transform,\n    )\n\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=False,\n    )\n    \n    test_ds = FishDataset(\n        images=test_data,\n        labels=test_labels,\n        transform=test_transform,\n    )\n\n    test_loader = DataLoader(\n        test_ds,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        shuffle=False,\n    )\n\n    return train_loader, val_loader, test_loader","269ee2b9":"train_loader, val_loader, test_loader = get_loaders(    \n                                                    train_data , \n                                                    val_data, \n                                                    train_labels, \n                                                    val_labels,\n                                                    test_data,\n                                                    test_labels, \n                                                    BATCH_SIZE, \n                                                    train_transform, \n                                                    val_transforms)","550fe436":"labels_dic = {i : label for i,label in enumerate(classes)}\ndef show_batch(loader, batch_size, labels_dic):\n    rows_number = 1\n    cols_number = 2\n    if batch_size > 2:\n        cols_number = 4\n        rows_number = batch_size\/\/cols_number\n        \n    fig = plt.figure(figsize=(48, 30))\n    images,labels = next(iter(loader))\n    for i,data in enumerate(images,1):\n        ax = fig.add_subplot(rows_number, cols_number, i)\n        plt.imshow(data.permute(1,2,0).numpy())\n        ax.set_title(labels_dic[labels[i-1].item()])\n    plt.show()","fbc835b0":"show_batch(train_loader, BATCH_SIZE, labels_dic)# We want to look at the data","485edf83":"#'''\nmodel = models.resnet101(pretrained=True)\nfor params in model.parameters():\n    params.requires_grad = False\n    \nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, 9)\n\nmodel = model.to(DEVICE)\n#'''","66243457":"\"\"\"\"\nmobilenet_v2 = models.mobilenet_v2()\nmobilenet_v2.classifier = torch.nn.Sequential(\n                torch.nn.Dropout(p=0.2, inplace=False),\n                torch.nn.Linear(in_features=1280, out_features=len(classes), bias=True))\nmodel = mobilenet_v2.to(DEVICE)\n\"\"\"","f2f28d77":"optimizer = torch.optim.Adam(model.parameters())\nloss_fn = torch.nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=2)","2b08fd81":"import os\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom catalyst import dl, utils\n\nloaders = {\n    \"train\": train_loader,\n    \"valid\": val_loader,\n}\n\n\nrunner = dl.SupervisedRunner(\n    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n)\n# model training\nrunner.train(\n    model=model,\n    criterion=loss_fn,\n    optimizer=optimizer,\n    loaders=loaders,\n    scheduler=scheduler,\n    num_epochs=NUM_EPOCHS,\n    callbacks=[\n        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk_args=(1, 3)),\n        dl.EarlyStoppingCallback(\n            patience=4, loader_key=\"valid\", metric_key=\"loss\", minimize=True),\n        ],\n    logdir=\".\/logs\",\n    valid_loader=\"valid\",\n    valid_metric=\"loss\",\n    minimize_valid_metric=True,\n    verbose=True,\n    load_best_on_end=True,\n)","58801b0c":"def eval_accuracy(loader):  \n    model.eval()\n    corrects = 0\n    total = 0\n    for images, labels in loader:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        predictions = model(images)\n        predict = torch.max(predictions.data, 1)[1].to(DEVICE)\n        total += len(labels)\n        corrects += (predict == labels).sum()\n    accuracy = 100 * corrects \/ float(total)\n    return accuracy","88eb9546":"print(f' Accuracy on validation images: {eval_accuracy(val_loader)}')\nprint(f' Accuracy on train images: {eval_accuracy(train_loader)}')\nprint(f' Accuracy on test images: {eval_accuracy(test_loader)}')","846335ed":"model.cuda()\ndata = next(iter(loaders[\"valid\"]))\nbatch_prediciton = runner.predict_batch(data)\nmodel.eval()\n# which would be the same with\nbatch_model_prediciton = model(data[0].cuda())\nbatch_prediciton['logits'] == batch_model_prediciton","7987d10d":"1. Make Dataset\n2. Make dataloader\n3. Define model,optim,loss,\n4. Make train loop\n5. Test results","985b1b66":"# 2)Define hyperparameters","d5ae462c":"# 1) Import libraries","d96041ab":"# 5) Test stage","a3161fbe":"# 4) Training stage","01f9b9dc":"# 3) Prepare data"}}