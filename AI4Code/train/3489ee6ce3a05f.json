{"cell_type":{"68b2b6a1":"code","7cc03112":"code","6ec435c8":"code","e9366699":"code","b24c7cd9":"code","94180367":"code","80dd9b45":"code","542e6161":"code","31ce3927":"code","7bd624ba":"code","20c7a320":"code","3cb58f89":"code","d2011a92":"code","1f8d1abb":"code","f4697fb7":"code","f9635892":"code","b4de7a26":"code","e9577838":"code","8f7f6ac8":"code","8aaa0e57":"code","027b1ae9":"code","8c3a4175":"code","7dbcb0a6":"code","fa92294a":"code","53dfe2fd":"code","2c26d25d":"code","efed0ae5":"code","28cfa717":"code","f92ccda4":"code","890ab927":"code","b98d6f60":"code","2649006d":"code","8a021f8e":"code","84b293e0":"code","968c64ce":"code","30ad0ad6":"code","03a11e05":"code","709f340c":"code","833ecbfd":"code","fb37d594":"code","fc1865f1":"code","e45810b1":"code","19e889d8":"code","294a9f20":"code","897837f6":"code","0aa03134":"code","e339c9a4":"code","a60796f4":"code","3f6daa14":"code","27a2130d":"code","45c37c78":"code","accd09f5":"code","9941bce8":"code","fe66f507":"code","e6b1271e":"code","9aed2b5b":"code","797054fb":"code","8da033b6":"code","9545dcf1":"code","29567b1f":"code","2eeb231f":"code","7a618193":"code","e428e6f7":"code","573d1d4e":"code","53d249ab":"code","6e4d9165":"code","2c1a15a9":"code","46956470":"code","5b37ebf9":"code","f02a6a09":"code","8b94d5de":"code","3540f32d":"code","7d294d8b":"code","cbc7218d":"code","9c0994f7":"code","78d1ddd1":"markdown","8a813ee0":"markdown","e360fff0":"markdown","a207fb8a":"markdown","c20067ce":"markdown","a8bbbcf0":"markdown","c3c578fd":"markdown","2daab393":"markdown","6546c9ba":"markdown","37f600aa":"markdown","3168fe33":"markdown","08637980":"markdown","6aca2098":"markdown","f1958e4a":"markdown","c980987a":"markdown","9c3ffaa8":"markdown","44a52584":"markdown","f850b8c3":"markdown","0bf5cc37":"markdown","766e2b03":"markdown","6e49e01e":"markdown","7934ac9a":"markdown","8dbfaaa9":"markdown","ae22f7f2":"markdown","3892bfed":"markdown","1c577908":"markdown","a452c96e":"markdown","c4f7fe71":"markdown","fb60acc7":"markdown","bcc82279":"markdown","c7208cbc":"markdown","1f4e1342":"markdown","887e9b4c":"markdown","2af7e0cd":"markdown","588064b3":"markdown","10639334":"markdown","a87ca999":"markdown","d6758019":"markdown","234fa6fa":"markdown","eb606592":"markdown","bd9d8e8e":"markdown","33b0db3c":"markdown","c6886d23":"markdown","b71db7d4":"markdown","e2a72a87":"markdown","c737cb50":"markdown","125a852a":"markdown","9329fb51":"markdown","cc52ed8d":"markdown","a9123c73":"markdown","7604a600":"markdown","2d2f1259":"markdown","fb4da3cc":"markdown","5e6a9fee":"markdown","8387b8e8":"markdown","44ea6244":"markdown","03a565bc":"markdown","1ce9a54d":"markdown","5b70be4c":"markdown","dc241f7a":"markdown","eef6d03e":"markdown","7eae31b3":"markdown","2b83645a":"markdown","6f4615b5":"markdown","fc4c13eb":"markdown","91214640":"markdown","a6329d22":"markdown","58a4907b":"markdown","46e987cc":"markdown","9bc23203":"markdown","1cabade3":"markdown","6ee6a4a6":"markdown","c881d258":"markdown","9766a88f":"markdown","51e846cd":"markdown","d98642f6":"markdown"},"source":{"68b2b6a1":"!pip install catboost\n!pip install category_encoders\n!pip install scikit-plot","7cc03112":"# Importing needed lib's\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nfrom scipy.stats import zscore\n\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.utils import class_weight\n\nfrom scikitplot.plotters import plot_roc_curve, plot_precision_recall_curve\n\nimport category_encoders as ce","6ec435c8":"accepted = pd.read_csv(\"\/kaggle\/input\/lending-club\/accepted_2007_to_2018q4.csv\/accepted_2007_to_2018Q4.csv\")","e9366699":"accepted.shape","b24c7cd9":"accepted.info()","94180367":"accepted.sample(5)","80dd9b45":"accepted.loan_status.value_counts()","542e6161":"accepted = accepted[accepted.loan_status.isin(['Fully Paid', 'Charged Off'])]\naccepted.shape","31ce3927":"issue_date = pd.to_datetime(accepted['issue_d']).dt.year\nissues_by_year = issue_date.groupby(issue_date).count()\nissues_by_year","7bd624ba":"df = accepted[issue_date.isin([2013])]\ndf.shape","20c7a320":"plt.figure(figsize=(8,6))\nplt.pie(df.loan_status.value_counts(), labels=df.loan_status.unique(),\n        explode=(0, 0.2), autopct='%1.2f%%', shadow=True, textprops={'fontsize': 14});","3cb58f89":"df['Target'] = df.loan_status.map({'Fully Paid' : 0, 'Charged Off': 1})\ndf.drop(['loan_status'], axis=1, inplace=True, errors='ignore')","d2011a92":"del accepted","1f8d1abb":"df_full = df.copy()","f4697fb7":"plt.figure(figsize=(8,5))\n(df.isna().sum() \/ df.shape[0]).hist(bins=20)\nplt.title('Histogram of Feature Incompleteness')\nplt.xlabel('Fraction of data missing')\nplt.ylabel('Feature count');","f9635892":"df.dropna(axis=1, thresh = 0.8*df.shape[0], inplace=True)","b4de7a26":"null_var_col =  list((df.std() == 0).index[(df.std() == 0)]) + list(df.describe(include=['object']).T.query('unique == 1').index)\ndf[null_var_col].head(3)","e9577838":"df.drop(columns=null_var_col, inplace=True, errors='ignore')","8f7f6ac8":"useless_cols = ['id', 'url', 'issue_d', 'title', 'zip_code', 'debt_settlement_flag', 'emp_title',\n                'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee',\n                'last_fico_range_high', 'last_fico_range_low', 'addr_state', 'funded_amnt', 'funded_amnt_inv']\ndf[useless_cols].sample(2)","8aaa0e57":"df.drop(columns=useless_cols, inplace=True, errors='ignore')","027b1ae9":"cat_cols = df.dtypes[df.dtypes == 'object'].index\nnum_cols = df.dtypes[~(df.dtypes == 'object')].index","8c3a4175":"# Import library for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif.sort_values(by=['VIF'], ascending=False))\n\nvif = calc_vif(df[num_cols].fillna(df[num_cols].mean()).iloc[:,:-1])","7dbcb0a6":"multicol = vif.head(23)['variables']\nplt.figure(figsize=(15,12))\ncmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)# plot heatmap\nmask = np.zeros_like(df[multicol].corr())\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(df[multicol].corr(), cmap=cmap, mask=mask, annot=True, fmt=\".2f\", square=True);","fa92294a":"df['fico_range'] = 0.5*df['fico_range_high'] + 0.5*df['fico_range_low']","53dfe2fd":"fig, axes = plt.subplots(2,3, figsize=(13,7), sharey=True);\nfeatures = ['total_acc', 'num_actv_rev_tl', 'num_rev_tl_bal_gt_0', 'num_rev_accts', 'num_op_rev_tl', 'num_bc_sats']\nfor i, axis in enumerate(axes.flat):\n    feature = df[features[i]]\n    axis.scatter(feature, df['num_sats'], s=0.3)\n    axis.set_xlabel(features[i])\n    axis.set_ylabel('num_sats')\nplt.tight_layout()","2c26d25d":"df.drop(['total_acc', 'num_actv_rev_tl', 'num_rev_tl_bal_gt_0', 'num_rev_accts', 'num_op_rev_tl', 'num_bc_sats'], axis=1, inplace=True, errors='ignore')","efed0ae5":"fig = plt.figure(figsize=(20,4))\nax = fig.add_subplot(1,4,1)\nax.scatter(df.tot_hi_cred_lim, df.tot_cur_bal, s=0.3)\nax.set_xlabel('tot_hi_cred_lim')\nax.set_ylabel('tot_cur_bal')\nax = fig.add_subplot(1,4,2)\nax.scatter(df.fico_range_low, df.fico_range_high,  s=0.3)\nax.set_xlabel('loan_amnt')\nax.set_ylabel('installment')\nax = fig.add_subplot(1,4,3)\nax.scatter(df.installment, df.loan_amnt,  s=0.3)\nax.set_xlabel('bc_util')\nax.set_ylabel('recol_util')\nax = fig.add_subplot(1,4,4)\nax.scatter(df.installment, df.loan_amnt,  s=0.3)\nax.set_xlabel('total_il_high_credit_lim')\nax.set_ylabel('total_bal_ex_mort')\nplt.show()","28cfa717":"df.drop(['tot_hi_cred_lim',  'installment', 'revol_util', 'total_bal_ex_mort'], axis=1, inplace=True)","f92ccda4":"df.shape","890ab927":"cor_tar = df.iloc[:, :-1].corrwith(df['Target']).abs().sort_values(ascending=False).head(10)[1:]\nplt.figure(figsize=(10,6))\nbar = sns.barplot(cor_tar, cor_tar.index, )\nfor p in bar.patches:\n    width = p.get_width()    # get bar length\n    bar.text(width,  # set the text at bar\n            p.get_y() + p.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n            '{:1.2f}'.format(width), # set variable to display, 2 decimals\n            ha = 'left',   # horizontal alignment\n            va = 'center')  # vertical alignment","b98d6f60":"df.groupby(['Target'])['recoveries'].describe()","2649006d":"df.groupby(['Target'])['collection_recovery_fee'].describe()","8a021f8e":"df.groupby(['Target'])['last_pymnt_amnt'].describe()","84b293e0":"df.groupby(['Target'])['int_rate'].describe()","968c64ce":"df.drop(['recoveries',  'collection_recovery_fee', 'last_pymnt_amnt'], axis=1, inplace=True)","30ad0ad6":"df[cat_cols].sample(5)","03a11e05":"df.drop(['last_pymnt_d', 'last_credit_pull_d', 'earliest_cr_line'], axis=1, inplace=True, errors='ignore')","709f340c":"df_before_eda = df.copy()","833ecbfd":"df.sample(5)","fb37d594":"sns.boxplot(x=df.loan_amnt, y=df.Target.astype(str))\ndf.groupby(['Target'])['loan_amnt'].describe()","fc1865f1":"fig, ax = plt.subplots(1,2, figsize=(13,5))\nsns.histplot(df.query('Target == 0')['loan_amnt'], bins=30, ax=ax[0])\nsns.histplot(df.query('Target == 1')['loan_amnt'], bins=30, color='orange', ax=ax[1]);","e45810b1":"plt.figure(figsize=(12,5))\nsns.boxplot(x=df.annual_inc, y=df.Target.astype(str))\ndf.groupby(['Target'])['annual_inc'].describe()","19e889d8":"df['log_income'] = np.log(df.annual_inc)\nplt.figure(figsize=(12,5))\nsns.boxplot(x=df.log_income, y=df.Target.astype(str))\ndf.groupby(['Target'])['log_income'].describe()","294a9f20":"fig, ax = plt.subplots(1,2, figsize=(13,5))\nsns.histplot(np.log(df.query('Target == 0').log_income), bins=100, ax=ax[0])\nsns.histplot(np.log(df.query('Target == 1').log_income), bins=100, color='orange', ax=ax[1])","897837f6":"df.drop(columns=['annual_inc'], inplace=True)","0aa03134":"sns.catplot(data=df, x='Target', kind='count', col='term', height=5, sharey=False);","e339c9a4":"sns.boxplot(x=df.int_rate, y=df.Target.astype(str))\ndf.groupby(['Target'])['int_rate'].describe()","a60796f4":"fig, ax = plt.subplots(1,2, figsize=(13,5))\n\nsns.histplot(df.query('Target == 0').int_rate, bins=100, ax=ax[0])\nsns.histplot(df.query('Target == 1').int_rate, bins=100, color='orange', ax=ax[1])\n","3f6daa14":"plt.figure(figsize=(7,4))\nsns.barplot(x='grade', y='Target', data=df, \n                  order=sorted(list(df.grade.unique())), palette='gist_rainbow')","27a2130d":"plt.figure(figsize=(14,4))\nsns.barplot(x='sub_grade', y='Target', data=df, \n                  order=sorted(list(df.sub_grade.unique())), palette='rainbow_r')","45c37c78":"subgrade_to_int = dict(zip(\n    sorted(list(df.sub_grade.unique())),\n    range(1,len(df.sub_grade.unique()))\n))\ndf['Subgrade_num'] = df['sub_grade'].map(subgrade_to_int)\ndf.drop(columns=['grade', 'sub_grade'], inplace=True, errors='ignore')","accd09f5":"sns.boxplot(x=df.Subgrade_num, y=df.Target.astype(str))\ndf.groupby(['Target'])['Subgrade_num'].describe()","9941bce8":"fig, ax = plt.subplots(1,2, figsize=(13,5))\n\nsns.histplot(df.query('Target == 0').Subgrade_num, bins=35, ax=ax[0])\nsns.histplot(df.query('Target == 1').Subgrade_num, bins=35, color='orange', ax=ax[1])","fe66f507":"plt.figure(figsize=(7,5))\nsns.barplot(x='home_ownership', y='Target', data=df)\ndf['home_ownership'].value_counts().to_frame().T","e6b1271e":"df['purpose'].value_counts().to_frame().T","9aed2b5b":"plt.figure(figsize=(16,6))\nsns.barplot(x='purpose', y='Target', data=df, palette='Set3')\nplt.xticks(rotation=45)\ndf['purpose'].value_counts().to_frame().T","797054fb":"plt.figure(figsize=(11,6))\nsns.barplot(x='pub_rec_bankruptcies', y='Target', ci=None, data=df, palette='tab10')\ndf['pub_rec_bankruptcies'].value_counts().to_frame().T","8da033b6":"plt.figure(figsize=(8,5))\nsns.barplot(x='verification_status', y='Target', ci=None, data=df, palette='tab10')\ndf['verification_status'].value_counts().to_frame().T","9545dcf1":"def preprocessing_boost(data):\n\n  cat_features = list(data.dtypes[data.dtypes == 'object'].index)\n  num_features = list(data.dtypes[~(data.dtypes == 'object')].index)\n\n  numeric_transformer = Pipeline(steps=[\n      ('imputer', SimpleImputer(strategy='mean'))]) \n\n  categor_transformer = Pipeline(steps=[\n      ('imputer', SimpleImputer(strategy='constant'))])\n\n  preprocessor = ColumnTransformer(transformers=[\n      ('numeric_transformer', numeric_transformer, num_features),\n      ('categor_transformer', categor_transformer, cat_features)])\n  \n  data_bst = pd.DataFrame(preprocessor.fit_transform(data), columns=num_features+cat_features)\n  \n  return data_bst, cat_features","29567b1f":"def preprocessing_ohe(data):\n\n  cat_features = list(data.dtypes[data.dtypes == 'object'].index)\n  num_features = list(data.dtypes[~(data.dtypes == 'object')].index)\n\n  \n  numeric_transformer = Pipeline(steps=[\n      ('imputer', SimpleImputer(strategy='mean')),\n      ('scaler', StandardScaler())]) \n\n  \n  data[cat_features].fillna('missing_value', inplace=True)\n  ohe = ce.OneHotEncoder(return_df=True, use_cat_names=True)\n\n  num_data = pd.DataFrame(numeric_transformer.fit_transform(data[num_features]), columns=num_features, index=data.index)\n  cat_data = ohe.fit_transform(data[cat_features])\n  \n  data_ohe = pd.concat([num_data, cat_data], axis=1, ignore_index=True)\n  data_ohe.columns = list(num_data.columns) + list(cat_data.columns)\n  \n  return data_ohe","2eeb231f":"X_ohe = preprocessing_ohe(df.drop(columns='Target'))\nX_cbt, cat_features = preprocessing_boost(df.drop(columns='Target'))\ny = np.array(df['Target'])","7a618193":"from sklearn.linear_model import LogisticRegression, LogisticRegressionCV,  SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","e428e6f7":"SKFold = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)","573d1d4e":"classifiers = [\n               ('Logistic Regression', LogisticRegression(class_weight='balanced')),\n               ('SGDClassifier', SGDClassifier(class_weight='balanced')),\n               ('LinearSVC', CalibratedClassifierCV(base_estimator = LinearSVC(class_weight='balanced'))),\n               ('Random Forest', RandomForestClassifier(class_weight='balanced')),\n               ('Ada Boost', AdaBoostClassifier( )),\n               ('LightGBM', LGBMClassifier(class_weight='balanced'))\n]","53d249ab":"%%time\nresults = []\nfor clf in classifiers:\n  model = clf[1]\n  cvs = cross_val_score(model, X_ohe, y, scoring='roc_auc', cv=SKFold, n_jobs=-1)\n  results.append([clf[0], cvs.mean(), cvs.std()])\n  print(f'ROC_AUC-score of model {clf[0]} is mean {cvs.mean()} with {cvs.std()} standard deviation.')","6e4d9165":"classes = class_weight.compute_sample_weight('balanced', np.unique(y), y)\nclasses","2c1a15a9":"cb = CatBoostClassifier(eval_metric = 'AUC', cat_features = cat_features,  verbose=False, class_weights=classes)\ncvs = cross_val_score(cb, X_cbt, y, scoring='roc_auc', cv=SKFold)\nresults.append(['Catboost', cvs.mean(), cvs.std()])\nprint(f'ROC_AUC-score of Catboost is mean {cvs.mean()} with {cvs.std()} standard deviation.')","46956470":"pd.DataFrame(results, columns=['model', 'mean', 'std']).sort_values(by='mean', ascending=False)","5b37ebf9":"logreg = LogisticRegressionCV(Cs=[0.001, 0.01, 0.1, 1], cv=SKFold, scoring='roc_auc', n_jobs=-1, verbose=1,)\nlogreg.fit(X_ohe, y)","f02a6a09":"print(f'The best value of regularization strength is {logreg.Cs[np.argmax(logreg.scores_[1].mean(axis=0))]} ' \nf'with the mean roc_auc-score of {max(logreg.scores_[1].mean(axis=0)).round(5)}')","8b94d5de":"params = {'learning_rate' : [0.05, 0.1],\n         'l2_leaf_reg': [5,7],\n         'depth': [3,8],\n         'loss_function': ['Logloss'],\n         'iterations': [500]}\ncb = CatBoostClassifier(eval_metric = 'AUC', cat_features = cat_features, class_weights=classes, verbose=0)\ncb_model = GridSearchCV(cb, params, scoring=\"roc_auc\", cv = SKFold,  \n                        n_jobs=-1, verbose=0)\ncb_model.fit(X_cbt, y)\nprint('The best parameters of Catboost Classifier after Model Tuning are \\n', cb_model.best_params_, sep='')\nprint()\nprint('Best score for Catboost Classifier is',cb_model.best_score_)\ncb_best = cb_model.best_estimator_","3540f32d":"X_train_cbt, X_test_cbt, y_train_cbt, y_test_cbt = train_test_split(X_cbt, y, test_size=0.25, stratify=y, random_state=28)","7d294d8b":"cb_best.fit(X_train_cbt, y_train_cbt, eval_set=(X_test_cbt, y_test_cbt), early_stopping_rounds=20, verbose=0)\npred = cb_best.predict_proba(X_test_cbt)\nprint('roc_auc_score on testing set is', roc_auc_score(y_test_cbt, pred[:,1]))","cbc7218d":"fig, ax = plt.subplots(1,2, figsize=(18,7))\nplot_roc_curve(y_test_cbt, pred, title_fontsize='large', curves=('each_class', 'macro'),  text_fontsize='medium', cmap='Set1', ax=ax[0])\nplot_precision_recall_curve(y_test_cbt, pred, title_fontsize='large',  text_fontsize='medium', cmap='Set2', ax=ax[1]);","9c0994f7":"fig, axes = plt.subplots(1,2, figsize=(15,11))\nfeat_imp_lr = pd.Series(logreg.coef_[0], index=list(X_ohe)).sort_values(ascending=False).head(20)\nfeat_imp_cb = pd.Series(cb_best.feature_importances_, index=list(X_cbt)).sort_values(ascending=False).head(20)\nimp = [(feat_imp_lr, 'Coefficients for Logistic Regression', 'hsv'), \n       (feat_imp_cb, 'Feature Importance for Catboost Classifier', None)]\nfor i, axis in enumerate(axes.flat):\n  imp_series, title, cmap = imp[i]\n  bar = sns.barplot(imp_series, imp_series.index, palette=cmap, ax=axis)\n  axis.tick_params(axis='y', labelsize=12) \n  axis.set_title(title)\n  for p in bar.patches:\n      width = p.get_width()    # get bar length\n      bar.text(width,  # set the text at bar\n              p.get_y() + p.get_height() \/ 2, # get Y coordinate + X coordinate \/ 2\n              '{:1.2f}'.format(width), # set variable to display, 2 decimals\n              ha = 'left',   # horizontal alignment\n              va = 'center', # vertical alignment\n              fontsize=13)  \nplt.tight_layout()","78d1ddd1":"## 3.1 Size Reduction","8a813ee0":"# 2. Import","e360fff0":"## 6.4 Feature Importance","a207fb8a":"Turns out, they don't differ that much. The best model with dummy variables is Logistic Regression.  \nCatboost is at 4th place.  \nFurther I am going to tune parameters for these two models in order to determine whether dummy categorical features as dummy variables have significant importance or they are better predictors as unified variables. ","c20067ce":"Let's take a quick glance at categorical_features.","a8bbbcf0":"At first, let's check the value counts of target variable.","c3c578fd":"# 6. Model training","2daab393":"Now let's check distribution of *grade* and *sub_grade* features.","6546c9ba":"Due to the large size of the dataset and lack of computing power at my disposal I am going to reduce the size of dataset by categories of target variable and time boundaries. ","37f600aa":"Borrowers that failed to pay loan in general were extimated worse. It will probably be one of most important features for prediciton.","3168fe33":"Various machine learning methods were applied to predict the probability of loan default on the base of prior information known about a borrower. After training and evaluating different models, I chose CatBoost for its unique approach to deal with categorical features and Logistic Regression that showed the highest performance among models that used data after One-Hot-Encoder transformation.\nWe tuned both models and got ROC-AUC-scores of 0.697 for Logistic Regression and 0.701 for Catboost.\nAfter that, we assessed the model performance of Catboost by ROC-curve and PR-curve and outlined relatively weak capability to predict charged off loans due to the fact of high imbalance in target variable.\nWe also found that two models prefer different features as most important for prediction.\n","08637980":"## 6.1. Comparison of models","6aca2098":"Now let's prepare data for model building Catboos\u0435 (without One-Hot-Encoding) and for other models (with One-Hot-En\u0441oding).","f1958e4a":"# 4. Exploratory Data Analysis","c980987a":"Looks like sub_grade provide us with more gradual (but not linear in all places) prediction of target variable.  \nSo, i will transform sub_grade into new numerical feature and drop grade and sub_grade.","9c3ffaa8":"Those who paid loan have higher annual income, so it must be very important feature. Also, distribution of variable now is normal and contains not so extreme outliers.  \nLet's drop original variable.","44a52584":"Let's assess contribution of features in each model.","f850b8c3":"Loans with the purpose of small business tend to be charged off more often and loans for renewable energy tend to be charged off less often. though this category has smallest amount of objects.  \nBut in general categories do not have significant differences.","0bf5cc37":"## 3.5 Categorical columns","766e2b03":"I am going to inspect differences  between fully paid loans and charged off ones.   \nSo, I will exclued current loans, ones that don't meet the credit policy, defaulted, or have a missing status.  \nLoans to keep have status \"Fully Paid\" and \"Charged Off.\"","6e49e01e":"Since Catboost requires the exact ratio of classes for *class_weight* parameter, I am going to use special method for computing balanced weights based on ratio of values in variable.","7934ac9a":"I will examine important features to determine differences in distribution by target variable and propose hypotheses.","8dbfaaa9":"Let's find constant features (null variance for numerical features and only one value for categorical features).","ae22f7f2":"### 3.4.2 Correlation of predictors with target feature","3892bfed":"And let's drop one from each pair.","1c577908":"This variable indicates if income was verified by LC [Lending Club], not verified, or if the income source was verified.  \nWe can see notable difference between groups.","a452c96e":"Mean and median interest rate for charged off loans are also in general higher, but minimum and maximum values don't differ. Variance is also does not differ sinificantly. It is matter of dispute whether it will be good predictor.","c4f7fe71":"There are 2.2 million rows and 151 variables. The size of the dataset is above 2.5 GB.","fb60acc7":"While the overall predictive power of model is quite satisfactory, ability to predict Charged off loans is quite weak.  \nIn conclusion, by changing threshold we will have to find proper balance between high recall and large amount of False Positive or high precision and large amount of false negatives.","bcc82279":"Further, I am going make scatterplots of cluster of dependent variables and delete some of them.","c7208cbc":"*collection_recovery_fee* - post charge off collection fee","1f4e1342":"# 7. Conclusion","887e9b4c":"Now I'b going to investigate correlation matrix of features with the largest VIF and pick clusters of correation features for further deletion.","2af7e0cd":"As previously stated, I am going to reduce the size of data by choosing time period. Due to the average quantity of loans in 2013 and final status of loans (maximum term of loan provision by Lending Club is 3 years) I will keep only loans from 2013. ","588064b3":"## 3.4 Numerical Features","10639334":"### 3.4.1 Multicollinearity","a87ca999":"Let's find the most effective parameter of C (regularization strength) by applying LogisticRegressionCV.\n\n","d6758019":"## 6.2. Model Tuning","234fa6fa":"*Recoveries* - post charge off gross recovery","eb606592":"This feature has too many outliers. In order to fix this problem, let's use apply logarithm.","bd9d8e8e":"Now let's look at the distribution of years, when loans were issued","33b0db3c":"# 5. Preprocessing","c6886d23":"Such features as *int_rate*, *loan_amnt*, *dti* turned out to bear high importance for both models. However, we can detect considerable differences.  \n**Catboost** attaches importance to only numerical features - we do not see categorical ones in top 20.  \nMeanwhile **Logistic Regression** outlines specific values of categorical features. For instance, *purpose_small_business*, *term_60_month* and *emp_lenth_nan* are in top features for** Logistic Regression**. These categories were detected to be more associated with loan default in EDA.  \n\nIt is important to note that some numerical features have high importance in one model and do not even have a place in the top for the another model.  \nFor **Logistic Regression** these are *num_sats*, and for Catboost - *Subgrade_num* and *log_income*.","b71db7d4":"Since all these features are correlated with *open_acc* (The number of open credit lines in the borrower's credit file) with coefficients from 0.61 to 1 and some of them are intercorrelated, I am going to drop them all.\n","e2a72a87":"Let's set variables with categorical and numerical columns","c737cb50":"Let's visualize ROC-curve and PR-curve.","125a852a":"Loans of clients with rented houses tend to be charged off more often, but difference is quite small, so this feature is probably not very significant.","9329fb51":"Now let's examine whether any feature is heavily correlated with target variable in order to find features that contain information emerged after the issue of loan and thus unfit for prediction.","cc52ed8d":"Let's look at other pairs of correlated features.","a9123c73":"## 3.2 Dropping missing values","7604a600":"# 1. Introoduction","2d2f1259":"Loans with higher term are significantly more likely to be charged off and thus should constitute important feature.","fb4da3cc":"I am going to carry out cross validation with the set ratio of classes and will use StratifiedKFold method with 5 splits and shuffle.","5e6a9fee":"## 6.3 Evaluation of model","8387b8e8":"Let's look at perfromance of all models.","44ea6244":"As we can see, ROC_AUC-score for Catboost is higher. ","03a565bc":"In the plot we can observe large gap between features missing small percentage of data (<20%) and those missing significant proportion of data (>40%).  \nLet's drop all columns with more than 20% missing values.","1ce9a54d":"Let's check the distribution of target variable in reduced dataset.","5b70be4c":"# 3. Data Cleaning","dc241f7a":"Let's determine models and set balanced class weights where it is possible. ","eef6d03e":"*last_pymnt_amnt* - last total payment amount received","7eae31b3":"Such features as last_pymnt_d, last_credit_pull_d, earliest_cr_line contain dates that I am not going to use in my models. Let's drop them.","2b83645a":"As we can see, amount of the loan is higher for those that failed to pay it afterwards, but distribution of its feature is basically the same for both categories.  \nIt looks like important feature for model building.","6f4615b5":"Let's convert target variable from categorical to numerical for the more comfortable analysis.","fc4c13eb":"Let's check statistical metrics and description of 4 most correlated features.","91214640":"In order to detect and drop correlating features I am going firstly to calculate VIF of numerical features.","a6329d22":"Now let's tune parameters for Catboost.","58a4907b":"Let's visualize the distribution of missing values ratio by columns:","46e987cc":"## 3.3 Useless features","9bc23203":"Such features as *recoveries*,  *collection_recovery_fee*, *last_pymnt_amnt* describe data after the issue of loand and thus unfit for prediction.","1cabade3":"[LendingClub](https:\/\/en.wikipedia.org\/wiki\/LendingClub) is a US peer-to-peer lending company and the world's largest peer-to-peer lending platform. \n\nLendingClub enables borrowers to create unsecured personal loans between 1,000  and  40,000 USD. The standard loan period is three years. Investors are able to search and browse the loan listings on LendingClub website and select loans that they want to invest in based on the information supplied about the borrower, amount of loan, loan grade, and loan purpose. Investors make money from the interest on these loans. LendingClub makes money by charging borrowers an origination fee and investors a service fee.\n\nThe goal of this project is to build a machine learning model to predict the probability of a loan to be charged off. \nI will attempt to delete all features that are filled after the provision of a loan and keep all information known about a borrower prior to receiving of a loan.","6ee6a4a6":"*int_rate* - interest Rate on the loan","c881d258":"Let's delete these features","9766a88f":"Let's look at description.  \n*fico_range_low*: \"The lower boundary range the borrower\u2019s FICO at loan origination belongs to.\"  \n*fico_range_high*: \"The upper boundary range the borrower\u2019s FICO at loan origination belongs to.\"\n\nI will create new feature as a mean between these two variables","51e846cd":"Now we are going to train different models with default parameters in order to determine the most effective one and conduct parameter tuning for it further.","d98642f6":"Now let's delete personal or irrelevant columns.\n* ID\n* URL\n* The month which the loan was funded \n* Zip code\n* Employment title\n* The loan title provided by the borrower\n* State of residence\n\nAlso information that contains information **up until the present time** because this data can not be used for prediction. Such as:  \n* total_pymnt - Payments received to date for total amount funded  \n* total_pymnt_inv - Payments received to date for portion of total amount funded by investors  \n* total_rec_prncp - Principal received to date  \n* total_rec_int - Interest received to date \n* total_rec_late_fee - Late fees received to date\n* debt_settlement_flag - The indication of settlement negotiatied with an insecured debtor  \n* funded_amnt - The total amount committed to that loan at that point in time\n* funded_amnt_inv - The total amount committed by investors for that loan at that point in time.  \n\nDescription of features is taken from [Data Dictionary](http:\/\/rstudio-pubs-static.s3.amazonaws.com\/290261_676d9bb194ae4c9882f599e7c0a808f2.html)."}}