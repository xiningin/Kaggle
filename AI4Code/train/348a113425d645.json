{"cell_type":{"1a4c79ea":"code","dedd27b3":"code","44ed3d74":"code","f8a2ed02":"code","852fa27e":"code","bbc874a6":"code","aa741521":"code","7dcca26a":"code","ecc99537":"code","91de8a78":"code","3328e590":"code","00a98be3":"code","3c7e8c1e":"markdown","72dc1717":"markdown","5f09cf61":"markdown","53b80a1b":"markdown","14d1c6c6":"markdown","895ef1a4":"markdown","8972f643":"markdown"},"source":{"1a4c79ea":"import numpy\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","dedd27b3":"data=pd.read_csv('..\/input\/sandp500\/individual_stocks_5yr\/individual_stocks_5yr\/AAPL_data.csv',skipfooter=1)\ndata.head()","44ed3d74":"data = data.iloc[:,1].values\nplt.plot(data)\nplt.xlabel(\"time\")\nplt.ylabel(\"stock prices\")\nplt.title(\"Apple stock prices\")\nplt.show()","f8a2ed02":"data = data.reshape(-1,1)\ndata = data.astype(\"float32\")\ndata.shape","852fa27e":"# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndata = scaler.fit_transform(data)","bbc874a6":"train_size = int(len(data) * 0.50)\ntest_size = len(data) - train_size\ntrain = data[0:train_size,:]\ntest = data[train_size:len(data),:]\nprint(\"train size: {}, test size: {} \".format(len(train), len(test)))","aa741521":"time_stemp = 50\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY)  \n","7dcca26a":"dataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)  ","ecc99537":"trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","91de8a78":"# model\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(1, time_stemp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=20, batch_size=1)","3328e590":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","00a98be3":"# shifting train\ntrainPredictPlot = numpy.empty_like(data)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(data)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(data)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(data))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","3c7e8c1e":"[](https:\/\/upload.wikimedia.org\/wikipedia\/en\/4\/43\/Apple_Logo_1998.jpg)","72dc1717":"<a id=\"43\"><\/a>\n### Create LSTM Model","5f09cf61":"<a id=\"44\"><\/a>\n### Predictions and Visualising LSTM Model","53b80a1b":"<a id=\"41\"><\/a>\n### Loading and Visualizing Data","14d1c6c6":"<a id=\"42\"><\/a>\n### Preprocessing Data\n* reshape\n* change type\n* scaling\n* train test split\n* Create dataset","895ef1a4":"<a id=\"\"><\/a>\n## Implementing Long Short Term Memory with Keras\n* [Loading and Visualizing Data](#41)\n* [Preprocessing Data](#42)\n* [Create LSTM Model](#43)\n* [Predictions and Visualising LSTM Model](#44)","8972f643":"\n## This dataset contains Apple stock prices between 2103 and 2018.\n## We will make prediction with use LSTMs for prices in specific timestampt.\n## We will use open prices to make predict."}}