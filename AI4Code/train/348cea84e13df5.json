{"cell_type":{"ff788e7f":"code","c2798b93":"code","77561fe3":"code","7745b3d6":"code","c928144b":"code","fb57db0e":"code","f1124a00":"code","e8d73fce":"code","175dde61":"code","3a448d8c":"code","ef761978":"markdown","a73fa524":"markdown","1b2db6bf":"markdown"},"source":{"ff788e7f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","c2798b93":"# set the model split test size. Usually it is .20 but for fun made it .30.\n# and set our seed\ntest_size = .3\nseed = 69","77561fe3":"# import our training file\ntrain_df = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')","7745b3d6":"# what does our data look like? \ntrain_df.head()","c928144b":"# we need to drop our target from X so we can predict\nX = train_df.drop(['target'], axis=1)\n# and add the target to y which is what we are trying to predict!\ny = train_df['target']","fb57db0e":"# now we can encode our labels for the target since they are cats. meow.\nlabel_encoder = LabelEncoder()\nlabel_encoder = label_encoder.fit(y)\nlabel_encoded_y = label_encoder.transform(y)","f1124a00":"# this is very standard fair. We split our data into train and test sets. \n# train is to train... so we have the x part of train to learn on and the y as the target we want to predict\n# ditto for the y portion of the test set. Which as you remember above is .30 of our dataset. \nX_train, X_test, y_train, y_test = train_test_split(X, label_encoded_y,\n    test_size=test_size, random_state=seed)","e8d73fce":"# we are making this a basic, out of the box XGBoost. \nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\nprint(model)\n# we print the model so you can see that we used the out of the box features of XGBoost","175dde61":"# we will set our prediction on the test data\npred = model.predict(X_test)","3a448d8c":"# and finally, the payoff. How accurate is our model?\naccuracy = accuracy_score(y_test, pred)\nprint('Accuracy: %.2f%%' % (accuracy*100))","ef761978":"Eh. We could almost flip a coin and predict this. Not so great. But we get ~58% without doing a single thing to the data. Time to engineer some features! I'll create another notebook with that and link here. ","a73fa524":"This is a super basic starter on XGBoost. If you need something to get you started this hopefully will help. ","1b2db6bf":"The target is a category. Well, that is interesting. We might want to encode those labels!"}}