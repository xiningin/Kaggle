{"cell_type":{"c2f566e9":"code","81a601f7":"code","2b2d4711":"code","53f53b39":"code","4b254ada":"code","8ad162a6":"code","c597b75e":"code","30ecb755":"code","0c1a2b0e":"code","99e2af0d":"code","7ad8bc27":"code","2cb06046":"code","caeda0ff":"markdown"},"source":{"c2f566e9":"# Importing the dataset\nimport pandas as pd\n\n# Read the file\nhousing = pd.read_csv(\"..\/input\/regressionhousing\/Housing.csv\")\n\n# Top 5 results\nhousing.head()","81a601f7":"# Converting Yes to 1 and No to 0\nhousing.mainroad = housing.mainroad.map({'yes':1, 'no':0})\nhousing.guestroom = housing.guestroom.map({'yes':1, 'no':0})\nhousing.basement = housing.basement.map({'yes':1, 'no':0})\nhousing.hotwaterheating = housing.hotwaterheating.map({'yes':1, 'no':0})\nhousing.airconditioning = housing.airconditioning.map({'yes':1, 'no':0})\nhousing.prefarea = housing.prefarea.map({'yes':1, 'no':0})\nhousing.head()","2b2d4711":"# Converting furnishingstatus column to binary column using get_dummies\nstatus = pd.get_dummies(housing.furnishingstatus, drop_first=True)\nhousing = pd.concat([housing, status], axis=1)\nhousing.drop(['furnishingstatus'], axis=1, inplace=True)\nhousing.head()","53f53b39":"#Normalising the data\nhousing = (housing - housing.mean())\/housing.std()\nhousing.head()","4b254ada":"# Simple Linear Regression\n# Assign feature variable X\nX = housing.area\n\n#Assign response variable to y\ny = housing.price ","8ad162a6":"# Conventional way to import seaborn\nimport seaborn as sns\n\n# To visualize in the notebook\nimport matplotlib.pyplot as plt","c597b75e":"# Import warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualise the relationship between the features and the response\nsns.pairplot(housing, x_vars='area', y_vars='price', size=7, aspect=0.7)\nplt.show()","30ecb755":"# Importing numbpy\nimport numpy as np\n\nX = np.array(X)\ny = np.array(y)","0c1a2b0e":"# Implement gradient descent function\ndef gradient(X, y, m_current=0, c_current=0, iters=1000, learning_rate=0.001):\n    N = float(len(y))\n    gd_df = pd.DataFrame(columns=['m_current', 'c_current', 'cost'])\n    for i in range(iters):\n        y_current = (m_current * X) + c_current\n        cost = sum([data**2 for data in (y - y_current)]) \/ N\n        m_gradient = -(2\/N) * sum(X * (y - y_current))\n        c_gradient = -(2\/N) * sum(y - y_current)\n        m_current = m_current - (learning_rate * m_gradient)\n        c_current = c_current - (learning_rate * c_gradient)\n        gd_df.loc[i] = [m_current, c_current, cost]\n    return (gd_df)","99e2af0d":"# Print gradients\ngradients = gradient(X, y)\ngradients.head()","7ad8bc27":"def gradient_descent_multi(X, y, theta, alpha, iterations=1000):    \n    theta = np.zeros(X.shape[1])    \n    m = len(X)    \n    gdm_df = pd.DataFrame( columns = ['Bets','cost'])    \n    for i in range(iterations):        \n        gradient = (1\/m) * np.matmul(X.T, np.matmul(X, theta) - y)        \n        theta = theta - alpha * gradient        \n        cost = compute_cost(X, y, theta)        \n        gdm_df.loc[i] = [theta,cost]    \n        return gdm_df","2cb06046":"# Plotting the cost against num_iterations\ngradients.reset_index().plot.line(x='index', y=['cost'])\nplt.show()","caeda0ff":"# Gradient Descent Implementation"}}