{"cell_type":{"7c0892e8":"code","acec1c18":"code","d3db55a1":"code","11814a1f":"code","3c36436e":"code","06a0de23":"code","52621b75":"code","c2a7b6e4":"code","90edb2c6":"code","616f3c90":"code","1cdc2435":"code","0d8301cb":"code","5e269e1e":"code","13e8527b":"markdown","0ffaebab":"markdown","48a76b65":"markdown","691bb3f9":"markdown","9cff8e72":"markdown","79cf4cb3":"markdown","e7ef0f99":"markdown","d25a887c":"markdown","ea5f9b70":"markdown","5c3dad39":"markdown","bf9f981a":"markdown"},"source":{"7c0892e8":"# Admin\nimport os\n\n# Data manipulation\nimport pandas as pd\n","acec1c18":"os.getcwd()","d3db55a1":"df_train = pd.read_csv('..\/input\/train.csv')","11814a1f":"df_train.head(3)","3c36436e":"%%html\n<style>\ntable {float:left}\n<\/style>","06a0de23":"df_train['Survived'].value_counts(dropna = False)","52621b75":"1 - df_train['Survived'].mean()","c2a7b6e4":"df_test = pd.read_csv('..\/input\/test.csv')","90edb2c6":"df_test.head(3)","616f3c90":"# not run\n#df_all = pd.concat([df_train, df_test], sort = False)\n#df_all['Survived'].value_counts(dropna = False)","1cdc2435":"pd_sub_1 = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": 0\n    })","0d8301cb":"pd_sub_1.head()","5e269e1e":"#pd_sub_1.to_csv('..\/POutput\/04a_pd_sub_1.csv', index=False)\npd_sub_1.to_csv('04a_pd_sub_1.csv', index=False)","13e8527b":"### Questions\n\n1. What perentage of passengers did not survive in the train data?\n2. What perentage of passengers did not survive in the test data?\n3. What is the overall survival percentage (including both train and test data)?\n4. Given the overall survival percentage, could the difference between train and test survival percentages be due to randomness in the samples?\n5. When preparing other (non naive) solutions which give probabilties as predictions, is it worthwhile to ensure that the average of the predictions is equal to 0.62679?  If yes, how would you make the adjustment?  If not, why not?","0ffaebab":"![](http:\/\/)### Start_. Import required packages","48a76b65":"The two cells below are not in the video.  I have added them just to remind you what each column means.","691bb3f9":"Score was 0.62679","9cff8e72":"**04a_Naive.ipynb**\n\n**Purpose:** Naive solution for titanic \n\n**Author**: Alan Chalk  \n**Modified**: 28  April 2018\n\n**Contents**:\n - Start_. Packages, directoties, functions\n - 1. Read the data\n - 2. Prepare naive solution\n - 3. Questions\n \n \n**Notes**","79cf4cb3":" - Note: In the code below, ..\/ goes up one directory level\n - Note: My personal preference is, that if when naming objects you are going to use two or three letters to describe the type of object (eg df_ for dataframe in the code below), then these two or three letters should be at the beginning of the name, not the end, e.g. df_all, mat_X, bln_ind","e7ef0f99":"Description of the features\n\n|name| description|\n| :- | :- |\n|PassengerId|\n|Survived| Did the passenger survive (0 = No, 1 = Yes)|\n|Pclass|Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)|\n|Name||\n|Sex||\n|Age|Age in years|\n|SibSp|# of siblings \/ spouses aboard the Titanic|\n|Parch|# of parents \/ children aboard the Titanic|\n|Ticket|Ticket number|\n|Fare| Passenger fare|\n|Cabin|Cabin number|\n|Embarked|Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)|","d25a887c":"Concatenate the two datasets","ea5f9b70":"### 1. Read the data","5c3dad39":"### 2. Prepare naive solution\n\nThe simplest solution is to predict the majority class","bf9f981a":"Check the working directory.  When using a Kaggle kernel the code should work without any changes. When using the structure suggested in AML, you need to be in the Titanic\/PCode subdirectory."}}