{"cell_type":{"9f88e1c5":"code","d1839ebe":"code","4b6ad0c3":"code","da8a870b":"code","7ab355b2":"code","19f6c4e0":"code","40895b95":"code","755b2c73":"code","f9252a30":"code","41503e9a":"code","8a9b8875":"code","b838604e":"code","20e0ef29":"code","ac496fb6":"code","61f09d65":"code","7cf7b817":"code","d390690b":"code","7f55df22":"code","a32544dc":"code","9401bee0":"code","3e23e7bc":"code","c83d0a42":"code","1b01c71a":"code","a53e2395":"code","c757991f":"code","bf993014":"code","ff57de7a":"code","64958e76":"code","ce1993a5":"code","bb87472a":"code","c6ec3bde":"code","fc7ef60f":"code","d931c573":"code","ddf588d3":"code","09bd618d":"code","8bb5761a":"code","8c6b6c48":"code","b5bce492":"code","3bde8368":"code","cb352870":"code","e922ff29":"code","407500ec":"code","5b5984d6":"code","7a9d1e47":"code","9c842f99":"code","6ee16b84":"code","e70f5b7e":"code","5c175c0c":"code","b997bd8f":"code","7cd03cee":"code","52c00eef":"code","31b36045":"code","31986e18":"code","14e9301f":"markdown","7934d576":"markdown","32e43209":"markdown","06eefed1":"markdown","063cbcf5":"markdown","bcb16875":"markdown","166b227c":"markdown","b24dfa86":"markdown","bb4fe531":"markdown","c61a1301":"markdown","d8a9b91d":"markdown","50c40457":"markdown","c02fcbfd":"markdown","b110215a":"markdown","8a3cb097":"markdown","dbeb1d12":"markdown","ef8e032a":"markdown","9b9e8aad":"markdown","1a6a38cd":"markdown","49a58562":"markdown","0afe841f":"markdown"},"source":{"9f88e1c5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom sklearn.metrics import silhouette_score, silhouette_samples\nimport sklearn.metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\nfrom sklearn.mixture import GaussianMixture\nimport seaborn as sns\nimport itertools\nimport scipy\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","d1839ebe":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","4b6ad0c3":"train.head()","da8a870b":"train.info()","7ab355b2":"test.head()","19f6c4e0":"sns.heatmap(train.isnull(),yticklabels=False, cbar=False,cmap='viridis')","40895b95":"sns.countplot(x='Survived', data=train, hue='Sex')","755b2c73":"train['Parch'].value_counts()","f9252a30":"sns.countplot(x='Survived', data=train, hue='Pclass')","41503e9a":"sns.distplot(train['Age'].dropna(), kde=False, bins=30)","8a9b8875":"sns.countplot(x='SibSp', data=train)","b838604e":"train['Fare'].hist(bins=40)","20e0ef29":"def impute_age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass==1: \n            return 37\n        elif Pclass==2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age\n        ","ac496fb6":"train['Age']=train[['Age', 'Pclass']].apply(impute_age,axis=1)","61f09d65":"train['Age']=np.log10(train['Age'])","7cf7b817":"train['Fare']=np.log10(train['Fare']+10)","d390690b":"sns.heatmap(train.isnull(),yticklabels=False, cbar=False, cmap='viridis')","7f55df22":"train.drop(['Cabin'],axis=1,inplace=True)","a32544dc":"train.dropna(inplace=True)","9401bee0":"sns.heatmap(train.isnull(),yticklabels=False, cbar=False, cmap='viridis')","3e23e7bc":"dums=pd.get_dummies(train[['Sex', 'Embarked']], drop_first=True)","c83d0a42":"train=pd.concat([train,dums], axis=1)","1b01c71a":"train.head()","a53e2395":"train.drop(['Sex', 'Embarked','Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)","c757991f":"train.head()","bf993014":"f = plt.figure(figsize=(19, 15))\nplt.matshow(train.corr(), fignum=f.number)\nplt.xticks(range(train.shape[1]), train.columns, fontsize=14, rotation=45)\nplt.yticks(range(train.shape[1]), train.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","ff57de7a":"X=train.drop(['Survived'], axis=1)\nY=train['Survived']","64958e76":"from sklearn.model_selection import train_test_split","ce1993a5":"X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.3,random_state=176)","bb87472a":"from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier(random_state=42, criterion=\"entropy\",\n                             min_samples_split=10, min_samples_leaf=10, max_depth=3, max_leaf_nodes=5)\nclf.fit(X_train, Y_train)\n\ny_pred_dt = clf.predict(X_test)","c6ec3bde":"feature_names = X.columns\nclass_names = [str(x) for x in clf.classes_]","fc7ef60f":"print(clf.tree_.node_count)\nprint(clf.tree_.impurity)\nprint(clf.tree_.children_left)\nprint(clf.tree_.threshold)","d931c573":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(Y_test, y_pred_dt)","ddf588d3":"from sklearn.metrics import classification_report","09bd618d":"\nprint(classification_report(Y_test, y_pred_dt, target_names=class_names))","8bb5761a":"from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, log_loss, roc_curve, auc\n\nprint(\"Accuracy = {:.2f}\".format(accuracy_score(Y_test, y_pred_dt)))\nprint(\"Kappa = {:.2f}\".format(cohen_kappa_score(Y_test, y_pred_dt)))\nprint(\"F1 Score = {:.2f}\".format(f1_score(Y_test, y_pred_dt)))\nprint(\"Log Loss = {:.2f}\".format(log_loss(Y_test, y_pred_dt)))","8c6b6c48":"def plot_roc(clf, X_test, y_test, name, ax, show_thresholds=True):\n    y_pred_rf = clf.predict_proba(X_test)[:, 1]\n    fpr, tpr, thr = roc_curve(y_test, y_pred_rf)\n\n    ax.plot([0, 1], [0, 1], 'k--');\n    ax.plot(fpr, tpr, label='{}, AUC={:.2f}'.format(name, auc(fpr, tpr)));\n    ax.scatter(fpr, tpr);\n\n    if show_thresholds:\n        for i, th in enumerate(thr):\n            ax.text(x=fpr[i], y=tpr[i], s=\"{:.2f}\".format(th), fontsize=14, \n                     horizontalalignment='left', verticalalignment='top', color='black',\n                     bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.1', alpha=0.1));\n        \n    ax.set_xlabel('False positive rate', fontsize=18);\n    ax.set_ylabel('True positive rate', fontsize=18);\n    ax.tick_params(axis='both', which='major', labelsize=18);\n    ax.grid(True);\n    ax.set_title('ROC Curve', fontsize=18)","b5bce492":"plt.style.use('default');\nfigure = plt.figure(figsize=(10, 6));    \nax = plt.subplot(1, 1, 1);\nplot_roc(clf, X_test, Y_test, \"Decision Tree\", ax)\nplt.legend(loc='lower right', fontsize=18);\nplt.tight_layout();","3bde8368":"test['Age']=test[['Age', 'Pclass']].apply(impute_age,axis=1)","cb352870":"test['Age']=np.log10(test['Age'])","e922ff29":"test['Fare']=np.log10(test['Fare']+10)","407500ec":"sns.heatmap(test.isnull(),yticklabels=False, cbar=False, cmap='viridis')","5b5984d6":"test.drop(['Cabin'],axis=1,inplace=True)","7a9d1e47":"test['Fare'] = test['Fare'].fillna(test['Fare'].median())","9c842f99":"sns.heatmap(test.isnull(),yticklabels=False, cbar=False, cmap='viridis')","6ee16b84":"dumst=pd.get_dummies(test[['Sex', 'Embarked']], drop_first=True)","e70f5b7e":"test=pd.concat([test,dumst], axis=1)","5c175c0c":"test.drop(['Sex', 'Embarked','Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)","b997bd8f":"test.head()","7cd03cee":"predictions1=clf.predict(test)","52c00eef":"predictions1","31b36045":"dataset1 = pd.DataFrame(predictions1)","31986e18":"dataset1.to_csv(\"DT1.csv\")","14e9301f":"# TEST DATA PREP","7934d576":"# Decision Tree\n","32e43209":"**# Too many Nans in Cabin so should be dropping it entirely.. but lets see\n**[](http:\/\/)","06eefed1":"ALL SET!! Lets do some homework now.","063cbcf5":"Dropping first i.e. females and category C so as to ensure multicollinearity is not introduced","bcb16875":"# PREDICTIONS ON SAMPLE DATA - DT","166b227c":"Applying same Age imputation with respect to Pclass to ensure same logics in both datasets","b24dfa86":"Taking log of both Age and Fare similar to train datasets","bb4fe531":"Though this version doesn't have any feature engineering, but this plot exhibits some good correlations and thus, there is a great scope of creating more features combing the combination and hence dropping the original ones","c61a1301":"Though Age has missing values, still resembles a normal distribution ","d8a9b91d":"Taking log of Fare and Age ","50c40457":"People were travelling alone or with 1 sibling \/spouse at max","c02fcbfd":"There's a clear trend here. Pclass 3 was least likely to survive","b110215a":"# EDA\n\n","8a3cb097":"# MODEL DEVELOPMENT","dbeb1d12":"Imputing age by Pclass","ef8e032a":"# Data Handling","9b9e8aad":"# Dummy Creation","1a6a38cd":"**FINAL DATA : **","49a58562":"**FINAL DATASET:**","0afe841f":"It looks like Males were more likely to die than females"}}