{"cell_type":{"df066ce8":"code","c781980e":"code","bde678dc":"code","14ff823a":"code","b43b7116":"code","f08f352e":"code","4d7dfab2":"code","9bb960a6":"code","0db49e5e":"code","da5cccfb":"code","e06fcc5b":"code","cc3947d5":"code","3eb2d452":"code","1a7c01bf":"code","801dc5dd":"code","9fe247ed":"code","f85903a6":"code","812dd001":"code","cf526f80":"code","9dac913f":"markdown","c286c35e":"markdown","42694be4":"markdown","4655e2cb":"markdown","dc16c259":"markdown","268959f3":"markdown","09a3529b":"markdown","5a144d45":"markdown","b7c93ad9":"markdown","62ea8ca7":"markdown","2f571cbe":"markdown","5b98ad10":"markdown","2f35fee5":"markdown","3f9b434f":"markdown","09a6962b":"markdown","ef325f2e":"markdown","cc439ee5":"markdown","3aa61de1":"markdown","b5e060fb":"markdown","a346ecd9":"markdown","aa359dbb":"markdown","eeb67d7e":"markdown","22600493":"markdown","c1887659":"markdown","1cf30f92":"markdown","f27d9ace":"markdown"},"source":{"df066ce8":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.decomposition import PCA\nimport umap","c781980e":"!ls ..\/input\/jane-street-market-prediction","bde678dc":"train = pd.read_csv(\"..\/input\/jane-street-market-prediction\/train.csv\")\nfeature = pd.read_csv(\"..\/input\/jane-street-market-prediction\/features.csv\")","14ff823a":"train.head()","b43b7116":"feature.head()","f08f352e":"feature_col = feature[\"feature\"]\ntag_col = [col for col in feature.columns if col not in [\"feature\"]]\nfeature = feature.rename(index=feature[\"feature\"])[tag_col]","4d7dfab2":"cos_matrix = cosine_similarity(feature, feature)\ncos_matrix","9bb960a6":"plt.figure(figsize=(15, 15))\ng = sns.heatmap(data=cos_matrix)\ng.set_title(\"Cosine similarity matrix of features' metadata\", fontsize=15)","0db49e5e":"distance_matrix = pairwise_distances(feature, feature, metric='euclidean')\ndistance_matrix","da5cccfb":"plt.figure(figsize=(15, 15))\ng = sns.heatmap(data=distance_matrix)\ng.set_title(\"Euclid distance matrix of features' metadata\", fontsize=15)","e06fcc5b":"train_feature = train[feature_col]\ntrain_feature_corr = train_feature.corr()\ntrain_feature_corr","cc3947d5":"plt.figure(figsize=(15, 15))\ng = sns.heatmap(data=train_feature_corr)\ng.set_title(\"Correlation matrix of features\", fontsize=15)","3eb2d452":"fig, axes = plt.subplots(1, 3, figsize=(15,6), gridspec_kw=dict(wspace=0.1, hspace=0.6))\nfig.suptitle(\"Comparison of the heatmaps\", fontsize=15)\n\ng_1 = sns.heatmap(data=cos_matrix, ax=axes[0])\ng_1.set_title(\"Cosine similarity matrix of features' metadata\")\n\ng_2 = sns.heatmap(data=distance_matrix, ax=axes[1])\ng_2.set_title(\"Euqlid distance matrix of features\")\n\ng_3 = sns.heatmap(data=train_feature_corr, ax=axes[2])\ng_3.set_title(\"Correlation matrix of features\")","1a7c01bf":"kmeans = KMeans(n_clusters=3, random_state=0).fit(feature)","801dc5dd":"reducer = umap.UMAP()\nembedding = reducer.fit_transform(feature)","9fe247ed":"fig = go.Figure(data=go.Scatter(x=embedding[:, 0],\n                                y=embedding[:, 1],\n                                mode='markers',\n                                marker_color=kmeans.labels_))\nfig.update_layout(title='features with kmeans labels')\nfig.show()","f85903a6":"feature[\"kmeans_label\"] = kmeans.labels_\nfeature[[\"kmeans_label\"]]","812dd001":"pca = PCA().fit(train[feature_col].dropna())","cf526f80":"#https:\/\/www.kaggle.com\/kushal1506\/deciding-n-components-in-pca\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 131, step=1)\ny = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, y, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 130, step=10)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()","9dac913f":"## Contents\n\n1. [Loading and overviewing dataset](#1)\n1. [Analysis with similarity matrix](#2)\n1. [Analysis with clustering method](#3)\n1. [Compressing](#4)","c286c35e":"<a id=\"2\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Analysis with similarity matrix<\/div>\n\nI create two similarity matrix and visualized as heatmap.\n\n- cosine similarity matrix for feature.csv\n\n- correlation matrix for train.csv","42694be4":"## Comparison of heatmaps \n\nLet's compare the previous two heat maps.","4655e2cb":"### Load dataset","dc16c259":"### Calculate cosine similarity matrix\n\nI regarded the dataframe as a vector representation of the features by tag_{0. .28}. So I create cosine similarity matrix for each feature pairs.","268959f3":"<a id=\"3\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Analysis with clustering method<\/div>\n\nI also check that there are some similar groups of features by clustering method. I assumed that features are spatially similar, and estimated their labels by kmeans. And I droped features into two dimensions with Umap, and I checked that the feature of the same label is gathered. For data, I use feature.csv.","09a3529b":"I could roughly divide features into three groups. So we can say that there are three similar groups of features.","5a144d45":"It is interesting that we can see that there are highly similar blocks floating on the diagonal elements on two heatmaps and the pattern is similar. Thus, it can be said that fetures with high similarity in terms of metadata tend to have also high correlation coefficients as well.","b7c93ad9":"<a id=\"1\"><\/a> <br>\n# <div class=\"alert alert-block alert-success\">Loading and overviewing dataset<\/div>","62ea8ca7":"train.csv contains historical data and returns.","2f571cbe":"### Load library","5b98ad10":"I'll visualize the data with Umap","2f35fee5":"### Visualize heatmap\n\nNext, I'll visualize the matrix.","3f9b434f":"If you look at the heat map, you can see that there are highly similar features each other and not ones. For example, features{0..40} are more similar to each other than to features{0..40} and features{41..54}.","09a6962b":"### Calculate correlation matrix\n\nBy train.csv's data, we can calculate correlation matrix.","ef325f2e":"<a id=\"4\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Compressing<\/div>\n\nI'll try PCA and see how well the trainset can be represented by the variables.","cc439ee5":"I estimate labels for each feature by kmeans. Note that I specified the n_clusters=3 because I visualized the data with Umap beforehand and I knew that it is divided into three clusters.","3aa61de1":"# Jane Street - EDA focused on \u201cfeatures\u201d\n\nGiven dataset contains an anonymized set of features, feature_{0...129}, representing real stock market data.\n\nBecause of the large number of variables, we might look at selecting variable or compressing them with PCA and so on. In order to do that, I got be curious to see what kind of relationship there is between the variables, so we did the analysis.","b5e060fb":"We found that with roughly 30 variables, 95% can be represented.","a346ecd9":"### Preprocess\n\nTo analysis, I'll try some preprocess for dataframe.","aa359dbb":"## Cosine similarity matrix for feature.csv\n\nFirst, I'll check features' similarity by feature.csv.","eeb67d7e":"## Euqlid distance matrix for feature.csv","22600493":"## Correlation matrix for train.csv\n\nI'll also check features' similarity by train.csv.","c1887659":"The brighter the color, the higher the correlation is. As you can see, there are some correlated features. It's hard to see, but you can see some highly correlated blocks.  For example, features{84..120} are more similar to each other than to features{84..120} and features{18..26}.","1cf30f92":"### Visualize heatmap\n\nAs in the previous example, we can visualize the matrix with heatmap.","f27d9ace":"feature.csv includes metadata pertaining to the anonymized features."}}