{"cell_type":{"b0e66787":"code","c666304f":"code","2d9a9445":"code","9f1f2a9b":"code","5982543f":"code","f2f575c1":"code","6ef5c59b":"code","0d26bfa2":"code","13db8f0b":"code","b36e336d":"code","c937ecdd":"code","44e99f83":"code","abca417f":"code","a48709a3":"code","abf7a85b":"code","eeb6bfb3":"code","b6d1b1dc":"code","41d3a885":"code","1b0ba977":"code","d0850d45":"code","d989bfe1":"code","dee2c9f4":"markdown","0c557c41":"markdown","3706d3be":"markdown","5965ddd4":"markdown"},"source":{"b0e66787":"import numpy as np # linear algebra\nimport random\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport cv2\nimport shutil\nfrom glob import glob\n# Helper libraries\nimport matplotlib.pyplot as plt\nimport math\n%matplotlib inline\nprint(tf.__version__)","c666304f":"data_root='\/kaggle\/input\/covidct\/'\npath_positive_cases = os.path.join('\/kaggle\/input\/covidct\/CT_COVID\/')\npath_negative_cases = os.path.join('\/kaggle\/input\/covidct\/CT_NonCOVID\/')","2d9a9445":"# jpg and png files\npositive_images_ls = glob(os.path.join(path_positive_cases,\"*.png\"))\n\nnegative_images_ls = glob(os.path.join(path_negative_cases,\"*.png\"))\nnegative_images_ls.extend(glob(os.path.join(path_negative_cases,\"*.jpg\")))","9f1f2a9b":"covid = {'class': 'CT_COVID',\n         'path': path_positive_cases,\n         'images': positive_images_ls}\n\nnon_covid = {'class': 'CT_NonCOVID',\n             'path': path_negative_cases,\n             'images': negative_images_ls}","5982543f":"total_positive_covid = len(positive_images_ls)\ntotal_negative_covid = len(negative_images_ls)\nprint(\"Total Positive Cases Covid19 images: {}\".format(total_positive_covid))\nprint(\"Total Negative Cases Covid19 images: {}\".format(total_negative_covid))","f2f575c1":"image_positive = cv2.imread(os.path.join(positive_images_ls[1]))\nimage_negative = cv2.imread(os.path.join(negative_images_ls[5]))\n\nf = plt.figure(figsize=(8, 8))\nf.add_subplot(1, 2, 1)\nplt.imshow(image_negative)\nf.add_subplot(1,2, 2)\nplt.imshow(image_positive)","6ef5c59b":"print(\"Image COVID Shape {}\".format(image_positive.shape))\nprint(\"Image Non COVID Shape {}\".format(image_negative.shape))","0d26bfa2":"# Create Train-Test Directory\nsubdirs  = ['train\/', 'test\/']\nfor subdir in subdirs:\n    labeldirs = ['CT_COVID', 'CT_NonCOVID']\n    for labldir in labeldirs:\n        newdir = subdir + labldir\n        os.makedirs(newdir, exist_ok=True)","13db8f0b":"# Copy Images to test set\n\n# seed random number generator\nrandom.seed(237)\n# define ratio of pictures used for testing \ntest_ratio = 0.2\n\n\nfor cases in [covid, non_covid]:\n    total_cases = len(cases['images']) #number of total images\n    num_to_select = int(test_ratio * total_cases) #number of images to copy to test set\n    \n    print(cases['class'], num_to_select)\n    \n    list_of_random_files = random.sample(cases['images'], num_to_select) #random files selected\n\n    for files in list_of_random_files:\n        shutil.copy2(files, 'test\/' + cases['class'])","b36e336d":"# Copy Images to train set\nfor cases in [covid, non_covid]:\n    image_test_files = os.listdir('test\/' + cases['class']) # list test files \n    for images in cases['images']:\n        if images.split('\/')[-1] not in (image_test_files): #exclude test files from shutil.copy\n            shutil.copy2(images, 'train\/' + cases['class'])","c937ecdd":"total_train_covid = len(os.listdir('\/kaggle\/working\/train\/CT_COVID'))\ntotal_train_noncovid = len(os.listdir('\/kaggle\/working\/train\/CT_NonCOVID'))\ntotal_test_covid = len(os.listdir('\/kaggle\/working\/test\/CT_COVID'))\ntotal_test_noncovid = len(os.listdir('\/kaggle\/working\/test\/CT_NonCOVID'))\n\nprint(\"Train sets images COVID: {}\".format(total_train_covid))\nprint(\"Train sets images Non COVID: {}\".format(total_train_noncovid))\nprint(\"Test sets images COVID: {}\".format(total_test_covid))\nprint(\"Test sets images Non COVID: {}\".format(total_test_noncovid))","44e99f83":"batch_size = 128\nepochs = 15\nIMG_HEIGHT = 150\nIMG_WIDTH = 150","abca417f":"train_image_generator = ImageDataGenerator(rescale=1.\/255) # Generator for our training data\ntest_image_generator = ImageDataGenerator(rescale=1.\/255) # Generator for our validation data","a48709a3":"train_dir = os.path.join('\/kaggle\/working\/train')\ntest_dir = os.path.join('\/kaggle\/working\/test')\n\n\ntotal_train = total_train_covid + total_train_noncovid\ntotal_test = total_test_covid + total_test_noncovid","abf7a85b":"train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n                                                           directory=train_dir,\n                                                           shuffle=True,\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode='binary')","eeb6bfb3":"test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n                                                              directory=test_dir,\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                              class_mode='binary')","b6d1b1dc":"model = Sequential([\n    Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n    MaxPooling2D(2, 2),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1)\n])","41d3a885":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","1b0ba977":"model.summary()","d0850d45":"history = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/ batch_size,\n    epochs=epochs,\n    validation_data=test_data_gen,\n    validation_steps=total_test \/\/ batch_size\n)","d989bfe1":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","dee2c9f4":"### Create Train-Test Directory ","0c557c41":"### Datasets Overview ","3706d3be":"Voil\u00e0! By modifying the CNN we obtain a clear improvement in performance on the validation set","5965ddd4":"### Simple CNN Model\n[Tensorflow Tutorial](https:\/\/www.tensorflow.org\/tutorials\/images\/classification)"}}