{"cell_type":{"009a1b3f":"code","d39b2dfd":"code","c9f45849":"code","4da581e0":"code","2dbb8d62":"code","2bdfe2c8":"code","b8a65ef8":"code","24b4d559":"code","51c5e8f7":"code","3fe47c25":"code","881969b8":"code","f9f3b667":"code","48d1279f":"code","3cc66be1":"code","17bef2e8":"markdown","17c710ef":"markdown","bb599aee":"markdown","2f36ec5a":"markdown","7ea8dfc5":"markdown","927d5605":"markdown"},"source":{"009a1b3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Import necessary modules\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d39b2dfd":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntrain.head(1)","c9f45849":"test.head(1)","4da581e0":"X = train.drop('label', axis = 1)\ny = train[['label']]","2dbb8d62":"X = X \/ 255.0\nX = np.array(X).reshape(-1, 28, 28, 1)","2bdfe2c8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, stratify = y)","b8a65ef8":"import seaborn as sns\nprint(len(train['label'].unique()))\nsns.countplot(train['label'])","24b4d559":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n    tf.keras.layers.Dense(10, activation = tf.nn.softmax) # Note 10 is the number of unique layers\n])","51c5e8f7":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","3fe47c25":"image_gen = ImageDataGenerator(rotation_range=90, horizontal_flip=False, vertical_flip=False)\nimage_gen.fit(X_train)","881969b8":"model.fit(X_train, y_train, epochs = 5, steps_per_epoch = 50)","f9f3b667":"test_loss, test_accuracy = model.evaluate(X_test, y_test, steps = 100)\nprint('Loss on test dataset : ', test_loss)\nprint('Accuracy on test dataset : ', test_accuracy)","48d1279f":"result_dataset = test \/ 255.0\nresult_dataset = np.array(result_dataset).reshape(-1,28,28,1)","3cc66be1":"predictions = model.predict(result_dataset)\n\nprediction_labels = []\nfor index, p in enumerate(predictions):\n    prediction_labels.append(np.argmax(p))\n\nprint(prediction_labels)","17bef2e8":"98 % acuracy is better that human detection. But still a lot of improvement is required to make the model more accurate. ","17c710ef":"- label is the target variable\n- pixel0 to pixel783 are the input variables.","bb599aee":"## Please upvote the kernel if you liked it. ","2f36ec5a":"For classification, it is recommended to use ADAM optimizer and sparse_categorical_crossentropy as loss function.","7ea8dfc5":"## Image Augumentation with Rotation","927d5605":"Note : This is for beginners only. Checkout more resources to improve your model accuracy."}}