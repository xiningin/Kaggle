{"cell_type":{"8b92da96":"code","070a38a3":"code","1831cd0e":"code","e79e633f":"code","59c8f090":"code","dd323022":"code","731a813d":"code","85d3e3a7":"code","ab4fdf4d":"code","80f66f9e":"code","2291ea22":"code","983a0776":"code","8b142f29":"code","d790c65e":"code","ea0918cb":"code","2e394d26":"code","7950af8e":"code","97af0c07":"code","aac700d5":"code","afcf5d99":"code","c8813bb6":"code","a61bb81f":"code","afeb34bc":"code","9ba514b3":"code","5749b5e5":"code","bab1268b":"code","7b8e471a":"code","34667b6c":"code","d3340026":"code","aab95cd8":"code","d5a6a53e":"code","6008be07":"code","d0b45485":"markdown","4547a36b":"markdown","64cac621":"markdown","496e4912":"markdown","508c78f0":"markdown","0251ea18":"markdown","0008d9e6":"markdown","dbbec554":"markdown","11ab8442":"markdown","51b93b9f":"markdown"},"source":{"8b92da96":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport tensorflow as tf","070a38a3":"dataset = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndataset_test =pd.read_csv('..\/input\/digit-recognizer\/test.csv')","1831cd0e":"dataset_test","e79e633f":"dataset","59c8f090":"dataset.isnull().sum().any()","dd323022":"plt.figure(figsize = (14,7))\nsns.countplot(x = 'label' , data = dataset)\nplt.xlabel('Label'  )\nplt.ylabel('Count')\nplt.show()","731a813d":"X = dataset.drop('label' , axis = 1).values\nX_test = dataset_test.values\nY = dataset.label\nY","85d3e3a7":"X","ab4fdf4d":"Y","80f66f9e":"# here we can also use OneHotEncoder for getting dummies \n# Donot use Label Encoder ","2291ea22":"Y= np.array(pd.get_dummies(Y))","983a0776":"Y","8b142f29":"X= X \/255\nX_test = X_test\/ 255","d790c65e":"X = X.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)","ea0918cb":"X.shape , X_test.shape , Y.shape ","2e394d26":"from sklearn.model_selection import train_test_split\nX_train , X_test_test ,Y_train , Y_test_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)","7950af8e":"\nfrom tensorflow.keras.layers import Dropout","97af0c07":"cnn = tf.keras.models.Sequential()","aac700d5":"\ncnn.add(tf.keras.layers.Conv2D(filters = 32 , kernel_size =3 , activation = 'relu', input_shape = [28,28,1]))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","afcf5d99":"## second Convolutional layes \n\ncnn.add(tf.keras.layers.Conv2D(filters = 32 , kernel_size =3 , activation = 'relu'))\n\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","c8813bb6":"# third Conv. layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32 , kernel_size =3 , activation = 'relu'))\n# max_pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","a61bb81f":"# flattening\ncnn.add(tf.keras.layers.Flatten())\n\ncnn.add(Dropout(0.5))","afeb34bc":"# full connection\ncnn.add(tf.keras.layers.Dense(units = 128 ,activation= 'relu', ))\ncnn.add(Dropout(0.5))\n","9ba514b3":"# Output_layes\ncnn.add(tf.keras.layers.Dense(units = 10, activation = 'softmax'))","5749b5e5":"cnn.compile(optimizer ='nadam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])","bab1268b":"cnn.summary()","7b8e471a":"cnn.fit(X_train , Y_train , epochs = 32 , batch_size = 100, validation_data = (X_test_test , Y_test_test))","34667b6c":"Y_pred = cnn.predict(X_test)","d3340026":"\nY_pred = np.argmax(Y_pred,axis=1)","aab95cd8":"Y_pred","d5a6a53e":"my_submission = pd.DataFrame({'ImageId': list(range(1, len(Y_pred)+1)), 'Label': Y_pred})\nmy_submission.to_csv('submission.csv', index=False)","6008be07":"# If you like my notebook please Upvote my work , It would make my day","d0b45485":"## predicting Test set Result ","4547a36b":"## submission  Test_set_result ","64cac621":"## Importing dataset","496e4912":"## spliting Dataset into Train , Test set","508c78f0":"## Getting Dummies of Labels ","0251ea18":"## Feature scalling (Normalization)","0008d9e6":"## Convolutional Neural Network (CNN)","dbbec554":"## Visualizing Labels","11ab8442":"## Test_set Accuracy =  98.35 %","51b93b9f":"## Importing Libraries "}}