{"cell_type":{"a56029ba":"code","a31e97fa":"code","99d129b7":"code","c7c1bb4e":"code","6dd6f2ad":"code","92aad4db":"code","d10f94d7":"code","b2761c0a":"code","a51f78a4":"code","d695afbb":"code","8fa26c5c":"code","42c1e901":"markdown","ce537178":"markdown","4df4d0f5":"markdown","44146d66":"markdown","ef5b3dbb":"markdown","93260af2":"markdown","67a4c3fe":"markdown","c744e514":"markdown"},"source":{"a56029ba":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","a31e97fa":"!pip install gwpy> \/dev\/null","99d129b7":"from gwpy.timeseries import TimeSeries\nlh = TimeSeries.fetch_open_data('H1', 1126259458+3.5, 1126259458+3.5+2,)\nspecgram = lh.spectrogram2(fftlength=1\/16., overlap=15\/256.) ** (1\/2.)\nspecgram.plot(figsize=(8, 2));\nplt.show()\nspecgram = lh.whiten(2, 1).spectrogram2(fftlength=1\/16., overlap=15\/256.) ** (1\/2.)\nspecgram.plot(figsize=(8, 2));\nplt.show()","c7c1bb4e":"import torch\nfrom torch.fft import fft, rfft, ifft\n\ndef whiten(signal):\n    hann = torch.hann_window(len(signal), periodic=True, dtype=float)\n    spec = fft(torch.from_numpy(signal).float()* hann)\n    mag = torch.sqrt(torch.real(spec*torch.conj(spec))) \n\n    return torch.real(ifft(spec\/mag)).numpy() * np.sqrt(len(signal)\/2)","6dd6f2ad":"plt.figure(figsize=(12, 4))\nplt.subplot(1, 3, 1)\nplt.plot(lh)\nplt.title(\"Raw Sample\")\nplt.subplot(1, 3, 2)\nplt.plot(lh.whiten(2,1))\nplt.title(\"GWPy Whitened\")\nplt.subplot(1, 3, 3)\nplt.title(\"nnAudio Whitened\")\nplt.plot(whiten(lh.value))\nplt.show()","92aad4db":"%timeit lh.whiten(2,0)\n%timeit whiten(lh.value)","d10f94d7":"!pip install -q nnAudio","b2761c0a":"from nnAudio.Spectrogram import CQT1992v2\ndef qgram(ts, \n           transform=CQT1992v2(sr=2048, fmin=20, fmax=2048\/2, hop_length=64)): # tweak parameters to make a 64x64 image\n    image = transform(torch.from_numpy(ts).float()) # returns a tensor of spectrograms of shape = (num_samples, freq_bins,time_steps)\n    image = image.squeeze().numpy()\n\n    return image","a51f78a4":"plt.figure(figsize=(12,7))\nplt.subplot(2,2,1)\nplt.imshow(lh.spectrogram2(fftlength=1\/32., overlap=1\/32-1\/64))\nplt.title(\"GWPy Unwhitened\")\n\nplt.subplot(2,2,2)\nplt.imshow(lh.whiten(2,0).spectrogram2(fftlength=1\/32., overlap=1\/32-1\/64.))\nplt.title(\"GWPy Whitened\")\n\nplt.subplot(2,2,3)\nplt.imshow(qgram(lh))\nplt.title(\"nnAudio Unwhitened\")\n\nplt.subplot(2,2,4)\nplt.imshow(qgram(whiten(lh)))\nplt.title(\"nnAudio Whitened\")\nplt.show()","d695afbb":"train_labels = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\nsample_submission = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\n\ndef id2path(idx,is_train=True):\n    path = \"..\/input\/g2net-gravitational-wave-detection\"\n    folder = 'train' if is_train else 'test'\n    return f'{path}\/{folder}\/{idx[0]}\/{idx[1]}\/{idx[2]}\/{idx}.npy'","8fa26c5c":"idLst1 = train_labels[train_labels.target == 1].sample(3).values.tolist()\nidLst0 = train_labels[train_labels.target == 0].sample(3).values.tolist()\n\nfor _id, target in idLst1+idLst0:\n    wave = np.load(id2path(_id,is_train=True))[0]\n    ts  = TimeSeries(wave, sample_rate=2048)\n    plt.figure(figsize=(14, 5))\n    \n    plt.subplot(131)\n    plt.imshow(ts.spectrogram2(fftlength=1\/32., overlap=1\/32-1\/64.))\n    plt.title(f\"Tgt={target} raw\")\n\n    plt.subplot(132)\n    plt.imshow(ts.whiten().spectrogram2(fftlength=1\/32., overlap=1\/32-1\/64.))\n    plt.title(\"Whiten\")","42c1e901":"While the use of Spectral Whitening did not lead to AUC improvments in my models I decided to document share this as experiments that fail are still valuable for the leassons that were learnt. \n\n## Spectral Whitening\n\nIn reviewing the examples given in [GWPy](https:\/\/gwpy.github.io\/docs\/stable\/examples\/spectrogram\/spectrogram2.html) I noticed the use of a technique called \"spectral wightening\" that was central to detecting the GW signal in the noice. Based on this work I decided to try:\n1. Standardizing each signal, i.e., dividing by the max value of the signal.\n2. Apply spectral whitening\n3. Convert that to a spectrogram\n4. Train a CNN to recognise the \"chirp\"\n\nTo implement this I made the following choices:\n* For the CNN I used a pre-trained EfficientNet. To make this easier to code I used Keras\n* I first tried to use the spectrogram code in GWPy however I found that nnAudio ran about 100x faster, so like many other I switched to using nnAudio to create the spectrogram on the fly.\n* I tried to use the GWPy whitening function but this was too slow. As I could not find a whitening function in nnAudio or other PyTorch modules I wrote my own. First I had to understand what whitening was, then I had to code for it.\n\n\nI then ran this, using EffficientNetB3, and found that whitening the signal gave a 10% lower AUC.","ce537178":"The charts of the whitened data below show the Torch version has similar but not quite the same output as GWPy. Comparing the GWPy [code](https:\/\/github.com\/gwpy\/gwpy\/blob\/v2.0.4\/gwpy\/timeseries\/timeseries.py#L1669), the key difference is  in the last line my algorithm use multiplication in frequency-space and GWPy uses convolution with a hann window in time-space. I think its the use of the hann window that results a slighly different envelope. ","4df4d0f5":"Again why not identical, we can see the tell tail signal of the 'chirp' in the spectrogram. However, when I used whitening in my modeling I found the AUC was substatially worse.","44146d66":"## Spectral Whitening\n\nMy first thought was just to use the GWPy tools however the spectrogram was 1 - 2 orders of magnitude slower than nnAudio. I switched to nnAudio and found I could generate the spectrograms of the fly, which was very convenient. \n\nHowever, I still had the problem that GWPy whitening  too slow so I set about building my own in torch to see how much faster this was. After much reading I implemented the following algorithm.","ef5b3dbb":"# What a real GW event looks like\nLoosely following the example in [GWPy](https:\/\/gwpy.github.io\/docs\/stable\/examples\/spectrogram\/spectrogram2.html) I read in a 2sec sample with known Gravity Wave event and create two spectrograms. \n1. The first, without whitening, the GW \"chirp\" can't be seen with the eye.\n2. The second, with whitening, clearly showsthe \"chip\" at the 0.4s mark starting at a low frequency (~30hx) and ramping up (~200hz) few hundrets of a second.\n \nLooking at how different these were I wondered if whitening could be used to improve my CNN model?","93260af2":"What is most notable is the PYtorch is about 10x faster when using a CPU ","67a4c3fe":"# Competition Data\nThe million dollar question is does this reveal the \"chirp\" signture for he competition data. \n\nIn the plots below we use the GWPy code, with the first column being the unwhitened spectrogram and the second whitened, but we don't get a dramatic result as we did with the real GW data.  Note the firs tthree are target =1 and the second three target =0","c744e514":"# Comparing Spectrogram\nTo show that the new torch function works just as well, I create spectrograms of teh whitened sample using GWPy vs nnAudio\/Torch"}}