{"cell_type":{"9b1bcd26":"code","729bdef6":"code","6671554f":"code","d5fe30c8":"code","63d48e10":"code","d91dce42":"code","422d5d24":"code","fcf422c5":"code","a5fb429d":"code","0713e39e":"code","ee04345f":"code","6c4a0913":"code","c227e4d7":"code","f84182b6":"code","4eecafa4":"code","11a4bbd2":"markdown","ddd636b4":"markdown","f77bc4d4":"markdown","05748884":"markdown","6f39ef0e":"markdown","56cd47dd":"markdown","1f3cbe26":"markdown"},"source":{"9b1bcd26":"import gc\nimport itertools\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Input, BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Multiply\n\nnp.random.seed(42)\ntf.random.set_seed(42)","729bdef6":"train_df = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntrain_df.set_index('id', inplace=True)\nprint(f\"train_df: {train_df.shape}\")\ntrain_df.head()","6671554f":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")\ntest_df.set_index('id', inplace=True)\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","d5fe30c8":"features = test_df.columns.tolist()\nlen(features)","63d48e10":"for col in tqdm(features):\n    train_df[col+'_bin'] = train_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n    test_df[col+'_bin'] = test_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0)\n\nprint(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")\ntrain_df.head()","d91dce42":"features = test_df.columns.tolist()\nprint(f\"Num features: {len(features)}\")","422d5d24":"train_df[features] = train_df[features].astype('float32')\ntest_df[features] = test_df[features].astype('float32')\nprint(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")","fcf422c5":"def plot_confusion_matrix(cm, classes):\n\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion matrix', fontweight='bold', pad=15)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontweight='bold')\n    plt.xlabel('Predicted label', fontweight='bold')\n    plt.tight_layout()","a5fb429d":"def dnn_model():\n    \n    x_input = Input(shape=(len(features),))\n    \n    x1 = Dense(units=384, activation='selu')(x_input)\n    x1 = BatchNormalization()(x1)\n    x2 = Dropout(rate=0.45)(x1)\n    \n    x2 = Dense(units=192, activation='selu')(x2)\n    x2 = BatchNormalization()(x2)\n    x3 = Dropout(rate=0.35)(x2)\n    \n    x3 = Dense(units=96, activation='selu')(x3)\n    x3 = BatchNormalization()(x3)\n    x3 = Dropout(rate=0.25)(x3)\n    \n    x4 = Dense(units=192, activation='selu')(x3)\n    x4 = BatchNormalization()(x4)\n    x4 = Multiply()([x2, x4])\n    x4 = Dropout(rate=0.35)(x4)\n    \n    x5 = Dense(units=384, activation='selu')(x4)\n    x5 = BatchNormalization()(x5)\n    x5 = Multiply()([x1, x5])\n    x5 = Dropout(rate=0.45)(x5)\n    \n    x = Concatenate()([x3, x5])\n    x = Dense(units=128, activation='selu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(rate=0.25)(x)\n    \n    x_output = Dense(units=1, activation='sigmoid')(x)\n\n    model = Model(inputs=x_input, outputs=x_output, \n                  name='DNN_Model')\n    return model","0713e39e":"model = dnn_model()\nmodel.summary()","ee04345f":"FOLD = 7\nVERBOSE = 0\nSEEDS = [13, 18]\nBATCH_SIZE = 1024\n\ncounter = 0\noof_score = 0\ny_pred_final_dnn = np.zeros((test_df.shape[0], 1))\ny_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n\n\nfor sidx, seed in enumerate(SEEDS):\n    seed_score = 0\n    \n    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n\n    for idx, (train, val) in enumerate(kfold.split(train_df[features], train_df['target'])):\n        counter += 1\n\n        train_x, train_y = train_df[features].iloc[train], train_df['target'].iloc[train]\n        val_x, val_y = train_df[features].iloc[val], train_df['target'].iloc[val]\n\n        model = dnn_model()\n        model.compile(optimizer=Adam(learning_rate=1e-2), \n                      loss=\"binary_crossentropy\", \n                      metrics=['AUC'])\n\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n                               patience=4, verbose=VERBOSE)\n        \n        chk_point = ModelCheckpoint(f'.\/Keras_DNN_Model_{counter}C.h5', \n                                    monitor='val_loss', verbose=VERBOSE, \n                                    save_best_only=True, mode='min')\n\n        es = EarlyStopping(monitor=\"val_loss\", patience=15, \n                           verbose=VERBOSE, mode=\"min\", \n                           restore_best_weights=True)\n        \n        model.fit(train_x, train_y, \n                  validation_data=(val_x, val_y), \n                  epochs=2000,\n                  verbose=VERBOSE,\n                  batch_size=BATCH_SIZE, \n                  callbacks=[lr, chk_point, es])\n        \n        model = load_model(f'.\/Keras_DNN_Model_{counter}C.h5')\n        \n        y_pred = model.predict(val_x, batch_size=BATCH_SIZE)\n        y_pred_meta_dnn[val] += y_pred\n        y_pred_final_dnn += model.predict(test_df, batch_size=BATCH_SIZE)\n        \n        score = roc_auc_score(val_y, y_pred)\n        oof_score += score\n        seed_score += score\n        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n        \n        del model, y_pred\n        del train_x, train_y\n        del val_x, val_y\n        gc.collect()\n    \n    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score \/ FOLD)))\n\n\ny_pred_meta_dnn = y_pred_meta_dnn \/ float(len(SEEDS))\ny_pred_final_dnn = y_pred_final_dnn \/ float(counter)\noof_score \/= float(counter)\nprint(\"Aggregate OOF Score: {}\".format(oof_score))","6c4a0913":"y_pred_meta = np.mean(y_pred_meta_dnn, axis=1)\ny_pred = (y_pred_meta>0.5).astype(int)\nprint(classification_report(train_df['target'], y_pred))","c227e4d7":"cnf_matrix = confusion_matrix(train_df['target'], y_pred, labels=[0, 1])\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(12, 5))\nplot_confusion_matrix(cnf_matrix, classes=[0, 1])","f84182b6":"np.savez_compressed('.\/TPS_1121_DNN_Meta_Features.npz',\n                    y_pred_meta_dnn=y_pred_meta_dnn,  \n                    y_pred_final_dnn=y_pred_final_dnn)","4eecafa4":"submit_df = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\nsubmit_df['target'] = y_pred_final_dnn.ravel()\nsubmit_df.to_csv(\"DNN_Submission.csv\", index=False)\nsubmit_df.head()","11a4bbd2":"## Feature Engineering","ddd636b4":"## Helper Function","f77bc4d4":"## Create submission file","05748884":"## Load source datasets","6f39ef0e":"## Import libraries","56cd47dd":"## Save meta features","1f3cbe26":"## Keras Model"}}