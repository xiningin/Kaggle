{"cell_type":{"a34bf0a1":"code","0c975470":"code","63860191":"code","92305a9b":"code","0dcb8d3c":"code","c9f546db":"code","f31ee997":"code","41d629ec":"code","8115b471":"code","8ef10384":"markdown","aa4b6731":"markdown","8ccc69da":"markdown"},"source":{"a34bf0a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0c975470":"#https:\/\/www.kaggle.com\/c\/quora-insincere-questions-classification\npath='\/kaggle\/input\/quora-insincere-questions-classification\/train.csv'\ntrain=pd.read_csv(path,nrows=1000)\ntrain.head()","63860191":"#Converting every character to lower case\ndocs=train['question_text'].str.lower()\nprint(docs.head())\nprint('\\n')\n\n#Remove non-alphabets\ndocs.str.replace('[^a-z ]','')\nprint(docs.head())\nprint('\\n')\n\n#Remove commonly used words\nimport nltk\nstopwords=nltk.corpus.stopwords.words('english')\nstemmer=nltk.stem.PorterStemmer()\nprint(stopwords)\nprint('\\n')\n\ndef clean_sentence(doc):\n    words=doc.split(' ')\n    words_clean=[stemmer.stem(word) for word in words if word not in stopwords]\n    return ' '.join(words_clean)\n    print(words_clean)\n    \ndocs=docs.apply(clean_sentence)\n","92305a9b":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\ndtm_vectorizer = CountVectorizer()\n\n\ntrain_x,validate_x, train_y,validate_y = train_test_split(docs, train['target'], test_size = 0.2, random_state = 1)\ndtm_vectorizer.fit(train_x)\ndtm_train = dtm_vectorizer.transform(train_x)\ndtm_validate = dtm_vectorizer.transform(validate_x)","0dcb8d3c":"dtm_train","c9f546db":"df_dtm_train = pd.DataFrame(dtm_train.toarray(),columns=dtm_vectorizer.get_feature_names(),index=train_x.index)\ndf_dtm_train","f31ee997":"df_dtm_train.sum().sort_values(ascending=False).head(20).plot.bar()","41d629ec":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB().fit(dtm_train,train_y)\ntrain_y_pred=model.predict(dtm_validate)\n\nfrom sklearn.metrics import accuracy_score,f1_score\nprint(accuracy_score(validate_y,train_y_pred))\nprint(f1_score(validate_y,train_y_pred))\n","8115b471":"#Sentiment Analysis\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nsentiment_analyzer=SentimentIntensityAnalyzer()\nsentiment_analyzer.polarity_scores('i like india')","8ef10384":"* target=0 means question can be asked in public forum\n* target=1 means insincere question\n* qid is just the ID -- we can ignore","aa4b6731":"# converting aplhabets into numbers - document term matrix\n To normalize in text mining.\n* Term frquency(TF)\n* Inverse doccumnet Frequency(IDF)","8ccc69da":"#Methods to convert text to numerical values\n- Document term Matrix\n- Using word2vec\/Doc2vec\n\n#Text cleaning\n- Convert every character to lower case\n- Using regular expression retain only alphabets (sometime numbers,#&@)\n- Remove commonly used words\n- Identify root from the word(stemming,lemmatization)"}}