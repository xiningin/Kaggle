{"cell_type":{"0e9b1895":"code","59e1fb9d":"code","39ef57ad":"code","5b3be3d0":"code","c50881af":"code","525301fd":"code","36221ed3":"code","c3df536c":"code","568f76a1":"code","e3c02b5a":"code","bf932430":"code","225d40aa":"code","32176e86":"code","8ee19b67":"code","1055c77a":"code","a5de63f9":"code","9ad9d504":"code","17969a6c":"code","6eb9f923":"code","30e30e14":"code","2b6f3cbe":"code","e4e454a5":"code","a73c6306":"code","91cf2d09":"code","4300a697":"markdown","24fd594f":"markdown","6ef8408e":"markdown","ec6c3336":"markdown","75a0277b":"markdown","904b58aa":"markdown","423530ae":"markdown","9c2bd53f":"markdown","c377398b":"markdown","7bd45960":"markdown","2e7bc47c":"markdown"},"source":{"0e9b1895":"!conda install dask -y\nimport dask\nimport dask.array as da\nimport dask.bag as db\nimport dask.dataframe as dd\nfrom dask.distributed import Client\n\n!pip install pydub\nfrom pydub import AudioSegment\nfrom pydub.utils import mediainfo\n\n!pip install zarr\nfrom zarr import Zlib, BZ2, LZMA, Blosc\n\nimport librosa, os, time, gc, json\nimport numpy as np\nimport h5py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\nfrom skimage.util.shape import view_as_windows, view_as_blocks\nimport tensorflow as tf\n\npd.set_option(\"display.max_columns\", 60)\npd.set_option(\"display.max_rows\", 120)","59e1fb9d":"temp_folder = '\/home\/dask_hdd'\nos.mkdir(temp_folder)\n\nclient = Client(memory_limit='4GB', local_directory=temp_folder)\nclient","39ef57ad":"audio = da.from_zarr('\/kaggle\/input\/bird-train')","5b3be3d0":"audio","c50881af":"%%time\nrecording = audio[20000:20500].compute()","525301fd":"recording","36221ed3":"train = pd.read_feather('\/kaggle\/input\/bird-train\/train.feather')\ntrain = train[train['len']>0]\n\nwindow_maxdim = np.prod(audio.shape[1:])\ntrain['shape'] = train['len'].map(lambda x: (x+window_maxdim-x%window_maxdim)\/window_maxdim)\ntrain['slice'] = train['shape'].cumsum().astype(int)\ntrain['slice'] = list(zip(train['slice'].shift(1,fill_value=0),train['slice']))\n\naudio_index = train['slice'].map(lambda x: slice(*x))\ntrain_index = train['slice'].apply(lambda x: np.arange(*x)).explode()\ntrain_index = pd.Series(train_index.index, index=train_index.astype(int))","c3df536c":"train.loc[5000]","568f76a1":"audio_index.loc[5000]","e3c02b5a":"recording = audio[audio_index.loc[5000]].compute()\nprint(recording.shape)","bf932430":"recording = recording.reshape(1,-1)\nipd.Audio(recording, rate=32000)","225d40aa":"train.loc[5000].path","32176e86":"recording_original = AudioSegment.from_mp3(train.loc[5000].path).set_frame_rate(32000).set_channels(1)\nrecording_original","8ee19b67":"recording = recording.ravel()\nrecording_original = np.array(recording_original.get_array_of_samples(), dtype=np.int32)\nnp.all(np.equal(recording[-recording_original.shape[0]:], recording_original))","1055c77a":"audio[99553]","a5de63f9":"train_index.loc[99553]","9ad9d504":"train.loc[train_index.loc[99553]]","17969a6c":"%%time\naudio.max().compute()","6eb9f923":"%%time\naudio.argmax().compute()","30e30e14":"%%time\nnp.unravel_index(1280089650, audio.shape)","2b6f3cbe":"audio[13151, 11, 13, 40].compute()","e4e454a5":"%%time\ngroupby_minmax = [dask.delayed(lambda x: (x.min(), x.max()))(audio[sli]) for sli in audio_index]","a73c6306":"%%time\ngroupby_minmax = db.compute(groupby_minmax)","91cf2d09":"groupby_minmax","4300a697":"**Double check to make sure we got the right one!**","24fd594f":"# Get max value of entire array\n\nGo through an entire 158gb array in under 2 minutes with only 16gb of ram!","6ef8408e":"**It's possible to retrieve any part of the array relatively fast.**","ec6c3336":"**Get exact position of max value**","75a0277b":"# Retrieve recording information from array row","904b58aa":"# Create index\n\n\nInside the dataset bird-train there is also a copy of the train dataframe with two columns \"len\" and \"path\" included.\n\nThe \"len\" column has the exact length of each audio sequence, and can be used to create an index. The length does not include left padding, so this has to be accounted for in the code. Also, some mp3 files could not be read, these were filtered out.\n\nThis way it's possible to create an index that maps a specific line of the train dataframe to a slice of the zarr array that contains that recording (audio_index). The inverse operation is also possible, map any array row to a specific entry in the train dataframe (train_index). ","423530ae":"# Bonus: group by recording and apply function\n\nGet min and max value of each recording.\n\nBe careful when calculating statistics like mean because the array has been zero padded. This can be accounted for during calculation. The processing notebook can also be modified to include numpy masked arrays.\n\nThe process takes about 3 minutes, but there may be more efficient ways to do this with Dask.","9c2bd53f":"# Retrieve recording from Zarr array","c377398b":"I took this competition as an opportunity to experiment with Dask and distributed computing. Everything was made using Kaggle kernels.\n\nIn a previous notebook I created a preprocessing scheme using **PyDub, Dask and Zarr** to read each MP3 file, resample it to 32MHz as recommended by this competition hosts, and extract only one audio channel.\n\nThe recording is then converted to a sequence stored as a NumPy array. Each audio sequence has been split into subsequences using a non overlapping moving window of size 46^3, or approximately 3 seconds of audio. These sequences are left padded with zeroes. The final shape of the array is (n,46,46,46), however it\u2019s also possible to slice and reshape it using the current solution or even create a different preprocessing scheme.\n\nFor example the first recording has 815616 steps and is splitted into an array of 9 rows.\n\nThe final result is stored as a compressed Zarr array composed of approximately 677 chunks totaling 42gb and uploaded as a Kaggle dataset. \n\nIf you find this useful, I can share the kernel where it\u2019s possible to adapt or alter the preprocessing to your own requirements.\n","7bd45960":"# Read Zarr dataset","2e7bc47c":"# Set up Dask Client"}}