{"cell_type":{"214e97f3":"code","fdb110d3":"code","1e401dd8":"code","42a8bb4f":"code","acf12674":"code","fad72940":"code","f476f6bd":"code","636e851e":"code","5aa4c8c1":"code","fd827a09":"code","04a5ad6c":"code","4f907381":"code","1c0aeb67":"code","fa951a74":"code","b0b62a10":"code","e994d53a":"code","ac806af3":"code","84a8c5d7":"code","98415919":"code","760458f6":"code","14ab5577":"code","305ff744":"code","72bcd2e1":"code","5a7ffb05":"code","7d3ccdc6":"code","208677fe":"code","1047e86d":"code","16ed9210":"code","dcca3e5e":"code","4af0da85":"code","aece9fec":"code","4848a2b5":"code","11dcf4b5":"code","badd3f45":"code","3e6ade9b":"code","4383d995":"code","5134db1f":"code","d8c063d5":"code","86272cb6":"code","57d9d0dc":"code","847f066d":"code","7b6c3485":"code","fd16ddc1":"code","4fbcd667":"code","c94134e4":"code","bf8e4a0f":"code","11133bc0":"code","40d68179":"code","0b0acf69":"code","2d830b26":"code","a6f28ac1":"code","85356bdc":"code","24bb7fe6":"code","ee0be820":"code","8550124d":"code","31468d84":"code","b809233a":"code","850aeaa0":"code","6d9f7743":"code","ca6c514d":"code","59fe15e2":"code","432882d0":"code","9d7327e8":"code","356bb6b4":"code","891530a7":"code","36031b39":"code","46430ccc":"code","bbe73e9e":"code","655f45f5":"code","3fee4873":"code","aeb31ae2":"code","49476d81":"code","f4066951":"code","eaec4a81":"code","550b970d":"code","999d5dd8":"code","70796140":"code","31d57dd6":"code","fb5e2d8a":"code","a37d00b4":"code","12f721c4":"code","0af4ec32":"code","ea1c1da8":"code","b9983f72":"code","33ef21be":"markdown","a54cc235":"markdown","4df9a3ce":"markdown","f359d594":"markdown","ddfa2dd1":"markdown","b0682b26":"markdown","b740cfc0":"markdown","865e16d2":"markdown","900aa9c2":"markdown","c109688c":"markdown","41820eba":"markdown","f3c86f40":"markdown","e48fb05a":"markdown","96fe74cb":"markdown","76e49154":"markdown","0fd9e3a8":"markdown","2b83ac9e":"markdown","b7cb15b9":"markdown","fefeb74a":"markdown","7bbb10b7":"markdown","c34326cd":"markdown","dc5affe4":"markdown","7f2172be":"markdown","831a703a":"markdown","9e8f0522":"markdown","23566ed8":"markdown","925df37d":"markdown","7b337d20":"markdown","c0a6845a":"markdown","0b2208c3":"markdown","fc4393a1":"markdown","22070bd3":"markdown","0d116594":"markdown","91583cd8":"markdown","d1268347":"markdown","caad547d":"markdown","644116dd":"markdown","86bf172b":"markdown","1f5e762d":"markdown","385f33b9":"markdown","7c727787":"markdown","6dcf804d":"markdown","acd54671":"markdown","b110f239":"markdown","04dd6ba6":"markdown","cf6a54b0":"markdown","0e54b082":"markdown","4aa985a4":"markdown","34eb3b1d":"markdown","8885518a":"markdown","fd1e440e":"markdown"},"source":{"214e97f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fdb110d3":"train_df=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_passengerid=test_df[\"PassengerId\"]\n#When i use the data in next steps i kept the passenger id in a variable to not lose passenger id feature(?)","1e401dd8":"train_df.columns","42a8bb4f":"train_df.head()# it shows first five rows","acf12674":"train_df.describe()","fad72940":"train_df.info()","f476f6bd":"def bar_plot(variable):\n    \n    # input: variable ex: \"Sex\"\n    # output: bar plot and value count\n\n    # get feature\n    var=train_df[variable]\n\n    #count number of categorical variable\n    varValue=var.value_counts()\n\n    #visualiza\n\n    plt.figure(figsize=(10,4)) #Size of figure\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{} \\n {}\".format(variable, varValue))\n\n","636e851e":"category = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\",\"Parch\"]\n\nfor i in category:\n  bar_plot(i)","5aa4c8c1":"category2 = [\"Cabin\",\"Name\",\"Ticket\"]\n\nfor i in category2:\n  print(\"{} \\n\".format(train_df[i].value_counts()))","fd827a09":"def plot_hist(variable):\n    plt.figure(figsize=(10,4))\n    plt.hist(train_df[variable])\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} Distribution with histogram\".format(variable))\n    plt.show()","04a5ad6c":"numericVariable=[\"Fare\",\"Age\",\"PassengerId\"]\nfor i in numericVariable:\n    plot_hist(i)","4f907381":"#Pclass-Survived\n\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","1c0aeb67":"#Sex-Survived\n\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","fa951a74":"#Age-Survived\n\ntrain_df[[\"Age\",\"Survived\"]].groupby([\"Age\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","b0b62a10":"#Sibsp-Survived\n\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","e994d53a":"#Parch-Survived\n\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","ac806af3":"def detect_outliers(df,features):\n    outlier_indices=[]\n    for i in features:\n        \n        # 1st quartile\n        Q1=np.percentile(df[i],25)\n    \n        # 3rd quartile\n        Q3=np.percentile(df[i],75)\n        \n        #IQR\n        IQR=Q3-Q1\n        \n        #Outlier step\n        Outlier_Step=IQR*1.5\n        \n        \n        #detect outlier and their indeces\n        outlier_list=df[(df[i]<Q1-Outlier_Step) | (df[i]>Q3-Outlier_Step)].index\n        #store indeces\n        outlier_indices.extend(outlier_list)\n    outlier_indices=Counter(outlier_indices)#her sample ka\u00e7 tane outlier i\u00e7eriyoru bulur. \n    #Bunu neden yap\u0131yoruz? e\u011fer birden fazla featureda outlier varsa o sample \u0131 yani yolcuyu \u00f6yle \u00e7\u0131kar\u0131r\u0131z.\n    #Bir yolcu i\u00e7in sadece bir feature da outlier varsa \u00e7\u0131karmaya gerek kalmaz.a\u015fa\u011f\u0131da kodu\n    multiple_outliers=list(i for i, v in outlier_indices.items() if v>2)\n    \n    return multiple_outliers\n","84a8c5d7":"train_df.loc[detect_outliers(train_df,[\"Age\",\"Fare\",\"SibSp\",\"Parch\"])]","98415919":"#drop outliers\n\ntrain_df=train_df.drop(detect_outliers(train_df,[\"Age\",\"Fare\",\"SibSp\",\"Parch\"]),axis=0).reset_index(drop=True)\n#axis=0 means is delete the rows(?)","760458f6":"train_df_len=len(train_df)\ntrain_df=pd.concat([train_df,test_df],axis=0).reset_index(drop=True)\n","14ab5577":"train_df.head()","305ff744":"train_df.columns[train_df.isnull().any()]","72bcd2e1":"train_df.isnull().sum()","5a7ffb05":"train_df[train_df[\"Embarked\"].isnull()]","7d3ccdc6":"train_df.boxplot(column=\"Fare\", by =\"Embarked\")\nplt.show()","208677fe":"train_df[\"Embarked\"]=train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]\n","1047e86d":"train_df[train_df[\"Fare\"].isnull()]","16ed9210":"train_df[\"Fare\"]=train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"]==3][\"Fare\"]))\ntrain_df[train_df[\"Fare\"].isnull()]","dcca3e5e":"list=[\"SibSp\",\"Parch\",\"Age\",\"Fare\",\"Survived\"]\nsns.heatmap(train_df[list].corr(),annot=True,fmt=\".2f\")#with annot i can see the correlation values\nplt.show()","4af0da85":"g=sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train_df,kind=\"bar\",size=6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","aece9fec":"g=sns.factorplot(x=\"Parch\",y=\"Survived\",kind=\"bar\",data=train_df,size=6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","4848a2b5":"g=sns.factorplot(x=\"Pclass\",y=\"Survived\",kind=\"bar\",data=train_df,size=6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","11dcf4b5":"g=sns.FacetGrid(train_df,col=\"Survived\")\ng.map(sns.distplot, \"Age\",bins=25)\nplt.show()","badd3f45":"g=sns.FacetGrid(train_df,col=\"Survived\",row=\"Pclass\",size=3)\ng.map(plt.hist,\"Age\",bins=25)\ng.add_legend()#(?)\nplt.show()","3e6ade9b":"g=sns.FacetGrid(train_df,row=\"Embarked\",size=3)\ng.map(sns.pointplot,\"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","4383d995":"g=sns.FacetGrid(train_df,row=\"Embarked\",col=\"Survived\",size=3)\ng.map(sns.barplot, \"Sex\",\"Fare\")\ng.add_legend()\nplt.show()","5134db1f":"train_df[train_df[\"Age\"].isnull()]","d8c063d5":"g=sns.factorplot(x=\"Sex\",y=\"Age\",data=train_df,kind=\"box\",size=6)\nplt.show()","86272cb6":"g=sns.factorplot(x=\"Sex\",y=\"Age\",hue=\"Pclass\",data=train_df,kind=\"box\",size=6)\nplt.show()","57d9d0dc":"g=sns.factorplot(x=\"Parch\",y=\"Age\",data=train_df,kind=\"box\",size=6)\nsns.factorplot(x=\"SibSp\",y=\"Age\",data=train_df,kind=\"box\",size=6)\nplt.show()","847f066d":"train_df[\"Sex\"]=[1 if i==\"male\" else 0 for i in train_df[\"Sex\"]]\n#The Sex feature is string. To see it in heatmap, we should convert \"Sex feature\" to integer.","7b6c3485":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),annot=True)\nplt.show()","fd16ddc1":"\n\nfor i in  train_df[\"Age\"][train_df[\"Age\"].isnull()].index.tolist():\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    \n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med\n#Datam\u0131zda ki ki\u015filerden 5 nolu indexteki ki\u015fi ile ayn\u0131 \"SibSp\" \"Pclass\" ve \"Parch\"\n#de\u011ferine sahip ki\u015fileri al bunlar\u0131n \"Age\" de\u011ferlerinin median\u0131n\u0131 hesapla \n#ve age olarak bu de\u011fere e\u015fitle,\n#Yani ya\u015f\u0131 olmayan her ki\u015finin ya\u015f\u0131n\u0131, bu 3 de\u011feri ayn\u0131 olan ki\u015filerin median\u0131n\u0131 alarak dolduruyoruz,\n","4fbcd667":"train_df[\"Name\"].head()","c94134e4":"name=train_df[\"Name\"]\ntrain_df[\"Title\"]=[i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","bf8e4a0f":"train_df[\"Title\"].head(10)","11133bc0":"sns.countplot(x=\"Title\",data=train_df)\nplt.xticks(rotation=60)\nplt.show()","40d68179":"#rare olanlar\u0131 other alt\u0131nda topluyorum\n#Convert to categorical\ntrain_df[\"Title\"]=train_df[\"Title\"].replace([\"Major\",\"Lady\",\"Sir\",\"Col\",\"the Countess\",\"Jonkheer\",\"Dona\",\"Don\",\"Rev\",\"Dr\"],\"other\")\n\ntrain_df[\"Title\"]=[0 if i==\"Master\" else 1 if i==\"Miss\" or i==\"Ms\" or i==\"Mlle\" or i==\"Mrs\" else 2 if i==\"Mr\" else 3 for i in train_df[\"Title\"]]","0b0acf69":"sns.countplot(x=\"Title\",data=train_df)\nplt.xticks(rotation=60)\nplt.show()","2d830b26":"train_df[\"Title\"].head(30)","a6f28ac1":"g=sns.factorplot(x=\"Title\",y=\"Survived\",data=train_df,kind=\"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","85356bdc":"#Name kullanrak yeni feature elde ettim title olarak dolay\u0131s\u0131yla name e gerek yok art\u0131k\ntrain_df.drop(labels=[\"Name\"], axis=1, inplace=True)\n","24bb7fe6":"train_df.head()","ee0be820":"train_df=pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","8550124d":"# SibSp ve Parch birle\u015fiyor\ntrain_df[\"FaSize\"]=train_df[\"SibSp\"]+train_df[\"Parch\"]+1\n#art\u0131 bir, bireyin kendisini ifade ediyor.","31468d84":"train_df.head()","b809233a":"g=sns.factorplot(x=\"FaSize\",y=\"Survived\",data=train_df,kind=\"bar\",size=6)\ng.set_ylabels(\"Survival\")\nplt.show()","850aeaa0":"train_df[\"family_size\"]=[1 if i <5 else 0 for i in train_df[\"FaSize\"]]","6d9f7743":"train_df.head(20)","ca6c514d":"sns.countplot(x=\"family_size\",data=train_df)\nplt.show()","59fe15e2":"g=sns.factorplot(x=\"family_size\",y=\"Survived\",data=train_df,kind=\"bar\",size=6)\ng.set_ylabels(\"Survival\")\nplt.show()","432882d0":"train_df=pd.get_dummies(train_df,columns=[\"family_size\"])\ntrain_df.head()","9d7327e8":"train_df[\"Embarked\"].head()","356bb6b4":"sns.countplot(x=\"Embarked\",data=train_df)\nplt.show()","891530a7":"#Embarked i kullan\u0131labilir hale getiriyoruz\ntrain_df=pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","36031b39":"train_df[\"Ticket\"].head(10)","46430ccc":"tickets=[]\n\nfor i in train_df.Ticket:\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\n        \ntrain_df[\"Ticket\"]=tickets","bbe73e9e":"train_df[\"Ticket\"].head(10)","655f45f5":"train_df=pd.get_dummies(train_df,columns=[\"Ticket\"],prefix=\"T\")\ntrain_df.head()","3fee4873":"sns.countplot(data=train_df,x=\"Pclass\")\nplt.show()","aeb31ae2":"train_df[\"Pclass\"]=train_df[\"Pclass\"].astype(\"category\")\ntrain_df=pd.get_dummies(train_df,columns=[\"Pclass\"])\ntrain_df.head()","49476d81":"train_df[\"Sex\"]=train_df[\"Sex\"].astype(\"category\")\ntrain_df=pd.get_dummies(train_df,columns=[\"Sex\"])\ntrain_df.head()","f4066951":"train_df.drop(labels=[\"PassengerId\",\"Cabin\"],axis=1,inplace=True)# these are not useful, they unnecessary\ntrain_df.columns","eaec4a81":"#Libraries\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","550b970d":"train_df_len#dataframe mizin boyutu","999d5dd8":"test=train_df[train_df_len:]#sondan al\ntest.drop(labels=\"Survived\",axis=1,inplace=True)\ntest.head(30)","70796140":"train=train_df[:train_df_len]\nx_train=train.drop(labels=\"Survived\",axis=1)\ny_train=train[\"Survived\"]\n\nx_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.33,random_state=42)\n\n\nprint(\"x_train: \",len(x_train))\nprint(\"x_test: \",len(x_test))\nprint(\"y_train: \",len(y_train))\nprint(\"y_test: \",len(y_test))\nprint(\"test: \",len(test))\n","31d57dd6":"lr=LogisticRegression()\nlr.fit(x_train,y_train)\nlr_train_score=round(lr.score(x_train,y_train)*100,2)\nlr_test_score=round(lr.score(x_test,y_test)*100,2)\n\nprint(\"Training Accuracy:%{} \".format(lr_train_score))\nprint(\"Testing Accuracy:%{} \".format(lr_test_score))","fb5e2d8a":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]","a37d00b4":"\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","12f721c4":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(x_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","0af4ec32":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")\n","ea1c1da8":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(x_train, y_train)\nprint(accuracy_score(votingC.predict(x_test),y_test))","b9983f72":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_passengerid, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","33ef21be":"<a id=\"28\"><\/a>\n## Drop PassengerId and Cabin","a54cc235":"<a id=\"16\"><\/a>\n## Age--Survived","4df9a3ce":"<a id=\"32\"><\/a>\n## Hyper Parameter Tuning--Grid Search--Cross Validation\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","f359d594":"<a id=\"8\"><\/a>\n# Missing Value\n* Find Missing Value\n* Fill Missing Value","ddfa2dd1":"* First class passengers are older than second class passengers. Second class passengers are older than first class passenger.","b0682b26":"<a id=\"6\"><\/a>\n# Basic Data Anlaysis\n\n* Pclass-Survived\n* Sex-Survived\n* Age-Survived\n* SibSp-Survived\n* Parch-Survived","b740cfc0":"<a id=\"30\"><\/a>\n## Train Test Split","865e16d2":"<a id=\"22\"><\/a>\n## Name--Title","900aa9c2":"<a id=\"33\"><\/a>\n## Ensemble Modelling","c109688c":"<a id=\"1\"><\/a>\n# Load and Check Data","41820eba":"* Passenger who pay higher fare have better survival rate. Fare can be used as categorical for training.","f3c86f40":"<a id=\"29\"><\/a>\n# Modelling","e48fb05a":"<a id=\"11\"><\/a>\n# Visualization","96fe74cb":"<a id=\"13\"><\/a>\n## SibSp--Survived","76e49154":"* Age is not correlated with Sex, but it is correlated with SibSp, Parch, Pclass.","0fd9e3a8":" # Introduction\n \n RMS Titanic sank in 1912 in the North Atlantic Ocean, four days into her maiden voyage from Southampton to New York City. Titanic had an estimated 2,224 people on board when she struck an iceberg at around 23:40 (ship's time) on Sunday, 14 April 1912. Her sinking two hours and forty minutes later at 02:20 (ship's time; 05:18 GMT) on Monday, 15 April, resulted in the deaths of more than 1,500 people, making it one of the deadliest peacetime maritime disasters in history.","2b83ac9e":"* The Passengers who have no Parch have more chance to survive.\n* The Passengers who have Parch have not chance to survive.\n* Siyah ok standart sapmay\u0131 g\u00f6sterir.\n* SibSp and Parch can be used for new feature extraction with th=1","b7cb15b9":"<a id=\"25\"><\/a>\n## Pclass","fefeb74a":"<a id=\"15\"><\/a>\n## Pclass--Survived","7bbb10b7":"<a id=\"20\"><\/a>\n## Filling Missing: Age Feature","c34326cd":"<a id=\"12\"><\/a>\n## Correlation Between SibSp--Parch--Age--Fare--Survived","dc5affe4":"<a id=\"7\"><\/a>\n# Outlier Detection\n\n### What is Outlier?\n\nIf there is a value in a data set that differs greatly from other values, that value may affect the result incorrectly. For example, if the numbers are 2,4,6,7,8,78 in a series of numbers, the number 78 prevents the average from reflecting the reality. So the outlier is 78.\n\n### How Can We Detect the Outliers?\n\nThere are a variety of techniques which we can use to identify the outliers in a data set.\n* We find our quartile1(Q1),quartile3(Q3) and median values. \n* Then we find IQR(Q3-Q1)\n* Multiply IQR with 1.5 (Finding outlier step)\n* Q1-outlier step || Q3-outlier step\n* Q1-outlier stepis show lower bound to values\n* Q3-outlier step is show upper bound to values\n* As a result, Values outside the upper bound and lower bound are detected as outliers","7f2172be":"Yukar\u0131da d\u00f6rt feature a d\u00f6n\u00fc\u015ft\u00fcrd\u00fck ve e\u011fer title 2 ise o bir oluyor.","831a703a":"<a id=\"10\"><\/a>\n## Fill Missing Value\n\n* Embarked has 2 missing value\n* Fare has only one","9e8f0522":"* Having a lot of Siblings\/Spoises have less chance to survive.\n* if SibSp==0,1,2 and passengers have more chance to survive\n* We see that if SibSp==3 passengers have almost %100 chance to survive.\n* We can consider a new feature describing these features.\n* There is a std in survival of passengers with parch=2","23566ed8":"<font color=\"blue\">\nContent:\n    \n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n   * [Univariate Variable Analysis](#3)\n      * [Categorical Variable ](#4)\n      * [Numerical Variable ](#5)\n3. [Basic Data Anlaysis](#6)\n4. [Outlier Detection](#7)\n4. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n4. [Visualization](#11)   \n   * [Correlation Between SibSp--Parch--Age--Fare--Survived](#12)\n   * [SibSp--Survived](#13)\n   * [Parch--Survived](#14)\n   * [Pclass--Survived](#15)\n   * [Age--Survived](#16)\n   * [Pclass--Survived--Age](#17)\n   * [Embarked--Sex--Pclass--Survived](#18)\n   * [Embarked--Sex--Fare--Survived](#19)\n   * [Filling Missing: Age Feature](#20)\n5. [Feature Engineering](#21)\n   * [Name--Title](#22)\n   * [Family Size](#23)\n   * [Embarked](#24)\n   * [Ticket](#25)\n   * [Pclass](#26)\n   * [Sex](#27)\n   * [Drop PassengerId and Cabin](#28)\n5. [Modelling](#29)\n   * [Train Test Split](#30)\n   * [Simple Logistic Regression](#31)\n   * [Hyper Parameter Tuning--GridSearch--Cross Validation](#32)\n   * [Ensemble Modelling](#33)\n   * [Prediction and Submission](#34)","925df37d":"Fare feature has correlation with Survived feature(0.30).","7b337d20":"<a id=\"14\"><\/a>\n## Parch--Survived","c0a6845a":"<a id=\"17\"><\/a>\n## Pclass--Survived--Age","0b2208c3":"<a id=\"21\"><\/a>\n# Feature Engineering","fc4393a1":"* As we see from the plot, Pclass have great result.","22070bd3":"<a id=\"25\"><\/a>\n## Ticket","0d116594":"<a id=\"18\"><\/a>\n## Embarked--Sex--Pclass--Survived","91583cd8":"<a id=\"26\"><\/a>\n## Sex","d1268347":"* We can see that small families have more chance to survival than big families.","caad547d":"<a id=\"2\"><\/a>\n# Variable Description\n\n1. PassengerId: unique id number to each passenger\n2. Survived: Passenger survive(1) or died(0)\n3. Pclass: Passenger class\n4. Name: Name of passenger\n5. Sex: Gender of passenger     \n6. Age: Age of passenger\n7. SibSp: Number of siblings\/spouses\n8. Parch: Number of parents\/children\n9. Ticket: Number of ticket\n10. Fare: Amount of money spend on ticket\n11. Cabin: Cabin category\n12. Embarked: Port where passenger embarked(C=Cherbourg, Q=Queenstown,S=Southampton)","644116dd":"<a id=\"9\"><\/a>\n## Find Missing Value","86bf172b":"* float64(2): Age and Fare\n* int64(5): PassengerId, Survived, Pclass, SibSp, Parch\n* object(5): Name, Sex, Ticket, Cabin, Embarked","1f5e762d":"* It is clear that Pclass is effect the chance of survival.\n* Pclass is important feature to model training.","385f33b9":"* Age <=10 has a high survival rate.\n* Oldest passengers survived.\n* Large number of 20s  did not survived.\n* Most passengers are in 20-40 age range.\n* We can use age feature in training.\n* We can use age distribution for missing value of age.","7c727787":"<a id=\"24\"><\/a>\n## Embarked","6dcf804d":"<a id=\"31\"><\/a>\n## Simple Logistic Regression","acd54671":"<a id=\"19\"><\/a>\n## Embarked--Sex--Fare--Survived","b110f239":"<a id=\"23\"><\/a>\n## Family Size","04dd6ba6":"<a id=\"3\"><\/a>\n# Univariate Variable Analysis\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Parch\n\n* Numerical Variable: Fare, Age, PassengerId","cf6a54b0":"<a id=\"34\"><\/a>\n## Prediction and Submission","0e54b082":"* Horizontal line is shows the median.\n* Males and Females median are close each other. Age distribution seems to be same.\n* So Sex is not informative for age prediction.","4aa985a4":"* The color is white because our heatmap command scales the rows before drawing the heatmap. \n* So the row  becomes a row of zeroes and zero is denoted by white in this color scheme.","34eb3b1d":"<a id=\"5\"><\/a>\n## Numerical Variable","8885518a":"<a id=\"4\"><\/a>\n## Categorical Variable\n","fd1e440e":"* Female passengers have much better survival rate than  males.\n* Male passengers have better survival rate in pclass 3 in C.\n* Embarked and Sex features will be used in training."}}