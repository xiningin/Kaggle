{"cell_type":{"e5bcdcd2":"code","11e833cf":"code","83dd8aab":"code","2588675b":"code","4c55fa7f":"code","d9a051d3":"code","a6d1dadf":"code","01dd326f":"code","337d00e5":"code","3033bec2":"code","985d1dc8":"code","473f92ae":"code","8140acde":"code","3f95edd1":"code","9862fec2":"code","977260b4":"code","aee15105":"code","d9b63840":"code","d5b687bd":"code","275257cc":"code","19aaf943":"markdown"},"source":{"e5bcdcd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","11e833cf":"import matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.metrics import mean_absolute_error, make_scorer\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.model_selection import KFold","83dd8aab":"train = pd.read_csv('..\/input\/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})","2588675b":"train.head()","4c55fa7f":"# pandas doesn't show us all the decimals\npd.options.display.precision = 15","d9a051d3":"# much better!\ntrain.head()","a6d1dadf":"# Create a training file with simple derived features\nrows = 150_000\n# shift_step for augmented training set\nshift_step = int(np.floor(rows \/ 2))\nsegments = int(np.floor(train.shape[0] \/ rows))\nsegments_augmented = 2*segments - 1\n\nX_train = pd.DataFrame(index=range(segments_augmented), dtype=np.float64,\n                       columns=['ave', 'std', 'max', 'min','q95','q99', 'q05','q01'])\ny_train = pd.DataFrame(index=range(segments_augmented), dtype=np.float64,\n                       columns=['time_to_failure'])\n\n\nfor segment in tqdm(range(segments)):\n    for do_shift in [False,True]:        \n        if(do_shift):\n            shift = shift_step\n            idx = segments + segment            \n            if(segment==segments-1): #last segment would be incomplete for the shifted version\n                continue\n        else:\n            shift = 0\n            idx = segment\n        \n        seg = train.iloc[segment*rows+shift:segment*rows+shift+rows]\n\n        x = seg['acoustic_data'].values\n        y = seg['time_to_failure'].values[-1]\n\n        y_train.loc[idx, 'time_to_failure'] = y\n\n        X_train.loc[idx, 'ave'] = x.mean()\n        X_train.loc[idx, 'std'] = x.std()\n        X_train.loc[idx, 'max'] = x.max()\n        X_train.loc[idx, 'min'] = x.min()\n        X_train.loc[idx, 'q95'] = np.quantile(x,0.95)\n        X_train.loc[idx, 'q99'] = np.quantile(x,0.99)\n        X_train.loc[idx, 'q05'] = np.quantile(x,0.05)\n        X_train.loc[idx, 'q01'] = np.quantile(x,0.01)\n\n    ","01dd326f":"X_train.shape","337d00e5":"# check new segments\nX_train.loc[[0,1,2,3,4,0+segments,1+segments,2+segments,3+segments]]","3033bec2":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)","985d1dc8":"nFolds = 3\n# custom kfold to remove segments in train set which share regions with validation set\ncustomKFoldAvoidLeakToValidation = []\nfor train_id, valid_id in KFold(nFolds,shuffle=True).split(X_train):\n    must_remove = []    \n    for v in valid_id:       \n        if(v>=segments):                \n            must_remove.append(v-segments)\n            must_remove.append(v-segments+1)                \n        else:                \n            must_remove.append(v+segments-1)\n            must_remove.append(v+segments)                \n    train_id = [t for t in train_id if t not in (must_remove)]\n    customKFoldAvoidLeakToValidation.append((train_id, valid_id)) ","473f92ae":"scorer = make_scorer(mean_absolute_error, greater_is_better=False)","8140acde":"parameters = [{ 'gamma': [0.6, 0.7, 0.8],\n               'C': [2.35, 2.4, 2.45, 2.5],\n              'nu': [0.85, 0.9, 0.95]}]\n\n##best_params_\n#parameters = [{'C': [2.35], 'gamma': [0.6], 'nu': [0.9]}]\n\nreg1 = GridSearchCV(NuSVR(kernel='rbf', tol=0.01), parameters, cv = customKFoldAvoidLeakToValidation, scoring=scorer)\nreg1.fit(X_train_scaled, y_train.values.flatten())\ny_pred1 = reg1.predict(X_train_scaled)\n\nprint(reg1.best_params_)\nprint(reg1.best_score_)","3f95edd1":"parameters = [{'gamma': [0.06, 0.1, 0.08, 0.09], #np.logspace(-2, 2, 5)\n               'alpha': [0.005, 0.01, 0.05]}]\n\n#best_params_\n#parameters = [{'alpha': [0.05], 'gamma': [0.06]}]\n\nreg2 = GridSearchCV(KernelRidge(kernel='rbf'), parameters, cv = customKFoldAvoidLeakToValidation, scoring=scorer)\nreg2.fit(X_train_scaled, y_train.values.flatten())\ny_pred2 = reg2.predict(X_train_scaled)\n\nprint(reg2.best_params_)\nprint(reg2.best_score_)","9862fec2":"plt.tight_layout()\nf = plt.figure(figsize=(12, 6))\nf.add_subplot(1,2, 1)\nplt.scatter(y_train.values.flatten(), y_pred1)\nplt.title('reg1', fontsize=20)\nplt.xlim(0, 20)\nplt.ylim(0, 20)\nplt.xlabel('actual', fontsize=12)\nplt.ylabel('predicted', fontsize=12)\nplt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\nf.add_subplot(1,2, 2)\nplt.scatter(y_train.values.flatten(), y_pred2)\nplt.title('reg2', fontsize=20)\nplt.xlim(0, 20)\nplt.ylim(0, 20)\nplt.xlabel('actual', fontsize=12)\nplt.ylabel('predicted', fontsize=12)\nplt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\nplt.show(block=True)","977260b4":"score1 = mean_absolute_error(y_train.values.flatten(), y_pred1)\nprint(f'Score1: {score1:0.3f}')\nscore2 = mean_absolute_error(y_train.values.flatten(), y_pred2)\nprint(f'Score2: {score2:0.3f}')\nscore3 = mean_absolute_error(y_train.values.flatten(), (0.5*y_pred1 + 0.5*y_pred2 ) )\nprint(f'Score3: {score3:0.3f}')","aee15105":"submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='seg_id')","d9b63840":"X_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)","d5b687bd":"for seg_id in X_test.index:\n    seg = pd.read_csv('..\/input\/test\/' + seg_id + '.csv')\n    \n    x = seg['acoustic_data'].values\n    \n    X_test.loc[seg_id, 'ave'] = x.mean()\n    X_test.loc[seg_id, 'std'] = x.std()\n    X_test.loc[seg_id, 'max'] = x.max()\n    X_test.loc[seg_id, 'min'] = x.min()\n    X_test.loc[seg_id, 'q95'] = np.quantile(x,0.95)\n    X_test.loc[seg_id, 'q99'] = np.quantile(x,0.99)\n    X_test.loc[seg_id, 'q05'] = np.quantile(x,0.05)\n    X_test.loc[seg_id, 'q01'] = np.quantile(x,0.01)","275257cc":"X_test_scaled = scaler.transform(X_test)\npredictions_submit = 0.5*reg1.predict(X_test_scaled) + 0.5*reg2.predict(X_test_scaled) \n#remove non-positive predictions\npredictions_submit = predictions_submit.clip(min=0)\nsubmission['time_to_failure'] = predictions_submit\nsubmission.to_csv('submission.csv')","19aaf943":"The aim of this kernel is to test (and share) the effect of augmenting training set, applying it to the initial kernel \"Basic Feature Benchmark with Quantiles\" [https:\/\/www.kaggle.com\/andrekos\/basic-feature-benchmark-with-quantiles] and considering first approach of \"Basic Feature Benchmark\" [https:\/\/www.kaggle.com\/inversion\/basic-feature-benchmark]\n\nFrom the initial approach of dividing the training set in (n\/150_00) segments, this solution **doubles the number of segments** under the following conditions:\n*  it avoids creating segments very similar to each other (with more than 50% of overlaping regions): each new segment shares 50% of 2 sequential segments (as in Figure 1 below); \n*  it uses custom split iterator in order to avoid segments in train set which share regions with segments in validation set.\n\nFigure 1: ![](https:\/\/i.imgur.com\/rovjuNK_d.jpg?maxwidth=640&fidelity=medium)\n\nApparently this augmentation does not change the results significantly (not with the features currently used).\n\nNot completely tested yet. Open to suggestions and contributions.\n"}}