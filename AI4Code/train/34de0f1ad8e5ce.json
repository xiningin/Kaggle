{"cell_type":{"95b16ba6":"code","295e56dc":"code","5502bbe5":"code","2deff63d":"code","6c636501":"code","3dd657da":"code","7c498f61":"code","7ee87720":"code","1cff5497":"code","b7eb909d":"code","2440652b":"code","0e16720e":"markdown","6357f79d":"markdown","b0431f08":"markdown"},"source":{"95b16ba6":"\nimport os\nimport pandas as pd\nimport numpy as np\nfrom pandas.io.json import json_normalize\nimport json\nimport time\nimport warnings\n\n#from pycountry_convert import ( map_countries, country_name_to_country_alpha3,)\nimport pytz as pytz\nimport datetime\n\n#Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n\n#Sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n#lgm and graph viz\nimport graphviz \nimport lightgbm as lgb\n\nwarnings.filterwarnings('ignore')\n","295e56dc":"os.listdir('..\/input')","5502bbe5":"def load_df(csv_path='..\/input\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n      \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str', 'visitId':'str', 'visitStartTime':'str', 'date':'str'}, \n                     nrows=nrows)\n\n    #Normalize JSON colunmns and drop\n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    return df\n\n\ndef drop_constant_cols(df):\n    ## Drop constant columns\n    const_cols = [c for c in df.columns if df[c].nunique(dropna=False) == 1]\n    df.drop(const_cols, axis=1, inplace=True)\n    \n    #this columnm is only in train data\n    try:\n        df.drop('trafficSource.campaignCode', axis=1, inplace=True)   \n    except:\n        None   \n    \n","2deff63d":"%%time\n#Load\ntrain_df = load_df(csv_path='..\/input\/ga-customer-revenue-prediction\/train.csv', nrows = None)\ndrop_constant_cols(train_df)\n\ntest_df = load_df(csv_path='..\/input\/ga-customer-revenue-prediction\/test.csv', nrows = None)\ndrop_constant_cols(test_df)\n","6c636501":"# Extract target values and Ids\ncat_cols = ['channelGrouping','device.browser',\n       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\n       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\n       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\n       'geoNetwork.subContinent','trafficSource.adContent',\n       'trafficSource.adwordsClickInfo.adNetworkType',\n       'trafficSource.adwordsClickInfo.gclId',\n       'trafficSource.adwordsClickInfo.isVideoAd',\n       'trafficSource.adwordsClickInfo.page',\n       'trafficSource.adwordsClickInfo.slot', 'trafficSource.campaign',\n       'trafficSource.isTrueDirect', 'trafficSource.keyword',\n       'trafficSource.medium', 'trafficSource.referralPath',\n       'trafficSource.source'  ]\n\n\nnum_cols = ['visitNumber', 'totals.bounces', 'totals.hits',\n            'totals.newVisits', 'totals.pageviews', \n            '_local_hourofday'  ]\n\ninteraction_cols = ['totals.hits \/ totals.pageviews', 'totals.hits * totals.pageviews',\n       'totals.hits - totals.pageviews']\n\nvisitStartTime = ['visitStartTime']\n\ntime_cols = ['_dayofweek', '_monthofyear', '_dayofyear']\n\nID_cols = ['date', 'fullVisitorId', 'sessionId', 'visitId']\n\ntarget_col = ['totals.transactionRevenue']\n\n","3dd657da":"#Load\ngeocode_df= pd.read_csv('..\/input\/geocoded-data\/geocodes_timezones.csv')\n\ndef time_zone_converter(x):\n    \n    try:\n        return pytz.country_timezones(x)[0]\n    except AttributeError:\n        return np.nan\n   \n\ndef time_localizer(s):\n    #format of series [time,zone]\n    try:\n        tz =pytz.timezone(s[1])\n        return pytz.utc.localize(s[0], is_dst=None).astimezone(tz)\n    except:\n        return np.nan\n    \ndef remove_missing_vals(x):\n    remove_list = ['(not set)', 'not available in demo dataset','unknown.unknown']\n    if x in remove_list:\n        return ''\n    else:\n        return x \n    \ndef map_timezone(x):   \n    try:\n        return timezone_dict[x]\n    except KeyError:\n        return 'UTC'\n\n","7c498f61":"%%time\ntrain_df['visitStartTime'] = pd.to_datetime(train_df['visitStartTime'], unit = 's')\ntest_df['visitStartTime'] = pd.to_datetime(test_df['visitStartTime'], unit = 's')\n\n#Generate foreign key '_search_term' by concatenating city, region, country\ntrain_df['_search_term'] = train_df['geoNetwork.city'].map(remove_missing_vals) + ' ' + train_df['geoNetwork.region'].map(remove_missing_vals) + ' ' + train_df['geoNetwork.country'].map(remove_missing_vals)\ntest_df['_search_term'] = test_df['geoNetwork.city'].map(remove_missing_vals) + ' ' + test_df['geoNetwork.region'].map(remove_missing_vals) + ' ' + test_df['geoNetwork.country'].map(remove_missing_vals)\n\n#Set global variable, needed for map_timezone function\nglobal timezone_dict\ntimezone_dict = dict(zip(geocode_df['search_term'], geocode_df['timeZoneId']))\n\n#Map timezones\ntrain_df['_timeZoneId'] = train_df['_search_term'].map(map_timezone)\ntest_df['_timeZoneId'] = test_df['_search_term'].map(map_timezone)\n  \n#Create time zone aware column\ntrain_df['_local_time'] = train_df[['visitStartTime', '_timeZoneId']].apply(time_localizer, axis = 1).astype(str)\ntest_df['_local_time'] = test_df[['visitStartTime', '_timeZoneId']].apply(time_localizer, axis = 1).astype(str)  \n\n#Localize hour time\ntrain_df['_local_hourofday'] = train_df['_local_time'].str[11:13]\ntest_df['_local_hourofday'] = test_df['_local_time'].str[11:13]\n\n","7ee87720":"%%time\ntrain_df['_time_since_last_visit'] = train_df[['fullVisitorId','visitStartTime']].groupby('fullVisitorId')['visitStartTime'].diff()\ntest_df['_time_since_last_visit'] = test_df[['fullVisitorId','visitStartTime']].groupby('fullVisitorId')['visitStartTime'].diff()\n\n#Replace 0 with very large number, as we are interested in small \/ medium values\ntrain_df['_time_since_last_visit'] = train_df['_time_since_last_visit'].fillna(999999999)\ntest_df['_time_since_last_visit'] = test_df['_time_since_last_visit'].fillna(999999999)\n\n#Convert to numeric\ntrain_df['_time_since_last_visit'] = pd.to_numeric(train_df['_time_since_last_visit'])\ntest_df['_time_since_last_visit'] = pd.to_numeric(test_df['_time_since_last_visit'])","1cff5497":"train_df.head()","b7eb909d":"# %%time\n# #Categorical encoding\n# for c in cat_cols:\n#     #Convert NAs to unknown\n#     train_df[c] = train_df[c].fillna('unknown')\n#     test_df[c] = test_df[c].fillna('unknown')\n    \n#     #Encode\n#     lbl = LabelEncoder()\n#     lbl.fit( list(train_df[c].values.astype('str')) + list(test_df[c].values.astype('str')))\n#     train_df[c] = lbl.transform(list(train_df[c].values.astype('str')))\n#     test_df[c] = lbl.transform(list(test_df[c].values.astype('str')))\n\n","2440652b":"train_df.to_pickle('train_flat_local_cat_enc.pkl')\ntest_df.to_pickle('test_flat_local_cat_enc.pkl')","0e16720e":"# Kernel for saving files ","6357f79d":"## Time since last visit ","b0431f08":"## Label encoding "}}