{"cell_type":{"2a589984":"code","93ce2c4b":"code","4c5b478f":"code","4bdd7fd5":"code","c4c04509":"code","759d12ed":"code","82181f91":"code","33cc349f":"code","0396fa89":"code","57136adb":"code","f4b65ac9":"markdown"},"source":{"2a589984":"from __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline","93ce2c4b":"# Defining the parameters\nbatch_size = 32\nnum_classes = 10\nepochs = 75","4c5b478f":"# Splitting the data between train and test\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","4bdd7fd5":"# plotting some random 10 images\n\nclass_names = ['airplane','automobile','bird','cat','deer',\n               'dog','frog','horse','ship','truck']\n\nfig = plt.figure(figsize=(8,3))\nfor i in range(num_classes):\n    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n    idx = np.where(y_train[:]==i)[0]\n    features_idx = x_train[idx,::]\n    img_num = np.random.randint(features_idx.shape[0])\n    im = (features_idx[img_num,::])\n    ax.set_title(class_names[i])\n    plt.imshow(im)\nplt.show()","c4c04509":"# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","759d12ed":"# Printing sample data\nprint(y_train[:10])","82181f91":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))","33cc349f":"# summary of the model\nprint(model.summary())","0396fa89":"# compile\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n# Normalizing the input image\nx_train \/= 255\nx_test \/= 255\n","57136adb":"# Training the model\nmodel.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True)","f4b65ac9":"# **Experiment** - III:\n\nUse batch normalization and dropouts after every convolutional layer. Also, retain the dropouts in the FC layer."}}