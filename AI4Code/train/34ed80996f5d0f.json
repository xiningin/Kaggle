{"cell_type":{"fc0fbb32":"code","3dc45b79":"code","80868aa0":"code","d5639639":"code","8a2fe8b7":"code","a6d35ced":"code","69c2c1d2":"code","b42fa0e3":"code","c8de3dbc":"code","be62627c":"code","9849a4d4":"code","2b85338d":"code","a9b16a01":"code","7b598e65":"code","8a693706":"code","7f20d3dc":"code","2becba8d":"code","3629f034":"code","9f2844d2":"code","9ea01036":"code","27920774":"code","813e09fe":"code","95cb161f":"code","2e0c8f68":"code","d1a2fc89":"code","a84f41ef":"code","3b07bfd9":"markdown","3ec6a5c2":"markdown"},"source":{"fc0fbb32":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, plot_roc_curve\nfrom sklearn.model_selection import train_test_split, cross_validate,cross_val_score,GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.svm import SVR\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 500)\n","3dc45b79":"def load_hitters():\n    data = pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\n    return data\n\ndf = load_hitters()","80868aa0":"df.describe().T","d5639639":"def check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ncheck_df(df)","8a2fe8b7":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","a6d35ced":"def num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show(block=True)\nfor col in num_cols:\n    num_summary(df, col, plot=True)","69c2c1d2":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\nfor col in cat_cols:\n    cat_summary(df,col, plot=True)","b42fa0e3":"def target_summary_with_cat(dataframe, col_name,target,plot=False):\n    print(pd.DataFrame({col_name: dataframe[col].value_counts(),\n                        \"RATIO\": 100 * dataframe[col].value_counts()\/len(dataframe),\n                        f\"{target}\" + \"_Mean\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\n\nfor col in cat_cols:\n    target_summary_with_cat(df, col ,\"Salary\", plot=True)","c8de3dbc":"def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit,up_limit\n\noutlier_thresholds(df,num_cols)","be62627c":"def grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index\n\ngrab_outliers(df, \"Salary\", index=True)\ngrab_outliers(df, \"HmRun\", index=True)\ngrab_outliers(df, \"CHmRun\", index=True)\ngrab_outliers(df, \"Years\", index=True)\ngrab_outliers(df, \"CRBI\", index=True)","9849a4d4":"def missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns\n\nmissing_values_table(df)","2b85338d":"def corr_plot(data, remove=[\"Id\"], corr_coef = \"pearson\", figsize=(20, 20)):\n    if len(remove) > 0:\n        num_cols2 = [x for x in data.columns if (x not in remove)]\n\n    sns.set(font_scale=1.1)\n    c = data[num_cols2].corr(method = corr_coef)\n    mask = np.triu(c.corr(method = corr_coef))\n    plt.figure(figsize=figsize)\n    sns.heatmap(c,\n                annot=True,\n                fmt='.1f',\n                cmap='coolwarm',\n                square=True,\n                mask=mask,\n                linewidths=1,\n                cbar=False)\n    plt.show()\n\ncorr_plot(df, corr_coef = \"spearman\")\n","a9b16a01":"df = df.dropna()\n\ndf.isnull().sum()","7b598e65":"def remove_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers\n\nfor col in num_cols:\n    remove_outlier(df, col)\n\n","8a693706":"df = remove_outlier(df,\"Salary\")\ndf = remove_outlier(df,\"HmRun\")\ndf = remove_outlier(df,\"Years\")\ndf = remove_outlier(df,\"CRBI\")","7f20d3dc":"def check_outlier(dataframe, col_name ):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\nfor col in num_cols:\n    print(col, check_outlier(df, col))","2becba8d":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\nfor col in num_cols:\n    replace_with_thresholds(df, col)","3629f034":"for col in num_cols:\n    print(col, check_outlier(df, col))","9f2844d2":"df.loc[(df[\"Years\"] <= 2), \"New_Years_Level\"] = \"Junior\"\ndf.loc[(df[\"Years\"] > 2) & (df['Years'] <= 5), \"New_Years_Level\"] = \"Mid\"\ndf.loc[(df[\"Years\"] > 5) & (df['Years'] <= 10), \"New_Years_Level\"] = \"Senior\"\ndf.loc[(df[\"Years\"] > 10), \"New_Years_Level\"] = \"Expert\"\n\ndf[\"New_Years_Level\"].value_counts()","9ea01036":"# Oyuncunun y\u0131ll\u0131k ortalama isabetli vuru\u015f say\u0131s\u0131\ndf[\"New_Ort_CHits\"] = df[\"CHits\"] \/ df[\"Years\"]\n\n# Oyuncunun tak\u0131m\u0131na y\u0131ll\u0131k ortalama kazand\u0131rd\u0131\u011f\u0131 say\u0131\ndf[\"New_Ort_Cruns\"] = df[\"CRuns\"] \/ df[\"Years\"]\n\n#1986-1987 y\u0131lllar\u0131 aras\u0131nda yap\u0131lan vuru\u015flar\u0131n ba\u015far\u0131 oran\u0131\ndf[\"New_Success_Hit\"] = df[\"Hits\"] \/ df[\"AtBat\"]\n\n#Kariyeri boyunca yap\u0131lan vuru\u015flar\u0131n ba\u015far\u0131 oran\u0131\ndf[\"New_Success_CHit\"] = df[\"CHits\"] \/ df[\"CAtBat\"]\n\n# Oyuncunun y\u0131ll\u0131k ortalama topa vuru\u015f say\u0131s\u0131\ndf[\"New_Ort_CAtBat\"] = df[\"CAtBat\"] \/ df[\"Years\"]\n\n#Oyuncunun y\u0131ll\u0131k ortalama ko\u015fu yapt\u0131rd\u0131\u011f\u0131 oyuncu say\u0131s\u0131\ndf[\"NEW_CRBI_MEAN\"] = df[\"CRBI\"] \/ df[\"Years\"]","27920774":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","813e09fe":"def label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2]\n\nfor col in binary_cols:\n    df = label_encoder(df, col)","95cb161f":"def one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\nohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]\n\ndf = one_hot_encoder(df,ohe_cols)","2e0c8f68":"#Model olu\u015fturuyoruz\n\ny = df[\"Salary\"]\nX = df.drop([\"Salary\"], axis=1)\n\n######################################################\n# Base Models\n######################################################\n\nmodels = [('LR', LinearRegression()),\n          (\"Ridge\", Ridge()),\n          (\"Lasso\", Lasso()),\n          (\"ElasticNet\", ElasticNet()),\n          ('KNN', KNeighborsRegressor()),\n          ('CART', DecisionTreeRegressor()),\n          ('RF', RandomForestRegressor()),\n          ('SVR', SVR()),\n          ('GBM', GradientBoostingRegressor()),\n          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n          (\"LightGBM\", LGBMRegressor()),\n          (\"CatBoost\", CatBoostRegressor(verbose=False))\n          ]\n\nfor name, regressor in models:\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n","d1a2fc89":"\n# Automated Hyperparameter Optimization\n\ncart_params = {'max_depth': range(1, 20),\n               \"min_samples_split\": range(2, 30)}\n\nrf_params = {\"max_depth\": [5, 8, 15, None],\n             \"max_features\": [5, 7, \"auto\"],\n             \"min_samples_split\": [8, 15, 20],\n             \"n_estimators\": [200, 500, 1000]}\n\nxgboost_params = {\"learning_rate\": [0.1, 0.01, 0.01],\n                  \"max_depth\": [5, 8, 12, 20],\n                  \"n_estimators\": [100, 200, 300, 500],\n                  \"colsample_bytree\": [0.5, 0.8, 1]}\n\nlightgbm_params = {\"learning_rate\": [0.01, 0.1, 0.001],\n                   \"n_estimators\": [300, 500, 1500],\n                   \"colsample_bytree\": [0.5, 0.7, 1]}\n\nregressors = [(\"CART\", DecisionTreeRegressor(), cart_params),\n              (\"RF\", RandomForestRegressor(), rf_params),\n              ('XGBoost', XGBRegressor(objective='reg:squarederror'), xgboost_params),\n              ('LightGBM', LGBMRegressor(), lightgbm_params)]\n\nbest_models = {}\n\nfor name, regressor, params in regressors:\n    print(f\"########## {name} ##########\")\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n\n    gs_best = GridSearchCV(regressor, params, cv=3, n_jobs=-1, verbose=False).fit(X, y)\n\n    final_model = regressor.set_params(**gs_best.best_params_)\n    rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE (After): {round(rmse, 4)} ({name}) \")\n\n    print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n\n    best_models[name] = final_model","a84f41ef":"voting_reg = VotingRegressor(estimators=[('RF', best_models[\"RF\"]),\n                                         ('LightGBM', best_models[\"LightGBM\"])])\n\nvoting_reg.fit(X, y)\n\nnp.mean(np.sqrt(-cross_val_score(voting_reg, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","3b07bfd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ec6a5c2":"**Feature Engineering**"}}