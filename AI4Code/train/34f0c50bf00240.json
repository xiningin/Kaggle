{"cell_type":{"770e5e0c":"code","93a919fe":"code","ed40811d":"code","5554a169":"code","785ef2d6":"code","235a0534":"code","e3b882f9":"code","154b8c0f":"code","ca23a7aa":"code","c0c4a9d6":"code","0ff767b7":"code","d8b62fb9":"code","ca86dfcb":"code","e1803edf":"code","eacc20d3":"code","b5dd77ec":"code","3d76e3b0":"code","a05be05f":"code","308590cd":"code","302bfc08":"code","1d6029a5":"code","061ddba8":"code","f2f0f661":"code","514ce73b":"code","e97218b7":"code","2240a8be":"code","f8679212":"code","3eb1ab64":"code","8ba85f72":"code","ab0920f7":"code","0d9949c3":"code","881e3a65":"code","31bc7fd8":"code","2bd78b42":"code","35934506":"code","47524753":"code","5bbffb6b":"code","cf9797bd":"code","edf3390c":"code","f54ef76d":"code","3a5fa0f1":"code","451cd022":"code","7cf8d037":"code","17499038":"code","4b52943d":"code","3969d47b":"code","dc53b8e6":"code","2dfe4e4d":"code","8893e15e":"code","e13fe386":"code","17929bed":"code","8048d968":"code","8c1f679b":"code","0e521694":"code","659f98fb":"code","90f481c6":"code","cd9c014a":"code","f6958332":"code","1ab331d3":"code","54c7afa5":"code","8a02e563":"code","cb9cd9ce":"code","0d699381":"code","29482b07":"code","9e41f3bb":"code","99cb26ab":"code","e2801a7e":"code","0426b0fe":"code","af192571":"code","bdf1e86c":"code","7c82dd7e":"code","8607317e":"code","cbce887f":"code","8cc6ce3a":"code","6f3ffd3c":"code","a01d50b9":"code","da789b8a":"code","09ecc9ad":"code","f2447541":"code","efd4f22b":"code","95e4c498":"code","e55dd11d":"code","2afe1dbb":"code","45866c75":"code","93b1f98e":"code","fd909639":"code","b0381365":"code","b6932402":"code","6e428080":"code","dafcb6ff":"code","ef6c38f4":"code","b0bc9e4c":"code","9fbdf5e6":"code","3b20119a":"code","6a7fe69b":"code","976bfcb2":"code","b7877a0a":"code","73d45319":"code","18504181":"code","de016b0c":"code","46a6030c":"code","3e562289":"code","a1a41176":"code","535935f7":"markdown","f3ec017b":"markdown","a24fc0f6":"markdown","26993720":"markdown","7c17640f":"markdown","3f6b0926":"markdown","bd9763fc":"markdown","85c3f91a":"markdown","cc6742a8":"markdown","61160805":"markdown","7465904c":"markdown","30b70209":"markdown","a86b305c":"markdown","784a0875":"markdown","27530739":"markdown","b871495b":"markdown","62d41b0e":"markdown","017b29b0":"markdown","30e980aa":"markdown","4abd43f9":"markdown","abb571bb":"markdown","0871ebb7":"markdown","0a79361b":"markdown","02bfd70a":"markdown","9594ad09":"markdown","eac3d61e":"markdown","5178fbcf":"markdown","a4cd276b":"markdown","7ccae4ff":"markdown","e43fb1b4":"markdown","586d4d4d":"markdown","e9a49785":"markdown","f63d3634":"markdown","295811c4":"markdown","c181ae29":"markdown","5ed354c6":"markdown","6b4f577a":"markdown","9453b028":"markdown","a4e5edbc":"markdown","2653c8ec":"markdown","caa420c1":"markdown","e518ec1e":"markdown","60eafab0":"markdown","7c4bffa4":"markdown","b2f766fd":"markdown","f35abd2d":"markdown","d8a90606":"markdown","9402b88e":"markdown"},"source":{"770e5e0c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n# from pandas_profiling import ProfileReport\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","93a919fe":"train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-2\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-2\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-2\/submission.csv')","ed40811d":"train.head()","5554a169":"test.head()","785ef2d6":"# train_profile = ProfileReport(train, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# train_profile","235a0534":"# test_profile = ProfileReport(test, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# test_profile","e3b882f9":"from plotly.offline import iplot\nfrom plotly import tools\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\npy.init_notebook_mode(connected=True)","154b8c0f":"temp = train.groupby(['Date', 'Country_Region'])['ConfirmedCases'].sum().reset_index()\ntemp['Date'] = pd.to_datetime(temp['Date']).dt.strftime('%m\/%d\/%Y')\ntemp['size'] = temp['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(temp, locations=\"Country_Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Cases Over Time', color_continuous_scale=\"greens\")\nfig.show()","ca23a7aa":"grouped = train.groupby('Date')['Date', 'ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nfig = px.line(grouped, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Worldwide Confirmed Cases Over Time\")\nfig.show()\n\nfig = px.line(grouped, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Worldwide Confirmed Cases (Logarithmic Scale) Over Time\", \n              log_y=True)\nfig.show()","c0c4a9d6":"latest_grouped = train.groupby('Country_Region')['ConfirmedCases', 'Fatalities'].sum().reset_index()","0ff767b7":"fig = px.bar(latest_grouped.sort_values('ConfirmedCases', ascending=False)[:20][::-1], \n             x='ConfirmedCases', y='Country_Region',\n             title='Confirmed Cases Worldwide', text='ConfirmedCases', height=1000, orientation='h')\nfig.show()","d8b62fb9":"europe = list(['Austria','Belgium','Bulgaria','Croatia','Cyprus','Czechia','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Ireland',\n               'Italy', 'Latvia','Luxembourg','Lithuania','Malta','Norway','Netherlands','Poland','Portugal','Romania','Slovakia','Slovenia',\n               'Spain', 'Sweden', 'United Kingdom', 'Iceland', 'Russia', 'Switzerland', 'Serbia', 'Ukraine', 'Belarus',\n               'Albania', 'Bosnia and Herzegovina', 'Kosovo', 'Moldova', 'Montenegro', 'North Macedonia'])\neurope_grouped_latest = latest_grouped[latest_grouped['Country_Region'].isin(europe)]","ca86dfcb":"temp = train[train['Country_Region'].isin(europe)]\ntemp = temp.groupby(['Date', 'Country_Region'])['ConfirmedCases'].sum().reset_index()\ntemp['Date'] = pd.to_datetime(temp['Date']).dt.strftime('%m\/%d\/%Y')\ntemp['size'] = temp['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(temp, locations=\"Country_Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],scope='europe',\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Cases Over Time', color_continuous_scale='Cividis_r')\nfig.show()","e1803edf":"fig = px.bar(europe_grouped_latest.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Country_Region', color_discrete_sequence=['#84DCC6'],\n             title='Confirmed Cases in Europe', text='ConfirmedCases', orientation='h')\nfig.show()","eacc20d3":"usa = train[train['Country_Region'] == \"US\"]\nusa_latest = usa[usa['Date'] == max(usa['Date'])]\nusa_latest = usa_latest.groupby('Province_State')['ConfirmedCases', 'Fatalities'].max().reset_index()\nfig = px.bar(usa_latest.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Province_State', color_discrete_sequence=['#D63230'],\n             title='Confirmed Cases in USA', text='ConfirmedCases', orientation='h')\nfig.show()","b5dd77ec":"ch = train[train['Country_Region'] == \"China\"]\nch = ch[ch['Date'] == max(ch['Date'])]\nch = ch.groupby('Province_State')['ConfirmedCases', 'Fatalities'].max().reset_index()\nfig = px.bar(ch.sort_values('ConfirmedCases', ascending=False)[:10][::-1], \n             x='ConfirmedCases', y='Province_State', color_discrete_sequence=['#D63230'],\n             title='Confirmed Cases in china', text='ConfirmedCases', orientation='h')\nfig.show()","3d76e3b0":"province_encoded = {state:index for index, state in enumerate(train['Province_State'].unique())}","a05be05f":"train['province_encoded'] = train['Province_State'].apply(lambda x: province_encoded[x])\ntrain.head()","308590cd":"country_encoded = dict(enumerate(train['Country_Region'].unique()))\ncountry_encoded = dict(map(reversed, country_encoded.items()))","302bfc08":"train['country_encoded'] = train['Country_Region'].apply(lambda x: country_encoded[x])\ntrain.head()","1d6029a5":"from datetime import datetime\nimport time","061ddba8":"# date_encoded = {}\n# for s in train['Date'].unique():\n#     date_encoded[s] = time.mktime(datetime.strptime(s, \"%Y-%m-%d\").timetuple())","f2f0f661":"# train['date_encoded'] = train['Date'].apply(lambda x: date_encoded[x])\n# train['date_encoded'] = (train['date_encoded'] - train['date_encoded'].mean()) \/ train['date_encoded'].std()\n# train.head()","514ce73b":"train['Mon'] = train['Date'].apply(lambda x: int(x.split('-')[1]))\ntrain['Day'] = train['Date'].apply(lambda x: int(x.split('-')[2]))","e97218b7":"train['serial'] = train['Mon'] * 30 + train['Day']\ntrain.head()","2240a8be":"train['serial'] = train['serial'] - train['serial'].min()","f8679212":"train.describe()","3eb1ab64":"gdp2020 = pd.read_csv('\/kaggle\/input\/gdp2020\/GDP2020.csv')\npopulation2020 = pd.read_csv('\/kaggle\/input\/population2020\/population2020.csv')","8ba85f72":"gdp2020 = gdp2020.rename(columns={\"rank\":\"rank_gdp\"})\ngdp2020_numeric_list = [list(gdp2020)[0]] + list(gdp2020)[2:-1]\ngdp2020.head()","ab0920f7":"map_state = {'US':'United States', \n             'Korea, South':'South Korea',\n             'Cote d\\'Ivoire':'Ivory Coast',\n             'Czechia':'Czech Republic',\n             'Eswatini':'Swaziland',\n             'Holy See':'Vatican City',\n             'Jersey':'United Kingdom',\n             'North Macedonia':'Macedonia',\n             'Taiwan*':'Taiwan',\n             'occupied Palestinian territory':'Palestine'\n            }\nmap_state_rev = {v: k for k, v in map_state.items()}","0d9949c3":"population2020['name'] = population2020['name'].apply(lambda x: map_state_rev[x] if x in map_state_rev else x)\ngdp2020['country'] = gdp2020['country'].apply(lambda x: map_state_rev[x] if x in map_state_rev else x)","881e3a65":"set(train['Country_Region']) - set(population2020['name'])","31bc7fd8":"set(train['Country_Region']) - set(gdp2020['country'])","2bd78b42":"population2020 = population2020.rename(columns={\"rank\":\"rank_pop\"})\npopulation2020_numeric_list = [list(population2020)[0]] + list(gdp2020)[2:]\npopulation2020.head()","35934506":"train = pd.merge(train, population2020, how='left', left_on = 'Country_Region', right_on = 'name')\ntrain = pd.merge(train, gdp2020, how='left', left_on = 'Country_Region', right_on = 'country')","47524753":"train.isnull().sum()","5bbffb6b":"train = train.fillna(-1)","cf9797bd":"# numeric_features_X = ['Lat','Long', 'province_encoded' ,'country_encoded','Mon','Day']\nnumeric_features_X = ['province_encoded' ,'country_encoded','Mon','Day'] + population2020_numeric_list + gdp2020_numeric_list\nnumeric_features_Y = ['ConfirmedCases', 'Fatalities']\ntrain_numeric_X = train[numeric_features_X]\ntrain_numeric_Y = train[numeric_features_Y]","edf3390c":"test['province_encoded'] = test['Province_State'].apply(lambda x: province_encoded[x] if x in province_encoded else max(province_encoded.values())+1)","f54ef76d":"test['country_encoded'] = test['Country_Region'].apply(lambda x: country_encoded[x] if x in country_encoded else max(country_encoded.values())+1)","3a5fa0f1":"test['Mon'] = test['Date'].apply(lambda x: int(x.split('-')[1]))\ntest['Day'] = test['Date'].apply(lambda x: int(x.split('-')[2]))","451cd022":"test['serial'] = test['Mon'] * 30 + test['Day']\ntest['serial'] = test['serial'] - test['serial'].min()","7cf8d037":"test = pd.merge(test, population2020, how='left', left_on = 'Country_Region', right_on = 'name')\ntest = pd.merge(test, gdp2020, how='left', left_on = 'Country_Region', right_on = 'country')","17499038":"# date_encoded = {}\n# for s in test['Date'].unique():\n#     date_encoded[s] = time.mktime(datetime.strptime(s, \"%Y-%m-%d\").timetuple())\n# test['date_encoded'] = test['Date'].apply(lambda x: date_encoded[x])\n# test['date_encoded'] = (test['date_encoded'] - test['date_encoded'].mean()) \/ test['date_encoded'].std()\n# test.head()","4b52943d":"# test.loc[:,'Lat'][test['Country\/Region']=='Aruba'] = -69.9683\n# test.loc[:,'Long'][test['Country\/Region']=='Aruba'] = 12.5211","3969d47b":"test_numeric_X = test[numeric_features_X]\ntest_numeric_X.isnull().sum()","dc53b8e6":"test_numeric_X = test_numeric_X.fillna(-1)","2dfe4e4d":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression","8893e15e":"pipeline = Pipeline([('scaler', StandardScaler()), ('lr', LinearRegression())])\npipeline.fit(train_numeric_X, train_numeric_Y)\npredicted = pipeline.predict(test_numeric_X)","e13fe386":"\nfig = go.Figure()\n\n# Make traces for graph\ntrace1 = go.Bar(x=train_numeric_X.columns, y=pipeline['lr'].coef_[0], xaxis='x2', yaxis='y2',\n                marker=dict(color='#0099ff'),\n                name='ConfirmedCases')\ntrace2 = go.Bar(x=train_numeric_X.columns, y=pipeline['lr'].coef_[1], xaxis='x2', yaxis='y2',\n                marker=dict(color='#404040'),\n                name='Fatalities')\n\n# Add trace data to figure\nfig.add_traces([trace1, trace2])\n\nfig.update_layout(\n    title_text='LR trainable weights', # title of plot\n    xaxis_title_text='feature', # xaxis label\n    yaxis_title_text='weight', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n# Plot!\nfig.show()","17929bed":"# submission = np.vstack((test['ForecastId'], predicted[:,0],predicted[:,1])).T\n# submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('LR_submission.csv', index=False)","8048d968":"from sklearn.svm import SVR","8c1f679b":"pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', SVR())])\npipeline.fit(train_numeric_X, train_numeric_Y.values[:,0])\npipeline2 = Pipeline([('scaler', StandardScaler()), ('estimator', SVR())])\npipeline2.fit(train_numeric_X, train_numeric_Y.values[:,1])\ndiscovered, fatal = pipeline.predict(test_numeric_X), pipeline2.predict(test_numeric_X)","0e521694":"# submission = np.vstack((test['ForecastId'], discovered, fatal)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('SVR_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","659f98fb":"predicted_x1 =  pipeline.predict(train_numeric_X)\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x=train_numeric_Y['ConfirmedCases'],\n    histnorm='percent',\n    name='actual discovered', # name used in legend and hover labels\n    xbins=dict( # bins used for histogram\n        start=-4.0,\n        end=3.0,\n        size=0.5\n    ),\n    opacity=0.75\n))\nfig.add_trace(go.Histogram(\n    x=predicted_x1,\n    histnorm='percent',\n    name='predicted discovered',\n    xbins=dict(\n        start=-3.0,\n        end=4,\n        size=0.5\n    ),\n    opacity=0.75\n))\n\nfig.update_layout(\n    title_text='SVR Histogram of ConfirmedCases', # title of plot\n    xaxis_title_text='bins', # xaxis label\n    yaxis_title_text='ConfirmedCases', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n\nfig.show()","90f481c6":"predicted_x2 =  pipeline2.predict(train_numeric_X)\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x=train_numeric_Y['Fatalities'],\n    histnorm='percent',\n    name='actual died', # name used in legend and hover labels\n    xbins=dict( # bins used for histogram\n        start=-4.0,\n        end=3.0,\n        size=0.5\n    ),\n    opacity=0.75\n))\nfig.add_trace(go.Histogram(\n    x=predicted_x2,\n    histnorm='percent',\n    name='predicted died',\n    xbins=dict(\n        start=-3.0,\n        end=4,\n        size=0.5\n    ),\n    opacity=0.75\n))\n\nfig.update_layout(\n    title_text='SVR Histogram of Fatalities', # title of plot\n    xaxis_title_text='bins', # xaxis label\n    yaxis_title_text='Fatalities', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n\nfig.show()","cd9c014a":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\noutcomes = []\n    \nfold = 0\nfor train_index, test_index in kf.split(train_numeric_X):\n    fold += 1\n    X_train, X_test = train_numeric_X.values[train_index], train_numeric_X.values[test_index]\n    y_train, y_test = train_numeric_Y['ConfirmedCases'].values[train_index], train_numeric_Y['ConfirmedCases'].values[test_index]\n    pipeline.fit(X_train, y_train)\n    predictions = RF_model.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    outcomes.append(accuracy)\n    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \nmean_outcome = np.mean(outcomes)\nprint(\"\\n\\nMean Accuracy: {0}\".format(mean_outcome)) ","f6958332":"from sklearn.neighbors import KNeighborsClassifier","1ab331d3":"pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', KNeighborsClassifier(n_jobs=4))])\npipeline.fit(train_numeric_X, train_numeric_Y)\npredicted_x = pipeline.predict(train_numeric_X)","54c7afa5":"fig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=train_numeric_Y['ConfirmedCases'],\n    y=train_numeric_Y['Fatalities'],\n    marker=dict(color=\"crimson\", size=12),\n    mode=\"markers\",\n    name=\"actual\",\n))\n\nfig.add_trace(go.Scatter(\n    x=predicted_x[:,0],\n    y=predicted_x[:,1],\n    marker=dict(color=\"lightseagreen\", size=8),\n    mode=\"markers\",\n    name=\"predicted\",\n))\n\nfig.update_layout(title=\"RF result\",\n                  xaxis_title=\"ConfirmedCases\",\n                  yaxis_title=\"Fatalities\")\n\nfig.show()","8a02e563":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\noutcomes = []\n    \nfold = 0\nfor train_index, test_index in kf.split(train_numeric_X):\n    fold += 1\n    X_train, X_test = train_numeric_X.values[train_index], train_numeric_X.values[test_index]\n    y_train, y_test = train_numeric_Y['ConfirmedCases'].values[train_index], train_numeric_Y['ConfirmedCases'].values[test_index]\n    pipeline.fit(X_train, y_train)\n    predictions = RF_model.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    outcomes.append(accuracy)\n    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \nmean_outcome = np.mean(outcomes)\nprint(\"\\n\\nMean Accuracy: {0}\".format(mean_outcome)) ","cb9cd9ce":"from sklearn.ensemble import RandomForestClassifier","0d699381":"RF_model = RandomForestClassifier(n_estimators=50, n_jobs=4, max_depth=5)\nRF_model.fit(train_numeric_X, train_numeric_Y)\npredicted = RF_model.predict(test_numeric_X)","29482b07":"# submission = np.vstack((test['ForecastId'], predicted[:,0],predicted[:,1])).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('RF_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","9e41f3bb":"predicted_x = RF_model.predict(train_numeric_X)","99cb26ab":"# fig = go.Figure()\n# fig.add_trace(go.Scatter(\n#     x=train_numeric_Y['ConfirmedCases'],\n#     y=train_numeric_Y['Fatalities'],\n#     marker=dict(color=\"crimson\", size=12),\n#     mode=\"markers\",\n#     name=\"actual\",\n# ))\n\n# fig.add_trace(go.Scatter(\n#     x=predicted_x[:,0],\n#     y=predicted_x[:,1],\n#     marker=dict(color=\"lightseagreen\", size=8),\n#     mode=\"markers\",\n#     name=\"predicted\",\n# ))\n\n# fig.update_layout(title=\"RF result\",\n#                   xaxis_title=\"ConfirmedCases\",\n#                   yaxis_title=\"Fatalities\")\n\n# fig.show()","e2801a7e":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x=train_numeric_Y['ConfirmedCases'],\n    histnorm='percent',\n    name='actual discovered', # name used in legend and hover labels\n    xbins=dict( # bins used for histogram\n        start=-4.0,\n        end=3.0,\n        size=0.5\n    ),\n    opacity=0.75\n))\nfig.add_trace(go.Histogram(\n    x=predicted_x[:,0],\n    histnorm='percent',\n    name='predicted discovered',\n    xbins=dict(\n        start=-3.0,\n        end=4,\n        size=0.5\n    ),\n    opacity=0.75\n))\n\nfig.update_layout(\n    title_text='RF Histogram of ConfirmedCases', # title of plot\n    xaxis_title_text='bins', # xaxis label\n    yaxis_title_text='ConfirmedCases', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n\nfig.show()","0426b0fe":"from sklearn.metrics import make_scorer, accuracy_score\naccuracy_score(train_numeric_Y['ConfirmedCases'], predicted_x[:,0]), accuracy_score(train_numeric_Y['Fatalities'], predicted_x[:,1])","af192571":" from sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\noutcomes = []\n    \nfold = 0\nfor train_index, test_index in kf.split(train_numeric_X):\n    fold += 1\n    X_train, X_test = train_numeric_X.values[train_index], train_numeric_X.values[test_index]\n    y_train, y_test = train_numeric_Y['ConfirmedCases'].values[train_index], train_numeric_Y['ConfirmedCases'].values[test_index]\n    RF_model.fit(X_train, y_train)\n    predictions = RF_model.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    outcomes.append(accuracy)\n    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \nmean_outcome = np.mean(outcomes)\nprint(\"\\n\\nMean Accuracy: {0}\".format(mean_outcome)) ","bdf1e86c":"from sklearn.ensemble import AdaBoostClassifier","7c82dd7e":"adaboost_model_for_ConfirmedCases = AdaBoostClassifier(n_estimators=5)\nadaboost_model_for_ConfirmedCases.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[0]])\nadaboost_model_for_Fatalities = AdaBoostClassifier(n_estimators=5)\nadaboost_model_for_Fatalities.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[1]])","8607317e":"# predicted = adaboost_model_for_ConfirmedCases.predict(test_numeric_X)\n# predicted2 = adaboost_model_for_Fatalities.predict(test_numeric_X)\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('Adaboost_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","cbce887f":"predicted_x1 = adaboost_model_for_ConfirmedCases.predict(train_numeric_X)\npredicted_x2 = adaboost_model_for_Fatalities.predict(train_numeric_X)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=train_numeric_Y['ConfirmedCases'],\n    y=train_numeric_Y['Fatalities'],\n    marker=dict(color=\"crimson\", size=12),\n    mode=\"markers\",\n    name=\"actual\",\n))\n\nfig.add_trace(go.Scatter(\n    x=predicted_x1,\n    y=predicted_x2,\n    marker=dict(color=\"lightseagreen\", size=8),\n    mode=\"markers\",\n    name=\"predicted\",\n))\n\nfig.update_layout(title=\"ADB result\",\n                  xaxis_title=\"ConfirmedCases\",\n                  yaxis_title=\"Fatalities\")\n\nfig.show()","8cc6ce3a":"# from sklearn.ensemble import StackingClassifier","6f3ffd3c":"# estimators = [('rf',RF_model ), ('ada', adaboost_model_for_ConfirmedCases)]\n# stacking_model_for_ConfirmedCases = StackingClassifier(estimators=estimators, n_jobs=4)\n# stacking_model_for_ConfirmedCases.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[0]])","a01d50b9":"# stacking_model_for_Fatalities = StackingClassifier(estimators=estimators, n_jobs=4)\n# stacking_model_for_Fatalities.fit(train_numeric_X, train_numeric_Y[numeric_features_Y[1]])","da789b8a":"# predicted = stacking_model_for_ConfirmedCases.predict(test_numeric_X)\n# predicted2 = stacking_model_for_Fatalities.predict(test_numeric_X)\n\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('stacking_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","09ecc9ad":"# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.naive_bayes import GaussianNB \n# from sklearn.linear_model import LogisticRegression\n# from sklearn import model_selection\n# from mlxtend.classifier import StackingCVClassifier","f2447541":"# clf1 = KNeighborsClassifier(n_neighbors=100)\n# clf2 = RandomForestClassifier(n_estimators=5)\n# clf3 = GaussianNB()\n# # Logit will be used for stacking\n# lr = LogisticRegression(solver='lbfgs')\n# # sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr, use_probas=True, cv=3)\n# sclf = StackingCVClassifier(classifiers=[clf1, clf2], meta_classifier=lr, use_probas=True, cv=3)\n\n\n# # Do CV\n# for clf, label in zip([clf1, clf2, clf3, sclf], \n#                       ['KNN', \n#                        'Random Forest', \n#                        'Naive Bayes',\n#                        'StackingClassifier']):\n\n#     scores = model_selection.cross_val_score(clf, train_numeric_X.values, train_numeric_Y[numeric_features_Y[0]].values, cv=3, scoring='neg_mean_squared_log_error')\n#     print(\"Avg_rmse: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","efd4f22b":"# clf1 = KNeighborsClassifier(n_neighbors=100)\n# clf1.fit(train_numeric_X.values, train_numeric_Y[numeric_features_Y[1]])\n# predicted2 = clf1.predict(test_numeric_X)\n\n# clf2 = RandomForestClassifier(n_estimators=10)\n# clf2.fit(train_numeric_X.values, train_numeric_Y[numeric_features_Y[0]])\n# predicted = clf2.predict(test_numeric_X)\n\n# submission = np.vstack((test['ForecastId'], predicted,predicted2)).T\n# submission = submission.astype(np.int32)\n# df = pd.DataFrame(data=submission, columns=['ForecastId','ConfirmedCases','Fatalities'])\n# df.to_csv('opt_submission.csv', index=False)\n# df.to_csv('submission.csv', index=False)","95e4c498":"train_y_pred = RF_model.predict(train_numeric_X)","e55dd11d":"# train_y_pred2 = clf2.predict(train_numeric_X)\n# train_y_pred =  np.stack((train_y_pred, train_y_pred2), axis=-1)","2afe1dbb":"plt.figure(figsize=(12,8))\nplt.hist([train_numeric_Y['ConfirmedCases'],train_y_pred[:,0]],bins=100, range=(1,100), label=['ConfirmedCases_actual','ConfirmedCases_pred'],alpha=0.75)\nplt.title('ConfirmedCases Comparison',fontsize=20)\nplt.xlabel('sample',fontsize=20)\nplt.ylabel('match',fontsize=20)\nplt.legend()\nplt.show()","45866c75":"plt.figure(figsize=(12,8))\nplt.hist([train_numeric_Y['Fatalities'],train_y_pred[:,1]],bins=100, range=(1,100), label=['Fatalities_actual','Fatalities_pred'],alpha=0.75)\nplt.title('Fatalities Comparison',fontsize=20)\nplt.xlabel('sample',fontsize=20)\nplt.ylabel('match',fontsize=20)\nplt.legend()\nplt.show()","93b1f98e":"error = np.sqrt((train_y_pred - train_numeric_Y)**2)\nerror = error.cumsum()","fd909639":"fig,ax = plt.subplots()\n \nplt.xlabel('sample')\nplt.ylabel('error')\nplt.subplot(2, 1, 1)\nplt.plot(range(len(error)), error['ConfirmedCases'], \"x-\",label=\"ConfirmedCases\",color='orange')\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(range(len(error)), error['Fatalities'], \"+-\", label=\"Fatalities\")\nplt.legend()\n\nplt.show()","b0381365":"from sklearn.metrics import mean_squared_error\nrmse = mean_squared_error(train_numeric_Y, train_y_pred , squared=False)\nrmse","b6932402":"corr = train[numeric_features_X+numeric_features_Y].corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","6e428080":"corr = train[numeric_features_X+numeric_features_Y].corr(method='spearman')\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","dafcb6ff":"corr = train[numeric_features_X+numeric_features_Y].corr(method='kendall')\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nwith sns.axes_style(\"white\"):\n    # Draw the heatmap with the mask and correct aspect ratio\n    f, ax = plt.subplots(figsize=(15, 12))\n    ax = sns.heatmap(corr, mask=mask,annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.4)\nplt.show()","ef6c38f4":"RF_model.feature_importances_","b0bc9e4c":"plt.bar(range(len(numeric_features_X)), RF_model.feature_importances_, tick_label=numeric_features_X)\nplt.xlabel('feature')\nplt.ylabel('weight')\nplt.xticks(rotation=90)\nplt.show()","9fbdf5e6":"f,ax = plt.subplots()\nax.scatter(train_numeric_Y['ConfirmedCases'], train_y_pred[:,0])\nax.scatter(train_numeric_Y['Fatalities'], train_y_pred[:,1])\n\nplt.show()","3b20119a":"# clf1 = RandomForestClassifier(n_estimators=1,n_jobs=4)\n# clf3 = RandomForestClassifier(n_estimators=3,n_jobs=4)\n# clf5 = RandomForestClassifier(n_estimators=5,n_jobs=4)\n# clf10 = RandomForestClassifier(n_estimators=10,n_jobs=4)\n# clf50 = RandomForestClassifier(n_estimators=50,n_jobs=4)","6a7fe69b":"# clf1.fit(train_numeric_X, train_numeric_Y)\n# clf3.fit(train_numeric_X, train_numeric_Y)\n# clf5.fit(train_numeric_X, train_numeric_Y)\n# clf10.fit(train_numeric_X, train_numeric_Y)\n# clf50.fit(train_numeric_X, train_numeric_Y)","976bfcb2":"# predicted1 = clf1.predict(train_numeric_X)\n# predicted3 = clf3.predict(train_numeric_X)\n# predicted5 = clf5.predict(train_numeric_X)\n# predicted10 = clf10.predict(train_numeric_X)\n# predicted50 = clf50.predict(train_numeric_X)","b7877a0a":"# a = np.sum((predicted1) - (train_numeric_Y))**2 \/ len(predicted1)\n# b = np.sum((predicted3) - (train_numeric_Y))**2 \/ len(predicted3)\n# c = np.sum((predicted5) - (train_numeric_Y))**2 \/ len(predicted5)\n# d = np.sum((predicted10) - (train_numeric_Y))**2 \/ len(predicted10)\n# e = np.sum((predicted50) - (train_numeric_Y))**2 \/ len(predicted50)","73d45319":"# dt_nums = [1,3,5,10,50]\n# plt.figure(figsize=(15,10))\n\n# plt.subplot(221)\n# plt.title('Decision Tree Number & MSE \\n of ConfirmedCases',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['ConfirmedCases'],b['ConfirmedCases'],c['ConfirmedCases'],d['ConfirmedCases'],e['ConfirmedCases']],\n#          label='ConfirmedCases')\n# plt.xlabel('decision tree numbers')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.subplot(222)\n# plt.title('Decision Tree Number & MSE \\n of Fatalities',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['Fatalities'],b['Fatalities'],c['Fatalities'],d['Fatalities'],e['Fatalities']],\n#          label='Fatalities',color='y')\n# plt.xlabel('decision tree numbers')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.show()","18504181":"# clf1 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=1)\n# clf2 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=2)\n# clf3 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=3)\n# clf4 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=4)\n# clf5 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=5)\n# clf10 = RandomForestClassifier(n_estimators=10,n_jobs=4,max_depth=10)","de016b0c":"# clf1.fit(train_numeric_X, train_numeric_Y)\n# clf2.fit(train_numeric_X, train_numeric_Y)\n# clf3.fit(train_numeric_X, train_numeric_Y)\n# clf4.fit(train_numeric_X, train_numeric_Y)\n# clf5.fit(train_numeric_X, train_numeric_Y)\n# clf10.fit(train_numeric_X, train_numeric_Y)","46a6030c":"# predicted1 = clf1.predict(train_numeric_X)\n# predicted2 = clf2.predict(train_numeric_X)\n# predicted3 = clf3.predict(train_numeric_X)\n# predicted4 = clf4.predict(train_numeric_X)\n# predicted5 = clf5.predict(train_numeric_X)\n# predicted10 = clf10.predict(train_numeric_X)","3e562289":"# a = np.sum((predicted1) - (train_numeric_Y))**2 \/ len(predicted1)\n# b = np.sum((predicted2) - (train_numeric_Y))**2 \/ len(predicted2)\n# c = np.sum((predicted3) - (train_numeric_Y))**2 \/ len(predicted3)\n# d = np.sum((predicted4) - (train_numeric_Y))**2 \/ len(predicted4)\n# e = np.sum((predicted5) - (train_numeric_Y))**2 \/ len(predicted5)\n# f = np.sum((predicted10) - (train_numeric_Y))**2 \/ len(predicted10)","a1a41176":"# dt_nums = [1,2,3,4,5,10]\n# plt.figure(figsize=(15,10))\n\n# plt.subplot(221)\n# plt.title('Decision Tree Depth & MSE \\n of ConfirmedCases',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['ConfirmedCases'],b['ConfirmedCases'],c['ConfirmedCases'],d['ConfirmedCases'],e['ConfirmedCases'],f['ConfirmedCases']],\n#          label='ConfirmedCases')\n# plt.xlabel('decision tree depth')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.subplot(222)\n# plt.title('Decision Tree Depth & MSE \\n of Fatalities',fontsize=20)\n# plt.plot(range(len(dt_nums)), [a['Fatalities'],b['Fatalities'],c['Fatalities'],d['Fatalities'],e['Fatalities'],f['ConfirmedCases']],\n#          label='Fatalities',color='y')\n# plt.xlabel('decision tree depth')\n# plt.ylabel('mse')\n# plt.xticks(range(len(dt_nums)),dt_nums)\n# plt.legend()\n\n# plt.show()","535935f7":"### Bagging: Random Forest","f3ec017b":"### Basic Model Comparasion","a24fc0f6":"#### Scatter Data points ","26993720":"### Look into the depth of decision tree composed of RF - Avoiding Overfitting","7c17640f":"#### Kendall","3f6b0926":"### take a look at US","bd9763fc":"#### Root Mean Square Error\n\n> Submissions are evaluated using the column-wise root mean squared logarithmic error.","85c3f91a":"#### Losing Country in GDP2020","cc6742a8":"### Drop Nan cells or repalce them to more suitable values","61160805":"#### Redefine all mismatch Country ","7465904c":"## Encoding Categorical Data\n\n1. Province Encoding\n2. Country Encoding\n3. Date Encoding\n4. Extra Dataset\n5. Missing Value Imputation","30b70209":"### take a look at China","a86b305c":"### SIR Model (Not yet)","784a0875":"### Province Encoding\nProvince is a string-type object in the dataset. To take advantage of them, we convert Province to a numeric index as shown below. `province_encoded` collects all states in the training data. Specially, `nan` cells indicate to index `0` avoiding missing data.","27530739":"The deeper depth gets the lower mse in confirmedCases but the higher fatalities","b871495b":"## Generate the numeric input for training","62d41b0e":"## Generate the numeric input for testing ","017b29b0":"### Take a look at Europe","30e980aa":"### Country Encoding","4abd43f9":"### KNN","abb571bb":"## Ensemble","0871ebb7":"### Linear Regression","0a79361b":"### Confirmed cases over time","02bfd70a":"- KNN: -6.54\n- Random Forest: -6.90\n- Naive Bayes: -25.89\n- StackingClassifier: -4.76","9594ad09":"### Boosting: Adaboost","eac3d61e":"#### Set extra attributes to zero","5178fbcf":"### SVR","a4cd276b":"## Exploratory Data Analysis","7ccae4ff":"#### Spearman","e43fb1b4":"Above diagram demostrated that with about 5 decision tree, RF had been enough good to fit in our dataset ","586d4d4d":"#### Losing Country in Population","e9a49785":"### Correlation Visualization","f63d3634":"#### Weights","295811c4":"### Stacking","c181ae29":"## Evaluation","5ed354c6":"#### Actual Value v.s. Predicted Results","6b4f577a":"### Extra Dataset","9453b028":"### Date encoding: enhance by serial fetures (poor design)","a4e5edbc":"### Date encoding: convert `y-m-d`  to Month.and Day.","2653c8ec":"### Date Encoding: sequential timestamp (poor design)","caa420c1":"#### Pearson","e518ec1e":"### Look into the number of decision tree composed of RF","60eafab0":"Parameter weights corresponding to `'Lat','Long', 'province_encoded' ,'country_encoded','Mon','Day'`","7c4bffa4":"### Disease spread over the countries","b2f766fd":"- KNN attains the better performance than others w.r.t. Fatalities\n- RF attains the better performance than others w.r.t. ConfirmedCases","f35abd2d":"### After Model Comparing, here provide an optimal result ","d8a90606":"## Import Data","9402b88e":"## Model\n#### Single Model \n1. Linear Regression\n2. SVM Regression\n3. KNN \n\n#### Ensemble \n1. Random Forest\n2. Adaboost \n\n#### SIR Model"}}