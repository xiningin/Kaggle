{"cell_type":{"1cbe3bd4":"code","b1b78ad1":"code","2d43b2ad":"code","6ee7cd91":"code","20d56e92":"code","be84a4ca":"code","6f9c9a49":"code","68a5b839":"code","ceac38a1":"code","6c49032d":"code","73b8a990":"code","34a98c9e":"code","6ebc4d2b":"code","550da692":"code","b71f0570":"code","288d08b2":"code","9326ab3d":"code","3f88826e":"code","15373d7d":"code","e0cacd58":"markdown","faec9c3c":"markdown","4eeabb34":"markdown","0d4813d8":"markdown","9d925bf2":"markdown","e362e974":"markdown","02abec37":"markdown","8a2c1880":"markdown","f65f88cd":"markdown","7db82f5f":"markdown","0310de02":"markdown","acc99884":"markdown","d821a4f8":"markdown","c2efd48c":"markdown","3ee3f08e":"markdown","e41ebf40":"markdown","f74d642f":"markdown","73805b2a":"markdown","5ec734e1":"markdown"},"source":{"1cbe3bd4":"import sys\nimport os\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import Image\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b1b78ad1":"# Load the data\ntrain = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")\n\nX_train = train.drop([\"label\"],axis=1)\nY_train = train['label']\n\ntest = test.drop(['label'], 1)","2d43b2ad":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","6ee7cd91":"class_names = ['T_shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nplt.figure(figsize=(20, 20))\nfor k in range(10):\n  XX = X_train[Y_train == k]\n  YY = Y_train[Y_train == k].reset_index()['label']\n  for i in range(10):\n    plt.subplot(10, 10, k*10 + i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(XX[i][:,:,0], cmap='gray')\n    label_index = int(YY[i])\n    plt.title('{}. {}'.format(k, class_names[label_index]))\nplt.show()","20d56e92":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, \n                                                  Y_train, \n                                                  test_size = 0.2, \n                                                  random_state=100)","be84a4ca":"print(\"Train set \uc774\ubbf8\uc9c0 \uc218: {} \uac1c\".format(X_train.shape[0]))\nprint(\"Validation set \uc774\ubbf8\uc9c0 \uc218: {} \uac1c\".format(X_val.shape[0]))","6f9c9a49":"# CNN\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') \/ 255\nX_val = X_val.reshape(X_val.shape[0], 28, 28, 1).astype('float32') \/ 255\n\nY_train = np_utils.to_categorical(Y_train)\nY_val = np_utils.to_categorical(Y_val)","68a5b839":"# \ucee8\ubcfc\ub8e8\uc158 \uc2e0\uacbd\ub9dd \uc124\uc815\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\nmodel.add(Conv2D(64,(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","ceac38a1":"model.summary()","6c49032d":"model.compile(loss = 'categorical_crossentropy',\n              optimizer='adam',\n              metrics = ['accuracy'])","73b8a990":"MODEL_DIR = \".\/model\/\"\n\nif not os.path.exists(MODEL_DIR):\n  os.mkdir(MODEL_DIR)\n\nmodelpath = '.\/model\/{epoch:02d}-{val_loss:.4f}.hdf5'\ncheckpointer = ModelCheckpoint(filepath=modelpath, monitor = 'val_loss', verbose=1, save_best_only=True)\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)","34a98c9e":"history = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), \n                    epochs=20, \n                    batch_size=200, \n                    verbose=0, \n                    callbacks=[early_stopping_callback, checkpointer])\n\nprint(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_val, Y_val)[1]))","6ebc4d2b":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 5))\n\n# \uc624\ucc28\ny_vloss = history.history['val_loss']\n\n# \ud559\uc2b5\uc14b \uc624\ucc28\ny_loss = history.history['loss']\n\n# \uadf8\ub798\ud504\ub85c \ud45c\ud604\nx_len = np.arange(len(y_loss))\nax1.plot(x_len, y_vloss, marker = '.', c=\"red\", label='Testset_loss')\nax1.plot(x_len, y_loss, marker = '.', c='blue', label = 'Trainset_loss')\n\n# \uadf8\ub798\ud504\uc5d0 \uadf8\ub9ac\ub4dc\ub97c \uc8fc\uace0 \ub808\uc774\ube14\uc744 \ud45c\uc2dc\nax1.legend(loc='upper right')\nax1.grid()\nax1.set(xlabel='epoch', ylabel='loss')\n\n\n# \uc815\ud655\ub3c4\ny_vaccuracy = history.history['val_accuracy']\n\n# \ud559\uc2b5\uc14b\ny_accuracy = history.history['accuracy']\n\n# \uadf8\ub798\ud504\ub85c \ud45c\ud604\nx_len = np.arange(len(y_accuracy))\nax2.plot(x_len, y_vaccuracy, marker = '.', c=\"red\", label='Testset_accuracy')\nax2.plot(x_len, y_accuracy, marker = '.', c='blue', label = 'Trainset_accuracy')\n\n# \uadf8\ub798\ud504\uc5d0 \uadf8\ub9ac\ub4dc\ub97c \uc8fc\uace0 \ub808\uc774\ube14\uc744 \ud45c\uc2dc\nax2.legend(loc='lower right')\nax2.grid()\n\nax2.set(xlabel='epoch', ylabel='accuracy')\n\n# draw gridlines\nax2.grid(True)\nplt.show()","550da692":"y_pred = model.predict(X_val).round(2)\n\ny_val_label = list(map(np.argmax, Y_val))\ny_pred_label = list(map(np.argmax, y_pred))","b71f0570":"plt.figure(figsize = (16,9))\n\ncm = confusion_matrix(y_val_label,y_pred_label)\n\nsns.heatmap(cm , annot = True,fmt = 'd',xticklabels = class_names,yticklabels = class_names)","288d08b2":"aaa = np.array(y_val_label) != np.array(y_pred_label)\n\nnot_equel_list = np.where(aaa == True)[0]\n\nplt.figure(figsize=(20,20))\nj = 1\nfor i in not_equel_list[0:36]:\n# for a in np.random.randint(0,206,36):\n#     i = not_equel_list[a]\n#     print(a)\n    plt.subplot(6,6,j); j+=1\n    plt.imshow(X_val[i].reshape(28,28),cmap = 'Greys')\n    plt.axis('off')\n    plt.title('Actual = {} \/ {} \\nPredicted = {} \/ {}'.format(class_names[y_val_label[i]],\n                                                            y_val_label[i],\n                                                            class_names[y_pred_label[i]],\n                                                            y_pred_label[i]))","9326ab3d":"Image(filename=\"..\/input\/imageset\/fashion_tail_img.PNG\", width= 1000, height=1000)","3f88826e":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","15373d7d":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"results_fashion_mnist.csv\",index=False)","e0cacd58":"### 1. Data\n\n\uc6b0\uc120 \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc624\uc790. \uadf8\ub9ac\uace0 label\uc5d0 \ub530\ub77c X_train, Y_train\uc73c\ub85c \ubd84\ub958 \ud574\uc900\ub2e4.","faec9c3c":"### 2. \ub370\uc774\ud130 \ud30c\uc545\n\n10\uac1c\uc758 class\ub85c \ub098\ub220\uc838 \uc788\uc73c\uba70 \uac01 \ubc88\ud638\uc5d0 \ub300\ud55c \uc815\ubcf4\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n\n- 0: T-shirt\/top\n- 1: Trouser\n- 2: Pullover\n- 3: Dress\n- 4: Coat\n- 5: Sandal\n- 6: Shirt\n- 7: Sneaker\n- 8: Bag\n- 9: Ankle boot\n\n\n\ucd94\uac00\ub85c \uac01\uac01\uc758 \uc774\ubbf8\uc9c0\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.","4eeabb34":"#### 3-1. \uc804\ucc98\ub9ac\n\n- X\n    - \uc774\uc81c \uc774 \ub370\uc774\ud130\ub97c 255\ub85c \ub098\ub204\uc5b4 \uc8fc\uc790. 0\uc5d0\uc11c 255\uc758 \uc22b\uc790\uc758 \ubc30\uc5f4\ub85c \uc774\ub8e8\uc5b4\uc9c4 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub97c 255\ub85c \ub098\ub204\uc5b4 \uc8fc\uc5b4 0~1\ub85c \ubcc0\ud658 \uc0ac\ucf1c\uc8fc\ub294 \uc791\uc5c5\uc774\ub2e4. \ucf00\ub77c\uc2a4\ub294 \ub370\uc774\ud130\ub97c 0\uc5d0\uc11c 1 \uc0ac\uc774\uc758 \uac12\uc73c\ub85c \ubcc0\ud658\ud55c \ub2e4\uc74c \uad6c\ub3d9\ud560 \ub54c \ucd5c\uc801\uc758 \uc131\ub2a5\uc744 \ubcf4\uc774\uae30 \ub54c\ubb38\uc774\ub2e4. \ub530\ub77c\uc11c astype()\ud568\uc218\ub97c \ud1b5\ud574 \uc2e4\uc218\ud615\uc73c\ub85c \ubc14\uafd4\uc900 \ud6c4 255\ub85c \ub098\ub204\ub294 \uc791\uc5c5\uc744 \uc9c4\ud589 \ud588\ub2e4.\n- Y\n    - Y\uc758 \uacbd\uc6b0\uc5d0\ub294 \uc6d0-\ud56b \uc778\ucf54\ub529\uc744 \uc801\uc6a9\ud574\uc8fc\uc790. np_utils.to_categorical()\ud568\uc218\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \ud65c\uc131\ud654 \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 Y\uac12\uc774 0\uacfc 1\ub85c \uc774\ub8e8\uc5b4\uc838\uc57c \ud558\uae30 \ub54c\ubb38\uc778\ub370 \uc774\ub294 5\ub77c\ub294 \ub77c\ubca8\uc744 \uac16\uace0 \uc788\ub294 \ub370\uc774\ud130\ub97c array([0.,0.,0.,0.,1.,0.,0.,0.,0.]) \ub85c \ubc14\uafd4\uc900\ub2e4.","0d4813d8":"pandas\ub85c \ubd88\ub7ec\uc628 \ub370\uc774\ud130\ub294 reshape\ud568\uc218\ub97c \ud1b5\ud574 28 * 28\ubc30\uc5f4\ub85c \ubcc0\ud658 \uc2dc\ucf1c \uc900\ub2e4.|","9d925bf2":"\uc6b0\uc120 confusion_matrix\uc744 \ud1b5\ud574 \uc5b4\ub5bb\uac8c \ubd84\ub958\ub97c \ud588\ub294\uc9c0 \ud655\uc778\ud574\ubcf4\uc790.","e362e974":"#### 4-3. \ubaa8\ub378 \ucd5c\uc801\ud654 \uc124\uc815\n\n\uc774\uc81c \ubaa8\ub378\uc758 \uc131\uacfc\ub97c \uc800\uc7a5\ud558\uace0 \ubaa8\ub378\uc758 \ucd5c\uc801\ud654 \ub2e8\uacc4\uc5d0\uc11c \ud559\uc2b5\uc744 \uc911\ub2e8\ud558\uac8c\ub054 \uc124\uc815 \ud574\uc8fc\uc790. \uc774\ub294 10\ud68c \uc774\uc0c1 \ubaa8\ub378\uc758 \uc131\uacfc \ud5a5\uc0c1\uc774 \uc5c6\uc73c\uba74 \uc790\ub3d9\uc73c\ub85c \ud559\uc2b5\uc744 \uc911\ub2e8\ud558\uac8c \ub41c\ub2e4.","02abec37":"### 6. \ud2c0\ub9b0 \ub370\uc774\ud130 \ud655\uc778\n\n\ubd84\ub958\ub97c \ud558\ub294\ub370 \uc5b4\ub5a4 \uac83\uc744 \ud2c0\ub838\ub294\uc9c0 \ud655\uc778\ud574\ubcf4\uc790.","8a2c1880":"# CNN\uc744 \uc0ac\uc6a9\ud55c Fashion mnist \ubd84\ub958\n\nCNN\uc744 \uc0ac\uc6a9\ud574\uc11c Fashion mnist\ub97c \ubd84\ub958 \ud574\ubcf4\uc790. mnist\uc758 \uae30\ucd08\uc5d0\ub294 \uc22b\uc790\ub3c4 \uc788\uc73c\uba70 \uc774\ubc88\uc5d0\ub294 \uc637\uc744 \uc778\uc2dd\ud558\uace0 \ubd84\ub958 \ud574\ubcf4\ub824 \ud55c\ub2e4.\n\n### 0. Library\n\n\ub77c\uc774\ube0c\ub7ec\ub9ac\ub294 pandas, numpy, tensorflow, matplotlib, seaborn, keras, sklearn\uc744 \uae30\ubcf8\uc801\uc73c\ub85c \uc0ac\uc6a9\ud55c\ub2e4. \ub610\ud55c, \ud658\uacbd\uc740 GPU\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 Kaggle \ub178\ud2b8\ubd81\uc5d0\uc11c \uc9c4\ud589 \ud55c\ub2e4. ","f65f88cd":"#### 4-2. \ubaa8\ub378 \ucef4\ud30c\uc77c\n\n\ubaa8\ub378\uc744 \ucef4\ud30c\uc77c \ud574\ubcf4\uc790. \uc624\ucc28 \ud568\uc218\ub85ccetegorical_crossentropy, \ucd5c\uc801\ud654 \ud568\uc218\ub85c adam\uc744 \uc0ac\uc6a9\ud55c\ub2e4.","7db82f5f":"\ubaa8\ub378 summary\ub97c \ubcf4\uc790.","0310de02":"# \ucd1d\ud3c9\n\n\ucd5c\uadfc\uc5d0 \ub525\ub7ec\ub2dd\uc744 \uacf5\ubd80 \ud558\uace0 \uc788\ub2e4. \uae30\ucd08\uc801\uc778 mnist\ub97c \ud544\uc0ac \ud558\ub294 \uacfc\uc815\uc778\ub370, \uc544\uc9c1\uc740 \ubaa8\ub378\uc744 \uc124\uacc4 \ud558\ub294\uacfc\uc815\uc5d0\uc11c \uc9c1\uad00\uc801\uc73c\ub85c \uc640\ub2ff\uc9c0\uac00 \uc54a\uc9c0\ub9cc \uc774\ub294 \uc5b4\ub290\uc815\ub3c4 \ud6c8\ub828\uc744 \ud574\uac00\uba74\uc11c \uc775\uc219\ud574\uc57c \uaca0\ub2e4.","acc99884":"\uc704\uc758 \uc0ac\uc9c4\uc744 \ubcf4\uba74 shirt\ub97c pullover\ub85c \ubd84\ub958 \ud558\uace0 ankle boot\ub97c sneaker\ub85c \ubd84\ub958 \ud55c\uac83\ub3c4 \uc788\ub294\ub370 \uc0ac\uc2e4 \uc774\ubd80\ubd84\uc740 \ub098\ub3c4 \uad6c\ubd84\uc744 \ubabb\ud558\uae34 \ud558\uaca0\ub2e4.","d821a4f8":"### 3. Train\/test set \ubd84\ub958\n\nsklearn\uc758 model_selection\uc5d0\uc11c train_test_split \ud568\uc218\ub97c \ubd88\ub7ec\uc628 \ud6c4, train set\uacfc validation set\uc73c\ub85c \ubd84\ub9ac \uc2dc\ucf1c\uc8fc\uc790. train\/val\uc758 \ube44\uc728\uc740 8:2\ub85c test_size\uc635\uc158\uc5d0\uc11c 0.2\ub97c \uc0ac\uc6a9 \ud574\uc8fc\uc5c8\ub2e4. \ucd94\uac00\ub85c randaom_state=100\uc73c\ub85c \ud574\uc8fc\uc5b4, seed\ub97c 100\uc73c\ub85c \uc9c0\uc815 \ud574\uc8fc\uc5c8\ub2e4. \ub2e4\uc74c\uc5d0 \uc0ac\uc6a9\ub41c \ub77c\uc774\ube0c\ub7ec\ub9ac\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n\n- from sklearn.model_selection import train_test_split","c2efd48c":"### 4. \ubaa8\ub378\n\n#### 4-1. \ubaa8\ub378 \uc124\uacc4\n\n\ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uc790. \uc6b0\uc120 model.Sequential()\ud55c\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec model\uc744 \uc120\uc5b8 \ud574\uc8fc\uace0 model.add()\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucc28\uace1\ucc28\uace1 \ud558\ub098\uc529 \uce35\uc744 \ub9cc\ub4e4\uc5b4 \uc8fc\ub824\uace0 \ud55c\ub2e4. \ub2e4\uc74c\uc744 \ubcf4\uc790.\n\n\n**a. Convolution\uce35**\n\n\ucf00\ub77c\uc2a4\uc5d0\uc11c Convolution\uce35\uc744 \ucd94\uac00\ud558\ub294 \ud568\uc218\ub294 Conv2D()\uc774\ub2e4.\n\n- model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n    - 32: 32\uac1c\uc758 mask\ub97c \uc0ac\uc6a9\n    - kernel_size: (3,3)\uc758 \ucee4\ub110\uc744 \uc815\ud55c\ub2e4. \n    - input_shape: (28,28,1)\n    - activation: \ud65c\uc131\ud654 \ud568\uc218\ub97c relu\ub85c \uc815\ud574\uc900\ub2e4.\n- model.add(Conv2D(64,(3,3), activation='relu'))\n    -  mask 64\ub97c \uc801\uc6a9\ud55c \uc0c8\ub85c\uc6b4 Convolution\uce35\uc744 \ud558\ub098 \ub354 \ucd94\uac00\ud55c\ub2e4.\n\n**b. Maxpooling**\n\n\uc774\uc81c \ucd94\uac00\ub85c Maxpooling \uce35\uc6b8 \ucd94\uac00 \ud558\ubcf4\uc790. convolution\uc73c\ub85c \uce35\uc744 \ucd94\uac00 \ud588\uc9c0\ub9cc \uc5ec\uc804\ud788 \ud06c\uae30 \ub54c\ubb38\uc5d0 \ud55c\ubc88 \ub354 \ucd95\uc18c\ub97c \uc9c4\ud589 \ud55c\ub2e4.\n\n- model.add(MaxPooling2D(pool_size=2))\n    - pool_size: pooling\ucc3d\uc758 \ud06c\uae30\ub97c \uc815\ud558\ub294 \uac83\uc73c\ub85c 2\ub85c \uc815\ud558\uc5ec \uc904\uc5ec \uc8fc\uc5c8\ub2e4.\n    \n**c. Drop out & Flatten**\n\n- model.add(Dropout(0.25))\n    - \ub525\ub7ec\ub2dd\uc744 \ud559\uc2b5\ud560\ub54c \uacfc\uc801\ud569\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud53c\ud574\uac00\ub294 \ubc29\ubc95\uc911 \ub2e4\uc74c\uc758 \uae30\ubc95\uc774 \uc788\ub2e4. drop out\uae30\ubc95\uc778\ub370, \uc774\ub294 \uc740\ub2c9\uce35\uc5d0 \ubc30\uce58\ub41c \ub178\ub4dc \uc911 \uc77c\ubd80\ub97c \uc784\uc758\ub85c \uaef4\uc8fc\ub294 \uac83\uc774\ub2e4.\n\n- model.add(Flatten())\n    - convolution\uc774\ub098 max pooling\ub294 2\ucc28\uc6d0 \ubc30\uc5f4\uc778 \ucc44\ub85c \ub2e4\ub8e8\ub294\ub370, \uc774\ub97c 1\ucc28\uc6d0\uc73c\ub85c \ubc14\uafd4\uc8fc\uc790.","3ee3f08e":"\uc774\ub807\uac8c 10000\uac1c\uc758 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc911 8000\uac1c\uc640 2000\uac1c\ub85c \ubd84\ub9ac \uc2dc\ucf1c\uc8fc\uc5c8\ub2e4.","e41ebf40":"\uc774\ubc88\uc5d0\ub294 \uc774\ubbf8\uc9c0\ub97c \ud1b5\ud574 \ud2c0\ub9b0\uac83\uc744 \ud655\uc778\ud574\ubcf4\uc790.","f74d642f":"#### 4-4. \ubaa8\ub378 \uc2e4\ud589\n\n\uc774\ub807\uac8c \uc0d8\ud50c 200\uac1c\ub97c \ubaa8\ub450 30\ud68c \uc2e4\ud589\ud558\uac8c \ud574\uc8fc\uc558\ub2e4. \uadf8\ub9ac\uace0 valid set\uc73c\ub85c \ucd5c\uc885 \ubaa8\ub378\uc758 \uc131\uacfc\ub97c \uce21\uc815\ud558\uc5ec \uadf8 \uac12\uc744 \ucd9c\ub825\ud558\uac8c \ud574\uc8fc\uc5c8\ub2e4. \uc774\ub54c, \uc870\uae08 \uc8fc\uc758\ud574\uc57c \ud560\uac83\uc774 \uc788\ub2e4\uba74 cpu\ub85c \ub3cc\ub9ac\ub294\ub370 \uc2dc\uac04\uc774 \ub9e4\uc6b0 \ub9ce\uc774 \uac78\ub9ac\uae30 \ub54c\ubb38\uc5d0, gpu\ub97c \uc0ac\uc6a9\ud574\uc8fc\ub3c4\ub85d \ud55c\ub2e4.","73805b2a":"---\n\n### Reference\n\n\n- Kaggle Mnist\n    - [Introduction to CNN Keras - 0.997 (top 6%)](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6)\n    - [TensorFlow deep NN](https:\/\/www.kaggle.com\/kakauandme\/tensorflow-deep-nn)\n    - [25 Million Images! [0.99757] MNIST](https:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist)\n\n- kaggle fashion\n    - [How Autoencoders Work: Intro and UseCases](https:\/\/www.kaggle.com\/shivamb\/how-autoencoders-work-intro-and-usecases)\n    - [A Simple CNN Model Beginner Guide !!!!!!](https:\/\/www.kaggle.com\/pavansanagapati\/a-simple-cnn-model-beginner-guide)\n    - [CNN-Fashion-MNIST Image Classification](https:\/\/www.kaggle.com\/lykin22\/cnn-fashion-mnist-image-classification)\n    - [Introduction to GANs on Fashion MNIST Dataset](https:\/\/www.kaggle.com\/sayakdasgupta\/introduction-to-gans-on-fashion-mnist-dataset)\n    - [CNN with Keras](https:\/\/www.kaggle.com\/bugraokcu\/cnn-with-keras)\n    - [CNN with Tensorflow|Keras for Fashion MNIST](https:\/\/www.kaggle.com\/gpreda\/cnn-with-tensorflow-keras-for-fashion-mnist)","5ec734e1":"### 5. \uc624\ucc28\uc640 \uc815\ud655\ub3c4 \ud655\uc778\n\n\uc2e4\ud589 \uacb0\uacfc\ub97c \uadf8\ub798\ud504\ub85c \ud655\uc778\ud574\ubcf4\uc790. \uc624\ucc28\uc640 \uc815\ud655\ub3c4\ub97c \ud655\uc778\ud558\ub824 \ud55c\ub2e4."}}