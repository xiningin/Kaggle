{"cell_type":{"d5cfe142":"code","17f32d0c":"code","b19c4c69":"code","dd2bdb21":"code","fb0c82a6":"code","dec69ec9":"code","79676c1c":"code","6e2420b9":"code","46498c91":"code","9cff9b66":"code","f6f03503":"code","a5d484eb":"code","104b2807":"markdown","73b08c2a":"markdown","6154d8ce":"markdown","deb12a5f":"markdown","8be6a11c":"markdown"},"source":{"d5cfe142":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","17f32d0c":"#!\/usr\/bin\/env python\nimport multiprocessing\nimport os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nfrom typing import Any, Optional, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.backends.cudnn as cudnn\n\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nfrom tqdm import tqdm\nprint('julyonline')","b19c4c69":"IN_KERNEL = os.environ.get('KAGGLE_WORKING_DIR') is not None\nMIN_SAMPLES_PER_CLASS = 50\nBATCH_SIZE = 512\nLEARNING_RATE = 1e-3\nLR_STEP = 3\nLR_FACTOR = 0.5\nNUM_WORKERS = multiprocessing.cpu_count()\n# \u6bcf\u4e00\u4e2aepoch\u9700\u8981\u7684iteration\n# MAX_STEPS_PER_EPOCH = 15000   \n# NUM_EPOCHS = 2 ** 32\nMAX_STEPS_PER_EPOCH = 20  \nNUM_EPOCHS = 2\n# \nLOG_FREQ = 5\nNUM_TOP_PREDICTS = 20\nTIME_LIMIT = 9 * 60 * 60","dd2bdb21":"class ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe: pd.DataFrame, mode: str) -> None:\n        print(f'creating data loader - {mode}')\n        assert mode in ['train', 'val', 'test']\n\n        self.df = dataframe\n        self.mode = mode\n\n        transforms_list = []\n\n        if self.mode == 'train':\n            transforms_list = [\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomChoice([\n                    transforms.RandomResizedCrop(64),\n                    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n                    transforms.RandomAffine(degrees=15, translate=(0.2, 0.2),\n                                            scale=(0.8, 1.2), shear=15,\n                                            resample=Image.BILINEAR)\n                ])\n            ]\n\n        transforms_list.extend([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                  std=[0.229, 0.224, 0.225]),\n        ])\n        self.transforms = transforms.Compose(transforms_list)\n\n    def __getitem__(self, index: int) -> Any:\n        ''' Returns: tuple (sample, target) '''\n        filename = self.df.id.values[index]\n\n        part = 1 if self.mode == 'test' or filename[0] in '01234567' else 2\n        directory = 'test' if self.mode == 'test' else 'train_' + filename[0]\n        sample = Image.open(f'..\/input\/google-landmarks-2019-64x64-part{part}\/{directory}\/{self.mode}_64\/{filename}.jpg')\n        assert sample.mode == 'RGB'\n\n        image = self.transforms(sample)\n\n        if self.mode == 'test':\n            return image\n        else:\n            return image, self.df.landmark_id.values[index]\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","fb0c82a6":"def GAP(predicts: torch.Tensor, confs: torch.Tensor, targets: torch.Tensor) -> float:\n    ''' Simplified GAP@1 metric: only one prediction per sample is supported '''\n    assert len(predicts.shape) == 1\n    assert len(confs.shape) == 1\n    assert len(targets.shape) == 1\n    assert predicts.shape == confs.shape and confs.shape == targets.shape\n\n    _, indices = torch.sort(confs, descending=True)\n\n    confs = confs.cpu().numpy()\n    predicts = predicts[indices].cpu().numpy()\n    targets = targets[indices].cpu().numpy()\n\n    res, true_pos = 0.0, 0\n\n    for i, (c, p, t) in enumerate(zip(confs, predicts, targets)):\n        rel = int(p == t)\n        true_pos += rel\n\n        res += true_pos \/ (i + 1) * rel\n\n    res \/= targets.shape[0] \n    return res","dec69ec9":"class AverageMeter:\n    ''' Computes and stores the average and current value '''\n    def __init__(self) -> None:\n        self.reset()\n\n    def reset(self) -> None:\n        self.val = 0.0\n        self.avg = 0.0\n        self.sum = 0.0\n        self.count = 0\n\n    def update(self, val: float, n: int = 1) -> None:\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n","79676c1c":"def has_time_run_out() -> bool:\n    return time.time() - global_start_time > TIME_LIMIT - 500","6e2420b9":"def load_data() -> 'Tuple[DataLoader[np.ndarray], DataLoader[np.ndarray], LabelEncoder, int]':\n    torch.multiprocessing.set_sharing_strategy('file_system')\n    cudnn.benchmark = True\n\n    # only use classes which have at least MIN_SAMPLES_PER_CLASS samples\n    print('loading data...')\n    df = pd.read_csv('..\/input\/google-landmarks-2019-64x64-part1\/train.csv')\n    df.drop(columns='url', inplace=True)\n\n    counts = df.landmark_id.value_counts()\n    selected_classes = counts[counts >= MIN_SAMPLES_PER_CLASS].index\n    num_classes = selected_classes.shape[0]\n    print('# of classes with at least N({:d}) samples: {:d}'.format(MIN_SAMPLES_PER_CLASS, num_classes))\n\n    train_df = df.loc[df.landmark_id.isin(selected_classes)].copy()\n    print('train_df', train_df.shape)\n\n    test_df = pd.read_csv('..\/input\/google-landmarks-2019-64x64-part1\/test.csv', dtype=str)\n    test_df.drop(columns='url', inplace=True)\n    print('test_df', test_df.shape)\n\n    # filter non-existing test images\n    exists = lambda img: os.path.exists(f'..\/input\/google-landmarks-2019-64x64-part1\/test\/test_64\/{img}.jpg')\n    test_df = test_df.loc[test_df.id.apply(exists)].copy()\n    print('test_df after filtering', test_df.shape)\n    assert test_df.shape[0] > 112000\n\n    label_encoder = LabelEncoder()\n    label_encoder.fit(train_df.landmark_id.values)\n    print('found classes', len(label_encoder.classes_))\n    assert len(label_encoder.classes_) == num_classes\n\n    train_df.landmark_id = label_encoder.transform(train_df.landmark_id)\n\n    train_dataset = ImageDataset(train_df, mode='train')\n    test_dataset = ImageDataset(test_df, mode='test')\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=False, num_workers=NUM_WORKERS, drop_last=True)\n\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                             shuffle=False, num_workers=NUM_WORKERS)\n\n    return train_loader, test_loader, label_encoder, num_classes","46498c91":"def train(train_loader: Any, model: Any, criterion: Any, optimizer: Any,\n          epoch: int, lr_scheduler: Any) -> None:\n    print(f'epoch {epoch}')\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    avg_score = AverageMeter()\n\n    model.train()\n    num_steps = min(len(train_loader), MAX_STEPS_PER_EPOCH)\n\n    print(f'total batches: {num_steps}')\n\n    end = time.time()\n    lr_str = ''\n\n    for i, (input_, target) in enumerate(train_loader):\n        if i >= num_steps:\n            break\n\n        output = model(input_.cuda())\n        loss = criterion(output, target.cuda())\n\n        # \u8fd9\u91cc\u4e3a\u4f55\u8981\u5199\u4e00\u4e2adetach\n        confs, predicts = torch.max(output.detach(), dim=1)\n        avg_score.update(GAP(predicts, confs, target))\n\n        losses.update(loss.data.item(), input_.size(0))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % LOG_FREQ == 0:\n            print(f'{epoch} [{i}\/{num_steps}]\\t'\n                        f'time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                        f'loss {losses.val:.4f} ({losses.avg:.4f})\\t'\n                        f'GAP {avg_score.val:.4f} ({avg_score.avg:.4f})'\n                        + lr_str)\n\n#         if has_time_run_out():\n#             break\n    print(f' * average GAP on train {avg_score.avg:.4f}')","9cff9b66":"def inference(data_loader: Any, model: Any) -> Tuple[torch.Tensor, torch.Tensor,\n                                                     Optional[torch.Tensor]]:\n    ''' Returns predictions and targets, if any. '''\n    model.eval()\n\n    activation = nn.Softmax(dim=1)\n    all_predicts, all_confs, all_targets = [], [], []\n\n    with torch.no_grad():\n        for i, data in enumerate(tqdm(data_loader, disable=IN_KERNEL)):\n            if data_loader.dataset.mode != 'test':\n                input_, target = data\n            else:\n                input_, target = data, None\n\n            output = model(input_.cuda())\n            output = activation(output)\n\n            confs, predicts = torch.topk(output, NUM_TOP_PREDICTS)\n            all_confs.append(confs)\n            all_predicts.append(predicts)\n\n            if target is not None:\n                all_targets.append(target)\n\n    predicts = torch.cat(all_predicts)\n    confs = torch.cat(all_confs)\n    targets = torch.cat(all_targets) if len(all_targets) else None\n\n    return predicts, confs, targets","f6f03503":"def generate_submission(test_loader: Any, model: Any, label_encoder: Any) -> np.ndarray:\n    \n    # sub \u662f\u6211\u4eec\u5b9e\u9645\u5f97\u5230\u7684\u7ed3\u679c\uff1bsample_sub\u662f\u5b98\u65b9\u7ed9\u5b9a\u7684 \u5f85 \u8bc4\u4ef7\u7684\u6570\u636e\u3002\u8fd9\u91cc\u6240\u4ee5\u4e0b\u5339\u914d\u3002\n    print('beging to read sample file')\n    sample_sub = pd.read_csv('..\/input\/landmark-recog\/haha_sample_submission.csv')\n    print('sample file reading done')\n    \n    predicts_gpu, confs_gpu, _ = inference(test_loader, model)\n    predicts, confs = predicts_gpu.cpu().numpy(), confs_gpu.cpu().numpy()\n\n    labels = [label_encoder.inverse_transform(pred) for pred in predicts]\n    print('labels')\n    print(np.array(labels))\n    print('confs')\n    print(np.array(confs))\n\n    sub = test_loader.dataset.df\n    def concat(label: np.ndarray, conf: np.ndarray) -> str:\n        return ' '.join([f'{L} {c}' for L, c in zip(label, conf)])\n    sub['landmarks'] = [concat(label, conf) for label, conf in zip(labels, confs)]\n\n    sample_sub = sample_sub.set_index('id')\n    sub = sub.set_index('id')\n    sample_sub.update(sub)\n    print('save output result')\n    sample_sub.to_csv('hyli2020_submission.csv')\n    print('done')","a5d484eb":"# \u4e0b\u9762\u662f\u4e3b\u51fd\u6570\nif __name__ == '__main__':\n    global_start_time = time.time()\n    train_loader, test_loader, label_encoder, num_classes = load_data()\n\n    # \u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u6211\u4eec\u5c31\u76f4\u63a5\u5229\u7528pytorch\u91cc \u5df2\u6709\u7684resnet-50 \u4f5c\u4e3a\u6211\u4eec\u7684model\n    model = torchvision.models.resnet50(pretrained=True)\n    model.avg_pool = nn.AdaptiveAvgPool2d(1)\n    model.fc = nn.Linear(model.fc.in_features, num_classes)\n    model.cuda()\n\n    criterion = nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP,\n                                                   gamma=LR_FACTOR)\n\n    for epoch in range(1, NUM_EPOCHS + 1):\n        print('-' * 50)\n        train(train_loader, model, criterion, optimizer, epoch, lr_scheduler)\n        lr_scheduler.step()\n#         if has_time_run_out():\n#             break\n\n    print('inference mode')\n    generate_submission(test_loader, model, label_encoder)","104b2807":"\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u51fd\u6570\uff1atrain","73b08c2a":"\u4e00\u4e9b\u8d85\u53c2\u6570\u7684\u8bbe\u7f6e","6154d8ce":"\u6784\u5efa\u8fd9\u4e2adataset, \u8bfb\u53d6image","deb12a5f":"\u4e0b\u9762\u6211\u4eec\u5199\u4e00\u4e2a data_loader","8be6a11c":"\u8bc4\u4ef7\u51fd\u6570"}}