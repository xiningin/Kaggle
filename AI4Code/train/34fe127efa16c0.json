{"cell_type":{"55f2bf69":"code","6d25e45a":"code","8b568e1c":"code","c9cde077":"code","fb25e3fa":"code","06c4346f":"code","fd08d219":"code","23c1675d":"code","cb5cc105":"code","99aeddaf":"code","fb72a666":"code","4d4f616b":"code","a3a04c60":"code","0e4d681b":"code","e4eababc":"code","61b53838":"code","70d62567":"code","66bc21a4":"code","00765661":"code","18ed785d":"code","75696d8c":"markdown"},"source":{"55f2bf69":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6d25e45a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport random\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport os\nimport cv2\nimport time\nimport torchvision\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport albumentations \nfrom albumentations.pytorch import ToTensorV2 as AT\n#import torch_optimizer as optim\n\n\nimport matplotlib.pyplot as plt","8b568e1c":"\n#PATH = '\/kaggle\/input\/'\ntrain_path = \"\/kaggle\/input\/new-train\/NEW DATA\/\"\ntest_path = \"\/kaggle\/input\/competition2\/test\/\"\nsample_submission = pd.read_csv(\"\/kaggle\/input\/sample-submission\/sample_submission.csv\")\ntrain_list = os.listdir(train_path)\ntest_list = os.listdir(test_path)\nprint(len(train_list), len(test_list))","c9cde077":"class ChartsDataset(Dataset):\n    \n    def __init__(self, path, img_list, transform=None, mode='train'):\n        self.path = path\n        self.img_list = img_list\n        self.transform=transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.img_list)\n    \n    def __getitem__(self, idx):\n        image_name = self.img_list[idx]\n        \n        if image_name.split(\".\")[1] == \"gif\":\n           gif = cv2.VideoCapture(self.path + image_name)\n           _, image = gif.read()\n        else:\n            image = cv2.imread(self.path + image_name)\n            \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        #label = 0\n        \n        if image_name.startswith('1'):\n            self.label = 1        \n        elif image_name.startswith('2'):\n            self.label = 2\n        elif image_name.startswith('3'):\n            self.label = 3\n        elif image_name.startswith('4'):\n            self.label = 4\n        elif image_name.startswith('5'):\n            self.label = 5\n        elif image_name.startswith('6'):\n            self.label = 6\n        elif image_name.startswith('7'):\n            self.label = 7\n        else:\n            self.label = 0\n            \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented[\"image\"]\n        \n        if self.mode == \"train\":\n            return image, self.label\n        else:\n            return image, image_name","fb25e3fa":"#\u0437\u0430\u0434\u0430\u0434\u0438\u043c \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\nbatch_size = 55\nnum_workers = 0\nimg_size = 256","06c4346f":"data_transforms = albumentations.Compose([\n    albumentations.Resize(img_size, img_size),\n    albumentations.ShiftScaleRotate(rotate_limit=0), #rotate_limit=0\n    albumentations.Normalize(),\n    #albumentations.ChannelShuffle(always_apply=False, p=0.5),\n    albumentations.RandomRotate90(always_apply=False),\n    #albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, always_apply=False, p=0.2),\n    AT()\n    ])\n# RandomRotate90(always_apply=False)\n#\n\ndata_transforms_test = albumentations.Compose([\n    albumentations.Resize(img_size, img_size),\n    albumentations.Normalize(),\n    AT()\n    ])","fd08d219":"#\u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u044b\ntrainset = ChartsDataset(train_path, train_list,  transform = data_transforms)\ntestset = ChartsDataset(test_path, test_list,  transform=data_transforms_test, mode=\"test\")","23c1675d":"#\u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u0442\u0440\u0435\u0439\u043d\u043e\u0432\u0443\u044e \u0447\u0430\u0441\u0442\u044c \u043d\u0430 \u0442\u0440\u0435\u0439\u043d \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0434\u0440\u0443\u0433\u043e\u0439 \u0441\u043f\u043e\u0441\u043e\u0431.\nvalid_size = int(len(train_list) * 0.1)\ntrain_set, valid_set = torch.utils.data.random_split(trainset, \n                                    (len(train_list)-valid_size, valid_size))","cb5cc105":"#\u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u043b\u043e\u0430\u0434\u0435\u0440\u044b \u0434\u043b\u044f \u0432\u0441\u0435\u0445 3\u0445 \u043f\u043e\u0434\u0432\u044b\u0431\u043e\u0440\u043e\u043a.\ntrainloader = torch.utils.data.DataLoader(train_set, pin_memory=True, \n                                        batch_size=batch_size, shuffle=True)\n\nvalidloader = torch.utils.data.DataLoader(valid_set, pin_memory=True, \n                                        batch_size=batch_size, shuffle=True)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch_size,\n                                         num_workers = num_workers)","99aeddaf":"samples, labels = next(iter(trainloader))\nplt.figure(figsize=(16,24))\ngrid_imgs = torchvision.utils.make_grid(samples[:32])\nnp_grid_imgs = grid_imgs.numpy()\nprint(labels)\nplt.imshow(np.transpose(np_grid_imgs, (1,2,0)))","fb72a666":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","4d4f616b":"#\u043d\u0435 \u0437\u0430\u0431\u0443\u0434\u044c\u0442\u0435 \u0432\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442 \u0432 \u043f\u0440\u0430\u0432\u043e\u043c \u043c\u0435\u043d\u044e \u043d\u0430\u0441\u0442\u0440\u043e\u0435\u043a ---------------------------------------------------------------------->\n#model = torchvision.models.resnet18(pretrained=True, progress=True)\nmodel = torchvision.models.resnext50_32x4d(pretrained=True, progress=True)\n#\u0442\u0443\u0442 \u043f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u043a \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u0442\u044c \u0432\u0441\u0435 \u0441\u043b\u043e\u0438, \u043a\u0430\u043a \u043f\u043e\u0441\u0442\u0443\u043f\u0438\u0442\u044c \u0432\u0430\u043c \u0440\u0435\u0448\u0430\u0439\u0442\u0435 \u0441\u0430\u043c\u0438, \u043e\u0442 \u044d\u0442\u043e\u0433\u043e \u0442\u043e\u0436\u0435 \u043c\u043d\u043e\u0433\u043e \u0437\u0430\u0432\u0438\u0441\u0438\u0442)\n\nfor param in model.parameters():\n    param.requires_grad = True\n    \n#in_features = model.fc.in_features\n#model.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n#model.maxpool = nn.MaxPool2d(output_size=1)\n#model.fc = nn.Linear(in_features, 8)\n#model.classifier._modules['6'] = nn.Linear(4096, 8)\n\n","a3a04c60":"for name, child in model.named_children():\n    print(name)","0e4d681b":"for name, child in model.named_children():\n   if name in ['layer4','fc', 'avgpool']:\n       print(name + ' is unfrozen')\n       for param in child.parameters():\n           param.requires_grad = True\n   else:\n       print(name + ' is frozen')\n       for param in child.parameters():\n           param.requires_grad = False","e4eababc":"in_features = model.fc.in_features\nmodel.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n#model.maxpool = nn.MaxPool2d(output_size=1)\nmodel.fc = nn.Linear(in_features, 8)\n#model.classifier._modules['6'] = nn.Linear(4096, 8)","61b53838":"def train_model(model_conv, train_loader, valid_loader, criterion, optimizer, sheduler, n_epochs):\n    model_conv.to(device)\n    valid_loss_min = np.Inf\n    val_loss_min = np.Inf\n    patience = 12\n    # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u044d\u043f\u043e\u0445 \u0436\u0434\u0435\u043c \u0434\u043e \u043e\u0442\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f\n    p = 0\n    # \u0438\u043d\u0430\u0447\u0435 \u043e\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n    stop = False\n\n    # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445\n    for epoch in range(1, n_epochs+1):\n        print(time.ctime(), 'Epoch:', epoch)\n\n        train_loss = []\n\n        for batch_i, (data, target) in enumerate(train_loader): # in enumerate(tqdm(train_loader)):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model_conv(data)\n            loss = criterion(output, target)\n            train_loss.append(loss.item())\n            loss.backward()\n            optimizer.step()\n    # \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e\n        model_conv.eval()\n        val_loss = []\n        correct = 0\n        for batch_i, (data, target) in enumerate(valid_loader):\n            data, target = data.to(device), target.to(device)\n            output = model_conv(data)\n            _, predicted = torch.max(output.data, 1)\n            correct += (predicted == target).sum().item()\n            loss = criterion(output, target)\n            val_loss.append(loss.item()) \n\n            \n        acc = correct \/ len(valid_set)\n        print('{:.6f}% Accuracy'.format(acc*100))\n\n\n        print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}.')\n\n        valid_loss = np.mean(val_loss)\n        tr_loss = np.mean(train_loss)\n        scheduler.step(valid_loss)\n        #print('Learning rate: {:.8f}'.format(scheduler.get_lr()[0]))\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).'.format(\n            valid_loss_min,\n            valid_loss))\n            valid_loss_min = valid_loss\n            p = 0\n        \n        if val_loss[epoch] < val_loss_min:\n            print('Current val loss is smaller now {:.6f} --> {:.6f}. Saving model.'.format(val_loss_min, val_loss[epoch]))\n            val_loss_min = val_loss[epoch]\n            torch.save(model_conv.state_dict(), 'model.pt')\n            \n        \n        # \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u043a\u0430\u043a \u0434\u0435\u043b\u0430 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n        if valid_loss > valid_loss_min:\n            p += 1\n            print(f'{p} epochs of increasing val loss')\n            if p > patience:\n                print('Stopping training')\n                stop = True\n                break        \n\n        if stop:\n            break\n    return model_conv, train_loss, val_loss","70d62567":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n#optimizer = optim.SGDW(model.parameters(),lr=0.05, momentum=0.9, dampening=0, weight_decay=0.001,  nesterov=True,)\n#optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n#optimizer = torch.optim.Adamax(model.parameters(), lr=0.0005)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7, patience=3)\n    \n#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0, last_epoch=-1)","66bc21a4":"model_resnet, train_loss, val_loss = train_model(model, trainloader, validloader, criterion, \n                              optimizer, scheduler, n_epochs = 100)","00765661":"model.load_state_dict(torch.load('\/kaggle\/working\/model.pt'))\nmodel.to(device)\nmodel.eval()\npred_list = []\nnames_list = []\nposs0_list = []\nposs1_list = []\nposs2_list = []\nposs3_list = []\nposs4_list = []\nposs5_list = []\nposs6_list = []\nposs7_list = []\nfor images, image_names in testloader:\n    with torch.no_grad():\n        images = images.to(device)\n        output = model(images)\n        print(output)\n        pred = F.softmax(output)\n        print(pred)\n        poss0_list += [p[0] for p in pred.cpu().numpy()]\n        poss1_list += [p[1] for p in pred.cpu().numpy()]\n        poss2_list += [p[2] for p in pred.cpu().numpy()]\n        poss3_list += [p[3] for p in pred.cpu().numpy()]\n        poss4_list += [p[4] for p in pred.cpu().numpy()]\n        poss5_list += [p[5] for p in pred.cpu().numpy()]\n        poss6_list += [p[6] for p in pred.cpu().numpy()]\n        poss7_list += [p[7] for p in pred.cpu().numpy()]\n        pred1 = torch.argmax(pred, dim=1).cpu().numpy()\n        print(pred1)\n        pred_list += [p.item() for p in pred1]\n        names_list += [name for name in image_names]\n\n\nsample_submission.image_name = names_list\nsample_submission.label = pred_list\nsample_submission.to_csv('submissionresnext.csv', index=False)\nsample_submission[\"0\"] = poss0_list\nsample_submission[\"1\"] = poss1_list\nsample_submission[\"2\"] = poss2_list\nsample_submission[\"3\"] = poss3_list\nsample_submission[\"4\"] = poss4_list\nsample_submission[\"5\"] = poss5_list\nsample_submission[\"6\"] = poss6_list\nsample_submission[\"7\"] = poss7_list\nsample_submission.to_csv('submission_probresnext.csv', index=False)","18ed785d":"model.load_state_dict(torch.load('\/kaggle\/working\/model.pt'))\nmodel.to(device)\nmodel.eval()\ncorrect = 0\n\nwith torch.no_grad():\n  for data, target in validloader:\n    data = data.to(device=device)\n    target = target.to(device=device)\n    outputs = model(data)\n    _, predicted = torch.max(outputs.data, 1)\n    correct += (predicted == target).sum().item()\n\n\nacc = correct \/ len(valid_set)\nprint(acc)","75696d8c":"0.9493914157591288"}}