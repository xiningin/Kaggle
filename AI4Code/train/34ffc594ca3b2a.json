{"cell_type":{"b4d5fd0d":"code","01215025":"code","a153ffe0":"code","9e1a5d0b":"code","2c63b1ec":"code","dfb4ae9a":"code","d1b28611":"code","a2eec6d0":"code","a0ddd62b":"code","f216c6fd":"code","5cb9cf88":"code","27be443a":"code","3659db43":"code","fd9b6a2c":"code","ceaea89b":"code","2da27a3e":"code","28c1b7da":"code","b8cfe331":"code","c345717f":"code","ce8ad4c3":"code","b101e23d":"code","af437951":"code","4b2673e9":"code","8af0d408":"code","ff781246":"code","bcb02897":"code","ee4cbf34":"code","aa68771f":"code","6aaba3f0":"code","09d96253":"code","99ae90aa":"code","6f32c4ae":"code","1eaadf1d":"code","526baf7c":"code","15a80696":"code","836301b2":"code","5b79de43":"code","d89330a1":"code","e00a6193":"code","7da7b257":"code","06e6ab93":"code","edf66818":"code","c76f5a45":"code","58898127":"code","49a0da66":"markdown","34a56ac6":"markdown","095b38de":"markdown","9255d9ed":"markdown","8c8fe754":"markdown","3f2a5291":"markdown","2a1983b9":"markdown","3e4c651c":"markdown","c3c88f3b":"markdown","b3ad31df":"markdown","91d194f7":"markdown","6cffab64":"markdown","1a3c1473":"markdown","00574174":"markdown","855be9d9":"markdown","8ecb2e4e":"markdown","431f910b":"markdown","585fcb0e":"markdown","ffaad3df":"markdown","5eea3922":"markdown","816796f4":"markdown","237cc0cc":"markdown","b6cd4226":"markdown","99fc1d76":"markdown","adb1e457":"markdown","d4a0477c":"markdown","180f2dce":"markdown","7c1e47c1":"markdown","3f3b0027":"markdown","275e2661":"markdown","533f6a51":"markdown","dbe469e4":"markdown","c016d609":"markdown","3fa7f1bc":"markdown","aac263db":"markdown"},"source":{"b4d5fd0d":"!pip install nb_black -q","01215025":"%load_ext nb_black","a153ffe0":"import warnings\n\nwarnings.filterwarnings(\"ignore\")","9e1a5d0b":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2c63b1ec":"data = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")\ndata.drop([\"Unnamed: 32\", \"id\"], axis=1, inplace=True)","dfb4ae9a":"data.isna().sum()","d1b28611":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntable = data\ntable[\"diagnosis_b\"] = table.diagnosis.map({\"M\": 1.0, \"B\": 0.0})\ntable = table.corr()\n\nwith sns.axes_style(\"white\"):\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(25, 25))\n    sns.heatmap(\n        round(table, 2),\n        cmap=\"Reds\",\n        mask=mask,\n        vmax=table.max().max(),\n        vmin=table.min().min(),\n        linewidths=0.5,\n        annot=True,\n        annot_kws={\"size\": 12},\n    ).set_title(\"Correlation Matrix Breast Cancer Wisconsin Dataset\")","a2eec6d0":"sns.pairplot(data, hue='diagnosis_b', vars=['radius_mean',\n'texture_mean',\n'perimeter_mean',\n'area_mean',\n'smoothness_mean',\n'compactness_mean',\n'concavity_mean',\n'concave points_mean',\n'symmetry_mean',\n'fractal_dimension_mean'])\n\n","a0ddd62b":"import plotly.express as px\n\naux = table[[\"diagnosis_b\"]].sort_values(\"diagnosis_b\", ascending=False)\naux[\"columns\"] = table.index\nfig = px.bar(\n    aux,\n    x=\"columns\",\n    y=\"diagnosis_b\",\n    hover_data=[\"columns\", \"diagnosis_b\"],\n    color=\"diagnosis_b\",\n    height=600,\n)\nfig.show()","f216c6fd":"data.head()","5cb9cf88":"import plotly.express as px\n\n\ndef plot_violin(columns, name):\n    final = []\n    for col in columns:\n        aux = data[[\"diagnosis\", col]]\n        aux[\"type\"] = col\n        aux.columns = [\"diagnosis\", f\"{name} values\", \"type\"]\n        final.append(aux)\n\n    df = pd.concat(final)\n    fig = px.violin(\n        df,\n        y=f\"{name} values\",\n        x=\"type\",\n        color=\"diagnosis\",\n        box=True,\n        points=\"all\",\n        hover_data=df.columns,\n    )\n    fig.update_layout(\n        title_text=f\"Values of {name} by the target (B,M)\",\n        xaxis_title=\"Diagnosis (0 = B = benign, 1 = M = malignant)\",\n    )\n    fig.show()","27be443a":"col = \"radius\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","3659db43":"col = \"texture\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","fd9b6a2c":"col = \"perimeter\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","ceaea89b":"col = \"area\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","2da27a3e":"col = \"smoothness\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","28c1b7da":"col = \"compactness\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","b8cfe331":"col = \"concavity\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","c345717f":"col = \"concave points\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","ce8ad4c3":"col = \"symmetry\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","b101e23d":"col = \"fractal_dimension\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","af437951":"from sklearn.model_selection import train_test_split\n\nx = data.drop([\"diagnosis\", \"diagnosis_b\"], axis=1)\ny = data.diagnosis.values\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y)","4b2673e9":"from sklearn.dummy import DummyClassifier\n\ndc = DummyClassifier(strategy=\"most_frequent\")\ndc.fit(train_x, train_y)\ndc.score(test_x, test_y)","8af0d408":"from sklearn.ensemble import RandomForestClassifier\nimport random\n\nSEED = 1234\nrandom.seed(SEED)\n\nrfc = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\nrfc.fit(train_x, train_y)\nrfc.score(test_x, test_y)","ff781246":"from sklearn.feature_selection import SelectKBest, chi2\n\nSEED = 1234\nrandom.seed(SEED)\n\nselect_k = SelectKBest(chi2, k=5)\n\nselect_k.fit(train_x, train_y)\ntrain_x_k = select_k.transform(train_x)\ntest_x_k = select_k.transform(test_x)\n\nrfck = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\nrfck.fit(train_x_k, train_y)\nrfck.score(test_x_k, test_y)","bcb02897":"from sklearn.feature_selection import RFE\n\nSEED = 12345\nrandom.seed(SEED)\n\nrfc_aux = RandomForestClassifier(\n    n_estimators=100, max_depth=2, random_state=0, n_jobs=-1\n)\nrfc_rfe = RFE(estimator=rfc_aux, n_features_to_select=5, step=1,)\n\nrfc_rfe.fit(train_x, train_y)\ntrain_x_rfe = rfc_rfe.transform(train_x)\ntest_x_rfe = rfc_rfe.transform(test_x)\n\nrfc_aux.fit(train_x_rfe, train_y)\nrfc_aux.score(test_x_rfe, test_y)","ee4cbf34":"train_x.columns[rfc_rfe.support_]","aa68771f":"from sklearn.feature_selection import RFECV\n\nSEED = 12345\nrandom.seed(SEED)\n\nrfc_aux_cv = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\nrfc_rfecv = RFECV(estimator=rfc_aux_cv, cv=10, step=1, scoring=\"accuracy\", n_jobs=-1)\n\nrfc_rfecv.fit(train_x, train_y)\ntrain_x_rfecv = rfc_rfecv.transform(train_x)\ntest_x_rfecv = rfc_rfecv.transform(test_x)\n\nrfc_aux_cv.fit(train_x_rfecv, train_y)\nrfc_aux_cv.score(test_x_rfecv, test_y)","6aaba3f0":"train_x.columns[rfc_rfecv.support_]","09d96253":"from sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\npca = PCA(n_components=\"mle\")\npca_result = pca.fit(normalize(x, norm=\"max\"))\ntrain_x_pca = pca_result.transform(train_x)\ntest_x_pca = pca_result.transform(test_x)\n\npca_model = RandomForestClassifier(\n    n_estimators=100, max_depth=2, random_state=0, n_jobs=-1\n)\npca_model.fit(train_x_pca, train_y)\n\n\nm_c = confusion_matrix(test_y, pca_model.predict(test_x_pca))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c, annot=True, cmap=\"Reds\", fmt=\"d\").set(xlabel=\"Predict\", ylabel=\"Real\")\nprint(\n    \"Inicial number of features: \",\n    test_x_pca.shape[1],\n    \" with the acurracy: \",\n    pca_model.score(test_x_pca, test_y),\n)","99ae90aa":"m_c = confusion_matrix(test_y, rfc.predict(test_x))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c, annot=True, cmap=\"Reds\", fmt=\"d\").set(xlabel=\"Predict\", ylabel=\"Real\")\nprint(\n    \"Inicial number of features: \",\n    train_x.shape[1],\n    \" with the acurracy: \",\n    rfc.score(test_x, test_y),\n)","6f32c4ae":"m_c_k = confusion_matrix(test_y, rfck.predict(test_x_k))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_k, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)\nprint(\n    \"SelectKBest number of features: \",\n    train_x_k.shape[1],\n    \" with the acurracy: \",\n    rfck.score(test_x_k, test_y),\n)","1eaadf1d":"m_c_rfe = confusion_matrix(test_y, rfc_aux.predict(test_x_rfe))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_rfe, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)\nprint(\n    \"RFE number of features: \",\n    train_x_rfe.shape[1],\n    \" with the acurracy: \",\n    rfc_aux.score(test_x_rfe, test_y),\n)","526baf7c":"m_c_rfecv = confusion_matrix(test_y, rfc_aux_cv.predict(test_x_rfecv))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_rfecv, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)\nprint(\n    \"RFECV number of features: \",\n    rfc_rfecv.n_features_,\n    \" with the acurracy: \",\n    rfc_aux_cv.score(test_x_rfecv, test_y),\n)","15a80696":"import plotly.graph_objects as go\n\npca = PCA(n_components=2)\npca_result = pca.fit_transform(normalize(x, norm=\"max\"))\ny_color = [\"red\" if el == \"M\" else \"blue\" for el in y]\n\nfig = go.Figure(\n    data=go.Scatter(\n        x=pca_result[:, 0],\n        y=pca_result[:, 1],\n        mode=\"markers\",\n        marker={\"color\": y_color},\n    )\n)\n\nfig.show()","836301b2":"from sklearn.manifold import TSNE\nfrom sklearn.preprocessing import normalize\nimport plotly.graph_objects as go\n\ntsne = TSNE(n_components=2)\ntsne_result = tsne.fit_transform(normalize(x, norm=\"max\"))\n\nfig = go.Figure(\n    data=go.Scatter(\n        x=tsne_result[:, 0],\n        y=tsne_result[:, 1],\n        mode=\"markers\",\n        marker={\"color\": y_color},\n    )\n)\n\nfig.show()","5b79de43":"import time\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n# Models\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n\nmodels = [\n    (\"SVC\", SVC()),\n    (\"RandomForestClassifier\", RandomForestClassifier()),\n    (\"SGDClassifier\", SGDClassifier()),\n    (\"MLPClassifier\", MLPClassifier()),\n    (\"DecisionTreeClassifier\", DecisionTreeClassifier()),\n    (\"NearestCentroid\", NearestCentroid()),\n    (\"KNeighborsClassifier\", KNeighborsClassifier()),\n]\n\n\ndef train_test_validation(model, name, X, Y):\n    print(f\"Starting {name}.\")  # Debug\n    ini = time.time()  # Start clock\n    scores = cross_val_score(model, X, Y, cv=4)  # Cross-validation\n    fim = time.time()  # Finish clock\n    print(f\"Finish {name}.\")  # Debug\n    return (name, scores.mean(), scores.max(), scores.min(), fim - ini)","d89330a1":"%%time\nresults = [ train_test_validation(model[1], model[0], x, y) for model in models ] # Testing for all models\nresults = pd.DataFrame(results, columns=['Classifier', 'Mean', 'Max', 'Min', 'TimeSpend (s)']) # Making a data frame","e00a6193":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=2, cols=1, shared_yaxes=True)\nx_plot = results[\"Classifier\"]\ny_plot = round(results[\"Mean\"] * 100, 2)\nz_plot = round(results[\"TimeSpend (s)\"], 2)\n\n# Plots\nfig.add_trace(go.Bar(x=x_plot, y=y_plot, text=y_plot, textposition=\"auto\"), 1, 1)\nfig.add_trace(go.Bar(x=x_plot, y=z_plot, text=z_plot, textposition=\"auto\"), 2, 1)\n\nfig.update_layout(height=800, width=1000, title_text=\"Traing Models Results\")\n\n# Update xaxis properties\nfig.update_xaxes(title_text=\"Acurracy by Crossvalidation\", row=1, col=1)\nfig.update_xaxes(title_text=\"Time Spended by traing\", row=2, col=1)\n\n# Update yaxis properties\nfig.update_yaxes(title_text=\"Accurracy in percent (%)\", row=1, col=1)\nfig.update_yaxes(title_text=\"Time in seconds (s)\", row=2, col=1)\n\n\nfig.show()","7da7b257":"%%time\nfrom sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=25)]\n# Number of features to consider at every split\nmax_features = [\"auto\", \"sqrt\"]\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num=25)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {\n    \"n_estimators\": n_estimators,\n    \"max_features\": max_features,\n    \"max_depth\": max_depth,\n    \"min_samples_split\": min_samples_split,\n    \"min_samples_leaf\": min_samples_leaf,\n    \"bootstrap\": bootstrap,\n}\n\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation,\n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=random_grid,\n    n_iter=300,\n    cv=3,\n    verbose=2,\n    random_state=42,\n    n_jobs=-1,\n)\n# Fit the random search model\nrf_random.fit(x, y)","06e6ab93":"bp = dict(rf_random.best_params_)\nbp","edf66818":"SEED = 1234\nrandom.seed(SEED)\n\nrf_tunned = RandomForestClassifier(\n    n_estimators=bp[\"n_estimators\"],\n    min_samples_split=bp[\"min_samples_split\"],\n    min_samples_leaf=bp[\"min_samples_leaf\"],\n    max_features=bp[\"max_features\"],\n    max_depth=bp[\"max_depth\"],\n    bootstrap=bp[\"bootstrap\"],\n)","c76f5a45":"rf_tunned.fit(train_x, train_y)\nrf_tunned.score(test_x, test_y)","58898127":"m_c = confusion_matrix(test_y, rf_tunned.predict(test_x))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_rfe, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)","49a0da66":"## Machine Learning","34a56ac6":"### Area\nThe area of a point.","095b38de":"### Smoothness\nThe local point variation in radius lengths.","9255d9ed":"### Fractal\nThe fractal dimension is calculate by (\"coastline approximation\" - 1).","8c8fe754":"### All dataset\nCorrelation between all the variables at dataset","3f2a5291":"### TSNE","2a1983b9":"A strong (almost 1) correlationship here means a malignant cancer.","3e4c651c":"Verify how much 'NaN' in the dataset.","c3c88f3b":"#### Inicial, 30 features","b3ad31df":"There are a few variables with the same impact in the target.","91d194f7":"### Models to baseline","6cffab64":"### Perimeter\nThe perimeter of a point.","1a3c1473":"#### DummyClassifier","00574174":"## Compare columns values\nInside the dataset are three types of data, there are: ** mean**, **worst** and **se**. Let's see all this three together at the same graph to 10 categories.","855be9d9":"### Concave\nThe number of concave portions of the contour.","8ecb2e4e":"#### RFE, 5 features","431f910b":"### Reduce features\nThere are too many features, let's reduce them","585fcb0e":"There is a lot of strong correlationship between some variables. Paying atention on the description some correlation are similar like **area_mean** with **perimeter_mean**. But our focus is the **diagnosis_b** (as diagnosis binary) let the this particular column.","ffaad3df":"#### RFECV, 14 features","5eea3922":"### Symmetry\nThe symmetry with the point itself.","816796f4":"#### RFE","237cc0cc":"#### RandomForestClassifier ","b6cd4226":"#### PCA","99fc1d76":"#### RFECV","adb1e457":"### Texture\nThe standard deviation of grey-scale values.","d4a0477c":"### Partial results","180f2dce":"Importing dataset","7c1e47c1":"### PCA","3f3b0027":"## Visualization by 2 components","275e2661":"### Concavity\nThe severity of concave portions of the contour.","533f6a51":"#### SelectKBest, 5 features","dbe469e4":"### The Target","c016d609":"### Tunning a Model","3fa7f1bc":"### Compactness\nCompactness is calculated by the expression -> (perimeter^2 \/ area - 1.0).","aac263db":"### Radius\nThe radius means of distances from the centre to points on the perimeter."}}