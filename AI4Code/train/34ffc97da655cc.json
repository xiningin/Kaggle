{"cell_type":{"3bc3cd4e":"code","744a7f0c":"code","ed681e44":"code","78cb78ae":"code","caa76322":"code","568a1d3f":"code","f209f87e":"code","3df411da":"code","c49c92a8":"code","154176af":"code","0f53c512":"code","735bd695":"code","59a07db3":"code","766c08dd":"code","87361e22":"code","b50bcd91":"code","8874de89":"code","6b441739":"code","e87937ca":"code","41841755":"code","47f9d9e6":"code","bb49345d":"code","82fdab65":"code","a208a80c":"code","60cf4462":"code","e01e6dba":"markdown"},"source":{"3bc3cd4e":"import glob\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom fastai import *\nfrom fastai.vision import *","744a7f0c":"train_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification-jpeg512\/train.csv')\ntest_df = pd.read_csv('..\/input\/test-files\/test.csv')\nsubmission_df = pd.read_csv('..\/input\/test-files\/sample_submission.csv')","ed681e44":"tfrm = get_transforms(do_flip = True, flip_vert = True)","78cb78ae":"# Check if only jpg files in test folder\nassert len(glob.glob('..\/input\/siim-isic-melanoma-classification-jpeg512\/test512\/*.jpg')) == len(os.listdir('..\/input\/siim-isic-melanoma-classification-jpeg512\/test512\/'))","caa76322":"# Check if only jpg files in train folder\nassert len(glob.glob('..\/input\/siim-isic-melanoma-classification-jpeg512\/train512\/*.jpg')) == len(os.listdir('..\/input\/siim-isic-melanoma-classification-jpeg512\/train512\/'))","568a1d3f":"test_df.image_name = test_df.image_name.apply(lambda file : file+'.jpg')","f209f87e":"train_df.image_name = train_df.image_name.apply(lambda file : file+'.jpg')","3df411da":"test_imgs = ImageList.from_df(test_df, path = '..\/input\/siim-isic-melanoma-classification-jpeg512', folder = 'test512')","c49c92a8":"np.random.seed(42)\nsrc = ImageList.from_df(train_df, path = '..\/input\/siim-isic-melanoma-classification-jpeg512', folder = 'train512')\\\n                      .split_by_rand_pct(0.2)\\\n                      .label_from_df(cols = -1)\\\n                      .add_test(test_imgs)\n                      ","154176af":"src","0f53c512":"data = src.transform(tfrm, padding_mode = 'reflection', size = 324, resize_method = ResizeMethod.SQUISH).databunch(bs = 32, device = None)\\\n          .normalize(imagenet_stats)\n          #.databunch(bs = 32, device = torch.device('cuda:0'))\\\n          ","735bd695":"data.show_batch(3)","59a07db3":"data.classes","766c08dd":"learn = cnn_learner(data=data, base_arch=models.resnet101, metrics=[FBeta(beta=1, average='macro'), accuracy],\n                    callback_fns=ShowGraph)","87361e22":"learn.summary()","b50bcd91":"learn.model_dir = '\/kaggle\/output\/'","8874de89":"for obj in gc.get_objects():\n    if torch.is_tensor(obj):\n        del obj\ngc.collect()\ntorch.cuda.empty_cache()","6b441739":"learn.fit_one_cycle(4)","e87937ca":"learn.model_dir = '\/kaggle\/working\/'","41841755":"learn.save('baseline')","47f9d9e6":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","bb49345d":"learn.unfreeze()\nlearn.fit_one_cycle(4, 1e-5)","82fdab65":"learn.save('version1')","a208a80c":"learn.summary()","60cf4462":"test = os.listdir(Path('..\/input\/siim-isic-melanoma-classification-jpeg512\/test512'))\ntest.sort(key=lambda f: int(re.sub('\\D', '', f)))\n\nwith open('\/kaggle\/working\/submission.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['image_name', 'target'])\n    \n    for image_file in test:\n        image = os.path.join(Path('..\/input\/siim-isic-melanoma-classification-jpeg512\/test512'), image_file) \n        image_name = Path(image).stem\n\n        img = open_image(image)\n        pred_class,pred_idx,outputs = learn.predict(img)\n        target = float(outputs[1])\n\n        \n        writer.writerow([image_name, target])","e01e6dba":"**FastAI implementation of Skin Cancer Classification competition with 512 * 512 sized images\n\nUpdate Log - Change in image size from 128 to 324 lifted score from 0.858 to 0.9. Data cleaning and Null data handling with further boost score**"}}