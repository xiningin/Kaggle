{"cell_type":{"0fbbd382":"code","f7dfebb0":"code","48d4559c":"code","6a62b92d":"code","aff5c729":"code","4a809114":"code","a1fa3a55":"code","c1d09ecd":"code","b124d42f":"code","34bf9dec":"code","3be82d04":"code","14e21fc0":"code","85710eb1":"code","4251a28b":"code","7d35e850":"code","33fc9e02":"code","cfbaa675":"code","219a72e1":"code","183698b4":"code","c12e0e7d":"code","e67a7662":"code","df538f1f":"code","fa9c1d27":"code","027446f6":"code","f33f1834":"code","60a1f690":"code","1ac4b868":"code","75f6ecf3":"code","6efd6a29":"code","a664c16a":"code","5eec3146":"code","a14bd055":"code","27d1dbe7":"markdown","d0a6d3b3":"markdown","ea4f8b38":"markdown","d812e608":"markdown","edd07c5d":"markdown","3d6dc230":"markdown","b8865c63":"markdown","3795a3df":"markdown","95920988":"markdown","6e4ac115":"markdown","2a643625":"markdown","6b948845":"markdown"},"source":{"0fbbd382":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","f7dfebb0":"df=pd.read_csv('\/kaggle\/input\/real-estate-price-prediction\/Real estate.csv')","48d4559c":"df.shape","6a62b92d":"df.head()","aff5c729":"df.info()","4a809114":"df.describe()","a1fa3a55":"sns.pairplot(df)","c1d09ecd":"plt.figure(figsize=(8,5))\nsns.displot(df['Y house price of unit area'] , bins=30 , kde=True )","b124d42f":"sns.heatmap(df.corr(), annot=True,cmap='Greens')","34bf9dec":"X = df.drop('Y house price of unit area',axis=1)\ny = df['Y house price of unit area']","3be82d04":"from sklearn.preprocessing import PolynomialFeatures","14e21fc0":"polynomial_converter=PolynomialFeatures(degree=3, include_bias=False)","85710eb1":"poly_features=polynomial_converter.fit(X)","4251a28b":"poly_features=polynomial_converter.transform(X)","7d35e850":"X.shape","33fc9e02":"poly_features.shape\n#Poly_Features: X1, X2, X3, X1^2, X2^2, X3^2, X1X2, X1X3, X2X3","cfbaa675":"from sklearn.model_selection import train_test_split","219a72e1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","183698b4":"from sklearn.linear_model import LinearRegression","c12e0e7d":"model= LinearRegression()","e67a7662":"model.fit(X_train, y_train)","df538f1f":"print(\"shape of original dataset :\", df.shape)\nprint(\"shape of input - training set\", X_train.shape)\nprint(\"shape of output - training set\", y_train.shape)\nprint(\"shape of input - testing set\", X_test.shape)\nprint(\"shape of output - testing set\", y_test.shape)","fa9c1d27":"pd.DataFrame(model.coef_, X.columns, columns=['Coeficient'])","027446f6":"y_pred=model.predict(X_test)","f33f1834":"pd.DataFrame({'Y_Test':y_test , 'Y_Pred':y_pred , 'Residuals':(y_test-y_pred)}).head()","60a1f690":"from sklearn import metrics\n\nMAE_Poly = metrics.mean_absolute_error(y_test,y_pred)\nMSE_Poly = metrics.mean_squared_error(y_test,y_pred)\nRMSE_Poly = np.sqrt(MSE_Poly)\n\npd.DataFrame([MAE_Poly, MSE_Poly, RMSE_Poly], index=['MAE', 'MSE', 'RMSE'], columns=['metrics'])","1ac4b868":"XS_train, XS_test, ys_train, ys_test = train_test_split(X, y, test_size=0.3, random_state=101)\nsimplemodel=LinearRegression()\nsimplemodel.fit(XS_train, ys_train)\nys_pred=simplemodel.predict(XS_test)\n\nMAE_simple = metrics.mean_absolute_error(ys_test,ys_pred)\nMSE_simple = metrics.mean_squared_error(ys_test,ys_pred)\nRMSE_simple = np.sqrt(MSE_simple)","75f6ecf3":"pd.DataFrame({'Poly Metrics': [MAE_Poly, MSE_Poly, RMSE_Poly], 'Simple Metrics':[MAE_simple, MSE_simple, RMSE_simple]}, index=['MAE', 'MSE', 'RMSE'])","6efd6a29":"# Train List of RMSE per degree\ntrain_RMSE_list=[]\n#Test List of RMSE per degree\ntest_RMSE_list=[]\n\nfor d in range(1,10):\n    \n    #Preprocessing\n    #create poly data set for degree (d)\n    polynomial_converter= PolynomialFeatures(degree=d, include_bias=False)\n    poly_features= polynomial_converter.fit(X)\n    poly_features= polynomial_converter.transform(X)\n    \n    #Split the dataset\n    X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n    \n    #Train the Model\n    polymodel=LinearRegression()\n    polymodel.fit(X_train, y_train)\n    \n    #Predicting on both Train & Test Data\n    y_train_pred=polymodel.predict(X_train)\n    y_test_pred=polymodel.predict(X_test)\n    \n    #Evaluating the Model\n    \n    #RMSE of Train set\n    train_RMSE=np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n    \n    #RMSE of Test Set\n    test_RMSE=np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n    \n    #Append the RMSE to the Train and Test List\n    \n    train_RMSE_list.append(train_RMSE)\n    test_RMSE_list.append(test_RMSE)","a664c16a":"train_RMSE_list","5eec3146":"test_RMSE_list","a14bd055":"plt.plot(range(1,5), train_RMSE_list[:4], label='Train RMSE')\nplt.plot(range(1,5), test_RMSE_list[:4], label='Test RMSE')\n\nplt.xlabel('Polynomial Degree')\nplt.ylabel('RMSE')\nplt.legend()","27d1dbe7":"# Split the Dataset to Train & Test\nSplit arrays or matrices into random train and test subsets\nQuick utility that wraps input validation and next and application to input data into a single call for splitting  data in a oneliner.\nIn machine learning, it is a common practice to split your data into two different sets. These two sets are the training set and the testing set. As the name suggests, the training set is used for training the model and the testing set is used for testing the accuracy of the model.","d0a6d3b3":"It seems degree 2 is the best choice for model.","ea4f8b38":"# Import all necessary Libraries","d812e608":"# Compare to the simple linear regression:","edd07c5d":"# Evalutaing the Model\nModel Evaluation is an integral part of the model development process. It helps to find the best model that represents our data and how well the chosen model will work in the future. Evaluating model performance with the data used for training is not acceptable in data science because it can easily generate overoptimistic and overfitted models. There are two methods of evaluating models in data science, Hold-Out and Cross-Validation. To avoid overfitting, both methods use a test set (not seen by the model) to evaluate model performance.\nIn this method, the mostly large dataset is randomly divided to three subsets:\t\t\nTraining set is a subset of the dataset used to build predictive models.\nValidation set is a subset of the dataset used to assess the performance of model built in the training phase. It provides a test platform for fine tuning model's parameters and selecting the best-performing model. Not all modeling algorithms need a validation set.\nTest set or unseen examples is a subset of the dataset to assess the likely future performance of a model. If a model fit to the training set much better than it fits the test set, overfitting is probably the cause.\n\n\n","3d6dc230":"# Polynomial Regression\nstatistics, polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x. Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y, denoted E(y |x). Although ","b8865c63":"# Preprocessing\nThe sklearn.preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\nIn general, learning algorithms benefit from standardization of the data set. If some outliers are present in the set, robust scalers or transformers are more appropriate. The behaviors of the different scalers, transformers, and normalizers on a dataset containing marginal outliers is highlighted in Compare the effect of different scalers on data with outliers.","3795a3df":"# Coeficient Matrix\nIn mathematics, a system of linear equations is a collection of one or more linear equations involving the same set of variable.","95920988":"#  Determine the Features & Target Variable","6e4ac115":"To compare the shape of different testing and training sets, use the following piece of code:","2a643625":"# Import the Dataset","6b948845":"train_test_split randomly distributes your data into training and testing set according to the ratio provided."}}