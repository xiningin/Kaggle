{"cell_type":{"5b885862":"code","3529745e":"code","25450b25":"code","c71c634f":"code","43d915ae":"code","9b46ba8f":"code","95a92581":"code","1a8a2c1b":"code","d4ffbf47":"code","d0e25ed4":"code","e6487bf3":"code","6cec297d":"code","aa4bdceb":"code","7339c7e3":"code","2703e310":"code","6165ed0f":"code","da25e579":"code","4bd4a7d0":"code","9cd06b44":"code","fc7d63c8":"code","a262da97":"code","0a6f033e":"code","802b083a":"code","fe66ae6f":"code","2a4d0511":"code","1f3d1de1":"markdown","d65b4cd9":"markdown","28152b1f":"markdown","b2e3d107":"markdown","b9d729e4":"markdown","57f277c3":"markdown","f756e404":"markdown","5297d8c7":"markdown","cdc8ace8":"markdown","c2e506ee":"markdown","b960c7c1":"markdown","fa3af88c":"markdown","39c59e97":"markdown","2168111f":"markdown"},"source":{"5b885862":"!wget -O gold.parquet https:\/\/www.dropbox.com\/s\/3m0xqogz5gi2moy\/gold.parquet?dl=1","3529745e":"!ls \/content","25450b25":"import pandas as pd\n\nwork_dir = \"\/content\"\n\n#leitura dos dados de entrada\ndf_bruto = pd.read_parquet(work_dir +\"\/gold.parquet\", engine=\"pyarrow\")\ndf_bruto.shape","c71c634f":"df_bruto","43d915ae":"df_bruto.info()","9b46ba8f":"# n\u00e3o iremos utilizar estas duas colunas no treinamento e no teste\ndf_preparado = df_bruto.drop(['key', 'timestamp'], axis=1)\n\n# iremos remover a feature ultima_compra, \n# mas fica como exerc\u00edcio voc\u00ea aproveit\u00e1-la no conjunto de features\ndf_preparado = df_preparado.drop(['ultima_compra'], axis=1)","95a92581":"df_preparado","1a8a2c1b":"df_bruto.head(200)\n#pd.set_option('display.max_rows', 200)","d4ffbf47":"df_preparado","d0e25ed4":"# Substitui valores nulos por 0 nas colunas num\u00e9ricas\ncolunas_numericas = ['pedidos_4_meses','pedidos_8_meses','pedidos_12_meses','itens_4_meses','itens_8_meses','itens_12_meses']\ndf_preparado[colunas_numericas] = df_preparado[colunas_numericas].fillna(value=0)\n\n# transformar colunas categ\u00f3ricas em num\u00e9ricas\ndf_preparado = pd.get_dummies(df_preparado, columns=[\"city\", \"state\", \"cnae_id\"])\ndf_preparado.head()","e6487bf3":"#Tentei deixar a coluna \"ultima_compra\" para ver se aumenta o Score, mas n\u00e3o deu certo.\n\n\"\"\"\n#df_preparado2\n#df_preparado2 = df_bruto.drop(['key', 'timestamp'], axis=1)\n\n# Substitui valores nulos por 0 nas colunas num\u00e9ricas\ncolunas_numericas2 = ['pedidos_4_meses','pedidos_8_meses','pedidos_12_meses','itens_4_meses','itens_8_meses','itens_12_meses', 'ultima_compra']\ndf_preparado2[colunas_numericas2] = df_preparado2[colunas_numericas2].fillna(value=0)\n\ndf_preparado2['ultima_compra'] = df_preparado2['ultima_compra'].astype('bool')\ndf_preparado2\n\n# transformar colunas categ\u00f3ricas em num\u00e9ricas\ndf_preparado2 = pd.get_dummies(df_preparado2, columns=[\"city\", \"state\", \"cnae_id\"])\ndf_preparado2.head()\n\n\n#df_preparado = df_preparado2\n#df_preparado\ndf_preparado2[\"ultima_compra\"] = df_preparado2[\"ultima_compra\"].astype(int)\n\ndf_preparado = df_preparado2\ndf_preparado\n\"\"\"","6cec297d":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# seleciona as tuplas com r\u00f3tulos\ndf_to_train = df_preparado[df_preparado[\"defaulting\"].notnull()]\n\n# remove a coluna defaulting dos dados de treinamento para n\u00e3o gerar overfiting\nX = df_to_train.drop('defaulting', axis=1)\n\n# Transforma a vari\u00e1vel a predizer de boolean para inteiro\nle = LabelEncoder()\ny = le.fit_transform(df_to_train.defaulting.values)\n\n# Divis\u00e3o em conjunto de treinamento e valida\u00e7\u00e3o\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.01, random_state=1) #Mudei o test_size de 0.2 para 0.01, ai aumentou o Score\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_valid.shape)\nprint(y_valid.shape)","aa4bdceb":"X_train","7339c7e3":"df_to_train.defaulting.values","2703e310":"y","6165ed0f":"X_train.info() #MUST BE int, float or bool.","da25e579":"#Havia feito um clone dos datasets, e converti a coluna client_id para INT para o xgboost n\u00e3o reclamar.\n#X_train_TESTE = X_train.copy()\n#X_valid_TESTE = X_valid.copy()\n\n\"\"\"\nConvertendo a primeira coluna para INT\nX_train to X_train_TESTE\ny_train to  - NAO PRECISA\nX_valid to X_valid_TESTE\n\"\"\"\n#X_train_TESTE = X_train_TESTE.astype({\"client_id\": int}) \n#X_valid_TESTE = X_valid_TESTE.astype({\"client_id\": int}) \n\n\n#Converti a coluna client_id para INT para o xgboost n\u00e3o reclamar.\nX_train = X_train.astype({\"client_id\": int}) \nX_valid = X_valid.astype({\"client_id\": int}) ","4bd4a7d0":"import xgboost as xgb\nimport sklearn.metrics as metrics\n#from sklearn.tree import DecisionTreeClassifier\n#from sklearn.ensemble import RandomForestClassifier\n\n# Cria um classificador\n#clf = DecisionTreeClassifier()\n#clf = RandomForestClassifier()\n#clf = xgb.XGBClassifier(learning_rate=0.009, max_depth=6, min_child_weight=3, subsample=0.15, colsample_bylevel=0.85, n_estimators=500)\nclf = xgb.XGBClassifier()\n\n# Treina a \u00c1rvore de Decis\u00e3o\nclf = clf.fit(X_train,y_train)\n\n# Prediz a resposta para o dataset de valida\u00e7\u00e3o\ny_pred = clf.predict(X_valid)\n\n#8000 linhas para treinamento e 2000 rows para treinamento, e 5000 est\u00e3o nullos, ou seja, n\u00e3o sabemos, ser\u00e3o os de testes la no kaggle\n\nprint(y_pred) #Verifica se o result est\u00e1 corretos (apenas com Zeros e Uns)\nprint(\"ROC AUC:\",metrics.roc_auc_score(y_valid, y_pred)) #Imprime o Score","9cd06b44":"y_valid.shape\ny_pred.shape","fc7d63c8":"import sklearn.metrics as metrics\nprint(\"ROC AUC:\",metrics.roc_auc_score(y_valid, y_pred)) #Usada no Kaggle\nprint(\"Acur\u00e1cia:\",metrics.accuracy_score(y_valid, y_pred))\nprint(\"F1 score:\",metrics.f1_score(y_valid, y_pred))\n\n#0.8214285714285714","a262da97":"df_test = df_preparado[df_preparado[\"defaulting\"].isnull()]\ndf_test.shape","0a6f033e":"X_test = X_test.astype({\"client_id\": int}) \n#X_test = df_test.drop('defaulting', axis=1)\ny_test = clf.predict(X_test)\ny_test","802b083a":"output = df_test.assign(inadimplente=y_test)\noutput = output.loc[:, ['client_id','inadimplente']]\noutput.head()","fe66ae6f":"output.to_csv(work_dir +\"\/ouput_sklearn.csv\", index=False)","2a4d0511":"from google.colab import files\nfiles.download('ouput_sklearn.csv') ","1f3d1de1":"## Preparando o ambiente\n\nO c\u00f3digo abaixo adiciona a **raiz** do projeto, que cont\u00e9m c\u00f3digos e dados necess\u00e1rios para o \"Hands on\".","d65b4cd9":"## Leitura dos dados\n\nO trecho de c\u00f3digo abaixo cria uma vari\u00e1vel *work_dir*, que ir\u00e1 apontar para o caminho no sistema de arquivos onde est\u00e3o os dados de entrada e onde a sa\u00edda ser\u00e1 escrita. Como os dados de entrada est\u00e3o no formato Parquet, o Pandas ir\u00e1 utilizar o motor de leitura Pyarrow para conseguir ler este formato de dados e aumentar a performance de leitura e transforma\u00e7\u00f5es no DataFrame.","28152b1f":"## Predi\u00e7\u00e3o sobre os dados de testes\n\nNesta \u00faltima etapa, o modelo busca predizer se o cliente est\u00e1 ou n\u00e3o inadimplente sobre os dados de teste (coluna defaulting igual a nulo). Os dados de teste ficar\u00e3o armazenados no DataFrame *df_test*. ","b2e3d107":"A sa\u00edda do modelo \u00e9 salvo em um arquivo csv, contendo as colunas \"client_id\" e \"inadimplente\". Estas colunas ser\u00e3o utilizadas para avaliar a acur\u00e1cia do modelo. Por isso, o resultado da predi\u00e7\u00e3o em *y_test* \u00e9 adicionada em uma nova coluna (inadimplente) do DataFrame df_test.","b9d729e4":"Os valores nulos das colunas num\u00e9ricas s\u00e3o substitu\u00eddos por zero.\nAs colunas \"city\", \"state\", \"cnae_id\" s\u00e3o transformadas para valores num\u00e9ricos utilizando a fun\u00e7\u00e3o [get_dummies](https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.23.4\/generated\/pandas.get_dummies.html) do Pandas. Essa Engenharia de Features \u00e9 importante para que o classificador funcione corretamente.","57f277c3":"O Dataframe *output* \u00e9 escrito no formato CSV para gerar a sa\u00edda do algoritmo de aprendizado de m\u00e1quina constru\u00eddo neste notebook.","f756e404":"## Engenharia de Features\n\nEngenharia de Features \u00e9 o processo de usar o conhecimento de dom\u00ednio sobre os dados para criar *features* que fazem os algoritmos de aprendizado de m\u00e1quina funcionar da forma que esperamos. \n\nPrimeiramente, iremos remover do DataFrame as features que n\u00e3o iremos utilizar na classifica\u00e7\u00e3o. As features *key* e *timestamp* s\u00e3o removidas por n\u00e3o terem correla\u00e7\u00e3o com o fato do cliente estar ou n\u00e3o inadimplente. A vari\u00e1vel *ultima_compra* foi removida para ficar como exerc\u00edcio para voc\u00ea inclu\u00ed-la no conjunto de features.","5297d8c7":"## Treinamento e Avalia\u00e7\u00e3o do modelo\n\nNesta etapa iremos treinar o nosso classificador, neste caso uma [\u00e1rvore de decis\u00e3o](https:\/\/spark.apache.org\/docs\/2.4.6\/ml-classification-regression.html#decision-tree-classifier). Os dados de treinamento est\u00e3o armazenados em *X_train* (features) e *y_train* (r\u00f3tulo). A predi\u00e7\u00e3o \u00e9 realizada com os dados de treinamento em *X_valid*.","cdc8ace8":"## Classifica\u00e7\u00e3o utilizando Pandas e Scikit-learn\n\nNeste notebook iremos fazer a predizer os clientes inadimplentes utilizando a biblioteca [Scikit-learn](https:\/\/scikit-learn.org\/) e o Pandas. Iremos desenvolver, neste notebook, um modelo capaz de predizer se o cliente est\u00e1 ou n\u00e3o inadimplente, ou seja, uma tarefa de classifica\u00e7\u00e3o bin\u00e1ria.","c2e506ee":"## Considera\u00e7\u00f5es Finais\n\nAgora \u00e9 com **voc\u00ea**! Ainda existe muito espa\u00e7o para melhoria na acur\u00e1cia do modelo que desenvolvemos at\u00e9 agora. Utilize o material complementar abaixo para modificar este notebook e construir um algoritmo melhor.\n\n- [Curso de Aprendizado de M\u00e1quina de Stanford com Andrew Ng](https:\/\/www.coursera.org\/learn\/machine-learning)\n- [M\u00e3os \u00e0 Obra: Aprendizado de M\u00e1quina com Scikit-Learn & TensorFlow](https:\/\/www.amazon.com.br\/M%C3%A3os-Obra-Aprendizado-Scikit-Learn-TensorFlow\/dp\/8550803812)\n- [Introduction to Machine Learning with Python](https:\/\/www.amazon.com.br\/Introduction-Machine-Learning-Andreas-Mueller\/dp\/1449369413)\n- [Data Science do Zero](https:\/\/www.amazon.com.br\/Data-Science-zero-Joel-Grus\/dp\/857608998X)\n- [Customer Churn Classification Using Predictive Machine Learning Models](https:\/\/towardsdatascience.com\/customer-churn-classification-using-predictive-machine-learning-models-ab7ba165bf56)","b960c7c1":"O esquema \u00e9 apresentado na linha abaixo, para que possamos visualizar o modelo de dados que iremos trabalhar.","fa3af88c":"O nosso *dataset* cont\u00e9m os dados de treinamento e de teste do nosso modelo. Aqui os dados de teste s\u00e3o aqueles que **n\u00e3o** possuem r\u00f3tulo e ser\u00e3o utilizados na solu\u00e7\u00e3o final. Dentro dos dados de treinamento (\"defaulting is not null\") vamos dividir nosso *dataset* entre dados de treinamento do modelo e dados de valida\u00e7\u00e3o, sendo 80% para o primeiro conjunto e 20% para o segundo. Queremos predizer o valor da coluna *defaulting*, mas ela \u00e9 do tipo boolean e deve ser transformada para o tipo inteiro para o nosso algoritmo de aprendizado de m\u00e1quina (\u00c1rvore de Decis\u00e3o) conseguir fazer a classifica\u00e7\u00e3o.","39c59e97":"Para **avaliar** a acur\u00e1cia do modelo, o resultado da predi\u00e7\u00e3o *y_pred* \u00e9 comparado com o resultado esperado *y_valid* para gerar as m\u00e9tricas ROC, Acur\u00e1cia e F1.","2168111f":"Os dados de teste s\u00e3o gerados e armazenados em *X_test*, excluindo a coluna *defaulting* que desejamos predizer. O modelo faz a predi\u00e7\u00e3o e tem como sa\u00edda os valores da predi\u00e7\u00e3o em *y_test*."}}