{"cell_type":{"c6b1290f":"code","7418bf39":"code","c6d05587":"code","413b0847":"code","87560acf":"code","3d3b90c8":"code","2b6147d1":"code","8c8418a5":"code","a0c8e96d":"code","d9399c04":"code","109a3ec2":"code","0b774388":"code","a03785bc":"code","c131a366":"code","a2fb01ea":"code","234c7c60":"code","462088f6":"code","f8d1746a":"code","e5b3e119":"code","269da5a1":"code","50c9d1a1":"code","d715169d":"code","24381af2":"code","6ba6e73a":"code","38b22ce2":"code","32153ec5":"code","4f9e9b38":"code","b2caf648":"code","acf90ee9":"code","3af8a294":"code","e60f3ebd":"code","39390997":"code","b0522975":"code","dd13fee5":"code","83986b37":"code","5ef17c82":"code","9df4029a":"code","3e503151":"code","ac006cfb":"code","02ac68f7":"code","7f87ebb0":"code","05e4ebfa":"code","b90dd4c2":"code","353b7ece":"markdown","56b009ca":"markdown","9c1cfef3":"markdown","78b374c1":"markdown","03231bb7":"markdown","5f91eb8d":"markdown","e0d66c56":"markdown","ec7993ab":"markdown","d14725f3":"markdown","5d35d315":"markdown","a8fdf02c":"markdown","c5d9be0e":"markdown","4fbaab11":"markdown","598565b4":"markdown","ec06766b":"markdown","11de8f23":"markdown"},"source":{"c6b1290f":"# Import the requires tools\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nimport plotly.express as px\nfrom sklearn.preprocessing import OrdinalEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold\nfrom mlxtend.regressor import StackingRegressor \nimport optuna\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7418bf39":"# Import the data\ntrain = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2021\/test.csv\")","c6d05587":"train.head()","413b0847":"train.info()","87560acf":"train.describe()","3d3b90c8":"# Count plot of the categorical features\nfig, ax = plt.subplots(nrows=5, ncols=2, figsize=(14, 16))\nax0 = sns.countplot(train[\"cat0\"], ax=ax[0][0])\nax1 = sns.countplot(train[\"cat1\"], ax=ax[0][1])\nax2 = sns.countplot(train[\"cat2\"], ax=ax[1][0])\nax3 = sns.countplot(train[\"cat3\"], ax=ax[1][1])\nax4 = sns.countplot(train[\"cat4\"], ax=ax[2][0])\nax5 = sns.countplot(train[\"cat5\"], ax=ax[2][1])\nax6 = sns.countplot(train[\"cat6\"], ax=ax[3][0])\nax7 = sns.countplot(train[\"cat7\"], ax=ax[3][1])\nax8 = sns.countplot(train[\"cat8\"], ax=ax[4][0])\nax9 = sns.countplot(train[\"cat9\"], ax=ax[4][1])","2b6147d1":"# PDF of the continous features\nfig, ax = plt.subplots(nrows=7, ncols=2, figsize=(14, 24))\nax0 = sns.kdeplot(train[\"cont0\"], ax=ax[0][0])\nax1 = sns.kdeplot(train[\"cont1\"], ax=ax[0][1])\nax2 = sns.kdeplot(train[\"cont2\"], ax=ax[1][0])\nax3 = sns.kdeplot(train[\"cont3\"], ax=ax[1][1])\nax4 = sns.kdeplot(train[\"cont4\"], ax=ax[2][0])\nax5 = sns.kdeplot(train[\"cont5\"], ax=ax[2][1])\nax6 = sns.kdeplot(train[\"cont6\"], ax=ax[3][0])\nax7 = sns.kdeplot(train[\"cont7\"], ax=ax[3][1])\nax8 = sns.kdeplot(train[\"cont8\"], ax=ax[4][0])\nax9 = sns.kdeplot(train[\"cont9\"], ax=ax[4][1])\nax10 = sns.kdeplot(train[\"cont10\"], ax=ax[5][0])\nax11 = sns.kdeplot(train[\"cont11\"], ax=ax[5][1])\nax12 = sns.kdeplot(train[\"cont12\"], ax=ax[6][0])\nax13 = sns.kdeplot(train[\"cont13\"], ax=ax[6][1])","8c8418a5":"# CDF of the continous features\nfig, ax = plt.subplots(nrows=7, ncols=2, figsize=(14, 24))\nax0 = sns.ecdfplot(train[\"cont0\"], ax=ax[0][0])\nax1 = sns.ecdfplot(train[\"cont1\"], ax=ax[0][1])\nax2 = sns.ecdfplot(train[\"cont2\"], ax=ax[1][0])\nax3 = sns.ecdfplot(train[\"cont3\"], ax=ax[1][1])\nax4 = sns.ecdfplot(train[\"cont4\"], ax=ax[2][0])\nax5 = sns.ecdfplot(train[\"cont5\"], ax=ax[2][1])\nax6 = sns.ecdfplot(train[\"cont6\"], ax=ax[3][0])\nax7 = sns.ecdfplot(train[\"cont7\"], ax=ax[3][1])\nax8 = sns.ecdfplot(train[\"cont8\"], ax=ax[4][0])\nax9 = sns.ecdfplot(train[\"cont9\"], ax=ax[4][1])\nax10 = sns.ecdfplot(train[\"cont10\"], ax=ax[5][0])\nax11 = sns.ecdfplot(train[\"cont11\"], ax=ax[5][1])\nax12 = sns.ecdfplot(train[\"cont12\"], ax=ax[6][0])\nax13 = sns.ecdfplot(train[\"cont13\"], ax=ax[6][1])","a0c8e96d":"# Violin plot of the continous features\nfig, ax = plt.subplots(nrows=7, ncols=2, figsize=(14, 24))\nax0 = sns.violinplot(train[\"cont0\"], ax=ax[0][0], orient=\"v\")\nax1 = sns.violinplot(train[\"cont1\"], ax=ax[0][1], orient=\"v\")\nax2 = sns.violinplot(train[\"cont2\"], ax=ax[1][0], orient=\"v\")\nax3 = sns.violinplot(train[\"cont3\"], ax=ax[1][1], orient=\"v\")\nax4 = sns.violinplot(train[\"cont4\"], ax=ax[2][0], orient=\"v\")\nax5 = sns.violinplot(train[\"cont5\"], ax=ax[2][1], orient=\"v\")\nax6 = sns.violinplot(train[\"cont6\"], ax=ax[3][0], orient=\"v\")\nax7 = sns.violinplot(train[\"cont7\"], ax=ax[3][1], orient=\"v\")\nax8 = sns.violinplot(train[\"cont8\"], ax=ax[4][0], orient=\"v\")\nax9 = sns.violinplot(train[\"cont9\"], ax=ax[4][1], orient=\"v\")\nax10 = sns.violinplot(train[\"cont10\"], ax=ax[5][0], orient=\"v\")\nax11 = sns.violinplot(train[\"cont11\"], ax=ax[5][1], orient=\"v\")\nax12 = sns.violinplot(train[\"cont12\"], ax=ax[6][0], orient=\"v\")\nax13 = sns.violinplot(train[\"cont13\"], ax=ax[6][1], orient=\"v\")","d9399c04":"fig, ax = plt.subplots(nrows=5, ncols=2, figsize=(12, 16))\nax0 = sns.boxplot(x=train[\"cat0\"], y=train[\"target\"], ax=ax[0][0]);\nax1 = sns.boxplot(x=train[\"cat1\"], y=train[\"target\"], ax=ax[0][1]);\nax2 = sns.boxplot(x=train[\"cat2\"], y=train[\"target\"], ax=ax[1][0]);\nax3 = sns.boxplot(x=train[\"cat3\"], y=train[\"target\"], ax=ax[1][1]);\nax4 = sns.boxplot(x=train[\"cat4\"], y=train[\"target\"], ax=ax[2][0]);\nax5 = sns.boxplot(x=train[\"cat5\"], y=train[\"target\"], ax=ax[2][1]);\nax6 = sns.boxplot(x=train[\"cat6\"], y=train[\"target\"], ax=ax[3][0]);\nax7 = sns.boxplot(x=train[\"cat7\"], y=train[\"target\"], ax=ax[3][1]);\nax8 = sns.boxplot(x=train[\"cat8\"], y=train[\"target\"], ax=ax[4][0]);\nax9 = sns.boxplot(x=train[\"cat9\"], y=train[\"target\"], ax=ax[4][1]);","109a3ec2":"# Distribution of the target variable\nsns.histplot(train[\"target\"]);","0b774388":"cont_feature = train.iloc[:, 12:24]\ncont_corr_p = cont_feature.corr(method=\"spearman\")","a03785bc":"sns.heatmap(cont_corr_p);","c131a366":"cont_corr_sp = cont_feature.corr(method=\"spearman\")\nsns.heatmap(cont_corr_sp);","a2fb01ea":"categorical_features = [\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\",\"cat6\", \"cat7\", \"cat8\", \"cat9\"]","234c7c60":"# def smoothing(train, test):\n    \n#     # compute the mean\n#     mean = train[\"target\"].mean()\n#     for i in categorical_features:\n#         agg = train.groupby(i)[\"target\"].agg([\"count\", \"mean\"])\n#         count = agg[\"count\"]\n#         mean = agg[\"mean\"]\n#         weight = 10\n        \n#         # smoothed mean\n#         smooth = (count * mean + weight * mean) \/ (count * weight)\n        \n#         train[i] = train[i].map(smooth)\n#         test[i] = test[i].map(smooth)\n    \n#     return train, test","462088f6":"le = LabelEncoder()\nfor cat in categorical_features:\n    train[cat] = le.fit_transform(train[cat])\n    test[cat] = le.fit_transform(test[cat])","f8d1746a":"train = train[train[\"target\"] > 4.0]","e5b3e119":"X = train.drop([\"target\", \"id\"],axis=1)\ny = train[\"target\"]","269da5a1":"def K_fold_CV(X, y, model, params, folds=5):\n    rmse_error = []\n    skf = KFold(n_splits=folds, shuffle=True, random_state=42)\n    for fold, (tr_idx, ts_idx) in enumerate(skf.split(X, y)):\n        print(f\"Fold: {fold}\")\n        x_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n        x_ts, y_ts = X.iloc[ts_idx], y.iloc[ts_idx]\n\n        reg = model(**params)\n        reg.fit(x_tr, y_tr,\n                eval_set=[(x_ts, y_ts)],\n                early_stopping_rounds=100,\n                verbose=False)\n\n        error = mean_squared_error(y_ts, reg.predict(x_ts), squared=False)\n        rmse_error.append(error)\n        print(f\"RMSE Error: {error}\")\n        print(\"-\"*25)\n    \n    return reg, np.mean(rmse_error)","50c9d1a1":"param_lgb = {\n    \"random_state\": 2021,\n    \"metric\": \"rmse\",\n    \"n_jobs\": -1,\n    \"early_stopping_round\": 200,\n    \"reg_alpha\": 9.03513073170552,\n    \"reg_lambda\": 0.024555737897445917,\n    \"colsample_bytree\": 0.2185112060137363,\n    \"learning_rate\": 0.003049106861273527,\n    \"max_depth\": 65,\n    \"num_leaves\": 51,\n    \"min_child_samples\": 177,\n    \"n_estimators\": 1600000,\n    \"cat_smooth\": 93.60968300634175,\n    \"max_bin\": 537,\n    \"min_data_per_group\": 117,\n    \"bagging_freq\": 1,\n    \"bagging_fraction\": 0.6709049555262285,\n    \"cat_l2\": 7.5586732660804445,\n}","d715169d":"%%time\nmodel_lgb, lgb_error = K_fold_CV(X, y, LGBMRegressor, params=param_lgb, folds=7)","24381af2":"lgb_error","6ba6e73a":"# plot importance features\nlgb.plot_importance(model_lgb)","38b22ce2":"param_cbr = {\n    'loss_function': 'RMSE',\n    \"max_depth\": 4,\n    'learning_rate': 0.03,\n    \"bootstrap_type\": 'Poisson',\n    \"subsample\": 0.8,\n    \"border_count\": 512,\n    \"l2_leaf_reg\": 200,\n    'random_state': 42,\n    \"thread_count\": 2,\n    'num_boost_round': 50000,\n    \"task_type\": \"GPU\",\n    \"devices\" : \"0\",\n}","32153ec5":"%%time\ncbr, cbr_error = K_fold_CV(X, y, CatBoostRegressor, params=param_cbr, folds=7)","4f9e9b38":"cbr_error","b2caf648":"#cbr.feature_importances_\nplt.bar(range(len(cbr.feature_importances_)), cbr.feature_importances_)\nplt.show()","acf90ee9":"param_xgb = {\n    'booster':'gbtree',\n    'n_estimators':2328,\n    'learning_rate':0.014,\n    'max_depth':7, \n    'eta':0.008,\n    'gamma':3.5,\n    'objective':'reg:squarederror',\n    'verbosity':0,\n    'subsample':0.7,\n    'colsample_bytree':0.3,\n    'reg_lambda':0.012137972665213192,\n    'reg_alpha':0.627569414718695,\n    'scale_pos_weight':1,\n    'min_child_weight': 4.635026563569194,\n    'eval_metric':'rmse',\n    'tree_method':'gpu_hist',\n    'gpu_id':0,\n}","3af8a294":"%%time\nmodel_xgb, xgb_error = K_fold_CV(X, y, XGBRegressor, params=param_xgb, folds=7)","e60f3ebd":"xgb_error","39390997":"xgb.plot_importance(model_xgb)","b0522975":"# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","dd13fee5":"# def objective(trial):\n    \n#     param = {\n#         'random_state': 42,\n#           'metric': 'rmse',\n#           'n_estimators': trial.suggest_int(\"n_estimators\", 100, 3000),\n#           'n_jobs': -1,\n#           'cat_feature': [x for x in range(len(categorical_features))],\n#           'bagging_seed': 1024,\n#           'feature_fraction_seed': 2024,\n#           'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2),\n#           'max_depth': trial.suggest_int('max_depth', 6, 127),\n#           'num_leaves': trial.suggest_int('num_leaves', 31, 128),\n#           'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n#           'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n#           'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 0.9),\n#           'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n#           'subsample_freq': trial.suggest_int('subsample_freq', 1, 10),\n#           'subsample': trial.suggest_float('subsample', 0.3, 0.9),\n#           'max_bin': trial.suggest_int('max_bin', 128, 1024),\n#           'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200),\n#           'cat_smooth': trial.suggest_int('cat_smooth', 10, 100),\n#           'cat_l2': trial.suggest_int('cat_l2', 1, 20)\n#     }\n#     model = LGBMRegressor(**param)  \n#     model.fit(x_train,y_train,eval_set=[(x_test,y_test)],early_stopping_rounds=100,verbose=False)\n#     preds = model.predict(x_test, num_iteration=model.best_iteration_)\n#     rmse = mean_squared_error(y_test, preds,squared=False)\n    \n#     return rmse","83986b37":"# study = optuna.create_study(direction='minimize')\n# study.optimize(objective, n_trials=40)\n# param_xgb = study.best_params","5ef17c82":"params = {\n    \"random_state\": 2021,\n    \"metric\": \"rmse\",\n    \"n_jobs\": -1,\n    'n_estimators': 1544, \n     'learning_rate': 0.009664135308408987, \n     'max_depth': 15, \n     'num_leaves': 119, \n     'reg_alpha': 3.966388879825433, \n     'reg_lambda': 0.7124404813240152, \n     'colsample_bytree': 0.2941761921420618, \n     'min_child_samples': 177, \n     'subsample_freq': 5, \n     'subsample': 0.8282629920254261, \n     'max_bin': 322, \n     'min_data_per_group': 110, \n     'cat_smooth': 23, \n     'cat_l2': 4\n}","9df4029a":"%%time\nmodel_lgb_new, error = K_fold_CV(X, y, LGBMRegressor, params=params, folds=7)","3e503151":"print(error)","ac006cfb":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv\")","02ac68f7":"# Make predictions for the base models\npred_lgb = model_lgb.predict(test[X.columns])\npred_cbr = cbr.predict(test[X.columns])\npred_xgb = model_xgb.predict(test[X.columns])","7f87ebb0":"# Average Ensembe\npred_avg = (pred_lgb + pred_cbr + pred_xgb) \/ 3","05e4ebfa":"# Weighted Average \npred_1 = 0.5 * pred_lgb + 0.1 * pred_cbr + 0.4 * pred_xgb\npred_2 = 0.6 * pred_lgb + 0.2 * pred_cbr + 0.2 * pred_xgb \npred_3 = 0.6 * pred_xgb + 0.4 * pred_lgb","b90dd4c2":"# Create submission files\n\n# Average Ensemble\nsubmission[\"target\"] = pred_avg\nsubmission.to_csv(\"Average_ensemble.csv\", index=False)\n\n# Weighted Ensemble\nsubmission[\"target\"] = pred_1\nsubmission.to_csv(\"weighted_ensemble_1.csv\", index=False)\n\nsubmission[\"target\"] = pred_2\nsubmission.to_csv(\"weighted_ensemble_2.csv\", index=False)\n\nsubmission[\"target\"] = pred_3\nsubmission.to_csv(\"weighted_ensemble_3.csv\", index=False)\n\nsubmission[\"target\"] = pred_xgb\nsubmission.to_csv(\"XGB.csv\", index=False)\n\nsubmission[\"target\"] = pred_lgb\nsubmission.to_csv(\"LGB.csv\", index=False)\n\nsubmission[\"target\"] = pred_cbr\nsubmission.to_csv(\"CBR.csv\", index=False)","353b7ece":"## Preprocessing","56b009ca":"### CatBoostRegressor","9c1cfef3":"## Lightgbm","78b374c1":"### Visualize the target variable with other features","03231bb7":"### XGBRegressor","5f91eb8d":"## Building the model","e0d66c56":"### Distribution of the continous features","ec7993ab":"Most of the target values lies between 6 and 10","d14725f3":"\n### Pearson correlation coffecient","5d35d315":"## Hyperparameter Tuning using optuna","a8fdf02c":"## Mean Encoding\nIn mean target encoding for each category in the feature label is decided with the mean value of the target variable on a training data. This encoding method brings out the relation between similar categories, but the connections are bounded within the categories and target itself. Smoothing is one of the variation of mean encoding.","c5d9be0e":"# Tabular Playground (Feb 2021)","4fbaab11":"### Spearman coorelation coefficient","598565b4":"## Data Visualization","ec06766b":"From the above two heatmaps  features from cont5 to cont12 have some coorelation between them.","11de8f23":"## Weighted Average Ensemble"}}