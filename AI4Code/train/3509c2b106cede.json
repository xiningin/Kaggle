{"cell_type":{"9c2c8e7f":"code","53223de2":"code","a8447f94":"code","fc212b9e":"code","a356c1f4":"code","d6b7545e":"code","53dcbe3c":"code","0034cf78":"code","0a72b94a":"code","6d9f69ca":"code","2288abb9":"code","6bd8d8b3":"code","71675434":"markdown","2497ac28":"markdown","995ec22a":"markdown","22f931f6":"markdown","fca03aa0":"markdown","707f2fe8":"markdown","51e74d46":"markdown","be179c39":"markdown"},"source":{"9c2c8e7f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","53223de2":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","a8447f94":"df_train.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], axis=1)\ndf_test.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], axis=1)","fc212b9e":"X_train = df_train.iloc[:, 1:-1] # ignore Id and Sale_price columns\nX_test = df_test.iloc[:, 1:] # ignore Id column\ny_train = df_train.iloc[:, -1] # select Sale_price column","a356c1f4":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)","d6b7545e":"num_features = X_train.dtypes[X_train.dtypes!='object'].index\ncat_features = X_train.dtypes[X_train.dtypes=='object'].index","53dcbe3c":"from sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\n\nnumerical_transformer = SimpleImputer(strategy='mean')\n\ncategorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), \n                                          ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n\n\n\npreprocessor = ColumnTransformer(transformers=[('numerical', numerical_transformer, num_features),\n                                               ('categorical', categorical_transformer, cat_features)],\n                                 remainder='passthrough')\n\nmodel = RandomForestRegressor(n_estimators=1500)","0034cf78":"my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n                              ('model', model)])\n\nmy_pipeline.fit(X_train, y_train)","0a72b94a":"y_pred = my_pipeline.predict(X_test)","6d9f69ca":"y_pred","2288abb9":"output = pd.DataFrame({'Id': df_test.Id,\n                      'SalePrice': y_pred})\noutput.to_csv('submission.csv', index=False)","6bd8d8b3":"output","71675434":"## Create train and test DataFrames","2497ac28":"## Drop columns with too many missing data","995ec22a":"## Make the predictions","22f931f6":"## Create the pipeline object and fit the training data","fca03aa0":"## Create the output file","707f2fe8":"## Create X_train, y_train and X_test datasets","51e74d46":"## Select the numerical and categorical column names","be179c39":"## Create the column transformers and the RandomForestRegressor model"}}