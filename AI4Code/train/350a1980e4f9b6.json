{"cell_type":{"1f2d111f":"code","c6cb83dc":"code","3a92d5ec":"code","5a375fb5":"code","37ce665b":"code","bb2315c4":"code","84f93004":"code","38267c66":"code","c217c785":"code","6b3a549f":"code","6e50f2bd":"code","0dcb185d":"code","35d7f292":"code","719dffc1":"code","d5b0cf65":"code","2de48983":"code","18c3cbd5":"code","450e363a":"code","43114850":"code","0ec88124":"code","c76528be":"code","e662dcfd":"code","7499bfe3":"code","5a64618d":"code","70746e0a":"code","56f3ad23":"code","3c3d88b5":"code","c61e8cf2":"markdown","45a9d96d":"markdown","a566aff4":"markdown","671faecb":"markdown","701672ec":"markdown","8654898d":"markdown","3d5ab55c":"markdown","6b303ff6":"markdown"},"source":{"1f2d111f":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","c6cb83dc":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3a92d5ec":"#load train data\ntrain_df = pd.read_csv(\"..\/input\/insurance-cost-prediction\/train.csv\")\ntrain_df","5a375fb5":"#checking for null values\ntrain_df.isnull().sum()","37ce665b":"train_df.info()","bb2315c4":"#our target is 'charges'\n#we can see below that charge distribution is right skewed\ncharge = train_df[\"charges\"]\nhist1 = px.histogram(\n            charge,\n            title = \"Charges Distribution\",\n            opacity = 0.8,\n            color_discrete_sequence = ['coral'],\n            marginal = \"box\"\n        )\nhist1.show()","84f93004":"fig = make_subplots(rows=3, cols=2)\n\ntrace0 = go.Histogram(x=train_df['age'], name='Age')\ntrace1 = go.Histogram(x=train_df['sex'], name='Sex')\ntrace2 = go.Histogram(x=train_df['bmi'], name='BMI')\ntrace3 = go.Histogram(x=train_df['children'], name='Children')\ntrace4 = go.Histogram(x=train_df['smoker'], name='Smoker')\ntrace5 = go.Histogram(x=train_df['region'], name='Region')\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\nfig.append_trace(trace3, 2, 2)\nfig.append_trace(trace4, 3, 1)\nfig.append_trace(trace5, 3, 2)\n\nfig.update_layout(title_text='Independent Features Count Plot')\n\nfig.show()","38267c66":"fig = px.violin(train_df, y=\"charges\", x=\"sex\", color=\"sex\", box=True, points=\"all\",\n          hover_data=train_df.columns)\nfig.show()","c217c785":"fig = px.scatter(train_df, x='age', y='charges', color='smoker', size='charges', opacity=0.6,\n             color_discrete_sequence = ['tomato', 'turquoise'])\nfig.show() ","6b3a549f":"fig = px.scatter(train_df, x='bmi', y='charges', color='sex', size='charges',\n             color_discrete_sequence=['lightcoral', 'cadetblue'])\nfig.show() ","6e50f2bd":"fig = px.violin(train_df, y=\"charges\", x=\"children\", color=\"children\", box=True, points=\"all\",\n          hover_data=train_df.columns)\nfig.show()","0dcb185d":"fig = px.violin(train_df, y=\"charges\", x=\"region\", color=\"region\", box=True, points=\"all\",\n          hover_data=train_df.columns)\nfig.show()","35d7f292":"def preprocess(df):\n    #dropping 'Id' column\n    df = df.drop(['Id'], axis = 1)\n    \n    #encoding categorical features\n    le = LabelEncoder()\n    le.fit(df.sex.drop_duplicates()) \n    df.sex = le.transform(df.sex)\n\n    le.fit(df.smoker.drop_duplicates()) \n    df.smoker = le.transform(df.smoker)\n\n    le.fit(df.region.drop_duplicates()) \n    df.region = le.transform(df.region)\n    \n    return df\n\ntrain_df = preprocess(train_df)\ntrain_df","719dffc1":"train_df.dtypes","d5b0cf65":"train_df.describe()","2de48983":"corr = train_df.corr()\n\nfig = go.Figure(go.Heatmap(\n                z = corr.values,\n                x = corr.index.values.tolist(),\n                y = corr.index.values.tolist(),\n                colorscale = 'Temps', xgap = 1, ygap = 1)\n                )\n\nfig.update_layout(title=\"Correlation Heatmap\", width = 600, height = 600, autosize = False )\nfig.show()","18c3cbd5":"X = train_df.drop('charges',axis=1) # independent variables\ny = train_df['charges'] # dependent variable\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","450e363a":"lr = LinearRegression()\nlr.fit(X_train, y_train)","43114850":"def predicting(lr, X):\n    y = lr.predict(X)\n    #since predicted charge values can't be -ve\n    y[y < 0] = 0\n    return y","0ec88124":"y_train_pred = predicting(lr, X_train)\ny_test_pred = predicting(lr, X_test)\n\nprint(\"Training RMSE: \", np.sqrt(mean_squared_error(y_train, y_train_pred)))\nprint(\"Validation RMSE: \", np.sqrt(mean_squared_error(y_test, y_test_pred)))","c76528be":"fig = px.scatter(x = y_train, y = y_train_pred, color_discrete_sequence=['aquamarine'], trendline=\"ols\")\nfig.update_layout(title='Training Predicted Vs Actual values')\nfig.show()","e662dcfd":"fig = px.scatter(x = y_test, y = y_test_pred, color_discrete_sequence=['hotpink'], trendline=\"ols\")\nfig.update_layout(title='Validation Predicted Vs Actual values')\nfig.show()","7499bfe3":"test_df = pd.read_csv(\"..\/input\/insurance-cost-prediction\/test.csv\")\ntest_df","5a64618d":"test_id = test_df['Id']\ntest_df = preprocess(test_df)\ntest_df","70746e0a":"test_pred = predicting(lr, test_df)","56f3ad23":"pred = pd.DataFrame(test_pred, columns = ['charges'])\nsubmission_df = pd.DataFrame({'Id': test_id, 'charges': pred['charges']})\nsubmission_df","3c3d88b5":"#submission_df.to_csv(\"submission.csv\", index=False)","c61e8cf2":"## 3. Preprocessing data","45a9d96d":"## 4. Correlation matrix","a566aff4":"## 7. Load Test data","671faecb":"## 5. Split Train data","701672ec":"## 8. Predictions & Submission file","8654898d":"## 1. Import libraries","3d5ab55c":"## 2. Load Train data & EDA","6b303ff6":"## 6. Linear regression"}}