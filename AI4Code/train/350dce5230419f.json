{"cell_type":{"ffa83fd1":"code","f5c309a7":"code","34037ae1":"code","e785a764":"code","ac508683":"code","86ce7e47":"code","04ad256b":"code","95dcc448":"code","f23867c2":"code","639dd0bf":"code","445f305c":"code","1b1bf938":"code","974b5314":"code","92483692":"code","1df2abfd":"code","a6672733":"code","162f1370":"code","969425d5":"code","480f377b":"code","9e7ce54b":"code","b5e34f23":"code","4fe3a622":"code","84bcd3f2":"code","a78f2f94":"code","c0d7a72a":"code","bf0dc27e":"code","c6c18577":"code","ab2f9971":"code","3bfa3d91":"code","48e4f737":"markdown","5e4cd4b5":"markdown","77c08821":"markdown","b68825f4":"markdown","10df94aa":"markdown","d2ca7727":"markdown","5298c391":"markdown","323802f4":"markdown","691bda73":"markdown","363fa332":"markdown","d4548d71":"markdown","4160d9de":"markdown","c24455d4":"markdown","613df674":"markdown","832c646b":"markdown","d7c86b42":"markdown","5961d7e4":"markdown","5b4fd279":"markdown","66a15a78":"markdown","b1bd5533":"markdown","643830ac":"markdown","86b7e928":"markdown","b2afac4a":"markdown","bcb436e0":"markdown","44c388c2":"markdown","17bf98d8":"markdown","c8136410":"markdown","6f2b3beb":"markdown"},"source":{"ffa83fd1":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5c309a7":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport cv2\nimport pandas as pd\nimport seaborn as sns\nimport keras\nimport tensorflow_addons as tfa\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import DenseNet169\nfrom keras.layers import Dense,Dropout,Flatten\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","34037ae1":"df=pd.read_csv(\"..\/input\/plant-pathology-2021-fgvc8\/train.csv\")\ndf","e785a764":"df.info()","ac508683":"ax = plt.subplots(figsize=(18, 6))\nsns.set_style(\"whitegrid\")\nsns.countplot(x='labels', data=df);\nplt.xticks(rotation=90);","86ce7e47":"df.labels.value_counts().to_frame().style.background_gradient(cmap=\"plasma\")","04ad256b":"import plotly.graph_objects as go\ncolors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen']\n\nlabel_counts = df['labels'].value_counts()\nfig = go.Figure(data=[go.Pie(labels=label_counts.index,values=label_counts)])\nfig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig.update_layout(title='Labels distribution')\nfig.show()\nplt.savefig('labels1.png',transparent=True)","95dcc448":"df['labels']","f23867c2":"df['labels']=df['labels'].apply( lambda string: string.split(' ') )\ndf.head()","639dd0bf":"train_path=\"..\/input\/plant-pathology-2021-fgvc8\/train_images\"\nplt.figure(figsize=(20,40))\ni=1\nfor idx,s in df.head(9).iterrows():\n    img_path = os.path.join(train_path,s['image'])\n    img=cv2.imread(img_path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    \n    fig=plt.subplot(9,3,i)\n    fig.imshow(img)\n    fig.set_title(s['labels'])\n    i+=1","445f305c":"datagen = ImageDataGenerator(\n    rescale=1\/255.0, # scale gi\u00e1 tr\u1ecb c\u1ee7a c\u00e1c \u0111i\u1ec3m \u1ea3nh v\u1ec1 [0, 1.0]\n    rotation_range=5, # quay \u1ea3nh 1 g\u00f3c 5 rad\n    zoom_range=0.1, # ph\u00f3ng to, thu nh\u1ecf \u1ea3nh trong kho\u1ea3ng b\u1eb1ng [0.1, 1.0] so v\u1edbi \u1ea3nh g\u1ed1c\n    horizontal_flip=True, # l\u1eadt \u1ea3nh theo chi\u1ec1u ngang\n    vertical_flip=True, # l\u00e2t \u1ea3nh theo chi\u1ec1u d\u1ecdc\n    shear_range=0.05, # l\u00e0m m\u00e9o \u1ea3nh ng\u1eabu nhi\u00ean \n    brightness_range=[0.7, 1.3], # t\u0103ng gi\u1ea3m \u0111\u1ed9 s\u00e1ng c\u1ee7a \u1ea3nh b\u1eb1ng [0.7, 1.3] so v\u1edbi \u1ea3nh g\u1ed1c\n    validation_split=0.2 # chia 2 ph\u1ea7n train v\u00e0 valid \u0111\u1ec3 training c\u0169ng nh\u01b0 l\u00e0 validating model\n)\nBATCH_SIZE = 32 # batch size = 32\nHEIGHT = 224 # Chi\u1ec1u cao c\u1ee7a \u1ea3nh\nWIDTH = 224 # Chi\u1ec1u r\u1ed9ng c\u1ee7a \u1ea3nh\nCHANNEL = 3 # S\u1ed1 k\u00eanh m\u00e0u c\u1ee7a \u1ea3nh","1b1bf938":"train_generator = datagen.flow_from_dataframe(\n    df,\n    directory='..\/input\/resized-plant2021\/img_sz_256',\n    subset='training',\n    x_col='image',\n    y_col='labels',\n    target_size=(HEIGHT,WIDTH),\n    color_mode='rgb', # 3 k\u00eanh m\u00e0u rgb\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=44\n    )\n\nvalid_generator = datagen.flow_from_dataframe(\n    df,\n    directory='..\/input\/resized-plant2021\/img_sz_256',\n    subset='validation',\n    x_col='image',\n    y_col='labels',\n    target_size=(HEIGHT,WIDTH),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=44\n    )","974b5314":"weight_path='..\/input\/keras-pretrain-model-weights\/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5'","92483692":"base_model=DenseNet169(weights=weight_path,include_top=False, input_shape=(HEIGHT,WIDTH,CHANNEL))\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(256,activation='relu')(x)\nx=Dropout(0.2)(x)\nx=Dense(128,activation='relu')(x)\npredictions=Dense(6,activation='sigmoid')(x)\n\nmodel=Model(inputs=base_model.input,outputs=predictions)\n\n# model.summary()","1df2abfd":"for layer in base_model.layers:\n    layer.trainable=False","a6672733":"f1 = tfa.metrics.F1Score(num_classes=6,average='macro')\n\nmodel.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy',metrics=[f1])","162f1370":"earlyStopping=EarlyStopping(\n    patience=5,\n    monitor=f1,\n    mode='max',\n    restore_best_weights=True\n)\nlrSchedule = ReduceLROnPlateau(\n    monitor='val_f1_score', \n    factor=0.05, \n    patience=4, \n    verbose=1\n)","969425d5":"hist = model.fit_generator(\n    generator=train_generator,\n    validation_data=valid_generator,\n    epochs=30,\n    steps_per_epoch=train_generator.samples\/\/128,\n    validation_steps=valid_generator.samples\/\/128,\n    callbacks=[earlyStopping, lrSchedule]\n)","480f377b":"# for i, layer in enumerate(model.layers):\n#     print(i, layer.name, \"-\", layer.trainable)","9e7ce54b":"model.layers[595:]","b5e34f23":"for layer in model.layers:\n    layer.trainable=True\n\nmodel.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy',metrics=[f1])\nhistory = model.fit_generator(generator=train_generator,\n                    validation_data=valid_generator,\n                    epochs=30,\n                    steps_per_epoch=train_generator.samples\/\/128,\n                    validation_steps=valid_generator.samples\/\/128,\n                    callbacks=[earlyStopping, lrSchedule])","4fe3a622":"# plt.figure(figsize=(15,6))\n# epoch_list = list(range(1, len(history.history['accuracy']) + 1))\n# plt.plot(epoch_list, history.history['accuracy'],label='accuracy')\n# plt.plot(epoch_list, history.history['val_accuracy'],label='val_accuracy')\n# plt.xlabel('epoches')\n# plt.ylabel('accuracy')\n# plt.legend()\n# plt.show()","84bcd3f2":"plt.figure(figsize=(15,6))\nepoch__list = list(range(1,len(history.history['f1_score'])+1))\nplt.plot(epoch__list, history.history['f1_score'],label='f1_score')\nplt.plot(epoch__list, history.history['val_f1_score'],label='val_f1_score')\nplt.xlabel('epoches')\nplt.ylabel('f1')\nplt.legend()\nplt.show()","a78f2f94":"model.save('plant_densenet169_ver02.h5')","c0d7a72a":"sample_sub = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')\nsample_sub","bf0dc27e":"test_data = datagen.flow_from_dataframe(\n    sample_sub,\n    directory='..\/input\/plant-pathology-2021-fgvc8\/test_images',\n    x_col='image',\n    y_col=None,\n    color_mode='rgb',\n    target_size=(HEIGHT,WIDTH),\n    class_mode=None,\n    shuffle=False\n)\n\npredictions = model.predict(test_data)\nprint(predictions)\n\nclass_idx=[]\nfor pred in predictions:\n    pred=list(pred)\n    temp=[]\n    for i in pred:\n        if (i>0.3):\n            temp.append(pred.index(i))\n    if (temp!=[]):\n        class_idx.append(temp)\n    else:\n        temp.append(np.argmax(pred))\n        class_idx.append(temp)\nprint(class_idx)","c6c18577":"class_dict = train_generator.class_indices\ndef get_key(val):\n    for key,value in class_dict.items():\n        if (val==value):\n            return key\nprint(class_dict)\n\nsub_pred=[]\nfor img_ in class_idx:\n    img_pred=[]\n    for i in img_:\n        img_pred.append(get_key(i))\n    sub_pred.append( ' '.join(img_pred))\nprint(sub_pred)","ab2f9971":"sub = sample_sub[['image']]\nsub['labels']=sub_pred\nsub","3bfa3d91":"sub.to_csv('submission.csv',index=False)","48e4f737":"Ch\u00fang em x\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh m\u1ea1ng neuron t\u1eeb m\u1ea1ng DenseNet169 k\u1ebft h\u1ee3p v\u1edbi m\u1ea1ng fully-connected c\u00f3 c\u00e1c t\u1ea7ng v\u1edbi k\u00edch th\u01b0\u1edbc (256, 128)  \nT\u1ea7ng dense cu\u1ed1i c\u00f9ng c\u1ee7a m\u00f4 h\u00ecnh s\u1ebd c\u00f3 6 unit v\u00ec \u0111\u00e2y l\u00e0 b\u00e0i to\u00e1n ph\u00e2n l\u1edbp v\u1edbi 6 nh\u00e3n. T\u1ea7ng dense 6 unit n\u00e0y sau \u0111\u1ea5y v\u1edbi 1 threshold n\u00e0o \u0111\u00f3 s\u1ebd quy\u1ebft \u0111\u1ecbnh xem t\u1eebng \u1ea3nh n\u00e0o s\u1ebd c\u00f3 1 hay nhi\u1ec1u nh\u00e3n b\u1ec7nh n\u00e0o.","5e4cd4b5":"V\u00ec nh\u1eefng b\u00e0i to\u00e1n ph\u00e2n lo\u1ea1i \u1ea3nh r\u1ea5t quan tr\u1ecdng d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o v\u00ec v\u1edbi c\u00e1c \u1ea3nh ch\u1ea5t l\u01b0\u1ee3ng kh\u00e1c nhau s\u1ebd \u1ea3nh h\u01b0\u1edfng t\u1edbi k\u1ebft qu\u1ea3 c\u1ee7a qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh t\u1eeb \u0111\u00f3 d\u1eabn \u0111\u1ebfn k\u1ebft qu\u1ea3 ph\u00e2n l\u1edbp t\u1ed1t hay ko t\u1ed1t.\n\nH\u00e3y c\u00f9ng xem qua 1 v\u00e0i \u1ea3nh c\u00f9ng v\u1edbi nh\u00e3n v\u00e0 k\u00edch th\u01b0\u1edbc c\u1ee7a \u1ea3nh ","77c08821":"C\u00f3 th\u1ec3 th\u1ea5y c\u00e1c \u1ea3nh c\u00f3 k\u00edch th\u01b0\u1edbc r\u1ea5t l\u1edbn v\u1edbi \u0111\u1ed9 d\u00e0i, \u0111\u1ed9 r\u1ed9ng kh\u00e1c nhau.  \n\u0110\u1ec3 x\u1eed l\u00fd c\u00e1c \u1ea3nh v\u1edbi k\u00edch th\u01b0\u1edbc l\u1edbn nh\u01b0 n\u00e0y l\u00e0 v\u00f4 c\u00f9ng t\u1ed1n t\u00e0i nguy\u00ean c\u0169ng nh\u01b0 l\u00e0 th\u1eddi gian:\n- Th\u1eddi gian load \u1ea3nh l\u00ean \u0111\u1ec3 x\u1eed l\u00fd\n- Th\u1eddi gian x\u1eed l\u00fd \n- T\u00e0i nguy\u00ean CPU c\u1ee7a kaggle l\u00e0 kh\u00f4ng \u0111\u1ee7 \u0111\u1ec3 x\u1eed l\u00fd \u0111\u01b0\u1ee3c h\u1ebft s\u1ed1 l\u01b0\u1ee3ng 18632 \u1ea3nh v\u1edbi size > 2500x2500  \nV\u00ec v\u1eady, ch\u00fang em s\u1eed d\u1ee5ng 1 h\u00e0m \u0111\u1ecdc \u1ea3nh t\u1eeb ImageDataGenerator \u0111\u1ec3 c\u00f3 th\u1ec3 load \u1ea3nh tr\u1ef1c ti\u1ebfp t\u1eeb th\u01b0 m\u1ee5c, \u0111\u00f3 l\u00e0 flow_from_dataframe. Th\u00eam n\u1eefa trong h\u00e0m n\u00e0y ch\u00fang em l\u1ea5y d\u1eef li\u1ec7u \u1ea3nh l\u00e0 t\u1eadp \u1ea3nh \u0111\u00e3 \u0111\u01b0\u1ee3c resize v\u1ec1 (256,256) \u0111\u1ec3 qu\u00e1 tr\u00ecnh ch\u1ea1y kh\u00f4ng t\u1ed1n k\u00e9m qu\u00e1 nhi\u1ec1u. ","b68825f4":"Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh","10df94aa":"V\u00ec **m\u1ed9t \u1ea3nh (hay 1 l\u00e1)** c\u00f3 th\u1ec3 c\u00f3 **nhi\u1ec1u** lo\u1ea1i **b\u1ec7nh (hay nh\u00e3n b\u1ec7nh)** kh\u00e1c nhau cho n\u00ean \u0111\u00e2y l\u00e0 b\u00e0i to\u00e1n **Multi-labels Classification!!!**","d2ca7727":"Ch\u00fang em s\u1eed d\u1ee5ng weight c\u1ee7a m\u1ea1ng m\u00e0 kh\u00f4ng c\u00f3 c\u00e1c t\u1ea7ng fully-connected \u1edf ph\u00eda tr\u00ean c\u1ee7a m\u1ea1ng DenseNet","5298c391":"In ra file submission.csv \u0111\u1ec3 n\u1ed9p b\u00e0i","323802f4":"> # 5. X\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh v\u00e0 hu\u1ea5n luy\u1ec7n","691bda73":"L\u1ea5y \u1ea3nh t\u1eeb file test_images \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n","363fa332":"### Visualize d\u1eef li\u1ec7u","d4548d71":"S\u1eed d\u1ee5ng \u0111\u1ed9 \u0111o accuracy v\u00e0 f1 \u0111\u1ec3 \u0111\u00e1nh gi\u00e1","4160d9de":"> # 1. Th\u00eam th\u01b0 vi\u1ec7n v\u00e0 c\u00e1c g\u00f3i h\u1ed7 tr\u1ee3","c24455d4":"Ch\u00fang ta c\u00f3 18632 \u1ea3nh cho vi\u1ec7c hu\u1ea5n luy\u1ec7n v\u00e0 ch\u00fang em ch\u01b0a bi\u1ebft r\u1eb1ng li\u1ec7u l\u01b0\u1ee3ng \u1ea3nh n\u00e0y \u0111\u00e3 l\u00e0 \u0111\u1ee7 cho m\u00f4 h\u00ecnh h\u1ecdc m\u00e0 kh\u00f4ng b\u1ecb overfitting hay ch\u01b0a cho n\u00ean ch\u00fang em \u0111\u00e3 th\u1eed 2 th\u1eed nghi\u1ec7m:\n1. 18632 \u1ea3nh l\u00e0 \u0111\u1ee7:\n- Khi th\u1ef1c hi\u1ec7n th\u1eed nghi\u1ec7m n\u00e0y, m\u00f4 h\u00ecnh v\u1ec1 sau c\u1ee7a ch\u00fang em c\u00f3 kh\u1ea3 n\u0103ng h\u1ecdc r\u1ea5t t\u1ed1t, h\u1ecdc g\u1ea7n ho\u00e0n h\u1ea3o 100% t\u1eeb t\u1eadp d\u1eef li\u1ec7u. Tuy nhi\u00ean khi ch\u1ea1y predict v\u00e0 n\u1ed9p k\u1ebft qu\u1ea3 th\u00ec score l\u1ea1i v\u00f4 c\u00f9ng k\u00e9m (kho\u1ea3ng 0.2) cho n\u00ean ch\u00fang em \u0111\u00e3 k\u1ebft lu\u1eadn r\u1eb1ng th\u1eed nghi\u1ec7m n\u00e0y l\u00e0 kh\u00f4ng \u1ed5n hay 18632 \u1ea3nh l\u00e0 kh\u00f4ng \u0111\u1ee7 \u0111\u1ec3 training. V\u00e0 th\u1eed nghi\u1ec7m th\u1ee9 2 c\u1ee7a ch\u00fang em l\u00e0 s\u1ebd Augment th\u00eam \u1ea3nh \u0111\u1ec3 cho m\u00f4 h\u00ecnh h\u1ecdc.\n2. Augment th\u00eam \u1ea3nh\n- Ch\u00fang em s\u1eed d\u1ee5ng 1 h\u00e0m c\u00f3 s\u1eb5n c\u1ee7a th\u01b0 vi\u1ec7n keras \u0111\u00f3 l\u00e0 ImageDataGenerator \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng augment th\u00eam \u1ea3nh. C\u00e1c ti\u00eau ch\u00ed sinh th\u00eam \u1ea3nh \u0111\u01b0\u1ee3c li\u1ec7t k\u00ea \u1edf block code b\u00ean d\u01b0\u1edbi \u0111\u00e2y:","613df674":"> # 2. \u0110\u1ecdc c\u00e1c file d\u1eef li\u1ec7u","832c646b":"### **_NOTE:_**  \nC\u00f3 th\u1ec3 th\u1ea5y r\u1eb1ng ta c\u00f3 12 nh\u00e3n b\u1ec7nh trong t\u1eadp d\u1eef li\u1ec7u tr\u00ean. Tuy nhi\u00ean, nhi\u1ec1u nh\u00e3n b\u1ec7nh l\u00e0 s\u1ef1 k\u1ebft h\u1ee3p c\u1ee7a c\u00e1c nh\u00e3n b\u1ec7nh kh\u00e1c v\u1edbi nhau.  \nCho n\u00ean, th\u1ef1c t\u1ebf ta s\u1ebd ch\u1ec9 c\u00f3 5 nh\u00e3n b\u1ec7nh:    \n* rust\n* scab\n* complex\n* frog_eye_leaf_spot\n* powdery_mildew\n\nV\u00e0 1 nh\u00e3n c\u00f2n l\u1ea1i l\u00e0:  \n* healthy","d7c86b42":"> # 3. Ti\u1ec1n x\u1eed l\u00fd","5961d7e4":"S\u1eed d\u1ee5ng m\u1ed9t v\u00e0i h\u00e0m h\u1ed7 tr\u1ee3 vi\u1ec7c hu\u1ea5n luy\u1ec7n nh\u01b0 EarlyStopping v\u00e0 ReduceLROnPlateau \u0111\u1ec3 m\u00f4 h\u00ecnh c\u00f3 th\u1ec3 h\u1ecdc t\u1ed1t h\u01a1n d\u1ef1a v\u00e0o vi\u1ec7c c\u1ea3i thi\u1ec7n learning rate v\u00e0 khi m\u00f4 h\u00ecnh kh\u00f4ng c\u1ea3i thi\u1ec7n \u0111\u01b0\u1ee3c vi\u1ec7c h\u1ecdc th\u00ec m\u00f4 h\u00ecnh s\u1ebd d\u1eebng l\u1ea1i theo c\u01a1 ch\u1ebf c\u1ee7a EarlyStopping.","5b4fd279":"Bi\u1ec3u th\u1ecb l\u1ea1i \u0111i\u1ec3m accuracy theo t\u1eebng epoch","66a15a78":"Bi\u1ec3u th\u1ecb l\u1ea1i \u0111i\u1ec3m f1 theo t\u1eebng epoch","b1bd5533":"> # 6. D\u1ef1 \u0111o\u00e1n tr\u00ean t\u1eadp test_images v\u00e0 n\u1ed9p b\u00e0i","643830ac":"freeze c\u00e1c t\u1ea7ng \u0111\u00e3 train t\u1eeb tr\u01b0\u1edbc l\u1ea1i v\u00e0 ti\u1ebfp t\u1ee5c train c\u00e1c t\u1ea7ng c\u00f2n l\u1ea1i","86b7e928":"Tuy nhi\u00ean, tr\u01b0\u1edbc khi train m\u00f4 h\u00ecnh ch\u00fang em s\u1ebd hu\u1ea5n luy\u1ec7n c\u00e1c t\u1ea7ng fully-connected tr\u01b0\u1edbc.","b2afac4a":"Ta c\u00f3 2 t\u1eadp d\u1eef li\u1ec7u d\u00f9ng \u0111\u1ec3 hu\u1ea5n luy\u1ec7n:  \n1. T\u1eadp d\u1eef li\u1ec7u l\u00e0 file .csv ch\u1ee9a 2 c\u1ed9t:  \n- C\u1ed9t 1 l\u00e0 t\u00ean c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c \u1ea3nh (**image**)\n- C\u1ed9t 2 l\u00e0 c\u00e1c lo\u1ea1i b\u1ec7nh t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed7i chi\u1ebfc \u1ea3nh b\u00ean c\u1ed9t 1 (**labels**)  \n2. T\u1eadp d\u1eef li\u1ec7u l\u00e0 file \u1ea3nh ch\u1ee9a t\u1ea5t c\u1ea3 g\u1ed3m 18632 \u1ea3nh m\u00e0u v\u00e0 t\u1ea5t c\u1ea3 c\u00e1c \u1ea3nh \u0111\u1ec1u c\u00f3 t\u00ean trong file .csv \u1edf tr\u00ean.","bcb436e0":"C\u00e1c nh\u00e3n \u0111ang \u1edf d\u1ea1ng string cho n\u00ean ch\u00fang em t\u00e1ch string n\u00e0y ra th\u00e0nh list ch\u1ee9a c\u00e1c nh\u00e3n b\u1ec7nh ri\u00eang bi\u1ec7t: ","44c388c2":"In ra k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n","17bf98d8":"\u0110\u1ecdc d\u1eef li\u1ec7u file sample_submission","c8136410":"> # 4. \u0110\u1ecdc v\u00e0 sinh \u1ea3nh","6f2b3beb":"Sau khi c\u00f3 d\u1eef li\u1ec7u \u1ea3nh, ch\u00fang em s\u1eed d\u1ee5ng m\u00f4 h\u00ecnh m\u1ea1ng DenseNet169 l\u00e0m m\u00f4 h\u00ecnh c\u01a1 s\u1edf \u0111\u1ec3 hu\u1ea5n luy\u1ec7n."}}