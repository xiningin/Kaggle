{"cell_type":{"56d6908c":"code","7e0c4e8d":"code","ec31aecf":"code","f78cfaab":"code","7b6aae83":"code","8d9e8565":"code","93a81083":"code","e3c1b52f":"code","75266f29":"code","cb0d7c56":"code","0f5b6345":"code","5b26e732":"code","3a3ad801":"code","54b8824e":"code","7e508c5e":"code","7be3a365":"code","b35acd73":"code","36f10ddf":"code","d5115461":"markdown","b396f5dd":"markdown","ebbf68ab":"markdown","5dd12823":"markdown","09ebab20":"markdown","d36264cd":"markdown","e755f3af":"markdown","f32faf84":"markdown","58fbec1a":"markdown","55e0da11":"markdown","b300327b":"markdown","aad8a55e":"markdown","8b416375":"markdown","6d1c91b5":"markdown","90920d07":"markdown","5fc8593f":"markdown","ca156a5b":"markdown","8a47cf77":"markdown","765ff34a":"markdown","a5e6f746":"markdown"},"source":{"56d6908c":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.offline as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\nimport matplotlib.image as mpimg\n\n# Set Color Palettes for the notebook (https:\/\/color.adobe.com\/)\ncolors_nude = ['#FFE61A','#B2125F','#FF007B','#14B4CC','#099CB3']\nsns.palplot(sns.color_palette(colors_nude))\n\n# Set Style\nsns.set_style(\"whitegrid\")\nsns.despine(left=True, bottom=True)","7e0c4e8d":"train_data= pd.read_csv(\"..\/input\/landmark-recognition-2020\/train.csv\")\nprint(train_data.head())\nprint()\nprint(\"Here, id means Image Id\\n      landmark_id points to a specific ID of the landmark \")","ec31aecf":"train_data.describe()","f78cfaab":"print(train_data.isna().sum())\nprint()\nprint('Here, we can see there is no missing data in any of the columns.')","7b6aae83":"!pip install basic_image_eda\nfrom basic_image_eda import BasicImageEDA","8d9e8565":"data_dir = \"..\/input\/landmark-recognition-2020\/train\/0\"\nextensions = ['png', 'jpg', 'jpeg']\nthreads = 0\ndimension_plot = True\nchannel_hist = True\nnonzero = False\nhw_division_factor = 1.0\n\nBasicImageEDA.explore(data_dir, extensions, threads, dimension_plot, channel_hist, nonzero, hw_division_factor)","93a81083":"train_data['landmark_id'].value_counts()\nprint(\"Types of Landmarks: 81313\")\nprint(\"Landmark ID: 138982 has the highest number of images (6272)\")","e3c1b52f":"# Occurance of landmark_id in decreasing order(Top categories)\ntemp = pd.DataFrame(train_data.landmark_id.value_counts().head(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['Landmark ID','Number of Images']\n\n# Plot the most frequent landmark_ids\nplt.figure(figsize = (9, 10))\nplt.title('Top 10 the mostfrequent landmarks')\nsns.set_color_codes(\"deep\")\nsns.barplot(x=\"Landmark ID\", y=\"Number of Images\", data=temp,\n            label=\"Count\")\nplt.show()\n","75266f29":"temp = pd.DataFrame(train_data.landmark_id.value_counts().tail(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['Landmark ID','Number of Images']\n# Plot the least frequent landmark_ids\nplt.figure(figsize = (9, 10))\nplt.title('Top 10 the least frequent landmarks')\nsns.set_color_codes(\"deep\")\nsns.barplot(x=\"Landmark ID\", y=\"Number of Images\", data=temp,\n            label=\"Count\")\nplt.show()\n","cb0d7c56":"import cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)","0f5b6345":"train_data['landmark_id'].value_counts(normalize=True).sort_values().iplot(kind='barh',\n                                                      xTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='blue',\n                                                      theme='pearl',\n                                                      bargap=0.2,\n                                                      gridcolor='white',\n                                                      title='Distribution in the training set')","5b26e732":"sns.distplot(temp['Landmark ID'], hist=True, rug=True);","3a3ad801":"from random import randrange\nfig= plt.figure(figsize=(20,10))\nindex= '..\/input\/landmark-recognition-2020\/train\/7\/0\/4\/704001a0be55059a.jpg'\na= fig.add_subplot(2,3,1)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/7\/0\/4\/7040a5cfa43e0633.jpg'\na= fig.add_subplot(2,3,2)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/7\/0\/0\/7000542ecac029aa.jpg'\na= fig.add_subplot(2,3,3)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/7\/0\/5\/7050308f31e8f117.jpg'\na= fig.add_subplot(2,3,4)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/7\/0\/a\/70a039ff5015a267.jpg'\na= fig.add_subplot(2,3,5)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/7\/0\/f\/70f0333a732c666d.jpg'\na= fig.add_subplot(2,3,6)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nplt.show()\n    ","54b8824e":"from albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,\n    ToFloat, ShiftScaleRotate, ElasticTransform,ChannelShuffle\n)","7e508c5e":"albumentation_list =  [\n    HorizontalFlip(p=0.5),\n    RandomContrast(limit=0.2, p=1),\n    RandomGamma(gamma_limit=(80, 120), p=1),\n    RandomBrightness(limit=0.2, p=0.5),\n    ShiftScaleRotate(\n        shift_limit=0.0625, scale_limit=0.1, \n        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n    ChannelShuffle(p=1),\n    ElasticTransform(p=1,border_mode=cv2.BORDER_REFLECT_101,alpha_affine=40)\n]","7be3a365":"chosen_image= plt.imread('..\/input\/landmark-recognition-2020\/train\/0\/4\/3\/04305edef6cf2186.jpg')\nimg_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\n    \nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\",\"Horizontal Flip\",\"Random Contrast\",\"Random Gamma\",\"RandomBrightness\",\n               \"Shift Scale Rotate\",\"Channel Shuffle\", \"Elastic Transform\"]\n","b35acd73":"def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=\"Data Augmentation\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=2, ncols=ncols, squeeze=True)\n    fig.suptitle(main_title, fontsize = 30)\n    #fig.subplots_adjust(wspace=0.3)\n    #fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i \/\/ ncols][i % ncols].imshow(img)\n        myaxes[i \/\/ ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()","36f10ddf":"plot_multiple_img(img_matrix_list, titles_list, ncols = 4)","d5115461":"Now, Let's see if the data contains any missing value in the csv","b396f5dd":"Now, let's analyze the number of landmark types and their distributions.","ebbf68ab":"**Plot the augmented images**","5dd12823":"Now let's a KDE (Kernel Density Estimate) plot for the landmark_ids.\n\nA kernel density estimate plot shows the distribution of a single variable and can be thought of as a smoothed histogram","09ebab20":"Now let's plot some random images","d36264cd":"**Load the training csv file and look at the first 5 entries**","e755f3af":"**Function for plotting images**","f32faf84":"# Part 2: Data augmentation\n\n**Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. In this notebook we will use *albumentations* data augmentation**","58fbec1a":"**Let's see another distribution plot**\n","55e0da11":"**Let's see the summary of the loaded data**","b300327b":"**There are various types of augmentation techniques available. In this case,  we applied:**\n\n1. Horizontal Flip\n2. Random contrast\n3. Random Gamma\n4. Random Brightness\n5. Shift Scale Rotate\n6. Channel Shuffle\n7. Elastic Transform\n","aad8a55e":"# Part 1: EDA","8b416375":"# Landmark Recognition\n\n**In this notebook, I will try to perform exploratory data analysis (EDA) on this dataset. As I am a beginner myself, I will try to explain the findings as much as possible. Please give your valuable opinions and suggestions in the comments.**\n\nThe following notebooks helped me a lot to write this notebook:\n1. https:\/\/www.kaggle.com\/chirag9073\/landmark-recognition-exploratory-data-analysis\/notebook\n2. https:\/\/www.kaggle.com\/azaemon\/mura-classification\n\nCheck out my other notebooks if interested: https:\/\/www.kaggle.com\/azaemon\/notebooks \n\n","6d1c91b5":"**Least frequent landmark counts (Top 10)**","90920d07":"**At first, Let's import the modules.**","5fc8593f":"**Apply the augmentations on a Random image**","ca156a5b":"There are total 1580470 images in the train folder. To run the following operation, it estimated about 9 hours which we do not have. That's why I am applying this only for one of the subfolders.","8a47cf77":"**Now let's do an EDA by using the *basic_image_eda* library**","765ff34a":"**Most frequent landmark counts (Top 10)**","a5e6f746":"Let's import the modules"}}