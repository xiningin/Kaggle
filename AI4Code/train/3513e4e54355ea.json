{"cell_type":{"8282f5de":"code","c643f26f":"code","b80181bc":"code","9bc26ae9":"code","186fc464":"code","d8d14dc3":"code","68b89df6":"code","8484c80c":"code","1a0065cd":"code","cd048d5d":"code","19d768be":"code","c3207e38":"code","af7377ad":"code","6347309e":"code","02e7e826":"code","40b3ede0":"code","8d0e77fe":"code","204d9491":"code","4e65dd07":"code","ba44f88a":"code","6348ce78":"code","d08c9c47":"code","907a4f4c":"code","78e3784c":"code","4d41ccba":"code","b617fcef":"code","89252177":"code","7b98cb5b":"code","627fe3b1":"code","6b21f9e0":"code","4d012d01":"code","b18ed4ca":"code","2ecab087":"code","27ba199e":"code","6abe7e1d":"code","6bfa8476":"code","f748e51d":"code","1950402c":"code","9cd2757a":"code","455c064a":"code","17995ea2":"code","2a464586":"code","3be2d5d4":"code","2069c81e":"code","ce4f949c":"code","e90cabb6":"code","c1ab84d6":"code","0c2aba0b":"code","3c884050":"code","3b9e77b8":"code","5b415d91":"code","9d48d270":"code","89833866":"code","c8831b3c":"code","5d68e265":"code","f9fa2df1":"code","8a0c8ed1":"markdown"},"source":{"8282f5de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c643f26f":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport librosa.display as display\nimport librosa\nimport IPython.display as ipd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchaudio\nfrom torch.utils.data import random_split, DataLoader, Dataset\nimport torchaudio.transforms as T\nimport torchvision\nfrom tqdm.notebook import tqdm\nimport random\nfrom scipy import signal\nfrom scipy.io import wavfile","b80181bc":"sample = wavfile.read('\/kaggle\/input\/synthetic-speech-commands-dataset\/augmented_dataset\/augmented_dataset\/happy\/1002.wav')\nsample_array = np.array(sample[1],dtype=float)\ndisplay.waveplot(sample_array, sr=sample[0])","9bc26ae9":"ipd.Audio(sample_array, rate=sample[0])","186fc464":"sample_spec = librosa.feature.melspectrogram(sample_array, sr=16000)\n","d8d14dc3":"a = np.max\ndisplay.specshow(librosa.core.power_to_db(sample_spec,ref= a), sr=16000,\n                 x_axis='ms', y_axis='mel')\nplt.show()","68b89df6":"sample_spec.shape","8484c80c":"data_dir = '..\/input\/synthetic-speech-commands-dataset\/augmented_dataset\/augmented_dataset\/'\nclasses = os.listdir(data_dir)\nprint(classes)\n","1a0065cd":"def convert():\n    X = []\n    for subdir, dirs, files in os.walk(data_dir + 'tree'):\n        for file in files:\n            x =  wavfile.read(os.path.join(subdir, file))\n            x_array = np.array(x[1],dtype=float)\n            X.append(x_array)\n    return X","cd048d5d":"Tree = convert()\nprint(Tree[0])","19d768be":"for x in Tree:\n    print(len(x))","c3207e38":"sample_spec = librosa.feature.melspectrogram(Tree[0], sr=16000)\ndb_img = librosa.core.power_to_db(sample_spec,ref= a)\ndisplay.specshow(db_img, sr=16000,\n                 x_axis='ms', y_axis='mel')\nplt.show()\n","af7377ad":"ipd.Audio(Tree[1], rate=16000)","6347309e":"melspec = T.MelSpectrogram(sample_rate=16000,\n                                        n_fft=2048,\n                                        hop_length=512)","02e7e826":"yad = melspec(torch.Tensor(Tree[0]))\nyad = yad.unsqueeze(0)\nprint(yad.shape)","40b3ede0":"print(Tree[0])","8d0e77fe":"Tree[0].shape","204d9491":"print(yad)","4e65dd07":"yad.shape","ba44f88a":"print(len(Tree))","6348ce78":"for subdir, dirs, files in os.walk(data_dir + 'tree'):\n    print(len(files))","d08c9c47":"X = []\ny = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/synthetic-speech-commands-dataset\/augmented_dataset\/augmented_dataset\/'):\n    melspec = T.MelSpectrogram(sample_rate=16000,n_fft=2048,hop_length=512)\n    for filename in filenames:\n        if dirname.split('\/')[-1]:\n            x = wavfile.read(os.path.join(dirname, filename))\n            x_array = np.array(x[1],dtype=float)\n            yad = melspec(torch.Tensor(x_array))\n            yad = yad.unsqueeze(0)\n            X.append(yad)\n            y.append(dirname.split('\/')[-1])\n   ","907a4f4c":"def Convert_To_Tensors(data_dir):\n    melspec = T.MelSpectrogram(sample_rate=16000,n_fft=2048,hop_length=512)\n    for subdir, dirs, files in os.walk(data_dir):\n        for file in files:\n            x =  wavfile.read(os.path.join(subdir, file))\n            x_array = np.array(x[1],dtype=float)\n            yad = melspec(torch.Tensor(x_array))\n            yad = yad.unsqueeze(0)\n            X.append(yad)\n    return X","78e3784c":"print(y)","4d41ccba":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport pandas as pd\nmlb = MultiLabelBinarizer()\n\nmlb.fit(pd.Series(y).fillna(\"missing\").str.split(', '))\ny_mlb = mlb.transform(pd.Series(y).fillna(\"missing\").str.split(', '))\nmlb.classes_","b617fcef":"y_mlb = torch.tensor(y_mlb)\ny_mlb_labels = torch.max(y_mlb, 1)[1]\nprint(y_mlb_labels)","89252177":"y_mlb = torch.tensor(y_mlb_labels, dtype=torch.long)\nprint(y_mlb.shape)","7b98cb5b":"print(X[0].shape)","627fe3b1":"\nX_train, X_valtest, y_train, y_valtest = train_test_split(X,y_mlb,test_size=0.2, random_state=37)\nX_val, X_test, y_val, y_test = train_test_split(X_valtest,y_valtest,test_size=0.5, random_state=37)","6b21f9e0":"print(len(X_train))\nX_train[0][0]","4d012d01":"print(len(X_train))\nprint(len(y_train))","b18ed4ca":"class MyDataset(Dataset):\n    def __init__(self, data, targets, transform=None):\n        self.data = data\n        self.targets = targets\n\n    def __getitem__(self, index):\n        x = self.data[index]\n        y = self.targets[index]\n            \n        return x, y\n\n    def __len__(self):\n        return len(self.data)","2ecab087":"train_ds = MyDataset(X_train,y_train)\nval_ds = MyDataset(X_val,y_val)\ntest_ds = MyDataset(X_test,y_test)\nbatch_size=128\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size,shuffle=True, pin_memory=True,num_workers=4 )\nval_dl = torch.utils.data.DataLoader(val_ds, batch_size,pin_memory=True,num_workers=4 )","27ba199e":"print(train_ds[0][0][0][0].shape)","6abe7e1d":"def accuracy(outs, labels):\n    _, preds = torch.max(outs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","6bfa8476":"class ModelBase(nn.Module):\n\n    # defines mechanism when training each batch in dl\n    def train_step(self, batch):\n        xb, labels = batch\n        outs = self(xb)\n        loss = F.cross_entropy(outs, labels)\n        return loss\n\n    # similar to `train_step`, but includes acc calculation & detach\n    def val_step(self, batch):\n        xb, labels = batch\n        outs = self(xb)\n        loss = F.cross_entropy(outs, labels )\n        acc = accuracy(outs,   labels)\n        return {'loss': loss.detach(), 'acc': acc.detach()}\n\n    # average out losses & accuracies from validation epoch\n    def val_epoch_end(self, outputs):\n        batch_loss = [x['loss'] for x in outputs]\n        batch_acc = [x['acc'] for x in outputs]\n        avg_loss = torch.stack(batch_loss).mean()\n        avg_acc = torch.stack(batch_acc).mean()\n        return {'avg_loss': avg_loss, 'avg_acc': avg_acc}\n\n    # print all data once done\n    def epoch_end(self, epoch, avgs, test=False):\n        s = 'test' if test else 'val'\n        print(f'Epoch #{epoch + 1}, {s}_loss:{avgs[\"avg_loss\"]}, {s}_acc:{avgs[\"avg_acc\"]}')","f748e51d":"@torch.no_grad()\ndef evaluate(model, val_dl):\n    # eval mode\n    model.eval()\n    outputs = [model.val_step(batch) for batch in val_dl]\n    return model.val_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_dl, val_dl, opt_func=torch.optim.Adam):\n    torch.cuda.empty_cache()\n    history = []\n    # define optimizer\n    optimizer = opt_func(model.parameters(), lr)\n    # for each epoch...\n    for epoch in range(epochs):\n        # training mode\n        model.train()\n        # (training) for each batch in train_dl...\n        for batch in tqdm(train_dl):\n            # pass thru model\n            loss = model.train_step(batch)\n            # perform gradient descent\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # validation\n        res = evaluate(model, val_dl)\n        # print everything useful\n        model.epoch_end(epoch, res, test=False)\n        # append to history\n        history.append(res)\n    return history","1950402c":"class Classifier(ModelBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(1, 512, kernel_size=3, padding=1),   # 512 x 128 x 32 \n            nn.ReLU(),\n            nn.BatchNorm2d(512),\n            nn.MaxPool2d(2, 2),\n            \n            \n            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), # 256 x 64 x 16\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(2, 2),\n\n            \n            nn.Conv2d(256,128, kernel_size=3, stride=1, padding=1), # 128 x 32x 8\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(2, 2),\n            \n            nn.Flatten(),\n            nn.Linear(8192, 64),\n            nn.ReLU(),\n            nn.Linear(64, 30))\n        \n    def forward(self, xb):\n        return self.network(xb)\n","9cd2757a":"model = Classifier()\nmodel","455c064a":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n","17995ea2":"device = get_default_device()\ndevice","2a464586":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device);","3be2d5d4":"model = to_device(Classifier(), device)","2069c81e":"lr = 1e-5\nepochs = 10\nprint(val_dl)","ce4f949c":"evaluate(model, val_dl)\n","e90cabb6":"history= []\nhistory += fit(epochs, lr, model, train_dl, val_dl)","c1ab84d6":"plt.plot([x['avg_loss'] for x in history])\nplt.title('Losses over epochs')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.show()","0c2aba0b":"plt.plot([x['avg_acc'] for x in history])\nplt.title('Accuracy over epochs')\nplt.xlabel('epochs')\nplt.ylabel('acc')\nplt.show()","3c884050":"torch.save(model.state_dict(), 'Classifier.pth')\n","3b9e77b8":"model.load_state_dict(torch.load('Classifier.pth'))","5b415d91":"test_dl = torch.utils.data.DataLoader(test_ds, batch_size,pin_memory=True,num_workers=4 )\nevaluate(model, test_dl)\n","9d48d270":"test_dl = torch.utils.data.DataLoader(test_ds, batch_size,pin_memory=True,num_workers=4 )\ntest_dl = DeviceDataLoader(test_dl, device)","89833866":"evaluate(model, test_dl)","c8831b3c":"!pip install jovian --upgrade -q","5d68e265":"import jovian","f9fa2df1":"project_name = 'Audio_Classifier_1'\njovian.commit(project=project_name)","8a0c8ed1":"print(Tree)"}}