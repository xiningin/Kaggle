{"cell_type":{"4c425f15":"code","a6cc4751":"code","d6d40a64":"code","27cc8251":"code","b5b391d1":"code","b59d8fa9":"code","1e5f1a2e":"code","b49b0eb3":"code","0f5dd14b":"code","bd4a680c":"code","7f0982a0":"code","2767ae73":"code","f2cac30d":"code","d0883024":"code","8e342654":"code","b0a90e6a":"code","f37ce5b1":"code","d0db3760":"code","daa94d28":"code","bcdf117d":"code","0381f428":"code","31123ec2":"code","84ecbbe1":"code","87d45885":"code","fd102364":"markdown","d56a431e":"markdown","9cb195bc":"markdown","9e55bfe0":"markdown","26390822":"markdown","89881b9f":"markdown","b6e24991":"markdown","ce394b86":"markdown","fcfaed3c":"markdown","3c5b5505":"markdown"},"source":{"4c425f15":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport optuna\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a6cc4751":"train = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')","d6d40a64":"train.head()","27cc8251":"train.isnull().sum()","b5b391d1":"train.shape","b59d8fa9":"test.shape","1e5f1a2e":"train['target'].value_counts()","b49b0eb3":"train.describe()","0f5dd14b":"df_train_label = train.drop('target', axis=1)\ndf_train_label['train-test'] = 1\ntest['train-test'] = 0","bd4a680c":"df = pd.concat([df_train_label, test])","7f0982a0":"numerical_col = [col for col in df.columns if pd.api.types.is_float_dtype(df[col])]\nplt.boxplot(df[numerical_col])\nplt.title('Numerical Boxplot', fontsize=24, fontweight='bold')\nplt.xlabel('Features');","2767ae73":"cat_feats = [col for col in train.columns if col.startswith(\"cat\")]\nnum_feats = [col for col in train.columns if col.startswith(\"cont\")]","f2cac30d":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"variables\"] = num_feats\nvif[\"VIF\"] = [variance_inflation_factor(train[num_feats].values, i) for i in range(train[num_feats].shape[1])]","d0883024":"vif = vif.sort_values(by=[\"VIF\"], ascending=False)\nvif.style.background_gradient(cmap=\"magma\")","8e342654":"target = train['target'].values\n\ncolumns = test.columns[1:]\ncolumns","b0a90e6a":"cont_cols = [col for col in columns if 'cont' in col]\ncat_cols = [col for col in columns if 'cat' in col]\n\ndef label_encode(train_df, test_df, column):\n    le = LabelEncoder()\n    new_feature = \"{}_le\".format(column)\n    le.fit(train_df[column].unique().tolist() + test_df[column].unique().tolist())\n    train_df[new_feature] = le.transform(train_df[column])\n    test_df[new_feature] = le.transform(test_df[column])\n    return new_feature\n\nle_cols = []\nfor feature in cat_cols:\n    le_cols.append(label_encode(train, test, feature))\n    \ncolumns = cont_cols + le_cols","f37ce5b1":"def run_rskf(train, target, clf, params):\n    train_preds = np.zeros((train.shape[0], 2))\n    test_preds = 0\n    rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=34)\n    for fold, (train_index, val_index) in enumerate(rskf.split(train, target)):\n        print(\"-> Fold {}\".format(fold + 1))\n       \n        x_train, x_valid = train.iloc[train_index][columns], train.iloc[val_index][columns]\n        y_train, y_valid = target[train_index], target[val_index]\n    \n        model = clf(**params)\n        model.fit(x_train, y_train,\n                    eval_set=[(x_valid, y_valid)], \n                    verbose=0,\n                    early_stopping_rounds=500)\n    \n        train_oof_preds = model.predict_proba(x_valid)[:,1]\n        train_preds[val_index, fold\/\/5] = train_oof_preds\n        test_oof_preds = model.predict_proba(test[columns])[:,1]\n        test_preds += test_oof_preds \/ 10\n        print(\"ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n        if fold in [4, 9]:\n            print(\"=> Overall ROC AUC Score = {}\".format(roc_auc_score(target, train_preds[:, fold\/\/5])))\n    return model, test_preds","d0db3760":"params_xgb = {'seed':2021,\n            'n_estimators':10000,\n            'verbosity':1,\n            'objective': 'binary:logistic',\n            'eval_metric':\"auc\",\n            'tree_method':\"gpu_hist\",\n            'use_label_encoder':False,\n            'gpu_id':0,\n            'alpha':7.105038963844129,\n            'colsample_bytree':0.25505629740052566,\n            'gamma':0.4999381950212869,\n            'reg_lambda':1.7256912198205319,\n            'learning_rate':0.011823142071967673,\n            'max_bin':338,\n            'max_depth':8,\n            'min_child_weight':2.286836198630466,\n            'subsample':0.618417952155855}\n\nclf_xgb = XGBClassifier","daa94d28":"model_xgb, test_preds_xgb = run_rskf(train, target, clf_xgb , params_xgb)","bcdf117d":"xgb = pd.DataFrame({'id':test['id'],'target':test_preds_xgb})\nxgb.to_csv('XGB.csv',index=False)","0381f428":"params_lgb = {\n            'cat_smooth':89.2699690675538,\n            'colsample_bytree':0.2557260109926193,\n            'learning_rate':0.00918685483594994,\n            'max_bin':788,\n            'max_depth':81,\n            'metric':\"auc\",\n            'min_child_samples':292,\n            'min_data_per_group':177,\n            'n_estimators':16000,\n            'n_jobs':-1,\n            'num_leaves':171,\n            'reg_alpha':0.7115353581785044,\n            'reg_lambda':5.658115293998945,\n            'subsample':0.9262904583735796,\n            'subsample_freq':1,\n            'verbose':-1\n            }\n\nclf_lgb = LGBMClassifier","31123ec2":"model_lgb, test_preds_lgb = run_rskf(train, target, clf_lgb , params_lgb)","84ecbbe1":"lgb = pd.DataFrame({'id':test['id'],'target':test_preds_lgb})\nlgb.to_csv('LGB.csv',index=False)","87d45885":"comb = pd.DataFrame({'id':test['id'],'target':(test_preds_xgb + test_preds_lgb)\/2 })\ncomb.to_csv('comb.csv',index=False)","fd102364":"def fun(trial,data=X,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2)\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 1000,10000),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6]),\n        'subsample': trial.suggest_uniform('subsample', 0,1),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0, 0.1 ),\n        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 1, 100),\n        'cat_l2': trial.suggest_int('cat_l2',1,20),\n        'device_type': 'gpu',\n        'metric': 'auc', \n        'random_state': 13,\n        \n    }\n    model = LGBMClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=200,verbose=False)\n    \n    preds = model.predict_proba(test_x)[:,1]\n    \n    auc = roc_auc_score(test_y, preds)\n    \n    return auc","d56a431e":"# Parameter tuning for Lightgbm via optuna","9cb195bc":"study = optuna.create_study(direction='maximize')\nstudy.optimize(fun, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","9e55bfe0":"# EDA","26390822":"best_params = study.best_params","89881b9f":"optuna.visualization.plot_optimization_history(study)","b6e24991":"# XGBoost","ce394b86":"optuna.visualization.plot_param_importances(study)","fcfaed3c":"plot_optimization_histor: shows the scores from all trials as well as the best score so far at each point.\n","3c5b5505":"Visualize parameter importances.\n"}}