{"cell_type":{"ec7208da":"code","9a7e8ea3":"code","52a76b7e":"code","f0c86057":"code","98f6f4d6":"code","e01c9670":"code","940c8f30":"code","c9e17ac7":"code","53a3b5c0":"code","2e03b0e6":"code","34daf863":"code","f5458794":"code","91d7d7a8":"code","19c01b85":"code","9b7d1592":"code","c0c9ebb7":"code","a800fef7":"code","6facb69e":"code","afe14600":"code","7f776c9f":"code","29b4e06a":"code","e2c20647":"code","7632cafb":"code","9a366d14":"code","3cbae98e":"code","63cc2181":"code","284da076":"code","aa212e49":"code","839f8b59":"code","d45d6fa3":"code","821bb395":"code","630435fd":"code","70ed45e1":"code","f5094f55":"code","7231bbf5":"code","9bf182e1":"markdown","3770fe02":"markdown","7939a0f8":"markdown","3a93a433":"markdown","36d9a74e":"markdown","9b8d3f8c":"markdown","48814ae9":"markdown","468ab8ef":"markdown","3b805b49":"markdown","b7fc1bbe":"markdown","4bd3eb55":"markdown","e409a835":"markdown","09c37c0f":"markdown","68cd293e":"markdown"},"source":{"ec7208da":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn import svm","9a7e8ea3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","52a76b7e":"df = pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndf.head()\n","f0c86057":"df['anaemia'] = df['anaemia'].astype(float)\ndf['creatinine_phosphokinase'] = df['creatinine_phosphokinase'].astype(float)\ndf['diabetes'] = df['diabetes'].astype(float)\ndf['ejection_fraction'] = df['ejection_fraction'].astype(float)\ndf['high_blood_pressure'] = df['high_blood_pressure'].astype(float)\ndf['platelets'] = df['platelets'].astype(float)\ndf['serum_creatinine'] = df['serum_creatinine'].astype(float)\ndf['serum_sodium'] = df['serum_sodium'].astype(float)\ndf['sex'] = df['sex'].astype(float)\ndf['smoking'] = df['smoking'].astype(float)\ndf['time'] = df['time'].astype(float)","98f6f4d6":"df.info()\n","e01c9670":"df.isnull().sum()","940c8f30":"df.describe()","c9e17ac7":"#preprocess data\nbins =(-1,0.5,2)\ngroups_names=['survived','dead']\ndf['DEATH_EVENT'] = pd.cut(df['DEATH_EVENT'], bins=bins, labels = groups_names)\ndf['DEATH_EVENT'].unique()","53a3b5c0":"label_quality=LabelEncoder()\ndf['DEATH_EVENT'] = label_quality.fit_transform(df['DEATH_EVENT'])\n","2e03b0e6":"df.head(10)","34daf863":"df['DEATH_EVENT'].value_counts()","f5458794":"sns.countplot(df['DEATH_EVENT'])","91d7d7a8":"#Now we can separate the dataset as response variable and feature variable\nX = df.drop('DEATH_EVENT', axis = 1)\ny = df['DEATH_EVENT']","19c01b85":"\ncorr = df.corr() #Correlation matrix for CB player\ncorr","9b7d1592":"fig = plt.figure(figsize=(8,8))\nplt.matshow(corr, cmap='RdBu', fignum=fig.number)\nplt.xticks(range(len(corr.columns)), corr.columns, rotation='vertical');\nplt.yticks(range(len(corr.columns)), corr.columns);","c0c9ebb7":"ax = df[['platelets', 'DEATH_EVENT']].boxplot(by='DEATH_EVENT', figsize=(10,6))\nax.set_ylabel('platelets')","a800fef7":"ax = df[['ejection_fraction', 'DEATH_EVENT']].boxplot(by='DEATH_EVENT', figsize=(10,6))\nax.set_ylabel('ejection_fraction')","6facb69e":"df['age'].plot(kind='density', figsize=(14,6))","afe14600":"all_inputs = df[['age','anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction',\n'high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium',\n'sex', 'smoking', 'time']].values\n# extracting quality labels\nall_labels = df['DEATH_EVENT'].values\n# a test to see what the inputs look like\nall_inputs[:2]","7f776c9f":"#Train and split the data\nX_train, X_test, y_train, y_test = train_test_split(all_inputs, all_labels, test_size= 0.2, random_state=42)","29b4e06a":"#Test of firsts values\nX_train[:1]","e2c20647":"#trying decision tree classfier \n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create the classifier\ndecision_tree_classifier = DecisionTreeClassifier()\n\n\n# Train the classifier on the training set\ndecision_tree_classifier.fit(X_train, y_train)\n\n\n# Validate the classifier on the testing set using classification accuracy\ndecision_tree_classifier.score(X_test, y_test)","7632cafb":"rfc = RandomForestClassifier(n_estimators = 200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","9a366d14":"pred_rfc[:20]","3cbae98e":"X_test[:2]","63cc2181":"# Let's see  the RFC efficients \nprint(classification_report(y_test, pred_rfc))\nprint(confusion_matrix(y_test,pred_rfc))","284da076":"\n# Validate the classifier on the testing set using classification accuracy\nrfc.score(X_test, y_test)","aa212e49":"Clf = svm.SVC()\nClf.fit(X_train,y_train)\npref_clf = Clf.predict(X_test)","839f8b59":"# Let's see  the SVM efficients \nprint(classification_report(y_test, pred_rfc))\nprint(confusion_matrix(y_test,pred_rfc))","d45d6fa3":"\n# Validate the classifier on the testing set using classification accuracy\nClf.score(X_test, y_test)","821bb395":"#selecting the models and the model names in an array\nmodels=[LogisticRegression(),\n        LinearSVC(),\n        SVC(kernel='rbf'),\n        KNeighborsClassifier(),\n        RandomForestClassifier(),\n        DecisionTreeClassifier(),\n        GradientBoostingClassifier(),\n        GaussianNB()]\nmodel_names=['Logistic Regression',\n             'Linear SVM',\n             'rbf SVM',\n             'K-Nearest Neighbors',\n             'Random Forest Classifier',\n             'Decision Tree',\n             'Gradient Boosting Classifier',\n             'Gaussian NB']\n\n\n# creating an accuracy array and a matrix to join the accuracy of the models\n# and the name of the models so we can read the results easier\nacc=[]\nm={}\n\n\n# next we're going to iterate through the models, and get the accuracy for each\nfor model in range(len(models)):\n     clf=models[model]\n     clf.fit(X_train,y_train)\n     pred=clf.predict(X_test)\n     acc.append(accuracy_score(pred,y_test))\n\n\nm={'Algorithm':model_names,'Accuracy':acc}\n\n\n# just putting the matrix into a data frame and listing out the results\nacc_frame=pd.DataFrame(m)\nacc_frame","630435fd":"random_forest_classifier = RandomForestClassifier()\n\n\n# setting up the parameters for our grid search\n# You can check out what each of these parameters mean on the Scikit webiste!\n# http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html\nparameter_grid = {'n_estimators': [10, 25, 50, 100, 200],\n'max_features': ['auto', 'sqrt', 'log2'],\n'criterion': ['gini', 'entropy'],\n'max_features': [1, 2, 3, 4]}\n\n\n# Stratified K-Folds cross-validator allows us mix up the given test\/train data per run\n# with k-folds each test set should not overlap across all shuffles. This allows us to \n# ultimately have \"more\" test data for our model\ncross_validation = StratifiedKFold(n_splits=10)\n\n\n# running the grid search function with our random_forest_classifer, our parameter grid\n# defineda bove, and our cross validation method\ngrid_search = GridSearchCV(random_forest_classifier,\nparam_grid=parameter_grid,\ncv=cross_validation)\n\n\n# using the defined grid search above, we're going to test it out on our\n# data set\ngrid_search.fit(all_inputs, all_labels)\n\n\n# printing the best scores, parameters, and estimator for our Random Forest classifer\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))\n\n\ngrid_search.best_estimator_","70ed45e1":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n\n          max_depth=None, max_features=2, max_leaf_nodes=None,\n\n          min_impurity_decrease=0.0, min_impurity_split=None,\n\n          min_samples_leaf=1, min_samples_split=2,\n\n          min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n\n          oob_score=False, random_state=None, verbose=0,\n\n          warm_start=False)","f5094f55":"random_forest_classifier = grid_search.best_estimator_\n\n\nrf_df = pd.DataFrame({'accuracy': cross_val_score(random_forest_classifier, all_inputs, all_labels, cv=10),\n                      'classifier': ['Random Forest'] * 10})\nrf_df.mean()","7231bbf5":"sns.boxplot(x='classifier', y='accuracy', data=rf_df)\nsns.stripplot(x='classifier', y='accuracy', data=rf_df, jitter=True, color='black')","9bf182e1":"# Testing other  ML methods using a loop and comparing results! ","3770fe02":"We compare platelets statistics between survivors and dead patient, we dont see any significant difference expect more extrems values within the dead group","7939a0f8":"## import Data and reshape","3a93a433":"# How to optimize parameters for a specific algorithm. Random forest classifier case","36d9a74e":"## Some statistics and studies before using ML tools","9b8d3f8c":"## Prepare inputs for ML tools","48814ae9":"# Predicting death due to Cardiovascular diseases with Scikit-learn\n\n\n## Main statistics, how to predict with scikit-learn, comparaison of algorithms and conclusion\n. \n\nThis notebook is covering 4 main studies: \n\n* Understand the main staistics about healtcare related to cardiovascular diseases  \n* Discover how to predict death of a patient using scikit-learn\n* Compare several ML algorithms using a loop \n* conclusion\n\nthe notebook include information and tips to shape data, optimise algorithms and plot intresting plots.\n\n","468ab8ef":"## Random Forest Classifier\n","3b805b49":" # SVM Classifier","b7fc1bbe":"The same analysis is made with a factor that is showed by the correlation matrix to be important in the death probability. \nIt is confirmed by the next plot with a significant difference of death regarding the ejection fraction","4bd3eb55":"## LIBRAIRIES","e409a835":"# Test of the new optimised Random forest classifier ","09c37c0f":"# Decision tree  Classifier","68cd293e":"# Data ready to be compiled into ML tools - Test of few ML tools "}}