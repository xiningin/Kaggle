{"cell_type":{"47c50dca":"code","cb3c4467":"code","6a02444b":"code","892abaeb":"code","37a8968f":"code","bfa376ac":"code","b1ada39d":"code","058c1737":"code","5168535d":"code","dcd1e22c":"code","664c1690":"code","d8c35e09":"code","a63e2301":"code","cb7d1dff":"code","563c4e8e":"code","a530d10d":"code","c163ca22":"code","3eb0448b":"code","0a4cc069":"code","b165de76":"code","99ac18f7":"code","51c9b9f3":"code","674021dc":"code","ae0cd0f8":"code","030217d8":"code","e9b3a552":"code","512d723e":"code","113f55c3":"code","865ed5bc":"code","d879fe25":"markdown"},"source":{"47c50dca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb3c4467":"data_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","6a02444b":"data_train","892abaeb":"data_train.describe()","37a8968f":"data_train.dtypes","bfa376ac":"data_train.drop(axis=0,columns='Name')","b1ada39d":"data_train.isna().sum()","058c1737":"test=test.drop(columns=['Cabin','Name'])\ndata_train=data_train.drop(columns=['Cabin','Name'])\n","5168535d":"data_train['Ticket'].value_counts()","dcd1e22c":"data_train['Sex']=data_train['Sex'].replace({'female':1,'male':2})\ndata_train['Embarked']=data_train['Embarked'].replace({'S':1,'C':2,'Q':3})\n\n\ntest['Sex']=test['Sex'].replace({'female':1,'male':2})\ntest['Embarked']=test['Embarked'].replace({'S':1,'C':2,'Q':3})","664c1690":"print(data_train.isna().sum(axis=0))\nprint('test',test.isna().sum(axis=0))","d8c35e09":"data_train['Age'].mean()","a63e2301":"data_train['Age']=data_train['Age'].fillna(value=data_train['Age'].mean())","cb7d1dff":"test['Age']=test['Age'].fillna(value=test['Age'].mean())","563c4e8e":"print(data_train.isna().sum())\nprint(test.isna().sum())\n","a530d10d":"data_train['Embarked']","c163ca22":"data_train['Embarked'].value_counts()","3eb0448b":"test.isna().sum(axis=0)","0a4cc069":"data_train","b165de76":"data_train['Embarked']=data_train['Embarked'].fillna(value=1)\ntest['Fare']=test['Fare'].fillna(value=test['Fare'].mean())","99ac18f7":"x_train=data_train[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n\ny_train=data_train['Survived']\n\nx_test=test[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n","51c9b9f3":"\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import confusion_matrix,f1_score\n\nfrom sklearn.model_selection import GridSearchCV ,train_test_split\n\nx_tr,xtes,y_tra,y_tes=train_test_split(x_train,y_train)","674021dc":"\nmodel=RandomForestClassifier()\n\nmodel.fit(x_tr,y_tra)","ae0cd0f8":"model.score(xtes,y_tes)","030217d8":"\n\n\nparam_grid={'max_depth':[3,5,6,7,8,9,10], 'min_samples_leaf':[2,3,5,6,\n                                                             7,8,9]\n                   }\n\ngris=GridSearchCV(RandomForestClassifier(),param_grid=param_grid,cv=5)\ngris.fit(xtes,y_tes)\n\nprint('best estimateur',gris.best_estimator_)\ngris.best_params_\n\n","e9b3a552":"y_pred=model.predict(xtes)\n\nconfusion_matrix(y_pred,y_tes)","512d723e":"print('le score est de ',f1_score(y_pred,y_tes ))","113f55c3":"from sklearn.model_selection import learning_curve\nimport matplotlib.pyplot as plt\n\n    \nn, score_trainset, score_testset=learning_curve(model,x_train,y_train,train_sizes=np.linspace(0.2,1,5),\n        cv=5, scoring='f1')\n    \n    \nplt.figure()\nplt.plot(n,score_trainset.mean(axis=1),label='score des donn\u00e9es entraine\u00e9')\nplt.plot(n,score_testset.mean(axis=1),label='score des donn\u00e9es test\u00e9')\nplt.legend()","865ed5bc":"model.predict(x_test)","d879fe25":"# Optimization of Algorithme with GridSearch"}}