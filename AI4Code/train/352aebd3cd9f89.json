{"cell_type":{"6fe2ab6c":"code","5c07eda0":"code","027ed0bd":"code","204eb86d":"code","05b75190":"code","7b581132":"code","47850e96":"code","c82ef6c8":"code","c9a21c8c":"code","eae52beb":"code","3c01f4d8":"code","a5f0c3df":"code","5f45acb2":"code","70d28174":"code","a1f08f05":"code","38c8a651":"code","f4e5c62f":"code","16db082c":"code","61680e92":"code","5b5ddaa0":"code","3e29f1ab":"code","b39ef2f7":"code","b1599cd7":"markdown"},"source":{"6fe2ab6c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5c07eda0":"!pip install bnlp_toolkit\nimport nltk\nnltk.download('punkt')","027ed0bd":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.utils as ku\nimport numpy as np\nimport re, string ","204eb86d":"with open('\/kaggle\/input\/converted2\/converted.txt', 'r') as file:\n    data = file.read()\n    \ndata[:1000]","05b75190":"from bnlp.nltk_tokenizer import NLTK_Tokenizer\nbnltk = NLTK_Tokenizer()\n\ncorpus = bnltk.sentence_tokenize(data)","7b581132":"corpus = corpus[1:]\nprint(len(corpus))","47850e96":"corpus = corpus[:10000]\ncorpus[935:955]","c82ef6c8":"len(corpus)","c9a21c8c":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(corpus)\ntotal_words = len(tokenizer.word_index) + 1","eae52beb":"print(total_words)","3c01f4d8":"input_sequences = []\n\nfor line in corpus:\n  token_list = tokenizer.texts_to_sequences([line])[0]\n  for i in range(1, len(token_list)):\n    n = token_list[:i+1]\n    input_sequences.append(n)","a5f0c3df":"len(input_sequences)","5f45acb2":"input_sequences = input_sequences[:100000]","70d28174":"len(input_sequences)","a1f08f05":"input_sequences[10000]","38c8a651":"max_sequence_len = max([len(x) for x in input_sequences])\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))","f4e5c62f":"predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n\nlabel = ku.to_categorical(label, num_classes=total_words)","16db082c":"print(total_words)\nprint(max_sequence_len)\nprint(len(n))\nprint(len(token_list))\na = [len(x) for x in input_sequences]\nprint(len(a))\nprint(len(input_sequences))","61680e92":"from keras.models import Sequential\nfrom keras.layers import Dense, Embedding, GRU, Dropout, Bidirectional, SpatialDropout1D","5b5ddaa0":"model = Sequential()\nmodel.add(Embedding(total_words, 100, input_length=max_sequence_len))\nmodel.add(Bidirectional(GRU(150, return_sequences=True)))\nmodel.add(Dropout(0.2))\nmodel.add(GRU(100))\n# model.add(Dense(total_words\/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dense(total_words, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","3e29f1ab":"history = model.fit(predictors, label, epochs=50, batch_size= 256)","b39ef2f7":"try:\n\twhile(True):\n\t\tseed_text = input('Write something: \\n')\n\t\tnext_words = 10\n\t\tif seed_text == 'exit':\n\t\t\tbreak\n\t\telse:\n\t\t\tfor _ in range(next_words):\n\t\t\t\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n\t\t\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n\t\t\t\tpredicted = model.predict_classes(token_list, verbose=0)\n\t\t\t\toutput_word = \"\"\n\t\t\t\tfor word, index in tokenizer.word_index.items():\n\t\t\t\t\tif index == predicted:\n\t\t\t\t\t\toutput_word = word\n\t\t\t\t\t\tbreak\n\t\t\t\tseed_text += \" \" + output_word\n\t\t\tprint(seed_text)\nexcept:\n\tprint('Error occured')","b1599cd7":"**If the number of epochs is increased, then the accuracy and the result will be much better than this.**"}}