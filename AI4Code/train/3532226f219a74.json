{"cell_type":{"ff6583bf":"code","526aa7e0":"code","b9ac2c19":"code","e5ec5970":"code","138fc382":"code","013c01d5":"code","08e022db":"code","ee7deb98":"code","ac0f2456":"code","747bcc93":"code","0ad156d4":"code","babab2e6":"code","9a32b937":"code","3e75b34e":"code","4213fa11":"code","0bb01933":"code","26d87255":"code","677bcd1d":"code","9c24ea68":"code","8e9a72b4":"code","c22800e9":"code","7d424275":"markdown"},"source":{"ff6583bf":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\n\nimport keras\n#from keras.applications.vgg19 import VGG19\nfrom keras.layers.convolutional import Conv2DTranspose\nfrom keras.layers.merge import concatenate\nfrom keras.layers import UpSampling2D, Conv2D, Activation, Input, Dropout, MaxPooling2D\nfrom keras import layers\nfrom keras import Model\nfrom keras import backend as K\nfrom keras.layers.core import Lambda","526aa7e0":"tr = pd.read_csv('..\/input\/train.csv')\nprint(len(tr))\ntr.head()","b9ac2c19":"#df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n#print(len(df_train))\ndf_train = tr\ndf_train['ImageId'], df_train['ClassId'] = zip(*df_train['ImageId_ClassId'].str.split('_')) #split imageId and classId\ndf_train['ClassId'] = df_train['ClassId'].astype(int)\ndf_train = df_train.pivot(index='ImageId',columns='ClassId',values='EncodedPixels') #remap\ndf_train['defects'] = df_train.count(axis=1) #count on defect type\ndf_train = df_train[df_train['defects'] > 0]\nprint(len(df_train))\ndf_train.head()\n#print(df_train.iloc[6666-1].name)","e5ec5970":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    if rle is not np.nan:\n        array = np.asarray([int(x) for x in rle.split()])\n        starts = array[0::2]\n        lengths = array[1::2]\n\n        current_position = 0\n        for index, start in enumerate(starts):\n            mask[int(start):int(start+lengths[index])] = 1\n            current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","138fc382":"img_scale = 2*2\nimg_size = (1600 \/\/ img_scale,256 \/\/ img_scale)\nclasses_num = 4","013c01d5":"#contrast enhancing\n\ndo_enhance = True\n\ngamma = 1.2\ninverse_gamma = 1.0 \/ gamma\nlook_up_table = np.array([((i\/255.0) ** inverse_gamma) * 255.0 for i in np.arange(0,256,1)]).astype(\"uint8\")\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n\ndef contrast_enhancement(img):\n    if not do_enhance:\n        return img\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n    img[:,:,0] = clahe.apply(img[:,:,0])\n    img = cv2.cvtColor(img, cv2.COLOR_YUV2RGB)\n    return img\n\ndef gamma_correction(img):\n    if not do_enhance:\n        return img\n    return cv2.LUT(img.astype('uint8'), look_up_table)","08e022db":"import random\ndef keras_generator(batch_size):\n    while True:\n        x_batch = []\n        y_batch = []\n        \n        for i in range(batch_size): \n            flip = int(100)\n            if random.uniform(0,1) > 0.5:\n                flip = random.randint(-1,1)\n            #print(flip)\n                \n            \n            fn = df_train.iloc[i].name\n            img = cv2.imread( '..\/input\/train_images\/'+fn )\n            #plt.subplot(3,1,1)\n            #plt.imshow(img)\n            img = gamma_correction(img)\n            #plt.subplot(3,1,2)\n            #plt.imshow(img)\n            img = contrast_enhancement(img)\n            #plt.subplot(3,1,3)\n            #plt.imshow(img)\n            #break\n            #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n            #mask_gt = np.zeros( shape = img.shape[0:2] ).astype(np.uint8) + 1\n            #mask_gt = cv2.resize(mask_gt, img_size,cv2.INTER_NEAREST)\n            #if flip != 100:\n            #    mask_gt = cv2.flip(mask_gt,flip)\n            #mask_gt = np.expand_dims(mask_gt,-1) #background\n            #masks = [mask_gt]\n            masks = []\n            for cls in range(0,classes_num):\n                mask = rle2mask(df_train[cls+1].iloc[i], img.shape)\n                mask = np.squeeze(mask)\n                mask = cv2.resize(mask, img_size,cv2.INTER_NEAREST)\n                if flip != 100:\n                    mask = cv2.flip(mask,flip)\n                mask = np.expand_dims(mask,-1)\n               # mask_gt[mask != 0] = 0 #move pixel from gt\n                masks.append(mask)\n\n            mask = np.concatenate(masks,axis=-1)\n            img = cv2.resize(img, img_size,cv2.INTER_AREA)\n            if flip != 100:\n                img = cv2.flip(img,flip)\n            x_batch += [img]\n            y_batch += [mask]\n                                    \n        x_batch = np.array(x_batch) \/ 255.0\n        y_batch = np.array(y_batch)\n\n        #yield x_batch, np.expand_dims(y_batch, -1)\n        yield x_batch, y_batch","ee7deb98":"for x, y in keras_generator(4):\n    break\n    \nprint(x.shape, y.shape)","ac0f2456":"test_image_id = 3\nplt.subplot(classes_num+1,1,1)\nplt.imshow(x[test_image_id])\nfor k in range(classes_num):\n    plt.subplot(classes_num+1,1,k+2)\n    plt.imshow(np.squeeze(y[test_image_id,:,:,k]))","747bcc93":"#Model\ndef get_net_raw(img_size,classes_num):\n    inputs = Input((img_size[1], img_size[0], 3))\n    #s = Lambda(lambda x: x \/ 255) (inputs)\n\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)  #1x\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1) \n\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1) #2x\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2) #4x\n    c3 = Dropout(0.2) (c3)\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3) #8x\n    c4 = Dropout(0.2) (c4)\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4) #16x\n    c5 = Dropout(0.3) (c5)\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)                          #8x\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.2) (c6)\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)                           #4x\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.2) (c7)\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)                          #2x\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)                          #1x\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n    \n    hp6 = Conv2DTranspose(64, (8, 8), strides=(8, 8), padding='same') (c6) \n    hp7 = Conv2DTranspose(32, (4, 4), strides=(4, 4), padding='same') (c7)  \n    hp8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)  \n    \n    hp = concatenate([hp6,hp7,hp8,c9])\n    hp = Conv2D(96, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (hp)\n    \n    #outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n    outputs = Conv2D(classes_num,(1,1),activation = 'sigmoid')(hp)  #todos: try softmax\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    #model.compile(optimizer='adam', loss='binary_crossentropy')\n    #model.compile(optimizer='adam',loss='categorical_crossentropy')\n    return model\n","0ad156d4":"from keras import optimizers\nmodel = get_net_raw(img_size,classes_num)\nsgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=sgd, loss='binary_crossentropy')\nprint(model.layers)\n#for layer in model.layers:\n#    print(layer.name)","babab2e6":"%%time\n\n# Fit model\nbatch_size = 32\nresults = model.fit_generator(keras_generator(batch_size), \n                              steps_per_epoch=100,\n                              epochs=50) \n\nmodel.save(\"severstal_s4.h5\")","9a32b937":"pred = model.predict(x)\nprint(pred.shape,pred.min(), pred.max())\nplt.imshow(np.squeeze(pred[3,:,:,3]))","3e75b34e":"testfiles=os.listdir(\"..\/input\/test_images\/\")\nlen(testfiles)","4213fa11":"\n\ndef mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,)   \n    inds = np.argwhere(tmp == 1)\n    if len(inds) == 0:\n        return ' '.join([])\n    inds = list(map(lambda x: x[0], inds))\n    last = inds[0]\n   # pdb.set_trace()\n    for k in range(1,len(inds)):\n        if inds[k] == inds[k-1] + 1:\n            continue\n        rle.append( str(last)+' '+str(inds[k-1]-last+1) )\n        last = inds[k]\n    return \" \".join(rle)\n\n","0bb01933":"%%time\nimport pdb\nthresh_score = 0.5\nthresh_num = 3500\npred_rle = []\n\ntest_img = []\nfor fn in tqdm_notebook(testfiles):\n        img = cv2.imread( '..\/input\/test_images\/'+fn )\n        img = gamma_correction(img)\n        img = contrast_enhancement(img)\n        img = cv2.resize(img,img_size)       \n        #test_img.append(img)   \n        scores = model.predict(np.asarray([img]))\n        scores = np.squeeze(scores)\n        pred = np.argmax(scores,axis=-1)\n        #print(scores.shape)\n        for cls in range(0, classes_num):\n            mask = np.squeeze(pred == cls).astype(np.uint8)\n            score = scores[:,:,cls]\n            #print(mask.shape,'---')\n            mask[score < thresh_score] = 0\n            if np.sum(mask) < thresh_num:\n                mask = mask * 0\n            mask = cv2.resize(mask, (1600, 256), cv2.INTER_NEAREST)\n            rle = mask2rle(mask)\n            #print(rle)\n            pred_rle.append(rle)\n        ","26d87255":"test_image_ind = 5\nimg_t = cv2.imread( '..\/input\/test_images\/'+ testfiles[test_image_ind])\nplt.subplot(classes_num+1,1,1)\nplt.imshow(img_t)\n\nfor cls in range(classes_num):\n    mask_t = rle2mask(pred_rle[test_image_ind*4 + cls], img_t.shape)\n    plt.subplot(classes_num+1,1,cls + 2)\n    plt.imshow(mask_t)","677bcd1d":"sub = pd.read_csv( '..\/input\/sample_submission.csv' )\nsub.head()","9c24ea68":"%%time\nprint(len(pred_rle)\/4)\nfor fn_ind,fn in enumerate(testfiles):\n    for cls in range(0, classes_num):\n       # if fn_ind == 4 and cls == 4:\n       #     idx = sub['ImageId_ClassId'] == \"{}_{}\".format(fn,cls)\n       #     print(sub['EncodedPixels'][idx])\n       #     print(fn)\n        sub['EncodedPixels'][sub['ImageId_ClassId'] == \"{}_{}\".format(fn,cls+1)] = pred_rle[fn_ind * 4 + cls]","8e9a72b4":"#img_s = cv2.imread( '..\/input\/test_images\/'+ sub['ImageId_ClassId'][4].split('_')[0])\n#plt.imshow(img_s)","c22800e9":"sub.to_csv('submission.csv', index=False)","7d424275":"Simple example of U-net for segmentation in Keras"}}