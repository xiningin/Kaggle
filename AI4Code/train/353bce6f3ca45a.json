{"cell_type":{"3862b4ba":"code","9a3c7221":"code","00c3cf97":"code","d660e025":"code","70d2cb2c":"code","2575a75e":"code","125a91d9":"code","792773d9":"code","ef801623":"code","88d41325":"code","c14a1b31":"code","5cddb163":"code","f348f567":"code","61d3a089":"code","cf00f61e":"code","0c470cf0":"code","2f23df20":"code","af718c77":"code","2c4ac64d":"code","6439d8b5":"code","fa911566":"code","642646e6":"code","84041478":"code","707df3c9":"code","05b4f452":"code","de60dea1":"code","97e05ebe":"code","7325e90a":"code","9f21b33e":"markdown","d64ed33c":"markdown","cf44c604":"markdown","d4937fdb":"markdown","873fa373":"markdown","c4ec6ed1":"markdown","201ac1fc":"markdown"},"source":{"3862b4ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n\n# Any results you write to the current directory are saved as output.","9a3c7221":"# Importing the libraries\n\ndata = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/trn.us.txt\")","00c3cf97":"data.head()","d660e025":"traindata = data.loc[:,[\"Open\"]].values","70d2cb2c":"traindata.shape","2575a75e":"# split into train and test sets\n\ntrain_size = int(len(traindata) * 0.9938)\ntest_size = len(traindata) - train_size\ntrain, test = traindata[0:train_size,:], traindata[train_size:len(traindata),:]\nprint(len(train), len(test))","125a91d9":"train.shape","792773d9":"test.shape","ef801623":"# Feature Scaling\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range= (0,1))\ntrain_scaled =scaler.fit_transform(train)\ntrain_scaled","88d41325":"plt.plot(train_scaled)\nplt.show()","c14a1b31":"# Creating a data structure with 50 timesteps and 1 output\n\nX_train = []\ny_train = []\ntimesteps = 50\nprint(train_scaled[0, 0])\nfor i in range(timesteps, train.shape[0]):\n   \n    X_train.append(train_scaled[i-timesteps:i, 0])\n    y_train.append(train_scaled[i, 0])\n    \nX_train, y_train = np.array(X_train), np.array(y_train)","5cddb163":"# Reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_train.shape","f348f567":"\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 50, batch_size = 32)","61d3a089":"# Getting the predicted stock price of 2017\ndataset_total = data['Open']\ninputs = dataset_total[len(dataset_total) - len(test) - timesteps:].values.reshape(-1,1)\ninputs\ninputs.shape","cf00f61e":"# min max scaler\ninputs = scaler.transform(inputs)  \n","0c470cf0":"X_test = []\nfor i in range(timesteps, 70):\n    X_test.append(inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n\n# Visualising the results\n\nplt.plot(test, color = 'red', label = 'Real  Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted  Stock Price')\nplt.title('Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel(' Stock Price')\nplt.legend()\nplt.show()\n","2f23df20":"data.columns","af718c77":"dataset = data.iloc[:,1].values\nplt.plot(dataset)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Stock Price\")\nplt.title(\"Stock Market Dataset\")\nplt.show()","2c4ac64d":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype(\"float32\")\ndataset.shape","6439d8b5":"# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","fa911566":"train_size = int(len(dataset) * 0.50)\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(\"train size: {}, test size: {} \".format(len(train), len(test)))","642646e6":"time_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = np.array(dataX)\ntrainY = np.array(dataY)  ","84041478":"dataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = np.array(dataX)\ntestY = np.array(dataY) ","707df3c9":"trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","05b4f452":"\nimport matplotlib.pyplot as plt\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","de60dea1":"# model\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(1, time_stemp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","97e05ebe":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","7325e90a":"# shifting train\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset[:200]))\nplt.plot(trainPredictPlot[:200])\nplt.plot(testPredictPlot[:200])\nplt.show()","9f21b33e":"### Create RNN Model","d64ed33c":"###  Use the same data set","cf44c604":"### Create LSTM Model","d4937fdb":"### Author : Sanjoy Biswas\n### Project : Stock Market Data Analysis & Visualization\n### Email : sanjoy.eee32@gmail.com","873fa373":"## Long Short Term Memory with Keras","c4ec6ed1":"### Predictions and Visualising RNN Model","201ac1fc":"### Loading and Preprocessing Data"}}