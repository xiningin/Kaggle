{"cell_type":{"9032bfac":"code","971cba4e":"code","4ca8e890":"code","dbabd6e6":"code","7827adbb":"code","ef95b688":"code","0c85fcf7":"code","bb92e013":"code","ef1a7259":"code","4a25a670":"code","58ceb87e":"code","f8d85c85":"code","4d3b9c99":"code","6389ef8f":"code","54e39d73":"code","2b90e1c7":"code","07cd9b90":"code","6aaec193":"code","e8ccc98d":"code","5f5a5531":"code","cbbf3644":"code","20d7c0a7":"code","574d877e":"code","4b9d3432":"code","e0d1910c":"code","78d20870":"code","6b83639c":"code","1dcb13d1":"code","faa07640":"code","070a748b":"code","02a0ece3":"code","87759224":"code","e1b957eb":"code","c0b688ad":"code","10445140":"code","5d4049a9":"code","86fc01ab":"code","856af08f":"code","717f3685":"code","fc2edcdd":"code","a142023a":"code","e755f930":"code","87d9380a":"code","6eb74bc8":"code","7e7a47a6":"code","97ec541a":"code","3bcb34ad":"code","c0af5667":"code","71cab5b3":"code","6fd14a89":"code","b727adf8":"code","70908e0a":"code","19845695":"code","b424837e":"code","f496895b":"code","14d53a3b":"code","83212d51":"code","50f04f52":"code","8e6667cf":"code","b20774da":"code","09caa72d":"code","802b4dbe":"code","69b9e317":"code","391fba04":"code","272014e5":"code","cf382b32":"code","815d4d55":"markdown","7b4c9421":"markdown","ada60e06":"markdown","b8828b99":"markdown","17f32734":"markdown","9c496faa":"markdown","444406eb":"markdown","e04d1012":"markdown","d4917db2":"markdown","25ad41a8":"markdown","89d7af69":"markdown","32ccd771":"markdown","e18a7b15":"markdown","ea6b9c4b":"markdown","5c13eea3":"markdown","e23138c1":"markdown","a46359c4":"markdown","ba24d151":"markdown","f8d0661a":"markdown","382a99c4":"markdown","5476220a":"markdown","bc7692b9":"markdown","457eec0f":"markdown","8615c370":"markdown","3daf90ad":"markdown","a8c20955":"markdown","4e631144":"markdown","af755912":"markdown","7ab653bd":"markdown","92e4318a":"markdown","9f3a331f":"markdown","3f3620fb":"markdown","df959f55":"markdown","65854f97":"markdown","de7c6d5b":"markdown","09882574":"markdown","0210554c":"markdown"},"source":{"9032bfac":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('whitegrid')","971cba4e":"#As dataset has a lot of columns, let's change the default display options\n#Doing that we will have full picture of our dataframe structure\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","4ca8e890":"houses_train_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col = 0)\nhouses_test_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col = 0)","dbabd6e6":"houses_train_data.head()","7827adbb":"houses_train_data.info()","ef95b688":"houses_test_data.head()","0c85fcf7":"houses_test_data.info()","bb92e013":"houses_train_data.isnull().sum().sort_values(ascending = False)","ef1a7259":"houses_test_data.isnull().sum().sort_values(ascending = False)","4a25a670":"# Checking correlation between LotFrontage and LotArea.\n\nhouses_train_data[['LotFrontage', 'LotArea']].corr()","58ceb87e":"# Checking correlation between Garage Cars and Garage Area.\n\nhouses_train_data[['GarageCars', 'GarageArea']].corr()","f8d85c85":"houses_test_data[houses_test_data['GarageCars'].isnull()]","4d3b9c99":"houses_test_data['GarageCars'].value_counts()","6389ef8f":"pd.get_dummies(houses_train_data[['SalePrice', 'BsmtCond', 'BsmtExposure', 'BsmtQual', \n                                  'BsmtFinType1', 'BsmtFinType2', 'BsmtHalfBath', 'BsmtFullBath', \n                                  'BsmtFinSF2', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF']]).corr()","54e39d73":"# Now let's check how 'MasVnrType' and 'MasVnrArea' affect sales price. \n\npd.get_dummies(houses_train_data[['SalePrice', 'MasVnrArea', 'MasVnrType']]).corr()","2b90e1c7":"pd.get_dummies(houses_train_data[['SalePrice', 'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond',\n                                  'BsmtQual', 'BsmtCond', 'BsmtExposure', 'KitchenQual', \n                                  'SaleCondition' ]]).corr()","07cd9b90":"pd.get_dummies(houses_train_data[['SalePrice', 'Electrical', 'MSZoning', 'Utilities', \n                                  'Functional', 'SaleType', 'Exterior1st', 'Exterior2nd']]).corr()","6aaec193":"# Checking Year-Price dependency\nprint((houses_train_data[['YearBuilt', 'SalePrice']].corr()))\nsns.scatterplot(houses_train_data['YearBuilt'], houses_train_data['SalePrice'])","e8ccc98d":"#dropping columns, where most of parameters are missing or weak correlation was detected\nhouses_train_data.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu', 'LotFrontage', \n                        'GarageType', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageYrBlt', \n                        'GarageArea', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', 'BsmtHalfBath', \n                        'BsmtFullBath', 'BsmtFinSF2', 'BsmtFinSF1', 'BsmtUnfSF', 'MasVnrType', \n                        'OverallCond','ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n                        'KitchenQual', 'SaleCondition', 'Electrical', 'MSZoning', 'Utilities', \n                        'Functional', 'SaleType', 'Exterior1st', 'Exterior2nd'], axis = 1, inplace = True)\nhouses_test_data.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu', 'LotFrontage', \n                        'GarageType', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageYrBlt', \n                        'GarageArea', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', 'BsmtHalfBath', \n                        'BsmtFullBath', 'BsmtFinSF2', 'BsmtFinSF1', 'BsmtUnfSF', 'MasVnrType', \n                        'OverallCond','ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n                        'KitchenQual', 'SaleCondition', 'Electrical', 'MSZoning', 'Utilities', \n                        'Functional', 'SaleType', 'Exterior1st', 'Exterior2nd'], axis = 1, inplace = True)\n\n#filling the gaps accordingly to notes above\nhouses_train_data.fillna({'TotalBsmtSF': 0, 'MasVnrArea': houses_train_data['MasVnrArea'].mean()}, \n                         inplace = True)\nhouses_test_data.fillna({'TotalBsmtSF': 0, 'GarageCars': 2, \n                         'MasVnrArea': houses_test_data['MasVnrArea'].mean()}, inplace = True)\n","5f5a5531":"#Confirming, that we do not have missing values in train dataset any more.\nhouses_train_data.isnull().sum().sort_values(ascending = False).head()","cbbf3644":"#Confirming, that we do not have missing values in test dataset any more.\nhouses_test_data.isnull().sum().sort_values(ascending = False).head()","20d7c0a7":"print(houses_train_data['SalePrice'].describe())\nhouses_train_data['SalePrice'].hist(bins = 30)","574d877e":"houses_train_data.columns","4b9d3432":"all_houses = pd.concat([houses_train_data, houses_test_data])","e0d1910c":"all_houses.dropna().nunique()","78d20870":"sns.countplot(all_houses['Street'])","6b83639c":"all_houses[all_houses['Street'] == 'Grvl']","1dcb13d1":"houses_train_data.drop(['Street'], axis = 1, inplace = True)\nhouses_test_data.drop(['Street'], axis = 1, inplace = True)","faa07640":"sns.countplot(all_houses['LandSlope'])","070a748b":"sns.boxplot(all_houses['LandSlope'], all_houses['SalePrice'])","02a0ece3":"houses_train_data.drop(['LandSlope'], axis = 1, inplace = True)\nhouses_test_data.drop(['LandSlope'], axis = 1, inplace = True)","87759224":"sns.countplot(all_houses['CentralAir'])","e1b957eb":"sns.boxplot(all_houses['CentralAir'], all_houses['SalePrice'])","c0b688ad":"houses_train_data['CentralAir'].replace(['Y', 'N'], [1, 0], inplace = True)\nhouses_test_data['CentralAir'].replace(['Y', 'N'], [1, 0], inplace = True)","10445140":"houses_train_data.columns","5d4049a9":"houses_train_data[['MSSubClass', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', \n                                'MasVnrArea', 'SalePrice']].corr()","86fc01ab":"fig = plt.figure()\naxes = fig.add_axes([0.1, 0.1, 1, 1])\n\naxes.plot(houses_train_data['YearBuilt'], houses_train_data['SalePrice'], 'b.', alpha = 0.5)\naxes.plot(houses_train_data['YearRemodAdd'], houses_train_data['SalePrice'], 'r.', alpha = 0.5)\naxes.set_xlabel('YearBuilt (blue), YearRemodAdd (red)')\naxes.set_ylabel('SalePrice')","856af08f":"houses_train_data[['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'SalePrice']].corr()","717f3685":"houses_train_data[['FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n                   'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'SalePrice']].corr()","fc2edcdd":"houses_train_data[['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice']].corr()","a142023a":"# List of columns, where we need to replace values\ncateg_columns = ['LotShape', 'LandContour', 'LotConfig',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n       'RoofStyle', 'RoofMatl', 'Foundation', 'Heating', 'HeatingQC', 'PavedDrive']","e755f930":"# Loop that replaces string values with numbers\nfor item in categ_columns:\n    to_replace = houses_train_data[item].unique()\n    values = list(range(len(pd.Series(houses_train_data[item].unique()))))\n    houses_train_data[item].replace(to_replace, values, inplace = True)\n    houses_test_data[item].replace(to_replace, values, inplace = True)","87d9380a":"# Checking correlation\nhouses_train_data[['LotShape', 'LandContour', 'LotConfig',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n       'RoofStyle', 'RoofMatl', 'Foundation', 'Heating', 'HeatingQC', 'PavedDrive', 'SalePrice']].corr()","6eb74bc8":"#dropping columns which weak impact on sales price\nhouses_train_data.drop(['EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MSSubClass',\n                        'LotArea', 'YearRemodAdd', 'LowQualFinSF', '1stFlrSF', 'HalfBath', 'BedroomAbvGr',\n                        'KitchenAbvGr', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', \n                        'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Heating', \n                        'PavedDrive'], axis = 1, inplace = True)\nhouses_test_data.drop(['EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MSSubClass',\n                       'LotArea', 'YearRemodAdd', 'LowQualFinSF', '1stFlrSF', 'HalfBath', 'BedroomAbvGr',\n                       'KitchenAbvGr', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', \n                       'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Heating', \n                       'PavedDrive'], axis = 1, inplace = True)","7e7a47a6":"houses_train_data.columns","97ec541a":"houses_train_data['Date'] = pd.to_datetime(houses_train_data['MoSold'].astype('str') + ' ' + houses_train_data['YrSold'].astype('str'))\nhouses_test_data['Date'] = pd.to_datetime(houses_test_data['MoSold'].astype('str') + ' ' + houses_test_data['YrSold'].astype('str'))","3bcb34ad":"plt.figure(figsize = (12, 6))\nsns.lineplot(houses_train_data['Date'], houses_train_data['SalePrice'])","c0af5667":"# Dropping columns which month and year\nhouses_train_data.drop(['MoSold', 'YrSold'], axis = 1, inplace = True)\nhouses_test_data.drop(['MoSold', 'YrSold'], axis = 1, inplace = True)\n\n# Saving date in different variables\ndates_in_houses_train_data = houses_train_data.pop('Date')\ndates_in_houses_test_data = houses_test_data.pop('Date')","71cab5b3":"# Let's check that all variables affect sales price using heatmap and correlation values\nplt.figure(figsize = (10, 10))\nsns.heatmap(houses_train_data.corr())","6fd14a89":"houses_train_data.corr()","b727adf8":"# Uploading prediction libraries\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor","70908e0a":"# Test split for model validation\nX = houses_train_data.drop(['SalePrice'], axis = 1)\ny = houses_train_data['SalePrice']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 100)","19845695":"# Creating classificators\nforest_reg = RandomForestRegressor()\nbooster_reg = GradientBoostingRegressor()","b424837e":"# Setting parameters for further search\n# parameters for forest_reg\nparameters_forest_reg = {'n_estimators': range(50, 300, 50), 'max_depth': range(5, 30, 2)}\n# parameters for booster_reg\nparameters_booster_reg = {'n_estimators': range(50, 300, 50)}","f496895b":"# Searching for best classificator settings\nsearch_forest_reg = GridSearchCV(forest_reg, parameters_forest_reg, cv = 5)\nsearch_booster_reg = GridSearchCV(booster_reg, parameters_booster_reg, cv = 5)","14d53a3b":"search_forest_reg.fit(X_train,y_train)\nsearch_booster_reg.fit(X_train,y_train)","83212d51":"# Checking best settings\n\nbest_forest_reg = search_forest_reg.best_estimator_\nbest_booster_reg = search_booster_reg.best_estimator_\n\nprint(best_forest_reg)\nprint(best_booster_reg)","50f04f52":"# Let's add random_state parameter and tune model a little bit more\nbest_forest_reg = RandomForestRegressor(max_depth = 17, n_estimators = 100, random_state = 50)\nbest_booster_reg = GradientBoostingRegressor(n_estimators = 100, random_state = 50)","8e6667cf":"# Making predictions\nbest_forest_reg.fit(X_train, y_train)\nbest_booster_reg.fit(X_train, y_train)\nforest_prediction = best_forest_reg.predict(X_test)\nbooster_prediction = best_booster_reg.predict(X_test)","b20774da":"# Cheching distribution of differences\n(y_test - forest_prediction).hist(alpha = 0.5, bins = 30)\n(y_test - booster_prediction).hist(alpha = 0.5, bins = 30)","09caa72d":"X_train = houses_train_data.drop(['SalePrice'], axis = 1)\ny_train = houses_train_data['SalePrice']\nX_test = houses_test_data","802b4dbe":"best_booster_reg.fit(X_train, y_train)\nbooster_prediction = best_booster_reg.predict(X_test)","69b9e317":"# Sales prices distribution in original dataset\nhouses_train_data['SalePrice'].describe()","391fba04":"# Distribution of predicted sales prices\npd.Series(booster_prediction).describe()","272014e5":"submission = pd.DataFrame({'Id': houses_test_data.index, 'SalePrice': booster_prediction})\nsubmission.head()","cf382b32":"submission.to_csv('\/kaggle\/working\/submission.csv', index = False)","815d4d55":"Minimal house price is 34900 USD, maximal - 755000 USD. However, having 75-th percentile on 214000 USD we can say, that only small amount of houses are really expensive. Mostly price is between 163000 and 214000 USD with mean 180921 USD. Similar picture we expect to see in the predictions. ","7b4c9421":"# Data analysis","ada60e06":"Checking how many empty rows there are in dataset:","b8828b99":"This notebook has next structure:\n- environment setup \n- data preparation and feature engineering\n- model built","17f32734":"To check if basement parameters affect sales price, I'm going to find correlation between 'SalePrice' and 'BsmtCond', 'BsmtExposure', 'BsmtQual', 'BsmtFinType1', 'BsmtFinType2', 'BsmtHalfBath', 'BsmtFullBath', 'BsmtFinSF2', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF'. I'm going to use 'get_dummies' method to include categorical variables in this analysis:","9c496faa":"Let's check how the rest of variable affect sales price.","444406eb":"# Handling of the missing data","e04d1012":"Let's check variables, that describe conditions and quality of the house:","d4917db2":"All the parameters are inter-correlated, so they may affect sales price and our further predictions, however it will be better to leave only one variable to avoid collinearity. Here I'm going to leave 'MasVnrArea' as it has higher correlation with both 'SalePrice' and 'MasVnrType'. To reduce the negative affect of missing values, I'll fill gaps with mean 'MasVnrArea' value. ","25ad41a8":"1. Sales price correlates with 'TotalBsmtSF', '1stFlrSF', '2stFlrSF' and 'GrLivAres'. However, 'TotalBsmtSF' is also highly correlated with '1stFlrSF', so from this two parameters we will use only 'TotalBsmtSF' further.\n2. There is no correlation with 'LowQualFinSF', so this variable will be removed.","89d7af69":"We can see that there is only minor impact of this variables on sales price. \n- Of course, there is some correlation between SalePrice and SaleType_New, but the same relation is present between 'SalePrice' - 'YearBuilt' (scatter plot is presented below).\n- Some correlation between SalePrice and Exterior has also place, but let's remove it for now to make analysis simpler. If model won't be precise enough, we can add it back.","32ccd771":"We can see that 'Foundation' and 'HeatingQC' has highest correlation with sales price (~ -0.42). The rest of variables do not impact the price, so we are going to remove them. ","e18a7b15":"# Setup","ea6b9c4b":"There are also few categorical varaibles that need to be analysed: 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Foundation', 'Heating', 'HeatingQC', 'PavedDrive'. Let's replace their string values with numerical and check the correlation.","5c13eea3":"For now there are still few more gaps in our data:\n- in train set we have one gap in 'Electrical' column\n- in test set we have several gaps in 'MSZoning', 'Utilities', 'Functional', 'SaleType', 'Exterior1st', 'Exterior2nd' columns\n\nLet's check how these variables affect sales price.","e23138c1":"Both models are quite similar, but let's choose GradientBoostingRegressor for submission.","a46359c4":"There are no strong dependency between sales price and 'MSSubClass' or 'LotArea', so I'll remove these variables. \n\nThere is also very similar picture for 'YearBuilt' and 'YearRemodAdd' (extra plot presented below), so there is no need to have both variables. I'm going to leave only 'YearBuilt'.","ba24d151":"Correlation between Garage Cars and Garage Area is quite strong, so we can say that multicollinearity has place there. Multicollinearity cannot reduce accuracy of sales predictions in general, but it can affect analysis of every single parameter separately. Because of that I'm going to remove numerical parameter 'GarageArea' and leave categorical varaible 'GarageCars'.\n\nThere is also one missing value in 'GarageCars' column. Let's look at that row and check the distribution:","f8d0661a":"Biggest correlation is between 'SalePrice' and 'OveralQual', which is logical and makes 'OveralQual' parameter important is our analysis.\nThere are also other variables, that have strong correlation with sales price, however they also correlate with 'OveralQual' variable. This means, that if we include both 'OveralQual' and other variables, we will include multicollinearity in our analysis. Let's avoid that and leave only one quality parameter. ","382a99c4":"We can see that we have a lot of columns with missing values. Let's analyse them.\n\n- There are 5 parameters, where near or more then 50% of data are absent:  'Alley' (1369 and 1352 null values in train and test datasets), 'PoolQC' (1453\/1456 null values), 'Fence' (1179\/1169 null values), 'MiscFeature' (1406\/1408 null values), 'FireplaceQu' (690\/730 null values). Since we cannot recover all the missing data having less then half known information, the best option here is to remove these columns from our analysis. \n- I assume that 'LotFrontage' parameter is correlated with 'LotArea' parameter and is less important one. If it is so, then we'll able to remove 'LotFrontage' from the dataset, as 'LotArea' handels affection on sales price. Let's check this relation before we make a decision.\n- In our dataset we have multiple garage-related parameters: 'GarageArea', 'GarageCars', 'GarageType', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageYrBlt'. We can see that the number of missing values is the same for last 5 parameters (81 and 78 in train and test datasets), which means that these parameters are missing for the same houses. These values can be absent as garage condition is not relevant at all (so people didn't provide this information) or if garage is still important for buyer, then most probably he will check 'GarageArea' or 'GarageCars'. At this stage I'm goint to remove redundant garage details ('GarageType', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageYrBlt') and I'll also check correlation between 'GarageArea' and 'GarageCars' and will leave only one parameter, if correlation has place.\n- There are also several columns related to basement: 'BsmtCond', 'BsmtExposure', 'BsmtQual', 'BsmtFinType1', 'BsmtFinType2', 'BsmtHalfBath', 'BsmtFullBath', 'BsmtFinSF2', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF'. Let's analyse them separately and remove all the redundant ones.","5476220a":"Let's check those variables, where we have only 2 values.","bc7692b9":"From all the presented varaibles there is some relation of sales price only with 'WoodDeckSF' and 'OpenPorchSF'. The rest are more chaotically distributed and I'm going to remove them from the analysis","457eec0f":"Knowing that house ID 2577 has a garage of a detached type and most often garages are built for 2 cars, let's fill a gap with a most possible option - 2. ","8615c370":"Uploading and checking data. \n*Note:* We have 'Id' column at a position 0 in our dataset. This column is not informative within further analysis, but I don't want to drop it, since it is needed for submission. I decided to use this column as main index.","3daf90ad":"Let's take a look on sales price distribution","a8c20955":"Now we have ~50 columns (independent parameters), which is way too much for our model. We need to find out, which parameters are the most important to make further analysis easier.\n\n\nLet's concatenate dataset to make analysis easier and then check distribution of some variables.","4e631144":"Boxplot shows that there is a significant difference between those two types of 'CentralAir', so we cannot remove this variable. \n\nHowever let's replace string values Yes\/No with numbers 1\/0, so it would be easier to analyse the dataset.","af755912":"From this batch I'm going to remove 'HalfBath', 'BedroomAbvGr' and 'KitchenAbvGr' as they do not really impact sales price.","7ab653bd":"First of all let's take a look on a dataset and short information about it. From that point we can find out data types that are used, memory usage, missing data. etc.","92e4318a":"We can see that second part of the year is more efficient in terms of sales, but difference is not very significant.\n\nLet's remove redundant Month and Year columns from datasets:","9f3a331f":"There are only 6 houses on Grvl street (with known sales price) and all the prices are around our mean value. \n\nI can conclude that Street parameter is not informative and I'm going to remove it from our analysis.","3f3620fb":"As most of the houses have LandSlope = Glt and mean values for all the LandSlope types are similar, I'll also remove this variable. ","df959f55":"Most of the houses are on Pave street... Let's check if Street = Grvl affects sales price. ","65854f97":"Let's analyse time data separately.","de7c6d5b":"Setting the environment by adding needed libraries. Some extra scikit libraries will be added at the later stages. ","09882574":"Some correlation has place there. Let's remove 'LotFrontage' for now and check how accurate our model will be. ","0210554c":"We can see that next variables affect sales price the most: 'BsmtFinSF1', 'BsmtFinType1', 'TotalBsmtSF', 'BsmtExposure', 'BsmtQual'. However, 'BsmtFinSF1' and 'BsmtFinType1' are also correlated with 'TotalBsmtSF' and 'BsmtExposure', which can cause some distortions in analysis of individual parameters. So for now let's leave only 3 the most independent and important variables: 'TotalBsmtSF', 'BsmtExposure', 'BsmtQual'. \n\nFor missing values in these columns I'm going to do the next steps:\n- gaps in 'TotalBsmtSF' I'll fill with '0'.\n- gaps in 'BsmtExposure' and 'BsmtQual' I'll fill with 'Not specified'."}}