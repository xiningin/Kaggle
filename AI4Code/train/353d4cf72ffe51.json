{"cell_type":{"476e2131":"code","b5117b27":"code","b961b964":"code","b7ea25e3":"code","a049ca1a":"code","ace93f53":"code","f6fd97e5":"code","85467bb1":"code","0ea15c9b":"code","ffebc18f":"code","fe5f9701":"code","f468bf5b":"code","157ddf38":"code","b85c53ab":"code","28c1e082":"code","4de90faa":"markdown","54c4c879":"markdown","1b84a18f":"markdown","84d428bd":"markdown","db04551f":"markdown","5f4a3fc9":"markdown","05b85ac6":"markdown","779a4200":"markdown","a9d206bd":"markdown","6700a703":"markdown","6e7c3244":"markdown","bd3a7161":"markdown","fb233d85":"markdown"},"source":{"476e2131":"from time import time\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nimport os\n\n# libraries to support custom function for copying.\n\nimport errno\nimport shutil","b5117b27":"def copy(src, dest):\n    try:\n        shutil.copytree(src, dest)\n    except OSError as e:\n        # If the error was caused because the source wasn't a directory\n        if e.errno == errno.ENOTDIR:\n            shutil.copy(src, dest)\n        else:\n            print('Directory not copied. Error: %s' % e)","b961b964":"src = '..\/input\/'\ndest = '..\/LFW\/lfw_home'\ncopy(src,dest)","b7ea25e3":"# verifying the contents of src and dest folder\n\nprint(os.listdir('..\/input'))\nprint(os.listdir('..\/LFW\/lfw_home'))\n# path = '..\/LFW\/lfw_home\/'\npath = '..\/LFW\/'","a049ca1a":"# Load data\nlfw_dataset = sklearn.datasets.fetch_lfw_people(data_home = path, min_faces_per_person=100,  download_if_missing = False)\n\n#download_if_missing = False ; it prevents downloading, and generates IOError if file is missing, by dfualt value = true\n# lfw_dataset = ","ace93f53":"n_samples, h, w = lfw_dataset.images.shape\n# for machine learning we use the 2 data directly (as relative pixel\n# positions info is ignored by this model)\nX = lfw_dataset.data\nn_features = X.shape[1]\n\n# the label to predict is the id of the person\ny = lfw_dataset.target\ntarget_names = lfw_dataset.target_names\nn_classes = target_names.shape[0]","f6fd97e5":"print(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)","85467bb1":"# #############################################################################\n# Split into a training set and a test set using a stratified k fold\n\n# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42)","0ea15c9b":"# #############################################################################\n# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n# dataset): unsupervised feature extraction \/ dimensionality reduction\n\nn_components = 150\n\nprint(\"Extracting the top %d eigenfaces from %d faces\"\n      % (n_components, X_train.shape[0]))\nt0 = time()\npca = PCA(n_components=n_components, svd_solver='randomized',\n          whiten=True).fit(X_train)\nprint(\"done in %0.3fs\" % (time() - t0))","ffebc18f":"eigenfaces = pca.components_.reshape((n_components, h, w))\n\nprint(\"Projecting the input data on the eigenfaces orthonormal basis\")\nt0 = time()\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(\"done in %0.3fs\" % (time() - t0))\n","fe5f9701":"#  #############################################################################\n# Train a SVM classification model\n\nprint(\"Fitting the classifier to the training set\")\nt0 = time()\nparam_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\nclf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\nclf = clf.fit(X_train_pca, y_train)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\n","f468bf5b":"# #############################################################################\n# Quantitative evaluation of the model quality on the test set\n\nprint(\"Predicting people's names on the test set\")\nt0 = time()\ny_pred = clf.predict(X_test_pca)\nprint(\"done in %0.3fs\" % (time() - t0))\n\nprint(classification_report(y_test, y_pred, target_names=target_names))\nprint(confusion_matrix(y_test, y_pred, labels=range(n_classes)))","157ddf38":"# #############################################################################\n# Qualitative evaluation of the predictions using matplotlib\n\ndef plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n        plt.title(titles[i], size=12)\n        plt.xticks(())\n        plt.yticks(())","b85c53ab":"# plot the gallery of the most significative eigenfaces\n\neigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\nplot_gallery(eigenfaces, eigenface_titles, h, w)\n\nplt.show()","28c1e082":"# plot the result of the prediction on a portion of the test set\n\ndef title(y_pred, y_test, target_names, i):\n    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n\nprediction_titles = [title(y_pred, y_test, target_names, i)\n                     for i in range(y_pred.shape[0])]\n\nplot_gallery(X_test, prediction_titles, h, w)","4de90faa":"Now we can simply use **scikit-learn\u2019s PCA** class to perform the **dimensionality reduction** for us! We have to select the number of components, i.e., the **output dimensionality** (the *number of eigenvectors* to project onto), that we want to reduce down to, and feel free to tweak this parameter to try to get the best result! We\u2019ll use **150 components**. Additionally, we\u2019ll **whiten our data**, which is easy to do with a simple boolean flag! (**Whitening** just makes our resulting data have a **unit variance**, which has been shown to produce better results).\n\nWe can apply the transform to **bring our images down to a 150-dimensional space**.\n\nNotice we\u2019re not performing PCA on the entire dataset, only the training data. \n**This is so we can better generalize to unseen data.**","54c4c879":"# Conclusion:\n## -----------------------------------------\n\nI have successfully demonstrated how to perform a **facial recognition task** on this dataset. There is ofcourse lots of scope for improvement;\n\n**like:** *improving the accuracy*, implementing *other modoleing algorithms, tweaking PCA*, trying other *dimensionality reduction methods;* and ofcourse, *trying on your own dataset*.\n\n## Please upvote (^) this Kernel, if you like it!\n\n**Thanks and Happy Kaggle Days!**","1b84a18f":"#### Visualizing the Eigen Faces (reduced components of faces).","84d428bd":"#### Visualising the prediction by plotting with Faces and train-test Prediction pairs.","db04551f":"# Here is THE Big TRICK...\n\nBy default running the `fetch_lfw_people()` function downloads the data into the '**~\/scikit_learn_data**' subfolders. This is not a big deal when you run the notebook on your **Local PC**. But, this becomes ***Shooting a STAR*** when you do the same in a **KAGGLE KERNEL**.\n\nIts *hard to locate* where your data gets downloaded when you run the above function. Matter of relief, I have collected the data from Sklearn's dataset folder, and uploaded here. So, you can easily get to know that data is available at location: '**..\/input**'.\n\nAgain, you get *a hit on your nose*; Because, You can not fetch and process data there as '**..\/input\/lfw_people\/**' has '***READ ONLY***' permission.\n\n### Solution:\n\nI ***created*** a folder named '**..\/LFW\/lfw_people**'. And, set it as the **path**. So, the next time my fetching function will access and process data here. Then, I **copied** my complete dataset to this location(* Moving is also a great option*).\n\nNow, It is behaving exactly like its running on your Local PC. Hurray !\n","5f4a3fc9":"#### Remember that PCA produces eigenvectors. We can reshape those eigenvectors into images and visualize the eigenfaces.","05b85ac6":"### copying the contents of src folder: files + directory...","779a4200":"### Above Function Returns...\n\n**dataset :** dict-like object with the following attributes:\n\n**dataset.data :** numpy array of shape (13233, 2914)\n\n*Each row corresponds to a ravelled face image of original size 62 x 47 pixels. Changing the slice_ or resize parameters will change the shape of the output.*\n\n**dataset.images :** numpy array of shape (13233, 62, 47)\n\n*Each row is a face image corresponding to one of the 5749 people in the dataset. Changing the slice_ or resize parameters will change the shape of the output.*\n\n**dataset.target :** numpy array of shape (13233,)\n\nLabels associated to each face image. Those labels range from 0-5748 and correspond to the person IDs.\n\n**dataset.DESCR :** string\n\nDescription of the Labeled Faces in the Wild (LFW) dataset.","a9d206bd":"# **The Labelled Faces in the Wild Dataset !**\n\n![LFW-People Banner](http:\/\/www.whdeng.cn\/CALFW\/positive_pairs.jpg)\n\n","6700a703":"### Data loading only; Not downloading as its already available to us.","6e7c3244":"# Importing all Libraries...","bd3a7161":"## Note:\n#### The argument to our function just **prunes** all people without at least 100 faces, thus reducing the number of classes. Then we can extract our dataset and other auxiliary information. Finally, we split our dataset into training and testing sets.","fb233d85":"## Princpal Component Analysis:\n# -------------------------------------------------\nOne technique of *dimensionality reduction* is called ***principal component analysis (PCA)***. The idea behind PCA is that we want to select the **hyperplane** such that when all the points are projected onto it, they are **maximally spread out**. In other words, we want the ***axis of maximal variance***! A potential axis is the x-axis or y-axis, but, in both cases, that\u2019s not the best axis. However, if we pick a line that cuts through our data diagonally, that is the axis where the *data would be most spread*!\n\n![PCA](https:\/\/pythonmachinelearning.pro\/wp-content\/uploads\/2017\/10\/PCA-Eigen.png.webp)\n\n**The longer blue axis is the correct axis**! If we were to project our points onto this axis, they would be **maximally spread**! But how do we figure out this axis? We can borrow a term from linear algebra called **eigenvectors**! This is where **eigenfaces** gets its name!\n\nEssentially, we compute the **covariance matrix** of our data and consider that covariance matrix\u2019s *largest eigenvectors*. Those are our principal axes and the axes that we project our data onto to reduce dimensions. Using this approach, we can take high-dimensional data and reduce it down to a lower dimension by selecting the largest eigenvectors of the covariance matrix and projecting onto those eigenvectors.\n\nSince we\u2019re computing the axes of maximum spread, we\u2019re retaining the most important aspects of our data. **It\u2019s easier for our classifier to separate faces when our data are spread out as opposed to bunched together**.\n\n(There are **other** dimensionality techniques, such as **Linear Discriminant Analysis**, that use *supervised learning* and are also used in face recognition, but **PCA works really well**!)"}}