{"cell_type":{"70fd458d":"code","0ea41469":"code","4211085b":"code","eb7ff01f":"code","5f27003b":"code","ffa331a2":"code","3726f8be":"code","bf405e38":"code","845be5a6":"code","4e2cdee3":"code","1d4c35c5":"code","1ce8d643":"code","41ce4967":"code","2eae6dcc":"code","6ae03543":"code","25962d11":"code","8960484c":"code","5b24dc7d":"code","d5a6e334":"code","ae39941f":"code","a4ec1371":"code","d2277fdf":"code","e57ad51f":"code","d4297178":"code","baa0f3fa":"code","3b94cf06":"code","dca31063":"code","45606794":"code","631403d5":"code","5a7d93cb":"code","fba94fe5":"code","5dd6e348":"code","03debfbd":"markdown","34c38134":"markdown","5174e3bf":"markdown"},"source":{"70fd458d":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import random_split, Dataset\n# from translate.py import translate\nimport torchvision.models as models\n\nimport random\n%matplotlib inline","0ea41469":"class MyDataSet(Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n    \n    def __len__(self):\n        return len(self.subset)","4211085b":"data_dir = '..\/input\/snake-dataset-india\/Snake Images\/train'\nclasses = (os.listdir(data_dir))\n\n\ndataset = datasets.ImageFolder(data_dir, transform = transforms.Compose([\n    transforms.Resize((288,288)), \n    transforms.ToTensor(),\n    ]))\n\nimg, label = dataset[10]\nprint(img.shape, label)\nimg\nprint(dataset.classes)","eb7ff01f":"test_dir = '..\/input\/snake-dataset-india\/Snake Images\/test'\n\ntest = datasets.ImageFolder(test_dir, transform = transforms.Compose([\n    transforms.Resize((288,288)), \n    transforms.ToTensor(),\n    ]))","5f27003b":"def show(img, label):\n    print('Label:', dataset.classes[label], '(' + str(label)+')')\n    plt.imshow(img.permute(1,2,0))\nshow(*dataset[random.randint(1,len(dataset))])","ffa331a2":"random_seed = 45\ntorch.manual_seed(random_seed)\nval_size = 100\ntest_size = len(test)\ntrain_size = len(dataset) - val_size\ntrain_size + val_size + test_size","3726f8be":"train_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","bf405e38":"stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\ntrain_set = MyDataSet(train_ds, transform = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(*stats, inplace=True),\n\n    ]))\n\nval_set = MyDataSet(val_ds, transform = transforms.Normalize(*stats, inplace=True))\n\n\ntest_set = MyDataSet(test, transform = transforms.Normalize(*stats, inplace=True))\n","845be5a6":"len(test_set), len(train_set)\ntrain_set[0][0].shape","4e2cdee3":"from torchvision.utils import make_grid\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(24,6))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1,2,0))\n        break","1d4c35c5":"batch_size = 8\ntrain_loader = DataLoader(train_set, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_set, 16, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_set, 16, num_workers=2, pin_memory=True)","1ce8d643":"show_batch(val_loader)","41ce4967":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    valid_preds = torch.sum(preds == labels).item()\n    all_preds = len(preds)\n    return torch.tensor(valid_preds\/all_preds)","2eae6dcc":"class ModelBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n    ","6ae03543":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\n    \ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    \n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n\n            optimizer.step()\n            optimizer.zero_grad()\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","25962d11":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')","8960484c":"device = get_default_device()\ndevice","5b24dc7d":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","d5a6e334":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","ae39941f":"input_size = 3\noutput_size = 2","a4ec1371":"def conv_block(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n              nn.BatchNorm2d(out_channels), \n              nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(5))\n    return nn.Sequential(*layers)\n\nclass Model1(ModelBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 64)\n        self.conv2 = conv_block(64, 128, pool=True)\n        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n        \n        self.conv3 = conv_block(128, 256, pool=True)\n        self.conv4 = conv_block(256, 512, pool=True)\n        self.res2 = nn.Sequential(conv_block(512,512), conv_block(512, 512))\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(2), \n                                        nn.Flatten(), \n                                        nn.Linear(512, num_classes))\n        \n    def forward(self, xb):\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out","d2277fdf":"class Model2(ModelBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 10)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))","e57ad51f":"model = Model1(3,2)\nmodel","d4297178":"for images, labels in train_loader:\n    print('images.shape: ', images.shape)\n    out = model(images)\n    print('out.shape: ', out.shape)\n    print(\"out[0]: \", out[0])\n    break","baa0f3fa":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","3b94cf06":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)\ndevice = get_default_device()\ndevice\nto_device(model, device)","dca31063":"epochs = 15\nmax_lr = 0.005\ngrad_clip = 0.1\nweight_decay = 1e-5\nopt_func = torch.optim.Adam","45606794":"evaluate(model, val_loader)","631403d5":"evaluate(model, test_loader)","5a7d93cb":"%%time\nhistory = []\nhistory += fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","fba94fe5":"plot_losses(history)","5dd6e348":"plot_accuracies(history)","03debfbd":"# CNN Using PyTorch\n\nThe venomous and non-venomous classification problem can play a vital role in many rural areas. This notebook is a tutorial of how you can use this dataset to make a real-life model. This notebook uses Pytorch library to make a CNN. You can try keras and tensorflow too to make a CNN model. Here I am making a simple NN model as complex models won't work in this situation according to me.","34c38134":"The graph here shows that the loss is getting stabled but the accuracy of the model is varying a bit. A reason of that could be less images than a usual dataset has or maybe some wrong model choice.  ","5174e3bf":"The model is performing good with 75% val. accuracy. You can use this notebook for how to use this dataset using pytorch.\n\nThank you for visiting this notebook. Hope you have liked my efforts.\n\nIf you liked this nb, Do Upvote."}}