{"cell_type":{"2c2c5ba8":"code","0978f6b6":"code","4cb84168":"code","0fc8dee4":"code","b292f3a7":"code","01df91d5":"code","b80fc20d":"code","f0d70981":"code","13ab900e":"code","9e20b1e0":"code","34d6531d":"code","34d6c57d":"code","e40dd55b":"code","25f5fb2f":"code","3c542466":"code","51e8d33c":"code","2d821009":"code","945711d9":"code","4a7fa676":"code","76e743c9":"code","0545d72b":"code","457a2e54":"code","12b3c737":"code","efe108f3":"code","77e2eb72":"code","705e4df1":"markdown","764062c8":"markdown","1ff4969f":"markdown","74acd9e4":"markdown","015c0a74":"markdown","1671937b":"markdown","7c3af7a3":"markdown","22f48300":"markdown","f7a69305":"markdown"},"source":{"2c2c5ba8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0978f6b6":"import random\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n\nfrom fastai import *\nfrom fastai.tabular.all import *\nimport torch\n\nsns.set_theme(style=\"white\")\ncmap_div = sns.diverging_palette(230, 20, as_cmap=True)","4cb84168":"# fixing seed\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED) # gpu vars\ntorch.backends.cudnn.deterministic = True  #needed\ntorch.backends.cudnn.benchmark = False","0fc8dee4":"!ls ..\/input\/tabular-playground-series-feb-2021","b292f3a7":"dpath = Path('..\/input\/tabular-playground-series-feb-2021')\nsample_sub = pd.read_csv(dpath \/ 'sample_submission.csv')\ntest_raw = pd.read_csv(dpath \/ 'test.csv')\ntrain_raw = pd.read_csv(dpath \/ 'train.csv')","01df91d5":"# crate full DataFrame for easier overview of the data\nfull = pd.concat([train_raw.copy(deep = True), test_raw.copy(deep =True)])","b80fc20d":"full.head()","f0d70981":"# quite a few cont. features are strongly correlated\nsns.heatmap(full.drop(columns=['id']).corr(), cmap=cmap_div);","13ab900e":"# luckely no columns have NA values\nfull.isna().sum().to_frame(name='NA').query('NA > 0')","9e20b1e0":"# no duplicated entries\nfull.drop(columns=['id', 'target']).duplicated().sum()","34d6531d":"def one_hot_encoding(df):\n    # pandas take care of one-hot encoding of categorial features\n    df = pd.get_dummies(df)\n    return df","34d6c57d":"def split_data(df):\n    df = df.reset_index(drop=True) # this makes the index going from 0 .. n-1 independently of any transformation before\n    id = df['id']\n    df = df.drop(columns=['id'])\n    \n    if 'target' in df.columns:\n        x = df.drop(columns=['target'])\n        y = df['target']\n    else:\n        x = df\n        y = None\n    \n    return (x, y, id)","e40dd55b":"def split_data_fastai(df):\n    df = df.reset_index(drop=True) # this makes the index going from 0 .. n-1 independently of any transformation before\n    id = df['id']\n    df = df.drop(columns=['id'])\n    \n    return (df, id)","25f5fb2f":"def apply_all(df, funs, debug=False):\n    \"\"\"Helper function to apply a series of functions onto a DataFrame\"\"\"\n    for fun in funs:\n        if debug:\n            print(f'Apply {fun.__name__}')\n        df = fun(df)\n    return df","3c542466":"train = train_raw.copy(deep = True)\nprep_triv = lambda x: apply_all(x, [one_hot_encoding, split_data])\nx, y, id = prep_triv(train)\n\ntriv_model = DummyRegressor(strategy='median')\n\nscores = cross_validate(triv_model, x, y, cv=5,\n                        scoring=('neg_root_mean_squared_error'),\n                        n_jobs=-1)\ntriv_model.fit(x, y)\n\n\nprint(f'triv_model - RMSE: {np.mean(scores[\"test_score\"]*-1)}')","51e8d33c":"train = train_raw.copy(deep = True)\nprep_nn1 = lambda x: apply_all(x, [split_data_fastai])\ntrain, train_ids = prep_nn1(train)\n\ntorch.device('cuda') # enable cuda, (activate GPU usage)\n\ncont_names = [f'cont{i}' for i in range(14)] # set the continous variables\ncat_names = [f'cat{i}' for i in range(10)] # set the categoriall variables\nprocs = [Categorify, Normalize] # different fast.ai preprocessing steps\ndep_var = 'target' # our target variable\n\nsplits = RandomSplitter(valid_pct=0.25, seed=42)(train.index) # to validate the results we use randomly 20% of the training set\n\ncfg = tabular_config(embed_p=0.10, ps=0.10)\n\ndls = TabularPandas(train,\n                    cont_names=cont_names,\n                    cat_names=cat_names,\n                    procs=procs,\n                    y_names=dep_var,\n                    splits=splits).dataloaders(bs=2056)\n\n\ncallbacks = [SaveModelCallback(min_delta=0.001, monitor='_rmse', comp=np.less, fname='model_triv_best')]\n\nlearn = tabular_learner(dls, layers=[2000,500], metrics=[rmse], config=cfg)","2d821009":"learn.lr_find()","945711d9":"learn.fit_one_cycle(45, lr_max=2e-2, cbs=callbacks)","4a7fa676":"learn.lr_find()","76e743c9":"learn.fit_one_cycle(45, lr_max=slice(1e-6, 1e-6, 1e-2), cbs=callbacks)","0545d72b":"learn.recorder.plot_loss()","457a2e54":"test, test_id = prep_nn1(test_raw.copy(deep=True))\n\ntest_dl = learn.dls.test_dl(test)\n\npreds, _ = learn.get_preds(dl=test_dl)\npreds = preds.numpy().T[0]\n\nsubmission = pd.DataFrame(\n    {'id': test_id,\n     'target': preds}\n)\nsubmission.to_csv('submission_trivial_nn.csv', index=False)","12b3c737":"full_train_dl = learn.dls.test_dl(train)\n\npreds, _ = learn.get_preds(dl=full_train_dl)\npreds = preds.numpy().T[0]\n\nfull_train_results = pd.DataFrame(\n    {'id': train_ids,\n     'target': preds}\n)","efe108f3":"!mkdir -p '\/kaggle\/working\/Feb2021Playground\/FastAi'","77e2eb72":"submission.to_csv('\/kaggle\/working\/Feb2021Playground\/FastAi\/test_results_fastai.csv', index=False)\nfull_train_results.to_csv('\/kaggle\/working\/Feb2021Playground\/FastAi\/train_results_fastai.csv', index=False)","705e4df1":"# Fast.ai on Feb Playground\n\nThis notebook uses fast.ai to use a neural network on the February Playground data.\nAll data analysis is done in a separate notebook.","764062c8":"### TODOs\n* look for temporal correlation\n* ...\n","1ff4969f":"The final result is not much better than the trivial model. Nevertheless I submit this first results.","74acd9e4":"## EDA\n\nJust a very brief look to avoid nonsense.","015c0a74":"Finally, run the model also on the full training dataset and store the results of the training and test set for later usage.","1671937b":"# Feature Engineering\n\nFor fast.ai no (or almost no) feature engineering is done.","7c3af7a3":"## Naive Model\n\nHere I calculate the performance of a naive model, which just applies the median.","22f48300":"## fast.ai\n\nSince the dataset is relativly large, the employed model can also quite big.\nThe data contains no missing data, so there is no need for much preprocessing here.\nI've used a small dropout probability for the embedding and linear layers. Setting the dropout to zero, leads to very unstable training.","f7a69305":"## Import packages and load data"}}