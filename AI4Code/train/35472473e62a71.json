{"cell_type":{"d5ead3e4":"code","bc58f992":"code","c5355626":"code","5843df29":"code","d657ae0c":"code","73d166e2":"code","c0d7516e":"code","07f72985":"code","f5192802":"code","1f208b64":"code","06f25e87":"code","3a33e333":"code","1bd1917b":"code","b515ebb6":"code","9e58523a":"code","db8859af":"code","b2fc679b":"code","3063203c":"code","3a85175c":"code","f1413a26":"code","d89ba2b1":"markdown","341926e9":"markdown","b9edbdeb":"markdown","be9b0f0a":"markdown","4b6cbc02":"markdown","cc699577":"markdown"},"source":{"d5ead3e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Plotting graphs\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc58f992":"# Loading dataset from Kaggle directly\n# https:\/\/www.kaggle.com\/aungpyaeap\/supermarket-sales\nds = pd.read_csv('..\/input\/supermarket-sales\/supermarket_sales - Sheet1.csv') ","c5355626":"# check columns types, null values\nds.info()","5843df29":"# View of the DS\nds.head()","d657ae0c":"# Getting extra statistics infos\nds.describe(include='all')","73d166e2":"# Manual checks\n\nds.City.mode() #display the most frequent value\nnp.unique(ds['Product line']) #display the list of unique values \nds['Payment'].value_counts() # Count frequence per appearance\n\nds[ds['cogs'] == ds.cogs.max()] # Display all columns for the max of the column cogs > Higher cogs from fashion accessories product\nds[ds['cogs'] == ds.cogs.min()]# Display all columns for the min of the column cogs > Lower cogs from sport and travel product\n\nds[ds['Rating'] == ds.Rating.max()] # 5 purchase with the maximum rate of 10\nds[ds['Rating'] == ds.Rating.min()] # 11 purchase with the lowest rate of 4\n","c0d7516e":"# Display the Day of the week wheen the most purchased items happend\n\nds['Date'] = pd.to_datetime(ds['Date'], format='%m\/%d\/%Y') # convert column 'Date' into datetime type\nds[\"week_days\"] = ds[\"Date\"].dt.day_name()\nds['week_days'].value_counts()\n\n# >> Most purchased frequences happen the Saturday","07f72985":"# Display the hour wheen the most purchased items happend\n\nds['Hours_only'] = pd.to_datetime(ds['Time'], format='%H:%M') # convert column 'Time' into datetime type\nds['Hours_only'] = ds['Hours_only'].dt.hour # Keeping only hours from datetime\nds['Hours_only'].value_counts() # Count frequence per appearance\n\n# >> Most purchased frequences happen between 19h - 20h\n","f5192802":"#Creating the unit cost of goods, to see the cogs over each piece\nds['unit_cogs'] = ds['cogs'] \/ ds['Quantity']\n\n# >> the tax is = the margin","1f208b64":"# Group on gender segmentation to find specificities\n\nds.Total.sum() # total turn over\nds['gross income'].sum() # total gross income\n\ngrp_gender_sum = ds.groupby(['Gender']).sum()\n# > Female tend to buy more in quantity than Male\n\ngrp_gender_mean = ds.groupby(['Gender']).mean()\n# > then due to fix margin, Female spend more than Male in total value\n","06f25e87":"# Group on Product line segmentation to find specificities\n\ngrp_prodLine_sum = ds.groupby(['Product line']).sum() \n# > Food and beverage is the type of product sold the most in quantity \n\n\ngrp_prodLine_mean = ds.groupby(['Product line']).mean() \n# > In average, Fashion product are the most expensive products per unit and the less sold in quantity\n\ngrp_prodLine_sum","3a33e333":"# Group on week days segmentation to find specificities\ngrp_weekdays_sum = ds.groupby(['week_days']).sum() \n# > The Saturday is cumulating the most value of sales versus the Monday\n\ngrp_weekdays_mean = ds.groupby(['week_days']).mean() \n# > Monday purchased products mean are the most expensive one","1bd1917b":"# Creating a list to sort the days of the week on specific order\norderList = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n\n# Plotting Total sales per days of the week per gender\nbox_P = sns.boxplot(\ndata = ds,\n    x = 'week_days',\n    y = 'Total',\n    hue = 'Gender',\n    order= orderList\n).set(title='Total sales per days of the week per gender')\n\nplt.yticks(list(range(0 , 1100 , 100))) # Changing Y axis value for a better reading\n\n# Changing size display\nsns.set(rc = {'figure.figsize':(15,10)})\n","b515ebb6":"#Plotting Total spend value per product type per Gender\nbar_P = sns.barplot(\ndata = ds,\nx = 'Product line' ,\ny =  'Total' ,\nhue = 'Gender'\n).set(title='Total spend value per product type per Gender')\n\nplt.yticks(list(range(0 , 550 , 50))) # Changing Y axis value for a better reading\n\n# Changing size display\nsns.set(rc = {'figure.figsize':(12,6)})","9e58523a":"# Grouping per date\ngrp_date = ds.groupby(['Date']).sum() \ngrp_date\n\n# Ploting time series Total sales per day\nline_P = sns.lineplot(\ndata = grp_date, \nx = 'Date',\ny = 'Total'\n)\n\nline_P.set(title='Total sales per day') #Set title\n\nplt.xticks(pd.date_range(start=\"2019-01-01\",end=\"2019-04-01\", periods=16)) # Changing X axis ticks per weeks\nplt.yticks(list(range(0 , 8000 , 500 ))) # Changing Y axis value for a better reading\n\n# Changing size display and police\nsns.set(rc = {'figure.figsize':(30,11)})\nsns.set(font_scale = 1.6)\n\n# > Some specific days may impact the business, only market intel could help on the understanding. No specific seasonality here","db8859af":"# Creating a Facet grid of distribution quantity per product type per gender\nFacetG_P = sns.FacetGrid(ds, row=\"Gender\",  col=\"Product line\", height=10)\nFacetG_P.map(sns.distplot, \"Quantity\")\n\n# Changing size display\nsns.set(rc = {'figure.figsize':(30,30)})\nsns.set(font_scale = 1.8)\n\nimport warnings # Removing display of warning histograms\nwarnings.filterwarnings('ignore')\n\n# > the purspose is to find any informations regarding quantity of purchase. Female tend to buy more quantities on electronics, home and food\n# > while Male are buying strongly several small quantities on Fashion\n","b2fc679b":"# Find any correlation\ncorrelations = ds.corr()\nsns.heatmap(correlations)\n\n\nsns.set(rc = {'figure.figsize':(5,5)})\n# > No none obvious correlations","3063203c":"# Searching any link between Unit price and rating\nreg_P = sns.regplot(\ndata= ds,\nx = 'Rating',\ny = 'Unit price',\n)\n\nsns.set(rc = {'figure.figsize':(5,5)})\n\n# > No link","3a85175c":"import mpl_toolkits\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\n\n","f1413a26":"\"\"\"\n> Transform categorical columns into values (OneHotEncoder)\n> Drop useless columns\n> Define Train\/test split\n> Define model (regression\/trees\/DL lstm time series\/ARIMA)\n> Train model + accuracy + normalization\n> Test model\n> KPIs  & metrics\n> Predict sales on next futur months \n> Visualize sales\n\"\"\"","d89ba2b1":"# Analysis","341926e9":"## **Supermarket_sales analysis**","b9edbdeb":"# ML Implementation TBC","be9b0f0a":"# Discovering points\n\n- No 'null' values, 1K count with 1K unique ID\n- 3 different city with Yangon as mode\n- Balance part of Gender frequence , close to 50%\n- 'Fashion accessories' are the most frequent type purchased VS 'Health and beauty' the least one\n- 'Ewallet' (and cash) are the most used payment method\n- 7pm+ is the most 'purchasing moment'\n- Saturday it the most frequent day of purchase\n\n- The gross margin percentage is the same for all products, the tax = margin = 5% constant\n- The higher cost is a fashion accessories product \/ the lowest is a sport and travel product\n- The average rating is close to 7 over 10 > it would be good to have comments specially on lowest ones\n- In average, 5.5 product are sold per customer\n","4b6cbc02":"In total value, we can see a clear gap where:\n- Female spend more in Home and lifestyle & Food and Beverages\n- Maybe surprisingly Male spend more in Health & Beauty\n\n> Market Intel required to explain those figures ","cc699577":"With this graph we can noticed a different volume of purchase from gender behaviour.\nThe median during the week are balanced, but during the weekend (on Friday and Sunday) we can see a strong gap where Female tend to spend more than male.\nTuesday and Friday looks to have a strong STD where the 3rd quartile of Female are above other values. \n\n> Events on specific days of the week ? Seasonality ?"}}