{"cell_type":{"5b0be8ec":"code","cf67633c":"code","59d3417b":"code","1f1e39ef":"code","94ec1fbd":"code","ad0659b8":"code","e21e3e5c":"code","72886a1f":"code","5512b10e":"code","8f059d88":"code","57b2bfc7":"code","d5037527":"code","3f544bb5":"code","3652804f":"code","a13bff6a":"code","88102b83":"code","c47cbd33":"code","9c4436c9":"code","8899f38f":"code","a8664607":"code","fc0be269":"code","e841c515":"code","dd46a505":"code","07166547":"code","2ed37c23":"code","cbb58cad":"code","30091056":"code","d9d793bc":"code","4edb487c":"code","21b56467":"code","4fa65c19":"code","e34c6f5d":"code","ceb874f7":"code","ce573d2e":"code","1a87409d":"code","cbf14fb3":"code","930f8263":"code","af9dfa54":"code","94a25718":"code","745e9eab":"code","2541c1c2":"markdown","8f37d2ac":"markdown","464424b2":"markdown","40dd0f36":"markdown","787240d9":"markdown","973f77e3":"markdown","571256a5":"markdown","e2e43649":"markdown","9b2e4a86":"markdown","caddf191":"markdown","634a657a":"markdown","c23c23bd":"markdown","ba7aa72b":"markdown","d3b82100":"markdown","a7acc332":"markdown","919dc057":"markdown","aeacad13":"markdown","78a06880":"markdown","3cdbe798":"markdown"},"source":{"5b0be8ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf67633c":"import pandas as pd\nimport numpy as np\ndata =  pd.read_csv(\"..\/input\/pump-sensor-data\/sensor.csv\")","59d3417b":"data.head()","1f1e39ef":"data.drop(['Unnamed: 0', 'timestamp'],axis=1, inplace=True)","94ec1fbd":"data.head()","ad0659b8":"data.isna().sum()","e21e3e5c":"data.drop(['sensor_00','sensor_15','sensor_50','sensor_51'],axis=1, inplace=True)","72886a1f":"possible_machine_states = list(data.machine_status.unique())","5512b10e":"possible_machine_states","8f059d88":"data.isna().sum()","57b2bfc7":"fill_value = -1.0\ndata_with_gaps_filled = data.fillna( fill_value )","d5037527":"data_with_gaps_filled.isna().sum()","3f544bb5":"sensordata_cols_only = data_with_gaps_filled.iloc[:,0:48]","3652804f":"sensordata_cols_only","a13bff6a":"nr_rows_total = data.shape[0]","88102b83":"from sklearn.preprocessing import MinMaxScaler\n\n\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nscaled_sensor_data = scaler.fit_transform(sensordata_cols_only)","c47cbd33":"scaled_sensor_data","9c4436c9":"window_width_input_minutes = 60\nwindow_width_output_minutes = 60*24\nnr_examples_to_prepare = 2000","8899f38f":"start_minute = 0\na_single_input_window = scaled_sensor_data[start_minute:start_minute+window_width_input_minutes]","a8664607":"a_single_input_vector = a_single_input_window.flatten()","fc0be269":"a_single_input_vector.shape","e841c515":"def check_for_pump_failure(start, stop):\n    \n    \n    for minute in range(start,stop):\n        # get the corresponding row from the data\n        machine_state_in_this_minute = data[\"machine_status\"].iloc[minute]\n        if machine_state_in_this_minute in [\"BROKEN\", \"RECOVERING\"]:\n            return 1\n    \n    return 0","dd46a505":"data_status_BROKEN = data[ data[\"machine_status\"] == \"BROKEN\" ]","07166547":"data_status_BROKEN","2ed37c23":"check_for_pump_failure(17000,17200)","cbb58cad":"\nmax_row_nr = nr_rows_total-window_width_input_minutes-window_width_output_minutes\n\n\ntraining_pairs = []\nfor example_nr in range(0,nr_examples_to_prepare):\n    \n \n    if example_nr % 100 == 0:\n        print(\"Collected examples so far:\", example_nr)\n    \n  \n    found_example_where_pump_worked_in_input_window = False\n    while not found_example_where_pump_worked_in_input_window:\n    \n        rnd_minute = np.random.randint(0,max_row_nr)\n        \n\n        start = rnd_minute\n        stop  = start+window_width_input_minutes\n        if check_for_pump_failure(start,stop)==0:\n            found_example_where_pump_worked_in_input_window = True\n            \n    \n \n    a_single_input_window = scaled_sensor_data[rnd_minute:rnd_minute+window_width_input_minutes]\n    a_single_input_vector = a_single_input_window.flatten()\n    \n\n    start = rnd_minute+window_width_input_minutes\n    stop  = rnd_minute+window_width_input_minutes+window_width_output_minutes\n    output_value = check_for_pump_failure(start,stop)\n    \n   \n    training_pairs.append( (a_single_input_vector, output_value) )","30091056":"len(training_pairs)","d9d793bc":"input_vec_len = training_pairs[0][0].shape[0]\noutput_vec_len = 1\n\n\nD = np.zeros( (nr_examples_to_prepare, input_vec_len+output_vec_len))\nprint(\"Shape of D is\", D.shape)\n\n\nfor nr in range(0,nr_examples_to_prepare):\n    (x,y) = training_pairs[nr]\n    D[nr,0:input_vec_len] = x\n    D[nr,input_vec_len]   = y","4edb487c":"nr_train_samples = int(nr_examples_to_prepare\/2)\nx_train = D[0:nr_train_samples, 0:input_vec_len]\ny_train = D[0:nr_train_samples, input_vec_len]","21b56467":"x_test = D[nr_train_samples:, 0:input_vec_len]\ny_test = D[nr_train_samples:, input_vec_len]","4fa65c19":"print(\"Enter number of layers for 1'st layer\")\nx=int(input())\nprint(\"Enter number of layers for 2'nd layer\")\ny=int(input())\nprint(\"Enter number of layers for 3'rd layer\")\nz=x=int(input())","e34c6f5d":"import tensorflow as tf\nfrom tensorflow.keras import layers\nmodel = tf.keras.Sequential()\nmodel.add(layers.Dense(x, activation='relu', input_shape=(input_vec_len,)) )\nmodel.add(layers.Dense(y, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(layers.Dense(z, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(layers.Dense(1))\n\nmodel.compile(optimizer='sgd',               \n              loss=tf.keras.losses.MeanSquaredError(),\n              metrics=['accuracy'])\n\nmodel.build()","ceb874f7":"model.summary()","ce573d2e":"history = model.fit(x_train, y_train, epochs=600)","1a87409d":"import matplotlib.pyplot as plt","cbf14fb3":"plt.plot(history.history[\"loss\"])\nplt.show()","930f8263":"preds = model.predict(x_test)","af9dfa54":"pump_failure_in_future_window = 0\ncorrectly_predicted_pump_failures = 0\ncorrectly_predicted = 0\nnr_test_samples = preds.shape[0]\n\ntp = 0\ntn = 0\nfp = 0\nfn = 0\n\nfor test_nr in range(0,nr_test_samples):\n    ground_truth_output = y_test[test_nr]\n    if preds[test_nr] < 0.5:\n        predicted_output = 0.0\n    else:\n        predicted_output = 1.0\n    print(\"Test example #{0}: ground truth vs. predicted machine status: {1} vs. {2}\"\n          .format(test_nr, ground_truth_output, predicted_output ))\n    \n    if predicted_output == ground_truth_output:\n        correctly_predicted +=1\n        \n    if ground_truth_output==1:\n        pump_failure_in_future_window += 1\n        if predicted_output == ground_truth_output:\n            correctly_predicted_pump_failures +=1\n            \n    if ground_truth_output==1:\n        if predicted_output == ground_truth_output:\n           \n            tp+=1\n        else:\n           \n            fn+=1\n            \n    if ground_truth_output==0:        \n        if predicted_output == ground_truth_output:\n           \n            tn+=1\n        else:\n           \n            fp+=1\n            \n        \ncorrect_classification_percent = (correctly_predicted\/nr_test_samples)*100.0\nprint(\"\\nCorrectly predicted {0} of {1} test examples --> {2}%\"\n      .format(correctly_predicted, nr_test_samples, correct_classification_percent))\n\nprint(\"\\nIf there was really a pump failure in the future window,\\n\"\n      \"the MLP could predict it in {0} of the {1} pump failure (in future window) example cases.\"\n      .format(correctly_predicted_pump_failures, pump_failure_in_future_window))\n\nprint(\"True positive:\", tp)\nprint(\"True negative:\", tn)\nprint(\"False positive:\", fp)\nprint(\"False negative:\", fn)","94a25718":"precision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\nprint(\"Precision: {0:.2f}\".format(precision))\nprint(\"Recall   : {0:.2f}\".format(recall))","745e9eab":"print(\"The machine status can be predicted with an accuracy of {0}%\".format(correct_classification_percent)) ","2541c1c2":"## Part 2 ) Seperate Data for Train&Test","8f37d2ac":"### We can fill values with a negative integer","464424b2":"# Part 0) Load Data & Import Main Libraries","40dd0f36":"### machine_status is a string object","787240d9":"## Now we will keep machine_status type but we will copy our sensor data to the another dataframe","973f77e3":"### After drop operation, let's check NaN values again","571256a5":"## We created 3 layer and 1 activation layer. We created a menu for change number of cells in each layer because of reaching optimal performance","e2e43649":"## 3)Creating Model","9b2e4a86":"## Now, with minmax scaler from sklearn library we will scale our values between 0 and 1","caddf191":"## Now we created a function for checking pump's failure. If it is BROKEN it is broken obviously but if it is RECOVERING stage it means it was BROKEN so we will consider these two statement as one statement","634a657a":"### Now Lets Check is our function working properly or not ?","c23c23bd":"### When we compare with other labels,sensor_00,sensor_15,sensor_50 and sensor_51 has much more NaN values. We have to get rid of them","ba7aa72b":"### We can eliminate it from original dataset or we can use it like a enumartaion. We chosed second way","d3b82100":"### As seen at isna.sum() there are lot of NaN values in this dataset. This is a problem for machine learning algorithm.","a7acc332":"## Part 1 ) Modify Data","919dc057":"## We added dropouts to prevent over-fittings","aeacad13":"## On this data we can see several problems when first seen. 'Unnamed: 0' label is keeping ID's only it is not useful for our machine learning algorithm and also 'machine_status' is a string. For our \"shutdown prediction\" algorith it has to be in dataset but it has to be also numerical value.'timestamp' label will not be used in our algorith","78a06880":"at rar 17155 it is broken","3cdbe798":"## Now we should go deeper. We checked blank(NaN) values"}}