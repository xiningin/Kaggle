{"cell_type":{"cbfa2266":"code","044b1ff6":"code","4973d3bd":"code","7414bffe":"code","1de09257":"code","d709a84a":"code","b21e6e2b":"code","82636b72":"code","8551b6b9":"code","1b755b06":"code","941c8887":"code","efeb1248":"code","327f6adf":"code","d0b2303f":"code","b5b57abe":"code","0d4da76c":"code","330f93d6":"code","e73add65":"code","2d9881ff":"code","635f6362":"code","01059a30":"code","e9f47d33":"code","79733096":"code","b83401d8":"code","648aaeff":"code","6dc45b29":"code","88b28c23":"code","850fe122":"code","753a10e1":"code","f6a4ad52":"code","44a8b2e1":"code","a3c0643f":"code","58ccd470":"code","c6750c7c":"code","5264fea0":"code","c06ff0d2":"markdown","8368707e":"markdown","7375706a":"markdown","aa8d4619":"markdown","685cc5b6":"markdown","dc442ba0":"markdown","e3fcee9f":"markdown","f6b5986d":"markdown","1dd482f9":"markdown","276d207b":"markdown","2346dcb5":"markdown","797462ba":"markdown","82da95e2":"markdown","3b8c5ef5":"markdown","4fdc2908":"markdown","5e19b33b":"markdown","587209de":"markdown","a21c6d77":"markdown","c59bfe46":"markdown","cb52653e":"markdown","07a1c5dd":"markdown","68696d01":"markdown"},"source":{"cbfa2266":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","044b1ff6":"train=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nsubmission= pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","4973d3bd":"# Let's take preview on train datas \ntrain.head()","7414bffe":"# Now, we will give preview on test datas\ntest.head()","1de09257":"# Let's give some statstics on the train datas \ntrain.describe()","d709a84a":"# Hereunder, we will give general informations about train datas.\ntrain.info()","b21e6e2b":"# We will do the same work for test datas.\n# We start by showing some statstics about the test datas.\ntest.describe()","82636b72":"# Then , we show some general informations about the test datas .\ntest.info()","8551b6b9":"xtr=train.iloc[:,1:].to_numpy() # extract train pixels datas .\nxts=test.to_numpy()             # extract test pixels datas.\nYtr=train.iloc[:,0].to_numpy()  # extract train label datas.","1b755b06":"Xtr=xtr.reshape(xtr.shape[0],28,28) # reshape the train pixels datas accordingly to the origin image size.\nXts=xts.reshape(xts.shape[0],28,28) # reshape the test pixels datas accordingly to the origin image size.","941c8887":"import matplotlib.pyplot as plt \nmeanprops={\"marker\":\"o\",\"markeredgecolor\":\"black\",\"markeredgecolor\":\"firebrick\"}\nmedianprops={'color':'black'}","efeb1248":"plt.subplot(211)\nplt.boxplot([xtr,xts],labels=['training pixels','test pixels'],meanprops=meanprops,\\\n            medianprops=medianprops,showfliers=True,showmeans=True,patch_artist=True,vert=False)\nplt.subplot(212)\nplt.boxplot([Ytr.flatten()],labels=['labels training datas'],showfliers=True,showmeans=True,meanprops=meanprops,\\\n           medianprops=medianprops,patch_artist=True,vert=False)\nplt.show()","327f6adf":"# we choice randomly 5 observations from our training dataset to compare the handwritten digit to his \n# correspond label .\nimport random \nsamples=random.sample(range(xtr.shape[0]+1),5)\nj=0\nfor i in samples :\n    j=j+1\n    plt.subplot(150+j)\n    plt.imshow(Xtr[i],cmap=plt.get_cmap('gray'))\n    plt.title(Ytr[i])\nplt.show()","d0b2303f":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split","b5b57abe":"# prepare datas\nxxtr,xxts,ytr,yts=train_test_split(xtr,Ytr,test_size=0.1)","0d4da76c":"# Implement svm estimator .\nestimator= SVC()","330f93d6":"# Training the SVM estimator .\nestimator.fit(xxtr,ytr)","e73add65":"sc=estimator.score(xxts,yts)\nprint(\"The estimated score of the SVM method is : {}\".format(sc))","2d9881ff":"submission['Label']=estimator.predict(xts)","635f6362":"submission.to_csv('svm.csv',index='False')","01059a30":"from keras.layers import Dense , Flatten \nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical","e9f47d33":"Xtr=Xtr.reshape(Xtr.shape[0],Xtr.shape[1],Xtr.shape[2],1)\nXts=Xts.reshape(Xts.shape[0],Xts.shape[1],Xts.shape[2],1)","79733096":"Ytr=to_categorical(Ytr)","b83401d8":"dtgen=ImageDataGenerator()","648aaeff":"X_train,X_val,Y_train,Y_val=train_test_split(Xtr,Ytr,test_size=0.1)\n","6dc45b29":"training=dtgen.flow(X_train,Y_train,batch_size=32)\nvalidation=dtgen.flow(X_val,Y_val,batch_size=32)","88b28c23":"NN=Sequential()\n# Add input layer\nNN.add(Dense(128,input_shape=(28,28,1),activation='relu'))\nNN.add(Flatten())\n\n# Add Hidden layers \nNN.add(Dense(256,activation='relu'))\nNN.add(Dense(256,activation='relu'))\n\n# output layer.\n\nNN.add(Dense(10,activation='softmax'))","850fe122":"# Compile the neural network \nNN.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","753a10e1":"# Training the DNN.\nhistory=NN.fit_generator(generator=training,steps_per_epoch=training.n,epochs=3,validation_data=validation,\\\n                validation_steps=validation.n)","f6a4ad52":"ht=history.history\nht.keys()","44a8b2e1":"epochs=range(1,len(ht['loss'])+1)\nplt.plot(epochs,ht['loss'],'bo')\nplt.plot(epochs,ht['val_loss'],'b+')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","a3c0643f":"plt.plot(epochs,ht['accuracy'],'bo')\nplt.plot(epochs,ht['val_accuracy'],'b+')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.show()","58ccd470":"submission1=pd.DataFrame({'ImageId':submission['ImageId']})","c6750c7c":"submission1.insert(1,'Label',NN.predict_classes(Xts),True)","5264fea0":"submission1.to_csv('dnn.csv',index=False)","c06ff0d2":"# Visualization :","8368707e":"# Importing data:","7375706a":"### 3.Implement Deep Neural Network (DNN):","aa8d4619":"### 2. Preprocessing datas:","685cc5b6":"# Neural network Classifier:","dc442ba0":"### 6.Predict the test handwritten digits labels","e3fcee9f":"### 1. Import required librairies :","f6b5986d":"To check if there is outliers in our dataset , we will create the boxeplot of the pixels values which should have values between 0 and 255 . Moreover , we will check the values of training labels, which should have values between 0 and 9. ","1dd482f9":"### 5. Results analyse :","276d207b":"**The above brief analyse, show that our datas don't encompasse missing values.**","2346dcb5":"# Preprocessing datas:","797462ba":"**The box plot above show that neither the pixel datas nor the labels trainig data encompasse outliers.**","82da95e2":"# Preliminary work :","3b8c5ef5":"### 2.Split datas and implement SVM:","4fdc2908":"### 1. Import required librairies :","5e19b33b":"# Outliers:","587209de":"### Contents :\n1. Import required librairies .\n2. Split datas & Implement SVM.\n3. Compute the estimated score of the svm estimator .\n4. Predict the test handwritten digits labels.","a21c6d77":"# SVM Classifier:","c59bfe46":"### 4. Train & test the DNN :","cb52653e":"### 4. Predict the test handwritten digits labels:","07a1c5dd":"### 3. Compute the estimated score of the svm estimator:","68696d01":"### Contents:\n1. Import required librairies.\n2. Preprocessing datas.\n3. Implement Deep Neural Network.\n4. Train & test the DNN.\n5. Results analyse\n6. Predict the test handwritten digits labels."}}