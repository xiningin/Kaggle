{"cell_type":{"0265b505":"code","12bc2a05":"code","9cfe17b9":"code","5b28ac14":"code","17794859":"code","13531667":"code","60685f5a":"code","7ee76ecf":"code","9838626b":"code","2b2ae062":"code","08de765c":"code","2378ea39":"code","6f964ce6":"code","5e335e55":"code","cda05072":"markdown","76050fae":"markdown","2de98914":"markdown","0690916f":"markdown"},"source":{"0265b505":"#declare headers\nimport pandas as pd\nimport numpy as np\nfrom keras import models\n# convert to one-hot-encoding\nfrom keras.utils.np_utils import to_categorical \nfrom keras import layers\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n","12bc2a05":"# Load the Test data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\nprint(\"Train dataset shape\",train.shape)\nY_train = train[\"label\"]\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1)","9cfe17b9":"# Load the Test data\ntest = pd.read_csv(\"..\/input\/test.csv\")\nprint(\"Test dataset shape\",test.shape)\ntest.head()","5b28ac14":"# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\n\n# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n","17794859":"print(\"Train image shape after reshaping:\",X_train.shape)\nprint(\"Test image shape after reshaping:\",test.shape)","13531667":"# Encode labels to one hot vectors (ex : 3 -> [0,0,1,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)","60685f5a":"# Some examples\ng = plt.imshow(X_train[7][:,:,0])\n","7ee76ecf":"# Define model architecture\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n\nmodel.add(layers.Flatten())\n#6. Add a fully connected layer and then the output layer model.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\n","9838626b":"#Summary of model\nmodel.summary()","2b2ae062":"#8. Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop',\nmetrics=[\"categorical_accuracy\"])","08de765c":"#9. Fit model on training data\nmodel.fit(X_train, Y_train,  batch_size=64, epochs=5, verbose=1)","2378ea39":"#Predicting the classes and display \nfor i in range(1,10) :\n    img1=test[i][:,:,0]\n    img1=image.img_to_array(img1)\n    img1.shape\n    tests1=img1.reshape((1,28,28,1))#in conv networks the should pe reshaped into 4d tensors\n    img_class=model.predict_classes(tests1)\n    prediction=img_class[0]\n    classname=img_class[0]\n    print(\" Predicted classname:\",classname)\n\n    #displaying the digit and classifying digit\n    img1=img1.reshape((28,28))\n    plt.imshow(img1)\n    plt.title(classname)\n    plt.show()","6f964ce6":"# predict results\nres = model.predict(test)\n\n# select the indix with the maximum probability\nres = np.argmax(res,axis = 1)\n\nres = pd.Series(res,name=\"Label\")","5e335e55":"#Submitting the predictions\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),res],axis = 1)\n\nsubmission.to_csv(\"predict_digit_class.csv\",index=False)","cda05072":"**PREPARING THE IMAGE BY RESHAPING**\n\nThe shape of the training images and testing images is changed, they were reshaped  into 4D array of (X_train[0], 28, 28, 1) and(X_train[0], 28, 28, 1) respectively for training images and testing images. And then normalized these images into [0, 1].\n","76050fae":"**IMPORT MODULES AND LIBRARIES**\n\nInitially all the required modules of keras were imported such as layers, models, mnist from keras datasets, metrics and image from keras preprocessing etc. And some other python libraries we also imported such as pyplot from matplotlib and numpy etc.\n\n","2de98914":"**INTRODUCTION**\n\nTarget detection and pattern detection is a very tedious task nowadays as the resolution and quality of images captured by cameras are improving day by day and a lot of pictures are taken by these devices. It is not feasible to manually detect or classify the images. Hence, high precision algorithms are required for extracting the features and classifying without any human intervention. This type of automatic classification saves time and reduces human effort. \n\nIn this work, a deep learning neural network known as Convolution Neural Network (CNN) is used for automatic classification of images. CNN gives good accuracy as they are based on the idea of preserving the spatial locality. The probability of network classification increases as the network becomes deeper. MNIST dataset containing gray-scale images of hand-written digits has been used for classifying.\n\n**WHY CONVOLUTIONAL NEURAL NETWORKS?**\n\nConvolutional neural networks (ConvNets) are based on the idea of preserving the spatial locality in images or any other form of information and the idea of learning via progressive levels of abstraction, therefore very well suited for classifying images.\n\n**MNIST dataset**\n\nMNIST dataset is a classic in the machine-learning community, which has been around almost as long as the field itself and has been intensively studied. It\u2019s a set of 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s. It contains grayscale images of handwritten digits (28 \u00d7 28) pixels. \n\n","0690916f":"**PREPARING THE LABELS **\n\nlabels are vectorized so that the output can be mapped and classified with required class of output. This is done by categorically encode the labels. One-hot encoding is a widely used format for categorical data, also called categorical. This is done by passing train and test labels as an attribute to to_categorical method. "}}