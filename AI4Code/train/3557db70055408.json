{"cell_type":{"38a2e2e1":"code","f265a9c0":"code","15ea9486":"code","44785d2d":"code","6ea12144":"code","0b711754":"code","8e0b99d8":"code","6165066b":"code","93354492":"code","1ee96d1f":"code","d6572e98":"code","760a8cb2":"code","25ce4cff":"code","1f668dff":"code","d55eab56":"code","e102876c":"code","d6ad2864":"code","1d8a4b4d":"code","02492831":"code","94823226":"code","85023270":"code","7f7fbba8":"code","93c7bc7e":"code","155f8b43":"code","af570783":"code","96a0aab1":"code","43ff653c":"code","d6ae062e":"code","496028b5":"code","a6cb8bd1":"code","cff7b67f":"code","a41cce1a":"code","4ca61035":"code","1381461e":"markdown","082a13f0":"markdown","1c2caaed":"markdown","9a560531":"markdown","f8326076":"markdown","807bf848":"markdown","50f8378e":"markdown","f2fd7261":"markdown","48e2afb8":"markdown","376755c7":"markdown","c6840fe6":"markdown","b5c8e0f1":"markdown","6d85596c":"markdown","4d71e8a7":"markdown","d9592fa9":"markdown","6915a5a7":"markdown","1f5de592":"markdown","82c74552":"markdown"},"source":{"38a2e2e1":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f265a9c0":"train = pd.read_csv('..\/input\/cat-in-the-dat\/train.csv', index_col='id')\ntest = pd.read_csv('..\/input\/cat-in-the-dat\/test.csv', index_col='id')","15ea9486":"train = train.drop('bin_0', axis=1)\ntest = test.drop('bin_0', axis=1)","44785d2d":"map_bin_3_4 = {'T': 1, 'F': 0, 'Y': 1, 'N': 0}\n\ntrain['bin_3'] = train['bin_3'].map(map_bin_3_4)\ntest['bin_3'] = test['bin_3'].map(map_bin_3_4)\n\ntrain['bin_4'] = train['bin_4'].map(map_bin_3_4)\ntest['bin_4'] = test['bin_4'].map(map_bin_3_4)","6ea12144":"train['ord_5_1'] = train['ord_5'].str[0]\ntrain['ord_5_2'] = train['ord_5'].str[1]\ntrain = train.drop('ord_5', axis=1)\n\ntest['ord_5_1'] = test['ord_5'].str[0]\ntest['ord_5_2'] = test['ord_5'].str[1]\ntest = test.drop('ord_5', axis=1)","0b711754":"train = train.drop('ord_5_2', axis=1)\ntest = test.drop('ord_5_2', axis=1)","8e0b99d8":"ord_1_values = ['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster']\n\nmap_ord_1 = lambda x: ord_1_values.index(x)\n\ntrain['ord_1'] = train['ord_1'].apply(map_ord_1)\ntest['ord_1'] = test['ord_1'].apply(map_ord_1)","6165066b":"ord_2_values = ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot']\n\nmap_ord_2 = lambda x: ord_2_values.index(x)\n\ntrain['ord_2'] = train['ord_2'].apply(map_ord_2)\ntest['ord_2'] = test['ord_2'].apply(map_ord_2)","93354492":"import string\n\n\nmap_to_ascii_index = lambda x: string.ascii_letters.index(x)\n\n# 'ord_5_2' dropped!\nfor column in ['ord_3', 'ord_4', 'ord_5_1']:\n    train[column] = train[column].apply(map_to_ascii_index)\n    test[column] = test[column].apply(map_to_ascii_index)","1ee96d1f":"# columns_to_test = list(test.columns)\n\ncolumns_to_test = ['nom_7', 'nom_8', 'nom_9']\n\nreplace_xor = lambda x: 'xor' if x in xor_values else x\n\nfor column in columns_to_test:\n    xor_values = set(train[column].unique()) ^ set(test[column].unique())\n    if xor_values:\n        print('Column', column, 'has', len(xor_values), 'XOR values')\n        train[column] = train[column].apply(replace_xor)\n        test[column] = test[column].apply(replace_xor)\n    else:\n        print('Column', column, 'has no XOR values')","d6572e98":"def get_infrequent_values(data, column, threshold):\n    value_counts = data[column].value_counts()\n    return list(value_counts[value_counts < threshold].index)","760a8cb2":"for column in train.columns:\n    n = len(get_infrequent_values(train, column, 3))\n    if n > 0:\n        print('Column', column, 'has', n, 'unique infrequent value(s)')","25ce4cff":"thresholds = {\n    # 'nom_7': 3,\n    # 'nom_8': 3,\n    'nom_9': 3\n}\n\nfor column in thresholds.keys():\n    values_to_replace = get_infrequent_values(train, column, thresholds[column])\n    \n    replace = lambda x: 'value' if x in values_to_replace else x\n    \n    train[column] = train[column].transform(replace)\n    test[column] = test[column].transform(replace)","1f668dff":"for column in thresholds.keys():\n    print(column, ':', train[column].value_counts()['value'], 'values replaced in train dataset')","d55eab56":"train.head().T","e102876c":"all_features = test.columns\n\nselected_features_for_thermometer = ['ord_1', 'ord_4', 'day', 'month', 'ord_5_1']\n\nselected_features_for_both = ['ord_2', 'ord_3']","d6ad2864":"y_train = train['target'].copy()\nx_train = train.drop('target', axis=1)\ndel train\n\nx_test = test.copy()\ndel test","1d8a4b4d":"from sklearn.base import BaseEstimator, TransformerMixin\n\n\n# This implementation supports numeric features only\nclass ThermometerEncoder(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, cols=None, drop_invariant=True):\n        self.cols = cols\n        self.drop_invariant = drop_invariant\n    \n    def get_params(self, deep=True):\n        return {'cols': self.cols, 'drop_invariant': self.drop_invariant}\n    \n    def set_params(self, **parameters):\n        for parameter, value in parameters.items():\n            setattr(self, parameter, value)\n        return self\n    \n    def fit(self, X, y=None):\n        self.bars = {}\n        for c in self.cols:\n            k = np.arange(X[c].max() + 1)\n            self.bars[c] = (k[:-1] < k.reshape(-1, 1)).astype(int)\n        return self\n    \n    def transform(self, X, y=None):\n        out = pd.DataFrame(index=X.index)\n        for c in self.cols:\n            out = out.join(self.transform_one(X, c))\n        \n        if self.drop_invariant:\n            columns_to_drop = []\n            for c in out.columns:\n                if len(out[c].unique()) == 1:\n                    columns_to_drop.append(c)\n            out = out.drop(columns_to_drop, axis=1)\n        \n        return out\n    \n    def transform_one(self, X, c):\n        bars = self.bars[c]\n        out = pd.DataFrame(index=X.index, data=bars[X[c]])\n        out.columns = [c + '_' + str(k) for k in range(bars.shape[1])]\n        return out","02492831":"train_part = len(x_train)\ntraintest = pd.concat([x_train, x_test])","94823226":"ohe_features = set(all_features) - set(selected_features_for_thermometer)","85023270":"ohe_traintest = pd.get_dummies(traintest[ohe_features], columns=ohe_features, drop_first=True, sparse=True).sparse.to_coo().tocsr()","7f7fbba8":"thermometer = ThermometerEncoder(selected_features_for_thermometer + selected_features_for_both)\nthermometer_traintest = thermometer.fit_transform(traintest)","93c7bc7e":"import scipy\n\n\nfinal_traintest = scipy.sparse.hstack([ohe_traintest, thermometer_traintest]).tocsr()","155f8b43":"final_x_train = final_traintest[:train_part]\nfinal_x_test  = final_traintest[train_part:]","af570783":"del x_train\ndel x_test","96a0aab1":"from sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom cross_validation_framework import *","43ff653c":"logit_param_grid = {\n    'C': [0.100, 0.150, 0.120, 0.125, 0.130, 0.135, 0.140, 0.145, 0.150]\n}\n\nlogit_grid = GridSearchCV(LogisticRegression(solver='lbfgs'), logit_param_grid,\n                          scoring='roc_auc', cv=5, n_jobs=-1, verbose=0)\nlogit_grid.fit(final_x_train, y_train)\n\nbest_C = logit_grid.best_params_['C']\n# best_C = C = 0.12345\n\nprint('Best C:', best_C)","d6ae062e":"logit = LogisticRegression(C=best_C, solver='lbfgs', max_iter=10000)\ncv = KFold(n_splits=10, random_state=42)\n_, trained_estimators = fit(ScikitLearnPredictProbaEstimator(logit), roc_auc_score, final_x_train, y_train, cv)\ny = predict(trained_estimators, final_x_test)","496028b5":"logit = LogisticRegression(C=0.123456789, solver=\"lbfgs\", max_iter=5000)\nlogit.fit(final_x_train, y_train)\ny_full_train = logit.predict_proba(final_x_test)[:, 1]","a6cb8bd1":"submission = pd.read_csv('..\/input\/cat-in-the-dat\/sample_submission.csv', index_col='id')\nsubmission['target'] = y\nsubmission.to_csv('logit.csv')","cff7b67f":"submission.head()","a41cce1a":"submission['target'] = y_full_train\nsubmission.to_csv('logit-full-train.csv')","4ca61035":"submission.head()","1381461e":"## Replace infrequent values with single value","082a13f0":"## Extract target variable","1c2caaed":"## Sort Ordinal Feature Values","9a560531":"## Submit predictions","f8326076":"## Logistic regression","807bf848":"# Top 10% (133th out of 1342) Solution","50f8378e":"### OHE","f2fd7261":"## Replace values that not presented in both train and test sets with single value","48e2afb8":"## Features","376755c7":"## Load data","c6840fe6":"### Set of models trained on folds","b5c8e0f1":"### Single model trained on full train set","6d85596c":"## Solution","4d71e8a7":"BTW: There is no reason replace 1 (or 2) infrequent values with 1 value","d9592fa9":"### Thermometer encoding","6915a5a7":"## Feature engineering","1f5de592":"## Acknowledgemnts\n\n- Original kernel: https:\/\/www.kaggle.com\/pavelvpster\/cat-in-dat-ohe-vs-thermometer-logit","82c74552":"## Thermometer encoder"}}