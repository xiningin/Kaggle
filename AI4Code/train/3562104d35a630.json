{"cell_type":{"75de0aeb":"code","b6469e60":"code","35e1d93c":"code","0f03c02d":"code","ec588fb8":"code","e09676b6":"code","2d64e97b":"code","063b804b":"code","bc54e03f":"code","b4e617df":"code","406f293b":"code","e1ee174e":"code","c134d9e8":"code","27e9c6d2":"code","9b06c334":"code","c0ed166c":"code","e6a40f14":"markdown"},"source":{"75de0aeb":"from keras.datasets.fashion_mnist import load_data\n# load the images into memory\n(trainX, trainy), (testX, testy) = load_data()\n# summarize the shape of the dataset\nprint('Train', trainX.shape, trainy.shape)\nprint('Test', testX.shape, testy.shape)","b6469e60":"# plot raw pixel data\nfrom matplotlib import pyplot\n# plot images from the training dataset\nfor i in range(100):\n\t# define subplot\n\tpyplot.subplot(10, 10, 1 + i)\n\t# turn off axis\n\tpyplot.axis('off')\n\t# plot raw pixel data\n\tpyplot.imshow(trainX[i], cmap='gray_r')\npyplot.show()","35e1d93c":"#training an unconditional gan on the fashion mnist dataset\nfrom numpy import expand_dims\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.datasets.fashion_mnist import load_data\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout","0f03c02d":"# define the standalone discriminator model\ndef define_discriminator(in_shape=(28,28,1)):\n\tmodel = Sequential()\n\t# downsample\n\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# downsample\n\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# classifier\n\tmodel.add(Flatten())\n\tmodel.add(Dropout(0.4))\n\tmodel.add(Dense(1, activation='sigmoid'))\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n\treturn model","ec588fb8":"# define the standalone generator model\ndef define_generator(latent_dim):\n\tmodel = Sequential()\n\t# foundation for 7x7 image\n\tn_nodes = 128 * 7 * 7\n\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\tmodel.add(Reshape((7, 7, 128)))\n\t# upsample to 14x14\n\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# upsample to 28x28\n\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# generate\n\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same'))\n\treturn model","e09676b6":"# define the combined generator and discriminator model, for updating the generator\ndef define_gan(generator, discriminator):\n\t# make weights in the discriminator not trainable\n\tdiscriminator.trainable = False\n\t# connect them\n\tmodel = Sequential()\n\t# add generator\n\tmodel.add(generator)\n\t# add the discriminator\n\tmodel.add(discriminator)\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n\treturn model\n","2d64e97b":"# load fashion mnist images\ndef load_real_samples():\n\t# load dataset\n\t(trainX, _), (_, _) = load_data()\n\t# expand to 3d, e.g. add channels\n\tX = expand_dims(trainX, axis=-1)\n\t# convert from ints to floats\n\tX = X.astype('float32')\n\t# scale from [0,255] to [-1,1]\n\tX = (X - 127.5) \/ 127.5\n\treturn X","063b804b":"# select real samples\ndef generate_real_samples(dataset, n_samples):\n\t# choose random instances\n\tix = randint(0, dataset.shape[0], n_samples)\n\t# select images\n\tX = dataset[ix]\n\t# generate class labels\n\ty = ones((n_samples, 1))\n\treturn X, y","bc54e03f":"# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n_samples):\n\t# generate points in the latent space\n\tx_input = randn(latent_dim * n_samples)\n\t# reshape into a batch of inputs for the network\n\tx_input = x_input.reshape(n_samples, latent_dim)\n\treturn x_input","b4e617df":"# use the generator to generate n fake examples, with class labels\ndef generate_fake_samples(generator, latent_dim, n_samples):\n\t# generate points in latent space\n\tx_input = generate_latent_points(latent_dim, n_samples)\n\t# predict outputs\n\tX = generator.predict(x_input)\n\t# create class labels\n\ty = zeros((n_samples, 1))\n\treturn X, y","406f293b":"# train the generator and discriminator\ndef train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=128):\n\tbat_per_epo = int(dataset.shape[0] \/ n_batch)\n\thalf_batch = int(n_batch \/ 2)\n\t# manually enumerate epochs\n\tfor i in range(n_epochs):\n\t\t# enumerate batches over the training set\n\t\tfor j in range(bat_per_epo):\n\t\t\t# get randomly selected 'real' samples\n\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n\t\t\t# update discriminator model weights\n\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n\t\t\t# generate 'fake' examples\n\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n\t\t\t# update discriminator model weights\n\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n\t\t\t# prepare points in latent space as input for the generator\n\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n\t\t\t# create inverted labels for the fake samples\n\t\t\ty_gan = ones((n_batch, 1))\n\t\t\t# update the generator via the discriminator's error\n\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n\t\t\t# summarize loss on this batch\n\t\t\tprint('>%d, %d\/%d, d1=%.3f, d2=%.3f g=%.3f' %\n\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n\t# save the generator model\n\tg_model.save('generator.h5')\n","e1ee174e":"# size of the latent space\nlatent_dim = 100\n# create the discriminator\ndiscriminator = define_discriminator()\n# create the generator\ngenerator = define_generator(latent_dim)\n# create the gan\ngan_model = define_gan(generator, discriminator)\n# load image data\ndataset = load_real_samples()\n# train model\ntrain(generator, discriminator, gan_model, dataset, latent_dim)\n","c134d9e8":"from keras.models import load_model\nfrom numpy.random import randn\nfrom matplotlib import pyplot","27e9c6d2":"# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n_samples):\n\t# generate points in the latent space\n\tx_input = randn(latent_dim * n_samples)\n\t# reshape into a batch of inputs for the network\n\tx_input = x_input.reshape(n_samples, latent_dim)\n\treturn x_input","9b06c334":"# create and save a plot of generated images (reversed grayscale)\ndef show_plot(examples, n):\n\t# plot images\n\tfor i in range(n * n):\n\t\t# define subplot\n\t\tpyplot.subplot(n, n, 1 + i)\n\t\t# turn off axis\n\t\tpyplot.axis('off')\n\t\t# plot raw pixel data\n\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n\tpyplot.show()","c0ed166c":"# load model\nmodel = load_model('generator.h5')\n# generate images\nlatent_points = generate_latent_points(100, 100)\n# generate images\nX = model.predict(latent_points)\n# plot the result\nshow_plot(X, 10)","e6a40f14":"# Construct a GAN model which can learn to generate fake images for MNIST fashion dataset"}}