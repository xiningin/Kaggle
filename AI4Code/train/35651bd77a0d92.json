{"cell_type":{"cae332a7":"code","4ecf6860":"code","c9d25e0b":"code","dba78aa7":"code","5d4a0b09":"code","3bea25f9":"code","bd61ff18":"code","7711bf08":"code","21953032":"code","1d8c5b0f":"code","e018c82a":"code","cca0359d":"code","753f36bd":"code","9d98f569":"code","ef162f12":"code","3dce0a84":"code","459ec47b":"code","8539db29":"code","3513f3be":"code","e166b524":"code","9dc78718":"code","d176f684":"code","998ff71b":"code","ec9ab2c7":"code","0222ae76":"code","43fae4f3":"code","5ec66cee":"code","31afb352":"code","7e00e543":"code","ca215bd4":"code","f3f9c0ab":"code","caa61ace":"code","083a58b3":"code","d13b2387":"markdown","065ca983":"markdown","346bc8c7":"markdown","663efb3d":"markdown","2d5206d2":"markdown","d2c1d512":"markdown","abad9462":"markdown","57eb5984":"markdown","c0ff82f1":"markdown","23905f67":"markdown","5a091364":"markdown","858a1bcd":"markdown","edeb363b":"markdown","c71f3008":"markdown","83f36336":"markdown","628da327":"markdown"},"source":{"cae332a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as dates\nfrom datetime import datetime\nimport seaborn as sns\n\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ecf6860":"# oct data as example\ndf = pd.read_csv(\"\/kaggle\/input\/ecommerce-events-history-in-cosmetics-shop\/2019-Oct.csv\")\ndf.head()","c9d25e0b":"df.info()","dba78aa7":"# event counts of each consumer\ndf['user_id'].value_counts()","5d4a0b09":"df.isnull().mean()","3bea25f9":"# Format date, week and time column\ndf['date'] = df['event_time'].apply(lambda r: datetime.strptime(str(r)[:10], '%Y-%m-%d'))\ndf['timepoint'] = df['event_time'].apply(lambda r: datetime.strptime(str(r)[11:19], '%H:%M:%S').time())\ndf['week'] = df['date'].apply(lambda d: (d.day-1) \/\/ 7 + 1)","bd61ff18":"df.drop(df[df.price < 0].index, inplace=True)","7711bf08":"df.drop_duplicates(inplace = True)","21953032":"df.head()","1d8c5b0f":"user_cnt_ax = df[df.event_type == \"purchase\"].groupby(['date'])['price'].agg(Dialy_sale = ('sum')).sort_values(by=['date'], ascending=True).plot.line()\nuser_cnt_ax.set_ylabel = \"sale amount\"","e018c82a":"user_cnt_ax = df.groupby(['date'])['user_id'].agg(User_daily_count =('nunique')).sort_values(by=['date'], ascending=True).plot.line()\nuser_cnt_ax.set_ylabel = \"user count\"","cca0359d":"labels = ['view', 'cart', 'remove_from_cart','purchase']\ncolors = ['red', 'blue','green', 'orange']\nplt.pie(df['event_type'].value_counts(), labels = labels, colors = colors, autopct = '%.2f%%')","753f36bd":"# daily conversion rate\nevent_type_ax = df.groupby(['date'])['event_type'].value_counts(['event_type']).unstack(level = -1).plot.line()\nevent_type_ax.legend(loc='best')","9d98f569":"# monthly covnersion rate\nlen(df[df['event_type'] == \"purchase\"]['user_id'].unique())\/len(df.user_id.unique())","ef162f12":"week_user_list = df.groupby(['week'])['user_id'].unique().to_list()\nretention_list = [len(list(set(i)&set(j)))\/len(list(i)) for i, j in zip(week_user_list[:5], week_user_list[1:])]\nplt.bar(np.arange(4), retention_list, width = 0.5)\nplt.ylabel(\"Weekly retention rate\")\nplt.xticks(np.arange(4), [\"week1-2\", \"week2-3\", \"week3-4\", \"week4-5\"])\nplt.title(\"October weekly retention rate \")","3dce0a84":"# number of days each participant show up in the given month\nid_daycount = df.groupby(['user_id'])['date'].agg(montly_online_daycnt =('nunique')).sort_values(by=['montly_online_daycnt'])\nid_daycount['montly_online_daycnt'].value_counts().plot(kind='bar')","459ec47b":"# event number of each participant\nid_sessioncount = df.groupby(['user_id'])['user_session'].agg(monthly_sessioncnt = ('nunique')).sort_values(by=['monthly_sessioncnt'])\nid_sessioncount['monthly_sessioncnt'].value_counts(bins=20)","8539db29":"id_totalprice = df[df['event_type'].str.contains('purchase')].groupby(['user_id'])['price'].agg(monthly_totalprice = ('sum')).sort_values(by=['monthly_totalprice'])\nid_totalprice['monthly_totalprice'].value_counts(bins=20).plot(kind='bar')","3513f3be":"# concatenate three dataframe\nactiveuser_df = pd.concat([id_sessioncount, id_daycount, id_totalprice], axis=1)\nactiveuser_df['monthly_totalprice'].fillna(0, inplace = True)","e166b524":"behavior_df = df.groupby(['user_id', 'event_type']).size().unstack(fill_value=0)\nprice_df = df[df['event_type'].str.contains('purchase')].groupby(['user_id'])['price'].agg('sum')\nbehavior_df = behavior_df.merge(price_df, how = 'left', on = 'user_id')\nbehavior_df['price'].fillna(0, inplace = True)","9dc78718":"# calculate the three rates\nbehavior_df['month_purchaseview_rate'] = behavior_df.purchase.div(behavior_df.view.replace(0, np.nan))\nbehavior_df['month_pricepurchase_rate'] = behavior_df.price.div(behavior_df.purchase.replace(0, np.nan))\nbehavior_df['month_purchasecart_rate'] = behavior_df.purchase.div(behavior_df.cart.replace(0, np.nan))","d176f684":"# drop nan rows based on the predefined three rates\nbehavior_df = behavior_df.dropna(subset=['month_purchaseview_rate', 'month_pricepurchase_rate', 'month_purchasecart_rate'])","998ff71b":"# get the behavior feature at freq and rate level \nbehavior_rate_df = behavior_df[['month_purchaseview_rate', 'month_pricepurchase_rate', 'month_purchasecart_rate']]\nbehavior_freq_df = behavior_df[['purchase', 'view', 'price']]","ec9ab2c7":"freq_boxplot = behavior_df.boxplot(rot=45, fontsize=10, column = ['cart', 'purchase', 'remove_from_cart', 'view'])\nfreq_boxplot.set_title('Behavior frequency boxplot')","0222ae76":"rate_boxplot = behavior_df.boxplot(rot=45, fontsize=10, column = ['month_purchaseview_rate', 'month_pricepurchase_rate', 'month_purchasecart_rate'] )\nrate_boxplot.set_title('Behavior rate boxplot')","43fae4f3":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans","5ec66cee":"# standardize the data before finding the k optimal value\nX_activeuser = StandardScaler().fit_transform(activeuser_df)\nX_freq_behavior = StandardScaler().fit_transform(behavior_freq_df)\nX_rate_behavior = StandardScaler().fit_transform(behavior_rate_df)","31afb352":"for j, XX in enumerate([X_freq_behavior, X_rate_behavior]): #X_freq_behavior, X_rate_behavior\n    SSE=[]\n    for i in range(1,9,1):\n        kmeans=KMeans(n_clusters=i)\n        kmeans.fit(XX)\n        SSE.append(kmeans.inertia_)\n    sns.set()\n    plt.plot(range(1,9,1),SSE,marker='o', label = j)\nplt.xlabel('k')\nplt.ylabel('SE')\nplt.legend()","7e00e543":"import random\nfrom mpl_toolkits.mplot3d import Axes3D\nimport plotly.graph_objs as go\ndef k_mean_cluster(df, n_cluster, figsize = (6, 6)):\n    '''\n    Assign and visualize the cluster to given X\n    :param: \n        df is dataframe\n        n_cluster \n        \n\n\n    ''' \n    # Check X validity\n    assert len(df.columns) == 3, \"Should be three features\"\n    X = df.copy()\n    \n    random.seed(7)\n    km = KMeans(n_clusters=n_cluster, \n                init = \"k-means++\", \n                max_iter = 300, \n                n_init = 10, \n                random_state=0)\n    X_standard = StandardScaler().fit_transform(X)\n    km.fit(X_standard)\n    y_pred = km.predict(X_standard)\n    X['y_pred'] = list(y_pred)\n    \n    feat_columns = df.columns\n    COLORS = sns.color_palette(\"tab10\")[:n_cluster]\n    \n    \n    # draw cluster mean statistics and scatter plot\n    \n    \n    sns.countplot(x = 'y_pred', palette = COLORS, data = X)\n#     sns.scatterplot(x=feat_columns[0],\n#                     y=feat_columns[1],\n#                     hue = 'y_pred',\n#                     size=feat_columns[2],\n#                     palette=mycolors,sizes=(200,1000), \n#                     legend=False,\n#                     data=df_RFM3)\n\n    fig = plt.figure(figsize = figsize)\n    ax=Axes3D(fig)\n    for k in range(n_cluster):\n        # index of cluster k, correspinding feature value, 0, 1, 2\n        ax.scatter(X.loc[X.y_pred == k, feat_columns[0]], \n                   X.loc[X.y_pred == k, feat_columns[1]],\n                   X.loc[X.y_pred == k, feat_columns[2]], \n                   marker='o', alpha=0.5, color = COLORS[k], label = f\"cluster {k}\")\n    \n    ax.set_xlabel(feat_columns[0])\n    ax.set_ylabel(feat_columns[1])\n    ax.set_zlabel(feat_columns[2])\n    ax.legend(loc='best')\n    plt.show()","ca215bd4":"k_mean_cluster(behavior_freq_df, 4)","f3f9c0ab":"k_mean_cluster(behavior_rate_df, 4)","caa61ace":"SSE=[]\nfor i in range(1,9,1):\n    kmeans=KMeans(n_clusters=i)\n    kmeans.fit(X_activeuser)\n    SSE.append(kmeans.inertia_)\nsns.set()\nplt.plot(range(1,9,1),SSE,marker='o')\nplt.xlabel('k')\nplt.ylabel('SE')","083a58b3":"k_mean_cluster(activeuser_df, 4)","d13b2387":"### Preprocessing\n1. Get the date, time point, and week number of the given month","065ca983":"#### Metric 2: Daily user count","346bc8c7":"2. Drop rows with price < 0","663efb3d":"The following is user's active data features","2d5206d2":"#### Revenue dimension (freqeuncy and rate level)","d2c1d512":"### Business goal\n1. Investigate the performance of ecommerce website with predefined metrics\n2. Cluster users in terms of user activity and browsing behavior","abad9462":"#### Weekly User Retention in this month\n* What's proportion of the users online in a given week are still online in the following week. ","57eb5984":"#### Metric 3: Distribution of view, cart, purchase event and conversion rate (daily and monthly)","c0ff82f1":"#### Metric 1: Daily sale amount","23905f67":"#### User active dimension","5a091364":"3. Drop duplicate records","858a1bcd":"### Performance Metrics\n1. daily sale amount\n2. daily user count \n3. distribution of user event and conversion rate\n    * Monthly conversion rate = $\\frac{\\text{number of the users that purchase per month}}{\\text{total users per month}}$\n4. retention rate\n    * Weekly retention rate = $\\frac{\\text{number of the users online in a given week are still online in the following week}}{\\text{total users in the given week}}$","edeb363b":"### User segmentation \nThis is the user clustering based on two dimensions of metrics, how active a user is at daily, month and purchase level and to what extend a user contribute to the monthly sale. In the first dimension, 391055 records were involved, no 0 values were removed because the majority of users have at least 1 day active or one session active per day. However, in the second and third dimension, most of users have 0 on all of the behavior related features and NAN in rate related features. Therefore these users records were removed and classified as a \"inactive users\"\n\n1. user active dimension\n    * Monthly active = how many days online per month\n    * Daily active = number of sessions per day\n    * Purcase price = total amount of transaction of each user\n\n\n\n2. revenue dimension at event frequency level\n    * Monthly purchase\n    * Monthly price\n    * Monthly view\n\n3. revenue dimension at rate level\n    * Monthly purchase\/view rate \n    * Monthly purchase\/cart rate\n    * Monthly price\/purchase rate","c71f3008":"##### Find the best k value for three dataset","83f36336":"The presence of each user in this month: ","628da327":"#### Clustering using k-means"}}