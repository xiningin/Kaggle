{"cell_type":{"1b20a8e9":"code","3c74c954":"code","6386d2d9":"code","026e3581":"code","397068ed":"code","19483b3d":"code","56b0724c":"code","7961b0c8":"code","f35cebd4":"code","61281a9f":"code","0db3dea5":"code","6caf0c42":"code","7e4c5bdd":"code","bd16cd26":"code","87cd5584":"code","a9579a16":"code","1f47e825":"code","998d7580":"code","36f28482":"code","0f1aa720":"code","57d4f679":"code","d93fcfee":"code","68b599b8":"code","2809f97c":"code","7c376f66":"code","71bc9d01":"code","b76fb61f":"code","50ff7baf":"code","dba1e4d2":"code","c7c0ef47":"code","831f70ab":"code","779568ef":"code","e43c4327":"code","d9640d25":"code","082a0fa4":"code","01e663c5":"code","975da1c4":"code","8b266d97":"code","90e03782":"code","221ce320":"code","6436d92b":"code","91e552cb":"code","517073e7":"code","4599b495":"code","6c436e64":"code","60710d32":"code","c623d3c0":"code","928ffd75":"code","c54c7900":"code","dd38e834":"code","33d35bd0":"code","6c2e0fde":"code","016ce977":"code","ce3992c8":"code","b2c9ec21":"code","844bd83f":"code","5c43e127":"code","f2dfd8a0":"code","b5ba7785":"code","2419fd60":"code","f5a3f3a0":"code","8a5151e4":"code","2541fe9b":"code","6549b71b":"markdown","bd00f6a1":"markdown","72cea780":"markdown","8c4c9003":"markdown","d96613a6":"markdown","2b1ea5f5":"markdown","5fab3c80":"markdown","152b6ef9":"markdown","5b7fea5a":"markdown","41f74e85":"markdown","73354a38":"markdown","cac9fe0f":"markdown","4a65ac18":"markdown","154048a7":"markdown","b75c6f3e":"markdown","450d713c":"markdown","e2ad5262":"markdown","c3307e16":"markdown","b17edaab":"markdown","be0fc763":"markdown","d0f31eb5":"markdown","c66dfea6":"markdown","d6bfe1e1":"markdown","bd99916e":"markdown","18634c87":"markdown","13a8cd14":"markdown","4f68be98":"markdown","e471533d":"markdown","5ea9a3cc":"markdown","aa8281a0":"markdown","a7be3400":"markdown","1a783491":"markdown","aab4d3fc":"markdown","933f6be4":"markdown","f8ed32c4":"markdown"},"source":{"1b20a8e9":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c74c954":"plt.style.use('classic') # the classic style works better for the first part, later we'll change it","6386d2d9":"major_cities = pd.read_csv('..\/input\/climate-change-earth-surface-temperature-data\/GlobalLandTemperaturesByMajorCity.csv')","026e3581":"major_cities.head()","397068ed":"major_cities.info()","19483b3d":"major_cities.nunique() # Chcking the number of unique values per column. ","56b0724c":"major_cities.isnull().sum()\/len(major_cities)","7961b0c8":"# First, it would be really helpful to convert the 'dt' values into datetime objects\nmajor_cities['dt'] = [datetime.strptime(date, '%Y-%m-%d') for date in major_cities['dt']]","f35cebd4":"nas_per_dt = major_cities.set_index('dt')['AverageTemperature'].isnull().reset_index().groupby('dt').sum()\nnas_per_dt.columns = ['Missing values']\n\n# First I set the 'dt' column as index and select only the 'AverageTemperature' column.\n# Then I check for each entry if it is na, but remember that there are multiple entries with the same date.\n# For this reason I need to group by each unique 'dt' value. To do this I make 'dt' a column again by reseting the index.\n# Finally we group by the newly reestablished 'dt' column and sum the values which are booleans.\n\nnas_per_dt.head(10)","61281a9f":"nas_per_dt.plot(figsize=(10,5), colormap='Dark2', grid=True)\nplt.show()","0db3dea5":"nas_per_city = major_cities.groupby(['dt', 'City']).mean()['AverageTemperature'].unstack(level=1).isnull().sum().sort_values()\/major_cities['dt'].nunique()\n\n# This time we need to get total missing values for each city regardless of the date.\n# First I groupby the 'dt' and 'City' columns and aggregate the values with \".mean()\". \n# Keep in mind that each city has only one entry per each unique date so our aggregate function basically just \"aggregates\" one value. \n# I could have used \".sum()\" or \".max()\" and get the same result.\n# After grouping the values I get a Multiindex DataFrame and select only the 'AverageTemperature' column.\n# Then I use the \".unstack()\" method to convert the index of level 1 (which is the cities) to columns.\n# Finally I use \".isnull()\" and \".sum()\" to get the total missing values per column (city) and I sort the values.\n# I divide by the number of unique 'dt' values to get the percentage\n\nnas_per_city.head(10)","6caf0c42":"plt.style.use('classic') # the classic style works better for the next few plots\n\nnas_per_city.plot(\n    kind='barh',\n    figsize=(8,15),\n    fontsize=9,\n    colormap='summer',\n    grid=True)\n\nplt.show()","7e4c5bdd":"sum(major_cities['AverageTemperature'].isnull() != major_cities['AverageTemperatureUncertainty'].isnull())","bd16cd26":"ts_by_city = major_cities.groupby(['dt', 'City']).mean()['AverageTemperature'].unstack(level=1)\n# I use the same steps as above, except this time I stop before checking for missing values.\n\nts_by_city.head(10)","87cd5584":"ten_cities = nas_per_city[:10].index.tolist()\n\nts_by_city[ten_cities].plot(figsize=(10,25), subplots=True)\nplt.show()","a9579a16":"major_cities['month'] = major_cities['dt'].apply(lambda x: x.month)\nmajor_cities['year'] = major_cities['dt'].apply(lambda x: x.year)\nmajor_cities['season'] = (major_cities['month']%12+3)\/\/3\nmajor_cities['decade'] = major_cities['dt'].apply(lambda x: x.year\/\/10)\nmajor_cities['quadrant_century'] = major_cities['dt'].apply(lambda x: x.year\/\/25)","1f47e825":"major_cities.head()","998d7580":"major_cities['quadrant_century'].unique()","36f28482":"# Fixing the quadrant_century values in order to know to which period they refer to\n\nd_25_year = dict(zip(range(70,80), [str(i) + '-' + str(i+25) for i in range(1750, 2000, 25)]))\nd_25_year[69] = '1743-1750'\nd_25_year[80] = '2000-2013'\n\nd_25_year","0f1aa720":"major_cities['quadrant_century'] = major_cities['quadrant_century'].map(d_25_year)","57d4f679":"major_cities.head()","d93fcfee":"decade_by_city = major_cities.groupby(['decade', 'City']).mean()['AverageTemperature'].unstack(level=1)\ndecade_by_city.head()","68b599b8":"decade_by_city[ten_cities].plot(figsize=(10,25), subplots=True, grid=True, marker='.',)\nplt.show()","2809f97c":"top_ten_diff_decade = decade_by_city.diff().mean().sort_values()[-10:].index.tolist() \ntop_ten_diff_decade","7c376f66":"# We'll swap Kiev, Moscow and Toronto with the next three since we already saw them above\ntop_ten_diff_decade = decade_by_city.diff().mean().sort_values()[-13:].index.tolist() \ntop_ten_diff_decade = [i for i in top_ten_diff_decade if i not in ten_cities]\ntop_ten_diff_decade","71bc9d01":"decade_by_city[top_ten_diff_decade].plot(figsize=(10,25), subplots=True, grid=True, marker='.',)\nplt.show()","b76fb61f":"last_ten_diff_decade = decade_by_city.diff().mean().sort_values()[:11].index.tolist() \nlast_ten_diff_decade","50ff7baf":"decade_by_city[last_ten_diff_decade].plot(figsize=(10,25), subplots=True, grid=True, marker='.',)\nplt.show()","dba1e4d2":"med_ten_diff_decade = decade_by_city.diff().mean().sort_values()[45:55].index.tolist() \nmed_ten_diff_decade","c7c0ef47":"decade_by_city[med_ten_diff_decade].plot(figsize=(10,25), subplots=True, grid=True, marker='.',)\nplt.show()","831f70ab":"quad_century_by_city = major_cities.groupby(['quadrant_century', 'City']).mean()['AverageTemperature'].unstack(level=1)\n# Better drop the first period since it's only seven years.\nquad_century_by_city = quad_century_by_city.iloc[1:]","779568ef":"quad_century_by_city[ten_cities].plot(subplots=True, figsize=(10,20), grid=True, marker='.',)\nplt.show()","e43c4327":"quad_century_by_city[top_ten_diff_decade].plot(subplots=True, figsize=(10,20), grid=True, marker='.',)\nplt.show()","d9640d25":"quad_century_by_city[last_ten_diff_decade].plot(subplots=True, figsize=(10,20), grid=True, marker='.',)\nplt.show()","082a0fa4":"quad_century_by_city[med_ten_diff_decade].plot(subplots=True, figsize=(10,20), grid=True, marker='.',)\nplt.show()","01e663c5":"winter_only = major_cities.groupby(['quadrant_century', 'season', 'City']).mean()['AverageTemperature'].xs(1, level=1).unstack(level=1).iloc[1:]\nwinter_only","975da1c4":"winter_only[ten_cities].plot(subplots=True, figsize=(10,20), grid=True, xlabel='Winter Months Only', marker='.')\nplt.show()","8b266d97":"winter_only[top_ten_diff_decade].plot(subplots=True, figsize=(10,20), grid=True, xlabel='Winter Months Only', marker='.')\nplt.show()","90e03782":"winter_only[last_ten_diff_decade].plot(subplots=True, figsize=(10,20), grid=True, xlabel='Winter Months Only', marker='.')\nplt.show()","221ce320":"winter_only[med_ten_diff_decade].plot(subplots=True, figsize=(10,20), grid=True, xlabel='Winter Months Only', marker='.')\nplt.show()","6436d92b":"lowest_std_month = dict(zip(\n    (major_cities.groupby(['month', 'year', 'City'\n    ]).mean()['AverageTemperature'].unstack(level=[2,0]).std().unstack(level=0).apply(np.argmin)+1).index, \n    \n    major_cities.groupby([\n    'month', 'year', 'City'\n    ]).mean()['AverageTemperature'].unstack(level=[2,0]).std().unstack(level=0).apply(np.argmin)+1\n))\n\nlowest_std_month","91e552cb":"values = []\nfor city in ten_cities:\n    values.append(\n            major_cities.groupby(['quadrant_century', 'month', 'City']).mean()['AverageTemperature'].xs(\n                                                    lowest_std_month[city], level=1, drop_level=True).xs(city, level=1))","517073e7":"fig, axs = plt.subplots(nrows=10, ncols=1, figsize=(8,20), sharex=True, tight_layout=True,)\nfor i in range(10):\n    axs[i].plot(values[i], marker='*')\n    axs[i].set_axisbelow(True)\n    axs[i].yaxis.grid(color='darkgray', linestyle='-')\n    axs[i].xaxis.grid(color='darkgray', linestyle='-')\n    axs[i].set_title(ten_cities[i] + ', month ' + str(lowest_std_month[ten_cities[i]]), loc='right')\n\nplt.xticks(rotation=45)\nplt.show()","4599b495":"all_cities = pd.read_csv('..\/input\/climate-change-earth-surface-temperature-data\/GlobalLandTemperaturesByCity.csv')","6c436e64":"all_cities.head()","60710d32":"all_cities['dt'] = all_cities['dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\nall_cities['quadrant_century'] = all_cities['dt'].apply(lambda x: x.year\/\/25)\nall_cities['decade'] = all_cities['dt'].apply(lambda x: x.year\/\/10)","c623d3c0":"all_cities['Latitude'] = all_cities['Latitude'].apply(lambda x: -float(x[:-1]) if x[-1] == 'S' else float(x[:-1]))\nall_cities['Longitude'] = all_cities['Longitude'].apply(lambda x: -float(x[:-1]) if x[-1] == 'W' else float(x[:-1]))","928ffd75":"all_cities['quadrant_century'] = all_cities['quadrant_century'].map(d_25_year)","c54c7900":"all_cities.head()","dd38e834":"unique_cities = all_cities[['City', 'Latitude', 'Longitude']].drop_duplicates().reset_index(drop=True)\nunique_cities.head()","33d35bd0":"diffs_1 = all_cities.loc[all_cities.quadrant_century.isin(\n                                ['1750-1775', '2000-2013']\n                                                )].groupby(\n                                                        ['quadrant_century', 'City']\n                                                                    ).mean()['AverageTemperature'].unstack(level=1).diff().iloc[1]\ndiffs_2 = all_cities.loc[all_cities.quadrant_century.isin(\n                                ['1850-1875', '2000-2013']\n                                                )].groupby(\n                                                        ['quadrant_century', 'City']\n                                                                    ).mean()['AverageTemperature'].unstack(level=1).diff().iloc[1]\n\n\ndiffs_and_coords = unique_cities.join(diffs_1, on='City').join(diffs_2, on='City', rsuffix='_2')\ndiffs_and_coords.columns = ['City', 'Latitude', 'Longitude', 'diff_between_1750-1775_and_2000-2013', 'diff_between_1850-1875_and_2000-2013']\ndiffs_and_coords.head()","6c2e0fde":"diffs_and_coords.corr()[['Latitude', 'Longitude']].iloc[2:]","016ce977":"print('North hemisphere')\ndiffs_and_coords.loc[diffs_and_coords.Latitude > 0].corr()[['Latitude', 'Longitude']].iloc[2:]","ce3992c8":"print('South hemisphere')\ndiffs_and_coords.loc[diffs_and_coords.Latitude < 0].corr()[['Latitude', 'Longitude']].iloc[2:]\n# Keep in mind that South-hemisphere cities have a lot of missing values in the earlier period","b2c9ec21":"print('East of prime meridian')\ndiffs_and_coords.loc[diffs_and_coords.Longitude > 0].corr()[['Latitude', 'Longitude']].iloc[2:]","844bd83f":"print('West of prime meridian')\ndiffs_and_coords.loc[diffs_and_coords.Longitude < 0].corr()[['Latitude', 'Longitude']].iloc[2:]","5c43e127":"plt.style.use('fivethirtyeight')","f2dfd8a0":"# We'll need to drop the outliers\nplt.scatter(x=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) & \n                (diffs_and_coords['diff_between_1850-1875_and_2000-2013'] < 6)\n                                    ]['diff_between_1850-1875_and_2000-2013'],\n            y=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) & \n                (diffs_and_coords['diff_between_1850-1875_and_2000-2013'] < 6)\n                                    ]['Latitude'])\nplt.title('North hemisphere')\nplt.xlabel('temperature increse between the everages of the periods 1850-1875 and 2000-2013')\nplt.ylabel('Latitude')\nplt.show()","b5ba7785":"# We'll need to drop the outliers\nplt.scatter(x=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) & \n                (diffs_and_coords['diff_between_1750-1775_and_2000-2013'] < 6)\n                                    ]['diff_between_1750-1775_and_2000-2013'],\n            y=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) & \n                (diffs_and_coords['diff_between_1750-1775_and_2000-2013'] < 6)\n                                    ]['Latitude'])\nplt.title('North hemisphere')\nplt.xlabel('temperature increse between the averages of the periods 1750-1775 and 2000-2013')\nplt.ylabel('Latitude')\nplt.show()","2419fd60":"plt.scatter(y=diffs_and_coords.loc[\n                (diffs_and_coords.Longitude >0) & \n                (diffs_and_coords['diff_between_1750-1775_and_2000-2013'] < 6)\n                                    ]['diff_between_1750-1775_and_2000-2013'],\n            x=diffs_and_coords.loc[\n                (diffs_and_coords.Longitude >0) & \n                (diffs_and_coords['diff_between_1750-1775_and_2000-2013'] < 6)\n                                    ]['Longitude'])\nplt.title('East of the Prime meridian')\nplt.ylabel('temperature increse between the averages of the periods 1750-1775 and 2000-2013', fontsize=10)\nplt.xlabel('Longitude')\nplt.show()","f5a3f3a0":"plt.scatter(y=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) &\n                (diffs_and_coords.Longitude >0) & \n                (diffs_and_coords['diff_between_1750-1775_and_2000-2013'] < 5)\n                                    ]['diff_between_1750-1775_and_2000-2013'],\n            x=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) &\n                (diffs_and_coords.Longitude >0) & \n                (diffs_and_coords['diff_between_1750-1775_and_2000-2013'] < 5)\n                                    ]['Longitude'])\nplt.title('North hemisphere and East of the Prime meridian')\nplt.ylabel('temperature increse between the averages of the periods 1750-1775 and 2000-2013', fontsize=10)\nplt.xlabel('Longitude')\nplt.show()","8a5151e4":"plt.scatter(y=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) &\n                (diffs_and_coords.Longitude >0) & \n                (diffs_and_coords['diff_between_1850-1875_and_2000-2013'] < 5)\n                                    ]['diff_between_1850-1875_and_2000-2013'],\n            x=diffs_and_coords.loc[\n                (diffs_and_coords.Latitude >0) &\n                (diffs_and_coords.Longitude >0) & \n                (diffs_and_coords['diff_between_1850-1875_and_2000-2013'] < 5)\n                                    ]['Longitude'])\nplt.title('North hemisphere and East of the Prime meridian')\nplt.ylabel('temperature increse between the averages of the periods 1850-1875 and 2000-2013', fontsize=10)\nplt.xlabel('Longitude')\nplt.show()","2541fe9b":"x = diffs_and_coords.loc[diffs_and_coords['diff_between_1850-1875_and_2000-2013']<5]['Longitude']\ny = diffs_and_coords.loc[diffs_and_coords['diff_between_1850-1875_and_2000-2013']<5]['Latitude']\nc = diffs_and_coords.loc[diffs_and_coords['diff_between_1850-1875_and_2000-2013']<5]['diff_between_1850-1875_and_2000-2013']\n\nfig, ax = plt.subplots(figsize=(15,10))\n\nscatter = ax.scatter(x,y,c=c, cmap='hsv', alpha=1, lw=0.6, ec='black')\n\nhandles, labels = scatter.legend_elements(prop = 'colors')\nax.legend(handles, labels)\n\nplt.show()","6549b71b":"**It's hard to discern any longterm trends.**\n* It would be better to plot the average values per decade or even 25-year period.\n* Another option would be to aggregate the temperatures by season or month in order to remove the yearly seasonality.","bd00f6a1":"#### Creating a DataFrame with all the unique cities and their coordinates","72cea780":"**A steep increase after the 1950s stands out**","8c4c9003":"### This time I'll use the dataset with all the cities.\n\n#### First I create some chronological columnslike before.","d96613a6":"**What about cities with the smallest average increase over each decade?**","2b1ea5f5":"**Now let's plot this to get a sense of which dates have the most missing values.**","5fab3c80":"**Creating columns for longer periods and seasons.**","152b6ef9":"### Finally, let's plot the whole map.","5b7fea5a":"Looks like we have 3239 unique date entries for 100 cities from 49 countries.\n\nBut how many are missing?","41f74e85":"### There seem to be positive correlation for longitudes 0-60, negative correlation for 60-100, and then positive again for further east.","73354a38":"# 1. Major Cities\n**First we're going to work with the dataset of the Major Cities**","cac9fe0f":"Let's check a few more cities, this time close to the median average rate of increase by decade.","4a65ac18":"**Next I check if there is any correlation between the difference in average temperatures of the 25-year periods starting in 1750 & 1850 and those of the period 2000-2013 **","154048a7":"**Plotting the missing values per city.**","b75c6f3e":" *It seems that most of the missing values are for dates in the 19th century, while the last entry which is 09-2013 has very few non-missing values.*\n \n Now let's see which cities have the most missing values","450d713c":"**Let's plot the ten cities from before**","e2ad5262":"#### The stronger correlations appear in the North hemisphere and East of the prime meridian cities. Let's plot those.","c3307e16":"**That spike in Xian is definetly not realistic. Keep in mind that we're talking about decade averages!**","b17edaab":"#### Next: check correlations with fixed N\/S Latitude or E\/W Longitude","be0fc763":"#### Turn the coordinate values to positive annd negative based on North\/South and East\/West","d0f31eb5":"*Looks like about hallf of the cities have at least 35% missing values*\n\nFor the 'AverageTemperatureUncertainty' column it would make sense that the missing values are in the same entries as the 'AverageTemperature' column. We can easily confirm it.","c66dfea6":"### **Next we try to further normalize the curves by plotting the averages over 25-year periods**","d6bfe1e1":"## All the graphs tell a similar story.\n### Before moving on let's have a look at data for specific months or seasons.","bd99916e":"About 4.5% of each Temperature column are missing values.\n\nLet's see to which years and cities they correspond.","18634c87":"# 2. Working with Latitudes and Longitudes","13a8cd14":"#### What these correlations show is that the first difference is larger the more southern the city and the more east from the prime meridian we go, while the second difference is larger the more northern the city and the more west from the prime meridian. The latitude correlations are stronger, however none of them is very large in absolute values.","4f68be98":"# In this notebook I work with the city datasets attempting to visualize any possible long term trend of the temperature values.\n\n\n","e471533d":"**What about other cities?**\n\nLet's plot the cities with the highest average increase over each decade","5ea9a3cc":"**Now let's take the columns for the 10 cities with the least missing values and plot them**","aa8281a0":"**Next I create a time-series of the 'AverageTemperature' column for each city**","a7be3400":"#### What about specific months?\n#### It would be wise to use for each city the month with the lowest yearly deviation in order to see better the possible effect of climate change.\n##### Let's find which month has the lowest yearly deviation for each city and plot the decade averages for that month.","1a783491":"***Besides the first three, the other cities are in India and the neighboring countries. What they all have in common is a steep decline of about 1.5 degrees in the beginning of the 19th century followed immediately by an upwards spike. After that, we see an almost continuous increase of constant rate.***\n\n***The first two cities, both in Northeastern China, not far from each other, show an identical downward spike in the middle of the 19th century, when their data begin. This could be an anomally of the data since it's difficult to imagine such a steep decline between two decades.***","aab4d3fc":"**Next, I create a dataframe with average temperatures by decade.**","933f6be4":"***All curves look about flat until around the middle of the 20th century when they begin to rise.***","f8ed32c4":"### It seems that certain regions like Central Asia, Siberia and Northeast US we affected more ."}}