{"cell_type":{"fcd91bdd":"code","be3fe70c":"code","b7733cef":"code","912c9136":"code","ebebb040":"code","6187756a":"code","404acff9":"code","48a1f5c1":"code","edba3e9a":"code","b9bf73e7":"code","32b51855":"code","97954a70":"code","1d6b0679":"code","976b5e01":"code","4a7c1fbf":"code","5c86ca6b":"code","b2441352":"code","474c090c":"code","66492300":"code","7e046f2c":"code","66b4176c":"code","445c095f":"code","c11d8b6d":"code","0a35c0fa":"code","91f8f441":"code","24a707e5":"code","dbd389c2":"code","094b6ac8":"code","24c5cce4":"code","51bfcb2e":"code","541bd75c":"code","e10cc056":"code","cf55c80a":"code","5649d530":"code","f975d5bc":"markdown","65d6eb23":"markdown","9916547c":"markdown","f8450234":"markdown","9598bd91":"markdown","66b54c68":"markdown"},"source":{"fcd91bdd":"from matplotlib import pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport os, sys","be3fe70c":"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b7733cef":"pd.options.display.max_columns = 500\ndataset = pd.read_csv(\"\/kaggle\/input\/ameshousingdataset\/AmesHousing.tsv\", delimiter=\"\\t\")\ndataset.shape","912c9136":"dataset.head()","ebebb040":"missing_data = dataset.isnull().sum()\ndropable_columns = missing_data[(missing_data> len(dataset)\/20)].sort_values()\ndropable_columns.index","6187756a":"dataset = dataset.drop(dropable_columns.index, axis=1)\ndataset.shape","404acff9":"text_type_data = dataset.select_dtypes(include=['object']).isnull().sum()\ndropable_text_columns = text_type_data[text_type_data>0]\ndropable_text_columns","48a1f5c1":"dataset = dataset.drop(dropable_text_columns.index, axis=1)\ndataset.shape","edba3e9a":"num_missing_colmuns = dataset.select_dtypes(include=['int','float']).isnull().sum()\ndropable_num_columns = num_missing_colmuns[num_missing_colmuns > 0]\ndropable_num_columns","b9bf73e7":"flexible_columns = num_missing_colmuns[(num_missing_colmuns < len(dataset)\/20) & (num_missing_colmuns > 0)]\nflexible_columns","32b51855":"replace_ment_dict = dataset[flexible_columns.index].mode().to_dict(orient='records')[0]\nreplace_ment_dict","97954a70":"dataset = dataset.fillna(replace_ment_dict)\ndataset.shape","1d6b0679":"dataset.isnull().sum().value_counts()","976b5e01":"years_sold = dataset['Yr Sold'] - dataset['Year Built']\nyears_sold[years_sold < 0]","4a7c1fbf":"years_since_remod = dataset['Yr Sold'] - dataset['Year Remod\/Add']\nyears_since_remod[years_since_remod < 0]","5c86ca6b":"dataset['Years Before Sale'] = years_sold\ndataset['Years Since Remod'] = years_since_remod\n\ndataset = dataset.drop([1702, 2180, 2181], axis=0)\ndataset = dataset.drop([\"Year Built\", \"Year Remod\/Add\"], axis = 1)\ndataset = dataset.drop([\"PID\", \"Order\",\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)","b2441352":"plt.figure(figsize=(10,8))\nsns.distplot(dataset['SalePrice'])\nplt.title(\"Sale price Frequency Graph\")\nplt.show()\n# SalePrice is our target column","474c090c":"fig_per_time = 3\ncount=0\ntrain_data = dataset[0:1460]\ntest_data = dataset[1460:]\n\nfor column in dataset.columns:\n    plt.figure(count\/\/fig_per_time,figsize=(25,5))\n    plt.subplot(1, fig_per_time, np.mod(count,3)+1)\n    plt.scatter(train_data[column],train_data['SalePrice'])\n    plt.title(\"Model: {0}\".format(column))\n    count +=1 \n\n# plt.scatter(train_data['MS SubClass'],train_data['SalePrice'])","66492300":"numeric_data = dataset.select_dtypes(include=['int','float'])\nnumeric_data.head()","7e046f2c":"asb_corr_coff = numeric_data.corr()['SalePrice'].abs().sort_values()\nasb_corr_coff","66b4176c":"corrdata = numeric_data.corr()\nfig = plt.figure(figsize=(12,9))\nsns.heatmap(corrdata, vmax=1, square=True)\nplt.title(\"Heatmap for data correlation\")\nplt.show()","445c095f":"transform_dataset = asb_corr_coff[asb_corr_coff >= 0.3]\ntransform_dataset","c11d8b6d":"nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n\ntransform_cat_cols = []\nfor col in nominal_features:\n    if col in dataset.columns:\n        transform_cat_cols.append(col)\nunique_values = dataset[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\nunique_values","0a35c0fa":"drop_nonuniq_cols = unique_values[unique_values>10].index\ndataset = dataset.drop(drop_nonuniq_cols, axis=1)\ndataset.shape","91f8f441":"dataset.head()","24a707e5":"text_cols = dataset.select_dtypes(include=['object'])\nfor col in text_cols:\n    dataset[col] = dataset[col].astype('category')\n\ntext_cols.head()","dbd389c2":"categorical_features = text_cols.columns\nfeat_cat = dataset[categorical_features]\n\nfor feat in feat_cat:\n    fig = plt.figure(figsize=(8,6))\n    fig = sns.boxplot(x=feat, y='SalePrice', data=dataset)\n    plt.show()","094b6ac8":"new_dataset = pd.concat([dataset, pd.get_dummies(dataset.select_dtypes(include=['category']))], axis=1)\nnew_dataset = new_dataset.drop(text_cols, axis=1)\nnew_dataset.head()","24c5cce4":"train_dataset = new_dataset[0:1460]\ntest_dataset = new_dataset[1460:]\nnumerical_data = new_dataset.select_dtypes(include=('int','float'))\nfeatures = numerical_data.columns.drop(\"SalePrice\")","51bfcb2e":"train_corrdata = train_dataset.select_dtypes(include=('int','float')).corr()\nfig = plt.figure(figsize=(12,9))\nsns.heatmap(train_corrdata, vmax=1, square=True)\nplt.title(\"Heatmap for data train_data correlation\")\nplt.show()","541bd75c":"corr_num = 15 #number of variables for heatmap\ncols_corr = train_corrdata.nlargest(corr_num, 'SalePrice')['SalePrice'].index\ncorr_mat_sales = np.corrcoef(train_dataset[cols_corr].values.T)\nsns.set(font_scale=1.25)\nf, ax = plt.subplots(figsize=(12, 9))\nhm = sns.heatmap(corr_mat_sales, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 7}, yticklabels=cols_corr.values, xticklabels=cols_corr.values)\nplt.title(\"Heatmap for data train_data correlation\")\nplt.show()","e10cc056":"lr = linear_model.LinearRegression()","cf55c80a":"kFolds = KFold(n_splits=5, shuffle=True)\nrmse_values = []\n\nfor train_index, test_index in kFolds.split(new_dataset):\n    train_data = new_dataset.iloc[train_index]\n    test_data = new_dataset.iloc[test_index]\n    \n    lr.fit(train_data[features], train_data['SalePrice'])\n    prediction = lr.predict(test_data[features])\n    \n    mse = mean_squared_error(prediction, test_data['SalePrice'])\n    rmse = np.sqrt(mse)\n    rmse_values.append(rmse)","5649d530":"print(rmse_values)\nprint(\"Avearge rmse mean: {0}\".format(np.mean(rmse_values)))","f975d5bc":"### House Price prediction with linear regression algorithm\nThis is my first machine learning algorithm implementation. Here I applied linear regression algorithm to predict house price based on house features. \nThe pipline I follewd is:\n* Dataset connect\n* Dataset cleaning\n* Findout proper features for the target set\n* Divide dataset in two protion, `train_dataset` and `test_dataset`\n* Fit the train dataset with proper features to predict\n* Calculate the `mean squarte root` and `root mean square root` of the prediction","65d6eb23":"We will continue with correlation coefficient greater than 0.3","9916547c":"### Data Cleaning","f8450234":"We need not above rows and those columns. So lets drop the rows first and then columns","9598bd91":"Model traing testing and counting mean error","66b54c68":"### Feature Selection"}}