{"cell_type":{"dd054bc4":"code","840f46fc":"code","35487e30":"code","de34f6c0":"code","5503c0f8":"code","fad2987d":"code","aad1e860":"code","9fbcba99":"code","62495785":"code","edd66cd7":"code","fa8c636d":"code","0d52205f":"code","79380ebd":"code","3de6cc44":"code","61b7d9a0":"code","406cbacb":"code","4bf20af9":"code","7fa3a85d":"code","80e0da6b":"code","910c4915":"code","c2e77ab4":"code","9f9f4a7a":"code","bac1615f":"code","1e3f931d":"code","2fc9f164":"code","2d758ce2":"code","c2f35477":"markdown","0d09ccf4":"markdown","9bf8b759":"markdown","360f291f":"markdown","fef63a15":"markdown","85e78d4f":"markdown","072ed96c":"markdown","7117e479":"markdown","70f482ec":"markdown","5be3b2cf":"markdown"},"source":{"dd054bc4":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold","840f46fc":"train = pd.read_csv('..\/input\/tpssep2021dataset10folds\/train_10_folds.csv', index_col='id')\nprint(train.shape)\ntrain.head()","35487e30":"train.describe()","de34f6c0":"test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv', index_col='id')\nprint(test.shape)\ntest.head()","5503c0f8":"test.describe()","fad2987d":"submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')\nsubmission.head()","aad1e860":"# Adding the number of missing values in a row as a feature increases the score significantly\ntrain[\"missing_value_cnt\"] = train.isnull().sum(axis=1)\ntest[\"missing_value_cnt\"] = test.isnull().sum(axis=1)\n\ntrain.head()","9fbcba99":"def imputation(X_train, X_valid, X_test = None):\n    imputer = SimpleImputer(strategy='mean')\n\n    imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\n    imputed_X_valid = pd.DataFrame(imputer.transform(X_valid))\n    imputed_X_test = None\n\n    # Imputation removed column names; put them back\n    imputed_X_train.columns = X_train.columns\n    imputed_X_valid.columns = X_valid.columns\n    \n    if X_test is not None:\n        imputed_X_test = pd.DataFrame(imputer.transform(X_test))\n        imputed_X_test.columns = X_test.columns\n    \n    return imputed_X_train, imputed_X_valid, imputed_X_test\n","62495785":"def feature_scaling(X_train, X_valid, X_test = None):\n    standardScaler = StandardScaler()\n    \n    scaled_X_train = pd.DataFrame(standardScaler.fit_transform(X_train))\n    scaled_X_valid = pd.DataFrame(standardScaler.transform(X_valid))\n    scaled_X_test = None\n    \n    # Scaling removed column names; put them back\n    scaled_X_train.columns = X_train.columns\n    scaled_X_valid.columns = X_valid.columns\n    \n    \n    if X_test is not None:\n        scaled_X_test = pd.DataFrame(standardScaler.transform(X_test))\n        scaled_X_test.columns = X_test.columns\n    \n    return scaled_X_train, scaled_X_valid, scaled_X_test","edd66cd7":"# y = train.claim\n# X = train.drop(columns = ['claim'])\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8, stratify = y, random_state = 1234)\n\n# # Perform imputation\n# imputed_X_train, imputed_X_valid, _ = imputation(X_train, X_valid)\n\n# # Perform Feature Scaling\n# scaled_X_train, scaled_X_valid, _ = feature_scaling(imputed_X_train, imputed_X_valid)  ","fa8c636d":"# cls_model = LGBMClassifier(device='gpu', random_state = 1234)\n# cls_model.fit(scaled_X_train, y_train)\n# valid_predictions = cls_model.predict_proba(scaled_X_valid)\n# print(\"Roc AUC score for Classifier : \", roc_auc_score(y_valid, valid_predictions[:, 1]))","0d52205f":"# reg_model = LGBMRegressor(device='gpu', random_state = 1234)\n# reg_model.fit(scaled_X_train, y_train)\n# valid_predictions = reg_model.predict(scaled_X_valid)\n# print(\"Roc AUC score for Regressor : \",roc_auc_score(y_valid, valid_predictions))","79380ebd":"def objective(trial):\n    \n    y = train.claim\n    X = train.drop(columns = ['claim', 'fold'])\n    \n    params = {\n        'objective': 'binary',\n        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 1024, step = 8),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200,10000, step = 50),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 0.5, log=True),\n        \"min_split_gain\": trial.suggest_float(\"gamma\", 0, 15.0),\n        \"reg_lambda\": trial.suggest_float(\"lambda\", 0, 100.0, step=0.1),\n        \"reg_alpha\": trial.suggest_float(\"alpha\", 0, 100.0, step=0.1),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n        \"subsample_freq\": trial.suggest_categorical(\"subsample_freq\", [1]),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0)\n    }\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.9, stratify = y, random_state = 1234)\n    \n    # Perform imputation\n    X_train, X_valid, _ = imputation(X_train, X_valid)\n\n    # Perform Feature Scaling\n    X_train, X_valid, _ = feature_scaling(X_train, X_valid)\n\n    model = LGBMClassifier(**params,\n                           random_state = 1234)\n\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_valid, y_valid)],\n        eval_metric=\"auc\",\n        early_stopping_rounds=15,\n        verbose=False,\n        callbacks=[\n            pruning_callback\n        ])\n\n    y_pred = model.predict_proba(X_valid)\n    roc_auc = roc_auc_score(y_valid, y_pred[:,1])\n\n    return roc_auc","3de6cc44":"pruner = optuna.pruners.MedianPruner(n_warmup_steps=15)\nstudy = optuna.create_study(pruner= pruner, study_name=\"lgbmc-study\", direction=\"maximize\")\nstudy.optimize(objective, n_trials=500, timeout=7200)","61b7d9a0":"print(\"Number of finished trials: \", len(study.trials))\ntrial = study.best_trial\nprint(\"Best trial validation score: {}\".format(trial.value))\n\nprint(\"The best parameters are: \")\nstudy.best_params","406cbacb":"# best_params = {'n_estimators': 10000,\n#  'num_leaves': 1200,\n#  'max_depth': 7,\n#  'min_data_in_leaf': 8200,\n#  'learning_rate': 0.027488306224509,\n#  'gamma': 2.7677862282755576,\n#  'lambda': 10.404083471231429,\n#  'alpha': 32.57511055307707,\n#  'subsample': 0.3748489217712975,\n#  'subsample_freq': 1,\n#  'colsample_bytree': 0.7259693776119154}\n\n# print(best_params)","4bf20af9":"all_test_predictions = []\nvalid_predictions = pd.DataFrame(np.zeros(train.index.shape), index = train.index, columns=['LGBM_preds'])\n# print(valid_predictions.shape)\nauc_scores = []\n\nfor fold in range(10):\n    X_train =  train[train.fold != fold]\n    X_valid = train[train.fold == fold]\n    X_test = test.copy()\n    \n    valid_ids = X_valid.index.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n    \n    X_train = X_train.drop(columns=['claim', 'fold'])\n    X_valid = X_valid.drop(columns=['claim', 'fold'])\n    \n    # Perform imputation\n    X_train, X_valid, X_test = imputation(X_train, X_valid, X_test)\n\n    # Perform Feature Scaling\n    X_train, X_valid, X_test = feature_scaling(X_train, X_valid, X_test) \n    \n    model = LGBMClassifier(**study.best_params,\n                           objective = 'binary',\n                           random_state = 1234)\n\n    model.fit(X_train, \n              y_train,\n              eval_set=[(X_valid, y_valid)],\n              eval_metric=\"auc\",\n              verbose=200,\n              early_stopping_rounds=100)\n    \n    valid_preds = model.predict_proba(X_valid)[:,1]\n    test_preds = model.predict_proba(X_test)[:,1]\n    all_test_predictions.append(test_preds)\n    valid_predictions.loc[valid_ids, 'LGBM_preds'] = valid_preds\n    \n    roc_auc = roc_auc_score(y_valid, valid_preds)\n    print(\"Validation score for fold {}: {}\".format(fold, roc_auc))\n    auc_scores.append(roc_auc)\n\nprint(\"Validation scores mean : {} and Standard deviation : {}\".format(np.mean(auc_scores), np.std(auc_scores)))","7fa3a85d":"valid_predictions = valid_predictions.reset_index()\nvalid_predictions.columns = [\"id\", \"LGBM_preds\"]\nvalid_predictions.to_csv(\"LGBM_train_predictions.csv\", index=False)","80e0da6b":"print(valid_predictions.shape)\nvalid_predictions.head()","910c4915":"test_predictions = submission.copy()\ntest_predictions.claim = np.mean(np.array(all_test_predictions), axis=0)\ntest_predictions.columns = [\"id\", \"LGBM_preds\"]\ntest_predictions.to_csv(\"LGBM_test_predictions.csv\", index=False)","c2e77ab4":"print(test_predictions.shape)\ntest_predictions.head()","9f9f4a7a":"X_train = train.copy()\nX_test = test.copy()\n\ny_train = train.claim\nX_train = X_train.drop(columns = ['claim', 'fold'])\n\n# Perform imputation\nX_train, X_test, _ = imputation(X_train, X_test)\n\n# Perform Feature Scaling\nX_train, X_test, _ = feature_scaling(X_train, X_test) ","bac1615f":"model = LGBMClassifier(**study.best_params,\n                       objective = 'binary',\n                       random_state = 1234)\n\nmodel.fit(X_train, y_train, verbose=50)\ntest_preds = model.predict_proba(X_test)[:,1]","1e3f931d":"print(roc_auc_score(y_train, model.predict_proba(X_train)[:,1]))","2fc9f164":"submission['claim'] = test_preds\nsubmission.to_csv('lgbm_output.csv', index = False)","2d758ce2":"submission.head(10)","c2f35477":"## Feature Scaling","0d09ccf4":"## Training Model with Whole Training Data","9bf8b759":"## Choose Between LGBMClassifier and LGBMRegressor","360f291f":"## HyperParameter Tuning using Optuna","fef63a15":"## Submission","85e78d4f":"## Import Necessary Libraries","072ed96c":"## Imputation for Handling Missing Values","7117e479":"## Training model with 10 Fold Cross Validation","70f482ec":"## Read the data files","5be3b2cf":"## Introducing Additional Features"}}