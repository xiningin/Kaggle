{"cell_type":{"b2576664":"code","bb5b907e":"code","f7b3a17d":"code","8863ef28":"code","336dc1ea":"code","23b3e799":"code","b6ba5c33":"code","d222c1f5":"code","cb288f6d":"code","45972751":"code","b5e1a3e7":"code","3ca4fb25":"code","466f7dc4":"markdown"},"source":{"b2576664":"import warnings\nwarnings.filterwarnings(\"ignore\")","bb5b907e":"%%capture\n!pip install efficientnet","f7b3a17d":"import cv2\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\nimport gc\nimport os\n\nfrom efficientnet.tfkeras import *\n\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.metrics import AUC\n\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.optimizers import SWA\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.utils import shuffle\n\nimport matplotlib.pyplot as plt","8863ef28":"DEVICE = \"TPU\"\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","336dc1ea":"def set_random_seed():\n    random.seed(2021)\n    tf.random.set_seed(2020)\n    np.random.seed(2019)\nset_random_seed()","23b3e799":"FOLDS = [0,1,2,3,4]\nCONFIG = {\n    'img_size':384,\n    'batch_size': 16,\n    'splits': 5,\n    'epochs': 20,\n    'phi': 0,\n     \n    # Transform params\n    'rot'               :   180.0,\n    'hzoom'             :   8.0,\n    'wzoom'             :   8.0,\n    'hshift'            :   8.0,\n    'wshift'            :   8.0,\n    \n    'mode' : 'COMBINED'\n}\nAUTO = tf.data.experimental.AUTOTUNE","b6ba5c33":"GCS_PATH    = KaggleDatasets().get_gcs_path(f'isic-{CONFIG[\"img_size\"]}-tfrecord')\nfiles_train_original = np.sort(np.array(tf.io.gfile.glob(GCS_PATH  + f'\/tfrecord_{CONFIG[\"img_size\"]}_original\/*.tfrecord')))\n# Pseudo Labeled\nfiles_train_external = np.sort(np.array(tf.io.gfile.glob(GCS_PATH  + f'\/tfrecord_{CONFIG[\"img_size\"]}_external\/*.tfrecord')))\nprint(len(files_train_original))\nprint(len(files_train_external))","d222c1f5":"'''\n    TF DATASET\n'''\ndef ShiftScaleRotate(image, p=0.5):    \n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, zoomed, and shifted\n    P = tf.cast( tf.random.uniform([],0,1) < p, tf.int32)\n    if (P==0): return image\n    \n    DIM = CONFIG[\"crop_size\"]\n    XDIM = DIM % 2 #fix for size 331\n    \n    rot = CONFIG['rot'] * tf.random.normal([1], dtype='float32')\n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') \/ CONFIG['hzoom']\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') \/ CONFIG['wzoom']\n    h_shift = CONFIG['hshift'] * tf.random.normal([1], dtype='float32') \n    w_shift = CONFIG['wshift'] * tf.random.normal([1], dtype='float32') \n    \n    def get_mat(rotation, height_zoom, width_zoom, height_shift, width_shift):\n        # returns 3x3 transformmatrix which transforms indicies\n\n        # CONVERT DEGREES TO RADIANS\n        rotation = math.pi * rotation \/ 180.\n\n        def get_3x3_mat(lst):\n            return tf.reshape(tf.concat([lst],axis=0), [3,3])\n\n        # ROTATION MATRIX\n        c1   = tf.math.cos(rotation)\n        s1   = tf.math.sin(rotation)\n        one  = tf.constant([1],dtype='float32')\n        zero = tf.constant([0],dtype='float32')\n\n        rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n                                       -s1,  c1,   zero, \n                                       zero, zero, one])    \n\n        # ZOOM MATRIX\n        zoom_matrix = get_3x3_mat([one\/height_zoom, zero,           zero, \n                                   zero,            one\/width_zoom, zero, \n                                   zero,            zero,           one])    \n        # SHIFT MATRIX\n        shift_matrix = get_3x3_mat([one,  zero, height_shift, \n                                    zero, one,  width_shift, \n                                    zero, zero, one])\n\n        return K.dot(rotation_matrix, K.dot(zoom_matrix,     shift_matrix))\n\n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x   = tf.repeat(tf.range(DIM\/\/2, -DIM\/\/2,-1), DIM)\n    y   = tf.tile(tf.range(-DIM\/\/2, DIM\/\/2), [DIM])\n    z   = tf.ones([DIM*DIM], dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n    idx2 = K.cast(idx2, dtype='int32')\n    idx2 = K.clip(idx2, -DIM\/\/2+XDIM+1, DIM\/\/2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack([DIM\/\/2-idx2[0,], DIM\/\/2-1+idx2[1,]])\n    d    = tf.gather_nd(image, tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM, DIM,3])\n\ndef Cutout(image, DIM=256, p = 0.5, CT = 4, SZ = 0.25):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image with CT squares of side size SZ*DIM removed\n    \n    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n    P = tf.cast( tf.random.uniform([],0,1)<p, tf.int32)\n    if (P==0)|(CT==0)|(SZ==0): return image\n    \n    for k in range(CT):\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        # COMPUTE SQUARE \n        ratio = tf.cast( tf.random.uniform([],0,1),tf.float32)\n        WIDTH = tf.cast( SZ*DIM*ratio,tf.int32 ) \n        ya = tf.math.maximum(0,y-WIDTH\/\/2)\n        yb = tf.math.minimum(DIM,y+WIDTH\/\/2)\n        xa = tf.math.maximum(0,x-WIDTH\/\/2)\n        xb = tf.math.minimum(DIM,x+WIDTH\/\/2)\n        # DROPOUT IMAGE\n        one = image[ya:yb,0:xa,:]\n        two = tf.zeros([yb-ya,xb-xa,3]) \n        three = image[ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n    image = tf.reshape(image,[DIM,DIM,3])\n    return image\n\ndef Flip(img):\n    img = tf.image.random_flip_left_right(img)\n    return tf.image.random_flip_up_down(img)\n\ndef RandomBrightnessContrast(img, p = 0.5):\n    img = tf.image.random_contrast(img, 0.8, 1.2)\n    img = tf.image.random_brightness(img, 0.1)\n    return img\n\ndef Augment(img):\n    img = Flip(img)\n    img = ShiftScaleRotate(img)\n    img = RandomBrightnessContrast(img)\n    img = Cutout(img, CONFIG['crop_size'])\n    return img\n\ndef cutmix(image, label, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with cutmix applied\n    DIM = CONFIG['crop_size']\n    CLASSES = CONFIG['num_classes']\n    \n    imgs = []; labs = []\n    for j in range(CONFIG['batch_size']*REPLICAS):\n        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n        k = tf.cast( tf.random.uniform([],0,CONFIG['batch_size']*REPLICAS),tf.int32)\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH\/\/2)\n        yb = tf.math.minimum(DIM,y+WIDTH\/\/2)\n        xa = tf.math.maximum(0,x-WIDTH\/\/2)\n        xb = tf.math.minimum(DIM,x+WIDTH\/\/2)\n        # MAKE CUTMIX IMAGE\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n        # MAKE CUTMIX LABEL\n        a = tf.cast(WIDTH*WIDTH\/DIM\/DIM,tf.float32)\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],CLASSES)\n            lab2 = tf.one_hot(label[k],CLASSES)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(CONFIG['batch_size']*REPLICAS,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(CONFIG['batch_size']*REPLICAS,CLASSES))\n    return image2,label2\n\ndef mixup(image, label, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    DIM = CONFIG['crop_size']\n    CLASSES = CONFIG['num_classes']\n    \n    imgs = []; labs = []\n    for j in range(CONFIG['batch_size']*REPLICAS):\n        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([],0,CONFIG['batch_size']*REPLICAS),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n        # MAKE CUTMIX LABEL\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],CLASSES)\n            lab2 = tf.one_hot(label[k],CLASSES)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(CONFIG['batch_size']*REPLICAS,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(CONFIG['batch_size']*REPLICAS,CLASSES))\n    return image2,label2\n\ndef prepare_image(img, augment=True):    \n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.cast(img, tf.float32) \/ 255.\n    img = tf.reshape(img, [600, 800, 3])\n    if augment:\n        img = tf.image.random_crop(img, [CONFIG['crop_size'], CONFIG['crop_size'], 3])\n        img = Augment(img)\n        img = tf.reshape(img, [CONFIG['crop_size'], CONFIG['crop_size'], 3])\n    return img \n\ndef read_tfrecord(example):\n    tfrec_format = {     \n        'image': tf.io.FixedLenFeature([], tf.string),\n        'image_name': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['image'], tf.one_hot(example['target'], 5)\n\ndef transform(image,label):\n    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n    DIM = CONFIG['crop_size']\n    CLASSES = CONFIG['num_classes']\n    SWITCH = 0.5\n    CUTMIX_PROB = 0.5\n    MIXUP_PROB = 0.5\n    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n    image2, label2 = cutmix(image, label, CUTMIX_PROB)\n    image3, label3 = mixup(image, label, MIXUP_PROB)\n    imgs = []; labs = []\n    for j in range(CONFIG['batch_size']*REPLICAS):\n        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n        labs.append(P*label2[j,]+(1-P)*label3[j,])\n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image4 = tf.reshape(tf.stack(imgs),(CONFIG['batch_size']*REPLICAS,DIM,DIM,3))\n    label4 = tf.reshape(tf.stack(labs),(CONFIG['batch_size']*REPLICAS,CLASSES))\n    return image4,label4\n\ndef get_dataset(files,augment = False, \n                shuffle = True, repeat = False):\n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*8)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    ds = ds.map(read_tfrecord, num_parallel_calls=AUTO)\n    ds = ds.map(lambda img, target: (prepare_image(img, augment=augment), target), \n            num_parallel_calls=AUTO)\n    ds = ds.batch(CONFIG['batch_size']*REPLICAS)\n    if augment:\n        ds = ds.map(transform, num_parallel_calls=AUTO)\n    ds = ds.prefetch(AUTO)\n    return ds","cb288f6d":"'''\n    Model\n'''\ndef build_model(fold=None):\n    with strategy.scope():\n        EFFNET_MODEL = [EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5]\n        input_tensor = Input(shape=(None, None, 3))\n        base_models = [M(weights='noisy-student', include_top=False, input_tensor=input_tensor) for M in EFFNET_MODEL]\n        base_models_output = [x.output for x in base_models]\n        gaps = [GlobalAveragePooling2D()(x) for x in base_models_output]\n        out = [Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x) for x in gaps]\n        model = Model(inputs=[input_tensor], outputs=[out])\n        opt = keras.optimizers.Adam(lr=0.001)\n#         loss = tfa.losses.SigmoidFocalCrossEntropy(gamma=2.0, alpha=0.9)\n        loss = keras.losses.BinaryCrossentropy()\n        model.compile(optimizer=opt, \n                  loss=loss,\n                  metrics=[AUC()])\n    return model","45972751":"'''\n    Callback\n'''\ndef get_lr_callback(batch_size=CONFIG['batch_size']):\n    lr_start   = 0.000005\n    lr_max     = 0.00000125 * REPLICAS * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) \/ lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\ndef get_callbacks():\n    return [keras.callbacks.ModelCheckpoint(f'efficientnetb{CONFIG[\"phi\"]}_{CONFIG[\"mode\"]}_fold_{fold}.h5',\n                                                 verbose=1,\n                                                 monitor='val_auc',\n                                                 mode='max',\n                                                 save_best_only=True,\n                                                 save_weights_only=True),\n                get_lr_callback(batch_size=CONFIG['batch_size'])]","b5e1a3e7":"'''\n    Training\n'''\ndef image_counts(files):\n    result = 0\n    for file in files:\n        result += int(file.split('_')[3])\n    return result\n\nkf = KFold(n_splits=CONFIG['splits'], shuffle=True, random_state=2020)\nfold = 0\nval_auc = []\nhists = []\nfiles_train = files_train_original\nif CONFIG[\"mode\"] == \"EXTERNAL\":\n    files_train = files_train_external\n    \nfor train_idx, test_idx in kf.split(files_train):\n    print(f\"***********Fold {fold}*************\")\n    if fold not in FOLDS:\n        fold += 1\n        continue\n    K.clear_session()\n    gc.collect()\n    \n    if CONFIG[\"mode\"] == \"COMBINED\":\n        train_tfrecords = np.concatenate([files_train[train_idx], files_train_external])\n        test_tfrecords = files_train[test_idx]\n    else:\n        train_tfrecords = files_train[train_idx]\n        test_tfrecords = files_train[test_idx]\n    \n        \n    train_ds = get_dataset(train_tfrecords, augment=False, shuffle=True, repeat=True)\n    test_ds = get_dataset(test_tfrecords, augment=False, shuffle=False, repeat=False)\n    \n    train_len = image_counts(train_tfrecords)\n    test_len = image_counts(files_train_original[test_idx])\n    \n    train_len = train_len \/\/ (CONFIG['batch_size']*REPLICAS)\n    test_len = test_len \/\/ (CONFIG['batch_size']*REPLICAS)\n    \n    print(f\"Training Steps: {train_len}\")\n    print(f\"Validation Steps: {test_len}\")\n    \n    callbacks = get_callbacks()\n    \n    model = build_model(fold)\n    hist = model.fit(train_ds,\n            steps_per_epoch=train_len,\n            epochs=CONFIG['epochs'],\n            callbacks=callbacks,\n            validation_data=test_ds,\n            validation_steps=test_len,\n            verbose=1)\n    fold += 1\n    hists.append(hist)\n    break","3ca4fb25":"val_auc = [max(hist.history['val_auc']) for hist in hists]\nprint(val_auc)\nprint(np.mean(val_auc))","466f7dc4":"- efficientnetb4: 0.938"}}