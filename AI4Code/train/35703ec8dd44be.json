{"cell_type":{"ea0900d2":"code","0ace7748":"code","ffabfbcd":"code","a6fe6c13":"code","fc203c21":"code","acfdd6e8":"code","c67395e5":"code","26d2b31b":"code","71ee4409":"code","83609b8e":"code","02ef01f4":"code","a7aa1e83":"code","899e8b68":"code","a7bd50aa":"code","e555459d":"code","88684fc6":"code","67e38f7e":"markdown","c6398024":"markdown","f05fdfef":"markdown","4d0a6a3c":"markdown","59091a2c":"markdown","87c8d8c0":"markdown","e5803916":"markdown","0919ee1b":"markdown","34c1abd1":"markdown","684e7764":"markdown","2d4d70e5":"markdown"},"source":{"ea0900d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ace7748":"# import resources\n%matplotlib inline\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms, models","ffabfbcd":"#vgg19 \u7f51\u7edc\u7ed3\u6784 \nvgg = models.vgg19(pretrained=True).features\n\n# freeze all VGG parameters since we're only optimizing the target image\nfor param in vgg.parameters():\n    param.requires_grad_(False)","a6fe6c13":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nvgg.to(device)","fc203c21":"def load_image(img_path, max_size=400, shape=None):\n    ''' Load in and transform an image, making sure the image\n       is <= 400 pixels in the x-y dims.'''\n    \n    image = Image.open(img_path).convert('RGB')\n    \n    # large images will slow down processing\n    if max(image.size) > max_size:\n        size = max_size\n    else:\n        size = max(image.size)\n    \n    if shape is not None:\n        size = shape\n        \n    in_transform = transforms.Compose([\n                        transforms.Resize(size),\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.485, 0.456, 0.406), \n                                             (0.229, 0.224, 0.225))])\n\n    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n    image = in_transform(image)[:3,:,:].unsqueeze(0)\n    \n    return image","acfdd6e8":"#\ncontent = load_image('..\/input\/cusersmarildownloads22365jpeg\/22365.jpeg').to(device)\n# Resize style to match content, makes code easier\nstyle = load_image('..\/input\/neuralstyle-guyun\/style3.jpg', shape=content.shape[-2:]).to(device)","c67395e5":"# helper function for un-normalizing an image \n# and converting it from a Tensor image to a NumPy image for display\ndef im_convert(tensor):\n    \"\"\" Display a tensor as an image. \"\"\"\n    \n    image = tensor.to(\"cpu\").clone().detach()\n    image = image.numpy().squeeze()\n    image = image.transpose(1,2,0)\n    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n    image = image.clip(0, 1)\n\n    return image","26d2b31b":"# display the images\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n# content and style ims side-by-side\nax1.imshow(im_convert(content))\nax1.set_title(\"Content Image\",fontsize = 20)\nax2.imshow(im_convert(style))\nax2.set_title(\"Style Image\", fontsize = 20)\nplt.show()","71ee4409":"#\u8f7d\u5165\u6a21\u578b\u53c2\u6570 \nprint(vgg)","83609b8e":"def get_features(image, model, layers=None):\n    \"\"\" Run an image forward through a model and get the features for \n        a set of layers. Default layers are for VGGNet matching Gatys et al (2016)\n    \"\"\"\n    \n    ## TODO: Complete mapping layer names of PyTorch's VGGNet to names from the paper\n    ## Need the layers for the content and style representations of an image\n    if layers is None:\n        layers = {'0': 'conv1_1',\n                  '5': 'conv2_1', \n                  '10': 'conv3_1', \n                  '19': 'conv4_1',\n                  '21': 'conv4_2',  ## content representation\n                  '28': 'conv5_1'}\n        \n    features = {}\n    x = image\n    # model._modules is a dictionary holding each module in the model\n    for name, layer in model._modules.items():\n        x = layer(x)\n        if name in layers:\n            features[layers[name]] = x\n            \n    return features","02ef01f4":"#\u63d0\u53d6\u98ce\u683c\u56fe\u76845\u4e2a\u5377\u79ef\u5757\u7684\u8f93\u51fa\n\ndef gram_matrix(tensor):\n    \"\"\" Calculate the Gram Matrix of a given tensor \n        Gram Matrix: https:\/\/en.wikipedia.org\/wiki\/Gramian_matrix\n    \"\"\"\n    \n    # get the batch_size, depth, height, and width of the Tensor\n    _, d, h, w = tensor.size()\n    \n    # reshape so we're multiplying the features for each channel\n    tensor = tensor.view(d, h * w)\n    \n    # calculate the gram matrix\n    gram = torch.mm(tensor, tensor.t())\n    \n    return gram","a7aa1e83":"# get content and style features only once before training\ncontent_features = get_features(content, vgg)\nstyle_features = get_features(style, vgg)\n\n# calculate the gram matrices for each layer of our style representation\nstyle_grams = {layer: gram_matrix(style_features[layer]) for layer in style_features}\n\n# create a third \"target\" image and prep it for change\n# it is a good idea to start of with the target as a copy of our *content* image\n# then iteratively change its style\ntarget = content.clone().requires_grad_(True).to(device)","899e8b68":"# \u8bbe\u7f6e\u5404\u5c42\u8f93\u51fa\u7684\u6743\u91cd \n\n# weighting earlier layers more will result in *larger* style artifacts\n# notice we are excluding `conv4_2` our content representation\nstyle_weights = {'conv1_1': 1.,\n                 'conv2_1': 0.75,\n                 'conv3_1': 0.2,\n                 'conv4_1': 0.2,\n                 'conv5_1': 0.2}\n\ncontent_weight = 1  # alpha\nstyle_weight = 1e9  # beta","a7bd50aa":"# for displaying the target image, intermittently\nshow_every = 400\n\n# iteration hyperparameters\noptimizer = optim.Adam([target], lr=0.003)\nsteps = 2000  # decide how many iterations to update your image (5000)\n\nfor ii in range(1, steps+1):\n    \n    # get the features from your target image\n    target_features = get_features(target, vgg)\n    \n    # the content loss\n    content_loss = torch.mean((target_features['conv4_2'] - content_features['conv4_2'])**2)\n    \n    # the style loss\n    # initialize the style loss to 0\n    style_loss = 0\n    # then add to it for each layer's gram matrix loss\n    for layer in style_weights:\n        # get the \"target\" style representation for the layer\n        target_feature = target_features[layer]\n        target_gram = gram_matrix(target_feature)\n        _, d, h, w = target_feature.shape\n        # get the \"style\" style representation\n        style_gram = style_grams[layer]\n        # the style loss for one layer, weighted appropriately\n        layer_style_loss = style_weights[layer] * torch.mean((target_gram - style_gram)**2)\n        # add to the style loss\n        style_loss += layer_style_loss \/ (d * h * w)\n        \n    # calculate the *total* loss\n    total_loss = content_weight * content_loss + style_weight * style_loss\n    \n    # update your target image\n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n    \n    # display intermediate images and print the loss\n    if  ii % show_every == 0:\n        print('Total loss: ', total_loss.item())\n        plt.imshow(im_convert(target))\n        plt.show()","e555459d":"# display content and final, target image\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 15))\nax1.imshow(im_convert(content))\nax1.set_title(\"Content Image\", fontsize = 20)\nax2.imshow(im_convert(target))\nax2.set_title(\"Stylized Target Image\", fontsize = 20)\nax1.grid(False)\nax2.grid(False)\n# Hide axes ticks\nax1.set_xticks([])\nax1.set_yticks([])\nax2.set_xticks([])\nax2.set_yticks([])\nplt.show()","88684fc6":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Der Schrei der Natur, Munch und Mar\u00edlia , @mpwolke sind hier' )","67e38f7e":"![](https:\/\/data.lustich.de\/bilder\/l\/30323-der-schrei-der-natur.jpg)lustich.de","c6398024":"#Codes by gwgking https:\/\/www.kaggle.com\/gwgking\/neuralstyle\nand https:\/\/www.kaggle.com\/ukveteran\/style-transfer-in-action-tiger-jma\/data","f05fdfef":"#Adults of any age with the following conditions, increased risk of severe illness from COVID-19:\n\nCancer\n\nChronic kidney disease\n\nCOPD (chronic obstructive pulmonary disease)\n\nHeart conditions, such as heart failure, coronary artery disease, or cardiomyopathies\n\nImmunocompromised state (weakened immune system) from solid organ transplant\n\nObesity (body mass index (BMI) of 30 kg\/m2 or higher but < 40 kg\/m2)\n\nSevere Obesity (BMI \u2265 40 kg\/m2)\n\nPregnancy\n\nSickle cell disease\n\nSmoking\n\nType 2 diabetes mellitus\nhttps:\/\/www.cdc.gov\/coronavirus\/2019-ncov\/need-extra-precautions\/people-with-medical-conditions.html","4d0a6a3c":"#The snippet below takes so long (more than 1 hour). Now, I'm the one Screaming.","59091a2c":"#Covid-19 and underlying medical conditions\n\nCOVID-19 is a new disease. Currently there are limited data and information about the impact of many underlying medical conditions and whether they increase the risk for severe illness from COVID-19. Based on what we know at this time, adults of any age with the following conditions might be at an increased risk for severe illness from the virus that causes COVID-19:\n\nAsthma (moderate-to-severe)\n\nCerebrovascular disease (affects blood vessels and blood supply to the brain)\n\nCystic fibrosis\n\nHypertension or high blood pressure\n\nImmunocompromised state (weakened immune system) from blood or bone marrow transplant, immune deficiencies, HIV, use of corticosteroids, or use of other immune weakening medicines\n\nNeurologic conditions, such as dementia\n\nLiver disease\n\nOverweight (BMI > 25 kg\/m2, but < 30 kg\/m2)\n\nPulmonary fibrosis (having damaged or scarred lung tissues)\n\nThalassemia (a type of blood disorder)\n\nType 1 diabetes mellitus\nhttps:\/\/www.cdc.gov\/coronavirus\/2019-ncov\/need-extra-precautions\/people-with-medical-conditions.html","87c8d8c0":"#Underlying medical conditions\n\nWe are learning more about COVID-19 every day. The list of underlying medical conditions is not exhaustive and only includes conditions with sufficient evidence to draw conclusions; it is a living document that may be updated at any time, subject to potentially rapid change as the science evolves.\n\nThis list is meant to inform clinicians to help them provide the best care possible for patients, and to inform individuals as to what their level of risk may be so they can make individual decisions about illness prevention. Notably, the list may not include every condition that might increase one\u2019s risk for developing severe illness from COVID-19, such as those for which evidence may be limited or nonexistent (e.g., rare conditions). \n\nIndividuals with any underlying condition (including those conditions that are NOT on the current list) should consult with their healthcare providers about personal risk factors and circumstances to determine whether extra precautions are warranted.\nhttps:\/\/www.cdc.gov\/coronavirus\/2019-ncov\/need-extra-precautions\/people-with-medical-conditions.html","e5803916":"#Severe illness from COVID-19\n\nRevisions were made on November 2, 2020 to reflect recent data supporting increased risk of severe illness during pregnancy from the virus that causes COVID-19. Revisions also include addition of sickle cell disease and chronic kidney disease to the conditions that might increase the risk of severe illness among children.\n\nAdults of any age with certain underlying medical conditions are at increased risk for severe illness from the virus that causes COVID-19. Severe illness from COVID-19 is defined as hospitalization, admission to the ICU, intubation or mechanical ventilation, or death.https:\/\/www.cdc.gov\/coronavirus\/2019-ncov\/need-extra-precautions\/people-with-medical-conditions.html","0919ee1b":"#Susceptibility to severe COVID-19, by David B. Beck, Ivona Aksentijevich\n\nScience  23 Oct 2020: Vol. 370, Issue 6515, pp. 404-405 - DOI: 10.1126\/science.abe7591\n\nOne of the many pressing questions surrounding severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infections is identifying the determinants of the clinical spectrum, from people with asymptomatic disease to patients with severe COVID-19. Up to 40% of infections may be asymptomatic, suggesting that a large proportion of people may be protected from disease. On the other end of the spectrum is severe disease, with an overall estimated fatality rate near 1%.\n\nMany studies have focused on characterizing the heterogeneity of COVID-19 in terms of demographics, with clear evidence of higher mortality in men and older individuals. \n\nThe adaptive immune system, including both B and T cells, has recently been recognized to play a critical role in providing preexisting immunity to SARS-CoV-2. These studies have highlighted mechanisms that protect against severe symptoms but have not revealed factors that predispose to mortality. Consequently, acquired immune responses to prior infections may account for a large percentage of the variability in disease presentation, although questions remain about additional determinants of disease, such as preexisting comorbidities.\n\nHost genetic risk factors have also emerged as a potential explanation for clinical heterogeneity and additionally offer the potential for understanding molecular pathways for tailored therapeutic intervention.\n\nSmall-scale studies have implicated the type I interferon (IFN) pathway as protective against SARS-CoV-2. The type I IFN pathway plays a crucial role in mediating innate immune responses to viral infection. Recently, multiple studies demonstrated that impaired type 1 IFN responses may be a hallmark of severe COVID-19, but why this pathway was suppressed remained unclear.\nhttps:\/\/science.sciencemag.org\/content\/370\/6515\/404","34c1abd1":"#Children and Covid-19\n\nWhile children have been less affected by COVID-19 compared to adults, children can be infected with the virus that causes COVID-19 and some children develop severe illness. Children with underlying medical conditions are at increased risk for severe illness compared to children without underlying medical conditions.\n\nCurrent evidence on which underlying medical conditions in children are associated with increased risk is limited. Children with the following conditions might be at increased risk for severe illness: obesity, medical complexity, severe genetic disorders, severe neurologic disorders, inherited metabolic disorders, sickle cell disease, congenital (since birth) heart disease, diabetes, chronic kidney disease, asthma and other chronic lung disease, and immunosuppression due to malignancy or immune-weakening medications.\n\nThey do not yet know who is at increased risk for developing the rare but serious complication associated with COVID-19 in children called Multisystem Inflammatory Syndrome in Children (MIS-C), nor do they know what causes MIS-C. https:\/\/www.cdc.gov\/coronavirus\/2019-ncov\/need-extra-precautions\/people-with-medical-conditions.html","684e7764":"#The Scream, (Der Schrei der Natur) by Edvard Munch\n\nThe Scream is the popular name given to a composition created by Norwegian Expressionist artist Edvard Munch in 1893. The original German title given by Munch to his work was Der Schrei der Natur (The Scream of Nature), and the Norwegian title is Skrik (Shriek). The agonised face in the painting has become one of the most iconic images of art, seen as symbolising the anxiety of the human condition.","2d4d70e5":"#Der Schrei der Natur von Edvard Munch wert 120 Millionen Euro. Let's see how much mine values."}}