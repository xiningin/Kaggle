{"cell_type":{"34d94be2":"code","7c0a2197":"code","a6ab5825":"code","762299a6":"code","6ef20e22":"code","8fce9ab0":"code","99f41be9":"code","011a4e6c":"code","ae1c8112":"code","ab89fc00":"code","1d71f8a8":"code","cf420cc4":"code","f43d98ae":"code","b90c599f":"code","4c23d4a9":"markdown","08fee9ad":"markdown","268d4371":"markdown","2dd02cc2":"markdown","ebd21e0f":"markdown","e5a02193":"markdown","54bdf2a8":"markdown","fef2ef35":"markdown","30b66910":"markdown","a6fc5d4b":"markdown","d1acd623":"markdown","1598f601":"markdown","64e4c8b3":"markdown","1d641959":"markdown"},"source":{"34d94be2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c0a2197":"import pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage import exposure\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT\uff08\u5982\u679cDICOM\u8bbe\u5907\u53ef\u7528\uff09\u7528\u4e8e\u5c06\u539f\u59cbDICOM\u6570\u636e\u8f6c\u6362\u4e3a\u201c\u4eba\u6027\u5316\u201d\u89c6\u56fe\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # \u6839\u636e\u8fd9\u4e2a\u503c\uff0cX\u5c04\u7ebf\u53ef\u80fd\u770b\u8d77\u6765\u662f\u53cd\u5411\u7684\u4fee\u590d\u8fd9\u4e2a\u95ee\u9898:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","a6ab5825":"img = read_xray('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/0108949daa13dc94634a7d650a05c0bb.dicom')\nplt.figure(figsize = (12,12))\nplt.imshow(img, 'gray')","762299a6":"img = read_xray('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/0108949daa13dc94634a7d650a05c0bb.dicom',fix_monochrome = False)\nplt.figure(figsize = (12,12))\nplt.imshow(img, 'gray')","6ef20e22":"dataset_dir = '..\/input\/vinbigdata-chest-xray-abnormalities-detection'","8fce9ab0":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n        \n    \ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)\/\/cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n    \n# def draw_bboxes(img, boxes, thickness=10, color=(255, 0, 0), img_size=(500,500)):\n#     img_copy = img.copy()\n#     if len(img_copy.shape) == 2:\n#         img_copy = np.stack([img_copy, img_copy, img_copy], axis=-1)\n#     for box in boxes:\n#         img_copy = cv2.rectangle(\n#             img_copy,\n#             (int(box[0]), int(box[1])),\n#             (int(box[2]), int(box[3])),\n#             color, thickness)\n#     if img_size is not None:\n#         img_copy = cv2.resize(img_copy, img_size)\n#     return img_copy","99f41be9":"dicom_paths = glob(f'{dataset_dir}\/train\/*.dicom')\nimgs = [dicom2array(path) for path in dicom_paths[:4]]\nplot_imgs(imgs)","011a4e6c":"imgs = [exposure.equalize_hist(img) for img in imgs]\nplot_imgs(imgs)","ae1c8112":"from bokeh.plotting import figure as bokeh_figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn import preprocessing\nimport random\nfrom random import randint","ab89fc00":"def get_bbox_area(row):\n    return (row['x_max']-row['x_min'])*(row['y_max']-row['y_min'])\n\ntrain_df = pd.read_csv(f'{dataset_dir}\/train.csv')\nle = preprocessing.LabelEncoder()  # encode rad_id\ntrain_df['rad_label'] = le.fit_transform(train_df['rad_id'])\n\nfinding_df = train_df[train_df['class_name'] != 'No finding']\nfinding_df['bbox_area'] = finding_df.apply(get_bbox_area, axis=1)\nfinding_df.head()","1d71f8a8":"imgs = []\nimg_ids = finding_df['image_id'].values\nclass_ids = finding_df['class_id'].unique()\n\n# map label_id to specify color\nlabel2color = {class_id:[randint(0,255) for i in range(3)] for class_id in class_ids}\nthickness = 3\nscale = 5\n\n\nfor i in range(8):\n    img_id = random.choice(img_ids)\n    img_path = f'{dataset_dir}\/train\/{img_id}.dicom'\n    img = dicom2array(path=img_path)\n    img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n    img = np.stack([img, img, img], axis=-1)\n    \n    boxes = finding_df.loc[finding_df['image_id'] == img_id, ['x_min', 'y_min', 'x_max', 'y_max']].values\/scale\n    labels = finding_df.loc[finding_df['image_id'] == img_id, ['class_id']].values.squeeze()\n    \n    for label_id, box in zip(labels, boxes):\n        color = label2color[label_id]\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n    )\n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","cf420cc4":"def hist_hover(dataframe, column, color=[\"#94c8d8\", \"#ea5e51\"], bins=30, title=\"\", value_range=None):\n    \"\"\"\n    Plot histogram\n    \"\"\"\n    hist, edges = np.histogram(dataframe[column], bins=bins, range=value_range)\n    hist_frame = pd.DataFrame({\n        column: hist,\n        \"left\": edges[:-1],\n        \"right\": edges[1:]\n    })\n    hist_frame[\"interval\"] = [\"%d to %d\" %\n                              (left, right) for left, right in zip(edges[:-1], edges[1:])]\n    src = ColumnDataSource(hist_frame)\n    plot = bokeh_figure(\n        plot_height=400, plot_width=600,\n        title=title, x_axis_label=column,\n        y_axis_label=\"Count\"\n    )\n    plot.quad(\n        bottom=0, top=column, left=\"left\", right=\"right\",\n        source=src, fill_color=color[0], line_color=\"#35838d\",\n        fill_alpha=0.7, hover_fill_alpha=0.7,\n        hover_fill_color=color[1]\n    )\n    hover = HoverTool(\n        tooltips=[(\"Interval\", \"@interval\"), (\"Count\", str(f\"@{column}\"))]\n    )\n    plot.add_tools(hover)\n    output_notebook()\n    show(plot)\n    \n    \nhist_hover(train_df, column='class_id')","f43d98ae":"#Note that a key part of this competition is working with ground truth from multiple radiologists.\nhist_hover(train_df, column='rad_label')","b90c599f":"## histogram of bbox area\nhist_hover(finding_df, column='bbox_area')","4c23d4a9":"**\u5728\u8fd9\u6b21\u6bd4\u8d5b\u4e2d\uff0c\u4f60\u5c06\u81ea\u52a8\u5b9a\u4f4d\u548c\u5206\u7c7b14\u79cd\u80f8\u7247\u80f8\u690e\u5f02\u5e38\u7c7b\u578b\u3002\u60a8\u5c06\u4f7f\u7528\u7531\u7ecf\u9a8c\u4e30\u5bcc\u7684\u653e\u5c04\u79d1\u533b\u751f\u6ce8\u91ca\u768418000\u4e2a\u626b\u63cf\u7ec4\u6210\u7684\u6570\u636e\u96c6\u3002\u60a8\u53ef\u4ee5\u4f7f\u752815000\u4e2a\u72ec\u7acb\u6807\u8bb0\u7684\u56fe\u50cf\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u5c06\u57283000\u4e2a\u56fe\u50cf\u7684\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u8fd9\u4e9b\u6ce8\u91ca\u662f\u901a\u8fc7VinBigData\u7684\u57fa\u4e8eweb\u7684\u5e73\u53f0VinLab\u6536\u96c6\u7684\u3002\u5173\u4e8e\u6784\u5efa\u6570\u636e\u96c6\u7684\u8be6\u7ec6\u4fe1\u606f\u53ef\u4ee5\u5728\u6211\u4eec\u6700\u8fd1\u7684\u8bba\u6587\u201cVinDr CXR\uff1a\u4e00\u4e2a\u5f00\u653e\u7684\u80f8\u90e8X\u5c04\u7ebf\u6570\u636e\u96c6\u548c\u653e\u5c04\u79d1\u533b\u751f\u7684\u6ce8\u91ca\u201d\u4e2d\u627e\u5230\u3002**","08fee9ad":"\u53ef\u4ee5\u8bd5\u8bd5\u5747\u8861\u76f4\u65b9\u56fe\u5904\u7406\uff0c\u5bf9\u6bd4\u5dee\u5f02","268d4371":"\u4e0b\u9762\u5f00\u59cb\u63d0\u53d6\u91cd\u8981\u7279\u5f81\uff0c\u9884\u5904\u7406\u6570\u636e","2dd02cc2":"**\u6bcf\u4e2a\u653e\u5c04\u79d1\u533b\u751f\u7684\u56fe\u50cf\u8d28\u91cf\u4e4b\u95f4\u7684\u4e0d\u5e73\u8861**","ebd21e0f":"**\u7ecf\u8fc7\u4e00\u4e9bEDA\u6b65\u9aa4\uff0c\u6211\u4eec\u8ba4\u8bc6\u5230\u6570\u636e\u96c6\u5728\u8bb8\u591a\u65b9\u9762\u76f8\u5f53\u4e0d\u5e73\u8861\u3002\u4e5f\u8bb8\uff0c\u6211\u4eec\u9700\u8981\u7528\u4e00\u4e9b\u589e\u5e7f\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u6570\u636e\u589e\u5e7f\u8fd8\u6ca1\u5904\u7406\uff0c\u4ee5\u540e\u4f1a\u7ee7\u7eed\u66f4\u65b0**","e5a02193":"**\u53ef\u4ee5\u770b\u5230\u6bcf\u4e2a\u7c7b\u7684\u56fe\u50cf\u8d28\u91cf\u4e4b\u95f4\u7684\u4e0d\u5e73\u8861**","54bdf2a8":"# 2.2 Plot histogram","fef2ef35":"# 1.Dicom to Numpy array","30b66910":"**\u5c06dicom\u6570\u636e\u8f6c\u6362\u6210png\/jpg\u770b\u8d77\u6765\u5f88\u7b80\u5355\uff0c\u4f46\u662f\uff0c\u60a8\u5fc5\u987b\u8003\u8651\u5230\uff0c\u539f\u59cbdicom\u6570\u636e\u5b9e\u9645\u4e0a\u5e76\u4e0d\u80fd\u7ebf\u6027\u8f6c\u6362\u4e3a\u201c\u4eba\u6027\u5316\u201d\u7684png\/jpg\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5927\u591a\u6570DICOM\u7684\u5b58\u50a8\u50cf\u7d20\u503c\u5728\u6307\u6570\u7ea7\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u5f97\u5230\u653e\u5c04\u5b66\u5bb6\u6700\u521d\u5728\u5de5\u4f5c\u533a\u770b\u5230\u7684jpg\/png\uff0c\u60a8\u9700\u8981\u5e94\u7528\u4e00\u4e9b\u8f6c\u6362\u3002DICOM\u5143\u6570\u636e\u5b58\u50a8\u4e86\u5982\u4f55\u8fdb\u884c\u8fd9\u79cd\u201c\u4eba\u6027\u5316\u201d\u8f6c\u6362\u7684\u4fe1\u606f\u3002\n\u4e0b\u9762\u662f\u6211\u4f7f\u7528\u7684\u793a\u4f8b\u4ee3\u7801\uff1a**","a6fc5d4b":"\u6ca1\u6709\u89e3\u51b3\u5355\u8272\u95ee\u9898,\u8bbe\u7f6efix_monochrome = False","d1acd623":"# 2.1 Plot bounding box","1598f601":"\u60a8\u53ef\u4ee5\u770b\u5230\uff1a\u5728\u6bcf\u4e2a\u56fe\u50cf\u4e2d\uff0c\u90fd\u6709\u8bb8\u591a\u91cd\u53e0\u7684\u6846\u3002\u8bf7\u6ce8\u610f\uff0c\u8fd9\u573a\u6bd4\u8d5b\u7684\u4e00\u4e2a\u5173\u952e\u90e8\u5206\u662f\u4ece\u591a\u4e2a\u653e\u5c04\u79d1\u533b\u751f\u7684\u5730\u9762\u771f\u76f8\u5de5\u4f5c\u3002\u6211\u60f3\u5982\u679c\u4f60\u5904\u7406\u5f97\u597d\u7684\u8bdd\uff0c\u5728\u8fd9\u573a\u6bd4\u8d5b\u4e2d\u83b7\u5f97\u6700\u597d\u7684\u540d\u6b21\u662f\u5173\u952e\u3002","64e4c8b3":"# 2.EDA csv","1d641959":"**\u6211\u4eec\u5c06\u5c1d\u8bd5\u7ed8\u5236\u4e00\u4e9b\u76f4\u65b9\u56fe\u3002**"}}