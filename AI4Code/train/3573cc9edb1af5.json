{"cell_type":{"1a429547":"code","931719f8":"code","87b87538":"code","8e9f9dca":"code","0b08dbd4":"code","b8b97924":"code","290ab691":"code","86834a73":"code","7a0f0362":"code","49cd034f":"code","2408d7bd":"code","2bd16a27":"code","0e3e3487":"code","4f553d82":"code","5d9df8c6":"markdown","5e8dd91f":"markdown"},"source":{"1a429547":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","931719f8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\ndiabetes_data = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\nprint(diabetes_data['Outcome'].value_counts())\ndiabetes_data.head(3)","87b87538":"diabetes_data.info( )","8e9f9dca":"def get_clf_eval(y_test, pred=None, pred_proba=None):\n    confusion = confusion_matrix( y_test, pred)\n    accuracy = accuracy_score(y_test , pred)\n    precision = precision_score(y_test , pred)\n    recall = recall_score(y_test , pred)\n    f1 = f1_score(y_test,pred)\n    # ROC-AUC \ucd94\uac00 \n    roc_auc = roc_auc_score(y_test, pred_proba)\n    print('Confusion Matrix')\n    print(confusion)\n    # ROC-AUC print \ucd94\uac00\n    print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f},\\\n    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))","0b08dbd4":"def precision_recall_curve_plot(y_test=None, pred_proba_c1=None):\n    # threshold ndarray\uc640 \uc774 threshold\uc5d0 \ub530\ub978 \uc815\ubc00\ub3c4, \uc7ac\ud604\uc728 ndarray \ucd94\ucd9c. \n    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n    \n    # X\ucd95\uc744 threshold\uac12\uc73c\ub85c, Y\ucd95\uc740 \uc815\ubc00\ub3c4, \uc7ac\ud604\uc728 \uac12\uc73c\ub85c \uac01\uac01 Plot \uc218\ud589. \uc815\ubc00\ub3c4\ub294 \uc810\uc120\uc73c\ub85c \ud45c\uc2dc\n    plt.figure(figsize=(8,6))\n    threshold_boundary = thresholds.shape[0]\n    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n    \n    # threshold \uac12 X \ucd95\uc758 Scale\uc744 0.1 \ub2e8\uc704\ub85c \ubcc0\uacbd\n    start, end = plt.xlim()\n    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n    \n    # x\ucd95, y\ucd95 label\uacfc legend, \uadf8\ub9ac\uace0 grid \uc124\uc815\n    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n    plt.legend(); plt.grid()\n    plt.show()","b8b97924":"# \ud53c\ucc98 \ub370\uc774\ud130 \uc138\ud2b8 X, \ub808\uc774\ube14 \ub370\uc774\ud130 \uc138\ud2b8 y\ub97c \ucd94\ucd9c. \n# \ub9e8 \ub05d\uc774 Outcome \uceec\ub7fc\uc73c\ub85c \ub808\uc774\ube14 \uac12\uc784. \uceec\ub7fc \uc704\uce58 -1\uc744 \uc774\uc6a9\ud574 \ucd94\ucd9c \nX = diabetes_data.iloc[:, :-1]\ny = diabetes_data.iloc[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y)\n\n# \ub85c\uc9c0\uc2a4\ud2f1 \ud68c\uadc0\ub85c \ud559\uc2b5,\uc608\uce21 \ubc0f \ud3c9\uac00 \uc218\ud589. \nlr_clf = LogisticRegression()\nlr_clf.fit(X_train , y_train)\npred = lr_clf.predict(X_test)\n# roc_auc_score \uc218\uc815\uc5d0 \ub530\ub978 \ucd94\uac00\npred_proba = lr_clf.predict_proba(X_test)[:, 1]\n\nget_clf_eval(y_test , pred, pred_proba)","290ab691":"pred_proba_c1 = lr_clf.predict_proba(X_test)[:, 1]\nprecision_recall_curve_plot(y_test, pred_proba_c1)","86834a73":"diabetes_data.describe()","7a0f0362":"# 0\uac12\uc744 \uac80\uc0ac\ud560 \ud53c\ucc98\uba85 \ub9ac\uc2a4\ud2b8 \uac1d\uccb4 \uc124\uc815\nzero_features = ['Glucose', 'BloodPressure','SkinThickness','Insulin','BMI']\n\n# \uc804\uccb4 \ub370\uc774\ud130 \uac74\uc218\ntotal_count = diabetes_data['Glucose'].count()\n\n# \ud53c\ucc98\ubcc4\ub85c \ubc18\ubcf5 \ud558\uba74\uc11c \ub370\uc774\ud130 \uac12\uc774 0 \uc778 \ub370\uc774\ud130 \uac74\uc218 \ucd94\ucd9c\ud558\uace0, \ud37c\uc13c\ud2b8 \uacc4\uc0b0\nfor feature in zero_features:\n    zero_count = diabetes_data[diabetes_data[feature] == 0][feature].count()\n    print('{0} 0 \uac74\uc218\ub294 {1}, \ud37c\uc13c\ud2b8\ub294 {2:.2f} %'.format(feature, zero_count, 100*zero_count\/total_count))\n","49cd034f":"# zero_features \ub9ac\uc2a4\ud2b8 \ub0b4\ubd80\uc5d0 \uc800\uc7a5\ub41c \uac1c\ubcc4 \ud53c\ucc98\ub4e4\uc5d0 \ub300\ud574\uc11c 0\uac12\uc744 \ud3c9\uade0 \uac12\uc73c\ub85c \ub300\uccb4\ndiabetes_data[zero_features]=diabetes_data[zero_features].replace(0, diabetes_data[zero_features].mean())","2408d7bd":"X = diabetes_data.iloc[:, :-1]\ny = diabetes_data.iloc[:, -1]\n\n# StandardScaler \ud074\ub798\uc2a4\ub97c \uc774\uc6a9\ud574 \ud53c\ucc98 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \uc77c\uad04\uc801\uc73c\ub85c \uc2a4\ucf00\uc77c\ub9c1 \uc801\uc6a9\nscaler = StandardScaler( )\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 156, stratify=y)\n\n# \ub85c\uc9c0\uc2a4\ud2f1 \ud68c\uadc0\ub85c \ud559\uc2b5, \uc608\uce21 \ubc0f \ud3c9\uac00 \uc218\ud589. \nlr_clf = LogisticRegression()\nlr_clf.fit(X_train , y_train)\npred = lr_clf.predict(X_test)\n# roc_auc_score \uc218\uc815\uc5d0 \ub530\ub978 \ucd94\uac00\npred_proba = lr_clf.predict_proba(X_test)[:, 1]\nget_clf_eval(y_test , pred, pred_proba)","2bd16a27":"from sklearn.preprocessing import Binarizer\n\ndef get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n    # thresholds \ub9ac\uc2a4\ud2b8 \uac1d\uccb4\ub0b4\uc758 \uac12\uc744 \ucc28\ub840\ub85c iteration\ud558\uba74\uc11c Evaluation \uc218\ud589.\n    for custom_threshold in thresholds:\n        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n        custom_predict = binarizer.transform(pred_proba_c1)\n        print('\uc784\uacd7\uac12:',custom_threshold)\n        # roc_auc_score \uad00\ub828 \uc218\uc815\n        get_clf_eval(y_test , custom_predict, pred_proba_c1)","0e3e3487":"thresholds = [0.3 , 0.33 ,0.36,0.39, 0.42 , 0.45 ,0.48, 0.50]\npred_proba = lr_clf.predict_proba(X_test)\nget_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds )","4f553d82":"# \uc784\uacd7\uac12\ub97c 0.50\ub85c \uc124\uc815\ud55c Binarizer \uc0dd\uc131\nbinarizer = Binarizer(threshold=0.48)\n\n# \uc704\uc5d0\uc11c \uad6c\ud55c lr_clf\uc758 predict_proba() \uc608\uce21 \ud655\ub960 array\uc5d0\uc11c 1\uc5d0 \ud574\ub2f9\ud558\ub294 \uceec\ub7fc\uac12\uc744 Binarizer\ubcc0\ud658. \npred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1)) \n\n# roc_auc_score \uad00\ub828 \uc218\uc815\nget_clf_eval(y_test , pred_th_048, pred_proba[:, 1])","5d9df8c6":"> ****Make Evaluation Function -> return confusion matrix, accuracy, precision, recall, f1 score, roc_auc","5e8dd91f":"> Logistic Regression model"}}