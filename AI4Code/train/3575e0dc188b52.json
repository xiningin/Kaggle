{"cell_type":{"775fc3a4":"code","3a271d0c":"code","fc0ce630":"code","6c52dbbb":"code","04f5ddc3":"code","b29a085e":"code","40f8581e":"code","c02511ae":"code","febbecb7":"code","f6ca4787":"code","d6fc8270":"code","8417b822":"code","cf55cd16":"code","662c33b9":"code","b781a6bd":"code","6337f75a":"code","679f0047":"code","4067e0c6":"code","58f73131":"code","0b72610a":"code","48a05c50":"code","68bbf925":"code","22ef1ece":"code","99d750f5":"code","af3ea49b":"code","8f0ccd36":"code","1521be3e":"code","d7d8651a":"markdown","137d803e":"markdown"},"source":{"775fc3a4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","3a271d0c":"train = pd.read_csv('..\/input\/titanic\/train.csv')","fc0ce630":"X_test_file = pd.read_csv('..\/input\/titanic\/test.csv')","6c52dbbb":"train.head()","04f5ddc3":"def impute_age(cols):\n    Age=cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age\n","b29a085e":"#APPLY THIS FUNCTION ON AGE COLUMN\ntrain['Age']= train[['Age', 'Pclass']].apply(impute_age, axis=1)\n#CREATE HEATMAP TO OBSERVE CHANGES\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n#NOW WE WILL DROP THE CABIN COLUMN SINCE ALOT OF VALUES ARE MISSING\ntrain.drop('Cabin', axis=1,inplace=True)\n#AGAIN CHECK THE HEATMAP FOR NULL VALUES\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n#JUST IN CASE PERFORM A DROPNA TO BE SURE\ntrain.dropna(inplace=True)\n\n#DUMMY DATA!!!!\n#CReATING DUMMY DATA FOR CATEGORICAL FIELDS\nsex = pd.get_dummies(train['Sex'], drop_first = True)\nembark = pd.get_dummies(train['Embarked'], drop_first = True)\n#CONCAT THESE FIELDS IN THE DATA\ntrain = pd.concat([train, sex, embark], axis=1)\n\n#DROP COULMNS WHICH YOU DONT NEED\ntrain.drop(['Sex', 'Embarked', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace= True)\n","40f8581e":"train.head()","c02511ae":"X_test_file['Fare'].fillna(0, inplace=True)","febbecb7":"X_test_file[X_test_file['Fare'].isnull()]","f6ca4787":"#APPLY THIS FUNCTION ON AGE COLUMN\nX_test_file['Age']= X_test_file[['Age', 'Pclass']].apply(impute_age, axis=1)\n#CREATE HEATMAP TO OBSERVE CHANGES\nsns.heatmap(X_test_file.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n#NOW WE WILL DROP THE CABIN COLUMN SINCE ALOT OF VALUES ARE MISSING\nX_test_file.drop('Cabin', axis=1,inplace=True)\n#AGAIN CHECK THE HEATMAP FOR NULL VALUES\nsns.heatmap(X_test_file.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n#JUST IN CASE PERFORM A DROPNA TO BE SURE\nX_test_file.dropna(inplace=True)\n\n#DUMMY DATA!!!!\n#CReATING DUMMY DATA FOR CATEGORICAL FIELDS\nsex_1 = pd.get_dummies(X_test_file['Sex'], drop_first = True)\nembark_1 = pd.get_dummies(X_test_file['Embarked'], drop_first = True)\n#CONCAT THESE FIELDS IN THE DATA\nX_test_file = pd.concat([X_test_file, sex_1, embark_1], axis=1)\n\n#DROP COULMNS WHICH YOU DONT NEED\nX_test_file.drop(['Sex', 'Embarked', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace= True)\n","d6fc8270":"X = train.drop('Survived', axis=1)\n#X = X[['Fare', 'male']]\ny = train['Survived']","8417b822":"from sklearn.feature_selection import SelectKBest,chi2\ntest=SelectKBest(score_func=chi2,k=2)\nfit=test.fit(X,y)\nprint(fit.scores_)","cf55cd16":"X.head()","662c33b9":"from sklearn.model_selection import train_test_split","b781a6bd":"X_train, X_validate, y_train, y_validate = train_test_split(X,y,test_size=0.25)","6337f75a":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_validate = scaler.transform(X_validate)","679f0047":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","4067e0c6":"model = Sequential()\nmodel.add(Dense(units = 8, activation = 'relu'))\nmodel.add(Dense(units = 4, activation = 'relu'))\n#model.add(Dropout(0.5))\n\n#model.add(Dense(units = 6, activation = 'relu'))\n#model.add(Dense(units = 4, activation = 'relu'))\n#model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n\n\n\nmodel.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","58f73131":"early_stop = EarlyStopping(monitor='val_loss', mode= 'min', verbose= 1, patience=15)\n","0b72610a":"model.fit(x=X_train, y=y_train, epochs = 2000, validation_data=(X_validate, y_validate), batch_size=128, callbacks=[early_stop])","48a05c50":"losses = pd.DataFrame(model.history.history)","68bbf925":"losses.plot()","22ef1ece":"X_test_file = scaler.transform(X_test_file)","99d750f5":"#model.predict_classes(X_test_file)","af3ea49b":"p = model.predict_classes(X_validate)","8f0ccd36":"from sklearn.metrics import classification_report\nprint(classification_report(y_validate, p))","1521be3e":"163\/267","d7d8651a":"model = Sequential()\nmodel.add(Dense(8, activation = 'relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(8, activation = 'relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","137d803e":"# Hey this is my Titanic Competition notebook. Upvote if you like..Thanks!"}}