{"cell_type":{"474bc246":"code","b4fd5b82":"code","bd3e116f":"code","c18dc4e9":"code","5ca0296d":"code","976e9e80":"code","f096186d":"code","f5b7ebfb":"code","f8f1daed":"markdown","1fc631f7":"markdown","6dcfd354":"markdown","ec8bcf4b":"markdown","bbb35255":"markdown","b379e8a6":"markdown","07c42c7a":"markdown","a7809b35":"markdown","22209d18":"markdown"},"source":{"474bc246":"#-------Import Dependencies-------#\n%matplotlib inline\nimport pandas as pd\nimport os,shutil,math,scipy,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.metrics import confusion_matrix,roc_curve,auc\n\nfrom PIL import Image\nfrom PIL import Image as pil_image\nfrom time import time\nfrom PIL import ImageDraw\nfrom glob import glob\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom IPython.display import SVG\n\nfrom scipy import misc,ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\n\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.preprocessing.image import save_img\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler","b4fd5b82":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","bd3e116f":"train_dir = '..\/input\/trypophobia\/trypophobia\/train\/'\nval_dir = '..\/input\/trypophobia\/trypophobia\/valid\/'\n\naugs = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,  \n    zoom_range=0.2,        \n    horizontal_flip=True)  \n\ntrain_gen = augs.flow_from_directory(\n    train_dir,\n    target_size = (128,128),\n    batch_size=32,\n    class_mode = 'binary',\n    shuffle=True)\n\nval_gen = augs.flow_from_directory(\n    val_dir,\n    target_size=(128,128),\n    batch_size=32,\n    class_mode='binary')","c18dc4e9":"model = Sequential()\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.summary()\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","5ca0296d":"checkpoint = ModelCheckpoint(\n    '.\/base.model',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=30,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = '.\/logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=1,\n    verbose=1, \n    mode='auto'\n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","976e9e80":"model.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n    \nhistory = model.fit_generator(\n    train_gen, \n    steps_per_epoch  = 100, \n    validation_data  = val_gen,\n    validation_steps = 100,\n    epochs           = 30, \n    verbose          = 1,\n    callbacks=callbacks\n)","f096186d":"show_final_history(history)\nmodel.load_weights('.\/base.model')\nmodel_score = model.evaluate_generator(val_gen,steps=100)\nprint(\"Model Test Loss:\",model_score[0])\nprint(\"Model Test Accuracy:\",model_score[1])\n\nmodel_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save(\"trypophobia.h5\")\nprint(\"Weights Saved\")","f5b7ebfb":"!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = '.\/logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('.\/ngrok http 8080 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","f8f1daed":"# Model Training","1fc631f7":"# Happy Learning!\n\nGitHub: https:\/\/github.com\/Terrance-Whitehurst\n\nKaggle: https:\/\/www.kaggle.com\/twhitehurst3\n\nLinkedIn: https:\/\/www.linkedin.com\/in\/terrance-whitehurst-242423173\/\n\nWebsite: https:\/\/www.terrancewhitehurst.com\/\n\nYoutube Channel: https:\/\/www.youtube.com\/channel\/UCwt6d06n0cbD5l-eoXBTEcA?view_as=subscriber\n\nBlog: https:\/\/medium.com\/@TerranceWhitehurst","6dcfd354":" # Import All The Neccessary Libraries For The Project ","ec8bcf4b":"# Evaluate The Model And Save The Weights Of The Model","bbb35255":"# Preprocessing\n### Here we use the Keras ImageDataGenerator. \n### We create the train and validation directory and use data augmenetation before passing it into the generator.\n### We use flow_from_directory","b379e8a6":"# Callbacks\n\n### These callbacks will help us monitor the training and even gradually change the learning rate of the model while training. Callbacks are extremely useful","07c42c7a":"# Function For Visualizing Training Results","a7809b35":"# TensorBoard\n### Here is a tensorboard scripts you can copy that will give you a link to view the models training on tensorboard","22209d18":"# The Sequential Model\n### Here we use a conv2D along with MaxPooling2D and BatchNormalization\n### The Activation is sigmoid\n### The relu activation is used"}}