{"cell_type":{"0beaa554":"code","de96d3e8":"code","d53a3ebe":"code","12620522":"code","7d351158":"code","8e7ab4c9":"code","fc0e5d57":"markdown","11add2a0":"markdown","cf3e0ca7":"markdown","724806fe":"markdown","be755ece":"markdown","fe5a0030":"markdown","4b79105d":"markdown","335be7bf":"markdown","bb5e18d8":"markdown"},"source":{"0beaa554":"!git clone https:\/\/github.com\/NCAI-Research\/CALM","de96d3e8":"print(\"Installing requirements...\")\n%cd CALM\n!pip install -q -r requirements.txt &> log","d53a3ebe":"# Initialize the name of the experiment\nexp_name = \"CALM\"\n\n# the name of the HF organization and model for the experiment\n%env HF_ORGANIZATION_NAME=CALM\n%env HF_MODEL_NAME={exp_name}\n\n# WANDB information for tracking the run \n\n%env WANDB_API_KEY=65dbae2761bd93ee41c54b443c361114be29b8ec\n\n# Name, project, and method for the WANDB Team\n%env WANDB_ENTITY=calm\n%env WANDB_PROJECT={exp_name}-hivemind-trainers\n%env WANDB_START_METHOD=thread","12620522":"import os\nfrom huggingface_auth import authorize_with_huggingface\n\nos.environ['HF_USER_ACCESS_TOKEN'] = authorize_with_huggingface().hf_user_access_token","7d351158":"import nltk\nnltk.download('punkt')","8e7ab4c9":"# Check the device capability to set the batch size\nimport torch\ncapability = torch.cuda.get_device_capability()\n# memory_gb = torch.cuda.mem_get_info()[1] \/ 1e9\ngradient_checkpointing = False\nbatch_size = 4\nfp16 = True\n# if capability >= (8, 0):  # ampere\n#   batch_size, fp16 = 8, True\n# elif capability >= (6, 0):  # v100, t4, p100\n#   batch_size, fp16 = 4, True\n# else:  # maxwell, kepler\n#   batch_size, fp16 = 1, False\n# if memory_gb < 9:  # 8gb gpus: 1070, 2060S, \n#   batch_size = min(batch_size, 2)\n# if memory_gb < 7:  # 6gb or less: try our best to fit\n#   batch_size, fp16 = min(batch_size, 1), True\n#   gradient_checkpointing = True\nprint(f\"\\nRunning {torch.cuda.get_device_name()}, setting batch size = {batch_size}, fp16 = {fp16}, gradient_checkpointing={gradient_checkpointing}\\n\")\n\n# start the training\n!ulimit -n 16384 && python run_trainer.py --run_id {exp_name} --per_device_train_batch_size {batch_size} --gradient_accumulation_steps 1 --fp16 {fp16} --gradient_checkpointing {gradient_checkpointing} \\\n  --client_mode --matchmaking_time 60 --initial_peers \/ip4\/34.124.232.172\/tcp\/12345\/p2p\/QmdGDSzDEi7uo8pTGG7n8s2dW12VGoPQKiDVDoQaVAo3bf \/ip4\/193.106.95.184\/tcp\/12345\/p2p\/QmRgdEXySu8hEB3xUxexJPxcv7M41PggRDnUTf9kStdgup \/ip4\/194.213.3.15\/tcp\/8080\/p2p\/QmeCHQ2CaqSNLmGGZjAcbNjcD9uTCxmZg5gg7RBHDVUbKb \/ip4\/34.87.16.100\/tcp\/12345\/p2p\/QmVLZVXCWfCiqnH78xun7Qs3mBa5rQB9xKhWb4STmdsmov \/ip4\/91.109.116.12\/tcp\/12345\/p2p\/QmdPf6urWDhAB93MrKhWWVDFNkfyVqAy3ty9QJjhV9Ugdo","fc0e5d57":"# Step 3: Let's start training \ud83d\udc4f \ud83d\udd56\n","11add2a0":"## Download the punkt sentence tokenizer\n","cf3e0ca7":"# Step 2: Installing required libraries\n\nNOTE: be patient this may take a couple of minutes.","724806fe":"# Step 1: Clone the repo","be755ece":"# Step 3: Setup the experiment environment variables","fe5a0030":"## Check the user authority in the HF organization \ud83e\udd17\n\nWhen the code runs it will request for the user access token \ud83d\udd11 in HF, to get it:\n\n1. Go to your [HF account](https:\/\/huggingface.co)\n2. Go to Settings \u21d2 Access Tokens\n3. Generate a new Access Token and enter any name for \"what's this token for\"\n4. Select `read` role\n5. Copy your access token\n6. Paste it in the execution prompt in the notebook\n\n\n","4b79105d":"This notebook was written for the Collaborative Arabic Language Model CALM project, it will contain instructions on how to set up your collaborative training.\n\n\n* For more information, please visit https:\/\/github.com\/NCAI-Research\/CALM and https:\/\/huggingface.co\/CALM. \n\n---","335be7bf":"<img src=\"https:\/\/raw.githubusercontent.com\/NCAI-Research\/CALM\/main\/assets\/notebook-header.png\"\/>","bb5e18d8":"# \ud83d\udce3 Pre-training required steps: \n1.   Create a [**Huggingface account**](https:\/\/huggingface.co) and join the NCAI-CALM organization \ud83d\udc49\ud83c\udffb https:\/\/huggingface.co\/CALM using the link sent to you on the invitation email.\n\n---"}}