{"cell_type":{"eaa368e6":"code","1a3528f4":"code","54da3471":"code","0da35cee":"code","e00bdcec":"code","4abdd4c1":"code","c50d3705":"code","47efae33":"code","47814aac":"code","8046ede9":"code","d4a28e77":"code","c1251744":"code","a0b0dbc6":"code","d2eef49e":"code","c304d2c1":"code","48c7196d":"code","6d856f57":"code","8db376b0":"markdown","f2f0997b":"markdown","6470eec4":"markdown","19504f7d":"markdown","41f2e728":"markdown","f8be6167":"markdown","40e90f9d":"markdown","8d770a5e":"markdown","bb8de860":"markdown","906b070f":"markdown","1382eab2":"markdown","349e5d6e":"markdown","232c5a15":"markdown","6c87c720":"markdown","8219ad22":"markdown"},"source":{"eaa368e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a3528f4":"train_data = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/train.csv')\nprint('Number of Training Samples = {}'.format(train_data.shape[0]))","54da3471":"train_data.head()","0da35cee":"test_data = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/test.csv')\nprint('Number of Testing Samples = {}'.format(test_data.shape[0]))","e00bdcec":"test_data.head()","4abdd4c1":"print('\\nMissing values of Train set:\\n', train_data.isnull().sum())\nprint('\\nNull values of Train set:\\n', train_data.isna().sum())","c50d3705":"columns = train_data.columns\nprint(columns)","47efae33":"train_data.fillna(0,inplace = True)\ntest_data.fillna(0,inplace = True)","47814aac":"selected_feature_set_1 = ['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n       'touch_screen', 'wifi'] # Validation accuracy 91.5%\n\nselected_feature_set_2 = ['battery_power', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n       'int_memory', 'n_cores', 'ram', 'talk_time', 'three_g',\n       'touch_screen', 'wifi'] # Validation accuracy 79.25%\n\nselected_feature_set_3 = ['battery_power', 'blue',\n       'int_memory', 'ram', 'sc_h', 'sc_w',\n       'touch_screen', 'wifi'] # Validation accuracy 79.25%\n\nselected_feature_set_4 = ['battery_power', 'blue',  'dual_sim', 'four_g',\n       'int_memory', 'm_dep', 'n_cores', 'pc', 'ram', 'sc_h', 'sc_w', 'three_g',\n       'touch_screen', 'wifi'] # Validation accuracy 80.5%\n\nselected_feature_set_5 = [\n       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n       'touch_screen', 'wifi'] # Validation accuracy 77.75%","8046ede9":"X = train_data[selected_feature_set_1]\nX.head()","d4a28e77":"y = train_data['price_range']\ny.head()","c1251744":"classes = set(y)\nprint(classes)","a0b0dbc6":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np","d2eef49e":"scaler = RobustScaler()\nX = scaler.fit_transform(X)","c304d2c1":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)\nprint(y_train.shape, X_train.shape)\nxgb_model = xgb.XGBClassifier(n_estimators=500)\nxgb_model.fit(X_train, y_train)\ny_pred = xgb_model.predict(X_val)\nprint('Validation accuracy: ', accuracy_score(y_val, y_pred))","48c7196d":"X_test = test_data[selected_feature_set_1]\nX_test.head()","6d856f57":"X_test = scaler.fit_transform(X_test)\nfuture_y_pred = xgb_model.predict(X_test)\nprint(future_y_pred)","8db376b0":"# Dealing with missing values","f2f0997b":"# Training XGB Classifier","6470eec4":"# Listing all the available features","19504f7d":"# Importing packages and the dataset","41f2e728":"# Importing the training data","f8be6167":"# Selecting features for the training data","40e90f9d":"# Checking for missing or null values","8d770a5e":"# Importing required packages","bb8de860":"# Obtaining predictions for test data","906b070f":"# **MOBILE PRICE PREDICTION USING XGB**","1382eab2":"# Preparing test data","349e5d6e":"# Trying different combination of features","232c5a15":"# Creating the output label and checking number of classes","6c87c720":"# Feature scaling","8219ad22":"# Importing the test data"}}