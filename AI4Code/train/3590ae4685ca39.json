{"cell_type":{"4debcd06":"code","11da827a":"code","ae14152c":"code","b799d889":"code","03c15d6b":"code","4295cc03":"code","95d4a12d":"code","341d1ec1":"code","dc1812d2":"code","5f37df76":"code","76c82cc5":"code","bbf32248":"code","724b42fe":"code","aac3040c":"code","85df6d9d":"code","fde1223a":"code","535e4163":"markdown","cbc1564c":"markdown","6d974954":"markdown","b617847c":"markdown","b541ef86":"markdown","405fe78e":"markdown","aca17788":"markdown","40eef0b8":"markdown","9e59d9ff":"markdown","fb46eaa6":"markdown"},"source":{"4debcd06":"import numpy as np\nimport pandas as pd\nimport pylab as plt\nimport seaborn as sns\nimport cv2\nimport os","11da827a":"train = pd.read_csv('..\/input\/train.csv')\ntrain.head()","ae14152c":"img_path='..\/input\/train\/'+train.id[5]+\".png\"\nimage=cv2.imread(img_path)\nimage_rgb=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nhsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\nh,s,v=np.average(hsv_image,axis=(0,1))\n\nplt.subplot(131),plt.imshow(image),plt.title('BGR')\nplt.subplot(132),plt.imshow(image_rgb),plt.title('RBG')\nplt.subplot(133),plt.imshow(hsv_image),plt.title('HSV')","b799d889":"image=cv2.imread(img_path)\nimg=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# Convert BGR to HSV\nhsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n# define range of blue color in HSV\nlower_blue=np.array([20,25,15])\nupper_blue=np.array([130,255,255])\n#Threshold the HSV impage to get only blue colors\nmask=cv2.inRange(hsv_image,lower_blue,upper_blue)\n# Bitwise-And mask and original image\nres = cv2.bitwise_and(img,img,mask=mask)\nplt.subplot(131),plt.imshow(img),plt.title('ORIGINAL')\nplt.subplot(132),plt.imshow(mask),plt.title('Mask')\nplt.subplot(133),plt.imshow(res),plt.title('Res')","03c15d6b":"def mask(img_path):\n    image=cv2.imread(img_path)\n    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    lower_blue=np.array([20,25,15])\n    upper_blue=np.array([130,255,255])\n    mask=cv2.inRange(hsv_image,lower_blue,upper_blue)\n    res = cv2.bitwise_and(img,img,mask=mask)\n    plt.subplot(131),plt.imshow(img),plt.title('ORIGINAL')\n    plt.subplot(132),plt.imshow(mask),plt.title('Mask')\n    plt.subplot(133),plt.imshow(res),plt.title('Res')\n    plt.show()\n    h,s,v=np.average(res,axis=(0,1))\n    print(h, s, v)\n\nfor i in range(5):\n    img_path='..\/input\/train\/'+train.id[i]+\".png\"\n    mask(img_path)","4295cc03":"def image_feature_extracion(img_path):\n    image=cv2.imread(img_path)\n    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    lower_blue=np.array([20,25,15])\n    upper_blue=np.array([130,255,255])\n    mask=cv2.inRange(hsv_image,lower_blue,upper_blue)\n    res = cv2.bitwise_and(img,img,mask=mask)\n    h,s,v=np.average(hsv_image,axis=(0,1))\n    return h,s,v\n\nread_len=1000\nhsv_list=[]\nfor i in range(read_len):    \n    img_path='..\/input\/train\/'+train.id[i]+\".png\"    \n    hsv_list.append(image_feature_extracion(img_path))\n    \nimport seaborn as sns\ndf = pd.DataFrame(hsv_list, columns=[\"Hue\", \"y\",'Brightness(Values)'])\nsns.jointplot(x=\"Hue\", y=\"Brightness(Values)\", data=df)","95d4a12d":"df.head()","341d1ec1":"def image_feature_extracion(img_path,ID):\n    image=cv2.imread(img_path)\n    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    lower_blue=np.array([20,25,15])\n    upper_blue=np.array([130,255,255])\n    mask=cv2.inRange(hsv_image,lower_blue,upper_blue)\n    res = cv2.bitwise_and(img,img,mask=mask)\n    h,s,v=np.average(hsv_image,axis=(0,1))\n    return ID,h,s,v\n\nread_len=10000 #109237\nhsv_list=[]\nfor i in range(read_len):    \n    img_path='..\/input\/train\/'+train.id[i]+\".png\"\n    ID=train.id[i]\n    hsv_list.append(image_feature_extracion(img_path,ID))\n\ndf = pd.DataFrame(hsv_list, columns=[\"ID\",\"Hue\", \"y\",'Brightness(Values)'])\ndf.head()","dc1812d2":"df.shape","5f37df76":"train['attribute_ids'].head()","76c82cc5":"train[\"attribute_ids\"] = train[\"attribute_ids\"].apply(lambda x:x.split(\" \"))\ntrain['attribute_ids'].head()","bbf32248":"labels = pd.read_csv('..\/input\/labels.csv')\nlabels.shape","724b42fe":"train_labels = []\nfor label in train['attribute_ids'][:10000].values:\n    zeros = np.zeros(labels.shape[0])\n    for label_i in label:\n        zeros[int(label_i)] = 1\n    train_labels.append(zeros)\n    \ntrain_labels = np.asarray(train_labels)\ntrain_labels","aac3040c":"train_labels.shape","85df6d9d":"Y = train_labels\nfeatures = ['Hue','y','Brightness(Values)']\nX = df[features]\nprint(Y.shape,X.shape)","fde1223a":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X, Y)\nsns.set(style=\"darkgrid\")\nfig, ax = plt.subplots(figsize=(6,6))\ny_pos = np.arange(len(features))\nplt.barh(y_pos, model.feature_importances_, align='center', alpha=0.4)\nplt.yticks(y_pos, features)\nplt.xlabel('features')\nplt.title('feature_importances')\nplt.show()","535e4163":"# Data Import","cbc1564c":"Thanks for DHTT's kernel(https:\/\/www.kaggle.com\/d5195295\/hsv-analysis). After background remove, let's check the destribution of feature:","6d974954":"We use 10000 images to extract the feature. All image used will be long time.","b617847c":"# iMet EDA\nThe Metropolitan Museum of Art in New York, also known as The Met , is the largest art museum in the United States. With 6,953,927 visitors in 2018. Including me is also attracted, I went to visit on 2019\/05 with my wife and 3 kids. My children are very interested in Egyptian artifacts and have been in the exhibition area for a long time.\n\nIts permanent collection contains over two million works of which over 200K have been digitized with imagery.\n\nThe online cataloguing information is generated by Subject Matter Experts (SME) and includes a wide range of data. SME can also be indirect in describing finer-grained attributes from the museum-goer\u2019s understanding. Adding fine-grained attributes to aid in the visual understanding of the museum objects will enable the ability to search for visually related objects.\n\nIn this study, we tried to extract the feature of image and analysis the feature by each attributes. Simple method (Random Forest) was performed and I hope it is useful for Machine Learningers.\n\n<img style=\"float: left;\" src=\"https:\/\/drive.google.com\/uc?export=view&id=1xLUWwsOJNRU-n0tPG7WH7UJlgCOpQAph\" width=\"65%\">","b541ef86":"# Data Exploration\nWe explore the image by 3 view: BGR\/RBG\/HSV","405fe78e":"# Feature Analysis","aca17788":"# Data Preprocess\nWe try to remove the background of image and let the object clear. First, we convert BGR image to HSV, we can use this to extract a colored object. In HSV, it is more easier to represent a color than RGB color-space. In our application, we will try to extract a background colored object. So here is the method:\n\n* Convert from BGR to HSV color-space\n* We threshold the HSV image for a range of color\n* Now extract the object alone, we can do whatever on that image we want.","40eef0b8":"# Data Preproces for Labels","9e59d9ff":"We analysis the feature by Random Forest. The brightness is the most important factor, followed by Saturation and Hue. The analysis results show that different luminance of target causing the observer to have different perceptions of the object.","fb46eaa6":"Let's do the same thing in 5 image and check how the oject had been extract:"}}