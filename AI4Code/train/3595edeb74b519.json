{"cell_type":{"31e5105b":"code","c8a797e8":"code","b2ee19aa":"code","c457d75f":"code","4950eec2":"code","33aa8268":"code","0e81d745":"code","5a699c7b":"code","c2a8f20d":"code","a61a6317":"code","8169bf4d":"code","00c4504e":"code","52227626":"code","701432e2":"code","8c021ea8":"code","41289b8d":"code","0c2a671e":"code","65def98a":"markdown","cafa91c6":"markdown","2e1add88":"markdown","e798acbc":"markdown","8d8ca662":"markdown","c6c7a797":"markdown","1a6d5421":"markdown","10ed085a":"markdown","71894fd3":"markdown","3026c428":"markdown","a30bc32f":"markdown"},"source":{"31e5105b":"!pip install pyspark --q","c8a797e8":"#Generic Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Apache Spark Libraries\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import IntegerType\n\n#Apache Spark ML CLassifier Libraries\nfrom pyspark.ml.classification import NaiveBayes\n\n#Apache Spark Evaluation Library\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n#Apache Spark Features libraries\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer\nfrom pyspark.ml.feature import Word2Vec\n\n#Apache Spark Pipelin Library\nfrom pyspark.ml import Pipeline\n\n#Apache Spark Fine Tuning Libraries\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n\n#Gensim Library for Text Processing\nimport gensim.parsing.preprocessing as gsp\nfrom gensim import utils\n\n\n\n#Tabulating Data\nfrom tabulate import tabulate\n\n#Garbage\nimport gc\n\n#Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b2ee19aa":"#Building Spark Session\nspark = (SparkSession.builder\n                  .appName('Restaurant Reviews Text Classification using Pyspark')\n                  .config(\"spark.executor.memory\", \"1G\")\n                  .config(\"spark.executor.cores\",\"4\")\n                  .getOrCreate())\n\n# Logging Level\nspark.sparkContext.setLogLevel('INFO')","c457d75f":"url = '..\/input\/restaurant-reviews\/Restaurant_Reviews.csv'\n\ndata = spark.read.csv(url, header=True, inferSchema=True)","4950eec2":"#total records\ndata.count()","33aa8268":"#Data Types\ndata.printSchema()","0e81d745":"#Converting Liked column data to integer\ndata = data.withColumn('Liked', data['Liked'].cast(IntegerType()))","5a699c7b":"#Records per Liked column\ndata.groupby('Liked').count().show()","c2a8f20d":"# Filling the null value with 0\ndata = data.fillna(0)","a61a6317":"#inspect data\ndata.show(5)","8169bf4d":"# Create list of pre-processing func\nprocesses = [\n           gsp.strip_tags, \n           gsp.strip_punctuation,\n           gsp.strip_multiple_whitespaces,\n           gsp.strip_numeric,\n           gsp.remove_stopwords, \n           gsp.strip_short, \n           gsp.stem_text\n          ]\n\n# Create func to pre-process text\ndef proc_txt(txt):\n    text = txt[0]\n    text = text.lower()  #lowering the case\n    text = utils.to_unicode(text)\n    for p in processes:\n        text = p(text)\n    return (text,txt[1])    \n        ","00c4504e":"#Creating a temp dataset with processed data\ntemp_ds = data.rdd.map(lambda x : proc_txt(x))\n\n# Create a new Dataset\ndata_proc = temp_ds.toDF(['Proc_Review','Liked'])\n\n#Inspect New Dataset\ndata_proc.show(5)","52227626":"# Split the processed data into 90-10 ratio [90% - Training & 10% - Validation]\ntrain_data, test_data = data_proc.randomSplit([0.9, 0.1])","701432e2":"#TF-IDF Vectorizing\ntok = Tokenizer(inputCol='Proc_Review', outputCol='Tok_Review')\nhashT = HashingTF(inputCol=tok.getOutputCol(), outputCol='raw_features_tf', numFeatures=30)\nidf = IDF(inputCol=hashT.getOutputCol(), outputCol='Features_tf', minDocFreq=5)\n\n#Create a TF-IDF pipeline\ntf_pipe = Pipeline(stages=[tok, hashT, idf])","8c021ea8":"#Fit TF-IDF Pipeline to Training & Test Data\ntf_mod = tf_pipe.fit(train_data)\n\n#Transforming the data\ntrain_data = tf_mod.transform(train_data)\ntest_data = tf_mod.transform(test_data)","41289b8d":"#Function to Create, Traing & Evaluate Multinomial NB Model\n\ndef mnb_mod(train,test):\n    \n    # Build Seperate Models for TF-IDF & Word2Vec\n    mnb_tf = NaiveBayes(smoothing=1.0, labelCol='Liked',featuresCol='Features_tf', modelType=\"multinomial\")\n    \n    # Fit the Models to Train Data\n    mnb_mod_tf = mnb_tf.fit(train)\n    \n    # Make Predictions\n    pred_tf = mnb_mod_tf.transform(test)\n    \n    # Evaluation\n    mnb_eval = BinaryClassificationEvaluator(labelCol='Liked')\n    \n    acc_tf = mnb_eval.evaluate(pred_tf)\n    \n    print(\"Multinomial Naive Bayes Model Accuracy =\", '{:.2%}'.format(acc_tf))\n        \n\n    \n#Applying the Function to vectorized data\nmnb_mod(train_data,test_data)","0c2a671e":"# Fine Tuning the model using Cross Validator & ParamBuilder\n\ndef MNB_CV(train,test):\n    \n    mnb = NaiveBayes(smoothing=1.0, labelCol='Liked',featuresCol='Features_tf', modelType=\"multinomial\")\n    \n    pipe = Pipeline(stages= [mnb])\n    \n    paramGrid = ParamGridBuilder().addGrid(mnb.smoothing, [1.0, 2.0, 3.0]).build()\n    \n    evaluate = BinaryClassificationEvaluator(labelCol=\"Liked\")\n    \n    crossValidator = CrossValidator(estimator=pipe,\n                                        evaluator=evaluate,\n                                        estimatorParamMaps=paramGrid,\n                                        numFolds=10)\n    \n    # use the Multinomial Model to train (fit) the model\n    # and Get the best Multinomial Naive Bayes model\n\n    cv = crossValidator.fit(train)\n    tuned_mod = cv.bestModel.stages[0]\n\n    predict = tuned_mod.transform(train)\n\n    acc_new = evaluate.evaluate(predict)\n    \n    print(\"Multinomial Naive Bayes Model Accuracy (fine tuned) =\", '{:.2%}'.format(acc_new)) \n\n\n# Applying the function to train & test data\nMNB_CV(train_data,test_data)\n","65def98a":"![](http:\/\/)![](https:\/\/cdn130.picsart.com\/322267252359201.jpg?type=webp&to=min&r=640)\nWhat to say, the fine tuning was not tuned finely ","cafa91c6":"# Restaurant Reviews Text Classification using PySpark\n\nIn this notebook, we will try to perform a text classification on the restaurant reviews using PySpark.","2e1add88":"## Data Load","e798acbc":"## Build Spark Session","8d8ca662":"## Build, Train & Evaluate Model","c6c7a797":"## Feature Extraction (with TF-IDF Vectorizer)","1a6d5421":"## Text Pre-Processing","10ed085a":"## Fine Tuning Model","71894fd3":"## Data Split","3026c428":"## Data Exploration & Preparation","a30bc32f":"## **Libraries**"}}