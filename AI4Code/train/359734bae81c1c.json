{"cell_type":{"c2a2025a":"code","2263cb54":"code","672849ab":"code","75d57056":"code","3f32c4b1":"code","0724a681":"code","a2cc9c8c":"code","9fb317d4":"code","9c915226":"code","8615ab66":"code","ec9d700e":"code","e1c6a0ea":"code","4b033928":"code","07a932d9":"code","44497efb":"code","69864849":"code","4e7bbdfa":"code","36e3bcad":"code","61521f4d":"code","2273f67b":"code","362faa1e":"code","75afc7d8":"code","747030b7":"code","461c43dd":"code","190e1a3a":"code","68bfe044":"code","8b2f9ab3":"code","b320fec1":"code","683c96bf":"code","ba1eb768":"code","f578006a":"code","7d41955f":"code","9e9d57ef":"code","146f4df5":"code","32a206a3":"code","f02addd6":"code","9e1c42f3":"code","046dd26b":"code","6f95fc4e":"code","819fdae0":"code","2af30fd2":"code","30093bcf":"code","e25721f1":"code","96d0ef2c":"code","1fef0e04":"code","caa671af":"code","8ad93ef2":"code","1011742f":"code","371d0cca":"code","2ae2652d":"code","d27c2ca5":"code","7fc1a85b":"code","fec1c0f6":"code","aa8a7ca7":"code","54ed8443":"code","12c9702b":"code","4f84e8d1":"code","282765cc":"code","c56c1d4f":"code","2cfaf9a7":"code","6cfd3db6":"code","e8db3380":"code","7c616bf9":"code","66ddc652":"code","4e214f43":"code","82a99226":"code","456f5194":"code","c0489c26":"code","eb541f30":"code","80488419":"code","d9ed1e02":"code","a555ebc0":"code","95ff3a90":"code","aa41b1e7":"code","adfd9b5a":"code","f6307ef1":"code","f21922a0":"code","b4e9b767":"code","1b268bcb":"code","78ab1ae5":"code","9614ebf8":"code","a540c359":"code","2af963ea":"code","e5e9620c":"code","fa2c86e8":"code","75916f50":"code","02882646":"code","f98e3867":"code","750161d9":"code","7189286f":"code","1714d524":"code","2a0e8f99":"code","70e9eafc":"code","62429e2a":"code","44b3169b":"code","1a60ec5b":"code","ef27f38a":"code","b25f8e70":"code","5c1894db":"code","78bcde09":"markdown","c23d5765":"markdown","373b864d":"markdown","792e4880":"markdown","eb6a2908":"markdown","915e7ec3":"markdown","010b7d5a":"markdown","06b73131":"markdown","0bfe86d4":"markdown","d067c360":"markdown","ecf5f8b3":"markdown","30ea4288":"markdown","89479648":"markdown","d68c7626":"markdown","cccf6e07":"markdown","7cb0ed44":"markdown","697e7ced":"markdown","b9f52c51":"markdown","d4469a14":"markdown","93fa55e4":"markdown","202ddc61":"markdown","ca0470b8":"markdown","1b31dc78":"markdown","5a81201d":"markdown","a05d3e4e":"markdown","a32197ae":"markdown","bffa02f0":"markdown","a2640f70":"markdown","0c8ddf28":"markdown","55ee5fe8":"markdown","4d70ff6e":"markdown","bac67a47":"markdown","b933760b":"markdown","29797a72":"markdown","ccb91167":"markdown","4696d0eb":"markdown","7c2f8223":"markdown","4db0a7ca":"markdown","318b728f":"markdown","b81cb2cb":"markdown","b0d20562":"markdown","7257af36":"markdown","161ecf94":"markdown","2216384f":"markdown","16aa99fb":"markdown","807dba38":"markdown","12aadff4":"markdown","cea8fcc1":"markdown","8cfff287":"markdown","e6a1b672":"markdown","42961348":"markdown","b9134f23":"markdown","647a906e":"markdown","cdb1f61f":"markdown","51228c7c":"markdown","ae7966be":"markdown","89d63034":"markdown","8770f0f1":"markdown","3cd5b336":"markdown","37b85cf4":"markdown","7ce04ef7":"markdown","64bf2359":"markdown","d5cbe9fb":"markdown","4e73b8bd":"markdown","a7a5d0ae":"markdown","3a09fb64":"markdown","5ddc6e61":"markdown","28252793":"markdown","9fc34127":"markdown","5eefb512":"markdown","08cadd58":"markdown","79561cb2":"markdown","2ae42c18":"markdown","124be895":"markdown","e371a257":"markdown","b2b126b0":"markdown","73dc02b7":"markdown","af23652e":"markdown","1678bc11":"markdown","30752b96":"markdown","35f5df35":"markdown","6ce6610f":"markdown","211494ad":"markdown","0649d7a1":"markdown","0c280236":"markdown","fab21cd5":"markdown","a106c907":"markdown","5325502e":"markdown","c4108eab":"markdown","9e2be055":"markdown","a0ad2403":"markdown"},"source":{"c2a2025a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils import resample\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n    \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2263cb54":"df = pd.read_csv('..\/input\/noshowappointments\/KaggleV2-May-2016.csv')\n","672849ab":"print(df.head(5))","75d57056":"print(df.columns)","3f32c4b1":"print(df.info())","0724a681":"print(df.shape)","a2cc9c8c":"df.describe()","9fb317d4":"df[\"No-show\"].value_counts()","9c915226":"fig = df[\"No-show\"].value_counts().plot(kind=\"bar\")\nfig.set_ylabel(\"Zahl der Patienten\")\nfig.set_xlabel(\"Patienten nehmen Termin nicht wahr\")","8615ab66":"NoShowData = df[\"No-show\"].value_counts()\nlabels1 = \"Nimmt Termin wahr\",\"Nimmt Termin nicht wahr\"\nplt.pie(NoShowData,labels=labels1, autopct=\"%1.1f%%\")\nplt.title(\"No Show Data\")\nplt.show()","ec9d700e":"Geschlechter = df[\"Gender\"].value_counts()\nlabels2 = \"Weiblich\",\"M\u00e4nnlich\"\nplt.pie(Geschlechter,labels=labels2, autopct=\"%1.1f%%\")\nplt.title(\"Geschlechter Aufteilung\")\nplt.show()","e1c6a0ea":"first = sns.PairGrid(df, y_vars=\"Age\", x_vars=[\"Diabetes\", \"Hipertension\"])\nfirst.map(sns.regplot)","4b033928":"Hypertension = df[\"Hipertension\"].value_counts()\nlabels3 = \"No\",\"Yes\"\nplt.pie(Hypertension,labels=labels3, autopct=\"%1.1f%%\")\nplt.title(\"Hipertension\")\nplt.show()","07a932d9":"Diabetes = df[\"Diabetes\"].value_counts()\nlabels4 = \"No\",\"Yes\"\nplt.pie(Diabetes,labels=labels4, autopct=\"%1.1f%%\")\nplt.title(\"Diabetes\")\nplt.show()","44497efb":"Alcoholism = df[\"Alcoholism\"].value_counts()\nlabels5 = \"No\",\"Yes\"\nplt.pie(Alcoholism,labels=labels5, autopct=\"%1.1f%%\")\nplt.title(\"Alcoholism\")\nplt.show()","69864849":"Scholarship = df[\"Scholarship\"].value_counts()\nlabels6 = \"No\",\"Yes\"\nplt.pie(Scholarship,labels=labels6, autopct=\"%1.1f%%\")\nplt.title(\"Scholarship\")\nplt.show()","4e7bbdfa":"print(df.isna().sum()) ","36e3bcad":"df = df[(df.Age >= 0) & (df.Age <= 100)]","61521f4d":"df.describe()","2273f67b":"df.PatientId = df.PatientId.astype(\"int\")","362faa1e":"df.info()","75afc7d8":"df[\"No-show\"] = df[\"No-show\"].replace({\"No\":0, \"Yes\":1})\ndf = df.rename(columns={\"No-show\":\"Noshow\"})","747030b7":"df = df.rename(columns={\"Gender\":\"Male\"})\ndf[\"Male\"] = df[\"Male\"].replace({\"F\":0, \"M\":1})","461c43dd":"df.info()","190e1a3a":"neighbourhoods = df[\"Neighbourhood\"]\nneighbourhoods_df = pd.DataFrame(neighbourhoods, columns =[\"Neighbourhood\"])","68bfe044":"labelencoder = LabelEncoder()\nneighbourhoods_df[\"NeighbourhoodNumbers\"] = labelencoder.fit_transform(neighbourhoods_df[\"Neighbourhood\"])","8b2f9ab3":"neighbourhoods_df","b320fec1":"df[\"NeighbourhoodNumbers\"] = neighbourhoods_df[\"NeighbourhoodNumbers\"]","683c96bf":"del df[\"Neighbourhood\"]","ba1eb768":"df.info()","f578006a":"df.ScheduledDay = pd.to_datetime(df.ScheduledDay)\ndf.AppointmentDay = pd.to_datetime(df.AppointmentDay)","7d41955f":"df[\"ScheduledTime\"] = pd.to_datetime(df.ScheduledDay).dt.time\ndf[\"AppointmentTime\"] = pd.to_datetime(df.AppointmentDay).dt.time","9e9d57ef":"df['ScheduledDay'] = df['ScheduledDay'].dt.date\ndf['AppointmentDay'] = df['AppointmentDay'].dt.date","146f4df5":"df['AppointmentWeekday'] = pd.to_datetime(df.AppointmentDay).dt.day_name()\ndf['AppointmentMonth'] = pd.to_datetime(df.AppointmentDay).dt.month_name()","32a206a3":"df.info()","f02addd6":"df[\"Waitingdays\"] = df.AppointmentDay - df.ScheduledDay\n","9e1c42f3":"df['Waitingdays'] = df['Waitingdays'].dt.days.astype('int')","046dd26b":"df","6f95fc4e":"df.AppointmentTime.nunique()\n","819fdae0":"df.drop(columns=\"AppointmentTime\", inplace=True)","2af30fd2":"df.info()","30093bcf":"df.drop(columns=\"ScheduledDay\", inplace=True)\ndf.drop(columns=\"ScheduledTime\", inplace=True)","e25721f1":"AppointmentDates = df[\"AppointmentDay\"]\nAppointmentDates_df = pd.DataFrame(AppointmentDates, columns =[\"AppointmentDay\"])\nAppointmentDates_df[\"AppointmentDateNumbers\"] = labelencoder.fit_transform(AppointmentDates_df[\"AppointmentDay\"])","96d0ef2c":"df[\"AppointmentDateNumbers\"] = AppointmentDates_df[\"AppointmentDateNumbers\"]","1fef0e04":"del df[\"AppointmentDay\"]","caa671af":"df.info()","8ad93ef2":"AppointmentWeekdays = df[\"AppointmentWeekday\"]\nAppointmentWeekday_df = pd.DataFrame(AppointmentWeekdays, columns =[\"AppointmentWeekday\"])\nAppointmentWeekday_df[\"AppointmentWeekdayNumbers\"] = labelencoder.fit_transform(AppointmentWeekday_df[\"AppointmentWeekday\"])\n","1011742f":"AppointmentMonths = df[\"AppointmentMonth\"]\nAppointmentMonth_df = pd.DataFrame(AppointmentMonths, columns =[\"AppointmentMonth\"])\nAppointmentMonth_df[\"AppointmentMonthNumbers\"] = labelencoder.fit_transform(AppointmentMonth_df[\"AppointmentMonth\"])\n","371d0cca":"df[\"AppointmentWeekdayNumbers\"] = AppointmentWeekday_df[\"AppointmentWeekdayNumbers\"]\ndf[\"AppointmentMonthNumbers\"] = AppointmentMonth_df[\"AppointmentMonthNumbers\"]\n\ndel df[\"AppointmentWeekday\"]\ndel df[\"AppointmentMonth\"]","2ae2652d":"df.info()","d27c2ca5":"plt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","7fc1a85b":"X = df[[\"PatientId\", \"Male\", \"Age\", \"Scholarship\", \"Hipertension\", \"Diabetes\", \"Alcoholism\", \"Handcap\", \"SMS_received\", \"NeighbourhoodNumbers\", \"Waitingdays\", \"AppointmentDateNumbers\", \"AppointmentWeekdayNumbers\", \"AppointmentMonthNumbers\"]]\ny = df[\"Noshow\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)","fec1c0f6":"print(\"Shape of X_train:\", X_train.shape)\nprint(\"Shape of X_test:\", X_test.shape)\nprint(\"Shape of y_train:\", y_train.shape)\nprint(\"Shape of y_test:\", y_test.shape)","aa8a7ca7":"knn = KNeighborsClassifier()","54ed8443":"params = {\n    'n_neighbors' : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\n    'weights': ['uniform', 'distance']\n}\n\ngrid_clf = GridSearchCV(estimator = knn,\n                        param_grid = params,\n                        scoring = 'accuracy',\n                        verbose = 1,\n                        n_jobs = -1)","12c9702b":"grid_clf.fit(X_train, y_train)","4f84e8d1":"grid_clf.best_estimator_","282765cc":"best_n_neighbors = grid_clf.best_params_['n_neighbors']  \nbest_weights      = grid_clf.best_params_['weights']\n\n\nprint(f\"Beste Cross-Validation Klassifikationsgenauigkeit: {grid_clf.best_score_:.3f}\")\nprint(f\"Bester n_neighbors Wert: {best_n_neighbors}\")\nprint(f\"Bester weights Wert: {best_weights}\")","c56c1d4f":"grid_clf.score(X_test, y_test)","2cfaf9a7":"knn = KNeighborsClassifier(n_neighbors=24, weights='uniform')","6cfd3db6":"knn.fit(X_train, y_train)","e8db3380":"y_pred = knn.predict(X_test)","7c616bf9":"cm = metrics.confusion_matrix(y_test, y_pred)\nprint(cm)\n","66ddc652":"cmd = ConfusionMatrixDisplay(cm)\ncmd.plot()","4e214f43":"print(classification_report(y_test, y_pred))","82a99226":"df_majority = df[df.Noshow==0]\ndf_minority = df[df.Noshow==1]","456f5194":"df_minority_upsampled = resample(df_minority,\n                                replace = True,\n                                n_samples = 88203,\n                                random_state = 42)","c0489c26":"df_upsampled = pd.concat([df_majority, df_minority_upsampled])","eb541f30":"df_upsampled.Noshow.value_counts()","80488419":"y = df_upsampled[\"Noshow\"]\nX = df_upsampled[[\"PatientId\", \"Male\", \"Age\", \"Scholarship\", \"Hipertension\", \"Diabetes\", \"Alcoholism\", \"Handcap\", \"SMS_received\", \"NeighbourhoodNumbers\", \"Waitingdays\", \"AppointmentDateNumbers\", \"AppointmentWeekdayNumbers\", \"AppointmentMonthNumbers\"]]","d9ed1e02":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)","a555ebc0":"grid_clf.fit(X_train, y_train)","95ff3a90":"grid_clf.best_estimator_","aa41b1e7":"knn2 = KNeighborsClassifier(n_neighbors=2, weights='distance')","adfd9b5a":"knn2.fit(X_train, y_train)","f6307ef1":"y_pred1 = knn2.predict(X_test)","f21922a0":"cm = metrics.confusion_matrix(y_test, y_pred1)\nprint(cm)","b4e9b767":"cmd = ConfusionMatrixDisplay(cm)\ncmd.plot()","1b268bcb":"class1 = classification_report(y_test, y_pred1)","78ab1ae5":"print(class1)","9614ebf8":"dtc = DecisionTreeClassifier()\n\nparams = {'max_depth': np.arange(1, 20, 1),\n         'criterion': ['gini', 'entropy'],\n         'min_samples_leaf': np.arange(1,6, 1)}","a540c359":"grid_dtc = GridSearchCV(estimator=dtc,\n                       param_grid=params,\n                       scoring='accuracy',\n                       return_train_score=True,\n                       verbose=1,\n                       cv=5,\n                       n_jobs= -1)","2af963ea":"grid_dtc.fit(X_train, y_train)","e5e9620c":"grid_dtc.best_params_","fa2c86e8":"grid_dtc.best_score_","75916f50":"dtc = DecisionTreeClassifier(criterion = \"gini\", max_depth = 19, min_samples_leaf = 1)","02882646":"fitted=dtc.fit(X_train, y_train)","f98e3867":"y_pred2 = dtc.predict(X_test)","750161d9":"feature_names = list(X.columns)\nclass_names = list(y.unique())\n\nfeature_names = [str(x) for x in feature_names]\nclass_names = [str(x) for x in class_names]\n","7189286f":"print(feature_names)\nprint(class_names)","1714d524":"from sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(40,30))\nplot_tree(dtc, max_depth=4, filled=True, class_names=class_names, feature_names=feature_names, fontsize=10)\nplt.show()","2a0e8f99":"class2 = classification_report(y_test, y_pred2)\nprint(class2)","70e9eafc":"cm1 = metrics.confusion_matrix(y_test, y_pred2)\nprint(cm1)","62429e2a":"from sklearn.metrics import ConfusionMatrixDisplay","44b3169b":"cmd1 = ConfusionMatrixDisplay(cm1)\ncmd1.plot()","1a60ec5b":"print(class1)","ef27f38a":"print(class2)","b25f8e70":"cmd.plot(cmap=\"Blues\")","5c1894db":"cmd1.plot(cmap=\"Blues\")","78bcde09":"\n# 3. Datenverst\u00e4ndnis (Exploratory Data Analysis)","c23d5765":"Es gibt keine fehlenden Daten.","373b864d":"Daf\u00fcr m\u00fcssen wir die beiden Spalten erstmal in ein anderen Type umwandeln, und zwar DateTime.\nQuelle: Pandas,\u201epandas.to_datetime\u201c ","792e4880":"Dann wird die minority Klasse hochgesetzt, indem wir n_samples so bestimmen, dass die Samples von der Majority Klasse und der Minority Klasse gleich sind. In unserem Fall also 88203.","eb6a2908":"Nun wiederholen wir die Vorg\u00e4nge von vorher mit den gesampelten Klassen.","915e7ec3":"# Analyse von fehlenden Daten","010b7d5a":"Da wir nicht denken, dass der Tag und die Zeit des Tag, an dem der Termin vereinbart wurde, l\u00f6schen wir \"ScheduledDay\" und \"ScheduledTime\" aus dem DataFrame.","06b73131":"\"AppointmentTime\" sieht so aus, als w\u00e4ren alle Werte gleich. Dies wird \u00fcberpr\u00fcft.\nQuelle: Pandas, \u201epandas.Series.nunique\u201c ","0bfe86d4":"Hier sieht man die Confusion Matrix des KNN Modelles. Wie man sieht sind die True Negatives und die True Positives sehr hoch. Von 35207 Patienten, die zu einem Termin kommen, werden 8676 f\u00e4lschlicherweise als Patienten vorhergesagt, die einen Termin nicht wahrnehmen.\nVon 35356 Patienten, die nicht zu einem Termin erscheinen, werden aber nur 2342 f\u00e4lschlicherweise als Patienten vorhergesagt, die den Termin wahrnehmen. Nat\u00fcrlich ist die Vorhersage nicht unbedingt perfekt, aber schon ziemlich gut.","d067c360":"Bestimmen von Feature_names und class_names --> Feature_names sind die Spalten von X. Class_names sind die Werte, die wir y gegeben haben, also die Noshow Werte. Wir haben diese Werte in eine Liste umgewandelt und au\u00dferdem die Werte in feature_names und class_names in strings umgewandelt, damit der Decision Tree dargestellt werden kann.","ecf5f8b3":"# 7. M\u00f6glicher Gesch\u00e4ftseinsatz","30ea4288":"Nun sehen wir, dass wir die Spalte NeighbourhoodNumbers hinzugef\u00fcgt haben, diese enth\u00e4lt nur numerische Werte","89479648":"Das wichtigste Merkmal zeigt die \"No-show\" Spalte","d68c7626":"Leider zeigt uns die Correlation Heatmap keine gro\u00dfen Zusammenh\u00e4nge zwischen den einzelnen Features und dem No-show Features. Also versuchen wir auf eine andere Weise die wichtigen Features herauszustellen.","cccf6e07":"Nun haben wir ein neues Feature namens \"Waitingdays\" hinzugef\u00fcgt.","7cb0ed44":"# KNN Modell ","697e7ced":"# 4. Datenaufbereitung ","b9f52c51":"Dann nutzen wir erneut den LabelEncoder, um die Spalte \"AppointmentDay\" in numerische Werte umzuwandeln. Dabei gehen wie vor, wie weiter oben bei der \"Neighbourhood\" Spalte","d4469a14":"Precision ist die F\u00e4higkeit des Modells die Vorhersagen richtig zu treffen, also wenn eine Instanz negativ ist, sie nicht f\u00e4lschlicherweise als positiv zu bezeichnen. \nRecall ist die F\u00e4higkeit des Modelles alle positiven F\u00e4lle zu finden, also wie hoch ist die Prozent Zahl die positiven F\u00e4lle zu finden.\nDer F1 Score sagt aus, wie viel Prozent der positiven Vorhersagen wirklich korrekt waren. Am besten ist ein F1 Score von 1.0, am schlechtesten ist ein Score von 0.0.\nSupport zeigt die Anzahl der Werte in der Klasse, unbalancierter Support weist auf strukturelle Fehler hin oder unausbalancierte Klassen.\nIm Gesch\u00e4ftssinn ist hier daran zu denken, dass die Positives hier die Aussage machen, dann jemand nicht zu einem Termin erscheint also Yes they don't show!","93fa55e4":"Die Features \"AppointmentId\", \"ScheduledTime\" und \"ScheduledDay\" wurden schon rausgel\u00f6scht, da jede Zeile einen anderen Wert hat und die Spalte somit nicht aussagekr\u00e4ftig ist und die Spalten \"ScheduledTime\" und \"ScheduledDay\" f\u00fcr uns nicht relevant erscheinen.\nAuch wenn die PatientenId ebenfalls rausgel\u00f6scht werden kann, behalten wir dieses Feature bei, da es sein kann, dass ein Patient \u00f6fter nicht erscheint und somit ein Zusammenhang mit dem \"No-show\" Feature erkennbar sein kann. \n","202ddc61":"# Beschreibung des Datensatzes","ca0470b8":"Bestimmung der Parameter","1b31dc78":"Dann werden mit jedem Set der Parameter die Daten trainiert.","5a81201d":"Die Confusion Matrix sieht nun viel sinnvoller aus!","a05d3e4e":"Wir erstellen aus den Ergebnissen eine ConfusionMatrix, um die Ergebnisse der Vorhersage genauer zu begutachten.","a32197ae":"Die ConfusionMatrix des Decision Trees sieht etwas anders aus. Durch die gleichen Farben, kann man sehen, dass bei beiden Confusion Matritzen das True Negative ziemlich hoch ist. Bei dieser Matrix ist der Wert aber etwas niedriger und somit die falsch Vorhersagen, also die False Negatives, nat\u00fcrlich h\u00f6her sind. Auch die True Positives sind niedriger und die False Positives h\u00f6her.","bffa02f0":"Das KNN Modell ist ein Verfahren um Daten zu klassifizieren. Dabei werden zu einem neuen Punkt die k n\u00e4chsten Nachbarn bestimmt, in unserem Fall haben wir 24 n\u00e4chste Nachbarn bestimmt. Wir nutzen ein kNN Modell, da es du den unkompliziertesten Modellarten geh\u00f6rt. Da unser Datensatz nicht allzu gro\u00df ist, k\u00f6nnen wir das kNN Modell nutzen.\nDie Klasse, die unter den k Nachbarn am h\u00e4ufigsten vorkommt wird die Klasse, zu der der neue Punkt geh\u00f6rt. Der richtige Wert f\u00fcr k ist wichtig, da ein zu niedriger Wert anf\u00e4llig f\u00fcr Varianz, also daf\u00fcr, dass einzelne Punkte falsch klassifiziert werden, ist. Wenn k zu gro\u00df gew\u00e4hlt ist, so kommt es zu Overfitting. Dadurch wird das Modell zu flexibel und das Modell lernt sozusagen das Rauschen der Daten, wodurch es zu falschen Vorhersagen kommen kann.","a2640f70":"Hier geben wir dann nochmal zusammengefasst die beiden besten Hyperparameter aus und auch die Klassifikationsgenauigkeit, die mit diesen erreicht wird.","0c8ddf28":"Quellenangabe: \nElite Data Science,  (keine Angabe) \u201eHow to Handle Imbalanced Classes in Machine Learning\u201c URL: https:\/\/elitedatascience.com\/imbalanced-classes [29.01.2022]\n\nMatplotlib, \u201eBasic Pie Chart\u201c  URL: https:\/\/matplotlib.org\/stable\/gallery\/pie_and_polar_charts\/pie_features.html [26.01.2022]\n\nPandas, \u201epandas.Series.dt.date\u201c URL: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.dt.date.html [26.01.2022]\n\nPandas, \u201epandas.Series.dt.day_name\u201c URL: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.dt.day_name.html [26.01.2022]\n\nPandas, \u201epandas.Series.dt.month_name\u201c URL: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.dt.month_name.html [26.01.2022]\n\nPandas, \u201epandas.Series.nunique\u201c URL:  https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.nunique.html [26.01.2022]\n\nPandas, \u201epandas.Series.dt.time\u201c URL: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.Series.dt.time.html [26.01.2022]\n\nPandas, \u201epandas.to_datetime\u201c URL: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.to_datetime.html [26.01.2022]\n\nYadav, D. (2019), \"Categorical encoding using Label-Encoding and One-Hot-Encoder\" URL: https:\/\/towardsdatascience.com\/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd [26.01.2022]\n","55ee5fe8":"Au\u00dferdem werden die Merkmale Wochentag und Monat in den Spalten \"AppointmentWeekday\" und \"AppointmentMonth\" gespeichert.\nQuellen: \nPandas, \u201epandas.Series.dt.day_name\u201c\nPandas, \u201epandas.Series.dt.month_name\u201c ","4d70ff6e":"Der Datensatz hat 14 Spalten und 110527 Zeilen. Die Spalten sind: 'PatientId', 'AppointmentID', 'Gender', 'ScheduledDay','AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension', 'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'No-show'","bac67a47":"Ersten f\u00fcnf Zeilen des DataFrames:\n","b933760b":"Also zusammenfassend kann man sagen, dass das KNN Modell hier besser geeignet ist, aber erst nachdem die Klassen ausgeglichen wurden. Es hat die h\u00f6chste Genauigkeit der beiden Modelle und auch wenn es nur kleine Unterschiede in den Modellen gibt, sind wir der Meinung, dass diese kleinen Unterschiede, das KNN Modell um einiges besser f\u00fcr die Vorhersagen unseres Gesch\u00e4ftsproblems macht.","29797a72":"Zuerst passen wir auch bei dem Decision Tree die HyperParameter an, um die optimalen Parameter zu finden nutzen wird wieder den GridSearch.","ccb91167":"Das genaueste Ergebnis erhalten wir, wenn wir 24 Nachbarn festlegen.","4696d0eb":"Dann werden die DataFrames wieder zusammen in ein DataFrame gesetzt.","7c2f8223":"Bei unserem Projekt ist es schwierig zu bestimmen, ob die False Positives oder False Negatives wichtiger sind. Wenn vorhergesagt wird, dass jemand nicht zu einem Termin kommt, jedoch erscheint (False Positive) kann es sein, dass der Termin anders vergeben wird und somit wichtige Behandlungen eines Patienten ausfallen. Wenn jemand nicht zu einem Termin erscheint, aber vorhergesagt wird, dass diese Person erscheint (False Negative), dann wird die Terminzeit eingeplant und f\u00fcr den Arzt und andere Patienten, die eigentlich diesen Termin wahrnehmen k\u00f6nnten, geht Zeit verloren. Beide Fehler sind also so niedrig wie m\u00f6glich zu halten. Man k\u00f6nnte die Vorhersage noch genauer machen, wenn der Datensatz mehr aussagekr\u00e4ftige Daten mitbringen w\u00fcrde, wie zum Beispiel mehr Daten zu der Krankheitsgeschichte eines Patienten oder Daten, die etwas dar\u00fcber Aussagen, wie besch\u00e4ftigt Patienten sind, z.B. ob sie Kinder haben, Arbeiten etc.","4db0a7ca":"Nun haben wir die neuen Werte: \"ScheduledTime\", \"AppointmentWeekday\", \"AppointmentMonth\" und \"Waitingdays\". In den Spalten \"ScheduledDay\" und \"AppointmentDay\" steht nur noch das Datum und nicht mehr die Zeitangabe. \n\"AppintmentWeekday\", \"AppointmentMonth\" und \"ScheduledTime\" wurden aus den bereits vorhandenen Spalten extrahiert und als neue Features eingebracht. Waitingdays ist ein komplett neues Feature, welches f\u00fcr die Vorhersage relevant sein k\u00f6nnte.","318b728f":"Als n\u00e4chstes wird die Spalte mit den Neighbourhoods umgewandelt. \nDazu nutzen wir einen LabelEncoder, der vorher schon importiert wurde.\nQuelle: Yadav, D. (2019), \"Categorical encoding using Label-Encoding and One-Hot-Encoder\"","b81cb2cb":"Durch df.info() sehen wir, dass 5 Spalten nicht numerisch sind. \nZuerst \u00e4ndern wir \"PatienId\", \"Gender\" und \"No-show\".\nDie PatientenId wird einfach in int umgewandelt.\nAuch die \"No-show\" Spalte wird in int umgewandelt. Wenn der Patient den Termin wahrgenommen hat (also Noshow = negativ), dann wird eine 0 angezeigt. Wenn nicht dann wird eine 1 angezeigt.\nDie Gender Spalte bennen wir um in \"Male\", wenn die Person m\u00e4nnlich ist wird eine 1 angezeigt, wenn nicht wird eine 0 angezeigt.","b0d20562":"Erstmal wird ein neues DataFrame mit den Werten aus der Spalte \"Neighbourhood\" erstellt","7257af36":"Hier stellen wir den Decision Tree dar. Um eine \u00fcbersichtliche Darstellung zu erm\u00f6glichen haben wir die max_depth auf 4 gesetzt, da es sonst zu un\u00fcbersichtlich wird.","161ecf94":"Um zu erkennen welche Merkmale im Datensatz, f\u00fcr die Vorhersage wichtig sind, nutzen wir eine HeatMap um zu verstehen wie gro\u00df die Korrelation zwischen den Merkmalen ist. Daf\u00fcr m\u00fcssen wir zuerst sicherstellen, dass der Datensatz nur numerische Werte enth\u00e4lt.","2216384f":"Die Spalte Alter enth\u00e4lt einige Werte, die keinen Sinn machen, wie zum Beispiel negative Werte oder Werte \u00fcber 100. Nat\u00fcrlich gibt es Menschen, die \u00fcber 100 Jahre alt werden, jedoch ist die eher unwahrscheinlich. Daher setzen wir das Intervall des Alters auf 0 bis 100 Jahre.","16aa99fb":"Trainieren der Daten mit .fit","807dba38":"Zuerst werden die einzelnen Werte in zwei DataFrames aufgeteilt. ","12aadff4":"88208 Personen verpassen ihren Termin nicht, 22319 Personen verpassen ihn. 79,8% kommen zum Termin, 20,2% kommen nicht zum Termin ","cea8fcc1":"Matplotlib wurde schon importiert.\nQuelle: Matplotlib, \"Basic Pie Chart\"","8cfff287":"Maximale Tiefe in den Werten 1 - 20 gesucht.","e6a1b672":"# 1. Allgemeine Informationen: \nDeniz Tuncer   MNr.: 1827813\nZoe Winterberg MNr.: 1825417\nDatensatz: Medical Appointment No Shows \n","42961348":"Mit best_estimator wird der beste Estimator ausgegeben.","b9134f23":"# Decision Tree\/Entscheidungsbaum","647a906e":"Nachdem nun die Werte umgewandelt wurden, k\u00f6nnen wir damit beginnen die wichtigsten Features auszuw\u00e4hlen. Dazu nutzen wir zuerst eine Correlation Heatmap.","cdb1f61f":"Dann werden die Werte in diesem DataFrame mit dem LabelEncoder transformiert und wir erhalten ein DataFrame mit zwei Spalten, einmal dem Namen der Nachbarschaft und dem zugeh\u00f6rigen Wert in der Spalte \"NeighbourhoodNumbers\"","51228c7c":"Beschreibung des Datensatzes: \n\nPatientId: Die ID, die jedem Patienten zugeordnet wird.\n\nAppointmentID: Die ID, f\u00fcr jeden Termin.\n\nGender: Geschlecht des jeweiligen Patienten.\n\nScheduledDay: Der Tag an dem der Termin festgelegt wurde.\n\nAppointmentDay: Der Tag an dem der Termin ist.\n\nAge: Das Alter des jeweiligen Patienten.\n\nNeighbourhood: Die Nachbarschaft, in der, der Termin wahrgenommen werden soll.\n\nScholarship: Zeigt ob der Patient ein Stipendium erh\u00e4lt.\n\nHipertension: Zeigt ob ein Patient an Hypertonie leidet.\n\nDiabetes: Zeigt ob ein Patient an Diabetes leidet.\n\nAlcoholism: Zeigt ob ein Patient an Alkoholismus leidet.\n\nHandcap: Zeigt an wie vielen Handicaps ein Patient leidet (Werte 0 - 4).\n\nSMS_received: Zeigt ob eine oder mehrere Nachrichten an den Patienten geschickt wurden oder nicht.\n\nNo-show: Zeigt ob der Patient zum Termin erschienen ist oder nicht.","ae7966be":"# 6. Modellevaluierung","89d63034":"Classifier nutzen um Vorhersagen zu treffen.","8770f0f1":"Da nur ein Wert in der ganzen Spalte ist, wird die Spalte komplett rausgel\u00f6scht, da sie keine Aussagekraft besitzt.","3cd5b336":"Durch die Ausgleichung der Klassen haben sich nun andere Parameter als optimal ergeben. Diese werden nun festgelegt.","37b85cf4":"Zusammenhang zwischen Alter und Diabetes und Alter und Hipertonie","7ce04ef7":"Alle Werte sehen sinnvoll aus, au\u00dfer der zwei Werte in der Spalte Age. Niemand kann -1 Jahr alt sein und auch \u00fcber 100 zu werden ist sehr sehr selten.","64bf2359":"Erstellung einer Confusion Matrix.","d5cbe9fb":"Maximale Tiefe am optimalsten 19, Criterion (Messung der Qualit\u00e4t einer Aufteilung) = Gini und Minimum Samples ist 1.","4e73b8bd":"Bei dem Bericht des KNN Modells ist zu erkennen, dass die Precision relativ hoch ist. Gerade bei dem Merkmal, dass jemand zu einem Termin kommt (0) ist diese hoch, bei der Vorhersage, dass jemand nicht zu einem Termin kommt ist das Modell etwas ungenauer, jedoch nicht zu ungenau. \nDer Recall ist bei diesem Modell bei der Klasse erscheint zum Termin etwas niedriger als bei der Klasse, dass jemand nicht auftaucht. Der F1 Score ist bei diesem Modell ziemlich gut. Der beste F1 Score, den man haben kann ist 1.0. Der schlechteste ist 0.0. Da der F1 bei 0.83 und 0.86 liegt, kann man diesen als ziemlich gut bezeichnen. Der Support ist gut ausbalanciert, dies wundert uns aber nicht, da wir die Klassen vor der Modell Durchf\u00fchrung ausgleichen mussten. Die Accuracy dieses Modelles ist 84%.","a7a5d0ae":"Ein weiteres Merkmal, das wichtig sein k\u00f6nnte, ist der zeitliche Abstand zwischen dem Tag, an dem der Termin vereinbart wurde (\"ScheduledDay\") und dem Tag, an dem der Termin stattfindet (\"AppointmentDay\"). Da dieses Merkmal f\u00fcr unsere Vorhersage relevant sein k\u00f6nnte, f\u00fcgen wir es zu dem Datensatz hinzu.","3a09fb64":"Um die Tage zwischen den beiden Tagen zuerhalten, subtrahieren wir die beiden Spalten sozusagen voneinander.","5ddc6e61":"Mit .predict lassen wir das kNN Modell eine Vorhersage f\u00fcr X_test machen.","28252793":"Unser Modell kann Unternehmen dadurch helfen, dass es voraussagt, ob jemand zum Termin erscheint oder nicht. Da die Genauigkeit unserer Modelle bei ungef\u00e4hr 80% liegen, kommt es nat\u00fcrlich noch zu einigen Fehlvorhersagen. Trotzdem k\u00f6nnten die Modelle, Arztpraxen dabei helfen die Terminvergabe zu verbessern. \u00c4rzte w\u00fcrden somit wissen, wie wahrscheinlich es ist, dass Patienten nicht auftauchen. Dadurch k\u00f6nnten Terminvergaben ver\u00e4ndert werden, flexibler gemacht werden oder vielleicht sogar doppelt vergeben werden. Bei der genauen Anwendung der Modelle ist aber nat\u00fcrlich zu beachten, dass es zu falschen Vorhersagen kommen kann, auch wenn die Genauigkeit ziemlich hoch ist. \nDurch eine flexiblere Terminvergabe, k\u00f6nnten aber Termin, die nicht wahrgenommen werden einfach an andere Patienten vergeben werden, wodurch weniger Zeit, Geld und Vorbereitung verschwendet werden w\u00fcrde.","9fc34127":"# 5. Modellbildung ","5eefb512":"Trainingsdaten werden mit dem neuen KNNClassifier trainiert.","08cadd58":"Die h\u00f6chste Klassifikationsgenauigkeit liegt bei ungef\u00e4hr 80%, der beste Wert f\u00fcr die kN-Nachbarn liegt bei 24 und der beste Wert f\u00fcr weight ist uniform, also dass alle Punkte in der Umgebung ausgewogen sind.","79561cb2":"Dann erzeugen wir zwei neue Spalten mit den Zeit-Werten aus den Spalten \"ScheduledTime\" und \"AppointmentTime\"\nQuelle: Pandas, \u201epandas.Series.dt.time\"","2ae42c18":"Wir wollen zwei Modelle nutzen. Einmal das kNN Modell und einmal einen DecisionTree\/Entscheidungsbaum.\n","124be895":"Trainieren des Modelles mit .fit","e371a257":"# 2. Gesch\u00e4ftsverst\u00e4ndnis: \nJemand vereinbart einen Termin aber erscheint nicht. Dies ist f\u00fcr \u00c4rzte mehr als unpraktisch. Sie warten auf Patienten, es werden Vorbereitungen getroffen und auch anderen Patienten werden dadurch Termine genommen, die genutzt werden k\u00f6nnten. In unserem Projekt wollen wir versuchen Vorherzusagen ob jemand zu einem Termin erscheint oder nicht, bzw. wollen wir ein Modell mit hoher Genauigkeit zur Verf\u00fcgung stellen, um Arztpraxen zu erm\u00f6glichen vorherzusagen, ob ein Patient zu einem Termin erscheint oder nicht. ","b2b126b0":"Wir nutzen GridSearch um die besten HyperParameter f\u00fcr unser KNN_Modell herauszufinden und diese dann in unserem kNN Modell anzupassen. Wir machen das, damit wir die h\u00f6chste Genauigkeit im Modell erreichen.\nBei einem GridSearch wird ein Search Space als Gitter aus Hyperparameterwerten festgesetzt und daraus werden dann der geeigneteste Hyperparameter bestimmt.","73dc02b7":"Festsetzen der besten Parameter f\u00fcr das kNN Modell","af23652e":"Der Decision Tree ist ein mathematisches Modell, mit dessen Hilfe sich Entscheidungen finden lassen. Das Modell ist baumartig aufgebaut und stellt einen gerichteten Entscheidungsweg dar. Er besteht aus Wurzel, Knoten, \u00c4sten und Bl\u00e4ttern. Wir nutzen ein Decision Tree Modell, da dieses Modell relativ einfach zu erstellen ist. Au\u00dferdem ist es f\u00fcr numerische als auch f\u00fcr kategorische Daten m\u00f6glich, daher ist die Nutzung kein Problem f\u00fcr uns. Au\u00dferdem ist ein Vorteil Decision Trees ist die anschauliche Darstellung der Entscheidungswege","1678bc11":"Dann f\u00fcgen wir die Spalte \"NeighbourhoodNumbers\" unserem originalen DataFrame und l\u00f6schen aus diesem die Spalte \"Neighbourhood\"","30752b96":"Bei dem Bericht des Decision Trees ist zu erkennen, dass die Precision auch relativ hoch ist, sie ist jedoch niedriger als bei dem KNN Modell. Der Recall ist bei diesem Modell ebenfalls niedriger als bei dem KNN Modell. Der F1 Score ist auch bei diesem Modell ziemlich gut, unterscheidet sich nur wenig von dem KNN Modell. Da der F1 bei 0.76 und 0.81 liegt, kann man diesen auch als ziemlich gut bezeichnen. Die Genauigkeit liegt hier bei 78%, ist also auch schlechter als das KNN Modell.","35f5df35":"Um die letzten zwei Spalten zu encoden nutzen wir wieder den LabelEncoder:","6ce6610f":"Wir \u00fcberpr\u00fcfen nochmal ob die Samples nun gleich sind.","211494ad":"**False Positive**: Jemand kommt zum Termin, es wird aber vorhergesagt, dass die Person nicht kommt.\n**False Negative**: Jemand kommt nicht zum Termin wird, es wird aber vorhergesagt, dass jemand zum Termin kommt","0649d7a1":"Hier setzen wir als Grid die \"n_neighbors\" und \"weights\" fest, da dies beide Hyperparameter des KNN Modells sind.","0c280236":"Da die Klassen nun ausgeglichen sind setzen wir nochmal die richtigen HyperParameter fest, damit die Performance optimal ist.","fab21cd5":"# Visualisierung der Daten: \n","a106c907":"Um mit dem Modeling Prozess anzufangen, teilen wir die Features in Test- und Trainingsdaten ein!.","5325502e":"Leider sieht die ConfusionMatrix nicht so aus wie sie sollte. Das liegt daran, dass die Klassen unausgeglichen sind. Im n\u00e4chsten Schritt arbeiten wir daran die Klassen auszugleichen, damit das Modell vern\u00fcnftig funktioniert. Dies machen wir, indem wir die unterverteilte Klasse \"upsamplen\". In diesem Fall ist die kleinere Klasse \"1\" und die gr\u00f6\u00dfere \"0\".\nQuelle: Elite Data Science,  (keine Angabe) \u201eHow to Handle Imbalanced Classes in Machine Learning\u201c ","c4108eab":"Zur Bewertung und zum Vergleich der beiden Modelle gibt es verschiedene M\u00f6glichkeiten. Zuerst gehen wir auf den Klassifikationsbericht ein. ","9e2be055":"Erstellung eines Klassifikationsreport","a0ad2403":"Nur das Datum wird in den Spalten \"ScheduledDay\" und \"AppointmentDay\" gespeichert. \nQuelle: Pandas, \u201epandas.Series.dt.date\u201c "}}