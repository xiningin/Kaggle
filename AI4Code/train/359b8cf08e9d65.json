{"cell_type":{"d4a0a636":"code","a487825c":"code","55bdd4d8":"code","19c8fce8":"code","cd0e290e":"code","e5387a70":"code","757906fa":"code","637b4b7d":"code","c12c36e8":"code","1be666f5":"markdown","233ba663":"markdown","8922fcc1":"markdown","13b52a23":"markdown","32f6126b":"markdown","886ecb20":"markdown","ff7f3fd7":"markdown","9460a6a8":"markdown","f481d96f":"markdown","6868c79e":"markdown","ec35a2bb":"markdown","ed2f3943":"markdown"},"source":{"d4a0a636":"#1.1 Calling Libraries\n\n%reset -f\nimport numpy as np\nimport pandas as pd \nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","a487825c":"#2.0 Import OS directory and import data from CSV file\nimport os\nimport pandas as pd\n\nfashion = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")\nfashion.shape\n","55bdd4d8":"#3.0 Let's get some feel of Data How Fashion Images visualizes.\n\ny = fashion['label']\nX= fashion.drop(['label'],axis =1)\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state =42)\n\nX_train_np = X_train.to_numpy()\ny_train_np = y_train.to_numpy()\nX_train.shape\nX_test.shape\ny_train.shape\ny_test.shape\n\n\n#3.1 See the images of various fashion items\nclass_names = ['T_shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nplt.figure(figsize=(10, 10))\nfor i in range(36):\n    plt.subplot(6, 6, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train_np[i].reshape((28,28)))\n    label_index = int(y_train_np[i])\n    plt.title(class_names[label_index])\nplt.show()","19c8fce8":"#4.1 Checking Correlation Between Different Components\n\ndf=fashion.drop('label', 1)\nf , ax = plt.subplots(figsize = (14,12))\nplt.title('Correlation of Features- HeatMap',y=1,size=16)\nsns.heatmap(df.corr(),square = True,  vmax=0.8)","cd0e290e":"#4.2 Great we find correlation between different variable\n\n#Dimentionality reduction using Principle Component Analysis convert the image size from \n# 1*784 to 1*144 size\n\n#Drop the Label Column from Fashion dataset dimentionality reduction in Pixel columns only\nfashion_label =fashion['label']\nfashion_pixel =fashion.drop(['label'],axis=1)\nss = StandardScaler()\npca = PCA(n_components =144)\npipeline =make_pipeline(ss,pca)\n\npipeline.fit(fashion_pixel)\n\nfashion_new = pipeline.transform(fashion_pixel)\nfashion_new.shape\n","e5387a70":"#5.0 Divide the Dataset into Test and Train dataset.\ny = fashion_label\nX= fashion_new\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state =42)\n\n#X_train_np = X_train.to_numpy()\n#y_train_np = y_train.to_numpy()\nX_train.shape\nX_test.shape\ny_train.shape\ny_test.shape\n#Doing Classification through Random Forest Classifier\nrf= RandomForestClassifier(n_estimators =50,oob_score = True,bootstrap=True)\nss = StandardScaler()\npca = PCA()\n\npipeline_rf = make_pipeline(ss,pca,rf)\n\n#Fit the fashion data into pipeline\npipeline_rf.fit(X_train,y_train)\ny_predict_rf = pipeline_rf.predict(X_test)\nscore_rf = np.sum(y_predict_rf == y_test)\/len(y_test)\nscore_rf\n\n\n","757906fa":"#5.1 Checking the Score of Logistics Regression Model\nlogreg = LogisticRegression()\n                            \npipeline_logreg =make_pipeline(ss,pca,logreg)\n\n#Fit the fashion data into pipeline\n\npipeline_logreg.fit(X_train,y_train)\n\ny_predict_logreg = pipeline_logreg.predict(X_test)\n\nscore_logreg =np.sum(y_predict_logreg ==y_test)\/len(y_test)\nscore_logreg","637b4b7d":"#5.2 Building Model using Adaboost Classifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n#Instantiate Decision Tree Classifier\ndt = DecisionTreeClassifier(max_depth =1,random_state =1) \nada = AdaBoostClassifier(base_estimator =dt,n_estimators =1000,random_state = 1)\n                            \npipeline_Adaboost =make_pipeline(ss,pca,ada)\n\n\n#Fit the fashion data into pipeline\n\npipeline_Adaboost.fit(X_train,y_train)\n\ny_predict_Adaboost = pipeline_Adaboost.predict(X_test)\n\nscore_Adaboost =np.sum(y_predict_Adaboost ==y_test)\/len(y_test)\nscore_Adaboost\n","c12c36e8":"#5.3 Confusion Matrix of AdaBoost Algorithm\ncf_Adaboost = confusion_matrix(y_test,y_predict_rf)\ncf_Adaboost","1be666f5":"**Random Forest Classifier Model** Using Random Forest tree based model we analyse fashion database.","233ba663":"**Supervised Learning with Fashion Minist Dataset** We now done supervised learning in Fsshion Minist Dataset and checking the scores of Different Models.","8922fcc1":"**Final Conclusion -** In this notebook we analyse important dataset in terms to analyse fashion industry. This is Supervised Learning classification Problem in the present \nnotebook we also build diffent models to analyse the trends of fashion Industry. \n\n**How Useful this dataset is -** This dataset has a very powerful implecations in fashion industry. Fashion Industry can analyse persons preferences by imply these models \nA. - Capturing the CCTV images of Mall customers and analyse the customers fashion behaviour.\nB. - Imply models in Online shopping and by provide products of customers need and demand.\nC. - Using CCTV footage of Hotels\/Tourist destinations\/Cinema Hall analyse the mood of customers fashion trends.\nD. - Predict the performance of new product by analysing existing customer fashion trends.\nE. - Analyse the fashion trends of Diffennt Countries of World and Differnt Cities of country.\nF. - By using our model using CCTV footage of differnt locations we can analyse which fashion trend becomes obselete and which is preffered trend of customers.\nG. - By using our models we can analyse the fashion trends and taste of differnt age group persons i.e. Child,Young and Old age persons.","13b52a23":"**Introduction -** Fashion Minist Dataset is very important database in reference to analysing the trends in Fashion Industry. This dataset is provided by Zalando Research having dataset of 60000 images of size 28*28 greystyle images of different fashion items these are\n1. T-shirt\/top\n2. Trouser\n3. Pullover\n4. Dress\n5. Coat\n6. Sandal\n7. Shirt\n8. Sneaker\n9. Bag\n10.Ankle boot\n\nA. In this notebook we are trying to understand this image dataset firstly by pictorial notification. \nB. We analyse how diffent pixels are mutually correlated and using Heatmap shows this relationship.\nC. Using Principle Component Analysis(PCA) we reduce the pixel size of dataset from 28*28 to 12*12 i.e. 144 pixels.\nD. We are also trying to build some models to do supervised learning in this classification problem.\n    - Logistics Regression Model\n    - Random Forest Model\n    - Ada Boost Model\n    - Decision Tree Classifier Model\nE. We also find the important features in the model and also analyse these model performances in important features columns.\n\n****","32f6126b":"**Principle Component Analysis** - Principal Component Analysis (PCA) is a linear dimensionality reduction technique that can be utilized for extracting information from a high-dimensional space\n by projecting it into a lower-dimensional sub-space. It tries to preserve the essential parts that have more variation of the data and remove the non-essential partswith fewer variation. We know size of any image is very important we can easily store the less size image when database is very big small size image without losing \nimporatant components that is where PCA comes in pictue.","886ecb20":"**Logistics Regression Model -** This is a simple Classification model we analyse the performance of Dataset by using this model also.","ff7f3fd7":"**Correlation Heat Maps-** (Courtsy Towards Data Science)\nYou already know that if you have a data set with many columns, a good way to quickly check correlations among columns is by visualizing the correlation matrix as a heatmap.\n","9460a6a8":"**Conclusion of PCA Analysis -**\nUsing PCA we are able to reduce the dimentionality of database image size from 28 by 28 image size to 12 by 12 image size. Since image database is a very big database and reduce dimentionality implicates reduced size and that what Principle Component Analysis does it reduces the size of Image Permanently.\n","f481d96f":"**Being an Initial learner I tried my best to understand fashion dataset and apply various models. Please UPVOTE my efforts as an initial learner to do better in future.**","6868c79e":"**Feeling the Fashion Database - This Fashion Minist dataset is a dataset of different fashion items by storing pixel information. Visualization of Images is first step to feel the Fashion Minist Dataset.**","ec35a2bb":"**ADABOOST Model -** Checking the performance of Fashion Minist dataset using Adaboost tree based model. This model boost uses many decision trees and normally performance of this model is quite good.","ed2f3943":"**Different Supervised Learning Classification Models Analysis**\nIn this notebook we analysed this Fashion Minist Dataset with different models from simpler models like Logistic Regression and Decision Tree Classification Models to Complex Models like Random Forest Classifier Model and AdaBoost Model.\n\n**Our Observation-** After analysis our observation of Supervised learning is simple model like Logistic Regression performance is also good compared to complex models like Ada Boost Model."}}