{"cell_type":{"7eaca57c":"code","62fc1365":"code","cab7689f":"code","06d11f47":"code","629bb4da":"code","b994d114":"code","8dd3fa72":"code","59c6fb0c":"code","fd856ce9":"code","21564117":"code","805bb6cc":"code","88b9ab27":"code","3150361e":"code","f4f2afc5":"code","f8083878":"code","eb072adb":"code","a39ce5c7":"code","c5b20ab3":"code","9f15ea89":"code","9bdc4ee4":"code","68d44a67":"code","6744b4ec":"code","8899aee4":"code","5c047bcb":"code","832fa6db":"code","9102519f":"code","1d4ade81":"code","b83fc3d3":"code","9f5867bf":"code","7fb00463":"code","c8a034dc":"code","8f94d094":"code","4ca9c17c":"code","83c22f53":"code","b1e8f078":"code","92b57f8b":"code","23f9d064":"code","78a83b6f":"code","12377961":"code","e434ff87":"code","941568a0":"code","08bfc237":"code","0a60de1c":"code","a063c496":"code","8c2b8679":"code","174bbbab":"code","34ca6ab0":"code","d75de04b":"code","a214923b":"code","81c291e4":"code","2093fefd":"code","666b8b74":"code","b4dd4d7d":"code","35babffc":"markdown","a2ce2760":"markdown","a2af82ba":"markdown","f63d8765":"markdown","d6689116":"markdown","f48b1d2e":"markdown","6abecdcf":"markdown","214c9397":"markdown","c2362aa7":"markdown","ab3e1d86":"markdown","bd028e9e":"markdown","952c3bd2":"markdown","053670f7":"markdown","67363300":"markdown","a9c62476":"markdown","444b23d4":"markdown","f159cf34":"markdown","70c87d7a":"markdown","37c6a2ab":"markdown","00d717ef":"markdown","906d49cd":"markdown","a663afc5":"markdown","74e2b899":"markdown","6af9571c":"markdown","76dc50eb":"markdown","d7030df6":"markdown","c85e78e9":"markdown","3a5b6432":"markdown","a966cd16":"markdown","b53a1b70":"markdown","7a1ff9db":"markdown","c05d6778":"markdown"},"source":{"7eaca57c":"# Import everything we need\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt, image as mpimg\nfrom tqdm import tqdm\nfrom time import time\nfrom collections import Counter\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers, optimizers, losses, metrics, utils, callbacks, applications\nfrom sklearn.model_selection import train_test_split as tts\nimport cv2 as cv\n\n# Image size: 1024px x 1024px (x 3 color (RGB) channels)\nIMG_SIZE = 1024\n\n# Batch size: 32 images\nBATCH_SIZE = 32\n\n# Paths to directories\n\ntrain_dir = '..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/Training Images'\ntest_dir = '..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/Testing Images'\nmain_dir = '..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K'\n\nhistory_dir = '\/kaggle\/working\/history'\nif not os.path.isdir(history_dir):\n    os.mkdir(history_dir)\n\n    models_dir = '\/kaggle\/working\/models'\nif not os.path.isdir(models_dir):\n    os.mkdir(models_dir)\n\n\n\n# A function to load and preprocess image (clip out the black background and resize it properly)\n\ndef load_prep_img(image_path, target_shape=(IMG_SIZE, IMG_SIZE)):\n    image = cv.imread(image_path, cv.IMREAD_COLOR) # load from the directory\n    non_0_rows = np.array([row_idx for row_idx, row in enumerate(image) if np.count_nonzero(row)!=0])\n    non_0_cols = np.array([col_idx for col_idx, col in enumerate(image.transpose(1,0,2)) if np.count_nonzero(col)!=0])\n    image = image[non_0_rows.min():non_0_rows.max()+1, non_0_cols.min():non_0_cols.max()+1, :] # clip\n    image = cv.resize(image, target_shape)\n    return image\n    \n\n# Function test:\nimage_path = os.path.join(train_dir, os.listdir(train_dir)[0])\n\nimage = cv.imread(image_path, cv.IMREAD_COLOR)\nprint('Original (raw) image:\\t',image.shape)\nplt.imshow(image)\nplt.show()\n\nimage_prepped = load_prep_img(image_path)\nprint('Preprocessed image:\\t', image_prepped.shape)\nplt.imshow(image_prepped)\nplt.show()","62fc1365":"data = pd.read_excel(os.path.join(main_dir, 'data.xlsx'))\ndata.head()","cab7689f":"classes = list(data.columns[7:15])\ndata['Patient Labels'] = data.apply(lambda x:[class_ for class_ in classes if x[class_]==1], axis=1)\ndata.head()","06d11f47":"# Names of columns in the DataFrame\ncol_names = ['Image', 'Keywords', 'Age', 'Sex', 'Patient Labels']\n\n# DataFrame for left-eye images\neyes_L = data[['Left-Fundus', 'Left-Diagnostic Keywords', 'Patient Age', 'Patient Sex', 'Patient Labels']]\neyes_L.columns = col_names\n\n# DataFrame for right-eye images\neyes_R = data[['Right-Fundus', 'Right-Diagnostic Keywords', 'Patient Age', 'Patient Sex', 'Patient Labels']]\neyes_R.columns = col_names\n\n# DataFrame for left-eye and right-eye images combined\neyes_df = pd.concat([eyes_L, eyes_R], axis=0)\n\neyes_df","629bb4da":"# Keywords characteristic for 'O' class:\n\nO_keywords = [\n    'macular epiretinal membrane',\n    'epiretinal membrane',\n    'drusen',\n    #'lens dust',\n    'myelinated nerve fibers',\n    'laser spot',\n    'vitreous degeneration',\n    'refractive media opacity',\n    'spotted membranous change',\n    'tessellated fundus',\n    'maculopathy',\n    'chorioretinal atrophy',\n    'branch retinal vein occlusion',\n    'retinal pigmentation',\n    'white vessel',\n    'post retinal laser surgery',\n    'epiretinal membrane over the macula',\n    'retinitis pigmentosa',\n    'central retinal vein occlusion',\n    'optic disc edema',\n    'post laser photocoagulation',\n    'retinochoroidal coloboma',\n    'atrophic change',\n    'optic nerve atrophy',\n    'old branch retinal vein occlusion',\n    'depigmentation of the retinal pigment epithelium',\n    'chorioretinal atrophy with pigmentation proliferation',\n    'central retinal artery occlusion',\n    'old chorioretinopathy',\n    'pigment epithelium proliferation',\n    'retina fold',\n    'abnormal pigment ',\n    'idiopathic choroidal neovascularization',\n    'branch retinal artery occlusion',\n    'vessel tortuosity',\n    'pigmentation disorder',\n    'rhegmatogenous retinal detachment',\n    'macular hole',\n    'morning glory syndrome',\n    'atrophy',\n    #'low image quality',\n    'arteriosclerosis',\n    'asteroid hyalosis',\n    'congenital choroidal coloboma',\n    'macular coloboma',\n    'optic discitis',\n    'oval yellow-white atrophy',\n    'wedge-shaped change',\n    'wedge white line change',\n    'retinal artery macroaneurysm',\n    'retinal vascular sheathing',\n    'suspected abnormal color of  optic disc',\n    'suspected retinal vascular sheathing',\n    'suspected retinitis pigmentosa',\n    'silicone oil eye',\n    'fundus laser photocoagulation spots',\n    'glial remnants anterior to the optic disc',\n    'intraretinal microvascular abnormality'\n    \n\n]","b994d114":"def generate_eye_labels(keywords, patient_labels):\n    eye_labels = []\n    \n    if 'normal fundus' in keywords:\n        eye_labels.append('N')\n        if list(set(keywords.replace('\uff0c', ',').split(',')))==['normal fundus']: # there were two images, for which 'normal fundus' keyphrase was duplicated\n            eye_labels.append('N+') # healthy fundus without any caveats (like lens dust or low image quality)\n            return eye_labels # in this case we know that there are no other keywords, so we can already quit the function and return the list\n        else:\n            eye_labels.append('N-') # healthy fundus but with some caveats\n    if 'lens dust' in keywords:\n        eye_labels.append('LD') # lens dust\n    if 'low image quality' in keywords:\n        eye_labels.append('LIQ') # low image quality\n    if 'D' in patient_labels and ('proliferative retinopathy' in keywords or 'diabetic' in keywords):\n        eye_labels.append('D') # diabetes\n    if 'suspected glaucoma' in keywords:\n        eye_labels.append('SG') # suspected glaucoma (it may be real glaucoma or may not)\n    elif 'glaucoma' in keywords:\n        eye_labels.append('G') # glaucoma\n    if 'cataract' in keywords:\n        eye_labels.append('C') # cataract\n    if 'age-related' in keywords:\n        eye_labels.append('A') # AMD\n    if 'hypertensi' in keywords:\n        eye_labels.append('H') # hypertension\n    if 'myopi' in keywords:\n        eye_labels.append('M') # myopia\n    if 'O' in patient_labels and (any(O_keyword in keywords for O_keyword in O_keywords)):\n        eye_labels.append('O') # other (anything else)\n    return eye_labels\n\n\n\n\neyes_df['Eye Labels'] = eyes_df.apply(lambda x: generate_eye_labels(x['Keywords'], x['Patient Labels']), axis=1)\neyes_df","8dd3fa72":"c = Counter()\nfor eye_label in eyes_df['Eye Labels']:\n    c[tuple(eye_label)] +=1 \nc","59c6fb0c":"def extract_dataframe(criteria=['C'], n_max=0, shuffle=True, df=eyes_df):\n    if type(criteria)!=type(list()):\n        criteria = [criteria]\n    disease_criteria = [criterion for criterion in criteria if criterion!='Male' and criterion!='Female']\n    \n    if disease_criteria==[]:\n        df['extract'] = 1\n    else:\n        df['extract'] = df['Eye Labels'].apply(lambda x: 1 if all(criterion in x for criterion in disease_criteria) else 0)\n    \n    if 'Male' in criteria:\n        df['extract'] = df['extract'] * df['Sex'].apply(lambda x: 1 if x=='Male' else 0 )\n    elif 'Female' in criteria:\n        df['extract'] = df['extract'] * df['Sex'].apply(lambda x: 1 if x=='Female' else 0 )\n        \n    extract_df = df.query(' `extract` == 1 ')\n    extract_df.drop('extract', axis=1, inplace=True)\n    df.drop('extract', axis=1, inplace=True)\n    if shuffle:\n        extract_df = extract_df.sample(frac=1)\n    extract_df.reset_index(drop=True, inplace=True)\n    if n_max!=0:\n        extract_df = extract_df.iloc[:n_max, :]\n    \n    return extract_df\n\n\n","fd856ce9":"males_with_cataract_df = extract_dataframe(['C', 'Male'])\nprint(males_with_cataract_df['Eye Labels'].value_counts()) # Distribution of eye labels in males with cataract\nprint(males_with_cataract_df['Patient Labels'].value_counts()) # Distribution of patient labels in males with cataract\nprint(males_with_cataract_df['Sex'].value_counts()) # Distribution of sexes in males with cataract - unsurprisingly boring\nmales_with_cataract_df","21564117":"all_eye_labels = [*classes, 'N-', 'N+','LD','LIQ','SG']\nfor criterion in [*all_eye_labels, 'Male', 'Female']:\n    print(criterion, extract_dataframe(criterion).shape[0])","805bb6cc":"print(\"There are %i images of perfectly healthy male eyes in the dataset\" % extract_dataframe(['Male','N+']).shape[0])\nprint(\"There are %i images of perfectly healthy female eyes in the dataset\" % extract_dataframe(['Female', 'N+']).shape[0])\nprint(\"There are %i images of perfectly healthy eyes in total in the dataset\" % extract_dataframe(['N+']).shape[0])","88b9ab27":"# Load the extractor - pre-trained ResNet152\nextractor = applications.ResNet152(include_top=False, weights='imagenet', pooling='max', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\ndef extract_features(extract_df, directory=train_dir, verbose=True):\n    if verbose:\n        print(extract_df.shape[0], \"images are being processed...\")\n    extracts = []\n    for i, row in tqdm(extract_df.iterrows()):\n        image_path = os.path.join(directory, row['Image'])\n        image = load_prep_img(image_path, (IMG_SIZE, IMG_SIZE)).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n        extract = extractor.predict(image)\n        extracts.append(extract)\n    \n    return np.array(extracts).reshape(-1,2048)","3150361e":"n_max = 1024\n\nN_extracts = extract_features(extract_df=extract_dataframe(criteria='N+', n_max=n_max))\nN_labels = np.zeros(shape=(n_max,))\n\nprint(N_extracts.shape, N_labels.shape)","f4f2afc5":"# A function for splitting data into training, validation, and testing sets of given relative sizes\ndef tvt_split(X, y, split_sizes=[8,1,1], stratify=True):\n    split_sizes = np.array(split_sizes)\n    if stratify:\n        train_X, test_X, train_y, test_y = tts(X, y, test_size=split_sizes[2]\/split_sizes.sum(), stratify=y)\n        train_X, val_X, train_y, val_y = tts(train_X, train_y, test_size=split_sizes[1]\/(split_sizes[0]+split_sizes[1]), stratify=train_y)\n    else:\n        train_X, test_X, train_y, test_y = tts(X, y, test_size=split_sizes[2]\/split_sizes.sum())\n        train_X, val_X, train_y, val_y = tts(train_X, train_y, test_size=split_sizes[1]\/(split_sizes[0]+split_sizes[1]))\n    return train_X, val_X, test_X, train_y, val_y, test_y\n\n# A function generating training, validation, and test sets, given the criteria and maximum number of examples per (positive or negative) class\ndef generate_datasets(criteria=['C'], n_max=1024):\n    X_extracts = extract_features(extract_dataframe(criteria, n_max=n_max))\n    X_n = X_extracts.shape[0]\n    X_labels = np.ones(shape=(X_n))\n    \n    extracts = np.concatenate([X_extracts, N_extracts[:X_n, :]], axis=0) # Previously generated extracts of healthy eyes are the negative class\n    labels = np.concatenate([X_labels, N_labels[:X_n]], axis=0)\n    \n    return  tvt_split(extracts, labels) #train_X, val_X, test_X, train_y, val_y, test_y","f8083878":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets(criteria=['D'], n_max=100)","eb072adb":"for X, y in [[train_X, train_y], [val_X, val_y], [test_X, test_y]]:\n    print(X.shape, y.shape) # Sanity-check for the shape of each set\n    print(np.bincount(y.astype(np.int32))) # Sanity check for equal distribution of classes in each set","a39ce5c7":"# Build a model template, whose copies will be trained to classify all the clinical conditions\n\nmodel_template = models.Sequential(name='model_template', layers=[\n    layers.Input(shape=(2048,)),\n    layers.BatchNormalization(),\n    layers.Dense(256, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(32, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(2, activation='softmax')\n])\n\n# Callbacks for training models\ndef generate_callbacks(filepath, monitor='val_acc', mode='max'):\n    return [\n        callbacks.EarlyStopping(patience=50), # Stop training after 50 epochs of no improvement\n        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=.1, patience=20, verbose=0), # Reduce learning rate by a factor of 10, if performance hasn't been improving for 20 epochs\n        callbacks.ModelCheckpoint(filepath=filepath, monitor=monitor, mode=mode, save_best_only=True, save_freq='epoch', save_weights_only=True)\n    ]\n\n# Function to evalute the given model on the training, validation, and testing set\ndef evaluate_model(model):\n    print(\"Training set:\\tLoss: %f\\tMetric: %f\"% tuple(model.evaluate(train_X, train_y, verbose=0)))\n    print(\"Validation set:\\tLoss: %f\\tMetric: %f\"% tuple(model.evaluate(val_X, val_y, verbose=0)))\n    print(\"Testing set:\\tLoss: %f\\tMetric: %f\"% tuple(model.evaluate(test_X, test_y, verbose=0)))\n\n\nmodel_template.summary()","c5b20ab3":"def plot_history(history):\n    epochs = np.arange(1, len(history.history['loss'])+1)\n    print(\"epochs:\", len(epochs))\n    \n    train_loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    plt.plot(epochs, train_loss, 'r-', label='train_loss')\n    plt.plot(epochs, val_loss, 'g--', label='val_loss')\n    plt.legend()\n    print(\"Training and validation loss:\")\n    plt.show()\n    \n    train_acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    plt.plot(epochs, train_acc, 'r-', label='train_acc')\n    plt.plot(epochs, val_acc, 'g--', label='val_acc')\n    plt.legend()\n    print(\"Training and validation accuracy:\")\n    plt.show()\n    \n    lr = history.history['lr']\n    plt.plot(epochs, lr, 'b--', label='lr')\n    plt.legend()\n    print(\"Learning rate:\")\n    plt.show()","9f15ea89":"# Generate datasets for diabetes\n\ntrain_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('D')","9bdc4ee4":"D_model = models.clone_model(model_template)\n\nD_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'D_model.h5')\nprint(model_filepath)\n\nD_history = D_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=2\n)","68d44a67":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(D_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nD_model.load_weights(model_filepath)# = models.load_model(model_filepath)\nevaluate_model(D_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(D_history.history['val_acc']))","6744b4ec":"plot_history(D_history)","8899aee4":"# Generate datasets for glaucoma\n\ntrain_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('G')","5c047bcb":"G_model = models.clone_model(model_template)\n\nG_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'G_model.h5')\n\nG_history = G_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","832fa6db":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(G_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nG_model.load_weights(model_filepath)# = models.load_model(model_filepath)\nevaluate_model(G_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(G_history.history['val_acc']))\n\nplot_history(G_history)","9102519f":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('C')","1d4ade81":"C_model = models.clone_model(model_template)\n\nC_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'C_model.h5')\n\nC_history = C_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","b83fc3d3":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(C_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nC_model.load_weights(model_filepath)# = models.load_model(model_filepath)\nevaluate_model(C_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(C_history.history['val_acc']))\n\nplot_history(C_history)","9f5867bf":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('A')","7fb00463":"A_model = models.clone_model(model_template)\n\nA_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'A_model.h5')\n\nA_history = A_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","c8a034dc":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(A_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nA_model.load_weights(model_filepath)\nevaluate_model(A_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(A_history.history['val_acc']))\n\nplot_history(A_history)","8f94d094":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('H')","4ca9c17c":"H_model = models.clone_model(model_template)\n\nH_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'H_model.h5')\n\nH_history = H_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","83c22f53":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(H_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nH_model.load_weights(model_filepath)\nevaluate_model(H_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(H_history.history['val_acc']))\n\nplot_history(H_history)","b1e8f078":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('M')","92b57f8b":"M_model = models.clone_model(model_template)\n\nM_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'M_model.h5')\n\nM_history = M_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","23f9d064":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(M_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nH_model.load_weights(model_filepath)\nevaluate_model(M_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(M_history.history['val_acc']))\n\nplot_history(M_history)","78a83b6f":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('O')","12377961":"O_model = models.clone_model(model_template)\n\nO_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'O_model.h5')\n\nO_history = O_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","e434ff87":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(O_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nO_model.load_weights(model_filepath)\nevaluate_model(O_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(O_history.history['val_acc']))\n\nplot_history(O_history)","941568a0":"n_max = 1024\n\n# Generate extracts from images of female retinas and assign labels\nFemale_extracts = extract_features(extract_dataframe(['Female', 'N+'], n_max=n_max))\nFemale_labels = np.zeros(shape=(n_max,))\n\n# Generate extracts from images of male retinas and assign labels\nMale_extracts = extract_features(extract_dataframe(['Male', 'N+'], n_max=n_max))\nMale_labels = np.ones(shape=(n_max,))","08bfc237":"extracts = np.concatenate([Female_extracts, Male_extracts], axis=0)\nlabels = np.concatenate([Male_labels, Female_labels], axis=0)\n\n#train_X, test_X, train_y, test_y = tts(extracts, labels, test_size=1\/10, stratify=labels)\n#train_X, val_X, train_y, val_y = tts(train_X, train_y, test_size=1\/9, stratify=train_y)\ntrain_X, val_X, test_X, train_y, val_y, test_y = tvt_split(extracts, labels, stratify=True)","0a60de1c":"for X, y in [[train_X, train_y], [val_X, val_y], [test_X, test_y]]:\n    print(X.shape, y.shape) # Sanity-check for the shape of each set\n    print(np.bincount(y.astype(np.int32))) # Sanity check for equal distribution of classes in each set","a063c496":"sex_model = models.clone_model(model_template)\n'''\nsex_model = models.Sequential(name='sex_model', layers=[\n    layers.Input(shape=(2048,)),\n    layers.BatchNormalization(),\n    layers.Dense(512, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(128, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(32, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(2, activation='softmax')\n])\n'''\n\nsex_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'sex_model.h5')\n\nsex_history = sex_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","8c2b8679":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(sex_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nsex_model.load_weights(model_filepath)\nevaluate_model(sex_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(sex_history.history['val_acc']))\n\nplot_history(sex_history)","174bbbab":"ages_df = eyes_df.query(' `Keywords` == \"normal fundus\" ')\nages_extracts = extract_features(ages_df)\nages_labels = ages_df['Age']\n\ntrain_X, val_X, test_X, train_y, val_y, test_y = tvt_split(X=ages_extracts, y=ages_labels, stratify=False)","34ca6ab0":"for X, y in [[train_X, train_y], [val_X, val_y], [test_X, test_y]]:\n    print(X.shape, y.shape) # Sanity-check for the shape of each set\n    #print(np.bincount(y.astype(np.int32))) # Sanity check for equal distribution of classes in each set","d75de04b":"# Since this is a regression task, we need to use a different final layer - with one output node and no (or identity) activation function\nage_model = models.Sequential(name='age_model', layers=[\n    layers.Input(shape=(2048,)),\n    layers.BatchNormalization(),\n    layers.Dense(256, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(32, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(1)\n])\n\n# For the same reason we specify loss function and metric appropriate for regression: Mean Squared Error (MSE) and Mean Absolute Error (MAE), respectively \nage_model.compile(\n    optimizer = optimizers.RMSprop(3e-3),\n    loss='mse',\n    metrics=['mae']\n)\n\nmodel_filepath = os.path.join(models_dir, 'age_model.h5')\n\nage_history = age_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 128, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath, monitor='val_mae', mode='min'),\n    verbose=0\n)","a214923b":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(age_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nage_model.load_weights(model_filepath)\nevaluate_model(age_model)\n\nprint(\"\\nThe lowest validation MAE achieved by this model was\", np.min(age_history.history['val_mae']))\n\n","81c291e4":"epochs = np.arange(1, len(age_history.history['loss'])+1)\nprint(\"epochs:\", len(epochs))\n\ntrain_mse = age_history.history['loss']\nval_mse = age_history.history['val_loss']\nplt.plot(epochs, train_mse, 'r-', label='train_mse')\nplt.plot(epochs, val_mse, 'g--', label='val_mse')\nplt.legend()\nprint(\"Training and validation Mean Squared Error:\")\nplt.show()\n\ntrain_mae = age_history.history['mae']\nval_mae = age_history.history['val_mae']\nplt.plot(epochs, train_mae, 'r-', label='train_mae')\nplt.plot(epochs, val_mae, 'g--', label='val_mae')\nplt.legend()\nprint(\"Training and validation Mean Absolute Error:\")\nplt.show()\n\nlr = age_history.history['lr']\nplt.plot(epochs, lr, 'b--', label='lr')\nplt.legend()\nprint(\"Learning rate:\")\nplt.show()","2093fefd":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets(['LD', 'N-']) # Only images of healthy fundi (other than having lens dust)","666b8b74":"LD_model = models.clone_model(model_template)\n\nLD_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'LD_model.h5')\n\nLD_history = LD_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","b4dd4d7d":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(LD_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nLD_model.load_weights(model_filepath)\nevaluate_model(LD_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(LD_history.history['val_acc']))\n\nplot_history(LD_history)","35babffc":"How many images with each combination of labels are there?","a2ce2760":"Create a separate DataFrame, where each contains information about a single eye (or, more precisely, about an image of a particular retinal fundus).","a2af82ba":"Read the data table ","f63d8765":"## extract_features\n\nA function to load images whose filenames are contained in the DataFrame and immediately extract perform on them feature extraction with pre-trained ResNet152","d6689116":"Function test","f48b1d2e":"## Lens dust","6abecdcf":"## plot_history\n","214c9397":"## generate_datasets (+tvt_split)\n\nA function, which combines the two previous functions and generates training, validation, and testing sets ","c2362aa7":"We will obtain a set of 1024 extracts of perfectly healthy eyes to be used later as negative examples for all the diseases ","ab3e1d86":"# Preparing functions for efficient data generation and model deployment","bd028e9e":"## Glaucoma","952c3bd2":"Function tests","053670f7":"# Some take-aways\n\n1) Picking the model instance with the best validation metric does not guarantee that it will perform best on the testing set\n\n2) I didn't show it here, but from what I tried, three-layer classifiers trained on extracted features perform better than one-layer classifiers. In future maybe I will try to use 1DConvnets for this purpose.\n\n3) Accuracy achieved varies quite a lot: from 66% for sex prediction up to 98% for cataract prediction.\n\n4) Sex and age prediction scores are much worse than those achieved by [Kim et al. (2020)](https:\/\/www.nature.com\/articles\/s41598-020-61519-9). I'm inclined to attribute this difference to them using a much larger dataset.","67363300":"## Age","a9c62476":"# Eye-row DataFrame","444b23d4":"Thanks to [this notebook](http:\/\/https:\/\/www.kaggle.com\/gpreda\/cataract-prediction-using-transfer-learning) from Gabriel Preda, I realized, that a small thing like choice of the proper image resizing function, can have a significant impact on performance. Switching from skimage.transform.resize to cv2.resize made my cataract classifier's accuracy jump from 50% (chance level) to over 90% (as you can see below).\n\nIn this notebook I implemented a form of transfer learning called Feature Extraction. The idea is pretty straightforward\u2013instead of passing the raw input data through the pre-trained part of the network, we pass it once, and train a naive classifier on its output, which is supposed to contain useful, higher-level information. This gives us a tremendous speedup.","f159cf34":"## Diabetes","70c87d7a":"## Sex","37c6a2ab":"## model_template, generate_callback, evaluate_model\n\nSome things for building, training and evaluating models","00d717ef":"Compress labels given to individual patients into a single column containing just a list of names of labels\/classes as single-character strings","906d49cd":"How many images can we extract for each defined criterion","a663afc5":"## Other","74e2b899":"## Cataract","6af9571c":"## Myopia","76dc50eb":"Here I tried using a little bigger model, but it didn't help","d7030df6":"# TO DO\n\n1) Build a multi-output model \n\n2) Make prettier and more elegant plots of training histories with Seaborn\n\n3) Experiment with different model architectures, gridsearch, randomsearch, and pipelines (maybe)\n\n    Maybe I will do some research on architectures used to diagnose such conditions\n    \n4) Build a proper pipeline (when I get to that in one of the textbooks I am currently working with, which may not be soon)","c85e78e9":"## extract_dataframe\n\nA function to select those rows of eyes_df, which satisfy given criteria","3a5b6432":"## Age-related Macular Degeneration (AMD)","a966cd16":"## Hypertension","b53a1b70":"A function for extracting information about the condition of a particular eye from keywords and patient's labels.\n\nI created a few new labels:\n\nN+ for perfectly healthy eyes\nN- for healthy eyes with some caveats (like lens dust or low image quality)\nLD for lens dust\nLIQ for low image quality\nSG for suspected glaucoma, which I decided not to include among other glaucoma cases","7a1ff9db":"# Predicting diseases, sex, and age","c05d6778":"# Predicting diseases, sex, and age from features extracted with pre-trained ResNet152"}}