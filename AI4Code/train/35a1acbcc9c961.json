{"cell_type":{"d47fb9be":"code","08ded01f":"code","4d747f1d":"code","c5afdef1":"code","2e69255b":"code","834888c6":"code","9390cedb":"code","b7e6d436":"code","847b814b":"code","56bc6c99":"code","7af68cf3":"code","532a2dcd":"code","9c51e939":"code","70ed8068":"code","527c6f9c":"code","1e241bb3":"code","b0a9ebfd":"code","1cb8f3f9":"code","a4d7f6c4":"markdown","ed7e7148":"markdown","42e906e5":"markdown","9c86dae2":"markdown","88f4d079":"markdown","f4616454":"markdown","fbcf5636":"markdown","f52bc4a5":"markdown","4630364f":"markdown","142d0a54":"markdown","61e6c5ba":"markdown","c96e2d3c":"markdown","c88dcb00":"markdown","38e67782":"markdown","ddb38419":"markdown","2f94e330":"markdown"},"source":{"d47fb9be":"# Import necessary packages\n%matplotlib inline\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\ntorch.manual_seed(42)","08ded01f":"train_image = []\nfor i in range(1200,1800):\n    img = image.load_img('..\/input\/shuffled-data-to-train-honor-cup-2019\/data_train\/64\/'+str(i).zfill(4)+'.png', target_size=(512,512,1), grayscale=False)\n    img = image.img_to_array(img)\n    img = img\/255\n    train_image.append(img)\nx = np.array(train_image)\nX = torch.from_numpy(x)\nprint(X.shape)\nplt.imshow(X[0])","4d747f1d":"# Open file    \nfileHandler = open (\"..\/input\/shuffled-data-to-train-honor-cup-2019\/data_train\/data_train_64_answers.txt\", \"r\")\n \n# Get list of all lines in file\nlistOfLines = fileHandler.readlines()\n \n# Close file \nfileHandler.close()","c5afdef1":"for line in listOfLines[:6]:\n    print(line.strip()) ","2e69255b":"i=0\ntrain_answer=[]\nfor line in listOfLines:\n    i=i+1\n    if i%2==1:\n        continue\n    string_line=line.strip().split() \n    answer_line=[]\n    for num in string_line:\n        answer_line.append(int(num))\n    train_answer.append(answer_line)\ny=np.array(train_answer)\nY=torch.from_numpy(y)\nprint(Y.shape)","834888c6":"def restore_image(p_images,permutation):\n    images=p_images.clone()\n    for i in range(8):\n        for j in range(8):\n            sr=i*64\n            sc=j*64\n            #print('{:d} {:d}'.format(sr,sc))\n            tr=permutation[i*8+j]\/\/8\n            tc=permutation[i*8+j]%8\n            tc=tc*64\n            tr=tr*64\n            #print('{:d} {:d}'.format(tr,tc))\n            #sr, sc = perm_inds[j]\n            #tr, tc = perm_inds[perms[i, j]]\n            images[ sr:sr+64, sc:sc+64,:] = p_images[ tr:tr+64, tc:tc+64,:]\n    return images","9390cedb":"r_image=restore_image(X[0],Y[0])\nplt.imshow(r_image)","b7e6d436":"def perm2vecmat2x2(perms):\n    \"\"\"\n    Converts permutation vectors to vectorized assignment matrices.\n    \"\"\"\n    n = perms.size()[0]\n    mat = torch.zeros(n, 64, 64)\n    # m[i][j] : i is assigned to j\n    for i in range(n):\n        for k in range(64):\n            mat[i, k, perms[i, k]] = 1.\n    return mat.view(n, -1)\ndef vecmat2perm2x2(x):\n    \"\"\"\n    Converts vectorized assignment matrices back to permutation vectors.\n    Note: this function is compatible with GPU tensors.\n    \"\"\"\n    n = x.size()[0]\n    x = x.view(n, 64, 64)\n    _, ind = x.max(2)\n    return ind\n    ","847b814b":"train_set = torch.utils.data.TensorDataset(X, Y)\nsample_loader = torch.utils.data.DataLoader(train_set, batch_size=8, shuffle=True)\ndataiter = iter(sample_loader)\nimages, labels = next(dataiter)\nz=perm2vecmat2x2(labels)\nvecmat2perm2x2(z)\n#r_image=restore_image(images[0],labels[0])\n#plt.imshow(r_image)","56bc6c99":"# Prepare training, validation, and test samples.\n\nvalidation_ratio = 0.1\ntotal = len(train_set)\nind = list(range(total))\nn_train = int(np.floor((1. - validation_ratio) * total))\ntrain_ind, validation_ind = ind[:n_train], ind[n_train:]\ntrain_subsampler = torch.utils.data.sampler.SubsetRandomSampler(train_ind)\nvalidation_subsampler = torch.utils.data.sampler.SubsetRandomSampler(validation_ind)\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=8,\n                                           sampler=train_subsampler, num_workers=0)\nvalidation_loader = torch.utils.data.DataLoader(train_set, batch_size=8,\n                                                sampler=validation_subsampler, num_workers=0)\n\nprint('Number of training batches: {}'.format(len(train_loader)))\nprint('Number of validation batches: {}'.format(len(validation_loader)))\n","7af68cf3":"from torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ndef sinkhorn(A, n_iter=4):\n    \"\"\"\n    Sinkhorn iterations.\n    \"\"\"\n    for i in range(n_iter):\n        A \/= A.sum(dim=1, keepdim=True)\n        A \/= A.sum(dim=2, keepdim=True)\n    return A\n\nclass SimpleConvNet(nn.Module):\n    \"\"\"\n    A simple convolutional neural network shared among all pieces.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n         # 3 x 64 x 64 input\n        self.conv1 = nn.Conv2d(3, 8, 3)\n        # 8 x 62 x 62\n        self.conv2 = nn.Conv2d(8, 8, 3)\n        self.conv2_bn = nn.BatchNorm2d(8)\n        # 8 x 60 x 60\n        self.pool1 = nn.MaxPool2d(2, 2)\n        # 8 x 30 x 30\n        self.conv3 = nn.Conv2d(8, 16, 3)\n        self.conv3_bn = nn.BatchNorm2d(16)\n        # 16 x 28 x 28\n        self.fc1 = nn.Linear(16*28*28, 512)\n        self.fc1_bn = nn.BatchNorm1d(512)\n        # 128-d features\n        self.fc2 = nn.Linear(512, 512)\n        self.fc2_bn = nn.BatchNorm1d(512)\n    \n    def forward(self, x):\n        #print(x.shape)\n        x = F.relu(self.conv1(x))\n        #print(x.shape)\n        x = F.relu(self.conv2_bn(self.conv2(x)))\n        #print(x.shape)\n        x = self.pool1(x)\n        #print(x.shape)\n        x = F.relu(self.conv3_bn(self.conv3(x)))\n        #print(x.shape)\n        x = x.reshape(-1, 16*28*28)\n        #print(x.shape)\n        x = F.relu(self.fc1_bn(self.fc1(x)))\n        #print(x.shape)\n        x = F.relu(self.fc2_bn(self.fc2(x)))\n        #print(x.shape)\n        return x\n\nclass JigsawNet(nn.Module):\n    \"\"\"\n    A neural network that solves 64x64 jigsaw puzzles.\n    \"\"\"\n    def __init__(self, sinkhorn_iter=0):\n        super().__init__()\n        self.conv_net = SimpleConvNet()\n        self.fc1 = nn.Linear(512*64, 8192)\n        self.fc1_bn = nn.BatchNorm1d(8192)\n        # 4 x 4 assigment matrix\n        self.fc2 = nn.Linear(8192, 4096)\n        self.sinkhorn_iter = sinkhorn_iter\n    \n    def forward(self, x):\n        # Split the input into four pieces and pass them into the\n        # same convolutional neural network.\n        piece=[]\n        for i in range (8):\n            for j in range(8):\n                one=self.conv_net(x[:,:, i*64:i*64+64, i*64:i*64+64])\n                piece.append(one)\n        # Cat\n        x = torch.cat(piece, dim=1)\n        #print(x.shape)\n        # Dense layer\n        x = F.dropout(x, p=0.1, training=self.training)\n        #print(x.shape)\n        x = F.relu(self.fc1_bn(self.fc1(x)))\n        #print(x.shape)\n        x = self.fc2(x)\n        #print(x.shape)\n        if self.sinkhorn_iter > 0:\n            x = x.view(-1, 64, 64)\n            x = sinkhorn(x, self.sinkhorn_iter)\n            x = x.view(-1, 4096)\n        return x","532a2dcd":"# Test helper\ndef compute_acc(p_pred, p_true, average=True):\n    \"\"\"\n    We require that the location of all four pieces are correctly predicted.\n    Note: this function is compatible with GPU tensors.\n    \"\"\"\n    # Remember to cast to float.\n    n = torch.sum((torch.sum(p_pred == p_true, 1) == 64).float())\n    if average:\n        return n \/ p_pred.size()[0]\n    else:\n        return n\n","9c51e939":"\n# Training process\ndef train_model(model, criterion, optimizer, train_loader, validation_loader,\n                n_epochs=40, save_file_name=None):\n    loss_history = []\n    val_loss_history = []\n    acc_history = []\n    val_acc_history = []\n    for epoch in range(n_epochs):\n        with tqdm(total=len(train_loader), desc=\"Epoch {}\".format(epoch + 1), unit='b', leave=False) as pbar:\n            # Training phase\n            model.train()\n            running_loss = 0.\n            n_correct_pred = 0\n            n_samples = 0\n            for i, data in enumerate(train_loader, 0):\n                inputs, perms = data\n                x_in=inputs\n                x_in=x_in.permute(0,3,1,2)\n                \n                #print(x_in.shape)\n                y_in = perm2vecmat2x2(perms)\n                \n                n_samples += inputs.size()[0]\n                if is_cuda_available:\n                    x_in, y_in = Variable(x_in.cuda()), Variable(y_in.cuda())\n                    perms = Variable(perms.cuda())\n                else:\n                    x_in, y_in = Variable(x_in), Variable(y_in)\n                    perms = Variable(perms)\n                optimizer.zero_grad()\n                outputs = model(x_in)\n                n_correct_pred += compute_acc(vecmat2perm2x2(outputs), perms, False)\n                loss = criterion(outputs, y_in)\n                print(loss)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss * x_in.size()[0]\n                pbar.update(1)\n            loss_history.append(running_loss \/ n_samples)\n            acc_history.append(n_correct_pred \/ n_samples)\n            \n            # Validation phase\n            model.eval()\n            running_loss = 0.\n            n_correct_pred = 0\n            n_samples = 0\n            for i, data in enumerate(validation_loader, 0):\n                inputs, perms = data\n                x_in=inputs\n                x_in=x_in.permute(0,3,1,2)\n                \n                #print(x_in.shape)\n                y_in = perm2vecmat2x2(perms)\n                n_samples += inputs.size()[0]\n                if is_cuda_available:\n                    x_in, y_in = Variable(x_in.cuda()), Variable(y_in.cuda())\n                    perms = Variable(perms.cuda())\n                else:\n                    x_in, y_in = Variable(x_in), Variable(y_in)\n                    perms = Variable(perms)\n                outputs = model(x_in)\n                n_correct_pred += compute_acc(vecmat2perm2x2(outputs), perms, False)\n                loss = criterion(outputs, y_in)\n                running_loss += loss * x_in.size()[0]\n            val_loss_history.append(running_loss \/ n_samples)\n            val_acc_history.append(n_correct_pred \/ n_samples)\n            \n            # Update the progress bar.\n            print(\"Epoch {0:03d}: loss={1:.4f}, val_loss={2:.4f}, acc={3:.2%}, val_acc={4:.2%}\".format(\n                epoch + 1, loss_history[-1], val_loss_history[-1], acc_history[-1], val_acc_history[-1]))\n    print('Training completed')\n    history = {\n        'loss': loss_history,\n        'val_loss': val_loss_history,\n        'acc': acc_history,\n        'val_acc': val_acc_history\n    }\n    # Save the model when requested.\n    if save_file_name is not None:\n        torch.save({\n            'history': history,\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict()\n        }, save_file_name)\n    return history\n","70ed8068":"\n# Test process\n# Compute the accuracy\ndef test_model(model, test_loader):\n    running_acc = 0.\n    n = 0\n    model.eval()\n    for i, data in enumerate(test_loader, 0):\n        inputs, perms = data\n        x_in=inputs\n        x_in=x_in.permute(0,3,1,2)\n                \n        #print(x_in.shape)\n        y_in = perm2vecmat2x2(perms)\n        if is_cuda_available:\n            x_in, y_in = Variable(x_in.cuda()), Variable(y_in.cuda())\n        else:\n            x_in, y_in = Variable(x_in), Variable(y_in)\n        pred = model(x_in)\n        perms_pred = vecmat2perm2x2(pred.cpu().data)\n        running_acc += compute_acc(perms_pred, perms, False)\n        n += x_in.size()[0]\n    acc = running_acc \/ n\n    return acc\n","527c6f9c":"n_epochs = 2\nsinkhorn_iter = 4\n\n# Create the neural network.\nmodel = JigsawNet(sinkhorn_iter=sinkhorn_iter)\nis_cuda_available = torch.cuda.is_available();\nif is_cuda_available:\n    model.cuda()\n\nn_params = 0\nfor p in model.parameters():\n    n_params += np.prod(p.size())\nprint('# of parameters: {}'.format(n_params))\n\n# We use binary cross-entropy loss here.\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters())\n\n# Train\n\nhistory = train_model(model, criterion, optimizer, train_loader, validation_loader,\n                      n_epochs=n_epochs)\n","1e241bb3":"model_save_name = 'classifier.pt'\ntorch.save(model.state_dict(), model_save_name)","b0a9ebfd":"plt.figure()\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'])\nplt.show()\nplt.figure()\nplt.plot(history['acc'])\nplt.plot(history['val_acc'])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'])\nplt.show()","1cb8f3f9":"# Calculate accuracy\nprint('Training accuracy: {}'.format(test_model(model, train_loader)))\nprint('Validation accuracy: {}'.format(test_model(model, validation_loader)))\n# Here training accuracy will be higher because dropout is disabled\n","a4d7f6c4":"Plot figure","ed7e7148":"Prepare training set and validation set","42e906e5":"Load train data in numpy array.\nAs they colorful image, making grayscale false","9c86dae2":"# Honor cup \nIn this problem, you have to restore the image, if it was previously divided into square fragments of **p\u00d7p** pixels, which were shuffled randomly. You are given a set of images, each has a size of **512\u00d7512** pixels. Divide each image into **m\u00d7m** square fragments of **pxp** pixels (m=512\/p) and rearrange them to restore the original image. It is guaranteed that all original images are regular photos (perhaps with some minor vertical\/horizontal scales).\n\nFor each image, you can get from 0 to 100 points. The score for the image is equal to the ratio of correctly defined **\"edges\"** between the images. Here, by an \"edge\" we call a horizontal or vertical segment of length p pixels, which separates two adjacent fragments along the side. An \"edge\" is defined correctly if output contains the edge the answer (the order of the fragments \"bottom-top\" or \"left-right\" matters). The total number of such \"edges\" is **2\u22c5m\u22c5(m\u22121)=k**. Formally, the score for the image will be **100\u22c5a\/k**, where **a** is the number of correct \"edges\". Points for the images in a test are summarized. If you do not provide an answer to the image, then the score for it is 0.\n\nProblem A contains tests with parameters p=64, m=8, k=112. Problem B contains tests with parameters p=32, m=16, k=480. Problem C contains tests with parameters p=16, m=32, k=1984. Each problem is divided into three subproblems.","88f4d079":"Import necessary packages to simulate the process","f4616454":"Take the answer line and split them by space.\nThen the data store in an array.","fbcf5636":"Main process","f52bc4a5":"Restore permuted image.","4630364f":"Make simple model","142d0a54":"Read answer file and get the lines in an array","61e6c5ba":"Testing restore function.","c96e2d3c":"Tester","c88dcb00":"Test helper","38e67782":"Make the train loader.","ddb38419":"Print first 6 lines","2f94e330":"Test process"}}