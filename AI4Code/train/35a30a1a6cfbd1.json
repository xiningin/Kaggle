{"cell_type":{"2d9e8245":"code","c8291c96":"code","16ecb464":"code","511a5b56":"code","c8190824":"code","e8b2ac2e":"code","72e6a03f":"code","25c12c4c":"code","3fce5d15":"code","7a39c433":"code","a5d629c6":"code","a4217bd3":"code","40b390da":"code","7b428694":"code","1b3bb16d":"markdown","aa4e1093":"markdown","735f8408":"markdown"},"source":{"2d9e8245":"import matplotlib.pyplot as plt\nimport numpy as np \nimport os\nimport pandas as pd","c8291c96":"from sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split","16ecb464":"from keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, BatchNormalization","511a5b56":"from keras.utils import Sequence\nclass SeqGen(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return int(np.ceil(len(self.x) \/ float(self.batch_size)))\n    \n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        return batch_x, batch_y","c8190824":"def get_model():\n    model = Sequential()\n    model.add(LSTM(16,input_shape=(11,11), return_sequences=True))    \n    model.add(LSTM(16))  \n    model.add(BatchNormalization())  \n    model.add(Dense(3, activation = 'softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n\n","e8b2ac2e":"def plot_history_accuracy(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","72e6a03f":"def plot_history_loss(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","25c12c4c":"def train_model(model, X, Y):\n    x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.3, random_state=42, shuffle=True )\n    standard = StandardScaler().fit(x_train)\n    x_train_standard = standard.transform(x_train).reshape(2016,11,11)\n    x_test_standard = standard.transform(x_test).reshape(864,11,11)\n    return model.fit_generator(SeqGen(x_train_standard,y_train,batch_size=12), validation_data=(x_test_standard,y_test), epochs=50, verbose=1)\n","3fce5d15":"df = pd.read_csv('\/kaggle\/input\/eeg-data-from-hands-movement\/Dataset\/user_a.csv', delimiter=',', index_col=False)\ndf.dataframeName = 'dataset.csv'","7a39c433":"X = df.iloc[:,1:]\nY = df.iloc[:,0]\nl = ['complement'] * (121 - X.shape[1]) \n\nfor index,col in enumerate(l):\n    X[col+str(index)] = 0\n\nX = X.values\nY = Y.values","a5d629c6":"encoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\ndummy_y = np_utils.to_categorical(encoded_Y)","a4217bd3":"model = get_model()\nhistory = train_model(model, X, dummy_y)","40b390da":"plot_history_accuracy(history)","7b428694":"plot_history_loss(history)","1b3bb16d":"### Pre-processing","aa4e1093":"### Simple RNN","735f8408":"### Read dataset"}}