{"cell_type":{"2a32eeea":"code","b8b3814d":"code","0f77b854":"code","91b91a88":"code","c7c011f2":"code","481f5831":"code","1c922cf0":"code","53a082e9":"code","9d8881e4":"code","129317e5":"code","556d3c0c":"code","368ace12":"code","a1ffdd20":"code","b427f793":"code","a548abd5":"code","95fc4d3b":"code","b56ef23e":"code","cbfdefe4":"code","96d6fad1":"code","55cbdc66":"markdown","fd252a16":"markdown","9a4a9b19":"markdown","ed1f992d":"markdown","75d8124a":"markdown","bb5cf745":"markdown"},"source":{"2a32eeea":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport zipfile\nwith zipfile.ZipFile('..\/input\/plates.zip', 'r') as zip_obj:\n   # Extract all the contents of zip file in current directory\n   zip_obj.extractall('\/kaggle\/working\/')\n    \nprint('After zip extraction:')\nprint(os.listdir(\"\/kaggle\/working\/\"))\n\ndata_root = '\/kaggle\/working\/plates\/'\nprint(os.listdir(data_root))","b8b3814d":"import shutil \nfrom tqdm import tqdm\n\ntrain_dir = 'train'\nval_dir = 'val'\n\nclass_names = ['cleaned', 'dirty']\n\nfor dir_name in [train_dir, val_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n\nfor class_name in class_names:\n    source_dir = os.path.join(data_root, 'train', class_name)\n    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n        if i % 6 != 0:\n            dest_dir = os.path.join(train_dir, class_name) \n        else:\n            dest_dir = os.path.join(val_dir, class_name)\n        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))","0f77b854":"import torch\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\n\ntorch.manual_seed(0)\nnp.random.seed(0)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nfrom torchvision import transforms, models\ntrain_transforms = transforms.Compose([\n     \n    transforms.RandomRotation(degrees = 80), \n    transforms.CenterCrop((224,224)),\n    #     transforms.RandomChoice(transforms = [transforms.CenterCrop((224,224)),transforms.RandomCrop((224,224))]),  \n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(size=224),\n    transforms.CenterCrop(size=224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\nval_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n\nbatch_size = 8\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","91b91a88":"len(train_dataloader), len(train_dataset)\nprint(val_dataset)","c7c011f2":"X_batch, y_batch = next(iter(train_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);","481f5831":"def show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=class_names[y_item])","1c922cf0":"from IPython import display\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef real_plot(epoch_acc_hist):\n    #loss, acc, val_loss, val_acc = zip(*history)\n  # acc, val_acc = history\n    plt.figure(figsize=(15, 9))\n    #plt.plot(acc, label=\"train_acc\")\n    #print('----------------')\n    plt.plot(epoch_acc_hist, label=\"val_acc\")\n    plt.legend(loc='best')\n    plt.xlabel(\"epochs\")\n    plt.ylabel(\"acc\")\n    plt.show()\n    display.clear_output(wait=True)\n    time.sleep(2)","53a082e9":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n    \n    epoch_loss_hist = []\n    epoch_acc_hist = []\n    for epoch in range(num_epochs):\n        #print('Epoch {}\/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                dataloader = val_dataloader\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.\n            running_acc = 0.\n\n            # Iterate over data.\n            for inputs, labels in dataloader: #tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                # forward and backward\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n\n            epoch_loss = running_loss \/ len(dataloader)\n            epoch_acc = running_acc \/ len(dataloader)\n            \n            epoch_loss_hist.append(epoch_loss)\n            \n            #epoch_acc_hist.append(epoch_acc)\n            \n            #print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n            if phase == 'val':\n                epoch_acc_hist.append(epoch_acc)\n                real_plot(epoch_acc_hist)\n    return model, epoch_loss_hist, epoch_acc_hist","9d8881e4":"# model = models.resnet50(pretrained=True) # \u0438\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \n\n# for param in model.parameters():  # \u0417\u0430\u043c\u043e\u0440\u0430\u0436\u0438\u0432\u0430\u0435\u043c \u0432\u0441\u0435 \u0441\u043b\u043e\u0438 \u0442.\u043a \u043e\u043d\u0438 \u0443\u0436\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u044b\n#     param.requires_grad = False\n\n# fc_inputs = model.fc.in_features\n# model.fc = torch.nn.Sequential(\n#     torch.nn.Linear(fc_inputs, 2),\n#     torch.nn.LogSoftmax(dim=1) #torch.nn.ReLU(), torch.nn.Dropout(0.4),\n# )\n\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# model = model.to(device)\n# loss = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma=0.2)","129317e5":"model = models.vgg16(pretrained=True)\n\n#models.resnet18(pretrained=True)\n# Disable grad for all conv layers\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.classifier = torch.nn.Sequential(\n    torch.nn.Linear(in_features=25088, out_features=4096, bias=True),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(p=0.5),\n    torch.nn.Linear(in_features=4096, out_features=4096, bias=True),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(p=0.5),\n    torch.nn.Linear(in_features=4096, out_features=2048, bias=True),\n    torch.nn.Linear(in_features=2048, out_features=2, bias=True),\n)\nprint(model)\n# model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n# model.classifier[7] = torch.nn.Dropout(p=0.2)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1.0e-2)\n# Decay LR by a factor of 0.1 every 7 epochs\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)","556d3c0c":"# \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\nmodel, epoch_loss_hist, epoch_acc_hist = train_model(model, loss, optimizer, scheduler, num_epochs=80);","368ace12":"plt.plot(epoch_loss_hist) # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u0448\u0438\u0431\u043a\u0438\nplt.plot(epoch_acc_hist) # \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c","a1ffdd20":"import shutil\nclass ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n    \n    \ntest_dir = 'test'\nshutil.rmtree(os.path.join(test_dir, 'unknown'))\nshutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'))\n\ntest_dataset = ImageFolderWithPaths('\/kaggle\/working\/test', val_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)","b427f793":"model.eval()\n\ntest_predictions = []\ntest_img_paths = []\nfor inputs, labels, paths in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n    \ntest_predictions = np.concatenate(test_predictions)","a548abd5":"inputs, labels, paths = next(iter(test_dataloader))\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","95fc4d3b":"submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})\nsubmission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred >= 0.5 else 'cleaned')\nsubmission_df['id'] = submission_df['id'].str.replace('\/kaggle\/working\/test\/unknown\/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df.set_index('id', inplace=True)\nsubmission_df.head(n=89)","b56ef23e":"submission_df.to_csv('submission.csv')","cbfdefe4":"!ls","96d6fad1":"# !rm -rf train val test","55cbdc66":"# \u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","fd252a16":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0433\u043b\u0430\u0437\u0430\u043c\u0438 \ud83d\udc40\ud83e\udd14","9a4a9b19":"# **\u0414\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u043e\u0433\u043d\u043e\u0437**","ed1f992d":"# **\u041e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c \u043e\u0442\u0432\u0435\u0442**","75d8124a":"# \u0420\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u0442\u0440\u0435\u0439\u043d \u0438 \u0442\u0435\u0441\u0442 (5:1)","bb5cf745":"# **\u0410\u0433\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 = \u043f\u0435\u0440\u0435\u0432\u0435\u0440\u043d\u0443\u0442\u044b\u0439 \u043a\u043e\u0442\u0438\u043a \u044d\u0442\u043e \u0432\u0441\u0435 \u0435\u0449\u0435 \u043a\u043e\u0442\u0438\u043a**"}}