{"cell_type":{"08f4ecac":"code","443c877a":"code","cb09ba49":"code","42e8780e":"code","6f781885":"code","a24417e2":"code","53233911":"code","94e5ff65":"code","0e1d29fe":"code","1bec3559":"code","3469c866":"code","8b3d4416":"code","89fcac9b":"code","6a890623":"code","b3f71239":"markdown","16528878":"markdown","e4df152b":"markdown","dd820bc3":"markdown","790db3ae":"markdown","44e25fe5":"markdown","b90678c3":"markdown","446b8866":"markdown"},"source":{"08f4ecac":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error # MSE metric\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostRegressor\nfrom hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\nfrom hyperopt import hp\n\nSEED = 91 # random seed","443c877a":"# Input data files are available in the read-only \"..\/input\/\" directory\nPATH = '\/kaggle\/input\/30-days-of-ml\/' # you can use your own local path\n\nprint('Files in directory:')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print('  '+os.path.join(dirname, filename))\nprint()\n\n# Load the training data\ntry:\n    df_train = pd.read_csv(PATH+'train.csv', index_col=0)\n    df_test = pd.read_csv(PATH+'test.csv', index_col=0)\n    submission = pd.read_csv(PATH+'sample_submission.csv', index_col=0)\n    print('All of the data has been loaded successfully!')\nexcept Exception as err:\n    print(repr(err))\nprint()","cb09ba49":"print(len(df_train))\nprint(len(df_test))","42e8780e":"#df_train = df_train.sample(frac=0.1, random_state=SEED)","6f781885":"CAT_FEATURES = ['cat0', 'cat1', 'cat3', 'cat5', 'cat8', 'cat9'] # most importance categorical features\nNUM_FEATURES = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8',\n                'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\nALL_FEATURES = CAT_FEATURES+NUM_FEATURES","a24417e2":"N_ITER = 10\nN_FOLDS = 3\n\nX_train, X_val, y_train, y_val = train_test_split(df_train[ALL_FEATURES], df_train['target'], \n                                                  test_size=0.20,\n                                                  shuffle=True,\n                                                  random_state=SEED)\n\nkf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)","53233911":"CONST_PARAMS = {\n    'cat_features': CAT_FEATURES,\n    'depth': 2,\n    'iterations': 5000,\n    'early_stopping_rounds': 20,\n    'task_type': 'GPU',\n    'silent': True,\n    'random_seed': SEED\n}","94e5ff65":"def catboost_rmse_cv(params, random_state=SEED, cv=kf, X=X_train, y=y_train):\n    # the function gets a set of variable parameters in \"param\"\n    catboost_params = {\n        **CONST_PARAMS,\n        'l2_leaf_reg': params['l2_leaf_reg'],\n        'random_strength': params['random_strength'],\n    }\n\n    model = CatBoostRegressor(**catboost_params)\n\n    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1).mean()\n\n    return score","0e1d29fe":"%%time\n\n# possible values of parameters\nspace={'l2_leaf_reg': hp.uniform('l2_leaf_reg', 1, 20),\n       'random_strength': hp.choice('random_strength', (0.0, 1.0)),\n      }\n\n# trials will contain logging information\ntrials = Trials()\n\nbest=fmin(fn=catboost_rmse_cv, # function to optimize\n          space=space, \n          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n          max_evals=N_ITER, # maximum number of iterations\n          trials=trials, # logging\n          rstate=np.random.RandomState(SEED) # fixing random state for the reproducibility\n         )\n\n# computing the score on the test set\nmodel = CatBoostRegressor(**CONST_PARAMS,\n                          l2_leaf_reg=best['l2_leaf_reg'],\n                          random_strength=best['random_strength'],\n                         )\nmodel.fit(X_train, y_train)\ntpe_test_score=mean_squared_error(y_val, model.predict(X_val))\n\nprint(\"Best RMSE {:.6f} with params {}\".format(catboost_rmse_cv(best), best))","1bec3559":"tpe_results=np.array([[x['result']['loss'],\n                      x['misc']['vals']['l2_leaf_reg'][0],\n                      x['misc']['vals']['random_strength'][0]] for x in trials.trials]\n                    )\n\ntpe_results_df=pd.DataFrame(tpe_results,\n                           columns=['score', 'l2_leaf_reg','random_strength'])\ntpe_results_df.plot(subplots=True,figsize=(10, 10))","3469c866":"feature_importance_df = pd.DataFrame(model.feature_importances_, index=X_train.columns)\nfeature_importance_df.sort_values(by=0, ascending=False)","8b3d4416":"from catboost import Pool\nimport shap as shap\n\ntrain_data = Pool(data=X_train,\n                  label=y_train,\n                  cat_features=CAT_FEATURES\n                 )\n                 \nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(train_data)\nshap.summary_plot(shap_values, X_train, feature_names=ALL_FEATURES)","89fcac9b":"model.fit(df_train[ALL_FEATURES], df_train['target'])\npredictions = model.predict(df_test[ALL_FEATURES])","6a890623":"# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': df_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","b3f71239":"# <center>CatBoost Hyperparameter tuning using Hyperopt<center>\n\nThis notebook for the 30 Days of ML competition.\n    \nIn this notebook has applied hyperparametr tuning using Hyperopt. Data splite with KFold for cross-validation. At the end look at feature importance.\n    \n#### Dataset:\nThe dataset is used for this competition is synthetic (and generated using a CTGAN), but based on a real dataset. The original dataset deals with predicting the amount of an insurance claim. \n* 'cat0' - 'cat9' categorical features\n* 'cont0' - 'cont13' continuous features\n* 'target' - continous target","16528878":"# Submit predictions","e4df152b":"Refit model on full train data","dd820bc3":"Function to calculate RMSE on each step","790db3ae":"# Load data","44e25fe5":"#### Feature importance","b90678c3":"# Model","446b8866":"# Import libraries"}}