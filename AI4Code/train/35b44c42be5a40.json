{"cell_type":{"3e7d32d7":"code","6a8f60f1":"code","49f82d12":"code","be52aad7":"code","2a60c138":"code","174bb45c":"code","a4bce70c":"code","154207da":"code","5fb3f6a1":"code","cc28b816":"code","4f1bbdc7":"code","f3930e2e":"code","55b7d8f8":"code","c32af73b":"code","e827deba":"code","add90536":"code","26a2171d":"code","5054ca86":"code","fd6d812f":"code","fd6fdc06":"code","2790a5ea":"code","9246c8c7":"code","98b9e35c":"code","8b97374f":"code","561f6ff7":"code","65fa8948":"code","7193be44":"code","4e60e9f6":"code","1b9e972a":"code","219baab4":"markdown","aeb327ae":"markdown","8458c925":"markdown","4f7404f9":"markdown","d93b4666":"markdown","bf398c9a":"markdown","a15a53d0":"markdown","1b2ebd79":"markdown","451d9ed4":"markdown","a9946e1f":"markdown","b3c57023":"markdown","83cb5be0":"markdown","bef4fda2":"markdown","bf6f89b8":"markdown","1d926f20":"markdown","d0dd1361":"markdown","ac7cfc65":"markdown","0bed0c15":"markdown","146e89aa":"markdown","09a6a31b":"markdown","8bd15524":"markdown","d42b72f0":"markdown","648b0751":"markdown"},"source":{"3e7d32d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a8f60f1":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras import optimizers, Sequential, Model\nimport keras\nimport seaborn as sns","49f82d12":"train = pd.read_csv('\/kaggle\/input\/dataprix21\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/dataprix21\/test.csv')\nsample=pd.read_csv('\/kaggle\/input\/dataprix21\/sampleSubmission.csv')","be52aad7":"train.info()","2a60c138":"\ntrain.head()","174bb45c":"train.nunique()","a4bce70c":"train=train.drop(['Diagnostic Testing','Carrier Testing','Enzyme Test','Insulin Test','Thyroid Test','Presence of severe allergies','Premature Delivery'],axis=1)\ntest=test.drop(['Diagnostic Testing','Carrier Testing','Enzyme Test','Insulin Test','Thyroid Test','Presence of severe allergies','Premature Delivery'],axis=1)","154207da":"train","5fb3f6a1":"train.isnull().sum()","cc28b816":"for column in train.columns:\n    mode = train[column].mode()\n    train[column].fillna(train[column].mode()[0], inplace=True)","4f1bbdc7":"for column in test.columns:\n    mode = test[column].mode()\n    test[column].fillna(test[column].mode()[0], inplace=True)","f3930e2e":"train","55b7d8f8":"from sklearn import preprocessing\nfor i in range(0,len(train)):\n    if(train['Gene B'].loc[i]=='Yes'):\n        train['Gene B'].loc[i]=1\n    if(train['Gene B'].loc[i]=='No'):\n        train['Gene B'].loc[i]=0\n    if(train['Gene A'].loc[i]=='Yes'):\n        train['Gene A'].loc[i]=1\n    if(train['Gene A'].loc[i]=='No'):\n        train['Gene A'].loc[i]=0\n    if(train['Gene C'].loc[i]=='Yes'):\n        train['Gene C'].loc[i]=1\n    if(train['Gene C'].loc[i]=='No'):\n        train['Gene C'].loc[i]=0  \n\n    if(train['Gene D'].loc[i]=='Yes'):\n        train['Gene D'].loc[i]=1\n    if(train['Gene D'].loc[i]=='No'):\n        train['Gene D'].loc[i]=0 \n\n    if(train['Breathing Rate'].loc[i]=='Normal (30-60)'):\n        train['Breathing Rate'].loc[i]=1\n    if(train['Breathing Rate'].loc[i]=='Tachypnea'):\n        train['Breathing Rate'].loc[i]=0 \n\n    if(train['Pulse rate'].loc[i]=='Normal'):\n        train['Pulse rate'].loc[i]=1\n    if(train['Pulse rate'].loc[i]=='Tachycardia'):\n        train['Pulse rate'].loc[i]=0 \n\n    if(train['Gastrin Defect'].loc[i]=='Yes'):\n        train['Gastrin Defect'].loc[i]=1\n    if(train['Gastrin Defect'].loc[i]=='No'):\n        train['Gastrin Defect'].loc[i]=0 \n\n    if(train['Neural Anomaly'].loc[i]=='Yes'):\n        train['Neural Anomaly'].loc[i]=1\n    if(train['Neural Anomaly'].loc[i]=='No'):\n        train['Neural Anomaly'].loc[i]=0 \n                      \n  \n\n    if(train['Assistance needed in fertility'].loc[i]=='Yes'):\n        train['Assistance needed in fertility'].loc[i]=1\n    if(train['Assistance needed in fertility'].loc[i]=='No'):\n        train['Assistance needed in fertility'].loc[i]=0  \n\n    if(train['Previous maternal pregnancy record'].loc[i]=='Yes'):\n        train['Previous maternal pregnancy record'].loc[i]=1\n    if(train['Previous maternal pregnancy record'].loc[i]=='No'):\n        train['Previous maternal pregnancy record'].loc[i]=0  \n    if(train['Gender'].loc[i]=='Male'):\n        train['Gender'].loc[i]=0\n    if(train['Gender'].loc[i]=='Female'):\n        train['Gender'].loc[i]=1\n    if(train['Gender'].loc[i]=='Ambiguous'):\n        train['Gender'].loc[i]=2\n    \n    if(train['CMP results'].loc[i]=='normal'):\n        train['CMP results'].loc[i]=0\n    if(train['CMP results'].loc[i]=='slightly abnormal'):\n        train['CMP results'].loc[i]=1\n    if(train['CMP results'].loc[i]=='abnormal'):\n        train['CMP results'].loc[i]=2\n    if(train['CMP results'].loc[i]=='normal'):\n        train['CMP results'].loc[i]=3\n    if(train['CMP results'].loc[i]=='inconclusive'):\n        train['CMP results'].loc[i]=4\n","c32af73b":"for i in range(0,len(test)):\n    if(test['Gene B'].loc[i]=='Yes'):\n        test['Gene B'].loc[i]=1\n    if(test['Gene B'].loc[i]=='No'):\n        test['Gene B'].loc[i]=0\n    if(test['Gene A'].loc[i]=='Yes'):\n        test['Gene A'].loc[i]=1\n    if(test['Gene A'].loc[i]=='No'):\n        test['Gene A'].loc[i]=0\n    if(test['Gene C'].loc[i]=='Yes'):\n        test['Gene C'].loc[i]=1\n    if(test['Gene C'].loc[i]=='No'):\n        test['Gene C'].loc[i]=0  \n\n    if(test['Gene D'].loc[i]=='Yes'):\n        test['Gene D'].loc[i]=1\n    if(test['Gene D'].loc[i]=='No'):\n        test['Gene D'].loc[i]=0 \n\n    if(test['Breathing Rate'].loc[i]=='Normal (30-60)'):\n        test['Breathing Rate'].loc[i]=1\n    if(test['Breathing Rate'].loc[i]=='Tachypnea'):\n        test['Breathing Rate'].loc[i]=0 \n\n    if(test['Pulse rate'].loc[i]=='Normal'):\n        test['Pulse rate'].loc[i]=1\n    if(test['Pulse rate'].loc[i]=='Tachycardia'):\n        test['Pulse rate'].loc[i]=0 \n\n    if(test['Gastrin Defect'].loc[i]=='Yes'):\n        test['Gastrin Defect'].loc[i]=1\n    if(test['Gastrin Defect'].loc[i]=='No'):\n        test['Gastrin Defect'].loc[i]=0 \n\n    if(test['Neural Anomaly'].loc[i]=='Yes'):\n        test['Neural Anomaly'].loc[i]=1\n    if(test['Neural Anomaly'].loc[i]=='No'):\n        test['Neural Anomaly'].loc[i]=0 \n                      \n  \n\n    if(test['Assistance needed in fertility'].loc[i]=='Yes'):\n        test['Assistance needed in fertility'].loc[i]=1\n    if(test['Assistance needed in fertility'].loc[i]=='No'):\n        test['Assistance needed in fertility'].loc[i]=0  \n\n    if(test['Previous maternal pregnancy record'].loc[i]=='Yes'):\n        test['Previous maternal pregnancy record'].loc[i]=1\n    if(test['Previous maternal pregnancy record'].loc[i]=='No'):\n        test['Previous maternal pregnancy record'].loc[i]=0  \n    if(test['Gender'].loc[i]=='Male'):\n        test['Gender'].loc[i]=0\n    if(test['Gender'].loc[i]=='Female'):\n        test['Gender'].loc[i]=1\n    if(test['Gender'].loc[i]=='Ambiguous'):\n        test['Gender'].loc[i]=2\n    \n    if(test['CMP results'].loc[i]=='normal'):\n        test['CMP results'].loc[i]=0\n    if(test['CMP results'].loc[i]=='slightly abnormal'):\n        test['CMP results'].loc[i]=1\n    if(test['CMP results'].loc[i]=='abnormal'):\n        test['CMP results'].loc[i]=2\n    if(test['CMP results'].loc[i]=='normal'):\n        test['CMP results'].loc[i]=3\n    if(test['CMP results'].loc[i]=='inconclusive'):\n        test['CMP results'].loc[i]=4\n","e827deba":"X = train.drop(['Metabolic Syndrome Type'], axis=1)\nY = train['Metabolic Syndrome Type']","add90536":"X=X.drop('Subject Id',axis=1).astype(int)\ntest=test.drop('Subject Id',axis=1).astype(int)","26a2171d":"X_train, X_test, Y_train, Y_test = train_test_split(X , Y,test_size=0.25,random_state=52)","5054ca86":"Y_train","fd6d812f":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.multioutput import MultiOutputRegressor\nmultioutputregressor =MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100))\nmultioutputregressor.fit(X_train,pd.get_dummies(Y_train))\nypred=multioutputregressor.predict(X_test)\n\npreds_2=[]\n\nfor i in ypred:\n    if(i[0]>i[1] and i[0]>i[2]):\n        preds_2.append(\"Type A\")\n    if(i[1]>i[2] and i[1]>i[0]):\n        preds_2.append(\"Type B\")\n    if(i[2]>i[1] and i[2]>i[0]):\n        preds_2.append(\"Type C\")\n        \n\nf1_score(preds_2,Y_test,average='micro')","fd6fdc06":"from keras.layers import Dropout\nimport matplotlib.pyplot as plt\nimport tensorflow.keras as keras\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tqdm import tqdm\nmodel = Sequential()\nmodel.add(Dense(units = 16, activation='relu', input_shape=(X_train.loc[0].shape)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 16, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 8, activation='relu'))\nmodel.add(Dense(units = 3, activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, pd.get_dummies(Y_train), epochs=100, verbose=1, validation_data=(X_test, pd.get_dummies(Y_test)))\nypred_1 =model.predict(X_test)\n\npreds_2=[]\n\nfor i in ypred_1:\n    if(i[0]>i[1] and i[0]>i[2]):\n        preds_2.append(\"Type A\")\n    if(i[1]>i[2] and i[1]>i[0]):\n        preds_2.append(\"Type B\")\n    if(i[2]>i[1] and i[2]>i[0]):\n        preds_2.append(\"Type C\")\n        \n\nf1_score(preds_2,Y_test,average='micro')","2790a5ea":"\nfrom sklearn import metrics\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nmlp = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(70,70,), random_state=1)\nmlp.out_activation_ = 'softmax'\npipe = Pipeline([('scaler', StandardScaler()), ('mlp', mlp)])\npipe.fit(X_train,Y_train)\ny_preds_2=pipe.predict(X_test)\nf1_score(y_preds_2,Y_test,average='micro')","9246c8c7":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nxgb_params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\n\nxgb_clf = XGBClassifier( learning_rate=0.02,n_estimators=600, objective='binary:logistic',\n                    silent=True, nthread=1)\n\nxgb_random_search = RandomizedSearchCV(\n       estimator=xgb_clf,\n       param_distributions=xgb_params,\n       n_iter=25,\n       cv=3,\n       scoring='accuracy',\n       verbose=2,\n       random_state=42,\n       n_jobs=-1\n        )\n\nxgb_random_search.fit(X_train, Y_train)\ny_pred_3=xgb_random_search.predict(X_test)\n \n","98b9e35c":"f1_score(y_pred_3,Y_test,average='micro')","8b97374f":"from sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier\ndef test_params(**params):\n    xgb_params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\n\n    xgb_clf = XGBClassifier( **params, objective='binary:logistic',\n                    silent=True, nthread=1)\n\n    xgb_random_search = RandomizedSearchCV(\n       estimator=xgb_clf,\n       param_distributions=xgb_params,\n       n_iter=25,\n       cv=3,\n       scoring='accuracy',\n       verbose=2,\n       random_state=42,\n       n_jobs=-1\n        )\n\n    xgb_random_search.fit(X_train, Y_train)\n    y_pred=xgb_random_search.predict(X_test)\n    from sklearn.metrics import f1_score\n    return f1_score(y_pred,Y_test,average='micro')","561f6ff7":"test_params(n_estimators=800),test_params(n_estimators=650),test_params(n_estimators=600),test_params(n_estimators=500)","65fa8948":"test_params(n_estimators=600, learning_rate=0.02),test_params(n_estimators=600, learning_rate=0.001)","7193be44":"xgb_params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\n\nxgb_clf = XGBClassifier( learning_rate=0.02,n_estimators=600, objective='binary:logistic',\n                    silent=True, nthread=1)\n\nxgb_random_search = RandomizedSearchCV(\n       estimator=xgb_clf,\n       param_distributions=xgb_params,\n       n_iter=25,\n       cv=3,\n       scoring='accuracy',\n       verbose=2,\n       random_state=42,\n       n_jobs=-1\n        )\n\nxgb_random_search.fit(X_train, Y_train)\n\npreds=xgb_random_search.predict(test)","4e60e9f6":"preds","1b9e972a":"sample[\"Metabolic Syndrome Type\"]=preds\n\nsample.to_csv(\"result.csv\", index=False)","219baab4":"\nF1_score of Vanilla Neural Network=0.5256217030896759","aeb327ae":"Since the features Diagnostic Testing,Carrier Testing,Enzyme Test,Insulin Test and Thyroid Test have no unique variables,I have dropped them.Since the features Presence of severe allergies and Premature Delivery contain several unknown variables,I have  removed them as well","8458c925":"**Model 2-Vanilla Neural Network**","4f7404f9":"F1 score of XGBoost Classifier-0.5388093443858327","d93b4666":"Hyperparameter Tuning and Regularization","bf398c9a":"The following steps have been taken by me to predict the metabolic syndromes\n1. Preprocessing\n* Removing columns with common values\n* Filling NaN values\n* Label Encoding of categorical features\n2.  Model Evaluation\n* Changing the type of variables in the train and test data to integer variables\n* Finding out the model with the best f1 score(XGBClassifier)\n3. Hyperparameter tuning\n* Tuning it's hyperparameters\n4.  Submission of predictions\n","a15a53d0":"Model 3-MLPClassifier","1b2ebd79":"Model 4-XGBoost Classifier","451d9ed4":"Learning Rate\n0.02-0.5388093443858327,\n0.01-0.5275056518462697","a9946e1f":"****Preprocessing****","b3c57023":"Submi","83cb5be0":"Let us find out the suitable learning rate of the model","bef4fda2":"Submission of Predictions\n","bf6f89b8":"Converted the datatype of variables in train and test data from object and float to integer for better accuracy","1d926f20":"Model 1-GradientBosstingRegressor","d0dd1361":"Let us determine the  number of trees to be created","ac7cfc65":"Label Encoding all categorical variables","0bed0c15":"Dividing the dataset for training and evaluation","146e89aa":"F1 score of MLPClassifier=0.4577995478522984","09a6a31b":"Given that most of the data is categorical and the null values for each column is unknown,I have replace them with the most frequent value of the column it is present in","8bd15524":"F1_score of GradientBoostingRegressor=0.5369253956292389","d42b72f0":"Since XGBoost Classifier gave the most accurate results compared to the other models,I have used XGBClassifier.","648b0751":"n_estimators-\n600-(0.5365486058779201,\n650-.5357950263752826,\n800-0.5388093443858327,\n500-0.5369253956292389)"}}