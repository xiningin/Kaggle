{"cell_type":{"e3b4be81":"code","f235fcc9":"code","95183f94":"code","6a7c5113":"code","7241fae3":"code","5b60870d":"code","c89dd2b5":"code","a59ad274":"code","b61673c3":"code","d1a6a2af":"code","319ab52b":"code","c0c90267":"code","fd553e40":"code","e6cb306d":"code","751aae43":"code","6fbe2b3c":"code","a3cbb48e":"code","4e294273":"code","42d4b904":"code","01190bda":"code","cbfb7240":"code","7d8e00b6":"code","b7823d6d":"code","68a4b344":"code","0792fbd7":"code","2a6c9e38":"code","300463b3":"code","f1bd9f22":"code","58e190cc":"code","96a6c55d":"code","c19dbce5":"code","ae299b29":"code","d9f617dd":"code","b1d6b168":"code","e828dad6":"code","4024ff48":"code","64424b09":"code","c5163b4c":"code","2ff20b56":"code","37c153b5":"code","f0e0d862":"code","b94b1c35":"code","d21eab7d":"code","4915cb0b":"code","06d0b9e9":"markdown","d32d3f4d":"markdown","f01d2880":"markdown","06b49870":"markdown","f8b521f8":"markdown"},"source":{"e3b4be81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f235fcc9":"data=pd.read_csv(\"..\/input\/groceries-dataset\/Groceries_dataset.csv\")\n#data.style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0, subset=None)","95183f94":"data.shape","6a7c5113":"data.head()","7241fae3":"data.groupby(['Date'])['itemDescription'].agg(['count']).plot(figsize=(12,5), grid=True, title=\"Total Number of Items Sold by Date\").set(xlabel=\"Date\", ylabel=\"Total Number of Items Sold\")","5b60870d":"d=data.set_index(['Date'])","c89dd2b5":"d","a59ad274":"d.index=pd.to_datetime(d.index)","b61673c3":"total_items = len(d)\ntotal_days = len(np.unique(d.index.date))\ntotal_months = len(np.unique(d.index.month))\naverage_items = total_items \/ total_days\nunique_items = d.itemDescription.unique().size\n\nprint(\"There are {} unique items sold \".format(unique_items))\nprint(\"Total {} items sold in {} days throughout {} months\".format(total_items, total_days, total_months))\nprint(\"With an average of {} items sold daily\".format(average_items))","d1a6a2af":"d.resample(\"D\")['itemDescription'].count().plot(figsize=(12,5), grid=True, title=\"Total Number of Items Sold by Date\").set(xlabel=\"Date\", ylabel=\"Total Number of Items Sold\")","319ab52b":"d.resample(\"M\")['itemDescription'].count().plot(figsize=(12,5), grid=True, title=\"Total Number by Items Sold by Month\").set(xlabel=\"Date\", ylabel=\"Total Number of Items Sold\")","c0c90267":"d[\"Hour\"] = d.index.hour\nd[\"Weekday\"] = d.index.weekday + 1\n\nd.head(10)","fd553e40":"data['itemDescription'].value_counts()","e6cb306d":"data['Date'].nunique()","751aae43":"import plotly.express as px","6fbe2b3c":"def bar_plot(df,col):\n\n    fig = px.bar(df,\n        x = df[col].value_counts().keys(), \n        y = df[col].value_counts().values,\n        color= df[col].value_counts().keys()\n    )\n    fig.update_layout(\n    xaxis_title= col,\n    yaxis_title=\"Count\",\n    legend_title=col,\n    font_family=\"Courier New\",\n    font_color=\"blue\",\n    title_font_family=\"Times New Roman\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\"\n)\n    \n    fig.show()","a3cbb48e":"bar_plot(data,'itemDescription')","4e294273":"df=data.groupby(['Member_number','Date'])['itemDescription'].apply(sum)","42d4b904":"df","01190bda":"df.values","cbfb7240":"pd.set_option('display.max_colwidth', -1)","7d8e00b6":"transactions = [a[1]['itemDescription'].tolist() for a in list(data.groupby(['Member_number','Date']))]","b7823d6d":"transactions","68a4b344":"from mlxtend.preprocessing import TransactionEncoder","0792fbd7":"te = TransactionEncoder()\n","2a6c9e38":"te_ary = te.fit(transactions).transform(transactions)","300463b3":"te.columns_","f1bd9f22":"te_ary","58e190cc":"transactions = pd.DataFrame(te_ary, columns=te.columns_)\npf = transactions.describe()","96a6c55d":"pf","c19dbce5":"pf.iloc[0]-pf.iloc[3]","ae299b29":"f = pf.iloc[0]-pf.iloc[3]\na = f.tolist()\nb = list(f.index)\nitem = pd.DataFrame([[a[r],b[r]]for r in range(len(a))], columns=['Count','Item'])\nitem = item.sort_values(['Count'], ascending=False).head(50)\ntransactions","d9f617dd":"item","b1d6b168":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud\n\nplt.rcParams['figure.figsize'] = (15, 15)\nwordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 121).generate(str(item['Item']))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Items',fontsize = 20)\nplt.show()","e828dad6":"fig = px.treemap(item, path=['Item'], values='Count')\nfig.show()","4024ff48":"from mlxtend.frequent_patterns import apriori, association_rules\nimport matplotlib.pyplot as plt","64424b09":"freq_items = apriori(transactions, min_support=0.001, use_colnames=True, verbose=1)\nfreq_items.head(7)","c5163b4c":"freq_items['length'] = freq_items['itemsets'].apply(lambda x: len(x))","2ff20b56":"freq_items.head(10)","37c153b5":"freq_items.tail(10)","f0e0d862":"rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.001)\nrules.head()","b94b1c35":"fig=px.scatter(rules['support'], rules['confidence'])\nfig.update_layout(\n    xaxis_title=\"support\",\n    yaxis_title=\"confidence\",\n   \n    font_family=\"Courier New\",\n    font_color=\"blue\",\n    title_font_family=\"Times New Roman\",\n    title_font_color=\"red\",\n    title=('Support vs Confidence')\n    \n)\n\nfig.show()","d21eab7d":"fig=px.scatter(rules['support'], rules['lift'])\nfig.update_layout(\n    xaxis_title=\"support\",\n    yaxis_title=\"lift\",\n   \n    font_family=\"Courier New\",\n    font_color=\"blue\",\n    title_font_family=\"Times New Roman\",\n    title_font_color=\"red\",\n    title=('Support vs Confidence')\n    \n)\n\nfig.show()","4915cb0b":"fit = np.polyfit(rules['lift'], rules['confidence'], 1)\nfit_fn = np.poly1d(fit)\nplt.plot(rules['lift'], rules['confidence'], 'yo', rules['lift'], \nfit_fn(rules['lift']))\nplt.xlabel('lift')\nplt.ylabel('Confidence')\nplt.title('lift vs Confidence')","06d0b9e9":"**Apriori is an algorithm for frequent item set mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.**","d32d3f4d":"![](https:\/\/datamathstat.files.wordpress.com\/2018\/02\/untitled.png)","f01d2880":"for details about TransactionEncoder-http:\/\/rasbt.github.io\/mlxtend\/user_guide\/preprocessing\/TransactionEncoder\/","06b49870":"**The dataset has 38765 rows of the purchase orders of people from the grocery stores. These orders can be analysed and association rules can be generated using Market Basket Analysis by algorithms like Apriori Algorithm.**","f8b521f8":"To construct association rules between elements or items, the algorithm considers 3 important factors which are, support, confidence and lift. Each of these factors is explained as follows:\n\nSupport:\nThe support of item I is defined as the ratio between the number of transactions containing the item I by the total number of transactions expressed as :\n\n**Support(I)=Number of transactions containing I\/Total number of Transactions\n**\n\nConfidence:\nThis is measured by the proportion of transactions with item I1, in which item I2 also appears. The confidence between two items I1 and I2,  in a transaction is defined as the total number of transactions containing both items I1 and I2 divided by the total number of transactions containing I1.\n\n**Confidence(I1->I2)=Number of Transactions containing I1 and I2\/(Total Number of Transactions containing I1)**\n\nLift:\nLift is the ratio between the confidence and support expressed as :\n\n**Lift(I1->I2)=Confidence(I1->I2)\/Support(I2)**\n"}}