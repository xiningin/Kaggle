{"cell_type":{"30a9a446":"code","abb0d5a4":"code","64624e32":"code","92ed34b8":"code","7f197c8f":"code","26a07a6a":"code","14d5d9e7":"code","5a0dd290":"code","b77965cf":"code","8633d0d0":"code","4e9dbb6e":"code","0d2bf270":"code","e4877479":"code","df1f7134":"code","72e94c12":"code","c853cc88":"markdown","1e9ff662":"markdown","4d531224":"markdown","3e66480c":"markdown","8b6c32c2":"markdown","9d888f2c":"markdown","7d0dd3da":"markdown","e241fbb3":"markdown","400d0f0f":"markdown","84dfc8fb":"markdown","287c436b":"markdown","ea7569a9":"markdown","2aa9067e":"markdown","c20e69ec":"markdown","7bece324":"markdown","6fc120eb":"markdown"},"source":{"30a9a446":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","abb0d5a4":"# import libraries\nimport time\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom scipy.signal import hilbert\nfrom scipy.signal import spectrogram\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nsns.set()","64624e32":"# check submission file\nsubmission = pd.read_csv('..\/input\/sample_submission.csv', index_col='seg_id')\nsubmission.head()","92ed34b8":"PATH = \"..\/input\"\nprint(\"There are {} files in the test folder\".format(len(os.listdir(os.path.join(PATH, \"test\")))))\n","7f197c8f":"# example 30 test files\ntests = os.listdir(os.path.join(PATH, \"test\"))\nn_tests = len(tests)\n\n# downsampling size\nds = 200\n\n# random sampling for test files\nN = 30\nnp.random.seed(1220)\nidx = np.random.choice(n_tests, N)\n\n# fig & ax\nnrow = int(N\/5)\nfig, ax = plt.subplots(nrow, 5, figsize=(16, 12))\nc = 0\nfor i in range(nrow):\n    for j in range(5):\n        # load data\n        seg = pd.read_csv(os.path.join(PATH, \"test\/\" + tests[idx[c]]))\n        \n        # zscore\n        seg = stats.zscore(seg)\n        \n        # plot\n        ax[i, j].plot(seg[::ds], color='g')\n        ax[i, j].title.set_text(tests[idx[c]])\n        ax[i, j].axis(\"off\")\n        \n        c += 1","26a07a6a":"%%time\ntrain_df = pd.read_csv(os.path.join(PATH, \"train.csv\"), \n                       dtype={\"acoustic_data\": np.int16, \n                              \"time_to_failure\": np.float32})","14d5d9e7":"print(\"Train data has {} rows and {} columns\"\n      .format(train_df.shape[0], train_df.shape[1]))","5a0dd290":"# head 10\npd.options.display.precision = 15\ntrain_df.head(10)","b77965cf":"# plot all data, downsampled\n\n# fig & ax\nfig, ax1 = plt.subplots(figsize=(12, 8))\n\n# acoustic data\nax1.plot(train_df[\"acoustic_data\"].values[::ds], color='g')\nax1.set_ylabel(\"acoustic data\")\nax1.tick_params('y', colors='g')\n\n# time to failure\nax2 = ax1.twinx()\nax2.plot(train_df[\"time_to_failure\"].values[::ds], color='r')\nax2.set_ylabel(\"time to failure\")\nax2.tick_params('y', colors='r')","8633d0d0":"# too heavy to take them anymore\nacousticData = train_df[\"acoustic_data\"][::ds].values\ntimeToFailure = train_df[\"time_to_failure\"][::ds].values\n\ndel train_df","4e9dbb6e":"# timing (index) of events\nsorted_idx = np.argsort(np.diff(timeToFailure))\nsorted_idx = sorted_idx[::-1]\neventTiming = np.sort(sorted_idx[0:15])\nprint(\"Timing of events: \" + str(eventTiming))","0d2bf270":"# event triggered average (n = 16)\nfig, ax1 = plt.subplots(4, 4, figsize=(12, 8))\nc = 0\nfor i in range(4):\n    for j in range(4):\n        triggeredRange = range(sorted_idx[c]-int(1500000\/ds), sorted_idx[c]+int(500000\/ds))\n\n        # acoustic data\n        ax1[i, j].plot(acousticData[triggeredRange], color='g')\n        ax1[i, j].axis(\"off\")\n\n        # time to failure\n        ax2 = ax1[i, j].twinx()\n        ax2.plot(timeToFailure[triggeredRange], color='r')\n        ax2.axis(\"off\")\n\n        c += 1","e4877479":"# event amplitude (max - min) vs time to failure from peak\namplitude = np.zeros(16)\nmax_to_failure = np.zeros(16)\nmin_to_failure = np.zeros(16)\nfor c in range(16):\n    triggeredRange = range(sorted_idx[c]-int(1500000\/ds), sorted_idx[c]+int(500000\/ds))\n    amplitude[c] = np.max(acousticData[triggeredRange]) - np.min(acousticData[triggeredRange])\n    max_to_failure[c] = int(1500000\/ds) - np.argmax(acousticData[triggeredRange])\n    min_to_failure[c] = int(1500000\/ds) - np.argmin(acousticData[triggeredRange])\n    \n# correlation?\nfig, ax = plt.subplots(1, 2, figsize=(12, 8))\nsns.regplot(x=amplitude, y=max_to_failure, ax=ax[0])\nax[0].set_xlabel(\"amplitude\")\nax[0].set_ylabel(\"time: event - max\")\nsns.regplot(x=amplitude, y=min_to_failure, ax=ax[1])\nax[1].set_xlabel(\"amplitude\")\nax[1].set_ylabel(\"time: event - min\")","df1f7134":"# spectrogram\nfig, ax1 = plt.subplots(4, 4, figsize=(12, 8))\nc = 0\nfor i in range(4):\n    for j in range(4):\n        triggeredRange = range(sorted_idx[c]-int(1500000\/ds), sorted_idx[c])\n\n        # FFT of acoustic data\n        f, t, Sxx = spectrogram(acousticData[triggeredRange], ds)\n        \n        # acoustic data\n        ax1[i, j].pcolormesh(t, f, Sxx)\n        if j == 0:\n            ax1[i, j].set_ylabel(\"frequency (Hz)\")\n            ax1[i, j].set_xlabel(\"\")\n            ax1[i, j].get_xaxis().set_ticks([])\n        else:\n            ax1[i, j].axis(\"off\")\n\n        c += 1","72e94c12":"# FFT\nfig, ax1 = plt.subplots(4, 4, figsize=(12, 8))\nc = 0\nfor i in range(4):\n    for j in range(4):\n        triggeredRange = range(sorted_idx[c]-int(10000\/ds), sorted_idx[c])\n\n        # FFT of acoustic data\n        power = 10*np.log10(np.abs(np.fft.rfft(acousticData[triggeredRange])))\n        f = np.linspace(0, ds\/2, len(power))\n        \n        # acoustic data\n        ax1[i, j].plot(f, power, c='b')\n        if j == 0:\n            ax1[i, j].set_ylabel(\"power\")\n            ax1[i, j].set_xlabel(\"\")\n            ax1[i, j].get_xaxis().set_ticks([])\n        elif i == 3:\n            ax1[i, j].set_ylabel(\"\")\n            ax1[i, j].set_xlabel(\"frequency (Hz)\")\n            ax1[i, j].get_yaxis().set_ticks([])\n        else:\n            ax1[i, j].set_ylabel(\"\")\n            ax1[i, j].set_xlabel(\"\")\n            ax1[i, j].get_xaxis().set_ticks([])\n            ax1[i, j].get_yaxis().set_ticks([])\n\n        c += 1","c853cc88":"... the train data contain over 600 million rows. This is huge.","1e9ff662":"Ah, OK, quite a lot. Let's have a look at 30 of them, which are picked up randomly. I do not have much RAM space (~13 GB), so I spare some by downsampling the data (using every 200 data points).","4d531224":"The exact value of frequency may not be correct, but anyway you see differences in power between frequencies. Those information may be important to predict the time_to_failure.\n\nIn conclusion, here in this kernel, some event-triggered analysis were performed to help feature engineering and building a model.","3e66480c":"It looks clean: just 2 columns. The second column is all zero, which we are asked to replace.\n\nHow many test files do we have?","8b6c32c2":"This visualization clearly shows that the event is always preceded by a big spike of acoustic_data. The interval between an event and the timing of a big spike looks similar across events. \n\nIs the amplitude of the spikes (max - min) related to the interval?","9d888f2c":"It is always nice to start with the data description, which tells us what we are asked to do:\n\n>The goal of this competition is to use seismic signals to predict **the timing of laboratory earthquakes**. The data comes from a well-known experimental set-up used to study earthquake physics. The acoustic_data input signal is used to predict the time remaining before the next laboratory earthquake (time_to_failure).\n\n>The training data is a single, continuous segment of experimental data. The test data consists of a folder containing many small segments. **The data within each test file is continuous, but the test files do not represent a continuous segment of the experiment**; thus, **the predictions cannot be assumed to follow the same regular pattern seen in the training file**.\n\n>For each seg_id in the test folder, **you should predict a single time_to_failure corresponding to the time between the last row of the segment and the next laboratory earthquake**.\n\nThe task is relatively straightforward ... to predict the timing of artificial earthquake. \n\nWhat is not straightforward is the second paragraph, which implies that **a model trained on the training data might not be useful for a prediction on the test data**.\n\nAnyway let's look at data file first.","7d0dd3da":"Yet there are just 2 columns: acoustic_data and time_to_failure. \n\nHow are they related?","e241fbb3":"It takes long time to load the data! Surely you need to specify the data type at least to accelerate the process because ...","400d0f0f":"Although the data is huge, there seems to be only 16 events, which occur in similar intervals.","84dfc8fb":"Yes, moderately. If the spike is huge, the event is likely to occur soonish. This is intuitive given the experimental setup for earthquake.\n\nIn a physical system (like the brain), it is sometimes the case where a particular frequency of the signal tells a lot about the system. Here is the spectrogram of the acoustic_data, where the right end of the x-axis is the timing of the event. ","287c436b":"Data are quite noisy and variable in terms of signal-to-noise ratio. All I can see is that there are some big spikes occasionally.\n\nHow does the train data look like?","ea7569a9":"They are nice enough to give us the sample_submission.csv file.\n\nAlso, train is a sigle csv file, whereas test is a folder containing a lot of data.\n\nNext, libraries.","2aa9067e":"Those bright areas correspond to the spikes in the signal. Interestingly the distribution of power is variable across events.\n\nThe spikes are outliers, so maybe it is more informative to see the signal without the spikes in the power-frequency space by FFT.  ","c20e69ec":"To see what in acoustic_data drives time_to_failure, the most intuitive way would be an event-triggered analysis: look at acoustic_data around the timing of the events.","7bece324":"Seemingly events (time_to_failure ~= 0) occur after big spikes.\n\nMy RAM is almost full already. I downsample the data and remove the original file.","6fc120eb":"How does the sample_submission.csv look like? "}}