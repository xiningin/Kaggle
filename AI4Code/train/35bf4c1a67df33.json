{"cell_type":{"3ec16a15":"code","603d2d1d":"code","311ad254":"code","dd1aaa7d":"code","f6f73a16":"code","7c827684":"code","d0c8ef94":"code","14533ba1":"code","66c13547":"code","af85ca0c":"code","ce9dc013":"code","374dc030":"code","d903be65":"code","528a4d79":"code","5c79c22c":"code","aa61abc9":"code","64e9ed1f":"code","11aa1557":"code","fc92482c":"code","c0e4146c":"code","4f50e99c":"code","b96502aa":"code","4a6180c8":"code","e61c80d8":"code","32b04dd9":"code","fcb41816":"code","618efa20":"code","8f365b37":"code","59b8417f":"code","d98fa109":"code","b957f0bf":"code","589e378f":"code","5eca5d7a":"code","11516d3a":"code","32d3f407":"code","37803b91":"code","66ebf601":"code","2587e737":"code","a4ab7fed":"code","1d832c45":"code","39cd24b2":"code","dc225400":"code","0e8672cd":"code","42caf80b":"code","e2d0b327":"code","99000637":"code","9f636a07":"code","8aa43a26":"code","29a2f475":"code","5ab32f4f":"code","3a429e6d":"code","97449451":"code","14a4bc0b":"code","ac0ca2ae":"code","4d420f53":"code","a8e8668e":"code","8015942c":"code","f8a28464":"code","384b7cea":"code","3db37828":"code","309063f1":"code","eb2472ee":"code","05e9b983":"code","8f0ba95f":"code","9efab7cd":"code","a4d38c4a":"code","d15c3ff1":"code","e771733d":"code","385b64ac":"code","863a01c5":"code","6c2838ba":"code","a8185d69":"code","b77b0746":"code","85f437fd":"code","9aa25ddf":"code","b22f461c":"code","848127fd":"code","2d02b036":"code","5d7ed75b":"markdown","38705bf0":"markdown","3def6873":"markdown","8bd8d5dc":"markdown","7e0e04b3":"markdown","f56daa35":"markdown","b549a3a8":"markdown","e99f5c47":"markdown","b9bbe2a2":"markdown","b1ef5427":"markdown","3e0abd76":"markdown","2c6fc458":"markdown","b8a6ed0a":"markdown","fb7a5da6":"markdown","7d301364":"markdown","c73a8e35":"markdown","06cfddb4":"markdown","7817ea09":"markdown","f20d1d11":"markdown","22325955":"markdown","76abf40b":"markdown","ba291f80":"markdown","9e0e2d31":"markdown","6181b321":"markdown","57b7f59d":"markdown","44eb80e6":"markdown"},"source":{"3ec16a15":"#importing usefull lib\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings as wr\nwr.filterwarnings(\"ignore\")\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","603d2d1d":"#reading the data using pandas read_csv. \n#It's ofthen used pandas fuction to read csc file.\nimport pandas as pd\ndf1=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf1.head()","311ad254":"#checking shape of data frame\ndf1.shape","dd1aaa7d":"#here we check mean,std,quantiles value using pandas describe function\ndf1.describe()","f6f73a16":"#extracting all columns from the data frame for forother uses\ndf1.columns.tolist()\n","7c827684":"#count NA values\ndf1.isnull().sum()","d0c8ef94":"#dropng unrelated column\n#here we going to drop cabin bcz it's have lots of nan vales\n#here is nothing use in traing og passenger id so simply we drop it using pandas drop()\ndf=df1.drop([\"PassengerId\",\"Ticket\",\"Cabin\"],axis=1)\ndf.head()","14533ba1":"#filing NA values\n#here we filling na values by mean() for numerical values \n#and mode() for categorical \ndf[\"Age\"].fillna(df[\"Age\"].mean(),inplace=True)\ndf['Embarked'].fillna(df['Embarked'].mode()[0],inplace=True)","66c13547":"df.info()","af85ca0c":"print(f'Number of people dead as 0 are {df.Survived.value_counts()[0]} and Number of people survived as 1 are {df.Survived.value_counts()[1]}')\nsns.countplot(df[\"Survived\"])\nplt.show()\n","ce9dc013":"\n#here wr checking outliers \nf,ax=plt.subplots()\nsns.violinplot(data=df.iloc[:,5:7])\nsns.despine(offset=10,trim=True)","374dc030":"f,ax=plt.subplots()\nsns.violinplot(data=df.iloc[:,0:2])\n#sns.despine(offset=10,trim=True)\nsns.swarmplot(data=df.iloc[:,0:2],color=\"white\")\n","d903be65":"#here we going to ploat scaterplot to see data distirbution\nsns.relplot(x=\"Pclass\",y=\"Age\",hue=\"Survived\",data=df);","528a4d79":"#visualisation how many pasanger survived and how many dead\n#here we creat a function for bar_chart \n#for avoiding write same code for defrent columns\n\ndef bar_chart(column):\n    survived=df[df[\"Survived\"]==1][column].value_counts()\n    dead=df[df[\"Survived\"]==0][column].value_counts()\n    df1=pd.DataFrame([survived,dead])\n    df1.index=[\"Survived\",\"Dead\"]\n    df1.plot(kind=\"bar\",figsize=(10,5))","5c79c22c":"#here we make a bar chart on sex column\n#for checking how many male & female\nbar_chart(\"Sex\")","aa61abc9":"#here we going to make bar char on Pclass\nbar_chart(\"Pclass\")","64e9ed1f":"#here we going to make bar chart on sibsp\nbar_chart(\"SibSp\")","11aa1557":"bar_chart(\"Parch\")","fc92482c":"bar_chart(\"Embarked\")","c0e4146c":"#visualisation data on boxplot to see the outliers\ndef box_plot(column):\n    df.boxplot(by=\"Survived\",column=[column],grid=True)\n\n","4f50e99c":"box_plot(\"Fare\")","b96502aa":"#checking outliers on Sibsp column\nbox_plot(\"SibSp\")","4a6180c8":"#ploting pair plot\ng=sns.PairGrid(df,hue=\"Survived\")\ng.map_diag(sns.histplot)\ng.map_offdiag(sns.scatterplot)\ng.add_legend","e61c80d8":"#by value_counts we can see total unique values\ndf[\"SibSp\"].value_counts()","32b04dd9":"#here we chacking largest values row on column Sibsp\ndf.nlargest(12,[\"SibSp\"])","fcb41816":"#now we gpoing to remove outliers\ndf=df.drop([159,180,201,324,792,846,863])\ndf.shape\n","618efa20":"#here we going to check outliers on parch\nbox_plot(\"Parch\")","8f365b37":"df[\"Parch\"].value_counts()","59b8417f":"df.nlargest(12,[\"Parch\"])","d98fa109":"df=df.drop([678])\ndf.shape\n","b957f0bf":"#here we going to drow heatmap to check co relation between columns \n\nplt.figure(figsize=(10, 10))\nsns.heatmap(df.corr(), annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\nplt.show()","589e378f":"df[\"Title\"]=df[\"Name\"].str.split(',',expand=True)[1].str.split('.',expand=True)[0]\n","5eca5d7a":"df[\"Title\"].unique()","11516d3a":"df[\"Title\"]=df[\"Title\"].replace([\" Don\",\" Rev\",\" Dr\",\" Major\",\" Lady\",\" Sir\",\" Col\",\" Capt\",\" the Countess\",\" Jonkheer\"],\"Rare\")\ndf[\"Title\"]=df[\"Title\"].replace([\" Mlle\", \" Ms\"],\" Miss\")\ndf[\"Title\"]=df[\"Title\"].replace([\" Mme\",\" Mrs\"],\" Mr\")","32d3f407":"df[\"Title\"].unique()","37803b91":"#droping an relevant columns\n#dividing data X(features) and Y(outcome)\nX=df.drop([\"Fare\",\"Survived\",\"Age\",\"Name\"],axis=True)\ny=df[\"Survived\"]","66ebf601":"print(X.shape)\nprint(y.shape)","2587e737":"X.head()","a4ab7fed":"#Here we encode Embarked in Rank\nX.loc[X['Embarked'] == \"C\", 'Embarked'] = 0\nX.loc[X['Embarked'] == \"Q\", 'Embarked'] = 1\nX.loc[X['Embarked'] == \"S\", 'Embarked'] = 2\n","1d832c45":"mapping={' Mr':0, ' Miss':1, ' Master':2, 'Rare':3}\nX[\"Title\"]=X[\"Title\"].map(mapping)","39cd24b2":"#Here we encode Sex in Rank\nX.loc[X['Sex'] == \"female\", 'Sex'] = 0\nX.loc[X['Sex'] == \"male\", 'Sex'] = 1","dc225400":"X.head()\n","0e8672cd":"X.isnull().sum()","42caf80b":"#here we going to split data in traing set and testing\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=.20,random_state=0)","e2d0b327":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(random_state=40)\nlr.fit(x_train,y_train)\n\nprint(lr.score(x_test,y_test))","99000637":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\ndtc = DecisionTreeClassifier()\n\nparameters = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : range(2, 32, 1),\n    'min_samples_leaf' : range(1, 10, 1),\n    'min_samples_split' : range(2, 10, 1),\n    'splitter' : ['best', 'random']\n}\n\ngrid_search_dt = GridSearchCV(dtc, parameters, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_dt.fit(x_train, y_train)","9f636a07":"# best parameters\n\ngrid_search_dt.best_params_","8aa43a26":"dtc = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4, min_samples_leaf = 6,\n                             min_samples_split = 8, splitter = 'random')\ndtc.fit(x_train, y_train)","29a2f475":"# accuracy score\nprint(dtc.score(x_test,y_test))\n","5ab32f4f":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier()\n\nparameters = {\n    'loss': ['deviance', 'exponential'],\n    'learning_rate': [0.001, 0.1, 1, 10],\n    'n_estimators': [100, 150, 180, 200]\n}\n\ngrid_search_gbc = GridSearchCV(gbc, parameters, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_gbc.fit(x_train, y_train)","3a429e6d":"# best parameters \n\ngrid_search_gbc.best_params_","97449451":"gbc = GradientBoostingClassifier(learning_rate = 0.1, loss = 'exponential', n_estimators = 100)\ngbc.fit(x_train, y_train)","14a4bc0b":"# accuracy score\nprint(gbc.score(x_test,y_test))\n","ac0ca2ae":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(random_state=40,min_impurity_decrease=0.002,min_weight_fraction_leaf=0.001)\n\nrfc.fit(x_train,y_train)\n\n#print(rfc.score(x_test,y_test))","4d420f53":"print(rfc.score(x_test,y_test))","a8e8668e":"from sklearn.svm import SVC\n\nsvc = SVC()\nparameters = {\n    'gamma' : [0.0001, 0.001, 0.01, 0.1],\n    'C' : [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20]\n}\n\ngrid_search = GridSearchCV(svc, parameters)\ngrid_search.fit(x_train, y_train)","8015942c":"# best parameters\n\ngrid_search.best_params_","f8a28464":"svc = SVC(C = 1, gamma = 0.1)\nsvc.fit(x_train, y_train)","384b7cea":"print(svc.score(x_test,y_test))","3db37828":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)","309063f1":"print(knn.score(x_test,y_test))","eb2472ee":"key = ['LogisticRegression','DecisionTreeClassifier','GradientBoostingClassifier','RandomForestClassifier','SVC','KNeighborsClassifier']\nmodel=[lr,dtc,gbc,rfc,svc,knn]","05e9b983":"score=[]\nfor i in model:\n    sco = i.score(x_test,y_test)\n    score.append(sco)\nprint(score)","8f0ba95f":"plt.figure(figsize = (10,5))\nsns.barplot(x = score, y = key, palette='pastel')","9efab7cd":"\ndf2=pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ndf2.head()","a4d38c4a":"df2[\"Title\"]=df2[\"Name\"].str.split(',',expand=True)[1].str.split('.',expand=True)[0]\ndf2[\"Title\"]=df2[\"Title\"].replace([\" Don\",\" Rev\",\" Dr\",\" Major\",\" Lady\",\" Sir\",\" Col\",\" Capt\",\" the Countess\",\" Jonkheer\"],\"Rare\")\ndf2[\"Title\"]=df2[\"Title\"].replace([\" Mlle\", \" Ms\",\" Dona\"],\" Miss\")\ndf2[\"Title\"]=df2[\"Title\"].replace([\" Mme\",\" Mrs\"],\" Mr\")\ndf2[\"Title\"].unique()","d15c3ff1":"mapping={' Mr':0, ' Miss':1, ' Master':2, 'Rare':3}\ndf2[\"Title\"]=df2[\"Title\"].map(mapping)","e771733d":"new_x=df2.drop([\"Cabin\",\"PassengerId\",\"Fare\",\"Age\",\"Name\",\"Ticket\"],axis=True)\nnew_x.head()","385b64ac":"new_x.isnull().sum()","863a01c5":"#Here we encode Embarked in Rank\nnew_x.loc[new_x['Embarked'] == \"C\", 'Embarked'] = 0\nnew_x.loc[new_x['Embarked'] == \"Q\", 'Embarked'] = 1\nnew_x.loc[new_x['Embarked'] == \"S\", 'Embarked'] = 2","6c2838ba":"new_x.loc[new_x['Sex'] == \"female\", 'Sex'] = 0\nnew_x.loc[new_x['Sex'] == \"male\", 'Sex'] = 1","a8185d69":"\nnew_x.head()\n","b77b0746":"#here we used over best train model\nnew_predict=gbc.predict(new_x)\nprint(new_predict)","85f437fd":"vip=np.array(new_predict).tolist()\n","9aa25ddf":"len(vip)","b22f461c":"df2.insert(2,column=\"Survived\",value=vip)\ndf2.head()","848127fd":"df3=df2.drop(['Pclass','Title','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'],axis=1)\ndf3.head()","2d02b036":"df3.to_csv('Titanic_modelP_lr.csv',index=False)\ndf3.head()","5d7ed75b":"**by the above chart on Pclass we can say that 1st class passenger have more chance to survived**","38705bf0":"**Dedacting outliers and removing them**","3def6873":"# Titanic data EDA and Prediction","8bd8d5dc":"**Frome EDA we got**\n* Cabin column have lots of null values so we drop it,\n* Ticket and paddenger Id is not usefull and does not have impact on survivl so drop it.\n* Passenger travelling in higher class have more chance to survived\n* Females survived more then Males.\n* In the 1st class Females were more then Males it is also a resion that females have more chance to survived.\n* Passenger travelling with siblings ,parents have more chance to survived.\n* Passenger traveilling from Cherbourg port survived more than other port passenger.\n","7e0e04b3":"**Traing RandomForestClassifier**","f56daa35":"**Training LogisticRegression**","b549a3a8":"here we can see outliers above the 100 we can considerd them as outlier","e99f5c47":"# Gradient Boosting Classifier","b9bbe2a2":"# macking csv(PassengerId & survived) file to upload","b1ef5427":"**Model building**","3e0abd76":"**Training DecisionTreeClassifier**","2c6fc458":"**Data description**\n\nHere we have 12 columns-\n\n**PassengerId** : ID of Passenger\n\n**Pclass** : Passenger class (1=1st,2=2nd,3=3rd)\n\n**Survived** : Survival (0=No,1=Yes)\n\n**Sex** : sex(male & female)\n\n**Name** : name of passengers\n\n**Age** : age of passengers\n\n**Sibsp** : Number of Siblings\n\n**Parch** : Number of Parents\n\n**Ticket** : passenger ticket number\n\n**Fare** : Passenger fare(British pound)\n\n**Cabin** : cabin\n\n**Embarked** : Port of Embarkation(C=Cherbourg ,Q=Queenstown, S=Southamption)\n\n\n\n","b8a6ed0a":"#  Support Vector Classifier (SVC)","fb7a5da6":"**making title feature using Name**","7d301364":"## finaly we chose over best model **GradientBoostingClassifier** for prediction","c73a8e35":"**In the above chart we can essly analyse that females have more chance to survived.**","06cfddb4":"# Exploratory Data Analysis","7817ea09":"# K Neighbors Classifier (KNN)","f20d1d11":"### Thanks","22325955":"**by above chart we can analyes that there is more chance to survivrd those who have 0 or 1 siblings**","76abf40b":"**now we can replace many titles with a more comman name as Rare**","ba291f80":"**by the above chart we can say that there are more chance to survived for those who bord from Southamption**\n\n**Passenger traveilling from Cherbourg port survived more than other port passenger**","9e0e2d31":"# If you like please Do a up vote","6181b321":"by above chart we consider more then 5 siblings as outlierS","57b7f59d":"# Prediction on Test data\n**clean and feature selection same as training**","44eb80e6":"**Feature Engineering**"}}