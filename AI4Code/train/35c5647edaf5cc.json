{"cell_type":{"5f935d58":"code","414dff3a":"code","9e908e59":"code","52bcc35c":"code","b96ccdba":"code","6e5d716c":"code","4c0b6fc1":"code","a69627be":"code","7fb6c70e":"code","f79aa5e6":"code","9ca40803":"code","0fa03180":"code","5563086e":"code","fdf04a4f":"code","ab604cfd":"code","52a42e17":"code","cca2fac2":"code","4c1cd2aa":"code","ff212c39":"code","bb2cb831":"code","81a03f96":"code","0dfd9c79":"code","16ec2829":"code","5c454307":"code","0579f887":"code","dcd4a25f":"code","2ba0c567":"code","ac6372c1":"code","40fc16e0":"code","5339e916":"code","df25a059":"code","125d9972":"code","1339e331":"code","5a2e7b8f":"code","ebc44793":"code","3c2be0a7":"code","41e9e8cd":"code","430b81bd":"code","b0cd26df":"code","b55cf4d5":"code","ed7edce7":"code","fd4d14f2":"code","f2b96b4d":"code","d0322d86":"code","856df504":"code","9a228cce":"code","5178e2b1":"code","72b7af44":"code","55efbbd6":"code","9bc6e280":"code","8a527344":"markdown","694761a6":"markdown","3a1f60bd":"markdown","84374514":"markdown","e39edc8c":"markdown","022e09b8":"markdown","a1b0b09c":"markdown","1f7fd28b":"markdown","0759e7d8":"markdown","82efa3a0":"markdown","7edea077":"markdown"},"source":{"5f935d58":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler","414dff3a":"df=pd.read_csv('titanic.csv',usecols=['Cabin','Survived'])\ndf.head()","9e908e59":"### Replacing\ndf['Cabin'].fillna('Missing',inplace=True)\ndf.head()","52bcc35c":"print(df['Cabin'].unique().tolist())","b96ccdba":"df['Cabin']=df['Cabin'].astype(str).str[0]\ndf.head()","6e5d716c":"df.Cabin.unique()","4c0b6fc1":"prob_df=df.groupby(['Cabin'])['Survived'].mean()","a69627be":"prob_df=pd.DataFrame(prob_df)\nprob_df","7fb6c70e":"prob_df['Died']=1-prob_df['Survived']","f79aa5e6":"prob_df.head()","9ca40803":"prob_df['Probability_ratio']=prob_df['Survived']\/prob_df['Died']\nprob_df.head()","0fa03180":"probability_encoded=prob_df['Probability_ratio'].to_dict()","5563086e":"df['Cabin_encoded']=df['Cabin'].map(probability_encoded)\ndf.head()","fdf04a4f":"df.head(20)","ab604cfd":"import pandas as pd\ndf=pd.read_csv('titanic.csv', usecols=['Pclass','Age','Fare','Survived'])\ndf.head()\n","52a42e17":"df['Age'].fillna(df['Age'].median(), inplace=True)","cca2fac2":"df.isnull().sum()","4c1cd2aa":"\nfrom sklearn.preprocessing import StandardScaler","ff212c39":"#!pip install scikit-learn==0.21.0","bb2cb831":"scaler = StandardScaler()\n\n#scaler=StandardScaler()\n### fit vs fit_transform\ndf_scaled=scaler.fit_transform(df)","81a03f96":"import matplotlib.pyplot as plt\n%matplotlib inline","0dfd9c79":"df_scaled","16ec2829":"plt.hist(df_scaled[0,:], bins=20);","5c454307":"plt.hist(df_scaled[:,2],bins=20);","0579f887":"plt.hist(df_scaled[:,3],bins=20);","dcd4a25f":"plt.hist(df['Fare'],bins=20);","2ba0c567":"from sklearn.preprocessing import MinMaxScaler\nmin_max = MinMaxScaler()\ndf_minmax = pd.DataFrame(min_max.fit_transform(df),columns = df.columns)\ndf_minmax.head()","ac6372c1":"from sklearn.preprocessing import MinMaxScaler\nmin_max=MinMaxScaler()\ndf_minmax=pd.DataFrame(min_max.fit_transform(df),columns=df.columns)\ndf_minmax.head()","40fc16e0":"plt.hist(df_minmax['Pclass'], bins=20)\n;\n#plt.hist(df_minmax['Pclass'],bins=20)","5339e916":"plt.hist(df_minmax['Age'],bins=20);","df25a059":"plt.hist(df_minmax['Fare'],bins=20);","125d9972":"from sklearn.preprocessing import RobustScaler\nscaler=RobustScaler()\ndf_robust_scaler=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)\ndf_robust_scaler.head()","1339e331":"plt.hist(df_robust_scaler['Age'],bins=20)","5a2e7b8f":"plt.hist(df_robust_scaler['Fare'],bins=20)","ebc44793":"df=pd.read_csv('titanic.csv',usecols=['Age','Fare','Survived'])\ndf.head()","3c2be0a7":"### fillnan\ndf['Age']=df['Age'].fillna(df['Age'].median())","41e9e8cd":"df.isnull().sum()","430b81bd":"import scipy.stats as stat\nimport pylab ","b0cd26df":"#### If you want to check whether feature is guassian or normal distributed\n#### Q-Q plot\ndef plot_data(df,feature):\n    plt.figure(figsize=(10,6))\n    plt.subplot(1,2,1)\n    df[feature].hist()\n    plt.subplot(1,2,2)\n    stat.probplot(df[feature],dist='norm',plot=pylab)\n    plt.show()\n    ","b55cf4d5":"plot_data(df,'Age')","ed7edce7":"import numpy as np\ndf['Age_log']=np.log(df['Age'])\nplot_data(df,'Age_log')","fd4d14f2":"df['Age_reciprocal']=1\/df.Age\nplot_data(df,'Age_reciprocal')","f2b96b4d":"##### Square Root Transformation\ndf['Age_sqaure']=df.Age**(1\/2)\nplot_data(df,'Age_sqaure')","d0322d86":"#### Exponential Transdormation\ndf['Age_exponential']=df.Age**(1\/1.2)\nplot_data(df,'Age_exponential')","856df504":"df['Age_Boxcox'],parameters=stat.boxcox(df['Age'])","9a228cce":"print(parameters)","5178e2b1":"plot_data(df,'Age_Boxcox')","72b7af44":"plot_data(df,'Fare')","55efbbd6":"#### Fare\ndf['Fare_log']=np.log1p(df['Fare'])\nplot_data(df,'Fare_log')","9bc6e280":"df['Fare_Boxcox'],parameters=stat.boxcox(df['Fare']+1)\nplot_data(df,'Fare_Boxcox')","8a527344":"#### Types Of Transformation\n1. Normalization And Standardization\n2. Scaling to Minimum And Maximum values\n3. Scaling To Median And Quantiles\n4. Guassian Transformation\n   Logarithmic Transformation\n   Reciprocal Trnasformation\n   Square Root Transformation\n   Exponential Trnasformation\n   Box Cox Transformation","694761a6":"##### Robust Scaler\nIt is used to scale the feature to median and quantiles\nScaling using median and quantiles consists of substracting the median to all the observations, and then dividing by the interquantile difference. The interquantile difference is the difference between the 75th and 25th quantile:\n\nIQR = 75th quantile - 25th quantile\n\nX_scaled = (X - X.median) \/ IQR","3a1f60bd":"#### Logarithmic Transformation","84374514":"#### BoxCOx Transformation\nThe Box-Cox transformation is defined as: \n\nT(Y)=(Y exp(\u03bb)\u22121)\/\u03bb\n\nwhere Y is the response variable and \u03bb is the transformation parameter. \u03bb varies from -5 to 5. In the transformation, all values of \u03bb  are considered and the optimal value for a given variable is selected.","e39edc8c":"#### Reciprocal Trnasformation","022e09b8":"##### Transformation of Features\n\nWhy Transformation of Features Are Required?\n\n1. Linear Regression---Gradient Descent ----Global Minima\n2. Algorithms like KNN,K Means,Hierarichal Clustering--- Eucledian Distance\n\nEvery Point has some vectors and Directiom\n\nDeep Learning Techniques(Standardization, Scaling)\n1.ANN--->GLobal Minima, Gradient\n2.CNN\n3.RNN\n\n0-255 pixels","a1b0b09c":"0,1,2,3,4,5,6,7,8,9,10\n\n9-90 percentile---90% of all values in this group is less than 9\n1-10 precentile---10% of all values in this group is less than 1\n4-40%","1f7fd28b":"#### Guassian Transformation\n\nSome machine learning algorithms like linear and logistic assume that the features are normally distributed\n-Accuracy\n-Performance\n- logarithmic transformation\n- reciprocal transformation\n- square root transformation\n- exponential transformation (more general, you can use any exponent)\n- boxcox transformation\n","0759e7d8":"#### Probability Ratio Encoding\n1. Probability of Survived based on Cabin--- Categorical Feature\n2. Probability of Not Survived---1-pr(Survived)\n3. pr(Survived)\/pr(Not Survived)\n4. Dictonary to map cabin with probability\n5. replace with the categorical feature","82efa3a0":"##### Min Max Scaling  (### CNN)---Deep Learning Techniques\nMin Max Scaling scales the values between 0 to 1.\nX_scaled = (X - X.min \/ (X.max - X.min)","7edea077":"##### Standardization\nWe try to bring all the variables or features to a similar scale. standarisation means centering the variable at zero.\nz=(x-x_mean)\/std"}}