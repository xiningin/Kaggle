{"cell_type":{"5b7f4809":"code","8e2110bd":"code","68535dae":"code","7000e1fe":"code","cda5b84f":"code","bba6b49d":"code","42098a07":"code","a3032251":"code","6fa56c37":"code","4f8937e8":"code","24f2b8c9":"code","ae63c483":"code","5138aa3b":"code","8893fe3a":"code","9462690b":"code","9b4f6026":"code","70147f09":"code","0035d0d4":"code","0419db42":"code","bdca1c4e":"code","b9b12959":"code","112a1792":"code","6f09f28f":"code","649a133f":"code","2279a5dc":"code","dae314ce":"code","5c1aacdc":"code","8537a8c7":"code","b4d28ddd":"code","66498c0b":"code","19825c8a":"code","9ebd7916":"code","c4c771ab":"code","c5cc363f":"code","a2eb759e":"markdown","5198f10f":"markdown","ca148027":"markdown","cd9d3bf3":"markdown","86a1e298":"markdown","bf049833":"markdown","3c379060":"markdown","0dbb3180":"markdown","7dd259a6":"markdown","3a2279eb":"markdown","8cc2bb36":"markdown","57013c2c":"markdown","9c8aec23":"markdown","bbcd88ec":"markdown"},"source":{"5b7f4809":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#import visulization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e2110bd":"train_path =\"..\/input\/30-days-of-ml\/train.csv\"\ntest_path= \"..\/input\/30-days-of-ml\/test.csv\"\nsample_submission_path= \"..\/input\/30-days-of-ml\/sample_submission.csv\"","68535dae":"train = pd.read_csv(train_path,index_col=0)\ntest = pd.read_csv(test_path,index_col=0)\nsample_submission = pd.read_csv(sample_submission_path)","7000e1fe":" #print shape of all three dataset avaiable to us\n print(train.shape)\n print(test.shape)\n print(sample_submission.shape)","cda5b84f":" #read first 5 rows of train dataset\n train.head(5)","bba6b49d":" #read first 5 rows of test dataset\n test.head(5)","42098a07":" #read first 5 rows of sample submission dataset\n sample_submission.head(5)","a3032251":"#checking null values of train and test data\ntrain.isnull().sum().sum(),test.isnull().sum().sum()","6fa56c37":"#checking duplicated value\ntrain.duplicated().sum(),test.duplicated().sum()","4f8937e8":"#Getting more info about data\ntrain.info()","24f2b8c9":"#Getting more info about data\ntest.info()","ae63c483":"#let's get statistical quick look to data\ntrain.describe()","5138aa3b":"#statistical quick look for TARGET variable\ntrain['target'].describe()","8893fe3a":"#get unique value of each column\ntrain.nunique()","9462690b":"# Get list of categorical variables\ns = (train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","9b4f6026":"#get list of numrical variables\ns = (train.dtypes == 'float64')\nnum_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(num_cols)","70147f09":"fig,axes = plt.subplots(1,1,figsize=(16,14))\nsns.heatmap(train.corr(),annot=True)\nplt.show()","0035d0d4":"#scatter plot between Target and cont12\nplt.scatter(train['cont12'], train['target'], alpha=0.5)\nplt.title('Scatter plot of Target with cont12')\nplt.xlabel('cont12')\nplt.ylabel('Target')\nplt.show()","0419db42":"#scatter plot between Target and cont13\nplt.scatter(train['cont13'], train['target'], alpha=0.5)\nplt.title('Scatter plot of Target with cont13')\nplt.xlabel('cont13')\nplt.ylabel('Target')\nplt.show()","bdca1c4e":"#sns.pairplot(train,hue='target')\n ","b9b12959":"train.columns","112a1792":"#Select target variable\ndependent_variable = train['target']\n","6f09f28f":"#Select features on which target value depend\nindependent_variables= train.drop('target',axis=1)","649a133f":"#Print head of independent variables\nindependent_variables.head()","2279a5dc":"# assign y for dependent and X for independent variable for our ease\ny = dependent_variable\nX = independent_variables.copy()\n\n#assign X_test for test for ease\nX_test =test.copy()","dae314ce":"#Get all Categorical column of Train data\ncategorical_col = [col for col in independent_variables.columns if 'cat'in col]\ncategorical_col","5c1aacdc":"# converting Categorical variable into numric by using Ordinal Encoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\nencoder_ordnl = OrdinalEncoder()\n\nX[categorical_col] = encoder_ordnl.fit_transform(independent_variables[categorical_col])\nX_test[categorical_col] = encoder_ordnl.transform(test[categorical_col])","8537a8c7":"#print head of  ordinal-encoded features of X\nX.head(2)","b4d28ddd":"#print head of  ordinal-encoded features of X_test\nX_test.head(2)","66498c0b":"#split the data in X_train, X_test, y_train, y_test\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,random_state=0)","19825c8a":"#it will take more time to run so i print result in comment.\n\n'''random_forest = RandomForestRegressor(random_state=1)\nrandom_forest.fit(X_train,y_train)\npredict_y_rf = random_forest.predict(X_valid)\nprint(mean_squared_error(predict_y_rf,y_valid,squared=False))'''\n\n#result 0.7375392165180452 ","9ebd7916":"#it takes very less time in  comparison to Random forest model and Error also reduced to 0.7287. \nfrom xgboost import XGBRegressor\n\nxgb_model =XGBRegressor(random_state=1)\nxgb_model.fit(X_train,y_train)\npredict_y_xgb = xgb_model.predict(X_valid)\nprint(mean_squared_error(predict_y_xgb,y_valid,squared=False))\n\n#result 0.7268784689736293  without tuning","c4c771ab":"# Use the model to generate predictions\npredictions = xgb_model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","c5cc363f":"pd.DataFrame(predictions).shape","a2eb759e":"### It takes very less time in  comparison to \"Random forest model\" and Error also reduced to 0.7268 from O.7375.","5198f10f":"## Checking RandomForest Accuracy","ca148027":"<b> Target have strong correlation with CONT12 (positive) and strong negative corr with CONT13<\/b>","cd9d3bf3":"## Checking XGBoost Accuracy","86a1e298":"# SO we can't use Any Regession model, data is much overlapping","bf049833":"# Train Model","3c379060":"### SUBMISSION OUTPUT","0dbb3180":"# Note: we can improve accuracy of our model with TUNING. we will do it later. it's basic!!","7dd259a6":"#scatter plot between Target and cont12<b> So we have to work on Categorical and Numrical Variable<\/b>","3a2279eb":"# Preprocessing for Model","8cc2bb36":">Luckily we have not any null and duplicated values in both datasets","57013c2c":"# For creating model we have to work more with Training Dataset.\nLet explore it more and trying to understand the data","9c8aec23":"# **Explore the Data**","bbcd88ec":"### it will take more time to run so i print result in comment."}}