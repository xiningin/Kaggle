{"cell_type":{"0787011c":"code","60e19c17":"code","73009778":"code","04d0e8f1":"code","2fa1e0a9":"code","8cfd6473":"code","24b313e6":"code","cd00c119":"code","1709812b":"code","7e7cd924":"code","569fd611":"code","a550a222":"code","d1b1779c":"code","357276bc":"code","9ed59038":"code","0f06ece6":"code","0a727ae5":"code","1bea06ca":"code","90f78183":"code","083150eb":"code","d3e85ae0":"code","94bc20da":"code","d531efd7":"code","049c1df1":"code","fbd0ae0c":"code","119bbcf3":"code","ac4d7199":"code","2dd5970c":"code","b355390d":"markdown","0ebaf317":"markdown","f935dbab":"markdown","73cd087f":"markdown","6a652dec":"markdown","91d5093f":"markdown","cb835145":"markdown","db199393":"markdown","08cf1f41":"markdown","ffb4215d":"markdown","39b3551e":"markdown","1950a7b9":"markdown","3c0b1b22":"markdown"},"source":{"0787011c":"%matplotlib inline","60e19c17":"from typing import List\nimport logging\nfrom typing import Optional\nfrom functools import partial\nfrom typing import Tuple\nfrom typing import Union\n\n\nimport torch.nn as nn\nimport numpy as np\nimport os\nimport pandas as pd\nimport torch\nfrom torch.optim import Adam\nfrom torchvision.models.resnet import BasicBlock\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom torchvision.models.resnet import ResNet\nfrom sklearn.metrics import roc_auc_score\nfrom torch import Tensor\nfrom torchvision import transforms\nfrom torch.autograd import Variable","73009778":"DATA_FOLDER = '..\/input'\nLABELS = f'{DATA_FOLDER}\/train_labels.csv'\nTRAIN_IMAGES_FOLDER = f'{DATA_FOLDER}\/train'\nUSE_GPU = torch.cuda.is_available()","04d0e8f1":"logging.basicConfig(level='INFO')\nlogger = logging.getLogger()","2fa1e0a9":"def read_labels(path_to_file: str) -> pd.DataFrame:\n    labels = pd.read_csv(path_to_file)\n    return labels\n\n\ndef format_labels_for_dataset(labels: pd.DataFrame) -> np.array:\n    return labels['label'].values.reshape(-1, 1)\n\n\ndef format_path_to_images_for_dataset(labels: pd.DataFrame, path: str) -> List:\n    return [os.path.join(path, f'{f}.tif') for f in labels['id'].values]\n\n\ndef train_valid_split(df: pd.DataFrame) -> Tuple:\n    limit_df = 50000\n    df = df.sample(n = df.shape[0])\n    df = df.iloc[:limit_df]\n    split = 40000\n    train = df.iloc[:split]\n    valid = df.iloc[:split]\n    return train, valid","8cfd6473":"class MainDataset(Dataset):\n    def __init__(self,\n                 x_dataset: Dataset,\n                 y_dataset: Dataset,\n                 x_tfms: Optional = None):\n        self.x_dataset = x_dataset\n        self.y_dataset = y_dataset\n        self.x_tfms = x_tfms\n\n    def __len__(self) -> int:\n        return self.x_dataset.__len__()\n\n    def __getitem__(self, index: int) -> Tuple:\n        x = self.x_dataset[index]\n        y = self.y_dataset[index]\n        if self.x_tfms is not None:\n            x = self.x_tfms(x)\n        return x, y\n    \nclass ImageDataset(Dataset):\n    def __init__(self, paths_to_imgs: List):\n        self.paths_to_imgs = paths_to_imgs\n\n    def __len__(self) -> int:\n        return len(self.paths_to_imgs)\n\n    def __getitem__(self, index: int) -> Image.Image:\n        img = Image.open(self.paths_to_imgs[index])\n        return img\n\n\nclass LabelDataset(Dataset):\n    def __init__(self, labels: List):\n        self.labels = labels\n\n    def __len__(self) -> int:\n        return len(self.labels)\n\n    def __getitem__(self, index: int) -> int:\n        return self.labels[index]","24b313e6":"labels = read_labels(LABELS)\ntrain, valid = train_valid_split(labels)\n\ntrain_labels = format_labels_for_dataset(train)\nvalid_labels = format_labels_for_dataset(valid)\n\ntrain_images = format_path_to_images_for_dataset(train, TRAIN_IMAGES_FOLDER)\nvalid_images = format_path_to_images_for_dataset(valid, TRAIN_IMAGES_FOLDER)\n\ntrain_images_dataset = ImageDataset(train_images)\nvalid_images_dataset = ImageDataset(valid_images)\ntrain_labels_dataset = LabelDataset(train_labels)\nvalid_labels_dataset = LabelDataset(valid_labels)","cd00c119":"x_tfms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])","1709812b":"train_dataset = MainDataset(train_images_dataset, train_labels_dataset, x_tfms)\nvalid_dataset = MainDataset(valid_images_dataset, valid_labels_dataset, x_tfms)","7e7cd924":"shuffle = True\nbatch_size = 512\nnum_workers = 0\ntrain_dataloader = DataLoader(train_dataset, \n                              batch_size=batch_size, \n                              shuffle=shuffle, \n                              num_workers=num_workers)\nvalid_dataloader = DataLoader(valid_dataset, \n                              batch_size=batch_size, \n                              shuffle=False, \n                              num_workers=num_workers)","569fd611":"# we will create custom resnet with 9 layers so it can process 96x96 images\ndef to_gpu(tensor):\n    return tensor.cuda() if USE_GPU else tensor\n\n\ndef create_resnet9_model(output_dim: int = 1) -> nn.Module:\n    model = ResNet(BasicBlock, [1, 1, 1, 1])\n    in_features = model.fc.in_features\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    model.fc = nn.Linear(in_features, output_dim)\n    model = to_gpu(model)\n    return model","a550a222":"resnet9 = create_resnet9_model(output_dim=1)\nresnet9","d1b1779c":"lr = 1e-3\noptimizer = Adam(resnet9.parameters(), lr=lr)","357276bc":"loss = nn.BCEWithLogitsLoss()","9ed59038":"def train_one_epoch(model,\n                    train_dataloader,\n                    valid_dataloader,\n                    loss,\n                    optimizer,\n                    loss_writer_train,\n                    loss_writer_valid,\n                    do_step_trigger,\n                    valid_loss_trigger,\n                    train_loss_trigger,\n                    ):\n    model.train()\n    y_true_train, y_hat_train = [], []\n    for iteration, (x, y) in enumerate(train_dataloader):\n        x = Variable(T(x), requires_grad=True)\n        y = Variable(T(y), requires_grad=True)\n        output = model(x)\n        y_true_train.append(to_numpy(y))\n        y_hat_train.append(to_numpy(output))\n        loss_values = loss(output, y)\n        loss_values.backward()\n        if do_step_trigger(iteration):\n            optimizer.step()\n            optimizer.zero_grad()\n        if train_loss_trigger(iteration):\n            auc_writer(y_true_train, y_hat_train, iteration)\n            y_true_train, y_hat_train = [], []\n        if valid_loss_trigger(iteration):\n            y_true, y_hat = predict(model, valid_dataloader)\n            auc_writer(y_true, y_hat, iteration)\n    return model","0f06ece6":"def predict(model, dataloader):\n    model.eval()\n    y_true, y_hat = [], []\n    with torch.no_grad():\n        for x, y in dataloader:\n            x = Variable(T(x))\n            y = Variable(T(y))\n            output = model(x)\n            y_true.append(to_numpy(y))\n            y_hat.append(to_numpy(output))\n    return y_true, y_hat","0a727ae5":"def iteration_trigger(iteration, every_x_iterations):\n    if every_x_iterations == 1:\n        return True\n    elif iteration > 0 and iteration % every_x_iterations == 0:\n        return True\n    else:\n        return False\n\n\ndef init_triggers(step=1, valid=10, train=10):\n    do_step_trigger = partial(iteration_trigger, every_x_iterations=step)\n    valid_loss_trigger = partial(iteration_trigger, every_x_iterations=valid)\n    train_loss_trigger = partial(iteration_trigger, every_x_iterations=train)\n    return do_step_trigger, valid_loss_trigger, train_loss_trigger","1bea06ca":"def auc_writer(y_true, y_hat, iteration):\n    try:\n        auc = roc_auc_score(np.vstack(y_true), np.vstack(y_hat))\n    except:\n        auc = -1\n    logger.info(f'iteration: {iteration}, auc: {auc}')","90f78183":"def T(tensor):\n    if not torch.is_tensor(tensor):\n        tensor = torch.FloatTensor(tensor)\n    else:\n        tensor = tensor.type(torch.FloatTensor)\n    if USE_GPU:\n        tensor = to_gpu(tensor)\n    return tensor\n\n\ndef to_numpy(tensor: Union[Tensor, Image.Image, np.array]) -> np.ndarray:\n    if type(tensor) == np.array or type(tensor) == np.ndarray:\n        return np.array(tensor)\n    elif type(tensor) == Image.Image:\n        return np.array(tensor)\n    elif type(tensor) == Tensor:\n        return tensor.cpu().detach().numpy()\n    else:\n        raise ValueError(msg)","083150eb":"loss_writer_train = auc_writer\nloss_writer_valid = auc_writer\n\n# backpropagate - every iter\n# calculate AUC on valid - every 20 iters \n# AUC on train - every 10 iters\ndo_step_trigger, valid_loss_trigger, train_loss_trigger = init_triggers(1, 20, 10)","d3e85ae0":"resnet9 = train_one_epoch(\n    resnet9,\n    train_dataloader,\n    valid_dataloader,\n    loss,\n    optimizer,\n    loss_writer_train,\n    loss_writer_valid,\n    do_step_trigger,\n    valid_loss_trigger,\n    train_loss_trigger,\n)","94bc20da":"y_true, y_hat = predict(resnet9, valid_dataloader)","d531efd7":"predictions = pd.DataFrame(\n    list(\n        zip(\n            valid_labels.reshape(-1), \n            np.vstack(y_hat).reshape(-1),\n            valid_images\n        )\n    ), \n     columns=['true', 'pred', 'files'])\npredictions.head(3)","049c1df1":"max_charts = 60\ndef implot(files, w=2, h=2, cols=12):\n    rows = len(files) \/ cols + 1\n    images = [Image.open(f) for f in files]\n    plt.figure(figsize = (cols * w, rows * h))\n    plt.tight_layout()\n    for chart, img in enumerate(images, 1):\n        ax = plt.subplot(rows, cols, chart)\n        ax.imshow(np.array(img))\n        ax.axis('off')","fbd0ae0c":"files = predictions[predictions['true']==1].sort_values('pred')['files'].values[:max_charts]\nimplot(files)","119bbcf3":"files = predictions[predictions['true']==0].sort_values('pred', ascending=False)['files'].values[:max_charts]\nimplot(files)","ac4d7199":"files = predictions[predictions['true']==1].sort_values('pred', ascending=False)['files'].values[:max_charts]\nimplot(files)","2dd5970c":"files = predictions[predictions['true']==0].sort_values('pred', ascending=True)['files'].values[:max_charts]\nimplot(files)","b355390d":"#### FALSE POSITIVE","0ebaf317":"### STEP 5 - OPTIMIZER","f935dbab":"#### FALSE NEGATIVE","73cd087f":"### STEP 6 - LOSS","6a652dec":"### STEP 3 - DATALOADER","91d5093f":"###  STEP 2 - TRANSFORMERS","cb835145":"### STEP 9 - ERRORS ANALYSIS","db199393":"### STEP 1 - DATASETS","08cf1f41":"### STEP 7 - TRAINER \/ PREDICTOR \/ TRIGGERS","ffb4215d":"#### TRUE POSITIVE","39b3551e":"### STEP 4 - MODEL","1950a7b9":"#### TRUE NEGATIVE","3c0b1b22":"### STEP 8 - PREDICTIONS EXTRACTION"}}