{"cell_type":{"d0e582cd":"code","1ee09f98":"code","92b3ca78":"code","0824a4dc":"code","60d00c43":"code","4fe10f95":"code","dee39f24":"code","808c0a64":"code","526f4853":"code","dcc6f18b":"code","ac9ef19b":"code","d5337701":"code","e101e484":"code","6d969a2b":"code","7398229c":"code","1a3ee06d":"code","5ba88122":"code","1c6bf802":"code","c08fc65c":"code","84181c27":"code","786087c5":"code","57c0c0e2":"code","7de59bcb":"code","aa90951b":"code","ca6fbf4f":"code","bfbf25c3":"code","ce02fc4e":"code","638d446f":"code","ece683b9":"code","4e913d68":"markdown","df311f8c":"markdown","830b5200":"markdown","7c362047":"markdown","31a9bef9":"markdown","c3f02b44":"markdown","ff93844d":"markdown","382ab015":"markdown","ce802c53":"markdown"},"source":{"d0e582cd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1ee09f98":"df_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")","92b3ca78":"#Columns\/Rows\" count\ncols, rows = df_train.shape\nprint(\"Number of columns: \", cols)\nprint(\"Number of rows: \", rows)","0824a4dc":"df_train.head()","60d00c43":"df_train.describe().T","4fe10f95":"#Check for null values\ndf_train.isnull().sum().sum()","dee39f24":"df_test.describe().T","808c0a64":"# Check for null values at test\ndf_test.isnull().sum().sum()","526f4853":"#Unique values\nprint(\"Number of unique values:\\n\", df_train.nunique())","dcc6f18b":"#Loss distribution\nsns.distplot(df_train['loss'])","ac9ef19b":"#Countplot of loss\nplt.figure(figsize = (10, 8))\nsns.countplot(data = df_train, x = 'loss',palette = 'icefire')","d5337701":"#Correlation matrix\nplt.figure(figsize = (12, 12))\ncorr = df_train.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, cmap='twilight_r', robust=True, center=0,square=True, linewidths=.6)\nplt.title(\"Correlation\")\nplt.show()","e101e484":"correlations = df_train.corr()['loss'].sort_values()\nprint(\"Lowest correlation features:\\n\")\nprint(correlations.head(15), \"\\n\")\nprint(\"Highest correlation features:\\n\")\nprint(correlations.tail(15))","6d969a2b":"# Plot feature correlations\nplt.figure(figsize = (24, 8))\ncorr[\"loss\"][:-1].plot(kind=\"bar\",grid=True)\nplt.title(\"Features Correlation\")","7398229c":"#Drop ID columns\ndf_train.drop(columns = 'id', inplace = True)\ndf_test.drop(columns = 'id', inplace = True)","1a3ee06d":"#Each feature distribution\ndf = pd.concat([df_train.drop([\"loss\"], axis=1)])\ndf = df_train.columns[0:100]\nplt.subplots(figsize=(20,160))\nlength = len(df)\nfor i, j in zip(df, range(length)):\n    fig = plt.subplot((length\/2), 3, j+1)\n    plt.subplots_adjust(wspace=.25, hspace=.6)\n    plt.yticks([])\n    sns.histplot(x=df_train[i], alpha=0.5,edgecolor=\"black\",color='#3e3b92')\n    sns.histplot(x=df_test[i], alpha=0.5,edgecolor=\"black\",color='#00ee6e')\n    fig.legend(labels=('Train','Test'))","5ba88122":"# Separate target from features\nx = df_train.drop('loss', axis = 1)\ny = df_train.loss","1c6bf802":"#split the validation sets\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\n# Checking split \nprint('X_train:', x_train.shape)\nprint('y_train:', y_train.shape)\nprint('X_val:', x_val.shape)\nprint('y_val:', y_val.shape)","c08fc65c":"# Scale the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_val = scaler.transform(x_val)","84181c27":"from catboost import CatBoostRegressor\ncat_model = CatBoostRegressor(random_state=42,iterations = 5000,learning_rate=0.005, early_stopping_rounds=50)\ncat_model.fit(x_train, y_train, verbose = 0)","786087c5":"# Metric evaluation\nfrom sklearn.metrics import  mean_squared_error\npred_cat = cat_model.predict(x_val)\nprint(\"RMSE: \", np.sqrt(mean_squared_error(y_val, pred_cat)))","57c0c0e2":"#Train the whole Dataset\ncat_model.fit(x, y, verbose = 0)","7de59bcb":"#Catboost prediction\ny_pred1 = cat_model.predict(df_test)","aa90951b":"# Feature impact on model\nimport shap\nimpact = shap.Explainer(cat_model)\nshap_values = impact(x)\nshap.plots.beeswarm(shap_values, max_display = 20)","ca6fbf4f":"from lightgbm import LGBMRegressor\nLGBModel = LGBMRegressor(random_state=42,n_estimators= 500,learning_rate=0.005, objective='regression', max_depth=5, n_jobs = -1)\nLGBModel.fit(x, y, verbose = 0)\npred_lgbm = LGBModel.predict(df_test)\nprint(\"RMSE\", np.sqrt(mean_squared_error(y, LGBModel.predict(x))))","bfbf25c3":"from xgboost import XGBRegressor\nXGBModel = XGBRegressor(random_state=42,n_estimators= 500,learning_rate=0.05,\n                      max_depth=8,booster='gbtree',verbosity=0)\nXGBModel.fit(x,y)\npred_xgb = XGBModel.predict(df_test)\nprint(\"RMSE\", np.sqrt(mean_squared_error(y, XGBModel.predict(x))))","ce02fc4e":"final_predictions = (0.25 * y_pred1) + (0.25 * pred_lgbm) + (0.5 * pred_xgb)","638d446f":"# Organize submission file\nsub['loss'] = final_predictions\nsub","ece683b9":"sub.to_csv(\"submission.csv\", index = False)","4e913d68":"## **LightGBM**","df311f8c":"## **Load and visualize dataset**","830b5200":"## **Exploratory Data Analysis**","7c362047":"## **Data split**","31a9bef9":"## **CatBoost**","c3f02b44":"## **XGBoost**","ff93844d":"# Model Training","382ab015":"# Ensembling\nWe are going to take the output of the 3 models and calculate a weighted average of them. Which will improve our results","ce802c53":"# Data preparation\/EDA"}}