{"cell_type":{"a89df4fd":"code","41461fbe":"code","d34b4ea7":"code","c507f701":"code","9b0725ef":"code","da8e2a87":"code","ad90dbec":"code","af5de197":"code","00c58fad":"code","21d823bc":"code","1f8bf770":"code","693b79ec":"code","ee12e837":"code","63272ce2":"code","9ae6ea10":"code","7c1d911f":"code","cbc5f7d6":"code","8b385f41":"code","00c87d87":"code","bb885b76":"code","e9631bfb":"code","e72a5f96":"code","a647d688":"code","9ea5c99f":"code","24604128":"code","6df7f862":"code","5eaebeb4":"code","caa47fbb":"markdown","9ea03ce6":"markdown","02214f0e":"markdown","40c83966":"markdown","95133737":"markdown","9d1e0a2d":"markdown","633332b8":"markdown","ce6eedeb":"markdown","081c1ae2":"markdown"},"source":{"a89df4fd":"#update gast to correct version\n#!pip install gast==0.2.2","41461fbe":"import math as m\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Lambda\nimport tensorflow.keras as keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import regularizers\n\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]\n\nimport matplotlib\nfrom matplotlib import font_manager\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom matplotlib import rc\n\nfrom matplotlib import animation as ani\nfrom IPython.display import Image\n\nplt.rcParams[\"patch.force_edgecolor\"] = True\n#rc('text', usetex=True)\nfrom IPython.display import display # Allows the use of display() for DataFrames\nimport seaborn as sns\nsns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\nsns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nred = sns.xkcd_rgb[\"light red\"]\ngreen = sns.xkcd_rgb[\"medium green\"]\nblue = sns.xkcd_rgb[\"denim blue\"]\n\n# pandas formatting\npd.set_option(\"display.max_colwidth\", 100)\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.options.display.float_format = '{:,.5f}'.format\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'","d34b4ea7":"def preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m\/%d\/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()\/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))\/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))\/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four\/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","c507f701":"def create_features(df, deploy=False):\n    def new_X(x_coordinate, play_direction):\n        if play_direction == 'left':\n            return 120.0 - x_coordinate\n        else:\n            return x_coordinate\n\n    def new_line(rush_team, field_position, yardline):\n        if rush_team == field_position:\n            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n            return 10.0 + yardline\n        else:\n            # half the field plus the yards between midfield and the line of scrimmage\n            return 60.0 + (50 - yardline)\n\n    def new_orientation(angle, play_direction):\n        if play_direction == 'left':\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return new_angle\n        else:\n            return angle\n\n    def euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n\n        return np.sqrt(x_diff + y_diff)\n\n    def back_direction(orientation):\n        if orientation > 180.0:\n            return 1\n        else:\n            return 0\n\n    def update_yardline(df):\n        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n        return new_yardline\n\n    def update_orientation(df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n        return df\n\n    def back_features(df):\n        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n\n        return carriers\n\n    def features_relative_to_back(df, carriers):\n        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n                                   'min_dist','max_dist','mean_dist','std_dist']\n\n        return player_distance\n\n    def defense_features(df):\n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n\n        return defense\n\n    def static_features(df):\n        static_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n        static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n\n        return static_features\n    \n    def split_personnel(s):\n        splits = s.split(',')\n        for i in range(len(splits)):\n            splits[i] = splits[i].strip()\n\n        return splits\n\n    def defense_formation(l):\n        dl = 0\n        lb = 0\n        db = 0\n        other = 0\n\n        for position in l:\n            sub_string = position.split(' ')\n            if sub_string[1] == 'DL':\n                dl += int(sub_string[0])\n            elif sub_string[1] in ['LB','OL']:\n                lb += int(sub_string[0])\n            else:\n                db += int(sub_string[0])\n\n        counts = (dl,lb,db,other)\n\n        return counts\n\n    def offense_formation(l):\n        qb = 0\n        rb = 0\n        wr = 0\n        te = 0\n        ol = 0\n\n        sub_total = 0\n        qb_listed = False\n        for position in l:\n            sub_string = position.split(' ')\n            pos = sub_string[1]\n            cnt = int(sub_string[0])\n\n            if pos == 'QB':\n                qb += cnt\n                sub_total += cnt\n                qb_listed = True\n            # Assuming LB is a line backer lined up as full back\n            elif pos in ['RB','LB']:\n                rb += cnt\n                sub_total += cnt\n            # Assuming DB is a defensive back and lined up as WR\n            elif pos in ['WR','DB']:\n                wr += cnt\n                sub_total += cnt\n            elif pos == 'TE':\n                te += cnt\n                sub_total += cnt\n            # Assuming DL is a defensive lineman lined up as an additional line man\n            else:\n                ol += cnt\n                sub_total += cnt\n\n        # If not all 11 players were noted at given positions we need to make some assumptions\n        # I will assume if a QB is not listed then there was 1 QB on the play\n        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n        if sub_total < 11:\n            diff = 11 - sub_total\n            if not qb_listed:\n                qb += 1\n                diff -= 1\n            ol += diff\n\n        counts = (qb,rb,wr,te,ol)\n\n        return counts\n    \n    def personnel_features(df):\n        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n\n        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n\n        # Let's create some features to specify if the OL is covered\n        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n        # Let's create a feature to specify if the defense is preventing the run\n        # Let's just assume 7 or more DL and LB is run prevention\n        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n\n        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n        \n        return personnel\n    \n    def process_two(t_):\n        t_['fe1'] = pd.Series(np.sqrt(np.absolute(np.square(t_.X.values) - np.square(t_.Y.values))))\n        t_['fe5'] = np.square(t_['S'].values) + 2 * t_['A'].values * t_['Dis'].values  # N\n        t_['fe7'] = np.arccos(np.clip(t_['X'].values \/ t_['Y'].values, -1, 1))  # N\n        t_['fe8'] = t_['S'].values \/ np.clip(t_['fe1'].values, 0.6, None)\n        radian_angle = (90 - t_['Dir']) * np.pi \/ 180.0\n        t_['fe10'] = np.abs(t_['S'] * np.cos(radian_angle))\n        t_['fe11'] = np.abs(t_['S'] * np.sin(radian_angle))\n        return t_\n\n    def combine_features(relative_to_back, defense, static, personnel, deploy=deploy):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,personnel,on=['GameId','PlayId'],how='inner')\n\n        if not deploy:\n            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n        return df\n    \n    df.loc[df['Season'] == 2017, 'S'] = (df['S'][df['Season'] == 2017] - 2.4355) \/ 1.2930 * 1.4551 + 2.7570\n    yardline = update_yardline(df)\n    df = update_orientation(df, yardline)\n    back_feats = back_features(df)\n    rel_back = features_relative_to_back(df, back_feats)\n    def_feats = defense_features(df)\n    static_feats = static_features(df)\n    personnel = personnel_features(df)\n    basetable = combine_features(rel_back, def_feats, static_feats, personnel, deploy=deploy)\n    basetable = process_two(basetable)\n    basetable = basetable.drop(['X','Y','S','A','Dis','Orientation','Dir','Yards','YardLine',\n           'Quarter','Down','Distance','DefendersInTheBox'], axis=1)\n    \n    return basetable","9b0725ef":"#https:\/\/www.kaggle.com\/rooshroosh\/fork-of-neural-networks-different-architecture\ndef strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])\/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n","da8e2a87":"%%time\ndf = pd.read_csv('..\/input\/nfl-big-data-bowl-2020\/train.csv', dtype={'WindSpeed': 'object'})\noutcomes = df[['GameId','PlayId','Yards']].drop_duplicates()\n\ntrain_gametable = preprocess(df)\ntrain_basetable = create_features(df, False)\n\njoin_by = ['GameId','PlayId']\ntrain = pd.merge(train_gametable, train_basetable, on=(join_by), how='left')\nprint(train.shape)","ad90dbec":"## DisplayName remove Outlier\nv = train[\"DisplayName\"].value_counts()\nmissing_values = list(v[v < 5].index)\ntrain[\"DisplayName\"] = train[\"DisplayName\"].where(~train[\"DisplayName\"].isin(missing_values), \"nan\")\n\n## PlayerCollegeName remove Outlier\nv = train[\"PlayerCollegeName\"].value_counts()\nmissing_values = list(v[v < 10].index)\ntrain[\"PlayerCollegeName\"] = train[\"PlayerCollegeName\"].where(~train[\"PlayerCollegeName\"].isin(missing_values), \"nan\")","af5de197":"#join_by = ['DisplayName','Team','Quarter_ob']\n#agg_history = train.groupby(join_by, as_index=False)['Yards'].agg('mean')\n#agg_history.reset_index(inplace=True, drop=True)\n#agg_history.columns = ['avg_' + c if c == 'Yards' else c for c in agg_history.columns.values]\n#agg_history = agg_history.replace(np.nan, 0)\n\n#agg_history.reset_index(inplace=True, drop=True)\n#agg_history.columns = ['avg_' + c if c == 'Yards' else c for c in agg_history.columns.values]\n#agg_history = agg_history.replace(np.nan, 0)\n\n#train = pd.merge(train, agg_history, on=(join_by), how='left')","00c58fad":"def drop(df):\n    drop_cols = [\"GameId\", \"GameWeather\", \"NflId\", \"Season\", \"NflIdRusher\"] \n    drop_cols += ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate']\n    drop_cols += [\"Orientation\", \"Dir\", 'WindSpeed', \"GameClock\"]\n    # drop_cols += [\"DefensePersonnel\",\"OffensePersonnel\"]\n    df = df.drop(drop_cols, axis = 1)\n    return df","21d823bc":"train = drop(train)\ntrain = train.drop('Yards', axis = 1)\npd.to_pickle(train, \"train.pkl\")","1f8bf770":"cat_features = []\ndense_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append(col)\n        print(\"*cat*\", col, len(train[col].unique()))\n    else:\n        dense_features.append(col)\n        print(\"!dense!\", col, len(train[col].unique()))\ndense_features.remove(\"PlayId\")\n#dense_features.remove(\"Yards\")","693b79ec":"train_cat = train[cat_features]\ncategories = []\nmost_appear_each_categories = {}\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n    categories.append(train_cat[col].unique())\ncategories = np.hstack(categories)\nprint(len(categories))","ee12e837":"le = LabelEncoder()\nle.fit(categories)\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:, col] = le.transform(train_cat[col])\nnum_classes = len(le.classes_)","63272ce2":"train_dense = train[dense_features]\nsss = {}\nmedians = {}\nfor col in tqdm_notebook(train_dense.columns):\n    print(col)\n    medians[col] = np.nanmedian(train_dense[col])\n    train_dense.loc[:, col] = train_dense[col].fillna(medians[col])\n    ss = StandardScaler()\n    train_dense.loc[:, col] = ss.fit_transform(train_dense[col].values[:,None])\n    sss[col] = ss","9ae6ea10":"## dense features for play\ndense_game_features = train_dense.columns[train_dense[:22].std() == 0]\n## dense features for each player\ndense_player_features = train_dense.columns[train_dense[:22].std() != 0]\n## categorical features for play\ncat_game_features = train_cat.columns[train_cat[:22].std() == 0]\n## categorical features for each player\ncat_player_features = train_cat.columns[train_cat[:22].std() != 0]","7c1d911f":"tn = train.iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values","cbc5f7d6":"train_dense_game = train_dense[dense_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_dense_game = np.hstack([train_dense_game, train_dense[dense_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_dense_players = [train_dense[dense_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_dense_players = np.stack([t.values for t in train_dense_players]).transpose(1, 0, 2)\n\ntrain_cat_game = train_cat[cat_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_cat_game = np.hstack([train_cat_game, train_cat[cat_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_cat_players = [train_cat[cat_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_cat_players = np.stack([t.values for t in train_cat_players]).transpose(1, 0, 2)","8b385f41":"def return_step(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\n#train_y_raw = train[\"Yards\"].iloc[np.arange(0, len(train), 22)].reset_index(drop = True)\ntrain_y_raw = outcomes['Yards']\ntrain_y = np.vstack(outcomes['Yards'].apply(return_step).values)","00c87d87":"train_dense_game.shape, train_dense_players.shape, train_cat_game.shape, train_cat_players.shape, train_y.shape","bb885b76":"tf.keras.backend.clear_session()\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\nfrom tensorflow.keras.layers import Concatenate, Layer\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\ndef crps(y_true, y_pred):\n    loss = K.mean((y_pred - y_true)**2)\n    return loss\n\nclass GaussianLayer(Layer):\n\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(GaussianLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        super(GaussianLayer, self).build(input_shape) \n\n    def call(self, x):\n        xx = K.arange(-99, 100, dtype=tf.float32)\n        sigma = tf.identity(K.exp(0.5 * tf.reshape(x[:, 1], (-1, 1))), name=\"sigma\")\n        pdf = 1\/(sigma* K.sqrt(2 * tf.constant(m.pi))) * K.exp( -(tf.subtract(xx, tf.reshape(x[:, 0], (-1, 1))))**2 \/ (2 * sigma**2) )\n        cdf = []\n        for i in range(199):\n            if i == 0:\n                cdf += [tf.reshape(pdf[:, i], (-1, 1))]\n            else:\n                cdf += [cdf[i-1] + tf.reshape(pdf[:, i], (-1, 1))]\n        return tf.concat(cdf, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.output_dim)\n\n    \n# get the newest model file within a directory\ndef getNewestModel(model, dirname):\n    from glob import glob\n    target = os.path.join(dirname, '*')\n    files = [(f, os.path.getmtime(f)) for f in glob(target)]\n    if len(files) == 0:\n        return model\n    else:\n        newestModel = sorted(files, key=lambda files: files[1])[-1]\n        model.load_weights(newestModel[0])\n        return model\n    \ndef l1_reg(weight_matrix):\n    return 0.01 * K.sum(K.abs(weight_matrix))\n\ndef posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n      n = kernel_size + bias_size\n      c = np.log(np.expm1(1.))\n      return tf.keras.Sequential([\n          tfp.layers.VariableLayer(2 * n, dtype=dtype),\n          tfp.layers.DistributionLambda(lambda t: tfd.Independent(  # pylint: disable=g-long-lambda\n              tfd.Normal(loc=t[..., :n],\n                         scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n              reinterpreted_batch_ndims=1)),])\n\ndef prior_trainable(kernel_size, bias_size=0, dtype=None):\n      n = kernel_size + bias_size\n      return tf.keras.Sequential([\n          tfp.layers.VariableLayer(n, dtype=dtype),\n          tfp.layers.DistributionLambda(\n              lambda t: tfd.Independent(tfd.Normal(loc=t, scale=1),  # pylint: disable=g-long-lambda\n                                        reinterpreted_batch_ndims=1)),])\n    \ndef get_model(n_iter, fold_, batch_size = 32, epochs = 10):\n    activation = \"relu\"\n    nodes = 32\n    \n    ## inputs\n    input_dense_game = keras.layers.Input(shape=(train_dense_game.shape[1],), name = \"numerical_general_inputs\")\n    input_dense_players = keras.layers.Input(shape=(train_dense_players.shape[1],train_dense_players.shape[2]), name = \"numerical_players_inputs\")\n    input_cat_game = keras.layers.Input(shape=(train_cat_game.shape[1], ), name = \"categorical_general_inputs\")\n    input_cat_players = keras.layers.Input(shape=(train_cat_players.shape[1], train_cat_players.shape[2]), name = \"categorical_players_input\")\n    \n    ## embedding\n    embedding = keras.layers.Embedding(num_classes, 4, embeddings_regularizer=l1_reg)\n    emb_cat_game = embedding(input_cat_game)\n    emb_cat_game = tfp.layers.Convolution1DFlipout(64, kernel_size=5, padding='SAME', activation=activation)(emb_cat_game)\n    emb_cat_game = keras.layers.Flatten()(emb_cat_game)\n    \n    emb_cat_players = embedding(input_cat_players)\n    emb_cat_players = keras.layers.Reshape((int(emb_cat_players.shape[1]), int(emb_cat_players.shape[2]) * int(emb_cat_players.shape[3])))(emb_cat_players)\n\n    ## general game features\n    game = keras.layers.Concatenate(name = \"general_features\")([input_dense_game, emb_cat_game])\n    game = keras.layers.Dense(nodes, activation=activation)(game)\n    game = keras.layers.Dropout(0.5)(game)\n    \n    ## players features\n    players = keras.layers.Concatenate(name = \"players_features\")([input_dense_players, emb_cat_players])\n    players = tfp.layers.Convolution1DFlipout(nodes, kernel_size=5, padding='SAME', activation=activation)(players)\n    players = keras.layers.Flatten()(players)\n    players = keras.layers.Dense(nodes, activation=activation)(players)\n    players = keras.layers.Dropout(0.5)(players)\n    \n    ## concat\n    x_concat = keras.layers.Concatenate(name = \"all_concat\")([game, players])\n    x_concat = keras.layers.Dropout(0.5)(x_concat)\n    x_concat = tfp.layers.DenseFlipout(nodes, activation=activation, name = \"last_dense1\")(x_concat)\n    x_concat = tfp.layers.DenseVariational(2, posterior_mean_field, prior_trainable, name = \"last_dense2\")(x_concat)\n    mu_log_var = keras.layers.Dense(2, activation=activation, name = \"mu_log_var\")(x_concat)\n    \n    out_dist = GaussianLayer(output_dim=199)(mu_log_var)\n    model = keras.models.Model(inputs = [input_dense_game, input_dense_players, input_cat_game, input_cat_players],\n                               outputs = out_dist)\n    ## compile\n    model.compile(loss=crps, optimizer=keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999))\n    print(model)\n\n    ## train\n    tr_x = [train_dense_game[tr_inds], train_dense_players[tr_inds], train_cat_game[tr_inds], train_cat_players[tr_inds]]\n    tr_y = train_y[tr_inds]\n    val_x = [train_dense_game[val_inds], train_dense_players[val_inds], train_cat_game[val_inds], train_cat_players[val_inds]]\n    val_y = train_y[val_inds]\n    \n    save_model_name = f'model_{fold_}.h5'\n    print(save_model_name)\n    \n    es = EarlyStopping(monitor='val_loss', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=10)\n        \n    modelCheckpoint = ModelCheckpoint(filepath = save_model_name,\n                                  monitor='val_loss',\n                                  verbose=1,\n                                  save_best_only=True,\n                                  save_weights_only=False,\n                                  mode='min',\n                                  period=1)\n    \n    model.fit(tr_x,\n              tr_y,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=0,\n              validation_data=(val_x, val_y), callbacks=[modelCheckpoint, es])\n    \n    loss = model.history.history[\"val_loss\"][-1]\n    model = getNewestModel(model, save_model_name)\n    return model, loss","e9631bfb":"import os\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nlosses = []\nmodels = []\nfor k in range(3):\n    #kfold = KFold(5, random_state = 420 + k, shuffle = True)\n    kfold = StratifiedKFold(3, random_state = 420 + k, shuffle = True)\n    \n    for fold_, (tr_inds, val_inds) in enumerate(kfold.split(train_y_raw, train_y_raw)):\n        print(f\"----- fold:{fold_} ------\")\n        print(\"--------------------------\")\n        model, loss = get_model(k, fold_, 64, 30)\n        models.append(model)\n        print(fold_, loss)\n        losses.append(loss)\nprint(\"-------\")\nprint(losses)\nprint(np.mean(losses))","e72a5f96":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model.png')","a647d688":"print(losses)\nprint(np.mean(losses))","9ea5c99f":"def make_pred(test, sample, env, model):    \n    test_gametable = preprocess(test)\n    test_basetable = create_features(test, False)\n\n    test = pd.merge(test_gametable, test_basetable, on=(join_by), how='left')\n    #test = pd.merge(test, agg_history, on=join_by, how='left')\n    test = drop(test)\n\n    ### categorical\n    test_cat = test[cat_features]\n    for col in (test_cat.columns):\n        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n        isnan = ~test_cat.loc[:,col].isin(categories)\n        if np.sum(isnan) > 0:\n#             print(\"------\")\n#             print(\"test have unseen label : col\")\n            if not ((col + \"__nan\") in categories):\n#                 print(\"not nan in train : \", col)\n                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n            else:\n#                 print(\"nan seen in train : \", col)\n                test_cat.loc[isnan,col] = col + \"__nan\"\n    for col in (test_cat.columns):\n        test_cat.loc[:, col] = le.transform(test_cat[col])\n\n    ### dense\n    test_dense = test[dense_features]\n    for col in (test_dense.columns):\n        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n\n    ### divide\n    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n\n    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_dense_game = np.hstack([test_dense_game, test_dense[dense_player_features][test_dense[\"IsRusher\"] > 0]])\n    \n    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n\n    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_cat_game = np.hstack([test_cat_game, test_cat[cat_player_features][test_dense[\"IsRusher\"] > 0]])\n\n    test_inp = [test_dense_game, test_dense_players, test_cat_game, test_cat_players]\n    \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test_inp)\n        #_pred = np.cumsum(_pred, axis = 1)\n        pred += _pred\n    pred \/= len(models)\n    pred = np.clip(pred, 0, 1)\n    #pred = np.where(pred > 0.93,1,pred)\n    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n    return pred","24604128":"env = nflrush.make_env()\npreds = []\nfor test, sample in tqdm_notebook(env.iter_test()):\n    pred = make_pred(test, sample, env, models)\n    preds.append(pred)\nenv.write_submission_file()","6df7f862":"preds = np.vstack(preds)\n## check whether prediction is submittable\nprint(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\nprint(np.mean(preds > 1) == 0)","5eaebeb4":"print(losses)\nprint(np.mean(losses))","caa47fbb":"## Model","9ea03ce6":"## Dense","02214f0e":"## categorical","40c83966":"Mixed the kernals together and added a couple TFP layers to the model!","95133737":"Inspiration from these 2:\nhttps:\/\/www.kaggle.com\/coolcoder22\/nn-19-features\nhttps:\/\/www.kaggle.com\/kenmatsu4\/nn-outputs-gaussian-distribution-directly","9d1e0a2d":"## Divide features into groups","633332b8":"## Feature engineering","ce6eedeb":"## Prediction","081c1ae2":"For TFP to work, we need to use TensorFlow.Keras"}}