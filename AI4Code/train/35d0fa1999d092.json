{"cell_type":{"95d5396f":"code","17a5da8a":"code","9bb68651":"code","99591da0":"code","79944ab2":"code","67559719":"code","2ae3b8c6":"code","b107ca3e":"code","2bd2ca4d":"code","04d827a0":"code","671ab9e3":"code","7cf38222":"code","b4c9c8f0":"code","c3064e2f":"code","6c866a3e":"code","8fb91aac":"code","11c52343":"code","efa3635e":"code","999c4393":"code","fb6e440a":"code","75198821":"code","d025a59e":"code","94f95038":"code","1c58ff45":"code","06337f88":"code","56aff83f":"code","d1090dcd":"code","9ef6ae9e":"code","300ad1b8":"code","1284c931":"code","2c1af958":"code","3e0c516f":"code","38e5cc53":"code","4710409f":"code","dbefb604":"code","c315ce3a":"code","64c1bf53":"code","023609ce":"code","b189cc76":"code","9fd43292":"code","c9bd9e7f":"code","f1f50e21":"code","2fc5da86":"code","a86a0827":"code","d8dffff7":"code","23d88734":"code","b29a9d26":"code","f1c4706d":"code","d25b08fa":"code","456b75cb":"code","0fd3357e":"code","b6ddfa80":"code","1291cd6b":"markdown","8b2868aa":"markdown","9eca3173":"markdown","851cd817":"markdown","46cfa0c7":"markdown","89ffc811":"markdown","7c93c369":"markdown","be9c24a8":"markdown","33effbda":"markdown","c542fcdd":"markdown","ae0603f8":"markdown","90e42a33":"markdown","76bcc857":"markdown","1bf82082":"markdown","9bc1f0c7":"markdown","74617f64":"markdown","8cee715e":"markdown","66191219":"markdown","548f923b":"markdown","61e2d0c0":"markdown","74b4fb82":"markdown","952f67b8":"markdown","ecbce64d":"markdown","3ef2a554":"markdown","09c4ade4":"markdown","26548b4b":"markdown","18b212f9":"markdown","d2bec090":"markdown"},"source":{"95d5396f":"!pip install feature_engine","17a5da8a":"!pip install arcticdata==\"1.4\"","9bb68651":"import pandas as pd\nimport arcticdata.ExploratoryDataAnalysis as eda\nimport arcticdata.FeatureEngineering as fe\nimport arcticdata.FeatureSelection as fs\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","99591da0":"eda.project_checklist()","79944ab2":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\ntrain.head(3)","67559719":"eda.corr_plot(train)","2ae3b8c6":"eda.correlation(train,'SibSp')","b107ca3e":"eda.missing_data(train,count=True)","2bd2ca4d":"eda.missing_data(train, percentage=True)","04d827a0":"eda.distribution_diag(train,'Age')","671ab9e3":"eda.outliers(train,'Age',method='IQR',table=True, limits=True)","7cf38222":"eda.outliers(train,'Age',method='IQR3',table=True, limits=True)","b4c9c8f0":"eda.value_counts(train.Embarked, count=True)","c3064e2f":"eda.value_counts(train.Embarked, percentage=True)","6c866a3e":"eda.feature_analysis(train, \"Age\", test=test)","8fb91aac":"eda.feature_analysis(train, \"Embarked\", test=test)","11c52343":"eda.feature_analysis(train, \"Fare\", test=test)","efa3635e":"eda.feature_analysis(train, \"Cabin\", test=test)","999c4393":"eda.distribution_diag(train,'Age')","fb6e440a":"x=fe.impute_missing(train,train,method='median')\neda.distribution_diag(x,'Age')","75198821":"x=fe.impute_missing(train,train,method='mean')\neda.distribution_diag(x,'Age')","d025a59e":"x=fe.impute_missing(train,train,method='arbitrary',arbitrary_number=120)\neda.distribution_diag(x,'Age')","94f95038":"x=fe.impute_missing(train,train,method='tail',tail='right')\neda.distribution_diag(x,'Age')","1c58ff45":"x=fe.impute_missing(train,train,method='indicator')\nx['Embarked_na'].sample(5)","06337f88":"x=fe.impute_missing(train,train,method='random')\neda.distribution_diag(x,'Age')","56aff83f":"x=fe.impute_missing(train.Embarked.to_frame(),train.Embarked.to_frame(),method='mode')\neda.value_counts(x.Embarked,percentage=True)","d1090dcd":"x=fe.impute_missing(train.Embarked.to_frame(),train.Embarked.to_frame(),method='category')\neda.value_counts(x.Embarked,percentage=True)","9ef6ae9e":"train = fe.impute_missing(train,train,method='random')\ntest = fe.impute_missing(train.drop(\"Survived\",axis=1),test,method='random')","300ad1b8":"train['Cabin'] = train['Cabin'].str[0]\ntest['Cabin'] = test['Cabin'].str[0]\neda.value_counts(train.Cabin,percentage=True)","1284c931":"x=fe.group_rare_labels(train.Cabin,train.Cabin,tol=0.05)\neda.value_counts(x.Cabin,percentage=True)","2c1af958":"train.drop(\"Name\",axis=1,inplace=True)\ntrain.drop(\"Ticket\",axis=1,inplace=True)\ntest.drop(\"Name\",axis=1,inplace=True)\ntest.drop(\"Ticket\",axis=1,inplace=True)","3e0c516f":"eda.distribution_diag(train,'Age')","38e5cc53":"x = fe.transform(train,'log',variables=['Age'])\neda.distribution_diag(x,'Age')","4710409f":"x = fe.transform(train,'exp',variables=['Age'])\neda.distribution_diag(x,'Age')","dbefb604":"x = fe.transform(train,'inv',variables=['Age'])\neda.distribution_diag(x,'Age')","c315ce3a":"x = fe.transform(train,'boxcox',variables=['Age'])\neda.distribution_diag(x,'Age')","64c1bf53":"x = fe.transform(train,'yeo',variables=['Age'])\neda.distribution_diag(x,'Age')","023609ce":"x = fe.discretization(train, train, method='equalfreq',variables=['Age'])\neda.value_counts(x.Age,percentage=True,table=False)","b189cc76":"x = fe.discretization(train, train, method='equalrange',variables=['Age'])\neda.value_counts(x.Age,percentage=True,table=False)","9fd43292":"x = fe.discretization(train, train, method='equalfreq',variables=['Age'],return_boundaries=True)\neda.value_counts(x.Age,percentage=True,table=False)","c9bd9e7f":"x = fe.encoding(train, train, method='order', variables=['Cabin'])\nx.head()","f1f50e21":"x = fe.encoding(train, train, method='onehot', variables=['Cabin'])\nx.head()","2fc5da86":"test = fe.encoding(train.drop(\"Survived\",axis=1), test)\ntrain = fe.encoding(train, train)","a86a0827":"x = fe.scale(train, method='standar')\nx.head()","d8dffff7":"x = fe.scale(train, method='normal')\nx.head()","23d88734":"x = fe.scale(train, method='minmax')\nx.head()","b29a9d26":"train = fe.scale(train)\ntest = fe.scale(test)","f1c4706d":"x = fs.dropconstant(train, tol=0.998)\nx.head()","d25b08fa":"x = fs.dropduplicated(train)\nx.head()","456b75cb":"x = fs.dropcorrelated(train, threshold=0.8)\nx.head()","0fd3357e":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()","b6ddfa80":"fs.step_forward(train.drop(\"Survived\",axis=1), train['Survived'],model,kfeatures=16,info=True)","1291cd6b":"<br><br>\n# Outliers","8b2868aa":"<br\/><br\/><br\/><br\/><br\/>\n![](https:\/\/i.imgur.com\/9GaTOTy.png)","9eca3173":"<br\/><br\/><br\/><br\/><br\/>\n![](https:\/\/i.imgur.com\/HEmI1A5.png)","851cd817":"<br><br>\n# Transformation of numerical features","46cfa0c7":"<br><br>\n# Discretization of numerical features","89ffc811":"<br><br>\n# Value count for categorical features","7c93c369":"<br><br>\n# Drop correlated features","be9c24a8":"#### Hello! I'm Javier and im a Data Science Master's Degree student. I have made a library to automate the processes in which data scientists invest most part of the time. The library is divided into three sections: EDA, feature engineering and feature selection. \n\n### Give me a like if you found it useful and leave me a comment if you have any suggestion!","33effbda":"## Before starting with the dataset, the library counts with a project checklist if you are lost in any moment and you don't remember what you need to do (This checklist is based in Aur\u00e9lien G\u00e9ron book called \"Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow\")","c542fcdd":"### It's normal to have some outliers, but we need to easy detect if there is something wrong with our dataset. We can use IQR method (1.5*IQR) or IQR3 (3*IQR) to get the outliers","ae0603f8":"<br\/><br\/><br\/><br\/><br\/>\n![](https:\/\/i.imgur.com\/N16UsDR.png)","90e42a33":"<br><br>\n# Distribution of numerical features","76bcc857":"<br><br>\n# Step forward feature selection","1bf82082":"<br><br>\n# Grouping rare labels","9bc1f0c7":"<br><br><br><br><br><br>\n![](https:\/\/i.imgur.com\/HCEMQgK.png)","74617f64":"<br><br>\n# Looking for correlations","8cee715e":"<br><br>\n# Getting all the functions together","66191219":"<br\/><br\/><br\/><br\/><br\/>\n![](https:\/\/i.imgur.com\/wZjLyh8.png)","548f923b":"<br><br>\n# Looking for missing values","61e2d0c0":"## To show what the library can do, we will work with a classic in Data Science, Titanic's dataset","74b4fb82":"<br><br>\n# Drop duplicated features","952f67b8":"<br><br>\n# Looking for correlations for one feature","ecbce64d":"<br><br>\n# Numerical features scaling","3ef2a554":"<br><br>\n# Thanks for watching! Like the notebook if you like it!","09c4ade4":"<br><br>\n# Encoding of categorical features","26548b4b":"<br><br><br><br><br><br>\n![](https:\/\/i.imgur.com\/TdKX2gW.png)","18b212f9":"# Imputing missing values","d2bec090":"# Drop constant features"}}