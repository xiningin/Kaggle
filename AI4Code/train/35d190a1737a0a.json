{"cell_type":{"c91e865b":"code","6bfbe2f9":"code","a7b011d9":"code","ef91ab44":"code","6aeea02c":"code","1aca02e5":"code","69113654":"code","0f7fdc3a":"code","3c633c64":"code","f3e21fac":"code","23fa6880":"code","27b9fa60":"code","dc58dc4d":"code","76ff5d1e":"code","ff7b1eb7":"code","c7803484":"code","6ca4da5d":"markdown","0da8d310":"markdown","6ee28d25":"markdown","1b002eb4":"markdown"},"source":{"c91e865b":"import os\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import kurtosis\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nimport xgboost as xgb\nfrom xgboost import XGBClassifier","6bfbe2f9":"DATA_DIRECTORY = \"..\/input\/home-credit-loan-better-data-processing\"","a7b011d9":"train = pd.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv'))\ntest = pd.read_csv(os.path.join(DATA_DIRECTORY, 'test.csv'))\nlabels = pd.read_csv(os.path.join(DATA_DIRECTORY, 'labels.csv'))\n","ef91ab44":"import re\ntrain = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\ntest = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\nlabels = labels.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))","6aeea02c":"train=np.nan_to_num(train)\ntest=np.nan_to_num(test)\nlabels=np.nan_to_num(labels)","1aca02e5":"train = pd.DataFrame(train)\ntest = pd.DataFrame(test)\nlabels=pd.DataFrame(labels)","69113654":"print(train.shape)","0f7fdc3a":"#perform training and test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, labels, random_state=42)","3c633c64":"#Dummy Classifier\nfrom sklearn.dummy import DummyClassifier\nclf = DummyClassifier(strategy= 'most_frequent').fit(X_train,y_train)\ny_pred = clf.predict(X_test)\n\n#Distribution of y test\nprint('y actual : \\n' +  str(y_test.value_counts()))\n\n#Distribution of y predicted\nprint('y predicted : \\n' + str(pd.Series(y_pred).value_counts()))","f3e21fac":"# Model Evaluation metrics \nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred)))\n\n#Dummy Classifier Confusion matrix\nfrom sklearn.metrics import confusion_matrix\nprint('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))","23fa6880":"from lightgbm import LGBMClassifier\n\n\nclf = LGBMClassifier().fit(X_train,y_train)\ny_pred = clf.predict(X_test)\n\n# Model Evaluation metrics \nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred)))\n\n#Logistic Regression Classifier Confusion matrix\nfrom sklearn.metrics import confusion_matrix\nprint('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))","27b9fa60":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\npre_probs1 = clf.predict_proba(X_test)\n\npre_probs1 = pre_probs1[:, 1]\n\npre_auc = roc_auc_score(y_test, pre_probs1)\n\nprint('LGBM: ROC AUC=%.3f' % (pre_auc))\n\npre_fpr, pre_tpr, _ = roc_curve(y_test, pre_probs1)\n# plot the roc curve for the model\n\nplt.plot(pre_fpr, pre_tpr, marker='.', label='LGBM')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()\n","dc58dc4d":"#Grid Search\nfrom sklearn.model_selection import GridSearchCV\nclf = LogisticRegression()\ngrid_values = {'penalty': ['l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\ngrid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall')\ngrid_clf_acc.fit(X_train, y_train)\n\n#Predict values based on new parameters\ny_pred_acc = grid_clf_acc.predict(X_test)\n\n# New Model Evaluation metrics \nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))\n\n#Logistic Regression (Grid Search) Confusion matrix\nconfusion_matrix(y_test,y_pred_acc)","76ff5d1e":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\npre_probs1 = clf.predict_proba(X_test)\n\npre_probs1 = pre_probs1[:, 1]\n\npre_auc = roc_auc_score(y_test, pre_probs1)\n\nprint('LGBM: ROC AUC=%.3f' % (pre_auc))\n\npre_fpr, pre_tpr, _ = roc_curve(y_test, pre_probs1)\n# plot the roc curve for the model\n\nplt.plot(pre_fpr, pre_tpr, marker='.', label='SVM')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()\n","ff7b1eb7":"pred = model.predict_proba(df_test)","c7803484":"submit = test[['SK_ID_CURR']]\nsubmit['TARGET'] = pred\nsubmit.to_csv('lgbm_Minimized_code.csv', index = False)","6ca4da5d":"# Now that we have the baseline accuracy, let\u2019s build a Logistic regression model with default parameters and evaluate the model.\n","0da8d310":"# Grid Search to maximize Recall","6ee28d25":"# ****LGBM****","1b002eb4":"# Calculate the evaluation metrics of this model."}}