{"cell_type":{"eba9f350":"code","15bf1715":"code","b581d9cc":"code","87dcc5e9":"code","20fc4bab":"code","9e838e94":"code","69f947c5":"code","9e78c82c":"code","a0902b25":"code","7387b56b":"code","68b5390a":"code","c8cd3d74":"code","3e5c6168":"code","f29f1234":"code","3c8f5699":"code","bad03042":"code","ab7483be":"code","ee058f0f":"code","ff4392d5":"code","e191ab16":"code","502377ef":"code","24979aa2":"code","032b9c0c":"code","9f735851":"code","3875b962":"code","29241119":"code","0bf8e13d":"code","36627486":"code","bb8eb159":"code","d84e0746":"code","2cb6728e":"code","5929e665":"code","63843165":"code","68973edf":"code","9b64bea7":"code","f984db98":"code","1ab4ebf2":"code","6db44177":"code","596f5c7a":"code","80f53819":"code","0602fe96":"code","fa643313":"code","f26f1aa4":"code","fb03f09a":"code","4583962a":"code","91c2f820":"code","7edb7a67":"code","27d2ec40":"code","c8d1ce07":"code","18bedf62":"code","f185eaee":"code","0e08f1bc":"code","76d368aa":"code","65c24594":"code","772ae327":"code","ba93d04d":"code","fa8947f6":"code","865fc8af":"code","fd730a86":"code","5856cd70":"markdown","c36a31c5":"markdown","dcf50e37":"markdown","b14b09b1":"markdown","99ecdb2d":"markdown","ec29de55":"markdown","1d11973b":"markdown","c6ee3a67":"markdown","b4c23e53":"markdown","ddf90ad0":"markdown","bd7a3a74":"markdown","38b3c1c2":"markdown","036c929d":"markdown","11c925ec":"markdown","8cbd95cb":"markdown","3dc3ec65":"markdown","5202d9b5":"markdown","8c15d6cd":"markdown","6e96fabe":"markdown","64cd8ba0":"markdown","1bcf7503":"markdown","ad3ab6e1":"markdown","088c7480":"markdown","da7f2046":"markdown","29e78098":"markdown","e28abc24":"markdown","d6413213":"markdown","0350e5a7":"markdown","f9d24fec":"markdown","fde21952":"markdown","b87f152b":"markdown","5c49d0f5":"markdown","13a30046":"markdown","0f9a3574":"markdown","b9d6a4b9":"markdown","de922c21":"markdown","aa26e5a1":"markdown"},"source":{"eba9f350":"!pip install plotly --quiet","15bf1715":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport plotly.express as px\nimport warnings\nwarnings.filterwarnings('ignore')","b581d9cc":"os.listdir(\"\/kaggle\/input\/DontGetKicked\")","87dcc5e9":"train = pd.read_csv(\"\/kaggle\/input\/DontGetKicked\/training.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/DontGetKicked\/test.csv\")\nexample_entry = pd.read_csv(\"\/kaggle\/input\/DontGetKicked\/example_entry.csv\")","20fc4bab":"train.head()","9e838e94":"train.shape","69f947c5":"test.head()","9e78c82c":"test.shape","a0902b25":"train.info()","7387b56b":"train.drop(columns=[\"RefId\", \"PurchDate\", \"BYRNO\"], inplace = True)","68b5390a":"plt.figure(figsize=(18, 18))\nmatrix = np.triu(train.corr())\nsns.heatmap(train.corr(), annot=True, linewidths=.5, fmt= '.1f', mask=matrix)\nplt.show()","c8cd3d74":"train.drop(columns = [\"VNZIP1\", \"WheelTypeID\"], inplace = True)","3e5c6168":"train.isna().sum()*100 \/ len(train)","f29f1234":"train.drop(columns = [\"PRIMEUNIT\", \"AUCGUART\", \"Trim\", \"WheelType\", \"SubModel\", \"Color\", \"TopThreeAmericanName\"], inplace = True)","3c8f5699":"train.isna().sum()*100 \/ len(train)","bad03042":"train.shape","ab7483be":"train.dropna(inplace = True)","ee058f0f":"train.shape","ff4392d5":"train.isna().sum()","e191ab16":"categorical_columns = train.select_dtypes(include = 'object')\nnumerical_columns = train.select_dtypes(exclude='object')","502377ef":"print(f\"Number of Categorical Columns: {categorical_columns.shape[1]}\")\nprint(f\"Number of Numerical Columns: {numerical_columns.shape[1]}\")","24979aa2":"sns.countplot(x = \"VehYear\", data = train, hue = \"IsBadBuy\")","032b9c0c":"sns.countplot(x = \"VehicleAge\", data = train, hue = \"IsBadBuy\")","9f735851":"px.histogram(train, x = \"Auction\", color = \"IsBadBuy\")","3875b962":"px.histogram(train, x = \"Make\", color = \"IsBadBuy\")","29241119":"px.histogram(train, x = \"Nationality\", color = \"IsBadBuy\")","0bf8e13d":"other_asian = len(train[(train['Nationality']==\"OTHER ASIAN\") & train[\"IsBadBuy\"]==1])*100\/len(train[train['Nationality']==\"OTHER ASIAN\"])\namerican = len(train[(train['Nationality']==\"AMERICAN\") & train[\"IsBadBuy\"]==1])*100\/len(train[train['Nationality']==\"AMERICAN\"])\ntop_line_asian = len(train[(train['Nationality']==\"TOP LINE ASIAN\") & train[\"IsBadBuy\"]==1])*100\/len(train[train['Nationality']==\"TOP LINE ASIAN\"])\nother = len(train[(train['Nationality']==\"OTHER\") & train[\"IsBadBuy\"]==1])*100\/len(train[train['Nationality']==\"OTHER\"])","36627486":"print(f\"OTHER ASIAN: {round(other_asian)}%\")\nprint(f\"AMERICAN: {round(american)}%\")\nprint(f\"TOP LINE ASIAN: {round(top_line_asian)}%\")\nprint(f\"OTHER: {round(other)}%\")","bb8eb159":"categorical_columns","d84e0746":"#Number of unique categories for Auction\ncategorical_columns.Auction.nunique()","2cb6728e":"categorical_columns.Auction.unique()","5929e665":"#Number of unique categories for Make\ncategorical_columns.Make.nunique()","63843165":"categorical_columns.Make.unique()","68973edf":"#Number of unique categories for Model\ncategorical_columns.Model.nunique()","9b64bea7":"#Number of unique categories for Transmission\ncategorical_columns.Transmission.nunique()","f984db98":"categorical_columns.Transmission.unique()","1ab4ebf2":"train.Transmission.replace(to_replace='Manual', value = \"MANUAL\", inplace = True)","6db44177":"train.Transmission.unique()","596f5c7a":"#Number of unique categories for Nationality\ncategorical_columns.Nationality.nunique()","80f53819":"categorical_columns.Nationality.unique()","0602fe96":"train.Nationality.replace(to_replace=[\"OTHER ASIAN\", \"TOP LINE ASIAN\"], value = \"ASIAN\", inplace = True)","fa643313":"train.Nationality.unique()","f26f1aa4":"categorical_columns.Size.nunique()","fb03f09a":"categorical_columns.Size.unique()","4583962a":"categorical_columns.VNST.nunique()","91c2f820":"categorical_columns.VNST.unique()","7edb7a67":"X = train.drop(columns=\"IsBadBuy\")\ny = train[\"IsBadBuy\"]","27d2ec40":"X","c8d1ce07":"y","18bedf62":"from sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split","f185eaee":"cat_cols_list = X.dtypes[X.dtypes.isin(['object','category'])].index.to_list()\ncat_cols_list","0e08f1bc":"num_cols_list = list(X.select_dtypes(exclude=['object']).columns)\nnum_cols_list","76d368aa":"x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","65c24594":"preprocess = make_column_transformer((StandardScaler(), num_cols_list), (OneHotEncoder(categories='auto', handle_unknown='ignore'), cat_cols_list))","772ae327":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression","ba93d04d":"pipeline1 = make_pipeline(preprocess, RandomForestClassifier())\npipeline1.fit(x_train, y_train)","fa8947f6":"print(f\"Random Forest Train Set: {pipeline1.score(x_train, y_train)}\")\nprint(f\"Random Forest Validation Set: {pipeline1.score(x_val, y_val)}\")","865fc8af":"pipeline2 = make_pipeline(preprocess, LogisticRegression(solver = 'liblinear'))\npipeline2.fit(x_train, y_train)","fd730a86":"print(f\"Logistic Regression Train Set: {pipeline2.score(x_train, y_train)}\")\nprint(f\"Losgistic Regression Val Set: {pipeline2.score(x_val, y_val)}\")","5856cd70":"# Data Description\n\n>**RefID**\t\t\t->\t    Unique (sequential) number assigned to vehicles\n\n>**IsBadBuy**\t\t->\t\tIdentifies if the kicked vehicle was an avoidable purchase \n\n>**PurchDate**\t\t->\t\tThe Date the vehicle was Purchased at Auction\n\n>**Auction**\t\t\t->\t\tAuction provider at which the  vehicle was purchased\n\n>**VehYear**\t\t\t->\t\tThe manufacturer's year of the vehicle\n\n>**VehicleAge**\t\t->\t\tThe Years elapsed since the manufacturer's year\n\n>**Make**\t\t\t->\t\tVehicle Manufacturer \n\n>**Model**\t\t\t->\t\tVehicle Model\n\n>**Trim**\t\t\t->\t\tVehicle Trim Level\n\n>**SubModel**\t\t->\t\tVehicle Submodel\n\n>**Color**\t\t\t->\t\tVehicle Color\n\n>**Transmission**\t\t->\t\tVehicles transmission type (Automatic, Manual)\n\n>**WheelTypeID**\t\t\t->\tThe type id of the vehicle wheel\n\n>**WheelType**\t\t\t->\tThe vehicle wheel type description (Alloy, Covers)\n\n>**VehOdo**\t\t\t\t->\tThe vehicles odometer reading\n\n>**Nationality**\t\t\t->\tThe Manufacturer's country\n\n>**Size**\t\t\t\t->\tThe size category of the vehicle (Compact, SUV, etc.)\n\n>**TopThreeAmericanName**\t->\t\tIdentifies if the manufacturer is one of the top three American manufacturers\n\n>**MMRAcquisitionAuctionAveragePrice**\t->  Acquisition price for this vehicle in average condition at time of purchase\t\n\n>**MMRAcquisitionAuctionCleanPrice**\t\t->  Acquisition price for this vehicle in the above Average condition at time of purchase\n\n>**MMRAcquisitionRetailAveragePrice**\t->  Acquisition price for this vehicle in the retail market in average condition at time of \npurchase\n\n>**MMRAcquisitonRetailCleanPrice**\t\t->  Acquisition price for this vehicle in the retail market in above average condition at time of purchase\n\n>**MMRCurrentAuctionAveragePrice**\t->\tAcquisition price for this vehicle in average condition as of current day\t\n\n>**MMRCurrentAuctionCleanPrice**\t\t->  Acquisition price for this vehicle in the above condition as of current day\n\n>**MMRCurrentRetailAveragePrice**\t->  Acquisition price for this vehicle in the retail market in average condition as of current day\n\n>**MMRCurrentRetailCleanPrice**\t->\tAcquisition price for this vehicle in the retail market in above average condition as of current day\n\n>**PRIMEUNIT**\t\t->\t\tIdentifies if the vehicle would have a higher demand than a standard purchase\n\n>**AcquisitionType**\t\t->\t\tIdentifies how the vehicle was aquired (Auction buy, trade in, etc)\n\n>**AUCGUART**\t\t\t->\tThe level guarntee provided by auction for the vehicle (Green light - Guaranteed\/arbitratable, Yellow Light - caution\/issue, red light - sold as is)\n\n>**KickDate**\t\t\t->\tDate the vehicle was kicked back to the auction\n\n>**BYRNO**\t\t\t\t->\tUnique number assigned to the buyer that purchased the vehicle\n\n>**VNZIP**                 ->                  Zipcode where the car was purchased\n\n>**VNST**                    ->                State where the the car was purchased\n\n>**VehBCost**\t\t->\t\tAcquisition cost paid for the vehicle at time of purchase\n\n>**IsOnlineSale**\t\t->\t\tIdentifies if the vehicle was originally purchased online\n\n>**WarrantyCost**          ->                  Warranty price (term=36month  and millage=36K) ","c36a31c5":"### Make","dcf50e37":"## StandardScaler\n\nStandardize features by removing the mean and scaling to unit variance\n\nThe standard score of a sample x is calculated as:\n\nz = (x - u) \/ s\n\nwhere u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n\nCentering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.\n\nStandardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).\n\nCheck [StandardScaler](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html) for more details.","b14b09b1":"**Also since we cannot guess the `Trim` and `WheelType` of cars just randomly, we are also dropping the same.**","99ecdb2d":"**Split the data in training and validation sets.**","ec29de55":"# Make vs IsBadBuy","1d11973b":"# Categorical Data","c6ee3a67":"**Probability of a car being a bad buy given it's Nationality.**","b4c23e53":"**Since we have a fairly small fraction of missing values, we can safely drop the rows with missing data.**","ddf90ad0":"### Preprocessing\n\nWe are going to use column transformer to One-hot encode the categorical variables and scale the numerical variables.","bd7a3a74":"# Missing Values (%ages)\n\nLet's check for the % of missing values in each column.","38b3c1c2":"### Model","036c929d":"**Now it is rectified.**","11c925ec":"### Transmission","8cbd95cb":"**From above it is clear that `PRIMEUNIT` and `AUCGUART` columns have more than `95%` of values missing. So it is best to drop them as it is.**","3dc3ec65":"**Lets check the percent of missing values once again.**","5202d9b5":"## make_column_transformer\n\nIt allows for applying different transformations to different columns in a pipeline. For example, we need different preprocessing steps for numerical and categorical columns. This allows us to apply different steps to specified columns in a pipeline.\n\nCheck [make_column_transformer](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.compose.make_column_transformer.html) for more details. Also check [Column Transformers Examples](https:\/\/machinelearningmastery.com\/columntransformer-for-numerical-and-categorical-data\/) for example implementation.","8c15d6cd":"### Nationality","6e96fabe":"**`SubModel` doesn't provide much valuable information and `Color` doesn't wouldn't certainly affect the car quality. Also, we don't need the `TopThreeAmericanName` as we already have `Make` and `Nationality` columns.**","64cd8ba0":"**It seems that Transmission column has naming error. Let's replace 'Manual' with 'MANUAL'.**","1bcf7503":"# VehicleAge vs IsBadBuy","ad3ab6e1":"### Auction","088c7480":"### Size","da7f2046":"# Auction vs IsBadBuy","29e78098":"## OneHot Encoder\n\nEncode categorical features as a one-hot numeric array.\n\nThe input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are encoded using a one-hot (aka \u2018one-of-K\u2019 or \u2018dummy\u2019) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter)\n\nBy default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the categories manually.\n\nThis encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.\n\nCheck [OneHot Encoder](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OneHotEncoder.html) for more details.","e28abc24":">**PurchDate** (Date of Purchase of car from auction) won't be any help in predicting if the car was a good or bad buy.\n\n>Similarly we don't have any use of **RefId** Column.\n\n>Also, **BYRNO** i.e. Unique number assigned to each buyer in auction is not useful as the buyer won't affect the quality of car.","d6413213":"**Let's merge OTHER ASIAN and TOP LINE ASIAN into a single ASIAN category. This will make more sense.**","0350e5a7":"**Now it seems more rational.**","f9d24fec":"**We have now 15 numerical columns and 7 categorical columns in our data.**","fde21952":"# Visualizing Correlations\n\nCorrelation is a very useful technique to get rid of unecessary columns from our dataset that don't affect our target.","b87f152b":"# VehYear vs IsBadBuy","5c49d0f5":"### VNST","13a30046":"**From above figure we can see that `VNZIP1` and `WheelTypeID` have no correlation with our target `IsBadBuy`. So we can safely drop them.**","0f9a3574":"## make_pipeline\n\nConstruct a Pipeline from the given estimators. Check [make_pipeline](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.make_pipeline.html) for details.","b9d6a4b9":"**Dogde, Ford, Chevrolet and Chrysler** cars account for the most listed as well as most bad buys. That makes sense. If a company has more listings, it will as well have higher bad buys.","de922c21":"## Features and Target","aa26e5a1":"Nothing seems irrational. As the number of listings increased, so did the number of bad buys."}}