{"cell_type":{"09990053":"code","3445d970":"code","57b9a2bb":"code","3782e6b2":"code","c6995159":"code","5d99f294":"code","d58fb354":"code","f754729c":"code","07e7f67c":"code","b9409b55":"code","ecaa8f8c":"code","daae1bd0":"code","5c69664e":"code","7b41b10f":"code","440d26f8":"code","3235d2dc":"code","813552f3":"code","1b66ac36":"code","de51979f":"code","c6f1d54a":"code","9ab45f01":"code","9d1c642e":"code","3c74af8a":"code","073a362f":"code","714c93d3":"code","926fa037":"code","38fc7c7c":"code","58af72a0":"code","9fe248bb":"code","f3da170a":"code","50f8618d":"code","c9630e31":"code","f3f3e5c0":"code","d028a5a1":"code","be25e52a":"code","9b2bf053":"code","a349e684":"code","5e3b9c0e":"code","598bca58":"code","6c22a6dc":"code","18920560":"code","140a104f":"code","49d6deb2":"code","1a6f1f81":"code","7a8dcfee":"code","28c3621f":"code","6c65ed2b":"code","b3d9cbba":"code","1750b5bf":"code","269016e7":"code","c32da03b":"code","292403a4":"code","9d75fad4":"code","3a674332":"code","d1416eec":"code","e0412884":"code","4477f142":"code","a948fec4":"code","0cdaf28f":"code","c0337a50":"code","0de72d35":"code","806d4653":"code","d3fbbc3e":"code","71dee279":"code","78861f7c":"code","72bcf491":"code","0ce36cf8":"code","8f6f8482":"code","6b5ce614":"code","dc5dd075":"code","e01a6560":"code","df6c0814":"code","8a392890":"code","f852d5d7":"code","9cde871b":"code","8c7d8ba9":"code","05d5dd86":"code","a0dceefd":"markdown","c694c0c7":"markdown","19fcb3a9":"markdown","66cc0591":"markdown","b66d5402":"markdown","5dfbd1b0":"markdown","547da47b":"markdown","dcff5492":"markdown","4b25ecf4":"markdown","0a6ccba1":"markdown","f2f4f1c2":"markdown","ba023b09":"markdown","1f3b000c":"markdown","2bddeb67":"markdown","dffcf496":"markdown","ee41567d":"markdown","34989851":"markdown","fde71834":"markdown","28bebf9d":"markdown","61899574":"markdown","9cd9f037":"markdown","865ec622":"markdown","276caac4":"markdown","19b3c58c":"markdown","bc7f137b":"markdown","f8573f49":"markdown","6b1ef336":"markdown","b3b5b416":"markdown","0e6dbbb1":"markdown","62d25ea0":"markdown","dc663f2e":"markdown","cdb9f314":"markdown","1ec39210":"markdown","7151f24f":"markdown","44647a35":"markdown","69835261":"markdown","62dff4c4":"markdown","3ce0c8a2":"markdown","aa3f4d72":"markdown","45a7b035":"markdown","a7cdbfd2":"markdown","29df7262":"markdown","94798df2":"markdown","44f6afd6":"markdown","d0955eec":"markdown","736878dd":"markdown","dd7d8b29":"markdown","73acb733":"markdown","ba56c786":"markdown","06758442":"markdown","46220377":"markdown","0e556420":"markdown","80805281":"markdown","95c066f4":"markdown","ce69756e":"markdown","8f17c546":"markdown","a1d7784a":"markdown","8e5b424c":"markdown","f2fafef9":"markdown","86615d4d":"markdown","1ac8691b":"markdown","8c616cf1":"markdown","af5de909":"markdown","f4859d65":"markdown","a7a83933":"markdown","9b19e1a5":"markdown","f81f4cb3":"markdown","873d25f8":"markdown","5fafda57":"markdown","ace6f28a":"markdown","622950f9":"markdown","bf60b971":"markdown","717d8df0":"markdown"},"source":{"09990053":"# importing the required library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom haversine import haversine\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import learning_curve\nimport pickle","3445d970":"# read the dataframe\ndf = pd.read_csv('\/kaggle\/input\/nyc-taxi\/train.csv')\ndf.head()","57b9a2bb":"# Checking the datatypes of dataset\ndf.dtypes","3782e6b2":"#Statistics of features\ndf.describe()","c6995159":"# shape of dataset\ndf.shape","5d99f294":"# check the nan or missing values\ndf.isnull().sum()","d58fb354":"# convert the timestamp into datetime formate \ndf['pickup_datetime']=pd.to_datetime(df['pickup_datetime'])\ndf['dropoff_datetime']= pd.to_datetime(df['dropoff_datetime'])","f754729c":"# add the weekname, month, hours and weekday into the dataframe\ndf['weekday']=df.pickup_datetime.dt.day_name()\ndf['month']=df.pickup_datetime.dt.month\ndf['weekday_num']=df.pickup_datetime.dt.weekday\ndf['pickup_hour']=df.pickup_datetime.dt.hour","07e7f67c":"#calculate the distance between the pickup location and drop location\ndef calculate_distance(df):\n    pickup = (df['pickup_latitude'], df['pickup_longitude'])\n    drop = (df['dropoff_latitude'], df['dropoff_longitude'])\n    return haversine(pickup, drop)","b9409b55":"# create a distance columns in dataframe\ndf['distance']=df.apply(lambda x: calculate_distance(x), axis=1)","ecaa8f8c":"# calculate the speed in km\/h \ndf['speed'] = (df.distance \/ (df.trip_duration\/3600))","daae1bd0":"# checking the type of features \ndf.dtypes.reset_index()","5c69664e":"#Dummify all the categorical features like \"store_and_fwd_flag, vendor_id, month, weekday_num, pickup_hour, passenger_count\" except the label i.e. \"trip_duration\"\n\ndummy = pd.get_dummies(df.store_and_fwd_flag, prefix='flag')\ndummy.drop(dummy.columns[0], axis=1, inplace=True) #avoid dummy trap\ndf = pd.concat([df,dummy], axis = 1)\n\ndummy = pd.get_dummies(df.vendor_id, prefix='vendor_id')\ndummy.drop(dummy.columns[0], axis=1, inplace=True) #avoid dummy trap\ndf = pd.concat([df,dummy], axis = 1)\n\ndummy = pd.get_dummies(df.month, prefix='month')\ndummy.drop(dummy.columns[0], axis=1, inplace=True) #avoid dummy trap\ndf = pd.concat([df,dummy], axis = 1)\n\ndummy = pd.get_dummies(df.weekday_num, prefix='weekday_num')\ndummy.drop(dummy.columns[0], axis=1, inplace=True) #avoid dummy trap\ndf = pd.concat([df,dummy], axis = 1)\n\ndummy = pd.get_dummies(df.pickup_hour, prefix='pickup_hour')\ndummy.drop(dummy.columns[0], axis=1, inplace=True) #avoid dummy trap\ndf = pd.concat([df,dummy], axis = 1)\n\ndummy = pd.get_dummies(df.passenger_count, prefix='passenger_count')\ndummy.drop(dummy.columns[0], axis=1, inplace=True) #avoid dummy trap\ndf = pd.concat([df,dummy], axis = 1)","7b41b10f":"df.head()","440d26f8":"df.passenger_count.value_counts()","3235d2dc":"# checking the outlier\nplt.figure(figsize=(5,8))\nsns.boxplot(y=df.passenger_count)\nplt.show()","813552f3":"# remove the passenger_count outlier\ndf = df[df.passenger_count <=6]\ndf['passenger_count']=df.passenger_count.map(lambda x: 1 if x==0 else x)","1b66ac36":"df.passenger_count.describe()","de51979f":"# count plot of passenger_count features\nplt.figure(figsize=(10,5))\nsns.set_theme(style='darkgrid')\nsns.countplot(data=df, x='passenger_count')\nplt.show()","c6f1d54a":"# countplot of the vendor\nsns.countplot(x = 'vendor_id', data = df)\nplt.show()","9ab45f01":"df.distance.describe()","9d1c642e":"# view the 5 point statistics of distance features\nplt.figure(figsize=(10,5))\nsns.boxplot(x='distance',data = df)\nplt.show()","3c74af8a":"# checking the number of trips where distance 0\nprint('There are {} trip records with 0 km distance'.format(df.distance[df.distance ==0].count()))","073a362f":"df.distance.groupby(pd.cut(df.distance, np.arange(0,100,10))).count().plot(kind='barh')\nplt.show()","714c93d3":"# description of the trip_duration features\ndf.trip_duration.describe()","926fa037":"# view the 5 points statistics \nplt.figure(figsize=(30,5))\nsns.boxplot(x = 'trip_duration', data = df)\nplt.show()","38fc7c7c":"print(df.trip_duration.groupby(pd.cut(df.trip_duration, np.arange(1, max(df.trip_duration),3600))).count())","58af72a0":"## removing the outliers\ndf[df.trip_duration <= 86400]\ndf.head()","9fe248bb":"df.trip_duration.groupby(pd.cut(df.trip_duration,np.arange(1,7200, 600))).count().plot(kind='barh')\nplt.xlabel('Trip counts')\nplt.ylabel('Trip Duration (Seconds)')\nplt.show()","f3da170a":"# Describe the data\ndf.speed.describe()","50f8618d":"# view the 5 points statistics \nplt.figure(figsize=(15,5))\nsns.boxplot(x = 'speed', data= df)\nplt.show()","c9630e31":"# remove the trips which more than 104 km\/h\ndf = df[df.speed <= 104]\nplt.figure(figsize=(10,5))\nsns.boxplot(x = 'speed', data = df)\nplt.show()","f3f3e5c0":"df.speed.groupby(pd.cut(df.speed, np.arange(0,104,10))).count().plot(kind='barh')\nplt.xlabel('Trip Count')\nplt.ylabel('Speed (km\/h)')\nplt.show()","d028a5a1":"df.store_and_fwd_flag.value_counts(normalize=True)","be25e52a":"df.store_and_fwd_flag.value_counts()","9b2bf053":"sns.countplot(x = 'pickup_hour', data = df)\nplt.show()","a349e684":"sns.countplot(x = 'weekday_num', data =df)\nplt.xlabel('Month')\nplt.ylabel('Pickup counts')\nplt.show()","5e3b9c0e":"sns.countplot(x = 'month', data = df)\nplt.ylabel('Trips counts')\nplt.xlabel('Months')\nplt.show()","598bca58":"group1 = df.groupby('pickup_hour').trip_duration.mean()\nsns.pointplot(group1.index, group1.values)\nplt.ylabel('Trip duration (seconds)')\nplt.xlabel('Pickup Hour')\nplt.show()","6c22a6dc":"group2 = df.groupby('weekday_num').trip_duration.mean()\nsns.pointplot(group2.index, group2.values)\nplt.ylabel('Trip Duratin (second)')\nplt.xlabel('Weekday')\nplt.show()","18920560":"group3 = df.groupby('month').trip_duration.mean()\nsns.pointplot(group3.index, group3.values)\nplt.ylabel('Trip duration (seconds)')\nplt.xlabel('Month')\nplt.show()","140a104f":"group4 = df.groupby('vendor_id').trip_duration.mean()\nsns.barplot(group4.index, group4.values)\nplt.ylabel('Trip duration (seconds)')\nplt.xlabel('Vendor')\nplt.show()","49d6deb2":"plt.figure(figsize=(5,5))\nplot_dur = df.loc[(df.trip_duration < 10000)]\nsns.boxplot(x = df.store_and_fwd_flag, y = 'trip_duration',data=plot_dur)\nplt.show()","1a6f1f81":"group5 = df.groupby('pickup_hour').distance.mean()\nsns.pointplot(group5.index, group5.values)\nplt.ylabel('Distance (km)')\nplt.show()","7a8dcfee":"group6 = df.groupby('weekday_num').distance.mean()\nsns.pointplot(group6.index, group6.values)\nplt.ylabel('Distance (km)')\nplt.show()","28c3621f":"group7 = df.groupby('month').distance.mean()\nsns.pointplot(group7.index, group7.values)\nplt.ylabel('Distance (km)')\nplt.show()","6c65ed2b":"group8 = df.groupby('vendor_id').distance.mean()\nsns.barplot(group8.index, group8.values)\nplt.ylabel('Distance km')\nplt.show()","b3d9cbba":"group9 = df.groupby('vendor_id').passenger_count.mean()\nsns.barplot(group9.index, group9.values)\nplt.ylabel('Passenger count')\nplt.show()","1750b5bf":"df.groupby('passenger_count').vendor_id.value_counts().reset_index(name='count').pivot(\"passenger_count\",\"vendor_id\",\"count\").plot(kind='bar')\nplt.show()","269016e7":"list(zip(range(0, len(df.columns)), df.columns))","c32da03b":"# seperating the dependent feature and independent feature\ny = df.iloc[:,10].values\nx = df.iloc[:,range(15,61)].values","292403a4":"x1 = np.append(arr = np.ones((x.shape[0],1)).astype(float), values = x, axis = 1)","9d75fad4":"#Select all the features in X array\nx_opt = x1[:,range(0,46)]\nregressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n\n#Fetch p values for each feature\np_values = regressor_OLS.pvalues\n\n#define significance level for accepting the feature.\nsig_Level = 0.05\n\n#Loop to iterate over features and remove the feature with p value less than the sig_level\nwhile max(p_values) > sig_Level:\n    print(\"Probability values of each feature \\n\")\n    print(p_values)\n    x_opt = np.delete(x_opt, np.argmax(p_values), axis = 1)\n    print(\"\\n\")\n    print(\"Feature at index {} is removed \\n\".format(str(np.argmax(p_values))))\n    print(str(x_opt.shape[1]-1) + \" dimensions remaining now... \\n\")\n    regressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()\n    p_values = regressor_OLS.pvalues\n    print(\"=================================================================\\n\")\n    \n#Print final summary\nprint(\"Final stat summary with optimal {} features\".format(str(x_opt.shape[1]-1)))\nregressor_OLS.summary()","3a674332":"## ploting the correlation\ndef plot_corr(x,y):\n  plt.figure(figsize=(15,15))\n  corr = pd.DataFrame(x).corr()\n  corr.index = pd.DataFrame(x).columns\n  sns.heatmap(corr, cmap='RdYlGn', vmin=-1, vmax=1, square=True)\n  plt.title(\"Correlation Heatmap\", fontsize=16)\n  plt.show()\n","d1416eec":"# split the raw data\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=0)\n\n# split the seleted featue data\nx_train_fs, x_test_fs, y_train_fs, y_test_fs = train_test_split(x_opt, y, test_size=0.25, random_state=0)","e0412884":"# correlation of raw data\nplot_corr(x_train, y_train)","4477f142":"# correlation of selected features\nplot_corr(x_train_fs, y_train_fs)","a948fec4":"# initialize the standard scaler object for row data\nscaler_x = StandardScaler()\nx_train = scaler_x.fit_transform(x_train)\nx_test = scaler_x.transform(x_test)\n\n# Initialize the standard scaler object for selected features\nscaler_x_fs = StandardScaler()\nx_train_fs = scaler_x_fs.fit_transform(x_train_fs)\nx_test_fs = scaler_x_fs.transform(x_test_fs)","0cdaf28f":"# set the hyperparameter for XGBRegressor\nparam_tuning = {\n        'learning_rate': [0.01, 0.1],\n        'max_depth': [3, 5, 7, 10],\n        'min_child_weight': [1, 3,4],\n        'subsample': [0.5, 0.7,0.75],\n        'colsample_bytree': [0.5, 0.7,1],\n        'n_estimators' : [100, 200,300,400],\n        'gama':[0,1,2,3,4,5],\n        'objective': ['reg:squarederror']\n    }","c0337a50":"# initialize the randomizedSearchCV \nrandom_xgb = RandomizedSearchCV(XGBRegressor(), param_distributions=param_tuning, cv=3, n_iter=10,n_jobs=-1)\n# fit the randomizedSearchCV\nrandom_xgb.fit(x_train_fs, y_train_fs)","0de72d35":"# define the function see best estimator, best score, best parameter and return best parameters\ndef best_parameters(model):\n    print('Best Estimators are: {}'.format(model.best_estimator_))\n    print('Best Scores are: {}'.format(model.best_score_))\n    print('Best parameters are: {}'.format(model.best_params_))\n    return model.best_params_","806d4653":"best_params_xgb = best_parameters(random_xgb)","d3fbbc3e":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]\n# Method of selecting samples for training each tree\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf\n              }\n","71dee279":"random_rf = RandomizedSearchCV(RandomForestRegressor(), param_distributions=random_grid, cv=3, n_iter=10,n_jobs=-1)\nrandom_rf.fit(x_train_fs, y_train_fs)","78861f7c":"best_params_rf = best_parameters(random_rf)","72bcf491":"hyperparameter_grid = {\n    'n_estimators': [100, 200, 300, 500],\n    'max_depth': [2, 3, 5, 10, 15],\n    'min_samples_leaf': [1, 2, 4, 6, 8],\n    'min_samples_split': [2, 4, 6, 10],\n    'max_features': ['auto', 'sqrt']}","0ce36cf8":"random_gard = RandomizedSearchCV(GradientBoostingRegressor(),  param_distributions=hyperparameter_grid, cv=3, n_iter=10,n_jobs=-1)\nrandom_gard.fit(x_train_fs, y_train_fs)","8f6f8482":"best_params_gard = best_parameters(random_gard)","6b5ce614":"# Initialize the random forest regressor model object\nxgb= XGBRegressor(subsample= 0.7,objective='reg:squarederror',n_estimators=200,min_child_weight= 3, max_depth= 5, learning_rate= 0.1, colsample_bytree= 1)\n# fit the model\nxgb.fit(x_train_fs, y_train_fs)","dc5dd075":"# Initialize the xgbRegressor for selected features\nrf = RandomForestRegressor()\nrf.fit(x_train_fs, y_train_fs)","e01a6560":"gb = GradientBoostingRegressor(n_estimators=200,min_samples_split=2,min_samples_leaf=6,max_features='auto', max_depth= 5)\ngb.fit(x_train_fs, y_train_fs)","df6c0814":"# predication on the test dataset\ny_pred_xgb = xgb.predict(x_test_fs)\nprint('RMSE score for the XGB regressor is : {}'.format(np.sqrt(metrics.mean_squared_error(y_test_fs,y_pred_xgb))))\nprint('Variance score for the XGB Regressor is : %.2f' % xgb.score(x_test_fs, y_test_fs))","8a392890":"# predication on the test dataset\n#y_pred_rf = rf.predict(x_test_fs)\n#print('RMSE score for the XGB regressor is : {}'.format(np.sqrt(metrics.mean_squared_error(y_test_fs,y_pred_rf))))\n#print('Variance score for the XGB Regressor is : %.2f' % rf.score(x_test_fs, y_test_fs))","f852d5d7":"# predication on the test dataset\ny_pred_gb = gb.predict(x_test_fs)\nprint('RMSE score for the Gradient boosting regressor is : {}'.format(np.sqrt(metrics.mean_squared_error(y_test_fs,y_pred_gb))))\nprint('Variance score for the Gradient boosting Regressor is : %.2f' % gb.score(x_test_fs, y_test_fs))","9cde871b":"#Define a function to plot learning curve.\ndef learning_curves(estimator, title, features, target, train_sizes, cv, n_jobs=-1):\n    plt.figure(figsize = (12,8))\n    train_sizes, train_scores, validation_scores = learning_curve(estimator, features, target, train_sizes = train_sizes, cv = cv, scoring = 'neg_mean_squared_error',  n_jobs=n_jobs)\n    train_scores_mean = -train_scores.mean(axis = 1)\n    validation_scores_mean = -validation_scores.mean(axis = 1)\n    \n    plt.grid()\n    \n    plt.plot(train_sizes, train_scores_mean,'o-', color=\"r\", label = 'Training error')\n    plt.plot(train_sizes, validation_scores_mean,'o-', color=\"g\", label = 'Validation error')\n\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    \n    title = 'Learning curves for a ' + title + ' model'\n    plt.title(title, fontsize = 18, loc='left')\n    \n    plt.legend(loc=\"best\")\n    \n    return plt","8c7d8ba9":"# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=4)\n\n# Plot learning curve for the RF Regressor\ntitle = \"XGB REgressor\"\n\n# Call learning curve with all dataset i.e. traininig and test combined because CV will take of data split.\nlearning_curves(xgb, title, x_opt,y, train_sizes=np.linspace(.1, 1.0, 5), cv=cv, n_jobs=-1)","05d5dd86":"# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=4)\n\n# Plot learning curve for the RF Regressor\ntitle = \"Gradient Boosting regressor\"\n\n# Call learning curve with all dataset i.e. traininig and test combined because CV will take of data split.\nlearning_curves(gb, title, x_opt,y, train_sizes=np.linspace(.1, 1.0, 5), cv=cv, n_jobs=-1)","a0dceefd":"**Observations:**\n* There are some trips with more than 24 hours\n* major trips are are completed within an interval 1 hours and good numbers of trips duration going above 1 hours\n","c694c0c7":"**Feature details:**\n* id: unique identifier of each trip\n* vendor_id: a code associated with trip record with trip provide\n* pickup_datetime: pickup date and time of the passenger\n* dropoff_datetime: drop date and time of the passenger\n* passenger_count: The numbers of passenger in the vehicle\n* pickup_longitude: The longitude where the passenger pickup\n* pickup_latitude: The latitude where the passenger pickup\n* dropoff_longitude: The longitude where the passenge drop\n* dropoff_latitude: The latitude where the passenger drop\n* store_and_fwd_flag: this flag indicates wheather the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server -Y =store and forward N=not a store and forward trip\n\n**Label details:**\n* trip_duration: duration of the trip in second","19fcb3a9":"### 2. Randome Forest Regressor","66cc0591":"The distribution is almost equivalent, varying mostly around 3.5 km\/h with 5th month being the highest in the average distance and 2nd month being the lowest.","b66d5402":"### Passenger count per vendor","5dfbd1b0":"### Trip duration per hour","547da47b":"### 2. RandomForestRegressor","dcff5492":"### 2. RandomForestRegressor","4b25ecf4":"we can see an increasing trend of taxi pickups starting from monday to friday. The trend starts declining from saturday till monday.","0a6ccba1":"### Distance","f2f4f1c2":"**Observation:**\n* we can see an increasing trend in the average trip duration with each month.\n* The duration difference between each month is not much\n* It is lowest during february","ba023b09":"## Model selection","1f3b000c":" {'subsample': 0.7, 'objective': 'reg:squarederror', 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.1, 'gama': 5, 'colsample_bytree': 1}","2bddeb67":"Average trip duration for vendor 2 is higher than vendor 1","dffcf496":"### Total trips per month","ee41567d":"### Distance per month","34989851":"* XGB training curve initially starts high but later on improves as the training size increases and then seems to plateau by the end.\n* Gradient Boosting training curve on the other hand starts approx same further improves with the increase in the training size and it too plateau towards the end.\n* Validation curve seems to show similar trend in both the models i.e. starts very high but improves with the training size with some differences in error rate i.e. XGBoost curve learning is quite fast and more accurate as compared to the Gradent boosting one.\n* Both the models seems to suffer from high variance since the training curve error is very less in both the models.\n* The large gap at the end also indicates that the model suffers from quite a low bias i.e. overfitting the training data.\n","fde71834":"## Univariate Analysis","28bebf9d":"### Trip duration per month","61899574":"### Speed","9cd9f037":"**Observation:**\n* There some trips with over 100 km distance\n* some of the trips distance value is 0 km\n* mean distance travelled is approx 3.5 kms\n* standard deviation of 4.3 which shows that most of the trips are limited to the range of 1-10 kms","865ec622":"most of the rides are 1-10 km and few rides are 10-30 km ","276caac4":"#### Split the data","19b3c58c":"**Observation:**\n* some trip duartion over 50000 seconds which are outlier and should be removed\n* There are some duration with as low as 1 second which points towards trip with 0 km distance\n* Major trip duration between 10-20 minutes to complete\n","bc7f137b":"## **I could not implemented the random forest regressor because the data point approx 1.4 M and memory is not enough as required.**","f8573f49":"### Trip duration per vendor","6b1ef336":"### Trip duration vs Flag","b3b5b416":"### Passenger_count","0e6dbbb1":"**Obeservation:**\n* we can see that the big car served by the vendor 2\n* vendor 1 has more mini vans \n* the vendor 2 has greater market share as compare to vendor 1","62d25ea0":"### Distance per vendor","dc663f2e":"**Obervations:**\n* Trip distance is highest during early morning hours\n* Trip distance is fairly equal from morning till the evening varying around 3 - 3.5 kms\n","cdb9f314":"### Store_and_fwd_flag","1ec39210":"### Vendor","7151f24f":"### 1. XGBRegressor","44647a35":"Below the 1% of the trip details were stored in the vehicle first before sending it to the server","69835261":"There are approximetely **1.5 million records** in our dataset","62dff4c4":"### **NOTE: I could not implement the hyperparameter tuning well as expected because the data point approx 1.4 M and memory is not enough as required.**","3ce0c8a2":"## Bivariate Analysis","aa3f4d72":"**Observation:**\n* General trends of taxi pickups which starts increasing from 6 AM There are not unusal behavior here\n","45a7b035":"### 1. XGBRegressor","a7cdbfd2":"### Distance per hour","29df7262":"### Trip duration per weekday","94798df2":"Clear difference between the two operators for the average count in all trips. It seems that vendor 2 trips generally consist of 2 passengers as compared to the vendor 1 with 1 passenger","44f6afd6":"We can see that trip duration is almost equally distributed across the week on a scale of 0-1000 minutes with minimal difference in the duration times","d0955eec":"## Model Training","736878dd":"## 1. XGBRegressor","dd7d8b29":"## Model Evaluation","73acb733":"Best parameters are: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'auto', 'max_depth': 5}","ba56c786":"## Exploratory Data Analysis\n","06758442":"### Trip Duration","46220377":"### 3. GradientBosstingRegressor","0e556420":"### Total trips per hours","80805281":"**Observation:**\n* few trips 0,7,8 or 9 passengers. all these are outlier\n* most of the trip of either 1,2,3,4,5 and 6","95c066f4":"**Intuition**\n* This technique to select the best features to dataset for our model\n* It show some statistical metrics with there significance value\n","ce69756e":"**Observation:**\n* Many trips were done at a speed of over 200 km\/h","8f17c546":"## Learning Curve","a1d7784a":"Now our feature set is ready for features selection\nHere we will take the level of significance as 5% which means that we will reject feature from the list of array and re-run the model till p value for all the features goes below .05 to find out the optimal combination for our model.","8e5b424c":"Fairly equal distribution with average distance metric verying around 3.5 km\/h with sunday being at the top may be due to outstation trips or night trips towards the airport.","f2fafef9":"There is not NULL or missing records so we don't need to impute any features","86615d4d":"## 3. GradientBoostingRegressor\n","1ac8691b":"### Scale the input data\nit is required because the different features have a different range of values. If you are not scaling the features it might give higher importance of some feature and less importance to other that might leads to overfitting","8c616cf1":"## Feature selection","af5de909":"### Total trips per weekday","f4859d65":"Both the vendor have almost equal share but the vendor 2 more famous show in the above graph","a7a83933":"most of the trips were done at a speed range of 10-20 km\/h","9b19e1a5":"This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a server connection. Y = store and forward and N= not store and forward trip","f81f4cb3":"### 3. GradientBoostingRegressor","873d25f8":"* There is a significant improvement in the RMSE score for the tuned XGBoost regressor over the Gradient boosting regressor when trained on the feature selection group.\n\n* The variance score of the XGB Regression little bit more efficient than Gradient boosting regression.\n\n* XGBoost proved to be much more efficient in predicting the output. But it takes much more time to train it over the large dataset with more complexity as compared to the Gradient boosting Regressor.\n\n* It little bit helped us much to generalize the model by tuning hyperparameters for the XGB model as there is not much difference in the RMSE scores of the default model and the tuned model of the feature selection group in fact both varies on every iteration and sometimes the tuned model gives poor results than the default model.\n\n* In contrast to the Gradient Boosting Regressor, XGBoost regressor prediction results were consistent on every iteration.\n","5fafda57":"### Distance per weekday","ace6f28a":"# Feature Engineering","622950f9":"## Hyperparameter Tunning","bf60b971":"**Model Selection**\n* This is superviesed regression problem. Model selection objective is speed or accuracy.\n* If you are care about the speed choose the following algorithms.\n** Linear Regression\n** Decision Tree Regressor\n* If you are care about the accuracy choose the following algorithms.\n** Random Forest Regressor\n** Neural Network\n** Gradient Boosting Regressor\n** XGBRegressor\n\n**I am care about the accuarcy so I would implement the following regression algorithms.**\n* Random forest Regressor\n* GradientBoostingRegressor\n* XGBRegressor\n","717d8df0":"**Observation:**\n* trip duration is lowest at 6 AM when there is minimal traffic on the roads.\n* Trip duration is generally highest around 3PM during the busy streets"}}