{"cell_type":{"f310a808":"code","bd69a417":"code","8b3a61ec":"code","92eea971":"code","015a285c":"code","52d87da2":"code","49596acd":"code","e126650a":"code","423cdaf4":"code","8c58d4da":"code","71bee19f":"code","693c9144":"code","484e095e":"code","6feb8e42":"code","d7b434f7":"code","0f374c25":"code","4e218908":"code","32395b21":"code","9d29730b":"code","cbc188b7":"code","9795b83f":"code","8e675408":"code","a39c5772":"code","1309e280":"code","fbf978ed":"code","24a774b7":"code","51989edb":"code","326dfe09":"code","abb6c230":"code","4e0b6b5e":"code","775abe58":"code","ffa0220d":"code","31ed4171":"code","92d9de56":"code","a0d80549":"code","b0e1813d":"code","ec3c9b70":"code","f5157052":"code","7ef0ecd5":"code","1bf0df2c":"code","31066937":"code","43c199f3":"code","0a300e9e":"code","ef1cb698":"code","fa9328a8":"code","60a95a56":"code","b3288381":"code","5977eb27":"code","4729d838":"code","61662838":"code","82d8b505":"code","646fa2d3":"code","2e2d3a1c":"code","4dab6f36":"code","a1be1353":"code","8bb7f4ce":"code","fc4be74b":"code","81543a0a":"code","c7af2a36":"code","b0c4e454":"code","c4ab9e04":"code","8f65acbb":"code","7dd8e5b7":"code","97c9178f":"code","12386865":"code","e01401bb":"code","4926fa0f":"markdown","89b5ed1b":"markdown","12483a14":"markdown","aef92a14":"markdown","f1532559":"markdown","990e50de":"markdown","4999949e":"markdown","c7c48fbc":"markdown","98a377de":"markdown"},"source":{"f310a808":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas_profiling\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd69a417":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv',sep = ',')\nsample = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv',sep = ',')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv',sep= ',')\ntxt = pd.read_fwf('\/kaggle\/input\/house-prices-advanced-regression-techniques\/data_description.txt',sep = ' ')\n\nprint(\"Load dataset\/\/\/\/\")","8b3a61ec":"txt.head()","92eea971":"train.head(-1)","015a285c":"sample.head()","52d87da2":"test.head()","49596acd":"#pandas_profiling.ProfileReport(train) ","e126650a":"train.plot(x='Id', y=[\"SalePrice\"])","423cdaf4":"fig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(x = train['Id'], y = train['SalePrice'])\nplt.xlabel(\"ID\")\nplt.ylabel(\"House Price\")\n\nplt.show()","8c58d4da":"train.isnull().sum()\n","71bee19f":"train.head()","693c9144":"fig = plt.figure()\nax = fig.add_subplot(111, projection = '3d')\n\nx = train['SalePrice']\ny = train['LotFrontage']\nz = train['LotArea']\n\nax.scatter(x, y, z)\nax.set_xlabel(\"Sale price\")\nax.set_ylabel(\"LotFrontage\")\nax.set_zlabel(\"LotArea\")\n\nplt.show()","484e095e":"train = pd.get_dummies(train)\ntrain.columns\n#train.head()","6feb8e42":"train.isnull().sum()","d7b434f7":"train['LotFrontage'] = train['LotFrontage'].fillna(train['LotFrontage'].mean())","0f374c25":"train.columns","4e218908":"train.isnull().sum()","32395b21":"for i in range(0,290):\n    if train[train.columns[i]].isnull().sum()>0:\n        train[train.columns[i]].isnull().sum()\n        #print(train.columns[i],train[train.columns[i]].isnull().sum())\n        train[train.columns[i]] = train[train.columns[i]].fillna(train[train.columns[i]].mean())\n        print(train.columns[i],train[train.columns[i]].isnull().sum())","9d29730b":"for i in range(0,290):\n    \n    \n    print(train.columns[i],train[train.columns[i]].isnull().sum())","cbc188b7":"#from sklearn.experimental import enable_iterative_imputer\n#from sklearn.impute import IterativeImputer\n#from sklearn import impute\n\n#num_cols = [\n#    train.columns\n#]\n#print(num_cols)\n\n#imputer = impute.IterativeImputer()\n#imputed = imputer.fit_transform(train[num_cols])\n#train.loc[:,num_cols] = imputed\n#meds = train.median()\n#train = train.fillna(meds)","9795b83f":"train.head(-1)","8e675408":"for i in range(0,290):\n    train.columns[i]\n    print(train.columns[i])","a39c5772":"train['SalePrice']","1309e280":"#pandas_profiling.ProfileReport(train)","fbf978ed":"model = RandomForestRegressor(random_state=42, n_estimators=500, criterion='mae')","24a774b7":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)\n","51989edb":"pd.options.mode.chained_assignment = None","326dfe09":"test = pd.get_dummies(test)\ntest.columns","abb6c230":"for i in range(0,271):\n    if test[test.columns[i]].isnull().sum()>0:\n        test[test.columns[i]].isnull().sum()\n        #print(train.columns[i],train[train.columns[i]].isnull().sum())\n        test[test.columns[i]] = test[test.columns[i]].fillna(test[test.columns[i]].mean())\n        print(test.columns[i],test[test.columns[i]].isnull().sum())","4e0b6b5e":"print(\"[\")\nfor i in range(0,271):\n\n    print(\"'\",test.columns[i],\"'\",\",\")\nprint(\"]\")","775abe58":"X = train.drop(columns = ['SalePrice'])","ffa0220d":"X = train[[\n'MSSubClass' ,\n'LotFrontage' ,\n'LotArea' ,\n'OverallQual' ,\n'OverallCond' ,\n'YearBuilt' ,\n'YearRemodAdd' ,\n'MasVnrArea' ,\n'BsmtFinSF1' ,\n'BsmtFinSF2' ,\n'BsmtUnfSF' ,\n'TotalBsmtSF' ,\n'1stFlrSF' ,\n'2ndFlrSF' ,\n'LowQualFinSF' ,\n'GrLivArea' ,\n'BsmtFullBath' ,\n'BsmtHalfBath' ,\n'FullBath' ,\n'HalfBath' ,\n'BedroomAbvGr' ,\n'KitchenAbvGr' ,\n'TotRmsAbvGrd' ,\n'Fireplaces' ,\n'GarageYrBlt' ,\n'GarageCars' ,\n'GarageArea' ,\n'WoodDeckSF' ,\n'OpenPorchSF' ,\n'EnclosedPorch' ,\n'3SsnPorch' ,\n'ScreenPorch' ,\n'PoolArea' ,\n'MiscVal' ,\n'MoSold' ,\n'YrSold' ,\n'MSZoning_C (all)' ,\n'MSZoning_FV' ,\n'MSZoning_RH' ,\n'MSZoning_RL' ,\n'MSZoning_RM' ,\n'Street_Grvl' ,\n'Street_Pave' ,\n'Alley_Grvl' ,\n'Alley_Pave' ,\n'LotShape_IR1' ,\n'LotShape_IR2' ,\n'LotShape_IR3' ,\n'LotShape_Reg' ,\n'LandContour_Bnk' ,\n'LandContour_HLS' ,\n'LandContour_Low' ,\n'LandContour_Lvl' ,\n'Utilities_AllPub' ,\n'LotConfig_Corner' ,\n'LotConfig_CulDSac' ,\n'LotConfig_FR2' ,\n'LotConfig_FR3' ,\n'LotConfig_Inside' ,\n'LandSlope_Gtl' ,\n'LandSlope_Mod' ,\n'LandSlope_Sev' ,\n'Neighborhood_Blmngtn' ,\n'Neighborhood_Blueste' ,\n'Neighborhood_BrDale' ,\n'Neighborhood_BrkSide' ,\n'Neighborhood_ClearCr' ,\n'Neighborhood_CollgCr' ,\n'Neighborhood_Crawfor' ,\n'Neighborhood_Edwards' ,\n'Neighborhood_Gilbert' ,\n'Neighborhood_IDOTRR' ,\n'Neighborhood_MeadowV' ,\n'Neighborhood_Mitchel' ,\n'Neighborhood_NAmes' ,\n'Neighborhood_NPkVill' ,\n'Neighborhood_NWAmes' ,\n'Neighborhood_NoRidge' ,\n'Neighborhood_NridgHt' ,\n'Neighborhood_OldTown' ,\n'Neighborhood_SWISU' ,\n'Neighborhood_Sawyer' ,\n'Neighborhood_SawyerW' ,\n'Neighborhood_Somerst' ,\n'Neighborhood_StoneBr' ,\n'Neighborhood_Timber' ,\n'Neighborhood_Veenker' ,\n'Condition1_Artery' ,\n'Condition1_Feedr' ,\n'Condition1_Norm' ,\n'Condition1_PosA' ,\n'Condition1_PosN' ,\n'Condition1_RRAe' ,\n'Condition1_RRAn' ,\n'Condition1_RRNe' ,\n'Condition1_RRNn' ,\n'Condition2_Artery' ,\n'Condition2_Feedr' ,\n'Condition2_Norm' ,\n'Condition2_PosA' ,\n'Condition2_PosN' ,\n'BldgType_1Fam' ,\n'BldgType_2fmCon' ,\n'BldgType_Duplex' ,\n'BldgType_Twnhs' ,\n'BldgType_TwnhsE' ,\n'HouseStyle_1.5Fin' ,\n'HouseStyle_1.5Unf' ,\n'HouseStyle_1Story' ,\n'HouseStyle_2.5Unf' ,\n'HouseStyle_2Story' ,\n'HouseStyle_SFoyer' ,\n'HouseStyle_SLvl' ,\n'RoofStyle_Flat' ,\n'RoofStyle_Gable' ,\n'RoofStyle_Gambrel' ,\n'RoofStyle_Hip' ,\n'RoofStyle_Mansard' ,\n'RoofStyle_Shed' ,\n'RoofMatl_CompShg' ,\n'RoofMatl_Tar&Grv' ,\n'RoofMatl_WdShake' ,\n'RoofMatl_WdShngl' ,\n'Exterior1st_AsbShng' ,\n'Exterior1st_AsphShn' ,\n'Exterior1st_BrkComm' ,\n'Exterior1st_BrkFace' ,\n'Exterior1st_CBlock' ,\n'Exterior1st_CemntBd' ,\n'Exterior1st_HdBoard' ,\n'Exterior1st_MetalSd' ,\n'Exterior1st_Plywood' ,\n'Exterior1st_Stucco' ,\n'Exterior1st_VinylSd' ,\n'Exterior1st_Wd Sdng' ,\n'Exterior1st_WdShing' ,\n'Exterior2nd_AsbShng' ,\n'Exterior2nd_AsphShn' ,\n'Exterior2nd_Brk Cmn' ,\n'Exterior2nd_BrkFace' ,\n'Exterior2nd_CBlock' ,\n'Exterior2nd_CmentBd' ,\n'Exterior2nd_HdBoard' ,\n'Exterior2nd_ImStucc' ,\n'Exterior2nd_MetalSd' ,\n'Exterior2nd_Plywood' ,\n'Exterior2nd_Stone' ,\n'Exterior2nd_Stucco' ,\n'Exterior2nd_VinylSd' ,\n'Exterior2nd_Wd Sdng' ,\n'Exterior2nd_Wd Shng' ,\n'MasVnrType_BrkCmn' ,\n'MasVnrType_BrkFace' ,\n'MasVnrType_None' ,\n'MasVnrType_Stone' ,\n'ExterQual_Ex' ,\n'ExterQual_Fa' ,\n'ExterQual_Gd' ,\n'ExterQual_TA' ,\n'ExterCond_Ex' ,\n'ExterCond_Fa' ,\n'ExterCond_Gd' ,\n'ExterCond_Po' ,\n'ExterCond_TA' ,\n'Foundation_BrkTil' ,\n'Foundation_CBlock' ,\n'Foundation_PConc' ,\n'Foundation_Slab' ,\n'Foundation_Stone' ,\n'Foundation_Wood' ,\n'BsmtQual_Ex' ,\n'BsmtQual_Fa' ,\n'BsmtQual_Gd' ,\n'BsmtQual_TA' ,\n'BsmtCond_Fa' ,\n'BsmtCond_Gd' ,\n'BsmtCond_Po' ,\n'BsmtCond_TA' ,\n'BsmtExposure_Av' ,\n'BsmtExposure_Gd' ,\n'BsmtExposure_Mn' ,\n'BsmtExposure_No' ,\n'BsmtFinType1_ALQ' ,\n'BsmtFinType1_BLQ' ,\n'BsmtFinType1_GLQ' ,\n'BsmtFinType1_LwQ' ,\n'BsmtFinType1_Rec' ,\n'BsmtFinType1_Unf' ,\n'BsmtFinType2_ALQ' ,\n'BsmtFinType2_BLQ' ,\n'BsmtFinType2_GLQ' ,\n'BsmtFinType2_LwQ' ,\n'BsmtFinType2_Rec' ,\n'BsmtFinType2_Unf' ,\n'Heating_GasA' ,\n'Heating_GasW' ,\n'Heating_Grav' ,\n'Heating_Wall' ,\n'HeatingQC_Ex' ,\n'HeatingQC_Fa' ,\n'HeatingQC_Gd' ,\n'HeatingQC_Po' ,\n'HeatingQC_TA' ,\n'CentralAir_N' ,\n'CentralAir_Y' ,\n'Electrical_FuseA' ,\n'Electrical_FuseF' ,\n'Electrical_FuseP' ,\n'Electrical_SBrkr' ,\n'KitchenQual_Ex' ,\n'KitchenQual_Fa' ,\n'KitchenQual_Gd' ,\n'KitchenQual_TA' ,\n'Functional_Maj1' ,\n'Functional_Maj2' ,\n'Functional_Min1' ,\n'Functional_Min2' ,\n'Functional_Mod' ,\n'Functional_Sev' ,\n'Functional_Typ' ,\n'FireplaceQu_Ex' ,\n'FireplaceQu_Fa' ,\n'FireplaceQu_Gd' ,\n'FireplaceQu_Po' ,\n'FireplaceQu_TA' ,\n'GarageType_2Types' ,\n'GarageType_Attchd' ,\n'GarageType_Basment' ,\n'GarageType_BuiltIn' ,\n'GarageType_CarPort' ,\n'GarageType_Detchd' ,\n'GarageFinish_Fin' ,\n'GarageFinish_RFn' ,\n'GarageFinish_Unf' ,\n'GarageQual_Fa' ,\n'GarageQual_Gd' ,\n'GarageQual_Po' ,\n'GarageQual_TA' ,\n'GarageCond_Ex' ,\n'GarageCond_Fa' ,\n'GarageCond_Gd' ,\n'GarageCond_Po' ,\n'GarageCond_TA' ,\n'PavedDrive_N' ,\n'PavedDrive_P' ,\n'PavedDrive_Y' ,\n'PoolQC_Ex' ,\n'PoolQC_Gd' ,\n'Fence_GdPrv' ,\n'Fence_GdWo' ,\n'Fence_MnPrv' ,\n'Fence_MnWw' ,\n'MiscFeature_Gar2' ,\n'MiscFeature_Othr' ,\n'MiscFeature_Shed' ,\n'SaleType_COD' ,\n'SaleType_CWD' ,\n'SaleType_Con' ,\n'SaleType_ConLD' ,\n'SaleType_ConLI' ,\n'SaleType_ConLw' ,\n'SaleType_New' ,\n'SaleType_Oth' ,\n'SaleType_WD' ,\n'SaleCondition_Abnorml' ,\n'SaleCondition_AdjLand' ,\n'SaleCondition_Alloca' ,\n'SaleCondition_Family' ,\n'SaleCondition_Normal' ,\n'SaleCondition_Partial']]\nX.head(-1)","31ed4171":"#for i in range(0,271):\n#    X = train[test.columns[i]]\n#X.head()","92d9de56":"y = train['SalePrice']\ny.head()","a0d80549":"#GS = GridSearchCV(model, random_grid, cv = 3, verbose=2, n_jobs = -1)\n# Fit the random search model\n#GS.fit(X, y)","b0e1813d":"#GS.best_params_","ec3c9b70":"for i in range(0,271):\n    if test[test.columns[i]].isnull().sum()>0:\n        test[test.columns[i]].isnull().sum()\n        #print(train.columns[i],train[train.columns[i]].isnull().sum())\n        test[test.columns[i]] = test[test.columns[i]].fillna(test[test.columns[i]].mean())\n        print(test.columns[i],test[test.columns[i]].isnull().sum())","f5157052":"test","7ef0ecd5":"X = X.drop(columns = ['SalePrice'])","1bf0df2c":"test = test.drop(columns = ['Id'])","31066937":"for i in range(0,270):\n    print(test.columns[i], X.columns[i])","43c199f3":"import lightgbm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer","0a300e9e":"parameters = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': ['l2', 'auc'],\n    'learning_rate': 0.005,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 10,\n    'verbose': 0,\n    \"max_depth\": 8,\n    \"num_leaves\": 128,  \n    \"max_bin\": 512,\n    \"num_iterations\": 100000,\n    \"n_estimators\": 1000\n}\n\n","ef1cb698":"model = lightgbm.LGBMRegressor(**parameters)","fa9328a8":"\nparameters = {\n    'application': 'binary',\n    'objective': 'binary',\n    'metric': 'auc',\n    'is_unbalance': 'true',\n    'boosting': 'gbdt',\n    'num_leaves': 31,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 20,\n    'learning_rate': 0.05,\n    'verbose': 0\n}\n\n","60a95a56":"model = lightgbm.train(parameters,\n                       train,\n                       valid_sets=test,\n                       num_boost_round=5000,\n                       early_stopping_rounds=10000)","b3288381":"model = lightgbm.train(parameters,\n                       train,\n                       test,\n                       num_boost_round=1000,\n                       early_stopping_rounds=100)","5977eb27":"y_test = sample","4729d838":"y_test = sample['SalePrice']\ny_test","61662838":"model.fit(X, y,\n        eval_set=[(test, y_test)],\n        eval_metric='l1',\n        early_stopping_rounds=1000)","82d8b505":"from sklearn.metrics import mean_squared_log_error","646fa2d3":"y_pred = model.predict(test)","2e2d3a1c":"print('The rmse of prediction is:', round(mean_squared_log_error(y_pred, train) ** 0.5, 5))","4dab6f36":"model = RandomForestRegressor(random_state=42, n_estimators=1000, criterion='mae')","a1be1353":"from sklearn.metrics import median_absolute_error","8bb7f4ce":"random_grid ={\n    'bootstrap': [True, False],\n 'max_depth': [10],\n 'max_features': ['auto'],\n 'min_samples_leaf': [2, 4],\n 'min_samples_split': [2, 5],\n 'n_estimators': [200, 800]\n}","fc4be74b":"GS = GridSearchCV(model, random_grid, cv = 3,scoring = \"neg_median_absolute_error\", verbose=1, n_jobs = -1)\n# Fit the random search model\nGS.fit(X, y)","81543a0a":"GS.best_params_","c7af2a36":"model = RandomForestRegressor(random_state=42, bootstrap = True, max_depth= 10,\n max_features = 'auto',\n min_samples_leaf = 2,\n min_samples_split = 5,\n n_estimators = 200, criterion='mae')","b0c4e454":"model.fit(X,y)\nmodel.score(X,y)","c4ab9e04":"test = test.drop(columns = ['Id'])","8f65acbb":"y_pred = model.predict(test)","7dd8e5b7":"y_pred","97c9178f":"model.score(test,y_pred)","12386865":"sample.head(-1)","e01401bb":"submission = pd.DataFrame({\n    \"Id\": sample.Id, \n    \"SalePrice\": y_pred\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"submission.csv ____________________________ SAVE\")","4926fa0f":"# ","89b5ed1b":"Show data visualization new train.\n# \npandas_profiling.ProfileReport(train)","12483a14":"Show all columns \nUpdate table Train and conver categorical data from other columns.\nNext step to create new important columns, search for dependencies between train(important columns)\n\n","aef92a14":"**Analysis data** \n**train csv\n#use pandas_profiling.ProfileReport\n* Report about all columns ","f1532559":"You might need a way of handling missing values, such as pandas.DataFrame.fillna or sklearn.preprocessing.Imputer. See our Missing Values tutorial for more details.","990e50de":"#Plot data houses","4999949e":"**File descriptions**\n* train.csv - the training set\n* test.csv - the test set\n* data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\n* sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\n\nData fields\n\nHere's a brief version of what you'll find in the data description file.\n\n* SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n* MSSubClass: The building class\n* MSZoning: The general zoning classification\n* LotFrontage: Linear feet of street connected to property\n* LotArea: Lot size in square feet\n* Street: Type of road access\n* Alley: Type of alley access\n* LotShape: General shape of property\n* LandContour: Flatness of the property\n* Utilities: Type of utilities available\n* LotConfig: Lot configuration\n* LandSlope: Slope of property\n* Neighborhood: Physical locations within Ames city limits\n* Condition1: Proximity to main road or railroad\n* Condition2: Proximity to main road or railroad (if a second is present)\n* BldgType: Type of dwelling\n* HouseStyle: Style of dwelling\n* OverallQual: Overall material and finish quality\n* OverallCond: Overall condition rating\n* YearBuilt: Original construction date\n* YearRemodAdd: Remodel date\n* RoofStyle: Type of roof\n* RoofMatl: Roof material\n* Exterior1st: Exterior covering on house\n* Exterior2nd: Exterior covering on house (if more than one material)\n* MasVnrType: Masonry veneer type\n* MasVnrArea: Masonry veneer area in square feet\n* ExterQual: Exterior material quality\n* ExterCond: Present condition of the material on the exterior\n* Foundation: Type of foundation\n* BsmtQual: Height of the basement\n* BsmtCond: General condition of the basement\n* BsmtExposure: Walkout or garden level basement walls\n* BsmtFinType1: Quality of basement finished area\n* BsmtFinSF1: Type 1 finished square feet\n* BsmtFinType2: Quality of second finished area (if present)\n* BsmtFinSF2: Type 2 finished square feet\n* BsmtUnfSF: Unfinished square feet of basement area\n* TotalBsmtSF: Total square feet of basement area\n* Heating: Type of heating\n* HeatingQC: Heating quality and condition\n* CentralAir: Central air conditioning\n* Electrical: Electrical system\n* 1stFlrSF: First Floor square feet\n* 2ndFlrSF: Second floor square feet\n* LowQualFinSF: Low quality finished square feet (all floors)\n* GrLivArea: Above grade (ground) living area square feet\n* BsmtFullBath: Basement full bathrooms\n* BsmtHalfBath: Basement half bathrooms\n* FullBath: Full bathrooms above grade\n* HalfBath: Half baths above grade\n* Bedroom: Number of bedrooms above basement level\n* Kitchen: Number of kitchens\n* KitchenQual: Kitchen quality\n* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n* Functional: Home functionality rating\n* Fireplaces: Number of fireplaces\n* FireplaceQu: Fireplace quality\n* GarageType: Garage location\n* GarageYrBlt: Year garage was built\n* GarageFinish: Interior finish of the garage\n* GarageCars: Size of garage in car capacity\n* GarageArea: Size of garage in square feet\n* GarageQual: Garage quality\n* GarageCond: Garage condition\n* PavedDrive: Paved driveway\n* WoodDeckSF: Wood deck area in square feet\n* OpenPorchSF: Open porch area in square feet\n* EnclosedPorch: Enclosed porch area in square feet\n* 3SsnPorch: Three season porch area in square feet\n* ScreenPorch: Screen porch area in square feet\n* PoolArea: Pool area in square feet\n* PoolQC: Pool quality\n* Fence: Fence quality\n* MiscFeature: Miscellaneous feature not covered in other categories\n* MiscVal: $Value of miscellaneous feature\n* MoSold: Month Sold\n* YrSold: Year Sold\n* SaleType: Type of sale\n* SaleCondition: Condition of sale","c7c48fbc":"Important page for research\nhttps:\/\/www.fortunebuilders.com\/things-to-consider-when-buying-a-home\/\nThis page about selection house","98a377de":"Competition Description\n![image.png](https:\/\/www.yorkpress.co.uk\/resources\/images\/11945543.jpg?display=1&htype=0&type=responsive-gallery)\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home."}}