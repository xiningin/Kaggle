{"cell_type":{"6707be34":"code","ddb3bee4":"code","8197cdbf":"code","2a0ee9a6":"code","8713b098":"code","27ff92de":"code","12042c12":"code","4d5458f6":"markdown"},"source":{"6707be34":"from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold","ddb3bee4":"SEED = 42","8197cdbf":"class UnionFind():\n    def __init__(self, n):\n        self.n = n\n        self.parents = [-1] * n\n\n    def find(self, x):\n        if self.parents[x] < 0:\n            return x\n        else:\n            self.parents[x] = self.find(self.parents[x])\n            return self.parents[x]\n\n    def union(self, x, y):\n        x = self.find(x)\n        y = self.find(y)\n        if x == y:\n            return\n        if self.parents[x] > self.parents[y]:\n            x, y = y, x\n        self.parents[x] += self.parents[y]\n        self.parents[y] = x\n\n\ndef get_group_unionfind(train: pd.DataFrame):\n    less_unique_text = train['less_toxic'].unique()\n    more_unique_text = train['more_toxic'].unique()\n    unique_text = np.hstack([less_unique_text, more_unique_text])\n    unique_text = np.unique(unique_text).tolist()    \n    text2num = {text: i for i, text in enumerate(unique_text)}\n    num2text = {num: text for text, num in text2num.items()}\n    train['num_less_toxic'] = train['less_toxic'].map(text2num)\n    train['num_more_toxic'] = train['more_toxic'].map(text2num)\n\n    uf = UnionFind(len(unique_text))\n    for seq1, seq2 in train[['num_less_toxic', 'num_more_toxic']].to_numpy():\n        uf.union(seq1, seq2)\n\n    text2group = {num2text[i]: uf.find(i) for i in range(len(unique_text))}\n    train['group'] = train['less_toxic'].map(text2group)\n    train = train.drop(columns=['num_less_toxic', 'num_more_toxic'])\n    return train","2a0ee9a6":"train = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")","8713b098":"train = train.sample(frac=1, random_state=SEED)","27ff92de":"%%time\n###GET GROUP!###\ntrain = get_group_unionfind(train)","12042c12":"group_kfold = GroupKFold(n_splits=5)\nfor fold, (trn_idx, val_idx) in enumerate(group_kfold.split(train, train, train['group'])): \n    train.loc[val_idx , \"fold\"] = fold\n\ntrain[\"fold\"] = train[\"fold\"].astype(int)\ntrain.to_csv('train_noleak.csv', index=False)\ndisplay(train)","4d5458f6":"This notebook is a reproducible version of [columbia2131](https:\/\/www.kaggle.com\/columbia2131)'s leak-free CV strategy.  \nI found [original code](https:\/\/www.kaggle.com\/columbia2131\/jigsaw-cv-strategy-by-union-find) cannot reproduce to split data into folds due to usage of `set()`  \nFor reproducibility, I would like to use `pd.Series.unique()` and `np.unique()` instead in this notebook.\n\nReference (the original authors):\n* https:\/\/www.kaggle.com\/columbia2131\/jigsaw-cv-strategy-by-union-find\n* https:\/\/www.kaggle.com\/its7171\/jigsaw-cv-strategy"}}