{"cell_type":{"47d4d817":"code","fce93f80":"code","0dd2b192":"code","de56f772":"code","057c6ff3":"code","e22b599e":"code","e5ecef0c":"code","cb31272e":"code","a427c018":"code","07340bb3":"code","4e9d1c22":"code","52e6d677":"code","adc4ee99":"code","4ff17d40":"code","aac11b0b":"code","cd1c1e33":"code","92f6f250":"code","c70a98fe":"code","aef3b6dd":"code","265706c2":"code","17698cec":"code","79ad57dd":"code","74d94e3c":"code","89522a69":"code","0b6066e2":"code","fe0a7479":"code","d67ee74c":"code","f1180356":"code","57222ac2":"code","7d169859":"code","baac4e27":"code","ae8303e4":"code","19e1ad1f":"code","a9d2e5e1":"markdown","9cede4c6":"markdown","c23f0277":"markdown","cb60a47c":"markdown","69fbc4ce":"markdown","992bcf04":"markdown","c1bdf6e6":"markdown","6e8e5477":"markdown","cbbc857e":"markdown","f43d3755":"markdown"},"source":{"47d4d817":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nos.chdir('\/kaggle\/input\/jane-street-market-prediction\/')\nimport janestreet\nos.chdir('\/kaggle\/working')\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport shap\nimport tqdm","fce93f80":"sample_prediction_df = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/example_sample_submission.csv', encoding = 'utf-8-sig')\nfeatures = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/features.csv', encoding = 'utf-8-sig')\ntest_data = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/example_test.csv', encoding = 'utf-8-sig')\ntrain_data = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv', encoding = 'utf-8-sig')","0dd2b192":"print(train_data.shape)\ntrain_data.head()","de56f772":"print(features.shape)\nfeatures.head()","057c6ff3":"print(test_data.shape)\ntest_data.head()","e22b599e":"print(sample_prediction_df.shape)\nsample_prediction_df.head()","e5ecef0c":"train_data.describe()","cb31272e":"print('Number of rows in data:', train_data.shape[0])\ncolumns_in_train_data_nan = pd.DataFrame(train_data.isna().sum()).rename(columns = {0:'Number of NaNs'}).sort_values(by = ['Number of NaNs'], ascending = False)\ncolumns_in_train_data_nan['% NaNs'] = (columns_in_train_data_nan['Number of NaNs']\/train_data.shape[0]) * 100\ncolumns_in_train_data_nan[columns_in_train_data_nan['Number of NaNs']>100000]","a427c018":"# Fill NaNs with mean of column:\ntrain_data.fillna(train_data.mean(), inplace = True)","07340bb3":"pd.DataFrame(train_data['date'].unique()).describe().rename(columns = {0:'Number of days'})","4e9d1c22":"print('Number of rows with weight 0:',train_data[train_data['weight']==0].shape[0])\nprint('Number of rows with weight non-zero:',train_data[train_data['weight']!=0].shape[0])","52e6d677":"features[features==True].count(axis = 1).plot()","adc4ee99":"train_data.groupby(['date']).size().reset_index().rename(columns = {0: '# Trades in a day'}).plot('date','# Trades in a day', title = 'Trades in a day [1-500]')","4ff17d40":"# Correlation analysis from <https:\/\/www.kaggle.com\/isaienkov\/jane-street-market-prediction-fast-understanding>\n\n# Correlation\ncorr_high_columns = []\ncols = train_data.columns.tolist()\nfor i in range(0, len(cols)):\n    for j in range(i+1, len(cols)):\n        if abs(train_data[cols[i]].corr(train_data[cols[j]])) > 0.95:\n            corr_high_columns = corr_high_columns + [cols[i], cols[j]]","aac11b0b":"corr_high_columns = list(set(corr_high_columns))\nprint('Number of columns:', len(corr_high_columns))","cd1c1e33":"corr_high_columns","92f6f250":"#Correlation matrix\nf = plt.figure(\n    figsize=(22, 22)\n)\n\nplt.matshow(\n    train_data[corr_high_columns].corr(), \n    fignum=f.number\n)\n\nplt.title('Correlation matrix - for corr above 0.9')\nplt.xticks(\n    range(train_data[corr_high_columns].shape[1]), \n    train_data[corr_high_columns].columns, \n    fontsize=14, \n    rotation=90\n)\n\nplt.yticks(\n    range(train_data[corr_high_columns].shape[1]), \n    train_data[corr_high_columns].columns, \n    fontsize=14\n)\n\ncb = plt.colorbar()\ncb.ax.tick_params(\n    labelsize=14\n)","c70a98fe":"#Action metric created using: <https:\/\/www.kaggle.com\/hamditarek\/market-prediction-xgboost-with-gpu-fit-in-1min>\n# Create action metric\n# train_data['action'] = ((train_data['weight'].values * train_data['resp'].values) > 0).astype('int')\ntrain_data['action'] = ((train_data['weight'].values * (train_data['resp_1'] + train_data['resp_2'] + train_data['resp_3'] + train_data['resp_4']).values)\/4 > 0).astype('int')\n\ntrain_data_for_model = train_data[train_data['weight'] != 0]\n# train_data_for_model = train_data.copy(deep = True)\n\nX_train = train_data_for_model.loc[:, train_data_for_model.columns.str.contains('feature')]\ny_train = train_data_for_model.loc[:, 'action']","aef3b6dd":"print(X_train.shape)\nX_train.head()","265706c2":"print(y_train.shape)\nprint(y_train.sum())\ny_train.head()","17698cec":"del columns_in_train_data_nan, train_data, features, test_data, train_data_for_model, corr_high_columns","79ad57dd":"import gc\ngc.collect()","74d94e3c":"features = [c for c in X_train.columns if 'feature' in c]","89522a69":"clf = xgb.XGBClassifier(use_label_encoder=False,\n    n_estimators=1000,\n    max_depth=10,\n    learning_rate=0.06,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    random_state=42,\n    tree_method='gpu_hist'  # Treats numerical variable as bins (makes process much faster)\n)","0b6066e2":"%time clf.fit(X_train[features], y_train)","fe0a7479":"import pickle\npickle.dump(clf, open('Jane_Street_forecasting_weight_xgboost_model_v1.sav','wb'))","d67ee74c":"# filename = '..\/input\/jane-street-pred-model-weights\/Jane_Street_forecasting_weight_xgboost_model_v1.sav'\n# clf = pickle.load(open(filename, 'rb'))","f1180356":"def normalize_data(df):\n#     return (df-df.min())\/(df.max()-df.min())\n      return (df-df.mean())\/df.std()\n    \ndf_train = normalize_data(X_train[features])","57222ac2":"# import tensorflow as tf\n# from keras.layers import Activation, Dense\n\n# model = tf.keras.models.Sequential()\n\n# model.add(tf.keras.layers.LSTM(\n#     len(features), \n#     activation='relu', \n#     input_shape=(1, len(features)), \n#     return_sequences=True))\n\n# model.add(tf.keras.layers.Dropout(0.02))\n\n# model.add(Dense(50, activation='swish',input_shape=(len(features), )))\n\n# model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n\n# model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n#                 optimizer=tf.optimizers.Adam(learning_rate=0.05),\n#                 metrics=[\"accuracy\"])\n# model.summary()","7d169859":"# from tensorflow.keras.callbacks import EarlyStopping\n# model.fit(df_train,\n#             epochs = 1,\n#             batch_size = 10000,\n#             verbose = 1,\n#             callbacks = [EarlyStopping(monitor='loss', verbose=1, patience=10)])","baac4e27":"# plot feature importance using built-in function\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom matplotlib import pyplot\nfig, ax = plt.subplots(figsize=(20,30))\nplot_importance(clf, ax = ax)\npyplot.show()","ae8303e4":"#SHAP plots\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(clf)\n\ndf = X_train.sample(n=1000)\n# calculate shap values. This is what we will plot.\nshap_values = explainer.shap_values(df)\n\n# Make plot\nshap.summary_plot(shap_values, df)","19e1ad1f":"env = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\n# count = 0\nfor (test_df, sample_prediction_df) in iter_test:\n    if test_df['weight'].item() > 0:\n        X_test = test_df.loc[:, features]\n        X_test = X_test.fillna(0)\n#         print(X_test.shape)\n        y_preds = clf.predict(X_test)\n        sample_prediction_df.action = y_preds.astype(int)\n    else:\n        sample_prediction_df.action = 0\n    env.predict(sample_prediction_df)","a9d2e5e1":"The data contains 500 days for trading","9cede4c6":"## Import packages","c23f0277":"## Feature importance","cb60a47c":"## EDA","69fbc4ce":"feature_0 is the only feature without any true tag","992bcf04":"## Load data files","c1bdf6e6":"## Prediction","6e8e5477":"Features 39, 64 & 20 strictly increase the action probability. The other features may be dependent on each other. Dimensionality reduction is required to train a better model.","cbbc857e":"## Modelling","f43d3755":"Trades with weight = 0 were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation"}}