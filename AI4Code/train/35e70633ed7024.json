{"cell_type":{"1279553a":"code","b0a63165":"code","27bd7a32":"code","ab9e53e6":"code","efc675ed":"code","ec907ed1":"code","31b07e67":"code","ab15e775":"code","fec0104c":"code","2c2c7882":"code","da3e123f":"code","3d423351":"code","4b80a5d4":"code","1479c2c2":"code","d3c8d544":"code","86d210e0":"code","a10ba8e0":"code","b33cb0b8":"code","6ec32a76":"code","92cf6fc0":"code","cb8c3b30":"code","38400e8c":"code","e8a1e08a":"code","f25c3ccd":"code","677e609e":"code","efbcb28d":"markdown","aad00922":"markdown","53e93ecb":"markdown","b10d48c9":"markdown","f3d92947":"markdown","72d09e9f":"markdown","44088447":"markdown","ac61824c":"markdown","ed3bbf13":"markdown","9bb05496":"markdown","c18d33d3":"markdown","e770c064":"markdown"},"source":{"1279553a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b0a63165":"raw_data = pd.read_csv('..\/input\/BlackFriday.csv')\nraw_data.head()","27bd7a32":"raw_data.info()\nprediction_data = raw_data.drop([\"User_ID\", \"Product_ID\"],axis=1)","ab9e53e6":"prediction_data = prediction_data.drop(\"Product_Category_2\", axis = 1)\nprediction_data = prediction_data.drop(\"Product_Category_3\", axis = 1)\nprediction_data.info()","efc675ed":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ntoEncode = prediction_data[\"Gender\"]\ngenderEncoded = encoder.fit_transform(toEncode)\nprediction_data[\"Gender\"] = genderEncoded\nprediction_data.head()","ec907ed1":"from sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer()\nage_1hot = encoder.fit_transform(prediction_data[\"Age\"])\nprint(encoder.classes_)\nprint(age_1hot)\n\n# Probably there's a much better way to do this\nage_1hot = age_1hot.transpose()\nfor (cat, ar) in zip(encoder.classes_, age_1hot):\n    prediction_data[cat] = ar\nprint(prediction_data.head())\nprediction_data = prediction_data.drop(\"Age\", axis=1)\nprediction_data.head()","31b07e67":"encoder = LabelEncoder()\ntoEncode = prediction_data[\"City_Category\"]\ncityEncoded = encoder.fit_transform(toEncode)\nprediction_data[\"City_Category\"] = cityEncoded\nprint(encoder.classes_)\nprediction_data.head()","ab15e775":"encoder = LabelEncoder()\ntoEncode = prediction_data[\"Stay_In_Current_City_Years\"]\nyearsEncoded = encoder.fit_transform(toEncode)\nprediction_data[\"Stay_In_Current_City_Years\"] = yearsEncoded\nprint(prediction_data.info())\nprediction_data.head()","fec0104c":"prediction_data[\"Gender\"].value_counts() \/ len(raw_data)","2c2c7882":"from sklearn.model_selection import StratifiedShuffleSplit","da3e123f":"split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(prediction_data, prediction_data[\"Gender\"]):\n    train_set = prediction_data.loc[train_index]\n    test_set = prediction_data.loc[test_index]","3d423351":"train_set[\"Gender\"].value_counts()\/len(train_set)\n","4b80a5d4":"test_set[\"Gender\"].value_counts()\/len(test_set)","1479c2c2":"corr_matrix = prediction_data.corr()\ncorr_matrix[\"Purchase\"].sort_values(ascending=False)","d3c8d544":"prediction_data.hist(bins=50,figsize=(20,15))","86d210e0":"blackFriday = train_set.drop(\"Purchase\", axis=1)\nblackFridayLabels = train_set[\"Purchase\"].copy()","a10ba8e0":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(blackFriday, blackFridayLabels)","b33cb0b8":"some_data = blackFriday.iloc[:10]\nsome_labels = blackFridayLabels.iloc[:10]\nprint(\"Predictions:\\t\",lin_reg.predict(some_data))\nprint(\"Labels:\\t\", list(some_labels))","6ec32a76":"from sklearn.metrics import mean_squared_error\npredictions = lin_reg.predict(some_data)\nlin_mse = mean_squared_error(predictions, some_labels)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","92cf6fc0":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(lin_reg, blackFriday, blackFridayLabels, \n                         scoring = \"neg_mean_squared_error\", cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(\"\\nScores: \", rmse_scores, \"\\nMean: \", rmse_scores.mean()\n     ,\"\\nStd Deviation: \" , rmse_scores.std())","cb8c3b30":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor(n_estimators=10)\nscores_forest = cross_val_score (forest_reg, blackFriday, \n                                 blackFridayLabels,\n                                 scoring = \"neg_mean_squared_error\",\n                                 cv=10)\nrmse_scores_forest = np.sqrt(-scores_forest)","38400e8c":"print(\"\\nScores: \", rmse_scores_forest, \"\\nMean: \", rmse_scores_forest.mean()\n     ,\"\\nStd Deviation: \" , rmse_scores_forest.std())","e8a1e08a":"forest_reg.fit(blackFriday, blackFridayLabels)","f25c3ccd":"test_x = test_set.drop(\"Purchase\", axis=1)\ntest_labels = test_set[\"Purchase\"].copy()\n","677e609e":"final_predictions = forest_reg.predict(test_x)\nfinal_mse = mean_squared_error(test_labels, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nprint(\"Final RMSE: \", final_rmse)","efbcb28d":"I drop the labels from the train set to try the first model: Linear Regression","aad00922":"Seems like men love this store, so I use stratified sampling to get a more representative train \/ test sets of the population. \nProbably the error wouldn't have been too much either, but the book I mentioned before explains this and I wanted to try.","53e93ecb":"I try Random Forest with Cross-Validation, it takes a while to train and test ","b10d48c9":"To see validate the model I use Cross-Validation","f3d92947":"Quick look at the correlation matrix and histograms","72d09e9f":"I decided to go with this model, but I know that I should try many of them with many hyperparameters","44088447":"This is my first attempt to train and test a model, I would appreciate a lot to have some feedback so I can improve.\nI'm following [this book](http:\/\/shop.oreilly.com\/product\/0636920052289.do).","ac61824c":"Gender and age are String categories so I encode them:\n* Gender [F,M] -> [0,1]\n* Age: ['0-17' '18-25' '26-35' '36-45' '46-50' '51-55' '55+'] I use one hot encoding for this one.\n* City Category: ['A' 'B' 'C'] -> [0, 1, 2]\n* Stay in current city years: ['0', '1', '2', '3' , '4+'] -> [0, 1, 2, 3, 4] \n","ed3bbf13":"Product category 1 and 2 seem to be missing lot of data so I drop them as well.","9bb05496":"I think User_ID and Product_ID are not relevant so I drop them.","c18d33d3":"Every feature is numerical now so I explore a bit","e770c064":"I try against the test set, and the final RMSE is: 2957"}}