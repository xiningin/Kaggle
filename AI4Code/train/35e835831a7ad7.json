{"cell_type":{"aed68a59":"code","700c2c0e":"code","e61f46b6":"code","cbef7f32":"code","1215c8ad":"code","3da4e789":"code","01508f5e":"code","4f45faa1":"code","bb5558d6":"code","6398767e":"code","6a07edec":"code","4baefa05":"code","432a8a9c":"code","fa40751a":"code","8ebf6cd1":"code","548b8227":"code","e27cf0bb":"code","5fcb3c2b":"code","66f5ab33":"code","3b62c60f":"code","c01d71d5":"code","0dc65abe":"code","6936e7a7":"code","c4cef60b":"code","eb991aa7":"code","c276bd31":"code","67ed2089":"code","fe1fbb2b":"code","86af40bd":"code","7829f5d0":"code","2b166900":"code","568fb8c3":"code","7d89ceeb":"code","34b3db9b":"code","fc8407a0":"code","ce19f18a":"code","c0b3b807":"code","c4c1f719":"code","96a726fd":"code","f1311c1b":"code","6f33f45c":"code","a46cbe52":"code","289e3ad0":"code","0fa77e49":"code","3c9e5702":"code","51c84794":"code","4dbc00c3":"code","9c119ad1":"code","6a7708c8":"code","96727d97":"code","a33bb4c1":"code","54896cf4":"code","2c1e4565":"code","cf44f0a6":"code","b3f926c6":"code","2ba42f2d":"code","4b5eb2a5":"code","3ad8b46b":"code","10d109e7":"code","67900f29":"code","db123933":"code","e20855f2":"code","7051a4a3":"code","457f5607":"code","30b64ffa":"code","d91d9b6a":"code","a389e461":"code","55e903bb":"code","8fe8b1d8":"code","16bfcaf9":"code","28810bd4":"code","88bb8e33":"code","59380d9a":"code","36c3eb83":"code","8ec6a844":"code","33ca39d2":"code","985cce19":"code","80b4d363":"code","5a0f3c05":"code","5053ff6a":"code","c09e9ec7":"code","2a459135":"code","104e38fa":"code","46a66819":"code","9557a056":"code","9b8a91aa":"code","1cb7fc70":"code","21440702":"code","dd2f65bf":"code","c6460fd4":"code","7521261b":"code","d2b8979a":"code","04282c55":"code","663f48c1":"code","37ff45cc":"code","d9525a3e":"code","77ca4459":"code","d3e5a0cb":"code","d098a36f":"code","0452982d":"code","3c13eb57":"code","043dc43f":"code","7790dbe1":"code","73cb29fb":"code","175771b4":"code","85e7e300":"code","a6e8fbaf":"code","08321dcf":"markdown","6002c84f":"markdown","dd0653aa":"markdown","b264c279":"markdown","f81ba2bd":"markdown","86d0457e":"markdown","01523f14":"markdown","88b97016":"markdown"},"source":{"aed68a59":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\n","700c2c0e":"csv_file='..\/input\/breast-cancer-prediction-dataset\/Breast_cancer_data.csv'\ndata_df=pd.read_csv(csv_file)\ndata_df","e61f46b6":"data_df.shape\n","cbef7f32":"data_df[\"diagnosis\"].value_counts()","1215c8ad":"data_df.isnull().sum()","3da4e789":"data_df.dtypes","01508f5e":"plt.hist(data_df['mean_area'])","4f45faa1":"plt.hist(data_df['mean_radius'])","bb5558d6":"plt.hist(data_df['mean_texture'])","6398767e":"plt.hist(data_df['mean_perimeter'])","6a07edec":"plt.hist(data_df['mean_smoothness'])","4baefa05":"sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_radius'],hue=data_df['diagnosis'])","432a8a9c":"sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_smoothness'],hue=data_df['diagnosis'])","fa40751a":"sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_perimeter'],hue=data_df['diagnosis'])","8ebf6cd1":"sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_texture'],hue=data_df['diagnosis'])","548b8227":"sns.scatterplot(x=data_df['mean_smoothness'],y=data_df['mean_texture'],hue=data_df['diagnosis'])","e27cf0bb":"data_df.corr()","5fcb3c2b":"sns.pairplot(data_df,hue='diagnosis')","66f5ab33":"x= data_df.drop('diagnosis',1)\nx","3b62c60f":"y= data_df['diagnosis']","c01d71d5":"from sklearn.model_selection import train_test_split","0dc65abe":"X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.2,random_state=10)","6936e7a7":"X_train","c4cef60b":"X_test","eb991aa7":"Y_test","c276bd31":"Y_train","67ed2089":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score, PrecisionRecallDisplay, precision_score, recall_score,f1_score\nfrom sklearn.metrics import confusion_matrix, classification_report","fe1fbb2b":"scaler = StandardScaler()\nX_train_scale = scaler.fit_transform(X_train)\nX_test_scale = scaler.transform(X_test)\nlogit_model = LogisticRegression()\nlogit_model.fit(X_train_scale,Y_train)\nX_pred = logit_model.predict(X_test_scale)\nlogit_model.score(X_test_scale,Y_test)","86af40bd":"confusion_matrix(X_pred,Y_test)","7829f5d0":"accuracy_score(X_pred,Y_test)","2b166900":"MinMaxscaler = MinMaxScaler()\nX_train_scale = MinMaxscaler.fit_transform(X_train)\nX_test_scale = MinMaxscaler.transform(X_test)\nlogit_model = LogisticRegression()\nlogit_model.fit(X_train_scale,Y_train)\nY_pred = logit_model.predict(X_test_scale)\nlogit_model.score(X_test_scale,Y_test)","568fb8c3":"logit_confusion = confusion_matrix(Y_test,Y_pred)","7d89ceeb":"logit_confusion","34b3db9b":"precision_score(Y_test,Y_pred)","fc8407a0":"recall_score(Y_test,Y_pred)","ce19f18a":"f1_score(Y_test,Y_pred)","c0b3b807":"from sklearn.ensemble import RandomForestClassifier","c4c1f719":"\n\nforest_model_test = RandomForestClassifier(max_depth=40,random_state=42)\nforest_model_test.fit(X_train,Y_train)\nY_random_model_test =forest_model_test.predict(X_test)\n\n","96a726fd":"forest_param = {'n_estimators':[500,700,1000],'max_depth':[10,20,40,70]}\nforest_Gridsearch = GridSearchCV(estimator=forest_model_test,param_grid=forest_param,cv=10,scoring='f1',n_jobs=-1)\nforest_Gridsearch.fit(X_train,Y_train)","f1311c1b":"forest_Gridsearch.best_params_","6f33f45c":"forest_model_best= RandomForestClassifier(n_estimators=700,max_depth=10)\n","a46cbe52":"forest_model_best.fit(X_train,Y_train)","289e3ad0":"Y_random_model =forest_model_best.predict(X_test)","0fa77e49":"forest_confusion = confusion_matrix(Y_random_model,Y_test)","3c9e5702":"forest_confusion","51c84794":"forest_model_best.score(X_test,Y_test)","4dbc00c3":"precision_score(Y_test,Y_random_model)\n","9c119ad1":"recall_score(Y_test,Y_random_model)","6a7708c8":"False_negetive_rate_Forest = forest_confusion[1][0]\/(forest_confusion[1][0]+forest_confusion[1][1])","96727d97":"False_negetive_rate_Forest*100","a33bb4c1":"from sklearn.neighbors import KNeighborsClassifier","54896cf4":"KNN_model =   KNeighborsClassifier(n_neighbors=10)\nKNN_model.fit(X_train_scale,Y_train)\nY_KNN =KNN_model.predict(X_test_scale)\n\n  ","2c1e4565":"KNN_Confusion = confusion_matrix(Y_KNN,Y_test)","cf44f0a6":"KNN_Confusion","b3f926c6":"accuracy_score(Y_test,Y_KNN)","2ba42f2d":"recall_score(Y_test,Y_KNN)","4b5eb2a5":"precision_score(Y_test,Y_KNN)","3ad8b46b":"KNN_param = {'n_neighbors':[4,5,6,7,8,9,10,14,15,20,25],'weights':['uniform','distance']}\nKNN_Grid = GridSearchCV(estimator=KNN_model,param_grid=KNN_param,cv=10,scoring='f1',n_jobs=-1)\nKNN_Grid.fit(X_train_scale,Y_train)","10d109e7":"KNN_Grid.best_params_","67900f29":"KNN_Grid.best_score_","db123933":"KNN_model_best = KNeighborsClassifier(n_neighbors=14,weights='distance')","e20855f2":"KNN_model_best.fit(X_train_scale,Y_train)","7051a4a3":"Y_KNN_best = KNN_model_best.predict(X_test_scale)","457f5607":"KNN_CM= confusion_matrix(Y_test,Y_KNN_best)","30b64ffa":"KNN_CM","d91d9b6a":"precision_score(Y_test,Y_KNN_best)","a389e461":"recall_score(Y_test,Y_KNN_best)","55e903bb":"f1_score(Y_test,Y_pred)","8fe8b1d8":"False_negetive_rate_KNN = KNN_CM[1][0]\/(KNN_CM[1][0]+KNN_CM[1][1])","16bfcaf9":"False_negetive_rate_KNN*100","28810bd4":"from sklearn.tree import DecisionTreeClassifier","88bb8e33":"\nTree_model_test = DecisionTreeClassifier(max_depth = 10)\nTree_model_test.fit(X_train,Y_train)\nY_tree_test = Tree_model_test.predict(X_test)\n","59380d9a":"confusion_matrix(Y_test,Y_tree_test)","36c3eb83":"Tree_param = {'max_depth':[50,70,20,10],'min_samples_split':[2,4,8],'min_samples_leaf':[2,4,8]}\nTree_search = GridSearchCV(estimator=Tree_model_test,cv=10,scoring='f1',n_jobs=-1,param_grid=Tree_param)","8ec6a844":"Tree_search.fit(X_train,Y_train)","33ca39d2":"Tree_search.best_params_","985cce19":"Tree_model = RandomForestClassifier(max_depth=70,min_samples_leaf=8,min_samples_split=4)","80b4d363":"Tree_model.fit(X_train,Y_train)","5a0f3c05":"Y_tree= Tree_model.predict(X_test)","5053ff6a":"Tree_model.score(X_test,Y_test)","c09e9ec7":"\nTree_confusion = confusion_matrix(Y_test,Y_tree)","2a459135":"Tree_confusion","104e38fa":"accuracy_score(Y_test,Y_tree)","46a66819":"precision_score(Y_test,Y_tree)","9557a056":"recall_score(Y_test,Y_tree)","9b8a91aa":"False_negetive_rate_Tree = Tree_confusion[1][0]\/(Tree_confusion[1][0]+Tree_confusion[1][1])","1cb7fc70":"False_negetive_rate_Tree*100\n","21440702":"from sklearn.svm import SVC\n","dd2f65bf":"SVM_model = SVC(C=100, kernel='linear')\nSVM_model.fit(X_train_scale,Y_train)","c6460fd4":"Y_SVM = SVM_model.predict(X_test_scale)","7521261b":"confusion_matrix(Y_test,Y_SVM)","d2b8979a":"accuracy_score(Y_test,Y_SVM)","04282c55":"recall_score(Y_test,Y_SVM)","663f48c1":"precision_score(Y_test,Y_SVM)","37ff45cc":"SVM_param = [{\"C\":[1,10,100,1000],'kernel':['linear']},{\"C\":[1,10,100,1000],'kernel':['rbf','sigmoid'],'gamma':[0.1,1,10]}]\ngrid_SVM = GridSearchCV(estimator=SVM_model, param_grid=SVM_param,cv=10,scoring=\"f1\", n_jobs=-1)","d9525a3e":"grid_SVM.fit(X_train_scale,Y_train)","77ca4459":"grid_SVM.best_score_","d3e5a0cb":"grid_SVM.best_params_","d098a36f":"SVM_model_best = SVC(C=100,kernel='rbf',gamma=10)","0452982d":"SVM_model_best.fit(X_train_scale,Y_train)","3c13eb57":"Y_SVM_best = SVM_model_best.predict(X_test_scale)","043dc43f":"SVM_CM= confusion_matrix(Y_test,Y_SVM_best)","7790dbe1":"accuracy_score(Y_test,Y_SVM_best)","73cb29fb":"recall_score(Y_test,Y_SVM_best)","175771b4":"precision_score(Y_test,Y_SVM_best)","85e7e300":"False_negetive_rate = SVM_CM[1][0]\/(SVM_CM[1][0]+SVM_CM[1][1])","a6e8fbaf":"False_negetive_rate*100","08321dcf":"##Random Forest ","6002c84f":"# SVM","dd0653aa":"Mean Radius, Mean Perimeter and Mean Area are highly correlated.","b264c279":"# **K** Nearest Neighbour ","f81ba2bd":"\n>**Introduction:\nWe have the breast cancer data set to predict if a cancer is malignant or not. In this dataset, I stated with some exploratory data analysis. Then I used classification models, Logistic Regression, KNN, Random Forest and Decision Tree to classify the data. I also hypertuned the model to get better results.\n******","86d0457e":"\n```\n\n## **Logistic Regression**","01523f14":"Conclusion\n- Five classification models, Logistic Regression, KNN, SVM, RF and Decison Tree were used to clasify the data. \n\n- Hypertuning was done to get the best result \n\n- Variables were scaled for KNN, SVM, Logitic Regresion model. The Tree model doe not need to be scaled as no distance is calculated for those model\n\n- Each model provides high accuracy with logitic Regreion being the lowest with 88% and all the other model provide an accuracy of more than 90% \n\n- As the model predicts cancer, false negetive rate is more important than accuracy. False negetive rate is FN\/(FN+TP). \n\n- Decision Tree model with hypertuning provides the best False Negetive rate at 4%\n","88b97016":"# **Decision Tree**"}}