{"cell_type":{"3da22219":"code","e9b42b31":"code","a17d5681":"code","5f63864f":"code","a836b8d3":"code","c363e5c6":"code","e91a55c7":"code","396ea90c":"code","b383fa5d":"code","51c9672f":"code","23ee088d":"code","3798a7d5":"code","dbfcc990":"code","0ad5b180":"code","1f676cd4":"code","8c7b510b":"code","5f1b7642":"code","99fb38b5":"markdown","59cfee7f":"markdown","2e991ed2":"markdown"},"source":{"3da22219":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras\nimport sys\nfrom matplotlib import pyplot\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation\nimport tensorflow\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport numpy as np\n\n","e9b42b31":"def define_model():\n    # load model\n    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n    # mark loaded layers as not trainable\n    for layer in model.layers:\n        layer.trainable = False\n    # add new classifier layers\n    flat1 = Flatten()(model.layers[-1].output)\n    class1 = Dense(1024, activation='relu', kernel_initializer='he_uniform')(flat1)\n    output = Dense(166, activation='softmax')(class1)\n    # define new model\n    model = Model(inputs=model.inputs, outputs=output)\n    # compile model\n    opt = SGD(lr=0.01)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","a17d5681":"''' For saving .png image for history of plots. '''\n\ndef summarize_diagnostics(history):\n\t# plot loss\n\tpyplot.subplot(211)\n\tpyplot.title('Cross Entropy Loss')\n\tpyplot.plot(history.history['loss'], color='blue', label='train')\n\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n\t# plot accuracy\n\tpyplot.subplot(212)\n\tpyplot.title('Classification Accuracy')\n\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n\t# save plot to file\n\tfilename = sys.argv[0].split('\/')[-1]\n\tpyplot.savefig(filename + '_plot.png')\n\tpyplot.close()","5f63864f":"train_datagen = ImageDataGenerator(rescale=1.0\/255.0)\ntest_datagen = ImageDataGenerator(rescale=1.0\/255.0)\n# # specify imagenet mean values for centering\n# train_datagen.mean = [123.68, 116.779, 103.939]\n# test_datagen.mean = [123.68, 116.779, 103.939]\n\n# prepare iterator\ntrain_it = train_datagen.flow_from_directory('\/kaggle\/input\/pokemonimagedataset\/dataset\/train\/',\n    class_mode='categorical', batch_size=64, target_size=(224, 224))\ntest_it = test_datagen.flow_from_directory('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/',\n    class_mode='categorical', batch_size=32, target_size=(224, 224))","a836b8d3":"model = define_model()\nmodel.summary()\n","c363e5c6":"''' Fitting the model '''\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n        validation_data=test_it, validation_steps=len(test_it), epochs=5, verbose=1)\n\n# evaluating model\n_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\nprint('> %.3f' % (acc * 100.0))\nmodel.save('VGG16_accuracy - %.3f' % (acc * 100.0) + '.h5')\n\n# learning curves\nsummarize_diagnostics(history)\n","e91a55c7":"''' Loading the above model after fitting '''\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf\n\nloadedModel = load_model('\/kaggle\/input\/accuracy-55530h5\/accuracy - 55.530.h5')\n","396ea90c":"allClasses = train_it.class_indices\nprint(\"Total Classes: \" + str(len(list(allClasses))))","b383fa5d":"''' Testing the trained VGG16 model on test dataset '''\n\n\nimport cv2, os\n\nperc = []\nfor pokemon in os.listdir('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/'):\n    count = 0\n    wrongCount = 0\n    # Taking Onix as an example Pokemon\n    if(pokemon == 'Onix'):    \n        for i in os.listdir('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/'+ pokemon + '\/'):\n            img = cv2.imread('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/'+ pokemon + '\/' +  i)\n            img = cv2.resize(img, (224, 224))\n            pred = loadedModel.predict(np.array([img]))\n            move_code = np.argmax(pred[0])\n            predictedPokemon = list(allClasses.keys())[list(allClasses.values()).index(move_code)]\n            if(predictedPokemon == pokemon):\n                count+=1\n            else:\n                wrongCount+=1\n#             print(str(move_code) + '  ' +  str(predictedPokemon))\n        print(\"Correct prediction : \", count)\n        print(\"Wrong  prediction : \", wrongCount)\n        print('Percentage: ' + str( (count\/(wrongCount+count))*100) + ', For ' + pokemon)\n        perc.append((count\/(wrongCount+count))*100)\n","51c9672f":"from tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n","23ee088d":"base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dropout(0.2)(x)\n# x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n# x=Dense(512,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n# x=Dropout(0.2)(x)\nx=Dense(256,activation='tanh')(x) #dense layer 2\n# x=Dense(256,activation='tanh')(x)\n#dense layer 3\npreds=Dense(166,activation='softmax')(x) #final layer with softmax activation\n","3798a7d5":"Testmodel=Model(inputs=base_model.input,outputs=preds)\nTestmodel.summary()","dbfcc990":"for layer in Testmodel.layers[:20]:\n    layer.trainable=False\nfor layer in Testmodel.layers[20:]:\n    layer.trainable=True\nTestmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","0ad5b180":"test_datagen = ImageDataGenerator(rescale=1.0\/255.0)\n# # specify imagenet mean values for centering\n# train_datagen.mean = [123.68, 116.779, 103.939]\n# test_datagen.mean = [123.68, 116.779, 103.939]\n\n\ntrain_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n\ntrain_generator=train_datagen.flow_from_directory('\/kaggle\/input\/pokemonimagedataset\/dataset\/train\/', # this is where you specify the path to the main data folder\n                                                 target_size=(100,100),\n                                                 color_mode='rgb',\n                                                 batch_size=100,\n                                                 class_mode='categorical',\n                                                 shuffle=True)\ntest_it = test_datagen.flow_from_directory('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/',\n    class_mode='categorical', batch_size=50, target_size=(100, 100))","1f676cd4":"# history = Testmodel.fit_generator(train_generator, steps_per_epoch=len(train_generator),\n#         validation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n# # evaluate model\n# _, acc = Testmodel.evaluate_generator(test_it, steps=len(test_it), verbose=1)\n# print('> %.3f' % (acc * 100.0))\n# Testmodel.save('MobileNet_accuracy - %.3f' % (acc * 100.0) + '.h5')\n# # learning curves\n# summarize_diagnostics(history)","8c7b510b":"''' Loading the above model after fitting '''\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf\n\nTestmodel = load_model('\/kaggle\/input\/mobilenetmodel\/MobileNet-63.237.h5')","5f1b7642":"''' Testing the trained MobileNet model on test dataset '''\n\n\nimport cv2, os\n\nperc = []\nfor pokemon in os.listdir('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/'):\n    count = 0\n    wrongCount = 0\n    # Taking Caterpie as an example Pokemon\n    if(pokemon == 'Caterpie'):    \n        for i in os.listdir('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/'+ pokemon + '\/'):\n            img = cv2.imread('\/kaggle\/input\/pokemonimagedataset\/dataset\/test\/'+ pokemon + '\/' +  i)\n            img = cv2.resize(img, (224, 224))\n            pred = Testmodel.predict(np.array([img]))\n            move_code = np.argmax(pred[0])\n            predictedPokemon = list(allClasses.keys())[list(allClasses.values()).index(move_code)]\n            if(predictedPokemon == pokemon):\n                count+=1\n            else:\n                wrongCount+=1\n    #             print(str(move_code) + '  ' +  str(predictedPokemon))\n        print(\"Correct prediction : \", count)\n        print(\"Wrong  prediction : \", wrongCount)\n        print('Percentage: ' + str( (count\/(wrongCount+count))*100) + ', For ' + pokemon)\n        perc.append((count\/(wrongCount+count))*100)","99fb38b5":"## 1. USING VGG16 Model","59cfee7f":"## 2. USING MOBILENET WITH TRANSFER LEARNING","2e991ed2":" ### POKEMON CLASSIFICATION USING TRANSFER LEARNING"}}