{"cell_type":{"be2fd980":"code","701a389f":"code","fb9ad39b":"code","63699222":"code","701afbb7":"code","2724e803":"code","9fcbd2f4":"code","c37afe1e":"code","7abb00e1":"code","5ef24cf0":"code","77a44ec2":"code","9a1ab5ec":"code","8aaba853":"code","2561215e":"code","cb576849":"code","06400343":"code","65aa08c6":"code","13435d5e":"code","50d3727d":"code","972f499b":"code","08d82822":"code","27f2c6a0":"code","b950ed24":"code","a71d7f93":"code","8de08e14":"code","84fdb84b":"code","7256a4e3":"markdown","56f408b0":"markdown","dd56d988":"markdown","ea24f96b":"markdown","7017e10a":"markdown","a522193e":"markdown","82cc1f41":"markdown","b12d5079":"markdown"},"source":{"be2fd980":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","701a389f":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')\ntrain.head()","fb9ad39b":"train.info()","63699222":"train.describe()","701afbb7":"train.shape","2724e803":"num=train[['Age','SibSp','Parch','Fare']]\ncat=train[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","9fcbd2f4":"for i in num:\n    sns.histplot(num[i])\n    plt.title(i)\n    plt.show()","c37afe1e":"for i in cat:\n    sns.countplot(cat[i])\n    plt.title(i)\n    plt.show()","7abb00e1":"train.isnull().sum()","5ef24cf0":"train['Age']=train.Age.fillna(train.Age.median())\ntrain['Embarked']=train.Embarked.fillna(train.Embarked.mode()[0])\ntest['Age']=test.Age.fillna(test.Age.median())\ntest['Embarked']=test.Embarked.fillna(test.Embarked.mode()[0])","77a44ec2":"x=train.Survived\ny=train.drop(['Survived'],axis='columns')","9a1ab5ec":"for i in y:\n    sns.barplot(y[i],x)\n    plt.title(i)\n    plt.show()","8aaba853":"sns.heatmap(train[['Pclass','Age','SibSp','Parch','Fare']].corr(),annot=True)","2561215e":"pd.pivot_table(train, index='Survived', values=['Pclass','Age','SibSp','Parch','Fare'])","cb576849":"train['Sex']=train.Sex.map({'male':1, 'female':2})\ntest['Sex']=test.Sex.map({'male':1,'female':2})","06400343":"train=train.drop(['Name','Cabin','Ticket','Fare','Embarked','PassengerId'],axis='columns')\ntest=test.drop(['Name','Cabin','Ticket','Fare','Embarked','PassengerId'],axis='columns')","65aa08c6":"x_train=train.drop(['Survived'],axis='columns')\ny_train=train.Survived","13435d5e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV","50d3727d":"reg=LogisticRegression()\nreg.fit(x_train,y_train)\nreg.score(x_train,y_train)","972f499b":"from sklearn.model_selection import cross_val_score","08d82822":"cross_val_score(LogisticRegression(),x_train,y_train)","27f2c6a0":"model={\n    'logic':{\n        'model':LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params':{\n            'C':[1,5,10]\n        }\n    },\n    'random':{\n        'model':RandomForestClassifier(),\n        'params':{\n            'n_estimators':[1,5,10]\n        }\n    },\n    'svm':{\n        'model':SVC(gamma='auto'),\n        'params':{\n            'C':[1,10,20],\n            'kernel':['rbf', 'linear']\n        }\n    },\n}\nscores=[]\nfor alm, i in model.items():\n    gls=GridSearchCV(i['model'],i['params'],cv=5, return_train_score=False)\n    gls.fit(x_train,y_train)\n    scores.append({\n        'model':alm,\n        'best_score':gls.best_score_,\n        'best_params':gls.best_params_\n    })","b950ed24":"df=pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf","a71d7f93":"model=RandomForestClassifier(n_estimators= 10)\nmodel.fit(x_train,y_train)","8de08e14":"y_predict=model.predict(test)","84fdb84b":"y_predict","7256a4e3":"arranging our categorical and numerical variable for plotting.","56f408b0":"plotting the variables against survived","dd56d988":"This is my first analysis, feel free to let me know what you think.","ea24f96b":"importing data","7017e10a":"EXPLORATORY DATA ANALYSIS","a522193e":"mapping sex to int","82cc1f41":"getting our data ready for modelling","b12d5079":"filling na values for both train and test data"}}