{"cell_type":{"5a765f3b":"code","b8984996":"code","6427c964":"code","8804dc07":"code","b1be768a":"code","01737620":"code","9ed6d1ee":"code","488a60bb":"code","a3d3067e":"code","be08e0f9":"code","e88d708b":"markdown","54464d38":"markdown"},"source":{"5a765f3b":"import os\nprint(os.listdir(\"..\/input\/agriculture\"))","b8984996":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.optim as optim","6427c964":"agriculture = \"..\/input\/agriculture\"\nprint(agriculture)\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\ndef resize2d(img, size):\n    return (F.adaptive_avg_pool2d(Variable(img, volatile=True), size)).data\n\n# a simple custom collate function, just to show the idea\ndef my_collate(batch):\n    data = torch.stack([item[0] for item in batch])\n    # data = torch.stack([resize2d(item[0], 224) for item in batch])\n    target = [item[1] for item in batch]\n    # AdaptiveAvgPooling\n    target = torch.LongTensor(target)\n    return [data, target]\n\ndef load_dataset(_transform=torchvision.transforms.ToTensor()):\n    # data_path = 'data\/train\/'\n    data_path = agriculture\n    train_dataset = torchvision.datasets.ImageFolder(\n        root=data_path,\n        transform=_transform,\n        # transform=train_transforms\n    )\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=16,\n        num_workers=0,\n        collate_fn=my_collate,  # use custom collate function here\n        shuffle=True\n    )\n    return train_loader\n\ndef show_transformed_images(_transform=torchvision.transforms.ToTensor()):\n    trainloader = load_dataset(_transform)\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # show images # Let us show some of the training images, for fun.\n    imshow(torchvision.utils.make_grid(images[0:2]))","8804dc07":"# this is original images\nshow_transformed_images()","b1be768a":"# this is Center Crop images\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.CenterCrop(700),transforms.ToTensor()]))","01737620":"# this is ColorJitter images\n# random application of brightness, contrast etc\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.CenterCrop(700), \n     transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0, hue=0),\n     transforms.ToTensor()]))","9ed6d1ee":"# Converting Images to gray scale\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.CenterCrop(700), \n     transforms.Grayscale(num_output_channels=1),\n     transforms.ToTensor()]))","488a60bb":"# Add padding to Images\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.CenterCrop(700), \n     transforms.Pad(50),\n     transforms.ToTensor()]))","a3d3067e":"# Add random affine transformation to Images\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.CenterCrop(700), \n     transforms.RandomAffine(30, translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n     transforms.ToTensor()]))","be08e0f9":"# Add random horizontal flips\nshow_transformed_images(_transform=torchvision.transforms.Compose(\n    [transforms.CenterCrop(700), \n     transforms.RandomHorizontalFlip(p=0.5),\n     transforms.ToTensor()]))","e88d708b":"## Center Crop Images","54464d38":"# Original Images"}}