{"cell_type":{"4deb4276":"code","09ac96b9":"code","f1e3a95b":"code","6ca275fa":"code","27ccbacd":"code","e2500d71":"code","49a3b252":"code","e1fb6256":"code","90ea087d":"code","0a0210fa":"code","a43b4382":"code","6dcc5da9":"code","1e571684":"code","2c464471":"code","310bbd21":"code","f85e5a49":"code","aba6006c":"code","8cffc395":"code","0e250d57":"code","4460de0a":"code","46f91006":"code","62b5f6e4":"code","78c84d46":"code","ab1ebdd0":"code","45edf4b1":"code","993e683b":"markdown","85cd4093":"markdown","43c11ccb":"markdown","d56fff08":"markdown","a1893d26":"markdown","59670dd0":"markdown"},"source":{"4deb4276":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow import feature_column\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']","09ac96b9":"def plot_loss(history, label, n):\n  # Use a log scale to show the wide range of values.\n  plt.semilogy(history.epoch,  history.history['loss'],\n               color=colors[n], label='Train '+label)\n  plt.semilogy(history.epoch,  history.history['val_loss'],\n          color=colors[n], label='Val '+label,\n          linestyle=\"--\")\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  \n  plt.legend()\n\ndef plot_metrics(history):\n  metrics =  ['loss', 'auc', 'precision', 'recall']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1)\n    plt.subplots_adjust(right=1.5)\n    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.7,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()\n    \nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]","f1e3a95b":"dataframe = pd.read_csv('\/kaggle\/input\/web-club-recruitment-2018\/train.csv')\ndataframe.head()","6ca275fa":"dataframe.describe()","27ccbacd":"neg, pos = np.bincount(dataframe['Y'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))\n","e2500d71":"data_labels = np.array(dataframe['Y'])\nbool_data_labels = data_labels != 0\n\ndata_features = np.array(dataframe)\n\npos_features = data_features[bool_data_labels]\nneg_features = data_features[~bool_data_labels]\n\npos_labels = data_labels[bool_data_labels]\nneg_labels = data_labels[~bool_data_labels]\n\n","49a3b252":"ids = np.arange(len(pos_features))\nchoices = np.random.choice(ids, len(neg_features))\n\nres_pos_features = pos_features[choices]\nres_pos_labels = pos_labels[choices]\n\nres_pos_features.shape","e1fb6256":"resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\nresampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n\norder = np.arange(len(resampled_labels))\nnp.random.shuffle(order)\nresampled_features = resampled_features[order]\nresampled_labels = resampled_labels[order]\n\nresampled_features.shape","90ea087d":"neg1, pos1 = np.bincount(resampled_labels)\ntotal1 = neg1 + pos1\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total1, pos1, 100 * pos1 \/ total1))","0a0210fa":"res = np.insert(resampled_features, 1, resampled_labels, axis=1)\npres = pd.DataFrame(data=resampled_features,columns=dataframe.columns)\npres.head()","a43b4382":"train, test = train_test_split(pres, test_size=0.08)\ntrain, val = train_test_split(train, test_size=0.08)\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')\nprint(len(test), 'test examples')","6dcc5da9":"train_labels = np.array(train['Y'])\nbool_train_labels = train_labels != 0\nval_labels = np.array(val['Y'])\n# test_labels = np.array(test['Y'])","1e571684":"def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n  dataframe = dataframe.copy()\n  labels = dataframe.pop('Y')\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","2c464471":"def demo(feature_column):\n    train_ds = df_to_dataset(train, batch_size=5)\n    example_batch = next(iter(train_ds))[0]\n    feature_layer = layers.DenseFeatures(feature_column)\n    print(feature_layer(example_batch).numpy())","310bbd21":"def zscore_x6(col):\n  mean = dataframe.describe()['X6']['mean']\n  std = dataframe.describe()['X6']['std']\n  return (col - mean)\/std\n\ndef zscore_x7(col):\n  mean = dataframe.describe()['X7']['mean']\n  std = dataframe.describe()['X7']['std']\n  return (col - mean)\/std\n\ndef zscore_x8(col):\n  mean = dataframe.describe()['X8']['mean']\n  std = dataframe.describe()['X8']['std']\n  return (col - mean)\/std\n\ndef zscore_x9(col):\n  mean = dataframe.describe()['X9']['mean']\n  std = dataframe.describe()['X9']['std']\n  return (col - mean)\/std\n\ndef zscore_x10(col):\n  mean = dataframe.describe()['X10']['mean']\n  std = dataframe.describe()['X10']['std']\n  return (col - mean)\/std\n\ndef zscore_x11(col):\n  mean = dataframe.describe()['X11']['mean']\n  std = dataframe.describe()['X11']['std']\n  return (col - mean)\/std\n\ndef zscore_x12(col):\n  mean = dataframe.describe()['X12']['mean']\n  std = dataframe.describe()['X12']['std']\n  return (col - mean)\/std\n\ndef zscore_x13(col):\n  mean = dataframe.describe()['X13']['mean']\n  std = dataframe.describe()['X13']['std']\n  return (col - mean)\/std\n\ndef zscore_x14(col):\n  mean = dataframe.describe()['X14']['mean']\n  std = dataframe.describe()['X14']['std']\n  return (col - mean)\/std\n\ndef zscore_x15(col):\n  mean = dataframe.describe()['X15']['mean']\n  std = dataframe.describe()['X15']['std']\n  return (col - mean)\/std\n\ndef zscore_x16(col):\n  mean = dataframe.describe()['X16']['mean']\n  std = dataframe.describe()['X16']['std']\n  return (col - mean)\/std\ndef zscore_x17(col):\n  mean = dataframe.describe()['X17']['mean']\n  std = dataframe.describe()['X17']['std']\n  return (col - mean)\/std\n\ndef zscore_x18(col):\n  mean = dataframe.describe()['X18']['mean']\n  std = dataframe.describe()['X18']['std']\n  return (col - mean)\/std\n\ndef zscore_x19(col):\n  mean = dataframe.describe()['X19']['mean']\n  std = dataframe.describe()['X19']['std']\n  return (col - mean)\/std\n\ndef zscore_x20(col):\n  mean = dataframe.describe()['X20']['mean']\n  std = dataframe.describe()['X20']['std']\n  return (col - mean)\/std\n\ndef zscore_x21(col):\n  mean = dataframe.describe()['X21']['mean']\n  std = dataframe.describe()['X21']['std']\n  return (col - mean)\/std\n\ndef zscore_x22(col):\n  mean = dataframe.describe()['X22']['mean']\n  std = dataframe.describe()['X22']['std']\n  return (col - mean)\/std\n\ndef zscore_x23(col):\n  mean = dataframe.describe()['X23']['mean']\n  std = dataframe.describe()['X23']['std']\n  return (col - mean)\/std","f85e5a49":"feature_columns = []\n\nX1_buckets = feature_column.bucketized_column(feature_column.numeric_column('X1'), boundaries=[i*10000 for i in range(1, 100)])\n# demo(X1_buckets)\nfeature_columns.append(X1_buckets)\n\nX2_categories = feature_column.indicator_column(feature_column.categorical_column_with_identity('X2', 3))\n# demo(X2_categories)\nfeature_columns.append(X2_categories)\n\nX3_categories = feature_column.indicator_column(feature_column.categorical_column_with_identity('X3', 7))\n# demo(X3_categories)\nfeature_columns.append(X3_categories)\n\nX4_categories = feature_column.indicator_column(feature_column.categorical_column_with_identity('X4', 4))\n# demo(X4_categories)\nfeature_columns.append(X4_categories)\n\n\nX5_buckets = feature_column.bucketized_column(feature_column.numeric_column('X5'), boundaries=[25, 30, 35, 40, 45, 50, 55, 60, 65, 70 , 75])\n# demo(X5_buckets)\nfeature_columns.append(X5_buckets)\n\n\n\nfeature_columns.append(feature_column.numeric_column('X6', normalizer_fn=zscore_x6))\nfeature_columns.append(feature_column.numeric_column('X7', normalizer_fn=zscore_x7))\nfeature_columns.append(feature_column.numeric_column('X8', normalizer_fn=zscore_x8))\nfeature_columns.append(feature_column.numeric_column('X9', normalizer_fn=zscore_x9))\nfeature_columns.append(feature_column.numeric_column('X10', normalizer_fn=zscore_x10))\nfeature_columns.append(feature_column.numeric_column('X11', normalizer_fn=zscore_x11))\nfeature_columns.append(feature_column.numeric_column('X12', normalizer_fn=zscore_x12))\nfeature_columns.append(feature_column.numeric_column('X13', normalizer_fn=zscore_x13))\nfeature_columns.append(feature_column.numeric_column('X14', normalizer_fn=zscore_x14))\nfeature_columns.append(feature_column.numeric_column('X15', normalizer_fn=zscore_x15))\nfeature_columns.append(feature_column.numeric_column('X16', normalizer_fn=zscore_x16))\nfeature_columns.append(feature_column.numeric_column('X17', normalizer_fn=zscore_x17))\nfeature_columns.append(feature_column.numeric_column('X18', normalizer_fn=zscore_x18))\nfeature_columns.append(feature_column.numeric_column('X19', normalizer_fn=zscore_x19))\nfeature_columns.append(feature_column.numeric_column('X20', normalizer_fn=zscore_x20))\nfeature_columns.append(feature_column.numeric_column('X21', normalizer_fn=zscore_x21))\nfeature_columns.append(feature_column.numeric_column('X22', normalizer_fn=zscore_x22))\nfeature_columns.append(feature_column.numeric_column('X23', normalizer_fn=zscore_x23))","aba6006c":"    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)","8cffc395":"batch_size = 200\ntrain_ds = df_to_dataset(train, batch_size=batch_size)\nval_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\ntest_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)","0e250d57":"model = tf.keras.Sequential([\n  feature_layer,\n  layers.Dense(200, activation='relu'),\n  layers.Dropout(0.5),\n  layers.Dense(128, activation='relu'),\n  layers.Dropout(0.5),\n  layers.Dense(100, activation='relu'),\n  layers.Dropout(0.5),\n  layers.Dense(80, activation='relu'),\n  layers.Dropout(0.5),\n  layers.Dense(40, activation='relu'),\n  layers.Dropout(0.5),\n  layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=METRICS)\n\n\nhistory = model.fit(train_ds,\n          validation_data=val_ds,\n          epochs=150)\nmodel.summary()\n","4460de0a":"model.evaluate(test_ds)","46f91006":"plot_loss(history, \"history\", 1)","62b5f6e4":"plot_metrics(history)","78c84d46":"test_dataframe = pd.read_csv('\/kaggle\/input\/web-club-recruitment-2018\/test.csv')\nkaggle_test_ds = tf.data.Dataset.from_tensor_slices((dict(test_dataframe))).batch(32)\nprint(kaggle_test_ds)\nprint(train_ds)","ab1ebdd0":"pred= model.predict(kaggle_test_ds).round().astype(int)\ndf = pd.DataFrame(pred)\ndf.index.name = 'id'\ndf.columns = ['predicted_val']\ndf.head()","45edf4b1":"df.to_csv('output.csv', index=True)","993e683b":"# \u062a\u0648\u0627\u0628\u0639 \u0645\u0648\u0631\u062f \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0628\u0631\u0627\u06cc \u0686\u0627\u067e \u0646\u0645\u0648\u062f\u0627\u0631 \u0647\u0627","85cd4093":"<p lang=\"fa\" dir=\"rtl\" align=\"right\">\n\u0628\u0631\u0627\u06cc \u0628\u0627\u0644\u0627\u0646\u0633 \u06a9\u0631\u062f\u0646 \u062f\u0627\u062f\u0647 \u0647\u0627 \u0628\u0647 \u0648\u0633\u06cc\u0644\u0647 \u06a9\u062f \u0632\u06cc\u0631 \u0633\u0639\u06cc \u06a9\u0631\u062f\u06cc\u0645 \u062a\u0639\u062f\u0627\u062f \u062f\u0627\u062f\u0647 \u0647\u0627\u06cc 1 \u0631\u0627 \u0628\u0647 \u0648\u0633\u06cc\u0644\u0647 resample \u0627\u0641\u0632\u0627\u06cc\u0634 \u0628\u062f\u06cc\u0645\n<\/p>\n\n","43c11ccb":"<p lang=\"fa\" dir=\"rtl\" align=\"right\">\n    \u0628\u0627 \u062a\u0648\u062c\u0647 \u0628\u0647 \u062e\u0631\u0648\u062c\u06cc \u0628\u0627\u0644\u0627 \u062f\u0627\u062f\u0647 \u0647\u0627 \u0628\u0627\u0644\u0627\u0646\u0633 \u0646\u06cc\u0633\u062a\u0646\u062f \u0648\u0642\u062a\u06cc \u0642\u0628\u0644 \u0627\u0632 \u0628\u0627\u0644\u0627\u0646\u0633 \u06a9\u0631\u062f\u0646 \u062f\u0627\u062f\u0647 \u0647\u0627 \u0645\u062f\u0644 \u0631\u0648 \u062a\u0631\u06cc\u0646 \u06a9\u0631\u062f\u06cc\u0645 \u0645\u062f\u0644 \u0628\u0631\u0627\u06cc \u0627\u06a9\u062b\u0631\u06cc\u062a \u062f\u0627\u062f\u0647 \u0647\u0627 \u062e\u0631\u0648\u062c\u06cc \u0631\u0648 \u062f\u0633\u062a\u0647 0 \u062a\u0634\u062e\u06cc\u0635 \u0645\u06cc \u062f\u0627\u062f\n<\/p>\n\n\n","d56fff08":"<p lang=\"fa\" dir=\"rtl\" align=\"right\">\n   \u0628\u0639\u062f \u0627\u0632 \u0628\u0627\u0644\u0627\u0646\u0633 \u06a9\u0631\u062f\u0646 \u062f\u0627\u062f\u0647 \u0647\u0627 \u0645\u062f\u0644 \u0634\u0631\u0648\u0639 \u0628\u0647 \u062a\u0634\u062e\u06cc\u0635 \u062f\u0648 \u062f\u0633\u062a\u0647 \u06a9\u0631\u062f \u0648\u0644\u06cc \u0645\u0634\u06a9\u0644\u06cc \u06a9\u0647 \u067e\u06cc\u0634 \u0627\u0648\u0645\u062f \u062f\u0642\u062a \u0645\u062f\u0644 \u062e\u06cc\u0644\u06cc \u06a9\u0645 \u0628\u0648\u062f \u0648 \u0647\u0645\u0686\u0646\u06cc\u0646 \u0645\u062f\u0644 \u0645\u0634\u06a9\u0644 overfit \u0646\u06cc\u0632 \u062f\u0627\u0634\u062a.\n    \u0628\u0631\u0627\u06cc \u0631\u0641\u0639 \u0627\u06cc\u0646 \u0645\u0634\u06a9\u0644\u0627\u062a \u0627\u0648\u0645\u062f\u06cc\u0645 \u0648 \u062f\u0627\u062f\u0647 \u0647\u0627 \u0631\u0648 \u0628\u0627 \u062a\u0648\u0627\u0628\u0639 \u0632\u06cc\u0631 \u0646\u0631\u0645\u0627\u0644 \u06a9\u0631\u062f\u06cc\u0645 \u0648 \u062f\u0642\u062a \u0645\u062f\u0644 \u0631\u0633\u06cc\u062f \u0628\u0647 98 \u062f\u0631\u0635\u062f.\n    \u062f\u0642\u062a \u062e\u06cc\u0644\u06cc \u0628\u0647\u0628\u0648\u062f \u067e\u06cc\u062f\u0627 \u06a9\u0631\u062f \u0648\u0644\u06cc \u0645\u062f\u0644 \u0639\u0645\u06cc\u0642\u0627 overfit \u0634\u062f\u0647 \u0628\u0648\u062f.\n    \u0646\u0645\u0648\u062f\u0627\u0631 history \u0628\u0631 \u0631\u0648\u06cc train \u0648 val \u0627\u0632  \u0647\u0645 \u0641\u0627\u0635\u0644\u0647 \u0645\u06cc \u06af\u0631\u0641\u062a\n<\/p>","a1893d26":"<p lang=\"fa\" dir=\"rtl\" align=\"right\">\n   \u0628\u0631\u0627\u06cc \u0631\u0641\u0639 \u0645\u0634\u06a9\u0644 overfit \u0627\u0632 \u0644\u0627\u06cc\u0647 \u0647\u0627\u06cc dropout \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0631\u062f\u06cc\u0645 \u0648 \u0645\u0634\u06a9\u0644 \u062d\u0644 \u0634\u062f \u0648\u0644\u06cc \u062f\u0642\u062a \u0645\u062f\u0644 \u0628\u0647 \u06f8\u06f3 \u06a9\u0627\u0647\u0634 \u067e\u06cc\u062f\u0627 \u06a9\u0631\u062f.\n    \u0647\u0645\u0686\u0646\u06cc\u0646 \u0631\u06af\u0631\u0633\u06cc\u0648\u0646 \u062e\u0637\u06cc L2 \u0631\u0648 \u0647\u0645 \u062a\u0633\u062a \u06a9\u0631\u062f\u06cc\u0645 \u0648\u0644\u06cc \u0646\u062a\u06cc\u062c\u0647 dropput \u062e\u06cc\u0644\u06cc \u0628\u0647\u062a\u0631 \u0628\u0648\u062f\n<\/p>\n","59670dd0":"<p lang=\"fa\" dir=\"rtl\" align=\"right\">\n  \u062f\u0631 \u0622\u062e\u0631 \u062f\u0631 \u0646\u0645\u0648\u062f\u0627\u0631 \u062e\u0637\u0627 \u0645\u06cc \u0628\u06cc\u0646\u06cc\u0645 \u06a9\u0647 \u0645\u062f\u0644 \u0645\u0634\u06a9\u0644 high variance \u0646\u062f\u0627\u0631\u0647\n    \u0647\u0645\u0686\u0646\u06cc\u0646 \u062f\u0642\u062a \u0648 recal \u0648 precision \u0645\u062f\u0644 \u0628\u0647 \u062d\u062f\u0648\u062f \u06f8\u06f0 \u0631\u0633\u06cc\u062f\u0647\n    \u0628\u0646\u0638\u0631 \u0645\u06cc \u0631\u0633\u0647 \u06a9\u0647 \u0628\u0631\u0627\u06cc \u0628\u0647\u0628\u0648\u062f \u0628\u06cc\u0634\u062a\u0631 \u062f\u0642\u062a \u0648 \u0633\u0627\u06cc\u0631 \u0645\u0639\u06cc\u0627\u0631 \u0647\u0627\u06cc \u0645\u062f\u0644 \u0646\u06cc\u0627\u0632 \u0628\u0647 \u062f\u0627\u062f\u0647 \u0647\u0627\u06cc \u0628\u06cc\u0634\u062a\u0631 \u0647\u0633\u062a \u0686\u0648\u0646\u06a9\u0647 \u0628\u0627 \u06a9\u0627\u0647\u0634 \u0633\u0627\u06cc\u0632 \u0648\u0644\u06cc\u062f\u06cc\u0634\u0646 \u0648 \u062a\u0633\u062a \u0633\u062a \u062f\u0642\u062a \u0645\u062f\u0644 \u0628\u06cc\u0634\u062a\u0631 \u0645\u06cc \u0634\u0647 \u0648\u0644\u06cc \u0686\u0648\u0646 \u06a9\u0647 \u062f\u0648\u0633\u062a \u0646\u062f\u0627\u0631\u06cc\u0645 \u0645\u062f\u0644 \u0627\u062d\u06cc\u0627\u0646\u0627 \u0622\u0648\u0631\u0641\u06cc\u062a \u0628\u0634\u0647 \u0628\u06cc\u0634\u062a\u0631 \u0627\u0632 \u0627\u06cc\u0646 \u0627\u0646\u062f\u0627\u0632\u0647 \u0645\u062c\u0645\u0648\u0639\u0647 \u062f\u0627\u062f\u0647 \u0647\u0627\u06cc \u062a\u0633\u062a \u0648 \u0648\u0644\u06cc\u062f\u06cc\u062a \u0631\u0648 \u06a9\u0627\u0647\u0634 \u0646\u0645\u06cc \u062f\u06cc\u0645\n    \u0646\u06a9\u062a\u0647 \u0645\u0647\u0645 \u0628\u0639\u062f\u06cc \u0645\u0639\u06cc\u0627\u0631 ROC \u0647\u0633\u062a \u06a9\u0647 \u0628\u0627 \u0645\u0642\u062f\u0627\u0631 0.9 \u0646\u0634\u0648\u0646 \u0645\u06cc\u062f\u0647 \u0645\u062f\u0644 \u0628\u0627 \u0627\u062d\u062a\u0645\u0627\u0644 \u062e\u0648\u0628\u06cc \u062f\u0633\u062a\u0647 \u0628\u0646\u062f\u06cc \u0631\u0648 \u0627\u0646\u062c\u0627\u0645 \u0645\u06cc\u062f\u0647\n<\/p>"}}