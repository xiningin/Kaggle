{"cell_type":{"52e77e30":"code","7ee33c11":"code","85896faf":"code","e78cbf0e":"code","e4d0439c":"code","749a3413":"code","fa338c90":"code","e398b3b2":"code","f2319389":"code","b267cfa0":"code","364e1b45":"code","c65027a1":"code","711d0a8e":"code","5b7f3578":"code","02bbd751":"code","0fe3bb44":"code","629cdf01":"code","2f54be0e":"code","49ecb016":"code","5b87f015":"code","47e478aa":"code","2d2492d3":"code","1b31777d":"code","b240b170":"code","ac926b5e":"code","55dcb90e":"code","9f989952":"code","58e02b63":"code","109204be":"code","3dd4bba7":"markdown"},"source":{"52e77e30":"#!pip install -q efficientnet_pytorch\n!pip install -q densenet_pytorch","7ee33c11":"import time\nimport random\nimport datetime\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nimport cv2\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import random_split\n#import efficientnet_pytorch\nimport densenet_pytorch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid","85896faf":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(2021)","e78cbf0e":"class DataLoaderConfig:\n    batch_size = 32\n    num_workers = 8\n\nclass TrainConfig:\n    criterion = nn.CrossEntropyLoss \n    n_epochs = 10\n    lr = 0.001\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode='min',\n        factor=0.5,\n        patience=1,\n        verbose=False, \n        threshold=0.0001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-8,\n        eps=1e-08\n    )\n    \nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nDEVICE","e4d0439c":"train_dir='..\/input\/cat-and-dog\/test_set\/test_set'\ntest_dir='..\/input\/cat-and-dog\/training_set\/training_set'","749a3413":"classes0 = os.listdir(train_dir)\nclasses=sorted(classes0)\nprint(classes0)\nprint(classes)","fa338c90":"N=[0,1]\nnormal_mapping=dict(zip(classes,N)) \nreverse_mapping=dict(zip(N,classes)) ","e398b3b2":"train_transform=transforms.Compose([\n        transforms.RandomRotation(10),      # rotate +\/- 10 degrees\n        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n        transforms.Resize(40),              # resize shortest side\n        transforms.CenterCrop(40),          # crop longest side\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n])","f2319389":"trainset = ImageFolder(train_dir, transform=train_transform)\ntestset = ImageFolder(test_dir, transform=train_transform)","b267cfa0":"def show_image(img, label):\n    print('Label: ', trainset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1,2,0))","364e1b45":"show_image(*trainset[20])","c65027a1":"torch.manual_seed(10)\nval_size = len(trainset)\/\/10\ntest_size = len(testset)\ntrain_size = len(trainset) - val_size","711d0a8e":"train_ds, val_ds = random_split(trainset, [train_size, val_size])\ntest_ds = testset\nlen(train_ds), len(val_ds), len(test_ds)   ","5b7f3578":"batch_size = 32\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nvalid_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size, num_workers=4, pin_memory=True)","02bbd751":"for images, labels in train_loader:\n    fig, ax = plt.subplots(figsize=(18,10))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n    break","0fe3bb44":"class DatasetRetriever(Dataset):\n    def __init__(self, X, y, transforms=None):\n        super().__init__()\n        self.X = X.reshape(-1,40,40).astype(np.float32)\n        self.y = y\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        image, target = self.X[index], self.y[index]\n        image = np.stack([image] * 3, axis=-1)\n        image \/= 255.\n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        return image, torch.tensor(target, dtype=torch.long)\n\n    def __len__(self):\n        return self.y.shape[0]","629cdf01":"def get_train_transforms():\n    return A.Compose(\n        [\n            A.Rotate(limit=10, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=2, max_w_size=2, fill_value=0, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=1, max_w_size=1, fill_value=1, p=0.5),\n            A.Resize(40,40, p=1.),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(40,40, p=1.),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0\n    )","2f54be0e":"plt.figure(figsize=(12,12))\n\nfor i in range(16):    \n    image, target = train_ds[random.randint(0,len(train_ds))]\n    numpy_image = image.permute(1,2,0).numpy()\n\n    plt.subplot(4,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(reverse_mapping[target],fontsize=12)\n    plt.imshow(numpy_image);","49ecb016":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count","5b87f015":"class AccMeter:\n    def __init__(self):\n        self.true_count = 0\n        self.all_count = 0\n        self.avg = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true\n        y_pred = y_pred.argmax(axis=1)\n        self.true_count += (y_true == y_pred).sum()\n        self.all_count += y_true.shape[0]\n        self.avg = self.true_count \/ self.all_count","47e478aa":"class Fitter:\n    def __init__(\n        self, model, device, criterion, n_epochs, \n        lr, sheduler=None, scheduler_params=None\n    ):\n        self.epoch = 0\n        self.n_epochs = n_epochs\n        self.base_dir = '.\/'\n        self.log_path = f'{self.base_dir}\/log.txt'\n        self.best_summary_loss = np.inf\n        self.model = model\n        self.device = device\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n        \n        if sheduler:\n            self.scheduler = sheduler(self.optimizer, **scheduler_params)\n            \n        self.criterion = criterion().to(self.device)\n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, valid_loader):\n        for e in range(self.n_epochs):\n            current_lr = self.optimizer.param_groups[0]['lr']\n            self.log(f'\\n{datetime.datetime.utcnow().isoformat()}\\nLR: {current_lr}')\n\n            t = int(time.time())\n            summary_loss, final_scores = self.train_one_epoch(train_loader)\n            self.log(\n                f'[RESULT]: Train. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n\n            t = int(time.time())\n            summary_loss, final_scores = self.validation(valid_loader)\n            self.log(\n                f'[RESULT]: Valid. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n            \n            f_best = 0\n            if summary_loss.avg < self.best_summary_loss:\n                self.best_summary_loss = summary_loss.avg\n                f_best = 1\n\n            self.scheduler.step(metrics=summary_loss.avg)    \n            self.save(f'{self.base_dir}\/last-checkpoint.bin')\n            \n            if f_best:\n                self.save(f'{self.base_dir}\/best-checkpoint.bin')\n                print('New best checkpoint')\n\n            self.epoch += 1\n\n    def validation(self, val_loader):\n        self.model.eval()\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n        \n        t = int(time.time())\n        for step, (images, targets) in enumerate(val_loader):\n            print(\n                f'Valid Step {step}\/{len(val_loader)}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s', end='\\r'\n            )\n            \n            with torch.no_grad():\n                targets = targets.to(self.device)\n                images = images.to(self.device)\n                batch_size = images.shape[0]\n                outputs = self.model(images)\n                loss = self.criterion(outputs, targets)\n                final_scores.update(targets, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n\n        return summary_loss, final_scores\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n        \n        t = int(time.time())\n        for step, (images, targets) in enumerate(train_loader):\n            print(\n                f'Train Step {step}\/{len(train_loader)}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s', end='\\r'\n            )\n            \n            targets = targets.to(self.device)\n            images = images.to(self.device)\n            batch_size = images.shape[0]\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            final_scores.update(targets, outputs.detach())\n            summary_loss.update(loss.detach().item(), batch_size)\n            self.optimizer.step()\n\n        return summary_loss, final_scores\n    \n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_summary_loss': self.best_summary_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_summary_loss = checkpoint['best_summary_loss']\n        self.epoch = checkpoint['epoch'] + 1\n        \n    def log(self, message):\n        print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","2d2492d3":"def get_net():\n    net = densenet_pytorch.DenseNet.from_pretrained('densenet201')\n    net._fc = nn.Linear(in_features=2560, out_features=2, bias=True)\n    return net\n\nnet = get_net().to(DEVICE)","1b31777d":"fitter = Fitter(\n    model=net, \n    device=DEVICE, \n    criterion=TrainConfig.criterion, \n    n_epochs=TrainConfig.n_epochs, \n    lr=TrainConfig.lr, \n    sheduler=TrainConfig.scheduler, \n    scheduler_params=TrainConfig.scheduler_params\n)","b240b170":"fitter.fit(train_loader, valid_loader)","ac926b5e":"checkpoint = torch.load('..\/working\/best-checkpoint.bin')\nnet.load_state_dict(checkpoint['model_state_dict']);\nnet.eval();","55dcb90e":"class DatasetRetriever(Dataset):\n    def __init__(self, X, transforms=None):\n        super().__init__()\n        self.X = X.reshape(-1,40,40).astype(np.float32)\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        image = self.X[index]\n        image = np.stack([image] * 3, axis=-1)\n        image \/= 255.\n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        return image\n\n    def __len__(self):\n        return self.X.shape[0]","9f989952":"y=[]\nresult = []\nfor images, labels in test_loader:\n    images2=images.to(DEVICE)\n    y_pred = net(images2).detach().cpu().numpy().argmax(axis=1).astype(int) \n    result.extend(y_pred)\n    y.extend(labels)\n    \nprint(result[0:10])\nprint(y[0:10])","58e02b63":"plt.figure(figsize=(12,12))\n\nfor i in range(16):    \n    image, target = test_ds[i]\n    numpy_image = image.permute(1,2,0).numpy()\n    plt.subplot(4,4, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(f'{reverse_mapping[result[i]]}=={reverse_mapping[target]}', fontsize=12)\n    plt.imshow(numpy_image)","109204be":"ANS=y\nPRED=result\naccuracy=accuracy_score(ANS,PRED)\nprint(accuracy)","3dd4bba7":"```\nmodel_name should be one of: densenet121, densenet161, densenet169, densenet201\n```"}}