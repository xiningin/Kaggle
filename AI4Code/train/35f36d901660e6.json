{"cell_type":{"dc8b25f1":"code","34b2f448":"code","1ab2425e":"code","d69ccd46":"code","79be961d":"code","32b6c659":"code","366dfa4d":"code","a9addecc":"code","ba7e69b4":"code","9edf74b3":"code","3478cd21":"code","1ef8a825":"code","07d2fab5":"code","3d257ddb":"markdown","2fd97b76":"markdown","86dabf15":"markdown","f781d32f":"markdown","18c638f8":"markdown","08dd0113":"markdown","9c673b44":"markdown","8fb56742":"markdown"},"source":{"dc8b25f1":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","34b2f448":"import tensorflow_hub as hub\nimport tensorflow as tf\n\nfrom pprint import pprint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\n\n# This needs to be done in order for the Hub module to communicate.\nimport os\nos.environ[\"TFHUB_CACHE_DIR\"] = \"gs:\/\/funmatch-tf\/model-cache-dir\"","1ab2425e":"try: # Cetect TPUs\n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # Detect GPUs\n    strategy = tf.distribute.MirroredStrategy() \n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","d69ccd46":"BATCH_SIZE = 64 * strategy.num_replicas_in_sync\nBIGGER = 160\nRESIZE = 128\nCENTRAL_FRAC = 0.875\nAUTO = tf.data.AUTOTUNE\n\nSCHEDULE_LENGTH = 500\nSCHEDULE_BOUNDARIES = [200, 300, 400]\nSCHEDULE_LENGTH = (SCHEDULE_LENGTH * 512 \/ BATCH_SIZE)","79be961d":"# This comes from this repository https:\/\/github.com\/GoogleCloudPlatform\/training-data-analyst.\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\ntrain_pattern = \"gs:\/\/funmatch-tf\/train\/*.tfrec\"\ntrain_filenames = tf.io.gfile.glob(train_pattern)\nval_pattern = \"gs:\/\/funmatch-tf\/validation\/*.tfrec\"\nval_filenames = tf.io.gfile.glob(val_pattern)\ntest_pattern = \"gs:\/\/funmatch-tf\/test\/*.tfrec\"\ntest_filenames = tf.io.gfile.glob(test_pattern)\n\nDATASET_NUM_TRAIN_EXAMPLES = count_data_items(train_filenames)\nSTEPS_PER_EPOCH = 10\n\npprint(train_filenames[:5])\npprint(val_filenames[:5])\npprint(test_filenames[:5])","32b6c659":"# Function to read the TFRecords, segregate the images and labels.\ndef read_tfrecord(example, train):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"class\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    \n    example = tf.io.parse_single_example(example, features)\n    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n    \n    if train:\n        image = augment(image)\n    else:\n        image = tf.image.central_crop(image, central_fraction=CENTRAL_FRAC)\n        image = tf.image.resize(image, (RESIZE, RESIZE))\n        \n    image = tf.reshape(image, (RESIZE, RESIZE, 3))\n    image = tf.cast(image, tf.float32) \/ 255.0  \n    class_label = tf.cast(example[\"class\"], tf.int32)\n    return (image, class_label)\n\n# Load the TFRecords and create tf.data.Dataset\ndef load_dataset(filenames, train):\n    opt = tf.data.Options()\n    opt.experimental_deterministic = False\n    \n    if not train:\n        opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n    \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    dataset = dataset.map(lambda x: (read_tfrecord(x, train)), num_parallel_calls=AUTO)\n    dataset = dataset.with_options(opt)\n    return dataset\n\n# Augmentation motivated from here:\n# https:\/\/github.com\/google-research\/big_transfer\/blob\/master\/colabs\/big_transfer_tf2.ipynb.\ndef augment(image):\n    # Resize to a bigger shape, randomly horizontally flip it,\n    # and then take the crops. \n    image = tf.image.resize(image, (BIGGER, BIGGER))\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_crop(image, [RESIZE, RESIZE, 3])\n    return image\n\n# Batch, shuffle, and repeat the dataset and prefetch it\n# well before the current epoch ends\ndef batch_dataset(filenames, train, batch_size=BATCH_SIZE):\n    dataset = load_dataset(filenames, train)\n    if train:\n        dataset = dataset.repeat(int(SCHEDULE_LENGTH * BATCH_SIZE \/ DATASET_NUM_TRAIN_EXAMPLES * STEPS_PER_EPOCH) + 1 + 50)\n        dataset = dataset.shuffle(BATCH_SIZE*10)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(AUTO) \n    return dataset","366dfa4d":"training_dataset = batch_dataset(train_filenames, True)\nvalidation_dataset = batch_dataset(val_filenames, False)\ntest_dataset = batch_dataset(test_filenames, False)","a9addecc":"# sample_images, _ = next(iter(training_dataset))\n# plt.figure(figsize=(10, 10))\n# for n in range(25):\n#     ax = plt.subplot(5, 5, n + 1)\n#     plt.imshow(sample_images[n].numpy())\n#     plt.axis(\"off\")\n# plt.show()","ba7e69b4":"# Referenced from: https:\/\/github.com\/google-research\/big_transfer\/blob\/master\/colabs\/big_transfer_tf2.ipynb. \nclass MyBiTModel(tf.keras.Model):\n    def __init__(self, num_classes, module):\n        super().__init__()\n\n        self.num_classes = num_classes\n        self.head = tf.keras.layers.Dense(num_classes, kernel_initializer=\"zeros\")\n        self.bit_model = module\n  \n    def call(self, images):\n        bit_embedding = self.bit_model(images)\n        return self.head(bit_embedding)","9edf74b3":"# Define optimizer and loss\n\nlr = (1e-5 * BATCH_SIZE \/ 512) * strategy.num_replicas_in_sync \n\n# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\nlr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES, \n                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\noptimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)","3478cd21":"# Target is 91.03%.\nwith strategy.scope():\n    model_url = \"https:\/\/tfhub.dev\/google\/bit\/m-r101x3\/1\"\n    module = hub.KerasLayer(model_url, trainable=True)\n    model = MyBiTModel(num_classes=37, module=module)\n    model.compile(optimizer=optimizer,\n              loss=loss_fn,\n              metrics=[\"accuracy\"])\n    \nhistory = model.fit(\n    training_dataset,\n    validation_data=validation_dataset,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    epochs=45\n)","1ef8a825":"_, accuracy = model.evaluate(test_dataset)\nprint(f\"Test top-1 accuracy: {round(accuracy * 100, 2)}%\")","07d2fab5":"model.save(\"gs:\/\/funmatch-tf\/models\/T-r101x3-128\")","3d257ddb":"## Data loading and input preprocessing\n\nTo know how these TFRecords were created refer to [this notebook](https:\/\/colab.research.google.com\/github\/sayakpaul\/FunMatch-Distillation\/blob\/main\/tfrecords_pets37.ipynb). **Be sure to update the GCS paths.**","2fd97b76":"Find the Kaggle Kernel of this notebook [here](https:\/\/www.kaggle.com\/spsayakpaul\/train-bit).\n\nThis notebook fine-tunes a teacher model (based on [BiT ResNet101x3](https:\/\/arxiv.org\/abs\/1912.11370)) to further train a student using function matching (proposed in [Knowledge distillation: A good teacher is patient and consistent](https:\/\/arxiv.org\/abs\/2106.05237)). You can find the distillation notebook [here](https:\/\/www.kaggle.com\/spsayakpaul\/funmatch-distillation). To run this notebook you would need to have a billing enabled GCP account to use a GCS Bucket.","86dabf15":"## Setup","f781d32f":"Should have trained for five more epochs.","18c638f8":"## Training and evaluation","08dd0113":"## Hyperparameters and constants","9c673b44":"## Model related utilities","8fb56742":"`gs:\/\/funmatch-tf` is the GCS Bucket I created beforehand. To proceed, you'd need to create a GCS Bucket with a universally unique name and replace `funmatch-tf` with it."}}