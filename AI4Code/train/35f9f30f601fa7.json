{"cell_type":{"2c2ab79e":"code","43ae50a9":"code","b0e9ef6b":"code","9cb68be2":"code","c74420e2":"code","b2dad771":"code","2afc031e":"code","1b57c3d0":"code","8741e3d7":"code","675f32b2":"code","5f99d7b1":"code","70cf9cfa":"code","8f0fc114":"code","c0ad2943":"code","c4e19edf":"markdown","6938e233":"markdown","6d1586e5":"markdown","000d6970":"markdown","397695c5":"markdown","a3dd8d80":"markdown","fd0579ad":"markdown","652e3c1e":"markdown","5e6b7626":"markdown","1e01f4ac":"markdown","fc98b4d2":"markdown","3d5c9ea6":"markdown","dca186b0":"markdown","2ca07897":"markdown","e3744171":"markdown","23501d41":"markdown","5bd2eae4":"markdown","28693a1e":"markdown","8580ba9d":"markdown","3b1baffb":"markdown","2f5d52f2":"markdown"},"source":{"2c2ab79e":"import pandas as pd\nimport numpy as np\nimport math\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","43ae50a9":"bike_rentals = pd.read_csv('..\/input\/hour.csv')\nbike_rentals.head(5)","b0e9ef6b":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,6))\nax1, ax2 = axes.flatten()\n\nbike_rentals['cnt'].hist(grid=False, ax=ax1)\n\n# Sorted correlations with'cnt'\nsorted_corrs = bike_rentals.corr()['cnt'].sort_values(ascending=False)\nsns.heatmap(bike_rentals[sorted_corrs.index].corr(), ax=ax2)\n\nax1.set_title('Target Column \"cnt\" Histogram')\nax2.set_title('Correlations')\nplt.show()\nprint(\"Correlations:\\n\\n\", sorted_corrs)","9cb68be2":"def assign_label(hour):\n    if hour >= 6 and hour < 12:\n        return 1\n    elif hour >= 12 and hour < 18:\n        return 2\n    elif hour >= 18 and hour < 24:\n        return 3\n    elif hour >= 0 and hour < 6:\n        return 4\n    \nbike_rentals['time_label'] = bike_rentals['hr'].apply(lambda hr: assign_label(hr))\nprint(bike_rentals['time_label'].value_counts())\nbike_rentals.head(5)","c74420e2":"bike_rentals['weather_idx'] = 0.8*bike_rentals['temp'] + 0.1*bike_rentals['atemp'] + 0.1*bike_rentals['hum'] ","b2dad771":"# Train: 80% of the data \/ Test: 20% of the data\ntrain, test = train_test_split(bike_rentals, test_size=0.2, random_state=100)\n\nprint(\"\\nTrain: \", train.shape)\nprint(\"Test: \", test.shape)","2afc031e":"features = bike_rentals.columns[~bike_rentals.columns.isin(['cnt', 'registered', 'casual', 'dteday'])].tolist()\n\nX_train = train[features]\ny_train = train['cnt']\n\nX_test = test[features]\ny_test = test['cnt']\n\nprint(\"\\nInitial features: \", features)","1b57c3d0":"# Linear model\nlr = LinearRegression()\n\n# Train \nlr.fit(X_train, y_train)\n\n#Predict \nnew_cnt_lr = lr.predict(X_test)\n\n# --------------------------------------------------\n# Error metric\n# --------------------------------------------------\n\n# MSE \nmse_lr = mean_squared_error(y_test, new_cnt_lr)\n\nprint(\"-----------------\\nLinear regression\\n-----------------\")\nprint(\"MSE: \", mse_lr)","8741e3d7":"# Decision Trees model\nmin_samples_leaf = range(5,20,5)\nmax_depth = range(5,50,5)\nmin_samples_split = range(5,20,5)\n\nmse_dt = {}\ncurrent_mse = math.inf\n\nfor msl in min_samples_leaf:\n    for md in max_depth:\n        for mss in min_samples_split:\n            \n            dt = DecisionTreeRegressor(min_samples_leaf=msl, max_depth=md, min_samples_split=mss)\n\n            # Train\n            dt.fit(X_train, y_train)\n\n            # Predict\n            new_cnt_dt = dt.predict(X_test)\n            \n            # Update MSE \n            mse = mean_squared_error(y_test, new_cnt_dt)\n            \n            if mse <= current_mse:\n                mse_dt['value'] = mse\n                mse_dt['min_samples_split'] = mss\n                mse_dt['max_depth'] = md\n                mse_dt['min_samples_leaf'] = msl\n                \n                current_mse = mse\n\nprint(\"-----------------\\nDecision Trees\\n-----------------\")\nprint(\"MSE: \", mse_dt)","675f32b2":"# Random Forests model (setting n_estimators=10 (default))\nmin_samples_leaf = range(5,20,5)\nmax_depth = range(5,50,5)\nmin_samples_split = range(5,20,5)\n\nmse_rf = {}\ncurrent_mse = math.inf\n\nfor msl in min_samples_leaf:\n    for md in max_depth:\n        for mss in min_samples_split:\n\n            dt = RandomForestRegressor(n_estimators=10, min_samples_leaf=msl, max_depth=md, min_samples_split=mss)\n\n            # Train\n            dt.fit(X_train, y_train)\n\n            # Predict\n            new_cnt_rf = dt.predict(X_test)\n\n            # Update MSE \n            mse = mean_squared_error(y_test, new_cnt_rf)\n\n            if mse <= current_mse:\n                mse_rf['value'] = mse\n                mse_rf['min_samples_split'] = mss\n                mse_rf['max_depth'] = md\n                mse_rf['min_samples_leaf'] = msl\n\n                current_mse = mse\n\nprint(\"-----------------\\nRandom Forests\\n-----------------\")\nprint(\"MSE: \", mse_rf)","5f99d7b1":"new_target = ['casual', 'registered']\nnew_y_train = train[new_target]","70cf9cfa":"# Linear model\nlr = LinearRegression()\n\n# Train (update y_train)\nlr.fit(X_train, new_y_train)\n\n#Predict\npredictions = lr.predict(X_test)\n\n# Add up 'casual' and 'registered'\nnew_cnt_lr = predictions.sum(axis=1)\n\n# --------------------------------------------------\n# Error metric\n# --------------------------------------------------\n\n# MSE \nmse_lr = mean_squared_error(y_test, new_cnt_lr)\n\nprint(\"-----------------\\nLinear regression\\n-----------------\")\nprint(\"MSE: \", mse_lr)","8f0fc114":"# Decision Trees model\nmin_samples_leaf = range(5,20,5)\nmax_depth = range(5,50,5)\nmin_samples_split = range(5,20,5)\n\nmse_dt = {}\ncurrent_mse = math.inf\n\nfor msl in min_samples_leaf:\n    for md in max_depth:\n        for mss in min_samples_split:\n            \n            dt = DecisionTreeRegressor(min_samples_leaf=msl, max_depth=md, min_samples_split=mss)\n\n            # Train (update y_train)\n            dt.fit(X_train, new_y_train)\n\n            # Predict\n            predictions = dt.predict(X_test)\n            \n            # Add up 'casual' and 'registered'\n            new_cnt_dt = predictions.sum(axis=1)\n            \n            # Update MSE \n            mse = mean_squared_error(y_test, new_cnt_dt)\n            \n            if mse <= current_mse:\n                mse_dt['value'] = mse\n                mse_dt['min_samples_split'] = mss\n                mse_dt['max_depth'] = md\n                mse_dt['min_samples_leaf'] = msl\n                \n                current_mse = mse\n\nprint(\"-----------------\\nDecision Trees\\n-----------------\")\nprint(\"MSE: \", mse_dt)","c0ad2943":"# Random Forests model (setting n_estimators=10 (default))\nmin_samples_leaf = range(5,20,5)\nmax_depth = range(5,50,5)\nmin_samples_split = range(5,20,5)\n\nmse_rf = {}\ncurrent_mse = math.inf\n\nfor msl in min_samples_leaf:\n    for md in max_depth:\n        for mss in min_samples_split:\n\n            dt = RandomForestRegressor(n_estimators=10, min_samples_leaf=msl, max_depth=md, min_samples_split=mss)\n\n            # Train (update y_train)\n            dt.fit(X_train, new_y_train)\n\n            # Predict\n            predictions = dt.predict(X_test)\n            \n            # Add up 'casual' and 'registered'\n            new_cnt_rf = predictions.sum(axis=1)\n            \n            # Update MSE \n            mse = mean_squared_error(y_test, new_cnt_rf)\n\n            if mse <= current_mse:\n                mse_rf['value'] = mse\n                mse_rf['min_samples_split'] = mss\n                mse_rf['max_depth'] = md\n                mse_rf['min_samples_leaf'] = msl\n\n                current_mse = mse\n\nprint(\"-----------------\\nRandom Forests\\n-----------------\")\nprint(\"MSE: \", mse_rf)","c4e19edf":"<a id='section3'><\/a>\n## Bike rentals, target column\nSince the goal is to predict the number of bikes that will be rented in a given hour, the target column is 'cnt'. Let's take a look at the correlation between the rest of the columns and 'cnt' and its values first.","6938e233":"Looks like the amount of bikes rented per hour mostly oscillates between 0 and 200 bikes. Also, as we could expect the bigger the number of signed up or casual riders, the more bikes that were rented (as we can tell by the correlation between 'cnt' and 'registered' and 'casual'). \n\nWe won't use those for the model, since 'cnt' is derived from them (those numbers are added together to get 'cnt'), and we won't have that information when we want to make predictions for new rentals.\n\nOther factors such as temperature ('temp'), 'atemp' or 'hr' seem to highly correlate as well. ","6d1586e5":"The error has decreased significantly, for the parameters shown above. This shows the data has powerful non-linear relations and the decision trees model is able to capture them (unlike the linear model). Let's see how combining several DT models performs by repeating the process with Random Forests.","000d6970":"<a id='section14'><\/a>\n## Decision trees","397695c5":"<a id='section16'><\/a>\n## Results\nThe error improved when predicting 'registered' and 'casual' and adding them up instead of predicting 'cnt' directly. This shows the features used to train the models have stronger\/more accurate relations with the number of sign up and casual riders individually than with the sum of both.  ","a3dd8d80":"---\n<a id='section1'><\/a>\n# Introduction \nThis project aims to predict bike rentals using different Linear Regression, Decision Trees and Random Forests models, testing their performance on bike rentals data compiled by Hadi Fanaee-T at the University of Porto, which can be found at http:\/\/archive.ics.uci.edu\/ml\/datasets\/Bike+Sharing+Dataset.","fd0579ad":"# Table of contents\n*  [Introduction](#section1) \n*  [Read in the data](#section2)\n    - [Bike rentals, target column](#section3)\n*  [Feature engineering](#section4)\n    - [Time labels](#section5)\n    - [Weather index](#section6)\n*  [Train\/Test split](#section7)\n*  [Modeling and testing](#section8)\n    *  [Linear model](#section9) \n    *  [Decision trees](#section10) \n    *  [Random forests](#section11) \n*  [Another strategy](#section12) \n    *  [Linear model](#section13) \n    *  [Decision trees](#section14) \n    *  [Random forests](#section15) \n    *  [Results](#section16)\n    \nby @samaxtech","652e3c1e":"The error dicreased even more. Random Forests helps remove the sources of overfitting present in the Decision Trees model.","5e6b7626":"<a id='section5'><\/a>\n## Time labels\nThe column 'hr' contains the hour each rental occurred. If we want the model to take into account the relation between certain hours instead of treating them differently (and add more information for it to make better decisions), we could add a 'time_label' column, so that each label is represented by a number, such that:\n\n- Morning: 1\n- Afternoon: 2\n- Evening: 3\n- Night: 4","1e01f4ac":"---\n<a id='section7'><\/a>\n# Train\/Test split","fc98b4d2":"----\n<a id='section10'><\/a>\n## Decision Trees\nIn this case, to test different models I am going to tweak 'min_samples_leaf', 'min_samples_split' and 'max_depth' and see which one performs best.","3d5c9ea6":"<a id='section6'><\/a>\n## Weather index\nBy combining temperature, humidity, and wind speed we can create a weather index, an additional feature that's \nvaluable for the model. \n\nWeighting temperature and humidity in a way that makes sense for someone who's thinking about renting a bike based on those factors. After tweaking the weights (from 0 to 1), I've found 'temp' to be the feature that dicreases the error the most.","dca186b0":"----\n<a id='section4'><\/a>\n# Feature engineering","2ca07897":"---\n<a id='section9'><\/a>\n## Linear model","e3744171":"It looks like the linear model has a very high error. This could be because of very high or very low values in the data, that cause MSE to go up significantly. Let's see how using Decision Trees does with the same set of features.","23501d41":"<a id='section15'><\/a>\n## Random forests","5bd2eae4":"---\n<a id='section12'><\/a>\n# Another strategy\nFinally, it could be interesting to see how much better or worse each model performs when predicting 'casual' and 'registered', instead of 'cnt', considering their relation:\n\n- *'cnt' = 'casual' + 'registered'*.\n\nWe can predict these two and add them up to get 'cnt' and test the error.","28693a1e":"---\n<a id='section8'><\/a>\n# Modeling and testing\nGiven what was mentioned before about 'casual', and 'registered', those along with the target column 'cnt' and 'dteday' (the calendar day the bike was rented, in date format) will be excluded from the features.","8580ba9d":"<a id='section13'><\/a>\n## Linear model","3b1baffb":"<a id='section2'><\/a>\n# Read in the data","2f5d52f2":"---\n<a id='section11'><\/a>\n## Random forests"}}