{"cell_type":{"94cf4471":"code","79c42e81":"code","3fec58b6":"code","61b7dd52":"code","369049f5":"code","2b9753d1":"code","ad438ec2":"code","0040df49":"code","cdd00a16":"code","75c4f7d3":"code","7a9e82ca":"code","ec39d4f7":"code","c83b68c7":"code","d924ed7e":"code","af52c395":"code","91b02f10":"code","0bd248b1":"code","a0cd1174":"code","c6592678":"code","f92ab38c":"code","ef20e9d8":"code","108e3721":"code","bf98307f":"code","753eeda5":"code","fd27db5c":"code","889c26dc":"markdown","b1b007b8":"markdown"},"source":{"94cf4471":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","79c42e81":"#Loading and Preprocessing Data\n\n# Importing the training set\ndataset_train = pd.read_csv('..\/input\/traininggoogleprices\/TrainPrices.csv')\ndataset_train.head()","3fec58b6":"train = dataset_train.loc[:, [\"Open\"]].values\ntrain","61b7dd52":"# Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\ntrain_scaled = scaler.fit_transform(train)\ntrain_scaled","369049f5":"plt.plot(train_scaled)\nplt.show()","2b9753d1":"# Creating a data structure with 50 timesteps and 1 output\nX_train = []\ny_train = []\ntimesteps = 50\nfor i in range(timesteps, 1258):\n    X_train.append(train_scaled[i-timesteps:i, 0])\n    y_train.append(train_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)","ad438ec2":"# Reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_train[0:1]","0040df49":"y_train[0:1]","cdd00a16":"# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['accuracy'])\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 10, batch_size = 32)","75c4f7d3":"# Getting the real stock price of 2017\ndataset_test = pd.read_csv('..\/input\/google-stock-price\/Stock_Price_Test.csv')\ndataset_test.head()","7a9e82ca":"real_stock_price = dataset_test.loc[:, [\"Open\"]].values\nreal_stock_price","ec39d4f7":"# Getting the predicted stock price of 2017\ndataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values.reshape(-1,1)\ninputs = scaler.transform(inputs)  # min max scaler\n#inputs","c83b68c7":"X_test = []\nfor i in range(timesteps, 70):\n    X_test.append(inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n\n# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","d924ed7e":"import numpy\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","af52c395":"data = pd.read_csv('..\/input\/airline-passengers\/international-airline-passengers.csv',skipfooter=5)\ndata.head()","91b02f10":"dataset = data.iloc[:,1].values\nplt.plot(dataset)\nplt.xlabel(\"time\")\nplt.ylabel(\"Number of Passenger\")\nplt.title(\"international airline passenger\")\nplt.show()","0bd248b1":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype(\"float32\")\ndataset.shape","a0cd1174":"# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","c6592678":"train_size = int(len(dataset) * 0.50)\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(\"train size: {}, test size: {} \".format(len(train), len(test)))","f92ab38c":"time_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY)  ","ef20e9d8":"dataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)  ","108e3721":"trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","bf98307f":"# model\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(1, time_stemp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","753eeda5":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","fd27db5c":"# shifting train\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","889c26dc":"**Long Short Term Memory (LSTMs)**","b1b007b8":"[Kaan Can Y\u0131lmaz'\u0131n](https:\/\/www.udemy.com\/user\/kaan-can-yilmaz\/)\n\n* [Machine Learning ve Python: A'dan Z'ye Makine \u00d6\u011frenmesi](https:\/\/www.udemy.com\/machine-learning-ve-python-adan-zye-makine-ogrenmesi-4)\n\nkursundan \u00f6\u011frendiklerimi denedi\u011fim ve derledi\u011fim kernelimdir."}}