{"cell_type":{"102253b1":"code","04f83091":"code","e334dfe3":"code","e7c44d19":"code","ae15cdf1":"code","c08209f4":"code","1c6e4e76":"code","5799d1d0":"code","44b930d0":"code","ffb49538":"code","aeefe527":"markdown","0472c6f0":"markdown","70e4ad66":"markdown","f71b6f6b":"markdown","335b8dea":"markdown","489f2e85":"markdown","0532fd75":"markdown","5e221712":"markdown"},"source":{"102253b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer # Simple Imputer to fill in missing data\nfrom sklearn.ensemble import RandomForestRegressor # Random forest model\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","04f83091":"# The first step is reading in the provided training and the testing datasets\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","e334dfe3":"# print first few lines of data\ntrain.head()","e7c44d19":"# identify the classes with null values and get the quantity of cells lacking information\nmissing_counts = train.isnull().sum()\nprint(missing_counts[missing_counts>0])","ae15cdf1":"# drop the identified columns from training and testing data\nreduced_train = train.drop(['Cabin','Embarked'], axis=1)\nreduced_test = test.drop(['Cabin','Embarked'], axis=1)\n# print last few lines from reduced training dataset\nreduced_train.tail()","c08209f4":"# Imputing the Age feature\n# compute the mean ages - force them to be integers\navg_train_age = int(reduced_train.Age.mean())\navg_test_age = int(reduced_test.Age.mean())\n# perform the imputation\ntrain_imputer = SimpleImputer(strategy='constant',fill_value=avg_train_age)\nimputed_train = train_imputer.fit_transform(reduced_train)\ntest_imputer = SimpleImputer(strategy='constant',fill_value=avg_test_age)\nimputed_test = test_imputer.fit_transform(reduced_test)\n\n# convert back to dataframes\ntrain_new = pd.DataFrame(imputed_train,index=imputed_train[:,0],columns=reduced_train.columns)\ntest_new = pd.DataFrame(imputed_test,index=imputed_test[:,0],columns=reduced_test.columns)\n\n# print last few lines from new imputed training dataset\ntrain_new.tail()","1c6e4e76":"# Dropping the Name feature and the Ticket feature\ntrain_small = train_new.drop(['Name','Ticket'], axis=1)\ntest_small = test_new.drop(['Name','Ticket'],axis=1)\n\n# printing last few lines\ntrain_small.tail()","5799d1d0":"# numerically encoding the Sex feature\ntrain_small['Sex'] = train_small['Sex'].map( {'female' : 1, 'male' : 0} ).astype(int)\ntest_small['Sex'] = test_small['Sex'].map( {'female' : 1, 'male' : 0} ).astype(int)\n\n# printing last few lines\ntrain_small.tail()","44b930d0":"# break out data into x and y components\nx_features = ['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare']\ntrain_x = train_small[x_features]\ntest_x = test_small[x_features]\n\ntrain_y = train_small['Survived']\n\n# implementing the random forest\nforest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(train_x, train_y)\n\ntest_pred = forest_model.predict(test_x)","ffb49538":"# round and make predictions an array of integers\ntest_pred = np.round(test_pred).astype(int)\n\n# create submission dataframe then convert to csv\nsubmission = pd.DataFrame({\n        \"PassengerId\" : test_x[\"PassengerId\"],\n        \"Survived\": test_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","aeefe527":"## Goal\nGiven a list of passengers, the objective is to predict which passengers survived the sinking of the Titanic.","0472c6f0":"### Using the training data to fit a model\nThis cleaned up and reduced training data will be used to fit a Random Tree. At this time the Random Tree Regressor is being used for convenience and simplicity.","70e4ad66":"### Have to write the output of the model to a csv with the PassengerId tags as well\nFirst the output will be rounded, made binary, and converted to integers as survival is binary (either you survive or you don't). Then the csv will be written with the rounded values.","f71b6f6b":"To explore the data, we can print the first few lines and see what categories of information are provided for each passenger.","335b8dea":"### Resolving the *Age* feature\nI do not want to assume that the *Age* feature is unimportant to a given person's odds of survival because we know from historical accounts (and the movie) that women and children were prioritized passengers on the lifeboats. Therefore we might expect a correlation between age and probability of surviving. In this kernel, the simple imputer from sklearn will be applied to fill in missing *Age* values with the average age.","489f2e85":"### Dropping additional features\nAfter some thought, I elected to drop the *Name* feature as familial connections are established via the *SibSp* and *Parch* features, and names are also keyed in many different ways. The *Ticket* feature was also dropped as I do not expect a significant relationship between the ticket number and a person's chance of survival","0532fd75":"### Resolving missing values\nThe three features which have missing values are *Age*, *Cabin*, and *Embarked*. I am going to make a large assumption and jump to the conclusion that I don't care about the specific cabin someone booked, or the location from which they embarked upon the vessel. This judgement call is not supported by any statistics, but I am subjectively deciding that the *Cabin* and *Embarked* features have a negligible impact on a person's chances of surviving the Titanic.","5e221712":"### To remove the last string feature, the *Sex* category will be made binary (1 for female, 0 for male)"}}