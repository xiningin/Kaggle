{"cell_type":{"cff1620f":"code","47af89ab":"code","e6306c68":"code","1628a3cc":"code","7c367a17":"code","d21c2fe9":"code","b7dac3ce":"code","2524c3a2":"code","e4ff0247":"code","be606bfc":"code","a6c7f052":"code","95d9b4d2":"code","79852cc6":"code","efa7024d":"code","05039b0b":"code","bf4e9971":"code","ec467030":"code","603edc3c":"code","1370c70d":"code","557af54f":"code","8ac217e3":"code","d6b620ac":"code","87644c2d":"code","ce57c8c3":"code","968b2d3f":"code","5bfbc07d":"code","38c51afc":"code","9df4639c":"code","7014ed4d":"code","5f6d8806":"code","4c03b553":"code","d6dba0fe":"code","38dd58f9":"code","33c3f33e":"code","9016f831":"code","8a171807":"code","d6561deb":"code","7cbf8b4a":"code","09937703":"code","a9cf7796":"code","aac46b8b":"code","6b6e1565":"code","16ee75fa":"code","43bd4a6c":"code","38fbc750":"code","b77d1d56":"code","2fbd722c":"code","72fef2c4":"code","38c5294a":"code","2db85f27":"code","9fe2ba14":"code","5a73efe0":"code","aed0207f":"code","d86acbcb":"code","fc44e3ab":"code","8d2eedba":"code","201e245d":"code","e6b3ba33":"code","047327ca":"code","6cccb330":"code","aa71d495":"code","35df1298":"code","ebbceeb5":"code","6345eef1":"code","64d7ae2b":"markdown","0d870f0f":"markdown","ec00b21a":"markdown","c54d6f95":"markdown","12af17f5":"markdown","6d8f4857":"markdown","ef24f8e0":"markdown","294a017e":"markdown","0ab5af62":"markdown","c1549156":"markdown","44996799":"markdown","46046f03":"markdown","3a6a6902":"markdown","ac165a2e":"markdown","4db0d1af":"markdown","4462a8b6":"markdown","02453fb1":"markdown","cf42e20c":"markdown","afa37d94":"markdown","942ca31c":"markdown","e13d4b73":"markdown","72bcdc67":"markdown","f8a1e57d":"markdown","bac31751":"markdown","4e25b9ef":"markdown","d4f1acb7":"markdown","2d180a80":"markdown"},"source":{"cff1620f":"#Import library\n\n#Data Manipulation\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display\npd.options.display.float_format = '{:,.2f}'.format\n!pip install dfply\nfrom dfply import *\n\n#Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Genetic Algorithm - https:\/\/github.com\/deap\/deap\n!pip install deap\nfrom deap import base\nfrom deap import creator\nfrom deap import tools\n\n#Modelling\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom sklearn.model_selection import StratifiedKFold, learning_curve, cross_val_score\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\n!pip install catboost\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn import metrics \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n#Algorithms\nfrom sklearn import ensemble, tree, svm, naive_bayes, neighbors, linear_model, gaussian_process, neural_network\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\n# Model\nfrom sklearn.metrics import accuracy_score, f1_score, auc, roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\nfrom sklearn.ensemble import VotingClassifier\nfrom imblearn.pipeline import Pipeline\n\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import RandomUnderSampler\n\n#preprocessing :\nfrom sklearn.preprocessing import MinMaxScaler , StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n#File Management System\nimport os","47af89ab":"#Import Data\n\ntrain = pd.read_csv('..\/input\/peopleanalytic\/train.csv')\ntest = pd.read_csv('..\/input\/peopleanalytic\/test.csv')\n\nprint(\"Dimension of train : {}\".format(train.shape))\nprint(\"Dimension of test : {}\".format(test.shape))","e6306c68":"train.head(3)","1628a3cc":"test.head(3)","7c367a17":"test.info()","d21c2fe9":"train = train.rename(columns={\"Avg_achievement_%\": \"Avg_achievement\", \"Last_achievement_%\": \"Last_achievement\",\n                     \"Achievement_above_100%_during3quartal\": \"Achievement_above_1_during3quartal\"})\n\ntest = test.rename(columns={\"Avg_achievement_%\": \"Avg_achievement\", \"Last_achievement_%\": \"Last_achievement\",\n                     \"Achievement_above_100%_during3quartal\": \"Achievement_above_1_during3quartal\"})","b7dac3ce":"train_null = (train.isnull().sum() \/ len(train)) * 100\nprint(train_null)\ntrain_null = train_null.drop(train_null[train_null == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :train_null})\nms = (missing_data.head(30)).style.background_gradient(low=0,high=1,axis=0,cmap='Oranges')\nms","2524c3a2":"print(train['Employee_type'].unique())\nprint(test['Employee_type'].unique())","e4ff0247":"train['Employee_type'] = train['Employee_type'].fillna(train['Employee_type'].mode()[0])","be606bfc":"train['job_duration_as_permanent_worker'].describe()","a6c7f052":"train['job_duration_as_permanent_worker'].median()","95d9b4d2":"train['job_duration_as_permanent_worker'] = train['job_duration_as_permanent_worker'].fillna(4)","79852cc6":"print(train['GPA'].unique())\nprint(test['GPA'].unique())","efa7024d":"train['GPA'] = np.where((train['GPA'] > 4.0),np.nan,train['GPA'])\ntrain['GPA'] = np.where((train['GPA'] < 2.5),np.nan,train['GPA'])\n\ntest['GPA'] = np.where((test['GPA'] > 4.0),np.nan,test['GPA'])\ntest['GPA'] = np.where((test['GPA'] < 2.5),np.nan,test['GPA'])\n\nprint(train['GPA'].unique())\nprint(test['GPA'].unique())","05039b0b":"train['GPA'] = train['GPA'].fillna(train['GPA'].mean())\ntest['GPA'] = test['GPA'].fillna(test['GPA'].mean())","bf4e9971":"print(train['year_graduated'].unique())\nprint(test['year_graduated'].unique())","ec467030":"sampah_train = ['\\\\N', '201', '102', '____', '-', '0', '2044', '2201', \n          '9999', '2031', '3016', '2200', '2999', '9464', 'nan']\nsampah_test = ['\\\\N', '207', '0', '3.05', '3.18', '209', '1016', '2201', \n          '9999', '3013', '.', '2999']\ntrain['year_graduated'] = train['year_graduated'].replace(sampah_train,np.nan)\ntest['year_graduated'] = test['year_graduated'].replace(sampah_test,np.nan)\nprint(train['year_graduated'].unique())\nprint(test['year_graduated'].unique())","603edc3c":"train['year_graduated'] = train['year_graduated'].fillna(train['year_graduated'].mode()[0])\ntest['year_graduated'] = test['year_graduated'].fillna(test['year_graduated'].mode()[0])","1370c70d":"print(train['Education_level'].unique())\nprint(test['Education_level'].unique())","557af54f":"train['Education_level'] = train['Education_level'].fillna(train['Education_level'].mode()[0])","8ac217e3":"print(train['Avg_achievement'].unique())\ntrain['Avg_achievement'].describe()","d6b620ac":"train['Avg_achievement'] = train['Avg_achievement'].fillna(train['Avg_achievement'].mean())","87644c2d":"print(train['Last_achievement'].unique())\ntrain['Last_achievement'].describe()","ce57c8c3":"train['Last_achievement'] = train['Last_achievement'].fillna(train['Last_achievement'].mean())","968b2d3f":"print(train['Achievement_above_1_during3quartal'].unique())","5bfbc07d":"train['Achievement_above_1_during3quartal'] = train['Achievement_above_1_during3quartal'].fillna(train['Achievement_above_1_during3quartal'].mode()[0])","38c51afc":"print(train['achievement_target_1'].unique())","9df4639c":"train['achievement_target_1'] = train['achievement_target_1'].fillna(train['achievement_target_1'].mode()[0])","7014ed4d":"print(train['achievement_target_2'].unique())","5f6d8806":"train['achievement_target_2'] = np.where((train['achievement_target_2'] == 'achiev_< 50%'),'Pencapaian < 50%',train['achievement_target_2'])\ntrain['achievement_target_2'] = np.where((train['achievement_target_2'] == 'achiev_50%-100%'),'Pencapaian 50%-100%',train['achievement_target_2'])\ntrain['achievement_target_2'] = np.where((train['achievement_target_2'] == 'achiev_100%-150%'),'Pencapaian 100%-150%',train['achievement_target_2'])\ntrain['achievement_target_2'] = np.where((train['achievement_target_2'] == 'achiev_> 1.5'),'Pencapaian > 150%',train['achievement_target_2'])\ntrain['achievement_target_2'] = np.where((train['achievement_target_2'] == 'Pencapaian > 1.5'),'Pencapaian > 150%',train['achievement_target_2'])\n\ntest['achievement_target_2'] = np.where((test['achievement_target_2'] == 'achiev_< 50%'),'Pencapaian < 50%',test['achievement_target_2'])\ntest['achievement_target_2'] = np.where((test['achievement_target_2'] == 'achiev_50%-100%'),'Pencapaian 50%-100%',test['achievement_target_2'])\ntest['achievement_target_2'] = np.where((test['achievement_target_2'] == 'achiev_100%-150%'),'Pencapaian 100%-150%',test['achievement_target_2'])\ntest['achievement_target_2'] = np.where((test['achievement_target_2'] == 'achiev_> 1.5'),'Pencapaian > 150%',test['achievement_target_2'])\ntest['achievement_target_2'] = np.where((test['achievement_target_2'] == 'Pencapaian > 1.5'),'Pencapaian > 150%',test['achievement_target_2'])","4c03b553":"train['achievement_target_2'] = train['achievement_target_2'].fillna(train['achievement_target_2'].mode()[0])","d6dba0fe":"print(train['achievement_target_3'].unique())\nprint(test['achievement_target_3'].unique())\ntrain['achievement_target_3'] = np.where((train['achievement_target_3'] == 'not reached'),'not_reached',train['achievement_target_3'])\ntest['achievement_target_3'] = np.where((test['achievement_target_3'] == 'not reached'),'not_reached',test['achievement_target_3'])","38dd58f9":"print(train['achievement_target_3'].unique())\nprint(test['achievement_target_3'].unique())","33c3f33e":"train['achievement_target_3'] = train['achievement_target_3'].fillna(train['achievement_target_3'].mode()[0])","9016f831":"plt.rcParams['figure.figsize'] = (18, 7)\n\nplt.subplot(1, 2, 1)\nsns.countplot(train['Best Performance'], palette = 'muted')\nplt.title('Baik atau Tidak', fontsize = 30)\nplt.xlabel('Performance', fontsize = 15)\nplt.ylabel('count', fontsize = 15)","8a171807":"plt.figure(figsize=(30, 30))\nsns.heatmap(train.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})","d6561deb":"traincor = train.drop(['job_duration_in_current_person_level', 'job_duration_from_training',\n        'age', 'Avg_achievement', 'job_duration_in_current_job_level','job_rotation',\n        'number_of_dependences', 'branch_rotation', 'Last_achievement'], axis = 1)\nplt.figure(figsize=(30, 30))\nsns.heatmap(traincor.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})","7cbf8b4a":"train['usia'] = 2020 - train['age']\ntest['usia'] = 2020 - test['age']\n\nprint(train['usia'].head())\nprint(test['usia'].head())","09937703":"train['lama_studi'] = train['year_graduated'].astype(int) - train['age']\ntest['lama_studi'] = test['year_graduated'].astype(int) - test['age']\n\nprint(train['lama_studi'].head())\nprint(test['lama_studi'].head())","a9cf7796":"keluarga = 2 + train['number_of_dependences'] + train['number_of_dependences (male)'] + train['number_of_dependences (female)']\nsingle = 1\n\ntrain.loc[train['marital_status_maried(Y\/N)'] == 'Y', 'keluarga'] = keluarga\ntrain.loc[train['marital_status_maried(Y\/N)'] != 'Y', 'keluarga'] = single\n    \ntest.loc[test['marital_status_maried(Y\/N)'] == 'Y', 'keluarga'] = keluarga\ntest.loc[test['marital_status_maried(Y\/N)'] != 'Y', 'keluarga'] = single\n\nprint(train['keluarga'].head())\nprint(test['keluarga'].head())","aac46b8b":"print(test['keluarga'].median())\ntest['keluarga'] = test['keluarga'].fillna(2)","6b6e1565":"train['lama_bekerja'] = train['job_duration_as_permanent_worker'] + train['job_duration_from_training']\ntest['lama_bekerja'] = test['job_duration_from_training'] + test['job_duration_as_permanent_worker']","16ee75fa":"train['ratio_lama_kerja'] = train['lama_bekerja']\/train['job_rotation']\ntest['ratio_lama_kerja'] = test['lama_bekerja']\/test['job_rotation']","43bd4a6c":"train['ratio_lama_kerja'] = train['ratio_lama_kerja'].replace([np.inf, -np.inf], np.nan)\ntest['ratio_lama_kerja'] = test['ratio_lama_kerja'].replace([np.inf, -np.inf], np.nan)","38fbc750":"train['ratio_lama_kerja'] = train['ratio_lama_kerja'].fillna(train['ratio_lama_kerja'].mean())\ntest['ratio_lama_kerja'] = test['ratio_lama_kerja'].fillna(test['ratio_lama_kerja'].mean())","b77d1d56":"train['lama_pindah_unit'] = train['lama_bekerja']\/train['branch_rotation']\ntest['lama_pindah_unit'] = test['lama_bekerja']\/test['branch_rotation']","2fbd722c":"train['lama_pindah_unit'] = train['lama_pindah_unit'].replace([np.inf, -np.inf], np.nan)\ntest['lama_pindah_unit'] = test['lama_pindah_unit'].replace([np.inf, -np.inf], np.nan)","72fef2c4":"train['lama_pindah_unit'] = train['lama_pindah_unit'].fillna(train['lama_pindah_unit'].mean())\ntest['lama_pindah_unit'] = test['lama_pindah_unit'].fillna(test['lama_pindah_unit'].mean())","38c5294a":"train['lama_rotasi_penugasan'] = train['lama_bekerja']\/train['assign_of_otherposition']\ntest['lama_rotasi_penugasan'] = test['lama_bekerja']\/test['assign_of_otherposition']","2db85f27":"train['lama_rotasi_penugasan'] = train['lama_rotasi_penugasan'].replace([np.inf, -np.inf], np.nan)\ntest['lama_rotasi_penugasan'] = test['lama_rotasi_penugasan'].replace([np.inf, -np.inf], np.nan)","9fe2ba14":"train['lama_rotasi_penugasan'] = train['lama_rotasi_penugasan'].fillna(train['lama_rotasi_penugasan'].mean())\ntest['lama_rotasi_penugasan'] = test['lama_rotasi_penugasan'].fillna(test['lama_rotasi_penugasan'].mean())","5a73efe0":"train.loc[train['keluarga'] > 2, 'memiliki_anak'] = 1\ntrain.loc[train['keluarga'] <= 2, 'memiliki_anak'] = 0\n\ntest.loc[test['keluarga'] > 2, 'memiliki_anak'] = 1\ntest.loc[test['keluarga'] <= 2, 'memiliki_anak'] = 0","aed0207f":"train['lama_tidak_masuk_kerja'] = train['sick_leaves']+train['annual leave']\ntest['lama_tidak_masuk_kerja'] = test['sick_leaves']+test['annual leave']","d86acbcb":"#test\ntest_null = (test.isnull().sum() \/ len(test)) * 100\nprint(test_null)\ntest_null = test_null.drop(test_null[test_null == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :test_null})\nms = (missing_data.head(30)).style.background_gradient(low=0,high=1,axis=0,cmap='Oranges')\nms","fc44e3ab":"#train\ntrain_null = (train.isnull().sum() \/ len(train)) * 100\nprint(train_null)\ntrain_null = train_null.drop(train_null[train_null == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :train_null})\nms = (missing_data.head(30)).style.background_gradient(low=0,high=1,axis=0,cmap='Oranges')\nms","8d2eedba":"test.columns","201e245d":"train = train.drop(columns=['age', 'year_graduated', 'number_of_dependences',\n                    'number_of_dependences (male)','number_of_dependences (female)',\n                    'marital_status_maried(Y\/N)','job_duration_as_permanent_worker',\n                    'job_duration_from_training','job_rotation','branch_rotation',\n                    'assign_of_otherposition', 'sick_leaves','annual leave'])\ntest = test.drop(columns=['age', 'year_graduated', 'number_of_dependences',\n                    'number_of_dependences (male)','number_of_dependences (female)',\n                    'marital_status_maried(Y\/N)','job_duration_as_permanent_worker',\n                    'job_duration_from_training','job_rotation','branch_rotation',\n                    'assign_of_otherposition', 'sick_leaves','annual leave'])","e6b3ba33":"#Train\nlabel_encode = LabelEncoder()\nfor i in train.select_dtypes(['object']):\n    train[i]=label_encode.fit_transform(train[i])\nprint(train.head())  \n\n#Test\nlabel_encode = LabelEncoder()\nfor i in test.select_dtypes(['object']):\n    test[i]=label_encode.fit_transform(test[i])\nprint(test.head()) ","047327ca":"X = train.drop(['Best Performance'], axis=1)\ny = train['Best Performance']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=66)","6cccb330":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","aa71d495":"def weighted_auc(y_true, y_valid):\n    tpr_thresholds = [0.0, 0.4, 1.0]\n    weights =        [       2,   1]\n    \n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_valid, pos_label=1)\n    \n    # size of subsets\n    areas = np.array(tpr_thresholds[1:]) - np.array(tpr_thresholds[:-1])\n    \n    # The total area is normalized by the sum of weights such that the final weighted AUC is between 0 and 1.\n    normalization = np.dot(areas, weights)\n    \n    competition_metric = 0\n    for idx, weight in enumerate(weights):\n        y_min = tpr_thresholds[idx]\n        y_max = tpr_thresholds[idx + 1]\n        mask = (y_min < tpr) & (tpr < y_max)\n\n        x_padding = np.linspace(fpr[mask][-1], 1, 100)\n\n        x = np.concatenate([fpr[mask], x_padding])\n        y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n        y = y - y_min # normalize such that curve starts at y=0\n        score = metrics.auc(x, y)\n        submetric = score * weight\n        best_subscore = (y_max - y_min) * weight\n        competition_metric += submetric\n        \n    return competition_metric \/ normalization","35df1298":"classifications = [\n    ensemble.AdaBoostClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n    gaussian_process.GaussianProcessClassifier(),\n    linear_model.LogisticRegressionCV(),\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    neighbors.KNeighborsClassifier(),\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    xgb.XGBClassifier()\n    ]\n\nresult_model = pd.DataFrame(columns = ['Method', 'roc_auc_score', 'weighted_auc_score'])\nresult_model","ebbceeb5":"for model in classifications:\n#     model.fit(X_train, y_train)\n#     y_score = model.predict_proba(X_test)[:,1]\n    \n    method = str(type(model)).split('.')[-1][:-2]\n    \n#     #roc_auc_score\n#     roc_auc_score_ = roc_auc_score(y_test, y_score)\n#     roc_auc_score_ = roc_auc_score_.item()\n    \n    # define resampling\n    resample = RandomUnderSampler()\n    # define pipeline\n    pipeline = Pipeline(steps=[('r', resample), ('m', model)])\n    #make model\n    pipeline.fit(X_train, y_train)\n    #model predict\n    y_score = pipeline.predict_proba(X_test)[:,1]\n    # define evaluation procedure\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    # evaluate model\n    scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n    #weighted auc\n    weight_auc = weighted_auc(y_test, y_score)\n    # output\n    final_pred = pipeline.predict_proba(test)[:, 1]\n    submission_svc = pd.DataFrame()\n    submission_svc[\"index\"] = test.index\n    submission_svc[\"Best Performance\"] = final_pred\n    submission_svc.to_csv('predik '+ method +'.csv', index=False)\n\n    result_model = result_model.append({\n        'Method': method,\n        'roc_auc_score': mean(scores),\n        'weighted_auc_score': weight_auc,\n    },ignore_index=True)\n    \nresult_model","6345eef1":"#Plot them\ng = sns.barplot(\"weighted_auc_score\", \"Method\", data = result_model)\ng.set_xlabel(\"Weighted AUC Score\")\ng = g.set_title(\"Algorithm Scores\")","64d7ae2b":"# Lama studi","0d870f0f":"### achievement_target_1","ec00b21a":"### cek NaN sebelum permodelan","c54d6f95":"# Modelling","12af17f5":"### Achievement_above_1_during3quartal","6d8f4857":"### lama penugasan","ef24f8e0":"### Last_achievement","294a017e":"### lama pindah unit","0ab5af62":"### year_graduated","c1549156":"### achievement_target_3","44996799":"### GPA","46046f03":"## 2. Preprocessing","3a6a6902":"### Employee_type","ac165a2e":"### achievement_target_2","4db0d1af":"### Education_level","4462a8b6":"# Feature Enginering","02453fb1":"## Usia","cf42e20c":"### job_duration_as_permanent_worker","afa37d94":"# 3. Exploratory Data Analyze","942ca31c":"### ratio lama kerja","e13d4b73":"# Import Data","72bcdc67":"### Avg_achievement\t","f8a1e57d":"### memiliki anak","bac31751":"# Label Encode","4e25b9ef":"### lama tidak masuk kerja","d4f1acb7":"### Keluarga","2d180a80":"### lama kerja"}}