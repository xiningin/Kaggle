{"cell_type":{"70b00445":"code","8f07821d":"code","e22b49f4":"code","45680afd":"code","18701657":"code","679ca45a":"code","80b3be2a":"code","4f5f5de0":"code","17865555":"code","a28b4ca4":"code","e99f5444":"code","965e3e34":"code","0b8ed310":"code","72b12d28":"code","2fc81b63":"code","9ce757d3":"code","93dad4d5":"code","41e25772":"code","b8630779":"markdown","fe9a4627":"markdown","5df11ed2":"markdown","6cef93da":"markdown","84e1a114":"markdown","de9733e2":"markdown","a015498a":"markdown","80146a67":"markdown"},"source":{"70b00445":"import pandas as pd\nimport numpy as np\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport glob","8f07821d":"from IPython import display\n\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport time\nimport os","e22b49f4":"top_path = '..\/input\/handwritten-math-symbol-dataset\/train\/'\nsymbols = os.listdir(top_path)","45680afd":"idx_to_name = {i:x for (i,x) in enumerate(symbols)}\nname_to_idx = {x:i for (i,x) in enumerate(symbols)}\nidx_to_name","18701657":"data = []\nlabels = []\ndim = (28,28)\n\nfor symbol in symbols:\n    path = top_path + symbol + \"\/*\"\n    imgs = [cv2.resize(cv2.imread(img, cv2.IMREAD_GRAYSCALE), dim, interpolation=cv2.INTER_AREA) for img in glob.glob(path)]\n    for img in imgs:\n        data.append(img)\n        labels.append(name_to_idx[symbol])","679ca45a":"# normalize data\ndata = np.array(data)\ndata = data \/ 255.0\ndata = data.astype('float32')\ndata = data.reshape(len(data), 28, 28, 1)\n\n# one hot encoding labels\nlabels = np.eye(len(name_to_idx))[labels]","80b3be2a":"split_limit = int(len(data) - len(data) * 0.3)","4f5f5de0":"train_images, test_images = data[:split_limit], data[split_limit:]","17865555":"train_size = 60000\nbatch_size = 32\ntest_size = 10000","a28b4ca4":"train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n                 .shuffle(train_size).batch(batch_size))\ntest_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n                .shuffle(test_size).batch(batch_size))","e99f5444":"class CVAE(tf.keras.Model):\n    def __init__(self, latent_dim):\n        super(CVAE, self).__init__()\n        self.latent_dim = latent_dim\n        self.encoder = tf.keras.Sequential(\n            [\n                tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n                tf.keras.layers.Conv2D(\n                    filters=16, kernel_size=3, strides=(2, 2), activation='relu'),\n                tf.keras.layers.Conv2D(\n                    filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n                tf.keras.layers.Flatten(),\n                # No activation\n                tf.keras.layers.Dense(latent_dim + latent_dim),\n            ]\n        )\n\n        self.decoder = tf.keras.Sequential(\n            [\n                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n                tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n                tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n                tf.keras.layers.Conv2DTranspose(\n                    filters=32, kernel_size=3, strides=2, padding='same',\n                    activation='relu'),\n                tf.keras.layers.Conv2DTranspose(\n                    filters=16, kernel_size=3, strides=2, padding='same',\n                    activation='relu'),\n                # No activation\n                tf.keras.layers.Conv2DTranspose(\n                    filters=1, kernel_size=3, strides=1, padding='same'),\n            ]\n        )\n\n    @tf.function\n    def sample(self, eps=None):\n        if eps is None:\n            eps = tf.random.normal(shape=(100, self.latent_dim))\n        return self.decode(eps, apply_sigmoid=True)\n    \n    def encode(self, x):\n        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n        return mean, logvar\n    \n    def reparameterize(self, mean, logvar):\n        eps = tf.random.normal(shape=mean.shape)\n        return eps * tf.exp(logvar * .5) + mean\n    \n    def decode(self, z, apply_sigmoid=False):\n        logits = self.decoder(z)\n        if apply_sigmoid:\n            probs = tf.sigmoid(logits)\n            return probs\n        return logits","965e3e34":"optimizer = tf.keras.optimizers.Adam(1e-4)\n\ndef log_normal_pdf(sample, mean, logvar, raxis=1):\n    log2pi = tf.math.log(2. * np.pi)\n    return tf.reduce_sum(\n      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n      axis=raxis)\n\ndef compute_loss(model, x):\n    mean, logvar = model.encode(x)\n    z = model.reparameterize(mean, logvar)\n    x_logit = model.decode(z)\n    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n    logpz = log_normal_pdf(z, 0., 0.)\n    logqz_x = log_normal_pdf(z, mean, logvar)\n    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n\n@tf.function\ndef train_step(model, x, optimizer):\n  \"\"\"Executes one training step and returns the loss.\n\n  This function computes the loss and gradients, and uses the latter to\n  update the model's parameters.\n  \"\"\"\n  with tf.GradientTape() as tape:\n    loss = compute_loss(model, x)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))","0b8ed310":"epochs = 500\n# dimensionality of the latent space\nlatent_dim = 2\nnum_examples_to_generate = 16\n\n# random vector constant for generation\nrandom_vector_for_generation = tf.random.normal(\n    shape=[num_examples_to_generate, latent_dim])\nmodel = CVAE(latent_dim)","72b12d28":"def generate_and_save_images(model, epoch, test_sample):\n    mean, logvar = model.encode(test_sample)\n    z = model.reparameterize(mean, logvar)\n    predictions = model.sample(z)\n    fig = plt.figure(figsize=(4, 4))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i + 1)\n        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n        plt.axis('off')\n\n    # tight_layout minimizes the overlap between 2 sub-plots\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","2fc81b63":"# Pick a sample of the test set for generating output images\nassert batch_size >= num_examples_to_generate\nfor test_batch in test_dataset.take(1):\n    test_sample = test_batch[0:num_examples_to_generate, :, :, :]","9ce757d3":"generate_and_save_images(model, 0, test_sample)\n\nfor epoch in range(1, epochs + 1):\n    start_time = time.time()\n    for train_x in train_dataset:\n        train_step(model, train_x, optimizer)\n    end_time = time.time()\n\n    loss = tf.keras.metrics.Mean()\n    for test_x in test_dataset:\n        loss(compute_loss(model, test_x))\n    elbo = -loss.result()\n    display.clear_output(wait=False)\n    if(epoch % 100 == 0):\n        print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n            .format(epoch, elbo, end_time - start_time))\n        generate_and_save_images(model, epoch, test_sample)","93dad4d5":"def plot_latent_images(model, n, digit_size=28):\n    \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n\n    norm = tfp.distributions.Normal(0, 1)\n    grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n    grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n    image_width = digit_size*n\n    image_height = image_width\n    image = np.zeros((image_height, image_width))\n\n    for i, yi in enumerate(grid_x):\n        for j, xi in enumerate(grid_y):\n            z = np.array([[xi, yi]])\n            x_decoded = model.sample(z)\n            digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n            image[i * digit_size: (i + 1) * digit_size,\n                j * digit_size: (j + 1) * digit_size] = digit.numpy()\n\n    plt.figure(figsize=(20, 20))\n    plt.imshow(image, cmap='Greys_r')\n    plt.axis('Off')\n    plt.show()","41e25772":"plot_latent_images(model, 20)","b8630779":"# Training","fe9a4627":"# Convolutional Variational Autoencoder using Handwritten Math Symbols","5df11ed2":"# Convolutional VAE","6cef93da":"# VAE Architecture","84e1a114":"<img align=left src='https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/28\/Autoencoder_structure.png'>","de9733e2":"# Data Preparation","a015498a":"# Loss function and optimizer","80146a67":"# 2D manifold Results"}}