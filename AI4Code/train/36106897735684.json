{"cell_type":{"36e4cade":"code","9467247c":"code","89f11e69":"code","94f87785":"code","889771f7":"code","9c6ff269":"code","bd4b052d":"code","acf1ea51":"code","118c91b3":"code","1aaf341e":"code","e6904736":"code","e2e389eb":"code","b679a2cc":"code","5e87b767":"markdown","d68453a2":"markdown","456a3c8c":"markdown","0ee8f3ce":"markdown","42e21ff7":"markdown","9d9f111f":"markdown","b17b43fd":"markdown","88b545af":"markdown","f3f71745":"markdown","ff79ccdf":"markdown","53a7b80f":"markdown","4deebdf2":"markdown","bead353d":"markdown"},"source":{"36e4cade":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nfrom sklearn.metrics import r2_score, explained_variance_score\n","9467247c":"dataset = pd.read_csv('..\/input\/predict-test-scores-of-students\/test_scores.csv')\ndataset.head()","89f11e69":"dataset.drop(['school', 'classroom', 'student_id'], axis = 1, inplace = True)\nsns.pairplot(dataset, hue = \"gender\")\ndataset.head()","94f87785":"x = dataset.iloc[:,0:7].values\ny = dataset.iloc[:, -1].values","889771f7":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nlbl_X = preprocessing.LabelEncoder()\nx[:,0] = lbl_X.fit_transform(x[:,0])\nx[:,1] = lbl_X.fit_transform(x[:,1])\nx[:, 2] = lbl_X.fit_transform(x[:, 2])\nx[:, 4] = lbl_X.fit_transform(x[:, 4])\nx[:,5] = lbl_X.fit_transform(x[:,5])","9c6ff269":"ct = ColumnTransformer(\n    [('one_hot_encoder', OneHotEncoder(categories='auto'),[0])],\n                        remainder = 'passthrough')\nx = np.array(ct.fit_transform(x), dtype = float)\n\nx = x[:, 1:]","bd4b052d":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 5)","acf1ea51":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nx_train, x_test = sc_x.fit_transform(x_train), sc_x.transform(x_test)","118c91b3":"from sklearn.svm import SVR\nregressor = SVR(gamma = 0.1).fit(x_train, y_train)\ny_pred = regressor.predict(x_test)\n#r2_score(y_test, y_pred)\nprint (explained_variance_score(y_test, y_pred), y_pred.std())","1aaf341e":"from xgboost import XGBRegressor\nregressor2 = XGBRegressor().fit(x_train, y_train)\ny_pred2 = regressor2.predict(x_test)\nprint (explained_variance_score(y_test, y_pred2), y_pred2.std())","e6904736":"from xgboost import XGBRFRegressor\nregressor3 = XGBRFRegressor(n_estimators  = 200, booster = 'gbtree', gamma = 0.1).fit(x_train, y_train)\ny_pred3 = regressor3.predict(x_test)\nprint (explained_variance_score(y_test, y_pred3), y_pred3.std())\n","e2e389eb":"from sklearn.linear_model import LinearRegression\nregressor4 = LinearRegression().fit(x_train, y_train)\ny_pred4 = regressor4.predict(x_test)\nprint (explained_variance_score(y_test, y_pred), y_pred4.std())","b679a2cc":"from sklearn.linear_model import LogisticRegression\nregressor5 = LogisticRegression(n_jobs= 4, random_state = 5).fit(x_train, y_train)\ny_pred5 = regressor5.predict(x_test)\nprint (explained_variance_score(y_test, y_pred5), y_pred5.std())","5e87b767":"**Logistic Regression**","d68453a2":"**XGBRFRegressor**","456a3c8c":"Dividing between training and testing   - - - - - - Dividiendo el conjunto entre entrenamiento y test","0ee8f3ce":"**Linear Regression**","42e21ff7":"# **Regression models**   Modelos de Regresion","9d9f111f":"Dividing the data set between X and Y - - - - - - - - Dividiendo el dataset entre los valores de X y Y","b17b43fd":"We can observe that the 3 main models resemble their explained variation and have a good prediction percentage, however (even if it is very little) we can observe that some models have a greater explained variation but in turn we must take into account their standard deviation that will indicate to us how much the model can go wrong\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nPodemos observar que los 3 principales modelos se asemejan a su variacion explicada y tienen un buen porcentaje de predicci\u00f3n, sin embargo (aunque sea muy poco) podemos observar que algunos modelos tienen una mayor variacion explicada pero a su vez debemos tener en cuenta su desviaci\u00f3n estandar que nos indicara que tanto puede llegar a equivocarse el modelo","88b545af":"**XGBRegressor**","f3f71745":"# Conclusions    - - - - - - - - - - - - - Conclusiones","ff79ccdf":"converting categorical variables to numeric  - - - - - - - - - - - - - Convirtiendo variables categoricas a numericas","53a7b80f":"#                                            **Data exploration**   - - - - - - - - - - - - - Exploraci\u00f3n de los datos ","4deebdf2":"Variable scaling  - - - - - - - - - - - -  Escalado de variables","bead353d":"**Support Vector Regressor**"}}