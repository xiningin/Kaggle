{"cell_type":{"be3bfd84":"code","56329f44":"code","7807d0c1":"code","9a3df9fe":"code","d4348099":"code","f364e969":"code","beece0c4":"code","6426ef46":"code","e20cf681":"code","a57d2b97":"code","1b596c0b":"code","5431030e":"code","2006e444":"code","17b96a9a":"code","e3db8e94":"code","f2ac4835":"code","594158ee":"code","74f0d685":"code","a6df1630":"code","20fc3249":"code","298d100f":"code","4af3a380":"code","a9b26bc7":"code","da2d461a":"code","91f5df58":"code","e4a32617":"code","cd827896":"code","a88b02a1":"code","a8ba7ec5":"code","5e663271":"code","23b89ef8":"code","2dced396":"code","d80eca3a":"code","c93acd0e":"code","1c89a59d":"code","39bfc936":"code","c540bbf8":"code","fbe1c365":"code","e12fd93b":"code","a7bd600b":"code","7846b5a3":"code","d57019e5":"code","2ed67bd8":"code","6100a776":"code","d382848a":"code","e6f80988":"code","cba6459f":"code","e5c8e2cd":"code","171eef40":"code","547851b2":"code","56e14ad4":"code","616b3aaf":"code","0c71ddd8":"code","1d915053":"code","1a71ec97":"code","19f0cbf3":"code","08f9b733":"code","500c5ae8":"code","6bc797fd":"code","14f90ce7":"code","7a665ebb":"code","f6440205":"code","7b551c19":"code","0dd06f18":"code","e65bfade":"code","cb1fdb13":"code","f868fb2f":"code","4e63473e":"code","830ef216":"code","91209438":"code","46fdb5ef":"code","85af54cb":"code","5893cbaf":"code","69070cfd":"code","eb757424":"code","02bbbf46":"code","46476a25":"code","e021c1a9":"markdown","5e3e434f":"markdown","88085c4c":"markdown","c6a75714":"markdown","aef8ae75":"markdown","1beec5e3":"markdown","a530f2e4":"markdown","d98491c8":"markdown","5f796a13":"markdown","f6b5c4aa":"markdown","bf7d8610":"markdown","5be3a618":"markdown","fb1bd14d":"markdown","8883ceab":"markdown","18468d1b":"markdown","598bfadc":"markdown","a5ed56e9":"markdown","f0e29e3c":"markdown","069022fc":"markdown","5d40dc61":"markdown","4409cf93":"markdown","a5cdb8c8":"markdown","11c7250d":"markdown","21750770":"markdown","098b4c89":"markdown","00fb2ac6":"markdown","86662248":"markdown","67886a5b":"markdown","4f4cdbb6":"markdown","a393cc07":"markdown","ed22c4c5":"markdown","74fb025c":"markdown","7edf37e5":"markdown","3d8db87a":"markdown","b451f63e":"markdown","76577f11":"markdown","7e83ec66":"markdown","3b1df337":"markdown","2da95f54":"markdown"},"source":{"be3bfd84":"\"\"\"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\"\"\"","56329f44":"# Loading the dependencies\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\nimport random\nimport cv2","7807d0c1":"# Loading csv file\ndf = pd.read_csv(\"..\/input\/understanding_cloud_organization\/train.csv\")","9a3df9fe":"df.head()","d4348099":"# Exploring the data\n# But this is the total number of labels that\n# can be assigned to whole of the dataset\nprint(f\"The number of data points {len(df)}\")","f364e969":"# Null values in each of the columns\ndf.isna().sum().plot(kind=\"bar\")","beece0c4":"# Percentage of null values\nsize = [len(df)-df.EncodedPixels.count(),df.EncodedPixels.count()]\nplt.figure(figsize=(8,8))\nplt.pie(size, labels=[\"empty\",\"Non-empty\"],explode=(0,0.1), autopct=\"%1.1f\")\nplt.title(\"Null value percentage\")  ","6426ef46":"# Replacing the nan values with 0s\ndf[\"EncodedPixels\"] = df['EncodedPixels'].fillna(-1)","e20cf681":"# creating a new columns with label\ndf[\"Label\"] = df[\"Image_Label\"].apply(lambda x: x.split(\"_\")[1])\ndf.head()","a57d2b97":"# Creating an new feature with just the image names\ndf[\"Image_name\"] = df[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])\n#df.drop(\"Image_Label\",axis=1,inplace=True)\ndf.head()","1b596c0b":"# Lets check the number of each corresponding labels\ndef check_num(label):\n  return df[(df[\"Label\"]==label) & (df[\"EncodedPixels\"]!=-1)][\"EncodedPixels\"].count()\n\nvalues = {}\nfor i in df.Label.unique():\n  values[i] = check_num(i)\n\nprint(values)\nplt.title(\"Number of each classes\")\npd.Series(values).plot(kind=\"bar\")","5431030e":"# Creating a dataframe of images and classes in each images\ndef dummy_var(label):\n  values = []\n  df_temp = df[df[\"Label\"]==label]\n  df_temp[\"Dummy\"] = df_temp[\"EncodedPixels\"].apply(lambda x: 1 if x!=-1 else 0)\n  return list(df_temp[\"Dummy\"])\n\ndf_images = pd.DataFrame()\ndf_images[\"Image\"] = df[\"Image_name\"].unique()\nfor i in df[\"Label\"].unique():\n  df_images[i] = dummy_var(i)\n\ndf_images.head()","2006e444":"# Number of images available for us\nprint(f\"Number of images: {len(df_images)}\")","17b96a9a":"# Number of detections per images\ndf_images[\"Total\"] = df_images[\"Fish\"]+df_images[\"Flower\"]+df_images[\"Gravel\"]+df_images[\"Sugar\"]\nplt.title(\"Number of labels per image\")\nsns.countplot(df_images[\"Total\"])","e3db8e94":"# Create one column for each mask\ntrain_df = pd.pivot_table(df, index=['Image_name'], values=['EncodedPixels'], columns=['Label'], aggfunc=np.min).reset_index()\ntrain_df.columns = ['image', 'Fish_mask', 'Flower_mask', 'Gravel_mask', 'Sugar_mask']\n\ntrain_df.head()","f2ac4835":"# dimenesions of image \nwidth = 2100\nheight = 1400","594158ee":"# Function to decode the encoded pixels\ndef decode_pixels(pix, rows=2100, cols=1400,label=255):\n  # coverting the string into a list of numbers\n  rle_numbers = [int(num_string) for num_string in pix.split(' ')]\n  # Coverting them into starting index and length pairs\n  rle_pairs = np.array(rle_numbers).reshape(-1,2)\n  # Creating a blank image in form of a single row array\n  img = np.zeros(rows*cols, dtype=np.uint8)\n\n  # Setting the segmented pixels in the img\n  for ind, length in rle_pairs:\n    ind -= 1\n    img[ind:ind+length] = label\n  img = img.reshape(rows,cols)\n  img = img.T\n  return img\n","74f0d685":"# Testing the function out\nseg = decode_pixels(df[\"EncodedPixels\"][4])\nseg = cv2.resize(seg, (1050,700))\nplt.imshow(seg)","a6df1630":"# Sample of the segment regions\nplt.figure(figsize=(15,8))\nj = 0\nfor i in range(6):\n  plt.subplot(2,3,i+1)\n  while True:\n    if df[\"EncodedPixels\"][j]!=-1:\n      break\n    j+=1\n  plt.imshow(decode_pixels(df[\"EncodedPixels\"][j]))\n  plt.title(df[\"Image_name\"][j]+\"_\"+df[\"Label\"][j])\n  j+=1\n  plt.xticks([])\n  plt.yticks([])\nplt.show()","20fc3249":"# location of img directory\nimg_dir = \"..\/input\/understanding_cloud_organization\/train_images\"","298d100f":"# Seeing the cloumns of train.csv\ndf.columns","4af3a380":"# Looking at any one image name\ndf[\"Image_name\"].unique()[10]","a9b26bc7":"# Displaying one image\npath = os.path.join(img_dir,df[\"Image_name\"][0])\nimg = cv2.imread(path,1)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)","da2d461a":"# Displaying sample images\nimgs = df[\"Image_name\"].unique()[:6]\nplt.figure(figsize=(15,8))\nfor i in range(len(imgs)):\n  plt.subplot(2,3,i+1)\n  path = os.path.join(img_dir,imgs[i])\n  img = cv2.imread(path,1)\n  plt.title(imgs[i])\n  plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\nplt.show()","91f5df58":"# Sample image with masks overlayed\nplt.figure(figsize=(15,8))\nj = 0\nfor i in range(6):\n  plt.subplot(2,3,i+1)\n  while True:\n    if df[\"EncodedPixels\"][j]!=-1:\n      break\n    j+=1\n  seg = decode_pixels(df[\"EncodedPixels\"][j])\n  path = os.path.join(img_dir,df[\"Image_name\"][j])\n  img = cv2.imread(path,0)\n  dest = cv2.addWeighted(img, 0.8, seg, 0.4, 0.0)\n  plt.imshow(dest)\n  plt.title(df[\"Image_name\"][j])\n  j+=1\n  plt.xticks([])\n  plt.yticks([])\nplt.show()","e4a32617":"# Function to preprocess the data \nBASE_DIR = \"..\/input\/understanding_cloud_organization\/train_images\"\nlabels = list(df[\"Label\"].unique())\ndef preprocess(df):\n  data = []\n  for i in range(len(df)):\n    if i % 100 == 0:\n      print(f\"{i} completed\")\n    path = os.path.join(BASE_DIR,df[\"image\"][i])\n    img_arr = cv2.imread(path,1)\n    img_arr = cv2.resize(img_arr,(480,384))\n    channels = []\n    for j in df.columns[1:]:\n      #print(type(df[j][i]),j,i)\n      if type(df[j][i]) is not str:\n            arr = np.zeros(384*480, dtype=np.uint8)\n            arr = arr.reshape(480,384)\n            #img = img.T\n            channels.append(arr.T)\n            continue\n      arr = decode_pixels(df[j][i],label=1)\n      arr = cv2.resize(arr,(480,384))\n      channels.append(arr)\n\n    data.append([img_arr\/255,np.dstack(channels)])\n  return data","cd827896":"# Sanity check on the output\ndata = preprocess(train_df[:5])\nlen(data)","a88b02a1":"# Checking the shape of image\ndata[1][0].shape","a8ba7ec5":"# Checking the shape of segmentation mask\ndata[1][1].shape","5e663271":"img_dir = \"..\/input\/understanding_cloud_organization\/train_images\"\nmasks_dir = \".\/masks\"","23b89ef8":"# utility function for Data Generators\nBASE_DIR = \"..\/input\/understanding_cloud_organization\/train_images\"\nlabels = list(df[\"Label\"].unique())\n\ndef preprocess1(df):\n    # To store the data\n    data = []\n    # Iterating through each of the rows in the dataframe\n    for i in range(len(df)):\n        # Getting the path of the image\n        path = os.path.join(BASE_DIR,df.iloc[i][\"image\"])\n        # Reading in the image\n        img_arr = cv2.imread(path,1)\n        # Resizing it to the proper size\n        img_arr = cv2.resize(img_arr,(480,384))\n        # To store the differnt segmentation maps\n        channels = []\n        # Getting the differnt segmentation maps\n        for j in df.columns[1:]:\n          # making an empty map if the image doesn't contain a label\n          if type(df.iloc[i][j]) is not str:\n                arr = np.zeros(384*480, dtype=np.uint8)\n                arr = arr.reshape(480,384)\n                channels.append(arr.T)\n                continue\n          # Creating the segmentation map\n          arr = decode_pixels(df.iloc[i][j],label=1)\n          # Resizing it to proper size\n          arr = cv2.resize(arr,(480,384))\n          channels.append(arr)\n        # Adding to the data list as [image, output seg map]\n        data.append([img_arr\/255,np.dstack(channels)])\n    # Spliting the data into input and output\n    imgs = []\n    masks = []\n    for i, j in data:\n        imgs.append(i)\n        masks.append(j)\n\n    return np.array(imgs), np.array(masks).astype(np.float)","2dced396":"# Creating a custom Data Generator\ndef data_gen(img_folder, df, batch_size):\n    \n    c = 0 \n    n = list(df[\"image\"])\n    while True:\n        c1 = c+batch_size\n        \n        if c1 > len(df):\n            c1 = len(df)\n        imgs, masks = preprocess1(df.iloc[c:c1])\n        c = c1\n        if c1 >= len(df):\n            c = 0\n        if imgs.shape == (batch_size,384, 480, 3) and masks.shape == (batch_size,384, 480, 4):\n            yield imgs, masks\n        else:\n            continue\n    ","d80eca3a":"# Sample check to see if the code is working\nthis = data_gen(img_folder=img_dir, df=train_df, batch_size=8)","c93acd0e":"# Checking\nk = 0\nfor i,j in this:\n    if k == 5:\n        break\n    print(i.shape,j.shape)\n    k+=1\n    ","1c89a59d":"# Installing the segmentation_models library\n! pip install segmentation_models","39bfc936":"# Loading the dependencies\nimport tensorflow as tf\nimport segmentation_models as sm\nimport glob\nimport cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\n\nfrom tensorflow.keras.utils import normalize\nfrom keras.metrics import MeanIoU\n\nsm.set_framework('tf.keras')\n\nsm.framework()","c540bbf8":"BACKBONE = 'efficientnetb5'\nLEARNING_RATE = 0.002\nHEIGHT = 384\nWIDTH = 480\nCHANNELS = 3\nN_CLASSES = 4\nES_PATIENCE = 10\nRLROP_PATIENCE = 3\nDECAY = 0.0001\nDECAY_DROP = 0.2\nmodel_path = f'uNet_%s_%sx%s_lr{LEARNING_RATE}.h5' % (BACKBONE, HEIGHT, WIDTH)","fbe1c365":"# Setting up the optimizer\noptim = tf.keras.optimizers.Adam(LEARNING_RATE)\n\n# Setting up the metrics\nmetrics = [sm.metrics.IOUScore(threshold=0.50),sm.metrics.FScore(threshold=0.5)]\n\n# Setting up the Callbacks\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\nes = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\nrlrop = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n\n# Final list of call backs\ncallback_list = [checkpoint, es, rlrop]","e12fd93b":"# Defining model\nmodel = sm.Unet(backbone_name=BACKBONE, \n                encoder_weights='imagenet',\n                classes=N_CLASSES,\n                activation='sigmoid', encoder_freeze=True,\n                input_shape=(HEIGHT, WIDTH, CHANNELS))\n\n# Compiling the model\nmodel.compile(optimizer=optim, loss=sm.losses.bce_dice_loss, metrics=metrics)\n\n# Model summary\nmodel.summary()","a7bd600b":"# Total number of images\nprint(f\"Total size of data {len(train_df)}\")","7846b5a3":"# Training and Testing Data\ntrain = train_df.iloc[0:4500]\ntest = train_df.iloc[4500:5000]\nbatch_size = 8","d57019e5":"# Data Generators\nTrain_data_generator = data_gen(img_folder=img_dir, df=train, batch_size=batch_size)\nValidation_data_generator = data_gen(img_folder=img_dir, df=test, batch_size=batch_size)","2ed67bd8":"history = model.fit(Train_data_generator,epochs=40,\n                             steps_per_epoch=(4500\/\/batch_size),\n                             validation_data=Validation_data_generator,\n                             validation_steps=(500\/\/batch_size),\n                             callbacks=callback_list)","6100a776":"res = model.evaluate(Validation_data_generator,steps=500\/\/16)\nprint(f\"Loss:{res[0]}\")\nprint(f\"IoU:{res[1]}\")\nprint(f\"F1:{res[2]}\")   ","d382848a":"model.save(f\"clouds_efficientnetb5_iouscore-{str(res[1])[:5]}.h5\")","e6f80988":"# All the curves together\ndf_res = pd.DataFrame(history.history)\nplt.title(\"Model Performance\")\nplt.plot(df_res)\nplt.show()","cba6459f":"# Looking at the columns of the result df\ndf_res.columns","e5c8e2cd":"# Each of the learning curves for the model has been displayed separately\ncolors = \"bgrcy\"\nplt.figure(figsize=(15,15))\nfor i in range(len(df_res.columns)):\n    plt.subplot(4,2,i+1)\n    df_res[df_res.columns[i]].plot(color=colors[random.randint(0,4)])\n    plt.title(df_res.columns[i])\nplt.show()","171eef40":"# Thresholding function to be applied on the output\ndef threshold(x):\n    if x>0.5:\n        return 1\n    else:\n        return 0\n\n# Making the function applicable to a numpy array\nexp =np.vectorize(threshold)","547851b2":"# Function to compare the predicted mask to the actual mask\n# Function simply plots the actual and predicted mask of the 4 classes \n# side by side\ndef compare_masks(actual,predicted):\n    plt.figure(figsize=(15,15))\n    j = 0\n    for i in range(8):\n        plt.subplot(4,2,i+1)\n        if (i+1)%2!=0:\n            plt.title(f\"Actual-{labels[j]}\")\n            plt.imshow(actual[:,:,j])\n        else:\n            plt.title(f\"Predicted-{labels[j]}\")\n            plt.imshow(predicted[:,:,j])\n            j+=1    \n    plt.show()","56e14ad4":"# Function to predict and visualise the outputs of the models\n# Simply combine the above 2 functions together\ndef predict(df):\n    data = preprocess(df)\n    output = model.predict(data[0][0][ np.newaxis, ...])\n    output = exp(output)\n    compare_masks(data[0][1],output[0])\n    return     ","616b3aaf":"# Function to display the actual image\ndef display_img(img_name):\n    path = os.path.join(img_dir,img_name)\n    img = cv2.imread(path,1)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)","0c71ddd8":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5107])","1d915053":"# Performance of model on image\ntest = pd.DataFrame(train_df.iloc[5107]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","1a71ec97":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5101])","19f0cbf3":"test = pd.DataFrame(train_df.iloc[5101]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","08f9b733":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5105])","500c5ae8":"test = pd.DataFrame(train_df.iloc[5105]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","6bc797fd":"#import keras","14f90ce7":"#model.load_weights('..\/input\/modelforsegmentation\/clouds_iouscore-0.39.h5')","7a665ebb":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5108])","f6440205":"test = pd.DataFrame(train_df.iloc[5108]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","7b551c19":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5117])","0dd06f18":"test = pd.DataFrame(train_df.iloc[5117]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","e65bfade":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][510])","cb1fdb13":"test = pd.DataFrame(train_df.iloc[510]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","f868fb2f":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5000])","4e63473e":"test = pd.DataFrame(train_df.iloc[5000]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","830ef216":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5111])","91209438":"test = pd.DataFrame(train_df.iloc[5111]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","46fdb5ef":"# Displaying the actual image\ndisplay_img(train_df[\"image\"][5222])","85af54cb":"test = pd.DataFrame(train_df.iloc[5222]).T.reset_index().drop(\"index\",axis=1)\npredict(test)","5893cbaf":"# Importing keras\nimport keras","69070cfd":"# Creating a model with the same architecture\nloaded_model = sm.Unet(backbone_name=BACKBONE, \n                encoder_weights='imagenet',\n                classes=N_CLASSES,\n                activation='sigmoid', encoder_freeze=True,\n                input_shape=(HEIGHT, WIDTH, CHANNELS))\n\n# COmpiling the model\nloaded_model.compile(optimizer=optim, loss=sm.losses.bce_dice_loss, metrics=metrics)","eb757424":"loaded_model.load_weights('..\/input\/trained-model\/clouds_effientnetb5_iouscore-0.417.h5')","02bbbf46":"# For testing\ndef predict_loaded(df):\n    data = preprocess(df)\n    output = loaded_model.predict(data[0][0][ np.newaxis, ...])\n    output = exp(output)\n    compare_masks(data[0][1],output[0])\n    return ","46476a25":"# Testing the model\ntest = pd.DataFrame(train_df.iloc[5222]).T.reset_index().drop(\"index\",axis=1)\npredict_loaded(test)","e021c1a9":"## Displaying some random segment maps","5e3e434f":"## Visualizing each curve separately","88085c4c":"### 8:","c6a75714":"### 9:","aef8ae75":"### Displaying some random images","1beec5e3":"# Exploring the segmentation masks","a530f2e4":"### 3:","d98491c8":"## Number of maps per image","5f796a13":"# Training the model","f6b5c4aa":"## Post processing the output from model","bf7d8610":"# Exploring the data","5be3a618":"# Loading and displaying satellite images","fb1bd14d":"### Custom data generators","8883ceab":"### Creating the data generators for batch learning","18468d1b":"### 4:","598bfadc":"# Model building","a5ed56e9":"## Testing the model on unseen data","f0e29e3c":"### 5:","069022fc":"#### Replacing the null values with the -1","5d40dc61":"### 7:","4409cf93":"# Loading in the necessary libraries","a5cdb8c8":"# Saving the best Model","11c7250d":"# Preprocessing the data","21750770":"# Setting up the Hyperparamters","098b4c89":"### 6","00fb2ac6":"## Loading the data","86662248":"# Creating a new df","67886a5b":"# Creating a custom generator for batch learning","4f4cdbb6":"# Setting the training and testing data","a393cc07":"### 1:","ed22c4c5":"# Visualizing the mask overlaid images","74fb025c":"# Performance of model on unseen images","7edf37e5":"### Splitting the data into train and test","3d8db87a":"# Evaluating the model on test data","b451f63e":"### 2:","76577f11":"# Loading in the trained model","7e83ec66":"# Visualising the training of model","3b1df337":"# Defining the model architecture","2da95f54":"### Function to decode the segmentation maps"}}